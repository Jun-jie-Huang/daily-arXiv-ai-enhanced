<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 40]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Incentives or Ontology? A Structural Rebuttal to OpenAI's Hallucination Thesis](https://arxiv.org/abs/2512.14801)
*Richard Ackermann,Simeon Emanuilov*

Main category: cs.CL

TL;DR: 本文挑战了大语言模型幻觉现象是由评估激励错误引起的观点，提出幻觉是Transformer模型的结构必然性。


<details>
  <summary>Details</summary>
Motivation: 质疑当前观点，即幻觉源于评估激励，探讨幻觉是否为Transformer的结构性问题。

Method: 利用结构性幻觉的前期研究及使用许可预言机的实验证明幻觉是模型结构导致，而非优化失败。

Result: 实验显示，幻觉只能通过外部真值验证和弃权模块消除，而非通过激励调整、提示或微调。许可预言机提供了所需的真实依据，达成完美的弃权精确度。

Conclusion: 幻觉是生成架构的结构性特征，可靠的AI需采用混合系统以区分语言流畅性与认知责任。

Abstract: OpenAI has recently argued that hallucinations in large language models result primarily from misaligned evaluation incentives that reward confident guessing rather than epistemic humility. On this view, hallucination is a contingent behavioral artifact, remediable through improved benchmarks and reward structures. In this paper, we challenge that interpretation. Drawing on previous work on structural hallucination and empirical experiments using a Licensing Oracle, we argue that hallucination is not an optimization failure but an architectural inevitability of the transformer model.
  Transformers do not represent the world; they model statistical associations among tokens. Their embedding spaces form a pseudo-ontology derived from linguistic co-occurrence rather than world-referential structure. At ontological boundary conditions - regions where training data is sparse or incoherent - the model necessarily interpolates fictional continuations in order to preserve coherence. No incentive mechanism can modify this structural dependence on pattern completion.
  Our empirical results demonstrate that hallucination can only be eliminated through external truth-validation and abstention modules, not through changes to incentives, prompting, or fine-tuning. The Licensing Oracle achieves perfect abstention precision across domains precisely because it supplies grounding that the transformer lacks.
  We conclude that hallucination is a structural property of generative architectures and that reliable AI requires hybrid systems that distinguish linguistic fluency from epistemic responsibility.

</details>


### [2] [T5Gemma 2: Seeing, Reading, and Understanding Longer](https://arxiv.org/abs/2512.14856)
*Biao Zhang,Paul Suganthan,Gaël Liu,Ilya Philippov,Sahil Dua,Ben Hora,Kat Black,Gus Martins,Omar Sanseviero,Shreya Pathak,Cassidy Hardin,Francesco Visin,Jiageng Zhang,Kathleen Kenealy,Qin Yin,Olivier Lacombe,Armand Joulin,Tris Warkentin,Adam Roberts*

Main category: cs.CL

TL;DR: T5Gemma 2是一款新一代轻量级开源编码器-解码器模型，支持多语言、多模态及长文本处理。


<details>
  <summary>Details</summary>
Motivation: 提升模型在多语言、多模态及长上下文理解上的能力，同时提高模型效率。

Method: 基于预训练的解码器模型通过UL2方法适配为编码器-解码器模型，结合Gemma 3的多模态技术，并采用共享词嵌入和合并注意力机制提升效率。

Result: T5Gemma 2在预训练表现上可比肩及优于Gemma 3，在后训练性能上显著提升，对长文本建模表现优异。

Conclusion: 该方法适用于多架构和多模态，编码器-解码器结构对长文本处理具有独特优势，预训练模型已公开供研究使用。

Abstract: We introduce T5Gemma 2, the next generation of the T5Gemma family of lightweight open encoder-decoder models, featuring strong multilingual, multimodal and long-context capabilities. T5Gemma 2 follows the adaptation recipe (via UL2) in T5Gemma -- adapting a pretrained decoder-only model into an encoder-decoder model, and extends it from text-only regime to multimodal based on the Gemma 3 models. We further propose two methods to improve the efficiency: tied word embedding that shares all embeddings across encoder and decoder, and merged attention that unifies decoder self- and cross-attention into a single joint module. Experiments demonstrate the generality of the adaptation strategy over architectures and modalities as well as the unique strength of the encoder-decoder architecture on long context modeling. Similar to T5Gemma, T5Gemma 2 yields comparable or better pretraining performance and significantly improved post-training performance than its Gemma 3 counterpart. We release the pretrained models (270M-270M, 1B-1B and 4B-4B) to the community for future research.

</details>


### [3] [Integrating Large Language Models and Knowledge Graphs to Capture Political Viewpoints in News Media](https://arxiv.org/abs/2512.14887)
*Massimiliano Fadda,Enrico Motta,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino*

Main category: cs.CL

TL;DR: 该论文提出了一种改进的新闻观点分类管道，通过微调大语言模型和引入Wikidata语义描述，提高了对英国移民辩论相关观点分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 新闻媒体在民主社会中通过特定话题和观点塑造公共话语，理解这些动态有助于评估媒体报道的公平性和平衡性。

Method: 通过微调大语言模型进行观点分类，并利用Wikidata的相关行为者语义描述丰富论点表现，结合人机混合方法识别观点并分类相关论点。

Result: 两种机制单独使用均提升分类性能，结合使用则效果最佳，尤其是利用能处理长输入的大语言模型时表现突出。

Conclusion: 微调大语言模型与引入语义描述相结合的观点分类方法有效提升了新闻观点分类的准确性，有助于更好地分析媒体报道的观点分布。

Abstract: News sources play a central role in democratic societies by shaping political and social discourse through specific topics, viewpoints and voices. Understanding these dynamics is essential for assessing whether the media landscape offers a balanced and fair account of public debate. In earlier work, we introduced a pipeline that, given a news corpus, i) uses a hybrid human-machine approach to identify the range of viewpoints expressed about a given topic, and ii) classifies relevant claims with respect to the identified viewpoints, defined as sets of semantically and ideologically congruent claims (e.g., positions arguing that immigration positively impacts the UK economy). In this paper, we improve this pipeline by i) fine-tuning Large Language Models (LLMs) for viewpoint classification and ii) enriching claim representations with semantic descriptions of relevant actors drawn from Wikidata. We evaluate our approach against alternative solutions on a benchmark centred on the UK immigration debate. Results show that while both mechanisms independently improve classification performance, their integration yields the best results, particularly when using LLMs capable of processing long inputs.

</details>


### [4] [DrugRAG: Enhancing Pharmacy LLM Performance Through A Novel Retrieval-Augmented Generation Pipeline](https://arxiv.org/abs/2512.14896)
*Houman Kazemzadeh,Kiarash Mokhtari Dizaji,Seyed Reza Tavakoli,Farbod Davoodi,MohammadReza KarimiNejad,Parham Abed Azad,Ali Sabzi,Armin Khosravi,Siavash Ahmadi,Mohammad Hossein Rohban,Glolamali Aminian,Tahereh Javaheri*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在药学执照题库问答任务上的表现，并提出了DrugRAG方法，通过外部结构化药物知识提升模型准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在药学题目上准确率有限，且模型本体难以改动，需开发一种既能提升准确率又无需修改模型架构的方法。

Method: 使用141题药学数据集测试11个不同参数规模的模型，提出DrugRAG三步检索增强生成流程，基于已验证药物知识库为模型提示提供证据支持，无需更改模型参数。

Result: 未经增强的模型准确率在46%-92%之间，参数少于80亿的模型准确率低于50%。DrugRAG使所有模型准确率提升7-21个百分点，如Gemma 3 27B从61%提升至71%，Llama 3.1 8B从46%提升至67%。

Conclusion: 通过DrugRAG外部药物知识整合显著提升了大型语言模型在药学任务的表现，为药学相关AI应用提供了基于证据的实用增强方案。

Abstract: Objectives: To evaluate large language model (LLM) performance on pharmacy licensure-style question-answering (QA) tasks and develop an external knowledge integration method to improve their accuracy.
  Methods: We benchmarked eleven existing LLMs with varying parameter sizes (8 billion to 70+ billion) using a 141-question pharmacy dataset. We measured baseline accuracy for each model without modification. We then developed a three-step retrieval-augmented generation (RAG) pipeline, DrugRAG, that retrieves structured drug knowledge from validated sources and augments model prompts with evidence-based context. This pipeline operates externally to the models, requiring no changes to model architecture or parameters.
  Results: Baseline accuracy ranged from 46% to 92%, with GPT-5 (92%) and o3 (89%) achieving the highest scores. Models with fewer than 8 billion parameters scored below 50%. DrugRAG improved accuracy across all tested models, with gains ranging from 7 to 21 percentage points (e.g., Gemma 3 27B: 61% to 71%, Llama 3.1 8B: 46% to 67%) on the 141-item benchmark.
  Conclusion: We demonstrate that external structured drug knowledge integration through DrugRAG measurably improves LLM accuracy on pharmacy tasks without modifying the underlying models. This approach provides a practical pipeline for enhancing pharmacy-focused AI applications with evidence-based information.

</details>


### [5] [Multiscale Aggregated Hierarchical Attention (MAHA): A Game Theoretic and Optimization Driven Approach to Efficient Contextual Modeling in Large Language Models](https://arxiv.org/abs/2512.14925)
*Caner Erden*

Main category: cs.CL

TL;DR: 提出MAHA，一种通过多尺度层次化注意力机制有效降低长序列中自注意力计算复杂度的方法。


<details>
  <summary>Details</summary>
Motivation: 解决多头自注意力机制在处理长序列时计算复杂度高，且现有稀疏和线性化注意力方法在全局依赖和语义粒度捕捉上存在不足的问题。

Method: 提出Multiscale Aggregated Hierarchical Attention（MAHA），通过可学习的下采样算子将输入序列动态划分为多层次尺度，并将尺度特定的注意力矩阵聚合建模为资源分配问题，采用凸优化或基于纳什均衡的博弈论方法求解。使用可微分优化层实现端到端训练，结合混合膨胀卷积的Transformer骨干结构。

Result: 在序列长度为4096时，MAHA相比标准注意力机制在计算量（FLOPs）上降低了81%，表现出更优的可扩展性。

Conclusion: MAHA通过引入层次化多尺度注意力结合优化理论，为长序列上下文的大规模语言模型提供了一种高效且理论优化的解决方案，弥合了优化理论与序列建模的鸿沟。

Abstract: The quadratic computational complexity of MultiHead SelfAttention (MHSA) remains a fundamental bottleneck in scaling Large Language Models (LLMs) for longcontext tasks. While sparse and linearized attention mechanisms attempt to mitigate this, they often compromise the representation of global dependencies or fail to capture multiscale semantic granularity effectively. In this paper, we propose Multiscale Aggregated Hierarchical Attention (MAHA), a novel architectural framework that reformulates the attention mechanism through hierarchical decomposition and mathematically rigorous aggregation. Unlike conventional approaches that treat token interactions at a single resolution, MAHA dynamically partitions the input sequence into hierarchical scales via learnable downsampling operators. The core innovation lies in its aggregation strategy: we model the fusion of scalespecific attention matrices as a resource allocation problem, solved via a convex optimization framework or a Nash equilibriumbased gametheoretic approach. This ensures a theoretically optimal balance between local nuance and global context fidelity. Implemented within a hybrid dilatedconvolutional transformer backbone, MAHA utilizes differentiable optimization layers to enable endtoend training. Experimental evaluations demonstrate that MAHA achieves superior scalability; empirical FLOPs analysis confirms an 81% reduction in computational cost at a sequence length of 4096 compared to standard attention. This work bridges the gap between optimization theory and sequence modeling, offering a scalable solution for nextgeneration LLMs.

</details>


### [6] [Parameter Efficient Multimodal Instruction Tuning for Romanian Vision Language Models](https://arxiv.org/abs/2512.14926)
*George-Andrei Dima,Dumitru-Clementin Cercel*

Main category: cs.CL

TL;DR: 本研究针对资源匮乏的罗马尼亚语，翻译并扩展了Flickr30k数据集，利用开源大模型改进了视觉问答和图像描述生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 弥合多模态自然语言处理资源在低资源语言（如罗马尼亚语）上的差距，推动生成式人工智能的普及。

Method: 将Flickr30k数据集翻译为罗马尼亚语，并利用开源大语言模型扩展视觉问答数据；使用LoRA方法针对三类主流视觉语言模型（LLaMA 3.2，LLaVA 1.6，Qwen2）进行微调。

Result: 模型在罗马尼亚语视觉问答和图像描述生成任务中表现提升，Qwen2-VL-RoVQA模型在BERTScore F1指标上分别提升6.05%和2.61%；语法错误显著减少，语言流畅性增强。

Conclusion: 通过数据集翻译与扩展及高效微调，显著提升了低资源语言罗马尼亚语在多模态任务上的表现与语言质量。

Abstract: Focusing on low-resource languages is an essential step toward democratizing generative AI. In this work, we contribute to reducing the multimodal NLP resource gap for Romanian. We translate the widely known Flickr30k dataset into Romanian and further extend it for visual question answering by leveraging open-source LLMs. We demonstrate the usefulness of our datasets by fine-tuning open-source VLMs on Romanian visual question answering. We select VLMs from three widely used model families: LLaMA 3.2, LLaVA 1.6, and Qwen2. For fine-tuning, we employ the parameter-efficient LoRA method. Our models show improved Romanian capabilities in visual QA, as well as on tasks they were not trained on, such as Romanian image description generation. The seven-billion-parameter Qwen2-VL-RoVQA obtains top scores on both tasks, with improvements of +6.05% and +2.61% in BERTScore F1 over its original version. Finally, the models show substantial reductions in grammatical errors compared to their original forms, indicating improvements not only in language understanding but also in Romanian fluency.

</details>


### [7] [Cross-Tokenizer Likelihood Scoring Algorithms for Language Model Distillation](https://arxiv.org/abs/2512.14954)
*Buu Phan,Ashish Khisti,Karen Ullrich*

Main category: cs.CL

TL;DR: 本文提出了一种利用BPE算法隐含递归结构解决不同分词器之间词汇表不匹配的问题，实现跨分词器的序列似然估计，提升了知识蒸馏的效果和模型性能。


<details>
  <summary>Details</summary>
Motivation: 不同语言模型在知识蒸馏中需要共享概率空间，但当教师和学生模型使用不同的分词器，尤其是词汇量不一致时，计算下一个词元的似然比存在挑战。

Method: 利用BPE算法的隐式递归结构，构建了一个概率框架，实现不同词汇表之间的似然评分，分别针对词汇表子集和任意词汇表两种情况，设计了精确和近似计算方法。

Result: 子集词汇表情况下，仅需常数模型评估次数即计算精确似然，使Qwen2.5-1.5B模型蒸馏时内存减少12%，性能提升4%；广义情况通过无损方案及快速近似应用于数学推理任务，使GSM8K准确率提升超过2%。

Conclusion: 本文方法有效解决了不同分词器带来的词汇不匹配问题，优化了知识蒸馏流程，显著提升了模型的内存效率和任务表现。

Abstract: Computing next-token likelihood ratios between two language models (LMs) is a standard task in training paradigms such as knowledge distillation. Since this requires both models to share the same probability space, it becomes challenging when the teacher and student LMs use different tokenizers, for instance, when edge-device deployment necessitates a smaller vocabulary size to lower memory overhead. In this work, we address this vocabulary misalignment problem by uncovering an implicit recursive structure in the commonly deployed Byte-Pair Encoding (BPE) algorithm and utilizing it to create a probabilistic framework for cross-tokenizer likelihood scoring. Our method enables sequence likelihood evaluation for vocabularies different from the teacher model native tokenizer, addressing two specific scenarios: when the student vocabulary is a subset of the teacher vocabulary, and the general case where it is arbitrary. In the subset regime, our framework computes exact likelihoods and provides next-token probabilities for sequential sampling with only O(1) model evaluations per token. When used for distillation, this yields up to a 12% reduction in memory footprint for the Qwen2.5-1.5B model while also improving baseline performance up to 4% on the evaluated tasks. For the general case, we introduce a rigorous lossless procedure that leverages BPE recursive structure, complemented by a fast approximation that keeps large-vocabulary settings practical. Applied to distillation for mathematical reasoning, our approach improves GSM8K accuracy by more than 2% over the current state of the art.

</details>


### [8] [Evaluating Large Language Models on Multimodal Chemistry Olympiad Exams](https://arxiv.org/abs/2512.14989)
*Yiming Cui,Xin Yao,Yuxuan Qin,Xin Li,Shijin Wang,Guoping Hu*

Main category: cs.CL

TL;DR: 本文系统评估了40种多模态大型语言模型在化学科学推理中的表现，发现当前模型在视觉与语言融合方面存在显著不足，提出了链式思维提示提升性能的方法。


<details>
  <summary>Details</summary>
Motivation: 大多数大型语言模型在处理依赖符号图、分子结构和结构化视觉数据的化学科学推理任务时表现不佳，亟需对这些模型的多模态能力进行评估和改进。

Method: 收集了超过二十年美国国家化学奥林匹克题库，设计涵盖视觉与文本综合推理的多模态评测基准，系统测试了包括GPT-5和其他开源模型的40种多模态模型，并通过消融实验和解释性分析探索链式思维提示的作用。

Result: 多数模型在视觉与语言模态融合存在明显挑战，移除图片反而提升部分题目准确率；链式思维提示显著提高了准确率和视觉理解能力。

Conclusion: 当前多模态大型语言模型的科学推理能力存在重要限制，链式思维提示是提升模型多模态集成和推理性能的有效策略，研究为领域特化的多模态AI系统的发展提供了实用的基准和改进方向。

Abstract: Multimodal scientific reasoning remains a significant challenge for large language models (LLMs), particularly in chemistry, where problem-solving relies on symbolic diagrams, molecular structures, and structured visual data. Here, we systematically evaluate 40 proprietary and open-source multimodal LLMs, including GPT-5, o3, Gemini-2.5-Pro, and Qwen2.5-VL, on a curated benchmark of Olympiad-style chemistry questions drawn from over two decades of U.S. National Chemistry Olympiad (USNCO) exams. These questions require integrated visual and textual reasoning across diverse modalities. We find that many models struggle with modality fusion, where in some cases, removing the image even improves accuracy, indicating misalignment in vision-language integration. Chain-of-Thought prompting consistently enhances both accuracy and visual grounding, as demonstrated through ablation studies and occlusion-based interpretability. Our results reveal critical limitations in the scientific reasoning abilities of current MLLMs, providing actionable strategies for developing more robust and interpretable multimodal systems in chemistry. This work provides a timely benchmark for measuring progress in domain-specific multimodal AI and underscores the need for further advances at the intersection of artificial intelligence and scientific reasoning.

</details>


### [9] [DASH: Dialogue-Aware Similarity and Handshake Recognition for Topic Segmentation in Public-Channel Conversations](https://arxiv.org/abs/2512.15042)
*Sijin Sun,Liangbin Zhao,Ming Deng,Xiuju Fu*

Main category: cs.CL

TL;DR: 本文提出了基于大模型的对话主题分割框架DASH-DTS，通过话题转移检测、语境增强和精选样本生成，提升了模型的鲁棒性和分割准确率，并发布了首个真实海事VHF对话数据集VHF-Dial。


<details>
  <summary>Details</summary>
Motivation: 传统对话主题分割方法难以应对海事VHF这样非正式且隐含转换的任务导向型公共频道通信，需改进方法提升理解能力。

Method: DASH-DTS框架包含对话握手识别实现话题转移检测，基于相似度引导的上下文示例选择，以及生成精选正负样本以增强模型判别力和鲁棒性，同时产生可解释的推理和置信度。

Result: 该方法在VHF-Dial数据集及标准基准测试中表现出多项最先进的主题分割准确率，实现了稳定的监测和决策支持基础。

Conclusion: DASH-DTS框架有效提升了海事VHF对话的主题分割性能，为实践中的对话监控和支持提供了强有力技术保障。

Abstract: Dialogue Topic Segmentation (DTS) is crucial for understanding task-oriented public-channel communications, such as maritime VHF dialogues, which feature informal speech and implicit transitions. To address the limitations of traditional methods, we propose DASH-DTS, a novel LLM-based framework. Its core contributions are: (1) topic shift detection via dialogue handshake recognition; (2) contextual enhancement through similarity-guided example selection; and (3) the generation of selective positive and negative samples to improve model discrimination and robustness. Additionally, we release VHF-Dial, the first public dataset of real-world maritime VHF communications, to advance research in this domain. DASH-DTS provides interpretable reasoning and confidence scores for each segment. Experimental results demonstrate that our framework achieves several sota segmentation trusted accuracy on both VHF-Dial and standard benchmarks, establishing a strong foundation for stable monitoring and decision support in operational dialogues.

</details>


### [10] [SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification](https://arxiv.org/abs/2512.15052)
*Hongbo Wang,MaungMaung AprilPyone,Isao Echizen*

Main category: cs.CL

TL;DR: 本文提出了一种名为SGM的多模态大语言模型去毒方法，通过白盒神经元级干预，软抑制有害神经元，显著降低模型有害输出。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型从弱过滤预训练语料继承有害、偏见和NSFW信号，导致安全风险，传统的训练后去毒方法难以应对对抗性触发。

Method: SGM对少量有害神经元进行专家加权软抑制，不更新参数，有选择地校正跨模态激活，白盒可解释干预。

Result: 在开源多模态大语言模型上，SGM能将有害率从48.2%降至2.5%，同时保持模型流畅性和多模态推理能力。

Conclusion: SGM提供了一种低成本、可扩展且可解释的多模态生成去毒方案，结合现有方法可进一步提升安全性能。

Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort.
  Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks, especially under adversarial triggers that late, opaque training-free detoxification methods struggle to handle. We propose SGM, a white-box neuron-level multimodal intervention that acts like safety glasses for toxic neurons: it selectively recalibrates a small set of toxic expert neurons via expertise-weighted soft suppression, neutralizing harmful cross-modal activations without any parameter updates. We establish MM-TOXIC-QA, a multimodal toxicity evaluation framework, and compare SGM with existing detoxification techniques. Experiments on open-source MLLMs show that SGM mitigates toxicity in standard and adversarial conditions, cutting harmful rates from 48.2\% to 2.5\% while preserving fluency and multimodal reasoning. SGM is extensible, and its combined defenses, denoted as SGM*, integrate with existing detoxification methods for stronger safety performance, providing an interpretable, low-cost solution for toxicity-controlled multimodal generation.

</details>


### [11] [The Meta-Prompting Protocol: Orchestrating LLMs via Adversarial Feedback Loops](https://arxiv.org/abs/2512.15053)
*Fanzhe Fu*

Main category: cs.CL

TL;DR: 本文提出了Meta-Prompting协议，通过生成器、审计器和优化器的三元拓扑结构，将大语言模型转化为可编程、自我优化的系统，从而提高其在关键任务中的确定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有基于启发式的提示工程方法无法满足关键任务应用中对于确定性和可靠性的需求，因此需要对大语言模型的交互范式进行根本性重构。

Method: 引入Meta-Prompting协议，采用生成器、审计器和优化器三元结构，将自然语言指令视为可微分变量，构建语义计算图，并利用文本批评作为梯度，实现自动文本微分以减少模型幻觉和防止模型崩溃。

Result: 通过声明式编程范式（DSPy）和自动文本微分（TextGrad）验证了该方法的理论可行性，为概率计算时代的“可观测软件工程”奠定基础。

Conclusion: Meta-Prompting协议提供了一种系统化且具理论支撑的框架，使大语言模型能以可编程和自我优化的方式运行，满足关键任务应用对确定性和可靠性的需求。

Abstract: The transition of Large Language Models (LLMs) from stochastic chat interfaces to reliable software components necessitates a fundamental re-engineering of interaction paradigms. Current methodologies, predominantly heuristic-based "prompt engineering," fail to provide the deterministic guarantees required for mission-critical applications. We introduce the Meta-Prompting Protocol, a rigorous theoretical framework that formalizes the orchestration of LLMs as a programmable, self-optimizing system. Central to this protocol is the Adversarial Trinity, a tripartite topology comprising a Generator (P), an Auditor (A), and an Optimizer (O). By treating natural language instructions as differentiable variables within a semantic computation graph and utilizing textual critiques as gradients, this architecture mitigates hallucination and prevents model collapse. We demonstrate the theoretical viability of this approach using declarative programming paradigms (DSPy) and automatic textual differentiation (TextGrad), establishing a foundation for "Observable Software Engineering" in the era of probabilistic computing.

</details>


### [12] [Beyond Majority Voting: Towards Fine-grained and More Reliable Reward Signal for Test-Time Reinforcement Learning](https://arxiv.org/abs/2512.15146)
*Weiqin Wang,Yile Wang,Kehao Chen,Hui Huang*

Main category: cs.CL

TL;DR: 本文提出了SCOPE框架，通过置信度加权和动态子群划分，改进了基于多数投票的伪标签推断，提升了大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的投票策略易导致确认偏差和稀疏奖励问题，限制模型性能提升。

Method: SCOPE结合步骤置信度加权和动态子群划分，通过局部共识生成多样化的监督信号，促进更广泛的探索。

Result: SCOPE在多个模型和基准测试中表现优越，在AIME 2025和AMC测试集上分别提升了13.1%和8.1%。

Conclusion: SCOPE有效解决了多数投票策略的局限性，为增强大语言模型推理能力提供了新的思路。

Abstract: Test-time reinforcement learning mitigates the reliance on annotated data by using majority voting results as pseudo-labels, emerging as a complementary direction to reinforcement learning with verifiable rewards (RLVR) for improving reasoning ability of large language models (LLMs). However, this voting strategy often induces confirmation bias and suffers from sparse rewards, limiting the overall performance. In this work, we propose subgroup-specific step-wise confidence-weighted pseudo-label estimation (SCOPE), a framework integrating model confidence and dynamic subgroup partitioning to address these issues. Specifically, SCOPE integrates the proposed step-wise confidence into pseudo label deduction, prioritizing high-quality reasoning paths over simple frequency count. Furthermore, it dynamically partitions the candidate outputs pool into independent subgroups by balancing reasoning quality against exploration diversity. By deriving local consensus via repeat sampling for each sub group, SCOPE provides diverse supervision targets to encourage broader exploration. We conduct experiments across various models and benchmarks, experimental results show that SCOPE consistently outperforms recent baselines. Notably, SCOPE achieving relative improvements of 13.1\% on challenging AIME 2025 and 8.1\% on AMC. The code is released at \href{https://github.com/szu-tera/SCOPE}{https://github.com/szu-tera/SCOPE}.

</details>


### [13] [Rakuten Data Release: A Large-Scale and Long-Term Reviews Corpus for Hotel Domain](https://arxiv.org/abs/2512.15151)
*Yuki Nakayama,Koki Hikichi,Yun Ching Liu,Yu Hirate*

Main category: cs.CL

TL;DR: 本文介绍了涵盖2009年至2024年共730万条评价的乐天旅游大规模评论语料库，并分析了2019年至2024年数据漂移的驱动因素。


<details>
  <summary>Details</summary>
Motivation: 构建大规模旅游评论数据集，以支持相关领域的研究和分析。

Method: 收集长期的客户评论数据，包含详细的元数据，并通过统计方法分析数据漂移。

Result: 构建了包含多维度信息的大型评论语料库，统计了数据特征，揭示了2019至2024年间数据漂移的因素。

Conclusion: 该语料库为旅游相关的文本分析和研究提供了丰富资源，并指出了数据变化趋势和潜在影响因素。

Abstract: This paper presents a large-scale corpus of Rakuten Travel Reviews. Our collection contains 7.3 million customer reviews for 16 years, ranging from 2009 to 2024. Each record in the dataset contains the review text, its response from an accommodation, an anonymized reviewer ID, review date, accommodation ID, plan ID, plan title, room type, room name, purpose, accompanying group, and user ratings from different aspect categories, as well as an overall score. We present statistical information about our corpus and provide insights into factors driving data drift between 2019 and 2024 using statistical approaches.

</details>


### [14] [MCP-SafetyBench: A Benchmark for Safety Evaluation of Large Language Models with Real-World MCP Servers](https://arxiv.org/abs/2512.15163)
*Xuanjun Zong,Zhiqi Shen,Lei Wang,Yunshi Lan,Chao Yang*

Main category: cs.CL

TL;DR: 本文提出了MCP-SafetyBench基准测试，用于评估多服务器环境下大型语言模型（LLM）在执行多步推理和跨服务器协调任务时的安全性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型逐渐演化为具备推理和规划能力的自主系统，连接多种异构工具和服务的模型上下文协议（MCP）引入了新的安全风险，而现有的基准测试无法全面捕捉这些风险。

Method: 构建基于真实MCP服务器的MCP-SafetyBench，包含五大领域的多轮任务，整合了涵盖服务器、主机和用户端的20种MCP攻击类型，支持多步推理和不确定性下跨服务器协作的安全评测。

Result: 通过MCP-SafetyBench系统评估主流开源及闭源大型语言模型，发现安全性能差异显著且随着任务复杂度和服务器交互增加，漏洞风险升高。

Conclusion: 结果强调了加强防御措施的紧迫性，MCP-SafetyBench为诊断和缓解现实多服务器MCP部署中的安全风险提供了基础。

Abstract: Large language models (LLMs) are evolving into agentic systems that reason, plan, and operate external tools. The Model Context Protocol (MCP) is a key enabler of this transition, offering a standardized interface for connecting LLMs with heterogeneous tools and services. Yet MCP's openness and multi-server workflows introduce new safety risks that existing benchmarks fail to capture, as they focus on isolated attacks or lack real-world coverage. We present MCP-SafetyBench, a comprehensive benchmark built on real MCP servers that supports realistic multi-turn evaluation across five domains: browser automation, financial analysis, location navigation, repository management, and web search. It incorporates a unified taxonomy of 20 MCP attack types spanning server, host, and user sides, and includes tasks requiring multi-step reasoning and cross-server coordination under uncertainty. Using MCP-SafetyBench, we systematically evaluate leading open- and closed-source LLMs, revealing large disparities in safety performance and escalating vulnerabilities as task horizons and server interactions grow. Our results highlight the urgent need for stronger defenses and establish MCP-SafetyBench as a foundation for diagnosing and mitigating safety risks in real-world MCP deployments.

</details>


### [15] [From NLG Evaluation to Modern Student Assessment in the Era of ChatGPT: The Great Misalignment Problem and Pedagogical Multi-Factor Assessment (P-MFA)](https://arxiv.org/abs/2512.15183)
*Mika Hämäläinen,Kimmo Leiviskä*

Main category: cs.CL

TL;DR: 本文探讨了芬兰大学中NLG评价与学生评分之间的认知相似性，提出了两者面临的“重大错位问题”，并引入了基于过程的多因素评估模型P-MFA，旨在提升评估有效性。


<details>
  <summary>Details</summary>
Motivation: 随着学生越来越多地使用ChatGPT等工具生成复杂作品，传统仅关注最终产品的评估方法失去有效性，需要一种新的评价方式来适应学习过程的变化。

Method: 提出了受多因素认证逻辑启发的教学多因素评估（P-MFA）模型，基于过程、多证据的框架替代传统的结果导向评估方法。

Result: 通过引入P-MFA模型，评估能够更准确地反映学生的学习过程，从而缓解了传统评估方法与现代生成技术使用之间的错位问题。

Conclusion: 提出的P-MFA模型为解决传统评估方法在面对生成式工具时的失效问题提供了有效途径，具有推广潜力。

Abstract: This paper explores the growing epistemic parallel between NLG evaluation and grading of students in a Finnish University. We argue that both domains are experiencing a Great Misalignment Problem. As students increasingly use tools like ChatGPT to produce sophisticated outputs, traditional assessment methods that focus on final products rather than learning processes have lost their validity. To address this, we introduce the Pedagogical Multi-Factor Assessment (P-MFA) model, a process-based, multi-evidence framework inspired by the logic of multi-factor authentication.

</details>


### [16] [RFKG-CoT: Relation-Driven Adaptive Hop-count Selection and Few-Shot Path Guidance for Knowledge-Aware QA](https://arxiv.org/abs/2512.15219)
*Chao Zhang,Minghan Li,Tianrui Lv,Guodong Zhou*

Main category: cs.CL

TL;DR: 提出RFKG-CoT方法，通过关系驱动的自适应跳数选择和少样本路径指导，提升LLM在知识图谱问答中的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱链式推理方法存在跳数选择刚性和路径利用不足的问题，导致LLM产生幻觉和不准确答案。

Method: 采用关系驱动的动态跳数选择器和带有链式思维的少样本示例路径指导，增强推理步骤的灵活性和路径理解能力。

Result: 在四个知识图谱问答基准测试中，RFKG-CoT相比KG-CoT最高提升准确率14.7个百分点，消融实验验证两大模块互补效果显著。

Conclusion: 通过动态调整推理跳数和示例路径引导，RFKG-CoT有效提升了知识图谱辅助的大语言模型问答的可靠性和准确性。

Abstract: Large language models (LLMs) often generate hallucinations in knowledge-intensive QA due to parametric knowledge limitations. While existing methods like KG-CoT improve reliability by integrating knowledge graph (KG) paths, they suffer from rigid hop-count selection (solely question-driven) and underutilization of reasoning paths (lack of guidance). To address this, we propose RFKG-CoT: First, it replaces the rigid hop-count selector with a relation-driven adaptive hop-count selector that dynamically adjusts reasoning steps by activating KG relations (e.g., 1-hop for direct "brother" relations, 2-hop for indirect "father-son" chains), formalized via a relation mask. Second, it introduces a few-shot in-context learning path guidance mechanism with CoT (think) that constructs examples in a "question-paths-answer" format to enhance LLMs' ability to understand reasoning paths. Experiments on four KGQA benchmarks show RFKG-CoT improves accuracy by up to 14.7 pp (Llama2-7B on WebQSP) over KG-CoT. Ablations confirm the hop-count selector and the path prompt are complementary, jointly transforming KG evidence into more faithful answers.

</details>


### [17] [Yes-MT's Submission to the Low-Resource Indic Language Translation Shared Task in WMT 2024](https://arxiv.org/abs/2512.15226)
*Yash Bhaskar,Parameswari Krishnamurthy*

Main category: cs.CL

TL;DR: 本文介绍了Yes-MT团队在WMT 2024低资源印度语言翻译任务中的系统，重点翻译英语与亚萨姆语、米佐语、卡西语和马尼普尔语。


<details>
  <summary>Details</summary>
Motivation: 针对这些低资源语言翻译的挑战，探索多种模型和方法以提升翻译性能。

Method: 尝试了预训练模型如mT5和IndicBart的多语种与单语种微调，LoRA技术在IndicTrans2和Llama 3上的微调，零样本和少样本提示，及从零训练Transformer模型。

Result: 在WMT23测试数据上使用SacreBLEU和CHRF指标评估，展示了低资源翻译的挑战及大语言模型通过微调提升效果的潜力。

Conclusion: 大语言模型尤其是经过微调后，在低资源印度语言翻译任务中展现出良好应用前景。

Abstract: This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024 (Pakray et al., 2024), focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 (Xue et al., 2020) and IndicBart (Dabre et al., 2021) in both multilingual and monolingual settings, LoRA (Hu et al., 2021) fine-tuning IndicTrans2 (Gala et al., 2023), zero-shot and few-shot prompting (Brown, 2020) with large language models (LLMs) like Llama 3 (Dubey et al., 2024) and Mixtral 8x7b (Jiang et al., 2024), LoRA supervised fine-tuning of Llama 3 (Mecklenburg et al., 2024), and training Transformer models (Vaswani, 2017) from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task test data using SacreBLEU (Post, 2018) and CHRF (Popovic, 2015), highlighting the challenges of low-resource translation and the potential of LLMs for these tasks, particularly with fine-tuning.

</details>


### [18] [FAME: Fictional Actors for Multilingual Erasure](https://arxiv.org/abs/2512.15235)
*Claudio Savelli,Moreno La Quatra,Alkis Koudounas,Flavio Giobergia*

Main category: cs.CL

TL;DR: 介绍了FAME，一个用于多语言机器遗忘评估的合成基准，支持实体级和实例级遗忘，覆盖五种语言。


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘评估基准仅限英语且仅支持实体级遗忘，无法多语言和细粒度测试。

Method: 构建包含1000个虚构演员传记、20000 QA对的多语言数据集，支持实体级和实例级遗忘场景，并通过两种数据拆分进行评估。

Result: FAME覆盖英、法、德、意、西五种语言，包含丰富结构化信息，便于跨语言比较和不同遗忘层级测试。

Conclusion: FAME为多语言机器遗忘评估提供首个全面基准，利用虚构数据保证评估的可控性和公平性，促进遗忘技术发展。

Abstract: LLMs trained on web-scale data raise concerns about privacy and the right to be forgotten. To address these issues, Machine Unlearning provides techniques to remove specific information from trained models without retraining from scratch. However, existing benchmarks for evaluating unlearning in LLMs face two major limitations: they focus only on English and support only entity-level forgetting (removing all information about a person). We introduce FAME (Fictional Actors for Multilingual Erasure), a synthetic benchmark for evaluating Machine Unlearning across five languages: English, French, German, Italian, and Spanish. FAME contains 1,000 fictional actor biographies and 20,000 question-answer pairs. Each biography includes information on 20 topics organized into structured categories (biography, career, achievements, personal information). This design enables both entity-level unlearning (i.e., forgetting entire identities) and instance-level unlearning (i.e., forgetting specific facts while retaining others). We provide two dataset splits to support these two different unlearning scenarios and enable systematic comparison of unlearning techniques across languages. Since FAME uses entirely fictional data, it ensures that the information was never encountered during model pretraining, allowing for a controlled evaluation of unlearning methods.

</details>


### [19] [The Moralization Corpus: Frame-Based Annotation and Analysis of Moralizing Speech Acts across Diverse Text Genres](https://arxiv.org/abs/2512.15248)
*Maria Becker,Mirko Sommer,Lars Tapken,Yi Wan Teh,Bruno Brocai*

Main category: cs.CL

TL;DR: 本文介绍了一个新的多领域德国道德化语料库，研究道德价值在论证中的策略性使用，评价了大语言模型对道德化检测的表现。


<details>
  <summary>Details</summary>
Motivation: 道德化论证作为一种说服手段尚未被充分研究，且其隐含和复杂性对人工和自动分析构成挑战。

Method: 建立基于框架的注释体系，标注道德价值、诉求和论述主体等要素，涵盖政治辩论、新闻和网络讨论，评估不同大语言模型在道德化检测和成分提取任务中的表现。

Result: 详细的提示说明比少量示例或解释性提示效果更好，且道德化任务高度主观且依赖上下文。

Conclusion: 提供公开的语料、注释指南及代码，促进道德言论和推理领域的跨学科研究。

Abstract: Moralizations - arguments that invoke moral values to justify demands or positions - are a yet underexplored form of persuasive communication. We present the Moralization Corpus, a novel multi-genre dataset designed to analyze how moral values are strategically used in argumentative discourse. Moralizations are pragmatically complex and often implicit, posing significant challenges for both human annotators and NLP systems. We develop a frame-based annotation scheme that captures the constitutive elements of moralizations - moral values, demands, and discourse protagonists - and apply it to a diverse set of German texts, including political debates, news articles, and online discussions. The corpus enables fine-grained analysis of moralizing language across communicative formats and domains. We further evaluate several large language models (LLMs) under varied prompting conditions for the task of moralization detection and moralization component extraction and compare it to human annotations in order to investigate the challenges of automatic and manual analysis of moralizations. Results show that detailed prompt instructions has a greater effect than few-shot or explanation-based prompting, and that moralization remains a highly subjective and context-sensitive task. We release all data, annotation guidelines, and code to foster future interdisciplinary research on moral discourse and moral reasoning in NLP.

</details>


### [20] [SynGP500: A Clinically-Grounded Synthetic Dataset of Australian General Practice Medical Notes](https://arxiv.org/abs/2512.15259)
*Piyawoot Songsiritat*

Main category: cs.CL

TL;DR: SynGP500是一个包含500条澳大利亚全科医生临床笔记的合成数据集，真实反映临床复杂性，并经过多方面验证，支持临床自然语言处理方法的开发。


<details>
  <summary>Details</summary>
Motivation: 现有数据集受限于自然病例分布，缺乏少见但重要病例，且真实临床笔记复杂多样，传统合成数据集过于理想化，难以支持泛化模型训练。

Method: 基于澳大利亚全科医师课程和流行病学数据构建数据集，涵盖常见及罕见病例，保留临床文档的混乱与真实特征；通过流行病学对齐、文体分析、语义多样性分析及医学概念提取验证数据质量。

Result: 数据集在真实临床案例流行病学一致性、语言多样性、语义覆盖广泛等方面表现良好，自监督医学概念提取任务中F1得分提升，表明数据有效支持下游NLP应用。

Conclusion: SynGP500填补了澳大利亚临床自然语言处理领域的数据空白，既保障患者隐私，又为研究和教学提供高质量、多样化的临床文本资源。

Abstract: We introduce SynGP500, a clinician-curated collection of 500 synthetic Australian general practice medical notes. The dataset integrates curriculum-based clinical breadth (RACGP 2022 Curriculum), epidemiologically-calibrated prevalence (BEACH study), and diverse consultation contexts. This approach systematically includes both common presentations and less-common curriculum-specified conditions that GPs must recognize but appear infrequently in single practice populations, potentially supporting more generalizable model training than datasets constrained by naturally occurring case distributions. SynGP500 is messy by design, reflecting the authentic complexity of healthcare delivery: telegraphic documentation, typos, patient non-adherence, socioeconomic barriers, and clinician-patient disagreements, unlike sanitized synthetic datasets that obscure clinical realities. Multi-faceted validation demonstrates dataset quality through epidemiological alignment with real Australian GP consultation patterns (BEACH study), stylometric analysis confirming high linguistic variation, semantic diversity analysis demonstrating broad coverage, and exploratory downstream evaluation using self-supervised medical concept extraction, showing F1 improvements. SynGP500 addresses a critical national gap, providing researchers and educators with a resource for developing and evaluating clinical NLP methods for Australian general practice while inherently protecting patient privacy.

</details>


### [21] [Well Begun, Half Done: Reinforcement Learning with Prefix Optimization for LLM Reasoning](https://arxiv.org/abs/2512.15274)
*Yiliu Sun,Zicheng Zhao,Yang Wei,Yanfang Zhang,Chen Gong*

Main category: cs.CL

TL;DR: 本文提出了一种名为渐进前缀策略优化（PPPO）的强化学习方法，通过聚焦生成文本中的前缀部分优化大语言模型的推理能力，显著提升训练效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习方法对所有生成的token均匀训练，忽略了前缀token对推理的关键影响，导致资源浪费和训练效率低下。

Method: 借鉴路径依赖的人类思维理论，提出前缀锁定效应（BLE），PPPO方法通过渐进保留前缀token和累积奖励策略，有针对性地优化推理的起始阶段，从而提升后续推理效果。

Result: 在多种推理任务中，PPPO方法在仅使用26.17%训练token的情况下，准确率提升了18.02%，显著优于现有RLVR方法。

Conclusion: 聚焦于前缀token的渐进训练策略和累积奖励信号，能够有效提升大语言模型的推理能力和训练效率，为强化学习训练大语言模型提供了新的思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) significantly enhances the reasoning capability of Large Language Models (LLMs). Current RLVR approaches typically conduct training across all generated tokens, but neglect to explore which tokens (e.g., prefix tokens) actually contribute to reasoning. This uniform training strategy spends substantial effort on optimizing low-return tokens, which in turn impedes the potential improvement from high-return tokens and reduces overall training effectiveness. To address this issue, we propose a novel RLVR approach called Progressive Prefix-token Policy Optimization (PPPO), which highlights the significance of the prefix segment of generated outputs. Specifically, inspired by the well-established human thinking theory of Path Dependence, where early-stage thoughts substantially constrain subsequent thinking trajectory, we identify an analogous phenomenon in LLM reasoning termed Beginning Lock-in Effect (BLE). PPPO leverages this finding by focusing its optimization objective on the prefix reasoning process of LLMs. This targeted optimization strategy can positively influence subsequent reasoning processes, and ultimately improve final results. To improve the learning effectiveness of LLMs on how to start reasoning with high quality, PPPO introduces two training strategies: (a) Progressive Prefix Retention, which shapes a progressive learning process by increasing the proportion of retained prefix tokens during training; (b) Continuation Accumulated Reward, which mitigates reward bias by sampling multiple continuations for one prefix token sequence, and accumulating their scores as the reward signal. Extensive experimental results on various reasoning tasks demonstrate that our proposed PPPO outperforms representative RLVR methods, with the accuracy improvements of 18.02% on only 26.17% training tokens.

</details>


### [22] [Towards Proactive Personalization through Profile Customization for Individual Users in Dialogues](https://arxiv.org/abs/2512.15302)
*Xiaotian Zhang,Yuan Wang,Ruizhe Chen,Zeya Wang,Runchen Hou,Zuozhu Liu*

Main category: cs.CL

TL;DR: 提出了PersonalAgent，一个能持续推断和适应用户偏好的终身用户代理，实现了长远个性化和解决冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在交互系统中的对齐技术主要针对通用价值观或静态偏好，难以满足长期个性化和用户冷启动需求。

Method: PersonalAgent通过将对话拆分为单轮交互，将偏好推断视为序列决策任务，构建并动态更新统一的用户画像。

Result: 实验证明PersonalAgent在理想和噪声对话环境中表现优于强基线方法，且跨会话偏好保持一致，人工评估显示其能自然连贯地捕捉用户偏好。

Conclusion: 终身个性化对构建更包容和适应性强的对话代理至关重要，PersonalAgent有效推进了这一目标。

Abstract: The deployment of Large Language Models (LLMs) in interactive systems necessitates a deep alignment with the nuanced and dynamic preferences of individual users. Current alignment techniques predominantly address universal human values or static, single-turn preferences, thereby failing to address the critical needs of long-term personalization and the initial user cold-start problem. To bridge this gap, we propose PersonalAgent, a novel user-centric lifelong agent designed to continuously infer and adapt to user preferences. PersonalAgent constructs and dynamically refines a unified user profile by decomposing dialogues into single-turn interactions, framing preference inference as a sequential decision-making task. Experiments show that PersonalAgent achieves superior performance over strong prompt-based and policy optimization baselines, not only in idealized but also in noisy conversational contexts, while preserving cross-session preference consistency. Furthermore, human evaluation confirms that PersonalAgent excels at capturing user preferences naturally and coherently. Our findings underscore the importance of lifelong personalization for developing more inclusive and adaptive conversational agents. Our code is available here.

</details>


### [23] [Evaluating LLMs for Zeolite Synthesis Event Extraction (ZSEE): A Systematic Analysis of Prompting Strategies](https://arxiv.org/abs/2512.15312)
*Charan Prakash Rathore,Saumi Ray,Dhruv Kumar*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在沸石合成实验信息抽取中的效果，发现高层次理解表现良好，但精细参数提取能力有限。


<details>
  <summary>Details</summary>
Motivation: 沸石合成实验中结构化信息提取对材料发现至关重要，但现有方法未系统评估LLMs在该领域的应用效果。

Method: 针对事件类型分类、触发词识别、参数角色和参数值抽取四个关键任务，比较零样本、少样本、特定事件及反思式四种提示策略，在六种先进LLMs上使用含1530句标注的ZSEE数据集进行实验。

Result: 事件分类任务获得80-90% F1分数，细粒度参数提取任务表现中等（50-65% F1），GPT-5-mini提示敏感性极高，先进提示策略对精细任务提升有限。错误分析发现模型存在系统性幻觉、过度泛化和捕获合成细节的困难。

Conclusion: 虽然LLMs具有较强的高层理解能力，但对合成实验参数的精确提取仍需领域适应模型，本文为科学信息抽取提供了量化基准。

Abstract: Extracting structured information from zeolite synthesis experimental procedures is critical for materials discovery, yet existing methods have not systematically evaluated Large Language Models (LLMs) for this domain-specific task. This work addresses a fundamental question: what is the efficacy of different prompting strategies when applying LLMs to scientific information extraction? We focus on four key subtasks: event type classification (identifying synthesis steps), trigger text identification (locating event mentions), argument role extraction (recognizing parameter types), and argument text extraction (extracting parameter values). We evaluate four prompting strategies - zero-shot, few-shot, event-specific, and reflection-based - across six state-of-the-art LLMs (Gemma-3-12b-it, GPT-5-mini, O4-mini, Claude-Haiku-3.5, DeepSeek reasoning and non-reasoning) using the ZSEE dataset of 1,530 annotated sentences. Results demonstrate strong performance on event type classification (80-90\% F1) but modest performance on fine-grained extraction tasks, particularly argument role and argument text extraction (50-65\% F1). GPT-5-mini exhibits extreme prompt sensitivity with 11-79\% F1 variation. Notably, advanced prompting strategies provide minimal improvements over zero-shot approaches, revealing fundamental architectural limitations. Error analysis identifies systematic hallucination, over-generalization, and inability to capture synthesis-specific nuances. Our findings demonstrate that while LLMs achieve high-level understanding, precise extraction of experimental parameters requires domain-adapted models, providing quantitative benchmarks for scientific information extraction.

</details>


### [24] [Why Your Academic Field Is Everywhere at Once: A Case Study of Arabic Linguistics](https://arxiv.org/abs/2512.15328)
*Ayman Eddakrouri,Amani Ramadan*

Main category: cs.CL

TL;DR: 本文采用Brookes的类别离散度测度(Δ)分析了2019-2025年1564篇阿拉伯语应用语言学论文的主题结构，发现极低的Δ值显示该领域主题高度分散且异质性显著。


<details>
  <summary>Details</summary>
Motivation: 旨在通过Brookes的类别离散度测度揭示当代阿拉伯语应用语言学的主题结构特点，明确其学科内部的异质性和主要研究方向。

Method: 基于2019-2025年1564篇论文数据，按照八个核心子学科分类，计算类别离散度指数Δ，分析各子领域主题分布和主导力量。

Result: 计算得到Δ=0.194，表明主题分散度极高，且计算语言学为主导但非唯一领域，社会语言学、语言教学等领域也具有较强研究活力。

Conclusion: 正确运用Brookes公式可有效表征学科结构，提供了一个可复制的书目计量方法，有助于跨领域的学科结构评估。

Abstract: This study applies Brookes' Measure of Categorical Dispersion (Δ) to analyze the thematic structure of contemporary Arabic Applied Linguistics research. Using a comprehensive, real-world dataset of 1,564 publications from 2019 to 2025, classified into eight core sub-disciplines, we calculate a dispersion index of Δ = 0.194. This remarkably low value indicates extreme thematic dispersion, revealing that the field is characterized by pronounced heterogeneity rather than concentration. The analysis identifies Computational Linguistics as a dominant but non-hegemonic force, coexisting with robust research in Sociolinguistics, Language Teaching, and other subfields. This study clarifies the correct application of Brookes' original formula, demonstrates its utility for field characterization, and provides a replicable bibliometric methodology for assessing disciplinary structure across domains.

</details>


### [25] [Adversarial versification in portuguese as a jailbreak operator in LLMs](https://arxiv.org/abs/2512.15353)
*Joao Queiroz*

Main category: cs.CL

TL;DR: 研究发现将攻击性提示转化为诗歌形式能显著绕过大型语言模型的安全限制，导致安全失败率大幅提升。


<details>
  <summary>Details</summary>
Motivation: 现有对齐的大型语言模型安全机制在面对诗歌形式的提示时表现出脆弱，且葡萄牙语相关的评估严重缺失。

Method: 通过将拒绝执行的指令转化为诗歌形式，测试不同模型在执行这些指令时的成功率，并强调在葡萄牙语环境下需考虑韵律和声调变化实验设计。

Result: 手动诗歌提示的攻击成功率约为62%，自动生成的约为43%，部分模型在单轮互动中成功率甚至超过90%，表明训练方法对韵律形式变化较为敏感。

Conclusion: 提示的诗歌化暴露了当前对齐机制对表层模式过度依赖的缺陷，提示安全性存在根本性不足，强调需要针对多语言尤其是葡萄牙语的韵律复杂性设计更加严谨的安全评估。

Abstract: Recent evidence shows that the versification of prompts constitutes a highly effective adversarial mechanism against aligned LLMs. The study 'Adversarial poetry as a universal single-turn jailbreak mechanism in large language models' demonstrates that instructions routinely refused in prose become executable when rewritten as verse, producing up to 18 x more safety failures in benchmarks derived from MLCommons AILuminate. Manually written poems reach approximately 62% ASR, and automated versions 43%, with some models surpassing 90% success in single-turn interactions. The effect is structural: systems trained with RLHF, constitutional AI, and hybrid pipelines exhibit consistent degradation under minimal semiotic formal variation. Versification displaces the prompt into sparsely supervised latent regions, revealing guardrails that are excessively dependent on surface patterns. This dissociation between apparent robustness and real vulnerability exposes deep limitations in current alignment regimes. The absence of evaluations in Portuguese, a language with high morphosyntactic complexity, a rich metric-prosodic tradition, and over 250 million speakers, constitutes a critical gap. Experimental protocols must parameterise scansion, metre, and prosodic variation to test vulnerabilities specific to Lusophone patterns, which are currently ignored.

</details>


### [26] [Dual-Density Inference for Efficient Language Model Reasoning](https://arxiv.org/abs/2512.15358)
*Zhengyi Zhao,Shubo Zhang,Yuxi Zhang,Huimin Wang,Binyang Li,Kam-Fai Wong*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Denser的双密度推理框架，通过区分推理阶段和回答阶段的信息密度，显著提升推理效率，同时保持答案的可读性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对推理中间过程和最终答案都采用统一的语言密度，导致计算资源浪费。推理过程主要是模型的计算功能，而回答则是为了人类理解的交流功能，两者对信息密度的需求不同。

Method: Denser框架包含三个部分：输入问题的查询处理模块，高密度压缩的推理机制，以及将压缩推理结果翻译成人类可读答案的生成组件，从而分别优化推理和回答的信息密度。

Result: 在多个推理问答基准测试中，Denser在保持或提升准确率的同时，相较于传统的思维链方法，最多减少了62%的Token消耗。该提升在复杂多步推理任务中尤为显著。

Conclusion: 通过区分推理与回答的功能和优化信息密度，Denser实现了更高效的推理过程，为处理复杂推理问题提供了有效的解决方案。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in complex reasoning tasks. However, current approaches employ uniform language density for both intermediate reasoning and final answers, leading to computational inefficiency. Our observation found that reasoning process serves a computational function for the model itself, while answering serves a communicative function for human understanding. This distinction enables the use of compressed, symbol-rich language for intermediate computations while maintaining human-readable final explanations. To address this inefficiency, we present Denser: \underline{D}ual-d\underline{ens}ity inf\underline{er}ence, a novel framework that optimizes information density separately for reasoning and answering phases. Our framework implements this through three components: a query processing module that analyzes input problems, a high-density compressed reasoning mechanism for efficient intermediate computations, and an answer generation component that translates compressed reasoning into human-readable solutions. Experimental evaluation across multiple reasoning question answering benchmarks demonstrates that Denser reduces token consumption by up to 62\% compared to standard Chain-of-Thought methods while preserving or improving accuracy. These efficiency gains are particularly significant for complex multi-step reasoning problems where traditional methods generate extensive explanations.

</details>


### [27] [ORACLE: Time-Dependent Recursive Summary Graphs for Foresight on News Data Using LLMs](https://arxiv.org/abs/2512.15397)
*Lev Kharlashkin,Eiaki Morooka,Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: ORACLE平台将每日新闻转化为周度的决策洞察，通过多层聚类和时间递归总结生成报告，辅助芬兰应用科学大学进行课程智能分析。


<details>
  <summary>Details</summary>
Motivation: 需要一个稳定的系统，将大量每日新闻转化为针对大学需求的具体、结构化、决策可用的信息。

Method: 系统爬取新闻，进行版本管理和大学特定的相关性过滤，将内容嵌入向量空间，分类到PESTEL维度，构建时间依赖的递归总结图，并利用轻量级变化检测器识别新闻变更，结合大语言模型进行两层聚类和总结。

Result: 系统稳定运行，能够每周自动生成汇总报告，并识别具体变更主题，辅助大学进行基于新闻的课程智能分析。

Conclusion: 本文提出的ORACLE平台有效实现了新闻内容的结构化分析和动态总结，支持课程智能和相关决策，具有较高的实际应用价值。

Abstract: ORACLE turns daily news into week-over-week, decision-ready insights for one of the Finnish University of Applied Sciences. The platform crawls and versions news, applies University-specific relevance filtering, embeds content, classifies items into PESTEL dimensions and builds a concise Time-Dependent Recursive Summary Graph (TRSG): two clustering layers summarized by an LLM and recomputed weekly. A lightweight change detector highlights what is new, removed or changed, then groups differences into themes for PESTEL-aware analysis. We detail the pipeline, discuss concrete design choices that make the system stable in production and present a curriculum-intelligence use case with an evaluation plan.

</details>


### [28] [Toward expert-level motivational interviewing for health behavior improvement with LLMs](https://arxiv.org/abs/2512.15446)
*Run-ze Hu,Yang Yang,Yi-hang Yang,Jing-qi Kong,Jia-hui Luo,Wen-yu Yang,Jing Chen,Jing-yao Liu,Hui-qun Zeng,Lei Zhang,Zheng Liu*

Main category: cs.CL

TL;DR: 本文开发并评估了针对动机性访谈(MI)的中文大型语言模型(MI-LLMs)，通过微调三款开源模型，使其产生接近真实咨询的对话内容，为人工智能辅助健康行为改变提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 动机性访谈虽然有效，但依赖高素质人类咨询师，难以大规模推广，故探索大规模语言模型作为可扩展替代方案。

Method: 收集五个中文心理咨询语料库，利用GPT-4转录生成2040条MI风格会话，使用其中2000条训练三款开源LLM并微调，评估模型表现及与真实MI对话的相似度。

Result: 微调显著提升BLEU-4和ROUGE分数，专家手动编码显示MI-LLMs在技术和关系评分及MI遵循率上接近真实MI会话，但复杂反思和反思与提问比率较低。

Conclusion: MI导向的微调可赋能通用LLM实现核心MI咨询行为，展示了AI辅助健康行为改变的潜力，未来需加强数据规模、复杂MI技能及实地干预试验。

Abstract: Background: Motivational interviewing (MI) is an effective counseling approach for promoting health behavior change, but its impact is constrained by the need for highly trained human counselors. Objective: This study aimed to explore a scalable alternative by developing and evaluating Large Language Models for Motivational Interviewing (MI-LLMs). Methods: We first curated five Chinese psychological counseling corpora and, using GPT-4 with an MI-informed prompt, transcribed multi-turn dialogues from the two highest-quality datasets (CPsyCounD and PsyDTCorpus) into 2,040 MI-style counseling conversations, of which 2,000 were used for training and 40 for testing. Three Chinese-capable open-source LLMs (Baichuan2-7B-Chat, ChatGLM-4-9B-Chat and Llama-3-8B-Chinese-Chat-v2) were fine-tuned on this corpus and were named as MI-LLMs. We evaluated MI-LLMs using round-based automatic metrics and expert manual coding with the Motivational Interviewing Treatment Integrity (MITI) Coding Manual 4.2.1. Results: Across all three models, fine-tuning substantially improved BLEU-4 and ROUGE scores compared with the base models, and manual coding showed that MI-LLMs achieved technical and relational global scores, and MI-adherent ratios that approached those of real MI dialogues, although complex reflections and reflection-to-question ratios remained less frequent. Conclusions: These findings provide initial evidence that MI-oriented fine-tuning can endow general-purpose LLMs with core MI-consistent counseling behaviors, suggesting a scalable pathway toward AI-assisted health behavior change support while underscoring the need for further work on data scale, complex MI skills and real-world intervention trials.

</details>


### [29] [When a Nation Speaks: Machine Learning and NLP in People's Sentiment Analysis During Bangladesh's 2024 Mass Uprising](https://arxiv.org/abs/2512.15547)
*Md. Samiul Alim,Mahir Shahriar Tamim,Maisha Rahman,Tanvir Ahmed Khan,Md Mushfique Anwar*

Main category: cs.CL

TL;DR: 本文首次在孟加拉语环境下，利用2,028条新闻标题数据，分析2024年孟加拉大规模起义期间的公众情绪，采用LDA主题建模和情感分类，模型表现优于多语言和传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前情感分析多聚焦于选举和社交媒体，缺乏对内乱期间、尤其是孟加拉语环境下情绪动态的研究。

Method: 收集带注释的新闻标题数据，采用LDA挖掘主题，使用语言专属模型进行情感分类（Outrage, Hope, Despair），并与多语言transformers及传统机器学习方法对比。

Result: 提出的语言专属模型准确率优于mBERT（67%）、XLM-RoBERTa（71%）及传统SVM和逻辑回归（均70%），表明其在政治动荡情境下的强大表现。

Conclusion: 语言专属情感分析模型在孟加拉语政治危机中有效揭示公众情绪动态，为理解和监测社会情绪提供了重要工具。

Abstract: Sentiment analysis, an emerging research area within natural language processing (NLP), has primarily been explored in contexts like elections and social media trends, but there remains a significant gap in understanding emotional dynamics during civil unrest, particularly in the Bangla language. Our study pioneers sentiment analysis in Bangla during a national crisis by examining public emotions amid Bangladesh's 2024 mass uprising. We curated a unique dataset of 2,028 annotated news headlines from major Facebook news portals, classifying them into Outrage, Hope, and Despair. Through Latent Dirichlet Allocation (LDA), we identified prevalent themes like political corruption and public protests, and analyzed how events such as internet blackouts shaped sentiment patterns. It outperformed multilingual transformers (mBERT: 67%, XLM-RoBERTa: 71%) and traditional machine learning methods (SVM and Logistic Regression: both 70%). These results highlight the effectiveness of language-specific models and offer valuable insights into public sentiment during political turmoil.

</details>


### [30] [CTkvr: KV Cache Retrieval for Long-Context LLMs via Centroid then Token Indexing](https://arxiv.org/abs/2512.15550)
*Kuan Lu,Shuhang Lin,Sai Wu,Yichen Yao,Junhan Yang,Huan Li,Wei Chu,Xu Yinghui,Yuan Qi,Gang Chen*

Main category: cs.CL

TL;DR: 本文提出CTKVR方案，提升大语言模型在长上下文中的KV检索效率，实现准确率微降且显著提速。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文下KV缓存检索方法面临效率和准确率的权衡问题，亟需提高推理效率并保持模型性能。

Method: CTKVR基于RoPE编码的相邻查询向量高相似特性，设计两阶段检索策略：先用预计算质心进行粗粒度索引，再用token级细化检索。并通过CPU-GPU协同优化提升系统性能。

Result: 在多个基准测试中，CTKVR精度下降不足1%，在Llama-3-8B和Yi-9B模型上实现了3至4倍的吞吐量加速，支持96K长上下文。

Conclusion: CTKVR有效平衡了长上下文推理的检索效率和准确率，展现了其在大规模语言模型长上下文推理中的应用潜力。

Abstract: Large language models (LLMs) are increasingly applied in long-context scenarios such as multi-turn conversations. However, long contexts pose significant challenges for inference efficiency, including high memory overhead from Key-Value (KV) cache and increased latency due to excessive memory accesses. Recent methods for dynamic KV selection struggle with trade-offs: block-level indexing degrades accuracy by retrieving irrelevant KV entries, while token-level indexing incurs high latency from inefficient retrieval mechanisms. In this paper, we propose CTKVR, a novel centroid-then-token KV retrieval scheme that addresses these limitations. CTKVR leverages a key observation: query vectors adjacent in position exhibit high similarity after Rotary Position Embedding (RoPE) and share most of their top-k KV cache entries. Based on this insight, CTKVR employs a two-stage retrieval strategy: lightweight centroids are precomputed during prefilling for centroid-grained indexing, followed by token-level refinement for precise KV retrieval. This approach balances retrieval efficiency and accuracy. To further enhance performance, we implement an optimized system for indexing construction and search using CPU-GPU co-execution. Experimentally, CTKVR achieves superior performance across multiple benchmarks with less than 1% accuracy degradation. Meanwhile, CTKVR delivers 3 times and 4 times throughput speedups on Llama-3-8B and Yi-9B at 96K context length across diverse GPU hardware.

</details>


### [31] [Learning inflection classes using Adaptive Resonance Theory](https://arxiv.org/abs/2512.15551)
*Peter Dekker,Heikki Rasilo,Bart de Boer*

Main category: cs.CL

TL;DR: 本文研究了语言使用者通过无监督聚类学习动词词形变化类的能力，采用自适应共振理论神经网络模型，应用于拉丁语、葡萄牙语和爱沙尼亚语。


<details>
  <summary>Details</summary>
Motivation: 词形变化类是语言学中用以描述语言模式并推断未见词形的重要抽象概念，该能力对形态学习与处理至关重要。

Method: 利用自适应共振理论（ART）神经网络进行词汇词根的无监督聚类，参数调节泛化程度以适配不同语言的词形变化复杂度。

Result: 模型在不同语言的词形变化系统中表现不同，最佳性能出现在泛化参数的狭窄区域。所学特征与语言学对词形变化类的描述相似。

Conclusion: 提出的模型在认知上可行且具有解释性，未来可用于模拟词形变化类的演变，结合基于主体的模型进行研究。

Abstract: The concept of inflection classes is an abstraction used by linguists, and provides a means to describe patterns in languages that give an analogical base for deducing previously unencountered forms. This ability is an important part of morphological acquisition and processing. We study the learnability of a system of verbal inflection classes by the individual language user by performing unsupervised clustering of lexemes into inflection classes. As a cognitively plausible and interpretable computational model, we use Adaptive Resonance Theory, a neural network with a parameter that determines the degree of generalisation (vigilance). The model is applied to Latin, Portuguese and Estonian. The similarity of clustering to attested inflection classes varies depending on the complexity of the inflectional system. We find the best performance in a narrow region of the generalisation parameter. The learned features extracted from the model show similarity with linguistic descriptions of the inflection classes. The proposed model could be used to study change in inflection classes in the future, by including it in an agent-based model.

</details>


### [32] [From Data to Dialogue: Unlocking Language for All](https://arxiv.org/abs/2512.15552)
*Dakota Ellis,Samy Bakikerali,Wanshan Chen,Bao Dinh,Uyen Le*

Main category: cs.CL

TL;DR: 本文提出通过自动化方法创建专用词表（SWL），优化语言学习词汇选择，比传统的通用服务列表（GSL）覆盖率更高且词数更少。


<details>
  <summary>Details</summary>
Motivation: 传统GSL的制作依赖语言学专家、主观判断及大量时间，效率低且难以普及。

Method: 通过模型自动生成专用词表（SWL），基于客观标准筛选词汇，针对语料库子集优化词汇选择。

Result: 所创建的SWL相比行业标准NGSL，在词汇数量更少的情况下达到95%的语言理解覆盖率，表现优异。

Conclusion: SWL的自动化和客观制作方法可实现规模化生产，满足全球语言学习者的个性化需求，提高学习效率。

Abstract: Traditional linguists have proposed the use of a General Service List (GSL) to assist new language learners in identifying the most important words in English. This process requires linguistic expertise, subjective input, and a considerable amount of time. We attempt to create our own GSL and evaluate its practicality against the industry standard (The NGSL). We found creating a Specialized Word List (SWL), or a word list specific to a subset of the overall corpus, to be the most practical way for language-learners to optimize the process. The SWL's that we created using our model outperformed the industry standard, reaching the 95% coverage required for language comprehension with fewer words comparatively. By restricting the SWL process to objective criteria only, it can be automated, scaled, and tailored to the needs of language-learners across the globe.

</details>


### [33] [An Empirical Study on Chinese Character Decomposition in Multiword Expression-Aware Neural Machine Translation](https://arxiv.org/abs/2512.15556)
*Lifeng Han,Gareth J. F. Jones,Alan F. Smeaton*

Main category: cs.CL

TL;DR: 本文系统研究了中文字符分解技术在多词表达（MWEs）感知的神经机器翻译中的作用，探讨其如何有效改善中文MWEs的翻译问题。


<details>
  <summary>Details</summary>
Motivation: 多词表达（MWEs）在自然语言理解和生成中引入歧义和变异，尤其中文等表意文字的处理相对西方语言困难，子词建模技术难以直接应用于中文，导致中文MWEs的翻译仍存在挑战。

Method: 本文针对中文，采用字符分解技术，对汉字进行拆解，以增强神经机器翻译对MWEs的表示和理解能力，系统评估该方法对保留词义和改善翻译效果的贡献。

Result: 实验结果表明中文字符分解技术有助于更准确地表示汉字及词义，提高机器翻译对中文MWEs的处理能力。

Conclusion: 中文字符分解技术在多词表达感知的神经机器翻译中表现出较强效果，是解决中文MWEs翻译问题的有效途径。

Abstract: Word meaning, representation, and interpretation play fundamental roles in natural language understanding (NLU), natural language processing (NLP), and natural language generation (NLG) tasks. Many of the inherent difficulties in these tasks stem from Multi-word Expressions (MWEs), which complicate the tasks by introducing ambiguity, idiomatic expressions, infrequent usage, and a wide range of variations. Significant effort and substantial progress have been made in addressing the challenging nature of MWEs in Western languages, particularly English. This progress is attributed in part to the well-established research communities and the abundant availability of computational resources. However, the same level of progress is not true for language families such as Chinese and closely related Asian languages, which continue to lag behind in this regard. While sub-word modelling has been successfully applied to many Western languages to address rare words improving phrase comprehension, and enhancing machine translation (MT) through techniques like byte-pair encoding (BPE), it cannot be applied directly to ideograph language scripts like Chinese. In this work, we conduct a systematic study of the Chinese character decomposition technology in the context of MWE-aware neural machine translation (NMT). Furthermore, we report experiments to examine how Chinese character decomposition technology contributes to the representation of the original meanings of Chinese words and characters, and how it can effectively address the challenges of translating MWEs.

</details>


### [34] [Bolmo: Byteifying the Next Generation of Language Models](https://arxiv.org/abs/2512.15586)
*Benjamin Minixhofer,Tyler Murray,Tomasz Limisiewicz,Anna Korhonen,Luke Zettlemoyer,Noah A. Smith,Edoardo M. Ponti,Luca Soldaini,Valentin Hofmann*

Main category: cs.CL

TL;DR: 本文介绍了Bolmo，一种通过将现有子词级语言模型字节化而成的竞争性全开放字节级语言模型。


<details>
  <summary>Details</summary>
Motivation: 克服子词分词的限制，如字符理解不足和固定词汇表带来的效率制约，同时保持领先子词级模型的表现。

Method: 设计适合字节化的架构，实现Bolmo与子词模型之间的精确蒸馏，以极低的预训练代价将子词模型转换为字节模型。

Result: Bolmo在同等规模的字节模型中表现最佳，提升了字符理解和部分编码任务的性能，并在推理速度和后续训练上具备竞争力。

Conclusion: Bolmo使得字节级语言模型成为实用且性能竞争力强的选择，能够广泛应用于多种任务，具有优于传统子词模型的潜力。

Abstract: We introduce Bolmo, the first family of competitive fully open byte-level language models (LMs) at the 1B and 7B parameter scales. In contrast to prior research on byte-level LMs, which focuses predominantly on training from scratch, we train Bolmo by byteifying existing subword-level LMs. Byteification enables overcoming the limitations of subword tokenization - such as insufficient character understanding and efficiency constraints due to the fixed subword vocabulary - while performing at the level of leading subword-level LMs. Bolmo is specifically designed for byteification: our architecture resolves a mismatch between the expressivity of prior byte-level architectures and subword-level LMs, which makes it possible to employ an effective exact distillation objective between Bolmo and the source subword model. This allows for converting a subword-level LM to a byte-level LM by investing less than 1\% of a typical pretraining token budget. Bolmo substantially outperforms all prior byte-level LMs of comparable size, and outperforms the source subword-level LMs on character understanding and, in some cases, coding, while coming close to matching the original LMs' performance on other tasks. Furthermore, we show that Bolmo can achieve inference speeds competitive with subword-level LMs by training with higher token compression ratios, and can be cheaply and effectively post-trained by leveraging the existing ecosystem around the source subword-level LM. Our results finally make byte-level LMs a practical choice competitive with subword-level LMs across a wide set of use cases.

</details>


### [35] [You Never Know a Person, You Only Know Their Defenses: Detecting Levels of Psychological Defense Mechanisms in Supportive Conversations](https://arxiv.org/abs/2512.15601)
*Hongbin Na,Zimu Wang,Zhaoming Chen,Peilin Zhou,Yining Hua,Grace Ziqi Zhou,Haiyang Zhang,Tao Shen,Wei Wang,John Torous,Shaoxiong Ji,Ling Chen*

Main category: cs.CL

TL;DR: 本文提出了一个关于心理防御机制的对话语料库PsyDefConv及辅助标注系统DMRS Co-Pilot，旨在提高临床对话中防御机制的自动识别和标注效率。


<details>
  <summary>Details</summary>
Motivation: 心理防御机制复杂且难以在临床对话中可靠测量，且其过度使用与心理健康负相关，影响求助者的交流和接受帮助的方式，因此需要构建相关标注资源和辅助工具。

Method: 构建包含200个对话和4709个话语的语料库，标注求助者的防御级别；设计四阶段的DMRS Co-Pilot辅助标注管线，提高标注效率并进行专家评审验证；使用强语言模型进行零样本和微调实验作为基线。

Result: 语料库标注一致性较好（Cohen's kappa 0.639），DMRS Co-Pilot降低标注时间22.4%，专家评审评分较高。语言模型基线F1分数最高约30%，存在对成熟防御的过预测倾向。分析显示成熟防御最为普遍，并存在情绪特异性偏差。

Conclusion: 所构建的资源和辅助系统有助于推进语言中防御功能的研究，相关语料和工具将被公开发布以支持后续研究。

Abstract: Psychological defenses are strategies, often automatic, that people use to manage distress. Rigid or overuse of defenses is negatively linked to mental health and shapes what speakers disclose and how they accept or resist help. However, defenses are complex and difficult to reliably measure, particularly in clinical dialogues. We introduce PsyDefConv, a dialogue corpus with help seeker utterances labeled for defense level, and DMRS Co-Pilot, a four-stage pipeline that provides evidence-based pre-annotations. The corpus contains 200 dialogues and 4709 utterances, including 2336 help seeker turns, with labeling and Cohen's kappa 0.639. In a counterbalanced study, the co-pilot reduced average annotation time by 22.4%. In expert review, it averaged 4.62 for evidence, 4.44 for clinical plausibility, and 4.40 for insight on a seven-point scale. Benchmarks with strong language models in zero-shot and fine-tuning settings demonstrate clear headroom, with the best macro F1-score around 30% and a tendency to overpredict mature defenses. Corpus analyses confirm that mature defenses are most common and reveal emotion-specific deviations. We will release the corpus, annotations, code, and prompts to support research on defensive functioning in language.

</details>


### [36] [Evaluating Metrics for Safety with LLM-as-Judges](https://arxiv.org/abs/2512.15617)
*Kester Clegg,Richard Hawkins,Ibrahim Habli,Tom Lawton*

Main category: cs.CL

TL;DR: 本文讨论了如何确保大型语言模型（LLMs）在关键任务中的安全与可靠，提出采用基于加权指标和上下文敏感性评价的LLM-as-Judges框架，结合置信度阈值引入人工审查以降低错误风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在文本处理中的广泛应用，有可能替代人类在信息流中的瓶颈角色，但由于LLMs存在错误风险，特别是在安全关键领域，需要确保其安全可靠。

Method: 本文强调安全性应基于评估过程中获得的证据，采用多个加权指标的组合，利用上下文敏感度界定错误严重性，设计置信度阈值以决定何时引入人为审查，特别是在LLM-as-Judges评估框架中。

Result: 通过采用加权指标和上下文敏感机制，能够降低评估错误的风险，并通过置信度阈值机制及时发现并交由人工审查，提高系统整体的安全性与可靠性。

Conclusion: 采用多指标加权评价结合置信度触发的人类复核机制是提升LLMs在安全关键任务中可靠性的有效途径，支持其在此前由人类执行的重要信息流程中的应用。

Abstract: LLMs (Large Language Models) are increasingly used in text processing pipelines to intelligently respond to a variety of inputs and generation tasks. This raises the possibility of replacing human roles that bottleneck existing information flows, either due to insufficient staff or process complexity. However, LLMs make mistakes and some processing roles are safety critical. For example, triaging post-operative care to patients based on hospital referral letters, or updating site access schedules in nuclear facilities for work crews. If we want to introduce LLMs into critical information flows that were previously performed by humans, how can we make them safe and reliable? Rather than make performative claims about augmented generation frameworks or graph-based techniques, this paper argues that the safety argument should focus on the type of evidence we get from evaluation points in LLM processes, particularly in frameworks that employ LLM-as-Judges (LaJ) evaluators. This paper argues that although we cannot get deterministic evaluations from many natural language processing tasks, by adopting a basket of weighted metrics it may be possible to lower the risk of errors within an evaluation, use context sensitivity to define error severity and design confidence thresholds that trigger human review of critical LaJ judgments when concordance across evaluators is low.

</details>


### [37] [How Much is Too Much? Exploring LoRA Rank Trade-offs for Retaining Knowledge and Domain Robustness](https://arxiv.org/abs/2512.15634)
*Darshita Rathore,Vineet Kumar,Chetna Bansal,Anindya Moitra*

Main category: cs.CL

TL;DR: 本文比较了全监督微调(SFT)和参数高效微调(PEFT)，特别是LoRA方法在推理和回忆任务中的表现，发现LoRA在特定配置下能达到甚至超越SFT效果，同时分析了模型内部表征变化。


<details>
  <summary>Details</summary>
Motivation: 当前PEFT方法如LoRA因计算效率受到广泛使用，但它们的配置对下游问答任务的影响及模型泛化能力尚未充分研究。

Method: 本文通过对多个推理及回忆数据集进行rank参数扫描，全面评估SFT与PEFT间的权衡，并比较它们在内外域适应中的表现差异，同时分析模型内部的频谱特征和层次注意力结构。

Result: 研究显示LoRA在某些rank值下，在推理任务表现出与SFT相当甚至更优的性能，且两者在泛化行为及任务遗忘方面存在显著差异。

Conclusion: LoRA不仅有效提升微调效率，还在特定任务上表现优异，内部表征及注意力结构的变化为理解微调机制提供了新视角。

Abstract: Large language models are increasingly adapted to downstream tasks through fine-tuning. Full supervised fine-tuning (SFT) and parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), are two dominant approaches. While PEFT methods are widely used for their computational efficiency, the implications of their configurations (e.g., rank) remain under-explored in downstream Q&A tasks and generalisation. In this work, we perform a comprehensive evaluation across multiple reasoning and recall datasets, conducting a rank sweep to quantify the trade-off between SFT and PEFT. We also compare the accuracy of PEFT and SFT models across in-domain and out-of-domain adaptation, highlighting distinct generalisation behaviour and task-specific forgetting. We demonstrate that LoRA achieves competitive and in some cases superior performance compared to SFT, particularly on reasoning tasks at specific rank values. Additionally, we analyze the internal representations via spectral features and layer-wise attention structures, offering insights into representational drift and structural changes in attention patterns.

</details>


### [38] [Characterizing Mamba's Selective Memory using Auto-Encoders](https://arxiv.org/abs/2512.15653)
*Tamanna Hossain,Robert L. Logan,Ganesh Jagadeesan,Sameer Singh,Joel Tetreault,Alejandro Jaimes*

Main category: cs.CL

TL;DR: 本论文研究了状态空间模型（SSM）语言模型在处理长序列时遗忘的信息类型，发现数学相关词汇、组织实体和非标准美式英语更容易丢失。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究探讨了SSM语言模型在序列长度增加时的信息丧失，但未明确其遗忘的具体信息类型，本文旨在填补这一空白。

Method: 通过训练一个自动编码器从SSM的隐藏状态重构序列，并比较输入与重构序列来衡量信息丧失，实验使用Mamba模型家族（130M-1.4B参数）在4-256令牌长度范围内进行。

Result: 发现数学相关词汇（数字、变量）、组织实体提及和非标准美式英语的遗忘率显著较高；分析预训练数据中这些词汇的出现频率，较少出现的词汇更易被遗忘。

Conclusion: 这项研究明确了SSM语言模型的信息遗忘模式，指出了未来改进模型记忆能力的方向，即增强对重要和不常见词汇的保留能力。

Abstract: State space models (SSMs) are a promising alternative to transformers for language modeling because they use fixed memory during inference. However, this fixed memory usage requires some information loss in the hidden state when processing long sequences. While prior work has studied the sequence length at which this information loss occurs, it does not characterize the types of information SSM language models (LMs) tend to forget. In this paper, we address this knowledge gap by identifying the types of tokens (e.g., parts of speech, named entities) and sequences (e.g., code, math problems) that are more frequently forgotten by SSM LMs. We achieve this by training an auto-encoder to reconstruct sequences from the SSM's hidden state, and measure information loss by comparing inputs with their reconstructions. We perform experiments using the Mamba family of SSM LMs (130M--1.4B) on sequences ranging from 4--256 tokens. Our results show significantly higher rates of information loss on math-related tokens (e.g., numbers, variables), mentions of organization entities, and alternative dialects to Standard American English. We then examine the frequency that these tokens appear in Mamba's pretraining data and find that less prevalent tokens tend to be the ones Mamba is most likely to forget. By identifying these patterns, our work provides clear direction for future research to develop methods that better control Mamba's ability to retain important information.

</details>


### [39] [PPSEBM: An Energy-Based Model with Progressive Parameter Selection for Continual Learning](https://arxiv.org/abs/2512.15658)
*Xiaodi Li,Dingcheng Li,Rujun Gao,Mahmoud Zamani,Feng Mi,Latifur Khan*

Main category: cs.CL

TL;DR: 本文提出了PPSEBM框架，通过结合能量模型和渐进参数选择，有效缓解自然语言处理中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 持续学习中灾难性遗忘问题严重，影响模型在新任务学习时对旧知识的保持。

Method: PPSEBM框架结合能量模型（EBM）生成伪样本，并通过渐进参数选择为新任务分配独特参数，利用伪样本指导参数选择过程。

Result: 在多种自然语言处理基准测试中，PPSEBM优于现有最先进的持续学习方法。

Conclusion: PPSEBM为持续学习中的灾难性遗忘提供了一种有效且鲁棒的解决方案。

Abstract: Continual learning remains a fundamental challenge in machine learning, requiring models to learn from a stream of tasks without forgetting previously acquired knowledge. A major obstacle in this setting is catastrophic forgetting, where performance on earlier tasks degrades as new tasks are learned. In this paper, we introduce PPSEBM, a novel framework that integrates an Energy-Based Model (EBM) with Progressive Parameter Selection (PPS) to effectively address catastrophic forgetting in continual learning for natural language processing tasks. In PPSEBM, progressive parameter selection allocates distinct, task-specific parameters for each new task, while the EBM generates representative pseudo-samples from prior tasks. These generated samples actively inform and guide the parameter selection process, enhancing the model's ability to retain past knowledge while adapting to new tasks. Experimental results on diverse NLP benchmarks demonstrate that PPSEBM outperforms state-of-the-art continual learning methods, offering a promising and robust solution to mitigate catastrophic forgetting.

</details>


### [40] [Activation Oracles: Training and Evaluating LLMs as General-Purpose Activation Explainers](https://arxiv.org/abs/2512.15674)
*Adam Karvonen,James Chua,Clément Dumas,Kit Fraser-Taliente,Subhash Kantamneni,Julian Minder,Euan Ong,Arnab Sen Sharma,Daniel Wen,Owain Evans,Samuel Marks*

Main category: cs.CL

TL;DR: 本文研究了一种名为LatentQA的简化方法，通过训练模型直接理解大型语言模型（LLM）的激活状态并回答相关问题，验证了其在任务广泛性和泛化能力上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有方法对LLM激活状态的解释较为复杂且任务狭窄，本文旨在探索一种通用且简洁的解释方法，提升模型对激活状态的理解与应用能力。

Method: 训练称为Activation Oracles（AOs）的模型，使用多样化数据集进行训练，包括分类任务和自监督上下文预测任务，评估其在分布外任务中的表现并与现有白盒和黑盒方法对比。

Result: AOs能够有效恢复模型中已微调的信息，即使未见过微调模型的激活，且在四个下游任务中表现优于或匹配先前方法，特别是多样化训练显著提升了泛化能力。

Conclusion: 通过多样化训练，LatentQA模型获得了通用的自然语言查询能力，能够有效解释LLM激活，展现出优异的泛化性能，成为理解LLM激活的新型强有力工具。

Abstract: Large language model (LLM) activations are notoriously difficult to understand, with most existing techniques using complex, specialized methods for interpreting them. Recent work has proposed a simpler approach known as LatentQA: training LLMs to directly accept LLM activations as inputs and answer arbitrary questions about them in natural language. However, prior work has focused on narrow task settings for both training and evaluation. In this paper, we instead take a generalist perspective. We evaluate LatentQA-trained models, which we call Activation Oracles (AOs), in far out-of-distribution settings and examine how performance scales with training data diversity. We find that AOs can recover information fine-tuned into a model (e.g., biographical knowledge or malign propensities) that does not appear in the input text, despite never being trained with activations from a fine-tuned model. Our main evaluations are four downstream tasks where we can compare to prior white- and black-box techniques. We find that even narrowly-trained LatentQA models can generalize well, and that adding additional training datasets (such as classification tasks and a self-supervised context prediction task) yields consistent further improvements. Overall, our best AOs match or exceed prior white-box baselines on all four tasks and are the best method on 3 out of 4. These results suggest that diversified training to answer natural-language queries imparts a general capability to verbalize information about LLM activations.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [41] [How Deep Does Your Dependency Tree Go? An Empirical Study of Dependency Amplification Across 10 Package Ecosystems](https://arxiv.org/abs/2512.14739)
*Jahidul Arafat*

Main category: cs.SE

TL;DR: 本文对十个主流软件包生态系统中依赖放大现象进行了大规模实证研究，发现各生态系统依赖放大倍数差异显著，且设计选择影响依赖放大程度。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发依赖包生态系统，但由于传递依赖导致的依赖放大对软件供应链安全有重大影响，且不同生态系统间的放大模式未被大规模比较。

Method: 选取500个项目，覆盖十个主要生态系统，通过计算传递依赖与直接依赖的比率，比较各生态系统的依赖放大倍数，并分析设计因素影响。

Result: Maven的平均依赖放大倍数最高（24.7倍），Go Modules、npm较低，CocoaPods最低。28% Maven项目放大超10倍，其他生态系统显著不同。设计选择如依赖解析、标准库完整性影响放大程度。

Conclusion: 依赖放大情况因生态系统设计不同而异，建议基于生态系统特点制定安全策略，如Maven需系统审计，npm和RubyGems需针对异常项目检测，而控制良好的生态系统则维持现状。

Abstract: Modern software development relies on package ecosystems where a single declared dependency can pull in many additional transitive packages. This dependency amplification, defined as the ratio of transitive to direct dependencies, has major implications for software supply chain security, yet amplification patterns across ecosystems have not been compared at scale. We present an empirical study of 500 projects across ten major ecosystems, including Maven Central for Java, npm Registry for JavaScript, crates io for Rust, PyPI for Python, NuGet Gallery for dot NET, RubyGems for Ruby, Go Modules for Go, Packagist for PHP, CocoaPods for Swift and Objective C, and Pub for Dart. Our analysis shows that Maven exhibits mean amplification of 24.70 times, compared to 4.48 times for Go Modules, 4.32 times for npm, and 0.32 times for CocoaPods. We find significant differences with large effect sizes in 22 of 45 pairwise comparisons, challenging the assumption that npm has the highest amplification due to its many small purpose packages. We observe that 28 percent of Maven projects exceed 10 times amplification, indicating a systematic pattern rather than isolated outliers, compared to 14 percent for RubyGems, 12 percent for npm, and zero percent for Cargo, PyPI, Packagist, CocoaPods, and Pub. We attribute these differences to ecosystem design choices such as dependency resolution behavior, standard library completeness, and platform constraints. Our findings suggest adopting ecosystem specific security strategies, including systematic auditing for Maven environments, targeted outlier detection for npm and RubyGems, and continuation of current practices for ecosystems with controlled amplification. We provide a full replication package with data and analysis scripts.

</details>


### [42] [VDMN: A Graphical Notation for Modelling Value Driver Trees](https://arxiv.org/abs/2512.14740)
*Benjamin Matthies*

Main category: cs.SE

TL;DR: 本文提出了价值驱动建模符号（VDMN），为价值驱动树（VDTs）的建模提供系统化指导，并通过案例研究和专家访谈验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管价值驱动树在管理决策和价值管理中应用广泛，但缺乏系统化的建模指导方法。

Method: 提出VDMN，一种包含完整语义构造和直观图形语法的图形符号，并通过两个案例研究与专家访谈进行评估。

Result: VDMN促进了VDTs的一致且易于理解的建模。

Conclusion: VDMN为价值驱动树的系统化和标准化建模迈出了重要一步。

Abstract: Value Driver Trees (VDTs) are conceptual models used to illustrate and analyse the causal relationships between key performance indicators and business outcomes, thereby supporting managerial decision-making and value-based management. Despite their increasing application, there are still no systematic guidelines for the modelling of such conceptual models. To fill this gap, this study introduces the Value Driver Modelling Notation (VDMN), a graphical notation developed to systematically guide VDT modelling. This notation includes a comprehensive set of semantic constructs and an intuitive graphical syntax. To evaluate its practical utility, the VDMN was applied in two case studies and assessed through expert interviews. The results show that the notation supports a consistent and comprehensible modelling of VDTs. The VDMN thus represents a significant step towards the systematisation and standardisation of VDT modelling.

</details>


### [43] [Revisiting the Reliability of Language Models in Instruction-Following](https://arxiv.org/abs/2512.14754)
*Jianshuo Dong,Yutong Zhang,Yan Liu,Zhenyu Zhong,Tao Wei,Chao Zhang,Han Qiu*

Main category: cs.SE

TL;DR: 本论文关注大语言模型在面对细微提示变化时的可靠性，发现当前模型在细微语义差异的提示下性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 尽管当前大语言模型在标准测试集上表现优异，但在真实应用中用户的表达常带细微差异，模型是否能稳定表现还未充分研究。

Method: 提出了新的评估指标 reliable@k，通过数据增强自动生成高质量相似提示，构建了系统化评测集 IFEval++。

Result: 测试了20个专有模型和26个开源模型，发现模型在细微提示变动下性能最多下降61.8%，表现出显著的不稳定性。

Conclusion: 细微差异提示下的可靠性是迈向更可信赖大语言模型的重要方向，未来需进一步优化模型表现。

Abstract: Advanced LLMs have achieved near-ceiling instruction-following accuracy on benchmarks such as IFEval. However, these impressive scores do not necessarily translate to reliable services in real-world use, where users often vary their phrasing, contextual framing, and task formulations. In this paper, we study nuance-oriented reliability: whether models exhibit consistent competence across cousin prompts that convey analogous user intents but with subtle nuances. To quantify this, we introduce a new metric, reliable@k, and develop an automated pipeline that generates high-quality cousin prompts via data augmentation. Building upon this, we construct IFEval++ for systematic evaluation. Across 20 proprietary and 26 open-source LLMs, we find that current models exhibit substantial insufficiency in nuance-oriented reliability -- their performance can drop by up to 61.8% with nuanced prompt modifications. What's more, we characterize it and explore three potential improvement recipes. Our findings highlight nuance-oriented reliability as a crucial yet underexplored next step toward more dependable and trustworthy LLM behavior. Our code and benchmark are accessible: https://github.com/jianshuod/IFEval-pp.

</details>


### [44] [Examining Software Developers' Needs for Privacy Enforcing Techniques: A survey](https://arxiv.org/abs/2512.14756)
*Ioanna Theophilou,Georgia M. Kapitsaki*

Main category: cs.SE

TL;DR: 本文通过调查68名开发者，分析了数据隐私合规中的开发者需求，发现自动化工具需求旺盛，隐私经验影响工具关注度，强调了隐私辅助工具的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 数据隐私法规如GDPR和CCPA要求软件系统合规，实现复杂且依赖法律知识，现有研究未充分关注开发者在隐私合规中的实际需求。

Method: 通过对68名开发者的调查，探讨他们在隐私法合规过程中的需求及影响因素。

Result: 大多数开发者需要更多自动化工具，且隐私经验丰富的开发者对隐私工具的需求更高。

Conclusion: 研究结果有助于实践者更好地将开发活动定位于隐私合规，凸显了开发隐私辅助工具的紧迫需求。

Abstract: Data privacy legislation, such as GDPR and CCPA/CPRA, has rendered data privacy law compliance a requirement of all software systems. Developers need to implement various kinds of functionalities to cover law needs, including user rights and law principles. As data compliance is tightly coupled with legal knowledge, it is not always easy to perform such integrations in software systems. Prior studies have focused on developers' understanding of privacy principles, such as Privacy by Design, and have examined privacy techniques used in the software industry. Nevertheless, emerging developer needs that can assist in privacy law compliance have not been examined but are useful in understanding what development automation tools, such as Generative AI, need to cover to make the compliance process more straightforward and seamless within the development process. In this work, we present a survey that examines the above needs with the participation of 68 developers, while we have examined which factors affect practitioners' needs. Most developers express a need for more automated tools, while privacy experience increases practitioners' concerns for privacy tools. Our results can assist practitioners in better positioning their development activities within privacy law compliance and point to an urgent need for privacy facilitators.

</details>


### [45] [CAPE: Capability Achievement via Policy Execution](https://arxiv.org/abs/2512.14761)
*David Ball*

Main category: cs.SE

TL;DR: 本文提出了能力工程（Capability Engineering）方法，通过将需求转换为可执行规范，并利用CAPE协议训练模型以满足这些规范，从而显著减少模型违反规定的情况，提高模型在实际应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现代人工智能系统缺乏表达和执行明确、上下文相关约束的机制，导致模型在实际部署中虽然在基准测试中表现优异，却频繁失败。

Method: 引入能力工程体系，采用CAPE协议（Specify -> Verify -> Correct -> Train循环），基于上下文客观性和验证准确度随模型规模提升的发现，替代传统的逐例标注，使用可复用的规范进行训练和验证。

Result: 在六个领域共109,500个样本上，CAPE协议相比标准DPO方法将违规率降低了81%，并且大幅减少了成本（5到20倍）和时间（数月缩短至数周）。

Conclusion: 能力工程及CAPE协议为模型合规性保障提供了一套系统方法，实现了能力测量向明确规范和执行的转变，有助于推动AI系统更可靠和高效的部署。

Abstract: Modern AI systems lack a way to express and enforce requirements. Pre-training produces intelligence, and post-training optimizes preferences, but neither guarantees that models reliably satisfy explicit, context-dependent constraints. This missing abstraction explains why highly intelligent models routinely fail in deployment despite strong benchmark performance.
  We introduce Capability Engineering, the systematic practice of converting requirements into executable specifications and training models to satisfy them by default. We operationalize this practice through CAPE (Capability Achievement via Policy Execution), a protocol implementing a Specify -> Verify -> Correct -> Train loop.
  CAPE is grounded in two empirical findings: (1) contextual objectivity, where properties appearing subjective become objective once context is fixed (inter-annotator agreement rises from kappa = 0.42 to kappa = 0.98), and (2) verification-fidelity scaling, where verification accuracy improves with model scale (r = 0.94), unlike preference agreement which plateaus at 30 to 50 percent disagreement regardless of compute. Across 109,500 examples in six domains, CAPE reduces violation rates by 81 percent relative to DPO (standard deviation less than 0.3 percent). By replacing per-example annotation with reusable specifications, CAPE reduces costs by 5 to 20 times and shortens timelines from months to weeks.
  We release the CAPE protocol, PredicateGraph schema, CPL specification language, and policy packs under Apache 2.0. We also launch CapabilityBench, a public registry of model evaluations against community-contributed policies, shifting evaluation from intelligence benchmarks toward capability measurement.

</details>


### [46] [Workflows vs Agents for Code Translation](https://arxiv.org/abs/2512.14762)
*Henry Gray,Tom Yotam,Octavian Udrea*

Main category: cs.SE

TL;DR: 研究比较了两种大型语言模型驱动的MATLAB到HDL语法修复方法，发现更自主的agentic方法在解决语法错误和提高流水线处理效率上效果更好，尤其对中小型模型提升显著。


<details>
  <summary>Details</summary>
Motivation: MATLAB到HDL的算法转换在FPGA和ASIC部署中非常重要，但由于大型语言模型对HDL代码训练有限，端到端转换易出错，需要有效的语法修复方法。

Method: 对42个MATLAB信号处理函数进行测试，比较结构化专家设计的固定流程与采用Model Context Protocol（MCP）动态选择工具的agentic方法在语法修复阶段的表现。

Result: agentic方法在多种模型规模下更有效解决语法错误，提升了流水线的处理能力，尤其在中型模型中，模拟成功率提升超过20个百分点。条件检索对8B和30B模型效果明显，235B模型中则朴素RAG表现最好。

Conclusion: 合理设计的agentic框架能有效弥补中小型号语言模型的能力限制，提升MATLAB到HDL代码转换的语法修复和整体表现。

Abstract: Translating algorithms from high-level languages like MATLAB to hardware description languages (HDLs) is a resource-intensive but necessary step for deployment on FPGAs and ASICs. While large language models (LLMs) offer a path to automation, their limited training on HDL code makes end-to-end transpilation brittle and prone to syntax errors. We compare two LLM-driven methods for syntax repair in a MATLAB-to-HDL pipeline: a structured, expert-designed flow that follows a fixed sequence of operations, and a more autonomous agentic approach that uses the Model Context Protocol (MCP) \cite{anthropic2024mcp} to dynamically select its own tools. We study 42 MATLAB signal-processing functions and isolate the syntax-repair stage. Across three model scales, the agentic approach is more effective at resolving initial syntax errors, unblocking a greater number of candidates to proceed through the pipeline. This upstream improvement yields measurable downstream improvements, most notably on mid-sized models, where it increases the simulation reach rate by over 20 percentage points. We hypothesize the gains come from short prompts, aggressive context management, and conditional tool use. Conditional retrieval helps at 8B and 30B; at 235B final-success gains are small and a naive RAG variant attains the highest final success. Our findings suggest that these agentic frameworks, when properly designed, are most effective at compensating for the capacity limits of small and mid-sized models.

</details>


### [47] [Let the Barbarians In: How AI Can Accelerate Systems Performance Research](https://arxiv.org/abs/2512.14806)
*Audrey Cheng,Shu Liu,Melissa Pan,Zhifei Li,Shubham Agarwal,Mert Cemri,Bowen Wang,Alexander Krentsel,Tian Xia,Jongseok Park,Shuo Yang,Jeff Chen,Lakshya Agrawal,Ashwin Naren,Shulu Li,Ruiying Ma,Aditya Desai,Jiarong Xing,Koushik Sen,Matei Zaharia,Ion Stoica*

Main category: cs.SE

TL;DR: 本文提出了AI驱动的系统研究（ADRS）方法，通过生成、评估和优化迭代循环，利用AI自动发现和验证系统性能解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统系统性能研究因复杂性和人工限制，难以高效发现最佳方案，AI自动化能显著提升研究效率和方案质量。

Method: 通过多个开源ADRS框架（如OpenEvolve、GEPA、ShinkaEvolve）应用于十个案例，结合生成候选方案、在实际系统或模拟器中评估验证、反复优化的流程。

Result: ADRS方法产生的解决方案在多个案例中匹配甚至优于人类设计的最先进方案。

Conclusion: 提出了ADRS应用的最佳实践建议，并展望未来研究方向，期望为系统研究中的问题构建和战略指导提供借鉴。

Abstract: Artificial Intelligence (AI) is beginning to transform the research process by automating the discovery of new solutions. This shift depends on the availability of reliable verifiers, which AI-driven approaches require to validate candidate solutions. Research focused on improving systems performance is especially well-suited to this paradigm because system performance problems naturally admit such verifiers: candidates can be implemented in real systems or simulators and evaluated against predefined workloads. We term this iterative cycle of generation, evaluation, and refinement AI-Driven Research for Systems (ADRS). Using several open-source ADRS instances (i.e., OpenEvolve, GEPA, and ShinkaEvolve), we demonstrate across ten case studies (e.g., multi-region cloud scheduling, mixture-of-experts load balancing, LLM-based SQL, transaction scheduling) that ADRS-generated solutions can match or even outperform human state-of-the-art designs. Based on these findings, we outline best practices (e.g., level of prompt specification, amount of feedback, robust evaluation) for effectively using ADRS, and we discuss future research directions and their implications. Although we do not yet have a universal recipe for applying ADRS across all of systems research, we hope our preliminary findings, together with the challenges we identify, offer meaningful guidance for future work as researcher effort shifts increasingly toward problem formulation and strategic oversight. Note: This paper is an extension of our prior work [14]. It adds extensive evaluation across multiple ADRS frameworks and provides deeper analysis and insights into best practices.

</details>


### [48] [Industry Expectations and Skill Demands in Quantum Software Testing](https://arxiv.org/abs/2512.14861)
*Ronnie de Souza Santos,Teresa Baldassarre,Cesar França*

Main category: cs.SE

TL;DR: 本文研究量子软件测试角色定义及技能要求，通过分析110个招聘信息发现测试结合传统软件保证与实验验证，强调量子特有技术。


<details>
  <summary>Details</summary>
Motivation: 量子软件测试面临与传统软件不同的挑战，需要了解行业如何定义测试角色及期待技能。

Method: 分析110条量子软件和硬件开发相关招聘岗位，识别测试活动、能力及技能要求。

Result: 测试工作融合传统质量保障与实验校准，强调量子-经典混合验证，企业要求结合编程自动化与量子专业知识。

Conclusion: 量子软件测试仍处于快速发展早期，结合软件工程与实验物理，需加强教育和研究以适应行业需求。

Abstract: Quantum software testing introduces new challenges that differ fundamentally from those in classical software engineering. Aims: This study investigates how the quantum software industry defines testing roles and what skills are expected from professionals in these positions. Method: We analyzed 110 job postings from organizations involved in quantum software and hardware development, identifying activities, competencies, and skill requirements related to testing. Results: The findings show that testing in quantum contexts combines traditional software quality assurance with experimental validation, emphasizing calibration, control, and hybrid quantum-classical verification. Employers seek professionals who integrate programming and automation expertise with quantum-specific technical knowledge and interdisciplinary collaboration skills. Conclusions: Quantum software testing remains at an early but rapidly evolving stage that bridges software engineering and experimental physics, highlighting the need for educational and research efforts that align testing practices with industrial realities.

</details>


### [49] [Evaluating Code Reasoning Abilities of Large Language Models Under Real-World Settings](https://arxiv.org/abs/2512.14917)
*Changshu Liu,Alireza Ghazanfari,Yang Chen,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出了RE2-Bench，一个涵盖复杂现实代码推理问题的新基准，显著提升了代码推理任务的真实性和难度分类，揭示了大模型在复杂任务上的表现下降。


<details>
  <summary>Details</summary>
Motivation: 现有代码推理基准往往过于简单，不能反映实际项目中的复杂依赖及高级特性，致使对语言模型推理能力的评估不准确。

Method: 构建了包含1101个推理问题（其中195个来自真实项目）的RE2-Bench基准，利用静态和动态程序分析实现复杂类型的序列化与反序列化，并通过九个代码复杂度指标采用多票制将问题分为“简单”和“困难”两类。

Result: 使用RE2-Bench评估六个大型语言模型，在输入预测和输出预测任务中，模型在困难问题上的表现分别比简单问题降低约51.50%和42.15%。

Conclusion: RE2-Bench更真实地反映了语言模型的代码推理能力，表明现有评估高估了模型处理复杂代码任务的能力，未来评测需考虑更复杂的代码特性。

Abstract: Code reasoning tasks are becoming prevalent in large language model (LLM) assessments. Existing benchmarks involve simple programs, failing to represent real-world complexities such as inter- or intra-procedural dependencies, core or third-party API calls, highly nested constructs, and non-primitive complex types. Evaluating LLMs under such a simplistic setting poses a significant threat to assumptions about their generalizability in practice. To enable a more realistic evaluation of code reasoning, this paper proposes RE2-Bench, a benchmark of 1,101 reasoning problems, including 195 drawn from mature real-world projects. RE2-Bench leverages static and dynamic program analysis to automatically serialize and deserialize compound, complex, and custom types in real-world code, going far beyond the primitive-only settings used in prior work.
  A key feature of RE2-Bench is categorizing each reasoning problem as Easy or Hard via a principled majority-vote mechanism over nine interpretable code complexity metrics, resulting in two well-separated and semantically meaningful difficulty categories suitable for precise calibration of LLM reasoning ability. A comprehensive evaluation of six general-purpose and reasoning-oriented LLMs on two widely used code reasoning tasks -- input prediction and output prediction -- using RE2-Bench reveals a significant performance drop from Easy to Hard problems (51.50\% for input prediction and 42.15\% for output prediction), confirming that prior evaluations substantially overestimate the reasoning capabilities of LLMs.

</details>


### [50] [Imitation Game: Reproducing Deep Learning Bugs Leveraging an Intelligent Agent](https://arxiv.org/abs/2512.14990)
*Mehil B Shah,Mohammad Masudur Rahman,Foutse Khomh*

Main category: cs.SE

TL;DR: 提出RepGen，一种自动化再现深度学习Bug的方法，实现了80.19%的再现率，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度学习应用存在诸多难以复现的Bug，手动方法再现率低，仅3%。

Method: RepGen通过构建学习增强的环境、制定全面再现计划，并采用迭代生成-验证-优化机制，使用大语言模型自动生成复现代码。

Result: 在106个真实DL Bug上，RepGen再现率达80.19%，比现有技术提高19.81%；开发者实验显示成功率提高23.35%，时间减半，认知负担减轻。

Conclusion: RepGen显著提升了DL Bug再现效率和效果，降低开发者工作量，有助于深度学习应用的故障排查和修复。

Abstract: Despite their wide adoption in various domains (e.g., healthcare, finance, software engineering), Deep Learning (DL)-based applications suffer from many bugs, failures, and vulnerabilities. Reproducing these bugs is essential for their resolution, but it is extremely challenging due to the inherent nondeterminism of DL models and their tight coupling with hardware and software environments. According to recent studies, only about 3% of DL bugs can be reliably reproduced using manual approaches. To address these challenges, we present RepGen, a novel, automated, and intelligent approach for reproducing deep learning bugs. RepGen constructs a learning-enhanced context from a project, develops a comprehensive plan for bug reproduction, employs an iterative generate-validate-refine mechanism, and thus generates such code using an LLM that reproduces the bug at hand. We evaluate RepGen on 106 real-world deep learning bugs and achieve a reproduction rate of 80.19%, a 19.81% improvement over the state-of-the-art measure. A developer study involving 27 participants shows that RepGen improves the success rate of DL bug reproduction by 23.35%, reduces the time to reproduce by 56.8%, and lowers participants' cognitive load.

</details>


### [51] [Toxicity Ahead: Forecasting Conversational Derailment on GitHub](https://arxiv.org/abs/2512.15031)
*Mia Mohammad Imran,Robert Zita,Rahat Rizvi Rahman,Preetha Chatterjee,Kostadin Damevski*

Main category: cs.SE

TL;DR: 本论文构建了一个GitHub对话数据集，利用大语言模型通过两步提示策略，实现对开源社区中有害对话失控的高效预测。


<details>
  <summary>Details</summary>
Motivation: 开源软件社区中的有害互动会降低贡献者参与度，威胁项目的可持续性，而现有的预防方法多依赖社区维护者的人工干预，效率低下。

Method: 构建159条有毒失控线程和207条非有毒线程的数据集，分析对话中的紧张触发点、情绪变化和对话模式；设计基于大语言模型的两步提示管线，先生成对话动态摘要，再预测对话失控的可能性。

Result: 基于Qwen和Llama模型的提示方法分别达到了F1分数0.901和0.852，优于现有自然语言处理基线；外部验证数据集上F1分数达到0.797，证明模型的泛化能力。

Conclusion: 结构化的大语言模型提示策略能够有效早期检测开源社区中的对话失控，支持主动且可解释的社区管理和有害内容干预。

Abstract: Toxic interactions in Open Source Software (OSS) communities reduce contributor engagement and threaten project sustainability. Preventing such toxicity before it emerges requires a clear understanding of how harmful conversations unfold. However, most proactive moderation strategies are manual, requiring significant time and effort from community maintainers. To support more scalable approaches, we curate a dataset of 159 derailed toxic threads and 207 non-toxic threads from GitHub discussions. Our analysis reveals that toxicity can be forecast by tension triggers, sentiment shifts, and specific conversational patterns.
  We present a novel Large Language Model (LLM)-based framework for predicting conversational derailment on GitHub using a two-step prompting pipeline. First, we generate \textit{Summaries of Conversation Dynamics} (SCDs) via Least-to-Most (LtM) prompting; then we use these summaries to estimate the \textit{likelihood of derailment}. Evaluated on Qwen and Llama models, our LtM strategy achieves F1-scores of 0.901 and 0.852, respectively, at a decision threshold of 0.3, outperforming established NLP baselines on conversation derailment. External validation on a dataset of 308 GitHub issue threads (65 toxic, 243 non-toxic) yields an F1-score up to 0.797. Our findings demonstrate the effectiveness of structured LLM prompting for early detection of conversational derailment in OSS, enabling proactive and explainable moderation.

</details>


### [52] [An Exploratory Study of Bayesian Prompt Optimization for Test-Driven Code Generation with Large Language Models](https://arxiv.org/abs/2512.15076)
*Shlok Tomar,Aryan Deshwal,Ethan Villalovoz,Mattia Fazzini,Haipeng Cai,Janardhan Rao Doppa*

Main category: cs.SE

TL;DR: 本文提出了一种基于贝叶斯优化的方法BODE-GEN，通过连续嵌入空间中的自适应搜索优化大语言模型的代码生成提示，从而提升代码生成的功能正确性。


<details>
  <summary>Details</summary>
Motivation: 代码生成的正确性受到提示(prompt)的影响，寻找合适的提示是一个组合搜索问题，现有方法缺乏高效自动优化提示策略。

Method: BODE-GEN利用贝叶斯优化在连续嵌入空间中搜索，通过辅助LLM将离散提示映射到连续空间，采用随机投影和维度缩放先验构建高维高斯过程代理模型，以训练数据引导自适应提示搜索。

Result: 在人类评测基准HumanEval+上，BODE-GEN相比固定和手工设计提示显著提高了代码生成准确率；同时，该方法具备样本高效性，所需优化迭代次数较少。

Conclusion: BODE-GEN为自动提示优化提供了一种有效的贝叶斯优化框架，能够提升大语言模型生成代码的功能正确性，且对提示优化过程的样本效率高。

Abstract: We consider the task of generating functionally correct code using large language models (LLMs). The correctness of generated code is influenced by the prompt used to query the given base LLM. We formulate the problem of finding the appropriate prompt as combinatorial search process and propose a Bayesian optimization (BO) approach referred to as {\em BO for Code GENeration (BODE-GEN)}. BODE-GEN performs an adaptive data-driven search over prompts guided by training data in the form of prompts tried and the functional accuracy of the generated code over a set of given test cases. The key insight is to perform BO in continuous embedding space by using an auxiliary LLM to bridge the gap between discrete prompt space and continuous embedding space. We leverage two synergistic ideas, namely, random projections and dimensionality scaled priors, to build effective Gaussian process based surrogate models over the high-dimensional embedding space. Our experiments on the HumanEval+ benchmark using multiple base LLMs show that BODE-GEN can improve performance in terms of code generation accuracy compared to fixed prompts and manual prompt engineering. Additionally, we demonstrate that BODE-GEN is sample-efficient, requiring relatively few iterations of BO to demonstrate improvements in code accuracy.

</details>


### [53] [Aligning Academia with Industry: An Empirical Study of Industrial Needs and Academic Capabilities in AI-Driven Software Engineering](https://arxiv.org/abs/2512.15148)
*Hang Yu,Yuzhou Lai,Li Zhang,Xiaoli Lian,Fang Liu,Yanrui Dong,Ting Zhang,Zhi Jin,David Lo*

Main category: cs.SE

TL;DR: 本文系统分析了2022-2025年软件工程顶级会议中1,367篇论文的研究主题和工业相关性，结合17家机构的调查，揭示学术成果与工业需求的差距，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管学术界在自动测试、程序修复等领域取得持续进展，但这些成果与工业实际需求的契合度尚不明确，亟需厘清学术与工业间的差距。

Method: 系统分析FSE、ASE、ICSE三大会议的论文，确定研究热点与工业相关性；通过问卷调查17家机构的282份反馈，比较学术能力与工业需求。

Result: 发现学术研究集中在有限领域，而软件需求、架构、智能方法的可靠性与可解释性、评价方法以及伦理问题等工业急需关注的领域尚被忽视。

Conclusion: 建议未来软件工程研究聚焦未充分解决的工业问题，提升学术研究的实际应用价值和工业影响力。

Abstract: The rapid advancement of large language models (LLMs) is fundamentally reshaping software engineering (SE), driving a paradigm shift in both academic research and industrial practice. While top-tier SE venues continue to show sustained or emerging focus on areas like automated testing and program repair, with researchers worldwide reporting continuous performance gains, the alignment of these academic advances with real industrial needs remains unclear. To bridge this gap, we first conduct a systematic analysis of 1,367 papers published in FSE, ASE, and ICSE between 2022 and 2025, identifying key research topics, commonly used benchmarks, industrial relevance, and open-source availability. We then carry out an empirical survey across 17 organizations, collecting 282 responses on six prominent topics, i.e., program analysis, automated testing, code generation/completion, issue resolution, pre-trained code models, and dependency management, through structured questionnaires. By contrasting academic capabilities with industrial feedback, we derive seven critical implications, highlighting under-addressed challenges in software requirements and architecture, the reliability and explainability of intelligent SE approaches, input assumptions in academic research, practical evaluation tensions, and ethical considerations. This study aims to refocus academic attention on these important yet under-explored problems and to guide future SE research toward greater industrial impact.

</details>


### [54] [Automating Execution and Verification of BPMN+DMN Business Processes](https://arxiv.org/abs/2512.15214)
*Giuseppe Della Penna,Igor Melatti*

Main category: cs.SE

TL;DR: 本文提出了BDTransTest工具，用于将BPMN+DMN业务流程转换为Java程序，并合成测试计划以检测语义错误，提升流程验证能力。


<details>
  <summary>Details</summary>
Motivation: 现有BPMN+DMN建模框架仅能检测语法错误，无法捕获语义（行为）错误，且需设计师手动运行单次执行检测失败，缺乏有效的测试与验证方法。

Method: 设计BDTransTest工具，实现BPMN+DMN流程向Java程序的转换，自动合成并执行测试计划，需业务设计师对部分输入域进行消歧义，同时分析测试计划在流程节点和边覆盖上的效果。

Result: 通过对文献中BPMN+DMN流程的实验验证，证明了该方法和工具能够有效提升流程的语义正确性验证能力。

Conclusion: BDTransTest为BPMN+DMN流程提供了系统化的语义错误检测与测试覆盖分析方法，弥补了现有工具只能检测语法错误的不足，推动业务流程正确性验证的发展。

Abstract: The increasing and widespread use of BPMN business processes, also embodying DMN tables, requires tools and methodologies to verify their correctness. However, most commonly used frameworks to build BPMN+DMN models only allow designers to detect syntactical errors, thus ignoring semantic (behavioural) faults. This forces business processes designers to manually run single executions of their BPMN+DMN processes using proprietary tools in order to detect failures. Furthermore, how proprietary tools translate a BPMN+DMN process to a computer simulation is left unspecified. In this paper, we advance this state of the art by designing a tool, named BDTransTest providing: i) a translation from a BPMN + DMN process B to a Java program P ; ii) the synthesis and execution of a testing plan for B, that may require the business designer to disambiguate some input domain; iii) the analysis of the coverage achieved by the testing plan in terms of nodes and edges of B. Finally, we provide an experimental evaluation of our methodology on BPMN+DMN processes from the literature.

</details>


### [55] [Heterogeneous Model Alignment in Digital Twin](https://arxiv.org/abs/2512.15281)
*Faima Abbasi,Jean-Sébastien Sottet,Cedric Pruski*

Main category: cs.SE

TL;DR: 本文提出了一种针对多层模型驱动数字孪生的异构模型对齐方法，通过自适应一致机制和大语言模型验证流程，实现语义一致性和结构保真性，减少人工映射，提升扩展性。


<details>
  <summary>Details</summary>
Motivation: 多层模型驱动数字孪生中，异构模型跨抽象层对齐存在语义不匹配、不一致和同步问题，现有静态映射方法灵活性差且易出错。

Method: 构建含自适应一致机制的框架，结合大语言模型验证流程，将元模型与领域知识结合，实现模型间自适应链接和语义对应的自动发现。

Result: 通过空气质量案例演示方法有效性，并利用本体对齐评测框架（OAEI）多测试用例验证性能。

Conclusion: 该方法自动化程度高，减少人工干预，提升异构模型对齐的语义一致性和扩展能力，有助于数字孪生多层模型的管理与优化。

Abstract: Digital twin (DT) technology integrates heterogeneous data and models, along with semantic technologies to create multi-layered digital representation of physical systems. DTs enable monitoring, simulation, prediction, and optimization to enhance decision making and operational efficiency. A key challenge in multi-layered, model-driven DTs is aligning heterogeneous models across abstraction layers, which can lead to semantic mismatches, inconsistencies, and synchronization issues. Existing methods, relying on static mappings and manual updates, are often inflexible, error-prone, and risk compromising data integrity. To address these limitations, we present a heterogeneous model alignment approach for multi-layered, model-driven DTs. The framework incorporates a flexibility mechanism that allows metamodels to adapt and interconnect seamlessly while maintaining semantic coherence across abstraction layers. It integrates: (i) adaptive conformance mechanisms that link metamodels with evolving models and (ii) a large language model (LLM) validated alignment process that grounds metamodels in domain knowledge, ensuring structural fidelity and conceptual consistency throughout the DT lifecycle. This approach automates semantic correspondences discovery, minimizes manual mapping, and enhances scalability across diverse model types. We illustrate the approach using air quality use case and validate its performance using different test cases from Ontology Alignment Evaluation Initiative (OAEI) tracks.

</details>


### [56] [Can AI Generate more Comprehensive Test Scenarios? Review on Automated Driving Systems Test Scenario Generation Methods](https://arxiv.org/abs/2512.15422)
*Ji Zhou,Yongqi Zhao,Yixian Hu,Hexuan Li,Zhengguo Gu,Nan Xu,Arno Eichberger*

Main category: cs.SE

TL;DR: 本文系统综述了2015至2025年间自动驾驶系统场景化测试的最新进展，重点分析了2023至2025年间的人工智能辅助和多模态方法。该研究发现当前方法存在评价指标不标准、伦理与人因整合不足、多模态和ODD覆盖有限等问题，并提出了改进的分类体系、伦理安全检查表和ODD覆盖地图以促进标准化和安全部署。


<details>
  <summary>Details</summary>
Motivation: 传统大规模道路测试成本高、耗时长，自动驾驶系统安全验证面临难题，因此需要场景化测试作为更高效且可扩展的替代方案。

Method: 系统分析了31项主要研究和10项综述，重点比较2023至2025年间采用生成模型（大型语言模型、生成对抗网络、扩散模型、强化学习框架）的最新方法，揭示方法学差距并提出新的分类和评价工具。

Result: 识别了三大瓶颈：缺乏统一评价指标，伦理与人因考量不足，以及多模态和运营设计域特定场景覆盖不足；提出了包括多模态扩展的分类体系、伦理安全检查清单及ODD场景难度图谱等工具。

Conclusion: 该综述为场景化测试方法提供了更清晰的框架和评价标准，促进了研究的可重复性和工业界的实际应用，加速了高阶自动驾驶系统的安全部署。

Abstract: Ensuring the safety and reliability of Automated Driving Systems (ADS) remains a critical challenge, as traditional verification methods such as large-scale on-road testing are prohibitively costly and time-consuming.To address this,scenario-based testing has emerged as a scalable and efficient alternative,yet existing surveys provide only partial coverage of recent methodological and technological advances.This review systematically analyzes 31 primary studies,and 10 surveys identified through a comprehensive search spanning 2015~2025;however,the in-depth methodological synthesis and comparative evaluation focus primarily on recent frameworks(2023~2025),reflecting the surge of Artificial Intelligent(AI)-assisted and multimodal approaches in this period.Traditional approaches rely on expert knowledge,ontologies,and naturalistic driving or accident data,while recent developments leverage generative models,including large language models,generative adversarial networks,diffusion models,and reinforcement learning frameworks,to synthesize diverse and safety-critical scenarios.Our synthesis identifies three persistent gaps:the absence of standardized evaluation metrics,limited integration of ethical and human factors,and insufficient coverage of multimodal and Operational Design Domain (ODD)-specific scenarios.To address these challenges,this review contributes a refined taxonomy that incorporates multimodal extensions,an ethical and safety checklist for responsible scenario design,and an ODD coverage map with a scenario-difficulty schema to enable transparent benchmarking.Collectively,these contributions provide methodological clarity for researchers and practical guidance for industry,supporting reproducible evaluation and accelerating the safe deployment of higher-level ADS.

</details>


### [57] [Insecure Ingredients? Exploring Dependency Update Patterns of Bundled JavaScript Packages on the Web](https://arxiv.org/abs/2512.15447)
*Ben Swierzy,Marc Ohm,Michael Meier*

Main category: cs.SE

TL;DR: 本文提出了一种名为Aletheia的新方法，通过剽窃检测算法解析JavaScript捆绑包，准确识别包版本，显著优于现有技术。通过对前10万网站的爬取分析发现，5%至20%的网站在16周内更新依赖包，且捆绑包的更新频率高于CDN引入的包，降低了已知易受攻击版本的使用。


<details>
  <summary>Details</summary>
Motivation: 尽管npm上的下载数据表明易受攻击的包版本依然广泛使用，但实际生产环境中包版本的使用情况尚不明确，现有的版本检测方法不足以全面分析现代网页应用的依赖更新行为。

Method: 提出Aletheia方法，利用来自剽窃检测领域的算法，无需依赖特定包，解析JavaScript捆绑包以识别具体的包版本，突破当前方法只能识别手选包或单文件资源的限制。

Result: Aletheia在实际应用中性能优于现有方案。通过对Tranco排名前10万网站的分析，发现5%-20%的网站会在16周更新依赖，捆绑包更新更快，包含的已知易受攻击版本数量是CDN包的10分之一。

Conclusion: 定量分析显示捆绑包更新更及时，减少了安全风险，但实际驱动更新的主要是少数大型供应商，表明单纯的数量统计不能完全反映依赖更新的实际情况。

Abstract: Reusable software components, typically distributed as packages, are a central paradigm of modern software development. The JavaScript ecosystem serves as a prime example, offering millions of packages with their use being promoted as idiomatic. However, download statistics on npm raise security concerns as they indicate a high popularity of vulnerable package versions while their real prevalence on production websites remains unknown. Package version detection mechanisms fill this gap by extracting utilized packages and versions from observed artifacts on the web. Prior research focuses on mechanisms for either hand-selected popular packages in bundles or for single-file resources utilizing the global namespace. This does not allow for a thorough analysis of modern web applications' dependency update behavior at scale. In this work, we improve upon this by presenting Aletheia, a package-agnostic method which dissects JavaScript bundles to identify package versions through algorithms originating from the field of plagiarism detection. We show that this method clearly outperforms the existing approaches in practical settings. Furthermore, we crawl the Tranco top 100,000 domains to reveal that 5% - 20% of domains update their dependencies within 16 weeks. Surprisingly, from a longitudinal perspective, bundled packages are updated significantly faster than their CDN-included counterparts, with consequently up to 10 times fewer known vulnerable package versions included. Still, we observe indicators that few widespread vendors seem to be a major driving force behind timely updates, implying that quantitative measures are not painting a complete picture.

</details>


### [58] [A Container-based Approach For Proactive Asset Administration Shell Digital Twins](https://arxiv.org/abs/2512.15452)
*Carsten Ellwein,Jingxi Zhang,Andreas Wortmann,Antony Ayman Alfy Meckhael*

Main category: cs.SE

TL;DR: 本文提出了一种基于子模型的资产管理壳（AAS）架构，支持动态服务集成和系统适应，实现数字孪生的主动功能。


<details>
  <summary>Details</summary>
Motivation: 现有资产管理壳作为数字孪生只是静态信息模型，缺乏对动态服务集成与系统适应的支持，限制了数字孪生的应用潜力。

Method: 通过对子模型进行扩展，定义行为，构建模块化事件驱动架构，实现基于触发条件的容器化服务动态部署和交互。

Result: 在一个三轴铣床案例中验证了所提架构的有效性，展示了资产管理壳作为主动服务接口的能力。

Conclusion: 该方法使资产管理壳不仅是被动数字表示，还能执行增值服务，为未来基于AI的系统适应和智能奠定基础。

Abstract: In manufacturing, digital twins, realized as Asset Administration Shells (AAS), have emerged as a prevalent practice. These digital replicas, often utilized as structured repositories of asset-related data, facilitate interoperability across diverse systems. However, extant approaches treat the AAS as a static information model, lacking support for dynamic service integration and system adaptation. The existing body of literature has not yet thoroughly explored the potential for integrating executable behavior, particularly in the form of containerized services, into or from the AAS. This integration could serve to enable proactive functionality. In this paper, we propose a submodel-based architecture that introduces a structured service notion to the AAS, enabling services to dynamically interact with and adapt AAS instances at runtime. This concept is implemented through the extension of a submodel with behavioral definitions, resulting in a modular event-driven architecture capable of deploying containerized services based on embedded trigger conditions. The approach is illustrated through a case study on a 3-axis milling machine. Our contribution enables the AAS to serve not only as a passive digital representation but also as an active interface for executing added-value services.%, thereby laying the foundation for future AI-driven adaptation and system-level intelligence in digital twin environments.

</details>


### [59] [On Assessing the Relevance of Code Reviews Authored by Generative Models](https://arxiv.org/abs/2512.15466)
*Robert Heumüller,Frank Ortmeier*

Main category: cs.SE

TL;DR: 本文提出了一种基于多重主观排序的新型代码审查生成评估方法，利用人类评委对ChatGPT生成的审查评论与人类最佳评论进行排名，结果显示ChatGPT表现优于人类。


<details>
  <summary>Details</summary>
Motivation: 现有代码审查自动评估方法依赖单一定义答案或模糊的“有用性”主观评价，不能充分反映人类审查的多样性与复杂性。

Method: 基于280个CodeReview StackExchange代码审查请求及评论，组织多名人类评委对ChatGPT生成的评论与平台顶级人类回答进行多重主观排名。

Result: ChatGPT生成的代码审查评论在排名中显著优于人类评论，甚至超过了StackExchange的官方采纳答案。

Conclusion: 提出的多重主观排序评估方法为生成式AI代码审查性能提供了更有意义的衡量标准，同时强调了在审查流程中谨慎整合AI的重要性以避免潜在风险。

Abstract: The use of large language models like ChatGPT in code review offers promising efficiency gains but also raises concerns about correctness and safety. Existing evaluation methods for code review generation either rely on automatic comparisons to a single ground truth, which fails to capture the variability of human perspectives, or on subjective assessments of "usefulness", a highly ambiguous concept. We propose a novel evaluation approach based on what we call multi-subjective ranking. Using a dataset of 280 self-contained code review requests and corresponding comments from CodeReview StackExchange, multiple human judges ranked the quality of ChatGPT-generated comments alongside the top human responses from the platform. Results show that ChatGPT's comments were ranked significantly better than human ones, even surpassing StackExchange's accepted answers. Going further, our proposed method motivates and enables more meaningful assessments of generative AI's performance in code review, while also raising awareness of potential risks of unchecked integration into review processes.

</details>


### [60] [How Do Semantically Equivalent Code Transformations Impact Membership Inference on LLMs for Code?](https://arxiv.org/abs/2512.15468)
*Hua Yang,Alejandro Velasco,Thanh Le-Cong,Md Nazmul Haque,Bowen Xu,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文研究了使用等效代码变换规避成员推断检测的效果，发现变量重命名等技术能显著降低检测准确率，暴露了许可合规性的漏洞。


<details>
  <summary>Details</summary>
Motivation: 在训练大语言模型时，使用含有许可限制代码的数据可能导致知识产权问题，成员推断检测技术虽然能识别违规数据，但等效代码变换可能削弱其效果。

Method: 系统分析多种等效代码变换规则对成员推断检测的干扰作用，特别进行了变量重命名的因果分析，并测试了单一及组合变换的影响。

Result: 模型准确率在最坏情况下仅下降1.5%，但变量重命名规则使成员推断检测成功率下降10.19%，组合变换未带来更大效果。

Conclusion: 基于代码变换的混淆技术能够显著削弱成员推断检测，提示许可合规执行存在重要漏洞。

Abstract: The success of large language models for code relies on vast amounts of code data, including public open-source repositories, such as GitHub, and private, confidential code from companies. This raises concerns about intellectual property compliance and the potential unauthorized use of license-restricted code. While membership inference (MI) techniques have been proposed to detect such unauthorized usage, their effectiveness can be undermined by semantically equivalent code transformation techniques, which modify code syntax while preserving semantic.
  In this work, we systematically investigate whether semantically equivalent code transformation rules might be leveraged to evade MI detection. The results reveal that model accuracy drops by only 1.5% in the worst case for each rule, demonstrating that transformed datasets can effectively serve as substitutes for fine-tuning. Additionally, we find that one of the rules (RenameVariable) reduces MI success by 10.19%, highlighting its potential to obscure the presence of restricted code. To validate these findings, we conduct a causal analysis confirming that variable renaming has the strongest causal effect in disrupting MI detection. Notably, we find that combining multiple transformations does not further reduce MI effectiveness. Our results expose a critical loophole in license compliance enforcement for training large language models for code, showing that MI detection can be substantially weakened by transformation-based obfuscation techniques.

</details>


### [61] [WuppieFuzz: Coverage-Guided, Stateful REST API Fuzzing](https://arxiv.org/abs/2512.15554)
*Thomas Rooijakkers,Anne Nijsten,Cristian Daniele,Erieke Weitenberg,Ringo Groenewegen,Arthur Melissen*

Main category: cs.SE

TL;DR: 本文提出了WuppieFuzz，一种基于LibAFL的开源REST API模糊测试工具，支持多种测试模式，自动生成测试用例并指导测试以发现软件缺陷。


<details>
  <summary>Details</summary>
Motivation: REST API广泛用于业务流程，但暴露的接口带来安全风险，需要自动化测试技术来提高测试效率和覆盖率。

Method: WuppieFuzz基于OpenAPI规范生成请求序列作为初始输入，结合REST特定的变异策略和覆盖率指导选择请求序列，自动创建测试环境并提供多样化报告。

Result: 通过对Petstore API的评估，验证了白盒模糊测试的鲁棒性及不同策略的有效性，同时监测了端点和代码覆盖率的提升。

Conclusion: WuppieFuzz有效提升了REST API的测试自动化水平和测试覆盖率，降低了手工工作量，对发现安全漏洞具有实用价值。

Abstract: Many business processes currently depend on web services, often using REST APIs for communication. REST APIs expose web service functionality through endpoints, allowing easy client interaction over the Internet. To reduce the security risk resulting from exposed endpoints, thorough testing is desired. Due to the generally vast number of endpoints, automated testing techniques, like fuzzing, are of interest.
  This paper introduces WuppieFuzz, an open-source REST API fuzzer built on LibAFL, supporting white-box, grey-box and black-box fuzzing. Using an OpenAPI specification, it can generate an initial input corpus consisting of sequences of requests. These are mutated with REST-specific and LibAFL-provided mutators to explore different code paths in the software under test. Guided by the measured coverage, WuppieFuzz then selects which request sequences to send next to reach complex states in the software under test. In this process, it automates harness creation to reduce manual efforts often required in fuzzing. Different kinds of reporting are provided by the fuzzer to help fixing bugs.
  We evaluated our tool on the Petstore API to assess the robustness of the white-box approach and the effectiveness of different power schedules. We further monitored endpoint and code coverage over time to measure the efficacy of the approach.

</details>


### [62] [A High-level Synthesis Toolchain for the Julia Language](https://arxiv.org/abs/2512.15679)
*Benedict Short,Ian McInerney,John Wickerson*

Main category: cs.SE

TL;DR: 本文提出了基于MLIR的编译工具链，将Julia语言编写的内核自动编译成SystemVerilog，实现了从高层语言到硬件描述语言的统一开发流程，有效解决了“二语言问题”。


<details>
  <summary>Details</summary>
Motivation: 随着Exascale计算和数据驱动方法的发展，算法计算需求大增。现有问题专用加速器开发过程存在“二语言问题”，算法和硬件实现语言差异大，且需要不同专业技能。

Method: 构建一个MLIR基础的编译工具链，能够自动将Julia代码编译为SystemVerilog，无需额外指令或语言定制，支持动态与静态调度，集成AXI4-Stream协议，并生成可用于各种FPGA的RTL代码。

Result: 该工具链成功综合了一系列信号处理和数学基准测试，实际FPGA设备运行频率达100MHz，吞吐量达到目前业界仅支持低级语言编译工具链的59.71%至82.6%。

Conclusion: 该工具链实现了高层语言Julia到FPGA硬件的直接编译，简化了开发流程，使领域专家无需额外修改即可进行FPGA加速，有助于推动问题专用加速器的设计与实现。

Abstract: With the push towards Exascale computing and data-driven methods, problem sizes have increased dramatically, increasing the computational requirements of the underlying algorithms. This has led to a push to offload computations to general purpose hardware accelerators such as GPUs and TPUs, and a renewed interest in designing problem-specific accelerators using FPGAs. However, the development process of these problem-specific accelerators currently suffers from the "two-language problem": algorithms are developed in one (usually higher-level) language, but the kernels are implemented in another language at a completely different level of abstraction and requiring fundamentally different expertise. To address this problem, we propose a new MLIR-based compiler toolchain that unifies the development process by automatically compiling kernels written in the Julia programming language into SystemVerilog without the need for any additional directives or language customisations. Our toolchain supports both dynamic and static scheduling, directly integrates with the AXI4-Stream protocol to interface with subsystems like on- and off-chip memory, and generates vendor-agnostic RTL. This prototype toolchain is able to synthesize a set of signal processing/mathematical benchmarks that can operate at 100MHz on real FPGA devices, achieving between 59.71% and 82.6% of the throughput of designs generated by state-of-the-art toolchains that only compile from low-level languages like C or C++. Overall, this toolchain allows domain experts to write compute kernels in Julia as they normally would, and then retarget them to an FPGA without additional pragmas or modifications.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [63] [Mapis: A Knowledge-Graph Grounded Multi-Agent Framework for Evidence-Based PCOS Diagnosis](https://arxiv.org/abs/2512.15398)
*Zanxiang He,Meng Li,Liyun Shi,Weiye Daia,Liming Nie*

Main category: cs.MA

TL;DR: 该论文提出了一个基于知识的多智能体框架Mapis，用于多囊卵巢综合症（PCOS）诊断，通过结构化流程模拟临床诊断过程，实现了比传统方法更高的准确率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习和深度学习诊断工具依赖大量标注数据且缺乏可解释性，现有多智能体系统未充分结合领域知识，针对PCOS诊断的专业框架尚未开发。

Method: 基于2023年国际指南，设计多智能体协作框架，将诊断任务拆分给专科智能体（妇科内分泌、放射学和排除因子智能体），并构建PCOS知识图，实现证据基础的决策。

Result: 在公共和临床数据集上，Mapis相较于传统机器学习、单智能体及先前多智能体系统分别提升了13.56%、6.55%和7.05%的准确率。

Conclusion: Mapis框架有效整合指南知识和多智能体协作，显著提升PCOS诊断准确性，展示了专业领域多智能体系统的潜力。

Abstract: Polycystic Ovary Syndrome (PCOS) constitutes a significant public health issue affecting 10% of reproductive-aged women, highlighting the critical importance of developing effective diagnostic tools. Previous machine learning and deep learning detection tools are constrained by their reliance on large-scale labeled data and an lack of interpretability. Although multi-agent systems have demonstrated robust capabilities, the potential of such systems for PCOS detection remains largely unexplored. Existing medical multi-agent frameworks are predominantly designed for general medical tasks, suffering from insufficient domain integration and a lack of specific domain knowledge. To address these challenges, we propose Mapis, the first knowledge-grounded multi-agent framework explicitly designed for guideline-based PCOS diagnosis. Specifically, it built upon the 2023 International Guideline into a structured collaborative workflow that simulates the clinical diagnostic process. It decouples complex diagnostic tasks across specialized agents: a gynecological endocrine agent and a radiology agent collaborative to verify inclusion criteria, while an exclusion agent strictly rules out other causes. Furthermore, we construct a comprehensive PCOS knowledge graph to ensure verifiable, evidence-based decision-making. Extensive experiments on public benchmarks and specialized clinical datasets, benchmarking against nine diverse baselines, demonstrate that Mapis significantly outperforms competitive methods. On the clinical dataset, it surpasses traditional machine learning models by 13.56%, single-agent by 6.55%, and previous medical multi-agent systems by 7.05% in Accuracy.

</details>
