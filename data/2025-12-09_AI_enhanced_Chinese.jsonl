{"id": "2512.06042", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06042", "abs": "https://arxiv.org/abs/2512.06042", "authors": ["Ashish Hooda", "Mihai Christodorescu", "Chuangang Ren", "Aaron Wilson", "Kassem Fawaz", "Somesh Jha"], "title": "Auto-SPT: Automating Semantic Preserving Transformations for Code", "comment": null, "summary": "Machine learning (ML) models for code clone detection determine whether two pieces of code are semantically equivalent, which in turn is a key building block for software-engineering tasks like refactoring and security tasks like vulnerability and malware detection. While these models are predominantly trained on clean, structured code datasets, real-world code often undergoes a variety of semantic-preserving transformations, including refactoring, minification, automated formatting, and compiler optimizations. To address this critical gap between training and test data, we propose Auto-SPT, a novel framework to automatically construct synthetic-data generators for code. Auto-SPT is designed to produce Semantic Preserving Transformations (SPTs) that alter a program's syntactic structure while preserving its functionality and is instantiated on top of Large Language Models (LLMs). In particular, we use LLMs to craft a diverse set of SPTs, generate strong implementations for these SPTs, and compose them to result into strong transformations. Our formal analysis shows that the diversity of SPTs impacts the strength of their composition. We then empirically demonstrate that Auto-SPT generates more diverse SPTs than existing approaches and these SPTs significantly drop the performance of state-of-the-art code clone detectors. Further experiments show Auto-SPT can be used to enhance code datasets for training, to produce code-clone detection models that are robust to real-world, adversarial code transformations.", "AI": {"tldr": "\u9488\u5bf9\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6a21\u578b\u5728\u73b0\u5b9e\u4ee3\u7801\u53d8\u6362\u4e0b\u8868\u73b0\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u51faAuto-SPT\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u591a\u6837\u4e14\u5f3a\u5927\u7684\u8bed\u4e49\u4fdd\u6301\u8f6c\u6362\uff0c\u4ee5\u63d0\u5347\u68c0\u6d4b\u6a21\u578b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u4ee3\u7801\u5e38\u7ecf\u8fc7\u591a\u79cd\u8bed\u4e49\u4e0d\u53d8\u53d8\u6362\uff0c\u5bfc\u81f4\u8bad\u7ec3\u5728\u5e72\u51c0\u6570\u636e\u4e0a\u7684\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff0c\u4e9f\u9700\u6709\u6548\u65b9\u6cd5\u63d0\u9ad8\u6a21\u578b\u5bf9\u771f\u5b9e\u4ee3\u7801\u53d8\u6362\u7684\u9c81\u68d2\u6027\u3002", "method": "\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u81ea\u52a8\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u591a\u6837\u5316\u7684\u8bed\u4e49\u4fdd\u6301\u8f6c\u6362\uff08SPTs\uff09\uff0c\u5c06\u8fd9\u4e9b\u8f6c\u6362\u7ec4\u5408\u4ee5\u751f\u6210\u5f3a\u53d8\u6362\uff0c\u7528\u4ee5\u751f\u6210\u5408\u6210\u6570\u636e\u589e\u5f3a\u8bad\u7ec3\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6a21\u578b\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAuto-SPT\u7684\u65b0\u6846\u67b6\uff0c\u65e8\u5728\u81ea\u52a8\u6784\u5efa\u4ee3\u7801\u7684\u8bed\u4e49\u4fdd\u6301\u8f6c\u6362\uff08SPTs\uff09\u751f\u6210\u5668\uff0c\u4ee5\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6a21\u578b\u5728\u9762\u5bf9\u73b0\u5b9e\u4e2d\u7ecf\u8fc7\u8bed\u4e49\u4e0d\u53d8\u8f6c\u6362\uff08\u5982\u91cd\u6784\u3001\u6df7\u6dc6\u3001\u683c\u5f0f\u5316\u3001\u7f16\u8bd1\u4f18\u5316\u7b49\uff09\u4ee3\u7801\u65f6\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002Auto-SPT\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8bbe\u8ba1\uff0c\u80fd\u591f\u751f\u6210\u591a\u6837\u4e14\u5f3a\u5927\u7684SPTs\u7ec4\u5408\uff0c\u4ece\u800c\u63d0\u5347\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u6a21\u578b\u5bf9\u771f\u5b9e\u4e16\u754c\u4ee3\u7801\u7684\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAuto-SPT\u751f\u6210\u7684\u8f6c\u6362\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5177\u591a\u6837\u6027\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u73b0\u6709\u68c0\u6d4b\u5668\u7684\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u589e\u5f3a\u8bad\u7ec3\u6570\u636e\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u9762\u5bf9\u5bf9\u6297\u6027\u4ee3\u7801\u53d8\u6362\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "conclusion": "Auto-SPT\u6846\u67b6\u6709\u6548\u751f\u6210\u4e86\u591a\u6837\u4e14\u5f3a\u5927\u7684\u8bed\u4e49\u4fdd\u6301\u8f6c\u6362\uff0c\u80fd\u591f\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u4ee3\u7801\u7684\u591a\u6837\u53d8\u6362\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u63d0\u9ad8\u6a21\u578b\u5bf9\u6297\u771f\u5b9e\u4ee3\u7801\u53d8\u6362\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.06046", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06046", "abs": "https://arxiv.org/abs/2512.06046", "authors": ["Ramprasath Ganesaraja", "Swathika N", "Saravanan AP", "Kamalkumar Rathinasamy", "Chetana Amancharla", "Rahul Das", "Sahil Dilip Panse", "Aditya Batwe", "Dileep Vijayan", "Veena Ashok", "Thanushree A P", "Kausthubh J Rao", "Alden Olivero", "Roshan", "Rajeshwar Reddy Manthena", "Asmitha Yuga Sre A", "Harsh Tripathi", "Suganya Selvaraj", "Vito Chin", "Kasthuri Rangan Bhaskar", "Kasthuri Rangan Bhaskar", "Venkatraman R", "Sajit Vijayakumar"], "title": "Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework", "comment": "17 pages, 9 figures", "summary": "We present AI4UI, a framework of autonomous front-end development agents purpose-built to meet the rigorous requirements of enterprise-grade application delivery. Unlike general-purpose code assistants designed for rapid prototyping, AI4UI focuses on production readiness delivering secure, scalable, compliant, and maintainable UI code integrated seamlessly into enterprise workflows. AI4UI operates with targeted human-in-the-loop involvement: at the design stage, developers embed a Gen-AI-friendly grammar into Figma prototypes to encode requirements for precise interpretation; and at the post processing stage, domain experts refine outputs for nuanced design adjustments, domain-specific optimizations, and compliance needs. Between these stages, AI4UI runs fully autonomously, converting designs into engineering-ready UI code. Technical contributions include a Figma grammar for autonomous interpretation, domain-aware knowledge graphs, a secure abstract/package code integration strategy, expertise driven architecture templates, and a change-oriented workflow coordinated by specialized agent roles. In large-scale benchmarks against industry baselines and leading competitor systems, AI4UI achieved 97.24% platform compatibility, 87.10% compilation success, 86.98% security compliance, 78.00% feature implementation success, 73.50% code-review quality, and 73.36% UI/UX consistency. In blind preference studies with 200 expert evaluators, AI4UI emerged as one of the leaders demonstrating strong competitive standing among leading solutions. Operating asynchronously, AI4UI generates thousands of validated UI screens in weeks rather than months, compressing delivery timeline", "AI": {"tldr": "AI4UI\u662f\u9762\u5411\u4f01\u4e1a\u7ea7\u5e94\u7528\u7684\u81ea\u4e3b\u524d\u7aef\u5f00\u53d1\u6846\u67b6\uff0c\u501f\u52a9Figma\u8bed\u6cd5\u3001\u4eba\u673a\u534f\u540c\u548c\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u5b89\u5168\u3001\u5408\u89c4\u7684UI\u4ee3\u7801\u81ea\u52a8\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u5f00\u53d1\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u76ee\u524d\u901a\u7528\u4ee3\u7801\u52a9\u624b\u4fa7\u91cd\u5feb\u901f\u539f\u578b\u5236\u4f5c\uff0c\u96be\u4ee5\u6ee1\u8db3\u4f01\u4e1a\u7ea7\u5e94\u7528\u5bf9\u5b89\u5168\u6027\u3001\u53ef\u6269\u5c55\u6027\u3001\u5408\u89c4\u6027\u548c\u7ef4\u62a4\u6027\u7684\u9ad8\u6807\u51c6\u9700\u6c42\uff0cAI4UI\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u5b9e\u73b0\u9762\u5411\u751f\u4ea7\u7684\u81ea\u52a8\u5316\u524d\u7aef\u5f00\u53d1\u3002", "method": "\u5229\u7528Figma\u4e2d\u5b9a\u4e49\u7684\u751f\u6210\u5f0fAI\u53cb\u597d\u8bed\u6cd5\u7f16\u7801\u8bbe\u8ba1\u9700\u6c42\uff0c\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u548c\u5b89\u5168\u4ee3\u7801\u96c6\u6210\u7b56\u7565\uff0c\u5b9e\u73b0\u8bbe\u8ba1\u5230\u4ee3\u7801\u7684\u81ea\u52a8\u8f6c\u6362\uff1b\u5728\u4eba\u673a\u534f\u540c\u73af\u8282\u7531\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u7ec6\u8282\u548c\u5408\u89c4\u6027\u8c03\u6574\uff1b\u91c7\u7528\u53d8\u66f4\u9a71\u52a8\u7684\u5de5\u4f5c\u6d41\u548c\u4e13\u4e1a\u67b6\u6784\u6a21\u677f\u786e\u4fdd\u4ee3\u7801\u8d28\u91cf\u4e0e\u7ef4\u62a4\u6027\u3002", "result": "AI4UI\u662f\u4e00\u5957\u4e13\u4e3a\u4f01\u4e1a\u7ea7\u5e94\u7528\u5f00\u53d1\u8bbe\u8ba1\u7684\u81ea\u4e3b\u524d\u7aef\u5f00\u53d1\u4ee3\u7406\u6846\u67b6\uff0c\u91cd\u70b9\u5728\u4e8e\u751f\u4ea7\u5c31\u7eea\u7684\u5b89\u5168\u3001\u53ef\u6269\u5c55\u3001\u5408\u89c4\u4e14\u6613\u7ef4\u62a4\u7684UI\u4ee3\u7801\u3002\u8be5\u6846\u67b6\u7ed3\u5408\u4eba\u673a\u534f\u540c\uff0c\u5728\u8bbe\u8ba1\u9636\u6bb5\u901a\u8fc7Figma\u5185\u5d4c\u751f\u6210\u5f0fAI\u53cb\u597d\u8bed\u6cd5\u7f16\u7801\u9700\u6c42\uff0c\u540e\u671f\u7531\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u7ec6\u8282\u4f18\u5316\u548c\u5408\u89c4\u5ba1\u67e5\uff0c\u4e2d\u95f4\u9636\u6bb5\u5b9e\u73b0\u81ea\u52a8\u5c06\u8bbe\u8ba1\u8f6c\u5316\u4e3a\u5de5\u7a0b\u5c31\u7eea\u4ee3\u7801\u3002\u6280\u672f\u521b\u65b0\u5305\u62ecFigma\u8bed\u6cd5\u89e3\u6790\u3001\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u3001\u5b89\u5168\u7684\u4ee3\u7801\u96c6\u6210\u7b56\u7565\u3001\u4e13\u4e1a\u67b6\u6784\u6a21\u677f\u4ee5\u53ca\u57fa\u4e8e\u53d8\u66f4\u7684\u5de5\u4f5c\u6d41\u3002\u5927\u89c4\u6a21\u8bc4\u6d4b\u663e\u793aAI4UI\u5728\u5e73\u53f0\u517c\u5bb9\u6027\u3001\u5b89\u5168\u5408\u89c4\u53ca\u529f\u80fd\u5b9e\u73b0\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u7528\u6237\u8bc4\u4ef7\u4e5f\u5c45\u4e8e\u9886\u5148\u6c34\u5e73\uff0c\u663e\u8457\u7f29\u77ed\u4e86\u4ea4\u4ed8\u5468\u671f\u3002", "conclusion": "AI4UI\u6210\u529f\u5b9e\u73b0\u4e86\u4f01\u4e1a\u7ea7\u524d\u7aef\u5f00\u53d1\u81ea\u52a8\u5316\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bbe\u8ba1\u8f93\u5165\u3001\u4eba\u673a\u534f\u540c\u4f18\u5316\u548c\u5b89\u5168\u5408\u89c4\u4fdd\u969c\uff0c\u63d0\u9ad8\u4e86\u4ee3\u7801\u8d28\u91cf\u53ca\u4ea4\u4ed8\u6548\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u4e1a\u754c\u4e3b\u6d41\u65b9\u6848\u3002"}}
{"id": "2512.06060", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06060", "abs": "https://arxiv.org/abs/2512.06060", "authors": ["Mohanakrishnan Hariharan"], "title": "Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring", "comment": null, "summary": "This paper introduces a framework that integrates reinforcement learning (RL) with autonomous agents to enable continuous improvement in the automated process of software test cases authoring from business requirement documents within Quality Engineering (QE) workflows. Conventional systems employing Large Language Models (LLMs) generate test cases from static knowledge bases, which fundamentally limits their capacity to enhance performance over time. Our proposed Reinforcement Infused Agentic RAG (Retrieve, Augment, Generate) framework overcomes this limitation by employing AI agents that learn from QE feedback, assessments, and defect discovery outcomes to automatically improve their test case generation strategies. The system combines specialized agents with a hybrid vector-graph knowledge base that stores and retrieves software testing knowledge. Through advanced RL algorithms, specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), these agents optimize their behavior based on QE-reported test effectiveness, defect detection rates, and workflow metrics. As QEs execute AI-generated test cases and provide feedback, the system learns from this expert guidance to improve future iterations. Experimental validation on enterprise Apple projects yielded substantive improvements: a 2.4% increase in test generation accuracy (from 94.8% to 97.2%), and a 10.8% improvement in defect detection rates. The framework establishes a continuous knowledge refinement loop driven by QE expertise, resulting in progressively superior test case quality that enhances, rather than replaces, human testing capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684AI\u667a\u80fd\u4f53\uff0c\u7ed3\u5408\u6df7\u5408\u77e5\u8bc6\u5e93\uff0c\u6301\u7eed\u4f18\u5316\u8f6f\u4ef6\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u51c6\u786e\u7387\u548c\u7f3a\u9677\u68c0\u6d4b\u7387\uff0c\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u7684\u8d28\u91cf\u5de5\u7a0b\u81ea\u52a8\u5316\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9759\u6001\u77e5\u8bc6\u5e93\u7684LLMs\u7cfb\u7edf\u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u80fd\u529b\u4e0a\u7f3a\u4e4f\u6301\u7eed\u81ea\u6211\u6539\u8fdb\uff0c\u672c\u6587\u65e8\u5728\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u9a71\u52a8\u7684\u667a\u80fd\u4f53\uff0c\u901a\u8fc7QE\u4e13\u5bb6\u53cd\u9988\u5b9e\u73b0\u6d41\u7a0b\u7684\u52a8\u6001\u4f18\u5316\u4e0e\u77e5\u8bc6\u6301\u7eed\u66f4\u65b0\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u6ce8\u5165\u667a\u80fdRAG\u6846\u67b6\uff0c\u7ed3\u5408\u4e13\u7528\u667a\u80fd\u4f53\u548c\u6df7\u5408\u5411\u91cf-\u56fe\u77e5\u8bc6\u5e93\uff0c\u4f7f\u7528PPO\u548cDQN\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u6839\u636eQE\u53cd\u9988\u548c\u7f3a\u9677\u68c0\u6d4b\u7ed3\u679c\u4e0d\u65ad\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7b56\u7565\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c06\u5f3a\u5316\u5b66\u4e60\u4e0e\u81ea\u4e3b\u667a\u80fd\u4f53\u76f8\u7ed3\u5408\u7684\u6846\u67b6\uff0c\u65e8\u5728\u5b9e\u73b0\u8f6f\u4ef6\u6d4b\u8bd5\u7528\u4f8b\u81ea\u52a8\u751f\u6210\u8fc7\u7a0b\u7684\u6301\u7eed\u6539\u8fdb\uff0c\u5728\u8d28\u91cf\u5de5\u7a0b(QE)\u6d41\u7a0b\u4e2d\u4ece\u4e1a\u52a1\u9700\u6c42\u6587\u6863\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002\u4e0d\u540c\u4e8e\u4f20\u7edf\u57fa\u4e8e\u9759\u6001\u77e5\u8bc6\u5e93\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u7cfb\u7edf\uff0c\u8be5\u6846\u67b6\u91c7\u7528\u5f3a\u5316\u6ce8\u5165\u7684\u667a\u80fdRAG\uff08\u68c0\u7d22\u3001\u589e\u5f3a\u3001\u751f\u6210\uff09\u65b9\u6cd5\uff0c\u5229\u7528AI\u667a\u80fd\u4f53\u4eceQE\u53cd\u9988\u3001\u8bc4\u4f30\u548c\u7f3a\u9677\u53d1\u73b0\u7ed3\u679c\u4e2d\u5b66\u4e60\uff0c\u4e0d\u65ad\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7b56\u7565\u3002\u7cfb\u7edf\u7ed3\u5408\u4e13\u7528\u667a\u80fd\u4f53\u548c\u6df7\u5408\u5411\u91cf-\u56fe\u77e5\u8bc6\u5e93\uff0c\u901a\u8fc7\u5148\u8fdb\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff08PPO\u548cDQN\uff09\u57fa\u4e8e\u6d4b\u8bd5\u6709\u6548\u6027\u3001\u7f3a\u9677\u68c0\u6d4b\u7387\u548c\u5de5\u4f5c\u6d41\u6307\u6807\u4f18\u5316\u667a\u80fd\u4f53\u884c\u4e3a\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u82f9\u679c\u4f01\u4e1a\u9879\u76ee\u4e2d\u6d4b\u8bd5\u751f\u6210\u51c6\u786e\u7387\u63d0\u5347\u4e862.4%\uff08\u753194.8%\u63d0\u5347\u81f397.2%\uff09\uff0c\u7f3a\u9677\u68c0\u6d4b\u7387\u63d0\u9ad8\u4e8610.8%\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u7531QE\u4e13\u4e1a\u77e5\u8bc6\u9a71\u52a8\u7684\u6301\u7eed\u77e5\u8bc6\u5b8c\u5584\u5faa\u73af\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u7528\u4f8b\u8d28\u91cf\uff0c\u540c\u65f6\u589e\u5f3a\u800c\u975e\u66ff\u4ee3\u4e86\u4eba\u5de5\u6d4b\u8bd5\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u548c\u4e13\u5bb6\u53cd\u9988\uff0c\u5b9e\u73b0\u4e86\u6d4b\u8bd5\u7528\u4f8b\u81ea\u52a8\u751f\u6210\u7684\u6301\u7eed\u6539\u8fdb\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u51c6\u786e\u6027\u548c\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u4eba\u5de5\u8d28\u91cf\u5de5\u7a0b\u7684\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2512.06123", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.06123", "abs": "https://arxiv.org/abs/2512.06123", "authors": ["Qilin Zhou", "Zhengyuan Wei", "Haipeng Wang", "Zhuo Wang", "W. K. Chan"], "title": "Toward Patch Robustness Certification and Detection for Deep Learning Systems Beyond Consistent Samples", "comment": "accepted by IEEE Transactions on Reliability; extended technical report", "summary": "Patch robustness certification is an emerging kind of provable defense technique against adversarial patch attacks for deep learning systems. Certified detection ensures the detection of all patched harmful versions of certified samples, which mitigates the failures of empirical defense techniques that could (easily) be compromised. However, existing certified detection methods are ineffective in certifying samples that are misclassified or whose mutants are inconsistently pre icted to different labels. This paper proposes HiCert, a novel masking-based certified detection technique. By focusing on the problem of mutants predicted with a label different from the true label with our formal analysis, HiCert formulates a novel formal relation between harmful samples generated by identified loopholes and their benign counterparts. By checking the bound of the maximum confidence among these potentially harmful (i.e., inconsistent) mutants of each benign sample, HiCert ensures that each harmful sample either has the minimum confidence among mutants that are predicted the same as the harmful sample itself below this bound, or has at least one mutant predicted with a label different from the harmful sample itself, formulated after two novel insights. As such, HiCert systematically certifies those inconsistent samples and consistent samples to a large extent. To our knowledge, HiCert is the first work capable of providing such a comprehensive patch robustness certification for certified detection. Our experiments show the high effectiveness of HiCert with a new state-of the-art performance: It certifies significantly more benign samples, including those inconsistent and consistent, and achieves significantly higher accuracy on those samples without warnings and a significantly lower false silent ratio.", "AI": {"tldr": "HiCert\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u63a9\u7801\u8ba4\u8bc1\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8865\u4e01\u653b\u51fb\u7684\u9c81\u68d2\u6027\u8ba4\u8bc1\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u8ba4\u8bc1\u8bef\u5206\u7c7b\u6216\u9884\u6d4b\u4e0d\u4e00\u81f4\u7684\u6837\u672c\uff0c\u5bfc\u81f4\u9632\u5fa1\u673a\u5236\u6613\u88ab\u7ed5\u8fc7\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u66f4\u5168\u9762\u7684\u8ba4\u8bc1\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u63a9\u7801\u7684\u5f62\u5f0f\u5316\u5206\u6790\uff0c\u5efa\u7acb\u6709\u5bb3\u6837\u672c\u4e0e\u826f\u6027\u6837\u672c\u7684\u7f6e\u4fe1\u5ea6\u8fb9\u754c\u5173\u7cfb\uff0c\u901a\u8fc7\u68c0\u6d4b\u4e0d\u540c\u9884\u6d4b\u6807\u7b7e\u7684\u53d8\u4f53\u4fdd\u8bc1\u6837\u672c\u5b89\u5168\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86HiCert\uff0c\u4e00\u79cd\u57fa\u4e8e\u63a9\u7801\u7684\u8865\u4e01\u9c81\u68d2\u6027\u8ba4\u8bc1\u68c0\u6d4b\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u8ba4\u8bc1\u8bef\u5206\u7c7b\u6216\u9884\u6d4b\u4e0d\u4e00\u81f4\u6837\u672c\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f62\u5f0f\u5316\u5206\u6790\uff0cHiCert\u5efa\u7acb\u4e86\u6709\u5bb3\u6837\u672c\u4e0e\u5176\u826f\u6027\u6837\u672c\u4e4b\u95f4\u7684\u65b0\u5173\u7cfb\uff0c\u901a\u8fc7\u68c0\u6d4b\u6709\u5bb3\u53d8\u4f53\u7684\u6700\u5927\u7f6e\u4fe1\u5ea6\u8fb9\u754c\uff0c\u7cfb\u7edf\u6027\u5730\u8ba4\u8bc1\u4e86\u4e00\u81f4\u548c\u4e0d\u4e00\u81f4\u6837\u672c\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cHiCert\u5728\u8ba4\u8bc1\u66f4\u591a\u826f\u6027\u6837\u672c\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002", "conclusion": "HiCert\u5b9e\u73b0\u4e86\u66f4\u5168\u9762\u6709\u6548\u7684\u8865\u4e01\u9c81\u68d2\u6027\u8ba4\u8bc1\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u8ba4\u8bc1\u68c0\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2512.06097", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06097", "abs": "https://arxiv.org/abs/2512.06097", "authors": ["Emre Umucu", "Guillermina Solis", "Leon Garza", "Emilia Rivas", "Beatrice Lee", "Anantaa Kotal", "Aritran Piplai"], "title": "Empathy by Design: Aligning Large Language Models for Healthcare Dialogue", "comment": null, "summary": "General-purpose large language models (LLMs) have demonstrated remarkable generative and reasoning capabilities but remain limited in healthcare and caregiving applications due to two key deficiencies: factual unreliability and a lack of empathetic communication. These shortcomings pose significant risks in sensitive contexts where users, particularly non-professionals and caregivers, seek medically relevant guidance or emotional reassurance. To address these challenges, we introduce a Direct Preference Optimization (DPO)-based alignment framework designed to improve factual correctness, semantic coherence, and human-centric qualities such as empathy, politeness, and simplicity in caregiver-patient dialogues. Our approach fine-tunes domain-adapted LLMs using pairwise preference data, where preferred responses reflect supportive and accessible communication styles while rejected ones represent prescriptive or overly technical tones. This direct optimization method aligns model outputs with human preferences more efficiently than traditional reinforcement-learning-based alignment. Empirical evaluations across multiple open and proprietary LLMs show that our DPO-tuned models achieve higher semantic alignment, improved factual accuracy, and stronger human-centric evaluation scores compared to baseline and commercial alternatives such as Google medical dialogue systems. These improvements demonstrate that preference-based alignment offers a scalable and transparent pathway toward developing trustworthy, empathetic, and clinically informed AI assistants for caregiver and healthcare communication. Our open-source code is available at: https://github.com/LeonG19/Empathy-by-Design", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u5bf9\u9f50\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u62a4\u7406\u5bf9\u8bdd\u4e2d\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u540c\u7406\u5fc3\u8868\u73b0\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u73b0\u6709\u5546\u4e1a\u7cfb\u7edf\uff0c\u63a8\u52a8\u53ef\u4fe1\u548c\u4eba\u6027\u5316\u533b\u7597AI\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u548c\u62a4\u7406\u9886\u57df\u5b58\u5728\u4e8b\u5b9e\u4e0d\u53ef\u9760\u548c\u7f3a\u4e4f\u540c\u7406\u5fc3\u4ea4\u6d41\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\uff0c\u5c24\u5176\u662f\u5728\u975e\u4e13\u4e1a\u7528\u6237\u548c\u62a4\u7406\u4eba\u5458\u5bfb\u6c42\u533b\u7597\u6307\u5bfc\u548c\u60c5\u611f\u652f\u6301\u65f6\u5b58\u5728\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u76f4\u63a5\u504f\u597d\u4f18\u5316(DPO)\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u6210\u5bf9\u504f\u597d\u6570\u636e\u5bf9\u9886\u57df\u9002\u5e94\u7684LLM\u8fdb\u884c\u5fae\u8c03\uff0c\u4f7f\u6a21\u578b\u8f93\u51fa\u66f4\u7b26\u5408\u4eba\u7c7b\u504f\u597d\uff0c\u5f3a\u8c03\u652f\u6301\u6027\u3001\u6613\u61c2\u548c\u6709\u540c\u7406\u5fc3\u7684\u6c9f\u901a\u98ce\u683c\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u5f3a\u5316\u5b66\u4e60\u5bf9\u9f50\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u516c\u5f00\u53ca\u4e13\u6709\u6a21\u578b\u7684\u8bc4\u6d4b\uff0cDPO\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u8bed\u4e49\u5bf9\u9f50\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u4ee5\u4eba\u4e3a\u672c\u7684\u8bc4\u4ef7\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u53ca\u5546\u4e1a\u7cfb\u7edf\uff08\u5982\u8c37\u6b4c\u533b\u7597\u5bf9\u8bdd\u7cfb\u7edf\uff09\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u548c\u540c\u7406\u5fc3\u8868\u73b0\u3002", "conclusion": "\u57fa\u4e8e\u504f\u597d\u7684\u5bf9\u9f50\u65b9\u6cd5\u4e3a\u5f00\u53d1\u53ef\u4fe1\u8d56\u3001\u5177\u540c\u7406\u5fc3\u4e14\u4e34\u5e8a\u4fe1\u606f\u4e30\u5bcc\u7684\u62a4\u7406\u548c\u533b\u7597AI\u52a9\u624b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u900f\u660e\u7684\u8def\u5f84\uff0c\u6709\u671b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2512.05983", "categories": ["cs.MA", "cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2512.05983", "abs": "https://arxiv.org/abs/2512.05983", "authors": ["Eyal Briman", "Ehud Shapiro", "Nimrod Talmon"], "title": "AI-Generated Compromises for Coalition Formation: Modeling, Simulation, and a Textual Case Study", "comment": "In Proceedings TARK 2025, arXiv:2511.20540. arXiv admin note: substantial text overlap with arXiv:2506.06837", "summary": "The challenge of finding compromises between agent proposals is fundamental to AI sub-fields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. The crucial step in this iterative process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals, however, remains an open question. We address this gap by formalizing a holistic model that encompasses agent bounded rationality and uncertainty and developing AI models to generate such compromise proposals. We focus on the domain of collaboratively writing text documents -- e.g., to enable the democratic creation of a community constitution. We apply NLP (Natural Language Processing) techniques and utilize LLMs (Large Language Models) to create a semantic metric space for text and develop algorithms to suggest suitable compromise points. To evaluate the effectiveness of our algorithms, we simulate various coalition formation processes and demonstrate the potential of AI to facilitate large-scale democratic text editing, such as collaboratively drafting a constitution, an area where traditional tools are limited.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528NLP\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6587\u672c\u534f\u4f5c\u5199\u4f5c\u4e2d\u751f\u6210\u667a\u80fd\u4f53\u95f4\u7684\u59a5\u534f\u63d0\u6848\uff0c\u4fc3\u8fdb\u5927\u89c4\u6a21\u6c11\u4e3b\u6587\u672c\u7f16\u8f91\uff0c\u5f25\u8865\u4f20\u7edf\u5de5\u5177\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u5728\u591a\u667a\u80fd\u4f53\u63d0\u6848\u95f4\u5bfb\u627e\u59a5\u534f\u65b9\u6848\u7684\u8fc7\u7a0b\u4e2d\uff0c\u5982\u4f55\u9ad8\u6548\u627e\u5230\u59a5\u534f\u63d0\u6848\u4ecd\u662f\u672a\u89e3\u96be\u9898\uff0c\u5c24\u5176\u5728\u6587\u672c\u534f\u4f5c\u5199\u4f5c\u9886\u57df\u8868\u73b0\u51fa\u4f20\u7edf\u5de5\u5177\u7684\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528NLP\u6280\u672f\u548c\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u6587\u672c\u7684\u8bed\u4e49\u5ea6\u91cf\u7a7a\u95f4\uff0c\u8bbe\u8ba1\u7b97\u6cd5\u751f\u6210\u9002\u5408\u7684\u59a5\u534f\u70b9\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u4e0d\u540c\u7684\u8054\u76df\u5f62\u6210\u8fc7\u7a0b\u9a8c\u8bc1\u7b97\u6cd5\u6548\u679c\u3002", "result": "\u5f00\u53d1\u7684\u7b97\u6cd5\u80fd\u6709\u6548\u751f\u6210\u88ab\u591a\u6570\u667a\u80fd\u4f53\u652f\u6301\u7684\u59a5\u534f\u6587\u672c\u63d0\u6848\uff0c\u4fc3\u8fdb\u4e86\u5927\u89c4\u6a21\u6c11\u4e3b\u534f\u4f5c\u6587\u672c\u7f16\u8f91\uff0c\u663e\u793a\u51faAI\u5728\u8be5\u9886\u57df\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u667a\u80fd\u4f53\u6709\u9650\u7406\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u7684\u6574\u4f53\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86AI\u6a21\u578b\u4ee5\u751f\u6210\u59a5\u534f\u63d0\u6848\uff0c\u5728\u6587\u672c\u534f\u4f5c\u5199\u4f5c\u9886\u57df\u5c55\u793a\u4e86\u6709\u6548\u6027\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6c11\u4e3b\u6587\u672c\u7f16\u8f91\u5982\u793e\u533a\u5baa\u6cd5\u7684\u534f\u4f5c\u8d77\u8349\u3002"}}
{"id": "2512.06178", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06178", "abs": "https://arxiv.org/abs/2512.06178", "authors": ["Georgiana Haldeman", "Peter Ohmann", "Paul Denny"], "title": "Systematically Thinking about the Complexity of Code Structuring Exercises at Introductory Level", "comment": null, "summary": "Decomposition and abstraction is an essential component of computational thinking, yet it is not always emphasized in introductory programming courses. In addition, as generative AI further reduces the focus on syntax and increases the importance of higher-level code reasoning, there is renewed opportunity to teach DA explicitly. In this paper, we introduce a framework for systematically assessing the complexity of code structuring tasks, where students must identify and separate meaningful abstractions within existing, unstructured code. The framework defines three dimensions of task complexity, each with multiple levels: repetition, code pattern, and data dependency. To support practical use, we provide example tasks mapped to these levels and offer an interactive tool for generating and exploring DA problems. The framework is designed to support the development of educational tasks that build students' skills with DA in the procedural paradigm.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u4ee3\u7801\u7ed3\u6784\u4efb\u52a1\u7684\u590d\u6742\u5ea6\uff0c\u5e2e\u52a9\u5b66\u751f\u8bc6\u522b\u548c\u5206\u79bb\u4ee3\u7801\u4e2d\u7684\u6709\u610f\u4e49\u62bd\u8c61\uff0c\u4ece\u800c\u57f9\u517b\u8ba1\u7b97\u601d\u7ef4\u4e2d\u7684\u5206\u89e3\u4e0e\u62bd\u8c61\u80fd\u529b\u3002", "motivation": "\u5206\u89e3\u4e0e\u62bd\u8c61\u4f5c\u4e3a\u8ba1\u7b97\u601d\u7ef4\u7684\u6838\u5fc3\uff0c\u5728\u521d\u7ea7\u7f16\u7a0b\u6559\u80b2\u4e2d\u5e38\u88ab\u5ffd\u89c6\u3002\u968f\u7740\u751f\u6210\u5f0fAI\u51cf\u5c11\u4e86\u5bf9\u8bed\u6cd5\u7684\u4f9d\u8d56\uff0c\u63d0\u5347\u4e86\u4ee3\u7801\u9ad8\u7ea7\u63a8\u7406\u7684\u91cd\u8981\u6027\uff0c\u91cd\u65b0\u5f3a\u8c03DA\u6559\u5b66\u7684\u5fc5\u8981\u6027\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u4e09\u4e2a\u7ef4\u5ea6\uff08\u91cd\u590d\u6027\u3001\u4ee3\u7801\u6a21\u5f0f\u3001\u6570\u636e\u4f9d\u8d56\uff09\u53ca\u5176\u591a\u4e2a\u7b49\u7ea7\uff0c\u8bbe\u8ba1\u793a\u4f8b\u4efb\u52a1\u5e76\u5f00\u53d1\u4ea4\u4e92\u5f0f\u5de5\u5177\u7528\u4e8e\u751f\u6210\u548c\u63a2\u7d22DA\u95ee\u9898\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8be6\u7ec6\u7684\u590d\u6742\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u914d\u5957\u793a\u4f8b\u548c\u5de5\u5177\uff0c\u652f\u6301\u6559\u5b66\u4e2d\u6709\u9488\u5bf9\u6027\u5730\u57f9\u517b\u5b66\u751f\u7684\u5206\u89e3\u4e0e\u62bd\u8c61\u6280\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5730\u652f\u6301\u4e86\u6559\u80b2\u4efb\u52a1\u7684\u5f00\u53d1\uff0c\u4fc3\u8fdb\u5b66\u751f\u5728\u8fc7\u7a0b\u5f0f\u7f16\u7a0b\u8303\u5f0f\u4e0b\u5bf9\u5206\u89e3\u548c\u62bd\u8c61\u6280\u80fd\u7684\u638c\u63e1\u3002"}}
{"id": "2512.06169", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06169", "abs": "https://arxiv.org/abs/2512.06169", "authors": ["Chris Crawford"], "title": "Morphologically-Informed Tokenizers for Languages with Non-Concatenative Morphology: A case study of Yolox\u00f3chtil Mixtec ASR", "comment": "67 pages, 5 figures, 6 tables", "summary": "This paper investigates the impact of using morphologically-informed tokenizers to aid and streamline the interlinear gloss annotation of an audio corpus of Yolox\u00f3chitl Mixtec (YM) using a combination of ASR and text-based sequence-to-sequence tools, with the goal of improving efficiency while reducing the workload of a human annotator. We present two novel tokenization schemes that separate words in a nonlinear manner, preserving information about tonal morphology as much as possible. One of these approaches, a Segment and Melody tokenizer, simply extracts the tones without predicting segmentation. The other, a Sequence of Processes tokenizer, predicts segmentation for the words, which could allow an end-to-end ASR system to produce segmented and unsegmented transcriptions in a single pass. We find that these novel tokenizers are competitive with BPE and Unigram models, and the Segment-and-Melody model outperforms traditional tokenizers in terms of word error rate but does not reach the same character error rate. In addition, we analyze tokenizers on morphological and information-theoretic metrics to find predictive correlations with downstream performance. Our results suggest that nonlinear tokenizers designed specifically for the non-concatenative morphology of a language are competitive with conventional BPE and Unigram models for ASR. Further research will be necessary to determine the applicability of these tokenizers in downstream processing tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u7ed3\u5408\u5f62\u6001\u4fe1\u606f\u7684\u975e\u7ebf\u6027\u5206\u8bcd\u65b9\u6cd5\uff0c\u5728Yolox\u00f3chitl Mixtec\u8bed\u8a00\u7684\u8bed\u97f3\u6ce8\u91ca\u4efb\u52a1\u4e2d\u8868\u73b0\u7ade\u4e89\u529b\uff0c\u63d0\u5347\u4e86\u6807\u6ce8\u6548\u7387\u5e76\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\u3002", "motivation": "\u63d0\u9ad8Yolox\u00f3chitl Mixtec\u8bed\u97f3\u8bed\u6599\u5e93\u7684\u9010\u8bcd\u6ce8\u91ca\u6548\u7387\uff0c\u51cf\u8f7b\u4eba\u5de5\u6807\u6ce8\u8d1f\u62c5\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u65b0\u9896\u7684\u5f62\u6001\u4fe1\u606f\u5206\u8bcd\u65b9\u6848\uff0c\u7ed3\u5408ASR\u548c\u6587\u672c\u5e8f\u5217\u5230\u5e8f\u5217\u5de5\u5177\uff0c\u5206\u522b\u4e3aSegment and Melody\u5206\u8bcd\u5668\u548cSequence of Processes\u5206\u8bcd\u5668\u3002", "result": "\u65b0\u5206\u8bcd\u5668\u5728\u8bcd\u9519\u8bef\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u5206\u8bcd\u5668\uff0c\u4f46\u5b57\u7b26\u9519\u8bef\u7387\u900a\u8272\uff1b\u4e0eBPE\u548cUnigram\u6a21\u578b\u8868\u73b0\u76f8\u5f53\u3002\u5b9e\u73b0\u4e86\u5f62\u6001\u5b66\u548c\u4fe1\u606f\u7406\u8bba\u6307\u6807\u4e0e\u6027\u80fd\u7684\u76f8\u5173\u6027\u5206\u6790\u3002", "conclusion": "\u9488\u5bf9\u975e\u62fc\u63a5\u5f62\u6001\u7684\u8bed\u8a00\u8bbe\u8ba1\u7684\u975e\u7ebf\u6027\u5206\u8bcd\u5668\uff0c\u5728ASR\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0e\u4f20\u7edf\u5206\u8bcd\u5668\u7ade\u4e89\u529b\u5f3a\uff0c\u672a\u6765\u9700\u8bc4\u4f30\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2512.06432", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.06432", "abs": "https://arxiv.org/abs/2512.06432", "authors": ["Yihan Xia", "Taotao Wang", "Shengli Zhang", "Zhangyuhua Weng", "Bin Cao", "Soung Chang Liew"], "title": "HiveMind: Contribution-Guided Online Prompt Optimization of LLM Multi-Agent Systems", "comment": "This paper was accepted to AAAI2026", "summary": "Recent advances in LLM-based multi-agent systems have demonstrated remarkable capabilities in complex decision-making scenarios such as financial trading and software engineering. However, evaluating each individual agent's effectiveness and online optimization of underperforming agents remain open challenges. To address these issues, we present HiveMind, a self-adaptive framework designed to optimize LLM multi-agent collaboration through contribution analysis. At its core, HiveMind introduces Contribution-Guided Online Prompt Optimization (CG-OPO), which autonomously refines agent prompts based on their quantified contributions. We first propose the Shapley value as a grounded metric to quantify each agent's contribution, thereby identifying underperforming agents in a principled manner for automated prompt refinement. To overcome the computational complexity of the classical Shapley value, we present DAG-Shapley, a novel and efficient attribution algorithm that leverages the inherent Directed Acyclic Graph structure of the agent workflow to axiomatically prune non-viable coalitions. By hierarchically reusing intermediate outputs of agents in the DAG, our method further reduces redundant computations, and achieving substantial cost savings without compromising the theoretical guarantees of Shapley values. Evaluated in a multi-agent stock-trading scenario, HiveMind achieves superior performance compared to static baselines. Notably, DAG-Shapley reduces LLM calls by over 80\\% while maintaining attribution accuracy comparable to full Shapley values, establishing a new standard for efficient credit assignment and enabling scalable, real-world optimization of multi-agent collaboration.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHiveMind\u6846\u67b6\uff0c\u5229\u7528Shapley\u503c\u548cDAG-Shapley\u7b97\u6cd5\u5b9e\u73b0\u9ad8\u6548\u8d21\u732e\u5206\u6790\u4e0e\u5728\u7ebf\u4f18\u5316\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u5728\u80a1\u7968\u4ea4\u6613\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u8ba1\u7b97\u4f18\u52bf\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4e2a\u4f53\u4ee3\u7406\u7684\u6548\u679c\u8bc4\u4f30\u56f0\u96be\uff0c\u53ca\u4f4e\u6548\u4ee3\u7406\u7684\u5373\u65f6\u4f18\u5316\u4e00\u76f4\u662f\u5f00\u653e\u6311\u6218\uff0c\u4e9f\u9700\u9ad8\u6548\u51c6\u786e\u7684\u8d21\u732e\u5206\u6790\u65b9\u6cd5\u4ee5\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5c06Shapley\u503c\u4f5c\u4e3a\u8d21\u732e\u5ea6\u91cf\u6807\u51c6\uff0c\u5f15\u5165DAG-Shapley\u7b97\u6cd5\u5229\u7528\u6709\u5411\u65e0\u73af\u56fe\u7ed3\u6784\u526a\u679d\u975e\u6709\u6548\u8054\u76df\u5e76\u91cd\u7528\u4e2d\u95f4\u7ed3\u679c\uff0c\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u8d21\u732e\u5206\u914d\u3002", "result": "\u5728\u80a1\u7968\u4ea4\u6613\u591a\u667a\u80fd\u4f53\u573a\u666f\u4e2d\uff0cHiveMind\u663e\u8457\u4f18\u4e8e\u9759\u6001\u57fa\u7ebf\uff0cDAG-Shapley\u51cf\u5c11\u4e8680%\u4ee5\u4e0a\u7684LLM\u8c03\u7528\u6b21\u6570\uff0c\u540c\u65f6\u8d21\u732e\u5f52\u56e0\u51c6\u786e\u5ea6\u63a5\u8fd1\u5b8c\u6574Shapley\u503c\u3002", "conclusion": "HiveMind\u6846\u67b6\u901a\u8fc7\u5f15\u5165Contribution-Guided Online Prompt Optimization (CG-OPO)\u548c\u9ad8\u6548\u7684DAG-Shapley\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4e2a\u4f53\u8d21\u732e\u7684\u7cbe\u786e\u8bc4\u4f30\u4e0e\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u7684\u6027\u80fd\u3002"}}
{"id": "2512.06247", "categories": ["cs.SE", "cs.AI", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.06247", "abs": "https://arxiv.org/abs/2512.06247", "authors": ["Gus Henry Smith", "Sandesh Adhikary", "Vineet Thumuluri", "Karthik Suresh", "Vivek Pandit", "Kartik Hegde", "Hamid Shojaei", "Chandra Bhagavatula"], "title": "DUET: Agentic Design Understanding via Experimentation and Testing", "comment": null, "summary": "AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation.", "AI": {"tldr": "\u9488\u5bf9LLM\u96be\u4ee5\u7406\u89e3\u590d\u6742RTL\u4ee3\u7801\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u5b9e\u9a8c\u548c\u6d4b\u8bd5\u8fed\u4ee3\u6784\u5efa\u8bbe\u8ba1\u7406\u89e3\u7684DUET\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u786c\u4ef6\u8bbe\u8ba1AI\u4ee3\u7406\u7684\u9a8c\u8bc1\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684AI\u4ee3\u7406\u80fd\u5904\u7406\u590d\u6742\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\uff0c\u4f46\u96be\u4ee5\u7406\u89e3\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u5bc4\u5b58\u5668\u4f20\u8f93\u7ea7\uff08RTL\uff09\u4ee3\u7801\uff0c\u56e0\u4e3aRTL\u4ee3\u7801\u5305\u542b\u590d\u6742\u3001\u52a8\u6001\u3001\u65f6\u95f4\u6f14\u5316\u7684\u884c\u4e3a\uff0c\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u4ec5\u51ed\u8bed\u6cd5\u63a8\u65ad\u8fd9\u4e9b\u884c\u4e3a\uff0c\u9650\u5236\u4e86\u5176\u5728\u4ee3\u7801\u8865\u5168\u3001\u6587\u6863\u7f16\u5199\u548c\u9a8c\u8bc1\u7b49\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86DUET\u65b9\u6cd5\u5b66\uff0c\u901a\u8fc7\u8fed\u4ee3\u751f\u6210\u5047\u8bbe\u5e76\u5229\u7528EDA\u5de5\u5177\uff08\u4eff\u771f\u3001\u6ce2\u5f62\u68c0\u67e5\u3001\u5f62\u5f0f\u9a8c\u8bc1\uff09\u8fdb\u884c\u5b9e\u9a8c\u6d4b\u8bd5\uff0c\u4ece\u5e95\u5411\u4e0a\u6784\u5efa\u8bbe\u8ba1\u7406\u89e3\u3002", "result": "DUET\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86AI\u4ee3\u7406\u5728\u5f62\u5f0f\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u76f8\u6bd4\u4e0d\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u7684\u57fa\u7ebf\u6d41\u7a0b\u6548\u679c\u66f4\u4f18\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u8fed\u4ee3\u5047\u8bbe\u751f\u6210\u4e0eEDA\u5de5\u5177\u7684\u5b9e\u9a8c\u6d4b\u8bd5\uff0cDUET\u6709\u6548\u589e\u5f3a\u4e86AI\u4ee3\u7406\u5bf9\u786c\u4ef6\u8bbe\u8ba1\u7684\u7406\u89e3\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u76f8\u5173\u4e0b\u6e38\u4efb\u52a1\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u5f62\u5f0f\u9a8c\u8bc1\u65b9\u9762\u3002"}}
{"id": "2512.06193", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06193", "abs": "https://arxiv.org/abs/2512.06193", "authors": ["Jihyung Park", "Saleh Afroogh", "Junfeng Jiao"], "title": "Do You Feel Comfortable? Detecting Hidden Conversational Escalation in AI Chatbots", "comment": null, "summary": "Large Language Models (LLM) are increasingly integrated into everyday interactions, serving not only as information assistants but also as emotional companions. Even in the absence of explicit toxicity, repeated emotional reinforcement or affective drift can gradually escalate distress in a form of \\textit{implicit harm} that traditional toxicity filters fail to detect. Existing guardrail mechanisms often rely on external classifiers or clinical rubrics that may lag behind the nuanced, real-time dynamics of a developing conversation. To address this gap, we propose GAUGE (Guarding Affective Utterance Generation Escalation), a lightweight, logit-based framework for the real-time detection of hidden conversational escalation. GAUGE measures how an LLM's output probabilistically shifts the affective state of a dialogue.", "AI": {"tldr": "\u63d0\u51faGAUGE\u6846\u67b6\uff0c\u5b9e\u65f6\u76d1\u6d4b\u5bf9\u8bdd\u60c5\u611f\u53d8\u5316\uff0c\u9632\u8303\u9690\u6027\u60c5\u611f\u4f24\u5bb3\u3002", "motivation": "\u73b0\u6709\u6bd2\u6027\u8fc7\u6ee4\u591a\u4f9d\u8d56\u5916\u90e8\u5206\u7c7b\u5668\uff0c\u96be\u4ee5\u6355\u6349\u5bf9\u8bdd\u4e2d\u7ec6\u5fae\u4e14\u5b9e\u65f6\u53d1\u5c55\u7684\u60c5\u611f\u6076\u5316\uff0c\u5b58\u5728\u9690\u6027\u4f24\u5bb3\u98ce\u9669\u3002", "method": "\u57fa\u4e8elogit\u7684\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u5b9e\u65f6\u5206\u6790LLM\u8f93\u51fa\u5bf9\u5bf9\u8bdd\u60c5\u611f\u72b6\u6001\u7684\u6982\u7387\u6027\u8f6c\u53d8\uff0c\u68c0\u6d4b\u9690\u6027\u60c5\u611f\u5347\u7ea7\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86GAUGE\u6846\u67b6\uff0c\u901a\u8fc7\u5b9e\u65f6\u68c0\u6d4b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u5bf9\u5bf9\u8bdd\u60c5\u611f\u72b6\u6001\u7684\u6982\u7387\u6027\u5f71\u54cd\uff0c\u8bc6\u522b\u9690\u6027\u60c5\u611f\u5347\u9ad8\uff0c\u9632\u6b62\u4f20\u7edf\u6bd2\u6027\u68c0\u6d4b\u6f0f\u5224\u7684\u201c\u9690\u6027\u4f24\u5bb3\u201d\u3002", "conclusion": "GAUGE\u6709\u6548\u8bc6\u522b\u51fa\u4f20\u7edf\u6bd2\u6027\u68c0\u6d4b\u96be\u4ee5\u6355\u6349\u7684\u60c5\u611f\u9010\u6e10\u6076\u5316\u98ce\u9669\uff0c\u586b\u8865\u4e86\u73b0\u6709\u62a4\u680f\u673a\u5236\u7684\u4e0d\u8db3\u3002"}}
{"id": "2512.06595", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06595", "abs": "https://arxiv.org/abs/2512.06595", "authors": ["Joe Shymanski"], "title": "ChargingBoul: A Competitive Negotiating Agent with Novel Opponent Modeling", "comment": "10 pages, 3 figures. Describes the ChargingBoul negotiating agent submitted to ANAC 2022. Preprint", "summary": "Automated negotiation has emerged as a critical area of research in multiagent systems, with applications spanning e-commerce, resource allocation, and autonomous decision-making. This paper presents ChargingBoul, a negotiating agent that competed in the 2022 Automated Negotiating Agents Competition (ANAC) and placed second in individual utility by an exceptionally narrow margin. ChargingBoul employs a lightweight yet effective strategy that balances concession and opponent modeling to achieve high negotiation outcomes. The agent classifies opponents based on bid patterns, dynamically adjusts its bidding strategy, and applies a concession policy in later negotiation stages to maximize utility while fostering agreements. We evaluate ChargingBoul's performance using competition results and subsequent studies that have utilized the agent in negotiation research. Our analysis highlights ChargingBoul's effectiveness across diverse opponent strategies and its contributions to advancing automated negotiation techniques. We also discuss potential enhancements, including more sophisticated opponent modeling and adaptive bidding heuristics, to improve its performance further.", "AI": {"tldr": "ChargingBoul\u4ee3\u7406\u901a\u8fc7\u5bf9\u5bf9\u624b\u5efa\u6a21\u4e0e\u52a8\u6001\u51fa\u4ef7\u7b56\u7565\u5b9e\u73b0\u9ad8\u6548\u81ea\u52a8\u8c08\u5224\uff0c\u57282022\u5e74ANAC\u7ade\u8d5b\u4e2d\u540d\u5217\u524d\u8305\uff0c\u5c55\u793a\u4e86\u5176\u5f3a\u5927\u6027\u80fd\u548c\u6f5c\u529b\u3002", "motivation": "\u81ea\u52a8\u5316\u8c08\u5224\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u662f\u5173\u952e\u7814\u7a76\u9886\u57df\uff0c\u5b58\u5728\u4e8e\u7535\u5b50\u5546\u52a1\u3001\u8d44\u6e90\u5206\u914d\u548c\u81ea\u4e3b\u51b3\u7b56\u7b49\u591a\u4e2a\u9886\u57df\uff0c\u9700\u8981\u8bbe\u8ba1\u9ad8\u6548\u8c08\u5224\u4ee3\u7406\u3002", "method": "ChargingBoul\u91c7\u7528\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u7ed3\u5408\u8ba9\u6b65\u653f\u7b56\u548c\u5bf9\u5bf9\u624b\u7684\u5efa\u6a21\uff0c\u901a\u8fc7\u6839\u636e\u5bf9\u624b\u51fa\u4ef7\u6a21\u5f0f\u5206\u7c7b\u3001\u52a8\u6001\u8c03\u6574\u51fa\u4ef7\u7b56\u7565\uff0c\u5b9e\u73b0\u9ad8\u6548\u8c08\u5224\u3002", "result": "ChargingBoul\u57282022\u5e74ANAC\u7ade\u8d5b\u4e2d\u83b7\u5f97\u7b2c\u4e8c\u540d\uff0c\u8868\u73b0\u51fa\u5bf9\u591a\u6837\u5316\u5bf9\u624b\u7b56\u7565\u7684\u9ad8\u9002\u5e94\u6027\u548c\u5353\u8d8a\u8c08\u5224\u6548\u679c\u3002", "conclusion": "ChargingBoul\u6709\u6548\u5e73\u8861\u4e86\u8ba9\u6b65\u4e0e\u5bf9\u624b\u5efa\u6a21\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u8c08\u5224\u6027\u80fd\u3002\u672a\u6765\u53ef\u901a\u8fc7\u66f4\u590d\u6742\u7684\u5bf9\u624b\u5efa\u6a21\u548c\u81ea\u9002\u5e94\u51fa\u4ef7\u542f\u53d1\u5f0f\u65b9\u6cd5\u8fdb\u4e00\u6b65\u4f18\u5316\u3002"}}
{"id": "2512.06248", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06248", "abs": "https://arxiv.org/abs/2512.06248", "authors": ["Cheng Cheng", "Jinqiu Yang"], "title": "CFCEval: Evaluating Security Aspects in Code Generated by Large Language Models", "comment": null, "summary": "Code-focused Large Language Models (LLMs), such as CodeX and Star-Coder, have demonstrated remarkable capabilities in enhancing developer productivity through context-aware code generation. However, evaluating the quality and security of LLM-generated code remains a significant challenge. Existing evaluation protocols for Code LLMs lack both methodological rigor and comprehensive scope. A key limitation is dataset bias, which arises from unintentional overlap between training and testing data. Furthermore, while CodeBLEU, a BLEU-based metric, is widely used to assess code similarity, it suffers from critical shortcomings, including imprecise tokenization, structural limitations, and low reference diversity. To address these challenges, we introduce CFCEval, a novel framework for evaluating the quality and security of code generated by LLMs. CFCEval mitigates dataset bias by creating a new benchmark, MLVBench, and incorporates ELRM, a new metric designed to assess the relevance between reference code and generated code. CFCEval evaluates generated code across four dimensions: programming quality, vulnerability-fixing capability, post-transformation fixing capability, and relevance. Our experiments show that CFCEval not only captures both quality and security aspects of generated code more effectively but also that its ELRM aligns more closely with human judgments than CodeBLEU, thus paving the way for future advancements in Code LLMs evaluation.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51faCFCEval\u8bc4\u4f30\u6846\u67b6\u548c\u65b0\u6307\u6807ELRM\uff0c\u901a\u8fc7\u65b0\u6570\u636e\u96c6\u89e3\u51b3\u6570\u636e\u504f\u5dee\uff0c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u548c\u5b89\u5168\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u548c\u5168\u9762\u6027\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\uff08Code LLM\uff09\u8bc4\u4f30\u7f3a\u4e4f\u65b9\u6cd5\u8bba\u4e25\u8c28\u6027\u548c\u5168\u9762\u6027\uff0c\u6570\u636e\u96c6\u504f\u5dee\u548cCodeBLEU\u6307\u6807\u7684\u5c40\u9650\u6027\u5f71\u54cd\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86CFCEval\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u65b0\u57fa\u51c6\u6570\u636e\u96c6MLVBench\u548c\u65b0\u8bc4\u4f30\u6307\u6807ELRM\uff0c\u4ee5\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u4e2d\u6570\u636e\u96c6\u504f\u5dee\u548cCodeBLEU\u6307\u6807\u7684\u4e0d\u8db3\u3002CFCEval\u4ece\u4ee3\u7801\u8d28\u91cf\u3001\u5b89\u5168\u6f0f\u6d1e\u4fee\u590d\u80fd\u529b\u3001\u540e\u671f\u53d8\u6362\u4fee\u590d\u80fd\u529b\u548c\u76f8\u5173\u6027\u56db\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u751f\u6210\u4ee3\u7801\u3002", "result": "CFCEval\u5728\u56db\u4e2a\u7ef4\u5ea6\u66f4\u6709\u6548\u5730\u6355\u6349\u4ee3\u7801\u8d28\u91cf\u548c\u5b89\u5168\u6027\uff0cELRM\u6307\u6807\u4e0e\u4eba\u7c7b\u5224\u65ad\u66f4\u4e00\u81f4\uff0c\u4f18\u4e8eCodeBLEU\u3002", "conclusion": "CFCEval\u4e3a\u4ee3\u7801\u751f\u6210\u6a21\u578b\u8bc4\u4ef7\u63d0\u4f9b\u4e86\u66f4\u79d1\u5b66\u548c\u5168\u9762\u7684\u5de5\u5177\uff0c\u63a8\u52a8\u672a\u6765\u4ee3\u7801\u5927\u6a21\u578b\u7684\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u6b65\u3002"}}
{"id": "2512.06227", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06227", "abs": "https://arxiv.org/abs/2512.06227", "authors": ["Junyu Mao", "Anthony Hills", "Talia Tseriotou", "Maria Liakata", "Aya Shamir", "Dan Sayda", "Dana Atzil-Slonim", "Natalie Djohari", "Arpan Mandal", "Silke Roth", "Pamela Ugwudike", "Mahesan Niranjan", "Stuart E. Middleton"], "title": "Automated Data Enrichment using Confidence-Aware Fine-Grained Debate among Open-Source LLMs for Mental Health and Online Safety", "comment": null, "summary": "Real-world indicators are important for improving natural language processing (NLP) tasks such as life events for mental health analysis and risky behaviour for online safety, yet labelling such information in NLP training datasets is often costly and/or difficult given the dynamic nature of such events. This paper compares several LLM-based data enrichment methods and introduces a novel Confidence-Aware Fine-Grained Debate (CFD) framework in which multiple LLM agents simulate human annotators and exchange fine-grained evidence to reach consensus. We describe two new expert-annotated datasets, a mental health Reddit wellbeing dataset and an online safety Facebook sharenting risk dataset. Our CFD framework achieves the most robust data enrichment performance compared to a range of baselines and we show that this type of data enrichment consistently improves downstream tasks. Enriched features incorporated via debate transcripts yield the largest gains, outperforming the non-enriched baseline by 10.1% for the online safety task.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u52a8\u6001\u96be\u6807\u6ce8\u7684\u73b0\u5b9e\u4e8b\u4ef6\uff0c\u63d0\u51faCFD\u591a\u6a21\u578b\u7ec6\u7c92\u5ea6\u8fa9\u8bba\u6846\u67b6\u589e\u5f3a\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u5fc3\u7406\u5065\u5eb7\u548c\u5728\u7ebf\u5b89\u5168NLP\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6307\u6807\uff08\u5982\u5fc3\u7406\u5065\u5eb7\u4e8b\u4ef6\u548c\u5728\u7ebf\u5b89\u5168\u884c\u4e3a\uff09\u5bf9\u4e8e\u6539\u8fdbNLP\u4efb\u52a1\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u6807\u6ce8\u8fd9\u4e9b\u52a8\u6001\u590d\u6742\u4fe1\u606f\u7684\u8bad\u7ec3\u6570\u636e\u96c6\u6210\u672c\u9ad8\u4e14\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u4fe1\u5fc3\u611f\u77e5\u7ec6\u7c92\u5ea6\u8fa9\u8bba\uff08CFD\uff09\u6846\u67b6\uff0c\u591a\u4e2aLLM\u4ee3\u7406\u6a21\u62df\u4eba\u5de5\u6807\u6ce8\u8005\uff0c\u901a\u8fc7\u4ea4\u6362\u7ec6\u7c92\u5ea6\u8bc1\u636e\u8fbe\u6210\u5171\u8bc6\uff0c\u540c\u65f6\u6bd4\u8f83\u591a\u79cdLLM\u6570\u636e\u4e30\u5bcc\u65b9\u6cd5\u3002", "result": "CFD\u6846\u67b6\u5728\u4e24\u4e2a\u4e13\u5bb6\u6807\u6ce8\u7684\u5fc3\u7406\u5065\u5eb7\u548c\u5728\u7ebf\u5b89\u5168\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u6700\u4f18\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6570\u636e\u4e30\u5bcc\u6548\u679c\uff0c\u5e76\u901a\u8fc7\u8fa9\u8bba\u751f\u6210\u7684\u7279\u5f81\u4f7f\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u63d0\u5347\u663e\u8457\uff0c\u5728\u7ebf\u5b89\u5168\u4efb\u52a1\u63d0\u534710.1%\u3002", "conclusion": "CFD\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u73b0\u5b9e\u4e16\u754c\u52a8\u6001\u4e8b\u4ef6\u7684NLP\u6570\u636e\u6807\u6ce8\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u578b\u8fa9\u8bba\u673a\u5236\u5728\u6570\u636e\u4e30\u5bcc\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.06645", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.06645", "abs": "https://arxiv.org/abs/2512.06645", "authors": ["Muyang Fan"], "title": "Analyzing Collision Rates in Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning", "comment": null, "summary": "Vehicle collisions remain a major challenge in large-scale mixed traffic systems, especially when human-driven vehicles (HVs) and robotic vehicles (RVs) interact under dynamic and uncertain conditions. Although Multi-Agent Reinforcement Learning (MARL) offers promising capabilities for traffic signal control, ensuring safety in such environments remains difficult. As a direct indicator of traffic risk, the collision rate must be well understood and incorporated into traffic control design. This study investigates the primary factors influencing collision rates in a MARL-governed Mixed Traffic Control (MTC) network. We examine three dimensions: total vehicle count, signalized versus unsignalized intersection configurations, and turning-movement strategies. Through controlled simulation experiments, we evaluate how each factor affects collision likelihood. The results show that collision rates are sensitive to traffic density, the level of signal coordination, and turning-control design. These findings provide practical insights for improving the safety and robustness of MARL-based mixed traffic control systems, supporting the development of intelligent transportation systems in which both efficiency and safety are jointly optimized.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7MARL\u548c\u4eff\u771f\u5206\u6790\u4e86\u4ea4\u901a\u5bc6\u5ea6\u3001\u4fe1\u53f7\u914d\u7f6e\u53ca\u8f6c\u5411\u7b56\u7565\u5bf9\u6df7\u5408\u4ea4\u901a\u7cfb\u7edf\u78b0\u649e\u7387\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u63d0\u5347\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u7684\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u5728\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\u4e0e\u673a\u5668\u4eba\u9a7e\u9a76\u8f66\u8f86\u6df7\u5408\u7684\u52a8\u6001\u4e0d\u786e\u5b9a\u4ea4\u901a\u73af\u5883\u4e2d\uff0c\u4ea4\u901a\u4fe1\u53f7\u63a7\u5236\u867d\u501f\u52a9MARL\u6709\u6f5c\u529b\uff0c\u4f46\u5b89\u5168\u6027\u96be\u4ee5\u4fdd\u969c\uff0c\u78b0\u649e\u7387\u4f5c\u4e3a\u4ea4\u901a\u98ce\u9669\u7684\u76f4\u63a5\u6307\u6807\u9700\u878d\u5165\u63a7\u5236\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u5bf9\u6df7\u5408\u4ea4\u901a\u63a7\u5236\u7f51\u7edc\u8fdb\u884c\u63a7\u5236\uff0c\u7ed3\u5408\u4eff\u771f\u5b9e\u9a8c\u5206\u6790\u78b0\u649e\u7387\u53d7\u8f66\u6d41\u91cf\u3001\u4fe1\u53f7\u706f\u914d\u7f6e\u4e0e\u8f6c\u5411\u7b56\u7565\u7684\u5f71\u54cd\u3002", "result": "\u4eff\u771f\u5b9e\u9a8c\u8868\u660e\u78b0\u649e\u7387\u5bf9\u4ea4\u901a\u5bc6\u5ea6\u3001\u4fe1\u53f7\u534f\u8c03\u6c34\u5e73\u53ca\u8f6c\u5411\u63a7\u5236\u8bbe\u8ba1\u5747\u9ad8\u5ea6\u654f\u611f\uff0c\u63ed\u793a\u4e86\u5f71\u54cd\u6df7\u5408\u4ea4\u901a\u7cfb\u7edf\u5b89\u5168\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8eMARL\u7684\u6df7\u5408\u4ea4\u901a\u63a7\u5236\u7cfb\u7edf\u5728\u63d0\u5347\u5b89\u5168\u6027\u548c\u6548\u7387\u65b9\u9762\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u63a8\u52a8\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.06401", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06401", "abs": "https://arxiv.org/abs/2512.06401", "authors": ["Zhenzhen Yang", "Chenhui Cui", "Tao Li", "Rubing Huang", "Nan Niu", "Dave Towey", "Shikai Guo"], "title": "LLMCFG-TGen: Using LLM-Generated Control Flow Graphs to Automatically Create Test Cases from Use Cases", "comment": null, "summary": "Appropriate test case generation is critical in software testing, significantly impacting the quality of the testing. Requirements-Based Test Generation (RBTG) derives test cases from software requirements, aiming to verify whether or not the system's behaviors align with user needs and expectations. Requirements are often documented in Natural Language (NL), with use-case descriptions being a popular method for capturing functional behaviors and interaction flows in a structured form. Large Language Models (LLMs) have shown strong potential for automating test generation directly from NL requirements. However, current LLM-based approaches may not provide comprehensive, non-redundant coverage. They may also fail to capture complex conditional logic in requirements, resulting in incomplete test cases. We propose a new approach that automatically generates test cases from NL use-case descriptions, called Test Generation based on LLM-generated Control Flow Graphs (LLMCFG-TGen). LLMCFG-TGen comprises three main steps: (1) An LLM transforms a use case into a structured CFG that encapsulates all potential branches; (2) The generated CFG is explored, and all complete execution paths are enumerated; and (3) The execution paths are then used to generate the test cases. To evaluate our proposed approach, we conducted a series of experiments. The results show that LLMs can effectively construct well-structured CFGs from NL use cases. Compared with the baseline methods, LLMCFG-TGen achieves full path coverage, improving completeness and ensuring clear and accurate test cases. Practitioner assessments confirm that LLMCFG-TGen produces logically consistent and comprehensive test cases, while substantially reducing manual effort. The findings suggest that coupling LLM-based semantic reasoning with structured modeling effectively bridges the gap between NL requirements and systematic test generation.", "AI": {"tldr": "\u901a\u8fc7LLM\u751f\u6210\u63a7\u5236\u6d41\u56fe\uff0c\u81ea\u52a8\u679a\u4e3e\u6267\u884c\u8def\u5f84\uff0c\u751f\u6210\u5168\u9762\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5b9e\u73b0\u5b8c\u6574\u8def\u5f84\u8986\u76d6\uff0c\u63d0\u5347\u6d4b\u8bd5\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u8986\u76d6\u4e0d\u5168\u3001\u903b\u8f91\u590d\u6742\u6761\u4ef6\u6355\u6349\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u751f\u6210\u5168\u9762\u4e14\u51c6\u786e\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\uff081\uff09\u5229\u7528LLM\u5c06\u7528\u4f8b\u8f6c\u6362\u4e3a\u5305\u542b\u6240\u6709\u53ef\u80fd\u5206\u652f\u7684\u7ed3\u6784\u5316\u63a7\u5236\u6d41\u56fe\uff08CFG\uff09\uff1b\uff082\uff09\u904d\u5386CFG\uff0c\u679a\u4e3e\u6240\u6709\u5b8c\u6574\u6267\u884c\u8def\u5f84\uff1b\uff083\uff09\u57fa\u4e8e\u8def\u5f84\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u751f\u6210\u63a7\u5236\u6d41\u56fe(CFG)\u7684\u81ea\u52a8\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff08LLMCFG-TGen\uff09\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\uff08NL\uff09\u7528\u4f8b\u63cf\u8ff0\u4e2d\u63d0\u53d6\u5b8c\u6574\u6267\u884c\u8def\u5f84\uff0c\u751f\u6210\u5168\u9762\u4e14\u975e\u5197\u4f59\u7684\u6d4b\u8bd5\u7528\u4f8b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5b8c\u6574\u8def\u5f84\u8986\u76d6\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u5b8c\u6574\u6027\u548c\u51c6\u786e\u6027\uff0c\u4e14\u663e\u8457\u51cf\u5c11\u4e86\u4eba\u5de5\u6295\u5165\u3002", "conclusion": "\u7ed3\u5408LLM\u8bed\u4e49\u63a8\u7406\u4e0e\u7ed3\u6784\u5316\u5efa\u6a21\uff0c\u6709\u6548\u5f25\u5408\u4e86\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u4e0e\u7cfb\u7edf\u5316\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4e4b\u95f4\u7684\u9e3f\u6c9f\uff0c\u63d0\u5347\u6d4b\u8bd5\u7684\u5168\u9762\u6027\u548c\u4e00\u81f4\u6027\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3002"}}
{"id": "2512.06228", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06228", "abs": "https://arxiv.org/abs/2512.06228", "authors": ["Xuanxin Wu", "Yuki Arase", "Masaaki Nagata"], "title": "Policy-based Sentence Simplification: Replacing Parallel Corpora with LLM-as-a-Judge", "comment": null, "summary": "Sentence simplification aims to modify a sentence to make it easier to read and understand while preserving the meaning. Different applications require distinct simplification policies, such as replacing only complex words at the lexical level or rewriting the entire sentence while trading off details for simplicity. However, achieving such policy-driven control remains an open challenge. In this work, we introduce a simple yet powerful approach that leverages Large Language Model-as-a-Judge (LLM-as-a-Judge) to automatically construct policy-aligned training data, completely removing the need for costly human annotation or parallel corpora. Our method enables building simplification systems that adapt to diverse simplification policies. Remarkably, even small-scale open-source LLMs such as Phi-3-mini-3.8B surpass GPT-4o on lexical-oriented simplification, while achieving comparable performance on overall rewriting, as verified by both automatic metrics and human evaluations. The consistent improvements across model families and sizes demonstrate the robustness of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6784\u5efa\u7b56\u7565\u9a71\u52a8\u7684\u7b80\u5316\u6570\u636e\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u591a\u6837\u5316\u7684\u53e5\u5b50\u7b80\u5316\u7cfb\u7edf\uff0c\u8868\u73b0\u4f18\u4e8e\u751a\u81f3\u53ef\u66ff\u4ee3\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u3002", "motivation": "\u9488\u5bf9\u53e5\u5b50\u7b80\u5316\u9700\u8981\u6839\u636e\u4e0d\u540c\u5e94\u7528\u91c7\u53d6\u4e0d\u540c\u7684\u7b80\u5316\u7b56\u7565\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u7b56\u7565\u9a71\u52a8\u7684\u63a7\u5236\uff0c\u5e76\u4e14\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u5e73\u884c\u8bed\u6599\u6210\u672c\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\uff08LLM-as-a-Judge\uff09\u6765\u81ea\u52a8\u6784\u5efa\u4e0e\u7b80\u5316\u7b56\u7565\u5bf9\u9f50\u7684\u8bad\u7ec3\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u5e73\u884c\u8bed\u6599\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u7b80\u5316\u7cfb\u7edf\u80fd\u9002\u5e94\u591a\u6837\u7684\u7b80\u5316\u7b56\u7565\uff0c\u5c0f\u89c4\u6a21\u5f00\u6e90\u6a21\u578bPhi-3-mini-3.8B\u5728\u8bcd\u6c47\u7b80\u5316\u4e0a\u8d85\u8fc7GPT-4o\uff0c\u5728\u6574\u4f53\u91cd\u5199\u4e0a\u8868\u73b0\u76f8\u5f53\uff0c\u81ea\u52a8\u6307\u6807\u548c\u4eba\u5de5\u8bc4\u4ef7\u5747\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u578b\u548c\u89c4\u6a21\u4e0b\u5747\u8868\u73b0\u51fa\u7a33\u5b9a\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2512.07219", "categories": ["cs.MA", "cs.GT", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.07219", "abs": "https://arxiv.org/abs/2512.07219", "authors": ["Sungyong Chung", "Alireza Talebpour", "Samer H. Hamdar"], "title": "Characterizing Lane-Changing Behavior in Mixed Traffic", "comment": null, "summary": "Characterizing and understanding lane-changing behavior in the presence of automated vehicles (AVs) is crucial to ensuring safety and efficiency in mixed traffic. Accordingly, this study aims to characterize the interactions between the lane-changing vehicle (active vehicle) and the vehicle directly impacted by the maneuver in the target lane (passive vehicle). Utilizing real-world trajectory data from the Waymo Open Motion Dataset (WOMD), this study explores patterns in lane-changing behavior and provides insight into how these behaviors evolve under different AV market penetration rates (MPRs). In particular, we propose a game-theoretic framework to analyze cooperative and defective behaviors in mixed traffic, applied to the 7,636 observed lane-changing events in the WOMD. First, we utilize k-means clustering to classify vehicles as cooperative or defective, revealing that the proportions of cooperative AVs are higher than those of HDVs in both active and passive roles. Next, we jointly estimate the utilities of active and passive vehicles to model their behaviors using the quantal response equilibrium framework. Empirical payoff tables are then constructed based on these utilities. Using these payoffs, we analyze the presence of social dilemmas and examine the evolution of cooperative behaviors using evolutionary game theory. Our results reveal the presence of social dilemmas in approximately 4% and 11% of lane-changing events for active and passive vehicles, respectively, with most classified as Stag Hunt or Prisoner's Dilemma (Chicken Game rarely observed). Moreover, the Monte Carlo simulation results show that repeated lane-changing interactions consistently lead to increased cooperative behavior over time, regardless of the AV penetration rate.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u771f\u5b9e\u6570\u636e\u548c\u535a\u5f08\u8bba\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u6df7\u5408\u4ea4\u901a\u6362\u9053\u884c\u4e3a\u4e2d\u7684\u5408\u4f5c\u6a21\u5f0f\u53ca\u793e\u4f1a\u56f0\u5883\uff0c\u5e76\u53d1\u73b0\u6362\u9053\u4e92\u52a8\u901a\u8fc7\u53cd\u590d\u8fdb\u884c\u4fc3\u8fdb\u5408\u4f5c\u884c\u4e3a\u7684\u6f14\u8fdb\u3002", "motivation": "\u5728\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\uff08AV\uff09\u9010\u6b65\u666e\u53ca\u7684\u6df7\u5408\u4ea4\u901a\u73af\u5883\u4e2d\uff0c\u7406\u89e3\u6362\u9053\u884c\u4e3a\u53ca\u5176\u5bf9\u4ea4\u901a\u5b89\u5168\u4e0e\u6548\u7387\u7684\u5f71\u54cd\u81f3\u5173\u91cd\u8981\u3002\u7279\u522b\u662f\u9700\u8981\u5206\u6790\u4e3b\u52a8\u6362\u9053\u8f66\u8f86\u4e0e\u53d7\u5f71\u54cd\u8f66\u8f86\u4e4b\u95f4\u7684\u4e92\u52a8\uff0c\u4ee5\u53ca\u4e0d\u540c\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5e02\u573a\u6e17\u900f\u7387\u4e0b\u884c\u4e3a\u7684\u6f14\u53d8\u3002", "method": "\u57fa\u4e8eWaymo\u516c\u5f00\u8fd0\u52a8\u6570\u636e\u96c6\uff08WOMD\uff09\u7684\u771f\u5b9e\u8f68\u8ff9\u6570\u636e\uff0c\u4f7f\u7528k-means\u805a\u7c7b\u548c\u91cf\u5316\u54cd\u5e94\u5747\u8861\u6846\u67b6\u5206\u6790\u6df7\u5408\u4ea4\u901a\u4e2d\u6362\u9053\u8f66\u8f86\uff08\u4e3b\u52a8\u8f66\u8f86\uff09\u4e0e\u53d7\u5f71\u54cd\u8f66\u8f86\uff08\u88ab\u52a8\u8f66\u8f86\uff09\u4e4b\u95f4\u7684\u4e92\u52a8\u884c\u4e3a\uff1b\u91c7\u7528\u6f14\u5316\u535a\u5f08\u8bba\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u7814\u7a76\u5408\u4f5c\u4e0e\u80cc\u53db\u884c\u4e3a\u7684\u6f14\u5316\u3002", "result": "\u53d1\u73b0\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u5728\u4e3b\u52a8\u548c\u88ab\u52a8\u89d2\u8272\u4e2d\u5408\u4f5c\u6bd4\u4f8b\u9ad8\u4e8e\u4eba\u7c7b\u9a7e\u9a76\u8f66\u8f86\uff1b\u7ea64%\u548c11%\u7684\u6362\u9053\u4e8b\u4ef6\u5b58\u5728\u793e\u4f1a\u56f0\u5883\uff0c\u4e3b\u8981\u8868\u73b0\u4e3a\u9e7f\u730e\u535a\u5f08\u548c\u56da\u5f92\u56f0\u5883\uff0c\u9e21\u535a\u5f08\u8f83\u5c11\uff1b\u8499\u7279\u5361\u6d1b\u6a21\u62df\u8868\u660e\uff0c\u6362\u9053\u4e92\u52a8\u7684\u53cd\u590d\u53d1\u751f\u63a8\u52a8\u5408\u4f5c\u884c\u4e3a\u9010\u6e10\u589e\u5f3a\uff0c\u4e14\u4e0d\u53d7\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6e17\u900f\u7387\u5f71\u54cd\u3002", "conclusion": "\u6df7\u5408\u4ea4\u901a\u4e2d\u7684\u6362\u9053\u884c\u4e3a\u5b58\u5728\u663e\u8457\u7684\u793e\u4f1a\u56f0\u5883\uff0c\u4f46\u968f\u7740\u8f66\u8f86\u95f4\u6362\u9053\u4e92\u52a8\u7684\u6301\u7eed\uff0c\u5408\u4f5c\u884c\u4e3a\u4f1a\u9010\u6b65\u589e\u5f3a\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u4ea4\u901a\u5b89\u5168\u548c\u6548\u7387\uff0c\u8fd9\u4e00\u8fc7\u7a0b\u4e0d\u4f9d\u8d56\u4e8e\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u5e02\u573a\u6e17\u900f\u7387\u6c34\u5e73\u3002"}}
{"id": "2512.06448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06448", "abs": "https://arxiv.org/abs/2512.06448", "authors": ["Takaaki Tateishi", "Yasuharu Katsuno"], "title": "Translating PL/I Macro Procedures into Java Using Automatic Templatization and Large Language Models", "comment": "5 pages, 7 figures, to be published in ICSE 2026 NIER", "summary": "Modernizing legacy enterprise systems often involves translating PL/I programs into modern languages such as Java. This task becomes significantly more complex when PL/I macro procedures are involved. The PL/I macro procedures are considered string-manipulating programs that generate PL/I code, and they make automated translation more complex. Recently, large language models (LLMs) have been explored for automated code translation. However, LLM-based code translation struggles to translate the PL/I macro procedures to Java programs that reproduce the behavior of the plain PL/I code generated by the original PL/I macro procedures.\n  This paper proposes a novel method called templatization, which uses symbolic execution to generate code templates (code with named placeholders) as an intermediate representation. In this approach, symbolic values are treated as parts of macro-generated code. By symbolically executing macro procedures and generating code templates, our approach facilitates LLMs to generate readable and maintainable Java code. Our preliminary experiment on ten PL/I macro procedures shows that the LLM-based translation through templatization successfully generates Java programs that reproduce the behavior of the macro-generated PL/I programs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u7b26\u53f7\u6267\u884c\u751f\u6210\u4ee3\u7801\u6a21\u677f\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u7ffb\u8bd1PL/I\u5b8f\u7a0b\u5e8f\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u81ea\u52a8\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4f7f\u5f97\u751f\u6210\u7684Java\u7a0b\u5e8f\u80fd\u518d\u73b0\u539fPL/I\u5b8f\u7a0b\u5e8f\u751f\u6210\u7684\u4ee3\u7801\u884c\u4e3a\u3002", "motivation": "\u4f20\u7edf\u5c06PL/I\u7a0b\u5e8f\u7ffb\u8bd1\u4e3a\u73b0\u4ee3\u8bed\u8a00\uff08\u5982Java\uff09\u65f6\uff0c\u6d89\u53caPL/I\u5b8f\u7a0b\u5e8f\u90e8\u5206\u4f7f\u81ea\u52a8\u7ffb\u8bd1\u590d\u6742\u4e14\u56f0\u96be\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u76f4\u63a5\u7ffb\u8bd1PL/I\u5b8f\u7a0b\u5e8f\u751f\u6210\u7684\u4ee3\u7801\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3atemplatization\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u7b26\u53f7\u6267\u884c\u751f\u6210\u5e26\u6709\u547d\u540d\u5360\u4f4d\u7b26\u7684\u4ee3\u7801\u6a21\u677f\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u5c06\u7b26\u53f7\u503c\u89c6\u4e3a\u5b8f\u751f\u6210\u4ee3\u7801\u7684\u4e00\u90e8\u5206\uff0c\u4ece\u800c\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u7ffb\u8bd1PL/I\u5b8f\u7a0b\u5e8f\u3002", "result": "\u5728\u5bf910\u4e2aPL/I\u5b8f\u7a0b\u5e8f\u7684\u521d\u6b65\u5b9e\u9a8c\u4e2d\uff0c\u57fa\u4e8etemplatization\u7684\u65b9\u6cd5\u6210\u529f\u751f\u6210\u4e86\u53ef\u8bfb\u4e14\u53ef\u7ef4\u62a4\u7684Java\u7a0b\u5e8f\uff0c\u4e14\u8fd9\u4e9bJava\u7a0b\u5e8f\u80fd\u5fe0\u5b9e\u518d\u73b0\u539f\u5b8f\u751f\u6210\u7684PL/I\u7a0b\u5e8f\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7templatization\u65b9\u6cd5\u7ed3\u5408\u7b26\u53f7\u6267\u884c\uff0c\u4e2d\u95f4\u751f\u6210\u4ee3\u7801\u6a21\u677f\uff0c\u5927\u5e45\u63d0\u5347\u4e86PL/I\u5b8f\u7a0b\u5e8f\u81ea\u52a8\u7ffb\u8bd1\u6210Java\u7684\u51c6\u786e\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002\u8be5\u65b9\u6cd5\u5728\u521d\u6b65\u5b9e\u9a8c\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2512.06239", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06239", "abs": "https://arxiv.org/abs/2512.06239", "authors": ["Dhanasekar Sundararaman", "Keying Li", "Wayne Xiong", "Aashna Garg"], "title": "LOCUS: A System and Method for Low-Cost Customization for Universal Specialization", "comment": null, "summary": "We present LOCUS (LOw-cost Customization for Universal Specialization), a pipeline that consumes few-shot data to streamline the construction and training of NLP models through targeted retrieval, synthetic data generation, and parameter-efficient tuning. With only a small number of labeled examples, LOCUS discovers pertinent data in a broad repository, synthesizes additional training samples via in-context data generation, and fine-tunes models using either full or low-rank (LoRA) parameter adaptation. Our approach targets named entity recognition (NER) and text classification (TC) benchmarks, consistently outperforming strong baselines (including GPT-4o) while substantially lowering costs and model sizes. Our resultant memory-optimized models retain 99% of fully fine-tuned accuracy while using barely 5% of the memory footprint, also beating GPT-4o on several benchmarks with less than 1% of its parameters.", "AI": {"tldr": "LOCUS\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u81ea\u5b9a\u4e49\u901a\u7528\u7279\u5316\u7684\u7ba1\u9053\uff0c\u901a\u8fc7\u5c11\u91cf\u6807\u6ce8\u6570\u636e\u4f18\u5316NLP\u6a21\u578b\uff0c\u8fbe\u5230\u9ad8\u6027\u80fd\u4e14\u8282\u7701\u5185\u5b58\u548c\u53c2\u6570\u7684\u6548\u679c\u3002", "motivation": "\u964d\u4f4e\u6784\u5efa\u548c\u8bad\u7ec3NLP\u6a21\u578b\u7684\u6210\u672c\u548c\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u63d0\u5347\u5c0f\u6837\u672c\u5b66\u4e60\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u76ee\u6807\u6570\u636e\u68c0\u7d22\u3001\u4e0a\u4e0b\u6587\u6570\u636e\u5408\u6210\u751f\u6210\u4ee5\u53ca\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\uff08\u5168\u53c2\u6570\u6216\u4f4e\u79e9LoRA\u8c03\u4f18\uff09\u4e09\u6b65\u6784\u5efa\u5b9a\u5236NLP\u6a21\u578b\u3002", "result": "LOCUS\u901a\u8fc7\u6570\u636e\u68c0\u7d22\u3001\u5408\u6210\u548c\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\uff0c\u5728\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u548c\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0c\u6027\u80fd\u4f18\u4e8e\u5305\u62ecGPT-4o\u5728\u5185\u7684\u5f3a\u57fa\u7ebf\uff0c\u4e14\u663e\u8457\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\u548c\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "LOCUS\u5728\u5c0f\u6837\u672c\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u6570\u636e\u68c0\u7d22\u3001\u751f\u6210\u548c\u53c2\u6570\u9ad8\u6548\u8c03\u4f18\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7cbe\u51c6\u7684NLP\u6a21\u578b\u5b9a\u5236\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u8bc1\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2512.07462", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.07462", "abs": "https://arxiv.org/abs/2512.07462", "authors": ["Trung-Kiet Huynh", "Duy-Minh Dao-Sy", "Thanh-Bang Cao", "Phong-Hao Le", "Hong-Dan Nguyen", "Phu-Quy Nguyen-Lam", "Minh-Luan Nguyen-Vo", "Hong-Phat Pham", "Phu-Hoa Pham", "Thien-Kim Than", "Chi-Nguyen Tran", "Huy Tran", "Gia-Thoai Tran-Le", "Alessio Buscemi", "Le Hong Trang", "The Anh Han"], "title": "Understanding LLM Agent Behaviours via Game Theory: Strategy Recognition, Biases and Multi-Agent Dynamics", "comment": null, "summary": "As Large Language Models (LLMs) increasingly operate as autonomous decision-makers in interactive and multi-agent systems and human societies, understanding their strategic behaviour has profound implications for safety, coordination, and the design of AI-driven social and economic infrastructures. Assessing such behaviour requires methods that capture not only what LLMs output, but the underlying intentions that guide their decisions. In this work, we extend the FAIRGAME framework to systematically evaluate LLM behaviour in repeated social dilemmas through two complementary advances: a payoff-scaled Prisoners Dilemma isolating sensitivity to incentive magnitude, and an integrated multi-agent Public Goods Game with dynamic payoffs and multi-agent histories. These environments reveal consistent behavioural signatures across models and languages, including incentive-sensitive cooperation, cross-linguistic divergence and end-game alignment toward defection. To interpret these patterns, we train traditional supervised classification models on canonical repeated-game strategies and apply them to FAIRGAME trajectories, showing that LLMs exhibit systematic, model- and language-dependent behavioural intentions, with linguistic framing at times exerting effects as strong as architectural differences. Together, these findings provide a unified methodological foundation for auditing LLMs as strategic agents and reveal systematic cooperation biases with direct implications for AI governance, collective decision-making, and the design of safe multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6269\u5c55FAIRGAME\u6846\u67b6\uff0c\u8bbe\u8ba1\u65b0\u535a\u5f08\u73af\u5883\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u91cd\u590d\u793e\u4f1a\u56f0\u5883\u4e2d\u7684\u7b56\u7565\u884c\u4e3a\uff0c\u53d1\u73b0\u5176\u5408\u4f5c\u504f\u597d\u548c\u8bed\u8a00\u4f9d\u8d56\u6027\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u65b9\u6cd5\u8bba\u4e3aLLMs\u4f5c\u4e3a\u6218\u7565\u667a\u80fd\u4f53\u7684\u5ba1\u8ba1\u63d0\u4f9b\u57fa\u7840\u3002", "motivation": "\u968f\u7740LLMs\u8d8a\u6765\u8d8a\u591a\u5730\u4f5c\u4e3a\u81ea\u4e3b\u51b3\u7b56\u8005\u5728\u4ea4\u4e92\u5f0f\u3001\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53ca\u4eba\u7c7b\u793e\u4f1a\u4e2d\u8fd0\u884c\uff0c\u7406\u89e3\u5176\u6218\u7565\u884c\u4e3a\u5bf9\u4e8e\u5b89\u5168\u3001\u534f\u8c03\u4ee5\u53caAI\u9a71\u52a8\u7684\u793e\u4f1a\u7ecf\u6d4e\u57fa\u7840\u8bbe\u65bd\u8bbe\u8ba1\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u8bc4\u4f30\u6b64\u7c7b\u884c\u4e3a\u9700\u6355\u6349\u4e0d\u4ec5\u662f\u8f93\u51fa\u5185\u5bb9\uff0c\u8fd8\u5305\u62ec\u6307\u5bfc\u51b3\u7b56\u7684\u6f5c\u5728\u610f\u56fe\u3002", "method": "\u901a\u8fc7\u6269\u5c55FAIRGAME\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u4ed8\u8d39\u523b\u5ea6\u56da\u5f92\u56f0\u5883\u548c\u52a8\u6001\u591a\u667a\u80fd\u4f53\u516c\u5171\u7269\u54c1\u535a\u5f08\u4e24\u79cd\u73af\u5883\uff0c\u7cfb\u7edf\u6027\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u91cd\u590d\u793e\u4f1a\u56f0\u5883\u4e2d\u7684\u884c\u4e3a\u3002\u4f7f\u7528\u4f20\u7edf\u76d1\u7763\u5206\u7c7b\u6a21\u578b\u5bf9\u91cd\u590d\u535a\u5f08\u7b56\u7565\u8fdb\u884c\u8bad\u7ec3\uff0c\u89e3\u91caLLMs\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "result": "\u5b9e\u9a8c\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u548c\u8bed\u8a00\u95f4\u5b58\u5728\u4e00\u81f4\u7684\u884c\u4e3a\u7279\u5f81\uff0c\u5982\u5bf9\u6fc0\u52b1\u7684\u654f\u611f\u5408\u4f5c\u3001\u8de8\u8bed\u8a00\u5dee\u5f02\u548c\u535a\u5f08\u672b\u671f\u8d8b\u5411\u80cc\u53db\u3002\u8bed\u8a00\u6846\u67b6\u7684\u5f71\u54cd\u6709\u65f6\u4e0e\u6a21\u578b\u7ed3\u6784\u5dee\u5f02\u540c\u7b49\u663e\u8457\u3002\u901a\u8fc7\u5206\u7c7b\u6a21\u578b\u5b9a\u4f4dLLMs\u5448\u73b0\u51fa\u7cfb\u7edf\u6027\u7684\u3001\u4f9d\u8d56\u6a21\u578b\u548c\u8bed\u8a00\u7684\u884c\u4e3a\u610f\u56fe\u3002", "conclusion": "\u7814\u7a76\u4e3a\u5ba1\u8ba1LLMs\u7684\u6218\u7565\u884c\u4e3a\u63d0\u4f9b\u4e86\u7edf\u4e00\u65b9\u6cd5\u8bba\uff0c\u63ed\u793a\u4e86\u5176\u7cfb\u7edf\u6027\u7684\u5408\u4f5c\u504f\u5dee\u53ca\u8bed\u8a00\u5f71\u54cd\uff0c\u63a8\u52a8\u4e86\u5b89\u5168\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u3001AI\u6cbb\u7406\u548c\u96c6\u4f53\u51b3\u7b56\u8bbe\u8ba1\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.06806", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06806", "abs": "https://arxiv.org/abs/2512.06806", "authors": ["Benjamin Weigell", "Simon Hornung", "Bernhard Bauer"], "title": "METRION: A Framework for Accurate Software Energy Measurement", "comment": "(Accepted/In press) 10th IEEE/ACM International Workshop on Green and Sustainable Software (GREENS'26): GREENS@ICSE 2026", "summary": "The Information and Communication Technology sector accounted for approximately 1.4% of global greenhouse gas emissions and 4% of the world's electricity consumption in 2020, with both expected to rise. To reduce this environmental impact, optimization strategies are employed to reduce energy consumption at the IT infrastructure and application levels. However, effective optimization requires, firstly, the identification of major energy consumers and, secondly, the ability to quantify whether an optimization has achieved the intended energy savings. Accurate determination of application-level energy consumption is thus essential. Therefore, we introduce an energy attribution model that quantifies the energy consumption of applications on CPU and DRAM at the thread level, considering the influence of Simultaneous Multithreading, frequency scaling, multi-socket architectures, and Non-Uniform Memory Access. To ensure cross-platform applicability, we integrate the proposed model into an extensible framework, METRION, including a platform-independent data model and an initial implementation for Linux systems using Intel CPUs. We evaluate METRION across three different workloads and demonstrate that the energy attribution model can accurately capture the CPU energy consumption of applications targeting solely the CPU with a Mean Absolute Percentage Error of 4.2%, and the DRAM energy consumption of applications targeting DRAM with an 16.1% error.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u591a\u79cd\u786c\u4ef6\u56e0\u7d20\u7684\u7ebf\u7a0b\u7ea7\u5e94\u7528\u80fd\u8017\u91cf\u5316\u6a21\u578b\uff0c\u5e76\u901a\u8fc7METRION\u6846\u67b6\u5b9e\u73b0\uff0c\u663e\u8457\u63d0\u5347\u4e86\u80fd\u8017\u6d4b\u91cf\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8eIT\u9886\u57df\u7684\u8282\u80fd\u4f18\u5316\u3002", "motivation": "\u4fe1\u606f\u901a\u4fe1\u6280\u672f\u884c\u4e1a\u7684\u80fd\u8017\u53ca\u78b3\u6392\u653e\u9010\u5e74\u4e0a\u5347\uff0c\u4e3a\u5b9e\u73b0\u6709\u6548\u4f18\u5316\u9700\u51c6\u786e\u8bc6\u522b\u4e3b\u8981\u80fd\u8017\u6765\u6e90\u53ca\u9a8c\u8bc1\u8282\u80fd\u6548\u679c\uff0c\u56e0\u800c\u6025\u9700\u5bf9\u5e94\u7528\u5c42\u80fd\u8017\u8fdb\u884c\u7cbe\u51c6\u91cf\u5316\u7684\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u80fd\u91cf\u5f52\u56e0\u6a21\u578b\uff0c\u652f\u6301\u7ebf\u7a0b\u7ea7\u80fd\u8017\u91cf\u5316\uff0c\u6db5\u76d6Simultaneous Multithreading\u3001\u9891\u7387\u8c03\u8282\u3001\u591a\u63d2\u69fd\u67b6\u6784\u53ca\u975e\u7edf\u4e00\u5185\u5b58\u8bbf\u95ee\u7b49\u56e0\u7d20\uff0c\u5e76\u96c6\u6210\u5728METRION\u6846\u67b6\u4e2d\uff0c\u91c7\u7528Linux\u7cfb\u7edf\u548cIntel CPU\u8fdb\u884c\u4e86\u5b9e\u73b0\u548c\u6d4b\u8bd5\u3002", "result": "\u6a21\u578b\u5728\u4e09\u4e2a\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0cCPU\u80fd\u8017\u5e73\u5747\u7edd\u5bf9\u767e\u5206\u6bd4\u8bef\u5dee\u4ec5\u4e3a4.2%\uff0cDRAM\u80fd\u8017\u8bef\u5dee\u4e3a16.1%\uff0c\u8868\u660e\u6a21\u578b\u80fd\u591f\u6709\u6548\u6355\u6349\u5e94\u7528\u7a0b\u5e8f\u7684\u80fd\u8017\u7279\u5f81\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684\u80fd\u91cf\u5f52\u56e0\u6a21\u578b\u80fd\u591f\u51c6\u786e\u91cf\u5316\u5e94\u7528\u7a0b\u5e8f\u5728CPU\u548cDRAM\u4e0a\u7684\u7ebf\u7a0b\u7ea7\u80fd\u8017\uff0c\u8003\u8651\u4e86\u591a\u79cd\u590d\u6742\u56e0\u7d20\uff0c\u4e14\u901a\u8fc7METRION\u6846\u67b6\u5b9e\u73b0\u8de8\u5e73\u53f0\u5e94\u7528\uff0c\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.06256", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06256", "abs": "https://arxiv.org/abs/2512.06256", "authors": ["Aniruddha Maiti", "Satya Nimmagadda", "Kartha Veerya Jammuladinne", "Niladri Sengupta", "Ananya Jana"], "title": "Convergence of Outputs When Two Large Language Models Interact in a Multi-Agentic Setup", "comment": "accepted to LLM 2025", "summary": "In this work, we report what happens when two large language models respond to each other for many turns without any outside input in a multi-agent setup. The setup begins with a short seed sentence. After that, each model reads the other's output and generates a response. This continues for a fixed number of steps. We used Mistral Nemo Base 2407 and Llama 2 13B hf. We observed that most conversations start coherently but later fall into repetition. In many runs, a short phrase appears and repeats across turns. Once repetition begins, both models tend to produce similar output rather than introducing a new direction in the conversation. This leads to a loop where the same or similar text is produced repeatedly. We describe this behavior as a form of convergence. It occurs even though the models are large, trained separately, and not given any prompt instructions. To study this behavior, we apply lexical and embedding-based metrics to measure how far the conversation drifts from the initial seed and how similar the outputs of the two models becomes as the conversation progresses.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4e24\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6ca1\u6709\u5916\u90e8\u8f93\u5165\u7684\u591a\u4ee3\u7406\u73af\u5883\u4e2d\u4e92\u52a8\u65f6\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5bf9\u8bdd\u6700\u521d\u8fde\u8d2f\u4f46\u4f1a\u9677\u5165\u91cd\u590d\uff0c\u5f62\u6210\u6536\u655b\u5faa\u73af\u73b0\u8c61\u3002", "motivation": "\u63a2\u7a76\u5728\u65e0\u5916\u754c\u5e72\u9884\u4e0b\uff0c\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u8f6e\u5bf9\u8bdd\u7684\u52a8\u6001\u53d8\u5316\u53ca\u76f8\u4e92\u5f71\u54cd\uff0c\u63ed\u793a\u5176\u5728\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u8868\u73b0\u548c\u6f5c\u5728\u95ee\u9898\u3002", "method": "\u8ba9\u4e24\u4e2a\u8bed\u8a00\u6a21\u578b\u4ea4\u66ff\u9605\u8bfb\u5bf9\u65b9\u8f93\u51fa\u5e76\u751f\u6210\u56de\u5e94\uff0c\u56fa\u5b9a\u8f6e\u6570\u540e\u5206\u6790\u5bf9\u8bdd\u6587\u672c\uff0c\u4f7f\u7528\u8bcd\u6c47\u548c\u5d4c\u5165\u5ea6\u91cf\u8861\u91cf\u5bf9\u8bdd\u504f\u79bb\u521d\u59cb\u79cd\u5b50\u53e5\u5b50\u53ca\u6a21\u578b\u8f93\u51fa\u76f8\u4f3c\u5ea6\u3002", "result": "\u53d1\u73b0\u5bf9\u8bdd\u521d\u671f\u8f83\u8fde\u8d2f\uff0c\u968f\u540e\u51fa\u73b0\u7279\u5b9a\u77ed\u8bed\u91cd\u590d\uff0c\u6a21\u578b\u8f93\u51fa\u8d8b\u540c\uff0c\u5bfc\u81f4\u5bf9\u8bdd\u9677\u5165\u8bed\u4e49\u5faa\u73af\u6536\u655b\u72b6\u6001\u3002", "conclusion": "\u4e24\u6a21\u578b\u5728\u591a\u8f6e\u4ea4\u6d41\u4e2d\u4f1a\u8d8b\u4e8e\u751f\u6210\u76f8\u4f3c\u4e14\u91cd\u590d\u7684\u5185\u5bb9\uff0c\u5bfc\u81f4\u5bf9\u8bdd\u9677\u5165\u5faa\u73af\uff0c\u5373\u4f7f\u6a21\u578b\u89c4\u6a21\u5927\u4e14\u72ec\u7acb\u8bad\u7ec3\u4e14\u65e0\u63d0\u793a\u6307\u4ee4\u3002"}}
{"id": "2512.07588", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.07588", "abs": "https://arxiv.org/abs/2512.07588", "authors": ["James Rudd-Jones", "Mar\u00eda P\u00e9rez-Ortiz", "Mirco Musolesi"], "title": "Understanding Individual Decision-Making in Multi-Agent Reinforcement Learning: A Dynamical Systems Approach", "comment": null, "summary": "Analysing learning behaviour in Multi-Agent Reinforcement Learning (MARL) environments is challenging, in particular with respect to \\textit{individual} decision-making. Practitioners frequently tend to study or compare MARL algorithms from a qualitative perspective largely due to the inherent stochasticity in practical algorithms arising from random dithering exploration strategies, environment transition noise, and stochastic gradient updates to name a few. Traditional analytical approaches, such as replicator dynamics, often rely on mean-field approximations to remove stochastic effects, but this simplification, whilst able to provide general overall trends, might lead to dissonance between analytical predictions and actual realisations of individual trajectories. In this paper, we propose a novel perspective on MARL systems by modelling them as \\textit{coupled stochastic dynamical systems}, capturing both agent interactions and environmental characteristics. Leveraging tools from dynamical systems theory, we analyse the stability and sensitivity of agent behaviour at individual level, which are key dimensions for their practical deployments, for example, in presence of strict safety requirements. This framework allows us, for the first time, to rigorously study MARL dynamics taking into consideration their inherent stochasticity, providing a deeper understanding of system behaviour and practical insights for the design and control of multi-agent learning processes.", "AI": {"tldr": "\u672c\u6587\u5c06\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u5efa\u6a21\u4e3a\u8026\u5408\u968f\u673a\u52a8\u529b\u7cfb\u7edf\uff0c\u501f\u52a9\u52a8\u529b\u5b66\u7406\u8bba\u5206\u6790\u4e2a\u4f53\u884c\u4e3a\u7684\u7a33\u5b9a\u6027\uff0c\u9996\u6b21\u5728\u8003\u8651\u968f\u673a\u6027\u7684\u60c5\u51b5\u4e0b\u6df1\u523b\u7406\u89e3MARL\u884c\u4e3a\uff0c\u4e3a\u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u8df5\u5e94\u7528\u67b6\u8d77\u6865\u6881\u3002", "motivation": "\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u5747\u503c\u573a\u8fd1\u4f3c\uff0c\u5ffd\u7565\u4e86\u968f\u673a\u6027\uff0c\u5bfc\u81f4\u7406\u8bba\u9884\u6d4b\u4e0e\u4e2a\u4f53\u8f68\u8ff9\u5b9e\u9645\u8868\u73b0\u5b58\u5728\u504f\u5dee\uff1b\u5b9e\u9645MARL\u7b97\u6cd5\u5177\u6709\u968f\u673a\u63a2\u7d22\u3001\u73af\u5883\u566a\u58f0\u548c\u968f\u673a\u68af\u5ea6\u66f4\u65b0\u7b49\u56fa\u6709\u968f\u673a\u6027\uff0c\u9700\u8003\u8651\u8fd9\u4e9b\u56e0\u7d20\u624d\u80fd\u6df1\u5165\u7406\u89e3\u7cfb\u7edf\u884c\u4e3a\u3002", "method": "\u5c06\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7cfb\u7edf\u5efa\u6a21\u4e3a\u8026\u5408\u968f\u673a\u52a8\u529b\u7cfb\u7edf\uff0c\u5e76\u5229\u7528\u52a8\u529b\u7cfb\u7edf\u7406\u8bba\u5de5\u5177\u5206\u6790\u4e2a\u4f53\u884c\u4e3a\u7684\u7a33\u5b9a\u6027\u548c\u654f\u611f\u6027\u3002", "result": "\u63d0\u51fa\u4e86\u5c06MARL\u89c6\u4e3a\u8026\u5408\u968f\u673a\u52a8\u529b\u7cfb\u7edf\u7684\u65b0\u65b9\u6cd5\uff0c\u9996\u6b21\u4e25\u8c28\u7814\u7a76\u4e86\u542b\u968f\u673a\u6027\u7684MARL\u52a8\u6001\uff0c\u63ed\u793a\u4e86\u4e2a\u4f53\u5c42\u9762\u884c\u4e3a\u7684\u7a33\u5b9a\u6027\u548c\u654f\u611f\u6027\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u8fc7\u7a0b\u7684\u8bbe\u8ba1\u548c\u63a7\u5236\u63d0\u4f9b\u4e86\u5b9e\u9645\u6d1e\u89c1\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u6355\u6349\u4e86MARL\u7cfb\u7edf\u7684\u968f\u673a\u6027\u548c\u4e2a\u4f53\u4ea4\u4e92\uff0c\u4e3a\u7406\u89e3\u548c\u63a7\u5236\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u8fc7\u7a0b\u63d0\u4f9b\u4e86\u65b0\u7684\u7406\u8bba\u57fa\u7840\u548c\u5b9e\u8df5\u6307\u5bfc\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u5bf9\u5b89\u5168\u6027\u6709\u4e25\u683c\u8981\u6c42\u7684\u573a\u666f\u3002"}}
{"id": "2512.06836", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.06836", "abs": "https://arxiv.org/abs/2512.06836", "authors": ["Weixing Zhang", "Regina Hebig", "Daniel Str\u00fcber"], "title": "Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs", "comment": null, "summary": "Software languages evolve over time for various reasons, such as the addition of new features. When the language's grammar definition evolves, textual instances that originally conformed to the grammar become outdated. For DSLs in a model-driven engineering context, there exists a plethora of techniques to co-evolve models with the evolving metamodel. However, these techniques are not geared to support DSLs with a textual syntax -- applying them to textual language definitions and instances may lead to the loss of information from the original instances, such as comments and layout information, which are valuable for software comprehension and maintenance. This study explores the potential of Large Language Model (LLM)-based solutions in achieving grammar and instance co-evolution, with attention to their ability to preserve auxiliary information when directly processing textual instances. By applying two advanced language models, Claude-3.5 and GPT-4o, and conducting experiments across seven case languages, we evaluated the feasibility and limitations of this approach. Our results indicate a good ability of the considered LLMs for migrating textual instances in small-scale cases with limited instance size, which are representative of a subset of cases encountered in practice. In addition, we observe significant challenges with the scalability of LLM-based solutions to larger instances, leading to insights that are useful for informing future research.", "AI": {"tldr": "\u7814\u7a76\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0DSL\u6587\u672c\u5b9e\u4f8b\u4e0e\u8bed\u6cd5\u5171\u540c\u6f14\u5316\uff0cLLM\u9002\u5408\u5c0f\u89c4\u6a21\u5b9e\u4f8b\u4f46\u6269\u5c55\u6027\u4e0d\u8db3\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u8bed\u8a00\u8bed\u6cd5\u5b9a\u4e49\u4e0d\u65ad\u6f14\u5316\uff0c\u4f20\u7edf\u6a21\u578b\u9a71\u52a8\u65b9\u6cd5\u96be\u4ee5\u4fdd\u6301DSL\u6587\u672c\u5b9e\u4f8b\u4e2d\u7684\u6ce8\u91ca\u548c\u5e03\u5c40\u7b49\u8f85\u52a9\u4fe1\u606f\uff0c\u63a2\u7d22\u5229\u7528LLM\u5b9e\u73b0\u6587\u672c\u5b9e\u4f8b\u4e0e\u8bed\u6cd5\u7684\u5171\u540c\u6f14\u5316\uff0c\u4ee5\u63d0\u9ad8\u8f6f\u4ef6\u7ef4\u62a4\u548c\u7406\u89e3\u6548\u7387\u3002", "method": "\u91c7\u7528Claude-3.5\u548cGPT-4o\u4e24\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u9488\u5bf9\u4e03\u4e2a\u4e0d\u540c\u7684\u8bed\u8a00\u6848\u4f8b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u5176\u5728\u6587\u672c\u5b9e\u4f8b\u8bed\u8a00\u6f14\u5316\u8fc1\u79fb\u4e2d\u7684\u8868\u73b0\u548c\u8f85\u52a9\u4fe1\u606f\u4fdd\u5b58\u80fd\u529b\u3002", "result": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u8f6f\u4ef6\u8bed\u8a00\u8bed\u6cd5\u5b9a\u4e49\u6f14\u5316\u4e2d\uff0c\u5b9e\u73b0\u8bed\u6cd5\u4e0e\u6587\u672c\u5b9e\u4f8b\u534f\u540c\u6f14\u5316\u7684\u53ef\u884c\u6027\u3002\u901a\u8fc7\u5bf9Claude-3.5\u548cGPT-4o\u4e24\u79cd\u9ad8\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u53ca\u4e03\u79cd\u6848\u4f8b\u8bed\u8a00\u7684\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793aLLM\u5728\u5904\u7406\u5c0f\u89c4\u6a21\u3001\u6587\u672c\u5b9e\u4f8b\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9762\u5bf9\u5927\u89c4\u6a21\u5b9e\u4f8b\u65f6\u5b58\u5728\u660e\u663e\u7684\u6269\u5c55\u6027\u6311\u6218\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u652f\u6301\u5c0f\u89c4\u6a21\u6587\u672c\u5b9e\u4f8b\u7684\u8bed\u8a00\u6f14\u5316\u8fc1\u79fb\uff0c\u4f46\u5927\u89c4\u6a21\u6587\u672c\u5b9e\u4f8b\u7684\u5904\u7406\u5b58\u5728\u6269\u5c55\u6027\u74f6\u9888\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u3002"}}
{"id": "2512.06266", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06266", "abs": "https://arxiv.org/abs/2512.06266", "authors": ["Chen Yang", "Guangyue Peng", "Jiaying Zhu", "Ran Le", "Ruixiang Feng", "Tao Zhang", "Wei Ruan", "Xiaoqi Liu", "Xiaoxue Cheng", "Xiyun Xu", "Yang Song", "Yanzipeng Gao", "Yiming Jia", "Yun Xing", "Yuntao Wen", "Zekai Wang", "Zhenwei An", "Zhicong Sun", "Zongchao Chen"], "title": "Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models", "comment": null, "summary": "We present Nanbeige4-3B, a family of small-scale but high-performing language models. Pretrained on 23T high-quality tokens and finetuned on over 30 million diverse instructions, we extend the boundary of the scaling law for small language models. In pre-training, we design a Fine-Grained Warmup-Stable-Decay (FG-WSD) training scheduler, which progressively refines data mixtures across stages to boost model performance. In post-training, to improve the quality of the SFT data, we design a joint mechanism that integrates deliberative generation refinement and chain-of-thought reconstruction, yielding substantial gains on complex tasks. Following SFT, we employ our flagship reasoning model to distill Nanbeige4-3B through our proposed Dual Preference Distillation (DPD) method, which leads to further performance gains. Finally, a multi-stage reinforcement learning phase was applied, leveraging verifiable rewards and preference modeling to strengthen abilities on both reasoning and human alignment. Extensive evaluations show that Nanbeige4-3B not only significantly outperforms models of comparable parameter scale but also rivals much larger models across a wide range of benchmarks. The model checkpoints are available at https://huggingface.co/Nanbeige.", "AI": {"tldr": "Nanbeige4-3B\u901a\u8fc7\u5148\u8fdb\u8bad\u7ec3\u8c03\u5ea6\u548c\u591a\u9636\u6bb5\u4f18\u5316\uff0c\u6210\u4e3a\u6027\u80fd\u9886\u5148\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u6269\u5c55\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u89c4\u6a21\u6548\u5e94\u8fb9\u754c\uff0c\u63d0\u9ad8\u5176\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86Fine-Grained Warmup-Stable-Decay\u8bad\u7ec3\u8c03\u5ea6\u5668\uff0c\u7ed3\u5408\u6df1\u601d\u719f\u8651\u7684\u751f\u6210\u4f18\u5316\u548c\u94fe\u5f0f\u601d\u8003\u91cd\u6784\u673a\u5236\uff0c\u91c7\u7528Dual Preference Distillation\u65b9\u6cd5\u84b8\u998f\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u591a\u9636\u6bb5\u5f3a\u5316\u5b66\u4e60\u3002", "result": "Nanbeige4-3B\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u8d85\u8d8a\u540c\u89c4\u6a21\u6a21\u578b\uff0c\u63a5\u8fd1\u66f4\u5927\u6a21\u578b\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u548c\u5fae\u8c03\u7b56\u7565\uff0cNanbeige4-3B\u5b9e\u73b0\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6027\u80fd\u7a81\u7834\u3002"}}
{"id": "2512.06902", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06902", "abs": "https://arxiv.org/abs/2512.06902", "authors": ["Fazle Rabbi", "Soumit Kanti Saha", "Tri Minh Triet Pham", "Song Wang", "Jinqiu Yang"], "title": "BabelCoder: Agentic Code Translation with Specification Alignment", "comment": "21 pages, 8 figures, 4 tables", "summary": "As software systems evolve, developers increasingly work across multiple programming languages and often face the need to migrate code from one language to another. While automatic code translation offers a promising solution, it has long remained a challenging task. Recent advancements in Large Language Models (LLMs) have shown potential for this task, yet existing approaches remain limited in accuracy and fail to effectively leverage contextual and structural cues within the code. Prior work has explored translation and repair mechanisms, but lacks a structured, agentic framework where multiple specialized agents collaboratively improve translation quality. In this work, we introduce BabelCoder, an agentic framework that performs code translation by decomposing the task into specialized agents for translation, testing, and refinement, each responsible for a specific aspect such as generating code, validating correctness, or repairing errors. We evaluate BabelCoder on four benchmark datasets and compare it against four state-of-the-art baselines. BabelCoder outperforms existing methods by 0.5%-13.5% in 94% of cases, achieving an average accuracy of 94.16%.", "AI": {"tldr": "\u63d0\u51fa\u4e86BabelCoder\u591a\u4ee3\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u4efb\u52a1\u5206\u89e3\u548c\u534f\u540c\u63d0\u5347\u81ea\u52a8\u4ee3\u7801\u7ffb\u8bd1\u7684\u51c6\u786e\u5ea6\uff0c\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5\u3002", "motivation": "\u81ea\u52a8\u5316\u4ee3\u7801\u7ffb\u8bd1\u957f\u671f\u6311\u6218\u6027\u5927\uff0c\u73b0\u6709\u65b9\u6cd5\u51c6\u786e\u7387\u6709\u9650\uff0c\u4e14\u672a\u6709\u6548\u5229\u7528\u4ee3\u7801\u7684\u4e0a\u4e0b\u6587\u548c\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u591a\u4e13\u95e8\u5316\u4ee3\u7406\u5206\u522b\u8d1f\u8d23\u4ee3\u7801\u751f\u6210\u3001\u6b63\u786e\u6027\u9a8c\u8bc1\u548c\u9519\u8bef\u4fee\u590d\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u534f\u540c\u7684\u4ee3\u7406\u6846\u67b6\u5b8c\u6210\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cBabelCoder\u572894%\u7684\u6848\u4f8b\u4e2d\u8868\u73b0\u4f18\u4e8e\u56db\u4e2a\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe94.16%\u3002", "conclusion": "BabelCoder\u901a\u8fc7\u5f15\u5165\u591a\u4ee3\u7406\u534f\u540c\u5de5\u4f5c\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u7ffb\u8bd1\u7684\u51c6\u786e\u6027\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2512.06464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06464", "abs": "https://arxiv.org/abs/2512.06464", "authors": ["Akriti Jain", "Aparna Garimella"], "title": "Modeling Contextual Passage Utility for Multihop Question Answering", "comment": "Accepted at IJCNLP-AACL 2025", "summary": "Multihop Question Answering (QA) requires systems to identify and synthesize information from multiple text passages. While most prior retrieval methods assist in identifying relevant passages for QA, further assessing the utility of the passages can help in removing redundant ones, which may otherwise add to noise and inaccuracies in the generated answers. Existing utility prediction approaches model passage utility independently, overlooking a critical aspect of multihop reasoning: the utility of a passage can be context-dependent, influenced by its relation to other passages - whether it provides complementary information or forms a crucial link in conjunction with others. In this paper, we propose a lightweight approach to model contextual passage utility, accounting for inter-passage dependencies. We fine-tune a small transformer-based model to predict passage utility scores for multihop QA. We leverage the reasoning traces from an advanced reasoning model to capture the order in which passages are used to answer a question and obtain synthetic training data. Through comprehensive experiments, we demonstrate that our utility-based scoring of retrieved passages leads to improved reranking and downstream QA performance compared to relevance-based reranking methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u8f7b\u91cf\u7ea7Transformer\u6a21\u578b\uff0c\u901a\u8fc7\u8003\u8651\u6bb5\u843d\u95f4\u4e0a\u4e0b\u6587\u4f9d\u8d56\u9884\u6d4b\u591a\u8df3\u95ee\u7b54\u4e2d\u6bb5\u843d\u7684\u5b9e\u7528\u6027\uff0c\u63d0\u5347\u7b54\u6848\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u72ec\u7acb\u5efa\u6a21\u6bb5\u843d\u5b9e\u7528\u6027\uff0c\u5ffd\u89c6\u6bb5\u843d\u4e4b\u95f4\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff0c\u800c\u591a\u8df3\u63a8\u7406\u4e2d\u6bb5\u843d\u7684\u5b9e\u7528\u6027\u5f80\u5f80\u4f9d\u8d56\u4e8e\u5176\u4e0e\u5176\u4ed6\u6bb5\u843d\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u5c0f\u578bTransformer\u6a21\u578b\u7684\u591a\u8df3\u95ee\u7b54\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u6bb5\u843d\u5b9e\u7528\u6027\u5efa\u6a21\u65b9\u6cd5\uff0c\u5229\u7528\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u9884\u6d4b\u6bb5\u843d\u5b9e\u7528\u6027\u5f97\u5206\u4ee5\u63d0\u5347\u91cd\u6392\u6548\u679c\u3002", "result": "\u65b9\u6cd5\u6709\u6548\u5229\u7528\u6bb5\u843d\u95f4\u4f9d\u8d56\u4fe1\u606f\uff0c\u63d0\u5347\u4e86\u68c0\u7d22\u6bb5\u843d\u7684\u91cd\u6392\u8d28\u91cf\uff0c\u8fdb\u800c\u6539\u5584\u591a\u8df3\u95ee\u7b54\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u76f8\u5173\u6027\u7684\u91cd\u6392\u65b9\u6cd5\u3002", "conclusion": "\u7ed3\u5408\u63a8\u7406\u8f68\u8ff9\u7684\u4e0a\u4e0b\u6587\u6bb5\u843d\u5b9e\u7528\u6027\u5efa\u6a21\u53ef\u6709\u6548\u63d0\u5347\u591a\u8df3\u95ee\u7b54\u7684\u6bb5\u843d\u91cd\u6392\u53ca\u6700\u7ec8\u8868\u73b0\uff0c\u4f18\u4e8e\u5355\u72ec\u8003\u8651\u76f8\u5173\u6027\u7684\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2512.07195", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.07195", "abs": "https://arxiv.org/abs/2512.07195", "authors": ["Xuan Zhang", "Wenxuan Zhang", "Anxu Wang", "See-Kiong Ng", "Yang Deng"], "title": "MASim: Multilingual Agent-Based Simulation for Social Science", "comment": null, "summary": "Multi-agent role-playing has recently shown promise for studying social behavior with language agents, but existing simulations are mostly monolingual and fail to model cross-lingual interaction, an essential property of real societies. We introduce MASim, the first multilingual agent-based simulation framework that supports multi-turn interaction among generative agents with diverse sociolinguistic profiles. MASim offers two key analyses: (i) global public opinion modeling, by simulating how attitudes toward open-domain hypotheses evolve across languages and cultures, and (ii) media influence and information diffusion, via autonomous news agents that dynamically generate content and shape user behavior. To instantiate simulations, we construct the MAPS benchmark, which combines survey questions and demographic personas drawn from global population distributions. Experiments on calibration, sensitivity, consistency, and cultural case studies show that MASim reproduces sociocultural phenomena and highlights the importance of multilingual simulation for scalable, controlled computational social science.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u4eff\u771f\u6846\u67b6MASim\uff0c\u80fd\u591f\u6a21\u62df\u8de8\u8bed\u8a00\u793e\u4f1a\u4e92\u52a8\u548c\u8206\u8bba\u6f14\u5316\uff0c\u4fc3\u8fdb\u53ef\u63a7\u7684\u8ba1\u7b97\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u89d2\u8272\u626e\u6f14\u591a\u4e3a\u5355\u8bed\u8a00\u73af\u5883\uff0c\u65e0\u6cd5\u6a21\u62df\u8de8\u8bed\u8a00\u4e92\u52a8\uff0c\u8fd9\u662f\u73b0\u5b9e\u793e\u4f1a\u7684\u91cd\u8981\u5c5e\u6027\u3002", "method": "\u5f15\u5165\u4e86MASim\uff0c\u4e00\u4e2a\u652f\u6301\u591a\u8f6e\u4ea4\u4e92\u7684\u591a\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u4eff\u771f\u6846\u67b6\uff0c\u7ed3\u5408\u751f\u6210\u5f0f\u667a\u80fd\u4f53\u548c\u591a\u6837\u7684\u793e\u4f1a\u8bed\u8a00\u5b66\u7279\u5f81\u3002\u6784\u5efa\u4e86MAPS\u57fa\u51c6\uff0c\u7ed3\u5408\u5168\u7403\u4eba\u53e3\u5206\u5e03\u7684\u8c03\u67e5\u95ee\u9898\u548c\u4eba\u53e3\u89d2\u8272\uff0c\u5b9e\u73b0\u4eff\u771f\u6267\u884c\u3002", "result": "MASim\u901a\u8fc7\u4eff\u771f\u8de8\u8bed\u8a00\u6587\u5316\u4e2d\u7684\u516c\u4f17\u8206\u8bba\u53d1\u5c55\u53ca\u5a92\u4f53\u5f71\u54cd\uff0c\u5b9e\u73b0\u4e86\u591a\u8bed\u8a00\u4eff\u771f\u793e\u4f1a\u73b0\u8c61\u590d\u73b0\uff0c\u9a8c\u8bc1\u4e86\u5176\u6821\u51c6\u6027\u3001\u654f\u611f\u6027\u3001\u4e00\u81f4\u6027\u548c\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "\u591a\u8bed\u8a00\u591a\u667a\u80fd\u4f53\u4eff\u771f\u662f\u7814\u7a76\u793e\u4f1a\u884c\u4e3a\u548c\u8bed\u8a00\u4e92\u52a8\u7684\u91cd\u8981\u5de5\u5177\uff0cMASim\u6709\u6548\u91cd\u73b0\u4e86\u590d\u6742\u793e\u4f1a\u6587\u5316\u73b0\u8c61\uff0c\u5f3a\u8c03\u4e86\u591a\u8bed\u8a00\u4eff\u771f\u7684\u5fc5\u8981\u6027\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.06906", "categories": ["cs.SE", "cs.CR", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06906", "abs": "https://arxiv.org/abs/2512.06906", "authors": ["Wenjie Zhang", "Yun Lin", "Chun Fung Amos Kwok", "Xiwen Teoh", "Xiaofei Xie", "Frank Liauw", "Hongyu Zhang", "Jin Song Dong"], "title": "MINES: Explainable Anomaly Detection through Web API Invariant Inference", "comment": null, "summary": "Detecting the anomalies of web applications, important infrastructures for running modern companies and governments, is crucial for providing reliable web services. Many modern web applications operate on web APIs (e.g., RESTful, SOAP, and WebSockets), their exposure invites intended attacks or unintended illegal visits, causing abnormal system behaviors. However, such anomalies can share very similar logs with normal logs, missing crucial information (which could be in database) for log discrimination. Further, log instances can be also noisy, which can further mislead the state-of-the-art log learning solutions to learn spurious correlation, resulting superficial models and rules for anomaly detection. In this work, we propose MINES which infers explainable API invariants for anomaly detection from the schema level instead of detailed raw log instances, which can (1) significantly discriminate noise in logs to identify precise normalities and (2) detect abnormal behaviors beyond the instrumented logs. Technically, MINES (1) converts API signatures into table schema to enhance the original database shema; and (2) infers the potential database constraints on the enhanced database schema to capture the potential relationships between APIs and database tables. MINES uses LLM for extracting potential relationship based on two given table structures; and use normal log instances to reject and accept LLM-generated invariants. Finally, MINES translates the inferred constraints into invariants to generate Python code for verifying the runtime logs. We extensively evaluate MINES on web-tamper attacks on the benchmarks of TrainTicket, NiceFish, Gitea, Mastodon, and NextCloud against baselines such as LogRobust, LogFormer, and WebNorm. The results show that MINES achieves high recall for the anomalies while introducing almost zero false positives, indicating a new state-of-the-art.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faMINES\uff0c\u901a\u8fc7\u4ece\u6570\u636e\u5e93\u6a21\u5f0f\u5c42\u9762\u63a8\u65adAPI\u4e0d\u53d8\u91cf\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u65e0\u8bef\u62a5\u7684\u7f51\u7edc\u5e94\u7528\u5f02\u5e38\u68c0\u6d4b\u3002", "motivation": "\u73b0\u4ee3\u7f51\u7edc\u5e94\u7528\u901a\u8fc7\u66b4\u9732\u7684Web API\u62db\u81f4\u6076\u610f\u653b\u51fb\u6216\u975e\u6cd5\u8bbf\u95ee\uff0c\u65e5\u5fd7\u5f02\u5e38\u5177\u6709\u4e0e\u6b63\u5e38\u65e5\u5fd7\u76f8\u4f3c\u7684\u7279\u70b9\u4e14\u7f3a\u4e4f\u5173\u952e\u4fe1\u606f\uff0c\u73b0\u6709\u65e5\u5fd7\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u88ab\u566a\u58f0\u8bef\u5bfc\uff0c\u5bfc\u81f4\u5f02\u5e38\u68c0\u6d4b\u6a21\u578b\u8868\u6d45\u4e14\u89c4\u5219\u4e0d\u51c6\u786e\u3002", "method": "MINES\u65b9\u6cd5\u901a\u8fc7\u5c06API\u7b7e\u540d\u8f6c\u6362\u4e3a\u589e\u5f3a\u7684\u6570\u636e\u5e93\u8868\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u63a8\u65ad\u6f5c\u5728\u7684\u6570\u636e\u5e93\u7ea6\u675f\u5173\u7cfb\uff0c\u8fdb\u800c\u751f\u6210\u53ef\u89e3\u91ca\u7684API\u4e0d\u53d8\u91cf\uff0c\u7528\u4e8e\u5f02\u5e38\u68c0\u6d4b\u3002\u5177\u4f53\u5305\u62ec\u5229\u7528\u6b63\u5e38\u65e5\u5fd7\u5b9e\u4f8b\u7b5b\u9009\u548c\u9a8c\u8bc1LLM\u751f\u6210\u7684\u4e0d\u53d8\u91cf\uff0c\u6700\u7ec8\u5c06\u63a8\u65ad\u7684\u7ea6\u675f\u8f6c\u5316\u4e3aPython\u4ee3\u7801\uff0c\u5b9e\u73b0\u8fd0\u884c\u65f6\u65e5\u5fd7\u7684\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u7cfb\u7edf\uff08TrainTicket\u3001NiceFish\u3001Gitea\u3001Mastodon\u3001NextCloud\uff09\u4e0a\uff0cMINES\u5728\u68c0\u6d4b\u7f51\u7edc\u7be1\u6539\u653b\u51fb\u4e2d\uff0c\u5b9e\u73b0\u4e86\u9ad8\u53ec\u56de\u7387\u4e14\u51e0\u4e4e\u65e0\u8bef\u62a5\uff0c\u4f18\u4e8eLogRobust\u3001LogFormer\u548cWebNorm\u7b49\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "MINES\u901a\u8fc7\u7ed3\u5408API\u7ed3\u6784\u4e0e\u6570\u636e\u5e93\u7ea6\u675f\u5173\u7cfb\uff0c\u6210\u529f\u6d88\u9664\u65e5\u5fd7\u566a\u58f0\u5f71\u54cd\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u7f51\u7edc\u653b\u51fb\u68c0\u6d4b\u4e2d\u7684\u4f18\u8d8a\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.06476", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06476", "abs": "https://arxiv.org/abs/2512.06476", "authors": ["Akriti Jain", "Aparna Garimella"], "title": "Knowing What's Missing: Assessing Information Sufficiency in Question Answering", "comment": null, "summary": "Determining whether a provided context contains sufficient information to answer a question is a critical challenge for building reliable question-answering systems. While simple prompting strategies have shown success on factual questions, they frequently fail on inferential ones that require reasoning beyond direct text extraction. We hypothesize that asking a model to first reason about what specific information is missing provides a more reliable, implicit signal for assessing overall sufficiency. To this end, we propose a structured Identify-then-Verify framework for robust sufficiency modeling. Our method first generates multiple hypotheses about missing information and establishes a semantic consensus. It then performs a critical verification step, forcing the model to re-examine the source text to confirm whether this information is truly absent. We evaluate our method against established baselines across diverse multi-hop and factual QA datasets. The results demonstrate that by guiding the model to justify its claims about missing information, our framework produces more accurate sufficiency judgments while clearly articulating any information gaps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u5957\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u5148\u8bc6\u522b\u7f3a\u5931\u4fe1\u606f\u518d\u6838\u5b9e\u6587\u672c\uff0c\u63d0\u5347\u95ee\u7b54\u7cfb\u7edf\u4e2d\u5224\u65ad\u4e0a\u4e0b\u6587\u4fe1\u606f\u5145\u5206\u6027\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u73b0\u6709\u76f4\u63a5\u63d0\u95ee\u5f0f\u65b9\u6cd5\u5728\u63a8\u7406\u7c7b\u95ee\u9898\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u5bf9\u4fe1\u606f\u7f3a\u5931\u7684\u663e\u6027\u5224\u65ad\uff0c\u6545\u63d0\u51fa\u901a\u8fc7\u5148\u8bc6\u522b\u7f3a\u5931\u4fe1\u606f\u518d\u9a8c\u8bc1\u7684\u9690\u5f0f\u4fe1\u53f7\u6765\u63d0\u5347\u5224\u65ad\u53ef\u9760\u6027\u3002", "method": "\u8be5\u65b9\u6cd5\u5148\u751f\u6210\u591a\u4e2a\u7f3a\u5931\u4fe1\u606f\u5047\u8bbe\u5e76\u8fbe\u6210\u8bed\u4e49\u5171\u8bc6\uff0c\u968f\u540e\u6a21\u578b\u91cd\u65b0\u68c0\u9a8c\u6587\u672c\u4ee5\u786e\u8ba4\u4fe1\u606f\u662f\u5426\u786e\u5b9e\u7f3a\u5931\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u7684\u8bc6\u522b-\u9a8c\u8bc1\u6d41\u7a0b\u3002", "result": "\u5728\u591a\u8df3\u53ca\u4e8b\u5b9e\u7c7b\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u6d4b\u8868\u660e\uff0c\u672c\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5224\u65ad\u4fe1\u606f\u5145\u5206\u6027\uff0c\u4e14\u80fd\u6e05\u6670\u8868\u8fbe\u4fe1\u606f\u7f3a\u53e3\u3002", "conclusion": "\u63d0\u51fa\u7684Identify-then-Verify\u6846\u67b6\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5148\u8bc6\u522b\u7f3a\u5931\u4fe1\u606f\u518d\u8fdb\u884c\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u4e0a\u4e0b\u6587\u4fe1\u606f\u5145\u5206\u6027\u7684\u5224\u65ad\u51c6\u786e\u6027\u3002"}}
{"id": "2512.06915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.06915", "abs": "https://arxiv.org/abs/2512.06915", "authors": ["Kelin Fu", "Tianyu Liu", "Zeyu Shang", "Yingwei Ma", "Jian Yang", "Jiaheng Liu", "Kaigui Bian"], "title": "Multi-Docker-Eval: A `Shovel of the Gold Rush' Benchmark on Automatic Environment Building for Software Engineering", "comment": null, "summary": "Automated environment configuration is a critical bottleneck in scaling software engineering (SWE) automation. To provide a reliable evaluation standard for this task, we present Multi-Docker-Eval benchmark. It includes 40 real-world repositories spanning 9 programming languages and measures both success in achieving executable states and efficiency under realistic constraints. Our extensive evaluation of state-of-the-art LLMs and agent frameworks reveals key insights: (1) the overall success rate of current models is low (F2P at most 37.7%), with environment construction being the primary bottleneck; (2) model size and reasoning length are not decisive factors, and open-source models like DeepSeek-V3.1 and Kimi-K2 are competitive in both efficiency and effectiveness; (3) agent framework and programming language also have significantly influence on success rate. These findings provide actionable guidelines for building scalable, fully automated SWE pipelines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7Multi-Docker-Eval\u57fa\u51c6\u7cfb\u7edf\u8bc4\u6d4b\u81ea\u52a8\u5316\u73af\u5883\u914d\u7f6e\u4efb\u52a1\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u74f6\u9888\u4e0e\u5173\u952e\u5f71\u54cd\u56e0\u7d20\uff0c\u6307\u5bfc\u66f4\u9ad8\u6548\u7684\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u4e2d\u73af\u5883\u914d\u7f6e\u7684\u5173\u952e\u74f6\u9888\uff0c\u63d0\u4f9b\u53ef\u4fe1\u8d56\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u63d0\u51faMulti-Docker-Eval\u57fa\u51c6\uff0c\u5305\u62ec40\u4e2a\u771f\u5b9e\u4ed3\u5e93\u548c9\u79cd\u7f16\u7a0b\u8bed\u8a00\uff0c\u8bc4\u6d4b\u6267\u884c\u72b6\u6001\u6210\u529f\u7387\u548c\u6548\u7387\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u7684\u6210\u529f\u7387\u8f83\u4f4e\uff08\u6700\u9ad837.7%\uff09\uff0c\u73af\u5883\u6784\u5efa\u662f\u4e3b\u8981\u74f6\u9888\uff1b\u6a21\u578b\u5927\u5c0f\u548c\u63a8\u7406\u957f\u5ea6\u975e\u51b3\u5b9a\u6027\u56e0\u7d20\uff0c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff1b\u4ee3\u7406\u6846\u67b6\u548c\u7f16\u7a0b\u8bed\u8a00\u663e\u8457\u5f71\u54cd\u6210\u529f\u7387\u3002", "conclusion": "\u57fa\u4e8e\u53d1\u73b0\u63d0\u51fa\u53ef\u64cd\u4f5c\u7684\u6307\u5bfc\u539f\u5219\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u53ef\u6269\u5c55\u3001\u5168\u81ea\u52a8\u7684\u8f6f\u4ef6\u5de5\u7a0b\u81ea\u52a8\u5316\u6d41\u7a0b\u3002"}}
{"id": "2512.06483", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06483", "abs": "https://arxiv.org/abs/2512.06483", "authors": ["Elias-Leander Ahlers", "Witold Brunsmann", "Malte Schilling"], "title": "Classifying German Language Proficiency Levels Using Large Language Models", "comment": "Accepted at 3rd International Conference on Foundation and Large Language Models (FLLM2025), Vienna (Austria)", "summary": "Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach that utilizes the internal neural state of the LLM for classification. Our results show a consistent performance improvement over prior methods, highlighting the potential of LLMs for reliable and scalable CEFR classification.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4f7f\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5bf9\u5fb7\u8bed\u6587\u672c\u8fdb\u884cCEFR\u7b49\u7ea7\u5206\u7c7b\uff0c\u7ed3\u5408\u591a\u6e90\u6570\u636e\u548c\u591a\u79cd\u65b9\u6cd5\uff0c\u53d6\u5f97\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u73b0\u4e86LLM\u5728\u8bed\u8a00\u80fd\u529b\u8bc4\u4f30\u4e2d\u7684\u5e94\u7528\u524d\u666f\u3002", "motivation": "\u8bed\u8a00\u80fd\u529b\u8bc4\u4f30\u5bf9\u4e8e\u6559\u80b2\u81f3\u5173\u91cd\u8981\uff0c\u6709\u52a9\u4e8e\u6839\u636e\u5b66\u4e60\u8005\u9700\u6c42\u5b9a\u5236\u6559\u5b66\u5185\u5bb9\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u591a\u6e90\u591a\u6837\u5316\u7684CEFR\u6807\u6ce8\u8bed\u6599\u5e93\u4e0e\u5408\u6210\u6570\u636e\u96c6\uff0c\u91c7\u7528\u63d0\u793a\u5de5\u7a0b\u3001\u5fae\u8c03LLaMA-3-8B-Instruct\u6a21\u578b\u548c\u57fa\u4e8e\u5185\u795e\u7ecf\u72b6\u6001\u7684\u63a2\u6d4b\u65b9\u6cd5\u5bf9\u5fb7\u6587\u6587\u672c\u8fdb\u884cCEFR\u7b49\u7ea7\u5206\u7c7b\u3002", "result": "\u5728\u8bad\u7ec3\u548c\u8bc4\u4f30\u4e2d\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u8f83\u4e4b\u524d\u65b9\u6cd5\u8868\u73b0\u51fa\u6301\u7eed\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728CEFR\u8bed\u8a00\u6c34\u5e73\u81ea\u52a8\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.07022", "categories": ["cs.SE", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.07022", "abs": "https://arxiv.org/abs/2512.07022", "authors": ["Genevieve Caumartin", "Glaucia Melo"], "title": "Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization", "comment": "Accepted at BoatSE 2026", "summary": "Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u975e\u5fae\u8c03LLM\u7684\u8f7b\u91cf\u67e5\u8be2\u6539\u5199\u4e0e\u6458\u8981\u65b9\u6cd5\uff0c\u7ed3\u5408BM25\u68c0\u7d22\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8f6f\u4ef6\u5e93\u4e2d\u9519\u8bef\u7684\u6587\u4ef6\u7ea7\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u4fe1\u606f\u68c0\u7d22\u7684\u9519\u8bef\u5b9a\u4f4d\u65b9\u6cd5\u4f9d\u8d56\u672a\u6539\u53d8\u7684\u9519\u8bef\u63cf\u8ff0\uff0c\u5e38\u542b\u6709\u566a\u58f0\u4fe1\u606f\uff0c\u5bfc\u81f4\u68c0\u7d22\u51c6\u786e\u7387\u4e0d\u4f73\uff1b\u6700\u65b0\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u53ef\u901a\u8fc7\u67e5\u8be2\u6539\u5199\u63d0\u5347\u5b9a\u4f4d\u6548\u679c\uff0c\u4f46\u5176\u5bf9\u4ee3\u7406\u6027\u80fd\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u63a2\u7a76\u3002", "method": "\u4f7f\u7528\u5f00\u6e90\u7684\u975e\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5bf9\u9519\u8bef\u62a5\u544a\u4e2d\u7684\u5173\u952e\u4fe1\u606f\uff08\u5982\u6807\u8bc6\u7b26\u548c\u4ee3\u7801\u7247\u6bb5\uff09\u8fdb\u884c\u63d0\u53d6\uff0c\u5e76\u5728\u68c0\u7d22\u524d\u5bf9\u67e5\u8be2\u8fdb\u884c\u8f7b\u91cf\u5316\u6539\u5199\u3002\u4e4b\u540e\uff0c\u7ed3\u5408BM25\u68c0\u7d22\u7b97\u6cd5\u5b9e\u73b0\u6587\u4ef6\u7ea7\u522b\u7684\u9519\u8bef\u5b9a\u4f4d\u81ea\u52a8\u5316\u3002", "result": "\u901a\u8fc7\u6700\u4f73\u67e5\u8be2\u6539\u5199\u6280\u672f\uff0c\u8be5\u65b9\u6cd5\u5728\u9996\u6b21\u6587\u4ef6\u68c0\u7d22\u4e2d\u7684\u6392\u540d\u63d0\u5347\u4e8635%\uff0c\u6587\u4ef6\u68c0\u7d22\u6027\u80fd\u8f83SWE-agent\u6700\u9ad8\u63d0\u534722%\u3002", "conclusion": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u7684LLM\u9a71\u52a8\u67e5\u8be2\u6539\u5199\u663e\u8457\u4f18\u5316\u4e86\u57fa\u4e8e\u4fe1\u606f\u68c0\u7d22\u7684\u9519\u8bef\u5b9a\u4f4d\u6548\u679c\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u6587\u4ef6\u7ea7\u9519\u8bef\u5b9a\u4f4d\u3002"}}
{"id": "2512.06515", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06515", "abs": "https://arxiv.org/abs/2512.06515", "authors": ["Somnath Banerjee", "Sayan Layek", "Sayantan Adak", "Mykola Pechenizkiy", "Animesh Mukherjee", "Rima Hazra"], "title": "ProSocialAlign: Preference Conditioned Test Time Alignment in Language Models", "comment": null, "summary": "Current language model safety paradigms often fall short in emotionally charged or high-stakes settings, where refusal-only approaches may alienate users and naive compliance can amplify risk. We propose ProSocialAlign, a test-time, parameter-efficient framework that steers generation toward safe, empathetic, and value-aligned responses without retraining the base model. We formalize five human-centered objectives and cast safety as lexicographic constrained generation: first, applying hard constraints to eliminate harmful continuations; then optimizing for prosocial quality within the safe set. Our method combines (i) directional regulation, a harm-mitigation mechanism that subtracts a learned \"harm vector\" in parameter space, and (ii) preference-aware autoregressive reward modeling trained jointly across attributes with gradient conflict resolution, enabling fine-grained, user-controllable decoding. Empirical evaluations across five safety benchmarks demonstrate state-of-the-art performance, reducing unsafe leakage and boosting alignment to human values, with strong gains across multiple evaluation metrics. ProSocialAlign offers a robust and modular foundation for generating context-sensitive, safe, and human-aligned responses at inference time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ProSocialAlign\u65b9\u6cd5\uff0c\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u53c2\u6570\u9ad8\u6548\u7684\u673a\u5236\u5f15\u5bfc\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5b89\u5168\u3001\u5bcc\u6709\u540c\u7406\u5fc3\u4e14\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u56de\u5e94\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u4e2a\u5b89\u5168\u8bc4\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u65b9\u6cd5\u5728\u60c5\u7eea\u6fc0\u70c8\u6216\u9ad8\u98ce\u9669\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u8db3\uff0c\u5355\u7eaf\u62d2\u7edd\u6216\u76f2\u76ee\u670d\u4ece\u53ef\u80fd\u758f\u8fdc\u7528\u6237\u6216\u52a0\u5267\u98ce\u9669\uff0c\u9700\u4e00\u79cd\u5b89\u5168\u4e14\u5177\u540c\u7406\u5fc3\u4e14\u53ef\u63a7\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u5408\u65b9\u5411\u6027\u8c03\u8282\uff08\u51cf\u53bb\u5b66\u4e60\u5f97\u5230\u7684\u201c\u4f24\u5bb3\u5411\u91cf\u201d\uff09\u548c\u504f\u597d\u611f\u77e5\u7684\u81ea\u56de\u5f52\u5956\u52b1\u5efa\u6a21\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8bcd\u6c47\u987a\u5e8f\u7684\u53d7\u9650\u751f\u6210\uff0c\u5148\u6392\u9664\u6709\u5bb3\u5185\u5bb9\uff0c\u518d\u5728\u5b89\u5168\u96c6\u5408\u5185\u4f18\u5316\u4eb2\u793e\u4f1a\u8d28\u91cf\u3002", "result": "\u5728\u4e94\u4e2a\u5b89\u5168\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cProSocialAlign\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u663e\u8457\u51cf\u5c11\u4e0d\u5b89\u5168\u751f\u6210\u5185\u5bb9\u5e76\u63d0\u5347\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\u7684\u4e00\u81f4\u6027\uff0c\u591a\u9879\u8bc4\u4f30\u6307\u6807\u5747\u6709\u5f3a\u52b2\u63d0\u5347\u3002", "conclusion": "ProSocialAlign\u6709\u6548\u51cf\u5c11\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u98ce\u9669\uff0c\u589e\u5f3a\u4e86\u751f\u6210\u5185\u5bb9\u7684\u4ef7\u503c\u5bf9\u9f50\u548c\u7528\u6237\u63a7\u5236\u80fd\u529b\uff0c\u662f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5e94\u5bf9\u590d\u6742\u60c5\u7eea\u548c\u9ad8\u98ce\u9669\u573a\u666f\u5b89\u5168\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\u3002"}}
{"id": "2512.07122", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07122", "abs": "https://arxiv.org/abs/2512.07122", "authors": ["Liping Han", "Tingting Nie", "Le Yu", "Mingzhe Hu", "Tao Yue"], "title": "RisConFix: LLM-based Automated Repair of Risk-Prone Drone Configurations", "comment": null, "summary": "Flight control software is typically designed with numerous configurable parameters governing multiple functionalities, enabling flexible adaptation to mission diversity and environmental uncertainty. Although developers and manufacturers usually provide recommendations for these parameters to ensure safe and stable operations, certain combinations of parameters with recommended values may still lead to unstable flight behaviors, thereby degrading the drone's robustness. To this end, we propose a Large Language Model (LLM) based approach for real-time repair of risk-prone configurations (named RisConFix) that degrade drone robustness. RisConFix continuously monitors the drone's operational state and automatically triggers a repair mechanism once abnormal flight behaviors are detected. The repair mechanism leverages an LLM to analyze relationships between configuration parameters and flight states, and then generates corrective parameter updates to restore flight stability. To ensure the validity of the updated configuration, RisConFix operates as an iterative process; it continuously monitors the drone's flight state and, if an anomaly persists after applying an update, automatically triggers the next repair cycle. We evaluated RisConFix through a case study of ArduPilot (with 1,421 groups of misconfigurations). Experimental results show that RisConFix achieved a best repair success rate of 97% and an optimal average number of repairs of 1.17, demonstrating its capability to effectively and efficiently repair risk-prone configurations in real time.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65e0\u4eba\u673a\u98de\u884c\u53c2\u6570\u5b9e\u65f6\u4fee\u590d\u65b9\u6cd5RisConFix\uff0c\u80fd\u81ea\u52a8\u7ea0\u6b63\u964d\u7a33\u98de\u884c\u7684\u4e0d\u826f\u914d\u7f6e\uff0c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u65e0\u4eba\u673a\u98de\u884c\u63a7\u5236\u7cfb\u7edf\u914d\u7f6e\u53c2\u6570\u4f17\u591a\u4e14\u590d\u6742\uff0c\u63a8\u8350\u503c\u7ec4\u5408\u53ef\u80fd\u4f9d\u7136\u5bfc\u81f4\u98de\u884c\u4e0d\u7a33\u5b9a\uff0c\u5f71\u54cd\u65e0\u4eba\u673a\u9c81\u68d2\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u3001\u5b9e\u65f6\u3001\u6709\u6548\u7684\u98ce\u9669\u914d\u7f6e\u4fee\u590d\u65b9\u6cd5\u3002", "method": "RisConFix\u901a\u8fc7\u5b9e\u65f6\u76d1\u6d4b\u65e0\u4eba\u673a\u98de\u884c\u72b6\u6001\uff0c\u53d1\u73b0\u5f02\u5e38\u5373\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5206\u6790\u914d\u7f6e\u53c2\u6570\u4e0e\u98de\u884c\u72b6\u6001\u95f4\u5173\u7cfb\uff0c\u751f\u6210\u53c2\u6570\u4fee\u6b63\u5e76\u8fed\u4ee3\u4fee\u590d\uff0c\u76f4\u5230\u98de\u884c\u6062\u590d\u6b63\u5e38\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65e0\u4eba\u673a\u98de\u884c\u63a7\u5236\u8f6f\u4ef6\u5b9e\u65f6\u4fee\u590d\u65b9\u6cd5RisConFix\uff0c\u7528\u4e8e\u81ea\u52a8\u4fee\u590d\u53ef\u80fd\u5bfc\u81f4\u98de\u884c\u4e0d\u7a33\u5b9a\u7684\u914d\u7f6e\u53c2\u6570\u7ec4\u5408\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6301\u7eed\u76d1\u6d4b\u65e0\u4eba\u673a\u8fd0\u884c\u72b6\u6001\uff0c\u68c0\u6d4b\u5f02\u5e38\u98de\u884c\u884c\u4e3a\u540e\uff0c\u5229\u7528LLM\u5206\u6790\u914d\u7f6e\u53c2\u6570\u4e0e\u98de\u884c\u72b6\u6001\u5173\u7cfb\uff0c\u751f\u6210\u4fee\u6b63\u53c2\u6570\u66f4\u65b0\u4ee5\u6062\u590d\u98de\u884c\u7a33\u5b9a\u3002\u6574\u4f53\u4fee\u590d\u8fc7\u7a0b\u4e3a\u8fed\u4ee3\u8fdb\u884c\uff0c\u76f4\u5230\u98de\u884c\u72b6\u6001\u6b63\u5e38\u3002\u5b9e\u9a8c\u57fa\u4e8eArduPilot\u8fdb\u884c\uff0c\u5305\u542b1421\u7ec4\u9519\u8bef\u914d\u7f6e\uff0cRisConFix\u4fee\u590d\u6210\u529f\u7387\u8fbe\u523097%\uff0c\u5e73\u5747\u4fee\u590d\u6b21\u65701.17\u6b21\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u3001\u51c6\u786e\u7684\u5b9e\u65f6\u4fee\u590d\u80fd\u529b\u3002", "conclusion": "RisConFix\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u8bc1\u98de\u884c\u5b89\u5168\u4e0e\u7a33\u5b9a\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u6709\u6548\u81ea\u52a8\u4fee\u590d\u65e0\u4eba\u673a\u98ce\u9669\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u4eba\u673a\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.06586", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06586", "abs": "https://arxiv.org/abs/2512.06586", "authors": ["Mikhail Zimin", "Milyausha Shamsutdinova", "Georgii Andriushchenko"], "title": "Adapting AlignScore Mertic for Factual Consistency Evaluation of Text in Russian: A Student Abstract", "comment": null, "summary": "Ensuring factual consistency in generated text is crucial for reliable natural language processing applications. However, there is a lack of evaluation tools for factual consistency in Russian texts, as existing tools primarily focus on English corpora. To bridge this gap, we introduce AlignRuScore, a comprehensive adaptation of the AlignScore metric for Russian. To adapt the metric, we fine-tuned a RuBERT-based alignment model with task-specific classification and regression heads on Russian and translated English datasets. Our results demonstrate that a unified alignment metric can be successfully ported to Russian, laying the groundwork for robust multilingual factual consistency evaluation. We release the translated corpora, model checkpoints, and code to support further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AlignRuScore\uff0c\u901a\u8fc7\u5fae\u8c03RuBERT\u6a21\u578b\uff0c\u4f7fAlignScore\u9002\u7528\u4e8e\u4fc4\u8bed\u6587\u672c\uff0c\u5b9e\u73b0\u4e86\u591a\u8bed\u8a00\u4e8b\u5b9e\u4e00\u81f4\u6027\u8bc4\u4f30\u7684\u57fa\u7840\u5efa\u8bbe\uff0c\u5e76\u516c\u5f00\u4e86\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u4e00\u81f4\u6027\u8bc4\u4f30\u5de5\u5177\u4e3b\u8981\u9488\u5bf9\u82f1\u6587\u8bed\u6599\uff0c\u7f3a\u4e4f\u9488\u5bf9\u4fc4\u8bed\u6587\u672c\u7684\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u57fa\u4e8eRuBERT\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u7ed3\u5408\u4efb\u52a1\u7279\u5b9a\u7684\u5206\u7c7b\u548c\u56de\u5f52\u5934\uff0c\u8fdb\u884c\u4e86\u5fae\u8c03\u4ee5\u9002\u914d\u4fc4\u8bed\u6587\u672c\u3002", "result": "\u6210\u529f\u5c06\u7edf\u4e00\u7684AlignScore\u4e8b\u5b9e\u4e00\u81f4\u6027\u8bc4\u4f30\u6307\u6807\u79fb\u690d\u5230\u4fc4\u8bed\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "AlignRuScore\u4e3a\u4fc4\u8bed\u751f\u6210\u6587\u672c\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\uff0c\u63a8\u52a8\u4e86\u591a\u8bed\u8a00\u53ef\u9760\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.07193", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07193", "abs": "https://arxiv.org/abs/2512.07193", "authors": ["Manthan Shenoy", "Andreas Rausch"], "title": "Towards Benchmarking Design Pattern Detection Under Obfuscation: Reproducing and Evaluating Attention-Based Detection Method", "comment": "Pre-peer-review version of the paper submitted to the Workshop Track of the European Conference on Software Architecture (ECSA 2025), Springer LNCS 15982. Dataset: https://github.com/manthan410/Benchmark_dpd_att. Version of Record: https://doi.org/10.1007/978-3-032-04403-7_13", "summary": "This paper investigates the semantic robustness of attention-based classifiers for design pattern detection, particularly focusing on their reliance on structural and behavioral semantics. We reproduce the DPDAtt, an attention-based design pattern detection approach using learning-based classifiers, and evaluate its performance under obfuscation. To this end, we curate an obfuscated version of the DPDAtt Corpus, where the name identifiers in code such as class names, method names, etc., and string literals like print statements and comment blocks are replaced while preserving control flow, inheritance, and logic. Our findings reveal that these trained classifiers in DPDAtt depend significantly on superficial syntactic features, leading to substantial misclassification when such cues are removed through obfuscation. This work highlights the need for more robust detection tools capable of capturing deeper semantic meanings in source code. We propose our curated Obfuscated corpus (containing 34 Java source files) as a reusable proof-of-concept benchmark for evaluating state-of-the-art design pattern detectors on their true semantic generalization capabilities.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u6ce8\u610f\u529b\u673a\u5236\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u5668\u5728\u4ee3\u7801\u6df7\u6dc6\u4e0b\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u5176\u4e3b\u8981\u4f9d\u8d56\u6d45\u5c42\u8bed\u6cd5\u7279\u5f81\uff0c\u63d0\u51fa\u4e00\u4e2a\u6df7\u6dc6\u8bed\u6599\u5e93\u4f5c\u4e3a\u8bed\u4e49\u6cdb\u5316\u80fd\u529b\u6d4b\u8bd5\u57fa\u51c6\u3002", "motivation": "\u63a2\u7a76\u73b0\u6709\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u65b9\u6cd5\u662f\u5426\u771f\u6b63\u4f9d\u8d56\u4e8e\u4ee3\u7801\u7684\u6df1\u5c42\u7ed3\u6784\u548c\u884c\u4e3a\u8bed\u4e49\uff0c\u907f\u514d\u4ec5\u4f9d\u8d56\u5bb9\u6613\u88ab\u6df7\u6dc6\u624b\u6bb5\u7834\u574f\u7684\u6d45\u5c42\u7279\u5f81\u3002", "method": "\u91cd\u73b0\u5b9e\u9a8c\u5e76\u8bc4\u4f30\u4e86DPDAtt\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5305\u542b\u540d\u79f0\u6807\u8bc6\u7b26\u548c\u5b57\u7b26\u4e32\u5b57\u9762\u91cf\u88ab\u66ff\u6362\u4f46\u63a7\u5236\u6d41\u7b49\u8bed\u4e49\u4fdd\u6301\u4e0d\u53d8\u7684\u6df7\u6dc6\u8bed\u6599\u5e93\uff0c\u4ee5\u6d4b\u8bd5\u5206\u7c7b\u5668\u7684\u9c81\u68d2\u6027\u3002", "result": "\u7ed3\u679c\u8868\u660eDPDAtt\u5206\u7c7b\u5668\u9ad8\u5ea6\u4f9d\u8d56\u8868\u9762\u8bed\u6cd5\u7279\u5f81\uff0c\u4ee3\u7801\u6df7\u6dc6\u663e\u8457\u964d\u4f4e\u5176\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u8868\u660e\u5176\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "\u8be5\u8bba\u6587\u63ed\u793a\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u5206\u7c7b\u5668\u5728\u8bed\u4e49\u9c81\u68d2\u6027\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5bf9\u6d45\u5c42\u8bed\u6cd5\u7279\u5f81\u7684\u4f9d\u8d56\uff0c\u5bfc\u81f4\u5728\u4ee3\u7801\u6df7\u6dc6\u540e\u68c0\u6d4b\u6548\u679c\u663e\u8457\u4e0b\u964d\u3002"}}
{"id": "2512.06656", "categories": ["cs.CL", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.06656", "abs": "https://arxiv.org/abs/2512.06656", "authors": ["Kwabena Yamoah", "Cass Dykeman"], "title": "The Online Discourse of Virtual Reality and Anxiety", "comment": "Three tables and two figures. Unfortunately, I did not formally register the dataset prior to conducting the analysis", "summary": "VR in the treatment of clinical concerns such as generalized anxiety disorder or social anxiety. VR has created additional pathways to support patient well-being and care. Understanding online discussion of what users think about this technology may further support its efficacy. The purpose of this study was to employ a corpus linguistic methodology to identify the words and word networks that shed light on the online discussion of virtual reality and anxiety. Using corpus linguistics, frequently used words in discussion along with collocation were identified by utilizing Sketch Engine software. The results of the study, based upon the English Trends corpus, identified VR, Oculus, and headset as the most frequently discussed within the VR and anxiety subcorpus. These results point to the development of the virtual system, along with the physical apparatus that makes viewing and engaging with the virtual environment possible. Additional results point to collocation of prepositional phrases such as of virtual reality, in virtual reality, and for virtual reality relating to the design, experience, and development, respectively. These findings offer new perspective on how VR and anxiety together are discussed in general discourse and offer pathways for future opportunities to support counseling needs through development and accessibility. Keywords: anxiety disorders, corpus linguistics, Sketch Engine, and virtual reality VR", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u8bed\u6599\u5e93\u8bed\u8a00\u5b66\u65b9\u6cd5\u5206\u6790\u4e86\u5173\u4e8eVR\u6cbb\u7597\u7126\u8651\u7684\u7f51\u7edc\u8ba8\u8bba\uff0c\u53d1\u73b0\u6838\u5fc3\u5173\u6ce8\u70b9\u5728\u4e8e\u865a\u62df\u7cfb\u7edf\u53ca\u8bbe\u5907\uff0c\u4e3a\u672a\u6765\u4e34\u5e8a\u652f\u6301\u548c\u6280\u672f\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u7406\u89e3\u7528\u6237\u5bf9VR\u6cbb\u7597\u7126\u8651\u75c7\u6280\u672f\u7684\u5728\u7ebf\u8ba8\u8bba\uff0c\u4ece\u800c\u4fc3\u8fdb\u8be5\u6280\u672f\u7684\u6548\u679c\u63d0\u5347\u548c\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u91c7\u7528\u8bed\u6599\u5e93\u8bed\u8a00\u5b66\u65b9\u6cd5\uff0c\u5229\u7528Sketch Engine\u8f6f\u4ef6\u5206\u6790\u82f1\u8bed\u8d8b\u52bf\u8bed\u6599\u5e93\u4e2d\u5173\u4e8eVR\u4e0e\u7126\u8651\u7684\u5e38\u7528\u8bcd\u53ca\u642d\u914d\u3002", "result": "\u8bc6\u522b\u51faVR\u3001Oculus\u548c\u5934\u6234\u8bbe\u5907\u4e3a\u8ba8\u8bba\u4e2d\u6700\u5e38\u89c1\u8bcd\u6c47\uff0c\u5e76\u53d1\u73b0\u4e0e\u865a\u62df\u73b0\u5b9e\u76f8\u5173\u7684\u4ecb\u8bcd\u77ed\u8bed\u642d\u914d\uff0c\u63ed\u793a\u4e86\u8bbe\u8ba1\u3001\u4f53\u9a8c\u548c\u5f00\u53d1\u7b49\u65b9\u9762\u7684\u4fe1\u606f\u3002", "conclusion": "VR\u6280\u672f\u5728\u7126\u8651\u75c7\u6cbb\u7597\u4e2d\u7684\u8ba8\u8bba\u4e3b\u8981\u56f4\u7ed5\u865a\u62df\u7cfb\u7edf\u53ca\u7269\u7406\u8bbe\u5907\u5c55\u5f00\uff0c\u663e\u793a\u51fa\u8be5\u6280\u672f\u5728\u60a3\u8005\u5173\u6000\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.07261", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07261", "abs": "https://arxiv.org/abs/2512.07261", "authors": ["Yusei Ishimizu", "Takuto Yamauchi", "Sinan Chen", "Jinyu Cai", "Jialong Li", "Kenji Tei"], "title": "Automatic Syntax Error Repair for Discrete Controller Synthesis using Large Language Model", "comment": null, "summary": "Discrete Controller Synthesis (DCS) is a powerful formal method for automatically generating specifications of discrete event systems. However, its practical adoption is often hindered by the highly specialized nature of formal models written in languages such as FSP and FLTL. In practice, syntax errors in modeling frequently become an important bottleneck for developers-not only disrupting the workflow and reducing productivity, but also diverting attention from higher-level semantic design. To this end, this paper presents an automated approach that leverages Large Language Models (LLMs) to repair syntax errors in DCS models using a well-designed, knowledge-informed prompting strategy. Specifically, the prompting is derived from a systematic empirical study of common error patterns, identified through expert interviews and student workshops. It equips the LLM with DCS-specific domain knowledge, including formal grammar rules and illustrative examples, to guide accurate corrections. To evaluate our method, we constructed a new benchmark by systematically injecting realistic syntax errors into validated DCS models. The quantitative evaluation demonstrates the high effectiveness of the proposed approach in terms of repair accuracy and its practical utility regarding time, achieving a speedup of 3.46 times compared to human developers. The experimental replication suite, including the benchmark and prompts, is available at https://github.com/Uuusay1432/DCSModelRepair.git", "AI": {"tldr": "\u9488\u5bf9DCS\u6a21\u578b\u8bed\u6cd5\u9519\u8bef\uff0c\u672c\u6587\u5229\u7528\u57fa\u4e8e\u77e5\u8bc6\u7684\u63d0\u793a\u7b56\u7565\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u52a8\u4fee\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u7387\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u79bb\u6563\u63a7\u5236\u5668\u7efc\u5408\uff08DCS\uff09\u5c3d\u7ba1\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u4e2d\u5e94\u7528\u53d7\u9650\uff0c\u4e3b\u8981\u662f\u56e0\u5efa\u6a21\u8bed\u8a00\uff08\u5982FSP\u548cFLTL\uff09\u8bed\u6cd5\u590d\u6742\uff0c\u4e14\u8bed\u6cd5\u9519\u8bef\u5e38\u5bfc\u81f4\u5f00\u53d1\u6548\u7387\u4f4e\u4e0b\u548c\u6ce8\u610f\u529b\u5206\u6563\u3002", "method": "\u901a\u8fc7\u4e13\u5bb6\u8bbf\u8c08\u4e0e\u5b66\u751f\u8c03\u7814\u7cfb\u7edf\u603b\u7ed3\u5e38\u89c1\u9519\u8bef\u6a21\u5f0f\uff0c\u8bbe\u8ba1\u77e5\u8bc6\u544a\u77e5\u7684\u63d0\u793a\u7b56\u7565\uff0c\u8f93\u5165DCS\u8bed\u6cd5\u89c4\u5219\u548c\u793a\u4f8b\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u6cd5\u9519\u8bef\u4fee\u590d\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u57fa\u4e8e\u77e5\u8bc6\u7684\u63d0\u793a\u7b56\u7565\u6765\u81ea\u52a8\u4fee\u590dDCS\u6a21\u578b\u8bed\u6cd5\u9519\u8bef\u7684\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u542b\u771f\u5b9e\u9519\u8bef\u6ce8\u5165\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u4fee\u590d\u51c6\u786e\u7387\u548c\u6548\u7387\uff08\u6bd4\u4eba\u5de5\u5feb3.46\u500d\uff09\u4e0a\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u7684\u63d0\u793a\u7b56\u7565\u5145\u5206\u53d1\u6325\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9519\u8bef\u4fee\u590d\u4e2d\u7684\u6f5c\u529b\uff0c\u663e\u8457\u4f18\u5316\u4e86DCS\u6a21\u578b\u5f00\u53d1\u7684\u5de5\u4f5c\u6d41\u7a0b\u548c\u6548\u7387\u3002"}}
{"id": "2512.06679", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06679", "abs": "https://arxiv.org/abs/2512.06679", "authors": ["Smitha Muthya Sudheendra", "Mani Deep Cherukuri", "Jaideep Srivastava"], "title": "CMV-Fuse: Cross Modal-View Fusion of AMR, Syntax, and Knowledge Representations for Aspect Based Sentiment Analysis", "comment": null, "summary": "Natural language understanding inherently depends on integrating multiple complementary perspectives spanning from surface syntax to deep semantics and world knowledge. However, current Aspect-Based Sentiment Analysis (ABSA) systems typically exploit isolated linguistic views, thereby overlooking the intricate interplay between structural representations that humans naturally leverage. We propose CMV-Fuse, a Cross-Modal View fusion framework that emulates human language processing by systematically combining multiple linguistic perspectives. Our approach systematically orchestrates four linguistic perspectives: Abstract Meaning Representations, constituency parsing, dependency syntax, and semantic attention, enhanced with external knowledge integration. Through hierarchical gated attention fusion across local syntactic, intermediate semantic, and global knowledge levels, CMV-Fuse captures both fine-grained structural patterns and broad contextual understanding. A novel structure aware multi-view contrastive learning mechanism ensures consistency across complementary representations while maintaining computational efficiency. Extensive experiments demonstrate substantial improvements over strong baselines on standard benchmarks, with analysis revealing how each linguistic view contributes to more robust sentiment analysis.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u79cd\u878d\u5408\u56db\u79cd\u8bed\u8a00\u89c6\u89d2\u548c\u5916\u90e8\u77e5\u8bc6\u7684\u591a\u89c6\u89d2\u878d\u5408\u6846\u67b6CMV-Fuse\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u65b9\u9762\u60c5\u611f\u5206\u6790\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u7684\u65b9\u9762\u60c5\u611f\u5206\u6790\u7cfb\u7edf\u901a\u5e38\u4ec5\u5229\u7528\u5355\u4e00\u7684\u8bed\u8a00\u89c6\u89d2\uff0c\u5ffd\u89c6\u4e86\u8bed\u8a00\u7ed3\u6784\u95f4\u590d\u6742\u7684\u4ea4\u4e92\uff0c\u800c\u4eba\u7c7b\u7406\u89e3\u8bed\u8a00\u65f6\u4f1a\u7efc\u5408\u591a\u79cd\u89c6\u89d2\u4ee5\u83b7\u53d6\u66f4\u51c6\u786e\u7684\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u62bd\u8c61\u610f\u4e49\u8868\u793a\u3001\u6210\u5206\u53e5\u6cd5\u5206\u6790\u3001\u4f9d\u5b58\u53e5\u6cd5\u548c\u8bed\u4e49\u5173\u6ce8\u56db\u79cd\u89c6\u89d2\uff0c\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u95e8\u63a7\u6ce8\u610f\u529b\u878d\u5408\u548c\u7ed3\u6784\u611f\u77e5\u7684\u591a\u89c6\u89d2\u5bf9\u6bd4\u5b66\u4e60\u673a\u5236\u5b9e\u73b0\u591a\u89c6\u89d2\u878d\u5408\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCMV-Fuse\u5728\u5f3a\u57fa\u7ebf\u57fa\u7840\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u5206\u6790\u8868\u660e\u4e0d\u540c\u8bed\u8a00\u89c6\u89d2\u5bf9\u60c5\u611f\u5206\u6790\u7684\u9c81\u68d2\u6027\u5747\u6709\u8d21\u732e\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684CMV-Fuse\u6846\u67b6\u901a\u8fc7\u878d\u5408\u591a\u79cd\u8bed\u8a00\u89c6\u89d2\u663e\u8457\u63d0\u5347\u4e86\u65b9\u9762\u60c5\u611f\u5206\u6790\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u591a\u89c6\u89d2\u878d\u5408\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.07293", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07293", "abs": "https://arxiv.org/abs/2512.07293", "authors": ["Roberto Verdecchia", "Justus Bogner"], "title": "The Human Need for Storytelling: Reflections on Qualitative Software Engineering Research With a Focus Group of Experts", "comment": "Published in ACM SIGSOFT Software Engineering Notes (SEN), Volume 51, Issue 1, 2026", "summary": "From its first adoption in the late 80s, qualitative research has slowly but steadily made a name for itself in what was, and perhaps still is, the predominantly quantitative software engineering (SE) research landscape. As part of our regular column on empirical software engineering (ACM SIGSOFT SEN-ESE), we reflect on the state of qualitative SE research with a focus group of experts. Among other things, we discuss why qualitative SE research is important, how it evolved over time, common impediments faced while practicing it today, and what the future of qualitative SE research might look like. Joining the conversation are Rashina Hoda (Monash University, Australia), Carolyn Seaman (University of Maryland, United States), and Klaas Stol (University College Cork, Ireland). The content of this paper is a faithful account of our conversation from October 25, 2025, which we moderated and edited for our column.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e13\u5bb6\u5bf9\u8bdd\uff0c\u7efc\u8ff0\u4e86\u5b9a\u6027\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u73b0\u72b6\u3001\u610f\u4e49\u53ca\u6311\u6218\uff0c\u5e76\u5c55\u671b\u5176\u672a\u6765\u53d1\u5c55\u3002", "motivation": "\u63a2\u8ba8\u5b9a\u6027\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u91cd\u8981\u6027\u3001\u53d1\u5c55\u5386\u7a0b\u3001\u5f53\u524d\u9762\u4e34\u7684\u5e38\u89c1\u969c\u788d\u53ca\u672a\u6765\u524d\u666f\u3002", "method": "\u901a\u8fc7\u7ec4\u7ec7\u4e13\u5bb6\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\uff0c\u4ee5\u4e09\u4f4d\u77e5\u540d\u5b66\u8005\u7684\u5bf9\u8bdd\u5f62\u5f0f\uff0c\u53cd\u6620\u5b9a\u6027\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u73b0\u72b6\u3002", "result": "\u603b\u7ed3\u4e86\u5b9a\u6027\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u4ef7\u503c\u3001\u6f14\u53d8\u8fc7\u7a0b\u3001\u5b9e\u8df5\u4e2d\u7684\u6311\u6218\u53ca\u672a\u6765\u53d1\u5c55\u8d8b\u52bf\u3002", "conclusion": "\u5b9a\u6027\u7814\u7a76\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u9010\u6e10\u88ab\u91cd\u89c6\uff0c\u867d\u5b58\u5728\u6311\u6218\uff0c\u4f46\u672a\u6765\u524d\u666f\u5e7f\u9614\u3002"}}
{"id": "2512.06681", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06681", "abs": "https://arxiv.org/abs/2512.06681", "authors": ["Amartya Hatua"], "title": "Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment Analysis", "comment": null, "summary": "We present a mechanistic interpretability study of GPT-2 that causally examines how sentiment information is processed across its transformer layers. Using systematic activation patching across all 12 layers, we test the hypothesized two-stage sentiment architecture comprising early lexical detection and mid-layer contextual integration. Our experiments confirm that early layers (0-3) act as lexical sentiment detectors, encoding stable, position specific polarity signals that are largely independent of context. However, all three contextual integration hypotheses: Middle Layer Concentration, Phenomenon Specificity, and Distributed Processing are falsified. Instead of mid-layer specialization, we find that contextual phenomena such as negation, sarcasm, domain shifts etc. are integrated primarily in late layers (8-11) through a unified, non-modular mechanism. These experimental findings provide causal evidence that GPT-2's sentiment computation differs from the predicted hierarchical pattern, highlighting the need for further empirical characterization of contextual integration in large language models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6fc0\u6d3b\u8865\u4e01\u7cfb\u7edf\u6027\u9a8c\u8bc1\u4e86GPT-2\u6a21\u578b\u60c5\u611f\u5904\u7406\u673a\u5236\uff0c\u53d1\u73b0\u65e9\u671f\u5c42\u68c0\u6d4b\u8bcd\u6c47\u60c5\u611f\uff0c\u8fdf\u7f13\u5c42\u7edf\u4e00\u6574\u5408\u4e0a\u4e0b\u6587\uff0c\u5426\u5b9a\u4e86\u4e2d\u671f\u5c42\u7279\u5316\u5047\u8bbe\u3002", "motivation": "\u63a2\u7a76GPT-2\u60c5\u611f\u4fe1\u606f\u5904\u7406\u673a\u5236\uff0c\u9a8c\u8bc1\u60c5\u611f\u8ba1\u7b97\u662f\u5426\u9075\u5faa\u9884\u671f\u7684\u5c42\u7ea7\u67b6\u6784\uff0c\u7279\u522b\u662f\u4e0a\u4e0b\u6587\u6574\u5408\u5728\u4e2d\u671f\u5c42\u7684\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6027\u6fc0\u6d3b\u8865\u4e01\u6280\u672f\uff0c\u5728GPT-2\u7684\u6240\u670912\u4e2aTransformer\u5c42\u4e2d\uff0c\u901a\u8fc7\u56e0\u679c\u5b9e\u9a8c\u68c0\u9a8c\u60c5\u611f\u4fe1\u606f\u5904\u7406\u7684\u4e24\u4e2a\u9636\u6bb5\u67b6\u6784\u53ca\u4e2d\u671f\u5c42\u4e09\u79cd\u4e0a\u4e0b\u6587\u6574\u5408\u5047\u8bf4\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5bf9GPT-2\u6a21\u578b\u7684\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u7814\u7a76\uff0c\u7cfb\u7edf\u6027\u5730\u4f7f\u7528\u6fc0\u6d3b\u8865\u4e01\u6280\u672f\u572812\u5c42Transformer\u4e2d\u8003\u5bdf\u60c5\u611f\u4fe1\u606f\u7684\u5904\u7406\u673a\u5236\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u60c5\u611f\u5904\u7406\u7684\u4e24\u4e2a\u9636\u6bb5\u67b6\u6784\uff1a\u524d\u671f\u7684\u8bcd\u6c47\u60c5\u611f\u68c0\u6d4b\u548c\u4e2d\u671f\u7684\u4e0a\u4e0b\u6587\u6574\u5408\u3002\u7ed3\u679c\u663e\u793a\uff0cGPT-2\u7684\u65e9\u671f\u5c42\uff08\u7b2c0-3\u5c42\uff09\u786e\u5b9e\u4f5c\u4e3a\u8bcd\u6c47\u60c5\u611f\u68c0\u6d4b\u5668\uff0c\u7f16\u7801\u7a33\u5b9a\u4e14\u4f4d\u7f6e\u7279\u5f02\u7684\u6781\u6027\u4fe1\u53f7\uff0c\u4e14\u4e0e\u4e0a\u4e0b\u6587\u57fa\u672c\u65e0\u5173\u3002\u4f46\u5bf9\u4e8e\u4e2d\u671f\u5c42\u7684\u4e0a\u4e0b\u6587\u6574\u5408\uff0c\u4e09\u4e2a\u5047\u8bf4\uff08\u4e2d\u671f\u96c6\u4e2d\u3001\u73b0\u8c61\u7279\u5f02\u6027\u3001\u5206\u5e03\u5f0f\u5904\u7406\uff09\u5747\u672a\u88ab\u652f\u6301\u3002\u76f8\u53cd\uff0c\u8bf8\u5982\u5426\u5b9a\u3001\u8bbd\u523a\u548c\u9886\u57df\u53d8\u5316\u7b49\u4e0a\u4e0b\u6587\u73b0\u8c61\u4e3b\u8981\u5728\u540e\u671f\u5c42\uff08\u7b2c8-11\u5c42\uff09\u901a\u8fc7\u7edf\u4e00\u7684\u975e\u6a21\u5757\u5316\u673a\u5236\u8fdb\u884c\u6574\u5408\u3002\u8fd9\u4e00\u53d1\u73b0\u8868\u660eGPT-2\u7684\u60c5\u611f\u8ba1\u7b97\u673a\u5236\u4e0e\u9884\u6d4b\u7684\u5c42\u7ea7\u7ed3\u6784\u4e0d\u540c\uff0c\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u8bc1\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0a\u4e0b\u6587\u6574\u5408\u7684\u5177\u4f53\u673a\u5236\u3002", "conclusion": "GPT-2\u7684\u60c5\u611f\u5904\u7406\u5e76\u975e\u5982\u9884\u671f\u7684\u4e2d\u671f\u5c42\u7279\u5316\uff0c\u800c\u662f\u65e9\u671f\u5c42\u8bcd\u6c47\u68c0\u6d4b\u4e0e\u540e\u671f\u5c42\u975e\u6a21\u5757\u5316\u7684\u4e0a\u4e0b\u6587\u6574\u5408\u673a\u5236\u3002\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u6574\u5408\u3002"}}
{"id": "2512.07368", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.07368", "abs": "https://arxiv.org/abs/2512.07368", "authors": ["Alex R. Mattukat", "Timo Langstrof", "Horst Lichter"], "title": "Challenges in Developing Secure Software -- Results of an Interview Study in the German Software Industry", "comment": "This paper includes 6 pages, 1 table, 1 figure. It is an English translation of our paper published in the German journal \"Softwaretechnik Trends\": ISSN 0720-8928, vol. 45, no. 4, pp. 2-7, year 2025", "summary": "The damage caused by cybercrime makes the development of secure software inevitable. Although many tools and frameworks exist to support the development of secure software, statistics on cybercrime show no improvement in recent years. To understand the challenges software companies face in developing secure software, we conducted an interview study with 19 industry experts from 12 cross-industry companies. The results of our study show that the challenges are mainly due to high complexity, a lack of security awareness, and unsuitable processes, which are further exacerbated by an immediate lack of skilled personnel. This article presents our study and the challenges we identified, and derives potential research directions from them.", "AI": {"tldr": "\u5b89\u5168\u8f6f\u4ef6\u5f00\u53d1\u56f0\u96be\u91cd\u91cd\uff0c\u4e3b\u8981\u56e0\u590d\u6742\u6027\u3001\u5b89\u5168\u610f\u8bc6\u548c\u6d41\u7a0b\u95ee\u9898\uff0c\u4ee5\u53ca\u4eba\u624d\u7f3a\u4e4f\u3002", "motivation": "\u7f51\u7edc\u72af\u7f6a\u9020\u6210\u7684\u635f\u5931\u4fc3\u4f7f\u5b89\u5168\u8f6f\u4ef6\u7684\u5f00\u53d1\u6210\u4e3a\u5fc5\u7136\uff0c\u4f46\u73b0\u6709\u63aa\u65bd\u672a\u80fd\u663e\u8457\u6539\u5584\u73b0\u72b6\uff0c\u6545\u9700\u6df1\u5165\u7406\u89e3\u8f6f\u4ef6\u4f01\u4e1a\u9762\u4e34\u7684\u5b89\u5168\u5f00\u53d1\u6311\u6218\u3002", "method": "\u91c7\u7528\u8bbf\u8c08\u6cd5\uff0c\u8bbf\u8c08\u4e8619\u4f4d\u6765\u81ea12\u5bb6\u8de8\u884c\u4e1a\u516c\u53f8\u7684\u884c\u4e1a\u4e13\u5bb6\uff0c\u6536\u96c6\u5173\u4e8e\u8f6f\u4ef6\u5b89\u5168\u5f00\u53d1\u7684\u6311\u6218\u3002", "result": "\u901a\u8fc7\u5bf912\u5bb6\u8de8\u884c\u4e1a\u516c\u53f8\u768419\u4f4d\u884c\u4e1a\u4e13\u5bb6\u8fdb\u884c\u8bbf\u8c08\uff0c\u672c\u6587\u53d1\u73b0\u8f6f\u4ef6\u5b89\u5168\u5f00\u53d1\u9762\u4e34\u7684\u4e3b\u8981\u6311\u6218\u662f\u8f6f\u4ef6\u590d\u6742\u6027\u9ad8\u3001\u5b89\u5168\u610f\u8bc6\u4e0d\u8db3\u3001\u8fc7\u7a0b\u4e0d\u9002\u5b9c\u53ca\u7f3a\u4e4f\u4e13\u4e1a\u4eba\u5458\u3002", "conclusion": "\u8f6f\u4ef6\u5b89\u5168\u5f00\u53d1\u7684\u6311\u6218\u4e3b\u8981\u6e90\u4e8e\u590d\u6742\u6027\u3001\u5b89\u5168\u610f\u8bc6\u4e0d\u8db3\u3001\u6d41\u7a0b\u4e0d\u9002\u5b9c\u53ca\u7f3a\u4e4f\u4e13\u4e1a\u4eba\u624d\uff0c\u9700\u8981\u9488\u5bf9\u6027\u7814\u7a76\u548c\u6539\u8fdb\u3002"}}
{"id": "2512.06688", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06688", "abs": "https://arxiv.org/abs/2512.06688", "authors": ["Bowen Jiang", "Yuan Yuan", "Maohao Shen", "Zhuoqun Hao", "Zhangchen Xu", "Zichen Chen", "Ziyi Liu", "Anvesh Rao Vijjini", "Jiashu He", "Hanchao Yu", "Radha Poovendran", "Gregory Wornell", "Lyle Ungar", "Dan Roth", "Sihao Chen", "Camillo Jose Taylor"], "title": "PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory", "comment": "Data is available at https://huggingface.co/datasets/bowen-upenn/PersonaMem-v2", "summary": "Personalization is one of the next milestones in advancing AI capability and alignment. We introduce PersonaMem-v2, the state-of-the-art dataset for LLM personalization that simulates 1,000 realistic user-chatbot interactions on 300+ scenarios, 20,000+ user preferences, and 128k-token context windows, where most user preferences are implicitly revealed to reflect real-world interactions. Using this data, we investigate how reinforcement fine-tuning enables a model to improve its long-context reasoning capabilities for user understanding and personalization. We also develop a framework for training an agentic memory system, which maintains a single, human-readable memory that grows with each user over time.\n  In our experiments, frontier LLMs still struggle with implicit personalization, achieving only 37-48% accuracy. While they support long context windows, reasoning remains the bottleneck for implicit personalization tasks. Using reinforcement fine-tuning, we successfully train Qwen3-4B to outperforms GPT-5, reaching 53% accuracy in implicit personalization. Moreover, our agentic memory framework achieves state-of-the-art 55% accuracy while using 16x fewer input tokens, relying on a 2k-token memory instead of full 32k conversation histories. These results underscore the impact of our dataset and demonstrate agentic memory as a scalable path toward real-world personalized intelligence.", "AI": {"tldr": "\u63d0\u51faPersonaMem-v2\u6570\u636e\u96c6\u548c\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u9690\u5f0f\u4e2a\u6027\u5316\u80fd\u529b\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u7528\u6237\u4e2a\u6027\u5316\u7406\u89e3\u3002", "motivation": "\u63a8\u52a8AI\u4e2a\u6027\u5316\u80fd\u529b\u53d1\u5c55\uff0c\u66f4\u597d\u5730\u7406\u89e3\u548c\u9002\u5e94\u7528\u6237\u9690\u5f0f\u504f\u597d\uff0c\u89e3\u51b3\u73b0\u5b9e\u4ea4\u4e92\u4e2d\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u74f6\u9888\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86PersonaMem-v2\u6570\u636e\u96c6\uff0c\u6a21\u62df1000\u6b21\u73b0\u5b9e\u7528\u6237-\u804a\u5929\u673a\u5668\u4eba\u4ea4\u4e92\uff0c\u5305\u542b300+\u573a\u666f\u548c20,000+\u7528\u6237\u504f\u597d\uff0c\u5e76\u91c7\u7528\u957f\u4e0a\u4e0b\u6587\u7a97\u53e3\u3002\u5229\u7528\u5f3a\u5316\u5fae\u8c03\u8bad\u7ec3\u6a21\u578b\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u9690\u5f0f\u4e2a\u6027\u5316\u7406\u89e3\u3002\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u6846\u67b6\uff0c\u4fdd\u6301\u53ef\u8bfb\u7684\u5355\u4e00\u8bb0\u5fc6\u968f\u7740\u7528\u6237\u4ea4\u4e92\u9010\u6e10\u589e\u957f\u3002", "result": "\u73b0\u6709\u524d\u6cbf\u5927\u6a21\u578b\u5728\u9690\u5f0f\u4e2a\u6027\u5316\u51c6\u786e\u5ea6\u4ec537-48%\u3002\u901a\u8fc7\u5f3a\u5316\u5fae\u8c03\uff0cQwen3-4B\u8fbe53%\uff0c\u8d85\u8d8aGPT-5\u3002\u4ee3\u7406\u8bb0\u5fc6\u6846\u67b6\u5728\u4f7f\u752816\u500d\u66f4\u5c11\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\uff0c\u8fbe55%\u51c6\u786e\u7387\uff0c\u663e\u8457\u63d0\u5347\u6548\u679c\u548c\u6548\u7387\u3002", "conclusion": "PersonaMem-v2\u6570\u636e\u96c6\u548c\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u4e3a\u5b9e\u73b0\u73b0\u5b9e\u4e16\u754c\u4e2a\u6027\u5316\u667a\u80fd\u63d0\u4f9b\u6709\u6548\u8def\u5f84\uff0c\u4ee3\u7406\u8bb0\u5fc6\u901a\u8fc7\u51cf\u5c11\u4e0a\u4e0b\u6587\u8f93\u5165\u4ee4\u4e2a\u6027\u5316\u66f4\u5177\u53ef\u6269\u5c55\u6027\u3002\u5f3a\u5316\u5fae\u8c03\u662f\u63d0\u5347\u9690\u5f0f\u4e2a\u6027\u5316\u63a8\u7406\u80fd\u529b\u7684\u5173\u952e\u65b9\u6cd5\u3002"}}
{"id": "2512.07404", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07404", "abs": "https://arxiv.org/abs/2512.07404", "authors": ["Francisco Ribeiro", "Claudio Spiess", "Prem Devanbu", "Sarah Nadi"], "title": "Do LLMs Trust the Code They Write?", "comment": null, "summary": "Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5b58\u5728\u4ee3\u7801\u6b63\u786e\u6027\u7684\u8868\u793a\uff0c\u901a\u8fc7\u5bf9\u6bd4\u6b63\u786e\u4e0e\u9519\u8bef\u4ee3\u7801\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5229\u7528\u8be5\u8868\u793a\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u65e0\u9700\u6267\u884c\u6d4b\u8bd5\u5373\u53ef\u7b5b\u9009\u66f4\u4f18\u4ee3\u7801\u3002", "motivation": "\u5c3d\u7ba1LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u8f93\u51fa\u7684\u6982\u7387\u5f80\u5f80\u4e0e\u4ee3\u7801\u6b63\u786e\u6027\u4e0d\u76f8\u5173\uff0c\u672c\u6587\u65e8\u5728\u5bfb\u627e\u6a21\u578b\u5185\u90e8\u5bf9\u4ee3\u7801\u6b63\u786e\u6027\u7684\u7f16\u7801\u7279\u5f81\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u6210\u4ee3\u7801\u7684\u53ef\u9760\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u76f8\u540c\u4efb\u52a1\u7684\u6b63\u786e\u4e0e\u9519\u8bef\u4ee3\u7801\u5728LLM\u9690\u85cf\u72b6\u6001\u4e0a\u7684\u5dee\u5f02\uff0c\u63d0\u53d6\u5185\u90e8\u6b63\u786e\u6027\u8868\u793a\uff0c\u57fa\u4e8e\u6b64\u8fdb\u884c\u4ee3\u7801\u6837\u672c\u7684\u8d28\u91cf\u8bc4\u4f30\u548c\u6392\u5e8f\u3002", "result": "\u5728\u56db\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u5185\u90e8\u8868\u793a\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u6982\u7387\u6392\u5e8f\u66f4\u4f18\u7684\u4ee3\u7801\u8d28\u91cf\u7b5b\u9009\u6548\u679c\uff0c\u4e14\u65e0\u9700\u6d4b\u8bd5\u6267\u884c\u3002", "conclusion": "\u6587\u4e2d\u5c55\u793a\u4e86\u5229\u7528LLM\u5185\u90e8\u7684\u6b63\u786e\u6027\u8868\u793a\u53ef\u4ee5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u6982\u7387\u548c\u53e3\u5934\u7f6e\u4fe1\u5ea6\u6392\u5e8f\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.06690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06690", "abs": "https://arxiv.org/abs/2512.06690", "authors": ["Chengbing Wang", "Yang Zhang", "Wenjie Wang", "Xiaoyan Zhao", "Fuli Feng", "Xiangnan He", "Tat-Seng Chua"], "title": "Think-While-Generating: On-the-Fly Reasoning for Personalized Long-Form Generation", "comment": null, "summary": "Preference alignment has enabled large language models (LLMs) to better reflect human expectations, but current methods mostly optimize for population-level preferences, overlooking individual users. Personalization is essential, yet early approaches-such as prompt customization or fine-tuning-struggle to reason over implicit preferences, limiting real-world effectiveness. Recent \"think-then-generate\" methods address this by reasoning before response generation. However, they face challenges in long-form generation: their static one-shot reasoning must capture all relevant information for the full response generation, making learning difficult and limiting adaptability to evolving content. To address this issue, we propose FlyThinker, an efficient \"think-while-generating\" framework for personalized long-form generation. FlyThinker employs a separate reasoning model that generates latent token-level reasoning in parallel, which is fused into the generation model to dynamically guide response generation. This design enables reasoning and generation to run concurrently, ensuring inference efficiency. In addition, the reasoning model is designed to depend only on previous responses rather than its own prior outputs, which preserves training parallelism across different positions-allowing all reasoning tokens for training data to be produced in a single forward pass like standard LLM training, ensuring training efficiency. Extensive experiments on real-world benchmarks demonstrate that FlyThinker achieves better personalized generation while keeping training and inference efficiency.", "AI": {"tldr": "\u63d0\u51faFlyThinker\uff0c\u901a\u8fc7\u5e76\u884c\u63a8\u7406\u4e0e\u751f\u6210\u5b9e\u73b0\u4e2a\u6027\u5316\u957f\u6587\u672c\u751f\u6210\uff0c\u63d0\u5347\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u4e2a\u6027\u5316\u957f\u6587\u672c\u751f\u6210\u65b9\u6cd5\u591a\u4e3a\u5148\u601d\u8003\u540e\u751f\u6210\uff0c\u96be\u4ee5\u6355\u83b7\u5168\u90e8\u4fe1\u606f\u4e14\u8bad\u7ec3\u6548\u7387\u4f4e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u52a8\u6001\u63a8\u7406\u65b9\u6cd5\u63d0\u9ad8\u4e2a\u6027\u5316\u751f\u6210\u6548\u679c\u3002", "method": "\u91c7\u7528\u72ec\u7acb\u63a8\u7406\u6a21\u578b\u751f\u6210\u9010\u8bcd\u6f5c\u5728\u63a8\u7406\u4fe1\u606f\uff0c\u4e0e\u751f\u6210\u6a21\u578b\u878d\u5408\uff0c\u63a8\u7406\u4e0e\u751f\u6210\u5e76\u884c\u8fdb\u884c\uff0c\u8bad\u7ec3\u65f6\u4fdd\u8bc1\u63a8\u7406\u4ec5\u4f9d\u8d56\u4e4b\u524d\u54cd\u5e94\uff0c\u5b9e\u73b0\u5e76\u884c\u8bad\u7ec3\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86FlyThinker\uff0c\u4e00\u79cd\u9ad8\u6548\u7684\u201c\u8fb9\u601d\u8003\u8fb9\u751f\u6210\u201d\u6846\u67b6\uff0c\u7528\u4e8e\u4e2a\u6027\u5316\u957f\u6587\u672c\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4e00\u4e2a\u72ec\u7acb\u7684\u63a8\u7406\u6a21\u578b\u5e76\u884c\u751f\u6210\u6f5c\u5728\u7684\u9010\u8bcd\u63a8\u7406\u4fe1\u606f\uff0c\u5e76\u5c06\u5176\u878d\u5408\u8fdb\u751f\u6210\u6a21\u578b\uff0c\u5b9e\u73b0\u63a8\u7406\u4e0e\u751f\u6210\u7684\u540c\u6b65\u8fdb\u884c\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u548c\u751f\u6210\u7684\u6548\u7387\u3002FlyThinker\u907f\u514d\u4e86\u5148\u524d\u65b9\u6cd5\u4e2d\u201c\u5148\u601d\u8003\u540e\u751f\u6210\u201d\u6240\u9762\u4e34\u7684\u9759\u6001\u5355\u6b21\u63a8\u7406\u96be\u4ee5\u6355\u83b7\u5168\u90e8\u4fe1\u606f\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u8bad\u7ec3\u7684\u5e76\u884c\u6027\u548c\u6548\u7387\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFlyThinker\u5728\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4e2a\u6027\u5316\u751f\u6210\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u9ad8\u6548\u6027\u3002", "conclusion": "FlyThinker\u6210\u529f\u5b9e\u73b0\u4e86\u4e2a\u6027\u5316\u957f\u6587\u672c\u751f\u6210\u4e2d\u7684\u52a8\u6001\u63a8\u7406\u4e0e\u9ad8\u6548\u8bad\u7ec3\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2512.07434", "categories": ["cs.SE", "cs.FL"], "pdf": "https://arxiv.org/pdf/2512.07434", "abs": "https://arxiv.org/abs/2512.07434", "authors": ["Bram Pellen", "Mar\u00eda Bel\u00e9n Rodr\u00edguez", "Frits Vaandrager", "Petra van den Bos"], "title": "Systematic Evaluation of Black-Box Checking for Fast Bug Detection", "comment": "23 pages, 4 figures", "summary": "Combinations of active automata learning, model-based testing and model checking have been successfully used in numerous applications, e.g., for spotting bugs in implementations of major network protocols and to support refactoring of embedded controllers. However, in the large majority of these applications, model checking is only used at the very end, when no counterexample can be found anymore for the latest hypothesis model. This contrasts with the original proposal of black-box checking (BBC) by Peled, Vardi & Yannakakis, which applies model checking for all hypotheses, also the intermediate ones. In this article, we present the first systematic evaluation of the ability of BBC to find bugs quickly, based on 77 benchmarks models from real protocol implementations and controllers for which specifications of safety properties are available. Our main finding are: (a) In cases where the full model can be learned, BBC detects violations of the specifications with just 3.4% of the queries needed by an approach in which model checking is only used for the full model. (b) Even when the full model cannot be learned, BBC is still able to detect many violations of the specification. In particular, BBC manages to detect 94% of the safety properties violations in the challenging RERS 2019 industrial LTL benchmarks. (c) Our results also confirm that BBC is way more effective than existing MBT algorithms in finding deep bugs in implementations.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u9ed1\u76d2\u68c0\u67e5\u65b9\u6cd5\u5728\u5b9e\u9645\u534f\u8bae\u548c\u63a7\u5236\u5668\u4e2d\u5feb\u901f\u53d1\u73b0\u5b89\u5168\u6f0f\u6d1e\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u5176\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u9ad8\u6548\u3001\u66f4\u6709\u6548\u3002", "motivation": "\u73b0\u6709\u5e94\u7528\u4e2d\u6a21\u578b\u68c0\u6d4b\u901a\u5e38\u53ea\u5728\u6700\u7ec8\u6a21\u578b\u65e0\u53cd\u4f8b\u65f6\u4f7f\u7528\uff0cBBC\u5219\u5728\u6240\u6709\u5047\u8bbe\u6a21\u578b\u4e2d\u4f7f\u7528\uff0c\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30BBC\u5feb\u901f\u53d1\u73b0\u6f0f\u6d1e\u7684\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u4e3b\u52a8\u81ea\u52a8\u673a\u5b66\u4e60\u3001\u57fa\u4e8e\u6a21\u578b\u7684\u6d4b\u8bd5\u548c\u6a21\u578b\u68c0\u6d4b\uff0c\u7279\u522b\u662f\u5728\u9ed1\u76d2\u68c0\u67e5\uff08BBC\uff09\u65b9\u6cd5\u4e2d\u5bf9\u6240\u6709\u5047\u8bbe\u6a21\u578b\u5e94\u7528\u6a21\u578b\u68c0\u6d4b\u3002", "result": "BBC\u5728\u5b8c\u5168\u6a21\u578b\u53ef\u5b66\u4e60\u65f6\u4ec5\u75283.4%\u7684\u67e5\u8be2\u5373\u53ef\u68c0\u6d4b\u8fdd\u89c4\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\uff1b\u5728\u65e0\u6cd5\u5b8c\u5168\u5b66\u4e60\u65f6\u4ecd\u80fd\u68c0\u6d4b\u5927\u91cf\u8fdd\u89c4\uff0c\u80fd\u68c0\u6d4b94%\u7684\u5b89\u5168\u6027\u8d28\u8fdd\u89c4\uff0c\u4e14\u6bd4\u73b0\u6709MBT\u7b97\u6cd5\u66f4\u6709\u6548\u53d1\u73b0\u6df1\u5c42\u6f0f\u6d1e\u3002", "conclusion": "\u9ed1\u76d2\u68c0\u67e5\uff08BBC\uff09\u65b9\u6cd5\u5728\u81ea\u52a8\u673a\u5b66\u4e60\u548c\u6d4b\u8bd5\u4e2d\u663e\u8457\u52a0\u901f\u548c\u63d0\u5347\u4e86\u5b89\u5168\u6027\u8d28\u8fdd\u89c4\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u662f\u53d1\u73b0\u5b9e\u73b0\u4e2d\u6df1\u5c42\u6b21\u6f0f\u6d1e\u7684\u66f4\u4f18\u65b9\u6cd5\u3002"}}
{"id": "2512.06694", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06694", "abs": "https://arxiv.org/abs/2512.06694", "authors": ["Aoi Fujita", "Taichi Yamamoto", "Yuri Nakayama", "Ryota Kobayashi"], "title": "TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction", "comment": "15 pages, 4 figures, code available at https://github.com/aoi8716/TopiCLEAR", "summary": "Rapid expansion of social media platforms such as X (formerly Twitter), Facebook, and Reddit has enabled large-scale analysis of public perceptions on diverse topics, including social issues, politics, natural disasters, and consumer sentiment. Topic modeling is a widely used approach for uncovering latent themes in text data, typically framed as an unsupervised classification task. However, traditional models, originally designed for longer and more formal documents, struggle with short social media posts due to limited co-occurrence statistics, fragmented semantics, inconsistent spelling, and informal language. To address these challenges, we propose a new method, TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction. Specifically, each text is embedded using Sentence-BERT (SBERT) and provisionally clustered using Gaussian Mixture Models (GMM). The clusters are then refined iteratively using a supervised projection based on linear discriminant analysis, followed by GMM-based clustering until convergence. Notably, our method operates directly on raw text, eliminating the need for preprocessing steps such as stop word removal. We evaluate our approach on four diverse datasets, 20News, AgNewsTitle, Reddit, and TweetTopic, each containing human-labeled topic information. Compared with seven baseline methods, including a recent SBERT-based method and a zero-shot generative AI method, our approach achieves the highest similarity to human-annotated topics, with significant improvements for both social media posts and online news articles. Additionally, qualitative analysis shows that our method produces more interpretable topics, highlighting its potential for applications in social media data and web content analytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53e5\u5b50\u5d4c\u5165\u548c\u8fed\u4ee3\u805a\u7c7b\u7684\u4e3b\u9898\u63d0\u53d6\u65b9\u6cd5TopiCLEAR\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u77ed\u6587\u672c\u4e3b\u9898\u5efa\u6a21\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u548c\u65b0\u95fb\u6587\u672c\u7684\u4e3b\u9898\u5206\u6790\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u4e3b\u9898\u6a21\u578b\u96be\u4ee5\u5904\u7406\u77ed\u4e14\u975e\u6b63\u5f0f\u7684\u793e\u4ea4\u5a92\u4f53\u6587\u672c\uff0c\u5b58\u5728\u8bed\u4e49\u788e\u7247\u5316\u548c\u62fc\u5199\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u66f4\u9002\u5408\u77ed\u6587\u672c\u7684\u4e3b\u9898\u63d0\u53d6\u65b9\u6cd5\u3002", "method": "\u5229\u7528Sentence-BERT\u8fdb\u884c\u6587\u672c\u5d4c\u5165\uff0c\u521d\u6b65\u901a\u8fc7\u9ad8\u65af\u6df7\u5408\u6a21\u578b\u805a\u7c7b\uff0c\u7ed3\u5408\u7ebf\u6027\u5224\u522b\u5206\u6790\u8fdb\u884c\u76d1\u7763\u6295\u5f71\u8fed\u4ee3\u4f18\u5316\uff0c\u76f4\u81f3\u805a\u7c7b\u6536\u655b\uff0c\u4e14\u65e0\u9700\u9884\u5904\u7406\u505c\u7528\u8bcd\u3002", "result": "\u5728\u56db\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cTopiCLEAR\u65b9\u6cd5\u76f8\u6bd4\u4e03\u79cd\u57fa\u7ebf\u6a21\u578b\uff0c\u5728\u4e0e\u4eba\u5de5\u6807\u6ce8\u4e3b\u9898\u7684\u76f8\u4f3c\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e14\u751f\u6210\u7684\u4e3b\u9898\u66f4\u52a0\u6613\u4e8e\u89e3\u91ca\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684TopiCLEAR\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u4e3b\u9898\u63d0\u53d6\u80fd\u529b\uff0c\u5c24\u5176\u9002\u5408\u77ed\u6587\u672c\u548c\u793e\u4ea4\u5a92\u4f53\u5185\u5bb9\uff0c\u80fd\u591f\u751f\u6210\u66f4\u5177\u89e3\u91ca\u6027\u7684\u4e3b\u9898\u3002"}}
{"id": "2512.07501", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07501", "abs": "https://arxiv.org/abs/2512.07501", "authors": ["Weilin Luo", "Xueyi Liang", "Haotian Deng", "Yanan Liu", "Hai Wan"], "title": "AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution", "comment": null, "summary": "Automatically synthesizing verifiable code from natural language requirements ensures software correctness and reliability while significantly lowering the barrier to adopting the techniques of formal methods. With the rise of large language models (LLMs), long-standing efforts at autoformalization have gained new momentum. However, existing approaches suffer from severe syntactic and semantic errors due to the scarcity of domain-specific pre-training corpora and often fail to formalize implicit knowledge effectively. In this paper, we propose AutoICE, an LLM-driven evolutionary search for synthesizing verifiable C code. It introduces the diverse individual initialization and the collaborative crossover to enable diverse iterative updates, thereby mitigating error propagation inherent in single-agent iterations. Besides, it employs the self-reflective mutation to facilitate the discovery of implicit knowledge. Evaluation results demonstrate the effectiveness of AutoICE: it successfully verifies $90.36$\\% of code, outperforming the state-of-the-art (SOTA) approach. Besides, on a developer-friendly dataset variant, AutoICE achieves a $88.33$\\% verification success rate, significantly surpassing the $65$\\% success rate of the SOTA approach.", "AI": {"tldr": "AutoICE\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u8fdb\u5316\u641c\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u81ea\u52a8\u5408\u6210\u53ef\u9a8c\u8bc1C\u4ee3\u7801\u7684\u6210\u529f\u7387\uff0c\u8d85\u8d8a\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\u3002", "motivation": "\u81ea\u52a8\u4ece\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u5408\u6210\u53ef\u9a8c\u8bc1\u4ee3\u7801\u6709\u52a9\u4e8e\u786e\u4fdd\u8f6f\u4ef6\u6b63\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u9886\u57df\u9884\u8bad\u7ec3\u8bed\u6599\u548c\u96be\u4ee5\u6709\u6548\u5f62\u5f0f\u5316\u9690\u542b\u77e5\u8bc6\uff0c\u5bfc\u81f4\u8bed\u6cd5\u548c\u8bed\u4e49\u9519\u8bef\u8f83\u591a\u3002", "method": "\u63d0\u51faAutoICE\uff0c\u4e00\u79cd\u7ed3\u5408\u591a\u6837\u6027\u4e2a\u4f53\u521d\u59cb\u5316\u3001\u591a\u6837\u534f\u540c\u4ea4\u53c9\u548c\u81ea\u6211\u53cd\u601d\u53d8\u5f02\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u5316\u641c\u7d22\u65b9\u6cd5\uff0c\u4ee5\u5408\u6210\u53ef\u9a8c\u8bc1\u7684C\u4ee3\u7801\u3002", "result": "AutoICE\u9a8c\u8bc1\u6210\u529f\u7387\u8fbe90.36%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002\u5728\u9488\u5bf9\u5f00\u53d1\u8005\u53cb\u597d\u6570\u636e\u96c6\u4e0a\uff0c\u6210\u529f\u7387\u4e3a88.33%\uff0c\u8fdc\u8d85\u73b0\u6709\u65b9\u6cd5\u768465%\u3002", "conclusion": "AutoICE\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u4ee3\u7801\u5408\u6210\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5c24\u5176\u5728\u53d1\u73b0\u9690\u542b\u77e5\u8bc6\u548c\u51cf\u5c11\u9519\u8bef\u4f20\u64ad\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u63a8\u52a8\u4e86\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u5f62\u5f0f\u5316\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2512.06711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06711", "abs": "https://arxiv.org/abs/2512.06711", "authors": ["Yulin Huang", "Yaxuan Luan", "Jinxu Guo", "Xiangchen Song", "Yuchen Liu"], "title": "Parameter-Efficient Fine-Tuning with Differential Privacy for Robust Instruction Adaptation in Large Language Models", "comment": null, "summary": "This study addresses the issues of privacy protection and efficiency in instruction fine-tuning of large-scale language models by proposing a parameter-efficient method that integrates differential privacy noise allocation with gradient clipping in a collaborative optimization framework. The method keeps the backbone model frozen and updates parameters through a low-dimensional projection subspace, while introducing clipping and adaptive noise allocation during gradient computation. This design reduces privacy budget consumption and ensures training stability and robustness. The unified framework combines gradient constraints, noise allocation, and parameter projection, effectively mitigating performance fluctuations and privacy risks in multi-task instruction scenarios. Experiments are conducted across hyperparameter, environment, and data sensitivity dimensions. Results show that the method outperforms baseline models in accuracy, privacy budget, and parameter efficiency, and maintains stable performance under diverse and uncertain data conditions. The findings enrich the theoretical integration of differential privacy and parameter-efficient fine-tuning and demonstrate its practical adaptability in instruction tasks, providing a feasible solution for secure training in complex instruction environments.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5dee\u5206\u9690\u79c1\u548c\u68af\u5ea6\u88c1\u526a\u7684\u53c2\u6570\u9ad8\u6548\u6307\u4ee4\u5fae\u8c03\u65b9\u6cd5\uff0c\u63d0\u5347\u9690\u79c1\u4fdd\u62a4\u4e0e\u8bad\u7ec3\u6548\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6548\u679c\u4f18\u8d8a\u4e14\u7a33\u5b9a\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6307\u4ee4\u5fae\u8c03\u4e2d\u7684\u9690\u79c1\u4fdd\u62a4\u548c\u6548\u7387\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u53c2\u6570\u9ad8\u6548\u65b9\u6cd5\uff0c\u5c06\u5dee\u5206\u9690\u79c1\u566a\u58f0\u5206\u914d\u4e0e\u68af\u5ea6\u88c1\u526a\u7ed3\u5408\uff0c\u5728\u534f\u540c\u4f18\u5316\u6846\u67b6\u4e2d\u51bb\u7ed3\u4e3b\u5e72\u6a21\u578b\uff0c\u4ec5\u66f4\u65b0\u4f4e\u7ef4\u6295\u5f71\u5b50\u7a7a\u95f4\u53c2\u6570\uff0c\u5e76\u5728\u68af\u5ea6\u8ba1\u7b97\u4e2d\u5f15\u5165\u88c1\u526a\u548c\u81ea\u9002\u5e94\u566a\u58f0\u5206\u914d\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u9690\u79c1\u9884\u7b97\u548c\u53c2\u6570\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u5728\u591a\u4efb\u52a1\u3001\u4e0d\u786e\u5b9a\u6027\u6570\u636e\u6761\u4ef6\u4e0b\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e30\u5bcc\u4e86\u5dee\u5206\u9690\u79c1\u4e0e\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u7406\u8bba\u7ed3\u5408\uff0c\u5c55\u793a\u4e86\u5176\u5728\u6307\u4ee4\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u9002\u5e94\u6027\uff0c\u4e3a\u590d\u6742\u6307\u4ee4\u73af\u5883\u4e0b\u7684\u5b89\u5168\u8bad\u7ec3\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.07814", "categories": ["cs.SE", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.07814", "abs": "https://arxiv.org/abs/2512.07814", "authors": ["Hua Yang", "Alejandro Velasco", "Sen Fang", "Bowen Xu", "Denys Poshyvanyk"], "title": "Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach", "comment": "21 pages, 8 figures", "summary": "Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks among different types. We investigate whether distinct PII types vary in their likelihood of being learned and leaked by LLM4Code, and whether this relationship is causal. Our methodology includes building a dataset with diverse PII types, fine-tuning representative models of different scales, computing training dynamics on real PII data, and formulating a structural causal model to estimate the causal effect of learnability on leakage. Results show that leakage risks differ substantially across PII types and correlate with their training dynamics: easy-to-learn instances such as IP addresses exhibit higher leakage, while harder types such as keys and passwords leak less frequently. Ambiguous types show mixed behaviors. This work provides the first causal evidence that leakage risks are type-dependent and offers guidance for developing type-aware and learnability-aware defenses for LLM4Code.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u4ece\u56e0\u679c\u89d2\u5ea6\u8bc1\u660e\u4e86\u4e0d\u540cPII\u7c7b\u578b\u5b58\u5728\u4e0d\u540c\u7a0b\u5ea6\u7684\u6cc4\u9732\u98ce\u9669\uff0c\u5e76\u57fa\u4e8e\u8bad\u7ec3\u52a8\u6001\u63ed\u793a\u4e86\u5176\u5185\u5728\u673a\u5236\uff0c\u6307\u5bfc\u9488\u5bf9\u4e0d\u540cPII\u7c7b\u578b\u7684\u9632\u62a4\u7b56\u7565\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5c06\u4e2a\u4eba\u53ef\u8bc6\u522b\u4fe1\u606f\uff08PII\uff09\u89c6\u4e3a\u5355\u4e00\u7c7b\u522b\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540cPII\u7c7b\u578b\u4e4b\u95f4\u6cc4\u9732\u98ce\u9669\u7684\u5f02\u8d28\u6027\u3002", "method": "\u5efa\u7acb\u5305\u542b\u591a\u79cdPII\u7c7b\u578b\u7684\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u4e0d\u540c\u89c4\u6a21\u7684\u4ee3\u8868\u6027\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u8ba1\u7b97\u771f\u5b9ePII\u6570\u636e\u4e0a\u7684\u8bad\u7ec3\u52a8\u6001\uff0c\u5e76\u6784\u5efa\u7ed3\u6784\u56e0\u679c\u6a21\u578b\u4f30\u8ba1\u5b66\u4e60\u6027\u5bf9\u6cc4\u9732\u7684\u56e0\u679c\u5f71\u54cd\u3002", "result": "\u4e0d\u540cPII\u7c7b\u578b\u7684\u6cc4\u9732\u98ce\u9669\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u4e0e\u5176\u8bad\u7ec3\u52a8\u6001\u76f8\u5173\uff1a\u6613\u4e8e\u5b66\u4e60\u7684PII\u7c7b\u578b\uff08\u5982IP\u5730\u5740\uff09\u6cc4\u9732\u98ce\u9669\u8f83\u9ad8\uff0c\u96be\u4ee5\u5b66\u4e60\u7684\uff08\u5982\u5bc6\u94a5\u548c\u5bc6\u7801\uff09\u6cc4\u9732\u8f83\u5c11\uff0c\u6a21\u7cca\u7c7b\u578b\u8868\u73b0\u4e0d\u4e00\u3002", "conclusion": "PII\u7684\u6cc4\u9732\u98ce\u9669\u4f9d\u8d56\u4e8e\u5176\u7c7b\u578b\u53ca\u5bf9\u5e94\u7684\u5b66\u4e60\u96be\u5ea6\uff0c\u5efa\u8bae\u672a\u6765\u9488\u5bf9\u4e0d\u540c\u7c7b\u578bPII\u91c7\u53d6\u5dee\u5f02\u5316\u3001\u57fa\u4e8e\u5b66\u4e60\u6027\u98ce\u9669\u7684\u9632\u5fa1\u63aa\u65bd\u4ee5\u63d0\u5347LLM4Code\u7684\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\u3002"}}
{"id": "2512.06732", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06732", "abs": "https://arxiv.org/abs/2512.06732", "authors": ["Aarushi Wagh", "Saniya Srivastava"], "title": "\"The Dentist is an involved parent, the bartender is not\": Revealing Implicit Biases in QA with Implicit BBQ", "comment": null, "summary": "Existing benchmarks evaluating biases in large language models (LLMs) primarily rely on explicit cues, declaring protected attributes like religion, race, gender by name. However, real-world interactions often contain implicit biases, inferred subtly through names, cultural cues, or traits. This critical oversight creates a significant blind spot in fairness evaluation. We introduce ImplicitBBQ, a benchmark extending the Bias Benchmark for QA (BBQ) with implicitly cued protected attributes across 6 categories. Our evaluation of GPT-4o on ImplicitBBQ illustrates troubling performance disparity from explicit BBQ prompts, with accuracy declining up to 7% in the \"sexual orientation\" subcategory and consistent decline located across most other categories. This indicates that current LLMs contain implicit biases undetected by explicit benchmarks. ImplicitBBQ offers a crucial tool for nuanced fairness evaluation in NLP.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faImplicitBBQ\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u9690\u6027\u63d0\u793a\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9690\u6027\u504f\u89c1\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u516c\u5e73\u6027\u8bc4\u4f30\u7684\u76f2\u533a\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u4f9d\u8d56\u663e\u6027\u63d0\u793a\u6765\u8bc4\u4f30LLMs\u7684\u504f\u89c1\uff0c\u800c\u73b0\u5b9e\u4ea4\u6d41\u4e2d\u504f\u89c1\u901a\u5e38\u662f\u901a\u8fc7\u540d\u79f0\u3001\u6587\u5316\u7ebf\u7d22\u7b49\u9690\u6027\u65b9\u5f0f\u8868\u73b0\uff0c\u9020\u6210\u8bc4\u4f30\u76f2\u70b9\u3002", "method": "\u63d0\u51fa\u4e86ImplicitBBQ\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6269\u5c55\u4e86Bias Benchmark for QA\uff08BBQ\uff09\uff0c\u5f15\u5165\u4e866\u4e2a\u7c7b\u522b\u7684\u9690\u6027\u4fdd\u62a4\u5c5e\u6027\u8fdb\u884c\u516c\u5e73\u6027\u68c0\u6d4b\u3002", "result": "GPT-4o\u5728ImplicitBBQ\u4e0a\u7684\u8868\u73b0\u660e\u663e\u4e0b\u964d\uff0c\u5728\u201c\u6027\u53d6\u5411\u201d\u5b50\u7c7b\u522b\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe7%\uff0c\u5176\u4ed6\u7c7b\u522b\u4e5f\u666e\u904d\u8868\u73b0\u4e0b\u6ed1\uff0c\u66b4\u9732\u51fa\u9690\u6027\u504f\u89c1\u95ee\u9898\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u663e\u6027\u504f\u89c1\u8bc4\u4f30\u4e0a\u8868\u73b0\u5c1a\u53ef\uff0c\u4f46\u5728\u9690\u6027\u504f\u89c1\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002"}}
{"id": "2512.07824", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07824", "abs": "https://arxiv.org/abs/2512.07824", "authors": ["Rabe Abdalkareem"], "title": "Studying the Role of Reusing Crowdsourcing Knowledge in Software Development", "comment": null, "summary": "Crowdsourcing platforms, such as Stack Overflow, have changed and impacted the software development practice. In these platforms, developers share and reuse their software development and programming experience. Therefore, a plethora of research work focused on crowdsourcing in software engineering and showed that, among other things, crowdsourced development tends to increase developers' productivity and reduce time-to-market. However, in crowdsourcing, the empirical studies of software quality are lacking, and simple questions, such as what developers use the crowdsourcing knowledge for, are unanswered.\n  Therefore, our research focused on studying the impact of reusing crowdsourcing knowledge on software projects. To do so, we conduct several large-scale empirical studies on some of the well-known crowdsourcing platforms, including Stack Overflow and npm. Our results showed that reusing knowledge from these crowdsourcing platforms has the potential to assist software development practice, specifically in the form of reusing crowdsourced code. However, using such knowledge affects the quality of the software in several aspects, such as making the software projects suffer from dependency overhead and increasing the maintenance effort. Based on these findings, we use the gained knowledge to make sound data-driven decisions where we examine software quality assurance methods to mitigate the risk of relying on crowd sourcing knowledge in software development. We examine the use of continuous integration (CI). Our analysis showed how CI can be improved to increase developers' productivity and save their resources.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u5206\u6790\u4e86\u590d\u7528\u4f17\u5305\u5e73\u53f0\u77e5\u8bc6\u5bf9\u8f6f\u4ef6\u9879\u76ee\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5176\u6709\u52a9\u5f00\u53d1\u4f46\u4e5f\u589e\u52a0\u8d28\u91cf\u98ce\u9669\uff0c\u63d0\u51fa\u6539\u8fdb\u6301\u7eed\u96c6\u6210\u4ee5\u63d0\u5347\u8d28\u91cf\u4fdd\u969c\u548c\u5f00\u53d1\u6548\u7387\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u4f17\u5305\u7684\u7ecf\u9a8c\u6027\u7814\u7a76\u7f3a\u4e4f\uff0c\u7279\u522b\u662f\u5173\u4e8e\u4f17\u5305\u77e5\u8bc6\u88ab\u5f00\u53d1\u8005\u5982\u4f55\u4f7f\u7528\u53ca\u5176\u5bf9\u8f6f\u4ef6\u8d28\u91cf\u7684\u5f71\u54cd\u8fd9\u4e00\u57fa\u7840\u95ee\u9898\u672a\u5f97\u5230\u89e3\u7b54\u3002", "method": "\u5bf9\u591a\u4e2a\u77e5\u540d\u4f17\u5305\u5e73\u53f0\u5982Stack Overflow\u548cnpm\u8fdb\u884c\u4e86\u5927\u89c4\u6a21\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5206\u6790\u4e86\u4f17\u5305\u77e5\u8bc6\u590d\u7528\u5bf9\u8f6f\u4ef6\u9879\u76ee\u7684\u5f71\u54cd\uff0c\u5e76\u63a2\u8ba8\u4e86\u6301\u7eed\u96c6\u6210(CI)\u5728\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u969c\u4e2d\u7684\u5e94\u7528\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u590d\u7528\u4f17\u5305\u5e73\u53f0\u4e0a\u7684\u77e5\u8bc6\u5c24\u5176\u662f\u4ee3\u7801\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u8f6f\u4ef6\u5f00\u53d1\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u4f9d\u8d56\u5f00\u9500\u548c\u7ef4\u62a4\u5de5\u4f5c\u91cf\u589e\u52a0\u7b49\u8d28\u91cf\u95ee\u9898\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u901a\u8fc7\u6539\u8fdb\u6301\u7eed\u96c6\u6210\u6d41\u7a0b\u6765\u63d0\u5347\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u5e76\u8282\u7701\u8d44\u6e90\u3002", "conclusion": "\u590d\u7528\u4f17\u5305\u77e5\u8bc6\u5728\u4fc3\u8fdb\u8f6f\u4ef6\u5f00\u53d1\u6548\u7387\u7684\u540c\u65f6\uff0c\u4f1a\u5f15\u5165\u8d28\u91cf\u98ce\u9669\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u548c\u6539\u8fdb\u6301\u7eed\u96c6\u6210\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u98ce\u9669\uff0c\u63d0\u5347\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u969c\u80fd\u529b\u3002"}}
{"id": "2512.06734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06734", "abs": "https://arxiv.org/abs/2512.06734", "authors": ["Subrit Dikshit", "Ritu Tiwari", "Priyank Jain"], "title": "A Patient-Doctor-NLP-System to contest inequality for less privileged", "comment": "19 pages, 6 figures", "summary": "Transfer Learning (TL) has accelerated the rapid development and availability of large language models (LLMs) for mainstream natural language processing (NLP) use cases. However, training and deploying such gigantic LLMs in resource-constrained, real-world healthcare situations remains challenging. This study addresses the limited support available to visually impaired users and speakers of low-resource languages such as Hindi who require medical assistance in rural environments. We propose PDFTEMRA (Performant Distilled Frequency Transformer Ensemble Model with Random Activations), a compact transformer-based architecture that integrates model distillation, frequency-domain modulation, ensemble learning, and randomized activation patterns to reduce computational cost while preserving language understanding performance. The model is trained and evaluated on medical question-answering and consultation datasets tailored to Hindi and accessibility scenarios, and its performance is compared against standard NLP state-of-the-art model baselines. Results demonstrate that PDFTEMRA achieves comparable performance with substantially lower computational requirements, indicating its suitability for accessible, inclusive, low-resource medical NLP applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7d27\u51d1\u9ad8\u6548\u7684Transformer\u6a21\u578bPDFTEMRA\uff0c\u4e13\u4e3a\u8d44\u6e90\u53d7\u9650\u533b\u7597\u573a\u666f\u4e2d\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u89c6\u89c9\u969c\u788d\u7528\u6237\u8bbe\u8ba1\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u7684\u771f\u5b9e\u4e16\u754c\u533b\u7597\u73af\u5883\u4e2d\uff0c\u89c6\u89c9\u969c\u788d\u7528\u6237\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u5370\u5730\u8bed\uff09\u4f7f\u7528\u8005\u5728\u533b\u7597\u8f85\u52a9\u4e0a\u7684\u652f\u6301\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86PDFTEMRA\u6a21\u578b\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684\u5c0f\u578b\u67b6\u6784\uff0c\u7ed3\u5408\u4e86\u6a21\u578b\u84b8\u998f\u3001\u9891\u57df\u8c03\u5236\u3001\u96c6\u6210\u5b66\u4e60\u548c\u968f\u673a\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u4ee5\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u540c\u65f6\u4fdd\u6301\u8bed\u8a00\u7406\u89e3\u6027\u80fd\u3002", "result": "PDFTEMRA\u5728\u5b9a\u5236\u7684\u533b\u7597\u95ee\u7b54\u548c\u54a8\u8be2\u6570\u636e\u96c6\u4e0a\uff0c\u9488\u5bf9\u5370\u5730\u8bed\u548c\u65e0\u969c\u788d\u573a\u666f\u8fdb\u884c\u4e86\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0c\u8868\u73b0\u51fa\u4e0e\u6700\u5148\u8fdbNLP\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "PDFTEMRA\u9002\u7528\u4e8e\u65e0\u969c\u788d\u3001\u5305\u5bb9\u6027\u5f3a\u7684\u4f4e\u8d44\u6e90\u533b\u7597\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5e94\u7528\uff0c\u80fd\u591f\u4ee5\u8f83\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u5b9e\u73b0\u4e0e\u5148\u8fdb\u6a21\u578b\u76f8\u5f53\u7684\u6548\u679c\u3002"}}
{"id": "2512.07666", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.07666", "abs": "https://arxiv.org/abs/2512.07666", "authors": ["Zeqi Chen", "Zhaoyang Chu", "Yi Gui", "Feng Guo", "Yao Wan", "Chuan Shi"], "title": "Bridging Code Graphs and Large Language Models for Better Code Understanding", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies have explored graphaugmented prompting and structure-aware pretraining, they either suffer from prompt length constraints or require task-specific architectural changes that are incompatible with large-scale instructionfollowing LLMs. To address these limitations, this paper proposes CGBridge, a novel plug-and-play method that enhances LLMs with Code Graph information through an external, trainable Bridge module. CGBridge first pre-trains a code graph encoder via selfsupervised learning on a large-scale dataset of 270K code graphs to learn structural code semantics. It then trains an external module to bridge the modality gap among code, graph, and text by aligning their semantics through cross-modal attention mechanisms. Finally, the bridge module generates structure-informed prompts, which are injected into a frozen LLM, and is fine-tuned for downstream code intelligence tasks. Experiments show that CGBridge achieves notable improvements over both the original model and the graphaugmented prompting method. Specifically, it yields a 16.19% and 9.12% relative gain in LLM-as-a-Judge on code summarization, and a 9.84% and 38.87% relative gain in Execution Accuracy on code translation. Moreover, CGBridge achieves over 4x faster inference than LoRA-tuned models, demonstrating both effectiveness and efficiency in structure-aware code understanding.", "AI": {"tldr": "CGBridge\u901a\u8fc7\u5f15\u5165\u53ef\u8bad\u7ec3\u6865\u63a5\u6a21\u5757\uff0c\u5c06\u4ee3\u7801\u56fe\u7ed3\u6784\u4fe1\u606f\u6574\u5408\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u7684\u6027\u80fd\u5927\u5e45\u63d0\u5347\u548c\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u73b0\u6709LLM\u5728\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u4e2d\u56e0\u7ebf\u6027\u5316\u7684token\u5e8f\u5217\u9650\u5236\uff0c\u96be\u4ee5\u5145\u5206\u7406\u89e3\u7a0b\u5e8f\u7ed3\u6784\u8bed\u4e49\uff0c\u4e14\u73b0\u6709\u56fe\u589e\u5f3a\u65b9\u6cd5\u5b58\u5728\u63d0\u793a\u957f\u5ea6\u9650\u5236\u6216\u9700\u8981\u7279\u5b9a\u67b6\u6784\u6539\u52a8\uff0c\u4e0d\u5229\u4e8e\u5927\u89c4\u6a21\u6307\u4ee4\u9075\u5faa\u578bLLM\u7684\u5e94\u7528\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u3001\u6a21\u5757\u5316\u4e14\u517c\u5bb9\u6027\u7684\u7ed3\u6784\u611f\u77e5\u589e\u5f3a\u65b9\u6848\u3002", "method": "\u65b9\u6cd5\u5305\u62ec\u4e09\u4e2a\u6b65\u9aa4\uff1a1) \u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u4ee3\u7801\u56fe\u7f16\u7801\u5668\u4ee5\u6355\u6349\u7a0b\u5e8f\u7ed3\u6784\u8bed\u4e49\uff1b2) \u8bad\u7ec3\u5916\u90e8\u6865\u63a5\u6a21\u5757\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u5bf9\u9f50\u4ee3\u7801\u3001\u56fe\u548c\u6587\u672c\u8bed\u4e49\uff1b3) \u6865\u63a5\u6a21\u5757\u751f\u6210\u7ed3\u6784\u611f\u77e5\u63d0\u793a\u6ce8\u5165\u51bb\u7ed3\u7684LLM\u4e2d\u5fae\u8c03\u5b8c\u6210\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86CGBridge\uff0c\u4e00\u79cd\u901a\u8fc7\u5916\u90e8\u53ef\u8bad\u7ec3\u6865\u63a5\u6a21\u5757\uff0c\u5c06\u4ee3\u7801\u56fe\u4fe1\u606f\u589e\u5f3a\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9884\u8bad\u7ec3\u4ee3\u7801\u56fe\u7f16\u7801\u5668\u5b66\u4e60\u7ed3\u6784\u8bed\u4e49\uff0c\u5229\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u9f50\u4ee3\u7801\u3001\u56fe\u548c\u6587\u672c\u7684\u8bed\u4e49\uff0c\u5e76\u751f\u6210\u7ed3\u6784\u611f\u77e5\u7684\u63d0\u793a\u6ce8\u5165\u51bb\u7ed3\u7684LLM\u4e2d\u8fdb\u884c\u5fae\u8c03\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cCGBridge\u5728\u4ee3\u7801\u603b\u7ed3\u548c\u4ee3\u7801\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u76f8\u8f83\u4e8e\u539f\u6a21\u578b\u548c\u56fe\u589e\u5f3a\u63d0\u793a\u65b9\u6cd5\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u63a8\u7406\u901f\u5ea6\u8d85\u8fc7LoRA\u5fae\u8c03\u6a21\u578b4\u500d\uff0c\u517c\u5177\u6548\u679c\u548c\u6548\u7387\u3002", "conclusion": "CGBridge\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u63d0\u793a\u957f\u5ea6\u9650\u5236\u548c\u7ed3\u6784\u611f\u77e5\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u7684\u8868\u73b0\u548c\u63a8\u7406\u6548\u7387\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f5c\u4e3a\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u589e\u5f3a\u65b9\u6cd5\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.06744", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06744", "abs": "https://arxiv.org/abs/2512.06744", "authors": ["Rajeev Ranjan"], "title": "One Word Is Not Enough: Simple Prompts Improve Word Embeddings", "comment": null, "summary": "Text embedding models are designed for sentence-level applications like retrieval and semantic similarity, and are primarily evaluated on sentence-level benchmarks. Their behavior on isolated words is less understood. We show that simply prepending semantic prompts to words before embedding substantially improves word similarity correlations. Testing 7 text embedding models, including text-embedding-3-large (OpenAI), embed-english-v3.0 (Cohere), voyage-3(Voyage AI), all-mpnet-base-v2, and Qwen3-Embedding-8B, on 3 standard benchmarks (SimLex-999, WordSim-353, MEN-3000), we find that prompts like \"meaning: {word}\" or \"Represent the semantic concept: {word}\" improve Spearman correlations by up to +0.29 on SimLex-999. Some models fail completely on bare words (correlation = 0) but recover with prompts (+0.73 improvement). Our best results achieve correlation = 0.692 on SimLex-999 with embed-english-v3.0 (Cohere), correlation = 0.811 on WordSim-353, and correlation = 0.855 on MEN-3000 with text-embedding-3-large (OpenAI). These results outperform classic static embeddings like Word2Vec (correlation = 0.40) and even the best static method LexVec (correlation = 0.48) on SimLex-999, establishing a new state-of-the-art for pure embedding methods. This zero-shot technique requires no training and works with any text embedding model.", "AI": {"tldr": "\u5411\u8bcd\u8bed\u524d\u6dfb\u52a0\u8bed\u4e49\u63d0\u793a\u8bcd\u80fd\u663e\u8457\u589e\u5f3a\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u8bcd\u8bed\u76f8\u4f3c\u5ea6\u8868\u73b0\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u5373\u53ef\u63d0\u5347\u591a\u79cd\u6a21\u578b\u6548\u679c\uff0c\u8d85\u8d8a\u7ecf\u5178\u9759\u6001\u8bcd\u5411\u91cf\u3002", "motivation": "\u76ee\u524d\u6587\u672c\u5d4c\u5165\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u53e5\u5b50\u7ea7\u4efb\u52a1\u8bbe\u8ba1\uff0c\u7f3a\u4e4f\u5bf9\u5b64\u7acb\u8bcd\u8bed\u8bed\u4e49\u8868\u73b0\u7684\u6df1\u5165\u7406\u89e3\uff0c\u90e8\u5206\u6a21\u578b\u88f8\u8bcd\u5d4c\u5165\u8868\u73b0\u4e0d\u4f73\uff0c\u7814\u7a76\u5982\u4f55\u63d0\u5347\u8bcd\u8bed\u5c42\u9762\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u6210\u4e3a\u4e9f\u5f85\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5728\u76ee\u6807\u8bcd\u524d\u9884\u7f6e\u5982\u201cmeaning: {word}\u201d\u6216\u201cRepresent the semantic concept: {word}\u201d\u7684\u8bed\u4e49\u63d0\u793a\u8bcd\uff0c\u8c03\u6574\u8f93\u5165\u7ed9\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u4ece\u800c\u63d0\u5347\u8bcd\u5411\u91cf\u7684\u8bed\u4e49\u8868\u793a\u80fd\u529b\uff0c\u6700\u7ec8\u901a\u8fc7\u6807\u51c6\u57fa\u51c6\u6d4b\u8bc4\u76f8\u5173\u5ea6\u63d0\u5347\u6548\u679c\u3002", "result": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6587\u672c\u5d4c\u5165\u6a21\u578b\u5728\u5b64\u7acb\u8bcd\u8bed\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u4e0a\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u901a\u8fc7\u5728\u8bcd\u8bed\u524d\u6dfb\u52a0\u8bed\u4e49\u63d0\u793a\u8bcd\u663e\u8457\u63d0\u5347\u8bcd\u8bed\u76f8\u4f3c\u5ea6\u76f8\u5173\u6027\u3002\u5b9e\u9a8c\u6d4b\u8bd5\u4e867\u79cd\u6587\u672c\u5d4c\u5165\u6a21\u578b\uff0c\u5728SimLex-999\u3001WordSim-353\u3001MEN-3000\u4e09\u4e2a\u57fa\u51c6\u4e0a\uff0c\u63d0\u793a\u8bcd\u65b9\u6cd5\u4f7fSpearman\u76f8\u5173\u7cfb\u6570\u6700\u5927\u63d0\u53470.29\uff0c\u6709\u4e9b\u6a21\u578b\u5bf9\u88f8\u8bcd\u8868\u73b0\u51e0\u4e4e\u4e3a\u96f6\uff0c\u4f46\u7ecf\u8fc7\u63d0\u793a\u8bcd\u5904\u7406\u540e\u76f8\u5173\u5ea6\u63d0\u5347\u81f30.73\u3002\u6700\u4f18\u6a21\u578b\u5728SimLex-999\u8fbe\u52300.692\uff0c\u8d85\u8fc7\u4e86\u7ecf\u5178\u9759\u6001\u5d4c\u5165Word2Vec\u76840.40\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86LexVec\u76840.48\uff0c\u786e\u7acb\u4e86\u6587\u672c\u5d4c\u5165\u65b9\u6cd5\u7684\u65b0\u6807\u6746\u3002\u8be5\u65b9\u6cd5\u4e3a\u96f6\u6837\u672c\u6280\u672f\uff0c\u65e0\u9700\u8bad\u7ec3\uff0c\u53ef\u9002\u7528\u4e8e\u4efb\u4f55\u6587\u672c\u5d4c\u5165\u6a21\u578b\u3002", "conclusion": "\u5728\u5b64\u7acb\u8bcd\u8bed\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u4efb\u52a1\u4e2d\uff0c\u7b80\u5355\u7684\u8bed\u4e49\u63d0\u793a\u8bcd\u9884\u7f6e\u7b56\u7565\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5d4c\u5165\u6a21\u578b\u7684\u6027\u80fd\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u4f20\u7edf\u9759\u6001\u8bcd\u5411\u91cf\u65b9\u6cd5\uff0c\u4e14\u8be5\u65b9\u6cd5\u96f6\u8bad\u7ec3\u6210\u672c\u4e14\u5177\u901a\u7528\u6027\u3002"}}
{"id": "2512.06751", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.06751", "abs": "https://arxiv.org/abs/2512.06751", "authors": ["Seungyeon Jwa", "Daechul Ahn", "Reokyoung Kim", "Dongyeop Kang", "Jonghyun Choi"], "title": "Becoming Experienced Judges: Selective Test-Time Learning for Evaluators", "comment": null, "summary": "Automatic evaluation with large language models, commonly known as LLM-as-a-judge, is now standard across reasoning and alignment tasks. Despite evaluating many samples in deployment, these evaluators typically (i) treat each case independently, missing the opportunity to accumulate experience, and (ii) rely on a single fixed prompt for all cases, neglecting the need for sample-specific evaluation criteria. We introduce Learning While Evaluating (LWE), a framework that allows evaluators to improve sequentially at inference time without requiring training or validation sets. LWE maintains an evolving meta-prompt that (i) produces sample-specific evaluation instructions and (ii) refines itself through self-generated feedback. Furthermore, we propose Selective LWE, which updates the meta-prompt only on self-inconsistent cases, focusing computation where it matters most. This selective approach retains the benefits of sequential learning while being far more cost-effective. Across two pairwise comparison benchmarks, Selective LWE outperforms strong baselines, empirically demonstrating that evaluators can improve during sequential testing with a simple selective update, learning most from the cases they struggle with.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u987a\u5e8f\u5b66\u4e60\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5LWE\uff0c\u901a\u8fc7\u81ea\u6211\u4f18\u5316\u548c\u9009\u62e9\u6027\u66f4\u65b0\uff0c\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5668\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8bc4\u4f30\u5668\u5728\u63a8\u7406\u548c\u5bf9\u9f50\u4efb\u52a1\u4e2d\u666e\u904d\u4f7f\u7528\uff0c\u4f46\u901a\u5e38\u72ec\u7acb\u5904\u7406\u6bcf\u4e2a\u6837\u672c\uff0c\u65e0\u6cd5\u79ef\u7d2f\u7ecf\u9a8c\u4e14\u56fa\u5b9a\u4f7f\u7528\u540c\u4e00\u63d0\u793a\u8bcd\uff0c\u5ffd\u89c6\u4e86\u6837\u672c\u7279\u5f02\u6027\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u79f0\u4e3aLearning While Evaluating (LWE)\u7684\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u5141\u8bb8\u8bc4\u4f30\u5668\u65e0\u9700\u8bad\u7ec3\u6216\u9a8c\u8bc1\u96c6\u5373\u53ef\u987a\u5e8f\u6539\u8fdb\u3002\u8be5\u65b9\u6cd5\u7ef4\u62a4\u4e00\u4e2a\u4e0d\u65ad\u8fdb\u5316\u7684\u5143\u63d0\u793a\u8bcd\uff0c\u8be5\u63d0\u793a\u4ea7\u751f\u9488\u5bf9\u6837\u672c\u7684\u7279\u5b9a\u8bc4\u4f30\u6307\u4ee4\uff0c\u5e76\u901a\u8fc7\u81ea\u6211\u53cd\u9988\u8fdb\u884c\u81ea\u6211\u4f18\u5316\u3002\u8fdb\u800c\u63d0\u51faSelective LWE\uff0c\u53ea\u9488\u5bf9\u81ea\u6211\u4e0d\u4e00\u81f4\u7684\u6848\u4f8b\u66f4\u65b0\u5143\u63d0\u793a\u8bcd\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u5728\u4e24\u4e2a\u6210\u5bf9\u6bd4\u8f83\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSelective LWE\u8d85\u8fc7\u4e86\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u8bc4\u4f30\u5668\u80fd\u591f\u5728\u8fde\u7eed\u6d4b\u8bd5\u4e2d\u901a\u8fc7\u7b80\u5355\u7684\u9009\u62e9\u6027\u66f4\u65b0\u63d0\u5347\u6027\u80fd\uff0c\u4e3b\u8981\u4ece\u5904\u7406\u56f0\u96be\u6848\u4f8b\u4e2d\u5b66\u4e60\u3002", "conclusion": "LWE\u6846\u67b6\u901a\u8fc7\u987a\u5e8f\u5b66\u4e60\u548c\u9009\u62e9\u6027\u66f4\u65b0\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8bc4\u4f30\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u66f4\u667a\u80fd\u3001\u9ad8\u6548\u7684\u6837\u672c\u7279\u5f02\u6027\u8bc4\u4f30\u3002"}}
{"id": "2512.06776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06776", "abs": "https://arxiv.org/abs/2512.06776", "authors": ["Yuchuan Tian", "Yuchen Liang", "Jiacheng Sun", "Shuo Zhang", "Guangwen Yang", "Yingte Shu", "Sibo Fang", "Tianyu Guo", "Kai Han", "Chao Xu", "Hanting Chen", "Xinghao Chen", "Yunhe Wang"], "title": "From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs", "comment": "13 pages, 4 figures", "summary": "Large language models (LLMs) excel at generation but dominant autoregressive (AR) decoding is inherently sequential, creating a throughput bottleneck. Diffusion Language Models (DLMs)--especially block-wise variants--enable parallel generation and intra-block bidirectional reasoning, yet training large DLMs from scratch is costly and wastes the knowledge in mature AR checkpoints. Prior \"adaptation\" attempts either modify logits or randomly grow attention masks to full-sequence diffusion, or simply transplant AR weights into a block-diffusion recipe, leaving a fundamental mismatch between AR causality and block-wise bidirectionality unaddressed. We reframe adaptation as a intra-paradigm path from AR to Block-Diffusion by viewing AR as Block-Diffusion with blocksize=1. Concretely, we design the pathway of adaptation as follows: we use a context-causal attention mask (causal in context, bidirectional only within the active block), an efficient parallel adaptation procedure, an auxiliary AR loss to maximize data utilization and retain pretrained knowledge, and gradual increment of the generation block size. The recipe integrates cleanly with masked block-diffusion and maintains train-inference consistency. Built on these components, NBDiff-7B (Base and Instruct) could inherit the long-context modeling and reasoning capabilities, and achieve state-of-the-art performance among the 7B-class DLMs, delivering strong gains on general-knowledge, math, and code benchmarks over strong baselines. These results demonstrate that principled AR-to-block-diffusion adaptation is an effective and compute-efficient alternative to training DLMs from scratch. Codes: https://github.com/YuchuanTian/NBDiff.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u9002\u914d\u4e3a\u5206\u5757\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u65e2\u4fdd\u6301\u81ea\u56de\u5f52\u6a21\u578b\u77e5\u8bc6\uff0c\u53c8\u5b9e\u73b0\u5206\u5757\u5e76\u884c\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e867B\u7ea7\u6269\u6563\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6027\u80fd\u4e0e\u751f\u6210\u6548\u7387\u7684\u77db\u76fe\uff1b\u6269\u6563\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u5229\u7528\u81ea\u56de\u5f52\u6a21\u578b\u5df2\u6709\u77e5\u8bc6\u3002", "method": "\u5c06\u81ea\u56de\u5f52\u6a21\u578b\u89c6\u4e3a\u5757\u5927\u5c0f\u4e3a1\u7684\u5206\u5757\u6269\u6563\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u4e00\u6761\u4ece\u81ea\u56de\u5f52\u5230\u5206\u5757\u6269\u6563\u7684\u9002\u914d\u8def\u5f84\u3002\u8bbe\u8ba1\u4e86\u4e0a\u4e0b\u6587\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\u3001\u6709\u6548\u7684\u5e76\u884c\u9002\u914d\u8fc7\u7a0b\u3001\u8f85\u52a9\u81ea\u56de\u5f52\u635f\u5931\u4ee5\u6700\u5927\u5229\u7528\u6570\u636e\u5e76\u4fdd\u6301\u9884\u8bad\u7ec3\u77e5\u8bc6\uff0c\u4ee5\u53ca\u9010\u6b65\u589e\u52a0\u751f\u6210\u5757\u5927\u5c0f\u3002\u8be5\u65b9\u6848\u4e0e\u63a9\u7801\u5206\u5757\u6269\u6563\u65e0\u7f1d\u7ed3\u5408\uff0c\u4fdd\u8bc1\u8bad\u7ec3\u548c\u63a8\u7406\u7684\u4e00\u81f4\u6027\u3002", "result": "\u57fa\u4e8e\u4e0a\u8ff0\u65b9\u6cd5\uff0c\u6784\u5efa\u7684NBDiff-7B\u6a21\u578b\uff08\u5305\u62ec\u57fa\u7840\u7248\u548c\u6307\u4ee4\u7248\uff09\u4fdd\u6301\u4e86\u957f\u4e0a\u4e0b\u6587\u5efa\u6a21\u548c\u63a8\u7406\u80fd\u529b\uff0c\u57287B\u53c2\u6570\u7ea7\u522b\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u901a\u7528\u77e5\u8bc6\u3001\u6570\u5b66\u53ca\u4ee3\u7801\u57fa\u51c6\u4e0a\u8f83\u5f3a\u5bf9\u6bd4\u6a21\u578b\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u4ee5\u7406\u8bba\u6307\u5bfc\u7684\u81ea\u56de\u5f52\u5230\u5206\u5757\u6269\u6563\u7684\u9002\u914d\u662f\u4e00\u79cd\u6709\u6548\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u907f\u514d\u4e86\u4ece\u96f6\u8bad\u7ec3\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6602\u6210\u672c\uff0c\u540c\u65f6\u80fd\u7ee7\u627f\u548c\u53d1\u6325\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4f18\u52bf\u3002"}}
{"id": "2512.06787", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06787", "abs": "https://arxiv.org/abs/2512.06787", "authors": ["Ofek Glick", "Vladimir Tchuiev", "Marah Ghoummaid", "Michal Moshkovitz", "Dotan Di-Castro"], "title": "LLM4SFC: Sequential Function Chart Generation via Large Language Models", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly used for synthesizing textual PLC programming languages like Structured Text (ST) code, other IEC 61131-3 standard graphical languages like Sequential Function Charts (SFCs) remain underexplored. Generating SFCs is challenging due to graphical nature and ST actions embedded within, which are not directly compatible with standard generation techniques, often leading to non-executable code that is incompatible with industrial tool-chains In this work, we introduce LLM4SFC, the first framework to receive natural-language descriptions of industrial workflows and provide executable SFCs. LLM4SFC is based on three components: (i) A reduced structured representation that captures essential topology and in-line ST and reduced textual verbosity; (ii) Fine-tuning and few-shot retrieval-augmented generation (RAG) for alignment with SFC programming conventions; and (iii) A structured generation approach that prunes illegal tokens in real-time to ensure compliance with the textual format of SFCs. We evaluate LLM4SFC on a dataset of real-world SFCs from automated manufacturing projects, using both open-source and proprietary LLMs. The results show that LLM4SFC reliably generates syntactically valid SFC programs effectively bridging graphical and textual PLC languages, achieving a generation generation success of 75% - 94%, paving the way for automated industrial programming.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LLM4SFC\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u7528\u4e8e\u5de5\u4e1a\u81ea\u52a8\u5316\u7684\u53ef\u6267\u884c\u987a\u5e8f\u529f\u80fd\u56fe(SFC)\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u56fe\u5f62\u5316\u548c\u6587\u672c\u5316PLC\u8bed\u8a00\u8f6c\u6362\u7684\u96be\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7f\u6cdb\u5e94\u7528\u4e8e\u7ed3\u6784\u5316\u6587\u672c\u4ee3\u7801\u751f\u6210\uff0c\u4f46\u5bf9\u56fe\u5f62\u5316\u7684IEC 61131-3\u6807\u51c6\u8bed\u8a00SFC\u652f\u6301\u4e0d\u8db3\uff0c\u4e14\u751f\u6210\u7684\u4ee3\u7801\u591a\u4e0d\u53ef\u6267\u884c\uff0c\u4e0d\u517c\u5bb9\u5de5\u4e1a\u5de5\u5177\u94fe\uff0c\u9700\u8981\u4e00\u4e2a\u80fd\u751f\u6210\u53ef\u6267\u884cSFC\u7684\u81ea\u52a8\u5316\u65b9\u6848\u3002", "method": "\u91c7\u7528\u4e09\u5927\u7ec4\u4ef6\uff1a(1)\u7b80\u5316\u7ed3\u6784\u5316\u8868\u793a\u4ee5\u6355\u6349\u5173\u952e\u62d3\u6251\u548c\u5185\u5d4c\u7684ST\u52a8\u4f5c\uff1b(2) \u901a\u8fc7\u5fae\u8c03\u548c\u5c11\u6837\u672c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u786e\u4fdd\u7b26\u5408SFC\u7f16\u7a0b\u89c4\u8303\uff1b(3) \u5b9e\u65f6\u526a\u679d\u975e\u6cd5token\uff0c\u4fdd\u8bc1\u751f\u6210\u683c\u5f0f\u5408\u6cd5\u3002", "result": "\u5728\u771f\u5b9e\u5236\u9020\u9879\u76ee\u7684SFC\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0cLLM4SFC\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u751f\u6210\u6210\u529f\u7387\uff0875%-94%\uff09\uff0c\u6709\u6548\u8fde\u63a5\u4e86\u56fe\u5f62PLC\u8bed\u8a00\u548c\u6587\u672cPLC\u8bed\u8a00\uff0c\u63a8\u52a8\u4e86\u5de5\u4e1a\u7f16\u7a0b\u81ea\u52a8\u5316\u7684\u53d1\u5c55\u3002", "conclusion": "LLM4SFC\u80fd\u591f\u53ef\u9760\u751f\u6210\u7b26\u5408\u8bed\u6cd5\u89c4\u8303\u7684SFC\u7a0b\u5e8f\uff0c\u6210\u529f\u7387\u8fbe\u523075%-94%\uff0c\u4e3a\u5de5\u4e1a\u81ea\u52a8\u5316\u7f16\u7a0b\u7684\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2512.06812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06812", "abs": "https://arxiv.org/abs/2512.06812", "authors": ["Tiago Rodrigues", "Carla Teixeira Lopes"], "title": "Large Language Model-Based Generation of Discharge Summaries", "comment": "17 pages, 6 figures", "summary": "Discharge Summaries are documents written by medical professionals that detail a patient's visit to a care facility. They contain a wealth of information crucial for patient care, and automating their generation could significantly reduce the effort required from healthcare professionals, minimize errors, and ensure that critical patient information is easily accessible and actionable. In this work, we explore the use of five Large Language Models on this task, from open-source models (Mistral, Llama 2) to proprietary systems (GPT-3, GPT-4, Gemini 1.5 Pro), leveraging MIMIC-III summaries and notes. We evaluate them using exact-match, soft-overlap, and reference-free metrics. Our results show that proprietary models, particularly Gemini with one-shot prompting, outperformed others, producing summaries with the highest similarity to the gold-standard ones. Open-source models, while promising, especially Mistral after fine-tuning, lagged in performance, often struggling with hallucinations and repeated information. Human evaluation by a clinical expert confirmed the practical utility of the summaries generated by proprietary models. Despite the challenges, such as hallucinations and missing information, the findings suggest that LLMs, especially proprietary models, are promising candidates for automatic discharge summary generation as long as data privacy is ensured.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8bc4\u4f30\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u533b\u5b66\u51fa\u9662\u6458\u8981\uff0c\u53d1\u73b0\u4e13\u6709\u6a21\u578b\u6548\u679c\u6700\u4f73\uff0c\u5c3d\u7ba1\u5b58\u5728\u5e7b\u89c9\u548c\u7f3a\u5931\u95ee\u9898\uff0c\u4f46\u4ecd\u5177\u5907\u5b9e\u7528\u6f5c\u529b\u3002", "motivation": "\u81ea\u52a8\u751f\u6210\u51fa\u9662\u6458\u8981\u53ef\u4ee5\u663e\u8457\u51cf\u8f7b\u533b\u62a4\u4eba\u5458\u7684\u5de5\u4f5c\u8d1f\u62c5\uff0c\u51cf\u5c11\u9519\u8bef\uff0c\u5e76\u786e\u4fdd\u5173\u952e\u4fe1\u606f\u7684\u6613\u83b7\u53d6\u548c\u53ef\u64cd\u4f5c\u6027\u3002", "method": "\u4f7f\u7528\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5f00\u6e90\u6a21\u578bMistral\u3001Llama 2\u4e0e\u4e13\u6709\u6a21\u578bGPT-3\u3001GPT-4\u3001Gemini 1.5 Pro\uff09\uff0c\u5229\u7528MIMIC-III\u7684\u51fa\u9662\u603b\u7ed3\u548c\u7b14\u8bb0\u6570\u636e\u8fdb\u884c\u81ea\u52a8\u751f\u6210\u51fa\u9662\u6458\u8981\u3002", "result": "\u4e13\u6709\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\uff0c\u5c24\u5176\u662fGemini 1.5 Pro\u5728\u5355\u6b21\u63d0\u793a\u4e0b\u751f\u6210\u7684\u6458\u8981\u4e0e\u6807\u51c6\u6458\u8981\u76f8\u4f3c\u5ea6\u6700\u9ad8\u3002\u5f00\u6e90\u6a21\u578b\u867d\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u5e7b\u89c9\u548c\u4fe1\u606f\u91cd\u590d\u95ee\u9898\u3002\u4e34\u5e8a\u4e13\u5bb6\u7684\u4eba\u7c7b\u8bc4\u4f30\u4e5f\u652f\u6301\u4e13\u6709\u6a21\u578b\u751f\u6210\u7684\u6458\u8981\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5c24\u5176\u662f\u4e13\u6709\u6a21\u578b\uff0c\u5728\u4fdd\u969c\u6570\u636e\u9690\u79c1\u7684\u524d\u63d0\u4e0b\uff0c\u662f\u81ea\u52a8\u751f\u6210\u533b\u5b66\u51fa\u9662\u6458\u8981\u7684\u6709\u524d\u666f\u65b9\u6cd5\u3002"}}
{"id": "2512.06814", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06814", "abs": "https://arxiv.org/abs/2512.06814", "authors": ["Dibyanayan Bandyopadhyay", "Soham Bhattacharjee", "Mohammed Hasanuzzaman", "Asif Ekbal"], "title": "CAuSE: Decoding Multimodal Classifiers using Faithful Natural Language Explanation", "comment": "Accepted at Transactions of the Association for Computational Linguistics (TACL). Pre-MIT Press publication version", "summary": "Multimodal classifiers function as opaque black box models. While several techniques exist to interpret their predictions, very few of them are as intuitive and accessible as natural language explanations (NLEs). To build trust, such explanations must faithfully capture the classifier's internal decision making behavior, a property known as faithfulness. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanations), a novel framework to generate faithful NLEs for any pretrained multimodal classifier. We demonstrate that CAuSE generalizes across datasets and models through extensive empirical evaluations. Theoretically, we show that CAuSE, trained via interchange intervention, forms a causal abstraction of the underlying classifier. We further validate this through a redesigned metric for measuring causal faithfulness in multimodal settings. CAuSE surpasses other methods on this metric, with qualitative analysis reinforcing its advantages. We perform detailed error analysis to pinpoint the failure cases of CAuSE. For replicability, we make the codes available at https://github.com/newcodevelop/CAuSE", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCAuSE\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u62bd\u8c61\u751f\u6210\u5fe0\u5b9e\u7684\u591a\u6a21\u6001\u5206\u7c7b\u5668\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u4fe1\u4efb\u5ea6\u548c\u56e0\u679c\u5fe0\u5b9e\u6027\u3002", "motivation": "\u591a\u6a21\u6001\u5206\u7c7b\u5668\u50cf\u9ed1\u76d2\u4e00\u6837\u96be\u4ee5\u7406\u89e3\uff0c\u73b0\u6709\u7684\u89e3\u91ca\u65b9\u6cd5\u96be\u4ee5\u505a\u5230\u76f4\u89c2\u4e14\u5fe0\u5b9e\uff0c\u8981\u5efa\u7acb\u7528\u6237\u4fe1\u4efb\uff0c\u9700\u751f\u6210\u5fe0\u5b9e\u53cd\u6620\u6a21\u578b\u5185\u90e8\u51b3\u7b56\u8fc7\u7a0b\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u3002", "method": "\u8bbe\u8ba1\u4e86CAuSE\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u6362\u5e72\u9884\u8bad\u7ec3\u5f62\u6210\u5206\u7c7b\u5668\u7684\u56e0\u679c\u62bd\u8c61\uff0c\u4ece\u800c\u751f\u6210\u5fe0\u5b9e\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u5e76\u63d0\u51fa\u4e86\u91cd\u65b0\u8bbe\u8ba1\u7684\u56e0\u679c\u5fe0\u5b9e\u6027\u5ea6\u91cf\u6807\u51c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "CAuSE\u5728\u65b0\u8bbe\u8ba1\u7684\u56e0\u679c\u5fe0\u5b9e\u6027\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5b9a\u6027\u5206\u6790\u548c\u8be6\u5c3d\u7684\u9519\u8bef\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u660e\u5176\u4f18\u8d8a\u6027\u548c\u5c40\u9650\u6027\u3002\u4ee3\u7801\u5df2\u5f00\u6e90\u4ee5\u4fbf\u590d\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684CAuSE\u6846\u67b6\u80fd\u591f\u4e3a\u9884\u8bad\u7ec3\u7684\u591a\u6a21\u6001\u5206\u7c7b\u5668\u751f\u6210\u5fe0\u5b9e\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\uff0c\u63d0\u5347\u4e86\u89e3\u91ca\u7684\u56e0\u679c\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u5e76\u5728\u591a\u6570\u636e\u96c6\u548c\u591a\u6a21\u578b\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.06848", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.06848", "abs": "https://arxiv.org/abs/2512.06848", "authors": ["Sepyan Purnama Kristanto", "Lutfi Hakim", "Hermansyah"], "title": "AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices", "comment": "9Pages, 3 figure, Politeknik Negeri Banyuwangi", "summary": "Evidence from many low and middle income regions shows that microbial contamination in small scale drinking water systems often fluctuates rapidly, yet existing monitoring tools capture only fragments of this behaviour. Microscopic imaging provides organism level visibility, whereas physicochemical sensors reveal shortterm changes in water chemistry; in practice, operators must interpret these streams separately, making realtime decision-making unreliable. This study introduces AquaFusionNet, a lightweight cross-modal framework that unifies both information sources inside a single edge deployable model. Unlike prior work that treats microscopic detection and water quality prediction as independent tasks, AquaFusionNet learns the statistical dependencies between microbial appearance and concurrent sensor dynamics through a gated crossattention mechanism designed specifically for lowpower hardware. The framework is trained on AquaMicro12K, a new dataset comprising 12,846 annotated 1000 micrographs curated for drinking water contexts, an area where publicly accessible microscopic datasets are scarce. Deployed for six months across seven facilities in East Java, Indonesia, the system processed 1.84 million frames and consistently detected contamination events with 94.8% mAP@0.5 and 96.3% anomaly prediction accuracy, while operating at 4.8 W on a Jetson Nano. Comparative experiments against representative lightweight detectors show that AquaFusionNet provides higher accuracy at comparable or lower power, and field results indicate that cross-modal coupling reduces common failure modes of unimodal detectors, particularly under fouling, turbidity spikes, and inconsistent illumination. All models, data, and hardware designs are released openly to facilitate replication and adaptation in decentralized water safety infrastructures.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f00\u53d1\u8f7b\u91cf\u7ea7\u8de8\u6a21\u6001\u6a21\u578bAquaFusionNet\uff0c\u878d\u5408\u663e\u5fae\u6210\u50cf\u4e0e\u4f20\u611f\u5668\u6570\u636e\u5b9e\u73b0\u4f4e\u529f\u8017\u3001\u9ad8\u7cbe\u5ea6\u996e\u7528\u6c34\u5fae\u751f\u7269\u6c61\u67d3\u5b9e\u65f6\u76d1\u6d4b\uff0c\u5df2\u5728\u5370\u5c3c\u73b0\u573a\u6210\u529f\u90e8\u7f72\uff0c\u63d0\u5347\u6c34\u8d28\u5b89\u5168\u4fdd\u969c\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5c0f\u89c4\u6a21\u996e\u7528\u6c34\u7cfb\u7edf\u76d1\u6d4b\u5de5\u5177\u53ea\u80fd\u6355\u83b7\u6c61\u67d3\u6ce2\u52a8\u7684\u90e8\u5206\u4fe1\u606f\uff0c\u663e\u5fae\u6210\u50cf\u548c\u7269\u7406\u5316\u5b66\u4f20\u611f\u5668\u6570\u636e\u9700\u5206\u5f00\u89e3\u8bfb\uff0c\u5bfc\u81f4\u5b9e\u65f6\u51b3\u7b56\u4e0d\u53ef\u9760\uff0c\u4e9f\u9700\u7edf\u4e00\u65b9\u6cd5\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u76d1\u6d4b\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u8de8\u6a21\u6001\u6846\u67b6AquaFusionNet\uff0c\u5229\u7528\u95e8\u63a7\u8de8\u6ce8\u610f\u529b\u673a\u5236\u7ed3\u5408\u663e\u5fae\u56fe\u50cf\u4e0e\u7269\u7406\u5316\u5b66\u4f20\u611f\u5668\u6570\u636e\uff0c\u8bad\u7ec3\u4e8e\u65b0\u6784\u5efa\u7684AquaMicro12K\u6570\u636e\u96c6\uff0c\u5e76\u90e8\u7f72\u5728Jetson Nano\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4f4e\u529f\u8017\u5b9e\u65f6\u76d1\u6d4b\u3002", "result": "AquaFusionNet\u5728\u5370\u5c3c\u4e03\u4e2a\u8bbe\u65bd\u516d\u4e2a\u6708\u90e8\u7f72\uff0c\u5904\u7406184\u4e07\u5e27\u89c6\u9891\uff0c\u6c61\u67d3\u68c0\u6d4b\u8fbe94.8% mAP@0.5\uff0c\u5f02\u5e38\u9884\u6d4b\u51c6\u786e\u738796.3%\uff0c\u529f\u8017\u4ec54.8W\uff0c\u4e14\u76f8\u8f83\u5176\u4ed6\u8f7b\u91cf\u7ea7\u68c0\u6d4b\u5668\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "AquaFusionNet\u6709\u6548\u878d\u5408\u4e86\u663e\u5fae\u56fe\u50cf\u548c\u6c34\u8d28\u4f20\u611f\u5668\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u89c4\u6a21\u996e\u7528\u6c34\u7cfb\u7edf\u4e2d\u5fae\u751f\u7269\u6c61\u67d3\u7684\u5b9e\u65f6\u68c0\u6d4b\u51c6\u786e\u7387\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.06869", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06869", "abs": "https://arxiv.org/abs/2512.06869", "authors": ["Wanyang Hong", "Zhaoning Zhang", "Yi Chen", "Libo Zhang", "Baihui Liu", "Linbo Qiao", "Zhiliang Tian", "Dongsheng Li"], "title": "Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs", "comment": null, "summary": "Large Language Models (LLMs) have achieved remarkable performance on single-turn tasks, yet their effectiveness deteriorates in multi-turn conversations. We define this phenomenon as cumulative contextual decay - a progressive degradation of contextual integrity caused by attention pollution, dilution, and drift. To address this challenge, we propose Rhea (Role-aware Heuristic Episodic Attention), a novel framework that decouples conversation history into two functionally independent memory modules: (1) an Instructional Memory (IM) that persistently stores high-fidelity global constraints via a structural priority mechanism, and (2) an Episodic Memory (EM) that dynamically manages user-model interactions via asymmetric noise control and heuristic context retrieval. During inference, Rhea constructs a high signal-to-noise context by applying its priority attention: selectively integrating relevant episodic information while always prioritizing global instructions. To validate this approach, experiments on multiple multi-turn conversation benchmarks - including MT-Eval and Long-MT-Bench+ - show that Rhea mitigates performance decay and improves overall accuracy by 1.04 points on a 10-point scale (a 16% relative gain over strong baselines). Moreover, Rhea maintains near-perfect instruction fidelity (IAR > 8.1) across long-horizon interactions. These results demonstrate that Rhea provides a principled and effective framework for building more precise, instruction-consistent conversational LLMs.", "AI": {"tldr": "Rhea\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4e0a\u4e0b\u6587\u8870\u51cf\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u548c\u6307\u4ee4\u9075\u5faa\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5355\u8f6e\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5b58\u5728\u7d2f\u79ef\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u8870\u51cf\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e9f\u9700\u8bbe\u8ba1\u673a\u5236\u7ef4\u62a4\u4e0a\u4e0b\u6587\u5b8c\u6574\u6027\u4e0e\u6307\u4ee4\u4e00\u81f4\u6027\u3002", "method": "\u901a\u8fc7\u5c06\u5bf9\u8bdd\u5386\u53f2\u5206\u89e3\u4e3aInstructional Memory\u548cEpisodic Memory\u4e24\u4e2a\u529f\u80fd\u72ec\u7acb\u7684\u8bb0\u5fc6\u6a21\u5757\uff0c\u5206\u522b\u7ba1\u7406\u5168\u5c40\u7ea6\u675f\u548c\u7528\u6237\u4ea4\u4e92\u4fe1\u606f\uff0c\u5229\u7528\u7ed3\u6784\u5316\u4f18\u5148\u673a\u5236\u548c\u542f\u53d1\u5f0f\u4e0a\u4e0b\u6587\u68c0\u7d22\uff0c\u6709\u6548\u8fc7\u6ee4\u566a\u58f0\uff0c\u6784\u5efa\u9ad8\u4fe1\u566a\u6bd4\u7684\u4e0a\u4e0b\u6587\u3002", "result": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u8868\u73b0\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5b9a\u4e49\u4e3a\u7d2f\u79ef\u4e0a\u4e0b\u6587\u8870\u51cf\uff0c\u63d0\u51fa\u4e86Rhea\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5bf9\u8bdd\u5386\u53f2\u5206\u6210\u4e24\u4e2a\u72ec\u7acb\u8bb0\u5fc6\u6a21\u5757\uff08Instructional Memory\u548cEpisodic Memory\uff09\uff0c\u5229\u7528\u4f18\u5148\u6ce8\u610f\u673a\u5236\u9009\u62e9\u6027\u6574\u5408\u4fe1\u606f\uff0c\u51cf\u8f7b\u6ce8\u610f\u529b\u6c61\u67d3\u7b49\u95ee\u9898\u3002\u5b9e\u9a8c\u663e\u793aRhea\u5728\u591a\u4e2a\u591a\u8f6e\u5bf9\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e86\u6a21\u578b\u51c6\u786e\u7387\uff0c\u5e76\u4fdd\u6301\u9ad8\u6307\u4ee4\u4e00\u81f4\u6027\u3002", "conclusion": "Rhea\u63d0\u51fa\u7684\u53cc\u8bb0\u5fc6\u6a21\u5757\u548c\u4f18\u5148\u6ce8\u610f\u673a\u5236\u663e\u8457\u51cf\u5c11\u4e86\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u8870\u51cf\uff0c\u5b9e\u73b0\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u66f4\u7cbe\u51c6\u4e14\u4e00\u81f4\u7684\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u3002"}}
{"id": "2512.06874", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06874", "abs": "https://arxiv.org/abs/2512.06874", "authors": ["Ziyun Yu", "Yiru Zhou", "Chen Zhao", "Hongyi Wen"], "title": "An Analysis of Large Language Models for Simulating User Responses in Surveys", "comment": "Accepted to IJCNLP-AACL 2025 (Main Conference)", "summary": "Using Large Language Models (LLMs) to simulate user opinions has received growing attention. Yet LLMs, especially trained with reinforcement learning from human feedback (RLHF), are known to exhibit biases toward dominant viewpoints, raising concerns about their ability to represent users from diverse demographic and cultural backgrounds. In this work, we examine the extent to which LLMs can simulate human responses to cross-domain survey questions through direct prompting and chain-of-thought prompting. We further propose a claim diversification method CLAIMSIM, which elicits viewpoints from LLM parametric knowledge as contextual input. Experiments on the survey question answering task indicate that, while CLAIMSIM produces more diverse responses, both approaches struggle to accurately simulate users. Further analysis reveals two key limitations: (1) LLMs tend to maintain fixed viewpoints across varying demographic features, and generate single-perspective claims; and (2) when presented with conflicting claims, LLMs struggle to reason over nuanced differences among demographic features, limiting their ability to adapt responses to specific user profiles.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30LLMs\u6a21\u62df\u8de8\u9886\u57df\u8c03\u67e5\u4e2d\u591a\u6837\u7528\u6237\u89c2\u70b9\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u901a\u8fc7CLAIMSIM\u589e\u5f3a\u89c2\u70b9\u591a\u6837\u6027\uff0c\u4f46LLMs\u4ecd\u96be\u51c6\u786e\u53cd\u6620\u4e0d\u540c\u7528\u6237\u80cc\u666f\u7684\u610f\u89c1\uff0c\u5b58\u5728\u56fa\u5b9a\u89c6\u89d2\u548c\u6709\u9650\u63a8\u7406\u80fd\u529b\u7684\u6311\u6218\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6a21\u62df\u591a\u5143\u7528\u6237\u610f\u89c1\u65b9\u9762\u7684\u80fd\u529b\u548c\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5176\u5728\u8868\u793a\u4e0d\u540c\u4eba\u53e3\u548c\u6587\u5316\u80cc\u666f\u7528\u6237\u610f\u89c1\u65f6\u7684\u504f\u89c1\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u76f4\u63a5\u63d0\u793a\u548c\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u4e24\u79cd\u65b9\u5f0f\u6a21\u62df\u7528\u6237\u5bf9\u8de8\u9886\u57df\u8c03\u67e5\u95ee\u9898\u7684\u56de\u7b54\uff0c\u5e76\u63d0\u51faCLAIMSIM\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5229\u7528LLM\u7684\u53c2\u6570\u77e5\u8bc6\u751f\u6210\u591a\u6837\u5316\u89c2\u70b9\u4f5c\u4e3a\u4e0a\u4e0b\u6587\u8f93\u5165\u3002", "result": "\u5b9e\u9a8c\u8868\u660eCLAIMSIM\u80fd\u591f\u751f\u6210\u66f4\u52a0\u591a\u6837\u5316\u7684\u56de\u7b54\uff0c\u4f46LLMs\u6574\u4f53\u96be\u4ee5\u51c6\u786e\u6a21\u62df\u7528\u6237\u610f\u89c1\u3002\u5206\u6790\u53d1\u73b0LLMs\u503e\u5411\u4e8e\u5728\u4e0d\u540c\u4eba\u53e3\u7279\u5f81\u95f4\u4fdd\u6301\u56fa\u5b9a\u89c2\u70b9\uff0c\u4e14\u5bf9\u590d\u6742\u7684\u7528\u6237\u7279\u5f81\u5dee\u5f02\u63a8\u7406\u80fd\u529b\u6709\u9650\u3002", "conclusion": "LLMs\u5728\u6a21\u62df\u4e0d\u540c\u7528\u6237\u80cc\u666f\u7684\u591a\u6837\u5316\u610f\u89c1\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u4eba\u53e3\u7edf\u8ba1\u5b66\u7279\u5f81\u7684\u590d\u6742\u5dee\u5f02\u548c\u751f\u6210\u591a\u89d2\u5ea6\u89c2\u70b9\u65f6\u8868\u73b0\u4e0d\u8db3\u3002"}}
{"id": "2512.06919", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06919", "abs": "https://arxiv.org/abs/2512.06919", "authors": ["Francois Vandenhende", "Anna Georgiou", "Michalis Georgiou", "Theodoros Psaras", "Ellie Karekla"], "title": "Automated PRO-CTCAE Symptom Selection based on Prior Adverse Event Profiles", "comment": "13 pages, 2 figures", "summary": "The PRO-CTCAE is an NCI-developed patient-reported outcome system for capturing symptomatic adverse events in oncology trials. It comprises a large library drawn from the CTCAE vocabulary, and item selection for a given trial is typically guided by expected toxicity profiles from prior data. Selecting too many PRO-CTCAE items can burden patients and reduce compliance, while too few may miss important safety signals. We present an automated method to select a minimal yet comprehensive PRO-CTCAE subset based on historical safety data. Each candidate PRO-CTCAE symptom term is first mapped to its corresponding MedDRA Preferred Terms (PTs), which are then encoded into Safeterm, a high-dimensional semantic space capturing clinical and contextual diversity in MedDRA terminology. We score each candidate PRO item for relevance to the historical list of adverse event PTs and combine relevance and incidence into a utility function. Spectral analysis is then applied to the combined utility and diversity matrix to identify an orthogonal set of medical concepts that balances relevance and diversity. Symptoms are rank-ordered by importance, and a cut-off is suggested based on the explained information. The tool is implemented as part of the Safeterm trial-safety app. We evaluate its performance using simulations and oncology case studies in which PRO-CTCAE was employed. This automated approach can streamline PRO-CTCAE design by leveraging MedDRA semantics and historical data, providing an objective and reproducible method to balance signal coverage against patient burden.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5386\u53f2\u5b89\u5168\u6570\u636e\u548cMedDRA\u8bed\u4e49\u4fe1\u606f\uff0c\u81ea\u52a8\u9009\u62e9PRO-CTCAE\u75c7\u72b6\u5b50\u96c6\u7684\u65b9\u6cd5\uff0c\u4ee5\u51cf\u5c11\u60a3\u8005\u8d1f\u62c5\u5e76\u4fdd\u8bc1\u4fe1\u53f7\u8986\u76d6\u3002", "motivation": "\u76ee\u524dPRO-CTCAE\u9879\u7684\u9009\u62e9\u4f9d\u8d56\u4e8e\u5386\u53f2\u7ecf\u9a8c\uff0c\u4e14\u5305\u542b\u9879\u8fc7\u591a\u4f1a\u589e\u52a0\u60a3\u8005\u8d1f\u62c5\uff0c\u9879\u8fc7\u5c11\u5219\u53ef\u80fd\u9057\u6f0f\u91cd\u8981\u5b89\u5168\u4fe1\u53f7\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u81ea\u52a8\u5316\u3001\u5ba2\u89c2\u4e14\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u4f18\u5316\u9879\u9009\u62e9\u3002", "method": "\u901a\u8fc7\u5c06PRO-CTCAE\u75c7\u72b6\u6620\u5c04\u81f3MedDRA\u9996\u9009\u672f\u8bed\uff08PTs\uff09\uff0c\u5e76\u7f16\u7801\u5165Safeterm\u8bed\u4e49\u7a7a\u95f4\uff1b\u7ed3\u5408\u76f8\u5173\u6027\u548c\u53d1\u75c5\u7387\u6784\u5efa\u6548\u7528\u51fd\u6570\uff1b\u5229\u7528\u8c31\u5206\u6790\u9009\u62e9\u4e0e\u4f17\u4e0d\u540c\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u533b\u7597\u6982\u5ff5\u5b50\u96c6\uff0c\u6700\u540e\u6839\u636e\u89e3\u91ca\u7684\u4fe1\u606f\u6392\u5e8f\u548c\u622a\u65ad\u9009\u9879\u3002", "result": "\u901a\u8fc7\u6a21\u62df\u548c\u80bf\u7624\u5b66\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e73\u8861\u4fe1\u53f7\u8986\u76d6\u548c\u60a3\u8005\u5408\u89c4\u6027\uff0c\u81ea\u52a8\u5316\u8bbe\u8ba1\u8fc7\u7a0b\u6709\u52a9\u4e8e\u8bd5\u9a8c\u5b89\u5168\u6027\u6570\u636e\u5206\u6790\u3002", "conclusion": "\u8be5\u81ea\u52a8\u5316\u65b9\u6cd5\u80fd\u591f\u57fa\u4e8e\u5386\u53f2\u5b89\u5168\u6570\u636e\u548cMedDRA\u8bed\u4e49\uff0c\u5ba2\u89c2\u5730\u9009\u62e9\u6700\u5c0f\u4e14\u5168\u9762\u7684PRO-CTCAE\u9879\u96c6\uff0c\u5e73\u8861\u60a3\u8005\u8d1f\u62c5\u4e0e\u5b89\u5168\u4fe1\u53f7\u6355\u83b7\uff0c\u63d0\u5347\u8bd5\u9a8c\u8bbe\u8ba1\u6548\u7387\u3002"}}
{"id": "2512.06922", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.06922", "abs": "https://arxiv.org/abs/2512.06922", "authors": ["George Mikros"], "title": "Large Language Models and Forensic Linguistics: Navigating Opportunities and Threats in the Age of Generative AI", "comment": null, "summary": "Large language models (LLMs) present a dual challenge for forensic linguistics. They serve as powerful analytical tools enabling scalable corpus analysis and embedding-based authorship attribution, while simultaneously destabilising foundational assumptions about idiolect through style mimicry, authorship obfuscation, and the proliferation of synthetic texts. Recent stylometric research indicates that LLMs can approximate surface stylistic features yet exhibit detectable differences from human writers, a tension with significant forensic implications. However, current AI-text detection techniques, whether classifier-based, stylometric, or watermarking approaches, face substantial limitations: high false positive rates for non-native English writers and vulnerability to adversarial strategies such as homoglyph substitution. These uncertainties raise concerns under legal admissibility standards, particularly the Daubert and Kumho Tire frameworks. The article concludes that forensic linguistics requires methodological reconfiguration to remain scientifically credible and legally admissible. Proposed adaptations include hybrid human-AI workflows, explainable detection paradigms beyond binary classification, and validation regimes measuring error and bias across diverse populations. The discipline's core insight, i.e., that language reveals information about its producer, remains valid but must accommodate increasingly complex chains of human and machine authorship.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e2\u662f\u5f3a\u5927\u5206\u6790\u5de5\u5177\uff0c\u4e5f\u662f\u6cd5\u533b\u8bed\u8a00\u5b66\u9762\u4e34\u7684\u6311\u6218\uff0c\u73b0\u6709AI\u6587\u672c\u68c0\u6d4b\u6280\u672f\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u9700\u8981\u65b9\u6cd5\u5b66\u91cd\u6784\u4ee5\u786e\u4fdd\u79d1\u5b66\u6027\u548c\u6cd5\u5f8b\u53ef\u91c7\u7eb3\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u98ce\u683c\u6a21\u4eff\u548c\u5408\u6210\u6587\u672c\u51b2\u51fb\u4f20\u7edf\u8bed\u8a00\u9274\u522b\u7406\u8bba\uff0c\u73b0\u6709\u68c0\u6d4b\u6280\u672f\u8bef\u5224\u7387\u9ad8\u4e14\u5bb9\u6613\u88ab\u5bf9\u6297\u653b\u51fb\uff0c\u9020\u6210\u6cd5\u5f8b\u91c7\u4fe1\u96be\u9898\u3002", "method": "\u63d0\u51fa\u91c7\u7528\u4eba\u673a\u6df7\u5408\u5de5\u4f5c\u6d41\u3001\u8d85\u8d8a\u4e8c\u5143\u5206\u7c7b\u7684\u53ef\u89e3\u91ca\u68c0\u6d4b\u6a21\u578b\uff0c\u4ee5\u53ca\u8de8\u591a\u6837\u5316\u4eba\u7fa4\u7684\u9a8c\u8bc1\u673a\u5236\u3002", "result": "\u53d1\u73b0LLM\u867d\u80fd\u6a21\u4eff\u98ce\u683c\uff0c\u4f46\u4e0e\u4eba\u7c7b\u5199\u4f5c\u5b58\u5728\u53ef\u4fa6\u6d4b\u5dee\u5f02\uff0c\u4e14\u68c0\u6d4b\u5de5\u5177\u9762\u4e34\u9ad8\u8bef\u5224\u548c\u6613\u53d7\u653b\u51fb\u7684\u5c40\u9650\uff0c\u4e9f\u9700\u65b0\u7684\u9002\u5e94\u6027\u65b9\u6cd5\u3002", "conclusion": "\u6cd5\u533b\u8bed\u8a00\u5b66\u9700\u8981\u91cd\u65b0\u8c03\u6574\u65b9\u6cd5\uff0c\u91c7\u7528\u4eba\u673a\u6df7\u5408\u6d41\u7a0b\u3001\u53ef\u89e3\u91ca\u68c0\u6d4b\u8303\u5f0f\u548c\u591a\u6837\u7fa4\u4f53\u7684\u8bef\u5dee\u504f\u5dee\u9a8c\u8bc1\uff0c\u4ee5\u4fdd\u6301\u79d1\u5b66\u53ef\u4fe1\u5ea6\u548c\u6cd5\u5f8b\u8ba4\u53ef\u3002"}}
{"id": "2512.06924", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06924", "abs": "https://arxiv.org/abs/2512.06924", "authors": ["Milad Alshomary", "Anisha Bhatnagar", "Peter Zeng", "Smaranda Muresan", "Owen Rambow", "Kathleen McKeown"], "title": "XAM: Interactive Explainability for Authorship Attribution Models", "comment": null, "summary": "We present IXAM, an Interactive eXplainability framework for Authorship Attribution Models. Given an authorship attribution (AA) task and an embedding-based AA model, our tool enables users to interactively explore the model's embedding space and construct an explanation of the model's prediction as a set of writing style features at different levels of granularity. Through a user evaluation, we demonstrate the value of our framework compared to predefined stylistic explanations.", "AI": {"tldr": "IXAM\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0f\u89e3\u91ca\u6846\u67b6\uff0c\u5e2e\u52a9\u7528\u6237\u7406\u89e3\u4f5c\u8005\u8eab\u4efd\u8bc6\u522b\u6a21\u578b\u7684\u9884\u6d4b\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u4f5c\u8005\u8eab\u4efd\u8bc6\u522b\u6a21\u578b\u7f3a\u4e4f\u6709\u6548\u7684\u89e3\u91ca\u5de5\u5177\uff0c\u7528\u6237\u96be\u4ee5\u7406\u89e3\u6a21\u578b\u7684\u9884\u6d4b\u673a\u5236\u3002", "method": "\u63d0\u51faIXAM\u6846\u67b6\uff0c\u5141\u8bb8\u7528\u6237\u4ea4\u4e92\u5f0f\u63a2\u7d22\u6a21\u578b\u7684\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u4ee5\u591a\u5c42\u6b21\u7684\u5199\u4f5c\u98ce\u683c\u7279\u5f81\u6784\u5efa\u9884\u6d4b\u89e3\u91ca\u3002", "result": "\u901a\u8fc7\u7528\u6237\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86IXAM\u5728\u89e3\u91ca\u6a21\u578b\u9884\u6d4b\u65b9\u9762\u76f8\u8f83\u4e8e\u9884\u5b9a\u4e49\u98ce\u683c\u89e3\u91ca\u7684\u4f18\u52bf\u3002", "conclusion": "IXAM\u6709\u6548\u63d0\u5347\u4e86\u4f5c\u8005\u8eab\u4efd\u8bc6\u522b\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u5bf9\u6a21\u578b\u9884\u6d4b\u7684\u7406\u89e3\u548c\u4fe1\u4efb\u3002"}}
{"id": "2512.06938", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.06938", "abs": "https://arxiv.org/abs/2512.06938", "authors": ["Ivanho\u00e9 Botcazou", "Tassadit Amghar", "Sylvain Lamprier", "Fr\u00e9d\u00e9ric Saubion"], "title": "Progress Ratio Embeddings: An Impatience Signal for Robust Length Control in Neural Text Generation", "comment": null, "summary": "Modern neural language models achieve high accuracy in text generation, yet precise control over generation length remains underdeveloped. In this paper, we first investigate a recent length control method based on Reverse Positional Embeddings (RPE) and show its limits when control is requested beyond the training distribution. In particular, using a discrete countdown signal tied to the absolute remaining token count leads to instability. To provide robust length control, we introduce Progress Ratio Embeddings (PRE), as continuous embeddings tied to a trigonometric impatience signal. PRE integrates seamlessly into standard Transformer architectures, providing stable length fidelity without degrading text accuracy under standard evaluation metrics. We further show that PRE generalizes well to unseen target lengths. Experiments on two widely used news-summarization benchmarks validate these findings.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eProgress Ratio Embeddings\u7684\u6587\u672c\u751f\u6210\u957f\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u63d0\u5347\u957f\u5ea6\u63a7\u5236\u7684\u7a33\u5065\u6027\u548c\u6cdb\u534e\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u867d\u7136\u751f\u6210\u6587\u672c\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5bf9\u751f\u6210\u6587\u672c\u957f\u5ea6\u7684\u7cbe\u786e\u63a7\u5236\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u73b0\u6709RPE\u65b9\u6cd5\u5728\u76ee\u6807\u957f\u5ea6\u8d85\u51fa\u8bad\u7ec3\u5206\u5e03\u65f6\u8868\u73b0\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eProgress Ratio Embeddings (PRE)\u7684\u957f\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u4f7f\u7528\u8fde\u7eed\u7684\u4e09\u89d2\u51fd\u6570\u4fe1\u53f7\u5d4c\u5165\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u5269\u4f59\u4ee4\u724c\u8ba1\u6570\u7684Reverse Positional Embeddings (RPE)\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u4e0e\u6807\u51c6Transformer\u67b6\u6784\u65e0\u7f1d\u96c6\u6210\u3002", "result": "PRE\u65b9\u6cd5\u5728\u4e24\u4e2a\u65b0\u95fb\u6458\u8981\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u957f\u5ea6\u63a7\u5236\u7684\u7a33\u5b9a\u6027\u548c\u751f\u6210\u6587\u672c\u51c6\u786e\u6027\u4e0a\u7684\u4f18\u52bf\uff0c\u4e14\u80fd\u591f\u5f88\u597d\u5730\u6cdb\u5316\u5230\u672a\u89c1\u8fc7\u7684\u76ee\u6807\u957f\u5ea6\u3002", "conclusion": "PRE\u4e3a\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u79cd\u7a33\u5b9a\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u957f\u5ea6\u63a7\u5236\u624b\u6bb5\uff0c\u6539\u8fdb\u4e86\u957f\u6587\u672c\u751f\u6210\u7684\u7cbe\u786e\u5ea6\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u6807\u51c6Transformer\u6a21\u578b\u3002"}}
{"id": "2512.06991", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.06991", "abs": "https://arxiv.org/abs/2512.06991", "authors": ["Jing Jie Tan", "Ban-Hoe Kwan", "Danny Wee-Kiat Ng", "Yan-Chai Hum", "Anissa Mokraoui", "Shih-Yu Lo"], "title": "Prompting-in-a-Series: Psychology-Informed Contents and Embeddings for Personality Recognition With Decoder-Only Models", "comment": "16 pages", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel \"Prompting-in-a-Series\" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition functions as a personality feature extractor and a generator for personality-rich content. We conducted various experiments to provide evidence to justify the rationale behind the PICEPR algorithm. Meanwhile, we also explored closed-source models such as \\textit{gpt4o} from OpenAI and \\textit{gemini} from Google, along with open-source models like \\textit{mistral} from Mistral AI, to compare the quality of the generated content. The PICEPR algorithm has achieved a new state-of-the-art performance for personality recognition by 5-15\\% improvement. The work repository and models' weight can be found at https://research.jingjietan.com/?q=PICEPR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5fc3\u7406\u5b66\u5185\u5bb9\u5d4c\u5165\u7684PICEPR\u7b97\u6cd5\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u4e2a\u6027\u8bc6\u522b\u6027\u80fd\uff0c\u5b9e\u73b0\u4e865-15%\u7684\u63d0\u5347\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u672c\u6587\u65e8\u5728\u5229\u7528\u5176\u80fd\u529b\u6539\u8fdb\u4e2a\u6027\u8bc6\u522b\u7684\u51c6\u786e\u6027\u80fd\uff0c\u901a\u8fc7\u5185\u5bb9\u751f\u6210\u548c\u5904\u7406\u5b9e\u73b0\u66f4\u7cbe\u51c6\u7684\u4e2a\u6027\u7279\u5f81\u63d0\u53d6\u3002", "method": "\u63d0\u51fa\u4e86\u201cPrompting-in-a-Series\u201d\u7b97\u6cd5\uff0c\u5305\u542b\u5185\u5bb9\u548c\u5d4c\u5165\u4e24\u4e2a\u7ba1\u9053\uff0c\u5229\u7528\u6a21\u5757\u5316\u89e3\u7801\u5668\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6216\u603b\u7ed3\u5185\u5bb9\uff0c\u4f5c\u4e3a\u4e2a\u6027\u7279\u5f81\u63d0\u53d6\u548c\u4e30\u5bcc\u5185\u5bb9\u751f\u6210\u7684\u5de5\u5177\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPICEPR\u7684\u201cPrompting-in-a-Series\u201d\u7b97\u6cd5\uff0c\u901a\u8fc7\u5185\u5bb9\u548c\u5d4c\u5165\u4e24\u4e2a\u7ba1\u9053\uff0c\u5229\u7528\u6a21\u5757\u5316\u7684\u89e3\u7801\u5668\u5355\u5411\u5927\u8bed\u8a00\u6a21\u578b\u6765\u751f\u6210\u548c\u603b\u7ed3\u5185\u5bb9\uff0c\u8fdb\u800c\u8f85\u52a9\u4e2a\u6027\u8bc6\u522b\u3002\u5b9e\u9a8c\u4e2d\u8fd8\u6bd4\u8f83\u4e86\u4e0d\u540c\u95ed\u6e90\u548c\u5f00\u6e90\u6a21\u578b\u7684\u5185\u5bb9\u751f\u6210\u8d28\u91cf\u3002PICEPR\u5728\u4e2a\u6027\u8bc6\u522b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e865-15%\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "PICEPR\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u4e2a\u6027\u8bc6\u522b\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u6a21\u578b\u6bd4\u8f83\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5237\u65b0\u4e86\u4e2a\u6027\u8bc6\u522b\u4efb\u52a1\u7684\u6027\u80fd\u8bb0\u5f55\u3002"}}
{"id": "2512.07015", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.07015", "abs": "https://arxiv.org/abs/2512.07015", "authors": ["Mayank Ravishankara"], "title": "FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to \"hallucinate with citations.\"\n  In this work, we introduce Falsification-Verification Alignment RAG (FVA-RAG), a framework that shifts the retrieval paradigm from Inductive Verification (seeking support) to Deductive Falsification (seeking disproof). Unlike existing \"Self-Correction\" methods that rely on internal consistency, FVA-RAG deploys a distinct Adversarial Retrieval Policy that actively generates \"Kill Queries\"-targeted search terms designed to surface contradictory evidence. We introduce a dual-verification mechanism that explicitly weighs the draft answer against this \"Anti-Context.\" Preliminary experiments on a dataset of common misconceptions demonstrate that FVA-RAG significantly improves robustness against sycophantic hallucinations compared to standard RAG baselines, effectively acting as an inference-time \"Red Team\" for factual generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6FVA-RAG\uff0c\u901a\u8fc7\u53cd\u5411\u5bfb\u627e\u53cd\u9a73\u8bc1\u636e\u548c\u53cc\u91cd\u9a8c\u8bc1\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u5927\u6a21\u578b\u751f\u6210\u4e2d\u7684\u9519\u8bef\u5f15\u8bc1\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5bb9\u6613\u53d7\u5230\u68c0\u7d22\u732e\u5a9a\uff08Retrieval Sycophancy\uff09\u95ee\u9898\u5f71\u54cd\uff0c\u5373\u68c0\u7d22\u7ed3\u679c\u503e\u5411\u4e8e\u652f\u6301\u7528\u6237\u504f\u89c1\u800c\u975e\u5ba2\u89c2\u4e8b\u5b9e\uff0c\u5bfc\u81f4\u6a21\u578b\u4f34\u968f\u9519\u8bef\u5f15\u7528\u4ea7\u751f\u5e7b\u89c9\u3002", "method": "\u5f15\u5165Falsification-Verification Alignment RAG\uff08FVA-RAG\uff09\u6846\u67b6\uff0c\u91c7\u7528\u5bf9\u6297\u5f0f\u68c0\u7d22\u7b56\u7565\u751f\u6210\u65e8\u5728\u63ed\u793a\u53cd\u9a73\u8bc1\u636e\u7684\u201c\u6740\u67e5\u8be2\u201d\uff0c\u5e76\u901a\u8fc7\u53cc\u91cd\u9a8c\u8bc1\u673a\u5236\u5bf9\u8349\u62df\u7b54\u6848\u548c\u53cd\u9762\u4e0a\u4e0b\u6587\u8fdb\u884c\u6743\u8861\u3002", "result": "FVA-RAG\u5728\u9488\u5bf9\u5e38\u89c1\u8bef\u89e3\u7684\u6570\u636e\u96c6\u4e0a\u7684\u521d\u6b65\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u8f83\u4e8e\u6807\u51c6RAG\u57fa\u7ebf\uff0cFVA-RAG\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u68c0\u7d22\u732e\u5a9a\u5e7b\u89c9\u7684\u9c81\u68d2\u6027\uff0c\u6709\u6548\u4f5c\u4e3a\u63a8\u7406\u65f6\u7684\u201c\u7ea2\u961f\u201d\u7b5b\u67e5\u751f\u6210\u4e8b\u5b9e\u7684\u51c6\u786e\u6027\u3002", "conclusion": "FVA-RAG\u901a\u8fc7\u8f6c\u53d8\u68c0\u7d22\u7b56\u7565\u548c\u5f15\u5165\u5bf9\u6297\u6027\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6a21\u578b\u5728\u9762\u5bf9\u9519\u8bef\u524d\u63d0\u67e5\u8be2\u65f6\u7684\u4e8b\u5b9e\u751f\u6210\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2512.07059", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07059", "abs": "https://arxiv.org/abs/2512.07059", "authors": ["Richard Young"], "title": "Replicating TEMPEST at Scale: Multi-Turn Adversarial Attacks Against Trillion-Parameter Frontier Models", "comment": "30 pages, 11 figures, 5 tables. Code and data: https://github.com/ricyoung/tempest-replication", "summary": "Despite substantial investment in safety alignment, the vulnerability of large language models to sophisticated multi-turn adversarial attacks remains poorly characterized, and whether model scale or inference mode affects robustness is unknown. This study employed the TEMPEST multi-turn attack framework to evaluate ten frontier models from eight vendors across 1,000 harmful behaviors, generating over 97,000 API queries across adversarial conversations with automated evaluation by independent safety classifiers. Results demonstrated a spectrum of vulnerability: six models achieved 96% to 100% attack success rate (ASR), while four showed meaningful resistance, with ASR ranging from 42% to 78%; enabling extended reasoning on identical architecture reduced ASR from 97% to 42%. These findings indicate that safety alignment quality varies substantially across vendors, that model scale does not predict adversarial robustness, and that thinking mode provides a deployable safety enhancement. Collectively, this work establishes that current alignment techniques remain fundamentally vulnerable to adaptive multi-turn attacks regardless of model scale, while identifying deliberative inference as a promising defense direction.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u591a\u8f6e\u5bf9\u6297\u653b\u51fb\u7684\u8106\u5f31\u6027\uff0c\u53d1\u73b0\u89c4\u6a21\u4e0d\u51b3\u5b9a\u9c81\u68d2\u6027\uff0c\u63a8\u7406\u6a21\u5f0f\u80fd\u6709\u6548\u589e\u5f3a\u5b89\u5168\u6027\uff0c\u73b0\u6709\u5bf9\u9f50\u6280\u672f\u4f9d\u7136\u96be\u4ee5\u5b8c\u5168\u9632\u5fa1\u6b64\u7c7b\u653b\u51fb\u3002", "motivation": "\u5c3d\u7ba1\u5728\u5b89\u5168\u5bf9\u9f50\u4e0a\u6295\u5165\u5de8\u5927\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u590d\u6742\u591a\u8f6e\u5bf9\u6297\u653b\u51fb\u7684\u8106\u5f31\u6027\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\uff0c\u4e14\u6a21\u578b\u89c4\u6a21\u53ca\u63a8\u7406\u6a21\u5f0f\u5bf9\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u91c7\u7528TEMPEST\u591a\u8f6e\u653b\u51fb\u6846\u67b6\uff0c\u5bf9\u6765\u81ea\u516b\u4e2a\u5382\u5546\u7684\u5341\u4e2a\u524d\u6cbf\u6a21\u578b\uff0c\u57281000\u79cd\u6709\u5bb3\u884c\u4e3a\u4e0a\u8fdb\u884c\u5bf9\u6297\u6d4b\u8bd5\uff0c\u5171\u751f\u6210\u7ea697000\u6b21API\u67e5\u8be2\uff0c\u5e76\u901a\u8fc7\u72ec\u7acb\u5b89\u5168\u5206\u7c7b\u5668\u81ea\u52a8\u8bc4\u4f30\u3002", "result": "\u516d\u4e2a\u6a21\u578b\u7684\u653b\u51fb\u6210\u529f\u7387\u9ad8\u8fbe96%-100%\uff0c\u56db\u4e2a\u6a21\u578b\u8868\u73b0\u51fa\u4e00\u5b9a\u62b5\u6297\u529b\uff0c\u653b\u51fb\u6210\u529f\u738742%-78%\uff1b\u5728\u76f8\u540c\u67b6\u6784\u4e0b\u542f\u7528\u5ef6\u4f38\u63a8\u7406\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4ece97%\u964d\u81f342%\u3002", "conclusion": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65e0\u8bba\u89c4\u6a21\u5927\u5c0f\uff0c\u5728\u9762\u5bf9\u9002\u5e94\u6027\u591a\u8f6e\u5bf9\u6297\u653b\u51fb\u65f6\u4ecd\u5b58\u5728\u663e\u8457\u8106\u5f31\u6027\uff0c\u5b89\u5168\u5bf9\u9f50\u8d28\u91cf\u5728\u4e0d\u540c\u5382\u5546\u95f4\u5dee\u5f02\u8f83\u5927\u3002\u63a8\u7406\u6a21\u5f0f\uff08\u601d\u8003\u6a21\u5f0f\uff09\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002"}}
{"id": "2512.07068", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07068", "abs": "https://arxiv.org/abs/2512.07068", "authors": ["Emma Markle", "Javier Gutierrez Bach", "Shira Wein"], "title": "SETUP: Sentence-level English-To-Uniform Meaning Representation Parser", "comment": null, "summary": "Uniform Meaning Representation (UMR) is a novel graph-based semantic representation which captures the core meaning of a text, with flexibility incorporated into the annotation schema such that the breadth of the world's languages can be annotated (including low-resource languages). While UMR shows promise in enabling language documentation, improving low-resource language technologies, and adding interpretability, the downstream applications of UMR can only be fully explored when text-to-UMR parsers enable the automatic large-scale production of accurate UMR graphs at test time. Prior work on text-to-UMR parsing is limited to date. In this paper, we introduce two methods for English text-to-UMR parsing, one of which fine-tunes existing parsers for Abstract Meaning Representation and the other, which leverages a converter from Universal Dependencies, using prior work as a baseline. Our best-performing model, which we call SETUP, achieves an AnCast score of 84 and a SMATCH++ score of 91, indicating substantial gains towards automatic UMR parsing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e24\u79cd\u82f1\u8bed\u6587\u672c\u5230UMR\u7684\u89e3\u6790\u65b9\u6cd5\uff0c\u6700\u4f73\u6a21\u578b\u8fbe91\u5206\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u89e3\u6790\u6548\u679c\u3002", "motivation": "\u4e3a\u4e86\u63a8\u52a8UMR\u7684\u5b9e\u9645\u5e94\u7528\u548c\u8bed\u8a00\u6280\u672f\u8fdb\u6b65\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u9886\u57df\uff0c\u9700\u8981\u5f00\u53d1\u51c6\u786e\u7684\u6587\u672c\u5230UMR\u81ea\u52a8\u89e3\u6790\u5668\uff0c\u4ee5\u5b9e\u73b0\u5927\u89c4\u6a21\u9ad8\u8d28\u91cfUMR\u56fe\u7684\u751f\u6210\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u73b0\u6709AMR\u89e3\u6790\u5668\u548c\u5229\u7528UD\u8f6c\u6362\u5668\u4e24\u79cd\u65b9\u6cd5\u8fdb\u884c\u6587\u672c\u5230UMR\u7684\u89e3\u6790\uff0c\u57fa\u4e8e\u5df2\u6709\u5de5\u4f5c\u8fdb\u884c\u6539\u8fdb\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u5c06\u82f1\u8bed\u6587\u672c\u89e3\u6790\u4e3a\u7edf\u4e00\u8bed\u4e49\u8868\u793a\uff08UMR\uff09\u56fe\u7684\u65b9\u6cd5\uff0c\u4e00\u79cd\u662f\u5bf9\u62bd\u8c61\u610f\u4e49\u8868\u793a\uff08AMR\uff09\u89e3\u6790\u5668\u7684\u5fae\u8c03\uff0c\u53e6\u4e00\u79cd\u5219\u5229\u7528\u901a\u7528\u4f9d\u5b58\u53e5\u6cd5\uff08UD\uff09\u8f6c\u6362\u5668\u4f5c\u4e3a\u57fa\u7ebf\u3002\u8be5\u5de5\u4f5c\u7684\u6700\u4f73\u6a21\u578bSETUP\u5728AnCast\u548cSMATCH++\u6307\u6807\u4e0a\u5206\u522b\u8fbe\u5230\u4e8684\u548c91\u5206\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8UMR\u89e3\u6790\u7684\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5fae\u8c03AMR\u89e3\u6790\u5668\u548c\u5229\u7528UD\u8f6c\u6362\uff0c\u4e24\u79cd\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5230UMR\u7684\u81ea\u52a8\u89e3\u6790\u6027\u80fd\uff0c\u6700\u4f18\u6a21\u578b\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u3002"}}
{"id": "2512.07075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07075", "abs": "https://arxiv.org/abs/2512.07075", "authors": ["Shiwei Guo", "Sihang Jiang", "Qianxi He", "Yanghua Xiao", "Jiaqing Liang", "Bi Yude", "Minggui He", "Shimin Tao", "Li Zhang"], "title": "Do Large Language Models Truly Understand Cross-cultural Differences?", "comment": null, "summary": "In recent years, large language models (LLMs) have demonstrated strong performance on multilingual tasks. Given its wide range of applications, cross-cultural understanding capability is a crucial competency. However, existing benchmarks for evaluating whether LLMs genuinely possess this capability suffer from three key limitations: a lack of contextual scenarios, insufficient cross-cultural concept mapping, and limited deep cultural reasoning capabilities. To address these gaps, we propose SAGE, a scenario-based benchmark built via cross-cultural core concept alignment and generative task design, to evaluate LLMs' cross-cultural understanding and reasoning. Grounded in cultural theory, we categorize cross-cultural capabilities into nine dimensions. Using this framework, we curated 210 core concepts and constructed 4530 test items across 15 specific real-world scenarios, organized under four broader categories of cross-cultural situations, following established item design principles. The SAGE dataset supports continuous expansion, and experiments confirm its transferability to other languages. It reveals model weaknesses across both dimensions and scenarios, exposing systematic limitations in cross-cultural reasoning. While progress has been made, LLMs are still some distance away from reaching a truly nuanced cross-cultural understanding. In compliance with the anonymity policy, we include data and code in the supplement materials. In future versions, we will make them publicly available online.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SAGE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u60c5\u666f\u5f0f\u8bbe\u8ba1\u548c\u8de8\u6587\u5316\u6838\u5fc3\u6982\u5ff5\u5bf9\u9f50\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6587\u5316\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u6db5\u76d6\u4e5d\u4e2a\u7ef4\u5ea6\u548c\u591a\u79cd\u771f\u5b9e\u573a\u666f\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u8de8\u6587\u5316\u63a8\u7406\u4e0a\u7684\u7cfb\u7edf\u6027\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u8bc4\u6d4b\u5de5\u5177\u7f3a\u4e4f\u60c5\u666f\u80cc\u666f\u3001\u8de8\u6587\u5316\u6982\u5ff5\u6620\u5c04\u4e0d\u8db3\u3001\u6df1\u5ea6\u6587\u5316\u63a8\u7406\u80fd\u529b\u6709\u9650\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6587\u5316\u7406\u89e3\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u57fa\u4e8e\u6587\u5316\u7406\u8bba\u5212\u5206\u7684\u4e5d\u4e2a\u8de8\u6587\u5316\u80fd\u529b\u7ef4\u5ea6\uff0c\u6536\u96c6210\u4e2a\u6838\u5fc3\u6982\u5ff5\uff0c\u8bbe\u8ba14530\u4e2a\u6d4b\u8bd5\u9898\u76ee\uff0c\u6db5\u76d615\u4e2a\u771f\u5b9e\u573a\u666f\uff0c\u6784\u5efa\u4e86SAGE\u573a\u666f\u5f0f\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u9a8c\u8bc1\u5176\u53ef\u8fc1\u79fb\u6027\u3002", "result": "SAGE\u57fa\u51c6\u63ed\u9732\u4e86\u6a21\u578b\u5728\u591a\u4e2a\u8de8\u6587\u5316\u7ef4\u5ea6\u4e0e\u573a\u666f\u4e0b\u7684\u5f31\u70b9\u548c\u7cfb\u7edf\u6027\u5c40\u9650\uff0c\u867d\u7136\u6a21\u578b\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u4ecd\u65e0\u6cd5\u8fbe\u5230\u7ec6\u81f4\u7684\u8de8\u6587\u5316\u7406\u89e3\u8981\u6c42\u3002", "conclusion": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u76ee\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6587\u5316\u7406\u89e3\u4e0e\u63a8\u7406\u65b9\u9762\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u8ddd\u79bb\u771f\u6b63\u7684\u7ec6\u817b\u8de8\u6587\u5316\u7406\u89e3\u8fd8\u6709\u8f83\u5927\u5dee\u8ddd\u3002"}}
{"id": "2512.07090", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07090", "abs": "https://arxiv.org/abs/2512.07090", "authors": ["Jungmin Lee", "Gwangeun Byeon", "Yulhwa Kim", "Seokin Hong"], "title": "Leveraging KV Similarity for Online Structured Pruning in LLMs", "comment": null, "summary": "Pruning has emerged as a promising direction for accelerating large language model (LLM) inference, yet existing approaches often suffer from instability because they rely on offline calibration data that may not generalize across inputs. In this work, we introduce Token Filtering, a lightweight online structured pruning technique that makes pruning decisions directly during inference without any calibration data. The key idea is to measure token redundancy via joint key-value similarity and skip redundant attention computations, thereby reducing inference cost while preserving critical information. To further enhance stability, we design a variance-aware fusion strategy that adaptively weights key and value similarity across heads, ensuring that informative tokens are retained even under high pruning ratios. This design introduces no additional memory overhead and provides a more reliable criterion for token importance. Extensive experiments on LLaMA-2 (7B/13B), LLaMA-3 (8B), and Mistral (7B) demonstrate that Token Filtering consistently outperforms prior structured pruning methods, preserving accuracy on commonsense reasoning benchmarks and maintaining strong performance on challenging tasks such as MMLU, even with 50% pruning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u7ebf\u8f7b\u91cf\u7ea7\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u2014\u2014Token Filtering\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u76f4\u63a5\u5224\u65adtoken\u5197\u4f59\u6765\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u65e0\u9700\u79bb\u7ebf\u6821\u51c6\u6570\u636e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b9\u5dee\u611f\u77e5\u878d\u5408\u7b56\u7565\u589e\u5f3a\u7a33\u5b9a\u6027\u3002\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u9879\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u526a\u679d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u79bb\u7ebf\u6821\u51c6\u6570\u636e\u7684\u526a\u679d\u65b9\u6cd5\u666e\u904d\u5b58\u5728\u6cdb\u5316\u80fd\u529b\u5dee\u548c\u526a\u679d\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u65e0\u9700\u6821\u51c6\u4e14\u5728\u7ebf\u52a8\u6001\u5224\u65ad\u7684\u91cd\u8981\u6027\u526a\u679d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8054\u5408\u952e\u503c\u76f8\u4f3c\u5ea6\u7684token\u5197\u4f59\u5ea6\u8861\u91cf\u65b9\u6cd5\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8df3\u8fc7\u5197\u4f59token\u7684\u6ce8\u610f\u529b\u8ba1\u7b97\uff1b\u8bbe\u8ba1\u4e86\u65b9\u5dee\u611f\u77e5\u7684\u878d\u5408\u7b56\u7565\u81ea\u9002\u5e94\u8c03\u6574\u591a\u5934\u6ce8\u610f\u529b\u4e2d\u7684\u76f8\u4f3c\u5ea6\u6743\u91cd\uff0c\u4ee5\u7a33\u5b9a\u4fdd\u7559\u91cd\u8981token\u3002", "result": "\u5728LLaMA-2\uff087B/13B\uff09\u3001LLaMA-3\uff088B\uff09\u548cMistral\uff087B\uff09\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u5927\u91cf\u5b9e\u9a8c\u663e\u793a\uff0cToken Filtering\u5728\u4fdd\u6301\u5e38\u8bc6\u63a8\u7406\u51c6\u786e\u7387\u548c\u5e94\u5bf9MMLU\u7b49\u6311\u6218\u6027\u4efb\u52a1\u65f6\uff0c\u572850%\u526a\u679d\u6bd4\u4e0b\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff0c\u4f18\u4e8e\u4ee5\u5f80\u65b9\u6cd5\u3002", "conclusion": "Token Filtering\u901a\u8fc7\u5728\u7ebf\u52a8\u6001\u5224\u65adtoken\u91cd\u8981\u6027\u548c\u8df3\u8fc7\u5197\u4f59\u6ce8\u610f\u529b\u8ba1\u7b97\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6bd4\u4f8b\u526a\u679d\u4e0b\u6a21\u578b\u6027\u80fd\u7684\u7a33\u5b9a\u4fdd\u6301\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7ed3\u6784\u5316\u526a\u679d\u65b9\u6cd5\u3002"}}
{"id": "2512.07132", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07132", "abs": "https://arxiv.org/abs/2512.07132", "authors": ["Nithin Sivakumaran", "Justin Chih-Yao Chen", "David Wan", "Yue Zhang", "Jaehong Yoon", "Elias Stengel-Eskin", "Mohit Bansal"], "title": "DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning", "comment": "Code: https://github.com/nsivaku/dart", "summary": "Specialized visual tools can augment large language models or vision language models with expert knowledge (e.g., grounding, spatial reasoning, medical knowledge, etc.), but knowing which tools to call (and when to call them) can be challenging. We introduce DART, a multi-agent framework that uses disagreements between multiple debating visual agents to identify useful visual tools (e.g., object detection, OCR, spatial reasoning, etc.) that can resolve inter-agent disagreement. These tools allow for fruitful multi-agent discussion by introducing new information, and by providing tool-aligned agreement scores that highlight agents in agreement with expert tools, thereby facilitating discussion. We utilize an aggregator agent to select the best answer by providing the agent outputs and tool information. We test DART on four diverse benchmarks and show that our approach improves over multi-agent debate as well as over single agent tool-calling frameworks, beating the next-strongest baseline (multi-agent debate with a judge model) by 3.4% and 2.4% on A-OKVQA and MMMU respectively. We also find that DART adapts well to new tools in applied domains, with a 1.3% improvement on the M3D medical dataset over other strong tool-calling, single agent, and multi-agent baselines. Additionally, we measure text overlap across rounds to highlight the rich discussion in DART compared to existing multi-agent methods. Finally, we study the tool call distribution, finding that diverse tools are reliably used to help resolve disagreement.", "AI": {"tldr": "DART\u901a\u8fc7\u591a\u4ee3\u7406\u5206\u6b67\u9a71\u52a8\u5de5\u5177\u8c03\u7528\u63d0\u5347\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8868\u73b0\uff0c\u5728\u591a\u9879\u4efb\u52a1\u548c\u5e94\u7528\u9886\u57df\u5747\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5728\u591a\u4ee3\u7406\u89c6\u89c9\u6a21\u578b\u4e2d\uff0c\u9009\u62e9\u5408\u9002\u7684\u5de5\u5177\u8fdb\u884c\u8c03\u7528\u53ca\u5176\u65f6\u673a\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51faDART\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u89c6\u89c9\u4ee3\u7406\u4e4b\u95f4\u7684\u5206\u6b67\u6765\u8bc6\u522b\u80fd\u89e3\u51b3\u5206\u6b67\u7684\u89c6\u89c9\u5de5\u5177\uff0c\u4f7f\u7528\u805a\u5408\u4ee3\u7406\u6839\u636e\u5de5\u5177\u4fe1\u606f\u548c\u4ee3\u7406\u8f93\u51fa\u9009\u62e9\u6700\u4f73\u7b54\u6848\u3002", "result": "DART\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u591a\u4ee3\u7406\u8fa9\u8bba\u53ca\u5355\u4ee3\u7406\u5de5\u5177\u8c03\u7528\u6846\u67b6\uff0c\u5728A-OKVQA\u548cMMMU\u6570\u636e\u96c6\u4e0a\u5206\u522b\u63d0\u53473.4%\u548c2.4%\uff0c\u5728M3D\u533b\u7597\u6570\u636e\u96c6\u63d0\u53471.3%\u3002", "conclusion": "DART\u80fd\u591f\u6709\u6548\u5229\u7528\u591a\u6837\u5316\u5de5\u5177\u89e3\u51b3\u4ee3\u7406\u95f4\u5206\u6b67\uff0c\u4fc3\u8fdb\u591a\u4ee3\u7406\u8ba8\u8bba\uff0c\u5e76\u9002\u5e94\u5e94\u7528\u9886\u57df\u4e2d\u65b0\u5de5\u5177\u7684\u4f7f\u7528\u3002"}}
{"id": "2512.07134", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07134", "abs": "https://arxiv.org/abs/2512.07134", "authors": ["Lauren Levine", "Amir Zeldes"], "title": "GUMBridge: a Corpus for Varieties of Bridging Anaphora", "comment": null, "summary": "Bridging is an anaphoric phenomenon where the referent of an entity in a discourse is dependent on a previous, non-identical entity for interpretation, such as in \"There is 'a house'. 'The door' is red,\" where the door is specifically understood to be the door of the aforementioned house. While there are several existing resources in English for bridging anaphora, most are small, provide limited coverage of the phenomenon, and/or provide limited genre coverage. In this paper, we introduce GUMBridge, a new resource for bridging, which includes 16 diverse genres of English, providing both broad coverage for the phenomenon and granular annotations for the subtype categorization of bridging varieties. We also present an evaluation of annotation quality and report on baseline performance using open and closed source contemporary LLMs on three tasks underlying our data, showing that bridging resolution and subtype classification remain difficult NLP tasks in the age of LLMs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GUMBridge\uff0c\u4e00\u4e2a\u6db5\u76d616\u79cd\u82f1\u8bed\u6587\u4f53\u7684\u6865\u63a5\u6307\u4ee3\u8d44\u6e90\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6ce8\u91ca\u8d28\u91cf\u53ca\u4f7f\u7528\u591a\u6b3e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u7ebf\u6027\u80fd\uff0c\u6307\u51fa\u6865\u63a5\u6307\u4ee3\u89e3\u6790\u4f9d\u7136\u8270\u96be\u3002", "motivation": "\u73b0\u6709\u7684\u82f1\u8bed\u6865\u63a5\u6307\u4ee3\u8d44\u6e90\u89c4\u6a21\u5c0f\u3001\u73b0\u8c61\u8986\u76d6\u6709\u9650\u3001\u6587\u4f53\u5355\u4e00\uff0c\u96be\u4ee5\u652f\u6301\u6df1\u5165\u7814\u7a76\u3002", "method": "\u63d0\u51faGUMBridge\u8d44\u6e90\uff0c\u5305\u542b16\u79cd\u82f1\u8bed\u4e0d\u540c\u6587\u4f53\u7684\u6865\u63a5\u6307\u4ee3\u6807\u6ce8\uff0c\u5e76\u8fdb\u884c\u4e86\u6ce8\u91ca\u8d28\u91cf\u8bc4\u4f30\u548c\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u6784\u5efa\u4e86\u6db5\u76d6\u591a\u6837\u6587\u4f53\u548c\u7ec6\u7c92\u5ea6\u5b50\u7c7b\u578b\u7684\u6865\u63a5\u6307\u4ee3\u8d44\u6e90\uff0c\u8bc4\u4f30\u4e86\u6ce8\u91ca\u8d28\u91cf\uff0c\u57fa\u4e8e\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u7ebf\u6027\u80fd\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6865\u63a5\u89e3\u6790\u548c\u5b50\u7c7b\u578b\u5206\u7c7b\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u63d0\u51fa\u4e86\u6db5\u76d6\u5e7f\u6cdb\u7684\u6865\u63a5\u6307\u4ee3\u6570\u636e\u96c6\uff0c\u6865\u63a5\u6307\u4ee3\u7684\u81ea\u52a8\u89e3\u6790\u548c\u7ec6\u5206\u7c7b\u522b\u8bc6\u522b\u4f9d\u7136\u662f\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u9ad8\u6548\u89e3\u51b3\u7684\u4efb\u52a1\u3002"}}
{"id": "2512.07218", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07218", "abs": "https://arxiv.org/abs/2512.07218", "authors": ["Feng Liang", "Weixin Zeng", "Runhao Zhao", "Xiang Zhao"], "title": "NeSTR: A Neuro-Symbolic Abductive Framework for Temporal Reasoning in Large Language Models", "comment": "Accepted by AAAI 2026", "summary": "Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, temporal reasoning, particularly under complex temporal constraints, remains a major challenge. To this end, existing approaches have explored symbolic methods, which encode temporal structure explicitly, and reflective mechanisms, which revise reasoning errors through multi-step inference. Nonetheless, symbolic approaches often underutilize the reasoning capabilities of LLMs, while reflective methods typically lack structured temporal representations, which can result in inconsistent or hallucinated reasoning. As a result, even when the correct temporal context is available, LLMs may still misinterpret or misapply time-related information, leading to incomplete or inaccurate answers. To address these limitations, in this work, we propose Neuro-Symbolic Temporal Reasoning (NeSTR), a novel framework that integrates structured symbolic representations with hybrid reflective reasoning to enhance the temporal sensitivity of LLM inference. NeSTR preserves explicit temporal relations through symbolic encoding, enforces logical consistency via verification, and corrects flawed inferences using abductive reflection. Extensive experiments on diverse temporal question answering benchmarks demonstrate that NeSTR achieves superior zero-shot performance and consistently improves temporal reasoning without any fine-tuning, showcasing the advantage of neuro-symbolic integration in enhancing temporal understanding in large language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNeSTR\u6846\u67b6\uff0c\u878d\u5408\u7b26\u53f7\u7f16\u7801\u548c\u53cd\u601d\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u65f6\u95f4\u63a8\u7406\u4efb\u52a1\u65f6\u5b58\u5728\u4e0d\u8db3\uff0c\u7b26\u53f7\u65b9\u6cd5\u548c\u53cd\u601d\u673a\u5236\u5404\u81ea\u6709\u4f18\u7f3a\u70b9\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u5145\u5206\u5229\u7528\u65f6\u95f4\u76f8\u5173\u4fe1\u606f\uff0c\u63a8\u7406\u7ed3\u679c\u53ef\u80fd\u4e0d\u51c6\u786e\u3002", "method": "NeSTR\u6846\u67b6\u901a\u8fc7\u7b26\u53f7\u7f16\u7801\u663e\u5f0f\u4fdd\u5b58\u65f6\u95f4\u5173\u7cfb\uff0c\u5229\u7528\u903b\u8f91\u9a8c\u8bc1\u4fdd\u8bc1\u4e00\u81f4\u6027\uff0c\u5e76\u7ed3\u5408\u6eaf\u56e0\u53cd\u601d\u7ea0\u6b63\u63a8\u7406\u9519\u8bef\uff0c\u5b9e\u73b0\u6df7\u5408\u53cd\u601d\u63a8\u7406\u673a\u5236\u3002", "result": "\u63d0\u51faNeuro-Symbolic Temporal Reasoning (NeSTR)\u6846\u67b6\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u7b26\u53f7\u8868\u793a\u4e0e\u6df7\u5408\u53cd\u601d\u63a8\u7406\uff0c\u63d0\u5347\u4e86LLM\u7684\u65f6\u95f4\u654f\u611f\u6027\u548c\u63a8\u7406\u4e00\u81f4\u6027\uff0c\u5728\u591a\u9879\u65f6\u95f4\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u73b0\u51fa\u4f18\u5f02\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "conclusion": "NeSTR\u901a\u8fc7\u795e\u7ecf\u7b26\u53f7\u878d\u5408\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u95f4\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u51c6\u786e\u548c\u4e00\u81f4\u7684\u65f6\u95f4\u76f8\u5173\u63a8\u7406\uff0c\u4e14\u65e0\u9700\u5fae\u8c03\u3002"}}
{"id": "2512.07246", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07246", "abs": "https://arxiv.org/abs/2512.07246", "authors": ["Mengqi Wang", "Jianwei Wang", "Qing Liu", "Xiwei Xu", "Zhenchang Xing", "Liming Zhu", "Wenjie Zhang"], "title": "Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection", "comment": "14 pages, 8 figures", "summary": "Error detection (ED), which aims to identify incorrect or inconsistent cell values in tabular data, is important for ensuring data quality. Recent state-of-the-art ED methods leverage the pre-trained knowledge and semantic capability embedded in large language models (LLMs) to directly label whether a cell is erroneous. However, this LLM-as-a-labeler pipeline (1) relies on the black box, implicit decision process, thus failing to provide explainability for the detection results, and (2) is highly sensitive to prompts, yielding inconsistent outputs due to inherent model stochasticity, therefore lacking robustness. To address these limitations, we propose an LLM-as-an-inducer framework that adopts LLM to induce the decision tree for ED (termed TreeED) and further ensembles multiple such trees for consensus detection (termed ForestED), thereby improving explainability and robustness. Specifically, based on prompts derived from data context, decision tree specifications and output requirements, TreeED queries the LLM to induce the decision tree skeleton, whose root-to-leaf decision paths specify the stepwise procedure for evaluating a given sample. Each tree contains three types of nodes: (1) rule nodes that perform simple validation checks (e.g., format or range), (2) Graph Neural Network (GNN) nodes that capture complex patterns (e.g., functional dependencies), and (3) leaf nodes that output the final decision types (error or clean). Furthermore, ForestED employs uncertainty-based sampling to obtain multiple row subsets, constructing a decision tree for each subset using TreeED. It then leverages an Expectation-Maximization-based algorithm that jointly estimates tree reliability and optimizes the consensus ED prediction. Extensive xperiments demonstrate that our methods are accurate, explainable and robust, achieving an average F1-score improvement of 16.1% over the best baseline.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8bf1\u5bfc\u51b3\u7b56\u6811\u53ca\u96c6\u6210\u5b66\u4e60\u7684\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6570\u636e\u9519\u8bef\u68c0\u6d4b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u7cbe\u5ea6\u4e0a\u8f83\u73b0\u6709\u65b9\u6cd5\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u91c7\u7528\u9ed1\u76d2\u76f4\u63a5\u6807\u6ce8\u7ec6\u80de\u662f\u5426\u9519\u8bef\uff0c\u5b58\u5728\u7f3a\u4e4f\u7ed3\u679c\u53ef\u89e3\u91ca\u6027\u548c\u5bf9\u63d0\u793a\u654f\u611f\u5bfc\u81f4\u8f93\u51fa\u4e0d\u7a33\u5b9a\u7684\u7f3a\u70b9\uff0c\u4e9f\u9700\u63d0\u51fa\u4e00\u79cd\u65e2\u80fd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u53c8\u5177\u5907\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u7684\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8bf1\u5bfc\u51b3\u7b56\u6811\u7684\u65b9\u6cd5\uff08TreeED\uff09\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5305\u542b\u89c4\u5219\u8282\u70b9\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u8282\u70b9\u548c\u53f6\u8282\u70b9\u7684\u51b3\u7b56\u6811\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u9010\u6b65\u4e14\u53ef\u89e3\u91ca\u7684\u9519\u8bef\u68c0\u6d4b\u6d41\u7a0b\uff1b\u8fdb\u4e00\u6b65\u901a\u8fc7\u4e0d\u786e\u5b9a\u91c7\u6837\u6784\u9020\u591a\u4e2a\u5b50\u96c6\uff0c\u5229\u7528\u671f\u671b\u6700\u5927\u5316\u7b97\u6cd5\u4f30\u8ba1\u6811\u7684\u53ef\u9760\u6027\u5e76\u4f18\u5316\u96c6\u6210\u51b3\u7b56\uff0c\u5b9e\u73b0\u4e86\u66f4\u9c81\u68d2\u7684\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\uff08ForestED\uff09\u3002", "result": "\u672c\u6587\u65b9\u6cd5\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\uff0c\u76f8\u8f83\u4e8e\u6700\u4f18\u57fa\u7ebf\u65b9\u6cd5\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u534716.1%\uff0c\u540c\u65f6\u5177\u5907\u8f83\u5f3a\u7684\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u6709\u6548\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8bf1\u5bfc\u51b3\u7b56\u6811\u7684\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\uff08TreeED\uff09\u53ca\u5176\u96c6\u6210\u7248\uff08ForestED\uff09\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9519\u8bef\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8868\u660e\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u9c81\u68d2\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u4f73\u65b9\u6cd5\uff0cF1\u5206\u6570\u5e73\u5747\u63d0\u9ad8\u4e8616.1%\u3002"}}
{"id": "2512.07265", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.07265", "abs": "https://arxiv.org/abs/2512.07265", "authors": ["Bhavana Akkiraju", "Srihari Bandarupalli", "Swathi Sambangi", "Vasavi Ravuri", "R Vijaya Saraswathi", "Anil Kumar Vuppala"], "title": "TeluguST-46: A Benchmark Corpus and Comprehensive Evaluation for Telugu-English Speech Translation", "comment": "Submitted to AACL IJCNLP 2025", "summary": "Despite Telugu being spoken by over 80 million people, speech translation research for this morphologically rich language remains severely underexplored. We address this gap by developing a high-quality Telugu--English speech translation benchmark from 46 hours of manually verified CSTD corpus data (30h/8h/8h train/dev/test split). Our systematic comparison of cascaded versus end-to-end architectures shows that while IndicWhisper + IndicMT achieves the highest performance due to extensive Telugu-specific training data, finetuned SeamlessM4T models demonstrate remarkable competitiveness despite using significantly less Telugu-specific training data. This finding suggests that with careful hyperparameter tuning and sufficient parallel data (potentially less than 100 hours), end-to-end systems can achieve performance comparable to cascaded approaches in low-resource settings. Our metric reliability study evaluating BLEU, METEOR, ChrF++, ROUGE-L, TER, and BERTScore against human judgments reveals that traditional metrics provide better quality discrimination than BERTScore for Telugu--English translation. The work delivers three key contributions: a reproducible Telugu--English benchmark, empirical evidence of competitive end-to-end performance potential in low-resource scenarios, and practical guidance for automatic evaluation in morphologically complex language pairs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6cf0\u5362\u56fa\u8bed-\u82f1\u8bed\u8bed\u97f3\u7ffb\u8bd1\u57fa\u51c6\uff0c\u5c55\u793a\u4e86\u7aef\u5230\u7aef\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684\u7ade\u4e89\u529b\uff0c\u5e76\u5bf9\u591a\u79cd\u8bc4\u4ef7\u6307\u6807\u8fdb\u884c\u4e86\u5b9e\u8bc1\u5206\u6790\u3002", "motivation": "\u6cf0\u5362\u56fa\u8bed\u4f5c\u4e3a\u4e00\u79cd\u5f62\u6001\u4e30\u5bcc\u7684\u8bed\u8a00\uff0c\u5c3d\u7ba1\u62e5\u6709\u8d85\u8fc78000\u4e07\u4f7f\u7528\u8005\uff0c\u4f46\u5176\u8bed\u97f3\u7ffb\u8bd1\u7814\u7a76\u4ecd\u4e25\u91cd\u7f3a\u4e4f\u3002", "method": "\u4ece46\u5c0f\u65f6\u7ecf\u4eba\u5de5\u9a8c\u8bc1\u7684CSTD\u8bed\u6599\u4e2d\u6784\u5efa\u8bad\u7ec3\u96c6\uff0c\u7cfb\u7edf\u6bd4\u8f83\u7ea7\u8054(IndicWhisper+IndicMT)\u548c\u7aef\u5230\u7aef(SeamlessM4T\u5fae\u8c03)\u67b6\u6784\uff0c\u8bc4\u4f30\u591a\u79cd\u7ffb\u8bd1\u8d28\u91cf\u6307\u6807\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u76f8\u5173\u6027\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u6cf0\u5362\u56fa\u8bed-\u82f1\u8bed\u8bed\u97f3\u7ffb\u8bd1\u57fa\u51c6\uff0c\u6bd4\u8f83\u4e86\u7ea7\u8054\u4e0e\u7aef\u5230\u7aef\u67b6\u6784\uff0c\u53d1\u73b0\u7aef\u5230\u7aef\u6a21\u578b\u5728\u5145\u5206\u8c03\u53c2\u5e76\u5177\u5907\u4e00\u5b9a\u5e73\u884c\u6570\u636e\u65f6\u53ef\u8fbe\u5230\u63a5\u8fd1\u7ea7\u8054\u6a21\u578b\u7684\u6027\u80fd\uff1b\u540c\u65f6\u8bc4\u4f30\u4e86\u591a\u79cd\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\uff0c\u4f20\u7edf\u6307\u6807\u5728\u8be5\u4efb\u52a1\u4e2d\u4f18\u4e8eBERTScore\u3002", "conclusion": "\u7aef\u5230\u7aef\u8bed\u97f3\u7ffb\u8bd1\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u6761\u4ef6\u4e0b\uff0c\u901a\u8fc7\u9002\u5f53\u8c03\u53c2\u548c\u9002\u91cf\u5e73\u884c\u6570\u636e\uff0c\u53ef\u4ee5\u5b9e\u73b0\u4e0e\u7ea7\u8054\u7cfb\u7edf\u76f8\u5f53\u7684\u7ffb\u8bd1\u6027\u80fd\uff0c\u540c\u65f6\u4f20\u7edf\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u66f4\u9002\u5408\u8bc4\u4f30\u6cf0\u5362\u56fa\u8bed-\u82f1\u8bed\u7ffb\u8bd1\u8d28\u91cf\u3002"}}
{"id": "2512.07277", "categories": ["cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.07277", "abs": "https://arxiv.org/abs/2512.07277", "authors": ["Srihari Bandarupalli", "Bhavana Akkiraju", "Charan Devarakonda", "Vamsiraghusimha Narsinga", "Anil Kumar Vuppala"], "title": "Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data", "comment": "Accepted in AACL IJCNLP 2025", "summary": "Automatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8de8\u8bed\u8a00\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u672a\u6807\u6ce8\u6570\u636e\uff0c\u6784\u5efa\u5c0f\u89c4\u6a21\u9ad8\u6548\u6a21\u578b\uff0c\u5b9e\u73b0\u4f4e\u8d44\u6e90\u8bed\u8a00\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7684\u65b0\u7a81\u7834\uff0c\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4f9d\u8d56\u3002", "motivation": "\u4f20\u7edfASR\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\u53ca\u8ba1\u7b97\u8d44\u6e90\u9650\u5236\uff0c\u4e9f\u9700\u5bfb\u627e\u65e0\u9700\u5927\u91cf\u6807\u6ce8\u6570\u636e\u548c\u89c4\u6a21\u8d85\u5927\u7684\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u8de8\u8bed\u8a00\u7684\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5229\u75283,000\u5c0f\u65f6\u7684\u591a\u8bed\u79cd\u672a\u6807\u6ce8\u6570\u636e\u96c6\u548c\u5f62\u6001\u5b66\u611f\u77e5\u7684\u5206\u8bcd\u6280\u672f\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a3\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u5728\u6ce2\u65af\u8bed\u4e0a\u4f18\u4e8e\u53c2\u6570\u89c4\u6a21\u66f4\u5927\u7684Whisper Large v3\uff0c\u5728\u963f\u62c9\u4f2f\u8bed\u548c\u4e4c\u5c14\u90fd\u8bed\u4e0a\u4e5f\u53d6\u5f97\u4e86\u6709\u7ade\u4e89\u529b\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u5c0f\u6a21\u578b\u7ed3\u5408\u76f8\u5173\u6570\u636e\u548c\u9884\u8bad\u7ec3\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u7ed3\u8bba\u6307\u51fa\uff0c\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u63d0\u5347\u4e3b\u8981\u4f9d\u8d56\u4e8e\u6570\u636e\u7684\u76f8\u5173\u6027\u548c\u6218\u7565\u6027\u9884\u8bad\u7ec3\uff0c\u800c\u975e\u4ec5\u4ec5\u4f9d\u9760\u6a21\u578b\u89c4\u6a21\u7684\u6269\u5927\u3002"}}
{"id": "2512.07288", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07288", "abs": "https://arxiv.org/abs/2512.07288", "authors": ["Tomoki Doi", "Masaru Isonuma", "Hitomi Yanaka"], "title": "Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models", "comment": "To appear in the Proceedings of the Asia-Pacific Chapter of the Association for Computational Linguistics: Student Research Workshop (AACL-SRW 2025)", "summary": "Large language models have the potential to generate explanations for their own predictions in a variety of styles based on user instructions. Recent research has examined whether these self-explanations faithfully reflect the models' actual behavior and has found that they often lack faithfulness. However, the question of how to improve faithfulness remains underexplored. Moreover, because different explanation styles have superficially distinct characteristics, it is unclear whether improvements observed in one style also arise when using other styles. This study analyzes the effects of training for faithful self-explanations and the extent to which these effects generalize, using three classification tasks and three explanation styles. We construct one-word constrained explanations that are likely to be faithful using a feature attribution method, and use these pseudo-faithful self-explanations for continual learning on instruction-tuned models. Our experiments demonstrate that training can improve self-explanation faithfulness across all classification tasks and explanation styles, and that these improvements also show signs of generalization to the multi-word settings and to unseen tasks. Furthermore, we find consistent cross-style generalization among three styles, suggesting that training may contribute to a broader improvement in faithful self-explanation ability.", "AI": {"tldr": "\u901a\u8fc7\u8bad\u7ec3\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u591a\u98ce\u683c\u4e0b\u81ea\u6211\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u5747\u5f97\u4ee5\u63d0\u5347\uff0c\u4e14\u89e3\u91ca\u98ce\u683c\u95f4\u5177\u6709\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u6211\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u8f83\u4f4e\uff0c\u4e14\u5982\u4f55\u63d0\u5347\u5fe0\u5b9e\u5ea6\u7814\u7a76\u4e0d\u8db3\uff0c\u540c\u65f6\u4e0d\u540c\u89e3\u91ca\u98ce\u683c\u7684\u5fe0\u5b9e\u5ea6\u63d0\u5347\u662f\u5426\u5177\u6709\u666e\u9002\u6027\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u7279\u5f81\u5f52\u56e0\u65b9\u6cd5\u7684\u4e00\u8bcd\u9650\u5236\u89e3\u91ca\uff0c\u4f5c\u4e3a\u4f2a\u5fe0\u5b9e\u7684\u81ea\u6211\u89e3\u91ca\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u89e3\u91ca\u5bf9\u6307\u4ee4\u8c03\u6574\u6a21\u578b\u8fdb\u884c\u6301\u7eed\u5b66\u4e60\u3002", "result": "\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u81ea\u6211\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\uff0c\u4e14\u8be5\u63d0\u5347\u5728\u6240\u6709\u5206\u7c7b\u4efb\u52a1\u548c\u89e3\u91ca\u98ce\u683c\u4e2d\u5747\u5b58\u5728\uff0c\u5e76\u80fd\u90e8\u5206\u63a8\u5e7f\u81f3\u591a\u8bcd\u89e3\u91ca\u8bbe\u7f6e\u548c\u672a\u89c1\u4efb\u52a1\u3002\u4e09\u79cd\u89e3\u91ca\u98ce\u683c\u95f4\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u4ea4\u53c9\u98ce\u683c\u6cdb\u5316\u3002", "conclusion": "\u8bad\u7ec3\u57fa\u4e8e\u4f2a\u5fe0\u5b9e\u89e3\u91ca\u7684\u81ea\u6211\u89e3\u91ca\u673a\u5236\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u89e3\u91ca\u5fe0\u5b9e\u5ea6\uff0c\u4e14\u8fd9\u79cd\u63d0\u5347\u5177\u6709\u8de8\u4efb\u52a1\u53ca\u8de8\u98ce\u683c\u7684\u6cdb\u5316\u6f5c\u529b\uff0c\u4fc3\u8fdb\u66f4\u5e7f\u6cdb\u7684\u5fe0\u5b9e\u81ea\u6211\u89e3\u91ca\u80fd\u529b\u53d1\u5c55\u3002"}}
{"id": "2512.07367", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07367", "abs": "https://arxiv.org/abs/2512.07367", "authors": ["Revekka Kyriakoglou", "Anna Pappa"], "title": "Multilingual corpora for the study of new concepts in the social sciences and humanities:", "comment": "in French language", "summary": "This article presents a hybrid methodology for building a multilingual corpus designed to support the study of emerging concepts in the humanities and social sciences (HSS), illustrated here through the case of ``non-technological innovation''. The corpus relies on two complementary sources: (1) textual content automatically extracted from company websites, cleaned for French and English, and (2) annual reports collected and automatically filtered according to documentary criteria (year, format, duplication). The processing pipeline includes automatic language detection, filtering of non-relevant content, extraction of relevant segments, and enrichment with structural metadata. From this initial corpus, a derived dataset in English is created for machine learning purposes. For each occurrence of a term from the expert lexicon, a contextual block of five sentences is extracted (two preceding and two following the sentence containing the term). Each occurrence is annotated with the thematic category associated with the term, enabling the construction of data suitable for supervised classification tasks. This approach results in a reproducible and extensible resource, suitable both for analyzing lexical variability around emerging concepts and for generating datasets dedicated to natural language processing applications.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u52a8\u63d0\u53d6\u4e0e\u7b5b\u9009\u6587\u672c\uff0c\u7ed3\u5408\u4e13\u5bb6\u8bcd\u5e93\uff0c\u6784\u5efa\u4e86\u652f\u6301\u65b0\u5174\u4eba\u6587\u793e\u79d1\u6982\u5ff5\u7814\u7a76\u7684\u591a\u8bed\u79cd\u8bed\u6599\u5e93\u3002", "motivation": "\u652f\u6301\u4eba\u6587\u793e\u4f1a\u79d1\u5b66\u4e2d\u65b0\u5174\u6982\u5ff5\u7684\u7814\u7a76\uff0c\u6784\u5efa\u4e00\u4e2a\u591a\u8bed\u79cd\u8bed\u6599\u5e93\u3002", "method": "\u7ed3\u5408\u81ea\u52a8\u63d0\u53d6\u7684\u516c\u53f8\u7f51\u7ad9\u6587\u672c\u548c\u7ecf\u8fc7\u7b5b\u9009\u7684\u5e74\u62a5\uff0c\u8fdb\u884c\u8bed\u8a00\u68c0\u6d4b\u3001\u5185\u5bb9\u8fc7\u6ee4\u3001\u76f8\u5173\u7247\u6bb5\u63d0\u53d6\u53ca\u7ed3\u6784\u5316\u5143\u6570\u636e\u8865\u5145\u3002\u57fa\u4e8e\u4e13\u5bb6\u8bcd\u5e93\uff0c\u63d0\u53d6\u4e0a\u4e0b\u6587\u53e5\u5757\u5e76\u6807\u6ce8\u4e3b\u9898\u7c7b\u522b\u4ee5\u4fbf\u76d1\u7763\u5206\u7c7b\u4efb\u52a1\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u4e14\u53ef\u6269\u5c55\u7684\u591a\u8bed\u79cd\u8bed\u6599\u5e93\u8d44\u6e90\uff0c\u9002\u5408\u5206\u6790\u8bcd\u6c47\u53d8\u5f02\u6027\u548c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u7684\u6570\u636e\u751f\u6210\u3002", "conclusion": "\u8be5\u6df7\u5408\u65b9\u6cd5\u6709\u6548\u5730\u652f\u6301\u4e86\u65b0\u5174\u6982\u5ff5\u7684\u8bed\u6599\u5efa\u8bbe\uff0c\u4e3a\u8bcd\u6c47\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u6570\u636e\u57fa\u7840\u3002"}}
{"id": "2512.07407", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07407", "abs": "https://arxiv.org/abs/2512.07407", "authors": ["Niklas Mellgren", "Peter Schneider-Kamp", "Lukas Galke Poech"], "title": "Training Language Models to Use Prolog as a Tool", "comment": "10 pages", "summary": "Ensuring reliable tool use is critical for safe agentic AI systems. Language models frequently produce unreliable reasoning with plausible but incorrect solutions that are difficult to verify. To address this, we investigate fine-tuning models to use Prolog as an external tool for verifiable computation. Using Group Relative Policy Optimization (GRPO), we fine-tune Qwen2.5-3B-Instruct on a cleaned GSM8K-Prolog-Prover dataset while varying (i) prompt structure, (ii) reward composition (execution, syntax, semantics, structure), and (iii) inference protocol: single-shot, best-of-N, and two agentic modes where Prolog is invoked internally or independently. Our reinforcement learning approach outperforms supervised fine-tuning, with our 3B model achieving zero-shot MMLU performance comparable to 7B few-shot results. Our findings reveal that: 1) joint tuning of prompt, reward, and inference shapes program syntax and logic; 2) best-of-N with external Prolog verification maximizes accuracy on GSM8K; 3) agentic inference with internal repair yields superior zero-shot generalization on MMLU-Stem and MMLU-Pro. These results demonstrate that grounding model reasoning in formal verification systems substantially improves reliability and auditability for safety-critical applications. The source code for reproducing our experiments is available under https://github.com/niklasmellgren/grpo-prolog-inference", "AI": {"tldr": "\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u8c03\u7528\u5916\u90e8Prolog\u5de5\u5177\u8fdb\u884c\u63a8\u7406\u9a8c\u8bc1\uff0c\u5927\u5e45\u63d0\u5347\u6a21\u578b\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u9002\u7528\u4e8e\u5b89\u5168\u5173\u952e\u9886\u57df\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u5e38\u4ea7\u751f\u770b\u4f3c\u5408\u7406\u4f46\u9519\u8bef\u7684\u7ed3\u679c\uff0c\u96be\u4ee5\u9a8c\u8bc1\uff0c\u4e3a\u4e86\u63d0\u5347\u6a21\u578b\u63a8\u7406\u7684\u53ef\u9760\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u5c1d\u8bd5\u5c06Prolog\u4f5c\u4e3a\u5916\u90e8\u5de5\u5177\u8fdb\u884c\u9a8c\u8bc1\u8ba1\u7b97\u3002", "method": "\u91c7\u7528Group Relative Policy Optimization (GRPO)\u65b9\u6cd5\u5bf9Qwen2.5-3B-Instruct\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u5229\u7528\u7ecf\u8fc7\u6e05\u6d17\u7684GSM8K-Prolog-Prover\u6570\u636e\u96c6\uff0c\u540c\u65f6\u8c03\u6574\u63d0\u793a\u7ed3\u6784\u3001\u5956\u52b1\u7ec4\u6210\u4ee5\u53ca\u63a8\u7406\u534f\u8bae\uff08\u5355\u6b21\u3001best-of-N\u53ca\u4e24\u79cdagentic\u6a21\u5f0f\uff09\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u65b9\u6cd5\u4f18\u4e8e\u76d1\u7763\u5fae\u8c03\uff0c3B\u6a21\u578b\u5728\u96f6\u6837\u672cMMLU\u4efb\u52a1\u4e2d\u8868\u73b0\u53ef\u4e0e7B\u5c11\u6837\u672c\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002\u8054\u5408\u8c03\u4f18\u63d0\u793a\u3001\u5956\u52b1\u548c\u63a8\u7406\u534f\u8bae\u6709\u52a9\u4e8e\u5f62\u6210\u66f4\u597d\u7684\u7a0b\u5e8f\u8bed\u6cd5\u548c\u903b\u8f91\uff1bbest-of-N\u52a0\u5916\u90e8Prolog\u9a8c\u8bc1\u63d0\u9ad8\u51c6\u786e\u7387\uff1bagentic\u63a8\u7406\u548c\u5185\u90e8\u4fee\u590d\u63d0\u5347\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06\u6a21\u578b\u63a8\u7406\u57fa\u7840\u5efa\u7acb\u5728\u5f62\u5f0f\u9a8c\u8bc1\u7cfb\u7edf\u4e0a\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u7684\u53ef\u9760\u6027\u4e0e\u53ef\u5ba1\u8ba1\u6027\uff0c\u5bf9\u5b89\u5168\u5173\u952e\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002\u6e90\u7801\u5df2\u516c\u5f00\u4fbf\u4e8e\u590d\u73b0\u3002"}}
{"id": "2512.07454", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07454", "abs": "https://arxiv.org/abs/2512.07454", "authors": ["Amir Mohammad Akhlaghi", "Amirhossein Shabani", "Mostafa Abdolmaleki", "Saeed Reza Kheradpisheh"], "title": "Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning", "comment": null, "summary": "The democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini -- originally a monolingual English model -- can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique \"warm-up\" stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at https://huggingface.co/amirakhlaghiqqq/PersianPhi.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u4f4e\u6210\u672c\u3001\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5c06\u5355\u8bed\u82f1\u8bed\u6a21\u578b\u6210\u529f\u8f6c\u5316\u4e3a\u652f\u6301\u6ce2\u65af\u8bed\u7684\u6a21\u578b\uff0c\u63a8\u52a8\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684AI\u6c11\u4e3b\u5316\u3002", "motivation": "\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4ee5\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u6240\u9700\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u963b\u788d\u4e86\u4eba\u5de5\u667a\u80fd\u7684\u666e\u53ca\u3002", "method": "\u57fa\u4e8eMicrosoft Phi-3 Mini\u5355\u8bed\u6a21\u578b\uff0c\u8bbe\u8ba1\u201c\u9884\u70ed\u201d\u9636\u6bb5\u5229\u7528\u53cc\u8bed\u53d9\u8ff0\u6570\u636e\u5bf9\u9f50\u5d4c\u5165\uff0c\u968f\u540e\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\uff0c\u5b9e\u73b0\u6a21\u578b\u7684\u8bed\u8a00\u9002\u914d\u3002", "result": "\u63d0\u51fa\u4e863.8B\u53c2\u6570\u7684Persian-Phi\u6a21\u578b\uff0c\u901a\u8fc7\u8d44\u6e90\u9ad8\u6548\u7684\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\u6210\u529f\u5730\u5c06\u5355\u8bed\u82f1\u8bed\u6a21\u578b\u9002\u914d\u5230\u6ce2\u65af\u8bed\uff0c\u4e14\u5728HuggingFace\u7684Open Persian LLM\u6392\u884c\u699c\u4e2d\u83b7\u5f97\u4e86\u7ade\u4e89\u6027\u7ed3\u679c\u3002", "conclusion": "\u901a\u8fc7\u8d44\u6e90\u9ad8\u6548\u7684\u5b66\u4e60\u6846\u67b6\uff0c\u8f83\u5c0f\u89c4\u6a21\u6a21\u578b\u4e5f\u53ef\u5b9e\u73b0\u591a\u8bed\u8a00\u5f3a\u5927\u80fd\u529b\uff0c\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u8bed\u8a00\u5927\u6a21\u578b\u7684\u62d3\u5c55\uff0c\u4e14\u786c\u4ef6\u9700\u6c42\u8f83\u4f4e\u3002"}}
{"id": "2512.07461", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07461", "abs": "https://arxiv.org/abs/2512.07461", "authors": ["Tong Wu", "Yang Liu", "Jun Bai", "Zixia Jia", "Shuyi Zhang", "Ziyong Lin", "Yanting Wang", "Song-Chun Zhu", "Zilong Zheng"], "title": "Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning", "comment": null, "summary": "We introduce Native Parallel Reasoner (NPR), a teacher-free framework that enables Large Language Models (LLMs) to self-evolve genuine parallel reasoning capabilities. NPR transforms the model from sequential emulation to native parallel cognition through three key innovations: 1) a self-distilled progressive training paradigm that transitions from ``cold-start'' format discovery to strict topological constraints without external supervision; 2) a novel Parallel-Aware Policy Optimization (PAPO) algorithm that optimizes branching policies directly within the execution graph, allowing the model to learn adaptive decomposition via trial and error; and 3) a robust NPR Engine that refactors memory management and flow control of SGLang to enable stable, large-scale parallel RL training. Across eight reasoning benchmarks, NPR trained on Qwen3-4B achieves performance gains of up to 24.5% and inference speedups up to 4.6x. Unlike prior baselines that often fall back to autoregressive decoding, NPR demonstrates 100% genuine parallel execution, establishing a new standard for self-evolving, efficient, and scalable agentic reasoning.", "AI": {"tldr": "NPR\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u8bad\u7ec3\u65b9\u6cd5\u4e0e\u6267\u884c\u5f15\u64ce\uff0c\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u771f\u6b63\u5e76\u884c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u4e0e\u6548\u7387\u3002", "motivation": "\u8d4b\u4e88\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u771f\u6b63\u7684\u5e76\u884c\u63a8\u7406\u80fd\u529b\uff0c\u4ece\u5e8f\u5217\u6a21\u62df\u8f6c\u53d8\u4e3a\u539f\u751f\u5e76\u884c\u8ba4\u77e5\u3002", "method": "\u4e09\u5927\u5173\u952e\u521b\u65b0\uff0c\u5305\u62ec\u81ea\u6211\u84b8\u998f\u7684\u6e10\u8fdb\u8bad\u7ec3\u8303\u5f0f\u3001\u5e76\u884c\u611f\u77e5\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\uff0c\u4ee5\u53caNPR\u5f15\u64ce\u91cd\u6784\u5185\u5b58\u7ba1\u7406\u4e0e\u6d41\u7a0b\u63a7\u5236\u3002", "result": "\u5728\u516b\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNPR\u8bad\u7ec3\u7684Qwen3-4B\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6700\u591a\u8fbe24.5%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u8fbe4.6\u500d\uff0c\u5b9e\u73b0100%\u771f\u6b63\u7684\u5e76\u884c\u6267\u884c\u3002", "conclusion": "NPR\u786e\u7acb\u4e86\u81ea\u6211\u8fdb\u5316\u3001\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u4ee3\u7406\u5f0f\u63a8\u7406\u65b0\u6807\u51c6\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u6a21\u578b\u4f9d\u8d56\u81ea\u56de\u5f52\u89e3\u7801\u7684\u5c40\u9650\u3002"}}
{"id": "2512.07478", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07478", "abs": "https://arxiv.org/abs/2512.07478", "authors": ["Zhuoran Zhuang", "Ye Chen", "Jianghao Su", "Chao Luo", "Luhui Liu", "Xia Zeng"], "title": "Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization", "comment": null, "summary": "Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction trajectories, but two key challenges hinder effectiveness: (1) Sparse, non-instructive rewards, such as binary 0-1 verifiable signals, provide limited guidance for intermediate steps and slow convergence; (2) Gradient degradation in Group Relative Policy Optimization (GRPO), where identical rewards within a rollout group yield zero advantage, reducing sample efficiency and destabilizing training. To address these challenges, we propose two complementary techniques: Progressive Reward Shaping (PRS) and Value-based Sampling Policy Optimization (VSPO). PRS is a curriculum-inspired reward design that introduces dense, stage-wise feedback - encouraging models to first master parseable and properly formatted tool calls, then optimize for factual correctness and answer quality. We instantiate PRS for short-form QA (with a length-aware BLEU to fairly score concise answers) and long-form QA (with LLM-as-a-Judge scoring to prevent reward hacking). VSPO is an enhanced GRPO variant that replaces low-value samples with prompts selected by a task-value metric balancing difficulty and uncertainty, and applies value-smoothing clipping to stabilize gradient updates. Experiments on multiple short-form and long-form QA benchmarks show that PRS consistently outperforms traditional binary rewards, and VSPO achieves superior stability, faster convergence, and higher final performance compared to PPO, GRPO, CISPO, and SFT-only baselines. Together, PRS and VSPO yield LLM-based TIR agents that generalize better across domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e24\u79cd\u6280\u672f\uff0c\u8fdb\u884c\u5956\u52b1\u8bbe\u8ba1\u4e0e\u7b56\u7565\u4f18\u5316\uff0c\u63d0\u9ad8\u5956\u52b1\u4fe1\u53f7\u7a00\u758f\u4e14\u975e\u6307\u5bfc\u6027\u7684\u95ee\u9898\uff0c\u63d0\u5347\u878d\u5408\u5de5\u5177\u63a8\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5de5\u5177\u4ea4\u4e92\u7684\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u7a00\u758f\u4e14\u975e\u5f15\u5bfc\u6027\u8d28\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u5bfc\u81f4\u8bad\u7ec3\u6536\u655b\u6162\u4e14\u6837\u672c\u6548\u7387\u4f4e\uff0c\u540c\u65f6\u68af\u5ea6\u9000\u5316\u5f71\u54cd\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5956\u52b1\u8bbe\u8ba1\u548c\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u6e10\u8fdb\u5f0f\u5956\u52b1\u8bbe\u8ba1\uff08PRS\uff09\uff0c\u901a\u8fc7\u9636\u6bb5\u5f0f\u3001\u5bc6\u96c6\u53cd\u9988\u5f15\u5bfc\u6a21\u578b\u9010\u6b65\u638c\u63e1\u5de5\u5177\u8c03\u7528\u4e0e\u7b54\u6848\u8d28\u91cf\uff1b2\uff09\u57fa\u4e8e\u4ef7\u503c\u7684\u91c7\u6837\u7b56\u7565\u4f18\u5316\uff08VSPO\uff09\uff0c\u901a\u8fc7\u7b5b\u9009\u9ad8\u4ef7\u503c\u6837\u672c\u548c\u4ef7\u503c\u5e73\u6ed1\u526a\u88c1\u7a33\u5b9a\u68af\u5ea6\u3002", "result": "\u5b9e\u9a8c\u5728\u591a\u9879\u77ed\u6587\u672c\u548c\u957f\u6587\u672c\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cPRS\u4f18\u4e8e\u4e8c\u5143\u5956\u52b1\u8bbe\u8ba1\uff0cVSPO\u5728\u7a33\u5b9a\u6027\u3001\u6536\u655b\u901f\u5ea6\u53ca\u6700\u7ec8\u6027\u80fd\u4e0a\u4f18\u4e8ePPO\u3001GRPO\u3001CISPO\u548c\u7eaf\u76d1\u7763\u8bad\u7ec3\u57fa\u7ebf\u3002", "conclusion": "PRS\u548cVSPO\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5de5\u5177\u63a8\u7406\u7684LLM\u4ee3\u7406\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u4f7f\u5176\u5728\u591a\u4e2a\u95ee\u7b54\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5177\u5907\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.07515", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07515", "abs": "https://arxiv.org/abs/2512.07515", "authors": ["Pengqian Lu", "Jie Lu", "Anjin Liu", "Guangquan Zhang"], "title": "SPAD: Seven-Source Token Probability Attribution with Syntactic Aggregation for Detecting Hallucinations in RAG", "comment": null, "summary": "Detecting hallucinations in Retrieval-Augmented Generation (RAG) remains a challenge. Prior approaches attribute hallucinations to a binary conflict between internal knowledge (stored in FFNs) and retrieved context. However, this perspective is incomplete, failing to account for the impact of other components in the generative process, such as the user query, previously generated tokens, the current token itself, and the final LayerNorm adjustment. To address this, we introduce SPAD. First, we mathematically attribute each token's probability into seven distinct sources: Query, RAG, Past, Current Token, FFN, Final LayerNorm, and Initial Embedding. This attribution quantifies how each source contributes to the generation of the current token. Then, we aggregate these scores by POS tags to quantify how different components drive specific linguistic categories. By identifying anomalies, such as Nouns relying on Final LayerNorm, SPAD effectively detects hallucinations. Extensive experiments demonstrate that SPAD achieves state-of-the-art performance", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ec6\u81f4\u7684\u6765\u6e90\u5f52\u56e0\u548c\u8bcd\u6027\u5206\u6790\uff0c\u63d0\u51faSPAD\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06\u5e7b\u89c9\u5f52\u56e0\u4e8e\u5185\u90e8\u77e5\u8bc6\u548c\u68c0\u7d22\u4e0a\u4e0b\u6587\u7684\u4e8c\u5143\u51b2\u7a81\uff0c\u5ffd\u89c6\u4e86\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u5176\u4ed6\u5173\u952e\u7ec4\u4ef6\u5bf9\u5e7b\u89c9\u4ea7\u751f\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u6570\u5b66\u65b9\u6cd5\u5c06\u6bcf\u4e2a\u751f\u6210token\u7684\u6982\u7387\u5f52\u56e0\u4e8e\u67e5\u8be2(Query)\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u3001\u8fc7\u53bb\u751f\u6210\u7684token\u3001\u5f53\u524dtoken\u3001\u672c\u5730\u524d\u9988\u795e\u7ecf\u7f51\u7edc(FFN)\u3001\u6700\u7ec8LayerNorm\u8c03\u6574\u548c\u521d\u59cb\u5d4c\u5165\u4e03\u4e2a\u4e0d\u540c\u6765\u6e90\uff0c\u5e76\u901a\u8fc7\u8bcd\u6027\u6807\u7b7e\u5bf9\u8fd9\u4e9b\u6765\u6e90\u8d21\u732e\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684SPAD\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u5f02\u5e38\u8d21\u732e\u6a21\u5f0f\uff08\u4f8b\u5982\u540d\u8bcd\u8fc7\u5ea6\u4f9d\u8d56\u6700\u7ec8LayerNorm\uff09\u6709\u6548\u68c0\u6d4b\u5e7b\u89c9\uff0c\u4e14\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\u5176\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "SPAD\u6210\u529f\u63ed\u793a\u4e86\u751f\u6210\u4e2d\u591a\u79cd\u56e0\u7d20\u5bf9\u5e7b\u89c9\u7684\u5f71\u54cd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cbe\u786e\u4e14\u6709\u6548\u7684\u5e7b\u89c9\u68c0\u6d4b\u624b\u6bb5\uff0c\u63a8\u52a8\u4e86RAG\u9886\u57df\u7684\u7814\u7a76\u8fdb\u5c55\u3002"}}
{"id": "2512.07522", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07522", "abs": "https://arxiv.org/abs/2512.07522", "authors": ["Sebastian Sztwiertnia", "Felix Friedrich", "Kristian Kersting", "Patrick Schramowski", "Bj\u00f6rn Deiseroth"], "title": "LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings", "comment": null, "summary": "Pre-training decoder-only language models relies on vast amounts of high-quality data, yet the availability of such data is increasingly reaching its limits. While metadata is commonly used to create and curate these datasets, its potential as a direct training signal remains under-explored. We challenge this status quo and propose LIME (Linguistic Metadata Embeddings), a method that enriches token embeddings with metadata capturing syntax, semantics, and contextual properties. LIME substantially improves pre-training efficiency. Specifically, it adapts up to 56% faster to the training data distribution, while introducing only 0.01% additional parameters at negligible compute overhead. Beyond efficiency, LIME improves tokenization, leading to remarkably stronger language modeling capabilities and generative task performance. These benefits persist across model scales (500M to 2B). In addition, we develop a variant with shifted metadata, LIME+1, that can guide token generation. Given prior metadata for the next token, LIME+1 improves reasoning performance by up to 38% and arithmetic accuracy by up to 35%.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165\u5143\u6570\u636e\u5d4c\u5165\uff0cLIME\u663e\u8457\u63d0\u5347\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6548\u7387\u548c\u751f\u6210\u80fd\u529b\uff0c\u4e14\u6210\u672c\u6781\u4f4e\uff0cLIME+1\u8fd8\u80fd\u663e\u8457\u589e\u5f3a\u63a8\u7406\u548c\u7b97\u672f\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u9884\u8bad\u7ec3\u7684\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u9ad8\u8d28\u91cf\u6570\u636e\uff0c\u4f46\u6b64\u7c7b\u6570\u636e\u8d44\u6e90\u65e5\u76ca\u532e\u4e4f\u3002\u5df2\u6709\u65b9\u6cd5\u4e3b\u8981\u5229\u7528\u5143\u6570\u636e\u6765\u6784\u5efa\u548c\u7b5b\u9009\u6570\u636e\u96c6\uff0c\u4f46\u5f88\u5c11\u76f4\u63a5\u5c06\u5143\u6570\u636e\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\u3002", "method": "\u63d0\u51faLIME\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u6355\u83b7\u53e5\u6cd5\u3001\u8bed\u4e49\u548c\u4e0a\u4e0b\u6587\u5c5e\u6027\u7684\u5143\u6570\u636e\u5d4c\u5165\u5230\u8bcd\u5143\u5d4c\u5165\u4e2d\uff0c\u63d0\u5347\u6a21\u578b\u9884\u8bad\u7ec3\u6548\u7387\u548c\u8868\u73b0\u3002\u8fdb\u4e00\u6b65\u63d0\u51faLIME+1\u53d8\u4f53\uff0c\u5229\u7528\u504f\u79fb\u7684\u5143\u6570\u636e\u6307\u5bfc\u8bcd\u5143\u751f\u6210\u3002", "result": "LIME\u4f7f\u6a21\u578b\u5bf9\u8bad\u7ec3\u6570\u636e\u5206\u5e03\u9002\u5e94\u901f\u5ea6\u63d0\u5347\u6700\u591a56%\uff0c\u53c2\u6570\u589e\u52a0\u4ec50.01%\uff0c\u8ba1\u7b97\u5f00\u9500\u6781\u5c0f\u3002LIME\u6539\u5584\u8bcd\u5143\u5316\uff0c\u589e\u5f3a\u8bed\u8a00\u5efa\u6a21\u548c\u751f\u6210\u4efb\u52a1\u6027\u80fd\uff0c\u5728500M\u52302B\u89c4\u6a21\u6a21\u578b\u5747\u6709\u6548\u3002LIME+1\u589e\u5f3a\u63a8\u7406\u6027\u80fd\u6700\u591a38%\u3001\u7b97\u672f\u51c6\u786e\u7387\u6700\u591a35%\u3002", "conclusion": "\u5229\u7528\u8bed\u8a00\u5143\u6570\u636e\u76f4\u63a5\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\u662f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u6548\u7387\u548c\u6027\u80fd\u7684\u6709\u6548\u9014\u5f84\uff0cLIME\u53ca\u5176\u53d8\u4f53\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u3002"}}
{"id": "2512.07525", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07525", "abs": "https://arxiv.org/abs/2512.07525", "authors": ["Xiaoran Liu", "Yuerong Song", "Zhigeng Liu", "Zengfeng Huang", "Qipeng Guo", "Zhaoxiang Liu", "Shiguo Lian", "Ziwei He", "Xipeng Qiu"], "title": "Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs", "comment": "20 pages, 6 figures, under review", "summary": "Rotary Position Embeddings (RoPE) have become a standard for encoding sequence order in Large Language Models (LLMs) by applying rotations to query and key vectors in the complex plane. Standard implementations, however, utilize only the real component of the complex-valued dot product for attention score calculation. This simplification discards the imaginary component, which contains valuable phase information, leading to a potential loss of relational details crucial for modeling long-context dependencies. In this paper, we propose an extension that re-incorporates this discarded imaginary component. Our method leverages the full complex-valued representation to create a dual-component attention score. We theoretically and empirically demonstrate that this approach enhances the modeling of long-context dependencies by preserving more positional information. Furthermore, evaluations on a suite of long-context language modeling benchmarks show that our method consistently improves performance over the standard RoPE, with the benefits becoming more significant as context length increases. The code is available at https://github.com/OpenMOSS/rope_pp.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165\u590d\u6570\u70b9\u79ef\u7684\u865a\u90e8\u4fe1\u606f\uff0c\u6539\u8fdb\u4e86RoPE\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u6807\u51c6RoPE\u4ec5\u91c7\u7528\u4e86\u590d\u6570\u70b9\u79ef\u7684\u5b9e\u90e8\uff0c\u4e22\u5931\u4e86\u5305\u542b\u91cd\u8981\u76f8\u4f4d\u4fe1\u606f\u7684\u865a\u90e8\uff0c\u5bfc\u81f4\u5bf9\u957f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u5efa\u6a21\u80fd\u529b\u53d7\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55RoPE\u7684\u65b9\u6cd5\uff0c\u91cd\u65b0\u5f15\u5165\u4e86\u88ab\u4e22\u5f03\u7684\u865a\u90e8\u4fe1\u606f\uff0c\u5229\u7528\u5168\u590d\u6570\u8868\u793a\u521b\u5efa\u4e86\u53cc\u5206\u91cf\u6ce8\u610f\u529b\u5206\u6570\u3002", "result": "\u7406\u8bba\u548c\u5b9e\u8bc1\u8bc1\u660e\u8be5\u65b9\u6cd5\u901a\u8fc7\u4fdd\u7559\u66f4\u591a\u4f4d\u7f6e\u4fe1\u606f\u589e\u5f3a\u4e86\u957f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u5efa\u6a21\u80fd\u529b\uff0c\u5e76\u5728\u591a\u9879\u957f\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u6807\u51c6RoPE\uff0c\u4e14\u4e0a\u4e0b\u6587\u8d8a\u957f\uff0c\u63d0\u5347\u8d8a\u660e\u663e\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5229\u7528\u4e86\u88ab\u5ffd\u7565\u7684\u865a\u90e8\u4fe1\u606f\uff0c\u663e\u8457\u6539\u5584\u4e86\u957f\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u5efa\u6a21\uff0c\u672a\u6765\u53ef\u4f5c\u4e3aRoPE\u7684\u589e\u5f3a\u65b9\u6848\u63a8\u5e7f\u5e94\u7528\u3002"}}
{"id": "2512.07538", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07538", "abs": "https://arxiv.org/abs/2512.07538", "authors": ["Michelle Wastl", "Jannis Vamvas", "Rico Sennrich"], "title": "SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents", "comment": "30 pages", "summary": "Recognizing semantic differences across documents, especially in different languages, is crucial for text generation evaluation and multilingual content alignment. However, as a standalone task it has received little attention. We address this by introducing SwissGov-RSD, the first naturalistic, document-level, cross-lingual dataset for semantic difference recognition. It encompasses a total of 224 multi-parallel documents in English-German, English-French, and English-Italian with token-level difference annotations by human annotators. We evaluate a variety of open-source and closed source large language models as well as encoder models across different fine-tuning settings on this new benchmark. Our results show that current automatic approaches perform poorly compared to their performance on monolingual, sentence-level, and synthetic benchmarks, revealing a considerable gap for both LLMs and encoder models. We make our code and datasets publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SwissGov-RSD\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8de8\u8bed\u8a00\u6587\u6863\u7ea7\u8bed\u4e49\u5dee\u5f02\u8bc6\u522b\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5f53\u524d\u81ea\u52a8\u65b9\u6cd5\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u8de8\u8bed\u8a00\u6587\u6863\u4e2d\u7684\u8bed\u4e49\u5dee\u5f02\u8bc6\u522b\u5bf9\u4e8e\u6587\u672c\u751f\u6210\u548c\u591a\u8bed\u79cd\u5185\u5bb9\u5bf9\u9f50\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f5c\u4e3a\u72ec\u7acb\u4efb\u52a1\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u6784\u5efa\u591a\u8bed\u79cd\u591a\u6587\u6863\u7684SwissGov-RSD\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u4eba\u5de5\u9010\u8bcd\u5dee\u5f02\u6807\u6ce8\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u8bc4\u6d4b\u591a\u79cd\u5f00\u6e90\u4e0e\u95ed\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7801\u5668\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524d\u6a21\u578b\u5728\u6b64\u8de8\u8bed\u8a00\u8de8\u6587\u6863\u4efb\u52a1\u4e0a\u6548\u679c\u8fdc\u4f4e\u4e8e\u5728\u5355\u8bed\u53e5\u5b50\u7ea7\u6216\u5408\u6210\u6570\u636e\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u3001\u6587\u6863\u7ea7\u8bed\u4e49\u5dee\u5f02\u8bc6\u522b\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u5b58\u5728\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2512.07540", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07540", "abs": "https://arxiv.org/abs/2512.07540", "authors": ["Boxuan Lyu", "Haiyue Song", "Hidetaka Kamigaito", "Chenchen Ding", "Hideki Tanaka", "Masao Utiyama", "Kotaro Funakoshi", "Manabu Okumura"], "title": "Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation", "comment": null, "summary": "Error Span Detection (ESD) is a subtask of automatic machine translation evaluation that localizes error spans in translations and labels their severity. State-of-the-art generative ESD methods typically decode using Maximum a Posteriori (MAP), assuming that model-estimated probabilities are perfectly correlated with similarity to human annotation. However, we observed that annotations dissimilar to the human annotation could achieve a higher model likelihood than the human annotation. We address this issue by applying Minimum Bayes Risk (MBR) decoding to generative ESD models. Specifically, we employ sentence- and span-level similarity metrics as utility functions to select candidate hypotheses based on their approximate similarity to the human annotation. Extensive experimental results show that our MBR decoding outperforms the MAP baseline at the system, sentence, and span-levels. Furthermore, to mitigate the computational cost of MBR decoding, we demonstrate that applying MBR distillation enables a standard greedy model to match MBR decoding performance, effectively eliminating the inference-time latency bottleneck.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165MBR\u89e3\u7801\u548c\u84b8\u998f\u6280\u672f\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u7ffb\u8bd1\u8bef\u5dee\u8de8\u5ea6\u68c0\u6d4b\u6a21\u578b\u7684\u6027\u80fd\u548c\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u6700\u5927\u540e\u9a8c\u6982\u7387\uff08MAP\uff09\u89e3\u7801\u65b9\u6cd5\u5047\u5b9a\u6a21\u578b\u6982\u7387\u4e0e\u4eba\u5de5\u6807\u6ce8\u76f8\u4f3c\u5ea6\u5b8c\u5168\u76f8\u5173\uff0c\u4f46\u5b9e\u9645\u5b58\u5728\u4e0e\u4eba\u5de5\u6807\u6ce8\u76f8\u4f3c\u5ea6\u8f83\u4f4e\u4f46\u6a21\u578b\u6982\u7387\u8f83\u9ad8\u7684\u60c5\u51b5\uff0c\u5f71\u54cd\u8bef\u5dee\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u751f\u6210\u5f0f\u8bef\u5dee\u8de8\u5ea6\u68c0\u6d4b\uff08ESD\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u6700\u5c0f\u8d1d\u53f6\u65af\u98ce\u9669\uff08MBR\uff09\u89e3\u7801\u65b9\u6cd5\uff0c\u901a\u8fc7\u53e5\u5b50\u7ea7\u548c\u8de8\u5ea6\u7ea7\u7684\u76f8\u4f3c\u5ea6\u6307\u6807\u8fdb\u884c\u5019\u9009\u5047\u8bbe\u9009\u62e9\uff0c\u5e76\u5f15\u5165MBR\u84b8\u998f\u6280\u672f\u4ee5\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "MBR\u89e3\u7801\u65b9\u6cd5\u5728\u7cfb\u7edf\u3001\u53e5\u5b50\u548c\u8bef\u5dee\u8de8\u5ea6\u7ea7\u522b\u5747\u4f18\u4e8eMAP\u57fa\u7ebf\u65b9\u6cd5\u3002\u5229\u7528MBR\u84b8\u998f\u6280\u672f\uff0c\u53ef\u4f7f\u8d2a\u5a6a\u6a21\u578b\u8fbe\u5230MBR\u89e3\u7801\u6027\u80fd\uff0c\u6709\u6548\u6d88\u9664\u63a8\u7406\u65f6\u5ef6\u74f6\u9888\u3002", "conclusion": "MBR\u89e3\u7801\u7ed3\u5408\u76f8\u4f3c\u5ea6\u6307\u6807\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u5f0fESD\u6a21\u578b\u7684\u68c0\u6d4b\u51c6\u786e\u6027\uff0cMBR\u84b8\u998f\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u517c\u987e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07543", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07543", "abs": "https://arxiv.org/abs/2512.07543", "authors": ["Frederic Blum"], "title": "Most over-representation of phonological features in basic vocabulary disappears when controlling for spatial and phylogenetic effects", "comment": "Accepted with minor revisions at *Linguistic Typology*, expected to be fully published in 2026", "summary": "The statistical over-representation of phonological features in the basic vocabulary of languages is often interpreted as reflecting potentially universal sound symbolic patterns. However, most of those results have not been tested explicitly for reproducibility and might be prone to biases in the study samples or models. Many studies on the topic do not adequately control for genealogical and areal dependencies between sampled languages, casting doubts on the robustness of the results. In this study, we test the robustness of a recent study on sound symbolism of basic vocabulary concepts which analyzed245 languages.The new sample includes data on 2864 languages from Lexibank. We modify the original model by adding statistical controls for spatial and phylogenetic dependencies between languages. The new results show that most of the previously observed patterns are not robust, and in fact many patterns disappear completely when adding the genealogical and areal controls. A small number of patterns, however, emerges as highly stable even with the new sample. Through the new analysis, we are able to assess the distribution of sound symbolism on a larger scale than previously. The study further highlights the need for testing all universal claims on language for robustness on various levels.", "AI": {"tldr": "\u901a\u8fc7\u66f4\u5927\u89c4\u6a21\u6837\u672c\u548c\u4e25\u683c\u63a7\u5236\u8bed\u8a00\u4f9d\u8d56\uff0c\u53d1\u73b0\u591a\u6570\u97f3\u8c61\u5f81\u6a21\u5f0f\u4e0d\u5177\u666e\u904d\u7a33\u5065\u6027\uff0c\u63d0\u793a\u9700\u8c28\u614e\u5bf9\u5f85\u8bed\u8a00\u666e\u904d\u6027\u4e3b\u5f20\u3002", "motivation": "\u68c0\u9a8c\u5148\u524d\u5173\u4e8e\u57fa\u672c\u8bcd\u6c47\u4e2d\u8bed\u97f3\u7279\u5f81\u7edf\u8ba1\u8fc7\u5ea6\u8868\u73b0\u7684\u7814\u7a76\u662f\u5426\u5177\u6709\u53ef\u91cd\u590d\u6027\uff0c\u6392\u9664\u6837\u672c\u548c\u6a21\u578b\u504f\u5dee\uff0c\u7279\u522b\u662f\u8bed\u8a00\u4e4b\u95f4\u7684\u5bb6\u7cfb\u548c\u5730\u7406\u4f9d\u8d56\u672a\u88ab\u5145\u5206\u63a7\u5236\u7684\u95ee\u9898\u3002", "method": "\u5229\u7528\u5305\u542b2864\u79cd\u8bed\u8a00\u7684Lexibank\u6570\u636e\uff0c\u4fee\u6539\u539f\u6709\u6a21\u578b\uff0c\u52a0\u5165\u8bed\u8a00\u95f4\u7684\u7a7a\u95f4\u548c\u7cfb\u8c31\u4f9d\u8d56\u4f5c\u4e3a\u7edf\u8ba1\u63a7\u5236\uff0c\u6d4b\u8bd5\u5148\u524d245\u8bed\u8a00\u6837\u672c\u7814\u7a76\u7684\u97f3\u8c61\u5f81\u6027\u6a21\u5f0f\u7684\u7a33\u5065\u6027\u3002", "result": "\u5927\u591a\u6570\u5148\u524d\u89c2\u5bdf\u5230\u7684\u97f3\u8c61\u5f81\u6027\u6a21\u5f0f\u5728\u63a7\u5236\u5bb6\u7cfb\u548c\u5730\u7406\u4f9d\u8d56\u540e\u4e0d\u518d\u7a33\u5065\uff0c\u8bb8\u591a\u6a21\u5f0f\u5b8c\u5168\u6d88\u5931\uff1b\u4f46\u5c11\u6570\u6a21\u5f0f\u4ecd\u8868\u73b0\u51fa\u9ad8\u5ea6\u7a33\u5b9a\u6027\u3002", "conclusion": "\u8bed\u8a00\u97f3\u8c61\u5f81\u6027\u7684\u666e\u904d\u6027\u4e3b\u5f20\u9700\u5728\u4e0d\u540c\u5c42\u9762\u53cd\u590d\u68c0\u9a8c\u5176\u7a33\u5065\u6027\uff0c\u65b0\u7814\u7a76\u4e3a\u5927\u89c4\u6a21\u97f3\u8c61\u5f81\u5206\u5e03\u63d0\u4f9b\u66f4\u53ef\u9760\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f3a\u8c03\u5728\u8bed\u8a00\u7814\u7a76\u4e2d\u63a7\u5236\u8bed\u8a00\u95f4\u4f9d\u8d56\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2512.07544", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07544", "abs": "https://arxiv.org/abs/2512.07544", "authors": ["Kyungro Lee", "Dongha Choi", "Hyunju Lee"], "title": "MoCoRP: Modeling Consistent Relations between Persona and Response for Persona-based Dialogue", "comment": "18 pages", "summary": "As dialogue systems become increasingly important across various domains, a key challenge in persona-based dialogue is generating engaging and context-specific interactions while ensuring the model acts with a coherent personality. However, existing persona-based dialogue datasets lack explicit relations between persona sentences and responses, which makes it difficult for models to effectively capture persona information. To address these issues, we propose MoCoRP (Modeling Consistent Relations between Persona and Response), a framework that incorporates explicit relations into language models. MoCoRP leverages an NLI expert to explicitly extract the NLI relations between persona sentences and responses, enabling the model to effectively incorporate appropriate persona information from the context into its responses. We applied this framework to pre-trained models like BART and further extended it to modern large language models (LLMs) through alignment tuning. Experimental results on the public datasets ConvAI2 and MPChat demonstrate that MoCoRP outperforms existing baselines, achieving superior persona consistency and engaging, context-aware dialogue generation. Furthermore, our model not only excels in quantitative metrics but also shows significant improvements in qualitative aspects. These results highlight the effectiveness of explicitly modeling persona-response relations in persona-based dialogue. The source codes of MoCoRP are available at https://github.com/DMCB-GIST/MoCoRP.", "AI": {"tldr": "\u9488\u5bf9\u4eba\u7269\u5bf9\u8bdd\u6570\u636e\u96c6\u4e2d\u7f3a\u4e4f\u663e\u5f0f\u5173\u7cfb\u7684\u95ee\u9898\uff0cMoCoRP\u5229\u7528NLI\u63d0\u53d6\u4eba\u7269\u4e0e\u56de\u590d\u95f4\u5173\u7cfb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8bdd\u7684\u4e00\u81f4\u6027\u548c\u8da3\u5473\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u4eba\u7269\u5bf9\u8bdd\u7cfb\u7edf\u96be\u4ee5\u751f\u6210\u4e0e\u89d2\u8272\u4e00\u81f4\u4e14\u5185\u5bb9\u76f8\u5173\u7684\u5bf9\u8bdd\uff0c\u56e0\u4e3a\u73b0\u6709\u6570\u636e\u96c6\u7f3a\u4e4f\u4eba\u7269\u53e5\u5b50\u4e0e\u56de\u590d\u7684\u663e\u5f0f\u5173\u8054\uff0c\u4f7f\u6a21\u578b\u96be\u4ee5\u6709\u6548\u6293\u53d6\u4eba\u7269\u4fe1\u606f\u3002", "method": "\u5229\u7528NLI\u4e13\u5bb6\u6a21\u578b\u63d0\u53d6\u4eba\u7269\u4e0e\u56de\u590d\u95f4\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u5173\u7cfb\uff0c\u5c06\u5173\u7cfb\u663e\u5f0f\u878d\u5165\u9884\u8bad\u7ec3\u6a21\u578b\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u9f50\u8c03\u4f18\u4f18\u5316\u5bf9\u8bdd\u751f\u6210\u80fd\u529b\u3002", "result": "\u5728ConvAI2\u548cMPChat\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cMoCoRP\u5728\u4eba\u7269\u4e00\u81f4\u6027\u3001\u5bf9\u8bdd\u8da3\u5473\u6027\u53ca\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u5728\u5b9a\u91cf\u548c\u5b9a\u6027\u6307\u6807\u4e0a\u5747\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u4eba\u7269\u53e5\u5b50\u4e0e\u56de\u590d\u4e4b\u95f4\u7684\u5173\u7cfb\u5bf9\u4e8e\u63d0\u5347\u4eba\u7269\u5bf9\u8bdd\u7cfb\u7edf\u7684\u8868\u73b0\u975e\u5e38\u6709\u6548\uff0c\u80fd\u591f\u751f\u6210\u66f4\u52a0\u4e00\u81f4\u4e14\u5bcc\u6709\u5438\u5f15\u529b\u7684\u4e0a\u4e0b\u6587\u76f8\u5173\u56de\u5e94\u3002"}}
{"id": "2512.07552", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07552", "abs": "https://arxiv.org/abs/2512.07552", "authors": ["Francois Vandenhende", "Anna Georgiou", "Michalis Georgiou", "Theodoros Psaras", "Ellie Karekla", "Elena Hadjicosta"], "title": "Performance of the SafeTerm AI-Based MedDRA Query System Against Standardised MedDRA Queries", "comment": "8 pages, 3 figures", "summary": "In pre-market drug safety review, grouping related adverse event terms into SMQs or OCMQs is critical for signal detection. We assess the performance of SafeTerm Automated Medical Query (AMQ) on MedDRA SMQs. The AMQ is a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score (0-1) using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity, and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against tier-1 SMQs (110 queries, v28.1). Precision, recall and F1 were computed at multiple similarity-thresholds, defined either manually or using an automated method. High recall (94%)) is achieved at moderate similarity thresholds, indicative of good retrieval sensitivity. Higher thresholds filter out more terms, resulting in improved precision (up to 89%). The optimal threshold (0.70)) yielded an overall recall of (48%) and precision of (45%) across all 110 queries. Restricting to narrow-term PTs achieved slightly better performance at an increased (+0.05) similarity threshold, confirming increased relatedness of narrow versus broad terms. The automatic threshold (0.66) selection prioritizes recall (0.58) to precision (0.29). SafeTerm AMQ achieves comparable, satisfactory performance on SMQs and sanitized OCMQs. It is therefore a viable supplementary method for automated MedDRA query generation, balancing recall and precision. We recommend using suitable MedDRA PT terminology in query formulation and applying the automated threshold method to optimise recall. Increasing similarity scores allows refined, narrow terms selection.", "AI": {"tldr": "SafeTerm AMQ\u662f\u4e00\u79cd\u57fa\u4e8e\u591a\u7ef4\u5411\u91cf\u548c\u7edf\u8ba1\u65b9\u6cd5\u7684\u533b\u7597\u67e5\u8be2\u81ea\u52a8\u5316\u7cfb\u7edf\uff0c\u80fd\u6709\u6548\u68c0\u7d22\u76f8\u5173MedDRA\u672f\u8bed\uff0c\u63d0\u5347\u836f\u54c1\u5b89\u5168\u4e0d\u826f\u4e8b\u4ef6\u4fe1\u53f7\u68c0\u6d4b\u7684\u6548\u7387\u4e0e\u51c6\u786e\u5ea6\u3002", "motivation": "\u5728\u836f\u54c1\u4e0a\u5e02\u524d\u5b89\u5168\u5ba1\u67e5\u4e2d\uff0c\u51c6\u786e\u5206\u7ec4\u76f8\u5173\u4e0d\u826f\u4e8b\u4ef6\u672f\u8bed\u4ee5\u8f85\u52a9\u4fe1\u53f7\u68c0\u6d4b\u6781\u4e3a\u5173\u952e\uff0c\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u5411\u91cf\u7a7a\u95f4\u5d4c\u5165\u533b\u836f\u672f\u8bed\uff0c\u5229\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u548c\u6781\u503c\u805a\u7c7b\u8ba1\u7b97\u76f8\u5173\u6027\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u591a\u91cd\u76f8\u4f3c\u5ea6\u9608\u503c\u8bc4\u4f30\u7cfb\u7edf\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cSafeTerm AMQ\u5728\u4e0d\u540c\u76f8\u4f3c\u5ea6\u9608\u503c\u4e0b\u5747\u80fd\u5b9e\u73b0\u9ad8\u53ec\u56de\u7387\uff08\u6700\u9ad894%\uff09\u548c\u9ad8\u7cbe\u51c6\u5ea6\uff08\u6700\u9ad889%\uff09\uff0c\u81ea\u52a8\u9608\u503c\u9009\u62e9\u4f18\u5148\u4fdd\u8bc1\u53ec\u56de\u7387\uff0c\u8be5\u65b9\u6cd5\u5bf9\u72ed\u4e49\u672f\u8bed\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "SafeTerm AMQ\u5728MedDRA SMQs\u7684\u81ea\u52a8\u67e5\u8be2\u751f\u6210\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u80fd\u591f\u5728\u53ec\u56de\u7387\u548c\u7cbe\u51c6\u5ea6\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u662f\u4e00\u79cd\u6709\u6548\u7684\u8f85\u52a9\u65b9\u6cd5\u3002"}}
{"id": "2512.07571", "categories": ["cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.07571", "abs": "https://arxiv.org/abs/2512.07571", "authors": ["Nicolas Calbucura", "Valentin Barriere"], "title": "A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification", "comment": null, "summary": "This paper presents a simple method that allows to easily enhance textual pre-trained large language models with speech information, when fine-tuned for a specific classification task. A classical issue with the fusion of many embeddings from audio with text is the large length of the audio sequence compared to the text one. Our method benefits from an existing speech tokenizer trained for Audio Speech Recognition that output long sequences of tokens from a large vocabulary, making it difficult to integrate it at low cost in a large language model. By applying a simple lasso-based feature selection on multimodal Bag-of-Words representation, we retain only the most important audio tokens for the task, and adapt the language model to them with a self-supervised language modeling objective, before fine-tuning it on the downstream task. We show this helps to improve the performances compared to an unimodal model, to a bigger SpeechLM or to integrating audio via a learned representation. We show the effectiveness of our method on two recent Argumentative Fallacy Detection and Classification tasks where the use of audio was believed counterproductive, reaching state-of-the-art results. We also provide an in-depth analysis of the method, showing that even a random audio token selection helps enhancing the unimodal model. Our code is available [online](https://github.com/salocinc/EACL26SpeechTokFallacy/).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7b80\u5355\u65b9\u6cd5\uff0c\u5c06\u9884\u8bad\u7ec3\u6587\u672c\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u8bed\u97f3\u4fe1\u606f\u878d\u5408\uff0c\u901a\u8fc7\u97f3\u9891\u7279\u5f81\u9009\u62e9\uff0c\u63d0\u5347\u5206\u7c7b\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u97f3\u9891\u5e8f\u5217\u957f\u5ea6\u8fdc\u5927\u4e8e\u6587\u672c\uff0c\u5bfc\u81f4\u878d\u5408\u6210\u672c\u9ad8\uff0c\u5982\u4f55\u6709\u6548\u878d\u5408\u8bed\u97f3\u4fe1\u606f\u4ee5\u63d0\u5347\u6587\u672c\u6a21\u578b\u6027\u80fd\u662f\u5173\u952e\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u8bed\u97f3\u8bc6\u522b\u8bad\u7ec3\u7684\u8bed\u97f3\u5206\u8bcd\u5668\u751f\u6210\u957f\u5e8f\u5217\u6807\u8bb0\u540e\uff0c\u5229\u7528\u5957\u7d22\u56de\u5f52\u8fdb\u884c\u591a\u6a21\u6001Bag-of-Words\u7279\u5f81\u9009\u62e9\uff0c\u4fdd\u7559\u91cd\u8981\u97f3\u9891\u6807\u8bb0\uff0c\u7ed3\u5408\u81ea\u76d1\u7763\u8bed\u8a00\u5efa\u6a21\u5bf9\u8bed\u8a00\u6a21\u578b\u9002\u914d\uff0c\u6700\u540e\u8fdb\u884c\u4efb\u52a1\u5fae\u8c03\u3002", "result": "\u672c\u65b9\u6cd5\u5728\u8bba\u8bc1\u8c2c\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\u3001\u8f83\u5927SpeechLM\u6a21\u578b\u53ca\u57fa\u4e8e\u5b66\u4e60\u8868\u793a\u7684\u878d\u5408\u65b9\u6cd5\uff0c\u751a\u81f3\u968f\u673a\u97f3\u9891\u6807\u8bb0\u9009\u62e9\u4e5f\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u97f3\u9891\u7279\u5f81\u9009\u62e9\u548c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6587\u672c\u6a21\u578b\u7684\u5206\u7c7b\u6027\u80fd\uff0c\u5728\u8bba\u8bc1\u8c2c\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e86\u6700\u65b0\u6c34\u5e73\u3002"}}
{"id": "2512.07583", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07583", "abs": "https://arxiv.org/abs/2512.07583", "authors": ["Navid Asgari", "Benjamin M. Cole"], "title": "Complementary Learning Approach for Text Classification using Large Language Models", "comment": "67 pages", "summary": "In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-shot learning prompting from computer science, extends best practices for co-author teams in qualitative research to human-machine teams in quantitative research. This allows humans to utilize abductive reasoning and natural language to interrogate not just what the machine has done but also what the human has done. Our method highlights how scholars can manage inherent weaknesses OF LLMs using careful, low-cost techniques. We demonstrate how to use the methodology to interrogate human-machine rating discrepancies for a sample of 1,934 press releases announcing pharmaceutical alliances (1990-2017).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u5b66\u8005\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u6784\u5316\u534f\u4f5c\u65b9\u6cd5\uff0c\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u548c\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\uff0c\u63d0\u5347\u5b9a\u91cf\u7814\u7a76\u4e2d\u4eba\u673a\u56e2\u961f\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "motivation": "\u89e3\u51b3\u4eba\u673a\u534f\u4f5c\u4e2d\u5404\u81ea\u7684\u5f31\u70b9\uff0c\u63d0\u9ad8\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u7ed3\u5408\u94fe\u5f0f\u601d\u7ef4\u548c\u5c11\u91cf\u793a\u4f8b\u5b66\u4e60\u63d0\u793a\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u65b9\u6cd5\u6574\u5408\u5b66\u8005\u548c\u673a\u5668\u7684\u4f18\u52bf\uff0c\u6269\u5c55\u4e86\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u56e2\u961f\u5408\u4f5c\u5230\u5b9a\u91cf\u7814\u7a76\u7684\u4eba\u673a\u56e2\u961f\u3002", "result": "\u5c55\u793a\u4e86\u5982\u4f55\u7528\u8be5\u65b9\u6cd5\u5206\u6790\u4eba\u673a\u8bc4\u5206\u5dee\u5f02\uff0c\u5177\u4f53\u5e94\u7528\u4e8e1934\u4efd\u533b\u836f\u8054\u76df\u65b0\u95fb\u7a3f\u7684\u6570\u636e\u6837\u672c\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5229\u7528\u4f4e\u6210\u672c\u6280\u672f\u5e2e\u52a9\u5b66\u8005\u6709\u6548\u7ba1\u7406\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56fa\u6709\u7684\u5f31\u70b9\uff0c\u5b9e\u73b0\u4e86\u4eba\u673a\u534f\u4f5c\u4e0b\u66f4\u6709\u6548\u7684\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2512.07608", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.07608", "abs": "https://arxiv.org/abs/2512.07608", "authors": ["Jing Wang", "Jie Shen", "Xing Niu", "Tong Zhang", "Jeremy Weiss"], "title": "Metric-Fair Prompting: Treating Similar Samples Similarly", "comment": null, "summary": "We introduce \\emph{Metric-Fair Prompting}, a fairness-aware prompting framework that guides large language models (LLMs) to make decisions under metric-fairness constraints. In the application of multiple-choice medical question answering, each {(question, option)} pair is treated as a binary instance with label $+1$ (correct) or $-1$ (incorrect). To promote {individual fairness}~--~treating similar instances similarly~--~we compute question similarity using NLP embeddings and solve items in \\emph{joint pairs of similar questions} rather than in isolation. The prompt enforces a global decision protocol: extract decisive clinical features, map each \\((\\text{question}, \\text{option})\\) to a score $f(x)$ that acts as confidence, and impose a Lipschitz-style constraint so that similar inputs receive similar scores and, hence, consistent outputs. Evaluated on the {MedQA (US)} benchmark, Metric-Fair Prompting is shown to improve performance over standard single-item prompting, demonstrating that fairness-guided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes clinical multiple-choice questions.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51faMetric-Fair Prompting\u65b9\u6cd5\uff0c\u5229\u7528\u5ea6\u91cf\u516c\u5e73\u7ea6\u675f\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5bf9\u533b\u7597\u591a\u9879\u9009\u62e9\u9898\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u65e8\u5728\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9879\u9009\u62e9\u533b\u7597\u95ee\u7b54\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5c24\u5176\u662f\u4fdd\u8bc1\u5bf9\u76f8\u4f3c\u5b9e\u4f8b\u5177\u6709\u4e00\u81f4\u7684\u5224\u65ad\uff0c\u4ece\u800c\u63d0\u5347\u6a21\u578b\u7684\u4fe1\u4efb\u5ea6\u548c\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u95ee\u9898\u95f4\u7684\u76f8\u4f3c\u5ea6\uff0c\u4ee5\u95ee\u7b54\u5bf9\u7684\u5f62\u5f0f\u5bf9\u76f8\u4f3c\u95ee\u9898\u8054\u5408\u5904\u7406\uff0c\u57fa\u4e8eNLP\u5d4c\u5165\u548cLipschitz\u7ea6\u675f\u8bbe\u8ba1\u63d0\u793a\uff0c\u5f15\u5bfc\u6a21\u578b\u63d0\u53d6\u5173\u952e\u4e34\u5e8a\u7279\u5f81\u5e76\u8f93\u51fa\u5e26\u7f6e\u4fe1\u5ea6\u7684\u5206\u6570\u3002", "result": "\u5728MedQA(US)\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cMetric-Fair Prompting\u4f18\u4e8e\u4f20\u7edf\u9010\u9879\u63d0\u793a\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u516c\u5e73\u6027\u3002", "conclusion": "Metric-Fair Prompting\u901a\u8fc7\u5f15\u5165\u5ea6\u91cf\u516c\u5e73\u6027\u7ea6\u675f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u591a\u9879\u9009\u62e9\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u5bf9\u76f8\u4f3c\u95ee\u9898\u7684\u4e00\u81f4\u6027\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2512.07612", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07612", "abs": "https://arxiv.org/abs/2512.07612", "authors": ["Kairong Luo", "Zhenbo Sun", "Xinyu Shi", "Shengqi Chen", "Bowen Yu", "Yunyi Chen", "Chenyi Dang", "Hengtao Tao", "Hui Wang", "Fangming Liu", "Kaifeng Lyu", "Wenguang Chen"], "title": "PCMind-2.1-Kaiyuan-2B Technical Report", "comment": null, "summary": "The rapid advancement of Large Language Models (LLMs) has resulted in a significant knowledge gap between the open-source community and industry, primarily because the latter relies on closed-source, high-quality data and training recipes. To address this, we introduce PCMind-2.1-Kaiyuan-2B, a fully open-source 2-billion-parameter model focused on improving training efficiency and effectiveness under resource constraints. Our methodology includes three key innovations: a Quantile Data Benchmarking method for systematically comparing heterogeneous open-source datasets and providing insights on data mixing strategies; a Strategic Selective Repetition scheme within a multi-phase paradigm to effectively leverage sparse, high-quality data; and a Multi-Domain Curriculum Training policy that orders samples by quality. Supported by a highly optimized data preprocessing pipeline and architectural modifications for FP16 stability, Kaiyuan-2B achieves performance competitive with state-of-the-art fully open-source models, demonstrating practical and scalable solutions for resource-limited pretraining. We release all assets (including model weights, data, and code) under Apache 2.0 license at https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa\u4e86\u4e00\u4e2a\u5168\u5f00\u6e90\u76842\u4ebf\u53c2\u6570\u6a21\u578bKaiyuan-2B\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u5904\u7406\u548c\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e0e\u4e1a\u5185\u5148\u8fdb\u5f00\u6e90\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5f00\u6e90\u793e\u533a\u4e0e\u5de5\u4e1a\u754c\u4e4b\u95f4\u7684\u77e5\u8bc6\u5dee\u8ddd\u4e3b\u8981\u6e90\u4e8e\u5de5\u4e1a\u754c\u4f9d\u8d56\u95ed\u6e90\u9ad8\u8d28\u91cf\u6570\u636e\u548c\u8bad\u7ec3\u65b9\u6848\uff0c\u8feb\u5207\u9700\u8981\u6253\u9020\u9ad8\u6548\u4e14\u516c\u5f00\u900f\u660e\u7684\u5f00\u6e90\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u4f4d\u6570\u6570\u636e\u57fa\u51c6\u65b9\u6cd5\u3001\u6218\u7565\u6027\u9009\u62e9\u91cd\u590d\u65b9\u6848\u548c\u591a\u57df\u8bfe\u7a0b\u8bad\u7ec3\u7b56\u7565\uff0c\u7ed3\u5408\u4f18\u5316\u7684\u6570\u636e\u9884\u5904\u7406\u6d41\u7a0b\u53caFP16\u7a33\u5b9a\u6027\u67b6\u6784\u4fee\u6539\uff0c\u5b9e\u73b0\u4e86\u8bad\u7ec3\u6548\u7387\u548c\u6548\u679c\u63d0\u5347\u3002", "result": "Kaiyuan-2B\u6a21\u578b\u5728\u591a\u9879\u6027\u80fd\u6307\u6807\u4e0a\u8fbe\u5230\u5148\u8fdb\u5f00\u6e90\u6a21\u578b\u6c34\u5e73\uff0c\u5e76\u4e14\u6240\u6709\u6a21\u578b\u6743\u91cd\u3001\u6570\u636e\u548c\u4ee3\u7801\u5747\u5df2\u901a\u8fc7Apache 2.0\u8bb8\u53ef\u8bc1\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "PCMind-2.1-Kaiyuan-2B\u5728\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u4e0e\u6700\u5148\u8fdb\u7684\u5b8c\u5168\u5f00\u6e90\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u9884\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.07684", "categories": ["cs.CL", "cs.AI", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.07684", "abs": "https://arxiv.org/abs/2512.07684", "authors": ["Zihan Chen", "Lanyu Yu"], "title": "When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks", "comment": "10 pages", "summary": "Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u7ed3\u5408\u6587\u672c\u4e0e\u7ed3\u6784\u7279\u5f81\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u5728\u7ebf\u4e0d\u6587\u660e\u884c\u4e3a\u68c0\u6d4b\u65b9\u6cd5\uff0c\u4f18\u4e8e\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u5728\u7ebf\u793e\u533a\u4e2d\u4e0d\u6587\u660e\u884c\u4e3a\u6cdb\u6ee5\uff0c\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u7684\u81ea\u52a8\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0d\u8db3\uff0c\u9700\u63a2\u7d22\u7ed3\u5408\u7ed3\u6784\u4fe1\u606f\u7684\u65b0\u65b9\u6cd5\u4ee5\u63d0\u5347\u68c0\u6d4b\u6027\u80fd\u3002", "method": "\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5c06\u7528\u6237\u8bc4\u8bba\u4f5c\u4e3a\u8282\u70b9\uff0c\u57fa\u4e8e\u6587\u672c\u76f8\u4f3c\u5ea6\u6784\u5efa\u8fb9\uff0c\u7ed3\u5408\u52a8\u6001\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8054\u5408\u5b66\u4e60\u8bed\u8a00\u5185\u5bb9\u548c\u8bc4\u8bba\u95f4\u7684\u5173\u7cfb\u7ed3\u6784\u8fdb\u884c\u4e0d\u6587\u660e\u884c\u4e3a\u68c0\u6d4b\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4b\u82f1\u6587Wikipedia\u793e\u533a\u4e2d\u7684\u4e09\u7c7b\u4e0d\u6587\u660e\u884c\u4e3a\uff08\u6bd2\u6027\u3001\u653b\u51fb\u6027\u548c\u4eba\u8eab\u653b\u51fb\uff09\uff0c\u901a\u8fc7\u5c06\u7528\u6237\u8bc4\u8bba\u8868\u793a\u4e3a\u8282\u70b9\uff0c\u8bc4\u8bba\u95f4\u7684\u6587\u672c\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u8fb9\uff0c\u5b9e\u73b0\u8bed\u8a00\u5185\u5bb9\u4e0e\u5173\u7cfb\u7ed3\u6784\u7684\u8054\u5408\u5b66\u4e60\u3002\u540c\u65f6\u5f15\u5165\u52a8\u6001\u8c03\u6574\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u4fe1\u606f\u805a\u5408\u65f6\u81ea\u9002\u5e94\u5e73\u8861\u8282\u70b9\u548c\u62d3\u6251\u7279\u5f81\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u9879\u6307\u6807\u4e0a\u4f18\u4e8e12\u4e2a\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u5927\u6a21\u578b\uff0c\u4e14\u63a8\u7406\u5f00\u9500\u663e\u8457\u8f83\u4f4e\u3002", "conclusion": "\u7ed3\u6784\u4e0a\u4e0b\u6587\u5728\u68c0\u6d4b\u5728\u7ebf\u4e0d\u6587\u660e\u884c\u4e3a\u4e2d\u8d77\u5173\u952e\u4f5c\u7528\uff0c\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u5747\u8d85\u8d8a\u4e86\u4ec5\u4f9d\u8d56\u6587\u672c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2512.07687", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.07687", "abs": "https://arxiv.org/abs/2512.07687", "authors": ["Sujoy Nath", "Arkaprabha Basu", "Sharanya Dasgupta", "Swagatam Das"], "title": "HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding tasks. While these models often produce linguistically coherent output, they often suffer from hallucinations, generating descriptions that are factually inconsistent with the visual content, potentially leading to adverse consequences. Therefore, the assessment of hallucinations in MLLM has become increasingly crucial in the model development process. Contemporary methodologies predominantly depend on external LLM evaluators, which are themselves susceptible to hallucinations and may present challenges in terms of domain adaptation. In this study, we propose the hypothesis that hallucination manifests as measurable irregularities within the internal layer dynamics of MLLMs, not merely due to distributional shifts but also in the context of layer-wise analysis of specific assumptions. By incorporating such modifications, \\textsc{\\textsc{HalluShift++}} broadens the efficacy of hallucination detection from text-based large language models (LLMs) to encompass multimodal scenarios. Our codebase is available at https://github.com/C0mRD/HalluShift_Plus.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u5e7b\u89c9\u68c0\u6d4b\u7684\u65b0\u65b9\u6cd5\u2014\u2014HalluShift++\uff0c\u57fa\u4e8e\u5185\u90e8\u5c42\u52a8\u6001\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u63d0\u5347\u4e86\u5e7b\u89c9\u8bc6\u522b\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5916\u90e8LLM\u8bc4\u4f30\u5668\uff0c\u5b58\u5728\u81ea\u8eab\u5e7b\u89c9\u548c\u9002\u5e94\u6027\u5dee\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65e0\u9700\u5916\u90e8\u8bc4\u4f30\u5668\u4e14\u9002\u5e94\u6027\u66f4\u5f3a\u7684\u5e7b\u89c9\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5185\u90e8\u5c42\u52a8\u6001\u7684\u5e7b\u89c9\u68c0\u6d4b\u5047\u8bbe\uff0c\u901a\u8fc7\u5c42\u7ea7\u5206\u6790\u548c\u7279\u5b9a\u5047\u8bbe\u4fee\u6b63\uff0c\u5b9e\u73b0\u4e86\u4ece\u6587\u672c\u5927\u8bed\u8a00\u6a21\u578b\u5230\u591a\u6a21\u6001\u6a21\u578b\u7684\u5e7b\u89c9\u68c0\u6d4b\u8fc1\u79fb\u3002", "result": "\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5185\u90e8\u5c42\u52a8\u6001\u7684\u68c0\u6d4b\u65b9\u6cd5\u5728MLLM\u4e2d\u5177\u6709\u826f\u597d\u7684\u5e7b\u89c9\u8bc6\u522b\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u5e7b\u89c9\u68c0\u6d4b\u7684\u6027\u80fd\u548c\u9002\u7528\u8303\u56f4\u3002", "conclusion": "HalluShift++\u901a\u8fc7\u5206\u6790MLLM\u5185\u90e8\u5c42\u7684\u52a8\u6001\u53d8\u5316\uff0c\u6709\u6548\u68c0\u6d4b\u51fa\u5e7b\u89c9\u73b0\u8c61\uff0c\u62d3\u5c55\u4e86\u5e7b\u89c9\u68c0\u6d4b\u6280\u672f\u5728\u591a\u6a21\u6001\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002"}}
{"id": "2512.07694", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07694", "abs": "https://arxiv.org/abs/2512.07694", "authors": ["Francois Vandenhende", "Anna Georgiou", "Michalis Georgiou", "Theodoros Psaras", "Ellie Karekla", "Elena Hadjicosta"], "title": "Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map", "comment": "12 pages, 4 figures", "summary": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against the FDA OCMQ v3.0 (104 queries), restricted to valid MedDRA PTs. Precision, recall and F1 were computed across similarity-thresholds. High recall (>95%) is achieved at moderate thresholds. Higher thresholds improve precision (up to 86%). The optimal threshold (~0.70 - 0.75) yielded recall ~50% and precision ~33%. Narrow-term PT subsets performed similarly but required slightly higher similarity thresholds. The SafeTerm AI-driven system provides a viable supplementary method for automated MedDRA query generation. A similarity threshold of ~0.60 is recommended initially, with increased thresholds for refined term selection.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u7684\u7cfb\u7edfSafeTerm\uff0c\u7528\u4e8e\u81ea\u52a8\u68c0\u7d22\u548c\u6392\u5e8f\u4e0e\u836f\u7269\u4e0d\u826f\u4e8b\u4ef6\u67e5\u8be2\u76f8\u5173\u7684MedDRA\u672f\u8bed\uff0c\u9a8c\u8bc1\u7ed3\u679c\u663e\u793a\u5176\u5728\u5b89\u5168\u6027\u4fe1\u53f7\u68c0\u6d4b\u4e2d\u5177\u5907\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u5728\u836f\u54c1\u4e0a\u5e02\u524d\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u4e2d\uff0c\u5c06\u76f8\u5173\u4e0d\u826f\u4e8b\u4ef6\u672f\u8bed\u5f52\u7c7b\u4e3a\u6807\u51c6\u5316\u7684MedDRA\u67e5\u8be2\u6216FDA OCMQ\u67e5\u8be2\u5bf9\u4e8e\u4fe1\u53f7\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u9896\u7684\u5b9a\u91cf\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff08SafeTerm\uff09\uff0c\u901a\u8fc7\u5c06\u533b\u5b66\u67e5\u8be2\u672f\u8bed\u548cMedDRA\u9996\u9009\u672f\u8bed\u5d4c\u5165\u591a\u7ef4\u5411\u91cf\u7a7a\u95f4\uff0c\u5229\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u548c\u6781\u503c\u805a\u7c7b\u6280\u672f\u81ea\u52a8\u68c0\u7d22\u548c\u6392\u5e8f\u4e0e\u8f93\u5165\u67e5\u8be2\u76f8\u5173\u7684MedDRA\u672f\u8bed\u3002", "result": "\u7cfb\u7edf\u5728104\u4e2aFDA OCMQ v3.0\u67e5\u8be2\u4e0a\u9a8c\u8bc1\uff0c\u8868\u73b0\u51fa\u9ad8\u53ec\u56de\u7387\uff08>95%\uff09\u548c\u826f\u597d\u7cbe\u786e\u5ea6\uff08\u6700\u9ad886%\uff09\uff0c\u6700\u4f18\u76f8\u4f3c\u5ea6\u9608\u503c\u4e3a0.70-0.75\u65f6\u53ec\u56de\u7387\u7ea6\u4e3a50%\uff0c\u7cbe\u786e\u7387\u7ea6\u4e3a33%\u3002", "conclusion": "SafeTerm\u7cfb\u7edf\u53ef\u4f5c\u4e3a\u81ea\u52a8\u751f\u6210MedDRA\u67e5\u8be2\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u63a8\u8350\u521d\u59cb\u76f8\u4f3c\u5ea6\u9608\u503c\u4e3a0.60\uff0c\u968f\u540e\u63d0\u9ad8\u9608\u503c\u4ee5\u4f18\u5316\u672f\u8bed\u7b5b\u9009\u3002"}}
{"id": "2512.07777", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07777", "abs": "https://arxiv.org/abs/2512.07777", "authors": ["Karin de Langis", "P\u00fcren \u00d6ncel", "Ryan Peters", "Andrew Elfenbein", "Laura Kristen Allen", "Andreas Schramm", "Dongyeop Kang"], "title": "Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?", "comment": null, "summary": "Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.", "AI": {"tldr": "LLMs\u80fd\u5185\u90e8\u8bc6\u522b\u4e0d\u8fde\u8d2f\u53d9\u4e8b\uff0c\u4f46\u751f\u6210\u8bc4\u4ef7\u65e0\u6cd5\u6709\u6548\u533a\u5206\u8fde\u8d2f\u6027\uff0c\u4e14\u66f4\u4f9d\u8d56\u4e16\u754c\u77e5\u8bc6\u800c\u975e\u53d9\u4e8b\u7406\u89e3\uff0c\u8868\u660e\u5176\u6545\u4e8b\u8fde\u8d2f\u6027\u7406\u89e3\u4e0d\u5b8c\u6574\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u591f\u53ef\u9760\u5730\u533a\u5206\u8fde\u8d2f\u4e0e\u4e0d\u8fde\u8d2f\u6545\u4e8b\uff0c\u63ed\u793a\u5176\u5728\u53d9\u4e8b\u7406\u89e3\u65b9\u9762\u7684\u80fd\u529b\u4e0e\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u6210\u5bf9\u6545\u4e8b\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5185\u5728\u8868\u5f81\u5206\u6790\u4e0e\u95ee\u7b54\u751f\u6210\u4e24\u79cd\u65b9\u5f0f\u8bc4\u4f30LLMs\u7684\u53d9\u4e8b\u8fde\u8d2f\u6027\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u6d4b\u8bd5\u591a\u79cd\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u3002", "result": "\u672c\u6587\u5229\u7528\u6210\u5bf9\u53d9\u4e8b\u6570\u636e\u96c6\uff0c\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u533a\u5206\u8fde\u8d2f\u4e0e\u4e0d\u8fde\u8d2f\u6545\u4e8b\u7684\u80fd\u529b\u3002\u53d1\u73b0\u6a21\u578b\u5185\u90e8\u8868\u5f81\u80fd\u53ef\u9760\u8bc6\u522b\u4e0d\u8fde\u8d2f\u53d9\u4e8b\uff0c\u4f46\u751f\u6210\u7684\u8bc4\u4ef7\u95ee\u7b54\u65e0\u6cd5\u6709\u6548\u5206\u8fa8\u4e24\u8005\uff0c\u663e\u793a\u6a21\u578b\u5728\u6545\u4e8b\u7406\u89e3\u4e0a\u5b58\u5728\u5dee\u8ddd\u3002\u63a8\u7406\u589e\u5f3a\u65b9\u6cd5\u672a\u80fd\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\uff0c\u8868\u660e\u5185\u90e8\u72b6\u6001\u4e0e\u884c\u4e3a\u95f4\u5b58\u5728\u4e0d\u4e00\u81f4\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5bf9\u73af\u5883\u8bbe\u5b9a\u8fdd\u80cc\uff08\u5982\u6c99\u6f20\u4e0b\u96e8\uff09\u7684\u4e0d\u8fde\u8d2f\u66f4\u654f\u611f\uff0c\u800c\u5bf9\u89d2\u8272\u7279\u6027\u8fdd\u80cc\uff08\u5982\u7d20\u98df\u8005\u70b9\u5976\u916a\u6c49\u5821\uff09\u654f\u611f\u5ea6\u8f83\u4f4e\uff0c\u6697\u793a\u6a21\u578b\u66f4\u4f9d\u8d56\u5178\u578b\u4e16\u754c\u77e5\u8bc6\u800c\u975e\u57fa\u4e8e\u610f\u4e49\u7684\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002\u6574\u4f53\u7ed3\u679c\u8868\u660eLLMs\u5c1a\u672a\u5b8c\u5168\u638c\u63e1\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002", "conclusion": "LLMs\u867d\u5177\u5185\u90e8\u8bc6\u522b\u4e0d\u8fde\u8d2f\u80fd\u529b\uff0c\u4f46\u5728\u884c\u4e3a\u5c42\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u4e14\u5bf9\u4e0d\u540c\u7c7b\u578b\u4e0d\u8fde\u8d2f\u654f\u611f\u5ea6\u4e0d\u5747\uff0c\u663e\u793a\u5176\u53d9\u4e8b\u8fde\u8d2f\u7406\u89e3\u5b58\u5728\u5c40\u9650\u3002"}}
{"id": "2512.07783", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.07783", "abs": "https://arxiv.org/abs/2512.07783", "authors": ["Charlie Zhang", "Graham Neubig", "Xiang Yue"], "title": "On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models", "comment": null, "summary": "Recent reinforcement learning (RL) techniques have yielded impressive reasoning improvements in language models, yet it remains unclear whether post-training truly extends a model's reasoning ability beyond what it acquires during pre-training. A central challenge is the lack of control in modern training pipelines: large-scale pre-training corpora are opaque, mid-training is often underexamined, and RL objectives interact with unknown prior knowledge in complex ways. To resolve this ambiguity, we develop a fully controlled experimental framework that isolates the causal contributions of pre-training, mid-training, and RL-based post-training. Our approach employs synthetic reasoning tasks with explicit atomic operations, parseable step-by-step reasoning traces, and systematic manipulation of training distributions. We evaluate models along two axes: extrapolative generalization to more complex compositions and contextual generalization across surface contexts. Using this framework, we reconcile competing views on RL's effectiveness. We show that: 1) RL produces true capability gains (pass@128) only when pre-training leaves sufficient headroom and when RL data target the model's edge of competence, tasks at the boundary that are difficult but not yet out of reach. 2) Contextual generalization requires minimal yet sufficient pre-training exposure, after which RL can reliably transfer. 3) Mid-training significantly enhances performance under fixed compute compared with RL only, demonstrating its central but underexplored role in training pipelines. 4) Process-level rewards reduce reward hacking and improve reasoning fidelity. Together, these results clarify the interplay between pre-training, mid-training, and RL, offering a foundation for understanding and improving reasoning LM training strategies.", "AI": {"tldr": "\u901a\u8fc7\u6784\u5efa\u53ef\u63a7\u5b9e\u9a8c\u6846\u67b6\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u540e\u8bad\u7ec3\u5bf9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u5347\u7684\u4e0d\u540c\u8d21\u732e\u53ca\u5176\u76f8\u4e92\u5173\u7cfb\uff0c\u4e3a\u4f18\u5316\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u4e0d\u900f\u660e\uff0c\u5f3a\u5316\u5b66\u4e60\u76ee\u6807\u4e0e\u5df2\u6709\u77e5\u8bc6\u590d\u6742\u4ea4\u4e92\uff0c\u5bfc\u81f4\u96be\u4ee5\u5398\u6e05\u5404\u8bad\u7ec3\u9636\u6bb5\u5bf9\u6a21\u578b\u63a8\u7406\u80fd\u529b\u63d0\u5347\u7684\u5177\u4f53\u8d21\u732e\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u63a7\u5236\u5b9e\u9a8c\u6846\u67b6\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5408\u6210\u63a8\u7406\u4efb\u52a1\uff0c\u8bbe\u8ba1\u660e\u786e\u7684\u539f\u5b50\u64cd\u4f5c\u548c\u53ef\u89e3\u6790\u7684\u9010\u6b65\u63a8\u7406\u8f68\u8ff9\uff0c\u901a\u8fc7\u7cfb\u7edf\u64cd\u63a7\u8bad\u7ec3\u5206\u5e03\uff0c\u5206\u522b\u8bc4\u4f30\u6a21\u578b\u7684\u5916\u63a8\u6cdb\u5316\u548c\u8bed\u5883\u6cdb\u5316\u80fd\u529b\uff0c\u4ece\u800c\u89e3\u6790\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u7684\u56e0\u679c\u8d21\u732e\u3002", "result": "\u672c\u6587\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u5b8c\u5168\u53ef\u63a7\u7684\u5b9e\u9a8c\u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u5206\u6790\u4e86\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u540e\u8bad\u7ec3\u5bf9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u8d21\u732e\u3002\u7814\u7a76\u53d1\u73b0\uff1a1\uff09\u53ea\u6709\u5f53\u9884\u8bad\u7ec3\u7559\u4e0b\u8db3\u591f\u53d1\u5c55\u7a7a\u95f4\u4e14RL\u8bad\u7ec3\u6570\u636e\u9488\u5bf9\u6a21\u578b\u80fd\u529b\u8fb9\u754c\u4efb\u52a1\u65f6\uff0cRL\u624d\u80fd\u5e26\u6765\u771f\u5b9e\u7684\u80fd\u529b\u63d0\u5347\uff1b2\uff09\u8bed\u5883\u6cdb\u5316\u9700\u8981\u9002\u5f53\u7684\u9884\u8bad\u7ec3\uff0c\u4e14RL\u80fd\u6709\u6548\u8fc1\u79fb\u6b64\u80fd\u529b\uff1b3\uff09\u4e2d\u671f\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e14\u5728\u8ba1\u7b97\u8d44\u6e90\u56fa\u5b9a\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4ec5\u7528RL\uff0c\u663e\u793a\u5176\u91cd\u8981\u4f5c\u7528\uff1b4\uff09\u8fc7\u7a0b\u7ea7\u5956\u52b1\u51cf\u5c11\u4e86\u5956\u52b1\u6b3a\u9a97\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u7684\u51c6\u786e\u6027\u3002\u6574\u4f53\u7ed3\u679c\u9610\u660e\u4e86\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u4e0eRL\u4e09\u8005\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u4e3a\u6539\u8fdb\u63a8\u7406\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86RL\u540e\u8bad\u7ec3\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u80fd\u529b\u7684\u524d\u63d0\u6761\u4ef6\uff0c\u5e76\u5f3a\u8c03\u4e86\u4e2d\u671f\u8bad\u7ec3\u7684\u91cd\u8981\u6027\u53ca\u8fc7\u7a0b\u7ea7\u5956\u52b1\u7684\u79ef\u6781\u4f5c\u7528\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u5bf9\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u673a\u5236\u3002"}}
{"id": "2512.07801", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07801", "abs": "https://arxiv.org/abs/2512.07801", "authors": ["Raunak Jain", "Mudita Khurana"], "title": "Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support", "comment": null, "summary": "LLM-based agents are rapidly being plugged into expert decision-support, yet in messy, high-stakes settings they rarely make the team smarter: human-AI teams often underperform the best individual, experts oscillate between verification loops and over-reliance, and the promised complementarity does not materialise. We argue this is not just a matter of accuracy, but a fundamental gap in how we conceive AI assistance: expert decisions are made through collaborative cognitive processes where mental models, goals, and constraints are continually co-constructed, tested, and revised between human and AI. We propose Collaborative Causal Sensemaking (CCS) as a research agenda and organizing framework for decision-support agents: systems designed as partners in cognitive work, maintaining evolving models of how particular experts reason, helping articulate and revise goals, co-constructing and stress-testing causal hypotheses, and learning from the outcomes of joint decisions so that both human and agent improve over time. We sketch challenges around training ecologies that make collaborative thinking instrumentally valuable, representations and interaction protocols for co-authored models, and evaluation centred on trust and complementarity. These directions can reframe MAS research around agents that participate in collaborative sensemaking and act as AI teammates that think with their human partners.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5408\u4f5c\u56e0\u679c\u5efa\u6784\u6846\u67b6\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u51b3\u7b56\uff0c\u901a\u8fc7\u5171\u4eab\u8ba4\u77e5\u6a21\u578b\u548c\u56e0\u679c\u63a8\u7406\u63d0\u5347\u4e13\u5bb6\u56e2\u961f\u8868\u73b0\uff0c\u89e3\u51b3\u4f20\u7edfAI\u8f85\u52a9\u4e2d\u4eba\u673a\u534f\u4f5c\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4e13\u5bb6\u51b3\u7b56\u652f\u6301\uff0c\u4f46\u5728\u4eba\u673a\u534f\u4f5c\u4e2d\u7ecf\u5e38\u65e0\u6cd5\u63d0\u5347\u56e2\u961f\u8868\u73b0\uff0c\u539f\u56e0\u5728\u4e8e\u4f20\u7edfAI\u8f85\u52a9\u5ffd\u89c6\u4e86\u4e13\u5bb6\u51b3\u7b56\u4e2d\u7684\u534f\u540c\u8ba4\u77e5\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86\u5408\u4f5c\u56e0\u679c\u5efa\u6784\uff08Collaborative Causal Sensemaking\uff0cCCS\uff09\u4f5c\u4e3a\u7814\u7a76\u6846\u67b6\uff0c\u8bbe\u8ba1\u652f\u6301\u8ba4\u77e5\u5de5\u4f5c\u7684\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\uff0c\u5f3a\u8c03\u5171\u540c\u6784\u5efa\u548c\u68c0\u9a8c\u56e0\u679c\u5047\u8bbe\uff0c\u52a8\u6001\u8c03\u6574\u6a21\u578b\u548c\u76ee\u6807\uff0c\u4ee5\u53ca\u4ece\u8054\u5408\u51b3\u7b56\u7ed3\u679c\u4e2d\u76f8\u4e92\u5b66\u4e60\u3002", "result": "\u63d0\u51fa\u7684CCS\u6846\u67b6\u80fd\u591f\u4fc3\u8fdb\u4eba\u673a\u5171\u540c\u601d\u8003\u4e0e\u63a8\u7406\uff0c\u4f7fAI\u771f\u6b63\u6210\u4e3a\u4eba\u7c7b\u4e13\u5bb6\u7684\u5408\u4f5c\u4f19\u4f34\uff0c\u63d0\u5347\u4fe1\u4efb\u548c\u4e92\u8865\u6027\uff0c\u89e3\u51b3\u73b0\u6709\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u590d\u6742\u73af\u5883\u4e2d\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\u3002", "conclusion": "\u5c06\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7814\u7a76\u8f6c\u5411\u652f\u6301\u534f\u4f5c\u8ba4\u77e5\u7684\u4ee3\u7406\uff0c\u5f3a\u8c03\u4eba\u673a\u534f\u540c\u7684\u56e0\u679c\u63a8\u7406\u548c\u5efa\u6a21\uff0c\u4fc3\u8fdb\u5171\u540c\u51b3\u7b56\u4e2d\u7684\u4fe1\u4efb\u4e0e\u4e92\u8865\uff0c\u5b9e\u73b0AI\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u7684\u957f\u671f\u5171\u8fdb\u3002"}}
{"id": "2512.07832", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.07832", "abs": "https://arxiv.org/abs/2512.07832", "authors": ["Matteo Boglioni", "Andrea Sgobbi", "Gabriel Tavernini", "Francesco Rita", "Marius Mosbach", "Tiago Pimentel"], "title": "Do Generalisation Results Generalise?", "comment": null, "summary": "A large language model's (LLM's) out-of-distribution (OOD) generalisation ability is crucial to its deployment. Previous work assessing LLMs' generalisation performance, however, typically focuses on a single out-of-distribution dataset. This approach may fail to precisely evaluate the capabilities of the model, as the data shifts encountered once a model is deployed are much more diverse. In this work, we investigate whether OOD generalisation results generalise. More specifically, we evaluate a model's performance across multiple OOD testsets throughout a finetuning run; we then evaluate the partial correlation of performances across these testsets, regressing out in-domain performance. This allows us to assess how correlated are generalisation performances once in-domain performance is controlled for. Analysing OLMo2 and OPT, we observe no overarching trend in generalisation results: the existence of a positive or negative correlation between any two OOD testsets depends strongly on the specific choice of model analysed.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u4e0d\u540c\u5206\u5e03\u7684\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u4e0d\u540cOOD\u6d4b\u8bd5\u96c6\u4e4b\u95f4\u7684\u8868\u73b0\u76f8\u5173\u6027\u4f9d\u8d56\u4e8e\u5177\u4f53\u6a21\u578b\uff0c\u6ca1\u6709\u7edf\u4e00\u8d8b\u52bf\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u901a\u5e38\u53ea\u7528\u5355\u4e00OOD\u6d4b\u8bd5\u96c6\uff0c\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u6a21\u578b\u5b9e\u9645\u90e8\u7f72\u4e2d\u9047\u5230\u7684\u591a\u6837\u5316\u6570\u636e\u5206\u5e03\u8f6c\u79fb\u3002", "method": "\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u591a\u4e2aOOD\u6d4b\u8bd5\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63a7\u5236\u5728\u57df\u5185\u8868\u73b0\u540e\u8ba1\u7b97\u5404\u6d4b\u8bd5\u96c6\u95f4\u7684\u504f\u76f8\u5173\u3002", "result": "\u901a\u8fc7OLMo2\u548cOPT\u7684\u5206\u6790\u53d1\u73b0\uff0c\u4e0d\u540cOOD\u6d4b\u8bd5\u96c6\u95f4\u7684\u8868\u73b0\u76f8\u5173\u6027\u53d6\u51b3\u4e8e\u5177\u4f53\u6a21\u578b\uff0c\u6ca1\u6709\u7edf\u4e00\u6b63\u8d1f\u76f8\u5173\u8d8b\u52bf\u3002", "conclusion": "\u4e0d\u540c\u6a21\u578b\u5728\u4e0d\u540cOOD\u6d4b\u8bd5\u96c6\u4e0a\u7684\u6cdb\u5316\u8868\u73b0\u76f8\u5173\u6027\u4e0d\u7a33\u5b9a\uff0c\u8bf4\u660e\u5355\u4e00OOD\u6d4b\u8bd5\u96c6\u7684\u6cdb\u5316\u8bc4\u4f30\u6709\u9650\u3002"}}
