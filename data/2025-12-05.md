<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 32]
- [cs.SE](#cs.SE) [Total: 17]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral](https://arxiv.org/abs/2512.04220)
*Wenlong Deng,Yushu Li,Boying Gong,Yi Ren,Christos Thrampoulidis,Xiaoxiao Li*

Main category: cs.CL

TL;DR: 本文发现GRPO训练崩溃的核心机制是LLD，提出LLDS正则化有效缓解问题，大幅提升工具集成强化学习中大语言模型的训练稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 工具集成强化学习中，GRPO方法虽然收敛快且无价值函数，但普遍存在训练崩溃问题，限制了大语言模型多步推理能力的发挥，亟需解决其核心机制以稳定训练。

Method: 本文提出了轻量级的似然保持正则化方法LLDS，仅在轨迹似然下降时激活，且只正则化相关的token，从而细粒度地缓解了LLD问题，提升训练的稳定性。

Result: 该方法在七个开放域和多跳问答基准任务中均稳定了训练，防止了梯度爆炸，带来了显著性能提升，例如Qwen2.5-3B提升37.8%，Qwen2.5-7B提升32.0%。

Conclusion: 本文确认了Lazy Likelihood Displacement（LLD）是导致GRPO在工具集成强化学习中训练崩溃的根本原因，提出了有针对性的正则化方法LLDS，有效解决了训练稳定性问题并显著提升了多项问答基准任务的性能。

Abstract: Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory's likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.

</details>


### [2] [Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification](https://arxiv.org/abs/2512.04257)
*Mansour Essgaer,Khamis Massud,Rabia Al Mamlook,Najah Ghmaid*

Main category: cs.CL

TL;DR: 针对利比亚方言推断任务，选择合适的n-gram特征和分类器能有效提升识别性能，多项式朴素贝叶斯表现最佳，达85.89%准确率。


<details>
  <summary>Details</summary>
Motivation: 解决利比亚方言推断中的正字法多样性和非标准拼写问题，找到影响分类的有效特征，并提升利比亚方言识别的准确率。

Method: 本研究比较了逻辑回归、线性支持向量机、多项式朴素贝叶斯和伯努利朴素贝叶斯四种分类器，采用QADI语料库和不同的词汇与字符n-gram特征进行利比亚方言推断。

Result: 多项式朴素贝叶斯在(1,2)词n-gram和(1,5)字符n-gram特征组合下达到最高85.89%的准确率和0.85741的F1值，表现优于逻辑回归和线性SVM。

Conclusion: 本研究证明了针对利比亚方言的n-gram特征选择与分类器选择的重要性，为阿拉伯方言自然语言处理提供了实证基准和方法指导。

Abstract: This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,000 sentences across 18 Arabic dialects. Preprocessing challenges include handling inconsistent orthographic variations and non-standard spellings typical of the Libyan dialect. The chi-square analysis revealed that certain features, such as email mentions and emotion indicators, were not significantly associated with dialect classification and were thus excluded from further analysis. Two main experiments were conducted: (1) evaluating the significance of meta-features extracted from the corpus using the chi-square test and (2) assessing classifier performance using different word and character n-gram representations. The classification experiments showed that Multinomial Naive Bayes (MNB) achieved the highest accuracy of 85.89% and an F1-score of 0.85741 when using a (1,2) word n-gram and (1,5) character n-gram representation. In contrast, Logistic Regression and Linear SVM exhibited slightly lower performance, with maximum accuracies of 84.41% and 84.73%, respectively. Additional evaluation metrics, including log loss, Cohen kappa, and Matthew correlation coefficient, further supported the effectiveness of MNB in this task. The results indicate that carefully selected n-gram representations and classification models play a crucial role in improving the accuracy of Libyan dialect identification. This study provides empirical benchmarks and insights for future research in Arabic dialect NLP applications.

</details>


### [3] [SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats](https://arxiv.org/abs/2512.04292)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: SQuARE是一个混合检索框架，通过复杂度感知路由，提高了多表头财务表格问答的准确性，优于传统方法及ChatGPT。


<details>
  <summary>Details</summary>
Motivation: 现有问答方法难以处理表格中的多行表头、合并单元格及单位标注，且SQL视图对无一致模式文件表现差，需新方法提升真实表格问答的准确性和鲁棒性。

Method: 通过计算表头深度和合并密度的连续分数，动态选择结构保留检索或自动构建的关系表示上的SQL查询，结合轻量级代理进行结果监督与融合。

Result: 提出了SQuARE框架，结合表格结构分析和SQL查询，解决了多行表头、合并单元格及单位注释等复杂问题，实现了更准确的问答性能。

Conclusion: SQuARE在多个多表头及合并复杂表格数据集上表现优于单一策略和ChatGPT-4o，检索精度和问答准确率均有提升，且延迟稳定。

Abstract: Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.

</details>


### [4] [DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle](https://arxiv.org/abs/2512.04324)
*Fangyu Lei,Jinxiang Meng,Yiming Huang,Junjie Zhao,Yitong Zhang,Jianwen Luo,Xin Zou,Ruiyi Yang,Wenbo Shi,Yan Gao,Shizhu He,Zuo Wang,Qian Liu,Yang Wang,Ke Wang,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: DAComp基准涵盖复杂企业数据工程与数据分析任务，揭示现有智能体在全流程管控和开放式推理上的严重不足，推动自主数据智能体发展。


<details>
  <summary>Details</summary>
Motivation: 当前企业数据智能工作流复杂，涵盖了从数据工程到数据分析多个环节，但现有方法难以全面评估这些复杂流程中的能力。

Method: 提出DAComp基准测试，包含210个任务，涵盖工业级多阶段SQL管道设计与演进，以及开放式业务问题的数据分析，采用多指标执行评价和基于LLM评判者的分层评分标准。

Result: 实验结果表明，即使是最先进的智能体在DAComp上表现不佳，数据工程任务成功率不足20%，数据分析任务得分低于40%，反映出管道协调和开放式推理方面的显著不足。

Conclusion: DAComp为企业环境中自主数据智能体的开发提供了严谨且现实的测试平台，明确揭示了当前技术的瓶颈和缺陷，促进未来技术进步。

Abstract: Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks that mirrors these complex workflows. Data engineering (DE) tasks require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving requirements. Data analysis (DA) tasks pose open-ended business problems that demand strategic planning, exploratory analysis through iterative coding, interpretation of intermediate results, and the synthesis of actionable recommendations. Engineering tasks are scored through execution-based, multi-metric evaluation. Open-ended tasks are assessed by a reliable, experimentally validated LLM-judge, which is guided by hierarchical, meticulously crafted rubrics. Our experiments reveal that even state-of-the-art agents falter on DAComp. Performance on DE tasks is particularly low, with success rates under 20%, exposing a critical bottleneck in holistic pipeline orchestration, not merely code generation. Scores on DA tasks also average below 40%, highlighting profound deficiencies in open-ended reasoning and demonstrating that engineering and analysis are distinct capabilities. By clearly diagnosing these limitations, DAComp provides a rigorous and realistic testbed to drive the development of truly capable autonomous data agents for enterprise settings. Our data and code are available at https://da-comp.github.io

</details>


### [5] [ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation](https://arxiv.org/abs/2512.04350)
*Yiming Xu,Yuan Yuan,Vijay Viswanathan,Graham Neubig*

Main category: cs.CL

TL;DR: 本文提出的ClusterFusion框架融合了LLM与轻量嵌入方法，显著提升了文本聚类的领域适应性和效果。


<details>
  <summary>Details</summary>
Motivation: 传统聚类算法依赖预训练嵌入，在特定领域缺乏适应性且微调成本高，而现有利用LLM的方法仅作为辅助未充分发挥其能力。

Method: 提出了ClusterFusion混合框架，将大语言模型（LLM）作为聚类核心，通过嵌入指导的子集划分、LLM驱动的话题总结和LLM基础的话题分配三个阶段实现。

Result: ClusterFusion在三个公共基准和两个新构建的领域数据集上均取得了最先进的性能，特别在专业领域表现明显提升。

Conclusion: ClusterFusion有效利用LLM的上下文理解能力，实现了领域知识的直接融合，推动了文本聚类任务的性能提升，并公开了数据集以促进后续研究。

Abstract: Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong contextual reasoning, yet prior work mainly uses them as auxiliary modules to refine embeddings or adjust cluster boundaries. We propose ClusterFusion, a hybrid framework that instead treats the LLM as the clustering core, guided by lightweight embedding methods. The framework proceeds in three stages: embedding-guided subset partition, LLM-driven topic summarization, and LLM-based topic assignment. This design enables direct incorporation of domain knowledge and user preferences, fully leveraging the contextual adaptability of LLMs. Experiments on three public benchmarks and two new domain-specific datasets demonstrate that ClusterFusion not only achieves state-of-the-art performance on standard tasks but also delivers substantial gains in specialized domains. To support future work, we release our newly constructed dataset and results on all benchmarks.

</details>


### [6] [LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving](https://arxiv.org/abs/2512.04374)
*Muyu Pan,Matthew Walter,Dheeraj Kodakandla,Mahfuza Farooque*

Main category: cs.CL

TL;DR: LangSAT框架结合自然语言转换和强化学习优化CDCL求解器，实现了基于英语描述的SAT求解，提升了求解效率并增强了易用性。


<details>
  <summary>Details</summary>
Motivation: 现有SAT求解器需以CNF形式输入，限制了普通用户的使用，本文旨在通过自然语言转换和强化学习优化提升SAT求解的可访问性和效率。

Method: 该方法通过Lang2Logic模块将英语转换为CNF表达，再由强化学习驱动的SmartSAT利用图结构编码和全局特征来优化CDCL启发式选择，提升求解性能。

Result: 本文提出了一个基于强化学习的框架LangSAT，通过优化冲突驱动子句学习（CDCL）过程中的启发式选择，提高了布尔可满足性问题（SAT）的求解效率。LangSAT包含Lang2Logic模块将英语描述转化为合取范式（CNF），以及SmartSAT模块采用强化学习增强的CDCL求解器。SmartSAT利用图结构编码子句变量关系，提取全局特征，赋予强化学习代理更深的上下文信息，从而提升解题效率。实验证明，Lang2Logic能处理最多450词的自然语言输入，SmartSAT求解时间与传统CDCL启发式方法相当。该框架使用户可通过标准英语输入进行SAT求解，提高了可访问性和扩展性，适用于推理、形式验证和调试等领域。

Conclusion: LangSAT成功将自然语言输入转化为CNF表达并利用强化学习优化CDCL求解，有效提升SAT求解效率和用户可访问性。

Abstract: Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfiability (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.

</details>


### [7] [MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation](https://arxiv.org/abs/2512.04386)
*Zhou Yang,Shunyan Luo,Jiazhen Zhu,Fang Jin*

Main category: cs.CL

TL;DR: 本文提出的MASE框架通过NLGP在嵌入层评估文本模型输入显著性，实现了高效且无模型依赖的解释，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度神经网络的解释方法多为后置解释且难以直接应用于离散的文本数据，亟需一种高效且模型无关的解释框架。

Method: 提出了基于归一化线性高斯扰动（NLGP）在嵌入层进行输入显著性估计的方法，避免了对模型内部架构的依赖。

Result: 实验表明，MASE在Delta准确率指标上超过其他无关模型解释技术，展示了其在文本模型解释上的优势。

Conclusion: MASE框架有效提升了文本预测模型的可解释性，优于其他模型无关的解释方法。

Abstract: Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or feature visualization, which might not be directly applicable to the discrete nature of word data in NLP. Addressing this, we introduce the Model-agnostic Saliency Estimation (MASE) framework. MASE offers local explanations for text-based predictive models without necessitating in-depth knowledge of a model's internal architecture. By leveraging Normalized Linear Gaussian Perturbations (NLGP) on the embedding layer instead of raw word inputs, MASE efficiently estimates input saliency. Our results indicate MASE's superiority over other model-agnostic interpretation methods, especially in terms of Delta Accuracy, positioning it as a promising tool for elucidating the operations of text-based models in NLP.

</details>


### [8] [Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering](https://arxiv.org/abs/2512.04396)
*Subrata Karmaker*

Main category: cs.CL

TL;DR: 本文用传统机器学习和特征工程，在无上下文情况下对Reddit讽刺评论进行检测，取得约0.57的F1分数，提供轻量可解释的基线。


<details>
  <summary>Details</summary>
Motivation: 鉴于讽刺语言与其字面意思相反，且识别难度大，本文旨在通过传统机器学习方法和特征工程，在无上下文和神经网络环境下实现讽刺检测。

Method: 采用词汇级和字符级TF-IDF特征结合简单文体指标，测试逻辑回归、线性SVM、多项式朴素贝叶斯和随机森林四种模型。

Result: 本文通过使用经典机器学习方法和显式特征工程，探讨了在没有神经网络和上下文信息的情况下检测网络交流中的讽刺。使用了10万条自注释Reddit语料（SARC 2.0）子样本，将词级和字符级TF-IDF特征与简单的文体指标相结合，评估了逻辑回归、线性SVM、多项式朴素贝叶斯和随机森林四种模型。朴素贝叶斯和逻辑回归表现最好，对讽刺评论的F1值约为0.57。虽然缺乏上下文限制了模型性能，但研究提供了一个轻量且可解释的讽刺检测基准。

Conclusion: 尽管缺乏对话上下文限制了性能，但基于传统方法的讽刺检测模型依然可达到合理效果，且具备轻量和可解释优势。

Abstract: Sarcasm is common in online discussions, yet difficult for machines to identify because the intended meaning often contradicts the literal wording. In this work, I study sarcasm detection using only classical machine learning methods and explicit feature engineering, without relying on neural networks or context from parent comments. Using a 100,000-comment subsample of the Self-Annotated Reddit Corpus (SARC 2.0), I combine word-level and character-level TF-IDF features with simple stylistic indicators. Four models are evaluated: logistic regression, a linear SVM, multinomial Naive Bayes, and a random forest. Naive Bayes and logistic regression perform the strongest, achieving F1-scores around 0.57 for sarcastic comments. Although the lack of conversational context limits performance, the results offer a clear and reproducible baseline for sarcasm detection using lightweight and interpretable methods.

</details>


### [9] [RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning](https://arxiv.org/abs/2512.04457)
*Guoshenghui Zhao,Huawei Lin,Weijie Zhao*

Main category: cs.CL

TL;DR: 提出了一种基于影响力驱动和参数高效的去学习框架RapidUn，大幅提升了大语言模型的去除特定数据影响的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型去除特定数据影响存在高昂的重训练成本和不稳定的近似去学习方法，特别是在遗忘集合较小或不平衡时问题更严重。

Method: 通过快速估计模块计算每个样本的影响力，然后将这些影响力转换为自适应权重，指导选择性参数更新。

Result: 在多个大型模型（Mistral-7B和Llama-3-8B）和数据集（Dolly-15k和Alpaca-57k）上，RapidUn比完全重训练效率提高100倍，且在内部和外部数据遗忘任务上优于现有方法如Fisher、GA和LoReUn。

Conclusion: RapidUn框架在大语言模型去除特定数据影响方面实现了高效且稳定的性能，优于现有方法。

Abstract: Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and parameter-efficient unlearning framework. It first estimates per-sample influence through a fast estimation module, then maps these scores into adaptive update weights that guide selective parameter updates -- forgetting harmful behavior while retaining general knowledge. On Mistral-7B and Llama-3-8B across Dolly-15k and Alpaca-57k, RapidUn achieves up to 100 times higher efficiency than full retraining and consistently outperforms Fisher, GA, and LoReUn on both in-distribution and out-of-distribution forgetting. These results establish influence-guided parameter reweighting as a scalable and interpretable paradigm for LLM unlearning.

</details>


### [10] [MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection](https://arxiv.org/abs/2512.04492)
*Yuanshuo Zhang,Aohua Li,Bo Chen,Jingbo Sun,Xiaobing Zhao*

Main category: cs.CL

TL;DR: MSME通过多阶段多专家协作，有效提升了零样本立场检测在复杂场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 解决复杂场景下立场检测面临的背景知识动态变化、复合目标定义以及修辞手法（如讽刺）干扰的问题。

Method: 提出MSME框架，包括知识准备、专家推理（知识专家、标签专家、语用专家）、决策聚合三个阶段。

Result: 在三个公开数据集上实现了最先进的零样本立场检测性能。

Conclusion: MSME框架有效解决了背景知识、目标定义和修辞干扰问题，显著提升了零样本立场检测的准确性。

Abstract: LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve compound entities or events that must be explicitly linked to stance labels, and rhetorical devices such as irony often obscure the author's actual intent. To address these challenges, we propose MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection. MSME consists of three stages: (1) Knowledge Preparation, where relevant background knowledge is retrieved and stance labels are clarified; (2) Expert Reasoning, involving three specialized modules-Knowledge Expert distills salient facts and reasons from a knowledge perspective, Label Expert refines stance labels and reasons accordingly, and Pragmatic Expert detects rhetorical cues such as irony to infer intent from a pragmatic angle; (3) Decision Aggregation, where a Meta-Judge integrates all expert analyses to produce the final stance prediction. Experiments on three public datasets show that MSME achieves state-of-the-art performance across the board.

</details>


### [11] [UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction](https://arxiv.org/abs/2512.04518)
*Tianmai M. Zhang,Zhaoyi Sun,Sihang Zeng,Chenxi Li,Neil F. Abernethy,Barbara D. Lam,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 本文针对从癌症患者电子健康记录构建抗癌治疗时间线任务，提出并比较了多种基于大型语言模型的方法，获得了良好效果，微调的Qwen3-14B模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 为了解决从癌症患者的电子健康记录中构建系统性抗癌治疗时间线的问题。

Method: 采用了链式思维、监督微调、直接偏好优化和基于词典查找的多种策略，利用大型语言模型（LLM）提取化疗事件，并通过算法对事件进行标准化和汇总，从而生成患者级时间线。

Result: 多种方法在测试集排行榜上表现出竞争力，其中微调的Qwen3-14B模型取得了最佳官方分数0.678。

Conclusion: 所提出的方法有效提升了从临床笔记中自动提取化疗事件并构建时间线的性能，研究结果为未来相关任务提供了有价值的参考。

Abstract: The ChemoTimelines shared task benchmarks methods for constructing timelines of systemic anticancer treatment from electronic health records of cancer patients. This paper describes our methods, results, and findings for subtask 2 -- generating patient chemotherapy timelines from raw clinical notes. We evaluated strategies involving chain-of-thought thinking, supervised fine-tuning, direct preference optimization, and dictionary-based lookup to improve timeline extraction. All of our approaches followed a two-step workflow, wherein an LLM first extracted chemotherapy events from individual clinical notes, and then an algorithm normalized and aggregated events into patient-level timelines. Each specific method differed in how the associated LLM was utilized and trained. Multiple approaches yielded competitive performances on the test set leaderboard, with fine-tuned Qwen3-14B achieving the best official score of 0.678. Our results and analyses could provide useful insights for future attempts on this task as well as the design of similar tasks.

</details>


### [12] [EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion](https://arxiv.org/abs/2512.04545)
*Pengfei Cao,Zeao Ji,Daojian Zeng,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 本文提出持续自由文本知识编辑任务LF-Edit及评测基准MRLF-Bench，设计认知多等级评估框架，提出EvoEdit方法实现高效且连续的知识更新，显著提升编辑性能。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型部署后难以更新过时知识，现有知识编辑方法依赖结构化三元组且支持的知识更新次数有限，难以满足连续编辑需求。

Method: 提出持续自由文本知识编辑任务（LF-Edit），建立包含16835条编辑请求的多等级基准MRLF-Bench，设计认知启发的多等级评估体系；提出EvoEdit方法，通过潜在扰动增强和知识驱动参数融合实现高效知识注入和旧知识保持。

Result: 实验结果表明，EvoEdit在LF-Edit任务上显著优于已有知识编辑方法。

Conclusion: 提出的LF-Edit任务及EvoEdit方法有效解决了语言模型持续自由文本知识编辑的关键问题，推动该领域研究发展。

Abstract: Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch. However, existing methods suffer from two limitations. First, they depend on structured triplets that are misaligned with the free-text nature of LLM pretraining and fail to capture the nuanced relationships among facts. Second, they typically support one-time knowledge updates, with relatively limited research on the problem of sequential or lifelong editing. To address these gaps, we propose a new task, Lifelong Free-text Knowledge Editing (LF-Edit), which enables models to incorporate updates expressed in natural language and supports continual editing over time. Despite its promise, LF-Edit faces the dual challenge of integrating new knowledge while mitigating the forgetting of prior information. To foster research on this new task, we construct a large-scale benchmark, Multi-Rank Lifelong Free-text Editing Benchmark (MRLF-Bench), containing 16,835 free-text edit requests. We further design a cognitively inspired multi-rank evaluation framework encompassing four levels: memorization, understanding, constrained comprehension, and reasoning. To tackle the challenges inherent in LF-Edit, we introduce a novel approach named EvoEdit that enhances knowledge injection through Latent Perturbation Augmentation and preserves prior information via Knowledge-driven Parameter Fusion. Experimental results demonstrate that EvoEdit substantially outperforms existing knowledge editing methods on the proposed LF-Edit task.

</details>


### [13] [AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees](https://arxiv.org/abs/2512.04550)
*Yangning Li,Shaoshen Chen,Yinghui Li,Yankai Chen,Hai-Tao Zheng,Hui Wang,Wenhao Jiang,Philip S. Yu*

Main category: cs.CL

TL;DR: 针对大语言模型处理长上下文的效率和语义保持问题，AdmTree提出了一种基于信息密度的自适应层级压缩框架，有效提升上下文表达能力和效率。


<details>
  <summary>Details</summary>
Motivation: 现有上下文压缩方法存在缺陷：显式方法牺牲局部细节，隐式方法存在位置偏差、信息丢失或无法捕捉长距离语义依赖，限制了大语言模型处理长上下文的能力。

Method: 提出AdmTree框架，通过自适应的层级上下文压缩，实现基于信息密度动态分割输入，并利用摘要标记总结变长段落，构建语义二叉树结构，同时引入轻量级聚合机制和冻结的LLM骨干。

Result: AdmTree在保持高语义保真度的同时实现高效上下文层级抽象，有效保留细粒度细节和全局语义一致性，减少位置偏差，动态适应内容，实现长上下文语义信息的稳健保留。

Conclusion: AdmTree能够在不增加大量训练参数的情况下，通过层级语义结构和动态自适应机制，高效且忠实地压缩长上下文，克服现有方法的限制，提升大语言模型处理长文本的能力。

Abstract: The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.

</details>


### [14] [ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning](https://arxiv.org/abs/2512.04555)
*Pritam Kadasi,Abhishek Upperwal,Mayank SIngh*

Main category: cs.CL

TL;DR: ADAPT通过元学习动态调整任务采样比例，优化token预算分配，提升多任务指令微调效果。


<details>
  <summary>Details</summary>
Motivation: 固定任务权重的训练策略难以充分利用有限的token预算，导致训练效率和效果受限，ADAPT旨在通过元学习动态分配训练资源，提升多任务指令微调的性能。

Method: ADAPT通过维护任务的连续采样分布，并利用平滑最大化验证目标的元梯度更新该分布，进而动态调整任务采样比例，实现自适应课程学习。

Result: ADAPT是一种元学习算法，在多任务指令微调中根据明确的token预算动态学习任务采样比例。该方法通过维护任务的连续分布并利用元梯度优化验证目标，实现自适应课程分配更多token到有用任务，避免任务权重固定带来的弊端。实验在三种约10亿参数的开源大模型上进行，在1%、5%、10%的token预算下，训练20种自然指令任务并对11个跨领域基准进行评估。结果显示，ADAPT在减少有效训练token使用的同时，实现了与最佳静态混合策略相当或略优的下游性能，且更倾向分配更多资源给难度较大且与基准相关的任务。

Conclusion: ADAPT能在减少训练token的前提下，匹配或超越最佳静态任务采样，且更加聚焦于关键且困难的任务，实现更优多任务微调表现。

Abstract: We propose ADAPT, a meta-learning algorithm that \emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1\%$, $5\%$, and $10\%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.

</details>


### [15] [LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence](https://arxiv.org/abs/2512.04578)
*Wenjin Liu,Haoran Luo,Xin Feng,Xiang Ji,Lijuan Zhou,Rui Mao,Jiapu Wang,Shirui Pan,Erik Cambria*

Main category: cs.CL

TL;DR: LexGenius是首个面向中文法律的专家级基准，通过系统化评测框架评估大型语言模型的法律智能，揭示当前模型差距，为未来法律通用智能发展提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试倾向结果导向，未能系统评估大型语言模型的法律智能，阻碍法律通用智能发展。

Method: 提出LexGenius基于Dimension-Task-Ability框架，涵盖七个维度、十一项任务和二十种能力，采用最新法律案例和考试题目，结合人工和LLM审核，确保题目准确性和可靠性。

Result: 利用LexGenius评测了12个顶级大型语言模型，发现模型间法律智能能力存在显著差异，且最佳模型仍落后于人类法律专家。

Conclusion: LexGenius有效评估大型语言模型的法律智能能力，发现现有模型不足，推动法律通用智能研究和提升。

Abstract: Legal general intelligence (GI) refers to artificial intelligence (AI) that encompasses legal understanding, reasoning, and decision-making, simulating the expertise of legal experts across domains. However, existing benchmarks are result-oriented and fail to systematically evaluate the legal intelligence of large language models (LLMs), hindering the development of legal GI. To address this, we propose LexGenius, an expert-level Chinese legal benchmark for evaluating legal GI in LLMs. It follows a Dimension-Task-Ability framework, covering seven dimensions, eleven tasks, and twenty abilities. We use the recent legal cases and exam questions to create multiple-choice questions with a combination of manual and LLM reviews to reduce data leakage risks, ensuring accuracy and reliability through multiple rounds of checks. We evaluate 12 state-of-the-art LLMs using LexGenius and conduct an in-depth analysis. We find significant disparities across legal intelligence abilities for LLMs, with even the best LLMs lagging behind human legal professionals. We believe LexGenius can assess the legal intelligence abilities of LLMs and enhance legal GI development. Our project is available at https://github.com/QwenQKing/LexGenius.

</details>


### [16] [Geschlechtsübergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden](https://arxiv.org/abs/2512.04683)
*Carolin Mueller-Spitzer,Samira Ochs,Jan Oliver Ruediger,Sascha Wolfer*

Main category: cs.CL

TL;DR: 本研究通过对大量德语新闻文本中的通用阳性词进行手工标注，揭示了其使用上的词汇差异和语法特征，发现其并非主要用于指代所有人群，且在不同词汇间表现差异显著。


<details>
  <summary>Details</summary>
Motivation: 针对通用阳性词是否真正具备性别中性这一争议，弥补了缺乏基于大规模语料库的实证分析的研究空白。

Method: 通过对21个阳性个人名词的全部词形进行手工标注，共标注6195个词元，分析其在语料库中的分布和用法特点。

Result: 通用阳性词在复数形式和不定名词短语中使用频率较高，且在表现上，消极角色名词和声望相关的个人名词存在明显差异，且其用法并非如之前观点所言主要指代整个群体。

Conclusion: 通用阳性词在实际语料中的使用存在显著的词汇和语法差异，且并非主要用于表示整个群体，这为心理语言学研究提供了更符合真实语言使用的语言材料。

Abstract: This study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.

</details>


### [17] [OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models](https://arxiv.org/abs/2512.04738)
*Zhuoyue Wan,Wentao Hu,Chen Jason Zhang,Yuanfeng Song,Shuaimin Li,Ruiqiang Xiao,Xiao-Yong Wei,Raymond Chi-Wing Wong*

Main category: cs.CL

TL;DR: 本文提出了开放源代码的OsmT模型，通过标签检索增强机制有效链接自然语言与OverpassQL，实现高效准确的查询生成与解释，适应地理空间复杂场景。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案多依赖封闭源大模型，存在高推理成本、透明度低和轻量部署适应性差，亟需开放、轻量且具有高准确性的模型以桥接自然语言和结构化查询语言，尤其是在地理空间数据领域。

Method: 引入Tag Retrieval Augmentation (TRA)机制，将语境相关的标签知识融合入生成过程，捕捉OSM中的层次和关系依赖，并定义了翻译结构化查询为自然语言的逆向任务OverpassQL-to-Text。

Result: 在公开基准测试中，OsmT较强的基线方法显示出持续的提升，且在参数量显著较少的情况下达到了有竞争力的准确率。

Conclusion: OsmT模型有效地桥接了自然语言与OverpassQL结构化查询语言，实现了查询生成与解释的准确性提升，证明了开源预训练语言模型在地理空间复杂环境中的优势。

Abstract: Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.

</details>


### [18] [SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs](https://arxiv.org/abs/2512.04746)
*Wenhua Cheng,Weiwei Zhang,Heng Guo,Haihao Shen*

Main category: cs.CL

TL;DR: SignRoundV2是一种有效的极低位后训练量化框架，通过改进敏感度评估和量化比例尺搜索，显著提升了大型语言模型在2-5位量化下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 极低位量化（如2位和4位）虽能高效部署大型语言模型，但通常导致性能显著下降，急需有效的量化后训练方法以缓解这一问题。

Method: 提出结合梯度信息与量化引起的偏差的快速敏感度度量和轻量级预调节量化比例尺的搜索策略，用于指导层级位宽分配和提高超低位量化效果。

Result: 通过广泛实验证明，SignRoundV2在极低位量化条件下保持了与全精度模型竞争的准确率，4-5位量化时性能波动仅约1%。

Conclusion: SignRoundV2框架在极低位宽量化中实现了接近原始全精度模型的性能，尤其在4至5位和2位量化下表现优秀。

Abstract: Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at https://github.com/intel/auto-round.

</details>


### [19] [Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time](https://arxiv.org/abs/2512.04748)
*Xinyue Kang,Diwei Shi,Li Chen*

Main category: cs.CL

TL;DR: 本文通过引入测试时引导向量（TTSV），无需调整大型语言模型参数，即可显著提升其在特定任务上的推理能力，且具备高效、轻量和良好的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统的测试时适配方法需要调节大型语言模型参数，计算开销大且可能降低模型已有能力。为此，本文提出通过在输入端加入轻量级引导向量，在保持模型参数冻结的同时激活模型推理潜力，从而实现高效且安全的适应。

Method: 本文设计了测试时引导向量（TTSV），其作为输入的一部分被添加至模型前端，通过在测试数据上优化以最小化输出熵，诱导模型进入更高置信度的状态，从而激活模型内在能力。该方法无需调整模型参数，优化过程高效且轻量。

Result: 本文提出了一种名为测试时引导向量（TTSV）的轻量级组件，用于在保持大型语言模型（LLMs）参数冻结的情况下提升其在特定任务上的推理能力。通过在测试数据上优化TTSV以最小化模型输出的熵，模型能够进入更高置信度的内部状态，从而激活其与当前任务最相关的内在能力。实验证明该方法不仅在基础模型和增强推理模型上均表现优异，而且在MATH500任务中显著提升了Qwen系列模型的性能，且具有良好的跨任务泛化能力。

Conclusion: 测试时引导向量（TTSV）是一种高效且轻量的模型调适方法，能够在不修改LLM参数的前提下显著改善模型在任务上的表现，且具备良好的泛化和迁移能力。

Abstract: It is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model's pre-existing abilities.To address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM's parameters entirely frozen. By optimizing the TTSV on test data to minimize the model's output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach's effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.

</details>


### [20] [EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](https://arxiv.org/abs/2512.04753)
*Ruilin Li,Yibin Wang,Wenhong Zhu,Chenglin Li,Jinghao Zhang,Chenliang Li,Junchi Yan,Jiaqi Wang*

Main category: cs.CL

TL;DR: 本文分析了当前大语言模型知识编辑在实际应用中的不足，提出了结合局部微调与轨迹级策略优化的Edit-then-Consolidate方法，有效提升知识编辑的实用性与稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有针对大语言模型知识编辑的方法在教师强制的受控评估上效果较好，但在真实终身学习场景中表现弱，主要因过拟合新事实和缺乏知识整合阶段，导致知识和生成行为不匹配。

Method: 提出了一种新的知识编辑范式——Edit-then-Consolidate，结合Targeted Proximal Supervised Fine-Tuning (TPSFT)以局部限制策略漂移防止过拟合，并通过Group Relative Policy Optimization (GRPO)进行知识整合，优化基于轨迹的推理行为。

Result: 大量实验证明，Edit-then-Consolidate框架在真实世界评估中提升了编辑的可靠性和泛化能力，同时较好地保持了编辑的局部性及预训练模型的能力。

Conclusion: 本论文提出的Edit-then-Consolidate方法有效解决了现有知识编辑方法在真实终身学习场景中表现不佳的问题，显著提升了编辑的可靠性和泛化能力，同时避免了对预训练能力的破坏。

Abstract: Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing evaluations and their real-world effectiveness in lifelong learning scenarios, which greatly limits their practical applicability. This work's empirical analysis reveals two recurring issues associated with this gap: (1) Most traditional methods lead the edited model to overfit to the new fact, thereby degrading pre-trained capabilities; (2) There is a critical absence of a knowledge consolidation stage, leaving new facts insufficiently integrated into LLMs' inference-time behavior under autoregressive generation, thereby leading to a mismatch between parametric knowledge and actual generation behavior. To this end, we propose Edit-then-Consolidate, a novel knowledge editing paradigm that aims to bridge the gap between theoretical knowledge editing methods and their real-world applicability. Specifically, (1) our framework mitigates overfitting via Targeted Proximal Supervised Fine-Tuning (TPSFT) that localizes the edit via a trust-region objective to limit policy drift; (2) Then, a consolidation stage using Group Relative Policy Optimization (GRPO) aligns the edited knowledge with CoT-based inference policy by optimizing trajectory-level behavior under comprehensive reward signals. Extensive experiments demonstrate our framework consistently improves editing reliability and generalization under real-world evaluations, while better preserving locality and pre-trained capabilities.

</details>


### [21] [Challenging the Abilities of Large Language Models in Italian: a Community Initiative](https://arxiv.org/abs/2512.04759)
*Malvina Nissim,Danilo Croce,Viviana Patti,Pierpaolo Basile,Giuseppe Attanasio,Elio Musacchio,Matteo Rinaldi,Federico Borazio,Maria Francis,Jacopo Gili,Daniel Scalena,Begoña Altuna,Ekhi Azurmendi,Valerio Basile,Luisa Bentivogli,Arianna Bisazza,Marianna Bolognesi,Dominique Brunato,Tommaso Caselli,Silvia Casola,Maria Cassese,Mauro Cettolo,Claudia Collacciani,Leonardo De Cosmo,Maria Pia Di Buono,Andrea Esuli,Julen Etxaniz,Chiara Ferrando,Alessia Fidelangeli,Simona Frenda,Achille Fusco,Marco Gaido,Andrea Galassi,Federico Galli,Luca Giordano,Mattia Goffetti,Itziar Gonzalez-Dios,Lorenzo Gregori,Giulia Grundler,Sandro Iannaccone,Chunyang Jiang,Moreno La Quatra,Francesca Lagioia,Soda Marem Lo,Marco Madeddu,Bernardo Magnini,Raffaele Manna,Fabio Mercorio,Paola Merlo,Arianna Muti,Vivi Nastase,Matteo Negri,Dario Onorati,Elena Palmieri,Sara Papi,Lucia Passaro,Giulia Pensa,Andrea Piergentili,Daniele Potertì,Giovanni Puccetti,Federico Ranaldi,Leonardo Ranaldi,Andrea Amelio Ravelli,Martina Rosola,Elena Sofia Ruzzetti,Giuseppe Samo,Andrea Santilli,Piera Santin,Gabriele Sarti,Giovanni Sartor,Beatrice Savoldi,Antonio Serino,Andrea Seveso,Lucia Siciliani,Paolo Torroni,Rossella Varvara,Andrea Zaninello,Asya Zanollo,Fabio Massimo Zanzotto,Kamyar Zeinalipour,Andrea Zugarini*

Main category: cs.CL

TL;DR: CALAMITA是针对意大利语的大规模、多任务语言模型评测项目，提出了细粒度指标和统一评测流程，推动了更全面和可持续的模型评估。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型（LLMs）的系统性评估主要集中在英语，其他语言尤其是意大利语的评估尚显不足。

Method: CALAMITA联合多个领域专家设计多样任务，建立统一评测管线，采用细粒度、多维度指标对LLM进行系统评估。

Result: CALAMITA组织了80余名来自学术界、工业界和公共部门的合作，构建了涵盖20多项任务和近100个子任务的意大利语多任务基准，并构建了集中化的评测流程，支持异构数据集和指标。实验显示4个开源LLM在多个能力上的系统性强弱并揭示了任务特异性评估挑战。

Conclusion: CALAMITA作为一个滚动基准和社区驱动框架，提供了意大利语最全面的评测基准，并为多语言社区提供了包容且严谨的LLM评估蓝图。

Abstract: The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. "Challenging the Abilities of LAnguage Models in ITAlian" (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource -- the most comprehensive and diverse benchmark for Italian to date -- and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.

</details>


### [22] [AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages](https://arxiv.org/abs/2512.04765)
*Pooja Singh,Sandeep Kumar*

Main category: cs.CL

TL;DR: AdiBhashaa通过社区驱动方式为印度四种少数民族语言开发了开放语料库和机器翻译模型，促进语言技术公平和社区赋能。


<details>
  <summary>Details</summary>
Motivation: 许多少数民族语言在大型语言模型和多语言翻译系统中不可见，导致结构性不平等加剧。

Method: 结合参与式数据创建、本地母语者参与、人工审校流程以及系统评估多种机器翻译模型。

Result: 成功构建了Bhili、Mundari、Gondi和Santali四种印度部落语言的首个开放平行语料库和基线机器翻译系统。

Conclusion: AdiBhashaa项目展示了通过社区驱动和本地专家参与，构建少数民族语言的机器翻译系统的可能路径，促进语言技术的公平发展。

Abstract: Large language models and multilingual machine translation (MT) systems increasingly drive access to information, yet many languages of the tribal communities remain effectively invisible in these technologies. This invisibility exacerbates existing structural inequities in education, governance, and digital participation. We present AdiBhashaa, a community-driven initiative that constructs the first open parallel corpora and baseline MT systems for four major Indian tribal languages-Bhili, Mundari, Gondi, and Santali. This work combines participatory data creation with native speakers, human-in-the-loop validation, and systematic evaluation of both encoder-decoder MT models and large language models. In addition to reporting technical findings, we articulate how AdiBhashaa illustrates a possible model for more equitable AI research: it centers local expertise, builds capacity among early-career researchers from marginalized communities, and foregrounds human validation in the development of language technologies.

</details>


### [23] [DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors](https://arxiv.org/abs/2512.04799)
*Gianluca Barmina,Nathalie Carmen Hau Norman,Peter Schneider-Kamp,Lukas Galke*

Main category: cs.CL

TL;DR: 针对丹麦语，我们设计了一个包含14种错误类型的语言接受度评测基准，提升了评测难度和区分能力，更全面评估大型语言模型的语言理解水平。


<details>
  <summary>Details</summary>
Motivation: 现有的丹麦语语言接受度基准测试范围有限，无法充分评估大型语言模型在语言理解和判断上的能力，因此需要一个更广泛且综合的基准。

Method: 基于对书面丹麦语中常见错误的分析，我们设计了14种系统引入错误的腐败函数，并通过人工和自动方法验证其准确性，接着这些生成的错误句子作为评测基准使用。

Result: 我们构造的基准测试涵盖了更多样的错误类型，导致大型语言模型的表现下降，显示任务难度增加，同时更有效区分模型性能差异。

Conclusion: 我们提出的基准测试通过引入更多种类的语言错误，显著提升了语言接受度评估的难度和区分能力，能够更准确地区分表现优异和表现较差的大型语言模型。

Abstract: We present an enhanced benchmark for evaluating linguistic acceptability in Danish. We first analyze the most common errors found in written Danish. Based on this analysis, we introduce a set of fourteen corruption functions that generate incorrect sentences by systematically introducing errors into existing correct Danish sentences. To ensure the accuracy of these corruptions, we assess their validity using both manual and automatic methods. The results are then used as a benchmark for evaluating Large Language Models on a linguistic acceptability judgement task. Our findings demonstrate that this extension is both broader and more comprehensive than the current state of the art. By incorporating a greater variety of corruption types, our benchmark provides a more rigorous assessment of linguistic acceptability, increasing task difficulty, as evidenced by the lower performance of LLMs on our benchmark compared to existing ones. Our results also suggest that our benchmark has a higher discriminatory power which allows to better distinguish well-performing models from low-performing ones.

</details>


### [24] [DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution](https://arxiv.org/abs/2512.04838)
*L. D. M. S. Sai Teja,N. Siva Gopala Krishna,Ufaq Khan,Muhammad Haris Khan,Partha Pakray,Atul Mishra*

Main category: cs.CL

TL;DR: 本文提出了一种名为Info-Mask的框架，用于检测混合人类与AI文本的作者转换点，通过整合文体特征、困惑度信号和结构化边界建模，实现对混合作者内容的准确分割。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型时代，人类与AI生成文本界限日益模糊，准确识别作者转换点对真实性、信任及监管至关重要，故本文旨在解决混合作者文本分割的挑战。

Method: 本文设计了Info-Mask框架，结合文体学特征、基于困惑度的信号以及结构化的边界建模方法，构建了一个新型的混合文本分割系统。

Result: Info-Mask在构建的对抗性测试集MAS上表现优异，显著提升了分割的抗干扰性，并通过人机研究验证了其可解释性；同时也揭示了该领域仍存在的许多挑战。

Conclusion: Info-Mask在多种架构下显著提升了混合作者文本分割的鲁棒性和准确性，并通过人机可解释的特征分析增强了预测的透明度，推动了混合作者文本检测领域的发展。

Abstract: In the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-versa, a problem with critical implications for authenticity, trust, and human oversight. We introduce a novel framework, called Info-Mask for mixed authorship detection that integrates stylometric cues, perplexity-driven signals, and structured boundary modeling to accurately segment collaborative human-AI content. To evaluate the robustness of our system against adversarial perturbations, we construct and release an adversarial benchmark dataset Mixed-text Adversarial setting for Segmentation (MAS), designed to probe the limits of existing detectors. Beyond segmentation accuracy, we introduce Human-Interpretable Attribution (HIA overlays that highlight how stylometric features inform boundary predictions, and we conduct a small-scale human study assessing their usefulness. Across multiple architectures, Info-Mask significantly improves span-level robustness under adversarial conditions, establishing new baselines while revealing remaining challenges. Our findings highlight both the promise and limitations of adversarially robust, interpretable mixed-authorship detection, with implications for trust and oversight in human-AI co-authorship.

</details>


### [25] [Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates](https://arxiv.org/abs/2512.04844)
*Atsuki Yamaguchi,Terufumi Morishita,Aline Villavicencio,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 提出了一种在仅使用无标注目标语言数据条件下，适应指令大语言模型（LLMs）的方法，以解决语言适应中因遗忘导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 为了促进大语言模型的全球可访问性，亟需在低资源环境下实现对多语言的适应，避免昂贵的标注数据需求和适应过程中的能力遗忘。

Method: 提出Source-Shielded Updates（SSU），利用少量源语言数据和参数重要性评分，识别关键参数并采用逐列冻结策略，保护这些参数防止遗忘，实现仅用无标注目标语言数据的有效适应。

Result: SSU在5种语言和7B、13B模型上测试，将源语言任务性能退化控制在3%左右，远优于全微调的20%以上；同时在目标语言性能上超越或接近全微调，表现更为稳健。

Conclusion: SSU通过选择性更新参数，有效保护了模型原有源语言能力，显著减轻灾难性遗忘现象，且在多语言和不同规模模型上表现优异，保持了目标语言的高性能。

Abstract: Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.

</details>


### [26] [SEAL: Self-Evolving Agentic Learning for Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2512.04868)
*Hao Wang,Jialun Zhong,Changcheng Wang,Zhujun Nie,Zheng Li,Shunyu Yao,Yanzeng Li,Xinchi Li*

Main category: cs.CL

TL;DR: 本文提出了一种新型两阶段语义解析框架SEAL，通过自我进化代理学习显著提升了知识驱动对话问答的结构准确性和推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有知识驱动对话问答方法在解决共指问题、上下文依赖建模和复杂逻辑推理方面存在结构不准确和计算成本高的问题，尤其是在大规模知识图谱上的复杂查询。

Method: 提出了SEAL，一种基于自我进化代理学习的两阶段语义解析框架。第一阶段由大型语言模型提取最小S表达式核心，并用代理校准模块修正语法和对齐知识图谱实体关系；第二阶段通过模板完成构建可执行S表达式，同时结合问题类型预测和占位符实例化。

Result: SEAL在SPICE基准测试上达到了先进水平，特别是在多跳推理、比较和聚合任务中，显著提升了结构准确性和计算效率。

Conclusion: SEAL有效解决了复杂问答中的结构和效率问题，展现出强大的鲁棒性和扩展性，适合大规模知识图谱上的对话推理任务。

Abstract: Knowledge-based conversational question answering (KBCQA) confronts persistent challenges in resolving coreference, modeling contextual dependencies, and executing complex logical reasoning. Existing approaches, whether end-to-end semantic parsing or stepwise agent-based reasoning, often suffer from structural inaccuracies and prohibitive computational costs, particularly when processing intricate queries over large knowledge graphs. To address these limitations, we introduce SEAL, a novel two-stage semantic parsing framework grounded in self-evolving agentic learning. In the first stage, a large language model (LLM) extracts a minimal S-expression core that captures the essential semantics of the input query. This core is then refined by an agentic calibration module, which corrects syntactic inconsistencies and aligns entities and relations precisely with the underlying knowledge graph. The second stage employs template-based completion, guided by question-type prediction and placeholder instantiation, to construct a fully executable S-expression. This decomposition not only simplifies logical form generation but also significantly enhances structural fidelity and linking efficiency. Crucially, SEAL incorporates a self-evolving mechanism that integrates local and global memory with a reflection module, enabling continuous adaptation from dialog history and execution feedback without explicit retraining. Extensive experiments on the SPICE benchmark demonstrate that SEAL achieves state-of-the-art performance, especially in multi-hop reasoning, comparison, and aggregation tasks. The results validate notable gains in both structural accuracy and computational efficiency, underscoring the framework's capacity for robust and scalable conversational reasoning.

</details>


### [27] [LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics](https://arxiv.org/abs/2512.04957)
*Weiye Shi,Zhaowei Zhang,Shaoheng Yan,Yaodong Yang*

Main category: cs.CL

TL;DR: 本文通过多语言数据集和丰富的语言特征评估大型语言模型学习深层语言属性的能力，发现模型需结合更复杂的语言信号提升性能。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否能够从原始文本中有效学习更深层次的语言学特征，如句法结构、语音线索和韵律模式，并将其应用于自然语言相关任务。

Method: 构建了一个多语言的类别分类数据集，包含六种语言和三种语言特征（句法树结构、隐喻计数、语音指标），通过比较原始文本与显式特征融合的分类效果来评估模型。

Result: 实验结果表明，LLM可以从原始文本或显式语言特征中学习潜在的语言结构，但不同语言特征对不同分类任务的贡献不均。

Conclusion: 大型语言模型能够捕捉潜在的语言结构特征，但不同语言特征在不同任务中的贡献存在差异，因此训练时需纳入更复杂的语言信号。

Abstract: Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.

</details>


### [28] [Nex-N1: Agentic Models Trained via a Unified Ecosystem for Large-Scale Environment Construction](https://arxiv.org/abs/2512.04987)
*Nex-AGI Team,:,Yuxuan Cai,Lu Chen,Qiaoling Chen,Yuyang Ding,Liwen Fan,Wenjie Fu,Yufei Gao,Honglin Guo,Pinxue Guo,Zhenhua Han,Zhengfu He,Hanglei Hu,Kai Hu,Shengjia Hua,Tianyu Huai,Baodai Huang,Li Ji,Zhen Jiang,Zhikai Lei,Bufan Li,Jiahang Lin,Lizhi Lin,Jinxiu Liu,Shichun Liu,Ziming Liu,Yuchen Ni,Pengfang Qian,Yujiong Shen,Qingyun Shi,Wentao Shu,Peng Sun,Yiran Suo,Tian Tang,Boyu Tian,Guoteng Wang,Junzhe Wang,Peixin Wang,Zhiheng Xi,Hang Yan,Jie Yang,Zhixiong Yang,Tianchu Yao,Guangze Ye,Qianxi Yu,Shuo Zhang,Xinyue Zhang,Yiqi Zhang,Jiarong Zhao,Miao Zheng,Rui Zheng,Enyu Zhou,Jiazheng Zhou,Maosen Zhou,Yuhao Zhou,Tao Gui,Yining Zheng,Xinchi Chen,Jie Zhou,Siyuan Feng,Qin Chen,Liang He,Qi Zhang,Xuanjing Huang,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出了一个多维度扩展交互环境的方法，训练出的Nex-N1模型在复杂智能体任务表现优异，并已开源生态系统及模型。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型向自主智能体发展，传统静态模仿学习已无法满足需求，缺乏可扩展的高质量交互信号建设基础设施，阻碍了政策学习效果的提升，因此需要系统方法扩展交互环境的多样性和复杂性。

Method: 提出了基于三维度的环境扩展方法：通过NexAU框架实现复杂智能体层级构建，利用NexA4A自动生成多样智能体层级，以自然语言覆盖无限领域，结合NexGAP动态现实环境缩小模拟与现实差距，基于构建环境训练Nex-N1模型。

Result: 该论文提出了一个系统的方法用于构建多样且复杂的交互环境，从而提升大语言模型从被动响应转向自主智能体的政策学习能力。该方法通过三个维度实现环境扩展：（1）复杂性：NexAU框架支持通过简单配置构建复杂智能体层级；（2）多样性：NexA4A能基于自然语言自动生成多样智能体层级，覆盖无限领域；（3）逼真性：NexGAP结合动态现实环境以生成真实轨迹，缩小模拟与现实差距。基于此基础，训练得到的Nex-N1模型在SWE-bench和tau2等基准测试中，优于当前开源模型并与顶尖闭源模型表现接近。该生态系统及模型权重已开源，有助于相关领域研究发展。

Conclusion: 通过构建复杂多样且高逼真度的交互环境，Nex-N1模型在复杂任务中表现超越现有开源模型，并可媲美顶尖闭源模型，显著推动了大语言模型向自主智能体转型的研究。

Abstract: The evolution of Large Language Models (LLMs) from passive responders to autonomous agents necessitates a fundamental shift in learning paradigms -- from static imitation to incentive-driven decision making. However, this transition is significantly impeded by the lack of scalable infrastructure capable of constructing high-quality interaction signals for effective policy learning. To address this, we introduce a comprehensive method designed to systematically scale the diversity and complexity of interactive environments. Our method realizes this scaling by addressing three orthogonal dimensions: (1) Complexity: NexAU, a flexible agent framework that supports building complex agent hierarchies via simple configurations; (2) Diversity: NexA4A automatically generates diverse agent hierarchies from natural language to cover infinite domains; and (3) Fidelity: NexGAP bridges the simulation-reality gap by integrating dynamic real-world environment for grounded trajectories synthesis. We train Nex-N1 upon the diverse and complex interactive environments established by our infrastructure. Empirical results on benchmarks such as SWE-bench and tau2 demonstrate that Nex-N1 consistently outperforms SOTA open-source models and achieves competitive performance against frontier proprietary models on complex agentic tasks. We open-source the Nex ecosystem and model weights to facilitate further research.

</details>


### [29] [Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking](https://arxiv.org/abs/2512.05012)
*Francielle Vargas,Daniel Pedronette*

Main category: cs.CL

TL;DR: 提出了一种基于对比学习和逐字归因的自解释证据再排序方法，提高了检索准确性和透明度，增强对安全关键领域的可靠支持。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域提升信息检索的准确性与透明度，减少基于生成模型的幻觉风险，确保系统能基于事实证据做出可靠判断。

Method: 通过对嵌入向量进行对比学习微调，并结合基于主观性的难负样本自动筛选，生成逐字归因的解释理由，实现事实证据驱动的检索和再排序。

Result: 本文提出了一种新的方法——自解释对比证据再排序（CER），通过对嵌入进行对比学习微调，并生成每个检索段落的逐字归因理由，围绕事实证据重构信息检索。利用基于主观性的标准自动选择难负样本，促使模型拉近事实依据的嵌入，同时排斥主观或误导性解释，进而构建与证据推理明确对齐的嵌入空间。实验在临床试验报告数据上进行，结果显示CER提升了检索准确性，降低了RAG系统产生幻觉的风险，并增强了检索过程的透明度和基于证据的可靠性，尤其适用于安全关键领域。

Conclusion: CER方法有效提升了检索准确性与可靠性，减少了生成式模型的幻觉风险，且通过逐字归因提升了结果的透明度，适合应用于安全要求高的临床等领域。

Abstract: This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.

</details>


### [30] [Arbitrage: Efficient Reasoning via Advantage-Aware Speculation](https://arxiv.org/abs/2512.05033)
*Monishwaran Maheswaran,Rishabh Tiwari,Yuezhou Hu,Kerem Dilmen,Coleman Hooper,Haocheng Xi,Nicholas Lee,Mehrdad Farajtabar,Michael W. Mahoney,Kurt Keutzer,Amir Gholami*

Main category: cs.CL

TL;DR: 针对推测解码中语义等价步骤的多余拒绝问题，本文提出了动态路由的Arbitrage框架，显著提升推理效率，降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法在数学推理任务中因语义等价但文本不匹配的步骤被不必要拒绝，导致重复生成浪费目标模型计算资源，亟需提升性能与计算成本比的新框架。

Method: 方法核心是一个轻量级路由器用于动态选择摘要模型或目标模型生成步骤，训练此路由器以预测目标模型是否会生成更高质量的步骤，从而近似一个理想的Arbitrage Oracle，实现最佳性能和准确率。

Result: 本文提出了一种名为Arbitrage的新型步级推测生成框架，通过动态路由方法在摘要模型和目标模型之间选择生成步骤，从而在数学推理任务中实现了推理速度提升和准确率保持的平衡。实验证明该方法相比传统步级推测解码技术，在保证准确性的同时，将推理延迟缩短了约2倍。

Conclusion: Arbitrage框架通过训练轻量路由器预测何时使用目标模型生成更优步骤，优化了效能和准确度的权衡，实验证明其优于现有步级推测解码方法。

Abstract: Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.

</details>


### [31] [Structured Document Translation via Format Reinforcement Learning](https://arxiv.org/abs/2512.05100)
*Haiyue Song,Johannes Eschbach-Dymanus,Hour Kaing,Sumire Honda,Hideki Tanaka,Bianka Buschbeck,Masao Utiyama*

Main category: cs.CL

TL;DR: 提出FormatRL利用强化学习优化结构感知奖励，提高复杂文档结构的翻译效果。


<details>
  <summary>Details</summary>
Motivation: 现有结构化文本翻译仅限于句子层面，难以有效处理复杂的文档级XML或HTML结构。

Method: 提出了Format Reinforcement Learning (FormatRL)，在监督微调模型基础上采用Group Relative Policy Optimization，优化新的结构感知奖励函数，包括TreeSim和Node-chrF，并引入细粒度指标StrucAUC。

Result: 在SAP软件文档基准测试中，FormatRL在六个指标上均取得提升，分析显示不同奖励函数均能增强结构和翻译质量。

Conclusion: FormatRL有效提升了文档级结构化文本翻译的质量，结构相似性和节点层面翻译质量均有改进。

Abstract: Recent works on structured text translation remain limited to the sentence level, as they struggle to effectively handle the complex document-level XML or HTML structures. To address this, we propose \textbf{Format Reinforcement Learning (FormatRL)}, which employs Group Relative Policy Optimization on top of a supervised fine-tuning model to directly optimize novel structure-aware rewards: 1) TreeSim, which measures structural similarity between predicted and reference XML trees and 2) Node-chrF, which measures translation quality at the level of XML nodes. Additionally, we apply StrucAUC, a fine-grained metric distinguishing between minor errors and major structural failures. Experiments on the SAP software-documentation benchmark demonstrate improvements across six metrics and an analysis further shows how different reward functions contribute to improvements in both structural and translation quality.

</details>


### [32] [Semantic Soft Bootstrapping: Long Context Reasoning in LLMs without Reinforcement Learning](https://arxiv.org/abs/2512.05105)
*Purbesh Mitra,Sennur Ulukus*

Main category: cs.CL

TL;DR: 本文提出了一种无需人工干预的自蒸馏训练方法SSB，通过语义上下文提升大型语言模型在数学推理任务的表现，相较于传统强化学习方法显著提高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在推理训练中依赖强化学习方法（RLVR），但存在奖励稀疏和样本利用率低等瓶颈，导致训练资源消耗大。

Method: 提出了语义软自举（Semantic Soft Bootstrapping，SSB）自蒸馏技术，利用相同模型充当教师和学生，通过筛选正确及常见错误答案并结合语义上下文，引导模型生成更稳健的推理步骤和正确答案，自动生成配对训练集，无需人工干预。

Result: 在GSM8K数据集上，基于Qwen2.5-3B模型进行参数高效微调后，在MATH500和AIME2024基准上分别比常用RLVR算法GRPO提升了10.6%和10%的准确率。

Conclusion: SSB方法有效克服了传统RLVR的密集奖励缺失和样本效率低问题，提高了推理任务的准确性并减少了训练资源需求。

Abstract: Long context reasoning in large language models (LLMs) has demonstrated enhancement of their cognitive capabilities via chain-of-thought (CoT) inference. Training such models is usually done via reinforcement learning with verifiable rewards (RLVR) in reasoning based problems, like math and programming. However, RLVR is limited by several bottlenecks, such as, lack of dense reward, and inadequate sample efficiency. As a result, it requires significant compute resources in post-training phase. To overcome these limitations, in this work, we propose \textbf{Semantic Soft Bootstrapping (SSB)}, a self-distillation technique, in which the same base language model plays the role of both teacher and student, but receives different semantic contexts about the correctness of its outcome at training time. The model is first prompted with a math problem and several rollouts are generated. From them, the correct and most common incorrect response are filtered, and then provided to the model in context to produce a more robust, step-by-step explanation with a verified final answer. This pipeline automatically curates a paired teacher-student training set from raw problem-answer data, without any human intervention. This generation process also produces a sequence of logits, which is what the student model tries to match in the training phase just from the bare question alone. In our experiment, Qwen2.5-3B-Instruct on GSM8K dataset via parameter-efficient fine-tuning. We then tested its accuracy on MATH500, and AIME2024 benchmarks. Our experiments show a jump of 10.6%, and 10% improvements in accuracy, respectively, over group relative policy optimization (GRPO), which is a commonly used RLVR algorithm. Our code is available at https://github.com/purbeshmitra/semantic-soft-bootstrapping, and the model, curated dataset is available at https://huggingface.co/purbeshmitra/semantic-soft-bootstrapping.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [33] [Retrieval-Augmented Few-Shot Prompting Versus Fine-Tuning for Code Vulnerability Detection](https://arxiv.org/abs/2512.04106)
*Fouad Trad,Ali Chehab*

Main category: cs.SE

TL;DR: 本文通过检索增强的少样本提示提升大语言模型在代码漏洞检测任务中的表现，在保证性能的同时节省了训练成本。


<details>
  <summary>Details</summary>
Motivation: 探讨提升大语言模型在代码漏洞检测领域少样本提示效果的方法，解决复杂领域中示例选择和质量对性能影响的问题。

Method: 采用检索增强提示策略，结合语义相似示例进行少样本提示，并与随机示例少样本提示和基于检索的标签分配三种方法进行系统评估，使用Gemini-1.5-Flash模型在多种基线下进行比较。

Result: 检索增强提示在20个样本时达到了74.05%的F1得分和83.90%的部分匹配准确率，显著优于随机少样本提示和基于检索的标签分配，也超过了零样本提示和微调后的Gemini模型，但低于微调后的CodeBERT。

Conclusion: 检索增强少样本提示在代码漏洞检测任务中表现优异，兼顾性能和计算资源消耗，避免了昂贵的微调过程，适合复杂领域的实际应用。

Abstract: Few-shot prompting has emerged as a practical alternative to fine-tuning for leveraging the capabilities of large language models (LLMs) in specialized tasks. However, its effectiveness depends heavily on the selection and quality of in-context examples, particularly in complex domains. In this work, we examine retrieval-augmented prompting as a strategy to improve few-shot performance in code vulnerability detection, where the goal is to identify one or more security-relevant weaknesses present in a given code snippet from a predefined set of vulnerability categories. We perform a systematic evaluation using the Gemini-1.5-Flash model across three approaches: (1) standard few-shot prompting with randomly selected examples, (2) retrieval-augmented prompting using semantically similar examples, and (3) retrieval-based labeling, which assigns labels based on retrieved examples without model inference. Our results show that retrieval-augmented prompting consistently outperforms the other prompting strategies. At 20 shots, it achieves an F1 score of 74.05% and a partial match accuracy of 83.90%. We further compare this approach against zero-shot prompting and several fine-tuned models, including Gemini-1.5-Flash and smaller open-source models such as DistilBERT, DistilGPT2, and CodeBERT. Retrieval-augmented prompting outperforms both zero-shot (F1 score: 36.35%, partial match accuracy: 20.30%) and fine-tuned Gemini (F1 score: 59.31%, partial match accuracy: 53.10%), while avoiding the training time and cost associated with model fine-tuning. On the other hand, fine-tuning CodeBERT yields higher performance (F1 score: 91.22%, partial match accuracy: 91.30%) but requires additional training, maintenance effort, and resources.

</details>


### [34] [HAI-Eval: Measuring Human-AI Synergy in Collaborative Coding](https://arxiv.org/abs/2512.04111)
*Hanjun Luo,Chiming Ni,Jiaheng Wen,Zhimu Huang,Yiran Wang,Bingduo Liao,Sylvia Chung,Yingbin Jin,Xinfeng Li,Wenyuan Xu,XiaoFeng Wang,Hanan Salam*

Main category: cs.SE

TL;DR: HAI-Eval提出了衡量人机协同编码的新基准，通过协作问题验证人机合作能显著提高编程效率，建立了AI时代开发者能力评估的新框架。


<details>
  <summary>Details</summary>
Motivation: 现有评估体系无法反映人机协同编码的场景，传统测试关注算法问题，忽略人机合作在复杂背景下的必要性和效率。

Method: 设计了45个协作必需问题模板，动态生成任务，提供标准化IDE和可复现工具包，进行45人参与的实验，与5种先进LLM在4种人类干预程度下对比测试。

Result: 独立LLM和独立人类的通过率较低（0.67%和18.89%），而人机协作通过率显著提升至31.11%，揭示了新兴的共推理伙伴关系。

Conclusion: HAI-Eval基于协作必需问题模板，成功构建了衡量人机协同编程的统一基准，证明了人机协作显著提升编程性能，挑战了传统人机等级关系。

Abstract: LLM-powered coding agents are reshaping the development paradigm. However, existing evaluation systems, neither traditional tests for humans nor benchmarks for LLMs, fail to capture this shift. They remain focused on well-defined algorithmic problems, which excludes problems where success depends on human-AI collaboration. Such collaborative problems not only require human reasoning to interpret complex contexts and guide solution strategies, but also demand AI efficiency for implementation. To bridge this gap, we introduce HAI-Eval, a unified benchmark designed to measure the synergy of human-AI partnership in coding. HAI-Eval's core innovation is its "Collaboration-Necessary" problem templates, which are intractable for both standalone LLMs and unaided humans, but solvable through effective collaboration. Specifically, HAI-Eval uses 45 templates to dynamically create tasks. It also provides a standardized IDE for human participants and a reproducible toolkit with 450 task instances for LLMs, ensuring an ecologically valid evaluation. We conduct a within-subject study with 45 participants and benchmark their performance against 5 state-of-the-art LLMs under 4 different levels of human intervention. Results show that standalone LLMs and unaided participants achieve poor pass rates (0.67% and 18.89%), human-AI collaboration significantly improves performance to 31.11%. Our analysis reveals an emerging co-reasoning partnership. This finding challenges the traditional human-tool hierarchy by showing that strategic breakthroughs can originate from either humans or AI. HAI-Eval establishes not only a challenging benchmark for next-generation coding agents but also a grounded, scalable framework for assessing core developer competencies in the AI era. Our benchmark and interactive demo will be openly accessible.

</details>


### [35] [Reusing Model Validation Methods for the Continuous Validation of Digital Twins of Cyber-Physical Systems](https://arxiv.org/abs/2512.04117)
*Joost Mertens,Joachim Denil*

Main category: cs.SE

TL;DR: 本文提出了一种利用验证指标检测孪生系统异常的通用方法，并通过港口龙门吊的案例展示其效果，同时通过参数估计纠正数字孪生的错误。


<details>
  <summary>Details</summary>
Motivation: 物理系统在运行过程中会发生变化（维护、磨损或人为错误），导致静态数字孪生模型失真，需及时检测并同步更新数字孪生。

Method: 利用模型验证技术和验证指标检测数字孪生与物理系统间的行为偏差，并基于历史数据通过参数估计校正数字孪生模型。

Result: 提出的验证指标方法成功检测出孪生系统中的异常，并在港口龙门吊案例中验证了通过参数估计纠正数字孪生模型误差的有效性。

Conclusion: 通过验证指标检测孪生系统异常，结合参数估计纠正数字孪生错误，实现了数字孪生模型与物理系统同步演化，提升了模型的代表性和可靠性。

Abstract: One of the challenges in twinned systems is ensuring the digital twin remains a valid representation of the system it twins. Depending on the type of twinning occurring, it is either trivial, such as in dashboarding/visualizations that mirror the system with real-time data, or challenging, in case the digital twin is a simulation model that reflects the behavior of a physical twinned system. The challenge in this latter case comes from the fact that in contrast to software systems, physical systems are not immutable once deployed, but instead they evolve through processes like maintenance, wear and tear or user error. It is therefore important to detect when changes occur in the physical system to evolve the twin alongside it. We employ and reuse validation techniques from model-based design for this goal. Model validation is one of the steps used to gain trust in the representativeness of a simulation model. In this work, we provide two contributions: (i) we provide a generic approach that, through the use of validation metrics, is able to detect anomalies in twinned systems, and (ii) we demonstrate these techniques with the help of an academic yet industrially relevant case study of a gantry crane such as found in ports. Treating anomalies also means correcting the error in the digital twin, which we do with a parameter estimation based on the historical data.

</details>


### [36] [DrP: Meta's Efficient Investigations Platform at Scale](https://arxiv.org/abs/2512.04250)
*Shubham Somani,Vanish Talwar,Madhura Parikh,Eduardo Hernandez,Jimmy Wang,Shreya Shah,Chinmay Gandhi,Sanjay Sundarajan,Neeru Sharma,Srikanth Kamath,Nitin Gupta,Benjamin Renard,Ohad Yahalom,Chris Davis*

Main category: cs.SE

TL;DR: 本文介绍了Meta开发的DrP自动化调查系统，显著降低事故解决时间和工程师负担，已大规模投入生产使用。


<details>
  <summary>Details</summary>
Motivation: 传统的人工调查或依赖临时脚本导致调查效率低下，增加了故障解决时间和工程师的工作负担。

Method: 提出并实现了DrP，一个端到端的自动调查框架，包括灵活的SDK用于编写调查剧本、可扩展的后端执行系统、集成到主流工作流的插件以及后处理系统执行缓解措施。

Result: DrP已在Meta大规模部署，覆盖300+团队，2000+分析器，每日执行5万次自动分析，平均MTTR降低20%，部分团队降低超过80%，显著提升了值班生产力。

Conclusion: DrP框架通过自动化调查流程显著降低了大规模系统事故的平均解决时间（MTTR）和减少了值班工程师的劳动强度。

Abstract: Investigations are a significant step in the operational workflows for large scale systems across multiple domains such as services, data, AI/ML, mobile. Investigation processes followed by on-call engineers are often manual or rely on ad-hoc scripts. This leads to inefficient investigations resulting in increased time to mitigate and isolate failures/SLO violations. It also contributes to on-call toil and poor productivity leading to multiple hours/days spent in triaging/debugging incidents. In this paper, we present DrP, an end-to-end framework and system to automate investigations that reduces the mean time to resolve incidents (MTTR) and reduces on-call toil. DrP consists of an expressive and flexible SDK to author investigation playbooks in code (called analyzers), a scalable backend system to execute these automated playbooks, plug-ins to integrate playbooks into mainstream workflows such as alerts and incident management tools, and a post-processing system to take actions on investigations including mitigation steps.
  We have implemented and deployed DrP at large scale at Meta covering 300+ teams, 2000+ analyzers, across a large set of use cases across domains such as services, core infrastructure, AI/ML, hardware, mobile. DrP has been running in production for the past 5 years and executes 50K automated analyses per day. Overall, our results and experience show that DrP has been able to reduce average MTTR by 20 percent at large scale (with over 80 percent for some teams) and has significantly improved on-call productivity.

</details>


### [37] [On the Role and Impact of GenAI Tools in Software Engineering Education](https://arxiv.org/abs/2512.04256)
*Qiaolin Qin,Ronnie de Souza Santos,Rodrigo Spinola*

Main category: cs.SE

TL;DR: 调查发现生成式AI在软件工程教育中既带来学习帮助，也产生伦理和适应性挑战，需制定教学策略以保障公平有效使用。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具的兴起改变了软件学习和编写方式，教育界需了解学生的使用体验及其带来的机遇与挑战，以优化教学改革和技术应用。

Method: 通过设计包含李克特量表和开放式问题的问卷调查，收集两所大学130名本科生关于使用环境、益处、问题以及伦理和教学感知的数据。

Result: 该论文通过对130名本科软件工程学生的调查，探讨了生成式AI工具（如ChatGPT和GitHub Copilot）在SE教育中的使用情况。学生通常利用这些工具进行渐进式学习和复杂代码实现，感受到头脑风暴支持与信心提升的好处，但也面对解释不清和适应输出难等挑战。此外，学生关注公平和学术不端等伦理问题，并期望有明确的教学指导。

Conclusion: 生成式AI正在以复杂多样的方式重塑软件工程教育，需要提供支撑架构、伦理政策和灵活的教学策略，以促进公平且有效的学习。

Abstract: Context. The rise of generative AI (GenAI) tools like ChatGPT and GitHub Copilot has transformed how software is learned and written. In software engineering (SE) education, these tools offer new opportunities for support, but also raise concerns about over-reliance, ethical use, and impacts on learning. Objective. This study investigates how undergraduate SE students use GenAI tools, focusing on the benefits, challenges, ethical concerns, and instructional expectations that shape their experiences. Method. We conducted a survey with 130 undergraduate students from two universities. The survey combined structured Likert-scale items and open-ended questions to investigate five dimensions: usage context, perceived benefits, challenges, ethical and instructional perceptions. Results. Students most often use GenAI for incremental learning and advanced implementation, reporting benefits such as brainstorming support and confidence-building. At the same time, they face challenges including unclear rationales and difficulty adapting outputs. Students highlight ethical concerns around fairness and misconduct, and call for clearer instructional guidance. Conclusion. GenAI is reshaping SE education in nuanced ways. Our findings underscore the need for scaffolding, ethical policies, and adaptive instructional strategies to ensure that GenAI supports equitable and effective learning.

</details>


### [38] [Catching UX Flaws in Code: Leveraging LLMs to Identify Usability Flaws at the Development Stage](https://arxiv.org/abs/2512.04262)
*Nolan Platt,Ethan Luchs,Sehrish Nizamani*

Main category: cs.SE

TL;DR: 本文探讨了大语言模型（LLMs）在早期开发阶段自动进行可用性启发式评估的可行性，发现GPT-4o在问题检测方面表现出中等一致性，但对严重性的判断存在较大差异，需要人工监督。


<details>
  <summary>Details</summary>
Motivation: 传统的可用性启发式评估耗时且主观性强，尤其在开发早期，探索使用LLMs自动化评估以提高效率和一致性。

Method: 研究通过对30个开源网站应用雅各布·尼尔森的十条可用性启发式规则，利用OpenAI的GPT-4o模型进行三次独立评估，共生成850余条评估结果，并计算了一致性指标如Cohen's Kappa和Krippendorff's Alpha。

Result: GPT-4o在问题检测中的平均Cohen's Kappa为0.50，准确率84%；严重性判断Cohen's Kappa为0.63但准确率仅56%，Krippendorff's Alpha接近零，表明严重性判断一致性较差。

Conclusion: GPT-4o 可在识别可用性问题方面提供较为一致的评估，但对问题严重性的判断一致性较低，实际应用时仍需人工参与。

Abstract: Usability evaluations are essential for ensuring that modern interfaces meet user needs, yet traditional heuristic evaluations by human experts can be time-consuming and subjective, especially early in development. This paper investigates whether large language models (LLMs) can provide reliable and consistent heuristic assessments at the development stage. By applying Jakob Nielsen's ten usability heuristics to thirty open-source websites, we generated over 850 heuristic evaluations in three independent evaluations per site using a pipeline of OpenAI's GPT-4o. For issue detection, the model demonstrated moderate consistency, with an average pairwise Cohen's Kappa of 0.50 and an exact agreement of 84%. Severity judgments showed more variability: weighted Cohen's Kappa averaged 0.63, but exact agreement was just 56%, and Krippendorff's Alpha was near zero. These results suggest that while GPT-4o can produce internally consistent evaluations, especially for identifying the presence of usability issues, its ability to judge severity varies and requires human oversight in practice. Our findings highlight the feasibility and limitations of using LLMs for early-stage, automated usability testing, and offer a foundation for improving consistency in automated User Experience (UX) evaluation. To the best of our knowledge, our work provides one of the first quantitative inter-rater reliability analyses of automated heuristic evaluation and highlights methods for improving model consistency.

</details>


### [39] [Polynomiogram: An Integrated Framework for Root Visualization and Generative Art](https://arxiv.org/abs/2512.04263)
*Hoang Duc Nguyen,Anh Van Pham,Hien D. Nguyen*

Main category: cs.SE

TL;DR: Polynomiogram框架融合科学研究与生成艺术，通过灵活采样方案和双重计算引擎，实现多项式根系统的高效可视化与精确计算。


<details>
  <summary>Details</summary>
Motivation: 希望构建一个统一平台，既能满足科学研究对多项式根精确分析的需求，又能支持生成艺术的创意表达，弥合数学研究与艺术创作的鸿沟。

Method: 设计了双参数采样方案，利用生成函数映射到多项式系数，结合NumPy快速计算和MPSolve高精度验证，实现对多项式根系统的高效计算和可视化。

Result: 验证了算法在Kac和Lucas多项式等经典问题上的数值准确性，分析立方多项式分岔结构，并成功生成类似木槿花的自然形态及表达对人工智能致敬的个性化艺术作品。

Conclusion: Polynomiogram不仅是探索多项式根结构的科学工具，也是一种教育辅助和个性化生成艺术的平台，展示了其在数学研究和创意表达上的广泛应用潜力。

Abstract: This work presents the Polynomiogram framework, an integrated computational platform for exploring, visualizing, and generating art from polynomial root systems. The main innovation is a flexible sampling scheme in which two independent parameters are drawn from user defined domains and mapped to the polynomial coefficients through a generating function. This design allows the same mathematical foundation to support both scientific investigation and generative algorithmic art. The framework integrates two complementary numerical engines: NumPy companion matrix solver for fast, large scale computation and MPSolve for high precision, scientifically rigorous validation. This dual architecture enables efficient visualization for creative use and accurate computation for research and education. Numerical accuracy was verified using classical ensembles, including the Kac and Lucas polynomials. The method was applied to the cubic polynomial system to analyze its bifurcation structure, demonstrating its value as both a scientific tool for exploring root phenomena and an educational aid for visualizing fundamental concepts in algebra and dynamical systems. Beyond analysis, the Polynomiogram also demonstrated its potential as a tool for personalized generative art. Examples include the use of the platform to generate a natural form resembling a hibiscus flower and to create personalized artwork expressing gratitude toward advances in artificial intelligence and large language models through a tribute composition.

</details>


### [40] [Quantitative Analysis of Technical Debt and Pattern Violation in Large Language Model Architectures](https://arxiv.org/abs/2512.04273)
*Tyler Slater*

Main category: cs.SE

TL;DR: 本文首次提出评估AI生成微服务架构侵蚀的实证框架，发现开源模型在架构遵从性和代码质量上存在显著不足，隐含技术债务风险。


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注功能正确性，但缺乏对由AI生成的微服务架构侵蚀和技术债务积累的量化研究。

Method: 对三个先进的语言模型（GPT-5.1, Claude 4.5 Sonnet, Llama 3 8B）在相同的六边形架构约束下，实施标准化的图书借阅微服务，并通过抽象语法树(AST)解析评估其架构一致性和代码复杂度。

Result: GPT-5.1的架构符合率为0%，而Llama 3的架构违规率高达80%，存在接口适配器绕过和非法循环依赖问题，且开源模型生成的逻辑代码行数显著较少，显示“实现懒惰”现象。

Conclusion: 在缺乏自动化架构检测的情况下，小型开源模型生成的系统架构易积累结构性技术债务，不适合用于系统初期搭建。

Abstract: As Large Language Models (LLMs) transition from code completion tools to autonomous system architects, their impact on long-term software maintainability remains unquantified. While existing research benchmarks functional correctness (pass@k), this study presents the first empirical framework to measure "Architectural Erosion" and the accumulation of Technical Debt in AI-synthesized microservices. We conducted a comparative pilot study of three state-of-the-art models (GPT-5.1, Claude 4.5 Sonnet, and Llama 3 8B) by prompting them to implement a standardized Book Lending Microservice under strict Hexagonal Architecture constraints. Utilizing Abstract Syntax Tree (AST) parsing, we find that while proprietary models achieve high architectural conformance (0% violation rate for GPT-5.1), open-weights models exhibit critical divergence. Specifically, Llama 3 demonstrated an 80% Architectural Violation Rate, frequently bypassing interface adapters to create illegal circular dependencies between Domain and Infrastructure layers. Furthermore, we identified a phenomenon of "Implementation Laziness," where open-weights models generated 60% fewer Logical Lines of Code (LLOC) than their proprietary counterparts, effectively omitting complex business logic to satisfy token constraints. These findings suggest that without automated architectural linting, utilizing smaller open-weights models for system scaffolding accelerates the accumulation of structural technical debt.

</details>


### [41] [MANTRA: a Framework for Multi-stage Adaptive Noise TReAtment During Training](https://arxiv.org/abs/2512.04319)
*Zixiao Zhao,Fatemeh H. Fard,Jie JW Wu*

Main category: cs.SE

TL;DR: 论文提出了MANTRA，一种多阶段自适应噪声处理框架，通过动态损失分析和聚类策略，有效减少数据噪声对代码语言模型性能的影响，提升模型精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大规模软件工程数据集往往包含噪声或错误标注，降低模型的准确性和鲁棒性，而现有噪声标签学习在软件工程和代码大语言模型领域研究甚少，因此需要一种有效的噪声处理方案提升模型性能。

Method: 提出了MANTRA，一个多阶段自适应噪声处理框架，将噪声诊断和缓解直接嵌入代码预训练语言模型（PTM）和代码大型语言模型（LLMs）的微调过程中。具体方法包括基于每个样本的损失动态和高斯混合模型聚类，应用自适应丢弃策略，以排除持续的噪声样本，同时保留干净数据。

Result: 实验证明，部分大型语言模型对噪声较为敏感，但应用MANTRA后，不论是在代码摘要还是提交意图分类任务中，所有模型的性能均有所提升。

Conclusion: MANTRA框架帮助研究人员和开发者减少训练数据中的错误影响，节省数据清洗和处理时间，同时最大化微调效果，提升代码相关任务中模型的性能。

Abstract: The reliable application of deep learning models to software engineering tasks hinges on high-quality training data. Yet, large-scale repositories inevitably introduce noisy or mislabeled examples that degrade both accuracy and robustness. While Noise Label Learning (NLL) has been extensively studied in other fields, there are a few works that investigate NLL in Software Engineering (SE) and Large Language Models (LLMs) for SE tasks. In this work, we propose MANTRA, a Multi-stage Adaptive Noise TReAtment framework that embeds noise diagnosis and mitigation directly into the fine-tuning process of code-Pretrained Language Models (PTM) and code-LLMs. We first investigate the effect of noise at varying levels on convergence and loss trajectories of the models. Then we apply an adaptive dropout strategy guided by per-sample loss dynamics and Gaussian Mixture Model clustering to exclude persistently noisy points while preserving clean data. Applying to code summarization and commit intent classification, our experiments reveal that some LLMs are more sensitive to noise than others. However, with MANTRA, the performance of all models in both tasks is improved. MANTRA enables researchers and practitioners to reduce the impact of errors introduced by the dataset in training, saves time in data cleaning and processing, while maximizing the effect of fine-tuning.

</details>


### [42] [Targeted Testing of Compiler Optimizations via Grammar-Level Composition Styles](https://arxiv.org/abs/2512.04344)
*Zitong Zhou,Ben Limpanukorn,Hong Jin Kang,Jiyuan Wang,Yaoxuan Wu,Akos Kiss,Renata Hodovan,Miryung Kim*

Main category: cs.SE

TL;DR: 本文提出了一种基于语法的针对性模糊测试方法，通过挖掘程序结构组合样式，提升了编译器优化测试的覆盖率和触发率，适用于多语言和模块化框架，显著优于传统管线模糊测试方法。


<details>
  <summary>Details</summary>
Motivation: 现有模糊测试器在测试编译器优化时效果有限，主要原因是使用固定的优化管线，导致错过优化交互和未调度优化，且测试输入难以满足优化触发的特定结构关系。

Method: 提出了一种基于语法的变异模糊测试工具TargetFuzz，通过挖掘和重建优化相关的程序构造的组合样式，针对单个优化进行有效测试。该工具从优化相关语料库中提取组合样式，并在更大的通用语料库中通过合成变异实现多样化测试，自动生成变异器和交叉操作，无需手写生成器或特定语言变异器，适用于多语言和模块化框架如MLIR。

Result: TargetFuzz在LLVM和MLIR上的实验表明，覆盖率分别提升了8%和11%，触发优化的次数分别提高了2.8倍和2.6倍；针对性模糊测试能有效测试所有37个LLVM优化，而传统管线模糊测试漏测了12个。

Conclusion: 针对性模糊测试补充传统管线测试，能够有效发现和触发编译器优化中的更多场景，增强优化正确性验证，特别适合动态多变、模块化的编译器框架如MLIR。

Abstract: Ensuring the correctness of compiler optimizations is critical, but existing fuzzers struggle to test optimizations effectively. First, most fuzzers use optimization pipelines (heuristics-based, fixed sequences of passes) as their harness. The phase-ordering problem can enable or preempt transformations, so pipelines inevitably miss optimization interactions; moreover, many optimizations are not scheduled, even at aggressive levels. Second, optimizations typically fire only when inputs satisfy specific structural relationships, which existing generators and mutations struggle to produce. We propose targeted fuzzing of individual optimizations to complement pipeline-based testing. Our key idea is to exploit composition styles - structural relations over program constructs (adjacency, nesting, repetition, ordering) - that optimizations look for. We build a general-purpose, grammar-based mutational fuzzer, TargetFuzz, that (i) mines composition styles from an optimization-relevant corpus, then (ii) rebuilds them inside different contexts offered by a larger, generic corpus via synthesized mutations to test variations of optimization logic. TargetFuzz is adaptable to a new programming language by lightweight, grammar-based, construct annotations - and it automatically synthesizes mutators and crossovers to rebuild composition styles. No need for hand-coded generators or language-specific mutators, which is particularly useful for modular frameworks such as MLIR, whose dialect-based, rapidly evolving ecosystem makes optimizations difficult to fuzz. Our evaluation on LLVM and MLIR shows that TargetFuzz improves coverage by 8% and 11% and triggers optimizations 2.8$\times$ and 2.6$\times$, compared to baseline fuzzers under the targeted fuzzing mode. We show that targeted fuzzing is complementary: it effectively tests all 37 sampled LLVM optimizations, while pipeline-fuzzing missed 12.

</details>


### [43] [Automating Complex Document Workflows via Stepwise and Rollback-Enabled Operation Orchestration](https://arxiv.org/abs/2512.04445)
*Yanbin Zhang,Hanhui Ye,Yue Bai,Qiming Zhang,Liao Xiang,Wu Mianzhi,Renjun Hu*

Main category: cs.SE

TL;DR: AutoDW通过增量规划与回滚机制，有效自动化复杂文档多步骤工作流，显著提升完成率与鲁棒性，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有智能代理系统只能执行孤立指令，难以自动化多步骤、会话级复杂工作流，操作过程控制能力有限。

Method: 提出了AutoDW框架，结合用户指令、意图过滤的API候选项及文档状态进行增量API操作规划，支持参数和API级别的回滚机制，实现动态纠错和容错。

Result: 在包含250个会话和1,708条人工标注指令的基准测试中，AutoDW在指令级和会话级任务上完成率分别达到90%和62%，分别领先强基线40%和76%。在不同主干大模型及任务难度下均表现稳健。

Conclusion: AutoDW通过逐步规划和回滚机制，有效提升了多步骤文档处理工作流的自动化能力，实现了用户意图和文档状态的高度对齐。

Abstract: Workflow automation promises substantial productivity gains in everyday document-related tasks. While prior agentic systems can execute isolated instructions, they struggle with automating multi-step, session-level workflows due to limited control over the operational process. To this end, we introduce AutoDW, a novel execution framework that enables stepwise, rollback-enabled operation orchestration. AutoDW incrementally plans API actions conditioned on user instructions, intent-filtered API candidates, and the evolving states of the document. It further employs robust rollback mechanisms at both the argument and API levels, enabling dynamic correction and fault tolerance. These designs together ensure that the execution trajectory of AutoDW remains aligned with user intent and document context across long-horizon workflows. To assess its effectiveness, we construct a comprehensive benchmark of 250 sessions and 1,708 human-annotated instructions, reflecting realistic document processing scenarios with interdependent instructions. AutoDW achieves 90% and 62% completion rates on instruction- and session-level tasks, respectively, outperforming strong baselines by 40% and 76%. Moreover, AutoDW also remains robust for the decision of backbone LLMs and on tasks with varying difficulty. Code and data will be open-sourced. Code: https://github.com/YJett/AutoDW

</details>


### [44] [LLM-SrcLog: Towards Proactive and Unified Log Template Extraction via Large Language Models](https://arxiv.org/abs/2512.04474)
*Jiaqi Sun,Wei Li,Heng Zhang,Chutong Ding,Shiyou Qian,Jian Cao,Guangtao Xue*

Main category: cs.SE

TL;DR: 提出LLM-SrcLog，通过源代码和数据驱动的结合，实现了快速准确的日志模板解析，显著优于现有方法，适用于实际工业环境。


<details>
  <summary>Details</summary>
Motivation: 现有日志解析器主要依赖日志本身，忽略源代码信息，难以捕捉动态日志结构且成本较高，限制其实际应用。

Method: 提出了LLM-SrcLog框架，结合跨函数静态代码分析、基于语言模型的白盒模板抽取和基于数据聚类的黑盒模板抽取，实现源代码和日志的统一模板解析。

Result: 在多个公共基准测试和大型工业系统中，LLM-SrcLog相较于现有LLM基线方法提升了2-35%的F1分数，且解析延迟大大降低，验证了其实用性和优越性。

Conclusion: LLM-SrcLog能够高效准确地解析日志模板，实现较高的F1分数，且比基于每条日志的LLM推理快约1000倍，兼顾了速度和准确性。

Abstract: Log parsing transforms raw logs into structured templates containing constants and variables. It underpins anomaly detection, failure diagnosis, and other AIOps tasks. Current parsers are mostly reactive and log-centric. They only infer templates from logs, mostly overlooking the source code. This restricts their capacity to grasp dynamic log structures or adjust to evolving systems. Moreover, per-log LLM inference is too costly for practical deployment. In this paper, we propose LLM-SrcLog, a proactive and unified framework for log template parsing. It extracts templates directly from source code prior to deployment and supplements them with data-driven parsing for logs without available code. LLM-SrcLog integrates a cross-function static code analyzer to reconstruct meaningful logging contexts, an LLM-based white-box template extractor with post-processing to distinguish constants from variables, and a black-box template extractor that incorporates data-driven clustering for remaining unmatched logs. Experiments on two public benchmarks (Hadoop and Zookeeper) and a large-scale industrial system (Sunfire-Compute) show that, compared to two LLM-based baselines, LLM-SrcLog improves average F1-score by 2-17% and 8-35%. Meanwhile, its online parsing latency is comparable to data-driven methods and about 1,000 times faster than per-log LLM parsing. LLM-SrcLog achieves a near-ideal balance between speed and accuracy. Finally, we further validate the effectiveness of LLM-SrcLog through practical case studies in a real-world production environment.

</details>


### [45] [Completion by Comprehension: Guiding Code Generation with Multi-Granularity Understanding](https://arxiv.org/abs/2512.04538)
*Xinkui Zhao,Rongkai Liu,Yifan Zhang,Chen Zhi,Lufei Zhang,Guanjie Cheng,Yueshen Xu,Shuiguang Deng,Jianwei Yin*

Main category: cs.SE

TL;DR: 提出基于多粒度上下文理解的代码补全新框架CoCo，改善了现有方法忽视结构语义的不足，显著提升补全质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成的代码补全方法普遍将代码作为普通文本处理，主要依赖浅层语义匹配，忽视控制流和代码特有依赖，导致生成质量受限。因此，需要一种能捕捉多层次结构语义和依赖关系的新方法，以提升大规模代码库的代码补全效果。

Method: 利用静态代码分析提取函数、文件及项目层次的结构化上下文，采用图结构的多粒度上下文选择机制过滤无关信息，将筛选结果转换成自然语言提示，然后通过结构感知的代码重排序机制确保生成代码在语义和结构上的一致性。

Result: 本文提出了CoCo框架，通过静态代码分析从函数、文件和项目三个层次提取结构化上下文，并采用图结构的多粒度上下文选择机制过滤冗余和噪声，最终将关键信息转换为自然语言提示辅助代码补全。同时设计结构感知的代码重排序机制提升语义与结构的一致性。在跨代码库评价基准上，CoCo超越了现有最先进方法，EM指标提升最高达20.2%。该框架具有模型无关性，可集成于多种现有方法，实现显著性能提升。

Conclusion: 基于静态分析的多粒度结构上下文捕获与图结构筛选机制，有效增强了代码补全的语义与结构理解能力，在多个基准测试中表现优越，且具备良好的适应性和扩展性。

Abstract: As code completion task from function-level to repository-level, leveraging contextual information from large-scale codebases becomes a core challenge. However, existing retrieval-augmented generation (RAG) methods typically treat code as plain natural language, relying primarily on shallow semantic matching while overlooking structural semantics and code-specific dependencies. This limits their ability to capture control flow and underlying intent, ultimately constraining the quality of generated code. Therefore, we propose CoCo, a novel framework that enables code Completion by Comprehension of multi-granularity context from large-scale code repositories. CoCo employs static code analysis to extract structured context at the function, file, and project levels, capturing execution logic and semantic dependencies. It then adopts an graph-based multi-granularity context selection mechanism to filter out redundant information and remove noise. Consequently, the information is converted into natural language in a consistent manner, thereby functioning as explicit contextual prompts to guide subsequent code completion. Additionally, a structure-aware code re-ranker mechanism ensures alignment at both semantic and structural levels. Extensive experiments on CrossCodeEval and RepoEval benchmarks demonstrate that CoCo consistently surpasses state-of-the-art baselines, achieving up to 20.2% gains in EM. Moreover, the framework is model-agnostic and can be seamlessly integrated into existing methods, leading to significant performance.

</details>


### [46] [Cross-Task Benchmarking and Evaluation of General-Purpose and Code-Specific Large Language Models](https://arxiv.org/abs/2512.04673)
*Gunjan Das,Paheli Bhattacharya,Rishabh Gupta*

Main category: cs.SE

TL;DR: 评估八款大型语言模型在多领域基准上的表现，发现代码优化模型在推理和语法上表现更佳，且在非代码任务中也有提升。


<details>
  <summary>Details</summary>
Motivation: 目前虽然已有研究评估单一模型能力，但缺乏统一不同领域（语言理解、推理、代码理解）的系统比较，因而本文旨在填补这一空白，提供跨领域的模型能力评测。

Method: 通过六个涵盖语言能力、数学推理和可信度的多样化基准，对五个通用和三个代码专用的先进大型语言模型进行综合评估，此外对代码解释任务使用CoNaLa数据集进行详细分析。

Result: 本文系统地评估了五个通用大型语言模型和三个代码专用大型语言模型在语言理解、数学推理和可信度六个基准测试上的表现，特别比较了在代码解释任务上的表现差异。结果显示，针对代码优化的模型（如CodeLLaMA）在推理和语法精确性方面表现优异，甚至在非编码任务中也具有显著的性能优势，优于通用模型（如Mistral-7B和Llama-3-8B）。

Conclusion: 代码专用大型语言模型不仅在代码理解和推理中表现优异，也在其他非编码任务中具备较强的性能优势，胜过部分通用模型。

Abstract: Large Language Models (LLMs) have revolutionized both general natural language processing and domain-specific applications such as code synthesis, legal reasoning, and finance. However, while prior studies have explored individual model capabilities, a systematic cross-domain comparison that unifies linguistic, reasoning, and code understanding abilities remains underexplored. In this work, we present a comprehensive evaluation of five general-purpose and three code-specific state-of-the-art LLMs across six diverse benchmarks encompassing linguistic competence, mathematical reasoning, and trustworthiness. Additionally, we analyze model behavior on the CoNaLa dataset for code explanation, comparing natural language and code-specialized LLMs. Our findings reveal that models optimized for code (e.g., CodeLLaMA variants) exhibit strong reasoning and syntactic precision, that even for non-coding tasks can show measurable performance gains, in contrast to general-purpose models like Mistral-7B and Llama-3-8B.

</details>


### [47] [Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap](https://arxiv.org/abs/2512.04680)
*Jialong Li,Mingyue Zhang,Nianyu Li,Danny Weyns,Zhi Jin,Kenji Tei*

Main category: cs.SE

TL;DR: 本文系统分析了生成式人工智能在自适应系统中的应用潜力，梳理潜在益处和挑战，并提出未来研究的路线图和实际应用建议。


<details>
  <summary>Details</summary>
Motivation: SAS需要应对变化和不确定性，而生成式人工智能（特别是大型语言模型）在数据理解和逻辑推理方面表现出色，与SAS的核心功能高度契合，因此探讨将GenAI用于增强SAS的潜力，同时目前此方面研究有限且技术多样且快速发展，故需系统梳理其益处与挑战

Method: 收集、筛选和分析四个不同研究领域的文献，将潜在益处分为两个类别：用于提升SAS的自主性（基于MAPE-K反馈环的监控、分析、规划和执行功能）和改善人与SAS的交互（人类在环场景）

Result: 系统总结了将GenAI应用于SAS的潜在益处和挑战，提出了一条研究路线图，明确了关键的研究挑战并讨论了当前GenAI的不足及可能的缓解策略

Conclusion: 将GenAI整合到自适应系统中虽具备显著提升自主性和人机交互的潜力，但面临多项技术和应用挑战，未来研究应聚焦关键挑战并探索解决方案以实现其最大价值。

Abstract: Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this paper aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI's within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.

</details>


### [48] [POLARIS: Is Multi-Agentic Reasoning the Next Wave in Engineering Self-Adaptive Systems?](https://arxiv.org/abs/2512.04702)
*Divyansh Pandey,Vyakhya Gupta,Prakhar Singhal,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 提出POLARIS三层自适应框架，结合多智能体和元学习，实现对复杂软件生态系统的高效自适应，优于现有方法，开启自适应3.0时代。


<details>
  <summary>Details</summary>
Motivation: 现代软件生态系统规模大、复杂度高且高度自治，带来了前所未有的不确定性，传统自适应方法难以应对新的环境和未知情况。

Method: 提出POLARIS框架，包含三层多智能体结构：低延迟的适配器层用于监控和安全执行；透明的推理层用于生成和验证计划；元层记录经验并通过元学习优化适应策略。

Result: 在两个自适应系统案例（SWIM和SWITCH）上的初步评估显示，POLARIS持续优于现有先进基线，能更好地处理不确定性和适应环境变化。

Conclusion: POLARIS推动了自适应系统向Self-Adaptation 3.0转变，即系统不仅学习环境，还能推理和演化自身的适应过程，实现持续改进以应对新挑战。

Abstract: The growing scale, complexity, interconnectivity, and autonomy of modern software ecosystems introduce unprecedented uncertainty, challenging the foundations of traditional self-adaptation. Existing approaches, typically rule-driven controllers or isolated learning components, struggle to generalize to novel contexts or coordinate responses across distributed subsystems, leaving them ill-equipped for emergent unknown unknowns. Recent discussions on Self-Adaptation 2.0 emphasize an equal partnership between AI and adaptive systems, merging learning-driven intelligence with adaptive control for predictive and proactive behavior. Building on this foundation, we introduce POLARIS, a three-layer multi-agentic self-adaptation framework that advances beyond reactive adaptation. POLARIS integrates: (1) a low-latency Adapter layer for monitoring and safe execution, (2) a transparent Reasoning layer that generates and verifies plans using tool-aware, explainable agents, and (3) a Meta layer that records experiences and meta-learns improved adaptation policies over time. Through shared knowledge and predictive models, POLARIS handles uncertainty, learns from past actions, and evolves its strategies, enabling systems that anticipate change and maintain resilient, goal-directed behavior. Preliminary evaluation on two self-adaptive exemplars, SWIM and SWITCH, shows that POLARIS consistently outperforms state-of-the-art baselines. We argue this marks a shift toward Self-Adaptation 3.0, akin to Software 3.0: a paradigm where systems not only learn from their environment but also reason about and evolve their own adaptation processes, continuously improving to meet novel challenges.

</details>


### [49] [Configuration Defects in Kubernetes](https://arxiv.org/abs/2512.05062)
*Yue Zhang,Uchswas Paul,Marcelo d'Amorim,Akond Rahman*

Main category: cs.SE

TL;DR: 本研究系统分析Kubernetes配置缺陷，评估现有工具检测能力，开发新工具补足检测盲点，促进缺陷预防和修复。


<details>
  <summary>Details</summary>
Motivation: Kubernetes配置易出错，缺陷常见且严重，急需研究帮助检测和预防这些缺陷。

Method: 对2260个Kubernetes配置脚本中的719个缺陷进行定性分析，识别15类缺陷；评估8个公开静态分析工具对缺陷的检测能力；开发新linter检测两类严重缺陷。

Result: 识别15类缺陷，8个工具检测其中8类，数据字段相关缺陷检测精度和召回最高；新开发linter发现26个新缺陷，19个已修复。

Conclusion: 通过分类缺陷和提升检测手段，可有效帮助开发者发现和修复Kubernetes配置缺陷，提升系统安全性和稳定性。推荐结合多种检测技术用于缺陷检测与修复。

Abstract: Kubernetes is a tool that facilitates rapid deployment of software. Unfortunately, configuring Kubernetes is prone to errors. Configuration defects are not uncommon and can result in serious consequences. This paper reports an empirical study about configuration defects in Kubernetes with the goal of helping practitioners detect and prevent these defects. We study 719 defects that we extract from 2,260 Kubernetes configuration scripts using open source repositories. Using qualitative analysis, we identify 15 categories of defects. We find 8 publicly available static analysis tools to be capable of detecting 8 of the 15 defect categories. We find that the highest precision and recall of those tools are for defects related to data fields. We develop a linter to detect two categories of defects that cause serious consequences, which none of the studied tools are able to detect. Our linter revealed 26 previously-unknown defects that have been confirmed by practitioners, 19 of which have already been fixed. We conclude our paper by providing recommendations on how defect detection and repair techniques can be used for Kubernetes configuration scripts. The datasets and source code used for the paper are publicly available online.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [50] [Semi Centralized Training Decentralized Execution Architecture for Multi Agent Deep Reinforcement Learning in Traffic Signal Control](https://arxiv.org/abs/2512.04653)
*Pouria Yazdani,Arash Rezaali,Monireh Abdoos*

Main category: cs.MA

TL;DR: 本文提出了区域划分的半集中训练分散执行架构SEMI-CTDE用于多路口交通信号控制，克服了纯集中和纯分散方法的缺点，显著提升了控制性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习方法在交通信号控制中存在全集中和全分散方法各自的缺陷，如维度灾难、单点依赖、局部可观测性差和缺乏协调，导致性能不佳。

Method: 通过将交通网络划分成多个区域，采用区域内集中训练和参数共享，设计复合状态与奖励函数以编码局部及区域信息，实现半集中训练分散执行架构SEMI-CTDE。基于该架构实现了两种不同设计目标的模型，并进行了多角度的性能评价。

Result: 提出了一种半集中训练、分散执行的架构SEMI-CTDE，通过区域划分和参数共享，有效融合局部与区域信息，实现了跨策略和状态奖励结构的良好迁移性，实验验证了该方法在多种交通密度和分布下优于规则基和全分散基线的方法。

Conclusion: SEMI-CTDE架构通过区域化处理和参数共享，有效解决了多路口交通信号控制中的协调和可观测性问题，实验表明其性能稳定优于现有规则基和完全分散方法。

Abstract: Multi-agent reinforcement learning (MARL) has emerged as a promising paradigm for adaptive traffic signal control (ATSC) of multiple intersections. Existing approaches typically follow either a fully centralized or a fully decentralized design. Fully centralized approaches suffer from the curse of dimensionality, and reliance on a single learning server, whereas purely decentralized approaches operate under severe partial observability and lack explicit coordination resulting in suboptimal performance. These limitations motivate region-based MARL, where the network is partitioned into smaller, tightly coupled intersections that form regions, and training is organized around these regions. This paper introduces a Semi-Centralized Training, Decentralized Execution (SEMI-CTDE) architecture for multi intersection ATSC. Within each region, SEMI-CTDE performs centralized training with regional parameter sharing and employs composite state and reward formulations that jointly encode local and regional information. The architecture is highly transferable across different policy backbones and state-reward instantiations. Building on this architecture, we implement two models with distinct design objectives. A multi-perspective experimental analysis of the two implemented SEMI-CTDE-based models covering ablations of the architecture's core elements including rule based and fully decentralized baselines shows that they achieve consistently superior performance and remain effective across a wide range of traffic densities and distributions.

</details>


### [51] [Complementary Characterization of Agent-Based Models via Computational Mechanics and Diffusion Models](https://arxiv.org/abs/2512.04771)
*Roberto Garrone*

Main category: cs.MA

TL;DR: 本文提出了一种结合$ε$-机和扩散模型的新框架，用于分析基于主体的模型（ABM）的输出，既捕捉时间序列的预测结构，也揭示高维分布特征，提供更全面的行为表示。


<details>
  <summary>Details</summary>
Motivation: 基于主体的模型生成的时间序列和高维群体结果存在不同数学性质的结构特征，单一方法难以全面捕捉行为特征，故提出结合$ε$-机和扩散模型以全面分析ABM输出。

Method: 引入扩散模型作为与$ε$-机正交互补的工具，分别针对ABM输出的时间过程和高维分布进行表征，结合两者形成基于时间组织和分布几何的双轴行为表示，并通过严谨的数学定义和命题证明两者的互补性。

Result: 建立了一个基于$ε$-机和扩散模型联合分析的框架，使用养老照护者ABM数据集验证了该方法的有效性，理论上证明两者在过程与分布两个数学域上的互补性，为ABM行为分析提供新的系统工具。

Conclusion: 该框架首次将计算力学与基于评分的生成建模结合起来，实现了对ABM输出的结构化分析，并验证了方法的互补性和有效性，为复杂模拟模型提供了分析时间可预测性与高维分布结构的系统方法。

Abstract: This article extends the preprint "Characterizing Agent-Based Model Dynamics via $ε$-Machines and Kolmogorov-Style Complexity" by introducing diffusion models as orthogonal and complementary tools for characterizing the output of agent-based models (ABMs). Where $ε$-machines capture the predictive temporal structure and intrinsic computation of ABM-generated time series, diffusion models characterize high-dimensional cross-sectional distributions, learn underlying data manifolds, and enable synthetic generation of plausible population-level outcomes. We provide a formal analysis demonstrating that the two approaches operate on distinct mathematical domains -- processes vs. distributions -- and show that their combination yields a two-axis representation of ABM behavior based on temporal organization and distributional geometry. To our knowledge, this is the first framework to integrate computational mechanics with score-based generative modeling for the structural analysis of ABM outputs, thereby situating ABM characterization within the broader landscape of modern machine-learning methods for density estimation and intrinsic computation. The framework is validated using the same elder-caregiver ABM dataset introduced in the companion paper, and we provide precise definitions and propositions formalizing the mathematical complementarity between $ε$-machines and diffusion models. This establishes a principled methodology for jointly analyzing temporal predictability and high-dimensional distributional structure in complex simulation models.

</details>


### [52] [Strategic Self-Improvement for Competitive Agents in AI Labour Markets](https://arxiv.org/abs/2512.04988)
*Christopher Chiu,Simpson Zhang,Mihaela van der Schaar*

Main category: cs.MA

TL;DR: 本文提出了首个捕捉现实经济动力学的AI代理竞争框架，展示了其在模拟零工经济中的战略自我提升和市场适应能力，揭示了AI驱动劳动力市场可能带来的深远经济影响。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能代理在经济领域的广泛部署，理解其战略行为及市场层面影响变得至关重要。

Method: 通过构建包含元认知、竞争意识和长远战略规划三大核心能力的框架，并在模拟零工经济环境中进行实验，分析不同策略下大型语言模型代理的行为与市场效应。

Result: 提出了一个能够捕捉现实经济力量（逆向选择、道德风险、声誉动态）的全新框架，并通过模拟的零工经济展示了大型语言模型代理如何通过元认知、竞争意识和长远战略规划实现自我提升，表现出对市场变化的高度适应性，同时重现了人类劳动力市场的宏观经济现象，揭示了可能出现的快速垄断和系统性价格下跌等趋势。

Conclusion: 该研究为深入探索AI驱动劳动市场的经济特性奠定了基础，并提供了研究代理在新兴经济中战略推理能力的理论框架。

Abstract: As artificial intelligence (AI) agents are deployed across economic domains, understanding their strategic behavior and market-level impact becomes critical. This paper puts forward a groundbreaking new framework that is the first to capture the real-world economic forces that shape agentic labor markets: adverse selection, moral hazard, and reputation dynamics. Our framework encapsulates three core capabilities that successful LLM-agents will need: \textbf{metacognition} (accurate self-assessment of skills), \textbf{competitive awareness} (modeling rivals and market dynamics), and \textbf{long-horizon strategic planning}. We illustrate our framework through a tractable simulated gig economy where agentic Large Language Models (LLMs) compete for jobs, develop skills, and adapt their strategies under competitive pressure. Our simulations illustrate how LLM agents explicitly prompted with reasoning capabilities learn to strategically self-improve and demonstrate superior adaptability to changing market conditions. At the market level, our simulations reproduce classic macroeconomic phenomena found in human labor markets, while controlled experiments reveal potential AI-driven economic trends, such as rapid monopolization and systemic price deflation. This work provides a foundation to further explore the economic properties of AI-driven labour markets, and a conceptual framework to study the strategic reasoning capabilities in agents competing in the emerging economy.

</details>
