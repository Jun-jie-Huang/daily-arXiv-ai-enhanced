{"id": "2602.07071", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07071", "abs": "https://arxiv.org/abs/2602.07071", "authors": ["S M Rakib UI Karim", "Wenyi Lu", "Sean Goggins"], "title": "Artificial Intelligence in Open Source Software Engineering: A Foundation for Sustainability", "comment": null, "summary": "Open-source software (OSS) is foundational to modern digital infrastructure, yet this context for group work continues to struggle to ensure sufficient contributions in many critical cases. This literature review explores how artificial intelligence (AI) is being leveraged to address critical challenges to OSS sustainability, including maintaining contributor engagement, securing funding, ensuring code quality and security, fostering healthy community dynamics, and preventing project abandonment. Synthesizing recent interdisciplinary research, the paper identifies key applications of AI in this domain, including automated bug triaging, system maintenance, contributor onboarding and mentorship, community health analytics, vulnerability detection, and task automation. The review also examines the limitations and ethical concerns that arise from applying AI in OSS contexts, including data availability, bias and fairness, transparency, risks of misuse, and the preservation of human-centered values in collaborative development. By framing AI not as a replacement but as a tool to augment human infrastructure, this study highlights both the promise and pitfalls of AI-driven interventions. It concludes by identifying critical research gaps and proposing future directions at the intersection of AI, sustainability, and OSS, aiming to support more resilient and equitable open-source ecosystems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86AI\u6280\u672f\u5982\u4f55\u52a9\u529b\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u53d1\u5c55\uff0c\u5f3a\u8c03AI\u5e94\u4f5c\u4e3a\u8f85\u52a9\u5de5\u5177\uff0c\u6307\u51fa\u5f53\u524d\u5e94\u7528\u4e2d\u7684\u4e0d\u8db3\u4e0e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u4f5c\u4e3a\u6570\u5b57\u57fa\u7840\u8bbe\u65bd\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u9762\u4e34\u8d21\u732e\u8005\u4e0d\u8db3\u3001\u8d44\u91d1\u5b89\u5168\u53ca\u793e\u533a\u5065\u5eb7\u7b49\u591a\u91cd\u53ef\u6301\u7eed\u6027\u6311\u6218\uff0c\u4fc3\u4f7f\u63a2\u7d22AI\u6280\u672f\u7684\u4ecb\u5165\u3002", "method": "\u672c\u6587\u91c7\u7528\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u7efc\u5408\u8de8\u5b66\u79d1\u7814\u7a76\uff0c\u7cfb\u7edf\u5206\u6790AI\u5728\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0AI\u5728\u81ea\u52a8\u7f3a\u9677\u5206\u914d\u3001\u7cfb\u7edf\u7ef4\u62a4\u3001\u8d21\u732e\u8005\u8f85\u5bfc\u3001\u793e\u533a\u5065\u5eb7\u5206\u6790\u53ca\u5b89\u5168\u6f0f\u6d1e\u68c0\u6d4b\u7b49\u65b9\u9762\u5c55\u73b0\u6f5c\u529b\uff0c\u540c\u65f6\u63ed\u793a\u5176\u5728\u6570\u636e\u516c\u5e73\u6027\u3001\u900f\u660e\u5ea6\u4e0e\u4f26\u7406\u98ce\u9669\u4e0a\u7684\u5c40\u9650\u3002", "conclusion": "AI\u6280\u672f\u5728\u5f00\u6e90\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u4e2d\u5177\u6709\u91cd\u8981\u4f5c\u7528\uff0c\u4f46\u4ecd\u9762\u4e34\u6570\u636e\u504f\u89c1\u3001\u900f\u660e\u6027\u4e0d\u8db3\u7b49\u6311\u6218\uff0c\u9700\u5f3a\u5316\u4eba\u673a\u534f\u4f5c\u4ee5\u5b9e\u73b0\u66f4\u5065\u5eb7\u7684\u5f00\u6e90\u751f\u6001\u3002"}}
{"id": "2602.07072", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.07072", "abs": "https://arxiv.org/abs/2602.07072", "authors": ["Igor Costa"], "title": "AgentSpawn: Adaptive Multi-Agent Collaboration Through Dynamic Spawning for Long-Horizon Code Generation", "comment": "18 pages, 4 figures, 6 tables", "summary": "Long-horizon code generation requires sustained context and adaptive expertise across domains. Current multi-agent systems use static workflows that cannot adapt when runtime analysis reveals unanticipated complexity. We propose AgentSpawn, an architecture enabling dynamic agent collaboration through: (1) automatic memory transfer during spawning, (2) adaptive spawning policies triggered by runtime complexity metrics, and (3) coherence protocols for concurrent modifications. AgentSpawn addresses five critical gaps in existing research around memory continuity, skill inheritance, task resumption, runtime spawning, and concurrent coherence. Experimental validation demonstrates AgentSpawn achieves 34% higher completion rates than static baselines on benchmarks like SWE-bench while reducing memory overhead by 42% through selective slicing.", "AI": {"tldr": "AgentSpawn\u63d0\u51fa\u4e86\u4e00\u79cd\u52a8\u6001\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u52a8\u8bb0\u5fc6\u4f20\u9012\u548c\u81ea\u9002\u5e94\u751f\u6210\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u957f\u65f6\u95f4\u4ee3\u7801\u751f\u6210\u7684\u5b8c\u6210\u7387\u548c\u6548\u7387\u3002", "motivation": "\u957f\u65f6\u95f4\u8de8\u5ea6\u7684\u4ee3\u7801\u751f\u6210\u9700\u8981\u6301\u7eed\u7684\u4e0a\u4e0b\u6587\u4fdd\u6301\u548c\u8de8\u9886\u57df\u7684\u81ea\u9002\u5e94\u4e13\u4e1a\u80fd\u529b\uff0c\u800c\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u91c7\u7528\u9759\u6001\u5de5\u4f5c\u6d41\u7a0b\uff0c\u65e0\u6cd5\u5728\u8fd0\u884c\u65f6\u5206\u6790\u53d1\u73b0\u610f\u5916\u590d\u6742\u6027\u65f6\u8fdb\u884c\u9002\u5e94\u3002", "method": "\u63d0\u51faAgentSpawn\u67b6\u6784\uff0c\u901a\u8fc7(1)\u81ea\u52a8\u8bb0\u5fc6\u4f20\u9012\u4ee5\u652f\u6301\u667a\u80fd\u4f53\u751f\u6210\uff0c(2)\u57fa\u4e8e\u8fd0\u884c\u65f6\u590d\u6742\u6027\u6307\u6807\u89e6\u53d1\u7684\u81ea\u9002\u5e94\u751f\u6210\u7b56\u7565\uff0c(3)\u5e76\u53d1\u4fee\u6539\u7684\u4e00\u81f4\u6027\u534f\u8bae\uff0c\u5b9e\u73b0\u52a8\u6001\u667a\u80fd\u4f53\u534f\u4f5c\u3002", "result": "AgentSpawn\u5728SWE-bench\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5b8c\u6210\u7387\u63d0\u9ad8\u4e8634%\uff0c\u540c\u65f6\u901a\u8fc7\u9009\u62e9\u6027\u5207\u7247\u51cf\u5c11\u4e8642%\u7684\u5185\u5b58\u5f00\u9500\u3002", "conclusion": "AgentSpawn\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u7814\u7a76\u4e2d\u8bb0\u5fc6\u8fde\u7eed\u6027\u3001\u6280\u80fd\u7ee7\u627f\u3001\u4efb\u52a1\u6062\u590d\u3001\u8fd0\u884c\u65f6\u751f\u6210\u548c\u5e76\u53d1\u4e00\u81f4\u6027\u7b49\u4e94\u5927\u5173\u952e\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u957f\u65f6\u95f4\u8de8\u5ea6\u4ee3\u7801\u751f\u6210\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2602.07079", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07079", "abs": "https://arxiv.org/abs/2602.07079", "authors": ["Go Frendi Gunawan", "Mukhlis Amien"], "title": "Comprehensive Evaluation of Large Language Models on Software Engineering Tasks: A Multi-Task Benchmark", "comment": "10 pages, 7 figures. Under review. Code and data will be fully released", "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in software engineering, yet comprehensive benchmarks covering diverse SE activities remain limited. We present a multi-task evaluation of 11 state-of-the-art LLMs across five representative software engineering tasks: bug fixing, feature development, code refactoring, technical copywriting, and research synthesis. Our automated verification framework measures both output quality and completion efficiency. Key findings reveal that (1) models achieving identical perfect scores exhibit 22x variation in completion time, 49x variation in tool efficiency, and 53x variation in estimated cost; (2) tool usage frequency shows no correlation with success (r = 0.077, p = 0.575) - one model used 917 tool calls while another solved the same task with 3 calls; (3) we identify two distinct inefficiency patterns: loop inefficiency and inference inefficiency; and (4) coding tasks achieve 100 percent success while research tasks present greater challenges (90.9 percent). We release all experimental data, verification scripts, and analysis code for full reproducibility.", "AI": {"tldr": "\u672c\u7814\u7a76\u5bf911\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e94\u4e2a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u591a\u7ef4\u5ea6\u8bc4\u6d4b\uff0c\u63ed\u793a\u4e86\u6548\u7387\u548c\u5de5\u5177\u4f7f\u7528\u7684\u663e\u8457\u5dee\u5f02\uff0c\u4fc3\u8fdb\u6a21\u578b\u9009\u7528\u548c\u4f18\u5316\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7f3a\u4e4f\u6db5\u76d6\u591a\u6837\u4efb\u52a1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7efc\u5408\u8bc4\u6d4b\u57fa\u51c6\uff0c\u56e0\u6b64\u9700\u8981\u5168\u9762\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u5728\u4e0d\u540c\u8f6f\u4ef6\u5de5\u7a0b\u6d3b\u52a8\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5bf911\u4e2a\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u4efb\u52a1\u8bc4\u4f30\uff0c\u6db5\u76d6\u7f3a\u9677\u4fee\u590d\u3001\u529f\u80fd\u5f00\u53d1\u3001\u4ee3\u7801\u91cd\u6784\u3001\u6280\u672f\u6587\u6848\u548c\u7814\u7a76\u5408\u6210\u4e94\u4e2a\u4efb\u52a1\uff0c\u4f7f\u7528\u81ea\u52a8\u5316\u9a8c\u8bc1\u6846\u67b6\u8bc4\u4f30\u8f93\u51fa\u8d28\u91cf\u548c\u5b8c\u6210\u6548\u7387\u3002", "result": "\u53d1\u73b0\u5373\u4f7f\u6a21\u578b\u5f97\u5206\u76f8\u540c\uff0c\u5b8c\u6210\u65f6\u95f4\u3001\u5de5\u5177\u6548\u7387\u548c\u6210\u672c\u5dee\u5f02\u5de8\u5927\uff0c\u5de5\u5177\u8c03\u7528\u6b21\u6570\u4e0e\u6210\u529f\u7387\u65e0\u5173\uff0c\u8bc6\u522b\u51fa\u5faa\u73af\u6548\u7387\u4f4e\u4e0b\u548c\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u4e24\u79cd\u4f4e\u6548\u6a21\u5f0f\uff0c\u7f16\u7a0b\u4efb\u52a1\u6210\u529f\u7387100%\uff0c\u7814\u7a76\u4efb\u52a1\u6210\u529f\u7387\u8f83\u4f4e\uff0890.9%\uff09\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u6548\u7387\u548c\u5de5\u5177\u4f7f\u7528\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u4e0d\u540c\u4f4e\u6548\u6a21\u5f0f\uff0c\u5e76\u6307\u51fa\u7814\u7a76\u4efb\u52a1\u6311\u6218\u8f83\u5927\u3002"}}
{"id": "2602.07092", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07092", "abs": "https://arxiv.org/abs/2602.07092", "authors": ["Haipeng Jiang", "Kailong Ren", "Zimo Yin", "Zhetao Sun", "Xin Gan", "Guangyi Lv", "Ming He", "Peng Wang", "Congli Yin", "Hong Pan", "Changwen Zhang", "Shan Tong", "Zhengyu Xu", "Zeping Chen", "Yubin Huangfu", "Yanzhi Xu", "Xing Su", "Qin Feng", "Dong An", "Jianping Fan"], "title": "Lemon Agent Technical Report", "comment": null, "summary": "Recent advanced LLM-powered agent systems have exhibited their remarkable capabilities in tackling complex, long-horizon tasks. Nevertheless, they still suffer from inherent limitations in resource efficiency, context management, and multimodal perception. Based on these observations, Lemon Agent is introduced, a multi-agent orchestrator-worker system built on a newly proposed AgentCortex framework, which formalizes the classic Planner-Executor-Memory paradigm through an adaptive task execution mechanism. Our system integrates a hierarchical self-adaptive scheduling mechanism that operates at both the overall orchestrator layer and workers layer. This mechanism can dynamically adjust computational intensity based on task complexity. It enables orchestrator to allocate one or more workers for parallel subtask execution, while workers can further improve operational efficiency by invoking tools concurrently. By virtue of this two-tier architecture, the system achieves synergistic balance between global task coordination and local task execution, thereby optimizing resource utilization and task processing efficiency in complex scenarios. To reduce context redundancy and increase information density during parallel steps, we adopt a three-tier progressive context management strategy. To make fuller use of historical information, we propose a self-evolving memory system, which can extract multi-dimensional valid information from all historical experiences to assist in completing similar tasks. Furthermore, we provide an enhanced MCP toolset. Empirical evaluations on authoritative benchmarks demonstrate that our Lemon Agent can achieve a state-of-the-art 91.36% overall accuracy on GAIA and secures the top position on the xbench-DeepSearch leaderboard with a score of 77+.", "AI": {"tldr": "Lemon Agent\u57fa\u4e8e\u65b0\u7684AgentCortex\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u5c42\u6b21\u8c03\u5ea6\u548c\u8bb0\u5fc6\u673a\u5236\uff0c\u663e\u8457\u4f18\u5316\u4e86\u590d\u6742\u4efb\u52a1\u7684\u5904\u7406\u6548\u7387\u548c\u51c6\u786e\u7387\uff0c\u5237\u65b0\u4e86\u591a\u9879\u6743\u5a01\u57fa\u51c6\u6d4b\u8bd5\u7eaa\u5f55\u3002", "motivation": "\u73b0\u6709LLM\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u8d44\u6e90\u6548\u7387\u3001\u4e0a\u4e0b\u6587\u7ba1\u7406\u548c\u591a\u6a21\u6001\u611f\u77e5\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u4e9f\u9700\u65b0\u65b9\u6cd5\u63d0\u5347\u590d\u6742\u957f\u4efb\u52a1\u7684\u5904\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51faAgentCortex\u6846\u67b6\uff0c\u91c7\u7528\u5206\u5c42\u81ea\u9002\u5e94\u8c03\u5ea6\u673a\u5236\uff0c\u7ed3\u5408\u4e09\u5c42\u6e10\u8fdb\u5f0f\u4e0a\u4e0b\u6587\u7ba1\u7406\u7b56\u7565\u548c\u81ea\u6211\u8fdb\u5316\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u4ee3\u7406\u534f\u540c\u6267\u884c\u548c\u5de5\u5177\u5e76\u53d1\u8c03\u7528\u3002", "result": "\u7cfb\u7edf\u5728GAIA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u523091.36%\u7684\u6574\u4f53\u51c6\u786e\u7387\uff0c\u5e76\u5728xbench-DeepSearch\u6392\u884c\u699c\u4e2d\u83b7\u5f9777+\u7684\u6700\u9ad8\u5206\u3002", "conclusion": "Lemon Agent\u901a\u8fc7\u5f15\u5165AgentCortex\u6846\u67b6\u548c\u5c42\u6b21\u5316\u81ea\u9002\u5e94\u8c03\u5ea6\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u8d44\u6e90\u5229\u7528\u548c\u4efb\u52a1\u6267\u884c\u6548\u7387\u7684\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u4efb\u52a1\u7684\u5904\u7406\u80fd\u529b\u548c\u51c6\u786e\u7387\u3002"}}
{"id": "2602.07080", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07080", "abs": "https://arxiv.org/abs/2602.07080", "authors": ["Yicheng He", "Zheng Zhao", "Zhou Kaiyu", "Bryan Dai", "Jie Fu", "Yonghui Yang"], "title": "CodeCircuit: Toward Inferring LLM-Generated Code Correctness via Attribution Graphs", "comment": null, "summary": "Current paradigms for code verification rely heavily on external mechanisms-such as execution-based unit tests or auxiliary LLM judges-which are often labor-intensive or limited by the judging model's own capabilities. This raises a fundamental, yet unexplored question: Can an LLM's functional correctness be assessed purely from its internal computational structure? Our primary objective is to investigate whether the model's neural dynamics encode internally decodable signals that are predictive of logical validity during code generation. Inspired by mechanistic interpretability, we propose to treat code verification as a mechanistic diagnostic task, mapping the model's explicit algorithmic trajectory into line-level attribution graphs. By decomposing complex residual flows, we aim to identify the structural signatures that distinguish sound reasoning from logical failure within the model's internal circuits. Analysis across Python, C++, and Java confirms that intrinsic correctness signals are robust across diverse syntaxes. Topological features from these internal graphs predict correctness more reliably than surface heuristics and enable targeted causal interventions to fix erroneous logic. These findings establish internal introspection as a decodable property for verifying generated code. Our code is at https:// github.com/bruno686/CodeCircuit.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u795e\u7ecf\u52a8\u6001\u7ed3\u6784\u7684\u4ee3\u7801\u6b63\u786e\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u6790\u6a21\u578b\u5185\u90e8\u7684\u7b97\u6cd5\u8f68\u8ff9\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u5b9e\u73b0\u65e0\u9700\u5916\u90e8\u6d4b\u8bd5\u6216\u8bc4\u5224\u5668\u7684\u4ee3\u7801\u529f\u80fd\u9a8c\u8bc1\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u9a8c\u8bc1\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6267\u884c\u6d4b\u8bd5\u6216\u8f85\u52a9\u7684LLM\u8bc4\u5224\u5668\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u8981\u4e48\u8d39\u529b\uff0c\u8981\u4e48\u53d7\u9650\u4e8e\u8bc4\u5224\u6a21\u578b\u80fd\u529b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4eceLLM\u81ea\u8eab\u7684\u8ba1\u7b97\u7ed3\u6784\u51fa\u53d1\uff0c\u63a2\u7d22\u5176\u5185\u90e8\u662f\u5426\u5b58\u5728\u53ef\u89e3\u7801\u7684\u529f\u80fd\u6b63\u786e\u6027\u4fe1\u53f7\uff0c\u4ece\u800c\u5b9e\u73b0\u5185\u7701\u5f0f\u7684\u4ee3\u7801\u9a8c\u8bc1\u3002", "method": "\u672c\u6587\u5c06\u4ee3\u7801\u9a8c\u8bc1\u89c6\u4e3a\u4e00\u79cd\u673a\u68b0\u8bca\u65ad\u4efb\u52a1\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u7684\u7b97\u6cd5\u8f68\u8ff9\u6620\u5c04\u4e3a\u4ee3\u7801\u7ea7\u5f52\u56e0\u56fe\uff0c\u5206\u89e3\u590d\u6742\u7684\u6b8b\u5dee\u6d41\uff0c\u8bc6\u522b\u533a\u5206\u6709\u6548\u63a8\u7406\u4e0e\u903b\u8f91\u9519\u8bef\u7684\u7ed3\u6784\u7279\u5f81\uff0c\u8fdb\u800c\u5229\u7528\u8fd9\u4e9b\u5185\u90e8\u56fe\u7684\u62d3\u6251\u7279\u5f81\u9884\u6d4b\u4ee3\u7801\u7684\u6b63\u786e\u6027\uff0c\u5e76\u8fdb\u884c\u56e0\u679c\u5e72\u9884\u4fee\u6b63\u9519\u8bef\u903b\u8f91\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\uff08Python\u3001C++\u3001Java\uff09\u4e2d\u6a21\u578b\u5185\u90e8\u7684\u6b63\u786e\u6027\u4fe1\u53f7\u5177\u6709\u9c81\u68d2\u6027\uff0c\u5229\u7528\u5185\u90e8\u7ed3\u6784\u7684\u62d3\u6251\u7279\u5f81\u6bd4\u8868\u9762\u542f\u53d1\u5f0f\u66f4\u80fd\u51c6\u786e\u9884\u6d4b\u4ee3\u7801\u6b63\u786e\u6027\uff0c\u5e76\u4e14\u53ef\u4ee5\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u7684\u56e0\u679c\u5e72\u9884\u4fee\u6b63\u9519\u8bef\u903b\u8f91\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4ee3\u7801\u751f\u6210\u8fc7\u7a0b\u4e2d\uff0c\u5176\u5185\u90e8\u795e\u7ecf\u52a8\u6001\u5305\u542b\u53ef\u9884\u6d4b\u903b\u8f91\u6b63\u786e\u6027\u7684\u4fe1\u53f7\uff0c\u8fd9\u4e9b\u4fe1\u53f7\u53ef\u4ee5\u901a\u8fc7\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u8fdb\u884c\u89e3\u7801\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u5916\u90e8\u673a\u5236\u9a8c\u8bc1\u4ee3\u7801\u6b63\u786e\u6027\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.07186", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07186", "abs": "https://arxiv.org/abs/2602.07186", "authors": ["Luoxi Tang", "Yuqiao Meng", "Joseph Costa", "Yingxue Zhang", "Muchao Ye", "Zhaohan Xi"], "title": "The Value of Variance: Mitigating Debate Collapse in Multi-Agent Systems via Uncertainty-Driven Policy Optimization", "comment": null, "summary": "Multi-agent debate (MAD) systems improve LLM reasoning through iterative deliberation, but remain vulnerable to debate collapse, a failure type where final agent decisions are compromised on erroneous reasoning. Existing methods lack principled mechanisms to detect or prevent such failures. To address this gap, we first propose a hierarchical metric that quantifies behavioral uncertainty at three levels: intra-agent (individual reasoning uncertainty), inter-agent (interactive uncertainty), and system-level (output uncertainty). Empirical analysis across several benchmarks reveals that our proposed uncertainty quantification reliably indicates system failures, which demonstrates the validity of using them as diagnostic metrics to indicate the system failure. Subsequently, we propose a mitigation strategy by formulating an uncertainty-driven policy optimization to penalize self-contradiction, peer conflict, and low-confidence outputs in a dynamic debating environment. Experiments demonstrate that our proposed uncertainty-driven mitigation reliably calibrates the multi-agent system by consistently improving decision accuracy while reducing system disagreement.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u5b58\u5728\u7684\u5931\u8d25\u68c0\u6d4b\u4e0d\u8db3\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5c42\u6b21\u5316\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u6307\u6807\u548c\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff0c\u4ece\u800c\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7684\u51b3\u7b56\u8d28\u91cf\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u5bb9\u6613\u51fa\u73b0\u8fa9\u8bba\u5d29\u6e83\uff0c\u5bfc\u81f4\u6700\u7ec8\u51b3\u7b56\u57fa\u4e8e\u9519\u8bef\u63a8\u7406\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u5931\u8d25\u68c0\u6d4b\u548c\u9884\u9632\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e09\u7ea7\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u6307\u6807\u4ece\u4e2a\u4f53\u3001\u4ea4\u4e92\u5230\u7cfb\u7edf\u5c42\u9762\u91cf\u5316\u4e0d\u786e\u5b9a\u6027\uff0c\u57fa\u4e8e\u6b64\u6784\u5efa\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u7b56\u7565\u4f18\u5316\u6846\u67b6\u6765\u60e9\u7f5a\u81ea\u6211\u77db\u76fe\u3001\u540c\u8f88\u51b2\u7a81\u548c\u4f4e\u7f6e\u4fe1\u5ea6\u8f93\u51fa\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u63d0\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u53ef\u9760\u6307\u793a\u7cfb\u7edf\u5931\u8d25\uff0c\u4e14\u4e0d\u786e\u5b9a\u6027\u9a71\u52a8\u7684\u7b56\u7565\u4f18\u5316\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u51b3\u7b56\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u5c42\u6b21\u5316\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u6307\u6807\u6709\u6548\u8bc6\u522b\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u7cfb\u7edf\u7684\u5931\u8d25\uff0c\u4e14\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u7b56\u7565\u4f18\u5316\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u51b3\u7b56\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u5206\u6b67\u3002"}}
{"id": "2602.06973", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06973", "abs": "https://arxiv.org/abs/2602.06973", "authors": ["Lucky Susanto", "Musa Izzanardi Wijanarko", "Khumaisa Nur'aini", "Farid Adilazuarda", "Alham Fikri Aji", "Derry Tanti Wijaya"], "title": "Does Visual Rendering Bypass Tokenization? Investigating Script-Tokenizer Misalignment in Pixel-Based Language Models", "comment": "Submitted to ARR January", "summary": "While pixel-based language modeling aims to bypass the sub-word tokenization bottleneck by rendering text as images, recent multimodal variants such as DualGPT reintroduce text tokenizers to improve autoregressive performance. We investigate a fundamental question, does visual rendering truly decouple a model from tokenization constraints? Focusing on four Indonesian low-resource local languages that have their own non-Latin scripts (i.e., Javanese, Balinese, Sundanese, and Lampungnese), we evaluate the impact of script-tokenizer alignment within the DualGPT architecture. Our results show that, despite visual rendering, reintegrating a text tokenizer into the architecture reintroduces the same issue that pixel-based language modeling aims to resolve, which is the tokenizer misalignment problem. Despite having lower OOV and fertility rates, we show that the Llama 2 tokenizer performs significantly worse than a custom tokenizer, with improvements of up to 30.15 chrF++. Our findings serve as a warning for future multimodal variants, as text tokenizers remain a significant barrier to equitable models.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u89c6\u89c9\u6e32\u67d3\u65e0\u6cd5\u6d88\u9664\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5206\u8bcd\u5668\u9650\u5236\uff0c\u5b9a\u5236\u5206\u8bcd\u5668\u663e\u8457\u4f18\u4e8e\u901a\u7528\u5206\u8bcd\u5668\uff0c\u5206\u8bcd\u5668\u4f9d\u7136\u662f\u591a\u6a21\u6001\u6a21\u578b\u516c\u5e73\u6027\u7684\u4e3b\u8981\u969c\u788d\u3002", "motivation": "\u63a2\u7d22\u89c6\u89c9\u6e32\u67d3\u662f\u5426\u80fd\u591f\u771f\u6b63\u4f7f\u6a21\u578b\u6446\u8131\u5206\u8bcd\u5668\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u975e\u62c9\u4e01\u811a\u672c\u8bed\u8a00\u7684\u591a\u6a21\u6001\u8bed\u8a00\u5efa\u6a21\u4e2d\u3002", "method": "\u5728\u4f7f\u7528DualGPT\u67b6\u6784\u8bc4\u4f30\u56db\u79cd\u5370\u5c3c\u4f4e\u8d44\u6e90\u672c\u5730\u8bed\u8a00\u975e\u62c9\u4e01\u5b57\u6bcd\u811a\u672c\u65f6\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u5206\u8bcd\u5668\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5c3d\u7ba1Llama 2\u5206\u8bcd\u5668\u5728\u8bcd\u5916\u7387\u548c\u7e41\u6b96\u7387\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u6027\u80fd\u663e\u8457\u4e0d\u5982\u5b9a\u5236\u5206\u8bcd\u5668\uff0c\u5b9a\u5236\u5206\u8bcd\u5668\u5728chrF++\u6307\u6807\u4e0a\u63d0\u5347\u6700\u591a\u8fbe30.15\u3002", "conclusion": "\u89c6\u89c9\u6e32\u67d3\u5e76\u672a\u771f\u6b63\u89e3\u8026\u6a21\u578b\u4e0e\u5206\u8bcd\u5668\u7684\u7ea6\u675f\uff0c\u5c06\u6587\u672c\u5206\u8bcd\u5668\u91cd\u65b0\u5f15\u5165\u591a\u6a21\u6001\u6a21\u578b\uff08\u5982DualGPT\uff09\u4e2d\u4ecd\u7136\u5b58\u5728\u5206\u8bcd\u5668\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002"}}
{"id": "2602.07083", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07083", "abs": "https://arxiv.org/abs/2602.07083", "authors": ["Yongqing Jiang", "Jianze Wang", "Zhiqi Shen", "Zhenghong Lin", "Jiayuan Wang", "Yijian Yang", "Kaoshan Dai", "Haoran Luo"], "title": "Rethinking Scientific Modeling: Toward Physically Consistent and Simulation-Executable Programmatic Generation", "comment": null, "summary": "Structural modeling is a fundamental component of computational engineering science, in which even minor physical inconsistencies or specification violations may invalidate downstream simulations. The potential of large language models (LLMs) for automatic generation of modeling code has been demonstrated. However, non-executable or physically inconsistent outputs remain prevalent under stringent engineering constraints. A framework for physics-consistent automatic building modeling is therefore proposed, integrating domain knowledge construction, constraint-oriented model alignment, and verification-driven evaluation. CivilInstruct is introduced as a domain-specific dataset that formalizes structural engineering knowledge and constraint reasoning to enable simulation-ready model generation. A two-stage fine-tuning strategy is further employed to enforce constraint satisfaction and application programming interface compliance, substantially reducing hallucinated and non-conforming outputs. MBEval is presented as a verification-driven benchmark that evaluates executability and structural dynamics consistency through closed-loop validation. Experimental results show consistent improvements over baselines across rigorous verification metrics. Our code is available at https://github.com/Jovanqing/AutoBM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9886\u57df\u77e5\u8bc6\u548c\u9a8c\u8bc1\u9a71\u52a8\u7684\u7269\u7406\u4e00\u81f4\u6027\u81ea\u52a8\u7ed3\u6784\u5efa\u6a21\u6846\u67b6\uff0c\u6210\u529f\u63d0\u5347\u4e86\u6a21\u578b\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u6267\u884c\u6027\u3002", "motivation": "\u7ed3\u6784\u5efa\u6a21\u4e2d\u7269\u7406\u4e0d\u4e00\u81f4\u6216\u89c4\u8303\u8fdd\u89c4\u4f1a\u5bfc\u81f4\u4eff\u771f\u65e0\u6548\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u4ecd\u9891\u7e41\u51fa\u73b0\u975e\u6267\u884c\u6216\u7269\u7406\u4e0d\u4e00\u81f4\u8f93\u51fa\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u4fdd\u8bc1\u7269\u7406\u4e00\u81f4\u6027\u7684\u81ea\u52a8\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5f15\u5165CivilInstruct\u7ed3\u6784\u5de5\u7a0b\u9886\u57df\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u5fae\u8c03\u7b56\u7565\u5f3a\u5316\u7ea6\u675f\u6ee1\u8db3\u548cAPI\u5408\u89c4\u6027\uff0c\u5e76\u5229\u7528MBEval\u57fa\u4e8e\u9a8c\u8bc1\u9a71\u52a8\u7684\u8bc4\u6d4b\u6807\u51c6\u8fdb\u884c\u95ed\u73af\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u4e25\u683c\u9a8c\u8bc1\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\uff0c\u751f\u6210\u7684\u6a21\u578b\u5177\u5907\u826f\u597d\u6267\u884c\u6027\u548c\u7ed3\u6784\u52a8\u6001\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u7269\u7406\u4e00\u81f4\u6027\u81ea\u52a8\u5efa\u7b51\u5efa\u6a21\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u7ed3\u6784\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u7269\u7406\u4e00\u81f4\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u975e\u6267\u884c\u6027\u548c\u7269\u7406\u4e0d\u4e00\u81f4\u8f93\u51fa\u3002"}}
{"id": "2602.07777", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.07777", "abs": "https://arxiv.org/abs/2602.07777", "authors": ["Shuhui Zhu", "Yue Lin", "Shriya Kaistha", "Wenhao Li", "Baoxiang Wang", "Hongyuan Zha", "Gillian K. Hadfield", "Pascal Poupart"], "title": "Talk, Judge, Cooperate: Gossip-Driven Indirect Reciprocity in Self-Interested LLM Agents", "comment": null, "summary": "Indirect reciprocity, which means helping those who help others, is difficult to sustain among decentralized, self-interested LLM agents without reliable reputation systems. We introduce Agentic Linguistic Gossip Network (ALIGN), an automated framework where agents strategically share open-ended gossip using hierarchical tones to evaluate trustworthiness and coordinate social norms. We demonstrate that ALIGN consistently improves indirect reciprocity and resists malicious entrants by identifying and ostracizing defectors without changing intrinsic incentives. Notably, we find that stronger reasoning capabilities in LLMs lead to more incentive-aligned cooperation, whereas chat models often over-cooperate even when strategically suboptimal. These results suggest that leveraging LLM reasoning through decentralized gossip is a promising path for maintaining social welfare in agentic ecosystems. Our code is available at https://github.com/shuhui-zhu/ALIGN.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faALIGN\u6846\u67b6\uff0c\u901a\u8fc7\u4ee3\u7406\u95f4\u7684\u53bb\u4e2d\u5fc3\u5316\u516b\u5366\u4f20\u64ad\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u7684\u95f4\u63a5\u4e92\u60e0\u548c\u9632\u5fa1\u6076\u610f\u884c\u4e3a\u7684\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5229\u7528\u63a8\u7406\u63d0\u5347\u5408\u4f5c\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u5728\u7f3a\u4e4f\u53ef\u9760\u4fe1\u8a89\u7cfb\u7edf\u7684\u53bb\u4e2d\u5fc3\u5316\u81ea\u5229\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\uff0c\u95f4\u63a5\u4e92\u60e0\u96be\u4ee5\u7ef4\u7cfb\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u4fc3\u8fdb\u5408\u4f5c\u53ca\u62b5\u6297\u6076\u610f\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86Agentic Linguistic Gossip Network (ALIGN)\u6846\u67b6\uff0c\u5229\u7528\u4ee3\u7406\u95f4\u5171\u4eab\u5f00\u653e\u5f0f\u516b\u5366\u4fe1\u606f\u548c\u5206\u5c42\u8bed\u8c03\u8bc4\u4f30\u4fe1\u8a89\u3001\u534f\u8c03\u793e\u4f1a\u89c4\u8303\uff0c\u4ece\u800c\u4fc3\u8fdb\u4fe1\u4efb\u548c\u5408\u4f5c\u3002", "result": "ALIGN\u663e\u8457\u63d0\u5347\u4e86\u95f4\u63a5\u4e92\u60e0\u7684\u6548\u679c\uff0c\u80fd\u591f\u8bc6\u522b\u5e76\u6392\u65a5\u4e0d\u5408\u4f5c\u6216\u6076\u610f\u4ee3\u7406\uff0c\u4e14\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u4f7f\u4ee3\u7406\u7684\u5408\u4f5c\u66f4\u7b26\u5408\u6fc0\u52b1\u673a\u5236\uff0c\u800c\u804a\u5929\u6a21\u578b\u5219\u5f80\u5f80\u8fc7\u5ea6\u5408\u4f5c\u3002", "conclusion": "ALIGN\u6846\u67b6\u901a\u8fc7\u5206\u5c42\u8bed\u8c03\u7684\u4f20\u64ad\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u95f4\u63a5\u4e92\u60e0\u673a\u5236\u7684\u5b9e\u73b0\uff0c\u80fd\u591f\u8bc6\u522b\u5e76\u6392\u65a5\u6076\u610f\u4e2a\u4f53\uff0c\u7ef4\u6301\u4e86\u53bb\u4e2d\u5fc3\u5316\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u7684\u793e\u4f1a\u798f\u5229\u3002"}}
{"id": "2602.06975", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06975", "abs": "https://arxiv.org/abs/2602.06975", "authors": ["R. James Cotton", "Thomas Leonard"], "title": "BiomechAgent: AI-Assisted Biomechanical Analysis Through Code-Generating Agents", "comment": null, "summary": "Markerless motion capture is making quantitative movement analysis increasingly accessible, yet analyzing the resulting data remains a barrier for clinicians without programming expertise. We present BiomechAgent, a code-generating AI agent that enables biomechanical analysis through natural language and allows users to querying databases, generating visualizations, and even interpret data without requiring users to write code. To evaluate BiomechAgent's capabilities, we developed a systematic benchmark spanning data retrieval, visualization, activity classification, temporal segmentation, and clinical reasoning. BiomechAgent achieved robust accuracy on data retrieval and visualization tasks and demonstrated emerging clinical reasoning capabilities. We used our dataset to systematically evaluate several of our design decisions. Biomechanically-informed, domain-specific instructions significantly improved performance over generic prompts, and integrating validated specialized tools for gait event detection substantially boosted accuracy on challenging spatiotemporal analysis where the base agent struggled. We also tested BiomechAgent using a local open-weight model instead of a frontier cloud based LLM and found that perform was substantially diminished in most domains other than database retrieval. In short, BiomechAgent makes the data from accessible motion capture and much more useful and accessible to end users.", "AI": {"tldr": "BiomechAgent\u662f\u4e00\u6b3e\u65e0\u9700\u7f16\u7a0b\u7684AI\u5de5\u5177\uff0c\u5e2e\u52a9\u4e34\u5e8a\u533b\u751f\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5206\u6790\u52a8\u4f5c\u6355\u6349\u6570\u636e\uff0c\u63d0\u5347\u6570\u636e\u5229\u7528\u7387\u548c\u4e34\u5e8a\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u6807\u8bb0\u65e0\u5173\u7684\u52a8\u4f5c\u6355\u6349\u6570\u636e\u5206\u6790\u5bf9\u6ca1\u6709\u7f16\u7a0b\u7ecf\u9a8c\u7684\u4e34\u5e8a\u533b\u751f\u6765\u8bf4\u4ecd\u7136\u5177\u6709\u8f83\u5927\u969c\u788d\u3002", "method": "\u63d0\u51faBiomechAgent\uff0c\u4e00\u4e2a\u57fa\u4e8e\u4ee3\u7801\u751f\u6210\u7684AI\u4ee3\u7406\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u5b9e\u73b0\u751f\u7269\u529b\u5b66\u5206\u6790\uff0c\u5305\u62ec\u6570\u636e\u5e93\u67e5\u8be2\u3001\u53ef\u89c6\u5316\u751f\u6210\u548c\u6570\u636e\u89e3\u91ca\uff0c\u65e0\u9700\u7528\u6237\u7f16\u5199\u4ee3\u7801\u3002", "result": "BiomechAgent\u5728\u6570\u636e\u68c0\u7d22\u548c\u53ef\u89c6\u5316\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8f83\u9ad8\u51c6\u786e\u6027\uff0c\u5e76\u5c55\u73b0\u4e86\u4e34\u5e8a\u63a8\u7406\u7684\u6f5c\u529b\u3002\u901a\u8fc7\u751f\u7269\u529b\u5b66\u7279\u5b9a\u6307\u4ee4\u548c\u6574\u5408\u4e13\u95e8\u5de5\u5177\u63d0\u5347\u4e86\u5206\u6790\u6027\u80fd\u3002\u4f7f\u7528\u672c\u5730\u5f00\u6e90\u6a21\u578b\u76f8\u6bd4\u4e91\u7aef\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u9664\u6570\u636e\u5e93\u68c0\u7d22\u4ee5\u5916\u7684\u9886\u57df\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "BiomechAgent\u663e\u8457\u63d0\u9ad8\u4e86\u6807\u8bb0\u65e0\u5173\u52a8\u4f5c\u6355\u6349\u6570\u636e\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u5b9e\u7528\u6027\uff0c\u4f7f\u975e\u7f16\u7a0b\u80cc\u666f\u7528\u6237\u80fd\u6709\u6548\u8fdb\u884c\u751f\u7269\u529b\u5b66\u5206\u6790\u3002"}}
{"id": "2602.07086", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07086", "abs": "https://arxiv.org/abs/2602.07086", "authors": ["Michael Marketsm\u00fcller", "Simon Martin", "Tim Schlippe"], "title": "Evaluating Retrieval-Augmented Generation Variants for Natural Language-Based SQL and API Call Generation", "comment": "preprint of conference submission", "summary": "Enterprise systems increasingly require natural language interfaces that can translate user requests into structured operations such as SQL queries and REST API calls. While large language models (LLMs) show promise for code generation [Chen et al., 2021; Huynh and Lin, 2025], their effectiveness in domain-specific enterprise contexts remains underexplored, particularly when both retrieval and modification tasks must be handled jointly. This paper presents a comprehensive evaluation of three retrieval-augmented generation (RAG) variants [Lewis et al., 2021] -- standard RAG, Self-RAG [Asai et al., 2024], and CoRAG [Wang et al., 2025] -- across SQL query generation, REST API call generation, and a combined task requiring dynamic task classification. Using SAP Transactional Banking as a realistic enterprise use case, we construct a novel test dataset covering both modalities and evaluate 18 experimental configurations under database-only, API-only, and hybrid documentation contexts. Results demonstrate that RAG is essential: Without retrieval, exact match accuracy is 0% across all tasks, whereas retrieval yields substantial gains in execution accuracy (up to 79.30%) and component match accuracy (up to 78.86%). Critically, CoRAG proves most robust in hybrid documentation settings, achieving statistically significant improvements in the combined task (10.29% exact match vs. 7.45% for standard RAG), driven primarily by superior SQL generation performance (15.32% vs. 11.56%). Our findings establish retrieval-policy design as a key determinant of production-grade natural language interfaces, showing that iterative query decomposition outperforms both top-k retrieval and binary relevance filtering under documentation heterogeneity.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5bf9\u4f01\u4e1a\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0cCoRAG\u5728\u590d\u6742\u6df7\u5408\u6587\u6863\u4e0b\u8868\u73b0\u6700\u4f18\uff0c\u663e\u8457\u63d0\u5347\u4e86SQL\u548cAPI\u8c03\u7528\u751f\u6210\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f01\u4e1a\u7cfb\u7edf\u65e5\u76ca\u9700\u8981\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u5c06\u7528\u6237\u8bf7\u6c42\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u64cd\u4f5c\uff0c\u4f46\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7279\u5b9a\u9886\u57df\u8054\u5408\u5904\u7406\u68c0\u7d22\u548c\u4fee\u6539\u4efb\u52a1\u7684\u6548\u679c\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u8bc4\u4f30\u4e86\u4e09\u79cdRAG\u53d8\u4f53\uff08\u6807\u51c6RAG\u3001Self-RAG \u548c CoRAG\uff09\u5728SQL\u67e5\u8be2\u751f\u6210\u3001REST API\u8c03\u7528\u751f\u6210\u53ca\u52a8\u6001\u4efb\u52a1\u5206\u7c7b\u7684\u8054\u5408\u4efb\u52a1\u4e0a\uff0c\u91c7\u7528SAP\u4e8b\u52a1\u6027\u94f6\u884c\u4e1a\u52a1\u4f5c\u4e3a\u5b9e\u9a8c\u7528\u4f8b\uff0c\u6784\u5efa\u4e86\u8986\u76d6\u4e24\u79cd\u6a21\u5f0f\u7684\u65b0\u6d4b\u8bd5\u6570\u636e\u96c6\uff0c\u5171\u6d4b\u8bd5\u4e8618\u79cd\u914d\u7f6e\uff0c\u5728\u6570\u636e\u5e93\u3001API\u53ca\u6df7\u5408\u6587\u6863\u73af\u5883\u4e2d\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5728\u65e0\u68c0\u7d22\u652f\u6301\u65f6\uff0c\u7cbe\u786e\u5339\u914d\u51c6\u786e\u7387\u4e3a0%\uff0c\u68c0\u7d22\u589e\u5f3a\u663e\u8457\u63d0\u5347\u6267\u884c\u51c6\u786e\u7387\uff08\u6700\u9ad879.30%\uff09\u548c\u7ec4\u4ef6\u5339\u914d\u51c6\u786e\u7387\uff08\u6700\u9ad878.86%\uff09\uff1bCoRAG\u5728\u6df7\u5408\u6587\u6863\u73af\u5883\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u8054\u5408\u4efb\u52a1\u7cbe\u786e\u5339\u914d\u63d0\u5347\u81f310.29%\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6RAG\u76847.45%\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u662f\u5b9e\u73b0\u51c6\u786e\u81ea\u7136\u8bed\u8a00\u63a5\u53e3\u7684\u5173\u952e\uff0c\u5c24\u5176\u5728\u5904\u7406\u6df7\u5408\u6587\u6863\u73af\u5883\u65f6\uff0cCoRAG\u8868\u73b0\u6700\u4f18\uff0c\u663e\u8457\u63d0\u5347\u4e86SQL\u67e5\u8be2\u548cREST API\u8c03\u7528\u7684\u751f\u6210\u51c6\u786e\u6027\u3002"}}
{"id": "2602.08389", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08389", "abs": "https://arxiv.org/abs/2602.08389", "authors": ["Yao-hua Franck Xu", "Tayeb Lemlouma", "Arnaud Braud", "Jean-Marie Bonnin"], "title": "Altruism and Fair Objective in Mixed-Motive Markov games", "comment": null, "summary": "Cooperation is fundamental for society's viability, as it enables the emergence of structure within heterogeneous groups that seek collective well-being. However, individuals are inclined to defect in order to benefit from the group's cooperation without contributing the associated costs, thus leading to unfair situations. In game theory, social dilemmas entail this dichotomy between individual interest and collective outcome. The most dominant approach to multi-agent cooperation is the utilitarian welfare which can produce efficient highly inequitable outcomes. This paper proposes a novel framework to foster fairer cooperation by replacing the standard utilitarian objective with Proportional Fairness. We introduce a fair altruistic utility for each agent, defined on the individual log-payoff space and derive the analytical conditions required to ensure cooperation in classic social dilemmas. We then extend this framework to sequential settings by defining a Fair Markov Game and deriving novel fair Actor-Critic algorithms to learn fair policies. Finally, we evaluate our method in various social dilemma environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6bd4\u4f8b\u516c\u5e73\u7684\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u516c\u5e73\u5229\u4ed6\u6548\u7528\u548c\u516c\u5e73\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\uff0c\u89e3\u51b3\u4e86\u793e\u4ea4\u56f0\u5883\u4e2d\u7684\u516c\u5e73\u6027\u95ee\u9898\uff0c\u5e76\u8bbe\u8ba1\u516c\u5e73\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u8fdb\u884c\u7b56\u7565\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u65b9\u6cd5\u4ee5\u529f\u5229\u4e3b\u4e49\u798f\u5229\u4e3a\u76ee\u6807\uff0c\u5bb9\u6613\u5bfc\u81f4\u9ad8\u6548\u4f46\u6781\u4e0d\u516c\u5e73\u7684\u7ed3\u679c\u3002", "method": "\u63d0\u51fa\u4ee5\u6bd4\u4f8b\u516c\u5e73\u4e3a\u76ee\u6807\u7684\u516c\u5e73\u5229\u4ed6\u6548\u7528\u51fd\u6570\uff0c\u5206\u6790\u786e\u4fdd\u5408\u4f5c\u7684\u6761\u4ef6\uff0c\u6269\u5c55\u5230\u6709\u5e8f\u60c5\u666f\uff0c\u6784\u5efa\u516c\u5e73\u9a6c\u5c14\u53ef\u592b\u535a\u5f08\u53ca\u516c\u5e73Actor-Critic\u7b97\u6cd5\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u591a\u4e2a\u793e\u4ea4\u56f0\u5883\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u66f4\u516c\u5e73\u7684\u5408\u4f5c\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u6bd4\u4f8b\u516c\u5e73\u66ff\u4ee3\u529f\u5229\u4e3b\u4e49\u6307\u6807\uff0c\u63a8\u52a8\u4e86\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u6548\u7387\u4e0e\u516c\u5e73\u7684\u77db\u76fe\u3002"}}
{"id": "2602.06976", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.06976", "abs": "https://arxiv.org/abs/2602.06976", "authors": ["Chen Shen", "Wei Cheng", "Jingyue Yang", "Huan Zhang", "Yuhan Wu", "Wei Hu"], "title": "Bridging the Knowledge Void: Inference-time Acquisition of Unfamiliar Programming Languages for Coding Tasks", "comment": null, "summary": "The proficiency of Large Language Models (LLMs) in coding tasks is often a reflection of their extensive pre-training corpora, which typically collapses when confronted with previously unfamiliar programming languages. Departing from data-intensive finetuning, we investigate the paradigm of Inference-time Language Acquisition (ILA), where an LLM masters an unfamiliar language through dynamic interaction with limited external resources. In this paper, we propose ILA-agent, a general ILA framework that equips LLMs with a set of behavioral primitives. By modeling essential human-like behaviors as a suite of tools, ILA-agent enables LLMs to incrementally explore, apply, and verify language knowledge through structured interactions with the official documentation and execution environment. To provide a rigorous evaluation in a low-resource setting, we construct Cangjie-bench, a multi-task benchmark based on the novel statically-typed language Cangjie. We instantiate ILA-agent for Cangjie and evaluate its performance across code generation, translation, and program repair tasks. Results using diverse LLMs demonstrate that ILA-agent significantly outperforms retrieval-augmented baselines. Further analysis of agent trajectories characterizes the emergent behavior patterns while highlighting persisting performance gaps.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faILA-agent\uff0c\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u52a8\u6001\u4e92\u52a8\u5b66\u4e60\u672a\u77e5\u8bed\u8a00\uff0c\u5728Cangjie\u8bed\u8a00\u57fa\u51c6\u4e0a\u83b7\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u975e\u6570\u636e\u5bc6\u96c6\u578b\u8bed\u8a00\u4e60\u5f97\u7684\u65b0\u8def\u5f84\u3002", "motivation": "\u4f20\u7edf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u672a\u77e5\u7f16\u7a0b\u8bed\u8a00\u9002\u5e94\u6027\u5dee\uff0c\u6545\u63a2\u7a76\u5728\u63a8\u7406\u65f6\u901a\u8fc7\u6709\u9650\u5916\u90e8\u8d44\u6e90\u5b66\u4e60\u65b0\u8bed\u8a00\u7684\u65b0\u8303\u5f0f\u3002", "method": "\u63d0\u51faILA-agent\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u4eba\u7c7b\u884c\u4e3a\u4f5c\u4e3a\u5de5\u5177\uff0c\u5141\u8bb8\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u52a8\u6001\u4ea4\u4e92\u5b98\u65b9\u6587\u6863\u548c\u6267\u884c\u73af\u5883\uff0c\u9010\u6b65\u638c\u63e1\u65b0\u8bed\u8a00\u3002", "result": "\u5728\u65b0\u9896\u7684\u9759\u6001\u7c7b\u578b\u8bed\u8a00Cangjie\u53ca\u5176\u591a\u4efb\u52a1\u57fa\u51c6Cangjie-bench\u4e0a\uff0cILA-agent\u5728\u4ee3\u7801\u751f\u6210\u3001\u7ffb\u8bd1\u548c\u7a0b\u5e8f\u4fee\u590d\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8fc7\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u3002", "conclusion": "ILA-agent\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u672a\u77e5\u7f16\u7a0b\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4f46\u4f9d\u7136\u5b58\u5728\u6027\u80fd\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2602.07147", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07147", "abs": "https://arxiv.org/abs/2602.07147", "authors": ["Marco De Luca", "Michele Perlotto", "Anna Rita Fasolino", "Porfirio Tramontana"], "title": "Architectural Anti-Patterns in Student-Developed Microservice Architectures: An Exploratory Study", "comment": null, "summary": "Teaching microservice architectures is challenging due to distributed complexity and the gap between academia and industry. Understanding the quality issues students introduce in MSAs is essential to improve education. This study analyzes student-developed microservices using an established anti-pattern taxonomy and derives lessons learned with actionable teaching recommendations. We conducted a longitudinal, project-based course (2023-2025) involving 216 Master's students (67 teams) who designed and deployed a realistic, containerized MSA for a gamified testing platform. The final systems revealed 23 out of 58 known MSA anti-patterns, spanning five categories. Security issues were most frequent, highlighting weaknesses in authentication, authorization, and data protection. Team Organization and Service Interaction problems followed, reflecting limited DevOps experience and difficulties in inter-service coordination. Fewer issues appeared in Intra-service Design and Inter-service Decomposition, suggesting students generally defined service boundaries well. Overall, students prioritized feature delivery over robustness and operational discipline. To address this, we recommend enforcing minimal standards (API contracts, gateways), providing labs on resilient communication, integrating security-by-design practices, and offering CI-CD templates. The paper contributes a realistic, full-scale educational experience and a replicable model for teaching industry-aligned microservice architecture.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5b66\u751f\u7684\u5fae\u670d\u52a1\u9879\u76ee\u63ed\u793a\u4e86\u5e38\u89c1\u53cd\u6a21\u5f0f\uff0c\u5c24\u5176\u662f\u5b89\u5168\u548c\u534f\u4f5c\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u6539\u8fdb\u6559\u5b66\u7684\u5177\u4f53\u5efa\u8bae\uff0c\u4fc3\u8fdb\u5b66\u4e1a\u4e0e\u5de5\u4e1a\u5b9e\u8df5\u7684\u7ed3\u5408\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u6559\u5b66\u9762\u4e34\u5206\u5e03\u5f0f\u7cfb\u7edf\u590d\u6742\u6027\u53ca\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u5dee\u8ddd\uff0c\u7406\u89e3\u5b66\u751f\u5f15\u5165\u7684\u8d28\u91cf\u95ee\u9898\u6709\u52a9\u4e8e\u6539\u8fdb\u6559\u5b66\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u4e3a\u671f\u591a\u5e74\u7684\u9879\u76ee\u9a71\u52a8\u8bfe\u7a0b\uff0c\u5206\u6790216\u540d\u7855\u58eb\u751f\u8bbe\u8ba1\u548c\u90e8\u7f72\u7684\u771f\u5b9e\u5bb9\u5668\u5316\u5fae\u670d\u52a1\u7cfb\u7edf\uff0c\u5229\u7528\u5df2\u77e5\u53cd\u6a21\u5f0f\u5206\u7c7b\u6cd5\u8bc6\u522b\u95ee\u9898\u3002", "result": "\u5b66\u751f\u8bbe\u8ba1\u7684\u7cfb\u7edf\u4e2d\u53d1\u73b023\u79cd\u5df2\u77e5\u53cd\u6a21\u5f0f\uff0c\u4e3b\u8981\u96c6\u4e2d\u5728\u5b89\u5168\u3001\u56e2\u961f\u7ec4\u7ec7\u548c\u670d\u52a1\u4ea4\u4e92\uff0c\u5c11\u6570\u6d89\u53ca\u670d\u52a1\u5185\u90e8\u8bbe\u8ba1\u548c\u5206\u89e3\u3002", "conclusion": "\u5b66\u751f\u5728\u5fae\u670d\u52a1\u67b6\u6784\u8bbe\u8ba1\u4e2d\u666e\u904d\u5b58\u5728\u5b89\u5168\u6027\u3001\u56e2\u961f\u534f\u4f5c\u548c\u670d\u52a1\u4ea4\u4e92\u65b9\u9762\u7684\u95ee\u9898\uff0c\u5f3a\u8c03\u529f\u80fd\u4ea4\u4ed8\u4f18\u5148\u4e8e\u7cfb\u7edf\u9c81\u68d2\u6027\u548c\u8fd0\u7ef4\u7eaa\u5f8b\u6027\u3002"}}
{"id": "2602.08529", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08529", "abs": "https://arxiv.org/abs/2602.08529", "authors": ["Ning Lin", "Haolun Li", "Mingshu Liu", "Chengyun Ruan", "Kaibo Huang", "Yukun Wei", "Zhongliang Yang", "Linna Zhou"], "title": "EvoCorps: An Evolutionary Multi-Agent Framework for Depolarizing Online Discourse", "comment": null, "summary": "Polarization in online discourse erodes social trust and accelerates misinformation, yet technical responses remain largely diagnostic and post-hoc. Current governance approaches suffer from inherent latency and static policies, struggling to counter coordinated adversarial amplification that evolves in real-time. We present EvoCorps, an evolutionary multi-agent framework for proactive depolarization. EvoCorps frames discourse governance as a dynamic social game and coordinates roles for monitoring, planning, grounded generation, and multi-identity diffusion. A retrieval-augmented collective cognition core provides factual grounding and action--outcome memory, while closed-loop evolutionary learning adapts strategies as the environment and attackers change. We implement EvoCorps on the MOSAIC social-AI simulation platform for controlled evaluation in a multi-source news stream with adversarial injection and amplification. Across emotional polarization, viewpoint extremity, and argumentative rationality, EvoCorps improves discourse outcomes over an adversarial baseline, pointing to a practical path from detection and post-hoc mitigation to in-process, closed-loop intervention. The code is available at https://github.com/ln2146/EvoCorps.", "AI": {"tldr": "EvoCorps\u63d0\u51fa\u57fa\u4e8e\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u7684\u4e3b\u52a8\u53bb\u6781\u5316\u6846\u67b6\uff0c\u52a8\u6001\u9002\u5e94\u654c\u5bf9\u884c\u4e3a\uff0c\u901a\u8fc7\u95ed\u73af\u5b66\u4e60\u663e\u8457\u6539\u5584\u7ebf\u4e0a\u8bdd\u8bed\u751f\u6001\u3002", "motivation": "\u5f53\u524d\u7ebf\u4e0a\u8bdd\u8bed\u6781\u5316\u52a0\u5267\u793e\u4f1a\u4fe1\u4efb\u6d41\u5931\u548c\u4fe1\u606f\u8bef\u5bfc\uff0c\u4f46\u73b0\u6709\u6280\u672f\u6cbb\u7406\u65b9\u6cd5\u591a\u4e3a\u4e8b\u540e\u8bca\u65ad\uff0c\u96be\u4ee5\u5e94\u5bf9\u5b9e\u65f6\u53d8\u5316\u4e14\u534f\u540c\u7684\u654c\u5bf9\u653e\u5927\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u7684\u6846\u67b6\uff0c\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u7684\u96c6\u4f53\u8ba4\u77e5\u6838\u5fc3\u548c\u95ed\u73af\u8fdb\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u52a8\u6001\u7684\u591a\u8eab\u4efd\u76d1\u63a7\u3001\u89c4\u5212\u3001\u751f\u6210\u4e0e\u6269\u6563\u7b56\u7565\u3002", "result": "\u901a\u8fc7\u5728MOSAIC\u793e\u4ea4AI\u6a21\u62df\u5e73\u53f0\u4e0a\u7684\u591a\u6e90\u65b0\u95fb\u6d41\u654c\u5bf9\u6ce8\u5165\u5b9e\u9a8c\uff0cEvoCorps\u76f8\u8f83\u5bf9\u6297\u57fa\u7ebf\u5728\u63a7\u5236\u60c5\u7eea\u6781\u5316\u3001\u89c2\u70b9\u6781\u7aef\u548c\u63d0\u5347\u8bba\u8fa9\u7406\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "EvoCorps\u6709\u6548\u63d0\u5347\u4e86\u7ebf\u4e0a\u8bdd\u8bed\u73af\u5883\u7684\u8d28\u91cf\uff0c\u901a\u8fc7\u4e3b\u52a8\u5e72\u9884\u51cf\u5c11\u4e86\u60c5\u7eea\u6781\u5316\u548c\u89c2\u70b9\u6781\u7aef\u5316\uff0c\u63d0\u9ad8\u4e86\u8bba\u8bc1\u7684\u7406\u6027\u6c34\u5e73\u3002"}}
{"id": "2602.07120", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07120", "abs": "https://arxiv.org/abs/2602.07120", "authors": ["Jacqueline He", "Jonathan Hayase", "Wen-tau Yih", "Sewoong Oh", "Luke Zettlemoyer", "Pang Wei Koh"], "title": "Anchored Decoding: Provably Reducing Copyright Risk for Any Language Model", "comment": "51 pages, 12 figures, 16 tables. Code is publicly available at https://github.com/jacqueline-he/anchored-decoding", "summary": "Modern language models (LMs) tend to memorize portions of their training data and emit verbatim spans. When the underlying sources are sensitive or copyright-protected, such reproduction raises issues of consent and compensation for creators and compliance risks for developers. We propose Anchored Decoding, a plug-and-play inference-time method for suppressing verbatim copying: it enables decoding from any risky LM trained on mixed-license data by keeping generation in bounded proximity to a permissively trained safe LM. Anchored Decoding adaptively allocates a user-chosen information budget over the generation trajectory and enforces per-step constraints that yield a sequence-level guarantee, enabling a tunable risk-utility trade-off. To make Anchored Decoding practically useful, we introduce a new permissively trained safe model (TinyComma 1.8B), as well as Anchored$_{\\mathrm{Byte}}$ Decoding, a byte-level variant of our method that enables cross-vocabulary fusion via the ByteSampler framework (Hayase et al., 2025). We evaluate our methods across six model pairs on long-form evaluations of copyright risk and utility. Anchored and Anchored$_{\\mathrm{Byte}}$ Decoding define a new Pareto frontier, preserving near-original fluency and factuality while eliminating up to 75% of the measurable copying gap (averaged over six copying metrics) between the risky baseline and a safe reference, at a modest inference overhead.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faAnchored Decoding\u65b9\u6cd5\uff0c\u6709\u6548\u6291\u5236\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u9010\u5b57\u590d\u5236\u95ee\u9898\uff0c\u51cf\u5c11\u7248\u6743\u98ce\u9669\uff0c\u4fdd\u6301\u6587\u672c\u8d28\u91cf\uff0c\u5177\u5907\u826f\u597d\u7684\u98ce\u9669\u4e0e\u6548\u7528\u5e73\u8861\u3002", "motivation": "\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u9010\u5b57\u590d\u5236\u654f\u611f\u6216\u53d7\u7248\u6743\u4fdd\u62a4\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u5e26\u6765\u521b\u4f5c\u8005\u540c\u610f\u3001\u8865\u507f\u53ca\u5f00\u53d1\u8005\u5408\u89c4\u98ce\u9669\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u5728\u4fdd\u8bc1\u6587\u672c\u8d28\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u9010\u5b57\u590d\u5236\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAnchored Decoding\u7684\u63a8\u7406\u65f6\u63d2\u62d4\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ea6\u675f\u751f\u6210\u6587\u672c\u5728\u4e00\u4e2a\u5b89\u5168\u8bb8\u53ef\u8bed\u8a00\u6a21\u578b\u7684\u90bb\u8fd1\u8303\u56f4\u5185\uff0c\u4ece\u800c\u9650\u5236\u9010\u5b57\u590d\u5236\uff1b\u540c\u65f6\u5f15\u5165\u4e86\u4fe1\u606f\u9884\u7b97\u548c\u9010\u6b65\u7ea6\u675f\u5b9e\u73b0\u5e8f\u5217\u7ea7\u4fdd\u8bc1\uff1b\u5f00\u53d1\u4e86\u4e00\u4e2a\u8bb8\u53ef\u8bad\u7ec3\u5b89\u5168\u6a21\u578b\uff08TinyComma 1.8B\uff09\u53ca\u5b57\u8282\u7ea7\u53d8\u4f53Anchored$_{\\mathrm{Byte}}$ Decoding\uff0c\u7ed3\u5408ByteSampler\u6846\u67b6\u5b9e\u73b0\u8de8\u8bcd\u6c47\u878d\u5408\u3002", "result": "\u5728\u516d\u4e2a\u6a21\u578b\u5bf9\u4e0a\u8fdb\u884c\u957f\u6587\u672c\u8bc4\u4f30\uff0cAnchored Decoding\u53ca\u5176\u5b57\u8282\u7ea7\u53d8\u4f53\u5728\u51cf\u5c11\u53ef\u6d4b\u590d\u5236\u7387\u65b9\u9762\u5e73\u5747\u964d\u4f4e\u4e8675%\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u4e14\u4fdd\u6301\u4e86\u63a5\u8fd1\u539f\u59cb\u6a21\u578b\u7684\u6587\u672c\u6d41\u7545\u5ea6\u548c\u4e8b\u5b9e\u6b63\u786e\u6027\uff0c\u63a8\u7406\u5f00\u9500\u9002\u4e2d\u3002", "conclusion": "Anchored Decoding\u53ca\u5176\u53d8\u4f53Anchored$_{\\mathrm{Byte}}$ Decoding\u6210\u529f\u6291\u5236\u4e86\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7684\u9010\u5b57\u590d\u5236\u73b0\u8c61\uff0c\u5728\u4fdd\u6301\u6587\u672c\u6d41\u7545\u6027\u548c\u4e8b\u5b9e\u6027\u7684\u540c\u65f6\uff0c\u5927\u5e45\u5ea6\u51cf\u5c11\u4e86\u7248\u6743\u98ce\u9669\uff0c\u8fbe\u5230\u4e86\u98ce\u9669\u4e0e\u6548\u7528\u7684\u4f18\u826f\u5e73\u8861\u3002"}}
{"id": "2602.07182", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07182", "abs": "https://arxiv.org/abs/2602.07182", "authors": ["Maximilian Vierlboeck", "Antonio Pugliese", "Roshanak Nilchian", "Paul Grogan", "Rashika Sugganahalli Natesh Babu"], "title": "Measuring Complexity at the Requirements Stage: Spectral Metrics as Development Effort Predictors", "comment": "16 pages, 3 figures, 5 tables", "summary": "Complexity in engineered systems presents one of the most persistent challenges in modern development since it is driving cost overruns, schedule delays, and outright project failures. Yet while architectural complexity has been studied, the structural complexity embedded within requirements specifications remains poorly understood and inadequately quantified. This gap is consequential: requirements fundamentally drive system design, and complexity introduced at this stage propagates through architecture, implementation, and integration. To address this gap, we build on Natural Language Processing methods that extract structural networks from textual requirements. Using these extracted structures, we conducted a controlled experiment employing molecular integration tasks as structurally isomorphic proxies for requirements integration - leveraging the topological equivalence between molecular graphs and requirement networks while eliminating confounding factors such as domain expertise and semantic ambiguity. Our results demonstrate that spectral measures predict integration effort with correlations exceeding 0.95, while structural metrics achieve correlations above 0.89. Notably, density-based metrics show no significant predictive validity. These findings indicate that eigenvalue-derived measures capture cognitive and effort dimensions that simpler connectivity metrics cannot. As a result, this research bridges a critical methodological gap between architectural complexity analysis and requirements engineering practice, providing a validated foundation for applying these metrics to requirements engineering, where similar structural complexity patterns may predict integration effort.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u5904\u7406\u63d0\u53d6\u9700\u6c42\u7ed3\u6784\u7f51\u7edc\uff0c\u5229\u7528\u5206\u5b50\u56fe\u4ee3\u7406\u5b9e\u9a8c\uff0c\u53d1\u73b0\u8c31\u6d4b\u5ea6\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7ed3\u6784\u6307\u6807\uff0c\u80fd\u591f\u51c6\u786e\u9884\u6d4b\u9700\u6c42\u96c6\u6210\u5de5\u4f5c\u91cf\uff0c\u4e3a\u9700\u6c42\u5de5\u7a0b\u4e2d\u7684\u590d\u6742\u5ea6\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\u57fa\u7840\u3002", "motivation": "\u9700\u6c42\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u590d\u6742\u5ea6\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u548c\u91cf\u5316\uff0c\u7136\u800c\u9700\u6c42\u590d\u6742\u5ea6\u76f4\u63a5\u5f71\u54cd\u7cfb\u7edf\u8bbe\u8ba1\u548c\u540e\u7eed\u96c6\u6210\u5de5\u4f5c\uff0c\u7814\u7a76\u8be5\u95ee\u9898\u6709\u52a9\u4e8e\u63d0\u5347\u9700\u6c42\u5de5\u7a0b\u5b9e\u8df5\u7684\u6709\u6548\u6027\u3002", "method": "\u5229\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u65b9\u6cd5\u63d0\u53d6\u9700\u6c42\u6587\u672c\u4e2d\u7684\u7ed3\u6784\u7f51\u7edc\uff0c\u5e76\u901a\u8fc7\u5206\u5b50\u56fe\u4f5c\u4e3a\u4e0e\u9700\u6c42\u7ed3\u6784\u540c\u6784\u7684\u4ee3\u7406\uff0c\u8bbe\u8ba1\u5bf9\u6bd4\u5b9e\u9a8c\u9a8c\u8bc1\u591a\u79cd\u7ed3\u6784\u590d\u6742\u5ea6\u6307\u6807\u5bf9\u96c6\u6210\u5de5\u4f5c\u91cf\u7684\u9884\u6d4b\u80fd\u529b\u3002", "result": "\u8c31\u6d4b\u5ea6\u4e0e\u96c6\u6210\u5de5\u4f5c\u91cf\u7684\u76f8\u5173\u6027\u8d85\u8fc70.95\uff0c\u7ed3\u6784\u5ea6\u91cf\u76f8\u5173\u6027\u8d85\u8fc70.89\uff0c\u5bc6\u5ea6\u6307\u6807\u65e0\u9884\u6d4b\u6548\u5ea6\uff0c\u8868\u660e\u8c31\u6d4b\u5ea6\u66f4\u80fd\u6709\u6548\u523b\u753b\u8ba4\u77e5\u548c\u5de5\u4f5c\u91cf\u7ef4\u5ea6\u3002", "conclusion": "\u7279\u5f81\u8c31\u6d4b\u5ea6\u53ef\u4ee5\u51c6\u786e\u9884\u6d4b\u9700\u6c42\u96c6\u6210\u5de5\u4f5c\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u7ed3\u6784\u5ea6\u91cf\uff0c\u8868\u660e\u9700\u6c42\u4e2d\u7684\u7ed3\u6784\u590d\u6742\u5ea6\u663e\u8457\u5f71\u54cd\u96c6\u6210\u96be\u5ea6\u3002"}}
{"id": "2602.08567", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08567", "abs": "https://arxiv.org/abs/2602.08567", "authors": ["Jinnuo Liu", "Chuke Liu", "Hua Shen"], "title": "ValueFlow: Measuring the Propagation of Value Perturbations in Multi-Agent LLM Systems", "comment": "Preprint. Under review. 18 pages, 9 figures", "summary": "Multi-agent large language model (LLM) systems increasingly consist of agents that observe and respond to one another's outputs. While value alignment is typically evaluated for isolated models, how value perturbations propagate through agent interactions remains poorly understood. We present ValueFlow, a perturbation-based evaluation framework for measuring and analyzing value drift in multi-agent systems. ValueFlow introduces a 56-value evaluation dataset derived from the Schwartz Value Survey and quantifies agents' value orientations during interaction using an LLM-as-a-judge protocol. Building on this measurement layer, ValueFlow decomposes value drift into agent-level response behavior and system-level structural effects, operationalized by two metrics: beta-susceptibility, which measures an agent's sensitivity to perturbed peer signals, and system susceptibility (SS), which captures how node-level perturbations affect final system outputs. Experiments across multiple model backbones, prompt personas, value dimensions, and network structures show that susceptibility varies widely across values and is strongly shaped by structural topology.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faValueFlow\u6846\u67b6\uff0c\u901a\u8fc7\u6270\u52a8\u8bc4\u4f30\u548c\u6307\u6807\u5206\u6790\uff0c\u63ed\u793a\u591a\u667a\u80fd\u4f53\u8bed\u8a00\u6a21\u578b\u4e2d\u4ef7\u503c\u89c2\u6f02\u79fb\u7684\u4f20\u64ad\u673a\u5236\u53ca\u7ed3\u6784\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u4e2d\uff0c\u4ef7\u503c\u89c2\u7684\u76f8\u4e92\u5f71\u54cd\u548c\u4f20\u9012\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86ValueFlow\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u6270\u52a8\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5229\u752856\u4e2a\u4ef7\u503c\u7ef4\u5ea6\u6570\u636e\u96c6\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u7684\u534f\u8bae\uff0c\u91cf\u5316\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u4ef7\u503c\u89c2\u6f02\u79fb\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u6307\u6807(beta-susceptibility\u548csystem susceptibility)\u5206\u89e3\u5206\u6790\u4ef7\u503c\u6f02\u79fb\u7684\u4e2a\u4f53\u884c\u4e3a\u548c\u7cfb\u7edf\u7ed3\u6784\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0d\u540c\u4ef7\u503c\u89c2\u5bf9\u6270\u52a8\u7684\u654f\u611f\u5ea6\u5dee\u5f02\u663e\u8457\uff0c\u4e14\u7cfb\u7edf\u7684\u7ed3\u6784\u62d3\u6251\u5bf9\u4ef7\u503c\u89c2\u6f02\u79fb\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "ValueFlow\u4e3a\u591a\u667a\u80fd\u4f53\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4ef7\u503c\u89c2\u6f02\u79fb\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u6d4b\u91cf\u4e0e\u5206\u6790\u5de5\u5177\uff0c\u6709\u52a9\u4e8e\u7406\u89e3\u548c\u63a7\u5236\u4ef7\u503c\u89c2\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u7684\u4f20\u64ad\u89c4\u5f8b\u3002"}}
{"id": "2602.07160", "categories": ["cs.CL", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.07160", "abs": "https://arxiv.org/abs/2602.07160", "authors": ["Jiecheng Lu", "Shihao Yang"], "title": "Free Energy Mixer", "comment": "Camera-ready version. Accepted at ICLR 2026", "summary": "Standard attention stores keys/values losslessly but reads them via a per-head convex average, blocking channel-wise selection. We propose the Free Energy Mixer (FEM): a free-energy (log-sum-exp) read that applies a value-driven, per-channel log-linear tilt to a fast prior (e.g., from queries/keys in standard attention) over indices. Unlike methods that attempt to improve and enrich the $(q,k)$ scoring distribution, FEM treats it as a prior and yields a value-aware posterior read at unchanged complexity, smoothly moving from averaging to per-channel selection as the learnable inverse temperature increases, while still preserving parallelism and the original asymptotic complexity ($O(T^2)$ for softmax; $O(T)$ for linearizable variants). We instantiate a two-level gated FEM that is plug-and-play with standard and linear attention, linear RNNs and SSMs. It consistently outperforms strong baselines on NLP, vision, and time-series at matched parameter budgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFree Energy Mixer\uff0c\u4e00\u79cd\u53ef\u5728\u901a\u9053\u5c42\u9762\u8fdb\u884c\u9009\u62e9\u7684\u9ad8\u6548\u6ce8\u610f\u529b\u8bfb\u5199\u673a\u5236\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u4e14\u4e0d\u589e\u52a0\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e8f\u5217\u6a21\u578b\u548c\u4efb\u52a1\u3002", "motivation": "\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u901a\u8fc7\u5934\u90e8\u51f8\u5e73\u5747\u8bfb\u53d6\u952e\u503c\uff0c\u963b\u788d\u4e86\u901a\u9053\u5c42\u9762\u7684\u9009\u62e9\u80fd\u529b\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8868\u8fbe\u529b\u3002\u672c\u6587\u65e8\u5728\u5f15\u5165\u4e00\u79cd\u80fd\u5728\u901a\u9053\u5c42\u9762\u8fdb\u884c\u66f4\u7075\u6d3b\u9009\u62e9\u4e14\u590d\u6742\u5ea6\u4e0d\u589e\u7684\u65b9\u6cd5\u3002", "method": "FEM \u4f7f\u7528\u81ea\u7531\u80fd\uff08log-sum-exp\uff09\u8bfb\u53d6\uff0c\u901a\u8fc7\u5b66\u4e60\u7684\u9006\u6e29\u5ea6\u53c2\u6570\u5bf9\u5148\u9a8c\u5206\u5e03\u8fdb\u884c\u5bf9\u6570\u7ebf\u6027\u8c03\u6574\uff0c\u5b9e\u73b0\u4ece\u5e73\u5747\u8bfb\u53d6\u5230\u9010\u901a\u9053\u9009\u62e9\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002\u65b9\u6cd5\u517c\u5bb9\u591a\u79cd\u6ce8\u610f\u529b\u548c\u5e8f\u5217\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u53cc\u5c42\u95e8\u63a7\u7ed3\u6784\uff0c\u652f\u6301\u6807\u51c6\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u3001\u7ebf\u6027RNN\u53caSSM\u3002", "result": "\u5728\u63a7\u5236\u53c2\u6570\u6570\u91cf\u76f8\u540c\u60c5\u51b5\u4e0b\uff0cFEM \u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u65f6\u95f4\u5e8f\u5217\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u548c\u901a\u7528\u6027\u3002", "conclusion": "Free Energy Mixer (FEM) \u63d0\u51fa\u4e86\u4e00\u79cd\u4ef7\u503c\u9a71\u52a8\u7684\u5bf9\u901a\u9053\u8fdb\u884c\u9009\u62e9\u7684\u8bfb\u64cd\u4f5c\u65b9\u6cd5\uff0c\u76f8\u8f83\u4e8e\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u7684\u51f8\u5e73\u5747\uff0cFEM \u80fd\u591f\u5b9e\u73b0\u66f4\u7ec6\u7c92\u5ea6\u7684\u901a\u9053\u9009\u62e9\uff0c\u5e76\u4e14\u4fdd\u6301\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0d\u53d8\u3002"}}
{"id": "2602.07195", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07195", "abs": "https://arxiv.org/abs/2602.07195", "authors": ["Bihui Jin", "Kaiyuan Wang", "Pengyu Nie"], "title": "Automated Modernization of Machine Learning Engineering Notebooks for Reproducibility", "comment": null, "summary": "Interactive computational notebooks (e.g., Jupyter notebooks) are widely used in machine learning engineering (MLE) to program and share end-to-end pipelines, from data preparation to model training and evaluation. However, environment erosion-the rapid evolution of hardware and software ecosystems for machine learning-has rendered many published MLE notebooks non-reproducible in contemporary environments, hindering code reuse and scientific progress. To quantify this gap, we study 12,720 notebooks mined from 79 popular Kaggle competitions: only 35.4% remain reproducible today. Crucially, we find that environment backporting, i.e., downgrading dependencies to match the submission time, does not improve reproducibility but rather introduces additional failure modes.\n  To address environment erosion, we design and implement MLEModernizer, an LLM-driven agentic framework that treats the contemporary environment as a fixed constraint and modernizes notebook code to restore reproducibility. MLEModernizer iteratively executes notebooks, collects execution feedback, and applies targeted fixes in three types: error-repair, runtime-reduction, and score-calibration. Evaluated on 7,402 notebooks that are non-reproducible under the baseline environment, MLEModernizer makes 5,492 (74.2%) reproducible. MLEModernizer enables practitioners to validate, reuse, and maintain MLE artifacts as the hardware and software ecosystems continue to evolve.", "AI": {"tldr": "\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\u56e0\u73af\u5883\u66f4\u65b0\u5bfc\u81f4\u4e0d\u53ef\u590d\u73b0\u7684\u95ee\u9898\uff0c\u63d0\u51faMLEModernizer\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4fee\u590d\u4e0e\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u7b14\u8bb0\u672c\u590d\u73b0\u7387\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u4e2d\u7684\u4ea4\u4e92\u5f0f\u8ba1\u7b97\u7b14\u8bb0\u672c\u56e0\u786c\u4ef6\u8f6f\u4ef6\u73af\u5883\u5feb\u901f\u53d8\u5316\u5bfc\u81f4\u96be\u4ee5\u590d\u73b0\uff0c\u963b\u788d\u4e86\u4ee3\u7801\u590d\u7528\u548c\u79d1\u5b66\u8fdb\u6b65\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684MLEModernizer\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u6267\u884c\u7b14\u8bb0\u672c\u3001\u6536\u96c6\u53cd\u9988\u5e76\u8fdb\u884c\u9519\u8bef\u4fee\u590d\u3001\u8fd0\u884c\u65f6\u4f18\u5316\u548c\u8bc4\u5206\u6821\u51c6\uff0c\u63d0\u5347\u7b14\u8bb0\u672c\u7684\u590d\u73b0\u7387\u3002", "result": "\u57287,402\u4e2a\u521d\u59cb\u4e0d\u53ef\u590d\u73b0\u7684\u7b14\u8bb0\u672c\u4e2d\uff0cMLEModernizer\u4f7f\u5f9774.2%\uff085,492\u4e2a\uff09\u7b14\u8bb0\u672c\u6062\u590d\u4e86\u590d\u73b0\u80fd\u529b\u3002", "conclusion": "MLEModernizer\u6709\u6548\u7f13\u89e3\u4e86\u73af\u5883\u4fb5\u8680\u95ee\u9898\uff0c\u5e2e\u52a9\u4ece\u4e1a\u8005\u7ef4\u62a4\u548c\u590d\u7528\u673a\u5668\u5b66\u4e60\u7b14\u8bb0\u672c\uff0c\u5b9e\u73b0\u4e86\u8de8\u73af\u5883\u7684\u4ee3\u7801\u590d\u73b0\u3002"}}
{"id": "2602.08938", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.08938", "abs": "https://arxiv.org/abs/2602.08938", "authors": ["Tuo Zhang", "Leonardo Stella"], "title": "Teaching an Old Dynamics New Tricks: Regularization-free Last-iterate Convergence in Zero-sum Games via BNN Dynamics", "comment": null, "summary": "Zero-sum games are a fundamental setting for adversarial training and decision-making in multi-agent learning (MAL). Existing methods often ensure convergence to (approximate) Nash equilibria by introducing a form of regularization. Yet, regularization requires additional hyperparameters, which must be carefully tuned--a challenging task when the payoff structure is known, and considerably harder when the structure is unknown or subject to change. Motivated by this problem, we repurpose a classical model in evolutionary game theory, i.e., the Brown-von Neumann-Nash (BNN) dynamics, by leveraging the intrinsic convergence of this dynamics in zero-sum games without regularization, and provide last-iterate convergence guarantees in noisy normal-form games (NFGs). Importantly, to make this approach more applicable, we develop a novel framework with theoretical guarantees that integrates the BNN dynamics in extensive-form games (EFGs) through counterfactual weighting. Furthermore, we implement an algorithm that instantiates our framework with neural function approximation, enabling scalable learning in both NFGs and EFGs. Empirical results show that our method quickly adapts to nonstationarities, outperforming the state-of-the-art regularization-based approach.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u96f6\u548c\u535a\u5f08\u4e2d\u6b63\u5219\u5316\u8c03\u53c2\u96be\u9898\uff0c\u63d0\u51fa\u57fa\u4e8eBNN\u52a8\u529b\u5b66\u7684\u65e0\u6b63\u5219\u5316\u6536\u655b\u7b97\u6cd5\uff0c\u5177\u5907\u9002\u5e94\u73af\u5883\u975e\u5b9a\u5e38\u6027\u7684\u4f18\u52bf\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u96f6\u548c\u535a\u5f08\u65b9\u6cd5\u4f9d\u8d56\u6b63\u5219\u5316\u4e14\u9700\u8c03\u53c2\uff0c\u8c03\u53c2\u56f0\u96be\u4e14\u9762\u4e34\u73af\u5883\u975e\u5b9a\u5e38\u6027\u95ee\u9898\uff0c\u9700\u5bfb\u627e\u65e0\u9700\u8c03\u53c2\u4e14\u80fd\u9002\u5e94\u73af\u5883\u53d8\u5316\u7684\u7b97\u6cd5\u3002", "method": "\u5c06\u7ecf\u5178BNN\u52a8\u529b\u5b66\u5f15\u5165\u4e09\u89d2\u535a\u5f08\uff0c\u5229\u7528\u5176\u56fa\u6709\u6536\u655b\u6027\uff0c\u901a\u8fc7\u53cd\u4e8b\u5b9e\u52a0\u6743\u6269\u5c55\u81f3\u6269\u5c55\u5f0f\u535a\u5f08\uff0c\u540c\u65f6\u7ed3\u5408\u795e\u7ecf\u7f51\u7edc\u51fd\u6570\u8fd1\u4f3c\u5b9e\u73b0\u9ad8\u6548\u7b97\u6cd5\u3002", "result": "\u7406\u8bba\u8bc1\u660eBNN\u52a8\u529b\u5b66\u5728\u566a\u58f0\u6b63\u5e38\u5f62\u5f0f\u535a\u5f08\u4e2d\u6700\u540e\u8fed\u4ee3\u6536\u655b\uff0c\u4e14\u6269\u5c55\u5230\u6269\u5c55\u5f62\u5f0f\u535a\u5f08\uff1b\u5b9e\u9a8c\u8868\u660e\u65b9\u6848\u5feb\u901f\u9002\u5e94\u975e\u5b9a\u5e38\u73af\u5883\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eBNN\u52a8\u529b\u5b66\u7684\u591a\u667a\u80fd\u4f53\u96f6\u548c\u535a\u5f08\u5b66\u4e60\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u65e0\u6b63\u5219\u5316\u6761\u4ef6\u4e0b\u7684\u6700\u540e\u8fed\u4ee3\u6536\u655b\uff0c\u4e14\u80fd\u5f88\u597d\u9002\u5e94\u4e0d\u7a33\u5b9a\u73af\u5883\uff0c\u4f18\u4e8e\u73b0\u6709\u6b63\u5219\u5316\u65b9\u6cd5\u3002"}}
{"id": "2602.07164", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07164", "abs": "https://arxiv.org/abs/2602.07164", "authors": ["Ruimeng Ye", "Zihan Wang", "Zinan Ling", "Yang Xiao", "Manling Li", "Xiaolong Ma", "Bo Hui"], "title": "Your Language Model Secretly Contains Personality Subnetworks", "comment": "ICLR 2026", "summary": "Humans shift between different personas depending on social context. Large Language Models (LLMs) demonstrate a similar flexibility in adopting different personas and behaviors. Existing approaches, however, typically adapt such behavior through external knowledge such as prompting, retrieval-augmented generation (RAG), or fine-tuning. We ask: do LLMs really need external context or parameters to adapt to different behaviors, or do they already have such knowledge embedded in their parameters? In this work, we show that LLMs already contain persona-specialized subnetworks in their parameter space. Using small calibration datasets, we identify distinct activation signatures associated with different personas. Guided by these statistics, we develop a masking strategy that isolates lightweight persona subnetworks. Building on the findings, we further discuss: how can we discover opposing subnetwork from the model that lead to binary-opposing personas, such as introvert-extrovert? To further enhance separation in binary opposition scenarios, we introduce a contrastive pruning strategy that identifies parameters responsible for the statistical divergence between opposing personas. Our method is entirely training-free and relies solely on the language model's existing parameter space. Across diverse evaluation settings, the resulting subnetworks exhibit significantly stronger persona alignment than baselines that require external knowledge while being more efficient. Our findings suggest that diverse human-like behaviors are not merely induced in LLMs, but are already embedded in their parameter space, pointing toward a new perspective on controllable and interpretable personalization in large language models.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u542b\u4eba\u683c\u5b50\u7f51\u7edc\uff0c\u901a\u8fc7\u65e0\u8bad\u7ec3\u63a9\u7801\u548c\u526a\u679d\u7b56\u7565\u53ef\u6709\u6548\u5b9e\u73b0\u4e0d\u540c\u4eba\u683c\u884c\u4e3a\uff0c\u65e0\u9700\u5916\u90e8\u8c03\u6574\uff0c\u63d0\u5347\u4e86\u884c\u4e3a\u63a7\u5236\u7684\u6548\u7387\u4e0e\u89e3\u91ca\u6027\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u7684\u9700\u8981\u5916\u90e8\u4e0a\u4e0b\u6587\u6216\u53c2\u6570\u8c03\u6574\u6765\u9002\u5e94\u4e0d\u540c\u4eba\u683c\u884c\u4e3a\uff0c\u6216\u8fd9\u4e9b\u884c\u4e3a\u5df2\u7ecf\u9690\u542b\u4e8e\u6a21\u578b\u53c2\u6570\u4e2d\u3002", "method": "\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u4eba\u683c\u5728\u6a21\u578b\u6fc0\u6d3b\u4e2d\u7684\u7279\u5f81\u7edf\u8ba1\uff0c\u8bbe\u8ba1\u63a9\u7801\u7b56\u7565\u5206\u79bb\u8f7b\u91cf\u7ea7\u7684\u4eba\u683c\u5b50\u7f51\u7edc\uff1b\u63d0\u51fa\u5bf9\u6bd4\u526a\u679d\u65b9\u6cd5\u5f3a\u5316\u4e8c\u5143\u5bf9\u7acb\u4eba\u683c\uff08\u5982\u5185\u5411-\u5916\u5411\uff09\u4e4b\u95f4\u7684\u533a\u5206\u3002", "result": "\u6240\u53d1\u73b0\u7684\u4eba\u683c\u5b50\u7f51\u7edc\u5728\u591a\u79cd\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u660e\u663e\u4f18\u4e8e\u4f9d\u8d56\u5916\u90e8\u77e5\u8bc6\u7684\u65b9\u6cd5\uff0c\u540c\u65f6\u66f4\u9ad8\u6548\uff0c\u8bc1\u660e\u4e86\u4eba\u683c\u884c\u4e3a\u5df2\u5d4c\u5165\u6a21\u578b\u53c2\u6570\u7a7a\u95f4\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5df2\u7ecf\u5b58\u5728\u9488\u5bf9\u4e0d\u540c\u4eba\u683c\u7684\u5b50\u7f51\u7edc\uff0c\u8fd9\u4e9b\u5b50\u7f51\u7edc\u53ef\u901a\u8fc7\u5c11\u91cf\u6821\u51c6\u6570\u636e\u548c\u63a9\u7801\u7b56\u7565\u6709\u6548\u5206\u79bb\uff0c\u65e0\u9700\u5916\u90e8\u77e5\u8bc6\u6216\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u4eba\u683c\u884c\u4e3a\u9002\u914d\u3002"}}
{"id": "2602.07412", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07412", "abs": "https://arxiv.org/abs/2602.07412", "authors": ["Raula Gaikovina Kula", "Christoph Treude", "Xing Hu", "Sebastian Baltes", "Earl T. Barr", "Kelly Blincoe", "Fabio Calefato", "Junjie Chen", "Marc Cheong", "Youmei Fan", "Daniel M. German", "Marco Gerosa", "Jin L. C. Guo", "Shinpei Hayashi", "Robert Hirschfeld", "Reid Holmes", "Yintong Huo", "Takashi Kobayashi", "Michele Lanza", "Zhongxin Liu", "Olivier Nourry", "Nicole Novielli", "Denys Poshyvanyk", "Shinobu Saito", "Kazumasa Shimari", "Igor Steinmacher", "Mairieli Wessel", "Markus Wagner", "Annie Vella", "Laurie Williams", "Xin Xia"], "title": "Forecasting Developer Environments with GenAI: A Research Perspective", "comment": "IDE Workshop", "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222, a four-day intensive research meeting. Four themes emerged as areas of interest for researchers and practitioners.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e13\u5bb6\u8ba8\u8bba\uff0c\u8bc6\u522b\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5bf9IDE\u5f71\u54cd\u7684\u56db\u4e2a\u5173\u952e\u7814\u7a76\u9886\u57df\u3002", "motivation": "\u63a2\u8ba8\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u6a21\u578b\u5bf9\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u4e2d\u4eba\u673a\u4ea4\u4e92\u7684\u5f71\u54cd\u3002", "method": "\u7ec4\u7ec733\u4f4d\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7684\u4e13\u5bb6\uff0c\u53c2\u52a0\u4e3a\u671f\u56db\u5929\u7684Shonan Meeting 222\u4f1a\u8bae\uff0c\u8ba8\u8bbaGenAI\u5e26\u6765\u7684\u6311\u6218\u548c\u673a\u9047\u3002", "result": "\u603b\u7ed3\u51fa\u56db\u4e2a\u4e3b\u8981\u4e3b\u9898\uff0c\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u5173\u6ce8\u7684\u7126\u70b9\u3002", "conclusion": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u3001\u5ba1\u67e5\u548c\u4fee\u590d\u65b9\u9762\u8868\u73b0\u5353\u8d8a\uff0c\u672a\u6765\u6709\u671b\u63d0\u5347\u7f16\u7a0b\u62bd\u8c61\u5c42\u6b21\uff0c\u6539\u53d8IDE\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u3002"}}
{"id": "2602.08965", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08965", "abs": "https://arxiv.org/abs/2602.08965", "authors": ["John Gardiner", "Orlando Romero", "Brendan Tivnan", "Nicol\u00f2 Dal Fabbro", "George J. Pappas"], "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning", "comment": null, "summary": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5171\u4eab\u91cf\u5b50\u7ea0\u7f20\u8bad\u7ec3\u591a\u667a\u80fd\u4f53\u5b9e\u73b0\u65e0\u901a\u4fe1\u534f\u8c03\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u91cf\u5b50\u4f18\u52bf\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\uff0c\u901a\u4fe1\u56f0\u96be\u9650\u5236\u4e86\u534f\u8c03\u80fd\u529b\uff0c\u800c\u91cf\u5b50\u7ea0\u7f20\u53ef\u80fd\u4f5c\u4e3a\u4e00\u79cd\u65b0\u7684\u534f\u8c03\u8d44\u6e90\u63d0\u5347\u65e0\u901a\u4fe1\u7b56\u7565\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u5fae\u5206\u7b56\u7565\u53c2\u6570\u5316\u548c\u65b0\u578b\u7b56\u7565\u67b6\u6784\uff0c\u7ed3\u5408\u91cf\u5b50\u6d4b\u91cf\u4f18\u5316\u8bad\u7ec3\u591a\u667a\u80fd\u4f53\u5229\u7528\u5171\u4eab\u91cf\u5b50\u7ea0\u7f20\u7684\u6846\u67b6\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5355\u8f6e\u6e38\u620f\u548c\u53bb\u4e2d\u5fc3\u5316\u90e8\u5206\u53ef\u89c2\u6d4bMarkov\u51b3\u7b56\u8fc7\u7a0b\u4e2d\u5b9e\u73b0\u4e86\u91cf\u5b50\u4f18\u52bf\u7684\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u6784\u5efa\u4e86\u5229\u7528\u5171\u4eab\u91cf\u5b50\u7ea0\u7f20\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u65e0\u901a\u4fe1\u534f\u8c03\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8d44\u6e90\u5728MARL\u4e2d\u7a81\u7834\u4f20\u7edf\u5171\u4eab\u968f\u673a\u6027\u9650\u5236\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.07176", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07176", "abs": "https://arxiv.org/abs/2602.07176", "authors": ["Mohamed El Hajji", "Tarek Ait Baha", "Aicha Dakir", "Hammou Fadili", "Youssef Es-Saady"], "title": "Open TutorAI: An Open-source Platform for Personalized and Immersive Learning with Generative AI", "comment": "19 pages, 15 figures", "summary": "Recent advances in artificial intelligence have created new possibilities for making education more scalable, adaptive, and learner-centered. However, existing educational chatbot systems often lack contextual adaptability, real-time responsiveness, and pedagogical agility. which can limit learner engagement and diminish instructional effectiveness. Thus, there is a growing need for open, integrative platforms that combine AI and immersive technologies to support personalized, meaningful learning experiences. This paper presents Open TutorAI, an open-source educational platform based on LLMs and generative technologies that provides dynamic, personalized tutoring. The system integrates natural language processing with customizable 3D avatars to enable multimodal learner interaction. Through a structured onboarding process, it captures each learner's goals and preferences in order to configure a learner-specific AI assistant. This assistant is accessible via both text-based and avatar-driven interfaces. The platform includes tools for organizing content, providing embedded feedback, and offering dedicated interfaces for learners, educators, and parents. This work focuses on learner-facing components, delivering a tool for adaptive support that responds to individual learner profiles without requiring technical expertise. Its assistant-generation pipeline and avatar integration enhance engagement and emotional presence, creating a more humanized, immersive learning environment. Embedded learning analytics support self-regulated learning by tracking engagement patterns and generating actionable feedback. The result is Open TutorAI, which unites modular architecture, generative AI, and learner analytics within an open-source framework. It contributes to the development of next-generation intelligent tutoring systems.", "AI": {"tldr": "Open TutorAI\u662f\u4e00\u4e2a\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u751f\u6210\u6280\u672f\u6253\u9020\u7684\u5f00\u6e90\u667a\u80fd\u6559\u80b2\u5e73\u53f0\uff0c\u652f\u6301\u4e2a\u6027\u5316\u3001\u6c89\u6d78\u5f0f\u3001\u591a\u6a21\u6001\u7684\u5b66\u4e60\u8f85\u5bfc\uff0c\u63d0\u5347\u4e86\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\u548c\u6559\u5b66\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6559\u80b2\u804a\u5929\u673a\u5668\u4eba\u7f3a\u4e4f\u60c5\u5883\u9002\u5e94\u6027\u548c\u6559\u5b66\u7075\u6d3b\u6027\uff0c\u9650\u5236\u4e86\u5b66\u4e60\u8005\u53c2\u4e0e\u548c\u6559\u5b66\u6548\u679c\uff0c\u56e0\u800c\u9700\u8981\u4e00\u4e2a\u5f00\u653e\u3001\u6574\u5408AI\u548c\u6c89\u6d78\u5f0f\u6280\u672f\u7684\u4e2a\u6027\u5316\u6559\u80b2\u5e73\u53f0\u3002", "method": "\u8be5\u5e73\u53f0\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3001\u5b9a\u52363D\u865a\u62df\u5f62\u8c61\u4ee5\u53ca\u5b66\u4e60\u8005\u5bfc\u5411\u7684\u914d\u7f6e\u6d41\u7a0b\uff0c\u751f\u6210\u4e2a\u6027\u5316AI\u52a9\u624b\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u4ea4\u4e92\u548c\u5b66\u4e60\u5206\u6790\u652f\u6301\u81ea\u6211\u8c03\u8282\u5b66\u4e60\u3002", "result": "\u5f00\u53d1\u4e86\u57fa\u4e8e\u5f00\u6e90\u7684Open TutorAI\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u5b66\u4e60\u8005\u7279\u5b9a\u7684AI\u52a9\u624b\u751f\u6210\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u3001\u5d4c\u5165\u5f0f\u53cd\u9988\u53ca\u5b66\u4e60\u5206\u6790\uff0c\u63d0\u5347\u4e86\u5b66\u4e60\u4f53\u9a8c\u548c\u6559\u5b66\u652f\u6301\u7684\u7075\u6d3b\u6027\u4e0e\u4eba\u6027\u5316\u3002", "conclusion": "Open TutorAI\u901a\u8fc7\u7ed3\u5408LLM\u548c\u751f\u6210\u5f0f\u6280\u672f\uff0c\u63d0\u4f9b\u4e2a\u6027\u5316\u3001\u52a8\u6001\u7684\u6559\u80b2\u8f85\u5bfc\uff0c\u63d0\u5347\u4e86\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\u548c\u6559\u5b66\u6548\u679c\uff0c\u662f\u4e0b\u4e00\u4ee3\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u7684\u91cd\u8981\u8d21\u732e\u3002"}}
{"id": "2602.07457", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07457", "abs": "https://arxiv.org/abs/2602.07457", "authors": ["Qinglin Zhu", "Tianyu Chen", "Shuai Lu", "Lei Ji", "Runcong Zhao", "Murong Ma", "Xiangxiang Dai", "Yulan He", "Lin Gui", "Peng cheng", "Yeyun Gong"], "title": "Pull Requests as a Training Signal for Repo-Level Code Editing", "comment": null, "summary": "Repository-level code editing requires models to understand complex dependencies and execute precise multi-file modifications across a large codebase. While recent gains on SWE-bench rely heavily on complex agent scaffolding, it remains unclear how much of this capability can be internalised via high-quality training signals. To address this, we propose Clean Pull Request (Clean-PR), a mid-training paradigm that leverages real-world GitHub pull requests as a training signal for repository-level editing. We introduce a scalable pipeline that converts noisy pull request diffs into Search/Replace edit blocks through reconstruction and validation, resulting in the largest publicly available corpus of 2 million pull requests spanning 12 programming languages. Using this training signal, we perform a mid-training stage followed by an agentless-aligned supervised fine-tuning process with error-driven data augmentation. On SWE-bench, our model significantly outperforms the instruction-tuned baseline, achieving absolute improvements of 13.6% on SWE-bench Lite and 12.3% on SWE-bench Verified. These results demonstrate that repository-level code understanding and editing capabilities can be effectively internalised into model weights under a simplified, agentless protocol, without relying on heavy inference-time scaffolding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faClean-PR\u8bad\u7ec3\u8303\u5f0f\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u771f\u5b9eGitHub\u62c9\u53d6\u8bf7\u6c42\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u590d\u6742\u4ee3\u7406\u6846\u67b6\u7684\u9ad8\u6548\u5e93\u7ea7\u4ee3\u7801\u7f16\u8f91\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728SWE-bench\u8bc4\u6d4b\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5e93\u7ea7\u4ee3\u7801\u7f16\u8f91\u65b9\u6cd5\u4f9d\u8d56\u590d\u6742\u7684\u4ee3\u7406\u7ed3\u6784\uff0c\u96be\u4ee5\u8bc4\u4f30\u901a\u8fc7\u9ad8\u8d28\u91cf\u8bad\u7ec3\u4fe1\u53f7\u6a21\u578b\u80fd\u5185\u5316\u591a\u5c11\u4ee3\u7801\u7406\u89e3\u548c\u7f16\u8f91\u80fd\u529b\u3002", "method": "\u63d0\u51faClean Pull Request\uff08Clean-PR\uff09\u4e2d\u8bad\u7ec3\u8303\u5f0f\uff0c\u5229\u7528\u771f\u5b9e\u7684GitHub\u62c9\u53d6\u8bf7\u6c42\u4f5c\u4e3a\u8bad\u7ec3\u4fe1\u53f7\uff0c\u901a\u8fc7\u91cd\u5efa\u548c\u9a8c\u8bc1\u5c06\u566a\u58f0\u62c9\u53d6\u8bf7\u6c42\u5dee\u5f02\u8f6c\u6362\u4e3a\u641c\u7d22/\u66ff\u6362\u7f16\u8f91\u5757\uff0c\u6784\u5efa\u5305\u542b200\u4e07\u4e2a\u62c9\u53d6\u8bf7\u6c42\u7684\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u4e2d\u671f\u8bad\u7ec3\u548c\u57fa\u4e8e\u9519\u8bef\u9a71\u52a8\u7684\u6570\u636e\u589e\u5f3a\u7684\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u6a21\u578b\u5728SWE-bench\u4e0a\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u5fae\u8c03\u57fa\u7ebf\uff0c\u5728SWE-bench Lite\u548cSWE-bench Verified\u4e0a\u5206\u522b\u63d0\u5347\u4e8613.6%\u548c12.3%\u3002", "conclusion": "\u5e93\u7ea7\u4ee3\u7801\u7f16\u8f91\u80fd\u529b\u53ef\u4ee5\u901a\u8fc7\u9ad8\u8d28\u91cf\u7684\u8bad\u7ec3\u4fe1\u53f7\u5185\u5316\u5230\u6a21\u578b\u6743\u91cd\u4e2d\uff0c\u65e0\u9700\u590d\u6742\u7684\u63a8\u7406\u65f6\u4ee3\u7406\u6846\u67b6\u5373\u53ef\u5b9e\u73b0\u9ad8\u6548\u7684\u4ee3\u7801\u7406\u89e3\u548c\u591a\u6587\u4ef6\u4fee\u6539\u3002"}}
{"id": "2602.07181", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07181", "abs": "https://arxiv.org/abs/2602.07181", "authors": ["Tianyu Zhao", "Siqi Li", "Yasser Shoukry", "Salma Elmalaki"], "title": "Can LLMs Discern the Traits Influencing Your Preferences? Evaluating Personality-Driven Preference Alignment in LLMs", "comment": null, "summary": "User preferences are increasingly used to personalize Large Language Model (LLM) responses, yet how to reliably leverage preference signals for answer generation remains under-explored. In practice, preferences can be noisy, incomplete, or even misleading, which can degrade answer quality when applied naively. Motivated by the observation that stable personality traits shape everyday preferences, we study personality as a principled ''latent'' signal behind preference statements. Through extensive experiments, we find that conditioning on personality-aligned preferences substantially improves personalized question answering: selecting preferences consistent with a user's inferred personality increases answer-choice accuracy from 29.25% to 76%, compared to using randomly selected preferences. Based on these findings, we introduce PACIFIC (Preference Alignment Choices Inference for Five-factor Identity Characterization), a personality-labeled preference dataset containing 1200 preference statements spanning diverse domains (e.g., travel, movies, education), annotated with Big-Five (OCEAN) trait directions. Finally, we propose a framework that enables an LLM model to automatically retrieve personality-aligned preferences and incorporate them during answer generation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u4e94\u5927\u4eba\u683c\u7279\u8d28\u5bf9\u7528\u6237\u504f\u597d\u8fdb\u884c\u6807\u6ce8\u548c\u5efa\u6a21\uff0c\u901a\u8fc7\u6784\u5efa\u6570\u636e\u96c6\u548c\u68c0\u7d22\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u51c6\u7684\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u7b54\u3002", "motivation": "\u73b0\u6709\u5229\u7528\u7528\u6237\u504f\u597d\u4e2a\u6027\u5316\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u7684\u65b9\u6cd5\u5b58\u5728\u504f\u597d\u4fe1\u53f7\u5608\u6742\u3001\u4e0d\u5b8c\u6574\u6216\u8bef\u5bfc\u7684\u95ee\u9898\uff0c\u9700\u8981\u627e\u5230\u7a33\u5b9a\u7684\u6f5c\u5728\u4eba\u683c\u56e0\u7d20\u4f5c\u4e3a\u504f\u597d\u80cc\u540e\u7684\u4fe1\u53f7\u3002", "method": "\u6784\u5efa\u4e86\u57fa\u4e8e\u4e94\u5927\u4eba\u683c\u7279\u8d28\uff08OCEAN\uff09\u7684\u504f\u597d\u6570\u636e\u96c6PACIFIC\uff0c\u5e76\u8bbe\u8ba1\u4e86\u81ea\u52a8\u68c0\u7d22\u4eba\u683c\u4e00\u81f4\u504f\u597d\u4ee5\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u56de\u7b54\u7684\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5229\u7528\u4eba\u683c\u4e00\u81f4\u7684\u504f\u597d\u5c06\u56de\u7b54\u51c6\u786e\u7387\u4ece29.25%\u63d0\u5347\u523076%\uff0c\u663e\u8457\u4f18\u4e8e\u968f\u673a\u504f\u597d\u9009\u62e9\u3002", "conclusion": "\u57fa\u4e8e\u4eba\u683c\u7279\u8d28\u5bf9\u7528\u6237\u504f\u597d\u8fdb\u884c\u5efa\u6a21\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u4e2a\u6027\u5316\u95ee\u7b54\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2602.07561", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07561", "abs": "https://arxiv.org/abs/2602.07561", "authors": ["Quanjun Zhang", "Ye Shang", "Haichuan Hu", "Chunrong Fang", "Zhenyu Chen", "Liang Xiao"], "title": "ComPass: Contrastive Learning for Automated Patch Correctness Assessment in Program Repair", "comment": "30 pages, 3 figures", "summary": "Automated program repair (APR) attempts to reduce manual debugging efforts and plays a vital role in software maintenance. Despite remarkable progress, APR is still limited in generating overfitting patches, i.e., patches passing available test suites but incorrect. This issue, known as patch overfitting, has become a key concern in the APR community, with numerous approaches proposed to address it. Very recent work proposes a pre-trained language model (PLM)-based automated patch correctness assessment (APCA) approach, indicating the potential of such PLMs in reasoning about patch correctness. Despite being promising, it is still far from perfect due to various limitations, such as the training paradigm and training dataset. In this paper, we present ComPass, a PLM-based APCA approach that leverages contrastive learning and data augmentation to address the technical limitations of prior work. Our work is inspired by the opportunity to integrate contrastive learning with recent PLMs in the field of patch correctness assessment, where large-scale labeled patches are difficult to obtain. ComPass utilizes code transformation rules to generate semantic-preserving code snippets for both unlabeled pre-training corpus and labeled fine-tuning patches. ComPass then pre-trains PLMs with contrastive learning, which captures code features with the same semantics but different structures. ComPass finally integrates representation embeddings of patch code snippets and fine-tunes PLMs with a binary classifier jointly to assess patch code correctness. Experimental results on 2274 real-world patches from Defects4J demonstrate that ComPass achieves an accuracy of 88.35%, significantly outperforming state-of-the-art baseline APPT.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u4f18\u5316PLM\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u8865\u4e01\u8fc7\u62df\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\u7684\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\u3002", "motivation": "\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4e2d\u8865\u4e01\u8fc7\u62df\u5408\u95ee\u9898\u4e25\u91cd\uff0c\u4e14\u5927\u89c4\u6a21\u5e26\u6807\u7b7e\u7684\u8865\u4e01\u6570\u636e\u96be\u4ee5\u83b7\u5f97\uff0c\u5f53\u524d\u4f7f\u7528PLM\u8fdb\u884c\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\u5b58\u5728\u8bad\u7ec3\u8303\u5f0f\u548c\u6570\u636e\u96c6\u7684\u9650\u5236\u3002", "method": "\u5229\u7528\u4ee3\u7801\u8f6c\u6362\u89c4\u5219\u751f\u6210\u8bed\u4e49\u4fdd\u6301\u4f46\u7ed3\u6784\u4e0d\u540c\u7684\u4ee3\u7801\u7247\u6bb5\u8fdb\u884c\u5bf9\u6bd4\u5b66\u4e60\u9884\u8bad\u7ec3\uff0c\u518d\u7ed3\u5408\u5d4c\u5165\u8868\u793a\u548c\u4e8c\u5206\u7c7b\u5668\u7684\u8054\u5408\u5fae\u8c03\uff0c\u5b9e\u73b0\u5bf9\u8865\u4e01\u4ee3\u7801\u6b63\u786e\u6027\u7684\u8bc4\u4f30\u3002", "result": "\u5728Defects4J\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cComPass\u4ee588.35%\u7684\u51c6\u786e\u7387\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684APPT\u57fa\u7ebf\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86ComPass\uff0c\u4e00\u79cd\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLM\uff09\u7684\u81ea\u52a8\u8865\u4e01\u6b63\u786e\u6027\u8bc4\u4f30\uff08APCA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\u663e\u8457\u63d0\u5347\u4e86\u8865\u4e01\u6b63\u786e\u6027\u5224\u65ad\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2602.07190", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07190", "abs": "https://arxiv.org/abs/2602.07190", "authors": ["Anagha Kulkarni", "Parin Rajesh Jhaveri", "Prasha Shrestha", "Yu Tong Han", "Reza Amini", "Behrouz Madahian"], "title": "Long-Context Long-Form Question Answering for Legal Domain", "comment": "EACL 2026", "summary": "Legal documents have complex document layouts involving multiple nested sections, lengthy footnotes and further use specialized linguistic devices like intricate syntax and domain-specific vocabulary to ensure precision and authority. These inherent characteristics of legal documents make question answering challenging, and particularly so when the answer to the question spans several pages (i.e. requires long-context) and is required to be comprehensive (i.e. a long-form answer). In this paper, we address the challenges of long-context question answering in context of long-form answers given the idiosyncrasies of legal documents. We propose a question answering system that can (a) deconstruct domain-specific vocabulary for better retrieval from source documents, (b) parse complex document layouts while isolating sections and footnotes and linking them appropriately, (c) generate comprehensive answers using precise domain-specific vocabulary. We also introduce a coverage metric that classifies the performance into recall-based coverage categories allowing human users to evaluate the recall with ease. We curate a QA dataset by leveraging the expertise of professionals from fields such as law and corporate tax. Through comprehensive experiments and ablation studies, we demonstrate the usability and merit of the proposed system.", "AI": {"tldr": "\u9488\u5bf9\u6cd5\u5f8b\u6587\u6863\u957f\u7bc7\u590d\u6742\u5185\u5bb9\uff0c\u672c\u6587\u8bbe\u8ba1\u4e86\u4e13\u4e1a\u8bcd\u6c47\u548c\u6587\u6863\u7ed3\u6784\u89e3\u6790\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u5168\u9762\u7cbe\u51c6\u7684\u957f\u7bc7\u7b54\u6848\u751f\u6210\u3002", "motivation": "\u6cd5\u5f8b\u6587\u6863\u5177\u6709\u590d\u6742\u7684\u5e03\u5c40\u548c\u4e13\u4e1a\u8bed\u8a00\uff0c\u5e38\u5e38\u9700\u8981\u8de8\u8d8a\u591a\u9875\u4e0a\u4e0b\u6587\u624d\u80fd\u5b8c\u6574\u56de\u7b54\u95ee\u9898\uff0c\u4f20\u7edf\u95ee\u7b54\u7cfb\u7edf\u96be\u4ee5\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e00\u79cd\u5305\u62ec\u4e13\u4e1a\u8bcd\u6c47\u5206\u89e3\u3001\u590d\u6742\u6587\u6863\u5e03\u5c40\u89e3\u6790\u3001\u7ae0\u8282\u53ca\u811a\u6ce8\u5173\u8054\u7684\u95ee\u7b54\u7cfb\u7edf\uff0c\u5e76\u8bbe\u8ba1\u8986\u76d6\u7387\u6307\u6807\u8bc4\u4f30\u56de\u6eaf\u6027\u80fd\uff0c\u540c\u65f6\u901a\u8fc7\u6cd5\u5f8b\u548c\u4f01\u4e1a\u7a0e\u52a1\u4e13\u5bb6\u53c2\u4e0e\u7684\u6570\u636e\u96c6\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u7efc\u5408\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7cfb\u7edf\u5728\u5904\u7406\u6cd5\u5f8b\u6587\u6863\u957f\u7bc7\u95ee\u7b54\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6cd5\u5f8b\u6587\u6863\u4e2d\u957f\u7bc7\u4e0a\u4e0b\u6587\u95ee\u7b54\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u6587\u6863\u7ed3\u6784\u548c\u4e13\u4e1a\u672f\u8bed\uff0c\u751f\u6210\u5168\u9762\u4e14\u7cbe\u51c6\u7684\u957f\u7bc7\u7b54\u6848\u3002"}}
{"id": "2602.07569", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.07569", "abs": "https://arxiv.org/abs/2602.07569", "authors": ["Eduardo C. Peixoto", "Hector Oliveira", "Geber L. Ramalho", "Cesar Fran\u00e7a"], "title": "Clarifying Core Dimensions in Digital Maturity Models: An Integrative Approach", "comment": "34 pages, 8 figures, 10 tables, 2 appendices", "summary": "Digital Transformation (DT) initiatives frequently face high failure rates, and while Digital Maturity Models (DMMs) offer potential solutions, they have notable shortcomings. Specifically, there is significant disparity in the dimensions considered relevant, a lack of clarity in their definitions, and uncertainty regarding their components. This study aims to provide a clearer understanding of DMMs by proposing integrative definitions of the most frequently used dimensions. Using a Systematic Mapping approach, including automatic search and snowballing techniques, we analyzed 76 DMMs to answer two Research Questions: (RQ1) What are the most frequent dimensions in DMMs? and (RQ2) How are these dimensions described, including their components? We reconcile varying interpretations of the ten most frequent dimensions -- Organization, Strategy, Technology, Culture, Process, Operations, People, Management, Customer, and Data -- and propose integrative definitions for each. Compared to previous analyses, this study provides a broader and more recent perspective on Digital Maturity Models.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u5206\u679076\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\uff0c\u6574\u5408\u5e76\u660e\u786e\u4e86\u5176\u5341\u4e2a\u6838\u5fc3\u7ef4\u5ea6\uff0c\u63d0\u5347\u4e86\u6570\u5b57\u8f6c\u578b\u76f8\u5173\u6a21\u578b\u7684\u7406\u8bba\u6e05\u6670\u5ea6\u3002", "motivation": "\u9274\u4e8e\u6570\u5b57\u8f6c\u578b\u9879\u76ee\u9ad8\u5931\u8d25\u7387\u548c\u73b0\u6709\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u4e2d\u7ef4\u5ea6\u5b9a\u4e49\u4e0d\u6e05\u6670\u3001\u5b58\u5728\u5dee\u5f02\uff0c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u66f4\u4e00\u81f4\u4e14\u7cfb\u7edf\u7684\u7ef4\u5ea6\u5b9a\u4e49\u3002", "method": "\u91c7\u7528\u7cfb\u7edf\u6620\u5c04\u65b9\u6cd5\uff0c\u5305\u62ec\u81ea\u52a8\u68c0\u7d22\u548c\u6eda\u96ea\u7403\u6280\u672f\uff0c\u5206\u6790\u4e8676\u4e2a\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u3002", "result": "\u786e\u5b9a\u4e86\u7ec4\u7ec7\u3001\u6218\u7565\u3001\u6280\u672f\u3001\u6587\u5316\u3001\u6d41\u7a0b\u3001\u8fd0\u8425\u3001\u4eba\u5458\u3001\u7ba1\u7406\u3001\u5ba2\u6237\u548c\u6570\u636e\u8fd9\u5341\u4e2a\u6700\u5e38\u89c1\u7ef4\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u6574\u5408\u6027\u5b9a\u4e49\u3002", "conclusion": "\u672c\u6587\u6574\u5408\u5e76\u6f84\u6e05\u4e86\u6570\u5b57\u6210\u719f\u5ea6\u6a21\u578b\u4e2d\u6700\u5e38\u89c1\u7684\u5341\u4e2a\u7ef4\u5ea6\u7684\u5b9a\u4e49\uff0c\u4e3a\u6570\u5b57\u8f6c\u578b\u63d0\u4f9b\u4e86\u66f4\u660e\u786e\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2602.07211", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.07211", "abs": "https://arxiv.org/abs/2602.07211", "authors": ["Ju Lin", "Jing Pan", "Ruizhi Li", "Ming Sun", "Yuzong Liu", "Alaa Hassan", "Jing Zheng", "Florian Metze"], "title": "Equipping LLM with Directional Multi-Talker Speech Understanding Capabilities", "comment": null, "summary": "Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech understanding capabilities. However, most speech LLMs are trained on single-channel, single-talker data, which makes it challenging to directly apply them to multi-talker and multi-channel speech understanding task. In this work, we present a comprehensive investigation on how to enable directional multi-talker speech understanding capabilities for LLMs, specifically in smart glasses usecase. We propose two novel approaches to integrate directivity into LLMs: (1) a cascaded system that leverages a source separation front-end module, and (2) an end-to-end system that utilizes serialized output training. All of the approaches utilize a multi-microphone array embedded in smart glasses to optimize directivity interpretation and processing in a streaming manner. Experimental results demonstrate the efficacy of our proposed methods in endowing LLMs with directional speech understanding capabilities, achieving strong performance in both speech recognition and speech translation tasks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u667a\u80fd\u773c\u955c\u4e2d\u7684\u591a\u8bf4\u8bdd\u4eba\u591a\u901a\u9053\u8bed\u97f3\u7406\u89e3\uff0c\u63d0\u51fa\u4e24\u79cd\u5229\u7528\u591a\u9ea6\u514b\u98ce\u9635\u5217\u63d0\u5347LLM\u65b9\u5411\u6027\u7406\u89e3\u7684\u65b0\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3LLM\u591a\u57fa\u4e8e\u5355\u901a\u9053\u5355\u8bf4\u8bdd\u4eba\u8bad\u7ec3\uff0c\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u591a\u8bf4\u8bdd\u4eba\u3001\u591a\u901a\u9053\u590d\u6742\u73af\u5883\uff0c\u5c24\u5176\u662f\u5728\u667a\u80fd\u773c\u955c\u7b49\u5b9e\u9645\u573a\u666f\u4e2d\u9700\u8981\u589e\u5f3a\u7684\u5b9a\u5411\u8bed\u97f3\u7406\u89e3\u80fd\u529b\u3002", "method": "\u91c7\u7528\u7ea7\u8054\u7cfb\u7edf\u7ed3\u5408\u58f0\u6e90\u5206\u79bb\u524d\u7aef\u6a21\u5757\u548c\u7aef\u5230\u7aef\u7684\u4e32\u884c\u8f93\u51fa\u8bad\u7ec3\u7cfb\u7edf\uff0c\u5229\u7528\u667a\u80fd\u773c\u955c\u5185\u5d4c\u7684\u591a\u9ea6\u514b\u98ce\u9635\u5217\uff0c\u4f18\u5316\u5b9a\u5411\u8bed\u97f3\u7684\u5904\u7406\u4e2d\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u8d4b\u4e88LLM\u65b9\u5411\u6027\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u5728\u8bed\u97f3\u8bc6\u522b\u548c\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e24\u79cd\u5c06\u5b9a\u5411\u6027\u6574\u5408\u5230\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e2d\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8bf4\u8bdd\u4eba\u3001\u591a\u901a\u9053\u8bed\u97f3\u7406\u89e3\u80fd\u529b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u667a\u80fd\u773c\u955c\u573a\u666f\u3002"}}
{"id": "2602.07589", "categories": ["cs.SE", "cs.CY", "cs.ET", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.07589", "abs": "https://arxiv.org/abs/2602.07589", "authors": ["Andriy Miranskyy"], "title": "A Course on the Introduction to Quantum Software Engineering: Experience Report", "comment": null, "summary": "Quantum computing is increasingly practiced through programming, yet most educational offerings emphasize algorithmic or framework-level use rather than software engineering concerns such as testing, abstraction, tooling, and lifecycle management.\n  This paper reports on the design and first offering of a cross-listed undergraduate--graduate course that frames quantum computing through a software engineering lens, focusing on early-stage competence relevant to software engineering practice. The course integrates foundational quantum concepts with software engineering perspectives, emphasizing executable artifacts, empirical reasoning, and trade-offs arising from probabilistic behaviour, noise, and evolving toolchains. Evidence is drawn from instructor observations, student feedback, surveys, and analysis of student work.\n  Despite minimal prior exposure to quantum computing, students were able to engage productively with quantum software engineering topics once a foundational understanding of quantum information and quantum algorithms, expressed through executable artifacts, was established. This experience report contributes a modular course design, a scalable assessment model for mixed academic levels, and transferable lessons for software engineering educators developing quantum computing curricula.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86\u4e00\u95e8\u4ee5\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u8bbe\u8ba1\u7684\u91cf\u5b50\u8ba1\u7b97\u8bfe\u7a0b\uff0c\u5e2e\u52a9\u5b66\u751f\u8de8\u5b66\u79d1\u638c\u63e1\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u77e5\u8bc6\uff0c\u63d0\u4f9b\u4e86\u8bfe\u7a0b\u8bbe\u8ba1\u548c\u8bc4\u4f30\u7684\u5b9e\u7528\u7ecf\u9a8c\u3002", "motivation": "\u4f20\u7edf\u91cf\u5b50\u8ba1\u7b97\u6559\u80b2\u591a\u805a\u7126\u7b97\u6cd5\u548c\u6846\u67b6\u4f7f\u7528\uff0c\u5ffd\u89c6\u8f6f\u4ef6\u5de5\u7a0b\u5982\u6d4b\u8bd5\u3001\u62bd\u8c61\u548c\u751f\u547d\u5468\u671f\u7ba1\u7406\u7b49\u65b9\u9762\u7684\u57f9\u517b\u3002", "method": "\u8bbe\u8ba1\u5e76\u9996\u6b21\u5f00\u8bbe\u4e86\u4e00\u95e8\u7ed3\u5408\u91cf\u5b50\u8ba1\u7b97\u4e0e\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u7684\u8de8\u672c\u79d1\u751f\u548c\u7814\u7a76\u751f\u8bfe\u7a0b\uff0c\u901a\u8fc7\u6559\u5e08\u89c2\u5bdf\u3001\u5b66\u751f\u53cd\u9988\u3001\u8c03\u67e5\u548c\u5b66\u751f\u4f5c\u54c1\u5206\u6790\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5f00\u53d1\u51fa\u4e00\u5957\u6a21\u5757\u5316\u8bfe\u7a0b\u8bbe\u8ba1\u3001\u9002\u7528\u4e8e\u6df7\u5408\u5b66\u672f\u6c34\u5e73\u7684\u53ef\u62d3\u5c55\u8bc4\u4f30\u6a21\u578b\uff0c\u5e76\u603b\u7ed3\u4e86\u9002\u7528\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u8005\u7684\u91cf\u5b50\u8ba1\u7b97\u8bfe\u7a0b\u5f00\u53d1\u7ecf\u9a8c\u3002", "conclusion": "\u5b66\u751f\u5728\u5efa\u7acb\u4e86\u91cf\u5b50\u4fe1\u606f\u548c\u91cf\u5b50\u7b97\u6cd5\u7684\u57fa\u7840\u7406\u89e3\u540e\uff0c\u80fd\u591f\u6709\u6548\u53c2\u4e0e\u91cf\u5b50\u8f6f\u4ef6\u5de5\u7a0b\u76f8\u5173\u4e3b\u9898\u7684\u5b66\u4e60\u3002"}}
{"id": "2602.07319", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07319", "abs": "https://arxiv.org/abs/2602.07319", "authors": ["Savan Doshi"], "title": "Beyond Accuracy: Risk-Sensitive Evaluation of Hallucinated Medical Advice", "comment": null, "summary": "Large language models are increasingly being used in patient-facing medical question answering, where hallucinated outputs can vary widely in potential harm. However, existing hallucination standards and evaluation metrics focus primarily on factual correctness, treating all errors as equally severe. This obscures clinically relevant failure modes, particularly when models generate unsupported but actionable medical language. We propose a risk-sensitive evaluation framework that quantifies hallucinations through the presence of risk-bearing language, including treatment directives, contraindications, urgency cues, and mentions of high-risk medications. Rather than assessing clinical correctness, our approach evaluates the potential impact of hallucinated content if acted upon. We further combine risk scoring with a relevance measure to identify high-risk, low-grounding failures. We apply this framework to three instruction-tuned language models using controlled patient-facing prompts designed as safety stress tests. Our results show that models with similar surface-level behavior exhibit substantially different risk profiles and that standard evaluation metrics fail to capture these distinctions. These findings highlight the importance of incorporating risk sensitivity into hallucination evaluation and suggest that evaluation validity is critically dependent on task and prompt design.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u98ce\u9669\u8bed\u8a00\u7684\u533b\u7597\u95ee\u7b54\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5f3a\u8c03\u98ce\u9669\u654f\u611f\u6027\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u7684\u4e0d\u8db3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u95ee\u7b54\u4e2d\u51fa\u73b0\u5e7b\u89c9\u8f93\u51fa\uff0c\u4e14\u4e0d\u540c\u5e7b\u89c9\u4ea7\u751f\u7684\u6f5c\u5728\u5371\u5bb3\u5dee\u5f02\u5927\uff0c\u4f20\u7edf\u8bc4\u4f30\u672a\u80fd\u53cd\u6620\u98ce\u9669\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u98ce\u9669\u8bed\u8a00\uff08\u5982\u6cbb\u7597\u6307\u5bfc\u3001\u7981\u5fcc\u3001\u7d27\u6025\u63d0\u793a\u3001\u9ad8\u98ce\u9669\u836f\u7269\u63d0\u53ca\uff09\u7684\u98ce\u9669\u654f\u611f\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u7ed3\u5408\u76f8\u5173\u6027\u8861\u91cf\u6765\u8bc6\u522b\u9ad8\u98ce\u9669\u4f4e\u652f\u6491\u7684\u9519\u8bef\u3002", "result": "\u5728\u4e09\u79cd\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u548c\u60a3\u8005\u5b89\u5168\u538b\u529b\u6d4b\u8bd5\u4e0b\uff0c\u53d1\u73b0\u8868\u9762\u884c\u4e3a\u76f8\u4f3c\u7684\u6a21\u578b\u5b58\u5728\u663e\u8457\u4e0d\u540c\u7684\u98ce\u9669\u8868\u73b0\uff0c\u6807\u51c6\u6307\u6807\u672a\u80fd\u6355\u6349\u8fd9\u4e00\u70b9\u3002", "conclusion": "\u73b0\u6709\u7684\u5e7b\u89c9\u8bc4\u4f30\u6807\u51c6\u672a\u80fd\u6709\u6548\u533a\u5206\u4e34\u5e8a\u98ce\u9669\uff0c\u5bfc\u81f4\u65e0\u6cd5\u8bc6\u522b\u9ad8\u98ce\u9669\u4f46\u8868\u9762\u6b63\u786e\u7684\u9519\u8bef\u3002"}}
{"id": "2602.07609", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07609", "abs": "https://arxiv.org/abs/2602.07609", "authors": ["Ruoyu Su", "Alexander Bakhtin", "Noman Ahmad", "Matteo Esposito", "Valentina Lenarduzzi", "Davide Taibi"], "title": "Evaluating Large Language Models for Detecting Architectural Decision Violations", "comment": null, "summary": "Architectural Decision Records (ADRs) play a central role in maintaining software architecture quality, yet many decision violations go unnoticed because projects lack both systematic documentation and automated detection mechanisms. Recent advances in Large Language Models (LLMs) open up new possibilities for automating architectural reasoning at scale. We investigated how effectively LLMs can identify decision violations in open-source systems by examining their agreement, accuracy, and inherent limitations. Our study analyzed 980 ADRs across 109 GitHub repositories using a multi-model pipeline in which one LLM primary screens potential decision violations, and three additional LLMs independently validate the reasoning. We assessed agreement, accuracy, precision, and recall, and complemented the quantitative findings with expert evaluation. The models achieved substantial agreement and strong accuracy for explicit, code-inferable decisions. Accuracy falls short for implicit or deployment-oriented decisions that depend on deployment configuration or organizational knowledge. Therefore, LLMs can meaningfully support validation of architectural decision compliance; however, they are not yet replacing human expertise for decisions not focused on code.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u68c0\u6d4b\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u8f6f\u4ef6\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\uff0c\u53d1\u73b0\u5176\u5bf9\u663e\u6027\u4ee3\u7801\u76f8\u5173\u51b3\u7b56\u6709\u6548\uff0c\u4f46\u5bf9\u9690\u6027\u6216\u90e8\u7f72\u76f8\u5173\u51b3\u7b56\u51c6\u786e\u6027\u4e0d\u8db3\uff0c\u8868\u660eLLM\u5728\u8f85\u52a9\u67b6\u6784\u51b3\u7b56\u5408\u89c4\u9a8c\u8bc1\u4e0a\u6709\u6f5c\u529b\uff0c\u4f46\u5c1a\u65e0\u6cd5\u5b8c\u5168\u66ff\u4ee3\u4e13\u5bb6\u5224\u65ad\u3002", "motivation": "\u76ee\u524d\u8f6f\u4ef6\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\u5f80\u5f80\u88ab\u5ffd\u89c6\uff0c\u539f\u56e0\u5728\u4e8e\u7f3a\u5c11\u7cfb\u7edf\u6027\u7684\u6587\u6863\u8bb0\u5f55\u548c\u81ea\u52a8\u5316\u68c0\u6d4b\u673a\u5236\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u4e3a\u81ea\u52a8\u5316\u5efa\u7b51\u51b3\u7b56\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u591a\u6a21\u578b\u6d41\u7a0b\uff0c\u4f7f\u7528\u4e00\u4e2a LLM \u8fdb\u884c\u521d\u6b65\u7b5b\u67e5\u6f5c\u5728\u7684\u51b3\u7b56\u8fdd\u89c4\uff0c\u518d\u7531\u4e09\u4e2a\u72ec\u7acb\u7684 LLM \u9a8c\u8bc1\u63a8\u7406\uff0c\u5206\u6790\u4e86\u6765\u81ea109\u4e2aGitHub\u9879\u76ee\u7684980\u4e2aADR\uff0c\u8bc4\u4f30\u4e00\u81f4\u6027\u3001\u51c6\u786e\u7387\u3001\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\uff0c\u5e76\u7ed3\u5408\u4e13\u5bb6\u8bc4\u4ef7\u8fdb\u884c\u7efc\u5408\u5206\u6790\u3002", "result": "\u6a21\u578b\u5bf9\u4e8e\u663e\u6027\u548c\u57fa\u4e8e\u4ee3\u7801\u7684\u51b3\u7b56\u8fdd\u89c4\u68c0\u6d4b\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u4e00\u81f4\u6027\u548c\u51c6\u786e\u7387\uff0c\u4f46\u5bf9\u9690\u6027\u548c\u4f9d\u8d56\u90e8\u7f72\u914d\u7f6e\u6216\u7ec4\u7ec7\u77e5\u8bc6\u7684\u51b3\u7b56\u68c0\u6d4b\u6548\u679c\u8f83\u5dee\uff0c\u663e\u793a\u51fa\u5f53\u524d\u6280\u672f\u7684\u4f18\u52bf\u548c\u5c40\u9650\u3002", "conclusion": "LLMs \u5728\u8bc6\u522b\u8f6f\u4ef6\u67b6\u6784\u51b3\u7b56\u8fdd\u89c4\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u548c\u4e00\u81f4\u6027\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u663e\u6027\u548c\u53ef\u4ece\u4ee3\u7801\u63a8\u65ad\u7684\u51b3\u7b56\uff0c\u4f46\u5bf9\u9690\u6027\u6216\u4f9d\u8d56\u90e8\u7f72\u53ca\u7ec4\u7ec7\u77e5\u8bc6\u7684\u51b3\u7b56\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u5c1a\u4e0d\u80fd\u5b8c\u5168\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u3002"}}
{"id": "2602.07338", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07338", "abs": "https://arxiv.org/abs/2602.07338", "authors": ["Geng Liu", "Fei Zhu", "Rong Feng", "Changyi Ma", "Shiqi Wang", "Gaofeng Meng"], "title": "Intent Mismatch Causes LLMs to Get Lost in Multi-Turn Conversation", "comment": null, "summary": "Multi-turn conversation has emerged as a predominant interaction paradigm for Large Language Models (LLMs). Users often employ follow-up questions to refine their intent, expecting LLMs to adapt dynamically. However, recent research reveals that LLMs suffer a substantial performance drop in multi-turn settings compared to single-turn interactions with fully specified instructions, a phenomenon termed ``Lost in Conversation'' (LiC). While this prior work attributes LiC to model unreliability, we argue that the root cause lies in an intent alignment gap rather than intrinsic capability deficits. In this paper, we first demonstrate that LiC is not a failure of model capability but rather a breakdown in interaction between users and LLMs. We theoretically show that scaling model size or improving training alone cannot resolve this gap, as it arises from structural ambiguity in conversational context rather than representational limitations. To address this, we propose to decouple intent understanding from task execution through a Mediator-Assistant architecture. By utilizing an experience-driven Mediator to explicate user inputs into explicit, well-structured instructions based on historical interaction patterns, our approach effectively bridges the gap between vague user intent and model interpretation. Experimental results demonstrate that this method significantly mitigates performance degradation in multi-turn conversations across diverse LLMs.", "AI": {"tldr": "\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5927\u6a21\u578b\u6027\u80fd\u4e0b\u964d\u6e90\u4e8e\u610f\u56fe\u5bf9\u9f50\u5dee\u8ddd\uff0c\u975e\u6a21\u578b\u80fd\u529b\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51faMediator-Assistant\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u8be5\u95ee\u9898\u3002", "motivation": "\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u4f20\u7edf\u8ba4\u4e3a\u662f\u6a21\u578b\u4e0d\u53ef\u9760\uff0c\u4f46\u5b9e\u8d28\u662f\u7528\u6237\u4e0e\u6a21\u578b\u95f4\u7684\u610f\u56fe\u5bf9\u9f50\u51fa\u73b0\u7ed3\u6784\u6027\u6b67\u4e49\u3002", "method": "\u63d0\u51fa\u4e86Mediator-Assistant\u67b6\u6784\uff0c\u5229\u7528\u7ecf\u9a8c\u9a71\u52a8\u7684Mediator\u5c06\u7528\u6237\u8f93\u5165\u8f6c\u5316\u4e3a\u660e\u786e\u3001\u7ed3\u6784\u826f\u597d\u7684\u6307\u4ee4\uff0c\u5f25\u5408\u7528\u6237\u6a21\u7cca\u610f\u56fe\u4e0e\u6a21\u578b\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u7f13\u89e3\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u5404\u7c7b\u5927\u6a21\u578b\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "Lost in Conversation\uff08LiC\uff09\u73b0\u8c61\u4e0d\u662f\u6a21\u578b\u80fd\u529b\u4e0d\u8db3\uff0c\u800c\u662f\u7528\u6237\u4e0e\u5927\u6a21\u578b\u4e4b\u95f4\u7684\u610f\u56fe\u5bf9\u9f50\u5dee\u8ddd\u5bfc\u81f4\u7684\u4ea4\u6d41\u5931\u8d25\u3002\u4f20\u7edf\u7684\u6269\u5927\u6a21\u578b\u89c4\u6a21\u6216\u6539\u8fdb\u8bad\u7ec3\u65e0\u6cd5\u89e3\u51b3\u6b64\u95ee\u9898\u3002"}}
{"id": "2602.07641", "categories": ["cs.SE", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.07641", "abs": "https://arxiv.org/abs/2602.07641", "authors": ["Marc Bara"], "title": "HAIF: A Human-AI Integration Framework for Hybrid Team Operations", "comment": "22 pages, 4 figures, 5 tables, 2 appendices", "summary": "The rapid deployment of generative AI, copilots, and agentic systems in knowledge work has created an operational gap: no existing framework addresses how to organize daily work in teams where AI agents perform substantive, delegated tasks alongside humans. Agile, DevOps, MLOps, and AI governance frameworks each cover adjacent concerns but none models the hybrid team as a coherent delivery unit. This paper proposes the Human-AI Integration Framework (HAIF): a protocol-based, scalable operational system built around four core principles, a formal delegation decision model, tiered autonomy with quantifiable transition criteria, and feedback mechanisms designed to integrate into existing Agile and Kanban workflows without requiring additional roles for small teams. The framework is developed following a Design Science Research methodology. HAIF explicitly addresses the central adoption paradox: the more capable AI becomes, the harder it is to justify the oversight the framework demands-and yet the greater the consequences of not providing it. The paper includes domain-specific validation checklists, adaptation guidance for non-software environments, and an examination of the framework's structural limitations-including the increasingly common pattern of continuous human-AI co-production that challenges the discrete delegation model. The framework is tool-agnostic and designed for iterative adoption. Empirical validation is identified as future work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHAIF\u6846\u67b6\uff0c\u7cfb\u7edf\u6574\u5408\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u6df7\u5408\u56e2\u961f\u7684\u534f\u4f5c\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u65e0\u6cd5\u8986\u76d6\u7684\u8fd0\u8425\u7f3a\u53e3\uff0c\u652f\u6301\u654f\u6377\u5de5\u4f5c\u6d41\uff0c\u672a\u6765\u5c06\u8fdb\u884c\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709\u7684\u654f\u6377\u3001DevOps\u3001MLOps\u548cAI\u6cbb\u7406\u6846\u67b6\u672a\u80fd\u6709\u6548\u878d\u5408\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u4f5c\u4e3a\u6df7\u5408\u56e2\u961f\u534f\u540c\u5de5\u4f5c\u7684\u9700\u6c42\uff0c\u5f62\u6210\u64cd\u4f5c\u4e0a\u7684\u7f3a\u53e3\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u5f00\u53d1HAIF\u6846\u67b6\uff0c\u7ed3\u5408\u534f\u8bae\u3001\u51b3\u7b56\u6a21\u578b\u548c\u53cd\u9988\u673a\u5236\u6784\u5efa\u56db\u5927\u6838\u5fc3\u539f\u5219\uff0c\u5b9e\u73b0\u5206\u5c42\u81ea\u4e3b\u6743\u548c\u59d4\u6258\u51b3\u7b56\u3002", "result": "\u63d0\u51fa\u4e86HAIF\u6846\u67b6\uff0c\u5305\u62ec\u7ed3\u6784\u6027\u9a8c\u8bc1\u6838\u67e5\u8868\u3001\u975e\u8f6f\u4ef6\u73af\u5883\u9002\u5e94\u6307\u5bfc\u4ee5\u53ca\u5bf9\u6301\u7eed\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\u7684\u63a2\u8ba8\uff0c\u5f3a\u8c03\u6846\u67b6\u5bf9\u5de5\u5177\u7684\u72ec\u7acb\u6027\u548c\u6e10\u8fdb\u5f0f\u91c7\u7528\u53ef\u80fd\u6027\uff0c\u540e\u7eed\u8ba1\u5212\u5f00\u5c55\u5b9e\u8bc1\u9a8c\u8bc1\u3002", "conclusion": "HAIF\u6846\u67b6\u89e3\u51b3\u4e86\u5f53\u524d\u6ca1\u6709\u5c06\u4eba\u7c7b\u4e0eAI\u4ee3\u7406\u7ed3\u5408\u4e3a\u4e00\u4e2a\u7edf\u4e00\u4ea4\u4ed8\u5355\u5143\u7684\u56e2\u961f\u8fd0\u8425\u7f3a\u53e3\uff0c\u5c3d\u7ba1\u9762\u4e34AI\u80fd\u529b\u63d0\u5347\u5e26\u6765\u7684\u76d1\u7763\u6311\u6218\uff0c\u4f46\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u73b0\u6709\u654f\u6377\u5de5\u4f5c\u6d41\u6574\u5408\u3002"}}
{"id": "2602.07361", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07361", "abs": "https://arxiv.org/abs/2602.07361", "authors": ["Long S. T. Nguyen", "Quan M. Bui", "Tin T. Ngo", "Quynh T. N. Vo", "Dung N. H. Le", "Tho T. Quan"], "title": "ViHERMES: A Graph-Grounded Multihop Question Answering Benchmark and System for Vietnamese Healthcare Regulations", "comment": "Accepted at ACIIDS 2026", "summary": "Question Answering (QA) over regulatory documents is inherently challenging due to the need for multihop reasoning across legally interdependent texts, a requirement that is particularly pronounced in the healthcare domain where regulations are hierarchically structured and frequently revised through amendments and cross-references. Despite recent progress in retrieval-augmented and graph-based QA methods, systematic evaluation in this setting remains limited, especially for low-resource languages such as Vietnamese, due to the lack of benchmark datasets that explicitly support multihop reasoning over healthcare regulations. In this work, we introduce the Vietnamese Healthcare Regulations-Multihop Reasoning Dataset (ViHERMES), a benchmark designed for multihop QA over Vietnamese healthcare regulatory documents. ViHERMES consists of high-quality question-answer pairs that require reasoning across multiple regulations and capture diverse dependency patterns, including amendment tracing, cross-document comparison, and procedural synthesis. To construct the dataset, we propose a controlled multihop QA generation pipeline based on semantic clustering and graph-inspired data mining, followed by large language model-based generation with structured evidence and reasoning annotations. We further present a graph-aware retrieval framework that models formal legal relations at the level of legal units and supports principled context expansion for legally valid and coherent answers. Experimental results demonstrate that ViHERMES provides a challenging benchmark for evaluating multihop regulatory QA systems and that the proposed graph-aware approach consistently outperforms strong retrieval-based baselines. The ViHERMES dataset and system implementation are publicly available at https://github.com/ura-hcmut/ViHERMES.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u8d8a\u5357\u533b\u7597\u6cd5\u89c4\u591a\u8df3\u95ee\u7b54\u57fa\u51c6ViHERMES\u53ca\u56fe\u611f\u77e5\u68c0\u7d22\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u6cd5\u89c4\u6587\u6863\u591a\u8df3\u63a8\u7406\u96be\u9898\uff0c\u63a8\u52a8\u4f4e\u8d44\u6e90\u8bed\u8a00\u6cd5\u5f8b\u95ee\u7b54\u7684\u53d1\u5c55\u3002", "motivation": "\u8d8a\u5357\u533b\u7597\u6cd5\u89c4\u5b58\u5728\u5c42\u7ea7\u590d\u6742\u3001\u9891\u7e41\u4fee\u8ba2\u4e14\u76f8\u4e92\u4f9d\u8d56\uff0c\u9700\u8981\u591a\u8df3\u63a8\u7406\u6765\u56de\u7b54\u76f8\u5173\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u652f\u6301\u8fd9\u4e00\u4efb\u52a1\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e2d\u3002", "method": "\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u56fe\u8bba\u6570\u636e\u6316\u6398\u6784\u5efa\u591a\u8df3QA\u751f\u6210\u7ba1\u9053\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7ed3\u6784\u5316\u63a8\u7406\u6ce8\u91ca\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u6846\u67b6\uff0c\u6a21\u62df\u6cd5\u5f8b\u6761\u6587\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u4e0a\u4e0b\u6587\u6269\u5c55\u3002", "result": "\u6784\u5efa\u4e86\u9ad8\u8d28\u91cf\u591a\u8df3\u63a8\u7406\u95ee\u7b54\u6570\u636e\u96c6ViHERMES\uff0c\u6db5\u76d6\u4fee\u8ba2\u8ffd\u8e2a\u3001\u6587\u6863\u6bd4\u8f83\u3001\u7a0b\u5e8f\u7efc\u5408\u7b49\u591a\u79cd\u4f9d\u8d56\u6a21\u5f0f\uff1b\u56fe\u611f\u77e5\u68c0\u7d22\u6846\u67b6\u5728\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "ViHERMES \u6570\u636e\u96c6\u4e3a\u591a\u8df3\u63a8\u7406\u7684\u8d8a\u5357\u533b\u7597\u6cd5\u89c4\u95ee\u7b54\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u57fa\u51c6\uff0c\u5e76\u4e14\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u68c0\u7d22\u57fa\u7ebf\u3002"}}
{"id": "2602.07672", "categories": ["cs.SE", "cs.AI", "cs.LG", "cs.PL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2602.07672", "abs": "https://arxiv.org/abs/2602.07672", "authors": ["Babak Rahmani"], "title": "Debugging code world models", "comment": "8 pages, 4 figures, under review in conference", "summary": "Code World Models (CWMs) are language models trained to simulate program execution by predicting explicit runtime state after every executed command. This execution-based world modeling enables internal verification within the model, offering an alternative to natural language chain-of-thought reasoning. However, the sources of errors and the nature of CWMs' limitations remain poorly understood. We study CWMs from two complementary perspectives: local semantic execution and long-horizon state tracking. On real-code benchmarks, we identify two dominant failure regimes. First, dense runtime state reveals produce token-intensive execution traces, leading to token-budget exhaustion on programs with long execution histories. Second, failures disproportionately concentrate in string-valued state, which we attribute to limitations of subword tokenization rather than program structure. To study long-horizon behavior, we use a controlled permutation-tracking benchmark that isolates state propagation under action execution. We show that long-horizon degradation is driven primarily by incorrect action generation: when actions are replaced with ground-truth commands, a Transformer-based CWM propagates state accurately over long horizons, despite known limitations of Transformers in long-horizon state tracking. These findings suggest directions for more efficient supervision and state representations in CWMs that are better aligned with program execution and data types.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4ee3\u7801\u4e16\u754c\u6a21\u578b\u7684\u9519\u8bef\u6e90\uff0c\u53d1\u73b0\u4e3b\u8981\u95ee\u9898\u662f\u7a0b\u5e8f\u6267\u884c\u4e2d\u4ee4\u724c\u9884\u7b97\u8017\u5c3d\u548c\u5b57\u7b26\u4e32\u72b6\u6001\u5904\u7406\u4e0d\u8db3\uff0c\u957f\u65f6\u95f4\u72b6\u6001\u8ddf\u8e2a\u7684\u5931\u8d25\u4e3b\u8981\u56e0\u52a8\u4f5c\u9519\u8bef\u751f\u6210\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65b9\u5411\u3002", "motivation": "CWMs\u4f5c\u4e3a\u6a21\u62df\u7a0b\u5e8f\u6267\u884c\u7684\u8bed\u8a00\u6a21\u578b\u5728\u5185\u90e8\u9a8c\u8bc1\u548c\u7a0b\u5e8f\u7406\u89e3\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5176\u9519\u8bef\u6765\u6e90\u548c\u9650\u5236\u672a\u88ab\u5145\u5206\u7406\u89e3\uff0c\u56e0\u6b64\u9700\u8981\u6df1\u5165\u7814\u7a76\u5176\u5931\u8d25\u6a21\u5f0f\u548c\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u771f\u5b9e\u4ee3\u7801\u57fa\u51c6\u7684\u5206\u6790\uff0c\u7814\u7a76CWMs\u5728\u5c40\u90e8\u8bed\u4e49\u6267\u884c\u548c\u957f\u65f6\u95f4\u72b6\u6001\u8ddf\u8e2a\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u8bbe\u8ba1\u63a7\u5236\u7684\u6392\u5217\u8ddf\u8e2a\u57fa\u51c6\u4ee5\u5206\u79bb\u72b6\u6001\u4f20\u64ad\u4e0e\u52a8\u4f5c\u6267\u884c\uff0c\u4f7f\u7528\u66ff\u6362\u6210\u771f\u5b9e\u547d\u4ee4\u7684\u52a8\u4f5c\u6765\u9a8c\u8bc1\u957f\u65f6\u95f4\u72b6\u6001\u4f20\u64ad\u80fd\u529b\u3002", "result": "\u53d1\u73b0CWMs\u5931\u8d25\u96c6\u4e2d\u5728\u4ee4\u724c\u8017\u5c3d\u548c\u5b57\u7b26\u4e32\u72b6\u6001\u9519\u8bef\u4e24\u4e2a\u65b9\u9762\uff0c\u957f\u65f6\u95f4\u72b6\u6001\u8870\u51cf\u4e3b\u8981\u56e0\u52a8\u4f5c\u751f\u6210\u9519\u8bef\uff0c\u4f46\u5728\u52a8\u4f5c\u51c6\u786e\u65f6\uff0cTransformer\u7ed3\u6784\u4ecd\u80fd\u5b9e\u73b0\u51c6\u786e\u957f\u5e8f\u5217\u72b6\u6001\u4f20\u64ad\u3002", "conclusion": "CWMs\u7684\u4e3b\u8981\u5931\u8d25\u539f\u56e0\u662f\u7a0b\u5e8f\u6267\u884c\u8fc7\u7a0b\u4e2d\u56e0\u5bc6\u96c6\u7684\u8fd0\u884c\u65f6\u72b6\u6001\u5bfc\u81f4\u7684\u4ee4\u724c\u9884\u7b97\u8017\u5c3d\u548c\u5b57\u7b26\u4e32\u72b6\u6001\u7684\u9519\u8bef\uff0c\u4e14\u957f\u65f6\u95f4\u6267\u884c\u7684\u72b6\u6001\u8ddf\u8e2a\u9519\u8bef\u4e3b\u8981\u6e90\u4e8e\u52a8\u4f5c\u751f\u6210\u4e0d\u51c6\u786e\u3002\u4f18\u5316\u52a8\u4f5c\u751f\u6210\u548c\u72b6\u6001\u8868\u793a\u53ef\u4ee5\u63d0\u5347CWMs\u6027\u80fd\u3002"}}
{"id": "2602.07374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07374", "abs": "https://arxiv.org/abs/2602.07374", "authors": ["Nisharg Nargund", "Priyesh Shukla"], "title": "TernaryLM: Memory-Efficient Language Modeling via Native 1-Bit Quantization with Adaptive Layer-wise Scaling", "comment": null, "summary": "Large language models (LLMs) achieve remarkable performance but demand substantial computational resources, limiting deployment on edge devices and resource-constrained environments. We present TernaryLM, a 132M parameter transformer architecture that employs native 1-bit ternary quantization {-1, 0, +1} during training, achieving significant memory reduction without sacrificing language modeling capability. Unlike post-training quantization approaches that quantize pre-trained full-precision models, TernaryLM learns quantization-aware representations from scratch using straight-through estimators and adaptive per-layer scaling factors. Our experiments demonstrate: (1) validation perplexity of 58.42 on TinyStories; (2) downstream transfer with 82.47 percent F1 on MRPC paraphrase detection; (3) 2.4x memory reduction (498MB vs 1197MB) with comparable inference latency; and (4) stable training dynamics across diverse corpora. We provide layer-wise quantization analysis showing that middle transformer layers exhibit highest compatibility with extreme quantization, informing future non-uniform precision strategies. Our results suggest that native 1-bit training is a promising direction for efficient neural language models. Code is available at https://github.com/1nisharg/TernaryLM-Memory-Efficient-Language-Modeling.", "AI": {"tldr": "\u63d0\u51fa\u4e86TernaryLM\uff0c\u4e00\u79cd\u91c7\u75281\u4f4d\u4e09\u5143\u91cf\u5316\u8bad\u7ec3\u7684\u9ad8\u6548\u8bed\u8a00\u6a21\u578b\uff0c\u53ef\u663e\u8457\u51cf\u5c11\u5185\u5b58\u5360\u7528\u4e14\u6027\u80fd\u4fdd\u6301\u3002", "motivation": "\u4f20\u7edf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\uff0c\u9650\u5236\u4e86\u8fb9\u7f18\u8bbe\u5907\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u90e8\u7f72\uff0c\u56e0\u6b64\u9700\u8981\u5185\u5b58\u9ad8\u6548\u4e14\u6027\u80fd\u7a33\u5b9a\u7684\u6a21\u578b\u3002", "method": "\u91c7\u7528132M\u53c2\u6570\u7684Transformer\u67b6\u6784\uff0c\u4ece\u96f6\u5f00\u59cb\u4f7f\u7528\u76f4\u63a5\u4f20\u9012\u4f30\u8ba1\u5668\u548c\u81ea\u9002\u5e94\u5206\u5c42\u7f29\u653e\u56e0\u5b50\u8bad\u7ec31\u4f4d\u4e09\u5143\u91cf\u5316\u6a21\u578b\u3002", "result": "TernaryLM\u5728TinyStories\u4e0a\u9a8c\u8bc1\u56f0\u60d1\u5ea6\u4e3a58.42\uff0cMRPC\u4e0aF1\u8fbe82.47%\uff0c\u5185\u5b58\u51cf\u5c112.4\u500d\uff08498MB vs 1197MB\uff09\uff0c\u63a8\u7406\u5ef6\u8fdf\u76f8\u5f53\uff0c\u8bad\u7ec3\u5728\u591a\u79cd\u8bed\u6599\u4e0a\u7a33\u5b9a\u3002", "conclusion": "TernaryLM\u901a\u8fc7\u539f\u751f1\u4f4d\u4e09\u5143\u91cf\u5316\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u5185\u5b58\u51cf\u5c0f\u4e14\u4e0d\u635f\u5bb3\u8bed\u8a00\u5efa\u6a21\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u9ad8\u6548\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.07698", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07698", "abs": "https://arxiv.org/abs/2602.07698", "authors": ["Adam Sorrenti", "Andriy Miranskyy"], "title": "On Sequence-to-Sequence Models for Automated Log Parsing", "comment": null, "summary": "Log parsing is a critical standard operating procedure in software systems, enabling monitoring, anomaly detection, and failure diagnosis. However, automated log parsing remains challenging due to heterogeneous log formats, distribution shifts between training and deployment data, and the brittleness of rule-based approaches. This study aims to systematically evaluate how sequence modelling architecture, representation choice, sequence length, and training data availability influence automated log parsing performance and computational cost. We conduct a controlled empirical study comparing four sequence modelling architectures: Transformer, Mamba state-space, monodirectional LSTM, and bidirectional LSTM models. In total, 396 models are trained across multiple dataset configurations and evaluated using relative Levenshtein edit distance with statistical significance testing. Transformer achieves the lowest mean relative edit distance (0.111), followed by Mamba (0.145), mono-LSTM (0.186), and bi-LSTM (0.265), where lower values are better. Mamba provides competitive accuracy with substantially lower computational cost. Character-level tokenization generally improves performance, sequence length has negligible practical impact on Transformer accuracy, and both Mamba and Transformer demonstrate stronger sample efficiency than recurrent models. Overall, Transformers reduce parsing error by 23.4%, while Mamba is a strong alternative under data or compute constraints. These results also clarify the roles of representation choice, sequence length, and sample efficiency, providing practical guidance for researchers and practitioners.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u6bd4\u8f83\u4e86\u56db\u79cd\u5e8f\u5217\u6a21\u578b\u5728\u81ea\u52a8\u65e5\u5fd7\u89e3\u6790\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0Transformer\u8868\u73b0\u6700\u4f73\uff0cMamba\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u65f6\u662f\u826f\u597d\u9009\u62e9\uff0c\u5b57\u7b26\u7ea7\u5206\u8bcd\u6709\u52a9\u6027\u80fd\u63d0\u5347\uff0c\u5e8f\u5217\u957f\u5ea6\u5f71\u54cd\u8f83\u5c0f\uff0c\u7ed3\u679c\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u81ea\u52a8\u65e5\u5fd7\u89e3\u6790\u5bf9\u4e8e\u8f6f\u4ef6\u7cfb\u7edf\u7684\u76d1\u63a7\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u6545\u969c\u8bca\u65ad\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u56e0\u65e5\u5fd7\u683c\u5f0f\u591a\u6837\u3001\u8bad\u7ec3\u4e0e\u90e8\u7f72\u6570\u636e\u5206\u5e03\u5dee\u5f02\u5927\u4ee5\u53ca\u57fa\u4e8e\u89c4\u5219\u65b9\u6cd5\u7684\u8106\u5f31\u6027\uff0c\u81ea\u52a8\u5316\u89e3\u6790\u4ecd\u5177\u6709\u6311\u6218\u6027\u3002\u672c\u7814\u7a76\u65e8\u5728\u7cfb\u7edf\u8bc4\u4f30\u5404\u79cd\u5e8f\u5217\u6a21\u578b\u67b6\u6784\u3001\u8868\u793a\u9009\u62e9\u3001\u5e8f\u5217\u957f\u5ea6\u548c\u8bad\u7ec3\u6570\u636e\u91cf\u5bf9\u81ea\u52a8\u65e5\u5fd7\u89e3\u6790\u6027\u80fd\u53ca\u8ba1\u7b97\u6210\u672c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u63a7\u5236\u53d8\u91cf\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u6bd4\u8f83Transformer\u3001Mamba\u72b6\u6001\u7a7a\u95f4\u3001\u5355\u5411LSTM\u548c\u53cc\u5411LSTM\u56db\u79cd\u5e8f\u5217\u5efa\u6a21\u67b6\u6784\uff0c\u5171\u8bad\u7ec3396\u4e2a\u6a21\u578b\uff0c\u91c7\u7528\u591a\u4e2a\u6570\u636e\u96c6\u914d\u7f6e\uff0c\u7528\u76f8\u5bf9Levenshtein\u7f16\u8f91\u8ddd\u79bb\u548c\u7edf\u8ba1\u663e\u8457\u6027\u68c0\u9a8c\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "Transformer\u6a21\u578b\u53d6\u5f97\u6700\u4f4e\u7684\u5e73\u5747\u76f8\u5bf9\u7f16\u8f91\u8ddd\u79bb\uff080.111\uff09\uff0cMamba\u4e3a0.145\uff0c\u5355\u5411LSTM\u4e3a0.186\uff0c\u53cc\u5411LSTM\u4e3a0.265\u3002Mamba\u5728\u8ba1\u7b97\u6210\u672c\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\u3002\u5b57\u7b26\u7ea7\u5206\u8bcd\u666e\u904d\u63d0\u5347\u6027\u80fd\uff0cTransformer\u5bf9\u5e8f\u5217\u957f\u5ea6\u4e0d\u654f\u611f\uff0cMamba\u548cTransformer\u5728\u6837\u672c\u6548\u7387\u4e0a\u4f18\u4e8e\u5faa\u73af\u7f51\u7edc\u3002", "conclusion": "Transformer\u6a21\u578b\u5728\u81ea\u52a8\u65e5\u5fd7\u89e3\u6790\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u63d0\u4f9b\u6700\u4f4e\u7684\u76f8\u5bf9\u7f16\u8f91\u8ddd\u79bb\uff0c\u540c\u65f6Mamba\u6a21\u578b\u5728\u8ba1\u7b97\u6210\u672c\u8f83\u4f4e\u7684\u60c5\u51b5\u4e0b\u4e5f\u80fd\u8fbe\u5230\u7ade\u4e89\u6027\u7684\u51c6\u786e\u7387\u3002\u5b57\u7b26\u7ea7\u5206\u8bcd\u63d0\u5347\u6027\u80fd\uff0c\u5e8f\u5217\u957f\u5ea6\u5bf9Transformer\u51c6\u786e\u7387\u5f71\u54cd\u4e0d\u5927\uff0c\u4e14Mamba\u548cTransformer\u7684\u6837\u672c\u6548\u7387\u4f18\u4e8e\u5faa\u73af\u6a21\u578b\u3002\u603b\u4f53\u800c\u8a00\uff0cTransformer\u53ef\u5c06\u89e3\u6790\u8bef\u5dee\u964d\u4f4e23.4%\uff0c\u800cMamba\u5728\u6570\u636e\u6216\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u65f6\u662f\u5f3a\u6709\u529b\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2602.07375", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07375", "abs": "https://arxiv.org/abs/2602.07375", "authors": ["Peiqi Yu", "Jinhao Wang", "Xinyi Sui", "Nam Ling", "Wei Wang", "Wei Jiang"], "title": "Efficient Post-Training Pruning of Large Language Models with Statistical Correction", "comment": "11 pages, 2 figures, 5 tables", "summary": "Post-training pruning is an effective approach for reducing the size and inference cost of large language models (LLMs), but existing methods often face a trade-off between pruning quality and computational efficiency. Heuristic pruning methods are efficient but sensitive to activation outliers, while reconstruction-based approaches improve fidelity at the cost of heavy computation. In this work, we propose a lightweight post-training pruning framework based on first-order statistical properties of model weights and activations. During pruning, channel-wise statistics are used to calibrate magnitude-based importance scores, reducing bias from activation-dominated channels. After pruning, we apply an analytic energy compensation to correct distributional distortions caused by weight removal. Both steps operate without retraining, gradients, or second-order information. Experiments across multiple LLM families, sparsity patterns, and evaluation tasks show that the proposed approach improves pruning performance while maintaining computational cost comparable to heuristic methods. The results suggest that simple statistical corrections can be effective for post-training pruning of LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4e00\u9636\u7edf\u8ba1\u7279\u6027\u7684\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u526a\u679d\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u526a\u679d\u6027\u80fd\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "motivation": "\u73b0\u6709\u526a\u679d\u65b9\u6cd5\u5728\u526a\u679d\u8d28\u91cf\u4e0e\u8ba1\u7b97\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u542f\u53d1\u5f0f\u65b9\u6cd5\u9ad8\u6548\u4f46\u5bf9\u6fc0\u6d3b\u5f02\u5e38\u654f\u611f\uff0c\u91cd\u6784\u65b9\u6cd5\u63d0\u9ad8\u8d28\u91cf\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "\u5229\u7528\u6a21\u578b\u6743\u91cd\u548c\u6fc0\u6d3b\u7684\u4e00\u9636\u7edf\u8ba1\u7279\u6027\uff0c\u901a\u8fc7\u901a\u9053\u7edf\u8ba1\u6821\u6b63\u57fa\u4e8e\u5e45\u503c\u7684\u91cd\u8981\u6027\u8bc4\u5206\uff0c\u5e76\u5728\u526a\u679d\u540e\u5e94\u7528\u89e3\u6790\u80fd\u91cf\u8865\u507f\u4ee5\u7ea0\u6b63\u6743\u91cd\u79fb\u9664\u5e26\u6765\u7684\u5206\u5e03\u5931\u771f\u3002", "result": "\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u3001\u7a00\u758f\u6a21\u5f0f\u53ca\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u4fdd\u6301\u4e0e\u542f\u53d1\u5f0f\u65b9\u6cd5\u76f8\u5f53\u7684\u8ba1\u7b97\u6210\u672c\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u526a\u679d\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u4e00\u9636\u7edf\u8ba1\u6027\u8d28\u7684\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u526a\u679d\u6846\u67b6\u5728\u4e0d\u9700\u8981\u91cd\u8bad\u7ec3\u6216\u590d\u6742\u8ba1\u7b97\u7684\u60c5\u51b5\u4e0b\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u526a\u679d\u6027\u80fd\u3002"}}
{"id": "2602.07783", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07783", "abs": "https://arxiv.org/abs/2602.07783", "authors": ["Zejun Zhang", "Yixin Gan", "Zhenchang Xing", "Tian Zhang", "Yi Li", "Xiwei Xu", "Qinghua Lu", "Liming Zhu"], "title": "Still Manual? Automated Linter Configuration via DSL-Based LLM Compilation of Coding Standards", "comment": "Accepted By FSE2026", "summary": "Coding standards are essential for maintaining consistent and high-quality code across teams and projects. Linters help developers enforce these standards by detecting code violations. However, manual linter configuration is complex and expertise-intensive, and the diversity and evolution of programming languages, coding standards, and linters lead to repetitive and maintenance-intensive configuration work. To reduce manual effort, we propose LintCFG, a domain-specific language (DSL)-driven, LLM-based compilation approach to automate linter configuration generation for coding standards, independent of programming languages, coding standards, and linters. Inspired by compiler design, we first design a DSL to express coding rules in a tool-agnostic, structured, readable, and precise manner. Then, we build linter configurations into DSL configuration instructions. For a given natural language coding standard, the compilation process parses it into DSL coding standards, matches them with the DSL configuration instructions to set configuration names, option names and values, verifies consistency between the standards and configurations, and finally generates linter-specific configurations. Experiments with Checkstyle for Java coding standard show that our approach achieves over 90% precision and recall in DSL representation, with accuracy, precision, recall, and F1-scores close to 70% (with some exceeding 70%) in fine-grained linter configuration generation. Notably, our approach outperforms baselines by over 100% in precision. A user study further shows that our approach improves developers' efficiency in configuring linters for coding standards. Finally, we demonstrate the generality of the approach by generating ESLint configurations for JavaScript coding standards, showcasing its broad applicability across other programming languages, coding standards, and linters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eDSL\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316linter\u914d\u7f6e\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u624b\u52a8\u914d\u7f6e\u96be\u5ea6\u548c\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u4e86\u914d\u7f6e\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u4e14\u9002\u7528\u4e8e\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c\u89c4\u8303\u3002", "motivation": "\u624b\u52a8\u914d\u7f6elinter\u590d\u6742\u4e14\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\uff0c\u7f16\u7a0b\u8bed\u8a00\u548c\u4ee3\u7801\u89c4\u8303\u591a\u6837\u4e14\u4e0d\u65ad\u53d8\u5316\uff0c\u5bfc\u81f4\u914d\u7f6e\u5de5\u4f5c\u91cd\u590d\u4e14\u7ef4\u62a4\u6210\u672c\u9ad8\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u964d\u4f4e\u4eba\u5de5\u8d1f\u62c5\u3002", "method": "\u8bbe\u8ba1\u4e86\u7528\u4e8e\u8868\u8fbe\u4ee3\u7801\u89c4\u5219\u7684\u9886\u57df\u7279\u5b9a\u8bed\u8a00(DSL)\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u7684\u4ee3\u7801\u89c4\u8303\u7f16\u8bd1\u4e3aDSL\u89c4\u8303\uff0c\u518d\u6839\u636eDSL\u89c4\u5219\u7ed3\u5408\u914d\u7f6e\u6307\u4ee4\u81ea\u52a8\u751f\u6210\u5177\u4f53\u7684linter\u914d\u7f6e\u6587\u4ef6\u3002", "result": "\u5728Java Checkstyle\u9a8c\u8bc1\u4e2d\uff0cDSL\u8868\u793a\u7684\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u5747\u8d85\u8fc790%\uff0c\u7ec6\u7c92\u5ea6\u914d\u7f6e\u751f\u6210\u7684\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u5747\u63a5\u8fd1\u6216\u8d85\u8fc770%\uff0c\u4e14\u7cbe\u5ea6\u8d85\u8fc7\u57fa\u7ebf100%\u4ee5\u4e0a\u3002\u7528\u6237\u7814\u7a76\u8868\u660e\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5f00\u53d1\u8005\u914d\u7f6e\u6548\u7387\uff0c\u540c\u65f6\u6210\u529f\u751f\u6210\u4e86JavaScript ESLint\u914d\u7f6e\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u901a\u7528\u6027\u3002", "conclusion": "LintCFG\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ed3\u5408\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u751f\u6210\u4ee3\u7801\u89c4\u8303\u68c0\u67e5\u5de5\u5177\u914d\u7f6e\u7684\u76ee\u6807\uff0c\u4e0d\u4f9d\u8d56\u4e8e\u5177\u4f53\u7f16\u7a0b\u8bed\u8a00\u3001\u89c4\u8303\u548c\u5de5\u5177\uff0c\u63d0\u5347\u4e86\u914d\u7f6e\u7684\u51c6\u786e\u6027\u548c\u5f00\u53d1\u8005\u6548\u7387\u3002"}}
{"id": "2602.07376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07376", "abs": "https://arxiv.org/abs/2602.07376", "authors": ["Usman Naseem", "Gautam Siddharth Kashyap", "Sushant Kumar Ray", "Rafiq Ali", "Ebad Shabbir", "Abdullah Mohammad"], "title": "Do Large Language Models Reflect Demographic Pluralism in Safety?", "comment": "Accepted at EACL Findings 2026", "summary": "Large Language Model (LLM) safety is inherently pluralistic, reflecting variations in moral norms, cultural expectations, and demographic contexts. Yet, existing alignment datasets such as ANTHROPIC-HH and DICES rely on demographically narrow annotator pools, overlooking variation in safety perception across communities. Demo-SafetyBench addresses this gap by modeling demographic pluralism directly at the prompt level, decoupling value framing from responses. In Stage I, prompts from DICES are reclassified into 14 safety domains (adapted from BEAVERTAILS) using Mistral 7B-Instruct-v0.3, retaining demographic metadata and expanding low-resource domains via Llama-3.1-8B-Instruct with SimHash-based deduplication, yielding 43,050 samples. In Stage II, pluralistic sensitivity is evaluated using LLMs-as-Raters-Gemma-7B, GPT-4o, and LLaMA-2-7B-under zero-shot inference. Balanced thresholds (delta = 0.5, tau = 10) achieve high reliability (ICC = 0.87) and low demographic sensitivity (DS = 0.12), confirming that pluralistic safety evaluation can be both scalable and demographically robust.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86Demo-SafetyBench\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u5c42\u9762\u5f15\u5165\u4eba\u53e3\u7edf\u8ba1\u591a\u5143\u6027\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u7684\u591a\u5143\u5316\u4e0e\u7a33\u5065\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u9f50\u6570\u636e\u96c6\u4eba\u53e3\u7edf\u8ba1\u5355\u4e00\uff0c\u5ffd\u89c6\u4e86\u4e0d\u540c\u793e\u533a\u5bf9\u5b89\u5168\u6027\u7684\u591a\u6837\u5316\u611f\u77e5\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u8003\u8651\u4eba\u53e3\u7edf\u8ba1\u591a\u5143\u6027\u3001\u53cd\u6620\u4e0d\u540c\u6587\u5316\u548c\u4ef7\u503c\u89c2\u7684\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u4e24\u4e2a\u9636\u6bb5\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528Mistral 7B-Instruct-v0.3\u6a21\u578b\u5c06DICES\u6570\u636e\u96c6\u4e2d\u7684\u63d0\u793a\u91cd\u65b0\u5206\u7c7b\u4e3a14\u4e2a\u5b89\u5168\u57df\uff0c\u5e76\u7ed3\u5408Llama-3.1-8B-Instruct\u6a21\u578b\u6269\u5c55\u4f4e\u8d44\u6e90\u5b89\u5168\u9886\u57df\uff0c\u901a\u8fc7SimHash\u964d\u91cd\uff0c\u751f\u6210\u4e8643050\u6761\u6837\u672c\uff1b\u7b2c\u4e8c\u9636\u6bb5\u91c7\u7528\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08Gemma-7B\uff0cGPT-4o\uff0cLLaMA-2-7B\uff09\u96f6\u6837\u672c\u63a8\u65ad\u5bf9\u591a\u5143\u5b89\u5168\u654f\u611f\u6027\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u8bbe\u7f6e\u5e73\u8861\u9608\u503c\uff08delta=0.5\uff0ctau=10\uff09\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5ea6\u53ef\u9760\u7684\u8bc4\u5206\u4e00\u81f4\u6027\uff08ICC=0.87\uff09\u548c\u8f83\u4f4e\u7684\u4eba\u53e3\u7edf\u8ba1\u654f\u611f\u6027\uff08DS=0.12\uff09\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u6269\u5c55\u6027\u548c\u4eba\u53e3\u7edf\u8ba1\u7a33\u5065\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5728\u63d0\u793a\u5c42\u9762\u76f4\u63a5\u5efa\u6a21\u4eba\u53e3\u7edf\u8ba1\u591a\u5143\u6027\uff0c\u53ef\u4ee5\u5b9e\u73b0\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6027\u7684\u591a\u5143\u5316\u8bc4\u4f30\uff0c\u5e76\u4e14\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u53ef\u9760\u6027\u548c\u8f83\u4f4e\u7684\u4eba\u53e3\u7edf\u8ba1\u654f\u611f\u6027\u3002"}}
{"id": "2602.07821", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07821", "abs": "https://arxiv.org/abs/2602.07821", "authors": ["Shinobu Saito"], "title": "Software Space Analytics: Towards Visualization and Statistics of Internal Software Execution", "comment": null, "summary": "In software maintenance work, software architects and programmers need to identify modules that require modification or deletion. Whilst user requests and bug reports are utilised for this purpose, evaluating the execution status of modules within the software is also crucial. This paper, therefore, applies spatial statistics to assess internal software execution data. First, we define a software space dataset, viewing the software's internal structure as a space based on module call relationships. Then, using spatial statistics, we conduct the visualization of spatial clusters and the statistical testing using spatial measures. Finally, we consider the usefulness of spatial statistics in the software engineering domain and future challenges.", "AI": {"tldr": "\u672c\u6587\u5c06\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5f15\u5165\u8f6f\u4ef6\u6267\u884c\u6570\u636e\u5206\u6790\uff0c\u901a\u8fc7\u6784\u5efa\u57fa\u4e8e\u6a21\u5757\u8c03\u7528\u5173\u7cfb\u7684\u8f6f\u4ef6\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u6267\u884c\u72b6\u6001\u7684\u805a\u7c7b\u53ef\u89c6\u5316\u548c\u7edf\u8ba1\u68c0\u9a8c\uff0c\u63a8\u52a8\u8f6f\u4ef6\u7ef4\u62a4\u6548\u7387\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u7684\u8f6f\u4ef6\u7ef4\u62a4\u4f9d\u8d56\u7528\u6237\u8bf7\u6c42\u548c\u7f3a\u9677\u62a5\u544a\uff0c\u7136\u800c\u8bc4\u4f30\u6a21\u5757\u6267\u884c\u72b6\u6001\u540c\u6837\u91cd\u8981\uff0c\u56e0\u6b64\u5f15\u5165\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5206\u6790\u5185\u90e8\u6267\u884c\u6570\u636e\u3002", "method": "\u5c06\u8f6f\u4ef6\u5185\u90e8\u7ed3\u6784\u89c6\u4e3a\u7a7a\u95f4\u6570\u636e\u96c6\uff0c\u4ee5\u6a21\u5757\u8c03\u7528\u5173\u7cfb\u6784\u5efa\u8f6f\u4ef6\u7a7a\u95f4\uff0c\u5229\u7528\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u8fdb\u884c\u805a\u7c7b\u53ef\u89c6\u5316\u548c\u7edf\u8ba1\u68c0\u9a8c\u3002", "result": "\u901a\u8fc7\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8f6f\u4ef6\u6a21\u5757\u7a7a\u95f4\u805a\u7c7b\u7684\u53ef\u89c6\u5316\u53ca\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u7a7a\u95f4\u7edf\u8ba1\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5e94\u7528\u4e8e\u8f6f\u4ef6\u6267\u884c\u6570\u636e\u7684\u5206\u6790\uff0c\u8f85\u52a9\u8f6f\u4ef6\u7ef4\u62a4\u5de5\u4f5c\u4e2d\u8bc6\u522b\u9700\u8981\u4fee\u6539\u6216\u5220\u9664\u7684\u6a21\u5757\u3002"}}
{"id": "2602.07381", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07381", "abs": "https://arxiv.org/abs/2602.07381", "authors": ["Gautam Siddharth Kashyap", "Mark Dras", "Usman Naseem"], "title": "When the Model Said 'No Comment', We Knew Helpfulness Was Dead, Honesty Was Alive, and Safety Was Terrified", "comment": "Accepted at EACL Mains 2026", "summary": "Large Language Models (LLMs) need to be in accordance with human values-being helpful, harmless, and honest (HHH)-is important for safe deployment. Existing works use Supervised Fine-Tuning (SFT) and Mixture-of-Experts (MoE) to align LLMs. However, these works face challenges in multi-objective settings, such as SFT leading to interference between conflicting objectives, while MoEs suffer from miscalibrated routing. We term this failure mode Axis Collapse, marked by (1) disjoint feature spaces causing catastrophic forgetting, and (2) unreliable inference from misrouted experts. To resolve this, we propose AlignX, a two-stage framework. Stage 1 uses prompt-injected fine-tuning to extract axis-specific task features, mitigating catastrophic forgetting. Stage 2 deploys a MoCaE module that calibrates expert routing using fractal and natural geometry, improving inference reliability. AlignX achieves significant gains on Alpaca (Helpfulness), BeaverTails (Harmlessness), and TruthfulQA (Honesty), with +171.5% win rate, +110.1% in truthfulness-informativeness, and 4.3% fewer safety violations. It also reduces latency and memory usage by over 35% compared to prior MoEs. Results across four LLMs validate its generalizability.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u76ee\u6807\u5bf9\u9f50\u4e2d\u8f74\u574d\u584c\u95ee\u9898\uff0cAlignX\u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5\u6709\u6548\u6539\u5584\u6a21\u578b\u6027\u80fd\u548c\u63a8\u7406\u53ef\u9760\u6027\uff0c\u5b9e\u73b0\u66f4\u5b89\u5168\u66f4\u7b26\u5408\u4eba\u7c7b\u4ef7\u503c\u7684\u6a21\u578b\u884c\u4e3a\u3002", "motivation": "\u73b0\u6709\u591a\u76ee\u6807\u5bf9\u9f50\u65b9\u6cd5\u5982SFT\u548cMoE\u5728\u5904\u7406\u51b2\u7a81\u76ee\u6807\u65f6\u5b58\u5728\u6311\u6218\uff0c\u8868\u73b0\u4e3a\u7279\u5f81\u7a7a\u95f4\u4e0d\u8fde\u8d2f\u5bfc\u81f4\u707e\u96be\u6027\u9057\u5fd8\u548c\u4e13\u5bb6\u8def\u7531\u5931\u51c6\u5bfc\u81f4\u63a8\u7406\u4e0d\u53ef\u9760\uff0c\u5373\u8f74\u574d\u584c\u95ee\u9898\u3002", "method": "\u63d0\u51faAlignX\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u9636\u6bb5\u4e00\u901a\u8fc7\u63d0\u793a\u6ce8\u5165\u5fae\u8c03\u63d0\u53d6\u8f74\u7279\u5b9a\u4efb\u52a1\u7279\u5f81\uff0c\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\uff1b\u9636\u6bb5\u4e8c\u91c7\u7528MoCaE\u6a21\u5757\u5229\u7528\u5206\u5f62\u548c\u81ea\u7136\u51e0\u4f55\u6821\u51c6\u4e13\u5bb6\u8def\u7531\uff0c\u63d0\u9ad8\u63a8\u7406\u53ef\u9760\u6027\u3002", "result": "AlignX\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u5e2e\u52a9\u6027\u3001\u65e0\u5bb3\u6027\u548c\u8bda\u5b9e\u6027\u6307\u6807\uff0c\u8d62\u7387\u63d0\u5347171.5%\uff0c\u771f\u5b9e\u6027\u4fe1\u606f\u63d0\u5347110.1%\uff0c\u5b89\u5168\u8fdd\u89c4\u51cf\u5c114.3%\uff0c\u5e76\u964d\u4f4e\u4e8635%\u4ee5\u4e0a\u7684\u5ef6\u8fdf\u548c\u5185\u5b58\u4f7f\u7528\uff0c\u9a8c\u8bc1\u4e86\u5176\u901a\u7528\u6027\u3002", "conclusion": "AlignX\u6846\u67b6\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86LLM\u591a\u76ee\u6807\u5bf9\u9f50\u4e2d\u7684\u8f74\u574d\u584c\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u4ef7\u503c\u89c2\uff08\u6709\u7528\u6027\u3001\u65e0\u5bb3\u6027\u3001\u8bda\u5b9e\u6027\uff09\u7684\u66f4\u597d\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.07871", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07871", "abs": "https://arxiv.org/abs/2602.07871", "authors": ["Xiang Li", "Siyu Lu", "Sarro Federica", "Claire Le Goues", "He Ye"], "title": "HerAgent: Rethinking the Automated Environment Deployment via Hierarchical Test Pyramid", "comment": null, "summary": "Automated software environment setup is a prerequisite for testing, debugging, and reproducing failures, yet remains challenging in practice due to complex dependencies, heterogeneous build systems, and incomplete documentation. Recent work leverages large language models to automate this process, but typically evaluates success using weak signals such as dependency installation or partial test execution, which do not ensure that a project can actually run. In this paper, we argue that environment setup success should be evaluated through executable evidence rather than a single binary signal. We introduce the Environment Maturity Hierarchy, which defines three success levels based on progressively stronger execution requirements, culminating in successful execution of a project's main entry point. Guided by this hierarchy, we propose HerAgent, an automated environment setup approach that incrementally constructs executable environments through execution-based validation and repair. We evaluate HerAgent on four public benchmarks, where it outperforms all related work, achieving up to 79.6\\% improvement due to its holistic understanding of project structure and dependencies. On complex C/C++ projects, HerAgent surpasses prior approaches by 66.7\\%. In addition, HerAgent uniquely resolves 11-30 environment instances across the benchmarks that no prior method can configure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6267\u884c\u9a8c\u8bc1\u7684\u81ea\u52a8\u8f6f\u4ef6\u73af\u5883\u8bbe\u7f6e\u65b9\u6cd5HerAgent\uff0c\u663e\u8457\u63d0\u5347\u4e86\u73af\u5883\u914d\u7f6e\u7684\u6210\u529f\u7387\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u9879\u76ee\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u81ea\u52a8\u5316\u8f6f\u4ef6\u73af\u5883\u8bbe\u7f6e\u5bf9\u4e8e\u6d4b\u8bd5\u3001\u8c03\u8bd5\u548c\u590d\u73b0\u6545\u969c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u4f9d\u8d56\u590d\u6742\u3001\u6784\u5efa\u7cfb\u7edf\u591a\u6837\u4ee5\u53ca\u6587\u6863\u4e0d\u5b8c\u6574\u7b49\u95ee\u9898\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u4ecd\u7136\u5145\u6ee1\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u73af\u5883\u6210\u719f\u5ea6\u5c42\u6b21\u7ed3\u6784\uff0c\u901a\u8fc7\u5206\u7ea7\u7684\u6267\u884c\u8981\u6c42\u8bc4\u4f30\u73af\u5883\u8bbe\u7f6e\u7684\u6210\u529f\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51faHerAgent\uff0c\u4e00\u79cd\u901a\u8fc7\u6267\u884c\u9a8c\u8bc1\u548c\u4fee\u590d\u9010\u6b65\u6784\u5efa\u53ef\u6267\u884c\u73af\u5883\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "result": "HerAgent\u5728\u56db\u4e2a\u516c\u5f00\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u8f83\u76f8\u5173\u5de5\u4f5c\u63d0\u5347\u6700\u9ad879.6%\uff0c\u5728\u590d\u6742C/C++\u9879\u76ee\u4e2d\u63d0\u534766.7%\u3002\u6b64\u5916\uff0cHerAgent\u80fd\u591f\u6210\u529f\u914d\u7f6e\u4ee5\u524d\u65b9\u6cd5\u65e0\u6cd5\u89e3\u51b3\u768411-30\u4e2a\u73af\u5883\u5b9e\u4f8b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u73af\u5883\u6210\u719f\u5ea6\u5c42\u6b21\u548c\u6267\u884c\u9a71\u52a8\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0cHerAgent\u663e\u8457\u63d0\u5347\u4e86\u8f6f\u4ef6\u73af\u5883\u8bbe\u7f6e\u7684\u6210\u529f\u7387\u548c\u53ef\u9760\u6027\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u73af\u5883\u642d\u5efa\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.07382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07382", "abs": "https://arxiv.org/abs/2602.07382", "authors": ["Debtanu Datta", "Rajdeep Mukherjee", "Adrijit Goswami", "Saptarshi Ghosh"], "title": "Advantages of Domain Knowledge Injection for Legal Document Summarization: A Case Study on Summarizing Indian Court Judgments in English and Hindi", "comment": "19 pages, 5 figures, 8 tables", "summary": "Summarizing Indian legal court judgments is a complex task not only due to the intricate language and unstructured nature of the legal texts, but also since a large section of the Indian population does not understand the complex English in which legal text is written, thus requiring summaries in Indian languages. In this study, we aim to improve the summarization of Indian legal text to generate summaries in both English and Hindi (the most widely spoken Indian language), by injecting domain knowledge into diverse summarization models. We propose a framework to enhance extractive neural summarization models by incorporating domain-specific pre-trained encoders tailored for legal texts. Further, we explore the injection of legal domain knowledge into generative models (including Large Language Models) through continual pre-training on large legal corpora in English and Hindi. Our proposed approaches achieve statistically significant improvements in both English-to-English and English-to-Hindi Indian legal document summarization, as measured by standard evaluation metrics, factual consistency metrics, and legal domain-specific metrics. Furthermore, these improvements are validated through domain experts, demonstrating the effectiveness of our approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u6ce8\u5165\u6cd5\u5f8b\u9886\u57df\u77e5\u8bc6\uff0c\u63d0\u5347\u4e86\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u7528\u82f1\u8bed\u548c\u5370\u5730\u8bed\u7684\u81ea\u52a8\u6458\u8981\u6548\u679c\uff0c\u65b9\u6cd5\u6709\u6548\u4e14\u7ecf\u4e13\u5bb6\u9a8c\u8bc1\u3002", "motivation": "\u5370\u5ea6\u6cd5\u5f8b\u5224\u51b3\u6587\u672c\u8bed\u8a00\u590d\u6742\u4e14\u7ed3\u6784\u4e0d\u89c4\u5219\uff0c\u540c\u65f6\u591a\u6570\u5370\u5ea6\u4eba\u96be\u4ee5\u7406\u89e3\u6cd5\u5f8b\u82f1\u8bed\uff0c\u9700\u8981\u751f\u6210\u5370\u5730\u8bed\u7b49\u5370\u5ea6\u8bed\u8a00\u7684\u6458\u8981\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6ce8\u5165\u6cd5\u5f8b\u9886\u57df\u77e5\u8bc6\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u7684\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u589e\u5f3a\u62bd\u53d6\u5f0f\u795e\u7ecf\u6458\u8981\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5728\u5927\u89c4\u6a21\u82f1\u5370\u6cd5\u5f8b\u8bed\u6599\u4e0a\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u5c06\u6cd5\u5f8b\u77e5\u8bc6\u6ce8\u5165\u751f\u6210\u5f0f\u6a21\u578b\uff08\u5305\u62ec\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u3002", "result": "\u5728\u82f1\u5370\u6cd5\u5f8b\u6587\u672c\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6807\u51c6\u8bc4\u6d4b\u6307\u6807\u3001\u4e8b\u5b9e\u4e00\u81f4\u6027\u6307\u6807\u548c\u6cd5\u5f8b\u9886\u57df\u7279\u5b9a\u6307\u6807\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347\uff0c\u4e14\u7ecf\u9886\u57df\u4e13\u5bb6\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6ce8\u5165\u6cd5\u5f8b\u9886\u57df\u77e5\u8bc6\u7684\u65b9\u5f0f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5370\u5ea6\u6cd5\u5f8b\u6587\u672c\u7684\u82f1\u5370\u53cc\u8bed\u6458\u8981\u8d28\u91cf\uff0c\u6ee1\u8db3\u4e86\u6cd5\u5f8b\u6587\u672c\u590d\u6742\u6027\u548c\u8bed\u8a00\u591a\u6837\u6027\u7684\u9700\u6c42\u3002"}}
{"id": "2602.07882", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07882", "abs": "https://arxiv.org/abs/2602.07882", "authors": ["Chen Xie", "Yuling Shi", "Xiaodong Gu", "Beijun Shen"], "title": "Rethinking Code Complexity Through the Lens of Large Language Models", "comment": null, "summary": "Code complexity metrics such as cyclomatic complexity have long been used to assess software quality and maintainability. With the rapid advancement of large language models (LLMs) on code understanding and generation tasks, an important yet underexplored question arises: do these traditional complexity metrics meaningfully characterize the difficulty LLMs experience when processing code? In this work, we empirically demonstrate that, after controlling for code length, classical metrics exhibit no consistent correlation with LLM performance, revealing a fundamental mismatch with model-perceived difficulty. To address this gap, we propose LM-CC, a novel code complexity metric designed from the perspective of LLMs. The core premise of LM-CC is that LLM-perceived difficulty is driven by the nonlinearity of program semantics. Accordingly, we decompose programs into semantic units based on entropy, organize these units into a compositional hierarchy, and quantify complexity as a principled aggregation of compositional level and branching-induced divergence, capturing cumulative model uncertainty during code processing. Our extensive experiments show that LM-CC not only correlates more strongly with LLM performance than traditional metrics but also that lowering it directly enhances task performance.", "AI": {"tldr": "\u4f20\u7edf\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u4ee3\u7801\u7684\u96be\u5ea6\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u975e\u7ebf\u6027\u7684LM-CC\u6307\u6807\uff0c\u66f4\u597d\u5730\u8861\u91cf\u6a21\u578b\u9762\u5bf9\u4ee3\u7801\u7684\u590d\u6742\u5ea6\uff0c\u4e14\u4e0e\u6a21\u578b\u6027\u80fd\u5bc6\u5207\u76f8\u5173\u3002", "motivation": "\u4f20\u7edf\u4ee3\u7801\u590d\u6742\u5ea6\u5ea6\u91cf\u6307\u6807\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u548c\u751f\u6210\u65f6\u9047\u5230\u7684\u56f0\u96be\u4e4b\u95f4\u7f3a\u4e4f\u4e00\u81f4\u5173\u8054\uff0c\u9650\u5236\u4e86\u590d\u6742\u5ea6\u6307\u6807\u5728\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u4e0a\u7684\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7a0b\u5e8f\u8bed\u4e49\u975e\u7ebf\u6027\u7684LM-CC\u6307\u6807\uff0c\u5c06\u7a0b\u5e8f\u5206\u89e3\u4e3a\u57fa\u4e8e\u71b5\u7684\u8bed\u4e49\u5355\u5143\uff0c\u6784\u5efa\u7ec4\u5408\u5c42\u7ea7\u7ed3\u6784\uff0c\u7ed3\u5408\u5206\u652f\u5f15\u8d77\u7684\u5206\u6b67\u91cf\u5316\u4ee3\u7801\u590d\u6742\u5ea6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e0eLLM\u6027\u80fd\u7684\u76f8\u5173\u6027\u3002", "result": "LM-CC\u6307\u6807\u4e0eLLM\u6027\u80fd\u7684\u76f8\u5173\u6027\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6307\u6807\uff0c\u4e14\u964d\u4f4eLM-CC\u503c\u80fd\u76f4\u63a5\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u6307\u6807\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u4f20\u7edf\u7684\u4ee3\u7801\u590d\u6742\u5ea6\u6307\u6807\u5982\u73af\u72b6\u590d\u6742\u5ea6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5904\u7406\u4ee3\u7801\u7684\u96be\u5ea6\u4e0d\u5339\u914d\uff0cLM-CC\u4f5c\u4e3a\u4eceLLM\u89c6\u89d2\u8bbe\u8ba1\u7684\u65b0\u590d\u6742\u5ea6\u5ea6\u91cf\u6307\u6807\u80fd\u66f4\u597d\u5730\u53cd\u6620\u6a21\u578b\u7684\u5b9e\u9645\u5904\u7406\u96be\u5ea6\u3002"}}
{"id": "2602.07447", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07447", "abs": "https://arxiv.org/abs/2602.07447", "authors": ["Liviu P Dinu", "Ana Sabina Uban", "Bogdan Iordache", "Anca Dinu", "Simona Georgescu"], "title": "Measuring cross-language intelligibility between Romance languages with computational tools", "comment": "16 pages, 7 figures, 2 tables", "summary": "We present an analysis of mutual intelligibility in related languages applied for languages in the Romance family. We introduce a novel computational metric for estimating intelligibility based on lexical similarity using surface and semantic similarity of related words, and use it to measure mutual intelligibility for the five main Romance languages (French, Italian, Portuguese, Spanish, and Romanian), and compare results using both the orthographic and phonetic forms of words as well as different parallel corpora and vectorial models of word meaning representation. The obtained intelligibility scores confirm intuitions related to intelligibility asymmetry across languages and significantly correlate with results of cloze tests in human experiments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u91cf\u5316\u7f57\u66fc\u8bed\u65cf\u4e94\u79cd\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u6709\u6548\u6027\u4e14\u7ed3\u679c\u4e0e\u4eba\u7c7b\u5b9e\u9a8c\u4e00\u81f4\u3002", "motivation": "\u63a2\u7a76\u7f57\u66fc\u8bed\u65cf\u8bed\u8a00\u4e4b\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u4e3a\u8bed\u8a00\u5b66\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u63d0\u4f9b\u91cf\u5316\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u6307\u6807\uff0c\u901a\u8fc7\u8003\u5bdf\u8bcd\u7684\u8868\u9762\u5f62\u6001\u53ca\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u7ed3\u5408\u6b63\u5199\u6cd5\u548c\u8bed\u97f3\u5f62\u5f0f\uff0c\u4ee5\u53ca\u5e73\u884c\u8bed\u6599\u5e93\u548c\u8bcd\u5411\u91cf\u6a21\u578b\u6765\u6d4b\u91cf\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\u3002", "result": "\u4e94\u79cd\u4e3b\u8981\u7f57\u66fc\u8bed\u8a00\uff08\u6cd5\u8bed\u3001\u610f\u5927\u5229\u8bed\u3001\u8461\u8404\u7259\u8bed\u3001\u897f\u73ed\u7259\u8bed\u3001\u7f57\u9a6c\u5c3c\u4e9a\u8bed\uff09\u5728\u4e0d\u540c\u8868\u793a\u5f62\u5f0f\u548c\u6a21\u578b\u4e0b\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\u5f97\u5206\uff0c\u8bc1\u5b9e\u4e86\u8bed\u8a00\u95f4\u7406\u89e3\u7684\u4e0d\u5bf9\u79f0\u6027\uff0c\u5e76\u4e0e\u4eba\u7c7b\u6d4b\u8bd5\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u7684\u8ba1\u7b97\u6307\u6807\u80fd\u591f\u6709\u6548\u91cf\u5316\u7f57\u66fc\u8bed\u65cf\u8bed\u8a00\u95f4\u7684\u76f8\u4e92\u7406\u89e3\u5ea6\uff0c\u7ed3\u679c\u4e0e\u4eba\u7c7b\u5b9e\u9a8c\u7684\u6d4b\u8bd5\u5b58\u5728\u663e\u8457\u76f8\u5173\u6027\u3002"}}
{"id": "2602.07893", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.07893", "abs": "https://arxiv.org/abs/2602.07893", "authors": ["Zhiyuan Chen", "Soham Sanjay Deo", "Poorna Chander Reddy Puttaparthi", "Vanessa Nava-Camal", "Yiming Tang", "Xueling Zhang", "Weiyi Shang"], "title": "Is Your Private Information Logged? An Empirical Study on Android App Logs", "comment": null, "summary": "With the rapid growth of mobile apps, users' concerns about their privacy have become increasingly prominent. Android app logs serve as crucial computer resources, aiding developers in debugging and monitoring the status of Android apps, while also containing a wealth of software system information. Previous studies have acknowledged privacy leaks in software logs and Android apps as significant issues without providing a comprehensive view of the privacy leaks in Android app logs. In this study, we build a comprehensive dataset of Android app logs and conduct an empirical study to analyze the status and severity of privacy leaks in Android app logs. Our study comprises three aspects: (1) Understanding real-world developers' concerns regarding privacy issues related to software logs; (2) Studying privacy leaks in the Android app logs; (3) Investigating the characteristics of privacy-leaking Android app logs and analyzing the reasons behind them. Our study reveals five different categories of concerns from real-world developers regarding privacy issues related to software logs and the prevalence of privacy leaks in Android app logs, with the majority stemming from developers' unawareness of such leaks. Additionally, our study provides developers with suggestions to safeguard their privacy from being logged.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u5206\u6790\u53d1\u73b0Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u9690\u79c1\u6cc4\u9732\u666e\u904d\uff0c\u5f00\u53d1\u8005\u7f3a\u4e4f\u8db3\u591f\u8ba4\u8bc6\uff0c\u5e76\u7ed9\u51fa\u76f8\u5e94\u9632\u62a4\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u5e94\u7528\u5feb\u901f\u589e\u957f\uff0c\u7528\u6237\u5bf9\u9690\u79c1\u7684\u5173\u6ce8\u65e5\u76ca\u7a81\u51fa\uff0c\u800c\u73b0\u6709\u7814\u7a76\u672a\u7cfb\u7edf\u63a2\u8ba8Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5168\u9762\u7684Android\u5e94\u7528\u65e5\u5fd7\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u901a\u8fc7\u5206\u6790\u771f\u5b9e\u5f00\u53d1\u8005\u5bf9\u9690\u79c1\u7684\u5173\u6ce8\u3001\u65e5\u5fd7\u4e2d\u7684\u9690\u79c1\u6cc4\u9732\u60c5\u51b5\u53ca\u5176\u7279\u5f81\u548c\u6210\u56e0\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u5bf9\u65e5\u5fd7\u9690\u79c1\u95ee\u9898\u5b58\u5728\u4e94\u7c7b\u4e0d\u540c\u5173\u6ce8\u70b9\uff0c\u4e14\u9690\u79c1\u6cc4\u9732\u666e\u904d\uff0c\u4e3b\u8981\u56e0\u5f00\u53d1\u8005\u65e0\u610f\u8bc6\u9020\u6210\uff0c\u5e76\u63d0\u51fa\u4fdd\u62a4\u9690\u79c1\u7684\u5efa\u8bae\u3002", "conclusion": "Android\u5e94\u7528\u65e5\u5fd7\u4e2d\u5b58\u5728\u666e\u904d\u7684\u9690\u79c1\u6cc4\u9732\u95ee\u9898\uff0c\u4e3b\u8981\u6e90\u4e8e\u5f00\u53d1\u8005\u5bf9\u9690\u79c1\u6cc4\u9732\u7684\u65e0\u610f\u8bc6\uff0c\u5e76\u4e14\u5f00\u53d1\u8005\u5bf9\u6b64\u8868\u73b0\u51fa\u591a\u6837\u5316\u7684\u9690\u79c1\u5173\u6ce8\u3002"}}
{"id": "2602.07451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07451", "abs": "https://arxiv.org/abs/2602.07451", "authors": ["Huiling Zhen", "Weizhe Lin", "Renxi Liu", "Kai Han", "Yiming Li", "Yuchuan Tian", "Hanting Chen", "Xiaoguang Li", "Xiaosong Li", "Chen Chen", "Xianzhi Yu", "Mingxuan Yuan", "Youliang Yan", "Peifeng Qin", "Jun Wang", "Yu Wang", "Dacheng Tao", "Yunhe Wang"], "title": "DLLM Agent: See Farther, Run Faster", "comment": null, "summary": "Diffusion large language models (DLLMs) have emerged as an alternative to autoregressive (AR) decoding with appealing efficiency and modeling properties, yet their implications for agentic multi-step decision making remain underexplored. We ask a concrete question: when the generation paradigm is changed but the agent framework and supervision are held fixed, do diffusion backbones induce systematically different planning and tool-use behaviors, and do these differences translate into end-to-end efficiency gains? We study this in a controlled setting by instantiating DLLM and AR backbones within the same agent workflow (DeepDiver) and performing matched agent-oriented fine-tuning on the same trajectory data, yielding diffusion-backed DLLM Agents and directly comparable AR agents. Across benchmarks and case studies, we find that, at comparable accuracy, DLLM Agents are on average over 30% faster end to end than AR agents, with some cases exceeding 8x speedup. Conditioned on correct task completion, DLLM Agents also require fewer interaction rounds and tool invocations, consistent with higher planner hit rates that converge earlier to a correct action path with less backtracking. We further identify two practical considerations for deploying diffusion backbones in tool-using agents. First, naive DLLM policies are more prone to structured tool-call failures, necessitating stronger tool-call-specific training to emit valid schemas and arguments. Second, for multi-turn inputs interleaving context and action spans, diffusion-style span corruption requires aligned attention masking to avoid spurious context-action information flow; without such alignment, performance degrades. Finally, we analyze attention dynamics across workflow stages and observe paradigm-specific coordination patterns, suggesting stronger global planning signals in diffusion-backed agents.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u7528\u4e8e\u591a\u6b65\u4ee3\u7406\u51b3\u7b56\u7684\u6548\u679c\uff0c\u53d1\u73b0DLLM\u6a21\u578b\u76f8\u6bd4\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u5728\u6548\u7387\u548c\u89c4\u5212\u8868\u73b0\u4e0a\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4f46\u4e5f\u9700\u9488\u5bf9\u5de5\u5177\u8c03\u7528\u5931\u8d25\u548c\u591a\u56de\u5408\u8f93\u5165\u8fdb\u884c\u7279\u6b8a\u8bad\u7ec3\u548c\u8bbe\u8ba1\u3002", "motivation": "\u63a2\u8ba8\u5728\u591a\u6b65\u4ee3\u7406\u51b3\u7b56\u4e2d\uff0c\u91c7\u7528\u6269\u6563\u751f\u6210\u8303\u5f0f\u662f\u5426\u4f1a\u5f15\u8d77\u89c4\u5212\u548c\u5de5\u5177\u4f7f\u7528\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u5e76\u8bc4\u4f30\u8fd9\u4e9b\u5dee\u5f02\u662f\u5426\u5e26\u6765\u7aef\u5230\u7aef\u6548\u7387\u63d0\u5347\u3002", "method": "\u5728\u7edf\u4e00\u4ee3\u7406\u5de5\u4f5c\u6d41\uff08DeepDiver\uff09\u4e2d\uff0c\u5c06DLLM\u548cAR\u6a21\u578b\u5206\u522b\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\u8fdb\u884c\u5339\u914d\u7684\u4ee3\u7406\u7ec6\u8c03\uff0c\u5e76\u5728\u76f8\u540c\u8f68\u8ff9\u6570\u636e\u4e0a\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "DLLM\u4ee3\u7406\u5728\u51c6\u786e\u7387\u76f8\u5f53\u7684\u6761\u4ef6\u4e0b\uff0c\u5e73\u5747\u6bd4AR\u4ee3\u7406\u5feb30%\u4ee5\u4e0a\uff0c\u90e8\u5206\u60c5\u51b5\u52a0\u901f\u8d85\u8fc78\u500d\u3002DLLM\u4ee3\u7406\u5728\u6b63\u786e\u5b8c\u6210\u4efb\u52a1\u65f6\uff0c\u4ea4\u4e92\u56de\u5408\u548c\u5de5\u5177\u8c03\u7528\u6b21\u6570\u66f4\u5c11\uff0c\u89c4\u5212\u5668\u547d\u4e2d\u7387\u66f4\u9ad8\u4e14\u6536\u655b\u66f4\u5feb\u3002\u6b64\u5916\uff0c\u53d1\u73b0DLLM\u6a21\u578b\u9700\u9488\u5bf9\u5de5\u5177\u8c03\u7528\u8fdb\u884c\u4e13\u95e8\u8bad\u7ec3\uff0c\u5e76\u5bf9\u591a\u56de\u5408\u8f93\u5165\u7684\u6ce8\u610f\u529b\u63a9\u7801\u8bbe\u8ba1\u63d0\u51fa\u4e86\u6539\u8fdb\u5efa\u8bae\u3002", "conclusion": "\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08DLLMs\uff09\u5728\u76f8\u540c\u7684\u4ee3\u7406\u6846\u67b6\u548c\u76d1\u7763\u6761\u4ef6\u4e0b\uff0c\u76f8\u8f83\u4e8e\u81ea\u56de\u5f52\uff08AR\uff09\u6a21\u578b\uff0c\u80fd\u663e\u8457\u63d0\u5347\u591a\u6b65\u51b3\u7b56\u8fc7\u7a0b\u7684\u6548\u7387\uff0c\u4f53\u73b0\u4e3a\u66f4\u5feb\u7684\u4efb\u52a1\u5b8c\u6210\u901f\u5ea6\u548c\u66f4\u5c11\u7684\u4ea4\u4e92\u56de\u5408\u53ca\u5de5\u5177\u8c03\u7528\u3002"}}
{"id": "2602.07900", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07900", "abs": "https://arxiv.org/abs/2602.07900", "authors": ["Zhi Chen", "Zhensu Sun", "Yuling Shi", "Chao Peng", "Xiaodong Gu", "David Lo", "Lingxiao Jiang"], "title": "Rethinking the Value of Agent-Generated Tests for LLM-Based Software Engineering Agents", "comment": null, "summary": "Large Language Model (LLM) code agents increasingly resolve repository-level issues by iteratively editing code, invoking tools, and validating candidate patches. In these workflows, agents often write tests on the fly, a paradigm adopted by many high-ranking agents on the SWE-bench leaderboard. However, we observe that GPT-5.2, which writes almost no new tests, can even achieve performance comparable to top-ranking agents. This raises the critical question: whether such tests meaningfully improve issue resolution or merely mimic human testing practices while consuming a substantial interaction budget.\n  To reveal the impact of agent-written tests, we present an empirical study that analyzes agent trajectories across six state-of-the-art LLMs on SWE-bench Verified. Our results show that while test writing is commonly adopted, but resolved and unresolved tasks within the same model exhibit similar test-writing frequencies Furthermore, these tests typically serve as observational feedback channels, where agents prefer value-revealing print statements significantly more than formal assertion-based checks. Based on these insights, we perform a controlled experiment by revising the prompts of four agents to either increase or reduce test writing. The results suggest that changes in the volume of agent-written tests do not significantly change final outcomes. Taken together, our study reveals that current test-writing practices may provide marginal utility in autonomous software engineering tasks.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLM\u4ee3\u7406\u7f16\u5199\u6d4b\u8bd5\u867d\u5e38\u89c1\uff0c\u4f46\u5bf9\u63d0\u5347\u4ee3\u7801\u95ee\u9898\u89e3\u51b3\u6548\u679c\u5e2e\u52a9\u4e0d\u5927\uff0c\u6d4b\u8bd5\u591a\u4e3a\u6253\u5370\u8bed\u53e5\uff0c\u8c03\u6574\u6d4b\u8bd5\u6570\u91cf\u5bf9\u7ed3\u679c\u65e0\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u63a2\u8ba8LLM\u4ee3\u7801\u4ee3\u7406\u5728\u89e3\u51b3\u4ed3\u5e93\u7ea7\u95ee\u9898\u65f6\u7f16\u5199\u6d4b\u8bd5\u5bf9\u4efb\u52a1\u89e3\u51b3\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u5bf9\u516d\u79cd\u6700\u5148\u8fdbLLM\u4ee3\u7406\u5728SWE-bench Verified\u4e0a\u7684\u884c\u4e3a\u8f68\u8ff9\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\uff0c\u5e76\u901a\u8fc7\u8c03\u6574\u56db\u4e2a\u4ee3\u7406\u7684\u63d0\u793a\u4fe1\u606f\u63a7\u5236\u6d4b\u8bd5\u7f16\u5199\u91cf\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u7f16\u5199\u6d4b\u8bd5\u7684\u9891\u7387\u5728\u89e3\u51b3\u548c\u672a\u89e3\u51b3\u4efb\u52a1\u4e2d\u76f8\u4f3c\uff0c\u4e14\u591a\u6570\u6d4b\u8bd5\u4e3a\u89c2\u5bdf\u6027\u53cd\u9988\uff08\u5982\u6253\u5370\u8bed\u53e5\uff09\uff0c\u6b63\u5f0f\u65ad\u8a00\u68c0\u67e5\u8f83\u5c11\uff1b\u589e\u52a0\u6216\u51cf\u5c11\u6d4b\u8bd5\u7f16\u5199\u91cf\u5bf9\u6700\u7ec8\u7ed3\u679c\u5f71\u54cd\u4e0d\u663e\u8457\u3002", "conclusion": "\u5f53\u524dLLM\u4ee3\u7406\u7684\u6d4b\u8bd5\u7f16\u5199\u5b9e\u8df5\u5bf9\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u7684\u6548\u679c\u63d0\u5347\u6709\u9650\u3002"}}
{"id": "2602.07464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07464", "abs": "https://arxiv.org/abs/2602.07464", "authors": ["Yijie Chen", "Yijin Liu", "Fandong Meng"], "title": "SED-SFT: Selectively Encouraging Diversity in Supervised Fine-Tuning", "comment": "The code is publicly available at https://github.com/pppa2019/SED-SFT", "summary": "Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has emerged as the standard post-training paradigm for large language models (LLMs). However, the conventional SFT process, driven by Cross-Entropy (CE) loss, often induces mode collapse, where models over-concentrate on specific response patterns. This lack of distributional diversity severely restricts the exploration efficiency required for subsequent RL. While recent studies have attempted to improve SFT by replacing the CE loss, aiming to preserve diversity or refine the update policy, they fail to adequately balance diversity and accuracy, thereby yielding suboptimal performance after RL. To address the mode collapse problem, we propose SED-SFT, which adaptively encourages diversity based on the token exploration space. This framework introduces a selective entropy regularization term with a selective masking mechanism into the optimization objective. Extensive experiments across eight mathematical benchmarks demonstrate that SED-SFT significantly enhances generation diversity with a negligible computational overhead increase compared with CE loss, yielding average improvements of 2.06 and 1.20 points in subsequent RL performance over standard CE-based baselines on Llama-3.2-3B-Instruct and Qwen2.5-Math-7B-Instruct, respectively. The code is publicly available at https://github.com/pppa2019/SED-SFT", "AI": {"tldr": "SED-SFT\u901a\u8fc7\u9009\u62e9\u6027\u71b5\u6b63\u5219\u5316\u89e3\u51b3\u4e86\u76d1\u7763\u5fae\u8c03\u4e2d\u7684\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u751f\u6210\u591a\u6837\u6027\u548c\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u6027\u80fd\uff0c\u4e14\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "motivation": "\u4f20\u7edf\u7684\u4ea4\u53c9\u71b5\u635f\u5931\u9a71\u52a8\u7684\u76d1\u7763\u5fae\u8c03\u5bfc\u81f4\u6a21\u578b\u96c6\u4e2d\u4e8e\u7279\u5b9a\u54cd\u5e94\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u5206\u5e03\u591a\u6837\u6027\uff0c\u9650\u5236\u4e86\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u63a2\u7d22\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u4ee4\u724c\u63a2\u7d22\u7a7a\u95f4\u81ea\u9002\u5e94\u9f13\u52b1\u591a\u6837\u6027\u7684\u9009\u62e9\u6027\u71b5\u6b63\u5219\u5316\u9879\u548c\u9009\u62e9\u6027\u63a9\u7801\u673a\u5236\uff0c\u5e76\u5c06\u5176\u96c6\u6210\u5230\u4f18\u5316\u76ee\u6807\u4e2d\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\u3002", "result": "\u5728\u516b\u4e2a\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSED-SFT\u5728Llama-3.2-3B-Instruct\u548cQwen2.5-Math-7B-Instruct\u6a21\u578b\u4e0a\u5206\u522b\u63d0\u5347\u4e86\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u6027\u80fd2.06\u548c1.20\u70b9\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u589e\u52a0\u6781\u5c0f\u3002", "conclusion": "SED-SFT\u901a\u8fc7\u5f15\u5165\u9009\u62e9\u6027\u71b5\u6b63\u5219\u9879\u548c\u63a9\u7801\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u4ea4\u53c9\u71b5\u9a71\u52a8\u7684\u76d1\u7763\u5fae\u8c03\u4e2d\u6a21\u5f0f\u5d29\u6e83\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u591a\u6837\u6027\u548c\u540e\u7eed\u5f3a\u5316\u5b66\u4e60\u7684\u8868\u73b0\u3002"}}
{"id": "2602.08004", "categories": ["cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.08004", "abs": "https://arxiv.org/abs/2602.08004", "authors": ["George Ling", "Shanshan Zhong", "Richard Huang"], "title": "Agent Skills: A Data-Driven Analysis of Claude Skills for Extending Large Language Model Functionality", "comment": null, "summary": "Agent skills extend large language model (LLM) agents with reusable, program-like modules that define triggering conditions, procedural logic, and tool interactions. As these skills proliferate in public marketplaces, it is unclear what types are available, how users adopt them, and what risks they pose. To answer these questions, we conduct a large-scale, data-driven analysis of 40,285 publicly listed skills from a major marketplace. Our results show that skill publication tends to occur in short bursts that track shifts in community attention. We also find that skill content is highly concentrated in software engineering workflows, while information retrieval and content creation account for a substantial share of adoption. Beyond content trends, we uncover a pronounced supply-demand imbalance across categories, and we show that most skills remain within typical prompt budgets despite a heavy-tailed length distribution. Finally, we observe strong ecosystem homogeneity, with widespread intent-level redundancy, and we identify non-trivial safety risks, including skills that enable state-changing or system-level actions. Overall, our findings provide a quantitative snapshot of agent skills as an emerging infrastructure layer for agents and inform future work on skill reuse, standardization, and safety-aware design.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u8d854\u4e07\u9879\u4ee3\u7406\u6280\u80fd\uff0c\u63ed\u793a\u4e86\u5176\u5185\u5bb9\u96c6\u4e2d\u5ea6\u3001\u7528\u6237\u91c7\u7528\u8d8b\u52bf\u3001\u4f9b\u5e94\u9700\u6c42\u4e0d\u5e73\u8861\u53ca\u5b89\u5168\u98ce\u9669\uff0c\u63d0\u4f9b\u4e86\u4ee3\u7406\u6280\u80fd\u751f\u6001\u7cfb\u7edf\u7684\u91cf\u5316\u6d1e\u5bdf\uff0c\u4e3a\u672a\u6765\u8bbe\u8ba1\u548c\u5b89\u5168\u7b56\u7565\u63d0\u4f9b\u4f9d\u636e\u3002", "motivation": "\u968f\u7740\u4ee3\u7406\u6280\u80fd\u7684\u589e\u591a\uff0c\u4e9f\u9700\u4e86\u89e3\u5176\u7c7b\u578b\u3001\u7528\u6237\u91c7\u7528\u60c5\u51b5\u4ee5\u53ca\u53ef\u80fd\u5b58\u5728\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4ee5\u6307\u5bfc\u672a\u6765\u7684\u6280\u80fd\u590d\u7528\u3001\u6807\u51c6\u5316\u548c\u5b89\u5168\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5bf9\u5927\u578b\u5e02\u573a\u4e2d40,285\u4e2a\u516c\u5f00\u5217\u51fa\u7684\u4ee3\u7406\u6280\u80fd\u8fdb\u884c\u6570\u636e\u9a71\u52a8\u7684\u5927\u89c4\u6a21\u5206\u6790\uff0c\u8bc4\u4f30\u5176\u53d1\u5e03\u6a21\u5f0f\u3001\u5185\u5bb9\u7c7b\u522b\u3001\u91c7\u7eb3\u7387\u53ca\u98ce\u9669\u3002", "result": "\u53d1\u73b0\u6280\u80fd\u53d1\u5e03\u5448\u77ed\u65f6\u7206\u53d1\u6a21\u5f0f\uff0c\u5185\u5bb9\u4e3b\u8981\u96c6\u4e2d\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\uff0c\u4fe1\u606f\u68c0\u7d22\u548c\u5185\u5bb9\u521b\u5efa\u9886\u91c7\u7eb3\u5360\u6bd4\u663e\u8457\uff1b\u5b58\u5728\u4f9b\u5e94\u9700\u6c42\u5931\u8861\uff0c\u6280\u80fd\u957f\u5ea6\u5206\u5e03\u91cd\u5c3e\u4e14\u5927\u90e8\u5206\u6280\u80fd\u5728\u63d0\u793a\u9884\u7b97\u5185\uff1b\u751f\u6001\u7cfb\u7edf\u540c\u8d28\u6027\u5f3a\uff0c\u5b58\u5728\u610f\u56fe\u5197\u4f59\u548c\u4e00\u5b9a\u7684\u5b89\u5168\u98ce\u9669\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u6280\u80fd\u5e02\u573a\u7684\u5185\u5bb9\u5206\u5e03\u3001\u7528\u6237\u91c7\u7eb3\u60c5\u51b5\u53ca\u6f5c\u5728\u98ce\u9669\uff0c\u5f3a\u8c03\u4e86\u5f53\u524d\u6280\u80fd\u751f\u6001\u7cfb\u7edf\u7684\u540c\u8d28\u5316\u53ca\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2602.07497", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07497", "abs": "https://arxiv.org/abs/2602.07497", "authors": ["Mo Wang", "Kaixuan Ren", "Pratik Jalan", "Ahmed Ashraf", "Tuong Vy Vu", "Rahul Seetharaman", "Shah Nawaz", "Usman Naseem"], "title": "From Native Memes to Global Moderation: Cros-Cultural Evaluation of Vision-Language Models for Hateful Meme Detection", "comment": "12 pages, 5 figures, Proceedings of the ACM Web Conference 2026 (WWW '26)", "summary": "Cultural context profoundly shapes how people interpret online content, yet vision-language models (VLMs) remain predominantly trained through Western or English-centric lenses. This limits their fairness and cross-cultural robustness in tasks like hateful meme detection. We introduce a systematic evaluation framework designed to diagnose and quantify the cross-cultural robustness of state-of-the-art VLMs across multilingual meme datasets, analyzing three axes: (i) learning strategy (zero-shot vs. one-shot), (ii) prompting language (native vs. English), and (iii) translation effects on meaning and detection. Results show that the common ``translate-then-detect'' approach deteriorate performance, while culturally aligned interventions - native-language prompting and one-shot learning - significantly enhance detection. Our findings reveal systematic convergence toward Western safety norms and provide actionable strategies to mitigate such bias, guiding the design of globally robust multimodal moderation systems.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u5316\u504f\u5dee\uff0c\u63d0\u51fa\u8de8\u6587\u5316\u8bc4\u4f30\u6846\u67b6\uff0c\u53d1\u73b0\u672c\u571f\u8bed\u8a00\u63d0\u793a\u548c\u4e00\u6b21\u5b66\u4e60\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u8de8\u6587\u5316\u9002\u5e94\u6027\u3002", "motivation": "\u6587\u5316\u80cc\u666f\u6df1\u523b\u5f71\u54cd\u4eba\u4eec\u5bf9\u7f51\u7edc\u5185\u5bb9\u7684\u89e3\u8bfb\uff0c\u4f46\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u7531\u897f\u65b9\u89c6\u89d2\u8bad\u7ec3\uff0c\u9650\u5236\u4e86\u5176\u5728\u591a\u6587\u5316\u73af\u5883\u4e2d\u7684\u4f7f\u7528\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8e\u591a\u8bed\u8a00\u7f51\u7edc\u8ff7\u56e0\u6570\u636e\u96c6\uff0c\u4ece\u5b66\u4e60\u7b56\u7565\u3001\u63d0\u793a\u8bed\u8a00\u548c\u7ffb\u8bd1\u6548\u679c\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u8de8\u6587\u5316\u7a33\u5065\u6027\u3002", "result": "\u201c\u5148\u7ffb\u8bd1\u518d\u68c0\u6d4b\u201d\u65b9\u6cd5\u8868\u73b0\u4e0b\u964d\uff1b\u672c\u571f\u8bed\u8a00\u63d0\u793a\u548c\u4e00\u6b21\u5b66\u4e60\u663e\u8457\u63d0\u5347\u8de8\u6587\u5316\u68c0\u6d4b\u80fd\u529b\uff1b\u63ed\u793a\u6a21\u578b\u5411\u897f\u65b9\u5b89\u5168\u89c4\u8303\u7684\u7cfb\u7edf\u6027\u8d8b\u540c\u3002", "conclusion": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u5316\u504f\u89c1\uff0c\u503e\u5411\u4e8e\u897f\u65b9\u6216\u82f1\u8bed\u89c6\u89d2\uff0c\u5f71\u54cd\u5176\u5728\u8de8\u6587\u5316\u60c5\u5883\u4e0b\u7684\u516c\u5e73\u6027\u548c\u7a33\u5065\u6027\u3002"}}
{"id": "2602.08015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08015", "abs": "https://arxiv.org/abs/2602.08015", "authors": ["Patricia G. F. Matsubara", "Tayana Conte"], "title": "Bridging the Gap: Adapting Evidence to Decision Frameworks to support the link between Software Engineering academia and industry", "comment": "Accepted for publication in ICSE 2026 - Future of Software Engineering", "summary": "Over twenty years ago, the Software Engineering (SE) research community have been involved with Evidence-Based Software Engineering (EBSE). EBSE aims to inform industrial practice with the best evidence from rigorous research, preferably from systematic literature reviews (SLRs). Since then, SE researchers have conducted many SLRs, perfected their SLR procedures, proposed alternative ways of presenting their results (such as Evidence Briefings), and profusely discussed how to conduct research that impacts practice. Nevertheless, there is still a feeling that SLRs' results are not reaching practitioners. Something is missing. In this vision paper, we introduce Evidence to Decision (EtD) frameworks from the health sciences, which propose gathering experts in panels to assess the existing best evidence about the impact of an intervention in all relevant outcomes and make structured recommendations based on them. The insight we can leverage from EtD frameworks is not their structure per se but all the relevant criteria for making recommendations to practitioners from SLRs. Furthermore, we provide a worked example based on an SE SLR. We also discuss the challenges the SE research and practice community may face when adopting EtD frameworks, highlighting the need for more comprehensive criteria in our recommendations to industry practitioners.", "AI": {"tldr": "\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57dfSLR\u6210\u679c\u96be\u4ee5\u5f71\u54cd\u5b9e\u8df5\uff0c\u672c\u6587\u5f15\u5165\u5065\u5eb7\u79d1\u5b66\u4e2d\u4e13\u4e1a\u7684Evidence to Decision\u6846\u67b6\uff0c\u501f\u52a9\u4e13\u5bb6\u8bc4\u5ba1\uff0c\u6539\u5584\u7814\u7a76\u8bc1\u636e\u8f6c\u5316\u4e3a\u5de5\u4e1a\u5b9e\u8df5\u7684\u63a8\u8350\u8fc7\u7a0b\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u8fdb\u884c\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u867d\u7136\u65b9\u6cd5\u5b8c\u5584\uff0c\u4f46\u5176\u7814\u7a76\u6210\u679c\u672a\u80fd\u6709\u6548\u5f71\u54cd\u5de5\u4e1a\u5b9e\u8df5\uff0c\u5b58\u5728\u6210\u679c\u4e0e\u5b9e\u8df5\u8131\u8282\u7684\u95ee\u9898\u3002", "method": "\u672c\u6587\u501f\u9274\u5065\u5eb7\u79d1\u5b66\u7684EtD\u6846\u67b6\uff0c\u63d0\u51fa\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u91c7\u7528\u4e13\u5bb6\u5c0f\u7ec4\u8bc4\u4f30\u6700\u4f73\u8bc1\u636e\u7684\u65b9\u5f0f\uff0c\u7ed3\u5408\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\u7ed3\u679c\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u7684\u63a8\u8350\u3002\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0bSLR\u7684\u5b9e\u4f8b\u8fdb\u884c\u8bf4\u660e\u3002", "result": "\u63d0\u51fa\u5e94\u7528EtD\u6846\u67b6\u6765\u8865\u5145\u548c\u4e30\u5bcc\u5bf9\u4eceSLR\u83b7\u5f97\u8bc1\u636e\u7684\u89e3\u8bfb\u4e0e\u63a8\u8350\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u63a8\u8350\u6807\u51c6\u4ee5\u4fc3\u8fdb\u7814\u7a76\u6210\u679c\u5411\u5b9e\u8df5\u7684\u8f6c\u5316\u3002", "conclusion": "\u5c3d\u7ba1\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u8fdb\u884c\u4e86\u5927\u91cf\u7684\u7cfb\u7edf\u6587\u732e\u7efc\u8ff0\uff08SLRs\uff09\uff0c\u4f46\u5176\u7ed3\u679c\u4ecd\u672a\u6709\u6548\u4f20\u8fbe\u5230\u5b9e\u8df5\u8005\u3002\u5f15\u5165\u5065\u5eb7\u79d1\u5b66\u4e2d\u7684Evidence to Decision (EtD)\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u4e13\u5bb6\u8bc4\u5ba1\u5c0f\u7ec4\u6784\u5efa\u66f4\u5168\u9762\u7684\u63a8\u8350\u6807\u51c6\uff0c\u4ece\u800c\u66f4\u597d\u5730\u5c06\u7814\u7a76\u8bc1\u636e\u8f6c\u5316\u4e3a\u5b9e\u9645\u51b3\u7b56\u3002"}}
{"id": "2602.07499", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07499", "abs": "https://arxiv.org/abs/2602.07499", "authors": ["Jingshen Zhang", "Xin Ying Qiu", "Lifang Lu", "Zhuhua Huang", "Yutao Hu", "Yuechang Wu", "JunYu Lu"], "title": "Let's Simplify Step by Step: Guiding LLM Towards Multilingual Unsupervised Proficiency-Controlled Sentence Simplification", "comment": "Accepted to EACL 2026 Findings", "summary": "Large language models demonstrate limited capability in proficiency-controlled sentence simplification, particularly when simplifying across large readability levels. We propose a framework that decomposes complex simplifications into manageable steps through dynamic path planning, semantic-aware exemplar selection, and chain-of-thought generation with conversation history for coherent reasoning. Evaluation on five languages across two benchmarks shows our approach improves simplification effectiveness while reducing computational steps by 22-42%. Human evaluation confirms the fundamental trade-off between simplification effectiveness and meaning preservation. Notably, even human annotators struggle to agree on semantic preservation judgments, highlighting the inherent complexity of this task. Our work shows that while step-by-step simplification improves control, preserving semantic fidelity during extensive simplification remains an open challenge.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u6b65\u6b65\u5206\u89e3\u7b80\u5316\u65b9\u6cd5\uff0c\u63d0\u9ad8\u8de8\u8bed\u8a00\u53e5\u5b50\u7b80\u5316\u6548\u679c\uff0c\u51cf\u5c11\u8ba1\u7b97\u91cf\uff0c\u4f46\u8bed\u4e49\u4fdd\u6301\u96be\u9898\u4ecd\u672a\u89e3\u51b3\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5927\u8de8\u5ea6\u53ef\u8bfb\u6027\u7ea7\u522b\u7684\u53e5\u5b50\u7b80\u5316\u80fd\u529b\u6709\u9650\uff0c\u9700\u63d0\u9ad8\u7b80\u5316\u6548\u679c\u53ca\u63a7\u5236\u529b\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u8def\u5f84\u89c4\u5212\u3001\u8bed\u4e49\u611f\u77e5\u793a\u4f8b\u9009\u62e9\u548c\u7ed3\u5408\u5bf9\u8bdd\u5386\u53f2\u7684\u94fe\u5f0f\u601d\u8003\u751f\u6210\uff0c\u5c06\u590d\u6742\u7b80\u5316\u5206\u89e3\u4e3a\u591a\u4e2a\u6b65\u9aa4\u3002", "result": "\u5728\u4e94\u79cd\u8bed\u8a00\u548c\u4e24\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u7b80\u5316\u6548\u679c\uff0c\u51cf\u5c1122-42%\u8ba1\u7b97\u6b65\u9aa4\u3002\u4eba\u5de5\u8bc4\u4f30\u663e\u793a\u7b80\u5316\u6548\u679c\u4e0e\u8bed\u4e49\u4fdd\u6301\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u9010\u6b65\u7b80\u5316\u80fd\u6539\u5584\u53ef\u63a7\u6027\uff0c\u4f46\u5728\u5927\u5e45\u5ea6\u7b80\u5316\u65f6\u8bed\u4e49\u4fdd\u6301\u4ecd\u662f\u96be\u70b9\u3002"}}
{"id": "2602.08084", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08084", "abs": "https://arxiv.org/abs/2602.08084", "authors": ["Mark Looi", "Marc Szepan"], "title": "Outsourcing in Global Software Development: Effects of Temporal Location and Methodologies", "comment": "Published in International Journal of Business and Social Science International Journal of Business and Social Science, Vol. 12, No. 3; March 2021, DOI: 10.30845/ijbss.v12n3p3", "summary": "Developing software globally using outsourced resources has become a common practice, with project teams often distributed in different time zones. In this study, we focus on customers that contract software development to vendors in temporally nearshore or far offshore locations. We conducted a survey to determine the effect of temporal distance on overall success, costs, project management effort, schedule, quality, communication problems, and other outcomes of interest to managers. In the survey of 80 customers and interviews with 6 of them, we also investigated the effect of software development methodology on the same outcomes. The results show that nearshore development is advantageous for overall success, quality, reduced PM effort, maintaining schedule, higher quality, and engendering fewer communication problems. Development methodology appears to only influence higher costs. We assess our findings in the context of prior GSE research and provide practical advice for customers of outsourced global software development, chief of which is to favor nearshore for communication-intensive or Agile projects.", "AI": {"tldr": "\u672c\u7814\u7a76\u8c03\u67e5\u4e86\u4e0d\u540c\u65f6\u95f4\u8ddd\u79bb\u4e0b\u8f6f\u4ef6\u5916\u5305\u5f00\u53d1\u7684\u6548\u679c\uff0c\u53d1\u73b0\u8fd1\u5cb8\u5f00\u53d1\u5728\u6210\u529f\u7387\u548c\u6c9f\u901a\u4e0a\u660e\u663e\u4f18\u4e8e\u8fdc\u5cb8\u5f00\u53d1\uff0c\u5c24\u5176\u9002\u5408\u654f\u6377\u9879\u76ee\u3002", "motivation": "\u5168\u7403\u5916\u5305\u8f6f\u4ef6\u5f00\u53d1\u9879\u76ee\u4e2d\uff0c\u4e0d\u540c\u65f6\u95f4\u533a\u7684\u5206\u5e03\u5bf9\u9879\u76ee\u6210\u529f\u53ca\u5176\u4ed6\u5173\u952e\u6307\u6807\u7684\u5f71\u54cd\u5c1a\u672a\u660e\u786e\u3002", "method": "\u901a\u8fc7\u8c03\u67e580\u4f4d\u5ba2\u6237\u53ca\u8bbf\u8c086\u4f4d\u5ba2\u6237\uff0c\u5206\u6790\u65f6\u95f4\u8ddd\u79bb\u53ca\u5f00\u53d1\u65b9\u6cd5\u5bf9\u9879\u76ee\u6210\u529f\u3001\u6210\u672c\u3001\u9879\u76ee\u7ba1\u7406\u3001\u8fdb\u5ea6\u3001\u8d28\u91cf\u548c\u6c9f\u901a\u7684\u5f71\u54cd\u3002", "result": "\u8fd1\u5cb8\u5916\u5305\u5728\u6574\u4f53\u6210\u529f\u3001\u8d28\u91cf\u3001\u964d\u4f4e\u9879\u76ee\u7ba1\u7406\u52aa\u529b\u3001\u4fdd\u6301\u8fdb\u5ea6\u53ca\u51cf\u5c11\u6c9f\u901a\u95ee\u9898\u4e0a\u6709\u663e\u8457\u4f18\u52bf\uff1b\u5f00\u53d1\u65b9\u6cd5\u4e3b\u8981\u5f71\u54cd\u6210\u672c\u3002", "conclusion": "\u5efa\u8bae\u5728\u901a\u4fe1\u5bc6\u96c6\u6216\u654f\u6377\u9879\u76ee\u4e2d\u4f18\u5148\u9009\u62e9\u8fd1\u5cb8\u5f00\u53d1\u4ee5\u63d0\u5347\u9879\u76ee\u6548\u679c\u548c\u51cf\u5c11\u95ee\u9898\u3002"}}
{"id": "2602.07546", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07546", "abs": "https://arxiv.org/abs/2602.07546", "authors": ["Zicong Cheng", "Ruixuan Jia", "Jia Li", "Guo-Wei Yang", "Meng-Hao Guo", "Shi-Min Hu"], "title": "Improving Variable-Length Generation in Diffusion Language Models via Length Regularization", "comment": "diffusion language models", "summary": "Diffusion Large Language Models (DLLMs) are inherently ill-suited for variable-length generation, as their inference is defined on a fixed-length canvas and implicitly assumes a known target length. When the length is unknown, as in realistic completion and infilling, naively comparing confidence across mask lengths becomes systematically biased, leading to under-generation or redundant continuations. In this paper, we show that this failure arises from an intrinsic lengthinduced bias in generation confidence estimates, leaving existing DLLMs without a robust way to determine generation length and making variablelength inference unreliable. To address this issue, we propose LR-DLLM, a length-regularized inference framework for DLLMs that treats generation length as an explicit variable and achieves reliable length determination at inference time. It decouples semantic compatibility from lengthinduced uncertainty through an explicit length regularization that corrects biased confidence estimates. Based on this, LR-DLLM enables dynamic expansion or contraction of the generation span without modifying the underlying DLLM or its training procedure. Experiments show that LRDLLM achieves 51.3% Pass@1 on HumanEvalInfilling under fully unknown lengths (+13.4% vs. DreamOn) and 51.5% average Pass@1 on four-language McEval (+14.3% vs. DreamOn).", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9DLLMs\u65e0\u6cd5\u9ad8\u6548\u5904\u7406\u672a\u77e5\u957f\u5ea6\u751f\u6210\u95ee\u9898\uff0c\u63d0\u51fa\u4e86LR-DLLM\u957f\u5ea6\u6b63\u5219\u5316\u63a8\u7406\u6846\u67b6\uff0c\u6709\u6548\u6821\u6b63\u957f\u5ea6\u504f\u5dee\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u957f\u5ea6\u5224\u65ad\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u4fee\u6539\u6a21\u578b\u7ed3\u6784\u7684\u53ef\u53d8\u957f\u5ea6\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\uff08DLLMs\uff09\u5728\u5904\u7406\u53d8\u91cf\u957f\u5ea6\u751f\u6210\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u56e0\u4e3a\u5176\u63a8\u7406\u57fa\u4e8e\u56fa\u5b9a\u957f\u5ea6\u4e14\u9700\u8981\u9884\u5148\u77e5\u9053\u76ee\u6807\u957f\u5ea6\uff0c\u8fd9\u5728\u5b9e\u9645\u751f\u6210\u5982\u8865\u5168\u548c\u586b\u5145\u65f6\u4e0d\u5207\u5b9e\u9645\u3002", "method": "\u63d0\u51faLR-DLLM\uff0c\u4e00\u79cd\u957f\u5ea6\u6b63\u5219\u5316\u63a8\u7406\u6846\u67b6\uff0c\u5c06\u751f\u6210\u957f\u5ea6\u4f5c\u4e3a\u663e\u5f0f\u53d8\u91cf\uff0c\u5e76\u901a\u8fc7\u957f\u5ea6\u6b63\u5219\u5316\u6821\u6b63\u751f\u6210\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\uff0c\u5b9e\u73b0\u957f\u5ea6\u7684\u52a8\u6001\u6269\u5c55\u6216\u6536\u7f29\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u7ed3\u6784\u6216\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "LR-DLLM\u5728\u5b8c\u5168\u672a\u77e5\u751f\u6210\u957f\u5ea6\u6761\u4ef6\u4e0b\uff0cHumanEval-Infilling\u4efb\u52a1Pass@1\u8fbe\u523051.3%\uff0c\u6bd4DreamOn\u63d0\u534713.4%\uff1b\u5728\u56db\u8bed\u8a00McEval\u6d4b\u8bd5\u4e2d\u5e73\u5747Pass@1\u4e3a51.5%\uff0c\u63d0\u534714.3%\u3002", "conclusion": "LR-DLLM\u6210\u529f\u89e3\u51b3\u4e86DLLMs\u5728\u53d8\u91cf\u957f\u5ea6\u751f\u6210\u4e2d\u7684\u957f\u5ea6\u504f\u5dee\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u9760\u7684\u957f\u5ea6\u5224\u5b9a\u548c\u9ad8\u6548\u7684\u751f\u6210\u8d28\u91cf\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u80fd\u529b\u3002"}}
{"id": "2602.08133", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08133", "abs": "https://arxiv.org/abs/2602.08133", "authors": ["Mojtaba Mostafavi Ghahfarokhi", "Hamed Jahantigh", "Alireza Asadi", "Abbas Heydarnoori"], "title": "Integrating Code Metrics into Automated Documentation Generation for Computational Notebooks", "comment": null, "summary": "Effective code documentation is essential for collaboration, comprehension, and long-term software maintainability, yet developers often neglect it due to its repetitive nature. Automated documentation generation has evolved from heuristic and rule-based methods to neural network-based and large language model (LLM)-based approaches. However, existing methods often overlook structural and quantitative characteristics of code that influence readability and comprehension. Prior research suggests that code metrics capture information relevant to program understanding. Building on these insights, this paper investigates the role of source code metrics as auxiliary signals for automated documentation generation, focusing on computational notebooks, a popular medium among data scientists that integrates code, narrative, and results but suffers from inconsistent documentation. We propose a two-stage approach. First, the CodeSearchNet dataset construction process was refined to create a specialized dataset from over 17 million code and markdown cells. After structural and semantic filtering, approximately 36,734 high-quality (code, markdown) pairs were extracted. Second, two modeling paradigms, a lightweight CNN-RNN architecture and a few-shot GPT-3.5 architecture, were evaluated with and without metric information. Results show that incorporating code metrics improves the accuracy and contextual relevance of generated documentation, yielding gains of 6% in BLEU-1 and 3% in ROUGE-L F1 for CNN-RNN-based architecture, and 9% in BERTScore F1 for LLM-based architecture. These findings demonstrate that integrating code metrics provides valuable structural context, enhancing automated documentation generation across diverse model families.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u4ee3\u7801\u5ea6\u91cf\u6307\u6807\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u606f\uff0c\u6539\u8fdb\u4e86\u8ba1\u7b97\u7b14\u8bb0\u672c\u6587\u6863\u81ea\u52a8\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u6a21\u578b\u4e0a\u5747\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u6587\u6863\u7684\u8d28\u91cf\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6587\u6863\u751f\u6210\u65b9\u6cd5\u5728\u6355\u6349\u4ee3\u7801\u7ed3\u6784\u548c\u91cf\u5316\u7279\u5f81\u65b9\u9762\u4e0d\u8db3\uff0c\u800c\u4ee3\u7801\u5ea6\u91cf\u6307\u6807\u5305\u542b\u6709\u52a9\u4e8e\u7a0b\u5e8f\u7406\u89e3\u7684\u91cd\u8981\u4fe1\u606f\u3002\u6570\u636e\u79d1\u5b66\u4e2d\u4f7f\u7528\u7684\u8ba1\u7b97\u7b14\u8bb0\u672c\u6587\u6863\u4e0d\u4e00\u81f4\uff0c\u8be5\u9886\u57df\u4e9f\u9700\u6539\u8fdb\u6587\u6863\u751f\u6210\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a\u4e00\u662f\u4eceCodeSearchNet\u6570\u636e\u96c6\u4e2d\u7b5b\u9009\u9ad8\u8d28\u91cf\u4ee3\u7801\u4e0e\u6587\u6863\u5bf9\u6784\u5efa\u4e13\u95e8\u6570\u636e\u96c6\uff1b\u4e8c\u662f\u8bc4\u4f30\u8f7b\u91cf\u7ea7CNN-RNN\u548c\u5c11\u91cf\u8bad\u7ec3\u7684GPT-3.5\u67b6\u6784\uff0c\u6bd4\u8f83\u52a0\u5165\u4e0e\u4e0d\u52a0\u5165\u4ee3\u7801\u5ea6\u91cf\u4fe1\u606f\u7684\u6548\u679c\u3002", "result": "\u901a\u8fc7\u5728\u6a21\u578b\u4e2d\u52a0\u5165\u4ee3\u7801\u5ea6\u91cf\uff0cCNN-RNN\u6a21\u578bBLEU-1\u6307\u6807\u63d0\u53476%\uff0cROUGE-L F1\u63d0\u53473%\uff1bLLM\u6a21\u578bBERTScore F1\u63d0\u53479%\uff0c\u8868\u660e\u4ee3\u7801\u5ea6\u91cf\u6709\u6548\u63d0\u9ad8\u4e86\u6587\u6863\u751f\u6210\u7684\u8868\u73b0\u3002", "conclusion": "\u96c6\u6210\u4ee3\u7801\u5ea6\u91cf\u6307\u6807\u4f5c\u4e3a\u8f85\u52a9\u4fe1\u53f7\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u52a8\u6587\u6863\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u589e\u5f3a\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u7684\u6027\u80fd\u3002"}}
{"id": "2602.07594", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07594", "abs": "https://arxiv.org/abs/2602.07594", "authors": ["Yuxin Chen", "Yu Wang", "Yi Zhang", "Ziang Ye", "Zhengzhou Cai", "Yaorui Shi", "Qi Gu", "Hui Su", "Xunliang Cai", "Xiang Wang", "An Zhang", "Tat-Seng Chua"], "title": "Learning to Self-Verify Makes Language Models Better Reasoners", "comment": null, "summary": "Recent large language models (LLMs) achieve strong performance in generating promising reasoning paths for complex tasks. However, despite powerful generation ability, LLMs remain weak at verifying their own answers, revealing a persistent capability asymmetry between generation and self-verification. In this work, we conduct an in-depth investigation of this asymmetry throughout training evolution and show that, even on the same task, improving generation does not lead to corresponding improvements in self-verification. Interestingly, we find that the reverse direction of this asymmetry behaves differently: learning to self-verify can effectively improve generation performance, achieving accuracy comparable to standard generation training while yielding more efficient and effective reasoning traces. Building on this observation, we further explore integrating self-verification into generation training by formulating a multi-task reinforcement learning framework, where generation and self-verification are optimized as two independent but complementary objectives. Extensive experiments across benchmarks and models demonstrate performance gains over generation-only training in both generation and verification capabilities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u80fd\u529b\u548c\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\u5b58\u5728\u4e0d\u5bf9\u79f0\u6027\uff0c\u63d0\u51fa\u901a\u8fc7\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u878d\u5408\u4e24\u8005\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u751f\u6210\u548c\u9a8c\u8bc1\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u7684\u63a8\u7406\u8def\u5f84\u751f\u6210\u4e0a\u8868\u73b0\u4f18\u79c0\uff0c\u4f46\u5728\u81ea\u6211\u9a8c\u8bc1\u7b54\u6848\u65b9\u9762\u8868\u73b0\u8f83\u5f31\uff0c\u5b58\u5728\u80fd\u529b\u4e0d\u5bf9\u79f0\u73b0\u8c61\uff0c\u9700\u63a2\u7d22\u4e8c\u8005\u5173\u7cfb\u53ca\u63d0\u5347\u7b56\u7565\u3002", "method": "\u6784\u5efa\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u89c6\u4e3a\u4e24\u4e2a\u72ec\u7acb\u4f46\u4e92\u8865\u7684\u4f18\u5316\u76ee\u6807\uff0c\u8054\u5408\u8bad\u7ec3\u4ee5\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u6a21\u578b\u5728\u751f\u6210\u548c\u81ea\u6211\u9a8c\u8bc1\u4e24\u4e2a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5747\u4f18\u4e8e\u5355\u72ec\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u8fbe\u5230\u66f4\u9ad8\u51c6\u786e\u7387\u5e76\u751f\u6210\u66f4\u9ad8\u6548\u6709\u6548\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "conclusion": "\u751f\u6210\u80fd\u529b\u4e0e\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\u5b58\u5728\u663e\u8457\u7684\u975e\u5bf9\u79f0\u6027\uff0c\u63d0\u5347\u751f\u6210\u80fd\u529b\u5e76\u4e0d\u4e00\u5b9a\u63d0\u9ad8\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\uff0c\u4f46\u63d0\u5347\u81ea\u6211\u9a8c\u8bc1\u80fd\u529b\u53ef\u4ee5\u53cd\u5411\u4fc3\u8fdb\u751f\u6210\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2602.08146", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08146", "abs": "https://arxiv.org/abs/2602.08146", "authors": ["Pengyu Chang", "Yixiong Fang", "Silin Chen", "Yuling Shi", "Beijun Shen", "Xiaodong Gu"], "title": "Test vs Mutant: Adversarial LLM Agents for Robust Unit Test Generation", "comment": null, "summary": "Software testing is a critical, yet resource-intensive phase of the software development lifecycle. Over the years, various automated tools have been developed to aid in this process. Search-based approaches typically achieve high coverage but produce tests with low readability, whereas large language model (LLM)-based methods generate more human-readable tests but often suffer from low coverage and compilability. While the majority of research efforts have focused on improving test coverage and readability, little attention has been paid to enhancing the robustness of bug detection, particularly in exposing corner cases and vulnerable execution paths. To address this gap, we propose AdverTest, a novel adversarial framework for LLM-powered test case generation. AdverTest comprises two interacting agents: a test case generation agent (T) and a mutant generation agent (M). These agents engage in an adversarial loop, where M persistently creates new mutants \"hacking\" the blind spots of T's current test suite, while T iteratively refines its test cases to \"kill\" the challenging mutants produced by M. This interaction loop is guided by both coverage and mutation scores, enabling the system to co-evolve toward both high test coverage and bug detection capability. Experimental results in the Defects4J dataset show that our approach improves fault detection rates by 8.56% over the best existing LLM-based methods and by 63.30% over EvoSuite, while also improving line and branch coverage.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faAdverTest\u5bf9\u6297\u6846\u67b6\u63d0\u5347LLM\u9a71\u52a8\u6d4b\u8bd5\u7528\u4f8b\u7684\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u548c\u8986\u76d6\u7387\uff0c\u5b9e\u9a8c\u8bc1\u660e\u6548\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u6ce8\u91cd\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53ef\u8bfb\u6027\uff0c\u7f3a\u4e4f\u5bf9\u8fb9\u754c\u60c5\u51b5\u548c\u8106\u5f31\u6267\u884c\u8def\u5f84\u7684\u9c81\u68d2\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u7684\u5173\u6ce8\u3002", "method": "\u63d0\u51fa\u4e86\u7531\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u4ee3\u7406(T)\u548c\u53d8\u5f02\u4f53\u751f\u6210\u4ee3\u7406(M)\u7ec4\u6210\u7684\u5bf9\u6297\u6846\u67b6\uff0c\u4e8c\u8005\u5728\u8986\u76d6\u7387\u548c\u53d8\u5f02\u5f97\u5206\u7684\u6307\u5bfc\u4e0b\u5faa\u73af\u4ea4\u4e92\uff0c\u9010\u6b65\u4f18\u5316\u6d4b\u8bd5\u96c6\u3002", "result": "\u5728Defects4J\u6570\u636e\u96c6\u4e0a\uff0cAdverTest\u76f8\u6bd4\u73b0\u6709\u6700\u4f73LLM\u65b9\u6cd5\u7f3a\u9677\u68c0\u6d4b\u7387\u63d0\u53478.56%\uff0c\u76f8\u6bd4EvoSuite\u63d0\u534763.30%\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4ee3\u7801\u884c\u8986\u76d6\u7387\u548c\u5206\u652f\u8986\u76d6\u7387\u3002", "conclusion": "AdverTest\u901a\u8fc7\u5bf9\u6297\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u9a71\u52a8\u7684\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u5728\u7f3a\u9677\u68c0\u6d4b\u548c\u4ee3\u7801\u8986\u76d6\u65b9\u9762\u7684\u8868\u73b0\u3002"}}
{"id": "2602.07621", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07621", "abs": "https://arxiv.org/abs/2602.07621", "authors": ["Xanh Ho", "Yun-Ang Wu", "Sunisth Kumar", "Tian Cheng Xia", "Florian Boudin", "Andre Greiner-Petter", "Akiko Aizawa"], "title": "SciClaimEval: Cross-modal Claim Verification in Scientific Papers", "comment": "12 pages; data is available at https://sciclaimeval.github.io/", "summary": "We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we introduce a novel approach that modifies the supporting evidence (figures and tables), rather than altering the claims or relying on large language models (LLMs) to fabricate contradictions. The dataset provides cross-modal evidence with diverse representations: figures are available as images, while tables are provided in multiple formats, including images, LaTeX source, HTML, and JSON. SciClaimEval contains 1,664 annotated samples from 180 papers across three domains, machine learning, natural language processing, and medicine, validated through expert annotation. We benchmark 11 multimodal foundation models, both open-source and proprietary, across the dataset. Results show that figure-based verification remains particularly challenging for all models, as a substantial performance gap remains between the best system and human baseline.", "AI": {"tldr": "SciClaimEval\u662f\u4e00\u4e2a\u5305\u542b\u771f\u5b9e\u79d1\u5b66\u58f0\u660e\u548c\u8de8\u6a21\u6001\u8bc1\u636e\u7684\u65b0\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u65b0\u65b9\u6cd5\u751f\u6210\u53cd\u9a73\u58f0\u660e\uff0c\u5bf9\u591a\u6a21\u6001\u6a21\u578b\u8fdb\u884c\u4e86\u8bc4\u6d4b\uff0c\u7ed3\u679c\u663e\u793a\u56fe\u50cf\u9a8c\u8bc1\u4efb\u52a1\u4f9d\u7136\u5177\u6709\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u6570\u636e\u96c6\u7f3a\u4e4f\u771f\u5b9e\u4e14\u591a\u6a21\u6001\uff08\u56fe\u50cf\u548c\u8868\u683c\uff09\u8bc1\u636e\uff0c\u4e14\u53cd\u9a73\u58f0\u660e\u591a\u9760\u5408\u6210\u6216\u4fee\u6539\u58f0\u660e\u672c\u8eab\uff0c\u96be\u4ee5\u53cd\u6620\u771f\u5b9e\u573a\u666f\u3002", "method": "\u901a\u8fc7\u4ece\u53d1\u8868\u7684\u8bba\u6587\u4e2d\u76f4\u63a5\u63d0\u53d6\u771f\u5b9e\u58f0\u660e\uff0c\u91c7\u7528\u65b0\u9896\u65b9\u6cd5\u901a\u8fc7\u4fee\u6539\u652f\u6301\u8bc1\u636e\uff08\u56fe\u8868\u548c\u8868\u683c\uff09\u751f\u6210\u53cd\u9a73\u58f0\u660e\uff0c\u800c\u975e\u6539\u53d8\u58f0\u660e\u6587\u672c\u6216\u501f\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u5236\u9020\u77db\u76fe\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b1664\u4e2a\u6807\u6ce8\u6837\u672c\uff0c\u6db5\u76d6180\u7bc7\u8bba\u6587\u548c\u4e09\u4e2a\u9886\u57df\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5bf911\u4e2a\u591a\u6a21\u6001\u57fa\u7840\u6a21\u578b\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6240\u6709\u6a21\u578b\u5728\u57fa\u4e8e\u56fe\u50cf\u7684\u9a8c\u8bc1\u4e0a\u4ecd\u5b58\u8f83\u5927\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "SciClaimEval \u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u771f\u5b9e\u4e14\u591a\u6a21\u6001\u7684\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u8d44\u6e90\uff0c\u5c24\u5176\u662f\u5728\u56fe\u50cf\u548c\u8868\u683c\u7684\u8de8\u6a21\u6001\u8bc1\u636e\u65b9\u9762\uff0c\u73b0\u6709\u6a21\u578b\u5728\u56fe\u50cf\uff08\u56fe\u8868\uff09\u9a8c\u8bc1\u4efb\u52a1\u4e0a\u4ecd\u8868\u73b0\u8f83\u5dee\u3002"}}
{"id": "2602.08166", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08166", "abs": "https://arxiv.org/abs/2602.08166", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "Distributed Architecture Reconstruction of Polyglot and Multi-Repository Microservice Projects", "comment": null, "summary": "Microservice architectures encourage the use of small, independently developed services; however, this can lead to increased architectural complexity. Accurate documentation is crucial, but is challenging to maintain due to the rapid, independent evolution of services. While static architecture reconstruction provides a way to maintain up-to-date documentation, existing approaches suffer from technology limitations, mono-repo constraints, or high implementation barriers. This paper presents a novel framework for static architecture reconstruction that supports technology-specific analysis modules, called \\emph{extractors}, and supports \\emph{distributed architecture reconstruction} in multi-repo environments. We describe the core design concepts and algorithms that govern how extractors are executed, how data is passed between them, and how their outputs are unified. Furthermore, the framework is interoperable with existing static analysis tools and algorithms, allowing them to be invoked from or embedded within extractors.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u652f\u6301\u591a\u6280\u672f\u6a21\u5757\u548c\u591a\u4ed3\u5e93\u73af\u5883\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u67b6\u6784\u6587\u6863\u96be\u7ef4\u62a4\u7684\u95ee\u9898\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u4e0b\u670d\u52a1\u6570\u91cf\u591a\u4e14\u5404\u81ea\u72ec\u7acb\uff0c\u5bfc\u81f4\u67b6\u6784\u590d\u6742\u4e14\u6587\u6863\u96be\u4ee5\u7ef4\u62a4\u3002\u73b0\u6709\u9759\u6001\u67b6\u6784\u91cd\u5efa\u65b9\u6cd5\u5b58\u5728\u6280\u672f\u9650\u5236\u3001\u5355\u4ed3\u5e93\u7ea6\u675f\u548c\u5b9e\u73b0\u95e8\u69db\u9ad8\u7b49\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u5957\u652f\u6301\u6280\u672f\u4e13\u7528\u5206\u6790\u6a21\u5757\uff08extractors\uff09\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\uff1b\u63d0\u51fa\u4e86extractors\u7684\u6267\u884c\u673a\u5236\u3001\u6570\u636e\u4f20\u9012\u548c\u7ed3\u679c\u7edf\u4e00\u7b97\u6cd5\uff1b\u652f\u6301\u4e0e\u73b0\u6709\u9759\u6001\u5206\u6790\u5de5\u5177\u548c\u7b97\u6cd5\u7684\u4e92\u64cd\u4f5c\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7075\u6d3b\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\uff0c\u652f\u6301\u591a\u6280\u672f\u5206\u6790\u6a21\u5757\u7684\u7ec4\u5408\u548c\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u5efa\uff0c\u5e76\u4e14\u80fd\u591f\u4e0e\u73b0\u6709\u5de5\u5177\u517c\u5bb9\uff0c\u63d0\u9ad8\u4e86\u67b6\u6784\u6587\u6863\u7684\u51c6\u786e\u6027\u548c\u7ef4\u62a4\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u9759\u6001\u67b6\u6784\u91cd\u5efa\u6846\u67b6\u6709\u6548\u652f\u6301\u591a\u6280\u672f\u5206\u6790\u6a21\u5757\u548c\u591a\u4ed3\u5e93\u73af\u5883\u4e0b\u7684\u5206\u5e03\u5f0f\u67b6\u6784\u91cd\u5efa\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u6280\u672f\u9650\u5236\u3001\u5355\u4e00\u4ed3\u5e93\u548c\u5b9e\u73b0\u96be\u5ea6\u65b9\u9762\u7684\u95ee\u9898\u3002"}}
{"id": "2602.07639", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07639", "abs": "https://arxiv.org/abs/2602.07639", "authors": ["Jaewook Lee", "Alexander Scarlatos", "Simon Woodhead", "Andrew Lan"], "title": "Letting Tutor Personas \"Speak Up\" for LLMs: Learning Steering Vectors from Dialogue via Preference Optimization", "comment": null, "summary": "With the emergence of large language models (LLMs) as a powerful class of generative artificial intelligence (AI), their use in tutoring has become increasingly prominent. Prior works on LLM-based tutoring typically learn a single tutor policy and do not capture the diversity of tutoring styles. In real-world tutor-student interactions, pedagogical intent is realized through adaptive instructional strategies, with tutors varying the level of scaffolding, instructional directiveness, feedback, and affective support in response to learners' needs. These differences can all impact dialogue dynamics and student engagement. In this paper, we explore how tutor personas embedded in human tutor-student dialogues can be used to guide LLM behavior without relying on explicitly prompted instructions. We modify Bidirectional Preference Optimization (BiPO) to learn a steering vector, an activation-space direction that steers model responses towards certain tutor personas. We find that this steering vector captures tutor-specific variation across dialogue contexts, improving semantic alignment with ground-truth tutor utterances and increasing preference-based evaluations, while largely preserving lexical similarity. Analysis of the learned directional coefficients further reveals interpretable structure across tutors, corresponding to consistent differences in tutoring behavior. These results demonstrate that activation steering offers an effective and interpretable way for controlling tutor-specific variation in LLMs using signals derived directly from human dialogue data.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fee\u6539BiPO\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411\uff0c\u5f15\u5bfcLLMs\u5c55\u73b0\u591a\u6837\u8f85\u5bfc\u8005\u98ce\u683c\uff0c\u6709\u6548\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u4e0e\u7528\u6237\u504f\u597d\uff0c\u63d0\u4f9b\u5bf9\u8f85\u5bfc\u98ce\u683c\u53d8\u5316\u7684\u53ef\u89e3\u91ca\u63a7\u5236\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edfLLM\u8f85\u5bfc\u7814\u7a76\u901a\u5e38\u53ea\u5b66\u4e60\u5355\u4e00\u8f85\u5bfc\u7b56\u7565\uff0c\u5ffd\u89c6\u4e86\u6559\u5b66\u98ce\u683c\u7684\u591a\u6837\u6027\uff0c\u800c\u73b0\u5b9e\u4e2d\u8f85\u5bfc\u8005\u901a\u8fc7\u8c03\u6574\u4e0d\u540c\u7684\u6559\u5b66\u7b56\u7565\u6ee1\u8db3\u5b66\u751f\u9700\u6c42\uff0c\u5f71\u54cd\u5bf9\u8bdd\u52a8\u6001\u548c\u5b66\u751f\u53c2\u4e0e\u5ea6\u3002", "method": "\u5bf9\u53cc\u5411\u504f\u597d\u4f18\u5316(BiPO)\u65b9\u6cd5\u8fdb\u884c\u4fee\u6539\uff0c\u5b66\u4e60\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684steering vector\u4ee5\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u7279\u5b9a\u8f85\u5bfc\u8005\u98ce\u683c\u7684\u56de\u7b54\uff0c\u65e0\u9700\u663e\u5f0f\u63d0\u793a\u6307\u4ee4\u3002", "result": "\u5b66\u4e60\u5230\u7684steering vector\u80fd\u591f\u6355\u6349\u4e0d\u540c\u8f85\u5bfc\u8005\u5728\u5bf9\u8bdd\u4e2d\u7684\u884c\u4e3a\u5dee\u5f02\uff0c\u663e\u8457\u6539\u5584\u6a21\u578b\u751f\u6210\u56de\u7b54\u7684\u8bed\u4e49\u5bf9\u9f50\u548c\u7528\u6237\u504f\u597d\u8bc4\u4f30\uff0c\u63ed\u793a\u4e86\u8f85\u5bfc\u98ce\u683c\u7684\u7ed3\u6784\u5316\u5dee\u5f02\u3002", "conclusion": "\u901a\u8fc7\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411(steering vector)\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u8f85\u5bfc\u8005\u98ce\u683c\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u6a21\u578b\u5bf9\u4eba\u7c7b\u8f85\u5bfc\u8bed\u53e5\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u504f\u597d\u8bc4\u5206\uff0c\u540c\u65f6\u4fdd\u6301\u8bcd\u6c47\u76f8\u4f3c\u6027\uff0c\u4e14\u8f85\u5bfc\u884c\u4e3a\u5dee\u5f02\u5177\u6709\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2602.08181", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08181", "abs": "https://arxiv.org/abs/2602.08181", "authors": ["Oscar Manglaras", "Alex Farkas", "Thomas Woolford", "Christoph Treude", "Markus Wagner"], "title": "ModARO: A Modular Approach to Architecture Reconstruction of Distributed Microservice Codebases", "comment": null, "summary": "Microservice architectures promote small, independently developed services, but increase overall architectural complexity. It is crucial that developers understand the architecture and how changes to a service affect the overall system, but rapid and independent development of services increases the risk of architectural drift and discourages the creation and maintenance of documentation. Automatic architecture reconstruction can help avoid these issues, but it is difficult to reuse reconstruction code across multiple projects, as all use different combinations of technologies and project-specific conventions. Reconstruction of architecture-level details is further complicated by the tendency to split microservices into separate repositories, preventing a full view of the system from any one codebase. In this paper, we present and evaluate ModARO, an approach to microservice architecture reconstruction that allows writing modular reconstruction code ('extractors') for any technologies and reusing them across different projects, independent of the surrounding technology stack or whether or not the services are split into multiple codebases. We demonstrate the effectiveness of our approach by configuring ModARO to reconstruct 10 open source projects, and we validate the usefulness and usability of ModARO against a state-of-the-art baseline in a user study with 8 industry practitioners. Using this approach, developers can assemble or create extractors tailored to their technology stacks and distribute architecture reconstruction across repositories, enabling integration into repository CI/CD pipelines.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faModARO\uff0c\u4e00\u79cd\u6a21\u5757\u5316\u7684\u5fae\u670d\u52a1\u67b6\u6784\u81ea\u52a8\u91cd\u6784\u65b9\u6cd5\uff0c\u652f\u6301\u8de8\u9879\u76ee\u3001\u8de8\u6280\u672f\u6808\u91cd\u7528\u4ee3\u7801\uff0c\u89e3\u51b3\u4e86\u591a\u4ee3\u7801\u5e93\u5206\u5e03\u5e26\u6765\u7684\u67b6\u6784\u590d\u6742\u6027\uff0c\u4e14\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u867d\u4fc3\u8fdb\u72ec\u7acb\u670d\u52a1\u5f00\u53d1\uff0c\u4f46\u5e26\u6765\u67b6\u6784\u590d\u6742\u6027\u548c\u6587\u6863\u7ef4\u62a4\u56f0\u96be\uff0c\u4e14\u591a\u4ee3\u7801\u5e93\u5206\u6563\u4f7f\u67b6\u6784\u91cd\u6784\u66f4\u52a0\u56f0\u96be\uff0c\u4e9f\u9700\u4e00\u79cd\u8de8\u9879\u76ee\u91cd\u7528\u4e14\u6280\u672f\u65e0\u5173\u7684\u81ea\u52a8\u67b6\u6784\u91cd\u6784\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86ModARO\u6846\u67b6\uff0c\u5229\u7528\u6a21\u5757\u5316\u7684\u91cd\u6784\u4ee3\u7801('extractors')\uff0c\u652f\u6301\u4e0d\u540c\u6280\u672f\u6808\u548c\u591a\u4ee3\u7801\u5e93\u73af\u5883\u4e0b\u7684\u67b6\u6784\u91cd\u6784\uff0c\u7ed3\u5408CI/CD\u6d41\u6c34\u7ebf\u5b9e\u73b0\u81ea\u52a8\u5316\u3002", "result": "ModARO\u6210\u529f\u914d\u7f6e\u7528\u4e8e10\u4e2a\u5f00\u6e90\u9879\u76ee\uff0c\u5e76\u901a\u8fc78\u540d\u4e1a\u5185\u4ece\u4e1a\u8005\u7684\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u548c\u6613\u7528\u6027\uff0c\u5c55\u793a\u4e86\u826f\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "ModARO\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5fae\u670d\u52a1\u67b6\u6784\u7684\u81ea\u52a8\u91cd\u6784\uff0c\u652f\u6301\u8de8\u6280\u672f\u3001\u591a\u9879\u76ee\u7684\u91cd\u7528\uff0c\u89e3\u51b3\u4e86\u591a\u4ee3\u7801\u5e93\u5206\u6563\u5e26\u6765\u7684\u590d\u6742\u6027\u95ee\u9898\u3002"}}
{"id": "2602.07673", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07673", "abs": "https://arxiv.org/abs/2602.07673", "authors": ["Jiangnan Fang", "Cheng-Tse Liu", "Hanieh Deilamsalehy", "Nesreen K. Ahmed", "Puneet Mathur", "Nedim Lipka", "Franck Dernoncourt", "Ryan A. Rossi"], "title": "Blind to the Human Touch: Overlap Bias in LLM-Based Summary Evaluation", "comment": null, "summary": "Large language model (LLM) judges have often been used alongside traditional, algorithm-based metrics for tasks like summarization because they better capture semantic information, are better at reasoning, and are more robust to paraphrasing. However, LLM judges show biases for length and order among others, and are vulnerable to various adversarial input prompts. While recent studies have looked into these biases, few have analyzed them at a more granular level in relation to a well-defined overlap metric. In this work we provide an LLM judge bias analysis as a function of overlap with human-written responses in the domain of summarization. We test 9 recent LLMs with parameter counts ranging from 1 billion to 12 billion, including variants of Gemma 3 and LLaMA 3. We find that LLM judges increasingly prefer summaries generated by other LLMs over those written by humans as the similarities (as measured by ROUGE and BLEU) between the judged summaries decrease, and this pattern extends to all but one model tested, and exists regardless of the models' own position biases. Additionally, we find that models struggle to judge even summaries with limited overlaps, suggesting that LLM-as-a-judge in the summary domain should rely on techniques beyond a simple comparison.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u4ef7\u8005\u5728\u5224\u65ad\u603b\u7ed3\u8d28\u91cf\u65f6\u5b58\u5728\u504f\u597d\u4e0e\u5c40\u9650\uff0c\u968f\u7740\u4e0e\u4eba\u5de5\u6458\u8981\u91cd\u53e0\u5ea6\u964d\u4f4e\uff0c\u6a21\u578b\u66f4\u504f\u7231\u673a\u5668\u751f\u6210\u7684\u603b\u7ed3\uff0c\u5efa\u8bae\u672a\u6765\u8bc4\u5224\u5e94\u7ed3\u5408\u66f4\u591a\u6280\u672f\u624b\u6bb5\u3002", "motivation": "\u5c3d\u7ba1LLM\u8bc4\u5224\u56e0\u5176\u66f4\u597d\u8bed\u4e49\u6355\u6349\u548c\u63a8\u7406\u80fd\u529b\u88ab\u5e7f\u6cdb\u7528\u4e8e\u603b\u7ed3\u8bc4\u4ef7\uff0c\u4f46\u5176\u504f\u5dee\u548c\u5bf9\u6297\u8106\u5f31\u6027\u4e0d\u8db3\u591f\u88ab\u7ec6\u81f4\u7814\u7a76\uff0c\u56e0\u6b64\u672c\u7814\u7a76\u65e8\u5728\u6df1\u5165\u63a2\u8ba8LLM\u8bc4\u5224\u5bf9\u603b\u7ed3\u4e0e\u4eba\u5de5\u6458\u8981\u91cd\u53e0\u5ea6\u7684\u654f\u611f\u6027\u3002", "method": "\u5206\u67909\u4e2a\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\uff0810\u4ebf\u5230120\u4ebf\uff09\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ecGemma 3\u548cLLaMA 3\u53d8\u4f53\uff0c\u901a\u8fc7\u4e0e\u4eba\u5de5\u64b0\u5199\u603b\u7ed3\u7684\u91cd\u53e0\u5ea6\uff08ROUGE\u548cBLEU\uff09\u6765\u7814\u7a76LLM\u8bc4\u5224\u504f\u5dee\u3002", "result": "\u53d1\u73b0\u6240\u6709\u6d4b\u8bd5\u6a21\u578b\u4e2d\uff0cLLM\u8bc4\u5224\u968f\u7740\u4e0e\u4eba\u5de5\u603b\u7ed3\u76f8\u4f3c\u5ea6\u964d\u4f4e\uff0c\u66f4\u504f\u7231LLM\u751f\u6210\u7684\u603b\u7ed3\uff0c\u4e14\u6a21\u578b\u5224\u65ad\u5373\u4f7f\u5728\u603b\u7ed3\u91cd\u53e0\u8f83\u5c11\u65f6\u4e5f\u8868\u73b0\u4e0d\u4f73\uff0c\u8868\u660e\u4ec5\u7528\u7b80\u5355\u6bd4\u8f83\u65e0\u6cd5\u5145\u5206\u8bc4\u4ef7\u603b\u7ed3\u8d28\u91cf\u3002", "conclusion": "LLM\u8bc4\u5224\u5728\u603b\u7ed3\u4efb\u52a1\u4e2d\u5b58\u5728\u660e\u663e\u504f\u597d\uff0c\u968f\u7740\u88ab\u8bc4\u4f30\u603b\u7ed3\u4e0e\u4eba\u5de5\u603b\u7ed3\u7684\u76f8\u4f3c\u5ea6\u4e0b\u964d\uff0cLLM\u8bc4\u5224\u66f4\u503e\u5411\u4e8e\u9009\u62e9\u7531\u5176\u4ed6LLM\u751f\u6210\u7684\u603b\u7ed3\uff0c\u4e14\u8fd9\u79cd\u504f\u597d\u72ec\u7acb\u4e8e\u6a21\u578b\u81ea\u8eab\u7684\u6392\u5e8f\u504f\u5dee\u3002"}}
{"id": "2602.08192", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08192", "abs": "https://arxiv.org/abs/2602.08192", "authors": ["Mirko Perkusich", "Danyllo Albuquerque", "Allysson Allex Ara\u00fajo", "Matheus Paix\u00e3o", "Rohit Gheyi", "Marcos Kalinowski", "Angelo Perkusich"], "title": "Adoption of Large Language Models in Scrum Management: Insights from Brazilian Practitioners", "comment": "Accepted for publication at the 27th International Conference on Agile Software Development (XP 2026)", "summary": "Scrum is widely adopted in software project management due to its adaptability and collaborative nature. The recent emergence of Large Language Models (LLMs) has created new opportunities to support knowledge-intensive Scrum practices. However, existing research has largely focused on technical activities such as coding and testing, with limited evidence on the use of LLMs in management-related Scrum activities. In this study, we investigate the use of LLMs in Scrum management activities through a survey of 70 Brazilian professionals. Among them, 49 actively use Scrum, and 33 reported using LLM-based assistants in their Scrum practices. The results indicate a high level of proficiency and frequent use of LLMs, with 85% of respondents reporting intermediate or advanced proficiency and 52% using them daily. LLM use concentrates on exploring Scrum practices, with artifacts and events receiving targeted yet uneven support, whereas broader management tasks appear to be adopted more cautiously. The main benefits include increased productivity (78%) and reduced manual effort (75%). However, several critical risks remain, as respondents report 'almost correct' outputs (81%), confidentiality concerns (63%), and hallucinations during use (59%). This work provides one of the first empirical characterizations of LLM use in Scrum management, identifying current practices, quantifying benefits and risks, and outlining directions for responsible adoption and integration in Agile environments.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86LLMs\u5728Scrum\u7ba1\u7406\u4e2d\u7684\u5e94\u7528\u72b6\u51b5\uff0c\u53d1\u73b0\u5176\u63d0\u9ad8\u4e86\u6548\u7387\u4f46\u5b58\u5728\u51c6\u786e\u6027\u548c\u5b89\u5168\u9690\u60a3\uff0c\u9996\u6b21\u4e3aScrum\u7ba1\u7406\u7ed3\u5408LLMs\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u6570\u636e\u548c\u6307\u5bfc\u5efa\u8bae\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u6280\u672f\u6d3b\u52a8\u4e2d\u5e94\u7528\u5e7f\u6cdb\uff0c\u4f46\u5176\u5728Scrum\u7ba1\u7406\u6d3b\u52a8\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u53ca\u6548\u679c\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u7814\u7a76\u3002\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u5bf970\u540d\u5df4\u897f\u4e13\u4e1a\u4eba\u58eb\u8fdb\u884c\u8c03\u67e5\uff0c\u6536\u96c6\u4ed6\u4eec\u5728Scrum\u7ba1\u7406\u4e2d\u4f7f\u7528LLM\u52a9\u624b\u7684\u5b9e\u9645\u60c5\u51b5\u548c\u7ecf\u9a8c\u3002", "result": "85%\u7684\u53d7\u8bbf\u8005\u5bf9LLM\u5177\u6709\u4e2d\u9ad8\u7ea7\u719f\u7ec3\u5ea6\uff0c52%\u6bcf\u5929\u4f7f\u7528\u3002LLM\u4e3b\u8981\u652f\u6301Scrum\u5b9e\u8df5\u4e2d\u7684\u7279\u5b9a\u4ea7\u7269\u548c\u4e8b\u4ef6\u7ba1\u7406\uff0c\u63d0\u5347\u751f\u4ea7\u529b\uff0878%\uff09\u548c\u51cf\u5c11\u624b\u5de5\u5de5\u4f5c\uff0875%\uff09\u3002\u4f46\u4e5f\u62a5\u544a\u4e86\u8f93\u51fa\u8fd1\u4f3c\u6b63\u786e\uff0881%\uff09\u3001\u4fdd\u5bc6\u987e\u8651\uff0863%\uff09\u548c\u5e7b\u89c9\uff0859%\uff09\u7b49\u98ce\u9669\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728Scrum\u7ba1\u7406\u6d3b\u52a8\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0LLMs\u88ab\u5e7f\u6cdb\u4f7f\u7528\u4e14\u5177\u6709\u663e\u8457\u63d0\u5347\u751f\u4ea7\u529b\u548c\u51cf\u5c11\u4eba\u5de5\u52aa\u529b\u7684\u6548\u679c\uff0c\u4f46\u540c\u65f6\u5b58\u5728\u8f93\u51fa\u51c6\u786e\u6027\u4e0d\u8db3\u3001\u4fdd\u5bc6\u6027\u98ce\u9669\u548c\u5e7b\u89c9\u73b0\u8c61\u7b49\u6311\u6218\u3002"}}
{"id": "2602.07773", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.07773", "abs": "https://arxiv.org/abs/2602.07773", "authors": ["Chen Zhang", "Kuicai Dong", "Dexun Li", "Wenjun Li", "Qu Yang", "Wei Han", "Yong Liu"], "title": "SRR-Judge: Step-Level Rating and Refinement for Enhancing Search-Integrated Reasoning in Search Agents", "comment": null, "summary": "Recent deep search agents built on large reasoning models (LRMs) excel at complex question answering by iteratively planning, acting, and gathering evidence, a capability known as search-integrated reasoning. However, mainstream approaches often train this ability using only outcome-based supervision, neglecting the quality of intermediate thoughts and actions. We introduce SRR-Judge, a framework for reliable step-level assessment of reasoning and search actions. Integrated into a modified ReAct-style rate-and-refine workflow, SRR-Judge provides fine-grained guidance for search-integrated reasoning and enables efficient post-training annotation. Using SRR-annotated data, we apply an iterative rejection sampling fine-tuning procedure to enhance the deep search capability of the base agent. Empirically, SRR-Judge delivers more reliable step-level evaluations than much larger models such as DeepSeek-V3.1, with its ratings showing strong correlation with final answer correctness. Moreover, aligning the policy with SRR-Judge annotated trajectories leads to substantial performance gains, yielding over a 10 percent average absolute pass@1 improvement across challenging deep search benchmarks.", "AI": {"tldr": "\u9488\u5bf9\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u63a8\u7406\u4e2d\u95f4\u6b65\u9aa4\u7f3a\u4e4f\u6709\u6548\u76d1\u7763\u7684\u95ee\u9898\uff0cSRR-Judge\u6846\u67b6\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6b65\u9aa4\u8bc4\u4f30\u548c\u6807\u6ce8\u63d0\u5347\u4e86\u63a8\u7406\u8d28\u91cf\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u641c\u7d22\u4ee3\u7406\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u4e3b\u6d41\u7684\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u8bad\u7ec3\u4ec5\u4f9d\u8d56\u7ed3\u679c\u5bfc\u5411\u76d1\u7763\uff0c\u5ffd\u7565\u4e86\u4e2d\u95f4\u601d\u8003\u548c\u884c\u52a8\u7684\u8d28\u91cf\uff0c\u5f71\u54cd\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u9760\u6027\u548c\u6548\u7387\u3002", "method": "\u63d0\u51faSRR-Judge\u6846\u67b6\uff0c\u7ed3\u5408\u4fee\u6539\u540e\u7684ReAct\u98ce\u683c\u7684rate-and-refine\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5b9e\u73b0\u9010\u6b65\u63a8\u7406\u548c\u641c\u7d22\u884c\u52a8\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4ef7\uff0c\u5e76\u5229\u7528SRR\u6807\u6ce8\u6570\u636e\u901a\u8fc7\u8fed\u4ee3\u62d2\u7edd\u91c7\u6837\u8fdb\u884c\u5fae\u8c03\u4f18\u5316\u3002", "result": "SRR-Judge\u5728\u6b65\u9aa4\u7ea7\u8bc4\u4ef7\u4e0a\u4f18\u4e8e\u66f4\u5927\u89c4\u6a21\u6a21\u578b\uff08\u5982DeepSeek-V3.1\uff09\uff0c\u5176\u8bc4\u5206\u4e0e\u6700\u7ec8\u7b54\u6848\u6b63\u786e\u6027\u5f3a\u76f8\u5173\uff0c\u5fae\u8c03\u540e\u7684\u4ee3\u7406\u5728\u591a\u4e2a\u590d\u6742\u6df1\u5ea6\u641c\u7d22\u57fa\u51c6\u4e0a\u6709\u8d85\u8fc710%\u7684\u7edd\u5bf9\u901a\u8fc7\u7387\u63d0\u5347\u3002", "conclusion": "SRR-Judge\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u6df1\u5ea6\u641c\u7d22\u4ee3\u7406\u7684\u63a8\u7406\u548c\u641c\u7d22\u80fd\u529b\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u9010\u6b65\u8bc4\u4f30\u548c\u6807\u6ce8\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u884c\u52a8\u8d28\u91cf\u5224\u65ad\u548c\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.08242", "categories": ["cs.SE", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.08242", "abs": "https://arxiv.org/abs/2602.08242", "authors": ["Ali Hassaan Mughal", "Muhammad Bilal"], "title": "Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications", "comment": "18 pages, 5 figures, 3 tables. Code and data: https://github.com/amughalbscs16/network-layer-quality-testing", "summary": "Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u81ea\u52a8\u5316\u5de5\u5177\u5206\u6790\u4e8618\u4e2a\u73b0\u4ee3\u7f51\u7ad9\u7684HTTP API\u8c03\u7528\u8d28\u91cf\uff0c\u53d1\u73b0\u666e\u904d\u5b58\u5728\u5197\u4f59\u8bf7\u6c42\u548c\u7f13\u5b58\u7f3a\u5931\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u6846\u67b6\uff0c\u4e3a\u7f51\u9875\u6027\u80fd\u548c\u5b89\u5168\u6539\u8fdb\u63d0\u4f9b\u6570\u636e\u652f\u6301\u3002", "motivation": "\u5f53\u524d\u73b0\u4ee3\u7f51\u9875\u5e94\u7528\u5ba2\u6237\u7aefAPI\u8c03\u7528\u8d28\u91cf\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6d4b\u8bd5\uff0c\u800c\u8fd9\u4e9b\u8d28\u91cf\u7f3a\u9677\u4e0d\u4ec5\u5f71\u54cd\u6027\u80fd\uff0c\u8fd8\u5e26\u6765\u5b89\u5168\u9690\u60a3\u3002", "method": "\u901a\u8fc7Playwright\u81ea\u52a8\u5316\u6d4f\u89c8\u5668\uff0c\u6536\u96c618\u4e2a\u7c7b\u522b\u768418\u4e2a\u751f\u4ea7\u7f51\u7ad9\u7684108\u4e2aHTTP Archive\uff08HAR\uff09\u6587\u4ef6\uff0c\u5e94\u75288\u4e2a\u542f\u53d1\u5f0f\u53cd\u6a21\u5f0f\u68c0\u6d4b\u5668\uff0c\u751f\u62100-100\u7684\u8d28\u91cf\u8bc4\u5206\u3002", "result": "\u6700\u4f18\u670d\u52a1\u5668\u6e32\u67d3\u7684\u7f51\u7ad9\u83b7\u5f97\u6ee1\u5206100\u5206\uff0c\u5185\u5bb9\u4e30\u5bcc\u7684\u5546\u4e1a\u7f51\u7ad9\u6700\u4f4e\u4ec5\u5f9756.8\u5206\u300267%\u7684\u7f51\u7ad9\u5b58\u5728\u5197\u4f59API\u8c03\u7528\u548c\u7f3a\u5931\u7f13\u5b58\u5934\uff0c72%\u7684\u7f51\u7ad9\u7b2c\u4e09\u65b9\u8bf7\u6c42\u5360\u6bd4\u8d85\u8fc720%\u3002\u6700\u5927\u8bf7\u6c42\u6570\u8fbe2,684\u6b21\uff0c\u8fdc\u8d85\u6700\u7b80\u7ad9\u70b9\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u4ee3\u7f51\u9875\u5e94\u7528\u4e2dHTTP API\u8c03\u7528\u8d28\u91cf\u7684\u5de8\u5927\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u5197\u4f59\u8bf7\u6c42\u3001\u7f3a\u5931\u7f13\u5b58\u5934\u548c\u7b2c\u4e09\u65b9\u4f9d\u8d56\u8fc7\u591a\u7b49\u5e38\u89c1\u53cd\u6a21\u5f0f\u5bf9\u6027\u80fd\u548c\u5b89\u5168\u7684\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2602.07778", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07778", "abs": "https://arxiv.org/abs/2602.07778", "authors": ["Shenglai Zeng", "Tianqi Zheng", "Chuan Tian", "Dante Everaert", "Yau-Shian Wang", "Yupin Huang", "Michael J. Morais", "Rohit Patki", "Jinjin Tian", "Xinnan Dai", "Kai Guo", "Monica Xiao Cheng", "Hui Liu"], "title": "Attn-GS: Attention-Guided Context Compression for Efficient Personalized LLMs", "comment": null, "summary": "Personalizing large language models (LLMs) to individual users requires incorporating extensive interaction histories and profiles, but input token constraints make this impractical due to high inference latency and API costs. Existing approaches rely on heuristic methods such as selecting recent interactions or prompting summarization models to compress user profiles. However, these methods treat context as a monolithic whole and fail to consider how LLMs internally process and prioritize different profile components. We investigate whether LLMs' attention patterns can effectively identify important personalization signals for intelligent context compression. Through preliminary studies on representative personalization tasks, we discover that (a) LLMs' attention patterns naturally reveal important signals, and (b) fine-tuning enhances LLMs' ability to distinguish between relevant and irrelevant information. Based on these insights, we propose Attn-GS, an attention-guided context compression framework that leverages attention feedback from a marking model to mark important personalization sentences, then guides a compression model to generate task-relevant, high-quality compressed user contexts. Extensive experiments demonstrate that Attn-GS significantly outperforms various baselines across different tasks, token limits, and settings, achieving performance close to using full context while reducing token usage by 50 times.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5Attn-GS\uff0c\u663e\u8457\u51cf\u5c11\u8f93\u5165\u4ee4\u724c\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u5b8c\u6574\u4e0a\u4e0b\u6587\u7684\u6548\u679c\u3002", "motivation": "\u7531\u4e8e\u4e2a\u6027\u5316LLM\u9700\u8981\u878d\u5165\u5927\u91cf\u7528\u6237\u4ea4\u4e92\u5386\u53f2\u548c\u4e2a\u4eba\u8d44\u6599\uff0c\u8f93\u5165\u4ee4\u724c\u9650\u5236\u5bfc\u81f4\u9ad8\u5ef6\u8fdf\u548c\u9ad8API\u6210\u672c\uff0c\u73b0\u6709\u542f\u53d1\u5f0f\u538b\u7f29\u65b9\u6cd5\u5ffd\u89c6\u4e86LLM\u5185\u90e8\u5bf9\u4e0d\u540c\u4e0a\u4e0b\u6587\u6210\u5206\u7684\u5904\u7406\u673a\u5236\uff0c\u96be\u4ee5\u9ad8\u6548\u63d0\u53d6\u5173\u952e\u4fe1\u606f\u3002", "method": "\u8be5\u65b9\u6cd5\u57fa\u4e8e\u5bf9LLM\u6ce8\u610f\u529b\u6a21\u5f0f\u7684\u5206\u6790\uff0c\u4f7f\u7528\u6807\u8bb0\u6a21\u578b\u8bc6\u522b\u91cd\u8981\u4e2a\u6027\u5316\u53e5\u5b50\uff0c\u8fdb\u800c\u5f15\u5bfc\u538b\u7f29\u6a21\u578b\u751f\u6210\u4e0e\u4efb\u52a1\u76f8\u5173\u4e14\u9ad8\u8d28\u91cf\u7684\u538b\u7f29\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u5fae\u8c03\u63d0\u5347\u6a21\u578b\u533a\u5206\u91cd\u8981\u4fe1\u606f\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cAttn-GS\u5728\u591a\u79cd\u4efb\u52a1\u548c\u8bbe\u7f6e\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u51cf\u5c1150\u500d\u4ee4\u724c\u4f7f\u7528\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4fdd\u6301\u63a5\u8fd1\u4f7f\u7528\u5b8c\u6574\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Attn-GS\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7528\u6237\u4e2a\u6027\u5316\u4e0a\u4e0b\u6587\u7684\u667a\u80fd\u538b\u7f29\uff0c\u5728\u4fdd\u6301\u63a5\u8fd1\u5b8c\u6574\u4e0a\u4e0b\u6587\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8f93\u5165\u4ee4\u724c\u6570\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\u548c\u964d\u4f4e\u4e86\u6210\u672c\u3002"}}
{"id": "2602.08263", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08263", "abs": "https://arxiv.org/abs/2602.08263", "authors": ["Taohong Zhu", "Lucas C. Cordeiro", "Mustafa A. Mustafa", "Youcheng Sun"], "title": "Specification Vibing for Automated Program Repair", "comment": null, "summary": "Large language model (LLM)-driven automated program repair (APR) has advanced rapidly, but most methods remain code-centric: they directly rewrite source code and thereby risk hallucinated, behaviorally inconsistent fixes. This limitation suggests the need for an alternative repair paradigm that relies on a representation more accessible to LLMs than raw code, enabling more accurate understanding, analysis, and alignment during repair. To address this gap, we propose VibeRepair, a specification-centric APR technique that treats repair as behavior-specification repair rather than ad-hoc code editing. VibeRepair first translates buggy code into a structured behavior specification that captures the program's intended runtime behavior, then infers and repairs specification misalignments, and finally synthesizes code strictly guided by the corrected behavior specification. An on-demand reasoning component enriches hard cases with program analysis and historical bug-fix evidence while controlling cost. Across Defects4J and real-world benchmarks and multiple LLMs, VibeRepair demonstrates consistently strong repair effectiveness with a significantly smaller patch space. On Defects4J v1.2, VibeRepair correctly repairs 174 bugs, exceeding the strongest state-of-the-art baseline by 28 bugs, which corresponds to a 19% improvement. On Defects4J v2.0, it repairs 178 bugs, outperforming prior approaches by 33 bugs, representing a 23% improvement. Evaluations on real-world benchmarks collected after the training period of selected LLMs further confirm its effectiveness and generalizability. By centering repair on explicit behavioral intent, VibeRepair reframes APR for the era of \"vibe\" coding: make the behavior sing, and the code will follow.", "AI": {"tldr": "VibeRepair\u901a\u8fc7\u4fee\u590d\u884c\u4e3a\u89c4\u8303\u800c\u975e\u76f4\u63a5\u4fee\u6539\u4ee3\u7801\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u5f00\u521b\u4e86\u57fa\u4e8e\u884c\u4e3a\u610f\u56fe\u7684\u7a0b\u5e8f\u4fee\u590d\u65b0\u8303\u5f0f\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u4e3b\u8981\u4fa7\u91cd\u4e8e\u4ee3\u7801\u672c\u8eab\uff0c\u5bb9\u6613\u4ea7\u751f\u5e7b\u89c9\u5f0f\u4e14\u884c\u4e3a\u4e0d\u4e00\u81f4\u7684\u4fee\u590d\u7ed3\u679c\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u8d34\u8fd1\u7a0b\u5e8f\u610f\u56fe\u3001\u6613\u4e8e\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u7684\u4fee\u590d\u8303\u5f0f\u3002", "method": "VibeRepair\u5148\u5c06\u6709\u7f3a\u9677\u7684\u4ee3\u7801\u8f6c\u6362\u4e3a\u7ed3\u6784\u5316\u7684\u884c\u4e3a\u89c4\u8303\uff0c\u6355\u83b7\u7a0b\u5e8f\u7684\u9884\u671f\u8fd0\u884c\u884c\u4e3a\uff0c\u968f\u540e\u63a8\u65ad\u5e76\u4fee\u590d\u89c4\u8303\u7684\u4e0d\u4e00\u81f4\uff0c\u6700\u540e\u57fa\u4e8e\u6821\u6b63\u540e\u7684\u884c\u4e3a\u89c4\u8303\u5408\u6210\u4ee3\u7801\u3002\u8be5\u65b9\u6cd5\u8fd8\u5f15\u5165\u6309\u9700\u63a8\u7406\u7ec4\u4ef6\uff0c\u7ed3\u5408\u7a0b\u5e8f\u5206\u6790\u548c\u5386\u53f2\u4fee\u590d\u8bc1\u636e\u63d0\u9ad8\u4fee\u590d\u8d28\u91cf\u3002", "result": "\u5728Defects4J v1.2\u548cv2.0\u4ee5\u53ca\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cVibeRepair\u5206\u522b\u6b63\u786e\u4fee\u590d\u4e86174\u548c178\u4e2a\u7f3a\u9677\uff0c\u5206\u522b\u9886\u5148\u76ee\u524d\u6700\u5f3a\u57fa\u7ebf28\u548c33\u4e2a\uff0c\u63d0\u5347\u7387\u8fbe19%\u548c23%\uff0c\u540c\u65f6\u4fee\u590d\u7a7a\u95f4\u663e\u8457\u7f29\u5c0f\uff0c\u4e14\u5728\u8bad\u7ec3\u671f\u95f4\u540e\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "VibeRepair\u901a\u8fc7\u5c06\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u7126\u70b9\u4ece\u4ee3\u7801\u672c\u8eab\u8f6c\u5411\u884c\u4e3a\u89c4\u8303\u7684\u4fee\u590d\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u4fee\u590d\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.07794", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07794", "abs": "https://arxiv.org/abs/2602.07794", "authors": ["Ningyu Xu", "Qi Zhang", "Xipeng Qiu", "Xuanjing Huang"], "title": "Emergent Structured Representations Support Flexible In-Context Inference in Large Language Models", "comment": "27 pages, 16 figures", "summary": "Large language models (LLMs) exhibit emergent behaviors suggestive of human-like reasoning. While recent work has identified structured, human-like conceptual representations within these models, it remains unclear whether they functionally rely on such representations for reasoning. Here we investigate the internal processing of LLMs during in-context concept inference. Our results reveal a conceptual subspace emerging in middle to late layers, whose representational structure persists across contexts. Using causal mediation analyses, we demonstrate that this subspace is not merely an epiphenomenon but is functionally central to model predictions, establishing its causal role in inference. We further identify a layer-wise progression where attention heads in early-to-middle layers integrate contextual cues to construct and refine the subspace, which is subsequently leveraged by later layers to generate predictions. Together, these findings provide evidence that LLMs dynamically construct and use structured, latent representations in context for inference, offering insights into the computational processes underlying flexible adaptation.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u65f6\u4f1a\u52a8\u6001\u6784\u5efa\u5e76\u5229\u7528\u7ed3\u6784\u5316\u7684\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u8be5\u5b50\u7a7a\u95f4\u5728\u591a\u4e2a\u5c42\u7ea7\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u5f62\u6210\u5e76\u4fc3\u6210\u6a21\u578b\u9884\u6d4b\uff0c\u8868\u660e\u6a21\u578b\u5185\u90e8\u5b58\u5728\u7c7b\u4f3c\u4eba\u7c7b\u7684\u63a8\u7406\u8868\u5f81\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u662f\u5426\u4f9d\u8d56\u7ed3\u6784\u5316\u7684\u3001\u7c7b\u4f3c\u4eba\u7c7b\u7684\u6982\u5ff5\u8868\u793a\u8fdb\u884c\u63a8\u7406\u3002", "method": "\u901a\u8fc7\u5bf9LLMs\u5728\u4e0a\u4e0b\u6587\u4e2d\u8fdb\u884c\u6982\u5ff5\u63a8\u65ad\u65f6\u7684\u5185\u90e8\u5904\u7406\u8fdb\u884c\u89c2\u5bdf\uff0c\u91c7\u7528\u56e0\u679c\u4e2d\u4ecb\u5206\u6790\u548c\u5c42\u7ea7\u6ce8\u610f\u673a\u5236\u5206\u6790\uff0c\u63ed\u793a\u6a21\u578b\u7684\u8868\u73b0\u65b9\u5f0f\u3002", "result": "\u53d1\u73b0\u4e2d\u540e\u5c42\u51fa\u73b0\u4e86\u4fdd\u6301\u8de8\u4e0a\u4e0b\u6587\u4e00\u81f4\u7684\u6982\u5ff5\u5b50\u7a7a\u95f4\uff0c\u8be5\u5b50\u7a7a\u95f4\u5728\u56e0\u679c\u5c42\u9762\u4e0a\u5bf9\u6a21\u578b\u9884\u6d4b\u81f3\u5173\u91cd\u8981\u3002\u65e9\u4e2d\u5c42\u7684\u6ce8\u610f\u529b\u5934\u8d1f\u8d23\u6784\u5efa\u548c\u7ec6\u5316\u8be5\u5b50\u7a7a\u95f4\uff0c\u540e\u5c42\u5229\u7528\u5176\u751f\u6210\u9884\u6d4b\u3002", "conclusion": "LLMs\u52a8\u6001\u6784\u5efa\u5e76\u4f7f\u7528\u7ed3\u6784\u5316\u7684\u6f5c\u5728\u6982\u5ff5\u8868\u793a\u8fdb\u884c\u63a8\u65ad\uff0c\u8868\u660e\u5176\u63a8\u7406\u8fc7\u7a0b\u4f9d\u8d56\u4e8e\u8fd9\u4e9b\u5185\u90e8\u7ed3\u6784\u5316\u8868\u5f81\u3002"}}
{"id": "2602.08316", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08316", "abs": "https://arxiv.org/abs/2602.08316", "authors": ["Jared Zhu", "Minhao Hu", "Junde Wu"], "title": "SWE Context Bench: A Benchmark for Context Learning in Coding", "comment": null, "summary": "Large language models are increasingly used as programming agents for repository level software engineering tasks. While recent benchmarks evaluate correctness in realistic codebases, they largely treat tasks as independent and do not assess whether agents can reuse experience across related problems. As a result, the ability of agents to accumulate, retrieve, and apply prior experience, as well as the efficiency gains from such reuse, remains difficult to measure. We introduce SWE-ContextBench, a benchmark designed to explicitly evaluate experience reuse in programming agents. Built on SWE-Bench Lite, SWE-ContextBench augments 300 base tasks with 99 related tasks derived from real dependency and reference relationships among GitHub issues and pull requests, forming task sequences with shared context. The benchmark evaluates agents along three complementary dimensions: prediction accuracy, time efficiency, and cost efficiency. Using SWE-ContextBench, we study multiple experience reuse settings, including oracle guided and autonomous retrieval, as well as full execution trajectories and compact summaries. Our results show that correctly selected summarized experience improves resolution accuracy and substantially reduces runtime and token cost, particularly on harder tasks. In contrast, unfiltered or incorrectly selected experience provides limited or negative benefits. These findings highlight the importance of experience representation and retrieval quality, and position SWE-ContextBench as a principled benchmark for studying experience reuse in programming agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSWE-ContextBench\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u7f16\u7a0b\u4ee3\u7406\u5728\u5173\u8054\u4efb\u52a1\u4e2d\u7684\u7ecf\u9a8c\u590d\u7528\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u4f18\u8d28\u7ecf\u9a8c\u68c0\u7d22\u4e0e\u8868\u8fbe\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u6027\u7684\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u7f16\u7a0b\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u8bc4\u4ef7\u57fa\u51c6\u591a\u5c06\u4efb\u52a1\u89c6\u4e3a\u72ec\u7acb\uff0c\u7f3a\u4e4f\u5bf9\u7ecf\u9a8c\u590d\u7528\u80fd\u529b\u7684\u6d4b\u8bc4\uff0c\u5bfc\u81f4\u65e0\u6cd5\u51c6\u786e\u8861\u91cf\u4ee3\u7406\u7d2f\u79ef\u3001\u68c0\u7d22\u53ca\u5e94\u7528\u5148\u524d\u7ecf\u9a8c\u7684\u80fd\u529b\u548c\u6548\u7387\u63d0\u5347\u3002", "method": "\u63d0\u51faSWE-ContextBench\u57fa\u51c6\uff0c\u5728SWE-Bench Lite\u57fa\u7840\u4e0a\u589e\u6dfb99\u4e2a\u76f8\u5173\u4efb\u52a1\u5f62\u6210\u5173\u8054\u5e8f\u5217\uff0c\u8bc4\u4f30\u4ee3\u7406\u5728\u9884\u6d4b\u51c6\u786e\u6027\u3001\u65f6\u95f4\u6548\u7387\u4e0e\u6210\u672c\u6548\u7387\u4e09\u65b9\u9762\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u591a\u79cd\u7ecf\u9a8c\u590d\u7528\u8bbe\u7f6e\u5982\u6307\u5bfc\u68c0\u7d22\u548c\u81ea\u4e3b\u68c0\u7d22\uff0c\u53ca\u4e0d\u540c\u7ecf\u9a8c\u8868\u8fbe\u65b9\u5f0f\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6b63\u786e\u7b5b\u9009\u548c\u603b\u7ed3\u7684\u7ecf\u9a8c\u663e\u8457\u63d0\u5347\u89e3\u51b3\u51c6\u786e\u6027\u5e76\u51cf\u5c11\u8fd0\u884c\u65f6\u95f4\u548c\u4ee3\u5e01\u6210\u672c\uff0c\u5c24\u5176\u662f\u590d\u6742\u4efb\u52a1\u4e2d\uff1b\u800c\u672a\u7ecf\u7b5b\u9009\u6216\u9519\u8bef\u7ecf\u9a8c\u5219\u6548\u679c\u6709\u9650\u751a\u81f3\u8d1f\u9762\u3002", "conclusion": "\u9ad8\u8d28\u91cf\u7ecf\u9a8c\u7684\u8868\u8fbe\u4e0e\u68c0\u7d22\u662f\u63d0\u5347\u7f16\u7a0b\u4ee3\u7406\u6548\u80fd\u7684\u5173\u952e\uff0cSWE-ContextBench\u4e3a\u7814\u7a76\u7ecf\u9a8c\u590d\u7528\u63d0\u4f9b\u4e86\u6709\u529b\u7684\u8bc4\u6d4b\u5de5\u5177\u3002"}}
{"id": "2602.07796", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07796", "abs": "https://arxiv.org/abs/2602.07796", "authors": ["Jiatong Li", "Changdae Oh", "Hyeong Kyu Choi", "Jindong Wang", "Sharon Li"], "title": "Thinking Makes LLM Agents Introverted: How Mandatory Thinking Can Backfire in User-Engaged Agents", "comment": "27 pages, 19 figures", "summary": "Eliciting reasoning has emerged as a powerful technique for improving the performance of large language models (LLMs) on complex tasks by inducing thinking. However, their effectiveness in realistic user-engaged agent scenarios remains unclear. In this paper, we conduct a comprehensive study on the effect of explicit thinking in user-engaged LLM agents. Our experiments span across seven models, three benchmarks, and two thinking instantiations, and we evaluate them through both a quantitative response taxonomy analysis and qualitative failure propagation case studies. Contrary to expectations, we find that mandatory thinking often backfires on agents in user-engaged settings, causing anomalous performance degradation across various LLMs. Our key finding reveals that thinking makes agents more ``introverted'' by shortening responses and reducing information disclosure to users, which weakens agent-user information exchange and leads to downstream task failures. Furthermore, we demonstrate that explicitly prompting for information disclosure reliably improves performance across diverse model families, suggesting that proactive transparency is a vital lever for agent optimization. Overall, our study suggests that information transparency awareness is a crucial yet underexplored perspective for the future design of reasoning agents in real-world scenarios. Our code is available at https://github.com/deeplearning-wisc/Thinking-Agent.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u663e\u5f0f\u601d\u8003\u5bf9\u7528\u6237\u53c2\u4e0e\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5f3a\u5236\u601d\u8003\u5f80\u5f80\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u539f\u56e0\u5728\u4e8e\u4fe1\u606f\u62ab\u9732\u51cf\u5c11\u3002\u901a\u8fc7\u4fc3\u8fdb\u4fe1\u606f\u900f\u660e\uff0c\u6027\u80fd\u5f97\u5230\u63d0\u5347\u3002", "motivation": "\u8c03\u67e5\u663e\u5f0f\u601d\u8003\u6280\u672f\u5728\u73b0\u5b9e\u7528\u6237\u53c2\u4e0e\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\uff0c\u89e3\u51b3\u5176\u5bf9\u590d\u6742\u4efb\u52a1\u6027\u80fd\u63d0\u5347\u4f5c\u7528\u662f\u5426\u6210\u7acb\u7684\u7591\u95ee\u3002", "method": "\u901a\u8fc7\u4e03\u4e2a\u6a21\u578b\u3001\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e24\u79cd\u601d\u8003\u5b9e\u4f8b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u5408\u5b9a\u91cf\u7684\u54cd\u5e94\u5206\u7c7b\u5206\u6790\u548c\u5b9a\u6027\u7684\u5931\u8d25\u4f20\u64ad\u6848\u4f8b\u7814\u7a76\uff0c\u5bf9\u663e\u5f0f\u601d\u8003\u5728\u7528\u6237\u53c2\u4e0e\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u7684\u5f71\u54cd\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5b9e\u9a8c\u7814\u7a76\u3002", "result": "\u53d1\u73b0\u5f3a\u5236\u601d\u8003\u4f7f\u5f97\u4ee3\u7406\u56de\u590d\u66f4\u77ed\uff0c\u4fe1\u606f\u62ab\u9732\u51cf\u5c11\uff0c\u53cd\u800c\u5bfc\u81f4\u6027\u80fd\u9000\u5316\uff0c\u540c\u65f6\u63d0\u51fa\u4e3b\u52a8\u4fc3\u8fdb\u4fe1\u606f\u62ab\u9732\u7684\u63d0\u793a\u80fd\u663e\u8457\u63d0\u5347\u591a\u79cd\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u5f3a\u5236\u6027\u601d\u8003\u5728\u7528\u6237\u53c2\u4e0e\u7684\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u4e2d\u5e38\u5e38\u9002\u5f97\u5176\u53cd\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u601d\u8003\u4f7f\u4ee3\u7406\u53d8\u5f97\u201c\u5185\u5411\u201d\uff0c\u51cf\u5c11\u4e86\u4fe1\u606f\u62ab\u9732\uff0c\u5f71\u54cd\u4e86\u4ee3\u7406\u4e0e\u7528\u6237\u4e4b\u95f4\u7684\u4fe1\u606f\u4ea4\u6d41\uff0c\u8fdb\u800c\u5bfc\u81f4\u4efb\u52a1\u5931\u8d25\u3002"}}
{"id": "2602.08561", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08561", "abs": "https://arxiv.org/abs/2602.08561", "authors": ["Syed Mehtab Hussain Shah", "Frank Hopfgartner", "Arnim Bleier"], "title": "Automating Computational Reproducibility in Social Science: Comparing Prompt-Based and Agent-Based Approaches", "comment": "12 pages, 5 figures. Submitted to ACM conference", "summary": "Reproducing computational research is often assumed to be as simple as rerunning the original code with provided data. In practice, missing packages, fragile file paths, version conflicts, or incomplete logic frequently cause analyses to fail, even when materials are shared. This study investigates whether large language models and AI agents can automate the diagnosis and repair of such failures, making computational results easier to reproduce and verify. We evaluate this using a controlled reproducibility testbed built from five fully reproducible R-based social science studies. Realistic failures were injected, ranging from simple issues to complex missing logic, and two automated repair workflows were tested in clean Docker environments. The first workflow is prompt-based, repeatedly querying language models with structured prompts of varying context, while the second uses agent-based systems that inspect files, modify code, and rerun analyses autonomously. Across prompt-based runs, reproduction success ranged from 31-79 percent, with performance strongly influenced by prompt context and error complexity. Complex cases benefited most from additional context. Agent-based workflows performed substantially better, with success rates of 69-96 percent across all complexity levels. These results suggest that automated workflows, especially agent-based systems, can significantly reduce manual effort and improve reproduction success across diverse error types. Unlike prior benchmarks, our testbed isolates post-publication repair under controlled failure modes, allowing direct comparison of prompt-based and agent-based approaches.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u53d7\u63a7\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u81ea\u52a8\u4fee\u590d\u8ba1\u7b97\u7814\u7a76\u5931\u8d25\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u80fd\u5927\u5e45\u63d0\u5347\u590d\u73b0\u6210\u529f\u7387\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u9700\u6c42\u3002", "motivation": "\u5c3d\u7ba1\u5171\u4eab\u539f\u59cb\u4ee3\u7801\u548c\u6570\u636e\uff0c\u4f46\u8ba1\u7b97\u7814\u7a76\u590d\u73b0\u7ecf\u5e38\u56e0\u7f3a\u5931\u8f6f\u4ef6\u5305\u3001\u8106\u5f31\u6587\u4ef6\u8def\u5f84\u3001\u7248\u672c\u51b2\u7a81\u6216\u4e0d\u5b8c\u6574\u903b\u8f91\u800c\u5931\u8d25\uff0c\u7814\u7a76\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548cAI\u4ee3\u7406\u80fd\u5426\u81ea\u52a8\u8bca\u65ad\u548c\u4fee\u590d\u8fd9\u4e9b\u5931\u8d25\uff0c\u63d0\u9ad8\u8ba1\u7b97\u7ed3\u679c\u7684\u6613\u590d\u73b0\u6027\u548c\u9a8c\u8bc1\u6027\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u4e94\u4e2a\u5b8c\u5168\u53ef\u590d\u73b0\u7684\u57fa\u4e8eR\u7684\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u7684\u53d7\u63a7\u590d\u73b0\u6d4b\u8bd5\u5e73\u53f0\uff0c\u6ce8\u5165\u5404\u79cd\u771f\u5b9e\u5931\u8d25\uff08\u4ece\u7b80\u5355\u95ee\u9898\u5230\u590d\u6742\u7f3a\u5931\u903b\u8f91\uff09\uff0c\u6d4b\u8bd5\u4e86\u4e24\u79cd\u81ea\u52a8\u4fee\u590d\u5de5\u4f5c\u6d41\uff1a\u57fa\u4e8e\u63d0\u793a\u7684\u591a\u8f6e\u67e5\u8be2\u548c\u57fa\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u81ea\u4e3b\u6587\u4ef6\u68c0\u67e5\u3001\u4ee3\u7801\u4fee\u6539\u53ca\u91cd\u8fd0\u884c\u3002", "result": "\u57fa\u4e8e\u63d0\u793a\u7684\u4fee\u590d\u6210\u529f\u7387\u4ecb\u4e8e31%-79%\uff0c\u53d7\u63d0\u793a\u4e0a\u4e0b\u6587\u548c\u9519\u8bef\u590d\u6742\u5ea6\u5f71\u54cd\u663e\u8457\uff0c\u590d\u6742\u9519\u8bef\u901a\u8fc7\u66f4\u591a\u4e0a\u4e0b\u6587\u6539\u5584\u6548\u679c\u660e\u663e\u3002\u667a\u80fd\u4ee3\u7406\u5de5\u4f5c\u6d41\u8868\u73b0\u66f4\u4f18\uff0c\u6210\u529f\u7387\u8fbe\u523069%-96%\u3002", "conclusion": "\u81ea\u52a8\u5316\u7684\u4fee\u590d\u5de5\u4f5c\u6d41\uff0c\u5c24\u5176\u662f\u57fa\u4e8e\u667a\u80fd\u4ee3\u7406\u7684\u7cfb\u7edf\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u5de5\u4f5c\u91cf\uff0c\u63d0\u9ad8\u4e0d\u540c\u590d\u6742\u9519\u8bef\u7c7b\u578b\u7684\u590d\u73b0\u6210\u529f\u7387\u3002"}}
{"id": "2602.07804", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07804", "abs": "https://arxiv.org/abs/2602.07804", "authors": ["Xuan Ding", "Pengyu Tong", "Ranjie Duan", "Yunjian Zhang", "Rui Sun", "Yao Zhu"], "title": "Pruning as a Cooperative Game: Surrogate-Assisted Layer Contribution Estimation for Large Language Models", "comment": "Accepted by ICLR 2026", "summary": "While large language models (LLMs) demonstrate impressive performance across various tasks, their deployment in real-world scenarios is still constrained by high computational demands. Layer-wise pruning, a commonly employed strategy to mitigate inference costs, can partially address this challenge. However, existing approaches generally depend on static heuristic rules and fail to account for the interdependencies among layers, thereby limiting the effectiveness of the pruning process. To this end, this paper proposes a game-theoretic framework that formulates layer pruning as a cooperative game in which each layer acts as a player and model performance serves as the utility. As computing exact Shapley values is computationally infeasible for large language models (LLMs), we propose using a lightweight surrogate network to estimate layer-wise marginal contributions. This network can predict LLM performance for arbitrary layer combinations at a low computational cost. Additionally, we employ stratified Monte Carlo mask sampling to further reduce the cost of Sharpley value estimation. This approach captures inter-layer dependencies and dynamically identifies critical layers for pruning. Extensive experiments demonstrate the consistent superiority of our method in terms of perplexity and zero-shot accuracy, achieving more efficient and effective layer-wise pruning for large language models.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5c42\u526a\u679d\u96be\u70b9\uff0c\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u535a\u5f08\u8bba\u548cShapley\u503c\u7684\u65b0\u65b9\u6cd5\uff0c\u52a8\u6001\u6355\u83b7\u5c42\u95f4\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u526a\u679d\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5c42\u7ea7\u526a\u679d\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u5ffd\u89c6\u5c42\u95f4\u4f9d\u8d56\u9650\u5236\u4e86\u526a\u679d\u6548\u679c\uff0c\u9700\u8bbe\u8ba1\u52a8\u6001\u4e14\u8003\u8651\u4f9d\u8d56\u6027\u7684\u526a\u679d\u673a\u5236\u3002", "method": "\u5c06\u5c42\u526a\u679d\u89c6\u4e3a\u534f\u4f5c\u535a\u5f08\uff0c\u6bcf\u5c42\u4f5c\u4e3a\u73a9\u5bb6\uff0c\u4f7f\u7528\u8f7b\u91cf\u7ea7\u4ee3\u7406\u7f51\u7edc\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u540c\u5c42\u7ec4\u5408\u7684\u6027\u80fd\uff0c\u7ed3\u5408\u5206\u5c42\u8499\u7279\u5361\u6d1b\u91c7\u6837\u4f30\u8ba1Shapley\u503c\u3002", "result": "\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u5728\u56f0\u60d1\u5ea6\u548c\u96f6\u6837\u672c\u51c6\u786e\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u3001\u66f4\u6709\u6548\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5c42\u7ea7\u526a\u679d\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u5c42\u7ea7\u526a\u679d\u6846\u67b6\u80fd\u591f\u52a8\u6001\u8bc6\u522b\u5173\u952e\u5c42\uff0c\u8003\u8651\u5c42\u95f4\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u526a\u679d\u7684\u6548\u679c\u548c\u6548\u7387\u3002"}}
{"id": "2602.08765", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08765", "abs": "https://arxiv.org/abs/2602.08765", "authors": ["Micah Villmow"], "title": "Taming Scylla: Understanding the multi-headed agentic daemon of the coding seas", "comment": "32 Pages, 7 Figures", "summary": "LLM-based tools are automating more software development tasks at a rapid pace, but there is no rigorous way to evaluate how different architectural choices -- prompts, skills, tools, multi-agent setups -- materially affect both capability and cost. This paper introduces Scylla, an evaluation framework for benchmarking agentic coding tools through structured ablation studies that uses seven testing tiers (T0-T6) progressively adding complexity to isolate what directly influences results and how. The key metric is Cost-of-Pass (CoP): the expected dollar cost to get one correct solution, which directly quantifies the trade-off between complexity and efficiency. The framework is model-agnostic, designed to work with any CLI tool; this paper demonstrates it with Claude Sonnet 4.5, using multiple LLM judges (Opus 4.5, Sonnet 4.5, Haiku 4.5) from the same vendor for evaluation consensus, where judges score results using direct tests, human-designed LLM-evaluated rubrics, and qualitative assessment. The result is a reproducible framework that quantifies trade-offs between agent complexity and actual outcomes, suggesting that architectural complexity does not always improve quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faScylla\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u6d4b\u8bd5\u548c\u6210\u672c\u6307\u6807\uff0c\u7cfb\u7edf\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u7f16\u7a0b\u4ee3\u7406\u590d\u6742\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u66f4\u590d\u6742\u67b6\u6784\u4e0d\u4e00\u5b9a\u66f4\u4f18\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u5de5\u5177\u5feb\u901f\u81ea\u52a8\u5316\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u4e25\u8c28\u65b9\u6cd5\u8bc4\u4f30\u4e0d\u540c\u67b6\u6784\u8bbe\u8ba1\uff08\u5982\u63d0\u793a\u3001\u6280\u80fd\u3001\u5de5\u5177\u3001\u591a\u4ee3\u7406\u8bbe\u7f6e\uff09\u5bf9\u80fd\u529b\u548c\u6210\u672c\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faScylla\u8bc4\u4f30\u6846\u67b6\uff0c\u901a\u8fc7\u4e03\u4e2a\u9012\u8fdb\u590d\u6742\u5ea6\u7684\u6d4b\u8bd5\u5c42\u7ea7\uff08T0-T6\uff09\u8fdb\u884c\u7ed3\u6784\u5316\u6d88\u878d\u7814\u7a76\uff0c\u91c7\u7528Cost-of-Pass(CoP)\u6307\u6807\u91cf\u5316\u590d\u6742\u5ea6\u4e0e\u6548\u7387\u7684\u6743\u8861\uff1b\u6846\u67b6\u6a21\u578b\u65e0\u5173\uff0c\u53ef\u9002\u7528\u4e8e\u4efb\u4f55\u547d\u4ee4\u884c\u5de5\u5177\uff1b\u7528Claude Sonnet 4.5\u53ca\u591a\u4e2aLLM\u8bc4\u5ba1\u6a21\u578b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u642d\u5efa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u91cf\u5316\u4ee3\u7406\u590d\u6742\u5ea6\u4e0e\u5b9e\u9645\u6548\u679c\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u53d1\u73b0\u67b6\u6784\u590d\u6742\u5ea6\u4e0d\u4e00\u5b9a\u63d0\u5347\u8d28\u91cf\u3002", "conclusion": "Scylla\u6846\u67b6\u4e3a\u8bc4\u4f30\u57fa\u4e8eLLM\u7684\u7f16\u7801\u4ee3\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e25\u8c28\u7684\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u63d0\u5347\u67b6\u6784\u590d\u6742\u6027\u5e76\u975e\u603b\u80fd\u5e26\u6765\u66f4\u597d\u6027\u80fd\u7684\u4e8b\u5b9e\u3002"}}
{"id": "2602.07812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07812", "abs": "https://arxiv.org/abs/2602.07812", "authors": ["Fengting Yuchi", "Li Du", "Jason Eisner"], "title": "LLMs Know More About Numbers than They Can Say", "comment": "EACL 2026", "summary": "Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: \"Which is larger, $5.7 \\times 10^2$ or $580$?\" This raises a fundamental question: Do LLMs even know how big these numbers are? We probe the hidden states of several smaller open-source LLMs. A single linear projection of an appropriate hidden layer encodes the log-magnitudes of both kinds of numerals, allowing us to recover the numbers with relative error of about 2.3% (on restricted synthetic text) or 19.06% (on scientific papers). Furthermore, the hidden state after reading a pair of numerals encodes their ranking, with a linear classifier achieving over 90% accuracy. Yet surprisingly, when explicitly asked to rank the same pairs of numerals, these LLMs achieve only 50-70% accuracy, with worse performance for models whose probes are less effective. Finally, we show that incorporating the classifier probe's log-loss as an auxiliary objective during finetuning brings an additional 3.22% improvement in verbalized accuracy over base models, demonstrating that improving models' internal magnitude representations can enhance their numerical reasoning capabilities.", "AI": {"tldr": "\u5f53\u524dLLMs\u5bf9\u6df7\u5408\u7b26\u53f7\u6570\u503c\u5927\u5c0f\u7684\u7406\u89e3\u6709\u9650\uff0c\u4f46\u5176\u9690\u85cf\u72b6\u6001\u4e2d\u6f5c\u85cf\u6570\u503c\u4fe1\u606f\uff0c\u901a\u8fc7\u7ebf\u6027\u63a2\u6d4b\u548c\u5fae\u8c03\u53ef\u4ee5\u663e\u8457\u589e\u5f3a\u6a21\u578b\u6570\u503c\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u53d1\u73b0\u5f53\u524d\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u6df7\u5408\u7b26\u53f7\u7684\u6570\u503c\u6bd4\u8f83\u65f6\u8868\u73b0\u51fa\u9519\u8bef\uff0c\u8d28\u7591\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u6570\u5b57\u5927\u5c0f\u3002", "method": "\u901a\u8fc7\u63a2\u67e5\u591a\u4e2a\u5c0f\u578b\u5f00\u6e90LLM\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5229\u7528\u7ebf\u6027\u6295\u5f71\u4ece\u9690\u85cf\u5c42\u7f16\u7801\u6570\u503c\u7684\u5bf9\u6570\u5927\u5c0f\uff0c\u5e76\u7528\u7ebf\u6027\u5206\u7c7b\u5668\u8fdb\u884c\u6570\u503c\u6392\u540d\u3002", "result": "\u6210\u529f\u6062\u590d\u6570\u503c\u5927\u5c0f\uff0c\u5bf9\u5408\u6210\u6587\u672c\u548c\u79d1\u5b66\u8bba\u6587\u7684\u76f8\u5bf9\u8bef\u5dee\u5206\u522b\u4e3a2.3%\u548c19.06%\uff1b\u6392\u540d\u51c6\u786e\u7387\u8d85\u8fc790%\uff1b\u5c06\u5206\u7c7b\u5668\u7684\u5bf9\u6570\u635f\u5931\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\u8fdb\u884c\u5fae\u8c03\uff0c\u63d0\u5347\u6a21\u578b3.22%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "LLM\u9690\u85cf\u72b6\u6001\u4e2d\u9690\u542b\u4e86\u6570\u503c\u5927\u5c0f\u7684\u4fe1\u606f\uff0c\u901a\u8fc7\u9002\u5f53\u7684\u7ebf\u6027\u63a2\u6d4b\u53ef\u4ee5\u63d0\u53d6\u4e14\u6539\u8fdb\u8fd9\u79cd\u8868\u793a\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u6570\u503c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.08866", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08866", "abs": "https://arxiv.org/abs/2602.08866", "authors": ["Bang Xie", "Senjian Zhang", "Zhiyuan Peng", "Wei Chen", "Chenhao Ying", "Yuan Luo"], "title": "ArkEval: Benchmarking and Evaluating Automated CodeRepair for ArkTS", "comment": null, "summary": "Large language models have transformed code generation, enabling unprecedented automation in software development. As mobile ecosystems evolve, HarmonyOS has emerged as a critical platform requiring robust development tools. Software development for the HarmonyOS ecosystem relies heavily on ArkTS, a statically typed extension of TypeScript. Despite its growing importance, the ecosystem lacks robust tools for automated code repair, primarily due to the absence of a high-quality benchmark for evaluation. To address this gap, we present ArkEval, a unified framework for ArkTS automated repair workflow evaluation and benchmark construction. It provides the first comprehensive benchmark specifically designed for ArkTS automated program repair. We constructed this benchmark by mining issues from a large-scale official Huawei repository containing over 400 independent ArkTS applications. Through a rigorous multi-stage filtering process, we curated 502 reproducible issues. To ensure testability, we employed a novel LLM-based test generation and voting mechanism involving Claude and other models. Furthermore, we standardized problem statements to facilitate fair evaluation. Finally, we evaluated four state-of-the-art Large Language Models (LLMs) on our benchmark using a retrieval-augmented repair workflow. Our results highlight the current capabilities and limitations of LLMs in repairing ArkTS code, paving the way for future research in this low-resource language domain.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9HarmonyOS\u7684ArkTS\u8bed\u8a00\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u81ea\u52a8\u4fee\u590d\u8bc4\u6d4b\u57fa\u51c6ArkEval\uff0c\u5e76\u5229\u7528\u591a\u9636\u6bb5\u8fc7\u6ee4\u3001LLM\u6d4b\u8bd5\u751f\u6210\u53ca\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u8bc4\u4f30\u4e86\u56db\u6b3e\u5927\u8bed\u8a00\u6a21\u578b\u5728ArkTS\u4ee3\u7801\u81ea\u52a8\u4fee\u590d\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u76ee\u524d\u6a21\u578b\u7684\u4f18\u52bf\u548c\u4e0d\u8db3\u3002", "motivation": "HarmonyOS\u751f\u6001\u4e2dArkTS\u4f5c\u4e3a\u5173\u952e\u8bed\u8a00\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u4ee3\u7801\u4fee\u590d\u5de5\u5177\u548c\u9ad8\u8d28\u91cf\u8bc4\u6d4b\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u4fee\u590d\u6280\u672f\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u4ece\u534e\u4e3a\u5b98\u65b9\u4ed3\u5e93\u6316\u6398\u8d85\u8fc7400\u4e2aArkTS\u5e94\u7528\u7684502\u4e2a\u53ef\u590d\u73b0\u95ee\u9898\u6784\u5efa\u57fa\u51c6\uff0c\u91c7\u7528\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982Claude\uff09\u7684\u6d4b\u8bd5\u751f\u6210\u4e0e\u6295\u7968\u673a\u5236\uff0c\u63d0\u9ad8\u6d4b\u8bd5\u6548\u529b\uff0c\u5e76\u6807\u51c6\u5316\u95ee\u9898\u8868\u8ff0\uff0c\u6700\u540e\u7528\u56db\u4e2a\u5148\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u4fee\u590d\u6d41\u7a0b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u6784\u5efa\u4e86\u9996\u4e2a\u9488\u5bf9ArkTS\u81ea\u52a8\u4fee\u590d\u7684\u7efc\u5408\u57fa\u51c6ArkEval\uff0c\u6210\u529f\u5b9e\u73b0\u81ea\u52a8\u5316\u6d4b\u8bd5\u751f\u6210\u548c\u6807\u51c6\u5316\u95ee\u9898\u63cf\u8ff0\uff0c\u5e76\u901a\u8fc7\u57fa\u51c6\u8bc4\u6d4b\u5448\u73b0\u4e86\u56db\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86ArkEval\u6846\u67b6\u53ca\u57fa\u51c6\uff0c\u586b\u8865\u4e86ArkTS\u81ea\u52a8\u4fee\u590d\u9886\u57df\u7684\u8bc4\u6d4b\u7a7a\u767d\uff0c\u901a\u8fc7\u6d4b\u8bd5\u94fe\u6807\u51c6\u5316\u548cLLM\u8f85\u52a9\u4fee\u590d\uff0c\u5c55\u793a\u4e86\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728ArkTS\u4ee3\u7801\u4fee\u590d\u4e0a\u7684\u80fd\u529b\u53ca\u4e0d\u8db3\u3002"}}
{"id": "2602.07839", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07839", "abs": "https://arxiv.org/abs/2602.07839", "authors": ["Jiaxi Liu", "Yanzuo Jiang", "Guibin Zhang", "Zihan Zhang", "Heng Chang", "Zhenfei Yin", "Qibing Ren", "Junchi Yan"], "title": "TodoEvolve: Learning to Architect Agent Planning Systems", "comment": null, "summary": "Planning has become a central capability for contemporary agent systems in navigating complex, long-horizon tasks, yet existing approaches predominantly rely on fixed, hand-crafted planning structures that lack the flexibility to adapt to the structural diversity of open-ended problems. To address this limitation, we introduce TodoEvolve, a meta-planning paradigm that autonomously synthesizes and dynamically revises task-specific planning architectures. Specifically, we first construct PlanFactory, a modular design space that standardizes diverse planning paradigms within a unified codebase encompassing topology, initialization, adaptation, and navigation, thereby providing a common interface for heterogeneous planning patterns. Leveraging PlanFactory, we collect high-quality planning trajectories and train Todo-14B via \\textit{Impedance-Guided Preference Optimization} (IGPO), a multi-objective reinforcement learning objective that encourages the generation of planning systems that are performant, stable, and token-efficient across arbitrary tasks and agent backbones. Empirical evaluations on five agentic benchmarks demonstrate that TodoEvolve consistently surpasses carefully engineered planning modules while maintaining economical API costs and runtime overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTodoEvolve\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u7075\u6d3b\u81ea\u9002\u5e94\u7684\u81ea\u52a8\u89c4\u5212\u67b6\u6784\u751f\u6210\uff0c\u4f7f\u667a\u80fd\u4f53\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u4e14\u8d44\u6e90\u6d88\u8017\u4f4e\u3002", "motivation": "\u73b0\u6709\u89c4\u5212\u65b9\u6cd5\u4f9d\u8d56\u56fa\u5b9a\u548c\u624b\u5de5\u8bbe\u8ba1\u7684\u89c4\u5212\u7ed3\u6784\uff0c\u7f3a\u4e4f\u5e94\u5bf9\u591a\u6837\u5316\u590d\u6742\u4efb\u52a1\u7684\u7075\u6d3b\u6027\u3002", "method": "\u63d0\u51faTodoEvolve\u5143\u89c4\u5212\u8303\u5f0f\uff0c\u5229\u7528PlanFactory\u6784\u5efa\u7edf\u4e00\u6a21\u5757\u5316\u7684\u89c4\u5212\u8bbe\u8ba1\u7a7a\u95f4\uff0c\u5e76\u901a\u8fc7\u963b\u6297\u5f15\u5bfc\u504f\u597d\u4f18\u5316\u7684\u591a\u76ee\u6807\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3Todo-14B\uff0c\u52a8\u6001\u5408\u6210\u548c\u8c03\u6574\u4efb\u52a1\u7279\u5b9a\u89c4\u5212\u67b6\u6784\u3002", "result": "\u5728\u4e94\u4e2a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTodoEvolve\u8d85\u8d8a\u4e86\u4f20\u7edf\u624b\u5de5\u8bbe\u8ba1\u7684\u89c4\u5212\u6a21\u5757\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684API\u8c03\u7528\u6210\u672c\u548c\u8fd0\u884c\u65f6\u5f00\u9500\u3002", "conclusion": "TodoEvolve\u6709\u6548\u63d0\u5347\u4e86\u89c4\u5212\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u5e94\u5bf9\u590d\u6742\u591a\u6837\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u4e14\u9ad8\u6548\u7684\u81ea\u52a8\u5316\u89c4\u5212\u67b6\u6784\u751f\u6210\u65b9\u6848\u3002"}}
{"id": "2602.08887", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08887", "abs": "https://arxiv.org/abs/2602.08887", "authors": ["Adam Trendowicz", "Daniel Seifert", "Andreas Jedlitschka", "Marcus Ciolkowski", "Anton Strahilov"], "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories", "comment": null, "summary": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8eGPT-4o\u7684DeepQuali\u65b9\u6cd5\uff0c\u7528\u4e8e\u654f\u6377\u5f00\u53d1\u4e2d\u7684\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\u3002\u5b9e\u9a8c\u663e\u793aLLM\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u8bc4\u4ef7\u9ad8\u5ea6\u4e00\u81f4\uff0c\u4e14\u5177\u5907\u89e3\u91ca\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u65b9\u6cd5\u63a5\u53d7\u5ea6\uff0c\u4f46\u9700\u6539\u8fdb\u4e0e\u5de5\u4f5c\u6d41\u7684\u6574\u5408\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u591a\u96c6\u4e2d\u4e8e\u7f16\u7801\uff0c\u9700\u6c42\u5de5\u7a0b\u7279\u522b\u662f\u9700\u6c42\u9a8c\u8bc1\u65b9\u9762\u7684\u5e94\u7528\u6709\u9650\uff0c\u4e14\u8d28\u91cf\u8bc4\u4f30\u7f3a\u4e4f\u6709\u6548\u65b9\u6cd5\uff0c\u6545\u63d0\u51fa\u57fa\u4e8eLLM\u7684\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u5e76\u8bc4\u4f30\u4e86\u57fa\u4e8eLLM\u7684DeepQuali\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u4e24\u4e2a\u5c0f\u578b\u516c\u53f8\u7684\u9879\u76ee\u8fdb\u884c\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\uff0c\u6bd4\u8f83LLM\u4e0e\u4e13\u5bb6\u7684\u5224\u65ad\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u53c2\u4e0e\u7684\u8bc4\u5ba1\u548c\u53cd\u9988\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "LLM\u7684\u8d28\u91cf\u8bc4\u4f30\u4e0e\u4e13\u5bb6\u6574\u4f53\u8bc4\u5206\u9ad8\u5ea6\u4e00\u81f4\uff0c\u5e76\u80fd\u63d0\u4f9b\u89e3\u91ca\u6027\u53cd\u9988\uff0c\u63d0\u5347\u4e86\u4e13\u5bb6\u5bf9\u8be5\u65b9\u6cd5\u7684\u8ba4\u53ef\uff0c\u4f46\u4e13\u5bb6\u5bf9\u8be6\u7ec6\u8bc4\u5206\u5b58\u5728\u5206\u6b67\uff0c\u53cd\u6620\u4e86\u4e2a\u4f53\u7ecf\u9a8c\u7684\u5f71\u54cd\uff0c\u540c\u65f6\u4e13\u5bb6\u6307\u51fa\u8be5\u65b9\u6cd5\u5c1a\u672a\u5f88\u597d\u96c6\u6210\u5230\u65e5\u5e38\u5de5\u4f5c\u6d41\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08GPT-4o\uff09\u7684DeepQuali\u65b9\u6cd5\u5728\u654f\u6377\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7528\u4e8e\u9700\u6c42\u8d28\u91cf\u8bc4\u4f30\u5177\u6709\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u4e13\u5bb6\u63a5\u53d7\u5ea6\uff0c\u4f46\u4e13\u5bb6\u5bf9\u7ec6\u8282\u8bc4\u5206\u5b58\u5728\u5206\u6b67\uff0c\u8868\u660e\u7ecf\u9a8c\u5f71\u54cd\u5224\u65ad\uff0c\u4e14\u65b9\u6cd5\u9700\u66f4\u597d\u5730\u4e0e\u5b9e\u9645\u5de5\u4f5c\u6d41\u7a0b\u6574\u5408\u3002"}}
{"id": "2602.07842", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07842", "abs": "https://arxiv.org/abs/2602.07842", "authors": ["Yuhan Wang", "Shiyu Ni", "Zhikai Ding", "Zihang Zhan", "Yuanzi Li", "Keping Bi"], "title": "Evaluating and Calibrating LLM Confidence on Questions with Multiple Correct Answers", "comment": null, "summary": "Confidence calibration is essential for making large language models (LLMs) reliable, yet existing training-free methods have been primarily studied under single-answer question answering. In this paper, we show that these methods break down in the presence of multiple valid answers, where disagreement among equally correct responses leads to systematic underestimation of confidence. To enable a systematic study of this phenomenon, we introduce MACE, a benchmark of 12,000 factual questions spanning six domains with varying numbers of correct answers. Experiments across 15 representative calibration methods and four LLM families (7B-72B) reveal that while accuracy increases with answer cardinality, estimated confidence consistently decreases, causing severe miscalibration for questions with mixed answer counts. To address this issue, we propose Semantic Confidence Aggregation (SCA), which aggregates confidence over multiple high-probability sampled responses. SCA achieves state-of-the-art calibration performance under mixed-answer settings while preserving strong calibration on single-answer questions.", "AI": {"tldr": "\u73b0\u6709\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u6cd5\u5728\u591a\u7b54\u6848\u95ee\u9898\u4e2d\u8868\u73b0\u8f83\u5dee\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u591a\u4e2a\u9ad8\u6982\u7387\u7b54\u6848\u805a\u5408\u7684SCA\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u6cd5\u4e3b\u8981\u5728\u5355\u4e00\u7b54\u6848\u95ee\u9898\u4e0a\u9a8c\u8bc1\uff0c\u9762\u5bf9\u591a\u6b63\u786e\u7b54\u6848\u65f6\u5bb9\u6613\u4f4e\u4f30\u7f6e\u4fe1\u5ea6\uff0c\u9020\u6210\u53ef\u9760\u6027\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u4e86\u5305\u542b1.2\u4e07\u4e8b\u5b9e\u6027\u95ee\u9898\u7684MACE\u57fa\u51c6\uff0c\u8bc4\u4f3015\u79cd\u6821\u51c6\u65b9\u6cd5\u548c4\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u65cf\u7684\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u8bed\u4e49\u7f6e\u4fe1\u5ea6\u805a\u5408\uff08SCA\uff09\u65b9\u6cd5\u4ee5\u805a\u5408\u591a\u4e2a\u9ad8\u6982\u7387\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u968f\u7740\u6b63\u786e\u7b54\u6848\u6570\u91cf\u7684\u589e\u52a0\uff0c\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4f46\u4f30\u8ba1\u7684\u7f6e\u4fe1\u5ea6\u6301\u7eed\u4e0b\u964d\uff0c\u9020\u6210\u4e25\u91cd\u7684\u6821\u51c6\u5931\u8861\uff1bSCA\u65b9\u6cd5\u5728\u591a\u7b54\u573a\u666f\u4e0b\u8fbe\u5230\u4e86\u6700\u4f18\u7684\u6821\u51c6\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5355\u7b54\u573a\u666f\u7684\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u73b0\u6709\u7684\u8bad\u7ec3\u65e0\u5173\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u6cd5\u5728\u591a\u7b54\u6848\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u5bfc\u81f4\u7f6e\u4fe1\u5ea6\u7cfb\u7edf\u6027\u4f4e\u4f30\uff1b\u63d0\u51fa\u7684SCA\u65b9\u6cd5\u901a\u8fc7\u5bf9\u591a\u9ad8\u6982\u7387\u7b54\u6848\u8fdb\u884c\u7f6e\u4fe1\u5ea6\u805a\u5408\uff0c\u663e\u8457\u6539\u5584\u4e86\u6821\u51c6\u6548\u679c\u3002"}}
{"id": "2602.08915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.08915", "abs": "https://arxiv.org/abs/2602.08915", "authors": ["Giovanni Pinna", "Jingzhi Gong", "David Williams", "Federica Sarro"], "title": "Comparing AI Coding Agents: A Task-Stratified Analysis of Pull Request Acceptance", "comment": "Accepted by MSR'26 Mining Challenge Track", "summary": "The rapid adoption of AI-powered coding assistants is transforming software development practices, yet systematic comparisons of their effectiveness across different task types and over time remain limited. This paper presents an empirical study comparing five popular agents (OpenAI Codex, GitHub Copilot, Devin, Cursor, and Claude Code), analyzing 7,156 pull requests (PRs) from the AIDev dataset. Temporal trend analysis reveals heterogeneous evolution patterns: Devin exhibits the only consistent positive trend in acceptance rate (+0.77% per week over 32 weeks), whereas other agents remain largely stable. Our analysis suggests that the PR task type is a dominant factor influencing acceptance rates: documentation tasks achieve 82.1% acceptance compared to 66.1% for new features - a 16 percentage point gap that exceeds typical inter-agent variance for most tasks. OpenAI Codex achieves consistently high acceptance rates across all nine task categories (59.6%-88.6%), with stratified Chi-square tests confirming statistically significant advantages over other agents in several task categories. However, no single agent performs best across all task types: Claude Code leads in documentation (92.3%) and features (72.6%), while Cursor excels in fix tasks (80.4%).", "AI": {"tldr": "\u672c\u7814\u7a76\u6bd4\u8f83\u4e86\u4e94\u6b3eAI\u7f16\u7801\u52a9\u624b\u5728\u4e0d\u540c\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4efb\u52a1\u7c7b\u578b\u662f\u5f71\u54cd\u63a5\u53d7\u7387\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5404\u52a9\u624b\u5728\u4e0d\u540c\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u4f18\u52bf\uff0cOpenAI Codex\u6574\u4f53\u8868\u73b0\u8f83\u4f18\uff0c\u4f46\u65e0\u5355\u4e00\u52a9\u624b\u9002\u7528\u4e8e\u6240\u6709\u4efb\u52a1\u3002", "motivation": "\u5c3d\u7ba1AI\u7f16\u7801\u52a9\u624b\u88ab\u5feb\u901f\u91c7\u7528\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u6bd4\u8f83\u7814\u7a76\uff0c\u7279\u522b\u662f\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u548c\u65f6\u95f4\u7ef4\u5ea6\u4e0a\u7684\u6548\u679c\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5206\u6790AIDev\u6570\u636e\u96c6\u4e2d7,156\u4e2a\u62c9\u53d6\u8bf7\u6c42\uff0c\u6bd4\u8f83\u4e94\u79cd\u6d41\u884c\u7684AI\u7f16\u7801\u52a9\u624b\uff08OpenAI Codex\u3001GitHub Copilot\u3001Devin\u3001Cursor\u548cClaude Code\uff09\u7684\u63a5\u53d7\u7387\uff0c\u5e76\u8fdb\u884c\u65f6\u95f4\u8d8b\u52bf\u5206\u6790\u548c\u5206\u5c42\u5361\u65b9\u68c0\u9a8c\u3002", "result": "Devin\u5728\u63a5\u53d7\u7387\u4e0a\u6709\u552f\u4e00\u6301\u7eed\u6b63\u5411\u8d8b\u52bf\uff0c\u6587\u6863\u4efb\u52a1\u7684\u63a5\u53d7\u7387\u9ad8\u8fbe82.1%\uff0c\u65b0\u529f\u80fd\u4efb\u52a1\u4ec5\u4e3a66.1%\uff0c\u4e14OpenAI Codex\u5728\u6240\u6709\u4efb\u52a1\u7c7b\u522b\u4e2d\u63a5\u53d7\u7387\u5747\u8f83\u9ad8\u3002\u4e0d\u540c\u52a9\u624b\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5982Claude Code\u5728\u6587\u6863\u548c\u7279\u6027\u4efb\u52a1\u4e2d\u9886\u5148\uff0cCursor\u5728\u4fee\u590d\u4efb\u52a1\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u4e0d\u540c\u7684AI\u7f16\u7801\u52a9\u624b\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u6ca1\u6709\u5355\u4e00\u52a9\u624b\u5728\u6240\u6709\u4efb\u52a1\u7c7b\u578b\u4e0a\u90fd\u8868\u73b0\u6700\u4f73\u3002\u4efb\u52a1\u7c7b\u578b\u662f\u5f71\u54cdPR\u63a5\u53d7\u7387\u7684\u4e3b\u8981\u56e0\u7d20\uff0c\u6587\u6863\u4efb\u52a1\u7684\u63a5\u53d7\u7387\u663e\u8457\u9ad8\u4e8e\u65b0\u529f\u80fd\u4efb\u52a1\u3002OpenAI Codex\u6574\u4f53\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u90e8\u5206\u52a9\u624b\u5728\u7279\u5b9a\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\u3002"}}
{"id": "2602.07909", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.07909", "abs": "https://arxiv.org/abs/2602.07909", "authors": ["Taolin Zhang", "Hang Guo", "Wang Lu", "Tao Dai", "Shu-Tao Xia", "Jindong Wang"], "title": "SparseEval: Efficient Evaluation of Large Language Models by Sparse Optimization", "comment": "ICLR2026", "summary": "As large language models (LLMs) continue to scale up, their performance on various downstream tasks has significantly improved. However, evaluating their capabilities has become increasingly expensive, as performing inference on a large number of benchmark samples incurs high computational costs. In this paper, we revisit the model-item performance matrix and show that it exhibits sparsity, that representative items can be selected as anchors, and that the task of efficient benchmarking can be formulated as a sparse optimization problem. Based on these insights, we propose SparseEval, a method that, for the first time, adopts gradient descent to optimize anchor weights and employs an iterative refinement strategy for anchor selection. We utilize the representation capacity of MLP to handle sparse optimization and propose the Anchor Importance Score and Candidate Importance Score to evaluate the value of each item for task-aware refinement. Extensive experiments demonstrate the low estimation error and high Kendall's~$\u03c4$ of our method across a variety of benchmarks, showcasing its superior robustness and practicality in real-world scenarios. Code is available at {https://github.com/taolinzhang/SparseEval}.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSparseEval\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u4f18\u5316\u548c\u951a\u70b9\u9009\u62e9\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u7684\u9ad8\u6548\u4f4e\u6210\u672c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4e0d\u65ad\u63d0\u5347\uff0c\u8bc4\u4f30\u5176\u80fd\u529b\u53d8\u5f97\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u9700\u5bfb\u627e\u6709\u6548\u4e14\u9ad8\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86SparseEval\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u4f18\u5316\u951a\u70b9\u6743\u91cd\uff0c\u91c7\u7528\u8fed\u4ee3\u7ec6\u5316\u7b56\u7565\u9009\u62e9\u951a\u70b9\uff0c\u5229\u7528MLP\u8fdb\u884c\u7a00\u758f\u4f18\u5316\uff0c\u5e76\u8bbe\u8ba1\u4e86\u951a\u70b9\u91cd\u8981\u6027\u5f97\u5206\u548c\u5019\u9009\u91cd\u8981\u6027\u5f97\u5206\u7528\u4e8e\u4efb\u52a1\u611f\u77e5\u7684\u7ec6\u5316\u3002", "result": "SparseEval\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4f4e\u4f30\u8ba1\u8bef\u5dee\u548c\u9ad8Kendall's \u03c4\uff0c\u663e\u793a\u51fa\u8f83\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "SparseEval\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u964d\u4f4e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u4fdd\u6301\u8f83\u4f4e\u7684\u4f30\u8ba1\u8bef\u5dee\u548c\u8f83\u9ad8\u7684\u6392\u540d\u76f8\u5173\u6027\uff0c\u5177\u5907\u826f\u597d\u7684\u9c81\u68d2\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2602.07930", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07930", "abs": "https://arxiv.org/abs/2602.07930", "authors": ["Irina Bigoulaeva", "Jonas Rohweder", "Subhabrata Dutta", "Iryna Gurevych"], "title": "Patches of Nonlinearity: Instruction Vectors in Large Language Models", "comment": null, "summary": "Despite the recent success of instruction-tuned language models and their ubiquitous usage, very little is known of how models process instructions internally. In this work, we address this gap from a mechanistic point of view by investigating how instruction-specific representations are constructed and utilized in different stages of post-training: Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO). Via causal mediation, we identify that instruction representation is fairly localized in models. These representations, which we call Instruction Vectors (IVs), demonstrate a curious juxtaposition of linear separability along with non-linear causal interaction, broadly questioning the scope of the linear representation hypothesis commonplace in mechanistic interpretability. To disentangle the non-linear causal interaction, we propose a novel method to localize information processing in language models that is free from the implicit linear assumptions of patching-based techniques. We find that, conditioned on the task representations formed in the early layers, different information pathways are selected in the later layers to solve that task, i.e., IVs act as circuit selectors.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u56e0\u679c\u8c03\u89e3\u5206\u6790\u63ed\u793a\u4e86\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u4e2d\u6307\u4ee4\u8868\u793a\u7684\u5c40\u90e8\u5316\u548c\u590d\u6742\u56e0\u679c\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u65b9\u6cd5\u8bba\uff0c\u53d1\u73b0IVs\u5728\u6a21\u578b\u4e2d\u4f5c\u4e3a\u7535\u8def\u9009\u62e9\u5668\u4f5c\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\u4fe1\u606f\u8def\u5f84\u3002", "motivation": "\u5c3d\u7ba1\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u53d6\u5f97\u4e86\u6210\u529f\u5e76\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5185\u90e8\u5982\u4f55\u5904\u7406\u6307\u4ee4\u5c1a\u4e0d\u6e05\u695a\uff0c\u56e0\u6b64\u4ece\u673a\u5236\u89d2\u5ea6\u63a2\u7a76\u6307\u4ee4\u8868\u5f81\u7684\u6784\u5efa\u548c\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u56e0\u679c\u8c03\u89e3\u5206\u6790\u65b9\u6cd5\uff0c\u7814\u7a76\u4e86\u8bad\u7ec3\u540e\u4e0d\u540c\u9636\u6bb5\uff08\u76d1\u7763\u5fae\u8c03\u548c\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff09\u4e2d\u6307\u4ee4\u7279\u5b9a\u8868\u793a\u7684\u6784\u5efa\u4e0e\u5229\u7528\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5b9a\u4f4d\u8bed\u8a00\u6a21\u578b\u4fe1\u606f\u5904\u7406\u7684\u65b9\u6cd5\uff0c\u907f\u514d\u4e86\u57fa\u4e8epatching\u7684\u7ebf\u6027\u5047\u8bbe\u3002", "result": "\u53d1\u73b0\u6307\u4ee4\u8868\u5f81\u9ad8\u5ea6\u5c40\u90e8\u5316\uff0c\u5b58\u5728\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u6df7\u5408\u7684\u56e0\u679c\u4ea4\u4e92\uff1b\u65e9\u671f\u5c42\u5f62\u6210\u4efb\u52a1\u76f8\u5173\u8868\u793a\uff0c\u540e\u7eed\u5c42\u6839\u636e\u4efb\u52a1\u9009\u62e9\u4e0d\u540c\u4fe1\u606f\u8def\u5f84\uff0cIVs\u5145\u5f53\u7535\u8def\u9009\u62e9\u5668\u3002", "conclusion": "\u8be5\u8bba\u6587\u53d1\u73b0\u6307\u4ee4\u5411\u91cf\uff08Instruction Vectors, IVs\uff09\u5728\u6a21\u578b\u4e2d\u5177\u6709\u5c40\u90e8\u5316\u7279\u5f81\uff0c\u5e76\u4e14\u5448\u73b0\u51fa\u7ebf\u6027\u53ef\u5206\u6027\u4e0e\u975e\u7ebf\u6027\u56e0\u679c\u4ea4\u4e92\u5e76\u5b58\u7684\u590d\u6742\u7279\u6027\uff0c\u6311\u6218\u4e86\u4f20\u7edf\u7684\u7ebf\u6027\u8868\u793a\u5047\u8bbe\u3002IVs\u5728\u4e0d\u540c\u5c42\u6b21\u53d1\u6325\u7740\u9009\u62e9\u4fe1\u606f\u5904\u7406\u8def\u5f84\u7684\u4f5c\u7528\uff0c\u7c7b\u4f3c\u7535\u8def\u9009\u62e9\u5668\u3002"}}
{"id": "2602.07954", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07954", "abs": "https://arxiv.org/abs/2602.07954", "authors": ["Krzysztof Wr\u00f3bel", "Jan Maria Kowalski", "Jerzy Surma", "Igor Ciuciura", "Maciej Szyma\u0144ski"], "title": "Bielik Guard: Efficient Polish Language Safety Classifiers for LLM Content Moderation", "comment": null, "summary": "As Large Language Models (LLMs) become increasingly deployed in Polish language applications, the need for efficient and accurate content safety classifiers has become paramount. We present Bielik Guard, a family of compact Polish language safety classifiers comprising two model variants: a 0.1B parameter model based on MMLW-RoBERTa-base and a 0.5B parameter model based on PKOBP/polish-roberta-8k. Fine-tuned on a community-annotated dataset of 6,885 Polish texts, these models classify content across five safety categories: Hate/Aggression, Vulgarities, Sexual Content, Crime, and Self-Harm. Our evaluation demonstrates that both models achieve strong performance on multiple benchmarks. The 0.5B variant offers the best overall discrimination capability with F1 scores of 0.791 (micro) and 0.785 (macro) on the test set, while the 0.1B variant demonstrates exceptional efficiency. Notably, Bielik Guard 0.1B v1.1 achieves superior precision (77.65\\%) and very low false positive rate (0.63\\%) on real user prompts, outperforming HerBERT-PL-Guard (31.55\\% precision, 4.70\\% FPR) despite identical model size. The models are publicly available and designed to provide appropriate responses rather than simple content blocking, particularly for sensitive categories like self-harm.", "AI": {"tldr": "\u672c\u6587\u63a8\u51fa\u4e86Bielik Guard\u4e24\u6b3e\u6ce2\u5170\u8bed\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u5668\uff0c\u5728\u7cbe\u5ea6\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5206\u7c7b\u5305\u62ec\u4ec7\u6068\u8a00\u8bba\u3001\u81ea\u6b8b\u7b49\u654f\u611f\u5185\u5bb9\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u6ce2\u5170\u8bed\u5e94\u7528\u4e2d\u7684\u666e\u53ca\uff0c\u4e9f\u9700\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u5668\u4ee5\u4fdd\u969c\u5185\u5bb9\u7684\u5408\u89c4\u6027\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u57fa\u4e8eMMLW-RoBERTa-base\u548cPKOBP/polish-roberta-8k\u6a21\u578b\uff0c\u4f7f\u7528\u793e\u533a\u6807\u6ce8\u76846885\u6761\u6ce2\u5170\u8bed\u6587\u672c\u6570\u636e\u96c6\u8fdb\u884c\u5fae\u8c03\uff0c\u9488\u5bf9\u4e94\u4e2a\u5b89\u5168\u7c7b\u522b\u8fdb\u884c\u5206\u7c7b\u3002", "result": "0.5B\u53c2\u6570\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u5b9e\u73b0\u4e86F1\u5206\u65700.791\uff08micro\uff09\u548c0.785\uff08macro\uff09\uff0c\u800c0.1B\u6a21\u578b\u5728\u7cbe\u786e\u7387\u548c\u8bef\u62a5\u7387\u65b9\u9762\u8868\u73b0\u5353\u8d8a\uff0c\u7cbe\u786e\u738777.65%\uff0c\u8bef\u62a5\u7387\u4ec50.63%\u3002\u4e24\u6a21\u578b\u516c\u5f00\u53d1\u5e03\uff0c\u4e14\u5bf9\u654f\u611f\u7c7b\u522b\u8bbe\u8ba1\u4e86\u9002\u5f53\u54cd\u5e94\u7b56\u7565\u3002", "conclusion": "Bielik Guard\u63d0\u4f9b\u4e86\u4e24\u4e2a\u7d27\u51d1\u7684\u6ce2\u5170\u8bed\u5185\u5bb9\u5b89\u5168\u5206\u7c7b\u5668\uff0c\u5206\u522b\u4ee5\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u5b9e\u73b0\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u5728\u51c6\u786e\u7387\u548c\u8bef\u62a5\u7387\u4e0a\u76f8\u8f83\u540c\u7c7b\u6a21\u578b\u6709\u660e\u663e\u4f18\u52bf\u3002"}}
{"id": "2602.07963", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07963", "abs": "https://arxiv.org/abs/2602.07963", "authors": ["Vaibhav Shukla", "Hardik Sharma", "Adith N Reganti", "Soham Wasmatkar", "Bagesh Kumar", "Vrijendra Singh"], "title": "Lost in Translation? A Comparative Study on the Cross-Lingual Transfer of Composite Harms", "comment": "Accepted at the AICS Workshop, AAAI 2026", "summary": "Most safety evaluations of large language models (LLMs) remain anchored in English. Translation is often used as a shortcut to probe multilingual behavior, but it rarely captures the full picture, especially when harmful intent or structure morphs across languages. Some types of harm survive translation almost intact, while others distort or disappear. To study this effect, we introduce CompositeHarm, a translation-based benchmark designed to examine how safety alignment holds up as both syntax and semantics shift. It combines two complementary English datasets, AttaQ, which targets structured adversarial attacks, and MMSafetyBench, which covers contextual, real-world harms, and extends them into six languages: English, Hindi, Assamese, Marathi, Kannada, and Gujarati. Using three large models, we find that attack success rates rise sharply in Indic languages, especially under adversarial syntax, while contextual harms transfer more moderately. To ensure scalability and energy efficiency, our study adopts lightweight inference strategies inspired by edge-AI design principles, reducing redundant evaluation passes while preserving cross-lingual fidelity. This design makes large-scale multilingual safety testing both computationally feasible and environmentally conscious. Overall, our results show that translated benchmarks are a necessary first step, but not a sufficient one, toward building grounded, resource-aware, language-adaptive safety systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faCompositeHarm\u591a\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\uff0c\u63ed\u793a\u7ffb\u8bd1\u8bc4\u4f30\u7684\u5c40\u9650\uff0c\u5f3a\u8c03\u9700\u9488\u5bf9\u8bed\u8a00\u5dee\u5f02\u6784\u5efa\u591a\u8bed\u8a00\u5b89\u5168\u6d4b\u8bd5\u4f53\u7cfb\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u63a8\u7406\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u4e3b\u8981\u57fa\u4e8e\u82f1\u6587\uff0c\u7b80\u5355\u7ffb\u8bd1\u65e0\u6cd5\u5168\u9762\u53cd\u6620\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5b89\u5168\u8868\u73b0\uff0c\u5c24\u5176\u662f\u6076\u610f\u5185\u5bb9\u7ed3\u6784\u548c\u610f\u56fe\u8de8\u8bed\u8a00\u53d8\u5f02\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faCompositeHarm\u57fa\u51c6\uff0c\u5c06\u4e24\u5957\u82f1\u6587\u6570\u636e\u96c6\uff08AttaQ\u548cMMSafetyBench\uff09\u6269\u5c55\u5230\u516d\u79cd\u8bed\u8a00\uff0c\u5229\u7528\u4e09\u6b3e\u5927\u578b\u6a21\u578b\u6d4b\u8bd5\u653b\u51fb\u6210\u529f\u7387\u548c\u5371\u5bb3\u8f6c\u79fb\u60c5\u51b5\uff0c\u540c\u65f6\u91c7\u7528\u8f7b\u91cf\u7ea7\u63a8\u7406\u7b56\u7565\u63d0\u5347\u8ba1\u7b97\u548c\u80fd\u6e90\u6548\u7387\u3002", "result": "\u53d1\u73b0\u7ed3\u6784\u5316\u5bf9\u6297\u653b\u51fb\u5728\u5370\u5ea6\u8bed\u8a00\u4e2d\u7684\u653b\u51fb\u6210\u529f\u7387\u663e\u8457\u4e0a\u5347\uff0c\u800c\u8bed\u5883\u76f8\u5173\u5371\u5bb3\u7684\u8f6c\u79fb\u8f83\u4e3a\u6e29\u548c\u3002\u8f7b\u91cf\u7ea7\u63a8\u7406\u7b56\u7565\u6709\u6548\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u4e14\u4fdd\u6301\u591a\u8bed\u8a00\u8bc4\u6d4b\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ffb\u8bd1\u4f5c\u4e3a\u591a\u8bed\u8a00\u5b89\u5168\u8bc4\u4f30\u7684\u5feb\u6377\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\uff0c\u90e8\u5206\u5371\u5bb3\u5728\u7ffb\u8bd1\u8fc7\u7a0b\u4e2d\u53d1\u751f\u53d8\u5f62\u6216\u6d88\u5931\uff0c\u5bfc\u81f4\u5b89\u5168\u5bf9\u9f50\u6548\u679c\u4e0d\u5b8c\u6574\u3002\u9700\u8981\u6784\u5efa\u8003\u8651\u8bed\u8a00\u8bed\u6cd5\u548c\u8bed\u4e49\u53d8\u5316\u7684\u591a\u8bed\u8a00\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u3002"}}
{"id": "2602.07978", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07978", "abs": "https://arxiv.org/abs/2602.07978", "authors": ["Rui Feng", "Zhiyao Luo", "Liuyu Wu", "Wei Wang", "Yuting Song", "Yong Liu", "Kok Pin Ng", "Jianqing Li", "Xingyao Wang"], "title": "Cross-Linguistic Persona-Driven Data Synthesis for Robust Multimodal Cognitive Decline Detection", "comment": "18 pages, 7 figures, 6 tables", "summary": "Speech-based digital biomarkers represent a scalable, non-invasive frontier for the early identification of Mild Cognitive Impairment (MCI). However, the development of robust diagnostic models remains impeded by acute clinical data scarcity and a lack of interpretable reasoning. Current solutions frequently struggle with cross-lingual generalization and fail to provide the transparent rationales essential for clinical trust. To address these barriers, we introduce SynCog, a novel framework integrating controllable zero-shot multimodal data synthesis with Chain-of-Thought (CoT) deduction fine-tuning. Specifically, SynCog simulates diverse virtual subjects with varying cognitive profiles to effectively alleviate clinical data scarcity. This generative paradigm enables the rapid, zero-shot expansion of clinical corpora across diverse languages, effectively bypassing data bottlenecks in low-resource settings and bolstering the diagnostic performance of Multimodal Large Language Models (MLLMs). Leveraging this synthesized dataset, we fine-tune a foundational multimodal backbone using a CoT deduction strategy, empowering the model to explicitly articulate diagnostic thought processes rather than relying on black-box predictions. Extensive experiments on the ADReSS and ADReSSo benchmarks demonstrate that augmenting limited clinical data with synthetic phenotypes yields competitive diagnostic performance, achieving Macro-F1 scores of 80.67% and 78.46%, respectively, outperforming current baseline models. Furthermore, evaluation on an independent real-world Mandarin cohort (CIR-E) demonstrates robust cross-linguistic generalization, attaining a Macro-F1 of 48.71%. These findings constitute a critical step toward providing clinically trustworthy and linguistically inclusive cognitive assessment tools for global healthcare.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSynCog\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u865a\u62df\u60a3\u8005\u6570\u636e\u548c\u94fe\u5f0f\u601d\u7ef4\u5fae\u8c03\uff0c\u63d0\u5347\u8ba4\u77e5\u969c\u788d\u8bed\u97f3\u8bca\u65ad\u6a21\u578b\u7684\u6027\u80fd\u4e0e\u53ef\u89e3\u91ca\u6027\uff0c\u5b9e\u73b0\u8de8\u8bed\u8a00\u6cdb\u5316\uff0c\u89e3\u51b3\u4e34\u5e8a\u6570\u636e\u532e\u4e4f\u548c\u900f\u660e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "MCI\u7684\u65e9\u671f\u8bc6\u522b\u53d7\u9650\u4e8e\u4e34\u5e8a\u6570\u636e\u7a00\u7f3a\u548c\u7f3a\u4e4f\u53ef\u89e3\u91ca\u7684\u8bca\u65ad\u63a8\u7406\uff0c\u73b0\u6709\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u6cdb\u5316\u548c\u900f\u660e\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u63d0\u51faSynCog\u6846\u67b6\uff0c\u7ed3\u5408\u53ef\u63a7\u96f6\u6837\u672c\u591a\u6a21\u6001\u6570\u636e\u5408\u6210\u548c\u94fe\u5f0f\u601d\u7ef4(CoT)\u5fae\u8c03\uff0c\u5229\u7528\u865a\u62df\u8ba4\u77e5\u591a\u6837\u8868\u578b\u5408\u6210\u6269\u5c55\u4e34\u5e8a\u6570\u636e\uff0c\u5e76\u901a\u8fc7CoT\u5f3a\u5316\u8bca\u65ad\u63a8\u7406\u7684\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728ADReSS\u548cADReSSo\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u5206\u522b\u53d6\u5f9780.67%\u548c78.46%\u7684Macro-F1\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff1b\u5728\u771f\u5b9e\u6c49\u8bed\u6570\u636e\u96c6CIR-E\u4e0a\u5b9e\u73b048.71%\u7684Macro-F1\uff0c\u663e\u793a\u826f\u597d\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "SynCog\u6709\u6548\u7f13\u89e3\u4e86\u4e34\u5e8a\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u8ba4\u77e5\u969c\u788d\u8bca\u65ad\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u4e86\u53ef\u4fe1\u8d56\u4e14\u591a\u8bed\u8a00\u9002\u7528\u7684\u6570\u5b57\u8bed\u8a00\u751f\u7269\u6807\u5fd7\u7269\u5e94\u7528\u3002"}}
{"id": "2602.07996", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07996", "abs": "https://arxiv.org/abs/2602.07996", "authors": ["Arash Marioriyad", "Omid Ghahroodi", "Ehsaneddin Asgari", "Mohammad Hossein Rohban", "Mahdieh Soleymani Baghshah"], "title": "The Judge Who Never Admits: Hidden Shortcuts in LLM-based Evaluation", "comment": null, "summary": "Large language models (LLMs) are increasingly used as automatic judges to evaluate system outputs in tasks such as reasoning, question answering, and creative writing. A faithful judge should base its verdicts solely on content quality, remain invariant to irrelevant context, and transparently reflect the factors driving its decisions. We test this ideal via controlled cue perturbations-synthetic metadata labels injected into evaluation prompts-for six judge models: GPT-4o, Gemini-2.0-Flash, Gemma-3-27B, Qwen3-235B, Claude-3-Haiku, and Llama3-70B. Experiments span two complementary datasets with distinct evaluation regimes: ELI5 (factual QA) and LitBench (open-ended creative writing). We study six cue families: source, temporal, age, gender, ethnicity, and educational status. Beyond measuring verdict shift rates (VSR), we introduce cue acknowledgment rate (CAR) to quantify whether judges explicitly reference the injected cues in their natural-language rationales. Across cues with strong behavioral effects-e.g., provenance hierarchies (Expert > Human > LLM > Unknown), recency preferences (New > Old), and educational-status favoritism-CAR is typically at or near zero, indicating that shortcut reliance is largely unreported even when it drives decisions. Crucially, CAR is also dataset-dependent: explicit cue recognition is more likely to surface in the factual ELI5 setting for some models and cues, but often collapses in the open-ended LitBench regime, where large verdict shifts can persist despite zero acknowledgment. The combination of substantial verdict sensitivity and limited cue acknowledgment reveals an explanation gap in LLM-as-judge pipelines, raising concerns about reliability of model-based evaluation in both research and deployment.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5408\u6210\u4fe1\u53f7\u6270\u52a8\u6d4b\u8bd5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u8005\u7684\u504f\u89c1\u548c\u900f\u660e\u5ea6\uff0c\u63ed\u793a\u5176\u5224\u51b3\u53d7\u65e0\u5173\u7ebf\u7d22\u5f71\u54cd\u4f46\u96be\u4ee5\u89e3\u91ca\uff0c\u8868\u660e\u6a21\u578b\u8bc4\u4f30\u4ecd\u9700\u6539\u8fdb\u3002", "motivation": "\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u81ea\u52a8\u8bc4\u5224\u8005\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u8bc4\u5206\u7684\u516c\u6b63\u6027\u548c\u900f\u660e\u6027\u3002", "method": "\u901a\u8fc7\u5bf9\u516d\u4e2a\u8bc4\u5224\u6a21\u578b\u6ce8\u5165\u5408\u6210\u5143\u6570\u636e\u6807\u7b7e\uff08\u63a7\u5236\u4fe1\u53f7\u6270\u52a8\uff09\uff0c\u6d4b\u8bd5\u5176\u5bf9\u65e0\u5173\u4e0a\u4e0b\u6587\u7684\u9c81\u68d2\u6027\u53ca\u51b3\u7b56\u900f\u660e\u5ea6\uff0c\u8986\u76d6\u4e24\u4e2a\u6570\u636e\u96c6\u548c\u516d\u79cd\u7ebf\u7d22\u7c7b\u522b\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5728\u67d0\u4e9b\u7ebf\u7d22\u4e0a\u4e25\u91cd\u504f\u5411\uff08\u5982\u6765\u6e90\u3001\u65f6\u95f4\u3001\u6559\u80b2\u72b6\u6001\uff09\uff0c\u4f46\u51e0\u4e4e\u672a\u5728\u81ea\u7136\u8bed\u8a00\u7406\u7531\u4e2d\u627f\u8ba4\u8fd9\u4e9b\u504f\u89c1\uff0c\u4e14\u900f\u660e\u5ea6\u4f9d\u8d56\u6570\u636e\u96c6\uff0c\u8868\u660e\u5b58\u5728\u89e3\u91ca\u7f3a\u53e3\u3002", "conclusion": "LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5b58\u5728\u663e\u8457\u7684\u5224\u51b3\u504f\u5dee\u548c\u900f\u660e\u5ea6\u4e0d\u8db3\u95ee\u9898\uff0c\u5f71\u54cd\u6a21\u578b\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.08005", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08005", "abs": "https://arxiv.org/abs/2602.08005", "authors": ["Jitai Hao", "Qiang Huang", "Yaowei Wang", "Min Zhang", "Jun Yu"], "title": "DeltaKV: Residual-Based KV Cache Compression via Long-Range Similarity", "comment": "preprint", "summary": "The deployment of efficient long-context LLMs in applications like autonomous agents, long-chain reasoning, and creative writing is fundamentally bottlenecked by the linear growth of KV cache memory. Existing compression and eviction methods often struggle to balance accuracy, compression ratio, and hardware efficiency. We propose DeltaKV, a residual-based KV cache compression framework motivated by two empirical findings: long-range inter-token similarity and highly shared latent components in KV representations. Instead of discarding tokens, DeltaKV encodes semantic residuals relative to retrieved historical references, preserving fidelity while substantially reducing storage. To translate compression gains into real system speedups, we further introduce Sparse-vLLM, a high-performance inference engine with decoupled memory management and kernels optimized for sparse and irregular KV layouts. Experiments show that DeltaKV reduces KV cache memory to 29\\% of the original while maintaining near-lossless accuracy on LongBench, SCBench, and AIME. When integrated with Sparse-vLLM, it achieves up to 2$\\times$ throughput improvement over vLLM in long-context scenarios, demonstrating a practical path toward scalable long-context LLM deployment. Code, model checkpoints, and datasets are available at https://github.com/CURRENTF/Sparse-vLLM.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6b8b\u5dee\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6DeltaKV\u548c\u9ad8\u6027\u80fd\u63a8\u7406\u5f15\u64ceSparse-vLLM\uff0c\u663e\u8457\u964d\u4f4e\u5185\u5b58\u5360\u7528\u5e76\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u52a9\u529b\u957f\u4e0a\u4e0b\u6587\u5927\u6a21\u578b\u9ad8\u6548\u90e8\u7f72\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587LLM\u5e94\u7528\u53d7\u9650\u4e8eKV\u7f13\u5b58\u7ebf\u6027\u589e\u957f\u7684\u5185\u5b58\u74f6\u9888\uff0c\u73b0\u6709\u538b\u7f29\u548c\u5254\u9664\u65b9\u6cd5\u96be\u4ee5\u517c\u987e\u7cbe\u5ea6\u3001\u538b\u7f29\u7387\u548c\u786c\u4ef6\u6548\u7387\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6b8b\u5dee\u7684KV\u7f13\u5b58\u538b\u7f29\u6846\u67b6DeltaKV\uff0c\u901a\u8fc7\u7f16\u7801\u8bed\u4e49\u6b8b\u5dee\u800c\u975e\u4e22\u5f03token\u5b9e\u73b0\u538b\u7f29\uff1b\u5f15\u5165Sparse-vLLM\u63a8\u7406\u5f15\u64ce\uff0c\u91c7\u7528\u89e3\u8026\u5185\u5b58\u7ba1\u7406\u548c\u4f18\u5316\u7a00\u758f\u975e\u89c4\u5219KV\u5e03\u5c40\u7684\u5185\u6838\u4ee5\u63d0\u5347\u7cfb\u7edf\u901f\u5ea6\u3002", "result": "DeltaKV\u5c06KV\u7f13\u5b58\u5185\u5b58\u538b\u7f29\u81f3\u539f\u6765\u768429%\uff0c\u5728LongBench\u3001SCBench\u548cAIME\u6570\u636e\u96c6\u4e0a\u4fdd\u6301\u8fd1\u65e0\u635f\u7cbe\u5ea6\uff1b\u7ed3\u5408Sparse-vLLM\u5b9e\u73b0\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u6700\u9ad82\u500d\u541e\u5410\u91cf\u63d0\u5347\u3002", "conclusion": "DeltaKV\u5728\u4fdd\u6301\u63a5\u8fd1\u65e0\u635f\u7cbe\u5ea6\u7684\u540c\u65f6\uff0c\u5c06KV\u7f13\u5b58\u5185\u5b58\u51cf\u5c11\u5230\u539f\u6765\u768429%\uff0c\u5e76\u7ed3\u5408Sparse-vLLM\u5b9e\u73b0\u4e86\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u6700\u9ad82\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u5c55\u793a\u4e86\u53ef\u6269\u5c55\u957f\u4e0a\u4e0b\u6587LLM\u90e8\u7f72\u7684\u5b9e\u9645\u8def\u5f84\u3002"}}
{"id": "2602.08028", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08028", "abs": "https://arxiv.org/abs/2602.08028", "authors": ["Po-Chun Chen", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Diverge to Induce Prompting: Multi-Rationale Induction for Zero-Shot Reasoning", "comment": "Accepted to Findings of IJCNLP-AACL 2025", "summary": "To address the instability of unguided reasoning paths in standard Chain-of-Thought prompting, recent methods guide large language models (LLMs) by first eliciting a single reasoning strategy. However, relying on just one strategy for each question can still limit performance across diverse tasks. We propose Diverge-to-Induce Prompting (DIP), a framework that first prompts an LLM to generate multiple diverse high-level rationales for each question. Each rationale is then elaborated into a detailed, step-by-step draft plan. Finally, these draft plans are induced into a final plan. DIP enhances zero-shot reasoning accuracy without reliance on resource-intensive sampling. Experiments show that DIP outperforms single-strategy prompting, demonstrating the effectiveness of multi-plan induction for prompt-based reasoning.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faDIP\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7b56\u7565\u751f\u6210\u4e0e\u5f52\u7eb3\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u7387\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u5355\u7b56\u7565\u65b9\u6cd5\u3002", "motivation": "\u5355\u4e00\u63a8\u7406\u7b56\u7565\u9650\u5236\u4e86\u6a21\u578b\u5728\u591a\u6837\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u800c\u591a\u7b56\u7565\u6574\u5408\u53ef\u80fd\u63d0\u5347\u63a8\u7406\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "DIP\u6846\u67b6\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5148\u751f\u6210\u591a\u4e2a\u591a\u6837\u5316\u7684\u9ad8\u5c42\u6b21\u63a8\u7406\u7b56\u7565\uff0c\u518d\u5c06\u6bcf\u4e2a\u7b56\u7565\u7ec6\u5316\u4e3a\u9010\u6b65\u8349\u6848\uff0c\u6700\u540e\u5c06\u8fd9\u4e9b\u8349\u6848\u5f52\u7eb3\u4e3a\u6700\u7ec8\u65b9\u6848\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDIP\u5728\u65e0\u9700\u8d44\u6e90\u5bc6\u96c6\u91c7\u6837\u7684\u60c5\u51b5\u4e0b\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u5355\u7b56\u7565\u63d0\u793a\u3002", "conclusion": "\u591a\u65b9\u6848\u5f52\u7eb3\u5f15\u5bfc\uff08DIP\uff09\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u63a8\u7406\u4e2d\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u5355\u4e00\u7b56\u7565\u7684\u63d0\u793a\u65b9\u6cd5\u3002"}}
{"id": "2602.08031", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08031", "abs": "https://arxiv.org/abs/2602.08031", "authors": ["Chenwang Wu", "Yiu-ming Cheung", "Shuhai Zhang", "Bo Han", "Defu Lian"], "title": "Beyond Raw Detection Scores: Markov-Informed Calibration for Boosting Machine-Generated Text Detection", "comment": null, "summary": "While machine-generated texts (MGTs) offer great convenience, they also pose risks such as disinformation and phishing, highlighting the need for reliable detection. Metric-based methods, which extract statistically distinguishable features of MGTs, are often more practical than complex model-based methods that are prone to overfitting. Given their diverse designs, we first place representative metric-based methods within a unified framework, enabling a clear assessment of their advantages and limitations. Our analysis identifies a core challenge across these methods: the token-level detection score is easily biased by the inherent randomness of the MGTs generation process. To address this, we theoretically and empirically reveal two relationships of context detection scores that may aid calibration: Neighbor Similarity and Initial Instability. We then propose a Markov-informed score calibration strategy that models these relationships using Markov random fields, and implements it as a lightweight component via a mean-field approximation, allowing our method to be seamlessly integrated into existing detectors. Extensive experiments in various real-world scenarios, such as cross-LLM and paraphrasing attacks, demonstrate significant gains over baselines with negligible computational overhead. The code is available at https://github.com/tmlr-group/MRF_Calibration.", "AI": {"tldr": "\u9488\u5bf9\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u4e2d\u8bc4\u5206\u6613\u53d7\u968f\u673a\u6027\u5f71\u54cd\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u7684\u6821\u51c6\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u4e14\u8ba1\u7b97\u8d1f\u62c5\u4f4e\u3002", "motivation": "\u673a\u5668\u751f\u6210\u6587\u672c\uff08MGTs\uff09\u5e26\u6765\u4fbf\u5229\u7684\u540c\u65f6\u4e5f\u5f15\u53d1\u865a\u5047\u4fe1\u606f\u548c\u7f51\u7edc\u9493\u9c7c\u7b49\u98ce\u9669\uff0c\u9700\u8981\u53ef\u9760\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u7edf\u4e00\u73b0\u6709\u57fa\u4e8e\u6307\u6807\u7684\u65b9\u6cd5\u6846\u67b6\uff0c\u5206\u6790\u5176\u6838\u5fc3\u6311\u6218\uff0c\u5373\u68c0\u6d4b\u5206\u6570\u53d7\u751f\u6210\u8fc7\u7a0b\u7684\u968f\u673a\u6027\u5f71\u54cd\uff0c\u63d0\u51fa\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u7684\u5206\u6570\u6821\u51c6\u7b56\u7565\uff0c\u5229\u7528\u90bb\u8fd1\u76f8\u4f3c\u6027\u548c\u521d\u59cb\u4e0d\u7a33\u5b9a\u6027\u4e24\u4e2a\u4e0a\u4e0b\u6587\u5173\u7cfb\uff0c\u901a\u8fc7\u5747\u573a\u8fd1\u4f3c\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u7ec4\u4ef6\uff0c\u6574\u5408\u8fdb\u73b0\u6709\u68c0\u6d4b\u5668\u3002", "result": "\u5728\u8de8\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u6539\u5199\u653b\u51fb\u7b49\u771f\u5b9e\u573a\u666f\u4e2d\uff0c\u65b9\u6cd5\u76f8\u8f83\u57fa\u51c6\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u7684\u5206\u6570\u6821\u51c6\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u6307\u6807\u65b9\u6cd5\u4e2d\u8bc4\u5206\u6613\u53d7\u968f\u673a\u6027\u504f\u5dee\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u68c0\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2602.08048", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08048", "abs": "https://arxiv.org/abs/2602.08048", "authors": ["Arshia Hemmat", "Philip Torr", "Yongqiang Chen", "Junchi Yu"], "title": "TDGNet: Hallucination Detection in Diffusion Language Models via Temporal Dynamic Graphs", "comment": null, "summary": "Diffusion language models (D-LLMs) offer parallel denoising and bidirectional context, but hallucination detection for D-LLMs remains underexplored. Prior detectors developed for auto-regressive LLMs typically rely on single-pass cues and do not directly transfer to diffusion generation, where factuality evidence is distributed across the denoising trajectory and may appear, drift, or be self-corrected over time. We introduce TDGNet, a temporal dynamic graph framework that formulates hallucination detection as learning over evolving token-level attention graphs. At each denoising step, we sparsify the attention graph and update per-token memories via message passing, then apply temporal attention to aggregate trajectory-wide evidence for final prediction. Experiments on LLaDA-8B and Dream-7B across QA benchmarks show consistent AUROC improvements over output-based, latent-based, and static-graph baselines, with single-pass inference and modest overhead. These results highlight the importance of temporal reasoning on attention graphs for robust hallucination detection in diffusion language models.", "AI": {"tldr": "\u4e3a\u4e86\u68c0\u6d4b\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u865a\u5047\u5185\u5bb9\uff0c\u672c\u6587\u63d0\u51fa\u5229\u7528\u65f6\u5e8f\u52a8\u6001\u6ce8\u610f\u529b\u56fe\u7684TDGNet\u65b9\u6cd5\uff0c\u901a\u8fc7\u5168\u8f68\u8ff9\u4fe1\u606f\u878d\u5408\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u68c0\u6d4b\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7531\u4e8e\u5e73\u884c\u53bb\u566a\u548c\u53cc\u5411\u4e0a\u4e0b\u6587\uff0c\u5176\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u96be\u5ea6\u8f83\u81ea\u52a8\u56de\u5f52\u6a21\u578b\u66f4\u5927\uff0c\u73b0\u6709\u57fa\u4e8e\u5355\u6b21\u751f\u6210\u7684\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u8fc1\u79fb\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u65f6\u5e8f\u52a8\u6001\u56fe\u6846\u67b6TDGNet\uff0c\u901a\u8fc7\u7a00\u758f\u5316\u6ce8\u610f\u529b\u56fe\u3001\u6d88\u606f\u4f20\u9012\u66f4\u65b0token\u8bb0\u5fc6\uff0c\u5e76\u4f7f\u7528\u65f6\u5e8f\u6ce8\u610f\u529b\u805a\u5408\u6574\u4e2a\u53bb\u566a\u8f68\u8ff9\u4e2d\u7684\u4e8b\u5b9e\u6027\u8bc1\u636e\uff0c\u5b8c\u6210\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u3002", "result": "\u5728LLaDA-8B\u548cDream-7B\u6a21\u578b\u7684\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cTDGNet\u5728AUROC\u6307\u6807\u4e0a\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6848\uff0c\u4e14\u4ec5\u9700\u5355\u6b21\u63a8\u7406\uff0c\u8ba1\u7b97\u5f00\u9500\u9002\u4e2d\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684TDGNet\u65b9\u6cd5\u901a\u8fc7\u5728\u65f6\u95f4\u6f14\u5316\u7684token\u7ea7\u6ce8\u610f\u529b\u56fe\u4e0a\u8fdb\u884c\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u865a\u5047\u4fe1\u606f\u7684\u6709\u6548\u68c0\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.08100", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08100", "abs": "https://arxiv.org/abs/2602.08100", "authors": ["Jasmine Cui", "Charles Ye"], "title": "Emergent Search and Backtracking in Latent Reasoning Models", "comment": null, "summary": "What happens when a language model thinks without words? Standard reasoning LLMs verbalize intermediate steps as chain-of-thought; latent reasoning transformers (LRTs) instead perform deliberation entirely in continuous hidden space. We investigate an LRT, decoding the model's evolving beliefs at every step on a multiple-choice QA benchmark. We find that the model spontaneously learns a structured search process in latent space. Deliberation follows a consistent trajectory: an exploration phase where probability mass spreads across candidates, tentative commitment to a frontrunner, and either convergence or backtracking. Backtracking is prevalent (32% of instances), beneficial (34% accuracy gain over non-backtracking instances), and predominantly directed away from the semantically closest distractor toward the correct answer. The search is adaptive: replacing distractors with implausible alternatives shortens exploration by 54%. Latent reasoning models achieve in activation space what chain-of-thought achieves through words: the ability to be wrong, notice, and recover.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u6f5c\u5728\u63a8\u7406\u8f6c\u6362\u5668\u5728\u9690\u85cf\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7ed3\u6784\u5316\u641c\u7d22\u7684\u80fd\u529b\uff0c\u4e14\u901a\u8fc7\u56de\u6eaf\u673a\u5236\u63d0\u5347\u63a8\u7406\u51c6\u786e\u5ea6\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u94fe\u5f0f\u601d\u7ef4\u7684\u63a8\u7406\u6548\u679c\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u6ca1\u6709\u663e\u5f0f\u6587\u5b57\u8868\u8fbe\u7684\u60c5\u51b5\u4e0b\u5982\u4f55\u8fdb\u884c\u63a8\u7406\u548c\u601d\u8003\uff0c\u7406\u89e3\u5176\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u89e3\u7801LRT\u6a21\u578b\u5728\u591a\u4e2a\u9009\u62e9\u9898\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bcf\u4e00\u6b65\u7684\u6f14\u53d8\u4fe1\u5ff5\uff0c\u5206\u6790\u5176\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u63a8\u7406\u8f68\u8ff9\u548c\u641c\u7d22\u884c\u4e3a\u3002", "result": "\u6a21\u578b\u5c55\u73b0\u4e86\u4e00\u4e2a\u5305\u542b\u63a2\u7d22\u3001\u521d\u6b65\u627f\u8bfa\u53ca\u6536\u655b\u6216\u56de\u6eaf\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u56de\u6eaf\u53d1\u751f\u7387\u9ad8\u4e14\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\uff0c\u4e14\u641c\u7d22\u8fc7\u7a0b\u5177\u6709\u9002\u5e94\u6027\uff0c\u66ff\u6362\u5e72\u6270\u9009\u9879\u80fd\u663e\u8457\u7f29\u77ed\u63a2\u7d22\u65f6\u95f4\u3002", "conclusion": "\u6f5c\u5728\u63a8\u7406\u8f6c\u6362\u5668\uff08LRTs\uff09\u80fd\u591f\u5728\u9690\u85cf\u7a7a\u95f4\u4e2d\u81ea\u53d1\u5730\u5b66\u4e60\u7ed3\u6784\u5316\u641c\u7d22\u8fc7\u7a0b\uff0c\u8868\u73b0\u51fa\u7c7b\u4f3c\u4e8e\u94fe\u5f0f\u601d\u7ef4\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u901a\u8fc7\u56de\u6eaf\u673a\u5236\u663e\u8457\u63d0\u5347\u591a\u9009\u9898\u95ee\u7b54\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2602.08124", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08124", "abs": "https://arxiv.org/abs/2602.08124", "authors": ["Ke Xu", "Shera Potka", "Alex Thomo"], "title": "Gender and Race Bias in Consumer Product Recommendations by Large Language Models", "comment": "Accepted at the 39th International Conference on Advanced Information Networking and Applications (AINA 2025)", "summary": "Large Language Models are increasingly employed in generating consumer product recommendations, yet their potential for embedding and amplifying gender and race biases remains underexplored. This paper serves as one of the first attempts to examine these biases within LLM-generated recommendations. We leverage prompt engineering to elicit product suggestions from LLMs for various race and gender groups and employ three analytical methods-Marked Words, Support Vector Machines, and Jensen-Shannon Divergence-to identify and quantify biases. Our findings reveal significant disparities in the recommendations for demographic groups, underscoring the need for more equitable LLM recommendation systems.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ea7\u54c1\u63a8\u8350\u4e2d\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\uff0c\u8bc1\u5b9e\u4e86\u5b58\u5728\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u5f3a\u8c03\u4e86\u6784\u5efa\u516c\u5e73\u63a8\u8350\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ea7\u54c1\u63a8\u8350\u4e2d\u6f5c\u5728\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\u95ee\u9898\uff0c\u4ee5\u586b\u8865\u8be5\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u5229\u7528\u63d0\u793a\u5de5\u7a0b\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u4e0d\u540c\u6027\u522b\u548c\u79cd\u65cf\u7fa4\u4f53\u7684\u4ea7\u54c1\u63a8\u8350\uff0c\u7ed3\u5408\u6807\u8bb0\u8bcd\u3001\u652f\u6301\u5411\u91cf\u673a\u548cJensen-Shannon\u6563\u5ea6\u4e09\u79cd\u65b9\u6cd5\u5206\u6790\u548c\u91cf\u5316\u504f\u89c1\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u63a8\u8350\u7ed3\u679c\u5728\u4e0d\u540c\u7fa4\u4f53\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8868\u660e\u5f53\u524d\u63a8\u8350\u7cfb\u7edf\u7f3a\u4e4f\u516c\u5e73\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u6d88\u8d39\u8005\u4ea7\u54c1\u63a8\u8350\u65f6\u5b58\u5728\u663e\u8457\u7684\u6027\u522b\u548c\u79cd\u65cf\u504f\u89c1\uff0c\u8fd9\u4e9b\u504f\u89c1\u5bfc\u81f4\u4e0d\u540c\u4eba\u53e3\u7fa4\u4f53\u95f4\u63a8\u8350\u7684\u4e0d\u516c\u5e73\u5dee\u5f02\u3002"}}
{"id": "2602.08149", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08149", "abs": "https://arxiv.org/abs/2602.08149", "authors": ["Sahana Ramnath", "Nima Chitsazan", "Mingyang Zhou", "Chia-Hsuan Lee", "Shi-Xiong Zhang", "Stephen Rawls", "Sambit Sahu", "Sangwoo Cho", "Xiang Ren", "Genta Indra Winata", "Akshaj Kumar Veldanda"], "title": "DIAL-SUMMER: A Structured Evaluation Framework of Hierarchical Errors in Dialogue Summaries", "comment": null, "summary": "Dialogues are a predominant mode of communication for humans, and it is immensely helpful to have automatically generated summaries of them (e.g., to revise key points discussed in a meeting, to review conversations between customer agents and product users). Prior works on dialogue summary evaluation largely ignore the complexities specific to this task: (i) shift in structure, from multiple speakers discussing information in a scattered fashion across several turns, to a summary's sentences, and (ii) shift in narration viewpoint, from speakers' first/second-person narration, standardized third-person narration in the summary. In this work, we introduce our framework DIALSUMMER to address the above. We propose DIAL-SUMMER's taxonomy of errors to comprehensively evaluate dialogue summaries at two hierarchical levels: DIALOGUE-LEVEL that focuses on the broader speakers/turns, and WITHIN-TURN-LEVEL that focuses on the information talked about inside a turn. We then present DIAL-SUMMER's dataset composed of dialogue summaries manually annotated with our taxonomy's fine-grained errors. We conduct empirical analyses of these annotated errors, and observe interesting trends (e.g., turns occurring in middle of the dialogue are the most frequently missed in the summary, extrinsic hallucinations largely occur at the end of the summary). We also conduct experiments on LLM-Judges' capability at detecting these errors, through which we demonstrate the challenging nature of our dataset, the robustness of our taxonomy, and the need for future work in this field to enhance LLMs' performance in the same. Code and inference dataset coming soon.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5bf9\u8bdd\u6458\u8981\u8bc4\u4ef7\u4e2d\u7684\u7ed3\u6784\u548c\u89c6\u89d2\u53d8\u5316\u96be\u70b9\uff0c\u63d0\u51fa\u4e86DIAL-SUMMER\u6846\u67b6\u53ca\u7ec6\u7c92\u5ea6\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\uff0c\u6784\u5efa\u4e86\u6807\u6ce8\u6570\u636e\u96c6\u5e76\u5206\u6790\u9519\u8bef\u5206\u5e03\uff0c\u63ed\u793a\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\uff0c\u63a8\u52a8\u672a\u6765\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u5bf9\u8bdd\u6458\u8981\u8bc4\u4ef7\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5bf9\u8bdd\u591a\u8bf4\u8bdd\u4eba\u7ed3\u6784\u548c\u53d9\u8ff0\u89c6\u89d2\u4ece\u7b2c\u4e00\u7b2c\u4e8c\u4eba\u79f0\u8f6c\u4e3a\u7b2c\u4e09\u4eba\u79f0\u7684\u590d\u6742\u6027\uff0c\u81f4\u4f7f\u8bc4\u4ef7\u4e0d\u8db3\u3002\u4e3a\u66f4\u5168\u9762\u6709\u6548\u5730\u8bc4\u4ef7\u5bf9\u8bdd\u6458\u8981\uff0c\u8bbe\u8ba1\u9488\u5bf9\u5bf9\u8bdd\u7279\u6027\u7684\u7efc\u5408\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u5e76\u6784\u5efa\u76f8\u5173\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86DIAL-SUMMER\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\uff0c\u4ece\u5bf9\u8bdd\u5c42\u9762\u548c\u5355\u8f6e\u5c42\u9762\u4e24\u4e2a\u5c42\u7ea7\u7ec6\u81f4\u8bc4\u4f30\u5bf9\u8bdd\u6458\u8981\uff1b\u6784\u5efa\u4e86\u4eba\u5de5\u6807\u6ce8\u7ec6\u7c92\u5ea6\u9519\u8bef\u7684\u5bf9\u8bdd\u6458\u8981\u6570\u636e\u96c6\uff1b\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u8fdb\u884c\u7ecf\u9a8c\u5206\u6790\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u9519\u8bef\u68c0\u6d4b\u5b9e\u9a8c\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u7ec6\u7c92\u5ea6\u9519\u8bef\u6807\u6ce8\u7684\u5bf9\u8bdd\u6458\u8981\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5bf9\u8bdd\u4e2d\u6bb5\u5185\u5bb9\u6700\u6613\u88ab\u9057\u6f0f\uff0c\u6458\u8981\u672b\u7aef\u6613\u4ea7\u751f\u5916\u90e8\u5e7b\u89c9\uff0c\u9a8c\u8bc1\u4e86\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u7684\u5408\u7406\u6027\u548c\u6570\u636e\u96c6\u7684\u6311\u6218\u6027\uff0c\u5e76\u663e\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u9519\u8bef\u7684\u80fd\u529b\u4ecd\u6709\u9650\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86DIAL-SUMMER\u6846\u67b6\u53ca\u5176\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\uff0c\u6784\u5efa\u4e86\u5e26\u6709\u7ec6\u7c92\u5ea6\u9519\u8bef\u6807\u6ce8\u7684\u5bf9\u8bdd\u6458\u8981\u6570\u636e\u96c6\uff0c\u5b9e\u8bc1\u5206\u6790\u4e86\u6458\u8981\u4e2d\u7684\u5e38\u89c1\u9519\u8bef\u5206\u5e03\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u6a21\u578b\u7684\u4e0d\u8db3\u548c\u672a\u6765\u6539\u8fdb\u65b9\u5411\u3002"}}
{"id": "2602.08162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08162", "abs": "https://arxiv.org/abs/2602.08162", "authors": ["Ricardo Campos", "Jos\u00e9 Pedro Evans", "Jos\u00e9 Miguel Isidro", "Miguel Marques", "Lu\u00eds Filipe Cunha", "Al\u00edpio Jorge", "S\u00e9rgio Nunes", "Nuno Guimar\u00e3es"], "title": "NLP for Local Governance Meeting Records: A Focus Article on Tasks, Datasets, Metrics and Benchmark", "comment": null, "summary": "Local governance meeting records are official documents, in the form of minutes or transcripts, documenting how proposals, discussions, and procedural actions unfold during institutional meetings. While generally structured, these documents are often dense, bureaucratic, and highly heterogeneous across municipalities, exhibiting significant variation in language, terminology, structure, and overall organization. This heterogeneity makes them difficult for non-experts to interpret and challenging for intelligent automated systems to process, limiting public transparency and civic engagement. To address these challenges, computational methods can be employed to structure and interpret such complex documents. In particular, Natural Language Processing (NLP) offers well-established methods that can enhance the accessibility and interpretability of governmental records. In this focus article, we review foundational NLP tasks that support the structuring of local governance meeting documents. Specifically, we review three core tasks: document segmentation, domain-specific entity extraction and automatic text summarization, which are essential for navigating lengthy deliberations, identifying political actors and personal information, and generating concise representations of complex decision-making processes. In reviewing these tasks, we discuss methodological approaches, evaluation metrics, and publicly available resources, while highlighting domain-specific challenges such as data scarcity, privacy constraints, and source variability. By synthesizing existing work across these foundational tasks, this article provides a structured overview of how NLP can enhance the structuring and accessibility of local governance meeting records.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5728\u5730\u65b9\u6cbb\u7406\u4f1a\u8bae\u8bb0\u5f55\u7ed3\u6784\u5316\u4e2d\u7684\u5e94\u7528\uff0c\u91cd\u70b9\u8ba8\u8bba\u6587\u6863\u5206\u6bb5\u3001\u5b9e\u4f53\u63d0\u53d6\u548c\u81ea\u52a8\u6458\u8981\u4e09\u5927\u4efb\u52a1\uff0c\u89e3\u51b3\u7406\u89e3\u548c\u81ea\u52a8\u5904\u7406\u96be\u9898\uff0c\u52a9\u529b\u63d0\u5347\u516c\u5171\u900f\u660e\u5ea6\u548c\u5e02\u6c11\u53c2\u4e0e\u3002", "motivation": "\u5730\u65b9\u6cbb\u7406\u4f1a\u8bae\u8bb0\u5f55\u5c3d\u7ba1\u7ed3\u6784\u5316\uff0c\u4f46\u5185\u5bb9\u7e41\u590d\u4e14\u8de8\u533a\u57df\u5f02\u8d28\u6027\u9ad8\uff0c\u666e\u901a\u516c\u4f17\u96be\u4ee5\u7406\u89e3\uff0c\u81ea\u52a8\u7cfb\u7edf\u5904\u7406\u56f0\u96be\uff0c\u5f71\u54cd\u516c\u5171\u900f\u660e\u5ea6\u548c\u5e02\u6c11\u53c2\u4e0e\uff0c\u56e0\u6b64\u9700\u501f\u52a9\u8ba1\u7b97\u65b9\u6cd5\u63d0\u5347\u5176\u7ed3\u6784\u5316\u548c\u89e3\u8bfb\u80fd\u529b\u3002", "method": "\u6587\u7ae0\u901a\u8fc7\u56de\u987e\u6587\u6863\u5206\u6bb5\u3001\u9886\u57df\u7279\u5b9a\u5b9e\u4f53\u63d0\u53d6\u548c\u81ea\u52a8\u6587\u672c\u6458\u8981\u4e09\u9879\u6838\u5fc3\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\uff0c\u5206\u6790\u4e86\u76f8\u5173\u65b9\u6cd5\u3001\u8bc4\u4f30\u6307\u6807\u53ca\u8d44\u6e90\uff0c\u7ed3\u5408\u9886\u57df\u7279\u6709\u7684\u6311\u6218\u63a2\u8ba8\u4e86\u6280\u672f\u5e94\u7528\u3002", "result": "\u6587\u7ae0\u7cfb\u7edf\u603b\u7ed3\u4e86\u652f\u6301\u4f1a\u8bae\u8bb0\u5f55\u7ed3\u6784\u5316\u7684\u57fa\u7840\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\uff0c\u63d0\u51fa\u4e86\u5bf9\u5e94\u7684\u65b9\u6cd5\u4e0e\u6311\u6218\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u8df5\u53c2\u8003\u3002", "conclusion": "\u6587\u7ae0\u7efc\u8ff0\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u5728\u5730\u65b9\u6cbb\u7406\u4f1a\u8bae\u8bb0\u5f55\u7ed3\u6784\u5316\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5f3a\u8c03\u4e86\u8fd9\u4e9b\u6280\u672f\u5bf9\u4e8e\u63d0\u5347\u4f1a\u8bae\u8bb0\u5f55\u7684\u53ef\u8bbf\u95ee\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.08208", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.08208", "abs": "https://arxiv.org/abs/2602.08208", "authors": ["Cameron R. Jones", "Agnese Lombardi", "Kyle Mahowald", "Benjamin K. Bergen"], "title": "LLMs and people both learn to form conventions -- just not with each other", "comment": "10 pages, 4 figures", "summary": "Humans align to one another in conversation -- adopting shared conventions that ease communication. We test whether LLMs form the same kinds of conventions in a multimodal communication game. Both humans and LLMs display evidence of convention-formation (increasing the accuracy and consistency of their turns while decreasing their length) when communicating in same-type dyads (humans with humans, AI with AI). However, heterogenous human-AI pairs fail -- suggesting differences in communicative tendencies. In Experiment 2, we ask whether LLMs can be induced to behave more like human conversants, by prompting them to produce superficially humanlike behavior. While the length of their messages matches that of human pairs, accuracy and lexical overlap in human-LLM pairs continues to lag behind that of both human-human and AI-AI pairs. These results suggest that conversational alignment requires more than just the ability to mimic previous interactions, but also shared interpretative biases toward the meanings that are conveyed.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u867d\u7136LLMs\u548c\u4eba\u7c7b\u5206\u522b\u80fd\u5f62\u6210\u4ea4\u6d41\u7ea6\u5b9a\uff0c\u4f46\u4eba\u673a\u5bf9\u8bdd\u672a\u80fd\u5b9e\u73b0\u6709\u6548\u5bf9\u9f50\uff0c\u63d0\u793a\u4ec5\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u4e0d\u8db3\u4ee5\u4fc3\u6210\u771f\u6b63\u7684\u4f1a\u8bdd\u7406\u89e3\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u5728\u591a\u6a21\u6001\u4ea4\u6d41\u4e2d\u5f62\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u4ea4\u6d41\u7ea6\u5b9a\uff0c\u4ee5\u63d0\u9ad8\u4eba\u673a\u5bf9\u8bdd\u7684\u81ea\u7136\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u591a\u6a21\u6001\u4ea4\u6d41\u6e38\u620f\uff0c\u5206\u522b\u6d4b\u8bd5\u4eba\u7c7b-\u4eba\u7c7b\u3001AI-AI\u53ca\u4eba\u7c7b-AI\u5bf9\u8bdd\u4e2d\u7684\u4ea4\u6d41\u8868\u73b0\uff0c\u7b2c\u4e8c\u4e2a\u5b9e\u9a8c\u901a\u8fc7\u63d0\u793a\u4fc3\u4f7fLLMs\u751f\u6210\u7c7b\u4f3c\u4eba\u7c7b\u7684\u884c\u4e3a\uff0c\u6bd4\u8f83\u5176\u4fe1\u606f\u957f\u5ea6\u3001\u51c6\u786e\u7387\u548c\u8bcd\u6c47\u91cd\u53e0\u3002", "result": "\u540c\u7c7b\u578b\u5bf9\u8bdd\u4e2d\u53cc\u65b9\u90fd\u8868\u73b0\u51fa\u7ea6\u5b9a\u5f62\u6210\uff0c\u8868\u73b0\u4e3a\u53d1\u8a00\u51c6\u786e\u7387\u548c\u4e00\u81f4\u6027\u63d0\u5347\u4e14\u53d1\u8a00\u957f\u5ea6\u7f29\u77ed\uff1b\u5f02\u8d28\u5bf9\u8bdd\u4e2d\u4eba\u673a\u5bf9\u8bdd\u51c6\u786e\u7387\u548c\u8bcd\u6c47\u91cd\u53e0\u7387\u4f4e\u4e8e\u5176\u4ed6\u7ec4\u5408\u3002\u63d0\u793a\u4ec5\u6539\u5584\u4e86\u53d1\u8a00\u957f\u5ea6\u4f46\u672a\u63d0\u9ad8\u51c6\u786e\u7387\u548c\u8bcd\u6c47\u91cd\u53e0\u3002", "conclusion": "\u4eba\u7c7b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u540c\u7c7b\u578b\u5bf9\u8bdd\u4e2d\uff08\u4eba\u7c7b-\u4eba\u7c7b\uff0cAI-AI\uff09\u90fd\u80fd\u5f62\u6210\u4ea4\u6d41\u7ea6\u5b9a\uff0c\u4f46\u5f02\u8d28\u4eba\u7c7b-AI\u5bf9\u8bdd\u672a\u80fd\u6210\u529f\uff0c\u8868\u660e\u4ea4\u6d41\u503e\u5411\u5b58\u5728\u5dee\u5f02\u3002\u4ec5\u6a21\u4eff\u4eba\u7c7b\u884c\u4e3a\u65e0\u6cd5\u5b9e\u73b0\u6709\u6548\u7684\u4f1a\u8bdd\u5bf9\u9f50\uff0c\u9700\u8981\u5171\u4eab\u7684\u89e3\u91ca\u504f\u597d\u3002"}}
{"id": "2602.08220", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08220", "abs": "https://arxiv.org/abs/2602.08220", "authors": ["Boyi Zeng", "Yiqin Hao", "He Li", "Shixiang Song", "Feichen Song", "Zitong Wang", "Siyuan Huang", "Yi Xu", "ZiWei He", "Xinbing Wang", "Zhouhan Lin"], "title": "Pretraining with Token-Level Adaptive Latent Chain-of-Thought", "comment": null, "summary": "Scaling large language models by increasing parameters and training data is increasingly constrained by limited high-quality corpora and rising communication costs. This work explores an alternative axis: increasing per-token computation without expanding parameters, by internalizing latent Chain-of-Thought (CoT) into pretraining. We propose Pretraining with Token-Level Adaptive Latent CoT (adaptive latent CoT), where the model generates a variable-length latent CoT trajectory before emitting each token -- allocating longer trajectories to difficult tokens and shorter (or even zero) trajectories to easy ones. Importantly, this behavior emerges naturally from one-stage pretraining on general text and reduces computation in both training and inference via token-wise adaptive halting. Experiments with Llama architectures show that adaptive latent CoT consistently improves language modeling perplexity and broad downstream accuracy, even with fewer training FLOPs than prior recurrent baselines.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5f15\u5165token\u7ea7\u81ea\u9002\u5e94\u6f5c\u5728\u601d\u7ef4\u94fe\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u89e3\u51b3\u4e86\u6269\u5c55\u6027\u53d7\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u53d7\u5230\u9ad8\u8d28\u91cf\u8bed\u6599\u9650\u5236\u548c\u901a\u4fe1\u6210\u672c\u4e0a\u5347\u7684\u7ea6\u675f\uff0c\u672c\u6587\u63a2\u7d22\u901a\u8fc7\u589e\u52a0\u6bcftoken\u8ba1\u7b97\u800c\u975e\u6269\u589e\u53c2\u6570\u89c4\u6a21\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u5f15\u5165\u4e86Token-Level Adaptive Latent CoT\u65b9\u6cd5\uff0c\u6a21\u578b\u5728\u53d1\u51fa\u6bcf\u4e2atoken\u4e4b\u524d\u751f\u6210\u53ef\u53d8\u957f\u5ea6\u7684\u6f5c\u5728\u601d\u7ef4\u8f68\u8ff9\uff0c\u6839\u636etoken\u96be\u5ea6\u81ea\u9002\u5e94\u8c03\u6574\u8f68\u8ff9\u957f\u5ea6\uff0c\u4e14\u901a\u8fc7token-wise adaptive halting\u673a\u5236\u51cf\u5c11\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728Llama\u67b6\u6784\u4e0a\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u6216\u964d\u4f4e\u8bad\u7ec3\u8ba1\u7b97\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u5efa\u6a21\u7684\u56f0\u60d1\u5ea6\u548c\u4e0b\u6e38\u4efb\u52a1\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Token-Level Adaptive Latent Chain-of-Thought\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u4e2d\u81ea\u9002\u5e94\u751f\u6210\u4e0d\u540c\u957f\u5ea6\u7684\u6f5c\u5728\u601d\u7ef4\u8f68\u8ff9\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2602.08221", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08221", "abs": "https://arxiv.org/abs/2602.08221", "authors": ["Xuhua Ma", "Richong Zhang", "Zhijie Nie"], "title": "CoRect: Context-Aware Logit Contrast for Hidden State Rectification to Resolve Knowledge Conflicts", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) often struggles with knowledge conflicts, where model-internal parametric knowledge overrides retrieved evidence, leading to unfaithful outputs. Existing approaches are often limited, relying either on superficial decoding adjustments or weight editing that necessitates ground-truth targets. Through layer-wise analysis, we attribute this failure to a parametric suppression phenomenon: specifically, in deep layers, certain FFN layers overwrite context-sensitive representations with memorized priors. To address this, we propose CoRect (Context-Aware Logit Contrast for Hidden State Rectification). By contrasting logits from contextualized and non-contextualized forward passes, CoRect identifies layers that exhibit high parametric bias without requiring ground-truth labels. It then rectifies the hidden states to preserve evidence-grounded information. Across question answering (QA) and summarization benchmarks, CoRect consistently improves faithfulness and reduces hallucinations compared to strong baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoRect\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9690\u72b6\u6001\u7684\u5bf9\u6bd4\u6027\u77eb\u6b63\uff0c\u89e3\u51b3\u4e86RAG\u6a21\u578b\u4e2d\u6df1\u5c42\u53c2\u6570\u6291\u5236\u5bfc\u81f4\u7684\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u751f\u6210\u6587\u672c\u7684\u771f\u5b9e\u5ea6\u3002", "motivation": "RAG\u6a21\u578b\u5b58\u5728\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u6a21\u578b\u5185\u90e8\u7684\u53c2\u6570\u5316\u77e5\u8bc6\u5f80\u5f80\u8986\u76d6\u5df2\u68c0\u7d22\u7684\u5916\u90e8\u8bc1\u636e\uff0c\u5bfc\u81f4\u8f93\u51fa\u5185\u5bb9\u4e0d\u771f\u5b9e\uff0c\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u8868\u9762\u89e3\u7801\u8c03\u6574\u6216\u9700\u8981\u771f\u5b9e\u6807\u7b7e\u7684\u6743\u91cd\u7f16\u8f91\u3002", "method": "\u901a\u8fc7\u5bf9\u4e0a\u4e0b\u6587\u5316\u548c\u975e\u4e0a\u4e0b\u6587\u5316\u7684\u524d\u5411\u4f20\u64ad\u7684logits\u8fdb\u884c\u5bf9\u6bd4\uff0cCoRect\u65b9\u6cd5\u81ea\u52a8\u8bc6\u522b\u51fa\u5b58\u5728\u53c2\u6570\u538b\u5236\u73b0\u8c61\u7684\u5c42\uff0c\u5e76\u6821\u6b63\u5176\u9690\u85cf\u72b6\u6001\uff0c\u4ece\u800c\u9632\u6b62\u9884\u8bad\u7ec3\u77e5\u8bc6\u8986\u76d6\u68c0\u7d22\u8bc1\u636e\u3002", "result": "\u5728\u95ee\u7b54\u548c\u6587\u672c\u6458\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoRect\u8868\u73b0\u51fa\u6bd4\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\u66f4\u597d\u7684\u5fe0\u5b9e\u5ea6\u548c\u66f4\u5c11\u7684\u5e7b\u89c9\uff0c\u8bc1\u660e\u5176\u6709\u6548\u6027\u3002", "conclusion": "CoRect\u65b9\u6cd5\u901a\u8fc7\u8bc6\u522b\u5e76\u6821\u6b63\u6df1\u5c42\u7f51\u7edc\u4e2d\u53c2\u6570\u504f\u7f6e\u660e\u663e\u7684\u5c42\uff0c\u6210\u529f\u63d0\u5347\u4e86RAG\u6a21\u578b\u7684\u8f93\u51fa\u5fe0\u5b9e\u5ea6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u5e7b\u89c9\u73b0\u8c61\u3002"}}
{"id": "2602.08235", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08235", "abs": "https://arxiv.org/abs/2602.08235", "authors": ["Jaylen Jones", "Zhehao Zhang", "Yuting Ning", "Eric Fosler-Lussier", "Pierre-Luc St-Charles", "Yoshua Bengio", "Dawn Song", "Yu Su", "Huan Sun"], "title": "When Benign Inputs Lead to Severe Harms: Eliciting Unsafe Unintended Behaviors of Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/AutoElicit/", "summary": "Although computer-use agents (CUAs) hold significant potential to automate increasingly complex OS workflows, they can demonstrate unsafe unintended behaviors that deviate from expected outcomes even under benign input contexts. However, exploration of this risk remains largely anecdotal, lacking concrete characterization and automated methods to proactively surface long-tail unintended behaviors under realistic CUA scenarios. To fill this gap, we introduce the first conceptual and methodological framework for unintended CUA behaviors, by defining their key characteristics, automatically eliciting them, and analyzing how they arise from benign inputs. We propose AutoElicit: an agentic framework that iteratively perturbs benign instructions using CUA execution feedback, and elicits severe harms while keeping perturbations realistic and benign. Using AutoElicit, we surface hundreds of harmful unintended behaviors from state-of-the-art CUAs such as Claude 4.5 Haiku and Opus. We further evaluate the transferability of human-verified successful perturbations, identifying persistent susceptibility to unintended behaviors across various other frontier CUAs. This work establishes a foundation for systematically analyzing unintended behaviors in realistic computer-use settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AutoElicit\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u8bc6\u522b\u548c\u5206\u6790\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\u4e2d\u7684\u672a\u9884\u671f\u6709\u5bb3\u884c\u4e3a\uff0c\u4e3a\u63d0\u5347CUA\u5b89\u5168\u6027\u5960\u5b9a\u4e86\u65b9\u6cd5\u57fa\u7840\u3002", "motivation": "\u5c3d\u7ba1CUAs\u6709\u6f5c\u529b\u81ea\u52a8\u5316\u590d\u6742\u7684\u64cd\u4f5c\u7cfb\u7edf\u5de5\u4f5c\u6d41\uff0c\u4f46\u5176\u672a\u9884\u671f\u7684\u884c\u4e3a\u53ef\u80fd\u5e26\u6765\u5b89\u5168\u98ce\u9669\uff0c\u73b0\u6709\u7814\u7a76\u591a\u4e3a\u96f6\u6563\u6848\u4f8b\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u523b\u753b\u548c\u4e3b\u52a8\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86AutoElicit\u6846\u67b6\uff0c\u901a\u8fc7\u8fed\u4ee3\u5730\u5229\u7528CUA\u6267\u884c\u53cd\u9988\uff0c\u6270\u52a8\u6b63\u5e38\u6307\u4ee4\u4ee5\u81ea\u52a8\u6fc0\u53d1\u4e25\u91cd\u7684\u672a\u9884\u671f\u6709\u5bb3\u884c\u4e3a\uff0c\u540c\u65f6\u4fdd\u8bc1\u6270\u52a8\u7684\u73b0\u5b9e\u6027\u548c\u65e0\u5bb3\u6027\u3002", "result": "\u5229\u7528AutoElicit\u4ece\u524d\u6cbfCUAs\uff08\u5982Claude 4.5 Haiku\u548cOpus\uff09\u4e2d\u53d1\u73b0\u6570\u767e\u4e2a\u6709\u5bb3\u7684\u672a\u9884\u671f\u884c\u4e3a\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6270\u52a8\u5bf9\u5176\u4ed6CUAs\u7684\u8f6c\u79fb\u80fd\u529b\uff0c\u8bf4\u660e\u95ee\u9898\u5177\u6709\u666e\u904d\u6027\u3002", "conclusion": "\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5316\u5730\u5b9a\u4e49\u548c\u81ea\u52a8\u5f15\u53d1\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u4e2d\u672a\u9884\u671f\u884c\u4e3a\u7684\u5173\u952e\u7279\u5f81\uff0c\u63ed\u793a\u4e86\u8fd9\u4e9b\u884c\u4e3a\u5728\u5b9e\u9645\u4f7f\u7528\u4e2d\u666e\u904d\u5b58\u5728\u4e14\u5177\u6709\u9ad8\u5ea6\u8f6c\u79fb\u6027\u3002"}}
{"id": "2602.08237", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08237", "abs": "https://arxiv.org/abs/2602.08237", "authors": ["Yao Xiao", "Lei Wang", "Yue Deng", "Guanzheng Chen", "Ziqi Jin", "Jung-jae Kim", "Xiaoli Li", "Roy Ka-wei Lee", "Lidong Bing"], "title": "Document Reconstruction Unlocks Scalable Long-Context RLVR", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards~(RLVR) has become a prominent paradigm to enhance the capabilities (i.e.\\ long-context) of Large Language Models~(LLMs). However, it often relies on gold-standard answers or explicit evaluation rubrics provided by powerful teacher models or human experts, which are costly and time-consuming. In this work, we investigate unsupervised approaches to enhance the long-context capabilities of LLMs, eliminating the need for heavy human annotations or teacher models' supervision. Specifically, we first replace a few paragraphs with special placeholders in a long document. LLMs are trained through reinforcement learning to reconstruct the document by correctly identifying and sequencing missing paragraphs from a set of candidate options. This training paradigm enables the model to capture global narrative coherence, significantly boosting long-context performance. We validate the effectiveness of our method on two widely used benchmarks, RULER and LongBench~v2. While acquiring noticeable gains on RULER, it can also achieve a reasonable improvement on LongBench~v2 without any manually curated long-context QA data. Furthermore, we conduct extensive ablation studies to analyze the impact of reward design, data curation strategies, training schemes, and data scaling effects on model performance. We publicly release our code, data, and models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u76d1\u7763\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u8ba9\u6a21\u578b\u91cd\u5efa\u6587\u6863\u7f3a\u5931\u6bb5\u843d\u6765\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u826f\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u6807\u6ce8\u6216\u5f3a\u6559\u5e08\u6a21\u578b\uff0c\u6210\u672c\u9ad8\u3001\u8017\u65f6\u957f\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u65e0\u76d1\u7763\u65b9\u6cd5\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\uff0c\u964d\u4f4e\u4f9d\u8d56\u6602\u8d35\u7684\u76d1\u7763\u8d44\u6e90\u3002", "method": "\u901a\u8fc7\u5728\u957f\u6587\u6863\u4e2d\u7528\u7279\u6b8a\u5360\u4f4d\u7b26\u66ff\u6362\u90e8\u5206\u6bb5\u843d\uff0c\u8bad\u7ec3\u6a21\u578b\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4ece\u5019\u9009\u6bb5\u843d\u4e2d\u8bc6\u522b\u548c\u6392\u5e8f\u7f3a\u5931\u6bb5\u843d\uff0c\u91cd\u5efa\u6587\u6863\u4ee5\u589e\u5f3a\u5168\u5c40\u53d9\u4e8b\u8fde\u8d2f\u6027\u3002", "result": "\u5728RULER\u57fa\u51c6\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5728LongBench v2\u4e0a\u4e5f\u83b7\u5f97\u5408\u7406\u7684\u6539\u5584\uff0c\u540c\u65f6\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u5206\u6790\u4e86\u5956\u52b1\u8bbe\u8ba1\u3001\u6570\u636e\u7b56\u7565\u3001\u8bad\u7ec3\u65b9\u6848\u548c\u6570\u636e\u89c4\u6a21\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u65e0\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u5efa\u7f3a\u5931\u6bb5\u843d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\uff0c\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u6216\u6559\u5e08\u6a21\u578b\u76d1\u7763\uff0c\u5728RULER\u548cLongBench v2\u4e24\u4e2a\u57fa\u51c6\u4e0a\u8868\u73b0\u51fa\u660e\u663e\u548c\u5408\u7406\u7684\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.08238", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08238", "abs": "https://arxiv.org/abs/2602.08238", "authors": ["Nathaniel Imel", "Noga Zaslavasky"], "title": "On convexity and efficiency in semantic systems", "comment": null, "summary": "There are two widely held characterizations of human semantic category systems: (1) they form convex partitions of conceptual spaces, and (2) they are efficient for communication. While prior work observed that convexity and efficiency co-occur in color naming, the analytical relation between them and why they co-occur have not been well understood. We address this gap by combining analytical and empirical analyses that build on the Information Bottleneck (IB) framework for semantic efficiency. First, we show that convexity and efficiency are distinct in the sense that neither entails the other: there are convex systems which are inefficient, and optimally-efficient systems that are non-convex. Crucially, however, the IB-optimal systems are mostly convex in the domain of color naming, explaining the main empirical basis for the convexity approach. Second, we show that efficiency is a stronger predictor for discriminating attested color naming systems from hypothetical variants, with convexity adding negligible improvement on top of that. Finally, we discuss a range of empirical phenomena that convexity cannot account for but efficiency can. Taken together, our work suggests that while convexity and efficiency can yield similar structural observations, they are fundamentally distinct, with efficiency providing a more comprehensive account of semantic typology.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u74f6\u9888\u6846\u67b6\u5206\u6790\u51f8\u6027\u548c\u6548\u7387\u5728\u8bed\u4e49\u8303\u7574\u7cfb\u7edf\u4e2d\u7684\u5173\u7cfb\uff0c\u53d1\u73b0\u4e24\u8005\u672c\u8d28\u4e0d\u540c\uff0c\u6548\u7387\u66f4\u80fd\u89e3\u91ca\u989c\u8272\u547d\u540d\u7b49\u8bed\u4e49\u7cfb\u7edf\u7684\u7ed3\u6784\u548c\u5206\u7c7b\u73b0\u8c61\u3002", "motivation": "\u4eba\u7c7b\u8bed\u4e49\u8303\u7574\u7cfb\u7edf\u662f\u5426\u5177\u6709\u51f8\u6027\u53ca\u5176\u6548\u7387\u5982\u4f55\u957f\u671f\u88ab\u8ba8\u8bba\uff0c\u4f46\u4e24\u8005\u7684\u5173\u7cfb\u53ca\u5171\u73b0\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u4fe1\u606f\u74f6\u9888\uff08IB\uff09\u6846\u67b6\uff0c\u91c7\u7528\u5206\u6790\u548c\u5b9e\u8bc1\u65b9\u6cd5\uff0c\u7814\u7a76\u51f8\u6027\u4e0e\u6548\u7387\u4e4b\u95f4\u7684\u5173\u7cfb\u5e76\u68c0\u9a8c\u5176\u5728\u989c\u8272\u547d\u540d\u9886\u57df\u7684\u8868\u73b0\u3002", "result": "IB\u6700\u4f18\u7cfb\u7edf\u5728\u989c\u8272\u547d\u540d\u9886\u57df\u591a\u4e3a\u51f8\u6027\uff0c\u4f46\u51f8\u6027\u4e0e\u6548\u7387\u72ec\u7acb\uff0c\u6548\u7387\u66f4\u5f3a\u9884\u6d4b\u5b9e\u9645\u989c\u8272\u547d\u540d\u7cfb\u7edf\uff0c\u51f8\u6027\u4ec5\u5e26\u6765\u7ec6\u5fae\u6539\u8fdb\uff0c\u5e76\u4e14\u6548\u7387\u80fd\u89e3\u91ca\u66f4\u591a\u51f8\u6027\u65e0\u6cd5\u89e3\u91ca\u7684\u73b0\u8c61\u3002", "conclusion": "\u51f8\u6027\u548c\u6548\u7387\u662f\u4e24\u4e2a\u672c\u8d28\u4e0a\u4e0d\u540c\u7684\u8bed\u4e49\u8303\u7574\u7cfb\u7edf\u7279\u5f81\uff0c\u51f8\u6027\u5e76\u4e0d\u5fc5\u7136\u5bfc\u81f4\u6548\u7387\uff0c\u6548\u7387\u66f4\u80fd\u5168\u9762\u89e3\u91ca\u8bed\u4e49\u4f53\u7cfb\u7684\u7ed3\u6784\u7279\u5f81\u3002"}}
{"id": "2602.08252", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08252", "abs": "https://arxiv.org/abs/2602.08252", "authors": ["Devin R. Wright", "Justin E. Lane", "F. LeRon Shults"], "title": "Language Predicts Identity Fusion Across Cultures and Reveals Divergent Pathways to Violence", "comment": "Initial submitted version", "summary": "In light of increasing polarization and political violence, understanding the psychological roots of extremism is increasingly important. Prior research shows that identity fusion predicts willingness to engage in extreme acts. We evaluate the Cognitive Linguistic Identity Fusion Score, a method that uses cognitive linguistic patterns, LLMs, and implicit metaphor to measure fusion from language. Across datasets from the United Kingdom and Singapore, this approach outperforms existing methods in predicting validated fusion scores. Applied to extremist manifestos, two distinct high-fusion pathways to violence emerge: ideologues tend to frame themselves in terms of group, forming kinship bonds; whereas grievance-driven individuals frame the group in terms of their personal identity. These results refine theories of identity fusion and provide a scalable tool aiding fusion research and extremism detection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bed\u8a00\u7684\u8eab\u4efd\u878d\u5408\u8bc4\u5206\u65b9\u6cd5\uff0c\u80fd\u66f4\u51c6\u786e\u9884\u6d4b\u6781\u7aef\u4e3b\u4e49\u503e\u5411\uff0c\u63ed\u793a\u4e24\u79cd\u4e0d\u540c\u7684\u66b4\u529b\u8def\u5f84\uff0c\u4fc3\u8fdb\u6781\u7aef\u4e3b\u4e49\u5fc3\u7406\u673a\u5236\u7814\u7a76\u4e0e\u68c0\u6d4b\u3002", "motivation": "\u968f\u7740\u6781\u7aef\u4e3b\u4e49\u548c\u653f\u6cbb\u66b4\u529b\u7684\u52a0\u5267\uff0c\u7406\u89e3\u5176\u5fc3\u7406\u6839\u6e90\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u5c24\u5176\u662f\u8eab\u4efd\u878d\u5408\u5bf9\u6781\u7aef\u884c\u4e3a\u7684\u9884\u6d4b\u4f5c\u7528\u3002", "method": "\u91c7\u7528\u8ba4\u77e5\u8bed\u8a00\u5b66\u6a21\u5f0f\u3001\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u9690\u55bb\u5206\u6790\uff0c\u901a\u8fc7\u8bed\u8a00\u6587\u672c\u6d4b\u91cf\u8eab\u4efd\u878d\u5408\u7a0b\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u82f1\u56fd\u548c\u65b0\u52a0\u5761\u7684\u6570\u636e\u96c6\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u6781\u7aef\u4e3b\u4e49\u5ba3\u8a00\u6587\u672c\u4e2d\u8bc6\u522b\u51fa\u4e24\u7c7b\u9ad8\u878d\u5408\u7fa4\u4f53\uff0c\u4e30\u5bcc\u4e86\u8eab\u4efd\u878d\u5408\u7406\u8bba\u5e76\u4e3a\u76f8\u5173\u7814\u7a76\u548c\u6781\u7aef\u4e3b\u4e49\u68c0\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u5de5\u5177\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u8ba4\u77e5\u8bed\u8a00\u5b66\u8eab\u4efd\u878d\u5408\u8bc4\u5206\uff08CLIFS\uff09\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u9884\u6d4b\u8eab\u4efd\u878d\u5408\u7a0b\u5ea6\uff0c\u5e76\u63ed\u793a\u4e86\u6781\u7aef\u4e3b\u4e49\u4e2d\u4e24\u79cd\u4e0d\u540c\u7684\u9ad8\u878d\u5408\u66b4\u529b\u8def\u5f84\uff0c\u5373\u610f\u8bc6\u5f62\u6001\u8005\u548c\u56e0\u4e0d\u6ee1\u9a71\u52a8\u8005\u7684\u4e0d\u540c\u8ba4\u540c\u6846\u67b6\u3002"}}
{"id": "2602.08274", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08274", "abs": "https://arxiv.org/abs/2602.08274", "authors": ["Jan Philip Wahle"], "title": "Language Modeling and Understanding Through Paraphrase Generation and Detection", "comment": "PhD dissertation, University of G\u00f6ttingen Germany, 2025. 182 pages", "summary": "Language enables humans to share knowledge, reason about the world, and pass on strategies for survival and innovation across generations. At the heart of this process is not just the ability to communicate but also the remarkable flexibility in how we can express ourselves. We can express the same thoughts in virtually infinite ways using different words and structures - this ability to rephrase and reformulate expressions is known as paraphrase. Modeling paraphrases is a keystone to meaning in computational language models; being able to construct different variations of texts that convey the same meaning or not shows strong abilities of semantic understanding. If computational language models are to represent meaning, they must understand and control the different aspects that construct the same meaning as opposed to different meanings at a fine granularity. Yet most existing approaches reduce paraphrasing to a binary decision between two texts or to producing a single rewrite of a source, obscuring which linguistic factors are responsible for meaning preservation. In this thesis, I propose that decomposing paraphrases into their constituent linguistic aspects (paraphrase types) offers a more fine-grained and cognitively grounded view of semantic equivalence. I show that even advanced machine learning models struggle with this task. Yet, when explicitly trained on paraphrase types, models achieve stronger performance on related paraphrase tasks and downstream applications. For example, in plagiarism detection, language models trained on paraphrase types surpass human baselines: 89.6% accuracy compared to 78.4% for plagiarism cases from Wikipedia, and 66.5% compared to 55.7% for plagiarism of scientific papers from arXiv. In identifying duplicate questions on Quora, models trained with paraphrase types improve over models trained on binary pairs. Furthermore, I demonstrate that...", "AI": {"tldr": "\u901a\u8fc7\u5c06\u91ca\u4e49\u7ec6\u5316\u4e3a\u591a\u4e2a\u8bed\u8a00\u5b66\u7ef4\u5ea6\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u548c\u5904\u7406\u76f8\u540c\u8bed\u4e49\u4e0d\u540c\u8868\u8fbe\u7684\u80fd\u529b\uff0c\u8fdb\u800c\u63d0\u9ad8\u4e86\u6284\u88ad\u68c0\u6d4b\u548c\u91cd\u590d\u95ee\u9898\u8bc6\u522b\u7b49\u4efb\u52a1\u7684\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u591a\u5c06\u91ca\u4e49\u7b80\u5316\u4e3a\u4e8c\u5143\u5224\u65ad\u6216\u5355\u4e00\u6539\u5199\uff0c\u63a9\u76d6\u4e86\u54ea\u4e9b\u8bed\u8a00\u56e0\u7d20\u4fdd\u969c\u8bed\u4e49\u4e0d\u53d8\uff0c\u96be\u4ee5\u4f53\u73b0\u6a21\u578b\u5bf9\u7ec6\u7c92\u5ea6\u8bed\u4e49\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u5206\u89e3\u91ca\u4e49\u4e3a\u591a\u4e2a\u8bed\u8a00\u5b66\u7ec4\u6210\u90e8\u5206\uff08\u91ca\u4e49\u7c7b\u578b\uff09\uff0c\u5e76\u8bad\u7ec3\u6a21\u578b\u8bc6\u522b\u8fd9\u4e9b\u7c7b\u578b\uff0c\u4ece\u800c\u6539\u8fdb\u6a21\u578b\u5bf9\u91ca\u4e49\u7684\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u3002", "result": "\u8bad\u7ec3\u4e86\u57fa\u4e8e\u91ca\u4e49\u7c7b\u578b\u7684\u6a21\u578b\uff0c\u5728\u6284\u88ad\u68c0\u6d4b\uff08\u8d85\u8fc7\u4eba\u7c7b\u57fa\u7ebf\u51c6\u786e\u7387\uff09\u548c\u95ee\u7b54\u91cd\u590d\u68c0\u6d4b\u7b49\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u4e86\u4f18\u5f02\u8868\u73b0\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u4e8c\u5143\u5206\u7c7b\u6a21\u578b\u3002", "conclusion": "\u5c06\u91ca\u4e49\uff08paraphrase\uff09\u5206\u89e3\u4e3a\u4e0d\u540c\u7684\u8bed\u8a00\u5b66\u65b9\u9762\uff0c\u53ef\u4ee5\u66f4\u7ec6\u81f4\u548c\u8ba4\u77e5\u57fa\u7840\u5730\u7406\u89e3\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u548c\u5e94\u7528\u8868\u73b0\u3002"}}
{"id": "2602.08281", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08281", "abs": "https://arxiv.org/abs/2602.08281", "authors": ["Zhilin Wang", "Yafu Li", "Shunkai Zhang", "Zhi Wang", "Haoran Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "New Skills or Sharper Primitives? A Probabilistic Perspective on the Emergence of Reasoning in RLVR", "comment": "15 pages", "summary": "Whether Reinforcement Learning with Verifiable Rewards (RLVR) endows Large Language Models (LLMs) with new capabilities or merely elicits latent traces remains a central debate. In this work, we align with the former view, proposing a probabilistic framework where capability is defined by instance-level solvability. We hypothesize that the emergence of complex reasoning can be driven by sharpening atomic step probabilities, which enables models to overcome the exponential decay of success rates inherent in multi-step reasoning chains. Utilizing the Algebrarium framework, we train models exclusively on single-step operations and evaluate their performance on unseen multi-step tasks. Our empirical results confirm that: (1) RLVR incentivizes the exploration of previously inaccessible solution paths by amplifying the model's existing skills; (2) composite performance is strictly governed by the joint probability of atomic steps, evidenced by high Pearson correlation coefficients ($\u03c1\\in [0.69, 0.96]$); and (3) RLVR, acting as a global optimizer, can cause specific skills to be sacrificed to maximize aggregate reward. Our work offers a novel explanation for emergent abilities in RLVR, suggesting that the iterative optimization of solvable problems enables models to develop the capabilities to tackle previously unsolvable scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u6982\u7387\u6846\u67b6\u89e3\u91ca\u5f3a\u5316\u5b66\u4e60\u53ef\u9a8c\u8bc1\u5956\u52b1\u5982\u4f55\u901a\u8fc7\u63d0\u5347\u6b65\u9aa4\u6982\u7387\u4fc3\u4f7f\u5927\u6a21\u578b\u6d8c\u73b0\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u591a\u6b65\u9aa4\u4efb\u52a1\u89e3\u9898\u6027\u80fd\u3002", "motivation": "\u63a2\u8ba8\u5f3a\u5316\u5b66\u4e60\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u662f\u5426\u8d4b\u4e88\u5927\u8bed\u8a00\u6a21\u578b\u65b0\u80fd\u529b\uff0c\u5e76\u89e3\u91ca\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u6d8c\u73b0\u673a\u5236\u3002", "method": "\u5efa\u7acb\u57fa\u4e8e\u6982\u7387\u7684\u80fd\u529b\u5b9a\u4e49\u6846\u67b6\uff0c\u4ee5\u5b9e\u4f8b\u7ea7\u53ef\u89e3\u6027\u4e3a\u6838\u5fc3\uff0c\u5229\u7528Algebrarium\u6846\u67b6\u4ec5\u8bad\u7ec3\u5355\u6b65\u64cd\u4f5c\uff0c\u6d4b\u8bd5\u591a\u6b65\u4efb\u52a1\u8868\u73b0\uff0c\u5206\u6790\u5956\u52b1\u673a\u5236\u5bf9\u6a21\u578b\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRLVR\u6fc0\u52b1\u6a21\u578b\u63a2\u7d22\u65b0\u89e3\u6cd5\u8def\u5f84\uff0c\u590d\u5408\u4efb\u52a1\u8868\u73b0\u7531\u591a\u4e2a\u539f\u5b50\u6b65\u9aa4\u8054\u5408\u6982\u7387\u51b3\u5b9a\uff0c\u4e14RLVR\u53ef\u4f5c\u4e3a\u5168\u5c40\u4f18\u5316\u5668\uff0c\u5bfc\u81f4\u90e8\u5206\u6280\u80fd\u6743\u8861\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u53ef\u9a8c\u8bc1\u5956\u52b1\uff08RLVR\uff09\u901a\u8fc7\u63d0\u5347\u539f\u5b50\u6b65\u9aa4\u6982\u7387\u4fc3\u8fdb\u4e86\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u51fa\u73b0\uff0c\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u591a\u6b65\u9aa4\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u5e76\u53ef\u80fd\u727a\u7272\u90e8\u5206\u5177\u4f53\u6280\u80fd\u4ee5\u6700\u5927\u5316\u603b\u4f53\u5956\u52b1\u3002"}}
{"id": "2602.08289", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08289", "abs": "https://arxiv.org/abs/2602.08289", "authors": ["Binglin Wu", "Xianneng Li"], "title": "Knowledge Augmented Entity and Relation Extraction for Legal Documents with Hypergraph Neural Network", "comment": null, "summary": "With the continuous progress of digitization in Chinese judicial institutions, a substantial amount of electronic legal document information has been accumulated. To unlock its potential value, entity and relation extraction for legal documents has emerged as a crucial task. However, existing methods often lack domain-specific knowledge and fail to account for the unique characteristics of the judicial domain. In this paper, we propose an entity and relation extraction algorithm based on hypergraph neural network (Legal-KAHRE) for drug-related judgment documents. Firstly, we design a candidate span generator based on neighbor-oriented packing strategy and biaffine mechanism, which identifies spans likely to contain entities. Secondly, we construct a legal dictionary with judicial domain knowledge and integrate it into text encoding representation using multi-head attention. Additionally, we incorporate domain-specific cases like joint crimes and combined punishment for multiple crimes into the hypergraph structure design. Finally, we employ a hypergraph neural network for higher-order inference via message passing. Experimental results on the CAIL2022 information extraction dataset demonstrate that our method significantly outperforms existing baseline models.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u53f8\u6cd5\u9886\u57df\u6587\u4e66\uff0c\u63d0\u51fa\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5\uff0c\u878d\u5408\u9886\u57df\u77e5\u8bc6\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u53f8\u6cd5\u673a\u6784\u6570\u5b57\u5316\u8fdb\u7a0b\u5e26\u6765\u4e86\u5927\u91cf\u7535\u5b50\u6cd5\u5f8b\u6587\u6863\uff0c\u4f46\u73b0\u6709\u5b9e\u4f53\u4e0e\u5173\u7cfb\u62bd\u53d6\u65b9\u6cd5\u7f3a\u4e4f\u53f8\u6cd5\u9886\u57df\u7279\u6709\u7684\u77e5\u8bc6\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u836f\u54c1\u76f8\u5173\u5224\u51b3\u6587\u4e66\u5b9e\u4f53\u5173\u7cfb\u62bd\u53d6\u7b97\u6cd5\uff08Legal-KAHRE\uff09\uff0c\u5305\u62ec\u5019\u9009\u5b9e\u4f53\u751f\u6210\u3001\u53f8\u6cd5\u9886\u57df\u8bcd\u5178\u6784\u5efa\u53ca\u878d\u5408\u3001\u591a\u5934\u6ce8\u610f\u529b\u7f16\u7801\u3001\u7ed3\u5408\u9886\u57df\u6848\u4f8b\u8bbe\u8ba1\u7684\u8d85\u56fe\u7ed3\u6784\uff0c\u4ee5\u53ca\u901a\u8fc7\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u9ad8\u9636\u63a8\u7406\u3002", "result": "\u5728CAIL2022\u4fe1\u606f\u62bd\u53d6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u4e86\u53f8\u6cd5\u9886\u57df\u77e5\u8bc6\u548c\u8d85\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5b9e\u73b0\u4e86\u836f\u54c1\u76f8\u5173\u6cd5\u5f8b\u6587\u6863\u4e2d\u5b9e\u4f53\u4e0e\u5173\u7cfb\u7684\u9ad8\u6548\u51c6\u786e\u62bd\u53d6\u3002"}}
{"id": "2602.08294", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08294", "abs": "https://arxiv.org/abs/2602.08294", "authors": ["Dingzirui Wang", "Xuanliang Zhang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che", "Yang Deng"], "title": "When Does Context Help? Error Dynamics of Contextual Information in Large Language Models", "comment": null, "summary": "Contextual information at inference time, such as demonstrations, retrieved knowledge, or interaction history, can substantially improve large language models (LLMs) without parameter updates, yet its theoretical role remains poorly understood beyond specific settings such as in-context learning (ICL). We present a unified theoretical framework for analyzing the effect of arbitrary contextual information in Transformer-based LLMs. Our analysis characterizes contextual influence through output error dynamics. In a single-layer Transformer, we prove that the context-conditioned error vector decomposes additively into the baseline error vector and a contextual correction vector. This yields necessary geometric conditions for error reduction: the contextual correction must align with the negative baseline error and satisfy a norm constraint. We further show that the contextual correction norm admits an explicit upper bound determined by context-query relevance and complementarity. These results extend to multi-context and multi-layer Transformers. Experiments across ICL, retrieval-augmented generation, and memory evolution validate our theory and motivate a principled context selection strategy that improves performance by $0.6\\%$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7406\u8bba\u6846\u67b6\u89e3\u6790\u4e0a\u4e0b\u6587\u4fe1\u606f\u5982\u4f55\u5f71\u54cdTransformer\u5927\u6a21\u578b\u8f93\u51fa\u8bef\u5dee\uff0c\u901a\u8fc7\u8bef\u5dee\u5411\u91cf\u5206\u89e3\u63ed\u793a\u8bef\u5dee\u51cf\u5c11\u6761\u4ef6\uff0c\u5e76\u9a8c\u8bc1\u4e86\u591a\u5c42\u591a\u4e0a\u4e0b\u6587\u9002\u7528\u6027\uff0c\u6307\u5bfc\u4e0a\u4e0b\u6587\u9009\u62e9\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5982\u793a\u4f8b\u3001\u68c0\u7d22\u77e5\u8bc6\u6216\u4ea4\u4e92\u5386\u53f2\uff09\u80fd\u663e\u8457\u63d0\u5347LLM\u6027\u80fd\uff0c\u4f46\u5176\u5728\u66f4\u5e7f\u6cdb\u573a\u666f\u4e0b\u7684\u7406\u8bba\u4f5c\u7528\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7406\u89e3\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u8bbe\u7f6e\u4e4b\u5916\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u4f5c\u8005\u8bc1\u660e\u4e86\u5355\u5c42Transformer\u4e2d\u4e0a\u4e0b\u6587\u6761\u4ef6\u8bef\u5dee\u5411\u91cf\u53ef\u5206\u89e3\u4e3a\u57fa\u7840\u8bef\u5dee\u5411\u91cf\u548c\u4e0a\u4e0b\u6587\u7ea0\u6b63\u5411\u91cf\u7684\u52a0\u6cd5\u5f62\u5f0f\uff0c\u63a8\u5bfc\u4e86\u8bef\u5dee\u51cf\u5c11\u7684\u51e0\u4f55\u5fc5\u8981\u6761\u4ef6\uff0c\u5e76\u7ed9\u51fa\u4e86\u4e0a\u4e0b\u6587\u7ea0\u6b63\u8303\u6570\u7684\u663e\u5f0f\u4e0a\u754c\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u4e86\u4e0a\u4e0b\u6587\u7ea0\u6b63\u5411\u91cf\u7684\u7ed3\u6784\u4e0e\u8bef\u5dee\u51cf\u5c11\u6761\u4ef6\uff0c\u6269\u5c55\u81f3\u591a\u4e0a\u4e0b\u6587\u548c\u591a\u5c42Transformer\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u5b9e\u8be5\u7406\u8bba\u5728\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e0b\u7684\u6709\u6548\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7406\u8bba\u6307\u5bfc\u7684\u4e0a\u4e0b\u6587\u9009\u62e9\u7b56\u7565\uff0c\u6027\u80fd\u63d0\u5347\u4e860.6%\u3002", "conclusion": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u4efb\u610f\u4e0a\u4e0b\u6587\u4fe1\u606f\u5bf9\u57fa\u4e8eTransformer\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f93\u51fa\u8bef\u5dee\u7684\u5f71\u54cd\u673a\u5236\uff0c\u6307\u51fa\u4e86\u4e0a\u4e0b\u6587\u7ea0\u6b63\u5411\u91cf\u4e0e\u57fa\u7840\u8bef\u5dee\u5411\u91cf\u7684\u51e0\u4f55\u5173\u7cfb\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5728\u591a\u5c42\u591a\u4e0a\u4e0b\u6587\u73af\u5883\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2602.08305", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08305", "abs": "https://arxiv.org/abs/2602.08305", "authors": ["Binglin Wu", "Yingyi Zhang", "Xiannneg Li"], "title": "JUSTICE: Judicial Unified Synthesis Through Intermediate Conclusion Emulation for Automated Judgment Document Generation", "comment": null, "summary": "Automated judgment document generation is a significant yet challenging legal AI task. As the conclusive written instrument issued by a court, a judgment document embodies complex legal reasoning. However, existing methods often oversimplify this complex process, particularly by omitting the ``Pre-Judge'' phase, a crucial step where human judges form a preliminary conclusion. This omission leads to two core challenges: 1) the ineffective acquisition of foundational judicial elements, and 2) the inadequate modeling of the Pre-Judge process, which collectively undermine the final document's legal soundness. To address these challenges, we propose \\textit{\\textbf{J}udicial \\textbf{U}nified \\textbf{S}ynthesis \\textbf{T}hrough \\textbf{I}ntermediate \\textbf{C}onclusion \\textbf{E}mulation} (JUSTICE), a novel framework that emulates the ``Search $\\rightarrow$ Pre-Judge $\\rightarrow$ Write'' cognitive workflow of human judges. Specifically, it introduces the Pre-Judge stage through three dedicated components: Referential Judicial Element Retriever (RJER), Intermediate Conclusion Emulator (ICE), and Judicial Unified Synthesizer (JUS). RJER first retrieves legal articles and a precedent case to establish a referential foundation. ICE then operationalizes the Pre-Judge phase by generating a verifiable intermediate conclusion. Finally, JUS synthesizes these inputs to craft the final judgment. Experiments on both an in-domain legal benchmark and an out-of-distribution dataset show that JUSTICE significantly outperforms strong baselines, with substantial gains in legal accuracy, including a 4.6\\% improvement in prison term prediction. Our findings underscore the importance of explicitly modeling the Pre-Judge process to enhance the legal coherence and accuracy of generated judgment documents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faJUSTICE\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u9884\u5224\u9636\u6bb5\u7684\u6a21\u62df\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u751f\u6210\u5224\u51b3\u6587\u4e66\u7684\u6cd5\u5f8b\u51c6\u786e\u6027\u548c\u5408\u7406\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u89c6\u4e86\u5224\u51b3\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u201c\u9884\u5224\u201d\u9636\u6bb5\uff0c\u5bfc\u81f4\u53f8\u6cd5\u5143\u7d20\u83b7\u53d6\u4e0d\u5145\u5206\u548c\u9884\u5224\u8fc7\u7a0b\u5efa\u6a21\u4e0d\u8db3\uff0c\u8fdb\u800c\u5f71\u54cd\u5224\u51b3\u6587\u4e66\u7684\u6cd5\u5f8b\u4e25\u8c28\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e09\u4e2a\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff1aRJER\u7528\u4e8e\u68c0\u7d22\u6cd5\u5f8b\u6761\u6587\u548c\u6848\u4f8b\uff0cICE\u7528\u4e8e\u6a21\u62df\u5e76\u751f\u6210\u53ef\u9a8c\u8bc1\u7684\u4e2d\u95f4\u5224\u51b3\u7ed3\u8bba\uff0cJUS\u7528\u4e8e\u7efc\u5408\u524d\u671f\u4fe1\u606f\u8f93\u51fa\u6700\u7ec8\u5224\u51b3\u6587\u672c\u3002", "result": "\u5728\u5185\u57df\u548c\u8de8\u57df\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cJUSTICE\u5728\u6cd5\u5f8b\u51c6\u786e\u7387\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u5211\u671f\u9884\u6d4b\u4e0a\u63d0\u5347\u4e864.6%\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684JUSTICE\u6846\u67b6\u901a\u8fc7\u6a21\u62df\u53f8\u6cd5\u4eba\u5458\u7684\u201c\u641c\u7d22-\u9884\u5224-\u5199\u4f5c\u201d\u8ba4\u77e5\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u751f\u6210\u5224\u51b3\u6587\u4e66\u7684\u6cd5\u5f8b\u51c6\u786e\u6027\u548c\u5408\u7406\u6027\u3002"}}
{"id": "2602.08321", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08321", "abs": "https://arxiv.org/abs/2602.08321", "authors": ["Zijie Chen", "Zhenghao Lin", "Xiao Liu", "Zhenzhong Lan", "Yeyun Gong", "Peng Cheng"], "title": "Improving Data and Reward Design for Scientific Reasoning in Large Language Models", "comment": null, "summary": "Solving open-ended science questions remains challenging for large language models, particularly due to inherently unreliable supervision and evaluation. The bottleneck lies in the data construction and reward design for scientific post-training. We develop a large-scale, systematic data processing pipeline that transforms heterogeneous open-source science data into Dr. SCI dataset, which comprises of 1M questions across eight STEM subjects, with explicit verifiable/open-ended splits, scalable difficulty annotation, and fine-grained rubrics that operationalize evaluation for open-ended answers. Building on this dataset, we propose the Dr. SCI post-training pipeline, which redesigns the standard SFT -> RL workflow through three components: (i) Exploration-Expanding SFT, which broadens the model's reasoning pattern coverage prior to RL; (ii) Dynamic Difficulty Curriculum, which adapts training data to the model's evolving scientific capability; and (iii) SciRubric-Guided RL, which enables stable reinforcement learning on open-ended scientific questions via rubric-based evaluation with explicit answer correctness. Qwen3-4B-Base trained using Dr.SCI pipeline achieves 63.2 on GPQA-diamond and 32.4 on GPQA-general, consistently improves over strong post-trained baselines such as o1-mini and GPT-4o, demonstrating substantial gains in scientific reasoning, especially in open-ended settings.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u79d1\u5b66\u6570\u636e\u96c6Dr. SCI\uff0c\u8bbe\u8ba1\u521b\u65b0\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u6027\u79d1\u5b66\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89e3\u51b3\u5f00\u653e\u6027\u79d1\u5b66\u95ee\u9898\u65f6\uff0c\u53d7\u5230\u4e0d\u53ef\u9760\u76d1\u7763\u548c\u8bc4\u4f30\u7684\u9650\u5236\uff0c\u6570\u636e\u6784\u5efa\u548c\u5956\u52b1\u8bbe\u8ba1\u662f\u74f6\u9888\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b100\u4e07\u95ee\u9898\u7684Dr. SCI\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86\u8986\u76d6\u63a8\u7406\u5e7f\u5ea6\u7684\u63a2\u7d22\u6269\u5c55\u5fae\u8c03\u3001\u9002\u5e94\u80fd\u529b\u7684\u52a8\u6001\u96be\u5ea6\u8bfe\u7a0b\u548c\u57fa\u4e8e\u8bc4\u5206\u7ec6\u5219\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8eDr. SCI\u8bad\u7ec3\u7684\u6a21\u578bQwen3-4B-Base\u5728GPQA\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79d1\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "\u7cfb\u7edf\u6570\u636e\u5904\u7406\u548c\u79d1\u5b66\u8bbe\u8ba1\u7684\u540e\u8bad\u7ec3\u7ba1\u9053\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u5f00\u653e\u6027\u79d1\u5b66\u95ee\u9898\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u7a33\u5b9a\u548c\u51c6\u786e\u7684\u79d1\u5b66\u63a8\u7406\u8868\u73b0\u3002"}}
{"id": "2602.08322", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08322", "abs": "https://arxiv.org/abs/2602.08322", "authors": ["Wei Zhu"], "title": "An Attention-over-Attention Generative Model for Joint Multiple Intent Detection and Slot Filling", "comment": null, "summary": "In task-oriented dialogue systems, spoken language understanding (SLU) is a critical component, which consists of two sub-tasks, intent detection and slot filling. Most existing methods focus on the single-intent SLU, where each utterance only has one intent. However, in real-world scenarios users usually express multiple intents in an utterance, which poses a challenge for existing dialogue systems and datasets. In this paper, we propose a generative framework to simultaneously address multiple intent detection and slot filling. In particular, an attention-over-attention decoder is proposed to handle the variable number of intents and the interference between the two sub-tasks by incorporating an inductive bias into the process of multi-task learning. Besides, we construct two new multi-intent SLU datasets based on single-intent utterances by taking advantage of the next sentence prediction (NSP) head of the BERT model. Experimental results demonstrate that our proposed attention-over-attention generative model achieves state-of-the-art performance on two public datasets, MixATIS and MixSNIPS, and our constructed datasets.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u5b9e\u4e2d\u7528\u6237\u591a\u610f\u56fe\u8868\u8fbe\u7684\u6311\u6218\uff0c\u672c\u6587\u63d0\u51fa\u751f\u6210\u5f0f\u591a\u610f\u56feSLU\u6a21\u578b\u53ca\u65b0\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u591a\u610f\u56fe\u68c0\u6d4b\u4e0e\u69fd\u4f4d\u586b\u5145\u8054\u5408\u4f18\u5316\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u591a\u6570\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4ec5\u9488\u5bf9\u5355\u610f\u56fe\u8bed\u53e5\uff0c\u800c\u5b9e\u9645\u573a\u666f\u4e2d\u7528\u6237\u5e38\u8868\u8fbe\u591a\u4e2a\u610f\u56fe\uff0c\u73b0\u6709\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u96be\u4ee5\u5e94\u5bf9\u591a\u610f\u56fe\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u6846\u67b6\u7684\u6ce8\u610f\u529b\u53e0\u52a0\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u5f15\u5165\u5f52\u7eb3\u504f\u7f6e\u5b9e\u73b0\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u652f\u6301\u53d8\u6570\u91cf\u610f\u56fe\u68c0\u6d4b\u548c\u69fd\u586b\u5145\u7684\u8054\u5408\u5904\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u591a\u610f\u56feSLU\u6570\u636e\u96c6MixATIS\u548cMixSNIPS\u53ca\u65b0\u6784\u5efa\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u6a21\u578b\u53d6\u5f97\u4e86\u9886\u5148\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u591a\u610f\u56fe\u53ca\u5b50\u4efb\u52a1\u5e72\u6270\u95ee\u9898\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6ce8\u610f\u529b\u53e0\u52a0\u89e3\u7801\u5668\u751f\u6210\u6846\u67b6\u6709\u6548\u5730\u89e3\u51b3\u4e86\u591a\u610f\u56fe\u68c0\u6d4b\u548c\u69fd\u4f4d\u586b\u5145\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u610f\u56fe\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2602.08332", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08332", "abs": "https://arxiv.org/abs/2602.08332", "authors": ["Ido Amos", "Avi Caciularu", "Mor Geva", "Amir Globerson", "Jonathan Herzig", "Lior Shani", "Idan Szpektor"], "title": "Latent Reasoning with Supervised Thinking States", "comment": null, "summary": "Reasoning with a chain-of-thought (CoT) enables Large Language Models (LLMs) to solve complex tasks but incurs significant inference costs due to the generation of long rationales. We propose Thinking States, a method that performs reasoning {\\em while} the input is processing. Specifically, Thinking States generates sequences of thinking tokens every few input tokens, transforms the thoughts back into embedding space, and adds them to the following input tokens. This has two key advantages. First, it captures the recurrent nature of CoT, but where the thought tokens are generated as input is processing. Second, since the thoughts are represented as tokens, they can be learned from natural language supervision, and using teacher-forcing, which is parallelizable. Empirically, Thinking States outperforms other latent reasoning methods on multiple reasoning tasks, narrowing the gap to CoT on math problems, and matching its performance on 2-Hop QA with improved latency. On state-tracking tasks, we show Thinking States leads to stronger reasoning behavior than CoT, successfully extrapolating to longer sequences than seen during training.", "AI": {"tldr": "\u63d0\u51fa\u4e86Thinking States\u65b9\u6cd5\uff0c\u8fb9\u5904\u7406\u8f93\u5165\u8fb9\u751f\u6210\u601d\u8003\u6807\u8bb0\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u548c\u6548\u679c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u591a\u79cd\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u6216\u5339\u914d\u94fe\u5f0f\u63a8\u7406\uff0c\u4e14\u5177\u6709\u66f4\u4f4e\u5ef6\u8fdf\u548c\u66f4\u597d\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u94fe\u5f0f\u63a8\u7406\uff08CoT\uff09\u867d\u7136\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u4f46\u5176\u751f\u6210\u957f\u63a8\u7406\u8fc7\u7a0b\u7684\u5f00\u9500\u5f88\u5927\u3002\u601d\u8003\u72b6\u6001\uff08Thinking States\uff09\u65e8\u5728\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u548c\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u901a\u8fc7\u8fb9\u8f93\u5165\u8fb9\u63a8\u7406\u7684\u673a\u5236\u6765\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "Thinking States\u65b9\u6cd5\u901a\u8fc7\u5728\u8f93\u5165\u5904\u7406\u7684\u8fc7\u7a0b\u4e2d\uff0c\u6bcf\u9694\u51e0\u4e2a\u8f93\u5165\u6807\u8bb0\u751f\u6210\u601d\u8003\u6807\u8bb0\u5e8f\u5217\uff0c\u5c06\u8fd9\u4e9b\u601d\u8003\u6807\u8bb0\u8f6c\u56de\u5d4c\u5165\u7a7a\u95f4\u5e76\u52a0\u5165\u540e\u7eed\u8f93\u5165\u4e2d\uff0c\u5b9e\u73b0\u4e86\u5728\u8f93\u5165\u6d41\u52a8\u4e2d\u9012\u5f52\u5730\u751f\u6210\u548c\u5229\u7528\u601d\u8003\u5185\u5bb9\u3002\u8fd9\u79cd\u65b9\u6cd5\u652f\u6301\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u76d1\u7763\u548c\u6559\u5e08\u5f3a\u5236\u8bad\u7ec3\uff0c\u5177\u6709\u5e76\u884c\u8ba1\u7b97\u4f18\u52bf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cThinking States\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7f29\u5c0f\u4e86\u4e0eCoT\u7684\u5dee\u8ddd\uff0c\u4e14\u57282-Hop\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4e0eCoT\u76f8\u5f53\u4f46\u63a8\u7406\u5ef6\u8fdf\u66f4\u4f4e\uff1b\u5728\u72b6\u6001\u8ddf\u8e2a\u4efb\u52a1\u4e2d\uff0cThinking States\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u6210\u529f\u63a8\u5e7f\u5230\u8bad\u7ec3\u4e2d\u672a\u89c1\u7684\u66f4\u957f\u5e8f\u5217\u3002", "conclusion": "Thinking States\u65b9\u6cd5\u80fd\u591f\u5728\u5904\u7406\u8f93\u5165\u7684\u540c\u65f6\u8fdb\u884c\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u548c\u6548\u679c\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e2d\u4f18\u4e8e\u5176\u4ed6\u6f5c\u5728\u63a8\u7406\u65b9\u6cd5\uff0c\u5e76\u4e14\u5728\u6570\u5b66\u95ee\u9898\u548c\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u6216\u8fbe\u5230\u94fe\u5f0f\u63a8\u7406\uff08CoT\uff09\u7684\u6c34\u5e73\uff0c\u540c\u65f6\u5728\u72b6\u6001\u8ddf\u8e2a\u4efb\u52a1\u4e0a\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u548c\u5bf9\u957f\u5e8f\u5217\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08336", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08336", "abs": "https://arxiv.org/abs/2602.08336", "authors": ["Cheng Yang", "Chufan Shi", "Bo Shui", "Yaokang Wu", "Muzi Tao", "Huijuan Wang", "Ivan Yee Lee", "Yong Liu", "Xuezhe Ma", "Taylor Berg-Kirkpatrick"], "title": "UReason: Benchmarking the Reasoning Paradox in Unified Multimodal Models", "comment": "Project page: https://ureason.github.io", "summary": "To elicit capabilities for addressing complex and implicit visual requirements, recent unified multimodal models increasingly adopt chain-of-thought reasoning to guide image generation. However, the actual effect of reasoning on visual synthesis remains unclear. We present UReason, a diagnostic benchmark for reasoning-driven image generation that evaluates whether reasoning can be faithfully executed in pixels. UReason contains 2,000 instances across five task families: Code, Arithmetic, Spatial, Attribute, and Text reasoning. To isolate the role of reasoning traces, we introduce an evaluation framework comparing direct generation, reasoning-guided generation, and de-contextualized generation which conditions only on the refined prompt. Across eight open-source unified models, we observe a consistent Reasoning Paradox: Reasoning traces generally improve performance over direct generation, yet retaining intermediate thoughts as conditioning context often hinders visual synthesis, and conditioning only on the refined prompt yields substantial gains. Our analysis suggests that the bottleneck lies in contextual interference rather than insufficient reasoning capacity. UReason provides a principled testbed for studying reasoning in unified models and motivates future methods that effectively integrate reasoning for visual generation while mitigating interference.", "AI": {"tldr": "\u63d0\u51faUReason\u57fa\u51c6\u5168\u9762\u8bc4\u4f30\u63a8\u7406\u9a71\u52a8\u56fe\u50cf\u751f\u6210\uff0c\u63ed\u793a\u63a8\u7406\u6761\u4ef6\u4e0a\u4e0b\u6587\u5e72\u6270\u95ee\u9898\uff0c\u63a8\u52a8\u672a\u6765\u6709\u6548\u6574\u5408\u63a8\u7406\u6307\u5bfc\u89c6\u89c9\u751f\u6210\u7684\u65b9\u6cd5\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u501f\u52a9\u94fe\u5f0f\u63a8\u7406\u5f15\u5bfc\u56fe\u50cf\u751f\u6210\uff0c\u4f46\u63a8\u7406\u5bf9\u89c6\u89c9\u5408\u6210\u7684\u5b9e\u9645\u5f71\u54cd\u5c1a\u4e0d\u660e\u6670\uff0c\u4e9f\u9700\u7cfb\u7edf\u8bc4\u4f30\u63a8\u7406\u6267\u884c\u7684\u771f\u5b9e\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86UReason\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b2000\u4e2a\u5b9e\u4f8b\u548c\u4e94\u7c7b\u63a8\u7406\u4efb\u52a1\uff0c\u901a\u8fc7\u6bd4\u8f83\u76f4\u63a5\u751f\u6210\u3001\u63a8\u7406\u5f15\u5bfc\u751f\u6210\u548c\u4ec5\u7528\u7cbe\u70bc\u63d0\u793a\u751f\u6210\uff0c\u8bc4\u4f30\u63a8\u7406\u5728\u56fe\u50cf\u751f\u6210\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u53d1\u73b0\u201c\u63a8\u7406\u6096\u8bba\u201d\u73b0\u8c61\uff1a\u4fdd\u7559\u63a8\u7406\u4e2d\u95f4\u6b65\u9aa4\u4f5c\u4e3a\u6761\u4ef6\u4f1a\u5e72\u6270\u56fe\u50cf\u751f\u6210\u6548\u679c\uff0c\u800c\u4ec5\u7528\u7cbe\u70bc\u7684\u63d0\u793a\u53cd\u800c\u8868\u73b0\u6700\u597d\u3002", "conclusion": "\u63a8\u7406\u8f68\u8ff9\u867d\u63d0\u5347\u4e86\u56fe\u50cf\u751f\u6210\u6027\u80fd\uff0c\u4f46\u5c06\u4e2d\u95f4\u601d\u8003\u8fc7\u7a0b\u4f5c\u4e3a\u6761\u4ef6\u4e0a\u4e0b\u6587\u53cd\u800c\u963b\u788d\u4e86\u89c6\u89c9\u5408\u6210\uff0c\u4e3b\u8981\u74f6\u9888\u662f\u4e0a\u4e0b\u6587\u5e72\u6270\u800c\u975e\u63a8\u7406\u80fd\u529b\u4e0d\u8db3\u3002"}}
{"id": "2602.08367", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08367", "abs": "https://arxiv.org/abs/2602.08367", "authors": ["Zexuan Wang", "Chenghao Yang", "Yingqi Que", "Zhenzhu Yang", "Huaqing Yuan", "Yiwen Wang", "Zhengxuan Jiang", "Shengjie Fang", "Zhenhe Wu", "Zhaohui Wang", "Zhixin Yao", "Jiashuo Liu", "Jincheng Ren", "Yuzhen Li", "Yang Yang", "Jiaheng Liu", "Jian Yang", "Zaiyuan Wang", "Ge Zhang", "Zhoufutu Wen", "Wenhao Huang"], "title": "WorldTravel: A Realistic Multimodal Travel-Planning Benchmark with Tightly Coupled Constraints", "comment": null, "summary": "Real-world autonomous planning requires coordinating tightly coupled constraints where a single decision dictates the feasibility of all subsequent actions. However, existing benchmarks predominantly feature loosely coupled constraints solvable through local greedy decisions and rely on idealized data, failing to capture the complexity of extracting parameters from dynamic web environments. We introduce \\textbf{WorldTravel}, a benchmark comprising 150 real-world travel scenarios across 5 cities that demand navigating an average of 15+ interdependent temporal and logical constraints. To evaluate agents in realistic deployments, we develop \\textbf{WorldTravel-Webscape}, a multi-modal environment featuring over 2,000 rendered webpages where agents must perceive constraint parameters directly from visual layouts to inform their planning. Our evaluation of 10 frontier models reveals a significant performance collapse: even the state-of-the-art GPT-5.2 achieves only 32.67\\% feasibility in text-only settings, which plummets to 19.33\\% in multi-modal environments. We identify a critical Perception-Action Gap and a Planning Horizon threshold at approximately 10 constraints where model reasoning consistently fails, suggesting that perception and reasoning remain independent bottlenecks. These findings underscore the need for next-generation agents that unify high-fidelity visual perception with long-horizon reasoning to handle brittle real-world logistics.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u771f\u5b9e\u4e16\u754c\u591a\u7ea6\u675f\u65c5\u884c\u89c4\u5212\u57fa\u51c6\u548c\u591a\u6a21\u6001\u7f51\u9875\u73af\u5883\uff0c\u63ed\u793a\u73b0\u6709\u9876\u5c16\u6a21\u578b\u5728\u611f\u77e5\u4e0e\u63a8\u7406\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u74f6\u9888\uff0c\u63a8\u52a8\u672a\u6765\u591a\u6a21\u6001\u957f\u7a0b\u63a8\u7406\u667a\u80fd\u4f53\u7684\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u591a\u5904\u7406\u677e\u8026\u5408\u7ea6\u675f\u548c\u7406\u60f3\u5316\u6570\u636e\uff0c\u65e0\u6cd5\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u591a\u7ea6\u675f\u89c4\u5212\u548c\u590d\u6742\u52a8\u6001\u7f51\u9875\u73af\u5883\u53c2\u6570\u63d0\u53d6\u7684\u590d\u6742\u6027\u3002", "method": "\u63d0\u51fa\u4e86WorldTravel\u57fa\u51c6\uff0c\u5305\u542b150\u4e2a\u8de85\u57ce\u5e02\u7684\u771f\u5b9e\u65c5\u884c\u573a\u666f\uff0c\u53caWorldTravel-Webscape\u591a\u6a21\u6001\u73af\u5883\uff0c\u5305\u542b2000\u591a\u4e2a\u7f51\u9875\u4ee5\u89c6\u89c9\u5f62\u5f0f\u63d0\u4f9b\u7ea6\u675f\u53c2\u6570\uff0c\u8bc4\u4ef710\u4e2a\u524d\u6cbf\u6a21\u578b\u8868\u73b0\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u6587\u672c\u73af\u5883\u4e2d\u53ef\u884c\u6027\u4ec5\u7ea632.67%\uff0c\u591a\u6a21\u6001\u73af\u5883\u4e0b\u964d\u81f319.33%\uff0c\u53d1\u73b0\u611f\u77e5-\u884c\u52a8\u9e3f\u6c9f\u548c\u7ea610\u4e2a\u7ea6\u675f\u7684\u89c4\u5212\u96be\u5ea6\u9608\u503c\uff0c\u8bf4\u660e\u611f\u77e5\u548c\u63a8\u7406\u5747\u5b58\u5728\u74f6\u9888\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u5728\u9762\u5bf9\u7d27\u5bc6\u8026\u5408\u7ea6\u675f\u7684\u771f\u5b9e\u4e16\u754c\u95ee\u9898\u65f6\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u5c24\u5176\u5728\u591a\u6a21\u6001\u4fe1\u606f\u73af\u5883\u4e2d\u8868\u73b0\u6781\u5dee\uff0c\u8868\u73b0\u51fa\u611f\u77e5\u4e0e\u63a8\u7406\u4e4b\u95f4\u5b58\u5728\u660e\u663e\u74f6\u9888\uff0c\u63d0\u793a\u672a\u6765\u9700\u8981\u7edf\u4e00\u89c6\u89c9\u611f\u77e5\u4e0e\u957f\u7a0b\u63a8\u7406\u7684\u7efc\u5408\u667a\u80fd\u4f53\u3002"}}
{"id": "2602.08371", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08371", "abs": "https://arxiv.org/abs/2602.08371", "authors": ["Hung Quang Tran", "Nam Tien Pham", "Son T. Luu", "Kiet Van Nguyen"], "title": "ViGoEmotions: A Benchmark Dataset For Fine-grained Emotion Detection on Vietnamese Texts", "comment": "Accepted as main paper at EACL 2026", "summary": "Emotion classification plays a significant role in emotion prediction and harmful content detection. Recent advancements in NLP, particularly through large language models (LLMs), have greatly improved outcomes in this field. This study introduces ViGoEmotions -- a Vietnamese emotion corpus comprising 20,664 social media comments in which each comment is classified into 27 fine-grained distinct emotions. To evaluate the quality of the dataset and its impact on emotion classification, eight pre-trained Transformer-based models were evaluated under three preprocessing strategies: preserving original emojis with rule-based normalization, converting emojis into textual descriptions, and applying ViSoLex, a model-based lexical normalization system. Results show that converting emojis into text often improves the performance of several BERT-based baselines, while preserving emojis yields the best results for ViSoBERT and CafeBERT. In contrast, removing emojis generally leads to lower performance. ViSoBERT achieved the highest Macro F1-score of 61.50% and Weighted F1-score of 63.26%. Strong performance was also observed from CafeBERT and PhoBERT. These findings highlight that while the proposed corpus can support diverse architectures effectively, preprocessing strategies and annotation quality remain key factors influencing downstream performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a8\u51fa\u8d8a\u5357\u8bed\u60c5\u611f\u8bed\u6599\u5e93ViGoEmotions\uff0c\u8bc4\u4f30\u8868\u60c5\u7b26\u53f7\u9884\u5904\u7406\u5bf9\u60c5\u611f\u5206\u7c7b\u6548\u679c\u5f71\u54cd\uff0cViSoBERT\u6a21\u578b\u53d6\u5f97\u6700\u4f73\u8868\u73b0\uff0c\u8868\u660e\u8bed\u6599\u8d28\u91cf\u548c\u9884\u5904\u7406\u7b56\u7565\u5173\u952e\u5f71\u54cd\u4e0b\u6e38\u6027\u80fd\u3002", "motivation": "\u60c5\u611f\u5206\u7c7b\u5bf9\u60c5\u611f\u9884\u6d4b\u548c\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u5728\u8d8a\u5357\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u4e9f\u9700\u9ad8\u8d28\u91cf\u6807\u6ce8\u60c5\u611f\u8bed\u6599\u6784\u5efa\u548c\u6a21\u578b\u6027\u80fd\u9a8c\u8bc1\u3002", "method": "\u6784\u5efa\u6db5\u76d620664\u6761\u793e\u4ea4\u5a92\u4f53\u8bc4\u8bba\u7684\u8d8a\u5357\u8bed\u60c5\u611f\u8bed\u6599\u5e93\uff0c\u5305\u542b27\u79cd\u7ec6\u7c92\u5ea6\u60c5\u611f\u6807\u7b7e\uff1b\u4f7f\u75288\u79cd\u9884\u8bad\u7ec3Transformer\u6a21\u578b\uff0c\u91c7\u7528\u4e09\u79cd\u8868\u60c5\u7b26\u53f7\u9884\u5904\u7406\u7b56\u7565\uff08\u4fdd\u7559\u3001\u6587\u672c\u8f6c\u6362\u3001\u6a21\u578b\u8bcd\u6c47\u89c4\u8303\u5316\uff09\u8fdb\u884c\u60c5\u611f\u5206\u7c7b\u8bc4\u4f30\u3002", "result": "\u8f6c\u6362\u8868\u60c5\u7b26\u53f7\u4e3a\u6587\u672c\u80fd\u63d0\u5347\u90e8\u5206BERT\u57fa\u7ebf\u6a21\u578b\u6027\u80fd\uff0c\u4fdd\u7559\u8868\u60c5\u7b26\u53f7\u5bf9ViSoBERT\u548cCafeBERT\u6548\u679c\u6700\u4f73\uff0c\u79fb\u9664\u8868\u60c5\u7b26\u53f7\u901a\u5e38\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0cViSoBERT\u8fbe\u5230\u5b8fF1 61.50%\u548c\u52a0\u6743F1 63.26%\u3002", "conclusion": "ViGoEmotions\u8d8a\u5357\u8bed\u60c5\u611f\u8bed\u6599\u5e93\u901a\u8fc7\u5bf9\u8868\u60c5\u7b26\u53f7\u7684\u4e0d\u540c\u9884\u5904\u7406\u7b56\u7565\u663e\u8457\u5f71\u54cd\u60c5\u611f\u5206\u7c7b\u6027\u80fd\uff0cViSoBERT\u6a21\u578b\u5728\u5b8fF1\u548c\u52a0\u6743F1\u5f97\u5206\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u9a8c\u8bc1\u4e86\u8be5\u8bed\u6599\u5e93\u7684\u6709\u6548\u6027\u548c\u591a\u6837\u67b6\u6784\u652f\u6301\u6027\u3002"}}
{"id": "2602.08382", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08382", "abs": "https://arxiv.org/abs/2602.08382", "authors": ["Zhuoen Chen", "Dongfang Li", "Meishan Zhang", "Baotian Hu", "Min Zhang"], "title": "Dynamic Long Context Reasoning over Compressed Memory via End-to-End Reinforcement Learning", "comment": "26 pages, 7 figures. Code and models will be released", "summary": "Large Language Models (LLMs) face significant challenges in long-context processing, including quadratic computational costs, information forgetting, and the context fragmentation inherent in retrieval-augmented generation (RAG). We propose a cognitively inspired framework for efficient long-context inference based on chunk-wise compression and selective memory recall, rather than processing all raw tokens. The framework segments long inputs into chunks and encodes each chunk into compressed memory representations using a learned compressor. A gating module dynamically selects relevant memory blocks, which are then iteratively processed by a reasoning module with an evolving working memory to solve downstream tasks. The compressor and reasoner are jointly optimized via end-to-end reinforcement learning, while the gating module is trained separately as a classifier. Experimental results show that the proposed method achieves competitive accuracy on multi-hop reasoning benchmarks such as RULER-HQA, extrapolates context length from 7K to 1.75M tokens, and offers a favorable accuracy-efficiency trade-off compared to strong long-context baselines. In particular, it achieves up to a 2 times reduction in peak GPU memory usage and a 6 times inference speedup over MemAgent.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5206\u5757\u538b\u7f29\u4e0e\u9009\u62e9\u6027\u8bb0\u5fc6\u53ec\u56de\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6781\u5927\u4e0a\u4e0b\u6587\u6269\u5c55\u4e0e\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u663e\u8457\u4f18\u5316\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u9762\u4e34\u9ad8\u8ba1\u7b97\u6210\u672c\u3001\u4fe1\u606f\u9057\u5fd8\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u4e0a\u4e0b\u6587\u788e\u7247\u5316\u7b49\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5206\u5757\u538b\u7f29\u548c\u9009\u62e9\u6027\u8bb0\u5fc6\u53ec\u56de\u7684\u9ad8\u6548\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u8ba4\u77e5\u542f\u53d1\u6846\u67b6\uff0c\u5229\u7528\u538b\u7f29\u5668\u7f16\u7801\u8bb0\u5fc6\u5757\uff0c\u95e8\u63a7\u6a21\u5757\u9009\u62e9\u76f8\u5173\u8bb0\u5fc6\uff0c\u63a8\u7406\u6a21\u5757\u8fed\u4ee3\u5904\u7406\u3002\u538b\u7f29\u5668\u4e0e\u63a8\u7406\u5668\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\uff0c\u95e8\u63a7\u6a21\u5757\u4f5c\u4e3a\u5206\u7c7b\u5668\u5355\u72ec\u8bad\u7ec3\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u8df3\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u957f\u5ea6\u4ece7K\u62d3\u5c55\u81f31.75M tokens\uff0c\u5177\u6709\u826f\u597d\u7684\u51c6\u786e\u7387\u4e0e\u6548\u7387\u6298\u4e2d\uff0c\u5728\u5cf0\u503cGPU\u5185\u5b58\u4f7f\u7528\u51cf\u5c112\u500d\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53476\u500d\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u6709\u6548\u7f13\u89e3\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u7684\u8ba1\u7b97\u4e0e\u8bb0\u5fc6\u74f6\u9888\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u957f\u6587\u672c\u63a8\u7406\u7684\u51c6\u786e\u6027\u4e0e\u6548\u7387\u3002"}}
{"id": "2602.08404", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08404", "abs": "https://arxiv.org/abs/2602.08404", "authors": ["Linye Wei", "Zixiang Luo", "Pingzhi Tang", "Meng Li"], "title": "TEAM: Temporal-Spatial Consistency Guided Expert Activation for MoE Diffusion Language Model Acceleration", "comment": null, "summary": "Diffusion large language models (dLLMs) have recently gained significant attention due to their inherent support for parallel decoding. Building on this paradigm, Mixture-of-Experts (MoE) dLLMs with autoregressive (AR) initialization have further demonstrated strong performance competitive with mainstream AR models. However, we identify a fundamental mismatch between MoE architectures and diffusion-based decoding. Specifically, a large number of experts are activated at each denoising step, while only a small subset of tokens is ultimately accepted, resulting in substantial inference overhead and limiting their deployment in latency-sensitive applications. In this work, we propose TEAM, a plug-and-play framework that accelerates MoE dLLMs by enabling more accepted tokens with fewer activated experts. TEAM is motivated by the observation that expert routing decisions exhibit strong temporal consistency across denoising levels as well as spatial consistency across token positions. Leveraging these properties, TEAM employs three complementary expert activation and decoding strategies, conservatively selecting necessary experts for decoded and masked tokens and simultaneously performing aggressive speculative exploration across multiple candidates. Experimental results demonstrate that TEAM achieves up to 2.2x speedup over vanilla MoE dLLM, with negligible performance degradation. Code is released at https://github.com/PKU-SEC-Lab/TEAM-MoE-dLLM.", "AI": {"tldr": "\u9488\u5bf9MoE\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faTEAM\uff0c\u901a\u8fc7\u4e13\u5bb6\u6fc0\u6d3b\u4f18\u5316\u548c\u591a\u5019\u9009\u63a2\u7d22\u7b56\u7565\uff0c\u5927\u5e45\u63d0\u5347\u89e3\u7801\u901f\u5ea6\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u6548\u7387\u3002", "motivation": "\u4f20\u7edfMoE\u7ed3\u6784\u5728\u6269\u6563\u89e3\u7801\u8fc7\u7a0b\u4e2d\u6fc0\u6d3b\u5927\u91cf\u4e13\u5bb6\u4f46\u6700\u7ec8\u53ea\u63a5\u53d7\u5c11\u91cftoken\uff0c\u5bfc\u81f4\u63a8\u7406\u5f00\u9500\u5927\uff0c\u9650\u5236\u4e86\u5176\u5728\u4f4e\u5ef6\u8fdf\u573a\u666f\u7684\u5e94\u7528\u3002", "method": "TEAM\u6846\u67b6\u57fa\u4e8e\u4e13\u5bb6\u8def\u7531\u51b3\u7b56\u5728\u65f6\u5e8f\u548c\u7a7a\u95f4\u4e0a\u7684\u4e00\u81f4\u6027\uff0c\u8bbe\u8ba1\u4e86\u4e09\u79cd\u4e13\u5bb6\u6fc0\u6d3b\u548c\u89e3\u7801\u7b56\u7565\uff0c\u9009\u62e9\u5fc5\u8981\u4e13\u5bb6\u540c\u65f6\u8fdb\u884c\u591a\u5019\u9009\u7684\u5927\u80c6\u63a2\u7d22\uff0c\u4ece\u800c\u51cf\u5c11\u6fc0\u6d3b\u4e13\u5bb6\u6570\u91cf\u4f46\u63d0\u9ad8\u88ab\u63a5\u53d7\u7684token\u6570\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cTEAM\u5728\u4fdd\u6301\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u539f\u59cbMoE\u6269\u6563\u8bed\u8a00\u6a21\u578b\u6700\u9ad82.2\u500d\u7684\u52a0\u901f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684TEAM\u6846\u67b6\u901a\u8fc7\u5408\u7406\u6fc0\u6d3b\u4e13\u5bb6\uff0c\u5b9e\u73b0\u4e86MoE\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u663e\u8457\u52a0\u901f\uff0c\u4e14\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.08426", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.08426", "abs": "https://arxiv.org/abs/2602.08426", "authors": ["Xinghao Wang", "Pengyu Wang", "Xiaoran Liu", "Fangxu Liu", "Jason Chu", "Kai Song", "Xipeng Qiu"], "title": "Prism: Spectral-Aware Block-Sparse Attention", "comment": null, "summary": "Block-sparse attention is promising for accelerating long-context LLM pre-filling, yet identifying relevant blocks efficiently remains a bottleneck. Existing methods typically employ coarse-grained attention as a proxy for block importance estimation, but often resort to expensive token-level searching or scoring, resulting in significant selection overhead. In this work, we trace the inaccuracy of standard coarse-grained attention via mean pooling to a theoretical root cause: the interaction between mean pooling and Rotary Positional Embeddings (RoPE). We prove that mean pooling acts as a low-pass filter that induces destructive interference in high-frequency dimensions, effectively creating a \"blind spot\" for local positional information (e.g., slash patterns). To address this, we introduce Prism, a training-free spectral-aware approach that decomposes block selection into high-frequency and low-frequency branches. By applying energy-based temperature calibration, Prism restores the attenuated positional signals directly from pooled representations, enabling block importance estimation using purely block-level operations, thereby improving efficiency. Extensive evaluations confirm that Prism maintains accuracy parity with full attention while delivering up to $\\mathbf{5.1\\times}$ speedup.", "AI": {"tldr": "\u901a\u8fc7\u89e3\u51b3\u5e73\u5747\u6c60\u5316\u4e0eRoPE\u95f4\u7684\u5e72\u6270\uff0cPrism\u65e0\u8bad\u7ec3\u5730\u6062\u590d\u5173\u952e\u4f4d\u7f6e\u4fe1\u53f7\uff0c\u5b9e\u73b0\u5757\u7a00\u758f\u6ce8\u610f\u529b\u7684\u9ad8\u6548\u5757\u9009\u62e9\uff0c\u63d0\u5347\u957f\u4e0a\u4e0b\u6587LLM\u9884\u586b\u5145\u901f\u5ea6\u81f35.1\u500d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5757\u7a00\u758f\u6ce8\u610f\u529b\u7684\u957f\u4e0a\u4e0b\u6587LLM\u9884\u586b\u5145\u65b9\u6cd5\u4e2d\uff0c\u7c97\u7c92\u5ea6\u6ce8\u610f\u529b\u4f5c\u4e3a\u5757\u91cd\u8981\u6027\u4f30\u8ba1\u7684\u4ee3\u7406\u5bfc\u81f4\u9009\u62e9\u5f00\u9500\u5927\u3002", "method": "\u63d0\u51faPrism\u65b9\u6cd5\uff0c\u901a\u8fc7\u9ad8\u9891\u548c\u4f4e\u9891\u5206\u652f\u5206\u89e3\u5757\u9009\u62e9\uff0c\u5229\u7528\u80fd\u91cf\u57fa\u6e29\u5ea6\u6821\u51c6\u6062\u590d\u88ab\u8870\u51cf\u7684\u4f4d\u7f6e\u4fe1\u53f7\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u7eaf\u5757\u7ea7\u64cd\u4f5c\u4f30\u8ba1\u5757\u91cd\u8981\u6027\u3002", "result": "Prism\u5728\u4fdd\u6301\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\uff0c\u63d0\u4f9b\u4e86\u6700\u9ad85.1\u500d\u7684\u52a0\u901f\u6548\u679c\u3002", "conclusion": "Prism\u6709\u6548\u89e3\u51b3\u4e86\u7c97\u7c92\u5ea6\u6ce8\u610f\u529b\u4e2d\u7684\u5e73\u5747\u6c60\u5316\u4e0eRoPE\u5bfc\u81f4\u7684\u4f4d\u7f6e\u4fe1\u606f\u76f2\u533a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5757\u91cd\u8981\u6027\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5757\u7a00\u758f\u6ce8\u610f\u529b\u7684\u6548\u7387\u3002"}}
{"id": "2602.08437", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08437", "abs": "https://arxiv.org/abs/2602.08437", "authors": ["Ziyan wang", "Longlong Ma"], "title": "Large Language Models and Impossible Language Acquisition: \"False Promise\" or an Overturn of our Current Perspective towards AI", "comment": null, "summary": "In Chomsky's provocative critique \"The False Promise of CHATGPT,\" Large Language Models (LLMs) are characterized as mere pattern predictors that do not acquire languages via intrinsic causal and self-correction structures like humans, therefore are not able to distinguish impossible languages. It stands as a representative in a fundamental challenge to the intellectual foundations of AI, for it integrally synthesizes major issues in methodologies within LLMs and possesses an iconic a priori rationalist perspective. We examine this famous critic from both the perspective in pre-existing literature of linguistics and psychology as well as a research based on an experiment inquiring the capacity of learning both possible and impossible languages among LLMs. We constructed a set of syntactically impossible languages by applying certain transformations to English. These include reversing whole sentences, and adding negation based on word-count parity. Two rounds of controlled experiments were each conducted on GPT-2 small models and long short-term memory (LSTM) models. Statistical analysis (Welch's t-test) shows GPT2 small models underperform in learning all of the impossible languages compared to their performance on the possible language (p<.001). On the other hand, LSTM models' performance tallies with Chomsky's argument, suggesting the irreplaceable role of the evolution of transformer architecture. Based on theoretical analysis and empirical findings, we propose a new vision within Chomsky's theory towards LLMs, and a shift of theoretical paradigm outside Chomsky, from his \"rationalist-romantics\" paradigm to functionalism and empiricism in LLMs research.", "AI": {"tldr": "\u8bba\u6587\u56de\u5e94\u4e54\u59c6\u65af\u57fa\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6279\u8bc4\uff0c\u901a\u8fc7\u8bbe\u8ba1\u4e0d\u53ef\u80fd\u8bed\u8a00\u5b9e\u9a8c\u9a8c\u8bc1GPT-2\u5728\u6b64\u7c7b\u4efb\u52a1\u4e0a\u7684\u4e0d\u8db3\uff0c\u652f\u6301\u5176\u89c2\u70b9\uff0c\u5e76\u63d0\u51fa\u7406\u8bba\u8303\u5f0f\u7684\u66f4\u65b0\u5efa\u8bae\u3002", "motivation": "\u56de\u5e94\u4e54\u59c6\u65af\u57fa\u5bf9ChatGPT\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6279\u8bc4\uff0c\u9a8c\u8bc1LLM\u662f\u5426\u80fd\u533a\u5206\u4e0d\u53ef\u80fd\u8bed\u8a00\uff0c\u63a2\u8ba8\u5176\u5b66\u4e60\u8bed\u8a00\u7684\u672c\u8d28\u548c\u8ba4\u77e5\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u6784\u9020\u8bed\u6cd5\u4e0d\u53ef\u80fd\u8bed\u8a00\uff08\u5982\u53e5\u5b50\u53cd\u8f6c\u548c\u57fa\u4e8e\u8bcd\u6570\u5947\u5076\u7684\u5426\u5b9a\uff09\u5e76\u5bf9GPT-2\u5c0f\u6a21\u578b\u548cLSTM\u6a21\u578b\u8fdb\u884c\u4e24\u8f6e\u5bf9\u7167\u5b9e\u9a8c\uff0c\u91c7\u7528Welch's t\u68c0\u9a8c\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u3002", "result": "GPT-2\u5728\u5b66\u4e60\u4e0d\u53ef\u80fd\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u663e\u8457\u8f83\u5dee\uff0c\u7b26\u5408\u4e54\u59c6\u65af\u57fa\u5bf9LLM\u7f3a\u4e4f\u5185\u5728\u56e0\u679c\u53ca\u81ea\u6211\u7ea0\u6b63\u7ed3\u6784\u7684\u6279\u8bc4\uff1bLSTM\u6a21\u578b\u8868\u73b0\u4e0e\u4e54\u59c6\u65af\u57fa\u89c2\u70b9\u4e00\u81f4\uff1b\u53d8\u538b\u5668\u67b6\u6784\u5177\u6709\u4e0d\u53ef\u66ff\u4ee3\u7684\u4f5c\u7528\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660eGPT-2\u6a21\u578b\u5728\u5b66\u4e60\u4e0d\u53ef\u80fd\u8bed\u8a00\u7684\u80fd\u529b\u663e\u8457\u4f4e\u4e8e\u53ef\u80fd\u8bed\u8a00\uff0c\u652f\u6301\u4e54\u59c6\u65af\u57fa\u5bf9LLM\u7684\u6279\u8bc4\uff0c\u5e76\u6307\u51fa\u53d8\u538b\u5668\u67b6\u6784\u7684\u91cd\u8981\u6027\u3002\u57fa\u4e8e\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u6570\u636e\uff0c\u63d0\u51fa\u4e86\u4e54\u59c6\u65af\u57fa\u7406\u8bba\u5185\u7684\u65b0\u89c6\u89d2\uff0c\u4ee5\u53ca\u4ece\u201c\u7406\u6027\u4e3b\u4e49-\u6d6a\u6f2b\u4e3b\u4e49\u201d\u8303\u5f0f\u5411\u529f\u80fd\u4e3b\u4e49\u548c\u7ecf\u9a8c\u4e3b\u4e49\u7684\u7406\u8bba\u8f6c\u53d8\u3002"}}
{"id": "2602.08498", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08498", "abs": "https://arxiv.org/abs/2602.08498", "authors": ["Haoran Zhang", "Yafu Li", "Zhi Wang", "Zhilin Wang", "Shunkai Zhang", "Xiaoye Qu", "Yu Cheng"], "title": "Characterizing, Evaluating, and Optimizing Complex Reasoning", "comment": "Code and data are available at \\url{https://github.com/zzzhr97/TRM}", "summary": "Large Reasoning Models (LRMs) increasingly rely on reasoning traces with complex internal structures. However, existing work lacks a unified answer to three fundamental questions: (1) what defines high-quality reasoning, (2) how to reliably evaluate long, implicitly structured reasoning traces, and (3) how to use such evaluation signals for reasoning optimization. To address these challenges, we provide a unified perspective. (1) We introduce the ME$^2$ principle to characterize reasoning quality along macro- and micro-level concerning efficiency and effectiveness. (2) Built on this principle, we model reasoning traces as directed acyclic graphs (DAGs) and develop a DAG-based pairwise evaluation method, capturing complex reasoning structures. (3) Based on this method, we construct the TRM-Preference dataset and train a Thinking Reward Model (TRM) to evaluate reasoning quality at scale. Experiments show that thinking rewards serve as an effective optimization signal. At test time, selecting better reasoning leads to better outcomes (up to 19.3% gain), and during RL training, thinking rewards enhance reasoning and performance (up to 3.9% gain) across diverse tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eME\u00b2\u539f\u5219\u7684DAG\u63a8\u7406\u75d5\u8ff9\u5efa\u6a21\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8bad\u7ec3\u601d\u7ef4\u5956\u52b1\u6a21\u578b\u4f18\u5316\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u63a8\u7406\u8d28\u91cf\uff0c\u6709\u6548\u63d0\u5347\u6027\u80fd\u8868\u73b0\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u4e2d\u63a8\u7406\u8d28\u91cf\u5b9a\u4e49\u4e0d\u660e\u786e\u3001\u7f3a\u4e4f\u6709\u6548\u8bc4\u4f30\u957f\u4e14\u9690\u5f0f\u7ed3\u6784\u63a8\u7406\u75d5\u8ff9\u65b9\u6cd5\uff0c\u4ee5\u53ca\u96be\u4ee5\u5229\u7528\u8bc4\u4f30\u4fe1\u53f7\u4f18\u5316\u63a8\u7406\u4e09\u5927\u96be\u9898\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eME\u00b2\u539f\u5219\u7684\u6709\u5411\u65e0\u73af\u56fe\uff08DAG\uff09\u63a8\u7406\u75d5\u8ff9\u5efa\u6a21\uff0c\u8bbe\u8ba1DAG\u5bf9\u6bd4\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6784\u5efaTRM-Preference\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u601d\u7ef4\u5956\u52b1\u6a21\u578b\uff08TRM\uff09\u7528\u4e8e\u8bc4\u4ef7\u548c\u4f18\u5316\u63a8\u7406\u8fc7\u7a0b\u3002", "result": "\u601d\u7ef4\u5956\u52b1\u6a21\u578b\u4f5c\u4e3a\u6709\u6548\u4f18\u5316\u4fe1\u53f7\uff0c\u5728\u6d4b\u8bd5\u65f6\u9009\u62e9\u66f4\u4f18\u63a8\u7406\u63d0\u5347\u6700\u9ad819.3%\u6027\u80fd\uff0c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u65f6\u63d0\u5347\u63a8\u7406\u53ca\u4efb\u52a1\u6027\u80fd\u6700\u9ad83.9%\u3002", "conclusion": "\u5f15\u5165ME\u00b2\u539f\u5219\u5e76\u57fa\u4e8e\u6709\u5411\u65e0\u73af\u56fe\u5efa\u6a21\u63a8\u7406\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u63a8\u7406\u7ed3\u6784\u7684\u7edf\u4e00\u8bc4\u4f30\u548c\u4f18\u5316\uff0c\u6709\u6548\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u548c\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2602.08543", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08543", "abs": "https://arxiv.org/abs/2602.08543", "authors": ["Yutao Zhu", "Xingshuo Zhang", "Maosen Zhang", "Jiajie Jin", "Liancheng Zhang", "Xiaoshuai Song", "Kangzhi Zhao", "Wencong Zeng", "Ruiming Tang", "Han Li", "Ji-Rong Wen", "Zhicheng Dou"], "title": "GISA: A Benchmark for General Information-Seeking Assistant", "comment": null, "summary": "The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate such agents. However, existing benchmarks often construct queries backward from answers, producing unnatural tasks misaligned with real-world needs. Moreover, these benchmarks tend to focus on either locating specific information or aggregating information from multiple sources, while relying on static answer sets prone to data contamination. To bridge these gaps, we introduce GISA, a benchmark for General Information-Seeking Assistants comprising 373 human-crafted queries that reflect authentic information-seeking scenarios. GISA features four structured answer formats (item, set, list, and table), enabling deterministic evaluation. It integrates both deep reasoning and broad information aggregation within unified tasks, and includes a live subset with periodically updated answers to resist memorization. Notably, GISA provides complete human search trajectories for every query, offering gold-standard references for process-level supervision and imitation learning. Experiments on mainstream LLMs and commercial search products reveal that even the best-performing model achieves only 19.30\\% exact match score, with performance notably degrading on tasks requiring complex planning and comprehensive information gathering. These findings highlight substantial room for future improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9762\u5411\u771f\u5b9e\u4fe1\u606f\u641c\u7d22\u573a\u666f\u7684GISA\u57fa\u51c6\uff0c\u5305\u542b\u591a\u6837\u7b54\u6848\u683c\u5f0f\u548c\u52a8\u6001\u6570\u636e\uff0c\u5b9e\u9a8c\u8868\u660e\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u5b58\u5728\u663e\u8457\u63d0\u5347\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u6d4b\u57fa\u51c6\u5f80\u5f80\u4ece\u7b54\u6848\u53cd\u5411\u6784\u9020\u67e5\u8be2\uff0c\u4efb\u52a1\u4e0d\u81ea\u7136\u4e14\u4e0d\u7b26\u5408\u771f\u5b9e\u4e16\u754c\u9700\u6c42\uff0c\u540c\u65f6\u53ea\u5173\u6ce8\u5b9a\u4f4d\u4fe1\u606f\u6216\u805a\u5408\u4fe1\u606f\uff0c\u5b58\u5728\u6570\u636e\u6c61\u67d3\u95ee\u9898\u3002", "method": "\u63d0\u51faGISA\u57fa\u51c6\uff0c\u5305\u542b373\u4e2a\u4eba\u5de5\u67e5\u8be2\uff0c\u6db5\u76d6\u771f\u5b9e\u4fe1\u606f\u641c\u7d22\u573a\u666f\uff0c\u8bbe\u8ba1\u6709\u56db\u79cd\u7b54\u6848\u683c\u5f0f\uff0c\u7ed3\u5408\u6df1\u5ea6\u63a8\u7406\u548c\u5e7f\u6cdb\u4fe1\u606f\u805a\u5408\uff1b\u63d0\u4f9b\u5b9e\u65f6\u66f4\u65b0\u7684\u7b54\u6848\u4ee5\u9632\u6b62\u8bb0\u5fc6\u5316\uff0c\u5e76\u5305\u542b\u5b8c\u6574\u7684\u4eba\u7c7b\u641c\u7d22\u8f68\u8ff9\u4ee5\u652f\u6301\u8fc7\u7a0b\u76d1\u7763\u548c\u6a21\u4eff\u5b66\u4e60\u3002", "result": "\u5728\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5546\u7528\u641c\u7d22\u4ea7\u54c1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u5373\u4f7f\u662f\u8868\u73b0\u6700\u597d\u7684\u6a21\u578b\u51c6\u786e\u5339\u914d\u7387\u4ec5\u4e3a19.30%\uff0c\u590d\u6742\u89c4\u5212\u548c\u7efc\u5408\u4fe1\u606f\u805a\u5408\u4efb\u52a1\u8868\u73b0\u5c24\u4e3a\u5dee\uff0c\u663e\u793a\u6539\u8fdb\u7a7a\u95f4\u5de8\u5927\u3002", "conclusion": "GISA\u4f5c\u4e3a\u4e00\u4e2a\u66f4\u81ea\u7136\u4e14\u5168\u9762\u7684\u8bc4\u6d4b\u57fa\u51c6\uff0c\u6709\u6548\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u4fe1\u606f\u641c\u7d22\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u672a\u6765\u5927\u8bed\u8a00\u6a21\u578b\u548c\u641c\u7d22\u4ee3\u7406\u7684\u7814\u7a76\u4e0e\u63d0\u5347\u3002"}}
{"id": "2602.08548", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08548", "abs": "https://arxiv.org/abs/2602.08548", "authors": ["Xuanliang Zhang", "Dingzirui Wang", "Keyan Xu", "Qingfu Zhu", "Wanxiang Che"], "title": "How Do Language Models Understand Tables? A Mechanistic Analysis of Cell Location", "comment": null, "summary": "While Large Language Models (LLMs) are increasingly deployed for table-related tasks, the internal mechanisms enabling them to process linearized two-dimensional structured tables remain opaque. In this work, we investigate the process of table understanding by dissecting the atomic task of cell location. Through activation patching and complementary interpretability techniques, we delineate the table understanding mechanism into a sequential three-stage pipeline: Semantic Binding, Coordinate Localization, and Information Extraction. We demonstrate that models locate the target cell via an ordinal mechanism that counts discrete delimiters to resolve coordinates. Furthermore, column indices are encoded within a linear subspace that allows for precise steering of model focus through vector arithmetic. Finally, we reveal that models generalize to multi-cell location tasks by multiplexing the identical attention heads identified during atomic location. Our findings provide a comprehensive explanation of table understanding within Transformer architectures.", "AI": {"tldr": "\u8bba\u6587\u901a\u8fc7\u89e3\u6790\u6fc0\u6d3b\u6a21\u5f0f\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u4e8c\u7ef4\u8868\u683c\u7684\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u5b9a\u4f4d\u7ba1\u7ebf\uff0c\u4e3a\u8868\u683c\u76f8\u5173\u4efb\u52a1\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8868\u683c\u76f8\u5173\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5bf9\u4e8c\u7ef4\u7ed3\u6784\u5316\u8868\u683c\u5904\u7406\u7684\u5185\u90e8\u673a\u5236\u5c1a\u4e0d\u6e05\u6670\uff0c\u4e9f\u9700\u6df1\u5165\u7406\u89e3\u6a21\u578b\u5982\u4f55\u5b9e\u73b0\u8868\u683c\u7406\u89e3\u3002", "method": "\u91c7\u7528\u6fc0\u6d3b\u4fee\u8865\u548c\u8f85\u52a9\u53ef\u89e3\u91ca\u6027\u6280\u672f\uff0c\u5bf9\u6a21\u578b\u5185\u90e8\u673a\u5236\u8fdb\u884c\u5206\u6790\u89e3\u7801\uff0c\u8bc6\u522b\u548c\u5212\u5206\u8868\u683c\u7406\u89e3\u8fc7\u7a0b\u4e2d\u7684\u5173\u952e\u6b65\u9aa4\u53ca\u5176\u5b9e\u73b0\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u8868\u683c\u7406\u89e3\u8fc7\u7a0b\u53ef\u5206\u4e3a\u4e09\u9636\u6bb5\u7ba1\u7ebf\uff0c\u660e\u786e\u4e86\u6a21\u578b\u5982\u4f55\u901a\u8fc7\u8ba1\u6570\u79bb\u6563\u5206\u9694\u7b26\u5b9a\u4f4d\u5355\u5143\u683c\uff0c\u8bc6\u522b\u51fa\u7f16\u7801\u5217\u7d22\u5f15\u7684\u7ebf\u6027\u5b50\u7a7a\u95f4\uff0c\u4ee5\u53ca\u6ce8\u610f\u529b\u5934\u590d\u7528\u4ee5\u5b9e\u73b0\u591a\u5355\u5143\u683c\u5b9a\u4f4d\u7684\u80fd\u529b\u3002", "conclusion": "\u8be5\u8bba\u6587\u8be6\u7ec6\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7406\u89e3\u8868\u683c\u7684\u5185\u5728\u673a\u5236\uff0c\u62c6\u89e3\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a\u8bed\u4e49\u7ed1\u5b9a\u3001\u5750\u6807\u5b9a\u4f4d\u548c\u4fe1\u606f\u63d0\u53d6\u3002\u6a21\u578b\u901a\u8fc7\u8ba1\u6570\u5206\u9694\u7b26\u5b9e\u73b0\u5bf9\u5355\u5143\u683c\u7684\u7cbe\u786e\u5b9a\u4f4d\uff0c\u5217\u7d22\u5f15\u5728\u4e00\u4e2a\u7ebf\u6027\u5b50\u7a7a\u95f4\u5185\u7f16\u7801\uff0c\u652f\u6301\u901a\u8fc7\u5411\u91cf\u8fd0\u7b97\u7cbe\u51c6\u5f15\u5bfc\u6a21\u578b\u6ce8\u610f\u529b\u3002\u6b64\u5916\uff0c\u6a21\u578b\u8fd8\u901a\u8fc7\u590d\u7528\u76f8\u540c\u7684\u6ce8\u610f\u529b\u5934\uff0c\u5b9e\u73b0\u5bf9\u591a\u5355\u5143\u683c\u5b9a\u4f4d\u4efb\u52a1\u7684\u6cdb\u5316\u3002"}}
{"id": "2602.08600", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08600", "abs": "https://arxiv.org/abs/2602.08600", "authors": ["Archchana Sindhujan", "Girish A. Koushik", "Shenbin Qian", "Diptesh Kanojia", "Constantin Or\u0103san"], "title": "Beyond Scalar Scores: Reinforcement Learning for Error-Aware Quality Estimation of Machine Translation", "comment": "Currently this article is under review for Natural Language Processing Journal", "summary": "Quality Estimation (QE) aims to assess the quality of machine translation (MT) outputs without relying on reference translations, making it essential for real-world, large-scale MT evaluation. Large Language Models (LLMs) have shown significant promise in advancing the field of quality estimation of machine translation. However, most of the QE approaches solely rely on scalar quality scores, offering no explicit information about the translation errors that should drive these judgments. Moreover, for low-resource languages where annotated QE data is limited, existing approaches struggle to achieve reliable performance. To address these challenges, we introduce the first segment-level QE dataset for English to Malayalam, a severely resource-scarce language pair in the QE domain, comprising human-annotated Direct Assessment (DA) scores and Translation Quality Remarks (TQR), which are short, contextual, free-form annotator comments that describe translation errors. We further introduce ALOPE-RL, a policy-based reinforcement learning framework that trains efficient adapters based on policy rewards derived from DA score and TQR. Integrating error-aware rewards with ALOPE-RL, enables LLMs to reason about translation quality beyond numeric scores. Despite being trained on a small-scale QE dataset, ALOPE-RL achieves state-of-the-art performance on English to Malayalam QE using compact LLMs (<=4B parameters}) fine-tuned with LoRA and 4-bit quantization, outperforming both larger LLM-based baselines and leading encoder-based QE models. Our results demonstrate that error-aware, policy-based learning can deliver strong QE performance under limited data and compute budgets. We release our dataset, code, and trained models to support future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u82f1\u8bed\u5230\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u7684\u6bb5\u7ea7\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u6570\u636e\u96c6\u53ca\u57fa\u4e8e\u9519\u8bef\u611f\u77e5\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5ALOPE-RL\uff0c\u5b9e\u73b0\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u65b9\u6cd5\u591a\u6570\u4f9d\u8d56\u6807\u91cf\u5206\u6570\uff0c\u7f3a\u4e4f\u5bf9\u7ffb\u8bd1\u9519\u8bef\u7684\u663e\u5f0f\u63cf\u8ff0\uff0c\u4e14\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u4e2d\u8868\u73b0\u6b20\u4f73\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u5305\u542b\u9519\u8bef\u63cf\u8ff0\u7684\u65b0\u6570\u636e\u96c6\u548c\u9519\u8bef\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00QE\u7684\u6548\u679c\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6ALOPE-RL\uff0c\u7ed3\u5408\u4eba\u7c7b\u6ce8\u91ca\u7684\u76f4\u63a5\u8bc4\u4f30\u5206\u6570\u548c\u7ffb\u8bd1\u8d28\u91cf\u5907\u6ce8\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u8bad\u7ec3\u9ad8\u6548\u9002\u914d\u5668\uff0c\u5e76\u91c7\u7528LoRA\u5fae\u8c03\u548c4\u4f4d\u91cf\u5316\u6765\u63d0\u5347\u5c0f\u578b\u5927\u6a21\u578b\u7684QE\u8868\u73b0\u3002", "result": "ALOPE-RL\u5728\u82f1\u8bed-\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u8bc4\u4f30\u4efb\u52a1\u4e2d\uff0c\u5728\u4ec5\u6709\u7684\u5c0f\u89c4\u6a21\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u4f7f\u7528\u53c2\u6570\u5c11\u4e8e4B\u7684\u5c0f\u578b\u5927\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc7\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u548c\u5148\u8fdb\u7f16\u7801\u5668\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "ALOPE-RL\u65b9\u6cd5\u5229\u7528\u9519\u8bef\u611f\u77e5\u7684\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\uff0c\u5728\u6781\u5176\u6709\u9650\u7684\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0b\uff0c\u5b9e\u73b0\u4e86\u82f1\u8bed\u5230\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u673a\u5668\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u7684\u6700\u65b0\u6027\u80fd\uff0c\u8d85\u8fc7\u4e86\u66f4\u5927\u89c4\u6a21\u7684\u6a21\u578b\u548c\u4e3b\u6d41\u7f16\u7801\u5668\u57fa\u7840QE\u6a21\u578b\u3002"}}
{"id": "2602.08607", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08607", "abs": "https://arxiv.org/abs/2602.08607", "authors": ["Ziyang Cheng", "Yuhao Wang", "Heyang Liu", "Ronghua Wu", "Qunshan Gu", "Yanfeng Wang", "Yu Wang"], "title": "VocalNet-MDM: Accelerating Streaming Speech LLM via Self-Distilled Masked Diffusion Modeling", "comment": null, "summary": "Recent Speech Large Language Models~(LLMs) have achieved impressive capabilities in end-to-end speech interaction. However, the prevailing autoregressive paradigm imposes strict serial constraints, limiting generation efficiency and introducing exposure bias. In this paper, we investigate Masked Diffusion Modeling~(MDM) as a non-autoregressive paradigm for speech LLMs and introduce VocalNet-MDM. To adapt MDM for streaming speech interaction, we address two critical challenges: training-inference mismatch and iterative overhead. We propose Hierarchical Block-wise Masking to align training objectives with the progressive masked states encountered during block diffusion decoding, and Iterative Self-Distillation to compress multi-step refinement into fewer steps for low-latency inference. Trained on a limited scale of only 6K hours of speech data, VocalNet-MDM achieves a 3.7$\\times$--10$\\times$ decoding speedup and reduces first-chunk latency by 34\\% compared to AR baselines. It maintains competitive recognition accuracy while achieving state-of-the-art text quality and speech naturalness, demonstrating that MDM is a promising and scalable alternative for low-latency, efficient speech LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMasked Diffusion Modeling\u7684\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578bVocalNet-MDM\uff0c\u514b\u670d\u4e86\u81ea\u56de\u5f52\u6a21\u578b\u7684\u4e32\u884c\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u901f\u5ea6\u63d0\u5347\u548c\u5ef6\u8fdf\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u8bc6\u522b\u6027\u80fd\u548c\u8bed\u97f3\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\u666e\u904d\u91c7\u7528\u81ea\u56de\u5f52\u8303\u5f0f\uff0c\u5b58\u5728\u4e32\u884c\u751f\u6210\u6548\u7387\u4f4e\u548c\u66b4\u9732\u504f\u5dee\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u63a2\u7d22\u975e\u81ea\u56de\u5f52\u65b9\u6cd5\u4ee5\u63d0\u5347\u751f\u6210\u6548\u7387\u548c\u964d\u4f4e\u5ef6\u8fdf\u3002", "method": "\u91c7\u7528Masked Diffusion Modeling (MDM)\u4f5c\u4e3a\u975e\u81ea\u56de\u5f52\u8303\u5f0f\uff0c\u8bbe\u8ba1Hierarchical Block-wise Masking\u5bf9\u9f50\u8bad\u7ec3\u4e0e\u63a8\u7406\u8fc7\u7a0b\uff0c\u7ed3\u5408Iterative Self-Distillation\u538b\u7f29\u591a\u6b65\u8fed\u4ee3\u4ee5\u964d\u4f4e\u63a8\u7406\u5ef6\u8fdf\u3002", "result": "\u5728\u4ec5\u75286K\u5c0f\u65f6\u8bed\u97f3\u6570\u636e\u8bad\u7ec3\u4e0b\uff0cVocalNet-MDM\u76f8\u6bd4\u81ea\u56de\u5f52\u57fa\u7ebf\u6a21\u578b\uff0c\u5b9e\u73b03.7\u523010\u500d\u7684\u89e3\u7801\u901f\u5ea6\u63d0\u5347\uff0c\u9996\u5757\u5ef6\u8fdf\u964d\u4f4e34%\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u7684\u8bc6\u522b\u51c6\u786e\u7387\u548c\u66f4\u4f18\u7684\u6587\u672c\u8d28\u91cf\u4e0e\u8bed\u97f3\u81ea\u7136\u5ea6\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684\u57fa\u4e8eMasked Diffusion Modeling (MDM)\u7684VocalNet-MDM\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u81ea\u56de\u5f52\u6a21\u578b\u66f4\u9ad8\u7684\u751f\u6210\u6548\u7387\u548c\u66f4\u4f4e\u7684\u5ef6\u8fdf\uff0c\u540c\u65f6\u7ef4\u6301\u4e86\u7ade\u4e89\u529b\u7684\u8bc6\u522b\u51c6\u786e\u7387\u548c\u51fa\u8272\u7684\u6587\u672c\u8d28\u91cf\u53ca\u8bed\u97f3\u81ea\u7136\u6027\uff0c\u8868\u660eMDM\u662f\u4e00\u79cd\u6709\u524d\u666f\u7684\u4f4e\u5ef6\u8fdf\u9ad8\u6548\u8bed\u97f3\u5927\u8bed\u8a00\u6a21\u578b\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2602.08625", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08625", "abs": "https://arxiv.org/abs/2602.08625", "authors": ["Muhammad Naufil"], "title": "Do Multilingual LLMs have specialized language heads?", "comment": null, "summary": "Multilingual large language models (LLMs) have gained significant popularity for their ability to process and generate text across multiple languages. However, deploying these models in production can be inefficient when only a subset of the supported languages is of interest. There has been some research conducted on identifying whether machine translation models have language-specific or language-agnostic heads, however no research has been conducted for multilingual LLMs, to the best of our knowledge, that as we know are capable of performing diverse tasks beyond just translation. This paper explores whether multilingual LLMs have specialized language attention heads for each language, and investigates the possibility of removing language-specific heads for unwanted languages without degrading performance in the targeted languages. Our findings could inform more efficient deployment strategies for multilingual LLMs, enabling reduced model complexity while maintaining high accuracy for targeted languages.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8bed\u8a00\u4e13\u7528\u6ce8\u610f\u529b\u5934\uff0c\u8bc1\u660e\u79fb\u9664\u975e\u76ee\u6807\u8bed\u8a00\u5934\u80fd\u6709\u6548\u7b80\u5316\u6a21\u578b\u5e76\u4fdd\u6301\u6027\u80fd\uff0c\u63d0\u9ad8\u90e8\u7f72\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u5904\u7406\u591a\u8bed\u79cd\uff0c\u4f46\u90e8\u7f72\u6548\u7387\u4f4e\u4e0b\uff0c\u5c24\u5176\u5f53\u53ea\u5173\u6ce8\u90e8\u5206\u8bed\u8a00\u65f6\uff0c\u56e0\u6b64\u5e0c\u671b\u901a\u8fc7\u8bc6\u522b\u548c\u79fb\u9664\u975e\u76ee\u6807\u8bed\u8a00\u7684\u4e13\u7528\u7ed3\u6784\u5b9e\u73b0\u9ad8\u6548\u90e8\u7f72\u3002", "method": "\u901a\u8fc7\u5206\u6790\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6ce8\u610f\u529b\u5934\uff0c\u8bc6\u522b\u54ea\u4e9b\u662f\u8bed\u8a00\u7279\u5b9a\u7684\uff0c\u5e76\u5b9e\u9a8c\u79fb\u9664\u975e\u76ee\u6807\u8bed\u8a00\u7684\u4e13\u7528\u5934\u4ee5\u8bc4\u4f30\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u591a\u8bed\u8a00LLM\u5177\u6709\u8bed\u8a00\u4e13\u7528\u7684\u6ce8\u610f\u529b\u5934\uff0c\u79fb\u9664\u975e\u76ee\u6807\u8bed\u8a00\u4e13\u7528\u5934\u53ef\u964d\u4f4e\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u786e\u5b9e\u5b58\u5728\u9488\u5bf9\u7279\u5b9a\u8bed\u8a00\u7684\u6ce8\u610f\u529b\u5934\uff0c\u79fb\u9664\u975e\u76ee\u6807\u8bed\u8a00\u7684\u4e13\u7528\u6ce8\u610f\u529b\u5934\u53ef\u4ee5\u5728\u4e0d\u5f71\u54cd\u76ee\u6807\u8bed\u8a00\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u6a21\u578b\u7b80\u5316\u3002"}}
{"id": "2602.08658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08658", "abs": "https://arxiv.org/abs/2602.08658", "authors": ["Mingzi Cao", "Xingwei Tan", "Mahmud Akhter", "Marco Valentino", "Maria Liakata", "Xi Wang", "Nikolaos Aletras"], "title": "Fundamental Reasoning Paradigms Induce Out-of-Domain Generalization in Language Models", "comment": null, "summary": "Deduction, induction, and abduction are fundamental reasoning paradigms, core for human logical thinking. Although improving Large Language Model (LLM) reasoning has attracted significant research efforts, the extent to which the fundamental paradigms induce generalization has yet to be systematically explored. In this study, we shed light on how the interplay between these core paradigms influences LLMs' reasoning behavior. To this end, we first collect a new dataset of reasoning trajectories from symbolic tasks, each targeting one of the three fundamental paradigms, to abstract from concrete world knowledge. Then, we investigate effective ways for inducing these skills into LLMs. We experiment with a battery of methods including simple fine-tuning, and more complex approaches to increase model depth, or transform a dense model to a mixture-of-experts. We comprehensively evaluate induced models on realistic out-of-domain tasks, that are entirely formulated in natural language and contain real-world knowledge. Our results reveal that our approach yields strong generalizability with substantial performance gains (up to $14.60$) across realistic tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u6eaf\u56e0\u4e09\u5927\u63a8\u7406\u8303\u5f0f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u7b26\u53f7\u4efb\u52a1\u6570\u636e\u96c6\u8bf1\u5bfc\u6a21\u578b\u63a8\u7406\u6280\u80fd\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u73b0\u5b9e\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u53d7\u5230\u91cd\u89c6\uff0c\u4f46\u4e09\u5927\u57fa\u672c\u63a8\u7406\u8303\u5f0f\u5bf9\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u7684\u7cfb\u7edf\u5f71\u54cd\u5c1a\u672a\u88ab\u6df1\u5165\u63a2\u7a76\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u6536\u96c6\u57fa\u4e8e\u7b26\u53f7\u4efb\u52a1\u7684\u65b0\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u5b9e\u9a8c\u91c7\u7528\u7b80\u5355\u5fae\u8c03\u3001\u589e\u52a0\u6a21\u578b\u6df1\u5ea6\u53ca\u8f6c\u53d8\u4e3a\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u7b49\u591a\u79cd\u65b9\u6cd5\u8bf1\u5bfc\u63a8\u7406\u80fd\u529b\uff0c\u518d\u5728\u771f\u5b9e\u81ea\u7136\u8bed\u8a00\u7684\u5f00\u653e\u9886\u57df\u4efb\u52a1\u4e2d\u8fdb\u884c\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u8bf1\u5bfc\u63a8\u7406\u6280\u80fd\u7684\u65b9\u6cd5\u5e26\u6765\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5728\u591a\u4e2a\u73b0\u5b9e\u4efb\u52a1\u4e2d\u6700\u9ad8\u63d0\u6548\u8fbe14.60\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u6f14\u7ece\u3001\u5f52\u7eb3\u548c\u6eaf\u56e0\u4e09\u5927\u63a8\u7406\u8303\u5f0f\u5982\u4f55\u76f8\u4e92\u4f5c\u7528\u5f71\u54cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\uff0c\u5e76\u8bc1\u660e\u901a\u8fc7\u6709\u6548\u7684\u65b9\u6cd5\u8bf1\u5bfc\u8fd9\u4e9b\u63a8\u7406\u6280\u80fd\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08672", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08672", "abs": "https://arxiv.org/abs/2602.08672", "authors": ["Clemencia Siro", "Pourya Aliannejadi", "Mohammad Aliannejadi"], "title": "Learning to Judge: LLMs Designing and Applying Evaluation Rubrics", "comment": "Accepted at EACL 2026 Findings", "summary": "Large language models (LLMs) are increasingly used as evaluators for natural language generation, applying human-defined rubrics to assess system outputs. However, human rubrics are often static and misaligned with how models internally represent language quality. We introduce GER-Eval (Generating Evaluation Rubrics for Evaluation) to investigate whether LLMs can design and apply their own evaluation rubrics. We evaluate the semantic coherence and scoring reliability of LLM-defined criteria and their alignment with human criteria. LLMs reliably generate interpretable and task-aware evaluation dimensions and apply them consistently within models, but their scoring reliability degrades in factual and knowledge-intensive settings. Closed-source models such as GPT-4o achieve higher agreement and cross-model generalization than open-weight models such as Llama. Our findings position evaluation as a learned linguistic capability of LLMs, consistent within models but fragmented across them, and call for new methods that jointly model human and LLM evaluative language to improve reliability and interpretability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0LLMs\u53ef\u4ee5\u81ea\u751f\u6210\u8bc4\u4f30\u6807\u51c6\u5e76\u4e00\u81f4\u5e94\u7528\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u95f4\u5b58\u5728\u5dee\u5f02\uff0c\u95ed\u6e90\u6a21\u578b\u8868\u73b0\u66f4\u597d\uff0c\u63d0\u793a\u672a\u6765\u9700\u878d\u5408\u4eba\u7c7b\u548cLLM\u8bc4\u4f30\u8bed\u8a00\u63d0\u9ad8\u8bc4\u4f30\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u4eba\u7c7b\u5b9a\u4e49\u7684\u8bc4\u5206\u6807\u51c6\u9759\u6001\u4e14\u4e0e\u6a21\u578b\u7684\u5185\u90e8\u8bed\u8a00\u8d28\u91cf\u8868\u793a\u4e0d\u4e00\u81f4\uff0c\u63a2\u7d22LLMs\u662f\u5426\u80fd\u81ea\u4e3b\u8bbe\u8ba1\u548c\u5e94\u7528\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u63d0\u51faGER-Eval\u6846\u67b6\uff0c\u8ba9LLMs\u751f\u6210\u5e76\u5e94\u7528\u81ea\u5df1\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u68c0\u9a8c\u5176\u8bed\u4e49\u8fde\u8d2f\u6027\u548c\u8bc4\u5206\u53ef\u9760\u6027\uff0c\u5e76\u4e0e\u4eba\u5de5\u6807\u51c6\u5bf9\u6bd4\u3002", "result": "LLMs\u80fd\u591f\u751f\u6210\u53ef\u89e3\u91ca\u3001\u4efb\u52a1\u611f\u77e5\u7684\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u4e14\u5728\u6a21\u578b\u5185\u90e8\u8bc4\u5206\u4e00\u81f4\u6027\u9ad8\uff0c\u4f46\u5728\u4e8b\u5b9e\u4e0e\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e2d\u8bc4\u5206\u53ef\u9760\u6027\u4e0b\u964d\u3002\u95ed\u6e90\u6a21\u578b\u5982GPT-4o\u8868\u73b0\u4f18\u4e8eLlama\u3002", "conclusion": "LLMs\u80fd\u591f\u81ea\u751f\u6210\u8bc4\u4f30\u6807\u51c6\uff0c\u5e76\u5728\u6a21\u578b\u5185\u90e8\u4e00\u81f4\u5e94\u7528\uff0c\u4f46\u5728\u6d89\u53ca\u4e8b\u5b9e\u548c\u77e5\u8bc6\u5bc6\u96c6\u7684\u4efb\u52a1\u4e2d\u8bc4\u5206\u53ef\u9760\u6027\u4e0b\u964d\u3002\u4e0d\u540c\u6a21\u578b\u95f4\u6807\u51c6\u5b58\u5728\u5dee\u5f02\uff0c\u95ed\u6e90\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\u3002"}}
{"id": "2602.08688", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08688", "abs": "https://arxiv.org/abs/2602.08688", "authors": ["Hossein Kermani", "Fatemeh Oudlajani", "Pardis Yarahmadi", "Hamideh Mahdi Soltani", "Mohammad Makki", "Zahra HosseiniKhoo"], "title": "Old wine in old glasses: Comparing computational and qualitative methods in identifying incivility on Persian Twitter during the #MahsaAmini movement", "comment": null, "summary": "This paper compares three approaches to detecting incivility in Persian tweets: human qualitative coding, supervised learning with ParsBERT, and large language models (ChatGPT). Using 47,278 tweets from the #MahsaAmini movement in Iran, we evaluate the accuracy and efficiency of each method. ParsBERT substantially outperforms seven evaluated ChatGPT models in identifying hate speech. We also find that ChatGPT struggles not only with subtle cases but also with explicitly uncivil content, and that prompt language (English vs. Persian) does not meaningfully affect its outputs. The study provides a detailed comparison of these approaches and clarifies their strengths and limitations for analyzing hate speech in a low-resource language context.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u4eba\u5de5\u7f16\u7801\u3001ParsBERT\u548cChatGPT\u4e09\u79cd\u65b9\u6cd5\u68c0\u6d4b\u6ce2\u65af\u8bed\u4e0d\u6587\u660e\u63a8\u6587\u7684\u6548\u679c\uff0c\u53d1\u73b0ParsBERT\u8868\u73b0\u6700\u597d\uff0cChatGPT\u8868\u73b0\u8f83\u5dee\u4e14\u8bed\u8a00\u63d0\u793a\u5f71\u54cd\u6709\u9650\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u6bd4\u8f83\u4e0d\u540c\u65b9\u6cd5\u68c0\u6d4b\u6ce2\u65af\u8bed\u63a8\u6587\u4e2d\u7684\u4e0d\u6587\u660e\u8a00\u8bba\uff0c\u5c24\u5176\u662f\u5728\u8d44\u6e90\u8f83\u5c11\u7684\u8bed\u8a00\u73af\u5883\u4e0b\uff0c\u63d0\u4f9b\u65b9\u6cd5\u9009\u62e9\u7684\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u65b9\u6cd5\u5bf947,278\u6761\u4f0a\u6717#MahsaAmini\u8fd0\u52a8\u76f8\u5173\u63a8\u6587\u8fdb\u884c\u5206\u6790\uff1a\u4eba\u5de5\u5b9a\u6027\u7f16\u7801\u3001\u57fa\u4e8eParsBERT\u7684\u76d1\u7763\u5b66\u4e60\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08ChatGPT\uff09\u3002", "result": "ParsBERT\u7684\u8868\u73b0\u660e\u663e\u4f18\u4e8e\u4e03\u4e2aChatGPT\u6a21\u578b\uff0c\u540e\u8005\u5728\u8bc6\u522b\u4ec7\u6068\u8a00\u8bba\u65b9\u9762\u8868\u73b0\u8f83\u5f31\uff0c\u4e14\u63d0\u793a\u8bed\u8a00\uff08\u82f1\u8bed\u4e0e\u6ce2\u65af\u8bed\uff09\u5bf9ChatGPT\u8f93\u51fa\u5f71\u54cd\u4e0d\u5927\u3002", "conclusion": "\u5728\u68c0\u6d4b\u6ce2\u65af\u8bed\u63a8\u6587\u4e2d\u7684\u4ec7\u6068\u8a00\u8bba\u65f6\uff0c\u57fa\u4e8eParsBERT\u7684\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u66f4\u5177\u51c6\u786e\u6027\u548c\u6548\u7387\uff0cChatGPT\u5b58\u5728\u660e\u663e\u5c40\u9650\u3002"}}
{"id": "2602.08698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08698", "abs": "https://arxiv.org/abs/2602.08698", "authors": ["Basudha Raje", "Sadanand Venkatraman", "Nandana TP", "Soumyadeepa Das", "Polkam Poojitha", "M. Vijaykumar", "Tanima Bagchi", "Hema A. Murthy"], "title": "Challenges in Translating Technical Lectures: Insights from the NPTEL", "comment": null, "summary": "This study examines the practical applications and methodological implications of Machine Translation in Indian Languages, specifically Bangla, Malayalam, and Telugu, within emerging translation workflows and in relation to existing evaluation frameworks. The choice of languages prioritized in this study is motivated by a triangulation of linguistic diversity, which illustrates the significance of multilingual accommodation of educational technology under NEP 2020. This is further supported by the largest MOOC portal, i.e., NPTEL, which has served as a corpus to facilitate the arguments presented in this paper. The curation of a spontaneous speech corpora that accounts for lucid delivery of technical concepts, considering the retention of suitable register and lexical choices are crucial in a diverse country like India. The findings of this study highlight metric-specific sensitivity and the challenges of morphologically rich and semantically compact features when tested against surface overlapping metrics.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63a2\u8ba8\u4e86\u5370\u5ea6\u4e09\u79cd\u8bed\u8a00\u7684\u673a\u5668\u7ffb\u8bd1\u53ca\u5176\u8bc4\u4f30\uff0c\u5f3a\u8c03\u73b0\u6709\u6307\u6807\u5bf9\u8bed\u8a00\u5f62\u6001\u548c\u8bed\u4e49\u7684\u9002\u5e94\u6027\u4e0d\u8db3\uff0c\u547c\u5401\u9488\u5bf9\u5370\u5ea6\u8bed\u8a00\u7279\u70b9\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u5370\u5ea6\u591a\u8bed\u8a00\u80cc\u666f\u4e0b\uff0c\u6559\u80b2\u6280\u672f\u9700\u652f\u6301\u591a\u8bed\u79cd\uff0c\u5c24\u5176\u662f\u5728NEP 2020\u653f\u7b56\u63a8\u52a8\u4e0b\uff0c\u673a\u5668\u7ffb\u8bd1\u6280\u672f\u5728\u672c\u5730\u5316\u6559\u80b2\u5185\u5bb9\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u9009\u53d6\u5b5f\u52a0\u62c9\u8bed\u3001\u9a6c\u62c9\u96c5\u62c9\u59c6\u8bed\u548c\u6cf0\u5362\u56fa\u8bed\u4e09\u79cd\u5370\u5ea6\u8bed\u8a00\uff0c\u5229\u7528\u6700\u5927MOOC\u5e73\u53f0NPTEL\u7684\u81ea\u53d1\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u6307\u6807\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u5f53\u524d\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u6307\u6807\u5bf9\u5f62\u6001\u590d\u6742\u548c\u8bed\u4e49\u5bc6\u96c6\u7684\u5370\u5ea6\u8bed\u8a00\u654f\u611f\u5ea6\u4e0d\u591f\uff0c\u8868\u73b0\u51fa\u65b9\u6cd5\u8bba\u4e0a\u7684\u5c40\u9650\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u5728\u591a\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u4e2d\uff0c\u9488\u5bf9\u5f62\u6001\u4e30\u5bcc\u548c\u8bed\u4e49\u7d27\u51d1\u8bed\u8a00\u7684\u4f20\u7edf\u8868\u9762\u91cd\u53e0\u8bc4\u4f30\u6307\u6807\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u9488\u5bf9\u6027\u6539\u8fdb\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2602.08700", "categories": ["cs.CL", "cs.HC", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08700", "abs": "https://arxiv.org/abs/2602.08700", "authors": ["Clemencia Siro", "Zahra Abbasiantaeb", "Yifei Yuan", "Mohammad Aliannejadi", "Maarten de Rijke"], "title": "Do Images Clarify? A Study on the Effect of Images on Clarifying Questions in Conversational Search", "comment": "Accepted at CHIIR 2025", "summary": "Conversational search systems increasingly employ clarifying questions to refine user queries and improve the search experience. Previous studies have demonstrated the usefulness of text-based clarifying questions in enhancing both retrieval performance and user experience. While images have been shown to improve retrieval performance in various contexts, their impact on user performance when incorporated into clarifying questions remains largely unexplored. We conduct a user study with 73 participants to investigate the role of images in conversational search, specifically examining their effects on two search-related tasks: (i) answering clarifying questions and (ii) query reformulation. We compare the effect of multimodal and text-only clarifying questions in both tasks within a conversational search context from various perspectives. Our findings reveal that while participants showed a strong preference for multimodal questions when answering clarifying questions, preferences were more balanced in the query reformulation task. The impact of images varied with both task type and user expertise. In answering clarifying questions, images helped maintain engagement across different expertise levels, while in query reformulation they led to more precise queries and improved retrieval performance. Interestingly, for clarifying question answering, text-only setups demonstrated better user performance as they provided more comprehensive textual information in the absence of images. These results provide valuable insights for designing effective multimodal conversational search systems, highlighting that the benefits of visual augmentation are task-dependent and should be strategically implemented based on the specific search context and user characteristics.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7528\u6237\u5b9e\u9a8c\u63a2\u8ba8\u56fe\u50cf\u5728\u5bf9\u8bdd\u5f0f\u641c\u7d22\u6f84\u6e05\u95ee\u9898\u4e2d\u7684\u4f5c\u7528\uff0c\u53d1\u73b0\u89c6\u89c9\u8f85\u52a9\u6548\u679c\u4f9d\u4efb\u52a1\u548c\u7528\u6237\u800c\u5f02\uff0c\u8bbe\u8ba1\u591a\u6a21\u6001\u5bf9\u8bdd\u641c\u7d22\u7cfb\u7edf\u65f6\u9700\u8003\u8651\u5177\u4f53\u641c\u7d22\u4efb\u52a1\u548c\u7528\u6237\u7279\u6027\u3002", "motivation": "\u5c3d\u7ba1\u6587\u672c\u6f84\u6e05\u95ee\u9898\u5df2\u88ab\u8bc1\u660e\u6709\u52a9\u4e8e\u63d0\u5347\u68c0\u7d22\u6027\u80fd\u548c\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u56fe\u50cf\u4f5c\u4e3a\u6f84\u6e05\u95ee\u9898\u7684\u8f85\u52a9\u5de5\u5177\u5bf9\u7528\u6237\u8868\u73b0\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5bf973\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u7528\u6237\u7814\u7a76\uff0c\u6bd4\u8f83\u591a\u6a21\u6001\uff08\u56fe\u6587\uff09\u4e0e\u7eaf\u6587\u672c\u6f84\u6e05\u95ee\u9898\u5728\u5bf9\u6f84\u6e05\u95ee\u9898\u56de\u7b54\u548c\u67e5\u8be2\u91cd\u6784\u4e24\u79cd\u641c\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u53c2\u4e0e\u8005\u5728\u56de\u7b54\u6f84\u6e05\u95ee\u9898\u65f6\u66f4\u504f\u597d\u591a\u6a21\u6001\uff0c\u67e5\u8be2\u91cd\u6784\u65f6\u504f\u597d\u5747\u8861\uff1b\u56fe\u50cf\u6709\u52a9\u4e8e\u7ef4\u6301\u4e0d\u540c\u4e13\u4e1a\u7a0b\u5ea6\u7528\u6237\u7684\u53c2\u4e0e\u5ea6\uff0c\u4fc3\u8fdb\u66f4\u7cbe\u786e\u67e5\u8be2\u7684\u751f\u6210\u53ca\u68c0\u7d22\u6027\u80fd\u63d0\u5347\uff1b\u4f46\u5728\u6f84\u6e05\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e2d\uff0c\u7eaf\u6587\u672c\u63d0\u4f9b\u66f4\u5168\u9762\u4fe1\u606f\uff0c\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u591a\u6a21\u6001\u7684\u6f84\u6e05\u95ee\u9898\u5728\u56de\u7b54\u6f84\u6e05\u95ee\u9898\u7684\u4efb\u52a1\u4e2d\u53d7\u5230\u7528\u6237\u504f\u597d\uff0c\u800c\u5728\u67e5\u8be2\u91cd\u6784\u4efb\u52a1\u4e2d\u504f\u597d\u8f83\u5747\u8861\uff0c\u89c6\u89c9\u589e\u5f3a\u7684\u6548\u679c\u53d7\u4efb\u52a1\u7c7b\u578b\u548c\u7528\u6237\u4e13\u4e1a\u7a0b\u5ea6\u5f71\u54cd\u3002\u6587\u672c\u4fe1\u606f\u7f3a\u5931\u7684\u60c5\u51b5\u4e0b\uff0c\u7eaf\u6587\u672c\u6f84\u6e05\u95ee\u9898\u5728\u7528\u6237\u8868\u73b0\u4e0a\u66f4\u4f18\u3002"}}
{"id": "2602.08709", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08709", "abs": "https://arxiv.org/abs/2602.08709", "authors": ["Leandro Anghinoni", "Jorge Sanchez"], "title": "FactSim: Fact-Checking for Opinion Summarization", "comment": "10 pages, 4 figures", "summary": "We explore the need for more comprehensive and precise evaluation techniques for generative artificial intelligence (GenAI) in text summarization tasks, specifically in the area of opinion summarization. Traditional methods, which leverage automated metrics to compare machine-generated summaries from a collection of opinion pieces, e.g. product reviews, have shown limitations due to the paradigm shift introduced by large language models (LLM). This paper addresses these shortcomings by proposing a novel, fully automated methodology for assessing the factual consistency of such summaries. The method is based on measuring the similarity between the claims in a given summary with those from the original reviews, measuring the coverage and consistency of the generated summary. To do so, we rely on a simple approach to extract factual assessment from texts that we then compare and summarize in a suitable score. We demonstrate that the proposed metric attributes higher scores to similar claims, regardless of whether the claim is negated, paraphrased, or expanded, and that the score has a high correlation to human judgment when compared to state-of-the-art metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6587\u672c\u4e8b\u5b9e\u9648\u8ff0\u76f8\u4f3c\u5ea6\u7684\u5168\u81ea\u52a8\u6307\u6807\uff0c\u6709\u6548\u63d0\u5347\u4e86\u751f\u6210\u89c2\u70b9\u6458\u8981\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u8bc4\u4f30\uff0c\u4e0e\u4eba\u5de5\u8bc4\u4ef7\u9ad8\u5ea6\u4e00\u81f4\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f15\u5165\u7684\u8303\u5f0f\u8f6c\u53d8\uff0c\u5bfc\u81f4\u8bc4\u4f30\u751f\u6210\u6458\u8981\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u901a\u8fc7\u63d0\u53d6\u6458\u8981\u4e0e\u539f\u59cb\u8bc4\u8bba\u4e2d\u7684\u9648\u8ff0\uff0c\u8861\u91cf\u5176\u76f8\u4f3c\u6027\u4ee5\u8bc4\u4f30\u8986\u76d6\u5ea6\u548c\u4e00\u81f4\u6027\uff0c\u6700\u7ec8\u751f\u6210\u4e00\u4e2a\u7efc\u5408\u5f97\u5206\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5bf9\u76f8\u4f3c\u8a00\u8bba\u7ed9\u51fa\u8f83\u9ad8\u8bc4\u5206\uff0c\u65e0\u8bba\u662f\u5426\u662f\u5426\u5b9a\u3001\u610f\u8bd1\u6216\u6269\u5c55\uff0c\u4e14\u5176\u8bc4\u5206\u4e0e\u4eba\u5de5\u5224\u65ad\u9ad8\u5ea6\u76f8\u5173\uff0c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6307\u6807\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u81ea\u52a8\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30\u751f\u6210\u6587\u672c\u6458\u8981\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u7279\u522b\u9002\u7528\u4e8e\u610f\u89c1\u6458\u8981\u4efb\u52a1\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u81ea\u52a8\u8bc4\u4f30\u6307\u6807\u7684\u5c40\u9650\u3002"}}
{"id": "2602.08716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08716", "abs": "https://arxiv.org/abs/2602.08716", "authors": ["Shangrui Nie", "Kian Omoomi", "Lucie Flek", "Zhixue Zhao", "Charles Welch"], "title": "PERSPECTRA: A Scalable and Configurable Pluralist Benchmark of Perspectives from Arguments", "comment": "15 pages, 1 figure", "summary": "Pluralism, the capacity to engage with diverse perspectives without collapsing them into a single viewpoint, is critical for developing large language models that faithfully reflect human heterogeneity. Yet this characteristic has not been carefully examined in the LLM research community and remains absent from most alignment studies. Debate-oriented sources provide a natural entry point for pluralism research. Previous work builds on online debate sources but remains constrained by costly human validation. Other debate-rich platforms such as Reddit and Kialo also offer promising material: Reddit provides linguistic diversity and scale but lacks clear argumentative structure, while Kialo supplies explicit pro/con graphs but remains overly concise and detached from natural discourse. We introduce PERSPECTRA, a pluralist benchmark that integrates the structural clarity of Kialo debate graphs with the linguistic diversity of real Reddit discussions. Using a controlled retrieval-and-expansion pipeline, we construct 3,810 enriched arguments spanning 762 pro/con stances on 100 controversial topics. Each opinion is expanded to multiple naturalistic variants, enabling robust evaluation of pluralism. We initialise three tasks with PERSPECTRA: opinion counting (identifying distinct viewpoints), opinion matching (aligning supporting stances and discourse to source opinions), and polarity check (inferring aggregate stance in mixed discourse). Experiments with state-of-the-art open-source and proprietary LLMs, highlight systematic failures, such as overestimating the number of viewpoints and misclassifying concessive structures, underscoring the difficulty of pluralism-aware understanding and reasoning. By combining diversity with structure, PERSPECTRA establishes the first scalable, configurable benchmark for evaluating how well models represent, distinguish, and reason over multiple perspectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPERSPECTRA\u57fa\u51c6\uff0c\u7ed3\u5408Reddit\u548cKialo\u6570\u636e\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u591a\u5143\u89c2\u70b9\u7684\u8bc6\u522b\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u591a\u89c6\u89d2\u7406\u89e3\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u9700\u8981\u51c6\u786e\u53cd\u6620\u4eba\u7c7b\u591a\u6837\u5316\u89c2\u70b9\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u591a\u5143\u4e3b\u4e49\u7279\u5f81\u7684\u7cfb\u7edf\u8003\u5bdf\uff0c\u73b0\u6709\u8fa9\u8bba\u6570\u636e\u5b58\u5728\u9a8c\u8bc1\u6210\u672c\u9ad8\u6216\u7ed3\u6784\u4e0d\u5b8c\u6574\u7b49\u95ee\u9898\uff0c\u4fc3\u4f7f\u6784\u5efa\u7ed3\u5408\u591a\u6837\u6027\u4e0e\u7ed3\u6784\u6027\u7684\u591a\u5143\u89c2\u70b9\u8bc4\u6d4b\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u6574\u5408Kialo\u8fa9\u8bba\u56fe\u7684\u7ed3\u6784\u6e05\u6670\u5ea6\u4e0eReddit\u8ba8\u8bba\u7684\u8bed\u8a00\u591a\u6837\u6027\uff0c\u6784\u5efa\u4e863810\u4e2a\u4e30\u5bcc\u89c2\u70b9\uff0c\u6db5\u76d6762\u4e2a\u6b63\u53cd\u7acb\u573a\u548c100\u4e2a\u4e89\u8bae\u8bdd\u9898\uff0c\u5e76\u8bbe\u8ba1\u4e86\u89c2\u70b9\u8ba1\u6570\u3001\u89c2\u70b9\u5339\u914d\u548c\u6781\u6027\u68c0\u6d4b\u4e09\u9879\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6784\u5efa\u4e86\u878d\u5408\u7ed3\u6784\u548c\u8bed\u8a00\u591a\u6837\u6027\u7684PERSPECTRA\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u591a\u4efb\u52a1\u8bc4\u6d4b\u6846\u67b6\uff0c\u5b9e\u9a8c\u63ed\u793a\u4e3b\u6d41\u5f00\u6e90\u53ca\u4e13\u6709\u5927\u6a21\u578b\u5728\u89c2\u70b9\u6570\u91cf\u4f30\u7b97\u4e0e\u8ba9\u6b65\u7ed3\u6784\u5206\u7c7b\u4e0a\u7684\u7cfb\u7edf\u6027\u5931\u8bef\uff0c\u9a8c\u8bc1\u4e86\u591a\u5143\u4e3b\u4e49\u7406\u89e3\u7684\u6311\u6218\u6027\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u53ef\u6269\u5c55\u4e14\u53ef\u914d\u7f6e\u7684\u591a\u5143\u89c2\u70b9\u8bc4\u4f30\u57fa\u51c6PERSPECTRA\uff0c\u4ee5\u6709\u6548\u8bc4\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u89c6\u89d2\u8868\u793a\u4e0e\u63a8\u7406\u4e2d\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u5f53\u524d\u5148\u8fdb\u6a21\u578b\u5728\u591a\u5143\u89c2\u70b9\u8bc6\u522b\u4e0e\u7406\u89e3\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u8db3\u3002"}}
{"id": "2602.08740", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08740", "abs": "https://arxiv.org/abs/2602.08740", "authors": ["Gaifan Zhang", "Danushka Bollegala"], "title": "Map of Encoders -- Mapping Sentence Encoders using Quantum Relative Entropy", "comment": null, "summary": "We propose a method to compare and visualise sentence encoders at scale by creating a map of encoders where each sentence encoder is represented in relation to the other sentence encoders. Specifically, we first represent a sentence encoder using an embedding matrix of a sentence set, where each row corresponds to the embedding of a sentence. Next, we compute the Pairwise Inner Product (PIP) matrix for a sentence encoder using its embedding matrix. Finally, we create a feature vector for each sentence encoder reflecting its Quantum Relative Entropy (QRE) with respect to a unit base encoder. We construct a map of encoders covering 1101 publicly available sentence encoders, providing a new perspective of the landscape of the pre-trained sentence encoders. Our map accurately reflects various relationships between encoders, where encoders with similar attributes are proximally located on the map. Moreover, our encoder feature vectors can be used to accurately infer downstream task performance of the encoders, such as in retrieval and clustering tasks, demonstrating the faithfulness of our map.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u91cf\u5b50\u76f8\u5bf9\u71b5\u6784\u5efa\u53e5\u5b50\u7f16\u7801\u5668\u7279\u5f81\u5411\u91cf\u5e76\u6620\u5c041101\u4e2a\u7f16\u7801\u5668\uff0c\u51c6\u786e\u53cd\u6620\u5176\u76f8\u4f3c\u5ea6\u548c\u9884\u6d4b\u4efb\u52a1\u6027\u80fd\uff0c\u52a9\u529b\u7f16\u7801\u5668\u6bd4\u8f83\u4e0e\u9009\u62e9\u3002", "motivation": "\u5f53\u524d\u5b58\u5728\u5927\u91cf\u9884\u8bad\u7ec3\u53e5\u5b50\u7f16\u7801\u5668\uff0c\u7f3a\u4e4f\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\u6765\u6bd4\u8f83\u548c\u76f4\u89c2\u5c55\u793a\u5b83\u4eec\u4e4b\u95f4\u7684\u5173\u7cfb\u3002", "method": "\u63d0\u51fa\u901a\u8fc7\u6784\u5efa\u53e5\u5b50\u96c6\u7684\u5d4c\u5165\u77e9\u9635\uff0c\u8ba1\u7b97\u6210\u5bf9\u5185\u79ef\u77e9\u9635\uff08PIP\uff09\uff0c\u5e76\u5229\u7528\u91cf\u5b50\u76f8\u5bf9\u71b5\uff08QRE\uff09\u76f8\u5bf9\u4e8e\u57fa\u51c6\u7f16\u7801\u5668\u751f\u6210\u7279\u5f81\u5411\u91cf\uff0c\u4ece\u800c\u6784\u5efa\u7f16\u7801\u5668\u4e4b\u95f4\u7684\u6620\u5c04\u3002", "result": "\u6784\u5efa\u4e86\u6db5\u76d61101\u4e2a\u516c\u5f00\u53e5\u5b50\u7f16\u7801\u5668\u7684\u5730\u56fe\uff0c\u8be5\u5730\u56fe\u51c6\u786e\u53cd\u6620\u4e86\u7f16\u7801\u5668\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c5e\u6027\u76f8\u8fd1\u7684\u7f16\u7801\u5668\u5728\u5730\u56fe\u4e0a\u4f4d\u7f6e\u76f8\u8fd1\uff0c\u5e76\u4e14\u7279\u5f81\u5411\u91cf\u80fd\u6709\u6548\u9884\u6d4b\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5927\u89c4\u6a21\u6bd4\u8f83\u548c\u53ef\u89c6\u5316\u53e5\u5b50\u7f16\u7801\u5668\u7684\u6709\u6548\u624b\u6bb5\uff0c\u80fd\u591f\u63ed\u793a\u7f16\u7801\u5668\u4e4b\u95f4\u7684\u5185\u5728\u5173\u7cfb\u5e76\u8f85\u52a9\u9884\u6d4b\u5176\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2602.08793", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2602.08793", "abs": "https://arxiv.org/abs/2602.08793", "authors": ["Yushi Sun", "Xujia Li", "Nan Tang", "Quanqing Xu", "Chuanhui Yang", "Lei Chen"], "title": "LakeHopper: Cross Data Lakes Column Type Annotation through Model Adaptation", "comment": null, "summary": "Column type annotation is vital for tasks like data cleaning, integration, and visualization. Recent solutions rely on resource-intensive language models fine-tuned on well-annotated columns from a particular set of tables, i.e., a source data lake. In this paper, we study whether we can adapt an existing pre-trained LM-based model to a new (i.e., target) data lake to minimize the annotations required on the new data lake. However, challenges include the source-target knowledge gap, selecting informative target data, and fine-tuning without losing shared knowledge exist. We propose LakeHopper, a framework that identifies and resolves the knowledge gap through LM interactions, employs a cluster-based data selection scheme for unannotated columns, and uses an incremental fine-tuning mechanism that gradually adapts the source model to the target data lake. Our experimental results validate the effectiveness of LakeHopper on two different data lake transfers under both low-resource and high-resource settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLakeHopper\uff0c\u4e00\u4e2a\u901a\u8fc7\u77e5\u8bc6\u5dee\u8ddd\u8c03\u8282\u3001\u6837\u672c\u9009\u62e9\u548c\u589e\u91cf\u5fae\u8c03\u5b9e\u73b0\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u65b0\u6570\u636e\u6e56\u9ad8\u6548\u8fc1\u79fb\u7684\u6846\u67b6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u6807\u6ce8\u5de5\u4f5c\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u8d44\u6e90\u5bc6\u96c6\u578b\u7684\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u4e14\u9700\u8981\u5927\u91cf\u7279\u5b9a\u6570\u636e\u6e56\u7684\u6807\u6ce8\u5217\uff0c\u5982\u4f55\u5728\u65b0\u6570\u636e\u6e56\u4e0a\u6700\u5c0f\u5316\u6ce8\u91ca\u9700\u6c42\u3001\u6709\u6548\u8fc1\u79fb\u9884\u8bad\u7ec3\u6a21\u578b\u6210\u4e3a\u6311\u6218\u3002", "method": "\u63d0\u51faLakeHopper\u6846\u67b6\uff0c\u5305\u62ec\u901a\u8fc7\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u8bc6\u522b\u5e76\u89e3\u51b3\u77e5\u8bc6\u5dee\u8ddd\u3001\u57fa\u4e8e\u805a\u7c7b\u7684\u6570\u636e\u9009\u62e9\u7b56\u7565\u4ee5\u53ca\u9010\u6b65\u5fae\u8c03\u7684\u589e\u91cf\u9002\u914d\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u5728\u4e24\u79cd\u4e0d\u540c\u6570\u636e\u6e56\u8fc1\u79fb\u573a\u666f\u4e0b\u9a8c\u8bc1\u4e86LakeHopper\u7684\u6709\u6548\u6027\uff0c\u8868\u73b0\u51fa\u5728\u4f4e\u8d44\u6e90\u548c\u9ad8\u8d44\u6e90\u73af\u5883\u4e0b\u5747\u80fd\u5b9e\u73b0\u826f\u597d\u7684\u9002\u914d\u548c\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "LakeHopper\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6e90\u6570\u636e\u6e56\u548c\u76ee\u6807\u6570\u636e\u6e56\u4e4b\u95f4\u7684\u77e5\u8bc6\u5dee\u8ddd\uff0c\u5b9e\u73b0\u4e86\u5728\u76ee\u6807\u6570\u636e\u6e56\u4e0a\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5217\u7c7b\u578b\u6807\u6ce8\u7684\u6709\u6548\u9002\u914d\uff0c\u51cf\u5c11\u4e86\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002"}}
{"id": "2602.08826", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08826", "abs": "https://arxiv.org/abs/2602.08826", "authors": ["Chenghui Zou", "Ning Wang", "Tiesunlong Shen", "Luwei Xiao", "Chuan Ma", "Xiangpeng Li", "Rui Mao", "Erik Cambria"], "title": "Affective Flow Language Model for Emotional Support Conversation", "comment": "19 pages, 7 figures", "summary": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684AFlow\u6846\u67b6\u901a\u8fc7\u7ec6\u7c92\u5ea6\u60c5\u611f\u6d41\u5efa\u6a21\u548c\u5b50\u8def\u5f84\u5c42\u7ea7\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u591a\u8f6e\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u7684\u7b56\u7565\u4e00\u81f4\u6027\u548c\u5171\u60c5\u6548\u679c\uff0c\u4f18\u4e8e\u591a\u79cd\u4e3b\u6d41\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u7a00\u758f\u7684\u7ed3\u679c\u7ea7\u4fe1\u53f7\uff0c\u96be\u4ee5\u6709\u6548\u6307\u5bfc\u4e2d\u95f4\u7b56\u7565\u51b3\u7b56\uff0c\u5bfc\u81f4\u590d\u6742\u591a\u8f6e\u652f\u6301\u6548\u679c\u4e0d\u7406\u60f3\u3002", "method": "AFlow\u901a\u8fc7\u5bf9\u591a\u8f6e\u5bf9\u8bdd\u8f68\u8ff9\u5efa\u6a21\u8fde\u7eed\u7684\u60c5\u611f\u6d41\uff0c\u5b9e\u73b0\u5bf9\u5bf9\u8bdd\u524d\u7f00\u7684\u7ec6\u7c92\u5ea6\u76d1\u7763\uff0c\u5e76\u5f15\u5165\u5b50\u8def\u5f84\u5c42\u7ea7\u7684\u6d41\u5e73\u8861\u76ee\u6807\u4ee5\u4f20\u9012\u504f\u597d\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u79cd\u60c5\u611f\u573a\u666f\u4e0b\uff0cAFlow\u663e\u8457\u4f18\u4e8e\u7ade\u4e89\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u57fa\u4e8e\u7d27\u51d1\u7684\u5f00\u6e90\u80cc\u9aa8\uff0c\u6027\u80fd\u8d85\u8fc7\u4e86GPT-4o\u548cClaude-3.5\u7b49\u4e13\u6709\u5927\u578b\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684AFlow\u6846\u67b6\u5728\u591a\u8f6e\u60c5\u611f\u652f\u6301\u5bf9\u8bdd\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u7b56\u7565\u4e00\u81f4\u6027\u548c\u5171\u60c5\u56de\u5e94\u8d28\u91cf\uff0c\u5b9e\u9a8c\u7ed3\u679c\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u3002"}}
{"id": "2602.08829", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08829", "abs": "https://arxiv.org/abs/2602.08829", "authors": ["Hao Peng", "Yunjia Qi", "Xiaozhi Wang", "Zijun Yao", "Lei Hou", "Juanzi Li"], "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions", "comment": null, "summary": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u771f\u5b9e\u73af\u5883\u7528\u6237\u4ea4\u4e92\u6570\u636e\u76f4\u63a5\u8bad\u7ec3\u5956\u52b1\u6a21\u578bWildReward\uff0c\u65e0\u9700\u504f\u597d\u5bf9\uff0c\u8fbe\u5230\u751a\u81f3\u8d85\u8d8a\u4f20\u7edf\u65b9\u6cd5\u6027\u80fd\uff0c\u4e14\u80fd\u5229\u7528\u7528\u6237\u591a\u6837\u6027\u63d0\u5347\u6548\u679c\uff0c\u663e\u8457\u6539\u8fdb\u5728\u7ebf\u8bad\u7ec3\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u4eba\u5de5\u6807\u6ce8\u7684\u504f\u597d\u5bf9\uff0c\u7136\u800c\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u771f\u5b9e\u73af\u5883\u4e2d\u7528\u6237\u4ea4\u4e92\u6210\u4e3a\u4e30\u5bcc\u7684\u9690\u5f0f\u5956\u52b1\u4fe1\u53f7\u6765\u6e90\u3002\u5982\u4f55\u76f4\u63a5\u5229\u7528\u771f\u5b9e\u73af\u5883\u7684\u7528\u6237\u4ea4\u4e92\u6765\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\u6210\u4e3a\u6311\u6218\u3002", "method": "\u91c7\u7528WildChat\u4f5c\u4e3a\u4ea4\u4e92\u6570\u636e\u6e90\uff0c\u8bbe\u8ba1\u4e00\u5957\u6d41\u6c34\u7ebf\u4ece\u7528\u6237\u53cd\u9988\u4e2d\u63d0\u53d6\u53ef\u9760\u7684\u4eba\u5de5\u4fe1\u53f7\uff0c\u751f\u6210186k\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6837\u672c\u3002\u4f7f\u7528\u5e8f\u6570\u56de\u5f52\u65b9\u6cd5\u76f4\u63a5\u57fa\u4e8e\u7528\u6237\u53cd\u9988\u8bad\u7ec3WildReward\u6a21\u578b\uff0c\u65e0\u9700\u504f\u597d\u5bf9\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWildReward\u5728\u6027\u80fd\u3001\u6821\u51c6\u5ea6\u548c\u6837\u672c\u95f4\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8e\u6216\u4e0d\u900a\u4e8e\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u3002\u6a21\u578b\u6027\u80fd\u968f\u7740\u7528\u6237\u591a\u6837\u6027\u63d0\u5347\u800c\u589e\u5f3a\u3002\u5728\u5728\u7ebfDPO\u8bad\u7ec3\u4e2d\uff0cWildReward\u5728\u591a\u4efb\u52a1\u4e0a\u5e26\u6765\u663e\u8457\u6539\u8fdb\u3002", "conclusion": "\u57fa\u4e8e\u771f\u5b9e\u73af\u5883\u7528\u6237\u4ea4\u4e92\u7684\u5956\u52b1\u6a21\u578b\u8bad\u7ec3\u65b9\u6cd5WildReward\u6709\u6548\u4e14\u4f18\u8d8a\uff0c\u65e0\u9700\u4f9d\u8d56\u4eba\u5de5\u504f\u597d\u5bf9\uff0c\u5229\u7528\u7528\u6237\u591a\u6837\u6027\u63d0\u5347\u6a21\u578b\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u5956\u52b1\u6a21\u578b\u7684\u5b9e\u7528\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.08864", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08864", "abs": "https://arxiv.org/abs/2602.08864", "authors": ["Ibraheem Muhammad Moosa", "Suhas Lohit", "Ye Wang", "Moitreya Chatterjee", "Wenpeng Yin"], "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers", "comment": null, "summary": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u6d4b\u65b9\u6cd5\u548c\u6a21\u578b\u6846\u67b6\uff0c\u7cfb\u7edf\u5206\u6790\u4e86\u57fa\u4e8e\u4ee4\u724c\u7684\u81ea\u9002\u5e94\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\uff0c\u63ed\u793a\u4e86\u8ba1\u7b97\u5bf9\u9f50\u590d\u6742\u5ea6\u7684\u6761\u4ef6\u53ca\u5176\u5bf9\u6cdb\u5316\u7684\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u96be\u4ee5\u76f4\u63a5\u89c2\u5bdf\u4ee4\u724c\u7ea7\u522b\u7684\u8ba1\u7b97\u5206\u914d\u4e0e\u590d\u6742\u5ea6\u7684\u5173\u7cfb\uff0c\u7f3a\u4e4f\u53ef\u63a7\u8bc4\u6d4b\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86ANIRA\u7edf\u4e00\u9012\u5f52Transformer\u6846\u67b6\uff0c\u7528\u4e8e\u652f\u6301\u57fa\u4e8e\u4ee4\u724c\u7684\u53ef\u53d8\u6df1\u5ea6\u8ba1\u7b97\uff0c\u5e76\u91c7\u7528\u590d\u6742\u5ea6\u53ef\u63a7\u7684\u7b97\u6cd5\u4e0e\u5408\u6210\u8bed\u8a00\u4efb\u52a1\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u8ba1\u7b97\u5206\u914d\u867d\u81ea\u7136\u5bf9\u5e94\u4efb\u52a1\u590d\u6742\u5ea6\uff0c\u4f46\u4e0d\u4ee3\u8868\u7b97\u6cd5\u6cdb\u5316\uff1b\u65e9\u671f\u51b3\u7b56\u4f9d\u8d56\u9759\u6001\u7ed3\u6784\u4fe1\u606f\uff0c\u5728\u7ebf\u505c\u6b62\u673a\u5236\u66f4\u8d34\u5408\u7b97\u6cd5\u6267\u884c\u72b6\u6001\u3002", "conclusion": "\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\u4e0e\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u5bf9\u9f50\u53ef\u4ee5\u81ea\u7136\u51fa\u73b0\uff0c\u4f46\u4e0d\u4e00\u5b9a\u4fdd\u8bc1\u7b97\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\uff1b\u6a21\u578b\u5728\u672a\u89c1\u8fc7\u7684\u8f93\u5165\u89c4\u6a21\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2602.08872", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.08872", "abs": "https://arxiv.org/abs/2602.08872", "authors": ["G. Cafferata", "T. Demarco", "K. Kalimeri", "Y. Mejova", "M. G. Beir\u00f3"], "title": "Large Language Models for Geolocation Extraction in Humanitarian Crisis Response", "comment": null, "summary": "Humanitarian crises demand timely and accurate geographic information to inform effective response efforts. Yet, automated systems that extract locations from text often reproduce existing geographic and socioeconomic biases, leading to uneven visibility of crisis-affected regions. This paper investigates whether Large Language Models (LLMs) can address these geographic disparities in extracting location information from humanitarian documents. We introduce a two-step framework that combines few-shot LLM-based named entity recognition with an agent-based geocoding module that leverages context to resolve ambiguous toponyms. We benchmark our approach against state-of-the-art pretrained and rule-based systems using both accuracy and fairness metrics across geographic and socioeconomic dimensions. Our evaluation uses an extended version of the HumSet dataset with refined literal toponym annotations. Results show that LLM-based methods substantially improve both the precision and fairness of geolocation extraction from humanitarian texts, particularly for underrepresented regions. By bridging advances in LLM reasoning with principles of responsible and inclusive AI, this work contributes to more equitable geospatial data systems for humanitarian response, advancing the goal of leaving no place behind in crisis analytics.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u6539\u8fdb\u4eba\u9053\u5371\u673a\u6587\u672c\u4e2d\u7684\u5730\u7406\u4f4d\u7f6e\u63d0\u53d6\uff0c\u63d0\u5347\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff0c\u7279\u522b\u662f\u6b20\u4ee3\u8868\u5730\u533a\u7684\u8868\u73b0\uff0c\u63a8\u52a8\u66f4\u516c\u5e73\u7684\u5730\u7406\u4fe1\u606f\u7cfb\u7edf\u5efa\u8bbe\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u5730\u7406\u4fe1\u606f\u63d0\u53d6\u7cfb\u7edf\u5b58\u5728\u5730\u7406\u548c\u793e\u4f1a\u7ecf\u6d4e\u504f\u89c1\uff0c\u5bfc\u81f4\u5371\u673a\u5f71\u54cd\u5730\u533a\u7684\u53ef\u89c1\u6027\u4e0d\u5747\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4e24\u6b65\u6846\u67b6\uff0c\u7ed3\u5408\u5c11\u91cf\u793a\u4f8b\u7684LLM\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4e0e\u57fa\u4e8e\u4ee3\u7406\u7684\u5730\u7406\u7f16\u7801\u6a21\u5757\uff0c\u5229\u7528\u4e0a\u4e0b\u6587\u89e3\u6790\u6b67\u4e49\u5730\u540d\u3002", "result": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\u5728HumSet\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u5730\u7406\u4f4d\u7f6e\u63d0\u53d6\u7684\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u6b20\u4ee3\u8868\u5730\u533a\u3002", "conclusion": "\u7ed3\u5408LLM\u63a8\u7406\u80fd\u529b\u4e0e\u8d1f\u8d23\u5305\u5bb9\u7684AI\u539f\u5219\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u52a0\u516c\u5e73\u7684\u5730\u7406\u7a7a\u95f4\u6570\u636e\u7cfb\u7edf\uff0c\u6539\u5584\u4eba\u9053\u4e3b\u4e49\u54cd\u5e94\u7684\u5730\u7406\u4fe1\u606f\u63d0\u53d6\u3002"}}
{"id": "2602.08874", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.08874", "abs": "https://arxiv.org/abs/2602.08874", "authors": ["Yu Fu", "Haz Sameen Shahgir", "Huanli Gong", "Zhipeng Wei", "N. Benjamin Erichson", "Yue Dong"], "title": "Is Reasoning Capability Enough for Safety in Long-Context Language Models?", "comment": "25 pages, 7 figures", "summary": "Large language models (LLMs) increasingly combine long-context processing with advanced reasoning, enabling them to retrieve and synthesize information distributed across tens of thousands of tokens. A hypothesis is that stronger reasoning capability should improve safety by helping models recognize harmful intent even when it is not stated explicitly. We test this hypothesis in long-context settings where harmful intent is implicit and must be inferred through reasoning, and find that it does not hold. We introduce compositional reasoning attacks, a new threat model in which a harmful query is decomposed into incomplete fragments that scattered throughout a long context. The model is then prompted with a neutral reasoning query that induces retrieval and synthesis, causing the harmful intent to emerge only after composition. Evaluating 14 frontier LLMs on contexts up to 64k tokens, we uncover three findings: (1) models with stronger general reasoning capability are not more robust to compositional reasoning attacks, often assembling the intent yet failing to refuse; (2) safety alignment consistently degrades as context length increases; and (3) inference-time reasoning effort is a key mitigating factor: increasing inference-time compute reduces attack success by over 50 percentage points on GPT-oss-120b model. Together, these results suggest that safety does not automatically scale with reasoning capability, especially under long-context inference.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u5e76\u4e0d\u5fc5\u7136\u5e26\u6765\u5b89\u5168\u6027\u589e\u5f3a\uff0c\u957f\u4e0a\u4e0b\u6587\u73af\u5883\u4e0b\u6a21\u578b\u6613\u88ab\u62c6\u5206\u6709\u5bb3\u67e5\u8be2\u653b\u51fb\uff0c\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u8d44\u6e90\u53ef\u90e8\u5206\u7f13\u89e3\u8be5\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u5047\u8bbe\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u53ef\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u4f7f\u5176\u8bc6\u522b\u9690\u542b\u7684\u6709\u5bb3\u610f\u56fe\u3002", "method": "\u63d0\u51fa\u4e86\u7ec4\u5408\u63a8\u7406\u653b\u51fb\u7684\u65b0\u5a01\u80c1\u6a21\u578b\uff0c\u5c06\u6709\u5bb3\u67e5\u8be2\u62c6\u5206\u6210\u5206\u6563\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u4e0d\u5b8c\u6574\u7247\u6bb5\uff0c\u901a\u8fc7\u4e2d\u6027\u63a8\u7406\u67e5\u8be2\u8bf1\u5bfc\u6a21\u578b\u68c0\u7d22\u548c\u5408\u6210\uff0c\u4ece\u800c\u63ed\u9732\u6709\u5bb3\u610f\u56fe\u3002", "result": "\u8bc4\u4f3014\u4e2a\u524d\u6cbf\u5927\u6a21\u578b\uff0c\u53d1\u73b0\uff1a1\uff09\u66f4\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u4e0d\u610f\u5473\u7740\u66f4\u5f3a\u7684\u5b89\u5168\u6027\uff1b2\uff09\u968f\u7740\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\uff0c\u5b89\u5168\u6027\u5bf9\u9f50\u4e0b\u964d\uff1b3\uff09\u52a0\u5927\u63a8\u7406\u8ba1\u7b97\u8d44\u6e90\u53ef\u4ee5\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u3002", "conclusion": "\u5b89\u5168\u6027\u5e76\u4e0d\u4f1a\u968f\u7740\u63a8\u7406\u80fd\u529b\u7684\u589e\u5f3a\u81ea\u52a8\u63d0\u9ad8\uff0c\u5c24\u5176\u662f\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u73af\u5883\u4e0b\uff0c\u5b89\u5168\u4fdd\u969c\u4ecd\u9700\u91cd\u70b9\u5173\u6ce8\u3002"}}
{"id": "2602.08945", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.08945", "abs": "https://arxiv.org/abs/2602.08945", "authors": ["Sahajpreet Singh", "Kokil Jaidka", "Min-Yen Kan"], "title": "GitSearch: Enhancing Community Notes Generation with Gap-Informed Targeted Search", "comment": "18 pages, 11 figures, 7 tables", "summary": "Community-based moderation offers a scalable alternative to centralized fact-checking, yet it faces significant structural challenges, and existing AI-based methods fail in \"cold start\" scenarios. To tackle these challenges, we introduce GitSearch (Gap-Informed Targeted Search), a framework that treats human-perceived quality gaps, such as missing context, etc., as first-class signals. GitSearch has a three-stage pipeline: identifying information deficits, executing real-time targeted web-retrieval to resolve them, and synthesizing platform-compliant notes. To facilitate evaluation, we present PolBench, a benchmark of 78,698 U.S. political tweets with their associated Community Notes. We find GitSearch achieves 99% coverage, almost doubling coverage over the state-of-the-art. GitSearch surpasses human-authored helpful notes with a 69% win rate and superior helpfulness scores (3.87 vs. 3.36), demonstrating retrieval effectiveness that balanced the trade-off between scale and quality.", "AI": {"tldr": "GitSearch\u63d0\u51fa\u901a\u8fc7\u8bc6\u522b\u4fe1\u606f\u7f3a\u53e3\u5e76\u7cbe\u51c6\u68c0\u7d22\u89e3\u51b3\u793e\u533a\u5ba1\u6838\u51b7\u542f\u52a8\u96be\u9898\uff0c\u663e\u8457\u63d0\u5347\u5ba1\u6838\u8986\u76d6\u7387\u548c\u6ce8\u91ca\u5e2e\u52a9\u6027\uff0c\u4f18\u4e8e\u5f53\u524d\u6280\u672f\u548c\u4eba\u5de5\u65b9\u6cd5\u3002", "motivation": "\u793e\u533a\u57fa\u7840\u7684\u5185\u5bb9\u5ba1\u6838\u867d\u7136\u6709\u8f83\u597d\u7684\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u9762\u4e34\u7ed3\u6784\u6027\u6311\u6218\uff0c\u7279\u522b\u662fAI\u65b9\u6cd5\u5728\u51b7\u542f\u52a8\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5ba1\u6838\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u9636\u6bb5\u6846\u67b6GitSearch\uff1a\u8bc6\u522b\u4fe1\u606f\u7f3a\u53e3\u3001\u5b9e\u65f6\u76ee\u6807\u5316\u7f51\u7edc\u68c0\u7d22\u4ee5\u5f25\u8865\u7f3a\u5931\u4fe1\u606f\u3001\u5408\u6210\u7b26\u5408\u5e73\u53f0\u89c4\u8303\u7684\u6ce8\u91ca\u3002\u5f15\u5165\u4e86PolBench\u6570\u636e\u96c6\u8f85\u52a9\u8bc4\u4f30\u3002", "result": "GitSearch\u5b9e\u73b0\u4e8699%\u7684\u8986\u76d6\u7387\uff0c\u8986\u76d6\u7387\u51e0\u4e4e\u662f\u73b0\u6709\u65b9\u6cd5\u7684\u4e24\u500d\uff0c\u5e76\u4ee569%\u7684\u80dc\u7387\u51fb\u8d25\u4eba\u7c7b\u7f16\u5199\u7684\u6ce8\u91ca\uff0c\u5e2e\u52a9\u6027\u5f97\u5206\u66f4\u9ad8\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "GitSearch\u901a\u8fc7\u8bc6\u522b\u4fe1\u606f\u7f3a\u53e3\u5e76\u8fdb\u884c\u9488\u5bf9\u6027\u68c0\u7d22\uff0c\u6709\u6548\u63d0\u5347\u4e86\u793e\u533a\u5185\u5bb9\u5ba1\u6838\u7684\u8986\u76d6\u7387\u548c\u5e2e\u52a9\u6027\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u548c\u4eba\u5de5\u7f16\u5199\u7684\u6ce8\u91ca\u3002"}}
{"id": "2602.08951", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08951", "abs": "https://arxiv.org/abs/2602.08951", "authors": ["Rasul Dent", "Pedro Ortiz Suarez", "Thibault Cl\u00e9rice", "Beno\u00eet Sagot"], "title": "How Should We Model the Probability of a Language?", "comment": "Accepted for Vardial 2026", "summary": "Of the over 7,000 languages spoken in the world, commercial language identification (LID) systems only reliably identify a few hundred in written form. Research-grade systems extend this coverage under certain circumstances, but for most languages coverage remains patchy or nonexistent. This position paper argues that this situation is largely self-imposed. In particular, it arises from a persistent framing of LID as decontextualized text classification, which obscures the central role of prior probability estimation and is reinforced by institutional incentives that favor global, fixed-prior models. We argue that improving coverage for tail languages requires rethinking LID as a routing problem and developing principled ways to incorporate environmental cues that make languages locally plausible.", "AI": {"tldr": "\u4f20\u7edf\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u5ffd\u89c6\u4e86\u4e0a\u4e0b\u6587\u548c\u5148\u9a8c\u6982\u7387\uff0c\u5bfc\u81f4\u8986\u76d6\u6709\u9650\u3002\u5c06\u8bed\u8a00\u8bc6\u522b\u89c6\u4e3a\u7ed3\u5408\u73af\u5883\u7ebf\u7d22\u7684\u8def\u7531\u95ee\u9898\u662f\u63d0\u5347\u5c0f\u4f17\u8bed\u8a00\u8bc6\u522b\u7684\u5173\u952e\u3002", "motivation": "\u5f53\u524d\u5546\u4e1a\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u5bf9\u8bed\u8a00\u8986\u76d6\u6709\u9650\uff0c\u4e14\u7814\u7a76\u7cfb\u7edf\u4e5f\u4ec5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u62d3\u5c55\u8986\u76d6\uff0c\u6839\u672c\u539f\u56e0\u5728\u4e8e\u5bf9\u4efb\u52a1\u6027\u8d28\u7406\u89e3\u8bef\u533a\u53ca\u673a\u6784\u6fc0\u52b1\u673a\u5236\u7684\u9650\u5236\u3002", "method": "\u901a\u8fc7\u91cd\u65b0 framing \u8bed\u8a00\u8bc6\u522b\u4efb\u52a1\uff0c\u5c06\u5176\u89c6\u4e3a\u7ed3\u5408\u73af\u5883\u4e0a\u4e0b\u6587\u7684\u8def\u7531\u95ee\u9898\uff0c\u800c\u975e\u5355\u7eaf\u6587\u672c\u5206\u7c7b\uff0c\u4ece\u800c\u63d0\u51fa\u65b0\u7684\u6a21\u578b\u8bbe\u8ba1\u601d\u8def\u3002", "result": "\u9610\u660e\u4e86\u5148\u9a8c\u6982\u7387\u5728\u8bed\u8a00\u8bc6\u522b\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u6307\u51fa\u7ed3\u5408\u73af\u5883\u4fe1\u606f\u53ef\u4ee5\u5b9e\u73b0\u66f4\u5e7f\u6cdb\u3001\u5408\u7406\u7684\u8bed\u8a00\u8bc6\u522b\u8986\u76d6\uff0c\u7279\u522b\u662f\u5bf9\u8fb9\u7f18\u8bed\u8a00\u3002", "conclusion": "\u73b0\u6709\u5546\u4e1a\u8bed\u8a00\u8bc6\u522b\u7cfb\u7edf\u8986\u76d6\u8bed\u8a00\u79cd\u7c7b\u6709\u9650\uff0c\u4e3b\u8981\u95ee\u9898\u5728\u4e8e\u5c06\u8bed\u8a00\u8bc6\u522b\u7b80\u5316\u4e3a\u53bb\u4e0a\u4e0b\u6587\u5316\u7684\u6587\u672c\u5206\u7c7b\uff0c\u5ffd\u89c6\u4e86\u5148\u9a8c\u6982\u7387\u4f30\u8ba1\u7684\u91cd\u8981\u6027\u3002\u63d0\u5347\u8fb9\u7f18\u8bed\u8a00\u8986\u76d6\u7387\u9700\u8981\u5c06\u8bed\u8a00\u8bc6\u522b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u8def\u7531\u95ee\u9898\uff0c\u7ed3\u5408\u73af\u5883\u7ebf\u7d22\u8fdb\u884c\u8bed\u8a00\u63a8\u65ad\u3002"}}
{"id": "2602.08984", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08984", "abs": "https://arxiv.org/abs/2602.08984", "authors": ["Yuliang Liu", "Yunchong Song", "Yixuan Wang", "Kewen Ge", "Alex Lamb", "Qipeng Guo", "Kai Chen", "Bowen Zhou", "Zhouhan Lin"], "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models", "comment": null, "summary": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6982\u5ff5\u9884\u6d4b\u7684\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u8303\u5f0f\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u5355\u6807\u8bb0\u9884\u6d4b\u4efb\u52a1\u8fc7\u4e8e\u7b80\u5355\uff0c\u9650\u5236\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\uff0c\u9700\u5f15\u5165\u66f4\u96be\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u4ee5\u63d0\u9ad8\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5411\u91cf\u91cf\u5316\u7684\u6982\u5ff5\u8bcd\u6c47\u8868\u6784\u5efa\u548c\u7ed3\u5408Next Concept Prediction\u4e0eNext Token Prediction\u7684\u65b9\u6cd5\u8fdb\u884c\u751f\u6210\u5f0f\u9884\u8bad\u7ec3\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cNCP\u4f18\u4e8e\u4f20\u7edf\u7684\u5355\u6807\u8bb0\u6a21\u578b\uff0c\u5e76\u4e14\u5728\u5bf9\u5df2\u6709\u6a21\u578b\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\u65f6\u4e5f\u80fd\u63d0\u5347\u6027\u80fd\u3002", "conclusion": "NCP\u901a\u8fc7\u5f15\u5165\u66f4\u5177\u6311\u6218\u6027\u7684\u591a\u6807\u8bb0\u79bb\u6563\u6982\u5ff5\u9884\u6d4b\u4efb\u52a1\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2602.08995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08995", "abs": "https://arxiv.org/abs/2602.08995", "authors": ["Yuting Ning", "Jaylen Jones", "Zhehao Zhang", "Chentao Ye", "Weitong Ruan", "Junyi Li", "Rahul Gupta", "Huan Sun"], "title": "When Actions Go Off-Task: Detecting and Correcting Misaligned Actions in Computer-Use Agents", "comment": "Project Homepage: https://osu-nlp-group.github.io/Misaligned-Action-Detection/", "summary": "Computer-use agents (CUAs) have made tremendous progress in the past year, yet they still frequently produce misaligned actions that deviate from the user's original intent. Such misaligned actions may arise from external attacks (e.g., indirect prompt injection) or from internal limitations (e.g., erroneous reasoning). They not only expose CUAs to safety risks, but also degrade task efficiency and reliability. This work makes the first effort to define and study misaligned action detection in CUAs, with comprehensive coverage of both externally induced and internally arising misaligned actions. We further identify three common categories in real-world CUA deployment and construct MisActBench, a benchmark of realistic trajectories with human-annotated, action-level alignment labels. Moreover, we propose DeAction, a practical and universal guardrail that detects misaligned actions before execution and iteratively corrects them through structured feedback. DeAction outperforms all existing baselines across offline and online evaluations with moderate latency overhead: (1) On MisActBench, it outperforms baselines by over 15% absolute in F1 score; (2) In online evaluation, it reduces attack success rate by over 90% under adversarial settings while preserving or even improving task success rate in benign environments.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9CUAs\u4e2d\u7684\u52a8\u4f5c\u4e0d\u5bf9\u9f50\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u68c0\u6d4b\u4e0e\u7ea0\u6b63\u65b9\u6cd5DeAction\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u5b89\u5168\u6027\u4e0e\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5f53\u524dCUAs\u9891\u7e41\u4ea7\u751f\u504f\u79bb\u7528\u6237\u610f\u56fe\u7684\u4e0d\u5bf9\u9f50\u52a8\u4f5c\uff0c\u5b58\u5728\u5916\u90e8\u653b\u51fb\u548c\u5185\u90e8\u63a8\u7406\u9519\u8bef\u98ce\u9669\uff0c\u5f71\u54cd\u5b89\u5168\u6027\u548c\u6548\u7387\uff0c\u4e9f\u9700\u68c0\u6d4b\u4e0e\u7ea0\u6b63\u673a\u5236\u3002", "method": "\u6784\u5efa\u4e86\u6db5\u76d6\u771f\u5b9e\u573a\u666f\u4e0b\u52a8\u4f5c\u4e0d\u5bf9\u9f50\u7684MisActBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u4e86DeAction\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u53cd\u9988\u5728\u6267\u884c\u524d\u68c0\u6d4b\u5e76\u8fed\u4ee3\u7ea0\u6b63\u4e0d\u5bf9\u9f50\u52a8\u4f5c\u3002", "result": "DeAction\u5728MisActBench\u4e0aF1\u5206\u6570\u63d0\u5347\u8d85\u8fc715%\uff0c\u5728\u7ebf\u8bc4\u6d4b\u4e2d\u5728\u5bf9\u6297\u73af\u5883\u4e0b\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90%\u4ee5\u4e0a\uff0c\u540c\u65f6\u5728\u6b63\u5e38\u73af\u5883\u4e0b\u4fdd\u6301\u6216\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u5b9a\u4e49\u5e76\u7814\u7a76\u4e86\u8ba1\u7b97\u673a\u4f7f\u7528\u4ee3\u7406\uff08CUAs\uff09\u4e2d\u7684\u52a8\u4f5c\u4e0d\u5bf9\u9f50\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5b9e\u7528\u4e14\u901a\u7528\u7684\u9632\u62a4\u65b9\u6cd5DeAction\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5e76\u7ea0\u6b63\u4e0d\u5bf9\u9f50\u52a8\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86CUAs\u7684\u5b89\u5168\u6027\u548c\u4efb\u52a1\u6548\u7387\u3002"}}
