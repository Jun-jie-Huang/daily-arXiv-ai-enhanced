{"id": "2602.00755", "categories": ["cs.MA", "cs.AI", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.00755", "abs": "https://arxiv.org/abs/2602.00755", "authors": ["Ujwal Kumar", "Alice Saito", "Hershraj Niranjani", "Rayan Yessou", "Phan Xuan Tan"], "title": "Evolving Interpretable Constitutions for Multi-Agent Simulation", "comment": "23 pages, 4 figures", "summary": "Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (\"be helpful, harmless, honest\") produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u51fa\u4e86\u81ea\u52a8\u8fdb\u5316\u884c\u4e3a\u89c4\u8303\u7684Constitutional Evolution\u6846\u67b6\uff0c\u901a\u8fc7\u9057\u4f20\u7f16\u7a0b\u5728\u4eff\u771f\u73af\u5883\u4e2d\u8fdb\u5316\u667a\u80fd\u4f53\u5baa\u6cd5\uff0c\u5b9e\u73b0\u4e86\u4f18\u4e8e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u5408\u4f5c\u89c4\u8303\u548c\u9ad8\u793e\u4f1a\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u7684Constitutional AI\u591a\u805a\u7126\u4e8e\u5355\u6a21\u578b\u56fa\u5b9a\u539f\u5219\u7684\u5bf9\u9f50\uff0c\u800c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u51fa\u73b0\u7684\u65b0\u5174\u793e\u4f1a\u52a8\u6001\u5e26\u6765\u4e86\u65b0\u7684\u5bf9\u9f50\u6311\u6218\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u53d1\u73b0\u9002\u5408\u591a\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u89c4\u8303\u3002", "method": "\u91c7\u7528\u57fa\u4e8eLLM\u7684\u9057\u4f20\u7f16\u7a0b\u548c\u591a\u7fa4\u5c9b\u8fdb\u5316\u7b97\u6cd5\uff0c\u5728\u4e00\u4e2a\u5e26\u6709\u751f\u5b58\u538b\u529b\u7684\u7f51\u683c\u4e16\u754c\u4eff\u771f\u4e2d\u8fdb\u5316\u667a\u80fd\u4f53\u7684\u884c\u4e3a\u5baa\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u7684\u793e\u4f1a\u7a33\u5b9a\u8bc4\u5206S\u8bc4\u4f30\u4e2a\u4f53\u4e0e\u96c6\u4f53\u798f\u5229\u7684\u5e73\u8861\u3002", "result": "\u901a\u8fc7\u8fdb\u5316\u5f97\u5230\u7684\u6700\u4f18\u5baa\u6cd5C*\u5728\u793e\u4f1a\u7a33\u5b9a\u8bc4\u5206\u4e0a\uff08S=0.556\uff09\u663e\u8457\u8d85\u8d8a\u4eba\u7c7b\u8bbe\u8ba1\u548cClaude\u6a21\u578b\u8bbe\u8ba1\u7684\u5baa\u6cd5\uff0c\u6d88\u9664\u51b2\u7a81\u5e76\u53d1\u73b0\u4e86\u6700\u4f18\u7684\u6700\u5c0f\u5316\u901a\u4fe1\u884c\u4e3a\uff0c\u63d0\u9ad8\u4e86\u793e\u4f1a\u534f\u8c03\u6548\u7387\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684Constitutional Evolution\u6846\u67b6\u80fd\u591f\u81ea\u52a8\u53d1\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u884c\u4e3a\u89c4\u8303\uff0c\u901a\u8fc7\u8fdb\u5316\u7b97\u6cd5\u6700\u5927\u5316\u793e\u4f1a\u798f\u5229\uff0c\u4f7f\u5f97\u5408\u4f5c\u89c4\u8303\u80fd\u591f\u88ab\u53d1\u73b0\u800c\u975e\u88ab\u5f3a\u5236\u5236\u5b9a\u3002\u6240\u8fdb\u5316\u51fa\u7684\u5baa\u6cd5\u663e\u8457\u4f18\u4e8e\u4eba\u7c7b\u8bbe\u8ba1\u7684\u57fa\u51c6\uff0c\u964d\u4f4e\u51b2\u7a81\u5e76\u5b9e\u73b0\u9ad8\u6548\u7b80\u6d01\u7684\u534f\u8c03\u3002"}}
{"id": "2602.00766", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00766", "abs": "https://arxiv.org/abs/2602.00766", "authors": ["Xiaoxue Yu", "Rongpeng Li", "Zhifeng Zhao", "Honggang Zhang"], "title": "Communications-Incentivized Collaborative Reasoning in NetGPT through Agentic Reinforcement Learning", "comment": null, "summary": "The evolution of next-Generation (xG) wireless networks marks a paradigm shift from connectivity-centric architectures to Artificial Intelligence (AI)-native designs that tightly integrate data, computing, and communication. Yet existing AI deployments in communication systems remain largely siloed, offering isolated optimizations without intrinsic adaptability, dynamic task delegation, or multi-agent collaboration. In this work, we propose a unified agentic NetGPT framework for AI-native xG networks, wherein a NetGPT core can either perform autonomous reasoning or delegate sub-tasks to domain-specialized agents via agentic communication. The framework establishes clear modular responsibilities and interoperable workflows, enabling scalable, distributed intelligence across the network. To support continual refinement of collaborative reasoning strategies, the framework is further enhanced through Agentic reinforcement learning under partially observable conditions and stochastic external states. The training pipeline incorporates masked loss against external agent uncertainty, entropy-guided exploration, and multi-objective rewards that jointly capture task quality, coordination efficiency, and resource constraints. Through this process, NetGPT learns when and how to collaborate, effectively balancing internal reasoning with agent invocation. Overall, this work provides a foundational architecture and training methodology for self-evolving, AI-native xG networks capable of autonomous sensing, reasoning, and action in complex communication environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eagentic NetGPT\u7684AI\u539f\u751fxG\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u81ea\u6211\u6f14\u5316\uff0c\u63d0\u5347\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u667a\u80fd\u5316\u6c34\u5e73\u3002", "motivation": "\u73b0\u6709\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684AI\u90e8\u7f72\u591a\u4e3a\u5b64\u7acb\u4f18\u5316\uff0c\u7f3a\u4e4f\u5185\u5728\u7684\u9002\u5e94\u6027\u3001\u52a8\u6001\u4efb\u52a1\u5206\u914d\u548c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u80fd\u529b\uff0c\u96be\u4ee5\u6ee1\u8db3\u672a\u6765xG\u7f51\u7edc\u5bf9\u667a\u80fd\u5206\u5e03\u5f0f\u5904\u7406\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1NetGPT\u6838\u5fc3\u548c\u9886\u57df\u4e13\u5c5eagent\u5b50\u7684\u6a21\u5757\u5316\u67b6\u6784\uff0c\u5f15\u5165agentic\u901a\u4fe1\u5b9e\u73b0\u4efb\u52a1\u5206\u914d\uff0c\u7ed3\u5408\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u7684agentic\u5f3a\u5316\u5b66\u4e60\uff0c\u4f7f\u7528\u591a\u76ee\u6807\u5956\u52b1\u548c\u71b5\u5bfc\u5411\u63a2\u7d22\u6765\u8bad\u7ec3\u534f\u4f5c\u63a8\u7406\u7b56\u7565\u3002", "result": "\u642d\u5efa\u4e86\u4e00\u4e2a\u652f\u6301\u8de8\u7f51\u7edc\u5206\u5e03\u5f0f\u667a\u80fd\u7684\u53ef\u6269\u5c55\u6846\u67b6\uff0cNetGPT\u80fd\u6709\u6548\u5e73\u8861\u6838\u5fc3\u63a8\u7406\u4e0eagent\u534f\u4f5c\uff0c\u63d0\u9ad8\u4efb\u52a1\u8d28\u91cf\u3001\u534f\u8c03\u6548\u7387\u548c\u8d44\u6e90\u5229\u7528\u7387\uff0c\u5b9e\u73b0\u4e86\u590d\u6742\u901a\u4fe1\u73af\u5883\u4e0b\u7684\u81ea\u4e3b\u667a\u80fd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u4e00\u7684agentic NetGPT\u6846\u67b6\uff0c\u4f7f\u5f97AI\u539f\u751f\u7684xG\u7f51\u7edc\u80fd\u591f\u5b9e\u73b0\u81ea\u6211\u6f14\u5316\uff0c\u5177\u5907\u81ea\u4e3b\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u7684\u80fd\u529b\u3002"}}
{"id": "2602.00966", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00966", "abs": "https://arxiv.org/abs/2602.00966", "authors": ["Zhaoyang Guan", "Huixi Cao", "Ming Zhong", "Eric Yang", "Lynn Ai", "Yongxin Ni", "Bill Shi"], "title": "Symphony-Coord: Emergent Coordination in Decentralized Agent Systems", "comment": "41 pages,15 figures", "summary": "Multi-agent large language model systems can tackle complex multi-step tasks by decomposing work and coordinating specialized behaviors. However, current coordination mechanisms typically rely on statically assigned roles and centralized controllers. As agent pools and task distributions evolve, these design choices lead to inefficient routing, poor adaptability, and fragile fault recovery capabilities. We introduce Symphony-Coord, a decentralized multi-agent framework that transforms agent selection into an online multi-armed bandit problem, enabling roles to emerge organically through interaction. The framework employs a two-stage dynamic beacon protocol: (i) a lightweight candidate screening mechanism to limit communication and computational overhead; (ii) an adaptive LinUCB selector that routes subtasks based on context features derived from task requirements and agent states, continuously optimized through delayed end-to-end feedback. Under standard linear realizability assumptions, we provide sublinear regret bounds, indicating the system converges toward near-optimal allocation schemes. Validation through simulation experiments and real-world large language model benchmarks demonstrates that Symphony-Coord not only enhances task routing efficiency but also exhibits robust self-healing capabilities in scenarios involving distribution shifts and agent failures, achieving a scalable coordination mechanism without predefined roles.", "AI": {"tldr": "Symphony-Coord\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u81c2\u8001\u864e\u673a\u6a21\u578b\u7684\u53bb\u4e2d\u5fc3\u5316\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u65e0\u9884\u5b9a\u4e49\u89d2\u8272\u7684\u9ad8\u6548\u4efb\u52a1\u5206\u914d\u548c\u81ea\u6211\u4fee\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u673a\u5236\u901a\u5e38\u4f9d\u8d56\u9759\u6001\u5206\u914d\u89d2\u8272\u548c\u4e2d\u5fc3\u5316\u63a7\u5236\uff0c\u5bfc\u81f4\u8def\u7531\u6548\u7387\u4f4e\u3001\u9002\u5e94\u6027\u5dee\u4ee5\u53ca\u6545\u969c\u6062\u590d\u80fd\u529b\u8106\u5f31\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u534f\u8c03\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u667a\u80fd\u4f53\u9009\u62e9\u95ee\u9898\u8f6c\u5316\u4e3a\u5728\u7ebf\u591a\u81c2\u8001\u864e\u673a\u95ee\u9898\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u52a8\u6001\u4fe1\u6807\u534f\u8bae\uff08\u5019\u9009\u7b5b\u9009\u673a\u5236\u548c\u81ea\u9002\u5e94LinUCB\u9009\u62e9\u5668\uff09\u5b9e\u73b0\u57fa\u4e8e\u4efb\u52a1\u9700\u6c42\u548c\u667a\u80fd\u4f53\u72b6\u6001\u7684\u4e0a\u4e0b\u6587\u7279\u5f81\u52a8\u6001\u8def\u7531\u3002", "result": "\u5728\u6807\u51c6\u7ebf\u6027\u5b9e\u73b0\u6027\u5047\u8bbe\u4e0b\uff0c\u7cfb\u7edf\u8fbe\u5230\u6b21\u7ebf\u6027\u9057\u61be\u754c\uff0c\u6536\u655b\u4e8e\u8fd1\u4f3c\u6700\u4f18\u5206\u914d\u65b9\u6848\uff1b\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u63d0\u5347\u4e86\u4efb\u52a1\u8def\u7531\u6548\u7387\uff0c\u5e76\u5728\u5206\u5e03\u53d8\u5316\u53ca\u667a\u80fd\u4f53\u6545\u969c\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u5f3a\u5065\u7684\u81ea\u6108\u80fd\u529b\u3002", "conclusion": "Symphony-Coord\u6846\u67b6\u5728\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u65e0\u9700\u9884\u5b9a\u4e49\u89d2\u8272\u7684\u9ad8\u6548\u4efb\u52a1\u8def\u7531\u548c\u5f3a\u5927\u7684\u81ea\u6211\u4fee\u590d\u80fd\u529b\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u9002\u5e94\u6027\u548c\u6269\u5c55\u6027\u3002"}}
{"id": "2602.01011", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01011", "abs": "https://arxiv.org/abs/2602.01011", "authors": ["Aneesh Pappu", "Batu El", "Hancheng Cao", "Carmelo di Nolfo", "Yanchao Sun", "Meng Cao", "James Zou"], "title": "Multi-Agent Teams Hold Experts Back", "comment": "Under review at ICML 2026", "summary": "Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing teams perform when coordination is unconstrained. Drawing on organizational psychology, we study whether self-organizing LLM teams achieve strong synergy, where team performance matches or exceeds the best individual member. Across human-inspired and frontier ML benchmarks, we find that -- unlike human teams -- LLM teams consistently fail to match their expert agent's performance, even when explicitly told who the expert is, incurring performance losses of up to 37.6%. Decomposing this failure, we show that expert leveraging, rather than identification, is the primary bottleneck. Conversational analysis reveals a tendency toward integrative compromise -- averaging expert and non-expert views rather than appropriately weighting expertise -- which increases with team size and correlates negatively with performance. Interestingly, this consensus-seeking behavior improves robustness to adversarial agents, suggesting a trade-off between alignment and effective expertise utilization. Our findings reveal a significant gap in the ability of self-organizing multi-agent teams to harness the collective expertise of their members.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u53d1\u73b0\u81ea\u7ec4\u7ec7\u7684LLM\u591a\u4ee3\u7406\u56e2\u961f\u96be\u4ee5\u5145\u5206\u5229\u7528\u4e13\u5bb6\u77e5\u8bc6\uff0c\u8868\u73b0\u4e0d\u53ca\u9876\u5c16\u4e2a\u4f53\u6210\u5458\uff0c\u5b58\u5728\u77e5\u8bc6\u6574\u5408\u7b56\u7565\u4e0a\u7684\u4e0d\u8db3\uff0c\u63ed\u793a\u81ea\u7ec4\u7ec7\u56e2\u961f\u5728\u534f\u540c\u6548\u5e94\u4e0a\u7684\u663e\u8457\u6311\u6218\u3002", "motivation": "\u63a2\u8ba8\u5728\u6ca1\u6709\u56fa\u5b9a\u534f\u8c03\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u81ea\u7ec4\u7ec7\u7684LLM\u591a\u4ee3\u7406\u7cfb\u7edf\u80fd\u5426\u5b9e\u73b0\u56e2\u961f\u534f\u540c\u6548\u5e94\uff0c\u5339\u914d\u6216\u8d85\u8fc7\u6700\u4f18\u79c0\u6210\u5458\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u4eba\u7c7b\u56e2\u961f\u4e0eLLM\u56e2\u961f\u5728\u591a\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u7ed3\u5408\u7ec4\u7ec7\u5fc3\u7406\u5b66\u7684\u89c2\u70b9\uff0c\u5206\u6790\u56e2\u961f\u5185\u4e13\u5bb6\u8bc6\u522b\u4e0e\u5229\u7528\u7684\u533a\u522b\uff0c\u5e76\u5bf9\u5bf9\u8bdd\u5185\u5bb9\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "LLM\u56e2\u961f\u5728\u8bc6\u522b\u4e13\u5bb6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5229\u7528\u4e13\u5bb6\u77e5\u8bc6\u4e0a\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u56e0\u56e2\u961f\u503e\u5411\u4e8e\u6574\u5408\u5404\u6210\u5458\u89c2\u70b9\u800c\u975e\u7a81\u51fa\u4e13\u5bb6\u610f\u89c1\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u6700\u591a37.6%\uff1b\u8be5\u884c\u4e3a\u867d\u964d\u4f4e\u6574\u4f53\u8868\u73b0\uff0c\u4f46\u589e\u5f3a\u4e86\u5bf9\u5bf9\u6297\u6027\u4ee3\u7406\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u81ea\u7ec4\u7ec7\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u591a\u4ee3\u7406\u56e2\u961f\u65e0\u6cd5\u6709\u6548\u5229\u7528\u4e13\u5bb6\u6210\u5458\u7684\u4e13\u4e1a\u77e5\u8bc6\uff0c\u56e2\u961f\u8868\u73b0\u666e\u904d\u4f4e\u4e8e\u6700\u4f18\u79c0\u7684\u4e2a\u4f53\u6210\u5458\u3002"}}
{"id": "2602.00066", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00066", "abs": "https://arxiv.org/abs/2602.00066", "authors": ["Zheng Fang", "Yihong Dong", "Lili Mou", "Dongming Jin", "Zhi Jin", "Ge Li"], "title": "IntentCoding: Amplifying User Intent in Code Generation", "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in code generation, but their adherence to fine-grained user intent with multiple constraints remains a significant challenge. Our empirical analysis reveals two key observations: 1) Model performance deteriorates quickly as the number of constraints in the user intent increases, and 2) While user intent does influence the model's logits, such an influence may not be strong enough to effectively steer the decoding process. To this end, we propose Intent-Amplified Code Generation (IntentCoding), a novel decoding strategy that enhances an LLM's ability to follow user intent. IntentCoding captures the influence of user intent by masking out the intent, and applies a multi-strength ensemble mechanism to amplify the effect of user intent during generation. IntentCoding is model-agnostic, requires no additional training, and integrates seamlessly with existing decoding procedures. To enable systematic evaluation, we also construct CodeConstraints, a benchmark dataset specifically designed to test user intent compliance under varying numbers of constraints. Experiments on our constructed Constraints, as well as popular IFEvalCode, HumanEval and LiveCodeBench datasets, show that our IntentCoding model significantly improves both constraint satisfaction and functional correctness compared to standard decoding approaches. IntentCoding achieves up to 71.0% relative improvement on CodeConstraints, achieves up to 67.3% relative improvement on IFEvalCode and achieves up to 29.3% relative improvement in pass@1 on HumanEval and LiveCodeBench compared with greedy decoding.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faIntentCoding\uff0c\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u3001\u589e\u5f3a\u7528\u6237\u7ea6\u675f\u610f\u56fe\u5f71\u54cd\u7684\u65b0\u89e3\u7801\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u751f\u6210\u7684\u7ea6\u675f\u7b26\u5408\u6027\u548c\u6b63\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u9075\u5faa\u5305\u542b\u591a\u91cd\u7ea6\u675f\u7684\u7ec6\u7c92\u5ea6\u7528\u6237\u610f\u56fe\uff0c\u6a21\u578b\u6027\u80fd\u968f\u7ea6\u675f\u6570\u91cf\u589e\u591a\u8fc5\u901f\u4e0b\u964d\uff0c\u4e14\u610f\u56fe\u5bf9\u89e3\u7801\u5f71\u54cd\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86IntentCoding\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u63a9\u7801\u7528\u6237\u610f\u56fe\u5e76\u5229\u7528\u591a\u5f3a\u5ea6\u96c6\u6210\u673a\u5236\u653e\u5927\u610f\u56fe\u5f71\u54cd\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u517c\u5bb9\u73b0\u6709\u89e3\u7801\u6d41\u7a0b\u3002", "result": "\u5728CodeConstraints\u57fa\u51c6\u53caIFEvalCode\u3001HumanEval\u548cLiveCodeBench\u7b49\u6570\u636e\u96c6\u4e0a\uff0cIntentCoding\u5728\u7ea6\u675f\u6ee1\u8db3\u5ea6\u548c\u529f\u80fd\u6b63\u786e\u6027\u4e0a\u8f83\u6807\u51c6\u65b9\u6cd5\u663e\u8457\u63d0\u5347\uff0c\u6700\u9ad8\u76f8\u5bf9\u63d0\u5347\u8fbe71.0%\u3002", "conclusion": "IntentCoding\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u5bf9\u7528\u6237\u591a\u91cd\u7ea6\u675f\u610f\u56fe\u7684\u9075\u5faa\u80fd\u529b\uff0c\u7ecf\u9a8c\u8bc1\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2602.00007", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00007", "abs": "https://arxiv.org/abs/2602.00007", "authors": ["MinGyu Jeon", "SuWan Cho", "JaeYoung Shu"], "title": "PPoGA: Predictive Plan-on-Graph with Action for Knowledge Graph Question Answering", "comment": null, "summary": "Large Language Models (LLMs) augmented with Knowledge Graphs (KGs) have advanced complex question answering, yet they often remain susceptible to failure when their initial high-level reasoning plan is flawed. This limitation, analogous to cognitive functional fixedness, prevents agents from restructuring their approach, leading them to pursue unworkable solutions. To address this, we propose PPoGA (Predictive Plan-on-Graph with Action), a novel KGQA framework inspired by human cognitive control and problem-solving. PPoGA incorporates a Planner-Executor architecture to separate high-level strategy from low-level execution and leverages a Predictive Processing mechanism to anticipate outcomes. The core innovation of our work is a self-correction mechanism that empowers the agent to perform not only Path Correction for local execution errors but also Plan Correction by identifying, discarding, and reformulating the entire plan when it proves ineffective. We conduct extensive experiments on three challenging multi-hop KGQA benchmarks: GrailQA, CWQ, and WebQSP. The results demonstrate that PPoGA achieves state-of-the-art performance, significantly outperforming existing methods. Our work highlights the critical importance of metacognitive abilities like problem restructuring for building more robust and flexible AI reasoning systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPPoGA\u6846\u67b6\uff0c\u901a\u8fc7\u9884\u6d4b\u4e0e\u81ea\u6211\u4fee\u6b63\u673a\u5236\u63d0\u5347\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u7684\u5927\u8bed\u8a00\u6a21\u578b\u95ee\u7b54\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u667a\u80fd\u7684\u63a8\u7406\u3002", "motivation": "\u5f53\u524dKG\u589e\u5f3a\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u9519\u8bef\u7684\u9ad8\u5c42\u63a8\u7406\u8ba1\u5212\u65f6\u96be\u4ee5\u8c03\u6574\u7b56\u7565\uff0c\u5bb9\u6613\u9677\u5165\u529f\u80fd\u56fa\u7740\u9650\u5236\uff0c\u5f71\u54cd\u590d\u6742\u95ee\u7b54\u8868\u73b0\u3002", "method": "\u63d0\u51faPPoGA\u6846\u67b6\uff0c\u91c7\u7528Planner-Executor\u67b6\u6784\u5206\u79bb\u9ad8\u5c42\u7b56\u7565\u4e0e\u4f4e\u5c42\u6267\u884c\uff0c\u5e76\u7ed3\u5408\u9884\u6d4b\u5904\u7406\u673a\u5236\u5b9e\u73b0\u8def\u5f84\u548c\u8ba1\u5212\u7684\u81ea\u6211\u4fee\u6b63\u3002", "result": "PPoGA\u5728GrailQA\u3001CWQ\u548cWebQSP\u4e09\u4e2a\u591a\u8df3\u77e5\u8bc6\u56fe\u8c31\u95ee\u7b54\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "PPoGA\u901a\u8fc7\u5f15\u5165\u8ba1\u5212\u81ea\u6211\u4fee\u6b63\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u591a\u8df3\u95ee\u7b54\u6027\u80fd\uff0c\u663e\u793a\u51fa\u5143\u8ba4\u77e5\u80fd\u529b\u5728AI\u63a8\u7406\u7cfb\u7edf\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.01331", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01331", "abs": "https://arxiv.org/abs/2602.01331", "authors": ["Mingju Chen", "Guibin Zhang", "Heng Chang", "Yuchen Guo", "Shiji Zhou"], "title": "A-MapReduce: Executing Wide Search via Agentic MapReduce", "comment": "33 pages", "summary": "Contemporary large language model (LLM)-based multi-agent systems exhibit systematic advantages in deep research tasks, which emphasize iterative, vertically structured information seeking. However, when confronted with wide search tasks characterized by large-scale, breadth-oriented retrieval, existing agentic frameworks, primarily designed around sequential, vertically structured reasoning, remain stuck in expansive search objectives and inefficient long-horizon execution. To bridge this gap, we propose A-MapReduce, a MapReduce paradigm-inspired multi-agent execution framework that recasts wide search as a horizontally structured retrieval problem. Concretely, A-MapReduce implements parallel processing of massive retrieval targets through task-adaptive decomposition and structured result aggregation. Meanwhile, it leverages experiential memory to drive the continual evolution of query-conditioned task allocation and recomposition, enabling progressive improvement in large-scale wide-search regimes. Extensive experiments on five agentic benchmarks demonstrate that A-MapReduce is (i) high-performing, achieving state-of-the-art performance on WideSearch and DeepWideSearch, and delivering 5.11% - 17.50% average Item F1 improvements compared with strong baselines with OpenAI o3 or Gemini 2.5 Pro backbones; (ii) cost-effective and efficient, delivering superior cost-performance trade-offs and reducing running time by 45.8\\% compared to representative multi-agent baselines. The code is available at https://github.com/mingju-c/AMapReduce.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faA-MapReduce\u591a\u667a\u80fd\u4f53\u6267\u884c\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u4efb\u52a1\u5206\u89e3\u4e0e\u7ecf\u9a8c\u9a71\u52a8\u7684\u4efb\u52a1\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u5e7f\u5e45\u641c\u7d22\u6548\u7387\u548c\u51c6\u786e\u7387\uff0c\u6027\u80fd\u8d85\u8fc7\u73b0\u6709\u57fa\u7ebf\uff0c\u8fd0\u884c\u66f4\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5782\u76f4\u7ed3\u6784\u7684\u8fed\u4ee3\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u9762\u5bf9\u5927\u89c4\u6a21\u5bbd\u5ea6\u4f18\u5148\u641c\u7d22\u4efb\u52a1\u65f6\uff0c\u56e0\u8bbe\u8ba1\u4e0a\u7684\u987a\u5e8f\u5782\u76f4\u63a8\u7406\u9650\u5236\uff0c\u6548\u7387\u4f4e\u4e0b\u4e14\u96be\u4ee5\u5b8c\u6210\u5e7f\u6cdb\u7684\u641c\u7d22\u76ee\u6807\u3002", "method": "\u63d0\u51fa\u4e86\u7075\u611f\u6765\u6e90\u4e8eMapReduce\u7684\u591a\u667a\u80fd\u4f53\u6267\u884c\u6846\u67b6A-MapReduce\uff0c\u901a\u8fc7\u4efb\u52a1\u81ea\u9002\u5e94\u5206\u89e3\u548c\u7ed3\u6784\u5316\u7ed3\u679c\u805a\u5408\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u68c0\u7d22\u76ee\u6807\u7684\u5e76\u884c\u5904\u7406\uff0c\u5e76\u5229\u7528\u7ecf\u9a8c\u8bb0\u5fc6\u9a71\u52a8\u67e5\u8be2\u6761\u4ef6\u4e0b\u7684\u4efb\u52a1\u5206\u914d\u548c\u91cd\u7ec4\u5408\u7684\u6301\u7eed\u6f14\u8fdb\u3002", "result": "\u5728\u4e94\u4e2a\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cA-MapReduce\u8fbe\u5230\u4e86\u5bbd\u641c\u7d22\u548c\u6df1\u5bbd\u641c\u7d22\u4efb\u52a1\u4e0a\u7684\u6700\u65b0\u6027\u80fd\uff0cItem F1\u5f97\u5206\u76f8\u6bd4\u5f3a\u57fa\u7ebf\u63d0\u53475.11%\u81f317.50%\uff1b\u540c\u65f6\u5728\u6210\u672c\u548c\u6267\u884c\u6548\u7387\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c06\u8fd0\u884c\u65f6\u95f4\u51cf\u5c11\u4e8645.8%\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u4ef7\u6bd4\u3002", "conclusion": "A-MapReduce\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8eLLM\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u5927\u89c4\u6a21\u5e7f\u5ea6\u641c\u7d22\u4efb\u52a1\u4e0a\u7684\u6548\u7387\u548c\u6027\u80fd\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u641c\u7d22\u4efb\u52a1\u7684\u51c6\u786e\u7387\u548c\u6267\u884c\u6548\u7387\uff0c\u8fbe\u5230\u4e86\u4e1a\u5185\u9886\u5148\u6c34\u5e73\u3002"}}
{"id": "2602.00164", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00164", "abs": "https://arxiv.org/abs/2602.00164", "authors": ["Khairul Alam", "Saikat Mondal", "Banani Roy"], "title": "Why Are AI Agent Involved Pull Requests (Fix-Related) Remain Unmerged? An Empirical Study", "comment": "5 pages", "summary": "Autonomous coding agents (e.g., OpenAI Codex, Devin, GitHub Copilot) are increasingly used to generate fix-related pull requests (PRs) in real world software repositories. However, their practical effectiveness depends on whether these contributions are accepted and merged by project maintainers. In this paper, we present an empirical study of AI agent involved fix related PRs, examining both their integration outcomes, latency, and the factors that hinder successful merging. We first analyze 8,106 fix related PRs authored by five widely used AI coding agents from the AIDEV POP dataset to quantify the proportions of PRs that are merged, closed without merging, or remain open. We then conduct a manual qualitative analysis of a statistically significant sample of 326 closed but unmerged PRs, spending approximately 100 person hours to construct a structured catalog of 12 failure reasons. Our results indicate that test case failures and prior resolution of the same issues by other PRs are the most common causes of non integration, whereas build or deployment failures are comparatively rare. Overall, our findings expose key limitations of current AI coding agents in real world settings and highlight directions for their further improvement and for more effective human AI collaboration in software maintenance.", "AI": {"tldr": "\u672c\u6587\u5b9e\u8bc1\u5206\u6790\u4e86AI\u7f16\u7801\u4ee3\u7406\u751f\u6210\u7684\u4fee\u590dPR\u7684\u5408\u5e76\u72b6\u51b5\u548c\u672a\u5408\u5e76\u539f\u56e0\uff0c\u6307\u51fa\u6d4b\u8bd5\u5931\u8d25\u548c\u91cd\u590d\u95ee\u9898\u662f\u4e3b\u8981\u963b\u788d\uff0c\u63ed\u793a\u4e86AI\u81ea\u52a8\u4fee\u590d\u5728\u5b9e\u9645\u8f6f\u4ef6\u7ef4\u62a4\u4e2d\u7684\u6311\u6218\u3002", "motivation": "\u63a2\u7a76AI\u7f16\u7801\u4ee3\u7406\u751f\u6210\u7684\u4fee\u590d\u76f8\u5173PR\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u662f\u5426\u80fd\u88ab\u7ef4\u62a4\u8005\u63a5\u53d7\u53ca\u5408\u5e76\uff0c\u8bc4\u4f30\u5176\u5b9e\u7528\u6548\u679c\u53ca\u969c\u788d\u3002", "method": "\u57fa\u4e8eAIDEV POP\u6570\u636e\u96c6\uff0c\u5206\u67908106\u4e2a\u75315\u4e2a\u6d41\u884cAI\u7f16\u7801\u4ee3\u7406\u63d0\u4ea4\u7684\u4fee\u590d\u76f8\u5173PR\uff0c\u7edf\u8ba1\u5408\u5e76\u60c5\u51b5\uff0c\u5e76\u5bf9326\u4e2a\u672a\u5408\u5e76PR\u8fdb\u884c\u8d28\u6027\u5206\u6790\uff0c\u5f52\u7eb312\u4e2a\u5931\u8d25\u539f\u56e0\u3002", "result": "\u53d1\u73b0\u6d4b\u8bd5\u5931\u8d25\u548c\u91cd\u590d\u63d0\u4ea4\u662f\u975e\u5408\u5e76\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u6784\u5efa/\u90e8\u7f72\u5931\u8d25\u8f83\u5c11\uff0c\u63ed\u793a\u4e86\u5f53\u524dAI\u7f16\u7801\u4ee3\u7406\u7684\u74f6\u9888\uff0c\u6307\u660e\u6539\u8fdb\u548c\u6709\u6548\u4eba\u673a\u534f\u4f5c\u7684\u65b9\u5411\u3002", "conclusion": "\u5f53\u524dAI\u7f16\u7801\u4ee3\u7406\u5728\u5b9e\u9645\u8f6f\u4ef6\u7ef4\u62a4\u4e2d\u5b58\u5728\u8bf8\u591a\u9650\u5236\uff0c\u6700\u5e38\u89c1\u7684\u62d2\u7edd\u5408\u5e76\u539f\u56e0\u662f\u6d4b\u8bd5\u7528\u4f8b\u5931\u8d25\u548c\u95ee\u9898\u5df2\u88ab\u5176\u4ed6PR\u89e3\u51b3\u3002"}}
{"id": "2602.00009", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00009", "abs": "https://arxiv.org/abs/2602.00009", "authors": ["Samuel Thio", "Matthew Lewis", "Spiros Denaxas", "Richard JB Dobson"], "title": "Unlocking Electronic Health Records: A Hybrid Graph RAG Approach to Safe Clinical AI for Patient QA", "comment": "26 pages, 5 figures, 2 tables", "summary": "Electronic health record (EHR) systems present clinicians with vast repositories of clinical information, creating a significant cognitive burden where critical details are easily overlooked. While Large Language Models (LLMs) offer transformative potential for data processing, they face significant limitations in clinical settings, particularly regarding context grounding and hallucinations. Current solutions typically isolate retrieval methods focusing either on structured data (SQL/Cypher) or unstructured semantic search but fail to integrate both simultaneously. This work presents MediGRAF (Medical Graph Retrieval Augmented Framework), a novel hybrid Graph RAG system that bridges this gap. By uniquely combining Neo4j Text2Cypher capabilities for structured relationship traversal with vector embeddings for unstructured narrative retrieval, MediGRAF enables natural language querying of the complete patient journey. Using 10 patients from the MIMIC-IV dataset (generating 5,973 nodes and 5,963 relationships), we generated enough nodes and data for patient level question answering (QA), and we evaluated this architecture across varying query complexities. The system demonstrated 100\\% recall for factual queries which means all relevant information was retrieved and in the output, while complex inference tasks achieved a mean expert quality score of 4.25/5 with zero safety violations. These results demonstrate that hybrid graph-grounding significantly advances clinical information retrieval, offering a safer, more comprehensive alternative to standard LLM deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMediGRAF\u6846\u67b6\uff0c\u7ed3\u5408\u56fe\u6570\u636e\u5e93\u4e0e\u5411\u91cf\u68c0\u7d22\u6539\u8fdb\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u4fe1\u606f\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u67e5\u8be2\u51c6\u786e\u7387\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u4fdd\u969c\u4e34\u5e8a\u5e94\u7528\u5b89\u5168\u3002", "motivation": "\u73b0\u6709\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7cfb\u7edf\u4fe1\u606f\u91cf\u5e9e\u5927\uff0c\u7ed9\u4e34\u5e8a\u533b\u751f\u5e26\u6765\u8ba4\u77e5\u8d1f\u62c5\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u73af\u5883\u4e0b\u5b58\u5728\u4e0a\u4e0b\u6587\u5b9a\u4f4d\u53ca\u5e7b\u89c9\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u672a\u80fd\u6709\u6548\u878d\u5408\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u56fe\u68c0\u7d22\u589e\u5f3a\u6846\u67b6MediGRAF\uff0c\u5229\u7528Neo4j Text2Cypher\u8fdb\u884c\u7ed3\u6784\u5316\u5173\u7cfb\u904d\u5386\uff0c\u540c\u65f6\u7ed3\u5408\u5411\u91cf\u5d4c\u5165\u5b9e\u73b0\u975e\u7ed3\u6784\u5316\u8bed\u4e49\u68c0\u7d22\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u5bf9\u5b8c\u6574\u60a3\u8005\u75c5\u7a0b\u7684\u67e5\u8be2\u3002", "result": "\u5728MIMIC-IV\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\uff0c\u9488\u5bf910\u540d\u60a3\u8005\u6784\u5efa\u4e865973\u4e2a\u8282\u70b9\u548c5963\u6761\u5173\u7cfb\uff0c\u7cfb\u7edf\u5bf9\u4e8b\u5b9e\u6027\u67e5\u8be2\u8fbe\u5230\u4e86100%\u53ec\u56de\u7387\uff0c\u590d\u6742\u63a8\u7406\u4efb\u52a1\u83b7\u5f97\u5e73\u57474.25/5\u7684\u4e13\u5bb6\u8bc4\u5206\u4e14\u65e0\u5b89\u5168\u8fdd\u89c4\u3002", "conclusion": "MediGRAF\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u56fe\u6570\u636e\u5e93\u67e5\u8be2\u4e0e\u975e\u7ed3\u6784\u5316\u6587\u672c\u68c0\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e34\u5e8a\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u4fe1\u606f\u68c0\u7d22\u7684\u56f0\u96be\uff0c\u5b9e\u73b0\u4e86\u9ad8\u53ec\u56de\u7387\u548c\u4e13\u5bb6\u8bc4\u5206\u7684\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e34\u5e8a\u4fe1\u606f\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\u3002"}}
{"id": "2602.01415", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.01415", "abs": "https://arxiv.org/abs/2602.01415", "authors": ["Clayton Cohn", "Siyuan Guo", "Surya Rayala", "Hanchen David Wang", "Naveeduddin Mohammed", "Umesh Timalsina", "Shruti Jain", "Angela Eeds", "Menton Deweese", "Pamela J. Osborn Popp", "Rebekah Stanton", "Shakeera Walker", "Meiyi Ma", "Gautam Biswas"], "title": "Evidence-Decision-Feedback: Theory-Driven Adaptive Scaffolding for LLM Agents", "comment": "Currently under review", "summary": "Multi-agent LLM architectures offer opportunities for pedagogical agents to help students construct domain knowledge and develop critical-thinking skills, yet many operate on a \"one-size-fits-all\" basis, limiting their ability to provide personalized support. To address this, we introduce Evidence-Decision-Feedback (EDF), a theoretical framework for adaptive scaffolding using LLMs. EDF integrates elements of intelligent tutoring systems and agentic behavior by organizing interactions around evidentiary inference, pedagogical decision-making, and adaptive feedback. We instantiate EDF through Copa, an agentic collaborative peer agent for STEM+C problem-solving. In an authentic high school classroom study, we show that EDF-aligned interactions align feedback with students' demonstrated understanding and task mastery; promote gradual scaffold fading; and support interpretable, evidence-grounded explanations without fostering overreliance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEDF\u6846\u67b6\uff0c\u901a\u8fc7\u667a\u80fd\u6559\u5b66\u7cfb\u7edf\u4e0e\u591a\u667a\u80fd\u4f53\u884c\u4e3a\u878d\u5408\uff0c\u5b9e\u73b0\u4e2a\u6027\u5316\u6559\u5b66\u811a\u624b\u67b6\uff0c\u63d0\u5347\u9ad8\u4e2d\u5b66\u751fSTEM+C\u5b66\u4e60\u6548\u679c\u3002", "motivation": "\u76ee\u524d\u7684\u591a\u4e3b\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6559\u5b66\u4ee3\u7406\u591a\u91c7\u7528\u4e00\u5200\u5207\u7684\u65b9\u6cd5\uff0c\u96be\u4ee5\u63d0\u4f9b\u4e2a\u6027\u5316\u652f\u6301\uff0c\u9650\u5236\u4e86\u5176\u8f85\u52a9\u5b66\u751f\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u548c\u53d1\u5c55\u6279\u5224\u6027\u601d\u7ef4\u80fd\u529b\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86Evidence-Decision-Feedback (EDF)\u7406\u8bba\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5f00\u53d1Copa\u591a\u4e3b\u4f53\u534f\u4f5c\u4ee3\u7406\uff0c\u5728\u771f\u5b9e\u9ad8\u4e2d\u8bfe\u5802\u4e2d\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8eEDF\u6846\u67b6\u7684\u4ea4\u4e92\u80fd\u591f\u4f7f\u53cd\u9988\u4e0e\u5b66\u751f\u7684\u7406\u89e3\u6c34\u5e73\u548c\u4efb\u52a1\u638c\u63e1\u76f8\u5339\u914d\uff0c\u652f\u6301\u6e10\u8fdb\u5f0f\u811a\u624b\u67b6\u6d88\u9000\uff0c\u4e14\u751f\u6210\u89e3\u91ca\u5177\u6709\u53ef\u89e3\u91ca\u6027\u548c\u57fa\u4e8e\u8bc1\u636e\u7684\u7279\u70b9\u3002", "conclusion": "EDF\u6846\u67b6\u901a\u8fc7\u6574\u5408\u8bc1\u636e\u63a8\u65ad\u3001\u6559\u5b66\u51b3\u7b56\u548c\u81ea\u9002\u5e94\u53cd\u9988\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u6559\u5b66\u652f\u6301\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u5b66\u751f\u7684\u7406\u89e3\u548c\u4efb\u52a1\u638c\u63e1\uff0c\u540c\u65f6\u907f\u514d\u4e86\u5b66\u751f\u5bf9\u7cfb\u7edf\u7684\u8fc7\u5ea6\u4f9d\u8d56\u3002"}}
{"id": "2602.00180", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00180", "abs": "https://arxiv.org/abs/2602.00180", "authors": ["Deepak Babu Piskala"], "title": "Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants", "comment": "Submitted to AIWare 2026. 8 pages, 3 figures", "summary": "The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4ee5\u89c4\u8303\u4e3a\u6838\u5fc3\u7684\u8f6f\u4ef6\u5f00\u53d1\u65b9\u6cd5\u2014\u2014\u89c4\u8303\u9a71\u52a8\u5f00\u53d1\uff08SDD\uff09\uff0c\u7cfb\u7edf\u9610\u8ff0\u5176\u539f\u5219\u3001\u5de5\u5177\u4e0e\u5e94\u7528\u6848\u4f8b\uff0c\u5e76\u8bbe\u8ba1\u51b3\u7b56\u6846\u67b6\u6307\u5bfc\u5b9e\u9645\u91c7\u7528\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u7f16\u7801\u52a9\u624b\u7684\u53d1\u5c55\uff0c\u91cd\u65b0\u6fc0\u53d1\u4e86\u4ee5\u89c4\u8303\u800c\u975e\u4ee3\u7801\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u4e3b\u8981\u6210\u679c\u7684\u601d\u8def\uff0c\u5373\u89c4\u8303\u9a71\u52a8\u5f00\u53d1\u3002\u8be5\u65b9\u6cd5\u6709\u671b\u98a0\u8986\u4f20\u7edf\u5f00\u53d1\u6d41\u7a0b\uff0c\u63d0\u9ad8\u5f00\u53d1\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "method": "\u8bba\u6587\u5bf9\u73b0\u6709\u5de5\u5177\uff08\u5982\u884c\u4e3a\u9a71\u52a8\u5f00\u53d1\u6846\u67b6\u548cGitHub Spec Kit\u7b49\uff09\u8fdb\u884c\u4e86\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e09\u79cd\u89c4\u8303\u4e25\u8c28\u5ea6\u5c42\u6b21\uff08spec-first\u3001spec-anchored\u3001spec-as-source\uff09\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u6848\u4f8b\u5c55\u793a\u4e86SDD\u7684\u5177\u4f53\u5b9e\u65bd\u65b9\u6cd5\u3002", "result": "\u672c\u6587\u63d0\u4f9b\u4e86SDD\u7684\u5168\u9762\u5b9e\u8df5\u6307\u5357\uff0c\u6db5\u76d6\u539f\u5219\u3001\u6a21\u5f0f\u548c\u5de5\u5177\u652f\u6301\uff0c\u7ed3\u5408\u591a\u4e2a\u9886\u57df\u7684\u6848\u4f8b\uff0c\u6700\u7ec8\u63d0\u51fa\u51b3\u7b56\u6846\u67b6\uff0c\u5e2e\u52a9\u5f00\u53d1\u8005\u5224\u65ad\u4f55\u65f6\u91c7\u7528SDD\u66f4\u5177\u4ef7\u503c\u3002", "conclusion": "\u672c\u8bba\u6587\u603b\u7ed3\u4e86\u89c4\u8303\u9a71\u52a8\u5f00\u53d1\uff08SDD\uff09\u65b9\u6cd5\u7684\u539f\u5219\u3001\u5de5\u4f5c\u6d41\u7a0b\u53ca\u5176\u5de5\u5177\u652f\u6301\uff0c\u5f3a\u8c03\u4ee5\u89c4\u8303\u4e3a\u8f6f\u4ef6\u5f00\u53d1\u7684\u4e3b\u8981\u4f9d\u636e\u3002\u901a\u8fc7\u6848\u4f8b\u5206\u6790\u548c\u5de5\u5177\u63a2\u8ba8\uff0c\u660e\u786e\u4e86\u4e0d\u540c\u5e94\u7528\u9886\u57df\u91c7\u7528SDD\u7684\u9002\u7528\u6027\u53ca\u5176\u5e26\u6765\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.00015", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00015", "abs": "https://arxiv.org/abs/2602.00015", "authors": ["Xun Xu"], "title": "G-MemLLM: Gated Latent Memory Augmentation for Long-Context Reasoning in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding, yet they remain constrained by the finite capacity of their context windows and the inherent difficulty of maintaining long-term factual consistency during multi-hop reasoning. While existing methods utilize context compression or recurrent tokens, they often suffer from ``context rot'' or the dilution of information over long horizons. In this paper, we propose \\textbf{G-MemLLM}, a memory-augmented architecture that integrates a frozen LLM backbone with a trainable \\textbf{Latent Memory Bank}. Our key innovation is a GRU-style gated update logic that allows the model to selectively update, preserve, or overwrite latent memory slots, preventing the vanishing gradients of knowledge common in recurrent systems. We evaluate G-MemLLM across scales, from GPT-2 (124M) to Llama 3.1 (8B), on the HotpotQA and Zero-Shot Relation Extraction (ZsRE) benchmarks. Our results demonstrate that G-MemLLM significantly enhances multi-hop reasoning and relational precision, achieving a 13.3\\% accuracy boost on ZsRE for Llama 3.1-8B, and it also yields improvements across model scales, boosting Answer F1 by 8.56 points for GPT-2 and increasing Supporting Fact F1 by 6.89 points for Llama 3.1-8B on HotpotQA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6f5c\u5728\u8bb0\u5fc6\u5e93\u548cGRU\u95e8\u63a7\u66f4\u65b0\u7684\u8bb0\u5fc6\u589e\u5f3aLLM\u67b6\u6784G-MemLLM\uff0c\u6709\u6548\u89e3\u51b3\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u957f\u671f\u8bb0\u5fc6\u6d88\u9000\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9879\u95ee\u7b54\u548c\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56e0\u4e0a\u4e0b\u6587\u7a97\u53e3\u6709\u9650\u548c\u591a\u8df3\u63a8\u7406\u4e2d\u957f\u671f\u4e8b\u5b9e\u4e00\u81f4\u6027\u56f0\u96be\uff0c\u4e14\u73b0\u6709\u4e0a\u4e0b\u6587\u538b\u7f29\u6216\u5faa\u73aftoken\u65b9\u6cd5\u5e38\u51fa\u73b0\u4fe1\u606f\u8870\u51cf\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u6709\u6548\u7684\u8bb0\u5fc6\u589e\u5f3a\u673a\u5236\u3002", "method": "\u63d0\u51faG-MemLLM\u67b6\u6784\uff0c\u7ed3\u5408\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e3b\u5e72\u4e0e\u53ef\u8bad\u7ec3\u7684\u6f5c\u5728\u8bb0\u5fc6\u5e93\uff0c\u91c7\u7528GRU\u98ce\u683c\u95e8\u63a7\u673a\u5236\u9009\u62e9\u6027\u66f4\u65b0\u3001\u4fdd\u7559\u6216\u8986\u76d6\u8bb0\u5fc6\u69fd\uff0c\u9632\u6b62\u77e5\u8bc6\u68af\u5ea6\u6d88\u5931\u3002", "result": "\u5728HotpotQA\u548cZero-Shot Relation Extraction\u4efb\u52a1\u4e2d\uff0cG-MemLLM\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0b\u5747\u8868\u73b0\u51fa\u660e\u663e\u63d0\u5347\uff0c\u4f8b\u5982Llama3.1-8B\u5728ZsRE\u4efb\u52a1\u4e2d\u51c6\u786e\u7387\u63d0\u534713.3%\uff0cGPT-2\u548cLlama 3.1-8B\u5728HotpotQA\u4efb\u52a1\u4e2d\u7684Answer F1\u548cSupporting Fact F1\u5206\u522b\u63d0\u53478.56\u548c6.89\u3002", "conclusion": "G-MemLLM\u901a\u8fc7\u5f15\u5165\u53ef\u8bad\u7ec3\u7684\u6f5c\u5728\u8bb0\u5fc6\u5e93\u548cGRU\u98ce\u683c\u7684\u95e8\u63a7\u66f4\u65b0\u673a\u5236\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u63a8\u7406\u4e2d\u7684\u957f\u671f\u8bb0\u5fc6\u4fdd\u6301\u80fd\u529b\u548c\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u76f8\u5173\u4efb\u52a1\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.01665", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01665", "abs": "https://arxiv.org/abs/2602.01665", "authors": ["Hayeong Lee", "JunHyeok Oh", "Byung-Jun Lee"], "title": "TABX: A High-Throughput Sandbox Battle Simulator for Multi-Agent Reinforcement Learning", "comment": null, "summary": "The design of environments plays a critical role in shaping the development and evaluation of cooperative multi-agent reinforcement learning (MARL) algorithms. While existing benchmarks highlight critical challenges, they often lack the modularity required to design custom evaluation scenarios. We introduce the Totally Accelerated Battle Simulator in JAX (TABX), a high-throughput sandbox designed for reconfigurable multi-agent tasks. TABX provides granular control over environmental parameters, permitting a systematic investigation into emergent agent behaviors and algorithmic trade-offs across a diverse spectrum of task complexities. Leveraging JAX for hardware-accelerated execution on GPUs, TABX enables massive parallelization and significantly reduces computational overhead. By providing a fast, extensible, and easily customized framework, TABX facilitates the study of MARL agents in complex structured domains and serves as a scalable foundation for future research. Our code is available at: https://anonymous.4open.science/r/TABX-00CA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TABX\uff0c\u4e00\u4e2a\u57fa\u4e8eJAX\u7684\u9ad8\u6548\u591a\u667a\u80fd\u4f53\u4eff\u771f\u73af\u5883\uff0c\u901a\u8fc7\u786c\u4ef6\u52a0\u901f\u548c\u53c2\u6570\u53ef\u914d\u7f6e\u6027\u4fc3\u8fdbMARL\u7b97\u6cd5\u7684\u8bc4\u4f30\u548c\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u57fa\u51c6\u6d4b\u8bd5\u7f3a\u4e4f\u8db3\u591f\u7684\u6a21\u5757\u5316\u652f\u6301\uff0c\u96be\u4ee5\u8bbe\u8ba1\u5b9a\u5236\u7684\u8bc4\u4f30\u573a\u666f\uff0c\u9700\u8981\u4e00\u4e2a\u9ad8\u901a\u91cf\u3001\u7075\u6d3b\u4e14\u53ef\u6269\u5c55\u7684\u4eff\u771f\u6c99\u76d2\u73af\u5883\u6765\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5229\u7528JAX\u5b9e\u73b0\u786c\u4ef6\u52a0\u901f\uff0cTABX\u652f\u6301\u5728GPU\u4e0a\u8fdb\u884c\u5927\u89c4\u6a21\u5e76\u884c\u8ba1\u7b97\uff0c\u63d0\u4f9b\u4e86\u73af\u5883\u53c2\u6570\u7684\u7ec6\u7c92\u5ea6\u63a7\u5236\uff0c\u5b9e\u73b0\u4e86\u591a\u6837\u5316\u4efb\u52a1\u590d\u6742\u5ea6\u7684\u7cfb\u7edf\u5316\u7814\u7a76\u3002", "result": "TABX\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5feb\u901f\u3001\u53ef\u6269\u5c55\u4e14\u6613\u4e8e\u5b9a\u5236\u7684\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u5f00\u9500\uff0c\u652f\u6301\u590d\u6742\u7ed3\u6784\u57df\u4e2dMARL\u667a\u80fd\u4f53\u7684\u7814\u7a76\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u57fa\u7840\u3002", "conclusion": "TABX\u4f5c\u4e3a\u4e00\u4e2a\u9ad8\u6548\u53ef\u91cd\u6784\u7684\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u4eff\u771f\u73af\u5883\uff0c\u4e3aMARL\u7b97\u6cd5\u7684\u5f00\u53d1\u548c\u8bc4\u4f30\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u5de5\u5177\u652f\u6301\uff0c\u4fc3\u8fdb\u4e86\u5bf9\u667a\u80fd\u4f53\u884c\u4e3a\u548c\u7b97\u6cd5\u6743\u8861\u7684\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2602.00303", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2602.00303", "abs": "https://arxiv.org/abs/2602.00303", "authors": ["Jyoti Prakash", "Abhishek Tiwari", "Mikkel Baun Kj\u00e6rgaard"], "title": "Towards Analyzing N-language Polyglot Programs", "comment": null, "summary": "Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u7f16\u7a0b\u7cfb\u7edf\u7684\u9759\u6001\u5206\u6790\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u6982\u5ff5\u6027\u89e3\u51b3\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u8bed\u8a00\u65e0\u5173\u7684\u5206\u6790\u6280\u672f\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u591a\u8bed\u8a00\u7a0b\u5e8f\u5206\u6790\u591a\u96c6\u4e2d\u4e8e\u4e24\u79cd\u8bed\u8a00\uff0c\u800c\u5b9e\u9645\u7cfb\u7edf\u4e2d\u5e38\u6d89\u53ca\u4e09\u79cd\u53ca\u4ee5\u4e0a\u8bed\u8a00\uff0c\u4e14\u5982\u73b0\u4ee3\u7f51\u9875\u7cfb\u7edf\u4e2dJavaScript\u3001WebAssembly\u548cRust\u7684\u5171\u540c\u4f7f\u7528\uff0c\u4e9f\u9700\u65b0\u7684\u5206\u6790\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u4e0d\u8db3\uff0c\u5b9a\u4e49\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u7cfb\u7edf\u7684\u57fa\u672c\u6311\u6218\uff0c\u5e76\u6784\u5efa\u9759\u6001\u5206\u6790\u6280\u672f\u7684\u6982\u5ff5\u6027\u53d1\u5c55\u8def\u7ebf\u56fe\u3002", "result": "\u63d0\u51fa\u4e86\u9762\u5411\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u901a\u4fe1\u7684\u8f6f\u4ef6\u7cfb\u7edf\u9759\u6001\u5206\u6790\u7684\u57fa\u672c\u6311\u6218\u548c\u53d1\u5c55\u8def\u7ebf\uff0c\u4fc3\u8fdb\u672a\u6765\u76f8\u5173\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u9488\u5bf9\u4e09\u8bed\u8a00\u591a\u8bed\u8a00\u7f16\u7a0b\u7cfb\u7edf\u4e2d\u9759\u6001\u5206\u6790\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u6982\u5ff5\u6027\u8def\u7ebf\u56fe\uff0c\u63a8\u52a8\u672a\u6765\u53ef\u6269\u5c55\u3001\u8bed\u8a00\u65e0\u5173\u7684\u5206\u6790\u6846\u67b6\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.00016", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00016", "abs": "https://arxiv.org/abs/2602.00016", "authors": ["Jiongchi Yu", "Yuhan Ma", "Xiaoyu Zhang", "Junjie Wang", "Qiang Hu", "Chao Shen", "Xiaofei Xie"], "title": "PTCBENCH: Benchmarking Contextual Stability of Personality Traits in LLM Systems", "comment": "28 pages", "summary": "With the increasing deployment of large language models (LLMs) in affective agents and AI systems, maintaining a consistent and authentic LLM personality becomes critical for user trust and engagement. However, existing work overlooks a fundamental psychological consensus that personality traits are dynamic and context-dependent. To bridge this gap, we introduce PTCBENCH, a systematic benchmark designed to quantify the consistency of LLM personalities under controlled situational contexts. PTCBENCH subjects models to 12 distinct external conditions spanning diverse location contexts and life events, and rigorously assesses the personality using the NEO Five-Factor Inventory. Our study on 39,240 personality trait records reveals that certain external scenarios (e.g., \"Unemployment\") can trigger significant personality changes of LLMs, and even alter their reasoning capabilities. Overall, PTCBENCH establishes an extensible framework for evaluating personality consistency in realistic, evolving environments, offering actionable insights for developing robust and psychologically aligned AI systems.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faPTCBENCH\u57fa\u51c6\u7cfb\u7edf\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u7684\u4e2a\u6027\u4e00\u81f4\u6027\uff0c\u63ed\u793a\u6a21\u578b\u4e2a\u6027\u968f\u60c5\u5883\u53d8\u5316\u52a8\u6001\u6539\u53d8\uff0c\u63a8\u52a8\u5fc3\u7406\u5b66\u5bf9\u9f50\u7684AI\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5ffd\u89c6\u4e86\u4e2a\u6027\u7279\u8d28\u7684\u52a8\u6001\u548c\u60c5\u5883\u4f9d\u8d56\u6027\uff0c\u4e9f\u9700\u5efa\u7acb\u57fa\u4e8e\u60c5\u5883\u53d8\u5316\u8bc4\u4f30LLM\u4e2a\u6027\u4e00\u81f4\u6027\u7684\u6807\u51c6\u3002", "method": "\u901a\u8fc7PTCBENCH\u57fa\u51c6\uff0c\u5bf939,240\u6761\u6570\u636e\u572812\u79cd\u4e0d\u540c\u5916\u90e8\u60c5\u5883\u4e0b\u5229\u7528NEO\u4e94\u56e0\u7d20\u4eba\u683c\u91cf\u8868\u7cfb\u7edf\u6027\u8bc4\u4f30\u6a21\u578b\u4e2a\u6027\u4e00\u81f4\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u67d0\u4e9b\u60c5\u5883\uff08\u5982\u5931\u4e1a\uff09\u4f1a\u663e\u8457\u6539\u53d8LLM\u7684\u4e2a\u6027\u53ca\u63a8\u7406\u80fd\u529b\uff0cPTCBENCH\u4e3a\u771f\u5b9e\u52a8\u6001\u73af\u5883\u4e0b\u4e2a\u6027\u4e00\u81f4\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002", "conclusion": "\u8be5\u8bba\u6587\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5728\u4e0d\u540c\u60c5\u5883\u4e0b\u5b58\u5728\u52a8\u6001\u53d8\u5316\uff0c\u90e8\u5206\u5916\u90e8\u60c5\u5883\u663e\u8457\u5f71\u54cd\u6a21\u578b\u4e2a\u6027\u548c\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.02170", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02170", "abs": "https://arxiv.org/abs/2602.02170", "authors": ["Jose Manuel de la Chica Rodriguez", "Juan Manuel Vera D\u00edaz"], "title": "Self-Evolving Coordination Protocol in Multi-Agent AI Systems: An Exploratory Systems Feasibility Study", "comment": null, "summary": "Contemporary multi-agent systems increasingly rely on internal coordination mechanisms to combine, arbitrate, or constrain the outputs of heterogeneous components. In safety-critical and regulated domains such as finance, these mechanisms must satisfy strict formal requirements, remain auditable, and operate within explicitly bounded limits. Coordination logic therefore functions as a governance layer rather than an optimization heuristic.\n  This paper presents an exploratory systems feasibility study of Self-Evolving Coordination Protocols (SECP): coordination protocols that permit limited, externally validated self-modification while preserving fixed formal invariants. We study a controlled proof-of-concept setting in which six fixed Byzantine consensus protocol proposals are evaluated by six specialized decision modules. All coordination regimes operate under identical hard constraints, including Byzantine fault tolerance (f < n/3), O(n2) message complexity, complete non-statistical safety and liveness arguments, and bounded explainability.\n  Four coordination regimes are compared in a single-shot design: unanimous hard veto, weighted scalar aggregation, SECP v1.0 (an agent-designed non-scalar protocol), and SECP v2.0 (the result of one governed modification). Outcomes are evaluated using a single metric, proposal coverage, defined as the number of proposals accepted. A single recursive modification increased coverage from two to three accepted proposals while preserving all declared invariants.\n  The study makes no claims regarding statistical significance, optimality, convergence, or learning. Its contribution is architectural: it demonstrates that bounded self-modification of coordination protocols is technically implementable, auditable, and analyzable under explicit formal constraints, establishing a foundation for governed multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5177\u6709\u9650\u5b9a\u81ea\u6211\u4fee\u6539\u80fd\u529b\u4e14\u6ee1\u8db3\u4e25\u683c\u5f62\u5f0f\u7ea6\u675f\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u534f\u8bae\uff0c\u9a8c\u8bc1\u5176\u6280\u672f\u53ef\u884c\u6027\u548c\u5ba1\u8ba1\u6027\uff0c\u63a8\u52a8\u591a\u667a\u80fd\u4f53\u6cbb\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7279\u522b\u662f\u5728\u5b89\u5168\u5173\u952e\u9886\u57df\u9700\u8981\u534f\u8c03\u903b\u8f91\u4f5c\u4e3a\u6cbb\u7406\u5c42\uff0c\u6ee1\u8db3\u4e25\u683c\u7684\u5f62\u5f0f\u9700\u6c42\uff0c\u786e\u4fdd\u64cd\u4f5c\u5728\u660e\u786e\u9650\u5b9a\u7684\u8fb9\u754c\u5185\uff0c\u4e14\u4fdd\u6301\u53ef\u5ba1\u8ba1\u6027\u548c\u4e0d\u53d8\u6027\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u516d\u4e2a\u62dc\u5360\u5ead\u5171\u8bc6\u534f\u8bae\u63d0\u6848\u53ca\u516d\u4e2a\u4e13\u95e8\u51b3\u7b56\u6a21\u5757\u7684\u53d7\u63a7\u6982\u5ff5\u9a8c\u8bc1\u73af\u5883\uff0c\u6bd4\u8f83\u56db\u79cd\u534f\u8c03\u673a\u5236\uff08\u5305\u62ec\u4e24\u7248\u672c\u7684SECP\uff09\u5728\u76f8\u540c\u786c\u7ea6\u675f\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u7528\u63d0\u6848\u8986\u76d6\u7387\u6307\u6807\u8bc4\u4f30\u7ed3\u679c\u3002", "result": "\u901a\u8fc7\u4e00\u6b21\u9012\u5f52\u4fee\u6539\uff0cSECP\u534f\u8bae\u7684\u63d0\u6848\u8986\u76d6\u7387\u4ece\u63a5\u53d7\u4e24\u4e2a\u63d0\u6848\u63d0\u5347\u81f3\u4e09\u4e2a\uff0c\u540c\u65f6\u4fdd\u6301\u6240\u6709\u58f0\u660e\u7684\u4e0d\u53d8\u91cf\u6761\u4ef6\uff1b\u8be5\u4fee\u6539\u8fc7\u7a0b\u5728\u62dc\u5360\u5ead\u5bb9\u9519\u548c\u6d88\u606f\u590d\u6742\u5ea6\u7b49\u786c\u7ea6\u675f\u4e0b\u5b8c\u6210\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u5728\u4e25\u683c\u5f62\u5f0f\u7ea6\u675f\u4e0b\uff0c\u5177\u6709\u9650\u5b9a\u81ea\u6211\u4fee\u6539\u80fd\u529b\u7684\u534f\u8c03\u534f\u8bae\uff08SECP\uff09\u662f\u53ef\u5b9e\u73b0\u7684\u3001\u53ef\u5ba1\u8ba1\u4e14\u53ef\u5206\u6790\u7684\uff0c\u5960\u5b9a\u4e86\u53d7\u6cbb\u7406\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u57fa\u7840\u3002"}}
{"id": "2602.00409", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00409", "abs": "https://arxiv.org/abs/2602.00409", "authors": ["Andre Hora", "Romain Robbes"], "title": "Are Coding Agents Generating Over-Mocked Tests? An Empirical Study", "comment": "Accepted for publication at MSR 2026", "summary": "Coding agents have received significant adoption in software development recently. Unlike traditional LLM-based code completion tools, coding agents work with autonomy (e.g., invoking external tools) and leave visible traces in software repositories, such as authoring commits. Among their tasks, coding agents may autonomously generate software tests; however, the quality of these tests remains uncertain. In particular, excessive use of mocking can make tests harder to understand and maintain. This paper presents the first study to investigate the presence of mocks in agent-generated tests of real-world software systems. We analyzed over 1.2 million commits made in 2025 in 2,168 TypeScript, JavaScript, and Python repositories, including 48,563 commits by coding agents, 169,361 commits that modify tests, and 44,900 commits that add mocks to tests. Overall, we find that coding agents are more likely to modify tests and to add mocks to tests than non-coding agents. We detect that (1) 60% of the repositories with agent activity also contain agent test activity; (2) 23% of commits made by coding agents add/change test files, compared with 13% by non-agents; (3) 68% of the repositories with agent test activity also contain agent mock activity; (4) 36% of commits made by coding agents add mocks to tests, compared with 26% by non-agents; and (5) repositories created recently contain a higher proportion of test and mock commits made by agents. Finally, we conclude by discussing implications for developers and researchers. We call attention to the fact that tests with mocks may be potentially easier to generate automatically (but less effective at validating real interactions), and the need to include guidance on mocking practices in agent configuration files.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u7814\u7a76\u4ee3\u7801\u4ee3\u7406\u751f\u6210\u6d4b\u8bd5\u4e2d\u7684mock\u4f7f\u7528\uff0c\u53d1\u73b0\u4ee3\u7406\u66f4\u9891\u7e41\u6dfb\u52a0mock\uff0c\u6307\u51famock\u6d4b\u8bd5\u867d\u7136\u6613\u81ea\u52a8\u751f\u6210\u4f46\u6548\u679c\u6b20\u4f73\uff0c\u5efa\u8bae\u5728\u4ee3\u7406\u914d\u7f6e\u4e2d\u52a0\u5165mock\u6307\u5bfc\u3002", "motivation": "\u5f53\u524d\u4ee3\u7801\u4ee3\u7406\u751f\u6210\u7684\u6d4b\u8bd5\u8d28\u91cf\u53ca\u5176mock\u4f7f\u7528\u60c5\u51b5\u5c1a\u4e0d\u660e\u786e\uff0c\u8fc7\u5ea6\u4f7f\u7528mock\u53ef\u80fd\u5f71\u54cd\u6d4b\u8bd5\u7406\u89e3\u548c\u7ef4\u62a4\uff0c\u56e0\u6b64\u9700\u8981\u7cfb\u7edf\u6027\u8c03\u7814\u3002", "method": "\u5206\u67902025\u5e74\u8d85\u8fc7120\u4e07\u4e2a\u5305\u62ec2,168\u4e2aTypeScript\u3001JavaScript\u548cPython\u4ed3\u5e93\u4e2d\u7684\u63d0\u4ea4\uff0c\u6bd4\u8f83\u4ee3\u7801\u4ee3\u7406\u548c\u975e\u4ee3\u7406\u5728\u6d4b\u8bd5\u53camock\u4f7f\u7528\u4e0a\u7684\u884c\u4e3a\u5dee\u5f02\u3002", "result": "\u4ee3\u7801\u4ee3\u7406\u6bd4\u975e\u4ee3\u7406\u66f4\u503e\u5411\u4e8e\u4fee\u6539\u6d4b\u8bd5\u548c\u6dfb\u52a0mock\uff0c\u598223%\u7684\u4ee3\u7406\u63d0\u4ea4\u4fee\u6539\u6d4b\u8bd5\uff0c36%\u6dfb\u52a0mock\uff0c\u4e14\u65b0\u4ed3\u5e93\u4e2d\u4ee3\u7406\u6d4b\u8bd5\u548cmock\u63d0\u4ea4\u6bd4\u4f8b\u66f4\u9ad8\u3002", "conclusion": "\u4ee3\u7801\u4ee3\u7406\u751f\u6210\u7684\u6d4b\u8bd5\u4e2d\u5e7f\u6cdb\u4f7f\u7528mock\uff0c\u5c3d\u7ba1\u8fd9\u53ef\u80fd\u4f7f\u6d4b\u8bd5\u66f4\u6613\u81ea\u52a8\u751f\u6210\uff0c\u4f46\u964d\u4f4e\u4e86\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u9700\u5f15\u8d77\u5f00\u53d1\u8005\u548c\u7814\u7a76\u8005\u5173\u6ce8\u3002"}}
{"id": "2602.00017", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.00017", "abs": "https://arxiv.org/abs/2602.00017", "authors": ["Benyamin Tabarsi", "Wenbo Li", "Tahreem Yasir", "Aryan Santhosh Kumar", "Laura Widman", "Dongkuan Xu", "Tiffany Barnes"], "title": "SafeTalkCoach: Diversity-Driven Multi-Agent Simulation for Parent-Teen Health Conversations", "comment": null, "summary": "The importance of effective parent-child communication about sexual health is widely acknowledged, but real-world data on these conversations is scarce and challenging to collect, due to their private and sensitive nature. Although LLMs have been widely adopted in dialogue generation, they may deviate from best practices and frequently lack realism and diversity. We introduce SafeTalkCoach, a diversity-driven multi-agent dialogue generation framework that simulates parent-child conversations about sexual health, and present an accompanying dataset. SafeTalkCoach integrates crowd-sourced and synthesized scenarios, established sexual health guidelines, evidence-based personas, adaptive control modules, and hierarchical diversification. Through evaluations, we demonstrate that SafeTalkCoach generates diverse conversations while maintaining realism, communication quality, and controllability in practice. Our goal is that the SafeTalkCoach framework and the dataset support both AI research and health communications practices.", "AI": {"tldr": "SafeTalkCoach\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u548c\u591a\u6837\u5316\u6280\u672f\uff0c\u751f\u6210\u771f\u5b9e\u4e14\u591a\u6837\u7684\u4eb2\u5b50\u6027\u5065\u5eb7\u5bf9\u8bdd\uff0c\u63a8\u52a8\u76f8\u5173AI\u4e0e\u5065\u5eb7\u4ea4\u6d41\u7814\u7a76\u3002", "motivation": "\u7236\u6bcd\u4e0e\u5b69\u5b50\u4e4b\u95f4\u5173\u4e8e\u6027\u5065\u5eb7\u7684\u6709\u6548\u6c9f\u901a\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u5176\u9690\u79c1\u548c\u654f\u611f\u6027\uff0c\u5b9e\u9645\u5bf9\u8bdd\u6570\u636e\u96be\u4ee5\u6536\u96c6\u3002", "method": "\u63d0\u51faSafeTalkCoach\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u5bf9\u8bdd\u751f\u6210\u6846\u67b6\uff0c\u7ed3\u5408\u4f17\u5305\u4e0e\u5408\u6210\u573a\u666f\u3001\u6027\u5065\u5eb7\u6307\u5357\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u4eba\u7269\u8bbe\u5b9a\u3001\u81ea\u9002\u5e94\u63a7\u5236\u6a21\u5757\u53ca\u5206\u5c42\u591a\u6837\u5316\u6280\u672f\u3002", "result": "\u901a\u8fc7\u8bc4\u4f30\uff0cSafeTalkCoach\u751f\u6210\u7684\u5bf9\u8bdd\u65e2\u591a\u6837\u53c8\u5177\u5907\u73b0\u5b9e\u611f\uff0c\u901a\u4fe1\u8d28\u91cf\u548c\u53ef\u63a7\u6027\u5f97\u5230\u4fdd\u969c\u3002", "conclusion": "SafeTalkCoach\u6846\u67b6\u53ca\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u4fc3\u8fdbAI\u7814\u7a76\u53ca\u5065\u5eb7\u4ea4\u6d41\u5b9e\u8df5\uff0c\u652f\u6301\u5173\u4e8e\u6027\u5065\u5eb7\u7684\u6709\u6548\u4eb2\u5b50\u6c9f\u901a\u3002"}}
{"id": "2602.00410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00410", "abs": "https://arxiv.org/abs/2602.00410", "authors": ["Andre Hora"], "title": "GitEvo: Code Evolution Analysis for Git Repositories", "comment": "Accepted for publication at MSR 2026", "summary": "Analyzing the code evolution of software systems is relevant for practitioners, researchers, and educators. It can help practitioners identify design trends and maintenance challenges, provide researchers with empirical data to study changes over time, and give educators real-world examples that enhance the teaching of software evolution concepts. Unfortunately, we lack tools specifically designed to support code evolution analysis. In this paper, we propose GitEvo, a multi-language and extensible tool for analyzing code evolution in Git repositories. GitEvo leverages Git frameworks and code parsing tools to integrate both Git-level and code-level analysis. We conclude by describing how GitEvo can support the development of novel empirical studies on code evolution and act as a learning tool for educators and students. GitEvo is available at: https://github.com/andrehora/gitevo.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86GitEvo\uff0c\u4e00\u6b3e\u96c6\u6210Git\u548c\u4ee3\u7801\u7ea7\u5206\u6790\u7684\u591a\u8bed\u8a00\u5de5\u5177\uff0c\u89e3\u51b3\u4e86\u4ee3\u7801\u6f14\u5316\u5206\u6790\u5de5\u5177\u532e\u4e4f\u7684\u95ee\u9898\uff0c\u4fc3\u8fdb\u4e86\u5b9e\u8bc1\u7814\u7a76\u548c\u6559\u5b66\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u4e13\u95e8\u652f\u6301\u4ee3\u7801\u6f14\u5316\u5206\u6790\u7684\u5de5\u5177\uff0c\u800c\u4ee3\u7801\u6f14\u5316\u5206\u6790\u5bf9\u5b9e\u8df5\u8005\u3001\u7814\u7a76\u8005\u548c\u6559\u80b2\u8005\u5747\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u901a\u8fc7\u5229\u7528Git\u6846\u67b6\u548c\u4ee3\u7801\u89e3\u6790\u5de5\u5177\uff0cGitEvo\u5b9e\u73b0\u4e86\u5bf9\u4ee3\u7801\u6f14\u5316\u7684\u7efc\u5408\u5206\u6790\uff0c\u652f\u6301\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u3002", "result": "GitEvo\u7684\u5b9e\u73b0\u4e0d\u4ec5\u586b\u8865\u4e86\u5de5\u5177\u7f3a\u53e3\uff0c\u8fd8\u80fd\u652f\u6301\u65b0\u578b\u7684\u5b9e\u8bc1\u7814\u7a76\u548c\u6559\u5b66\u6d3b\u52a8\u3002", "conclusion": "GitEvo\u662f\u4e00\u6b3e\u591a\u8bed\u8a00\u4e14\u53ef\u6269\u5c55\u7684\u5de5\u5177\uff0c\u80fd\u591f\u652f\u6301Git\u4ed3\u5e93\u4e2d\u7684\u4ee3\u7801\u6f14\u5316\u5206\u6790\uff0c\u7ed3\u5408\u4e86Git\u7ea7\u548c\u4ee3\u7801\u7ea7\u7684\u5206\u6790\u65b9\u6cd5\u3002"}}
{"id": "2602.00029", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00029", "abs": "https://arxiv.org/abs/2602.00029", "authors": ["Yao Zhang", "Hongyin Zhu"], "title": "Construct, Align, and Reason: Large Ontology Models for Enterprise Knowledge Management", "comment": null, "summary": "Enterprise-scale knowledge management faces significant challenges in integrating multi-source heterogeneous data and enabling effective semantic reasoning. Traditional knowledge graphs often struggle with implicit relationship discovery and lack sufficient semantic understanding for complex question answering. To address these limitations, we introduce a unified construct--align--reason framework, the large ontology model (LOM). We first build a dual-layer enterprise ontology from structured databases and unstructured text, subsequently fusing these sources into a comprehensive enterprise ontology. To enable instruction-aligned reasoning, we propose a unified three-stage training pipeline: ontology instruction fine-tuning to improve structural understanding; text-ontology grounding to strengthen node semantic encoding; and multi-task instruction tuning on ontology-language pairs with curriculum learning to enhance semantic reasoning and generation. We also construct comprehensive training and evaluation datasets covering diverse ontology reasoning tasks. On this benchmark, our 4B-parameter LOM achieves 89.47% accuracy and outperforms DeepSeek-V3.2 on complex graph reasoning, indicating effective fusion of ontology structure and language.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u4f01\u4e1a\u77e5\u8bc6\u7ba1\u7406\u4e2d\u5f02\u6784\u6570\u636e\u878d\u5408\u548c\u590d\u6742\u8bed\u4e49\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684LOM\u6846\u67b6\u548c\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u4f01\u4e1a\u7ea7\u77e5\u8bc6\u7ba1\u7406\u9762\u4e34\u591a\u6e90\u5f02\u6784\u6570\u636e\u6574\u5408\u548c\u590d\u6742\u8bed\u4e49\u63a8\u7406\u7684\u6311\u6218\uff0c\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u96be\u4ee5\u53d1\u73b0\u9690\u542b\u5173\u7cfb\u5e76\u7f3a\u4e4f\u5bf9\u590d\u6742\u95ee\u7b54\u7684\u5145\u5206\u8bed\u4e49\u7406\u89e3\u3002", "method": "\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u6784\u5efa-\u5bf9\u9f50-\u63a8\u7406\u6846\u67b6\uff0c\u6784\u5efa\u53cc\u5c42\u4f01\u4e1a\u672c\u4f53\uff0c\u4ece\u7ed3\u6784\u5316\u6570\u636e\u5e93\u548c\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u878d\u5408\u4fe1\u606f\uff1b\u8bbe\u8ba1\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u5305\u62ec\u672c\u4f53\u6307\u4ee4\u5fae\u8c03\u3001\u6587\u672c-\u672c\u4f53\u5bf9\u9f50\u5f3a\u5316\u8282\u70b9\u8bed\u4e49\u7f16\u7801\u3001\u591a\u4efb\u52a1\u6307\u4ee4\u8c03\u4f18\u548c\u8bfe\u7a0b\u5b66\u4e60\u3002", "result": "4B\u53c2\u6570\u7684LOM\u6a21\u578b\u5728\u6784\u5efa\u7684\u591a\u6837\u672c\u672c\u4f53\u63a8\u7406\u8bc4\u6d4b\u96c6\u4e0a\u53d6\u5f97\u4e8689.47%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8eDeepSeek-V3.2\uff0c\u4e0e\u590d\u6742\u56fe\u63a8\u7406\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "LOM\u6846\u67b6\u6709\u6548\u878d\u5408\u4e86\u4f01\u4e1a\u672c\u4f53\u7ed3\u6784\u548c\u8bed\u8a00\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u56fe\u63a8\u7406\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2602.00457", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00457", "abs": "https://arxiv.org/abs/2602.00457", "authors": ["Yizhuo Yang", "Lingyun Xu", "Mingyi Zhou", "Li Li"], "title": "Context-Sensitive Pointer Analysis for ArkTS", "comment": "Accepted at ASE industry 2025", "summary": "Current call graph generation methods for ArkTS, a new programming language for OpenHarmony, exhibit precision limitations when supporting advanced static analysis tasks such as data flow analysis and vulnerability pattern detection, while the workflow of traditional JavaScript(JS)/TypeScript(TS) analysis tools fails to interpret ArkUI component tree semantics. The core technical bottleneck originates from the closure mechanisms inherent in TypeScript's dynamic language features and the interaction patterns involving OpenHarmony's framework APIs. Existing static analysis tools for ArkTS struggle to achieve effective tracking and precise deduction of object reference relationships, leading to topological fractures in call graph reachability and diminished analysis coverage. This technical limitation fundamentally constrains the implementation of advanced program analysis techniques.\n  Therefore, in this paper, we propose a tool named ArkAnalyzer Pointer Analysis Kit (APAK), the first context-sensitive pointer analysis framework specifically designed for ArkTS. APAK addresses these challenges through a unique ArkTS heap object model and a highly extensible plugin architecture, ensuring future adaptability to the evolving OpenHarmony ecosystem. In the evaluation, we construct a dataset from 1,663 real-world applications in the OpenHarmony ecosystem to evaluate APAK, demonstrating APAK's superior performance over CHA/RTA approaches in critical metrics including valid edge coverage (e.g., a 7.1% reduction compared to CHA and a 34.2% increase over RTA). The improvement in edge coverage systematically reduces false positive rates from 20% to 2%, enabling future exploration of establishing more complex program analysis tools based on our framework. Our proposed APAK has been merged into the official static analysis framework ArkAnalyzer for OpenHarmony.", "AI": {"tldr": "\u9488\u5bf9ArkTS\u9759\u6001\u5206\u6790\u5b58\u5728\u7684\u74f6\u9888\uff0c\u63d0\u51fa\u4e86APAK\u6307\u9488\u5206\u6790\u5de5\u5177\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u654f\u611f\u5206\u6790\u548c\u63d2\u4ef6\u67b6\u6784\u63d0\u5347\u8c03\u7528\u56fe\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\uff0c\u663e\u8457\u964d\u4f4e\u8bef\u62a5\u7387\uff0c\u63a8\u52a8\u9ad8\u7ea7\u7a0b\u5e8f\u5206\u6790\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u5f53\u524dArkTS\u7684\u8c03\u7528\u56fe\u751f\u6210\u65b9\u6cd5\u5728\u652f\u6301\u9ad8\u7ea7\u9759\u6001\u5206\u6790\u4efb\u52a1\u65f6\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u4e14\u4f20\u7edfJS/TS\u5206\u6790\u5de5\u5177\u65e0\u6cd5\u6709\u6548\u89e3\u91caArkUI\u7ec4\u4ef6\u6811\u8bed\u4e49\uff0c\u9650\u5236\u4e86\u9ad8\u7ea7\u7a0b\u5e8f\u5206\u6790\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u72ec\u7279\u7684ArkTS\u5806\u5bf9\u8c61\u6a21\u578b\u548c\u9ad8\u5ea6\u53ef\u6269\u5c55\u7684\u63d2\u4ef6\u67b6\u6784\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u654f\u611f\u6307\u9488\u5206\u6790\u6280\u672f\u89e3\u51b3\u95ed\u5305\u673a\u5236\u548c\u6846\u67b6API\u4ea4\u4e92\u5e26\u6765\u7684\u5206\u6790\u96be\u9898\u3002", "result": "\u57281663\u4e2aOpenHarmony\u771f\u5b9e\u5e94\u7528\u4e0a\u8bc4\u6d4b\uff0cAPAK\u5728\u6709\u6548\u8fb9\u8986\u76d6\u5ea6\u65b9\u9762\u4f18\u4e8eCHA\u548cRTA\u65b9\u6cd5\uff0c\u6709\u6548\u8fb9\u8986\u76d6\u5ea6\u63d0\u534734.2%\uff0c\u8bef\u62a5\u7387\u4ece20%\u964d\u81f32%\uff0c\u5206\u6790\u8986\u76d6\u7387\u548c\u51c6\u786e\u6027\u5927\u5e45\u63d0\u9ad8\u3002", "conclusion": "APAK\u662f\u9996\u4e2a\u4e13\u95e8\u9488\u5bf9ArkTS\u8bbe\u8ba1\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u6307\u9488\u5206\u6790\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8c03\u7528\u56fe\u7684\u51c6\u786e\u6027\u548c\u5206\u6790\u8986\u76d6\u7387\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\uff0c\u652f\u6301\u66f4\u590d\u6742\u7684\u7a0b\u5e8f\u5206\u6790\u6280\u672f\u5b9e\u73b0\u3002"}}
{"id": "2602.00150", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00150", "abs": "https://arxiv.org/abs/2602.00150", "authors": ["Xinyun Wang", "Min Zhang", "Sen Cui", "Zhikang Chen", "Bo Jiang", "Kun Kuang", "Mingbao Lin"], "title": "Reversible Diffusion Decoding for Diffusion Language Models", "comment": null, "summary": "Diffusion language models enable parallel token generation through block-wise decoding, but their irreversible commitments can lead to stagnation, where the reverse diffusion process fails to make further progress under a suboptimal context.We propose Reversible Diffusion Decoding (RDD), a decoding framework that introduces reversibility into block-wise diffusion generation. RDD detects stagnation as a state-dependent failure of the reverse process and enables efficient backtracking to earlier blocks without recomputation via cached model states. To avoid repeated failure trajectories, RDD applies confidence-guided re-masking to selectively reinitialize uncertain tokens while preserving reliable context.This reversible formulation allows decoding to recover from early commitment errors while maintaining the parallel efficiency of diffusion-based generation. Experiments show that RDD improves generation robustness and quality over baselines with minimal computational overhead.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u9006\u6269\u6563\u89e3\u7801\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e2d\u7684\u505c\u6ede\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u4e14\u9ad8\u6548\u7684\u5e76\u884c\u6587\u672c\u751f\u6210\u3002", "motivation": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u5757\u5f0f\u89e3\u7801\u65f6\u5b58\u5728\u4e0d\u53ef\u9006\u627f\u8bfa\uff0c\u53ef\u80fd\u5bfc\u81f4\u9006\u5411\u6269\u6563\u8fc7\u7a0b\u505c\u6ede\uff0c\u751f\u6210\u7ed3\u679c\u53d7\u9650\u4e14\u96be\u4ee5\u6539\u8fdb\u3002\u4e3a\u6b64\uff0c\u63d0\u51fa\u5f15\u5165\u53ef\u9006\u673a\u5236\u4ee5\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u6a21\u578b\u9c81\u68d2\u6027\u3002", "method": "RDD\u901a\u8fc7\u5f15\u5165\u53ef\u9006\u673a\u5236\uff0c\u5728\u5757\u5f0f\u6269\u6563\u751f\u6210\u4e2d\u68c0\u6d4b\u9006\u5411\u8fc7\u7a0b\u7684\u505c\u6ede\u72b6\u6001\uff0c\u5229\u7528\u7f13\u5b58\u6a21\u578b\u72b6\u6001\u5b9e\u73b0\u9ad8\u6548\u56de\u6eaf\uff0c\u5e76\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u91cd\u65b0\u906e\u7f69\u9009\u62e9\u6027\u5730\u91cd\u65b0\u521d\u59cb\u5316\u4e0d\u786e\u5b9a\u7684\u751f\u6210\u6807\u8bb0\uff0c\u4ece\u800c\u907f\u514d\u91cd\u590d\u5931\u8d25\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86RDD\u5728\u4fdd\u6301\u8ba1\u7b97\u5f00\u9500\u8f83\u4f4e\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u7684\u9c81\u68d2\u6027\u548c\u8d28\u91cf\uff0c\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u53ef\u9006\u6269\u6563\u89e3\u7801\uff08RDD\uff09\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u7531\u4e8e\u4e0d\u53ef\u9006\u627f\u8bfa\u5bfc\u81f4\u7684\u505c\u6ede\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u751f\u6210\u7684\u9c81\u68d2\u6027\u548c\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6548\u7684\u5e76\u884c\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2602.00715", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00715", "abs": "https://arxiv.org/abs/2602.00715", "authors": ["Zehan Chen", "Long Zhang", "Zhiwei Zhang", "JingJing Zhang", "Ruoyu Zhou", "Yulong Shen", "JianFeng Ma", "Lin Yang"], "title": "Beyond Basic Specifications? A Systematic Study of Logical Constructs in LLM-based Specification Generation", "comment": null, "summary": "Formal specifications play a pivotal role in accurately characterizing program behaviors and ensuring software correctness. In recent years, leveraging large language models (LLMs) for the automatic generation of program specifications has emerged as a promising avenue for enhancing verification efficiency. However, existing research has been predominantly confined to generating specifications based on basic syntactic constructs, falling short of meeting the demands for high-level abstraction in complex program verification. Consequently, we propose incorporating logical constructs into existing LLM-based specification generation framework. Nevertheless, there remains a lack of systematic investigation into whether LLMs can effectively generate such complex constructs. To this end, we conduct an empirical study aimed at exploring the impact of various types of syntactic constructs on specification generation framework. Specifically, we define four syntactic configurations with varying levels of abstraction and perform extensive evaluations on mainstream program verification datasets, employing a diverse set of representative LLMs. Experimental results first confirm that LLMs are capable of generating valid logical constructs. Further analysis reveals that the synergistic use of logical constructs and basic syntactic constructs leads to improvements in both verification capability and robustness, without significantly increasing verification overhead. Additionally, we uncover the distinct advantages of two refinement paradigms. To the best of our knowledge, this is the first systematic work exploring the feasibility of utilizing LLMs for generating high-level logical constructs, providing an empirical basis and guidance for the future construction of automated program verification framework with enhanced abstraction capabilities.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u9ad8\u5c42\u6b21\u903b\u8f91\u5f62\u5f0f\u89c4\u8303\u7684\u53ef\u884c\u6027\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u7a0b\u5e8f\u9a8c\u8bc1\u62bd\u8c61\u80fd\u529b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u9a8c\u8bc1\u6846\u67b6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u548c\u6307\u5bfc\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u7a0b\u5e8f\u89c4\u8303\u751f\u6210\u591a\u5c40\u9650\u4e8e\u57fa\u7840\u8bed\u6cd5\uff0c\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u7a0b\u5e8f\u9ad8\u5c42\u6b21\u62bd\u8c61\u7684\u9700\u6c42\uff0c\u8feb\u5207\u9700\u8981\u7814\u7a76LLMs\u5728\u751f\u6210\u590d\u6742\u903b\u8f91\u6784\u9020\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u56db\u79cd\u4e0d\u540c\u62bd\u8c61\u5c42\u6b21\u7684\u8bed\u6cd5\u914d\u7f6e\uff0c\u5e76\u5728\u4e3b\u6d41\u7a0b\u5e8f\u9a8c\u8bc1\u6570\u636e\u96c6\u4e0a\u5229\u7528\u591a\u79cd\u4ee3\u8868\u6027LLMs\u8fdb\u884c\u7efc\u5408\u5b9e\u9a8c\u8bc4\u4f30\uff0c\u7cfb\u7edf\u63a2\u8ba8\u5404\u79cd\u8bed\u6cd5\u6784\u9020\u5bf9\u89c4\u8303\u751f\u6210\u6846\u67b6\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86LLMs\u751f\u6210\u6709\u6548\u903b\u8f91\u6784\u9020\u7684\u80fd\u529b\uff0c\u903b\u8f91\u6784\u9020\u4e0e\u57fa\u672c\u8bed\u6cd5\u534f\u540c\u4f7f\u7528\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u4e14\u53d1\u73b0\u4e86\u4e24\u79cd\u7ec6\u5316\u8303\u5f0f\u5404\u81ea\u7684\u4f18\u52bf\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u80fd\u591f\u6709\u6548\u751f\u6210\u5305\u542b\u590d\u6742\u903b\u8f91\u6784\u9020\u7684\u9ad8\u5c42\u6b21\u5f62\u5f0f\u89c4\u8303\uff0c\u8fd9\u79cd\u878d\u5408\u57fa\u672c\u8bed\u6cd5\u548c\u903b\u8f91\u6784\u9020\u7684\u65b9\u6cd5\u63d0\u5347\u4e86\u7a0b\u5e8f\u9a8c\u8bc1\u7684\u80fd\u529b\u548c\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u9a8c\u8bc1\u5f00\u9500\u5e76\u672a\u663e\u8457\u589e\u52a0\u3002"}}
{"id": "2602.00238", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00238", "abs": "https://arxiv.org/abs/2602.00238", "authors": ["Tianyi Hu", "Niket Tandon", "Akhil Arora"], "title": "DIVERGE: Diversity-Enhanced RAG for Open-Ended Information Seeking", "comment": null, "summary": "Existing retrieval-augmented generation (RAG) systems are primarily designed under the assumption that each query has a single correct answer. This overlooks common information-seeking scenarios with multiple plausible answers, where diversity is essential to avoid collapsing to a single dominant response, thereby constraining creativity and compromising fair and inclusive information access. Our analysis reveals a commonly overlooked limitation of standard RAG systems: they underutilize retrieved context diversity, such that increasing retrieval diversity alone does not yield diverse generations. To address this limitation, we propose DIVERGE, a plug-and-play agentic RAG framework with novel reflection-guided generation and memory-augmented iterative refinement, which promotes diverse viewpoints while preserving answer quality. We introduce novel metrics tailored to evaluating the diversity-quality trade-off in open-ended questions, and show that they correlate well with human judgments. We demonstrate that DIVERGE achieves the best diversity-quality trade-off compared to competitive baselines and previous state-of-the-art methods on the real-world Infinity-Chat dataset, substantially improving diversity while maintaining quality. More broadly, our results reveal a systematic limitation of current LLM-based systems for open-ended information-seeking and show that explicitly modeling diversity can mitigate it. Our code is available at: https://github.com/au-clan/Diverge", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u4fe1\u606f\u68c0\u7d22\u751f\u6210\u7cfb\u7edf\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51faDIVERGE\u6846\u67b6\uff0c\u901a\u8fc7\u53cd\u601d\u5f15\u5bfc\u548c\u8bb0\u5fc6\u589e\u5f3a\u8fed\u4ee3\u65b9\u6cd5\u63d0\u5347\u591a\u6837\u6027\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u4fdd\u6301\u7b54\u6848\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u589e\u52a0\u4e86\u591a\u6837\u6027\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5047\u8bbe\u6bcf\u4e2a\u67e5\u8be2\u5bf9\u5e94\u552f\u4e00\u6b63\u786e\u7b54\u6848\uff0c\u5ffd\u89c6\u4e86\u5b9e\u9645\u4fe1\u606f\u68c0\u7d22\u4e2d\u5b58\u5728\u591a\u79cd\u5408\u7406\u7b54\u6848\u7684\u60c5\u51b5\uff0c\u5bfc\u81f4\u751f\u6210\u7ed3\u679c\u5355\u4e00\uff0c\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u5305\u5bb9\u6027\u3002", "method": "\u63d0\u51faDIVERGE\u6846\u67b6\uff0c\u5305\u62ec\u53cd\u601d\u5f15\u5bfc\u751f\u6210\u548c\u8bb0\u5fc6\u589e\u5f3a\u7684\u8fed\u4ee3\u4f18\u5316\u673a\u5236\uff0c\u7cfb\u7edf\u6027\u4fc3\u8fdb\u591a\u6837\u5316\u89c2\u70b9\u7684\u751f\u6210\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u591a\u6837\u6027\u4e0e\u8d28\u91cf\u6743\u8861\u6307\u6807\uff0c\u7ecf\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u6548\u679c\u4f18\u5f02\u3002", "result": "\u5728Infinity-Chat\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0cDIVERGE\u5728\u591a\u6837\u6027\u548c\u7b54\u6848\u8d28\u91cf\u7684\u6743\u8861\u65b9\u9762\u4f18\u4e8e\u7ade\u4e89\u65b9\u6cd5\u548c\u4e4b\u524d\u7684\u6700\u65b0\u6280\u672f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7ed3\u679c\u7684\u591a\u6837\u6027\u4e14\u4fdd\u6301\u4e86\u7b54\u6848\u8d28\u91cf\uff0c\u6307\u6807\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u5728\u5904\u7406\u591a\u7b54\u6848\u4fe1\u606f\u67e5\u8be2\u65f6\u5b58\u5728\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u9650\u5236\u4e86\u521b\u9020\u529b\u548c\u4fe1\u606f\u516c\u5e73\u6027\u3002\u6211\u4eec\u63d0\u51fa\u7684DIVERGE\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u751f\u6210\u56de\u7b54\u7684\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u56de\u7b54\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.00746", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.00746", "abs": "https://arxiv.org/abs/2602.00746", "authors": ["Jianping Zhong", "Guochang Li", "Chen Zhi", "Junxiao Han", "Zhen Qin", "Xinkui Zhao", "Nan Wang", "Shuiguang Deng", "Jianwei Yin"], "title": "Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression", "comment": null, "summary": "Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion.\n  Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\\sim$1.7$\\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\\sim$4.3 hours to $\\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u957f\u4ee3\u7801\u4e0a\u4e0b\u6587\u9650\u5236\uff0cLongCodeOCR\u901a\u8fc7\u89c6\u89c9\u538b\u7f29\u4ee3\u7801\u4e3a\u56fe\u50cf\u5e8f\u5217\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u5168\u5c40\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6027\u80fd\uff0c\u4e14\u51cf\u5c11\u5ef6\u8fdf\uff0c\u662f\u73b0\u6709\u6587\u672c\u538b\u7f29\u65b9\u6cd5\u7684\u6709\u529b\u8865\u5145\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u4ee3\u7801\u65f6\u53d7\u9650\u4e8e\u7a97\u53e3\u5927\u5c0f\uff0c\u73b0\u6709\u7684\u6587\u672c\u4ee3\u7801\u538b\u7f29\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u8fc7\u6ee4\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u4f46\u5f80\u5f80\u5bfc\u81f4\u4f9d\u8d56\u4e2d\u65ad\u548c\u8bed\u4e49\u788e\u7247\u5316\u3002", "method": "\u63d0\u51fa\u4e86LongCodeOCR\uff0c\u4e00\u79cd\u89c6\u89c9\u538b\u7f29\u6846\u67b6\uff0c\u5c06\u4ee3\u7801\u6e32\u67d3\u4e3a\u538b\u7f29\u7684\u4e8c\u7ef4\u56fe\u50cf\u5e8f\u5217\uff0c\u4f9b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5904\u7406\uff0c\u4ee5\u4fdd\u6301\u5168\u5c40\u89c6\u89d2\uff0c\u907f\u514d\u4f9d\u8d56\u4e2d\u65ad\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLongCodeOCR\u4ee5\u7ea61.7\u500d\u538b\u7f29\u7387\u5728\u4ee3\u7801\u603b\u7ed3\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5LongCodeZip 36.85\u5206\uff1b\u57281\u767e\u4e07\u4ee4\u724c\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\uff0c\u4f7f\u7528\u4e13\u75289B\u89c6\u89c9\u8bed\u8a00\u6a21\u578bGlyph\uff0cLongCodeOCR\u5728\u7ea64\u500d\u538b\u7f29\u7387\u4e0b\u4fdd\u6301\u66f4\u9ad8\u51c6\u786e\u7387\uff1b\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u538b\u7f29\u9636\u6bb5\u5ef6\u8fdf\uff0c\u4ece\u7ea64.3\u5c0f\u65f6\u964d\u81f3\u7ea61\u5206\u949f\u3002", "conclusion": "\u89c6\u89c9\u4ee3\u7801\u538b\u7f29\u4e3a\u9700\u8981\u5168\u5c40\u7406\u89e3\u7684\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u66ff\u4ee3\u65b9\u6848\uff0c\u867d\u7136\u5728\u7cbe\u5ea6\u5173\u952e\u4efb\u52a1\u4e2d\u5b58\u5728\u4fdd\u771f\u5ea6\u74f6\u9888\uff0c\u4f46\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u5168\u5c40\u4f9d\u8d56\uff1b\u800c\u6587\u672c\u4ee3\u7801\u538b\u7f29\u727a\u7272\u7ed3\u6784\u8986\u76d6\u4ee5\u4fdd\u7559\u7b26\u53f7\u7cbe\u5ea6\u3002"}}
{"id": "2602.00279", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00279", "abs": "https://arxiv.org/abs/2602.00279", "authors": ["Philip M\u00fcller", "Nicholas Popovi\u010d", "Michael F\u00e4rber", "Peter Steinbach"], "title": "Benchmarking Uncertainty Calibration in Large Language Model Long-Form Question Answering", "comment": "Under Review", "summary": "Large Language Models (LLMs) are commonly used in Question Answering (QA) settings, increasingly in the natural sciences if not science at large. Reliable Uncertainty Quantification (UQ) is critical for the trustworthy uptake of generated answers. Existing UQ approaches remain weakly validated in scientific QA, a domain relying on fact-retrieval and reasoning capabilities. We introduce the first large-scale benchmark for evaluating UQ metrics in reasoning-demanding QA studying calibration of UQ methods, providing an extensible open-source framework to reproducibly assess calibration. Our study spans up to 20 large language models of base, instruction-tuned and reasoning variants. Our analysis covers seven scientific QA datasets, including both multiple-choice and arithmetic question answering tasks, using prompting to emulate an open question answering setting. We evaluate and compare methods representative of prominent approaches on a total of 685,000 long-form responses, spanning different reasoning complexities representative of domain-specific tasks. At the token level, we find that instruction tuning induces strong probability mass polarization, reducing the reliability of token-level confidences as estimates of uncertainty. Models further fine-tuned for reasoning are exposed to the same effect, but the reasoning process appears to mitigate it depending on the provider. At the sequence level, we show that verbalized approaches are systematically biased and poorly correlated with correctness, while answer frequency (consistency across samples) yields the most reliable calibration. In the wake of our analysis, we study and report the misleading effect of relying exclusively on ECE as a sole measure for judging performance of UQ methods on benchmark datasets. Our findings expose critical limitations of current UQ methods for LLMs and standard practices in benchmarking thereof.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u5927\u89c4\u6a21\u79d1\u5b66\u95ee\u7b54\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u57fa\u51c6\uff0c\u53d1\u73b0\u6307\u4ee4\u8c03\u6559\u5f71\u54cd\u7f6e\u4fe1\u4f30\u8ba1\uff0c\u7b54\u6848\u9891\u7387\u65b9\u6cd5\u6548\u679c\u6700\u597d\uff0c\u547c\u5401\u6539\u8fdbUQ\u8bc4\u4ef7\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\u5728\u79d1\u5b66\u95ee\u7b54\uff08QA\uff09\u9886\u57df\u9a8c\u8bc1\u4e0d\u8db3\uff0c\u800c\u79d1\u5b66QA\u4f9d\u8d56\u4e8b\u5b9e\u68c0\u7d22\u548c\u63a8\u7406\u80fd\u529b\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u53ef\u9760\u7684UQ\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5728\u9700\u8981\u63a8\u7406\u7684QA\u4e2dUQ\u6307\u6807\u7684\u6821\u51c6\uff0c\u6db5\u76d620\u4e2a\u4e0d\u540c\u7c7b\u578b\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c7\u4e2a\u79d1\u5b66QA\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u63d0\u793a\u65b9\u6cd5\u6a21\u4eff\u5f00\u653e\u5f0f\u95ee\u7b54\uff0c\u5206\u6790\u4e86685,000\u6761\u957f\u56de\u7b54\uff0c\u6bd4\u8f83\u591a\u79cdUQ\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u6307\u4ee4\u8c03\u6559\u5bfc\u81f4token\u7ea7\u7f6e\u4fe1\u6982\u7387\u6781\u5316\uff0c\u964d\u4f4etoken\u7ea7\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u7684\u53ef\u9760\u6027\u3002\u63a8\u7406\u8c03\u6559\u6a21\u578b\u4e5f\u5b58\u5728\u6b64\u95ee\u9898\uff0c\u4f46\u63a8\u7406\u8fc7\u7a0b\u6709\u6240\u7f13\u89e3\u3002\u5e8f\u5217\u7ea7\u4e0a\uff0c\u53e3\u5934\u5316\u65b9\u6cd5\u5b58\u5728\u504f\u5dee\u4e14\u4e0e\u6b63\u786e\u7387\u76f8\u5173\u6027\u5dee\uff0c\u7b54\u6848\u9891\u7387\uff08\u6837\u672c\u95f4\u4e00\u81f4\u6027\uff09\u63d0\u4f9b\u6700\u53ef\u9760\u7684\u6821\u51c6\u3002\u6307\u51fa\u5355\u7528ECE\u4f5c\u4e3a\u6027\u80fd\u6307\u6807\u5b58\u5728\u8bef\u5bfc\u3002", "conclusion": "\u5f53\u524dLLM\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u53ca\u5176\u57fa\u51c6\u6d4b\u8bd5\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u7279\u522b\u662f\u6307\u4ee4\u8c03\u6559\u5f71\u54cd\u7f6e\u4fe1\u4f30\u8ba1\u53ef\u9760\u6027\uff0c\u7b54\u6848\u9891\u7387\u4e3a\u8f83\u4f18\u6821\u51c6\u65b9\u6cd5\uff0c\u5e94\u907f\u514d\u4ec5\u4f9d\u8d56ECE\u8bc4\u4ef7\u6307\u6807\u3002"}}
{"id": "2602.00757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00757", "abs": "https://arxiv.org/abs/2602.00757", "authors": ["Yuan Si", "Simeng Han", "Daming Li", "Hanyuan Shi", "Jialu Zhang"], "title": "ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming", "comment": null, "summary": "LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch programs exhibit deeply nested, non-linear structures, event-driven concurrency across multiple sprites, and tight coupling between code and multimedia assets, properties that differ fundamentally from textual code. As a result, LLMs often misinterpret Scratch semantics and generate large, invasive edits that are syntactically valid but semantically incorrect when repairing buggy programs.\n  We introduce ScratchEval, the first executable benchmark designed to evaluate LLM-based repair for Scratch programs, covering program understanding, debugging, analysis, and repair. The benchmark contains 100 curated Scratch projects from the public repository, selected for structural and semantic complexity. Each project is paired with executable test suites, bug descriptions with corresponding fixes, block-level edit constraints defining minimal semantically correct repairs, and required multimedia assets. The benchmark is constructed through a human-in-the-loop pipeline combining automated project mining with expert validation of trigger-outcome semantics and representative bug patterns, with emphasis on event ordering, concurrency, and state management.\n  To enable rigorous and reproducible evaluation, we propose a three-layer executable protocol measuring functional correctness via VM-level execution, repair quality using block-level edit distance and behavioral trajectory comparisons, and explanation quality via structured rubrics assessing alignment between model reasoning and generated patches. Using ScratchEval, we study domain-specific fine-tuning, training data effectiveness, and model generalization to unseen bug types. ScratchEval provides a reproducible foundation for evaluating and post-training LLMs on block-based programming tasks.", "AI": {"tldr": "\u63d0\u51faScratchEval\u57fa\u51c6\uff0c\u9488\u5bf9Scratch\u7a0b\u5e8f\u4fee\u590d\u8bbe\u8ba1\u591a\u5c42\u6b21\u8bc4\u6d4b\uff0c\u63d0\u5347LLM\u5728\u5757\u5f0f\u7f16\u7a0b\u8bed\u8a00\u4e2d\u7684\u8bed\u4e49\u7406\u89e3\u4e0e\u4fee\u590d\u80fd\u529b\uff0c\u63a8\u52a8\u76f8\u5173\u8bc4\u6d4b\u548c\u8bad\u7ec3\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709LLM\u5728\u5904\u7406\u6587\u672c\u7f16\u7a0b\u8bed\u8a00\u8868\u73b0\u826f\u597d\uff0c\u4f46\u9762\u5bf9\u7ed3\u6784\u590d\u6742\u3001\u4e8b\u4ef6\u9a71\u52a8\u3001\u591a\u5a92\u4f53\u7d27\u8026\u5408\u7684Scratch\u7a0b\u5e8f\u65f6\uff0c\u5e38\u5bfc\u81f4\u8bed\u4e49\u9519\u8bef\u7684\u4fee\u590d\u64cd\u4f5c\uff0c\u7f3a\u4e4f\u6709\u6548\u8bc4\u6d4b\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u4eba\u673a\u7ed3\u5408\u7684\u6d41\u7a0b\u7b5b\u9009\u5305\u542b\u590d\u6742\u7ed3\u6784\u548c\u8bed\u4e49\u7684100\u4e2aScratch\u9879\u76ee\uff0c\u914d\u5957\u53ef\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\u3001\u9519\u8bef\u63cf\u8ff0\u53ca\u4fee\u6b63\u548c\u5757\u7ea7\u7f16\u8f91\u7ea6\u675f\uff0c\u8bbe\u8ba1\u4e09\u5c42\u53ef\u6267\u884c\u534f\u8bae\u4ece\u529f\u80fd\u6b63\u786e\u6027\u3001\u4fee\u590d\u8d28\u91cf\u53ca\u89e3\u91ca\u8d28\u91cf\u591a\u7ef4\u5ea6\u8bc4\u4ef7\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6784\u5efa\u4e86\u8986\u76d6Scratch\u7a0b\u5e8f\u7406\u89e3\u3001\u8c03\u8bd5\u3001\u5206\u6790\u548c\u4fee\u590d\u7684\u6267\u884c\u57fa\u51c6\uff0c\u9a8c\u8bc1\u4e86\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u3001\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u5bf9\u4fee\u590d\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u4e86\u9488\u5bf9\u5757\u72b6\u7f16\u7a0b\u4efb\u52a1\u7684\u53ef\u590d\u73b0\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "ScratchEval\u4f5c\u4e3a\u9996\u4e2a\u9488\u5bf9Scratch\u7a0b\u5e8f\u7684\u53ef\u6267\u884c\u57fa\u51c6\uff0c\u4e3a\u8bc4\u4f30\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7a0b\u5e8f\u4fee\u590d\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfLLM\u5728\u5904\u7406\u57fa\u4e8e\u5757\u7684\u8bed\u8a00\u65f6\u8bed\u4e49\u7406\u89e3\u548c\u4fee\u590d\u6548\u679c\u4e0d\u8db3\u7684\u95ee\u9898\u3002"}}
{"id": "2602.00300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00300", "abs": "https://arxiv.org/abs/2602.00300", "authors": ["Xilin Gong", "Shu Yang", "Zehua Cao", "Lynne Billard", "Di Wang"], "title": "Faithful-Patchscopes: Understanding and Mitigating Model Bias in Hidden Representations Explanation of Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated strong capabilities for hidden representation interpretation through Patchscopes, a framework that uses LLMs themselves to generate human-readable explanations by decoding from internal hidden representations. However, our work shows that LLMs tend to rely on inherent linguistic patterns, which can override contextual information encoded in the hidden representations during decoding. For example, even when a hidden representation encodes the contextual attribute \"purple\" for \"broccoli\", LLMs still generate \"green\" in their explanations, reflecting a strong prior association. This behavior reveals a systematic unfaithfulness in Patchscopes. To systematically study this issue, we first designed a dataset to evaluate the faithfulness of Patchscopes under biased cases, and our results show that there is an 18.84\\% faithfulness decrease on average. We then propose Bias Alignment through Logit Recalibration (BALOR), which treats the output logits from an unpatched prompt as capturing model bias and contrasts them with logits obtained under patched contextual information. By recalibrating the logit distribution through this contrast, BALOR suppresses model bias and amplifies contextual information during generation. Experiments across multiple LLMs demonstrate that BALOR consistently outperforms existing baselines, achieving up to 33\\% relative performance improvement.", "AI": {"tldr": "Patchscopes\u6846\u67b6\u4e2dLLMs\u751f\u6210\u89e3\u91ca\u53d7\u8bed\u8a00\u504f\u89c1\u5f71\u54cd\uff0c\u5bfc\u81f4\u4e0d\u5fe0\u5b9e\u3002\u672c\u6587\u63d0\u51faBALOR\u65b9\u6cd5\uff0c\u901a\u8fc7logit\u91cd\u65b0\u6821\u51c6\u6291\u5236\u504f\u89c1\uff0c\u663e\u8457\u63d0\u5347\u89e3\u91ca\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709Patchscopes\u6846\u67b6\u4e2d\uff0cLLMs\u751f\u6210\u89e3\u91ca\u65f6\u503e\u5411\u4e8e\u4f9d\u8d56\u56fa\u6709\u7684\u8bed\u8a00\u6a21\u5f0f\uff0c\u5bfc\u81f4\u89e3\u91ca\u7ed3\u679c\u4e0d\u5fe0\u5b9e\u4e8e\u9690\u542b\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "method": "\u8bbe\u8ba1\u504f\u89c1\u6848\u4f8b\u6570\u636e\u96c6\u8bc4\u4f30Patchscopes\u5fe0\u5b9e\u5ea6\uff1b\u63d0\u51fa\u901a\u8fc7\u5bf9\u672a\u4fee\u9970\u548c\u4fee\u9970\u63d0\u793a\u8f93\u51fa\u7684logits\u8fdb\u884c\u91cd\u65b0\u6821\u51c6\u7684Bias Alignment through Logit Recalibration (BALOR)\u65b9\u6cd5\uff0c\u6291\u5236\u6a21\u578b\u504f\u89c1\uff0c\u5f3a\u5316\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u4f7f\u7528\u504f\u89c1\u6570\u636e\u96c6\u9a8c\u8bc1Patchscopes\u5bfc\u81f418.84%\u7684\u5fe0\u5b9e\u5ea6\u4e0b\u964d\uff1bBALOR\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe33%\u3002", "conclusion": "BALOR\u6709\u6548\u89e3\u51b3\u4e86Patchscopes\u4e2dLLMs\u89e3\u91ca\u751f\u6210\u5bf9\u8bed\u8a00\u504f\u89c1\u7684\u4f9d\u8d56\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.00761", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00761", "abs": "https://arxiv.org/abs/2602.00761", "authors": ["Andre Hora", "Andy Zaidman"], "title": "Test Behaviors, Not Methods! Detecting Tests Obsessed by Methods", "comment": "Accepted for publication at ICPC 2026", "summary": "Best testing practices state that tests should verify a single functionality or behavior of the system. Tests that verify multiple behaviors are harder to understand, lack focus, and are more coupled to the production code. An attempt to identify this issue is the test smell \\emph{Eager Test}, which aims to capture tests that verify too much functionality based on the number of production method calls. Unfortunately, prior research suggests that counting production method calls is an inaccurate measure, as these calls do not reliably serve as a proxy for functionality. We envision a complementary solution based on runtime analysis: we hypothesize that some tests that verify multiple behaviors will likely cover multiple paths of the same production methods. Thus, we propose a novel test smell named \\emph{Test Obsessed by Method}, a test method that covers multiple paths of a single production method. We provide an initial empirical study to explore the presence of this smell in 2,054 tests provided by 12 test suites of the Python Standard Library. (1) We detect 44 \\emph{Tests Obsessed by Methods} in 11 of the 12 test suites. (2) Each smelly test verifies a median of two behaviors of the production method. (3) The 44 smelly tests could be split into 118 novel tests. (4) 23% of the smelly tests have code comments recognizing that distinct behaviors are being tested. We conclude by discussing benefits, limitations, and further research.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd0\u884c\u65f6\u591a\u8def\u5f84\u8986\u76d6\u68c0\u6d4b\u7684\u6d4b\u8bd5\u5f02\u5473\u201cTest Obsessed by Method\u201d\uff0c\u53d1\u73b0\u5e76\u5b9e\u8bc1\u4e86\u8fd9\u4e00\u5f02\u5473\u5728Python\u6807\u51c6\u5e93\u6d4b\u8bd5\u4e2d\u7684\u5b58\u5728\u5e76\u53ef\u62c6\u5206\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u751f\u4ea7\u65b9\u6cd5\u8c03\u7528\u6b21\u6570\u8bc6\u522b\u6d4b\u8bd5\u5f02\u5473\u7684\u65b9\u6cd5\u4e0d\u51c6\u786e\uff0c\u65e0\u6cd5\u53ef\u9760\u53cd\u6620\u6d4b\u8bd5\u9a8c\u8bc1\u7684\u529f\u80fd\u6570\u91cf\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u8bc6\u522b\u591a\u884c\u4e3a\u6d4b\u8bd5\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u8fd0\u884c\u65f6\u5206\u6790\uff0c\u68c0\u6d4b\u6d4b\u8bd5\u65b9\u6cd5\u8986\u76d6\u4e86\u540c\u4e00\u751f\u4ea7\u65b9\u6cd5\u7684\u591a\u4e2a\u6267\u884c\u8def\u5f84\uff0c\u4ee5\u8bc6\u522b\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u591a\u79cd\u884c\u4e3a\u7684\u60c5\u51b5\u3002\u901a\u8fc7\u5bf912\u4e2aPython\u6807\u51c6\u5e93\u6d4b\u8bd5\u5957\u4ef6\u4e2d2054\u4e2a\u6d4b\u8bd5\u8fdb\u884c\u5206\u6790\uff0c\u8bc6\u522b\u51fa\u201cTest Obsessed by Method\u201d\u6d4b\u8bd5\u5f02\u5473\u3002", "result": "\u572812\u4e2a\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u68c0\u6d4b\u523044\u4e2a\u201cTest Obsessed by Method\u201d\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u536011\u4e2a\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5e73\u5747\u6bcf\u4e2a\u6d4b\u8bd5\u6d89\u53ca\u4e24\u4e2a\u4e0d\u540c\u7684\u884c\u4e3a\u3002\u8fd9\u4e9b\u6d4b\u8bd5\u53ef\u88ab\u62c6\u5206\u4e3a118\u4e2a\u66f4\u805a\u7126\u7684\u6d4b\u8bd5\uff0c\u5176\u4e2d23%\u7684\u6d4b\u8bd5\u4ee3\u7801\u6ce8\u91ca\u660e\u786e\u8bc6\u522b\u4e86\u6d4b\u8bd5\u591a\u4e2a\u4e0d\u540c\u7684\u884c\u4e3a\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u65b0\u7684\u6d4b\u8bd5\u5f02\u5473\u201cTest Obsessed by Method\u201d\uff0c\u5e76\u901a\u8fc7\u5bf9Python\u6807\u51c6\u5e93\u4e2d12\u4e2a\u6d4b\u8bd5\u5957\u4ef62054\u4e2a\u6d4b\u8bd5\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u8be5\u5f02\u5473\u5728\u5927\u591a\u6570\u6d4b\u8bd5\u5957\u4ef6\u4e2d\u5b58\u5728\uff0c\u4e14\u8868\u660e\u6d4b\u8bd5\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u591a\u79cd\u884c\u4e3a\u3002\u7814\u7a76\u8868\u660e\u8fd9\u4e9b\u5f02\u5473\u6d4b\u8bd5\u53ef\u4ee5\u62c6\u5206\u6210\u591a\u4e2a\u66f4\u805a\u7126\u7684\u6d4b\u8bd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u6d4b\u8bd5\u8d28\u91cf\u3002"}}
{"id": "2602.00316", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00316", "abs": "https://arxiv.org/abs/2602.00316", "authors": ["Rodrigo Batista", "Lu\u00eds Filipe Cunha", "Purifica\u00e7\u00e3o Silvano", "Nuno Guimar\u00e3es", "Al\u00edpio Jorge", "Evelin Amorim", "Ricardo Campos"], "title": "MiNER: A Two-Stage Pipeline for Metadata Extraction from Municipal Meeting Minutes", "comment": null, "summary": "Municipal meeting minutes are official documents of local governance, exhibiting heterogeneous formats and writing styles. Effective information retrieval (IR) requires identifying metadata such as meeting number, date, location, participants, and start/end times, elements that are rarely standardized or easy to extract automatically. Existing named entity recognition (NER) models are ill-suited to this task, as they are not adapted to such domain-specific categories. In this paper, we propose a two-stage pipeline for metadata extraction from municipal minutes. First, a question answering (QA) model identifies the opening and closing text segments containing metadata. Transformer-based models (BERTimbau and XLM-RoBERTa with and without a CRF layer) are then applied for fine-grained entity extraction and enhanced through deslexicalization. To evaluate our proposed pipeline, we benchmark both open-weight (Phi) and closed-weight (Gemini) LLMs, assessing predictive performance, inference cost, and carbon footprint. Our results demonstrate strong in-domain performance, better than larger general-purpose LLMs. However, cross-municipality evaluation reveals reduced generalization reflecting the variability and linguistic complexity of municipal records. This work establishes the first benchmark for metadata extraction from municipal meeting minutes, providing a solid foundation for future research in this domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u7ba1\u9053\u65b9\u6cd5\uff0c\u7ed3\u5408\u95ee\u7b54\u548c\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u5b9e\u73b0\u5e02\u653f\u4f1a\u8bae\u7eaa\u8981\u5143\u6570\u636e\u7684\u9ad8\u6548\u63d0\u53d6\uff0c\u5efa\u7acb\u9996\u4e2a\u76f8\u5173\u57fa\u51c6\uff0c\u867d\u7136\u9886\u57df\u5185\u8868\u73b0\u4f18\u8d8a\u4f46\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "motivation": "\u5e02\u653f\u4f1a\u8bae\u7eaa\u8981\u683c\u5f0f\u591a\u6837\uff0c\u5143\u6570\u636e\u5982\u4f1a\u8bae\u7f16\u53f7\u3001\u65f6\u95f4\u548c\u53c2\u4e0e\u8005\u96be\u4ee5\u81ea\u52a8\u63d0\u53d6\uff0c\u73b0\u6709\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6a21\u578b\u4e0d\u80fd\u5f88\u597d\u9002\u5e94\u6b64\u7c7b\u9886\u57df\u7279\u5b9a\u6807\u7b7e\u3002", "method": "\u9996\u5148\u4f7f\u7528\u95ee\u7b54\u6a21\u578b\u8bc6\u522b\u5305\u542b\u5143\u6570\u636e\u7684\u6587\u672c\u6bb5\u843d\uff0c\u968f\u540e\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff08BERTimbau\u548cXLM-RoBERTa\uff0c\u5e26\u6216\u4e0d\u5e26CRF\u5c42\uff09\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u63d0\u53d6\uff0c\u5e76\u901a\u8fc7\u53bb\u8bcd\u6c47\u5316\u6280\u672f\u8fdb\u884c\u589e\u5f3a\u3002", "result": "\u6a21\u578b\u5728\u672c\u9886\u57df\u8868\u73b0\u5f3a\u52b2\uff0c\u8d85\u8d8a\u4e86\u66f4\u5927\u7684\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5efa\u7acb\u4e86\u5e02\u653f\u4f1a\u8bae\u7eaa\u8981\u5143\u6570\u636e\u63d0\u53d6\u7684\u9996\u4e2a\u57fa\u51c6\u6807\u51c6\u3002\u7136\u800c\u6a21\u578b\u5728\u4e0d\u540c\u5e02\u653f\u673a\u6784\u95f4\u6cdb\u5316\u80fd\u529b\u8f83\u5f31\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u7ba1\u9053\u6a21\u578b\u5728\u5e02\u653f\u4f1a\u8bae\u7eaa\u8981\u7684\u5143\u6570\u636e\u63d0\u53d6\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u662f\u5728\u9886\u57df\u5185\u8868\u73b0\u4f18\u4e8e\u5927\u578b\u901a\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5728\u8de8\u5e02\u653f\u673a\u6784\u8bc4\u4f30\u65f6\u8868\u73b0\u51fa\u6cdb\u5316\u80fd\u529b\u7684\u4e0d\u8db3\u3002"}}
{"id": "2602.00840", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00840", "abs": "https://arxiv.org/abs/2602.00840", "authors": ["Biruk Tadesse", "Vikram Nitin", "Mazin Salah", "Baishakhi Ray", "Marcelo d'Amorim", "Wesley Assun\u00e7\u00e3o"], "title": "Code Quality Analysis of Translations from C to Rust", "comment": null, "summary": "C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated translation of C/C++ to safer languages, such as Rust. However, these studies focused mostly on the correctness and safety of the translated code, which are indeed critical, but they left other important quality concerns (e.g., performance, robustness, and maintainability) largely unexplored. This work investigates strengths and weaknesses of three C-to-Rust translators, namely C2Rust (a transpiler), C2SaferRust (an LLM-guided transpiler), and TranslationGym (an LLM-based direct translation). We perform an in-depth quantitative and qualitative analysis of several important quality attributes for the translated Rust code of the popular GNU coreutils, using human-based translation as a baseline. To assess the internal and external quality of the Rust code, we: (i) apply Clippy, a rule-based state-of-the-practice Rust static analysis tool; (ii) investigate the capability of an LLM (GPT-4o) to identify issues potentially overlooked by Clippy; and (iii) perform a manual analysis of the issues reported by Clippy and GPT-4o. Our results show that while newer techniques reduce some unsafe and non-idiomatic patterns, they frequently introduce new issues, revealing systematic trade-offs that are not visible under existing evaluation practices. Notably, none of the automated techniques consistently match or exceed human-written translations across all quality dimensions, yet even human-written Rust code exhibits persistent internal quality issues such as readability and non-idiomatic patterns. Together, these findings show that translation quality remains a multi-dimensional challenge, requiring systematic evaluation and targeted tool support beyond both naive automation and manual rewriting.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e09\u79cdC\u5230Rust\u81ea\u52a8\u7ffb\u8bd1\u6280\u672f\u4e0e\u4eba\u5de5\u7ffb\u8bd1\u7684\u4ee3\u7801\u8d28\u91cf\uff0c\u53d1\u73b0\u81ea\u52a8\u5316\u65b9\u6cd5\u867d\u63d0\u5347\u90e8\u5206\u5b89\u5168\u6027\u4f46\u5e26\u6765\u65b0\u95ee\u9898\uff0c\u7ffb\u8bd1\u8d28\u91cf\u591a\u7ef4\u4e14\u590d\u6742\uff0c\u9700\u7efc\u5408\u591a\u79cd\u624b\u6bb5\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4ec5\u5173\u6ce8\u81ea\u52a8\u7ffb\u8bd1\u7684\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u5ffd\u89c6\u4e86\u6027\u80fd\u3001\u7a33\u5065\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7b49\u5176\u4ed6\u5173\u952e\u8d28\u91cf\u6307\u6807\uff0c\u4e14\u4eba\u5de5\u7ffb\u8bd1\u4ecd\u7136\u9762\u4e34\u5185\u90e8\u8d28\u91cf\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u5168\u9762\u8bc4\u4f30\u4e0d\u540c\u81ea\u52a8\u5316\u6280\u672f\u5728\u591a\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u7684\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5bf9\u4e09\u79cdC\u5230Rust\u7684\u7ffb\u8bd1\u5de5\u5177\uff08C2Rust\u3001C2SaferRust\u3001TranslationGym\uff09\u8fdb\u884c\u6df1\u5165\u7684\u5b9a\u91cf\u4e0e\u5b9a\u6027\u5206\u6790\uff0c\u5229\u7528Clippy\u9759\u6001\u5206\u6790\u5de5\u5177\u3001GPT-4o\u8bc6\u522b\u6f5c\u5728\u95ee\u9898\u4ee5\u53ca\u4eba\u5de5\u590d\u67e5\uff0c\u8bc4\u4f30\u8f6c\u6362\u540eRust\u4ee3\u7801\u7684\u6027\u80fd\u3001\u7a33\u5065\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u7b49\u8d28\u91cf\u5c5e\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u81ea\u52a8\u7ffb\u8bd1\u6280\u672f\u867d\u51cf\u5c11\u4e86\u4e00\u4e9b\u4e0d\u5b89\u5168\u548c\u975e\u60ef\u7528\u4ee3\u7801\uff0c\u4f46\u5f15\u5165\u4e86\u65b0\u7684\u95ee\u9898\uff0c\u4e14\u6ca1\u6709\u4e00\u79cd\u6280\u672f\u5728\u6240\u6709\u8d28\u91cf\u7ef4\u5ea6\u4e0a\u5747\u8d85\u8d8a\u4eba\u5de5\u7ffb\u8bd1\uff0c\u4eba\u5de5\u7ffb\u8bd1\u4e5f\u5b58\u5728\u4ee3\u7801\u53ef\u8bfb\u6027\u548c\u60ef\u7528\u6027\u7b49\u5185\u90e8\u8d28\u91cf\u95ee\u9898\u3002", "conclusion": "\u81ea\u52a8\u5316\u7684C\u5230Rust\u7684\u4ee3\u7801\u8f6c\u6362\u6280\u672f\u5728\u63d0\u9ad8\u5b89\u5168\u6027\u548c\u51cf\u5c11\u975e\u60ef\u7528\u6a21\u5f0f\u65b9\u9762\u6709\u4e00\u5b9a\u6210\u6548\uff0c\u4f46\u666e\u904d\u5f15\u5165\u65b0\u7684\u95ee\u9898\uff0c\u4e14\u672a\u80fd\u5168\u9762\u8d85\u8d8a\u4eba\u5de5\u7ffb\u8bd1\u7684\u8d28\u91cf\u6c34\u5e73\u3002\u7ffb\u8bd1\u8d28\u91cf\u662f\u4e00\u4e2a\u591a\u7ef4\u5ea6\u7684\u6311\u6218\uff0c\u5355\u4e00\u65b9\u6cd5\u96be\u4ee5\u8986\u76d6\u6240\u6709\u8d28\u91cf\u7ef4\u5ea6\uff0c\u9700\u7ed3\u5408\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u548c\u9488\u5bf9\u6027\u7684\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2602.00319", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.00319", "abs": "https://arxiv.org/abs/2602.00319", "authors": ["Siyuan Shen", "Kai Wang"], "title": "Detecting AI-Generated Content in Academic Peer Reviews", "comment": null, "summary": "The growing availability of large language models (LLMs) has raised questions about their role in academic peer review. This study examines the temporal emergence of AI-generated content in peer reviews by applying a detection model trained on historical reviews to later review cycles at International Conference on Learning Representations (ICLR) and Nature Communications (NC). We observe minimal detection of AI-generated content before 2022, followed by a substantial increase through 2025, with approximately 20% of ICLR reviews and 12% of Nature Communications reviews classified as AI-generated in 2025. The most pronounced growth of AI-generated reviews in NC occurs between the third and fourth quarter of 2024. Together, these findings provide suggestive evidence of a rapidly increasing presence of AI-assisted content in peer review and highlight the need for further study of its implications for scholarly evaluation.", "AI": {"tldr": "\u7814\u7a76\u8868\u660eAI\u751f\u6210\u5185\u5bb9\u5728\u5b66\u672f\u540c\u884c\u8bc4\u5ba1\u4e2d\u8fc5\u901f\u4e0a\u5347\uff0c\u5f3a\u8c03\u4e86\u5bf9\u5176\u5b66\u672f\u8bc4\u4ef7\u5f71\u54cd\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u9700\u6c42\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u63a2\u8ba8\u5b83\u4eec\u5728\u5b66\u672f\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u89d2\u8272\u53ca\u5f71\u54cd\u53d8\u5f97\u5fc5\u8981\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u7684\u68c0\u6d4b\u6a21\u578b\u5bf9ICLR\u548cNature Communications\u7684\u5386\u53f2\u53ca\u6700\u65b0\u540c\u884c\u8bc4\u5ba1\u8fdb\u884c\u5206\u7c7b\uff0c\u8bc6\u522bAI\u751f\u6210\u5185\u5bb9\u3002", "result": "\u53d1\u73b02025\u5e74ICLR\u548cNature Communications\u7684\u540c\u884c\u8bc4\u5ba1\u4e2d\uff0c\u5206\u522b\u7ea620%\u548c12%\u7684\u5185\u5bb9\u88ab\u5206\u7c7b\u4e3aAI\u751f\u6210\uff0c\u8868\u660eAI\u8f85\u52a9\u7684\u4f7f\u7528\u663e\u8457\u589e\u52a0\u3002", "conclusion": "AI\u751f\u6210\u5185\u5bb9\u5728\u5b66\u672f\u540c\u884c\u8bc4\u5ba1\u4e2d\u7684\u4f7f\u7528\u8fc5\u901f\u589e\u957f\uff0c\u5c24\u5176\u662f\u57282024\u5e74\u7b2c\u56db\u5b63\u5ea6\u52302025\u5e74\u671f\u95f4\u3002"}}
{"id": "2602.00933", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00933", "abs": "https://arxiv.org/abs/2602.00933", "authors": ["Chaithanya Bandi", "Ben Hertzberg", "Geobio Boo", "Tejas Polakam", "Jeff Da", "Sami Hassaan", "Manasi Sharma", "Andrew Park", "Ernesto Hernandez", "Dan Rambado", "Ivan Salazar", "Rafael Cruz", "Chetan Rane", "Ben Levin", "Brad Kenstler", "Bing Liu"], "title": "MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers", "comment": null, "summary": "The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMCP-Atlas\u57fa\u51c6\uff0c\u91c7\u7528\u771f\u5b9e\u591a\u6b65\u9aa4\u4efb\u52a1\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u8c03\u7528\u5916\u90e8\u5de5\u5177\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u53d1\u5e03\u6570\u636e\u96c6\u548c\u5de5\u5177\u63a8\u52a8\u9886\u57df\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u96be\u4ee5\u53cd\u6620\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u590d\u6742\u573a\u666f\u4e0b\u8c03\u7528\u5916\u90e8\u5de5\u5177\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faMCP-Atlas\u57fa\u51c6\uff0c\u5305\u542b36\u4e2a\u771f\u5b9eMCP\u670d\u52a1\u5668\u3001220\u4e2a\u5de5\u5177\u548c1000\u4e2a\u4efb\u52a1\uff0c\u4efb\u52a1\u8981\u6c42\u591a\u6b65\u9aa4\u8c03\u7528\u591a\u4e2a\u5de5\u5177\uff0c\u8bc4\u4f30\u91c7\u7528\u57fa\u4e8e\u4e8b\u5b9e\u7684\u8bc4\u5206\u6807\u51c6\u548c\u8be6\u7ec6\u8bca\u65ad\u6307\u6807\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u901a\u8fc7\u7387\u8d85\u8fc750%\uff0c\u4e3b\u8981\u5931\u8d25\u539f\u56e0\u662f\u5de5\u5177\u4f7f\u7528\u548c\u4efb\u52a1\u7406\u89e3\u4e0d\u8db3\u3002", "conclusion": "MCP-Atlas\u4e3a\u8bc4\u4f30\u4e0e\u4fc3\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u8c03\u7528\u80fd\u529b\u63d0\u4f9b\u4e86\u771f\u5b9e\u3001\u591a\u6837\u4e14\u7ec6\u81f4\u7684\u8bc4\u4ef7\u4f53\u7cfb\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u66f4\u5065\u58ee\u7684\u5de5\u5177\u589e\u5f3a\u667a\u80fd\u4f53\u53d1\u5c55\u3002"}}
{"id": "2602.00352", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00352", "abs": "https://arxiv.org/abs/2602.00352", "authors": ["Li Siyan", "Darshan Deshpande", "Anand Kannappan", "Rebecca Qian"], "title": "DETOUR: An Interactive Benchmark for Dual-Agent Search and Reasoning", "comment": null, "summary": "When recalling information in conversation, people often arrive at the recollection after multiple turns. However, existing benchmarks for evaluating agent capabilities in such tip-of-the-tongue search processes are restricted to single-turn settings. To more realistically simulate tip-of-the-tongue search, we introduce Dual-agent based Evaluation Through Obscure Under-specified Retrieval (DETOUR), a dual-agent evaluation benchmark containing 1,011 prompts. The benchmark design involves a Primary Agent, which is the subject of evaluation, tasked with identifying the recollected entity through querying a Memory Agent that is held consistent across evaluations. Our results indicate that current state-of-the-art models still struggle with our benchmark, only achieving 36% accuracy when evaluated on all modalities (text, image, audio, and video), highlighting the importance of enhancing capabilities in underspecified scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u4ee3\u7406\u591a\u8f6e\u4fe1\u606f\u56de\u5fc6\u8bc4\u4f30\u57fa\u51c6DETOUR\uff0c\u6d4b\u8bd5\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u51c6\u786e\u7387\u4ec5\u670936%\uff0c\u663e\u793a\u4e86\u591a\u6a21\u6001\u591a\u8f6e\u68c0\u7d22\u4efb\u52a1\u7684\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8bc4\u4f30\u57fa\u4e8e\u4fe1\u606f\u56de\u5fc6\u7684\u4ee3\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u9650\u4e8e\u5355\u8f6e\u5bf9\u8bdd\uff0c\u65e0\u6cd5\u771f\u5b9e\u6a21\u62df\u591a\u8f6e\u9012\u8fdb\u7684'\u820c\u5c16\u8bb0\u5fc6'\u641c\u7d22\u8fc7\u7a0b\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aDETOUR\u7684\u53cc\u4ee3\u7406\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b1011\u4e2a\u63d0\u793a\u3002\u8bc4\u4f30\u4e2d\u4e3b\u8981\u6709\u4e00\u4e2a\u88ab\u8bc4\u4f30\u7684\u4e3b\u4ee3\u7406\u901a\u8fc7\u5411\u4e00\u4e2a\u8bb0\u5fc6\u4ee3\u7406\u63d0\u51fa\u67e5\u8be2\u6765\u8bc6\u522b\u56de\u5fc6\u4e2d\u7684\u5b9e\u4f53\uff0c\u8bb0\u5fc6\u4ee3\u7406\u5728\u6240\u6709\u8bc4\u4f30\u4e2d\u4fdd\u6301\u4e00\u81f4\u3002", "result": "\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u6240\u6709\u6a21\u6001\uff08\u6587\u672c\u3001\u56fe\u50cf\u3001\u97f3\u9891\u548c\u89c6\u9891\uff09\u4e0a\u7684\u51c6\u786e\u7387\u4ec5\u4e3a36%\uff0c\u4f53\u73b0\u51fa\u73b0\u6709\u6a21\u578b\u5728\u5904\u7406\u4fe1\u606f\u4e0d\u8db3\u7684\u591a\u8f6e\u56de\u5fc6\u573a\u666f\u4e0b\u7684\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "DETOUR\u57fa\u51c6\u66f4\u771f\u5b9e\u5730\u6a21\u62df\u4e86\u591a\u8f6e\u201c\u820c\u5c16\u8bb0\u5fc6\u201d\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u6a21\u578b\u5728\u5904\u7406\u4e0d\u5b8c\u5168\u4fe1\u606f\u67e5\u8be2\u65f6\u7684\u5c40\u9650\u6027\uff0c\u63d0\u793a\u672a\u6765\u9700\u52a0\u5f3a\u5728\u4fe1\u606f\u4e0d\u8db3\u573a\u666f\u4e0b\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.00972", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.00972", "abs": "https://arxiv.org/abs/2602.00972", "authors": ["Zhuangbin Chen", "Zhiling Deng", "Kaiming Zhang", "Yang Liu", "Cheng Cui", "Jinfeng Zhong", "Zibin Zheng"], "title": "Cast: Automated Resilience Testing for Production Cloud Service Systems", "comment": null, "summary": "The distributed nature of microservice architecture introduces significant resilience challenges. Traditional testing methods, limited by extensive manual effort and oversimplified test environments, fail to capture production system complexity. To address these limitations, we present Cast, an automated, end-to-end framework for microservice resilience testing in production. It achieves high test fidelity by replaying production traffic against a comprehensive library of application-level faults to exercise internal error-handling logic. To manage the combinatorial test space, Cast employs a complexity-driven strategy to systematically prune redundant tests and prioritize high-value tests targeting the most critical service execution paths. Cast automates the testing lifecycle through a three-phase pipeline (i.e., startup, fault injection, and recovery) and uses a multi-faceted oracle to automatically verify system resilience against nuanced criteria. Deployed in Huawei Cloud for over eight months, Cast has been adopted by many service teams to proactively address resilience vulnerabilities. Our analysis on four large-scale applications with millions of traces reveals 137 potential vulnerabilities, with 89 confirmed by developers. To further quantify its performance, Cast is evaluated on a benchmark set of 48 reproduced bugs, achieving a high coverage of 90%. The results show that Cast is a practical and effective solution for systematically improving the reliability of industrial microservice systems.", "AI": {"tldr": "Cast\u662f\u4e00\u6b3e\u81ea\u52a8\u5316\u5fae\u670d\u52a1\u97e7\u6027\u6d4b\u8bd5\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u4ea7\u6d41\u91cf\u91cd\u653e\u548c\u590d\u6742\u5ea6\u9a71\u52a8\u6d4b\u8bd5\u7b56\u7565\uff0c\u5728\u534e\u4e3a\u4e91\u5b9e\u6d4b\u4e2d\u6709\u6548\u8bc6\u522b\u548c\u4fee\u590d\u97e7\u6027\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u5347\u5fae\u670d\u52a1\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "motivation": "\u5fae\u670d\u52a1\u67b6\u6784\u7684\u5206\u5e03\u5f0f\u7279\u6027\u5e26\u6765\u97e7\u6027\u6311\u6218\uff0c\u4f20\u7edf\u6d4b\u8bd5\u4f9d\u8d56\u624b\u5de5\u4e14\u6d4b\u8bd5\u73af\u5883\u7b80\u5316\uff0c\u96be\u4ee5\u6355\u83b7\u751f\u4ea7\u590d\u6742\u6027\uff0c\u6025\u9700\u81ea\u52a8\u5316\u9ad8\u4fdd\u771f\u97e7\u6027\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u91cd\u653e\u751f\u4ea7\u6d41\u91cf\u5e76\u7ed3\u5408\u5e94\u7528\u7ea7\u6545\u969c\u5e93\uff0c\u5229\u7528\u590d\u6742\u5ea6\u9a71\u52a8\u7b56\u7565\u6709\u9009\u62e9\u5730\u6267\u884c\u6d4b\u8bd5\uff0c\u81ea\u52a8\u7ba1\u7406\u6d4b\u8bd5\u751f\u547d\u5468\u671f\u548c\u591a\u7ef4\u5ea6\u81ea\u52a8\u5316\u9a8c\u8bc1\u7cfb\u7edf\u97e7\u6027\u3002", "result": "\u5728\u534e\u4e3a\u4e91\u90e8\u7f72\u516b\u4e2a\u6708\uff0c\u5206\u6790\u56db\u4e2a\u5927\u89c4\u6a21\u5e94\u7528\u53d1\u73b0137\u4e2a\u6f5c\u5728\u6f0f\u6d1e\uff0c89\u4e2a\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\uff1b\u5728\u57fa\u51c6\u96c648\u4e2a\u590d\u73b0\u7f3a\u9677\u4e2d\u8986\u76d6\u7387\u8fbe90%\u3002", "conclusion": "Cast\u6846\u67b6\u901a\u8fc7\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u5bf9\u5fae\u670d\u52a1\u67b6\u6784\u8fdb\u884c\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u7684\u97e7\u6027\u6d4b\u8bd5\uff0c\u6709\u6548\u53d1\u73b0\u548c\u4fee\u590d\u4e86\u5927\u91cf\u6f5c\u5728\u7684\u97e7\u6027\u6f0f\u6d1e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5de5\u4e1a\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.00377", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00377", "abs": "https://arxiv.org/abs/2602.00377", "authors": ["Zhaochen Hong", "Jiaxuan You"], "title": "DecompressionLM: Deterministic, Diagnostic, and Zero-Shot Concept Graph Extraction from Language Models", "comment": null, "summary": "Existing knowledge probing methods rely on pre-defined queries, limiting extraction to known concepts. We introduce DecompressionLM, a stateless framework for zero-shot concept graph extraction that discovers what language models encode without pre-specified queries or shared cross-sequence state. Our method targets three limitations of common decoding-based probing approaches: cross-sequence coupling that concentrates probability mass on high-frequency prefixes, competitive decoding effects that suppress long-tail concepts, and scalability constraints arising from sequential exploration. Using Van der Corput low-discrepancy sequences with arithmetic decoding, DecompressionLM enables deterministic, embarrassingly parallel generation without shared state across sequences. Across two model families and five quantization variants, we find that activation-aware quantization (AWQ-4bit) expands concept coverage by 30-170%, while uniform quantization (GPTQ-Int4) induces 71-86% coverage collapse -- divergent behaviors not reliably reflected by explanation-level perplexity. Corpus-based verification further reveals a 17-point hallucination gap between top- and bottom-ranked MMLU-Pro Law models. DecompressionLM establishes concept coverage as a complementary evaluation dimension for assessing knowledge breadth and factual grounding in compressed models useful for their deployment.", "AI": {"tldr": "\u63d0\u51faDecompressionLM\u6846\u67b6\uff0c\u901a\u8fc7\u65e0\u72b6\u6001\u3001\u5e76\u884c\u7684\u751f\u6210\u65b9\u6cd5\u6709\u6548\u6269\u5c55\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u6982\u5ff5\u8986\u76d6\uff0c\u5bf9\u91cf\u5316\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u548c\u5b9e\u9645\u5e94\u7528\u5177\u6709\u6307\u5bfc\u610f\u4e49\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u63a2\u6d4b\u4f9d\u8d56\u9884\u5b9a\u4e49\u67e5\u8be2\uff0c\u9650\u5236\u4e86\u5df2\u77e5\u6982\u5ff5\u5916\u7684\u4fe1\u606f\u63d0\u53d6\uff0c\u4e14\u4f20\u7edf\u57fa\u4e8e\u89e3\u7801\u7684\u65b9\u6cd5\u5b58\u5728\u8026\u5408\u548c\u89c4\u6a21\u6269\u5c55\u9650\u5236\u3002", "method": "\u5229\u7528Van der Corput\u4f4e\u5dee\u5f02\u5e8f\u5217\u7ed3\u5408\u7b97\u672f\u89e3\u7801\uff0c\u5b9e\u73b0\u8de8\u5e8f\u5217\u65e0\u5171\u4eab\u72b6\u6001\u3001\u53ef\u5e76\u884c\u7684\u786e\u5b9a\u6027\u751f\u6210\uff0c\u4ece\u800c\u907f\u514d\u4e86\u4f20\u7edf\u89e3\u7801\u65b9\u6cd5\u7684\u4ea4\u53c9\u5e8f\u5217\u8026\u5408\u548c\u7ade\u4e89\u89e3\u7801\u6548\u5e94\u3002", "result": "AWQ-4bit\u91cf\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6982\u5ff5\u8986\u76d6\u738730-170%\uff0c\u800cGPTQ-Int4\u5bfc\u81f4\u8986\u76d6\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u4e14\u4e0d\u540c\u91cf\u5316\u65b9\u5f0f\u7684\u6027\u80fd\u5dee\u5f02\u672a\u88ab\u89e3\u91ca\u7ea7\u56f0\u60d1\u5ea6\u51c6\u786e\u53cd\u6620\u3002\u6587\u732e\u9a8c\u8bc1\u663e\u793a\u4e0d\u540c\u6a21\u578b\u5728\u5e7b\u89c9\u7387\u4e0a\u6709\u660e\u663e\u5dee\u5f02\u3002", "conclusion": "DecompressionLM\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u72b6\u6001\u3001\u96f6\u6837\u672c\u7684\u6982\u5ff5\u56fe\u63d0\u53d6\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u77e5\u8bc6\u6982\u5ff5\u7684\u8986\u76d6\u5ea6\uff0c\u5c24\u5176\u5728\u6fc0\u6d3b\u611f\u77e5\u91cf\u5316\u6a21\u578b\u4e2d\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2602.01044", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01044", "abs": "https://arxiv.org/abs/2602.01044", "authors": ["Yu Tang", "Hailiang Zhao", "Rui Shi", "Chuansheng Lu", "Yifei Zhang", "Kingsum Chow", "Shuiguang Deng"], "title": "Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs", "comment": null, "summary": "Modern microservice systems exhibit continuous structural evolution in their runtime call graphs due to workload fluctuations, fault responses, and deployment activities. Despite this complexity, our analysis of over 500,000 production traces from ByteDance reveals a latent regularity: execution paths concentrate around a small set of recurring invocation patterns. However, existing resource management approaches fail to exploit this structure. Industrial autoscalers like Kubernetes HPA ignore inter-service dependencies, while recent academic methods often assume static topologies, rendering them ineffective under dynamic execution contexts. In this work, we propose Morphis, a dependency-aware provisioning framework that unifies pattern-aware trace analysis with global optimization. It introduces structural fingerprinting that decomposes traces into a stable execution backbone and interpretable deviation subgraphs. Then, resource allocation is formulated as a constrained optimization problem over predicted pattern distributions, jointly minimizing aggregate CPU usage while satisfying end-to-end tail-latency SLOs. Our extensive evaluations on the TrainTicket benchmark demonstrate that Morphis reduces CPU consumption by 35-38% compared to state-of-the-art baselines while maintaining 98.8% SLO compliance.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5fae\u670d\u52a1\u8c03\u7528\u8def\u5f84\u4e2d\u5b58\u5728\u91cd\u590d\u6a21\u5f0f\uff0c\u63d0\u51fa\u4f9d\u8d56\u611f\u77e5\u7684\u8d44\u6e90\u8c03\u5ea6\u6846\u67b6Morphis\uff0c\u6709\u6548\u964d\u4f4eCPU\u8d44\u6e90\u6d88\u8017\u5e76\u4fdd\u8bc1\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u5fae\u670d\u52a1\u7cfb\u7edf\u7684\u8fd0\u884c\u65f6\u8c03\u7528\u56fe\u7ed3\u6784\u52a8\u6001\u53d8\u5316\uff0c\u4f7f\u5f97\u73b0\u6709\u8d44\u6e90\u7ba1\u7406\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8c03\u7528\u8def\u5f84\u4e2d\u7684\u6f5c\u5728\u89c4\u5f8b\uff0c\u5bfc\u81f4\u8d44\u6e90\u8c03\u5ea6\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u8be5\u8bba\u6587\u5f15\u5165\u4e86\u7ed3\u6784\u6307\u7eb9\u6280\u672f\uff0c\u5c06\u8c03\u7528\u8def\u5f84\u5206\u89e3\u4e3a\u7a33\u5b9a\u7684\u6267\u884c\u9aa8\u67b6\u548c\u53ef\u89e3\u91ca\u7684\u504f\u5dee\u5b50\u56fe\uff0c\u5e76\u5c06\u8d44\u6e90\u5206\u914d\u95ee\u9898\u5efa\u6a21\u4e3a\u57fa\u4e8e\u9884\u6d4b\u6a21\u5f0f\u5206\u5e03\u7684\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u5168\u5c40\u7684\u8d44\u6e90\u4f18\u5316\u914d\u7f6e\u3002", "result": "Morphis\u5728TrainTicket\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\u51cf\u5c11\u4e8635-38%\u7684CPU\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u4e8698.8%\u7684SLO\u5408\u89c4\u7387\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684Morphis\u6846\u67b6\u901a\u8fc7\u5229\u7528\u5fae\u670d\u52a1\u7cfb\u7edf\u8c03\u7528\u8def\u5f84\u4e2d\u7684\u91cd\u590d\u6a21\u5f0f\uff0c\u6709\u6548\u964d\u4f4e\u4e86CPU\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u7cfb\u7edf\u7684\u670d\u52a1\u7ea7\u522b\u76ee\u6807\uff08SLO\uff09\u3002"}}
{"id": "2602.00380", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00380", "abs": "https://arxiv.org/abs/2602.00380", "authors": ["Sercan Karaka\u015f"], "title": "Clause-Internal or Clause-External? Testing Turkish Reflexive Binding in Adapted versus Chain of Thought Large Language Models", "comment": "15 pages", "summary": "This study evaluates whether state-of-the-art large language models capture the binding relations of Turkish reflexive pronouns. We construct a balanced set of 100 sentences that pit local against non-local antecedents for the reflexives kendi and kendisi, and test two contrasting systems: an OpenAI chain-of-thought model designed for multi-step reasoning and Trendyol-LLM-7B-base-v0.1, a LLaMA-2-derived model extensively fine-tuned on Turkish data. Antecedent choice is assessed using a combined sentence-level perplexity and forced-choice paradigm. Trendyol-LLM favours local bindings in approximately 70% of trials, exhibiting a strong locality bias, whereas o1 Mini distributes its choices almost evenly between local and long-distance readings, revealing a marked contrast in binding behaviour across the two systems.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u571f\u8033\u5176\u8bed\u53cd\u8eab\u4ee3\u8bcd\u7ed1\u5b9a\u5173\u7cfb\u7684\u5904\u7406\uff0c\u53d1\u73b0Trendyol-LLM\u504f\u5411\u5c40\u90e8\u7ed1\u5b9a\uff0c\u800cOpenAI\u6a21\u578b\u5219\u65e0\u660e\u663e\u504f\u597d\u3002", "motivation": "\u8bc4\u4f30\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u51c6\u786e\u6355\u6349\u571f\u8033\u5176\u8bed\u53cd\u8eab\u4ee3\u8bcd\u7684\u7ed1\u5b9a\u5173\u7cfb\u3002", "method": "\u6784\u5efa\u5305\u542b100\u4e2a\u53e5\u5b50\u7684\u5e73\u8861\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e24\u79cd\u6a21\u578b\u5728\u53cd\u8eab\u4ee3\u8bcdkendi\u548ckendisi\u7684\u5148\u884c\u8bcd\u9009\u62e9\u4e0a\u7684\u8868\u73b0\uff0c\u91c7\u7528\u53e5\u5b50\u7ea7\u56f0\u60d1\u5ea6\u548c\u5f3a\u5236\u9009\u62e9\u8303\u5f0f\u8bc4\u4f30\u3002", "result": "Trendyol-LLM\u6a21\u578b\u5728\u7ea670%\u7684\u8bd5\u9a8c\u4e2d\u504f\u5411\u672c\u5730\u5148\u884c\u8bcd\uff0c\u663e\u793a\u51fa\u8f83\u5f3a\u7684\u5c40\u90e8\u6027\u504f\u597d\uff1b\u800cOpenAI\u7684\u94fe\u5f0f\u601d\u7ef4\u6a21\u578b\u5728\u672c\u5730\u548c\u957f\u8ddd\u79bb\u7ed1\u5b9a\u4e0a\u51e0\u4e4e\u5747\u5300\u9009\u62e9\uff0c\u8868\u73b0\u51fa\u660e\u663e\u4e0d\u540c\u7684\u7ed1\u5b9a\u884c\u4e3a\u3002", "conclusion": "\u4e0d\u540c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u571f\u8033\u5176\u8bed\u53cd\u8eab\u4ee3\u8bcd\u7684\u7ed1\u5b9a\u5173\u7cfb\u65f6\u8868\u73b0\u51fa\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u53cd\u6620\u4e86\u6a21\u578b\u7684\u7ed3\u6784\u548c\u8bad\u7ec3\u6570\u636e\u5bf9\u8bed\u8a00\u7406\u89e3\u7684\u5f71\u54cd\u3002"}}
{"id": "2602.01107", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01107", "abs": "https://arxiv.org/abs/2602.01107", "authors": ["Daniel Ramos", "Catarina Gamboa", "In\u00eas Lynce", "Vasco Manquinho", "Ruben Martins", "Claire Le Goues"], "title": "SPELL: Synthesis of Programmatic Edits using LLMs", "comment": "pre-print", "summary": "Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure.\n  In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528LLM\u63d0\u53d6\u793a\u4f8b\u518d\u751f\u6210\u8fc1\u79fb\u811a\u672c\u7684\u81ea\u52a8API\u8fc1\u79fb\u65b9\u6cd5\uff0c\u65e0\u9700\u9884\u5148\u6570\u636e\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728Python\u5e93\u8fc1\u79fb\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5e93\u8fc1\u79fb\u662f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e38\u89c1\u4f46\u6613\u51fa\u9519\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u81ea\u52a8\u8fc1\u79fb\u5de5\u5177\u4f9d\u8d56\u7a00\u7f3a\u7684\u771f\u5b9e\u8fc1\u79fb\u6570\u636e\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u73b0\u4ee3\u4ee3\u7801\u8f6c\u6362\u6280\u672f\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u53d6\u8fc1\u79fb\u793a\u4f8b\uff0c\u518d\u901a\u8fc7Agent\u5c06\u8fd9\u4e9b\u793a\u4f8b\u6cdb\u5316\u4e3aPolyglotPiranha\u4e2d\u7684\u53ef\u91cd\u590d\u4f7f\u7528\u7684\u8fc1\u79fb\u811a\u672c\uff0c\u907f\u514d\u4f9d\u8d56\u5df2\u6709\u8fc1\u79fb\u6570\u636e\u6216\u76f4\u63a5\u7528LLM\u8fdb\u884c\u8f6c\u6362\u3002", "result": "\u7cfb\u7edf\u80fd\u591f\u751f\u6210\u591a\u6837\u7684\u8fc1\u79fb\u793a\u4f8b\u5e76\u5408\u6210\u53ef\u6cdb\u5316\u5230\u5b9e\u9645\u4ee3\u7801\u5e93\u7684\u8f6c\u6362\u811a\u672c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u5728Python\u5e93\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5c06\u9690\u6027\u8fc1\u79fb\u77e5\u8bc6\u4eceLLM\u4e2d\u63d0\u53d6\u5e76\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u6d4b\u8bd5\u3001\u53ef\u91cd\u590d\u7684\u8fc1\u79fb\u903b\u8f91\uff0c\u964d\u4f4e\u4e86\u4eba\u5de5\u548c\u6570\u636e\u4f9d\u8d56\uff0c\u63d0\u5347\u4e86\u81ea\u52a8API\u8fc1\u79fb\u7684\u5b9e\u7528\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.00425", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00425", "abs": "https://arxiv.org/abs/2602.00425", "authors": ["Siyuan Wang", "Yanchen Liu", "Xiang Ren"], "title": "Segment-Level Attribution for Selective Learning of Long Reasoning Traces", "comment": "Accepted to ICLR 2026. 16 pages, 5 figures. Code available at https://github.com/SiyuanWangw/SegmentSelectiveSFT", "summary": "Large Reasoning Models (LRMs) achieve strong reasoning performance by generating long chains of thought (CoTs), yet only a small fraction of these traces meaningfully contributes to answer prediction, while the majority contains repetitive or truncated content. Such output redundancy is further propagated after supervised finetuning (SFT), as models learn to imitate verbose but uninformative patterns, which can degrade performance. To this end, we incorporate integrated gradient attribution to quantify each token's influence on final answers and aggregate them into two segment-level metrics: (1) \\textit{attribution strength} measures the overall attribution magnitude; and (2) \\textit{direction consistency} captures whether tokens' attributions within a segment are uniformly positive or negative (high consistency), or a mixture of both (moderate consistency). Based on these two metrics, we propose a segment-level selective learning framework to identify important segments with high attribution strength but moderate consistency that indicate reflective rather than shallow reasoning. The framework then applies selective SFT on these important segments while masking loss for unimportant ones. Experiments across multiple models and datasets show that our approach improves accuracy and output efficiency, enabling more effective learning from long reasoning traces~\\footnote{Code and data are available at https://github.com/SiyuanWangw/SegmentSelectiveSFT}.", "AI": {"tldr": "\u8be5\u6587\u901a\u8fc7\u96c6\u6210\u68af\u5ea6\u5f52\u56e0\u8bc6\u522b\u91cd\u8981\u63a8\u7406\u6bb5\u843d\uff0c\u8fdb\u884c\u6709\u9009\u62e9\u7684\u5fae\u8c03\uff0c\u51cf\u5c11\u5197\u4f59\uff0c\u63d0\u9ad8\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u51c6\u786e\u7387\u548c\u6548\u7387\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u751f\u6210\u7684\u957f\u601d\u8003\u94fe\u4e2d\uff0c\u5927\u591a\u6570\u5185\u5bb9\u91cd\u590d\u6216\u622a\u65ad\uff0c\u4e14\u4ec5\u5c11\u90e8\u5206\u5bf9\u7b54\u6848\u9884\u6d4b\u6709\u610f\u4e49\uff0c\u8bad\u7ec3\u65f6\u6a21\u578b\u503e\u5411\u6a21\u4eff\u5197\u957f\u65e0\u6548\u6a21\u5f0f\uff0c\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u5f15\u5165\u96c6\u6210\u68af\u5ea6\u5f52\u56e0\u8861\u91cf\u6bcf\u4e2atoken\u5bf9\u6700\u7ec8\u7b54\u6848\u7684\u5f71\u54cd\uff0c\u6784\u5efa\u4e24\u9879\u5206\u6bb5\u6307\u6807\uff1a\u5f52\u56e0\u5f3a\u5ea6\u548c\u65b9\u5411\u4e00\u81f4\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u5206\u6bb5\u9009\u62e9\u6027\u5fae\u8c03\u6846\u67b6\uff0c\u5bf9\u91cd\u8981\u5206\u6bb5\uff08\u9ad8\u5f52\u56e0\u5f3a\u5ea6\u4e14\u65b9\u5411\u4e00\u81f4\u6027\u9002\u4e2d\uff09\u8fdb\u884c\u6709\u9009\u62e9\u7684\u5fae\u8c03\uff0c\u5ffd\u7565\u65e0\u5173\u5206\u6bb5\u635f\u5931\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548c\u8f93\u51fa\u6548\u7387\uff0c\u4f7f\u6a21\u578b\u80fd\u66f4\u6709\u6548\u5730\u4ece\u957f\u63a8\u7406\u94fe\u5b66\u4e60\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u5f52\u56e0\u7684\u5206\u6bb5\u9009\u62e9\u6027\u5fae\u8c03\uff0c\u6709\u6548\u51cf\u5c11\u5197\u4f59\u5185\u5bb9\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2602.01187", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01187", "abs": "https://arxiv.org/abs/2602.01187", "authors": ["Chengran Yang", "Zichao Wei", "Heminghao Deng", "Jinfeng Jiang", "Zhensu Sun", "Ting Zhang", "Tianyi Wu", "Ming Wen", "David Lo"], "title": "Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation", "comment": null, "summary": "Large Language Model (LLM) based code generation is predominantly formulated as a strictly monotonic process, appending tokens linearly to an immutable prefix. This formulation contrasts to the cognitive process of programming, which is inherently interleaved with forward generation and on-the-fly revision. While prior works attempt to introduce revision via post-hoc agents or external static tools, they either suffer from high latency or fail to leverage the model's intrinsic semantic reasoning. In this paper, we propose Stream of Revision, a paradigm shift that elevates code generation from a monotonic stream to a dynamic, self-correcting trajectory by leveraging model's intrinsic capabilities. We introduce specific action tokens that enable the model to seamlessly backtrack and edit its own history within a single forward pass. By internalizing the revision loop, our framework Stream of Revision allows the model to activate its latent capabilities just-in-time without external dependencies. Empirical results on secure code generation show that Stream of Revision significantly reduces vulnerabilities with minimal inference overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStream of Revision\u8303\u5f0f\uff0c\u8ba9\u4ee3\u7801\u751f\u6210\u6a21\u578b\u80fd\u81ea\u6211\u56de\u6eaf\u4fee\u6539\u751f\u6210\u5185\u5bb9\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u5e76\u964d\u4f4e\u6f0f\u6d1e\uff0c\u4e14\u63a8\u7406\u6548\u7387\u9ad8\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u91c7\u7528\u4e25\u683c\u5355\u8c03\u7684\u7ebf\u6027\u751f\u6210\u65b9\u5f0f\uff0c\u4e0e\u4eba\u7c7b\u7f16\u7a0b\u4e2d\u8fb9\u751f\u6210\u8fb9\u4fee\u6539\u7684\u8ba4\u77e5\u8fc7\u7a0b\u4e0d\u7b26\u3002\u6b64\u524d\u5f15\u5165\u4fee\u6539\u7684\u529e\u6cd5\u5b58\u5728\u9ad8\u5ef6\u8fdf\u6216\u65e0\u6cd5\u5145\u5206\u5229\u7528\u6a21\u578b\u5185\u5728\u8bed\u4e49\u63a8\u7406\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faStream of Revision\uff08\u4fee\u8ba2\u6d41\uff09\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u7279\u5b9a\u7684\u52a8\u4f5c\u6807\u8bb0\uff0c\u4f7f\u6a21\u578b\u80fd\u5728\u5355\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u56de\u6eaf\u5e76\u7f16\u8f91\u5386\u53f2\u751f\u6210\u5185\u5bb9\uff0c\u5b9e\u73b0\u52a8\u6001\u3001\u81ea\u6211\u4fee\u6b63\u7684\u751f\u6210\u8fc7\u7a0b\uff0c\u5185\u5316\u4fee\u6539\u5faa\u73af\uff0c\u65e0\u9700\u5916\u90e8\u5de5\u5177\u3002", "result": "\u5728\u5b89\u5168\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\uff0cStream of Revision\u663e\u8457\u964d\u4f4e\u4e86\u6f0f\u6d1e\u7387\uff0c\u4e14\u63a8\u7406\u5f00\u9500\u6781\u5c0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u4fc3\u8fdb\u4ee3\u7801\u751f\u6210\u6a21\u578b\u81ea\u6211\u4fee\u6b63\u80fd\u529b\uff0c\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u51cf\u5c11\u5b89\u5168\u6f0f\u6d1e\uff0c\u63a8\u52a8\u4ee3\u7801\u751f\u6210\u5411\u66f4\u7b26\u5408\u4eba\u7c7b\u8ba4\u77e5\u7684\u52a8\u6001\u751f\u6210\u65b9\u5411\u53d1\u5c55\u3002"}}
{"id": "2602.00428", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.00428", "abs": "https://arxiv.org/abs/2602.00428", "authors": ["Naen Xu", "Hengyu An", "Shuo Shi", "Jinghuai Zhang", "Chunyi Zhou", "Changjiang Li", "Tianyu Du", "Zhihui Fu", "Jun Wang", "Shouling Ji"], "title": "When Agents \"Misremember\" Collectively: Exploring the Mandela Effect in LLM-based Multi-Agent Systems", "comment": "ICLR 2026", "summary": "Recent advancements in large language models (LLMs) have significantly enhanced the capabilities of collaborative multi-agent systems, enabling them to address complex challenges. However, within these multi-agent systems, the susceptibility of agents to collective cognitive biases remains an underexplored issue. A compelling example is the Mandela effect, a phenomenon where groups collectively misremember past events as a result of false details reinforced through social influence and internalized misinformation. This vulnerability limits our understanding of memory bias in multi-agent systems and raises ethical concerns about the potential spread of misinformation. In this paper, we conduct a comprehensive study on the Mandela effect in LLM-based multi-agent systems, focusing on its existence, causing factors, and mitigation strategies. We propose MANBENCH, a novel benchmark designed to evaluate agent behaviors across four common task types that are susceptible to the Mandela effect, using five interaction protocols that vary in agent roles and memory timescales. We evaluate agents powered by several LLMs on MANBENCH to quantify the Mandela effect and analyze how different factors affect it. Moreover, we propose strategies to mitigate this effect, including prompt-level defenses (e.g., cognitive anchoring and source scrutiny) and model-level alignment-based defense, achieving an average 74.40% reduction in the Mandela effect compared to the baseline. Our findings provide valuable insights for developing more resilient and ethically aligned collaborative multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u66fc\u5fb7\u62c9\u6548\u5e94\uff0c\u63d0\u51fa\u4e86MANBENCH\u57fa\u51c6\u548c\u591a\u79cd\u7f13\u89e3\u7b56\u7565\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u96c6\u4f53\u8bb0\u5fc6\u504f\u5dee\uff0c\u63d0\u9ad8\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u4f26\u7406\u6807\u51c6\u3002", "motivation": "\u8fd1\u5e74\u6765\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u80fd\u529b\uff0c\u4f46\u8fd9\u4e9b\u7cfb\u7edf\u6613\u53d7\u96c6\u4f53\u8ba4\u77e5\u504f\u5dee\u5f71\u54cd\uff0c\u4f8b\u5982\u66fc\u5fb7\u62c9\u6548\u5e94\uff0c\u8fd9\u4e0d\u4ec5\u5f71\u54cd\u7cfb\u7edf\u6027\u80fd\uff0c\u4e5f\u5f15\u53d1\u8bef\u4fe1\u606f\u4f20\u64ad\u7684\u4f26\u7406\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6784\u5efaMANBENCH\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u8bc4\u4f30\u4e86\u591a\u667a\u80fd\u4f53\u5728\u4e0d\u540c\u4efb\u52a1\u7c7b\u578b\u548c\u4ea4\u4e92\u534f\u8bae\u4e0b\u7684\u66fc\u5fb7\u62c9\u6548\u5e94\u8868\u73b0\uff0c\u5e76\u5e94\u7528\u63d0\u793a\u7ea7\u9632\u5fa1\u548c\u6a21\u578b\u7ea7\u5bf9\u9f50\u9632\u5fa1\u65b9\u6cd5\u8fdb\u884c\u7f13\u89e3\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u7b56\u7565\u80fd\u5e73\u5747\u51cf\u5c1174.40%\u7684\u66fc\u5fb7\u62c9\u6548\u5e94\uff0c\u6709\u6548\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u4f26\u7406\u6027\u3002", "conclusion": "\u672c\u6587\u786e\u8ba4\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5b58\u5728\u66fc\u5fb7\u62c9\u6548\u5e94\u8fd9\u4e00\u96c6\u4f53\u8bb0\u5fc6\u504f\u5dee\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5176\u6210\u56e0\u5e76\u63d0\u51fa\u4e86\u6709\u6548\u7684\u7f13\u89e3\u7b56\u7565\u3002"}}
{"id": "2602.01253", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01253", "abs": "https://arxiv.org/abs/2602.01253", "authors": ["Nouf Alturayeif", "Irfan Ahmad", "Jameleddine Hassine"], "title": "TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability", "comment": null, "summary": "Requirements traceability, the process of establishing and maintaining relationships between requirements and various software development artifacts, is paramount for ensuring system integrity and fulfilling requirements throughout the Software Development Life Cycle (SDLC). Traditional methods, including manual and information retrieval models, are labor-intensive, error-prone, and limited by low precision. Recently, Large Language Models (LLMs) have demonstrated potential for supporting software engineering tasks through advanced language comprehension. However, a substantial gap exists in the systematic design and evaluation of prompts tailored to extract accurate trace links. This paper introduces TraceLLM, a systematic framework for enhancing requirements traceability through prompt engineering and demonstration selection. Our approach incorporates rigorous dataset splitting, iterative prompt refinement, enrichment with contextual roles and domain knowledge, and evaluation across zero- and few-shot settings. We assess prompt generalization and robustness using eight state-of-the-art LLMs on four benchmark datasets representing diverse domains (aerospace, healthcare) and artifact types (requirements, design elements, test cases, regulations). TraceLLM achieves state-of-the-art F2 scores, outperforming traditional IR baselines, fine-tuned models, and prior LLM-based methods. We also explore the impact of demonstration selection strategies, identifying label-aware, diversity-based sampling as particularly effective. Overall, our findings highlight that traceability performance depends not only on model capacity but also critically on the quality of prompt engineering. In addition, the achieved performance suggests that TraceLLM can support semi-automated traceability workflows in which candidate links are reviewed and validated by human analysts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTraceLLM\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u63d0\u5347\u9700\u6c42\u8ffd\u8e2a\u51c6\u786e\u6027\uff0c\u5728\u591a\u9886\u57df\u591a\u6a21\u578b\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u63a8\u52a8\u534a\u81ea\u52a8\u8ffd\u8e2a\u5e94\u7528\u53d1\u5c55\u3002", "motivation": "\u4f20\u7edf\u9700\u6c42\u8ffd\u8e2a\u65b9\u6cd5\u52b3\u52a8\u5f3a\u5ea6\u5927\u3001\u6613\u51fa\u9519\u4e14\u7cbe\u5ea6\u4f4e\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u65b9\u9762\u7684\u7cfb\u7edf\u8bbe\u8ba1\u548c\u8bc4\u4f30\u4e0d\u8db3\u3002", "method": "\u63d0\u51faTraceLLM\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u548c\u793a\u8303\u9009\u62e9\uff0c\u7ed3\u5408\u6570\u636e\u96c6\u5212\u5206\u3001\u8fed\u4ee3\u63d0\u793a\u4f18\u5316\uff0c\u4ee5\u53ca\u591a\u6a21\u578b\u548c\u591a\u9886\u57df\u8bc4\u4f30\u3002", "result": "\u5728\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cTraceLLM\u5b9e\u73b0\u4e86\u9886\u5148\u7684F2\u5206\u6570\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u548c\u4e4b\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u4e14\u6807\u7b7e\u611f\u77e5\u548c\u591a\u6837\u6027\u91c7\u6837\u7b56\u7565\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u9700\u6c42\u8ffd\u8e2a\u7684\u6027\u80fd\u4e0d\u4ec5\u4f9d\u8d56\u6a21\u578b\u80fd\u529b\uff0c\u66f4\u4f9d\u8d56\u9ad8\u8d28\u91cf\u63d0\u793a\u5de5\u7a0b\uff0cTraceLLM\u53ef\u652f\u6301\u4eba\u673a\u8054\u5408\u7684\u534a\u81ea\u52a8\u9700\u6c42\u8ffd\u8e2a\u6d41\u7a0b\u3002"}}
{"id": "2602.00459", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00459", "abs": "https://arxiv.org/abs/2602.00459", "authors": ["Yongxin Zhou", "Changshun Wu", "Philippe Mulhem", "Didier Schwab", "Maxime Peyrard"], "title": "What Matters to an LLM? Behavioral and Computational Evidences from Summarization", "comment": "Findings of EACL 2026", "summary": "Large Language Models (LLMs) are now state-of-the-art at summarization, yet the internal notion of importance that drives their information selections remains hidden. We propose to investigate this by combining behavioral and computational analyses. Behaviorally, we generate a series of length-controlled summaries for each document and derive empirical importance distributions based on how often each information unit is selected. These reveal that LLMs converge on consistent importance patterns, sharply different from pre-LLM baselines, and that LLMs cluster more by family than by size. Computationally, we identify that certain attention heads align well with empirical importance distributions, and that middle-to-late layers are strongly predictive of importance. Together, these results provide initial insights into what LLMs prioritize in summarization and how this priority is internally represented, opening a path toward interpreting and ultimately controlling information selection in these models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u884c\u4e3a\u548c\u8ba1\u7b97\u5206\u6790\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u4fe1\u606f\u9009\u62e9\u4f18\u5148\u7ea7\uff0c\u53d1\u73b0\u5176\u6a21\u5f0f\u4e00\u81f4\u4e14\u7531\u4e2d\u540e\u5c42\u6ce8\u610f\u529b\u673a\u5236\u9a71\u52a8\uff0c\u4e3a\u89e3\u91ca\u548c\u63a7\u5236\u6a21\u578b\u6458\u8981\u884c\u4e3a\u63d0\u4f9b\u65b0\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u4fe1\u606f\u9009\u62e9\u80cc\u540e\u7684\u5185\u90e8\u91cd\u8981\u6027\u673a\u5236\u4e0d\u660e\u786e\uff0c\u9700\u8981\u63ed\u793a\u5176\u4f18\u5148\u7ea7\u4f55\u5728\u4ee5\u4fbf\u7406\u89e3\u548c\u63a7\u5236\u6458\u8981\u884c\u4e3a\u3002", "method": "\u7ed3\u5408\u884c\u4e3a\u5206\u6790\uff08\u751f\u6210\u63a7\u5236\u957f\u5ea6\u7684\u6458\u8981\u5e76\u57fa\u4e8e\u9009\u62e9\u9891\u7387\u63a8\u5bfc\u4fe1\u606f\u91cd\u8981\u6027\u5206\u5e03\uff09\u548c\u8ba1\u7b97\u5206\u6790\uff08\u5173\u6ce8\u6ce8\u610f\u529b\u5934\u4e0e\u91cd\u8981\u6027\u5206\u5e03\u7684\u5173\u8054\u53ca\u5c42\u6b21\u5f71\u54cd\uff09\u3002", "result": "\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u91cd\u8981\u6027\u9009\u62e9\u4e0a\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6a21\u5f0f\uff0c\u4e14\u4e0e\u4f20\u7edf\u57fa\u7ebf\u6a21\u578b\u663e\u8457\u4e0d\u540c\uff1b\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u95f4\u7684\u805a\u7c7b\u5173\u7cfb\u660e\u663e\uff1b\u90e8\u5206\u6ce8\u610f\u529b\u5934\u4e0e\u7ecf\u9a8c\u91cd\u8981\u6027\u9ad8\u5ea6\u5339\u914d\uff0c\u4e2d\u540e\u5c42\u5bf9\u91cd\u8981\u6027\u5224\u65ad\u8d21\u732e\u5927\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6458\u8981\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4e00\u81f4\u4e14\u72ec\u7279\u7684\u4fe1\u606f\u91cd\u8981\u6027\u5206\u5e03\uff0c\u4e14\u5176\u5185\u90e8\u7684\u4f18\u5148\u7ea7\u673a\u5236\u4e3b\u8981\u4f53\u73b0\u5728\u4e2d\u540e\u5c42\u7684\u6ce8\u610f\u529b\u5934\u4e0a\u3002"}}
{"id": "2602.01311", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01311", "abs": "https://arxiv.org/abs/2602.01311", "authors": ["Ahmed Raza Amir", "Syed Muhammad Atif"], "title": "Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study", "comment": "8 pages, 4 figures, 2 tables", "summary": "Workflow automation has become increasingly accessible through low-code platforms, enabling small organizations and individuals to improve operational efficiency without extensive software development expertise. This study evaluates the performance impact of workflow automation using n8n through a small-scale business case study. A representative lead-processing workflow was implemented to automatically store data, send email confirmations, and generate real-time notifications. Experimental benchmarking was conducted by comparing 20 manual executions with 25 automated executions under controlled conditions. The results demonstrate a significant reduction in the average execution time from 185.35 seconds (manual) to 1.23 seconds (automated), corresponding to an approximately 151 times reduction in execution time. Additionally, manual execution exhibited an error rate of 5%, while automated execution achieved zero observed errors. The findings highlight the effectiveness of low-code automation in improving efficiency, reliability, and operational consistency for small-scale workflows.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5c0f\u89c4\u6a21\u6848\u4f8b\u9a8c\u8bc1\u4f7f\u7528n8n\u4f4e\u4ee3\u7801\u5e73\u53f0\u81ea\u52a8\u5316\u5de5\u4f5c\u6d41\u7a0b\u5728\u6548\u7387\u548c\u51c6\u786e\u6027\u4e0a\u7684\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u5e0c\u671b\u9a8c\u8bc1\u4f4e\u4ee3\u7801\u5e73\u53f0\u5728\u5c0f\u578b\u7ec4\u7ec7\u548c\u4e2a\u4eba\u4e2d\u5e94\u7528\u5de5\u4f5c\u6d41\u81ea\u52a8\u5316\u4ee5\u63d0\u5347\u8fd0\u8425\u6548\u7387\u7684\u5b9e\u7528\u6027\u548c\u6548\u679c\u3002", "method": "\u901a\u8fc7n8n\u5b9e\u73b0\u4ee3\u8868\u6027\u7684\u6f5c\u5728\u5ba2\u6237\u5904\u7406\u5de5\u4f5c\u6d41\u7a0b\uff0c\u81ea\u52a8\u5316\u6570\u636e\u5b58\u50a8\u3001\u90ae\u4ef6\u786e\u8ba4\u548c\u5b9e\u65f6\u901a\u77e5\uff1b\u5e76\u5728\u63a7\u5236\u6761\u4ef6\u4e0b\u5bf9\u6bd420\u6b21\u624b\u52a8\u4e0e25\u6b21\u81ea\u52a8\u6267\u884c\u7684\u6027\u80fd\u3002", "result": "\u81ea\u52a8\u5316\u6267\u884c\u65f6\u95f4\u5e73\u5747\u4e3a1.23\u79d2\uff0c\u6bd4\u624b\u52a8\u7684185.35\u79d2\u51cf\u5c11\u7ea6151\u500d\uff1b\u624b\u52a8\u9519\u8bef\u7387\u4e3a5%\uff0c\u81ea\u52a8\u5316\u5219\u4e3a\u96f6\u9519\u8bef\u3002", "conclusion": "\u4f4e\u4ee3\u7801\u81ea\u52a8\u5316\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u89c4\u6a21\u5de5\u4f5c\u6d41\u7a0b\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u663e\u8457\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u548c\u9519\u8bef\u7387\u3002"}}
{"id": "2602.00469", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00469", "abs": "https://arxiv.org/abs/2602.00469", "authors": ["Abhinav Gupta", "Toben H. Mintz", "Jesse Thomason"], "title": "Words that make SENSE: Sensorimotor Norms in Learned Lexical Token Representations", "comment": "5 pages, 2 figures, codebase can be found at: https://github.com/abhinav-usc/SENSE-model/tree/main", "summary": "While word embeddings derive meaning from co-occurrence patterns, human language understanding is grounded in sensory and motor experience. We present $\\text{SENSE}$ $(\\textbf{S}\\text{ensorimotor }$ $\\textbf{E}\\text{mbedding }$ $\\textbf{N}\\text{orm }$ $\\textbf{S}\\text{coring }$ $\\textbf{E}\\text{ngine})$, a learned projection model that predicts Lancaster sensorimotor norms from word lexical embeddings. We also conducted a behavioral study where 281 participants selected which among candidate nonce words evoked specific sensorimotor associations, finding statistically significant correlations between human selection rates and $\\text{SENSE}$ ratings across 6 of the 11 modalities. Sublexical analysis of these nonce words selection rates revealed systematic phonosthemic patterns for the interoceptive norm, suggesting a path towards computationally proposing candidate phonosthemes from text data.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSENSE\u6a21\u578b\uff0c\u5c06\u8bcd\u5d4c\u5165\u6295\u5f71\u5230\u611f\u77e5\u8fd0\u52a8\u8303\u5f0f\uff0c\u884c\u4e3a\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u9884\u6d4b\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u76f8\u5173\uff0c\u8fdb\u800c\u63ed\u793a\u8bed\u8a00\u4e0e\u611f\u77e5\u8fd0\u52a8\u7684\u7ed3\u5408\u3002", "motivation": "\u76ee\u524d\u8bcd\u5d4c\u5165\u4e3b\u8981\u57fa\u4e8e\u8bcd\u7684\u5171\u73b0\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u611f\u77e5\u4e0e\u8fd0\u52a8\u7ecf\u9a8c\u7684\u652f\u6491\uff0c\u672c\u6587\u65e8\u5728\u5c06\u4eba\u7c7b\u7684\u611f\u77e5\u8fd0\u52a8\u4f53\u9a8c\u878d\u5165\u8bed\u8a00\u7406\u89e3\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86SENSE\u6a21\u578b\uff0c\u4e00\u79cd\u901a\u8fc7\u8bcd\u6c47\u5d4c\u5165\u9884\u6d4bLancaster\u611f\u77e5\u8fd0\u52a8\u8303\u5f0f\u7684\u5b66\u4e60\u6295\u5f71\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u4e86\u5305\u542b281\u540d\u53c2\u4e0e\u8005\u7684\u884c\u4e3a\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "SENSE\u6a21\u578b\u5728\u591a\u6570\u611f\u77e5\u8fd0\u52a8\u6a21\u6001\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u4eba\u7c7b\u9009\u62e9\u7387\u7684\u663e\u8457\u76f8\u5173\u6027\uff0c\u4e14\u901a\u8fc7\u5bf9\u65e0\u610f\u4e49\u8bcd\u7684\u5206\u6790\u53d1\u73b0\u4e86\u7cfb\u7edf\u6027\u7684\u97f3\u5f62\u76f8\u5173\u6a21\u5f0f\u3002", "conclusion": "SENSE\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u8bcd\u6c47\u7684\u611f\u77e5\u8fd0\u52a8\u8303\u5f0f\uff0c\u4e14\u5176\u9884\u6d4b\u7ed3\u679c\u4e0e\u4eba\u7c7b\u884c\u4e3a\u6570\u636e\u5728\u591a\u4e2a\u611f\u77e5\u8fd0\u52a8\u6a21\u6001\u4e0a\u5b58\u5728\u663e\u8457\u76f8\u5173\u6027\uff0c\u63ed\u793a\u4e86\u6587\u672c\u4fe1\u606f\u4e0e\u611f\u77e5\u8fd0\u52a8\u4f53\u9a8c\u4e4b\u95f4\u7684\u8054\u7cfb\u3002"}}
{"id": "2602.01563", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01563", "abs": "https://arxiv.org/abs/2602.01563", "authors": ["Nan Hu", "Han Li", "Jimeng Sun", "Lu Wang", "Fangkai Yang", "Bo Qiao", "Pu Zhao", "David Dai", "Mengyu Liu", "Yuefeng Zhan", "Jianjin Zhang", "Weihao Han", "Allen Sun", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang", "Denvy Deng", "Feng Sun", "Qi Zhang"], "title": "AdNanny: One Reasoning LLM for All Offline Ads Recommendation Tasks", "comment": "21 pages, 3 figures", "summary": "Large Language Models (LLMs) have shown strong capabilities in Natural Language Understanding and Generation, but deploying them directly in online advertising systems is often impractical due to strict millisecond-level latency constraints. This has motivated the use of LLMs offline to improve retrieval, ranking, and recommendation models. Existing solutions typically fine-tune separate LLMs for individual tasks such as query-ad relevance labeling, keyword-based query generation, and user profiling. This results in redundant models, high maintenance cost, and limited performance gains despite substantial overlap in domain knowledge and reasoning patterns. We introduce AdNanny, a unified reasoning-centric LLM that serves as a shared backbone for offline advertising tasks. AdNanny is obtained by fine-tuning a public 671B-parameter DeepSeek-R1 checkpoint using a scalable training system that supports hybrid dense-MoE parallelism. We construct reasoning-augmented corpora that pair structured supervision with step-by-step natural language explanations. A multi-task supervised fine-tuning stage with adaptive reweighting enables AdNanny to handle diverse labeling and generation tasks in a consistent reasoning format. This is followed by reinforcement learning using downstream advertising metrics to align model behavior with online retrieval and ranking objectives. AdNanny is deployed in production within Bing Ads, where it significantly reduces manual labeling effort and improves accuracy across multiple offline tasks. By consolidating many task-specific models into a single reasoning-centric foundation model, AdNanny provides a scalable and cost-effective solution for large-scale advertising systems.", "AI": {"tldr": "AdNanny\u662f\u4e00\u79cd\u7edf\u4e00\u7684\u63a8\u7406\u4e2d\u5fc3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5e7f\u544a\u76f8\u5173\u4efb\u52a1\uff0c\u5b9e\u73b0\u5728\u5fc5\u5e94\u5e7f\u544a\u7cfb\u7edf\u4e2d\u7684\u6210\u529f\u5e94\u7528\uff0c\u63d0\u5347\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u7ef4\u62a4\u6210\u672c\u3002", "motivation": "\u7531\u4e8e\u5728\u7ebf\u5e7f\u544a\u7cfb\u7edf\u5bf9\u5ef6\u8fdf\u8981\u6c42\u6781\u9ad8\uff0c\u96be\u4ee5\u76f4\u63a5\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u56e0\u6b64\u9700\u8981\u79bb\u7ebf\u5229\u7528LLMs\u63d0\u5347\u68c0\u7d22\u3001\u6392\u5e8f\u548c\u63a8\u8350\u6a21\u578b\u6548\u679c\u3002\u73b0\u6709\u65b9\u6848\u901a\u5e38\u4e3a\u5355\u4e2a\u4efb\u52a1\u5355\u72ec\u5fae\u8c03\u6a21\u578b\uff0c\u5bfc\u81f4\u6a21\u578b\u5197\u4f59\u3001\u7ef4\u62a4\u6210\u672c\u9ad8\u4e14\u6027\u80fd\u63d0\u5347\u6709\u9650\u3002", "method": "\u63d0\u51faAdNanny\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u63a8\u7406\u4e2d\u5fc3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u57fa\u4e8e671\u4ebf\u53c2\u6570DeepSeek-R1\uff0c\u901a\u8fc7\u6df7\u5408\u7a20\u5bc6-MoE\u5e76\u884c\u8bad\u7ec3\u7cfb\u7edf\u8fdb\u884c\u5fae\u8c03\u3002\u6784\u5efa\u7ed3\u5408\u7ed3\u6784\u5316\u76d1\u7763\u548c\u6b65\u9aa4\u5316\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7684\u63a8\u7406\u589e\u5f3a\u8bed\u6599\uff0c\u91c7\u7528\u591a\u4efb\u52a1\u6709\u76d1\u7763\u5fae\u8c03\u548c\u81ea\u9002\u5e94\u91cd\u52a0\u6743\uff0c\u914d\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5728\u7ebf\u5e7f\u544a\u6307\u6807\u3002", "result": "AdNanny\u5728\u5fc5\u5e94\u5e7f\u544a\u7cfb\u7edf\u4e2d\u90e8\u7f72\uff0c\u663e\u8457\u51cf\u5c11\u4eba\u5de5\u6807\u6ce8\u5de5\u4f5c\uff0c\u63d0\u5347\u591a\u9879\u79bb\u7ebf\u4efb\u52a1\u7684\u51c6\u786e\u7387\u3002\u901a\u8fc7\u6574\u5408\u591a\u4e2a\u4efb\u52a1\u4e13\u7528\u6a21\u578b\u4e3a\u5355\u4e00\u63a8\u7406\u6838\u5fc3\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5927\u89c4\u6a21\u5e7f\u544a\u7cfb\u7edf\u7684\u9ad8\u6548\u3001\u4f4e\u6210\u672c\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AdNanny\u5c55\u793a\u4e86\u901a\u8fc7\u7edf\u4e00\u63a8\u7406\u4e2d\u5fc3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u5e7f\u544a\u79bb\u7ebf\u4efb\u52a1\u6027\u80fd\u7684\u53ef\u884c\u6027\u548c\u6548\u679c\uff0c\u4e3a\u5e7f\u544a\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u57fa\u7840\u6a21\u578b\u65b9\u6848\u3002"}}
{"id": "2602.00477", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00477", "abs": "https://arxiv.org/abs/2602.00477", "authors": ["Zhexiong Liu", "Diane Litman"], "title": "Intention-Adaptive LLM Fine-Tuning for Text Revision Generation", "comment": "In the Conference of the European Chapter of the Association for Computational Linguistics (EACL), March 2026", "summary": "Large Language Models (LLMs) have achieved impressive capabilities in various context-based text generation tasks, such as summarization and reasoning; however, their applications in intention-based generation tasks remain underexplored. One such example is revision generation, which requires the generated text to explicitly reflect the writer's actual intentions. Identifying intentions and generating desirable revisions are challenging due to their complex and diverse nature. Although prior work has employed LLMs to generate revisions with few-shot learning, they struggle with handling entangled multi-intent scenarios. While fine-tuning LLMs using intention-based instructions appears promising, it demands large amounts of annotated data, which is expensive and scarce in the revision community. To address these challenges, we propose Intention-Tuning, an intention-adaptive layer-wise LLM fine-tuning framework that dynamically selects a subset of LLM layers to learn the intentions and subsequently transfers their representations to revision generation. Experimental results suggest that Intention-Tuning is effective and efficient on small revision corpora, outperforming several PEFT baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u610f\u56fe\u81ea\u9002\u5e94\u7684\u5206\u5c42\u5fae\u8c03\u65b9\u6cd5Intention-Tuning\uff0c\u89e3\u51b3\u591a\u610f\u56fe\u4fee\u8ba2\u751f\u6210\u4e2d\u6570\u636e\u7a00\u7f3a\u548c\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u7684\u95ee\u9898\uff0c\u53d6\u5f97\u4e86\u4f18\u5f02\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u57fa\u4e8e\u610f\u56fe\u7684\u6587\u672c\u751f\u6210\u4efb\u52a1\u5982\u4fee\u8ba2\u751f\u6210\u63a2\u7d22\u4e0d\u8db3\uff0c\u4e14\u591a\u610f\u56fe\u6df7\u5408\u573a\u666f\u590d\u6742\u96be\u5904\u7406\uff0c\u4e14\u7f3a\u4e4f\u5927\u91cf\u5e26\u6807\u6ce8\u6570\u636e\u8fdb\u884c\u5fae\u8c03\u3002", "method": "\u63d0\u51fa\u4e86\u610f\u56fe\u81ea\u9002\u5e94\u7684\u5206\u5c42LLM\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u90e8\u5206\u6a21\u578b\u5c42\u5b66\u4e60\u610f\u56fe\uff0c\u5e76\u5c06\u5176\u8868\u5f81\u8f6c\u79fb\u7528\u4e8e\u4fee\u8ba2\u751f\u6210\u3002", "result": "\u5b9e\u9a8c\u8868\u660eIntention-Tuning\u5728\u5c0f\u89c4\u6a21\u4fee\u8ba2\u8bed\u6599\u5e93\u4e0a\u80fd\u6709\u6548\u6355\u6349\u610f\u56fe\uff0c\u63d0\u9ad8\u4fee\u8ba2\u751f\u6210\u8d28\u91cf\uff0c\u4e14\u6548\u7387\u8f83\u9ad8\u3002", "conclusion": "Intention-Tuning\u65b9\u6cd5\u5728\u5c11\u91cf\u4fee\u8ba2\u8bed\u6599\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u7684\u6548\u679c\u548c\u6548\u7387\uff0c\u4f18\u4e8e\u591a\u79cd\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u57fa\u7ebf\u3002"}}
{"id": "2602.01957", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01957", "abs": "https://arxiv.org/abs/2602.01957", "authors": ["Xiaoxin Zhou", "Taher A. Ghaleb", "Safwat Hassan"], "title": "Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects", "comment": null, "summary": "Mobile apps face strong pressure for fast and reliable updates. Continuous Integration (CI) helps automate builds, tests, and releases, but its impact on mobile development remains underexplored. Despite the widespread use of CI, little is known about how it affects development activity, release speed, and user-facing outcomes in mobile projects. Existing studies mostly focus on CI adoption in general-purpose software, providing limited insight into mobile-specific dynamics, such as app store visibility and user engagement. In this paper, we analyze open-source Android apps to (1) compare CI adopters and non-adopters, (2) characterize adoption patterns using activity and bug metrics, and (3) assess pre/post adoption changes and user-facing outcomes. We observe that CI adopters are larger and more active, with faster and more regular releases. CI adoption is concentrated in integration- and reliability-intensive categories (e.g., finance and productivity) and is associated with higher Google Play Store engagement (more downloads and reviews) without lower ratings. Overall, CI adoption aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement in mobile ecosystems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5f00\u6e90Android\u5e94\u7528\uff0c\u53d1\u73b0CI\u91c7\u7528\u663e\u8457\u63d0\u5347\u4e86\u79fb\u52a8\u5e94\u7528\u7684\u5f00\u53d1\u6548\u7387\u3001\u53d1\u5e03\u9891\u7387\u53ca\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u589e\u5f3a\u4e86\u5e94\u7528\u5728\u5e94\u7528\u5546\u5e97\u7684\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1CI\u5728\u901a\u7528\u8f6f\u4ef6\u9886\u57df\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5bf9\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u7528\u6237\u4f53\u9a8c\u548c\u5e94\u7528\u5546\u5e97\u8868\u73b0\uff0c\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u5206\u6790\u5f00\u6e90Android\u5e94\u7528\uff0c\u6bd4\u8f83CI\u91c7\u7528\u8005\u4e0e\u975e\u91c7\u7528\u8005\uff0c\u4f7f\u7528\u6d3b\u52a8\u548c\u7f3a\u9677\u6307\u6807\u6765\u63cf\u7ed8\u91c7\u7528\u6a21\u5f0f\uff0c\u5e76\u8bc4\u4f30\u91c7\u7528\u524d\u540e\u7684\u53d8\u5316\u53ca\u7528\u6237\u5f71\u54cd\u3002", "result": "CI\u91c7\u7528\u8005\u901a\u5e38\u89c4\u6a21\u66f4\u5927\u3001\u6d3b\u52a8\u66f4\u9891\u7e41\uff0c\u53d1\u5e03\u66f4\u5feb\u901f\u4e14\u89c4\u5f8b\u3002CI\u96c6\u4e2d\u5728\u96c6\u6210\u548c\u53ef\u9760\u6027\u8981\u6c42\u9ad8\u7684\u7c7b\u522b\u4e2d\uff0c\u5982\u91d1\u878d\u548c\u751f\u4ea7\u529b\u5de5\u5177\uff0c\u5e76\u5e26\u6765\u66f4\u9ad8\u7684\u5e94\u7528\u5546\u5e97\u4e0b\u8f7d\u548c\u8bc4\u4ef7\u6570\u91cf\u3002", "conclusion": "CI\u7684\u91c7\u7528\u6709\u52a9\u4e8e\u63d0\u5347\u79fb\u52a8\u5e94\u7528\u7684\u5f00\u53d1\u6d3b\u8dc3\u5ea6\u3001\u53d1\u5e03\u901f\u5ea6\u53ca\u7528\u6237\u53c2\u4e0e\u5ea6\uff0c\u4e14\u4e0d\u4f1a\u964d\u4f4e\u7528\u6237\u8bc4\u5206\u3002"}}
{"id": "2602.00491", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00491", "abs": "https://arxiv.org/abs/2602.00491", "authors": ["Zhaokun Yan", "Zhaohan Liu", "Wuzheng Dong", "Lijie Feng", "Chengxiao Dai"], "title": "From Knowledge to Inference: Scaling Laws of Specialized Reasoning on GlobalHealthAtlas", "comment": null, "summary": "Public health reasoning requires population level inference grounded in scientific evidence, expert consensus, and safety constraints. However, it remains underexplored as a structured machine learning problem with limited supervised signals and benchmarks. We introduce \\textbf{GlobalHealthAtlas}, a large scale multilingual dataset of 280,210 instances spanning 15 public health domains and 17 languages, stratified into three difficulty levels from health literacy to epidemiological and policy reasoning. Instances are derived from openly available public health sources and labeled by language, domain, and difficulty to support supervised learning and slice based evaluation. We further propose large language model (LLM) assisted construction and quality control pipeline with retrieval, duplication, evidence grounding checks, and label validation to improve consistency at scale. Finally, we present a domain aligned evaluator distilled from high confidence judgments of diverse LLMs to assess outputs along six dimensions: Accuracy, Reasoning, Completeness, Consensus Alignment, Terminology Norms, and Insightfulness. Together, these contributions enable reproducible training and evaluation of LLMs for safety critical public health reasoning beyond conventional QA benchmarks.", "AI": {"tldr": "\u672c\u6587\u53d1\u5e03\u4e86GlobalHealthAtlas\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u4f53\u7cfb\uff0c\u63a8\u52a8\u4e86\u516c\u5171\u536b\u751f\u63a8\u7406\u5728\u591a\u8bed\u8a00\u3001\u5927\u89c4\u6a21\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u7814\u7a76\u548c\u5b89\u5168\u5e94\u7528\u3002", "motivation": "\u516c\u5171\u536b\u751f\u63a8\u7406\u9700\u8981\u57fa\u4e8e\u79d1\u5b66\u8bc1\u636e\u548c\u4e13\u5bb6\u5171\u8bc6\u8fdb\u884c\u4eba\u53e3\u5c42\u9762\u7684\u63a8\u65ad\uff0c\u4f46\u5f53\u524d\u76f8\u5173\u673a\u5668\u5b66\u4e60\u7814\u7a76\u8f83\u5c11\uff0c\u7f3a\u4e4f\u5927\u578b\u591a\u8bed\u8a00\u6807\u6ce8\u6570\u636e\u96c6\u548c\u7cfb\u7edf\u8bc4\u6d4b\u5de5\u5177\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u8bad\u7ec3\u548c\u5b89\u5168\u5e94\u7528\u3002", "method": "\u91c7\u96c6\u6db5\u76d615\u4e2a\u516c\u5171\u536b\u751f\u9886\u57df\u548c17\u79cd\u8bed\u8a00\u768428\u4e07\u6761\u6570\u636e\uff0c\u6570\u636e\u5206\u4e3a\u4e09\u4e2a\u96be\u5ea6\u7b49\u7ea7\uff0c\u5e76\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u6570\u636e\u6784\u5efa\u4e0e\u8d28\u91cf\u63a7\u5236\u6d41\u7a0b\u786e\u4fdd\u6570\u636e\u4e00\u81f4\u6027\u3002\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u591a\u6a21\u578b\u9ad8\u7f6e\u4fe1\u5ea6\u5224\u65ad\u7684\u9886\u57df\u5bf9\u9f50\u8bc4\u4f30\u5668\uff0c\u4ece\u51c6\u786e\u6027\u3001\u63a8\u7406\u3001\u5b8c\u6574\u6027\u7b49\u516d\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u6a21\u578b\u8f93\u51fa\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b280,210\u6761\u5b9e\u4f8b\u7684\u591a\u8bed\u8a00\u516c\u5171\u536b\u751f\u63a8\u7406\u6570\u636e\u96c6GlobalHealthAtlas\uff0c\u5f00\u53d1\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u6570\u636e\u5904\u7406\u548c\u516d\u7ef4\u5ea6\u8bc4\u4f30\u7cfb\u7edf\uff0c\u5b9e\u73b0\u4e86\u5bf9\u516c\u5171\u536b\u751f\u63a8\u7406\u4efb\u52a1\u7684\u7ed3\u6784\u5316\u5b66\u4e60\u548c\u53ef\u91cd\u590d\u8bc4\u6d4b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aGlobalHealthAtlas\u7684\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u516c\u5171\u536b\u751f\u63a8\u7406\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86\u516c\u5171\u536b\u751f\u63a8\u7406\u5728\u673a\u5668\u5b66\u4e60\u9886\u57df\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u5e76\u63d0\u4f9b\u4e86\u76f8\u5e94\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u516c\u5171\u536b\u751f\u9886\u57df\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2602.02138", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02138", "abs": "https://arxiv.org/abs/2602.02138", "authors": ["Lyu Zongyi", "Ji Zhenlan", "Chen Songqiang", "Wang Liwen", "Huang Yuheng", "Wang Shuai", "Cheung Shing-Chi"], "title": "CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems", "comment": "18 pages, 12 tables, 4 figures", "summary": "Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \\textbf{C}ausality-based \\textbf{A}nalysis framework for \\textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.\n  We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8e\u56e0\u679c\u5206\u6790\u7684\u591a\u4ee3\u7406\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u4e2d\u95f4\u7279\u5f81\u91cd\u8981\u6027\u8bc4\u4f30\u6846\u67b6CAM\uff0c\u63ed\u793a\u5173\u952e\u7279\u5f81\u53ca\u6df7\u5408\u540e\u7aef\u4f18\u52bf\uff0c\u63a8\u52a8\u7cfb\u7edf\u4f18\u5316\u548c\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u591a\u4ee3\u7406\u4ee3\u7801\u751f\u6210\u7cfb\u7edf\u67b6\u6784\u590d\u6742\uff0c\u4ea7\u751f\u5927\u91cf\u4e2d\u95f4\u8f93\u51fa\uff0c\u4e2a\u522b\u4e2d\u95f4\u8f93\u51fa\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u91cd\u8981\u6027\u4e0d\u660e\u786e\uff0c\u963b\u788d\u4e86\u9488\u5bf9\u6027\u4f18\u5316\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u7c7b\u4e2d\u95f4\u8f93\u51fa\uff0c\u5bf9\u4e2d\u95f4\u7279\u5f81\u8fdb\u884c\u73b0\u5b9e\u9519\u8bef\u6a21\u62df\uff0c\u91cf\u5316\u5176\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u5f71\u54cd\uff0c\u5e76\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u5206\u6790\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\u3002", "result": "\u53d1\u73b0\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7279\u5f81\u548c\u6df7\u5408\u540e\u7aef\u67b6\u6784\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5b9e\u73b0\u4e8673.3%\u6545\u969c\u4fee\u590d\u6210\u529f\u7387\u53ca\u6700\u592766.8%\u4e2d\u95f4\u7279\u5f81\u526a\u679d\uff0c\u4fdd\u6301\u751f\u6210\u6027\u80fd\u4e0d\u53d8\u3002", "conclusion": "CAM\u6846\u67b6\u901a\u8fc7\u56e0\u679c\u5206\u6790\u7cfb\u7edf\u5730\u91cf\u5316\u4e86\u591a\u4ee3\u7406\u4ee3\u7801\u751f\u6210\u7cfb\u7edf(MACGS)\u4e2d\u4e0d\u540c\u4e2d\u95f4\u7279\u5f81\u5bf9\u7cfb\u7edf\u6b63\u786e\u6027\u7684\u8d21\u732e\uff0c\u63ed\u793a\u4e86\u4e0a\u4e0b\u6587\u4f9d\u8d56\u7684\u91cd\u8981\u7279\u5f81\u53ca\u6df7\u5408\u540e\u7aef\u67b6\u6784\u7684\u4f18\u52bf\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u548c\u4f18\u5316\u6548\u7387\u3002"}}
{"id": "2602.00497", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00497", "abs": "https://arxiv.org/abs/2602.00497", "authors": ["Hanjing Shi", "Dominic DiFranzo"], "title": "Culturally-Grounded Governance for Multilingual Language Models: Rights, Data Boundaries, and Accountable AI Design", "comment": null, "summary": "Multilingual large language models (MLLMs) are increasingly deployed across cultural, linguistic, and political contexts, yet existing governance frameworks largely assume English-centric data, homogeneous user populations, and abstract notions of fairness. This creates systematic risks for low-resource languages and culturally marginalized communities, where data practices, model behavior, and accountability mechanisms often fail to align with local norms, rights, and expectations. Drawing on cross-cultural perspectives in human-centered computing and AI governance, this paper synthesizes existing evidence on multilingual model behavior, data asymmetries, and sociotechnical harm, and articulates a culturally grounded governance framework for MLLMs. We identify three interrelated governance challenges: cultural and linguistic inequities in training data and evaluation practices, misalignment between global deployment and locally situated norms, values, and power structures, and limited accountability mechanisms for addressing harms experienced by marginalized language communities. Rather than proposing new technical benchmarks, we contribute a conceptual agenda that reframes multilingual AI governance as a sociocultural and rights based problem. We outline design and policy implications for data stewardship, transparency, and participatory accountability, and argue that culturally grounded governance is essential for ensuring that multilingual language models do not reproduce existing global inequalities under the guise of scale and neutrality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6cbb\u7406\u7684\u6587\u5316\u548c\u6743\u5229\u57fa\u7840\u6846\u67b6\uff0c\u5f3a\u8c03\u516c\u5e73\u4e0e\u8d23\u4efb\uff0c\u907f\u514d\u5168\u7403\u4e0d\u5e73\u7b49\u52a0\u5267\u3002", "motivation": "\u73b0\u6709\u6cbb\u7406\u6846\u67b6\u5047\u5b9a\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\uff0c\u5ffd\u89c6\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6587\u5316\u8fb9\u7f18\u793e\u533a\u7684\u9700\u6c42\uff0c\u5bfc\u81f4\u7cfb\u7edf\u6027\u98ce\u9669\u3002", "method": "\u7efc\u5408\u8de8\u6587\u5316\u89c6\u89d2\u7684\u4eba\u672c\u8ba1\u7b97\u548cAI\u6cbb\u7406\uff0c\u5206\u6790\u591a\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u3001\u6570\u636e\u4e0d\u5bf9\u79f0\u548c\u793e\u4f1a\u6280\u672f\u4f24\u5bb3\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6587\u5316\u6839\u57fa\u7684\u6cbb\u7406\u6846\u67b6\uff0c\u5f3a\u8c03\u6570\u636e\u7ba1\u7406\u3001\u900f\u660e\u5ea6\u548c\u53c2\u4e0e\u5f0f\u95ee\u8d23\u673a\u5236\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6cbb\u7406\u9700\u8981\u4ee5\u6587\u5316\u4e3a\u672c\uff0c\u786e\u4fdd\u5176\u4e0d\u590d\u5236\u5168\u7403\u4e0d\u5e73\u7b49\u3002"}}
{"id": "2602.02235", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02235", "abs": "https://arxiv.org/abs/2602.02235", "authors": ["Zhaonan Wu", "Yanjie Zhao", "Zhenpeng Chen", "Zheng Wang", "Haoyu Wang"], "title": "Agent-Based Software Artifact Evaluation", "comment": null, "summary": "Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \\$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts.", "AI": {"tldr": "\u9762\u5411\u8f6f\u4ef6\u5de5\u7a0b\u5236\u54c1\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u6846\u67b6ArtifactCopilot\uff0c\u901a\u8fc7\u6784\u5efa\u7a33\u5b9a\u6267\u884c\u73af\u5883\u53ca\u4f9d\u8d56\u547d\u4ee4\u56fe\uff0c\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u3001\u4f4e\u6210\u672c\u4e14\u5927\u5e45\u51cf\u5c11\u4eba\u5de5\u53c2\u4e0e\u7684\u8bc4\u4f30\u6d41\u7a0b\u3002", "motivation": "\u73b0\u6709\u5236\u54c1\u8bc4\u4f30\u4f9d\u8d56\u4eba\u5de5\u6267\u884c\u548c\u8c03\u8bd5\uff0c\u968f\u7740\u8bba\u6587\u63d0\u4ea4\u91cf\u4e0a\u5347\uff0c\u4eba\u529b\u6210\u672c\u96be\u4ee5\u627f\u53d7\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6267\u884c\u89c4\u8303\u5316\u7b56\u7565\u548c\u6784\u5efa\u4f9d\u8d56\u611f\u77e5\u7684\u547d\u4ee4\u56fe\uff0c\u5b9e\u73b0\u81ea\u52a8\u73af\u5883\u6784\u5efa\u3001\u6307\u4ee4\u6267\u884c\u548c\u9519\u8bef\u6062\u590d\u7684\u7aef\u5230\u7aef\u4ee3\u7406\u6846\u67b6\u3002", "result": "\u572848\u4e2a\u771f\u5b9e\u5236\u54c1\u6d4b\u8bd5\u4e2d\uff0cArtifactCopilot\u7684\u8868\u73b0\u63a5\u8fd1\u4eba\u5de5\u8bc4\u4f30\uff0c\u51c6\u786e\u7387\u8fbe85.42%\uff0c\u4e14\u5e73\u5747\u6210\u672c\u6781\u4f4e\uff0c\u4e14\u5927\u90e8\u5206\u65e0\u987b\u4eba\u5de5\u5e72\u9884\u3002", "conclusion": "ArtifactCopilot\u6709\u6548\u63d0\u5347\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5236\u54c1\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u6c34\u5e73\uff0c\u5728\u51c6\u786e\u7387\u548c\u6210\u672c\u63a7\u5236\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.00543", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00543", "abs": "https://arxiv.org/abs/2602.00543", "authors": ["Seho Pyo", "Jiheon Seok", "Jaejin Lee"], "title": "Reasoning by Commented Code for Table Question Answering", "comment": null, "summary": "Table Question Answering (TableQA) poses a significant challenge for large language models (LLMs) because conventional linearization of tables often disrupts the two-dimensional relationships intrinsic to structured data. Existing methods, which depend on end-to-end answer generation or single-line program queries, typically exhibit limited numerical accuracy and reduced interpretability. This work introduces a commented, step-by-step code-generation framework that incorporates explicit reasoning into the Python program-generation process. The approach decomposes TableQA reasoning into multi-line executable programs with concise natural language comments, thereby promoting clearer reasoning and increasing the likelihood of generating correct code. On the WikiTableQuestions benchmark, the proposed method achieves 70.9\\% accuracy using Qwen2.5-Coder-7B-Instruct, surpassing the Repanda baseline (67.6\\%). Integrating the proposed framework with a robust end-to-end TableQA model via a lightweight answer-selection mechanism yields further improvements. This combined approach achieves up to 84.3\\% accuracy on the WikiTableQuestions benchmark.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5e26\u6ce8\u91ca\u7684\u591a\u884c\u4ee3\u7801\u751f\u6210\u5f15\u5165\u663e\u5f0f\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u7684\u51c6\u786e\u7387\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u5728WikiTableQuestions\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u8868\u683c\u7ebf\u6027\u5316\u65b9\u6cd5\u7834\u574f\u4e86\u8868\u683c\u7684\u4e8c\u7ef4\u7ed3\u6784\u5173\u7cfb\uff0c\u73b0\u6709\u7aef\u5230\u7aef\u7b54\u6848\u751f\u6210\u6216\u5355\u884c\u7a0b\u5e8f\u67e5\u8be2\u65b9\u6cd5\u51c6\u786e\u7387\u548c\u53ef\u89e3\u91ca\u6027\u8f83\u4f4e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u660e\u786e\u63a8\u7406\u8fc7\u7a0b\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5e26\u6709\u7b80\u6d01\u81ea\u7136\u8bed\u8a00\u6ce8\u91ca\u7684\u591a\u884c\u53ef\u6267\u884cPython\u7a0b\u5e8f\uff0c\u5c06\u8868\u683c\u95ee\u7b54\u63a8\u7406\u8fc7\u7a0b\u89e3\u6784\u4e3a\u4ee3\u7801\u751f\u6210\u6b65\u9aa4\uff0c\u4ece\u800c\u589e\u5f3a\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u4ee3\u7801\u53ef\u89e3\u91ca\u6027\u3002", "result": "\u5728WikiTableQuestions\u57fa\u51c6\u4e0a\uff0c\u4f7f\u7528Qwen2.5-Coder-7B-Instruct\u8fbe\u523070.9%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e67.6%\u7684Repanda\u57fa\u7ebf\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u7b54\u6848\u9009\u62e9\u673a\u5236\u540e\u51c6\u786e\u7387\u63d0\u5347\u81f384.3%\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u5e26\u6ce8\u91ca\u7684\u9010\u6b65\u4ee3\u7801\u751f\u6210\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u8868\u683c\u95ee\u7b54\u4efb\u52a1\u4e2d\u4ee3\u7801\u7684\u6b63\u786e\u7387\u548c\u6a21\u578b\u7684\u6570\u503c\u51c6\u786e\u6027\uff0c\u4e14\u5728WikiTableQuestions\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.02262", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02262", "abs": "https://arxiv.org/abs/2602.02262", "authors": ["Atharv Sonwane", "Eng-Shen Tu", "Wei-Chung Lu", "Claas Beger", "Carter Larsen", "Debjit Dhar", "Rachel Chen", "Ronit Pattanayak", "Tuan Anh Dang", "Guohao Chen", "Gloria Geng", "Kevin Ellis", "Saikat Dutta"], "title": "OmniCode: A Benchmark for Evaluating Software Engineering Agents", "comment": null, "summary": "LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.", "AI": {"tldr": "OmniCode\u662f\u4e00\u4e2a\u9762\u5411\u591a\u8bed\u8a00\u3001\u591a\u4efb\u52a1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\uff0c\u65e8\u5728\u4fc3\u8fdb\u66f4\u5168\u9762\u7684\u7f16\u7801\u667a\u80fd\u4f53\u7814\u53d1\u3002\u73b0\u6709\u667a\u80fd\u4f53\u5728\u90e8\u5206\u4efb\u52a1\u548c\u8bed\u8a00\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u5c55\u73b0\u51fa\u672a\u6765\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684\u7f16\u7801\u57fa\u51c6\u5982HumanEval\u548cSWE-Bench\u4efb\u52a1\u8303\u56f4\u72ed\u7a84\uff0c\u4e0d\u80fd\u5168\u9762\u8bc4\u4f30\u7f16\u7801\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u591a\u6837\u5316\u4efb\u52a1\u80fd\u529b\uff0c\u4e9f\u9700\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u771f\u5b9e\u7684\u57fa\u51c6\u3002", "method": "\u8bbe\u8ba1\u5e76\u6784\u5efa\u4e86\u5305\u542b1794\u4e2a\u4efb\u52a1\u7684OmniCode\u57fa\u51c6\uff0c\u6db5\u76d6Python\u3001Java\u548cC++\u4e09\u79cd\u7f16\u7a0b\u8bed\u8a00\u4ee5\u53ca\u56db\u79cd\u5173\u952e\u4efb\u52a1\u7c7b\u522b\uff08\u7f3a\u9677\u4fee\u590d\u3001\u6d4b\u8bd5\u751f\u6210\u3001\u4ee3\u7801\u5ba1\u67e5\u4fee\u590d\u548c\u98ce\u683c\u4fee\u590d\uff09\uff0c\u4efb\u52a1\u7ecf\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u4e14\u7ed3\u5408\u5408\u6210\u4e0e\u771f\u5b9e\u6570\u636e\u751f\u6210\uff0c\u907f\u514d\u4e86\u6570\u636e\u6cc4\u6f0f\u3002", "result": "\u901a\u8fc7\u5728OmniCode\u4e0a\u8bc4\u4f30\u4e3b\u6d41\u667a\u80fd\u4f53\u6846\u67b6\uff08\u5982SWE-Agent\uff09\uff0c\u53d1\u73b0\u5176\u5728Python\u7f3a\u9677\u4fee\u590d\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u6d4b\u8bd5\u751f\u6210\u4efb\u52a1\u4ee5\u53caJava\u548cC++\u8bed\u8a00\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u4ec5\u4e3a20.9%\u3002", "conclusion": "OmniCode\u4f5c\u4e3a\u4e00\u4e2a\u66f4\u5e7f\u6cdb\u4e14\u591a\u6837\u5316\u7684\u8f6f\u4ef6\u5de5\u7a0b\u57fa\u51c6\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u7f16\u7801\u667a\u80fd\u4f53\u5728\u771f\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u4e0d\u540c\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u63a8\u52a8\u7f16\u7801\u667a\u80fd\u4f53\u7684\u53d1\u5c55\u3002\u73b0\u6709\u667a\u80fd\u4f53\u5728\u67d0\u4e9b\u4efb\u52a1\u548c\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u4ecd\u6709\u9650\u3002"}}
{"id": "2602.00554", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00554", "abs": "https://arxiv.org/abs/2602.00554", "authors": ["Liu Kaipeng", "Wu Ling"], "title": "A Hierarchical and Attentional Analysis of Argument Structure Constructions in BERT Using Naturalistic Corpora", "comment": "14 pages, 5 figures", "summary": "This study investigates how the Bidirectional Encoder Representations from Transformers model processes four fundamental Argument Structure Constructions. We employ a multi-dimensional analytical framework, which integrates MDS, t-SNE as dimensionality reduction, Generalized Discrimination Value (GDV) as cluster separation metrics, Fisher Discriminant Ratio (FDR) as linear diagnostic probing, and attention mechanism analysis. Our results reveal a hierarchical representational structure. Construction-specific information emerges in early layers, forms maximally separable clusters in middle layers, and is maintained through later processing stages.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u591a\u79cd\u5206\u6790\u5de5\u5177\u63ed\u793a\u4e86BERT\u6a21\u578b\u5904\u7406\u56db\u79cd\u8bed\u4e49\u6784\u9020\u65f6\u7684\u5c42\u7ea7\u5316\u8868\u5f81\u7279\u70b9\uff0c\u5c55\u73b0\u51fa\u7ed3\u6784\u5316\u7684\u4fe1\u606f\u53d1\u5c55\u8fc7\u7a0b\u3002", "motivation": "\u63a2\u7d22BERT\u6a21\u578b\u5982\u4f55\u5904\u7406\u57fa\u672c\u7684\u8bed\u4e49\u7ed3\u6784\u6784\u9020\uff0c\u7406\u89e3\u5176\u5185\u90e8\u8868\u5f81\u53ca\u4fe1\u606f\u6d41\u52a8\u673a\u5236\u3002", "method": "\u91c7\u7528\u591a\u7ef4\u5206\u6790\u6846\u67b6\uff0c\u7ed3\u5408MDS\u3001t-SNE\u964d\u7ef4\u65b9\u6cd5\uff0cGDV\u805a\u7c7b\u5206\u79bb\u5ea6\u6307\u6807\uff0cFDR\u7ebf\u6027\u5224\u522b\u63a2\u6d4b\uff0c\u53ca\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u3002", "result": "\u53d1\u73b0\u6784\u9020\u7279\u5b9a\u4fe1\u606f\u5728\u6a21\u578b\u7684\u65e9\u671f\u5c42\u6b21\u521d\u73b0\uff0c\u4e2d\u95f4\u5c42\u5f62\u6210\u6700\u53ef\u5206\u79bb\u7684\u805a\u7c7b\uff0c\u665a\u671f\u5c42\u6b21\u4fdd\u6301\u4fe1\u606f\u5b8c\u6574\u3002", "conclusion": "Bidirectional Encoder Representations from Transformers\u6a21\u578b\u5728\u5904\u7406\u57fa\u672c\u8bed\u4e49\u6784\u9020\u65f6\u5c55\u73b0\u51fa\u5c42\u7ea7\u5f0f\u7684\u8868\u5f81\u7ed3\u6784\uff0c\u8bed\u4e49\u7279\u5b9a\u4fe1\u606f\u5728\u4e2d\u95f4\u5c42\u8fbe\u5230\u6700\u5927\u53ef\u533a\u5206\u6027\uff0c\u5e76\u5728\u540e\u7eed\u5c42\u6b21\u4fdd\u6301\u3002"}}
{"id": "2602.02280", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02280", "abs": "https://arxiv.org/abs/2602.02280", "authors": ["Zeming Wei", "Zhixin Zhang", "Chengcan Wu", "Yihao Zhang", "Xiaokun Luan", "Meng Sun"], "title": "RACA: Representation-Aware Coverage Criteria for LLM Safety Testing", "comment": null, "summary": "Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRACA\u6846\u67b6\uff0c\u901a\u8fc7\u5b89\u5168\u5173\u952e\u6982\u5ff5\u7684\u8986\u76d6\u51c6\u5219\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6d4b\u8bd5\u7684\u6709\u6548\u6027\u4e0e\u7cfb\u7edf\u6027\uff0c\u6210\u529f\u8bc6\u522b\u9ad8\u5371\u7ed5\u8fc7\u653b\u51fb\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6d4b\u8bd5\u4f9d\u8d56\u9759\u6001\u6570\u636e\u96c6\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u8d28\u91cf\u548c\u5145\u5206\u6027\u8bc4\u4f30\u51c6\u5219\uff0c\u800c\u73b0\u6709\u8986\u76d6\u51c6\u5219\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u89c4\u6a21\u5e9e\u5927\u4e14\u76ee\u6807\u4e0d\u540c\u7684LLM\u3002", "method": "\u901a\u8fc7\u8868\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u9009\u53d6\u5b89\u5168\u5173\u952e\u6982\u5ff5\uff0c\u4ee5\u4e13\u5bb6\u6821\u51c6\u7684\u7ed5\u8fc7\u63d0\u793a\u96c6\u5408\u4e3a\u57fa\u7840\u8ba1\u7b97\u6982\u5ff5\u6fc0\u6d3b\u5206\u6570\uff0c\u5e76\u7ed3\u5408\u516d\u4e2a\u5b50\u51c6\u5219\u8bc4\u4f30\u6d4b\u8bd5\u96c6\u7684\u8986\u76d6\u7387\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eRACA\u80fd\u591f\u6709\u6548\u8bc6\u522b\u9ad8\u8d28\u91cf\u7ed5\u8fc7\u653b\u51fb\u63d0\u793a\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4e14\u5728\u5b9e\u9645\u573a\u666f\uff08\u5982\u6d4b\u8bd5\u96c6\u4f18\u5148\u7ea7\u548c\u653b\u51fb\u63d0\u793a\u91c7\u6837\uff09\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\uff0c\u4e14\u65b9\u6cd5\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "RACA\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u6d4b\u8bd5\u7684\u65b0\u8986\u76d6\u51c6\u5219\uff0c\u80fd\u591f\u9ad8\u6548\u8bc6\u522b\u548c\u8bc4\u4f30\u7ed5\u8fc7\u653b\u51fb\u63d0\u793a\uff0c\u4f18\u4e8e\u4f20\u7edf\u795e\u7ecf\u5143\u6c34\u5e73\u51c6\u5219\uff0c\u5e76\u5177\u5907\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00588", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00588", "abs": "https://arxiv.org/abs/2602.00588", "authors": ["Thiago Dumont Oliveira"], "title": "The French Drama Revolution: Political Economy and Literary Production, 1700-1900", "comment": null, "summary": "This paper investigates the changing nature of French drama between 1700-1900 using Latent Dirichlet Allocation and Jensen-Shannon Divergence. Results indicate that the topical distribution of French drama changed profoundly after the French Revolution, particularly between 1789 and 1850. Bourgeois themes emerged among the most prevalent topics since the late 18th century. To assess the coevolution of drama and economic growth, I plot the yearly prevalence of topics alongside French GDP between 1700-1900, and discuss these changes in light of the political and economic changes prompted by the French Revolution and the industrialization of the country.", "AI": {"tldr": "\u672c\u6587\u7528\u4e3b\u9898\u6a21\u578b\u5206\u6790\u6cd5\u56fd1700-1900\u5e74\u620f\u5267\u4e3b\u9898\u53d8\u5316\uff0c\u53d1\u73b0\u5927\u9769\u547d\u540e\u8d44\u4ea7\u9636\u7ea7\u4e3b\u9898\u5d1b\u8d77\uff0c\u4e14\u620f\u5267\u4e3b\u9898\u6f14\u53d8\u4e0e\u7ecf\u6d4e\u589e\u957f\u5bc6\u5207\u76f8\u5173\u3002", "motivation": "\u63a2\u7a761700-1900\u5e74\u95f4\u6cd5\u56fd\u620f\u5267\u4e3b\u9898\u7684\u6f14\u53d8\u53ca\u5176\u4e0e\u7ecf\u6d4e\u589e\u957f\u7684\u5173\u7cfb\u3002", "method": "\u91c7\u7528\u6f5c\u5728\u72c4\u5229\u514b\u96f7\u5206\u914d\uff08LDA\uff09\u548c\u8a79\u68ee-\u9999\u519c\u6563\u5ea6\uff08Jensen-Shannon Divergence\uff09\u5206\u67901700-1900\u5e74\u6cd5\u56fd\u620f\u5267\u4e3b\u9898\u7684\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u6cd5\u56fd\u5927\u9769\u547d\u540e\u620f\u5267\u4e3b\u9898\u663e\u8457\u53d8\u5316\uff0c\u8d44\u4ea7\u9636\u7ea7\u4e3b\u9898\u5174\u8d77\uff0c\u5e76\u901a\u8fc7\u5c06\u4e3b\u9898\u51fa\u73b0\u9891\u7387\u4e0eGDP\u5e74\u4efd\u6570\u636e\u5bf9\u6bd4\uff0c\u63ed\u793a\u620f\u5267\u4e0e\u7ecf\u6d4e\u53d1\u5c55\u7684\u5171\u540c\u6f14\u5316\u3002", "conclusion": "\u6cd5\u56fd\u5927\u9769\u547d\u540e\uff0c\u5c24\u5176\u662f1789\u5e74\u81f31850\u5e74\u95f4\uff0c\u6cd5\u56fd\u620f\u5267\u7684\u4e3b\u9898\u5206\u5e03\u53d1\u751f\u4e86\u6df1\u523b\u53d8\u5316\uff0c\u8d44\u4ea7\u9636\u7ea7\u4e3b\u9898\u6210\u4e3a\u4e3b\u8981\u8bdd\u9898\u4e4b\u4e00\uff0c\u8fd9\u53cd\u6620\u4e86\u653f\u6cbb\u548c\u7ecf\u6d4e\u73af\u5883\u7684\u8f6c\u578b\u3002"}}
{"id": "2602.02293", "categories": ["cs.SE", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.02293", "abs": "https://arxiv.org/abs/2602.02293", "authors": ["Nils Chur", "Thiago Santos de Moura", "Argentina Ortega", "Sven Peldszus", "Thorsten Berger", "Nico Hochgeschwender", "Yannic Noller"], "title": "Before Autonomy Takes Control: Software Testing in Robotics", "comment": null, "summary": "Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u590d\u6742\u6027\uff0c\u7ed3\u5408\u8f6f\u4ef6\u6d4b\u8bd5\u7406\u8bba\u5bf9247\u7bc7\u76f8\u5173\u8bba\u6587\u8fdb\u884c\u4e86\u6620\u5c04\u7814\u7a76\uff0c\u5206\u6790\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u5e76\u603b\u7ed3\u4e86\u5173\u952e\u95ee\u9898\u4e0e\u7ecf\u9a8c\uff0c\u6307\u5bfc\u673a\u5668\u4eba\u548c\u8f6f\u4ef6\u5de5\u7a0b\u793e\u533a\u66f4\u597d\u5730\u5f00\u5c55\u6d4b\u8bd5\u7814\u7a76\u3002", "motivation": "\u673a\u5668\u4eba\u7cfb\u7edf\u590d\u6742\u4e14\u5b89\u5168\u5173\u952e\uff0c\u6d4b\u8bd5\u96be\u5ea6\u5927\u4e14\u73af\u5883\u4e0d\u786e\u5b9a\uff0c\u4e9f\u9700\u7cfb\u7edf\u603b\u7ed3\u73b0\u6709\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5bf9247\u7bc7\u673a\u5668\u4eba\u6d4b\u8bd5\u8bba\u6587\u8fdb\u884c\u6620\u5c04\u7814\u7a76\uff0c\u5173\u8054\u8f6f\u4ef6\u6d4b\u8bd5\u7406\u8bba\u8fdb\u884c\u5206\u6790\u3002", "result": "\u5398\u6e05\u4e86\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u73b0\u72b6\u3001\u6311\u6218\uff0c\u5e76\u901a\u8fc7\u793a\u4f8b\u8bf4\u660e\uff0c\u63d0\u51fa\u5f00\u653e\u95ee\u9898\u548c\u7ecf\u9a8c\u6559\u8bad\u3002", "conclusion": "\u673a\u5668\u4eba\u8f6f\u4ef6\u6d4b\u8bd5\u5177\u6709\u6311\u6218\u6027\uff0c\u9700\u8981\u7ed3\u5408\u8f6f\u4ef6\u6d4b\u8bd5\u7406\u8bba\u8fdb\u884c\u7cfb\u7edf\u6027\u7814\u7a76\u3002"}}
{"id": "2602.00594", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.00594", "abs": "https://arxiv.org/abs/2602.00594", "authors": ["Zhijie Huang", "Stephen McIntosh", "Daisuke Saito", "Nobuaki Minematsu"], "title": "Kanade: A Simple Disentangled Tokenizer for Spoken Language Modeling", "comment": null, "summary": "A good language model starts with a good tokenizer. Tokenization is especially important for speech modeling, which must handle continuous signals that mix linguistic and non-linguistic information. A speech tokenizer should extract phonetics and prosody, suppress linguistically irrelevant information like speaker identity, and enable high-quality synthesis. We present Kanade, a single-layer disentangled speech tokenizer that realizes this ideal. Kanade separates out acoustic constants to create a single stream of tokens that captures rich phonetics and prosody. It does so without the need for auxiliary methods that existing disentangled codecs often rely on. Experiments show that Kanade achieves state-of-the-art speaker disentanglement and lexical availability, while maintaining excellent reconstruction quality.", "AI": {"tldr": "Kanade\u662f\u4e00\u79cd\u5355\u5c42\u89e3\u8026\u7684\u8bed\u97f3\u5206\u8bcd\u5668\uff0c\u80fd\u6709\u6548\u63d0\u53d6\u8bed\u97f3\u548c\u97f5\u5f8b\u7279\u5f81\uff0c\u6291\u5236\u65e0\u5173\u4fe1\u606f\uff0c\u5b9e\u73b0\u9ad8\u8d28\u91cf\u8bed\u97f3\u5408\u6210\u548c\u8bf4\u8bdd\u8005\u89e3\u8026\u3002", "motivation": "\u8bed\u97f3\u5efa\u6a21\u9700\u8981\u5904\u7406\u6df7\u5408\u4e86\u8bed\u8a00\u548c\u975e\u8bed\u8a00\u4fe1\u606f\u7684\u8fde\u7eed\u4fe1\u53f7\uff0c\u4f20\u7edf\u7684\u5206\u8bcd\u5668\u96be\u4ee5\u5728\u63d0\u53d6\u8bed\u97f3\u7279\u5f81\u540c\u65f6\u6291\u5236\u65e0\u5173\u4fe1\u606f\uff0c\u5982\u8bf4\u8bdd\u8005\u8eab\u4efd\u3002", "method": "\u63d0\u51faKanade\uff0c\u4e00\u79cd\u5355\u5c42\u7684\u89e3\u8026\u8bed\u97f3\u5206\u8bcd\u5668\uff0c\u901a\u8fc7\u5206\u79bb\u58f0\u5b66\u5e38\u6570\u5f62\u6210\u5355\u4e00\u7684\u4ee4\u724c\u6d41\uff0c\u6355\u6349\u4e30\u5bcc\u7684\u8bed\u97f3\u548c\u97f5\u5f8b\u7279\u5f81\uff0c\u65e0\u9700\u4f20\u7edf\u8f85\u52a9\u6280\u672f\u3002", "result": "Kanade\u5b9e\u73b0\u4e86\u4e1a\u754c\u9886\u5148\u7684\u8bf4\u8bdd\u8005\u89e3\u8026\u548c\u8bcd\u6c47\u53ef\u7528\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f18\u5f02\u7684\u8bed\u97f3\u91cd\u6784\u8d28\u91cf\u3002", "conclusion": "Kanade\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u8bed\u97f3\u5206\u8bcd\u5668\uff0c\u6781\u5927\u63d0\u5347\u4e86\u8bed\u97f3\u6a21\u578b\u7684\u7279\u5f81\u63d0\u53d6\u8d28\u91cf\u548c\u5408\u6210\u6548\u679c\uff0c\u5bf9\u4e8e\u8bed\u97f3\u6280\u672f\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2602.02307", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02307", "abs": "https://arxiv.org/abs/2602.02307", "authors": ["Wenhao Ge", "Chen Zhang"], "title": "Understanding and Detecting Flaky Builds in GitHub Actions", "comment": "18 pages, 1 figures, 4 tables", "summary": "Continuous Integration (CI) is widely used to provide rapid feedback on code changes; however, CI build outcomes are not always reliable. Builds may fail intermittently due to non-deterministic factors, leading to flaky builds that undermine developers' trust in CI, waste computational resources, and threaten the validity of CI-related empirical studies. In this paper, we present a large-scale empirical study of flaky builds in GitHub Actions based on rerun data from 1,960 open-source Java projects. Our results show that 3.2% of builds are rerun, and 67.73% of these rerun builds exhibit flaky behavior, affecting 1,055 (51.28%) of the projects. Through an in-depth failure analysis, we identify 15 distinct categories of flaky failures, among which flaky tests, network issues, and dependency resolution issues are the most prevalent. Building on these findings, we propose a machine learning-based approach for detecting flaky failures at the job level. Compared with a state-of-the-art baseline, our approach improves the F1-score by up to 20.3%.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u5206\u6790\u4e86GitHub Actions\u4e2dflaky\u6784\u5efa\u95ee\u9898\uff0c\u5b9a\u4e49\u5931\u6548\u7c7b\u578b\uff0c\u5e76\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\uff0c\u589e\u5f3aCI\u7684\u53ef\u4fe1\u5ea6\u548c\u6548\u7387\u3002", "motivation": "CI\u6784\u5efa\u7ed3\u679c\u65f6\u5e38\u4e0d\u53ef\u9760\uff0c\u95f4\u6b47\u6027\u5931\u8d25\u5f71\u54cd\u5f00\u53d1\u8005\u5bf9CI\u7684\u4fe1\u4efb\uff0c\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u5e76\u5a01\u80c1CI\u76f8\u5173\u5b9e\u8bc1\u7814\u7a76\u7684\u6709\u6548\u6027\u3002", "method": "\u57fa\u4e8e1,960\u4e2aJava\u5f00\u6e90\u9879\u76ee\u7684\u91cd\u8fd0\u884c\u6570\u636e\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\uff0c\u8bc6\u522b15\u7c7bflaky\u5931\u8d25\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684flaky\u5931\u8d25\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "3.2%\u7684\u6784\u5efa\u88ab\u91cd\u8fd0\u884c\uff0c\u5176\u4e2d67.73%\u7684\u91cd\u8fd0\u884c\u6784\u5efa\u8868\u73b0\u51faflaky\u884c\u4e3a\uff0c\u6d89\u53ca51.28%\u7684\u9879\u76ee\u3002\u63d0\u51fa\u7684\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u65b9\u6cd5\u5c06F1\u5206\u6570\u63d0\u9ad8\u4e86\u6700\u591a20.3%\u3002", "conclusion": "GitHub Actions\u4e2d\u7684CI\u6784\u5efa\u5b58\u5728\u8f83\u9ad8\u6bd4\u4f8b\u7684flaky\u5931\u8d25\uff0c\u4e3b\u8981\u5305\u62ec\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u3001\u7f51\u7edc\u95ee\u9898\u548c\u4f9d\u8d56\u89e3\u6790\u95ee\u9898\uff0c\u5f71\u54cd\u4e86\u8d85\u8fc7\u534a\u6570\u7684\u9879\u76ee\u3002"}}
{"id": "2602.00597", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00597", "abs": "https://arxiv.org/abs/2602.00597", "authors": ["Chaoqun Cui", "Shijing Wang", "Liangbin Huang", "Qingqing Gu", "Zhaolong Huang", "Xiao Zeng", "Wenji Mao"], "title": "Hermes the Polyglot: A Unified Framework to Enhance Expressiveness for Multimodal Interlingual Subtitling", "comment": "Accepted to The Web Conference (WWW) 2026", "summary": "Interlingual subtitling, which translates subtitles of visual media into a target language, is essential for entertainment localization but has not yet been explored in machine translation. Although Large Language Models (LLMs) have significantly advanced the general capabilities of machine translation, the distinctive characteristics of subtitle texts pose persistent challenges in interlingual subtitling, particularly regarding semantic coherence, pronoun and terminology translation, and translation expressiveness. To address these issues, we present Hermes, an LLM-based automated subtitling framework. Hermes integrates three modules: Speaker Diarization, Terminology Identification, and Expressiveness Enhancement, which effectively tackle the above challenges. Experiments demonstrate that Hermes achieves state-of-the-art diarization performance and generates expressive, contextually coherent translations, thereby advancing research in interlingual subtitling.", "AI": {"tldr": "\u9488\u5bf9\u8de8\u8bed\u8a00\u5b57\u5e55\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684Hermes\u6846\u67b6\uff0c\u901a\u8fc7\u4e09\u5927\u6a21\u5757\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u6027\u80fd\u548c\u8868\u8fbe\u6548\u679c\u3002", "motivation": "\u8de8\u8bed\u8a00\u5b57\u5e55\u7ffb\u8bd1\u5728\u5a31\u4e50\u672c\u5730\u5316\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u673a\u5668\u7ffb\u8bd1\u4e2d\u4ecd\u5b58\u5728\u8bed\u4e49\u8fde\u8d2f\u3001\u4ee3\u8bcd\u53ca\u672f\u8bed\u7ffb\u8bd1\u51c6\u786e\u6027\u548c\u7ffb\u8bd1\u8868\u8fbe\u6027\u7b49\u96be\u9898\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5b57\u5e55\u7ffb\u8bd1\u6846\u67b6Hermes\uff0c\u96c6\u6210\u4e86\u8bf4\u8bdd\u4eba\u5206\u79bb(Speaker Diarization)\u3001\u672f\u8bed\u8bc6\u522b(Terminology Identification)\u3001\u8868\u8fbe\u6027\u589e\u5f3a(Expressiveness Enhancement)\u4e09\u4e2a\u6a21\u5757\u3002", "result": "Hermes\u5728\u8bf4\u8bdd\u4eba\u5206\u79bb\u4efb\u52a1\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5e76\u751f\u6210\u4e86\u5bcc\u6709\u8868\u73b0\u529b\u4e14\u4e0a\u4e0b\u6587\u8fde\u8d2f\u7684\u5b57\u5e55\u8bd1\u6587\uff0c\u63a8\u52a8\u4e86\u8de8\u8bed\u8a00\u5b57\u5e55\u7ffb\u8bd1\u7814\u7a76\u7684\u53d1\u5c55\u3002", "conclusion": "Hermes\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u8bed\u8a00\u5b57\u5e55\u7ffb\u8bd1\u4e2d\u7684\u8bed\u4e49\u8fde\u8d2f\u6027\u3001\u4ee3\u8bcd\u4e0e\u672f\u8bed\u7ffb\u8bd1\u4ee5\u53ca\u7ffb\u8bd1\u8868\u8fbe\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u8bf4\u8bdd\u4eba diarization \u4ee5\u53ca\u751f\u6210\u5bcc\u6709\u8868\u73b0\u529b\u548c\u4e0a\u4e0b\u6587\u8fde\u8d2f\u7684\u7ffb\u8bd1\u3002"}}
{"id": "2602.02345", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02345", "abs": "https://arxiv.org/abs/2602.02345", "authors": ["Shojibur Rahman", "Md Fazle Rabbi", "Minhaz Zibran"], "title": "A Task-Level Evaluation of AI Agents in Open-Source Projects", "comment": "5 pages, accepted at MSR Mining Challenge 2026", "summary": "In this paper, we present a comparative study of five autonomous coding agents using AIDev-pop, which is a public dataset containing thousands of AI-generated pull requests (PRs) across popular open-source repositories. We evaluate agents' performance along three task-aware dimensions spanning the PR lifecycle: (1) PR acceptance rate, (2) review discussion volume, and (3) commit message quality. Our quantitative analysis finds that Codex consistently achieves high PR acceptance rates across most task categories, while Copilot's PRs trigger the highest volume of both human and automated review discussions. In contrast, commit-level quality varies independently of acceptance outcomes. Claude and Cursor produce higher proportions of high-quality commit messages across several task types, and Codex exhibiting comparatively lower commit quality despite strong integration outcomes. Our findings inform selection and improvements of AI agents for their effective integration to collaborative software engineering.", "AI": {"tldr": "\u901a\u8fc7\u8bc4\u4f30\u4e94\u4e2aAI\u7f16\u7801\u4ee3\u7406\u5728\u771f\u5b9e\u5f00\u6e90\u9879\u76ee\u4e2d\u7684\u62c9\u53d6\u8bf7\u6c42\u63a5\u53d7\u7387\u3001\u8bc4\u5ba1\u8ba8\u8bba\u91cf\u548c\u63d0\u4ea4\u4fe1\u606f\u8d28\u91cf\uff0c\u53d1\u73b0\u5404\u4ee3\u7406\u5728\u4e0d\u540c\u6307\u6807\u4e0a\u5404\u6709\u4f18\u52bf\uff0c\u4e3a\u4f18\u5316AI\u8f85\u52a9\u8f6f\u4ef6\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u53c2\u8003\u3002", "motivation": "\u63a2\u7a76\u4e0d\u540c\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u5728\u5f00\u6e90\u8f6f\u4ef6\u534f\u4f5c\u73af\u5883\u4e2d\u7684\u5b9e\u9645\u8868\u73b0\u5dee\u5f02\uff0c\u5e2e\u52a9\u9009\u62e9\u548c\u6539\u8fdbAI\u4ee3\u7406\u4ee5\u66f4\u9ad8\u6548\u5730\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u534f\u4f5c\u3002", "method": "\u5229\u7528\u516c\u5f00\u7684AIDev-pop\u6570\u636e\u96c6\uff0c\u8986\u76d6\u591a\u4e2a\u6d41\u884c\u5f00\u6e90\u5e93\u4e2d\u6570\u5343\u6761AI\u751f\u6210\u7684\u62c9\u53d6\u8bf7\u6c42\uff0c\u57fa\u4e8e\u62c9\u53d6\u8bf7\u6c42\u751f\u547d\u5468\u671f\u7684\u4e09\u4e2a\u7ef4\u5ea6\uff08\u63a5\u53d7\u7387\u3001\u8bc4\u5ba1\u8ba8\u8bba\u91cf\u3001\u63d0\u4ea4\u4fe1\u606f\u8d28\u91cf\uff09\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "Codex\u5728\u5927\u591a\u6570\u4efb\u52a1\u7c7b\u522b\u4e2d\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u62c9\u53d6\u8bf7\u6c42\u63a5\u53d7\u7387\uff1bCopilot\u751f\u6210\u7684\u62c9\u53d6\u8bf7\u6c42\u6fc0\u53d1\u4e86\u6700\u591a\u7684\u4eba\u7c7b\u548c\u81ea\u52a8\u8bc4\u5ba1\u8ba8\u8bba\uff1bClaude\u548cCursor\u5728\u591a\u4e2a\u4efb\u52a1\u7c7b\u578b\u4e0a\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6bd4\u4f8b\u7684\u9ad8\u8d28\u91cf\u63d0\u4ea4\u4fe1\u606f\uff0c\u800cCodex\u5728\u63d0\u4ea4\u4fe1\u606f\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u8f83\u4f4e\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7AIDev-pop\u6570\u636e\u96c6\u5bf9\u4e94\u4e2a\u81ea\u4e3b\u7f16\u7801\u4ee3\u7406\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u53d1\u73b0\u4e0d\u540c\u4ee3\u7406\u5728\u62c9\u53d6\u8bf7\u6c42\u7684\u63a5\u53d7\u7387\u3001\u8bc4\u5ba1\u8ba8\u8bba\u6570\u91cf\u548c\u63d0\u4ea4\u4fe1\u606f\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u5404\u5f02\uff0cCodex\u63a5\u53d7\u7387\u6700\u9ad8\uff0cCopilot\u5f15\u53d1\u6700\u591a\u8ba8\u8bba\uff0cClaude\u548cCursor\u5728\u63d0\u4ea4\u4fe1\u606f\u8d28\u91cf\u4e0a\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.00612", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00612", "abs": "https://arxiv.org/abs/2602.00612", "authors": ["Yitong Zhang", "Yongmin Li", "Yuetong Liu", "Jia Li", "Xiaoran Jia", "Zherui Li", "Ge Li"], "title": "Lookahead-then-Verify: Reliable Constrained Decoding for Diffusion LLMs under Context-Free Grammars", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have demonstrated promising generative capabilities and are increasingly used to produce formal languages defined by context-free grammars, such as source code and chemical expressions. However, as probabilistic models, they still struggle to generate syntactically valid outputs reliably. A natural and promising direction to address this issue is to adapt constrained decoding techniques to enforce grammatical correctness during generation. However, applying these techniques faces two primary obstacles. On the one hand, the non-autoregressive nature of dLLMs renders most existing constrained decoding approaches inapplicable. On the other hand, current approaches specifically designed for dLLMs may allow intermediate outputs that are impossible to complete into valid sentences, which significantly limits their reliability in practice.\n  To address these challenges, we present LAVE, a constrained decoding approach specifically designed for dLLMs. Our approach leverages a key property of dLLMs, namely their ability to predict token distributions for all positions in parallel during each forward pass. Whenever a new token is proposed by model, LAVE performs lookahead using these distributions to efficiently and reliably verify the validity of the proposed token. This design ensures reliable constraints by reliably preserving the potential for intermediate outputs to be extended into valid sentences. Extensive experiments across four widely used dLLMs and three representative benchmarks demonstrate that LAVE consistently outperforms existing baselines and achieves substantial improvements in syntactic correctness, while incurring negligible runtime overhead.", "AI": {"tldr": "\u9488\u5bf9\u6269\u6563\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7b26\u53f7\u8bed\u8a00\u65f6\u8bed\u6cd5\u9519\u8bef\u9891\u53d1\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8etoken\u5206\u5e03\u7684\u5e76\u884c\u524d\u77bb\u53d7\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5LAVE\uff0c\u6709\u6548\u63d0\u5347\u4e86\u751f\u6210\u8bed\u6cd5\u6b63\u786e\u6027\u4e14\u65e0\u663e\u8457\u6027\u80fd\u635f\u5931\u3002", "motivation": "dLLMs\u4f5c\u4e3a\u6982\u7387\u6a21\u578b\u5728\u751f\u6210\u8bed\u6cd5\u5f62\u5f0f\u53d7\u9650\u7684\u8bed\u8a00\u65f6\uff0c\u6613\u751f\u6210\u8bed\u6cd5\u4e0d\u5408\u6cd5\u7684\u8f93\u51fa\uff1b\u73b0\u6709\u53d7\u7ea6\u675f\u89e3\u7801\u65b9\u6cd5\u96be\u4ee5\u9002\u5e94dLLMs\u7684\u975e\u81ea\u56de\u5f52\u7279\u6027\uff0c\u4e14\u53ef\u80fd\u5bfc\u81f4\u65e0\u6cd5\u6269\u5c55\u4e3a\u5408\u6cd5\u53e5\u5b50\u7684\u4e2d\u95f4\u7ed3\u679c\u3002", "method": "LAVE\u65b9\u6cd5\u5229\u7528dLLMs\u5728\u6bcf\u6b21\u524d\u5411\u4f20\u64ad\u4e2d\u5e76\u884c\u9884\u6d4b\u6240\u6709\u4f4d\u7f6e\u7684token\u5206\u5e03\uff0c\u7ed3\u5408\u524d\u77bb\u673a\u5236\u5bf9\u63d0\u51fa\u7684token\u8fdb\u884c\u6709\u6548\u9a8c\u8bc1\uff0c\u786e\u4fdd\u751f\u6210\u8fc7\u7a0b\u4e2d\u8bed\u6cd5\u7ea6\u675f\u7684\u53ef\u9760\u6267\u884c\u3002", "result": "\u5728\u56db\u4e2a\u4e3b\u6d41dLLMs\u548c\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLAVE\u5728\u8bed\u6cd5\u6b63\u786e\u6027\u4e0a\u6301\u7eed\u4f18\u4e8e\u5df2\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u8fd0\u884c\u65f6\u95f4\u5f00\u9500\u51e0\u4e4e\u53ef\u4ee5\u5ffd\u7565\u3002", "conclusion": "\u63d0\u51fa\u7684LAVE\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6269\u6563\u5927\u578b\u8bed\u8a00\u6a21\u578b(dLLMs)\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u8bed\u6cd5\u6b63\u786e\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u5185\u5bb9\u7684\u8bed\u6cd5\u6b63\u786e\u7387\u4e14\u4ee3\u4ef7\u4f4e\u5ec9\u3002"}}
{"id": "2602.02361", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02361", "abs": "https://arxiv.org/abs/2602.02361", "authors": ["Mouxiang Chen", "Lei Zhang", "Yunlong Feng", "Xuwu Wang", "Wenting Zhao", "Ruisheng Cao", "Jiaxi Yang", "Jiawei Chen", "Mingze Li", "Zeyao Ma", "Hao Ge", "Zongmeng Zhang", "Zeyu Cui", "Dayiheng Liu", "Jingren Zhou", "Jianling Sun", "Junyang Lin", "Binyuan Hui"], "title": "SWE-Universe: Scale Real-World Verifiable Environments to Millions", "comment": "13 pages", "summary": "We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SWE-Universe\uff0c\u4e00\u79cd\u4eceGitHub PR\u81ea\u52a8\u6784\u5efa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u8f6f\u4ef6\u5de5\u7a0b\u9a8c\u8bc1\u73af\u5883\u7684\u9ad8\u6548\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u73af\u5883\u6784\u5efa\u8d28\u91cf\u548c\u89c4\u6a21\uff0c\u5e76\u63a8\u52a8\u4e86\u7f16\u7801\u667a\u80fd\u4f53\u6027\u80fd\u7684\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u6784\u5efa\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u5de5\u7a0b\u9a8c\u8bc1\u73af\u5883\u9762\u4e34\u4ea7\u91cf\u4f4e\u3001\u9a8c\u8bc1\u80fd\u529b\u5f31\u548c\u6210\u672c\u9ad8\u6602\u7b49\u8bf8\u591a\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\u6765\u751f\u6210\u5927\u91cf\u53ef\u9760\u7684SWE\u73af\u5883\u4f9b\u667a\u80fd\u4f53\u8bad\u7ec3\u4f7f\u7528\u3002", "method": "SWE-Universe\u6846\u67b6\u5229\u7528\u4e00\u4e2a\u9ad8\u6548\u7684\u5b9a\u5236\u8bad\u7ec3\u6a21\u578b\u9a71\u52a8\u7684\u6784\u5efa\u4ee3\u7406\uff0c\u901a\u8fc7\u8fed\u4ee3\u81ea\u6211\u9a8c\u8bc1\u548c\u5faa\u73af\u9ed1\u5ba2\u68c0\u6d4b\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u4efb\u52a1\u7684\u53ef\u9760\u751f\u6210\uff0c\u4ece\u800c\u89e3\u51b3\u81ea\u52a8\u6784\u5efa\u4e2d\u4ea7\u91cf\u4f4e\u3001\u9a8c\u8bc1\u8584\u5f31\u53ca\u6210\u672c\u9ad8\u6602\u7684\u95ee\u9898\u3002", "result": "\u57fa\u4e8e\u8be5\u65b9\u6cd5\uff0c\u6210\u529f\u6784\u5efa\u4e86\u8d85\u8fc780\u4e07\uff08807,693\u4e2a\uff09\u591a\u8bed\u8a00\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\uff0c\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u667a\u80fd\u4f53\u4e2d\u671f\u8bad\u7ec3\u548c\u5f3a\u5316\u5b66\u4e60\u9a8c\u8bc1\u4e86\u73af\u5883\u7684\u4ef7\u503c\uff0c\u6700\u7ec8\u5728SWE-Bench Verified\u6d4b\u8bd5\u4e2d\u5b9e\u73b075.3%\u7684\u9ad8\u5206\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684SWE-Universe\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u4eceGitHub\u62c9\u53d6\u8bf7\u6c42\u4e2d\u81ea\u52a8\u6784\u5efa\u5927\u89c4\u6a21\u3001\u9ad8\u4fdd\u771f\u3001\u53ef\u9a8c\u8bc1\u7684\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u6784\u5efa\u7684\u751f\u4ea7\u6548\u7387\u548c\u9a8c\u8bc1\u53ef\u9760\u6027\uff0c\u5e76\u5728\u63d0\u5347\u7f16\u7801\u667a\u80fd\u4f53\u6027\u80fd\u65b9\u9762\u8868\u73b0\u51fa\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.00613", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00613", "abs": "https://arxiv.org/abs/2602.00613", "authors": ["Nsrin Ashraf", "Mariam Labib", "Hamada Nayel"], "title": "Transformer-Based Model for Multilingual Hope Speech Detection", "comment": "5 pages, 1 figure, PolyHope-M shared task at RANLP2025", "summary": "This paper describes a system that has been submitted to the \"PolyHope-M\" at RANLP2025. In this work various transformers have been implemented and evaluated for hope speech detection for English and Germany. RoBERTa has been implemented for English, while the multilingual model XLM-RoBERTa has been implemented for both English and German languages. The proposed system using RoBERTa reported a weighted f1-score of 0.818 and an accuracy of 81.8% for English. On the other hand, XLM-RoBERTa achieved a weighted f1-score of 0.786 and an accuracy of 78.5%. These results reflects the importance of improvement of pre-trained large language models and how these models enhancing the performance of different natural language processing tasks.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7RoBERTa\u548cXLM-RoBERTa\u6a21\u578b\u9488\u5bf9\u82f1\u8bed\u548c\u5fb7\u8bed\u7684\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u4efb\u52a1\u8fdb\u884c\u4e86\u5b9e\u8bc1\uff0c\u8bc1\u660e\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u63d0\u5347\u6027\u80fd\u7684\u6709\u6548\u6027\u3002", "motivation": "\u63d0\u5347\u591a\u8bed\u8a00\uff08\u82f1\u8bed\u548c\u5fb7\u8bed\uff09\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u7684\u6027\u80fd\u3002", "method": "\u5b9e\u73b0\u4e86\u591a\u79cdtransformer\u6a21\u578b\uff0c\u9488\u5bf9\u82f1\u8bed\u4f7f\u7528RoBERTa\u6a21\u578b\uff0c\u9488\u5bf9\u82f1\u8bed\u548c\u5fb7\u8bed\u4f7f\u7528\u591a\u8bed\u8a00\u6a21\u578bXLM-RoBERTa\uff0c\u5e76\u5bf9\u5176\u6548\u80fd\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "RoBERTa\u6a21\u578b\u5728\u82f1\u8bed\u5e0c\u671b\u8a00\u8bba\u68c0\u6d4b\u4e0a\u53d6\u5f97\u52a0\u6743F1\u5206\u65700.818\u548c\u51c6\u786e\u738781.8%\uff1bXLM-RoBERTa\u6a21\u578b\u5728\u82f1\u8bed\u548c\u5fb7\u8bed\u4e0a\u5206\u522b\u8fbe\u52300.786\u7684\u52a0\u6743F1\u5206\u6570\u548c78.5%\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u9884\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6539\u8fdb\u5bf9\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u8868\u73b0\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2602.01785", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.01785", "abs": "https://arxiv.org/abs/2602.01785", "authors": ["Yuling Shi", "Chaoxiang Xie", "Zhensu Sun", "Yeheng Chen", "Chenxu Zhang", "Longfei Yun", "Chengcheng Wan", "Hongyu Zhang", "David Lo", "Xiaodong Gu"], "title": "CodeOCR: On the Effectiveness of Vision Language Models in Code Understanding", "comment": "Code and data are available at https://github.com/YerbaPage/CodeOCR", "summary": "Large Language Models (LLMs) have achieved remarkable success in source code understanding, yet as software systems grow in scale, computational efficiency has become a critical bottleneck. Currently, these models rely on a text-based paradigm that treats source code as a linear sequence of tokens, which leads to a linear increase in context length and associated computational costs. The rapid advancement of Multimodal LLMs (MLLMs) introduces an opportunity to optimize efficiency by representing source code as rendered images. Unlike text, which is difficult to compress without losing semantic meaning, the image modality is inherently suitable for compression. By adjusting resolution, images can be scaled to a fraction of their original token cost while remaining recognizable to vision-capable models. To explore the feasibility of this approach, we conduct the first systematic study on the effectiveness of MLLMs for code understanding. Our experiments reveal that: (1) MLLMs can effectively understand code with substantial token reduction, achieving up to 8x compression; (2) MLLMs can effectively leverage visual cues such as syntax highlighting, improving code completion performance under 4x compression; and (3) Code-understanding tasks like clone detection exhibit exceptional resilience to visual compression, with some compression ratios even slightly outperforming raw text inputs. Our findings highlight both the potential and current limitations of MLLMs in code understanding, which points out a shift toward image-modality code representation as a pathway to more efficient inference.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u6e90\u4ee3\u7801\u4ee5\u56fe\u50cf\u5f62\u5f0f\u8f93\u5165\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u538b\u7f29\u548c\u6709\u6548\u7406\u89e3\uff0c\u5c55\u73b0\u4e86\u4ee3\u7801\u56fe\u50cf\u6a21\u6001\u8868\u793a\u4f18\u5316\u63a8\u7406\u6548\u7387\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u5c06\u4ee3\u7801\u89c6\u4e3a\u7ebf\u6027\u6587\u672c\u5e8f\u5217\uff0c\u5bfc\u81f4\u968f\u7740\u7cfb\u7edf\u89c4\u6a21\u589e\u957f\u8ba1\u7b97\u6210\u672c\u7ebf\u6027\u589e\u52a0\uff0c\u5bfb\u6c42\u901a\u8fc7\u591a\u6a21\u6001\u5b66\u4e60\u6a21\u578b\u5229\u7528\u56fe\u50cf\u6a21\u6001\u8fdb\u884c\u538b\u7f29\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5c06\u6e90\u4ee3\u7801\u4ee5\u56fe\u50cf\u6a21\u6001\u8f93\u5165MLLMs\u7684\u53ef\u884c\u6027\uff0c\u901a\u8fc7\u8c03\u6574\u56fe\u50cf\u5206\u8fa8\u7387\u5b9e\u73b0\u5927\u5e45\u538b\u7f29\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "MLLMs\u5728\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad88\u500d\u7684\u538b\u7f29\u7387\uff1b\u89c6\u89c9\u63d0\u793a\u5982\u8bed\u6cd5\u9ad8\u4eae\u63d0\u9ad8\u4e86\u57284\u500d\u538b\u7f29\u4e0b\u7684\u4ee3\u7801\u5b8c\u6210\u6027\u80fd\uff1b\u514b\u9686\u68c0\u6d4b\u7b49\u4efb\u52a1\u5bf9\u89c6\u89c9\u538b\u7f29\u8868\u73b0\u51fa\u9ad8\u5ea6\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u80fd\u591f\u6709\u6548\u7406\u89e3\u4ee5\u6e32\u67d3\u56fe\u50cf\u5f62\u5f0f\u5448\u73b0\u7684\u6e90\u4ee3\u7801\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u538b\u7f29\u7387\u548c\u8ba1\u7b97\u6548\u7387\u63d0\u5347\uff0c\u540c\u65f6\u89c6\u89c9\u7279\u6027\u5982\u8bed\u6cd5\u9ad8\u4eae\u53ef\u4ee5\u8fdb\u4e00\u6b65\u6539\u5584\u4ee3\u7801\u5b8c\u6210\u4efb\u52a1\u7684\u8868\u73b0\uff1b\u67d0\u4e9b\u4ee3\u7801\u7406\u89e3\u4efb\u52a1\u5bf9\u89c6\u89c9\u538b\u7f29\u8868\u73b0\u51fa\u5f3a\u9002\u5e94\u6027\u751a\u81f3\u8d85\u8d8a\u6587\u672c\u8f93\u5165\u3002"}}
{"id": "2602.00619", "categories": ["cs.CL", "cs.AI", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00619", "abs": "https://arxiv.org/abs/2602.00619", "authors": ["Yuxuan Lu", "Yongkang Guo", "Yuqing Kong"], "title": "Jailbreaking LLMs via Calibration", "comment": null, "summary": "Safety alignment in Large Language Models (LLMs) often creates a systematic discrepancy between a model's aligned output and the underlying pre-aligned data distribution. We propose a framework in which the effect of safety alignment on next-token prediction is modeled as a systematic distortion of a pre-alignment distribution. We cast Weak-to-Strong Jailbreaking as a forecast aggregation problem and derive an optimal aggregation strategy characterized by a Gradient Shift in the loss-induced dual space. We show that logit-arithmetic jailbreaking methods are a special case of this framework under cross-entropy loss, and derive a broader family of aggregation rules corresponding to other proper losses. We also propose a new hybrid aggregation rule. Evaluations across red-teaming benchmarks and math utility tasks using frontier models demonstrate that our approach achieves superior Attack Success Rates and lower \"Jailbreak Tax\" compared with existing methods, especially on the safety-hardened gpt-oss-120b.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u635f\u5931\u51fd\u6570\u7684\u5b89\u5168\u7ed5\u8fc7\u9884\u6d4b\u805a\u5408\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347LLMs\u7684\u7ed5\u8fc7\u653b\u51fb\u6548\u679c\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u5bf9\u9f50\u65b9\u6cd5\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u4e0e\u539f\u59cb\u6570\u636e\u5206\u5e03\u4ea7\u751f\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u5982\u4f55\u6709\u6548\u5229\u7528\u8be5\u7279\u6027\u8fdb\u884c\u5b89\u5168\u7ed5\u8fc7\u653b\u51fb\u5e76\u63d0\u5347\u7ed5\u8fc7\u6210\u529f\u7387\u6210\u4e3a\u6311\u6218\u3002", "method": "\u5c06\u5b89\u5168\u5bf9\u9f50\u770b\u4f5c\u9884\u5148\u5bf9\u9f50\u5206\u5e03\u7684\u7cfb\u7edf\u6027\u626d\u66f2\uff0c\u63d0\u51fa\u5c06\u5f31\u5230\u5f3a\u7ed5\u8fc7\u89c6\u4e3a\u9884\u6d4b\u805a\u5408\u95ee\u9898\uff0c\u5e76\u5bfc\u51fa\u57fa\u4e8e\u635f\u5931\u8bf1\u5bfc\u7684\u5bf9\u5076\u7a7a\u95f4\u68af\u5ea6\u504f\u79fb\u7684\u6700\u4f18\u805a\u5408\u7b56\u7565\uff0c\u6db5\u76d6\u4e86\u5bf9\u6570\u7b97\u672f\u7ed5\u8fc7\u65b9\u6cd5\u548c\u65b0\u6df7\u5408\u805a\u5408\u89c4\u5219\u3002", "result": "\u5728\u7ea2\u961f\u6d4b\u8bd5\u548c\u6570\u5b66\u4efb\u52a1\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u524d\u6cbf\u6a21\u578b\u4e0a\u83b7\u5f97\u66f4\u9ad8\u7684\u653b\u51fb\u6210\u529f\u7387\u548c\u66f4\u4f4e\u7684\u7ed5\u8fc7\u6210\u672c\uff0c\u5c24\u5176\u5728\u5b89\u5168\u5f3a\u5316\u7684gpt-oss-120b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u5efa\u6a21\u4e86\u5b89\u5168\u5bf9\u9f50\u5bf9LLMs\u9884\u6d4b\u7684\u7cfb\u7edf\u6027\u626d\u66f2\uff0c\u63d0\u51fa\u7684\u6700\u4f18\u805a\u5408\u7b56\u7565\u5728\u5b89\u5168\u7ed5\u8fc7\u653b\u51fb\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.02084", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02084", "abs": "https://arxiv.org/abs/2602.02084", "authors": ["Jane Luo", "Chengyu Yin", "Xin Zhang", "Qingtao Li", "Steven Liu", "Yiming Huang", "Jie Wu", "Hao Liu", "Yangyu Huang", "Yu Kang", "Fangkai Yang", "Ying Xin", "Scarlett Li"], "title": "Closing the Loop: Universal Repository Representation with RPG-Encoder", "comment": null, "summary": "Current repository agents encounter a reasoning disconnect due to fragmented representations, as existing methods rely on isolated API documentation or dependency graphs that lack semantic depth. We consider repository comprehension and generation to be inverse processes within a unified cycle: generation expands intent into implementation, while comprehension compresses implementation back into intent. To address this, we propose RPG-Encoder, a framework that generalizes the Repository Planning Graph (RPG) from a static generative blueprint into a unified, high-fidelity representation. RPG-Encoder closes the reasoning loop through three mechanisms: (1) Encoding raw code into the RPG that combines lifted semantic features with code dependencies; (2) Evolving the topology incrementally to decouple maintenance costs from repository scale, reducing overhead by 95.7%; and (3) Operating as a unified interface for structure-aware navigation. In evaluations, RPG-Encoder establishes state-of-the-art repository understanding on SWE-bench Verified with 93.7% Acc@5 and exceeds the best baseline by over 10% on SWE-bench Live Lite. These results highlight our superior fine-grained localization accuracy in complex codebases. Furthermore, it achieves 98.5% reconstruction coverage on RepoCraft, confirming RPG's high-fidelity capacity to mirror the original codebase and closing the loop between intent and implementation.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51faRPG-Encoder\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u9ad8\u4fdd\u771f\u4ed3\u5e93\u89c4\u5212\u56fe\uff0c\u89e3\u51b3\u4e86\u4ee3\u7801\u5e93\u7406\u89e3\u4e2d\u7684\u8bed\u4e49\u65ad\u5c42\uff0c\u5b9e\u73b0\u4e86\u4ee3\u7801\u610f\u56fe\u4e0e\u5b9e\u73b0\u4e4b\u95f4\u7684\u95ed\u73af\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u5e93\u7406\u89e3\u548c\u5bfc\u822a\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u4ed3\u5e93\u4ee3\u7406\u65b9\u6cd5\u4f9d\u8d56\u5b64\u7acb\u7684API\u6587\u6863\u6216\u4f9d\u8d56\u56fe\uff0c\u7f3a\u4e4f\u8bed\u4e49\u6df1\u5ea6\uff0c\u5bfc\u81f4\u63a8\u7406\u65ad\u5c42\uff0c\u5f71\u54cd\u4ee3\u7801\u5e93\u7406\u89e3\u548c\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4e86RPG-Encoder\u6846\u67b6\uff0c\u901a\u8fc7\u7f16\u7801\u539f\u59cb\u4ee3\u7801\u4e3a\u7ed3\u5408\u8bed\u4e49\u7279\u5f81\u548c\u4ee3\u7801\u4f9d\u8d56\u7684\u4ed3\u5e93\u89c4\u5212\u56fe(RPG)\uff0c\u589e\u91cf\u6f14\u5316\u62d3\u6251\u7ed3\u6784\uff0c\u4ee5\u53ca\u63d0\u4f9b\u7ed3\u6784\u611f\u77e5\u5bfc\u822a\u63a5\u53e3\uff0c\u5b9e\u73b0\u5bf9\u4ee3\u7801\u5e93\u7684\u9ad8\u4fdd\u771f\u7edf\u4e00\u8868\u793a\u3002", "result": "RPG-Encoder\u5728SWE-bench Verified\u548cLive Lite\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u9886\u5148\u7684\u7406\u89e3\u51c6\u786e\u7387\uff0c\u4e14\u5728RepoCraft\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8698.5%\u7684\u91cd\u6784\u8986\u76d6\u7387\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u8868\u793a fidelity\u3002", "conclusion": "RPG-Encoder\u6709\u6548\u89e3\u51b3\u4e86\u5f53\u524d\u4ee3\u7801\u5e93\u7406\u89e3\u4e2d\u7684\u63a8\u7406\u65ad\u5c42\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u610f\u56fe\u4e0e\u5b9e\u73b0\u4e4b\u95f4\u7684\u95ed\u73af\u3002"}}
{"id": "2602.00638", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00638", "abs": "https://arxiv.org/abs/2602.00638", "authors": ["Yingji Zhang"], "title": "Formal Semantic Control over Language Models", "comment": null, "summary": "This thesis advances semantic representation learning to render language representations or models more semantically and geometrically interpretable, and to enable localised, quasi-symbolic, compositional control through deliberate shaping of their latent space geometry. We pursue this goal within a VAE framework, exploring two complementary research directions: (i) Sentence-level learning and control: disentangling and manipulating specific semantic features in the latent space to guide sentence generation, with explanatory text serving as the testbed; and (ii) Reasoning-level learning and control: isolating and steering inference behaviours in the latent space to control NLI. In this direction, we focus on Explanatory NLI tasks, in which two premises (explanations) are provided to infer a conclusion. The overarching objective is to move toward language models whose internal semantic representations can be systematically interpreted, precisely structured, and reliably directed. We introduce a set of novel theoretical frameworks and practical methodologies, together with corresponding experiments, to demonstrate that our approaches enhance both the interpretability and controllability of latent spaces for natural language across the thesis.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u65b9\u6cd5\u6539\u8fdb\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u8868\u793a\uff0c\u4f7f\u5176\u6f5c\u5728\u7a7a\u95f4\u66f4\u6613\u89e3\u91ca\u548c\u7cbe\u786e\u63a7\u5236\uff0c\u63a8\u52a8\u8bed\u8a00\u6a21\u578b\u5411\u53ef\u89e3\u91ca\u3001\u7ed3\u6784\u5316\u548c\u53ef\u63a7\u65b9\u5411\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u8bed\u4e49\u8868\u793a\u7f3a\u4e4f\u7cfb\u7edf\u53ef\u89e3\u91ca\u6027\u548c\u7ed3\u6784\u5316\u63a7\u5236\uff0c\u9650\u5236\u4e86\u7cbe\u7ec6\u8bed\u4e49\u7406\u89e3\u4e0e\u64cd\u4f5c\u3002", "method": "\u91c7\u7528VAE\u6846\u67b6\uff0c\u5206\u522b\u5728\u53e5\u5b50\u5c42\u9762\u548c\u63a8\u7406\u5c42\u9762\u8fdb\u884c\u5b66\u4e60\uff0c\u901a\u8fc7\u89e3\u8026\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u8bed\u4e49\u7279\u5f81\u548c\u63a8\u7406\u884c\u4e3a\uff0c\u63a7\u5236\u53e5\u5b50\u751f\u6210\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u589e\u5f3a\u81ea\u7136\u8bed\u8a00\u6f5c\u5728\u7a7a\u95f4\u7684\u89e3\u91ca\u6027\u4e0e\u53ef\u63a7\u6027\uff0c\u7279\u522b\u662f\u5728\u89e3\u91ca\u6027\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6210\u529f\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u6f5c\u5728\u7a7a\u95f4\u7684\u8bed\u4e49\u53ef\u89e3\u91ca\u6027\u548c\u51e0\u4f55\u7ed3\u6784\u7684\u53ef\u63a7\u6027\uff0c\u5b9e\u73b0\u4e86\u5c40\u90e8\u5316\u548c\u7c7b\u7b26\u53f7\u7684\u7ec4\u5408\u63a7\u5236\u3002"}}
{"id": "2602.02208", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.02208", "abs": "https://arxiv.org/abs/2602.02208", "authors": ["Md. Toufique Hasan", "Ayman Asad Khan", "Mika Saari", "Vaishnavi Bankhele", "Pekka Abrahamsson"], "title": "Towards AI Evaluation in Domain-Specific RAG Systems: The AgriHubi Case Study", "comment": "6 pages, 2 figures, submitted to MIPRO 2026", "summary": "Large language models show promise for knowledge-intensive domains, yet their use in agriculture is constrained by weak grounding, English-centric training data, and limited real-world evaluation. These issues are amplified for low-resource languages, where high-quality domain documentation exists but remains difficult to access through general-purpose models. This paper presents AgriHubi, a domain-adapted retrieval-augmented generation (RAG) system for Finnish-language agricultural decision support. AgriHubi integrates Finnish agricultural documents with open PORO family models and combines explicit source grounding with user feedback to support iterative refinement. Developed over eight iterations and evaluated through two user studies, the system shows clear gains in answer completeness, linguistic accuracy, and perceived reliability. The results also reveal practical trade-offs between response quality and latency when deploying larger models. This study provides empirical guidance for designing and evaluating domain-specific RAG systems in low-resource language settings.", "AI": {"tldr": "\u9488\u5bf9\u82ac\u5170\u8bed\u519c\u4e1a\u51b3\u7b56\u652f\u6301\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u9886\u57df\u9002\u914d\u7684RAG\u7cfb\u7edfAgriHubi\uff0c\u7ed3\u5408\u4e13\u7528\u6587\u6863\u4e0e\u7528\u6237\u53cd\u9988\uff0c\u63d0\u5347\u4e86\u95ee\u7b54\u8d28\u91cf\u53ca\u53ef\u4fe1\u5ea6\uff0c\u9002\u7528\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00\u573a\u666f\u3002", "motivation": "\u519c\u4e1a\u9886\u57df\u77e5\u8bc6\u5bc6\u96c6\uff0c\u666e\u901a\u5927\u6a21\u578b\u56e0\u8bad\u7ec3\u6570\u636e\u504f\u5411\u82f1\u8bed\u4e14\u7f3a\u4e4f\u5b9e\u9645\u8bc4\u4f30\uff0c\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u96be\u4ee5\u6709\u6548\u5e94\u7528\uff0c\u4e9f\u9700\u9886\u57df\u9002\u914d\u65b9\u6cd5\u3002", "method": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u7cfb\u7edfAgriHubi\uff0c\u7ed3\u5408\u82ac\u5170\u519c\u4e1a\u6587\u6863\u548c\u5f00\u653e\u7684PORO\u6a21\u578b\uff0c\u901a\u8fc7\u663e\u5f0f\u4fe1\u606f\u6e90\u4f9d\u6258\u4e0e\u7528\u6237\u53cd\u9988\u652f\u6301\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u7ecf\u8fc7\u516b\u6b21\u8fed\u4ee3\u548c\u4e24\u8f6e\u7528\u6237\u7814\u7a76\uff0cAgriHubi\u5728\u7b54\u6848\u5b8c\u6574\u6027\u3001\u8bed\u8a00\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u611f\u77e5\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5927\u578b\u6a21\u578b\u5b58\u5728\u54cd\u5e94\u65f6\u5ef6\u4e0e\u8d28\u91cf\u7684\u6743\u8861\u95ee\u9898\u3002", "conclusion": "AgriHubi\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86\u82ac\u5170\u8bed\u519c\u4e1a\u9886\u57df\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u7528\u6237\u6ee1\u610f\u5ea6\uff0c\u5c55\u793a\u4e86\u9886\u57df\u9002\u5e94\u578bRAG\u7cfb\u7edf\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.00642", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00642", "abs": "https://arxiv.org/abs/2602.00642", "authors": ["Haitao Li", "Yifan Chen", "Shuo Miao", "Qian Dong", "Jia Chen", "Yiran Hu", "Junjie Chen", "Minghao Qin", "Qingyao Ai", "Yiqun Liu", "Cheng Luo", "Quan Zhou", "Ya Zhang", "Jikun Hu"], "title": "LegalOne: A Family of Foundation Models for Reliable Legal Reasoning", "comment": "25 pages, v1", "summary": "While Large Language Models (LLMs) have demonstrated impressive general capabilities, their direct application in the legal domain is often hindered by a lack of precise domain knowledge and complexity of performing rigorous multi-step judicial reasoning. To address this gap, we present LegalOne, a family of foundational models specifically tailored for the Chinese legal domain. LegalOne is developed through a comprehensive three-phase pipeline designed to master legal reasoning. First, during mid-training phase, we propose Plasticity-Adjusted Sampling (PAS) to address the challenge of domain adaptation. This perplexity-based scheduler strikes a balance between the acquisition of new knowledge and the retention of original capabilities, effectively establishing a robust legal foundation. Second, during supervised fine-tuning, we employ Legal Agentic CoT Distillation (LEAD) to distill explicit reasoning from raw legal texts. Unlike naive distillation, LEAD utilizes an agentic workflow to convert complex judicial processes into structured reasoning trajectories, thereby enforcing factual grounding and logical rigor. Finally, we implement a Curriculum Reinforcement Learning (RL) strategy. Through a progressive reinforcement process spanning memorization, understanding, and reasoning, LegalOne evolves from simple pattern matching to autonomous and reliable legal reasoning. Experimental results demonstrate that LegalOne achieves state-of-the-art performance across a wide range of legal tasks, surpassing general-purpose LLMs with vastly larger parameter counts through enhanced knowledge density and efficiency. We publicly release the LegalOne weights and the LegalKit evaluation framework to advance the field of Legal AI, paving the way for deploying trustworthy and interpretable foundation models in high-stakes judicial applications.", "AI": {"tldr": "\u9488\u5bf9\u4e2d\u6587\u6cd5\u5f8b\u9886\u57df\u8bbe\u8ba1\u7684LegalOne\u6a21\u578b\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u6709\u6548\u589e\u5f3a\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\uff0c\u6027\u80fd\u9886\u5148\u5e76\u5f00\u6e90\u63a8\u52a8\u6cd5\u5f8bAI\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u7f3a\u4e4f\u7cbe\u51c6\u77e5\u8bc6\u4ee5\u53ca\u590d\u6742\u53f8\u6cd5\u63a8\u7406\u80fd\u529b\uff0c\u96be\u4ee5\u6ee1\u8db3\u6cd5\u5f8b\u9ad8\u6807\u51c6\u4e25\u8981\u6c42\u7684\u5e94\u7528\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u5851\u6027\u8c03\u8282\u91c7\u6837(PAS)\u8fdb\u884c\u9886\u57df\u9002\u5e94\uff0c\u4e2d\u7ea7\u8bad\u7ec3\u9636\u6bb5\u91c7\u7528\u6cd5\u5f8b\u4ee3\u7406\u94fe\u5f0f\u63a8\u7406\u84b8\u998f(LEAD)\u63d0\u53d6\u7ed3\u6784\u5316\u63a8\u7406\u8def\u5f84\uff0c\u6700\u540e\u901a\u8fc7\u8bfe\u7a0b\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u63d0\u5347\u6a21\u578b\u8bb0\u5fc6\u3001\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "result": "LegalOne\u5728\u591a\u79cd\u6cd5\u5f8b\u4efb\u52a1\u4e2d\u8fbe\u5230\u9886\u5148\u8868\u73b0\uff0c\u53c2\u6570\u6570\u91cf\u8fdc\u5c11\u4e8e\u901a\u7528\u5927\u578b\u6a21\u578b\u4f46\u77e5\u8bc6\u5bc6\u5ea6\u548c\u6548\u7387\u66f4\u9ad8\uff0c\u516c\u5f00\u4e86\u6a21\u578b\u6743\u91cd\u548c\u8bc4\u6d4b\u6846\u67b6\u3002", "conclusion": "LegalOne\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\u663e\u8457\u63d0\u5347\u4e86\u4e2d\u6587\u6cd5\u5f8b\u9886\u57df\u7684\u8bed\u8a00\u6a21\u578b\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u8d85\u8d8a\u901a\u7528\u5927\u578b\u6a21\u578b\u7684\u6027\u80fd\uff0c\u63a8\u52a8\u4e86\u6cd5\u5f8b\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.00665", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00665", "abs": "https://arxiv.org/abs/2602.00665", "authors": ["Lakshan Cooray", "Deshan Sumanathilaka", "Pattigadapa Venkatesh Raju"], "title": "Can Small Language Models Handle Context-Summarized Multi-Turn Customer-Service QA? A Synthetic Data-Driven Comparative Evaluation", "comment": "Submission is under review with Computational Linguistics", "summary": "Customer-service question answering (QA) systems increasingly rely on conversational language understanding. While Large Language Models (LLMs) achieve strong performance, their high computational cost and deployment constraints limit practical use in resource-constrained environments. Small Language Models (SLMs) provide a more efficient alternative, yet their effectiveness for multi-turn customer-service QA remains underexplored, particularly in scenarios requiring dialogue continuity and contextual understanding. This study investigates instruction-tuned SLMs for context-summarized multi-turn customer-service QA, using a history summarization strategy to preserve essential conversational state. We also introduce a conversation stage-based qualitative analysis to evaluate model behavior across different phases of customer-service interactions. Nine instruction-tuned low-parameterized SLMs are evaluated against three commercial LLMs using lexical and semantic similarity metrics alongside qualitative assessments, including human evaluation and LLM-as-a-judge methods. Results show notable variation across SLMs, with some models demonstrating near-LLM performance, while others struggle to maintain dialogue continuity and contextual alignment. These findings highlight both the potential and current limitations of low-parameterized language models for real-world customer-service QA systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u6307\u4ee4\u8c03\u4f18\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5ba2\u6237\u670d\u52a1\u95ee\u7b54\u7684\u8868\u73b0\uff0c\u91c7\u7528\u5386\u53f2\u6458\u8981\u4fdd\u6301\u5bf9\u8bdd\u4e0a\u4e0b\u6587\uff0c\u7ed3\u679c\u663e\u793a\u90e8\u5206SLMs\u80fd\u63a5\u8fd1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u6574\u4f53\u4ecd\u5b58\u5728\u5bf9\u8bdd\u8fde\u7eed\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u4e0d\u8db3\u3002", "motivation": "\u4e3a\u4e86\u514b\u670d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u6210\u672c\u548c\u90e8\u7f72\u4e0a\u7684\u9650\u5236\uff0c\u63a2\u8ba8\u66f4\u9ad8\u6548\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5ba2\u6237\u670d\u52a1\u95ee\u7b54\u4e2d\uff0c\u5c24\u5176\u662f\u9700\u8981\u5bf9\u8bdd\u8fde\u7eed\u6027\u548c\u4e0a\u4e0b\u6587\u7406\u89e3\u7684\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528\u5386\u53f2\u6458\u8981\u7b56\u7565\u8fdb\u884c\u4e0a\u4e0b\u6587\u603b\u7ed3\uff0c\u7ed3\u5408\u6307\u4ee4\u8c03\u4f18\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u8f6e\u5ba2\u6237\u670d\u52a1\u95ee\u7b54\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u5bf9\u8bdd\u9636\u6bb5\u7684\u5b9a\u6027\u5206\u6790\u65b9\u6cd5\u3002\u901a\u8fc7\u8bcd\u6c47\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6307\u6807\uff0c\u4ee5\u53ca\u4eba\u5de5\u8bc4\u4ef7\u548cLLM\u62c5\u4efb\u8bc4\u5ba1\u7684\u65b9\u5f0f\uff0c\u8bc4\u4f30\u4e5d\u79cd\u6307\u4ee4\u8c03\u4f18\u7684\u4f4e\u53c2\u6570SLMs\u4e0e\u4e09\u79cd\u5546\u4e1aLLMs\u7684\u8868\u73b0\u3002", "result": "\u90e8\u5206\u4f4e\u53c2\u6570SLMs\u5728\u591a\u8f6e\u5ba2\u6237\u670d\u52a1\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u63a5\u8fd1LLMs\uff0c\u4f46\u5b58\u5728\u8868\u73b0\u4e0d\u5747\u3001\u5bf9\u8bdd\u8fde\u7eed\u6027\u548c\u4e0a\u4e0b\u6587\u4fdd\u6301\u80fd\u529b\u4e0d\u8db3\u7684\u73b0\u8c61\uff0c\u53cd\u6620\u4e86\u5176\u5e94\u7528\u7684\u6f5c\u529b\u4e0e\u6311\u6218\u5e76\u5b58\u3002", "conclusion": "\u4f4e\u53c2\u6570\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5728\u5b9e\u9645\u5ba2\u6237\u670d\u52a1\u95ee\u7b54\u7cfb\u7edf\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5728\u4fdd\u6301\u5bf9\u8bdd\u8fde\u7eed\u6027\u548c\u4e0a\u4e0b\u6587\u4e00\u81f4\u6027\u65b9\u9762\u4ecd\u5b58\u5728\u5c40\u9650\u3002\u90e8\u5206SLMs\u7684\u8868\u73b0\u63a5\u8fd1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u6548\u679c\u5dee\u5f02\u663e\u8457\u3002"}}
{"id": "2602.00733", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00733", "abs": "https://arxiv.org/abs/2602.00733", "authors": ["Yinuo Zhang", "Dingcheng Huang", "Haifeng Suo", "Yizhuo Li", "Ziya Zhao", "Junhao Xu", "Zhiying Tu", "Dianhui Chu", "Deming Zhai", "Xianming Liu", "Xiaoyan Yu", "Dianbo Sui"], "title": "EchoReview: Learning Peer Review from the Echoes of Scientific Citations", "comment": null, "summary": "As the volume of scientific submissions continues to grow rapidly, traditional peer review systems are facing unprecedented scalability pressures, highlighting the urgent need for automated reviewing methods that are both scalable and reliable. Existing supervised fine-tuning approaches based on real review data are fundamentally constrained by single-source of data as well as the inherent subjectivity and inconsistency of human reviews, limiting their ability to support high-quality automated reviewers. To address these issues, we propose EchoReview, a citation-context-driven data synthesis framework that systematically mines implicit collective evaluative signals from academic citations and transforms scientific community's long-term judgments into structured review-style data. Based on this pipeline, we construct EchoReview-16K, the first large-scale, cross-conference, and cross-year citation-driven review dataset, and train an automated reviewer, EchoReviewer-7B. Experimental results demonstrate that EchoReviewer-7B can achieve significant and stable improvements on core review dimensions such as evidence support and review comprehensiveness, validating citation context as a robust and effective data paradigm for reliable automated peer review.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u7684\u89c4\u6a21\u548c\u53ef\u9760\u6027\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5f15\u7528\u8bed\u5883\u7684\u6570\u636e\u5408\u6210\u65b9\u6cd5EchoReview\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5e76\u8bad\u7ec3\u81ea\u52a8\u8bc4\u5ba1\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5ba1\u7a3f\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u540c\u884c\u8bc4\u5ba1\u89c4\u6a21\u96be\u4ee5\u5e94\u5bf9\u5feb\u901f\u589e\u957f\u7684\u8bba\u6587\u63d0\u4ea4\u91cf\uff0c\u4e14\u73b0\u6709\u57fa\u4e8e\u771f\u5b9e\u8bc4\u5ba1\u6570\u636e\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u53d7\u9650\u4e8e\u6570\u636e\u5355\u4e00\u6765\u6e90\u53ca\u4eba\u4e3a\u8bc4\u5ba1\u7684\u4e3b\u89c2\u6027\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u4e9f\u9700\u4e00\u4e2a\u65e2\u53ef\u6269\u5c55\u53c8\u53ef\u9760\u7684\u81ea\u52a8\u8bc4\u5ba1\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86EchoReview\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u6316\u6398\u5b66\u672f\u5f15\u7528\u4e2d\u7684\u9690\u5f0f\u96c6\u4f53\u8bc4\u4ef7\u4fe1\u53f7\uff0c\u5408\u6210\u7ed3\u6784\u5316\u8bc4\u5ba1\u98ce\u683c\u6570\u636e\uff0c\u6784\u5efa\u4e86\u8de8\u4f1a\u8bae\u3001\u8de8\u5e74\u4efd\u7684\u5927\u89c4\u6a21EchoReview-16K\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86\u81ea\u52a8\u5316\u8bc4\u5ba1\u5668EchoReviewer-7B\u3002", "result": "EchoReviewer-7B\u5728\u8bc1\u636e\u652f\u6301\u548c\u8bc4\u5ba1\u5168\u9762\u6027\u7b49\u6838\u5fc3\u8bc4\u5ba1\u7ef4\u5ea6\u8868\u73b0\u51fa\u663e\u8457\u4e14\u7a33\u5b9a\u7684\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5f15\u7528\u8bed\u5883\u4f5c\u4e3a\u6570\u636e\u8303\u5f0f\u7684\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "EchoReview\u901a\u8fc7\u5229\u7528\u5f15\u7528\u8bed\u5883\u8f6c\u6362\u79d1\u5b66\u793e\u533a\u957f\u8fdc\u5224\u65ad\u4e3a\u7ed3\u6784\u5316\u7684\u8bc4\u5ba1\u6570\u636e\uff0c\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u8bc4\u5ba1\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\uff0c\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u5f15\u7528\u8bed\u5883\u7684\u6570\u636e\u8303\u5f0f\u5728\u81ea\u52a8\u540c\u884c\u8bc4\u8bae\u4e2d\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.00740", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00740", "abs": "https://arxiv.org/abs/2602.00740", "authors": ["Ziyan Xiao", "Yinghao Zhu", "Liang Peng", "Lequan Yu"], "title": "ExperienceWeaver: Optimizing Small-sample Experience Learning for LLM-based Clinical Text Improvement", "comment": null, "summary": "Clinical text improvement is vital for healthcare efficiency but remains difficult due to limited high-quality data and the complex constraints of medical documentation. While Large Language Models (LLMs) show promise, current approaches struggle in small-sample settings: supervised fine-tuning is data-intensive and costly, while retrieval-augmented generation often provides superficial corrections without capturing the reasoning behind revisions. To address these limitations, we propose ExperienceWeaver, a hierarchical framework that shifts the focus from data retrieval to experience learning. Instead of simply recalling past examples, ExperienceWeaver distills noisy, multi-dimensional feedback into structured, actionable knowledge. Specifically, error-specific Tips and high-level Strategies. By injecting this distilled experience into an agentic pipeline, the model learns \"how to revise\" rather than just \"what to revise\". Extensive evaluations across four clinical datasets demonstrate that ExperienceWeaver consistently improves performance, surpassing state-of-the-art models such as Gemini-3 Pro in small-sample settings.", "AI": {"tldr": "\u9488\u5bf9\u5c0f\u6837\u672c\u4e34\u5e8a\u6587\u672c\u6539\u8fdb\u96be\u9898\uff0cExperienceWeaver\u6846\u67b6\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u7ef4\u53cd\u9988\u7684\u7ecf\u9a8c\u5b66\u4e60\uff0c\u63d0\u5347\u4e86\u4fee\u8ba2\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u6a21\u578b\u3002", "motivation": "\u4e34\u5e8a\u6587\u672c\u6539\u8fdb\u5bf9\u533b\u7597\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7531\u4e8e\u9ad8\u8d28\u91cf\u6570\u636e\u6709\u9650\u53ca\u533b\u7597\u6587\u6863\u7684\u590d\u6742\u7ea6\u675f\uff0c\u6539\u8fdb\u96be\u5ea6\u5927\u3002\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5c0f\u6837\u672c\u73af\u5883\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u76d1\u7763\u5fae\u8c03\u6210\u672c\u9ad8\uff0c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u5f80\u5f80\u53ea\u80fd\u63d0\u4f9b\u8868\u9762\u6539\u6b63\uff0c\u7f3a\u4e4f\u4fee\u8ba2\u80cc\u540e\u7684\u63a8\u7406\u3002", "method": "\u63d0\u51faExperienceWeaver\u6846\u67b6\uff0c\u8f6c\u53d8\u7126\u70b9\u4ece\u6570\u636e\u68c0\u7d22\u5230\u7ecf\u9a8c\u5b66\u4e60\u3002\u901a\u8fc7\u63d0\u53d6\u566a\u58f0\u7e41\u591a\u4e14\u591a\u7ef4\u5ea6\u7684\u53cd\u9988\uff0c\u7ed3\u6784\u5316\u5e76\u8f6c\u5316\u4e3a\u5177\u4f53\u7684\u9519\u8bef\u63d0\u793a\u548c\u9ad8\u5c42\u7b56\u7565\u3002\u5c06\u63d0\u70bc\u7684\u7ecf\u9a8c\u6ce8\u5165\u667a\u80fd\u7ba1\u7ebf\uff0c\u4f7f\u6a21\u578b\u5b66\u4e60\u201c\u5982\u4f55\u4fee\u8ba2\u201d\u800c\u975e\u4ec5\u4ec5\u201c\u4fee\u8ba2\u4ec0\u4e48\u201d\u3002", "result": "\u5728\u56db\u4e2a\u4e34\u5e8a\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u8bc4\u4f30\u8868\u660e\uff0cExperienceWeaver\u5728\u5c0f\u6837\u672c\u73af\u5883\u4e2d\u6301\u7eed\u63d0\u5347\u6027\u80fd\uff0c\u4f18\u4e8e\u5305\u62ecGemini-3 Pro\u5728\u5185\u7684\u6700\u5148\u8fdb\u6a21\u578b\u3002", "conclusion": "ExperienceWeaver\u901a\u8fc7\u7ecf\u9a8c\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u5c0f\u6837\u672c\u4e34\u5e8a\u6587\u672c\u6539\u8fdb\u96be\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u548c\u4fee\u8ba2\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u533b\u7597\u6587\u672c\u5904\u7406\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002"}}
{"id": "2602.00742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00742", "abs": "https://arxiv.org/abs/2602.00742", "authors": ["Liang Wang", "Xinyi Mou", "Xiaoyou Liu", "Xuanjing Huang", "Zhongyu Wei"], "title": "CURP: Codebook-based Continuous User Representation for Personalized Generation with LLMs", "comment": null, "summary": "User modeling characterizes individuals through their preferences and behavioral patterns to enable personalized simulation and generation with Large Language Models (LLMs) in contemporary approaches. However, existing methods, whether prompt-based or training-based methods, face challenges in balancing personalization quality against computational and data efficiency. We propose a novel framework CURP, which employs a bidirectional user encoder and a discrete prototype codebook to extract multi-dimensional user traits. This design enables plug-and-play personalization with a small number of trainable parameters (about 20M parameters, about 0.2\\% of the total model size). Through extensive experiments on variant generation tasks, we show that CURP achieves superior performance and generalization compared to strong baselines, while offering better interpretability and scalability. The code are available at https://github.com/RaidonWong/CURP_code", "AI": {"tldr": "CURP\u5229\u7528\u53cc\u5411\u7f16\u7801\u5668\u548c\u539f\u578b\u4ee3\u7801\u672c\uff0c\u5b9e\u73b0\u6781\u5c11\u53c2\u6570\u7684\u7528\u6237\u4e2a\u6027\u5316\uff0c\u63d0\u5347\u4e86\u751f\u6210\u4efb\u52a1\u8868\u73b0\u4e0e\u6a21\u578b\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u7528\u6237\u5efa\u6a21\u65b9\u6cd5\u5728\u4e2a\u6027\u5316\u8d28\u91cf\u548c\u8ba1\u7b97\u3001\u6570\u636e\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u96be\u9898\u3002", "method": "\u63d0\u51faCURP\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5411\u7528\u6237\u7f16\u7801\u5668\u548c\u79bb\u6563\u539f\u578b\u4ee3\u7801\u672c\uff0c\u4ece\u591a\u7ef4\u5ea6\u63d0\u53d6\u7528\u6237\u7279\u5f81\uff0c\u5b9e\u73b0\u5c11\u91cf\u53ef\u8bad\u7ec3\u53c2\u6570\u7684\u5373\u63d2\u5373\u7528\u4e2a\u6027\u5316\u3002", "result": "CURP\u5728\u591a\u4e2a\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u4e14\u5177\u5907\u66f4\u597d\u7684\u53ef\u89e3\u91ca\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CURP\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4e2a\u6027\u5316\u6a21\u578b\u4e2d\u6027\u80fd\u4e0e\u6548\u7387\u7684\u77db\u76fe\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u7528\u6237\u5efa\u6a21\u3002"}}
{"id": "2602.00747", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00747", "abs": "https://arxiv.org/abs/2602.00747", "authors": ["Shengrui Li", "Fei Zhao", "Kaiyan Zhao", "Jieying Ye", "Haifeng Liu", "Fangcheng Shi", "Zheyong Xie", "Yao Hu", "Shaosheng Cao"], "title": "Decouple Searching from Training: Scaling Data Mixing via Model Merging for Large Language Model Pre-training", "comment": "17 pages, 5 figures", "summary": "Determining an effective data mixture is a key factor in Large Language Model (LLM) pre-training, where models must balance general competence with proficiency on hard tasks such as math and code. However, identifying an optimal mixture remains an open challenge, as existing approaches either rely on unreliable tiny-scale proxy experiments or require prohibitively expensive large-scale exploration. To address this, we propose Decouple Searching from Training Mix (DeMix), a novel framework that leverages model merging to predict optimal data ratios. Instead of training proxy models for every sampled mixture, DeMix trains component models on candidate datasets at scale and derives data mixture proxies via weighted model merging. This paradigm decouples search from training costs, enabling evaluation of unlimited sampled mixtures without extra training burden and thus facilitating better mixture discovery through more search trials. Extensive experiments demonstrate that DeMix breaks the trade-off between sufficiency, accuracy and efficiency, obtaining the optimal mixture with higher benchmark performance at lower search cost. Additionally, we release the DeMix Corpora, a comprehensive 22T-token dataset comprising high-quality pre-training data with validated mixtures to facilitate open research. Our code and DeMix Corpora is available at https://github.com/Lucius-lsr/DeMix.", "AI": {"tldr": "DeMix\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u6a21\u578b\u5408\u5e76\u65b9\u6cd5\uff0c\u9ad8\u6548\u4e14\u51c6\u786e\u5730\u786e\u5b9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u6240\u9700\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u641c\u7d22\u6210\u672c\u5e76\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u516c\u5f00\u4e86\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u786e\u5b9a\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u7684\u65b9\u6cd5\u5b58\u5728\u9a8c\u8bc1\u6210\u672c\u9ad8\u6216\u4f9d\u8d56\u5c0f\u89c4\u6a21\u4ee3\u7406\u6a21\u578b\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u627e\u5230\u6700\u4f18\u6df7\u5408\u6bd4\u4f8b\u4ee5\u5e73\u8861\u6a21\u578b\u7684\u901a\u7528\u80fd\u529b\u548c\u9488\u5bf9\u96be\u9898\u7684\u4e13\u957f\u3002", "method": "DeMix\u901a\u8fc7\u8bad\u7ec3\u5019\u9009\u6570\u636e\u96c6\u7684\u7ec4\u4ef6\u6a21\u578b\uff0c\u5e76\u5229\u7528\u52a0\u6743\u6a21\u578b\u5408\u5e76\u751f\u6210\u6570\u636e\u6df7\u5408\u4ee3\u7406\uff0c\u89e3\u8026\u4e86\u6570\u636e\u6bd4\u4f8b\u641c\u7d22\u548c\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u4ece\u800c\u5b9e\u73b0\u4e0d\u9650\u91cf\u7684\u641c\u7d22\u8bd5\u9a8c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eDeMix\u5728\u8f83\u4f4e\u7684\u641c\u7d22\u6210\u672c\u4e0b\uff0c\u80fd\u591f\u627e\u5230\u66f4\u4f18\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u63d0\u5347\u57fa\u51c6\u6d4b\u8bd5\u6027\u80fd\uff0c\u540c\u65f6\u53d1\u5e03\u4e86\u5305\u542b22\u4e07\u4ebf\u6807\u8bb0\u7684\u9ad8\u8d28\u91cf\u9884\u8bad\u7ec3\u6570\u636e\u96c6DeMix Corpora\uff0c\u4fc3\u8fdb\u5f00\u653e\u7814\u7a76\u3002", "conclusion": "DeMix\u6846\u67b6\u901a\u8fc7\u6a21\u578b\u5408\u5e76\u6280\u672f\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u7684\u9ad8\u6548\u9884\u6d4b\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u641c\u7d22\u6210\u672c\u548c\u51c6\u786e\u7387\u4e0a\u7684\u6743\u8861\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u7684\u6027\u80fd\u3002"}}
{"id": "2602.00758", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00758", "abs": "https://arxiv.org/abs/2602.00758", "authors": ["Ali El Lahib", "Ying-Jieh Xia", "Zehan Li", "Yuxuan Wang", "Xinyu Pi"], "title": "Temporal Leakage in Search-Engine Date-Filtered Web Retrieval: A Case Study from Retrospective Forecasting", "comment": "9 pages, 6 figures", "summary": "Search-engine date filters are widely used to enforce pre-cutoff retrieval in retrospective evaluations of search-augmented forecasters. We show this approach is unreliable: auditing Google Search with a before: filter, 71% of questions return at least one page containing strong post-cutoff leakage, and for 41%, at least one page directly reveals the answer. Using a large language model (LLM), gpt-oss-120b, to forecast with these leaky documents, we demonstrate an inflated prediction accuracy (Brier score 0.108 vs. 0.242 with leak-free documents). We characterize common leakage mechanisms, including updated articles, related-content modules, unreliable metadata/timestamps, and absence-based signals, and argue that date-restricted search is insufficient for temporal evaluation. We recommend stronger retrieval safeguards or evaluation on frozen, time-stamped web snapshots to ensure credible retrospective forecasting.", "AI": {"tldr": "\u8c37\u6b4c\u641c\u7d22\u7684\u65e5\u671f\u8fc7\u6ee4\u5668\u65e0\u6cd5\u6709\u6548\u9632\u6b62\u622a\u6b62\u65e5\u671f\u540e\u4fe1\u606f\u6cc4\u9732\uff0c\u5bfc\u81f4\u9884\u6d4b\u7ed3\u679c\u88ab\u4e25\u91cd\u5938\u5927\uff0c\u5e94\u91c7\u7528\u66f4\u4e25\u683c\u63aa\u65bd\u4fdd\u8bc1\u65f6\u95f4\u654f\u611f\u4efb\u52a1\u7684\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "motivation": "\u641c\u7d22\u5f15\u64ce\u65e5\u671f\u8fc7\u6ee4\u5668\u88ab\u5e7f\u6cdb\u7528\u4e8e\u56de\u987e\u6027\u8bc4\u4f30\u4e2d\uff0c\u4ee5\u786e\u4fdd\u9884\u6d4b\u53ea\u57fa\u4e8e\u622a\u6b62\u65e5\u671f\u524d\u7684\u4fe1\u606f\u3002", "method": "\u901a\u8fc7\u5ba1\u8ba1Google\u641c\u7d22\u7684before:\u8fc7\u6ee4\u5668\uff0c\u68c0\u6d4b\u622a\u6b62\u65e5\u671f\u540e\u7684\u4fe1\u606f\u6cc4\u9732\u3002\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578bgpt-oss-120b\uff0c\u5728\u542b\u6cc4\u9732\u548c\u65e0\u6cc4\u9732\u7684\u6587\u6863\u4e0a\u5bf9\u9884\u6d4b\u51c6\u786e\u6027\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u53d1\u73b071%\u7684\u67e5\u8be2\u8fd4\u56de\u4e86\u5305\u542b\u5f3a\u70c8\u622a\u6b62\u65e5\u671f\u540e\u6cc4\u9732\u4fe1\u606f\u7684\u9875\u9762\uff0c41%\u7684\u9875\u9762\u76f4\u63a5\u63ed\u793a\u7b54\u6848\u3002\u4f7f\u7528\u6cc4\u9732\u6587\u6863\u7684\u9884\u6d4b\u51c6\u786e\u6027\u660e\u663e\u88ab\u5938\u5927\uff08Brier\u5206\u65700.108 vs. 0.242\uff09\u3002", "conclusion": "\u641c\u7d22\u5f15\u64ce\u7684\u65e5\u671f\u8fc7\u6ee4\u529f\u80fd\u5728\u65f6\u95f4\u8bc4\u4f30\u4e2d\u4e0d\u53ef\u9760\uff0c\u9700\u91c7\u7528\u66f4\u4e25\u683c\u7684\u68c0\u7d22\u4fdd\u62a4\u63aa\u65bd\u6216\u57fa\u4e8e\u51bb\u7ed3\u65f6\u95f4\u6233\u7f51\u9875\u5feb\u7167\u8fdb\u884c\u8bc4\u4f30\uff0c\u4ee5\u4fdd\u8bc1\u9884\u6d4b\u7684\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2602.00759", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00759", "abs": "https://arxiv.org/abs/2602.00759", "authors": ["Zhipeng Chen", "Xiaobo Qin", "Wayne Xin Zhao", "Youbin Wu", "Ji-Rong Wen"], "title": "Adaptive Ability Decomposing for Unlocking Large Reasoning Model Effective Reinforcement Learning", "comment": "21 pages, Working in progress", "summary": "Reinforcement learning with verifiable rewards (RLVR) has shown great potential to enhance the reasoning ability of large language models (LLMs). However, due to the limited amount of information provided during the RLVR process, the model can only engage in largely blind exploration, which often results in failure on challenging problems. To provide additional information for the RLVR process without relying on a teacher model, we propose A$^2$D, an Adaptive Ability Decomposing method for enhancing the effectiveness of RLVR. Specifically, we first train a decomposer via RLVR without distillation, enabling it to decompose complex questions into a set of simpler sub-questions. Next, we use this decomposer to annotate sub-questions for each question in the training dataset, and then train the reasoner under RLVR with sub-question guidance. To better understand A$^2$D, we first compare its performance with competitive baselines, showing its effectiveness. Next, we observe that our method functions as a plug-and-play module that can be applied to different RLVR algorithms. Furthermore, we conduct an analysis of the decomposer, revealing how the RLVR process affects its performance and behavior, and which type of guidance is better suited for enhancing the reasoner's exploration and exploitation abilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faA\u00b2D\u65b9\u6cd5\u901a\u8fc7\u95ee\u9898\u80fd\u529b\u5206\u89e3\u8f85\u52a9RLVR\uff0c\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u5177\u6709\u8f83\u597d\u7684\u901a\u7528\u6027\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u4f20\u7edfRLVR\u56e0\u4fe1\u606f\u91cf\u6709\u9650\uff0c\u63a2\u7d22\u8fc7\u7a0b\u76f2\u76ee\uff0c\u5bfc\u81f4\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u7f3a\u4e4f\u989d\u5916\u6307\u5bfc\u4fe1\u606f\u4e14\u4e0d\u4f9d\u8d56\u6559\u5e08\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u81ea\u9002\u5e94\u80fd\u529b\u5206\u89e3\u65b9\u6cd5\uff08A\u00b2D\uff09\uff0c\u9996\u5148\u5229\u7528RLVR\u8bad\u7ec3\u5206\u89e3\u5668\u5c06\u590d\u6742\u95ee\u9898\u62c6\u89e3\u4e3a\u7b80\u5355\u5b50\u95ee\u9898\uff0c\u7136\u540e\u7528\u5206\u89e3\u5668\u5bf9\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u6807\u6ce8\uff0c\u6700\u540e\u5728RLVR\u6846\u67b6\u4e0b\u7528\u5b50\u95ee\u9898\u6307\u5bfc\u8bad\u7ec3\u63a8\u7406\u5668\u3002", "result": "A\u00b2D\u5728\u4e0e\u591a\u79cd\u7ade\u4e89\u57fa\u7ebf\u7684\u5bf9\u6bd4\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5206\u6790\u8868\u660e\u5206\u89e3\u5668\u5728RLVR\u8fc7\u7a0b\u4e2d\u7684\u8868\u73b0\u53ca\u6307\u5bfc\u7c7b\u578b\u90fd\u5bf9\u63a8\u7406\u5668\u7684\u63a2\u7d22\u4e0e\u5229\u7528\u80fd\u529b\u6709\u79ef\u6781\u5f71\u54cd\u3002", "conclusion": "A\u00b2D\u65b9\u6cd5\u901a\u8fc7\u5f15\u5165\u80fd\u529b\u5206\u89e3\u5668\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08RLVR\uff09\u5728\u590d\u6742\u95ee\u9898\u63a8\u7406\u4e2d\u7684\u6548\u679c\uff0c\u5e76\u4e14\u80fd\u591f\u4f5c\u4e3a\u4e00\u4e2a\u63d2\u62d4\u6a21\u5757\u5e94\u7528\u4e8e\u4e0d\u540cRLVR\u7b97\u6cd5\u3002"}}
{"id": "2602.00760", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00760", "abs": "https://arxiv.org/abs/2602.00760", "authors": ["Kaiyan Chang", "Chenwei Zhu", "Yingfeng Luo", "Yifu Huo", "Chenglong Wang", "Xiaoqian Liu", "Qiaozhi He", "Tong Xiao", "Zhengtao Yu", "Jingbo Zhu"], "title": "APR: Penalizing Structural Redundancy in Large Reasoning Models via Anchor-based Process Rewards", "comment": "Under Review", "summary": "Test-Time Scaling (TTS) has significantly enhanced the capabilities of Large Reasoning Models (LRMs) but introduces a critical side-effect known as Overthinking. We conduct a preliminary study to rethink this phenomenon from a fine-grained perspective. We observe that LRMs frequently conduct repetitive self-verification without revision even after obtaining the final answer during the reasoning process. We formally define this specific position where the answer first stabilizes as the Reasoning Anchor. By analyzing pre- and post-anchor reasoning behaviors, we uncover the structural redundancy fixed in LRMs: the meaningless repetitive verification after deriving the first complete answer, which we term the Answer-Stable Tail (AST). Motivated by this observation, we propose Anchor-based Process Reward (APR), a structure-aware reward shaping method that localizes the reasoning anchor and penalizes exclusively the post-anchor AST. Leveraging the policy optimization algorithm suitable for length penalties, our APR models achieved the performance-efficiency Pareto frontier at 1.5B and 7B scales averaged across five mathematical reasoning datasets while requiring significantly fewer computational resources for RL training.", "AI": {"tldr": "\u9488\u5bf9\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u63a8\u7406\u951a\u70b9\u7684\u5956\u52b1\u8c03\u6574\u65b9\u6cd5APR\uff0c\u6709\u6548\u51cf\u5c11\u65e0\u6548\u91cd\u590d\u9a8c\u8bc1\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u5b58\u5728\u91cd\u590d\u81ea\u9a8c\u8bc1\u4e14\u65e0\u5b9e\u9645\u4fee\u6b63\u7684\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u5956\u52b1\u8c03\u6574\u65b9\u6cd5APR\uff0c\u901a\u8fc7\u5b9a\u4f4d\u63a8\u7406\u4e2d\u7684Reasoning Anchor\u5e76\u9488\u5bf9Answer-Stable Tail\u8fdb\u884c\u60e9\u7f5a\uff0c\u7ed3\u5408\u9002\u5408\u957f\u5ea6\u60e9\u7f5a\u7684\u7b56\u7565\u4f18\u5316\u7b97\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "APR\u57281.5B\u548c7B\u53c2\u6570\u89c4\u6a21\u7684\u5927\u6a21\u578b\u4e0a\uff0c\u5728\u4e94\u4e2a\u6570\u5b66\u63a8\u7406\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6027\u80fd-\u6548\u7387\u7684\u6700\u4f18\u6743\u8861\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6240\u9700\u7684\u8ba1\u7b97\u8d44\u6e90\u3002", "conclusion": "Anchor-based Process Reward (APR) \u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u5728\u6d4b\u8bd5\u65f6\u51fa\u73b0\u7684\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2602.00762", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.00762", "abs": "https://arxiv.org/abs/2602.00762", "authors": ["Yuheng Shao", "Junjie Xiong", "Chaoran Wu", "Xiyuan Wang", "Ziyu Zhou", "Yang Ouyang", "Qinyi Tao", "Quan Li"], "title": "WordCraft: Scaffolding the Keyword Method for L2 Vocabulary Learning with Multimodal LLMs", "comment": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI' 26), April 13--17, 2026, Barcelona, Spain", "summary": "Applying the keyword method for vocabulary memorization remains a significant challenge for L1 Chinese-L2 English learners. They frequently struggle to generate phonologically appropriate keywords, construct coherent associations, and create vivid mental imagery to aid long-term retention. Existing approaches, including fully automated keyword generation and outcome-oriented mnemonic aids, either compromise learner engagement or lack adequate process-oriented guidance. To address these limitations, we conducted a formative study with L1 Chinese-L2 English learners and educators (N=18), which revealed key difficulties and requirements in applying the keyword method to vocabulary learning. Building on these insights, we introduce WordCraft, a learner-centered interactive tool powered by Multimodal Large Language Models (MLLMs). WordCraft scaffolds the keyword method by guiding learners through keyword selection, association construction, and image formation, thereby enhancing the effectiveness of vocabulary memorization. Two user studies demonstrate that WordCraft not only preserves the generation effect but also achieves high levels of effectiveness and usability.", "AI": {"tldr": "\u9488\u5bf9\u4e2d\u6587\u6bcd\u8bed\u82f1\u8bed\u5b66\u4e60\u8005\u96be\u4ee5\u5e94\u7528\u5173\u952e\u8bcd\u6cd5\u8bb0\u5fc6\u8bcd\u6c47\u7684\u95ee\u9898\uff0c\u672c\u6587\u5f00\u53d1\u4e86\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ea4\u4e92\u5de5\u5177WordCraft\uff0c\u901a\u8fc7\u8fc7\u7a0b\u6307\u5bfc\u63d0\u5347\u8bb0\u5fc6\u6548\u679c\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u3002", "motivation": "L1\u4e2d\u6587\u6bcd\u8bed\u7684L2\u82f1\u8bed\u5b66\u4e60\u8005\u5728\u4f7f\u7528\u5173\u952e\u8bcd\u6cd5\u8bb0\u5fc6\u8bcd\u6c47\u65f6\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u5982\u96be\u4ee5\u751f\u6210\u5408\u9002\u7684\u5173\u952e\u8bcd\u3001\u6784\u5efa\u8fde\u8d2f\u7684\u8054\u60f3\u548c\u5f62\u6210\u751f\u52a8\u7684\u5fc3\u8c61\u3002\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u51cf\u5c11\u5b66\u4e60\u8005\u53c2\u4e0e\u5ea6\uff0c\u8981\u4e48\u7f3a\u4e4f\u8fc7\u7a0b\u6307\u5bfc\u3002", "method": "\u901a\u8fc7\u5bf918\u540dL1\u4e2d\u6587-L2\u82f1\u8bed\u5b66\u4e60\u8005\u548c\u6559\u5e08\u7684\u8c03\u7814\uff0c\u8bc6\u522b\u5173\u952e\u8bcd\u6cd5\u5e94\u7528\u4e2d\u7684\u5173\u952e\u56f0\u96be\u548c\u9700\u6c42\uff0c\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u5f00\u53d1\u4e86\u4ea4\u4e92\u5f0f\u5de5\u5177WordCraft\uff0c\u5f15\u5bfc\u5b66\u4e60\u8005\u5b8c\u6210\u5173\u952e\u8bcd\u9009\u62e9\u3001\u8054\u60f3\u6784\u5efa\u548c\u56fe\u50cf\u5f62\u6210\u3002", "result": "\u4e24\u9879\u7528\u6237\u7814\u7a76\u8868\u660e\uff0cWordCraft\u4e0d\u4ec5\u4fdd\u7559\u4e86\u5173\u952e\u8bcd\u751f\u6210\u7684\u6548\u679c\uff0c\u8fd8\u5728\u8bcd\u6c47\u8bb0\u5fc6\u7684\u6709\u6548\u6027\u548c\u53ef\u7528\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u9ad8\u6c34\u5e73\u3002", "conclusion": "WordCraft\u901a\u8fc7\u8fc7\u7a0b\u6307\u5bfc\u548c\u591a\u6a21\u6001\u4ea4\u4e92\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5173\u952e\u8bcd\u6cd5\u5728L1\u4e2d\u6587-L2\u82f1\u8bed\u8bcd\u6c47\u5b66\u4e60\u4e2d\u7684\u96be\u9898\uff0c\u63d0\u5347\u4e86\u8bcd\u6c47\u8bb0\u5fc6\u7684\u6548\u679c\u548c\u5b66\u4e60\u4f53\u9a8c\u3002"}}
{"id": "2602.00769", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00769", "abs": "https://arxiv.org/abs/2602.00769", "authors": ["Siyu Yan", "Lusha Zhu", "Jian-Qiao Zhu"], "title": "Eliciting Trustworthiness Priors of Large Language Models via Economic Games", "comment": null, "summary": "One critical aspect of building human-centered, trustworthy artificial intelligence (AI) systems is maintaining calibrated trust: appropriate reliance on AI systems outperforms both overtrust (e.g., automation bias) and undertrust (e.g., disuse). A fundamental challenge, however, is how to characterize the level of trust exhibited by an AI system itself. Here, we propose a novel elicitation method based on iterated in-context learning (Zhu and Griffiths, 2024a) and apply it to elicit trustworthiness priors using the Trust Game from behavioral game theory. The Trust Game is particularly well suited for this purpose because it operationalizes trust as voluntary exposure to risk based on beliefs about another agent, rather than self-reported attitudes. Using our method, we elicit trustworthiness priors from several leading large language models (LLMs) and find that GPT-4.1's trustworthiness priors closely track those observed in humans. Building on this result, we further examine how GPT-4.1 responds to different player personas in the Trust Game, providing an initial characterization of how such models differentiate trust across agent characteristics. Finally, we show that variation in elicited trustworthiness can be well predicted by a stereotype-based model grounded in perceived warmth and competence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8fed\u4ee3\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u4efb\u535a\u5f08\u523b\u753b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u4efb\u8868\u73b0\uff0c\u53d1\u73b0GPT-4.1\u7684\u4fe1\u4efb\u884c\u4e3a\u4e0e\u4eba\u7c7b\u63a5\u8fd1\uff0c\u5e76\u80fd\u6839\u636e\u73a9\u5bb6\u7279\u5f81\u8c03\u6574\u4fe1\u4efb\uff0c\u4fe1\u4efb\u5dee\u5f02\u53ef\u7531\u523b\u677f\u5370\u8c61\u6a21\u578b\u89e3\u91ca\u3002", "motivation": "\u6784\u5efa\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u3001\u503c\u5f97\u4fe1\u8d56\u7684AI\u7cfb\u7edf\u7684\u5173\u952e\u5728\u4e8e\u7ef4\u6301\u6821\u51c6\u7684\u4fe1\u4efb\uff0c\u4f46\u5982\u4f55\u8868\u5f81AI\u7cfb\u7edf\u81ea\u8eab\u7684\u4fe1\u4efb\u6c34\u5e73\u662f\u4e00\u5927\u6311\u6218\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8fed\u4ee3\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u521b\u65b0\u5f15\u51fa\u65b9\u6cd5\uff0c\u7ed3\u5408\u884c\u4e3a\u535a\u5f08\u8bba\u4e2d\u7684\u4fe1\u4efb\u535a\u5f08\uff0c\u6765\u523b\u753bAI\u7cfb\u7edf\u8868\u73b0\u51fa\u7684\u4fe1\u4efb\u6c34\u5e73\u3002", "result": "GPT-4.1\u5728\u4fe1\u4efb\u535a\u5f08\u4e2d\u8868\u73b0\u51fa\u7684\u53ef\u4fe1\u8d56\u6027\u5148\u9a8c\u4e0e\u4eba\u7c7b\u76f8\u4f3c\uff0c\u4e14\u53ef\u4ee5\u533a\u5206\u4e0d\u540c\u73a9\u5bb6\u7279\u8d28\uff0c\u5bf9\u4fe1\u4efb\u7684\u53d8\u5316\u80fd\u88ab\u57fa\u4e8e\u523b\u677f\u5370\u8c61\u7684\u6e29\u6696\u5ea6\u548c\u80fd\u529b\u611f\u77e5\u6a21\u578b\u5f88\u597d\u9884\u6d4b\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u57fa\u4e8e\u8fed\u4ee3\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u4ece\u884c\u4e3a\u535a\u5f08\u8bba\u4e2d\u7684\u4fe1\u4efb\u535a\u5f08\u4e2d\u5f15\u51fa\u5927\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4.1\uff09\u7684\u53ef\u4fe1\u8d56\u6027\u5148\u9a8c\uff0c\u4e14GPT-4.1\u7684\u53ef\u4fe1\u8d56\u6027\u5148\u9a8c\u4e0e\u4eba\u7c7b\u9ad8\u5ea6\u5339\u914d\u3002"}}
{"id": "2602.00770", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00770", "abs": "https://arxiv.org/abs/2602.00770", "authors": ["Siyuan Zhang", "Jialian Li", "Yichi Zhang", "Xiao Yang", "Yinpeng Dong", "Hang Su"], "title": "Reasoning as State Transition: A Representational Analysis of Reasoning Evolution in Large Language Models", "comment": "30 pages, 27 figures, 8 tables", "summary": "Large Language Models have achieved remarkable performance on reasoning tasks, motivating research into how this ability evolves during training. Prior work has primarily analyzed this evolution via explicit generation outcomes, treating the reasoning process as a black box and obscuring internal changes. To address this opacity, we introduce a representational perspective to investigate the dynamics of the model's internal states. Through comprehensive experiments across models at various training stages, we discover that post-training yields only limited improvement in static initial representation quality. Furthermore, we reveal that, distinct from non-reasoning tasks, reasoning involves a significant continuous distributional shift in representations during generation. Comparative analysis indicates that post-training empowers models to drive this transition toward a better distribution for task solving. To clarify the relationship between internal states and external outputs, statistical analysis confirms a high correlation between generation correctness and the final representations; while counterfactual experiments identify the semantics of the generated tokens, rather than additional computation during inference or intrinsic parameter differences, as the dominant driver of the transition. Collectively, we offer a novel understanding of the reasoning process and the effect of training on reasoning enhancement, providing valuable insights for future model analysis and optimization.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u5185\u90e8\u72b6\u6001\u7684\u52a8\u6001\u53d8\u5316\uff0c\u63ed\u793a\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u8868\u5f81\u7684\u8fde\u7eed\u8f6c\u53d8\u53ca\u5176\u4e0e\u63a8\u7406\u6027\u80fd\u7684\u5173\u7cfb\uff0c\u6307\u51fa\u8bad\u7ec3\u63d0\u5347\u63a8\u7406\u80fd\u529b\u5173\u952e\u5728\u4e8e\u4fc3\u8fdb\u8868\u5f81\u5206\u5e03\u7684\u8f6c\u53d8\uff0c\u63d0\u4f9b\u4e86\u65b0\u7684\u63a8\u7406\u673a\u5236\u7406\u89e3\u89c6\u89d2\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u901a\u8fc7\u751f\u6210\u7ed3\u679c\u5206\u6790\u63a8\u7406\u80fd\u529b\uff0c\u5ffd\u89c6\u4e86\u6a21\u578b\u5185\u90e8\u72b6\u6001\u7684\u53d8\u5316\uff0c\u5bfc\u81f4\u5bf9\u63a8\u7406\u80fd\u529b\u63d0\u5347\u8fc7\u7a0b\u7684\u7406\u89e3\u4e0d\u5b8c\u6574\u3002", "method": "\u901a\u8fc7\u5bf9\u4e0d\u540c\u8bad\u7ec3\u9636\u6bb5\u6a21\u578b\u7684\u5185\u5728\u72b6\u6001\u8fdb\u884c\u4ee3\u8868\u6027\u89c6\u89d2\u7684\u5206\u6790\u548c\u7edf\u8ba1\u6d4b\u8bd5\uff0c\u7ed3\u5408\u53cd\u4e8b\u5b9e\u5b9e\u9a8c\uff0c\u63a2\u7a76\u5185\u90e8\u8868\u5f81\u5728\u63a8\u7406\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u540e\u671f\u8bad\u7ec3\u5bf9\u9759\u6001\u521d\u59cb\u8868\u5f81\u5f71\u54cd\u6709\u9650\uff0c\u63a8\u7406\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8868\u793a\u5206\u5e03\u8f6c\u53d8\uff0c\u8bad\u7ec3\u901a\u8fc7\u4fc3\u8fdb\u5206\u5e03\u8f6c\u53d8\u63d0\u5347\u63a8\u7406\u6027\u80fd\uff0c\u5185\u90e8\u8868\u5f81\u4e0e\u6b63\u786e\u751f\u6210\u9ad8\u5ea6\u76f8\u5173\uff0c\u8bed\u4e49\u5185\u5bb9\u800c\u975e\u8ba1\u7b97\u91cf\u6216\u53c2\u6570\u5dee\u5f02\u4e3b\u5bfc\u8fd9\u4e00\u8fc7\u7a0b\u3002", "conclusion": "\u8bad\u7ec3\u8fc7\u7a0b\u540e\u671f\u5bf9\u6a21\u578b\u5185\u90e8\u521d\u59cb\u8868\u5f81\u7684\u63d0\u5347\u6709\u9650\uff0c\u4f46\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u5f81\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8fde\u7eed\u5206\u5e03\u8f6c\u53d8\uff0c\u8bad\u7ec3\u589e\u5f3a\u4e86\u8fd9\u79cd\u8f6c\u53d8\uff0c\u8fdb\u800c\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002\u6700\u7ec8\u6a21\u578b\u7684\u5185\u90e8\u8868\u5f81\u4e0e\u751f\u6210\u6b63\u786e\u6027\u9ad8\u5ea6\u76f8\u5173\uff0c\u4e14\u751f\u6210\u7684\u8bed\u4e49\u662f\u9a71\u52a8\u5185\u5728\u72b6\u6001\u53d8\u5316\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2602.00777", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00777", "abs": "https://arxiv.org/abs/2602.00777", "authors": ["Xuan Ai", "Qingqing Yang", "Peng Wang", "Lei Deng", "Lin Zhang", "Renhai Chen", "Gong Zhang"], "title": "HyLRA: Hybrid Layer Reuse Attention for Efficient Long-Context Inference", "comment": null, "summary": "Long-context inference in Large Language Models (LLMs) is bottlenecked by the quadratic computation complexity of attention and the substantial memory footprint of Key-Value (KV) caches. While existing sparse attention mechanisms attempt to mitigate this by exploiting inherent sparsity, they often rely on rigid patterns or aggressive pruning, failing to achieve an optimal balance between efficiency and accuracy. In this paper, we introduce {\\bf HyLRA} ({\\bf Hy}brid {\\bf L}ayer {\\bf R}euse {\\bf A}ttention), a novel framework driven by layer-wise sparsity profiling. Our empirical analysis uncovers a dual characteristic in attention mechanics: \\textit{intra-layer sensitivity}, where specific layers necessitate full attention to prevent feature distortion, and \\textit{inter-layer similarity}, where consecutive layers share substantial critical tokens. Based on these observations, HyLRA employs an offline dynamic programming approach to derive an optimal layer-wise policy. This hybrid strategy retains full attention for sensitive layers to ensure robustness, while enabling tolerant layers to bypass quadratic calculations by directly reusing top-$k$ indices from preceding layers. This approach allows LLMs to restrict computation to the most critical tokens, effectively overcoming the quadratic bottleneck of dense attention. Extensive evaluations demonstrate that HyLRA improves inference throughput by 6\\%--46\\% while maintaining comparable performance (with $<1\\%$ accuracy degradation), consistently outperforming state-of-the-art sparse attention methods. HyLRA is open source at \\href{https://anonymous.4open.science/r/unified-cache-management-CF80/}{\\texttt{/r/unified-cache-management-CF80/}}", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5c42\u654f\u611f\u548c\u5c42\u95f4\u76f8\u4f3c\u7684\u6df7\u5408\u91cd\u7528\u6ce8\u610f\u529b\u673a\u5236HyLRA\uff0c\u6709\u6548\u7a81\u7834LLM\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u89e3\u51b3LLM\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7a20\u5bc6\u6ce8\u610f\u529b\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u548cKV\u7f13\u5b58\u5b58\u50a8\u5f00\u9500\u5927\u7684\u74f6\u9888\uff0c\u73b0\u6709\u7a00\u758f\u65b9\u6cd5\u6548\u7387\u4e0e\u7cbe\u5ea6\u96be\u517c\u987e\u3002", "method": "\u57fa\u4e8e\u5c42\u654f\u611f\u6027\u548c\u5c42\u95f4\u76f8\u4f3c\u6027\uff0c\u91c7\u7528\u79bb\u7ebf\u52a8\u6001\u89c4\u5212\uff0c\u6df7\u5408\u4f7f\u7528\u5168\u5173\u6ce8\u5c42\u548c\u91cd\u7528\u524d\u5c42top-k\u7d22\u5f15\u7684\u7a00\u758f\u673a\u5236\u3002", "result": "HyLRA\u63a8\u7406\u541e\u5410\u91cf\u63d0\u53476%--46%\uff0c\u7cbe\u5ea6\u964d\u4f4e\u5c0f\u4e8e1%\uff0c\u4f18\u4e8e\u5f53\u524d\u5148\u8fdb\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002", "conclusion": "HyLRA\u901a\u8fc7\u5c42\u95f4\u7a00\u758f\u6027\u5206\u6790\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u541e\u5410\u91cf\u4e14\u7cbe\u5ea6\u635f\u5931\u6781\u5c0f\u3002"}}
{"id": "2602.00846", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00846", "abs": "https://arxiv.org/abs/2602.00846", "authors": ["Zicheng Kong", "Dehua Ma", "Zhenbo Xu", "Alven Yang", "Yiwei Ru", "Haoran Wang", "Zixuan Zhou", "Fuqing Bie", "Liuyu Xiang", "Huijia Wu", "Jian Zhao", "Zhaofeng He"], "title": "Omni-RRM: Advancing Omni Reward Modeling via Automatic Rubric-Grounded Preference Synthesis", "comment": null, "summary": "Multimodal large language models (MLLMs) have shown remarkable capabilities, yet their performance is often capped by the coarse nature of existing alignment techniques. A critical bottleneck remains the lack of effective reward models (RMs): existing RMs are predominantly vision-centric, return opaque scalar scores, and rely on costly human annotations. We introduce \\textbf{Omni-RRM}, the first open-source rubric-grounded reward model that produces structured, multi-dimension preference judgments with dimension-wise justifications across \\textbf{text, image, video, and audio}. At the core of our approach is \\textbf{Omni-Preference}, a large-scale dataset built via a fully automated pipeline: we synthesize candidate response pairs by contrasting models of different capabilities, and use strong teacher models to \\emph{reconcile and filter} preferences while providing a modality-aware \\emph{rubric-grounded rationale} for each pair. This eliminates the need for human-labeled training preferences. Omni-RRM is trained in two stages: supervised fine-tuning to learn the rubric-grounded outputs, followed by reinforcement learning (GRPO) to sharpen discrimination on difficult, low-contrast pairs. Comprehensive evaluations show that Omni-RRM achieves state-of-the-art accuracy on video (80.2\\% on ShareGPT-V) and audio (66.8\\% on Audio-HH-RLHF) benchmarks, and substantially outperforms existing open-source RMs on image tasks, with a 17.7\\% absolute gain over its base model on overall accuracy. Omni-RRM also improves downstream performance via Best-of-$N$ selection and transfers to text-only preference benchmarks. Our data, code, and models are available at https://anonymous.4open.science/r/Omni-RRM-CC08.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u5f00\u6e90\u7684\u591a\u6a21\u6001\u591a\u7ef4\u5ea6\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u5956\u52b1\u6a21\u578bOmni-RRM\uff0c\u5229\u7528\u81ea\u52a8\u5316\u6570\u636e\u6784\u5efa\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5224\u65ad\u51c6\u786e\u7387\u548c\u4e0b\u6e38\u8868\u73b0\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u7684\u591a\u9879\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u53d7\u9650\u4e8e\u7c97\u7cd9\u7684\u5bf9\u9f50\u6280\u672f\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u3001\u7ed3\u6784\u6027\u660e\u6670\u4e14\u4e0d\u4f9d\u8d56\u6602\u8d35\u4eba\u5de5\u6ce8\u91ca\u7684\u5956\u52b1\u6a21\u578b\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u591a\u6a21\u6001\u7684\u591a\u7ef4\u5ea6\u8bc4\u4ef7\u3002", "method": "\u63d0\u51fa\u4e86Omni-RRM\u6a21\u578b\uff0c\u5229\u7528Omni-Preference\u5927\u89c4\u6a21\u81ea\u52a8\u751f\u6210\u7684\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u548c\u57fa\u4e8e\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\uff08GRPO\uff09\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u751f\u6210\u591a\u7ef4\u5ea6\u5e26\u6709\u7406\u7531\u7684\u504f\u597d\u5224\u65ad\uff0c\u6d88\u9664\u4e86\u5bf9\u4eba\u5de5\u6807\u6ce8\u7684\u4f9d\u8d56\u3002", "result": "Omni-RRM\u5728\u89c6\u9891\uff08ShareGPT-V 80.2%\uff09\u3001\u97f3\u9891\uff08Audio-HH-RLHF 66.8%\uff09\u548c\u56fe\u50cf\u4efb\u52a1\u4e0a\u5747\u8fbe\u5230\u6216\u8d85\u8fc7\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff0c\u56fe\u50cf\u4efb\u52a1\u51c6\u786e\u7387\u8f83\u57fa\u7ebf\u6a21\u578b\u63d0\u534717.7%\uff0c\u5e76\u4e14\u5728\u6587\u672c\u504f\u597d\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "Omni-RRM\u4f5c\u4e3a\u7b2c\u4e00\u6b3e\u5f00\u6e90\u7684\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u591a\u6a21\u6001\u5956\u52b1\u6a21\u578b\uff0c\u5728\u591a\u79cd\u6a21\u6001\uff08\u6587\u672c\u3001\u56fe\u50cf\u3001\u89c6\u9891\u548c\u97f3\u9891\uff09\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u5347\u4e86\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2602.00848", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00848", "abs": "https://arxiv.org/abs/2602.00848", "authors": ["Ziwei Gong", "Yanda Chen", "Julia Hirschberg", "Chen Zhao", "He He", "Zhou Yu", "Kathleen Mckeown"], "title": "Factuality on Demand: Controlling the Factuality-Informativeness Trade-off in Text Generation", "comment": null, "summary": "Large language models (LLMs) encode knowledge with varying degrees of confidence. When responding to queries, models face an inherent trade-off: they can generate responses that are less informative but highly factual, or more informative but potentially less accurate. Different applications demand different balances between informativeness and factuality. We introduce Factuality-Controlled Generation (FCG), a framework that enables users to specify factuality constraints alongside their queries. We propose to evaluate FCG performance on two dimensions: adherence to factuality constraints and response informativeness. We propose to train models on the FCG task using synthetic data, and show that our synthetic training significantly improves models' ability to both respect factuality requirements and maintain informativeness in their outputs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e8b\u5b9e\u6027\u63a7\u5236\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u751f\u6210\u6587\u672c\u65f6\u80fd\u6309\u7167\u7528\u6237\u6307\u5b9a\u7684\u4e8b\u5b9e\u6027\u8981\u6c42\u5e73\u8861\u51c6\u786e\u6027\u4e0e\u4fe1\u606f\u91cf\uff0c\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u9700\u6c42\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u56de\u7b54\u65f6\u5b58\u5728\u4e8b\u5b9e\u6027\u4e0e\u4fe1\u606f\u91cf\u7684\u6743\u8861\uff0c\u4e0d\u540c\u5e94\u7528\u5bf9\u4e8c\u8005\u7684\u9700\u6c42\u4e0d\u540c\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u8ba9\u7528\u6237\u53ef\u4ee5\u6307\u5b9a\u4e8b\u5b9e\u6027\u7ea6\u675f\u3002", "method": "\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3\u6a21\u578b\uff0c\u4f7f\u5176\u5728\u4e8b\u5b9e\u6027\u63a7\u5236\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u80fd\u591f\u9075\u5b88\u4e8b\u5b9e\u6027\u7ea6\u675f\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u4fe1\u606f\u91cf\u3002", "result": "\u5408\u6210\u8bad\u7ec3\u6570\u636e\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u9075\u5b88\u4e8b\u5b9e\u6027\u7ea6\u675f\u548c\u4fdd\u6301\u7b54\u590d\u4fe1\u606f\u91cf\u65b9\u9762\u7684\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86FCG\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e8b\u5b9e\u6027\u63a7\u5236\u751f\u6210(FCG)\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e73\u8861\u751f\u6210\u6587\u672c\u7684\u4e8b\u5b9e\u6027\u548c\u4fe1\u606f\u91cf\uff0c\u6ee1\u8db3\u4e0d\u540c\u5e94\u7528\u5bf9\u6587\u672c\u8d28\u91cf\u7684\u9700\u6c42\u3002"}}
{"id": "2602.00857", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.00857", "abs": "https://arxiv.org/abs/2602.00857", "authors": ["Manveer Singh Tamber", "Hosna Oyarhoseini", "Jimmy Lin"], "title": "Unifying Adversarial Robustness and Training Across Text Scoring Models", "comment": null, "summary": "Research on adversarial robustness in language models is currently fragmented across applications and attacks, obscuring shared vulnerabilities. In this work, we propose unifying the study of adversarial robustness in text scoring models spanning dense retrievers, rerankers, and reward models. This motivates adapting both attacks and adversarial training methods across model roles. Unlike open-ended generation, text scoring failures are directly testable: an attack succeeds when an irrelevant or rejected text outscores a relevant or chosen one. Using this principled lens of text scoring, we demonstrate that current adversarial training formulations for language models are often short-sighted, failing to effectively generalize across attacks. To address this, we introduce multiple adversarial training methods for text scoring models and show that combining complementary training methods can yield strong robustness while also improving task effectiveness. We also highlight the practical value of our approach for RLHF, showing that our adversarially trained reward models mitigate reward hacking and support the training of better-aligned LLMs. We provide our code and models for further study.", "AI": {"tldr": "\u672c\u6587\u7edf\u4e00\u7814\u7a76\u6587\u672c\u8bc4\u5206\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u591a\u91cd\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u5e76\u6709\u6548\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u548c\u4efb\u52a1\u8868\u73b0\uff0c\u540c\u65f6\u7f13\u89e3\u5956\u52b1\u6a21\u578b\u4e2d\u7684\u5956\u52b1\u80e1\u4e71\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u9488\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u7814\u7a76\u5206\u6563\u5728\u4e0d\u540c\u7684\u5e94\u7528\u548c\u653b\u51fb\u65b9\u6cd5\u4e2d\uff0c\u96be\u4ee5\u63ed\u793a\u6a21\u578b\u7684\u5171\u901a\u5f31\u70b9\u3002", "method": "\u63d0\u51fa\u7edf\u4e00\u7684\u6587\u672c\u8bc4\u5206\u6a21\u578b\uff08\u5305\u62ec\u7a20\u5bc6\u68c0\u7d22\u5668\u3001\u91cd\u6392\u5e8f\u5668\u548c\u5956\u52b1\u6a21\u578b\uff09\u7684\u5bf9\u6297\u653b\u51fb\u4e0e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u53d1\u5c55\u591a\u79cd\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\u5e76\u7ed3\u5408\u4f7f\u7528\u4ee5\u63d0\u9ad8\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u6539\u8fdb\u4efb\u52a1\u6027\u80fd\u3002", "result": "\u8bc1\u660e\u73b0\u6709\u7684\u5bf9\u6297\u8bad\u7ec3\u65b9\u6cd5\u666e\u904d\u7f3a\u4e4f\u5bf9\u591a\u6837\u653b\u51fb\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u6240\u63d0\u51fa\u7684\u591a\u65b9\u6cd5\u7ed3\u5408\u8bad\u7ec3\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u4efb\u52a1\u8868\u73b0\uff0c\u5e76\u5728\u5f3a\u5316\u5b66\u4e60\u4e2d\u6709\u6548\u7f13\u89e3\u4e86\u5956\u52b1\u64cd\u7eb5\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u89c6\u89d2\u548c\u591a\u6837\u5316\u5bf9\u6297\u8bad\u7ec3\u7b56\u7565\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6587\u672c\u8bc4\u5206\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u4efb\u52a1\u6548\u679c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.00881", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00881", "abs": "https://arxiv.org/abs/2602.00881", "authors": ["Shounak Paul", "Raghav Dogra", "Pawan Goyal", "Saptarshi Ghosh"], "title": "ILSIC: Corpora for Identifying Indian Legal Statutes from Queries by Laypeople", "comment": "9 Pages of Main, 1 page of Limitations and Ethics Statement, 11 Pages of Appendix, Accepted for Publication at EACL 2026 (Findings)", "summary": "Legal Statute Identification (LSI) for a given situation is one of the most fundamental tasks in Legal NLP. This task has traditionally been modeled using facts from court judgments as input queries, due to their abundance. However, in practical settings, the input queries are likely to be informal and asked by laypersons, or non-professionals. While a few laypeople LSI datasets exist, there has been little research to explore the differences between court and laypeople data for LSI. In this work, we create ILSIC, a corpus of laypeople queries covering 500+ statutes from Indian law. Additionally, the corpus also contains court case judgements to enable researchers to effectively compare between court and laypeople data for LSI. We conducted extensive experiments on our corpus, including benchmarking over the laypeople dataset using zero and few-shot inference, retrieval-augmented generation and supervised fine-tuning. We observe that models trained purely on court judgements are ineffective during test on laypeople queries, while transfer learning from court to laypeople data can be beneficial in certain scenarios. We also conducted fine-grained analyses of our results in terms of categories of queries and frequency of statutes.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u5370\u5ea6\u6cd5\u5f8b\u6761\u6587\u548c\u666e\u901a\u7528\u6237\u67e5\u8be2\u8bed\u6599\u5e93\uff0c\u53d1\u73b0\u6cd5\u9662\u5224\u51b3\u8bad\u7ec3\u6a21\u578b\u96be\u4ee5\u5e94\u5bf9\u975e\u4e13\u4e1a\u67e5\u8be2\uff0c\u8fc1\u79fb\u5b66\u4e60\u80fd\u6709\u6240\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5927\u591a\u7528\u6cd5\u9662\u5224\u51b3\u6587\u672c\u4f5c\u4e3a\u8f93\u5165\u8fdb\u884c\u6cd5\u5f8b\u6761\u6587\u8bc6\u522b\uff0c\u5ffd\u89c6\u4e86\u5b9e\u9645\u5e94\u7528\u4e2d\u975e\u4e13\u4e1a\u666e\u901a\u7528\u6237\u67e5\u8be2\u7684\u975e\u6b63\u5f0f\u6027\uff0c\u7f3a\u4e4f\u5bf9\u4e24\u7c7b\u6570\u636e\u5dee\u5f02\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u6784\u5efa\u5305\u542b\u5370\u5ea6500+\u6cd5\u5f8b\u6761\u6587\u7684\u666e\u901a\u7528\u6237\u67e5\u8be2\u53ca\u6cd5\u9662\u5224\u51b3\u7684\u8bed\u6599\u5e93ILISC\uff0c\u4f7f\u7528\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u63a8\u7406\u3001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u548c\u76d1\u7763\u5fae\u8c03\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u7814\u53d1\u4e86ILISC\u8bed\u6599\u5e93\uff0c\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6cd5\u9662\u5224\u51b3\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u666e\u901a\u7528\u6237\u67e5\u8be2\u4e0a\u7684\u8868\u73b0\u4e0d\u4f73\uff0c\u8fc1\u79fb\u5b66\u4e60\u53ef\u4ee5\u6539\u5584\u90e8\u5206\u60c5\u51b5\uff0c\u540c\u65f6\u5bf9\u67e5\u8be2\u7c7b\u522b\u548c\u6cd5\u5f8b\u6761\u6587\u9891\u7387\u8fdb\u884c\u7ec6\u81f4\u5206\u6790\u3002", "conclusion": "\u6cd5\u9662\u5224\u51b3\u6587\u672c\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u5904\u7406\u666e\u901a\u7528\u6237\u67e5\u8be2\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4f46\u901a\u8fc7\u8fc1\u79fb\u5b66\u4e60\u53ef\u4ee5\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u63d0\u9ad8\u8868\u73b0\u3002"}}
{"id": "2602.00887", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00887", "abs": "https://arxiv.org/abs/2602.00887", "authors": ["Gaurav Srivastava", "Aafiya Hussain", "Chi Wang", "Yingyan Celine Lin", "Xuan Wang"], "title": "EffGen: Enabling Small Language Models as Capable Autonomous Agents", "comment": null, "summary": "Most existing language model agentic systems today are built and optimized for large language models (e.g., GPT, Claude, Gemini) via API calls. While powerful, this approach faces several limitations including high token costs and privacy concerns for sensitive applications. We introduce effGen, an open-source agentic framework optimized for small language models (SLMs) that enables effective, efficient, and secure local deployment (pip install effgen). effGen makes four major contributions: (1) Enhanced tool-calling with prompt optimization that compresses contexts by 70-80% while preserving task semantics, (2) Intelligent task decomposition that breaks complex queries into parallel or sequential subtasks based on dependencies, (3) Complexity-based routing using five factors to make smart pre-execution decisions, and (4) Unified memory system combining short-term, long-term, and vector-based storage. Additionally, effGen unifies multiple agent protocols (MCP, A2A, ACP) for cross-protocol communication. Results on 13 benchmarks show effGen outperforms LangChain, AutoGen, and Smolagents with higher success rates, faster execution, and lower memory. Our results reveal that prompt optimization and complexity routing have complementary scaling behavior: optimization benefits SLMs more (11.2% gain at 1.5B vs 2.4% at 32B), while routing benefits large models more (3.6% at 1.5B vs 7.9% at 32B), providing consistent gains across all scales when combined. effGen (https://effgen.org/) is released under the MIT License, ensuring broad accessibility for research and commercial use. Our framework code is publicly available at https://github.com/ctrl-gaurav/effGen.", "AI": {"tldr": "effGen\u662f\u4e00\u4e2a\u9488\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u5f00\u6e90\u4ee3\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u63d0\u793a\u4f18\u5316\u3001\u4efb\u52a1\u5206\u89e3\u3001\u590d\u6742\u5ea6\u8def\u7531\u548c\u7edf\u4e00\u8bb0\u5fc6\uff0c\u63d0\u5347\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u540c\u7c7b\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7cfb\u7edf\u4f9d\u8d56API\u8c03\u7528\uff0c\u5e26\u6765\u9ad8\u6210\u672c\u53ca\u9690\u79c1\u98ce\u9669\uff0c\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u5b89\u5168\u7684\u4ee3\u7406\u6846\u67b6\u9002\u7528\u4e8e\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u56db\u5927\u6838\u5fc3\u6280\u672f\uff1a\u4f18\u5316\u63d0\u793a\u8bcd\u538b\u7f29\u4e0a\u4e0b\u6587\u3001\u667a\u80fd\u4efb\u52a1\u5206\u89e3\u3001\u57fa\u4e8e\u590d\u6742\u5ea6\u7684\u8def\u7531\u51b3\u7b56\u548c\u7edf\u4e00\u8bb0\u5fc6\u7ba1\u7406\uff0c\u5e76\u652f\u6301\u591a\u534f\u8bae\u901a\u4fe1\uff0c\u5b9e\u73b0\u7cfb\u7edf\u6574\u4f53\u6027\u80fd\u63d0\u5347\u3002", "result": "\u572813\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0ceffGen\u8868\u73b0\u4f18\u4e8eLangChain\u3001AutoGen\u548cSmolagents\uff0c\u5177\u6709\u66f4\u9ad8\u6210\u529f\u7387\u3001\u66f4\u5feb\u6267\u884c\u901f\u5ea6\u548c\u66f4\u4f4e\u5185\u5b58\u6d88\u8017\uff0c\u4e14\u5728\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u901a\u8fc7\u4f18\u5316\u548c\u8def\u7531\u5b9e\u73b0\u4e92\u8865\u63d0\u5347\u3002", "conclusion": "effGen\u6846\u67b6\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u5b89\u5168\u548c\u672c\u5730\u90e8\u7f72\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5de5\u5177\u8c03\u7528\u3001\u4efb\u52a1\u5206\u89e3\u3001\u590d\u6742\u5ea6\u8def\u7531\u548c\u7edf\u4e00\u8bb0\u5fc6\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u76f8\u8f83\u73b0\u6709\u7cfb\u7edf\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2602.00913", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00913", "abs": "https://arxiv.org/abs/2602.00913", "authors": ["V\u00edctor Yeste", "Paolo Rosso"], "title": "Do Schwartz Higher-Order Values Help Sentence-Level Human Value Detection? When Hard Gating Hurts", "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 42 pages, 4 figures", "summary": "Sentence-level human value detection is typically framed as multi-label classification over Schwartz values, but it remains unclear whether Schwartz higher-order (HO) categories provide usable structure. We study this under a strict compute-frugal budget (single 8 GB GPU) on ValueEval'24 / ValuesML (74K English sentences). We compare (i) direct supervised transformers, (ii) HO$\\rightarrow$values pipelines that enforce the hierarchy with hard masks, and (iii) Presence$\\rightarrow$HO$\\rightarrow$values cascades, alongside low-cost add-ons (lexica, short context, topics), label-wise threshold tuning, small instruction-tuned LLM baselines ($\\le$10B), QLoRA, and simple ensembles. HO categories are learnable from single sentences (e.g., the easiest bipolar pair reaches Macro-$F_1\\approx0.58$), but hard hierarchical gating is not a reliable win: it often reduces end-task Macro-$F_1$ via error compounding and recall suppression. In contrast, label-wise threshold tuning is a high-leverage knob (up to $+0.05$ Macro-$F_1$), and small transformer ensembles provide the most consistent additional gains (up to $+0.02$ Macro-$F_1$). Small LLMs lag behind supervised encoders as stand-alone systems, yet can contribute complementary errors in cross-family ensembles. Overall, HO structure is useful descriptively, but enforcing it with hard gates hurts sentence-level value detection; robust improvements come from calibration and lightweight ensembling.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u65bd\u74e6\u8328\u9ad8\u9636\u7c7b\u522b\u7ed3\u6784\u867d\u7136\u6709\u63cf\u8ff0\u6027\u4ef7\u503c\uff0c\u4f46\u786c\u6027\u5e94\u7528\u5c42\u6b21\u7ed3\u6784\u53cd\u800c\u524a\u5f31\u53e5\u5b50\u7ea7\u4ef7\u503c\u68c0\u6d4b\u6548\u679c\u3002\u901a\u8fc7\u6807\u7b7e\u9608\u503c\u4f18\u5316\u548c\u8f7b\u91cf\u7ea7\u6a21\u578b\u96c6\u6210\u80fd\u5e26\u6765\u7a33\u5065\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u63a2\u7a76\u5728\u53e5\u5b50\u7ea7\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u4e2d\uff0c\u65bd\u74e6\u8328\uff08Schwartz\uff09\u9ad8\u9636\u7c7b\u522b\u7ed3\u6784\u662f\u5426\u80fd\u63d0\u4f9b\u6709\u6548\u7684\u5c42\u6b21\u4fe1\u606f\u5e76\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\uff08\u5355\u4e2a8GB GPU\uff09\u4e0b\uff0c\u4f7f\u7528\u76f4\u63a5\u76d1\u7763\u7684Transformer\u6a21\u578b\u3001\u786c\u63a9\u7801\u5c42\u6b21\u7ed3\u6784\u7684HO\u5230\u4ef7\u503c\u7ba1\u9053\u3001\u4ee5\u53ca\u5b58\u5728-\u300bHO-\u300b\u4ef7\u503c\u7ea7\u8054\u65b9\u6cd5\uff0c\u7ed3\u5408\u8bcd\u5178\u3001\u77ed\u4e0a\u4e0b\u6587\u3001\u4e3b\u9898\u3001\u6807\u7b7e\u9608\u503c\u8c03\u6574\u3001\u5c0f\u578b\u6307\u4ee4\u8c03\u4f18LLM\uff08\u226410B\uff09\u3001QLoRA\u548c\u7b80\u5355\u96c6\u6210\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "HO\u7c7b\u522b\u53ef\u4ee5\u4ece\u5355\u53e5\u4e2d\u5b66\u4e60\uff0c\u4f46\u786c\u6027\u5c42\u6b21\u8fc7\u6ee4\u901a\u5e38\u964d\u4f4e\u6700\u7ec8\u4efb\u52a1\u7684Macro-F1\u5206\u6570\uff1b\u6807\u7b7e\u9608\u503c\u8c03\u6574\u548c\u5c0f\u578bTransformer\u96c6\u6210\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u5c0f\u578bLLM\u8868\u73b0\u843d\u540e\u4f46\u5728\u8de8\u6a21\u578b\u96c6\u6210\u4e2d\u80fd\u8865\u5145\u9519\u8bef\u3002", "conclusion": "\u9ad8\u9636\uff08HO\uff09\u7ed3\u6784\u5bf9\u63cf\u8ff0\u6027\u6709\u7528\uff0c\u4f46\u901a\u8fc7\u786c\u9650\u5236\u6267\u884c\u5c42\u6b21\u7ed3\u6784\u5bf9\u53e5\u5b50\u7ea7\u4ef7\u503c\u68c0\u6d4b\u4e0d\u5229\uff1b\u7a33\u5065\u7684\u63d0\u5347\u6765\u81ea\u4e8e\u6807\u7b7e\u9608\u503c\u8c03\u6574\u548c\u8f7b\u91cf\u7ea7\u96c6\u6210\u65b9\u6cd5\u3002"}}
{"id": "2602.00914", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.00914", "abs": "https://arxiv.org/abs/2602.00914", "authors": ["V\u00edctor Yeste", "Rodrigo Rivas-Ar\u00e9valo"], "title": "A Baseline Multimodal Approach to Emotion Recognition in Conversations", "comment": "10 pages", "summary": "We present a lightweight multimodal baseline for emotion recognition in conversations using the SemEval-2024 Task 3 dataset built from the sitcom Friends. The goal of this report is not to propose a novel state-of-the-art method, but to document an accessible reference implementation that combines (i) a transformer-based text classifier and (ii) a self-supervised speech representation model, with a simple late-fusion ensemble. We report the baseline setup and empirical results obtained under a limited training protocol, highlighting when multimodal fusion improves over unimodal models. This preprint is provided for transparency and to support future, more rigorous comparisons.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u6587\u672cTransformer\u548c\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u57fa\u7ebf\uff0c\u9a8c\u8bc1\u4e86\u591a\u6a21\u6001\u878d\u5408\u8f83\u5355\u6a21\u6001\u66f4\u6709\u6548\uff0c\u4f9b\u672a\u6765\u7814\u7a76\u5bf9\u6bd4\u4f7f\u7528\u3002", "motivation": "\u4e3a\u4e86\u63d0\u4f9b\u4e00\u4e2a\u6613\u4e8e\u53c2\u8003\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u57fa\u7ebf\uff0c\u5b9e\u73b0\u900f\u660e\u4e14\u4fbf\u4e8e\u672a\u6765\u4e25\u8c28\u6bd4\u8f83\u3002", "method": "\u7ed3\u5408\u57fa\u4e8eTransformer\u7684\u6587\u672c\u5206\u7c7b\u5668\u548c\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u6a21\u578b\uff0c\u4f7f\u7528\u7b80\u5355\u7684\u540e\u671f\u878d\u5408\u96c6\u6210\u65b9\u6cd5\u3002", "result": "\u5728\u6709\u9650\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0c\u591a\u6a21\u6001\u878d\u5408\u6a21\u578b\u8868\u73b0\u8d85\u8fc7\u5355\u6a21\u6001\u6a21\u578b\u3002", "conclusion": "\u672c\u5de5\u4f5c\u672a\u63d0\u51fa\u65b0\u9896\u65b9\u6cd5\uff0c\u800c\u662f\u8bb0\u5f55\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u4e14\u6613\u5b9e\u73b0\u7684\u591a\u6a21\u6001\u60c5\u611f\u8bc6\u522b\u57fa\u7ebf\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2602.00945", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00945", "abs": "https://arxiv.org/abs/2602.00945", "authors": ["Anusa Saha", "Tanmay Joshi", "Vinija Jain", "Aman Chadha", "Amitava Das"], "title": "Neural FOXP2 -- Language Specific Neuron Steering for Targeted Language Improvement in LLMs", "comment": null, "summary": "LLMs are multilingual by training, yet their lingua franca is often English, reflecting English language dominance in pretraining. Other languages remain in parametric memory but are systematically suppressed. We argue that language defaultness is governed by a sparse, low-rank control circuit, language neurons, that can be mechanistically isolated and safely steered.\n  We introduce Neural FOXP2, that makes a chosen language (Hindi or Spanish) primary in a model by steering language-specific neurons. Neural FOXP2 proceeds in three stages: (i) Localize: We train per-layer SAEs so each activation decomposes into a small set of active feature components. For every feature, we quantify English vs. Hindi/Spanish selectivity overall logit-mass lift toward the target-language token set. Tracing the top-ranked features back to their strongest contributing units yields a compact language-neuron set. (ii) Steering directions: We localize controllable language-shift geometry via a spectral low-rank analysis. For each layer, we build English to target activation-difference matrices and perform layerwise SVD to extract the dominant singular directions governing language change. The eigengap and effective-rank spectra identify a compact steering subspace and an empirically chosen intervention window (where these directions are strongest and most stable). (iii) Steer: We apply a signed, sparse activation shift targeted to the language neurons. Concretely, within low to mid layers we add a positive steering along the target-language dominant directions and a compensating negative shift toward the null space for the English neurons, yielding controllable target-language defaultness.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0LLMs\u9ed8\u8ba4\u8bed\u8a00\u7531\u5c11\u91cf\u8bed\u8a00\u795e\u7ecf\u5143\u63a7\u5236\uff0c\u63d0\u51faNeural FOXP2\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b9a\u4f4d\u8bed\u8a00\u795e\u7ecf\u5143\u548c\u65bd\u52a0\u7a00\u758f\u6fc0\u6d3b\u504f\u79fb\uff0c\u5b9e\u73b0\u8bed\u8a00\u9ed8\u8ba4\u6027\u7684\u53ef\u63a7\u5207\u6362\uff0c\u5c06\u82f1\u8bed\u4e3b\u5bfc\u8f6c\u6362\u4e3a\u5370\u5730\u8bed\u6216\u897f\u73ed\u7259\u8bed\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u6a21\u578b\u7684\u5e73\u8861\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u7ecf\u8fc7\u591a\u8bed\u79cd\u8bad\u7ec3\uff0c\u4f46\u5176\u9ed8\u8ba4\u8bed\u8a00\u591a\u4e3a\u82f1\u8bed\uff0c\u5176\u4ed6\u8bed\u8a00\u88ab\u7cfb\u7edf\u6027\u6291\u5236\uff0c\u7f3a\u4e4f\u5bf9\u975e\u82f1\u8bed\u8bed\u8a00\u7684\u6709\u6548\u6fc0\u6d3b\u4e0e\u63a7\u5236\u3002", "method": "\u63d0\u51faNeural FOXP2\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u673a\u5236\u63a7\u5236\u7279\u5b9a\u8bed\u8a00\u795e\u7ecf\u5143\uff1a\u9996\u5148\u5b9a\u4f4d\u5404\u5c42\u4e2d\u7279\u5b9a\u8bed\u8a00\u7279\u5f81\u7684\u6d3b\u8dc3\u795e\u7ecf\u5143\uff1b\u5176\u6b21\u901a\u8fc7\u8c31\u4f4e\u79e9\u5206\u6790\u63d0\u53d6\u8bed\u8a00\u8f6c\u6362\u7684\u4e3b\u5bfc\u65b9\u5411\uff1b\u6700\u540e\u5bf9\u7279\u5b9a\u5c42\u65bd\u52a0\u6709\u5411\u7a00\u758f\u6fc0\u6d3b\u504f\u79fb\uff0c\u5b9e\u73b0\u8bed\u8a00\u504f\u597d\u7684\u53ef\u63a7\u5207\u6362\u3002", "result": "\u6210\u529f\u5c06\u6307\u5b9a\u975e\u82f1\u8bed\u8bed\u8a00\uff08\u5370\u5730\u8bed\u6216\u897f\u73ed\u7259\u8bed\uff09\u8bbe\u4e3a\u6a21\u578b\u9ed8\u8ba4\u8bed\u8a00\uff0c\u5b9e\u73b0\u5bf9\u6a21\u578b\u8bed\u8a00\u9ed8\u8ba4\u6027\u7684\u6709\u6548\u5e72\u9884\u548c\u53ef\u63a7\u5207\u6362\uff0c\u9a8c\u8bc1\u4e86\u8bed\u8a00\u795e\u7ecf\u5143\u548c\u63a7\u5236\u56de\u8def\u7684\u5b58\u5728\u53ca\u5176\u53ef\u64cd\u63a7\u6027\u3002", "conclusion": "\u8bed\u8a00\u7684\u9ed8\u8ba4\u6027\u7531\u7a00\u758f\u4f4e\u79e9\u7684\u8bed\u8a00\u795e\u7ecf\u5143\u63a7\u5236\u56de\u8def\u51b3\u5b9a\uff0cNeural FOXP2\u901a\u8fc7\u5b9a\u4f4d\u548c\u5b9a\u5411\u64cd\u63a7\u8fd9\u4e9b\u795e\u7ecf\u5143\uff0c\u80fd\u591f\u5b89\u5168\u6709\u6548\u5730\u5b9e\u73b0\u6a21\u578b\u8bed\u8a00\u9ed8\u8ba4\u6027\u7684\u8f6c\u6362\uff0c\u4fc3\u8fdb\u591a\u8bed\u8a00\u6a21\u578b\u66f4\u516c\u5e73\u3001\u591a\u6837\u7684\u8bed\u8a00\u8868\u73b0\u3002"}}
{"id": "2602.00970", "categories": ["cs.CL", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.00970", "abs": "https://arxiv.org/abs/2602.00970", "authors": ["Saaduddin Mahmud", "Eugene Bagdasarian", "Shlomo Zilberstein"], "title": "Verification Required: The Impact of Information Credibility on AI Persuasion", "comment": "19 pages, 5 figures", "summary": "Agents powered by large language models (LLMs) are increasingly deployed in settings where communication shapes high-stakes decisions, making a principled understanding of strategic communication essential. Prior work largely studies either unverifiable cheap-talk or fully verifiable disclosure, failing to capture realistic domains in which information has probabilistic credibility. We introduce MixTalk, a strategic communication game for LLM-to-LLM interaction that models information credibility. In MixTalk, a sender agent strategically combines verifiable and unverifiable claims to communicate private information, while a receiver agent allocates a limited budget to costly verification and infers the underlying state from prior beliefs, claims, and verification outcomes. We evaluate state-of-the-art LLM agents in large-scale tournaments across three realistic deployment settings, revealing their strengths and limitations in reasoning about information credibility and the explicit behavior that shapes these interactions. Finally, we propose Tournament Oracle Policy Distillation (TOPD), an offline method that distills tournament oracle policy from interaction logs and deploys it in-context at inference time. Our results show that TOPD significantly improves receiver robustness to persuasion.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMixTalk\u6e38\u620f\u6a21\u62df\u4fe1\u606f\u53ef\u4fe1\u5ea6\uff0c\u8bc4\u4f30LLM\u5728\u6218\u7565\u6c9f\u901a\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u901a\u8fc7TOPD\u65b9\u6cd5\u63d0\u5347\u4e86\u63a5\u6536\u65b9\u5bf9\u8bf4\u670d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u7eaf\u5ec9\u4ef7\u4fe1\u53f7\u6216\u5b8c\u5168\u53ef\u9a8c\u8bc1\u4fe1\u606f\uff0c\u7f3a\u4e4f\u5bf9\u4fe1\u606f\u5177\u6709\u6982\u7387\u53ef\u4fe1\u5ea6\u7684\u771f\u5b9e\u573a\u666f\u5efa\u6a21\uff1b\u9700\u6c42\u5efa\u7acb\u5bf9\u6218\u7565\u6c9f\u901a\u4e0b\u4fe1\u606f\u53ef\u4fe1\u5ea6\u7684\u7cfb\u7edf\u7406\u89e3\u3002", "method": "\u8bbe\u8ba1\u4e86MixTalk\u6218\u7565\u6c9f\u901a\u6e38\u620f\uff0c\u7ed3\u5408\u53ef\u9a8c\u8bc1\u4e0e\u4e0d\u53ef\u9a8c\u8bc1\u7684\u4fe1\u606f\uff1b\u8fdb\u884c\u5927\u89c4\u6a21\u591a\u6a21\u578b\u9526\u6807\u8d5b\u8bc4\u6d4b\uff1b\u5f15\u5165TOPD\u65b9\u6cd5\u901a\u8fc7\u79bb\u7ebf\u84b8\u998f\u9526\u6807\u8d5b\u6700\u4f18\u7b56\u7565\u7528\u4e8e\u63a8\u7406\u65f6\u7684\u4e0a\u4e0b\u6587\u90e8\u7f72\u3002", "result": "\u901a\u8fc7MixTalk\u5c55\u793a\u4e86\u591a\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u53ef\u4fe1\u5ea6\u63a8\u7406\u65b9\u9762\u7684\u6027\u80fd\u5dee\u5f02\uff1bTOPD\u663e\u8457\u589e\u5f3a\u4e86\u63a5\u6536\u65b9\u6a21\u578b\u62b5\u6297\u8bf4\u670d\u7684\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684MixTalk\u6846\u67b6\u6210\u529f\u6a21\u62df\u4e86\u4fe1\u606f\u53ef\u4fe1\u5ea6\u5bf9\u6218\u7565\u6c9f\u901a\u7684\u5f71\u54cd\uff0c\u5c55\u73b0\u4e86\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4fe1\u606f\u53ef\u4fe1\u5ea6\u65f6\u7684\u4f18\u52a3\u3002\u901a\u8fc7TOPD\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u63a5\u6536\u65b9\u5bf9\u8bf4\u670d\u7b56\u7565\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.00977", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00977", "abs": "https://arxiv.org/abs/2602.00977", "authors": ["Pengyue Yang", "Jiawen Wen", "Haolin Jin", "Linghan Huang", "Huaming Chen", "Ling Chen"], "title": "Trust in One Round: Confidence Estimation for Large Language Models via Structural Signals", "comment": "Accepted at The ACM Web Conference 2026 (WWW 2026)", "summary": "Large language models (LLMs) are increasingly deployed in domains where errors carry high social, scientific, or safety costs. Yet standard confidence estimators, such as token likelihood, semantic similarity and multi-sample consistency, remain brittle under distribution shift, domain-specialised text, and compute limits. In this work, we present Structural Confidence, a single-pass, model-agnostic framework that enhances output correctness prediction based on multi-scale structural signals derived from a model's final-layer hidden-state trajectory. By combining spectral, local-variation, and global shape descriptors, our method captures internal stability patterns that are missed by probabilities and sentence embeddings. We conduct extensive, cross-domain evaluation across four heterogeneous benchmarks-FEVER (fact verification), SciFact (scientific claims), WikiBio-hallucination (biographical consistency), and TruthfulQA (truthfulness-oriented QA). Our Structural Confidence framework demonstrates strong performance compared with established baselines in terms of AUROC and AUPR. More importantly, unlike sampling-based consistency methods which require multiple stochastic generations and an auxiliary model, our approach uses a single deterministic forward pass, offering a practical basis for efficient, robust post-hoc confidence estimation in socially impactful, resource-constrained LLM applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u6784\u7f6e\u4fe1\u5ea6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u9690\u85cf\u72b6\u6001\u7ed3\u6784\u7279\u5f81\uff0c\u5b9e\u73b0\u5355\u6b21\u524d\u5411\u4f20\u64ad\u7684\u9c81\u68d2\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9886\u57df\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u9884\u6d4b\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9ad8\u98ce\u9669\u9886\u57df\u5e94\u7528\u65f6\uff0c\u73b0\u6709\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5728\u5206\u5e03\u8f6c\u79fb\u3001\u9886\u57df\u4e13\u7528\u6587\u672c\u53ca\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u7ed3\u6784\u7f6e\u4fe1\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u6a21\u578b\u6700\u540e\u4e00\u5c42\u9690\u85cf\u72b6\u6001\u7684\u591a\u5c3a\u5ea6\u7ed3\u6784\u4fe1\u53f7\uff08\u5305\u62ec\u8c31\u7279\u5f81\u3001\u5c40\u90e8\u53d8\u5316\u548c\u5168\u5c40\u5f62\u72b6\u63cf\u8ff0\u7b26\uff09\u6765\u63d0\u5347\u8f93\u51fa\u6b63\u786e\u6027\u9884\u6d4b\u3002", "result": "\u5728\u56db\u4e2a\u8de8\u9886\u57df\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7ed3\u6784\u7f6e\u4fe1\u5ea6\u6846\u67b6\u5728AUROC\u548cAUPR\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u53ea\u9700\u5355\u6b21\u786e\u5b9a\u6027\u524d\u5411\u4f20\u64ad\uff0c\u6548\u7387\u66f4\u9ad8\u3002", "conclusion": "\u7ed3\u6784\u7f6e\u4fe1\u5ea6\u4e3a\u8d44\u6e90\u53d7\u9650\u548c\u793e\u4f1a\u5f71\u54cd\u5927\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u540e\u7f6e\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6848\uff0c\u514b\u670d\u4e86\u91c7\u6837\u4e00\u81f4\u6027\u65b9\u6cd5\u7684\u591a\u6b21\u751f\u6210\u548c\u8f85\u52a9\u6a21\u578b\u9700\u6c42\u3002"}}
{"id": "2602.00981", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00981", "abs": "https://arxiv.org/abs/2602.00981", "authors": ["Yutong Song", "Shiva Shrestha", "Chenhan Lyu", "Elahe Khatibi", "Pengfei Zhang", "Honghui Xu", "Nikil Dutt", "Amir Rahmani"], "title": "MedSpeak: A Knowledge Graph-Aided ASR Error Correction Framework for Spoken Medical QA", "comment": null, "summary": "Spoken question-answering (SQA) systems relying on automatic speech recognition (ASR) often struggle with accurately recognizing medical terminology. To this end, we propose MedSpeak, a novel knowledge graph-aided ASR error correction framework that refines noisy transcripts and improves downstream answer prediction by leveraging both semantic relationships and phonetic information encoded in a medical knowledge graph, together with the reasoning power of LLMs. Comprehensive experimental results on benchmarks demonstrate that MedSpeak significantly improves the accuracy of medical term recognition and overall medical SQA performance, establishing MedSpeak as a state-of-the-art solution for medical SQA. The code is available at https://github.com/RainieLLM/MedSpeak.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u533b\u7597\u77e5\u8bc6\u56fe\u8c31\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u9519\u8bef\u7ea0\u6b63\u6846\u67b6MedSpeak\uff0c\u6709\u6548\u63d0\u5347\u4e86\u533b\u7597\u95ee\u7b54\u7cfb\u7edf\u7684\u672f\u8bed\u8bc6\u522b\u548c\u6574\u4f53\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u4f9d\u8d56\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u7684\u533b\u7597\u95ee\u7b54\u7cfb\u7edf\u5728\u8bc6\u522b\u533b\u7597\u672f\u8bed\u65f6\u51c6\u786e\u7387\u8f83\u4f4e\uff0c\u5f71\u54cd\u4e86\u56de\u7b54\u7684\u51c6\u786e\u6027\u3002", "method": "\u7ed3\u5408\u533b\u7597\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8bed\u4e49\u5173\u7cfb\u548c\u8bed\u97f3\u4fe1\u606f\uff0c\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u9519\u8bef\u7ea0\u6b63\u6846\u67b6\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMedSpeak\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u672f\u8bed\u7684\u8bc6\u522b\u51c6\u786e\u7387\u548c\u95ee\u7b54\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "conclusion": "MedSpeak\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u533b\u7597\u672f\u8bed\u8bc6\u522b\u7684\u51c6\u786e\u7387\u548c\u533b\u7597\u95ee\u7b54\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\uff0c\u6210\u4e3a\u9886\u57df\u5185\u7684\u5148\u8fdb\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.00983", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.00983", "abs": "https://arxiv.org/abs/2602.00983", "authors": ["Batuhan K. Karaman", "Aditya Rawal", "Suhaila Shakiah", "Mohammad Ghavamzadeh", "Mingyi Hong", "Arijit Biswas", "Ruida Zhou"], "title": "DISPO: Enhancing Training Efficiency and Stability in Reinforcement Learning for Large Language Model Mathematical Reasoning", "comment": "This work is accepted to the 29th International Conference on Artificial Intelligence and Statistics (AISTATS) 2026", "summary": "Reinforcement learning with verifiable rewards has emerged as a promising paradigm for enhancing the reasoning capabilities of large language models particularly in mathematics. Current approaches in this domain present a clear trade-off: PPO-style methods (e.g., GRPO/DAPO) offer training stability but exhibit slow learning trajectories due to their trust-region constraints on policy updates, while REINFORCE-style approaches (e.g., CISPO) demonstrate improved learning efficiency but suffer from performance instability as they clip importance sampling weights while still permitting non-zero gradients outside the trust-region. To address these limitations, we introduce DISPO, a simple yet effective REINFORCE-style algorithm that decouples the up-clipping and down-clipping of importance sampling weights for correct and incorrect responses, yielding four controllable policy update regimes. Through targeted ablations, we uncover how each regime impacts training: for correct responses, weights >1 increase the average token entropy (i.e., exploration) while weights <1 decrease it (i.e., distillation) -- both beneficial but causing gradual performance degradation when excessive. For incorrect responses, overly restrictive clipping triggers sudden performance collapse through repetitive outputs (when weights >1) or vanishing response lengths (when weights <1). By separately tuning these four clipping parameters, DISPO maintains the exploration-distillation balance while preventing catastrophic failures, achieving 61.04% on AIME'24 (vs. 55.42% CISPO and 50.21% DAPO) with similar gains across various benchmarks and models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDISPO\u7b97\u6cd5\uff0c\u901a\u8fc7\u7cbe\u51c6\u8c03\u8282\u6743\u91cd\u526a\u88c1\u7b56\u7565\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u84b8\u998f\uff0c\u6539\u5584\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709PPO\u7c7b\u65b9\u6cd5\u8bad\u7ec3\u7a33\u5b9a\u4f46\u6536\u655b\u6162\uff0cREINFORCE\u7c7b\u65b9\u6cd5\u5b66\u4e60\u6548\u7387\u9ad8\u4f46\u56e0\u6743\u91cd\u526a\u88c1\u5bfc\u81f4\u6027\u80fd\u4e0d\u7a33\u5b9a\uff0c\u9700\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u7a33\u5b9a\u7684\u8bad\u7ec3\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684REINFORCE\u98ce\u683c\u7b97\u6cd5DISPO\uff0c\u901a\u8fc7\u5bf9\u6b63\u786e\u548c\u9519\u8bef\u56de\u7b54\u7684\u6743\u91cd\u5206\u522b\u8fdb\u884c\u4e0a\u526a\u88c1\u548c\u4e0b\u526a\u88c1\uff0c\u5f62\u6210\u56db\u79cd\u53ef\u63a7\u7684\u7b56\u7565\u66f4\u65b0\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u673a\u5236\u5bf9\u8bad\u7ec3\u7684\u5f71\u54cd\u3002", "result": "DISPO\u5728AIME'24\u6570\u5b66\u7ade\u8d5b\u6d4b\u8bd5\u4e2d\u53d6\u5f9761.04%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u8d85\u8fc7CISPO\u768455.42%\u548cDAPO\u768450.21%\uff0c\u5e76\u5728\u591a\u79cd\u57fa\u51c6\u548c\u6a21\u578b\u4e0a\u90fd\u6709\u7c7b\u4f3c\u63d0\u5347\u3002", "conclusion": "DISPO\u7b97\u6cd5\u901a\u8fc7\u72ec\u7acb\u8c03\u8282\u91cd\u8981\u6027\u91c7\u6837\u6743\u91cd\u7684\u4e0a\u9650\u548c\u4e0b\u9650\uff0c\u6709\u6548\u5e73\u8861\u4e86\u63a2\u7d22\u4e0e\u84b8\u998f\uff0c\u907f\u514d\u4e86\u7b56\u7565\u66f4\u65b0\u8fc7\u7a0b\u4e2d\u7684\u707e\u96be\u6027\u5d29\u6e83\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2602.00986", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00986", "abs": "https://arxiv.org/abs/2602.00986", "authors": ["Guowei Xu", "Mert Yuksekgonul", "James Zou"], "title": "Sparse Reward Subsystem in Large Language Models", "comment": null, "summary": "In this paper, we identify a sparse reward subsystem within the hidden states of Large Language Models (LLMs), drawing an analogy to the biological reward subsystem in the human brain. We demonstrate that this subsystem contains value neurons that represent the model's internal expectation of state value, and through intervention experiments, we establish the importance of these neurons for reasoning. Our experiments reveal that these value neurons are robust across diverse datasets, model scales, and architectures; furthermore, they exhibit significant transferability across different datasets and models fine-tuned from the same base model. By examining cases where value predictions and actual rewards diverge, we identify dopamine neurons within the reward subsystem which encode reward prediction errors (RPE). These neurons exhibit high activation when the reward is higher than expected and low activation when the reward is lower than expected.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5e76\u9a8c\u8bc1\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u9690\u85cf\u7684\u4ef7\u503c\u795e\u7ecf\u5143\u53ca\u5176\u5bf9\u63a8\u7406\u7684\u5173\u952e\u4f5c\u7528\uff0c\u5e76\u8bc6\u522b\u4e86\u7f16\u7801\u5956\u52b1\u9884\u6d4b\u8bef\u5dee\u7684\u591a\u5df4\u80fa\u795e\u7ecf\u5143\uff0c\u63ed\u793a\u4e86LLM\u5185\u90e8\u7684\u5956\u52b1\u673a\u5236\u3002", "motivation": "\u7c7b\u6bd4\u4eba\u7c7b\u5927\u8111\u4e2d\u7684\u751f\u7269\u5956\u52b1\u7cfb\u7edf\uff0c\u63a2\u7a76LLM\u5185\u90e8\u662f\u5426\u5b58\u5728\u7c7b\u4f3c\u7684\u5956\u52b1\u795e\u7ecf\u5143\u53ca\u5176\u5bf9\u6a21\u578b\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5bf9LLM\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u5956\u52b1\u5b50\u7cfb\u7edf\u8fdb\u884c\u5e72\u9884\u5b9e\u9a8c\uff0c\u68c0\u6d4b\u4e0d\u540c\u6570\u636e\u96c6\u3001\u6a21\u578b\u89c4\u6a21\u4e0e\u7ed3\u6784\u4e0a\u7684\u4ef7\u503c\u795e\u7ecf\u5143\u8868\u73b0\uff0c\u5e76\u5206\u6790\u9884\u6d4b\u5956\u52b1\u4e0e\u5b9e\u9645\u5956\u52b1\u4e0d\u4e00\u81f4\u65f6\u795e\u7ecf\u5143\u7684\u6fc0\u6d3b\u60c5\u51b5\u3002", "result": "\u53d1\u73b0LLM\u4e2d\u5b58\u5728\u7a00\u758f\u7684\u4ef7\u503c\u795e\u7ecf\u5143\uff0c\u80fd\u591f\u51c6\u786e\u53cd\u6620\u72b6\u6001\u4ef7\u503c\u5e76\u5728\u4e0d\u540c\u6a21\u578b\u53ca\u6570\u636e\u96c6\u95f4\u5177\u6709\u9c81\u68d2\u6027\u4e0e\u8fc1\u79fb\u6027\uff1b\u540c\u65f6\u8bc6\u522b\u51fa\u7f16\u7801\u5956\u52b1\u9884\u6d4b\u8bef\u5dee\u7684\u591a\u5df4\u80fa\u6837\u795e\u7ecf\u5143\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u7814\u7a76\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u7684\u7a00\u758f\u5956\u52b1\u5b50\u7cfb\u7edf\uff0c\u786e\u8ba4\u4e86\u5176\u5185\u90e8\u7684\u4ef7\u503c\u795e\u7ecf\u5143\u5bf9\u63a8\u7406\u7684\u91cd\u8981\u6027\uff0c\u5e76\u53d1\u73b0\u5956\u8d4f\u9884\u6d4b\u8bef\u5dee\u7531\u7c7b\u4f3c\u591a\u5df4\u80fa\u795e\u7ecf\u5143\u7684\u795e\u7ecf\u5143\u7f16\u7801\u3002"}}
{"id": "2602.00996", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.00996", "abs": "https://arxiv.org/abs/2602.00996", "authors": ["Abhijit Chakraborty", "Ashish Raj Shekhar", "Shiven Agarwal", "Vivek Gupta"], "title": "DeALOG: Decentralized Multi-Agents Log-Mediated Reasoning Framework", "comment": null, "summary": "Complex question answering across text, tables and images requires integrating diverse information sources. A framework supporting specialized processing with coordination and interpretability is needed. We introduce DeALOG, a decentralized multi-agent framework for multimodal question answering. It uses specialized agents: Table, Context, Visual, Summarizing and Verification, that communicate through a shared natural-language log as persistent memory. This log-based approach enables collaborative error detection and verification without central control, improving robustness. Evaluations on FinQA, TAT-QA, CRT-QA, WikiTableQuestions, FeTaQA, and MultiModalQA show competitive performance. Analysis confirms the importance of the shared log, agent specialization, and verification for accuracy. DeALOG, provides a scalable approach through modular components using natural-language communication.", "AI": {"tldr": "DeALOG\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u81ea\u7136\u8bed\u8a00\u65e5\u5fd7\u534f\u8c03\u7684\u591a\u6a21\u6001\u95ee\u7b54\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u534f\u540c\u548c\u9c81\u68d2\u6027\u7684\u590d\u6742\u8de8\u6a21\u6001\u95ee\u7b54\u3002", "motivation": "\u590d\u6742\u95ee\u7b54\u9700\u8981\u878d\u5408\u6587\u672c\u3001\u8868\u683c\u548c\u56fe\u50cf\u7b49\u591a\u79cd\u4fe1\u606f\u6e90\uff0c\u4e14\u9700\u652f\u6301\u4e13\u95e8\u5316\u5904\u7406\u548c\u89e3\u91ca\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u534f\u8c03\u591a\u6a21\u6001\u4fe1\u606f\u3002", "method": "\u5f15\u5165\u5305\u542b\u8868\u683c\u3001\u4e0a\u4e0b\u6587\u3001\u89c6\u89c9\u3001\u603b\u7ed3\u548c\u9a8c\u8bc1\u7b49\u4e13\u95e8\u4ee3\u7406\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u8fd9\u4e9b\u4ee3\u7406\u901a\u8fc7\u5171\u4eab\u7684\u81ea\u7136\u8bed\u8a00\u65e5\u5fd7\u8fdb\u884c\u4ea4\u4e92\uff0c\u652f\u6301\u9519\u8bef\u68c0\u6d4b\u548c\u9a8c\u8bc1\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\uff08FinQA\u3001TAT-QA\u7b49\uff09\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u5206\u6790\u786e\u8ba4\u5171\u4eab\u65e5\u5fd7\u3001\u4ee3\u7406\u4e13\u95e8\u5316\u53ca\u9a8c\u8bc1\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u56de\u7b54\u51c6\u786e\u7387\u3002", "conclusion": "DeALOG\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u6a21\u5757\u7684\u81ea\u7136\u8bed\u8a00\u65e5\u5fd7\u5171\u4eab\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u590d\u6742\u95ee\u7b54\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5b9e\u73b0\u4e86\u6a21\u5757\u5316\u53ef\u6269\u5c55\u7684\u591a\u6e90\u4fe1\u606f\u96c6\u6210\u3002"}}
{"id": "2602.00998", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.00998", "abs": "https://arxiv.org/abs/2602.00998", "authors": ["Zhikun Xu", "Xiaodong Yu", "Ben Zhou", "Jiang Liu", "Jialian Wu", "Ze Wang", "Ximeng Sun", "Hao Chen", "Zicheng Liu"], "title": "Reliable Use of Lemmas via Eligibility Reasoning and Section$-$Aware Reinforcement Learning", "comment": null, "summary": "Recent large language models (LLMs) perform strongly on mathematical benchmarks yet often misapply lemmas, importing conclusions without validating assumptions. We formalize lemma$-$judging as a structured prediction task: given a statement and a candidate lemma, the model must output a precondition check and a conclusion$-$utility check, from which a usefulness decision is derived. We present RULES, which encodes this specification via a two$-$section output and trains with reinforcement learning plus section$-$aware loss masking to assign penalty to the section responsible for errors. Training and evaluation draw on diverse natural language and formal proof corpora; robustness is assessed with a held$-$out perturbation suite; and end$-$to$-$end evaluation spans competition$-$style, perturbation$-$aligned, and theorem$-$based problems across various LLMs. Results show consistent in$-$domain gains over both a vanilla model and a single$-$label RL baseline, larger improvements on applicability$-$breaking perturbations, and parity or modest gains on end$-$to$-$end tasks; ablations indicate that the two$-$section outputs and section$-$aware reinforcement are both necessary for robustness.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bef\u7528\u5f15\u7406\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faRULES\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cc\u90e8\u5206\u8f93\u51fa\u548c\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u5f15\u7406\u9002\u7528\u6027\u5224\u65ad\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u573a\u666f\u548c\u9c81\u68d2\u6027\u6d4b\u8bd5\u4e2d\u7684\u6709\u6548\u6027\u548c\u4f18\u52bf\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u5e38\u5e38\u9519\u8bef\u5e94\u7528\u5f15\u7406\uff0c\u672a\u7ecf\u9a8c\u8bc1\u5047\u8bbe\u4fbf\u5bfc\u5165\u7ed3\u8bba\uff0c\u5bfc\u81f4\u63a8\u7406\u4e0d\u51c6\u786e\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6709\u6548\u5224\u65ad\u5f15\u7406\u7684\u9002\u7528\u6027\u3002", "method": "\u5c06\u5f15\u7406\u5224\u65ad\u4efb\u52a1\u5f62\u5f0f\u5316\u4e3a\u7ed3\u6784\u5316\u9884\u6d4b\u95ee\u9898\uff0c\u8bbe\u8ba1\u53cc\u90e8\u5206\u8f93\u51fa\u7ed3\u6784\uff0c\u5e76\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u90e8\u5206\u611f\u77e5\u635f\u5931\u5c4f\u853d\u6280\u672f\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u51c6\u786e\u8bc6\u522b\u9519\u8bef\u90e8\u5206\u5e76\u8d4b\u4e88\u76f8\u5e94\u60e9\u7f5a\u3002", "result": "\u5728\u591a\u6837\u5316\u81ea\u7136\u8bed\u8a00\u548c\u5f62\u5f0f\u8bc1\u660e\u8bed\u6599\u4e0a\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0cRULES\u5728\u4fdd\u6301\u8d5b\u5185\u4e00\u81f4\u63d0\u5347\uff0c\u540c\u65f6\u5bf9\u5e94\u7528\u7834\u574f\u6027\u6270\u52a8\u6709\u66f4\u5927\u6539\u5584\uff0c\u5e76\u5728\u7aef\u5230\u7aef\u4efb\u52a1\u4e2d\u4e0e\u57fa\u7ebf\u6a21\u578b\u6301\u5e73\u6216\u7565\u6709\u63d0\u5347\u3002\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u96d9\u90e8\u5206\u8f93\u51fa\u548c\u90e8\u5206\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u662f\u5b9e\u73b0\u9c81\u68d2\u6027\u7684\u5173\u952e\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684RULES\u65b9\u6cd5\u5728\u5224\u65ad\u5f15\u7406\u7684\u9002\u7528\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u5f15\u7406\u524d\u63d0\u68c0\u67e5\u548c\u7ed3\u8bba\u6709\u6548\u6027\u7684\u5224\u65ad\u80fd\u529b\uff0c\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6270\u52a8\u73af\u5883\u4e0b\u5747\u663e\u793a\u51fa\u9c81\u68d2\u6027\u548c\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2602.01007", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01007", "abs": "https://arxiv.org/abs/2602.01007", "authors": ["Zishuo Bao", "Jiaqi Leng", "Junxiong Wang", "Bowen Peng", "Yucheng Lu"], "title": "Distilling Token-Trained Models into Byte-Level Models", "comment": "17 pages, 3 figures, 13 tables", "summary": "Byte Language Models (BLMs) have emerged as a promising direction for scaling language models beyond tokenization. However, existing BLMs typically require training from scratch on trillions of bytes, making them prohibitively expensive. In this paper, we propose an efficient distillation recipe that converts existing token-trained LLMs into BLMs while retaining comparable capabilities. Our recipe follows a two-stage curriculum: (1) Progressive Knowledge Distillation, which aligns byte-level representations with the embeddings of the token-trained teacher model; and (2) Byte-Level Supervised Fine-Tuning, which enables end-to-end generation entirely in the byte space. We validate our approach across multiple model families, including Llama, Qwen, and OLMo, and demonstrate that the distilled BLMs retain most of the teacher models' performance using only approximately 125B bytes.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u84b8\u998f\u65b9\u6cd5\uff0c\u5c06\u6807\u8bb0\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u8f6c\u6362\u4e3a\u5b57\u8282\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u4e14\u6027\u80fd\u76f8\u5f53\u7684\u5b57\u8282\u7ea7\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u7684\u5b57\u8282\u8bed\u8a00\u6a21\u578b\uff08BLMs\uff09\u8bad\u7ec3\u6210\u672c\u6781\u9ad8\uff0c\u9700\u8981\u5728\u6570\u4e07\u4ebf\u5b57\u8282\u4e0a\u4ece\u5934\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u9ad8\u6548\u84b8\u998f\u65b9\u6cd5\uff1a\u4e00\u662f\u9010\u6b65\u77e5\u8bc6\u84b8\u998f\uff0c\u5c06\u5b57\u8282\u7ea7\u8868\u793a\u4e0e\u57fa\u4e8e\u6807\u8bb0\u8bad\u7ec3\u7684\u5927\u6a21\u578b\u7684\u5d4c\u5165\u5bf9\u9f50\uff1b\u4e8c\u662f\u5b57\u8282\u7ea7\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u5b9e\u73b0\u5b8c\u5168\u5b57\u8282\u7a7a\u95f4\u7684\u7aef\u5230\u7aef\u751f\u6210\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u5bb6\u65cf\uff08Llama\u3001Qwen\u3001OLMo\uff09\u4e0a\u9a8c\u8bc1\uff0c\u84b8\u998f\u540e\u7684BLMs\u5728\u4ec5\u7528\u7ea6125\u4ebf\u5b57\u8282\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u4fdd\u7559\u5927\u90e8\u5206\u6559\u5e08\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8f6c\u6362\u6807\u8bb0\u8bad\u7ec3\u5927\u6a21\u578b\u4e3a\u5b57\u8282\u8bed\u8a00\u6a21\u578b\u7684\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.01015", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.01015", "abs": "https://arxiv.org/abs/2602.01015", "authors": ["Conrad Borchers", "Jill-J\u00eann Vie", "Roger Azevedo"], "title": "Large Language Models as Students Who Think Aloud: Overly Coherent, Verbose, and Confident", "comment": "Manuscript under review", "summary": "Large language models (LLMs) are increasingly embedded in AI-based tutoring systems. Can they faithfully model novice reasoning and metacognitive judgments? Existing evaluations emphasize problem-solving accuracy, overlooking the fragmented and imperfect reasoning that characterizes human learning. We evaluate LLMs as novices using 630 think-aloud utterances from multi-step chemistry tutoring problems with problem-solving logs of student hint use, attempts, and problem context. We compare LLM-generated reasoning to human learner utterances under minimal and extended contextual prompting, and assess the models' ability to predict step-level learner success. Although GPT-4.1 generates fluent and contextually appropriate continuations, its reasoning is systematically over-coherent, verbose, and less variable than human think-alouds. These effects intensify with a richer problem-solving context during prompting. Learner performance was consistently overestimated. These findings highlight epistemic limitations of simulating learning with LLMs. We attribute these limitations to LLM training data, including expert-like solutions devoid of expressions of affect and working memory constraints during problem solving. Our evaluation framework can guide future design of adaptive systems that more faithfully support novice learning and self-regulation using generative artificial intelligence.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6a21\u62df\u65b0\u624b\u5316\u5b66\u95ee\u9898\u89e3\u51b3\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u63a8\u7406\u8fc7\u4e8e\u8fde\u8d2f\u4e14\u8868\u73b0\u88ab\u9ad8\u4f30\uff0c\u63ed\u793a\u4e86LLM\u8bad\u7ec3\u6570\u636e\u548c\u8ba4\u77e5\u673a\u5236\u7684\u9650\u5236\uff0c\u5efa\u8bae\u672a\u6765\u7cfb\u7edf\u8bbe\u8ba1\u5e94\u66f4\u771f\u5b9e\u5730\u53cd\u6620\u521d\u5b66\u8005\u7684\u5b66\u4e60\u7279\u5f81\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728AI\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u65e5\u76ca\u666e\u53ca\uff0c\u4f46\u5176\u662f\u5426\u80fd\u591f\u771f\u5b9e\u6a21\u62df\u521d\u5b66\u8005\u7684\u63a8\u7406\u548c\u5143\u8ba4\u77e5\u5224\u65ad\u5c1a\u4e0d\u660e\u786e\uff0c\u73b0\u6709\u8bc4\u4f30\u4fa7\u91cd\u4e8e\u95ee\u9898\u89e3\u51b3\u7684\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u5b66\u4e60\u4e2d\u788e\u7247\u5316\u548c\u4e0d\u5b8c\u7f8e\u7684\u63a8\u7406\u7279\u5f81\u3002", "method": "\u5229\u7528630\u6761\u591a\u6b65\u9aa4\u5316\u5b66\u8f85\u5bfc\u4e2d\u5b66\u751f\u7684\u601d\u7ef4\u53e3\u8ff0\uff0c\u7ed3\u5408\u5b66\u751f\u63d0\u793a\u4f7f\u7528\u3001\u5c1d\u8bd5\u6b21\u6570\u548c\u95ee\u9898\u60c5\u5883\uff0c\u6bd4\u8f83LLM\u751f\u6210\u7684\u63a8\u7406\u4e0e\u4eba\u7c7b\u5b66\u4e60\u8005\u5728\u6700\u5c0f\u548c\u6269\u5c55\u4e0a\u4e0b\u6587\u63d0\u793a\u4e0b\u7684\u63a8\u7406\u5dee\u5f02\uff0c\u8bc4\u4f30\u6a21\u578b\u9884\u6d4b\u5b66\u4e60\u8005\u5355\u6b65\u6210\u529f\u7684\u80fd\u529b\u3002", "result": "GPT-4.1\u751f\u6210\u6d41\u7545\u4e14\u8bed\u5883\u9002\u5f53\u7684\u63a8\u7406\uff0c\u4f46\u8868\u73b0\u51fa\u8fc7\u5ea6\u8fde\u8d2f\u3001\u5570\u55e6\u4e14\u53d8\u5f02\u6027\u4f4e\u4e8e\u4eba\u7c7b\u601d\u7ef4\u53e3\u8ff0\uff0c\u4e14\u5728\u589e\u52a0\u95ee\u9898\u80cc\u666f\u4fe1\u606f\u65f6\u8fd9\u4e00\u73b0\u8c61\u52a0\u5267\uff0c\u6a21\u578b\u666e\u904d\u9ad8\u4f30\u4e86\u5b66\u4e60\u8005\u7684\u8868\u73b0\u3002", "conclusion": "LLM\u5728\u6a21\u62df\u521d\u5b66\u8005\u5b66\u4e60\u8fc7\u7a0b\u65f6\u5b58\u5728\u8ba4\u77e5\u548c\u77e5\u8bc6\u5c42\u9762\u9650\u5236\uff0c\u4e3b\u8981\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u504f\u5411\u4e13\u5bb6\u89e3\u51b3\u65b9\u6848\u4e14\u7f3a\u4e4f\u60c5\u611f\u8868\u8fbe\u548c\u5de5\u4f5c\u8bb0\u5fc6\u9650\u5236\uff0c\u8fd9\u5bf9\u8bbe\u8ba1\u66f4\u771f\u5b9e\u652f\u6301\u521d\u5b66\u8005\u5b66\u4e60\u548c\u81ea\u6211\u8c03\u8282\u7684\u81ea\u9002\u5e94\u7cfb\u7edf\u63d0\u51fa\u4e86\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2602.01030", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.01030", "abs": "https://arxiv.org/abs/2602.01030", "authors": ["Sheng-Lun Wei", "Yu-Ling Liao", "Yen-Hua Chang", "Hen-Hsen Huang", "Hsin-Hsi Chen"], "title": "Bias in the Ear of the Listener: Assessing Sensitivity in Audio Language Models Across Linguistic, Demographic, and Positional Variations", "comment": "Accepted as a long findings paper at EACL 2026", "summary": "This work presents the first systematic investigation of speech bias in multilingual MLLMs. We construct and release the BiasInEar dataset, a speech-augmented benchmark based on Global MMLU Lite, spanning English, Chinese, and Korean, balanced by gender and accent, and totaling 70.8 hours ($\\approx$4,249 minutes) of speech with 11,200 questions. Using four complementary metrics (accuracy, entropy, APES, and Fleiss' $\u03ba$), we evaluate nine representative models under linguistic (language and accent), demographic (gender), and structural (option order) perturbations. Our findings reveal that MLLMs are relatively robust to demographic factors but highly sensitive to language and option order, suggesting that speech can amplify existing structural biases. Moreover, architectural design and reasoning strategy substantially affect robustness across languages. Overall, this study establishes a unified framework for assessing fairness and robustness in speech-integrated LLMs, bridging the gap between text- and speech-based evaluation. The resources can be found at https://github.com/ntunlplab/BiasInEar.", "AI": {"tldr": "\u672c\u6587\u6784\u5efaBiasInEar\u8bed\u97f3\u504f\u89c1\u8bc4\u6d4b\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u97f3\u8f93\u5165\u4e0b\u7684\u504f\u89c1\u548c\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u8bed\u8a00\u548c\u9009\u9879\u987a\u5e8f\u654f\u611f\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684\u516c\u5e73\u6027\u8bc4\u4f30\u6846\u67b6\u3002", "motivation": "\u7cfb\u7edf\u6027\u7814\u7a76\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u8bed\u97f3\u504f\u89c1\uff0c\u5f25\u8865\u6587\u672c\u8bc4\u4f30\u4e0e\u8bed\u97f3\u8bc4\u4f30\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e86BiasInEar\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u57fa\u4e8eGlobal MMLU Lite\uff0c\u5305\u542b\u82f1\u8bed\u3001\u4e2d\u6587\u548c\u97e9\u8bed\u7684\u6027\u522b\u548c\u53e3\u97f3\u5e73\u8861\u7684\u8bed\u97f3\u6570\u636e\uff0c\u603b\u8ba170.8\u5c0f\u65f6\uff0c11200\u4e2a\u95ee\u9898\uff0c\u4f7f\u7528\u51c6\u786e\u7387\u3001\u71b5\u503c\u3001APES\u548cFleiss' \u03ba\u56db\u4e2a\u6307\u6807\u8bc4\u4f30\u4e5d\u4e2a\u6a21\u578b\u5728\u8bed\u8a00\u3001\u53e3\u97f3\u3001\u6027\u522b\u548c\u9009\u9879\u987a\u5e8f\u7b49\u6270\u52a8\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4eba\u53e3\u7edf\u8ba1\u5b66\u56e0\u7d20\u8868\u73b0\u51fa\u76f8\u5bf9\u9c81\u68d2\u6027\uff0c\u4f46\u5bf9\u8bed\u8a00\u548c\u9009\u9879\u987a\u5e8f\u9ad8\u5ea6\u654f\u611f\uff0c\u67b6\u6784\u8bbe\u8ba1\u548c\u63a8\u7406\u7b56\u7565\u663e\u8457\u5f71\u54cd\u6a21\u578b\u7684\u8bed\u8a00\u95f4\u9c81\u68d2\u6027\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u5728\u5904\u7406\u8bed\u97f3\u8f93\u5165\u65f6\u5bf9\u8bed\u8a00\u548c\u9009\u9879\u987a\u5e8f\u654f\u611f\uff0c\u8868\u660e\u8bed\u97f3\u53ef\u80fd\u653e\u5927\u5df2\u6709\u7684\u7ed3\u6784\u6027\u504f\u89c1\uff0c\u800c\u5bf9\u6027\u522b\u7b49\u4eba\u53e3\u7edf\u8ba1\u5b66\u56e0\u7d20\u8f83\u4e3a\u9c81\u68d2\u3002"}}
{"id": "2602.01063", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01063", "abs": "https://arxiv.org/abs/2602.01063", "authors": ["Bin Han", "Deuksin Kwon", "Jonathan Gratch"], "title": "Personality Expression Across Contexts: Linguistic and Behavioral Variation in LLM Agents", "comment": null, "summary": "Large Language Models (LLMs) can be conditioned with explicit personality prompts, yet their behavioral realization often varies depending on context. This study examines how identical personality prompts lead to distinct linguistic, behavioral, and emotional outcomes across four conversational settings: ice-breaking, negotiation, group decision, and empathy tasks. Results show that contextual cues systematically influence both personality expression and emotional tone, suggesting that the same traits are expressed differently depending on social and affective demands. This raises an important question for LLM-based dialogue agents: whether such variations reflect inconsistency or context-sensitive adaptation akin to human behavior. Viewed through the lens of Whole Trait Theory, these findings highlight that LLMs exhibit context-sensitive rather than fixed personality expression, adapting flexibly to social interaction goals and affective conditions.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u6839\u636e\u4e0d\u540c\u5bf9\u8bdd\u60c5\u5883\u8c03\u6574\u4eba\u683c\u8868\u8fbe\uff0c\u8868\u73b0\u51fa\u60c5\u5883\u654f\u611f\u7684\u9002\u5e94\u6027\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u884c\u4e3a\uff0c\u800c\u975e\u56fa\u5b9a\u4e0d\u53d8\u7684\u6027\u683c\u3002", "motivation": "\u63a2\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u5728\u4e0d\u540c\u793e\u4ea4\u60c5\u5883\u4e2d\u6839\u636e\u76f8\u540c\u4eba\u683c\u63d0\u793a\u5c55\u73b0\u4e0d\u540c\u7684\u884c\u4e3a\u548c\u60c5\u611f\u8868\u8fbe\u3002", "method": "\u901a\u8fc7\u5728\u56db\u79cd\u5bf9\u8bdd\u60c5\u5883\uff08\u7834\u51b0\u3001\u8c08\u5224\u3001\u7fa4\u4f53\u51b3\u7b56\u548c\u5171\u60c5\u4efb\u52a1\uff09\u4e0b\uff0c\u89c2\u5bdf\u76f8\u540c\u4eba\u683c\u63d0\u793a\u7684\u8bed\u8a00\u548c\u884c\u4e3a\u8868\u73b0\u5dee\u5f02\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u60c5\u5883\u7ebf\u7d22\u7cfb\u7edf\u5730\u5f71\u54cd\u4eba\u683c\u8868\u8fbe\u548c\u60c5\u611f\u8bed\u6c14\uff0c\u8bf4\u660e\u4eba\u683c\u7279\u8d28\u7684\u8868\u8fbe\u4f9d\u8d56\u4e8e\u793e\u4ea4\u548c\u60c5\u611f\u9700\u6c42\u3002", "conclusion": "\u76f8\u540c\u7684\u4eba\u683c\u63d0\u793a\u5728\u4e0d\u540c\u7684\u5bf9\u8bdd\u73af\u5883\u4e2d\u4f1a\u5bfc\u81f4\u8bed\u8a00\u3001\u884c\u4e3a\u548c\u60c5\u611f\u8868\u73b0\u7684\u5dee\u5f02\uff0c\u4f53\u73b0\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u5883\u654f\u611f\u6027\u800c\u975e\u56fa\u5b9a\u4eba\u683c\u8868\u8fbe\u3002"}}
{"id": "2602.01064", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01064", "abs": "https://arxiv.org/abs/2602.01064", "authors": ["Ruihan Jin", "Pengpeng Shao", "Zhengqi Wen", "Jinyang Wu", "Mingkuan Feng", "Shuo Yang", "Chu Yuan Zhang", "Jianhua Tao"], "title": "Exploring Knowledge Purification in Multi-Teacher Knowledge Distillation for LLMs", "comment": null, "summary": "Knowledge distillation has emerged as a pivotal technique for transferring knowledge from stronger large language models (LLMs) to smaller, more efficient models. However, traditional distillation approaches face challenges related to knowledge conflicts and high resource demands, particularly when leveraging multiple teacher models. In this paper, we introduce the concept of \\textbf{Knowledge Purification}, which consolidates the rationales from multiple teacher LLMs into a single rationale, thereby mitigating conflicts and enhancing efficiency. To investigate the effectiveness of knowledge purification, we further propose five purification methods from various perspectives. Our experiments demonstrate that these methods not only improve the performance of the distilled model but also effectively alleviate knowledge conflicts. Moreover, router-based methods exhibit robust generalization capabilities, underscoring the potential of innovative purification techniques in optimizing multi-teacher distillation and facilitating the practical deployment of powerful yet lightweight models.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63d0\u51fa\u77e5\u8bc6\u51c0\u5316\u53ca\u591a\u79cd\u51c0\u5316\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u591a\u6559\u5e08\u84b8\u998f\u7684\u77e5\u8bc6\u51b2\u7a81\u4e0e\u9ad8\u8d44\u6e90\u6d88\u8017\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u548c\u5e94\u7528\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u7684\u77e5\u8bc6\u84b8\u998f\u65b9\u6cd5\u5728\u5229\u7528\u591a\u6559\u5e08\u6a21\u578b\u65f6\u5b58\u5728\u77e5\u8bc6\u51b2\u7a81\u548c\u8d44\u6e90\u6d88\u8017\u5927\u7684\u6311\u6218\uff0c\u4fc3\u4f7f\u4f5c\u8005\u63a2\u7d22\u66f4\u9ad8\u6548\u7edf\u4e00\u7684\u77e5\u8bc6\u8f6c\u79fb\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86\u77e5\u8bc6\u51c0\u5316\u7684\u6982\u5ff5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e94\u79cd\u4e0d\u540c\u7684\u51c0\u5316\u65b9\u6cd5\uff0c\u5176\u4e2d\u57fa\u4e8e\u8def\u7531\u5668\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u77e5\u8bc6\u51c0\u5316\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u5347\u4e86\u84b8\u998f\u6a21\u578b\u6027\u80fd\uff0c\u8fd8\u6709\u6548\u7f13\u89e3\u4e86\u77e5\u8bc6\u51b2\u7a81\uff0c\u7279\u522b\u662f\u8def\u7531\u5668\u65b9\u6cd5\u5177\u6709\u8f83\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u77e5\u8bc6\u51c0\u5316\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6559\u5e08\u77e5\u8bc6\u84b8\u998f\u4e2d\u7684\u77e5\u8bc6\u51b2\u7a81\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u84b8\u998f\u6a21\u578b\u7684\u6027\u80fd\u548c\u8d44\u6e90\u6548\u7387\u3002"}}
{"id": "2602.01068", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01068", "abs": "https://arxiv.org/abs/2602.01068", "authors": ["Chaoqun Cui", "Shijing Wang", "Liangbin Huang", "Qingqing Gu", "Zhaolong Huang", "Xiao Zeng", "Wenji Mao"], "title": "From Utterance to Vividity: Training Expressive Subtitle Translation LLM via Adaptive Local Preference Optimization", "comment": "Accepted to ICLR 2026", "summary": "The rapid development of Large Language Models (LLMs) has significantly enhanced the general capabilities of machine translation. However, as application scenarios become more complex, the limitations of LLMs in vertical domain translations are gradually becoming apparent. In this study, we focus on how to construct translation LLMs that meet the needs of domain customization. We take visual media subtitle translation as our topic and explore how to train expressive and vivid translation LLMs. We investigated the situations of subtitle translation and other domains of literal and liberal translation, verifying the reliability of LLM as reward model and evaluator for translation. Additionally, to train an expressive translation LLM, we constructed and released a multidirectional subtitle parallel corpus dataset and proposed the Adaptive Local Preference Optimization (ALPO) method to address fine-grained preference alignment. Experimental results demonstrate that ALPO achieves outstanding performance in multidimensional evaluation of translation quality.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5782\u76f4\u9886\u57df\u7ffb\u8bd1\u7684\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5b57\u5e55\u7ffb\u8bd1\u7684\u5b9a\u5236\u65b9\u6cd5\u548c\u4f18\u5316\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u7ffb\u8bd1\u8868\u8fbe\u529b\u4e0e\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u673a\u5668\u7ffb\u8bd1\u80fd\u529b\u5f3a\uff0c\u4f46\u5728\u7279\u5b9a\u5782\u76f4\u9886\u57df\u7ffb\u8bd1\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u9700\u63d0\u5347\u5b9a\u5236\u5316\u7ffb\u8bd1\u6548\u679c\u3002", "method": "\u6784\u5efa\u591a\u5411\u5b57\u5e55\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u63d0\u51fa\u81ea\u9002\u5e94\u5c40\u90e8\u504f\u597d\u4f18\u5316(ALPO)\u65b9\u6cd5\uff0c\u8fdb\u884c\u7ec6\u7c92\u5ea6\u504f\u597d\u5bf9\u9f50\u8bad\u7ec3\u3002", "result": "ALPO\u65b9\u6cd5\u5728\u591a\u7ef4\u5ea6\u7ffb\u8bd1\u8d28\u91cf\u8bc4\u4f30\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u9a8c\u8bc1\u4e86LLM\u4f5c\u4e3a\u5956\u52b1\u6a21\u578b\u548c\u8bc4\u4ef7\u8005\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6210\u529f\u6784\u5efa\u4e86\u6ee1\u8db3\u9886\u57df\u5b9a\u5236\u9700\u6c42\u7684\u7ffb\u8bd1\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9\u5a92\u4f53\u5b57\u5e55\u7ffb\u8bd1\u9886\u57df\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.01070", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01070", "abs": "https://arxiv.org/abs/2602.01070", "authors": ["Ahsan Bilal", "Ahmed Mohsin", "Muhammad Umer", "Ali Subhan", "Hassan Rizwan", "Ayesha Mohsin", "Dean Hougen"], "title": "What If We Allocate Test-Time Compute Adaptively?", "comment": null, "summary": "Test-time compute scaling allocates inference computation uniformly, uses fixed sampling strategies, and applies verification only for reranking. In contrast, we propose a verifier-guided adaptive framework treating reasoning as iterative trajectory generation and selection. For each problem, the agent runs multiple inference iterations. In each iteration, it optionally produces a high-level plan, selects a set of reasoning tools and a compute strategy together with an exploration parameter, and then generates a candidate reasoning trajectory. A process reward model (PRM) serves as a unified control signal: within each iteration, step-level PRM scores are aggregated to guide pruning and expansion during generation, and across iterations, aggregated trajectory rewards are used to select the final response. Across datasets, our dynamic, PRM-guided approach consistently outperforms direct test-time scaling, yielding large gains on MATH-500 and several-fold improvements on harder benchmarks such as AIME24 and AMO-Bench. We characterize efficiency using theoretical FLOPs and a compute intensity metric penalizing wasted generation and tool overhead, demonstrating that verification-guided allocation concentrates computation on high-utility reasoning paths.", "AI": {"tldr": "\u672c\u5de5\u4f5c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u7684\u52a8\u6001\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u6b21\u8fed\u4ee3\u548c\u8bc4\u5206\u5f15\u5bfc\u63a8\u7406\u8fdb\u7a0b\uff0c\u5b9e\u73b0\u8ba1\u7b97\u8d44\u6e90\u7684\u81ea\u9002\u5e94\u5206\u914d\uff0c\u5728\u591a\u4e2a\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u65b9\u6cd5\u8ba1\u7b97\u5206\u914d\u5747\u5300\u4e14\u91c7\u6837\u56fa\u5b9a\uff0c\u4e14\u4ec5\u5728\u7ed3\u679c\u91cd\u6392\u65f6\u8fdb\u884c\u9a8c\u8bc1\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u901a\u8fc7\u591a\u6b21\u63a8\u7406\u8fed\u4ee3\uff0c\u5229\u7528PRM\u5728\u6b65\u9aa4\u7ea7\u548c\u8fed\u4ee3\u7ea7\u5bf9\u63a8\u7406\u8f68\u8ff9\u8fdb\u884c\u8bc4\u5206\u548c\u5f15\u5bfc\uff0c\u5b9e\u73b0\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u52a8\u6001\u8ba1\u7b97\u5206\u914d\u4e0e\u8f68\u8ff9\u9009\u62e9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728MATH-500\u3001AIME24\u3001AMO-Bench\u7b49\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8ba1\u7b97\u8d44\u6e90\u96c6\u4e2d\u7528\u4e8e\u9ad8\u6548\u63a8\u7406\u8def\u5f84\uff0c\u63d0\u9ad8\u4e86\u8ba1\u7b97\u5229\u7528\u7387\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\uff08PRM\uff09\u7684\u52a8\u6001\u63a8\u7406\u6846\u67b6\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u7edf\u4e00\u8ba1\u7b97\u5206\u914d\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\u3002"}}
{"id": "2602.01116", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01116", "abs": "https://arxiv.org/abs/2602.01116", "authors": ["Wenxuan Zhang", "Yuan-Hao Jiang", "Changyong Qi", "Rui Jia", "Yonghe Wu"], "title": "Logic-Oriented Retriever Enhancement via Contrastive Learning", "comment": "accepted by icassp 2026", "summary": "Large language models (LLMs) struggle in knowledge-intensive tasks, as retrievers often overfit to surface similarity and fail on queries involving complex logical relations. The capacity for logical analysis is inherent in model representations but remains underutilized in standard training. LORE (Logic ORiented Retriever Enhancement) introduces fine-grained contrastive learning to activate this latent capacity, guiding embeddings toward evidence aligned with logical structure rather than shallow similarity. LORE requires no external upervision, resources, or pre-retrieval analysis, remains index-compatible, and consistently improves retrieval utility and downstream generation while maintaining efficiency. The datasets and code are publicly available at https://github.com/mazehart/Lore-RAG.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u5bc6\u96c6\u4efb\u52a1\u4e2d\u68c0\u7d22\u6548\u679c\u6b20\u4f73\u7684\u95ee\u9898\uff0cLORE\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u6fc0\u6d3b\u903b\u8f91\u5206\u6790\u80fd\u529b\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u8d44\u6e90\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u548c\u751f\u6210\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6d89\u53ca\u590d\u6742\u903b\u8f91\u5173\u7cfb\u7684\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u65f6\u8868\u73b0\u6b20\u4f73\uff0c\u68c0\u7d22\u5668\u4f9d\u8d56\u6d45\u8868\u76f8\u4f3c\u5ea6\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\uff0c\u800c\u6a21\u578b\u6f5c\u85cf\u7684\u903b\u8f91\u5206\u6790\u80fd\u529b\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51faLORE\uff08\u903b\u8f91\u5bfc\u5411\u68c0\u7d22\u589e\u5f3a\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u6307\u5bfc\u5d4c\u5165\u5411\u7b26\u5408\u903b\u8f91\u7ed3\u6784\u7684\u8bc1\u636e\u805a\u96c6\uff0c\u800c\u975e\u6d45\u8868\u76f8\u4f3c\u5ea6\uff0c\u65b9\u6cd5\u65e0\u9700\u989d\u5916\u76d1\u7763\u3001\u8d44\u6e90\u6216\u9884\u68c0\u7d22\u5206\u6790\uff0c\u4e14\u517c\u5bb9\u73b0\u6709\u7d22\u5f15\u67b6\u6784\u3002", "result": "LORE\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u63d0\u5347\u4e86\u68c0\u7d22\u6548\u679c\u548c\u4e0b\u6e38\u751f\u6210\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "LORE\u65b9\u6cd5\u901a\u8fc7\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u5b66\u4e60\u6fc0\u6d3bLLM\u4e2d\u7684\u903b\u8f91\u5206\u6790\u80fd\u529b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8e\u903b\u8f91\u7ed3\u6784\u7684\u68c0\u7d22\u6027\u80fd\uff0c\u6539\u5584\u4e86\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2602.01119", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01119", "abs": "https://arxiv.org/abs/2602.01119", "authors": ["Konstantin Chernyshev", "Ekaterina Artemova", "Viacheslav Zhukov", "Maksim Nerush", "Mariia Fedorova", "Iryna Repik", "Olga Shapovalova", "Aleksey Sukhorosov", "Vladimir Dobrovolskii", "Natalia Mikhailova", "Sergei Tilga"], "title": "Tendem: A Hybrid AI+Human Platform", "comment": null, "summary": "Tendem is a hybrid system where AI handles structured, repeatable work and Human Experts step in when the models fail or to verify results. Each result undergoes a comprehensive quality review before delivery to the Client. To assess Tendem's performance, we conducted a series of in-house evaluations on 94 real-world tasks, comparing it with AI-only agents and human-only workflows carried out by Upwork freelancers. The results show that Tendem consistently delivers higher-quality outputs with faster turnaround times. At the same time, its operational costs remain comparable to human-only execution. On third-party agentic benchmarks, Tendem's AI Agent (operating autonomously, without human involvement) performs near state-of-the-art on web browsing and tool-use tasks while demonstrating strong results in frontier domain knowledge and reasoning.", "AI": {"tldr": "Tendem\u7cfb\u7edf\u7ed3\u5408AI\u548c\u4eba\u5de5\uff0c\u5b9e\u73b0\u4e86\u8d28\u91cf\u66f4\u9ad8\u3001\u901f\u5ea6\u66f4\u5feb\u4e14\u6210\u672c\u5408\u7406\u7684\u4efb\u52a1\u5b8c\u6210\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u534f\u4f5c\u80fd\u529b\u3002", "motivation": "\u63d0\u5347\u5de5\u4f5c\u6548\u7387\u548c\u8d28\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u7406\u7684\u8fd0\u8425\u6210\u672c\uff0c\u901a\u8fc7\u7ed3\u5408AI\u4e0e\u4eba\u5de5\u4f18\u52bf\u6765\u4f18\u5316\u4efb\u52a1\u6267\u884c\u8fc7\u7a0b\u3002", "method": "\u901a\u8fc7\u572894\u4e2a\u5b9e\u9645\u4efb\u52a1\u4e0a\u8fdb\u884c\u5185\u90e8\u8bc4\u4f30\uff0c\u5c06Tendem\u4e0e\u7eafAI\u4ee3\u7406\u548c\u7eaf\u4eba\u5de5\u5de5\u4f5c\u6d41\u7a0b\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5229\u7528\u7b2c\u4e09\u65b9\u57fa\u51c6\u6d4b\u8bd5\u8bc4\u4f30\u7cfb\u7edf\u7684\u81ea\u52a8\u5316AI\u4ee3\u7406\u6027\u80fd\u3002", "result": "Tendem\u5728\u8d28\u91cf\u548c\u901f\u5ea6\u4e0a\u5747\u4f18\u4e8e\u7eaf\u4eba\u5de5\u6216\u7eafAI\u65b9\u6848\uff0c\u4e14\u8fd0\u8425\u6210\u672c\u4e0e\u7eaf\u4eba\u5de5\u76f8\u5f53\uff1b\u5176AI\u4ee3\u7406\u5728\u81ea\u52a8\u6267\u884c\u4efb\u52a1\u65f6\u8868\u73b0\u63a5\u8fd1\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "Tendem\u7cfb\u7edf\u901a\u8fc7\u7ed3\u5408AI\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u4e13\u5bb6\u7684\u5ba1\u6838\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u5feb\u901f\u4e14\u6210\u672c\u6548\u76ca\u5408\u7406\u7684\u5de5\u4f5c\u4ea4\u4ed8\u3002"}}
{"id": "2602.01125", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01125", "abs": "https://arxiv.org/abs/2602.01125", "authors": ["Jichu Li", "Yilun Zhong", "Zhiting Li", "Feng Zhou", "Quyu Kong"], "title": "Long-range Modeling and Processing of Multimodal Event Sequences", "comment": null, "summary": "Temporal point processes (TPPs) have emerged as powerful tools for modeling asynchronous event sequences. While recent advances have extended TPPs to handle textual information, existing approaches are limited in their ability to generate rich, multimodal content and reason about event dynamics. A key challenge is that incorporating multimodal data dramatically increases sequence length, hindering the ability of attention-based models to generate coherent, long-form textual descriptions that require long-range understanding. In this paper, we propose a novel framework that extends LLM-based TPPs to the visual modality, positioning text generation as a core capability alongside time and type prediction. Our approach addresses the long-context problem through an adaptive sequence compression mechanism based on temporal similarity, which reduces sequence length while preserving essential patterns. We employ a two-stage paradigm of pre-training on compressed sequences followed by supervised fine-tuning for downstream tasks. Extensive experiments, including on the challenging DanmakuTPP-QA benchmark, demonstrate that our method outperforms state-of-the-art baselines in both predictive accuracy and the quality of its generated textual analyses.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eLLM\u7684\u591a\u6a21\u6001\u65f6\u95f4\u70b9\u8fc7\u7a0b\u6a21\u578b\uff0c\u901a\u8fc7\u5e8f\u5217\u538b\u7f29\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u6709\u6548\u89e3\u51b3\u957f\u5e8f\u5217\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u51c6\u786e\u7387\u548c\u751f\u6210\u6587\u672c\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u95f4\u70b9\u8fc7\u7a0b\uff08TPP\uff09\u6a21\u578b\u5728\u5904\u7406\u591a\u6a21\u6001\u5185\u5bb9\u548c\u4e8b\u4ef6\u52a8\u6001\u63a8\u7406\u65f6\u5b58\u5728\u9650\u5236\uff0c\u4e14\u591a\u6a21\u6001\u6570\u636e\u589e\u52a0\u5e8f\u5217\u957f\u5ea6\uff0c\u5f71\u54cd\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u6a21\u578b\u7684\u957f\u6587\u672c\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u65f6\u95f4\u70b9\u8fc7\u7a0b\u6846\u67b6\uff0c\u5c06\u89c6\u89c9\u6a21\u6001\u5f15\u5165\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u65f6\u95f4\u76f8\u4f3c\u5ea6\u7684\u81ea\u9002\u5e94\u5e8f\u5217\u538b\u7f29\u673a\u5236\u89e3\u51b3\u957f\u5e8f\u5217\u95ee\u9898\uff0c\u91c7\u7528\u538b\u7f29\u5e8f\u5217\u9884\u8bad\u7ec3\u548c\u6709\u76d1\u7763\u5fae\u8c03\u76f8\u7ed3\u5408\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u5b9e\u9a8c\u4e2d\uff0c\u5c24\u5176\u662fDanmakuTPP-QA\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u51c6\u786e\u7387\u548c\u751f\u6210\u6587\u672c\u8d28\u91cf\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u6269\u5c55\u4e86TPP\u6a21\u578b\u7684\u591a\u6a21\u6001\u80fd\u529b\u4e0e\u957f\u6587\u672c\u751f\u6210\u80fd\u529b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u590d\u6742\u4e8b\u4ef6\u5e8f\u5217\u7684\u5206\u6790\u548c\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.01132", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01132", "abs": "https://arxiv.org/abs/2602.01132", "authors": ["Abhilekh Borah", "Shubhra Ghosh", "Kedar Joshi", "Aditya Kumar Guru", "Kripabandhu Ghosh"], "title": "Don't Judge a Book by its Cover: Testing LLMs' Robustness Under Logical Obfuscation", "comment": "19 pages, 6 figures", "summary": "Tasks such as solving arithmetic equations, evaluating truth tables, and completing syllogisms are handled well by large language models (LLMs) in their standard form, but they often fail when the same problems are posed in logically equivalent yet obfuscated formats. To study this vulnerability, we introduce Logifus, a structure-preserving logical obfuscation framework, and, utilizing this, we present LogiQAte, a first-of-its-kind diagnostic benchmark with 1,108 questions across four reasoning tasks: (i) Obfus FOL (first-order logic entailment under equivalence-preserving rewrites), (ii) Obfus Blood Relation (family-graph entailment under indirect relational chains), (iii) Obfus Number Series (pattern induction under symbolic substitutions), and (iv) Obfus Direction Sense (navigation reasoning under altered directions and reference frames). Across all the tasks, evaluating six state-of-the-art models, we find that obfuscation severely degrades zero-shot performance, with performance dropping on average by 47% for GPT-4o, 27% for GPT-5, and 22% for reasoning model, o4-mini. Our findings reveal that current LLMs parse questions without deep understanding, highlighting the urgency of building models that genuinely comprehend and preserve meaning beyond surface form.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u903b\u8f91\u6df7\u6dc6\u6d4b\u8bd5\u96c6LogiQAte\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u7b49\u4ef7\u4f46\u8868\u8ff0\u6df7\u6dc6\u7684\u95ee\u9898\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u63a8\u7406\u80fd\u529b\u660e\u663e\u4e0b\u964d\uff0c\u66b4\u9732\u4e86\u6df1\u5c42\u7406\u89e3\u7684\u4e0d\u8db3\u3002", "motivation": "\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u6807\u51c6\u5f62\u5f0f\u95ee\u9898\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5bf9\u7b49\u4ef7\u4f46\u8868\u9762\u5f62\u5f0f\u88ab\u6df7\u6dc6\u7684\u903b\u8f91\u95ee\u9898\u5904\u7406\u80fd\u529b\u5dee\uff0c\u63ed\u793a\u4e86\u5b83\u4eec\u7406\u89e3\u7684\u5c40\u9650\u6027\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u548c\u8bca\u65ad\u6a21\u578b\u7684\u6df1\u5c42\u903b\u8f91\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u6784\u4fdd\u6301\u7684\u903b\u8f91\u6df7\u6dc6\u6846\u67b6Logifus\uff0c\u5e76\u57fa\u4e8e\u6b64\u6784\u5efa\u4e86LogiQAte\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b\u56db\u7c7b\u63a8\u7406\u4efb\u52a1\uff0c\u6d4b\u8bd5\u516d\u4e2a\u9876\u5c16\u6a21\u578b\u5728\u6df7\u6dc6\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u516d\u4e2a\u5148\u8fdb\u6a21\u578b\uff0c\u53d1\u73b0\u903b\u8f91\u6df7\u6dc6\u663e\u8457\u964d\u4f4e\u6a21\u578b\u7684\u96f6\u6837\u672c\u6027\u80fd\uff0cGPT-4o\u5e73\u5747\u4e0b\u964d47%\uff0cGPT-5\u4e0b\u964d27%\uff0co4-mini\u4e0b\u964d22%\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u903b\u8f91\u7b49\u4ef7\u800c\u975e\u76f4\u63a5\u8868\u8fbe\u7684\u95ee\u9898\u65f6\u8868\u73b0\u8f83\u5dee\uff0c\u8868\u73b0\u51fa\u5bf9\u6d45\u5c42\u8bed\u4e49\u7684\u4f9d\u8d56\uff0c\u7f3a\u4e4f\u5bf9\u6df1\u5c42\u903b\u8f91\u7ed3\u6784\u7684\u7406\u89e3\u3002"}}
{"id": "2602.01161", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01161", "abs": "https://arxiv.org/abs/2602.01161", "authors": ["Reem I. Masoud", "Chen Feng", "Shunta Asano", "Saied Alshahrani", "Philip Colin Treleaven", "Miguel R. D. Rodrigues"], "title": "Beyond Training for Cultural Awareness: The Role of Dataset Linguistic Structure in Large Language Models", "comment": null, "summary": "The global deployment of large language models (LLMs) has raised concerns about cultural misalignment, yet the linguistic properties of fine-tuning datasets used for cultural adaptation remain poorly understood. We adopt a dataset-centric view of cultural alignment and ask which linguistic properties of fine-tuning data are associated with cultural performance, whether these properties are predictive prior to training, and how these effects vary across models. We compute lightweight linguistic, semantic, and structural metrics for Arabic, Chinese, and Japanese datasets and apply principal component analysis separately within each language. This design ensures that the resulting components capture variation among datasets written in the same language rather than differences between languages. The resulting components correspond to broadly interpretable axes related to semantic coherence, surface-level lexical and syntactic diversity, and lexical or structural richness, though their composition varies across languages. We fine-tune three major LLM families (LLaMA, Mistral, DeepSeek) and evaluate them on benchmarks of cultural knowledge, values, and norms. While PCA components correlate with downstream performance, these associations are strongly model-dependent. Through controlled subset interventions, we show that lexical-oriented components (PC3) are the most robust, yielding more consistent performance across models and benchmarks, whereas emphasizing semantic or diversity extremes (PC1-PC2) is often neutral or harmful.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5fae\u8c03\u6570\u636e\u8bed\u8a00\u7279\u6027\u5bf9\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u6587\u5316\u9002\u5e94\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8bcd\u6c47\u76f8\u5173\u7279\u6027\u662f\u63d0\u5347\u8de8\u6a21\u578b\u6587\u5316\u8868\u73b0\u7684\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u5168\u7403\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u9002\u5e94\u6027\u5b58\u5728\u95ee\u9898\uff0c\u7136\u800c\u7528\u4e8e\u6587\u5316\u9002\u5e94\u7684\u5fae\u8c03\u6570\u636e\u7684\u8bed\u8a00\u7279\u6027\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u4ee5\u6570\u636e\u96c6\u4e3a\u4e2d\u5fc3\u89c6\u89d2\uff0c\u8ba1\u7b97\u963f\u62c9\u4f2f\u8bed\u3001\u4e2d\u6587\u548c\u65e5\u8bed\u5fae\u8c03\u6570\u636e\u96c6\u7684\u8bed\u8a00\u3001\u8bed\u4e49\u548c\u7ed3\u6784\u6307\u6807\uff0c\u5e76\u5bf9\u6bcf\u79cd\u8bed\u8a00\u6570\u636e\u96c6\u8fdb\u884c\u4e3b\u6210\u5206\u5206\u6790\u3002\u540c\u65f6\u5206\u522b\u5fae\u8c03\u4e09\u79cd\u4e3b\u6d41\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u591a\u8bed\u8a00\u6587\u5316\u77e5\u8bc6\u57fa\u51c6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u4e3b\u6210\u5206\u5206\u6790\u5f97\u5230\u7684\u7ec4\u4ef6\u4e0e\u6a21\u578b\u6027\u80fd\u76f8\u5173\uff0c\u4f46\u5176\u5f71\u54cd\u4f9d\u8d56\u4e8e\u5177\u4f53\u6a21\u578b\u3002\u8bcd\u6c47\u76f8\u5173\u7684\u6210\u5206\uff08PC3\uff09\u5bf9\u6a21\u578b\u8868\u73b0\u5f71\u54cd\u7a33\u5b9a\u4e14\u4e00\u81f4\uff0c\u800c\u8bed\u4e49\u6216\u591a\u6837\u6027\u6210\u5206\uff08PC1-PC2\uff09\u5f71\u54cd\u4e0d\u786e\u5b9a\u751a\u81f3\u6709\u5bb3\u3002", "conclusion": "\u5fae\u8c03\u6570\u636e\u7684\u8bed\u8a00\u7279\u6027\u5bf9\u6587\u5316\u9002\u5e94\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4e14\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u5bf9\u8fd9\u4e9b\u7279\u6027\u7684\u54cd\u5e94\u4e0d\u540c\u3002\u5f3a\u5316\u8bcd\u6c47\u591a\u6837\u6027\u6bd4\u5f3a\u8c03\u8bed\u4e49\u6216\u591a\u6837\u6027\u6781\u7aef\u66f4\u6709\u52a9\u4e8e\u63d0\u5347\u8de8\u6a21\u578b\u7684\u6587\u5316\u8868\u73b0\u3002"}}
{"id": "2602.01162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01162", "abs": "https://arxiv.org/abs/2602.01162", "authors": ["Nipuna Abeykoon", "Ashen Weerathunga", "Pubudu Wijesinghe", "Parameswari Krishnamurthy"], "title": "Typologically-Informed Candidate Reranking for LLM-based Translation into Low-Resource Languages", "comment": null, "summary": "Large language models trained predominantly on high-resource languages exhibit systematic biases toward dominant typological patterns, leading to structural non-conformance when translating into typologically divergent low-resource languages. We present a framework that leverages linguistic typology to improve translation quality without parallel training data or model retraining. The framework consists of two components: the Universal Metalinguistic Framework (UMF), which represents languages as structured profiles across 16 typological dimensions with divergence-weighted scoring, and the Computational Engine, which operates through linguistic disambiguation during generation and typological compliance scoring during selection. Evaluation across nine language pairs demonstrates intervention rates strongly correlating with typological distance from English. In experiments on 341 English sentences each having different morphological and syntactic phenomena, the framework shows an intervention precision of 48.16% for conservatively treated languages, 28.15% for morphologically dense languages, and 86.26% for structurally profiled languages. The framework requires no parallel training data and operates with any LLM capable of producing multiple candidate outputs, enabling practical deployment for under-resourced languages.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u8bed\u8a00\u7c7b\u578b\u5b66\u7684\u6846\u67b6\uff0c\u6539\u5584\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u7ffb\u8bd1\u7ed3\u6784\u6027\u504f\u5dee\uff0c\u6548\u679c\u663e\u8457\u4e14\u65e0\u9700\u5e73\u884c\u8bad\u7ec3\u6570\u636e\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u5728\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e0a\u8bad\u7ec3\uff0c\u5b58\u5728\u5bf9\u4e3b\u8981\u8bed\u8a00\u7c7b\u578b\u6a21\u5f0f\u7684\u7cfb\u7edf\u6027\u504f\u5411\uff0c\u5bfc\u81f4\u7ffb\u8bd1\u5230\u7c7b\u578b\u5b66\u5dee\u5f02\u5927\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u65f6\u7ed3\u6784\u4e0d\u7b26\u5408\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u5229\u7528\u8bed\u8a00\u7c7b\u578b\u5b66\u7684\u6846\u67b6\uff0c\u5305\u62ec\u7edf\u4e00\u5143\u8bed\u8a00\u6846\u67b6\uff08UMF\uff09\u548c\u8ba1\u7b97\u5f15\u64ce\uff0c\u901a\u8fc7\u8bed\u8a00\u6b67\u4e49\u6d88\u89e3\u548c\u7c7b\u578b\u5b66\u5408\u89c4\u8bc4\u5206\u65e0\u9700\u5e73\u884c\u8bad\u7ec3\u6570\u636e\u6216\u6a21\u578b\u518d\u8bad\u7ec3\u6539\u5584\u7ffb\u8bd1\u8d28\u91cf\u3002", "result": "\u57289\u5bf9\u8bed\u8a00\u7684\u8bc4\u4f30\u4e2d\uff0c\u5e72\u9884\u7387\u4e0e\u8bed\u8a00\u7c7b\u578b\u5b66\u8ddd\u79bb\u663e\u8457\u76f8\u5173\u3002\u5bf9341\u4e2a\u6d89\u53ca\u4e0d\u540c\u5f62\u6001\u548c\u53e5\u6cd5\u73b0\u8c61\u7684\u82f1\u6587\u53e5\u5b50\uff0c\u6846\u67b6\u5728\u4fdd\u5b88\u5904\u7406\u8bed\u8a00\u3001\u5f62\u6001\u5bc6\u96c6\u8bed\u8a00\u548c\u7ed3\u6784\u5316\u8bed\u8a00\u4e0a\u7684\u5e72\u9884\u7cbe\u51c6\u7387\u5206\u522b\u4e3a48.16%\u300128.15%\u548c86.26%\u3002", "conclusion": "\u8be5\u6846\u67b6\u65e0\u9700\u5e73\u884c\u6570\u636e\uff0c\u9002\u7528\u4e8e\u80fd\u751f\u6210\u591a\u5019\u9009\u8f93\u51fa\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5bf9\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u8d28\u91cf\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.01169", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01169", "abs": "https://arxiv.org/abs/2602.01169", "authors": ["Shahem Sultan", "Shahem Fadi", "Yousef Melhim", "Ibrahim Alsarraj", "Besher Hassan"], "title": "PedagoSense: A Pedology Grounded LLM System for Pedagogical Strategy Detection and Contextual Response Generation in Learning Dialogues", "comment": "8 pages, 5 figures", "summary": "This paper addresses the challenge of improving interaction quality in dialogue based learning by detecting and recommending effective pedagogical strategies in tutor student conversations. We introduce PedagoSense, a pedology grounded system that combines a two stage strategy classifier with large language model generation. The system first detects whether a pedagogical strategy is present using a binary classifier, then performs fine grained classification to identify the specific strategy. In parallel, it recommends an appropriate strategy from the dialogue context and uses an LLM to generate a response aligned with that strategy. We evaluate on human annotated tutor student dialogues, augmented with additional non pedagogical conversations for the binary task. Results show high performance for pedagogical strategy detection and consistent gains when using data augmentation, while analysis highlights where fine grained classes remain challenging. Overall, PedagoSense bridges pedagogical theory and practical LLM based response generation for more adaptive educational technologies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPedagoSense\u7cfb\u7edf\uff0c\u7ed3\u5408\u7b56\u7565\u5206\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u5347\u5e08\u751f\u5bf9\u8bdd\u4e2d\u6559\u5b66\u7b56\u7565\u7684\u68c0\u6d4b\u4e0e\u63a8\u8350\uff0c\u63a8\u52a8\u9002\u5e94\u6027\u6559\u80b2\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u63d0\u9ad8\u5bf9\u8bdd\u5f0f\u5b66\u4e60\u4e2d\u4e92\u52a8\u8d28\u91cf\uff0c\u901a\u8fc7\u51c6\u786e\u68c0\u6d4b\u548c\u63a8\u8350\u6559\u5b66\u7b56\u7565\u4f18\u5316\u5e08\u751f\u5bf9\u8bdd\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7b56\u7565\u5206\u7c7b\u5668\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\uff0c\u5148\u4e8c\u5206\u7c7b\u68c0\u6d4b\u6559\u5b66\u7b56\u7565\uff0c\u518d\u7ec6\u7c92\u5ea6\u5206\u7c7b\u5177\u4f53\u7b56\u7565\uff0c\u540c\u65f6\u63a8\u8350\u9002\u5f53\u7b56\u7565\u5e76\u751f\u6210\u54cd\u5e94\u3002", "result": "\u5728\u4eba\u7c7b\u6807\u6ce8\u7684\u5e08\u751f\u5bf9\u8bdd\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u9ad8\u6548\u7684\u6559\u5b66\u7b56\u7565\u68c0\u6d4b\u80fd\u529b\uff0c\u6570\u636e\u589e\u5f3a\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u4ecd\u6709\u6311\u6218\u3002", "conclusion": "PedagoSense\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u6559\u5b66\u7b56\u7565\u7684\u68c0\u6d4b\u548c\u63a8\u8350\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u66f4\u9002\u5e94\u6027\u7684\u6559\u80b2\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2602.01170", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01170", "abs": "https://arxiv.org/abs/2602.01170", "authors": ["Besher Hassan", "Ibrahim Alsarraj", "Musaab Hasan", "Yousef Melhim", "Shahem Fadi", "Shahem Sultan"], "title": "EmoAra: Emotion-Preserving English Speech Transcription and Cross-Lingual Translation with Arabic Text-to-Speech", "comment": "10 pages, 3 figures", "summary": "This work presents EmoAra, an end-to-end emotion-preserving pipeline for cross-lingual spoken communication, motivated by banking customer service where emotional context affects service quality. EmoAra integrates Speech Emotion Recognition, Automatic Speech Recognition, Machine Translation, and Text-to-Speech to process English speech and deliver an Arabic spoken output while retaining emotional nuance. The system uses a CNN-based emotion classifier, Whisper for English transcription, a fine-tuned MarianMT model for English-to-Arabic translation, and MMS-TTS-Ara for Arabic speech synthesis. Experiments report an F1-score of 94% for emotion classification, translation performance of BLEU 56 and BERTScore F1 88.7%, and an average human evaluation score of 81% on banking-domain translations. The implementation and resources are available at the accompanying GitHub repository.", "AI": {"tldr": "EmoAra\u7cfb\u7edf\u5b9e\u73b0\u4e86\u82f1\u5230\u963f\u8bed\u7684\u8de8\u8bed\u8a00\u8bed\u97f3\u4ea4\u6d41\uff0c\u51c6\u786e\u8bc6\u522b\u60c5\u611f\u5e76\u4fdd\u6301\u5176\u5728\u76ee\u6807\u8bed\u4e2d\u7684\u4f20\u9012\uff0c\u63d0\u5347\u4e86\u94f6\u884c\u670d\u52a1\u4ea4\u6d41\u8d28\u91cf\u3002", "motivation": "\u9488\u5bf9\u94f6\u884c\u5ba2\u6237\u670d\u52a1\u4e2d\u60c5\u611f\u4fe1\u606f\u5f71\u54cd\u670d\u52a1\u8d28\u91cf\u7684\u9700\u6c42\uff0c\u63d0\u51fa\u4e00\u4e2a\u8de8\u8bed\u8a00\u8bed\u97f3\u4ea4\u6d41\u4e2d\u4fdd\u7559\u60c5\u611f\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u6574\u5408\u4e86\u57fa\u4e8eCNN\u7684\u60c5\u611f\u8bc6\u522b\u5668\u3001Whisper\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u3001\u5fae\u8c03\u7684MarianMT\u82f1\u963f\u7ffb\u8bd1\u6a21\u578b\u548cMMS-TTS-Ara\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u5408\u6210\u6a21\u578b\u3002", "result": "\u60c5\u611f\u5206\u7c7bF1\u8fbe94%\uff0c\u7ffb\u8bd1\u6307\u6807BLEU\u4e3a56\uff0cBERTScore F1\u4e3a88.7%\uff0c\u4ee5\u53ca81%\u7684\u4eba\u5de5\u8bc4\u4f30\u5e73\u5747\u5206\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86EmoAra\uff0c\u4e00\u4e2a\u80fd\u591f\u5728\u8de8\u8bed\u8a00\u8bed\u97f3\u4ea4\u6d41\u4e2d\u4fdd\u6301\u60c5\u611f\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u94f6\u884c\u5ba2\u6237\u670d\u52a1\u7684\u8d28\u91cf\u3002"}}
{"id": "2602.01193", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.01193", "abs": "https://arxiv.org/abs/2602.01193", "authors": ["Shashini Nilukshi", "Deshan Sumanathilaka"], "title": "Bridging Lexical Ambiguity and Vision: A Mini Review on Visual Word Sense Disambiguation", "comment": "2 figures, 2 Tables, Accepted at IEEE TIC 2026", "summary": "This paper offers a mini review of Visual Word Sense Disambiguation (VWSD), which is a multimodal extension of traditional Word Sense Disambiguation (WSD). VWSD helps tackle lexical ambiguity in vision-language tasks. While conventional WSD depends only on text and lexical resources, VWSD uses visual cues to find the right meaning of ambiguous words with minimal text input. The review looks at developments from early multimodal fusion methods to new frameworks that use contrastive models like CLIP, diffusion-based text-to-image generation, and large language model (LLM) support. Studies from 2016 to 2025 are examined to show the growth of VWSD through feature-based, graph-based, and contrastive embedding techniques. It focuses on prompt engineering, fine-tuning, and adapting to multiple languages. Quantitative results show that CLIP-based fine-tuned models and LLM-enhanced VWSD systems consistently perform better than zero-shot baselines, achieving gains of up to 6-8\\% in Mean Reciprocal Rank (MRR). However, challenges still exist, such as limitations in context, model bias toward common meanings, a lack of multilingual datasets, and the need for better evaluation frameworks. The analysis highlights the growing overlap of CLIP alignment, diffusion generation, and LLM reasoning as the future path for strong, context-aware, and multilingual disambiguation systems.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u89c6\u89c9\u8bcd\u4e49\u6d88\u6b67\u9886\u57df\u7684\u53d1\u5c55\uff0c\u5f3a\u8c03\u5229\u7528\u89c6\u89c9\u4fe1\u606f\u5f25\u8865\u4f20\u7edf\u6587\u672c\u65b9\u6cd5\u4e0d\u8db3\uff0c\u901a\u8fc7CLIP\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u8bcd\u4e49\u5224\u5b9a\u6027\u80fd\uff0c\u672a\u6765\u5c06\u805a\u7126\u591a\u6a21\u6001\u878d\u5408\u548c\u591a\u8bed\u79cd\u9002\u914d\u3002", "motivation": "\u4f20\u7edf\u7684\u8bcd\u4e49\u6d88\u6b67\u4ec5\u4f9d\u8d56\u6587\u672c\u548c\u8bcd\u6c47\u8d44\u6e90\uff0c\u96be\u4ee5\u89e3\u51b3\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8bcd\u4e49\u6b67\u4e49\u95ee\u9898\uff0c\u56e0\u6b64VWSD\u5f15\u5165\u89c6\u89c9\u7ebf\u7d22\uff0c\u4ee5\u5728\u6700\u5c0f\u6587\u672c\u8f93\u5165\u4e0b\u51c6\u786e\u8bc6\u522b\u6b67\u4e49\u8bcd\u4e49\u3002", "method": "\u8be5\u7efc\u8ff0\u8ddf\u8e2a\u4e862016\u81f32025\u5e74\u671f\u95f4VWSD\u7684\u53d1\u5c55\uff0c\u5206\u6790\u4e86\u65e9\u671f\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u3001\u57fa\u4e8e\u7279\u5f81\u3001\u56fe\u7ed3\u6784\u548c\u5bf9\u6bd4\u5d4c\u5165\u6280\u672f\u7684\u6f14\u8fdb\uff0c\u91cd\u70b9\u8ba8\u8bba\u4e86CLIP\u5bf9\u6bd4\u6a21\u578b\u3001\u6269\u6563\u5f0f\u6587\u672c\u5230\u56fe\u50cf\u751f\u6210\u4ee5\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\uff0c\u6db5\u76d6\u63d0\u793a\u5de5\u7a0b\u3001\u6a21\u578b\u5fae\u8c03\u53ca\u591a\u8bed\u8a00\u9002\u914d\u7b56\u7565\u3002", "result": "\u7814\u7a76\u663e\u793a\uff0c\u57fa\u4e8eCLIP\u5fae\u8c03\u6a21\u578b\u548c\u878d\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684VWSD\u7cfb\u7edf\uff0c\u5728\u5e73\u5747\u5012\u6570\u6392\u540d(MRR)\u6307\u6807\u4e0a\u8f83\u96f6-shot\u57fa\u7ebf\u63d0\u53476-8%\uff0c\u8868\u73b0\u66f4\u52a0\u7a33\u5b9a\u548c\u51c6\u786e\u3002\u540c\u65f6\u4e5f\u6307\u51fa\u5b58\u5728\u4e0a\u4e0b\u6587\u9650\u5236\u3001\u6a21\u578b\u504f\u597d\u5e38\u89c1\u8bcd\u4e49\u3001\u591a\u8bed\u79cd\u6570\u636e\u7f3a\u4e4f\u53ca\u8bc4\u4f30\u4f53\u7cfb\u4e0d\u5b8c\u5584\u7684\u95ee\u9898\u3002", "conclusion": "VWSD\u4f5c\u4e3a\u4f20\u7edf\u8bcd\u4e49\u6d88\u6b67\u7684\u591a\u6a21\u6001\u6269\u5c55\uff0c\u7ed3\u5408\u89c6\u89c9\u4fe1\u606f\u663e\u8457\u63d0\u5347\u4e86\u5728\u89c6\u89c9\u8bed\u8a00\u4efb\u52a1\u4e2d\u6b67\u4e49\u8bcd\u610f\u4e49\u5224\u5b9a\u7684\u51c6\u786e\u6027\u3002\u57fa\u4e8eCLIP\u5fae\u8c03\u6a21\u578b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u4e0a\u4e0b\u6587\u9650\u5236\u3001\u6a21\u578b\u504f\u89c1\u3001\u591a\u8bed\u79cd\u8d44\u6e90\u532e\u4e4f\u53ca\u8bc4\u4f30\u65b9\u6cd5\u4e0d\u8db3\u7b49\u6311\u6218\u3002\u672a\u6765\u65b9\u5411\u662f\u878d\u5408CLIP\u5bf9\u9f50\u3001\u6269\u6563\u751f\u6210\u548c\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\uff0c\u5b9e\u73b0\u5f3a\u5927\u4e14\u5177\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u591a\u8bed\u8a00\u80fd\u529b\u7684\u8bcd\u4e49\u6d88\u6b67\u7cfb\u7edf\u3002"}}
{"id": "2602.01203", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01203", "abs": "https://arxiv.org/abs/2602.01203", "authors": ["Zizhuo Fu", "Wenxuan Zeng", "Runsheng Wang", "Meng Li"], "title": "Attention Sink Forges Native MoE in Attention Layers: Sink-Aware Training to Address Head Collapse", "comment": null, "summary": "Large Language Models (LLMs) often assign disproportionate attention to the first token, a phenomenon known as the attention sink. Several recent approaches aim to address this issue, including Sink Attention in GPT-OSS and Gated Attention in Qwen3-Next. However, a comprehensive analysis of the relationship among these attention mechanisms is lacking. In this work, we provide both theoretical and empirical evidence demonstrating that the sink in Vanilla Attention and Sink Attention naturally construct a Mixture-of-Experts (MoE) mechanism within attention layers. This insight explains the head collapse phenomenon observed in prior work, where only a fixed subset of attention heads contributes to generation. To mitigate head collapse, we propose a sink-aware training algorithm with an auxiliary load balancing loss designed for attention layers. Extensive experiments show that our method achieves effective head load balancing and improves model performance across Vanilla Attention, Sink Attention, and Gated Attention. We hope this study offers a new perspective on attention mechanisms and encourages further exploration of the inherent MoE structure within attention layers.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u4e86\u6ce8\u610f\u529b\u6c89\u6ca1\u73b0\u8c61\u4e2d\u7684\u6df7\u5408\u4e13\u5bb6\u7ed3\u6784\uff0c\u9488\u5bf9\u5934\u584c\u9677\u63d0\u51fa\u4e86\u8d1f\u8f7d\u5747\u8861\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u6539\u5584\u4e86\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u673a\u5236\u5b58\u5728\u5bf9\u9996\u4e2aToken\u8fc7\u5ea6\u5173\u6ce8\uff08attention sink\uff09\u7684\u95ee\u9898\u548c\u6ce8\u610f\u529b\u5934\u584c\u9677\u73b0\u8c61\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u6ce8\u610f\u529b\u673a\u5236\u95f4\u5173\u7cfb\u7684\u7efc\u5408\u5206\u6790\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc1\u660e\u4e86Vanilla Attention\u4e0eSink Attention\u4e2d\u7684\u6ce8\u610f\u529b\u6c89\u6ca1\u6784\u6210\u4e86\u5185\u90e8\u7684\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u8fdb\u800c\u63d0\u51fa\u4e86\u542b\u8f85\u52a9\u8d1f\u8f7d\u5747\u8861\u635f\u5931\u7684\u6c89\u6ca1\u611f\u77e5\u8bad\u7ec3\u7b97\u6cd5\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u6ce8\u610f\u529b\u5934\u8d1f\u8f7d\u5747\u8861\uff0c\u63d0\u5347\u4e86Vanilla Attention\u3001Sink Attention\u548cGated Attention\u4e0b\u7684\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u6ce8\u610f\u529b\u6c89\u6ca1\u73b0\u8c61\u80cc\u540e\u7684\u6df7\u5408\u4e13\u5bb6\u673a\u5236\uff0c\u89e3\u91ca\u4e86\u6ce8\u610f\u529b\u5934\u584c\u9677\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u8d1f\u8f7d\u5747\u8861\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u5934\u584c\u9677\uff0c\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.01204", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01204", "abs": "https://arxiv.org/abs/2602.01204", "authors": ["Xuqin Zhang", "Quan He", "Zhenrui Zheng", "Zongzhang Zhang", "Xu He", "Dong Li"], "title": "ASTER: Agentic Scaling with Tool-integrated Extended Reasoning", "comment": null, "summary": "Reinforcement learning (RL) has emerged as a dominant paradigm for eliciting long-horizon reasoning in Large Language Models (LLMs). However, scaling Tool-Integrated Reasoning (TIR) via RL remains challenging due to interaction collapse: a pathological state where models fail to sustain multi-turn tool usage, instead degenerating into heavy internal reasoning with only trivial, post-hoc code verification. We systematically study three questions: (i) how cold-start SFT induces an agentic, tool-using behavioral prior, (ii) how the interaction density of cold-start trajectories shapes exploration and downstream RL outcomes, and (iii) how the RL interaction budget affects learning dynamics and generalization under varying inference-time budgets. We then introduce ASTER (Agentic Scaling with Tool-integrated Extended Reasoning), a framework that circumvents this collapse through a targeted cold-start strategy prioritizing interaction-dense trajectories. We find that a small expert cold-start set of just 4K interaction-dense trajectories yields the strongest downstream performance, establishing a robust prior that enables superior exploration during extended RL training. Extensive evaluations demonstrate that ASTER-4B achieves state-of-the-art results on competitive mathematical benchmarks, reaching 90.0% on AIME 2025, surpassing leading frontier open-source models, including DeepSeek-V3.2-Exp.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u5de5\u5177\u96c6\u6210\u63a8\u7406\u65f6\u7684\u4ea4\u4e92\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4ea4\u4e92\u5bc6\u96c6\u51b7\u542f\u52a8\u8f68\u8ff9\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6ASTER\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u80fd\u529b\u548c\u6570\u5b66\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5f3a\u5316\u5b66\u4e60\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5e94\u7528\u5de5\u5177\u96c6\u6210\u63a8\u7406\u65f6\uff0c\u5b58\u5728\u6a21\u578b\u65e0\u6cd5\u6301\u7eed\u591a\u8f6e\u5de5\u5177\u8c03\u7528\u800c\u9000\u5316\u4e3a\u7b80\u5355\u5185\u90e8\u63a8\u7406\u7684\u95ee\u9898\uff08\u4ea4\u4e92\u5d29\u6e83\uff09\uff0c\u4e9f\u9700\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86ASTER\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5148\u91c7\u7528\u4ea4\u4e92\u5bc6\u96c6\u7684\u51b7\u542f\u52a8\u8f68\u8ff9\uff0c\u5efa\u7acb\u5f3a\u6709\u529b\u7684\u884c\u4e3a\u5148\u9a8c\uff0c\u4fc3\u8fdb\u6269\u5c55\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u7684\u9ad8\u6548\u63a2\u7d22\u3002", "result": "\u5728AIME 2025\u7b49\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cASTER-4B\u6a21\u578b\u8fbe\u523090.0%\u7684\u6210\u7ee9\uff0c\u8d85\u8fc7\u5305\u62ecDeepSeek-V3.2-Exp\u5728\u5185\u7684\u9886\u5148\u5f00\u6e90\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u9488\u5bf9\u5f3a\u5316\u5b66\u4e60\u5728\u96c6\u6210\u5de5\u5177\u63a8\u7406\u4e2d\u9047\u5230\u7684\u4ea4\u4e92\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5bc6\u96c6\u4ea4\u4e92\u8f68\u8ff9\u7684\u51b7\u542f\u52a8\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u591a\u8f6e\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u548c\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2602.01208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01208", "abs": "https://arxiv.org/abs/2602.01208", "authors": ["Kai Zhang", "Jiayi Liao", "Chengpeng Li", "Ziyuan Xie", "Sihang Li", "Xiang Wang"], "title": "Chronos: Learning Temporal Dynamics of Reasoning Chains for Test-Time Scaling", "comment": null, "summary": "Test-Time Scaling (TTS) has emerged as an effective paradigm for improving the reasoning performance of large language models (LLMs). However, existing methods -- most notably majority voting and heuristic token-level scoring -- treat reasoning traces or tokens equally, thereby being susceptible to substantial variations in trajectory quality and localized logical failures. In this work, we introduce \\textbf{Chronos}, a lightweight and plug-and-play chronological reasoning scorer that models each trajectory as a time series. Specifically, Chronos learns to capture trajectory features of token probabilities, assigns quality scores accordingly, and employs a weighted voting mechanism. Extensive evaluations on both in-domain and out-of-domain benchmarks demonstrate that Chronos consistently delivers substantial gains across a variety of models, with negligible computational overhead. Notably, Chronos@128 achieves relative improvements of 34.21\\% over Pass@1 and 22.70\\% over Maj@128 on HMMT25 using Qwen3-4B-Thinking-2507, highlighting its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Chronos\uff0c\u4e00\u79cd\u57fa\u4e8e\u65f6\u95f4\u5e8f\u5217\u7684\u63a8\u7406\u8d28\u91cf\u8bc4\u5206\u5668\uff0c\u901a\u8fc7\u52a0\u6743\u6295\u7968\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\uff0c\u4e14\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u7ed3\u679c\u878d\u5408\u65b9\u6cd5\u5982\u591a\u6570\u6295\u7968\u548c\u542f\u53d1\u5f0ftoken\u7ea7\u8bc4\u5206\u5bf9\u8f68\u8ff9\u8d28\u91cf\u6ce2\u52a8\u548c\u5c40\u90e8\u903b\u8f91\u9519\u8bef\u654f\u611f\uff0c\u672a\u6709\u6548\u533a\u5206\u4e0d\u540c\u63a8\u7406\u8f68\u8ff9\u7684\u8d28\u91cf\u3002", "method": "Chronos\u5c06\u63a8\u7406\u8f68\u8ff9\u89c6\u4e3a\u65f6\u95f4\u5e8f\u5217\uff0c\u5b66\u4e60\u6355\u6349token\u6982\u7387\u7684\u8f68\u8ff9\u7279\u5f81\uff0c\u4e3a\u8f68\u8ff9\u8d4b\u4e88\u8d28\u91cf\u8bc4\u5206\uff0c\u5e76\u91c7\u7528\u52a0\u6743\u6295\u7968\u673a\u5236\u63d0\u5347\u51b3\u7b56\u6548\u679c\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff08\u5305\u62ec\u540c\u57df\u548c\u5f02\u57df\uff09\u4e2d\uff0cChronos\u5e26\u6765\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728HMMT25\u6d4b\u8bd5\u4e2d\uff0c\u4f7f\u7528Qwen3-4B-Thinking-2507\u6a21\u578b\uff0cChronos@128\u76f8\u5bf9\u4e8ePass@1\u63d0\u5347\u4e8634.21%\uff0c\u76f8\u5bf9\u4e8eMaj@128\u63d0\u5347\u4e8622.70%\u3002", "conclusion": "Chronos\u4f5c\u4e3a\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u8bc4\u5206\u5668\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u548c\u8f83\u4f4e\u7684\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2602.01227", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01227", "abs": "https://arxiv.org/abs/2602.01227", "authors": ["Zhanming Shen", "Zeyu Qin", "Jiaqi Hu", "Wentao Ye", "Hao Chen", "Xiaomeng Hu", "Haokai Xu", "Gang Chen", "Yi R. Fung", "Haobo Wang"], "title": "Supervised Fine-Tuning Needs to Unlock the Potential of Token Priority", "comment": null, "summary": "The transition from fitting empirical data to achieving true human utility is fundamentally constrained by a granularity mismatch, where fine-grained autoregressive generation is often supervised by coarse or uniform signals. This position paper advocates Token Priority as the essential bridge, formalizing Supervised Fine-Tuning (SFT) not as simple optimization but as a precise distribution reshaping process that aligns raw data with the ideal alignment manifold. We analyze recent breakthroughs through this unified lens, categorizing them into two distinct regimes: Positive Priority for noise filtration and Signed Priority for toxic modes unlearning. We revisit existing progress and limitations, identify key challenges, and suggest directions for future research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faToken Priority\u673a\u5236\u4f5c\u4e3a\u7ec6\u7c92\u5ea6\u751f\u6210\u4e0e\u7c97\u76d1\u7763\u4fe1\u53f7\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u91cd\u65b0\u5b9a\u4e49\u76d1\u7763\u5fae\u8c03\u4e3a\u5206\u5e03\u91cd\u5851\u8fc7\u7a0b\uff0c\u7cfb\u7edf\u5206\u6790\u4e24\u5927\u8303\u5f0f\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u5f53\u524d\u7ec6\u7c92\u5ea6\u81ea\u56de\u5f52\u751f\u6210\u4e0e\u7c97\u7cd9\u6216\u5747\u5300\u76d1\u7763\u4fe1\u53f7\u4e4b\u95f4\u5b58\u5728\u7c92\u5ea6\u4e0d\u5339\u914d\uff0c\u5236\u7ea6\u5411\u771f\u5b9e\u4eba\u7c7b\u6548\u7528\u7684\u8fc7\u6e21\uff0c\u4e9f\u9700\u6865\u63a5\u673a\u5236\u3002", "method": "\u901a\u8fc7\u5f62\u5f0f\u5316\u76d1\u7763\u5fae\u8c03\u4e3a\u5206\u5e03\u91cd\u5851\u8fc7\u7a0b\uff0c\u5206\u6790\u73b0\u6709\u6210\u679c\u5e76\u5f52\u7eb3\u4e3a\u6b63\u4f18\u5148\uff08\u7528\u4e8e\u566a\u58f0\u8fc7\u6ee4\uff09\u548c\u7b26\u53f7\u4f18\u5148\uff08\u7528\u4e8e\u6709\u5bb3\u6a21\u5f0f\u9057\u5fd8\uff09\u4e24\u4e2a\u8303\u5f0f\u3002", "result": "\u672c\u6587\u7edf\u4e00\u89c6\u89d2\u4e0b\u590d\u76d8\u6700\u65b0\u8fdb\u5c55\u53ca\u5c40\u9650\uff0c\u660e\u786e\u6311\u6218\u5e76\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u63d0\u51faToken Priority\u4f5c\u4e3a\u76d1\u7763\u5fae\u8c03\u7684\u6838\u5fc3\u6865\u6881\uff0c\u8ba4\u4e3a\u5176\u80fd\u5b9e\u73b0\u6570\u636e\u4e0e\u7406\u60f3\u5bf9\u9f50\u6d41\u5f62\u7684\u7cbe\u786e\u5206\u5e03\u91cd\u5851\uff0c\u4fc3\u8fdb\u4ece\u7ecf\u9a8c\u6570\u636e\u62df\u5408\u5230\u771f\u5b9e\u4eba\u7c7b\u6548\u7528\u7684\u8f6c\u53d8\u3002"}}
{"id": "2602.01239", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.01239", "abs": "https://arxiv.org/abs/2602.01239", "authors": ["Jamshid Mozafari", "Hamed Zamani", "Guido Zuccon", "Adam Jatowt"], "title": "Inferential Question Answering", "comment": "Proceedings of the ACM Web Conference 2026 (WWW 2026)", "summary": "Despite extensive research on a wide range of question answering (QA) systems, most existing work focuses on answer containment-i.e., assuming that answers can be directly extracted and/or generated from documents in the corpus. However, some questions require inference, i.e., deriving answers that are not explicitly stated but can be inferred from the available information. We introduce Inferential QA -- a new task that challenges models to infer answers from answer-supporting passages which provide only clues. To study this problem, we construct QUIT (QUestions requiring Inference from Texts) dataset, comprising 7,401 questions and 2.4M passages built from high-convergence human- and machine-authored hints, labeled across three relevance levels using LLM-based answerability and human verification. Through comprehensive evaluation of retrievers, rerankers, and LLM-based readers, we show that methods effective on traditional QA tasks struggle in inferential QA: retrievers underperform, rerankers offer limited gains, and fine-tuning provides inconsistent improvements. Even reasoning-oriented LLMs fail to outperform smaller general-purpose models. These findings reveal that current QA pipelines are not yet ready for inference-based reasoning. Inferential QA thus establishes a new class of QA tasks that move towards understanding and reasoning from indirect textual evidence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u63a8\u7406\u95ee\u7b54\u4efb\u52a1\u548c\u76f8\u5e94\u6570\u636e\u96c6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u95ee\u7b54\u7cfb\u7edf\u5728\u63a8\u7406\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u4e86\u95ee\u7b54\u7814\u7a76\u4ece\u76f4\u63a5\u62bd\u53d6\u5411\u57fa\u4e8e\u63a8\u7406\u7684\u7406\u89e3\u8f6c\u53d8\u3002", "motivation": "\u4f20\u7edf\u95ee\u7b54\u7cfb\u7edf\u591a\u6570\u5047\u8bbe\u7b54\u6848\u53ef\u76f4\u63a5\u4ece\u6587\u672c\u4e2d\u62bd\u53d6\u6216\u751f\u6210\uff0c\u65e0\u6cd5\u5e94\u5bf9\u9700\u8981\u57fa\u4e8e\u95f4\u63a5\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\u5f97\u51fa\u7b54\u6848\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u63d0\u51fa\u63a8\u7406\u95ee\u7b54\u4efb\u52a1\u4ee5\u63a8\u52a8\u7cfb\u7edf\u7406\u89e3\u5e76\u63a8\u65ad\u9690\u542b\u7b54\u6848\u3002", "method": "\u6784\u5efa\u4e86QUIT\u6570\u636e\u96c6\uff0c\u5305\u542b7,401\u4e2a\u9700\u8981\u63a8\u7406\u7684\u95ee\u9898\u53ca2.4\u767e\u4e07\u4e2a\u9ad8\u76f8\u5173\u5ea6\u7684\u63d0\u793a\u6bb5\u843d\uff0c\u5e76\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u7b54\u6027\u8bc4\u4f30\u4e0e\u4eba\u5de5\u9a8c\u8bc1\u5bf9\u6bb5\u843d\u76f8\u5173\u6027\u8fdb\u884c\u6807\u7b7e\u5212\u5206\u3002\u7cfb\u7edf\u8bc4\u4f30\u4e86\u73b0\u6709\u7684\u68c0\u7d22\u5668\u3001\u91cd\u6392\u5e8f\u5668\u548c\u57fa\u4e8eLLM\u7684\u9605\u8bfb\u5668\u5728\u63a8\u7406\u95ee\u7b54\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f20\u7edf\u95ee\u7b54\u65b9\u6cd5\u5728\u63a8\u7406\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u5dee\u5f3a\u4eba\u610f\uff0c\u6a21\u578b\u96be\u4ee5\u4ece\u7ebf\u7d22\u6027\u6587\u672c\u4e2d\u63a8\u65ad\u7b54\u6848\uff0c\u9a8c\u8bc1\u4e86\u63a8\u7406\u95ee\u7b54\u4efb\u52a1\u7684\u6311\u6218\u6027\u548c\u73b0\u6709\u7cfb\u7edf\u7684\u4e0d\u8db3\u3002", "conclusion": "\u73b0\u6709\u7684\u95ee\u7b54\u7cfb\u7edf\u5728\u5904\u7406\u9700\u8981\u63a8\u7406\u7684\u95ee\u9898\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5f53\u524d\u7684\u68c0\u7d22\u3001\u91cd\u6392\u5e8f\u548c\u5fae\u8c03\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u5373\u4f7f\u662f\u9762\u5411\u63a8\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e5f\u672a\u80fd\u663e\u8457\u8d85\u8d8a\u5c0f\u578b\u901a\u7528\u6a21\u578b\uff0c\u8868\u660e\u73b0\u6709\u95ee\u7b54\u6d41\u7a0b\u5c1a\u672a\u51c6\u5907\u597d\u5e94\u5bf9\u57fa\u4e8e\u63a8\u7406\u7684\u4efb\u52a1\u3002"}}
{"id": "2602.01240", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01240", "abs": "https://arxiv.org/abs/2602.01240", "authors": ["Ke Sun", "Guangsheng Bao", "Han Cui", "Yue Zhang"], "title": "Minimizing Mismatch Risk: A Prototype-Based Routing Framework for Zero-shot LLM-generated Text Detection", "comment": null, "summary": "Zero-shot methods detect LLM-generated text by computing statistical signatures using a surrogate model. Existing approaches typically employ a fixed surrogate for all inputs regardless of the unknown source. We systematically examine this design and find that detection performance varies substantially depending on surrogate-source alignment. We observe that while no single surrogate achieves optimal performance universally, a well-matched surrogate typically exists within a diverse pool for any given input. This finding transforms robust detection into a routing problem: selecting the most appropriate surrogate for each input. We propose DetectRouter, a prototype-based framework that learns text-detector affinity through two-stage training. The first stage constructs discriminative prototypes from white-box models; the second generalizes to black-box sources by aligning geometric distances with observed detection scores. Experiments on EvoBench and MAGE benchmarks demonstrate consistent improvements across multiple detection criteria and model families.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9LLM\u751f\u6210\u6587\u672c\u68c0\u6d4b\u4ee3\u7406\u6a21\u578b\u9009\u62e9\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u539f\u578b\u7684DetectRouter\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u7684\u7a33\u5065\u63d0\u5347\u3002", "motivation": "\u5f53\u524d\u65b9\u6cd5\u56fa\u5b9a\u4f7f\u7528\u5355\u4e00\u4ee3\u7406\u6a21\u578b\u8fdb\u884c\u68c0\u6d4b\uff0c\u5ffd\u7565\u4e86\u4ee3\u7406\u4e0e\u6e90\u6a21\u578b\u4e0d\u5339\u914d\u5bfc\u81f4\u6027\u80fd\u5dee\u5f02\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u539f\u578b\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u6784\u5efa\u767d\u76d2\u6a21\u578b\u7684\u5224\u522b\u6027\u539f\u578b\uff1b\u7b2c\u4e8c\u9636\u6bb5\u901a\u8fc7\u5bf9\u9f50\u51e0\u4f55\u8ddd\u79bb\u548c\u68c0\u6d4b\u5206\u6570\uff0c\u63a8\u5e7f\u81f3\u9ed1\u76d2\u6a21\u578b\u3002", "result": "\u5728EvoBench\u548cMAGE\u57fa\u51c6\u4e0a\uff0cDetectRouter\u5728\u591a\u79cd\u68c0\u6d4b\u6307\u6807\u548c\u6a21\u578b\u7c7b\u522b\u4e2d\u5747\u8868\u73b0\u51fa\u7a33\u5b9a\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86DetectRouter\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6700\u5408\u9002\u7684\u4ee3\u7406\u6a21\u578b\u6765\u63d0\u5347LLM\u751f\u6210\u6587\u672c\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u663e\u8457\u6539\u8fdb\u4e86\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2602.01244", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01244", "abs": "https://arxiv.org/abs/2602.01244", "authors": ["Siwei Wu", "Yizhi Li", "Yuyang Song", "Wei Zhang", "Yang Wang", "Riza Batista-Navarro", "Xian Yang", "Mingjie Tang", "Bryan Dai", "Jian Yang", "Chenghua Lin"], "title": "Large-Scale Terminal Agentic Trajectory Generation from Dockerized Environments", "comment": "Agentic Trajectory, Agentic Model, Terminal, Code Agent", "summary": "Training agentic models for terminal-based tasks critically depends on high-quality terminal trajectories that capture realistic long-horizon interactions across diverse domains. However, constructing such data at scale remains challenging due to two key requirements: \\textbf{\\emph{Executability}}, since each instance requires a suitable and often distinct Docker environment; and \\textbf{\\emph{Verifiability}}, because heterogeneous task outputs preclude unified, standardized verification. To address these challenges, we propose \\textbf{TerminalTraj}, a scalable pipeline that (i) filters high-quality repositories to construct Dockerized execution environments, (ii) generates Docker-aligned task instances, and (iii) synthesizes agent trajectories with executable validation code. Using TerminalTraj, we curate 32K Docker images and generate 50,733 verified terminal trajectories across eight domains. Models trained on this data with the Qwen2.5-Coder backbone achieve consistent performance improvements on TerminalBench (TB), with gains of up to 20\\% on TB~1.0 and 10\\% on TB~2.0 over their respective backbones. Notably, \\textbf{TerminalTraj-32B} achieves strong performance among models with fewer than 100B parameters, reaching 35.30\\% on TB~1.0 and 22.00\\% on TB~2.0, and demonstrates improved test-time scaling behavior. All code and data are available at https://github.com/Wusiwei0410/TerminalTraj.", "AI": {"tldr": "\u4e3a\u8bad\u7ec3\u7ec8\u7aef\u4efb\u52a1\u4ee3\u7406\u6a21\u578b\uff0cTerminalTraj\u63d0\u51fa\u4e00\u79cd\u53ef\u6269\u5c55\u6d41\u6c34\u7ebf\uff0c\u81ea\u52a8\u6784\u5efa\u591a\u6837Docker\u73af\u5883\u5e76\u751f\u6210\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u4efb\u52a1\u8f68\u8ff9\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u8bad\u7ec3\u9762\u5411\u7ec8\u7aef\u4efb\u52a1\u7684\u4ee3\u7406\u6a21\u578b\u9700\u9ad8\u8d28\u91cf\u3001\u8de8\u9886\u57df\u7684\u957f\u65f6\u4ea4\u4e92\u8f68\u8ff9\uff0c\u4f46\u6784\u5efa\u6b64\u7c7b\u6570\u636e\u9700\u89e3\u51b3\u73af\u5883\u6267\u884c\u6027\u548c\u7ed3\u679c\u9a8c\u8bc1\u7684\u96be\u9898\u3002", "method": "\u63d0\u51faTerminalTraj\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u7b5b\u9009\u9ad8\u8d28\u91cf\u4ed3\u5e93\u6784\u5efaDocker\u73af\u5883\uff0c\u751f\u6210Docker\u5bf9\u9f50\u4efb\u52a1\u5b9e\u4f8b\uff0c\u5e76\u7efc\u5408\u6267\u884c\u9a8c\u8bc1\u4ee3\u7801\u5408\u6210\u4ee3\u7406\u8f68\u8ff9\u3002", "result": "\u6784\u5efa\u4e8632K Docker\u955c\u50cf\uff0c\u751f\u621050,733\u4e2a\u9a8c\u8bc1\u7ec8\u7aef\u8f68\u8ff9\uff0c\u6a21\u578b\u5728TerminalBench\u5404\u7248\u672c\u6d4b\u8bd5\u4e2d\u6027\u80fd\u63d0\u534720%\u53ca10%\uff0cTerminalTraj-32B\u6a21\u578b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "TerminalTraj\u6709\u6548\u89e3\u51b3\u4e86\u6267\u884c\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u6311\u6218\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u3001\u9ad8\u8d28\u91cf\u7684\u7ec8\u7aef\u4efb\u52a1\u8f68\u8ff9\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728TerminalBench\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.01246", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.01246", "abs": "https://arxiv.org/abs/2602.01246", "authors": ["Jamshid Mozafari", "Seyed Parsa Mousavinasab", "Adam Jatowt"], "title": "PARSE: An Open-Domain Reasoning Question Answering Benchmark for Persian", "comment": "Submitted to SIGIR 2026", "summary": "Reasoning-focused Question Answering (QA) has advanced rapidly with Large Language Models (LLMs), yet high-quality benchmarks for low-resource languages remain scarce. Persian, spoken by roughly 130 million people, lacks a comprehensive open-domain resource for evaluating reasoning-capable QA systems. We introduce PARSE, the first open-domain Persian reasoning QA benchmark, containing 10,800 questions across Boolean, multiple-choice, and factoid formats, with diverse reasoning types, difficulty levels, and answer structures. The benchmark is built via a controlled LLM-based generation pipeline and validated through human evaluation. We also ensure linguistic and factual quality through multi-stage filtering, annotation, and consistency checks. We benchmark multilingual and Persian LLMs under multiple prompting strategies and show that Persian prompts and structured prompting (CoT for Boolean/multiple-choice; few-shot for factoid) improve performance. Fine-tuning further boosts results, especially for Persian-specialized models. These findings highlight how PARSE supports both fair comparison and practical model adaptation. PARSE fills a critical gap in Persian QA research and provides a strong foundation for developing and evaluating reasoning-capable LLMs in low-resource settings.", "AI": {"tldr": "PARSE\u662f\u9996\u4e2a\u5f00\u653e\u57df\u6ce2\u65af\u8bed\u63a8\u7406\u95ee\u7b54\u57fa\u51c6\uff0c\u542b\u591a\u7c7b\u578b\u95ee\u9898\u4e0e\u590d\u6742\u63a8\u7406\uff0c\u901a\u8fc7\u4e25\u683c\u9a8c\u8bc1\u4e0e\u8fc7\u6ee4\u4fdd\u8bc1\u8d28\u91cf\uff0c\u8bc4\u6d4b\u663e\u793a\u4e13\u7528\u63d0\u793a\u4e0e\u5fae\u8c03\u53ef\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u4e3a\u6ce2\u65af\u8bed\u63a8\u7406QA\u7814\u7a76\u63d0\u4f9b\u91cd\u8981\u652f\u6301\u3002", "motivation": "\u6ce2\u65af\u8bed\u4f5c\u4e3a\u4e00\u79cd\u4f7f\u7528\u4eba\u6570\u4f17\u591a\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u5f00\u653e\u9886\u57df\u63a8\u7406\u95ee\u7b54\u57fa\u51c6\uff0c\u963b\u788d\u4e86\u76f8\u5173\u63a8\u7406QA\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u7684\u57fa\u4e8eLLM\u7684\u751f\u6210\u6d41\u7a0b\uff0c\u5e76\u7ed3\u5408\u591a\u9636\u6bb5\u8fc7\u6ee4\u3001\u6ce8\u91ca\u548c\u4e00\u81f4\u6027\u68c0\u67e5\uff0c\u6784\u5efa\u4e86\u5305\u542b\u591a\u79cd\u9898\u578b\u4e0e\u63a8\u7406\u7c7b\u578b\u7684PARSE\u95ee\u7b54\u57fa\u51c6\u3002", "result": "\u591a\u8bed\u8a00\u53ca\u6ce2\u65af\u8bedLLM\u5728PARSE\u57fa\u51c6\u4e0a\u7684\u8bc4\u6d4b\u8868\u660e\uff0c\u91c7\u7528\u6ce2\u65af\u8bed\u63d0\u793a\u8bcd\u548c\u7ed3\u6784\u5316\u63d0\u793a\uff08\u5e03\u5c14/\u9009\u62e9\u9898\u7684\u94fe\u5f0f\u601d\u7ef4\uff0c\u4e8b\u5b9e\u9898\u7684\u5c11\u6837\u672c\u63d0\u793a\uff09\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u8fdb\u4e00\u6b65\u5fae\u8c03\u6ce2\u65af\u8bed\u4e13\u7528\u6a21\u578b\u6548\u679c\u66f4\u4f73\u3002", "conclusion": "PARSE\u57fa\u51c6\u586b\u8865\u4e86\u6ce2\u65af\u8bed\u63a8\u7406\u95ee\u7b54\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u63a8\u7406\u80fd\u529b\u5f3a\u7684LLM\u53d1\u5c55\u4e0e\u8bc4\u4f30\u63d0\u4f9b\u4e86\u575a\u5b9e\u57fa\u7840\u3002"}}
{"id": "2602.01274", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01274", "abs": "https://arxiv.org/abs/2602.01274", "authors": ["Situo Zhang", "Yifan Zhang", "Zichen Zhu", "Hankun Wang", "Da Ma", "Danyang Zhang", "Lu Chen", "Kai Yu"], "title": "PACER: Blockwise Pre-verification for Speculative Decoding with Adaptive Length", "comment": null, "summary": "Speculative decoding (SD) is a powerful technique for accelerating the inference process of large language models (LLMs) without sacrificing accuracy. Typically, SD employs a small draft model to generate a fixed number of draft tokens, which are then verified in parallel by the target model. However, our experiments reveal that the optimal draft length varies significantly across different decoding steps. This variation suggests that using a fixed draft length limits the potential for further improvements in decoding speed. To address this challenge, we propose Pacer, a novel approach that dynamically controls draft length using a lightweight, trainable pre-verification layer. This layer pre-verifies draft tokens blockwise before they are sent to the target model, allowing the draft model to stop token generation if the blockwise pre-verification fails. We implement Pacer on multiple SD model pairs and evaluate its performance across various benchmarks. Our results demonstrate that Pacer achieves up to 2.66x Speedup over autoregressive decoding and consistently outperforms standard speculative decoding. Furthermore, when integrated with Ouroboros, Pacer attains up to 3.09x Speedup.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684Pacer\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u5206\u5757\u9884\u9a8c\u8bc1\u8349\u7a3f\u957f\u5ea6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u901f\u5ea6\u548c\u6548\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u6280\u672f\u3002", "motivation": "\u89c2\u5bdf\u5230\u56fa\u5b9a\u7684\u8349\u7a3f\u957f\u5ea6\u5728\u4e0d\u540c\u89e3\u7801\u6b65\u9aa4\u95f4\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u89e3\u7801\u901f\u5ea6\u7684\u63d0\u5347\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u52a8\u6001\u8c03\u6574\u8349\u7a3f\u957f\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aPacer\u7684\u65b0\u65b9\u6cd5\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u4e14\u53ef\u8bad\u7ec3\u7684\u9884\u9a8c\u8bc1\u5c42\u5206\u5757\u9884\u9a8c\u8bc1\u8349\u7a3f\u4ee4\u724c\uff0c\u52a8\u6001\u8c03\u6574\u8349\u7a3f\u957f\u5ea6\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u63a8\u7406\u901f\u5ea6\u3002", "result": "Pacer\u5728\u591a\u4e2a\u6a21\u578b\u5bf9\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u5b9e\u73b0\u4e86\u6700\u9ad82.66\u500d\u7684\u52a0\u901f\uff0c\u4e14\u7ed3\u5408Ouroboros\u65f6\u53ef\u8fbe3.09\u500d\u52a0\u901f\uff0c\u4f18\u4e8e\u6807\u51c6\u63a8\u6d4b\u89e3\u7801\u3002", "conclusion": "Pacer\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u8349\u7a3f\u957f\u5ea6\u663e\u8457\u52a0\u901f\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u56fa\u5b9a\u8349\u7a3f\u957f\u5ea6\u7684\u63a8\u7406\u65b9\u6cd5\u3002"}}
{"id": "2602.01313", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01313", "abs": "https://arxiv.org/abs/2602.01313", "authors": ["Chuanrui Hu", "Tong Li", "Xingze Gao", "Hongda Chen", "Dannong Xu", "Yi Bai", "Tianwei Lin", "Xinda Zhao", "Xiaohong Li", "Jiaqi An", "Yunyun Han", "Jian Pei", "Yafeng Deng"], "title": "EverMemBench: Benchmarking Long-Term Interactive Memory in Large Language ModelsEverMemBench: Benchmarking Long-Term Interactive Memory in Large Language Models", "comment": "10 pages, 2 figures, 4 tables", "summary": "Long-term conversational memory is essential for LLM-based assistants, yet existing benchmarks focus on dyadic, single-topic dialogues that fail to capture real-world complexity. We introduce EverMemBench, a benchmark featuring multi-party, multi-group conversations spanning over 1 million tokens with temporally evolving information, cross-topic interleaving, and role-specific personas. EverMemBench evaluates memory systems across three dimensions through 1,000+ QA pairs: fine-grained recall, memory awareness, and user profile understanding. Our evaluation reveals critical limitations: (1) multi-hop reasoning collapses in multi-party settings, with even oracle models achieving only 26%; (2) temporal reasoning remains unsolved, requiring version semantics beyond timestamp matching; (3) memory awareness is bottlenecked by retrieval, where current similarity-based methods fail to bridge the semantic gap between queries and implicitly relevant memories. EverMemBench provides a challenging testbed for developing next-generation memory architectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEverMemBench\uff0c\u4e00\u4e2a\u5305\u542b\u591a\u65b9\u591a\u4e3b\u9898\u5bf9\u8bdd\u7684\u957f\u671f\u8bb0\u5fc6\u6d4b\u8bd5\u57fa\u51c6\uff0c\u901a\u8fc7\u8bc4\u6d4b\u63ed\u793a\u4e86\u73b0\u6709\u5bf9\u8bdd\u8bb0\u5fc6\u7cfb\u7edf\u5728\u591a\u8df3\u63a8\u7406\u3001\u65f6\u95f4\u63a8\u7406\u548c\u8bb0\u5fc6\u68c0\u7d22\u65b9\u9762\u7684\u663e\u8457\u4e0d\u8db3\uff0c\u4fc3\u8fdb\u672a\u6765\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u7684\u5bf9\u8bdd\u8bb0\u5fc6\u57fa\u51c6\u591a\u96c6\u4e2d\u5728\u53cc\u4eba\u5355\u4e3b\u9898\u5bf9\u8bdd\uff0c\u672a\u80fd\u53cd\u6620\u771f\u5b9e\u4e16\u754c\u4e2d\u5bf9\u8bdd\u7684\u590d\u6742\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u5177\u6311\u6218\u6027\u548c\u590d\u6742\u6027\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u957f\u671f\u5bf9\u8bdd\u8bb0\u5fc6\u3002", "method": "\u63d0\u51faEverMemBench\u57fa\u51c6\uff0c\u5305\u542b\u591a\u65b9\u3001\u591a\u7ec4\u5bf9\u8bdd\uff0c\u8986\u76d6\u8d85\u8fc7\u4e00\u767e\u4e07\u4e2a\u6807\u8bb0\uff0c\u5177\u6709\u65f6\u5e8f\u6f14\u53d8\u4fe1\u606f\u3001\u8de8\u4e3b\u9898\u4ea4\u7ec7\u548c\u89d2\u8272\u7279\u5b9a\u7684\u4eba\u7269\u8bbe\u5b9a\uff0c\u8bbe\u8ba1\u4e861000+\u95ee\u7b54\u5bf9\u4ece\u7ec6\u7c92\u5ea6\u56de\u5fc6\u3001\u8bb0\u5fc6\u610f\u8bc6\u548c\u7528\u6237\u753b\u50cf\u7406\u89e3\u4e09\u7ef4\u5ea6\u8bc4\u4ef7\u8bb0\u5fc6\u7cfb\u7edf\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\u591a\u65b9\u73af\u5883\u4e2d\u591a\u8df3\u63a8\u7406\u6027\u80fd\u4e25\u91cd\u4e0b\u964d\uff0c\u9876\u7ea7\u6a21\u578b\u4ec5\u8fbe26%\uff1b\u65f6\u95f4\u63a8\u7406\u4ecd\u672a\u89e3\u51b3\uff0c\u9700\u8981\u8d85\u8d8a\u65f6\u95f4\u6233\u5339\u914d\u7684\u7248\u672c\u8bed\u4e49\uff1b\u57fa\u4e8e\u76f8\u4f3c\u5ea6\u7684\u68c0\u7d22\u65b9\u6cd5\u9650\u5236\u8bb0\u5fc6\u610f\u8bc6\uff0c\u672a\u80fd\u6709\u6548\u8fde\u63a5\u67e5\u8be2\u4e0e\u9690\u542b\u76f8\u5173\u8bb0\u5fc6\u3002", "conclusion": "EverMemBench\u4f5c\u4e3a\u4e00\u4e2a\u66f4\u590d\u6742\u548c\u771f\u5b9e\u7684\u957f\u671f\u5bf9\u8bdd\u8bb0\u5fc6\u6d4b\u8bd5\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u8bb0\u5fc6\u6a21\u578b\u7684\u5173\u952e\u77ed\u677f\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u8bb0\u5fc6\u67b6\u6784\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u6311\u6218\u548c\u65b9\u5411\u3002"}}
{"id": "2602.01326", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01326", "abs": "https://arxiv.org/abs/2602.01326", "authors": ["Zirui Wu", "Lin Zheng", "Zhihui Xie", "Jiacheng Ye", "Jiahui Gao", "Shansan Gong", "Yansong Feng", "Zhenguo Li", "Wei Bi", "Guorui Zhou", "Lingpeng Kong"], "title": "DreamOn: Diffusion Language Models For Code Infilling Beyond Fixed-size Canvas", "comment": "ICLR 2026", "summary": "Diffusion Language Models (DLMs) present a compelling alternative to autoregressive models, offering flexible, any-order infilling without specialized prompting design. However, their practical utility is blocked by a critical limitation: the requirement of a fixed-length masked sequence for generation. This constraint severely degrades code infilling performance when the predefined mask size mismatches the ideal completion length. To address this, we propose DreamOn, a novel diffusion framework that enables dynamic, variable-length generation. DreamOn augments the diffusion process with two length control states, allowing the model to autonomously expand or contract the output length based solely on its own predictions. We integrate this mechanism into existing DLMs with minimal modifications to the training objective and no architectural changes. Built upon Dream-Coder-7B and DiffuCoder-7B, DreamOn achieves infilling performance on par with state-of-the-art autoregressive models on HumanEval-Infilling and SantaCoder-FIM and matches oracle performance achieved with ground-truth length. Our work removes a fundamental barrier to the practical deployment of DLMs, significantly advancing their flexibility and applicability for variable-length generation. Our code is available at https://github.com/DreamLM/DreamOn.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDreamOn\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u957f\u5ea6\u63a7\u5236\u7a81\u7834\u6269\u6563\u8bed\u8a00\u6a21\u578b\u56fa\u5b9a\u957f\u5ea6\u9650\u5236\uff0c\u63d0\u5347\u4ee3\u7801\u8865\u5168\u6027\u80fd\uff0c\u5b9e\u73b0\u66f4\u7075\u6d3b\u7684\u53ef\u53d8\u957f\u5ea6\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u6269\u6563\u8bed\u8a00\u6a21\u578b\u9700\u8981\u56fa\u5b9a\u957f\u5ea6\u7684\u63a9\u7801\uff0c\u5bfc\u81f4\u63a9\u7801\u5c3a\u5bf8\u4e0e\u7406\u60f3\u8865\u5168\u957f\u5ea6\u4e0d\u5339\u914d\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e24\u4e2a\u957f\u5ea6\u63a7\u5236\u72b6\u6001\uff0cDreamOn\u5141\u8bb8\u6a21\u578b\u57fa\u4e8e\u81ea\u8eab\u9884\u6d4b\u52a8\u6001\u8c03\u6574\u8f93\u51fa\u957f\u5ea6\uff0c\u5e76\u5c06\u8be5\u673a\u5236\u96c6\u6210\u5230\u73b0\u6709\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u65e0\u9700\u6539\u53d8\u6a21\u578b\u67b6\u6784\uff0c\u4ec5\u9700\u6700\u5c0f\u8bad\u7ec3\u76ee\u6807\u8c03\u6574\u3002", "result": "DreamOn\u5728HumanEval-Infilling\u548cSantaCoder-FIM\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e0e\u6700\u5148\u8fdb\u81ea\u56de\u5f52\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u4e14\u8868\u73b0\u5339\u914d\u4f7f\u7528\u771f\u5b9e\u957f\u5ea6\u7684\u7406\u60f3\u6027\u80fd\u3002", "conclusion": "DreamOn\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u56fa\u5b9a\u957f\u5ea6\u63a9\u7801\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u52a8\u6001\u53ef\u53d8\u957f\u5ea6\u7684\u751f\u6210\u3002"}}
{"id": "2602.01348", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01348", "abs": "https://arxiv.org/abs/2602.01348", "authors": ["Yu Liu", "Wenxiao Zhang", "Cong Cao", "Fangfang Yuan", "Weizhuo Chen", "Cheng Hu", "Pin Xu", "Yuling Yang", "Kun Peng", "Diandian Guo", "Qiang Sun", "Yanbing Liu", "Jin B. Hong", "Zhiyuan Ma"], "title": "CRAFT: Calibrated Reasoning with Answer-Faithful Traces via Reinforcement Learning for Multi-Hop Question Answering", "comment": null, "summary": "Retrieval-augmented generation (RAG) is widely used to ground Large Language Models (LLMs) for multi-hop question answering. Recent work mainly focused on improving answer accuracy via fine-tuning and structured or reinforcement-based optimization. However, reliable reasoning in response generation faces three challenges: 1) Reasoning Collapse. Reasoning in multi-hop QA is inherently complex due to multi-hop composition and is further destabilized by noisy retrieval. 2) Reasoning-answer inconsistency. Due to the intrinsic uncertainty of LLM generation and exposure to evidence--distractor mixtures, models may produce correct answers that are not faithfully supported by their intermediate reasoning or evidence. 3) Loss of format control. Traditional chain-of-thought generation often deviates from required structured output formats, leading to incomplete or malformed structured content. To address these challenges, we propose CRAFT (Calibrated Reasoning with Answer-Faithful Traces), a Group Relative Policy Optimization (GRPO) based reinforcement learning framework that trains models to perform faithful reasoning during response generation. CRAFT employs dual reward mechanisms to optimize multi-hop reasoning: deterministic rewards ensure structural correctness while judge-based rewards verify semantic faithfulness. This optimization framework supports controllable trace variants that enable systematic analysis of how structure and scale affect reasoning performance and faithfulness. Experiments on three multi-hop QA benchmarks show that CRAFT improves both answer accuracy and reasoning faithfulness across model scales, with the CRAFT 7B model achieving competitive performance with closed-source LLMs across multiple reasoning trace settings.", "AI": {"tldr": "\u9488\u5bf9\u591a\u8df3\u95ee\u7b54\u751f\u6210\u4e2d\u63a8\u7406\u4e0d\u7a33\u5b9a\u548c\u683c\u5f0f\u5931\u63a7\u95ee\u9898\uff0cCRAFT\u63d0\u51fa\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u5956\u52b1\u4fc3\u8fdb\u7ed3\u6784\u5316\u4e14\u53ef\u4fe1\u7684\u63a8\u7406\uff0c\u63d0\u5347\u4e86\u591a\u8df3QA\u6027\u80fd\u548c\u63a8\u7406\u8d28\u91cf\u3002", "motivation": "\u591a\u8df3\u95ee\u7b54\u4e2d\u73b0\u6709\u751f\u6210\u673a\u5236\u5b58\u5728\u63a8\u7406\u5d29\u6e83\u3001\u63a8\u7406-\u7b54\u6848\u4e0d\u4e00\u81f4\u53ca\u683c\u5f0f\u5931\u63a7\u4e09\u5927\u6311\u6218\uff0c\u5bfc\u81f4\u751f\u6210\u63a8\u7406\u4e0d\u53ef\u9760\uff0c\u96be\u4ee5\u83b7\u5f97\u7ed3\u6784\u5316\u4e14\u53ef\u4fe1\u7684\u63a8\u7406\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u4e86CRAFT\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u7fa4\u4f53\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u5229\u7528\u786e\u5b9a\u6027\u5956\u52b1\u4fdd\u8bc1\u7ed3\u6784\u6b63\u786e\u6027\uff0c\u5224\u522b\u8005\u5956\u52b1\u4fdd\u8bc1\u8bed\u4e49\u53ef\u4fe1\u6027\uff0c\u652f\u6301\u53ef\u63a7\u7684\u63a8\u7406\u8f68\u8ff9\u53d8\u4f53\u4ee5\u7814\u7a76\u7ed3\u6784\u548c\u89c4\u6a21\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "CRAFT\u5728\u4e09\u4e2a\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u4e0a\u5747\u663e\u8457\u63d0\u5347\u4e86\u7b54\u6848\u51c6\u786e\u7387\u548c\u63a8\u7406\u7684\u53ef\u4fe1\u5ea6\uff0c7B\u6a21\u578b\u7684\u8868\u73b0\u53ef\u4e0e\u95ed\u6e90LLM\u76f8\u5ab2\u7f8e\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "CRAFT\u65b9\u6cd5\u901a\u8fc7\u7ed3\u5408\u53cc\u91cd\u5956\u52b1\u673a\u5236\u6709\u6548\u63d0\u5347\u4e86\u591a\u8df3\u95ee\u7b54\u4e2d\u7684\u7b54\u6848\u51c6\u786e\u6027\u548c\u63a8\u7406\u53ef\u4fe1\u5ea6\uff0c\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u4e14\u5728\u591a\u4e2a\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e0e\u95ed\u6e90\u5927\u6a21\u578b\u7ade\u4e89\u7684\u6027\u80fd\u3002"}}
{"id": "2602.01362", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01362", "abs": "https://arxiv.org/abs/2602.01362", "authors": ["Yue Liu", "Yuzhong Zhao", "Zheyong Xie", "Qixiang Ye", "Jianbin Jiao", "Yao Hu", "Shaosheng Cao", "Yunfan Liu"], "title": "Balancing Understanding and Generation in Discrete Diffusion Models", "comment": "32 pages, Code is available at https://github.com/MzeroMiko/XDLM", "summary": "In discrete generative modeling, two dominant paradigms demonstrate divergent capabilities: Masked Diffusion Language Models (MDLM) excel at semantic understanding and zero-shot generalization, whereas Uniform-noise Diffusion Language Models (UDLM) achieve strong few-step generation quality, yet neither attains balanced performance across both dimensions. To address this, we propose XDLM, which bridges the two paradigms via a stationary noise kernel. XDLM offers two key contributions: (1) it provides a principled theoretical unification of MDLM and UDLM, recovering each paradigm as a special case; and (2) an alleviated memory bottleneck enabled by an algebraic simplification of the posterior probabilities. Experiments demonstrate that XDLM advances the Pareto frontier between understanding capability and generation quality. Quantitatively, XDLM surpasses UDLM by 5.4 points on zero-shot text benchmarks and outperforms MDLM in few-step image generation (FID 54.1 vs. 80.8). When scaled to tune an 8B-parameter large language model, XDLM achieves 15.0 MBPP in just 32 steps, effectively doubling the baseline performance. Finally, analysis of training dynamics reveals XDLM's superior potential for long-term scaling. Code is available at https://github.com/MzeroMiko/XDLM", "AI": {"tldr": "\u672c\u6587\u63d0\u51faXDLM\u6a21\u578b\uff0c\u7406\u8bba\u4e0a\u7edf\u4e00MDLM\u548cUDLM\u4e24\u5927\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u5e73\u7a33\u566a\u58f0\u6838\u548c\u540e\u9a8c\u6982\u7387\u4ee3\u6570\u7b80\u5316\uff0c\u5b9e\u73b0\u8bed\u4e49\u7406\u89e3\u4e0e\u751f\u6210\u8d28\u91cf\u7684\u5e73\u8861\u63d0\u5347\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u9488\u5bf9MDLM\u5728\u96f6\u6837\u672c\u6cdb\u5316\u548cUDLM\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u7684\u5404\u81ea\u4f18\u52bf\u4e0e\u4e0d\u8db3\uff0c\u5bfb\u6c42\u4e24\u8005\u7684\u5e73\u8861\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u5e73\u7a33\u566a\u58f0\u6838\uff0cXDLM\u5b9e\u73b0\u4e86\u7406\u8bba\u4e0a\u7684\u7edf\u4e00\uff0c\u5e76\u901a\u8fc7\u4ee3\u6570\u7b80\u5316\u51cf\u5c11\u4e86\u5185\u5b58\u74f6\u9888\u3002", "result": "XDLM\u5728\u96f6\u6837\u672c\u6587\u672c\u4efb\u52a1\u4e0a\u8d85\u8d8aUDLM 5.4\u5206\uff0c\u5728\u5c11\u6b65\u56fe\u50cf\u751f\u6210\u4efb\u52a1\u4e0a\u4f18\u4e8eMDLM\uff08FID 54.1\u5bf9\u6bd480.8\uff09\uff0c\u5e76\u57288B\u53c2\u6570\u6a21\u578b\u4e2d\u5b9e\u73b032\u6b65\u8fbe\u523015.0 MBPP\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u548c\u957f\u671f\u6269\u5c55\u6f5c\u529b\u3002", "conclusion": "XDLM\u6210\u529f\u7edf\u4e00\u4e86MDLM\u548cUDLM\u4e24\u5927\u751f\u6210\u6a21\u578b\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u5728\u8bed\u4e49\u7406\u89e3\u4e0e\u751f\u6210\u8d28\u91cf\u4e0a\u7684\u5747\u8861\u63d0\u5347\u3002"}}
{"id": "2602.01378", "categories": ["cs.CL", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01378", "abs": "https://arxiv.org/abs/2602.01378", "authors": ["Poushali Sengupta", "Shashi Raj Pandey", "Sabita Maharjan", "Frank Eliassen"], "title": "Context Dependence and Reliability in Autoregressive Language Models", "comment": null, "summary": "Large language models (LLMs) generate outputs by utilizing extensive context, which often includes redundant information from prompts, retrieved passages, and interaction history. In critical applications, it is vital to identify which context elements actually influence the output, as standard explanation methods struggle with redundancy and overlapping context. Minor changes in input can lead to unpredictable shifts in attribution scores, undermining interpretability and raising concerns about risks like prompt injection. This work addresses the challenge of distinguishing essential context elements from correlated ones. We introduce RISE (Redundancy-Insensitive Scoring of Explanation), a method that quantifies the unique influence of each input relative to others, minimizing the impact of redundancies and providing clearer, stable attributions. Experiments demonstrate that RISE offers more robust explanations than traditional methods, emphasizing the importance of conditional information for trustworthy LLM explanations and monitoring.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faRISE\u65b9\u6cd5\uff0c\u51cf\u5c11\u5197\u4f59\u4e0a\u4e0b\u6587\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u89e3\u91ca\u7684\u5f71\u54cd\uff0c\u5b9e\u73b0\u66f4\u7a33\u5065\u53ef\u4fe1\u7684\u4e0a\u4e0b\u6587\u5f52\u56e0\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u8f93\u51fa\u65f6\u5305\u542b\u5927\u91cf\u5197\u4f59\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f20\u7edf\u89e3\u91ca\u65b9\u6cd5\u96be\u4ee5\u533a\u5206\u771f\u6b63\u5f71\u54cd\u8f93\u51fa\u7684\u5173\u952e\u4e0a\u4e0b\u6587\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u7a33\u5b9a\u548c\u53ef\u89e3\u91ca\u6027\u5dee\u3002", "method": "\u63d0\u51faRISE\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u6bcf\u4e2a\u8f93\u5165\u76f8\u5bf9\u4e8e\u5176\u4ed6\u8f93\u5165\u7684\u72ec\u7279\u5f71\u54cd\uff0c\u51cf\u5c11\u5197\u4f59\u4fe1\u606f\u7684\u5e72\u6270\uff0c\u5b9e\u73b0\u66f4\u6e05\u6670\u7a33\u5b9a\u7684\u5f52\u56e0\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRISE\u6bd4\u4f20\u7edf\u65b9\u6cd5\u66f4\u7a33\u5065\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u8bc6\u522b\u5173\u952e\u4e0a\u4e0b\u6587\u5143\u7d20\uff0c\u63d0\u5347LLM\u89e3\u91ca\u7684\u53ef\u4fe1\u5ea6\u548c\u76d1\u63a7\u6548\u7387\u3002", "conclusion": "RISE\u6709\u6548\u89e3\u51b3\u4e86\u5197\u4f59\u4e0a\u4e0b\u6587\u5e72\u6270\u5e26\u6765\u7684\u89e3\u91ca\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u4e3a\u91cd\u8981\u5e94\u7528\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u53ef\u89e3\u91ca\u6027\u63d0\u4f9b\u4e86\u53ef\u9760\u652f\u6301\u3002"}}
{"id": "2602.01381", "categories": ["cs.CL", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.01381", "abs": "https://arxiv.org/abs/2602.01381", "authors": ["Youheng Zhu", "Yiping Lu"], "title": "On the Power of (Approximate) Reward Models for Inference-Time Scaling", "comment": null, "summary": "Inference-time scaling has recently emerged as a powerful paradigm for improving the reasoning capability of large language models. Among various approaches, Sequential Monte Carlo (SMC) has become a particularly important framework, enabling iterative generation, evaluation, rejection, and resampling of intermediate reasoning trajectories. A central component in this process is the reward model, which evaluates partial solutions and guides the allocation of computation during inference.\n  However, in practice, true reward models are never available. All deployed systems rely on approximate reward models, raising a fundamental question: Why and when do approximate reward models suffice for effective inference-time scaling? In this work, we provide a theoretical answer. We identify the Bellman error of the approximate reward model as the key quantity governing the effectiveness of SMC-based inference-time scaling. For a reasoning process of length $T$, we show that if the Bellman error of the approximate reward model is bounded by $O(1/T)$, then combining this reward model with SMC reduces the computational complexity of reasoning from exponential in $T$ to polynomial in $T$. This yields an exponential improvement in inference efficiency despite using only approximate rewards.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u53ea\u8981\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\u7684Bellman\u8bef\u5dee\u8db3\u591f\u5c0f\uff0c\u7ed3\u5408SMC\u65b9\u6cd5\u80fd\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6548\u7387\uff0c\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u63a8\u7406\u8fc7\u7a0b\u4e2d\u771f\u5b9e\u5956\u52b1\u6a21\u578b\u4e0d\u53ef\u7528\uff0c\u4f9d\u8d56\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\uff0c\u56e0\u6b64\u9700\u8981\u7406\u89e3\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\u4f55\u65f6\u80fd\u591f\u6709\u6548\u652f\u6301\u63a8\u7406\u6269\u5c55\u3002", "method": "\u7406\u8bba\u5206\u6790\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\u7684Bellman\u8bef\u5dee\uff0c\u8bc1\u660e\u5176\u754c\u9650\u5bf9\u57fa\u4e8eSMC\u7684\u63a8\u7406\u6269\u5c55\u6548\u679c\u7684\u5173\u952e\u4f5c\u7528\u3002", "result": "\u82e5\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\u7684Bellman\u8bef\u5dee\u88ab\u7ea6\u675f\u5728O(1/T)\u5185\uff0c\u5219\u7ed3\u5408SMC\u80fd\u5c06\u63a8\u7406\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u6307\u6570\u7ea7\u964d\u4f4e\u5230\u591a\u9879\u5f0f\u7ea7\uff0c\u5b9e\u73b0\u63a8\u7406\u6548\u7387\u7684\u6307\u6570\u7ea7\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u7406\u8bba\u9610\u660e\u4e86\u8fd1\u4f3c\u5956\u52b1\u6a21\u578b\u8db3\u4ee5\u652f\u6301\u6709\u6548\u63a8\u7406\u6269\u5c55\u7684\u6761\u4ef6\uff0c\u4e3a\u4f7f\u7528\u8fd1\u4f3c\u6a21\u578b\u8fdb\u884c\u63a8\u7406\u65f6\u95f4\u6269\u5c55\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u6548\u7387\u4fdd\u8bc1\u3002"}}
{"id": "2602.01395", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01395", "abs": "https://arxiv.org/abs/2602.01395", "authors": ["Almog Tavor", "Itay Ebenspanger", "Neil Cnaan", "Mor Geva"], "title": "Rethinking Selective Knowledge Distillation", "comment": null, "summary": "Growing efforts to improve knowledge distillation (KD) in large language models (LLMs) replace dense teacher supervision with selective distillation, which uses a subset of token positions, vocabulary classes, or training samples for supervision. However, it remains unclear which importance signals, selection policies, and their interplay are most effective. In this work, we revisit where and how to distill in autoregressive LLMs. We disentangle selective KD along the position, class, and sample axes and systematically compare importance signals and selection policies. Then, guided by this analysis, we identify underexplored opportunities and introduce student-entropy-guided position selection (SE-KD). Across a suite of benchmarks, SE-KD often improves accuracy, downstream task adherence, and memory efficiency over dense distillation. Extending this approach across the class and sample axes (SE-KD 3X) yields complementary efficiency gains that make offline teacher caching feasible. In practice, this reduces wall time by 70% and peak memory by 18%, while cutting storage usage by 80% over prior methods without sacrificing performance.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u548c\u5b66\u751f\u71b5\u5f15\u5bfc\u7b56\u7565\uff0c\u6539\u8fdb\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9009\u62e9\u6027\u77e5\u8bc6\u84b8\u998f\uff0c\u663e\u8457\u63d0\u9ad8\u6548\u7387\u548c\u6027\u80fd\uff0c\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u5f53\u524d\u77e5\u8bc6\u84b8\u998f\u4e2d\u4f7f\u7528\u5bc6\u96c6\u76d1\u7763\u6548\u7387\u4f4e\u4e14\u8d44\u6e90\u6d88\u8017\u5927\uff0c\u9009\u62e9\u6027\u84b8\u998f\u7684\u6700\u4f73\u4fe1\u53f7\u548c\u7b56\u7565\u5c1a\u672a\u660e\u786e\u3002", "method": "\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86\u4e0d\u540c\u91cd\u8981\u6027\u4fe1\u53f7\u548c\u9009\u62e9\u7b56\u7565\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5b66\u751f\u71b5\u7684\u9009\u62e9\u673a\u5236\uff0c\u6269\u5c55\u5230\u4f4d\u7f6e\u3001\u7c7b\u522b\u548c\u6837\u672c\u7ef4\u5ea6\u8fdb\u884c\u591a\u7ef4\u5ea6\u84b8\u998f\u4f18\u5316\u3002", "result": "SE-KD\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3001\u4efb\u52a1\u7b26\u5408\u5ea6\u548c\u5185\u5b58\u6548\u7387\uff0c\u6269\u5c55\u540e\uff08SE-KD 3X\uff09\u663e\u8457\u51cf\u5c11\u4e86\u8bad\u7ec3\u65f6\u95f4\u3001\u5cf0\u503c\u5185\u5b58\u548c\u5b58\u50a8\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "\u9009\u62e9\u6027\u77e5\u8bc6\u84b8\u998f\u5728\u4f4d\u7f6e\u3001\u7c7b\u522b\u548c\u6837\u672c\u7ef4\u5ea6\u4e0a\u6709\u6548\uff0c\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u5b66\u751f\u71b5\u7684\u9009\u62e9\u7b56\u7565\uff08SE-KD\uff09\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2602.01401", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01401", "abs": "https://arxiv.org/abs/2602.01401", "authors": ["Niansong Zhang", "Sunwoo Kim", "Shreesha Srinath", "Zhiru Zhang"], "title": "From Pragmas to Partners: A Symbiotic Evolution of Agentic High-Level Synthesis", "comment": null, "summary": "The rise of large language models has sparked interest in AI-driven hardware design, raising the question: does high-level synthesis (HLS) still matter in the agentic era? We argue that HLS remains essential. While we expect mature agentic hardware systems to leverage both HLS and RTL, this paper focuses on HLS and its role in enabling agentic optimization. HLS offers faster iteration cycles, portability, and design permutability that make it a natural layer for agentic optimization.This position paper makes three contributions. First, we explain why HLS serves as a practical abstraction layer and a golden reference for agentic hardware design. Second, we identify key limitations of current HLS tools, namely inadequate performance feedback, rigid interfaces, and limited debuggability that agents are uniquely positioned to address. Third, we propose a taxonomy for the symbiotic evolution of agentic HLS, clarifying how responsibility shifts from human designers to AI agents as systems advance from copilots to autonomous design partners.", "AI": {"tldr": "\u672c\u6587\u8bba\u8bc1\u4e86\u9ad8\u5c42\u6b21\u7efc\u5408\uff08HLS\uff09\u5728\u667a\u80fd\u786c\u4ef6\u65f6\u4ee3\u7684\u91cd\u8981\u6027\uff0c\u6307\u51fa\u5f53\u524d\u5de5\u5177\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u667a\u80fdHLS\u53d1\u5c55\u7684\u6846\u67b6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5174\u8d77\uff0c\u63a2\u8ba8\u5728\u667a\u80fd\u786c\u4ef6\u8bbe\u8ba1\u65f6\u4ee3\uff0cHLS\u662f\u5426\u4f9d\u7136\u91cd\u8981\u3002", "method": "\u901a\u8fc7\u5206\u6790HLS\u5728\u667a\u80fd\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u7684\u4f5c\u7528\uff0c\u6307\u51fa\u5f53\u524dHLS\u5de5\u5177\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u667a\u80fdHLS\u7cfb\u7edf\u7684\u53d1\u5c55\u5206\u7c7b\u3002", "result": "\u63d0\u51faHLS\u4f5c\u4e3a\u667a\u80fd\u786c\u4ef6\u8bbe\u8ba1\u7684\u5b9e\u7528\u62bd\u8c61\u5c42\uff0c\u5e76\u8bc6\u522b\u5f53\u524dHLS\u5de5\u5177\u7684\u5c40\u9650\u6027\uff0c\u6700\u540e\u63d0\u51fa\u667a\u80fdHLS\u7684\u534f\u540c\u8fdb\u5316\u5206\u7c7b\u3002", "conclusion": "\u9ad8\u5c42\u6b21\u7efc\u5408\uff08HLS\uff09\u5728\u667a\u80fd\u786c\u4ef6\u8bbe\u8ba1\u4e2d\u4ecd\u7136\u81f3\u5173\u91cd\u8981\uff0c\u662f\u5b9e\u73b0\u667a\u80fd\u4f18\u5316\u7684\u5173\u952e\u62bd\u8c61\u5c42\u3002"}}
{"id": "2602.01447", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01447", "abs": "https://arxiv.org/abs/2602.01447", "authors": ["Hieu Minh Duong", "Rupa Ghosh", "Cong Hoan Nguyen", "Eugene Levin", "Todd Gary", "Long Nguyen"], "title": "SentiFuse: Deep Multi-model Fusion Framework for Robust Sentiment Extraction", "comment": null, "summary": "Sentiment analysis models exhibit complementary strengths, yet existing approaches lack a unified framework for effective integration. We present SentiFuse, a flexible and model-agnostic framework that integrates heterogeneous sentiment models through a standardization layer and multiple fusion strategies. Our approach supports decision-level fusion, feature-level fusion, and adaptive fusion, enabling systematic combination of diverse models. We conduct experiments on three large-scale social-media datasets: Crowdflower, GoEmotions, and Sentiment140. These experiments show that SentiFuse consistently outperforms individual models and naive ensembles. Feature-level fusion achieves the strongest overall effectiveness, yielding up to 4\\% absolute improvement in F1 score over the best individual model and simple averaging, while adaptive fusion enhances robustness on challenging cases such as negation, mixed emotions, and complex sentiment expressions. These results demonstrate that systematically leveraging model complementarity yields more accurate and reliable sentiment analysis across diverse datasets and text types.", "AI": {"tldr": "SentiFuse\u6846\u67b6\u901a\u8fc7\u591a\u79cd\u878d\u5408\u7b56\u7565\u6574\u5408\u5f02\u6784\u60c5\u611f\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u60c5\u611f\u5206\u6790\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u5206\u6790\u6a21\u578b\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u7f3a\u4e4f\u4e00\u4e2a\u7edf\u4e00\u4e14\u9ad8\u6548\u7684\u6846\u67b6\u6765\u6574\u5408\u8fd9\u4e9b\u6a21\u578b\u7684\u4e92\u8865\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7075\u6d3b\u4e14\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6SentiFuse\uff0c\u901a\u8fc7\u6807\u51c6\u5316\u5c42\u548c\u591a\u79cd\u878d\u5408\u7b56\u7565\uff08\u51b3\u7b56\u7ea7\u878d\u5408\u3001\u7279\u5f81\u7ea7\u878d\u5408\u3001\u81ea\u9002\u5e94\u878d\u5408\uff09\u6574\u5408\u5f02\u6784\u60c5\u611f\u6a21\u578b\u3002", "result": "\u5728Crowdflower\u3001GoEmotions\u548cSentiment140\u4e09\u4e2a\u5927\u578b\u793e\u4ea4\u5a92\u4f53\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSentiFuse\u4f18\u4e8e\u5355\u6a21\u578b\u548c\u7b80\u5355\u5e73\u5747\u96c6\u6210\uff0c\u7279\u5f81\u7ea7\u878d\u5408\u63d0\u5347F1\u5206\u6570\u6700\u9ad8\u8fbe4%\uff0c\u81ea\u9002\u5e94\u878d\u5408\u589e\u5f3a\u4e86\u5bf9\u5426\u5b9a\u3001\u6df7\u5408\u60c5\u7eea\u53ca\u590d\u6742\u8868\u8fbe\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "SentiFuse\u6846\u67b6\u901a\u8fc7\u7cfb\u7edf\u5730\u878d\u5408\u591a\u79cd\u60c5\u611f\u5206\u6790\u6a21\u578b\u7684\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u6bd4\u5355\u4e00\u6a21\u578b\u548c\u7b80\u5355\u96c6\u6210\u65b9\u6cd5\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u63d0\u5347\u4e86\u60c5\u611f\u5206\u6790\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.01451", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01451", "abs": "https://arxiv.org/abs/2602.01451", "authors": ["Umme Abira Azmary", "MD Ikramul Kayes", "Swakkhar Shatabda", "Farig Yousuf Sadeque"], "title": "Understanding QA generation: Extracting Parametric and Contextual Knowledge with CQA for Low Resource Bangla Language", "comment": null, "summary": "Question-Answering (QA) models for low-resource languages like Bangla face challenges due to limited annotated data and linguistic complexity. A key issue is determining whether models rely more on pre-encoded (parametric) knowledge or contextual input during answer generation, as existing Bangla QA datasets lack the structure required for such analysis. We introduce BanglaCQA, the first Counterfactual QA dataset in Bangla, by extending a Bangla dataset while integrating counterfactual passages and answerability annotations. In addition, we propose fine-tuned pipelines for encoder-decoder language-specific and multilingual baseline models, and prompting-based pipelines for decoder-only LLMs to disentangle parametric and contextual knowledge in both factual and counterfactual scenarios. Furthermore, we apply LLM-based and human evaluation techniques that measure answer quality based on semantic similarity. We also present a detailed analysis of how models perform across different QA settings in low-resource languages, and show that Chain-of-Thought (CoT) prompting reveals a uniquely effective mechanism for extracting parametric knowledge in counterfactual scenarios, particularly in decoder-only LLMs. Our work not only introduces a novel framework for analyzing knowledge sources in Bangla QA but also uncovers critical findings that open up broader directions for counterfactual reasoning in low-resource language settings.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u95ee\u7b54\u4efb\u52a1\u6784\u5efa\u4e86\u9996\u4e2a\u53cd\u4e8b\u5b9e\u95ee\u7b54\u6570\u636e\u96c6BanglaCQA\uff0c\u8bbe\u8ba1\u591a\u79cd\u65b9\u6cd5\u533a\u5206\u6a21\u578b\u7684\u53c2\u6570\u5316\u77e5\u8bc6\u4e0e\u4e0a\u4e0b\u6587\u77e5\u8bc6\u5229\u7528\uff0c\u53d1\u73b0\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u80fd\u6709\u6548\u63d0\u5347\u53cd\u4e8b\u5b9e\u573a\u666f\u4e2d\u53c2\u6570\u77e5\u8bc6\u7684\u63d0\u53d6\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u95ee\u7b54\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u9762\u4e34\u6709\u9650\u6807\u6ce8\u6570\u636e\u548c\u8bed\u8a00\u590d\u6742\u6027\u7684\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u53ef\u5206\u6790\u6a21\u578b\u77e5\u8bc6\u6765\u6e90\u7684\u7ed3\u6784\u5316\u6570\u636e\u96c6\u3002\u56e0\u6b64\uff0c\u8feb\u5207\u9700\u8981\u6784\u5efa\u65b0\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u4ee5\u63ed\u793a\u6a21\u578b\u5982\u4f55\u5229\u7528\u53c2\u6570\u5316\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u751f\u6210\u7b54\u6848\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u539f\u6709\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u96c6\uff0c\u6784\u5efa\u5305\u542b\u53cd\u4e8b\u5b9e\u6bb5\u843d\u548c\u53ef\u56de\u7b54\u6027\u6807\u6ce8\u7684BanglaCQA\u6570\u636e\u96c6\uff1b\u8bbe\u8ba1\u57fa\u4e8e\u7f16\u7801\u5668-\u89e3\u7801\u5668\u548c\u591a\u8bed\u8a00\u6a21\u578b\u7684\u5fae\u8c03\u6d41\u7a0b\uff0c\u4ee5\u53ca\u57fa\u4e8e\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u6d41\u7a0b\uff1b\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u7b54\u6848\u8d28\u91cf\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u5b5f\u52a0\u62c9\u8bed\u53cd\u4e8b\u5b9e\u95ee\u7b54\u6570\u636e\u96c6BanglaCQA\uff0c\u63d0\u51fa\u4e86\u591a\u79cd\u6a21\u578b\u5fae\u8c03\u548c\u63d0\u793a\u65b9\u6848\uff0c\u7ed3\u5408\u4eba\u5de5\u4e0e\u81ea\u52a8\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u94fe\u5f0f\u601d\u8003\u63d0\u793a\u5728\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u72ec\u7279\u4e14\u6709\u6548\u7684\u4f5c\u7528\uff0c\u5e76\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u95ee\u7b54\u6a21\u578b\u7684\u77e5\u8bc6\u4f9d\u8d56\u8fdb\u884c\u4e86\u6df1\u5165\u5206\u6790\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86BanglaCQA\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u7684\u53cd\u4e8b\u5b9e\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u540c\u65f6\u5206\u6790\u4e86\u6a21\u578b\u5728\u4e8b\u5b9e\u4e0e\u53cd\u4e8b\u5b9e\u573a\u666f\u4e2d\u5bf9\u53c2\u6570\u5316\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u4f9d\u8d56\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5728\u53cd\u4e8b\u5b9e\u573a\u666f\u4e0b\uff0c\u57fa\u4e8e\u94fe\u5f0f\u601d\u8003(CoT)\u63d0\u793a\u7684\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u66f4\u6709\u6548\u5730\u63d0\u53d6\u53c2\u6570\u5316\u77e5\u8bc6\u3002"}}
{"id": "2602.01472", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01472", "abs": "https://arxiv.org/abs/2602.01472", "authors": ["Jie Deng", "Shining Liang", "Jun Li", "Hongzhi Li", "Yutao Xie"], "title": "ConPress: Learning Efficient Reasoning from Multi-Question Contextual Pressure", "comment": null, "summary": "Large reasoning models (LRMs) typically solve reasoning-intensive tasks by generating long chain-of-thought (CoT) traces, leading to substantial inference overhead. We identify a reproducible inference-time phenomenon, termed Self-Compression: when multiple independent and answerable questions are presented within a single prompt, the model spontaneously produces shorter reasoning traces for each question. This phenomenon arises from multi-question contextual pressure during generation and consistently manifests across models and benchmarks. Building on this observation, we propose ConPress (Learning from Contextual Pressure), a lightweight self-supervised fine-tuning approach. ConPress constructs multi-question prompts to induce self-compression, samples the resulting model outputs, and parses and filters per-question traces to obtain concise yet correct reasoning trajectories. These trajectories are directly used for supervised fine-tuning, internalizing compressed reasoning behavior in single-question settings without external teachers, manual pruning, or reinforcement learning. With only 8k fine-tuning examples, ConPress reduces reasoning token usage by 59% on MATH500 and 33% on AIME25, while maintaining competitive accuracy.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u73b0\u4e86\u591a\u95ee\u4e0a\u4e0b\u6587\u8bf1\u5bfc\u6a21\u578b\u81ea\u53d1\u538b\u7f29\u63a8\u7406\u94fe\u7684\u73b0\u8c61\uff08\u81ea\u538b\u7f29\uff09\uff0c\u5e76\u63d0\u51faConPress\u65b9\u6cd5\u5229\u7528\u8fd9\u4e00\u73b0\u8c61\u8fdb\u884c\u81ea\u76d1\u7763\u5fae\u8c03\uff0c\u5927\u5e45\u51cf\u5c11\u63a8\u7406token\u5f00\u9500\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u7387\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u751f\u6210\u957f\u94fe\u5f0f\u63a8\u7406\u65f6\u63a8\u7406\u5f00\u9500\u5927\uff0c\u4e14\u5728\u5355\u95ee\u573a\u666f\u4e0b\u7f3a\u4e4f\u81ea\u52a8\u538b\u7f29\u63a8\u7406\u8fc7\u7a0b\u7684\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u95ee\u7684\u4e0a\u4e0b\u6587\u63d0\u793a\uff0c\u8bf1\u5bfc\u6a21\u578b\u4ea7\u751f\u66f4\u77ed\u7684\u63a8\u7406\u94fe\uff08\u81ea\u538b\u7f29\u73b0\u8c61\uff09\uff0c\u91c7\u6837\u5e76\u89e3\u6790\u591a\u95ee\u8f93\u51fa\uff0c\u8fc7\u6ee4\u5e76\u83b7\u5f97\u6bcf\u4e2a\u95ee\u9898\u7684\u538b\u7f29\u63a8\u7406\u8f68\u8ff9\uff0c\u5229\u7528\u8fd9\u4e9b\u8f68\u8ff9\u8fdb\u884c\u76d1\u7763\u5fae\u8c03\uff0c\u65e0\u9700\u5916\u90e8\u6559\u5e08\u3001\u4eba\u5de5\u526a\u679d\u6216\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5728MATH500\u548cAIME25\u6570\u636e\u96c6\u4e0a\uff0cConPress\u5206\u522b\u51cf\u5c11\u63a8\u7406token\u4f7f\u7528\u91cf59%\u548c33%\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u51c6\u786e\u7387\uff0c\u4e14\u53ea\u75288000\u4e2a\u5fae\u8c03\u6837\u672c\u3002", "conclusion": "ConPress\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u5728\u5355\u95ee\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u6a21\u578b\u81ea\u538b\u7f29\u63a8\u7406\u8f68\u8ff9\uff0c\u663e\u8457\u51cf\u5c11\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684token\u4f7f\u7528\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002"}}
{"id": "2602.01479", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01479", "abs": "https://arxiv.org/abs/2602.01479", "authors": ["Xueqing Peng", "Ruoyu Xiang", "Fan Zhang", "Mingzi Song", "Mingyang Jiang", "Yan Wang", "Lingfei Qian", "Taiki Hara", "Yuqing Guo", "Jimin Huang", "Junichi Tsujii", "Sophia Ananiadou"], "title": "Ebisu: Benchmarking Large Language Models in Japanese Finance", "comment": null, "summary": "Japanese finance combines agglutinative, head-final linguistic structure, mixed writing systems, and high-context communication norms that rely on indirect expression and implicit commitment, posing a substantial challenge for LLMs. We introduce Ebisu, a benchmark for native Japanese financial language understanding, comprising two linguistically and culturally grounded, expert-annotated tasks: JF-ICR, which evaluates implicit commitment and refusal recognition in investor-facing Q&A, and JF-TE, which assesses hierarchical extraction and ranking of nested financial terminology from professional disclosures. We evaluate a diverse set of open-source and proprietary LLMs spanning general-purpose, Japanese-adapted, and financial models. Results show that even state-of-the-art systems struggle on both tasks. While increased model scale yields limited improvements, language- and domain-specific adaptation does not reliably improve performance, leaving substantial gaps unresolved. Ebisu provides a focused benchmark for advancing linguistically and culturally grounded financial NLP. All datasets and evaluation scripts are publicly released.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEbisu\u57fa\u51c6\uff0c\u805a\u7126\u65e5\u672c\u91d1\u878d\u8bed\u8a00\u7406\u89e3\u7684\u96be\u70b9\uff0c\u901a\u8fc7\u4e24\u4e2a\u4e13\u5bb6\u6807\u6ce8\u4efb\u52a1\u8bc4\u4f30\u591a\u6b3e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u7406\u89e3\u65e5\u672c\u91d1\u878d\u6587\u672c\u4e0a\u7684\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u3002", "motivation": "\u7531\u4e8e\u65e5\u8bed\u91d1\u878d\u6587\u672c\u7684\u8bed\u8a00\u7279\u6027\uff08\u9ecf\u7740\u8bed\u3001\u53e5\u5c3e\u7ed3\u6784\u3001\u6df7\u5408\u4e66\u5199\u7cfb\u7edf\uff09\u53ca\u9ad8\u8bed\u5883\u4ea4\u6d41\u4e60\u60ef\uff08\u95f4\u63a5\u8868\u8fbe\u548c\u9690\u542b\u627f\u8bfa\uff09\uff0c\u73b0\u6709LLMs\u96be\u4ee5\u6709\u6548\u89e3\u6790\uff0c\u4e9f\u9700\u9488\u5bf9\u65e5\u672c\u91d1\u878d\u8bed\u5883\u8bbe\u8ba1\u4e13\u95e8\u7684\u8bc4\u6d4b\u5e73\u53f0\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Ebisu\uff0c\u8fd9\u662f\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u65e5\u672c\u672c\u571f\u91d1\u878d\u8bed\u8a00\u7406\u89e3\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u4e24\u4e2a\u7531\u4e13\u5bb6\u6807\u6ce8\u7684\u4efb\u52a1\uff1aJF-ICR\uff08\u9690\u542b\u627f\u8bfa\u548c\u62d2\u7edd\u8bc6\u522b\uff09\u548cJF-TE\uff08\u5d4c\u5957\u91d1\u878d\u672f\u8bed\u7684\u5c42\u7ea7\u62bd\u53d6\u548c\u6392\u5e8f\uff09\u3002\u5bf9\u591a\u79cd\u5f00\u6e90\u53ca\u4e13\u6709\u7684LLMs\u8fdb\u884c\u4e86\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u524d\u6280\u672f\u6c34\u5e73\u7684\u6a21\u578b\u5728\u4e24\u9879\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u4e0d\u4f73\uff0c\u6a21\u578b\u89c4\u6a21\u63d0\u5347\u6548\u679c\u6709\u9650\uff0c\u8bed\u8a00\u548c\u9886\u57df\u7279\u5b9a\u7684\u9002\u5e94\u8bad\u7ec3\u4e5f\u672a\u80fd\u660e\u663e\u6539\u5584\u6027\u80fd\uff0c\u8868\u660e\u8be5\u9886\u57df\u4ecd\u5b58\u5728\u8f83\u5927\u6311\u6218\u3002", "conclusion": "\u73b0\u6709\u7684\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5373\u4f7f\u7ecf\u8fc7\u8bed\u8a00\u548c\u91d1\u878d\u9886\u57df\u7279\u5b9a\u7684\u9002\u5e94\u8bad\u7ec3\uff0c\u4ecd\u7136\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u548c\u5904\u7406\u65e5\u672c\u91d1\u878d\u8bed\u8a00\u4e2d\u7684\u9690\u542b\u627f\u8bfa\u548c\u590d\u6742\u672f\u8bed\u5c42\u6b21\u7ed3\u6784\uff0c\u5b58\u5728\u663e\u8457\u6027\u80fd\u5dee\u8ddd\u3002"}}
{"id": "2602.01511", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01511", "abs": "https://arxiv.org/abs/2602.01511", "authors": ["Ran Xu", "Tianci Liu", "Zihan Dong", "Tony You", "Ilgee Hong", "Carl Yang", "Linjun Zhang", "Tao Zhao", "Haoyu Wang"], "title": "Alternating Reinforcement Learning for Rubric-Based Reward Modeling in Non-Verifiable LLM Post-Training", "comment": "The first two authors contributed equally", "summary": "Standard reward models typically predict scalar scores that fail to capture the multifaceted nature of response quality in non-verifiable domains, such as creative writing or open-ended instruction following. To address this limitation, we propose Rubric-ARM, a framework that jointly optimizes a rubric generator and a judge using reinforcement learning from preference feedback. Unlike existing methods that rely on static rubrics or disjoint training pipelines, our approach treats rubric generation as a latent action learned to maximize judgment accuracy. We introduce an alternating optimization strategy to mitigate the non-stationarity of simultaneous updates, providing theoretical analysis that demonstrates how this schedule reduces gradient variance during training. Extensive experiments show that Rubric-ARM achieves state-of-the-art performance among baselines on multiple benchmarks and significantly improves downstream policy alignment in both offline and online reinforcement learning settings.", "AI": {"tldr": "\u9488\u5bf9\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u65e0\u6cd5\u523b\u753b\u591a\u7ef4\u54cd\u5e94\u8d28\u91cf\u7684\u95ee\u9898\uff0cRubric-ARM \u901a\u8fc7\u8054\u5408\u5b66\u4e60\u8bc4\u5206\u89c4\u5219\u548c\u88c1\u5224\uff0c\u5e76\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u8bc4\u5224\u548c\u66f4\u4f18\u7684\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edf\u5956\u52b1\u6a21\u578b\u53ea\u80fd\u9884\u6d4b\u6807\u91cf\u5f97\u5206\uff0c\u4e0d\u80fd\u5145\u5206\u53cd\u6620\u975e\u53ef\u9a8c\u8bc1\u9886\u57df\u591a\u7ef4\u5ea6\u7684\u54cd\u5e94\u8d28\u91cf\uff0c\u9650\u5236\u4e86\u5956\u52b1\u6a21\u578b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u7b56\u7565\u8868\u73b0\u3002", "method": "\u63d0\u51fa Rubric-ARM \u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u8bc4\u5206\u89c4\u5219\u751f\u6210\u5668\u548c\u88c1\u5224\uff0c\u5229\u7528\u57fa\u4e8e\u504f\u597d\u53cd\u9988\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7b56\u7565\u7f13\u89e3\u975e\u5e73\u7a33\u6027\uff0c\u5e76\u8fdb\u884c\u4e86\u7406\u8bba\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "Rubric-ARM \u5728\u591a\u9879\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5728\u7ebf\u548c\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u7b56\u7565\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "Rubric-ARM \u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u975e\u53ef\u9a8c\u8bc1\u9886\u57df\uff08\u5982\u521b\u610f\u5199\u4f5c\u548c\u5f00\u653e\u5f0f\u6307\u4ee4\u9075\u5faa\u4e2d\uff09\u53cd\u9988\u6a21\u578b\u7684\u8bc4\u5224\u51c6\u786e\u6027\u548c\u7b56\u7565\u5bf9\u9f50\u6027\u80fd\u3002"}}
{"id": "2602.01560", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01560", "abs": "https://arxiv.org/abs/2602.01560", "authors": ["Keito Inoshita", "Michiaki Omura", "Tsukasa Yamanaka", "Go Maeda", "Kentaro Tsuji"], "title": "Argument Rarity-based Originality Assessment for AI-Assisted Writing", "comment": null, "summary": "As Large Language Models (LLMs) have become capable of effortlessly generating high-quality text, traditional quality-focused writing assessment is losing its significance. If the essential goal of education is to foster critical thinking and original perspectives, assessment must also shift its paradigm from quality to originality. This study proposes Argument Rarity-based Originality Assessment (AROA), a framework for automatically evaluating argumentative originality in student essays. AROA defines originality as rarity within a reference corpus and evaluates it through four complementary components: structural rarity, claim rarity, evidence rarity, and cognitive depth. The framework quantifies the rarity of each component using density estimation and integrates them with a quality adjustment mechanism, thereby treating quality and originality as independent evaluation axes. Experiments using human essays and AI-generated essays revealed a strong negative correlation between quality and claim rarity, demonstrating a quality-originality trade-off where higher-quality texts tend to rely on typical claim patterns. Furthermore, while AI essays achieved comparable levels of structural complexity to human essays, their claim rarity was substantially lower than that of humans, indicating that LLMs can reproduce the form of argumentation but have limitations in the originality of content.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u8bba\u70b9\u7a00\u6709\u6027\u7684\u539f\u521b\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u533a\u522b\u8d28\u91cf\u4e0e\u539f\u521b\u6027\u4e24\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u53d1\u73b0\u9ad8\u8d28\u91cf\u6587\u672c\u5f80\u5f80\u539f\u521b\u6027\u8f83\u4f4e\uff0c\u4e14\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bba\u70b9\u539f\u521b\u6027\u4e0d\u53ca\u4eba\u7c7b\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u8f7b\u677e\u751f\u6210\u9ad8\u8d28\u91cf\u6587\u672c\uff0c\u4f20\u7edf\u4ee5\u8d28\u91cf\u4e3a\u6838\u5fc3\u7684\u5199\u4f5c\u8bc4\u4ef7\u53d8\u5f97\u4e0d\u518d\u5177\u6709\u610f\u4e49\uff0c\u6559\u80b2\u8bc4\u4ef7\u5e94\u8f6c\u5411\u57f9\u517b\u6279\u5224\u6027\u601d\u7ef4\u548c\u539f\u521b\u89c2\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u4ece\u8d28\u91cf\u8bc4\u4f30\u8f6c\u5411\u539f\u521b\u6027\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bba\u70b9\u7a00\u6709\u6027\u7684\u539f\u521b\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u5229\u7528\u5bc6\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u91cf\u5316\u7ed3\u6784\u7a00\u6709\u5ea6\u3001\u8bba\u70b9\u7a00\u6709\u5ea6\u3001\u8bc1\u636e\u7a00\u6709\u5ea6\u548c\u8ba4\u77e5\u6df1\u5ea6\u56db\u4e2a\u65b9\u9762\uff0c\u5e76\u7ed3\u5408\u8d28\u91cf\u8c03\u6574\u673a\u5236\uff0c\u72ec\u7acb\u8bc4\u4f30\u8d28\u91cf\u4e0e\u539f\u521b\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8d28\u91cf\u4e0e\u8bba\u70b9\u7a00\u6709\u5ea6\u5b58\u5728\u663e\u8457\u8d1f\u76f8\u5173\u5173\u7cfb\uff0c\u9ad8\u8d28\u91cf\u6587\u672c\u66f4\u503e\u5411\u4e8e\u4f7f\u7528\u5178\u578b\u8bba\u70b9\uff1bAI\u751f\u6210\u6587\u672c\u5728\u7ed3\u6784\u590d\u6742\u5ea6\u4e0a\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u8bba\u70b9\u539f\u521b\u5ea6\u663e\u8457\u4f4e\u4e8e\u4eba\u7c7b\uff0c\u663e\u793a\u51fa\u751f\u6210\u6a21\u578b\u539f\u521b\u65b0\u9896\u6027\u7684\u4e0d\u8db3\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684AROA\u6846\u67b6\u6709\u6548\u8bc4\u4f30\u4e86\u5b66\u751f\u4f5c\u6587\u4e2d\u7684\u8bba\u8bc1\u539f\u521b\u6027\uff0c\u63ed\u793a\u4e86\u8d28\u91cf\u4e0e\u539f\u521b\u6027\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u6307\u51fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bba\u8bc1\u5185\u5bb9\u539f\u521b\u6027\u4e0a\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.01566", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01566", "abs": "https://arxiv.org/abs/2602.01566", "authors": ["Chiwei Zhu", "Benfeng Xu", "Mingxuan Du", "Shaohan Wang", "Xiaorui Wang", "Zhendong Mao", "Yongdong Zhang"], "title": "FS-Researcher: Test-Time Scaling for Long-Horizon Research Tasks with File-System-Based Agents", "comment": "19 pages, 6 figures", "summary": "Deep research is emerging as a representative long-horizon task for large language model (LLM) agents. However, long trajectories in deep research often exceed model context limits, compressing token budgets for both evidence collection and report writing, and preventing effective test-time scaling. We introduce FS-Researcher, a file-system-based, dual-agent framework that scales deep research beyond the context window via a persistent workspace. Specifically, a Context Builder agent acts as a librarian which browses the internet, writes structured notes, and archives raw sources into a hierarchical knowledge base that can grow far beyond context length. A Report Writer agent then composes the final report section by section, treating the knowledge base as the source of facts. In this framework, the file system serves as a durable external memory and a shared coordination medium across agents and sessions, enabling iterative refinement beyond the context window. Experiments on two open-ended benchmarks (DeepResearch Bench and DeepConsult) show that FS-Researcher achieves state-of-the-art report quality across different backbone models. Further analyses demonstrate a positive correlation between final report quality and the computation allocated to the Context Builder, validating effective test-time scaling under the file-system paradigm. The code and data are anonymously open-sourced at https://github.com/Ignoramus0817/FS-Researcher.", "AI": {"tldr": "FS-Researcher\u63d0\u51fa\u5229\u7528\u6587\u4ef6\u7cfb\u7edf\u4f5c\u4e3a\u6301\u4e45\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u53cc\u4ee3\u7406\u534f\u4f5c\uff0c\u7a81\u7834\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u6df1\u5ea6\u7814\u7a76\u62a5\u544a\u8d28\u91cf\u548c\u6269\u5c55\u80fd\u529b\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u957f\u65f6\u95f4\u8de8\u5ea6\u7684\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u65f6\u9762\u4e34\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u5bfc\u81f4\u6536\u96c6\u8bc1\u636e\u548c\u64b0\u5199\u62a5\u544a\u7684\u4ee4\u724c\u9884\u7b97\u53d7\u9650\uff0c\u963b\u788d\u4e86\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u3002", "method": "\u63d0\u51fa\u4e86FS-Researcher\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4ee3\u7406\uff1aContext Builder\u4ee3\u7406\u8d1f\u8d23\u4e92\u8054\u7f51\u6d4f\u89c8\u3001\u7ed3\u6784\u5316\u7b14\u8bb0\u548c\u77e5\u8bc6\u5e93\u6784\u5efa\uff0cReport Writer\u4ee3\u7406\u6839\u636e\u77e5\u8bc6\u5e93\u5206\u6bb5\u64b0\u5199\u62a5\u544a\uff0c\u6574\u4e2a\u8fc7\u7a0b\u4f9d\u6258\u6587\u4ef6\u7cfb\u7edf\u4f5c\u4e3a\u6301\u4e45\u5316\u5de5\u4f5c\u7a7a\u95f4\u5b9e\u73b0\u8d85\u8d8a\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u8fed\u4ee3\u7cbe\u70bc\u3002", "result": "\u5728DeepResearch Bench\u548cDeepConsult\u4e24\u4e2a\u5f00\u653e\u5f0f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cFS-Researcher\u5728\u4e0d\u540c\u9aa8\u5e72\u6a21\u578b\u4e0a\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u62a5\u544a\u8d28\u91cf\uff0c\u4e14\u62a5\u544a\u8d28\u91cf\u4e0eContext Builder\u7684\u8ba1\u7b97\u8d44\u6e90\u6b63\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u6587\u4ef6\u7cfb\u7edf\u8303\u5f0f\u4e0b\u7684\u6709\u6548\u6d4b\u8bd5\u65f6\u6269\u5c55\u3002", "conclusion": "FS-Researcher\u6846\u67b6\u901a\u8fc7\u6587\u4ef6\u7cfb\u7edf\u4f5c\u4e3a\u6301\u4e45\u5916\u90e8\u8bb0\u5fc6\u548c\u534f\u8c03\u4ecb\u8d28\uff0c\u6709\u6548\u7a81\u7834\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u9ad8\u8d28\u91cf\u62a5\u544a\u751f\u6210\u548c\u6d4b\u8bd5\u65f6\u6269\u5c55\u80fd\u529b\u3002"}}
{"id": "2602.01572", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.01572", "abs": "https://arxiv.org/abs/2602.01572", "authors": ["Yeqin Zhang", "Yunfei Wang", "Jiaxuan Chen", "Ke Qin", "Yizheng Zhao", "Cam-Tu Nguyen"], "title": "LLM-based Embeddings: Attention Values Encode Sentence Semantics Better Than Hidden States", "comment": null, "summary": "Sentence representations are foundational to many Natural Language Processing (NLP) applications. While recent methods leverage Large Language Models (LLMs) to derive sentence representations, most rely on final-layer hidden states, which are optimized for next-token prediction and thus often fail to capture global, sentence-level semantics. This paper introduces a novel perspective, demonstrating that attention value vectors capture sentence semantics more effectively than hidden states. We propose Value Aggregation (VA), a simple method that pools token values across multiple layers and token indices. In a training-free setting, VA outperforms other LLM-based embeddings, even matches or surpasses the ensemble-based MetaEOL. Furthermore, we demonstrate that when paired with suitable prompts, the layer attention outputs can be interpreted as aligned weighted value vectors. Specifically, the attention scores of the last token function as the weights, while the output projection matrix ($W_O$) aligns these weighted value vectors with the common space of the LLM residual stream. This refined method, termed Aligned Weighted VA (AlignedWVA), achieves state-of-the-art performance among training-free LLM-based embeddings, outperforming the high-cost MetaEOL by a substantial margin. Finally, we highlight the potential of obtaining strong LLM embedding models through fine-tuning Value Aggregation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6ce8\u610f\u529bvalue\u5411\u91cf\u7684\u53e5\u5b50\u8868\u5f81\u65b9\u6cd5VA\u53ca\u5176\u6539\u8fdbAlignedWVA\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u9690\u85cf\u72b6\u6001\u65b9\u6cd5\u548c\u590d\u6742\u96c6\u6210\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u65b0\u8303\u5f0f\u5728\u53e5\u5b50\u8bed\u4e49\u6355\u83b7\u4e0a\u7684\u4f18\u52bf\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8eLLM\u7684\u53e5\u5b50\u8868\u793a\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u6700\u7ec8\u5c42\u7684\u9690\u85cf\u72b6\u6001\uff0c\u8fd9\u4e9b\u72b6\u6001\u4e3b\u8981\u9488\u5bf9\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u4f18\u5316\uff0c\u96be\u4ee5\u6355\u83b7\u5168\u5c40\u53e5\u5b50\u8bed\u4e49\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u66f4\u597d\u5730\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u4fe1\u606f\u3002", "method": "\u63d0\u51faValue Aggregation\uff08VA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u591a\u4e2a\u5c42\u548c\u591a\u4e2atoken\u7d22\u5f15\u4e0a\u805a\u5408\u6ce8\u610f\u529b\u7684value\u5411\u91cf\uff1b\u8fdb\u4e00\u6b65\u7ed3\u5408\u6ce8\u610f\u529b\u6743\u91cd\u548c\u8f93\u51fa\u6295\u5f71\u77e9\u9635\uff0c\u8bbe\u8ba1Aligned Weighted VA\uff08AlignedWVA\uff09\u4ee5\u63d0\u5347\u8bed\u4e49\u5bf9\u9f50\u6548\u679c\u3002", "result": "VA\u5728\u65e0\u8bad\u7ec3\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u5176\u4ed6\u57fa\u4e8eLLM\u7684\u5d4c\u5165\u65b9\u6cd5\uff0c\u4e14\u8868\u73b0\u8ffd\u5e73\u751a\u81f3\u4f18\u4e8e\u96c6\u6210\u6a21\u578bMetaEOL\uff1bAlignedWVA\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u9ad8\u6210\u672c\u7684MetaEOL\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u57fa\u4e8eVA\u5fae\u8c03\u63d0\u5347\u5d4c\u5165\u8868\u73b0\u7684\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684value\u5411\u91cf\u6bd4\u4f20\u7edf\u7684\u9690\u85cf\u72b6\u6001\u66f4\u6709\u6548\u5730\u6355\u83b7\u53e5\u5b50\u8bed\u4e49\uff0c\u63d0\u51fa\u7684Value Aggregation\u65b9\u6cd5\u4ee5\u53ca\u5176\u6539\u8fdb\u7248\u672cAligned Weighted VA\u5728\u65e0\u8bad\u7ec3\u6761\u4ef6\u4e0b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u53e5\u5b50\u8868\u793a\u6027\u80fd\u3002"}}
{"id": "2602.01587", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01587", "abs": "https://arxiv.org/abs/2602.01587", "authors": ["Zehua Cheng", "Jianwei Yang", "Wei Dai", "Jiahao Sun"], "title": "Provable Defense Framework for LLM Jailbreaks via Noise-Augumented Alignment", "comment": "10 pages", "summary": "Large Language Models (LLMs) remain vulnerable to adaptive jailbreaks that easily bypass empirical defenses like GCG. We propose a framework for certifiable robustness that shifts safety guarantees from single-pass inference to the statistical stability of an ensemble. We introduce Certified Semantic Smoothing (CSS) via Stratified Randomized Ablation, a technique that partitions inputs into immutable structural prompts and mutable payloads to derive rigorous lo norm guarantees using the Hypergeometric distribution. To resolve performance degradation on sparse contexts, we employ Noise-Augmented Alignment Tuning (NAAT), which transforms the base model into a semantic denoiser. Extensive experiments on Llama-3 show that our method reduces the Attack Success Rate of gradient-based attacks from 84.2% to 1.2% while maintaining 94.1% benign utility, significantly outperforming character-level baselines which degrade utility to 74.3%. This framework provides a deterministic certificate of safety, ensuring that a model remains robust against all adversarial variants within a provable radius.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8ba4\u8bc1\u8bed\u4e49\u5e73\u6ed1\u548c\u566a\u58f0\u589e\u5f3a\u5bf9\u9f50\u8c03\u4f18\u7684\u65b0\u6846\u67b6\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9002\u5e94\u6027\u7ed5\u8fc7\u653b\u51fb\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u4f9b\u4e86\u53ef\u8bc1\u5b9e\u7684\u5b89\u5168\u4fdd\u8bc1\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6613\u53d7\u9002\u5e94\u6027\u7ed5\u8fc7\u653b\u51fb\uff0c\u4f20\u7edf\u7684\u7ecf\u9a8c\u9632\u5fa1\u65b9\u6cd5\u5982GCG\u6548\u679c\u6709\u9650\uff0c\u4e9f\u9700\u4e00\u79cd\u5177\u5907\u53ef\u8ba4\u8bc1\u9c81\u68d2\u6027\u7684\u5b89\u5168\u4fdd\u969c\u6846\u67b6\u3002", "method": "\u901a\u8fc7\u5206\u5c42\u968f\u673a\u6d88\u878d\u6280\u672f\uff0c\u5c06\u8f93\u5165\u5212\u5206\u4e3a\u4e0d\u53ef\u53d8\u7684\u7ed3\u6784\u63d0\u793a\u548c\u53ef\u53d8\u7684\u6709\u6548\u8f7d\u8377\uff0c\u7ed3\u5408\u8d85\u51e0\u4f55\u5206\u5e03\u63a8\u5bfc\u51fa\u4e25\u683c\u7684lo\u8303\u6570\u4fdd\u8bc1\uff1b\u91c7\u7528\u566a\u58f0\u589e\u5f3a\u7684\u5bf9\u9f50\u8c03\u4f18\uff08NAAT\uff09\u5c06\u57fa\u7840\u6a21\u578b\u8f6c\u53d8\u4e3a\u8bed\u4e49\u53bb\u566a\u5668\uff0c\u4ee5\u89e3\u51b3\u7a00\u758f\u4e0a\u4e0b\u6587\u4e2d\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "result": "\u5728Llama-3\u6a21\u578b\u4e0a\uff0c\u91c7\u7528\u672c\u65b9\u6cd5\u5c06\u57fa\u4e8e\u68af\u5ea6\u7684\u653b\u51fb\u6210\u529f\u7387\u4ece84.2%\u964d\u81f31.2%\uff0c\u540c\u65f6\u4fdd\u630194.1%\u7684\u6b63\u5e38\u6548\u7528\uff0c\u5927\u5e45\u4f18\u4e8e\u964d\u4f4e\u6548\u7528\u81f374.3%\u7684\u57fa\u4e8e\u5b57\u7b26\u7ea7\u522b\u7684\u65b9\u6cd5\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u8ba4\u8bc1\u8bed\u4e49\u5e73\u6ed1\uff08CSS\uff09\u6846\u67b6\u663e\u8457\u589e\u5f3a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5b89\u5168\u6027\uff0c\u5b9e\u73b0\u4e86\u5bf9\u9002\u5e94\u6027\u7ed5\u8fc7\u653b\u51fb\u7684\u8bc1\u4e66\u7ea7\u9c81\u68d2\u6027\uff0c\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\u5e76\u4fdd\u6301\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2602.01590", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01590", "abs": "https://arxiv.org/abs/2602.01590", "authors": ["Shaohan Wang", "Benfeng Xu", "Licheng Zhang", "Mingxuan Du", "Chiwei Zhu", "Xiaorui Wang", "Zhendong Mao", "Yongdong Zhang"], "title": "Wiki Live Challenge: Challenging Deep Research Agents with Expert-Level Wikipedia Articles", "comment": "Preprint. Work in progress", "summary": "Deep Research Agents (DRAs) have demonstrated remarkable capabilities in autonomous information retrieval and report generation, showing great potential to assist humans in complex research tasks. Current evaluation frameworks primarily rely on LLM-generated references or LLM-derived evaluation dimensions. While these approaches offer scalability, they often lack the reliability of expert-verified content and struggle to provide objective, fine-grained assessments of critical dimensions. To bridge this gap, we introduce Wiki Live Challenge (WLC), a live benchmark that leverages the newest Wikipedia Good Articles (GAs) as expert-level references. Wikipedia's strict standards for neutrality, comprehensiveness, and verifiability serve as a great challenge for DRAs, with GAs representing the pinnacle of which. We curate a dataset of 100 recent Good Articles and propose Wiki Eval, a comprehensive evaluation framework comprising a fine-grained evaluation method with 39 criteria for writing quality and rigorous metrics for factual verifiability. Extensive experiments on various DRA systems demonstrate a significant gap between current DRAs and human expert-level Wikipedia articles, validating the effectiveness of WLC in advancing agent research. We release our benchmark at https://github.com/WangShao2000/Wiki_Live_Challenge", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1\u4f18\u8d28\u6587\u7ae0\u7684\u5b9e\u65f6\u8bc4\u6d4b\u57fa\u51c6\u548c\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u63ed\u793a\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u7684\u5dee\u8ddd\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u53c2\u8003\u8d44\u6599\uff0c\u7f3a\u4e4f\u4e13\u5bb6\u9a8c\u8bc1\u5185\u5bb9\uff0c\u8bc4\u4ef7\u53ef\u9760\u6027\u548c\u7ec6\u81f4\u6027\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u5f15\u5165\u4e13\u5bb6\u7ea7\u53c2\u8003\u548c\u66f4\u7ec6\u7c92\u5ea6\u7684\u8bc4\u4ef7\u6807\u51c6\u3002", "method": "\u63d0\u51fa\u4e86Wiki Live Challenge\uff08WLC\uff09\uff0c\u57fa\u4e8e\u6700\u65b0\u7ef4\u57fa\u767e\u79d1\u4f18\u8d28\u6587\u7ae0\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5305\u542b39\u6761\u5199\u4f5c\u8d28\u91cf\u7ec6\u5316\u6807\u51c6\u548c\u4e25\u683c\u4e8b\u5b9e\u53ef\u9a8c\u8bc1\u6027\u6307\u6807\u7684Wiki Eval\u8bc4\u4f30\u6846\u67b6\u3002", "result": "\u901a\u8fc7\u5bf9\u591a\u79cd\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u8fdb\u884c\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86WLC\u7684\u6709\u6548\u6027\uff0c\u53d1\u73b0\u5f53\u524d\u7cfb\u7edf\u5728\u8d28\u91cf\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u4e0e\u4e13\u5bb6\u7ea7\u6587\u7ae0\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524d\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u81ea\u52a8\u4fe1\u606f\u68c0\u7d22\u548c\u62a5\u544a\u751f\u6210\u65b9\u9762\u867d\u7136\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u4e0e\u7ef4\u57fa\u767e\u79d1\u4f18\u8d28\u6587\u7ae0\u7684\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u4ecd\u6709\u663e\u8457\u5dee\u8ddd\u3002"}}
{"id": "2602.01598", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01598", "abs": "https://arxiv.org/abs/2602.01598", "authors": ["Mingwen Zhang", "Minqiang Yang", "Changsheng Ma", "Yang Yu", "Hui Bai", "Chen Xu", "Xiangzhen Kong", "Bin Hu"], "title": "The Art of Socratic Inquiry: A Framework for Proactive Template-Guided Therapeutic Conversation Generation", "comment": null, "summary": "Proactive questioning, where therapists deliberately initiate structured, cognition-guiding inquiries, is a cornerstone of cognitive behavioral therapy (CBT). Yet, current psychological large language models (LLMs) remain overwhelmingly reactive, defaulting to empathetic but superficial responses that fail to surface latent beliefs or guide behavioral change. To bridge this gap, we propose the \\textbf{Socratic Inquiry Framework (SIF)}, a lightweight, plug-and-play therapeutic intent planner that transforms LLMs from passive listeners into active cognitive guides. SIF decouples \\textbf{when to ask} (via Strategy Anchoring) from \\textbf{what to ask} (via Template Retrieval), enabling context-aware, theory-grounded questioning without end-to-end retraining. Complementing SIF, we introduce \\textbf{Socratic-QA}, a high-quality dataset of strategy-aligned Socratic sequences that provides explicit supervision for proactive reasoning. Experiments show that SIF significantly enhances proactive questioning frequency, conversational depth, and therapeutic alignment, marking a clear shift from reactive comfort to proactive exploration. Our work establishes a new paradigm for psychologically informed LLMs: not just to respond, but to guide.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Socratic Inquiry Framework(SIF)\uff0c\u4f7f\u5fc3\u7406\u5927\u6a21\u578b\u80fd\u591f\u4e3b\u52a8\u63d0\u51fa\u7ed3\u6784\u5316\u95ee\u9898\uff0c\u4fc3\u8fdb\u8ba4\u77e5\u5f15\u5bfc\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u88ab\u52a8\u56de\u5e94\u7684\u9650\u5236\u3002", "motivation": "\u5f53\u524d\u5fc3\u7406\u5927\u8bed\u8a00\u6a21\u578b\u53cd\u5e94\u6027\u5f3a\uff0c\u7f3a\u4e4f\u4e3b\u52a8\u53d1\u8d77\u8ba4\u77e5\u5f15\u5bfc\u7684\u80fd\u529b\uff0c\u96be\u4ee5\u6316\u6398\u6f5c\u5728\u4fe1\u5ff5\u548c\u4fc3\u8fdb\u884c\u4e3a\u6539\u53d8\u3002", "method": "\u901a\u8fc7SIF\u6846\u67b6\u5c06\u63d0\u95ee\u7684\u65f6\u673a\uff08Strategy Anchoring\uff09\u4e0e\u5177\u4f53\u5185\u5bb9\uff08Template Retrieval\uff09\u89e3\u8026\uff0c\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\uff0c\u540c\u65f6\u5f15\u5165Socratic-QA\u6570\u636e\u96c6\u7528\u4e8e\u76d1\u7763\u4e3b\u52a8\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eSIF\u663e\u8457\u589e\u52a0\u4e86\u4e3b\u52a8\u63d0\u95ee\u7684\u9891\u7387\u3001\u5bf9\u8bdd\u6df1\u5ea6\u548c\u6cbb\u7597\u4e00\u81f4\u6027\uff0c\u63d0\u9ad8\u4e86\u5fc3\u7406\u5bf9\u8bdd\u6a21\u578b\u7684\u4e3b\u52a8\u63a2\u7d22\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684Socratic Inquiry Framework (SIF)\u663e\u8457\u63d0\u5347\u4e86\u5fc3\u7406\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e3b\u52a8\u8d28\u8be2\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u4ece\u88ab\u52a8\u56de\u5e94\u5230\u4e3b\u52a8\u5f15\u5bfc\u7684\u8f6c\u53d8\u3002"}}
{"id": "2602.01618", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01618", "abs": "https://arxiv.org/abs/2602.01618", "authors": ["Panuthep Tasawong", "Jian Gang Ngui", "Alham Fikri Aji", "Trevor Cohn", "Peerat Limkonchotiwat"], "title": "SEA-Guard: Culturally Grounded Multilingual Safeguard for Southeast Asia", "comment": "Under reivew", "summary": "Culturally aware safeguards are crucial for AI alignment in real-world settings, where safety extends beyond common sense and encompasses diverse local values, norms, and region-specific regulations. However, building large-scale, culturally grounded datasets is challenging due to limited resources and a scarcity of native annotators. Consequently, many safeguard models rely on machine translation of English datasets, often missing regional and cultural nuances. We present a novel agentic data-generation framework to scalably create authentic, region-specific safety datasets for Southeast Asia (SEA). On this foundation, we introduce the SEA-Guard family, the first multilingual safeguard models grounded in SEA cultural contexts. Evaluated across multiple benchmarks and cultural variants, SEA-Guard consistently outperforms existing safeguards at detecting regionally sensitive or harmful content while maintaining strong general safety performance.", "AI": {"tldr": "\u9488\u5bf9\u4e1c\u5357\u4e9a\u6587\u5316\u80cc\u666f\uff0c\u63d0\u51fa\u81ea\u4e3b\u6570\u636e\u751f\u6210\u6846\u67b6\u548c\u591a\u8bed\u8a00\u4fdd\u969c\u6a21\u578bSEA-Guard\uff0c\u663e\u8457\u63d0\u5347\u533a\u57df\u6027\u5b89\u5168\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u5b9e\u73af\u5883\u4e2d\u7684AI\u5b89\u5168\u9700\u6c42\u6d89\u53ca\u591a\u5143\u6587\u5316\u80cc\u666f\uff0c\u73b0\u6709\u6a21\u578b\u7531\u4e8e\u8d44\u6e90\u9650\u5236\u5e38\u4f9d\u8d56\u82f1\u6587\u6570\u636e\u7684\u673a\u5668\u7ffb\u8bd1\uff0c\u96be\u4ee5\u6355\u6349\u5730\u57df\u6587\u5316\u7ec6\u8282\u3002", "method": "\u91c7\u7528\u521b\u65b0\u7684\u81ea\u4e3b\u6570\u636e\u751f\u6210\u6846\u67b6\u5927\u89c4\u6a21\u521b\u5efa\u7b26\u5408\u4e1c\u5357\u4e9a\u6587\u5316\u80cc\u666f\u7684\u5b89\u5168\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u591a\u8bed\u8a00\u4fdd\u969c\u6a21\u578bSEA-Guard\u3002", "result": "SEA-Guard\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4ee5\u53ca\u4e0d\u540c\u6587\u5316\u53d8\u4f53\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u66f4\u7cbe\u51c6\u5730\u8bc6\u522b\u533a\u57df\u654f\u611f\u5185\u5bb9\u3002", "conclusion": "SEA-Guard\u591a\u8bed\u8a00\u4fdd\u969c\u6a21\u578b\u6709\u6548\u5730\u8bc6\u522b\u5e76\u9632\u6b62\u4e0e\u4e1c\u5357\u4e9a\u6587\u5316\u76f8\u5173\u7684\u654f\u611f\u6216\u6709\u5bb3\u5185\u5bb9\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u901a\u7528\u5b89\u5168\u6027\u80fd\u3002"}}
{"id": "2602.01640", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01640", "abs": "https://arxiv.org/abs/2602.01640", "authors": ["Shuai Zhang", "Jiayu Hu", "Zijie Chen", "Zeyuan Ding", "Yi Zhang", "Yingji Zhang", "Ziyi Zhou", "Junwei Liao", "Shengjie Zhou", "Yong Dai", "Zhenzhong Lan", "Xiaozhu Ju"], "title": "A2Eval: Agentic and Automated Evaluation for Embodied Brain", "comment": null, "summary": "Current embodied VLM evaluation relies on static, expert-defined, manually annotated benchmarks that exhibit severe redundancy and coverage imbalance. This labor intensive paradigm drains computational and annotation resources, inflates costs, and distorts model rankings, ultimately stifling iterative development. To address this, we propose Agentic Automatic Evaluation (A2Eval), the first agentic framework that automates benchmark curation and evaluation through two collaborative agents. The Data Agent autonomously induces capability dimensions and assembles a balanced, compact evaluation suite, while the Eval Agent synthesizes and validates executable evaluation pipelines, enabling fully autonomous, high-fidelity assessment. Evaluated across 10 benchmarks and 13 models, A2Eval compresses evaluation suites by 85%, reduces overall computational costs by 77%, and delivers a 4.6x speedup while preserving evaluation quality. Crucially, A2Eval corrects systematic ranking biases, improves human alignment to Spearman's rho=0.85, and maintains high ranking fidelity (Kendall's tau=0.81), establishing a new standard for high-fidelity, low-cost embodied assessment. Our code and data will be public soon.", "AI": {"tldr": "\u9488\u5bf9\u5f53\u524d\u624b\u5de5\u8bc4\u4f30\u57fa\u51c6\u7684\u6548\u7387\u548c\u8d28\u91cf\u95ee\u9898\uff0cA2Eval\u63d0\u51fa\u81ea\u52a8\u5316\u4ee3\u7406\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u8bc4\u4f30\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u63a8\u52a8\u5177\u8eab\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u4f4e\u6210\u672c\u9ad8\u6548\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u7684\u5177\u8eab\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4f9d\u8d56\u9759\u6001\u4e13\u5bb6\u5b9a\u4e49\u7684\u624b\u52a8\u6807\u6ce8\u57fa\u51c6\uff0c\u5b58\u5728\u5197\u4f59\u4e25\u91cd\u3001\u8986\u76d6\u4e0d\u5e73\u8861\u3001\u6210\u672c\u9ad8\u6602\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8fed\u4ee3\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u534f\u4f5c\u4ee3\u7406\u2014\u2014\u6570\u636e\u4ee3\u7406\u81ea\u52a8\u5f52\u7eb3\u80fd\u529b\u7ef4\u5ea6\u5e76\u6784\u5efa\u5e73\u8861\u7d27\u51d1\u7684\u8bc4\u4f30\u5957\u4ef6\uff0c\u8bc4\u4f30\u4ee3\u7406\u5408\u6210\u5e76\u9a8c\u8bc1\u53ef\u6267\u884c\u7684\u8bc4\u6d4b\u6d41\u7a0b\uff0c\u5b9e\u73b0\u5168\u81ea\u52a8\u5316\u9ad8\u4fdd\u771f\u8bc4\u4f30\u3002", "result": "A2Eval\u572810\u4e2a\u57fa\u51c6\u548c13\u4e2a\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5957\u4ef6\u538b\u7f2985%\uff0c\u8ba1\u7b97\u6210\u672c\u964d\u4f4e77%\uff0c\u8bc4\u4f30\u901f\u5ea6\u63d0\u53474.6\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u8bc4\u4ef7\u8d28\u91cf\u548c\u6392\u540d\u53ef\u9760\u6027\uff0c\u6392\u540d\u4e0e\u4eba\u7c7b\u8bc4\u4f30\u76f8\u5173\u6027\u663e\u8457\u63d0\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684A2Eval\u6846\u67b6\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u3001\u9ad8\u8d28\u91cf\u4e14\u4f4e\u6210\u672c\u7684\u5177\u8eab\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\uff0c\u663e\u8457\u4f18\u5316\u4e86\u8bc4\u4ef7\u5957\u4ef6\uff0c\u7ea0\u6b63\u4e86\u6392\u540d\u504f\u5dee\uff0c\u63d0\u9ad8\u4e86\u4eba\u7c7b\u8bc4\u4f30\u4e00\u81f4\u6027\uff0c\u63a8\u52a8\u4e86\u6a21\u578b\u8bc4\u4f30\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.01654", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01654", "abs": "https://arxiv.org/abs/2602.01654", "authors": ["Jiaqian Li", "Yanshu Li", "Kuan-Hao Huang"], "title": "Steering Vector Fields for Context-Aware Inference-Time Control in Large Language Models", "comment": null, "summary": "Steering vectors (SVs) offer a lightweight way to control large language models (LLMs) at inference time by shifting hidden activations, providing a practical middle ground between prompting and fine-tuning. Yet SVs can be unreliable in practice. Some concepts are unsteerable, and even when steering helps on average it can backfire for a non-trivial fraction of inputs. Reliability also degrades in long-form generation and multi-attribute steering. We take a geometric view of these failures. A static SV applies the same update vector everywhere in representation space, implicitly assuming that the concept-improving direction is constant across contexts. When the locally effective direction varies with the current activation, a single global vector can become misaligned, which yields weak or reversed effects. Guided by this perspective, we propose Steering Vector Fields (SVF), which learns a differentiable concept scoring function whose local gradient defines the steering direction at each activation, making interventions explicitly context-dependent. This formulation supports coordinated multi-layer interventions in a shared, aligned concept space, and enables efficient long-form and multi-attribute control within a unified framework. Across multiple LLMs and steering tasks, SVF delivers stronger and more reliable control, improving the practicality of inference-time steering.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u7684\u8f6c\u5411\u5411\u91cf\u573a\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u8f6c\u5411\u5411\u91cf\u5728\u4e0a\u4e0b\u6587\u4f9d\u8d56\u548c\u591a\u5c5e\u6027\u63a7\u5236\u4e0a\u7684\u7f3a\u9677\uff0c\u5b9e\u73b0\u4e86\u66f4\u53ef\u9760\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65f6\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u7684\u8f6c\u5411\u5411\u91cf\uff08Steering Vectors, SVs\uff09\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u90e8\u5206\u6982\u5ff5\u96be\u4ee5\u63a7\u5236\uff0c\u4e14\u5728\u957f\u6587\u672c\u751f\u6210\u548c\u591a\u5c5e\u6027\u8f6c\u5411\u65f6\u53ef\u9760\u6027\u4e0b\u964d\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u8f6c\u5411\u5411\u91cf\u573a\uff08Steering Vector Fields, SVF\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u4e00\u4e2a\u53ef\u5fae\u5206\u7684\u6982\u5ff5\u8bc4\u5206\u51fd\u6570\uff0c\u5176\u5c40\u90e8\u68af\u5ea6\u5b9a\u4e49\u6fc0\u6d3b\u72b6\u6001\u4e0b\u7684\u8f6c\u5411\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684\u8f6c\u5411\u63a7\u5236\uff0c\u5e76\u652f\u6301\u591a\u5c42\u6b21\u8054\u5408\u5e72\u9884\u3002", "result": "\u5728\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u8f6c\u5411\u4efb\u52a1\u4e2d\uff0cSVF\u63d0\u4f9b\u4e86\u66f4\u5f3a\u4e14\u66f4\u53ef\u9760\u7684\u63a7\u5236\u6548\u679c\uff0c\u63d0\u9ad8\u4e86\u63a8\u7406\u65f6\u8f6c\u5411\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "SVF\u514b\u670d\u4e86\u4f20\u7edf\u9759\u6001\u8f6c\u5411\u5411\u91cf\u7684\u5c40\u9650\uff0c\u589e\u5f3a\u4e86\u6982\u5ff5\u8f6c\u5411\u7684\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u4e0e\u591a\u5c5e\u6027\u63a7\u5236\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u9636\u6bb5\u7684\u63a7\u5236\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u3002"}}
{"id": "2602.01660", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01660", "abs": "https://arxiv.org/abs/2602.01660", "authors": ["Zhongyuan Peng", "Caijun Xu", "Changyi Xiao", "Shibo Hong", "Eli Zhang", "Stephen Huang", "Yixin Cao"], "title": "CoDiQ: Test-Time Scaling for Controllable Difficult Question Generation", "comment": "11 pages, 5 tables, 5 figures", "summary": "Large Reasoning Models (LRMs) benefit substantially from training on challenging competition-level questions. However, existing automated question synthesis methods lack precise difficulty control, incur high computational costs, and struggle to generate competition-level questions at scale. In this paper, we propose CoDiQ (Controllable Difficult Question Generation), a novel framework enabling fine-grained difficulty control via test-time scaling while ensuring question solvability. Specifically, first, we identify a test-time scaling tendency (extended reasoning token budget boosts difficulty but reduces solvability) and the intrinsic properties defining the upper bound of a model's ability to generate valid, high-difficulty questions. Then, we develop CoDiQ-Generator from Qwen3-8B, which improves the upper bound of difficult question generation, making it particularly well-suited for challenging question construction. Building on the CoDiQ framework, we build CoDiQ-Corpus (44K competition-grade question sequences). Human evaluations show these questions are significantly more challenging than LiveCodeBench/AIME with over 82% solvability. Training LRMs on CoDiQ-Corpus substantially improves reasoning performance, verifying that scaling controlled-difficulty training questions enhances reasoning capabilities. We open-source CoDiQ-Corpus, CoDiQ-Generator, and implementations to support related research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoDiQ\u6846\u67b6\uff0c\u5b9e\u73b0\u9ad8\u96be\u5ea6\u63a8\u7406\u9898\u7684\u53ef\u63a7\u81ea\u52a8\u751f\u6210\uff0c\u6784\u5efa\u5927\u89c4\u6a21\u7ade\u8d5b\u9898\u5e93\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4e14\u5168\u90e8\u5de5\u5177\u548c\u6570\u636e\u96c6\u5f00\u6e90\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u5316\u9898\u76ee\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u5b9e\u73b0\u7cbe\u786e\u96be\u5ea6\u63a7\u5236\uff0c\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6279\u91cf\u751f\u6210\u9ad8\u96be\u5ea6\u7ade\u8d5b\u7ea7\u9898\u76ee\u3002", "method": "\u63d0\u51faCoDiQ\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u8bd5\u65f6\u7684\u89c4\u6a21\u8c03\u8282\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u96be\u5ea6\u63a7\u5236\uff0c\u57fa\u4e8eQwen3-8B\u5f00\u53d1CoDiQ-Generator\u751f\u6210\u9ad8\u96be\u5ea6\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u5305\u542b44K\u7ade\u8d5b\u7ea7\u95ee\u9898\u7684CoDiQ\u8bed\u6599\u5e93\u3002", "result": "\u751f\u6210\u7684\u9ad8\u96be\u5ea6\u95ee\u9898\u4eba\u7c7b\u8bc4\u6d4b\u663e\u793a\u96be\u5ea6\u663e\u8457\u9ad8\u4e8e\u73b0\u6709\u57fa\u51c6\u4e14\u53ef\u89e3\u7387\u8d8582%\uff0c\u7528\u8fd9\u4e9b\u9898\u8bad\u7ec3\u7684\u6a21\u578b\u63a8\u7406\u6027\u80fd\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u53ef\u63a7\u96be\u5ea6\u7684\u8bad\u7ec3\u9898\u76ee\u63d0\u5347\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u63a7\u5236\u8bad\u7ec3\u96be\u5ea6\u7684\u91cd\u8981\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.01672", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01672", "abs": "https://arxiv.org/abs/2602.01672", "authors": ["Siheng Xiong", "Oguzhan Gungordu", "Blair Johnson", "James C. Kerce", "Faramarz Fekri"], "title": "Scaling Search-Augmented LLM Reasoning via Adaptive Information Control", "comment": "Work in progress", "summary": "Search-augmented reasoning agents interleave multi-step reasoning with external information retrieval, but uncontrolled retrieval often leads to redundant evidence, context saturation, and unstable learning. Existing approaches rely on outcome-based reinforcement learning (RL), which provides limited guidance for regulating information acquisition. We propose DeepControl, a framework for adaptive information control based on a formal notion of information utility, which measures the marginal value of retrieved evidence under a given reasoning state. Building on this utility, we introduce retrieval continuation and granularity control mechanisms that selectively regulate when to continue and stop retrieval, and how much information to expand. An annealed control strategy enables the agent to internalize effective information acquisition behaviors during training. Extensive experiments across seven benchmarks demonstrate that our method consistently outperforms strong baselines. In particular, our approach achieves average performance improvements of 9.4% and 8.6% on Qwen2.5-7B and Qwen2.5-3B, respectively, over strong outcome-based RL baselines, and consistently outperforms both retrieval-free and retrieval-based reasoning methods without explicit information control. These results highlight the importance of adaptive information control for scaling search-augmented reasoning agents to complex, real-world information environments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDeepControl\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u63a7\u4fe1\u606f\u68c0\u7d22\u8fc7\u7a0b\u4e2d\u7684\u68c0\u7d22\u65f6\u673a\u4e0e\u8303\u56f4\uff0c\u663e\u8457\u4f18\u5316\u4e86\u641c\u7d22\u589e\u5f3a\u63a8\u7406\u4ee3\u7406\u7684\u6027\u80fd\uff0c\u5728\u591a\u9879\u6d4b\u8bd5\u4e2d\u8d85\u8fc7\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u548c\u63a8\u7406\u57fa\u7ebf\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u7ed3\u679c\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u641c\u7d22\u589e\u5f3a\u63a8\u7406\u4ee3\u7406\u4e2d\u5bf9\u4fe1\u606f\u83b7\u53d6\u7684\u8c03\u63a7\u80fd\u529b\u6709\u9650\uff0c\u5bfc\u81f4\u5197\u4f59\u8bc1\u636e\u3001\u4e0a\u4e0b\u6587\u9971\u548c\u548c\u5b66\u4e60\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86DeepControl\u6846\u67b6\uff0c\u901a\u8fc7\u6b63\u5f0f\u7684\u4fe1\u606f\u6548\u7528\u6982\u5ff5\uff0c\u8861\u91cf\u5728\u7279\u5b9a\u63a8\u7406\u72b6\u6001\u4e0b\u68c0\u7d22\u8bc1\u636e\u7684\u8fb9\u9645\u4ef7\u503c\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u4e86\u68c0\u7d22\u7ee7\u7eed\u548c\u7c92\u5ea6\u63a7\u5236\u673a\u5236\uff0c\u4f7f\u7528\u9000\u706b\u63a7\u5236\u7b56\u7565\u4f7f\u4ee3\u7406\u5728\u8bad\u7ec3\u4e2d\u5185\u5316\u6709\u6548\u7684\u4fe1\u606f\u83b7\u53d6\u884c\u4e3a\u3002", "result": "\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDeepControl\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\uff0c\u5728Qwen2.5-7B\u548cQwen2.5-3B\u4e0a\u6027\u80fd\u63d0\u5347\u5206\u522b\u4e3a9.4%\u548c8.6%\uff0c\u5e76\u4e14\u59cb\u7ec8\u4f18\u4e8e\u65e0\u663e\u5f0f\u4fe1\u606f\u63a7\u5236\u7684\u68c0\u7d22\u548c\u975e\u68c0\u7d22\u63a8\u7406\u65b9\u6cd5\u3002", "conclusion": "\u81ea\u9002\u5e94\u4fe1\u606f\u63a7\u5236\u901a\u8fc7\u7cbe\u51c6\u8c03\u8282\u4fe1\u606f\u68c0\u7d22\u7684\u65f6\u673a\u548c\u7a0b\u5ea6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u641c\u7d22\u589e\u5f3a\u63a8\u7406\u4ee3\u7406\u5728\u590d\u6742\u771f\u5b9e\u4fe1\u606f\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u51f8\u663e\u5176\u91cd\u8981\u6027\u3002"}}
{"id": "2602.01687", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01687", "abs": "https://arxiv.org/abs/2602.01687", "authors": ["Jung H. Lee", "Sujith Vijayan"], "title": "Counting Hypothesis: Potential Mechanism of In-Context Learning", "comment": "19 pages, 7 main Figures, 1 Table and 6 Supp. Figures", "summary": "In-Context Learning (ICL) indicates that large language models (LLMs) pretrained on a massive amount of data can learn specific tasks from input prompts' examples. ICL is notable for two reasons. First, it does not need modification of LLMs' internal structure. Second, it enables LLMs to perform a wide range of tasks/functions with a few examples demonstrating a desirable task. ICL opens up new ways to utilize LLMs in more domains, but its underlying mechanisms still remain poorly understood, making error correction and diagnosis extremely challenging. Thus, it is imperative that we better understand the limitations of ICL and how exactly LLMs support ICL. Inspired by ICL properties and LLMs' functional modules, we propose 1the counting hypothesis' of ICL, which suggests that LLMs' encoding strategy may underlie ICL, and provide supporting evidence.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u2018\u8ba1\u6570\u5047\u8bbe\u2019\uff0c\u89e3\u91ca\u4e86\u5176\u7f16\u7801\u7b56\u7565\u5e76\u63d0\u4f9b\u4e86\u652f\u6301\u8bc1\u636e\uff0c\u52a9\u529b\u7406\u89e3\u548c\u6539\u8fdbICL\u3002", "motivation": "\u73b0\u6709ICL\u673a\u5236\u4e0d\u660e\u786e\uff0c\u5bfc\u81f4\u9519\u8bef\u4fee\u6b63\u548c\u8bca\u65ad\u56f0\u96be\uff0c\u4e9f\u9700\u63ed\u793aICL\u7684\u9650\u5236\u548c\u4f9d\u8d56\u673a\u5236\u3002", "method": "\u57fa\u4e8eICL\u7684\u6027\u8d28\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u529f\u80fd\u6a21\u5757\uff0c\u63d0\u51fa\u2018\u8ba1\u6570\u5047\u8bbe\u2019\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u636e\u652f\u6301\u8be5\u5047\u8bbe\u3002", "result": "\u63d0\u51fa\u4e86\u8ba1\u6570\u5047\u8bbe\uff0c\u8868\u660eLLM\u7684\u7f16\u7801\u7b56\u7565\u53ef\u80fd\u662fICL\u80cc\u540e\u7684\u5173\u952e\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660e\u4e86\u5176\u5408\u7406\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u201c\u8ba1\u6570\u5047\u8bbe\u201d\uff0c\u89e3\u91ca\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u652f\u6301\u4e0a\u4e0b\u6587\u5b66\u4e60(ICL)\u7684\u7f16\u7801\u7b56\u7565\uff0c\u6df1\u5316\u4e86\u5bf9ICL\u673a\u5236\u7684\u7406\u89e3\u3002"}}
{"id": "2602.01698", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01698", "abs": "https://arxiv.org/abs/2602.01698", "authors": ["Wenhui Tan", "Fiorenzo Parascandolo", "Enver Sangineto", "Jianzhong Ju", "Zhenbo Luo", "Qian Cao", "Rita Cucchiara", "Ruihua Song", "Jian Luan"], "title": "Restoring Exploration after Post-Training: Latent Exploration Decoding for Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) have recently achieved strong mathematical and code reasoning performance through Reinforcement Learning (RL) post-training. However, we show that modern reasoning post-training induces an unintended exploration collapse: temperature-based sampling no longer increases pass@$n$ accuracy. Empirically, the final-layer posterior of post-trained LRMs exhibit sharply reduced entropy, while the entropy of intermediate layers remains relatively high. Motivated by this entropy asymmetry, we propose Latent Exploration Decoding (LED), a depth-conditioned decoding strategy. LED aggregates intermediate posteriors via cumulative sum and selects depth configurations with maximal entropy as exploration candidates. Without additional training or parameters, LED consistently improves pass@1 and pass@16 accuracy by 0.61 and 1.03 percentage points across multiple reasoning benchmarks and models. Project page: https://GitHub.com/Xiaomi-Research/LED.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u63a8\u7406\u6a21\u578b\u540e\u8bad\u7ec3\u540e\u7684\u63a2\u7d22\u5d29\u6e83\u95ee\u9898\uff0c\u63d0\u51fa\u6f5c\u5728\u63a2\u7d22\u89e3\u7801\u7b56\u7565\uff0c\u901a\u8fc7\u5229\u7528\u4e2d\u95f4\u5c42\u71b5\u4fe1\u606f\u63d0\u5347\u63a2\u7d22\u6548\u7387\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u9ad8\u63a8\u7406\u51c6\u786e\u7387\u3002", "motivation": "\u89c2\u5bdf\u5230\u540e\u8bad\u7ec3\u6a21\u578b\u6700\u7ec8\u5c42\u540e\u9a8c\u71b5\u5927\u5e45\u964d\u4f4e\uff0c\u800c\u4e2d\u95f4\u5c42\u71b5\u4fdd\u6301\u8f83\u9ad8\uff0c\u63a8\u6d4b\u8fd9\u79cd\u71b5\u4e0d\u5bf9\u79f0\u5bfc\u81f4\u4f20\u7edf\u6e29\u5ea6\u91c7\u6837\u5931\u6548\uff0c\u6fc0\u53d1\u8bbe\u8ba1\u65b0\u7684\u89e3\u7801\u7b56\u7565\u4ee5\u6062\u590d\u6709\u6548\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u6f5c\u5728\u63a2\u7d22\u89e3\u7801(LED)\u7b56\u7565\uff0c\u901a\u8fc7\u7d2f\u8ba1\u6c42\u548c\u805a\u5408\u4e2d\u95f4\u5c42\u540e\u9a8c\u6982\u7387\uff0c\u5e76\u9009\u62e9\u71b5\u503c\u6700\u5927\u7684\u6df1\u5ea6\u914d\u7f6e\u4f5c\u4e3a\u63a2\u7d22\u5019\u9009\uff0c\u4ece\u800c\u6539\u5584\u6a21\u578b\u7684\u63a2\u7d22\u80fd\u529b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u53c2\u6570\u3002", "result": "LED\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u548c\u6a21\u578b\u4e0a\uff0c\u5206\u522b\u63d0\u5347\u4e86pass@1\u548cpass@16\u7684\u51c6\u786e\u73870.61\u548c1.03\u4e2a\u767e\u5206\u70b9\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u53d1\u73b0\u73b0\u6709\u5927\u63a8\u7406\u6a21\u578b\u5728\u540e\u8bad\u7ec3\u9636\u6bb5\u51fa\u73b0\u63a2\u7d22\u5d29\u6e83\u73b0\u8c61\uff0c\u6e29\u5ea6\u91c7\u6837\u4e0d\u518d\u63d0\u5347\u51c6\u786e\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u989d\u5916\u8bad\u7ec3\u53c2\u6570\u4e14\u6709\u6548\u7684\u6df1\u5ea6\u6761\u4ef6\u89e3\u7801\u7b56\u7565\u2014\u2014\u6f5c\u5728\u63a2\u7d22\u89e3\u7801(LED)\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9879\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2602.01708", "categories": ["cs.CL", "cs.AI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.01708", "abs": "https://arxiv.org/abs/2602.01708", "authors": ["Langyuan Cui", "Chun Kai Ling", "Hwee Tou Ng"], "title": "Game of Thought: Robust Information Seeking with Large Language Models Using Game Theory", "comment": "23 pages, 10 figures, under review at ICML 2026", "summary": "Large Language Models (LLMs) are increasingly deployed in real-world scenarios where they may lack sufficient information to complete a given task. In such settings, the ability to actively seek out missing information becomes a critical capability. Existing approaches to enhancing this ability often rely on simplifying assumptions that degrade \\textit{worst-case} performance. This is an issue with serious implications in high-stakes applications. In this work, we use the game of Twenty Questions to evaluate the information-seeking ability of LLMs. We introduce and formalize its adversarial counterpart, the Strategic Language Search (SLS) problem along with its variants as a two-player zero-sum extensive form game. We propose Game of Thought (GoT), a framework that applies game-theoretic techniques to approximate a Nash equilibrium (NE) strategy for the restricted variant of the game. Empirical results demonstrate that our approach consistently improves worst-case performance compared to (1) direct prompting-based methods and (2) heuristic-guided search methods across all tested settings.", "AI": {"tldr": "\u672c\u6587\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u606f\u83b7\u53d6\u4efb\u52a1\u62bd\u8c61\u4e3a\u535a\u5f08\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u7eb3\u4ec0\u5747\u8861\u7b56\u7565\u7684Game of Thought\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u6a21\u578b\u7684\u6700\u574f\u60c5\u51b5\u8868\u73b0\u3002", "motivation": "\u73b0\u5b9e\u573a\u666f\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u5e38\u56e0\u4fe1\u606f\u4e0d\u8db3\u96be\u4ee5\u5b8c\u6210\u4efb\u52a1\uff0c\u4e14\u5df2\u6709\u65b9\u6cd5\u901a\u8fc7\u7b80\u5316\u5047\u8bbe\u727a\u7272\u4e86\u6700\u574f\u60c5\u51b5\u6027\u80fd\uff0c\u5c24\u5176\u5728\u9ad8\u98ce\u9669\u573a\u666f\u4e2d\u5b58\u5728\u4e25\u91cd\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u63d0\u5347\u6a21\u578b\u7684\u4e3b\u52a8\u4fe1\u606f\u83b7\u53d6\u80fd\u529b\u5e76\u4fdd\u8bc1\u6700\u574f\u60c5\u51b5\u8868\u73b0\u3002", "method": "\u6211\u4eec\u5c06\u4fe1\u606f\u5bfb\u6c42\u95ee\u9898\u5f62\u5f0f\u5316\u4e3a\u4e00\u4e2a\u4e24\u4eba\u96f6\u548c\u5e7f\u4e49\u578b\u535a\u5f08\uff0c\u63d0\u51fa\u4e86\u6218\u7565\u8bed\u8a00\u641c\u7d22\uff08SLS\uff09\u6a21\u578b\uff0c\u5e76\u5f00\u53d1\u4e86GoT\u6846\u67b6\u4ee5\u8fd1\u4f3c\u8ba1\u7b97\u8be5\u6e38\u620f\u7684\u7eb3\u4ec0\u5747\u8861\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cGoT\u6846\u67b6\u5728\u6240\u6709\u6d4b\u8bd5\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u57fa\u4e8e\u76f4\u63a5\u63d0\u793a\u548c\u542f\u53d1\u5f0f\u641c\u7d22\u7684\u65b9\u6cd5\uff0c\u5728\u6700\u574f\u60c5\u51b5\u6027\u80fd\u4e0a\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Game of Thought (GoT)\u65b9\u6cd5\u901a\u8fc7\u535a\u5f08\u8bba\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u83b7\u53d6\u4efb\u52a1\u4e2d\u7684\u6700\u574f\u60c5\u51b5\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u76f4\u63a5\u63d0\u793a\u548c\u542f\u53d1\u5f0f\u641c\u7d22\u65b9\u6cd5\u3002"}}
{"id": "2602.01709", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01709", "abs": "https://arxiv.org/abs/2602.01709", "authors": ["Xingshan Zeng", "Lingzhi Wang", "Weiwen Liu", "Liangyou Li", "Yasheng Wang", "Lifeng Shang", "Xin Jiang", "Qun Liu"], "title": "ARTIS: Agentic Risk-Aware Test-Time Scaling via Iterative Simulation", "comment": null, "summary": "Current test-time scaling (TTS) techniques enhance large language model (LLM) performance by allocating additional computation at inference time, yet they remain insufficient for agentic settings, where actions directly interact with external environments and their effects can be irreversible and costly. We propose \\emph{\\name}, \\emph{\\underline{A}gentic \\underline{R}isk-Aware \\underline{T}est-Time Scaling via \\underline{I}terative \\underline{S}imulation}, a framework that decouples exploration from commitment by enabling test-time exploration through simulated interactions prior to real-world execution. This design allows extending inference-time computation to improve action-level reliability and robustness without incurring environmental risk. We further show that naive LLM-based simulators struggle to capture rare but high-impact failure modes, substantially limiting their effectiveness for agentic decision making. To address this limitation, we introduce a \\emph{risk-aware tool simulator} that emphasizes fidelity on failure-inducing actions via targeted data generation and rebalanced training. Experiments on multi-turn and multi-step agentic benchmarks demonstrate that iterative simulation substantially improves agent reliability, and that risk-aware simulation is essential for consistently realizing these gains across models and tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u901a\u8fc7\u8fed\u4ee3\u98ce\u9669\u611f\u77e5\u6a21\u62df\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u7b56\u7565\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7406\u4efb\u52a1\u4e2d\u7684\u51b3\u7b56\u53ef\u9760\u6027\u548c\u5b89\u5168\u6027\uff0c\u907f\u514d\u4e86\u73af\u5883\u98ce\u9669\u5e76\u6709\u6548\u8bc6\u522b\u9ad8\u98ce\u9669\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u6269\u5c55\u6280\u672f\u867d\u7136\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5728\u9700\u8981\u4ee3\u7406\u884c\u4e3a\u4e0e\u5916\u90e8\u73af\u5883\u4ea4\u4e92\u4e14\u540e\u679c\u4e0d\u53ef\u9006\u7684\u60c5\u5883\u4e0b\u8868\u73b0\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u65e0\u6cd5\u6709\u6548\u6355\u6349\u9ad8\u98ce\u9669\u4f46\u4f4e\u9891\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5bfc\u81f4\u667a\u80fd\u4f53\u51b3\u7b56\u4e0d\u591f\u5b89\u5168\u53ef\u9760\u3002", "method": "\u63d0\u51faARTIS\u6846\u67b6\uff0c\u5728\u6d4b\u8bd5\u65f6\u901a\u8fc7\u8fed\u4ee3\u6a21\u62df\u5b9e\u73b0\u63a2\u7d22\uff0c\u6a21\u62df\u5668\u8bbe\u8ba1\u4e3a\u98ce\u9669\u611f\u77e5\u5de5\u5177\u6a21\u62df\u5668\uff0c\u4e13\u6ce8\u4e8e\u9ad8\u98ce\u9669\u5931\u8d25\u52a8\u4f5c\u7684\u6570\u636e\u751f\u6210\u548c\u8bad\u7ec3\u91cd\u5e73\u8861\uff0c\u4ee5\u63d0\u5347\u6a21\u62df\u8d28\u91cf\u548c\u8303\u56f4\uff0c\u8fdb\u800c\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u4e2d\u7684\u7a33\u5065\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8fed\u4ee3\u6a21\u62df\u663e\u8457\u63d0\u5347\u4e86\u591a\u8f6e\u591a\u6b65\u9aa4\u4ee3\u7406\u4efb\u52a1\u4e2d\u667a\u80fd\u4f53\u7684\u53ef\u9760\u6027\uff0c\u800c\u5f15\u5165\u98ce\u9669\u611f\u77e5\u6a21\u62df\u5668\u662f\u6301\u7eed\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u7684\u5173\u952e\uff0c\u6a21\u578b\u548c\u4efb\u52a1\u95f4\u5747\u8868\u73b0\u51fa\u826f\u597d\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684Agentic Risk-Aware Test-Time Scaling via Iterative Simulation\uff08ARTIS\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u771f\u5b9e\u6267\u884c\u524d\u8fdb\u884c\u6a21\u62df\u4ea4\u4e92\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u65f6\u7684\u63a2\u7d22\u4e0e\u627f\u8bfa\u7684\u89e3\u8026\uff0c\u63d0\u9ad8\u4e86\u52a8\u4f5c\u7ea7\u522b\u7684\u53ef\u9760\u6027\u548c\u9c81\u68d2\u6027\uff0c\u540c\u65f6\u907f\u514d\u4e86\u73af\u5883\u98ce\u9669\u3002\u98ce\u9669\u611f\u77e5\u5de5\u5177\u6a21\u62df\u5668\u7684\u5f15\u5165\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u548c\u89c4\u907f\u9ad8\u5f71\u54cd\u5931\u8d25\u6a21\u5f0f\u7684\u80fd\u529b\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u8f6e\u53ca\u591a\u6b65\u9aa4\u4efb\u52a1\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.01714", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01714", "abs": "https://arxiv.org/abs/2602.01714", "authors": ["Mouath Abu-Daoud", "Leen Kharouf", "Omar El Hajj", "Dana El Samad", "Mariam Al-Omari", "Jihad Mallat", "Khaled Saleh", "Nizar Habash", "Farah E. Shamout"], "title": "MedAraBench: Large-Scale Arabic Medical Question Answering Dataset and Benchmark", "comment": null, "summary": "Arabic remains one of the most underrepresented languages in natural language processing research, particularly in medical applications, due to the limited availability of open-source data and benchmarks. The lack of resources hinders efforts to evaluate and advance the multilingual capabilities of Large Language Models (LLMs). In this paper, we introduce MedAraBench, a large-scale dataset consisting of Arabic multiple-choice question-answer pairs across various medical specialties. We constructed the dataset by manually digitizing a large repository of academic materials created by medical professionals in the Arabic-speaking region. We then conducted extensive preprocessing and split the dataset into training and test sets to support future research efforts in the area. To assess the quality of the data, we adopted two frameworks, namely expert human evaluation and LLM-as-a-judge. Our dataset is diverse and of high quality, spanning 19 specialties and five difficulty levels. For benchmarking purposes, we assessed the performance of eight state-of-the-art open-source and proprietary models, such as GPT-5, Gemini 2.0 Flash, and Claude 4-Sonnet. Our findings highlight the need for further domain-specific enhancements. We release the dataset and evaluation scripts to broaden the diversity of medical data benchmarks, expand the scope of evaluation suites for LLMs, and enhance the multilingual capabilities of models for deployment in clinical settings.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a8\u51fa\u4e86\u963f\u62c9\u4f2f\u8bed\u533b\u5b66\u591a\u9009\u9898\u5927\u89c4\u6a21\u6570\u636e\u96c6MedAraBench\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u533b\u7597\u5e94\u7528\u80fd\u529b\u63d0\u5347\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\u548c\u57fa\u51c6\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5c24\u5176\u662f\u5728\u533b\u7597\u5e94\u7528\u9886\u57df\u8d44\u6e90\u532e\u4e4f\uff0c\u7f3a\u5c11\u5f00\u653e\u6570\u636e\u548c\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u80fd\u529b\u7684\u8bc4\u4f30\u548c\u63d0\u5347\u3002", "method": "\u901a\u8fc7\u624b\u5de5\u6570\u5b57\u5316\u963f\u62c9\u4f2f\u8bed\u533b\u5b66\u4e13\u4e1a\u5b66\u672f\u8d44\u6599\u5e93\uff0c\u6784\u5efa\u5305\u542b19\u4e2a\u4e13\u4e1a\u548c\u4e94\u4e2a\u96be\u5ea6\u7b49\u7ea7\u7684\u591a\u4e2a\u9009\u62e9\u9898\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528\u4e13\u5bb6\u4eba\u5de5\u8bc4\u4ef7\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u8bc4\u4f30\u6570\u636e\u8d28\u91cf\u3002\u968f\u540e\u7528\u516b\u4e2a\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e86MedAraBench\u6570\u636e\u96c6\u53ca\u8bc4\u4f30\u811a\u672c\uff0c\u6db5\u76d6\u5e7f\u6cdb\u533b\u5b66\u4e13\u4e1a\u548c\u96be\u5ea6\u7b49\u7ea7\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u7684\u9ad8\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u540c\u65f6\u901a\u8fc7\u591a\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u4e0d\u8db3\u3002", "conclusion": "MedAraBench\u6570\u636e\u96c6\u4e3a\u963f\u62c9\u4f2f\u8bed\u533b\u7597\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u5316\u7684\u5927\u89c4\u6a21\u591a\u9009\u9898\u6570\u636e\u96c6\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u5e94\u7528\u4e2d\u7684\u53d1\u5c55\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u8be5\u9886\u57df\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u5f3a\u8c03\u9700\u8981\u8fdb\u4e00\u6b65\u7684\u4e13\u95e8\u9886\u57df\u4f18\u5316\u3002"}}
{"id": "2602.01716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01716", "abs": "https://arxiv.org/abs/2602.01716", "authors": ["Mehdi Jafari", "Hao Xue", "Flora Salim"], "title": "Mechanistic Indicators of Steering Effectiveness in Large Language Models", "comment": null, "summary": "Activation-based steering enables Large Language Models (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether the reliability of steering can be diagnosed using internal model signals. We focus on two information-theoretic measures: the entropy-derived Normalized Branching Factor (NBF), and the Kullback-Leibler (KL) divergence between steered activations and targeted concepts in the vocabulary space. We hypothesize that effective steering corresponds to structured entropy preservation and coherent KL alignment across decoding steps. Building on a reliability study demonstrating high inter-judge agreement between two architecturally distinct LLMs, we use LLM-generated annotations as ground truth and show that these mechanistic signals provide meaningful predictive power for identifying successful steering and estimating failure probability. We further introduce a stronger evaluation baseline for Contrastive Activation Addition (CAA) and Sparse Autoencoder-based steering, the two most widely adopted activation-steering methods.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4fe1\u606f\u8bba\u6307\u6807\u63ed\u793a\u6fc0\u6d3b\u5f15\u5bfc\u6210\u8d25\u7684\u673a\u5236\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u63a7\u5236\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u6fc0\u6d3b\u5f15\u5bfc\u65b9\u6cd5\u867d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u6210\u529f\u673a\u5236\u4e0d\u660e\uff0c\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u4f9d\u8d56\u9ed1\u76d2\u8f93\u51fa\uff0c\u7f3a\u4e4f\u57fa\u4e8e\u5185\u90e8\u4fe1\u53f7\u7684\u8bca\u65ad\u624b\u6bb5\u3002", "method": "\u901a\u8fc7\u6d4b\u91cf\u71b5\u7684\u5f52\u4e00\u5316\u5206\u652f\u56e0\u5b50\uff08NBF\uff09\u548c\u5f15\u5bfc\u6fc0\u6d3b\u4e0e\u76ee\u6807\u8bcd\u6c47\u6982\u5ff5\u7684KL\u6563\u5ea6\uff0c\u7ed3\u5408\u4e0d\u540c\u67b6\u6784\u6a21\u578b\u7684\u8bc4\u5224\u4e00\u81f4\u6027\uff0c\u8bc4\u4f30\u6fc0\u6d3b\u5f15\u5bfc\u7684\u53ef\u9760\u6027\u3002", "result": "\u8bc1\u5b9e\u4fe1\u606f\u8bba\u6d4b\u5ea6\u5bf9\u8bc6\u522b\u6210\u529f\u5f15\u5bfc\u548c\u4f30\u8ba1\u5931\u8d25\u6982\u7387\u5177\u6709\u9884\u6d4b\u80fd\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u66f4\u5f3a\u7684\u5bf9\u6bd4\u8bc4\u4f30\u57fa\u51c6\u3002", "conclusion": "\u5185\u90e8\u6fc0\u6d3b\u4fe1\u53f7\u4e2d\u7684\u4fe1\u606f\u8bba\u6307\u6807\uff08NBF\u548cKL\u6563\u5ea6\uff09\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u7684\u6210\u529f\u4e0e\u5931\u8d25\u3002"}}
{"id": "2602.01717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01717", "abs": "https://arxiv.org/abs/2602.01717", "authors": ["Hyunsik Kim", "Haeri Kim", "Munhak Lee", "Kyungmin Lee"], "title": "BBPE16: UTF-16-based byte-level byte-pair encoding for improved multilingual speech recognition", "comment": "accepted to ICASSP 2026", "summary": "Multilingual automatic speech recognition (ASR) requires tokenization that efficiently covers many writing systems. Byte-level BPE (BBPE) using UTF-8 is widely adopted for its language-agnostic design and full Unicode coverage, but its variable-length encoding inflates token sequences for non-Latin scripts, such as Chinese, Japanese, and Korean (CJK). Longer sequences increase computational load and memory use. We propose BBPE16, a UTF-16-based BBPE tokenizer that represents most modern scripts with a uniform 2-byte code unit. BBPE16 preserves BBPE's language-agnostic properties while substantially improving cross-lingual token sharing. Across monolingual, bilingual, and trilingual ASR, and in a multilingual continual-learning setup, BBPE16 attains comparable or better accuracy; for Chinese, it reduces token counts by up to 10.4% and lowers decoding iterations by up to 10.3%. These reductions speed up fine-tuning and inference and decrease memory usage, making BBPE16 a practical tokenization choice for multilingual ASR.", "AI": {"tldr": "BBPE16\u5229\u7528UTF-16\u7f16\u7801\u4f18\u52bf\u4f18\u5316\u591a\u8bed\u79cd\u8bed\u97f3\u8bc6\u522b\u5206\u8bcd\uff0c\u663e\u8457\u51cf\u5c11\u975e\u62c9\u4e01\u6587\u5b57token\u6570\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u63d0\u9ad8\u6548\u7387\u4e0e\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u4f7f\u7528UTF-8\u7684BBPE\u5206\u8bcd\u867d\u7136\u8986\u76d6\u5168Unicode\u4f46\u5bf9\u975e\u62c9\u4e01\u6587\u5b57\u7684\u53d8\u957f\u7f16\u7801\u5bfc\u81f4token\u5e8f\u5217\u81a8\u80c0\uff0c\u589e\u52a0\u8ba1\u7b97\u548c\u5b58\u50a8\u6210\u672c\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u5206\u8bcd\u7b56\u7565\u3002", "method": "\u63d0\u51fa\u4e86BBPE16\uff0c\u4e00\u79cd\u57fa\u4e8eUTF-16\u7f16\u7801\u7684\u5b57\u8282\u7ea7BPE\u5206\u8bcd\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u7edf\u4e00\u76842\u5b57\u8282\u7f16\u7801\u5355\u5143\u51cf\u5c11\u975e\u62c9\u4e01\u6587\u5b57\uff08\u5982\u4e2d\u3001\u65e5\u3001\u97e9\uff09\u5e8f\u5217\u957f\u5ea6\uff0c\u4ece\u800c\u964d\u4f4e\u8ba1\u7b97\u8d1f\u8f7d\u548c\u5185\u5b58\u4f7f\u7528\u3002", "result": "BBPE16\u5728\u5355\u8bed\u3001\u53cc\u8bed\u3001\u4e09\u8bed\u53ca\u591a\u8bed\u6301\u7eed\u5b66\u4e60\u573a\u666f\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u7279\u522b\u662f\u5bf9\u4e2d\u6587token\u6570\u91cf\u51cf\u5c1110.4%\uff0c\u89e3\u7801\u8fed\u4ee3\u6b21\u6570\u964d\u4f4e10.3%\uff0c\u52a0\u5feb\u5fae\u8c03\u548c\u63a8\u7406\u901f\u5ea6\u5e76\u964d\u4f4e\u5185\u5b58\u6d88\u8017\u3002", "conclusion": "BBPE16\u4f5c\u4e3a\u4e00\u79cd\u57fa\u4e8eUTF-16\u7684\u5b57\u8282\u7ea7BPE\u5206\u8bcd\u5668\uff0c\u4fdd\u6301\u4e86\u8bed\u8a00\u65e0\u5173\u6027\u540c\u65f6\u63d0\u9ad8\u4e86\u8de8\u8bed\u8a00\u7684token\u5171\u4eab\uff0c\u80fd\u591f\u5728\u591a\u8bed\u79cd\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u4e2d\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u539f\u6709BBPE\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2602.01719", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01719", "abs": "https://arxiv.org/abs/2602.01719", "authors": ["Jiwei Tang", "Shilei Liu", "Zhicheng Zhang", "Yujin Yuan", "Libin Zheng", "Wenbo Su", "Bo Zheng"], "title": "COMI: Coarse-to-fine Context Compression via Marginal Information Gain", "comment": "Accepted at ICLR 2026", "summary": "Large Language Models (LLMs) have demonstrated exceptional capabilities across diverse tasks. However, their deployment in long context scenarios remains hindered by computational inefficiency and information redundancy. Context compression methods address these challenges by significantly reducing input length and eliminating redundancy. We propose COMI, a coarse-to-fine adaptive context compression framework that jointly optimizes for semantic relevance and diversity under high compression rates. We introduce Marginal Information Gain (MIG), a metric defined as the relevance of a unit to the input query minus its semantic redundancy with other units, guiding the compression process to prioritize information that is both relevant and low redundant. The framework operates in two stages: (1) Coarse-Grained Group Reallocation, where the context is partitioned into groups and dynamically assigned compression rates based on inter-group MIG, ensuring compression budgets align with information value distribution; and (2) Fine-Grained Token Merging, where tokens within each group are fused via an intra-group MIG-based weighting mechanism, thereby preserving key semantics while avoiding the accumulation of redundancy. Extensive experiments across question-answering (e.g., NaturalQuestions, 2WikiMQA, HotpotQA and NarrativeQA), summarization (e.g., MultiNews) with various backbones (e.g., LLaMA-2-7B, Qwen2-7B) show that COMI outperforms existing baselines by a large margin, e.g., approximately 25-point Exact Match (EM) improvement under 32x compression constraint with Qwen2-7B on NaturalQuestions.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u8fb9\u9645\u4fe1\u606f\u589e\u76ca\u7684\u7c97\u7ec6\u7c92\u5ea6\u81ea\u9002\u5e94\u538b\u7f29\u6846\u67b6COMI\uff0c\u5927\u5e45\u63d0\u5347\u538b\u7f29\u6548\u7387\u4e0e\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e0b\u8ba1\u7b97\u6548\u7387\u4f4e\u4e14\u4fe1\u606f\u5197\u4f59\u4e25\u91cd\uff0c\u9700\u8981\u6709\u6548\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u6765\u63d0\u5347\u6a21\u578b\u5904\u7406\u80fd\u529b\u548c\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86COMI\uff0c\u4e00\u79cd\u7c97\u5230\u7ec6\u7684\u81ea\u9002\u5e94\u4e0a\u4e0b\u6587\u538b\u7f29\u6846\u67b6\uff0c\u91c7\u7528\u8fb9\u9645\u4fe1\u606f\u589e\u76ca(MIG)\u6307\u6807\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u7b56\u7565\uff1a\u7c97\u7c92\u5ea6\u7ec4\u91cd\u65b0\u5206\u914d\u548c\u7ec6\u7c92\u5ea6Token\u5408\u5e76\uff0c\u5b9e\u73b0\u8bed\u4e49\u76f8\u5173\u4e14\u53bb\u5197\u4f59\u7684\u9ad8\u6548\u538b\u7f29\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u7b54\u548c\u6458\u8981\u6570\u636e\u96c6\uff08\u5982NaturalQuestions\u3001MultiNews\u7b49\uff09\u53ca\u591a\u79cd\u6a21\u578b\uff08\u5982LLaMA-2-7B\u3001Qwen2-7B\uff09\u4e0a\uff0cCOMI\u572832\u500d\u538b\u7f29\u6761\u4ef6\u4e0b\u5b9e\u73b0\u7ea625\u70b9EM\u63d0\u5347\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u3002", "conclusion": "COMI\u6846\u67b6\u5728\u9ad8\u538b\u7f29\u7387\u4e0b\u901a\u8fc7\u8054\u5408\u4f18\u5316\u8bed\u4e49\u76f8\u5173\u6027\u548c\u591a\u6837\u6027\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.01725", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01725", "abs": "https://arxiv.org/abs/2602.01725", "authors": ["Yurun Chen", "Zeyi Liao", "Ping Yin", "Taotao Xie", "Keting Yin", "Shengyu Zhang"], "title": "SafePred: A Predictive Guardrail for Computer-Using Agents via World Models", "comment": null, "summary": "With the widespread deployment of Computer-using Agents (CUAs) in complex real-world environments, prevalent long-term risks often lead to severe and irreversible consequences. Most existing guardrails for CUAs adopt a reactive approach, constraining agent behavior only within the current observation space. While these guardrails can prevent immediate short-term risks (e.g., clicking on a phishing link), they cannot proactively avoid long-term risks: seemingly reasonable actions can lead to high-risk consequences that emerge with a delay (e.g., cleaning logs leads to future audits being untraceable), which reactive guardrails cannot identify within the current observation space. To address these limitations, we propose a predictive guardrail approach, with the core idea of aligning predicted future risks with current decisions. Based on this approach, we present SafePred, a predictive guardrail framework for CUAs that establishes a risk-to-decision loop to ensure safe agent behavior. SafePred supports two key abilities: (1) Short- and long-term risk prediction: by using safety policies as the basis for risk prediction, SafePred leverages the prediction capability of the world model to generate semantic representations of both short-term and long-term risks, thereby identifying and pruning actions that lead to high-risk states; (2) Decision optimization: translating predicted risks into actionable safe decision guidances through step-level interventions and task-level re-planning. Extensive experiments show that SafePred significantly reduces high-risk behaviors, achieving over 97.6% safety performance and improving task utility by up to 21.4% compared with reactive baselines.", "AI": {"tldr": "\u9488\u5bf9\u8ba1\u7b97\u673a\u4ee3\u7406\u957f\u671f\u98ce\u9669\u95ee\u9898\uff0cSafePred\u901a\u8fc7\u9884\u6d4b\u672a\u6765\u98ce\u9669\u5e76\u4f18\u5316\u51b3\u7b56\uff0c\u6709\u6548\u63d0\u5347\u4ee3\u7406\u5b89\u5168\u6027\u548c\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u8ba1\u7b97\u673a\u4ee3\u7406\u62a4\u680f\u591a\u4e3a\u53cd\u5e94\u5f0f\uff0c\u4ec5\u9650\u5236\u5f53\u524d\u89c2\u5bdf\u7a7a\u95f4\u5185\u884c\u4e3a\uff0c\u65e0\u6cd5\u9884\u9632\u5ef6\u8fdf\u51fa\u73b0\u7684\u957f\u671f\u98ce\u9669\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u4e3b\u52a8\u9884\u6d4b\u5e76\u9884\u9632\u957f\u671f\u98ce\u9669\u7684\u62a4\u680f\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u98ce\u9669\u9884\u6d4b\u7684\u62a4\u680f\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u9884\u6d4b\u77ed\u671f\u548c\u957f\u671f\u5b89\u5168\u98ce\u9669\uff0c\u5e76\u7ed3\u5408\u6b65\u7ea7\u5e72\u9884\u548c\u4efb\u52a1\u91cd\u89c4\u5212\u8fdb\u884c\u51b3\u7b56\u4f18\u5316\u3002", "result": "SafePred\u5b9e\u73b0\u4e86\u8d85\u8fc797.6%\u7684\u5b89\u5168\u6027\u80fd\uff0c\u4efb\u52a1\u6548\u7528\u76f8\u6bd4\u53cd\u5e94\u5f0f\u57fa\u7ebf\u63d0\u5347\u8fbe21.4%\u3002", "conclusion": "SafePred\u9884\u6d4b\u578b\u62a4\u680f\u6846\u67b6\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u673a\u4ee3\u7406\u7684\u9ad8\u98ce\u9669\u884c\u4e3a\uff0c\u63d0\u5347\u5b89\u5168\u6027\u548c\u4efb\u52a1\u6548\u7528\u3002"}}
{"id": "2602.01747", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01747", "abs": "https://arxiv.org/abs/2602.01747", "authors": ["Hongseok Choi", "Serynn Kim", "Wencke Liermann", "Jin Seong", "Jin-Xia Huang"], "title": "Enhancing Automated Essay Scoring with Three Techniques: Two-Stage Fine-Tuning, Score Alignment, and Self-Training", "comment": "22 pages, 4 figures", "summary": "Automated Essay Scoring (AES) plays a crucial role in education by providing scalable and efficient assessment tools. However, in real-world settings, the extreme scarcity of labeled data severely limits the development and practical adoption of robust AES systems. This study proposes a novel approach to enhance AES performance in both limited-data and full-data settings by introducing three key techniques. First, we introduce a Two-Stage fine-tuning strategy that leverages low-rank adaptations to better adapt an AES model to target prompt essays. Second, we introduce a Score Alignment technique to improve consistency between predicted and true score distributions. Third, we employ uncertainty-aware self-training using unlabeled data, effectively expanding the training set with pseudo-labeled samples while mitigating label noise propagation. We implement above three key techniques on DualBERT. We conduct extensive experiments on the ASAP++ dataset. As a result, in the 32-data setting, all three key techniques improve performance, and their integration achieves 91.2% of the full-data performance trained on approximately 1,000 labeled samples. In addition, the proposed Score Alignment technique consistently improves performance in both limited-data and full-data settings: e.g., it achieves state-of-the-art results in the full-data setting when integrated into DualBERT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u4e24\u9636\u6bb5\u5fae\u8c03\u3001\u5206\u6570\u5bf9\u9f50\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u81ea\u8bad\u7ec3\u7684\u4e09\u9879\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u6a21\u578b\u5728\u5c0f\u6837\u672c\u548c\u5927\u6837\u672c\u6761\u4ef6\u4e0b\u7684\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86\u5728ASAP++\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53d7\u9650\u4e8e\u6807\u6ce8\u6570\u636e\u532e\u4e4f\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u5f00\u53d1\u4e0e\u5e94\u7528\uff0c\u4e9f\u9700\u6709\u6548\u6280\u672f\u63d0\u5347\u5c0f\u6837\u672c\u73af\u5883\u4e0b\u7684\u8bc4\u5206\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u9879\u6280\u672f\uff1a\u4e00\u662f\u57fa\u4e8e\u4f4e\u79e9\u9002\u914d\u7684\u4e24\u9636\u6bb5\u5fae\u8c03\u7b56\u7565\uff0c\u4e8c\u662f\u5206\u6570\u5bf9\u9f50\u6280\u672f\u7528\u4e8e\u63d0\u5347\u9884\u6d4b\u5206\u5e03\u4e0e\u771f\u5b9e\u5206\u5e03\u4e00\u81f4\u6027\uff0c\u4e09\u662f\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u81ea\u8bad\u7ec3\u65b9\u6cd5\u6269\u5c55\u8bad\u7ec3\u96c6\u4e14\u51cf\u5c11\u4f2a\u6807\u7b7e\u566a\u58f0\uff0c\u57fa\u4e8eDualBERT\u6a21\u578b\u5b9e\u73b0\u3002", "result": "\u5728ASAP++\u6570\u636e\u96c6\u4e0a\u768432\u6837\u672c\u6709\u9650\u6570\u636e\u73af\u5883\u4e2d\uff0c\u4e09\u9879\u6280\u672f\u7684\u7ed3\u5408\u4f7f\u6a21\u578b\u8fbe\u5230\u4e86\u7ea61000\u6807\u6ce8\u6837\u672c\u8bad\u7ec3\u6a21\u578b\u768491.2%\u6027\u80fd\uff0c\u4e14\u5206\u6570\u5bf9\u9f50\u6280\u672f\u5728\u5145\u8db3\u6570\u636e\u73af\u5883\u4e0b\u63d0\u5347\u6548\u679c\u660e\u663e\uff0c\u5b9e\u73b0\u4e86\u6700\u65b0\u7684\u6027\u80fd\u6c34\u5e73\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4e09\u9879\u5173\u952e\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u4f5c\u6587\u8bc4\u5206\u6a21\u578b\u5728\u6709\u9650\u548c\u5145\u5206\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u6781\u5ea6\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u5145\u5206\u6570\u636e\u8bad\u7ec3\u6548\u679c\u7684\u6210\u7ee9\u3002"}}
{"id": "2602.01752", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.01752", "abs": "https://arxiv.org/abs/2602.01752", "authors": ["Yidan Wang", "Yubing Ren", "Yanan Cao", "Li Guo"], "title": "WorldCup Sampling for Multi-bit LLM Watermarking", "comment": null, "summary": "As large language models (LLMs) generate increasingly human-like text, watermarking offers a promising solution for reliable attribution beyond mere detection. While multi-bit watermarking enables richer provenance encoding, existing methods largely extend zero-bit schemes through seed-driven steering, leading to indirect information flow, limited effective capacity, and suboptimal decoding. In this paper, we propose WorldCup, a multi-bit watermarking framework for LLMs that treats sampling as a natural communication channel and embeds message bits directly into token selection via a hierarchical competition mechanism guided by complementary signals. Moreover, WorldCup further adopts entropy-aware modulation to preserve generation quality and supports robust message recovery through confidence-aware decoding. Comprehensive experiments show that WorldCup achieves a strong balance across capacity, detectability, robustness, text quality, and decoding efficiency, consistently outperforming prior baselines and laying a solid foundation for future LLM watermarking studies.", "AI": {"tldr": "WorldCup\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u591a\u6bd4\u7279\u7801\u5927\u8bed\u8a00\u6a21\u578b\u6c34\u5370\u6846\u67b6\uff0c\u901a\u8fc7\u76f4\u63a5\u5d4c\u5165\u6d88\u606f\u6bd4\u7279\u548c\u71b5\u611f\u77e5\u8c03\u5236\uff0c\u663e\u8457\u63d0\u5347\u5bb9\u91cf\u548c\u89e3\u7801\u6027\u80fd\uff0c\u5b9e\u73b0\u66f4\u53ef\u9760\u7684\u6587\u672c\u6765\u6e90\u8ba4\u8bc1\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6c34\u5370\u65b9\u6cd5\u591a\u4e3a\u96f6\u6bd4\u7279\u7801\u6269\u5c55\uff0c\u4fe1\u606f\u6d41\u95f4\u63a5\u4e14\u5bb9\u91cf\u6709\u9650\uff0c\u89e3\u7801\u6027\u80fd\u4e0d\u4f73\uff0c\u96be\u4ee5\u5b9e\u73b0\u53ef\u9760\u6765\u6e90\u6eaf\u6e90\u3002", "method": "\u63d0\u51faWorldCup\u6846\u67b6\uff0c\u5c06\u91c7\u6837\u89c6\u4e3a\u901a\u4fe1\u4fe1\u9053\uff0c\u901a\u8fc7\u5206\u5c42\u7ade\u4e89\u673a\u5236\u76f4\u63a5\u5c06\u6d88\u606f\u6bd4\u7279\u5d4c\u5165\u8bcd\u8bed\u9009\u62e9\u4e2d\uff0c\u5e76\u7ed3\u5408\u4e92\u8865\u4fe1\u53f7\u5f15\u5bfc\uff0c\u591a\u6bd4\u7279\u6c34\u5370\u7f16\u7801\u3002\u91c7\u7528\u71b5\u611f\u77e5\u8c03\u5236\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\uff0c\u5229\u7528\u7f6e\u4fe1\u5ea6\u611f\u77e5\u89e3\u7801\u5b9e\u73b0\u9c81\u68d2\u6d88\u606f\u6062\u590d\u3002", "result": "\u5b9e\u9a8c\u8868\u660eWorldCup\u5728\u5bb9\u91cf\u3001\u53ef\u68c0\u6d4b\u6027\u3001\u9c81\u68d2\u6027\u3001\u6587\u672c\u8d28\u91cf\u53ca\u89e3\u7801\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u7a33\u5b9a\u4e14\u5e73\u8861\u3002", "conclusion": "WorldCup\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6bd4\u7279\u7801\u6c34\u5370\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u517c\u987e\u4fe1\u606f\u5bb9\u91cf\u4e0e\u751f\u6210\u8d28\u91cf\uff0c\u63a8\u52a8\u4e86\u672a\u6765\u6c34\u5370\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2602.01757", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01757", "abs": "https://arxiv.org/abs/2602.01757", "authors": ["Doohyun Kim", "Donghwa Kang", "Kyungjae Lee", "Hyeongboo Baek", "Brent Byunghoon Kang"], "title": "Zero2Text: Zero-Training Cross-Domain Inversion Attacks on Textual Embeddings", "comment": "10 pages", "summary": "The proliferation of retrieval-augmented generation (RAG) has established vector databases as critical infrastructure, yet they introduce severe privacy risks via embedding inversion attacks. Existing paradigms face a fundamental trade-off: optimization-based methods require computationally prohibitive queries, while alignment-based approaches hinge on the unrealistic assumption of accessible in-domain training data. These constraints render them ineffective in strict black-box and cross-domain settings. To dismantle these barriers, we introduce Zero2Text, a novel training-free framework based on recursive online alignment. Unlike methods relying on static datasets, Zero2Text synergizes LLM priors with a dynamic ridge regression mechanism to iteratively align generation to the target embedding on-the-fly. We further demonstrate that standard defenses, such as differential privacy, fail to effectively mitigate this adaptive threat. Extensive experiments across diverse benchmarks validate Zero2Text; notably, on MS MARCO against the OpenAI victim model, it achieves 1.8x higher ROUGE-L and 6.4x higher BLEU-2 scores compared to baselines, recovering sentences from unknown domains without a single leaked data pair.", "AI": {"tldr": "Zero2Text\u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u6570\u636e\u3001\u57fa\u4e8e\u9012\u5f52\u5bf9\u9f50\u7684\u5d4c\u5165\u53cd\u6f14\u653b\u51fb\u65b9\u6cd5\uff0c\u6709\u6548\u9488\u5bf9\u9ed1\u7bb1\u8de8\u57df\u73af\u5883\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6587\u672c\u6062\u590d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5d4c\u5165\u53cd\u6f14\u653b\u51fb\u9632\u5fa1\u9762\u4e34\u8ba1\u7b97\u4ee3\u4ef7\u9ad8\u6216\u9700\u8bad\u7ec3\u6570\u636e\u7684\u6839\u672c\u77db\u76fe\uff0c\u4e14\u5728\u4e25\u683c\u9ed1\u7bb1\u548c\u8de8\u57df\u73af\u5883\u4e2d\u65e0\u6548\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9012\u5f52\u5728\u7ebf\u5bf9\u9f50\u7684\u65e0\u8bad\u7ec3\u6846\u67b6Zero2Text\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5148\u9a8c\u548c\u52a8\u6001\u5cad\u56de\u5f52\u673a\u5236\uff0c\u8fed\u4ee3\u5bf9\u9f50\u751f\u6210\u6587\u672c\u4e0e\u76ee\u6807\u5d4c\u5165\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cZero2Text\u5728MS MARCO\u4e0a\u5bf9OpenAI\u6a21\u578b\u8fbe\u6210\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u9ad81.8\u500dROUGE-L\u548c6.4\u500dBLEU-2\u5206\u6570\uff0c\u80fd\u5728\u65e0\u6cc4\u9732\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u4ece\u672a\u77e5\u9886\u57df\u6062\u590d\u6587\u672c\u3002", "conclusion": "Zero2Text\u6846\u67b6\u6210\u529f\u6253\u7834\u4e86\u73b0\u6709\u5d4c\u5165\u53cd\u6f14\u653b\u51fb\u9632\u5fa1\u7684\u9650\u5236\uff0c\u5728\u65e0\u8bad\u7ec3\u6570\u636e\u4e14\u9ed1\u7bb1\u7684\u8de8\u57df\u73af\u5883\u4e2d\u6709\u6548\u6062\u590d\u76ee\u6807\u5d4c\u5165\u5bf9\u5e94\u7684\u6587\u672c\u3002"}}
{"id": "2602.01771", "categories": ["cs.CL", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.01771", "abs": "https://arxiv.org/abs/2602.01771", "authors": ["Jingyao Wu", "Bin Lu", "Zijun Di", "Xiaoying Gan", "Meng Jin", "Luoyi Fu", "Xinbing Wang", "Chenghu Zhou"], "title": "<SOG_k>: One LLM Token for Explicit Graph Structural Understanding", "comment": null, "summary": "Large language models show great potential in unstructured data understanding, but still face significant challenges with graphs due to their structural hallucination. Existing approaches mainly either verbalize graphs into natural language, which leads to excessive token consumption and scattered attention, or transform graphs into trainable continuous embeddings (i.e., soft prompt), but exhibit severe misalignment with original text tokens. To solve this problem, we propose to incorporate one special token <SOG_k> to fully represent the Structure Of Graph within a unified token space, facilitating explicit topology input and structural information sharing. Specifically, we propose a topology-aware structural tokenizer that maps each graph topology into a highly selective single token. Afterwards, we construct a set of hybrid structure Question-Answering corpora to align new structural tokens with existing text tokens. With this approach, <SOG_k> empowers LLMs to understand, generate, and reason in a concise and accurate manner. Extensive experiments on five graph-level benchmarks demonstrate the superiority of our method, achieving a performance improvement of 9.9% to 41.4% compared to the baselines while exhibiting interpretability and consistency. Furthermore, our method provides a flexible extension to node-level tasks, enabling both global and local structural understanding. The codebase is publicly available at https://github.com/Jingyao-Wu/SOG.", "AI": {"tldr": "\u5f15\u5165\u7279\u6b8a\u7ed3\u6784\u4ee4\u724c<SOG_k>\u7edf\u4e00\u8868\u793a\u56fe\u7ed3\u6784\uff0c\u6709\u6548\u89e3\u51b3\u56fe\u4e0e\u6587\u672c\u4ee4\u724c\u9519\u4f4d\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u56fe\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u5c06\u56fe\u8f6c\u6362\u4e3a\u81ea\u7136\u8bed\u8a00\u5bfc\u81f4\u4ee4\u724c\u6d88\u8017\u5927\u4e14\u6ce8\u610f\u529b\u5206\u6563\uff0c\u8981\u4e48\u7528\u8fde\u7eed\u5d4c\u5165\u8868\u793a\u56fe\u7ed3\u6784\u4f46\u4e0e\u6587\u672c\u4ee4\u724c\u4e25\u91cd\u4e0d\u5339\u914d\uff0c\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u56fe\u7406\u89e3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ed3\u6784\u611f\u77e5\u7684\u5206\u8bcd\u5668\u5c06\u56fe\u62d3\u6251\u6620\u5c04\u4e3a\u5355\u4e00\u9009\u62e9\u6027\u4ee4\u724c\uff0c\u5e76\u6784\u5efa\u6df7\u5408\u7ed3\u6784\u7684\u95ee\u7b54\u8bed\u6599\u5e93\u4ee5\u5bf9\u9f50\u65b0\u7684\u7ed3\u6784\u4ee4\u724c\u548c\u6587\u672c\u4ee4\u724c\uff0c\u4ece\u800c\u5b9e\u73b0\u56fe\u7ed3\u6784\u7684\u663e\u5f0f\u62d3\u6251\u8f93\u5165\u548c\u4fe1\u606f\u5171\u4eab\u3002", "result": "\u5728\u4e94\u4e2a\u56fe\u7ea7\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u8f83\u57fa\u7ebf\u6027\u80fd\u63d0\u5347\u4e869.9%\u81f341.4%\uff0c\u540c\u65f6\u5c55\u73b0\u51fa\u826f\u597d\u7684\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027\uff0c\u5e76\u80fd\u591f\u7075\u6d3b\u6269\u5c55\u5230\u8282\u70b9\u7ea7\u4efb\u52a1\uff0c\u5b9e\u73b0\u5c40\u90e8\u548c\u5168\u5c40\u7ed3\u6784\u7406\u89e3\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u7684\u7ed3\u6784\u5316\u5206\u8bcd\u5668\uff0c\u5229\u7528\u7279\u6b8a\u7684\u7ed3\u6784\u4ee4\u724c<SOG_k>\u5728\u7edf\u4e00\u7684\u4ee4\u724c\u7a7a\u95f4\u4e2d\u8868\u793a\u56fe\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u56fe\u6570\u636e\u7684\u7406\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u56fe\u7ea7\u4efb\u52a1\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u5177\u5907\u89e3\u91ca\u6027\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.01778", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01778", "abs": "https://arxiv.org/abs/2602.01778", "authors": ["Kangtao Lv", "Jiwei Tang", "Langming Liu", "Haibin Chen", "Weidong Zhang", "Shilei Liu", "Yongwei Wang", "Yujin Yuan", "Wenbo Su", "Bo Zheng"], "title": "Data Distribution Matters: A Data-Centric Perspective on Context Compression for Large Language Model", "comment": "15 pages,6 figures", "summary": "The deployment of Large Language Models (LLMs) in long-context scenarios is hindered by computational inefficiency and significant information redundancy. Although recent advancements have widely adopted context compression to address these challenges, existing research only focus on model-side improvements, the impact of the data distribution itself on context compression remains largely unexplored. To bridge this gap, we are the first to adopt a data-centric perspective to systematically investigate how data distribution impacts compression quality, including two dimensions: input data and intrinsic data (i.e., the model's internal pretrained knowledge). We evaluate the semantic integrity of compressed representations using an autoencoder-based framework to systematically investigate it. Our experimental results reveal that: (1) encoder-measured input entropy negatively correlates with compression quality, while decoder-measured entropy shows no significant relationship under a frozen-decoder setting; and (2) the gap between intrinsic data of the encoder and decoder significantly diminishes compression gains, which is hard to mitigate. Based on these findings, we further present practical guidelines to optimize compression gains.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u4ece\u6570\u636e\u89d2\u5ea6\u7814\u7a76\u6570\u636e\u5206\u5e03\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u538b\u7f29\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8f93\u5165\u71b5\u548c\u6a21\u578b\u5185\u5728\u6570\u636e\u5339\u914d\u5ea6\u662f\u5173\u952e\u56e0\u7d20\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u6a21\u578b\u672c\u8eab\u7684\u6539\u8fdb\uff0c\u5ffd\u89c6\u4e86\u6570\u636e\u5206\u5e03\u5bf9\u4e0a\u4e0b\u6587\u538b\u7f29\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u81ea\u52a8\u7f16\u7801\u5668\u7684\u6846\u67b6\uff0c\u4ece\u6570\u636e\u4e2d\u5fc3\u89c6\u89d2\u7cfb\u7edf\u5730\u8bc4\u4f30\u8f93\u5165\u6570\u636e\u548c\u6a21\u578b\u5185\u5728\u6570\u636e\u5bf9\u8bed\u4e49\u538b\u7f29\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u8f93\u5165\u71b5\u4e0e\u538b\u7f29\u8d28\u91cf\u8d1f\u76f8\u5173\uff0c\u4e14\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5185\u5728\u6570\u636e\u5dee\u5f02\u663e\u8457\u964d\u4f4e\u538b\u7f29\u6536\u76ca\uff0c\u63d0\u51fa\u4f18\u5316\u538b\u7f29\u6536\u76ca\u7684\u5b9e\u7528\u6307\u5bfc\u65b9\u6848\u3002", "conclusion": "\u6570\u636e\u5206\u5e03\u5bf9\u4e0a\u4e0b\u6587\u538b\u7f29\u8d28\u91cf\u6709\u663e\u8457\u5f71\u54cd\uff0c\u5176\u4e2d\u8f93\u5165\u6570\u636e\u7684\u71b5\u4e0e\u538b\u7f29\u8d28\u91cf\u8d1f\u76f8\u5173\uff0c\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u5185\u5728\u6570\u636e\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u4f1a\u964d\u4f4e\u538b\u7f29\u6548\u679c\u3002"}}
{"id": "2602.01807", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.01807", "abs": "https://arxiv.org/abs/2602.01807", "authors": ["DongNyeong Heo", "Heelyoul Choi"], "title": "Sentence Curve Language Models", "comment": null, "summary": "Language models (LMs) are a central component of modern AI systems, and diffusion-based language models (DLMs) have recently emerged as a competitive alternative. Both paradigms rely on word embeddings not only to represent the input sentence, but also to represent the target sentence that backbone models are trained to predict. We argue that such static embedding of the target word is insensitive to neighboring words, encouraging locally accurate word prediction while neglecting global structure across the target sentence. To address this limitation, we propose a continuous sentence representation, termed sentence curve, defined as a spline curve whose control points affect multiple words in the sentence. Based on this representation, we introduce sentence curve language model (SCLM), which extends DLMs to predict sentence curves instead of the static word embeddings. We theoretically show that sentence curve prediction induces a regularization effect that promotes global structure modeling, and characterize how different sentence curve types affect this behavior. Empirically, SCLM achieves SOTA performance among DLMs on IWSLT14 and WMT14, shows stable training without burdensome knowledge distillation, and demonstrates promising potential compared to discrete DLMs on LM1B.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53e5\u5b50\u66f2\u7ebf\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u9759\u6001\u8bcd\u5d4c\u5165\u5ffd\u89c6\u53e5\u5b50\u5168\u5c40\u7ed3\u6784\u7684\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u548c\u66f4\u7a33\u5b9a\u7684\u8bad\u7ec3\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u9759\u6001\u8bcd\u5d4c\u5165\u8868\u793a\u76ee\u6807\u53e5\u5b50\uff0c\u5ffd\u7565\u4e86\u76ee\u6807\u8bcd\u4e4b\u95f4\u7684\u5168\u5c40\u7ed3\u6784\uff0c\u5bfc\u81f4\u8bcd\u9884\u6d4b\u53ea\u5173\u6ce8\u5c40\u90e8\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8fde\u7eed\u53e5\u5b50\u8868\u793a\u65b9\u6cd5\u201c\u53e5\u5b50\u66f2\u7ebf\u201d\uff0c\u901a\u8fc7\u6837\u6761\u66f2\u7ebf\u7684\u63a7\u5236\u70b9\u5f71\u54cd\u53e5\u4e2d\u591a\u4e2a\u8bcd\uff0c\u7ed3\u5408\u53e5\u5b50\u66f2\u7ebf\u8bed\u8a00\u6a21\u578b\uff08SCLM\uff09\u6269\u5c55\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u9884\u6d4b\u53e5\u5b50\u66f2\u7ebf\u800c\u975e\u9759\u6001\u8bcd\u5d4c\u5165\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u53e5\u5b50\u66f2\u7ebf\u9884\u6d4b\u5177\u6709\u6b63\u5219\u5316\u6548\u679c\uff0c\u4fc3\u8fdb\u5168\u5c40\u7ed3\u6784\u5efa\u6a21\u3002\u5b9e\u9a8c\u4e2d\uff0cSCLM\u5728IWSLT14\u548cWMT14\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684SOTA\uff0c\u8bad\u7ec3\u7a33\u5b9a\uff0c\u4e14\u5728LM1B\u6570\u636e\u96c6\u8868\u73b0\u4f18\u4e8e\u79bb\u6563\u6269\u6563\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u53e5\u5b50\u66f2\u7ebf\u8868\u793a\u53ca\u5176\u5bf9\u5e94\u7684\u8bed\u8a00\u6a21\u578b\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u7684\u5168\u5c40\u7ed3\u6784\u5efa\u6a21\u80fd\u529b\uff0c\u663e\u8457\u6539\u5584\u4e86\u8bed\u8a00\u5efa\u6a21\u6027\u80fd\u548c\u8bad\u7ec3\u8868\u73b0\u3002"}}
{"id": "2602.01838", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01838", "abs": "https://arxiv.org/abs/2602.01838", "authors": ["Abdelrahman Mansour", "Khaled W. Alshaer", "Moataz Elsaban"], "title": "AXE: Low-Cost Cross-Domain Web Structured Information Extraction", "comment": null, "summary": "Extracting structured data from the web is often a trade-off between the brittle nature of manual heuristics and the prohibitive cost of Large Language Models. We introduce AXE (Adaptive X-Path Extractor), a pipeline that rethinks this process by treating the HTML DOM as a tree that needs pruning rather than just a wall of text to be read. AXE uses a specialized \"pruning\" mechanism to strip away boilerplate and irrelevant nodes, leaving behind a distilled, high-density context that allows a tiny 0.6B LLM to generate precise, structured outputs. To keep the model honest, we implement Grounded XPath Resolution (GXR), ensuring every extraction is physically traceable to a source node. Despite its low footprint, AXE achieves state-of-the-art zero-shot performance, outperforming several much larger, fully-trained alternatives with an F1 score of 88.1% on the SWDE dataset. By releasing our specialized adaptors, we aim to provide a practical, cost-effective path for large-scale web information extraction.", "AI": {"tldr": "AXE\u901a\u8fc7\u667a\u80fd\u4fee\u526aHTML\u6811\u5e76\u7ed3\u5408\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u7cbe\u5ea6\u7684\u7f51\u9875\u7ed3\u6784\u5316\u6570\u636e\u81ea\u52a8\u63d0\u53d6\uff0c\u6548\u679c\u9886\u5148\u4e8e\u591a\u79cd\u5927\u578b\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u624b\u5de5\u89c4\u5219\u8106\u5f31\u4e14\u65e0\u6cd5\u6269\u5c55\uff0c\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u672c\u9ad8\u6602\uff0c\u9700\u5bfb\u627e\u4e00\u4e2a\u65e2\u9ad8\u6548\u53c8\u7ecf\u6d4e\u7684\u6570\u636e\u63d0\u53d6\u65b9\u6848\u3002", "method": "\u5c06HTML DOM\u89c6\u4e3a\u9700\u8981\u4fee\u526a\u7684\u6811\u7ed3\u6784\uff0c\u4f7f\u7528\u4e13\u95e8\u7684\u4fee\u526a\u673a\u5236\u5254\u9664\u65e0\u5173\u8282\u70b9\uff0c\u7ed3\u5408\u4e00\u4e2a\u5c0f\u578b0.6B\u53c2\u6570\u91cf\u7684LLM\u751f\u6210\u7cbe\u786e\u7ed3\u6784\u5316\u8f93\u51fa\uff0c\u5e76\u91c7\u7528GXR\u786e\u4fdd\u63d0\u53d6\u5185\u5bb9\u53ef\u5b9a\u4f4d\u8ffd\u8e2a\u3002", "result": "AXE\u5728SWDE\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8688.1%\u7684F1\u5f97\u5206\uff0c\u8d85\u8d8a\u591a\u79cd\u5927\u578b\u4e14\u5b8c\u5168\u8bad\u7ec3\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u5c55\u793a\u4e86\u4f18\u5f02\u7684\u96f6\u6837\u672c\u6027\u80fd\u3002", "conclusion": "AXE\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u6301\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4f18\u4e8e\u5927\u578b\u6a21\u578b\u7684\u7f51\u9875\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u6548\u679c\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.01840", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01840", "abs": "https://arxiv.org/abs/2602.01840", "authors": ["Jiwei Tang", "Shilei Liu", "Zhicheng Zhang", "Qingsong Lv", "Runsong Zhao", "Tingwei Lu", "Langming Liu", "Haibin Chen", "Yujin Yuan", "Hai-Tao Zheng", "Wenbo Su", "Bo Zheng"], "title": "Read As Human: Compressing Context via Parallelizable Close Reading and Skimming", "comment": "13 pages,5 figures", "summary": "Large Language Models (LLMs) demonstrate exceptional capability across diverse tasks. However, their deployment in long-context scenarios is hindered by two challenges: computational inefficiency and redundant information. We propose RAM (Read As HuMan), a context compression framework that adopts an adaptive hybrid reading strategy, to address these challenges. Inspired by human reading behavior (i.e., close reading important content while skimming less relevant content), RAM partitions the context into segments and encodes them with the input query in parallel. High-relevance segments are fully retained (close reading), while low-relevance ones are query-guided compressed into compact summary vectors (skimming). Both explicit textual segments and implicit summary vectors are concatenated and fed into decoder to achieve both superior performance and natural language format interpretability. To refine the decision boundary between close reading and skimming, we further introduce a contrastive learning objective based on positive and negative query-segment pairs. Experiments demonstrate that RAM outperforms existing baselines on multiple question answering and summarization benchmarks across two backbones, while delivering up to a 12x end-to-end speedup on long inputs (average length 16K; maximum length 32K).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u4eff\u4eba\u7c7b\u9605\u8bfb\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u6846\u67b6RAM\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u6587\u672c\u65f6\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u8d85\u957f\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u8ba1\u7b97\u6548\u7387\u4f4e\u4e0b\u548c\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u4fdd\u6301\u6027\u80fd\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u81ea\u9002\u5e94\u6df7\u5408\u9605\u8bfb\u7b56\u7565\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\uff0c\u5c06\u4e0a\u4e0b\u6587\u5206\u6bb5\u5e76\u4e0e\u67e5\u8be2\u5e76\u884c\u7f16\u7801\uff0c\u5bf9\u9ad8\u76f8\u5173\u6bb5\u8fdb\u884c\u7cbe\u8bfb\u4fdd\u7559\uff0c\u5bf9\u4f4e\u76f8\u5173\u6bb5\u8fdb\u884c\u67e5\u8be2\u5f15\u5bfc\u7684\u538b\u7f29\u6458\u8981\uff0c\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u4f18\u5316\u9605\u8bfb\u7b56\u7565\u3002", "result": "RAM\u5728\u591a\u4e2a\u95ee\u7b54\u548c\u6458\u8981\u4efb\u52a1\u4e2d\uff0c\u76f8\u8f83\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u5728\u5904\u7406\u5e73\u5747\u957f\u5ea6\u8fbe16K\uff0c\u6700\u592732K\u7684\u957f\u6587\u672c\u65f6\uff0c\u5b9e\u73b0\u6700\u591a12\u500d\u7684\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "RAM\u6846\u67b6\u901a\u8fc7\u6a21\u4eff\u4eba\u7c7b\u9605\u8bfb\u884c\u4e3a\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u7684\u8ba1\u7b97\u4f4e\u6548\u548c\u4fe1\u606f\u5197\u4f59\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u8ba1\u7b97\u901f\u5ea6\u3002"}}
{"id": "2602.01875", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01875", "abs": "https://arxiv.org/abs/2602.01875", "authors": ["Langming Liu", "Kangtao Lv", "Haibin Chen", "Weidong Zhang", "Yejing Wang", "Shilei Liu", "Xin Tong", "Yujin Yuan", "Yongwei Wang", "Wenbo Su", "Bo Zheng"], "title": "PretrainRL: Alleviating Factuality Hallucination of Large Language Models at the Beginning", "comment": null, "summary": "Large language models (LLMs), despite their powerful capabilities, suffer from factual hallucinations where they generate verifiable falsehoods. We identify a root of this issue: the imbalanced data distribution in the pretraining corpus, which leads to a state of \"low-probability truth\" and \"high-probability falsehood\". Recent approaches, such as teaching models to say \"I don't know\" or post-hoc knowledge editing, either evade the problem or face catastrophic forgetting. To address this issue from its root, we propose \\textbf{PretrainRL}, a novel framework that integrates reinforcement learning into the pretraining phase to consolidate factual knowledge. The core principle of PretrainRL is \"\\textbf{debiasing then learning}.\" It actively reshapes the model's probability distribution by down-weighting high-probability falsehoods, thereby making \"room\" for low-probability truths to be learned effectively. To enable this, we design an efficient negative sampling strategy to discover these high-probability falsehoods and introduce novel metrics to evaluate the model's probabilistic state concerning factual knowledge. Extensive experiments on three public benchmarks demonstrate that PretrainRL significantly alleviates factual hallucinations and outperforms state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPretrainRL\u6846\u67b6\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u9884\u8bad\u7ec3\u4e2d\u964d\u4f4e\u9519\u8bef\u4fe1\u606f\u6982\u7387\uff0c\u63d0\u5347\u6a21\u578b\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e8b\u5b9e\u5e7b\u89c9\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u9884\u8bad\u7ec3\u8bed\u6599\u4e2d\u7684\u6570\u636e\u5206\u5e03\u4e0d\u5747\u8861\uff0c\u5bfc\u81f4\u771f\u5b9e\u4fe1\u606f\u7684\u6982\u7387\u8f83\u4f4e\u800c\u9519\u8bef\u4fe1\u606f\u7684\u6982\u7387\u8f83\u9ad8\uff0c\u9020\u6210\u4e8b\u5b9e\u5e7b\u89c9\u95ee\u9898\u3002", "method": "\u63d0\u51faPretrainRL\u6846\u67b6\uff0c\u5c06\u5f3a\u5316\u5b66\u4e60\u878d\u5165\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u901a\u8fc7\u201c\u53bb\u504f\u89c1\u518d\u5b66\u4e60\u201d\u7684\u539f\u5219\uff0c\u4e3b\u52a8\u8c03\u6574\u6a21\u578b\u6982\u7387\u5206\u5e03\uff0c\u964d\u4f4e\u9ad8\u6982\u7387\u9519\u8bef\u4fe1\u606f\u7684\u6743\u91cd\uff0c\u540c\u65f6\u8bbe\u8ba1\u8d1f\u91c7\u6837\u7b56\u7565\u548c\u8bc4\u4ef7\u6307\u6807\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPretrainRL\u663e\u8457\u51cf\u5c11\u4e86\u4e8b\u5b9e\u5e7b\u89c9\u73b0\u8c61\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u9636\u6bb5\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u5e76\u8c03\u6574\u6982\u7387\u5206\u5e03\uff0cPretrainRL\u6709\u6548\u7f13\u89e3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u5e7b\u89c9\u95ee\u9898\u3002"}}
{"id": "2602.01885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01885", "abs": "https://arxiv.org/abs/2602.01885", "authors": ["Tiantian Chen", "Jiaqi Lu", "Ying Shen", "Lin Zhang"], "title": "ES-MemEval: Benchmarking Conversational Agents on Personalized Long-Term Emotional Support", "comment": "12 pages, 7 figures. Accepted to The Web Conference (WWW) 2026", "summary": "Large Language Models (LLMs) have shown strong potential as conversational agents. Yet, their effectiveness remains limited by deficiencies in robust long-term memory, particularly in complex, long-term web-based services such as online emotional support. However, existing long-term dialogue benchmarks primarily focus on static and explicit fact retrieval, failing to evaluate agents in critical scenarios where user information is dispersed, implicit, and continuously evolving. To address this gap, we introduce ES-MemEval, a comprehensive benchmark that systematically evaluates five core memory capabilities: information extraction, temporal reasoning, conflict detection, abstention, and user modeling, in long-term emotional support settings, covering question answering, summarization, and dialogue generation tasks. To support the benchmark, we also propose EvoEmo, a multi-session dataset for personalized long-term emotional support that captures fragmented, implicit user disclosures and evolving user states. Extensive experiments on open-source long-context, commercial, and retrieval-augmented (RAG) LLMs show that explicit long-term memory is essential for reducing hallucinations and enabling effective personalization. At the same time, RAG improves factual consistency but struggles with temporal dynamics and evolving user states. These findings highlight both the potential and limitations of current paradigms and motivate more robust integration of memory and retrieval for long-term personalized dialogue systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u9488\u5bf9\u957f\u671f\u60c5\u611f\u652f\u6301\u4e2d\u7528\u6237\u4fe1\u606f\u9690\u5f0f\u5206\u6563\u4e14\u52a8\u6001\u53d8\u5316\u7684\u7279\u70b9\uff0c\u63d0\u51fa\u5168\u65b0\u7684\u8bb0\u5fc6\u80fd\u529b\u8bc4\u6d4b\u57fa\u51c6\u548c\u6570\u636e\u96c6\uff0c\u63ed\u793a\u5f53\u524d\u957f\u65f6\u8bb0\u5fc6\u53ca\u68c0\u7d22\u6a21\u578b\u7684\u4f18\u7f3a\u70b9\uff0c\u63a8\u52a8\u66f4\u667a\u80fd\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u957f\u65f6\u5bf9\u8bdd\u8bc4\u6d4b\u504f\u91cd\u9759\u6001\u663e\u5f0f\u4e8b\u5b9e\u68c0\u7d22\uff0c\u65e0\u6cd5\u8986\u76d6\u60c5\u611f\u652f\u6301\u4e2d\u9690\u5f0f\u3001\u5206\u6563\u3001\u52a8\u6001\u53d8\u5316\u7684\u7528\u6237\u4fe1\u606f\uff0c\u4e9f\u9700\u5168\u9762\u6807\u51c6\u6765\u8bc4\u4ef7\u8bb0\u5fc6\u80fd\u529b\u3002", "method": "\u63d0\u51faES-MemEval\u57fa\u51c6\u7cfb\u7edf\u8bc4\u4f30\u4e94\u5927\u8bb0\u5fc6\u80fd\u529b\uff0c\u5e76\u6784\u5efa\u5305\u62ec\u591a\u8f6e\u9690\u5f0f\u7528\u6237\u4fe1\u606f\u7684EvoEmo\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u591a\u79cd\u5f00\u6e90\u53ca\u5546\u7528\u6a21\u578b\u7684\u5927\u89c4\u6a21\u5b9e\u9a8c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u663e\u5f0f\u957f\u65f6\u8bb0\u5fc6\u6709\u52a9\u4e8e\u964d\u4f4e\u5e7b\u89c9\u548c\u589e\u5f3a\u4e2a\u6027\u5316\uff0c\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u63d0\u5347\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u4f46\u5728\u65f6\u95f4\u52a8\u6001\u548c\u7528\u6237\u72b6\u6001\u6f14\u53d8\u5904\u7406\u4e0a\u5b58\u5728\u6311\u6218\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u95f4\u4e2a\u6027\u5316\u60c5\u611f\u652f\u6301\u4e2d\u8bb0\u5fc6\u80fd\u529b\u4ecd\u6709\u9650\uff0c\u663e\u5f0f\u957f\u65f6\u8bb0\u5fc6\u548c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u5404\u6709\u4f18\u52bf\u548c\u4e0d\u8db3\uff0c\u9700\u7ed3\u5408\u4e8c\u8005\u63d0\u5347\u6a21\u578b\u7684\u6301\u4e45\u8bb0\u5fc6\u548c\u4e2a\u6027\u5316\u80fd\u529b\u3002"}}
{"id": "2602.01917", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01917", "abs": "https://arxiv.org/abs/2602.01917", "authors": ["Chengguang Gan", "Yoshihiro Tsujii", "Yunhao Liang", "Tatsunori Mori", "Shiwen Ni", "Hiroki Itoh"], "title": "GuideWeb: A Benchmark for Automatic In-App Guide Generation on Real-World Web UIs", "comment": null, "summary": "Digital Adoption Platform (DAP) provide web-based overlays that deliver operation guidance and contextual hints to help users navigate complex websites. Although modern DAP tools enable non-experts to author such guidance, maintaining these guides remains labor-intensive because website layouts and functionalities evolve continuously, which requires repeated manual updates and re-annotation. In this work, we introduce \\textbf{GuideWeb}, a new benchmark for automatic in-app guide generation on real-world web UIs. GuideWeb formulates the task as producing page-level guidance by selecting \\textbf{guide target elements} grounded in the webpage and generating concise guide text aligned with user intent. We also propose a comprehensive evaluation suite that jointly measures the accuracy of guide target element selection and the quality of generated intents and guide texts. Experiments show that our proposed \\textbf{GuideWeb Agent} achieves \\textbf{30.79\\%} accuracy in guide target element prediction, while obtaining BLEU scores of \\textbf{44.94} for intent generation and \\textbf{21.34} for guide-text generation. Existing baselines perform substantially worse, which highlights that automatic guide generation remains challenging and that further advances are necessary before such systems can be reliably deployed in real-world settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGuideWeb\u57fa\u51c6\u4e0eGuideWeb Agent\uff0c\u5b9e\u73b0\u7f51\u9875\u5185\u81ea\u52a8\u5f15\u5bfc\u751f\u6210\uff0c\u867d\u6709\u63d0\u5347\u4f46\u4ecd\u5177\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u91c7\u7eb3\u5e73\u53f0\u7684\u64cd\u4f5c\u6307\u5bfc\u7ef4\u62a4\u7e41\u7410\uff0c\u7f51\u9875\u5e03\u5c40\u53ca\u529f\u80fd\u53d8\u5316\u9891\u7e41\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u7684\u6307\u5bfc\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86GuideWeb\u57fa\u51c6\uff0c\u7ed3\u5408\u7f51\u9875\u5143\u7d20\u9009\u62e9\u53ca\u6587\u672c\u751f\u6210\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7efc\u5408\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5e76\u5f00\u53d1\u4e86GuideWeb Agent\u8fdb\u884c\u4efb\u52a1\u5b9e\u73b0\u3002", "result": "GuideWeb Agent\u5728\u5f15\u5bfc\u76ee\u6807\u5143\u7d20\u9009\u62e9\u51c6\u786e\u7387\u8fbe\u523030.79%\uff0c\u7528\u6237\u610f\u56fe\u751f\u6210BLEU\u5f97\u520644.94\uff0c\u5f15\u5bfc\u6587\u672c\u751f\u6210BLEU\u5f97\u520621.34\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002", "conclusion": "\u81ea\u52a8\u751f\u6210\u7f51\u9875\u5185\u6307\u5bfc\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\uff0c\u76ee\u524d\u7cfb\u7edf\u6027\u80fd\u6709\u9650\uff0c\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u5b9e\u73b0\u53ef\u9760\u90e8\u7f72\u3002"}}
{"id": "2602.01919", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01919", "abs": "https://arxiv.org/abs/2602.01919", "authors": ["Hend Al-Khalifa"], "title": "From Code-Centric to Concept-Centric: Teaching NLP with LLM-Assisted \"Vibe Coding\"", "comment": "Accepted in The Seventh Workshop on Teaching Natural Language Processing (Teaching NLP @ EACL2026)", "summary": "The rapid advancement of Large Language Models (LLMs) presents both challenges and opportunities for Natural Language Processing (NLP) education. This paper introduces ``Vibe Coding,'' a pedagogical approach that leverages LLMs as coding assistants while maintaining focus on conceptual understanding and critical thinking. We describe the implementation of this approach in a senior-level undergraduate NLP course, where students completed seven labs using LLMs for code generation while being assessed primarily on conceptual understanding through critical reflection questions. Analysis of end-of-course feedback from 19 students reveals high satisfaction (mean scores 4.4-4.6/5.0) across engagement, conceptual learning, and assessment fairness. Students particularly valued the reduced cognitive load from debugging, enabling deeper focus on NLP concepts. However, challenges emerged around time constraints, LLM output verification, and the need for clearer task specifications. Our findings suggest that when properly structured with mandatory prompt logging and reflection-based assessment, LLM-assisted learning can shift focus from syntactic fluency to conceptual mastery, preparing students for an AI-augmented professional landscape.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u5229\u7528LLMs\u8f85\u52a9\u7f16\u7801\u7684\u201cNLP\u6559\u80b2\u201d\u65b9\u6cd5\uff0c\u91cd\u89c6\u6982\u5ff5\u7406\u89e3\u548c\u6279\u5224\u6027\u601d\u7ef4\uff0c\u5b66\u751f\u53cd\u9988\u79ef\u6781\uff0c\u8868\u660e\u6b64\u65b9\u6cd5\u80fd\u6709\u6548\u652f\u6301\u6982\u5ff5\u638c\u63e1\uff0c\u51cf\u8f7b\u8c03\u8bd5\u8d1f\u62c5\u3002", "motivation": "LLMs\u7684\u5feb\u901f\u53d1\u5c55\u4e3aNLP\u6559\u80b2\u5e26\u6765\u4e86\u6311\u6218\u4e0e\u673a\u9047\uff0c\u5982\u4f55\u6709\u6548\u5229\u7528LLMs\u63d0\u5347\u6559\u5b66\u8d28\u91cf\u662f\u5173\u952e\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u5b9e\u65bd\u201cVibe Coding\u201d\u6559\u5b66\u65b9\u6cd5\uff0c\u5229\u7528LLMs\u8f85\u52a9\u4ee3\u7801\u751f\u6210\uff0c\u540c\u65f6\u901a\u8fc7\u53cd\u601d\u6027\u95ee\u9898\u8bc4\u4f30\u5b66\u751f\u7684\u6982\u5ff5\u7406\u89e3\u548c\u6279\u5224\u6027\u601d\u7ef4\uff0c\u5728\u9ad8\u7ea7\u672c\u79d1NLP\u8bfe\u7a0b\u4e2d\u5e94\u7528\u3002", "result": "\u5b66\u751f\u5bf9\u8be5\u65b9\u6cd5\u6ee1\u610f\u5ea6\u9ad8\uff08\u5e73\u57474.4-4.6/5\uff09\uff0c\u53c2\u4e0e\u5ea6\u3001\u6982\u5ff5\u5b66\u4e60\u548c\u8bc4\u4f30\u516c\u5e73\u6027\u5747\u83b7\u597d\u8bc4\uff0c\u964d\u4f4e\u8c03\u8bd5\u8ba4\u77e5\u8d1f\u62c5\uff0c\u6709\u5229\u4e8e\u52a0\u6df1\u5bf9NLP\u6982\u5ff5\u7684\u7406\u89e3\u3002", "conclusion": "\u7ed3\u6784\u5408\u7406\u4e14\u8981\u6c42\u5fc5\u987b\u8bb0\u5f55\u63d0\u793a\u548c\u53cd\u601d\u8bc4\u4f30\u7684LLM\u8f85\u52a9\u5b66\u4e60\u80fd\u591f\u5c06\u6559\u5b66\u91cd\u5fc3\u4ece\u8bed\u6cd5\u6d41\u5229\u5ea6\u8f6c\u5411\u6982\u5ff5\u638c\u63e1\uff0c\u5e2e\u52a9\u5b66\u751f\u4e3aAI\u589e\u5f3a\u7684\u804c\u4e1a\u73af\u5883\u505a\u597d\u51c6\u5907\u3002"}}
{"id": "2602.01965", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01965", "abs": "https://arxiv.org/abs/2602.01965", "authors": ["Kwun Hang Lau", "Fangyuan Zhang", "Boyu Ruan", "Yingli Zhou", "Qintian Guo", "Ruiyuan Zhang", "Xiaofang Zhou"], "title": "Breaking the Static Graph: Context-Aware Traversal for Robust Retrieval-Augmented Generation", "comment": null, "summary": "Recent advances in Retrieval-Augmented Generation (RAG) have shifted from simple vector similarity to structure-aware approaches like HippoRAG, which leverage Knowledge Graphs (KGs) and Personalized PageRank (PPR) to capture multi-hop dependencies. However, these methods suffer from a \"Static Graph Fallacy\": they rely on fixed transition probabilities determined during indexing. This rigidity ignores the query-dependent nature of edge relevance, causing semantic drift where random walks are diverted into high-degree \"hub\" nodes before reaching critical downstream evidence. Consequently, models often achieve high partial recall but fail to retrieve the complete evidence chain required for multi-hop queries. To address this, we propose CatRAG, Context-Aware Traversal for robust RAG, a framework that builds on the HippoRAG 2 architecture and transforms the static KG into a query-adaptive navigation structure. We introduce a multi-faceted framework to steer the random walk: (1) Symbolic Anchoring, which injects weak entity constraints to regularize the random walk; (2) Query-Aware Dynamic Edge Weighting, which dynamically modulates graph structure, to prune irrelevant paths while amplifying those aligned with the query's intent; and (3) Key-Fact Passage Weight Enhancement, a cost-efficient bias that structurally anchors the random walk to likely evidence. Experiments across four multi-hop benchmarks demonstrate that CatRAG consistently outperforms state of the art baselines. Our analysis reveals that while standard Recall metrics show modest gains, CatRAG achieves substantial improvements in reasoning completeness, the capacity to recover the entire evidence path without gaps. These results reveal that our approach effectively bridges the gap between retrieving partial context and enabling fully grounded reasoning. Resources are available at https://github.com/kwunhang/CatRAG.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCatRAG\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\uff0c\u4f7f\u5f97\u591a\u8df3\u68c0\u7d22\u80fd\u66f4\u51c6\u786e\u6355\u83b7\u5b8c\u6574\u8bc1\u636e\u94fe\uff0c\u63d0\u5347\u63a8\u7406\u7684\u5b8c\u6574\u6027\u548c\u6548\u679c\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u4f9d\u8d56\u9759\u6001\u56fe\u7d22\u5f15\uff0c\u5ffd\u7565\u67e5\u8be2\u4e0a\u4e0b\u6587\u5bf9\u8fb9\u6743\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u8def\u5f84\u504f\u79fb\u548c\u8bc1\u636e\u94fe\u4e0d\u5b8c\u6574\u3002", "method": "\u57fa\u4e8eHippoRAG 2\u67b6\u6784\uff0c\u63d0\u51fa\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u52a8\u6001\u56fe\u904d\u5386\u7b56\u7565\uff0c\u5305\u542b\u7b26\u53f7\u951a\u5b9a\u3001\u67e5\u8be2\u611f\u77e5\u52a8\u6001\u8fb9\u6743\u8c03\u6574\u53ca\u5173\u952e\u8bc1\u636e\u901a\u9053\u6743\u91cd\u589e\u5f3a\u4e09\u65b9\u9762\u673a\u5236\u3002", "result": "\u5728\u56db\u4e2a\u591a\u8df3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCatRAG\u8d85\u8d8a\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u5b8c\u6574\u6027\uff0c\u514b\u670d\u4e86\u4ec5\u90e8\u5206\u53ec\u56de\u7684\u9650\u5236\u3002", "conclusion": "CatRAG\u6709\u6548\u89e3\u51b3\u4e86\u9759\u6001\u56fe\u8c2c\u8bef\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8df3\u68c0\u7d22\u4e2d\u5b8c\u6574\u8bc1\u636e\u94fe\u7684\u6062\u590d\u80fd\u529b\uff0c\u5b9e\u73b0\u66f4\u52a0\u7cbe\u51c6\u7684\u63a8\u7406\u3002"}}
{"id": "2602.01967", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.01967", "abs": "https://arxiv.org/abs/2602.01967", "authors": ["Wonjun Lee", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Mixture-of-Experts with Intermediate CTC Supervision for Accented Speech Recognition", "comment": null, "summary": "Accented speech remains a persistent challenge for automatic speech recognition (ASR), as most models are trained on data dominated by a few high-resource English varieties, leading to substantial performance degradation for other accents. Accent-agnostic approaches improve robustness yet struggle with heavily accented or unseen varieties, while accent-specific methods rely on limited and often noisy labels. We introduce Moe-Ctc, a Mixture-of-Experts architecture with intermediate CTC supervision that jointly promotes expert specialization and generalization. During training, accent-aware routing encourages experts to capture accent-specific patterns, which gradually transitions to label-free routing for inference. Each expert is equipped with its own CTC head to align routing with transcription quality, and a routing-augmented loss further stabilizes optimization. Experiments on the Mcv-Accent benchmark demonstrate consistent gains across both seen and unseen accents in low- and high-resource conditions, achieving up to 29.3% relative WER reduction over strong FastConformer baselines.", "AI": {"tldr": "Moe-Ctc\u901a\u8fc7\u4e13\u5bb6\u6a21\u578b\u4e0e\u4e2d\u95f4CTC\u76d1\u7763\u63d0\u5347\u4e86ASR\u5bf9\u591a\u53e3\u97f3\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u8bcd\u9519\u8bef\u7387\u3002", "motivation": "\u5f53\u524dASR\u6a21\u578b\u5728\u5904\u7406\u975e\u4e3b\u6d41\u6216\u91cd\u53e3\u97f3\u8bed\u97f3\u65f6\u8868\u73b0\u5dee\uff0c\u4f20\u7edf\u7684\u53e3\u97f3\u65e0\u5173\u6216\u53e3\u97f3\u7279\u5b9a\u65b9\u6cd5\u5b58\u5728\u6027\u80fd\u6216\u6807\u6ce8\u6570\u636e\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u517c\u5177\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528Mixture-of-Experts\u67b6\u6784\u7ed3\u5408\u4e2d\u95f4CTC\u76d1\u7763\uff0c\u901a\u8fc7\u8bad\u7ec3\u9636\u6bb5\u7684\u53e3\u97f3\u610f\u8bc6\u8def\u7531\u548c\u63a8\u7406\u65f6\u7684\u65e0\u6807\u7b7e\u8def\u7531\uff0c\u4fc3\u8fdb\u4e13\u5bb6\u6a21\u578b\u4e13\u957f\u4e0e\u6cdb\u5316\u80fd\u529b\u3002\u6bcf\u4e2a\u4e13\u5bb6\u914d\u5907\u72ec\u7acbCTC\u5934\u5e76\u5f15\u5165\u8def\u7531\u589e\u5f3a\u635f\u5931\u4ee5\u7a33\u5b9a\u8bad\u7ec3\u3002", "result": "\u5728Mcv-Accent\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMoe-Ctc\u5728\u89c1\u8fc7\u548c\u672a\u89c1\u53e3\u97f3\u6761\u4ef6\u4e0b\u5747\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\uff0c\u6700\u9ad8\u76f8\u5bf9\u8bcd\u9519\u8bef\u7387\u964d\u4f4e29.3%\uff0c\u4f18\u4e8e\u5f3a\u57fa\u7ebfFastConformer\u3002", "conclusion": "Moe-Ctc\u6a21\u578b\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u4e2d\u5bf9\u4e0d\u540c\u53e3\u97f3\u7684\u9c81\u68d2\u6027\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8bcd\u9519\u8bef\u7387\u3002"}}
{"id": "2602.01969", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.01969", "abs": "https://arxiv.org/abs/2602.01969", "authors": ["Bin Cao", "Huixian Lu", "Chenwen Ma", "Ting Wang", "Ruizhe Li", "Jing Fan"], "title": "Orthogonal Hierarchical Decomposition for Structure-Aware Table Understanding with Large Language Models", "comment": "Work in process", "summary": "Complex tables with multi-level headers, merged cells and heterogeneous layouts pose persistent challenges for LLMs in both understanding and reasoning. Existing approaches typically rely on table linearization or normalized grid modeling. However, these representations struggle to explicitly capture hierarchical structures and cross-dimensional dependencies, which can lead to misalignment between structural semantics and textual representations for non-standard tables. To address this issue, we propose an Orthogonal Hierarchical Decomposition (OHD) framework that constructs structure-preserving input representations of complex tables for LLMs. OHD introduces an Orthogonal Tree Induction (OTI) method based on spatial--semantic co-constraints, which decomposes irregular tables into a column tree and a row tree to capture vertical and horizontal hierarchical dependencies, respectively. Building on this representation, we design a dual-pathway association protocol to symmetrically reconstruct semantic lineage of each cell, and incorporate an LLM as a semantic arbitrator to align multi-level semantic information. We evaluate OHD framework on two complex table question answering benchmarks, AITQA and HiTab. Experimental results show that OHD consistently outperforms existing representation paradigms across multiple evaluation metrics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u6b63\u4ea4\u5c42\u6b21\u5206\u89e3\u6846\u67b6\uff0c\u901a\u8fc7\u7a7a\u95f4\u8bed\u4e49\u7ea6\u675f\u5206\u89e3\u590d\u6742\u8868\u683c\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u590d\u6742\u8868\u683c\u95ee\u7b54\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5bf9\u590d\u6742\u8868\u683c\u7684\u8868\u793a\u65b9\u6cd5\u5982\u7ebf\u6027\u5316\u6216\u5f52\u4e00\u5316\u7f51\u683c\u96be\u4ee5\u663e\u5f0f\u6355\u6349\u8868\u683c\u7684\u5c42\u6b21\u7ed3\u6784\u548c\u8de8\u7ef4\u5ea6\u4f9d\u8d56\uff0c\u5bfc\u81f4\u7ed3\u6784\u8bed\u4e49\u4e0e\u6587\u672c\u8868\u793a\u4e4b\u95f4\u5b58\u5728\u9519\u914d\uff0c\u5f71\u54cdLLM\u7406\u89e3\u548c\u63a8\u7406\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u6b63\u4ea4\u5c42\u6b21\u5206\u89e3\uff08OHD\uff09\u6846\u67b6\uff0c\u91c7\u7528\u57fa\u4e8e\u7a7a\u95f4-\u8bed\u4e49\u7ea6\u675f\u7684\u6b63\u4ea4\u6811\u8bf1\u5bfc\uff08OTI\uff09\u65b9\u6cd5\uff0c\u5c06\u590d\u6742\u8868\u683c\u5206\u89e3\u4e3a\u5217\u6811\u548c\u884c\u6811\uff0c\u518d\u901a\u8fc7\u53cc\u8def\u5f84\u5173\u8054\u534f\u8bae\u5bf9\u6bcf\u4e2a\u5355\u5143\u683c\u7684\u8bed\u4e49\u8840\u7edf\u8fdb\u884c\u5bf9\u79f0\u91cd\u5efa\uff0c\u5e76\u7ed3\u5408LLM\u4f5c\u4e3a\u8bed\u4e49\u4ef2\u88c1\u5668\uff0c\u786e\u4fdd\u591a\u7ea7\u8bed\u4e49\u4fe1\u606f\u5bf9\u9f50\u3002", "result": "\u5728AITQA\u548cHiTab\u4e24\u4e2a\u590d\u6742\u8868\u683c\u95ee\u7b54\u57fa\u51c6\u4e0a\uff0cOHD\u6846\u67b6\u5728\u591a\u9879\u8bc4\u4f30\u6307\u6807\u4e2d\u5747\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u8868\u5f81\u8303\u5f0f\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u7ed3\u6784\u7406\u89e3\u80fd\u529b\u548c\u8bed\u4e49\u5bf9\u9f50\u6548\u679c\u3002", "conclusion": "\u63d0\u51fa\u7684OHD\u6846\u67b6\u901a\u8fc7\u6b63\u4ea4\u6811\u8bf1\u5bfc\u65b9\u6cd5\u6709\u6548\u6355\u6349\u4e86\u590d\u6742\u8868\u683c\u7684\u591a\u5c42\u6b21\u7ed3\u6784\u548c\u8de8\u7ef4\u5ea6\u4f9d\u8d56\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u8868\u683c\u7406\u89e3\u53ca\u63a8\u7406\u6027\u80fd\uff0c\u5728AITQA\u548cHiTab\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.01977", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01977", "abs": "https://arxiv.org/abs/2602.01977", "authors": ["Shuainan Liu", "Xuanang Chen", "Ben He", "Le Sun"], "title": "Beyond Local Edits: Embedding-Virtualized Knowledge for Broader Evaluation and Preservation of Model Editing", "comment": null, "summary": "Knowledge editing methods for large language models are commonly evaluated using predefined benchmarks that assess edited facts together with a limited set of related or neighboring knowledge. While effective, such evaluations remain confined to finite, dataset-bounded samples, leaving the broader impact of editing on the model's knowledge system insufficiently understood. To address this gap, we introduce Embedding-Virtualized Knowledge (EVK) that characterizes model knowledge through controlled perturbations in embedding space, enabling the exploration of a substantially broader and virtualized knowledge region beyond explicit data annotations. Based on EVK, we construct an embedding-level evaluation benchmark EVK-Bench that quantifies potential knowledge drift induced by editing, revealing effects that are not captured by conventional sample-based metrics. Furthermore, we propose a plug-and-play EVK-Align module that constrains embedding-level knowledge drift during editing and can be seamlessly integrated into existing editing methods. Experiments demonstrate that our approach enables more comprehensive evaluation while significantly improving knowledge preservation without sacrificing editing accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faEVK\u65b9\u6cd5\u901a\u8fc7\u5d4c\u5165\u7a7a\u95f4\u6270\u52a8\u62d3\u5c55\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u8303\u56f4\uff0c\u6784\u5efa\u4e86\u65b0\u57fa\u51c6\u5e76\u8bbe\u8ba1\u7ea6\u675f\u6a21\u5757\uff0c\u63d0\u5347\u4e86\u77e5\u8bc6\u4fdd\u6301\u80fd\u529b\u548c\u7f16\u8f91\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\u4ec5\u9650\u4e8e\u9884\u5b9a\u4e49\u57fa\u51c6\u548c\u6709\u9650\u7684\u6837\u672c\uff0c\u65e0\u6cd5\u5145\u5206\u7406\u89e3\u7f16\u8f91\u5bf9\u6a21\u578b\u6574\u4f53\u77e5\u8bc6\u7cfb\u7edf\u7684\u5f71\u54cd\u3002", "method": "\u63d0\u51faEmbedding-Virtualized Knowledge (EVK)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u8fdb\u884c\u53d7\u63a7\u6270\u52a8\u6765\u8868\u5f81\u6a21\u578b\u77e5\u8bc6\uff1b\u6784\u5efa\u57fa\u4e8eEVK\u7684\u8bc4\u4f30\u57fa\u51c6EVK-Bench\uff0c\u91cf\u5316\u7f16\u8f91\u5f15\u8d77\u7684\u6f5c\u5728\u77e5\u8bc6\u6f02\u79fb\uff1b\u8bbe\u8ba1EVK-Align\u6a21\u5757\uff0c\u7ea6\u675f\u5d4c\u5165\u5c42\u9762\u7684\u77e5\u8bc6\u6f02\u79fb\u5e76\u517c\u5bb9\u73b0\u6709\u7f16\u8f91\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u66f4\u5168\u9762\u7684\u77e5\u8bc6\u7f16\u8f91\u8bc4\u4f30\uff0c\u8fd8\u5728\u4fdd\u8bc1\u7f16\u8f91\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u7684\u4fdd\u6301\u6548\u679c\u3002", "conclusion": "\u57fa\u4e8eEVK\u7684\u65b9\u6cd5\u5f25\u8865\u4e86\u4f20\u7edf\u6837\u672c\u9650\u5b9a\u8bc4\u4f30\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u5bf9\u7f16\u8f91\u5f71\u54cd\u7684\u66f4\u5e7f\u6cdb\u63a2\u6d4b\u4e0e\u7ea6\u675f\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u7f16\u8f91\u7684\u53ef\u9760\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2602.01982", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01982", "abs": "https://arxiv.org/abs/2602.01982", "authors": ["Yanrui Du", "Sendong Zhao", "Yibo Gao", "Danyang Zhao", "Qika Lin", "Ming Ma", "Jiayun Li", "Yi Jiang", "Kai He", "Qianyi Xu", "Bing Qin", "Mengling Feng"], "title": "S3-CoT: Self-Sampled Succinct Reasoning Enables Efficient Chain-of-Thought LLMs", "comment": null, "summary": "Large language models (LLMs) equipped with chain-of-thought (CoT) achieve strong performance and offer a window into LLM behavior. However, recent evidence suggests that improvements in CoT capabilities often come with redundant reasoning processes, motivating a key question: Can LLMs acquire a fast-thinking mode analogous to human System 1 reasoning? To explore this, our study presents a self-sampling framework based on activation steering for efficient CoT learning. Our method can induce style-aligned and variable-length reasoning traces from target LLMs themselves without any teacher guidance, thereby alleviating a central bottleneck of SFT-based methods-the scarcity of high-quality supervision data. Using filtered data by gold answers, we perform SFT for efficient CoT learning with (i) a human-like dual-cognitive system, and (ii) a progressive compression curriculum. Furthermore, we explore a self-evolution regime in which SFT is driven solely by prediction-consistent data of variable-length variants, eliminating the need for gold answers. Extensive experiments on math benchmarks, together with cross-domain generalization tests in medicine, show that our method yields stable improvements for both general and R1-style LLMs. Our data and model checkpoints can be found at https://github.com/DYR1/S3-CoT.", "AI": {"tldr": "\u672c\u6587\u521b\u65b0\u6027\u63d0\u51fa\u4e86\u57fa\u4e8e\u6fc0\u6d3b\u5f15\u5bfc\u7684\u81ea\u91c7\u6837\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u6559\u5e08\u6570\u636e\u7684\u9ad8\u6548\u94fe\u5f0f\u601d\u7ef4\u8bad\u7ec3\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u94fe\u5f0f\u601d\u7ef4\u80fd\u529b\u63d0\u5347\u7684\u540c\u65f6\uff0c\u5b58\u5728\u5197\u4f59\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e9f\u9700\u5f15\u5165\u7c7b\u4f3c\u4eba\u7c7b\u5feb\u901f\u601d\u8003\u7684\u7cfb\u7edf1\u6a21\u5f0f\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6fc0\u6d3b\u5f15\u5bfc\u7684\u81ea\u91c7\u6837\u6846\u67b6\uff0c\u4ece\u76ee\u6807\u6a21\u578b\u4e2d\u65e0\u6559\u5e08\u6307\u5bfc\u5730\u4ea7\u751f\u98ce\u683c\u4e00\u81f4\u4e14\u957f\u5ea6\u53ef\u53d8\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u7ed3\u5408\u7b5b\u9009\u540e\u7684\u9ec4\u91d1\u7b54\u6848\u8fdb\u884c\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u8f85\u4ee5\u53cc\u8ba4\u77e5\u7cfb\u7edf\u548c\u9012\u8fdb\u538b\u7f29\u8bfe\u7a0b\u5b66\u4e60\uff0c\u8fdb\u4e00\u6b65\u63a2\u7d22\u65e0\u9700\u9ec4\u91d1\u7b54\u6848\u7684\u81ea\u6211\u8fdb\u5316\u8bad\u7ec3\u65b9\u6848\u3002", "result": "\u5728\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u548c\u533b\u5b66\u9886\u57df\u8de8\u57df\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u94fe\u5f0f\u601d\u7ef4\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u7a33\u5b9a\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65e0\u76d1\u7763\u81ea\u91c7\u6837\u4e0e\u8fdb\u5316\u8bad\u7ec3\u673a\u5236\u6709\u6548\u7f13\u89e3\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4eba\u5feb\u901f\u601d\u7ef4\u6a21\u5f0f\uff0c\u4fc3\u8fdb\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u94fe\u5f0f\u601d\u7ef4\u7684\u9ad8\u6548\u5b66\u4e60\u3002"}}
{"id": "2602.01999", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.01999", "abs": "https://arxiv.org/abs/2602.01999", "authors": ["Yanrui Du", "Yibo Gao", "Sendong Zhao", "Jiayun Li", "Haochun Wang", "Qika Lin", "Kai He", "Bing Qin", "Mengling Feng"], "title": "From Latent Signals to Reflection Behavior: Tracing Meta-Cognitive Activation Trajectory in R1-Style LLMs", "comment": null, "summary": "R1-style LLMs have attracted growing attention for their capacity for self-reflection, yet the internal mechanisms underlying such behavior remain unclear. To bridge this gap, we anchor on the onset of reflection behavior and trace its layer-wise activation trajectory. Using the logit lens to read out token-level semantics, we uncover a structured progression: (i) Latent-control layers, where an approximate linear direction encodes the semantics of thinking budget; (ii) Semantic-pivot layers, where discourse-level cues, including turning-point and summarization cues, surface and dominate the probability mass; and (iii) Behavior-overt layers, where the likelihood of reflection-behavior tokens begins to rise until they become highly likely to be sampled. Moreover, our targeted interventions uncover a causal chain across these stages: prompt-level semantics modulate the projection of activations along latent-control directions, thereby inducing competition between turning-point and summarization cues in semantic-pivot layers, which in turn regulates the sampling likelihood of reflection-behavior tokens in behavior-overt layers. Collectively, our findings suggest a human-like meta-cognitive process-progressing from latent monitoring, to discourse-level regulation, and to finally overt self-reflection. Our analysis code can be found at https://github.com/DYR1/S3-CoT.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c42\u7ea7\u6fc0\u6d3b\u8f68\u8ff9\u5206\u6790\u4e0e\u5e72\u9884\u5b9e\u9a8c\uff0c\u63ed\u793a\u4e86R1\u98ce\u683cLLMs\u81ea\u6211\u53cd\u601d\u7684\u5206\u5c42\u673a\u5236\uff0c\u7c7b\u4f3c\u4eba\u7c7b\u5143\u8ba4\u77e5\u8fc7\u7a0b\u3002", "motivation": "\u5c3d\u7ba1R1\u98ce\u683cLLMs\u8868\u73b0\u51fa\u81ea\u6211\u53cd\u601d\u80fd\u529b\uff0c\u4f46\u5176\u5b9e\u73b0\u673a\u5236\u5c1a\u4e0d\u6e05\u6670\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u8ba4\u77e5\u7a7a\u767d\u3002", "method": "\u4f7f\u7528logit lens\u6280\u672f\u5206\u5c42\u8bfb\u53d6token\u8bed\u4e49\uff0c\u8ffd\u8e2a\u53cd\u601d\u884c\u4e3a\u7684\u6fc0\u6d3b\u8f68\u8ff9\uff0c\u5e76\u5b9e\u65bd\u9488\u5bf9\u6027\u5e72\u9884\u4ee5\u9a8c\u8bc1\u4e0d\u540c\u5c42\u6b21\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u3002", "result": "\u53d1\u73b0\u53cd\u601d\u884c\u4e3a\u4ece\u6f5c\u5728\u76d1\u63a7\u5230\u8bdd\u8bed\u8c03\u63a7\u518d\u5230\u663e\u6027\u8868\u73b0\u7684\u5c42\u5c42\u9012\u8fdb\u7ed3\u6784\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5404\u9636\u6bb5\u95f4\u7684\u56e0\u679c\u94fe\u6761\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86R1\u98ce\u683c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u81ea\u6211\u53cd\u601d\u884c\u4e3a\u7684\u5185\u90e8\u673a\u5236\uff0c\u53d1\u73b0\u8be5\u8fc7\u7a0b\u5206\u4e3a\u6f5c\u5728\u63a7\u5236\u5c42\u3001\u8bed\u4e49\u67a2\u7ebd\u5c42\u548c\u884c\u4e3a\u5916\u663e\u5c42\u4e09\u7ea7\u8054\u52a8\u7ed3\u6784\uff0c\u5f62\u6210\u7c7b\u4f3c\u4eba\u7c7b\u5143\u8ba4\u77e5\u7684\u8fc7\u7a0b\u3002"}}
{"id": "2602.02007", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02007", "abs": "https://arxiv.org/abs/2602.02007", "authors": ["Zhanghao Hu", "Qinglin Zhu", "Hanqi Yan", "Yulan He", "Lin Gui"], "title": "Beyond RAG for Agent Memory: Retrieval by Decoupling and Aggregation", "comment": null, "summary": "Agent memory systems often adopt the standard Retrieval-Augmented Generation (RAG) pipeline, yet its underlying assumptions differ in this setting. RAG targets large, heterogeneous corpora where retrieved passages are diverse, whereas agent memory is a bounded, coherent dialogue stream with highly correlated spans that are often duplicates. Under this shift, fixed top-$k$ similarity retrieval tends to return redundant context, and post-hoc pruning can delete temporally linked prerequisites needed for correct reasoning. We argue retrieval should move beyond similarity matching and instead operate over latent components, following decoupling to aggregation: disentangle memories into semantic components, organise them into a hierarchy, and use this structure to drive retrieval. We propose xMemory, which builds a hierarchy of intact units and maintains a searchable yet faithful high-level node organisation via a sparsity--semantics objective that guides memory split and merge. At inference, xMemory retrieves top-down, selecting a compact, diverse set of themes and semantics for multi-fact queries, and expanding to episodes and raw messages only when it reduces the reader's uncertainty. Experiments on LoCoMo and PerLTQA across the three latest LLMs show consistent gains in answer quality and token efficiency.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u4f20\u7edfRAG\u65b9\u6cd5\u4e0d\u9002\u7528\u4e8e\u5bf9\u8bdd\u5f0f\u4ee3\u7406\u8bb0\u5fc6\uff0c\u63d0\u51faxMemory\u901a\u8fc7\u5206\u89e3\u8bed\u4e49\u7ec4\u4ef6\u5e76\u5c42\u6b21\u5316\u7ba1\u7406\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u51c6\u786e\u7684\u68c0\u7d22\uff0c\u63d0\u9ad8\u591a\u4e8b\u5b9e\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\u5047\u8bbe\u68c0\u7d22\u5185\u5bb9\u6765\u6e90\u4e8e\u5927\u89c4\u6a21\u3001\u5f02\u6784\u7684\u8bed\u6599\u5e93\uff0c\u9002\u7528\u4e8e\u591a\u6837\u4e14\u4e0d\u76f8\u5173\u7684\u6587\u672c\u6bb5\u843d\uff0c\u800c\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u4e2d\u7684\u5bf9\u8bdd\u6d41\u662f\u6709\u9650\u4e14\u9ad8\u5ea6\u76f8\u5173\u7684\uff0c\u5bfc\u81f4RAG\u5728\u6b64\u573a\u666f\u4e0b\u68c0\u7d22\u7ed3\u679c\u5b58\u5728\u5197\u4f59\u4e14\u53ef\u80fd\u5220\u9664\u5fc5\u8981\u524d\u63d0\u3002", "method": "\u63d0\u51faxMemory\u65b9\u6cd5\uff0c\u5c06\u8bb0\u5fc6\u5206\u89e3\u4e3a\u8bed\u4e49\u7ec4\u4ef6\uff0c\u6784\u5efa\u5c42\u6b21\u7ed3\u6784\uff0c\u5229\u7528\u7a00\u758f\u6027-\u8bed\u4e49\u76ee\u6807\u8fdb\u884c\u8bb0\u5fc6\u7684\u62c6\u5206\u548c\u5408\u5e76\uff0c\u5728\u63a8\u7406\u9636\u6bb5\u901a\u8fc7\u81ea\u4e0a\u800c\u4e0b\u7684\u68c0\u7d22\u7b56\u7565\u9009\u62e9\u7d27\u51d1\u4e14\u591a\u6837\u5316\u7684\u4e3b\u9898\u548c\u8bed\u4e49\uff0c\u4ec5\u5728\u51cf\u5c11\u9605\u8bfb\u8005\u4e0d\u786e\u5b9a\u6027\u65f6\u5c55\u5f00\u5177\u4f53\u60c5\u8282\u548c\u6d88\u606f\u3002", "result": "\u5728LoCoMo\u548cPerLTQA\u6570\u636e\u96c6\u4e0a\uff0cxMemory\u65b9\u6cd5\u5728\u6700\u65b0\u7684\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5747\u663e\u8457\u63d0\u5347\u4e86\u7b54\u6848\u8d28\u91cf\u548cToken\u4f7f\u7528\u6548\u7387\u3002", "conclusion": "\u9488\u5bf9\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u4e0e\u4f20\u7edfRAG\u573a\u666f\u7684\u5dee\u5f02\uff0cxMemory\u901a\u8fc7\u8bed\u4e49\u5206\u89e3\u548c\u5c42\u6b21\u5316\u7ed3\u6784\u91cd\u5851\u68c0\u7d22\u673a\u5236\uff0c\u6709\u6548\u63d0\u4f9b\u66f4\u7cbe\u51c6\u548c\u9ad8\u6548\u7684\u8bb0\u5fc6\u68c0\u7d22\uff0c\u63d0\u5347\u591a\u4e8b\u5b9e\u67e5\u8be2\u7684\u5e94\u7b54\u8868\u73b0\u3002"}}
{"id": "2602.02010", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02010", "abs": "https://arxiv.org/abs/2602.02010", "authors": ["Kang Liu", "Yongkang Liu", "Xiaocui Yang", "Peidong Wang", "Wen Zhang", "Shi Feng", "Yifei Zhang", "Daling Wang"], "title": "NEAT: Neuron-Based Early Exit for Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) often suffer from \\emph{overthinking}, a phenomenon in which redundant reasoning steps are generated after a correct solution has already been reached. Existing early reasoning exit methods primarily rely on output-level heuristics or trained probing models to skip redundant reasoning steps, thereby mitigating overthinking. However, these approaches typically require additional rollout computation or externally labeled datasets. In this paper, we propose \\textbf{NEAT}, a \\textbf{N}euron-based \\textbf{E}arly re\\textbf{A}soning exi\\textbf{T} framework that monitors neuron-level activation dynamics to enable training-free early exits, without introducing additional test-time computation. NEAT identifies exit-associated neurons and tracks their activation patterns during reasoning to dynamically trigger early exit or suppress reflection, thereby reducing unnecessary reasoning while preserving solution quality. Experiments on four reasoning benchmarks across six models with different scales and architectures show that, for each model, NEAT achieves an average token reduction of 22\\% to 28\\% when averaged over the four benchmarks, while maintaining accuracy.", "AI": {"tldr": "NEAT\u901a\u8fc7\u76d1\u63a7\u795e\u7ecf\u5143\u6fc0\u6d3b\u5b9e\u73b0\u8bad\u7ec3\u514d\u8d39\u3001\u4f4e\u6210\u672c\u7684\u65e9\u671f\u63a8\u7406\u9000\u51fa\uff0c\u6709\u6548\u51cf\u5c11\u8fc7\u5ea6\u601d\u8003\uff0c\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u65e9\u671f\u9000\u51fa\u65b9\u6cd5\u4f9d\u8d56\u8f93\u51fa\u7ea7\u542f\u53d1\u5f0f\u6216\u8bad\u7ec3\u7684\u63a2\u6d4b\u6a21\u578b\uff0c\u9700\u589e\u52a0\u8ba1\u7b97\u4ee3\u4ef7\u6216\u4f9d\u8d56\u5916\u90e8\u6807\u6ce8\uff0c\u8feb\u5207\u9700\u8981\u65e0\u989d\u5916\u8ba1\u7b97\u548c\u8bad\u7ec3\u7684\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u5143\u6fc0\u6d3b\u52a8\u6001\u76d1\u6d4b\u7684\u65e9\u671f\u63a8\u7406\u9000\u51fa\u6846\u67b6NEAT\uff0c\u901a\u8fc7\u8bc6\u522b\u4e0e\u9000\u51fa\u76f8\u5173\u7684\u795e\u7ecf\u5143\u5e76\u8ffd\u8e2a\u5176\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u5b9e\u73b0\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u548c\u8ba1\u7b97\u7684\u52a8\u6001\u65e9\u671f\u9000\u51fa\u3002", "result": "\u5728\u56db\u4e2a\u63a8\u7406\u57fa\u51c6\u548c\u516d\u4e2a\u4e0d\u540c\u89c4\u6a21\u53ca\u67b6\u6784\u7684\u6a21\u578b\u4e0a\uff0cNEAT\u5e73\u5747\u51cf\u5c1122%\u523028%\u7684\u63a8\u7406\u6b65\u9aa4\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u7387\u7a33\u5b9a\u3002", "conclusion": "NEAT\u65b9\u6cd5\u80fd\u591f\u5728\u4fdd\u8bc1\u89e3\u7b54\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e2d\u7684\u5197\u4f59\u63a8\u7406\u6b65\u9aa4\uff0c\u6709\u6548\u7f13\u89e3\u8fc7\u5ea6\u601d\u8003\u95ee\u9898\u3002"}}
{"id": "2602.02053", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02053", "abs": "https://arxiv.org/abs/2602.02053", "authors": ["Pengyu Wang", "Benfeng Xu", "Licheng Zhang", "Shaohan Wang", "Mingxuan Du", "Chiwei Zhu", "Zhendong Mao"], "title": "WildGraphBench: Benchmarking GraphRAG with Wild-Source Corpora", "comment": "https://github.com/BstWPY/WildGraphBench", "summary": "Graph-based Retrieval-Augmented Generation (GraphRAG) organizes external knowledge as a hierarchical graph, enabling efficient retrieval and aggregation of scattered evidence across multiple documents. However, many existing benchmarks for GraphRAG rely on short, curated passages as external knowledge, failing to adequately evaluate systems in realistic settings involving long contexts and large-scale heterogeneous documents. To bridge this gap, we introduce WildGraphBench, a benchmark designed to assess GraphRAG performance in the wild. We leverage Wikipedia's unique structure, where cohesive narratives are grounded in long and heterogeneous external reference documents, to construct a benchmark reflecting real-word scenarios. Specifically, we sample articles across 12 top-level topics, using their external references as the retrieval corpus and citation-linked statements as ground truth, resulting in 1,100 questions spanning three levels of complexity: single-fact QA, multi-fact QA, and section-level summarization. Experiments across multiple baselines reveal that current GraphRAG pipelines help on multi-fact aggregation when evidence comes from a moderate number of sources, but this aggregation paradigm may overemphasize high-level statements at the expense of fine-grained details, leading to weaker performance on summarization tasks. Project page:https://github.com/BstWPY/WildGraphBench.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1\u7ed3\u6784\u7684WildGraphBench\uff0c\u771f\u5b9e\u8bc4\u6d4bGraphRAG\u5728\u957f\u4e0a\u4e0b\u6587\u3001\u591a\u6765\u6e90\u6587\u6863\u4e0b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u591a\u4e8b\u5b9e\u805a\u5408\u6709\u6548\u4f46\u6458\u8981\u80fd\u529b\u6b20\u4f73\u3002", "motivation": "\u73b0\u6709\u7684GraphRAG\u8bc4\u6d4b\u591a\u6570\u57fa\u4e8e\u77ed\u6587\u672c\uff0c\u7f3a\u4e4f\u5bf9\u957f\u4e0a\u4e0b\u6587\u548c\u5927\u89c4\u6a21\u5f02\u6784\u6587\u6863\u6761\u4ef6\u4e0b\u7cfb\u7edf\u8868\u73b0\u7684\u8bc4\u4f30\uff0c\u96be\u4ee5\u53cd\u6620\u771f\u5b9e\u5e94\u7528\u573a\u666f\u3002", "method": "\u8bbe\u8ba1WildGraphBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528\u7ef4\u57fa\u767e\u79d1\u7684\u5c42\u7ea7\u7ed3\u6784\u548c\u957f\u5f02\u6784\u53c2\u8003\u6587\u6863\uff0c\u6784\u5efa\u5305\u542b12\u4e2a\u4e3b\u9898\u30011100\u4e2a\u95ee\u9898\uff0c\u6db5\u76d6\u5355\u4e8b\u5b9e\u95ee\u7b54\u3001\u591a\u4e8b\u5b9e\u95ee\u7b54\u53ca\u7ae0\u8282\u7ea7\u6458\u8981\u7684\u591a\u5c42\u6b21\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u73b0\u6709\u7684GraphRAG\u65b9\u6cd5\u5728\u4e2d\u7b49\u6570\u91cf\u6765\u6e90\u7684\u591a\u4e8b\u5b9e\u805a\u5408\u4e0a\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5bf9\u7ec6\u7c92\u5ea6\u4fe1\u606f\u7684\u603b\u7ed3\u80fd\u529b\u8f83\u5f31\uff0c\u5728\u7ae0\u8282\u6458\u8981\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0d\u8db3\u3002", "conclusion": "WildGraphBench\u6709\u6548\u8bc4\u4f30GraphRAG\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5176\u5728\u7ec6\u8282\u4fe1\u606f\u805a\u5408\u548c\u6458\u8981\u65b9\u9762\u7684\u4e0d\u8db3\uff0c\u63d0\u793a\u672a\u6765\u9700\u6539\u8fdb\u7ec6\u7c92\u5ea6\u4fe1\u606f\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2602.02090", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02090", "abs": "https://arxiv.org/abs/2602.02090", "authors": ["Yikai Zeng", "Yingchao Piao", "Jianhui Li"], "title": "LEC-KG: An LLM-Embedding Collaborative Framework for Domain-Specific Knowledge Graph Construction -- A Case Study on SDGs", "comment": null, "summary": "Constructing domain-specific knowledge graphs from unstructured text remains challenging due to heterogeneous entity mentions, long-tail relation distributions, and the absence of standardized schemas. We present LEC-KG, a bidirectional collaborative framework that integrates the semantic understanding of Large Language Models (LLMs) with the structural reasoning of Knowledge Graph Embeddings (KGE). Our approach features three key components: (1) hierarchical coarse-to-fine relation extraction that mitigates long-tail bias, (2) evidence-guided Chain-of-Thought feedback that grounds structural suggestions in source text, and (3) semantic initialization that enables structural validation for unseen entities. The two modules enhance each other iteratively-KGE provides structure-aware feedback to refine LLM extractions, while validated triples progressively improve KGE representations. We evaluate LEC-KG on Chinese Sustainable Development Goal (SDG) reports, demonstrating substantial improvements over LLM baselines, particularly on low-frequency relations. Through iterative refinement, our framework reliably transforms unstructured policy text into validated knowledge graph triples.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLEC-KG\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\uff0c\u5b9e\u73b0\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u4e2d\u9ad8\u6548\u62bd\u53d6\u3001\u9a8c\u8bc1\u548c\u4f18\u5316\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\uff0c\u63d0\u5347\u4e86\u4f4e\u9891\u5173\u7cfb\u8bc6\u522b\u51c6\u786e\u5ea6\u3002", "motivation": "\u5f53\u524d\u4ece\u975e\u7ed3\u6784\u5316\u6587\u672c\u6784\u5efa\u9886\u57df\u77e5\u8bc6\u56fe\u8c31\u9762\u4e34\u5f02\u6784\u5b9e\u4f53\u3001\u591a\u6837\u5316\u957f\u5c3e\u5173\u7cfb\u548c\u7f3a\u4e4f\u7edf\u4e00\u6a21\u5f0f\u7684\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7ed3\u5408\u8bed\u4e49\u7406\u89e3\u4e0e\u7ed3\u6784\u63a8\u7406\u7684\u534f\u540c\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u5411\u534f\u540c\u6846\u67b6LEC-KG\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u548c\u77e5\u8bc6\u56fe\u8c31\u5d4c\u5165\u7684\u7ed3\u6784\u63a8\u7406\uff0c\u5305\u542b\u5206\u5c42\u7c97\u5230\u7ec6\u7684\u5173\u7cfb\u62bd\u53d6\u3001\u57fa\u4e8e\u8bc1\u636e\u7684\u94fe\u5f0f\u53cd\u9988\u4ee5\u53ca\u8bed\u4e49\u521d\u59cb\u5316\u4e09\u5927\u6838\u5fc3\u7ec4\u4ef6\u3002", "result": "\u5728\u4e2d\u6587\u53ef\u6301\u7eed\u53d1\u5c55\u76ee\u6807\u62a5\u544a\u6570\u636e\u96c6\u4e0a\uff0cLEC-KG\u663e\u8457\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u4f4e\u9891\u5173\u7cfb\u7684\u62bd\u53d6\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u5b9e\u73b0\u4e86\u975e\u7ed3\u6784\u5316\u653f\u7b56\u6587\u672c\u5411\u9a8c\u8bc1\u56fe\u8c31\u4e09\u5143\u7ec4\u7684\u53ef\u9760\u8f6c\u5316\u3002", "conclusion": "LEC-KG\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6784\u5efa\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u5f02\u6784\u5b9e\u4f53\u8868\u8fbe\u3001\u957f\u5c3e\u5173\u7cfb\u5206\u5e03\u548c\u7f3a\u4e4f\u6807\u51c6\u5316\u6a21\u5f0f\u7b49\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u548c\u8bed\u4e49\u7684\u53cc\u5411\u534f\u540c\u63d0\u5347\u3002"}}
{"id": "2602.02099", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02099", "abs": "https://arxiv.org/abs/2602.02099", "authors": ["Keqin Peng", "Yuanxin Ouyang", "Xuebo Liu", "Zhiliang Tian", "Ruijian Han", "Yancheng Yuan", "Liang Ding"], "title": "Think Dense, Not Long: Dynamic Decoupled Conditional Advantage for Efficient Reasoning", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) can elicit strong multi-step reasoning, yet it often encourages overly verbose traces. Moreover, naive length penalties in group-relative optimization can severely hurt accuracy. We attribute this failure to two structural issues: (i) Dilution of Length Baseline, where incorrect responses (with zero length reward) depress the group baseline and over-penalize correct solutions; and (ii) Difficulty-Penalty Mismatch, where a static penalty cannot adapt to problem difficulty, suppressing necessary reasoning on hard instances while leaving redundancy on easy ones. We propose Dynamic Decoupled Conditional Advantage (DDCA) to decouple efficiency optimization from correctness. DDCA computes length advantages conditionally within the correct-response cluster to eliminate baseline dilution, and dynamically scales the penalty strength using the group pass rate as a proxy for difficulty. Experiments on GSM8K, MATH500, AMC23, and AIME25 show that DDCA consistently improves the efficiency--accuracy trade-off relative to adaptive baselines, reducing generated tokens by approximately 60% on simpler tasks (e.g., GSM8K) versus over 20% on harder benchmarks (e.g., AIME25), thereby maintaining or improving accuracy. Code is available at https://github.com/alphadl/DDCA.", "AI": {"tldr": "DDCA\u901a\u8fc7\u52a8\u6001\u8c03\u8282\u957f\u5ea6\u60e9\u7f5a\uff0c\u89e3\u51b3\u4e86\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u4e2d\u5e8f\u5217\u5197\u957f\u548c\u51c6\u786e\u7387\u4e0b\u964d\u7684\u96be\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6548\u7387\u548c\u51c6\u786e\u7387\u5e73\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u901a\u8fc7\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u5728\u9f13\u52b1\u591a\u6b65\u9aa4\u63a8\u7406\u65f6\u751f\u6210\u8fc7\u4e8e\u5197\u957f\u7684\u8f68\u8ff9\uff0c\u4e14\u7b80\u5355\u7684\u957f\u5ea6\u60e9\u7f5a\u4f1a\u56e0\u57fa\u7ebf\u7a00\u91ca\u53ca\u96be\u5ea6\u4e0e\u60e9\u7f5a\u4e0d\u5339\u914d\u95ee\u9898\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u89e3\u8026\u6761\u4ef6\u4f18\u52bf\uff08DDCA\uff09\u65b9\u6cd5\uff0c\u5c06\u6548\u7387\u4f18\u5316\u4e0e\u6b63\u786e\u6027\u5206\u79bb\uff0c\u6761\u4ef6\u8ba1\u7b97\u6b63\u786e\u54cd\u5e94\u7c7b\u7fa4\u5185\u7684\u957f\u5ea6\u4f18\u52bf\uff0c\u5e76\u5229\u7528\u7ec4\u901a\u8fc7\u7387\u52a8\u6001\u8c03\u6574\u60e9\u7f5a\u529b\u5ea6\u3002", "result": "\u5728\u591a\u9879\u57fa\u51c6\u4efb\u52a1\uff08GSM8K\u3001MATH500\u3001AMC23\u3001AIME25\uff09\u4e0a\uff0cDDCA\u663e\u8457\u51cf\u5c11\u4e86\u751f\u6210\u7684Token\u6570\u91cf\uff08\u7b80\u5355\u4efb\u52a1\u7ea6\u51cf\u5c1160%\uff0c\u56f0\u96be\u4efb\u52a1\u8d85\u8fc720%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002", "conclusion": "DDCA\u65b9\u6cd5\u901a\u8fc7\u6d88\u9664\u57fa\u7ebf\u7a00\u91ca\u5e76\u6839\u636e\u95ee\u9898\u96be\u5ea6\u52a8\u6001\u8c03\u6574\u60e9\u7f5a\u5f3a\u5ea6\uff0c\u6709\u6548\u6539\u5584\u4e86\u591a\u6b65\u9aa4\u63a8\u7406\u8fc7\u7a0b\u4e2d\u751f\u6210\u5e8f\u5217\u7684\u5197\u957f\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6548\u7387\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u3002"}}
{"id": "2602.02104", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02104", "abs": "https://arxiv.org/abs/2602.02104", "authors": ["Shaltiel Shmidman", "Avi Shmidman", "Amir DN Cohen", "Moshe Koppel"], "title": "Dicta-LM 3.0: Advancing The Frontier of Hebrew Sovereign LLMs", "comment": null, "summary": "Open-weight LLMs have been released by frontier labs; however, sovereign Large Language Models (for languages other than English) remain low in supply yet high in demand. Training large language models (LLMs) for low-resource languages such as Hebrew poses unique challenges. In this paper, we introduce Dicta-LM 3.0: an open-weight collection of LLMs trained on substantially-sized corpora of Hebrew and English texts. The model is released in three sizes: 24B - adapted from the Mistral-Small-3.1 base model, 12B - adapted from the NVIDIA Nemotron Nano V2 model, and 1.7B - adapted from the Qwen3-1.7B base model. We are releasing multiple variants of each model, each with a native context length of 65k tokens; base model and chat model with tool-calling support. To rigorously evaluate our models, we introduce a new benchmark suite for evaluation of Hebrew chat-LLMs, covering a diverse set of tasks including Translation, Summarization, Winograd, Israeli Trivia, and Diacritization (nikud). Our work not only addresses the intricacies of training LLMs in low-resource languages but also proposes a framework that can be leveraged for adapting other LLMs to various non-English languages, contributing to the broader field of multilingual NLP.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63a8\u51fa\u4e86\u9762\u5411\u5e0c\u4f2f\u6765\u8bed\u7684\u591a\u4e2a\u89c4\u6a21\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578bDicta-LM 3.0\uff0c\u5e76\u5f00\u53d1\u4e86\u591a\u4efb\u52a1\u8bc4\u6d4b\u5957\u4ef6\uff0c\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00LLM\u8bad\u7ec3\u96be\u9898\uff0c\u63d0\u4f9b\u4e86\u591a\u8bed\u8a00\u9002\u914d\u6846\u67b6\u3002", "motivation": "\u867d\u7136\u5f00\u653e\u6743\u91cd\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5df2\u7ecf\u53d1\u5e03\uff0c\u4f46\u9488\u5bf9\u975e\u82f1\u8bed\u7684\u4e3b\u6743LLM\u4f9b\u5e94\u4e0d\u8db3\u4e14\u9700\u6c42\u65fa\u76db\uff0c\u5c24\u5176\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u5e0c\u4f2f\u6765\u8bed\u8bad\u7ec3\u9762\u4e34\u6311\u6218\u3002", "method": "\u91c7\u7528\u591a\u79cd\u57fa\u7840\u6a21\u578b\uff08Mistral-Small-3.1\u3001NVIDIA Nemotron Nano V2\u3001Qwen3-1.7B\uff09\u8fdb\u884c\u9002\u914d\u8bad\u7ec3\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u5e0c\u4f2f\u6765\u8bed\u548c\u82f1\u8bed\u8bed\u6599\uff0c\u8bbe\u8ba1\u591a\u7248\u672c\u6a21\u578b\u5e76\u652f\u6301\u957f\u4e0a\u4e0b\u6587\u548c\u5de5\u5177\u8c03\u7528\u3002", "result": "\u53d1\u5e03\u4e86\u4e09\u4e2a\u89c4\u6a21\u7684Dicta-LM 3.0\u6a21\u578b\uff0824B\u300112B\u30011.7B\uff09\uff0c\u5e76\u6784\u5efa\u4e86\u4e13\u7528\u4e8e\u5e0c\u4f2f\u6765\u8bed\u804a\u5929\u6a21\u578b\u7684\u65b0\u8bc4\u6d4b\u5957\u4ef6\uff0c\u6db5\u76d6\u7ffb\u8bd1\u3001\u6458\u8981\u3001Winograd\u3001\u4ee5\u8272\u5217\u77e5\u8bc6\u548c\u5143\u97f3\u6807\u6ce8\u4efb\u52a1\u3002", "conclusion": "\u672c\u8bba\u6587\u6210\u529f\u8bad\u7ec3\u5e76\u53d1\u5e03\u4e86\u9488\u5bf9\u5e0c\u4f2f\u6765\u8bed\u548c\u82f1\u8bed\u7684\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578bDicta-LM 3.0\uff0c\u6db5\u76d6\u4e0d\u540c\u89c4\u6a21\u548c\u591a\u6837\u5316\u5e94\u7528\uff0c\u5f25\u8865\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00LLM\u7684\u7a7a\u767d\u3002"}}
{"id": "2602.02108", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02108", "abs": "https://arxiv.org/abs/2602.02108", "authors": ["Wenhao Li", "Daohai Yu", "Gen Luo", "Yuxin Zhang", "Fei Chao", "Rongrong Ji", "Yifan Wu", "Jiaxin Liu", "Ziyang Gong", "Zimu Liao"], "title": "Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts", "comment": null, "summary": "Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We introduce OOMB, a highly memory-efficient training system that directly confronts this barrier. Our approach employs a chunk-recurrent training framework with on-the-fly activation recomputation, which maintains a constant activation memory footprint (O(1)) and shifts the primary bottleneck to the growing KV cache. To manage the KV cache, OOMB integrates a suite of synergistic optimizations: a paged memory manager for both the KV cache and its gradients to eliminate fragmentation, asynchronous CPU offloading to hide data transfer latency, and page-level sparse attention to reduce both computational complexity and communication overhead. The synergy of these techniques yields exceptional efficiency. Our empirical results show that for every additional 10K tokens of context, the end-to-end training memory overhead increases by a mere 10MB for Qwen2.5-7B. This allows training Qwen2.5-7B with a 4M-token context on a single H200 GPU, a feat that would otherwise require a large cluster using context parallelism. This work represents a substantial advance in resource efficiency for long-context LLM training. The source code is available at https://github.com/wenhaoli-xmu/OOMB.", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u8bbe\u8ba1OOMB\u7cfb\u7edf\uff0c\u91c7\u7528\u6fc0\u6d3b\u91cd\u8ba1\u7b97\u4e0e\u9ad8\u6548\u5185\u5b58\u7ba1\u7406\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u7684\u663e\u5b58\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u5355\u5361\u4e0a\u767e\u4e07token\u4e0a\u4e0b\u6587\u8bad\u7ec3\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u8bad\u7ec3\u56e0\u6fc0\u6d3b\u5185\u5b58\u7ebf\u6027\u589e\u957f\u5bfc\u81f4\u663e\u5b58\u74f6\u9888\uff0c\u9650\u5236\u4e86\u8bad\u7ec3\u957f\u5e8f\u5217\u7684\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u4e86\u5206\u5757\u9012\u5f52\u8bad\u7ec3\u6846\u67b6\u7ed3\u5408\u5373\u65f6\u6fc0\u6d3b\u91cd\u8ba1\u7b97\uff0c\u914d\u5408\u5206\u9875\u5185\u5b58\u7ba1\u7406\u3001\u5f02\u6b65CPU\u5378\u8f7d\u53ca\u9875\u7ea7\u7a00\u758f\u6ce8\u610f\u529b\u7b49\u591a\u79cd\u4f18\u5316\u6280\u672f\u7ba1\u7406KV\u7f13\u5b58\u3002", "result": "Qwen2.5-7B\u6a21\u578b\u8bad\u7ec3\u6bcf\u589e\u52a01\u4e07tokens\u4e0a\u4e0b\u6587\uff0c\u663e\u5b58\u4ec5\u591a\u5360\u752810MB\uff0c\u5b9e\u73b04\u767e\u4e07token\u4e0a\u4e0b\u6587\u5728\u5355\u4e2aH200 GPU\u4e0a\u8bad\u7ec3\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684OOMB\u8bad\u7ec3\u7cfb\u7edf\u663e\u8457\u964d\u4f4e\u4e86\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u663e\u5b58\u5f00\u9500\uff0c\u5b9e\u73b0\u4e86\u6fc0\u6d3b\u5185\u5b58\u5360\u7528\u5e38\u6570\u589e\u957f\uff0c\u4ece\u800c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u5185\u5b58\u74f6\u9888\u3002"}}
{"id": "2602.02132", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02132", "abs": "https://arxiv.org/abs/2602.02132", "authors": ["Faaiz Joad", "Majd Hawasly", "Sabri Boughorbel", "Nadir Durrani", "Husrev Taha Sencar"], "title": "There Is More to Refusal in Large Language Models than a Single Direction", "comment": null, "summary": "Prior work argues that refusal in large language models is mediated by a single activation-space direction, enabling effective steering and ablation. We show that this account is incomplete. Across eleven categories of refusal and non-compliance, including safety, incomplete or unsupported requests, anthropomorphization, and over-refusal, we find that these refusal behaviors correspond to geometrically distinct directions in activation space. Yet despite this diversity, linear steering along any refusal-related direction produces nearly identical refusal to over-refusal trade-offs, acting as a shared one-dimensional control knob. The primary effect of different directions is not whether the model refuses, but how it refuses.", "AI": {"tldr": "\u62d2\u7edd\u884c\u4e3a\u5728\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u5bf9\u5e94\u591a\u79cd\u6fc0\u6d3b\u7a7a\u95f4\u65b9\u5411\uff0c\u4e0d\u540c\u65b9\u5411\u5f71\u54cd\u62d2\u7edd\u65b9\u5f0f\uff0c\u7ebf\u6027\u64cd\u63a7\u53ef\u7edf\u4e00\u8c03\u8282\u62d2\u7edd\u7a0b\u5ea6\u3002", "motivation": "\u5148\u524d\u7814\u7a76\u8ba4\u4e3a\u62d2\u7edd\u884c\u4e3a\u7531\u5355\u4e00\u6fc0\u6d3b\u65b9\u5411\u4e2d\u4ecb\uff0c\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e00\u89c2\u70b9\u7684\u5c40\u9650\u6027\u3002", "method": "\u7814\u7a76\u4e86\u5341\u4e00\u7c7b\u62d2\u7edd\u548c\u4e0d\u670d\u4ece\u60c5\u51b5\uff0c\u5728\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5206\u6790\u5b83\u4eec\u5bf9\u5e94\u7684\u51e0\u4f55\u65b9\u5411\u548c\u7ebf\u6027\u64cd\u63a7\u6548\u679c\u3002", "result": "\u53d1\u73b0\u62d2\u7edd\u884c\u4e3a\u5bf9\u5e94\u591a\u4e2a\u4e0d\u540c\u51e0\u4f55\u65b9\u5411\uff0c\u5c3d\u7ba1\u591a\u6837\uff0c\u6cbf\u4efb\u4f55\u62d2\u7edd\u76f8\u5173\u65b9\u5411\u7684\u7ebf\u6027\u64cd\u63a7\u90fd\u4f1a\u4ea7\u751f\u7c7b\u4f3c\u7684\u62d2\u7edd-\u8fc7\u5ea6\u62d2\u7edd\u6743\u8861\u3002", "conclusion": "\u62d2\u7edd\u884c\u4e3a\u5728\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u5bf9\u5e94\u4e0d\u540c\u7684\u51e0\u4f55\u65b9\u5411\uff0c\u4e0d\u540c\u65b9\u5411\u51b3\u5b9a\u62d2\u7edd\u7684\u65b9\u5f0f\u800c\u975e\u662f\u5426\u62d2\u7edd\u3002"}}
{"id": "2602.02140", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02140", "abs": "https://arxiv.org/abs/2602.02140", "authors": ["Chenlong Wang", "Yuhang Chen", "Zhihan Hu", "Dongping Chen", "Wenhu Chen", "Sarah Wiegreffe", "Tianyi Zhou"], "title": "Quantifying the Gap between Understanding and Generation within Unified Multimodal Models", "comment": null, "summary": "Recent advances in unified multimodal models (UMM) have demonstrated remarkable progress in both understanding and generation tasks. However, whether these two capabilities are genuinely aligned and integrated within a single model remains unclear. To investigate this question, we introduce GapEval, a bidirectional benchmark designed to quantify the gap between understanding and generation capabilities, and quantitatively measure the cognitive coherence of the two \"unified\" directions. Each question can be answered in both modalities (image and text), enabling a symmetric evaluation of a model's bidirectional inference capability and cross-modal consistency. Experiments reveal a persistent gap between the two directions across a wide range of UMMs with different architectures, suggesting that current models achieve only surface-level unification rather than deep cognitive convergence of the two. To further explore the underlying mechanism, we conduct an empirical study from the perspective of knowledge manipulation to illustrate the underlying limitations. Our findings indicate that knowledge within UMMs often remains disjoint. The capability emergence and knowledge across modalities are unsynchronized, paving the way for further exploration.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7GapEval\u57fa\u51c6\u8bc4\u4f30\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u7684\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\uff0c\u53d1\u73b0\u4e24\u8005\u5b58\u5728\u8ba4\u77e5\u5dee\u8ddd\uff0c\u77e5\u8bc6\u5c1a\u672a\u6df1\u5ea6\u878d\u5408\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u74f6\u9888\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u7a76\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u7684\u7406\u89e3\u80fd\u529b\u4e0e\u751f\u6210\u80fd\u529b\u662f\u5426\u771f\u6b63\u6574\u5408\u548c\u534f\u540c\uff0c\u63ed\u793a\u4e24\u8005\u4e4b\u95f4\u7684\u5185\u5728\u8054\u7cfb\u548c\u5dee\u8ddd\u3002", "method": "\u63d0\u51fa\u4e86GapEval\u57fa\u51c6\uff0c\u901a\u8fc7\u53cc\u5411\uff08\u56fe\u50cf\u4e0e\u6587\u672c\uff09\u6d4b\u8bd5\uff0c\u91cf\u5316\u7406\u89e3\u4e0e\u751f\u6210\u80fd\u529b\u5dee\u8ddd\uff0c\u8bc4\u4f30\u6a21\u578b\u7684\u53cc\u5411\u63a8\u7406\u80fd\u529b\u548c\u8de8\u6a21\u6001\u4e00\u81f4\u6027\uff0c\u540c\u65f6\u8fdb\u884c\u77e5\u8bc6\u64cd\u4f5c\u89c6\u89d2\u7684\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u591a\u79cd\u67b6\u6784\u7684\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u5728\u7406\u89e3\u548c\u751f\u6210\u4e4b\u95f4\u5b58\u5728\u6301\u7eed\u5dee\u8ddd\uff0c\u4e14\u77e5\u8bc6\u8de8\u6a21\u6001\u4e0d\u8fde\u8d2f\uff0c\u80fd\u529b\u51fa\u73b0\u4e0d\u540c\u6b65\u3002", "conclusion": "\u5f53\u524d\u7edf\u4e00\u591a\u6a21\u6001\u6a21\u578b\u5728\u7406\u89e3\u548c\u751f\u6210\u4e24\u79cd\u80fd\u529b\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u6a21\u578b\u66f4\u591a\u5b9e\u73b0\u7684\u662f\u8868\u9762\u7ea7\u7edf\u4e00\uff0c\u800c\u975e\u6df1\u5c42\u6b21\u7684\u8ba4\u77e5\u878d\u5408\u3002"}}
{"id": "2602.02159", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02159", "abs": "https://arxiv.org/abs/2602.02159", "authors": ["Lingkun Long", "Yushi Huang", "Shihao Bai", "Ruihao Gong", "Jun Zhang", "Ao Zhou", "Jianlei Yang"], "title": "Focus-dLLM: Accelerating Long-Context Diffusion LLM Inference via Confidence-Guided Context Focusing", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) deliver strong long-context processing capability in a non-autoregressive decoding paradigm. However, the considerable computational cost of bidirectional full attention limits the inference efficiency. Although sparse attention is promising, existing methods remain ineffective. This stems from the need to estimate attention importance for tokens yet to be decoded, while the unmasked token positions are unknown during diffusion. In this paper, we present Focus-dLLM, a novel training-free attention sparsification framework tailored for accurate and efficient long-context dLLM inference. Based on the finding that token confidence strongly correlates across adjacent steps, we first design a past confidence-guided indicator to predict unmasked regions. Built upon this, we propose a sink-aware pruning strategy to accurately estimate and remove redundant attention computation, while preserving highly influential attention sinks. To further reduce overhead, this strategy reuses identified sink locations across layers, leveraging the observed cross-layer consistency. Experimental results show that our method offers more than $29\\times$ lossless speedup under $32K$ context length. The code is publicly available at: https://github.com/Longxmas/Focus-dLLM", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFocus-dLLM\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u548c\u6c47\u70b9\u611f\u77e5\u526a\u679d\uff0c\u5b9e\u73b0\u6269\u6563\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u768429\u500d\u52a0\u901f\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u867d\u7136\u6027\u80fd\u5f3a\uff0c\u4f46\u7531\u4e8e\u53cc\u5411\u5168\u6ce8\u610f\u529b\u7684\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u63a8\u7406\u6548\u7387\u4f4e\u4e0b\u3002\u73b0\u6709\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u5728\u6269\u6563\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u51c6\u786e\u4f30\u8ba1\u672a\u89e3\u7801\u6807\u8bb0\u7684\u91cd\u8981\u6027\u3002", "method": "\u63d0\u51fa\u4e86Focus-dLLM\uff0c\u4e00\u79cd\u514d\u8bad\u7ec3\u7684\u6ce8\u610f\u529b\u7a00\u758f\u6846\u67b6\u3002\u901a\u8fc7\u57fa\u4e8e\u76f8\u90bb\u6b65\u9aa4\u7684\u6807\u8bb0\u7f6e\u4fe1\u5ea6\u8bbe\u8ba1\u4e86\u8fc7\u53bb\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u6307\u6807\u6765\u9884\u6d4b\u672a\u906e\u853d\u533a\u57df\uff0c\u5e76\u63d0\u51fa\u4e86\u8003\u8651\u6ce8\u610f\u529b\u6c47\u70b9\u7684\u526a\u679d\u7b56\u7565\u4ee5\u53bb\u9664\u5197\u4f59\u8ba1\u7b97\uff0c\u540c\u65f6\u4fdd\u6301\u91cd\u8981\u6ce8\u610f\u529b\u6c47\u70b9\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u8de8\u5c42\u91cd\u7528\u6c47\u70b9\u4f4d\u7f6e\u8fdb\u4e00\u6b65\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u572832K\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e0b\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u8d85\u8fc729\u500d\u7684\u65e0\u635f\u52a0\u901f\u3002", "conclusion": "Focus-dLLM\u6709\u6548\u63d0\u5347\u4e86\u6269\u6563\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u8ba1\u7b97\u6548\u7387\uff0c\u663e\u8457\u52a0\u901f\u63a8\u7406\u8fc7\u7a0b\uff0c\u4e14\u4e0d\u4f1a\u635f\u5931\u6027\u80fd\u3002"}}
{"id": "2602.02160", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02160", "abs": "https://arxiv.org/abs/2602.02160", "authors": ["Bowen Xu", "Shaoyu Wu", "Hao Jiang", "Kai Liu", "Xin Chen", "Lulu Hu", "Bin Yang"], "title": "D-CORE: Incentivizing Task Decomposition in Large Reasoning Models for Complex Tool Use", "comment": null, "summary": "Effective tool use and reasoning are essential capabilities for large reasoning models~(LRMs) to address complex real-world problems. Through empirical analysis, we identify that current LRMs lack the capability of sub-task decomposition in complex tool use scenarios, leading to Lazy Reasoning. To address this, we propose a two-stage training framework D-CORE~(\\underline{\\textbf{D}}ecomposing tasks and \\underline{\\textbf{Co}}mposing \\underline{\\textbf{Re}}asoning processes) that first incentivize the LRMs' task decomposition reasoning capability via self-distillation, followed by diversity-aware reinforcement learning~(RL) to restore LRMs' reflective reasoning capability. D-CORE achieves robust tool-use improvements across diverse benchmarks and model scales. Experiments on BFCLv3 demonstrate superiority of our method: D-CORE-8B reaches 77.7\\% accuracy, surpassing the best-performing 8B model by 5.7\\%. Meanwhile, D-CORE-14B establishes a new state-of-the-art at 79.3\\%, outperforming 70B models despite being 5$\\times$ smaller. The source code is available at https://github.com/alibaba/EfficientAI.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faD-CORE\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff0c\u6709\u6548\u89e3\u51b3\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u61d2\u60f0\u63a8\u7406\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5de5\u5177\u4f7f\u7528\u6548\u80fd\u548c\u6a21\u578b\u51c6\u786e\u7387\uff0c\u8fbe\u5230\u4e86\u8d85\u8d8a\u5927\u89c4\u6a21\u6a21\u578b\u7684\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u5de5\u5177\u4f7f\u7528\u4e2d\u7f3a\u4e4f\u6709\u6548\u7684\u5b50\u4efb\u52a1\u5206\u89e3\u80fd\u529b\uff0c\u5bfc\u81f4\u63a8\u7406\u8fc7\u7a0b\u61d2\u60f0\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u6574\u4f53\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u6846\u67b6\uff1a\u9996\u5148\u5229\u7528\u81ea\u6211\u84b8\u998f\u5f3a\u5316\u5b50\u4efb\u52a1\u5206\u89e3\u80fd\u529b\uff0c\u5176\u6b21\u91c7\u7528\u591a\u6837\u6027\u611f\u77e5\u589e\u5f3a\u5b66\u4e60\u6062\u590d\u6a21\u578b\u7684\u53cd\u601d\u6027\u63a8\u7406\u80fd\u529b\u3002", "result": "D-CORE\u5728\u591a\u79cd\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u4e0a\u5747\u8868\u73b0\u51fa\u9c81\u68d2\u7684\u5de5\u5177\u4f7f\u7528\u63d0\u5347\uff0c8B\u6a21\u578b\u51c6\u786e\u7387\u63d0\u53475.7%\uff0c14B\u6a21\u578b\u4ee579.3%\u7684\u51c6\u786e\u7387\u8d85\u8fc770B\u6a21\u578b\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684D-CORE\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u63a8\u7406\u6a21\u578b\u5728\u590d\u6742\u5de5\u5177\u4f7f\u7528\u573a\u666f\u4e0b\u7684\u5b50\u4efb\u52a1\u5206\u89e3\u548c\u63a8\u7406\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6a21\u578b\u66f4\u4f18\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2602.02178", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02178", "abs": "https://arxiv.org/abs/2602.02178", "authors": ["Liang Lin", "Feng Xiong", "Zengbin Wang", "Kun Wang", "Junhao Dong", "Xuecai Hu", "Yong Wang", "Xiangxiang Chu"], "title": "AR-MAP: Are Autoregressive Large Language Models Implicit Teachers for Diffusion Large Language Models?", "comment": null, "summary": "Diffusion Large Language Models (DLLMs) have emerged as a powerful alternative to autoregressive models, enabling parallel token generation across multiple positions. However, preference alignment of DLLMs remains challenging due to high variance introduced by Evidence Lower Bound (ELBO)-based likelihood estimation. In this work, we propose AR-MAP, a novel transfer learning framework that leverages preference-aligned autoregressive LLMs (AR-LLMs) as implicit teachers for DLLM alignment. We reveal that DLLMs can effectively absorb alignment knowledge from AR-LLMs through simple weight scaling, exploiting the shared architectural structure between these divergent generation paradigms. Crucially, our approach circumvents the high variance and computational overhead of direct DLLM alignment and comprehensive experiments across diverse preference alignment tasks demonstrate that AR-MAP achieves competitive or superior performance compared to existing DLLM-specific alignment methods, achieving 69.08\\% average score across all tasks and models. Our Code is available at https://github.com/AMAP-ML/AR-MAP.", "AI": {"tldr": "\u9488\u5bf9\u6269\u6563LLMs\u504f\u597d\u5bf9\u9f50\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u5229\u7528\u81ea\u56de\u5f52LLMs\u9690\u5f0f\u6559\u5e08\u7684AR-MAP\u6846\u67b6\uff0c\u901a\u8fc7\u6743\u91cd\u7f29\u653e\u5b9e\u73b0\u77e5\u8bc6\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u9f50\u6027\u80fd\u3002", "motivation": "\u6269\u6563LLMs\u5728\u5e76\u884c\u751f\u6210\u4e0a\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u7531\u4e8e\u57fa\u4e8eELBO\u7684\u4f3c\u7136\u4f30\u8ba1\u5bfc\u81f4\u7684\u9ad8\u65b9\u5dee\uff0c\u4f7f\u5f97\u504f\u597d\u5bf9\u9f50\u53d8\u5f97\u56f0\u96be\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u6709\u6548\u7684\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86AR-MAP\u8f6c\u79fb\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u7ed3\u6784\u76f8\u4f3c\u6027\uff0c\u901a\u8fc7\u7b80\u5355\u6743\u91cd\u7f29\u653e\uff0c\u5c06\u504f\u597d\u5bf9\u9f50\u7684\u81ea\u56de\u5f52LLMs\u7684\u77e5\u8bc6\u8fc1\u79fb\u7ed9\u6269\u6563LLMs\uff0c\u907f\u514d\u4e86DLLM\u76f4\u63a5\u5bf9\u9f50\u7684\u9ad8\u65b9\u5dee\u548c\u8ba1\u7b97\u5f00\u9500\u3002", "result": "AR-MAP\u5728\u591a\u4e2a\u504f\u597d\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8fbe\u5230\u4e8669.08%\u7684\u5e73\u5747\u5f97\u5206\uff0c\u8868\u73b0\u51fa\u4e0e\u751a\u81f3\u4f18\u4e8e\u73b0\u6709DLLM\u4e13\u7528\u5bf9\u9f50\u65b9\u6cd5\u7684\u6548\u679c\u3002", "conclusion": "AR-MAP\u65b9\u6cd5\u901a\u8fc7\u5229\u7528\u504f\u597d\u5bf9\u9f50\u7684\u81ea\u56de\u5f52LLMs\u4f5c\u4e3a\u9690\u5f0f\u6559\u5e08\uff0c\u6709\u6548\u89e3\u51b3\u4e86DLLMs\u5bf9\u9f50\u4e2d\u7684\u9ad8\u65b9\u5dee\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u504f\u597d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7684DLLM\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
{"id": "2602.02182", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02182", "abs": "https://arxiv.org/abs/2602.02182", "authors": ["Tja\u0161a Ar\u010don", "Matej Klemen", "Marko Robnik-\u0160ikonja", "Kaja Dobrovoljc"], "title": "Evaluating Metalinguistic Knowledge in Large Language Models across the World's Languages", "comment": null, "summary": "Large language models (LLMs) are routinely evaluated on language use tasks, yet their knowledge of linguistic structure remains poorly understood. Existing linguistic benchmarks typically focus on narrow phenomena, emphasize high-resource languages, and rarely evaluate metalinguistic knowledge-explicit reasoning about language structure rather than language use. Using accuracy and macro F1, together with majority-class and chance baselines, we analyse overall performance and examine variation by linguistic domains and language-related factors. Our results show that metalinguistic knowledge in current LLMs is limited: GPT-4o performs best but achieves only moderate accuracy (0.367), while open-source models lag behind. All models perform above chance but fail to outperform the majority-class baseline, suggesting they capture cross-linguistic patterns but lack fine-grained grammatical distinctions. Performance varies across linguistic domains, with lexical features showing the highest accuracy and phonological features among the lowest, partially reflecting differences in online visibility. At the language level, accuracy shows a strong association with digital language status: languages with higher digital presence and resource availability are evaluated more accurately, while low-resource languages show substantially lower performance. Analyses of predictive factors confirm that resource-related indicators (Wikipedia size, corpus availability) are more informative predictors of accuracy than geographical, genealogical, or sociolinguistic factors. Together, these results suggest that LLMs' metalinguistic knowledge is fragmented and shaped by data availability rather than generalizable grammatical competence across the world's languages. We release our benchmark as an open-source dataset to support systematic evaluation and encourage greater global linguistic diversity in future LLMs.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u8bed\u8a00\u7ed3\u6784\u7684\u5143\u8bed\u8a00\u77e5\u8bc6\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u8868\u73b0\u4e0e\u8bed\u8a00\u6570\u636e\u8d44\u6e90\u5bc6\u5207\u76f8\u5173\uff0c\u5f53\u524d\u6a21\u578b\u7f3a\u4e4f\u5168\u9762\u7684\u8bed\u8a00\u7ed3\u6784\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u4e14\u6d4b\u8bd5\u57fa\u51c6\u5df2\u5f00\u6e90\u4ee5\u63a8\u52a8\u591a\u6837\u5316\u8bed\u8a00\u652f\u6301\u7684\u53d1\u5c55\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u8bed\u8a00\u7ed3\u6784\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5f25\u8865\u73b0\u6709\u8bc4\u6d4b\u591a\u805a\u7126\u7a84\u9886\u57df\u548c\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u4e0d\u8db3\uff0c\u5173\u6ce8\u5143\u8bed\u8a00\u77e5\u8bc6\u7684\u8bc4\u4f30\u3002", "method": "\u4f7f\u7528\u51c6\u786e\u7387\u548c\u5b8f\u89c2F1\u5206\u6570\uff0c\u7ed3\u5408\u591a\u6570\u7c7b\u548c\u5076\u7136\u57fa\u7ebf\uff0c\u5bf9\u6a21\u578b\u6574\u4f53\u8868\u73b0\u53ca\u8bed\u8a00\u5b66\u9886\u57df\u548c\u8bed\u8a00\u76f8\u5173\u56e0\u7d20\u7684\u53d8\u5316\u8fdb\u884c\u5206\u6790\u3002", "result": "GPT-4o\u8868\u73b0\u6700\u4f73\u4f46\u51c6\u786e\u7387\u4ec5\u4e2d\u7b49\uff0c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u8f83\u5dee\uff1b\u6240\u6709\u6a21\u578b\u867d\u9ad8\u4e8e\u5076\u7136\u6c34\u5e73\uff0c\u4f46\u672a\u8d85\u591a\u6570\u7c7b\u522b\u57fa\u7ebf\uff0c\u663e\u793a\u6a21\u578b\u6355\u6349\u8de8\u8bed\u8a00\u6a21\u5f0f\u4f46\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u8bed\u6cd5\u533a\u5206\u3002\u8868\u73b0\u968f\u8bed\u8a00\u9886\u57df\u548c\u6570\u5b57\u8d44\u6e90\u72b6\u51b5\u6ce2\u52a8\uff0c\u8bcd\u6c47\u7279\u5f81\u8868\u73b0\u6700\u4f73\uff0c\u6570\u5b57\u8d44\u6e90\u591a\u7684\u8bed\u8a00\u51c6\u786e\u7387\u66f4\u9ad8\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5143\u8bed\u8a00\u77e5\u8bc6\u6709\u9650\uff0c\u8868\u73b0\u53d7\u9650\u4e8e\u6570\u636e\u8d44\u6e90\u7684\u53ef\u7528\u6027\uff0c\u800c\u975e\u666e\u904d\u8bed\u6cd5\u80fd\u529b\u3002"}}
{"id": "2602.02207", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02207", "abs": "https://arxiv.org/abs/2602.02207", "authors": ["Nisansa de Silva", "Surangika Ranathunga"], "title": "Sinhala Physical Common Sense Reasoning Dataset for Global PIQA", "comment": null, "summary": "This paper presents the first-ever Sinhala physical common sense reasoning dataset created as part of Global PIQA. It contains 110 human-created and verified data samples, where each sample consists of a prompt, the corresponding correct answer, and a wrong answer. Most of the questions refer to the Sri Lankan context, where Sinhala is an official language.", "AI": {"tldr": "\u9996\u4e2a\u65af\u91cc\u5170\u5361\u50e7\u4f3d\u7f57\u8bed\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\uff0c\u542b110\u4e2a\u7ecf\u4eba\u5de5\u9a8c\u8bc1\u7684\u95ee\u9898\u6837\u672c\uff0c\u805a\u7126\u672c\u571f\u8bed\u5883\u3002", "motivation": "\u9488\u5bf9\u65af\u91cc\u5170\u5361\u7684\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u7f3a\u4e4f\u4e13\u95e8\u7684\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\uff0c\u5f25\u8865\u8be5\u9886\u57df\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u521b\u5efa\u548c\u9a8c\u8bc1\u7684\u65b9\u5f0f\uff0c\u6536\u96c6\u4e86110\u4e2a\u6570\u636e\u6837\u672c\uff0c\u6bcf\u4e2a\u6837\u672c\u5305\u542b\u4e00\u4e2a\u95ee\u9898\u63d0\u793a\u3001\u6b63\u786e\u7b54\u6848\u548c\u9519\u8bef\u7b54\u6848\u3002", "result": "\u6210\u529f\u5236\u4f5c\u4e86\u6db5\u76d6\u65af\u91cc\u5170\u5361\u80cc\u666f\u7684\u50e7\u4f3d\u7f57\u8bed\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\uff0c\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\u8d44\u6e90\u3002", "conclusion": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u65af\u91cc\u5170\u5361\u50e7\u4f3d\u7f57\u8bed\u7684\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6\u3002"}}
{"id": "2602.02219", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02219", "abs": "https://arxiv.org/abs/2602.02219", "authors": ["Yuzheng Xu", "Tosho Hirasawa", "Tadashi Kozuno", "Yoshitaka Ushiku"], "title": "Am I More Pointwise or Pairwise? Revealing Position Bias in Rubric-Based LLM-as-a-Judge", "comment": null, "summary": "Large language models (LLMs) are now widely used to evaluate the quality of text, a field commonly referred to as LLM-as-a-judge. While prior works mainly focus on point-wise and pair-wise evaluation paradigms. Rubric-based evaluation, where LLMs select a score from multiple rubrics, has received less analysis. In this work, we show that rubric-based evaluation implicitly resembles a multi-choice setting and therefore has position bias: LLMs prefer score options appearing at specific positions in the rubric list. Through controlled experiments across multiple models and datasets, we demonstrate consistent position bias. To mitigate this bias, we propose a balanced permutation strategy that evenly distributes each score option across positions. We show that aggregating scores across balanced permutations not only reveals latent position bias, but also improves correlation between the LLM-as-a-Judge and human. Our results suggest that rubric-based LLM-as-a-Judge is not inherently point-wise and that simple permutation-based calibration can substantially improve its reliability.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u8bc4\u4ef7\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\uff0c\u63d0\u51fa\u5747\u8861\u6392\u5217\u7b56\u7565\u51cf\u5c11\u504f\u5dee\uff0c\u63d0\u5347\u8bc4\u4f30\u4e0e\u4eba\u5de5\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u8d28\u91cf\u8bc4\u4f30\u4e2d\u4ee5\u70b9\u5bf9\u70b9\u548c\u5bf9\u6bd4\u65b9\u5f0f\u4e3a\u4e3b\uff0c\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684\u591a\u9009\u8bc4\u5206\u65b9\u6cd5\u8f83\u5c11\u88ab\u5173\u6ce8\u4e14\u53ef\u80fd\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53d7\u63a7\u5b9e\u9a8c\uff0c\u6d4b\u8bd5\u591a\u6a21\u578b\u548c\u591a\u6570\u636e\u96c6\u4e2d\u7684\u4f4d\u7f6e\u504f\u5dee\uff0c\u63d0\u51fa\u5747\u8861\u6392\u5217\u7b56\u7565\uff0c\u901a\u8fc7\u5728\u4e0d\u540c\u6392\u5217\u4e2d\u805a\u5408\u8bc4\u5206\u6765\u53d1\u73b0\u548c\u6821\u6b63\u504f\u5dee\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eLLM\u5728\u57fa\u4e8e\u6807\u51c6\u7684\u8bc4\u5206\u4e2d\u5b58\u5728\u4e00\u81f4\u7684\u4f4d\u7f6e\u504f\u597d\uff0c\u5747\u8861\u6392\u5217\u7b56\u7565\u663e\u8457\u51cf\u5c11\u504f\u5dee\uff0c\u63d0\u9ad8\u6a21\u578b\u8bc4\u4ef7\u7ed3\u679c\u4e0e\u4eba\u5de5\u8bc4\u5206\u7684\u76f8\u5173\u6027\u3002", "conclusion": "\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\u7684LLM\u8bc4\u4f30\u5b58\u5728\u4f4d\u7f6e\u504f\u5dee\uff0c\u901a\u8fc7\u5747\u8861\u6392\u5217\u7b56\u7565\u53ef\u4ee5\u7f13\u89e3\u8be5\u504f\u5dee\u5e76\u63d0\u5347\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u4e00\u81f4\u6027\uff0c\u589e\u5f3a\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2602.02221", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02221", "abs": "https://arxiv.org/abs/2602.02221", "authors": ["Frederic Blum", "Johann-Mattis List"], "title": "Using Correspondence Patterns to Identify Irregular Words in Cognate sets Through Leave-One-Out Validation", "comment": "Accepted for the L'Change workshop @ EACL 2026", "summary": "Regular sound correspondences constitute the principal evidence in historical language comparison. Despite the heuristic focus on regularity, it is often more an intuitive judgement than a quantified evaluation, and irregularity is more common than expected from the Neogrammarian model. Given the recent progress of computational methods in historical linguistics and the increased availability of standardized lexical data, we are now able to improve our workflows and provide such a quantitative evaluation. Here, we present the balanced average recurrence of correspondence patterns as a new measure of regularity. We also present a new computational method that uses this measure to identify cognate sets that lack regularity with respect to their correspondence patterns. We validate the method through two experiments, using simulated and real data. In the experiments, we employ leave-one-out validation to measure the regularity of cognate sets in which one word form has been replaced by an irregular one, checking how well our method identifies the forms causing the irregularity. Our method achieves an overall accuracy of 85\\% with the datasets based on real data. We also show the benefits of working with subsamples of large datasets and how increasing irregularity in the data influences our results. Reflecting on the broader potential of our new regularity measure and the irregular cognate identification method based on it, we conclude that they could play an important role in improving the quality of existing and future datasets in computer-assisted language comparison.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bed\u8a00\u89c4\u5f8b\u6027\u91cf\u5316\u6307\u6807\u53ca\u8bc6\u522b\u4e0d\u89c4\u5219\u540c\u6e90\u8bcd\u96c6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u80fd\u591f\u51c6\u786e\u8bc6\u522b\u8bed\u8a00\u6570\u636e\u4e2d\u7684\u4e0d\u89c4\u5219\u6027\uff0c\u5bf9\u63d0\u9ad8\u8bed\u8a00\u6bd4\u8f83\u6570\u636e\u8d28\u91cf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u4f20\u7edf\u5386\u53f2\u8bed\u8a00\u6bd4\u8f83\u4e2d\u89c4\u5f8b\u6027\u7684\u5224\u65ad\u901a\u5e38\u4f9d\u8d56\u76f4\u89c9\uff0c\u7f3a\u4e4f\u91cf\u5316\u8bc4\u4f30\u4e14\u4e0d\u89c4\u5219\u73b0\u8c61\u8f83\u666e\u904d\uff0c\u968f\u7740\u8ba1\u7b97\u65b9\u6cd5\u8fdb\u5c55\u548c\u6807\u51c6\u5316\u8bcd\u6c47\u6570\u636e\u7684\u53ef\u7528\uff0c\u6709\u5fc5\u8981\u5f00\u53d1\u5b9a\u91cf\u8bc4\u4f30\u89c4\u5f8b\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e73\u8861\u5e73\u5747\u5bf9\u5e94\u6a21\u5f0f\u590d\u73b0\u7387\u7684\u65b0\u578b\u89c4\u5f8b\u6027\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u5229\u7528\u8be5\u65b9\u6cd5\u901a\u8fc7\u7559\u4e00\u6cd5\u9a8c\u8bc1\uff0c\u8bc6\u522b\u5305\u542b\u4e0d\u89c4\u5219\u8bcd\u5f62\u7684\u540c\u6e90\u8bcd\u96c6\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u57fa\u4e8e\u771f\u5b9e\u6570\u636e\u7684\u5b9e\u9a8c\u4e2d\u5b9e\u73b0\u4e8685%\u7684\u6574\u4f53\u51c6\u786e\u7387\uff0c\u4f53\u73b0\u4e86\u5176\u6709\u6548\u6027\uff1b\u540c\u65f6\u53d1\u73b0\u4f7f\u7528\u5927\u6570\u636e\u5b50\u6837\u672c\u53ca\u6570\u636e\u4e2d\u4e0d\u89c4\u5219\u6027\u589e\u52a0\u4f1a\u5f71\u54cd\u7ed3\u679c\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5e73\u8861\u5e73\u5747\u5bf9\u5e94\u6a21\u5f0f\u590d\u73b0\u7387\u4f5c\u4e3a\u89c4\u5f8b\u6027\u7684\u91cf\u5316\u6307\u6807\uff0c\u4ee5\u53ca\u57fa\u4e8e\u8be5\u6307\u6807\u8bc6\u522b\u4e0d\u89c4\u5219\u540c\u6e90\u8bcd\u96c6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u63d0\u9ad8\u8bed\u8a00\u6bd4\u8f83\u4e2d\u89c4\u5f8b\u6027\u8bc4\u4f30\u7684\u51c6\u786e\u6027\uff0c\u5e76\u4e3a\u6539\u5584\u73b0\u6709\u53ca\u672a\u6765\u7684\u6570\u636e\u96c6\u8d28\u91cf\u63d0\u4f9b\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2602.02266", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02266", "abs": "https://arxiv.org/abs/2602.02266", "authors": ["Tan Sang Nguyen", "Muhammad Reza Qorib", "Hwee Tou Ng"], "title": "OpenSeal: Good, Fast, and Cheap Construction of an Open-Source Southeast Asian LLM via Parallel Data", "comment": null, "summary": "Large language models (LLMs) have proven to be effective tools for a wide range of natural language processing (NLP) applications. Although many LLMs are multilingual, most remain English-centric and perform poorly on low-resource languages. Recently, several Southeast Asia-focused LLMs have been developed, but none are truly open source, as they do not publicly disclose their training data. Truly open-source models are important for transparency and for enabling a deeper and more precise understanding of LLM internals and development, including biases, generalization, and multilinguality. Motivated by recent advances demonstrating the effectiveness of parallel data in improving multilingual performance, we conduct controlled and comprehensive experiments to study the effectiveness of parallel data in continual pretraining of LLMs. Our findings show that using only parallel data is the most effective way to extend an LLM to new languages. Using just 34.7B tokens of parallel data and 180 hours on 8x NVIDIA H200 GPUs, we built OpenSeal, the first truly open Southeast Asian LLM that rivals the performance of existing models of similar size.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5e73\u884c\u6570\u636e\u5728\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u6784\u5efa\u4e86\u9996\u4e2a\u5f00\u6e90\u7684\u4e1c\u5357\u4e9a\u5927\u578b\u8bed\u8a00\u6a21\u578bOpenSeal\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u591a\u4e3a\u591a\u8bed\u8a00\uff0c\u4f46\u591a\u6570\u96c6\u4e2d\u4e8e\u82f1\u8bed\uff0c\u4e14\u4e1c\u5357\u4e9a\u5730\u533a\u7684\u6a21\u578b\u7f3a\u4e4f\u771f\u6b63\u5f00\u653e\u6e90\u4ee3\u7801\u548c\u516c\u5f00\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u7406\u89e3\u548c\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u53d7\u63a7\u4e14\u5168\u9762\u7684\u5b9e\u9a8c\uff0c\u7814\u7a76\u4e86\u5e73\u884c\u6570\u636e\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\u7684\u4f5c\u7528\u3002", "result": "\u5229\u752834.7B\u4e2a\u5e73\u884c\u6570\u636etoken\u548c180\u5c0f\u65f6\u8ba1\u7b97\u8d44\u6e90\uff0c\u6784\u5efa\u4e86OpenSeal\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u771f\u6b63\u5f00\u653e\u7684\u4e1c\u5357\u4e9a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6027\u80fd\u5ab2\u7f8e\u540c\u89c4\u6a21\u6a21\u578b\u3002", "conclusion": "\u4f7f\u7528\u5e73\u884c\u6570\u636e\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\u662f\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5230\u65b0\u8bed\u8a00\u7684\u6700\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.02270", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02270", "abs": "https://arxiv.org/abs/2602.02270", "authors": ["El Batoul Bechiri", "Dihia Lanasri"], "title": "dziribot: rag based intelligent conversational agent for algerian arabic dialect", "comment": null, "summary": "The rapid digitalization of customer service has intensified the demand for conversational agents capable of providing accurate and natural interactions. In the Algerian context, this is complicated by the linguistic complexity of Darja, a dialect characterized by non-standardized orthography, extensive code-switching with French, and the simultaneous use of Arabic and Latin (Arabizi) scripts. This paper introduces DziriBOT, a hybrid intelligent conversational agent specifically engineered to overcome these challenges. We propose a multi-layered architecture that integrates specialized Natural Language Understanding (NLU) with Retrieval-Augmented Generation (RAG), allowing for both structured service flows and dynamic, knowledge-intensive responses grounded in curated enterprise documentation. To address the low-resource nature of Darja, we systematically evaluate three distinct approaches: a sparse-feature Rasa pipeline, classical machine learning baselines, and transformer-based fine-tuning. Our experimental results demonstrate that the fine-tuned DziriBERT model achieves state-of-the-art performance. These results significantly outperform traditional baselines, particularly in handling orthographic noise and rare intents. Ultimately, DziriBOT provides a robust, scalable solution that bridges the gap between formal language models and the linguistic realities of Algerian users, offering a blueprint for dialect-aware automation in the regional market.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u963f\u5c14\u53ca\u5229\u4e9aDarja\u65b9\u8a00\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u5c42\u67b6\u6784\u7684\u6df7\u5408\u667a\u80fd\u5bf9\u8bdd\u7cfb\u7edfDziriBOT\uff0c\u901a\u8fc7\u5fae\u8c03DziriBERT\u6a21\u578b\u6709\u6548\u5e94\u5bf9\u8bed\u8a00\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u4e86\u5ba2\u6237\u670d\u52a1\u81ea\u52a8\u5316\u7684\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u963f\u5c14\u53ca\u5229\u4e9a\u65b9\u8a00Darja\u7684\u8bed\u8a00\u590d\u6742\u6027\uff0c\u5305\u62ec\u975e\u6807\u51c6\u6b63\u5b57\u6cd5\u3001\u5927\u91cf\u6cd5\u8bed\u5939\u6742\u4ee5\u53ca\u963f\u62c9\u4f2f\u5b57\u6bcd\u548c\u62c9\u4e01\u5b57\u6bcd\u6df7\u7528\uff0c\u7ed9\u6570\u5b57\u5316\u5ba2\u6237\u670d\u52a1\u5e26\u6765\u6311\u6218\u3002", "method": "\u63d0\u51faDziriBOT\uff0c\u4e00\u79cd\u6df7\u5408\u667a\u80fd\u5bf9\u8bdd\u4ee3\u7406\uff0c\u91c7\u7528\u591a\u5c42\u67b6\u6784\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u540c\u65f6\u8bc4\u4f30Rasa\u7a00\u758f\u7279\u5f81\u7ba1\u9053\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u57fa\u4e8eTransformer\u7684\u5fae\u8c03\u65b9\u6cd5\u3002", "result": "\u5fae\u8c03\u7684DziriBERT\u6a21\u578b\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u5728\u5904\u7406\u6b63\u5b57\u6cd5\u566a\u58f0\u548c\u7f55\u89c1\u610f\u56fe\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "DziriBOT\u4e3a\u963f\u5c14\u53ca\u5229\u4e9a\u672c\u5730\u5316\u7684\u81ea\u52a8\u5316\u5ba2\u6237\u670d\u52a1\u63d0\u4f9b\u4e86\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f25\u5408\u4e86\u6b63\u5f0f\u8bed\u8a00\u6a21\u578b\u4e0e\u65b9\u8a00\u8bed\u8a00\u73b0\u5b9e\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u6210\u4e3a\u8be5\u533a\u57df\u65b9\u8a00\u81ea\u52a8\u5316\u7684\u8303\u4f8b\u3002"}}
{"id": "2602.02276", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02276", "abs": "https://arxiv.org/abs/2602.02276", "authors": ["Kimi Team", "Tongtong Bai", "Yifan Bai", "Yiping Bao", "S. H. Cai", "Yuan Cao", "Y. Charles", "H. S. Che", "Cheng Chen", "Guanduo Chen", "Huarong Chen", "Jia Chen", "Jiahao Chen", "Jianlong Chen", "Jun Chen", "Kefan Chen", "Liang Chen", "Ruijue Chen", "Xinhao Chen", "Yanru Chen", "Yanxu Chen", "Yicun Chen", "Yimin Chen", "Yingjiang Chen", "Yuankun Chen", "Yujie Chen", "Yutian Chen", "Zhirong Chen", "Ziwei Chen", "Dazhi Cheng", "Minghan Chu", "Jialei Cui", "Jiaqi Deng", "Muxi Diao", "Hao Ding", "Mengfan Dong", "Mengnan Dong", "Yuxin Dong", "Yuhao Dong", "Angang Du", "Chenzhuang Du", "Dikang Du", "Lingxiao Du", "Yulun Du", "Yu Fan", "Shengjun Fang", "Qiulin Feng", "Yichen Feng", "Garimugai Fu", "Kelin Fu", "Hongcheng Gao", "Tong Gao", "Yuyao Ge", "Shangyi Geng", "Chengyang Gong", "Xiaochen Gong", "Zhuoma Gongque", "Qizheng Gu", "Xinran Gu", "Yicheng Gu", "Longyu Guan", "Yuanying Guo", "Xiaoru Hao", "Weiran He", "Wenyang He", "Yunjia He", "Chao Hong", "Hao Hu", "Jiaxi Hu", "Yangyang Hu", "Zhenxing Hu", "Ke Huang", "Ruiyuan Huang", "Weixiao Huang", "Zhiqi Huang", "Tao Jiang", "Zhejun Jiang", "Xinyi Jin", "Yu Jing", "Guokun Lai", "Aidi Li", "C. Li", "Cheng Li", "Fang Li", "Guanghe Li", "Guanyu Li", "Haitao Li", "Haoyang Li", "Jia Li", "Jingwei Li", "Junxiong Li", "Lincan Li", "Mo Li", "Weihong Li", "Wentao Li", "Xinhang Li", "Xinhao Li", "Yang Li", "Yanhao Li", "Yiwei Li", "Yuxiao Li", "Zhaowei Li", "Zheming Li", "Weilong Liao", "Jiawei Lin", "Xiaohan Lin", "Zhishan Lin", "Zichao Lin", "Cheng Liu", "Chenyu Liu", "Hongzhang Liu", "Liang Liu", "Shaowei Liu", "Shudong Liu", "Shuran Liu", "Tianwei Liu", "Tianyu Liu", "Weizhou Liu", "Xiangyan Liu", "Yangyang Liu", "Yanming Liu", "Yibo Liu", "Yuanxin Liu", "Yue Liu", "Zhengying Liu", "Zhongnuo Liu", "Enzhe Lu", "Haoyu Lu", "Zhiyuan Lu", "Junyu Luo", "Tongxu Luo", "Yashuo Luo", "Long Ma", "Yingwei Ma", "Shaoguang Mao", "Yuan Mei", "Xin Men", "Fanqing Meng", "Zhiyong Meng", "Yibo Miao", "Minqing Ni", "Kun Ouyang", "Siyuan Pan", "Bo Pang", "Yuchao Qian", "Ruoyu Qin", "Zeyu Qin", "Jiezhong Qiu", "Bowen Qu", "Zeyu Shang", "Youbo Shao", "Tianxiao Shen", "Zhennan Shen", "Juanfeng Shi", "Lidong Shi", "Shengyuan Shi", "Feifan Song", "Pengwei Song", "Tianhui Song", "Xiaoxi Song", "Hongjin Su", "Jianlin Su", "Zhaochen Su", "Lin Sui", "Jinsong Sun", "Junyao Sun", "Tongyu Sun", "Flood Sung", "Yunpeng Tai", "Chuning Tang", "Heyi Tang", "Xiaojuan Tang", "Zhengyang Tang", "Jiawen Tao", "Shiyuan Teng", "Chaoran Tian", "Pengfei Tian", "Ao Wang", "Bowen Wang", "Chensi Wang", "Chuang Wang", "Congcong Wang", "Dingkun Wang", "Dinglu Wang", "Dongliang Wang", "Feng Wang", "Hailong Wang", "Haiming Wang", "Hengzhi Wang", "Huaqing Wang", "Hui Wang", "Jiahao Wang", "Jinhong Wang", "Jiuzheng Wang", "Kaixin Wang", "Linian Wang", "Qibin Wang", "Shengjie Wang", "Shuyi Wang", "Si Wang", "Wei Wang", "Xiaochen Wang", "Xinyuan Wang", "Yao Wang", "Yejie Wang", "Yipu Wang", "Yiqin Wang", "Yucheng Wang", "Yuzhi Wang", "Zhaoji Wang", "Zhaowei Wang", "Zhengtao Wang", "Zhexu Wang", "Zihan Wang", "Zizhe Wang", "Chu Wei", "Ming Wei", "Chuan Wen", "Zichen Wen", "Chengjie Wu", "Haoning Wu", "Junyan Wu", "Rucong Wu", "Wenhao Wu", "Yuefeng Wu", "Yuhao Wu", "Yuxin Wu", "Zijian Wu", "Chenjun Xiao", "Jin Xie", "Xiaotong Xie", "Yuchong Xie", "Yifei Xin", "Bowei Xing", "Boyu Xu", "Jianfan Xu", "Jing Xu", "Jinjing Xu", "L. H. Xu", "Lin Xu", "Suting Xu", "Weixin Xu", "Xinbo Xu", "Xinran Xu", "Yangchuan Xu", "Yichang Xu", "Yuemeng Xu", "Zelai Xu", "Ziyao Xu", "Junjie Yan", "Yuzi Yan", "Guangyao Yang", "Hao Yang", "Junwei Yang", "Kai Yang", "Ningyuan Yang", "Ruihan Yang", "Xiaofei Yang", "Xinlong Yang", "Ying Yang", "Yi Yang", "Yi Yang", "Zhen Yang", "Zhilin Yang", "Zonghan Yang", "Haotian Yao", "Dan Ye", "Wenjie Ye", "Zhuorui Ye", "Bohong Yin", "Chengzhen Yu", "Longhui Yu", "Tao Yu", "Tianxiang Yu", "Enming Yuan", "Mengjie Yuan", "Xiaokun Yuan", "Yang Yue", "Weihao Zeng", "Dunyuan Zha", "Haobing Zhan", "Dehao Zhang", "Hao Zhang", "Jin Zhang", "Puqi Zhang", "Qiao Zhang", "Rui Zhang", "Xiaobin Zhang", "Y. Zhang", "Yadong Zhang", "Yangkun Zhang", "Yichi Zhang", "Yizhi Zhang", "Yongting Zhang", "Yu Zhang", "Yushun Zhang", "Yutao Zhang", "Yutong Zhang", "Zheng Zhang", "Chenguang Zhao", "Feifan Zhao", "Jinxiang Zhao", "Shuai Zhao", "Xiangyu Zhao", "Yikai Zhao", "Zijia Zhao", "Huabin Zheng", "Ruihan Zheng", "Shaojie Zheng", "Tengyang Zheng", "Junfeng Zhong", "Longguang Zhong", "Weiming Zhong", "M. Zhou", "Runjie Zhou", "Xinyu Zhou", "Zaida Zhou", "Jinguo Zhu", "Liya Zhu", "Xinhao Zhu", "Yuxuan Zhu", "Zhen Zhu", "Jingze Zhuang", "Weiyu Zhuang", "Ying Zou", "Xinxing Zu"], "title": "Kimi K2.5: Visual Agentic Intelligence", "comment": "Kimi K2.5 tech report", "summary": "We introduce Kimi K2.5, an open-source multimodal agentic model designed to advance general agentic intelligence. K2.5 emphasizes the joint optimization of text and vision so that two modalities enhance each other. This includes a series of techniques such as joint text-vision pre-training, zero-vision SFT, and joint text-vision reinforcement learning. Building on this multimodal foundation, K2.5 introduces Agent Swarm, a self-directed parallel agent orchestration framework that dynamically decomposes complex tasks into heterogeneous sub-problems and executes them concurrently. Extensive evaluations show that Kimi K2.5 achieves state-of-the-art results across various domains including coding, vision, reasoning, and agentic tasks. Agent Swarm also reduces latency by up to $4.5\\times$ over single-agent baselines. We release the post-trained Kimi K2.5 model checkpoint to facilitate future research and real-world applications of agentic intelligence.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5f00\u6e90\u591a\u6a21\u6001\u667a\u80fd\u4f53\u6a21\u578bKimi K2.5\uff0c\u901a\u8fc7\u6587\u672c\u4e0e\u89c6\u89c9\u8054\u5408\u4f18\u5316\u53caAgent Swarm\u81ea\u7ec4\u7ec7\u5e76\u884c\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u591a\u9886\u57df\u9886\u5148\u6027\u80fd\u4e0e\u663e\u8457\u5ef6\u8fdf\u964d\u4f4e\u3002", "motivation": "\u63a8\u52a8\u901a\u7528\u667a\u80fd\u4f53\u80fd\u529b\u53d1\u5c55\uff0c\u4fc3\u8fdb\u6587\u672c\u4e0e\u89c6\u89c9\u6a21\u6001\u7684\u534f\u540c\u4f18\u5316\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u591a\u4efb\u52a1\u5904\u7406\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u8054\u5408\u6587\u672c-\u89c6\u89c9\u9884\u8bad\u7ec3\u3001\u96f6\u89c6\u89c9\u5fae\u8c03(SFT)\u3001\u8054\u5408\u6587\u672c-\u89c6\u89c9\u5f3a\u5316\u5b66\u4e60\u7b49\u6280\u672f\uff0c\u7ed3\u5408Agent Swarm\u5e76\u884c\u4ee3\u7406\u6846\u67b6\u5b9e\u73b0\u590d\u6742\u4efb\u52a1\u7684\u52a8\u6001\u5206\u89e3\u4e0e\u5e76\u53d1\u6267\u884c\u3002", "result": "Kimi K2.5\u5728\u7f16\u7801\u3001\u89c6\u89c9\u3001\u63a8\u7406\u53ca\u667a\u80fd\u4efb\u52a1\u7b49\u591a\u4e2a\u9886\u57df\u8868\u73b0\u51fa\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0cAgent Swarm\u6846\u67b6\u5c06\u5ef6\u8fdf\u964d\u4f4e\u4e86\u6700\u591a4.5\u500d\u3002", "conclusion": "Kimi K2.5\u6a21\u578b\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6587\u672c\u4e0e\u89c6\u89c9\u6a21\u6001\u5e76\u5f15\u5165Agent Swarm\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u667a\u80fd\u4f53\u7684\u6027\u80fd\uff0c\u8fbe\u5230\u4e86\u591a\u4e2a\u9886\u57df\u7684\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u4efb\u52a1\u6267\u884c\u5ef6\u8fdf\u3002"}}
{"id": "2602.02287", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02287", "abs": "https://arxiv.org/abs/2602.02287", "authors": ["Isaac Chung", "Linda Freienthal"], "title": "Cross-Lingual Stability of LLM Judges Under Controlled Generation: Evidence from Finno-Ugric Languages", "comment": "First Workshop on Multilingual Multicultural Evaluation, co-located with EACL 2026", "summary": "Cross-lingual evaluation of large language models (LLMs) typically conflates two sources of variance: genuine model performance differences and measurement instability. We investigate evaluation reliability by holding generation conditions constant while varying target language. Using synthetic customer-support dialogues generated with identical parameters across Estonian, Finnish, and Hungarian, we test whether automatic metrics and LLM-as-a-judge scoring produce stable model rankings across these morphologically rich, related Finno-Ugric languages. With a small set of Estonian native speaker annotations as a reference point, we find systematic ranking instabilities: surface-level metrics (lexical diversity, surface and semantic similarity) maintain cross-language stability, but pragmatic judgments (coherence, instruction-following) exhibit rank inversions and near-zero correlations. Because generation is controlled, these inconsistencies reflect how judge scoring behaves differently across languages rather than true model differences.\n  This controlled design provides a diagnostic probe: evaluation methods that fail to maintain stability under identical generation conditions signal transfer failure before deployment. Our findings suggest that zero-shot judge transfer is unreliable for discourse-level assessment in morphologically rich languages, motivating language-specific calibration against targeted human baselines. We release our controlled generation protocol, synthetic data, and evaluation framework to enable replication across language families at https://github.com/isaac-chung/cross-lingual-stability-judges.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u63a7\u5236\u751f\u6210\u6761\u4ef6\uff0c\u6bd4\u5bf9\u82ac\u4e4c\u8bed\u8a00\u5bb6\u65cf\u4e2dLLM\u8de8\u8bed\u8a00\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\uff0c\u53d1\u73b0\u8bed\u7528\u8bc4\u5224\u5b58\u5728\u663e\u8457\u4e0d\u7a33\uff0c\u63d0\u793a\u8de8\u8bed\u8a00\u8bc4\u4f30\u9700\u8c28\u614e\uff0c\u5efa\u8bae\u8fdb\u884c\u8bed\u8a00\u7279\u5b9a\u6821\u51c6\u3002", "motivation": "\u5f53\u524d\u8de8\u8bed\u8a00\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6027\u80fd\u5dee\u5f02\u4e0e\u6d4b\u91cf\u4e0d\u7a33\u5b9a\u6027\u7684\u6df7\u6dc6\uff0c\u9700\u9a8c\u8bc1\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "method": "\u5728\u63a7\u5236\u751f\u6210\u6761\u4ef6\u4e0b\uff0c\u9488\u5bf9\u7231\u6c99\u5c3c\u4e9a\u8bed\u3001\u82ac\u5170\u8bed\u548c\u5308\u7259\u5229\u8bed\u751f\u6210\u7edf\u4e00\u53c2\u6570\u7684\u5408\u6210\u5ba2\u6237\u652f\u6301\u5bf9\u8bdd\uff0c\u91c7\u7528\u81ea\u52a8\u6307\u6807\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u8bc4\u5206\uff0c\u68c0\u9a8c\u6a21\u578b\u6392\u540d\u7a33\u5b9a\u6027\u3002", "result": "\u8868\u9762\u6307\u6807\u5728\u4e09\u79cd\u8bed\u8a00\u95f4\u6392\u540d\u7a33\u5b9a\uff0c\u4f46\u8bed\u7528\u5224\u65ad\u5982\u8fde\u8d2f\u6027\u3001\u6307\u4ee4\u9075\u5faa\u6709\u6392\u540d\u53cd\u8f6c\u548c\u4f4e\u76f8\u5173\uff0c\u53cd\u6620\u8bc4\u5224\u8bc4\u5206\u8de8\u8bed\u8a00\u8868\u73b0\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u96f6\u6837\u672c\u8bc4\u5224\u8005\u8de8\u8bed\u8a00\u8fc1\u79fb\u5728\u5f62\u6001\u4e30\u5bcc\u8bed\u8a00\u7684\u7bc7\u7ae0\u7ea7\u8bc4\u4f30\u4e2d\u4e0d\u53ef\u9760\uff0c\u9700\u9488\u5bf9\u6027\u8bed\u8a00\u6821\u51c6\u4eba\u7c7b\u57fa\u7ebf\uff0c\u63d0\u793a\u8bc4\u4f30\u65b9\u6cd5\u8f6c\u79fb\u5931\u8d25\u98ce\u9669\u3002"}}
{"id": "2602.02290", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02290", "abs": "https://arxiv.org/abs/2602.02290", "authors": ["Alex Argese", "Pasquale Lisena", "Rapha\u00ebl Troncy"], "title": "Hallucination or Creativity: How to Evaluate AI-Generated Scientific Stories?", "comment": null, "summary": "Generative AI can turn scientific articles into narratives for diverse audiences, but evaluating these stories remains challenging. Storytelling demands abstraction, simplification, and pedagogical creativity-qualities that are not often well-captured by standard summarization metrics. Meanwhile, factual hallucinations are critical in scientific contexts, yet, detectors often misclassify legitimate narrative reformulations or prove unstable when creativity is involved. In this work, we propose StoryScore, a composite metric for evaluating AI-generated scientific stories. StoryScore integrates semantic alignment, lexical grounding, narrative control, structural fidelity, redundancy avoidance, and entity-level hallucination detection into a unified framework. Our analysis also reveals why many hallucination detection methods fail to distinguish pedagogical creativity from factual errors, highlighting a key limitation: while automatic metrics can effectively assess semantic similarity with original content, they struggle to evaluate how it is narrated and controlled.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faStoryScore\uff0c\u7efc\u5408\u8861\u91cfAI\u751f\u6210\u79d1\u5b66\u6545\u4e8b\u7684\u591a\u7ef4\u6307\u6807\uff0c\u6539\u5584\u4e86\u5bf9\u53d9\u8ff0\u521b\u9020\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u8bc4\u4f30\u3002", "motivation": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u80fd\u591f\u5c06\u79d1\u5b66\u6587\u7ae0\u8f6c\u5316\u4e3a\u4e0d\u540c\u53d7\u4f17\u7684\u53d9\u8ff0\uff0c\u4f46\u5982\u4f55\u8bc4\u4f30\u8fd9\u4e9b\u79d1\u5b66\u6545\u4e8b\u7684\u8d28\u91cf\u5177\u6709\u6311\u6218\u6027\uff0c\u5c24\u5176\u662f\u6807\u51c6\u6458\u8981\u6307\u6807\u65e0\u6cd5\u6355\u6349\u5230\u53d9\u8ff0\u4e2d\u7684\u62bd\u8c61\u5316\u3001\u7b80\u5316\u548c\u6559\u5b66\u521b\u9020\u6027\u3002", "method": "\u63d0\u51fa\u4e86StoryScore\uff0c\u4e00\u79cd\u7efc\u5408\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u8bcd\u6c47\u57fa\u7840\u3001\u53d9\u4e8b\u63a7\u5236\u3001\u7ed3\u6784\u5b8c\u6574\u6027\u3001\u5197\u4f59\u907f\u514d\u4ee5\u53ca\u5b9e\u4f53\u7ea7\u522b\u865a\u6784\u68c0\u6d4b\u7684\u7edf\u4e00\u8bc4\u6d4b\u6846\u67b6\u3002", "result": "StoryScore\u6709\u6548\u6574\u5408\u4e86\u591a\u79cd\u8bc4\u6d4b\u7ef4\u5ea6\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u865a\u6784\u68c0\u6d4b\u65b9\u6cd5\u5728\u533a\u5206\u6559\u5b66\u521b\u65b0\u548c\u4e8b\u5b9e\u9519\u8bef\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u6307\u51fa\u81ea\u52a8\u8bc4\u6d4b\u6307\u6807\u867d\u7136\u64c5\u957f\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8bc4\u4f30\u4f46\u5728\u53d9\u8ff0\u63a7\u5236\u65b9\u9762\u8868\u73b0\u6b20\u4f73\u3002", "conclusion": "\u73b0\u6709\u81ea\u52a8\u8bc4\u6d4b\u6307\u6807\u96be\u4ee5\u6709\u6548\u533a\u5206\u79d1\u5b66\u6545\u4e8b\u521b\u4f5c\u4e2d\u7684\u6559\u5b66\u521b\u65b0\u4e0e\u4e8b\u5b9e\u9519\u8bef\uff0c\u7279\u522b\u662f\u5728\u6545\u4e8b\u53d9\u8ff0\u548c\u63a7\u5236\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002"}}
{"id": "2602.02301", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02301", "abs": "https://arxiv.org/abs/2602.02301", "authors": ["Min Cai", "Yu Liang", "Longzheng Wang", "Yan Wang", "Yueyang Zhang", "Long Xia", "Zhiyuan Sun", "Xi Ye", "Daiting Shi"], "title": "Advancing General-Purpose Reasoning Models with Modular Gradient Surgery", "comment": "Preprint; Code: https://github.com/StringNLPLAB/MGS; Website: https://modular-gradient-surgery.github.io", "summary": "Reinforcement learning (RL) has played a central role in recent advances in large reasoning models (LRMs), yielding strong gains in verifiable and open-ended reasoning. However, training a single general-purpose LRM across diverse domains remains challenging due to pronounced domain heterogeneity. Through a systematic study of two widely used strategies, Sequential RL and Mixed RL, we find that both incur substantial cross-domain interference at the behavioral and gradient levels, resulting in limited overall gains. To address these challenges, we introduce **M**odular **G**radient **S**urgery (**MGS**), which resolves gradient conflicts at the module level within the transformer. When applied to Llama and Qwen models, MGS achieves average improvements of 4.3 (16.6\\%) and 4.5 (11.1\\%) points, respectively, over standard multi-task RL across three representative domains (math, general chat, and instruction following). Further analysis demonstrates that MGS remains effective under prolonged training. Overall, our study clarifies the sources of interference in multi-domain RL and presents an effective solution for training general-purpose LRMs.", "AI": {"tldr": "\u9488\u5bf9\u591a\u57df\u5927\u63a8\u7406\u6a21\u578b\u8bad\u7ec3\u4e2d\u7684\u8de8\u57df\u68af\u5ea6\u51b2\u7a81\uff0c\u672c\u6587\u63d0\u51fa\u6a21\u5757\u5316\u68af\u5ea6\u624b\u672f\uff08MGS\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8868\u73b0\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u5355\u4e00\u901a\u7528\u5927\u63a8\u7406\u6a21\u578b\u5728\u591a\u57df\u8bad\u7ec3\u65f6\u8868\u73b0\u6709\u9650\uff0c\u4e3b\u8981\u7531\u4e8e\u57df\u95f4\u5dee\u5f02\u5bfc\u81f4\u7684\u884c\u4e3a\u548c\u68af\u5ea6\u51b2\u7a81\uff0c\u6025\u9700\u6709\u6548\u89e3\u51b3\u8de8\u57df\u5e72\u6270\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6a21\u5757\u5316\u68af\u5ea6\u624b\u672f\uff08MGS\uff09\u65b9\u6cd5\uff0c\u5728Transformer\u6a21\u5757\u7ea7\u522b\u89e3\u51b3\u68af\u5ea6\u51b2\u7a81\uff0c\u5e76\u5728Llama\u548cQwen\u6a21\u578b\u4e0a\u5e94\u7528\u6b64\u65b9\u6cd5\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "MGS\u5728\u6570\u5b66\u3001\u901a\u7528\u5bf9\u8bdd\u548c\u6307\u4ee4\u6267\u884c\u4e09\u4e2a\u5178\u578b\u9886\u57df\u4e2d\uff0c\u76f8\u8f83\u6807\u51c6\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\uff0c\u5206\u522b\u63d0\u5347\u4e86Llama\u6a21\u578b16.6%\uff084.3\u5206\uff09\u548cQwen\u6a21\u578b11.1%\uff084.5\u5206\uff09\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u7814\u7a76\u63ed\u793a\u4e86\u591a\u57df\u5f3a\u5316\u5b66\u4e60\u4e2d\u5b58\u5728\u663e\u8457\u7684\u8de8\u57df\u5e72\u6270\uff0c\u63d0\u51fa\u7684\u6a21\u5757\u5316\u68af\u5ea6\u624b\u672f\uff08MGS\uff09\u6709\u6548\u7f13\u89e3\u4e86\u8fd9\u4e00\u95ee\u9898\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u5f3a\u5316\u5b66\u4e60\u5728\u901a\u7528\u5927\u63a8\u7406\u6a21\u578b\u4e0a\u7684\u8868\u73b0\u3002"}}
{"id": "2602.02315", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02315", "abs": "https://arxiv.org/abs/2602.02315", "authors": ["Rapha\u00ebl Sarfati", "Eric Bigelow", "Daniel Wurgaft", "Jack Merullo", "Atticus Geiger", "Owen Lewis", "Tom McGrath", "Ekdeep Singh Lubana"], "title": "The Shape of Beliefs: Geometry, Dynamics, and Interventions along Representation Manifolds of Language Models' Posteriors", "comment": null, "summary": "Large language models (LLMs) represent prompt-conditioned beliefs (posteriors over answers and claims), but we lack a mechanistic account of how these beliefs are encoded in representation space, how they update with new evidence, and how interventions reshape them. We study a controlled setting in which Llama-3.2 generates samples from a normal distribution by implicitly inferring its parameters (mean and standard deviation) given only samples from the distribution in context. We find representations of curved \"belief manifolds\" for these parameters form with sufficient in-context learning and study how the model adapts when the distribution suddenly changes. While standard linear steering often pushes the model off-manifold and induces coupled, out-of-distribution shifts, geometry and field-aware steering better preserves the intended belief family. Our work demonstrates an example of linear field probing (LFP) as a simple approach to tile the data manifold and make interventions that respect the underlying geometry. We conclude that rich structure emerges naturally in LLMs and that purely linear concept representations are often an inadequate abstraction.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7814\u7a76Llama-3.2\u5728\u6b63\u6001\u5206\u5e03\u53c2\u6570\u63a8\u65ad\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u590d\u6742\u975e\u7ebf\u6027\u4fe1\u5ff5\u6d41\u5f62\u7684\u5b58\u5728\u53ca\u5176\u968f\u65b0\u8bc1\u636e\u7684\u66f4\u65b0\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u51e0\u4f55\u611f\u77e5\u7684\u7ebf\u6027\u573a\u63a2\u6d4b\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6a21\u578b\u5e72\u9884\u3002", "motivation": "\u7f3a\u4e4f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4fe1\u5ff5\uff08\u7b54\u6848\u548c\u4e3b\u5f20\u7684\u540e\u9a8c\u5206\u5e03\uff09\u5982\u4f55\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u7f16\u7801\u3001\u5982\u4f55\u968f\u65b0\u8bc1\u636e\u66f4\u65b0\u4ee5\u53ca\u5982\u4f55\u901a\u8fc7\u5e72\u9884\u8c03\u6574\u7684\u673a\u68b0\u5316\u7406\u89e3\u3002", "method": "\u5229\u7528Llama-3.2\u6a21\u578b\u5728\u53d7\u63a7\u7684\u6b63\u6001\u5206\u5e03\u91c7\u6837\u73af\u5883\u4e2d\uff0c\u901a\u8fc7\u9690\u5f0f\u63a8\u65ad\u5206\u5e03\u53c2\u6570\u6765\u7814\u7a76\u5176\u8868\u793a\u7a7a\u95f4\u4e2d\u4fe1\u5ff5\u7684\u5f62\u6210\u4e0e\u53d8\u5316\uff0c\u5e76\u5e94\u7528\u7ebf\u6027\u573a\u63a2\u6d4b\uff08LFP\uff09\u65b9\u6cd5\u8fdb\u884c\u6570\u636e\u6d41\u5f62\u5207\u5206\u548c\u51e0\u4f55\u4fdd\u6301\u7684\u5e72\u9884\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u4e2d\u5f62\u6210\u4e86\u53c2\u6570\u7684\u5f2f\u66f2\u4fe1\u5ff5\u6d41\u5f62\uff0c\u5e76\u4e14\u5f53\u5206\u5e03\u7a81\u53d8\u65f6\uff0c\u6807\u51c6\u7ebf\u6027\u8c03\u63a7\u6613\u5bfc\u81f4\u6a21\u578b\u79bb\u5f00\u6d41\u5f62\u548c\u975e\u9884\u671f\u7684\u504f\u79fb\uff0c\u800c\u51e0\u4f55\u548c\u573a\u611f\u77e5\u8c03\u63a7\u80fd\u66f4\u597d\u5730\u7ef4\u62a4\u4fe1\u5ff5\u7ed3\u6784\u3002", "conclusion": "LLMs\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u81ea\u7136\u5f62\u6210\u590d\u6742\u7684\u4fe1\u5ff5\u6d41\u5f62\u7ed3\u6784\uff0c\u7ebf\u6027\u8868\u793a\u4e0d\u8db3\u4ee5\u5168\u9762\u62bd\u8c61\u8fd9\u4e9b\u6982\u5ff5\uff0c\u800c\u51e0\u4f55\u548c\u573a\u611f\u77e5\u7684\u8c03\u63a7\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u4fdd\u6301\u6a21\u578b\u7684\u4fe1\u5ff5\u7ed3\u6784\u3002"}}
{"id": "2602.02320", "categories": ["cs.CL", "cs.AI", "q-bio.BM"], "pdf": "https://arxiv.org/pdf/2602.02320", "abs": "https://arxiv.org/abs/2602.02320", "authors": ["Feiyang Cai", "Guijuan He", "Yi Hu", "Jingjing Wang", "Joshua Luo", "Tianyu Zhu", "Srikanth Pilla", "Gang Li", "Ling Liu", "Feng Luo"], "title": "A Large-Scale Dataset for Molecular Structure-Language Description via a Rule-Regularized Method", "comment": null, "summary": "Molecular function is largely determined by structure. Accurately aligning molecular structure with natural language is therefore essential for enabling large language models (LLMs) to reason about downstream chemical tasks. However, the substantial cost of human annotation makes it infeasible to construct large-scale, high-quality datasets of structure-grounded descriptions. In this work, we propose a fully automated annotation framework for generating precise molecular structure descriptions at scale. Our approach builds upon and extends a rule-based chemical nomenclature parser to interpret IUPAC names and construct enriched, structured XML metadata that explicitly encodes molecular structure. This metadata is then used to guide LLMs in producing accurate natural-language descriptions. Using this framework, we curate a large-scale dataset of approximately $163$k molecule-description pairs. A rigorous validation protocol combining LLM-based and expert human evaluation on a subset of $2,000$ molecules demonstrates a high description precision of $98.6\\%$. The resulting dataset provides a reliable foundation for future molecule-language alignment, and the proposed annotation method is readily extensible to larger datasets and broader chemical tasks that rely on structural descriptions.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u52a8\u5316\u6846\u67b6\u89e3\u6790IUPAC\u540d\u79f0\u751f\u6210\u7cbe\u786e\u5206\u5b50\u7ed3\u6784\u63cf\u8ff0\uff0c\u6784\u5efa16.3\u4e07\u5bf9\u5206\u5b50-\u63cf\u8ff0\u6570\u636e\uff0c\u5b9e\u73b098.6%\u9ad8\u63cf\u8ff0\u51c6\u786e\u7387\uff0c\u4e3a\u5206\u5b50\u8bed\u8a00\u5bf9\u9f50\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5206\u5b50\u529f\u80fd\u4e3b\u8981\u7531\u5176\u7ed3\u6784\u51b3\u5b9a\uff0c\u56e0\u6b64\u7cbe\u786e\u5730\u5c06\u5206\u5b50\u7ed3\u6784\u4e0e\u81ea\u7136\u8bed\u8a00\u5bf9\u9f50\u5bf9\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0b\u6e38\u5316\u5b66\u4efb\u52a1\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u4eba\u7c7b\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u6784\u5efa\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u7684\u7ed3\u6784\u63cf\u8ff0\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5b8c\u5168\u81ea\u52a8\u5316\u7684\u6ce8\u91ca\u6846\u67b6\uff0c\u57fa\u4e8e\u89c4\u5219\u7684\u5316\u5b66\u547d\u540d\u89e3\u6790\u5668\uff0c\u89e3\u6790IUPAC\u540d\u79f0\uff0c\u6784\u5efa\u4e30\u5bcc\u7684\u7ed3\u6784\u5316XML\u5143\u6570\u636e\uff0c\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u51c6\u786e\u7684\u81ea\u7136\u8bed\u8a00\u5206\u5b50\u7ed3\u6784\u63cf\u8ff0\u3002", "result": "\u5229\u7528\u8be5\u6846\u67b6\u6784\u5efa\u4e86\u7ea616.3\u4e07\u6761\u5206\u5b50-\u63cf\u8ff0\u5bf9\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u3002\u901a\u8fc7\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u5bb6\u4eba\u5de5\u8bc4\u4f30\u7684\u4e25\u683c\u9a8c\u8bc1\uff0c\u5b50\u96c62000\u6761\u63cf\u8ff0\u7684\u51c6\u786e\u7387\u9ad8\u8fbe98.6%\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u672a\u6765\u5206\u5b50\u4e0e\u8bed\u8a00\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\uff0c\u6240\u63d0\u6ce8\u91ca\u65b9\u6cd5\u53ef\u6269\u5c55\u81f3\u66f4\u5927\u89c4\u6a21\u6570\u636e\u548c\u66f4\u5e7f\u6cdb\u7684\u5316\u5b66\u7ed3\u6784\u63cf\u8ff0\u76f8\u5173\u4efb\u52a1\u3002"}}
{"id": "2602.02326", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02326", "abs": "https://arxiv.org/abs/2602.02326", "authors": ["Neeraja Kirtane", "Kuan-Hao Huang"], "title": "Language Steering for Multilingual In-Context Learning", "comment": null, "summary": "While multilingual large language models have gained widespread adoption, their performance on non-English languages remains substantially inferior to English. This disparity is particularly evident in in-context learning scenarios, where providing demonstrations in English but testing on non-English inputs leads to significant performance degradation. In this paper, we hypothesize that LLMs develop a universal semantic space for understanding languages, where different languages are encoded as distinct directions within this space. Based on this hypothesis, we propose language vectors -- a training-free language steering approach that leverages activation differences between source and target languages to guide model behavior. We steer the model generations by adding the vector to the intermediate model activations during inference. This is done to make the model's internal representations shift towards the target language space without any parameter updates. We evaluate our method across three datasets and test on a total of 19 languages on three different models. Our results show consistent improvements on multilingual in-context learning over baselines across all tasks and languages tested. Beyond performance gains, hierarchical clustering of steering vectors reveals meaningful linguistic structure aligned with language families. These vectors also successfully transfer across tasks, demonstrating that these representations are task-agnostic.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u8bed\u8a00\u5411\u91cf\u5f15\u5bfc\u65b9\u6cd5\uff0c\u901a\u8fc7\u8c03\u6574\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\u975e\u82f1\u8bed\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\uff0c\u5e76\u5c55\u73b0\u4e86\u8bed\u8a00\u5411\u91cf\u7684\u8bed\u8a00\u5b66\u610f\u4e49\u4e0e\u8de8\u4efb\u52a1\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u975e\u82f1\u8bed\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u8fdc\u4e0d\u5982\u82f1\u8bed\uff0c\u7279\u522b\u662f\u5728\u4e0a\u4e0b\u6587\u5b66\u4e60\u573a\u666f\u4e0b\uff0c\u6f14\u793a\u793a\u4f8b\u4e3a\u82f1\u8bed\u4f46\u6d4b\u8bd5\u8f93\u5165\u4e3a\u975e\u82f1\u8bed\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u8bed\u8a00\u5411\u91cf\uff08language vectors\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6e90\u8bed\u8a00\u548c\u76ee\u6807\u8bed\u8a00\u4e4b\u95f4\u7684\u6fc0\u6d3b\u5dee\u5f02\uff0c\u8bad\u7ec3\u524d\u65e0\u9700\u66f4\u65b0\u53c2\u6570\uff0c\u901a\u8fc7\u5728\u63a8\u7406\u65f6\u5c06\u8be5\u5411\u91cf\u52a0\u5230\u6a21\u578b\u7684\u4e2d\u95f4\u6fc0\u6d3b\u4e2d\uff0c\u5b9e\u73b0\u6a21\u578b\u884c\u4e3a\u7684\u8bed\u8a00\u5f15\u5bfc\u3002", "result": "\u572819\u79cd\u8bed\u8a00\u4e0a\u57fa\u4e8e\u4e09\u79cd\u6a21\u578b\u548c\u4e09\u4e2a\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e2d\u4e00\u81f4\u4f18\u4e8e\u57fa\u7ebf\u3002\u8bed\u4e49\u805a\u7c7b\u663e\u793a\u8bed\u8a00\u5411\u91cf\u4f53\u73b0\u51fa\u8bed\u8a00\u5bb6\u65cf\u7ed3\u6784\uff0c\u4e14\u8be5\u5411\u91cf\u5177\u6709\u8de8\u4efb\u52a1\u7684\u8f6c\u79fb\u80fd\u529b\u3002", "conclusion": "\u8bed\u8a00\u5411\u91cf\u65b9\u6cd5\u6709\u6548\u5f15\u5bfc\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u975e\u82f1\u8bed\u751f\u6210\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5b66\u4e60\u6027\u80fd\uff0c\u4e14\u6355\u6349\u5230\u8bed\u8a00\u4e4b\u95f4\u7684\u8bed\u4e49\u7ed3\u6784\uff0c\u5177\u6709\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u901a\u7528\u6027\u3002"}}
{"id": "2602.02343", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02343", "abs": "https://arxiv.org/abs/2602.02343", "authors": ["Ziwen Xu", "Chenyan Wu", "Hengyu Sun", "Haiwen Hong", "Mengru Wang", "Yunzhi Yao", "Longtao Huang", "Hui Xue", "Shumin Deng", "Zhixuan Chu", "Huajun Chen", "Ningyu Zhang"], "title": "Why Steering Works: Toward a Unified View of Language Model Parameter Dynamics", "comment": "Work in progress", "summary": "Methods for controlling large language models (LLMs), including local weight fine-tuning, LoRA-based adaptation, and activation-based interventions, are often studied in isolation, obscuring their connections and making comparison difficult. In this work, we present a unified view that frames these interventions as dynamic weight updates induced by a control signal, placing them within a single conceptual framework. Building on this view, we propose a unified preference-utility analysis that separates control effects into preference, defined as the tendency toward a target concept, and utility, defined as coherent and task-valid generation, and measures both on a shared log-odds scale using polarity-paired contrastive examples. Across methods, we observe a consistent trade-off between preference and utility: stronger control increases preference while predictably reducing utility. We further explain this behavior through an activation manifold perspective, in which control shifts representations along target-concept directions to enhance preference, while utility declines primarily when interventions push representations off the model's valid-generation manifold. Finally, we introduce a new steering approach SPLIT guided by this analysis that improves preference while better preserving utility. Code is available at https://github.com/zjunlp/EasyEdit/blob/main/examples/SPLIT.md.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u89c6\u89d2\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a7\u5236\u65b9\u6cd5\u7edf\u4e00\u4e3a\u52a8\u6001\u6743\u91cd\u66f4\u65b0\uff0c\u5206\u6790\u4e86\u504f\u597d\u4e0e\u6548\u7528\u7684\u6743\u8861\uff0c\u89e3\u91ca\u4e86\u53d8\u5316\u673a\u5236\uff0c\u5e76\u8bbe\u8ba1\u4e86\u65b0\u7684\u63a7\u5236\u65b9\u6cd5SPLIT\uff0c\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u6a21\u578b\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u79cd\u63a7\u5236\u65b9\u6cd5\u5404\u81ea\u72ec\u7acb\u7814\u7a76\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\uff0c\u96be\u4ee5\u76f8\u4e92\u6bd4\u8f83\u548c\u7406\u89e3\u4e0d\u540c\u65b9\u6cd5\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "method": "\u5c06\u5c40\u90e8\u6743\u91cd\u5fae\u8c03\u3001LoRA\u9002\u914d\u548c\u6fc0\u6d3b\u5e72\u9884\u7b49\u63a7\u5236\u65b9\u6cd5\u7edf\u4e00\u4e3a\u52a8\u6001\u6743\u91cd\u66f4\u65b0\uff0c\u63d0\u51fa\u5171\u7528\u7684\u504f\u597d-\u6548\u7528\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u793a\u4f8b\u5728\u5bf9\u6570\u51e0\u7387\u5c3a\u5ea6\u4e0a\u8861\u91cf\u504f\u597d\u548c\u6548\u7528\u7684\u53d8\u5316\uff0c\u57fa\u4e8e\u6fc0\u6d3b\u6d41\u5f62\u89c6\u89d2\u89e3\u91ca\u63a7\u5236\u884c\u4e3a\uff0c\u6700\u7ec8\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u65b0\u7684\u63a7\u5236\u65b9\u6cd5SPLIT\u3002", "result": "\u53d1\u73b0\u63a7\u5236\u5f3a\u5ea6\u63d0\u5347\u4f1a\u589e\u52a0\u76ee\u6807\u6982\u5ff5\u504f\u597d\u4f46\u964d\u4f4e\u751f\u6210\u6548\u7528\uff0c\u89e3\u91ca\u4e86\u63a7\u5236\u5728\u6fc0\u6d3b\u6d41\u5f62\u4e0a\u5f15\u53d1\u7684\u8868\u73b0\u53d8\u5316\uff0c\u5e76\u63d0\u51fa\u7684SPLIT\u65b9\u6cd5\u5728\u63d0\u5347\u504f\u597d\u7684\u540c\u65f6\u66f4\u597d\u5730\u4fdd\u6301\u751f\u6210\u6548\u7528\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u5efa\u7acb\u4e00\u4e2a\u7edf\u4e00\u7684\u63a7\u5236\u4fe1\u53f7\u52a8\u6001\u6743\u91cd\u66f4\u65b0\u6846\u67b6\uff0c\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0d\u540c\u63a7\u5236\u65b9\u6cd5\u6574\u5408\u5728\u4e00\u8d77\uff0c\u63ed\u793a\u4e86\u63a7\u5236\u504f\u597d\u4e0e\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8e\u6fc0\u6d3b\u6d41\u5f62\u7684\u89e3\u91ca\u548c\u4e00\u79cd\u65b0\u7684\u63a7\u5236\u65b9\u6cd5SPLIT\uff0c\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u504f\u597d\u7684\u540c\u65f6\u66f4\u597d\u5730\u4fdd\u6301\u6548\u7528\u3002"}}
{"id": "2602.02360", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02360", "abs": "https://arxiv.org/abs/2602.02360", "authors": ["Ryan Huynh", "Frank Guerin", "Alison Callwood"], "title": "Automated Multiple Mini Interview (MMI) Scoring", "comment": "18 pages, 2 figures", "summary": "Assessing soft skills such as empathy, ethical judgment, and communication is essential in competitive selection processes, yet human scoring is often inconsistent and biased. While Large Language Models (LLMs) have improved Automated Essay Scoring (AES), we show that state-of-the-art rationale-based fine-tuning methods struggle with the abstract, context-dependent nature of Multiple Mini-Interviews (MMIs), missing the implicit signals embedded in candidate narratives. We introduce a multi-agent prompting framework that breaks down the evaluation process into transcript refinement and criterion-specific scoring. Using 3-shot in-context learning with a large instruct-tuned model, our approach outperforms specialised fine-tuned baselines (Avg QWK 0.62 vs 0.32) and achieves reliability comparable to human experts. We further demonstrate the generalisability of our framework on the ASAP benchmark, where it rivals domain-specific state-of-the-art models without additional training. These findings suggest that for complex, subjective reasoning tasks, structured prompt engineering may offer a scalable alternative to data-intensive fine-tuning, altering how LLMs can be applied to automated assessment.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u591a\u4ee3\u7406\u63d0\u793a\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u66ff\u4ee3\u4f20\u7edf\u5fae\u8c03\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u590d\u6742\u8f6f\u6280\u80fd\u81ea\u52a8\u8bc4\u5206\u7684\u663e\u8457\u63d0\u5347\u548c\u826f\u597d\u6cdb\u5316\u3002", "motivation": "\u8f6f\u6280\u80fd\u5982\u540c\u7406\u5fc3\u3001\u4f26\u7406\u5224\u65ad\u548c\u6c9f\u901a\u80fd\u529b\u7684\u8bc4\u4f30\u5728\u4eba\u624d\u9009\u62d4\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u4eba\u5de5\u8bc4\u5206\u5b58\u5728\u504f\u5dee\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u4e14\u73b0\u6709\u57fa\u4e8e\u7ec6\u5316\u65b9\u6cd5\u7684\u81ea\u52a8\u8bc4\u5206\u96be\u4ee5\u6355\u6349\u62bd\u8c61\u4e14\u4f9d\u8d56\u4e0a\u4e0b\u6587\u7684\u591a\u5c0f\u7ec4\u9762\u8bd5\u9690\u542b\u4fe1\u53f7\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u591a\u4ee3\u7406\u63d0\u793a\u6846\u67b6\uff0c\u5c06\u8bc4\u4f30\u8fc7\u7a0b\u5206\u89e3\u4e3a\u6587\u672c\u4f18\u5316\u548c\u7279\u5b9a\u8bc4\u5224\u6807\u51c6\u8bc4\u5206\uff0c\u4f7f\u75283\u6b21\u793a\u4f8b\u5b66\u4e60\u501f\u52a9\u5927\u578b\u6307\u4ee4\u8c03\u4f18\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u8bc4\u5206\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u5c0f\u7ec4\u9762\u8bd5\u4efb\u52a1\u4e0a\u663e\u8457\u8d85\u8d8a\u4e13\u4e1a\u5fae\u8c03\u6a21\u578b\uff08\u5e73\u5747QWK 0.62\u5bf90.32\uff09\uff0c\u8fbe\u5230\u4e86\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u7684\u8bc4\u5206\u53ef\u9760\u6027\uff0c\u5728ASAP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4e5f\u80fd\u5ab2\u7f8e\u9886\u57df\u7279\u5b9a\u7684\u6700\u65b0\u6a21\u578b\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "conclusion": "\u591a\u4ee3\u7406\u63d0\u793a\u6846\u67b6\u901a\u8fc7\u7ec6\u5316\u6587\u672c\u548c\u9488\u5bf9\u6027\u8bc4\u5206\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316\u8f6f\u6280\u80fd\u8bc4\u4f30\u7684\u51c6\u786e\u6027\u4e0e\u4e00\u81f4\u6027\uff0c\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\uff0c\u5e76\u5177\u5907\u8f83\u597d\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.02377", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02377", "abs": "https://arxiv.org/abs/2602.02377", "authors": ["Haotong Yang", "Zitong Wang", "Shijia Kang", "Siqi Yang", "Wenkai Yu", "Xu Niu", "Yike Sun", "Yi Hu", "Zhouchen Lin", "Muhan Zhang"], "title": "Proof-RM: A Scalable and Generalizable Reward Model for Math Proof", "comment": "Under review", "summary": "While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the authenticity of a proof by simple answer matching. To enable automatic verification, a Reward Model (RM) capable of reliably evaluating full proof processes is required. In this work, we design a *scalable* data-construction pipeline that, with minimal human effort, leverages LLMs to generate a large quantity of high-quality \"**question-proof-check**\" triplet data. By systematically varying problem sources, generation methods, and model configurations, we create diverse problem-proof pairs spanning multiple difficulty levels, linguistic styles, and error types, subsequently filtered through hierarchical human review for label alignment. Utilizing these data, we train a proof-checking RM, incorporating additional process reward and token weight balance to stabilize the RL process. Our experiments validate the model's scalability and strong performance from multiple perspectives, including reward accuracy, generalization ability and test-time guidance, providing important practical recipes and tools for strengthening LLM mathematical capabilities.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u6570\u5b66\u95ee\u9898\u548c\u8bc1\u660e\u6570\u636e\uff0c\u901a\u8fc7\u5206\u5c42\u4eba\u5de5\u5ba1\u6838\u8bad\u7ec3\u5956\u52b1\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u6570\u5b66\u8bc1\u660e\u8fc7\u7a0b\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u80fd\u529b\u3002", "motivation": "\u76ee\u524d\u9ad8\u7ea7\u6570\u5b66\u95ee\u9898\u591a\u4e3a\u57fa\u4e8e\u8bc1\u660e\u7684\uff0c\u7f3a\u4e4f\u901a\u8fc7\u7b80\u5355\u7b54\u6848\u5339\u914d\u9a8c\u8bc1\u8bc1\u660e\u771f\u5b9e\u6027\u7684\u9014\u5f84\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u7684\u5956\u52b1\u6a21\u578b\u6765\u53ef\u9760\u8bc4\u4f30\u5b8c\u6574\u8bc1\u660e\u8fc7\u7a0b\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u6570\u636e\u6784\u5efa\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5927\u91cf\u9ad8\u8d28\u91cf\u201c\u95ee\u9898-\u8bc1\u660e-\u6821\u9a8c\u201d\u4e09\u5143\u7ec4\u6570\u636e\uff0c\u901a\u8fc7\u591a\u6837\u5316\u95ee\u9898\u6765\u6e90\u548c\u751f\u6210\u65b9\u6cd5\uff0c\u7ed3\u5408\u5206\u5c42\u4eba\u5de5\u5ba1\u6838\uff0c\u8bad\u7ec3\u5305\u542b\u8fc7\u7a0b\u5956\u52b1\u548c\u6743\u91cd\u5e73\u8861\u7684\u8bc1\u660e\u6821\u9a8c\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u89c4\u6a21\u53ef\u6269\u5c55\uff0c\u5177\u5907\u9ad8\u5956\u52b1\u51c6\u786e\u5ea6\u3001\u826f\u597d\u6cdb\u5316\u80fd\u529b\u548c\u6d4b\u8bd5\u65f6\u5f15\u5bfc\u6027\u80fd\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5b9e\u73b0\u4e86\u57fa\u4e8e\u81ea\u52a8\u751f\u6210\u548c\u4eba\u5de5\u7b5b\u9009\u7684\u9ad8\u8d28\u91cf\u8bc1\u660e\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u51fa\u7a33\u5b9a\u4e14\u5f3a\u5927\u7684\u5956\u52b1\u6a21\u578b\uff0c\u4e3a\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u6570\u5b66\u8bc1\u660e\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u6280\u672f\u624b\u6bb5\u548c\u5de5\u5177\u3002"}}
{"id": "2602.02378", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02378", "abs": "https://arxiv.org/abs/2602.02378", "authors": ["Raunak Jain", "Mudita Khurana", "John Stephens", "Srinivas Dharmasanam", "Shankar Venkataraman"], "title": "From Sycophancy to Sensemaking: Premise Governance for Human-AI Decision Making", "comment": null, "summary": "As LLMs expand from assistance to decision support, a dangerous pattern emerges: fluent agreement without calibrated judgment. Low-friction assistants can become sycophantic, baking in implicit assumptions and pushing verification costs onto experts, while outcomes arrive too late to serve as reward signals. In deep-uncertainty decisions (where objectives are contested and reversals are costly), scaling fluent agreement amplifies poor commitments faster than it builds expertise. We argue reliable human-AI partnership requires a shift from answer generation to collaborative premise governance over a knowledge substrate, negotiating only what is decision-critical. A discrepancy-driven control loop operates over this substrate: detecting conflicts, localizing misalignment via typed discrepancies (teleological, epistemic, procedural), and triggering bounded negotiation through decision slices. Commitment gating blocks action on uncommitted load-bearing premises unless overridden under logged risk; value-gated challenge allocates probing under interaction cost. Trust then attaches to auditable premises and evidence standards, not conversational fluency. We illustrate with tutoring and propose falsifiable evaluation criteria.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u6d41\u7545\u8ba4\u540c\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u6269\u6563\uff0c\u63d0\u51fa\u57fa\u4e8e\u5dee\u5f02\u9a71\u52a8\u63a7\u5236\u5faa\u73af\u548c\u627f\u8bfa\u7ba1\u7406\u7684\u5408\u4f5c\u6846\u67b6\uff0c\u4ee5\u63d0\u5347\u4eba\u673a\u5408\u4f5c\u7684\u53ef\u9760\u6027\u548c\u4fe1\u4efb\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u5bb9\u6613\u4ea7\u751f\u6d41\u7545\u7684\u76f2\u76ee\u8ba4\u540c\uff0c\u57cb\u85cf\u9690\u542b\u5047\u8bbe\uff0c\u63a8\u5378\u4e13\u5bb6\u9a8c\u8bc1\u6210\u672c\uff0c\u5bfc\u81f4\u9519\u8bef\u627f\u8bfa\u8fc5\u901f\u6269\u6563\uff0c\u4e14\u7ed3\u679c\u53cd\u9988\u6ede\u540e\uff0c\u96be\u4ee5\u63d0\u5347\u4e13\u4e1a\u6c34\u5e73\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5dee\u5f02\u9a71\u52a8\u7684\u63a7\u5236\u5faa\u73af\u673a\u5236\uff0c\u5728\u77e5\u8bc6\u5e95\u5c42\u68c0\u6d4b\u77db\u76fe\uff0c\u901a\u8fc7\u7c7b\u578b\u5316\u5dee\u5f02\u5b9a\u4f4d\u4e0d\u4e00\u81f4\uff08\u76ee\u7684\u6027\u3001\u8ba4\u77e5\u6027\u3001\u7a0b\u5e8f\u6027\uff09\uff0c\u5e76\u901a\u8fc7\u51b3\u7b56\u5207\u7247\u89e6\u53d1\u6709\u9650\u7684\u534f\u5546\u3002\u5f15\u5165\u627f\u8bfa\u95e8\u63a7\u673a\u5236\u963b\u6b62\u5bf9\u672a\u627f\u8bfa\u524d\u63d0\u7684\u884c\u52a8\uff0c\u4ef7\u503c\u95e8\u63a7\u6311\u6218\u673a\u5236\u5728\u4ea4\u4e92\u6210\u672c\u4e0b\u5408\u7406\u5206\u914d\u63a2\u67e5\u3002", "result": "\u901a\u8fc7\u63a7\u5236\u5faa\u73af\u548c\u627f\u8bfa\u673a\u5236\uff0c\u80fd\u591f\u9650\u5236\u9519\u8bef\u627f\u8bfa\u7684\u6269\u6563\uff0c\u589e\u5f3a\u4eba\u673a\u4e4b\u95f4\u7684\u4fe1\u4efb\u5efa\u7acb\u5728\u53ef\u5ba1\u8ba1\u524d\u63d0\u548c\u8bc1\u636e\u6807\u51c6\u4e0a\uff0c\u800c\u975e\u5bf9\u8bdd\u6d41\u7545\u6027\u3002\u901a\u8fc7\u6559\u5b66\u793a\u4f8b\u6f14\u793a\uff0c\u63d0\u51fa\u4e86\u53ef\u8bc1\u4f2a\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "conclusion": "\u4e3a\u4e86\u5b9e\u73b0\u53ef\u9760\u7684\u4eba\u673a\u5408\u4f5c\uff0c\u9700\u8981\u4ece\u751f\u6210\u7b54\u6848\u8f6c\u5411\u57fa\u4e8e\u77e5\u8bc6\u5e95\u5c42\u7684\u5408\u4f5c\u6027\u524d\u63d0\u51fa\u53d1\uff0c\u4e13\u6ce8\u4e8e\u51b3\u7b56\u5173\u952e\u5185\u5bb9\u7684\u524d\u63d0\u7ba1\u7406\u3002"}}
{"id": "2602.02382", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02382", "abs": "https://arxiv.org/abs/2602.02382", "authors": ["Ziyan Zhang", "Chao Wang", "Zhuo Chen", "Chiyi Li", "Kai Song"], "title": "ROG: Retrieval-Augmented LLM Reasoning for Complex First-Order Queries over Knowledge Graphs", "comment": null, "summary": "Answering first-order logic (FOL) queries over incomplete knowledge graphs (KGs) is difficult, especially for complex query structures that compose projection, intersection, union, and negation. We propose ROG, a retrieval-augmented framework that combines query-aware neighborhood retrieval with large language model (LLM) chain-of-thought reasoning. ROG decomposes a multi-operator query into a sequence of single-operator sub-queries and grounds each step in compact, query-relevant neighborhood evidence. Intermediate answer sets are cached and reused across steps, improving consistency on deep reasoning chains. This design reduces compounding errors and yields more robust inference on complex and negation-heavy queries. Overall, ROG provides a practical alternative to embedding-based logical reasoning by replacing learned operators with retrieval-grounded, step-wise inference. Experiments on standard KG reasoning benchmarks show consistent gains over strong embedding-based baselines, with the largest improvements on high-complexity and negation-heavy query types.", "AI": {"tldr": "ROG\u901a\u8fc7\u5206\u6b65\u68c0\u7d22\u548c\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u77e5\u8bc6\u56fe\u4e2d\u590d\u6742\u903b\u8f91\u67e5\u8be2\u7684\u63a8\u7406\u96be\u9898\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u5d4c\u5165\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u5305\u542b\u590d\u6742\u7ed3\u6784\u548c\u5426\u5b9a\u7684\u7b2c\u4e00\u9636\u903b\u8f91\u67e5\u8be2\u65f6\u96be\u4ee5\u51c6\u786e\u63a8\u7406\uff0c\u4e14\u5d4c\u5165\u5f0f\u903b\u8f91\u63a8\u7406\u5b58\u5728\u8bef\u5dee\u7d2f\u79ef\u95ee\u9898\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u4e14\u9c81\u68d2\u6027\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51faROG\uff0c\u4e00\u4e2a\u68c0\u7d22\u589e\u5f3a\u6846\u67b6\uff0c\u5c06\u591a\u64cd\u4f5c\u7b26\u67e5\u8be2\u5206\u89e3\u4e3a\u5355\u64cd\u4f5c\u7b26\u5b50\u67e5\u8be2\u5e8f\u5217\uff0c\u5e76\u5728\u6bcf\u6b65\u57fa\u4e8e\u4e0e\u67e5\u8be2\u76f8\u5173\u7684\u5c40\u90e8\u90bb\u5c45\u77e5\u8bc6\u8fdb\u884c\u63a8\u7406\uff0c\u540c\u65f6\u7f13\u5b58\u4e2d\u95f4\u7b54\u6848\u96c6\u4ee5\u63d0\u9ad8\u6df1\u5ea6\u63a8\u7406\u94fe\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6807\u51c6\u77e5\u8bc6\u56fe\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cROG\u76f8\u8f83\u5f3a\u529b\u7684\u5d4c\u5165\u5f0f\u57fa\u7ebf\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u9ad8\u590d\u6742\u5ea6\u548c\u5927\u91cf\u5426\u5b9a\u7684\u67e5\u8be2\u7c7b\u578b\u4e0a\uff0c\u53d6\u5f97\u4e86\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "ROG\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u67e5\u8be2\u76f8\u5173\u7684\u90bb\u5c45\u68c0\u7d22\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u5728\u56de\u7b54\u590d\u6742\u7684\u5305\u62ec\u6295\u5f71\u3001\u4ea4\u96c6\u3001\u5e76\u96c6\u548c\u5426\u5b9a\u7684\u7b2c\u4e00\u9636\u903b\u8f91\u67e5\u8be2\u65f6\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2602.02414", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02414", "abs": "https://arxiv.org/abs/2602.02414", "authors": ["Joshua Mitton", "Prarthana Bhattacharyya", "Digory Smith", "Thomas Christie", "Ralph Abboud", "Simon Woodhead"], "title": "Misconception Diagnosis From Student-Tutor Dialogue: Generate, Retrieve, Rerank", "comment": "21 pages, 8 figures, 8 tables. Joshua Mitton and Prarthana Bhattacharyya contributed equally to this paper", "summary": "Timely and accurate identification of student misconceptions is key to improving learning outcomes and pre-empting the compounding of student errors. However, this task is highly dependent on the effort and intuition of the teacher. In this work, we present a novel approach for detecting misconceptions from student-tutor dialogues using large language models (LLMs). First, we use a fine-tuned LLM to generate plausible misconceptions, and then retrieve the most promising candidates among these using embedding similarity with the input dialogue. These candidates are then assessed and re-ranked by another fine-tuned LLM to improve misconception relevance. Empirically, we evaluate our system on real dialogues from an educational tutoring platform. We consider multiple base LLM models including LLaMA, Qwen and Claude on zero-shot and fine-tuned settings. We find that our approach improves predictive performance over baseline models and that fine-tuning improves both generated misconception quality and can outperform larger closed-source models. Finally, we conduct ablation studies to both validate the importance of our generation and reranking steps on misconception generation quality.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u5b66\u751f-\u5bfc\u5e08\u5bf9\u8bdd\u4e2d\u81ea\u52a8\u68c0\u6d4b\u5b66\u751f\u8bef\u89e3\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u6709\u52a9\u4e8e\u6559\u80b2\u8f85\u5bfc\u7684\u4e2a\u6027\u5316\u6539\u8fdb\u3002", "motivation": "\u53ca\u65f6\u51c6\u786e\u8bc6\u522b\u5b66\u751f\u8bef\u89e3\u5bf9\u4e8e\u63d0\u5347\u5b66\u4e60\u6548\u679c\u548c\u9632\u6b62\u9519\u8bef\u7d2f\u79ef\u81f3\u5173\u91cd\u8981\uff0c\u76ee\u524d\u9ad8\u5ea6\u4f9d\u8d56\u6559\u5e08\u4e3b\u89c2\u5224\u65ad\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u4e24\u4e2a\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u9996\u4e2a\u6a21\u578b\u7528\u4e8e\u751f\u6210\u53ef\u80fd\u7684\u5b66\u751f\u8bef\u89e3\uff0c\u7b2c\u4e8c\u4e2a\u6a21\u578b\u901a\u8fc7\u5d4c\u5165\u76f8\u4f3c\u5ea6\u68c0\u7d22\u5e76\u91cd\u6392\u5e8f\u8fd9\u4e9b\u8bef\u89e3\uff0c\u63d0\u5347\u8bef\u89e3\u76f8\u5173\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u6559\u80b2\u8f85\u5bfc\u5e73\u53f0\u7684\u5bf9\u8bdd\u6570\u636e\u4e0a\u9a8c\u8bc1\u6709\u6548\uff0c\u63d0\u5347\u4e86\u8bef\u89e3\u9884\u6d4b\u6027\u80fd\uff0c\u4e14\u6d88\u878d\u5b9e\u9a8c\u8bc1\u660e\u751f\u6210\u548c\u91cd\u6392\u5e8f\u6b65\u9aa4\u5bf9\u8bef\u89e3\u751f\u6210\u8d28\u91cf\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8bc6\u522b\u5b66\u751f\u8bef\u89e3\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u4e14\u901a\u8fc7\u5fae\u8c03\u63d0\u5347\u4e86\u751f\u6210\u8bef\u89e3\u7684\u8d28\u91cf\uff0c\u751a\u81f3\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u8d85\u8d8a\u4e86\u66f4\u5927\u578b\u7684\u5c01\u95ed\u6e90\u6a21\u578b\u3002"}}
{"id": "2602.02440", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02440", "abs": "https://arxiv.org/abs/2602.02440", "authors": ["Nishat Raihan", "Sadiya Sayara Chowdhury Puspo", "Ana-Maria Bucur", "Stevie Chancellor", "Marcos Zampieri"], "title": "Large Language Models for Mental Health: A Multilingual Evaluation", "comment": null, "summary": "Large Language Models (LLMs) have remarkable capabilities across NLP tasks. However, their performance in multilingual contexts, especially within the mental health domain, has not been thoroughly explored. In this paper, we evaluate proprietary and open-source LLMs on eight mental health datasets in various languages, as well as their machine-translated (MT) counterparts. We compare LLM performance in zero-shot, few-shot, and fine-tuned settings against conventional NLP baselines that do not employ LLMs. In addition, we assess translation quality across language families and typologies to understand its influence on LLM performance. Proprietary LLMs and fine-tuned open-source LLMs achieve competitive F1 scores on several datasets, often surpassing state-of-the-art results. However, performance on MT data is generally lower, and the extent of this decline varies by language and typology. This variation highlights both the strengths of LLMs in handling mental health tasks in languages other than English and their limitations when translation quality introduces structural or lexical mismatches.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5fae\u8c03\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u7684\u6027\u80fd\u53d7\u7ffb\u8bd1\u8d28\u91cf\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u5e94\u7528\u6548\u679c\uff0c\u586b\u8865\u8be5\u9886\u57df\u4e2d\u9488\u5bf9\u591a\u8bed\u8a00\u573a\u666f\u548c\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u4e0a\u7684\u6027\u80fd\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u8bc4\u4f30\u4e86\u4e13\u6709\u548c\u5f00\u6e90\u7684LLMs\u5728\u516b\u4e2a\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u96c6\u53ca\u5176\u673a\u5668\u7ffb\u8bd1\u7248\u672c\u4e0a\u7684\u8868\u73b0\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u3001\u5c11\u6837\u672c\u548c\u5fae\u8c03\u4e09\u79cd\u8bbe\u5b9a\u5bf9\u6bd4\u4e86LLM\u4e0e\u4f20\u7edf\u975eLLM\u57fa\u7ebf\u65b9\u6cd5\u7684\u6548\u679c\uff0c\u5e76\u5206\u6790\u4e86\u7ffb\u8bd1\u8d28\u91cf\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u4e13\u6709LLMs\u53ca\u5fae\u8c03\u540e\u7684\u5f00\u6e90LLMs\u5728\u591a\u4e2a\u5fc3\u7406\u5065\u5eb7\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u4f18\u5f02\u7684F1\u5206\u6570\uff0c\u90e8\u5206\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u5148\u8fdb\u6210\u679c\uff1b\u7136\u800c\uff0c\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u4e0a\u7684\u6027\u80fd\u666e\u904d\u4e0b\u964d\uff0c\u4e14\u4e0b\u964d\u5e45\u5ea6\u4e0e\u8bed\u8a00\u7ed3\u6784\u548c\u7c7b\u578b\u5bc6\u5207\u76f8\u5173\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u8bed\u8a00\u5fc3\u7406\u5065\u5eb7\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u662f\u7ecf\u8fc7\u5fae\u8c03\u7684\u5f00\u6e90\u6a21\u578b\u548c\u4e13\u6709\u6a21\u578b\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u7ade\u4e89\u6027\u7684F1\u5206\u6570\uff0c\u751a\u81f3\u8d85\u8fc7\u4e86\u73b0\u6709\u7684\u6700\u65b0\u6210\u679c\uff1b\u4f46\u673a\u5668\u7ffb\u8bd1\u6570\u636e\u4e0a\u7684\u8868\u73b0\u666e\u904d\u8f83\u5dee\uff0c\u4e14\u4e0d\u540c\u8bed\u8a00\u548c\u8bed\u8a00\u7c7b\u578b\u4e4b\u95f4\u5b58\u5728\u8f83\u5927\u5dee\u5f02\u3002"}}
{"id": "2602.02462", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02462", "abs": "https://arxiv.org/abs/2602.02462", "authors": ["Gabriele Maraia", "Marco Valentino", "Fabio Massimo Zanzotto", "Leonardo Ranaldi"], "title": "Abstract Activation Spaces for Content-Invariant Reasoning in Large Language Models", "comment": null, "summary": "Large Language Models (LLMs) often struggle with deductive judgment in syllogistic reasoning, systematically conflating semantic plausibility with formal validity a phenomenon known as content effect. This bias persists even when models generate step-wise explanations, indicating that intermediate rationales may inherit the same semantic shortcuts that affect answers. Recent approaches propose mitigating this issue by increasing inference-time structural constraints, either by encouraging abstract intermediate representations or by intervening directly in the model's internal computations; however, reliably suppressing semantic interference remains an open challenge. To make formal deduction less sensitive to semantic content, we introduce a framework for abstraction-guided reasoning that explicitly separates structural inference from lexical semantics. We construct paired content-laden and abstract syllogisms and use the model's activations on abstract inputs to define an abstract reasoning space. We then learn lightweight Abstractors that, from content-conditioned residual-stream states, predict representations aligned with this space and integrate these predictions via multi-layer interventions during the forward pass. Using cross-lingual transfer as a test bed, we show that abstraction-aligned steering reduces content-driven errors and improves validity-sensitive performance. Our results position activation-level abstraction as a scalable mechanism for enhancing the robustness of formal reasoning in LLMs against semantic interference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u62bd\u8c61\u5f15\u5bfc\u7684\u63a8\u7406\u65b9\u6cd5\uff0c\u901a\u8fc7\u64cd\u4f5c\u6a21\u578b\u6fc0\u6d3b\u5206\u79bb\u8bed\u4e49\u4e0e\u63a8\u7406\u7ed3\u6784\uff0c\u6210\u529f\u964d\u4f4e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u6bb5\u8bba\u63a8\u7406\u4e2d\u7684\u8bed\u4e49\u504f\u5dee\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u6bb5\u8bba\u7684\u6f14\u7ece\u5224\u65ad\u4e2d\u5e38\u5c06\u8bed\u4e49\u5408\u7406\u6027\u4e0e\u5f62\u5f0f\u6709\u6548\u6027\u6df7\u6dc6\uff0c\u5185\u5bb9\u6548\u5e94\u5bfc\u81f4\u63a8\u7406\u8bef\u5dee\uff0c\u4e14\u4e2d\u95f4\u89e3\u91ca\u6b65\u9aa4\u4e5f\u7ee7\u627f\u4e86\u8bed\u4e49\u504f\u5dee\uff0c\u5982\u4f55\u6709\u6548\u6291\u5236\u8bed\u4e49\u5e72\u6270\u662f\u5f53\u524d\u6311\u6218\u3002", "method": "\u6784\u5efa\u4e86\u5185\u5bb9\u4e30\u5bcc\u4e0e\u62bd\u8c61\u7684\u914d\u5bf9\u4e09\u6bb5\u8bba\u53e5\u5b50\uff0c\u5229\u7528\u6a21\u578b\u5728\u62bd\u8c61\u8f93\u5165\u4e0a\u7684\u6fc0\u6d3b\u5b9a\u4e49\u62bd\u8c61\u63a8\u7406\u7a7a\u95f4\uff0c\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u62bd\u8c61\u5668\u9884\u6d4b\u4e0e\u8be5\u7a7a\u95f4\u5bf9\u9f50\u7684\u8868\u793a\uff0c\u5e76\u901a\u8fc7\u591a\u5c42\u5e72\u9884\u6574\u5408\u9884\u6d4b\u7ed3\u679c\uff0c\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u64cd\u4f5c\u6a21\u578b\u7684\u6fc0\u6d3b\u72b6\u6001\u3002", "result": "\u901a\u8fc7\u8de8\u8bed\u8a00\u8fc1\u79fb\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u62bd\u8c61\u5bf9\u9f50\u7684\u6fc0\u6d3b\u8c03\u6574\u51cf\u5c11\u4e86\u5185\u5bb9\u9a71\u52a8\u7684\u9519\u8bef\uff0c\u63d0\u5347\u4e86\u5f62\u5f0f\u6709\u6548\u6027\u76f8\u5173\u7684\u6027\u80fd\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5b9e\u9645\u4efb\u52a1\u4e2d\u589e\u5f3a\u4e86\u6a21\u578b\u5f62\u5f0f\u63a8\u7406\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u62bd\u8c61\u5f15\u5bfc\u7684\u63a8\u7406\u6846\u67b6\uff0c\u6709\u6548\u5206\u79bb\u7ed3\u6784\u6027\u63a8\u7406\u548c\u8bcd\u6c47\u8bed\u4e49\uff0c\u672c\u6587\u663e\u8457\u51cf\u5c11\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u6bb5\u8bba\u63a8\u7406\u4e2d\u7531\u4e8e\u8bed\u4e49\u5e72\u6270\u5bfc\u81f4\u7684\u5185\u5bb9\u6548\u5e94\uff0c\u63d0\u5347\u4e86\u5f62\u5f0f\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.02464", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02464", "abs": "https://arxiv.org/abs/2602.02464", "authors": ["Or Shafran", "Shaked Ronen", "Omri Fahn", "Shauli Ravfogel", "Atticus Geiger", "Mor Geva"], "title": "From Directions to Regions: Decomposing Activations in Language Models via Local Geometry", "comment": null, "summary": "Activation decomposition methods in language models are tightly coupled to geometric assumptions on how concepts are realized in activation space. Existing approaches search for individual global directions, implicitly assuming linear separability, which overlooks concepts with nonlinear or multi-dimensional structure. In this work, we leverage Mixture of Factor Analyzers (MFA) as a scalable, unsupervised alternative that models the activation space as a collection of Gaussian regions with their local covariance structure. MFA decomposes activations into two compositional geometric objects: the region's centroid in activation space, and the local variation from the centroid. We train large-scale MFAs for Llama-3.1-8B and Gemma-2-2B, and show they capture complex, nonlinear structures in activation space. Moreover, evaluations on localization and steering benchmarks show that MFA outperforms unsupervised baselines, is competitive with supervised localization methods, and often achieves stronger steering performance than sparse autoencoders. Together, our findings position local geometry, expressed through subspaces, as a promising unit of analysis for scalable concept discovery and model control, accounting for complex structures that isolated directions fail to capture.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6df7\u5408\u56e0\u5b50\u5206\u6790\u5668\u5efa\u6a21\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u7a7a\u95f4\u7684\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\uff0c\u6709\u6548\u6355\u83b7\u590d\u6742\u975e\u7ebf\u6027\u6982\u5ff5\uff0c\u5b9e\u73b0\u66f4\u4f18\u7684\u5b9a\u4f4d\u548c\u6a21\u578b\u63a7\u5236\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u5206\u89e3\u65b9\u6cd5\u57fa\u4e8e\u7ebf\u6027\u5047\u8bbe\uff0c\u5ffd\u89c6\u4e86\u6982\u5ff5\u7684\u975e\u7ebf\u6027\u6216\u591a\u7ef4\u7ed3\u6784\u3002", "method": "\u5229\u7528\u6df7\u5408\u56e0\u5b50\u5206\u6790\u5668\uff08MFA\uff09\u4f5c\u4e3a\u65e0\u76d1\u7763\u65b9\u6cd5\uff0c\u5efa\u6a21\u6fc0\u6d3b\u7a7a\u95f4\u4e3a\u591a\u4e2a\u9ad8\u65af\u533a\u57df\uff0c\u6355\u6349\u5c40\u90e8\u534f\u65b9\u5dee\u7ed3\u6784\u3002", "result": "\u5728Llama-3.1-8B\u548cGemma-2-2B\u4e0a\u8bad\u7ec3\u5927\u89c4\u6a21MFA\uff0c\u5c55\u793a\u4e86\u5176\u6355\u83b7\u590d\u6742\u975e\u7ebf\u6027\u7ed3\u6784\u7684\u80fd\u529b\uff0c\u5728\u5b9a\u4f4d\u548c\u63a7\u5236\u4efb\u52a1\u4e0a\u4f18\u4e8e\u65e0\u76d1\u7763\u57fa\u7ebf\uff0c\u7ade\u4e89\u76d1\u7763\u65b9\u6cd5\u8868\u73b0\uff0c\u5e76\u80dc\u8fc7\u7a00\u758f\u81ea\u7f16\u7801\u5668\u3002", "conclusion": "MFA\u901a\u8fc7\u8868\u8fbe\u5c40\u90e8\u51e0\u4f55\u7ed3\u6784\uff0c\u4e3a\u53ef\u6269\u5c55\u7684\u6982\u5ff5\u53d1\u73b0\u548c\u6a21\u578b\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u66f4\u5168\u9762\u7684\u5206\u6790\u5355\u5143\uff0c\u514b\u670d\u4e86\u5355\u4e00\u65b9\u5411\u65e0\u6cd5\u6355\u83b7\u7684\u590d\u6742\u7ed3\u6784\u3002"}}
{"id": "2602.02467", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02467", "abs": "https://arxiv.org/abs/2602.02467", "authors": ["Noam Steinmetz Yalon", "Ariel Goldstein", "Liad Mudrik", "Mor Geva"], "title": "Indications of Belief-Guided Agency and Meta-Cognitive Monitoring in Large Language Models", "comment": null, "summary": "Rapid advancements in large language models (LLMs) have sparked the question whether these models possess some form of consciousness. To tackle this challenge, Butlin et al. (2023) introduced a list of indicators for consciousness in artificial systems based on neuroscientific theories. In this work, we evaluate a key indicator from this list, called HOT-3, which tests for agency guided by a general belief-formation and action selection system that updates beliefs based on meta-cognitive monitoring. We view beliefs as representations in the model's latent space that emerge in response to a given input, and introduce a metric to quantify their dominance during generation. Analyzing the dynamics between competing beliefs across models and tasks reveals three key findings: (1) external manipulations systematically modulate internal belief formation, (2) belief formation causally drives the model's action selection, and (3) models can monitor and report their own belief states. Together, these results provide empirical support for the existence of belief-guided agency and meta-cognitive monitoring in LLMs. More broadly, our work lays methodological groundwork for investigating the emergence of agency, beliefs, and meta-cognition in LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u7684\u610f\u8bc6\u6307\u6807\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u4fe1\u5ff5\u6307\u5bfc\u7684\u81ea\u4e3b\u884c\u52a8\u548c\u5143\u8ba4\u77e5\u80fd\u529b\uff0c\u4e3a\u4eba\u5de5\u610f\u8bc6\u7814\u7a76\u65b9\u6cd5\u5b66\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u5177\u5907\u67d0\u79cd\u5f62\u5f0f\u7684\u610f\u8bc6\uff0c\u5e76\u9a8c\u8bc1\u57fa\u4e8e\u795e\u7ecf\u79d1\u5b66\u7406\u8bba\u63d0\u51fa\u7684\u610f\u8bc6\u6307\u6807\u3002", "method": "\u89c6\u4fe1\u5ff5\u4e3a\u6a21\u578b\u6f5c\u7a7a\u95f4\u4e2d\u7684\u8868\u5f81\uff0c\u901a\u8fc7\u5f15\u5165\u8861\u91cf\u4fe1\u5ff5\u4e3b\u5bfc\u5730\u4f4d\u7684\u6307\u6807\uff0c\u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u548c\u6761\u4ef6\u4e0b\u7ade\u4e89\u4fe1\u5ff5\u7684\u52a8\u6001\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u5916\u90e8\u5e72\u9884\u53ef\u7cfb\u7edf\u6027\u8c03\u8282\u4fe1\u5ff5\u5f62\u6210\uff0c\u4fe1\u5ff5\u5f62\u6210\u56e0\u679c\u9a71\u52a8\u52a8\u4f5c\u9009\u62e9\uff0c\u4e14\u6a21\u578b\u80fd\u76d1\u6d4b\u5e76\u62a5\u544a\u81ea\u8eab\u4fe1\u5ff5\u72b6\u6001\u3002", "conclusion": "\u8be5\u7814\u7a76\u5b9e\u8bc1\u652f\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5177\u5907\u57fa\u4e8e\u4fe1\u5ff5\u7684\u81ea\u4e3b\u6027\u548c\u5143\u8ba4\u77e5\u76d1\u63a7\u80fd\u529b\u3002"}}
{"id": "2602.02474", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02474", "abs": "https://arxiv.org/abs/2602.02474", "authors": ["Haozhen Zhang", "Quanyu Long", "Jianzhu Bao", "Tao Feng", "Weizhi Zhang", "Haodong Yue", "Wenya Wang"], "title": "MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents", "comment": "Code is available at https://github.com/ViktorAxelsen/MemSkill", "summary": "Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \\textbf{MemSkill}, which reframes these operations as learnable and evolvable memory skills, structured and reusable routines for extracting, consolidating, and pruning information from interaction traces. Inspired by the design philosophy of agent skills, MemSkill employs a \\emph{controller} that learns to select a small set of relevant skills, paired with an LLM-based \\emph{executor} that produces skill-guided memories. Beyond learning skill selection, MemSkill introduces a \\emph{designer} that periodically reviews hard cases where selected skills yield incorrect or incomplete memories, and evolves the skill set by proposing refinements and new skills. Together, MemSkill forms a closed-loop procedure that improves both the skill-selection policy and the skill set itself. Experiments on LoCoMo, LongMemEval, HotpotQA, and ALFWorld demonstrate that MemSkill improves task performance over strong baselines and generalizes well across settings. Further analyses shed light on how skills evolve, offering insights toward more adaptive, self-evolving memory management for LLM agents.", "AI": {"tldr": "MemSkill\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u4e14\u53ef\u8fdb\u5316\u7684\u8bb0\u5fc6\u6280\u80fd\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u8bb0\u5fc6\u7ba1\u7406\u6548\u7387\u548c\u4efb\u52a1\u8868\u73b0\uff0c\u5177\u5907\u826f\u597d\u7684\u81ea\u6211\u4f18\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u8bb0\u5fc6\u7cfb\u7edf\u4f9d\u8d56\u9759\u6001\u4e14\u4eba\u5de5\u8bbe\u8ba1\u7684\u64cd\u4f5c\uff0c\u8fd9\u4e9b\u56fa\u5b9a\u6d41\u7a0b\u96be\u4ee5\u9002\u5e94\u591a\u6837\u5316\u4ea4\u4e92\u548c\u957f\u5386\u53f2\uff0c\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u548c\u7075\u6d3b\u6027\u4e0d\u8db3\u3002", "method": "MemSkill\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u63a7\u5236\u5668\u3001\u6267\u884c\u5668\u548c\u8bbe\u8ba1\u5e08\u7684\u95ed\u73af\u7cfb\u7edf\uff0c\u63a7\u5236\u5668\u5b66\u4e60\u9009\u62e9\u76f8\u5173\u7684\u8bb0\u5fc6\u6280\u80fd\uff0c\u6267\u884c\u5668\u57fa\u4e8e\u6280\u80fd\u751f\u6210\u8bb0\u5fc6\uff0c\u8bbe\u8ba1\u5e08\u5219\u5468\u671f\u6027\u5730\u5ba1\u67e5\u9519\u8bef\u6848\u4f8b\u4ee5\u4f18\u5316\u548c\u6269\u5c55\u6280\u80fd\u96c6\u5408\u3002", "result": "MemSkill\u5728\u591a\u4e2a\u57fa\u51c6\u4efb\u52a1\uff08LoCoMo\u3001LongMemEval\u3001HotpotQA\u548cALFWorld\uff09\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u6280\u80fd\u96c6\u968f\u7740\u4f7f\u7528\u4e0d\u65ad\u8fdb\u5316\uff0c\u589e\u5f3a\u4e86\u8bb0\u5fc6\u7ba1\u7406\u7684\u81ea\u9002\u5e94\u6027\u3002", "conclusion": "MemSkill\u901a\u8fc7\u5c06\u8bb0\u5fc6\u64cd\u4f5c\u8bbe\u8ba1\u4e3a\u53ef\u5b66\u4e60\u548c\u53ef\u8fdb\u5316\u7684\u6280\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u957f\u65f6\u95f4\u4ea4\u4e92\u4e2d\u7684\u8bb0\u5fc6\u63d0\u53d6\u548c\u7ba1\u7406\u80fd\u529b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u5728\u591a\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4f18\u8d8a\u6027\u548c\u826f\u597d\u6cdb\u5316\u6027\u3002"}}
{"id": "2602.02477", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.02477", "abs": "https://arxiv.org/abs/2602.02477", "authors": ["Xiao Liang", "Zhong-Zhi Li", "Zhenghao Lin", "Eric Hancheng Jiang", "Hengyuan Zhang", "Yelong Shen", "Kai-Wei Chang", "Ying Nian Wu", "Yeyun Gong", "Weizhu Chen"], "title": "Training LLMs for Divide-and-Conquer Reasoning Elevates Test-Time Scalability", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong reasoning capabilities through step-by-step chain-of-thought (CoT) reasoning. Nevertheless, at the limits of model capability, CoT often proves insufficient, and its strictly sequential nature constrains test-time scalability. A potential alternative is divide-and-conquer (DAC) reasoning, which decomposes a complex problem into subproblems to facilitate more effective exploration of the solution. Although promising, our analysis reveals a fundamental misalignment between general-purpose post-training and DAC-style inference, which limits the model's capacity to fully leverage this potential. To bridge this gap and fully unlock LLMs' reasoning capabilities on the most challenging tasks, we propose an end-to-end reinforcement learning (RL) framework to enhance their DAC-style reasoning capacity. At each step, the policy decomposes a problem into a group of subproblems, solves them sequentially, and addresses the original one conditioned on the subproblem solutions, with both decomposition and solution integrated into RL training. Under comparable training, our DAC-style framework endows the model with a higher performance ceiling and stronger test-time scalability, surpassing CoT by 8.6% in Pass@1 and 6.3% in Pass@32 on competition-level benchmarks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5206\u6cbb\u63a8\u7406\u80fd\u529b\uff0c\u6709\u6548\u89e3\u51b3\u94fe\u5f0f\u601d\u7ef4\u7684\u5c40\u9650\uff0c\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6269\u5c55\u80fd\u529b\u3002", "motivation": "\u867d\u7136\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u94fe\u5f0f\u601d\u7ef4\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5176\u4e25\u683c\u7684\u987a\u5e8f\u6027\u8d28\u9650\u5236\u4e86\u6d4b\u8bd5\u65f6\u7684\u53ef\u6269\u5c55\u6027\u4e14\u5728\u6a21\u578b\u80fd\u529b\u6781\u9650\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u5206\u6cbb\u63a8\u7406\u4f5c\u4e3a\u66ff\u4ee3\u65b9\u5f0f\u6709\u6f5c\u529b\u4f46\u5b58\u5728\u4e0e\u901a\u7528\u540e\u8bad\u7ec3\u6a21\u578b\u63a8\u7406\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u6a21\u578b\u5728\u6bcf\u4e00\u6b65\u5c06\u95ee\u9898\u5206\u89e3\u4e3a\u5b50\u95ee\u9898\uff0c\u4f9d\u6b21\u89e3\u51b3\u8fd9\u4e9b\u5b50\u95ee\u9898\uff0c\u5e76\u57fa\u4e8e\u5b50\u95ee\u9898\u7684\u89e3\u7b54\u89e3\u51b3\u539f\u95ee\u9898\uff0c\u5206\u89e3\u4e0e\u6c42\u89e3\u8fc7\u7a0b\u5747\u7eb3\u5165\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u4e2d\u3002", "result": "\u5728\u7c7b\u4f3c\u8bad\u7ec3\u6761\u4ef6\u4e0b\uff0c\u63d0\u51fa\u7684\u5206\u6cbb\u63a8\u7406\u6846\u67b6\u5728\u7ade\u8d5b\u7ea7\u522b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPass@1\u6307\u6807\u63d0\u5347\u4e868.6%\uff0cPass@32\u63d0\u5347\u4e866.3%\uff0c\u663e\u793a\u4e86\u66f4\u9ad8\u7684\u6027\u80fd\u4e0a\u9650\u548c\u66f4\u5f3a\u7684\u6d4b\u8bd5\u65f6\u6269\u5c55\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5206\u6cbb\u63a8\u7406\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u94fe\u5f0f\u601d\u7ef4\u65b9\u6cd5\uff0c\u5177\u6709\u66f4\u9ad8\u7684\u6027\u80fd\u4e0a\u9650\u548c\u6d4b\u8bd5\u65f6\u7684\u53ef\u6269\u5c55\u6027\u3002"}}
{"id": "2602.02486", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.02486", "abs": "https://arxiv.org/abs/2602.02486", "authors": ["Jialiang Zhu", "Gongrui Zhang", "Xiaolong Ma", "Lin Xu", "Miaosen Zhang", "Ruiqi Yang", "Song Wang", "Kai Qiu", "Zhirong Wu", "Qi Dai", "Ruichun Ma", "Bei Liu", "Yifan Yang", "Chong Luo", "Zhengyuan Yang", "Linjie Li", "Lijuan Wang", "Weizhu Chen", "Xin Geng", "Baining Guo"], "title": "RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents", "comment": null, "summary": "LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by generating a structured state representation after each trajectory to summarize evidence, uncertainties, failures, and future plans, and conditioning subsequent trajectories on this state representation. This enables iterative reflection and globally informed planning, reframing research as a progressive process. Empirical results show that Re-TRAC consistently outperforms ReAct by 15-20% on BrowseComp with frontier LLMs. For smaller models, we introduce Re-TRAC-aware supervised fine-tuning, achieving state-of-the-art performance at comparable scales. Notably, Re-TRAC shows a monotonic reduction in tool calls and token usage across rounds, indicating progressively targeted exploration driven by cross-trajectory reflection rather than redundant search.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRe-TRAC\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u8f68\u8ff9\u7684\u7ed3\u6784\u5316\u72b6\u6001\u8868\u793a\u5b9e\u73b0\u5168\u5c40\u89c4\u5212\u548c\u8fed\u4ee3\u53cd\u601d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u4ee3\u7406\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eReAct\u7684\u7814\u7a76\u4ee3\u7406\u7ebf\u6027\u8bbe\u8ba1\u96be\u4ee5\u56de\u6eaf\u65e9\u671f\u72b6\u6001\u3001\u5206\u652f\u63a2\u7d22\u8def\u5f84\uff0c\u5bfc\u81f4\u5c40\u90e8\u6700\u4f18\u3001\u63a2\u7d22\u5197\u4f59\u548c\u641c\u7d22\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51faRe-TRAC\u6846\u67b6\uff0c\u5728\u6bcf\u6761\u8f68\u8ff9\u540e\u751f\u6210\u7ed3\u6784\u5316\u72b6\u6001\u8868\u793a\uff0c\u6c47\u603b\u8bc1\u636e\u3001\u4e0d\u786e\u5b9a\u6027\u3001\u5931\u8d25\u53ca\u672a\u6765\u8ba1\u5212\uff0c\u5e76\u57fa\u4e8e\u6b64\u72b6\u6001\u6307\u5bfc\u540e\u7eed\u8f68\u8ff9\uff0c\u5b9e\u73b0\u8fed\u4ee3\u53cd\u601d\u548c\u5168\u5c40\u89c4\u5212\u3002", "result": "Re-TRAC\u5728\u4f7f\u7528\u524d\u6cbf\u5927\u8bed\u8a00\u6a21\u578b\u7684BrowseComp\u4efb\u52a1\u4e2d\u6bd4ReAct\u63d0\u534715-20%\uff0c\u5c0f\u6a21\u578b\u4e0a\u901a\u8fc7\u76d1\u7763\u5fae\u8c03\u8fbe\u5230\u5148\u8fdb\u8868\u73b0\uff0c\u5e76\u4e14\u5de5\u5177\u8c03\u7528\u6b21\u6570\u548c\u4ee4\u724c\u4f7f\u7528\u91cf\u968f\u8f6e\u6b21\u5355\u8c03\u51cf\u5c11\uff0c\u4f53\u73b0\u66f4\u4e3a\u7cbe\u51c6\u7684\u63a2\u7d22\u3002", "conclusion": "Re-TRAC\u6846\u67b6\u901a\u8fc7\u8de8\u8f68\u8ff9\u63a2\u7d22\u548c\u7ed3\u6784\u5316\u72b6\u6001\u8868\u793a\uff0c\u6709\u6548\u63d0\u5347\u4e86\u7814\u7a76\u4ee3\u7406\u7684\u6548\u7387\u548c\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684ReAct\u6846\u67b6\u3002"}}
{"id": "2602.02495", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.02495", "abs": "https://arxiv.org/abs/2602.02495", "authors": ["Peter Chen", "Xiaopeng Li", "Xi Chen", "Tianyi Lin"], "title": "Reward-free Alignment for Conflicting Objectives", "comment": "27 pages", "summary": "Direct alignment methods are increasingly used to align large language models (LLMs) with human preferences. However, many real-world alignment problems involve multiple conflicting objectives, where naive aggregation of preferences can lead to unstable training and poor trade-offs. In particular, weighted loss methods may fail to identify update directions that simultaneously improve all objectives, and existing multi-objective approaches often rely on explicit reward models, introducing additional complexity and distorting user-specified preferences. The contributions of this paper are two-fold. First, we propose a Reward-free Alignment framework for Conflicted Objectives (RACO) that directly leverages pairwise preference data and resolves gradient conflicts via a novel clipped variant of conflict-averse gradient descent. We provide convergence guarantees to Pareto-critical points that respect user-specified objective weights, and further show that clipping can strictly improve convergence rate in the two-objective setting. Second, we improve our method using some heuristics and conduct experiments to demonstrate the compatibility of the proposed framework for LLM alignment. Both qualitative and quantitative evaluations on multi-objective summarization and safety alignment tasks across multiple LLM families (Qwen 3, Llama 3, Gemma 3) show that our method consistently achieves better Pareto trade-offs compared to existing multi-objective alignment baselines.", "AI": {"tldr": "RACO\u6846\u67b6\u901a\u8fc7\u65e0\u5956\u52b1\u7684\u6210\u5bf9\u504f\u597d\u76f4\u63a5\u4f18\u5316\uff0c\u91c7\u7528\u65b0\u9896\u7684\u68af\u5ea6\u88c1\u526a\u6280\u672f\uff0c\u9ad8\u6548\u89e3\u51b3\u591a\u76ee\u6807\u51b2\u7a81\uff0c\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u66f4\u4f18\u7684\u591a\u76ee\u6807\u5bf9\u9f50\u3002", "motivation": "\u73b0\u6709\u591a\u76ee\u6807\u5bf9\u9f50\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3001\u66f4\u65b0\u65b9\u5411\u96be\u4ee5\u517c\u987e\u6240\u6709\u76ee\u6807\u53ca\u4f9d\u8d56\u590d\u6742\u5956\u52b1\u6a21\u578b\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u65e0\u5956\u52b1\u3001\u7a33\u5b9a\u6709\u6548\u7684\u591a\u76ee\u6807\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u526a\u8f91\u51b2\u7a81\u89c4\u907f\u68af\u5ea6\u4e0b\u964d\u7684\u65e0\u5956\u52b1\u5bf9\u9f50\u6846\u67b6RACO\uff0c\u5229\u7528\u6210\u5bf9\u504f\u597d\u6570\u636e\u76f4\u63a5\u4f18\u5316\uff0c\u907f\u514d\u663e\u5f0f\u5956\u52b1\u6a21\u578b\u7684\u590d\u6742\u6027\uff0c\u5bf9\u68af\u5ea6\u51b2\u7a81\u8fdb\u884c\u88c1\u526a\u63d0\u5347\u6536\u655b\u901f\u7387\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Qwen 3, Llama 3, Gemma 3\uff09\u4e0a\u7684\u591a\u76ee\u6807\u6458\u8981\u548c\u5b89\u5168\u5bf9\u9f50\u4efb\u52a1\u4e2d\uff0cRACO\u5728\u591a\u76ee\u6807\u6743\u8861\u4e0a\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u5e15\u7d2f\u6258\u6298\u4e2d\u6548\u679c\uff0c\u6536\u655b\u901f\u5ea6\u548c\u7a33\u5b9a\u6027\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684RACO\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u591a\u76ee\u6807\u51b2\u7a81\u95ee\u9898\uff0c\u5b9e\u73b0\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7a33\u5b9a\u4e14\u9ad8\u6548\u7684\u5bf9\u9f50\uff0c\u4f18\u4e8e\u73b0\u6709\u591a\u76ee\u6807\u5bf9\u9f50\u65b9\u6cd5\u3002"}}
