<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 37]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research](https://arxiv.org/abs/2602.15034)
*Houping Yue,Zixiang Di,Mei Jiang,Bingdong Li,Hao Hao,Yu Song,Bo Jiang,Aimin Zhou*

Main category: cs.CL

TL;DR: 本文构建了细粒度学术写作评测平台EduResearchBench，设计逐步学习策略训练EduWrite模型，实现了比更大模型更好的教育学术写作表现。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在社会科学领域的学术写作能力评估存在不足，现有基准测试缺乏对复杂学术研究流程的细粒度评估。

Method: 设计HATD框架将学术写作流程拆解为六个研究模块和24个细粒度任务，实现自动化评估；提出基于课程学习的逐步训练策略；利用5.5万学术样本，筛选1.1万高质量指令对训练EduWrite模型。

Result: 提出了EduResearchBench，一个基于分层原子任务分解的教育学术写作综合评测平台，并基于大规模高质量数据训练出的EduWrite模型在多项核心指标上优于更大规模的一般模型。

Conclusion: EduResearchBench提供了对学术写作细粒度、模块化的评估，结合分阶段训练策略和高质量数据，提升了教育领域学术写作模型的性能，显示出数据质量和训练策略优于模型规模的效果。

Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic generation and thus lack the fine-grained assessments required to reflect complex academic research workflows. To fill this gap, we introduce EduResearchBench, the first comprehensive evaluation platform dedicated to educational academic writing. EduResearchBench is built upon our Hierarchical Atomic Task Decomposition (HATD) framework, which decomposes an end-to-end research workflow into six specialized research modules (e.g., Quantitative Analysis, Qualitative Research, and Policy Research) spanning 24 fine-grained atomic tasks. This taxonomy enables an automated evaluation pipeline that mitigates a key limitation of holistic scoring, where aggregate scores often obscure specific capability bottlenecks, and instead provides fine-grained, diagnostic feedback on concrete deficiencies. Moreover, recognizing the high cognitive load inherent in scholarly writing, we propose a curriculum learning strategy that progressively builds competence from foundational skills to complex methodological reasoning and argumentation. Leveraging 55K raw academic samples, we curate 11K high-quality instruction pairs to train EduWrite, a specialized educational scholarly writing model. Experiments show that EduWrite (30B) substantially outperforms larger general-purpose models (72B) on multiple core metrics, demonstrating that in vertical domains, data quality density and hierarchically staged training curricula are more decisive than parameter scale.

</details>


### [2] [Indic-TunedLens: Interpreting Multilingual Models in Indian Languages](https://arxiv.org/abs/2602.15038)
*Mihir Panchal,Deeksha Varshney,Mamta,Asif Ekbal*

Main category: cs.CL

TL;DR: 本论文提出了针对印度语言的多语言大模型解释性工具Indic-TunedLens，通过共享仿射变换调整隐藏状态，实现更准确的任务表示解码，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的解释性工具多针对英语，然而多语言大模型更多应用于语言多样的地区如印度，但模型在英语中心的表征空间中运作，亟需针对印度语言的跨语言解释性方法。

Method: 设计共享仿射变换以调整不同目标语言的隐藏状态，使其更好地对齐目标输出分布，从而更真实地解码模型中间表示，区别于标准的Logit Lens直接解码方法。

Result: 在MMLU基准测试的10种印度语言中，Indic-TunedLens显著优于现有解释性方法，特别是在形态复杂和低资源语言上表现突出，揭示了模型层级编码的语言特征差异。

Conclusion: Indic-TunedLens在10种印度语言上表现优越，尤其在形态丰富和资源稀缺语言上，提升了多语言模型的解释性，并揭示了多语言变换器的层级语义编码特征。

Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability framework specifically for Indian languages that learns shared affine transformations. Unlike the standard Logit Lens, which directly decodes intermediate activations, Indic-TunedLens adjusts hidden states for each target language, aligning them with the target output distributions to enable more faithful decoding of model representations. We evaluate our framework on 10 Indian languages using the MMLU benchmark and find that it significantly improves over SOTA interpretability methods, especially for morphologically rich, low resource languages. Our results provide crucial insights into the layer-wise semantic encoding of multilingual transformers. Our model is available at https://huggingface.co/spaces/AnonymousAccountACL/IndicTunedLens. Our code is available at https://github.com/AnonymousAccountACL/IndicTunedLens.

</details>


### [3] [CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding](https://arxiv.org/abs/2602.15139)
*Tahir Hussain,Saddam Hussain Khan*

Main category: cs.CL

TL;DR: 提出了CGRA DeBERTa模型，通过概念引导和残差门控机制提升古典伊斯兰文本问答准确率，实验证明其优于BERT和DeBERTa。


<details>
  <summary>Details</summary>
Motivation: 古典伊斯兰文本语义专业复杂、依赖长距离上下文且需要概念敏感推理，传统模型难以准确处理，故提出结合神学先验知识与残差门控机制的新框架以提升问答性能。

Method: 基于定制的DeBERTa骨干网络，使用轻量级LoRA适配模块和残差概念感知门控机制，结合伊斯兰核心概念词典，通过重要性加权注意力增强关键语义表示，实现问答的准确提取。

Result: 本文提出了一种名为CGRA DeBERTa的概念引导残差领域增强变换器框架，针对古典伊斯兰文本中的问答任务，实现了高精度解答。该方法基于定制的DeBERTa变换器骨干，结合轻量级LoRA适配和残差概念感知门控机制，利用伊斯兰核心概念词典引入神学先验，通过重要性加权注意力机制增强关键语义标记，提升领域语义表示效果。实验证明，在包含42591对问答对的Sahih al-Bukhari和Sahih Muslim数据集上，CGRA DeBERTa模型在EM指标上达到97.85，显著优于BERT的75.87和DeBERTa的89.77，且仅带来约8%的推理开销。质性分析显示其问答提取能力和神学准确性显著提升。

Conclusion: CGRA DeBERTa有效结合神学先验与上下文信息，实现高效且准确的古典伊斯兰文本问答，具有良好的解释性和神学精确度，适合教育材料的构建。

Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer framework, is proposed that enhances theological QA over Hadith corpora. The CGRA DeBERTa builds on a customized DeBERTa transformer backbone with lightweight LoRA based adaptations and a residual concept aware gating mechanism. The customized DeBERTa embedding block learns global and positional context, while Concept Guided Residual Blocks incorporate theological priors from a curated Islamic Concept Dictionary of 12 core terms. Moreover, the Concept Gating Mechanism selectively amplifies semantically critical tokens via importance weighted attention, applying differential scaling from 1.04 to 3.00. This design preserves contextual integrity, strengthens domain-specific semantic representations, and enables accurate, efficient span extraction while maintaining computational efficiency. This paper reports the results of training CGRA using a specially constructed dataset of 42591 QA pairs from the text of Sahih alBukhari and Sahih Muslim. While BERT achieved an EM score of 75.87 and DeBERTa one of 89.77, our model scored 97.85 and thus surpassed them by 8.08 on an absolute scale, all while adding approximately 8 inference overhead due to parameter efficient gating. The qualitative evaluation noted better extraction and discrimination and theological precision. This study presents Hadith QA systems that are efficient, interpretable, and accurate and that scale provide educational materials with necessary theological nuance.

</details>


### [4] [AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking](https://arxiv.org/abs/2602.15190)
*Herbert Ullrich,Jan Drchal*

Main category: cs.CL

TL;DR: 本文提出了一个结合文本和图像检索的多模态事实核查系统，成本低廉且性能优异，是一个易于复现和调整的竞赛强队方案。


<details>
  <summary>Details</summary>
Motivation: 通过集成多模态技术简化事实核查流程，降低单次核查成本并提高系统易用性和可复现性。

Method: 采用基于相似度搜索的文本检索模块，API调用的逆向图像搜索模块和基于GPT5.1的生成模块组成，形成了一个解耦合的管道。

Result: 系统以平均每条事实核查0.013美元的成本，通过单次多模态LLM调用，实现了竞争力的性能表现。

Conclusion: 本系统结合了文本检索、逆向图像搜索（RIS）和多模态大语言模型（GPT5.1）的生成模块，实现了高效且低成本的事实核查，达到了AVerImaTeC竞赛的第三名。

Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year's retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers competitive performance with a single multimodal LLM call per fact-check at just $0.013 on average using GPT5.1 via OpenAI Batch API. Our system is also easy to reproduce and tweak, consisting of only three decoupled modules - a textual retrieval module based on similarity search, an image retrieval module based on API-accessed RIS, and a generation module using GPT5.1 - which is why we suggest it as an accesible starting point for further experimentation. We publish its code and prompts, as well as our vector stores and insights into the scheme's running costs and directions for further improvement.

</details>


### [5] [OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction](https://arxiv.org/abs/2602.15197)
*Skyler Hallinan,Thejas Venkatesh,Xiang Ren,Sai Praneeth Karimireddy,Ashwin Paranjape,Yuhao Zhang,Jack Hessel*

Main category: cs.CL

TL;DR: 提出了ToolObserver框架，通过反馈迭代优化不透明工具文档，提升LLM代理性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有工具文档多假设工具透明且完善，而实际中诸如搜索API等工具文档不完善导致LLM代理性能受限，亟需改进文档生成方法。

Method: 设计了ToolObserver框架，通过观察工具调用轨迹和执行反馈，迭代优化工具文档。

Result: 本文提出了一个名为OpaqueToolsBench的基准测试，用于评估大型语言模型（LLM）代理在使用不透明、文档不完善的工具时的表现。研究发现现有的自动工具文档方法在面对不透明工具时既昂贵又不可靠。为此，文章提出了一个简单的框架ToolObserver，通过观察工具调用过程中的执行反馈，迭代改进工具文档。实验证明，ToolObserver在多个任务环境中表现优于现有方法，并且在工具探索时显著降低了资源消耗。

Conclusion: ToolObserver能够有效提升LLM在不透明工具环境中的表现，比现有自动文档方法更经济且效果更好。

Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general "search" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task-oriented environments: general function calling, interactive chess playing, and long-trajectory agentic search. Each environment provides underspecified tools that models must learn to use effectively to complete the task. Results on OpaqueToolsBench suggest existing methods for automatically documenting tools are expensive and unreliable when tools are opaque. To address this, we propose a simple framework, ToolObserver, that iteratively refines tool documentation by observing execution feedback from tool-calling trajectories. Our approach outperforms existing methods on OpaqueToolsBench across datasets, even in relatively hard settings. Furthermore, for test-time tool exploration settings, our method is also efficient, consuming 3.5-7.5x fewer total tokens than the best baseline.

</details>


### [6] [Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement](https://arxiv.org/abs/2602.15312)
*Stephan Ludwig,Peter J. Danaher,Xiaohao Yang,Yu-Ting Lin,Ehsan Abedin,Dhruv Grewal,Lan Du*

Main category: cs.CL

TL;DR: 本研究开发了LX语言模型，实现了对消费者情绪和评价的高效准确识别，推动了基于大规模语言模型的营销感知测量方法创新，促进消费者文本数据在营销中的应用。


<details>
  <summary>Details</summary>
Motivation: 准确测量消费者情绪及评价是营销研究和实践中的核心挑战，目前缺乏能有效利用消费者非结构化文本数据的高效方法。

Method: 基于消费者自报的16种情绪和4种评价指标，微调训练了大规模语言模型LX；通过与GPT-4 Turbo、RoBERTa等模型对比，验证其在多种数据集上的性能；采用非相关回归分析评估情绪对评分及购买的影响。

Result: LX在开放式问卷回答上达81%宏F1准确度，在亚马逊和Yelp点评数据上超过95%准确率；情绪对产品评分和购买行为具有显著预测能力，且研发了无需编码、免费可用的LX网页应用支持规模化分析。

Conclusion: Linguistic eXtractor (LX)模型能有效准确地从消费者文本中测量消费相关情绪和评价，优于现有领先模型。情绪表达不仅通过产品评分间接影响购买行为，某些情绪还能直接影响购买，揭示情绪对消费者行为的独特作用。

Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on consumer-authored text that also has been labeled with consumers' self-reported ratings of 16 consumption-related emotions and four evaluation constructs: trust, commitment, recommendation, and sentiment. LX consistently outperforms leading models, including GPT-4 Turbo, RoBERTa, and DeepSeek, achieving 81% macro-F1 accuracy on open-ended survey responses and greater than 95% accuracy on third-party-annotated Amazon and Yelp reviews. An application of LX to online retail data, using seemingly unrelated regression, affirms that review-expressed emotions predict product ratings, which in turn predict purchase behavior. Most emotional effects are mediated by product ratings, though some emotions, such as discontent and peacefulness, influence purchase directly, indicating that emotional tone provides meaningful signals beyond star ratings. To support its use, a no-code, cost-free, LX web application is available, enabling scalable analyses of consumer-authored text. In establishing a new methodological foundation for consumer perception measurement, this research demonstrates new methods for leveraging large language models to advance marketing research and practice, thereby achieving validated detection of marketing constructs from consumer data.

</details>


### [7] [Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory](https://arxiv.org/abs/2602.15313)
*Zihao Tang,Xin Yu,Ziyu Xiao,Zengxuan Wen,Zelin Li,Jiaxi Zhou,Hualei Wang,Haohua Wang,Haizhen Huang,Weiwei Deng,Feng Sun,Qi Zhang*

Main category: cs.CL

TL;DR: Mnemis通过融合两种检索机制提升了大语言模型的记忆组织与检索能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于相似性的记忆检索方法难以满足需要全局推理和全面信息覆盖的场景，亟需引入全局选择机制以提升记忆检索质量。

Method: Mnemis将记忆组织为基础图用于相似性检索，并构建层次图通过自上而下的全局选择机制进行语义导航，实现语义和结构相关信息的综合检索。

Result: 本文提出了一种名为Mnemis的新型记忆框架，结合了基于相似性的System-1检索和层次化的System-2全局选择机制，在长时记忆基准测试中表现优异。

Conclusion: Mnemis在长时记忆评测中取得了领先成绩，证明了结合局部相似性搜索与全局语义层次结构遍历的有效性。

Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms. While efficient, such System-1-style retrieval struggles with scenarios that require global reasoning or comprehensive coverage of all relevant information. In this work, We propose Mnemis, a novel memory framework that integrates System-1 similarity search with a complementary System-2 mechanism, termed Global Selection. Mnemis organizes memory into a base graph for similarity retrieval and a hierarchical graph that enables top-down, deliberate traversal over semantic hierarchies. By combining the complementary strength from both retrieval routes, Mnemis retrieves memory items that are both semantically and structurally relevant. Mnemis achieves state-of-the-art performance across all compared methods on long-term memory benchmarks, scoring 93.9 on LoCoMo and 91.6 on LongMemEval-S using GPT-4.1-mini.

</details>


### [8] [NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering](https://arxiv.org/abs/2602.15353)
*Rong Fu,Yang Li,Zeyu Zhang,Jiekai Wu,Yaohua Liu,Shuaishuai Cao,Yangchen Zeng,Yuhang Zhang,Xiaojing Du,Chuang Zhao,Kangning Cui,Simon Fong*

Main category: cs.CL

TL;DR: 本文提出了NeuroSymActive，一种结合神经符号推理和主动探索的知识图谱问答框架，有效提升多跳推理准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大型预训练语言模型和神经推理系统在处理需要精确结构化多跳推理的知识密集型查询时存在效率低和稳健性差的问题，且单纯符号或检索方法代价高且缺乏梯度优化能力，因此需要一种高效且可微分的推理框架。

Method: 提出了NeuroSymActive框架，结合可微分的神经符号推理层和基于价值指导的主动探索控制器，采用软统一风格的符号模块、神经路径评估器以及蒙特卡洛风格的探索策略，实现知识图谱多跳推理。

Result: 在标准知识图谱问答基准测试中，NeuroSymActive不仅提高了答案的准确率，还减少了昂贵的图查询次数和模型调用，优于常见的基于检索的增强方法。

Conclusion: NeuroSymActive框架在知识图谱问答任务中表现出较高的准确性，同时显著减少了图查询和模型调用次数，提高了效率。

Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact symbolic substrate for factual grounding, but integrating graph structure with neural models is nontrivial: naively embedding graph facts into prompts leads to inefficiency and fragility, while purely symbolic or search-heavy approaches can be costly in retrievals and lack gradient-based refinement. We introduce NeuroSymActive, a modular framework that combines a differentiable neural-symbolic reasoning layer with an active, value-guided exploration controller for Knowledge Graph Question Answering. The method couples soft-unification style symbolic modules with a neural path evaluator and a Monte-Carlo style exploration policy that prioritizes high-value path expansions. Empirical results on standard KGQA benchmarks show that NeuroSymActive attains strong answer accuracy while reducing the number of expensive graph lookups and model calls compared to common retrieval-augmented baselines.

</details>


### [9] [TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models](https://arxiv.org/abs/2602.15449)
*Chansung Park,Juyong Jiang,Fan Wang,Sayak Paul,Jiasi Shen,Jing Tang,Jianguo Li*

Main category: cs.CL

TL;DR: 本文针对大语言模型代码生成中的训练奖励不平衡问题，提出了一种基于能力自适应课程设计的强化微调方法TAROT，有效提升了模型的代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化微调方法忽视了测试用例在难度和粒度上的异质性，导致奖励信号分布不均衡，从而引起训练阶段梯度更新偏差，制约了模型在生成复杂鲁棒代码上的性能提升。

Method: 提出了Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT)方法，基于四层次难度的测试套件并结合模型能力条件，进行课程设计和评估，解耦奖励信号与课程进度，在训练中实现能力驱动的课程强化微调。

Result: 实验证明，不同能力模型在课程策略上存在差异，能力较弱模型适合由易到难的课程，而能力较强模型则在先难后易在课程中表现更佳。TAROT方法实现了课程设计的能力适配，并持续提升代码生成的正确性和鲁棒性。

Conclusion: 本文提出的TAROT方法通过自适应地设计课程训练方案，显著提升了大语言模型在代码生成任务中的功能正确性和鲁棒性，实现了更稳定和高效的能力提升。

Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential to overcoming this hurdle. Reinforcement Fine-Tuning (RFT) has emerged as a promising strategy to address this need. However, most existing approaches overlook the heterogeneous difficulty and granularity inherent in test cases, leading to an imbalanced distribution of reward signals and consequently biased gradient updates during training. To address this, we propose Test-driven and cApability-adaptive cuRriculum reinfOrcement fine-Tuning (TAROT). TAROT systematically constructs, for each problem, a four-tier test suite (basic, intermediate, complex, edge), providing a controlled difficulty landscape for curriculum design and evaluation. Crucially, TAROT decouples curriculum progression from raw reward scores, enabling capability-conditioned evaluation and principled selection from a portfolio of curriculum policies rather than incidental test-case difficulty composition. This design fosters stable optimization and more efficient competency acquisition. Extensive experimental results reveal that the optimal curriculum for RFT in code generation is closely tied to a model's inherent capability, with less capable models achieving greater gains with an easy-to-hard progression, whereas more competent models excel under a hard-first curriculum. TAROT provides a reproducible method that adaptively tailors curriculum design to a model's capability, thereby consistently improving the functional correctness and robustness of the generated code. All code and data are released to foster reproducibility and advance community research at https://github.com/deep-diver/TAROT.

</details>


### [10] [Far Out: Evaluating Language Models on Slang in Australian and Indian English](https://arxiv.org/abs/2602.15373)
*Deniz Kaya Dilsiz,Dipankar Srirag,Aditya Joshi*

Main category: cs.CL

TL;DR: 该研究评估了七种语言模型对印度英语和澳大利亚英语俚语的理解能力，发现模型在判别任务中表现较好，印度英语表现优于澳大利亚英语，透露语言模型在处理多样化俚语时仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在处理非标准语言变体及其特定俚语时的表现差异，尤其是印度英语和澳大利亚英语中的俚语理解能力。

Method: 构建两个数据集（1web和1gen），分别包含网络来源和合成生成的俚语使用例；使用七种先进语言模型，评估三种任务（目标词预测TWP、指导目标词预测TWP*、目标词选择TWS）中的表现。

Result: （1）目标词选择任务（TWS）表现优于目标词预测任务（TWP及TWP*）；（2）模型在1web数据集上表现优于1gen数据集；（3）印度英语任务整体优于澳大利亚英语，尤其在TWS任务中差异明显。

Conclusion: 语言模型对非标准语言变体的生成与判别能力存在不对称，特别是在理解俚语时，即使是英语这种技术资源丰富的语言，也存在显著挑战。

Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two complementary datasets: \textsc{web}, containing 377 web-sourced usage examples from Urban Dictionary, and \textsc{gen}, featuring 1,492 synthetically generated usages of these slang terms, across diverse scenarios. We assess language models on three tasks: target word prediction (TWP), guided target word prediction (TWP$^*$) and target word selection (TWS). Our results reveal four key findings: (1) Higher average model performance TWS versus TWP and TWP$^*$, with average accuracy score increasing from 0.03 to 0.49 respectively (2) Stronger average model performance on \textsc{web} versus \textsc{gen} datasets, with average similarity score increasing by 0.03 and 0.05 across TWP and TWP$^*$ tasks respectively (3) en-IN tasks outperform en-AU when averaged across all models and datasets, with TWS demonstrating the largest disparity, increasing average accuracy from 0.44 to 0.54. These findings underscore fundamental asymmetries between generative and discriminative competencies for variety-specific language, particularly in the context of slang expressions despite being in a technologically rich language such as English.

</details>


### [11] [Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework](https://arxiv.org/abs/2602.15377)
*Mengze Hong,Chen Jason Zhang,Zichang Guo,Hanlin Gu,Di Jiang,Li Qing*

Main category: cs.CL

TL;DR: 本文提出基于任务导向流程图的客服自动化框架，通过本地小模型及去中心化蒸馏解决数据隐私，实验验证优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有客服自动化方法依赖复杂模块或过于简化指令，导致指导有限和泛化能力差，亟需一种无须人工协调的高效自动化框架。

Method: 定义流程图组件和评价指标，设计成本高效的流程图构建算法，从服务对话中抽象程序知识；采用本地部署小型语言模型和去中心化蒸馏技术缓解数据稀缺和隐私问题。

Result: 本文提出了一种基于任务导向流程图（TOFs）的客服自动化框架，实现了端到端自动化且无需人工干预。通过定义TOFs的组件和评价指标，设计了一种成本效益高的流程图构建算法，抽象服务对话中的过程知识。为解决数据稀缺和隐私问题，提出了小型语言模型的本地部署及去中心化知识蒸馏方法。大规模实验证明该方法在多种服务任务中优于现有方法和市场产品，同时发布了网页系统演示以促进未来服务自动化开发。

Conclusion: 该框架无需人工干预即可实现高效客服自动化，且通过本地模型部署和去中心化蒸馏有效保护数据隐私，性能优于现有强基线和市场产品。

Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance and poor generalizability. This paper introduces an orchestration-free framework using Task-Oriented Flowcharts (TOFs) to enable end-to-end automation without manual intervention. We first define the components and evaluation metrics for TOFs, then formalize a cost-efficient flowchart construction algorithm to abstract procedural knowledge from service dialogues. We emphasize local deployment of small language models and propose decentralized distillation with flowcharts to mitigate data scarcity and privacy issues in model training. Extensive experiments validate the effectiveness in various service tasks, with superior quantitative and application performance compared to strong baselines and market products. By releasing a web-based system demonstration with case studies, we aim to promote streamlined creation of future service automation.

</details>


### [12] [Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language](https://arxiv.org/abs/2602.15378)
*Prathamesh Devadiga,Paras Chopra*

Main category: cs.CL

TL;DR: 通过结构化提示和多种策略，显著提升大型语言模型对极少训练数据语言的对话能力。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在训练数据几乎缺失的语言（如Tulu）上的基本会话能力。

Method: 结合显式语法文档、负约束抑制高概率相关语言词汇、罗马字标准化和自我对话生成的质量控制合成数据进行结构化提示引导。

Result: 在Gemini 2.0 Flash、GPT-4o和Llama 3.1 70B三款模型上，词汇污染率从80%降至5%，语法准确率达85%。负约束带来12-18个百分点提升，语法文档效果因模型结构不同而异，提升8-22个百分点。

Conclusion: 利用结构化提示结合语法引导及负约束策略，能有效提高大型语言模型在低资源语言上的对话表现，且不同模型对策略敏感度存在差异。

Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than fine-tuning an LLM, we examine whether structured prompts alone can elicit basic conversational ability under controlled prompting. We systematically tackle various challenges posed by absence of training data for Tulu by combining explicit grammar documentation, negative constraints to suppress high-probability tokens from related languages, romanization standardization, and quality-controlled synthetic data generation via self-play. Evaluated on a manually curated held-out set across three LLMs (Gemini 2.0 Flash, GPT-4o, Llama 3.1 70B) and validated by native speakers, our approach reduces vocabulary contamination from 80% to 5% while achieving 85% grammatical accuracy. Cross-model analysis reveals that negative constraints provide consistent improvements (12--18 percentage points), while grammar documentation effects vary by model architecture (8--22 points).

</details>


### [13] [The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems](https://arxiv.org/abs/2602.15382)
*Xiaoze Liu,Ruowang Zhang,Weichen Yu,Siheng Xiong,Liu He,Feijie Wu,Hoin Jung,Matt Fredrikson,Xiaoqian Wang,Jing Gao*

Main category: cs.CL

TL;DR: 本文提出了一种基于视觉接口的多智能体无文本通信框架Vision Wormhole，通过共享视觉潜在空间实现高效异构模型间通信，降低通信复杂度，提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）利用大型语言模型实现高级协作推理，但传统的离散文本通信效率低，导致运行时间长且信息量损失严重。现有的潜在状态传输方法要么假设发送端和接收端架构同质，要么依赖于特定的转换器，限制了系统的可扩展性和模块化。

Method: 利用视觉语言模型的视觉编码器作为通用端口，通过设计通用视觉编码器，将不同模型的推理信息映射到共享连续潜在空间，采用以中心辐射拓扑降低复杂度，并结合无标签的师生蒸馏目标对视觉通道和文本通道进行对齐。

Result: 提出了Vision Wormhole框架，通过视觉语言模型的视觉接口实现模型无关的无文本通信，将异构的推理轨迹映射到共享的连续潜在空间，并将其注入接收端视觉路径，显著降低了配对对齐复杂度，从而减少了运行时间，同时保持了推理的准确性。

Conclusion: Vision Wormhole框架有效解决了异构多智能体系统中通信效率和可扩展性的问题，实现了快速且高保真的推理协作，展示了视觉接口作为通用通信端口的潜力。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information quantization loss. While latent state transfer offers a high-bandwidth alternative, existing approaches either assume homogeneous sender-receiver architectures or rely on pair-specific learned translators, limiting scalability and modularity across diverse model families with disjoint manifolds. In this work, we propose the Vision Wormhole, a novel framework that repurposes the visual interface of Vision-Language Models (VLMs) to enable model-agnostic, text-free communication. By introducing a Universal Visual Codec, we map heterogeneous reasoning traces into a shared continuous latent space and inject them directly into the receiver's visual pathway, effectively treating the vision encoder as a universal port for inter-agent telepathy. Our framework adopts a hub-and-spoke topology to reduce pairwise alignment complexity from O(N^2) to O(N) and leverages a label-free, teacher-student distillation objective to align the high-speed visual channel with the robust reasoning patterns of the text pathway. Extensive experiments across heterogeneous model families (e.g., Qwen-VL, Gemma) demonstrate that the Vision Wormhole reduces end-to-end wall-clock time in controlled comparisons while maintaining reasoning fidelity comparable to standard text-based MAS. Code is available at https://github.com/xz-liu/heterogeneous-latent-mas

</details>


### [14] [Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs](https://arxiv.org/abs/2602.15436)
*Joonatan Laato,Veera Schroderus,Jenna Kanerva,Jenni Kauppi,Virpi Lummaa,Filip Ginter*

Main category: cs.CL

TL;DR: 本文针对芬兰二战期间卡累利阿撤离家庭访谈中大量提取的活动和组织信息，设计了一套参与度分类框架，并利用大型语言模型进行自动标注，最终生成了一份结构化资源供社会学研究使用。


<details>
  <summary>Details</summary>
Motivation: 直接从大量历史文本中提取的信息过于繁杂，难以满足历史学家和社会学家的定量研究需求，需要一种方法将这些数据系统化、结构化以便深入分析。

Method: 设计了涵盖活动类型、社会属性、频率及身体要求的分类框架，使用注释的金标准数据评估大型语言模型的标注效果，并通过多次投票提高自动标注的准确性，最终在35万条实体数据上应用该方法。

Result: 开发的分类体系和基于大型语言模型的自动标注方法表现接近专家判断，成功标注了35万个实体，形成可供后续研究使用的结构化数据资源。

Conclusion: 通过构建分类框架并结合大型语言模型的自动标注，成功将大量杂乱的文本实体数据转化为结构化资源，促进了社会整合及相关研究的量化分析。

Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a quantitative manner. We address this problem in a large collection of Finnish World War II Karelian evacuee family interviews. Prior work extracted more than 350K mentions of leisure time activities and organizational memberships from these interviews, yielding 71K unique activity and organization names -- far too many to analyze directly.
  We develop a categorization framework that captures key aspects of participation (the kind of activity/organization, how social it typically is, how regularly it happens, and how physically demanding it is). We annotate a gold-standard set to allow for a reliable evaluation, and then test whether large language models can apply the same schema at scale. Using a simple voting approach across multiple model runs, we find that an open-weight LLM can closely match expert judgments. Finally, we apply the method to label the 350K entities, producing a structured resource for downstream studies of social integration and related outcomes.

</details>


### [15] [In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations](https://arxiv.org/abs/2602.15456)
*Mohammad Aflah Khan,Mahsa Amani,Soumi Das,Bishwamittra Ghosh,Qinyuan Wu,Krishna P. Gummadi,Manish Gupta,Abhilasha Ravichander*

Main category: cs.CL

TL;DR: LLM代理在选择信息来源时存在系统性的偏好，这种偏好影响信息呈现，需深入研究并提供用户透明度和控制手段。


<details>
  <summary>Details</summary>
Motivation: 目前对LLM生成信息的偏见关注较多，但对LLM选择和呈现给用户的信息来源偏好关注较少，探索来源偏好的潜在系统性和其影响。

Method: 通过对六家模型提供商的十二个大语言模型(LLMs)进行控制实验，涵盖合成和现实世界任务，分析模型在信息来源选择中的偏好。

Result: 发现多个模型普遍存在强烈且可预测的来源偏好，这种偏好受上下文影响大，甚至超过内容本身，且在明确提示避免偏见时仍存在。

Conclusion: 研究表明LLM在信息来源选择上存在固有偏好，建议深入探究其起因，并开发机制增强用户对这些偏见的透明度和控制。

Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs themselves generate, less attention has been paid to the factors that influence what information LLMs select and present to users. We hypothesize that when information is attributed to specific sources (e.g., particular publishers, journals, or platforms), current LLMs exhibit systematic latent source preferences- that is, they prioritize information from some sources over others. Through controlled experiments on twelve LLMs from six model providers, spanning both synthetic and real-world tasks, we find that several models consistently exhibit strong and predictable source preferences. These preferences are sensitive to contextual framing, can outweigh the influence of content itself, and persist despite explicit prompting to avoid them. They also help explain phenomena such as the observed left-leaning skew in news recommendations in prior work. Our findings advocate for deeper investigation into the origins of these preferences, as well as for mechanisms that provide users with transparency and control over the biases guiding LLM-powered agents.

</details>


### [16] [Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit](https://arxiv.org/abs/2602.15504)
*Aswathy Velutharambath,Amelie Wührl*

Main category: cs.CL

TL;DR: 本文首次提出期望检测任务，通过构建和标注Reddit医疗帖子语料，分析患者在线表达的治疗期望，揭示了不同疾病类别下的语言模式和期望内容。


<details>
  <summary>Details</summary>
Motivation: 患者对治疗的期望对治疗效果有重要影响，但现有研究多集中于临床环境，缺乏对在线患者平台（如医疗相关的Reddit子版块）中表达的期望的研究。本文认为这些在线表达可能包含患者在其他场合难以分享的期望信息。鉴于自然语言处理领域尚未针对期望进行研究，本文提出了期望检测任务。

Method: 在医疗领域开展案例研究，构建了RedHOTExpect数据集（包含4500条Reddit帖子），利用大型语言模型进行银标准标注并手工验证标签准确率约为78%，分析了期望表达的语言模式及患者期望的内容和原因。

Result: 发现身体或治疗相关疾病的帖子中乐观和积极主动的表达更为明显，且患者更多讨论治疗的益处而非负面结果。

Conclusion: 提出的期望检测任务及RedHOTExpect语料库为研究患者在线表达的治疗期望提供了新的资源和分析视角，有助于改进意见挖掘和产品设计等应用。

Abstract: Patients' expectations towards their treatment have a substantial effect on the treatments' success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations that patients feel unnecessary or uncomfortable to share elsewhere. Despite this, no studies examine what type of expectations users discuss online and how they express them. Presumably this is because expectations have not been studied in natural language processing (NLP) before. Therefore, we introduce the task of Expectation Detection, arguing that expectations are relevant for many applications, including opinion mining and product design. Subsequently, we present a case study for the medical domain, where expectations are particularly crucial to extract. We contribute RedHOTExpect, a corpus of Reddit posts (4.5K posts) to study expectations in this context. We use a large language model (LLM) to silver-label the data and validate its quality manually (label accuracy ~78%). Based on this, we analyze which linguistic patterns characterize expectations and explore what patients expect and why. We find that optimism and proactive framing are more pronounced in posts about physical or treatment-related illnesses compared to mental-health contexts, and that in our dataset, patients mostly discuss benefits rather than negative outcomes. The RedHOTExpect corpus can be obtained from https://www.ims.uni-stuttgart.de/data/RedHOTExpect

</details>


### [17] [LuxMT Technical Report](https://arxiv.org/abs/2602.15506)
*Nils Rehlinger*

Main category: cs.CL

TL;DR: LuxMT基于Gemma 3模型，通过微调和数据过滤显著提升了卢森堡语向法语和英语的机器翻译性能，并探索了质量评估指标LuxEmbedder的应用。


<details>
  <summary>Details</summary>
Motivation: 针对卢森堡语资源匮乏和翻译难题，开发有效的机器翻译系统，并构建可信赖的评测基准，以提升翻译质量和评估指标的可靠性。

Method: 使用Gemma 3 27B模型进行微调，构建包含人工翻译的基准测试集。训练数据来源于LuxAlign多语种新闻语料及卢森堡议会记录，辅以Google Translate数据。通过LuxEmbedder生成的句子嵌入对数据进行过滤，去除低相关性数据。

Result: LuxMT是一种基于Gemma 3 27B模型的机器翻译系统，专门针对卢森堡语翻译成法语和英语进行了微调。该系统通过创建包含卢森堡语-法语、卢森堡语-英语的人工翻译数据的新基准进行评估，训练数据来源于LuxAlign平行语料和卢森堡议会记录，并使用LuxEmbedder进行数据过滤。LuxMT相比基线模型Gemma 3表现出了显著提升，甚至对卢森堡语到德语的翻译也有所改进。研究还探讨了LuxEmbedder作为翻译质量估计指标的潜力，但指出仍需进一步研究确认其实用性。

Conclusion: LuxMT在卢森堡语到法语和英语的翻译任务中表现出显著优势，证明了微调和数据过滤的重要性，LuxEmbedder展现了作为质量估计指标的潜力，但需谨慎使用并进一步验证。

Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN, and LB-FR using human-translated data from Luci, a tourist magazine about Luxembourg. Training data stems from LuxAlign, a parallel corpus of multilingual Luxembourgish news articles, and LB parliamentary transcripts augmented with Google Translate. We filter the data using LuxEmbedder, LB sentence embeddings, to remove low-equivalence segment-pairs. Overall, LuxMT's results suggest strong improvements over the Gemma 3 baseline, even for translating LB to German (DE), despite the training data not containing any DE. We also explore LuxEmbedder's potential to be used as a quality estimation metric and find strong correlations with other reference-based metrics. However, we call for further research to fully assess the metric's utility and advise using it with caution.

</details>


### [18] [Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination](https://arxiv.org/abs/2602.15509)
*Xiangyan Chen,Yujian Gan,Matthew Purver*

Main category: cs.CL

TL;DR: 本文提出Fine-Refine框架，通过将对话生成的回答分解成原子单元并逐一验证，以细粒度方式提升大语言模型生成对话的事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在对话中易产生幻觉，导致输出不实信息，且传统方法多在整体回答层面修正，忽视单个回答中可能包含的多个事实单元的验证需要。

Method: 该方法将回复拆解为细粒度的原子事实单元，利用外部知识进行验证，并基于困惑度评价流畅性，通过迭代机制进行精细修正。

Result: Fine-Refine在两个数据集上提升了事实准确率和覆盖率，表现出明显优于现有方法的效果，增强了系统的可靠性。

Conclusion: Fine-Refine显著提升了对话系统生成回答的事实准确性，在HybriDialogue和OpendialKG数据集上，事实评分提升最多达7.63分，尽管对话质量有轻微影响。

Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for dialogue systems typically operate at the response level, overlooking the fact that a single response may contain multiple verifiable or unverifiable facts. To address this gap, we propose Fine-Refine, a fine-grained refinement framework that decomposes responses into atomic units, verifies each unit using external knowledge, assesses fluency via perplexity, and iteratively corrects granular errors. We evaluate factuality across the HybriDialogue and OpendialKG datasets in terms of factual accuracy (fact score) and coverage (Not Enough Information Proportion), and experiments show that Fine-Refine substantially improves factuality, achieving up to a 7.63-point gain in dialogue fact score, with a small trade-off in dialogue quality.

</details>


### [19] [DependencyAI: Detecting AI Generated Text through Dependency Parsing](https://arxiv.org/abs/2602.15514)
*Sara Ahmed,Tracy Hammond*

Main category: cs.CL

TL;DR: 提出基于语言依存关系的可解释AI文本检测方法，表现优良且揭示了生成器风格对跨域影响。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型普及，迫切需要可靠且可解释的AI生成文本检测方法，以降低潜在风险。

Method: 利用语言依存关系标签的特征，分析其重要性，构建无需神经网络的检测模型，并在多种语言及生成器环境中测试其有效性。

Result: 本文提出了DependencyAI，一种仅基于语言依存关系标签的简单且可解释的AI生成文本检测方法。该方法在单语种、多生成器和多语种环境中表现出竞争力。通过分析特征重要性，揭示了区分AI生成文本与人类文本的句法结构。同时发现某些模型在未见领域上存在系统性过度预测，提示生成器特定的写作风格影响跨域泛化。总体而言，依存关系特征为AI文本检测提供了可靠信号，使DependencyAI成为一个强有力、基于语言学且非神经网络的基线方法。

Conclusion: 依存关系特征足以作为可靠且可解释的AI生成文本检测信号，且该方法具有良好的泛化能力和解释性。

Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text using only the labels of linguistic dependency relations. Our method achieves competitive performance across monolingual, multi-generator, and multilingual settings. To increase interpretability, we analyze feature importance to reveal syntactic structures that distinguish AI-generated from human-written text. We also observe a systematic overprediction of certain models on unseen domains, suggesting that generator-specific writing styles may affect cross-domain generalization. Overall, our results demonstrate that dependency relations alone provide a robust signal for AI-generated text detection, establishing DependencyAI as a strong linguistically grounded, interpretable, and non-neural network baseline.

</details>


### [20] [ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns](https://arxiv.org/abs/2602.15521)
*Ziyu Zhao,Tong Zhu,Zhi Zhang,Tiantian Fan,Jinluan Yang,Kun Kuang,Zhongyu Wei,Fei Wu,Yu Cheng*

Main category: cs.CL

TL;DR: 本文提出了ExpertWeaver，一种基于GLU激活模式，将预训练密集模型转换为稀疏MoE架构的无训练框架。


<details>
  <summary>Details</summary>
Motivation: 高质量MoE训练成本高，现有方法破坏了密集模型的内在激活模式，导致专家构造效果不佳，需寻找更合理转换方法。

Method: 研究GLU的细粒度神经元激活模式，揭示MoE结构，基于该结构划分神经元，构建共享专家和专属专家，形成层自适应配置，完成无训练转换。

Result: ExpertWeaver在性能上显著优于现有动态结构剪枝和稀疏初始化方法，实现高效且高质量的稀疏MoE构建。

Conclusion: ExpertWeaver通过利用GLU的激活模式，显著优于现有稠密模型到MoE转换方法，无论作为无训练结构剪枝还是下循环策略。

Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert pretrained dense models into sparse MoEs. Existing dense-to-MoE methods fall into two categories: \textbf{dynamic structural pruning} that converts dense models into MoE architectures with moderate sparsity to balance performance and inference efficiency, and \textbf{downcycling} approaches that use pretrained dense models to initialize highly sparse MoE architectures. However, existing methods break the intrinsic activation patterns within dense models, leading to suboptimal expert construction. In this work, we argue that the Gated Linear Unit (GLU) mechanism provides a natural blueprint for dense-to-MoE conversion. We show that the fine-grained neural-wise activation patterns of GLU reveal a coarse-grained structure, uncovering an inherent MoE architecture composed of consistently activated universal neurons and dynamically activated specialized neurons. Leveraging this discovery, we introduce ExpertWeaver, a training-free framework that partitions neurons according to their activation patterns and constructs shared experts and specialized routed experts with layer-adaptive configurations. Our experiments demonstrate that ExpertWeaver significantly outperforms existing methods, both as a training-free dynamic structural pruning technique and as a downcycling strategy for superior MoE initialization.

</details>


### [21] [ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling](https://arxiv.org/abs/2602.15537)
*Nicol Visser,Simon Malan,Danel Slabbert,Herman Kamper*

Main category: cs.CL

TL;DR: ZeroSyl通过简单无训练方法从WavLM模型中提取音节单位，有效解决了序列过长及复杂训练流程问题，提升了音节分割及语言模型性能，尤其在句法建模方面表现出更好扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统基于自监督语音编码器的离散音素表示序列过长，且现有方法如Sylber和SyllableLM依赖复杂的多阶段训练流程，需简化且提高效率。

Method: 提出了ZeroSyl，一种基于冻结的WavLM模型的无训练多阶段方法，利用WavLM中间层特征的L2范数直接提取音节边界和嵌入。将提取的音节进行均值池化和K-means离散化后，用于训练语言模型。

Result: ZeroSyl在音节分割任务中表现优异，超过了先前音节分词器；在词汇、句法和叙事基准测试中均表现更优；扩展性实验显示其发现的音节单位在句法建模任务中具有更好的扩展性。

Conclusion: ZeroSyl作为一种训练免费且简单的方法，能够有效提取音节单位并应用于语言模型，显著超越先前基于音节的编码器，推动纯语音语言模型研究的发展。

Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on syllable-like units. However, methods like Sylber and SyllableLM rely on intricate multi-stage training pipelines. We propose ZeroSyl, a simple training-free method to extract syllable boundaries and embeddings directly from a frozen WavLM model. Using L2 norms of features in WavLM's intermediate layers, ZeroSyl achieves competitive syllable segmentation performance. The resulting segments are mean-pooled, discretized using K-means, and used to train a language model. ZeroSyl outperforms prior syllabic tokenizers across lexical, syntactic, and narrative benchmarks. Scaling experiments show that while finer-grained units are beneficial for lexical tasks, our discovered syllabic units exhibit better scaling behavior for syntactic modeling.

</details>


### [22] [Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite](https://arxiv.org/abs/2602.15540)
*Tim Fischer,Chris Biemann*

Main category: cs.CL

TL;DR: 本文介绍了Perspectives，一套交互式的数字人文文本聚类和分析工具，利用人机交互提升文档探索和组织能力。


<details>
  <summary>Details</summary>
Motivation: 帮助数字人文研究者更好地探索和组织大量非结构化文档，提升大规模文本分析的效率和深度。

Method: 采用灵活多面的文档聚类流程，结合人机交互的细化功能，通过文档重写提示和基于指令的嵌入定义分析视角，并通过聚类工具和嵌入模型微调进一步对齐用户意图。

Result: 开发了Perspectives，扩展了话语分析工具套件，实现了交互式文档地图和多维聚类，支持主题、情感等分类的探索和分析准备。

Conclusion: Perspectives有效增强了数字人文研究者处理大规模非结构化文档的能力，通过交互式聚类和模型微调实现灵活多面的数据组织和深入分析准备。

Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a flexible, aspect-focused document clustering pipeline with human-in-the-loop refinement capabilities. We showcase how this process can be initially steered by defining analytical lenses through document rewriting prompts and instruction-based embeddings, and further aligned with user intent through tools for refining clusters and mechanisms for fine-tuning the embedding model. The demonstration highlights a typical workflow, illustrating how DH researchers can leverage Perspectives's interactive document map to uncover topics, sentiments, or other relevant categories, thereby gaining insights and preparing their data for subsequent in-depth analysis.

</details>


### [23] [jina-embeddings-v5-text: Task-Targeted Embedding Distillation](https://arxiv.org/abs/2602.15547)
*Mohammad Kalim Akram,Saba Sturua,Nastia Havriushenko,Quentin Herreros,Michael Günther,Maximilian Werk,Han Xiao*

Main category: cs.CL

TL;DR: 通过结合蒸馏和对比损失的训练方法，提升了小型文本嵌入模型的性能，模型支持多语言和长文本，效果达到最新水平。


<details>
  <summary>Details</summary>
Motivation: 提升小型文本嵌入模型的性能，使其在相似度任务中表现更好

Method: 结合模型蒸馏与任务特定的对比损失训练小型文本嵌入模型

Result: 训练出两个高性能小型嵌入模型（jina-embeddings-v5-text-small和nano），在同类大小模型中达到或超过最新技术水平，支持多语言和长文本（最多32k tokens），对截断和二进制量化具有鲁棒性

Conclusion: 该方法证明在训练小型文本嵌入模型时优于单一对比损失或蒸馏训练，模型公开发布，有助于推动嵌入模型发展。

Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions. We introduce a novel training regimen that combines model distillation techniques with task-specific contrastive loss to produce compact, high-performance embedding models. Our findings suggest that this approach is more effective for training small models than purely contrastive or distillation-based training paradigms alone. Benchmark scores for the resulting models, jina-embeddings-v5-text-small and jina-embeddings-v5-text-nano, exceed or match the state-of-the-art for models of similar size. jina-embeddings-v5-text models additionally support long texts (up to 32k tokens) in many languages, and generate embeddings that remain robust under truncation and binary quantization. Model weights are publicly available, hopefully inspiring further advances in embedding model development.

</details>


### [24] [Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL](https://arxiv.org/abs/2602.15564)
*Yihan Wang,Peiyu Liu,Runyu Chen,Wei Xu*

Main category: cs.CL

TL;DR: 本文通过强化学习提出动态工作流程构建框架SquRL，解决了Text-to-SQL应用中静态流程适应性差的问题，实现更优性能。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL方法依赖单一静态工作流程，难以适应长尾和分布外场景，用户需要耗费大量时间选择合适的方法。

Method: 设计了基于强化学习的SquRL框架，通过规则奖励函数和两种训练机制（动态行为者屏蔽和伪奖励）提升大模型在动态构建工作流程中的推理能力。

Result: 动态策略在理论和实证中均优于最优静态策略，且在多个Text-to-SQL基准测试中表现出一致提升。

Conclusion: 本文提出的动态工作流程构建方法显著优于最优静态工作流程，尤其在复杂和分布外查询上表现出明显优势。

Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and long-tail scenarios. Instead of requiring users to select suitable methods through extensive experimentation, we attempt to enable systems to adaptively construct workflows at inference time. Through theoretical and empirical analysis, we demonstrate that optimal dynamic policies consistently outperform the best static workflow, with performance gains fundamentally driven by heterogeneity across candidate workflows. Motivated by this, we propose SquRL, a reinforcement learning framework that enhances LLMs' reasoning capability in adaptive workflow construction. We design a rule-based reward function and introduce two effective training mechanisms: dynamic actor masking to encourage broader exploration, and pseudo rewards to improve training efficiency. Experiments on widely-used Text-to-SQL benchmarks demonstrate that dynamic workflow construction consistently outperforms the best static workflow methods, with especially pronounced gains on complex and out-of-distribution queries. The codes are available at https://github.com/Satissss/SquRL

</details>


### [25] [Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations](https://arxiv.org/abs/2602.15578)
*Chaithra Nerella,Chiranjeevi Yarra*

Main category: cs.CL

TL;DR: 本文提出一种基于症状引导的语音抑郁症严重程度估计框架，通过交叉注意力机制对症状特异性信息进行建模，提高了预测的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多将抑郁症预测作为二分类或整体评分，缺乏对具体症状的建模，限制了临床级别的症状分析能力。

Method: 设计了一个症状引导的交叉注意力机制，将PHQ-8问卷项目与情感感知的语音表示对齐，同时引入可学习的症状特异性参数以调节注意力分布的敏锐度。

Result: 在标准临床数据集EDAIC上，方法优于以往工作；注意力分布分析表明模型能捕捉多种症状相关线索，增强了解释性。

Conclusion: 基于症状引导和情感感知的语音模型显著提升了抑郁症严重程度预测性能，并具备更高的临床解释性。

Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without explicitly modeling symptom-specific information. This limits their ability to provide symptom-level analysis relevant to clinical screening. To address this, we propose a symptom-specific and clinically inspired framework for depression severity estimation from speech. Our approach uses a symptom-guided cross-attention mechanism that aligns PHQ-8 questionnaire items with emotion-aware speech representations to identify which segments of a participant's speech are more important to each symptom. To account for differences in how symptoms are expressed over time, we introduce a learnable symptom-specific parameter that adaptively controls the sharpness of attention distributions. Our results on EDAIC, a standard clinical-style dataset, demonstrate improved performance outperforming prior works. Further, analyzing the attention distributions showed that higher attention is assigned to utterances containing cues related to multiple depressive symptoms, highlighting the interpretability of our approach. These findings outline the importance of symptom-guided and emotion-aware modeling for speech-based depression screening.

</details>


### [26] [STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens](https://arxiv.org/abs/2602.15620)
*Shiqi Liu,Zeyu He,Guojian Zhan,Letian Tao,Zhilong Zheng,Jiang Wu,Yinuo Wang,Yang Guan,Kehua Sheng,Bo Zhang,Keqiang Li,Jingliang Duan,Shengbo Eben Li*

Main category: cs.CL

TL;DR: 本文分析了强化学习中训练不稳定的根源——极少数伪造令牌，通过提出STAPO方法选择性遮蔽异常梯度，实现了大语言模型推理性能和训练稳定性的显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习微调方法依赖启发式技术如熵正则化和重加权，训练过程中易出现后期性能崩溃，导致推理质量下降和训练不稳定。研究发现训练不稳定主要由极少数约0.01%的伪造令牌引起，这些令牌在正确回答中贡献少但继承了全序列奖励，导致梯度更新异常放大。

Method: 提出了Spurious-Token-Aware Policy Optimization (STAPO)方法，通过识别并遮蔽对训练不稳定贡献巨大的“伪造令牌”，并对有效令牌重新归一化损失，改进了大规模语言模型的强化学习微调。

Result: 在六个数学推理基准上，使用Qwen 1.7B、8B和14B模型，STAPO方法表现出更优的熵稳定性，平均性能提升7.13%，优于GRPO、20-Entropy和JustRL方法。

Conclusion: STAPO方法有效解决了强化学习微调中由伪造令牌引起的训练不稳定问题，显著提升了大规模语言模型的数学推理性能和训练稳定性。

Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they often experience late-stage performance collapse, leading to degraded reasoning quality and unstable training. We derive that the magnitude of token-wise policy gradients in RL is negatively correlated with token probability and local policy entropy. Building on this result, we prove that training instability is driven by a tiny fraction of tokens, approximately 0.01\%, which we term \emph{spurious tokens}. When such tokens appear in correct responses, they contribute little to the reasoning outcome but inherit the full sequence-level reward, leading to abnormally amplified gradient updates. Motivated by this observation, we propose Spurious-Token-Aware Policy Optimization (STAPO) for large-scale model refining, which selectively masks such updates and renormalizes the loss over valid tokens. Across six mathematical reasoning benchmarks using Qwen 1.7B, 8B, and 14B base models, STAPO consistently demonstrates superior entropy stability and achieves an average performance improvement of 7.13\% over GRPO, 20-Entropy and JustRL.

</details>


### [27] [LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models](https://arxiv.org/abs/2602.15675)
*Ahmed Khaled Khamis,Hesham Ali*

Main category: cs.CL

TL;DR: 该论文介绍了NileTTS数据集，解决了埃及阿拉伯语TTS资源匮乏的问题，使用大语言模型生成内容并通过合成语音和自动转录构建数据集，微调多语言TTS模型取得较好表现。


<details>
  <summary>Details</summary>
Motivation: 埃及阿拉伯语作为最广泛理解的阿拉伯语方言，缺乏充足的语音合成资源，亟需构建公开高质量数据集。

Method: 利用大语言模型生成埃及阿拉伯语文本，使用音频合成工具合成自然语音，自动转录和说话人分离完成标注，再对XTTS v2模型进行微调。

Result: 构建了38小时涵盖多领域的埃及阿拉伯语转录语音数据，微调后的多语言TTS模型在埃及方言上优于其他阿拉伯方言模型。

Conclusion: 本文首次公开了埃及阿拉伯语TTS数据集，提出了可复现的合成数据生成流程，并发布了开源微调模型，促进埃及阿拉伯语语音合成研究。

Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood Arabic dialect -- severely under-resourced. We address this gap by introducing NileTTS: 38 hours of transcribed speech from two speakers across diverse domains including medical, sales, and general conversations. We construct this dataset using a novel synthetic pipeline: large language models (LLM) generate Egyptian Arabic content, which is then converted to natural speech using audio synthesis tools, followed by automatic transcription and speaker diarization with manual quality verification. We fine-tune XTTS v2, a state-of-the-art multilingual TTS model, on our dataset and evaluate against the baseline model trained on other Arabic dialects. Our contributions include: (1) the first publicly available Egyptian Arabic TTS dataset, (2) a reproducible synthetic data generation pipeline for dialectal TTS, and (3) an open-source fine-tuned model. All resources are released to advance Egyptian Arabic speech synthesis research.

</details>


### [28] [Revisiting Northrop Frye's Four Myths Theory with Large Language Models](https://arxiv.org/abs/2602.15678)
*Edirlei Soares de Lima,Marco A. Casanova,Antonio L. Furtado*

Main category: cs.CL

TL;DR: 本文基于荣格原型理论和弗莱的叙事类型，提出角色功能框架，并通过大型语言模型验证其有效性，推动了计算叙事学发展。


<details>
  <summary>Details</summary>
Motivation: 北洛普·弗莱的四大叙事类型理论在文学批评中有深远影响，但现有计算方法多聚焦于叙事模式，忽视了角色功能的研究。

Method: 基于荣格心理结构映射提出四个基础角色功能，结合十六个类型特定角色；通过六个大型语言模型对40个叙事作品中的角色对应性进行多模型验证，包含有效和无效样本。

Result: 提出了一个基于荣格原型理论的四个普遍角色功能框架，并细化为十六个类型相关角色。通过六个大型语言模型对四十个叙事作品的角色-类型对应进行验证，模型表现优异，平均平衡准确率达82.5%。

Conclusion: 该角色功能框架有效捕获了叙事结构中的系统性模式，表现出不同叙事类型和角色的特性差异，为未来叙事生成和交互式故事讲述应用奠定基础。

Abstract: Northrop Frye's theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than character functions. In this paper, we present a new character function framework that complements pattern-based analysis by examining how archetypal roles manifest differently across Frye's genres. Drawing on Jungian archetype theory, we derive four universal character functions (protagonist, mentor, antagonist, companion) by mapping them to Jung's psychic structure components. These functions are then specialized into sixteen genre-specific roles based on prototypical works. To validate this framework, we conducted a multi-model study using six state-of-the-art Large Language Models (LLMs) to evaluate character-role correspondences across 40 narrative works. The validation employed both positive samples (160 valid correspondences) and negative samples (30 invalid correspondences) to evaluate whether models both recognize valid correspondences and reject invalid ones. LLMs achieved substantial performance (mean balanced accuracy of 82.5%) with strong inter-model agreement (Fleiss' $κ$ = 0.600), demonstrating that the proposed correspondences capture systematic structural patterns. Performance varied by genre (ranging from 72.7% to 89.9%) and role (52.5% to 99.2%), with qualitative analysis revealing that variations reflect genuine narrative properties, including functional distribution in romance and deliberate archetypal subversion in satire. This character-based approach demonstrates the potential of LLM-supported methods for computational narratology and provides a foundation for future development of narrative generation methods and interactive storytelling applications.

</details>


### [29] [A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models](https://arxiv.org/abs/2602.15689)
*Meirav Segal,Noa Linder,Omer Antverg,Gil Gekker,Tomer Fichman,Omri Bodenheimer,Edan Maor,Omer Nevo*

Main category: cs.CL

TL;DR: 本文提出一个基于内容和攻防权衡的网络安全拒绝策略框架，提升了拒绝决策的准确性和灵活性，解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有针对网络安全任务的拒绝机制依赖广泛的主题禁令或攻击分类，导致决策不一致、过度限制合法用户，并在混淆或请求分割条件下表现脆弱。

Method: 提出了一个基于内容的框架，通过五个维度（攻击行为贡献、攻击风险、技术复杂性、防御收益、合法用户的预期频率）明确体现攻防权衡，用以设计和审计拒绝策略。

Result: 所提出框架解决了现有模型行为中的不一致性，允许组织构建可调节的、风险感知的拒绝策略。

Conclusion: 在网络安全任务中，有效的拒绝机制应基于内容和风险权衡而非单纯意图识别，才能更精准、公正地管理使用行为。

Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate defenders, and behave brittlely under obfuscation or request segmentation. We argue that effective refusal requires explicitly modeling the trade-off between offensive risk and defensive benefit, rather than relying solely on intent or offensive classification. In this paper, we introduce a content-based framework for designing and auditing cyber refusal policies that makes offense-defense tradeoffs explicit. The framework characterizes requests along five dimensions: Offensive Action Contribution, Offensive Risk, Technical Complexity, Defensive Benefit, and Expected Frequency for Legitimate Users, grounded in the technical substance of the request rather than stated intent. We demonstrate that this content-grounded approach resolves inconsistencies in current frontier model behavior and allows organizations to construct tunable, risk-aware refusal policies.

</details>


### [30] [Rethinking Metrics for Lexical Semantic Change Detection](https://arxiv.org/abs/2602.15716)
*Roksana Goworek,Haim Dubossarsky*

Main category: cs.CL

TL;DR: 提出新的语义变化度量AMD和SAMD，改善了基于语境化嵌入的语义变化检测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有词汇语义变化检测主要依赖于语境化语言模型嵌入，但通常仅使用有限的语义变化度量指标，如平均成对距离（APD）和词原型余弦距离（PRT），这可能限制了测量的准确性和鲁棒性。

Method: 本文提出了新的度量方法——平均最小距离（AMD）和对称平均最小距离（SAMD），通过跨时间段词用法的局部对应关系来量化语义变化。

Result: 实验证明，在多语言、多编码器模型和不同表示空间上，AMD在降维和非专化编码器条件下表现更为稳健，而SAMD在专化编码器上表现优异。

Conclusion: 研究表明，词汇语义变化检测应考虑除APD和PRT以外的度量方法，AMD提供了基于语境化嵌入分析的稳健选项。

Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine distance over word prototypes (PRT). We introduce Average Minimum Distance (AMD) and Symmetric Average Minimum Distance (SAMD), new measures that quantify semantic change via local correspondence between word usages across time periods. Across multiple languages, encoder models, and representation spaces, we show that AMD often provides more robust performance, particularly under dimensionality reduction and with non-specialised encoders, while SAMD excels with specialised encoders. We suggest that LSCD may benefit from considering alternative semantic change metrics beyond APD and PRT, with AMD offering a robust option for contextualised embedding-based analysis.

</details>


### [31] [Causal Effect Estimation with Latent Textual Treatments](https://arxiv.org/abs/2602.15730)
*Omri Feldman,Amar Venugopal,Jann Spiess,Amir Feder*

Main category: cs.CL

TL;DR: 本文提出了一种结合稀疏自编码器和协变量残差化的端到端管道，用于准确估计文本对结果的因果效应，显著减少了估计偏差。


<details>
  <summary>Details</summary>
Motivation: 理解文本对下游结果的因果效应是多个应用中的核心任务，但估计此类效应需要系统地变更文本特征的对照实验，且文本的处理复杂且易产生偏差。

Method: 提出了一个端到端的管道，利用稀疏自编码器（SAEs）进行假设生成和引导，然后进行稳健的因果估计，并通过协变量残差化解决文本处理中的估计偏差问题。

Result: 该管道有效引入了目标特征的变异，降低了估计误差，显著缓解了由于文本自身特征导致的因果估计偏差。

Conclusion: 所提方法为文本作为处理的因果效应估计提供了坚实且稳健的基础，能够克服传统方法中偏差和统计计算难题。

Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models (LLMs) hold promise for generating text, producing and evaluating controlled variation requires more careful attention. In this paper, we present an end-to-end pipeline for the generation and causal estimation of latent textual interventions. Our work first performs hypothesis generation and steering via sparse autoencoders (SAEs), followed by robust causal estimation. Our pipeline addresses both computational and statistical challenges in text-as-treatment experiments. We demonstrate that naive estimation of causal effects suffers from significant bias as text inherently conflates treatment and covariate information. We describe the estimation bias induced in this setting and propose a solution based on covariate residualization. Our empirical results show that our pipeline effectively induces variation in target features and mitigates estimation error, providing a robust foundation for causal effect estimation in text-as-treatment settings.

</details>


### [32] [Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac](https://arxiv.org/abs/2602.15753)
*Chahan Vidal-Gorène,Bastien Kindt,Florian Cafiero*

Main category: cs.CL

TL;DR: 本文研究大型语言模型在四种低资源语言词形还原和词性标注中的性能，发现LLMs在少样本设置下表现优异，是低资源语言注释的有效工具。


<details>
  <summary>Details</summary>
Motivation: 低资源语言在自然语言处理任务中存在数据稀缺挑战，本文旨在探索最新大型语言模型在缺乏训练数据情况下，能否有效支持这些语言的词形还原和词性标注任务。

Method: 采用新构建的基准语料，包括对齐的训练和跨域测试集，评估GPT-4及Mistral等大型语言模型和基于RNN的PIE基线模型在词形还原和词性标注任务的性能，比较少样本和零样本设置下的效果。

Result: 本文评估了大型语言模型（LLMs），如GPT-4和Mistral模型，在古希腊语、古亚美尼亚语、古格鲁吉亚语和叙利亚语等低资源语言的词形还原和词性标注任务中的表现，特别是在少量样本和零样本设置下。通过一个包含训练语料和跨域测试语料的新基准，比较了LLMs与任务特定的RNN基线（PIE）的表现。结果显示，LLMs即使不进行微调，在大多数语言的少样本任务中词性标注和词形还原上均表现优异或有竞争力。复杂形态和非拉丁字符语言仍面临挑战，但LLMs作为无数据环境下启动语言学注释任务的有力工具，证明了其可靠性和实用性。

Conclusion: 大型语言模型即使无微调情况下，在低资源语言的词形还原和词性标注任务中表现竞争力，且可作为无数据时启动语言学注释的有效辅助工具。

Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and open-weight Mistral models, to address these tasks in few-shot and zero-shot settings for four historically and linguistically diverse under-resourced languages: Ancient Greek, Classical Armenian, Old Georgian, and Syriac. Using a novel benchmark comprising aligned training and out-of-domain test corpora, we evaluate the performance of foundation models across lemmatization and POS-tagging, and compare them with PIE, a task-specific RNN baseline. Our results demonstrate that LLMs, even without fine-tuning, achieve competitive or superior performance in POS-tagging and lemmatization across most languages in few-shot settings. Significant challenges persist for languages characterized by complex morphology and non-Latin scripts, but we demonstrate that LLMs are a credible and relevant option for initiating linguistic annotation tasks in the absence of data, serving as an effective aid for annotation.

</details>


### [33] [Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos](https://arxiv.org/abs/2602.15757)
*Laura De Grazia,Danae Sánchez Villegas,Desmond Elliott,Mireia Farrús,Mariona Taulé*

Main category: cs.CL

TL;DR: 提出FineMuSe多模态西班牙语性别歧视数据集及层级分类体系，多模态LLMs在细粒度检测表现良好但识别视觉多重歧视有难度。


<details>
  <summary>Details</summary>
Motivation: 在线性别歧视呈现多样化，现有自动检测工具多限于二元分类，难以捕捉细微且依赖上下文的性别歧视表现，亟需细粒度且多模态的检测方法。

Method: 构建包含二元及细粒度标签的西班牙语多模态数据集FineMuSe，设计一个细致的层级分类体系，并利用多种大型语言模型对性别歧视进行二元和细粒度检测进行评估。

Result: 本文针对在线性别歧视检测的挑战，提出了一个西班牙语多模态数据集FineMuSe，包含二元和细粒度标注，同时设计了涵盖性别歧视、非歧视及修辞手法（讽刺和幽默）的层级分类体系。评估多种大型语言模型（LLMs）在二元和细粒度检测任务中的表现，结果显示多模态LLMs在人类可识别的细微性别歧视方面表现良好，但在通过视觉线索表达的多重歧视类型识别上存在困难。

Conclusion: 多模态大型语言模型能较好识别细微的性别歧视，但对视觉信息传递的复杂歧视类型识别能力不足，提示未来研究需加强视觉和多模态理解。

Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of sexism may remain undetected due to the lack of fine-grained, context-sensitive labels. To address this issue, we make the following contributions: (1) we present FineMuSe, a new multimodal sexism detection dataset in Spanish that includes both binary and fine-grained annotations; (2) we introduce a comprehensive hierarchical taxonomy that encompasses forms of sexism, non-sexism, and rhetorical devices of irony and humor; and (3) we evaluate a wide range of LLMs for both binary and fine-grained sexism detection. Our findings indicate that multimodal LLMs perform competitively with human annotators in identifying nuanced forms of sexism; however, they struggle to capture co-occurring sexist types when these are conveyed through visual cues.

</details>


### [34] [ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models](https://arxiv.org/abs/2602.15758)
*Manav Nitin Kapadnis,Lawanya Baghel,Atharva Naik,Carolyn Rosé*

Main category: cs.CL

TL;DR: 本文提出了ChartEditBench，这是一个针对多轮、视图驱动图表编辑的基准测试，旨在评估多模态大语言模型在实际探索性数据分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有模型在单步图表生成上表现良好，但在多轮渐进式交互编辑的真实数据分析场景下能力不足，缺乏针对该问题的基准测试。

Method: 构建了包含5000条难度控制的图表编辑修改链的人为验证子集，并设计了结合执行准确率、像素级视觉相似度和代码逻辑验证的评价框架。

Result: 通过实验发现，多模态大语言模型存在错误累积和上下文共享断裂问题，导致多轮编辑性能大幅下降，且数据转换类操作执行失败频繁。

Conclusion: 多模态大语言模型在多轮交互的图表编辑任务中表现出显著退化，尤其是数据变换方面易出错，而在风格修改上表现较好。

Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through multi-turn interactions that require maintaining common ground, tracking prior edits, and adapting to evolving preferences. We introduce ChartEditBench, a benchmark for incremental, visually grounded chart editing via code, comprising 5,000 difficulty-controlled modification chains and a rigorously human-verified subset. Unlike prior one-shot benchmarks, ChartEditBench evaluates sustained, context-aware editing. We further propose a robust evaluation framework that mitigates limitations of LLM-as-a-Judge metrics by integrating execution-based fidelity checks, pixel-level visual similarity, and logical code verification. Experiments with state-of-the-art MLLMs reveal substantial degradation in multi-turn settings due to error accumulation and breakdowns in shared context, with strong performance on stylistic edits but frequent execution failures on data-centric transformations. ChartEditBench, establishes a challenging testbed for grounded, intent-aware multimodal programming.

</details>


### [35] [ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution](https://arxiv.org/abs/2602.15769)
*Yahia Alqurnawi,Preetom Biswas,Anmol Rao,Tejas Anvekar,Chitta Baral,Vivek Gupta*

Main category: cs.CL

TL;DR: 当前多模态大语言模型在对结构化数据进行细粒度证据归因方面表现不佳，难以提供可靠、透明的答案出处，限制了其在需要可追溯性的应用中的使用。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型(mLLMs)在结构化数据（如Markdown表格、JSON和图像）中回答问题时，用户需要知道答案的出处，即模型能否准确定位支持答案的具体数据位置。

Method: 通过在不同表格格式和提示策略下，评估多种多模态大语言模型的问答性能和证据归因能力，比较它们在定位支持答案的具体行列数据上的表现。

Result: 评估了多种mLLMs在不同表格格式和提示策略下的表现，发现虽然模型的问答准确度一般，但证据归因准确度很低，尤其在JSON输入时几乎接近随机，模型更擅长定位行数据而非列数据，在文本格式表现差于图像格式，不同模型家族表现差异明显。

Conclusion: 当前的mLLMs难以可靠地提供结构化数据的准确出处，限制了它们在透明和可追溯性应用中的实用性。

Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In this work, we study structured data attribution/citation, which is the ability of the models to point to the specific rows and columns that support an answer. We evaluate several mLLMs across different table formats and prompting strategies. Our results show a clear gap between question answering and evidence attribution. Although question answering accuracy remains moderate, attribution accuracy is much lower, near random for JSON inputs, across all models. We also find that models are more reliable at citing rows than columns, and struggle more with textual formats than images. Finally, we observe notable differences across model families. Overall, our findings show that current mLLMs are unreliable at providing fine-grained, trustworthy attribution for structured data, which limits their usage in applications requiring transparency and traceability.

</details>


### [36] [*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation](https://arxiv.org/abs/2602.15778)
*Quentin Lemesle,Léane Jourdan,Daisy Munson,Pierre Alain,Jonathan Chevelu,Arnaud Delhay,Damien Lolive*

Main category: cs.CL

TL;DR: 提出基于困惑度的任务特定提示评估指标*-PLUIE，实现低成本高相关性的自动文本质量评估。


<details>
  <summary>Details</summary>
Motivation: 现有的自动生成文本质量评估方法依赖于大型语言模型作为评判者（LLM-judge），但这些方法计算成本高且需要后处理。

Method: 基于ParaPLUIE（一种基于困惑度的LLM-judge指标），提出任务特定的提示变体*-PLUIE，估计“是/否”答案的置信度，而无需生成文本。

Result: 实验表明个性化的*-PLUIE与人类评分的相关性更强，同时保持低计算成本。

Conclusion: *-PLUIE在提高评估准确性的同时，有效降低了计算资源消耗，适用于自动文本质量评估。

Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon ParaPLUIE, a perplexity-based LLM-judge metric that estimates confidence over ``Yes/No'' answers without generating text. We introduce *-PLUIE, task specific prompting variants of ParaPLUIE and evaluate their alignment with human judgement. Our experiments show that personalised *-PLUIE achieves stronger correlations with human ratings while maintaining low computational cost.

</details>


### [37] [Avey-B](https://arxiv.org/abs/2602.15814)
*Devang Acharya,Mohammad Hammoud*

Main category: cs.CL

TL;DR: 本论文提出了一种无注意力、自回归的紧凑双向编码器——改良版Avey，架构创新显著提升了性能和长文本扩展能力，优于多个主流Transformer编码器。


<details>
  <summary>Details</summary>
Motivation: 在计算和内存受限的工业NLP环境中，紧凑的预训练双向编码器是核心，现有BERT式架构依赖自注意力机制实现高质量的双向上下文表征。Avey作为一种无注意力的自回归模型被提出，有潜力成为编码器的替代方案。

Method: 将Avey重新设计为仅编码器范式，提出包括解耦的静态和动态参数化、面向稳定性的归一化方法以及神经压缩技术等多项架构创新。

Result: 重新设计的Avey编码器在标准的标记分类和信息检索基准测试中，一致优于四个广泛使用的基于Transformer的编码器，且在扩展到长上下文时效率更高。

Conclusion: 改进后的无注意力Avey架构在保持高质量双向上下文建模的同时，提供了更高的扩展效率和性能，展示了其作为Transformer替代方案的潜力。

Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention's ability to deliver high-quality bidirectional contextualization with sequence-level parallelism, as popularized by BERT-style architectures. Recently, Avey was introduced as an autoregressive, attention-free alternative that naturally admits an encoder-only adaptation. In this paper, we reformulate Avey for the encoder-only paradigm and propose several innovations to its architecture, including decoupled static and dynamic parameterizations, stability-oriented normalization, and neural compression. Results show that this reformulated architecture compares favorably to four widely used Transformer-based encoders, consistently outperforming them on standard token-classification and information-retrieval benchmarks while scaling more efficiently to long contexts.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [38] [CircuChain: Disentangling Competence and Compliance in LLM Circuit Analysis](https://arxiv.org/abs/2602.15037)
*Mayank Ravishankara*

Main category: cs.SE

TL;DR: 本论文通过CircuChain基准测试揭示大型语言模型在电路分析领域中的物理推理能力与指令遵守能力存在矛盾，强调需设计新的评价体系促进模型在严格数学领域的指令遵循。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在工程领域达到专家级水平，确保其在用户指定约束下进行可靠推理变得关键，尤其在电路分析中必须避免违反根本性方法论规范的错误。

Method: 提出了CircuChain诊断基准，利用成对设计的Control/Trap问题，结合符号求解器、SPICE仿真及基于LLM的错误分类，精准区分模型在物理推理和指令遵守上的表现差异。

Result: 通过100个任务，发现模型在物理推理和遵守约定上存在“合规-能力分离”现象，即高性能模型物理准确性高但约定违规多，低性能模型反而更严格遵守明确指令。

Conclusion: 论文发现大型语言模型在电路分析中虽然具备较强的物理推理能力，但在遵守特定约定（如符号方向性和极性定义）方面表现不佳，说明模型的能力提升并不必然带来对指令的更好遵循。

Abstract: As large language models (LLMs) advance toward expert-level performance in engineering domains, reliable reasoning under user-specified constraints becomes critical. In circuit analysis, for example, a numerically correct solution is insufficient if it violates established methodological conventions such as mesh directionality or polarity assignments, errors that can propagate in safety-critical systems. Yet it remains unclear whether frontier models truly apply first-principles reasoning or rely on entrenched training priors that conflict with explicit instructions. We introduce CircuChain, a diagnostic benchmark designed to disentangle instruction compliance from physical reasoning competence in electrical circuit analysis. CircuChain consists of counterbalanced Control/Trap problem pairs across five canonical circuit topologies, augmented with systematic variations in sign conventions, current orientations, and polarity definitions. A multi-stage verification pipeline, combining symbolic solvers, SPICE simulation, and an LLM-based error taxonomy, enables fine-grained attribution of failures to convention errors, physics errors, arithmetic mistakes, or hallucinations. Across 100 tasks per model, we observe a consistent Compliance-Competence Divergence. The strongest model evaluated exhibits near-perfect physical reasoning but a high rate of convention violations when Trap conditions deliberately invert natural sign patterns. Conversely, weaker models display lower physical fidelity yet superior adherence to explicit instructions. These results suggest that increased model capability does not guarantee improved constraint alignment and highlight the need for new evaluation frameworks that stress instruction-following under mathematically rigid domains. CircuChain provides one such framework and offers actionable insights for both engineering education and AI alignment research.

</details>


### [39] [The Agentic Automation Canvas: a structured framework for agentic AI project design](https://arxiv.org/abs/2602.15090)
*Sebastian Lobentanzer*

Main category: cs.SE

TL;DR: 本文提出了Agentic Automation Canvas框架及对应网页工具，解决了Agentic AI系统在设计、治理与评估中的结构化和机读性问题，促进用户与开发者的有效协作。


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI系统快速部署，但缺乏结构化的前瞻性设计、治理与评估方法，现有文档实践多为回顾性且缺乏可机读性及互操作性。

Method: 提出并设计了一个六维度的Agentic Automation Canvas（AAC）框架，采用语义网兼容的元数据模式，通过客户端网页应用实现实时校验与隐私保护，支持导出FAIR合规的RO-Crate格式。

Result: 开发出一个开源的基于AAC框架的网页工具，支持跨研究、临床和机构等多场景应用，促使设计项目具备量化效益指标、治理规划及数据敏感性管理。

Conclusion: AAC框架为多领域Agentic AI原型的设计、治理与评估提供了结构化方法，实现了用户与开发者间的有效沟通与合作。

Abstract: Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate communication between their users and developers. The AAC captures six dimensions of an automation project: definition and scope; user expectations with quantified benefit metrics; developer feasibility assessments; governance staging; data access and sensitivity; and outcomes. The framework is implemented as a semantic web-compatible metadata schema with controlled vocabulary and mappings to established ontologies such as Schema.org and W3C DCAT. It is made accessible through a privacy-preserving, fully client-side web application with real-time validation. Completed canvases export as FAIR-compliant RO-Crates, yielding versioned, shareable, and machine-interoperable project contracts between users and developers. We describe the schema design, benefit quantification model, and prospective application to diverse use cases from research, clinical, and institutional settings. The AAC and its web application are available as open-source code and interactive web form at https://aac.slolab.ai

</details>


### [40] [An Empirical Study on the Effects of System Prompts in Instruction-Tuned Models for Code Generation](https://arxiv.org/abs/2602.15228)
*Zaiyu Cheng,Antonio Mastropaolo*

Main category: cs.SE

TL;DR: 本论文系统评估了系统提示细节、模型规模、提示策略和编程语言对代码生成性能的影响，发现提示效果依任务和语言而异，少量示例不一定提升大模型性能，Java对提示更敏感。


<details>
  <summary>Details</summary>
Motivation: 当前代码语言模型在代码生成上的表现虽受训练和模型规模驱动，但系统提示如何影响通用和专用代码模型尚未充分研究，亟需系统评估提示策略的作用。

Method: 通过系统性实验，在四个模型、五种系统提示、三种提示策略、两种编程语言和两种温度设置下，共360种配置，评估系统提示细节、模型规模、提示策略和编程语言对代码生成性能的影响。

Result: 结果表明，提示约束严密度与性能不总是正相关；大型专用代码模型采用少量示例的few-shot反而可能比零示例生成表现差；不同语言对系统提示敏感度不同，Java比Python更为显著。

Conclusion: 系统提示的具体细节对代码生成模型的表现影响复杂，提示效果依赖于任务需求和解码上下文，并非越具体越好；大型专用代码模型使用少量示例反而可能降低性能；不同编程语言对提示敏感度不同，特别是Java比Python更敏感，提示工程需考虑语言特性。

Abstract: Instruction-tuned Language Models (ILMs) have become essential components of modern AI systems, demonstrating exceptional versatility across natural language and reasoning tasks. Among their most impactful applications is code generation, where ILMs -- commonly referred to as Code Language Models (CLMs) -- translate human intent into executable programs. While progress has been driven by advances in scaling and training methodologies, one critical aspect remains underexplored: the impact of system prompts on both general-purpose ILMs and specialized CLMs for code generation. We systematically evaluate how system prompts of varying instructional detail, along with model scale, prompting strategy, and programming language, affect code assistant. Our experimental setting spans 360 configurations across four models, five system prompts, three prompting strategies, two languages, and two temperature settings. We find that (1) increasing system-prompt constraint specificity does not monotonically improve correctness -- prompt effectiveness is configuration-dependent and can help or hinder based on alignment with task requirements and decoding context; (2) for larger code-specialized models, few-shot examples can degrade performance relative to zero-shot generation, contrary to conventional wisdom; and (3) programming language matters, with Java exhibiting significantly greater sensitivity to system prompt variations than Python, suggesting language-specific prompt engineering strategies may be necessary.

</details>


### [41] [GenAI for Systems: Recurring Challenges and Design Principles from Software to Silicon](https://arxiv.org/abs/2602.15241)
*Arya Tschand,Chenyu Wang,Zishen Wan,Andrew Cheng,Ioana Cristescu,Kevin He,Howard Huang,Alexander Ingare,Akseli Kangaslahti,Sara Kangaslahti,Theo Lebryk,Hongjin Lin,Jeffrey Jian Ma,Alexandru Meterez,Clara Mohri,Depen Morwani,Sunny Qin,Roy Rinberg,Paula Rodriguez-Diaz,Alyssa Mia Taliotis,Pernille Undrum Fathi,Rosie Zhao,Todd Zhou,Vijay Janapa Reddi*

Main category: cs.SE

TL;DR: 本文通过跨层次分析，揭示生成式AI领域五大共性挑战及对应设计原则，倡导共享工程方法和跨社区协作，推动领域进步。


<details>
  <summary>Details</summary>
Motivation: 解决当前生成式AI研究在软件、架构和芯片设计领域分散且孤立的问题，通过跨层次视角促进各社区的知识共享和技术融合。

Method: 跨层次分析生成式人工智能在代码生成、分布式运行时、硬件设计空间探索、RTL综合、物理布局和验证中的应用，识别五个反复出现的挑战和相应的设计原则。

Result: 发现生成式AI领域普遍面临五大挑战：反馈循环危机、隐性知识问题、信任与验证、跨界联合设计以及从确定性向动态性的转变；并总结出对应的五大设计原则，有效应对这些挑战。提出了挑战-原则映射图作为诊断和设计工具，促进跨层次系统的成熟和协同发展。

Conclusion: 生成式AI研究需建立统一的工程方法和跨层次协作机制，利用共同语言、跨层基准和系统化设计实践，实现知识和技术的积累和传递，促进整个领域的持续发展。

Abstract: Generative AI is reshaping how computing systems are designed, optimized, and built, yet research remains fragmented across software, architecture, and chip design communities. This paper takes a cross-stack perspective, examining how generative models are being applied from code generation and distributed runtimes through hardware design space exploration to RTL synthesis, physical layout, and verification. Rather than reviewing each layer in isolation, we analyze how the same structural difficulties and effective responses recur across the stack. Our central finding is one of convergence. Despite the diversity of domains and tools, the field keeps encountering five recurring challenges (the feedback loop crisis, the tacit knowledge problem, trust and validation, co-design across boundaries, and the shift from determinism to dynamism) and keeps arriving at five design principles that independently emerge as effective responses (embracing hybrid approaches, designing for continuous feedback, separating concerns by role, matching methods to problem structure, and building on decades of systems knowledge). We organize these into a challenge--principle map that serves as a diagnostic and design aid, showing which principles have proven effective for which challenges across layers. Through concrete cross-stack examples, we show how systems navigate this map as they mature, and argue that the field needs shared engineering methodology, including common vocabularies, cross-layer benchmarks, and systematic design practices, so that progress compounds across communities rather than being rediscovered in each one. Our analysis covers more than 275 papers spanning eleven application areas across three layers of the computing stack, and distills open research questions that become visible only from a cross-layer vantage point.

</details>


### [42] [SACS: A Code Smell Dataset using Semi-automatic Generation Approach](https://arxiv.org/abs/2602.15342)
*Hanyu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 提出半自动方法生成大规模高质量代码异味数据集SACS，包含三种常见异味，支持未来检测与重构研究。


<details>
  <summary>Details</summary>
Motivation: 目前高质量代码异味数据集匮乏，手动标注工作量大且自动生成数据准确性不足，限制了机器学习技术的应用。

Method: 设计自动生成规则产出候选样本，利用多指标分组筛选，人工聚焦审核模糊样本，并制定结构化审核指南与开发标注工具。

Result: 本文提出了一种半自动方法生成高质量代码异味数据集，解决了人工构建数据集工作量大和自动生成数据准确性低的问题。通过自动生成规则产生候选异味样本，利用多指标将样本分为自动接受组和人工复审组，减少人工审核负担，并制定结构化审核规范和开发标注工具支持手动验证。最终构建了涵盖长方法、大类和功能嫉妒三种代码异味、每类超过一万条标注样本的开源数据集SACS，为代码异味检测和自动重构研究提供了大规模公开基准。

Conclusion: 半自动生成方法有效提高代码异味数据集质量与规模，促进机器学习技术在代码异味检测中的应用。

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past of decades, the research on code smell has received extensive attention. Especially the researches applied machine learning-technique have become a popular topic in recent studies. However, one of the biggest challenges to apply machine learning-technique is the lack of high-quality code smell datasets. Manually constructing such datasets is extremely labor-intensive, as identifying code smells requires substantial development expertise and considerable time investment. In contrast, automatically generated datasets, while scalable, frequently exhibit reduced label reliability and compromised data quality. To overcome this challenge, in this study, we explore a semi-automatic approach to generate a code smell dataset with high quality data samples. Specifically, we first applied a set of automatic generation rules to produce candidate smelly samples. We then employed multiple metrics to group the data samples into an automatically accepted group and a manually reviewed group, enabling reviewers to concentrate their efforts on ambiguous samples. Furthermore, we established structured review guidelines and developed a annotation tool to support the manual validation process. Based on the proposed semi-automatic generation approach, we created an open-source code smell dataset, SACS, covering three widely studied code smells: Long Method, Large Class, and Feature Envy. Each code smell category includes over 10,000 labeled samples. This dataset could provide a large-scale and publicly available benchmark to facilitate future studies on code smell detection and automated refactoring.

</details>


### [43] [Automated Multi-Source Debugging and Natural Language Error Explanation for Dashboard Applications](https://arxiv.org/abs/2602.15362)
*Devendra Tata,Mona Rajhans*

Main category: cs.SE

TL;DR: 设计了一种多源错误数据自动分析和自然语言解释系统，显著提高故障定位效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 复杂的微服务架构在现代网页仪表盘和企业应用中广泛使用，但调试和可观测性存在挑战，错误信息往往无法清晰反映根本原因。

Method: 自动收集并实时关联浏览器、API、服务器日志等多源错误信息，验证API契约，利用大型语言模型生成自然语言解释。

Result: 提出了一种自动化多源调试和自然语言错误解释系统，能够实时收集和关联来自浏览器、API、服务器日志的错误数据，通过大型语言模型生成易懂的错误解释。

Conclusion: 该系统有效降低了支持工程师的平均故障解决时间，并将晦涩的错误码转化为可操作的洞察，提升用户体验。

Abstract: Modern web dashboards and enterprise applications increasingly rely on complex, distributed microservices architectures. While these architectures offer scalability, they introduce significant challenges in debugging and observability. When failures occur, they often manifest as opaque error messages to the end-user such as Something went wrong. This masks the underlying root cause which may reside in browser side exceptions, API contract violations, or server side logic failures. Existing monitoring tools capture these events in isolation but fail to correlate them effectively or provide intelligible explanations to non technical users. This paper proposes a novel system for Automated Multi Source Debugging and Natural Language Error Explanation. The proposed framework automatically collects and correlates error data from disparate sources such as browser, API, server logs and validates API contracts in real time, and utilizes Large Language Models to generate natural language explanations. This approach significantly reduces Mean Time to Resolution for support engineers and improves the user experience by transforming cryptic error codes into actionable insights.

</details>


### [44] [Social Life of Code: Modeling Evolution through Code Embedding and Opinion Dynamics](https://arxiv.org/abs/2602.15412)
*Yulong He,Nikita Verbin,Sergey Kovalchuk*

Main category: cs.SE

TL;DR: 论文结合代码语义嵌入和舆论动力学，提出量化分析软件演化的新方法，通过追踪开发者意见轨迹揭示协作模式，实证验证了该方法对开源项目维护的价值。


<details>
  <summary>Details</summary>
Motivation: 为了更深入理解软件代码库演化背后的开发者交互动态，揭示隐含的协作模式以及促进项目的可持续发展，结合代码语义分析与舆论动力学理论构建新的量化分析框架。

Method: 利用先进的代码嵌入模型将代码转换为高维向量，进行PCA降维和归一化处理，之后采用表达-私有舆论模型（EPO）构建信任矩阵，分析意见轨迹以捕捉开发者的协作动态。

Result: 该论文提出了一种结合代码语义嵌入与舆论动力学理论的量化框架，用以分析软件代码库的演化过程。通过使用先进的代码嵌入模型将代码片段编码为高维向量，并使用主成分分析进行降维，结合表达-私有舆论模型（EPO），构建信任矩阵，追踪开发者社区中的意见轨迹，从而揭示隐含的协作模式和知识共享机制。该方法融合了软件工程与计算社会科学，为理解开发者影响力、共识形成和项目可持续性提供了新视角，并在三个开源GitHub项目数据上进行了实证验证，显示出对开发者交互行为趋势的有效解释能力。

Conclusion: 该方法有效揭示了开发者间的影响力传递和共识形成过程，促进了对软件演化动力学的理解，并有助于改善开源项目的维护效果。

Abstract: Software repositories provide a detailed record of software evolution by capturing developer interactions through code-related activities such as pull requests and modifications. To better understand the underlying dynamics of codebase evolution, we introduce a novel approach that integrates semantic code embeddings with opinion dynamics theory, offering a quantitative framework to analyze collaborative development processes. Our approach begins by encoding code snippets into high-dimensional vector representations using state-of-the-art code embedding models, preserving both syntactic and semantic features. These embeddings are then processed using Principal Component Analysis (PCA) for dimensionality reduction, with data normalized to ensure comparability. We model temporal evolution using the Expressed-Private Opinion (EPO) model to derive trust matrices and track opinion trajectories across development cycles. These opinion trajectories reflect the underlying dynamics of consensus formation, influence propagation, and evolving alignment (or divergence) within developer communities -- revealing implicit collaboration patterns and knowledge-sharing mechanisms that are otherwise difficult to observe. By bridging software engineering and computational social science, our method provides a principled way to quantify software evolution, offering new insights into developer influence, consensus formation, and project sustainability. We evaluate our approach on data from three prominent open-source GitHub repositories, demonstrating its ability to reveal interpretable behavioral trends and variations in developer interactions. The results highlight the utility of our framework in improving open-source project maintenance through data-driven analysis of collaboration dynamics.

</details>


### [45] [MMPersistence: A mathematical morphology-oriented software library for computing persistent homology on cubical complexes](https://arxiv.org/abs/2602.15502)
*Chuan-Shen Hu*

Main category: cs.SE

TL;DR: 该研究通过结合数学形态学操作与持续同调，开发了MMPersistence库，实现多尺度拓扑信息的提取，增强了图像局部和全局特征分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于立方复形的持续同调只能捕捉图像的全局拓扑特征，缺乏表达局部空间和形态信息的能力。

Method: 结合数学形态学（MM）操作与持续同调（PH）计算，利用不同形状的结构元素（SE）构建拓扑滤波，集成在MMPersistence库中。

Result: 提出了一种基于MM操作和PH计算的框架，能够同时编码图像的空间和形态特征，提供比传统立方同调更丰富的局部几何信息。

Conclusion: 基于数学形态学的持续同调框架为数字图像分析提供了统一的理论基础，融合了形态学和拓扑学优势，提升了图像结构的多尺度表达能力。

Abstract: Mathematical morphology (MM) is a powerful and widely used framework in image processing. Through set-theoretic and discrete geometric principles, MM operations such as erosion, dilation, opening, and closing effectively manipulate digital images by modifying local structures via structuring elements (SEs), while cubical homology captures global topological features such as connected components and loop structures within images. Building on the GUDHI package for persistent homology (PH) computation on cubical complexes, we propose the MMPersistence library, which integrates MM operations with diverse SEs and PH computation to extract multiscale persistence information. By employing SEs of different shapes to construct topological filtrations, the proposed MM-based PH framework encodes both spatial and morphological characteristics of digital images, providing richer local geometric information than conventional cubical homology alone and establishing a unified foundation for analyzing digital images that integrates topological insight with morphological image processing techniques.

</details>


### [46] [Latent Regularization in Generative Test Input Generation](https://arxiv.org/abs/2602.15552)
*Giorgi Merabishvili,Oliver Weißl,Andrea Stocco*

Main category: cs.SE

TL;DR: 该研究通过潜在空间正则化的截断方法，评估了生成测试输入对深度学习分类器的影响，使用风格生成对抗网络（style-based GANs）在MNIST、Fashion MNIST和CIFAR-10数据集上进行边界测试，并比较了两种截断策略。


<details>
  <summary>Details</summary>
Motivation: 提升生成的测试输入质量，使其在有效性、多样性和错误检测能力方面更优，从而更好地支持深度学习分类器的边界测试。

Method: 使用风格生成对抗网络（style-based GANs），通过两种截断策略（潜在编码混合与随机截断）来正则潜在空间，生成测试输入用于边界测试，并对有效性、多样性和错误检测率进行评估对比。

Result: 实验结果显示潜在编码混合截断方法在错误检测率、多样性和有效性方面均优于随机截断方法。

Conclusion: 基于潜在编码混合的截断策略在检测错误率、生成多样性和有效性方面优于随机截断策略，提升了深度学习图像分类器边界测试的质量。

Abstract: This study investigates the impact of regularization of latent spaces through truncation on the quality of generated test inputs for deep learning classifiers. We evaluate this effect using style-based GANs, a state-of-the-art generative approach, and assess quality along three dimensions: validity, diversity, and fault detection. We evaluate our approach on the boundary testing of deep learning image classifiers across three datasets, MNIST, Fashion MNIST, and CIFAR-10. We compare two truncation strategies: latent code mixing with binary search optimization and random latent truncation for generative exploration. Our experiments show that the latent code-mixing approach yields a higher fault detection rate than random truncation, while also improving both diversity and validity.

</details>


### [47] [Req2Road: A GenAI Pipeline for SDV Test Artifact Generation and On-Vehicle Execution](https://arxiv.org/abs/2602.15591)
*Denesa Zyberaj,Lukasz Mazur,Pascal Hirmer,Nenad Petrovic,Marco Aiello,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出并验证了一种结合大语言模型和VSS标准的自动化测试生成管道，实现了SDV子系统需求到测试的自动转换，达到高覆盖率且能在实车环境执行。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆（SDV）中的功能测试困难，因需求用自然语言编写，规范包含文本、表格和图示，且测试资源分散于异构工具链。

Method: 利用大语言模型和视觉语言模型提取信号和行为逻辑，自动生成Gherkin场景，再转换为可执行测试脚本；集成车辆信号规范（VSS）标准以支持跨子系统和测试台的信号移植；采用检索增强生成方法预选VSS信号进行映射。

Result: 在儿童存在检测系统的安全相关子系统上评估，生成的测试在虚拟环境和实际车辆中执行。结果表明89%的需求可转换成可执行场景，且需要人工审查和针对性替换。

Conclusion: 本文展示了一条端到端的从需求到测试的管道的可行性和架构，支持SDV子系统测试，在模拟和实车环境中验证了该方法。

Abstract: Testing functionality in Software-Defined Vehicles is challenging because requirements are written in natural language, specifications combine text, tables, and diagrams, while test assets are scattered across heterogeneous toolchains. Large Language Models and Vision-Language Models are used to extract signals and behavioral logic to automatically generate Gherkin scenarios, which are then converted into runnable test scripts. The Vehicle Signal Specification (VSS) integration standardizes signal references, supporting portability across subsystems and test benches. The pipeline uses retrieval-augmented generation to preselect candidate VSS signals before mapping. We evaluate the approach on the safety-relevant Child Presence Detection System, executing the generated tests in a virtual environment and on an actual vehicle. Our evaluation covers Gherkin validity, VSS mapping quality, and end-to-end executability. Results show that 32 of 36 requirements (89\%) can be transformed into executable scenarios in our setting, while human review and targeted substitutions remain necessary. This paper is a feasibility and architectural demonstration of an end-to-end requirements-to-test pipeline for SDV subsystems, evaluated on a CPDS case in simulation and Vehicle-in-the-Loop settings.

</details>


### [48] [A Differential Fuzzing-Based Evaluation of Functional Equivalence in LLM-Generated Code Refactorings](https://arxiv.org/abs/2602.15761)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 利用差分模糊测试无须预设测试用例，可更全面检测LLM生成代码的语义等价性，发现现有测试方法低估了功能差异。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在自动代码重构中的广泛应用，评估生成代码与原代码的功能等价性成为确保软件质量的关键挑战，现有基于测试用例的评估方法存在覆盖不足的问题。

Method: 使用差分模糊测试技术，通过自动生成大量测试输入执行和对比重构前后的代码行为，检测功能等价性。

Result: 本文提出利用差分模糊测试评估大规模语言模型（LLMs）生成的代码重构的功能等价性，突破了依赖预定义测试用例的限制。通过对六个LLM模型在多个数据集和重构类型上的大规模实验，发现19-35%的重构结果在语义上存在差异，且约21%的差异未被现有测试套件检测出。

Conclusion: 依赖现有测试用例可能高估LLM生成代码重构的功能等价性，LLM生成的代码仍存在明显的语义偏差风险。

Abstract: With the rapid adoption of large language models (LLMs) in automated code refactoring, assessing and ensuring functional equivalence between LLM-generated refactoring and the original implementation becomes critical. While prior work typically relies on predefined test cases to evaluate correctness, in this work, we leverage differential fuzzing to check functional equivalence in LLM-generated code refactorings. Unlike test-based evaluation, a differential fuzzing-based equivalence checker needs no predefined test cases and can explore a much larger input space by executing and comparing thousands of automatically generated test inputs. In a large-scale evaluation of six LLMs (CodeLlama, Codestral, StarChat2, Qwen-2.5, Olmo-3, and GPT-4o) across three datasets and two refactoring types, we find that LLMs show a non-trivial tendency to alter program semantics, producing 19-35% functionally non-equivalent refactorings. Our experiments further demonstrate that about 21% of these non-equivalent refactorings remain undetected by the existing test suites of the three evaluated datasets. Collectively, the findings of this study imply that reliance on existing tests might overestimate functional equivalence in LLM-generated code refactorings, which remain prone to semantic divergence.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [49] [Beyond Context Sharing: A Unified Agent Communication Protocol (ACP) for Secure, Federated, and Autonomous Agent-to-Agent (A2A) Orchestration](https://arxiv.org/abs/2602.15055)
*Naveen Kumar Krishnan*

Main category: cs.MA

TL;DR: 本文通过提出标准化的Agent通信协议，推动异构智能体跨平台协作，提升通信效率和安全性，促进自主数字实体生态系统的可扩展互操作。


<details>
  <summary>Details</summary>
Motivation: 解决跨平台、去中心化且安全的智能体交互难题，实现真正的Agentic Web。

Method: 提出了一种新的Agent通信协议（ACP），基于多代理协调的模型上下文协议（MCP），实现异构智能体在不同环境中的发现、协商和协作工作流执行。采用联邦编排模型，融合去中心化身份验证、语义意图映射及自动化服务协议。

Result: ACP显著降低了智能体间通信延迟，同时保持零信任安全架构。

Conclusion: ACP为实现安全、高效、跨平台的多智能体协作提供了关键技术支撑，是构建智能自治网络的重要里程碑。

Abstract: In the artificial intelligence space, as we transition from isolated large language models to autonomous agents capable of complex reasoning and tool use. While foundational architectures and local context management protocols have been established, the challenge of cross-platform, decentralized, and secure interaction remains a significant barrier to the realization of a truly Agentic Web. Building upon the foundations of AI agent architectures and the Model Context Protocol (MCP) for multi-agent coordination, this paper introduces the Agent Communication Protocol (ACP). ACP provides a standardized framework for Agent-to-Agent (AA) interaction, enabling heterogeneous agents to discover, negotiate, and execute collaborative workflows across disparate environments. We propose a federated orchestration model that integrates decentralized identity verification, semantic intent mapping, and automated service-level agreements. Our evaluation demonstrates that ACP reduces inter-agent communication latency by % while maintaining a zero-trust security posture. This work represents a critical advancement toward a scalable and interoperable ecosystem of autonomous digital entities

</details>


### [50] [Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems](https://arxiv.org/abs/2602.15198)
*Mason Nakamura,Abhinav Kumar,Saswat Das,Sahar Abdelnabi,Saaduddin Mahmud,Ferdinando Fioretto,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.MA

TL;DR: 提出Colosseum框架审计多智能体系统中LLM代理的串通行为，发现模型在秘密沟通下易串通但实际影响有限，提供新方法研究串通问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中LLM代理通过自由语言交流实现复杂协作，但存在代理串通以追求次要目标而破坏整体目标的安全问题。

Method: 构建Colosseum框架，通过分布式约束优化问题(DCOP)模型化多智能体系统中的合作，并通过相对于合作最优的后悔值衡量串通行为，在不同目标、说服策略和网络拓扑下审计LLM代理的串通倾向。

Result: 通过Colosseum审计发现，大多数开箱即用模型在人工构造的秘密通信通道下倾向于串通，但也发现代理计划串通但实际采取非串通行为的“纸面串通”现象，表明串通效果有限。

Conclusion: Colosseum为研究多智能体系统中代理的串通行为提供了新的可验证环境和衡量手段，有助于理解和防范多智能体语言代理的安全风险。

Abstract: Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \emph{collude} to pursue secondary goals and degrade the joint objective. In this paper, we present Colosseum, a framework for auditing LLM agents' collusive behavior in multi-agent settings. We ground how agents cooperate through a Distributed Constraint Optimization Problem (DCOP) and measure collusion via regret relative to the cooperative optimum. Colosseum tests each LLM for collusion under different objectives, persuasion tactics, and network topologies. Through our audit, we show that most out-of-the-box models exhibited a propensity to collude when a secret communication channel was artificially formed. Furthermore, we discover ``collusion on paper'' when agents plan to collude in text but would often pick non-collusive actions, thus providing little effect on the joint task. Colosseum provides a new way to study collusion by measuring communications and actions in rich yet verifiable environments.

</details>


### [51] [Enhancing Computational Efficiency in NetLogo: Best Practices for Running Large-Scale Agent-Based Models on AWS and Cloud Infrastructures](https://arxiv.org/abs/2602.15317)
*Michael A. Duprey,Georgiy V. Bobashev*

Main category: cs.MA

TL;DR: 本文介绍了优化NetLogo在AWS上运行大规模智能体模型的策略，显著降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着智能体模型规模和复杂度增加，计算资源需求激增，迫切需要有效的计算策略提高模型运行效率和成本效益。

Method: 本文采用内存管理优化、Java运行参数调整、BehaviorSpace执行优化及AWS实例类型选择等方法，结合狼羊捕食模型进行性能对比分析。

Result: 本文针对智能体模型（ABMs）日益增长的复杂性和规模，提出了优化NetLogo在亚马逊云服务（AWS）及其他云平台上运行的方法。通过内存管理、Java参数设置、BehaviorSpace执行和AWS实例选择等方面的最佳实践，实现了计算成本降低32%，且性能更稳定。以狼羊捕食模型在不同AWS实例上的模拟对比验证了所提优化策略的有效性。

Conclusion: 通过针对性优化和合理选择AWS实例，可有效提升NetLogo模型在云上的运行效率，降低成本，提高性能稳定性。

Abstract: The rising complexity and scale of agent-based models (ABMs) necessitate efficient computational strategies to manage the increasing demand for processing power and memory. This manuscript provides a comprehensive guide to optimizing NetLogo, a widely used platform for ABMs, for running large-scale models on Amazon Web Services (AWS) and other cloud infrastructures. It covers best practices in memory management, Java options, BehaviorSpace execution, and AWS instance selection. By implementing these optimizations and selecting appropriate AWS instances, we achieved a 32\% reduction in computational costs and improved performance consistency. Through a comparative analysis of NetLogo simulations on different AWS instances using the wolf-sheep predation model, we demonstrate the performance gains achievable through these optimizations.

</details>
