<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 66]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.SE](#cs.SE) [Total: 24]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Open-Source Multimodal Moxin Models with Moxin-VLM and Moxin-VLA](https://arxiv.org/abs/2512.22208)
*Pu Zhao,Xuan Shen,Zhenglun Kong,Yixin Shen,Sung-En Chang,Arash Akbari,Timothy Rupprecht,Lei Lu,Enfu Nan,Changdi Yang,Yumei He,Weiyan Shi,Xingchen Xu,Yu Huang,Wei Jiang,Wei Wang,Yue Chen,Yong He,Yanzhi Wang*

Main category: cs.CL

TL;DR: 本文介绍了一个完全开源的大型语言模型Moxin 7B，基于模型开放框架，实现训练过程、数据集和实现细节的完全透明。并基于Moxin开发了三个变体（包括视觉语言和中文能力），在多个任务中表现优异。所有模型、数据和代码均公开发布。


<details>
  <summary>Details</summary>
Motivation: 当前主流大型语言模型多为闭源或仅共享模型权重，限制了研究创新和应用拓展；通过完全开源和透明化，促进更包容、合作和可持续的研究环境。

Method: 基于模型开放框架，采用开源训练框架和公开数据，详细公开训练细节、数据集和实现代码，开发包括视觉语言、视觉语言动作和中文能力的多个模型变体。

Result: Moxin 7B及其变体在多个评测中表现优越，验证了开放策略和多任务能力扩展的有效性，且模型及资源全部开源。

Conclusion: Moxin 7B及其变体在多项评测中展现了优越性能，且实现了完全开源和透明，推动了健康的开源生态系统发展。

Abstract: Recently, Large Language Models (LLMs) have undergone a significant transformation, marked by a rapid rise in both their popularity and capabilities. Leading this evolution are proprietary LLMs like GPT-4 and GPT-o1, which have captured widespread attention in the AI community due to their remarkable performance and versatility. Simultaneously, open-source LLMs, such as LLaMA and Mistral, have made great contributions to the ever-increasing popularity of LLMs due to the ease to customize and deploy the models across diverse applications. Moxin 7B is introduced as a fully open-source LLM developed in accordance with the Model Openness Framework, which moves beyond the simple sharing of model weights to embrace complete transparency in training, datasets, and implementation detail, thus fostering a more inclusive and collaborative research environment that can sustain a healthy open-source ecosystem. To further equip Moxin with various capabilities in different tasks, we develop three variants based on Moxin, including Moxin-VLM, Moxin-VLA, and Moxin-Chinese, which target the vision-language, vision-language-action, and Chinese capabilities, respectively. Experiments show that our models achieve superior performance in various evaluations. We adopt open-source framework and open data for the training. We release our models, along with the available data and code to derive these models.

</details>


### [2] [Hierarchical Geometry of Cognitive States in Transformer Embedding Spaces](https://arxiv.org/abs/2512.22227)
*Sophie Zhao*

Main category: cs.CL

TL;DR: 本文发现transformer句子嵌入体现了与人类认知层级对应的分级结构，用线性及非线性探针验证了这种结构的显著性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 探索transformer语言模型的句子嵌入是否编码了与人类认知属性对齐的分级层次结构。

Method: 构建带有能量分数和认知层级标签的句子数据集，利用线性和浅层非线性探针从多种transformer模型的句子嵌入中解码这些标注，通过基线对比和非参数置换检验验证结果。

Result: 不同模型的句子嵌入均能可靠解码认知分数和层级标签，浅层非线性探针优于线性探针，词汇TF-IDF基线表现较差，说明结构非表面词统计引起，置换检验支持结果显著性。

Conclusion: transformer嵌入空间呈现出与人定义认知属性一致的分级几何组织结构，但不涉及是否具备内部意识或主观体验的判断。

Abstract: Recent work has shown that transformer-based language models learn rich geometric structure in their embedding spaces, yet the presence of higher-level cognitive organization within these representations remains underexplored. In this work, we investigate whether sentence embeddings encode a graded, hierarchical structure aligned with human-interpretable cognitive or psychological attributes. We construct a dataset of 480 natural-language sentences annotated with continuous ordinal energy scores and discrete tier labels spanning seven ordered cognitive categories. Using fixed sentence embeddings from multiple transformer models, we evaluate the recoverability of these annotations via linear and shallow nonlinear probes. Across models, both continuous scores and tier labels are reliably decodable, with shallow nonlinear probes providing consistent performance gains over linear probes. Lexical TF-IDF baselines perform substantially worse, indicating that the observed structure is not attributable to surface word statistics alone. Nonparametric permutation tests further confirm that probe performance exceeds chance under label-randomization nulls. Qualitative analyses using UMAP visualizations and confusion matrices reveal smooth low-to-high gradients and predominantly adjacent-tier confusions in embedding space. Taken together, these results provide evidence that transformer embedding spaces exhibit a hierarchical geometric organization aligned with human-defined cognitive attributes, while remaining agnostic to claims of internal awareness or phenomenology.

</details>


### [3] [SmartSnap: Proactive Evidence Seeking for Self-Verifying Agents](https://arxiv.org/abs/2512.22322)
*Shaofei Cai,Yulei Qin,Haojia Lin,Zihan Xu,Gang Li,Yuchen Shi,Zongyi Li,Yong Mao,Siqi Cai,Xiaoyu Tan,Yitao Liang,Ke Li,Xing Sun*

Main category: cs.CL

TL;DR: 提出通过智能体主动生成关键快照自我验证任务完成，显著提升了自动化GUI任务中RL智能体的性能与可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于轨迹的任务完成验证存在冗长、噪声以及成本高、可靠性低的问题，限制了智能体在复杂GUI任务中的可扩展性，因此需要一种更高效且可靠的验证机制。

Method: 设计Self-Verifying Agent，赋予智能体双重使命：完成任务并生成符合3C原则（完整性、简洁性、创造性）的快照证据，利用在线环境进行主动自我验证，辅助LLM作为评判者高效判定任务完成。

Result: 本文提出了SmartSnap范式，将传统的事后任务完成验证转变为智能体自身主动的在位自我验证，解决了基于长交互轨迹的验证容易受到噪声影响且效率低的问题。通过设计自我验证智能体，使其在完成任务的同时，生成符合完整性、简洁性和创造性原则的关键快照证据，供大型语言模型作为评判者进行验证。实验证明，该方法在移动任务上显著提升了8B和30B模型性能，分别提高了26.08%和16.66%，显示了较强的可扩展性和竞争力。

Conclusion: SmartSnap范式有效提高了任务完成验证的效率与准确性，推动了基于大型语言模型的自主代理在复杂GUI任务中的可扩展发展。

Abstract: Agentic reinforcement learning (RL) holds great promise for the development of autonomous agents under complex GUI tasks, but its scalability remains severely hampered by the verification of task completion. Existing task verification is treated as a passive, post-hoc process: a verifier (i.e., rule-based scoring script, reward or critic model, and LLM-as-a-Judge) analyzes the agent's entire interaction trajectory to determine if the agent succeeds. Such processing of verbose context that contains irrelevant, noisy history poses challenges to the verification protocols and therefore leads to prohibitive cost and low reliability. To overcome this bottleneck, we propose SmartSnap, a paradigm shift from this passive, post-hoc verification to proactive, in-situ self-verification by the agent itself. We introduce the Self-Verifying Agent, a new type of agent designed with dual missions: to not only complete a task but also to prove its accomplishment with curated snapshot evidences. Guided by our proposed 3C Principles (Completeness, Conciseness, and Creativity), the agent leverages its accessibility to the online environment to perform self-verification on a minimal, decisive set of snapshots. Such evidences are provided as the sole materials for a general LLM-as-a-Judge verifier to determine their validity and relevance. Experiments on mobile tasks across model families and scales demonstrate that our SmartSnap paradigm allows training LLM-driven agents in a scalable manner, bringing performance gains up to 26.08% and 16.66% respectively to 8B and 30B models. The synergizing between solution finding and evidence seeking facilitates the cultivation of efficient, self-verifying agents with competitive performance against DeepSeek V3.1 and Qwen3-235B-A22B.

</details>


### [4] [The Syntax of qulk-clauses in Yemeni Ibbi Arabic: A Minimalist Approach](https://arxiv.org/abs/2512.22376)
*Zubaida Mohammed Albadani,Mohammed Q. Shormani*

Main category: cs.CL

TL;DR: 本文利用极简主义方法系统分析了也门伊比阿拉伯语中qulk从句的双分句结构及其句法生成机制，揭示其方言特征并对生成句法理论做出贡献。


<details>
  <summary>Details</summary>
Motivation: 探讨也门伊比阿拉伯语中qulk从句的句法结构，尤其是在极简主义框架下如何分析其形态和嵌套特性。

Method: 应用极简主义核心操作（Merge、Move、Agree和Spell-out）分析qulk从句的分层句法结构，并结合后句法过程如形态融合进行解释。

Result: 提出qulk从句是双分句结构，其中qulk作为从句嵌入谓词，选择一个空的CP补语，成功解释了qulk从句的生成过程及方言特征如双重否定、附着词化和CP嵌入。

Conclusion: 该研究不仅丰富了生成句法中的极简主义理论，也提出将该分析扩展到其他类似结构（如kil-k从句）的潜在可能，进一步探讨了极简主义的普遍性。

Abstract: This study investigates the syntax of qulk-clauses in Yemeni Ibbi Arabic (YIA) within the Minimalist Program. The construction qulk-clause, a morphologically fused form meaning 'I said,' introduces embedded declarative interrogative, and imperative clauses, often eithout complementizer. The central proposal of this paper is that qulk-clauses are biclausal structures in which qulk functions a clause-embedding predicate sec;ecting a dull CP complement. By applying core minimalist operations, viz., Merge, Move, Agree, and Spell-out, the study provides a layered syntactic analysis of qulk-clauses, for illustrating how their derivation proceeds through standard computational steps and post-syntactic processes such as Morphological Merger. The proposal also accounts for dialect-specific features like bipartite negation, cliticization, and CP embedding. The findings offer theoretical contributions to generative syntax, specifically minimalism. The study concludes raising theoretical questions concerning extending the analysis to the addressee-clause kil-k 'you said'. It also provides insights into the possibility of the universality of minimalism.

</details>


### [5] [Towards Efficient Post-Training via Fourier-Driven Adapter Architectures](https://arxiv.org/abs/2512.22378)
*Donggyun Bae,Jongil Park*

Main category: cs.CL

TL;DR: FAA通过随机傅里叶特征进行频率感知调制，实现参数高效且表现出色的语言模型微调。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法难以平衡参数效率和模型表示能力，FAA旨在通过频率感知机制实现高效且性能优异的微调。

Method: 引入随机傅里叶特征到轻量适配器模块，将中间表示分解为低频和高频部分，基于频率的激活和自适应加权机制实现语义调制。

Result: 本文提出了一种新颖的参数高效微调大规模预训练语言模型的框架，称为傅里叶激活适配器（FAA）。通过引入随机傅里叶特征至轻量级适配模块，FAA将中间表示分解为低频和高频成分，实现频率感知的语义信息调制。该设计使模型在微调时能够有选择地强调信息频段，同时保持模型骨干的表示能力。大量实验证明FAA在GLUE、E2E NLG及指令微调任务中表现优异，且计算和内存开销低。消融研究进一步验证了频率感知激活和自适应加权机制的有效性。

Conclusion: FAA是一种稳健且高效的大语言模型微调方法，能够选择性强化不同频率的语义信息，保持骨干模型性能并降低计算资源消耗。

Abstract: We propose a novel framework, termed Fourier-Activated Adapter (FAA), for parameter-efficient fine-tuning of large pre-trained language models. By incorporating random Fourier features into lightweight adapter modules, FAA decomposes intermediate representations into complementary low- and high-frequency components, enabling frequency-aware modulation of semantic information. This design allows the model to selectively emphasize informative frequency bands during adaptation while preserving the representational capacity of the frozen backbone. Extensive experiments on GLUE, E2E NLG, and instruction-tuning benchmarks demonstrate that FAA consistently achieves competitive or superior performance compared to existing parameter-efficient fine-tuning methods, while maintaining low computational and memory overhead. Ablation studies further verify the effectiveness of frequency-aware activation and adaptive weighting mechanisms, highlighting FAA as a robust and efficient approach for post-training large language models.

</details>


### [6] [LLM-Guided Exemplar Selection for Few-Shot Wearable-Sensor Human Activity Recognition](https://arxiv.org/abs/2512.22385)
*Elsen Ronando,Sozo Inoue*

Main category: cs.CL

TL;DR: 本研究提出一种结合LLM语义知识的示例选择框架，解决了少样本条件下的可穿戴设备人体活动识别难题，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统人体活动识别方法依赖大量标注数据且基于纯几何示例选择，难以区分相似活动如走路、上楼和下楼，亟需引入语义推理提升示例选择效果。

Method: 结合LLM生成的语义先验与结构性和几何性线索，通过边界验证、PageRank中心性、中心性惩罚和设施定位优化，实现了紧凑且信息丰富的示例集合选择。

Result: 在UCI-HAR数据集严格少样本条件下，提出方法实现了88.78%的宏F1分数，优于随机采样、聚类和$k$-中心等经典方法。

Conclusion: LLM引导的示例选择框架在少样本条件下优于传统方法，有效提升了可穿戴传感器的人体活动识别性能。

Abstract: In this paper, we propose an LLM-Guided Exemplar Selection framework to address a key limitation in state-of-the-art Human Activity Recognition (HAR) methods: their reliance on large labeled datasets and purely geometric exemplar selection, which often fail to distinguish similar weara-ble sensor activities such as walking, walking upstairs, and walking downstairs. Our method incorporates semantic reasoning via an LLM-generated knowledge prior that captures feature importance, inter-class confusability, and exemplar budget multipliers, and uses it to guide exemplar scoring and selection. These priors are combined with margin-based validation cues, PageRank centrality, hubness penalization, and facility-location optimization to obtain a compact and informative set of exemplars. Evaluated on the UCI-HAR dataset under strict few-shot conditions, the framework achieves a macro F1-score of 88.78%, outperforming classical approaches such as random sampling, herding, and $k$-center. The results show that LLM-derived semantic priors, when integrated with structural and geometric cues, provide a stronger foundation for selecting representative sensor exemplars in few-shot wearable-sensor HAR.

</details>


### [7] [Hallucination Detection and Evaluation of Large Language Model](https://arxiv.org/abs/2512.22416)
*Chenggong Zhang,Haopeng Wang*

Main category: cs.CL

TL;DR: 提出轻量级幻觉检测模型HHEM，大幅提升效率和准确率，改进局部幻觉检测，分析模型规模与幻觉关系。


<details>
  <summary>Details</summary>
Motivation: LLM幻觉影响内容可信，现有方法计算成本高，需更加高效准确的检测机制。

Method: 采用轻量级分类模型HHEM，结合片段检索技术，独立于LLM判断进行幻觉检测。

Result: HHEM显著降低检测时间，提高准确率，发现大模型幻觉较少，中型模型波动大。

Conclusion: 建议开发高效且具事实验证能力的评估框架以提升LLM内容可靠性。

Abstract: Hallucinations in Large Language Models (LLMs) pose a significant challenge, generating misleading or unverifiable content that undermines trust and reliability. Existing evaluation methods, such as KnowHalu, employ multi-stage verification but suffer from high computational costs. To address this, we integrate the Hughes Hallucination Evaluation Model (HHEM), a lightweight classification-based framework that operates independently of LLM-based judgments, significantly improving efficiency while maintaining high detection accuracy. We conduct a comparative analysis of hallucination detection methods across various LLMs, evaluating True Positive Rate (TPR), True Negative Rate (TNR), and Accuracy on question-answering (QA) and summarization tasks. Our results show that HHEM reduces evaluation time from 8 hours to 10 minutes, while HHEM with non-fabrication checking achieves the highest accuracy \(82.2\%\) and TPR \(78.9\%\). However, HHEM struggles with localized hallucinations in summarization tasks. To address this, we introduce segment-based retrieval, improving detection by verifying smaller text components. Additionally, our cumulative distribution function (CDF) analysis indicates that larger models (7B-9B parameters) generally exhibit fewer hallucinations, while intermediate-sized models show higher instability. These findings highlight the need for structured evaluation frameworks that balance computational efficiency with robust factual validation, enhancing the reliability of LLM-generated content.

</details>


### [8] [HiFi-RAG: Hierarchical Content Filtering and Two-Pass Generation for Open-Domain RAG](https://arxiv.org/abs/2512.22442)
*Cattalyya Nuengsigkapian*

Main category: cs.CL

TL;DR: HiFi-RAG通过多阶段层次过滤和双模型策略，有效提升开放域文本生成准确率，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决开放域RAG中检索文档信息无关性及生成答案与用户意图错配的问题。

Method: 采用分层过滤管道，结合Gemini 2.5 Flash进行查询生成、内容过滤和引用归属，利用Gemini 2.5 Pro进行最终答案生成。

Result: 在MMU-RAGent验证集上ROUGE-L提升19.6%，DeBERTaScore提升6.2%；在Test2025自定义数据集上ROUGE-L提升57.4%，DeBERTaScore提升14.9%。

Conclusion: HiFi-RAG通过多阶段流程显著提升了开放域RAG系统在生成答案的准确性和对用户意图的匹配度，取得了领先的竞赛成绩。

Abstract: Retrieval-Augmented Generation (RAG) in open-domain settings faces significant challenges regarding irrelevant information in retrieved documents and the alignment of generated answers with user intent. We present HiFi-RAG (Hierarchical Filtering RAG), the winning closed-source system in the Text-to-Text static evaluation of the MMU-RAGent NeurIPS 2025 Competition. Our approach moves beyond standard embedding-based retrieval via a multi-stage pipeline. We leverage the speed and cost-efficiency of Gemini 2.5 Flash (4-6x cheaper than Pro) for query formulation, hierarchical content filtering, and citation attribution, while reserving the reasoning capabilities of Gemini 2.5 Pro for final answer generation. On the MMU-RAGent validation set, our system outperformed the baseline, improving ROUGE-L to 0.274 (+19.6%) and DeBERTaScore to 0.677 (+6.2%). On Test2025, our custom dataset evaluating questions that require post-cutoff knowledge (post January 2025), HiFi-RAG outperforms the parametric baseline by 57.4% in ROUGE-L and 14.9% in DeBERTaScore.

</details>


### [9] [Exploring the Vertical-Domain Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2512.22443)
*Jie Zhou,Xin Chen,Jie Zhang,Zhe Li*

Main category: cs.CL

TL;DR: 本文针对大型语言模型（LLMs）在会计领域的推理能力进行评估，提出垂直领域会计推理的概念和评价标准，对多种模型的表现进行了比较，发现GPT-4表现最好，但当前模型仍未满足实际企业应用需求。


<details>
  <summary>Details</summary>
Motivation: 促进大型语言模型与专业会计领域的有效融合，推动企业数字化转型和社会发展，亟需理解和提升模型在会计领域的专业推理能力。

Method: 通过分析GLM系列模型的训练数据特性，建立垂直领域会计推理评价标准，并利用该标准评估GLM-6B、GLM-130B、GLM-4及OpenAI GPT-4等模型在会计推理任务上的表现，比较不同提示工程策略对模型性能的影响。

Result: 不同提示工程策略对模型性能提升有显著影响，GPT-4表现出最强的会计推理能力，但整体模型尚难满足真实企业会计应用的需求，需进一步优化以实现更广泛应用。

Conclusion: 虽然GPT-4在会计推理任务中表现出最佳能力，但现有大型语言模型仍不足以满足企业级会计场景的应用需求，需要进一步优化。

Abstract: Large Language Models (LLMs) are reshaping learning paradigms, cognitive processes, and research methodologies across a wide range of domains. Integrating LLMs with professional fields and redefining the relationship between LLMs and domain-specific applications has become a critical challenge for promoting enterprise digital transformation and broader social development. To effectively integrate LLMs into the accounting domain, it is essential to understand their domain-specific reasoning capabilities. This study introduces the concept of vertical-domain accounting reasoning and establishes evaluation criteria by analyzing the training data characteristics of representative GLM-series models. These criteria provide a foundation for subsequent research on reasoning paradigms and offer benchmarks for improving accounting reasoning performance. Based on this framework, we evaluate several representative models, including GLM-6B, GLM-130B, GLM-4, and OpenAI GPT-4, on a set of accounting reasoning tasks. Experimental results show that different prompt engineering strategies lead to varying degrees of performance improvement across models, with GPT-4 achieving the strongest accounting reasoning capability. However, current LLMs still fall short of real-world application requirements. In particular, further optimization is needed for deployment in enterprise-level accounting scenarios to fully realize the potential value of LLMs in this domain.

</details>


### [10] [Nested Browser-Use Learning for Agentic Information Seeking](https://arxiv.org/abs/2512.23647)
*Baixuan Li,Jialong Wu,Wenbiao Yin,Kuan Li,Zhongwang Zhang,Huifeng Yin,Zhengwei Tao,Liwen Zhang,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 本文提出NestBrowse，一个将浏览器交互控制与页面探索解耦的嵌套浏览框架，有效提升了信息检索智能体在深度网页搜索任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索智能体工具使用受限于API级别片段检索与URL页面抓取，无法充分利用真实浏览带来的丰富信息，且全浏览器交互存在细粒度控制复杂性和冗长页面内容处理难题。

Method: 提出NestBrowse方法，构建一个嵌套结构的浏览器动作框架，将交互控制与页面探索解耦，简化了代理的推理过程，提升了深度网页信息获取能力。

Result: 在具有挑战性的深度信息检索基准测试中，NestBrowse表现出明显优势，且分析结果显示其效率和灵活性较高。

Conclusion: NestBrowse框架通过简化浏览器交互控制与页面探索的耦合，实现了智能体在深度信息检索任务中的更高效表现，验证了其在深度信息检索任务中的有效性和灵活性。

Abstract: Information-seeking (IS) agents have achieved strong performance across a range of wide and deep search tasks, yet their tool use remains largely restricted to API-level snippet retrieval and URL-based page fetching, limiting access to the richer information available through real browsing. While full browser interaction could unlock deeper capabilities, its fine-grained control and verbose page content returns introduce substantial complexity for ReAct-style function-calling agents. To bridge this gap, we propose Nested Browser-Use Learning (NestBrowse), which introduces a minimal and complete browser-action framework that decouples interaction control from page exploration through a nested structure. This design simplifies agentic reasoning while enabling effective deep-web information acquisition. Empirical results on challenging deep IS benchmarks demonstrate that NestBrowse offers clear benefits in practice. Further in-depth analyses underscore its efficiency and flexibility.

</details>


### [11] [Constituency Structure over Eojeol in Korean Treebanks](https://arxiv.org/abs/2512.22487)
*Jungyeul Park,Chulwoo Park*

Main category: cs.CL

TL;DR: 本文提出以eojeol为基础的韩语句法树库注释方法，解决形态与句法成分混淆问题，实现不同树库的结构等价和跨库比较转换。


<details>
  <summary>Details</summary>
Motivation: 解决韩语形态复杂性与句法树库终端单元选择的矛盾，避免词内形态与短语结构的混淆，统一依存句法资源表示。

Method: 通过将形态细分和词性信息移至非成分层，比较Sejong和Penn树库，基于显式标准化假设，提出一种eojeol基础的注释方案。

Result: 本文探讨了韩语句法树库中终结单元的选择问题，主张以语法单元（eojeol）为构成成分终结节点，将形态分解和细粒度词性信息置于独立层。通过对Sejong和Penn韩国句法树库的比较分析，证明在明确标准化假设下，两者在eojeol级别的句法结构表示是等价的，并提出了基于eojeol的注释方案，可保持句法成分的可解释性，支持跨树库比较及依存句法转换。

Conclusion: 采用eojeol为基础单元的句法成分表示方法，使韩语句法树库间的比较和转换成为可能，提升了注释的一致性和解释性。

Abstract: The design of Korean constituency treebanks raises a fundamental representational question concerning the choice of terminal units. Although Korean words are morphologically complex, treating morphemes as constituency terminals conflates word internal morphology with phrase level syntactic structure and creates mismatches with eojeol based dependency resources. This paper argues for an eojeol based constituency representation, with morphological segmentation and fine grained part of speech information encoded in a separate, non constituent layer. A comparative analysis shows that, under explicit normalization assumptions, the Sejong and Penn Korean treebanks can be treated as representationally equivalent at the eojeol based constituency level. Building on this result, we outline an eojeol based annotation scheme that preserves interpretable constituency and supports cross treebank comparison and constituency dependency conversion.

</details>


### [12] [ManchuTTS: Towards High-Quality Manchu Speech Synthesis via Flow Matching and Hierarchical Text Representation](https://arxiv.org/abs/2512.22491)
*Suhua Wang,Zifan Wang,Xiaoxin Sun,D. J. Wang,Zhanbo Liu,Xin Li*

Main category: cs.CL

TL;DR: 本文针对满语的语言特性，提出了ManchuTTS语音合成方法，通过多层次文本表示和层次对比损失等技术，有效提升了合成语音的自然度和发音准确率。


<details>
  <summary>Details</summary>
Motivation: 满语作为一种濒危语言，存在数据稀缺和强烈的音系粘着性，给语音合成带来挑战。

Method: 采用三层文本表示（音素、音节、韵律）和跨模态层次注意力机制，结合深度卷积网络与流匹配Transformer进行非自回归语音合成，加入分层对比损失及数据增强策略。

Result: ManchuTTS模型在6.24小时的标注语料上训练，达到了4.52的MOS评分，显著优于基线模型。

Conclusion: 分层指导机制显著提升了满语粘着词的发音准确率和韵律自然度，证明了该方法在低资源条件下合成满语的有效性。

Abstract: As an endangered language, Manchu presents unique challenges for speech synthesis, including severe data scarcity and strong phonological agglutination. This paper proposes ManchuTTS(Manchu Text to Speech), a novel approach tailored to Manchu's linguistic characteristics. To handle agglutination, this method designs a three-tier text representation (phoneme, syllable, prosodic) and a cross-modal hierarchical attention mechanism for multi-granular alignment. The synthesis model integrates deep convolutional networks with a flow-matching Transformer, enabling efficient, non-autoregressive generation. This method further introduce a hierarchical contrastive loss to guide structured acoustic-linguistic correspondence. To address low-resource constraints, This method construct the first Manchu TTS dataset and employ a data augmentation strategy. Experiments demonstrate that ManchuTTS attains a MOS of 4.52 using a 5.2-hour training subset derived from our full 6.24-hour annotated corpus, outperforming all baseline models by a notable margin. Ablations confirm hierarchical guidance improves agglutinative word pronunciation accuracy (AWPA) by 31% and prosodic naturalness by 27%.

</details>


### [13] [Learning When Not to Attend Globally](https://arxiv.org/abs/2512.22562)
*Xuan Luo,Kailai Zhang,Xifeng Yan*

Main category: cs.CL

TL;DR: 本文提出了All-or-Here Attention (AHA)机制，通过动态切换全局注意力和局部滑动窗口注意力，高效处理上下文信息，实现大幅减少计算量且不损失性能。


<details>
  <summary>Details</summary>
Motivation: 受人类阅读行为启发，希望提高大模型处理长文本时的效率，减少冗余的全局注意力计算。

Method: 引入每个注意力头的二元路由器，在每个token处动态决定采用全局注意力或局部滑动窗口注意力。通过调整窗口大小评估影响，并分析上下文依赖的长尾分布。

Result: 在窗口大小为256的情况下，最多93%的全局注意力运算被局部滑动窗口注意力替代，性能无损。发现全文注意力需求随着局部窗口扩大迅速递减。

Conclusion: AHA机制成功实现动态选择注意力范围，大部分全局注意力操作可以被滑动窗口注意力替代，显著提升计算效率而不降低模型表现。

Abstract: When reading books, humans focus primarily on the current page, flipping back to recap prior context only when necessary. Similarly, we demonstrate that Large Language Models (LLMs) can learn to dynamically determine when to attend to global context. We propose All-or-Here Attention (AHA), which utilizes a binary router per attention head to dynamically toggle between full attention and local sliding window attention for each token. Our results indicate that with a window size of 256 tokens, up to 93\% of the original full attention operations can be replaced by sliding window attention without performance loss. Furthermore, by evaluating AHA across various window sizes, we identify a long-tail distribution in context dependency, where the necessity for full attention decays rapidly as the local window expands. By decoupling local processing from global access, AHA reveals that full attention is largely redundant, and that efficient inference requires only on-demand access to the global context.

</details>


### [14] [Structured Prompting and LLM Ensembling for Multimodal Conversational Aspect-based Sentiment Analysis](https://arxiv.org/abs/2512.22603)
*Zhiqiang Gao,Shihao Gao,Zixing Zhang,Yihao Guo,Hongyu Chen,Jing Han*

Main category: cs.CL

TL;DR: 该论文针对多模态会话中的情感分析挑战，设计了分步骤提取情感成分的结构化提示方法和多模型集成策略，提升情感成分识别和情感翻转检测的准确率。


<details>
  <summary>Details</summary>
Motivation: 多模态会话情感理解复杂且关键，需准确识别情感成分及动态情感变化以构建具情感智能的AI系统。

Method: 针对情感成分提取设计了结构化提示管道，利用大语言模型逐步提取六元组信信息；对情感翻转检测则采用三种大语言模型集成的方法。

Result: 系统在第一子任务中取得47.38%的平均分，第二子任务中获得74.12%的完全匹配F1分，显示方法有效。

Conclusion: 分步骤精细化提取和多模型集成策略有效提升了多模态会话情感分析的性能。

Abstract: Understanding sentiment in multimodal conversations is a complex yet crucial challenge toward building emotionally intelligent AI systems. The Multimodal Conversational Aspect-based Sentiment Analysis (MCABSA) Challenge invited participants to tackle two demanding subtasks: (1) extracting a comprehensive sentiment sextuple, including holder, target, aspect, opinion, sentiment, and rationale from multi-speaker dialogues, and (2) detecting sentiment flipping, which detects dynamic sentiment shifts and their underlying triggers. For Subtask-I, in the present paper, we designed a structured prompting pipeline that guided large language models (LLMs) to sequentially extract sentiment components with refined contextual understanding. For Subtask-II, we further leveraged the complementary strengths of three LLMs through ensembling to robustly identify sentiment transitions and their triggers. Our system achieved a 47.38% average score on Subtask-I and a 74.12% exact match F1 on Subtask-II, showing the effectiveness of step-wise refinement and ensemble strategies in rich, multimodal sentiment analysis tasks.

</details>


### [15] [Chain-of-thought Reviewing and Correction for Time Series Question Answering](https://arxiv.org/abs/2512.22627)
*Chen Su,Yuanhe Tian,Yan Song*

Main category: cs.CL

TL;DR: 提出基于三模型协作的T3LLM，通过多步推理与显式纠错机制提升时间序列问答准确率，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法在处理复杂时间序列数值推理时易出错，而时间序列数据具有可验证性，可通过一致性检查推理步骤与原始输入来纠正错误。基于此，提出引入显式纠正机制以提升推理准确性。

Method: 设计了T3LLM框架，该框架由三个大型语言模型组成：worker负责生成步骤推理链，reviewer负责审查推理过程并纠正错误，student通过学习正确的推理链进行多步推理能力内化。采用结构化提示促进worker生成推理链，reviewer提供纠正意见，最后用于微调student模型。

Result: 在多个真实世界时间序列问答基准测试中，T3LLM显著优于现有强基线，达到了最先进的性能。

Conclusion: T3LLM有效利用时间序列数据的可验证性，通过worker、reviewer和student三者协作实现多步推理与自我纠错，显著提升时间序列问答任务的性能。

Abstract: With the advancement of large language models (LLMs), diverse time series analysis tasks are reformulated as time series question answering (TSQA) through a unified natural language interface. However, existing LLM-based approaches largely adopt general natural language processing techniques and are prone to reasoning errors when handling complex numerical sequences. Different from purely textual tasks, time series data are inherently verifiable, enabling consistency checking between reasoning steps and the original input. Motivated by this property, we propose T3LLM, which performs multi-step reasoning with an explicit correction mechanism for time series question answering. The T3LLM framework consists of three LLMs, namely, a worker, a reviewer, and a student, that are responsible for generation, review, and reasoning learning, respectively. Within this framework, the worker generates step-wise chains of thought (CoT) under structured prompts, while the reviewer inspects the reasoning, identifies erroneous steps, and provides corrective comments. The collaboratively generated corrected CoT are used to fine-tune the student model, internalizing multi-step reasoning and self-correction into its parameters. Experiments on multiple real-world TSQA benchmarks demonstrate that T3LLM achieves state-of-the-art performance over strong LLM-based baselines.

</details>


### [16] [M2G-Eval: Enhancing and Evaluating Multi-granularity Multilingual Code Generation](https://arxiv.org/abs/2512.22628)
*Fanglin Xu,Wei Zhang,Jian Yang,Guo Chen,Aishan Liu,Zhoujun Li,Xianglong Liu,Bryan Dai*

Main category: cs.CL

TL;DR: 本文提出了一个多粒度、多语言的代码生成评估框架M2G-Eval，涵盖四个结构层级和18种编程语言，并通过对30个大型语言模型的评测，揭示了代码生成能力的细微差异和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估多聚焦单一结构粒度和少数语言，难以揭示代码生成能力在不同层级及多语言场景中的细粒度差异，迫切需要一个多维度、多语言的评估框架。

Method: 构建包含17K训练任务和1,286人工标注测试实例的多结构层级、多语言评估框架M2G-Eval，基于Qwen3-8B模型进行监督微调和组相对策略优化，系统评测30个大型语言模型。

Result: M2G-Eval评测结果显示任务难度从行、块、函数到类递增，复杂代码任务中语言间性能差距扩大，且模型表现出强跨语言相关性，体现出迁移编程知识的能力。

Conclusion: M2G-Eval可以细粒度诊断大型语言模型的代码生成能力，发现随着任务复杂度增加，不同结构层级和语言间性能差异加大，模型具备跨语言迁移编程概念的能力，但复杂长代码生成仍存在挑战。

Abstract: The rapid advancement of code large language models (LLMs) has sparked significant research interest in systematically evaluating their code generation capabilities, yet existing benchmarks predominantly assess models at a single structural granularity and focus on limited programming languages, obscuring fine-grained capability variations across different code scopes and multilingual scenarios. We introduce M2G-Eval, a multi-granularity, multilingual framework for evaluating code generation in large language models (LLMs) across four levels: Class, Function, Block, and Line. Spanning 18 programming languages, M2G-Eval includes 17K+ training tasks and 1,286 human-annotated, contamination-controlled test instances. We develop M2G-Eval-Coder models by training Qwen3-8B with supervised fine-tuning and Group Relative Policy Optimization. Evaluating 30 models (28 state-of-the-art LLMs plus our two M2G-Eval-Coder variants) reveals three main findings: (1) an apparent difficulty hierarchy, with Line-level tasks easiest and Class-level most challenging; (2) widening performance gaps between full- and partial-granularity languages as task complexity increases; and (3) strong cross-language correlations, suggesting that models learn transferable programming concepts. M2G-Eval enables fine-grained diagnosis of code generation capabilities and highlights persistent challenges in synthesizing complex, long-form code.

</details>


### [17] [On the Role of Discreteness in Diffusion LLMs](https://arxiv.org/abs/2512.22630)
*Ziqi Jin,Bin Wang,Xiang Lin,Lidong Bing,Aixin Sun*

Main category: cs.CL

TL;DR: 本文分析了扩散语言模型面临的离散文本挑战，指出现有方法的不足，强调设计更符合文本结构的扩散过程的重要性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型具并行解码和迭代优化优势，但文本的离散和结构特性限制了其直接应用，故需重新审视扩散机制与语言模型需求的匹配性。

Method: 将扩散语言模型分为嵌入空间的连续扩散和词元的离散扩散两类，分析其对五个扩散与语言建模核心属性的满足程度，结合大规模模型实验提炼关键挑战。

Result: 本文重新审视了扩散模型在语言生成中的应用，指出文本的离散性和结构性对扩散模型的直接应用带来挑战。论文总结了扩散过程与语言建模的五个核心属性，分析了现有方法在连续嵌入空间扩散和离散词元扩散两类中的表现及其权衡。通过对大型扩散语言模型的分析，发现两大关键问题：统一的噪声破坏方式忽视了信息在文本中的分布特点，且基于词元的边缘训练无法捕捉多词依赖，影响并行解码效果。本文提出未来应设计更符合文本结构的扩散过程，以提升模型生成的连贯性。

Conclusion: 目前扩散语言模型存在统一腐败机制和词元边缘训练导致的信息分布和多词依赖捕捉不足，需改进扩散过程以更好符合文本结构，提升语言生成质量。

Abstract: Diffusion models offer appealing properties for language generation, such as parallel decoding and iterative refinement, but the discrete and highly structured nature of text challenges the direct application of diffusion principles. In this paper, we revisit diffusion language modeling from the view of diffusion process and language modeling, and outline five properties that separate diffusion mechanics from language-specific requirements. We first categorize existing approaches into continuous diffusion in embedding space and discrete diffusion over tokens. We then show that each satisfies only part of the five essential properties and therefore reflects a structural trade-off. Through analyses of recent large diffusion language models, we identify two central issues: (i) uniform corruption does not respect how information is distributed across positions, and (ii) token-wise marginal training cannot capture multi-token dependencies during parallel decoding. These observations motivate diffusion processes that align more closely with the structure of text, and encourage future work toward more coherent diffusion language models.

</details>


### [18] [Evaluating GRPO and DPO for Faithful Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2512.22631)
*Hadi Mohammadi,Tamas Kozak,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 本文探讨了两种优化方法提升大语言模型连锁思维推理忠实性，结果显示GRPO在大型模型中更有效，有助于模型生成更透明可信的推理过程。


<details>
  <summary>Details</summary>
Motivation: 当前CoT推理虽提升了模型解决问题的能力，但存在推理解释与实际过程不符的问题，导致安全监督和对齐监控效果受限，因此探讨提升CoT忠实性的优化方法成为研究动力。

Method: 本文通过对比实验，评估GRPO和DPO两种优化策略在不同规模的大语言模型上的表现，采用一系列评价指标来衡量CoT推理的忠实性。

Result: 本文评估了两种优化方法——Group Relative Policy Optimization (GRPO) 和 Direct Preference Optimization (DPO)——在提升大语言模型连锁思维（CoT）推理忠实性方面的效果。实验发现，GRPO在较大模型上表现优于DPO，尤其是在Qwen2.5-14B-Instruct模型上取得最佳结果。两种方法的性能与模型规模呈正相关，但GRPO更有潜力提升忠实度指标，尽管在较小模型上表现不稳定。该研究为增强语言模型推理过程的透明度和可信度提供了有价值的方向。

Conclusion: GRPO在提升大型语言模型CoT推理忠实性方面表现优异，显示出增强模型推理透明度和可信性的潜力，是未来研究的有希望方向。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful technique for improving the problem-solving capabilities of large language models (LLMs), particularly for tasks requiring multi-step reasoning. However, recent studies show that CoT explanations often fail to reflect the model's actual reasoning process, as models may produce coherent yet misleading justifications or modify answers without acknowledging external cues. Such discrepancies undermine the reliability of CoT-based methods for safety supervision and alignment monitoring, as models can generate plausible but deceptive rationales for incorrect answers. To better understand this limitation, we evaluate two optimization methods, Group Relative Policy Optimization (GRPO) and Direct Preference Optimization (DPO), in their ability to improve CoT faithfulness. Our experiments show that GRPO achieves higher performance than DPO in larger models, with the Qwen2.5-14B-Instruct model attaining the best results across all evaluation metrics. Both approaches exhibit positive correlations between model size and performance, but GRPO shows greater potential for improving faithfulness metrics, albeit with less stable behavior at smaller scales. These results suggest that GRPO offers a promising direction for developing more transparent and trustworthy reasoning in LLMs.

</details>


### [19] [Fragile Knowledge, Robust Instruction-Following: The Width Pruning Dichotomy in Llama-3.2](https://arxiv.org/abs/2512.22671)
*Pere Martra*

Main category: cs.CL

TL;DR: MAW引导的宽度剪枝并非简单压缩，而是选择性地降低参数知识、提升行为对齐和指令跟随能力。扩展比是关键调控因素，剪枝带来效率与性能的权衡。


<details>
  <summary>Details</summary>
Motivation: 探索剪枝对模型不同能力的影响，挑战剪枝导致整体性能衰退的假设，揭示扩展比作为关键结构参数的作用。

Method: 采用最大绝对权重（MAW）标准对GLU-MLP层进行结构化宽度剪枝，测试七种扩展比配置，通过多种基准任务评估模型的不同认知能力。

Result: 在基于参数知识的任务（如MMLU、GSM8K）和困惑度指标上的表现下降，但指令跟随能力显著提升（IFEval提升46%-75%），多步推理能力保持强健。模型知识能力下降时，真诚性能力（TruthfulQA）反而增强，显著负相关（r=-0.864，p=0.012）。剪枝降低能耗23%，但单次请求延迟增加，批处理效率提升。

Conclusion: 宽度剪枝通过调整扩展比，系统性保存或提升了模型的特定认知能力，尤其增强指令跟随和行为对齐，挑战了剪枝必然性能下降的传统看法，并实现了能效优化。

Abstract: Structured width pruning of GLU-MLP layers, guided by the Maximum Absolute Weight (MAW) criterion, reveals a systematic dichotomy in how reducing the expansion ratio affects different model capabilities. While performance on tasks relying on parametric knowledge (e.g., MMLU, GSM8K) and perplexity metrics degrades predictably, instruction-following capabilities improve substantially (+46% to +75% in IFEval for Llama-3.2-1B and 3B models), and multi-step reasoning remains robust (MUSR). This pattern challenges the prevailing assumption that pruning induces uniform degradation. We evaluated seven expansion ratio configurations using comprehensive benchmarks assessing factual knowledge, mathematical reasoning, language comprehension, instruction-following, and truthfulness. Our analysis identifies the expansion ratio as a critical architectural parameter that selectively modulates cognitive capabilities, rather than merely serving as a compression metric. We provide the first systematic characterization of this selective preservation phenomenon. Notably, we document a robust inverse correlation (r = -0.864, p = 0.012 in Llama-3B) between factual knowledge capacity (MMLU) and truthfulness metrics (TruthfulQA-MC2): as knowledge degrades, the model's ability to discriminate misconceptions improves consistently. This connects two previously distinct research areas, demonstrating that MAW-guided width pruning acts as a selective filter, reducing parametric knowledge while preserving or enhancing behavioral alignment. Additionally, we quantify context-dependent efficiency trade-offs: pruned configurations achieve up to 23% reduction in energy consumption (J/token) but incur penalties in single-request latency, whereas batch processing workloads benefit uniformly.

</details>


### [20] [Conformal Prediction Sets for Next-Token Prediction in Large Language Models: Balancing Coverage Guarantees with Set Efficiency](https://arxiv.org/abs/2512.22682)
*Yoshith Roy Kotla,Varshith Roy Kotla*

Main category: cs.CL

TL;DR: 针对大词汇量语言模型预测集过大问题，提出VACP方法，显著提高预测效率且保证覆盖率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在高风险领域的部署需要准确的不确定性量化，而标准softmax概率校准较差，且传统方法生成的预测集合过大。

Method: 提出VACP方法，结合语义掩码和温度调整评分，优化大词汇量下的适应性预测集。

Result: 在Gemma-2B模型上，VACP方法在SQUAD和WikiText基准测试中，实现了89.7%的覆盖率（目标90%），同时将平均预测集合大小从847降至4.3，实现197倍效率提升。

Conclusion: 本文提出的Vocabulary-Aware Conformal Prediction (VACP) 框架成功在保证覆盖率的前提下，大幅减少了预测集的大小，提高了预测效率。

Abstract: Deploying large language models (LLMs) in high-stakes domains requires rigorous uncertainty quantification, yet standard softmax probabilities are often poorly calibrated. We present a systematic study of Adaptive Prediction Sets (APS) applied to next-token prediction in transformer-based models with large vocabularies (greater than 250,000 tokens). Our central contribution is the identification of a coverage-efficiency tradeoff: while naive conformal prediction achieves valid coverage, it produces prediction sets of hundreds of tokens, rendering them uninformative. We propose Vocabulary-Aware Conformal Prediction (VACP), a framework that leverages semantic masking and temperature-adjusted scoring to reduce the effective prediction space while provably maintaining marginal coverage. Experiments on Gemma-2B using SQUAD and WikiText benchmarks demonstrate that VACP achieves 89.7 percent empirical coverage (90 percent target) while reducing the mean prediction set size from 847 tokens to 4.3 tokens -- a 197x improvement in efficiency. We provide a theoretical analysis of vocabulary reduction and release our implementation for reproducibility.

</details>


### [21] [GHaLIB: A Multilingual Framework for Hope Speech Detection in Low-Resource Languages](https://arxiv.org/abs/2512.22705)
*Ahmed Abdullah,Sana Fatima,Haroon Mahmood*

Main category: cs.CL

TL;DR: 本文提出了基于多语言预训练模型的希望言论检测框架，重点支持低资源语言乌尔都语，实验表明该方法在多个语言上均能取得优异的性能，有助于促进积极的数字交流环境。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理领域对希望言论的研究较少，且多集中于英语，导致低资源语言如乌尔都语的相关资源缺乏，限制了促进积极在线交流的工具开发。

Method: 使用预训练的多语言转换器模型（XLM-RoBERTa、mBERT、EuroBERT、UrduBERT）结合简单预处理方法，构建多语言希望言论检测框架，重点针对低资源语言乌尔都语进行分类器训练。

Result: 在PolyHope-M 2025基准测试中，模型在乌尔都语二分类任务中取得了95.2%的F1分数，乌尔都语多分类任务取得65.2%的F1分数，西班牙语、德语和英语也表现出具有竞争力的成绩。

Conclusion: 多语言预训练模型在低资源语言环境中能够有效识别希望言论，为构建更具建设性的数字社交提供技术支持，展示了现有模型应用于语言资源匮乏场景的潜力。

Abstract: Hope speech has been relatively underrepresented in Natural Language Processing (NLP). Current studies are largely focused on English, which has resulted in a lack of resources for low-resource languages such as Urdu. As a result, the creation of tools that facilitate positive online communication remains limited. Although transformer-based architectures have proven to be effective in detecting hate and offensive speech, little has been done to apply them to hope speech or, more generally, to test them across a variety of linguistic settings. This paper presents a multilingual framework for hope speech detection with a focus on Urdu. Using pretrained transformer models such as XLM-RoBERTa, mBERT, EuroBERT, and UrduBERT, we apply simple preprocessing and train classifiers for improved results. Evaluations on the PolyHope-M 2025 benchmark demonstrate strong performance, achieving F1-scores of 95.2% for Urdu binary classification and 65.2% for Urdu multi-class classification, with similarly competitive results in Spanish, German, and English. These results highlight the possibility of implementing existing multilingual models in low-resource environments, thus making it easier to identify hope speech and helping to build a more constructive digital discourse.

</details>


### [22] [Beg to Differ: Understanding Reasoning-Answer Misalignment Across Languages](https://arxiv.org/abs/2512.22712)
*Anaelia Ovalle,Candace Ross,Sebastian Ruder,Adina Williams,Karen Ullrich,Mark Ibrahim,Levent Sagun*

Main category: cs.CL

TL;DR: 本文提出了一种多语言推理链验证框架，发现大型语言模型在非拉丁文字语言中推理结果与结论不一致的错误较多，强调了多语言推理能力评估的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在语言推理表现出色，但其推理质量跨语言是否一致尚未充分研究，尤其是推理链与结论的逻辑支持关系缺乏深入评估。

Method: 作者设计了一个人工验证的评估框架，利用人工注释方法对6种语言和6个模型在GlobalMMLU上的推理链进行系统分析，构建了错误类型分类体系，重点识别推理链与结论之间的逻辑一致性。

Result: 该论文研究了大型语言模型在多语言环境下链式推理的质量转移问题，提出了一个经过人工验证的评估框架，评估模型生成的推理链是否逻辑上支持其结论。通过分析6种语言、6个前沿模型在GlobalMMLU数据集上的6.5万个推理链，发现虽然模型在任务准确率上表现良好，但推理链与结论之间的逻辑对齐存在显著缺陷，特别是在非拉丁文字语言中，错误率至少是拉丁字母语言的两倍。通过人工注释形成错误分类，主要错误源自证据错误（无支持的断言、含糊事实）和不合逻辑的推理步骤。论文指出当前多语言评估方法无法全面反映模型推理能力，强调了构建推理能力感知评估框架的必要性。

Conclusion: 当前多语言评估方法未能完整反映大型语言模型的推理能力，尤其在非拉丁文字语言中推理逻辑支持结论的准确率较低，未来需开发推理感知的多语言评估体系。

Abstract: Large language models demonstrate strong reasoning capabilities through chain-of-thought prompting, but whether this reasoning quality transfers across languages remains underexplored. We introduce a human-validated framework to evaluate whether model-generated reasoning traces logically support their conclusions across languages. Analyzing 65k reasoning traces from GlobalMMLU questions across 6 languages and 6 frontier models, we uncover a critical blind spot: while models achieve high task accuracy, their reasoning can fail to support their conclusions. Reasoning traces in non-Latin scripts show at least twice as much misalignment between their reasoning and conclusions than those in Latin scripts. We develop an error taxonomy through human annotation to characterize these failures, finding they stem primarily from evidential errors (unsupported claims, ambiguous facts) followed by illogical reasoning steps. Our findings demonstrate that current multilingual evaluation practices provide an incomplete picture of model reasoning capabilities and highlight the need for reasoning-aware evaluation frameworks.

</details>


### [23] [Anka: A Domain-Specific Language for Reliable LLM Code Generation](https://arxiv.org/abs/2512.23214)
*Saif Khalfan Saif Al Mazrouei*

Main category: cs.CL

TL;DR: 本文提出了领域特定语言Anka，减少代码生成模糊性，提升了大语言模型在多步骤编程任务的准确度，证明专用语言优于通用语言的潜力。


<details>
  <summary>Details</summary>
Motivation: 多步骤编程任务中，通用语言的灵活性导致大语言模型（LLMs）产生系统性错误，需探索减少模糊性的专用语言。

Method: 设计并使用名为Anka的领域特定语言(DSL)，具有明确且受限的语法，减少代码生成中的歧义，并通过无预训练下的上下文提示让LLMs学习。

Result: Claude 3.5 Haiku在100个基准测试中取得99.9%解析成功率和95.8%任务准确率，在多步骤任务中，Anka比Python准确率高40个百分点（100% vs. 60%），GPT-4o-mini也验证了该优势。

Conclusion: 1）LLMs能通过上下文提示学习新DSL并达到近本地级准确率；2）受限语法显著降低复杂任务错误；3）专为LLM生成设计的DSL在多步骤任务上优于训练充分的通用语言。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation, yet they exhibit systematic errors on complex, multi-step programming tasks. We hypothesize that these errors stem from the flexibility of general-purpose languages, which permits multiple valid approaches and requires implicit state management. To test this hypothesis, we introduce Anka, a domain-specific language (DSL) for data transformation pipelines designed with explicit, constrained syntax that reduces ambiguity in code generation. Despite having zero prior training exposure to Anka, Claude 3.5 Haiku achieves 99.9% parse success and 95.8% overall task accuracy across 100 benchmark problems. Critically, Anka demonstrates a 40 percentage point accuracy advantage over Python on multi-step pipeline tasks (100% vs. 60%), where Python's flexible syntax leads to frequent errors in operation sequencing and variable management. Cross-model validation with GPT-4o-mini confirms this advantage (+26.7 percentage points on multi-step tasks). Our results demonstrate that: (1) LLMs can learn novel DSLs entirely from in-context prompts, achieving near-native accuracy; (2) constrained syntax significantly reduces errors on complex tasks; and (3) domain-specific languages purposefully designed for LLM generation can outperform general-purpose languages on which the LLM has extensive training. We release the complete language implementation, benchmark suite, and evaluation framework to facilitate further research.

</details>


### [24] [Mitigating Social Desirability Bias in Random Silicon Sampling](https://arxiv.org/abs/2512.22725)
*Sashank Chapala,Maksym Mironov,Songgaojun Deng*

Main category: cs.CL

TL;DR: 通过对提示语进行心理学指导的设计，可以有效减轻大型语言模型回答中的社会期望偏差，提高模拟数据的现实代表性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在模拟群体响应时存在社会期望偏差，导致回答偏向社会认可的答案，降低与真实人类数据的匹配度，需要探索有效的提示语设计来减轻这种偏差。

Method: 使用基于心理学的简短提示语，对三个大型语言模型（包括Llama-3.1系列和GPT-4.1-mini）进行社会期望偏差的实验，采用了重新表述、语义反转和两种元指令（激励分析和真诚）的提示控制技术。采用Jensen-Shannon散度和自助法置信区间评估模型回答与人类调查数据（ANES）的对齐度。

Result: 重新表述的提示语最有效地减少了社会期望偏差，使模型回答的分布更接近真实人类数据。语义反转的效果不一致，激励分析和真诚的元指令虽然增加了回答的一致性，但未能系统地减轻偏差。

Conclusion: 基于提示语的框架控制是一种行之有效的方法，可以调节大型语言模型回答中的社会期望偏差，为获得更具代表性的模拟样本提供实用路径。

Abstract: Large Language Models (LLMs) are increasingly used to simulate population responses, a method known as ``Silicon Sampling''. However, responses to socially sensitive questions frequently exhibit Social Desirability Bias (SDB), diverging from real human data toward socially acceptable answers. Existing studies on social desirability bias in LLM-based sampling remain limited. In this work, we investigate whether minimal, psychologically grounded prompt wording can mitigate this bias and improve alignment between silicon and human samples. We conducted a study using data from the American National Election Study (ANES) on three LLMs from two model families: the open-source Llama-3.1 series and GPT-4.1-mini. We first replicate a baseline silicon sampling study, confirming the persistent Social Desirability Bias. We then test four prompt-based mitigation methods: \emph{reformulated} (neutral, third-person phrasing), \emph{reverse-coded} (semantic inversion), and two meta-instructions, \emph{priming} and \emph{preamble}, respectively encouraging analytics and sincerity. Alignment with ANES is evaluated using Jensen-Shannon Divergence with bootstrap confidence intervals. Our results demonstrate that reformulated prompts most effectively improve alignment by reducing distribution concentration on socially acceptable answers and achieving distributions closer to ANES. Reverse-coding produced mixed results across eligible items, while the Priming and Preamble encouraged response uniformity and showed no systematic benefit for bias mitigation. Our findings validate the efficacy of prompt-based framing controls in mitigating inherent Social Desirability Bias in LLMs, providing a practical path toward more representative silicon samples.

</details>


### [25] [Data Augmentation for Classification of Negative Pregnancy Outcomes in Imbalanced Data](https://arxiv.org/abs/2512.22732)
*Md Badsha Biswas*

Main category: cs.CL

TL;DR: 本文提出利用Twitter社交媒体数据和自然语言处理技术，自动识别并分类孕期经历女性，以辅助研究美国婴儿死亡率相关的孕期不良结局，展示了社交媒体数据在公共卫生研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 美国婴儿死亡率依然是重大公共卫生问题，出生缺陷是主要原因。尽管已有研究关注怀孕不良结局，但仍缺乏更全面的研究数据和干预策略。利用社交媒体数据为孕期不良结局研究提供新的数据来源。

Method: 构建自然语言处理（NLP）流水线，自动识别和分类社交媒体上分享孕期经历的女性，根据报告的孕期结果进行分类。通过使用Twitter等公共社交媒体数据，结合数据预处理和增强技术应对数据不平衡、噪声和结构缺失问题。

Result: 成功开发了NLP管道识别孕妇并根据孕期结果分类，验证了社交媒体数据作为流行病学研究辅助资源的可行性。该方法可支持评估特定干预、治疗或产前暴露对母婴健康的因果影响，以及为未来孕妇队列研究提供框架。

Conclusion: 社交媒体数据通过自然语言处理技术可以有效补充现有孕期不良结局观测数据，支持因果影响分析和未来孕妇健康研究，展现出作为流行病学辅助资源的广泛应用前景。

Abstract: Infant mortality remains a significant public health concern in the United States, with birth defects identified as a leading cause. Despite ongoing efforts to understand the causes of negative pregnancy outcomes like miscarriage, stillbirths, birth defects, and premature birth, there is still a need for more comprehensive research and strategies for intervention. This paper introduces a novel approach that uses publicly available social media data, especially from platforms like Twitter, to enhance current datasets for studying negative pregnancy outcomes through observational research. The inherent challenges in utilizing social media data, including imbalance, noise, and lack of structure, necessitate robust preprocessing techniques and data augmentation strategies. By constructing a natural language processing (NLP) pipeline, we aim to automatically identify women sharing their pregnancy experiences, categorizing them based on reported outcomes. Women reporting full gestation and normal birth weight will be classified as positive cases, while those reporting negative pregnancy outcomes will be identified as negative cases. Furthermore, this study offers potential applications in assessing the causal impact of specific interventions, treatments, or prenatal exposures on maternal and fetal health outcomes. Additionally, it provides a framework for future health studies involving pregnant cohorts and comparator groups. In a broader context, our research showcases the viability of social media data as an adjunctive resource in epidemiological investigations about pregnancy outcomes.

</details>


### [26] [WeDLM: Reconciling Diffusion Language Models with Standard Causal Attention for Fast Inference](https://arxiv.org/abs/2512.22737)
*Aiwei Liu,Minghua He,Shaoxun Zeng,Sijun Zhang,Linhao Zhang,Chuhan Wu,Wei Jia,Yuan Liu,Xiao Zhou,Jie Zhou*

Main category: cs.CL

TL;DR: WeDLM通过拓扑重排序与因果注意力结合，优化扩散语言模型解码，实现比优化AR引擎更快的并行生成，显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: AR生成虽然是LLM的标准解码方式，但其逐字生成限制了推理时并行性。DLLMs通过并行恢复多个掩码词提供了解码加速潜力，但受制于双向注意力导致的效率问题，未能实际跑赢优化过的AR引擎。

Method: 提出WeDLM，基于标准因果注意力的扩散解码框架，通过拓扑重排序将观察词移动到物理前缀保持严格因果掩码，实现并行生成且友好前缀缓存，并引入流式解码持续锁定高置信度词，避免块扩散的停顿等待。

Result: WeDLM在保留强AR模型质量的同时，在硬推理任务上实现近3倍加速，低熵生成上最高达10倍，且在与优化AR引擎(vLLM)的公平对比中表现更优。

Conclusion: WeDLM验证了扩散解码结合因果注意力和拓扑重排序可突破AR解码并行性瓶颈，实现实际部署中的显著速度提升，同时保证生成质量。

Abstract: Autoregressive (AR) generation is the standard decoding paradigm for Large Language Models (LLMs), but its token-by-token nature limits parallelism at inference time. Diffusion Language Models (DLLMs) offer parallel decoding by recovering multiple masked tokens per step; however, in practice they often fail to translate this parallelism into deployment speed gains over optimized AR engines (e.g., vLLM). A key reason is that many DLLMs rely on bidirectional attention, which breaks standard prefix KV caching and forces repeated contextualization, undermining efficiency. We propose WeDLM, a diffusion decoding framework built entirely on standard causal attention to make parallel generation prefix-cache friendly. The core idea is to let each masked position condition on all currently observed tokens while keeping a strict causal mask, achieved by Topological Reordering that moves observed tokens to the physical prefix while preserving their logical positions. Building on this property, we introduce a streaming decoding procedure that continuously commits confident tokens into a growing left-to-right prefix and maintains a fixed parallel workload, avoiding the stop-and-wait behavior common in block diffusion methods. Experiments show that WeDLM preserves the quality of strong AR backbones while delivering substantial speedups, approaching 3x on challenging reasoning benchmarks and up to 10x in low-entropy generation regimes; critically, our comparisons are against AR baselines served by vLLM under matched deployment settings, demonstrating that diffusion-style decoding can outperform an optimized AR engine in practice.

</details>


### [27] [Harnessing Large Language Models for Biomedical Named Entity Recognition](https://arxiv.org/abs/2512.22738)
*Jian Chen,Leilei Su,Cong Sun*

Main category: cs.CL

TL;DR: 本文提出BioSelectTune，一种注重数据质量的高效微调框架，显著提升生物医学命名实体识别性能，胜过多种先进模型。


<details>
  <summary>Details</summary>
Motivation: 医学领域的大型语言模型在生物医学命名实体识别任务中存在领域知识缺乏及训练数据质量低导致性能下降的问题。

Method: 将BioNER任务重构为结构化JSON生成问题，并使用弱到强的混合超滤策略，通过同源弱模型提炼紧凑高效的训练集。

Result: 提出了BioSelectTune框架，通过结构化JSON生成和混合超滤策略，有效筛选高质量训练数据，实现了BioNER任务的最先进性能，且使用的数据量仅为全部数据的50%。

Conclusion: BioSelectTune在多个BioNER基准测试中表现优异，使用一半优质数据就能超越传统全量训练和专业模型，展示了数据质量优先策略的有效性。

Abstract: Background and Objective: Biomedical Named Entity Recognition (BioNER) is a foundational task in medical informatics, crucial for downstream applications like drug discovery and clinical trial matching. However, adapting general-domain Large Language Models (LLMs) to this task is often hampered by their lack of domain-specific knowledge and the performance degradation caused by low-quality training data. To address these challenges, we introduce BioSelectTune, a highly efficient, data-centric framework for fine-tuning LLMs that prioritizes data quality over quantity. Methods and Results: BioSelectTune reformulates BioNER as a structured JSON generation task and leverages our novel Hybrid Superfiltering strategy, a weak-to-strong data curation method that uses a homologous weak model to distill a compact, high-impact training dataset. Conclusions: Through extensive experiments, we demonstrate that BioSelectTune achieves state-of-the-art (SOTA) performance across multiple BioNER benchmarks. Notably, our model, trained on only 50% of the curated positive data, not only surpasses the fully-trained baseline but also outperforms powerful domain-specialized models like BioMedBERT.

</details>


### [28] [Text-Routed Sparse Mixture-of-Experts Model with Explanation and Temporal Alignment for Multi-Modal Sentiment Analysis](https://arxiv.org/abs/2512.22741)
*Dongning Rao,Yunbiao Zeng,Zhihua Jiang,Jujian Lv*

Main category: cs.CL

TL;DR: 本文提出的TEXT模型通过解释增强和时间对齐提升多模态情感分析，取得了多项指标上的领先表现。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互应用中，多模态情感分析（MSA）需求增加，但现有关解释能力和时间对齐方法的探索不足。

Method: 提出了基于文本路由的稀疏专家混合模型TEXT，该模型通过多模态大语言模型增强解释能力，并通过时间导向的神经网络块实现音频和视频的时间对齐，结合门控融合实现多模态对齐。

Result: 在四个数据集上，TEXT在包括三种最新方法和三种多模态大语言模型的所有测试模型中表现最佳，在至少六个指标中的四个指标取得领先，如在CH-SIMS数据集上MAE下降13.5%至0.353。

Conclusion: TEXT通过引入解释增强和时间对齐机制，显著提升了多模态情感分析的性能，证明了该方法的有效性。

Abstract: Human-interaction-involved applications underscore the need for Multi-modal Sentiment Analysis (MSA). Although many approaches have been proposed to address the subtle emotions in different modalities, the power of explanations and temporal alignments is still underexplored. Thus, this paper proposes the Text-routed sparse mixture-of-Experts model with eXplanation and Temporal alignment for MSA (TEXT). TEXT first augments explanations for MSA via Multi-modal Large Language Models (MLLM), and then novelly aligns the epresentations of audio and video through a temporality-oriented neural network block. TEXT aligns different modalities with explanations and facilitates a new text-routed sparse mixture-of-experts with gate fusion. Our temporal alignment block merges the benefits of Mamba and temporal cross-attention. As a result, TEXT achieves the best performance cross four datasets among all tested models, including three recently proposed approaches and three MLLMs. TEXT wins on at least four metrics out of all six metrics. For example, TEXT decreases the mean absolute error to 0.353 on the CH-SIMS dataset, which signifies a 13.5% decrement compared with recently proposed approaches.

</details>


### [29] [Fake News Classification in Urdu: A Domain Adaptation Approach for a Low-Resource Language](https://arxiv.org/abs/2512.22778)
*Muhammad Zain Ali,Bernhard Pfahringer,Tony Smith*

Main category: cs.CL

TL;DR: 本文针对乌尔都语虚假新闻检测，提出利用领域自适应预训练提升多语言预训练模型的表现，实验表明领域适应的XLM-RoBERTa效果最佳。


<details>
  <summary>Details</summary>
Motivation: 现有多语言预训练模型在处理低资源语言及其特定领域术语时表现欠佳，需要通过领域适应改进模型泛化能力。

Method: 采用分阶段训练方法，先进行领域自适应预训练，再进行下游虚假新闻分类任务的微调。

Result: 在四个公开乌尔都语虚假新闻数据集上，领域适应XLM-RoBERTa显著优于未适应模型，mBERT结果则不稳定。

Conclusion: 领域适应预训练显著提升了XLM-RoBERTa在乌尔都语虚假新闻分类任务上的表现，而mBERT的效果表现不稳定。

Abstract: Misinformation on social media is a widely acknowledged issue, and researchers worldwide are actively engaged in its detection. However, low-resource languages such as Urdu have received limited attention in this domain. An obvious approach is to utilize a multilingual pretrained language model and fine-tune it for a downstream classification task, such as misinformation detection. However, these models struggle with domain-specific terms, leading to suboptimal performance. To address this, we investigate the effectiveness of domain adaptation before fine-tuning for fake news classification in Urdu, employing a staged training approach to optimize model generalization. We evaluate two widely used multilingual models, XLM-RoBERTa and mBERT, and apply domain-adaptive pretraining using a publicly available Urdu news corpus. Experiments on four publicly available Urdu fake news datasets show that domain-adapted XLM-R consistently outperforms its vanilla counterpart, while domain-adapted mBERT exhibits mixed results.

</details>


### [30] [CNSight: Evaluation of Clinical Note Segmentation Tools](https://arxiv.org/abs/2512.22795)
*Risha Surana,Adrian Law,Sunwoo Kim,Rishab Sridhar,Angxiao Han,Peiyu Hong*

Main category: cs.CL

TL;DR: 本研究比较了多种方法在临床笔记章节分割中的效果，发现大型语言模型效果最佳，为临床数据结构化和下游应用奠定基础。


<details>
  <summary>Details</summary>
Motivation: 临床笔记通常以非结构化或半结构化格式存储，导致其在二次分析和临床应用中难以使用，因此需要可靠的章节边界识别来实现笔记的结构化。

Method: 评估了基于规则的基线方法、领域特定的变换器模型和大型语言模型，使用来自MIMIC-IV的1000条临床笔记数据集进行分割任务。

Result: 大型基于API的模型，如GPT-5-mini，在句子级和自由文本分割任务中平均F1得分达72.4，表现优于其他方法。轻量级基线在结构化句子任务中依然有竞争力，但在自由文本处理中表现较差。

Conclusion: 大型语言模型在临床笔记分割任务中表现最佳，尤其是在非结构化自由文本的处理上表现突出，而轻量级模型则更适合结构化句子级任务。

Abstract: Clinical notes are often stored in unstructured or semi-structured formats after extraction from electronic medical record (EMR) systems, which complicates their use for secondary analysis and downstream clinical applications. Reliable identification of section boundaries is a key step toward structuring these notes, as sections such as history of present illness, medications, and discharge instructions each provide distinct clinical contexts. In this work, we evaluate rule-based baselines, domain-specific transformer models, and large language models for clinical note segmentation using a curated dataset of 1,000 notes from MIMIC-IV. Our experiments show that large API-based models achieve the best overall performance, with GPT-5-mini reaching a best average F1 of 72.4 across sentence-level and freetext segmentation. Lightweight baselines remain competitive on structured sentence-level tasks but falter on unstructured freetext. Our results provide guidance for method selection and lay the groundwork for downstream tasks such as information extraction, cohort identification, and automated summarization.

</details>


### [31] [NepEMO: A Multi-Label Emotion and Sentiment Analysis on Nepali Reddit with Linguistic Insights and Temporal Trends](https://arxiv.org/abs/2512.22823)
*Sameer Sitoula,Tej Bahadur Shahi,Laxmi Prasad Bhatt,Anisha Pokhrel,Arjun Neupane*

Main category: cs.CL

TL;DR: 本研究构建了一个尼泊尔语Reddit帖子的多标签情绪与情感分类数据集NepEMO，综合对比了多种模型，发现transformer表现最佳。


<details>
  <summary>Details</summary>
Motivation: 社交媒体，尤其是Reddit，成为用户匿名分享敏感话题（如健康和日常生活）情感的独特空间，因此需要针对尼泊尔语帖子进行多标签情绪和情感分类的数据和模型。

Method: 构建包含4462条帖子（英语、罗马化尼泊尔语和天城文）的手工标注数据集，涵盖五种情绪（恐惧、愤怒、悲伤、喜悦和抑郁）以及三种情感类别（正面、负面、中性），使用传统机器学习、深度学习和transformer模型进行多标签情绪和情感分类。

Result: 通过详细的语言学分析捕捉情绪趋势、情绪共现、情感特定n-gram和主题建模，实验结果显示transformer模型在情绪和情感分类任务上优于传统机器学习和深度学习模型。

Conclusion: NepEMO数据集和分析揭示了尼泊尔语社交媒体帖子中的情绪和情感分布，证实transformer模型在该任务中的优越性，为未来相关情绪分析研究提供了重要资源和基线。

Abstract: Social media (SM) platforms (e.g. Facebook, Twitter, and Reddit) are increasingly leveraged to share opinions and emotions, specifically during challenging events, such as natural disasters, pandemics, and political elections, and joyful occasions like festivals and celebrations. Among the SM platforms, Reddit provides a unique space for its users to anonymously express their experiences and thoughts on sensitive issues such as health and daily life. In this work, we present a novel dataset, called NepEMO, for multi-label emotion (MLE) and sentiment classification (SC) on the Nepali subreddit post. We curate and build a manually annotated dataset of 4,462 posts (January 2019- June 2025) written in English, Romanised Nepali and Devanagari script for five emotions (fear, anger, sadness, joy, and depression) and three sentiment classes (positive, negative, and neutral). We perform a detailed analysis of posts to capture linguistic insights, including emotion trends, co-occurrence of emotions, sentiment-specific n-grams, and topic modelling using Latent Dirichlet Allocation and TF-IDF keyword extraction. Finally, we compare various traditional machine learning (ML), deep learning (DL), and transformer models for MLE and SC tasks. The result shows that transformer models consistently outperform the ML and DL models for both tasks.

</details>


### [32] [AutoForge: Automated Environment Synthesis for Agentic Reinforcement Learning](https://arxiv.org/abs/2512.22857)
*Shihao Cai,Runnan Fang,Jialong Wu,Baixuan Li,Xinyu Wang,Yong Jiang,Liangcai Su,Liwen Zhang,Wenbiao Yin,Zhen Zhang,Fuli Feng,Pengjun Xie,Xiaobin Wang*

Main category: cs.CL

TL;DR: 本文设计了自动化高难度模拟环境生成和环境级强化学习算法，提升了语言代理的训练效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言代理强化学习多局限于半自动化环境生成或难度不足的任务，且模拟用户的不稳定性及环境异质性影响了训练表现和泛化能力，需提出新的方法提升训练的广度、深度与稳定性。

Method: 本文提出了两个核心方法：1）一个可自动且可扩展地合成高难度且易于验证任务的模拟环境流水线；2）一种环境级强化学习算法，能够缓解用户不稳定性问题，并在环境层面进行优势估计，提高训练效率和稳定性。

Result: 本文提出了一个统一的自动化且可扩展的高难度模拟环境合成流程，以及一种能够缓解模拟用户不稳定性的环境级强化学习算法。实验表明该方法在多个代理强化学习基准测试中表现优异，并具备良好的跨领域泛化能力。

Conclusion: 通过统一的自动化环境合成和环境级RL算法，本文显著提升了模拟环境中语言代理训练的难度、效率和稳定性，并验证了其优越的跨领域泛化性能。

Abstract: Conducting reinforcement learning (RL) in simulated environments offers a cost-effective and highly scalable way to enhance language-based agents. However, previous work has been limited to semi-automated environment synthesis or tasks lacking sufficient difficulty, offering little breadth or depth. In addition, the instability of simulated users integrated into these environments, along with the heterogeneity across simulated environments, poses further challenges for agentic RL. In this work, we propose: (1) a unified pipeline for automated and scalable synthesis of simulated environments associated with high-difficulty but easily verifiable tasks; and (2) an environment level RL algorithm that not only effectively mitigates user instability but also performs advantage estimation at the environment level, thereby improving training efficiency and stability. Comprehensive evaluations on agentic benchmarks, including tau-bench, tau2-Bench, and VitaBench, validate the effectiveness of our proposed method. Further in-depth analyses underscore its out-of-domain generalization.

</details>


### [33] [Diversity or Precision? A Deep Dive into Next Token Prediction](https://arxiv.org/abs/2512.22955)
*Haoyuan Wu,Hai Wang,Jiajia Wu,Jinxiang Ou,Keyao Wang,Weile Chen,Zihao Zheng,Bei Yu*

Main category: cs.CL

TL;DR: 本文将交叉熵损失视为单步策略梯度优化的一种形式，提出通过奖励塑形调整token预测分布，改善强化学习的探索空间，以增强大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习能够显著提升大语言模型的推理能力，但其效果依赖于预训练模型的token输出分布所定义的探索空间。理解和改进这一探索空间对于提升强化学习训练效果至关重要。

Method: 将下一token预测看作随机决策过程，引入奖励塑形策略，包括正奖励缩放和平等级别感知机制，分别控制正确token的概率集中度和对不同负样本的非对称处理，从而调整token输出分布，优化强化学习的探索空间。

Result: 提出了一种基于强化学习原则的广义预训练目标，通过奖励塑形策略平衡多样性与精确度，重新塑造预训练token分布，验证了以精确度为导向的先验比高熵分布更有利于强化学习的探索空间，从而提升推理性能。

Conclusion: 实验表明，采用以精度为导向的token分布先验比简单提升分布熵更能促进强化学习探索空间的构建，从而提高大语言模型在推理任务上的表现。

Abstract: Recent advancements have shown that reinforcement learning (RL) can substantially improve the reasoning abilities of large language models (LLMs). The effectiveness of such RL training, however, depends critically on the exploration space defined by the pre-trained model's token-output distribution. In this paper, we revisit the standard cross-entropy loss, interpreting it as a specific instance of policy gradient optimization applied within a single-step episode. To systematically study how the pre-trained distribution shapes the exploration potential for subsequent RL, we propose a generalized pre-training objective that adapts on-policy RL principles to supervised learning. By framing next-token prediction as a stochastic decision process, we introduce a reward-shaping strategy that explicitly balances diversity and precision. Our method employs a positive reward scaling factor to control probability concentration on ground-truth tokens and a rank-aware mechanism that treats high-ranking and low-ranking negative tokens asymmetrically. This allows us to reshape the pre-trained token-output distribution and investigate how to provide a more favorable exploration space for RL, ultimately enhancing end-to-end reasoning performance. Contrary to the intuition that higher distribution entropy facilitates effective exploration, we find that imposing a precision-oriented prior yields a superior exploration space for RL.

</details>


### [34] [Prompt engineering does not universally improve Large Language Model performance across clinical decision-making tasks](https://arxiv.org/abs/2512.22966)
*Mengdi Chai,Ali R. Zomorrodi*

Main category: cs.CL

TL;DR: 该研究评估了三款先进大语言模型在临床决策支持中的表现，发现模型在不同任务上的准确性差异较大，提示工程对性能提升效果有限且依赖模型和任务。


<details>
  <summary>Details</summary>
Motivation: 当前虽有大语言模型在医学知识评估中的应用，但其在实际临床决策中的效用及连续推理能力尚不明确。

Method: 研究通过36个临床案例测试了三款大语言模型在五个关键临床任务中的表现，并比较了不同温度设置和提示工程（MedPrompt框架下的动态few-shot学习）对模型性能的影响。

Result: 模型在最终诊断任务中表现接近完美，但在相关诊断测试任务中表现较差。提示工程提升了诊断测试任务的准确率，但对其他任务有负面影响；动态few-shot学习的针对性选择未必优于随机选择。

Conclusion: 大语言模型在临床决策支持中表现存在任务依赖性，提示工程并非万能，需针对具体任务和模型制定个性化方案。

Abstract: Large Language Models (LLMs) have demonstrated promise in medical knowledge assessments, yet their practical utility in real-world clinical decision-making remains underexplored. In this study, we evaluated the performance of three state-of-the-art LLMs-ChatGPT-4o, Gemini 1.5 Pro, and LIama 3.3 70B-in clinical decision support across the entire clinical reasoning workflow of a typical patient encounter. Using 36 case studies, we first assessed LLM's out-of-the-box performance across five key sequential clinical decision-making tasks under two temperature settings (default vs. zero): differential diagnosis, essential immediate steps, relevant diagnostic testing, final diagnosis, and treatment recommendation. All models showed high variability by task, achieving near-perfect accuracy in final diagnosis, poor performance in relevant diagnostic testing, and moderate performance in remaining tasks. Furthermore, ChatGPT performed better under the zero temperature, whereas LIama showed stronger performance under the default temperature. Next, we assessed whether prompt engineering could enhance LLM performance by applying variations of the MedPrompt framework, incorporating targeted and random dynamic few-shot learning. The results demonstrate that prompt engineering is not a one-size-fit-all solution. While it significantly improved the performance on the task with lowest baseline accuracy (relevant diagnostic testing), it was counterproductive for others. Another key finding was that the targeted dynamic few-shot prompting did not consistently outperform random selection, indicating that the presumed benefits of closely matched examples may be counterbalanced by loss of broader contextual diversity. These findings suggest that the impact of prompt engineering is highly model and task-dependent, highlighting the need for tailored, context-aware strategies for integrating LLMs into healthcare.

</details>


### [35] [Improving Generalization in LLM Structured Pruning via Function-Aware Neuron Grouping](https://arxiv.org/abs/2512.23014)
*Tao Yu,Yongqi An,Kuan Zhu,Guibo Zhu,Ming Tang,Jinqiao Wang*

Main category: cs.CL

TL;DR: 本文提出FANG框架，通过函数感知的神经元分组和加权稀疏策略，实现了对大语言模型更高效且准确的结构化剪枝，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练结构化剪枝方法在少样本校准集未能充分反映预训练数据分布时，表现出有限的泛化能力。

Method: 提出了函数感知神经元分组(FANG)框架，通过基于神经元处理的语义上下文类型进行分组，并在估计重要性时对功能相关的token赋予更高权重，同时自适应分配稀疏率。

Result: FANG提升了下游任务准确率和语言模型性能，结合FLAP和OBC方法达到当前最佳结果，在30%和40%稀疏率下，准确率提升1.5%-8.5%。

Conclusion: FANG有效缓解了校准偏差问题，提升了剪枝方法在实际应用中的泛化能力和性能表现。

Abstract: Large Language Models (LLMs) demonstrate impressive performance across natural language tasks but incur substantial computational and storage costs due to their scale. Post-training structured pruning offers an efficient solution. However, when few-shot calibration sets fail to adequately reflect the pretraining data distribution, existing methods exhibit limited generalization to downstream tasks. To address this issue, we propose Function-Aware Neuron Grouping (FANG), a post-training pruning framework that alleviates calibration bias by identifying and preserving neurons critical to specific function. FANG groups neurons with similar function based on the type of semantic context they process and prunes each group independently. During importance estimation within each group, tokens that strongly correlate with the functional role of the neuron group are given higher weighting. Additionally, FANG also preserves neurons that contribute across multiple context types. To achieve a better trade-off between sparsity and performance, it allocates sparsity to each block adaptively based on its functional complexity. Experiments show that FANG improves downstream accuracy while preserving language modeling performance. It achieves the state-of-the-art (SOTA) results when combined with FLAP and OBC, two representative pruning methods. Specifically, FANG outperforms FLAP and OBC by 1.5%--8.5% in average accuracy under 30% and 40% sparsity.

</details>


### [36] [LENS: LLM-Enabled Narrative Synthesis for Mental Health by Aligning Multimodal Sensing with Language Models](https://arxiv.org/abs/2512.23025)
*Wenxuan Xu,Arvind Pillai,Subigya Nepal,Amanda C Collins,Daniel M Mackin,Michael V Heinz,Tess Z Griffin,Nicholas C Jacobson,Andrew Campbell*

Main category: cs.CL

TL;DR: 本文提出LENS框架，结合多模态传感数据与大型语言模型，成功生成临床相关的精神健康文本描述，提升了精神健康评估的自动化与临床应用价值。


<details>
  <summary>Details</summary>
Motivation: 多模态健康感知提供丰富的行为信号用于评估精神健康，但如何将这些数值时间序列数据转换为自然语言描述存在困难。当前大型语言模型（LLMs）无法原生处理长时间的传感器数据流，且缺乏传感器与文本配对的数据集。

Method: 提出LENS框架，通过构建大规模的传感器-文本问答对数据集（基于生态瞬时评估EMA数据转换而成），并训练一种补丁级编码器将原始传感信号直接映射到语言模型的表示空间，实现多模态数据与语言模型的对齐。

Result: LENS在标准自然语言处理指标和症状严重度的任务特定测评中优于现有强基线方法。用户研究显示，LENS生成的叙述内容全面且具临床意义。

Conclusion: 该方法推动了大型语言模型作为健康感知接口的发展，为模型直接推理原始行为信号并支持临床决策提供了可扩展路径。

Abstract: Multimodal health sensing offers rich behavioral signals for assessing mental health, yet translating these numerical time-series measurements into natural language remains challenging. Current LLMs cannot natively ingest long-duration sensor streams, and paired sensor-text datasets are scarce. To address these challenges, we introduce LENS, a framework that aligns multimodal sensing data with language models to generate clinically grounded mental-health narratives. LENS first constructs a large-scale dataset by transforming Ecological Momentary Assessment (EMA) responses related to depression and anxiety symptoms into natural-language descriptions, yielding over 100,000 sensor-text QA pairs from 258 participants. To enable native time-series integration, we train a patch-level encoder that projects raw sensor signals directly into an LLM's representation space. Our results show that LENS outperforms strong baselines on standard NLP metrics and task-specific measures of symptom-severity accuracy. A user study with 13 mental-health professionals further indicates that LENS-produced narratives are comprehensive and clinically meaningful. Ultimately, our approach advances LLMs as interfaces for health sensing, providing a scalable path toward models that can reason over raw behavioral signals and support downstream clinical decision-making.

</details>


### [37] [Is Chain-of-Thought Really Not Explainability? Chain-of-Thought Can Be Faithful without Hint Verbalization](https://arxiv.org/abs/2512.23032)
*Kerem Zaman,Shashank Srivastava*

Main category: cs.CL

TL;DR: 本文指出Biasing Features指标误将CoT不完整性误判为不忠实，提出faithful@k指标并结合因果中介分析，展示增加token预算提升忠实度，主张多元评估方法避免误判。


<details>
  <summary>Details</summary>
Motivation: 当前使用Biasing Features指标将省略提示线索的Chain-of-Thought(CoT)标记为不忠实，但该指标可能将不忠实性误判为不完整性，即将复杂计算压缩为线性语言叙述时的自然信息丢失。

Method: 在多个多跳推理任务上，使用Llama-3和Gemma-3模型，通过Biasing Features指标、其他忠实度指标和新提出的faithful@k指标进行评估，并采用因果中介分析探究未言明的提示对预测的因果影响。

Result: 发现许多被Biasing Features判定为不忠实的CoT在其他指标下显示忠实度超过50%；增加推理时的token预算能显著提升提示言明率（最高达90%）；未言明的提示也能通过CoT对预测产生因果影响。

Conclusion: 提示线索基础的评估指标容易混淆不忠实与不完整，建议避免单一依赖此类指标，应结合因果中介和扰动指标等多种解释性工具共同评估CoT的忠实性。

Abstract: Recent work, using the Biasing Features metric, labels a CoT as unfaithful if it omits a prompt-injected hint that affected the prediction. We argue this metric confuses unfaithfulness with incompleteness, the lossy compression needed to turn distributed transformer computation into a linear natural language narrative. On multi-hop reasoning tasks with Llama-3 and Gemma-3, many CoTs flagged as unfaithful by Biasing Features are judged faithful by other metrics, exceeding 50% in some models. With a new faithful@k metric, we show that larger inference-time token budgets greatly increase hint verbalization (up to 90% in some settings), suggesting much apparent unfaithfulness is due to tight token limits. Using Causal Mediation Analysis, we further show that even non-verbalized hints can causally mediate prediction changes through the CoT. We therefore caution against relying solely on hint-based evaluations and advocate a broader interpretability toolkit, including causal mediation and corruption-based metrics.

</details>


### [38] [Accelerating Language Model Workflows with Prompt Choreography](https://arxiv.org/abs/2512.23049)
*TJ Bai,Jason Eisner*

Main category: cs.CL

TL;DR: Prompt Choreography通过缓存和微调提升大语言模型多代理工作流的执行效率，显著降低延迟并实现加速。


<details>
  <summary>Details</summary>
Motivation: 由于多代理工作流中存在大量冗余计算，导致调用大语言模型时延迟较高。本文动机在于通过利用缓存机制和模型微调，减少重复编码带来的计算浪费，提高整体效率。

Method: 该方法维护一个动态全局键值缓存，使每次调用时可参考任意重排序的历史消息编码，支持并行调用。通过对模型进行微调，使其适应缓存编码带来的上下文变化，从而保持输出一致性。

Result: 本文提出了Prompt Choreography框架，通过维护动态的全局键值缓存，有效提升大语言模型（LLM）在多代理工作流中的执行效率。该方法允许每次调用LLM时参考之前编码过的信息的任意重排序子集，支持并行调用。虽然缓存编码可能导致结果与重新编码有所不同，但通过微调模型，能使其输出近似于原始结果。实验表明，该方法显著降低了每条消息的延迟（时间缩短2.0至6.2倍）并且在冗余计算占主导的工作流中实现了超过2.2倍的端到端加速。

Conclusion: Prompt Choreography框架能够有效利用缓存编码并结合模型微调，显著加速多代理大语言模型工作流的执行，同时保证输出结果的质量。

Abstract: Large language models are increasingly deployed in multi-agent workflows. We introduce Prompt Choreography, a framework that efficiently executes LLM workflows by maintaining a dynamic, global KV cache. Each LLM call can attend to an arbitrary, reordered subset of previously encoded messages. Parallel calls are supported. Though caching messages' encodings sometimes gives different results from re-encoding them in a new context, we show in diverse settings that fine-tuning the LLM to work with the cache can help it mimic the original results. Prompt Choreography significantly reduces per-message latency (2.0--6.2$\times$ faster time-to-first-token) and achieves substantial end-to-end speedups ($>$2.2$\times$) in some workflows dominated by redundant computation.

</details>


### [39] [TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish](https://arxiv.org/abs/2512.23065)
*Melikşah Türker,A. Ebrar Kızıloğlu,Onur Güngör,Susan Üsküdarlı*

Main category: cs.CL

TL;DR: 提出了土耳其语单语编码器TabiBERT，用现代Transformer技术从零训练，提升效率与性能，在多任务评测中领先现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管编码器-only的Transformer架构在效率和长上下文建模上有显著进步，土耳其语自然语言处理尚缺乏采用这些现代架构的从零训练的单语编码器。

Method: 基于ModernBERT架构，结合Rotary Positional Embeddings（RoPE）、FlashAttention和优化的归一化方法，从头开始训练单语种土耳其语编码器TabiBERT。

Result: TabiBERT预训练于多域大规模语料（1万亿标记），支持8192标记上下文长度，推理速度提升2.65倍，显存消耗减少，实现更大批次训练。在28个任务数据集组成的TabiBench上，取得77.58分，超过BERTurk 1.62分，并在5个类别刷新最优表现。平均优于先前最佳任务特定模型1.47分，显示出强健的跨域泛化能力。

Conclusion: TabiBERT实现了土耳其语NLP领域的架构和性能突破，促进了该语言的编码器研究，并通过开源模型和代码支持社区透明和可复现研究。

Abstract: Since the inception of BERT, encoder-only Transformers have evolved significantly in computational efficiency, training stability, and long-context modeling. ModernBERT consolidates these advances by integrating Rotary Positional Embeddings (RoPE), FlashAttention, and refined normalization. Despite these developments, Turkish NLP lacks a monolingual encoder trained from scratch incorporating such modern architectural paradigms. This work introduces TabiBERT, a monolingual Turkish encoder based on ModernBERT architecture trained from scratch on a large, curated corpus. TabiBERT is pre-trained on one trillion tokens sampled from an 84.88B token multi-domain corpus: web text (73%), scientific publications (20%), source code (6%), and mathematical content (0.3%). The model supports 8,192-token context length (16x original BERT), achieves up to 2.65x inference speedup, and reduces GPU memory consumption, enabling larger batch sizes. We introduce TabiBench with 28 datasets across eight task categories with standardized splits and protocols, evaluated using GLUE-style macro-averaging. TabiBERT attains 77.58 on TabiBench, outperforming BERTurk by 1.62 points and establishing state-of-the-art on five of eight categories: question answering (+9.55), code retrieval (+2.41), and document retrieval (+0.60). Compared with task-specific prior best results, including specialized models like TurkishBERTweet, TabiBERT achieves +1.47 average improvement, indicating robust cross-domain generalization. We release model weights, training configurations, and evaluation code for transparent, reproducible Turkish encoder research.

</details>


### [40] [Reservoir Computing inspired Matrix Multiplication-free Language Model](https://arxiv.org/abs/2512.23145)
*Takumi Shiratsuchi,Yuichiro Tanaka,Hakaru Tamukoh*

Main category: cs.CL

TL;DR: 本文提出了一种结合reservoir计算的无矩阵乘法语言模型，有效降低计算资源消耗，保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型计算成本高，限制了其应用，本文旨在提高计算效率，减少训练和推理开销。

Method: 通过部分固定和共享无矩阵乘法语言模型中选定层的权重，插入reservoir层以提供丰富动态表示，并结合多种操作减少内存访问。

Result: 参数数目降低最多19%，训练时间减少9.9%，推理时间减少8.0%，性能与基线模型相当。

Conclusion: 本文提出的基于reservoir计算架构的无矩阵乘法语言模型在保持性能的同时显著降低了参数数量、训练时间和推理时间。

Abstract: Large language models (LLMs) have achieved state-of-the-art performance in natural language processing; however, their high computational cost remains a major bottleneck. In this study, we target computational efficiency by focusing on a matrix multiplication free language model (MatMul-free LM) and further reducing the training cost through an architecture inspired by reservoir computing. Specifically, we partially fix and share the weights of selected layers in the MatMul-free LM and insert reservoir layers to obtain rich dynamic representations without additional training overhead. Additionally, several operations are combined to reduce memory accesses. Experimental results show that the proposed architecture reduces the number of parameters by up to 19%, training time by 9.9%, and inference time by 8.0%, while maintaining comparable performance to the baseline model.

</details>


### [41] [Not too long do read: Evaluating LLM-generated extreme scientific summaries](https://arxiv.org/abs/2512.23206)
*Zhuoqi Lyu,Qing Ke*

Main category: cs.CL

TL;DR: 本文构建了高质量科学TLDR数据集BiomedTLDR，评估了开源大语言模型生成极致摘要的能力，发现其多倾向于提取而非抽象总结。


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量的科学极致摘要（TLDR）数据集，限制了LLM在该领域的发展与评估。

Method: 构建了一个包含研究者撰写的摘要的BiomedTLDR数据集，并使用多个开源LLM基于摘要生成TLDR。

Result: 一些LLM能够生成类人摘要，但整体更依赖原文词汇和修辞结构，表现出较强的提取性质。

Conclusion: LLMs在生成科研摘要方面表现良好，但通常倾向于提取原文内容，缺乏抽象总结能力，与人类专家写作存在差异。

Abstract: High-quality scientific extreme summary (TLDR) facilitates effective science communication. How do large language models (LLMs) perform in generating them? How are LLM-generated summaries different from those written by human experts? However, the lack of a comprehensive, high-quality scientific TLDR dataset hinders both the development and evaluation of LLMs' summarization ability. To address these, we propose a novel dataset, BiomedTLDR, containing a large sample of researcher-authored summaries from scientific papers, which leverages the common practice of including authors' comments alongside bibliography items. We then test popular open-weight LLMs for generating TLDRs based on abstracts. Our analysis reveals that, although some of them successfully produce humanoid summaries, LLMs generally exhibit a greater affinity for the original text's lexical choices and rhetorical structures, hence tend to be more extractive rather than abstractive in general, compared to humans. Our code and datasets are available at https://github.com/netknowledge/LLM_summarization (Lyu and Ke, 2025).

</details>


### [42] [Scoring, Reasoning, and Selecting the Best! Ensembling Large Language Models via a Peer-Review Process](https://arxiv.org/abs/2512.23213)
*Zhijun Chen,Zeyu Ji,Qianren Mao,Junhang Cheng,Bangjie Qin,Hao Wu,Zhuoran Li,Jingzheng Li,Kai Sun,Zizhe Wang,Yikun Ban,Zhu Sun,Xiangyang Ji,Hailong Sun*

Main category: cs.CL

TL;DR: LLM-PeerReview利用多个LLM之间的“同行评审”机制无监督地选择最优回答，效果优于当前先进模型。


<details>
  <summary>Details</summary>
Motivation: 针对多个大规模语言模型(LLM)生成多个候选回答的情况，如何选择出最理想的回答实现优势互补。

Method: 方法包含三个阶段：（1）用LLM作为评审者对每个回答进行评分；（2）采用图模型或平均策略融合多个评分得到最终分数；（3）选择最高评分回答作为输出。

Result: 提出了一种基于同行评审机制的无监督LLM集成方法LLM-PeerReview，在四个数据集上取得优异效果，其中两个变体分别比现有先进模型Smoothie-Global高出6.9%和7.3%。

Conclusion: LLM-PeerReview方法简单且解释性强，通过采用多LLM评分、基于图模型的推断或平均策略，显著提升集成模型的回答质量。

Abstract: We propose LLM-PeerReview, an unsupervised LLM Ensemble method that selects the most ideal response from multiple LLM-generated candidates for each query, harnessing the collective wisdom of multiple models with diverse strengths. LLM-PeerReview is built on a novel, peer-review-inspired framework that offers a clear and interpretable mechanism, while remaining fully unsupervised for flexible adaptability and generalization. Specifically, it operates in three stages: For scoring, we use the emerging LLM-as-a-Judge technique to evaluate each response by reusing multiple LLMs at hand; For reasoning, we can apply a principled graphical model-based truth inference algorithm or a straightforward averaging strategy to aggregate multiple scores to produce a final score for each response; Finally, the highest-scoring response is selected as the best ensemble output. LLM-PeerReview is conceptually simple and empirically powerful. The two variants of the proposed approach obtain strong results across four datasets, including outperforming the recent advanced model Smoothie-Global by 6.9% and 7.3% points, respectively.

</details>


### [43] [Interpretable Safety Alignment via SAE-Constructed Low-Rank Subspace Adaptation](https://arxiv.org/abs/2512.23260)
*Dianyun Wang,Qingsen Ma,Yuhu Shang,Zhifeng Lu,Lechen Ning,Zhenbo Xu,Huijia Wu,Zhaofeng He*

Main category: cs.CL

TL;DR: 通过引入可解释的稀疏自编码器特征空间，提升低秩微调方法的性能与安全性，实现高效且透明的模型适配。


<details>
  <summary>Details</summary>
Motivation: 目前低秩适应方法学习的子空间为黑箱，缺乏解释性和直接控制，主要问题在于维度的多义性导致难以有效学习。

Method: 利用预训练的稀疏自编码器识别任务相关的解缠结特征空间，构建可解释的低秩子空间以指导适配器初始化。

Result: 在安全对齐任务中，将更新参数比例降低至0.19-0.24%，安全率达到99.6%，超越全量微调7.4个百分点，且接近基于强化学习的对齐方法。

Conclusion: 引入可解释的解缠结特征空间能显著提升低秩适应方法的效果与安全性。

Abstract: Parameter-efficient fine-tuning has become the dominant paradigm for adapting large language models to downstream tasks. Low-rank adaptation methods such as LoRA operate under the assumption that task-relevant weight updates reside in a low-rank subspace, yet this subspace is learned implicitly from data in a black-box manner, offering no interpretability or direct control. We hypothesize that this difficulty stems from polysemanticity--individual dimensions encoding multiple entangled concepts. To address this, we leverage pre-trained Sparse Autoencoders (SAEs) to identify task-relevant features in a disentangled feature space, then construct an explicit, interpretable low-rank subspace to guide adapter initialization. We provide theoretical analysis proving that under monosemanticity assumptions, SAE-based subspace identification achieves arbitrarily small recovery error, while direct identification in polysemantic space suffers an irreducible error floor. On safety alignment, our method achieves up to 99.6% safety rate--exceeding full fine-tuning by 7.4 percentage points and approaching RLHF-based methods--while updating only 0.19-0.24% of parameters. Crucially, our method provides interpretable insights into the learned alignment subspace through the semantic grounding of SAE features. Our work demonstrates that incorporating mechanistic interpretability into the fine-tuning process can simultaneously improve both performance and transparency.

</details>


### [44] [Chinese Morph Resolution in E-commerce Live Streaming Scenarios](https://arxiv.org/abs/2512.23280)
*Jiahao Zhu,Jipeng Qiang,Ran Bai,Chenyu Liu,Xiaoye Ouyang*

Main category: cs.CL

TL;DR: 本文提出了检测电商直播中主播通过发音变声规避监管的LiveAMR任务，构建了大规模数据集并利用大型语言模型提升检测效果，显著促进了直播平台的监管。


<details>
  <summary>Details</summary>
Motivation: 电商直播中，主播通过变声规避监管并进行虚假广告，当前针对文本类的变形研究无法有效应对基于发音的规避行为，因此提出LiveAMR任务以检测此类违规行为。

Method: 本研究构建了首个包含86,790个样本的Live Auditory Morph Resolution (LiveAMR)数据集，并将任务转化为文本到文本的生成问题，通过利用大型语言模型(LLMs)生成额外训练数据来提升模型性能。

Result: 通过引入LiveAMR任务和数据集，并运用大型语言模型辅助生成训练数据，有效提升了对直播中发音变形规避行为的识别能力。

Conclusion: Morph Resolution技术在电商直播监管中表现出显著作用，利用大型语言模型增强训练数据，能够有效检测主播的发音变形规避行为，提升直播监管水平。

Abstract: E-commerce live streaming in China, particularly on platforms like Douyin, has become a major sales channel, but hosts often use morphs to evade scrutiny and engage in false advertising. This study introduces the Live Auditory Morph Resolution (LiveAMR) task to detect such violations. Unlike previous morph research focused on text-based evasion in social media and underground industries, LiveAMR targets pronunciation-based evasion in health and medical live streams. We constructed the first LiveAMR dataset with 86,790 samples and developed a method to transform the task into a text-to-text generation problem. By leveraging large language models (LLMs) to generate additional training data, we improved performance and demonstrated that morph resolution significantly enhances live streaming regulation.

</details>


### [45] [AI4Reading: Chinese Audiobook Interpretation System Based on Multi-Agent Collaboration](https://arxiv.org/abs/2512.23300)
*Minjiang Huang,Jipeng Qiang,Yi Zhu,Chaowei Zhang,Xiangyu Zhao,Kui Yu*

Main category: cs.CL

TL;DR: 本文提出AI4Reading，多代理系统利用大语言模型自动生成有声书解读，生成内容简洁准确，语音质量有待提升，有效提升了解读效率。


<details>
  <summary>Details</summary>
Motivation: 传统有声书解读的手动创作过程耗时且资源密集，亟需自动化系统提升效率和质量。

Method: 提出了一个由11个专门代理组成的多代理协作系统，结合大语言模型和语音合成技术，涵盖主题分析、案例分析、编辑、旁白和校对等环节，实现内容探索、案例提取、内容组织优化和自然语言合成。

Result: 系统生成的解读内容在保持内容准确性、提高理解度和逻辑结构合理性方面表现良好。与专家解读相比，脚本更简洁且准确，但语音质量尚需提升。

Conclusion: AI4Reading系统虽然在语音生成质量方面仍有提升空间，但生成的解读脚本更加简洁准确，验证了其在有声书解读领域的有效性。

Abstract: Audiobook interpretations are attracting increasing attention, as they provide accessible and in-depth analyses of books that offer readers practical insights and intellectual inspiration. However, their manual creation process remains time-consuming and resource-intensive. To address this challenge, we propose AI4Reading, a multi-agent collaboration system leveraging large language models (LLMs) and speech synthesis technology to generate podcast, like audiobook interpretations. The system is designed to meet three key objectives: accurate content preservation, enhanced comprehensibility, and a logical narrative structure. To achieve these goals, we develop a framework composed of 11 specialized agents,including topic analysts, case analysts, editors, a narrator, and proofreaders that work in concert to explore themes, extract real world cases, refine content organization, and synthesize natural spoken language. By comparing expert interpretations with our system's output, the results show that although AI4Reading still has a gap in speech generation quality, the generated interpretative scripts are simpler and more accurate.

</details>


### [46] [AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents](https://arxiv.org/abs/2512.23343)
*Jiafeng Liang,Hao Li,Chang Li,Jiaqi Zhou,Shixin Jiang,Zekun Wang,Changkai Ji,Zhihao Zhu,Runxuan Liu,Tao Ren,Jinlan Fu,See-Kiong Ng,Xia Liang,Ming Liu,Bing Qin*

Main category: cs.CL

TL;DR: 论文总结了跨学科的记忆机制研究，连接了认知神经科学和智能体内存设计，展望了多模态记忆系统和技能获取的未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有自主智能体在内存设计上存在难以充分吸收人类记忆机制精髓的问题，难以有效结合认知神经科学与人工智能的相关知识。

Method: 系统综述并比较了认知神经科学和人工智能领域中记忆的定义、功能、分类和管理机制，评估智能体记忆基准，探讨内存安全的攻防策略。

Result: 系统整合了认知神经科学与大语言模型驱动智能体的记忆研究，比较分析了记忆的分类、存储机制和管理生命周期，评估了主流的智能体记忆基准，并探讨了记忆的安全性问题。

Conclusion: 通过跨学科整合，本文搭建了认知神经科学与人工智能记忆研究的桥梁，为未来智能体内存设计和安全提供了指导。

Abstract: Memory serves as the pivotal nexus bridging past and future, providing both humans and AI systems with invaluable concepts and experience to navigate complex tasks. Recent research on autonomous agents has increasingly focused on designing efficient memory workflows by drawing on cognitive neuroscience. However, constrained by interdisciplinary barriers, existing works struggle to assimilate the essence of human memory mechanisms. To bridge this gap, we systematically synthesizes interdisciplinary knowledge of memory, connecting insights from cognitive neuroscience with LLM-driven agents. Specifically, we first elucidate the definition and function of memory along a progressive trajectory from cognitive neuroscience through LLMs to agents. We then provide a comparative analysis of memory taxonomy, storage mechanisms, and the complete management lifecycle from both biological and artificial perspectives. Subsequently, we review the mainstream benchmarks for evaluating agent memory. Additionally, we explore memory security from dual perspectives of attack and defense. Finally, we envision future research directions, with a focus on multimodal memory systems and skill acquisition.

</details>


### [47] [A Stepwise-Enhanced Reasoning Framework for Large Language Models Based on External Subgraph Generation](https://arxiv.org/abs/2512.23356)
*Xin Zhang,Yang Cao,Baoxing Wu,Xinyi Chen,Kai Song,Siying Li*

Main category: cs.CL

TL;DR: 大型语言模型在复杂推理任务中表现受限，本文提出基于外部子图生成的分步推理增强框架SGR，通过构建相关知识子图引导多步推理。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在处理需要深度推理和逻辑推断的任务时，容易受到训练语料噪声的影响，产生错误或不一致的输出。

Method: 该方法首先根据输入查询生成外部知识子图，然后模型在该结构化子图上进行多步分步推理，最后融合多个推理路径得出最终答案。

Result: 在多个基准数据集上的实验显示，SGR框架在提升推理能力和准确性方面优于其他强基线方法。

Conclusion: SGR框架通过动态构建外部子图并引导多步推理，显著提升了大型语言模型的推理准确性和鲁棒性，实验结果表明其优于多种强基线。

Abstract: Large Language Models (LLMs) have achieved strong performance across a wide range of natural language processing tasks in recent years, including machine translation, text generation, and question answering. As their applications extend to increasingly complex scenarios, however, LLMs continue to face challenges in tasks that require deep reasoning and logical inference. In particular, models trained on large scale textual corpora may incorporate noisy or irrelevant information during generation, which can lead to incorrect predictions or outputs that are inconsistent with factual knowledge. To address this limitation, we propose a stepwise reasoning enhancement framework for LLMs based on external subgraph generation, termed SGR. The proposed framework dynamically constructs query relevant subgraphs from external knowledge bases and leverages their semantic structure to guide the reasoning process. By performing reasoning in a step by step manner over structured subgraphs, SGR reduces the influence of noisy information and improves reasoning accuracy. Specifically, the framework first generates an external subgraph tailored to the input query, then guides the model to conduct multi step reasoning grounded in the subgraph, and finally integrates multiple reasoning paths to produce the final answer. Experimental results on multiple benchmark datasets demonstrate that SGR consistently outperforms strong baselines, indicating its effectiveness in enhancing the reasoning capabilities of LLMs.

</details>


### [48] [Entropy-Guided Token Dropout: Training Autoregressive Language Models with Limited Domain Data](https://arxiv.org/abs/2512.23422)
*Jiapeng Wang,Yiwen Hu,Yanzipeng Gao,Haoyu Wang,Shuo Wang,Hongyu Lu,Jiaxin Mao,Wayne Xin Zhao,Junyi Li,Xiao Zhang*

Main category: cs.CL

TL;DR: 多轮训练中，语言模型因低熵token过拟合导致性能下降，EntroDrop通过熵引导的token丢弃和课程学习，有效提升模型泛化能力，适用于数据有限的领域。


<details>
  <summary>Details</summary>
Motivation: 在领域特定数据稀缺情况下，多轮训练成为适应大规模语言模型的策略，但模型在重复数据暴露中性能显著下降，需解决低熵token导致的学习动态失衡问题。

Method: 提出EntroDrop方法，利用token熵值选择性丢弃低熵token作为结构化正则化，并结合课程学习动态调整正则化强度。

Result: 本文针对大规模语言模型（LLMs）在多轮训练中出现的性能退化问题，提出了一种基于熵引导的token丢弃方法EntroDrop。研究发现过拟合主要源于低熵、易预测token的快速学习，使得模型对高熵token的泛化能力下降。EntroDrop通过选择性屏蔽低熵token并结合课程学习调整正则化强度，有效缓解了这一问题。实验证明，在0.6B至8B参数规模的模型上，EntroDrop优于传统正则化方法，在多轮训练中保持了鲁棒性。

Conclusion: EntroDrop方法通过匹配token级别学习动态的正则化策略，显著提升了在有限数据条件下多轮训练的模型稳定性和性能，是适应领域特定数据匮乏问题的有效途径。

Abstract: As access to high-quality, domain-specific data grows increasingly scarce, multi-epoch training has become a practical strategy for adapting large language models (LLMs). However, autoregressive models often suffer from performance degradation under repeated data exposure, where overfitting leads to a marked decline in model capability. Through empirical analysis, we trace this degradation to an imbalance in learning dynamics: predictable, low-entropy tokens are learned quickly and come to dominate optimization, while the model's ability to generalize on high-entropy tokens deteriorates with continued training. To address this, we introduce EntroDrop, an entropy-guided token dropout method that functions as structured data regularization. EntroDrop selectively masks low-entropy tokens during training and employs a curriculum schedule to adjust regularization strength in alignment with training progress. Experiments across model scales from 0.6B to 8B parameters show that EntroDrop consistently outperforms standard regularization baselines and maintains robust performance throughout extended multi-epoch training. These findings underscore the importance of aligning regularization with token-level learning dynamics when training on limited data. Our approach offers a promising pathway toward more effective adaptation of LLMs in data-constrained domains.

</details>


### [49] [The Effect of Gender Diversity on Scientific Team Impact: A Team Roles Perspective](https://arxiv.org/abs/2512.23429)
*Yi Zhao,Yongjun Zhu,Donghun Kim,Yuzhuo Wang,Heng Zhang,Chao Lu,Chengzhi Zhang*

Main category: cs.CL

TL;DR: 本研究细分团队角色探讨性别多样性对科研团队影响，揭示了不同角色和团队规模中性别多样性的复杂作用机制。


<details>
  <summary>Details</summary>
Motivation: 学术界关注性别多样性对科研团队成功的影响，但现有研究多将多样性整体化，忽视角色分化，导致对性别多样性如何影响团队成果理解不充分。

Method: 基于超过13万篇PLOS期刊论文，利用多变量回归和阈值回归模型，分析性别多样性在领导和支持角色上的影响。

Result: 发现性别多样性与团队影响呈倒U形关系；全女性领导组配合全男性支持组的团队影响最大；领导组性别多样性对小团队负面影响，对大团队影响正向但不显著；支持组性别多样性对团队影响始终正向显著。

Conclusion: 性别多样性对科研团队的影响具有角色和团队规模依赖性，尤其支持角色的性别多样性持续促进团队影响，建议在团队组建和管理中考虑角色分化的性别多样性。

Abstract: The influence of gender diversity on the success of scientific teams is of great interest to academia. However, prior findings remain inconsistent, and most studies operationalize diversity in aggregate terms, overlooking internal role differentiation. This limitation obscures a more nuanced understanding of how gender diversity shapes team impact. In particular, the effect of gender diversity across different team roles remains poorly understood. To this end, we define a scientific team as all coauthors of a paper and measure team impact through five-year citation counts. Using author contribution statements, we classified members into leadership and support roles. Drawing on more than 130,000 papers from PLOS journals, most of which are in biomedical-related disciplines, we employed multivariable regression to examine the association between gender diversity in these roles and team impact. Furthermore, we apply a threshold regression model to investigate how team size moderates this relationship. The results show that (1) the relationship between gender diversity and team impact follows an inverted U-shape for both leadership and support groups; (2) teams with an all-female leadership group and an all-male support group achieve higher impact than other team types. Interestingly, (3) the effect of leadership-group gender diversity is significantly negative for small teams but becomes positive and statistically insignificant in large teams. In contrast, the estimates for support-group gender diversity remain significant and positive, regardless of team size.

</details>


### [50] [C2PO: Diagnosing and Disentangling Bias Shortcuts in LLMs](https://arxiv.org/abs/2512.23430)
*Xuan Feng,Bo An,Tianlong Gu,Liang Chang,Fengrui Hao,Peipeng Yu,Shuai Zhao*

Main category: cs.CL

TL;DR: 为同时缓解大型语言模型中的刻板与结构性偏见，提出C2PO框架，利用因果对比优化策略精准抑制潜在偏见特征，实验证明其效果显著且不损害模型推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理刻板偏见或结构性偏见，往往缓解一种偏见时加剧另一种，需统一解决两类偏见带来的信任风险。

Method: 提出了Causal-Contrastive Preference Optimization（C2PO）统一对齐框架，通过因果对比信号识别并压制输入中的诱发偏见的潜在虚假特征，实现动态评估和抑制捷径特征。

Result: 在多个基准测试上，包括刻板偏见、结构性偏见、领域外公平性和通用能力测试，C2PO展示了对偏见的有效抑制和推理能力的良好保持。

Conclusion: C2PO方法有效缓解了大型语言模型中的刻板偏见和结构性偏见，同时保持了模型的通用推理能力。

Abstract: Bias in Large Language Models (LLMs) poses significant risks to trustworthiness, manifesting primarily as stereotypical biases (e.g., gender or racial stereotypes) and structural biases (e.g., lexical overlap or position preferences). However, prior paradigms typically address these in isolation, often mitigating one at the expense of exacerbating the other. To address this, we conduct a systematic exploration of these reasoning failures and identify a primary inducement: the latent spurious feature correlations within the input that drive these erroneous reasoning shortcuts. Driven by these findings, we introduce Causal-Contrastive Preference Optimization (C2PO), a unified alignment framework designed to tackle these specific failures by simultaneously discovering and suppressing these correlations directly within the optimization process. Specifically, C2PO leverages causal counterfactual signals to isolate bias-inducing features from valid reasoning paths, and employs a fairness-sensitive preference update mechanism to dynamically evaluate logit-level contributions and suppress shortcut features. Extensive experiments across multiple benchmarks covering stereotypical bias (BBQ, Unqover), structural bias (MNLI, HANS, Chatbot, MT-Bench), out-of-domain fairness (StereoSet, WinoBias), and general utility (MMLU, GSM8K) demonstrate that C2PO effectively mitigates stereotypical and structural biases while preserving robust general reasoning capabilities.

</details>


### [51] [ClinDEF: A Dynamic Evaluation Framework for Large Language Models in Clinical Reasoning](https://arxiv.org/abs/2512.23440)
*Yuqi Tang,Jing Yu,Zichang Su,Kehua Feng,Zhihui Zhu,Libin Wang,Lei Liang,Qiang Zhang,Keyan Ding,Huajun Chen*

Main category: cs.CL

TL;DR: 本文提出基于动态诊断对话的ClinDEF框架，突破传统静态评测不足，更精准评估大型语言模型的临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型(LLM)评估方法多侧重静态问答，难以反映临床医生与患者之间动态、迭代的信息交流和诊断推理过程。

Method: 提出ClinDEF动态框架，通过基于疾病知识图谱动态生成病例，实现LLM医生与自动患者代理的多轮诊断对话，进行细粒度、多层次的评价。

Result: 实验表明ClinDEF能有效暴露现有LLM在临床推理中的关键不足，评价方式更细致且临床意义更强。

Conclusion: ClinDEF提供了一种更符合真实临床场景的动态评估范式，有助于推动LLM在临床诊断推理能力上的提升。

Abstract: Clinical diagnosis begins with doctor-patient interaction, during which physicians iteratively gather information, determine examination and refine differential diagnosis through patients' response. This dynamic clinical-reasoning process is poorly represented by existing LLM benchmarks that focus on static question-answering. To mitigate these gaps, recent methods explore dynamic medical frameworks involving interactive clinical dialogues. Although effective, they often rely on limited, contamination-prone datasets and lack granular, multi-level evaluation. In this work, we propose ClinDEF, a dynamic framework for assessing clinical reasoning in LLMs through simulated diagnostic dialogues. Grounded in a disease knowledge graph, our method dynamically generates patient cases and facilitates multi-turn interactions between an LLM-based doctor and an automated patient agent. Our evaluation protocol goes beyond diagnostic accuracy by incorporating fine-grained efficiency analysis and rubric-based assessment of diagnostic quality. Experiments show that ClinDEF effectively exposes critical clinical reasoning gaps in state-of-the-art LLMs, offering a more nuanced and clinically meaningful evaluation paradigm.

</details>


### [52] [Coupling Experts and Routers in Mixture-of-Experts via an Auxiliary Loss](https://arxiv.org/abs/2512.23447)
*Ang Lv,Jin Ma,Yiyuan Ma,Siyuan Qiao*

Main category: cs.CL

TL;DR: 本文提出了ERC loss，通过强化路由器和专家间的能力耦合，提高了MoE模型的性能和控制能力，且计算成本低。


<details>
  <summary>Details</summary>
Motivation: Mixture-of-Experts (MoE)模型缺乏显式约束，难以保证路由器决策与专家能力一致，限制了模型性能。

Method: 提出了一种名为expert-router coupling (ERC) loss的辅助损失函数，通过将每个专家的路由器嵌入作为代理token，并利用扰动后的路由器嵌入经过专家获取内部激活，施加两项约束以确保专家能力与路由器决策紧密耦合。

Result: ERC loss计算开销较低，仅依赖于专家数平方的激活数，独立于批量大小。在3B到15B参数规模的MoE-LLMs预训练及兆计token上验证了ERC loss的有效性，并能灵活控制和跟踪专家专门化水平。

Conclusion: ERC loss能有效提升MoE模型的专家与路由器匹配度，促进专家专门化，提升模型性能，且带来可控的训练动态监控。

Abstract: Mixture-of-Experts (MoE) models lack explicit constraints to ensure the router's decisions align well with the experts' capabilities, which ultimately limits model performance. To address this, we propose expert-router coupling (ERC) loss, a lightweight auxiliary loss that tightly couples the router's decisions with expert capabilities. Our approach treats each expert's router embedding as a proxy token for the tokens assigned to that expert, and feeds perturbed router embeddings through the experts to obtain internal activations. The ERC loss enforces two constraints on these activations: (1) Each expert must exhibit higher activation for its own proxy token than for the proxy tokens of any other expert. (2) Each proxy token must elicit stronger activation from its corresponding expert than from any other expert. These constraints jointly ensure that each router embedding faithfully represents its corresponding expert's capability, while each expert specializes in processing the tokens actually routed to it. The ERC loss is computationally efficient, operating only on n^2 activations, where n is the number of experts. This represents a fixed cost independent of batch size, unlike prior coupling methods that scale with the number of tokens (often millions per batch). Through pre-training MoE-LLMs ranging from 3B to 15B parameters and extensive analysis on trillions of tokens, we demonstrate the effectiveness of the ERC loss. Moreover, the ERC loss offers flexible control and quantitative tracking of expert specialization levels during training, providing valuable insights into MoEs.

</details>


### [53] [Semantic Tree Inference on Text Corpa using a Nested Density Approach together with Large Language Model Embeddings](https://arxiv.org/abs/2512.23471)
*Thomas Haschka,Joseph Bakarji*

Main category: cs.CL

TL;DR: 本文提出一种基于嵌套密度聚类的层次语义文本分类方法，通过在大语言模型嵌入空间中识别密集语义簇并逐步合并，构建文本的层次树结构，实现无需预定义类别的文本分类与语义关系挖掘。


<details>
  <summary>Details</summary>
Motivation: 传统基于语义相似性的向量检索难以揭示文本语料库的全局语义结构，缺乏层次关系的语义表示，需要一种能够自动发现文本层次语义结构的方法。

Method: 采用大语言模型生成文本嵌入，利用嵌套密度聚类方法逐步放松密度阈值，在嵌入空间中发现语义密集簇并合并为层次结构，形成语义树。

Result: 实验表明该方法不仅能够发现科学文摘的研究领域及其子领域，还在20 Newsgroups和IMDB 50k电影评论这类标准数据集上表现出鲁棒性，展示了其跨领域适用性。

Conclusion: 该方法能够有效构建文本的层次语义结构，适用于科学文摘、新闻组与影评等多类语料，具有较强的鲁棒性和广泛应用潜力。

Abstract: Semantic text classification has undergone significant advances in recent years due to the rise of large language models (LLMs) and their high dimensional embeddings. While LLM-embeddings are frequently used to store and retrieve text by semantic similarity in vector databases, the global structure semantic relationships in text corpora often remains opaque. Herein we propose a nested density clustering approach, to infer hierarchical trees of semantically related texts. The method starts by identifying texts of strong semantic similarity as it searches for dense clusters in LLM embedding space. As the density criterion is gradually relaxed, these dense clusters merge into more diffuse clusters, until the whole dataset is represented by a single cluster -- the root of the tree. By embedding dense clusters into increasingly diffuse ones, we construct a tree structure that captures hierarchical semantic relationships among texts. We outline how this approach can be used to classify textual data for abstracts of scientific abstracts as a case study. This enables the data-driven discovery research areas and their subfields without predefined categories. To evaluate the general applicability of the method, we further apply it to established benchmark datasets such as the 20 Newsgroups and IMDB 50k Movie Reviews, demonstrating its robustness across domains. Finally we discuss possible applications on scientometrics, topic evolution, highlighting how nested density trees can reveal semantic structure and evolution in textual datasets.

</details>


### [54] [Automatic Detection of Complex Quotation Patterns in Aggadic Literature](https://arxiv.org/abs/2512.23504)
*Hadar Miller,Tsvi Kuflik,Moshe Lavee*

Main category: cs.CL

TL;DR: 本文提出了结合形态学和上下文增强的ACT算法，显著提升了拉比文学中圣经引用的自动检测效果，并推动了数字人文和计算文献学的发展。


<details>
  <summary>Details</summary>
Motivation: 现有文本重复利用框架难以准确检测拉比文学中短句、意译及结构嵌入的圣经引用，亟需一种能处理复杂引用模式的自动检测方法，促进数字人文和计算文献学的发展。

Method: 提出了三阶段算法：形态学感知对齐算法，基于上下文的风格增强阶段，以及引用模式识别模块。该方法兼顾召回率和准确率，通过不同配置验证各组件贡献。

Result: 本文提出了ACT（Allocate Connections between Texts）算法，用于自动检测拉比文学中的圣经引用。该方法创新性地结合了形态学敏感的对齐算法与上下文敏感的增强阶段，能够识别复杂的引用模式，解决了短句、意译及结构嵌入引用的难题。通过与多个现有系统和人工标注版本对比，ACT表现出优秀的F1值（0.91），显著提升了召回率和准确率。不同配置下的ACT在召回率和准确率之间实现权衡。此外，ACT还能分类风格化模式，促进文体分类和互文性分析。该研究弥补了机器检测与人工编辑之间的方法差距，为形态丰富、引用密集的历史文本分析提供重要基础。

Conclusion: ACT算法全面提升了拉比文学中圣经引用的检测性能，实现了高精度和高召回率，同时其风格模式分类功能拓展了研究应用场景，为数字人文的文本分析提供了重要工具。

Abstract: This paper presents ACT (Allocate Connections between Texts), a novel three-stage algorithm for the automatic detection of biblical quotations in Rabbinic literature. Unlike existing text reuse frameworks that struggle with short, paraphrased, or structurally embedded quotations, ACT combines a morphology-aware alignment algorithm with a context-sensitive enrichment stage that identifies complex citation patterns such as "Wave" and "Echo" quotations.
  Our approach was evaluated against leading systems, including Dicta, Passim, Text-Matcher, as well as human-annotated critical editions. We further assessed three ACT configurations to isolate the contribution of each component. Results demonstrate that the full ACT pipeline (ACT-QE) outperforms all baselines, achieving an F1 score of 0.91, with superior Recall (0.89) and Precision (0.94). Notably, ACT-2, which lacks stylistic enrichment, achieves higher Recall (0.90) but suffers in Precision, while ACT-3, using longer n-grams, offers a tradeoff between coverage and specificity.
  In addition to improving quotation detection, ACT's ability to classify stylistic patterns across corpora opens new avenues for genre classification and intertextual analysis. This work contributes to digital humanities and computational philology by addressing the methodological gap between exhaustive machine-based detection and human editorial judgment. ACT lays a foundation for broader applications in historical textual analysis, especially in morphologically rich and citation-dense traditions like Aggadic literature.

</details>


### [55] [UniHetero: Could Generation Enhance Understanding for Vision-Language-Model at Large Data Scale?](https://arxiv.org/abs/2512.23512)
*Fengjiao Chen,Minhao Jing,Weitao Lu,Yan Feng,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 本文通过大规模预训练，研究生成任务对视觉理解的促进作用，发现生成语义内容显著提升理解能力，提出的UniHetero模型效果优异。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言大模型中，生成任务是否能促进视觉理解能力，尤其是在大规模数据下的表现。

Method: 提出一个简洁结构的统一模型UniHetero，进行大规模（超过2亿样本）预训练，结合生成和理解任务评估效果。

Result: 发现生成语义任务能有效提升理解任务性能，且显示出更优的数据扩展趋势和更高的数据利用率；采用输入嵌入的自回归方法能更好捕捉视觉细节。

Conclusion: 生成任务能够提升视觉理解，但只有生成语义内容而非像素才能取得效果。

Abstract: Vision-language large models are moving toward the unification of visual understanding and visual generation tasks. However, whether generation can enhance understanding is still under-explored on large data scale. In this work, we analysis the unified model with a concise structure, UniHetero, under large-scale pretraining (>200M samples). Our key observations are: (1) Generation can improve understanding, but Only if you generate Semantics, Not Pixels. (2) Generation reveals a superior Data Scaling trend and higher Data Utilization. (3) Autoregression on Input Embedding is effective to capture visual details.

</details>


### [56] [Single LLM Debate, MoLaCE: Mixture of Latent Concept Experts Against Confirmation Bias](https://arxiv.org/abs/2512.23518)
*Hazel Kim,Philip Torr*

Main category: cs.CL

TL;DR: 论文提出一种轻量级推理时框架，通过混合潜在概念激活强化弱化模型应对确认偏差，提升鲁棒性且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在输入的确认偏差问题上表现脆弱，且多智能体辩论中回声室效应可能加剧偏差，需要一种高效且可扩展的方法解决。

Method: 提出Mixture of Latent Concept Experts (MoLaCE)推理时框架，通过混合不同激活强度的潜在概念专家来缓解确认偏差。

Result: MoLaCE能够持续减少确认偏差，提高模型鲁棒性，并在计算资源远低于多智能体辩论的情况下，性能与其持平或更优。

Conclusion: MoLaCE有效抑制确认偏差，提升模型在多样输入下的准确性，适用于单模型内部和多智能体辩论环境，具备优良的效率和扩展性。

Abstract: Large language models (LLMs) are highly vulnerable to input confirmation bias. When a prompt implies a preferred answer, models often reinforce that bias rather than explore alternatives. This phenomenon remains underexplored, yet it is already harmful in base models and poses an even greater risk in multi-agent debate, where echo chambers reinforce bias instead of correction. We introduce Mixture of Latent Concept Experts (MoLaCE), a lightweight inference-time framework that addresses confirmation bias by mixing experts instantiated as different activation strengths over latent concepts that shape model responses. Our key insight is that, due to the compositional nature of language, differently phrased prompts reweight latent concepts in prompt-specific ways that affect factual correctness, so no single fixed intervention can be applied universally across inputs. This design enables a single LLM to emulate the benefits of debate internally while remaining computationally efficient and scalable. It can also be integrated into multi-agent debate frameworks to diversify perspectives and reduce correlated errors. We empirically show that it consistently reduces confirmation bias, improves robustness, and matches or surpasses multi-agent debate while requiring only a fraction of the computation.

</details>


### [57] [Lie to Me: Knowledge Graphs for Robust Hallucination Self-Detection in LLMs](https://arxiv.org/abs/2512.23547)
*Sahil Kale,Antonio Luca Alfeo*

Main category: cs.CL

TL;DR: 本文提出利用知识图谱结构提升大型语言模型（LLM）幻觉自我检测的准确性，通过将LLM生成的回答转化为实体与关系的知识图谱，并基于图谱估计回答中幻觉的可能性。


<details>
  <summary>Details</summary>
Motivation: 幻觉问题严重阻碍LLM的安全应用，现有自我检测方法存在不足，作者希望通过结构化知识表示（知识图谱）提升幻觉检测效果。

Method: 将LLM的回答转化为包含实体和关系的知识图谱，利用知识图谱估计回答中是否含有幻觉，从而实现幻觉的自我检测。

Result: 与标准自我检测方法及前沿SelfCheckGPT相比，提出的方法在准确率和F1分数上分别提升了16%和20%，并发布了一个经过人工增强的检测数据集供社区使用。

Conclusion: 方法在两个LLM和两个检测数据集上的实验结果显示，相比传统自我检测方法和最先进的SelfCheckGPT，所提方法在准确率和F1分数上分别提升了16%和20%，证明知识图谱能够帮助模型更精准识别幻觉。

Abstract: Hallucinations, the generation of apparently convincing yet false statements, remain a major barrier to the safe deployment of LLMs. Building on the strong performance of self-detection methods, we examine the use of structured knowledge representations, namely knowledge graphs, to improve hallucination self-detection. Specifically, we propose a simple yet powerful approach that enriches hallucination self-detection by (i) converting LLM responses into knowledge graphs of entities and relations, and (ii) using these graphs to estimate the likelihood that a response contains hallucinations. We evaluate the proposed approach using two widely used LLMs, GPT-4o and Gemini-2.5-Flash, across two hallucination detection datasets. To support more reliable future benchmarking, one of these datasets has been manually curated and enhanced and is released as a secondary outcome of this work. Compared to standard self-detection methods and SelfCheckGPT, a state-of-the-art approach, our method achieves up to 16% relative improvement in accuracy and 20% in F1-score. Our results show that LLMs can better analyse atomic facts when they are structured as knowledge graphs, even when initial outputs contain inaccuracies. This low-cost, model-agnostic approach paves the way toward safer and more trustworthy language models.

</details>


### [58] [Instruction-Following Evaluation of Large Vision-Language Models](https://arxiv.org/abs/2512.23572)
*Daiki Shiono,Shumpei Miyawaki,Ryota Tanaka,Jun Suzuki*

Main category: cs.CL

TL;DR: LVLMs微调后指令遵循能力下降，但在训练时加入输出格式指令能有效缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 观察到LVLMs在视觉指令微调后，原有的指令遵循能力下降，旨在探索这一现象的原因及解决方案。

Method: 构建突出输出格式的训练数据集，比较含输出格式指令和不含输出格式指令数据集对LVLMs微调效果的影响，并进行量化评估。

Result: 本文研究了大型视觉语言模型（LVLMs）在经过视觉指令微调后指令遵循能力下降的问题。通过构建强调输出格式的训练数据集，定量分析了输出格式指示对LVLMs指令遵循能力的影响。实验证明，常用数据集微调后，LVLMs的指令遵循能力明显下降，但包含输出格式指令的数据集有助于提升模型遵循指令的准确性。

Conclusion: 加入输出格式指令的样本进行微调能有效减轻LVLMs指令遵循能力下降的问题。

Abstract: Following the initial flourishing of large language models (LLMs), there has been a surge in proposed large vision-language models (LVLMs) that integrate LLMs with vision capabilities. However, it has been observed that LVLMs, after tuning to visual instruction using commonly used training datasets, often fail to exhibit the instruction-following ability that was present in the LLM before integration, leading to results in which they do not follow task instructions as expected. This study quantitatively demonstrates that LVLMs' instruction-following ability declines after fine-tuning and analyzes its underlying causes. In particular, we constructed new training datasets highlighting whether the output format is specified. Then, we investigated how explicitly indicating the output format during fine-tuning affects LVLMs' instruction-following ability. Our quantitative evaluation confirmed that LVLMs' instruction-following ability declines after fine-tuning with commonly used datasets. Furthermore, we found that LVLMs trained with datasets, including instructions on output format, tend to follow instructions more accurately than models that do not. These findings suggest that including samples with instructions on output format during (visual) instruction tuning may help mitigate the decline in instruction-following abilities.

</details>


### [59] [Style Amnesia: Investigating Speaking Style Degradation and Mitigation in Multi-Turn Spoken Language Models](https://arxiv.org/abs/2512.23578)
*Yu-Xiang Lin,Cheng-Han Chiang,Hung-yi Lee*

Main category: cs.CL

TL;DR: 本文揭示语音语言模型多轮对话中难以保持指定发言风格的问题，提出显式提醒风格指令可部分改进，但系统消息提示效果有限。


<details>
  <summary>Details</summary>
Motivation: 探究SLMs在多轮交互时能否持续保持预设发言风格，提升其应用中的自然性和一致性。

Method: 通过对三款专有模型和两款开源SLMs进行评估，比较不同提示策略对风格保持的影响，验证模型在情感、口音、音量和语速等旁语言风格上的表现。

Result: 无一模型能持续维持一致的发言风格，尽管模型能记住风格指令，但难以表达完整风格；显式提醒模型记忆风格指令能部分缓解此问题；且系统消息中的风格指令效果不佳。

Conclusion: 本文发现语音语言模型（SLMs）存在“风格遗忘”问题，无法在多轮对话中持续保持指定的发言风格。

Abstract: In this paper, we show that when spoken language models (SLMs) are instructed to speak in a specific speaking style at the beginning of a multi-turn conversation, they cannot maintain the required speaking styles after several turns of interaction; we refer to this as the style amnesia of SLMs. We focus on paralinguistic speaking styles, including emotion, accent, volume, and speaking speed. We evaluate three proprietary and two open-source SLMs, demonstrating that none of these models can maintain a consistent speaking style when instructed to do so. We further show that when SLMs are asked to recall the style instruction in later turns, they can recall the style instruction, but they fail to express it throughout the conversation. We also show that explicitly asking the model to recall the style instruction can partially mitigate style amnesia. In addition, we examine various prompting strategies and find that SLMs struggle to follow the required style when the instruction is placed in system messages rather than user messages, which contradicts the intended function of system prompts.

</details>


### [60] [Close the Loop: Synthesizing Infinite Tool-Use Data via Multi-Agent Role-Playing](https://arxiv.org/abs/2512.23611)
*Yuwen Li,Wei Zhang,Zelong Huang,Mason Yang,Jiajun Wu,Shawn Guo,Huahao Hu,Lingyi Sun,Jian Yang,Mingjie Tang,Byran Dai*

Main category: cs.CL

TL;DR: InfTool通过多代理自演进合成和闭环策略优化，实现大语言模型调用工具能力的显著提升，解决了人工标注和泛化差难题。


<details>
  <summary>Details</summary>
Motivation: 解决现有大语言模型调用外部工具时面临的高质量轨迹标注昂贵、模型对未见工具泛化差、单模型合成导致偏差和覆盖不足等三大瓶颈。

Method: 引入InfTool，一个包含用户模拟器、工具调用助理和MCP服务器的三代理协同框架，通过多代理自演进合成生成高质量多样的工具调用轨迹。采用闭环的群组相对策略优化（GRPO）训练模型，实现数据和模型能力的互相提升循环，无需人工标注。

Result: 在Berkeley Function-Calling Leaderboard(BFCL)测试中，InfTool将基础32B模型准确率从19.8%提升至70.9%，增长258%，表现优于体积大10倍的模型，且完全依赖合成数据训练，无需人工标注。

Conclusion: InfTool展示了无需人工标注、依靠多代理协同和自我迭代的方式，在工具调用任务上极大提升大语言模型性能，具有重要推广价值。

Abstract: Enabling Large Language Models (LLMs) to reliably invoke external tools remains a critical bottleneck for autonomous agents. Existing approaches suffer from three fundamental challenges: expensive human annotation for high-quality trajectories, poor generalization to unseen tools, and quality ceilings inherent in single-model synthesis that perpetuate biases and coverage gaps. We introduce InfTool, a fully autonomous framework that breaks these barriers through self-evolving multi-agent synthesis. Given only raw API specifications, InfTool orchestrates three collaborative agents (User Simulator, Tool-Calling Assistant, and MCP Server) to generate diverse, verified trajectories spanning single-turn calls to complex multi-step workflows. The framework establishes a closed loop: synthesized data trains the model via Group Relative Policy Optimization (GRPO) with gated rewards, the improved model generates higher-quality data targeting capability gaps, and this cycle iterates without human intervention. Experiments on the Berkeley Function-Calling Leaderboard (BFCL) demonstrate that InfTool transforms a base 32B model from 19.8% to 70.9% accuracy (+258%), surpassing models 10x larger and rivaling Claude-Opus, and entirely from synthetic data without human annotation.

</details>


### [61] [A Dataset and Benchmark for Consumer Healthcare Question Summarization](https://arxiv.org/abs/2512.23637)
*Abhishek Basu,Deepak Gupta,Dina Demner-Fushman,Shweta Yadav*

Main category: cs.CL

TL;DR: 本文针对消费者健康问题的总结任务，推出了一个包含1507条领域专家标注的消费健康问题及对应摘要的数据集CHQ-Sum，用以提升问答的自然语言理解效果。


<details>
  <summary>Details</summary>
Motivation: 消费者表达健康需求时往往信息冗杂，导致自然语言理解困难，且缺乏领域专家标注的摘要数据集，阻碍了高效摘要系统的研究。

Method: 收集社区问答论坛中的健康问题，邀请领域专家进行标注，构建包含原始问题及其摘要的数据集；针对该数据集，使用多种先进的摘要模型进行基准测试。

Result: 建立了一个高质量的专家标注数据集，并展示了其在多个先进摘要模型上的良好应用效果。

Conclusion: 通过引入CHQ-Sum数据集和基准测试，验证了该数据集能有效促进消费者健康问题摘要系统的发展。

Abstract: The quest for seeking health information has swamped the web with consumers health-related questions. Generally, consumers use overly descriptive and peripheral information to express their medical condition or other healthcare needs, contributing to the challenges of natural language understanding. One way to address this challenge is to summarize the questions and distill the key information of the original question. Recently, large-scale datasets have significantly propelled the development of several summarization tasks, such as multi-document summarization and dialogue summarization. However, a lack of a domain-expert annotated dataset for the consumer healthcare questions summarization task inhibits the development of an efficient summarization system. To address this issue, we introduce a new dataset, CHQ-Sum,m that contains 1507 domain-expert annotated consumer health questions and corresponding summaries. The dataset is derived from the community question answering forum and therefore provides a valuable resource for understanding consumer health-related posts on social media. We benchmark the dataset on multiple state-of-the-art summarization models to show the effectiveness of the dataset

</details>


### [62] [Less is more: Probabilistic reduction is best explained by small-scale predictability measures](https://arxiv.org/abs/2512.23659)
*Cassandra L. Jacobs,Andrés Buxó-Lugo,Anna K. Taylor,Marie Leopold-Hooke*

Main category: cs.CL

TL;DR: 本文探讨了在研究语言模型概率与认知现象关系时，所需上下文量的问题，发现n-gram作为规划的认知单元已足够，无需整体话语。


<details>
  <summary>Details</summary>
Motivation: 明确研究语言模型概率与认知现象关系时，合适的上下文范围，提高模型的认知解释力。

Method: 通过分析语言模型概率与认知现象的关系，比较整体话语与n-gram表示的效果。

Result: 实验证明使用n-gram表示即可观察到概率性降低，支持其作为认知规划单元。

Conclusion: n-gram表示作为认知规划单元，足以观察到概率性降低，整体话语并非必须。

Abstract: The primary research questions of this paper center on defining the amount of context that is necessary and/or appropriate when investigating the relationship between language model probabilities and cognitive phenomena. We investigate whether whole utterances are necessary to observe probabilistic reduction and demonstrate that n-gram representations suffice as cognitive units of planning.

</details>


### [63] [Multilingual Hidden Prompt Injection Attacks on LLM-Based Academic Reviewing](https://arxiv.org/abs/2512.23684)
*Panagiotis Theocharopoulos,Ajinkya Kulkarni,Mathew Magimai. -Doss*

Main category: cs.CL

TL;DR: 本文展示了隐藏提示注入攻击在多语言学术论文中对LLM同行评审的影响，揭示了该系统的脆弱性及语言差异。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型（LLMs）在学术同行评审等高影响力工作流中的应用，但其易受到文档级隐藏提示注入攻击的影响。

Method: 构建包含约500篇被ICML接受的真实学术论文的数据集，在文档中嵌入用四种语言表达的语义等价的隐藏对抗提示，使用LLM进行评审。

Result: 提示注入导致英语、日语和中文的评审分数和接受/拒绝决策发生显著变化，而阿拉伯语注入基本无效。

Conclusion: 基于LLM的评审系统易受到文档级提示注入攻击，且不同语言的易受攻击程度存在显著差异。

Abstract: Large language models (LLMs) are increasingly considered for use in high-impact workflows, including academic peer review. However, LLMs are vulnerable to document-level hidden prompt injection attacks. In this work, we construct a dataset of approximately 500 real academic papers accepted to ICML and evaluate the effect of embedding hidden adversarial prompts within these documents. Each paper is injected with semantically equivalent instructions in four different languages and reviewed using an LLM. We find that prompt injection induces substantial changes in review scores and accept/reject decisions for English, Japanese, and Chinese injections, while Arabic injections produce little to no effect. These results highlight the susceptibility of LLM-based reviewing systems to document-level prompt injection and reveal notable differences in vulnerability across languages.

</details>


### [64] [PROFASR-BENCH: A Benchmark for Context-Conditioned ASR in High-Stakes Professional Speech](https://arxiv.org/abs/2512.23686)
*Deepak Babu Piskala*

Main category: cs.CL

TL;DR: 该论文提出了ProfASR-Bench，一个针对金融、医学、法律和技术等专业领域的高风险应用的自动语音识别评估套件，重点考察了领域术语密集、正式用语变化和关键实体错误的容忍度极低的情况。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别基准测试未能充分反映专业领域中术语密集、正式语言变体以及关键实体识别准确度要求高的实际挑战，因此需要一个更具针对性和精细化控件的测试标准。

Method: 通过设计包含领域提示和说话者档案的自然语言提示与实体丰富的语音内容配对，构建了一个支持传统和实体意识评估指标，并按口音和性别分片报告的专业语音识别测试套件。实验使用了Whisper和Qwen-Omni两种代表性模型，在多种上下文条件下评估性能变化。

Result: 实验结果显示，轻量级的文本上下文提示对系统词错误率几乎没有提升效果，即便是最优提示也无法显著改善性能；对抗性提示也未能稳定降低识别能力，揭示了当前ASR系统在利用上下文信息方面存在严重不足。

Conclusion: 研究发现当前主流的自动语音识别系统虽然名义上支持上下文提示，但实际利用上下文信息的能力有限，文本上下文对错误率影响不大，即存在明显的“上下文利用差距（CUG）”。

Abstract: Automatic Speech Recognition (ASR) in professional settings faces challenges that existing benchmarks underplay: dense domain terminology, formal register variation, and near-zero tolerance for critical entity errors. We present ProfASR-Bench, a professional-talk evaluation suite for high-stakes applications across finance, medicine, legal, and technology. Each example pairs a natural-language prompt (domain cue and/or speaker profile) with an entity-rich target utterance, enabling controlled measurement of context-conditioned recognition. The corpus supports conventional ASR metrics alongside entity-aware scores and slice-wise reporting by accent and gender. Using representative families Whisper (encoder-decoder ASR) and Qwen-Omni (audio language models) under matched no-context, profile, domain+profile, oracle, and adversarial conditions, we find a consistent pattern: lightweight textual context produces little to no change in average word error rate (WER), even with oracle prompts, and adversarial prompts do not reliably degrade performance. We term this the context-utilization gap (CUG): current systems are nominally promptable yet underuse readily available side information. ProfASR-Bench provides a standardized context ladder, entity- and slice-aware reporting with confidence intervals, and a reproducible testbed for comparing fusion strategies across model families.
  Dataset: https://huggingface.co/datasets/prdeepakbabu/ProfASR-Bench
  Code: https://github.com/prdeepakbabu/ProfASR-Bench

</details>


### [65] [Fine-Tuning LLMs with Fine-Grained Human Feedback on Text Spans](https://arxiv.org/abs/2512.23693)
*Sky CH-Wang,Justin Svegliato,Helen Appel,Jason Eisner*

Main category: cs.CL

TL;DR: 通过反馈驱动的增量改进链，实现语言模型细粒度偏好微调，效果优于传统偏好排名方法。


<details>
  <summary>Details</summary>
Motivation: 提高语言模型基于偏好的微调效率与效果，解决传统整体偏好排序和全重写方法对局部编辑学习利用不足的问题。

Method: 标注者对模型生成结果中喜欢和不喜欢的片段进行标记并说明理由，模型从左到右逐步重写不喜欢的部分形成改进链，利用链中相邻步骤构建偏好对进行直接对齐训练。

Result: 提出了一种基于反馈驱动的改进链进行语言模型偏好监督微调的方法及数据集。通过标注者细粒度标记模型响应中的喜欢与不喜欢部分，并指出具体原因，模型逐步从左到右对不喜欢的部分进行重写，形成增量改进序列。利用相邻步骤构建偏好对，实现局部针对性编辑学习。该方法优于传统的A/B偏好排序及全对比重写，证明基于结构化修订的监督更高效有效。

Conclusion: 结构化的基于修订的偏好监督能更高效、有效地对语言模型进行偏好微调，比标准的A/B排序和完整对比重写方法表现更佳。

Abstract: We present a method and dataset for fine-tuning language models with preference supervision using feedback-driven improvement chains. Given a model response, an annotator provides fine-grained feedback by marking ``liked'' and ``disliked'' spans and specifying what they liked or disliked about them. The base model then rewrites the disliked spans accordingly, proceeding from left to right, forming a sequence of incremental improvements. We construct preference pairs for direct alignment from each adjacent step in the chain, enabling the model to learn from localized, targeted edits. We find that our approach outperforms direct alignment methods based on standard A/B preference ranking or full contrastive rewrites, demonstrating that structured, revision-based supervision leads to more efficient and effective preference tuning.

</details>


### [66] [Eliciting Behaviors in Multi-Turn Conversations](https://arxiv.org/abs/2512.23701)
*Jing Huang,Shujian Zhang,Lun Wang,Andrew Hard,Rajiv Mathews,John Lambert*

Main category: cs.CL

TL;DR: 本文提出并评估了多轮对话中从大型语言模型激发特定行为的方法，验证在线方法在效率和成功率上的优势，强调了动态评测的重要性。


<details>
  <summary>Details</summary>
Motivation: 在多轮对话环境中，从大型语言模型中识别特定且复杂的行为对于其评估至关重要，而现有方法主要研究单轮情境。

Method: 提出了一个分析框架，将现有方法分为三类：仅使用先验知识的、使用离线交互的、以及基于在线交互学习的。引入了多轮对话中在线方法的广义形式，统一了单轮和多轮行为激发方法。评估了这三类方法在自动生成多轮测试用例上的效果，并分析了查询预算与成功率之间的权衡。

Result: 在线方法在三个任务上仅用少量查询就能分别达到45%、19%和77%的平均成功率，而静态方法在现有多轮对话基准上难以找到失败案例。

Conclusion: 在线行为激发方法在多轮对话评估中表现出显著优势，强调了动态基准测试的必要性，推动社区关注动态评测方法。

Abstract: Identifying specific and often complex behaviors from large language models (LLMs) in conversational settings is crucial for their evaluation. Recent work proposes novel techniques to find natural language prompts that induce specific behaviors from a target model, yet they are mainly studied in single-turn settings. In this work, we study behavior elicitation in the context of multi-turn conversations. We first offer an analytical framework that categorizes existing methods into three families based on their interactions with the target model: those that use only prior knowledge, those that use offline interactions, and those that learn from online interactions. We then introduce a generalized multi-turn formulation of the online method, unifying single-turn and multi-turn elicitation. We evaluate all three families of methods on automatically generating multi-turn test cases. We investigate the efficiency of these approaches by analyzing the trade-off between the query budget, i.e., the number of interactions with the target model, and the success rate, i.e., the discovery rate of behavior-eliciting inputs. We find that online methods can achieve an average success rate of 45/19/77% with just a few thousand queries over three tasks where static methods from existing multi-turn conversation benchmarks find few or even no failure cases. Our work highlights a novel application of behavior elicitation methods in multi-turn conversation evaluation and the need for the community to move towards dynamic benchmarks.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [67] [ReCollab: Retrieval-Augmented LLMs for Cooperative Ad-hoc Teammate Modeling](https://arxiv.org/abs/2512.22129)
*Conor Wallace,Umer Siddique,Yongcan Cao*

Main category: cs.MA

TL;DR: 本文利用大语言模型提出团队协作中的行为识别与适应方法，显著提升了临时组队中策略的适应性能和分类准确率。


<details>
  <summary>Details</summary>
Motivation: 传统方法在部分可观察和有限交互场景中表现脆弱，LLMs提供了灵活的行为假设建模能力，有望改善临时组队中的协作效果。

Method: 通过设计行为评价标准，将短行为轨迹映射为高层假设，利用LLMs进行队友类型分类；进一步引入检索增强生成以稳定推断。

Result: 本文提出了两个基于大语言模型（LLMs）的自适应团队协作框架——\Collab和\ReCollab，用于解决临时组队中队友行为识别及策略适应问题。\Collab通过行为轨迹特征构建行为评价标准，实现对队友类型的分类；\ReCollab引入检索增强生成技术，提高推断的稳定性。实验在合作游戏Overcooked中表明，\Collab能够有效区分队友类型，\ReCollab提升了适应性表现，并在分类准确率和回报之间达到帕累托最优。结果验证了LLMs作为行为世界模型在动态协作环境中的潜力，强调了检索机制对复杂协调场景的重要性。

Conclusion: 基于大语言模型的行为世界模型能够有效支持临时组队中的队友行为推断与策略自适应，且检索增强机制显著提升了模型的稳定性和表现。

Abstract: Ad-hoc teamwork (AHT) requires agents to infer the behavior of previously unseen teammates and adapt their policy accordingly. Conventional approaches often rely on fixed probabilistic models or classifiers, which can be brittle under partial observability and limited interaction. Large language models (LLMs) offer a flexible alternative: by mapping short behavioral traces into high-level hypotheses, they can serve as world models over teammate behavior. We introduce \Collab, a language-based framework that classifies partner types using a behavior rubric derived from trajectory features, and extend it to \ReCollab, which incorporates retrieval-augmented generation (RAG) to stabilize inference with exemplar trajectories. In the cooperative Overcooked environment, \Collab effectively distinguishes teammate types, while \ReCollab consistently improves adaptation across layouts, achieving Pareto-optimal trade-offs between classification accuracy and episodic return. These findings demonstrate the potential of LLMs as behavioral world models for AHT and highlight the importance of retrieval grounding in challenging coordination settings.

</details>


### [68] [Solving Multi-Agent Multi-Goal Path Finding Problems in Polynomial Time](https://arxiv.org/abs/2512.22171)
*Stefan Edelkamp*

Main category: cs.MA

TL;DR: 本文提出了一种多智能体路径规划方法，自动调整任务分配，实现无冲突的优化路径规划且解决复杂冲突问题，且在离散场景下多项式时间可解，突破了车辆路径规划的NP难限制。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体路径规划任务中，路径和目标分配通常固定，且常见问题如车辆路径规划在一般图上为NP难问题。本文旨在设计一种自动更新任务分配、解决冲突且多项式时间可解的方法。

Method: 针对无向图（如网格）中的多目标任务，设计了一种能够自动更新任务分配的多智能体路径规划算法。对连续空间中的点智能体运动，通过优化求解路径接近最优；对存在节点和边冲突的离散情况，证明了该问题在多项式时间内可解。实现了一个规划器，通过全局任务分配策略减少冲突，同时利用局部任务分配、路径交错及移除已到达智能体等手段解决剩余冲突。

Result: 提出的算法在连续情形下接近最优地解决路径规划，在离散情形中实现多项式时间内解决路径和目标冲突，超越了传统车辆路径规划的难度。实现的规划器能够找到无冲突且优化的路径，实现了全局与局部任务分配策略的结合，显著减少并解决路径冲突。

Conclusion: 本文设计的多智能体路径规划方案通过动态任务分配和冲突解决策略，实现了高效且多项式时间可解的无冲突路径规划，为多目标多智能体系统任务规划提供了新的解决思路。

Abstract: In this paper, we plan missions for a fleet of agents in undirected graphs, such as grids, with multiple goals. In contrast to regular multi-agent path-finding, the solver finds and updates the assignment of goals to the agents on its own. In the continuous case for a point agent with motions in the Euclidean plane, the problem can be solved arbitrarily close to optimal. For discrete variants that incur node and edge conflicts, we show that it can be solved in polynomial time, which is unexpected, since traditional vehicle routing on general graphs is NP-hard. We implement a corresponding planner that finds conflict-free optimized routes for the agents. Global assignment strategies greatly reduce the number of conflicts, with the remaining ones resolved by elaborating on the concept of ants-on-the-stick, by solving local assignment problems, by interleaving agent paths, and by kicking agents that have already arrived out of their destinations

</details>


### [69] [Hierarchical Pedagogical Oversight: A Multi-Agent Adversarial Framework for Reliable AI Tutoring](https://arxiv.org/abs/2512.22496)
*Saisab Sadhu,Ashim Dhor*

Main category: cs.MA

TL;DR: 本文设计了层次化教学监督框架，通过多方对抗辩论提升大语言模型的教学能力，在中学数学对话任务中表现优于GPT-4o，且模型更小更高效。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型作为自动辅导工具存在教学推理不足，经常错误肯定学生答案或提供过直接解答，阻碍学习效果，亟需改进教学监管机制。

Method: 设计了层次化教学监督框架（HPO），通过专门代理提炼对话信息并组织五幕对抗辩论，增强模型的教学评估和批判能力。

Result: 本文提出了层次化教学监督（HPO）框架，用于改进大语言模型（LLMs）在教育辅导中的教学推理能力。通过引入多方对抗性的教学评估机制，HPO避免了合作多智能体系统中容易出现的肤浅共识问题。其核心是让专业代理先提炼对话上下文，再进行五幕式辩论，促进深入教学批评。实验中，基于MRBench中学数学对话数据集的8亿参数模型取得了0.845的宏F1值，超越GPT-4o 3.3%，且参数量仅为后者的1/20，证明了对抗性推理在资源受限环境下实现可靠教学监督的有效性。

Conclusion: 引入对抗性教学监督机制显著提升了模型的教学推理能力和准确性，使低参数模型在资源有限环境中可实现可靠辅导。

Abstract: Large Language Models (LLMs) are increasingly deployed as automated tutors to address educator shortages; however, they often fail at pedagogical reasoning, frequently validating incorrect student solutions (sycophancy) or providing overly direct answers that hinder learning. We introduce Hierarchical Pedagogical Oversight (HPO), a framework that adapts structured adversarial synthesis to educational assessment. Unlike cooperative multi-agent systems that often drift toward superficial consensus, HPO enforces a dialectical separation of concerns: specialist agents first distill dialogue context, which then grounds a moderated, five-act debate between opposing pedagogical critics. We evaluate this framework on the MRBench dataset of 1,214 middle-school mathematics dialogues. Our 8B-parameter model achieves a Macro F1 of 0.845, outperforming GPT-4o (0.812) by 3.3% while using 20 times fewer parameters. These results establish adversarial reasoning as a critical mechanism for deploying reliable, low-compute pedagogical oversight in resource-constrained environments.

</details>


### [70] [MARPO: A Reflective Policy Optimization for Multi Agent Reinforcement Learning](https://arxiv.org/abs/2512.22832)
*Cuiling Wu,Yaozhong Gan,Junliang Xing,Ying Fu*

Main category: cs.MA

TL;DR: 本文提出了多智能体反思策略优化（MARPO），通过反思机制和非对称剪辑机制提升了多智能体强化学习的样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习中样本效率低的问题。

Method: MARPO包含反思机制（利用后续轨迹提升样本效率）和非对称剪辑机制（基于KL散度动态调整剪辑范围以提高稳定性）。

Result: 在经典多智能体环境中，MARPO持续优于其他方法。

Conclusion: MARPO在经典多智能体环境中表现优异，显著优于其他方法。

Abstract: We propose Multi Agent Reflective Policy Optimization (MARPO) to alleviate the issue of sample inefficiency in multi agent reinforcement learning. MARPO consists of two key components: a reflection mechanism that leverages subsequent trajectories to enhance sample efficiency, and an asymmetric clipping mechanism that is derived from the KL divergence and dynamically adjusts the clipping range to improve training stability. We evaluate MARPO in classic multi agent environments, where it consistently outperforms other methods.

</details>


### [71] [Reinforcement Networks: novel framework for collaborative Multi-Agent Reinforcement Learning tasks](https://arxiv.org/abs/2512.22876)
*Maksim Kryzhanovskiy,Svetlana Glazyrina,Roman Ischenko,Konstantin Vorontsov*

Main category: cs.MA

TL;DR: 本文提出Reinforcement Networks框架，利用DAG结构组织多智能体，提升训练灵活性和性能，优于传统方法，推动了可扩展的图结构MARL研究。


<details>
  <summary>Details</summary>
Motivation: 解决传统多智能体强化学习中因拓扑限制、集中训练等带来的灵活性和可扩展性瓶颈，寻找统一且灵活的多智能体组织和训练框架。

Method: 将多智能体视为有向无环图中的节点，设计了适用于该结构的训练和推理方法；结合LevelEnv支持框架的复现和评估；通过多个合作MARL任务验证效果优于传统基线。

Result: 本文提出了Reinforcement Networks框架，将多智能体强化学习（MARL）中的智能体组织成有向无环图（DAG）结构，拓展了层级强化学习，提升了灵活的信用分配和协调能力，避免了严格拓扑和集中训练的限制。通过训练和推理方法的形式化及与LevelEnv的结合，实现了可复现的构建、训练和评估。实验表明该框架在多个合作MARL任务中优于标准基线。该方法统一了层级、模块化和图结构视角，开启了设计和训练复杂多智能体系统的原则性路径。最后提出了理论及实际应用的未来方向，如丰富的图形形态、组合课程和图感知探索。

Conclusion: Reinforcement Networks为多智能体强化学习提供了统一且灵活的图结构框架，实现了更优的性能和更好的可扩展性，成为复杂多智能体系统设计与训练的新基础。

Abstract: Modern AI systems often comprise multiple learnable components that can be naturally organized as graphs. A central challenge is the end-to-end training of such systems without restrictive architectural or training assumptions. Such tasks fit the theory and approaches of the collaborative Multi-Agent Reinforcement Learning (MARL) field. We introduce Reinforcement Networks, a general framework for MARL that organizes agents as vertices in a directed acyclic graph (DAG). This structure extends hierarchical RL to arbitrary DAGs, enabling flexible credit assignment and scalable coordination while avoiding strict topologies, fully centralized training, and other limitations of current approaches. We formalize training and inference methods for the Reinforcement Networks framework and connect it to the LevelEnv concept to support reproducible construction, training, and evaluation. We demonstrate the effectiveness of our approach on several collaborative MARL setups by developing several Reinforcement Networks models that achieve improved performance over standard MARL baselines. Beyond empirical gains, Reinforcement Networks unify hierarchical, modular, and graph-structured views of MARL, opening a principled path toward designing and training complex multi-agent systems. We conclude with theoretical and practical directions - richer graph morphologies, compositional curricula, and graph-aware exploration. That positions Reinforcement Networks as a foundation for a new line of research in scalable, structured MARL.

</details>


### [72] [Heterogeneity in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.22941)
*Tianyi Hu,Zhiqiang Pu,Yuan Wang,Tenghai Qiu,Min Chen,Xin Yu*

Main category: cs.MA

TL;DR: 本文系统定义和量化了MARL中的异质性，并提出基于异质性的参数共享算法，实验表明该方法具有更好的可解释性和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前MARL领域缺乏对异质性的严格定义和深入理解，异质性不仅涉及智能体功能差异，还关系到策略多样性和环境交互，因此需要系统性探讨以推动算法发展。

Method: 通过智能体级别建模给出五类异质性数学定义，提出异质性距离及量化方法，设计基于异质性的多智能体动态参数共享算法，并通过案例及实验验证方法有效性。

Result: 本文系统探讨了多智能体强化学习（MARL）中的异质性问题，包括其定义、量化及应用方法。通过对智能体层面的建模，将异质性分为五种类型并给出数学定义，提出了异质性距离的概念及实用量化方法。此外，设计了一种基于异质性的多智能体动态参数共享算法，实验验证了其在识别异质性和提升算法可解释性及适应性方面的有效性。

Conclusion: 该研究为MARL中的异质性提供了严格定义和量化工具，所提出的算法在实验中表现出更强的适应性和可解释性，促进了MARL算法的发展。

Abstract: Heterogeneity is a fundamental property in multi-agent reinforcement learning (MARL), which is closely related not only to the functional differences of agents, but also to policy diversity and environmental interactions. However, the MARL field currently lacks a rigorous definition and deeper understanding of heterogeneity. This paper systematically discusses heterogeneity in MARL from the perspectives of definition, quantification, and utilization. First, based on an agent-level modeling of MARL, we categorize heterogeneity into five types and provide mathematical definitions. Second, we define the concept of heterogeneity distance and propose a practical quantification method. Third, we design a heterogeneity-based multi-agent dynamic parameter sharing algorithm as an example of the application of our methodology. Case studies demonstrate that our method can effectively identify and quantify various types of agent heterogeneity. Experimental results show that the proposed algorithm, compared to other parameter sharing baselines, has better interpretability and stronger adaptability. The proposed methodology will help the MARL community gain a more comprehensive and profound understanding of heterogeneity, and further promote the development of practical algorithms.

</details>


### [73] [Assessing behaviour coverage in a multi-agent system simulation for autonomous vehicle testing](https://arxiv.org/abs/2512.23445)
*Manuel Franco-Vivo*

Main category: cs.MA

TL;DR: 本文研究了自动驾驶车辆测试的多智能体系统仿真中的行为覆盖分析，提出了一种系统化的行为覆盖测量方法，并通过引入模型预测控制行人代理提高测试的趣味性和真实性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，保障其安全性和可靠性非常关键，本文旨在通过全面的行为覆盖分析提升多智能体仿真测试方法的有效性，确保自动驾驶系统在复杂真实场景下的表现。

Method: 通过定义多种驾驶场景和智能体交互，采用行为覆盖指标评估仿真环境的行为覆盖范围，并提出利用模型预测控制（MPC）的行人代理来生成更具“趣味性”且行为更真实的测试案例。

Result: 研究表明行为覆盖分析能够识别仿真测试中的盲点和不足，提出的MPC行人代理能够生成更有价值的测试场景，为提升自动驾驶系统的安全性、可靠性及性能提供了有效的测试支持。

Conclusion: 行为覆盖对于验证自动驾驶系统的有效性和鲁棒性至关重要，通过行为覆盖度量和基于覆盖的测试，本文识别出仿真框架中的关键改进点，提高了自动驾驶测试的全面性和可靠性。

Abstract: As autonomous vehicle technology advances, ensuring the safety and reliability of these systems becomes paramount. Consequently, comprehensive testing methodologies are essential to evaluate the performance of autonomous vehicles in diverse and complex real-world scenarios. This study focuses on the behaviour coverage analysis of a multi-agent system simulation designed for autonomous vehicle testing, and provides a systematic approach to measure and assess behaviour coverage within the simulation environment. By defining a set of driving scenarios, and agent interactions, we evaluate the extent to which the simulation encompasses a broad range of behaviours relevant to autonomous driving.
  Our findings highlight the importance of behaviour coverage in validating the effectiveness and robustness of autonomous vehicle systems. Through the analysis of behaviour coverage metrics and coverage-based testing, we identify key areas for improvement and optimization in the simulation framework. Thus, a Model Predictive Control (MPC) pedestrian agent is proposed, where its objective function is formulated to encourage \textit{interesting} tests while promoting a more realistic behaviour than other previously studied pedestrian agents. This research contributes to advancing the field of autonomous vehicle testing by providing insights into the comprehensive evaluation of system behaviour in simulated environments. The results offer valuable implications for enhancing the safety, reliability, and performance of autonomous vehicles through rigorous testing methodologies.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [74] [Syntax Is Not Enough: An Empirical Study of Small Transformer Models for Neural Code Repair](https://arxiv.org/abs/2512.22216)
*Shaunak Samant*

Main category: cs.SE

TL;DR: 小型Transformer模型在Java自动修复中语法正确率高但语义修复失败。


<details>
  <summary>Details</summary>
Motivation: 探索小型Transformer模型在真实Java程序缺陷自动修复中的有效性及语法正确性是否可以作为语义正确性的代理指标。

Method: 微调CodeT5-small模型在52,364个Java缺陷修复对上，使用AST解析测试语法正确性及精确匹配测试语义准确性。

Result: 该论文研究了使用小型Transformer模型（CodeT5-small）对Java程序进行自动化修复的效果，发现虽然模型能生成高语法正确率（约94%）的代码，但在语义修复准确性上表现极差，完全没有生成正确修复代码的情况，80%情况下直接复现了有缺陷的代码。

Conclusion: 语法正确性并不能保证语义修复的正确，且小型模型难以实现有效的真实世界Java缺陷修复。

Abstract: Automated program repair using neural models has shown promising results on benchmark datasets, yet practical deployment remains limited. In this study, we examine whether a small transformer model can meaningfully repair real-world Java bugs and whether syntactic correctness is a reliable proxy for semantic correctness.
  We fine-tune CodeT5-small (60.5M parameters) on 52,364 Java bug-fix pairs from CodeXGLUE and evaluate both token-level performance and syntactic validity using AST parsing. While the model converges cleanly and achieves high grammatical correctness, producing syntactically valid Java code in approximately ninety-four percent of cases, it fails to generate correct repairs under exact-match evaluation, achieving zero exact matches. In approximately eighty percent of cases, the model reproduces the buggy input verbatim.

</details>


### [75] [Failure Analysis of Safety Controllers in Autonomous Vehicles Under Object-Based LiDAR Attacks](https://arxiv.org/abs/2512.22244)
*Daniyal Ganiuly,Nurzhau Bolatbek,Assel Smaiyl*

Main category: cs.SE

TL;DR: 论文系统分析了基于激光雷达的对象欺骗攻击对高速公路驾驶中纵向安全控制器的影响，揭示了感知鲁棒性与控制安全之间的关键差距，并为设计抗攻击安全机制提供了实用见解。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆依赖激光雷达感知以支持关键安全控制功能，如自适应巡航控制和自动紧急制动。然而，激光雷达感知易受到基于对象的欺骗和注入攻击，其对车辆安全控制器的影响尚未充分理解。

Method: 采用高保真仿真框架，集成激光雷达感知、目标跟踪和闭环车辆控制，模拟高速公路并线和跟车场景，对虚假和错位目标检测在感知-规划-控制流程中的传播进行评估。

Result: 研究发现，即使是短时间的激光雷达虚假对象检测也会引发不安全的制动、对真实危险的响应延迟和控制不稳定。在并线场景下，攻击导致不安全减速事件和碰撞时间违规显著增加，且控制器故障更多受欺骗对象时间一致性的影响，而非仅空间误差。

Conclusion: 感知欺骗对自动驾驶车辆的安全控制器构成显著威胁，需设计具备攻击感知能力的安全机制和更具韧性的控制策略以保障系统安全。

Abstract: Autonomous vehicles rely on LiDAR based perception to support safety critical control functions such as adaptive cruise control and automatic emergency braking. While previous research has shown that LiDAR perception can be manipulated through object based spoofing and injection attacks, the impact of such attacks on vehicle safety controllers is still not well understood. This paper presents a systematic failure analysis of longitudinal safety controllers under object based LiDAR attacks in highway driving scenarios. The study focuses on realistic cut in and car following situations in which adversarial objects introduce persistent perception errors without directly modifying vehicle control software. A high fidelity simulation framework integrating LiDAR perception, object tracking, and closed loop vehicle control is used to evaluate how false and displaced object detections propagate through the perception planning and control pipeline. The results demonstrate that even short duration LiDAR induced object hallucinations can trigger unsafe braking, delayed responses to real hazards, and unstable control behavior. In cut in scenarios, a clear increase in unsafe deceleration events and time to collision violations is observed when compared to benign conditions, despite identical controller parameters. The analysis further shows that controller failures are more strongly influenced by the temporal consistency of spoofed objects than by spatial inaccuracies alone. These findings reveal a critical gap between perception robustness and control level safety guarantees in autonomous driving systems. By explicitly characterizing safety controller failure modes under adversarial perception, this work provides practical insights for the design of attack aware safety mechanisms and more resilient control strategies for LiDAR dependent autonomous vehicles.

</details>


### [76] [Hallucination Detection for LLM-based Text-to-SQL Generation via Two-Stage Metamorphic Testing](https://arxiv.org/abs/2512.22250)
*Bo Yang,Yinfen Xia,Weisong Sun,Yang Liu*

Main category: cs.SE

TL;DR: 针对大语言模型生成的SQL幻觉问题，提出无需标准答案的SQLHD变形测试方法，分两阶段检测模式链接和逻辑幻觉，显著提升检测性能，优于自评估方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在文本到SQL生成任务中表现出强大的泛化和适应能力，但容易产生幻觉（生成不真实或不合逻辑的内容），导致错误的SQL查询，影响下游应用，且现有错误检测方法难以有效识别LLMs的幻觉，主要因缺乏标准答案数据。

Method: 提出SQLHD方法，基于变形测试（Metamorphic Testing），分两个阶段检测幻觉：第一阶段利用8个结构感知变形关系检测模式链接幻觉，通过扰动比较词、实体、句子结构或数据库模式来生成并交叉验证模式映射；第二阶段使用9个逻辑感知变形关系检测逻辑综合幻觉，变异前缀词、极值表达、比较范围或整个数据库，通过交叉验证生成的SQL人工制品发现幻觉。该方法不依赖标准答案。

Result: 实验结果显示SQLHD在幻觉检测任务中F1分数高达69.36%至82.76%，优于LLM自评估方法，显著提升文本到SQL任务中的幻觉识别能力。

Conclusion: SQLHD有效解决了缺乏标准答案情况下大语言模型生成SQL幻觉的检测难题，证明了基于变形测试的多阶段检测策略在文本到SQL幻觉识别中的优越性和实用价值。

Abstract: In Text-to-SQL generation, large language models (LLMs) have shown strong generalization and adaptability. However, LLMs sometimes generate hallucinations, i.e.,unrealistic or illogical content, which leads to incorrect SQL queries and negatively impacts downstream applications. Detecting these hallucinations is particularly challenging. Existing Text-to-SQL error detection methods, which are tailored for traditional deep learning models, face significant limitations when applied to LLMs. This is primarily due to the scarcity of ground-truth data. To address this challenge, we propose SQLHD, a novel hallucination detection method based on metamorphic testing (MT) that does not require standard answers. SQLHD splits the detection task into two sequentiial stages: schema-linking hallucination detection via eight structure-aware Metamorphic Relations (MRs) that perturb comparative words, entities, sentence structure or database schema, and logical-synthesis hallucination detection via nine logic-aware MRs that mutate prefix words, extremum expressions, comparison ranges or the entire database. In each stage the LLM is invoked separately to generate schema mappings or SQL artefacts; the follow-up outputs are cross-checked against their source counterparts through the corresponding MRs, and any violation is flagged as a hallucination without requiring ground-truth SQL. The experimental results demonstrate our method's superior performance in terms of the F1-score, which ranges from 69.36\% to 82.76\%. Additionally, SQLHD demonstrates superior performance over LLM Self-Evaluation methods, effectively identifying hallucinations in Text-to-SQL tasks.

</details>


### [77] [Agentic Software Issue Resolution with Large Language Models: A Survey](https://arxiv.org/abs/2512.22256)
*Zhonghao Jiang,David Lo,Zhongxin Liu*

Main category: cs.SE

TL;DR: 本文综述了采用大型语言模型代理系统进行软件问题解决的最新进展，提出了任务分类体系，强调代理强化学习的革命性作用，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 软件问题解决任务复杂且需长程推理与迭代反馈，传统单步方法不足以应对，随着LLM推理及生成能力的发展，基于代理系统的新范式为提升软件维护效率和质量提供了可能，而且为检验人工智能推理和执行能力提供了实际应用场景。

Method: 本文通过系统综述126项最新研究，归纳软件问题解决的通用流程，建立基准、技术与实证研究三维分类体系，分析代理强化学习在软件工程代理系统设计与训练中的应用。

Result: 本文系统综述了基于大型语言模型（LLM）的代理系统在软件问题解决中的最新研究进展，涵盖了126个相关研究，重点介绍了软件问题解决的任务流程及其在基准测试、技术及实证研究三维度的分类。文中指出，传统单步解决方法难以满足软件问题解决中需要的长程推理、迭代探索和反馈驱动决策，代理系统尤其是采用强化学习的代理系统带来了范式转变。研究不仅提升了软件维护的效率和质量，也为验证人工智能中的推理、规划和执行能力提供了现实平台。最后，文章总结了当前面临的挑战及未来研究方向。

Conclusion: 基于LLM的代理系统显著推动了软件问题解决的发展，有效提升了维护效率与质量，为人工智能与软件工程的结合搭建了桥梁，但仍需克服多项技术挑战。

Abstract: Software issue resolution aims to address real-world issues in software repositories (e.g., bug fixing and efficiency optimization) based on natural language descriptions provided by users, representing a key aspect of software maintenance. With the rapid development of large language models (LLMs) in reasoning and generative capabilities, LLM-based approaches have made significant progress in automated software issue resolution. However, real-world software issue resolution is inherently complex and requires long-horizon reasoning, iterative exploration, and feedback-driven decision making, which demand agentic capabilities beyond conventional single-step approaches. Recently, LLM-based agentic systems have become mainstream for software issue resolution. Advancements in agentic software issue resolution not only greatly enhance software maintenance efficiency and quality but also provide a realistic environment for validating agentic systems' reasoning, planning, and execution capabilities, bridging artificial intelligence and software engineering.
  This work presents a systematic survey of 126 recent studies at the forefront of LLM-based agentic software issue resolution research. It outlines the general workflow of the task and establishes a taxonomy across three dimensions: benchmarks, techniques, and empirical studies. Furthermore, it highlights how the emergence of agentic reinforcement learning has brought a paradigm shift in the design and training of agentic systems for software engineering. Finally, it summarizes key challenges and outlines promising directions for future research.

</details>


### [78] [AI-Generated Code Is Not Reproducible (Yet): An Empirical Study of Dependency Gaps in LLM-Based Coding Agents](https://arxiv.org/abs/2512.22387)
*Bhanu Prakash Vangala,Ali Adibifar,Tanu Malik,Ashish Gehani*

Main category: cs.SE

TL;DR: 研究发现当前LLMs生成代码在依赖声明和实际运行依赖之间存在巨大差距，导致只有约七成代码能顺利执行，语言间差异显著。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成中表现卓越，其生成代码的可复现性和依赖管理尚未被充分研究，且这一问题直接影响软件开发的实用性与可靠性。

Method: 通过标准化100个提示生成300个跨Python、JavaScript和Java项目，利用三层依赖框架分析声明依赖、实际工作依赖和运行时依赖，实证评估三款主流LLM编码工具的代码复现能力。

Result: 该论文通过实证研究探讨了大型语言模型(LLMs)生成代码的可执行复现性，评估了Claude Code、OpenAI Codex和Gemini三种主流编码代理在Python、JavaScript和Java三种语言上生成的300个项目。通过引入三层依赖框架区分声明的依赖、工作依赖和运行时依赖，量化代码的复现性。结果显示仅68.3%的项目能开箱即用执行，且不同语言间差异显著，Python最高达89.2%，Java最低仅44.0%。运行时隐含依赖比声明依赖多13.5倍，暴露出大量隐藏依赖问题。

Conclusion: 大型语言模型生成的代码在依赖管理和复现性方面存在明显不足，需要更精准的依赖声明和管理策略以提升代码执行成功率。

Abstract: The rise of Large Language Models (LLMs) as coding agents promises to accelerate software development, but their impact on generated code reproducibility remains largely unexplored. This paper presents an empirical study investigating whether LLM-generated code can be executed successfully in a clean environment with only OS packages and using only the dependencies that the model specifies. We evaluate three state-of-the-art LLM coding agents (Claude Code, OpenAI Codex, and Gemini) across 300 projects generated from 100 standardized prompts in Python, JavaScript, and Java. We introduce a three-layer dependency framework (distinguishing between claimed, working, and runtime dependencies) to quantify execution reproducibility. Our results show that only 68.3% of projects execute out-of-the-box, with substantial variation across languages (Python 89.2%, Java 44.0%). We also find a 13.5 times average expansion from declared to actual runtime dependencies, revealing significant hidden dependencies.

</details>


### [79] [Building Software by Rolling the Dice: A Qualitative Study of Vibe Coding](https://arxiv.org/abs/2512.22418)
*Yi-Hung Chou,Boyuan Jiang,Yi Wen Chen,Mingyue Weng,Victoria Jackson,Thomas Zimmermann,James A. Jones*

Main category: cs.SE

TL;DR: 本文通过分析20个vibe coding视频，揭示了开发者如何在大型语言模型辅助下进行软件开发，展示了行为多样性及随机性挑战，为未来软件工程研究和工具优化提供指导。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型支持的“vibe coding”实践缺乏深入理解，尤其是开发者如何定义和实际参与此类活动尚不明确。

Method: 通过对20个vibe coding相关视频（包括7个直播编码场景和13个观点视频）的扎根理论研究，辅以活动时长和提示意图的额外分析。

Result: 发现vibe coding行为存在谱系，从完全依赖AI不检查代码到检查并改编生成内容不等。生成过程的随机性使调试和细化充满不确定性，且编码者的专业背景和对AI的依赖影响了提示策略、评估方法和信任水平。

Conclusion: vibe coding作为一种新兴的软件开发实践，展现出多样化行为模式，揭示了未来软件工程研究和工具设计、教育的潜在方向和机会。

Abstract: Large language models (LLMs) are reshaping software engineering by enabling "vibe coding," in which developers build software primarily through prompts rather than writing code. Although widely publicized as a productivity breakthrough, little is known about how practitioners actually define and engage in these practices. To shed light on this emerging phenomenon, we conducted a grounded theory study of 20 vibe-coding videos, including 7 live-streamed coding sessions (about 16 hours, 254 prompts) and 13 opinion videos (about 5 hours), supported by additional analysis of activity durations and prompt intents. Our findings reveal a spectrum of behaviors: some vibe coders rely almost entirely on AI without inspecting code, while others examine and adapt generated outputs. Across approaches, all must contend with the stochastic nature of generation, with debugging and refinement often described as "rolling the dice." Further, divergent mental models, shaped by vibe coders' expertise and reliance on AI, influence prompting strategies, evaluation practices, and levels of trust. These findings open new directions for research on the future of software engineering and point to practical opportunities for tool design and education.

</details>


### [80] [GraphLocator: Graph-guided Causal Reasoning for Issue Localization](https://arxiv.org/abs/2512.22469)
*Wei Liu,Chao Peng,Pengfei Gao,Aofan Liu,Wei Zhang,Haiyan Zhao,Zhi Jin*

Main category: cs.SE

TL;DR: 提出GraphLocator通过因果问题图解决缺陷定位中的语义不匹配问题，大幅提升了定位准确度和后续修复效果。


<details>
  <summary>Details</summary>
Motivation: 软件缺陷定位面临症状与根因信息缺乏直接对应及一个缺陷对应多代码实体的挑战，现有自动化方法难以有效桥接自然语言描述与代码实现之间的语义鸿沟。

Method: 提出因果问题图（CIG）作为关键结构，通过两阶段流程：先定位症状顶点，再动态推理扩展图的邻接节点，解决语义差异引起的定位难题。

Result: 本文提出了一种名为GraphLocator的方法，旨在解决软件缺陷定位中的两个主要语义差异问题：症状与根因不匹配及单一缺陷对应多代码实体的复杂性。通过构建因果问题图（CIG），该方法先定位症状节点，再动态扩展图结构以揭示因果依赖关系，从而提高了缺陷定位的准确性。实验证明，GraphLocator在功能级召回率和精确率上分别提升了约19.49%和11.89%，在解决两类语义不匹配问题上表现更优，同时生成的因果图对后续缺陷修复任务也有显著促进作用。

Conclusion: GraphLocator有效缓解了症状与根因及单一缺陷多代码实体的匹配难题，显著提升缺陷定位及后续修复任务表现，验证了其在实际软件工程中的应用价值。

Abstract: The issue localization task aims to identify the locations in a software repository that requires modification given a natural language issue description. This task is fundamental yet challenging in automated software engineering due to the semantic gap between issue description and source code implementation. This gap manifests as two mismatches:(1) symptom-to-cause mismatches, where descriptions do not explicitly reveal underlying root causes; (2) one-to-many mismatches, where a single issue corresponds to multiple interdependent code entities. To address these two mismatches, we propose GraphLocator, an approach that mitigates symptom-to-cause mismatches through causal structure discovering and resolves one-to-many mismatches via dynamic issue disentangling. The key artifact is the causal issue graph (CIG), in which vertices represent discovered sub-issues along with their associated code entities, and edges encode the causal dependencies between them. The workflow of GraphLocator consists of two phases: symptom vertices locating and dynamic CIG discovering; it first identifies symptom locations on the repository graph, then dynamically expands the CIG by iteratively reasoning over neighboring vertices. Experiments on three real-world datasets demonstrates the effectiveness of GraphLocator: (1) Compared with baselines, GraphLocator achieves more accurate localization with average improvements of +19.49% in function-level recall and +11.89% in precision. (2) GraphLocator outperforms baselines on both symptom-to-cause and one-to-many mismatch scenarios, achieving recall improvement of +16.44% and +19.18%, precision improvement of +7.78% and +13.23%, respectively. (3) The CIG generated by GraphLocator yields the highest relative improvement, resulting in a 28.74% increase in performance on downstream resolving task.

</details>


### [81] [Isolating Compiler Faults via Multiple Pairs of Adversarial Compilation Configurations](https://arxiv.org/abs/2512.22538)
*Qingyang Li,Yibiao Yang,Maolin Sun,Jiangchang Wu,Qingkai Shi,Yuming Zhou*

Main category: cs.SE

TL;DR: 本文提出MultiConf方法，利用多组对抗配置对和加权投票，实现了对复杂编译器故障的高效准确定位，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 编译器是现代软件开发的基础，有效识别和定位编译器故障至关重要，但由于现代编译器基础设施的复杂性，准确定位故障到具体源文件极具挑战性。

Method: 提出MultiConf方法，通过构造多组对抗编译配置对（每对由失败和少量细粒度选项不同的通过配置组成）来自动隔离编译器故障，利用轻量级生成失败配置，通过选择性禁用相关选项获得通过配置，使用基于谱的故障定位方法对文件可疑性排名，最后通过加权投票聚合多个配置对的排名。

Result: 在60个真实GCC编译器缺陷的基准测试中，MultiConf在定位准确率和效率上显著优于现有方法，成功实现27个缺陷的Top-1文件定位，分别比Odfl(20)和Basic(21)提高了35.0%和28.6%。

Conclusion: MultiConf通过多对抗配置的生成和加权投票机制，提升了编译器故障定位的准确性和稳定性，验证了其在实际GCC缺陷上的优越性能。

Abstract: Compilers are fundamental to modern software development, making the effective identification and resolution of compiler faults essential. However, localizing these faults to specific source files remains highly challenging due to the complexity and scale of modern compiler infrastructures. In this study, we propose MultiConf, a novel approach that automatically isolates compiler faults by constructing multiple pairs of adversarial compilation configurations. Each adversarial compilation configuration pair consists of a failing configuration and its corresponding passing configuration, which differ in only a small number of fine-grained options. MultiConf generates failing configurations through a lightweight construction process and derives the corresponding passing configurations by selectively disabling bug-related fine-grained options. We then employ a Spectrum-Based Fault Localization (SBFL) formula to rank the suspiciousness of compiler source files. Each adversarial configuration pair independently produces a ranking, which is subsequently aggregated using a weighted voting scheme to derive a final suspiciousness ranking, enabling more accurate and robust fault localization. We evaluate MultiConf on a benchmark of 60 real-world GCC compiler bugs. The results demonstrate that MultiConf significantly outperforms existing compiler fault localization techniques in both effectiveness and efficiency. In particular, MultiConf successfully localizes 27 out of 60 bugs at the Top-1 file level, representing improvements of 35.0% and 28.6% over the two state-of-the-art approaches, Odfl(20) and Basic(21), respectively.

</details>


### [82] [Rethinking the Capability of Fine-Tuned Language Models for Automated Vulnerability Repair](https://arxiv.org/abs/2512.22633)
*Woorim Han,Yeongjun Kwak,Miseon Yu,Kyeongmin Kim,Younghan Lee,Hyungon Moon,Yunheung Paek*

Main category: cs.SE

TL;DR: 研究发现现有自动漏洞修复模型存在过拟合和不合理评估问题，提出多项改进措施并构建新基准，提升评估的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的自动漏洞修复模型容易过拟合且评估指标存在局限，无法准确衡量其对未见漏洞的修复能力，亟需更严谨的评估方法和基准。

Method: 通过语义保留变换测试集、重新划分训练验证测试集保障互斥性以及设计新的测试基准L-AVRBench，综合评估修复模型的性能和泛化能力。

Result: 本文通过实证研究揭示了当前基于微调语言模型的自动漏洞修复技术存在过拟合和评估集不互斥的问题，且基于匹配的评估指标忽略了多个有效修复方案的可能。为此，研究对测试集进行语义保留变换、重新划分训练集和测试集以确保互斥性，并构建了针对学习型自动漏洞修复的新基准L-AVRBench，全面评估模型的泛化和真实修复能力。

Conclusion: 基于微调语言模型的自动漏洞修复方法在泛化性和评估方式上存在显著不足，本文通过数据集重划分、语义转化测试及新基准构建有效提升了模型的真实修复能力评估。

Abstract: Learning-based automated vulnerability repair (AVR) techniques that utilize fine-tuned language models have shown promise in generating vulnerability patches. However, questions remain about their ability to repair unseen vulnerabilities. Our empirical study reveals that state-of-the-art models often overfit to the training set and are evaluated using training, validation, and test sets that are not mutually exclusive. Furthermore, relying on match-based metrics that compare generated patches to reference fixes at the token level has some limitations, failing to account for the possibility of various valid ways to patch the vulnerability. In this paper, we examine the capabilities of state-of-the-art fine-tuned AVR models and the adequacy of match-based evaluation metrics in three ways. First, we apply semantic-preserving transformations to test sets in order to determine whether models truly learn robust vulnerability-repair patterns or simply rely on spurious features. Second, we re-split the training, validation, and test sets to be mutually exclusive and evaluate the models on the revised test set to assess their generalization capabilities. Third, we introduce L-AVRBench, a test-based benchmark tailored for learning-based AVR, to overcome the limitations of match-based metrics and examine the AVR models' true repair capabilities.

</details>


### [83] [CFIghter: Automated Control-Flow Integrity Enablement and Evaluation for Legacy C/C++ Systems](https://arxiv.org/abs/2512.22701)
*Sabine Houy,Bruno Kreyssig,Alexandre Bartel*

Main category: cs.SE

TL;DR: CFIghter通过自动检测和修复，使严格的基于类型的控制流完整性技术在大型成熟的C软件项目中变得可行，无需人工干预即可兼顾安全性和兼容性。


<details>
  <summary>Details</summary>
Motivation: 传统基于编译器的CFI虽然能有效保护前向控制流，但在大型C/C++项目中因可见性不匹配、类型不一致以及非预期行为失败而难以部署。为了解决这些挑战，需要一种自动化的、严格基于类型的CFI实现方式。

Method: 引入CFIghter系统，该系统结合全程序分析与引导运行时监控，自动检测、分类并修复测试套件暴露的非预期控制流完整性（CFI）策略违规。通过迭代地对CFI执行进行最小必要调整，确保所有测试通过或将无法解决的失败标记出来。

Result: CFIghter在四个GNU项目上进行了评估，成功解决了所有的可见性相关构建错误，并在大型多库项目util-linux中自动修复了95.8%的非预期CFI违规，同时在89%以上的间接控制流点保持了严格执行。整个代码库大部分代码保留了严格的类型基CFI，且不需要手动修改源码，仅依赖自动生成的可见性调整和局部的执行范围限制。

Conclusion: 自动化兼容性修复使得严格的编译器级CFI技术在成熟模块化的C软件中实际可用，成功解决了部署中因类型和可见性导致的主要障碍，提高了CFI的应用范围和实用性。

Abstract: Compiler-based Control-Flow Integrity (CFI) offers strong forward-edge protection but remains challenging to deploy in large C/C++ software due to visibility mismatches, type inconsistencies, and unintended behavioral failures. We present CFIghter, the first fully automated system that enables strict, type-based CFI in real-world projects by detecting, classifying, and repairing unintended policy violations exposed by the test suite. CFIghter integrates whole-program analysis with guided runtime monitoring and iteratively applies the minimal necessary adjustments to CFI enforcement only where required, stopping once all tests pass or remaining failures are deemed unresolvable. We evaluate CFIghter on four GNU projects. It resolves all visibility-related build errors and automatically repairs 95.8% of unintended CFI violations in the large, multi-library util-linux codebase, while retaining strict enforcement at over 89% of indirect control-flow sites. Across all subjects, CFIghter preserves strict type-based CFI for the majority of the codebase without requiring manual source-code changes, relying only on automatically generated visibility adjustments and localized enforcement scopes where necessary. These results show that automated compatibility repair makes strict compiler CFI practically deployable in mature, modular C software.

</details>


### [84] [From Rookie to Expert: Manipulating LLMs for Automated Vulnerability Exploitation in Enterprise Software](https://arxiv.org/abs/2512.22753)
*Moustapha Awwalou Diouf,Maimouna Tamah Diao,Iyiola Emmanuel Olatunji,Abdoul Kader Kaboré,Jordan Samhi,Gervais Mendy,Samuel Ouya,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.SE

TL;DR: 本论文展示了如何通过社会工程手段操纵大型语言模型，使无经验者也能生成有效漏洞利用代码，颠覆了传统安全假设，呼吁重新设计软件安全策略。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型（LLMs）使非程序员也能创建应用程序，传统的软件工程安全假设受到了根本挑战。

Method: 提出RSA方法（角色分配、场景预设和行为诱导），诱导LLMs绕过安全机制生成功能性漏洞利用代码。

Result: 在使用RSA方法针对主流ERP平台Odoo测试五种主流LLMs时，成功率达到100%，利用已知CVE漏洞在3-4轮提示内生成有效利用代码。

Conclusion: 安全领域的核心原则如技术与非技术角色区分、漏洞描述的技术复杂度保护以及传统安全边界被打破，表明安全防护需针对仅凭提示构造能力的攻击进行重新设计。

Abstract: LLMs democratize software engineering by enabling non-programmers to create applications, but this same accessibility fundamentally undermines security assumptions that have guided software engineering for decades. We show in this work how publicly available LLMs can be socially engineered to transform novices into capable attackers, challenging the foundational principle that exploitation requires technical expertise. To that end, we propose RSA (Role-assignment, Scenario-pretexting, and Action-solicitation), a pretexting strategy that manipulates LLMs into generating functional exploits despite their safety mechanisms. Testing against Odoo -- a widely used ERP platform, we evaluated five mainstream LLMs (GPT-4o, Gemini, Claude, Microsoft Copilot, and DeepSeek) and achieved a 100% success rate: tested CVE yielded at least one working exploit within 3-4 prompting rounds. While prior work [13] found LLM-assisted attacks difficult and requiring manual effort, we demonstrate that this overhead can be eliminated entirely.
  Our findings invalidate core software engineering security principles: the distinction between technical and non-technical actors no longer provides valid threat models; technical complexity of vulnerability descriptions offers no protection when LLMs can abstract it away; and traditional security boundaries dissolve when the same tools that build software can be manipulated to break it. This represents a paradigm shift in software engineering -- we must redesign security practices for an era where exploitation requires only the ability to craft prompts, not understand code.
  Artifacts available at: https://anonymous.4open.science/r/From-Rookie-to-Attacker-D8B3.

</details>


### [85] [FasterPy: An LLM-based Code Execution Efficiency Optimization Framework](https://arxiv.org/abs/2512.22827)
*Yue Wu,Minghao Han,Ruiyin Li,Peng Liang,Amjed Tahir,Zengyang Li,Qiong Feng,Mojtaba Shahin*

Main category: cs.SE

TL;DR: 本论文提出了FasterPy，一个结合LLM和知识库检索的低成本高效Python代码优化框架，通过RAG和LoRA技术提升代码执行效率。


<details>
  <summary>Details</summary>
Motivation: 传统规则方法费力且适用有限，现有机器学习方法依赖特定程序表示和训练数据，开发成本高且难以扩展，LLM为自动化代码优化提供新可能。

Method: 采用基于检索增强生成（RAG）的方式，结合由已有代码对及性能数据构建的知识库，并通过低秩适配（LoRA）技术提升模型优化性能。

Result: 在PIE基准测试中，FasterPy在多个指标上优于现有模型，展现了其有效的代码性能提升能力。

Conclusion: FasterPy在PIE基准测试中表现优于现有模型，证明了其高效的代码性能优化能力。

Abstract: Code often suffers from performance bugs. These bugs necessitate the research and practice of code optimization. Traditional rule-based methods rely on manually designing and maintaining rules for specific performance bugs (e.g., redundant loops, repeated computations), making them labor-intensive and limited in applicability. In recent years, machine learning and deep learning-based methods have emerged as promising alternatives by learning optimization heuristics from annotated code corpora and performance measurements. However, these approaches usually depend on specific program representations and meticulously crafted training datasets, making them costly to develop and difficult to scale. With the booming of Large Language Models (LLMs), their remarkable capabilities in code generation have opened new avenues for automated code optimization. In this work, we proposed FasterPy, a low-cost and efficient framework that adapts LLMs to optimize the execution efficiency of Python code. FasterPy combines Retrieval-Augmented Generation (RAG), supported by a knowledge base constructed from existing performance-improving code pairs and corresponding performance measurements, with Low-Rank Adaptation (LoRA) to enhance code optimization performance. Our experimental results on the Performance Improving Code Edits (PIE) benchmark demonstrate that our method outperforms existing models on multiple metrics. The FasterPy tool and the experimental results are available at https://github.com/WuYue22/fasterpy.

</details>


### [86] [Towards the analysis of team members well-being](https://arxiv.org/abs/2512.22845)
*Zan Xu,Sari Nurfauziyyah,Anastasia Romanova,Kaamesh G S,Yiqun Gao,Maria Spichkova*

Main category: cs.SE

TL;DR: 论文探讨了软件开发团队成员的幸福感，强调了被认可对幸福感的重要性，并介绍了一个团队幸福感分析项目及其原型。


<details>
  <summary>Details</summary>
Motivation: 团队成员幸福感对工作绩效和员工的身体健康及个人生活均有重要影响，且认可感被认为是关键因素。

Method: 通过项目研究，收集和分析团队成员的幸福感数据，开发了一个原型工具用于团队幸福感分析。

Result: 项目成果包括对团队幸福感的洞察及一个支持幸福感分析的原型系统。

Conclusion: 团队成员感受到的认可对于提升幸福感至关重要，该项目开发的原型有助于分析和提升团队幸福感。

Abstract: Many recent research studies have focused on the well-being of software development team members, as this aspect may be critical not only for productivity and performance at work but also for the physical health and personal life of employees. Many studies agree that an important factor of team member well-being is whether team members feel appreciated and acknowledged for their contributions. This paper presents the results of a project on the team well-being analysis as well as the prototype developed within the project.

</details>


### [87] [Interpretable Gallbladder Ultrasound Diagnosis: A Lightweight Web-Mobile Software Platform with Real-Time XAI](https://arxiv.org/abs/2512.23033)
*Fuyad Hasan Bhoyan,Prashanta Sarker,Parsia Noor Ethila,Md. Emon Hossain,Md Kaviul Hossain,Md Humaion Kabir Mehedi*

Main category: cs.SE

TL;DR: 本论文提出了一种轻量且高精度的AI系统，通过混合深度学习模型和可解释AI技术，实现了胆囊疾病超声图像的多类别分类，支持临床实时、透明的决策。


<details>
  <summary>Details</summary>
Motivation: 胆囊疾病的早期准确检测对于治疗至关重要，但超声图像解释复杂且依赖经验。因此，开发一种智能、高效且具备可解释性的诊断工具迫切需要，以辅助临床决策。

Method: 采用混合深度学习模型MobResTaNet，结合可解释性人工智能（XAI）技术，实现对超声图像的多分类诊断，同时开发基于HTML、CSS、JavaScript、Bootstrap和Flutter的Web和移动应用，以实现系统的广泛部署和实时使用。

Result: 系统实现了99.85%的分类准确率，模型参数量仅2.24M，支持实时、可解释的诊断输出，并成功部署于Web和移动端应用，提升了诊断的便捷性和可信度。

Conclusion: 本研究开发的基于混合深度学习模型MobResTaNet的AI诊断软件，实现了从超声图像中准确识别九种胆囊疾病及正常状态，准确率高达99.85%，且模型轻量仅2.24M参数，满足临床实时检测需求。

Abstract: Early and accurate detection of gallbladder diseases is crucial, yet ultrasound interpretation is challenging. To address this, an AI-driven diagnostic software integrates our hybrid deep learning model MobResTaNet to classify ten categories, nine gallbladder disease types and normal directly from ultrasound images. The system delivers interpretable, real-time predictions via Explainable AI (XAI) visualizations, supporting transparent clinical decision-making. It achieves up to 99.85% accuracy with only 2.24M parameters. Deployed as web and mobile applications using HTML, CSS, JavaScript, Bootstrap, and Flutter, the software provides efficient, accessible, and trustworthy diagnostic support at the point of care

</details>


### [88] [An Automated Grey Literature Extraction Tool for Software Engineering](https://arxiv.org/abs/2512.23066)
*Houcine Abdelkader Cherief,Brahim Mahmoudi,Zacharie Chenail-Larcher,Naouel Moha,Quentin Sti'evenart,Florent Avellaneda*

Main category: cs.SE

TL;DR: GLiSE是一款面向软件工程灰色文献的大规模、可复现搜集与筛选工具，有效解决了多源异构数据问题。


<details>
  <summary>Details</summary>
Motivation: 灰色文献对于软件工程研究至关重要，但因来源多样、格式和API异构，难以实现大规模、可复现的数据收集与分析。

Method: 提出GLiSE工具，通过提示驱动生成针对不同平台的查询，从GitHub、Stack Overflow和Google搜集软件工程相关的灰色文献数据，利用基于嵌入的语义分类器进行筛选和排序。

Result: 开发了GLiSE工具，实现配置化设置、可访问的查询记录，提供了经过语义相关性分类的软件工程灰色文献数据集，并通过实证研究验证工具的可用性。

Conclusion: GLiSE有效支持了软件工程领域灰色文献的收集与分析，促进了相关研究的广泛应用和数据共享。

Abstract: Grey literature is essential to software engineering research as it captures practices and decisions that rarely appear in academic venues. However, collecting and assessing it at scale remains difficult because of their heterogeneous sources, formats, and APIs that impede reproducible, large-scale synthesis. To address this issue, we present GLiSE, a prompt-driven tool that turns a research topic prompt into platform-specific queries, gathers results from common software-engineering web sources (GitHub, Stack Overflow) and Google Search, and uses embedding-based semantic classifiers to filter and rank results according to their relevance. GLiSE is designed for reproducibility with all settings being configuration-based, and every generated query being accessible. In this paper, (i) we present the GLiSE tool, (ii) provide a curated dataset of software engineering grey-literature search results classified by semantic relevance to their originating search intent, and (iii) conduct an empirical study on the usability of our tool.

</details>


### [89] [An Empirical Study of Generative AI Adoption in Software Engineering](https://arxiv.org/abs/2512.23327)
*Görkem Giray,Onur Demirörs,Marcos Kalinowski,Daniel Mendez*

Main category: cs.SE

TL;DR: 研究表明生成式人工智能在软件工程中被广泛采纳，带来效率和质量提升，但存在准确性、安全和培训等挑战，实践者期待其重塑工作方式而非替代人力。


<details>
  <summary>Details</summary>
Motivation: 鉴于生成式人工智能工具在软件工程中日益普及，却缺乏实际应用的实证研究，本文旨在全面了解其应用现状及影响，为行业发展提供参考。

Method: 通过实证调研收集软件工程从业者对生成式人工智能工具使用情况的反馈，分析其应用范围、效益、挑战及制度化程度。

Result: 该论文研究了生成式人工智能（GenAI）工具在软件工程（SE）中的实际应用现状，探讨其带来的好处、挑战、工具的制度化情况及对专业人员和社区的长期影响。研究结果显示，GenAI工具被广泛采用并深度集成于日常软件开发工作中，尤其是在实现、验证、个人助理和维护任务中。实践者报告了显著效益，如缩短周期时间、提升质量、增强知识管理支持和生产力提升，但实际中对生产力和质量的客观衡量有限。挑战包括输出结果不准确、提示工程复杂、验证负担、安全隐私问题以及过度依赖风险。工具制度化普遍存在，但侧重于工具访问，培训和治理较少。实践者普遍认为GenAI将重塑而非替代他们的工作角色，对职位减少和技能转变持适度担忧。

Conclusion: 生成式人工智能已深度融入软件工程，带来显著效益同时伴随多重挑战，需加强培训与治理以促进工具的有效制度化，且对职业角色将产生重塑影响。

Abstract: Context. GenAI tools are being increasingly adopted by practitioners in SE, promising support for several SE activities. Despite increasing adoption, we still lack empirical evidence on how GenAI is used in practice, the benefits it provides, the challenges it introduces, and its broader organizational and societal implications. Objective. This study aims to provide an overview of the status of GenAI adoption in SE. It investigates the status of GenAI adoption, associated benefits and challenges, institutionalization of tools and techniques, and anticipated long term impacts on SE professionals and the community. Results. The results indicate a wide adoption of GenAI tools and how they are deeply integrated into daily SE work, particularly for implementation, verification and validation, personal assistance, and maintenance-related tasks. Practitioners report substantial benefits, most notably reduction in cycle time, quality improvements, enhanced support in knowledge work, and productivity gains. However, objective measurement of productivity and quality remains limited in practice. Significant challenges persist, including incorrect or unreliable outputs, prompt engineering difficulties, validation overhead, security and privacy concerns, and risks of overreliance. Institutionalization of tools and techniques seems to be common, but it varies considerably, with a strong focus on tool access and less emphasis on training and governance. Practitioners expect GenAI to redefine rather than replace their roles, while expressing moderate concern about job market contraction and skill shifts.

</details>


### [90] [Securing the AI Supply Chain: What Can We Learn From Developer-Reported Security Issues and Solutions of AI Projects?](https://arxiv.org/abs/2512.23385)
*The Anh Nguyen,Triet Huynh Minh Le,M. Ali Babar*

Main category: cs.SE

TL;DR: 本研究基于大规模开发者讨论，系统识别并分类了AI供应链中的安全问题与对应解决策略，揭示了模型和数据安全的挑战，为实际安全措施提供实证支持。


<details>
  <summary>Details</summary>
Motivation: AI模型和应用快速发展带来复杂安全威胁，但实践中安全问题及解决策略缺乏系统性理解，阻碍有效安全措施制定。研究旨在填补这一空白。

Method: 构建结合关键词匹配与最优微调distilBERT分类器的识别管道，从Hugging Face和GitHub获取数据，生成安全讨论数据集；对样本进行主题分析并归纳安全问题和解决方案分类。

Result: 本论文通过分析Hugging Face和GitHub上的开发者讨论，系统性揭示了AI供应链中常见的安全问题及其解决方案，构建了一个包含312,868条安全相关讨论的数据集，并提出了涵盖系统软件、外部工具、模型和数据四大主题下的32个安全问题和24个解决方案的细致分类。研究发现，AI组件的复杂依赖关系和黑盒特性导致多种安全风险，尤其是模型和数据相关问题缺乏有效解决办法。

Conclusion: AI供应链安全问题复杂且多样，尤其模型和数据安全尚无充分解决方案，需更多关注和研究。基于开发者实际反馈的信息可为安全防护提供重要指导。

Abstract: The rapid growth of Artificial Intelligence (AI) models and applications has led to an increasingly complex security landscape. Developers of AI projects must contend not only with traditional software supply chain issues but also with novel, AI-specific security threats. However, little is known about what security issues are commonly encountered and how they are resolved in practice. This gap hinders the development of effective security measures for each component of the AI supply chain. We bridge this gap by conducting an empirical investigation of developer-reported issues and solutions, based on discussions from Hugging Face and GitHub. To identify security-related discussions, we develop a pipeline that combines keyword matching with an optimal fine-tuned distilBERT classifier, which achieved the best performance in our extensive comparison of various deep learning and large language models. This pipeline produces a dataset of 312,868 security discussions, providing insights into the security reporting practices of AI applications and projects. We conduct a thematic analysis of 753 posts sampled from our dataset and uncover a fine-grained taxonomy of 32 security issues and 24 solutions across four themes: (1) System and Software, (2) External Tools and Ecosystem, (3) Model, and (4) Data. We reveal that many security issues arise from the complex dependencies and black-box nature of AI components. Notably, challenges related to Models and Data often lack concrete solutions. Our insights can offer evidence-based guidance for developers and researchers to address real-world security threats across the AI supply chain.

</details>


### [91] [An SLO Driven and Cost-Aware Autoscaling Framework for Kubernetes](https://arxiv.org/abs/2512.23415)
*Vinoth Punniyamoorthy,Bikesh Kumar,Sumit Saha,Lokesh Butra,Mayilsamy Palanigounder,Akash Kumar Agarwal,Kabilan Kannan*

Main category: cs.SE

TL;DR: 本文基于AIOps原则改进Kubernetes自动扩缩，通过多信号融合实现SLO优先和成本效益，提升系统可靠性和运营透明度。


<details>
  <summary>Details</summary>
Motivation: 当前Kubernetes自动扩缩机制存在反应迟缓、对应用层信号利用不足以及控制逻辑不透明，导致SLO违约和成本低效问题。

Method: 通过缺口分析现有自动扩缩方法，设计一种结合SLO感知、成本意识及轻量级需求预测的多信号自动扩缩框架，并在微服务和事件驱动负载下进行实验验证。

Result: 提出了一种安全且可解释的多信号自动扩缩框架，结合SLO感知和成本控制，利用轻量级需求预测，显著降低SLO违约时间，提升扩缩响应速度并节省基础设施成本。

Conclusion: AIOps驱动的SLO优先自动扩缩显著提升了Kubernetes云平台的可靠性、效率和运维可信度。

Abstract: Kubernetes provides native autoscaling mechanisms, including the Horizontal Pod Autoscaler, Vertical Pod Autoscaler, and node-level autoscalers, to enable elastic resource management for cloud-native applications. However, production environments frequently experience Service Level Objective violations and cost inefficiencies due to reactive scaling behavior, limited use of application-level signals, and opaque control logic. This paper investigates how Kubernetes autoscaling can be enhanced using AIOps principles to jointly satisfy SLO and cost constraints under diverse workload patterns without compromising safety or operational transparency. We present a gap-driven analysis of existing autoscaling approaches and propose a safe and explainable multi-signal autoscaling framework that integrates SLO-aware and cost-conscious control with lightweight demand forecasting. Experimental evaluation using representative microservice and event-driven workloads shows that the proposed approach reduces SLO violation duration by up to 31 percent, improves scaling response time by 24 percent, and lowers infrastructure cost by 18 percent compared to default and tuned Kubernetes autoscaling baselines, while maintaining stable and auditable control behavior. These results demonstrate that AIOps-driven, SLO-first autoscaling can significantly improve the reliability, efficiency, and operational trustworthiness of Kubernetes-based cloud platforms.

</details>


### [92] [Embedding Quality Assurance in project-based learning](https://arxiv.org/abs/2512.23488)
*Maria Spichkova*

Main category: cs.SE

TL;DR: 本文基于作者十多年在敏捷Scrum环境下的教学经验，分享了软件质量教学的经验教训，并推荐如何将质量保障主题嵌入项目式学习中。


<details>
  <summary>Details</summary>
Motivation: 提升学生在敏捷软件开发环境中对软件质量保障的理解和应用能力。

Method: 总结了过去十多年在软件工程课程，尤其是敏捷Scrum环境下教学软件质量方面的经验教训。

Result: 提出了若干将质量保障知识融入基于项目学习和敏捷Scrum环境的建议。

Conclusion: 通过多年的教学实践，质量保证在敏捷开发环境中的项目式学习中起着关键作用。

Abstract: In this paper, we share our lessons learned from more than a decade of teaching software quality aspects within Software Engineering (SE) courses, where the focus is on Agile/Scrum settings: final year software development projects and the course on SE Project Management. Based on the lessons learned, we also provide a number of recommendations on embedding quality assurance topics in the project-based learning with Agile/Scrum context.

</details>


### [93] [Adaptable Teastore with Energy Consumption Awareness: A Case Study](https://arxiv.org/abs/2512.23498)
*Henrique De Medeiros,Denisse Muñante,Sophie Chabridon,César Perdigão Batista,Denis Conan*

Main category: cs.SE

TL;DR: 论文提出EnCoMSAS在线监测自适应软件系统能耗，实验验证工具有效且对整体系统能耗影响较小，有助推动软件的能源感知和能效优化。


<details>
  <summary>Details</summary>
Motivation: 随着全球能源消耗不断增加，数据中心成为主要能源消耗者，云应用普及和用户增长推动能耗上升。动态自适应方法被视为减少软件运行时能耗的有效途径，但现有方法对自适应系统的能耗监测工具不足，且其对整体系统能耗影响尚不清楚。

Method: 提出EnCoMSAS工具，用于在运行时监测和评估分布式自适应系统（如云环境中应用）的能耗。通过在适应性TeaStore微服务架构中的推荐服务上实验，变换工作负载模拟用户交互，利用Grid5000测试平台采集数据，评估EnCoMSAS的效果及其对整体系统能耗的影响。

Result: EnCoMSAS能够有效采集软件应用能耗，且采集能耗与CPU使用率高度相关，验证了监测数据的有效性。研究发现能耗受算法复杂度和部署环境特性共同影响。EnCoMSAS对整体自适应系统生态能耗的影响较小。

Conclusion: EnCoMSAS是一种有效的能耗监测工具，能够支持自适应系统在运行时实现能源感知和动态优化，同时其自身对系统整体能耗影响有限，适合实际部署和应用。

Abstract: [Context and Motivation] Global energy consumption has been steadily increasing in recent years, with data centers emerging as major contributors. This growth is largely driven by the widespread migration of applications to the Cloud, alongside a rising number of users consuming digital content. Dynamic adaptation (or self-adaptive) approaches appear as a way to reduce, at runtime and under certain constraints, the energy consumption of software applications.
  [Question/Problem] Despite efforts to make energy-efficiency a primary goal in the dynamic adaptation of software applications, there is still a gap in understanding how to equip these self-adaptive software systems (SAS), which are dynamically adapted at runtime, with effective energy consumption monitoring tools that enable energy-awareness. Furthermore, the extent to which such an energy consumption monitoring tool impacts the overall energy consumption of the SAS ecosystem has not yet been thoroughly explored.
  [Methodology] To address this gap, we introduce the EnCoMSAS (Energy Consumption Monitoring for Self-Adaptive Systems) tool that allows to gather the energy consumed by distributed software applications deployed, for instance, in the Cloud. EnCoMSAS enables the evaluation of energy consumption of SAS variants at runtime. It allows to integrate energy-efficiency as a main goal in the analysis and execution of new adaptation plans for the SAS. In order to evaluate the effectiveness of EnCoMSAS and investigate its impact on the overall energy consumption of the SAS ecosystem, we conduct an empirical study by using the Adaptable TeaStore case study. Adaptable TeaStore is a self-adaptive extension of the TeaStore application, a microservice benchmarking application. For this study, we focus on the recommender service of Adaptable TeaStore. Regarding the experiments, we first equip Adaptable TeaStore with EnCoMSAS. Next, we execute Adaptable TeaStore by varying workload conditions that simulate users interactions. Finally, we use EnCoMSAS for gathering and assessing the energy consumption of the recommender algorithms of Adaptable TeaStore. To run these experiments, we use nodes of the Grid5000 testbed.
  [Results] The results show that EnCoMSAS is effective in collecting energy consumption of software applications for enabling dynamic adaptation at runtime. The observed correlation between CPU usage and energy consumption collected by EnCoMSAS provides evidence supporting the validity of the collected energy measurements. Moreover, we point out, through EnCoMSAS, that energy consumption is influenced not only by the algorithmic complexity but also by the characteristics of the deployment environment. Finally, the results show that the impact of EnCoMSAS on the overall energy consumption of the SAS ecosystem is comparatively modest with respect to the entire set of the TeaStore applications microservices.

</details>


### [94] [AdaptiFlow: An Extensible Framework for Event-Driven Autonomy in Cloud Microservices](https://arxiv.org/abs/2512.23499)
*Brice Arléon Zemtsop Ndadji,Simon Bliudze,Clément Quinton*

Main category: cs.SE

TL;DR: 本文提出了AdaptiFlow框架，利用自主计算原理，实现微服务的去中心化自适应，增强云架构的弹性和自治性。


<details>
  <summary>Details</summary>
Motivation: 现有云架构自适应方案多依赖中心化控制，难以适应微服务的分布式、去中心化特性，亟需提供兼顾自治性和系统整体适应性的解决方案。

Method: 设计了度量收集器、声明式适应动作和基于事件驱动及规则的适应逻辑机制，结合增强的TeaStore基准测试，实现了三个不同层级的自治适应场景。

Result: 通过三个自治场景的验证，AdaptiFlow不仅实现了服务的简单代码修改即能支持自治，还证明了局部决策可促进整体系统的去中心化自适应。未来计划融合形式协调模型及AI驱动的前瞻性适应技术。

Conclusion: AdaptiFlow通过监控和执行层的解耦，实现了微服务自治元素的演进，验证了去中心化适应策略的可行性，提升了系统的自愈、自保护和自优化能力。

Abstract: Modern cloud architectures demand self-adaptive capabilities to manage dynamic operational conditions. Yet, existing solutions often impose centralized control models ill-suited to microservices decentralized nature. This paper presents AdaptiFlow, a framework that leverages well-established principles of autonomous computing to provide abstraction layers focused on the Monitor and Execute phases of the MAPE-K loop. By decoupling metrics collection and action execution from adaptation logic, AdaptiFlow enables microservices to evolve into autonomous elements through standardized interfaces, preserving their architectural independence while enabling system-wide adaptability. The framework introduces: (1) Metrics Collectors for unified infrastructure/business metric gathering, (2) Adaptation Actions as declarative actuators for runtime adjustments, and (3) a lightweight Event-Driven and rule-based mechanism for adaptation logic specification. Validation through the enhanced Adaptable TeaStore benchmark demonstrates practical implementation of three adaptation scenarios targeting three levels of autonomy self-healing (database recovery), self-protection (DDoS mitigation), and self-optimization (traffic management) with minimal code modification per service. Key innovations include a workflow for service instrumentation and evidence that decentralized adaptation can emerge from localized decisions without global coordination. The work bridges autonomic computing theory with cloud-native practice, providing both a conceptual framework and concrete tools for building resilient distributed systems. Future work includes integration with formal coordination models and application of adaptation techniques relying on AI agents for proactive adaptation to address complex adaptation scenarios.

</details>


### [95] [Beyond Correctness: Exposing LLM-generated Logical Flaws in Reasoning via Multi-step Automated Theorem Proving](https://arxiv.org/abs/2512.23511)
*Xinyi Zheng,Ningke Li,Xiaokun Luan,Kailong Wang,Ling Shi,Meng Sun,Haoyu Wang*

Main category: cs.SE

TL;DR: 本文提出MATP框架，通过自动定理证明验证LLM多步推理逻辑，有效发现复杂错误，显著优于现有方法，提升了推理的可信度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理能力上表现出色，但其推理过程常包含被流畅语言掩盖的细微逻辑错误，尤其在医疗、法律和科学研究等关键领域存在较大风险。现有的方法部分解决此类问题但无法有效检测复杂多步推理中的逻辑缺陷。

Method: 提出了MATP框架，通过将自然语言推理转换为一阶逻辑（FOL），利用自动定理证明器逐步验证逻辑有效性，从而系统地检查和分类推理的正确性。

Result: 在包含10,830条由10个LLM生成的推理实例的基准测试中，MATP在推理步骤验证上超越了基于提示的基线方法42个百分点以上，且揭示了不同模型的逻辑一致性差异，推理模型比通用模型生成的推理逻辑更连贯。

Conclusion: MATP有效提升了LLM推理的可信度，能够检测隐藏的逻辑错误，推动了多步自动定理证明在LLM推理验证中的应用前景。

Abstract: Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, leading to their adoption in high-stakes domains such as healthcare, law, and scientific research. However, their reasoning often contains subtle logical errors masked by fluent language, posing significant risks for critical applications. While existing approaches like fact-checking, self-consistency methods, and rule-based validation provide partial solutions, they fail to detect complex logical flaws in multi-step reasoning.
  To overcome these challenges, we present MATP, an evaluation framework for systematically verifying LLM reasoning via Multi-step Automatic Theorem Proving. MATP translates natural language reasoning into First-Order Logic (FOL) and applies automated theorem provers to assess step-by-step logical validity. This approach identifies hidden logical errors and provides fine-grained classifications of reasoning correctness. Evaluations on a benchmark comprising 10,830 reasoning instances generated by 10 LLMs across tasks from PrOntoQA-OOD, ProofWriter, and FOLIO show that MATP surpasses prompting-based baselines by over 42 percentage points in reasoning step verification. It further reveals model-level disparities, with reasoning models generating more logically coherent outputs than general models. These results demonstrate MATP's potential to enhance the trustworthiness of LLM-generated reasoning.

</details>


### [96] [Model-based Development for Autonomous Driving Software Considering Parallelization](https://arxiv.org/abs/2512.23575)
*Kenshin Obi,Takumi Onozawa,Hiroshi Fujimoto,Takuya Azumi*

Main category: cs.SE

TL;DR: 本论文提出了一种基于模型驱动开发的自动驾驶软件并行化方法，有效提升了实时性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶软件需要满足实时性能要求，但功能复杂且环境多变，传统单线程处理难以满足需求。

Method: 扩展现有的基于模型的并行化方法（MBP），利用模型驱动开发（MBD）过程实现自动驾驶软件的并行化。

Result: 通过并行化方法，显著减少了执行时间，提升了软件的实时性能。

Conclusion: 所提方法验证了其在自动驾驶软件开发中的适用性，尤其在实现软件的实时性能方面表现良好。

Abstract: In recent years, autonomous vehicles have attracted attention as one of the solutions to various social problems. However, autonomous driving software requires real-time performance as it considers a variety of functions and complex environments. Therefore, this paper proposes a parallelization method for autonomous driving software using the Model-Based Development (MBD) process. The proposed method extends the existing Model-Based Parallelizer (MBP) method to facilitate the implementation of complex processing. As a result, execution time was reduced. The evaluation results demonstrate that the proposed method is suitable for the development of autonomous driving software, particularly in achieving real-time performance.

</details>


### [97] [Parallelized Code Generation from Simulink Models for Event-driven and Timer-driven ROS 2 Nodes](https://arxiv.org/abs/2512.23605)
*Kenshin Obi,Ryo Yoshinaka,Hiroshi Fujimoto,Takuya Azumi*

Main category: cs.SE

TL;DR: 本文提出一种针对ROS 2多输入模型的基于模型开发并行化框架，显著降低了执行时间，提升了自动驾驶嵌入式系统的开发效率和性能。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统复杂度和规模显著增加，特别是在自动驾驶系统领域，传统手动程序并行化面临数据完整性维护和避免死锁等并发问题的挑战，同时，基于模型的开发在多输入情况下整合现代框架（如ROS 2）存在困难。

Method: 提出一种基于模型的开发(MBD)框架，针对ROS 2兼容的Simulink模型进行事件驱动和计时驱动分类，实现针对性并行化，支持ROS 2多输入模型的并行代码生成。

Result: 该框架扩展了传统MBD的并行化方法，支持多输入ROS 2模型的并行代码生成，评估结果显示所有测试模式执行时间均有所减少，验证了并行化的有效性。

Conclusion: 通过该MBD框架实现的并行化有效提高了基于ROS 2的多输入嵌入式系统模型的执行效率，解决了传统手动并行化中的多种问题。

Abstract: In recent years, the complexity and scale of embedded systems, especially in the rapidly developing field of autonomous driving systems, have increased significantly. This has led to the adoption of software and hardware approaches such as Robot Operating System (ROS) 2 and multi-core processors. Traditional manual program parallelization faces challenges, including maintaining data integrity and avoiding concurrency issues such as deadlocks. While model-based development (MBD) automates this process, it encounters difficulties with the integration of modern frameworks such as ROS 2 in multi-input scenarios. This paper proposes an MBD framework to overcome these issues, categorizing ROS 2-compatible Simulink models into event-driven and timer-driven types for targeted parallelization. As a result, it extends the conventional parallelization by MBD and supports parallelized code generation for ROS 2-based models with multiple inputs. The evaluation results show that after applying parallelization with the proposed framework, all patterns show a reduction in execution time, confirming the effectiveness of parallelization.

</details>
