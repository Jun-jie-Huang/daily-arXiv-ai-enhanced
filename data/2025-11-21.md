<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning](https://arxiv.org/abs/2511.15886)
*Jeremias Ferrao,Ezgi Basar,Khondoker Ittehadul Islam,Mahrokh Hassani*

Main category: cs.CL

TL;DR: 本文研究了多语言大模型中CoT推理的归因特点，发现其多语言性能和解释性存在不足，尤其对非高资源语言的支持有限。


<details>
  <summary>Details</summary>
Motivation: 探讨多语言大语言模型(LLM)中Chain-of-Thought(CoT)推理的归因模式，特别是关注生成推理链的真实性和可解释性。

Method: 采用两种补充性的归因方法——ContextCite（步骤级归因）和Inseq（token级归因），在Qwen2.5 1.5B-Instruct模型和MGSM基准上进行实验分析。

Result: 发现归因分数过度强调最终推理步骤，尤其在错误生成中更明显；结构化CoT提示显著提升高资源拉丁文语言的准确率；通过否定和干扰句子的受控扰动会降低模型准确性和归因的一致性。

Conclusion: CoT提示在多语言环境下存在局限性，特别是在多语言的鲁棒性和解释透明度方面表现不足。

Abstract: This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.

</details>


### [2] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 该论文提出了Motion2Mind框架，旨在评估机器对非言语线索解读他人心智状态的能力，建立了包含丰富非言语线索注释和心理解释的视频数据集。实验表明现有AI系统在非言语线索解读方面表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前心智理论测试主要围绕错误信念和非对称信息，缺乏对于其他心理状态和非言语沟通的全面考察，亟需建立评估机器解读非言语线索能力的框架。

Method: 构建基于专家编制肢体语言参考的Motion2Mind视频数据集，注释222种非言语线索和397种心理状态，通过该数据集评估机器的心智理论能力。

Result: Motion2Mind实验显示AI在非言语线索的检测和解释上均表现不佳，存在性能差距及过度解释现象。

Conclusion: 现有AI系统在理解和解释非言语线索方面存在显著不足，远不能达到人类水平。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [3] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出基于复杂过程指令的TOD-ProcBench基准，通过三项任务全面评测大型语言模型在多轮任务型对话中理解、执行复杂且细粒度约束指令的能力，填补现有基准简单化指令的不足。


<details>
  <summary>Details</summary>
Motivation: 当前任务导向对话评测多将复杂指令简化为意图、槽位、API调用配置，无法充分评估大型语言模型遵循复杂多步骤指令的能力，需构建一个挑战性且细粒度约束的基准以系统测评模型执行复杂任务对话指令的能力。

Method: 提出TOD-ProcBench基准，利用多层次条件-动作指令表述复杂步骤指令，设计三项任务评测大型语言模型在多轮任务对话中遵循复杂指令的能力。任务包括相关指令检索和动作预测、识别违背指令的对话回复、基于复杂指令条件生成回复，同时研究多语言环境和指令文本格式对性能的影响。

Result: 构建包含来源于高质量ABCD数据集的指令文档与对应对话数据的基准数据集；设计三项任务围绕复杂指令理解与执行进行系统评测；并通过多语言及文本格式实验验证模型遵循指令的表现差异。

Conclusion: TOD-ProcBench为评估大型语言模型遵循复杂多步骤指令提供了系统框架和挑战性测试，展现了模型在检索相关指令、识别违规回复及条件生成回复的能力，推动多语言环境下任务导向对话系统的研究发展。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [4] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文引入了LIARS' BENCH测试平台，包含大量真实与谎言示例，以评估和推进大型语言模型谎言检测技术。


<details>
  <summary>Details</summary>
Motivation: 以往谎言检测方法验证环境有限，不能全面捕捉语言模型产生多样化谎言的情况，亟需更具代表性和复杂度的测试平台。

Method: 构建包含72863个样本的LIARS' BENCH数据集，涵盖不同谎言类型和模型说谎动机，并对三种黑盒与白盒检测方法进行系统性评估。

Result: 评估显示现有检测方法难以有效识别某些谎言类型，特别是在无法仅凭转录文本判断谎言的情况下表现实较差。LIARS' BENCH揭示了这些局限性并推动检测技术进步。

Conclusion: 现有谎言检测技术在多样化谎言识别上存在系统性不足，尤其是无法仅通过对话文本判断的情境。LIARS' BENCH为谎言检测提供了更全面的测评环境。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [5] [Learning Tractable Distributions Of Language Model Continuations](https://arxiv.org/abs/2511.16054)
*Gwen Yidou-Weng,Ian Li,Anji Liu,Oliver Broadrick,Guy Van den Broeck,Benjie Wang*

Main category: cs.CL

TL;DR: 提出LTLA方法结合语言模型和HMM，实现高效上下文感知的受控语言生成，提升约束满足度和生成质量。


<details>
  <summary>Details</summary>
Motivation: 控制语言生成时，序列级别的约束（如语法、风格、安全性）依赖未来的词元，使用自回归语言模型直接建模困难。现有方法使用隐马尔可夫模型（HMM）等近似模型，但这些模型缺乏上下文感知，导致查询质量下降。

Method: 提出了Learning to Look Ahead (LTLA)方法，将基础语言模型的丰富前缀编码与固定的可解模型（HMM）结合，通过批量一次性更新HMM以覆盖所有候选词元，并使HMM的隐状态条件仅依赖LM的隐藏表示，避免重复计算，提升效率。

Result: LTLA实现了比无条件HMM更高的条件似然度，能够近似视觉语言模型的续写分布，提升受控生成任务中的约束满足度与语言流畅度，且推理开销极低。

Conclusion: LTLA有效结合了神经语言模型的上下文感知能力与HMM的可解性，克服了先前方法的计算瓶颈和上下文缺失问题，显著提升控制生成质量和效率。

Abstract: Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.

</details>


### [6] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 本文以多个案例展示GPT-5在科学研究中的应用，证明其在加速科研和解决复杂问题上的巨大潜力，但仍需人类专家辅助。


<details>
  <summary>Details</summary>
Motivation: 许多科学家尚未充分认识前沿AI（如GPT-5）的潜力和能力，因此希望通过实际案例展示AI如何助力科研。

Method: 通过展示多个跨学科的简短案例研究，记录人类作者与GPT-5的互动过程，验证其在研究中的具体应用效果。

Result: 论文呈现了GPT-5在数学、物理、天文学、计算机科学、生物学和材料科学中的应用实例，特别包括四个经过严格人类验证的新数学成果。

Conclusion: GPT-5能够显著加速科学研究过程，尤其在数学领域帮助解决了之前未解决的问题，但仍需人类专家的参与和验证。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [7] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出ELPO，通过集成学习提升自动提示优化效果，在多任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法通常依赖单一模型或算法，限制了其在复杂任务中的性能表现。

Method: 提出了一种基于集成学习的自动提示优化框架（ELPO），结合投票机制、共享生成策略和多样化搜索方法优化提示词生成过程。

Result: ELPO在多个任务中表现优于现有先进方法，如在ArSarcasm数据集上F1分数提升7.6。

Conclusion: 基于集成学习的ELPO框架能够生成更精确、鲁棒的提示，促进大语言模型提示工程的自动化和实用化。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [8] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 本文提出了选择性位置索引的PEFT（TS-PEFT），证实有针对性的微调优于传统对所有位置索引微调的方法。


<details>
  <summary>Details</summary>
Motivation: 质疑传统PEFT对所有位置索引一视同仁的调整是否必要，寻求更高效的微调方案。

Method: 提出了Token-Selective PEFT（TS-PEFT）方法，通过函数S选择性地在部分位置索引上应用PEFT修改。

Result: 实验证明，选择性应用PEFT修改在下游任务中表现更好，全面调整反而多余且可能降低性能。

Conclusion: 传统PEFT方法对所有位置索引应用调整是不必要且可能有害的，选择性应用PEFT修改更有利于性能提升。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [9] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: 本文介绍了SemanticCite，一种基于AI的引用验证系统，通过全文分析和四类分类机制，实现对引用准确性的高效验证和解释，支持大规模应用并开源相关资源。


<details>
  <summary>Details</summary>
Motivation: 当前学术文献存在语义性引用错误、AI生成的虚假引用及传统引用格式模糊具体关联等问题，严重影响科研诚信和学术交流的准确性，亟需一种高效且可扩展的引用验证系统。

Method: 采用基于轻量级语言模型的多重检索与四分类系统（支持、部分支持、不支持、不确定），结合详细语义注释和文本片段，实现对引用的准确验证和错误分类。

Result: 本文提出了一种名为SemanticCite的AI驱动系统，通过全文分析源文献验证引用的准确性，并提供详细的上下文信息和相关文本片段。该系统结合多种检索方法和四类分类机制（支持、部分支持、不支持、不确定），准确捕捉文献与论断之间的关系，并能针对不同的错误类型采取相应措施。实验证明，经过微调的轻量级语言模型在性能上可媲美大型商业系统，且计算资源消耗显著降低，适合大规模应用。此外，系统提供透明且基于证据的解释，增强用户的信任和理解。作者还贡献了包含1000多个引用的综合数据集，以及微调模型和完整验证框架的开源软件。该系统有效提升了学术引用的准确性，有助于促进研究诚信、简化同行评审及控制AI生成内容的质量。

Conclusion: SemanticCite有效解决了学术引用中的语义错误和AI虚假引用问题，实现了准确、透明且可扩展的引用验证，提升了科研诚信和质量控制水平。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [10] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了基于语义结构熵的语言模型不确定性量化方法SeSE，通过捕获语义结构信息，实现了更精确的幻觉检测，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLMs）不确定性量化（UQ）方法主要依赖于语义概率分布或成对距离，忽略了潜在的语义结构信息，导致无法准确估计不确定性，难以有效防止生成幻觉内容。

Method: 提出了语义结构熵（SeSE）框架，通过构建自适应稀疏的有向语义图捕获方向性语义依赖，并通过层次化抽象定义最优语义编码树的结构熵来量化语义空间中的内在不确定性。SeSE的值越高表示不确定性越大，能够有效检测幻觉。此外，SeSE扩展到对长文本生成中个别陈述的不确定性进行细粒度量化，理论上解释幻觉检测。

Result: 在29个模型-数据集组合的广泛实验中，SeSE显著优于先进的不确定性量化基线方法，包括强监督方法和最新的KLE方法。

Conclusion: SeSE通过引入潜在语义结构信息，实现了更准确的语言模型不确定性量化，为防止语言模型在安全关键场景中生成幻觉提供了有效工具。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [11] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 本文提出一种无需训练的模型对齐方法SDA，通过动态概率调整实现开源大语言模型行为与人类意图的有效对齐，显著提升模型的实用性、诚实性和安全性，且兼容性和资源效率均优。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在实际应用中的广泛部署，确保其输出响应符合人类意图变得关键，尤其是在无需昂贵再训练或大量监督的情况下高效实现模型行为对齐是一大挑战。

Method: 提出了一种名为SDA（Steering-Driven Distribution Alignment）的训练免费且模型无关的对齐框架，通过动态重新分配模型输出概率来实现用户定义的对齐指令。该方法轻量级、资源效率高，可在推理阶段独立运行或与基于训练的对齐策略结合使用，并支持个性化偏好对齐。

Result: 在八种不同规模和来源的开源LLMs上进行评估，SDA在三个关键对齐维度——有用性（helpfulness）、诚实性（honesty）和无害性（harmlessness）上均显著提升表现，平均分别提升64.4%、30%和11.5%。

Conclusion: SDA作为一种轻量且高效的训练免费对齐框架，成功解决了大语言模型推理阶段行为对齐的难题，具备广泛的适用性和个性化控制能力，为实际部署中LLMs的安全和实用提供了有效工具。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [12] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本论文提出通过模型自我重写推理文本的方法，改善推理质量，提升准确率并缩短推理长度，有效优化了推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习仅以最终正确性奖励为目标，缺乏对内部推理过程的细致监督，导致推理质量不理想，存在多种推理缺陷，亟需改进内部推理监督机制。

Method: 设计了选择性重写策略，仅对模型推理结果一致正确的 "简单" 样本进行重写，同时在一个批次内融合重写与原始生成，保证算法可扩展性，仅带来约10%的计算开销。

Result: 通过引入自我重写框架，模型能够对自身的推理文本进行重写，并利用重写后的推理进行学习，从而提高内部推理过程的质量。该方法在保证强化学习奖励信号的前提下，选择性地对 "简单" 样本进行重写，实现了推理准确率的提升和推理长度的显著缩短，同时有效减少了推理过程中的过度思考、欠思考、冗余思考和无序思考等问题。

Conclusion: 自我重写方法显著提升了内部推理质量和任务表现，减少了无效和混乱推理，且在多个任务及不同模型规模上均表现优异。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [13] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文针对大型语言模型难以准确处理习语和比喻语言的问题，构建了一个大规模的习语和比喻语言数据集，并通过该数据集评估了预训练模型在识别习语的能力。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻语言在口语和写作中广泛出现，尤其是在社交媒体上增加了观察和训练的机会，但大型语言模型在理解这类语言时仍存在不足，需通过更大的数据集提升模型表现。

Method: 整合多个现有习语和比喻语言数据集，提取习语列表，从大规模语料中检索上下文序列，构建包含潜在和确定习语表达的数据集，并进行后期处理以适配不同模型进行训练和评估。

Result: 构建了一个大型潜在习语和比喻语言表达数据集及两个人工注释验证数据集，成功用于基线模型在习语识别的插槽标注和序列标注任务的训练与评估。

Conclusion: 通过新构建的大规模包含潜在习语和两个人工注释的确切习语数据集，验证了微调方法的有效性，提升了语言模型对习语识别任务的表现。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [14] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 本文探讨了理据信息对模型性能影响的复杂性，指出充分性指标的局限性，并分析了将理据信息融入模型的效果，强调需进一步研究更可靠的理据评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的充分性指标用于评估自然语言理据的信息量，但对理据信息影响模型性能的作用洞察有限。

Method: 将充分性指标与两种建模范式关联：通过标注理据相关的词元进行标注分类，以及通过注意力正则化将理据信息融入输入中，观察其对模型性能的影响。

Result: 发现高信息量的理据未必有助于正确分类；充分性指标反映了非理据上下文对分类的影响，且与词元分类无关。融入理据信息可以提升跨领域分类，但效果依任务和模型而异。

Conclusion: 理据的作用复杂，现有指标难以全面捕捉理据信息，亟需开发更有效的评估指标。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [15] [AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser](https://arxiv.org/abs/2511.16397)
*Ren Ma,Jiantao Qiu,Chao Xu,Pei Chu,Kaiwen Liu,Pengli Ren,Yuan Qu,Jiahui Peng,Linfeng Hou,Mengjie Liu,Lindong Lu,Wenchang Ning,Jia Yu,Rui Min,Jin Shi,Haojiong Chen,Peng Zhang,Wenjian Zhang,Qian Jiang,Zengjie Hu,Guoqiang Yang,Zhenxiang Li,Fukai Shang,Zhongying Tu,Wentao Zhang,Dahua Lin,Conghui He*

Main category: cs.CL

TL;DR: 通过将HTML内容提取任务建模为序列标注问题，提出了基于语言模型的MinerU-HTML方法，实现了比传统启发式提取方法更准确的结构化内容保留，提升了网页数据质量，进而提升大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有网页数据清理多集中于过滤和去重，忽视了HTML到文本的提取步骤，而现有基于启发式的网页文本提取工具难以保留文档结构，容易破坏公式、代码、表格等结构化元素，影响大型语言模型的下游性能。

Method: 本研究提出MinerU-HTML作为内容提取流水线，利用6亿参数语言模型进行序列标注，结合语义理解与两阶段格式化转为Markdown，替代传统启发式文本密度方法，实现结构化网页元素的高保真提取。

Result: MinerU-HTML在MainWebBench（7,887个网页标注数据集）上达到了81.8%的ROUGE-N F1分数，显著优于Trafilatura的63.6%，并在结构化元素保留上表现优异（代码块90.9%，公式94.0%）。使用MinerU-HTML构建了7.3万亿token的多语言AICC语料库，训练的模型在13个基准测试中平均准确率提升了1.08个百分点，表明提取质量对模型能力有显著影响。

Conclusion: HTML提取质量是网页语料构建中关键且经常被低估的环节。高质量的内容提取可以显著提升下游大语言模型的性能。

Abstract: While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\% ROUGE-N F1 compared to Trafilatura's 63.6\%, with exceptional structured element preservation (90.9\% for code blocks, 94.0\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.

</details>


### [16] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究使用监督学习和深度学习模型，基于超过140万篇新闻文章的数据，成功区分了被感知为低质量和高质量的新闻。


<details>
  <summary>Details</summary>
Motivation: 探究机器学习和深度学习模型是否能够有效辨别新闻文章的质量，以提升新闻质量评估的自动化水平。

Method: 利用3种传统机器学习分类器和3种深度学习模型，基于579个新闻网站的专家评定（分为高低质量两类），对1,412,272篇英文新闻文章进行分类，使用194个语言特征。

Result: 传统机器学习中的随机森林表现良好（准确率0.7355，ROC AUC 0.8131），而深度学习模型中ModernBERT-large取得最佳效果（准确率0.8744，ROC AUC 0.9593，F1值0.8739）。

Conclusion: 机器学习和深度学习方法均能有效区分世界范围内新闻文章的感知质量，其中深度学习模型表现更优。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [17] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 本文提出了ESGBench基准，用以评估基于企业可持续报告的可解释ESG问答系统，并分析了现有大型语言模型的表现及其面临的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有ESG问答系统缺乏透明度和可解释性，且缺少标准化评估基准，促使提出ESGBench以促进该领域公平、细致的模型表现评估。

Method: 构建包含多主题ESG领域问题、人工策划答案及支持证据的数据集，并基于此设计细粒度评估框架，对先进大型语言模型进行性能测试。

Result: 本文提出了ESGBench，一个用于评估基于企业可持续发展报告的可解释ESG问答系统的基准数据集和评估框架。该基准包含跨多个ESG主题的领域相关问题，配备人工策划的答案和支持证据，以实现模型推理的细粒度评估。通过分析最先进的大型语言模型(LLMs)在ESGBench上的表现，揭示了事实一致性、可追溯性和领域对齐方面的关键挑战。ESGBench旨在促进透明且负责任的ESG AI系统的研究进展。

Conclusion: ESGBench为评估和推动可解释且负责任的ESG问答系统研究提供了标准化的数据集和框架，揭示了当前模型在事实一致性和领域对齐方面的不足。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [18] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文通过电路发现技术揭示了变换器在处理惯用语时的独特计算模式，发现了专门的注意力头和增强词元间注意力机制，促进理解非组合语言处理。


<details>
  <summary>Details</summary>
Motivation: 探索变换器如何处理非组合性语言（如惯用语），揭示其计算机制及效率与鲁棒性的平衡。

Method: 使用改进的路径拼接算法进行电路发现和分析，研究变换器语言模型中惯用语处理的计算模式。

Result: 发现了"惯用语头"—在不同惯用语中频繁激活的注意力头，以及"增强接收"现象，即惯用语词元间增强的注意力，揭示了变换器处理中惯用语的特殊机制。

Conclusion: 变换器通过特定的注意力头和增强的词元间注意力机制实现对惯用语的高效与鲁棒处理，为理解更复杂语法结构的处理提供了新路径。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [19] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract是一款轻量级且性能优越的文档结构化数据提取模型，适合资源有限设备部署。


<details>
  <summary>Details</summary>
Motivation: 提高结构化数据提取模型在资源受限设备上的部署灵活性，同时保证处理长文档的能力和准确性。

Method: 通过设计轻量级模型结构和优化训练协议，实现高效文档结构化数据提取。

Result: Arctic-Extract是一款先进的结构化数据提取模型，能够处理扫描件或数字文档中的问答、实体和表格数据。该模型体积仅6.6 GiB，适合资源受限硬件设备（如拥有24 GB显存的A10 GPU）部署，可处理最多125页A4文档，支持长文档解析。本文介绍了其训练方案与评估结果，验证了其在文档理解上的优异表现。

Conclusion: Arctic-Extract表现出强大的文档结构数据提取能力，且适合在资源有限的硬件上高效运行。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [20] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 本文首次系统评估了针对土耳其语检索的密集编码器与后期交互模型，提出TurkColBERT基准。其模型在参数效率和性能上表现优异，尤其是轻量级后期交互模型ColmmBERT-base-TR在领域任务中提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前神经信息检索系统多聚焦高资源语言，缺少对形态丰富且资源较少语言如土耳其语的系统性评估，特别是后期交互模型未被充分研究。

Method: 采用两阶段适配流程，先在土耳其语NLI/STS任务上微调英文和多语编码器，再用PyLate基于MS MARCO-TR将其转换为ColBERT风格检索器。比较了10个模型在五个土耳其语BEIR数据集上的表现。

Result: Colbert-hash-nano-tr模型参数仅为大型密集编码器的1/600，保持了71%以上的性能；后期交互模型体积更小，性能提升最高达13.8%；MUVERA+Rerank索引算法速度提升3.33倍，并带来1.7%的mAP增益；ColmmBERT-base-TR实现了0.54毫秒的查询时延。

Conclusion: 轻量级的后期交互模型显著优于密集编码器，且参数效率高，适合土耳其语信息检索；MUVERA+Rerank索引算法提高了检索速度和效果。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [21] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 本文首次展示通过分析大语言模型激活，使用浅层分类模型预测文本体裁的可行性，效果显著。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型结构难以解释且难以对所有输出进行人工评估，亟需一个能够基于模型内部信息预测文本属性的框架。

Method: 利用Mistral-7B大语言模型及两个数据集，通过scikit-learn分类器基于模型激活预测文本的体裁。

Result: 在两个数据集上，成功使用浅层学习模型预测文本体裁，F1分数最高达98%和71%，且表现优于控制任务。

Conclusion: 文本体裁可从大语言模型激活中有效推断，验证了此预测框架的概念，推动了对LLM可解释性和安全性的研究。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [22] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 传统ASR评估指标难以反映误差的临床安全风险，本文通过专家标注和优化语言模型实现了自动化、准确的临床风险评估框架，提升了ASR在临床对话中的安全评估能力。


<details>
  <summary>Details</summary>
Motivation: 传统ASR评估指标如词错误率（WER）与实际临床转录错误的影响相关性较差，无法有效反映转录错误在临床对话中的安全风险。

Method: 建立专家临床医师标注的临床影响评价基准，比较ASR生成的转录与人工转录的差异；引入经过GEPA优化的大型语言模型评审者(LLM-as-a-Judge)来自动评估临床风险。

Result: 发现WER及多种常用指标与临床风险等级（无影响、最小影响、显著影响）相关性较弱；开发的优化后大型语言模型评审者在临床风险判定上达到90%准确率和0.816的Cohen's κ，表现接近人工评审。

Conclusion: 本文提出了一种基于专家标注和大型语言模型优化的自动化临床风险评估框架，实现了比WER更有效的评估方法，为ASR临床应用中的安全性评估提供了可扩展且可靠的工具。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [23] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 本文提出了一种无需手工标注训练数据，利用统计语言模型作为判别工具，结合符号自然语言理解系统和大型语言模型来实现词义消歧的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有词义消歧方法主要针对粗粒度表示且依赖手工标注数据，难以支持基于更丰富表示（如OpenCyc）的消歧，限制了复杂推理能力的发展。

Method: 将符号自然语言理解系统生成的多个候选词义转换为可区分的自然语言替代选项，利用大型语言模型在上下文中对这些选项进行查询选择合适的词义，再将选择结果反馈回符号系统。

Result: 实验结果表明，所提方法在无需手工标注的前提下，能够有效地选择符合语境的词义，且效果接近人工标注答案。

Conclusion: 该方法能够有效地在无需手工标注的情况下，利用大型语言模型辅助符号自然语言理解系统，实现更丰富语义表示的词义消歧，并在与人工标注的答案对比中表现出良好效果。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [24] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文比较了基于文本摘要和直接多模态向量嵌入两种多模态检索增强生成（RAG）方法，发现直接多模态嵌入检索在金融文档问答任务上表现显著优越。


<details>
  <summary>Details</summary>
Motivation: 现有多模态RAG系统通过将图像转换为文本嵌入，导致关键信息丢失，难以充分利用视觉细节。

Method: 本文构建了包含图像和文本的金融财报问答基准，对两种检索策略（文本摘要检索和直接多模态嵌入检索）进行了综合评估。

Result: 直接多模态嵌入检索在mAP@5和nDCG@5指标上分别提升了13%和11%（相对提升32%和20%），且答案更准确且事实一致。

Conclusion: 直接多模态嵌入检索方法相比基于LLM摘要的文本检索，显著提升了检索准确率和回答的事实一致性，有效避免了视觉信息的损失。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


### [25] [Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs](https://arxiv.org/abs/2511.16664)
*Ali Taghibakhshi,Sharath Turuvekere Sreenivas,Saurav Muralidharan,Ruisi Cai,Marcin Chochowski,Ameya Sunil Mahabaleshwarkar,Yoshi Suhara,Oluwatobi Olabiyi,Daniel Korzekwa,Mostofa Patwary,Mohammad Shoeybi,Jan Kautz,Bryan Catanzaro,Ashwath Aithal,Nima Tajbakhsh,Pavlo Molchanov*

Main category: cs.CL

TL;DR: Nemotron Elastic通过权重共享和多阶段训练，在单模型内同时支持多子模型规模，极大降低多规模大语言模型训练和部署成本，达成高准确率与低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型训练成本极高，针对不同规模和部署需求需重复训练，造成资源浪费。需要一种优化多规模模型训练和部署的方法以降低成本和提升效率。

Method: 提出Nemotron Elastic框架，采用混合Mamba-Attention架构和多阶段训练流程，配合端到端训练的路由器，利用权重共享和知识蒸馏，实现零训练提取多子模型。此外引入了群组感知SSM弹性化、异构MLP弹性化、基于归一化均方误差的层重要性估计和多预算优化。

Result: 在Nemotron Nano V2 12B模型上，实现了9B和6B子模型的同时训练，仅用1100亿训练tokens，训练成本相较于从零训练同类模型家族降低360倍，相较于最先进压缩方法降低7倍，多个子模型在准确率上达到或优于现有最优水平，且部署内存恒定。

Conclusion: Nemotron Elastic框架通过在单一父模型中嵌入多个适应不同部署需求的子模型，实现了多模型规模训练的成本大幅降低，同时保证了模型推理能力和准确性。

Abstract: Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [26] [Technique to Baseline QE Artefact Generation Aligned to Quality Metrics](https://arxiv.org/abs/2511.15733)
*Eitan Farchi,Kiran Nayak,Papia Ghosh Majumdar,Saritha Route*

Main category: cs.SE

TL;DR: 本文提出了一种基于大语言模型的质量工程（QE）工件生成与评估方法，通过反向生成和迭代优化，提升工件的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型生成的质量工程工件质量参差不齐，亟需一种量化指标和系统化技术保障输出质量。

Method: 结合大语言模型驱动生成、反向生成和基于评分标准（清晰度、完整性、一致性和可测试性）的迭代细化方法。

Result: 12个项目实验证明，反向生成工件在提升低质量输入效果及保持高输入质量方面表现优异。

Conclusion: 反向生成的QE工件能够超越低质量输入，并在高质量输入时保持高标准，实现了QE工件的可扩展和可靠验证。

Abstract: Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.

</details>


### [27] [Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym](https://arxiv.org/abs/2511.15757)
*Kareem Shehada,Yifan Wu,Wyatt D. Feng,Adithya Iyer,Gryphon Kumfert,Yangruibo Ding,Zhiyun Qian*

Main category: cs.SE

TL;DR: 该文提出了适用于Linux内核的轻量级APR框架RGym和一个基于定位技术的高效修复流水线，实现了较高的修复成功率和低成本，推动了内核空间APR研究。


<details>
  <summary>Details</summary>
Motivation: 当前的自动程序修复（APR）基准测试主要集中在用户空间应用，忽视了内核空间的调试和修复难题。Linux内核因其单体结构、并发性和底层硬件交互的复杂性，使得APR更加困难。现有方法成功率低且依赖昂贵复杂的硬件和云基础设施。

Method: 设计了RGym评估框架，构建了一个APR流水线，采用调用栈和责备提交等定位方法，结合GPT-5 Thinking技术进行程序修复，并通过反馈机制实现多次重试提高修复率。

Result: 提出了RGym，一个轻量级、平台无关的Linux内核APR评估框架，能在本地普通硬件上运行。基于RGym，设计了一个简单有效的APR流水线，利用调用栈和有问题的提交等定位技术，避免使用不切实际的oracle。测试143个已验证的内核漏洞，实现了最高43.36%的修复通过率，且成本低于每个漏洞0.20美元。

Conclusion: 基于RGym的APR方法在Linux内核程序修复中表现出较高的成功率和低成本优势。定位策略、提示结构和模型选择对性能有重要影响，且基于反馈的重试机制能显著提高成功率。

Abstract: Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.

</details>


### [28] [A Causal Perspective on Measuring, Explaining and Mitigating Smells in \llm-Generated Code](https://arxiv.org/abs/2511.15817)
*Alejandro Velasco,Daniel Rodriguez-Cardenas,Dipin Khati,David N. Palacio,Luftar Rahman Alif,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 本文通过概率指标PSC分析大型语言模型生成代码中的代码异味，揭示影响因素并提出缓解策略，验证了PSC在辅助代码质量评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程中的应用日益广泛，但生成代码常含有影响可读性和维护性的代码异味，尚缺乏对异味产生机理的深入理解。

Method: 基于概率指标Propensity Smelly Score(PSC)系统测量LLM生成代码的代码异味倾向，利用PSC进行因果分析，研究生成策略、模型规模、架构及提示设计对代码结构质量的影响。

Result: 发现提示设计和模型架构对代码异味倾向有决定性影响，提出了有效的减缓异味产生的策略，且通过用户研究证明PSC有助于开发者理解模型行为和评估代码质量。

Conclusion: PSC作为结构质量的指标，可融入LLM代码生成的评估与部署过程，支持提升生成代码的质量，促进人机协作判断代码质量的能力。

Abstract: Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.
  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.

</details>


### [29] [AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises](https://arxiv.org/abs/2511.15852)
*Monu Sharma*

Main category: cs.SE

TL;DR: 该论文提出了一种基于AI的事件驱动编排框架，集成于Workday ERP中，用于智能同步分布式医疗机构的财务与供应链流程，提升流程效率和决策准确性。


<details>
  <summary>Details</summary>
Motivation: 传统ERP系统的工作流逻辑缺乏适应医疗环境事件驱动和数据密集特性的能力，亟需引入智能机制提升系统适应性和效率。

Method: 利用机器学习触发器、异常检测和流程挖掘分析，自动响应库存不足、支付延迟和患者需求波动等运营事件，实现跨组织流程智能同步。

Result: 多组织案例分析表明，该框架显著提升了流程效率、成本透明度和决策准确性。

Conclusion: 将AI嵌入Workday事件驱动架构显著增强了运营弹性、治理和可扩展性，为医疗企业下一代自动化策略提供了参考。

Abstract: The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.
  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.
  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.

</details>


### [30] [RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems](https://arxiv.org/abs/2511.15859)
*Hina Saeeda,Mazen Mohamad,Eric Knauss,Jennifer Horkoff,Ali Nouri*

Main category: cs.SE

TL;DR: 研究通过访谈分析自动驾驶AI感知系统的数据标注需求，发现主要挑战与改进方法，提出实证指导以提高标注质量和系统可靠性，助力AI系统安全发展。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的AI感知系统对高质量数据标注需求迫切，但标注需求的制定与管理不足，导致不一致性、安全风险及合规问题。

Method: 通过对六家国际公司和四个研究机构的19次半结构化访谈，采用主题分析方法探讨标注需求的定义、使用及其质量保障挑战和改进措施。

Result: 识别出标注需求面临的五大挑战（歧义、边缘案例复杂性、需求演变、不一致性、资源限制）及三大最佳实践（合伦理标准、改进标注指导、嵌入质量保障），揭示标注需求缺陷如何影响AI感知系统开发和性能。

Conclusion: 本研究首次基于实证为改进标注需求提供指导，提升标注质量、合规性与系统可靠性，促进软件工程与需求工程在人工智能领域的融合，为AI感知系统的安全可靠发展奠定基础。

Abstract: High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.

</details>


### [31] [InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution](https://arxiv.org/abs/2511.16004)
*KeFan Li,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: 本文提出了InfCode，一种用于自动解决仓库级软件问题的对抗多智能体框架，通过让测试生成器和代码补丁生成器相互对抗迭代，提升测试和补丁质量，从而实现对真实软件缺陷的有效修复。


<details>
  <summary>Details</summary>
Motivation: 现有基于智能体或流水线的方法依赖不足的测试，虽验证通过但可能未修复根本缺陷，难以解决真实世界的软件问题。

Method: 该方法通过测试补丁生成器和代码补丁生成器之间的对抗交互，迭代精炼测试和补丁，使用选择器智能体确定最可靠的修复方案，框架运行于支持真实仓库操作的容器化环境中。

Result: 在SWE-bench Lite和SWE-bench Verified基准测试上，使用DeepSeek-V3和Claude 4.5 Sonnet模型，InfCode均显著优于强基线方法，并发布了开源代码。

Conclusion: InfCode在多个基准测试中表现优异，显著超过现有方法，达到79.4%的性能，确立了新的最先进水平。

Abstract: Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.

</details>


### [32] [InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution](https://arxiv.org/abs/2511.16005)
*Qingao Dong,Mengfei Wang,Hengzhi Zhang,Zhichao Li,Yuan Yuan,Mu Li,Xiang Gao,Hailong Sun,Chunming Hu,Weifeng Lv*

Main category: cs.SE

TL;DR: INFCODE-C++是一种首个针对C++问题解决的自主系统，通过语义和结构化查询相结合提升了上下文检索和错误定位性能，在C++项目自动修复任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自动修复方法主要针对Python，对C++中复杂的命名和结构支持不足，性能大幅下降，亟需设计适合C++的多语言感知修复系统。

Method: 该方法结合语义代码意图检索和确定性AST结构化查询两种互补机制，构建准确的语言感知上下文，实现精准定位和稳定补丁合成。

Result: 在MultiSWE-bench-CPP基准测试中，INFCODE-C++达到25.58%的问题解决率，比现有最好模型提升了10.85个百分点，性能超过MSWE-agent两倍以上。

Conclusion: INFCODE-C++系统在C++项目自动修复任务中显著优于现有方法，强调语言感知检索和结构化分析对复杂静态类型语言问题解决的重要性。

Abstract: Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.

</details>


### [33] [The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report](https://arxiv.org/abs/2511.16092)
*Xing Hu,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文报告了33位软件工程、人工智能及人机交互领域专家在湘南会议222上关于生成式人工智能（GenAI）对集成开发环境（IDE）影响的讨论。


<details>
  <summary>Details</summary>
Motivation: 探索生成式人工智能在代码生成、测试、审查和修复等任务中的优秀表现，及其对提升IDE人机交互抽象级别的潜力。

Method: 组织33位来自软件工程、人工智能和人机交互领域的专家在湘南会议222中进行面对面讨论，汇集多领域视角。

Result: 总结了GenAI应用于IDE的挑战与机遇，为未来相关研究和开发提供方向。

Conclusion: 生成式人工智能技术有望显著改变集成开发环境中的人机交互方式，但仍存在诸多挑战需要解决。

Abstract: Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report

</details>


### [34] [Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions](https://arxiv.org/abs/2511.16123)
*Linyi Han,Shidong Pan,Zhenchang Xing,Sofonias Yitagesu,Xiaowang Zhang,Zhiyong Feng,Jiamou Sun,Qing Huang*

Main category: cs.SE

TL;DR: 本文针对漏洞描述中信息不一致问题，提出利用领域约束大型语言模型的三阶段合成框架，显著提升了漏洞信息的统一性和分析效率。


<details>
  <summary>Details</summary>
Motivation: 不同软件漏洞描述库中的文本漏洞描述（TVDs）存在关键方面不一致，影响安全分析人员对漏洞的全面理解。现有方法对齐外部知识库，但往往忽略有价值的信息，难以综合全面的表示。

Method: 提出基于领域约束的大型语言模型合成框架，包含三个阶段：1）基于规则模板提取关键细节；2）利用领域锚词进行自我评估语义变异；3）通过信息熵融合不一致信息，优先考虑相关细节。

Result: 该框架将关键方面增强的F1分数从0.82提高到0.87，提升了超过30%的理解效率和效果。

Conclusion: 该框架有效解决了TVDs中的不一致问题，提高了漏洞描述的综合度和安全分析的效率，且开发的Digest Labels工具显著提升了可用性。

Abstract: Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.

</details>


### [35] [Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts](https://arxiv.org/abs/2511.16224)
*Francesco Salzano,Simone Scalabrino,Rocco Oliveto,Simone Scalabrino*

Main category: cs.SE

TL;DR: LLM生成的智能合约代码表面语义相似，但功能鲁棒性不足；检索增强能提升生成质量，但生产级代码生成仍需专家严格验证。


<details>
  <summary>Details</summary>
Motivation: 现有LMM生成的智能合约代码缺乏对其功能性和非功能性关键属性的全面评估，尤其是考虑到智能合约在Gas消耗、安全性和确定性方面的独特要求。

Method: 基于四种最先进的模型，分别在零-shot和检索增强生成设置下，对500个真实智能合约函数进行多方面评估，包括代码相似度、语义嵌入、自动化测试执行、Gas使用剖析、认知复杂度和环形复杂度分析。

Result: LLM生成的代码与真实合约具有较高语义相似度，但功能正确性较低（仅20%-26%零-shot生成函数在测试中行为一致）。生成代码更简单，复杂度和Gas消耗显著降低，常因省略验证逻辑。检索增强生成显著提升性能，功能正确率提升至最高45%，代码更简洁高效。

Conclusion: LLM生成智能合约虽具有潜力，但功能正确性和安全性仍有较大挑战，检索增强是有效提升手段，但实现高质量生产代码仍需综合方法和专家审查。

Abstract: Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.

</details>


### [36] [Data Annotation Quality Problems in AI-Enabled Perception System Development](https://arxiv.org/abs/2511.16410)
*Hina Saeeda,Tommy Johansson,Mazen Mohamad,Eric Knauss*

Main category: cs.SE

TL;DR: 本文基于多组织案例研究，提出了包含18类错误的自动驾驶数据标注错误分类法，旨在帮助识别和管理标注质量问题，提升AI感知系统的可信度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶AI感知系统的数据标注错误普遍存在且影响模型性能、安全与可靠性，但业界缺乏对错误产生与传播机制的实证洞察，亟需系统分析和管理工具。

Method: 采用多组织案例研究，结合19次半结构化访谈和六阶段主题分析，归纳标注错误分类并通过行业专家验证。

Result: 本文通过对涉足欧洲和英国的六家公司和四个研究机构的多组织案例研究，揭示了自动驾驶AI感知系统中数据标注错误的产生与传播机制。基于19次半结构化访谈，提炼出涵盖完整性、准确性和一致性三大数据质量维度的18类常见标注错误类型，如属性遗漏、误标注及标注员间分歧等。该分类法经过行业专家验证，被视为类似故障模式与影响分析（FMEA）的失效模式目录，有助于根因分析、供应商质量评估、人员培训和标注指南改进。研究将标注质量视为生命周期及供应链管理问题，为工程化可信AI感知系统构建提供了统一术语、诊断工具和可操作建议。

Conclusion: 通过建立标注错误分类体系并验证其行业适用性，研究促进了标注质量的系统化管理，支持可信自动驾驶感知系统的开发。

Abstract: Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.

</details>


### [37] [Green Resilience of Cyber-Physical Systems: Doctoral Dissertation](https://arxiv.org/abs/2511.16593)
*Diaeddin Rimawi*

Main category: cs.SE

TL;DR: 本文研究了如何在在线协同AI系统中实现弹性和绿色恢复，提出新框架和策略，有效提升恢复性能并控制能耗。


<details>
  <summary>Details</summary>
Motivation: 针对在线协同AI系统在破坏事件中性能下降问题，研究如何恢复性能并同时限制能耗，实现弹性与绿色的权衡。

Method: 通过建模系统运行状态，采用多目标优化、博弈论决策和强化学习设计恢复策略，并构建度量框架对弹性和绿色程度进行量化。

Result: 本文提出了针对在线协同人工智能系统（OL-CAIS）如何平衡弹性与节能的模型、指标和策略。通过定义系统的三种运行状态，设计了GResilience框架，利用多目标优化、博弈论决策和强化学习，实现了在破坏事件中快速且绿色的恢复。实验证明该框架能提升恢复速度和性能稳定性，减少对人工干预的依赖，同时RL代理效果最佳但略微增加碳排放。容器化技术可显著降低碳排放。

Conclusion: GResilience框架成功平衡了OL-CAIS的弹性和绿色需求，实现了更快、更稳定、低碳的恢复，强化学习策略表现最佳，但需要注意碳排放的轻微增加。容器化执行能显著减少碳排放。

Abstract: Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems](https://arxiv.org/abs/2511.15862)
*Devang Kulshreshtha,Wanyu Du,Raghav Jain,Srikanth Doss,Hang Su,Sandesh Swamy,Yanjun Qi*

Main category: cs.MA

TL;DR: 本文提出博弈论驱动的框架模拟非合作行为对LLM多代理系统的影响，实验验证非合作行为快速引起系统崩溃，强调提升系统韧性的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前研究尚未系统分析非合作行为如何影响基于大型语言模型（LLM）的多代理系统的稳定性和运行效果。

Method: 提出基于博弈论的非合作代理行为分类体系，并构建多阶段动态模拟流程，实现非合作行为的生成和演化。

Result: 框架在资源管理场景的实验中达到96.7%的行为生成准确率，显示合作代理系统完全稳定，而非合作行为导致系统在1至7轮内迅速崩溃。

Conclusion: 非合作行为显著破坏多代理系统的稳定性，提示设计更具韧性的多代理系统的重要性。

Abstract: This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.

</details>
