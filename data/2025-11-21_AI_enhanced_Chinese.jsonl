{"id": "2511.15886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15886", "abs": "https://arxiv.org/abs/2511.15886", "authors": ["Jeremias Ferrao", "Ezgi Basar", "Khondoker Ittehadul Islam", "Mahrokh Hassani"], "title": "What Really Counts? Examining Step and Token Level Attribution in Multilingual CoT Reasoning", "comment": "Received the Best Student Project Award at RuG's Advanced-NLP course", "summary": "This study investigates the attribution patterns underlying Chain-of-Thought (CoT) reasoning in multilingual LLMs. While prior works demonstrate the role of CoT prompting in improving task performance, there are concerns regarding the faithfulness and interpretability of the generated reasoning chains. To assess these properties across languages, we applied two complementary attribution methods--ContextCite for step-level attribution and Inseq for token-level attribution--to the Qwen2.5 1.5B-Instruct model using the MGSM benchmark. Our experimental results highlight key findings such as: (1) attribution scores excessively emphasize the final reasoning step, particularly in incorrect generations; (2) structured CoT prompting significantly improves accuracy primarily for high-resource Latin-script languages; and (3) controlled perturbations via negation and distractor sentences reduce model accuracy and attribution coherence. These findings highlight the limitations of CoT prompting, particularly in terms of multilingual robustness and interpretive transparency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u591a\u8bed\u8a00\u5927\u6a21\u578b\u4e2dCoT\u63a8\u7406\u7684\u5f52\u56e0\u7279\u70b9\uff0c\u53d1\u73b0\u5176\u591a\u8bed\u8a00\u6027\u80fd\u548c\u89e3\u91ca\u6027\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u5bf9\u975e\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u652f\u6301\u6709\u9650\u3002", "motivation": "\u63a2\u8ba8\u591a\u8bed\u8a00\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u4e2dChain-of-Thought(CoT)\u63a8\u7406\u7684\u5f52\u56e0\u6a21\u5f0f\uff0c\u7279\u522b\u662f\u5173\u6ce8\u751f\u6210\u63a8\u7406\u94fe\u7684\u771f\u5b9e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u8865\u5145\u6027\u7684\u5f52\u56e0\u65b9\u6cd5\u2014\u2014ContextCite\uff08\u6b65\u9aa4\u7ea7\u5f52\u56e0\uff09\u548cInseq\uff08token\u7ea7\u5f52\u56e0\uff09\uff0c\u5728Qwen2.5 1.5B-Instruct\u6a21\u578b\u548cMGSM\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u53d1\u73b0\u5f52\u56e0\u5206\u6570\u8fc7\u5ea6\u5f3a\u8c03\u6700\u7ec8\u63a8\u7406\u6b65\u9aa4\uff0c\u5c24\u5176\u5728\u9519\u8bef\u751f\u6210\u4e2d\u66f4\u660e\u663e\uff1b\u7ed3\u6784\u5316CoT\u63d0\u793a\u663e\u8457\u63d0\u5347\u9ad8\u8d44\u6e90\u62c9\u4e01\u6587\u8bed\u8a00\u7684\u51c6\u786e\u7387\uff1b\u901a\u8fc7\u5426\u5b9a\u548c\u5e72\u6270\u53e5\u5b50\u7684\u53d7\u63a7\u6270\u52a8\u4f1a\u964d\u4f4e\u6a21\u578b\u51c6\u786e\u6027\u548c\u5f52\u56e0\u7684\u4e00\u81f4\u6027\u3002", "conclusion": "CoT\u63d0\u793a\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u7684\u9c81\u68d2\u6027\u548c\u89e3\u91ca\u900f\u660e\u5ea6\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\u3002"}}
{"id": "2511.15862", "categories": ["cs.MA", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15862", "abs": "https://arxiv.org/abs/2511.15862", "authors": ["Devang Kulshreshtha", "Wanyu Du", "Raghav Jain", "Srikanth Doss", "Hang Su", "Sandesh Swamy", "Yanjun Qi"], "title": "The Subtle Art of Defection: Understanding Uncooperative Behaviors in LLM based Multi-Agent Systems", "comment": null, "summary": "This paper introduces a novel framework for simulating and analyzing how uncooperative behaviors can destabilize or collapse LLM-based multi-agent systems. Our framework includes two key components: (1) a game theory-based taxonomy of uncooperative agent behaviors, addressing a notable gap in the existing literature; and (2) a structured, multi-stage simulation pipeline that dynamically generates and refines uncooperative behaviors as agents' states evolve. We evaluate the framework via a collaborative resource management setting, measuring system stability using metrics such as survival time and resource overuse rate. Empirically, our framework achieves 96.7% accuracy in generating realistic uncooperative behaviors, validated by human evaluations. Our results reveal a striking contrast: cooperative agents maintain perfect system stability (100% survival over 12 rounds with 0% resource overuse), while any uncooperative behavior can trigger rapid system collapse within 1 to 7 rounds. These findings demonstrate that uncooperative agents can significantly degrade collective outcomes, highlighting the need for designing more resilient multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u535a\u5f08\u8bba\u9a71\u52a8\u7684\u6846\u67b6\u6a21\u62df\u975e\u5408\u4f5c\u884c\u4e3a\u5bf9LLM\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u975e\u5408\u4f5c\u884c\u4e3a\u5feb\u901f\u5f15\u8d77\u7cfb\u7edf\u5d29\u6e83\uff0c\u5f3a\u8c03\u63d0\u5347\u7cfb\u7edf\u97e7\u6027\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u5c1a\u672a\u7cfb\u7edf\u5206\u6790\u975e\u5408\u4f5c\u884c\u4e3a\u5982\u4f55\u5f71\u54cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u8fd0\u884c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u535a\u5f08\u8bba\u7684\u975e\u5408\u4f5c\u4ee3\u7406\u884c\u4e3a\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u6784\u5efa\u591a\u9636\u6bb5\u52a8\u6001\u6a21\u62df\u6d41\u7a0b\uff0c\u5b9e\u73b0\u975e\u5408\u4f5c\u884c\u4e3a\u7684\u751f\u6210\u548c\u6f14\u5316\u3002", "result": "\u6846\u67b6\u5728\u8d44\u6e90\u7ba1\u7406\u573a\u666f\u7684\u5b9e\u9a8c\u4e2d\u8fbe\u523096.7%\u7684\u884c\u4e3a\u751f\u6210\u51c6\u786e\u7387\uff0c\u663e\u793a\u5408\u4f5c\u4ee3\u7406\u7cfb\u7edf\u5b8c\u5168\u7a33\u5b9a\uff0c\u800c\u975e\u5408\u4f5c\u884c\u4e3a\u5bfc\u81f4\u7cfb\u7edf\u57281\u81f37\u8f6e\u5185\u8fc5\u901f\u5d29\u6e83\u3002", "conclusion": "\u975e\u5408\u4f5c\u884c\u4e3a\u663e\u8457\u7834\u574f\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\uff0c\u63d0\u793a\u8bbe\u8ba1\u66f4\u5177\u97e7\u6027\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.15887", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15887", "abs": "https://arxiv.org/abs/2511.15887", "authors": ["Seungbeen Lee", "Jinhong Jeong", "Donghyun Kim", "Yejin Son", "Youngjae Yu"], "title": "Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language", "comment": null, "summary": "Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Motion2Mind\u6846\u67b6\uff0c\u65e8\u5728\u8bc4\u4f30\u673a\u5668\u5bf9\u975e\u8a00\u8bed\u7ebf\u7d22\u89e3\u8bfb\u4ed6\u4eba\u5fc3\u667a\u72b6\u6001\u7684\u80fd\u529b\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u4e30\u5bcc\u975e\u8a00\u8bed\u7ebf\u7d22\u6ce8\u91ca\u548c\u5fc3\u7406\u89e3\u91ca\u7684\u89c6\u9891\u6570\u636e\u96c6\u3002\u5b9e\u9a8c\u8868\u660e\u73b0\u6709AI\u7cfb\u7edf\u5728\u975e\u8a00\u8bed\u7ebf\u7d22\u89e3\u8bfb\u65b9\u9762\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u5f53\u524d\u5fc3\u667a\u7406\u8bba\u6d4b\u8bd5\u4e3b\u8981\u56f4\u7ed5\u9519\u8bef\u4fe1\u5ff5\u548c\u975e\u5bf9\u79f0\u4fe1\u606f\uff0c\u7f3a\u4e4f\u5bf9\u4e8e\u5176\u4ed6\u5fc3\u7406\u72b6\u6001\u548c\u975e\u8a00\u8bed\u6c9f\u901a\u7684\u5168\u9762\u8003\u5bdf\uff0c\u4e9f\u9700\u5efa\u7acb\u8bc4\u4f30\u673a\u5668\u89e3\u8bfb\u975e\u8a00\u8bed\u7ebf\u7d22\u80fd\u529b\u7684\u6846\u67b6\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u4e13\u5bb6\u7f16\u5236\u80a2\u4f53\u8bed\u8a00\u53c2\u8003\u7684Motion2Mind\u89c6\u9891\u6570\u636e\u96c6\uff0c\u6ce8\u91ca222\u79cd\u975e\u8a00\u8bed\u7ebf\u7d22\u548c397\u79cd\u5fc3\u7406\u72b6\u6001\uff0c\u901a\u8fc7\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u673a\u5668\u7684\u5fc3\u667a\u7406\u8bba\u80fd\u529b\u3002", "result": "Motion2Mind\u5b9e\u9a8c\u663e\u793aAI\u5728\u975e\u8a00\u8bed\u7ebf\u7d22\u7684\u68c0\u6d4b\u548c\u89e3\u91ca\u4e0a\u5747\u8868\u73b0\u4e0d\u4f73\uff0c\u5b58\u5728\u6027\u80fd\u5dee\u8ddd\u53ca\u8fc7\u5ea6\u89e3\u91ca\u73b0\u8c61\u3002", "conclusion": "\u73b0\u6709AI\u7cfb\u7edf\u5728\u7406\u89e3\u548c\u89e3\u91ca\u975e\u8a00\u8bed\u7ebf\u7d22\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u8fdc\u4e0d\u80fd\u8fbe\u5230\u4eba\u7c7b\u6c34\u5e73\u3002"}}
{"id": "2511.15976", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.15976", "abs": "https://arxiv.org/abs/2511.15976", "authors": ["Sarik Ghazarian", "Abhinav Gullapalli", "Swair Shah", "Anurag Beniwal", "Nanyun Peng", "Narayanan Sadagopan", "Zhou Yu"], "title": "TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues", "comment": null, "summary": "In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u590d\u6742\u8fc7\u7a0b\u6307\u4ee4\u7684TOD-ProcBench\u57fa\u51c6\uff0c\u901a\u8fc7\u4e09\u9879\u4efb\u52a1\u5168\u9762\u8bc4\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u4efb\u52a1\u578b\u5bf9\u8bdd\u4e2d\u7406\u89e3\u3001\u6267\u884c\u590d\u6742\u4e14\u7ec6\u7c92\u5ea6\u7ea6\u675f\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u586b\u8865\u73b0\u6709\u57fa\u51c6\u7b80\u5355\u5316\u6307\u4ee4\u7684\u4e0d\u8db3\u3002", "motivation": "\u5f53\u524d\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u8bc4\u6d4b\u591a\u5c06\u590d\u6742\u6307\u4ee4\u7b80\u5316\u4e3a\u610f\u56fe\u3001\u69fd\u4f4d\u3001API\u8c03\u7528\u914d\u7f6e\uff0c\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9075\u5faa\u590d\u6742\u591a\u6b65\u9aa4\u6307\u4ee4\u7684\u80fd\u529b\uff0c\u9700\u6784\u5efa\u4e00\u4e2a\u6311\u6218\u6027\u4e14\u7ec6\u7c92\u5ea6\u7ea6\u675f\u7684\u57fa\u51c6\u4ee5\u7cfb\u7edf\u6d4b\u8bc4\u6a21\u578b\u6267\u884c\u590d\u6742\u4efb\u52a1\u5bf9\u8bdd\u6307\u4ee4\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faTOD-ProcBench\u57fa\u51c6\uff0c\u5229\u7528\u591a\u5c42\u6b21\u6761\u4ef6-\u52a8\u4f5c\u6307\u4ee4\u8868\u8ff0\u590d\u6742\u6b65\u9aa4\u6307\u4ee4\uff0c\u8bbe\u8ba1\u4e09\u9879\u4efb\u52a1\u8bc4\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u4efb\u52a1\u5bf9\u8bdd\u4e2d\u9075\u5faa\u590d\u6742\u6307\u4ee4\u7684\u80fd\u529b\u3002\u4efb\u52a1\u5305\u62ec\u76f8\u5173\u6307\u4ee4\u68c0\u7d22\u548c\u52a8\u4f5c\u9884\u6d4b\u3001\u8bc6\u522b\u8fdd\u80cc\u6307\u4ee4\u7684\u5bf9\u8bdd\u56de\u590d\u3001\u57fa\u4e8e\u590d\u6742\u6307\u4ee4\u6761\u4ef6\u751f\u6210\u56de\u590d\uff0c\u540c\u65f6\u7814\u7a76\u591a\u8bed\u8a00\u73af\u5883\u548c\u6307\u4ee4\u6587\u672c\u683c\u5f0f\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6784\u5efa\u5305\u542b\u6765\u6e90\u4e8e\u9ad8\u8d28\u91cfABCD\u6570\u636e\u96c6\u7684\u6307\u4ee4\u6587\u6863\u4e0e\u5bf9\u5e94\u5bf9\u8bdd\u6570\u636e\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff1b\u8bbe\u8ba1\u4e09\u9879\u4efb\u52a1\u56f4\u7ed5\u590d\u6742\u6307\u4ee4\u7406\u89e3\u4e0e\u6267\u884c\u8fdb\u884c\u7cfb\u7edf\u8bc4\u6d4b\uff1b\u5e76\u901a\u8fc7\u591a\u8bed\u8a00\u53ca\u6587\u672c\u683c\u5f0f\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u9075\u5faa\u6307\u4ee4\u7684\u8868\u73b0\u5dee\u5f02\u3002", "conclusion": "TOD-ProcBench\u4e3a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9075\u5faa\u590d\u6742\u591a\u6b65\u9aa4\u6307\u4ee4\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6846\u67b6\u548c\u6311\u6218\u6027\u6d4b\u8bd5\uff0c\u5c55\u73b0\u4e86\u6a21\u578b\u5728\u68c0\u7d22\u76f8\u5173\u6307\u4ee4\u3001\u8bc6\u522b\u8fdd\u89c4\u56de\u590d\u53ca\u6761\u4ef6\u751f\u6210\u56de\u590d\u7684\u80fd\u529b\uff0c\u63a8\u52a8\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2511.15733", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15733", "abs": "https://arxiv.org/abs/2511.15733", "authors": ["Eitan Farchi", "Kiran Nayak", "Papia Ghosh Majumdar", "Saritha Route"], "title": "Technique to Baseline QE Artefact Generation Aligned to Quality Metrics", "comment": null, "summary": "Large Language Models (LLMs) are transforming Quality Engineering (QE) by automating the generation of artefacts such as requirements, test cases, and Behavior Driven Development (BDD) scenarios. However, ensuring the quality of these outputs remains a challenge. This paper presents a systematic technique to baseline and evaluate QE artefacts using quantifiable metrics. The approach combines LLM-driven generation, reverse generation , and iterative refinement guided by rubrics technique for clarity, completeness, consistency, and testability. Experimental results across 12 projects show that reverse-generated artefacts can outperform low-quality inputs and maintain high standards when inputs are strong. The framework enables scalable, reliable QE artefact validation, bridging automation with accountability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8d28\u91cf\u5de5\u7a0b\uff08QE\uff09\u5de5\u4ef6\u751f\u6210\u4e0e\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u53cd\u5411\u751f\u6210\u548c\u8fed\u4ee3\u4f18\u5316\uff0c\u63d0\u5347\u5de5\u4ef6\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u8d28\u91cf\u5de5\u7a0b\u5de5\u4ef6\u8d28\u91cf\u53c2\u5dee\u4e0d\u9f50\uff0c\u4e9f\u9700\u4e00\u79cd\u91cf\u5316\u6307\u6807\u548c\u7cfb\u7edf\u5316\u6280\u672f\u4fdd\u969c\u8f93\u51fa\u8d28\u91cf\u3002", "method": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u751f\u6210\u3001\u53cd\u5411\u751f\u6210\u548c\u57fa\u4e8e\u8bc4\u5206\u6807\u51c6\uff08\u6e05\u6670\u5ea6\u3001\u5b8c\u6574\u6027\u3001\u4e00\u81f4\u6027\u548c\u53ef\u6d4b\u8bd5\u6027\uff09\u7684\u8fed\u4ee3\u7ec6\u5316\u65b9\u6cd5\u3002", "result": "12\u4e2a\u9879\u76ee\u5b9e\u9a8c\u8bc1\u660e\uff0c\u53cd\u5411\u751f\u6210\u5de5\u4ef6\u5728\u63d0\u5347\u4f4e\u8d28\u91cf\u8f93\u5165\u6548\u679c\u53ca\u4fdd\u6301\u9ad8\u8f93\u5165\u8d28\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u53cd\u5411\u751f\u6210\u7684QE\u5de5\u4ef6\u80fd\u591f\u8d85\u8d8a\u4f4e\u8d28\u91cf\u8f93\u5165\uff0c\u5e76\u5728\u9ad8\u8d28\u91cf\u8f93\u5165\u65f6\u4fdd\u6301\u9ad8\u6807\u51c6\uff0c\u5b9e\u73b0\u4e86QE\u5de5\u4ef6\u7684\u53ef\u6269\u5c55\u548c\u53ef\u9760\u9a8c\u8bc1\u3002"}}
{"id": "2511.16035", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16035", "abs": "https://arxiv.org/abs/2511.16035", "authors": ["Kieron Kretschmar", "Walter Laurito", "Sharan Maiya", "Samuel Marks"], "title": "Liars' Bench: Evaluating Lie Detectors for Language Models", "comment": "*Kieron Kretschmar and Walter Laurito contributed equally to this work. 10 pages, 2 figures; plus appendix. Code at https://github.com/Cadenza-Labs/liars-bench and datasets at https://huggingface.co/datasets/Cadenza-Labs/liars-bench Subjects: Computation and Language (cs.CL); Artificial Intelligence (cs.AI)", "summary": "Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u4e86LIARS' BENCH\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5305\u542b\u5927\u91cf\u771f\u5b9e\u4e0e\u8c0e\u8a00\u793a\u4f8b\uff0c\u4ee5\u8bc4\u4f30\u548c\u63a8\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8c0e\u8a00\u68c0\u6d4b\u6280\u672f\u3002", "motivation": "\u4ee5\u5f80\u8c0e\u8a00\u68c0\u6d4b\u65b9\u6cd5\u9a8c\u8bc1\u73af\u5883\u6709\u9650\uff0c\u4e0d\u80fd\u5168\u9762\u6355\u6349\u8bed\u8a00\u6a21\u578b\u4ea7\u751f\u591a\u6837\u5316\u8c0e\u8a00\u7684\u60c5\u51b5\uff0c\u4e9f\u9700\u66f4\u5177\u4ee3\u8868\u6027\u548c\u590d\u6742\u5ea6\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u6784\u5efa\u5305\u542b72863\u4e2a\u6837\u672c\u7684LIARS' BENCH\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e0d\u540c\u8c0e\u8a00\u7c7b\u578b\u548c\u6a21\u578b\u8bf4\u8c0e\u52a8\u673a\uff0c\u5e76\u5bf9\u4e09\u79cd\u9ed1\u76d2\u4e0e\u767d\u76d2\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u6027\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u8bc6\u522b\u67d0\u4e9b\u8c0e\u8a00\u7c7b\u578b\uff0c\u7279\u522b\u662f\u5728\u65e0\u6cd5\u4ec5\u51ed\u8f6c\u5f55\u6587\u672c\u5224\u65ad\u8c0e\u8a00\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u5b9e\u8f83\u5dee\u3002LIARS' BENCH\u63ed\u793a\u4e86\u8fd9\u4e9b\u5c40\u9650\u6027\u5e76\u63a8\u52a8\u68c0\u6d4b\u6280\u672f\u8fdb\u6b65\u3002", "conclusion": "\u73b0\u6709\u8c0e\u8a00\u68c0\u6d4b\u6280\u672f\u5728\u591a\u6837\u5316\u8c0e\u8a00\u8bc6\u522b\u4e0a\u5b58\u5728\u7cfb\u7edf\u6027\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u65e0\u6cd5\u4ec5\u901a\u8fc7\u5bf9\u8bdd\u6587\u672c\u5224\u65ad\u7684\u60c5\u5883\u3002LIARS' BENCH\u4e3a\u8c0e\u8a00\u68c0\u6d4b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u6d4b\u8bc4\u73af\u5883\u3002"}}
{"id": "2511.15757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15757", "abs": "https://arxiv.org/abs/2511.15757", "authors": ["Kareem Shehada", "Yifan Wu", "Wyatt D. Feng", "Adithya Iyer", "Gryphon Kumfert", "Yangruibo Ding", "Zhiyun Qian"], "title": "Rethinking Kernel Program Repair: Benchmarking and Enhancing LLMs with RGym", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling", "summary": "Large Language Models (LLMs) have revolutionized automated program repair (APR) but current benchmarks like SWE-Bench predominantly focus on userspace applications and overlook the complexities of kernel-space debugging and repair. The Linux kernel poses unique challenges due to its monolithic structure, concurrency, and low-level hardware interactions. Prior efforts such as KGym and CrashFixer have highlighted the difficulty of APR in this domain, reporting low success rates or relying on costly and complex pipelines and pricey cloud infrastructure. In this work, we introduce RGym, a lightweight, platform-agnostic APR evaluation framework for the Linux kernel designed to operate on local commodity hardware. Built on RGym, we propose a simple yet effective APR pipeline leveraging specialized localization techniques (e.g., call stacks and blamed commits) to overcome the unrealistic usage of oracles in KGym. We test on a filtered and verified dataset of 143 bugs. Our method achieves up to a 43.36% pass rate with GPT-5 Thinking while maintaining a cost of under $0.20 per bug. We further conduct an ablation study to analyze contributions from our proposed localization strategy, prompt structure, and model choice, and demonstrate that feedback-based retries can significantly enhance success rates.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u9002\u7528\u4e8eLinux\u5185\u6838\u7684\u8f7b\u91cf\u7ea7APR\u6846\u67b6RGym\u548c\u4e00\u4e2a\u57fa\u4e8e\u5b9a\u4f4d\u6280\u672f\u7684\u9ad8\u6548\u4fee\u590d\u6d41\u6c34\u7ebf\uff0c\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u4fee\u590d\u6210\u529f\u7387\u548c\u4f4e\u6210\u672c\uff0c\u63a8\u52a8\u4e86\u5185\u6838\u7a7a\u95f4APR\u7814\u7a76\u3002", "motivation": "\u5f53\u524d\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff08APR\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u7528\u6237\u7a7a\u95f4\u5e94\u7528\uff0c\u5ffd\u89c6\u4e86\u5185\u6838\u7a7a\u95f4\u7684\u8c03\u8bd5\u548c\u4fee\u590d\u96be\u9898\u3002Linux\u5185\u6838\u56e0\u5176\u5355\u4f53\u7ed3\u6784\u3001\u5e76\u53d1\u6027\u548c\u5e95\u5c42\u786c\u4ef6\u4ea4\u4e92\u7684\u590d\u6742\u6027\uff0c\u4f7f\u5f97APR\u66f4\u52a0\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u6210\u529f\u7387\u4f4e\u4e14\u4f9d\u8d56\u6602\u8d35\u590d\u6742\u7684\u786c\u4ef6\u548c\u4e91\u57fa\u7840\u8bbe\u65bd\u3002", "method": "\u8bbe\u8ba1\u4e86RGym\u8bc4\u4f30\u6846\u67b6\uff0c\u6784\u5efa\u4e86\u4e00\u4e2aAPR\u6d41\u6c34\u7ebf\uff0c\u91c7\u7528\u8c03\u7528\u6808\u548c\u8d23\u5907\u63d0\u4ea4\u7b49\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u7ed3\u5408GPT-5 Thinking\u6280\u672f\u8fdb\u884c\u7a0b\u5e8f\u4fee\u590d\uff0c\u5e76\u901a\u8fc7\u53cd\u9988\u673a\u5236\u5b9e\u73b0\u591a\u6b21\u91cd\u8bd5\u63d0\u9ad8\u4fee\u590d\u7387\u3002", "result": "\u63d0\u51fa\u4e86RGym\uff0c\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u5e73\u53f0\u65e0\u5173\u7684Linux\u5185\u6838APR\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u5728\u672c\u5730\u666e\u901a\u786c\u4ef6\u4e0a\u8fd0\u884c\u3002\u57fa\u4e8eRGym\uff0c\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7b80\u5355\u6709\u6548\u7684APR\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u8c03\u7528\u6808\u548c\u6709\u95ee\u9898\u7684\u63d0\u4ea4\u7b49\u5b9a\u4f4d\u6280\u672f\uff0c\u907f\u514d\u4f7f\u7528\u4e0d\u5207\u5b9e\u9645\u7684oracle\u3002\u6d4b\u8bd5143\u4e2a\u5df2\u9a8c\u8bc1\u7684\u5185\u6838\u6f0f\u6d1e\uff0c\u5b9e\u73b0\u4e86\u6700\u9ad843.36%\u7684\u4fee\u590d\u901a\u8fc7\u7387\uff0c\u4e14\u6210\u672c\u4f4e\u4e8e\u6bcf\u4e2a\u6f0f\u6d1e0.20\u7f8e\u5143\u3002", "conclusion": "\u57fa\u4e8eRGym\u7684APR\u65b9\u6cd5\u5728Linux\u5185\u6838\u7a0b\u5e8f\u4fee\u590d\u4e2d\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u6210\u529f\u7387\u548c\u4f4e\u6210\u672c\u4f18\u52bf\u3002\u5b9a\u4f4d\u7b56\u7565\u3001\u63d0\u793a\u7ed3\u6784\u548c\u6a21\u578b\u9009\u62e9\u5bf9\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4e14\u57fa\u4e8e\u53cd\u9988\u7684\u91cd\u8bd5\u673a\u5236\u80fd\u663e\u8457\u63d0\u9ad8\u6210\u529f\u7387\u3002"}}
{"id": "2511.16054", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16054", "abs": "https://arxiv.org/abs/2511.16054", "authors": ["Gwen Yidou-Weng", "Ian Li", "Anji Liu", "Oliver Broadrick", "Guy Van den Broeck", "Benjie Wang"], "title": "Learning Tractable Distributions Of Language Model Continuations", "comment": null, "summary": "Controlled language generation conditions text on sequence-level constraints (for example, syntax, style, or safety). These constraints may depend on future tokens, which makes directly conditioning an autoregressive language model (LM) generally intractable. Prior work uses tractable surrogates such as hidden Markov models (HMMs) to approximate the distribution over continuations and adjust the model's next-token logits at decoding time. However, we find that these surrogates are often weakly context aware, which reduces query quality. We propose Learning to Look Ahead (LTLA), a hybrid approach that pairs the same base language model for rich prefix encoding with a fixed tractable surrogate model that computes exact continuation probabilities. Two efficiency pitfalls arise when adding neural context: (i) naively rescoring the prefix with every candidate next token requires a sweep over the entire vocabulary at each step, and (ii) predicting fresh surrogate parameters for each prefix, although tractable at a single step, forces recomputation of future probabilities for every new prefix and eliminates reuse. LTLA avoids both by using a single batched HMM update to account for all next-token candidates at once, and by conditioning only the surrogate's latent state prior on the LM's hidden representations while keeping the surrogate decoder fixed, so computations can be reused across prefixes. Empirically, LTLA attains higher conditional likelihood than an unconditional HMM, approximates continuation distributions for vision-language models where a standalone HMM cannot encode visual context, and improves constraint satisfaction at comparable fluency on controlled-generation tasks, with minimal inference overhead.", "AI": {"tldr": "\u63d0\u51faLTLA\u65b9\u6cd5\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u548cHMM\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u53d7\u63a7\u8bed\u8a00\u751f\u6210\uff0c\u63d0\u5347\u7ea6\u675f\u6ee1\u8db3\u5ea6\u548c\u751f\u6210\u8d28\u91cf\u3002", "motivation": "\u63a7\u5236\u8bed\u8a00\u751f\u6210\u65f6\uff0c\u5e8f\u5217\u7ea7\u522b\u7684\u7ea6\u675f\uff08\u5982\u8bed\u6cd5\u3001\u98ce\u683c\u3001\u5b89\u5168\u6027\uff09\u4f9d\u8d56\u672a\u6765\u7684\u8bcd\u5143\uff0c\u4f7f\u7528\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u76f4\u63a5\u5efa\u6a21\u56f0\u96be\u3002\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\uff08HMM\uff09\u7b49\u8fd1\u4f3c\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u611f\u77e5\uff0c\u5bfc\u81f4\u67e5\u8be2\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86Learning to Look Ahead (LTLA)\u65b9\u6cd5\uff0c\u5c06\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u7684\u4e30\u5bcc\u524d\u7f00\u7f16\u7801\u4e0e\u56fa\u5b9a\u7684\u53ef\u89e3\u6a21\u578b\uff08HMM\uff09\u7ed3\u5408\uff0c\u901a\u8fc7\u6279\u91cf\u4e00\u6b21\u6027\u66f4\u65b0HMM\u4ee5\u8986\u76d6\u6240\u6709\u5019\u9009\u8bcd\u5143\uff0c\u5e76\u4f7fHMM\u7684\u9690\u72b6\u6001\u6761\u4ef6\u4ec5\u4f9d\u8d56LM\u7684\u9690\u85cf\u8868\u793a\uff0c\u907f\u514d\u91cd\u590d\u8ba1\u7b97\uff0c\u63d0\u5347\u6548\u7387\u3002", "result": "LTLA\u5b9e\u73b0\u4e86\u6bd4\u65e0\u6761\u4ef6HMM\u66f4\u9ad8\u7684\u6761\u4ef6\u4f3c\u7136\u5ea6\uff0c\u80fd\u591f\u8fd1\u4f3c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u7eed\u5199\u5206\u5e03\uff0c\u63d0\u5347\u53d7\u63a7\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u7ea6\u675f\u6ee1\u8db3\u5ea6\u4e0e\u8bed\u8a00\u6d41\u7545\u5ea6\uff0c\u4e14\u63a8\u7406\u5f00\u9500\u6781\u4f4e\u3002", "conclusion": "LTLA\u6709\u6548\u7ed3\u5408\u4e86\u795e\u7ecf\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u4e0eHMM\u7684\u53ef\u89e3\u6027\uff0c\u514b\u670d\u4e86\u5148\u524d\u65b9\u6cd5\u7684\u8ba1\u7b97\u74f6\u9888\u548c\u4e0a\u4e0b\u6587\u7f3a\u5931\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u63a7\u5236\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2511.15817", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15817", "abs": "https://arxiv.org/abs/2511.15817", "authors": ["Alejandro Velasco", "Daniel Rodriguez-Cardenas", "Dipin Khati", "David N. Palacio", "Luftar Rahman Alif", "Denys Poshyvanyk"], "title": "A Causal Perspective on Measuring, Explaining and Mitigating Smells in \\llm-Generated Code", "comment": null, "summary": "Recent advances in large language models (LLMs) have accelerated their adoption in software engineering contexts. However, concerns persist about the structural quality of the code they produce. In particular, LLMs often replicate poor coding practices, introducing code smells (i.e., patterns that hinder readability, maintainability, or design integrity). Although prior research has examined the detection or repair of smells, we still lack a clear understanding of how and when these issues emerge in generated code.\n  This paper addresses this gap by systematically measuring, explaining and mitigating smell propensity in LLM-generated code. We build on the Propensity Smelly Score (PSC), a probabilistic metric that estimates the likelihood of generating particular smell types, and establish its robustness as a signal of structural quality. Using PSC as an instrument for causal analysis, we identify how generation strategy, model size, model architecture and prompt formulation shape the structural properties of generated code. Our findings show that prompt design and architectural choices play a decisive role in smell propensity and motivate practical mitigation strategies that reduce its occurrence. A user study further demonstrates that PSC helps developers interpret model behavior and assess code quality, providing evidence that smell propensity signals can support human judgement. Taken together, our work lays the groundwork for integrating quality-aware assessments into the evaluation and deployment of LLMs for code.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6982\u7387\u6307\u6807PSC\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u63ed\u793a\u5f71\u54cd\u56e0\u7d20\u5e76\u63d0\u51fa\u7f13\u89e3\u7b56\u7565\uff0c\u9a8c\u8bc1\u4e86PSC\u5728\u8f85\u52a9\u4ee3\u7801\u8d28\u91cf\u8bc4\u4f30\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u5e7f\u6cdb\uff0c\u4f46\u751f\u6210\u4ee3\u7801\u5e38\u542b\u6709\u5f71\u54cd\u53ef\u8bfb\u6027\u548c\u7ef4\u62a4\u6027\u7684\u4ee3\u7801\u5f02\u5473\uff0c\u5c1a\u7f3a\u4e4f\u5bf9\u5f02\u5473\u4ea7\u751f\u673a\u7406\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u57fa\u4e8e\u6982\u7387\u6307\u6807Propensity Smelly Score(PSC)\u7cfb\u7edf\u6d4b\u91cfLLM\u751f\u6210\u4ee3\u7801\u7684\u4ee3\u7801\u5f02\u5473\u503e\u5411\uff0c\u5229\u7528PSC\u8fdb\u884c\u56e0\u679c\u5206\u6790\uff0c\u7814\u7a76\u751f\u6210\u7b56\u7565\u3001\u6a21\u578b\u89c4\u6a21\u3001\u67b6\u6784\u53ca\u63d0\u793a\u8bbe\u8ba1\u5bf9\u4ee3\u7801\u7ed3\u6784\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u63d0\u793a\u8bbe\u8ba1\u548c\u6a21\u578b\u67b6\u6784\u5bf9\u4ee3\u7801\u5f02\u5473\u503e\u5411\u6709\u51b3\u5b9a\u6027\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u6709\u6548\u7684\u51cf\u7f13\u5f02\u5473\u4ea7\u751f\u7684\u7b56\u7565\uff0c\u4e14\u901a\u8fc7\u7528\u6237\u7814\u7a76\u8bc1\u660ePSC\u6709\u52a9\u4e8e\u5f00\u53d1\u8005\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u548c\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\u3002", "conclusion": "PSC\u4f5c\u4e3a\u7ed3\u6784\u8d28\u91cf\u7684\u6307\u6807\uff0c\u53ef\u878d\u5165LLM\u4ee3\u7801\u751f\u6210\u7684\u8bc4\u4f30\u4e0e\u90e8\u7f72\u8fc7\u7a0b\uff0c\u652f\u6301\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u4fc3\u8fdb\u4eba\u673a\u534f\u4f5c\u5224\u65ad\u4ee3\u7801\u8d28\u91cf\u7684\u80fd\u529b\u3002"}}
{"id": "2511.16072", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16072", "abs": "https://arxiv.org/abs/2511.16072", "authors": ["S\u00e9bastien Bubeck", "Christian Coester", "Ronen Eldan", "Timothy Gowers", "Yin Tat Lee", "Alexandru Lupsasca", "Mehtaab Sawhney", "Robert Scherrer", "Mark Sellke", "Brian K. Spears", "Derya Unutmaz", "Kevin Weil", "Steven Yin", "Nikita Zhivotovskiy"], "title": "Early science acceleration experiments with GPT-5", "comment": "89 pages", "summary": "AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.", "AI": {"tldr": "\u672c\u6587\u4ee5\u591a\u4e2a\u6848\u4f8b\u5c55\u793aGPT-5\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u8bc1\u660e\u5176\u5728\u52a0\u901f\u79d1\u7814\u548c\u89e3\u51b3\u590d\u6742\u95ee\u9898\u4e0a\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4ecd\u9700\u4eba\u7c7b\u4e13\u5bb6\u8f85\u52a9\u3002", "motivation": "\u8bb8\u591a\u79d1\u5b66\u5bb6\u5c1a\u672a\u5145\u5206\u8ba4\u8bc6\u524d\u6cbfAI\uff08\u5982GPT-5\uff09\u7684\u6f5c\u529b\u548c\u80fd\u529b\uff0c\u56e0\u6b64\u5e0c\u671b\u901a\u8fc7\u5b9e\u9645\u6848\u4f8b\u5c55\u793aAI\u5982\u4f55\u52a9\u529b\u79d1\u7814\u3002", "method": "\u901a\u8fc7\u5c55\u793a\u591a\u4e2a\u8de8\u5b66\u79d1\u7684\u7b80\u77ed\u6848\u4f8b\u7814\u7a76\uff0c\u8bb0\u5f55\u4eba\u7c7b\u4f5c\u8005\u4e0eGPT-5\u7684\u4e92\u52a8\u8fc7\u7a0b\uff0c\u9a8c\u8bc1\u5176\u5728\u7814\u7a76\u4e2d\u7684\u5177\u4f53\u5e94\u7528\u6548\u679c\u3002", "result": "\u8bba\u6587\u5448\u73b0\u4e86GPT-5\u5728\u6570\u5b66\u3001\u7269\u7406\u3001\u5929\u6587\u5b66\u3001\u8ba1\u7b97\u673a\u79d1\u5b66\u3001\u751f\u7269\u5b66\u548c\u6750\u6599\u79d1\u5b66\u4e2d\u7684\u5e94\u7528\u5b9e\u4f8b\uff0c\u7279\u522b\u5305\u62ec\u56db\u4e2a\u7ecf\u8fc7\u4e25\u683c\u4eba\u7c7b\u9a8c\u8bc1\u7684\u65b0\u6570\u5b66\u6210\u679c\u3002", "conclusion": "GPT-5\u80fd\u591f\u663e\u8457\u52a0\u901f\u79d1\u5b66\u7814\u7a76\u8fc7\u7a0b\uff0c\u5c24\u5176\u5728\u6570\u5b66\u9886\u57df\u5e2e\u52a9\u89e3\u51b3\u4e86\u4e4b\u524d\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u4f46\u4ecd\u9700\u4eba\u7c7b\u4e13\u5bb6\u7684\u53c2\u4e0e\u548c\u9a8c\u8bc1\u3002"}}
{"id": "2511.15852", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15852", "abs": "https://arxiv.org/abs/2511.15852", "authors": ["Monu Sharma"], "title": "AI-Enabled Orchestration of Event-Driven Business Processes in Workday ERP for Healthcare Enterprises", "comment": "10 Pages, 6 figures , 2 Tables", "summary": "The adoption of cloud-based Enterprise Resource Planning (ERP) platforms such as Workday has transformed healthcare operations by integrating financial, supply-chain, and workforce processes into a unified ecosystem. However, traditional workflow logic in ERP systems often lacks the adaptability required to manage event-driven and data-intensive healthcare environments.\n  This study proposes an AI-enabled event-driven orchestration framework within Workday ERP that intelligently synchronizes financial and supply-chain workflows across distributed healthcare entities. The framework employs machine-learning triggers, anomaly detection, and process mining analytics to anticipate and automate responses to operational events such as inventory depletion, payment delays, or patient demand fluctuations. A multi-organization case analysis demonstrates measurable gains in process efficiency, cost visibility, and decision accuracy.\n  Results confirm that embedding AI capabilities into Workday's event-based architecture enhances operational resilience, governance, and scalability. The proposed model contributes to the broader understanding of intelligent ERP integration and establishes a reference for next-generation automation strategies in healthcare enterprises.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eAI\u7684\u4e8b\u4ef6\u9a71\u52a8\u7f16\u6392\u6846\u67b6\uff0c\u96c6\u6210\u4e8eWorkday ERP\u4e2d\uff0c\u7528\u4e8e\u667a\u80fd\u540c\u6b65\u5206\u5e03\u5f0f\u533b\u7597\u673a\u6784\u7684\u8d22\u52a1\u4e0e\u4f9b\u5e94\u94fe\u6d41\u7a0b\uff0c\u63d0\u5347\u6d41\u7a0b\u6548\u7387\u548c\u51b3\u7b56\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edfERP\u7cfb\u7edf\u7684\u5de5\u4f5c\u6d41\u903b\u8f91\u7f3a\u4e4f\u9002\u5e94\u533b\u7597\u73af\u5883\u4e8b\u4ef6\u9a71\u52a8\u548c\u6570\u636e\u5bc6\u96c6\u7279\u6027\u7684\u80fd\u529b\uff0c\u4e9f\u9700\u5f15\u5165\u667a\u80fd\u673a\u5236\u63d0\u5347\u7cfb\u7edf\u9002\u5e94\u6027\u548c\u6548\u7387\u3002", "method": "\u5229\u7528\u673a\u5668\u5b66\u4e60\u89e6\u53d1\u5668\u3001\u5f02\u5e38\u68c0\u6d4b\u548c\u6d41\u7a0b\u6316\u6398\u5206\u6790\uff0c\u81ea\u52a8\u54cd\u5e94\u5e93\u5b58\u4e0d\u8db3\u3001\u652f\u4ed8\u5ef6\u8fdf\u548c\u60a3\u8005\u9700\u6c42\u6ce2\u52a8\u7b49\u8fd0\u8425\u4e8b\u4ef6\uff0c\u5b9e\u73b0\u8de8\u7ec4\u7ec7\u6d41\u7a0b\u667a\u80fd\u540c\u6b65\u3002", "result": "\u591a\u7ec4\u7ec7\u6848\u4f8b\u5206\u6790\u8868\u660e\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6d41\u7a0b\u6548\u7387\u3001\u6210\u672c\u900f\u660e\u5ea6\u548c\u51b3\u7b56\u51c6\u786e\u6027\u3002", "conclusion": "\u5c06AI\u5d4c\u5165Workday\u4e8b\u4ef6\u9a71\u52a8\u67b6\u6784\u663e\u8457\u589e\u5f3a\u4e86\u8fd0\u8425\u5f39\u6027\u3001\u6cbb\u7406\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u533b\u7597\u4f01\u4e1a\u4e0b\u4e00\u4ee3\u81ea\u52a8\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2511.16122", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16122", "abs": "https://arxiv.org/abs/2511.16122", "authors": ["Qing Zhang", "Bing Xu", "Xudong Zhang", "Yifan Shi", "Yang Li", "Chen Zhang", "Yik Chung Wu", "Ngai Wong", "Yijie Chen", "Hong Dai", "Xiansen Chen", "Mian Zhang"], "title": "ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models", "comment": null, "summary": "The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.", "AI": {"tldr": "\u63d0\u51faELPO\uff0c\u901a\u8fc7\u96c6\u6210\u5b66\u4e60\u63d0\u5347\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6548\u679c\uff0c\u5728\u591a\u4efb\u52a1\u4e2d\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\u6216\u7b97\u6cd5\uff0c\u9650\u5236\u4e86\u5176\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff08ELPO\uff09\uff0c\u7ed3\u5408\u6295\u7968\u673a\u5236\u3001\u5171\u4eab\u751f\u6210\u7b56\u7565\u548c\u591a\u6837\u5316\u641c\u7d22\u65b9\u6cd5\u4f18\u5316\u63d0\u793a\u8bcd\u751f\u6210\u8fc7\u7a0b\u3002", "result": "ELPO\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u5982\u5728ArSarcasm\u6570\u636e\u96c6\u4e0aF1\u5206\u6570\u63d0\u53477.6\u3002", "conclusion": "\u57fa\u4e8e\u96c6\u6210\u5b66\u4e60\u7684ELPO\u6846\u67b6\u80fd\u591f\u751f\u6210\u66f4\u7cbe\u786e\u3001\u9c81\u68d2\u7684\u63d0\u793a\uff0c\u4fc3\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u5de5\u7a0b\u7684\u81ea\u52a8\u5316\u548c\u5b9e\u7528\u5316\u3002"}}
{"id": "2511.15859", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.15859", "abs": "https://arxiv.org/abs/2511.15859", "authors": ["Hina Saeeda", "Mazen Mohamad", "Eric Knauss", "Jennifer Horkoff", "Ali Nouri"], "title": "RE for AI in Practice: Managing Data Annotation Requirements for AI Autonomous Driving Systems", "comment": null, "summary": "High-quality data annotation requirements are crucial for the development of safe and reliable AI-enabled perception systems (AIePS) in autonomous driving. Although these requirements play a vital role in reducing bias and enhancing performance, their formulation and management remain underexplored, leading to inconsistencies, safety risks, and regulatory concerns. Our study investigates how annotation requirements are defined and used in practice, the challenges in ensuring their quality, practitioner-recommended improvements, and their impact on AIePS development and performance. We conducted $19$ semi-structured interviews with participants from six international companies and four research organisations. Our thematic analysis reveals five main key challenges: ambiguity, edge case complexity, evolving requirements, inconsistencies, and resource constraints and three main categories of best practices, including ensuring compliance with ethical standards, improving data annotation requirements guidelines, and embedded quality assurance for data annotation requirements. We also uncover critical interrelationships between annotation requirements, annotation practices, annotated data quality, and AIePS performance and development, showing how requirement flaws propagate through the AIePS development pipeline. To the best of our knowledge, this study is the first to offer empirically grounded guidance on improving annotation requirements, offering actionable insights to enhance annotation quality, regulatory compliance, and system reliability. It also contributes to the emerging fields of Software Engineering (SE for AI) and Requirements Engineering (RE for AI) by bridging the gap between RE and AI in a timely and much-needed manner.", "AI": {"tldr": "\u7814\u7a76\u901a\u8fc7\u8bbf\u8c08\u5206\u6790\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u7684\u6570\u636e\u6807\u6ce8\u9700\u6c42\uff0c\u53d1\u73b0\u4e3b\u8981\u6311\u6218\u4e0e\u6539\u8fdb\u65b9\u6cd5\uff0c\u63d0\u51fa\u5b9e\u8bc1\u6307\u5bfc\u4ee5\u63d0\u9ad8\u6807\u6ce8\u8d28\u91cf\u548c\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u52a9\u529bAI\u7cfb\u7edf\u5b89\u5168\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u9a7e\u9a76\u4e2d\u7684AI\u611f\u77e5\u7cfb\u7edf\u5bf9\u9ad8\u8d28\u91cf\u6570\u636e\u6807\u6ce8\u9700\u6c42\u8feb\u5207\uff0c\u4f46\u6807\u6ce8\u9700\u6c42\u7684\u5236\u5b9a\u4e0e\u7ba1\u7406\u4e0d\u8db3\uff0c\u5bfc\u81f4\u4e0d\u4e00\u81f4\u6027\u3001\u5b89\u5168\u98ce\u9669\u53ca\u5408\u89c4\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf9\u516d\u5bb6\u56fd\u9645\u516c\u53f8\u548c\u56db\u4e2a\u7814\u7a76\u673a\u6784\u768419\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u91c7\u7528\u4e3b\u9898\u5206\u6790\u65b9\u6cd5\u63a2\u8ba8\u6807\u6ce8\u9700\u6c42\u7684\u5b9a\u4e49\u3001\u4f7f\u7528\u53ca\u5176\u8d28\u91cf\u4fdd\u969c\u6311\u6218\u548c\u6539\u8fdb\u63aa\u65bd\u3002", "result": "\u8bc6\u522b\u51fa\u6807\u6ce8\u9700\u6c42\u9762\u4e34\u7684\u4e94\u5927\u6311\u6218\uff08\u6b67\u4e49\u3001\u8fb9\u7f18\u6848\u4f8b\u590d\u6742\u6027\u3001\u9700\u6c42\u6f14\u53d8\u3001\u4e0d\u4e00\u81f4\u6027\u3001\u8d44\u6e90\u9650\u5236\uff09\u53ca\u4e09\u5927\u6700\u4f73\u5b9e\u8df5\uff08\u5408\u4f26\u7406\u6807\u51c6\u3001\u6539\u8fdb\u6807\u6ce8\u6307\u5bfc\u3001\u5d4c\u5165\u8d28\u91cf\u4fdd\u969c\uff09\uff0c\u63ed\u793a\u6807\u6ce8\u9700\u6c42\u7f3a\u9677\u5982\u4f55\u5f71\u54cdAI\u611f\u77e5\u7cfb\u7edf\u5f00\u53d1\u548c\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u9996\u6b21\u57fa\u4e8e\u5b9e\u8bc1\u4e3a\u6539\u8fdb\u6807\u6ce8\u9700\u6c42\u63d0\u4f9b\u6307\u5bfc\uff0c\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\u3001\u5408\u89c4\u6027\u4e0e\u7cfb\u7edf\u53ef\u9760\u6027\uff0c\u4fc3\u8fdb\u8f6f\u4ef6\u5de5\u7a0b\u4e0e\u9700\u6c42\u5de5\u7a0b\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u878d\u5408\uff0c\u4e3aAI\u611f\u77e5\u7cfb\u7edf\u7684\u5b89\u5168\u53ef\u9760\u53d1\u5c55\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.16147", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16147", "abs": "https://arxiv.org/abs/2511.16147", "authors": ["Dabiao Ma", "Ziming Dai", "Zhimin Xin", "Shu Wang", "Ye Wang", "Haojun Fei"], "title": "TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating", "comment": "11 pages, 3 figures", "summary": "In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9009\u62e9\u6027\u4f4d\u7f6e\u7d22\u5f15\u7684PEFT\uff08TS-PEFT\uff09\uff0c\u8bc1\u5b9e\u6709\u9488\u5bf9\u6027\u7684\u5fae\u8c03\u4f18\u4e8e\u4f20\u7edf\u5bf9\u6240\u6709\u4f4d\u7f6e\u7d22\u5f15\u5fae\u8c03\u7684\u65b9\u6cd5\u3002", "motivation": "\u8d28\u7591\u4f20\u7edfPEFT\u5bf9\u6240\u6709\u4f4d\u7f6e\u7d22\u5f15\u4e00\u89c6\u540c\u4ec1\u7684\u8c03\u6574\u662f\u5426\u5fc5\u8981\uff0c\u5bfb\u6c42\u66f4\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86Token-Selective PEFT\uff08TS-PEFT\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u51fd\u6570S\u9009\u62e9\u6027\u5730\u5728\u90e8\u5206\u4f4d\u7f6e\u7d22\u5f15\u4e0a\u5e94\u7528PEFT\u4fee\u6539\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u9009\u62e9\u6027\u5e94\u7528PEFT\u4fee\u6539\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u5168\u9762\u8c03\u6574\u53cd\u800c\u591a\u4f59\u4e14\u53ef\u80fd\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u4f20\u7edfPEFT\u65b9\u6cd5\u5bf9\u6240\u6709\u4f4d\u7f6e\u7d22\u5f15\u5e94\u7528\u8c03\u6574\u662f\u4e0d\u5fc5\u8981\u4e14\u53ef\u80fd\u6709\u5bb3\u7684\uff0c\u9009\u62e9\u6027\u5e94\u7528PEFT\u4fee\u6539\u66f4\u6709\u5229\u4e8e\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.16004", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16004", "abs": "https://arxiv.org/abs/2511.16004", "authors": ["KeFan Li", "Mengfei Wang", "Hengzhi Zhang", "Zhichao Li", "Yuan Yuan", "Mu Li", "Xiang Gao", "Hailong Sun", "Chunming Hu", "Weifeng Lv"], "title": "InfCode: Adversarial Iterative Refinement of Tests and Patches for Reliable Software Issue Resolution", "comment": null, "summary": "Large language models have advanced software engineering automation, yet resolving real-world software issues remains difficult because it requires repository-level reasoning, accurate diagnostics, and strong verification signals. Existing agent-based and pipeline-based methods often rely on insufficient tests, which can lead to patches that satisfy verification but fail to fix the underlying defect. We present InfCode, an adversarial multi-agent framework for automated repository-level issue resolution. InfCode iteratively refines both tests and patches through adversarial interaction between a Test Patch Generator and a Code Patch Generator, while a Selector agent identifies the most reliable fix. The framework runs inside a containerized environment that supports realistic repository inspection, modification, and validation. Experiments on SWE-bench Lite and SWE-bench Verified using models such as DeepSeek-V3 and Claude 4.5 Sonnet show that InfCode consistently outperforms strong baselines. It achieves 79.4% performance on SWE-bench Verified, establishing a new state-of-the-art. We have released InfCode as an open-source project at https://github.com/Tokfinity/InfCode.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InfCode\uff0c\u4e00\u79cd\u7528\u4e8e\u81ea\u52a8\u89e3\u51b3\u4ed3\u5e93\u7ea7\u8f6f\u4ef6\u95ee\u9898\u7684\u5bf9\u6297\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8ba9\u6d4b\u8bd5\u751f\u6210\u5668\u548c\u4ee3\u7801\u8865\u4e01\u751f\u6210\u5668\u76f8\u4e92\u5bf9\u6297\u8fed\u4ee3\uff0c\u63d0\u5347\u6d4b\u8bd5\u548c\u8865\u4e01\u8d28\u91cf\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u771f\u5b9e\u8f6f\u4ef6\u7f3a\u9677\u7684\u6709\u6548\u4fee\u590d\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u667a\u80fd\u4f53\u6216\u6d41\u6c34\u7ebf\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e0d\u8db3\u7684\u6d4b\u8bd5\uff0c\u867d\u9a8c\u8bc1\u901a\u8fc7\u4f46\u53ef\u80fd\u672a\u4fee\u590d\u6839\u672c\u7f3a\u9677\uff0c\u96be\u4ee5\u89e3\u51b3\u771f\u5b9e\u4e16\u754c\u7684\u8f6f\u4ef6\u95ee\u9898\u3002", "method": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6d4b\u8bd5\u8865\u4e01\u751f\u6210\u5668\u548c\u4ee3\u7801\u8865\u4e01\u751f\u6210\u5668\u4e4b\u95f4\u7684\u5bf9\u6297\u4ea4\u4e92\uff0c\u8fed\u4ee3\u7cbe\u70bc\u6d4b\u8bd5\u548c\u8865\u4e01\uff0c\u4f7f\u7528\u9009\u62e9\u5668\u667a\u80fd\u4f53\u786e\u5b9a\u6700\u53ef\u9760\u7684\u4fee\u590d\u65b9\u6848\uff0c\u6846\u67b6\u8fd0\u884c\u4e8e\u652f\u6301\u771f\u5b9e\u4ed3\u5e93\u64cd\u4f5c\u7684\u5bb9\u5668\u5316\u73af\u5883\u4e2d\u3002", "result": "\u5728SWE-bench Lite\u548cSWE-bench Verified\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u4f7f\u7528DeepSeek-V3\u548cClaude 4.5 Sonnet\u6a21\u578b\uff0cInfCode\u5747\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u53d1\u5e03\u4e86\u5f00\u6e90\u4ee3\u7801\u3002", "conclusion": "InfCode\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u65b9\u6cd5\uff0c\u8fbe\u523079.4%\u7684\u6027\u80fd\uff0c\u786e\u7acb\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002"}}
{"id": "2511.16198", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2511.16198", "abs": "https://arxiv.org/abs/2511.16198", "authors": ["Sebastian Haan"], "title": "SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning", "comment": "21 pages, 4 figures", "summary": "Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SemanticCite\uff0c\u4e00\u79cd\u57fa\u4e8eAI\u7684\u5f15\u7528\u9a8c\u8bc1\u7cfb\u7edf\uff0c\u901a\u8fc7\u5168\u6587\u5206\u6790\u548c\u56db\u7c7b\u5206\u7c7b\u673a\u5236\uff0c\u5b9e\u73b0\u5bf9\u5f15\u7528\u51c6\u786e\u6027\u7684\u9ad8\u6548\u9a8c\u8bc1\u548c\u89e3\u91ca\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e94\u7528\u5e76\u5f00\u6e90\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u5f53\u524d\u5b66\u672f\u6587\u732e\u5b58\u5728\u8bed\u4e49\u6027\u5f15\u7528\u9519\u8bef\u3001AI\u751f\u6210\u7684\u865a\u5047\u5f15\u7528\u53ca\u4f20\u7edf\u5f15\u7528\u683c\u5f0f\u6a21\u7cca\u5177\u4f53\u5173\u8054\u7b49\u95ee\u9898\uff0c\u4e25\u91cd\u5f71\u54cd\u79d1\u7814\u8bda\u4fe1\u548c\u5b66\u672f\u4ea4\u6d41\u7684\u51c6\u786e\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u5f15\u7528\u9a8c\u8bc1\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u7684\u591a\u91cd\u68c0\u7d22\u4e0e\u56db\u5206\u7c7b\u7cfb\u7edf\uff08\u652f\u6301\u3001\u90e8\u5206\u652f\u6301\u3001\u4e0d\u652f\u6301\u3001\u4e0d\u786e\u5b9a\uff09\uff0c\u7ed3\u5408\u8be6\u7ec6\u8bed\u4e49\u6ce8\u91ca\u548c\u6587\u672c\u7247\u6bb5\uff0c\u5b9e\u73b0\u5bf9\u5f15\u7528\u7684\u51c6\u786e\u9a8c\u8bc1\u548c\u9519\u8bef\u5206\u7c7b\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSemanticCite\u7684AI\u9a71\u52a8\u7cfb\u7edf\uff0c\u901a\u8fc7\u5168\u6587\u5206\u6790\u6e90\u6587\u732e\u9a8c\u8bc1\u5f15\u7528\u7684\u51c6\u786e\u6027\uff0c\u5e76\u63d0\u4f9b\u8be6\u7ec6\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u76f8\u5173\u6587\u672c\u7247\u6bb5\u3002\u8be5\u7cfb\u7edf\u7ed3\u5408\u591a\u79cd\u68c0\u7d22\u65b9\u6cd5\u548c\u56db\u7c7b\u5206\u7c7b\u673a\u5236\uff08\u652f\u6301\u3001\u90e8\u5206\u652f\u6301\u3001\u4e0d\u652f\u6301\u3001\u4e0d\u786e\u5b9a\uff09\uff0c\u51c6\u786e\u6355\u6349\u6587\u732e\u4e0e\u8bba\u65ad\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5e76\u80fd\u9488\u5bf9\u4e0d\u540c\u7684\u9519\u8bef\u7c7b\u578b\u91c7\u53d6\u76f8\u5e94\u63aa\u65bd\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u7ecf\u8fc7\u5fae\u8c03\u7684\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u53ef\u5ab2\u7f8e\u5927\u578b\u5546\u4e1a\u7cfb\u7edf\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u663e\u8457\u964d\u4f4e\uff0c\u9002\u5408\u5927\u89c4\u6a21\u5e94\u7528\u3002\u6b64\u5916\uff0c\u7cfb\u7edf\u63d0\u4f9b\u900f\u660e\u4e14\u57fa\u4e8e\u8bc1\u636e\u7684\u89e3\u91ca\uff0c\u589e\u5f3a\u7528\u6237\u7684\u4fe1\u4efb\u548c\u7406\u89e3\u3002\u4f5c\u8005\u8fd8\u8d21\u732e\u4e86\u5305\u542b1000\u591a\u4e2a\u5f15\u7528\u7684\u7efc\u5408\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u5fae\u8c03\u6a21\u578b\u548c\u5b8c\u6574\u9a8c\u8bc1\u6846\u67b6\u7684\u5f00\u6e90\u8f6f\u4ef6\u3002\u8be5\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86\u5b66\u672f\u5f15\u7528\u7684\u51c6\u786e\u6027\uff0c\u6709\u52a9\u4e8e\u4fc3\u8fdb\u7814\u7a76\u8bda\u4fe1\u3001\u7b80\u5316\u540c\u884c\u8bc4\u5ba1\u53ca\u63a7\u5236AI\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u3002", "conclusion": "SemanticCite\u6709\u6548\u89e3\u51b3\u4e86\u5b66\u672f\u5f15\u7528\u4e2d\u7684\u8bed\u4e49\u9519\u8bef\u548cAI\u865a\u5047\u5f15\u7528\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u3001\u900f\u660e\u4e14\u53ef\u6269\u5c55\u7684\u5f15\u7528\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u79d1\u7814\u8bda\u4fe1\u548c\u8d28\u91cf\u63a7\u5236\u6c34\u5e73\u3002"}}
{"id": "2511.16005", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16005", "abs": "https://arxiv.org/abs/2511.16005", "authors": ["Qingao Dong", "Mengfei Wang", "Hengzhi Zhang", "Zhichao Li", "Yuan Yuan", "Mu Li", "Xiang Gao", "Hailong Sun", "Chunming Hu", "Weifeng Lv"], "title": "InfCode-C++: Intent-Guided Semantic Retrieval and AST-Structured Search for C++ Issue Resolution", "comment": null, "summary": "Large language model (LLM) agents have recently shown strong performance on repository-level issue resolution, but existing systems are almost exclusively designed for Python and rely heavily on lexical retrieval and shallow code navigation. These approaches transfer poorly to C++ projects, where overloaded identifiers, nested namespaces, template instantiations, and deep control-flow structures make context retrieval and fault localization substantially more difficult. As a result, state-of-the-art Python-oriented agents show a drastic performance drop on the C++ subset of MultiSWE-bench. We introduce INFCODE-C++, the first C++-aware autonomous system for end-to-end issue resolution. The system combines two complementary retrieval mechanisms -- semantic code-intent retrieval and deterministic AST-structured querying -- to construct accurate, language-aware context for repair.These components enable precise localization and robust patch synthesis in large, statically typed C++ repositories. Evaluated on the \\texttt{MultiSWE-bench-CPP} benchmark, INFCODE-C++ achieves a resolution rate of 25.58\\%, outperforming the strongest prior agent by 10.85 percentage points and more than doubling the performance of MSWE-agent. Ablation and behavioral studies further demonstrate the critical role of semantic retrieval, structural analysis, and accurate reproduction in C++ issue resolution. INFCODE-C++ highlights the need for language-aware reasoning in multi-language software agents and establishes a foundation for future research on scalable, LLM-driven repair for complex, statically typed ecosystems.", "AI": {"tldr": "INFCODE-C++\u662f\u4e00\u79cd\u9996\u4e2a\u9488\u5bf9C++\u95ee\u9898\u89e3\u51b3\u7684\u81ea\u4e3b\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u548c\u7ed3\u6784\u5316\u67e5\u8be2\u76f8\u7ed3\u5408\u63d0\u5347\u4e86\u4e0a\u4e0b\u6587\u68c0\u7d22\u548c\u9519\u8bef\u5b9a\u4f4d\u6027\u80fd\uff0c\u5728C++\u9879\u76ee\u81ea\u52a8\u4fee\u590d\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u4fee\u590d\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9Python\uff0c\u5bf9C++\u4e2d\u590d\u6742\u7684\u547d\u540d\u548c\u7ed3\u6784\u652f\u6301\u4e0d\u8db3\uff0c\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff0c\u4e9f\u9700\u8bbe\u8ba1\u9002\u5408C++\u7684\u591a\u8bed\u8a00\u611f\u77e5\u4fee\u590d\u7cfb\u7edf\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u8bed\u4e49\u4ee3\u7801\u610f\u56fe\u68c0\u7d22\u548c\u786e\u5b9a\u6027AST\u7ed3\u6784\u5316\u67e5\u8be2\u4e24\u79cd\u4e92\u8865\u673a\u5236\uff0c\u6784\u5efa\u51c6\u786e\u7684\u8bed\u8a00\u611f\u77e5\u4e0a\u4e0b\u6587\uff0c\u5b9e\u73b0\u7cbe\u51c6\u5b9a\u4f4d\u548c\u7a33\u5b9a\u8865\u4e01\u5408\u6210\u3002", "result": "\u5728MultiSWE-bench-CPP\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cINFCODE-C++\u8fbe\u523025.58%\u7684\u95ee\u9898\u89e3\u51b3\u7387\uff0c\u6bd4\u73b0\u6709\u6700\u597d\u6a21\u578b\u63d0\u5347\u4e8610.85\u4e2a\u767e\u5206\u70b9\uff0c\u6027\u80fd\u8d85\u8fc7MSWE-agent\u4e24\u500d\u4ee5\u4e0a\u3002", "conclusion": "INFCODE-C++\u7cfb\u7edf\u5728C++\u9879\u76ee\u81ea\u52a8\u4fee\u590d\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5f3a\u8c03\u8bed\u8a00\u611f\u77e5\u68c0\u7d22\u548c\u7ed3\u6784\u5316\u5206\u6790\u5bf9\u590d\u6742\u9759\u6001\u7c7b\u578b\u8bed\u8a00\u95ee\u9898\u89e3\u51b3\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.16275", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16275", "abs": "https://arxiv.org/abs/2511.16275", "authors": ["Xingtao Zhao", "Hao Peng", "Dingli Su", "Xianghua Zeng", "Chunyang Liu", "Jinzhi Liao", "Philip S. Yu"], "title": "SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs", "comment": "14 pages of main text and 10 pages of appendices", "summary": "Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bed\u4e49\u7ed3\u6784\u71b5\u7684\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5SeSE\uff0c\u901a\u8fc7\u6355\u83b7\u8bed\u4e49\u7ed3\u6784\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u66f4\u7cbe\u786e\u7684\u5e7b\u89c9\u68c0\u6d4b\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff08UQ\uff09\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8bed\u4e49\u6982\u7387\u5206\u5e03\u6216\u6210\u5bf9\u8ddd\u79bb\uff0c\u5ffd\u7565\u4e86\u6f5c\u5728\u7684\u8bed\u4e49\u7ed3\u6784\u4fe1\u606f\uff0c\u5bfc\u81f4\u65e0\u6cd5\u51c6\u786e\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\uff0c\u96be\u4ee5\u6709\u6548\u9632\u6b62\u751f\u6210\u5e7b\u89c9\u5185\u5bb9\u3002", "method": "\u63d0\u51fa\u4e86\u8bed\u4e49\u7ed3\u6784\u71b5\uff08SeSE\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u81ea\u9002\u5e94\u7a00\u758f\u7684\u6709\u5411\u8bed\u4e49\u56fe\u6355\u83b7\u65b9\u5411\u6027\u8bed\u4e49\u4f9d\u8d56\uff0c\u5e76\u901a\u8fc7\u5c42\u6b21\u5316\u62bd\u8c61\u5b9a\u4e49\u6700\u4f18\u8bed\u4e49\u7f16\u7801\u6811\u7684\u7ed3\u6784\u71b5\u6765\u91cf\u5316\u8bed\u4e49\u7a7a\u95f4\u4e2d\u7684\u5185\u5728\u4e0d\u786e\u5b9a\u6027\u3002SeSE\u7684\u503c\u8d8a\u9ad8\u8868\u793a\u4e0d\u786e\u5b9a\u6027\u8d8a\u5927\uff0c\u80fd\u591f\u6709\u6548\u68c0\u6d4b\u5e7b\u89c9\u3002\u6b64\u5916\uff0cSeSE\u6269\u5c55\u5230\u5bf9\u957f\u6587\u672c\u751f\u6210\u4e2d\u4e2a\u522b\u9648\u8ff0\u7684\u4e0d\u786e\u5b9a\u6027\u8fdb\u884c\u7ec6\u7c92\u5ea6\u91cf\u5316\uff0c\u7406\u8bba\u4e0a\u89e3\u91ca\u5e7b\u89c9\u68c0\u6d4b\u3002", "result": "\u572829\u4e2a\u6a21\u578b-\u6570\u636e\u96c6\u7ec4\u5408\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0cSeSE\u663e\u8457\u4f18\u4e8e\u5148\u8fdb\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5305\u62ec\u5f3a\u76d1\u7763\u65b9\u6cd5\u548c\u6700\u65b0\u7684KLE\u65b9\u6cd5\u3002", "conclusion": "SeSE\u901a\u8fc7\u5f15\u5165\u6f5c\u5728\u8bed\u4e49\u7ed3\u6784\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u7684\u8bed\u8a00\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4e3a\u9632\u6b62\u8bed\u8a00\u6a21\u578b\u5728\u5b89\u5168\u5173\u952e\u573a\u666f\u4e2d\u751f\u6210\u5e7b\u89c9\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.16092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16092", "abs": "https://arxiv.org/abs/2511.16092", "authors": ["Xing Hu", "Raula Gaikovina Kula", "Christoph Treude"], "title": "The Future of Development Environments with AI Foundation Models: NII Shonan Meeting 222 Report", "comment": null, "summary": "Generative Artificial Intelligence (GenAI) models are achieving remarkable performance in various tasks, including code generation, testing, code review, and program repair. The ability to increase the level of abstraction away from writing code has the potential to change the Human-AI interaction within the integrated development environment (IDE). To explore the impact of GenAI on IDEs, 33 experts from the Software Engineering, Artificial Intelligence, and Human-Computer Interaction domains gathered to discuss challenges and opportunities at Shonan Meeting 222. This is the report", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e8633\u4f4d\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u5de5\u667a\u80fd\u53ca\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u4e13\u5bb6\u5728\u6e58\u5357\u4f1a\u8bae222\u4e0a\u5173\u4e8e\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5bf9\u96c6\u6210\u5f00\u53d1\u73af\u5883\uff08IDE\uff09\u5f71\u54cd\u7684\u8ba8\u8bba\u3002", "motivation": "\u63a2\u7d22\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5728\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u3001\u5ba1\u67e5\u548c\u4fee\u590d\u7b49\u4efb\u52a1\u4e2d\u7684\u4f18\u79c0\u8868\u73b0\uff0c\u53ca\u5176\u5bf9\u63d0\u5347IDE\u4eba\u673a\u4ea4\u4e92\u62bd\u8c61\u7ea7\u522b\u7684\u6f5c\u529b\u3002", "method": "\u7ec4\u7ec733\u4f4d\u6765\u81ea\u8f6f\u4ef6\u5de5\u7a0b\u3001\u4eba\u5de5\u667a\u80fd\u548c\u4eba\u673a\u4ea4\u4e92\u9886\u57df\u7684\u4e13\u5bb6\u5728\u6e58\u5357\u4f1a\u8bae222\u4e2d\u8fdb\u884c\u9762\u5bf9\u9762\u8ba8\u8bba\uff0c\u6c47\u96c6\u591a\u9886\u57df\u89c6\u89d2\u3002", "result": "\u603b\u7ed3\u4e86GenAI\u5e94\u7528\u4e8eIDE\u7684\u6311\u6218\u4e0e\u673a\u9047\uff0c\u4e3a\u672a\u6765\u76f8\u5173\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u65b9\u5411\u3002", "conclusion": "\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u6709\u671b\u663e\u8457\u6539\u53d8\u96c6\u6210\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u4eba\u673a\u4ea4\u4e92\u65b9\u5f0f\uff0c\u4f46\u4ecd\u5b58\u5728\u8bf8\u591a\u6311\u6218\u9700\u8981\u89e3\u51b3\u3002"}}
{"id": "2511.16324", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16324", "abs": "https://arxiv.org/abs/2511.16324", "authors": ["Wei Xia", "Zhi-Hong Deng"], "title": "SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning", "comment": null, "summary": "With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u6a21\u578b\u5bf9\u9f50\u65b9\u6cd5SDA\uff0c\u901a\u8fc7\u52a8\u6001\u6982\u7387\u8c03\u6574\u5b9e\u73b0\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u4e0e\u4eba\u7c7b\u610f\u56fe\u7684\u6709\u6548\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3001\u8bda\u5b9e\u6027\u548c\u5b89\u5168\u6027\uff0c\u4e14\u517c\u5bb9\u6027\u548c\u8d44\u6e90\u6548\u7387\u5747\u4f18\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u5e7f\u6cdb\u90e8\u7f72\uff0c\u786e\u4fdd\u5176\u8f93\u51fa\u54cd\u5e94\u7b26\u5408\u4eba\u7c7b\u610f\u56fe\u53d8\u5f97\u5173\u952e\uff0c\u5c24\u5176\u662f\u5728\u65e0\u9700\u6602\u8d35\u518d\u8bad\u7ec3\u6216\u5927\u91cf\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\u9ad8\u6548\u5b9e\u73b0\u6a21\u578b\u884c\u4e3a\u5bf9\u9f50\u662f\u4e00\u5927\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSDA\uff08Steering-Driven Distribution Alignment\uff09\u7684\u8bad\u7ec3\u514d\u8d39\u4e14\u6a21\u578b\u65e0\u5173\u7684\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u91cd\u65b0\u5206\u914d\u6a21\u578b\u8f93\u51fa\u6982\u7387\u6765\u5b9e\u73b0\u7528\u6237\u5b9a\u4e49\u7684\u5bf9\u9f50\u6307\u4ee4\u3002\u8be5\u65b9\u6cd5\u8f7b\u91cf\u7ea7\u3001\u8d44\u6e90\u6548\u7387\u9ad8\uff0c\u53ef\u5728\u63a8\u7406\u9636\u6bb5\u72ec\u7acb\u8fd0\u884c\u6216\u4e0e\u57fa\u4e8e\u8bad\u7ec3\u7684\u5bf9\u9f50\u7b56\u7565\u7ed3\u5408\u4f7f\u7528\uff0c\u5e76\u652f\u6301\u4e2a\u6027\u5316\u504f\u597d\u5bf9\u9f50\u3002", "result": "\u5728\u516b\u79cd\u4e0d\u540c\u89c4\u6a21\u548c\u6765\u6e90\u7684\u5f00\u6e90LLMs\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0cSDA\u5728\u4e09\u4e2a\u5173\u952e\u5bf9\u9f50\u7ef4\u5ea6\u2014\u2014\u6709\u7528\u6027\uff08helpfulness\uff09\u3001\u8bda\u5b9e\u6027\uff08honesty\uff09\u548c\u65e0\u5bb3\u6027\uff08harmlessness\uff09\u4e0a\u5747\u663e\u8457\u63d0\u5347\u8868\u73b0\uff0c\u5e73\u5747\u5206\u522b\u63d0\u534764.4%\u300130%\u548c11.5%\u3002", "conclusion": "SDA\u4f5c\u4e3a\u4e00\u79cd\u8f7b\u91cf\u4e14\u9ad8\u6548\u7684\u8bad\u7ec3\u514d\u8d39\u5bf9\u9f50\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u9636\u6bb5\u884c\u4e3a\u5bf9\u9f50\u7684\u96be\u9898\uff0c\u5177\u5907\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u4e2a\u6027\u5316\u63a7\u5236\u80fd\u529b\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2dLLMs\u7684\u5b89\u5168\u548c\u5b9e\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.16123", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16123", "abs": "https://arxiv.org/abs/2511.16123", "authors": ["Linyi Han", "Shidong Pan", "Zhenchang Xing", "Sofonias Yitagesu", "Xiaowang Zhang", "Zhiyong Feng", "Jiamou Sun", "Qing Huang"], "title": "Domain-constrained Synthesis of Inconsistent Key Aspects in Textual Vulnerability Descriptions", "comment": null, "summary": "Textual Vulnerability Descriptions (TVDs) are crucial for security analysts to understand and address software vulnerabilities. However, the key aspect inconsistencies in TVDs from different repositories pose challenges for achieving a comprehensive understanding of vulnerabilities. Existing approaches aim to mitigate inconsistencies by aligning TVDs with external knowledge bases, but they often discard valuable information and fail to synthesize comprehensive representations. In this paper, we propose a domain-constrained LLM-based synthesis framework for unifying key aspects of TVDs. Our framework consists of three stages: 1) Extraction, guided by rule-based templates to ensure all critical details are captured; 2) Self-evaluation, using domain-specific anchor words to assess semantic variability across sources; and 3) Fusion, leveraging information entropy to reconcile inconsistencies and prioritize relevant details. This framework improves synthesis performance, increasing the F1 score for key aspect augmentation from 0.82 to 0.87, while enhancing comprehension and efficiency by over 30\\%. We further develop Digest Labels, a practical tool for visualizing TVDs, which human evaluations show significantly boosts usability.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6f0f\u6d1e\u63cf\u8ff0\u4e2d\u4fe1\u606f\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u5229\u7528\u9886\u57df\u7ea6\u675f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e09\u9636\u6bb5\u5408\u6210\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u4fe1\u606f\u7684\u7edf\u4e00\u6027\u548c\u5206\u6790\u6548\u7387\u3002", "motivation": "\u4e0d\u540c\u8f6f\u4ef6\u6f0f\u6d1e\u63cf\u8ff0\u5e93\u4e2d\u7684\u6587\u672c\u6f0f\u6d1e\u63cf\u8ff0\uff08TVDs\uff09\u5b58\u5728\u5173\u952e\u65b9\u9762\u4e0d\u4e00\u81f4\uff0c\u5f71\u54cd\u5b89\u5168\u5206\u6790\u4eba\u5458\u5bf9\u6f0f\u6d1e\u7684\u5168\u9762\u7406\u89e3\u3002\u73b0\u6709\u65b9\u6cd5\u5bf9\u9f50\u5916\u90e8\u77e5\u8bc6\u5e93\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u6709\u4ef7\u503c\u7684\u4fe1\u606f\uff0c\u96be\u4ee5\u7efc\u5408\u5168\u9762\u7684\u8868\u793a\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u9886\u57df\u7ea6\u675f\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5408\u6210\u6846\u67b6\uff0c\u5305\u542b\u4e09\u4e2a\u9636\u6bb5\uff1a1\uff09\u57fa\u4e8e\u89c4\u5219\u6a21\u677f\u63d0\u53d6\u5173\u952e\u7ec6\u8282\uff1b2\uff09\u5229\u7528\u9886\u57df\u951a\u8bcd\u8fdb\u884c\u81ea\u6211\u8bc4\u4f30\u8bed\u4e49\u53d8\u5f02\uff1b3\uff09\u901a\u8fc7\u4fe1\u606f\u71b5\u878d\u5408\u4e0d\u4e00\u81f4\u4fe1\u606f\uff0c\u4f18\u5148\u8003\u8651\u76f8\u5173\u7ec6\u8282\u3002", "result": "\u8be5\u6846\u67b6\u5c06\u5173\u952e\u65b9\u9762\u589e\u5f3a\u7684F1\u5206\u6570\u4ece0.82\u63d0\u9ad8\u52300.87\uff0c\u63d0\u5347\u4e86\u8d85\u8fc730%\u7684\u7406\u89e3\u6548\u7387\u548c\u6548\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86TVDs\u4e2d\u7684\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u6f0f\u6d1e\u63cf\u8ff0\u7684\u7efc\u5408\u5ea6\u548c\u5b89\u5168\u5206\u6790\u7684\u6548\u7387\uff0c\u4e14\u5f00\u53d1\u7684Digest Labels\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u53ef\u7528\u6027\u3002"}}
{"id": "2511.16331", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16331", "abs": "https://arxiv.org/abs/2511.16331", "authors": ["Jiashu Yao", "Heyan Huang", "Shuang Zeng", "Chuwei Luo", "WangJie You", "Jie Tang", "Qingsong Liu", "Yuhang Guo", "Yangyang Kang"], "title": "Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement", "comment": "Accepted to AAAI 2026", "summary": "Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only \"simple\" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u6a21\u578b\u81ea\u6211\u91cd\u5199\u63a8\u7406\u6587\u672c\u7684\u65b9\u6cd5\uff0c\u6539\u5584\u63a8\u7406\u8d28\u91cf\uff0c\u63d0\u5347\u51c6\u786e\u7387\u5e76\u7f29\u77ed\u63a8\u7406\u957f\u5ea6\uff0c\u6709\u6548\u4f18\u5316\u4e86\u63a8\u7406\u8fc7\u7a0b\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u4ec5\u4ee5\u6700\u7ec8\u6b63\u786e\u6027\u5956\u52b1\u4e3a\u76ee\u6807\uff0c\u7f3a\u4e4f\u5bf9\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u7684\u7ec6\u81f4\u76d1\u7763\uff0c\u5bfc\u81f4\u63a8\u7406\u8d28\u91cf\u4e0d\u7406\u60f3\uff0c\u5b58\u5728\u591a\u79cd\u63a8\u7406\u7f3a\u9677\uff0c\u4e9f\u9700\u6539\u8fdb\u5185\u90e8\u63a8\u7406\u76d1\u7763\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u4e86\u9009\u62e9\u6027\u91cd\u5199\u7b56\u7565\uff0c\u4ec5\u5bf9\u6a21\u578b\u63a8\u7406\u7ed3\u679c\u4e00\u81f4\u6b63\u786e\u7684 \"\u7b80\u5355\" \u6837\u672c\u8fdb\u884c\u91cd\u5199\uff0c\u540c\u65f6\u5728\u4e00\u4e2a\u6279\u6b21\u5185\u878d\u5408\u91cd\u5199\u4e0e\u539f\u59cb\u751f\u6210\uff0c\u4fdd\u8bc1\u7b97\u6cd5\u53ef\u6269\u5c55\u6027\uff0c\u4ec5\u5e26\u6765\u7ea610%\u7684\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u81ea\u6211\u91cd\u5199\u6846\u67b6\uff0c\u6a21\u578b\u80fd\u591f\u5bf9\u81ea\u8eab\u7684\u63a8\u7406\u6587\u672c\u8fdb\u884c\u91cd\u5199\uff0c\u5e76\u5229\u7528\u91cd\u5199\u540e\u7684\u63a8\u7406\u8fdb\u884c\u5b66\u4e60\uff0c\u4ece\u800c\u63d0\u9ad8\u5185\u90e8\u63a8\u7406\u8fc7\u7a0b\u7684\u8d28\u91cf\u3002\u8be5\u65b9\u6cd5\u5728\u4fdd\u8bc1\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4fe1\u53f7\u7684\u524d\u63d0\u4e0b\uff0c\u9009\u62e9\u6027\u5730\u5bf9 \"\u7b80\u5355\" \u6837\u672c\u8fdb\u884c\u91cd\u5199\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u51c6\u786e\u7387\u7684\u63d0\u5347\u548c\u63a8\u7406\u957f\u5ea6\u7684\u663e\u8457\u7f29\u77ed\uff0c\u540c\u65f6\u6709\u6548\u51cf\u5c11\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8fc7\u5ea6\u601d\u8003\u3001\u6b20\u601d\u8003\u3001\u5197\u4f59\u601d\u8003\u548c\u65e0\u5e8f\u601d\u8003\u7b49\u95ee\u9898\u3002", "conclusion": "\u81ea\u6211\u91cd\u5199\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5185\u90e8\u63a8\u7406\u8d28\u91cf\u548c\u4efb\u52a1\u8868\u73b0\uff0c\u51cf\u5c11\u4e86\u65e0\u6548\u548c\u6df7\u4e71\u63a8\u7406\uff0c\u4e14\u5728\u591a\u4e2a\u4efb\u52a1\u53ca\u4e0d\u540c\u6a21\u578b\u89c4\u6a21\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.16224", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16224", "abs": "https://arxiv.org/abs/2511.16224", "authors": ["Francesco Salzano", "Simone Scalabrino", "Rocco Oliveto", "Simone Scalabrino"], "title": "Beyond Code Similarity: Benchmarking the Plausibility, Efficiency, and Complexity of LLM-Generated Smart Contracts", "comment": "20 pages", "summary": "Smart Contracts are critical components of blockchain ecosystems, with Solidity as the dominant programming language. While LLMs excel at general-purpose code generation, the unique constraints of Smart Contracts, such as gas consumption, security, and determinism, raise open questions about the reliability of LLM-generated Solidity code. Existing studies lack a comprehensive evaluation of these critical functional and non-functional properties. We benchmark four state-of-the-art models under zero-shot and retrieval-augmented generation settings across 500 real-world functions. Our multi-faceted assessment employs code similarity metrics, semantic embeddings, automated test execution, gas profiling, and cognitive and cyclomatic complexity analysis. Results show that while LLMs produce code with high semantic similarity to real contracts, their functional correctness is low: only 20% to 26% of zero-shot generations behave identically to ground-truth implementations under testing. The generated code is consistently simpler, with significantly lower complexity and gas consumption, often due to omitted validation logic. Retrieval-Augmented Generation markedly improves performance, boosting functional correctness by up to 45% and yielding more concise and efficient code. Our findings reveal a significant gap between semantic similarity and functional plausibility in LLM-generated Smart Contracts. We conclude that while RAG is a powerful enhancer, achieving robust, production-ready code generation remains a substantial challenge, necessitating careful expert validation.", "AI": {"tldr": "LLM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\u8868\u9762\u8bed\u4e49\u76f8\u4f3c\uff0c\u4f46\u529f\u80fd\u9c81\u68d2\u6027\u4e0d\u8db3\uff1b\u68c0\u7d22\u589e\u5f3a\u80fd\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u751f\u4ea7\u7ea7\u4ee3\u7801\u751f\u6210\u4ecd\u9700\u4e13\u5bb6\u4e25\u683c\u9a8c\u8bc1\u3002", "motivation": "\u73b0\u6709LMM\u751f\u6210\u7684\u667a\u80fd\u5408\u7ea6\u4ee3\u7801\u7f3a\u4e4f\u5bf9\u5176\u529f\u80fd\u6027\u548c\u975e\u529f\u80fd\u6027\u5173\u952e\u5c5e\u6027\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u5c24\u5176\u662f\u8003\u8651\u5230\u667a\u80fd\u5408\u7ea6\u5728Gas\u6d88\u8017\u3001\u5b89\u5168\u6027\u548c\u786e\u5b9a\u6027\u65b9\u9762\u7684\u72ec\u7279\u8981\u6c42\u3002", "method": "\u57fa\u4e8e\u56db\u79cd\u6700\u5148\u8fdb\u7684\u6a21\u578b\uff0c\u5206\u522b\u5728\u96f6-shot\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u8bbe\u7f6e\u4e0b\uff0c\u5bf9500\u4e2a\u771f\u5b9e\u667a\u80fd\u5408\u7ea6\u51fd\u6570\u8fdb\u884c\u591a\u65b9\u9762\u8bc4\u4f30\uff0c\u5305\u62ec\u4ee3\u7801\u76f8\u4f3c\u5ea6\u3001\u8bed\u4e49\u5d4c\u5165\u3001\u81ea\u52a8\u5316\u6d4b\u8bd5\u6267\u884c\u3001Gas\u4f7f\u7528\u5256\u6790\u3001\u8ba4\u77e5\u590d\u6742\u5ea6\u548c\u73af\u5f62\u590d\u6742\u5ea6\u5206\u6790\u3002", "result": "LLM\u751f\u6210\u7684\u4ee3\u7801\u4e0e\u771f\u5b9e\u5408\u7ea6\u5177\u6709\u8f83\u9ad8\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u6027\u8f83\u4f4e\uff08\u4ec520%-26%\u96f6-shot\u751f\u6210\u51fd\u6570\u5728\u6d4b\u8bd5\u4e2d\u884c\u4e3a\u4e00\u81f4\uff09\u3002\u751f\u6210\u4ee3\u7801\u66f4\u7b80\u5355\uff0c\u590d\u6742\u5ea6\u548cGas\u6d88\u8017\u663e\u8457\u964d\u4f4e\uff0c\u5e38\u56e0\u7701\u7565\u9a8c\u8bc1\u903b\u8f91\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u529f\u80fd\u6b63\u786e\u7387\u63d0\u5347\u81f3\u6700\u9ad845%\uff0c\u4ee3\u7801\u66f4\u7b80\u6d01\u9ad8\u6548\u3002", "conclusion": "LLM\u751f\u6210\u667a\u80fd\u5408\u7ea6\u867d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u529f\u80fd\u6b63\u786e\u6027\u548c\u5b89\u5168\u6027\u4ecd\u6709\u8f83\u5927\u6311\u6218\uff0c\u68c0\u7d22\u589e\u5f3a\u662f\u6709\u6548\u63d0\u5347\u624b\u6bb5\uff0c\u4f46\u5b9e\u73b0\u9ad8\u8d28\u91cf\u751f\u4ea7\u4ee3\u7801\u4ecd\u9700\u7efc\u5408\u65b9\u6cd5\u548c\u4e13\u5bb6\u5ba1\u67e5\u3002"}}
{"id": "2511.16345", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16345", "abs": "https://arxiv.org/abs/2511.16345", "authors": ["Blake Matheny", "Phuong Minh Nguyen", "Minh Le Nguyen", "Stephanie Reynolds"], "title": "NLP Datasets for Idiom and Figurative Language Tasks", "comment": "32 pages, 10 figures", "summary": "Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u5904\u7406\u4e60\u8bed\u548c\u6bd4\u55bb\u8bed\u8a00\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u4e60\u8bed\u548c\u6bd4\u55bb\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u8bc6\u522b\u4e60\u8bed\u7684\u80fd\u529b\u3002", "motivation": "\u4e60\u8bed\u548c\u6bd4\u55bb\u8bed\u8a00\u5728\u53e3\u8bed\u548c\u5199\u4f5c\u4e2d\u5e7f\u6cdb\u51fa\u73b0\uff0c\u5c24\u5176\u662f\u5728\u793e\u4ea4\u5a92\u4f53\u4e0a\u589e\u52a0\u4e86\u89c2\u5bdf\u548c\u8bad\u7ec3\u7684\u673a\u4f1a\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u8fd9\u7c7b\u8bed\u8a00\u65f6\u4ecd\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u901a\u8fc7\u66f4\u5927\u7684\u6570\u636e\u96c6\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "method": "\u6574\u5408\u591a\u4e2a\u73b0\u6709\u4e60\u8bed\u548c\u6bd4\u55bb\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u63d0\u53d6\u4e60\u8bed\u5217\u8868\uff0c\u4ece\u5927\u89c4\u6a21\u8bed\u6599\u4e2d\u68c0\u7d22\u4e0a\u4e0b\u6587\u5e8f\u5217\uff0c\u6784\u5efa\u5305\u542b\u6f5c\u5728\u548c\u786e\u5b9a\u4e60\u8bed\u8868\u8fbe\u7684\u6570\u636e\u96c6\uff0c\u5e76\u8fdb\u884c\u540e\u671f\u5904\u7406\u4ee5\u9002\u914d\u4e0d\u540c\u6a21\u578b\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5927\u578b\u6f5c\u5728\u4e60\u8bed\u548c\u6bd4\u55bb\u8bed\u8a00\u8868\u8fbe\u6570\u636e\u96c6\u53ca\u4e24\u4e2a\u4eba\u5de5\u6ce8\u91ca\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u6210\u529f\u7528\u4e8e\u57fa\u7ebf\u6a21\u578b\u5728\u4e60\u8bed\u8bc6\u522b\u7684\u63d2\u69fd\u6807\u6ce8\u548c\u5e8f\u5217\u6807\u6ce8\u4efb\u52a1\u7684\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u3002", "conclusion": "\u901a\u8fc7\u65b0\u6784\u5efa\u7684\u5927\u89c4\u6a21\u5305\u542b\u6f5c\u5728\u4e60\u8bed\u548c\u4e24\u4e2a\u4eba\u5de5\u6ce8\u91ca\u7684\u786e\u5207\u4e60\u8bed\u6570\u636e\u96c6\uff0c\u9a8c\u8bc1\u4e86\u5fae\u8c03\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u5bf9\u4e60\u8bed\u8bc6\u522b\u4efb\u52a1\u7684\u8868\u73b0\u3002"}}
{"id": "2511.16410", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.16410", "abs": "https://arxiv.org/abs/2511.16410", "authors": ["Hina Saeeda", "Tommy Johansson", "Mazen Mohamad", "Eric Knauss"], "title": "Data Annotation Quality Problems in AI-Enabled Perception System Development", "comment": null, "summary": "Data annotation is essential but highly error-prone in the development of AI-enabled perception systems (AIePS) for automated driving, and its quality directly influences model performance, safety, and reliability. However, the industry lacks empirical insights into how annotation errors emerge and spread across the multi-organisational automotive supply chain. This study addresses this gap through a multi-organisation case study involving six companies and four research institutes across Europe and the UK. Based on 19 semi-structured interviews with 20 experts (50 hours of transcripts) and a six-phase thematic analysis, we develop a taxonomy of 18 recurring annotation error types across three data-quality dimensions: completeness (e.g., attribute omission, missing feedback loops, edge-case omissions, selection bias), accuracy (e.g., mislabelling, bounding-box inaccuracies, granularity mismatches, bias-driven errors), and consistency (e.g., inter-annotator disagreement, ambiguous instructions, misaligned hand-offs, cross-modality inconsistencies). The taxonomy was validated with industry practitioners, who reported its usefulness for root-cause analysis, supplier quality reviews, onboarding, and improving annotation guidelines. They described it as a failure-mode catalogue similar to FMEA. By conceptualising annotation quality as a lifecycle and supply-chain issue, this study contributes to SE4AI by offering a shared vocabulary, diagnostic toolset, and actionable guidance for building trustworthy AI-enabled perception systems.", "AI": {"tldr": "\u672c\u6587\u57fa\u4e8e\u591a\u7ec4\u7ec7\u6848\u4f8b\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5305\u542b18\u7c7b\u9519\u8bef\u7684\u81ea\u52a8\u9a7e\u9a76\u6570\u636e\u6807\u6ce8\u9519\u8bef\u5206\u7c7b\u6cd5\uff0c\u65e8\u5728\u5e2e\u52a9\u8bc6\u522b\u548c\u7ba1\u7406\u6807\u6ce8\u8d28\u91cf\u95ee\u9898\uff0c\u63d0\u5347AI\u611f\u77e5\u7cfb\u7edf\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u7684\u6570\u636e\u6807\u6ce8\u9519\u8bef\u666e\u904d\u5b58\u5728\u4e14\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3001\u5b89\u5168\u4e0e\u53ef\u9760\u6027\uff0c\u4f46\u4e1a\u754c\u7f3a\u4e4f\u5bf9\u9519\u8bef\u4ea7\u751f\u4e0e\u4f20\u64ad\u673a\u5236\u7684\u5b9e\u8bc1\u6d1e\u5bdf\uff0c\u4e9f\u9700\u7cfb\u7edf\u5206\u6790\u548c\u7ba1\u7406\u5de5\u5177\u3002", "method": "\u91c7\u7528\u591a\u7ec4\u7ec7\u6848\u4f8b\u7814\u7a76\uff0c\u7ed3\u540819\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\u548c\u516d\u9636\u6bb5\u4e3b\u9898\u5206\u6790\uff0c\u5f52\u7eb3\u6807\u6ce8\u9519\u8bef\u5206\u7c7b\u5e76\u901a\u8fc7\u884c\u4e1a\u4e13\u5bb6\u9a8c\u8bc1\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5bf9\u6d89\u8db3\u6b27\u6d32\u548c\u82f1\u56fd\u7684\u516d\u5bb6\u516c\u53f8\u548c\u56db\u4e2a\u7814\u7a76\u673a\u6784\u7684\u591a\u7ec4\u7ec7\u6848\u4f8b\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u81ea\u52a8\u9a7e\u9a76AI\u611f\u77e5\u7cfb\u7edf\u4e2d\u6570\u636e\u6807\u6ce8\u9519\u8bef\u7684\u4ea7\u751f\u4e0e\u4f20\u64ad\u673a\u5236\u3002\u57fa\u4e8e19\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u63d0\u70bc\u51fa\u6db5\u76d6\u5b8c\u6574\u6027\u3001\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u4e09\u5927\u6570\u636e\u8d28\u91cf\u7ef4\u5ea6\u768418\u7c7b\u5e38\u89c1\u6807\u6ce8\u9519\u8bef\u7c7b\u578b\uff0c\u5982\u5c5e\u6027\u9057\u6f0f\u3001\u8bef\u6807\u6ce8\u53ca\u6807\u6ce8\u5458\u95f4\u5206\u6b67\u7b49\u3002\u8be5\u5206\u7c7b\u6cd5\u7ecf\u8fc7\u884c\u4e1a\u4e13\u5bb6\u9a8c\u8bc1\uff0c\u88ab\u89c6\u4e3a\u7c7b\u4f3c\u6545\u969c\u6a21\u5f0f\u4e0e\u5f71\u54cd\u5206\u6790\uff08FMEA\uff09\u7684\u5931\u6548\u6a21\u5f0f\u76ee\u5f55\uff0c\u6709\u52a9\u4e8e\u6839\u56e0\u5206\u6790\u3001\u4f9b\u5e94\u5546\u8d28\u91cf\u8bc4\u4f30\u3001\u4eba\u5458\u57f9\u8bad\u548c\u6807\u6ce8\u6307\u5357\u6539\u8fdb\u3002\u7814\u7a76\u5c06\u6807\u6ce8\u8d28\u91cf\u89c6\u4e3a\u751f\u547d\u5468\u671f\u53ca\u4f9b\u5e94\u94fe\u7ba1\u7406\u95ee\u9898\uff0c\u4e3a\u5de5\u7a0b\u5316\u53ef\u4fe1AI\u611f\u77e5\u7cfb\u7edf\u6784\u5efa\u63d0\u4f9b\u4e86\u7edf\u4e00\u672f\u8bed\u3001\u8bca\u65ad\u5de5\u5177\u548c\u53ef\u64cd\u4f5c\u5efa\u8bae\u3002", "conclusion": "\u901a\u8fc7\u5efa\u7acb\u6807\u6ce8\u9519\u8bef\u5206\u7c7b\u4f53\u7cfb\u5e76\u9a8c\u8bc1\u5176\u884c\u4e1a\u9002\u7528\u6027\uff0c\u7814\u7a76\u4fc3\u8fdb\u4e86\u6807\u6ce8\u8d28\u91cf\u7684\u7cfb\u7edf\u5316\u7ba1\u7406\uff0c\u652f\u6301\u53ef\u4fe1\u81ea\u52a8\u9a7e\u9a76\u611f\u77e5\u7cfb\u7edf\u7684\u5f00\u53d1\u3002"}}
{"id": "2511.16353", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16353", "abs": "https://arxiv.org/abs/2511.16353", "authors": ["Jonathan Kamp", "Lisa Beinborn", "Antske Fokkens"], "title": "Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies", "comment": "Long paper accepted to the main conference of AACL 2025. Please cite the conference proceedings when available", "summary": "Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u7406\u636e\u4fe1\u606f\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u7684\u590d\u6742\u6027\uff0c\u6307\u51fa\u5145\u5206\u6027\u6307\u6807\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5c06\u7406\u636e\u4fe1\u606f\u878d\u5165\u6a21\u578b\u7684\u6548\u679c\uff0c\u5f3a\u8c03\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u66f4\u53ef\u9760\u7684\u7406\u636e\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u5145\u5206\u6027\u6307\u6807\u7528\u4e8e\u8bc4\u4f30\u81ea\u7136\u8bed\u8a00\u7406\u636e\u7684\u4fe1\u606f\u91cf\uff0c\u4f46\u5bf9\u7406\u636e\u4fe1\u606f\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u7684\u4f5c\u7528\u6d1e\u5bdf\u6709\u9650\u3002", "method": "\u5c06\u5145\u5206\u6027\u6307\u6807\u4e0e\u4e24\u79cd\u5efa\u6a21\u8303\u5f0f\u5173\u8054\uff1a\u901a\u8fc7\u6807\u6ce8\u7406\u636e\u76f8\u5173\u7684\u8bcd\u5143\u8fdb\u884c\u6807\u6ce8\u5206\u7c7b\uff0c\u4ee5\u53ca\u901a\u8fc7\u6ce8\u610f\u529b\u6b63\u5219\u5316\u5c06\u7406\u636e\u4fe1\u606f\u878d\u5165\u8f93\u5165\u4e2d\uff0c\u89c2\u5bdf\u5176\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u9ad8\u4fe1\u606f\u91cf\u7684\u7406\u636e\u672a\u5fc5\u6709\u52a9\u4e8e\u6b63\u786e\u5206\u7c7b\uff1b\u5145\u5206\u6027\u6307\u6807\u53cd\u6620\u4e86\u975e\u7406\u636e\u4e0a\u4e0b\u6587\u5bf9\u5206\u7c7b\u7684\u5f71\u54cd\uff0c\u4e14\u4e0e\u8bcd\u5143\u5206\u7c7b\u65e0\u5173\u3002\u878d\u5165\u7406\u636e\u4fe1\u606f\u53ef\u4ee5\u63d0\u5347\u8de8\u9886\u57df\u5206\u7c7b\uff0c\u4f46\u6548\u679c\u4f9d\u4efb\u52a1\u548c\u6a21\u578b\u800c\u5f02\u3002", "conclusion": "\u7406\u636e\u7684\u4f5c\u7528\u590d\u6742\uff0c\u73b0\u6709\u6307\u6807\u96be\u4ee5\u5168\u9762\u6355\u6349\u7406\u636e\u4fe1\u606f\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u6307\u6807\u3002"}}
{"id": "2511.16593", "categories": ["cs.SE", "cs.AI", "cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.16593", "abs": "https://arxiv.org/abs/2511.16593", "authors": ["Diaeddin Rimawi"], "title": "Green Resilience of Cyber-Physical Systems: Doctoral Dissertation", "comment": null, "summary": "Cyber-physical systems (CPS) combine computational and physical components. Online Collaborative AI System (OL-CAIS) is a type of CPS that learn online in collaboration with humans to achieve a common goal, which makes it vulnerable to disruptive events that degrade performance. Decision-makers must therefore restore performance while limiting energy impact, creating a trade-off between resilience and greenness. This research addresses how to balance these two properties in OL-CAIS. It aims to model resilience for automatic state detection, develop agent-based policies that optimize the greenness-resilience trade-off, and understand catastrophic forgetting to maintain performance consistency. We model OL-CAIS behavior through three operational states: steady, disruptive, and final. To support recovery during disruptions, we introduce the GResilience framework, which provides recovery strategies through multi-objective optimization (one-agent), game-theoretic decision-making (two-agent), and reinforcement learning (RL-agent). We also design a measurement framework to quantify resilience and greenness. Empirical evaluation uses real and simulated experiments with a collaborative robot learning object classification from human demonstrations. Results show that the resilience model captures performance transitions during disruptions, and that GResilience policies improve green recovery by shortening recovery time, stabilizing performance, and reducing human dependency. RL-agent policies achieve the strongest results, although with a marginal increase in CO2 emissions. We also observe catastrophic forgetting after repeated disruptions, while our policies help maintain steadiness. A comparison with containerized execution shows that containerization cuts CO2 emissions by half. Overall, this research provides models, metrics, and policies that ensure the green recovery of OL-CAIS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5982\u4f55\u5728\u5728\u7ebf\u534f\u540cAI\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5f39\u6027\u548c\u7eff\u8272\u6062\u590d\uff0c\u63d0\u51fa\u65b0\u6846\u67b6\u548c\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u6062\u590d\u6027\u80fd\u5e76\u63a7\u5236\u80fd\u8017\u3002", "motivation": "\u9488\u5bf9\u5728\u7ebf\u534f\u540cAI\u7cfb\u7edf\u5728\u7834\u574f\u4e8b\u4ef6\u4e2d\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u7814\u7a76\u5982\u4f55\u6062\u590d\u6027\u80fd\u5e76\u540c\u65f6\u9650\u5236\u80fd\u8017\uff0c\u5b9e\u73b0\u5f39\u6027\u4e0e\u7eff\u8272\u7684\u6743\u8861\u3002", "method": "\u901a\u8fc7\u5efa\u6a21\u7cfb\u7edf\u8fd0\u884c\u72b6\u6001\uff0c\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u3001\u535a\u5f08\u8bba\u51b3\u7b56\u548c\u5f3a\u5316\u5b66\u4e60\u8bbe\u8ba1\u6062\u590d\u7b56\u7565\uff0c\u5e76\u6784\u5efa\u5ea6\u91cf\u6846\u67b6\u5bf9\u5f39\u6027\u548c\u7eff\u8272\u7a0b\u5ea6\u8fdb\u884c\u91cf\u5316\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u5728\u7ebf\u534f\u540c\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\uff08OL-CAIS\uff09\u5982\u4f55\u5e73\u8861\u5f39\u6027\u4e0e\u8282\u80fd\u7684\u6a21\u578b\u3001\u6307\u6807\u548c\u7b56\u7565\u3002\u901a\u8fc7\u5b9a\u4e49\u7cfb\u7edf\u7684\u4e09\u79cd\u8fd0\u884c\u72b6\u6001\uff0c\u8bbe\u8ba1\u4e86GResilience\u6846\u67b6\uff0c\u5229\u7528\u591a\u76ee\u6807\u4f18\u5316\u3001\u535a\u5f08\u8bba\u51b3\u7b56\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u4e86\u5728\u7834\u574f\u4e8b\u4ef6\u4e2d\u5feb\u901f\u4e14\u7eff\u8272\u7684\u6062\u590d\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6846\u67b6\u80fd\u63d0\u5347\u6062\u590d\u901f\u5ea6\u548c\u6027\u80fd\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u5bf9\u4eba\u5de5\u5e72\u9884\u7684\u4f9d\u8d56\uff0c\u540c\u65f6RL\u4ee3\u7406\u6548\u679c\u6700\u4f73\u4f46\u7565\u5fae\u589e\u52a0\u78b3\u6392\u653e\u3002\u5bb9\u5668\u5316\u6280\u672f\u53ef\u663e\u8457\u964d\u4f4e\u78b3\u6392\u653e\u3002", "conclusion": "GResilience\u6846\u67b6\u6210\u529f\u5e73\u8861\u4e86OL-CAIS\u7684\u5f39\u6027\u548c\u7eff\u8272\u9700\u6c42\uff0c\u5b9e\u73b0\u4e86\u66f4\u5feb\u3001\u66f4\u7a33\u5b9a\u3001\u4f4e\u78b3\u7684\u6062\u590d\uff0c\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u9700\u8981\u6ce8\u610f\u78b3\u6392\u653e\u7684\u8f7b\u5fae\u589e\u52a0\u3002\u5bb9\u5668\u5316\u6267\u884c\u80fd\u663e\u8457\u51cf\u5c11\u78b3\u6392\u653e\u3002"}}
{"id": "2511.16397", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16397", "abs": "https://arxiv.org/abs/2511.16397", "authors": ["Ren Ma", "Jiantao Qiu", "Chao Xu", "Pei Chu", "Kaiwen Liu", "Pengli Ren", "Yuan Qu", "Jiahui Peng", "Linfeng Hou", "Mengjie Liu", "Lindong Lu", "Wenchang Ning", "Jia Yu", "Rui Min", "Jin Shi", "Haojiong Chen", "Peng Zhang", "Wenjian Zhang", "Qian Jiang", "Zengjie Hu", "Guoqiang Yang", "Zhenxiang Li", "Fukai Shang", "Zhongying Tu", "Wentao Zhang", "Dahua Lin", "Conghui He"], "title": "AICC: Parse HTML Finer, Make Models Better -- A 7.3T AI-Ready Corpus Built by a Model-Based HTML Parser", "comment": null, "summary": "While web data quality is crucial for large language models, most curation efforts focus on filtering and deduplication,treating HTML-to-text extraction as a fixed pre-processing step. Existing web corpora rely on heuristic-based extractors like Trafilatura, which struggle to preserve document structure and frequently corrupt structured elements such as formulas, codes, and tables. We hypothesize that improving extraction quality can be as impactful as aggressive filtering strategies for downstream performance. We introduce MinerU-HTML, a novel extraction pipeline that reformulates content extraction as a sequence labeling problem solved by a 0.6B-parameter language model. Unlike text-density heuristics, MinerU-HTML leverages semantic understanding and employs a two-stage formatting pipeline that explicitly categorizes semantic elements before converting to Markdown. Crucially, its model-based approach is inherently scalable, whereas heuristic methods offer limited improvement pathways. On MainWebBench, our benchmark of 7,887 annotated web pages, MinerU-HTML achieves 81.8\\% ROUGE-N F1 compared to Trafilatura's 63.6\\%, with exceptional structured element preservation (90.9\\% for code blocks, 94.0\\% for formulas). Using MinerU-HTML, we construct AICC (AI-ready Common Crawl), a 7.3-trillion token multilingual corpus from two Common Crawl snapshots. In controlled pretraining experiments where AICC and Trafilatura-extracted TfCC undergo identical filtering, models trained on AICC (62B tokens) achieve 50.8\\% average accuracy across 13 benchmarks, outperforming TfCC by 1.08pp-providing direct evidence that extraction quality significantly impacts model capabilities. AICC also surpasses RefinedWeb and FineWeb on key benchmarks. We publicly release MainWebBench, MinerU-HTML, and AICC, demonstrating that HTML extraction is a critical, often underestimated component of web corpus construction.", "AI": {"tldr": "\u901a\u8fc7\u5c06HTML\u5185\u5bb9\u63d0\u53d6\u4efb\u52a1\u5efa\u6a21\u4e3a\u5e8f\u5217\u6807\u6ce8\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u7684MinerU-HTML\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u542f\u53d1\u5f0f\u63d0\u53d6\u65b9\u6cd5\u66f4\u51c6\u786e\u7684\u7ed3\u6784\u5316\u5185\u5bb9\u4fdd\u7559\uff0c\u63d0\u5347\u4e86\u7f51\u9875\u6570\u636e\u8d28\u91cf\uff0c\u8fdb\u800c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7f51\u9875\u6570\u636e\u6e05\u7406\u591a\u96c6\u4e2d\u4e8e\u8fc7\u6ee4\u548c\u53bb\u91cd\uff0c\u5ffd\u89c6\u4e86HTML\u5230\u6587\u672c\u7684\u63d0\u53d6\u6b65\u9aa4\uff0c\u800c\u73b0\u6709\u57fa\u4e8e\u542f\u53d1\u5f0f\u7684\u7f51\u9875\u6587\u672c\u63d0\u53d6\u5de5\u5177\u96be\u4ee5\u4fdd\u7559\u6587\u6863\u7ed3\u6784\uff0c\u5bb9\u6613\u7834\u574f\u516c\u5f0f\u3001\u4ee3\u7801\u3001\u8868\u683c\u7b49\u7ed3\u6784\u5316\u5143\u7d20\uff0c\u5f71\u54cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e0b\u6e38\u6027\u80fd\u3002", "method": "\u672c\u7814\u7a76\u63d0\u51faMinerU-HTML\u4f5c\u4e3a\u5185\u5bb9\u63d0\u53d6\u6d41\u6c34\u7ebf\uff0c\u5229\u75286\u4ebf\u53c2\u6570\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5e8f\u5217\u6807\u6ce8\uff0c\u7ed3\u5408\u8bed\u4e49\u7406\u89e3\u4e0e\u4e24\u9636\u6bb5\u683c\u5f0f\u5316\u8f6c\u4e3aMarkdown\uff0c\u66ff\u4ee3\u4f20\u7edf\u542f\u53d1\u5f0f\u6587\u672c\u5bc6\u5ea6\u65b9\u6cd5\uff0c\u5b9e\u73b0\u7ed3\u6784\u5316\u7f51\u9875\u5143\u7d20\u7684\u9ad8\u4fdd\u771f\u63d0\u53d6\u3002", "result": "MinerU-HTML\u5728MainWebBench\uff087,887\u4e2a\u7f51\u9875\u6807\u6ce8\u6570\u636e\u96c6\uff09\u4e0a\u8fbe\u5230\u4e8681.8%\u7684ROUGE-N F1\u5206\u6570\uff0c\u663e\u8457\u4f18\u4e8eTrafilatura\u768463.6%\uff0c\u5e76\u5728\u7ed3\u6784\u5316\u5143\u7d20\u4fdd\u7559\u4e0a\u8868\u73b0\u4f18\u5f02\uff08\u4ee3\u7801\u575790.9%\uff0c\u516c\u5f0f94.0%\uff09\u3002\u4f7f\u7528MinerU-HTML\u6784\u5efa\u4e867.3\u4e07\u4ebftoken\u7684\u591a\u8bed\u8a00AICC\u8bed\u6599\u5e93\uff0c\u8bad\u7ec3\u7684\u6a21\u578b\u572813\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u51c6\u786e\u7387\u63d0\u5347\u4e861.08\u4e2a\u767e\u5206\u70b9\uff0c\u8868\u660e\u63d0\u53d6\u8d28\u91cf\u5bf9\u6a21\u578b\u80fd\u529b\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "HTML\u63d0\u53d6\u8d28\u91cf\u662f\u7f51\u9875\u8bed\u6599\u6784\u5efa\u4e2d\u5173\u952e\u4e14\u7ecf\u5e38\u88ab\u4f4e\u4f30\u7684\u73af\u8282\u3002\u9ad8\u8d28\u91cf\u7684\u5185\u5bb9\u63d0\u53d6\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4e0b\u6e38\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.16416", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16416", "abs": "https://arxiv.org/abs/2511.16416", "authors": ["Connor McElroy", "Thiago E. A. de Oliveira", "Chris Brogly"], "title": "Classification of worldwide news articles by perceived quality, 2018-2024", "comment": null, "summary": "This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.", "AI": {"tldr": "\u672c\u7814\u7a76\u4f7f\u7528\u76d1\u7763\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e\u8d85\u8fc7140\u4e07\u7bc7\u65b0\u95fb\u6587\u7ae0\u7684\u6570\u636e\uff0c\u6210\u529f\u533a\u5206\u4e86\u88ab\u611f\u77e5\u4e3a\u4f4e\u8d28\u91cf\u548c\u9ad8\u8d28\u91cf\u7684\u65b0\u95fb\u3002", "motivation": "\u63a2\u7a76\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u662f\u5426\u80fd\u591f\u6709\u6548\u8fa8\u522b\u65b0\u95fb\u6587\u7ae0\u7684\u8d28\u91cf\uff0c\u4ee5\u63d0\u5347\u65b0\u95fb\u8d28\u91cf\u8bc4\u4f30\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "method": "\u5229\u75283\u79cd\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u5206\u7c7b\u5668\u548c3\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u57fa\u4e8e579\u4e2a\u65b0\u95fb\u7f51\u7ad9\u7684\u4e13\u5bb6\u8bc4\u5b9a\uff08\u5206\u4e3a\u9ad8\u4f4e\u8d28\u91cf\u4e24\u7c7b\uff09\uff0c\u5bf91,412,272\u7bc7\u82f1\u6587\u65b0\u95fb\u6587\u7ae0\u8fdb\u884c\u5206\u7c7b\uff0c\u4f7f\u7528194\u4e2a\u8bed\u8a00\u7279\u5f81\u3002", "result": "\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u968f\u673a\u68ee\u6797\u8868\u73b0\u826f\u597d\uff08\u51c6\u786e\u73870.7355\uff0cROC AUC 0.8131\uff09\uff0c\u800c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u4e2dModernBERT-large\u53d6\u5f97\u6700\u4f73\u6548\u679c\uff08\u51c6\u786e\u73870.8744\uff0cROC AUC 0.9593\uff0cF1\u503c0.8739\uff09\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5747\u80fd\u6709\u6548\u533a\u5206\u4e16\u754c\u8303\u56f4\u5185\u65b0\u95fb\u6587\u7ae0\u7684\u611f\u77e5\u8d28\u91cf\uff0c\u5176\u4e2d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8868\u73b0\u66f4\u4f18\u3002"}}
{"id": "2511.16438", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.16438", "abs": "https://arxiv.org/abs/2511.16438", "authors": ["Sherine George", "Nithish Saji"], "title": "ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports", "comment": "Workshop paper accepted at AI4DF 2025 (part of ACM ICAIF 2025). 3 pages including tables and figures", "summary": "We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ESGBench\u57fa\u51c6\uff0c\u7528\u4ee5\u8bc4\u4f30\u57fa\u4e8e\u4f01\u4e1a\u53ef\u6301\u7eed\u62a5\u544a\u7684\u53ef\u89e3\u91caESG\u95ee\u7b54\u7cfb\u7edf\uff0c\u5e76\u5206\u6790\u4e86\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u53ca\u5176\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u3002", "motivation": "\u73b0\u6709ESG\u95ee\u7b54\u7cfb\u7edf\u7f3a\u4e4f\u900f\u660e\u5ea6\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u4e14\u7f3a\u5c11\u6807\u51c6\u5316\u8bc4\u4f30\u57fa\u51c6\uff0c\u4fc3\u4f7f\u63d0\u51faESGBench\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u516c\u5e73\u3001\u7ec6\u81f4\u7684\u6a21\u578b\u8868\u73b0\u8bc4\u4f30\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u4e3b\u9898ESG\u9886\u57df\u95ee\u9898\u3001\u4eba\u5de5\u7b56\u5212\u7b54\u6848\u53ca\u652f\u6301\u8bc1\u636e\u7684\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u6846\u67b6\uff0c\u5bf9\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86ESGBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u57fa\u4e8e\u4f01\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u62a5\u544a\u7684\u53ef\u89e3\u91caESG\u95ee\u7b54\u7cfb\u7edf\u7684\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u57fa\u51c6\u5305\u542b\u8de8\u591a\u4e2aESG\u4e3b\u9898\u7684\u9886\u57df\u76f8\u5173\u95ee\u9898\uff0c\u914d\u5907\u4eba\u5de5\u7b56\u5212\u7684\u7b54\u6848\u548c\u652f\u6301\u8bc1\u636e\uff0c\u4ee5\u5b9e\u73b0\u6a21\u578b\u63a8\u7406\u7684\u7ec6\u7c92\u5ea6\u8bc4\u4f30\u3002\u901a\u8fc7\u5206\u6790\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728ESGBench\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u4e8b\u5b9e\u4e00\u81f4\u6027\u3001\u53ef\u8ffd\u6eaf\u6027\u548c\u9886\u57df\u5bf9\u9f50\u65b9\u9762\u7684\u5173\u952e\u6311\u6218\u3002ESGBench\u65e8\u5728\u4fc3\u8fdb\u900f\u660e\u4e14\u8d1f\u8d23\u4efb\u7684ESG AI\u7cfb\u7edf\u7684\u7814\u7a76\u8fdb\u5c55\u3002", "conclusion": "ESGBench\u4e3a\u8bc4\u4f30\u548c\u63a8\u52a8\u53ef\u89e3\u91ca\u4e14\u8d1f\u8d23\u4efb\u7684ESG\u95ee\u7b54\u7cfb\u7edf\u7814\u7a76\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u6570\u636e\u96c6\u548c\u6846\u67b6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u9886\u57df\u5bf9\u9f50\u65b9\u9762\u7684\u4e0d\u8db3\u3002"}}
{"id": "2511.16467", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16467", "abs": "https://arxiv.org/abs/2511.16467", "authors": ["Andrew Gomes"], "title": "Anatomy of an Idiom: Tracing Non-Compositionality in Language Models", "comment": null, "summary": "We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7535\u8def\u53d1\u73b0\u6280\u672f\u63ed\u793a\u4e86\u53d8\u6362\u5668\u5728\u5904\u7406\u60ef\u7528\u8bed\u65f6\u7684\u72ec\u7279\u8ba1\u7b97\u6a21\u5f0f\uff0c\u53d1\u73b0\u4e86\u4e13\u95e8\u7684\u6ce8\u610f\u529b\u5934\u548c\u589e\u5f3a\u8bcd\u5143\u95f4\u6ce8\u610f\u529b\u673a\u5236\uff0c\u4fc3\u8fdb\u7406\u89e3\u975e\u7ec4\u5408\u8bed\u8a00\u5904\u7406\u3002", "motivation": "\u63a2\u7d22\u53d8\u6362\u5668\u5982\u4f55\u5904\u7406\u975e\u7ec4\u5408\u6027\u8bed\u8a00\uff08\u5982\u60ef\u7528\u8bed\uff09\uff0c\u63ed\u793a\u5176\u8ba1\u7b97\u673a\u5236\u53ca\u6548\u7387\u4e0e\u9c81\u68d2\u6027\u7684\u5e73\u8861\u3002", "method": "\u4f7f\u7528\u6539\u8fdb\u7684\u8def\u5f84\u62fc\u63a5\u7b97\u6cd5\u8fdb\u884c\u7535\u8def\u53d1\u73b0\u548c\u5206\u6790\uff0c\u7814\u7a76\u53d8\u6362\u5668\u8bed\u8a00\u6a21\u578b\u4e2d\u60ef\u7528\u8bed\u5904\u7406\u7684\u8ba1\u7b97\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u4e86\"\u60ef\u7528\u8bed\u5934\"\u2014\u5728\u4e0d\u540c\u60ef\u7528\u8bed\u4e2d\u9891\u7e41\u6fc0\u6d3b\u7684\u6ce8\u610f\u529b\u5934\uff0c\u4ee5\u53ca\"\u589e\u5f3a\u63a5\u6536\"\u73b0\u8c61\uff0c\u5373\u60ef\u7528\u8bed\u8bcd\u5143\u95f4\u589e\u5f3a\u7684\u6ce8\u610f\u529b\uff0c\u63ed\u793a\u4e86\u53d8\u6362\u5668\u5904\u7406\u4e2d\u60ef\u7528\u8bed\u7684\u7279\u6b8a\u673a\u5236\u3002", "conclusion": "\u53d8\u6362\u5668\u901a\u8fc7\u7279\u5b9a\u7684\u6ce8\u610f\u529b\u5934\u548c\u589e\u5f3a\u7684\u8bcd\u5143\u95f4\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\u5bf9\u60ef\u7528\u8bed\u7684\u9ad8\u6548\u4e0e\u9c81\u68d2\u5904\u7406\uff0c\u4e3a\u7406\u89e3\u66f4\u590d\u6742\u8bed\u6cd5\u7ed3\u6784\u7684\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002"}}
{"id": "2511.16470", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.16470", "abs": "https://arxiv.org/abs/2511.16470", "authors": ["Mateusz Chili\u0144ski", "Julita O\u0142tusek", "Wojciech Ja\u015bkowski"], "title": "Arctic-Extract Technical Report", "comment": null, "summary": "Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.", "AI": {"tldr": "Arctic-Extract\u662f\u4e00\u6b3e\u8f7b\u91cf\u7ea7\u4e14\u6027\u80fd\u4f18\u8d8a\u7684\u6587\u6863\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u6a21\u578b\uff0c\u9002\u5408\u8d44\u6e90\u6709\u9650\u8bbe\u5907\u90e8\u7f72\u3002", "motivation": "\u63d0\u9ad8\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u7075\u6d3b\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u5904\u7406\u957f\u6587\u6863\u7684\u80fd\u529b\u548c\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6a21\u578b\u7ed3\u6784\u548c\u4f18\u5316\u8bad\u7ec3\u534f\u8bae\uff0c\u5b9e\u73b0\u9ad8\u6548\u6587\u6863\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u3002", "result": "Arctic-Extract\u662f\u4e00\u6b3e\u5148\u8fdb\u7684\u7ed3\u6784\u5316\u6570\u636e\u63d0\u53d6\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u626b\u63cf\u4ef6\u6216\u6570\u5b57\u6587\u6863\u4e2d\u7684\u95ee\u7b54\u3001\u5b9e\u4f53\u548c\u8868\u683c\u6570\u636e\u3002\u8be5\u6a21\u578b\u4f53\u79ef\u4ec56.6 GiB\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u786c\u4ef6\u8bbe\u5907\uff08\u5982\u62e5\u670924 GB\u663e\u5b58\u7684A10 GPU\uff09\u90e8\u7f72\uff0c\u53ef\u5904\u7406\u6700\u591a125\u9875A4\u6587\u6863\uff0c\u652f\u6301\u957f\u6587\u6863\u89e3\u6790\u3002\u672c\u6587\u4ecb\u7ecd\u4e86\u5176\u8bad\u7ec3\u65b9\u6848\u4e0e\u8bc4\u4f30\u7ed3\u679c\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u6587\u6863\u7406\u89e3\u4e0a\u7684\u4f18\u5f02\u8868\u73b0\u3002", "conclusion": "Arctic-Extract\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6587\u6863\u7ed3\u6784\u6570\u636e\u63d0\u53d6\u80fd\u529b\uff0c\u4e14\u9002\u5408\u5728\u8d44\u6e90\u6709\u9650\u7684\u786c\u4ef6\u4e0a\u9ad8\u6548\u8fd0\u884c\u3002"}}
{"id": "2511.16528", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.16528", "abs": "https://arxiv.org/abs/2511.16528", "authors": ["\u00d6zay Ezerceli", "Mahmoud El Hussieni", "Selva Ta\u015f", "Reyhan Bayraktar", "Fatma Bet\u00fcl Terzio\u011flu", "Yusuf \u00c7elebi", "Ya\u011f\u0131z Asker"], "title": "TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval", "comment": null, "summary": "Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\\% of its average mAP. Late-interaction models that are 3--5$\\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\\times$ faster than PLAID and offers +1.7\\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u9488\u5bf9\u571f\u8033\u5176\u8bed\u68c0\u7d22\u7684\u5bc6\u96c6\u7f16\u7801\u5668\u4e0e\u540e\u671f\u4ea4\u4e92\u6a21\u578b\uff0c\u63d0\u51faTurkColBERT\u57fa\u51c6\u3002\u5176\u6a21\u578b\u5728\u53c2\u6570\u6548\u7387\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c24\u5176\u662f\u8f7b\u91cf\u7ea7\u540e\u671f\u4ea4\u4e92\u6a21\u578bColmmBERT-base-TR\u5728\u9886\u57df\u4efb\u52a1\u4e2d\u63d0\u5347\u663e\u8457\u3002", "motivation": "\u5f53\u524d\u795e\u7ecf\u4fe1\u606f\u68c0\u7d22\u7cfb\u7edf\u591a\u805a\u7126\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u5c11\u5bf9\u5f62\u6001\u4e30\u5bcc\u4e14\u8d44\u6e90\u8f83\u5c11\u8bed\u8a00\u5982\u571f\u8033\u5176\u8bed\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u540e\u671f\u4ea4\u4e92\u6a21\u578b\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9002\u914d\u6d41\u7a0b\uff0c\u5148\u5728\u571f\u8033\u5176\u8bedNLI/STS\u4efb\u52a1\u4e0a\u5fae\u8c03\u82f1\u6587\u548c\u591a\u8bed\u7f16\u7801\u5668\uff0c\u518d\u7528PyLate\u57fa\u4e8eMS MARCO-TR\u5c06\u5176\u8f6c\u6362\u4e3aColBERT\u98ce\u683c\u68c0\u7d22\u5668\u3002\u6bd4\u8f83\u4e8610\u4e2a\u6a21\u578b\u5728\u4e94\u4e2a\u571f\u8033\u5176\u8bedBEIR\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "Colbert-hash-nano-tr\u6a21\u578b\u53c2\u6570\u4ec5\u4e3a\u5927\u578b\u5bc6\u96c6\u7f16\u7801\u5668\u76841/600\uff0c\u4fdd\u6301\u4e8671%\u4ee5\u4e0a\u7684\u6027\u80fd\uff1b\u540e\u671f\u4ea4\u4e92\u6a21\u578b\u4f53\u79ef\u66f4\u5c0f\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe13.8%\uff1bMUVERA+Rerank\u7d22\u5f15\u7b97\u6cd5\u901f\u5ea6\u63d0\u53473.33\u500d\uff0c\u5e76\u5e26\u67651.7%\u7684mAP\u589e\u76ca\uff1bColmmBERT-base-TR\u5b9e\u73b0\u4e860.54\u6beb\u79d2\u7684\u67e5\u8be2\u65f6\u5ef6\u3002", "conclusion": "\u8f7b\u91cf\u7ea7\u7684\u540e\u671f\u4ea4\u4e92\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u5bc6\u96c6\u7f16\u7801\u5668\uff0c\u4e14\u53c2\u6570\u6548\u7387\u9ad8\uff0c\u9002\u5408\u571f\u8033\u5176\u8bed\u4fe1\u606f\u68c0\u7d22\uff1bMUVERA+Rerank\u7d22\u5f15\u7b97\u6cd5\u63d0\u9ad8\u4e86\u68c0\u7d22\u901f\u5ea6\u548c\u6548\u679c\u3002"}}
{"id": "2511.16540", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.16540", "abs": "https://arxiv.org/abs/2511.16540", "authors": ["\u00c9lo\u00efse Benito-Rodriguez", "Einar Urdshals", "Jasmina Nasufi", "Nicky Pochinkov"], "title": "Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks", "comment": "13 pages, 5 figures", "summary": "Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5c55\u793a\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\uff0c\u4f7f\u7528\u6d45\u5c42\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u6587\u672c\u4f53\u88c1\u7684\u53ef\u884c\u6027\uff0c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u96be\u4ee5\u89e3\u91ca\u4e14\u96be\u4ee5\u5bf9\u6240\u6709\u8f93\u51fa\u8fdb\u884c\u4eba\u5de5\u8bc4\u4f30\uff0c\u4e9f\u9700\u4e00\u4e2a\u80fd\u591f\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u9884\u6d4b\u6587\u672c\u5c5e\u6027\u7684\u6846\u67b6\u3002", "method": "\u5229\u7528Mistral-7B\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u901a\u8fc7scikit-learn\u5206\u7c7b\u5668\u57fa\u4e8e\u6a21\u578b\u6fc0\u6d3b\u9884\u6d4b\u6587\u672c\u7684\u4f53\u88c1\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u6210\u529f\u4f7f\u7528\u6d45\u5c42\u5b66\u4e60\u6a21\u578b\u9884\u6d4b\u6587\u672c\u4f53\u88c1\uff0cF1\u5206\u6570\u6700\u9ad8\u8fbe98%\u548c71%\uff0c\u4e14\u8868\u73b0\u4f18\u4e8e\u63a7\u5236\u4efb\u52a1\u3002", "conclusion": "\u6587\u672c\u4f53\u88c1\u53ef\u4ece\u5927\u8bed\u8a00\u6a21\u578b\u6fc0\u6d3b\u4e2d\u6709\u6548\u63a8\u65ad\uff0c\u9a8c\u8bc1\u4e86\u6b64\u9884\u6d4b\u6846\u67b6\u7684\u6982\u5ff5\uff0c\u63a8\u52a8\u4e86\u5bf9LLM\u53ef\u89e3\u91ca\u6027\u548c\u5b89\u5168\u6027\u7684\u7814\u7a76\u3002"}}
{"id": "2511.16544", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16544", "abs": "https://arxiv.org/abs/2511.16544", "authors": ["Zachary Ellis", "Jared Joselowitz", "Yash Deo", "Yajie He", "Anna Kalygina", "Aisling Higham", "Mana Rahimzadeh", "Yan Jia", "Ibrahim Habli", "Ernest Lim"], "title": "WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue", "comment": null, "summary": "As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $\u03ba$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.", "AI": {"tldr": "\u4f20\u7edfASR\u8bc4\u4f30\u6307\u6807\u96be\u4ee5\u53cd\u6620\u8bef\u5dee\u7684\u4e34\u5e8a\u5b89\u5168\u98ce\u9669\uff0c\u672c\u6587\u901a\u8fc7\u4e13\u5bb6\u6807\u6ce8\u548c\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u81ea\u52a8\u5316\u3001\u51c6\u786e\u7684\u4e34\u5e8a\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u63d0\u5347\u4e86ASR\u5728\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u7684\u5b89\u5168\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfASR\u8bc4\u4f30\u6307\u6807\u5982\u8bcd\u9519\u8bef\u7387\uff08WER\uff09\u4e0e\u5b9e\u9645\u4e34\u5e8a\u8f6c\u5f55\u9519\u8bef\u7684\u5f71\u54cd\u76f8\u5173\u6027\u8f83\u5dee\uff0c\u65e0\u6cd5\u6709\u6548\u53cd\u6620\u8f6c\u5f55\u9519\u8bef\u5728\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5efa\u7acb\u4e13\u5bb6\u4e34\u5e8a\u533b\u5e08\u6807\u6ce8\u7684\u4e34\u5e8a\u5f71\u54cd\u8bc4\u4ef7\u57fa\u51c6\uff0c\u6bd4\u8f83ASR\u751f\u6210\u7684\u8f6c\u5f55\u4e0e\u4eba\u5de5\u8f6c\u5f55\u7684\u5dee\u5f02\uff1b\u5f15\u5165\u7ecf\u8fc7GEPA\u4f18\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5ba1\u8005(LLM-as-a-Judge)\u6765\u81ea\u52a8\u8bc4\u4f30\u4e34\u5e8a\u98ce\u9669\u3002", "result": "\u53d1\u73b0WER\u53ca\u591a\u79cd\u5e38\u7528\u6307\u6807\u4e0e\u4e34\u5e8a\u98ce\u9669\u7b49\u7ea7\uff08\u65e0\u5f71\u54cd\u3001\u6700\u5c0f\u5f71\u54cd\u3001\u663e\u8457\u5f71\u54cd\uff09\u76f8\u5173\u6027\u8f83\u5f31\uff1b\u5f00\u53d1\u7684\u4f18\u5316\u540e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5ba1\u8005\u5728\u4e34\u5e8a\u98ce\u9669\u5224\u5b9a\u4e0a\u8fbe\u523090%\u51c6\u786e\u7387\u548c0.816\u7684Cohen's \u03ba\uff0c\u8868\u73b0\u63a5\u8fd1\u4eba\u5de5\u8bc4\u5ba1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u6807\u6ce8\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f18\u5316\u7684\u81ea\u52a8\u5316\u4e34\u5e8a\u98ce\u9669\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6bd4WER\u66f4\u6709\u6548\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4e3aASR\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u5b89\u5168\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u9760\u7684\u5de5\u5177\u3002"}}
{"id": "2511.16577", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.16577", "abs": "https://arxiv.org/abs/2511.16577", "authors": ["Kexin Zhao", "Ken Forbus"], "title": "Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation", "comment": "16 pages", "summary": "Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u624b\u5de5\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\uff0c\u5229\u7528\u7edf\u8ba1\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5224\u522b\u5de5\u5177\uff0c\u7ed3\u5408\u7b26\u53f7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u5b9e\u73b0\u8bcd\u4e49\u6d88\u6b67\u7684\u65b0\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u8bcd\u4e49\u6d88\u6b67\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u7c97\u7c92\u5ea6\u8868\u793a\u4e14\u4f9d\u8d56\u624b\u5de5\u6807\u6ce8\u6570\u636e\uff0c\u96be\u4ee5\u652f\u6301\u57fa\u4e8e\u66f4\u4e30\u5bcc\u8868\u793a\uff08\u5982OpenCyc\uff09\u7684\u6d88\u6b67\uff0c\u9650\u5236\u4e86\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\u3002", "method": "\u5c06\u7b26\u53f7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u751f\u6210\u7684\u591a\u4e2a\u5019\u9009\u8bcd\u4e49\u8f6c\u6362\u4e3a\u53ef\u533a\u5206\u7684\u81ea\u7136\u8bed\u8a00\u66ff\u4ee3\u9009\u9879\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u4e2d\u5bf9\u8fd9\u4e9b\u9009\u9879\u8fdb\u884c\u67e5\u8be2\u9009\u62e9\u5408\u9002\u7684\u8bcd\u4e49\uff0c\u518d\u5c06\u9009\u62e9\u7ed3\u679c\u53cd\u9988\u56de\u7b26\u53f7\u7cfb\u7edf\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u65e0\u9700\u624b\u5de5\u6807\u6ce8\u7684\u524d\u63d0\u4e0b\uff0c\u80fd\u591f\u6709\u6548\u5730\u9009\u62e9\u7b26\u5408\u8bed\u5883\u7684\u8bcd\u4e49\uff0c\u4e14\u6548\u679c\u63a5\u8fd1\u4eba\u5de5\u6807\u6ce8\u7b54\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u5728\u65e0\u9700\u624b\u5de5\u6807\u6ce8\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7b26\u53f7\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\uff0c\u5b9e\u73b0\u66f4\u4e30\u5bcc\u8bed\u4e49\u8868\u793a\u7684\u8bcd\u4e49\u6d88\u6b67\uff0c\u5e76\u5728\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u7b54\u6848\u5bf9\u6bd4\u4e2d\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\u3002"}}
{"id": "2511.16654", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16654", "abs": "https://arxiv.org/abs/2511.16654", "authors": ["Elias Lumer", "Alex Cardenas", "Matt Melich", "Myles Mason", "Sara Dieter", "Vamse Kumar Subbiah", "Pradeep Honaganahalli Basavaraju", "Roberto Hernandez"], "title": "Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems", "comment": null, "summary": "Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u57fa\u4e8e\u6587\u672c\u6458\u8981\u548c\u76f4\u63a5\u591a\u6a21\u6001\u5411\u91cf\u5d4c\u5165\u4e24\u79cd\u591a\u6a21\u6001\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u53d1\u73b0\u76f4\u63a5\u591a\u6a21\u6001\u5d4c\u5165\u68c0\u7d22\u5728\u91d1\u878d\u6587\u6863\u95ee\u7b54\u4efb\u52a1\u4e0a\u8868\u73b0\u663e\u8457\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001RAG\u7cfb\u7edf\u901a\u8fc7\u5c06\u56fe\u50cf\u8f6c\u6362\u4e3a\u6587\u672c\u5d4c\u5165\uff0c\u5bfc\u81f4\u5173\u952e\u4fe1\u606f\u4e22\u5931\uff0c\u96be\u4ee5\u5145\u5206\u5229\u7528\u89c6\u89c9\u7ec6\u8282\u3002", "method": "\u672c\u6587\u6784\u5efa\u4e86\u5305\u542b\u56fe\u50cf\u548c\u6587\u672c\u7684\u91d1\u878d\u8d22\u62a5\u95ee\u7b54\u57fa\u51c6\uff0c\u5bf9\u4e24\u79cd\u68c0\u7d22\u7b56\u7565\uff08\u6587\u672c\u6458\u8981\u68c0\u7d22\u548c\u76f4\u63a5\u591a\u6a21\u6001\u5d4c\u5165\u68c0\u7d22\uff09\u8fdb\u884c\u4e86\u7efc\u5408\u8bc4\u4f30\u3002", "result": "\u76f4\u63a5\u591a\u6a21\u6001\u5d4c\u5165\u68c0\u7d22\u5728mAP@5\u548cnDCG@5\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e8613%\u548c11%\uff08\u76f8\u5bf9\u63d0\u534732%\u548c20%\uff09\uff0c\u4e14\u7b54\u6848\u66f4\u51c6\u786e\u4e14\u4e8b\u5b9e\u4e00\u81f4\u3002", "conclusion": "\u76f4\u63a5\u591a\u6a21\u6001\u5d4c\u5165\u68c0\u7d22\u65b9\u6cd5\u76f8\u6bd4\u57fa\u4e8eLLM\u6458\u8981\u7684\u6587\u672c\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u51c6\u786e\u7387\u548c\u56de\u7b54\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u6709\u6548\u907f\u514d\u4e86\u89c6\u89c9\u4fe1\u606f\u7684\u635f\u5931\u3002"}}
{"id": "2511.16664", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.16664", "abs": "https://arxiv.org/abs/2511.16664", "authors": ["Ali Taghibakhshi", "Sharath Turuvekere Sreenivas", "Saurav Muralidharan", "Ruisi Cai", "Marcin Chochowski", "Ameya Sunil Mahabaleshwarkar", "Yoshi Suhara", "Oluwatobi Olabiyi", "Daniel Korzekwa", "Mostofa Patwary", "Mohammad Shoeybi", "Jan Kautz", "Bryan Catanzaro", "Ashwath Aithal", "Nima Tajbakhsh", "Pavlo Molchanov"], "title": "Nemotron Elastic: Towards Efficient Many-in-One Reasoning LLMs", "comment": null, "summary": "Training a family of large language models targeting multiple scales and deployment objectives is prohibitively expensive, requiring separate training runs for each different size. Recent work on model compression through pruning and knowledge distillation has reduced this cost; however, this process still incurs hundreds of billions of tokens worth of training cost per compressed model. In this paper, we present Nemotron Elastic, a framework for building reasoning-oriented LLMs, including hybrid Mamba-Attention architectures, that embed multiple nested submodels within a single parent model, each optimized for different deployment configurations and budgets. Each of these submodels shares weights with the parent model and can be extracted zero-shot during deployment without additional training or fine-tuning. We enable this functionality through an end-to-end trained router, tightly coupled to a two-stage training curriculum designed specifically for reasoning models. We additionally introduce group-aware SSM elastification that preserves Mamba's structural constraints, heterogeneous MLP elastification, normalized MSE-based layer importance for improved depth selection, and knowledge distillation enabling simultaneous multi-budget optimization. We apply Nemotron Elastic to the Nemotron Nano V2 12B model, simultaneously producing a 9B and a 6B model using only 110B training tokens; this results in over 360x cost reduction compared to training model families from scratch, and around 7x compared to SoTA compression techniques. Each of the nested models performs on par or better than the SoTA in accuracy. Moreover, unlike other compression methods, the nested capability of our approach allows having a many-in-one reasoning model that has constant deployment memory against the number of models in the family.", "AI": {"tldr": "Nemotron Elastic\u901a\u8fc7\u6743\u91cd\u5171\u4eab\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\uff0c\u5728\u5355\u6a21\u578b\u5185\u540c\u65f6\u652f\u6301\u591a\u5b50\u6a21\u578b\u89c4\u6a21\uff0c\u6781\u5927\u964d\u4f4e\u591a\u89c4\u6a21\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u548c\u90e8\u7f72\u6210\u672c\uff0c\u8fbe\u6210\u9ad8\u51c6\u786e\u7387\u4e0e\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6210\u672c\u6781\u9ad8\uff0c\u9488\u5bf9\u4e0d\u540c\u89c4\u6a21\u548c\u90e8\u7f72\u9700\u6c42\u9700\u91cd\u590d\u8bad\u7ec3\uff0c\u9020\u6210\u8d44\u6e90\u6d6a\u8d39\u3002\u9700\u8981\u4e00\u79cd\u4f18\u5316\u591a\u89c4\u6a21\u6a21\u578b\u8bad\u7ec3\u548c\u90e8\u7f72\u7684\u65b9\u6cd5\u4ee5\u964d\u4f4e\u6210\u672c\u548c\u63d0\u5347\u6548\u7387\u3002", "method": "\u63d0\u51faNemotron Elastic\u6846\u67b6\uff0c\u91c7\u7528\u6df7\u5408Mamba-Attention\u67b6\u6784\u548c\u591a\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff0c\u914d\u5408\u7aef\u5230\u7aef\u8bad\u7ec3\u7684\u8def\u7531\u5668\uff0c\u5229\u7528\u6743\u91cd\u5171\u4eab\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5b9e\u73b0\u96f6\u8bad\u7ec3\u63d0\u53d6\u591a\u5b50\u6a21\u578b\u3002\u6b64\u5916\u5f15\u5165\u4e86\u7fa4\u7ec4\u611f\u77e5SSM\u5f39\u6027\u5316\u3001\u5f02\u6784MLP\u5f39\u6027\u5316\u3001\u57fa\u4e8e\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u7684\u5c42\u91cd\u8981\u6027\u4f30\u8ba1\u548c\u591a\u9884\u7b97\u4f18\u5316\u3002", "result": "\u5728Nemotron Nano V2 12B\u6a21\u578b\u4e0a\uff0c\u5b9e\u73b0\u4e869B\u548c6B\u5b50\u6a21\u578b\u7684\u540c\u65f6\u8bad\u7ec3\uff0c\u4ec5\u75281100\u4ebf\u8bad\u7ec3tokens\uff0c\u8bad\u7ec3\u6210\u672c\u76f8\u8f83\u4e8e\u4ece\u96f6\u8bad\u7ec3\u540c\u7c7b\u6a21\u578b\u5bb6\u65cf\u964d\u4f4e360\u500d\uff0c\u76f8\u8f83\u4e8e\u6700\u5148\u8fdb\u538b\u7f29\u65b9\u6cd5\u964d\u4f4e7\u500d\uff0c\u591a\u4e2a\u5b50\u6a21\u578b\u5728\u51c6\u786e\u7387\u4e0a\u8fbe\u5230\u6216\u4f18\u4e8e\u73b0\u6709\u6700\u4f18\u6c34\u5e73\uff0c\u4e14\u90e8\u7f72\u5185\u5b58\u6052\u5b9a\u3002", "conclusion": "Nemotron Elastic\u6846\u67b6\u901a\u8fc7\u5728\u5355\u4e00\u7236\u6a21\u578b\u4e2d\u5d4c\u5165\u591a\u4e2a\u9002\u5e94\u4e0d\u540c\u90e8\u7f72\u9700\u6c42\u7684\u5b50\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u591a\u6a21\u578b\u89c4\u6a21\u8bad\u7ec3\u7684\u6210\u672c\u5927\u5e45\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u51c6\u786e\u6027\u3002"}}
