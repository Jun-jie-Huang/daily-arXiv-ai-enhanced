<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 31]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.SE](#cs.SE) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages](https://arxiv.org/abs/2512.10967)
*Subham Kumar,Prakrithi Shivaprakash,Abhishek Manoharan,Astut Kurariya,Diptadhi Mukherjee,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 本文首次系统评估了多语种自动语音识别（ASR）系统在印度临床访谈数据上的表现，揭示了模型间及语言间的巨大差异和公平性问题。


<details>
  <summary>Details</summary>
Motivation: 当前ASR在多语种和印度复杂人口构成的医疗环境中的可靠性尚不明确，亟需评估其在真实临床场景下的表现及公平性。

Method: 对比分析了包括Indic Whisper、Whisper、Sarvam等在内的多款领先ASR模型，基于康纳达语、印地语和印度英语的真实临床访谈数据，评估跨语言、说话者身份、性别及交叉人口学变量的转录准确性及错误模式。

Result: 不同模型和语言间转录准确度存在显著差异，部分模型在印度英语表现良好，但对混合语和方言表现较差。发现依据说话者角色和性别存在系统性表现差距。

Conclusion: 本文建立了印度医疗多语种ASR性能和公平性基准，强调必须在ASR开发中充分考虑文化和人口多样性，确保技术在医疗领域的公平有效应用。

Abstract: Automatic Speech Recognition (ASR) is increasingly used to document clinical encounters, yet its reliability in multilingual and demographically diverse Indian healthcare contexts remains largely unknown. In this study, we conduct the first systematic audit of ASR performance on real world clinical interview data spanning Kannada, Hindi, and Indian English, comparing leading models including Indic Whisper, Whisper, Sarvam, Google speech to text, Gemma3n, Omnilingual, Vaani, and Gemini. We evaluate transcription accuracy across languages, speakers, and demographic subgroups, with a particular focus on error patterns affecting patients vs. clinicians and gender based or intersectional disparities. Our results reveal substantial variability across models and languages, with some systems performing competitively on Indian English but failing on code mixed or vernacular speech. We also uncover systematic performance gaps tied to speaker role and gender, raising concerns about equitable deployment in clinical settings. By providing a comprehensive multilingual benchmark and fairness analysis, our work highlights the need for culturally and demographically inclusive ASR development for healthcare ecosystem in India.

</details>


### [2] [Benchmarking Automatic Speech Recognition Models for African Languages](https://arxiv.org/abs/2512.10968)
*Alvin Nahabwe,Sulaiman Kagumire,Denis Musinguzi,Bruno Beijuka,Jonah Mubuuke Kyagaba,Peter Nabende,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CL

TL;DR: 本文系统评估了四种先进的自动语音识别（ASR）模型在13种非洲语言上的表现，揭示了不同模型在不同数据资源规模下的优势与劣势。


<details>
  <summary>Details</summary>
Motivation: 非洲语言的自动语音识别受限于标注数据匮乏和缺乏模型选择、数据规模扩展及解码策略的系统指导，亟需统一比较研究以指导实际应用。

Method: 本研究对Whisper、XLS-R、MMS和W2v-BERT四种ASR模型进行了统一基准测试，使用从1小时到400小时不同规模的带注释数据进行微调，分析模型表现和外部语言模型解码的作用。

Result: 研究发现：MMS和W2v-BERT在极低资源条件下更为高效，XLS-R随着数据增多表现提升明显，而Whisper在中等资源条件下优势突出。同时揭示了外部语言模型解码提升效果的条件和局限。

Conclusion: 通过揭示预训练覆盖度、模型架构、数据领域及资源量之间的交互影响，本文为设计适合非洲低资源语言的ASR系统提供了实践性指导和理论洞见。

Abstract: Automatic speech recognition (ASR) for African languages remains constrained by limited labeled data and the lack of systematic guidance on model selection, data scaling, and decoding strategies. Large pre-trained systems such as Whisper, XLS-R, MMS, and W2v-BERT have expanded access to ASR technology, but their comparative behavior in African low-resource contexts has not been studied in a unified and systematic way. In this work, we benchmark four state-of-the-art ASR models across 13 African languages, fine-tuning them on progressively larger subsets of transcribed data ranging from 1 to 400 hours. Beyond reporting error rates, we provide new insights into why models behave differently under varying conditions. We show that MMS and W2v-BERT are more data efficient in very low-resource regimes, XLS-R scales more effectively as additional data becomes available, and Whisper demonstrates advantages in mid-resource conditions. We also analyze where external language model decoding yields improvements and identify cases where it plateaus or introduces additional errors, depending on the alignment between acoustic and text resources. By highlighting the interaction between pre-training coverage, model architecture, dataset domain, and resource availability, this study offers practical and insights into the design of ASR systems for underrepresented languages.

</details>


### [3] [MedBioRAG: Semantic Search and Retrieval-Augmented Generation with Large Language Models for Medical and Biological QA](https://arxiv.org/abs/2512.10996)
*Seonok Kim*

Main category: cs.CL

TL;DR: MedBioRAG是一种结合语义和词汇检索的生物医学问答模型，通过文档检索和监督微调提升问答性能，在多个基准数据集上优于此前最先进模型和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 提高大型语言模型在复杂生物医学问答任务中的表现，利用增强检索技术更精准地获取相关文献以支持回答生成。

Method: 结合语义搜索和词汇搜索策略进行文档检索，并通过监督微调优化模型生成准确且符合上下文的回答。

Result: 在多个生物医学文本检索与问答任务上，MedBioRAG的文档检索（NDCG和MRR指标）、闭合式问答准确率和长文本问答ROUGE得分均超过了前沿模型和GPT-4o基线。

Conclusion: 基于语义搜索的检索结合大语言模型的微调显著提升了生物医学领域问答系统的性能，证明了该方法的有效性。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have significantly enhanced the ability of large language models (LLMs) to perform complex question-answering (QA) tasks. In this paper, we introduce MedBioRAG, a retrieval-augmented model designed to improve biomedical QA performance through a combination of semantic and lexical search, document retrieval, and supervised fine-tuning. MedBioRAG efficiently retrieves and ranks relevant biomedical documents, enabling precise and context-aware response generation. We evaluate MedBioRAG across text retrieval, close-ended QA, and long-form QA tasks using benchmark datasets such as NFCorpus, TREC-COVID, MedQA, PubMedQA, and BioASQ. Experimental results demonstrate that MedBioRAG outperforms previous state-of-the-art (SoTA) models and the GPT-4o base model in all evaluated tasks. Notably, our approach improves NDCG and MRR scores for document retrieval, while achieving higher accuracy in close-ended QA and ROUGE scores in long-form QA. Our findings highlight the effectiveness of semantic search-based retrieval and LLM fine-tuning in biomedical applications.

</details>


### [4] [KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering](https://arxiv.org/abs/2512.10999)
*Xin Sun,Zhongqi Chen,Xing Zheng,Qiang Liu,Shu Wu,Bowen Song,Zilei Wang,Weiqiang Wang,Liang Wang*

Main category: cs.CL

TL;DR: KBQA-R1通过强化学习优化交互策略，解决了知识库问答中大语言模型生成错误查询和模板化推理的问题，实现了更准确的答案生成。


<details>
  <summary>Details</summary>
Motivation: 现有KBQA方法存在生成幻觉查询或模板化推理的问题，缺乏对知识库环境的真正理解和执行验证。

Method: 提出KBQA-R1框架，将KBQA视为多轮决策过程，采用Group Relative Policy Optimization强化学习方法优化策略，结合Referenced Rejection Sampling进行冷启动数据合成。

Result: 在WebQSP、GrailQA和GraphQuestions数据集上，KBQA-R1展示了先进的性能，显著提升了模型基于执行反馈的推理能力。

Conclusion: KBQA-R1有效地将大语言模型推理与可验证执行结合，推动了知识库问答领域的发展。

Abstract: Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.

</details>


### [5] [PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data](https://arxiv.org/abs/2512.11013)
*Pawel Batorski,Paul Swoboda*

Main category: cs.CL

TL;DR: 提出了一种快速自动构造提示（prompt）的方法，通过生成并优化少量示例，提升大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 手工设计高效提示困难且需复杂的少量示例构造，因此需要一种自动化且高效的提示生成方法。

Method: 采用蒙特卡洛Shapley值估计示例效用，迭代替换/删除/保留少量示例；结合激进子采样和重放缓冲区，加速评估过程。

Result: 在有限计算预算下，在文本简化和GSM8K任务上超越现有自动提示方法，并在分类和摘要任务上取得第二名；扩展预算后在多个任务中刷新了自动提示的最先进水平。

Conclusion: 精心构造的少量示例相比全方位指令搜索更能快速且高效地提升提示效果，验证了自动提示中示例选择的重要性。

Abstract: LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our method iteratively replaces/drops/keeps few-shot examples using Monte Carlo Shapley estimation of example utility. For faster execution, we use aggressive subsampling and a replay buffer for faster evaluations. Our method can be run using different compute time budgets. On a limited budget, we outperform existing automatic prompting methods on text simplification and GSM8K and obtain second best results on classification and summarization. With an extended, but still modest compute budget we set a new state of the art among automatic prompting methods on classification, simplification and GSM8K. Our results show that carefully constructed examples, rather than exhaustive instruction search, are the dominant lever for fast and data efficient prompt engineering. Our code is available at https://github.com/Batorskq/PIAST.

</details>


### [6] [MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data](https://arxiv.org/abs/2512.11074)
*Christopher Driggers-Ellis,Detravious Brinkley,Ray Chen,Aashish Dhawan,Daisy Zhe Wang,Christan Grant*

Main category: cs.CL

TL;DR: 本文提出了MultiScript30k，一个涵盖多种全球语言新脚本的多模态机器翻译数据集扩展，弥补了原Multi30k数据集仅限欧洲拉丁语系语言的问题。


<details>
  <summary>Details</summary>
Motivation: 原Multi30k数据集仅包含捷克语、英语、法语和德语，局限了多模态机器翻译（MMT）技术的发展，缺乏对更多语言尤其是非拉丁文字语言的支持。

Method: 通过使用NLLB200-3.3B模型，将Multi30k的英文版本（Multi30k-En）翻译成阿拉伯语、西班牙语、乌克兰语、简体中文和繁体中文，建立了包含3万多句子的MultiScript30k数据集。

Result: 多语种 similarity 分析显示翻译与原文具有较高的余弦相似度（>0.8）和极低对称KL散度(<0.000251)，COMETKiwi评测结果显示不同语言表现各异，部分语言表现接近或稍逊于已有类似数据集。

Conclusion: MultiScript30k有效拓展了Multi30k的语言覆盖范围，支持多种全球语言和文字，促进多模态机器翻译对更多语言的研究与发展。

Abstract: Multi30k is frequently cited in the multimodal machine translation (MMT) literature, offering parallel text data for training and fine-tuning deep learning models. However, it is limited to four languages: Czech, English, French, and German. This restriction has led many researchers to focus their investigations only on these languages. As a result, MMT research on diverse languages has been stalled because the official Multi30k dataset only represents European languages in Latin scripts. Previous efforts to extend Multi30k exist, but the list of supported languages, represented language families, and scripts is still very short. To address these issues, we propose MultiScript30k, a new Multi30k dataset extension for global languages in various scripts, created by translating the English version of Multi30k (Multi30k-En) using NLLB200-3.3B. The dataset consists of over \(30000\) sentences and provides translations of all sentences in Multi30k-En into Ar, Es, Uk, Zh\_Hans and Zh\_Hant. Similarity analysis shows that Multi30k extension consistently achieves greater than \(0.8\) cosine similarity and symmetric KL divergence less than \(0.000251\) for all languages supported except Zh\_Hant which is comparable to the previous Multi30k extensions ArEnMulti30k and Multi30k-Uk. COMETKiwi scores reveal mixed assessments of MultiScript30k as a translation of Multi30k-En in comparison to the related work. ArEnMulti30k scores nearly equal MultiScript30k-Ar, but Multi30k-Uk scores $6.4\%$ greater than MultiScript30k-Uk per split.

</details>


### [7] [Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment](https://arxiv.org/abs/2512.11079)
*Alan Gerber,Sam Cooperman*

Main category: cs.CL

TL;DR: 本文介绍了一种iMessage文本消息分析器，用于研究iMessage消息数据，通过话题建模、响应时间、犹豫打分和情感分析回答五个研究问题。


<details>
  <summary>Details</summary>
Motivation: 随着社会依赖短消息通信，用户对平台中个人信息的了解不足。Apple提供了iMessage消息文件，揭示了数据潜在用途，激发了利用这些数据进行深度分析的动机。

Method: 通过构建iMessage文本消息分析器，进行话题建模、响应时间分析、犹豫度评分和情感分析，回答设定的五个研究问题。

Result: 研究展示了分析器如何有效处理本地存储的iMessage数据，揭示消息主题、用户响应行为及情绪状态，证明该工具在数据解读上的潜力。

Conclusion: 本文证明了利用本地iMessage数据进行多维度分析的可行性，展示了分析器在未来iMessage数据研究中的应用前景。

Abstract: What is your messaging data used for? While many users do not often think about the information companies can gather based off of their messaging platform of choice, it is nonetheless important to consider as society increasingly relies on short-form electronic communication. While most companies keep their data closely guarded, inaccessible to users or potential hackers, Apple has opened a door to their walled-garden ecosystem, providing iMessage users on Mac with one file storing all their messages and attached metadata. With knowledge of this locally stored file, the question now becomes: What can our data do for us? In the creation of our iMessage text message analyzer, we set out to answer five main research questions focusing on topic modeling, response times, reluctance scoring, and sentiment analysis. This paper uses our exploratory data to show how these questions can be answered using our analyzer and its potential in future studies on iMessage data.

</details>


### [8] [Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution](https://arxiv.org/abs/2512.11108)
*Jonathan Kamp,Roos Bakker,Dominique Blok*

Main category: cs.CL

TL;DR: 本文分析了语言模型中不同特征归因方法在解释同一输入时存在的偏差和不一致性，提出了一个模型和方法无关的偏差评估框架。


<details>
  <summary>Details</summary>
Motivation: 不同的特征归因方法对同一输入的解释结果可能存在显著差异，影响用户对解释的信任度，因此需要系统性地理解和量化这些偏差。

Method: 构建了一个包含三种评估指标的通用框架，系统评估了两种Transformer模型在伪随机分类任务和半控因果关系检测任务中，词汇偏差和位置偏差的表现。

Result: 发现词汇偏差和位置偏差在两个模型间结构性不平衡，且产生异常解释的方法更可能自身带有偏差。

Conclusion: 论文揭示了不同归因方法偏差结构的本质，为理解和改进特征归因方法提供了理论支持，有助于提升解释的可信度。

Abstract: Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same input may vary greatly due to underlying biases of different methods. Users may be aware of this issue and mistrust their utility, while unaware users may trust them inadequately. In this work, we delve beyond the superficial inconsistencies between attribution methods, structuring their biases through a model- and method-agnostic framework of three evaluation metrics. We systematically assess both the lexical and position bias (what and where in the input) for two transformers; first, in a controlled, pseudo-random classification task on artificial data; then, in a semi-controlled causal relation detection task on natural data. We find that lexical and position biases are structurally unbalanced in our model comparison, with models that score high on one type score low on the other. We also find signs that methods producing anomalous explanations are more likely to be biased themselves.

</details>


### [9] [FIBER: A Multilingual Evaluation Resource for Factual Inference Bias](https://arxiv.org/abs/2512.11110)
*Evren Ayberk Munis,Deniz Yılmaz,Arianna Muti,Çağrı Toraman*

Main category: cs.CL

TL;DR: 本文提出了FIBER，一个多语言事实知识评估基准，涵盖了英文、意大利文和土耳其文的单实体与多实体任务。


<details>
  <summary>Details</summary>
Motivation: 现有事实知识评估多集中于单实体和单语言，缺乏多语言和多实体设置的系统评估。

Method: 构建包含句子补全、问答和物体计数的多语言数据集，分析提示语言对实体选择的偏见影响及模型在多实体和单实体任务中的表现。

Result: 提示语言确实对输出有影响，且偏见因主题和语言不同而异；多实体问题比单实体更难，英语表现最好，较大模型优于小模型。

Conclusion: 语言和任务类型均影响大语言模型的事实知识表现，FIBER基准有助于更全面评估模型的多语言、多实体事实推断能力。

Abstract: Large language models are widely used across domains, yet there are concerns about their factual reliability and biases. Factual knowledge probing offers a systematic means to evaluate these aspects. Most existing benchmarks focus on single-entity facts and monolingual data. We therefore present FIBER, a multilingual benchmark for evaluating factual knowledge in single- and multi-entity settings. The dataset includes sentence completion, question-answering, and object-count prediction tasks in English, Italian, and Turkish. Using FIBER, we examine whether the prompt language induces inference bias in entity selection and how large language models perform on multi-entity versus single-entity questions. The results indicate that the language of the prompt can influence the model's generated output, particularly for entities associated with the country corresponding to that language. However, this effect varies across different topics such that 31% of the topics exhibit factual inference bias score greater than 0.5. Moreover, the level of bias differs across languages such that Turkish prompts show higher bias compared to Italian in 83% of the topics, suggesting a language-dependent pattern. Our findings also show that models face greater difficulty when handling multi-entity questions than the single-entity questions. Model performance differs across both languages and model sizes. The highest mean average precision is achieved in English, while Turkish and Italian lead to noticeably lower scores. Larger models, including Llama-3.1-8B and Qwen-2.5-7B, show consistently better performance than smaller 3B-4B models.

</details>


### [10] [SciLaD: A Large-Scale, Transparent, Reproducible Dataset for Natural Scientific Language Processing](https://arxiv.org/abs/2512.11192)
*Luca Foppiano,Sotaro Takeshita,Pedro Ortiz Suarez,Ekaterina Borisova,Raia Abu Ahmad,Malte Ostendorff,Fabio Barth,Julian Moreno-Schneider,Georg Rehm*

Main category: cs.CL

TL;DR: SciLaD是一个基于开源工具和公开数据源构建的大规模科学语言数据集，涵盖1000万英文和3500万多语言科学出版物。


<details>
  <summary>Details</summary>
Motivation: 利用开源工具实现大规模科学数据的高质量整理，推动科学语言处理研究。

Method: 基于开源框架构建SciLaD数据集，包含英文和多语言科学文献，并公开数据生成流水线。

Result: 通过在SciLaD上预训练RoBERTa模型，并在多项基准测试中表现良好，验证数据集的质量和实用性。

Conclusion: SciLaD数据集及评估流水线的发布促进了科学语言处理的可复现性、透明性和研究发展。

Abstract: SciLaD is a novel, large-scale dataset of scientific language constructed entirely using open-source frameworks and publicly available data sources. It comprises a curated English split containing over 10 million scientific publications and a multilingual, unfiltered TEI XML split including more than 35 million publications. We also publish the extensible pipeline for generating SciLaD. The dataset construction and processing workflow demonstrates how open-source tools can enable large-scale, scientific data curation while maintaining high data quality. Finally, we pre-train a RoBERTa model on our dataset and evaluate it across a comprehensive set of benchmarks, achieving performance comparable to other scientific language models of similar size, validating the quality and utility of SciLaD. We publish the dataset and evaluation pipeline to promote reproducibility, transparency, and further research in natural scientific language processing and understanding including scholarly document processing.

</details>


### [11] [Multi-Intent Spoken Language Understanding: Methods, Trends, and Challenges](https://arxiv.org/abs/2512.11258)
*Di Wu,Ruiyu Fang,Liting Jiang,Shuangyong Song,Xiaomeng Huang,Shiquan Wang,Zhongqiu Li,Lingling Shi,Mengjiao Bao,Yongxiang Li,Hao Huang*

Main category: cs.CL

TL;DR: 本文综述了多意图语音理解领域的最新进展，重点分析了多意图检测和槽位填充的解码范式与建模方法。


<details>
  <summary>Details</summary>
Motivation: 当前多意图语音理解研究虽取得显著进展，但缺乏系统、全面的综述，难以指导后续研究。

Method: 从解码范式和建模方法两个角度，详细回顾现有多意图SLU模型，比较代表性模型性能，分析其优缺点。

Result: 综合评估了不同模型的表现，揭示了它们在处理多意图语音理解任务中的优势与不足。

Conclusion: 本文总结当前多意图SLU面临的挑战，展望未来研究方向，旨在推动该领域深入发展。

Abstract: Multi-intent spoken language understanding (SLU) involves two tasks: multiple intent detection and slot filling, which jointly handle utterances containing more than one intent. Owing to this characteristic, which closely reflects real-world applications, the task has attracted increasing research attention, and substantial progress has been achieved. However, there remains a lack of a comprehensive and systematic review of existing studies on multi-intent SLU. To this end, this paper presents a survey of recent advances in multi-intent SLU. We provide an in-depth overview of previous research from two perspectives: decoding paradigms and modeling approaches. On this basis, we further compare the performance of representative models and analyze their strengths and limitations. Finally, we discuss the current challenges and outline promising directions for future research. We hope this survey will offer valuable insights and serve as a useful reference for advancing research in multi-intent SLU.

</details>


### [12] [Leveraging LLMs for Title and Abstract Screening for Systematic Review: A Cost-Effective Dynamic Few-Shot Learning Approach](https://arxiv.org/abs/2512.11261)
*Yun-Chung Liu,Rui Yang,Jonathan Chong Kai Liew,Ziran Yin,Henry Foote,Christopher J. Lindsell,Chuan Hong*

Main category: cs.CL

TL;DR: 本文提出了一种两阶段动态少样本学习方法，利用大型语言模型提高系统评价中标题和摘要筛选的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 随着研究文献数量的迅速增长，系统评价标题和摘要筛选步骤耗时且资源密集，亟需提高效率的方法。

Method: 设计两阶段动态少样本学习方法，先用低成本大型语言模型进行初筛，再用高性能模型重新评估低置信度样本，平衡性能与计算成本。

Result: 在10个系统评价中验证，该方法表现出较强的泛化能力和成本效益，能显著减少人工筛选负担。

Conclusion: 该方法可有效提高系统评价筛选效率，具备在实际应用中加速系统评价过程的潜力。

Abstract: Systematic reviews are a key component of evidence-based medicine, playing a critical role in synthesizing existing research evidence and guiding clinical decisions. However, with the rapid growth of research publications, conducting systematic reviews has become increasingly burdensome, with title and abstract screening being one of the most time-consuming and resource-intensive steps. To mitigate this issue, we designed a two-stage dynamic few-shot learning (DFSL) approach aimed at improving the efficiency and performance of large language models (LLMs) in the title and abstract screening task. Specifically, this approach first uses a low-cost LLM for initial screening, then re-evaluates low-confidence instances using a high-performance LLM, thereby enhancing screening performance while controlling computational costs. We evaluated this approach across 10 systematic reviews, and the results demonstrate its strong generalizability and cost-effectiveness, with potential to reduce manual screening burden and accelerate the systematic review process in practical applications.

</details>


### [13] [When Actions Teach You to Think: Reasoning-Action Synergy via Reinforcement Learning in Conversational Agents](https://arxiv.org/abs/2512.11277)
*Mrinal Rawat,Arkajyoti Chakraborty,Neha Gupta,Roberto Pieraccini*

Main category: cs.CL

TL;DR: 该论文提出利用强化学习改进大语言模型推理能力和工具调用精度，提升下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调难以应对数据分布变化，且收集高质量推理路径注释成本高且主观性强。推理能力对于模型泛化和可靠性至关重要。

Method: 通过强化学习训练大语言模型生成推理步骤，指导工具调用和答案生成。采用Group Relative Policy Optimization，设计基于工具准确率和答案正确性的奖励机制，实现推理和动作的迭代优化。

Result: 实验显示该方法相比无显式推理监督微调模型提升1.5%，相比基础模型Qwen3-1.7B提升40%。推理质量和工具调用精度均得到显著提升。

Conclusion: 结合强化学习从任务结果中学习推理策略，能有效增强大语言模型推理和行动能力，提升对话代理的通用性和表现。

Abstract: Supervised fine-tuning (SFT) has emerged as one of the most effective ways to improve the performance of large language models (LLMs) in downstream tasks. However, SFT can have difficulty generalizing when the underlying data distribution changes, even when the new data does not fall completely outside the training domain. Recent reasoning-focused models such as o1 and R1 have demonstrated consistent gains over their non-reasoning counterparts, highlighting the importance of reasoning for improved generalization and reliability. However, collecting high-quality reasoning traces for SFT remains challenging -- annotations are costly, subjective, and difficult to scale. To address this limitation, we leverage Reinforcement Learning (RL) to enable models to learn reasoning strategies directly from task outcomes. We propose a pipeline in which LLMs generate reasoning steps that guide both the invocation of tools (e.g., function calls) and the final answer generation for conversational agents. Our method employs Group Relative Policy Optimization (GRPO) with rewards designed around tool accuracy and answer correctness, allowing the model to iteratively refine its reasoning and actions. Experimental results demonstrate that our approach improves both the quality of reasoning and the precision of tool invocations, achieving a 1.5% relative improvement over the SFT model (trained without explicit thinking) and a 40% gain compared to the base of the vanilla Qwen3-1.7B model. These findings demonstrate the promise of unifying reasoning and action learning through RL to build more capable and generalizable conversational agents.

</details>


### [14] [AdaSD: Adaptive Speculative Decoding for Efficient Language Model Inference](https://arxiv.org/abs/2512.11280)
*Kuan-Wei Lu,Ding-Yong Hong,Pangfeng Liu*

Main category: cs.CL

TL;DR: 提出了一种无需预训练和超参数调节的自适应推测解码方法AdaSD，通过动态调整生成长度和接受阈值，显著加快大语言模型推理速度，同时保持较高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有推测解码方法通常需要额外训练、复杂调参或事先分析模型与任务，限制了实际应用的便利性和效率。

Method: AdaSD设计了两个自适应阈值：一个用于决定何时停止生成候选token，另一个用于接受token，阈值基于token熵和Jensen-Shannon距离实时调整，无需预训练和调参，兼容现成模型。

Result: 在基准数据集上，AdaSD比标准推测解码速度提升最高49%，准确率下降不到2%，实现了高效且自适应的推理性能。

Conclusion: AdaSD是一种实用且高效的推理方案，适合无需额外调优即可提升大语言模型推理速度的应用场景。

Abstract: Large language models (LLMs) have achieved remarkable performance across a wide range of tasks, but their increasing parameter sizes significantly slow down inference. Speculative decoding mitigates this issue by leveraging a smaller draft model to predict candidate tokens, which are then verified by a larger target model. However, existing approaches often require additional training, extensive hyperparameter tuning, or prior analysis of models and tasks before deployment. In this paper, we propose Adaptive Speculative Decoding (AdaSD), a hyperparameter-free decoding scheme that dynamically adjusts generation length and acceptance criteria during inference. AdaSD introduces two adaptive thresholds: one to determine when to stop candidate token generation and another to decide token acceptance, both updated in real time based on token entropy and Jensen-Shannon distance. This approach eliminates the need for pre-analysis or fine-tuning and is compatible with off-the-shelf models. Experiments on benchmark datasets demonstrate that AdaSD achieves up to 49\% speedup over standard speculative decoding while limiting accuracy degradation to under 2\%, making it a practical solution for efficient and adaptive LLM inference.

</details>


### [15] [CIP: A Plug-and-Play Causal Prompting Framework for Mitigating Hallucinations under Long-Context Noise](https://arxiv.org/abs/2512.11282)
*Qingsen Ma,Dianyun Wang,Ran Jing,Yujun Sun,Zhenbo Xu*

Main category: cs.CL

TL;DR: 该论文提出了一种轻量级的因果提示框架CIP，用于降低大语言模型在处理长且噪声多的检索上下文时的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对复杂检索上下文时，往往依赖虚假的相关性而非真实的因果关系，导致幻觉现象频发。

Method: CIP通过构建实体、动作和事件间的因果关系序列，并将其注入提示中，利用因果干预和反事实推理抑制非因果推理路径，引导模型关注因果相关的证据。

Result: 在包含GPT-4o、Gemini 2.0 Flash和Llama 3.1在内的七个主流语言模型上，CIP均显著提升了推理质量和可靠性，Attributable Rate提升2.6点，Causal Consistency Score提升0.38，有效信息密度提高四倍；API级别测试显示上下文理解加速，响应时延最多减少55.1%。

Conclusion: 因果推理作为一种范式，有望提升大语言模型的可解释性、稳定性和效率，CIP提供了有效的实现路径。

Abstract: Large language models often hallucinate when processing long and noisy retrieval contexts because they rely on spurious correlations rather than genuine causal relationships. We propose CIP, a lightweight and plug-and-play causal prompting framework that mitigates hallucinations at the input stage. CIP constructs a causal relation sequence among entities, actions, and events and injects it into the prompt to guide reasoning toward causally relevant evidence. Through causal intervention and counterfactual reasoning, CIP suppresses non causal reasoning paths, improving factual grounding and interpretability. Experiments across seven mainstream language models, including GPT-4o, Gemini 2.0 Flash, and Llama 3.1, show that CIP consistently enhances reasoning quality and reliability, achieving 2.6 points improvement in Attributable Rate, 0.38 improvement in Causal Consistency Score, and a fourfold increase in effective information density. API level profiling further shows that CIP accelerates contextual understanding and reduces end to end response latency by up to 55.1 percent. These results suggest that causal reasoning may serve as a promising paradigm for improving the explainability, stability, and efficiency of large language models.

</details>


### [16] [LegalRikai: Open Benchmark -- A Benchmark for Complex Japanese Corporate Legal Tasks](https://arxiv.org/abs/2512.11297)
*Shogo Fujita,Yuji Naraki,Yiqing Zhu,Shinsuke Mori*

Main category: cs.CL

TL;DR: 本文介绍了LegalRikai：一个包含四项复杂日本企业法律实践任务的新基准数据集，包含100个需要长篇结构化输出的样本。


<details>
  <summary>Details</summary>
Motivation: 现有自动化法律文本评估方法在处理长篇结构化法律文档时存在不足，且缺乏真实法律环境下的复杂任务基准。

Method: 由法律专业人士在律师监督下构建数据集，并对多个主流大型语言模型（如GPT-5、Gemini 2.5 Pro、Claude Opus 4.1）进行人类和自动化评估，分析其在长文本编辑和结构一致性方面的表现。

Result: 发现抽象指令会导致模型不必要的修改，显示了模型在文档级编辑上的弱点。自动化评价在具备明确语言标准的评价标准上与人类判断高度一致，但在结构一致性评估上仍存在挑战。

Conclusion: 自动化评价可以作为专家资源有限时的筛选工具，提出的数据集评估框架推动法律领域更贴近实际的研究。

Abstract: This paper introduces LegalRikai: Open Benchmark, a new benchmark comprising four complex tasks that emulate Japanese corporate legal practices. The benchmark was created by legal professionals under the supervision of an attorney. This benchmark has 100 samples that require long-form, structured outputs, and we evaluated them against multiple practical criteria. We conducted both human and automated evaluations using leading LLMs, including GPT-5, Gemini 2.5 Pro, and Claude Opus 4.1. Our human evaluation revealed that abstract instructions prompted unnecessary modifications, highlighting model weaknesses in document-level editing that were missed by conventional short-text tasks. Furthermore, our analysis reveals that automated evaluation aligns well with human judgment on criteria with clear linguistic grounding, and assessing structural consistency remains a challenge. The result demonstrates the utility of automated evaluation as a screening tool when expert availability is limited. We propose a dataset evaluation framework to promote more practice-oriented research in the legal domain.

</details>


### [17] [Unifying Dynamic Tool Creation and Cross-Task Experience Sharing through Cognitive Memory Architecture](https://arxiv.org/abs/2512.11303)
*Jiarun Liu,Shiyue Xu,Yang Li,Shangkun Liu,Yongli Yu,Peng Cao*

Main category: cs.CL

TL;DR: SMITH是一种结合动态工具创建与跨任务经验共享的统一认知架构，显著提升大语言模型代理的任务适应能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型代理在适应新任务时受限于工具可用性和经验复用，现有方法工具覆盖有限且经验利用不足，导致探索效率低和性能不佳。

Method: 提出SMITH架构，通过层级记忆系统（程序、语义、情景记忆）实现工具的迭代代码生成与经验的语义匹配检索；采用基于代理集难度再估计的课程学习策略。

Result: 在GAIA基准测试中，SMITH达到81.8% Pass@1准确率，优于最新基线Alita（75.2%）和Memento（70.9%）。

Conclusion: SMITH为构建能通过工具创建与经验累积持续进化能力的自适应智能体奠定了基础。

Abstract: Large Language Model agents face fundamental challenges in adapting to novel tasks due to limitations in tool availability and experience reuse. Existing approaches either rely on predefined tools with limited coverage or build tools from scratch without leveraging past experiences, leading to inefficient exploration and suboptimal performance. We introduce SMITH (Shared Memory Integrated Tool Hub), a unified cognitive architecture that seamlessly integrates dynamic tool creation with cross-task experience sharing through hierarchical memory organization. SMITH organizes agent memory into procedural, semantic, and episodic components, enabling systematic capability expansion while preserving successful execution patterns. Our approach formalizes tool creation as iterative code generation within controlled sandbox environments and experience sharing through episodic memory retrieval with semantic similarity matching. We further propose a curriculum learning strategy based on agent-ensemble difficulty re-estimation. Extensive experiments on the GAIA benchmark demonstrate SMITH's effectiveness, achieving 81.8% Pass@1 accuracy and outperforming state-of-the-art baselines including Alita (75.2%) and Memento (70.9%). Our work establishes a foundation for building truly adaptive agents that continuously evolve their capabilities through principled integration of tool creation and experience accumulation.

</details>


### [18] [qa-FLoRA: Data-free query-adaptive Fusion of LoRAs for LLMs](https://arxiv.org/abs/2512.11366)
*Shreya Shukla,Aditya Sriram,Milinda Kuppur Narayanaswamy,Hiteshi Jain*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的查询自适应LoRA融合方法qa-FLoRA，动态计算融合权重，有效提升多领域大语言模型微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA融合方法在处理多领域复杂任务时要么采用静态权重，忽视各适配器的重要性差异；要么需耗费大量数据为每种组合训练权重，存在实用性和效率问题。

Method: 提出qa-FLoRA，通过衡量基础模型与各LoRA适配器的分布差异，动态计算层级融合权重，避免数据和训练需求，适用于现有适配器集合。

Result: 在涵盖数学、编程和医疗等九个多语言复合任务上，qa-FLoRA相比静态融合和无训练基线分别提升约5%-10%，并在LLaMA-2及LLaMA-3模型上接近有监督方法性能。

Conclusion: qa-FLoRA有效实现了多领域适配器的无训练自适应融合，提升了模型对复合查询的处理能力，并且融合权重具有可解释性，展现出良好的实用价值和推广前景。

Abstract: The deployment of large language models for specialized tasks often requires domain-specific parameter-efficient finetuning through Low-Rank Adaptation (LoRA) modules. However, effectively fusing these adapters to handle complex, multi-domain composite queries remains a critical challenge. Existing LoRA fusion approaches either use static weights, which assign equal relevance to each participating LoRA, or require data-intensive supervised training for every possible LoRA combination to obtain respective optimal fusion weights. We propose qa-FLoRA, a novel query-adaptive data-and-training-free method for LoRA fusion that dynamically computes layer-level fusion weights by measuring distributional divergence between the base model and respective adapters. Our approach eliminates the need for composite training data or domain-representative samples, making it readily applicable to existing adapter collections. Extensive experiments across nine multilingual composite tasks spanning mathematics, coding, and medical domains, show that qa-FLoRA outperforms static fusion by ~5% with LLaMA-2 and ~6% with LLaMA-3, and the training-free baselines by ~7% with LLaMA-2 and ~10% with LLaMA-3, while significantly closing the gap with supervised baselines. Further, layer-level analysis of our fusion weights reveals interpretable fusion patterns, demonstrating the effectiveness of our approach for robust multi-domain adaptation.

</details>


### [19] [Mining Legal Arguments to Study Judicial Formalism](https://arxiv.org/abs/2512.11374)
*Tomáš Koref,Lena Held,Mahammad Namazov,Harun Kumru,Yassine Thlija,Christoph Burchard,Ivan Habernal*

Main category: cs.CL

TL;DR: 本文开发了自动化方法，利用自然语言处理技术分析捷克最高法院的司法推理，构建了含9183段落注释的MADON数据集，并通过调整大规模变换模型提高分类效果，实验证伪中东欧形式主义判断的说法。


<details>
  <summary>Details</summary>
Motivation: 现有研究难以大规模系统性地分析司法推理，尤其是针对中东欧形式主义判断的主张缺乏实证支持。

Method: 构建含多类型论证段落和整体形式主义标签的MADON数据集，利用持续训练的法律领域定制变换器大型语言模型及不平衡数据处理技术，结合三阶段模型管线以实现决策和论证类型的分类。

Result: 模型在论证段落检测、法律论点分类和形式主义判断分类均达较高准确度（宏F1分别为82.6%、77.5%、83.2%），管线同时提升效率与可解释性。

Conclusion: 研究挑战了关于中东欧司法形式主义的既有观念，验证了法律论证挖掘在司法哲学分类及更广泛计算法律研究中的潜力，方法具有良好迁移性和开源共享价值。

Abstract: Courts must justify their decisions, but systematically analyzing judicial reasoning at scale remains difficult. This study refutes claims about formalistic judging in Central and Eastern Europe (CEE) by developing automated methods to detect and classify judicial reasoning in Czech Supreme Courts' decisions using state-of-the-art natural language processing methods. We create the MADON dataset of 272 decisions from two Czech Supreme Courts with expert annotations of 9,183 paragraphs with eight argument types and holistic formalism labels for supervised training and evaluation. Using a corpus of 300k Czech court decisions, we adapt transformer LLMs for Czech legal domain by continued pretraining and experiment with methods to address dataset imbalance including asymmetric loss and class weighting. The best models successfully detect argumentative paragraphs (82.6\% macro-F1), classify traditional types of legal argument (77.5\% macro-F1), and classify decisions as formalistic/non-formalistic (83.2\% macro-F1). Our three-stage pipeline combining ModernBERT, Llama 3.1, and traditional feature-based machine learning achieves promising results for decision classification while reducing computational costs and increasing explainability. Empirically, we challenge prevailing narratives about CEE formalism. This work shows that legal argument mining enables reliable judicial philosophy classification and shows the potential of legal argument mining for other important tasks in computational legal studies. Our methodology is easily replicable across jurisdictions, and our entire pipeline, datasets, guidelines, models, and source codes are available at https://github.com/trusthlt/madon.

</details>


### [20] [Improving Translation Quality by Selecting Better Data for LLM Fine-Tuning: A Comparative Analysis](https://arxiv.org/abs/2512.11388)
*Felipe Ribeiro Fujita de Mello,Hideyuki Takada*

Main category: cs.CL

TL;DR: 研究了数据选择对开源大语言模型机器翻译微调的影响，比较了五种选择方法，发现语义选择器效果最佳且微调对数据质量高度敏感。


<details>
  <summary>Details</summary>
Motivation: 探讨不同数据选择方法对机器翻译微调效果的影响，提升微调效果的理解与实践。

Method: 在日英语料库上，采用五种数据选择器（TF-IDF、COMET Kiwi、QuRate、FD-Score和随机选择），在控制条件下比较其性能。

Result: 语义基的数据选择方法总体优于词汇和几何启发式方法，即使选择数据的差异小于3%，模型性能也表现出显著差异。

Conclusion: 微调过程对数据质量极为敏感，语义选择器能显著提升机器翻译微调性能。

Abstract: We investigated the impact of data selection on machine translation fine-tuning for open LLMs. Using Japanese-English corpora, we compare five selectors: TF-IDF, COMET Kiwi, QuRate, FD-Score, and random selection, under controlled training conditions. We observed that semantic selectors consistently outperform lexical and geometry-based heuristics, and that even when the selected data differ by less than 3%, the impact on model performance is substantial, underscoring the sensitivity of fine-tuning to data quality.

</details>


### [21] [Minimal Clips, Maximum Salience: Long Video Summarization via Key Moment Extraction](https://arxiv.org/abs/2512.11399)
*Galann Pennec,Zhengyuan Liu,Nicholas Asher,Philippe Muller,Nancy F. Chen*

Main category: cs.CL

TL;DR: 本文提出了一种基于视觉信息关键片段选择的视频摘要方法，通过轻量级视频字幕模型生成视觉描述，再利用大语言模型从中选取最相关片段，从而实现高效且低成本的长视频多模态摘要生成。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型处理长视频时容易丢失重要视觉信息，且缺乏成本效益高的分析工具，需设计能准确捕捉关键片段的摘要方法。

Method: 将视频分割成短片段，使用轻量级视频字幕模型生成每个片段的视觉描述，再由大语言模型选取包含最相关视觉信息的K个片段进行多模态摘要。

Result: 在MovieSum数据集上，所选取的片段仅占影片的6%，但能够构建完整的多模态摘要，摘要性能接近人工标注参考片段选择，明显优于随机选取，且计算成本低。

Conclusion: 本文提出的方法有效提升了长视频关键视觉信息的捕捉和摘要质量，同时保持计算高效，适合成本敏感的多模态视频内容分析。

Abstract: Vision-Language Models (VLMs) are able to process increasingly longer videos. Yet, important visual information is easily lost throughout the entire context and missed by VLMs. Also, it is important to design tools that enable cost-effective analysis of lengthy video content. In this paper, we propose a clip selection method that targets key video moments to be included in a multimodal summary. We divide the video into short clips and generate compact visual descriptions of each using a lightweight video captioning model. These are then passed to a large language model (LLM), which selects the K clips containing the most relevant visual information for a multimodal summary. We evaluate our approach on reference clips for the task, automatically derived from full human-annotated screenplays and summaries in the MovieSum dataset. We further show that these reference clips (less than 6% of the movie) are sufficient to build a complete multimodal summary of the movies in MovieSum. Using our clip selection method, we achieve a summarization performance close to that of these reference clips while capturing substantially more relevant video information than random clip selection. Importantly, we maintain low computational cost by relying on a lightweight captioning model.

</details>


### [22] [CLINIC: Evaluating Multilingual Trustworthiness in Language Models for Healthcare](https://arxiv.org/abs/2512.11437)
*Akash Ghosh,Srivarshinee Sridhar,Raghav Kaushik Ravi,Muhsin Muhsin,Sriparna Saha,Chirag Agarwal*

Main category: cs.CL

TL;DR: 本文提出了CLINIC，一个涵盖15种语言的多维度医疗语言模型可信度评估基准，评测模型的真实性、公平性、安全性、健壮性和隐私保护能力，揭示了现有模型在事实准确性、偏见和隐私安全方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型主要针对高资源语言训练，难以应对多语言医疗场景中复杂多样的查询，且缺乏对模型可信度的系统评估，限制了其在全球医疗中的应用。

Method: 构建CLINIC基准，涵盖5个可信度维度和18个任务，涵盖15种语言和广泛的医疗主题，通过系统性评测揭示模型在多语言医疗环境中的表现。

Result: 评测显示语言模型在事实正确性方面存在困难，存在不同人群和语言的偏见，且易受隐私泄露和对抗攻击影响。

Conclusion: CLINIC基准为提升多语言医疗语言模型的可信度和安全性提供基础，推动其在全球多样化医疗环境中的安全应用。

Abstract: Integrating language models (LMs) in healthcare systems holds great promise for improving medical workflows and decision-making. However, a critical barrier to their real-world adoption is the lack of reliable evaluation of their trustworthiness, especially in multilingual healthcare settings. Existing LMs are predominantly trained in high-resource languages, making them ill-equipped to handle the complexity and diversity of healthcare queries in mid- and low-resource languages, posing significant challenges for deploying them in global healthcare contexts where linguistic diversity is key. In this work, we present CLINIC, a Comprehensive Multilingual Benchmark to evaluate the trustworthiness of language models in healthcare. CLINIC systematically benchmarks LMs across five key dimensions of trustworthiness: truthfulness, fairness, safety, robustness, and privacy, operationalized through 18 diverse tasks, spanning 15 languages (covering all the major continents), and encompassing a wide array of critical healthcare topics like disease conditions, preventive actions, diagnostic tests, treatments, surgeries, and medications. Our extensive evaluation reveals that LMs struggle with factual correctness, demonstrate bias across demographic and linguistic groups, and are susceptible to privacy breaches and adversarial attacks. By highlighting these shortcomings, CLINIC lays the foundation for enhancing the global reach and safety of LMs in healthcare across diverse languages.

</details>


### [23] [Mistake Notebook Learning: Selective Batch-Wise Context Optimization for In-Context Learning](https://arxiv.org/abs/2512.11485)
*Xuanbo Su,Yingfang Zhang,Hao Luo,Xiaoteng Liu,Leo Huang*

Main category: cs.CL

TL;DR: 引入了一种无需训练的错误笔记本学习框架（MNL），通过批量抽象错误模式并动态更新知识库，提升大语言模型的任务适应能力。


<details>
  <summary>Details</summary>
Motivation: 克服现有大语言模型的梯度微调（计算量大，遗忘问题）和上下文学习（鲁棒性低，错误学习差）缺陷。

Method: MNL通过批量错误抽象提取通用指导，将其存储在动态知识库中，并通过保留验证确保指导的单调改进，无需训练即可提升性能。

Result: MNL在多个复杂推理任务（如GSM8K、Spider、AIME、KaggleDBQA）上表现优异，接近甚至超越监督微调，并显著优于其他无需训练的方法。

Conclusion: MNL是一种强有力的无需训练的替代方案，有效提升了大语言模型在复杂推理任务上的性能与鲁棒性。

Abstract: Large language models (LLMs) adapt to tasks via gradient fine-tuning (heavy computation, catastrophic forgetting) or In-Context Learning (ICL: low robustness, poor mistake learning). To fix this, we introduce Mistake Notebook Learning (MNL), a training-free framework with a persistent knowledge base of abstracted error patterns. Unlike prior instance/single-trajectory memory methods, MNL uses batch-wise error abstraction: it extracts generalizable guidance from multiple failures, stores insights in a dynamic notebook, and retains only baseline-outperforming guidance via hold-out validation (ensuring monotonic improvement). We show MNL nearly matches Supervised Fine-Tuning (93.9% vs 94.3% on GSM8K) and outperforms training-free alternatives on GSM8K, Spider, AIME, and KaggleDBQA. On KaggleDBQA (Qwen3-8B), MNL hits 28% accuracy (47% relative gain), outperforming Memento (15.1%) and Training-Free GRPO (22.1) - proving it's a strong training-free alternative for complex reasoning.

</details>


### [24] [Building Patient Journeys in Hebrew: A Language Model for Clinical Timeline Extraction](https://arxiv.org/abs/2512.11502)
*Kai Golan Hashiloni,Brenda Kasabe Nokai,Michal Shevach,Esthy Shemesh,Ronit Bartin,Anna Bergrin,Liran Harel,Nachum Dershowitz,Liat Nadai Arad,Kfir Bar*

Main category: cs.CL

TL;DR: 本文提出了一个基于Hebrew医疗语言模型的新方法，用于从电子健康记录中提取结构化的临床时间线，实现患者就诊历程构建。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中包含大量临床信息，如何从中准确提取时间事件关系，构建患者的完整临床历程，是医疗信息处理中的难点。

Method: 基于DictaBERT 2.0，利用超过五百万去标识化医院记录进行持续预训练。同时，构建两个新的带时间事件注释的数据集用于评估模型性能。

Result: 模型在内科、急诊和肿瘤学两个数据集上表现出较强的效果。词汇适配提升了词元效率，去标识化处理未影响模型性能。

Conclusion: 该模型支持隐私保护的医疗文本分析，能够有效构建患者临床时间线，有助于医疗研究和临床决策，且已对研究开放使用。

Abstract: We present a new Hebrew medical language model designed to extract structured clinical timelines from electronic health records, enabling the construction of patient journeys. Our model is based on DictaBERT 2.0 and continually pre-trained on over five million de-identified hospital records. To evaluate its effectiveness, we introduce two new datasets -- one from internal medicine and emergency departments, and another from oncology -- annotated for event temporal relations. Our results show that our model achieves strong performance on both datasets. We also find that vocabulary adaptation improves token efficiency and that de-identification does not compromise downstream performance, supporting privacy-conscious model development. The model is made available for research use under ethical restrictions.

</details>


### [25] [Does Less Hallucination Mean Less Creativity? An Empirical Investigation in LLMs](https://arxiv.org/abs/2512.11509)
*Mohor Banerjee,Nadya Yuki Wangsajaya,Syed Ali Redha Alsagoff,Min Sen Tan,Zachary Choy Kit Chun,Alvin Chan Guo Wei*

Main category: cs.CL

TL;DR: 本文研究了减少大语言模型幻觉的三种方法对模型创造力的影响，发现链式验证提升了发散性创造力，解码法抑制它，检索增强生成影响较小。


<details>
  <summary>Details</summary>
Motivation: 现有减少大语言模型幻觉的方法对创造性生成的影响尚未探讨，而科学发现需要兼顾事实准确性和创造性假设生成。

Method: 研究了三种减少幻觉的方法：链式验证（CoVe）、对比层解码（DoLa）和检索增强生成（RAG），并在不同模型和尺度上使用两个创造力基准进行评估。

Result: 链式验证方法提升了模型的发散性创造力，解码对比层方法抑制了发散性创造力，检索增强生成对创造力影响较小。

Conclusion: 选择幻觉减少方法时需要权衡事实准确性和创造性，链式验证适合科学应用中需高创造性的场景，为科学发现中的模型应用提供指导。

Abstract: Large Language Models (LLMs) exhibit remarkable capabilities in natural language understanding and reasoning, but suffer from hallucination: the generation of factually incorrect content. While numerous methods have been developed to reduce hallucinations, their impact on creative generations remains unexplored. This gap is particularly critical for AI-assisted scientific discovery, which requires both factual accuracy and creative hypothesis generation. We investigate how three hallucination-reduction techniques: Chain of Verification (CoVe), Decoding by Contrasting Layers (DoLa), and Retrieval-Augmented Generation (RAG), affect creativity in LLMs. Evaluating multiple model families (LLaMA, Qwen, Mistral) at varying scales (1B - 70B parameters) on two creativity benchmarks (NeoCoder and CS4), we find that these methods have opposing effects on divergent creativity. CoVe enhances divergent thinking, DoLa suppresses it, and RAG shows minimal impact. Our findings provide guidance for selecting appropriate hallucination-reduction methods in scientific applications, where the balance between factual accuracy and creative exploration is crucial.

</details>


### [26] [Extending a Parliamentary Corpus with MPs' Tweets: Automatic Annotation and Evaluation Using MultiParTweet](https://arxiv.org/abs/2512.11567)
*Mevlüt Bagci,Ali Abusaleh,Daniel Baumartz,Giueseppe Abrami,Maxim Konca,Alexander Mehler*

Main category: cs.CL

TL;DR: 本文介绍了MultiParTweet多语言推文语料库，将政治人物社交媒体内容与德国议会辩论语料连接，实现线上线下政治话语比较。该语料包含近4万条推文及丰富的情感、情绪和主题自动标注，并通过人工注释进行了验证。


<details>
  <summary>Details</summary>
Motivation: 社交媒体成为现代政治的重要媒介，能够反映政治人物意识形态并促进与年轻一代沟通，因而需要关联社交媒体与传统政治语料以开展比较研究。

Method: 构建MultiParTweet推文语料库，结合九个文本模型和一个视觉语言模型进行情感、情绪和主题标注，并开发TTLABTweetCrawler工具实现数据收集。利用模型间相互预测验证标注方法的有效性。

Result: MultiParTweet包含39546条推文和19056条媒体项，自动标注效果经人工验证，并且视觉语言模型标注更符合人工标注者的偏好，模型间具有良好的相互预测能力。

Conclusion: MultiParTweet及TTLABTweetCrawler工具为研究政治线上线下话语提供了丰富资源和技术支持，视觉语言多模态标注更贴合人类理解，推动了多模态政治文本分析的发展。

Abstract: Social media serves as a critical medium in modern politics because it both reflects politicians' ideologies and facilitates communication with younger generations. We present MultiParTweet, a multilingual tweet corpus from X that connects politicians' social media discourse with German political corpus GerParCor, thereby enabling comparative analyses between online communication and parliamentary debates. MultiParTweet contains 39 546 tweets, including 19 056 media items. Furthermore, we enriched the annotation with nine text-based models and one vision-language model (VLM) to annotate MultiParTweet with emotion, sentiment, and topic annotations. Moreover, the automated annotations are evaluated against a manually annotated subset. MultiParTweet can be reconstructed using our tool, TTLABTweetCrawler, which provides a framework for collecting data from X. To demonstrate a methodological demonstration, we examine whether the models can predict each other using the outputs of the remaining models. In summary, we provide MultiParTweet, a resource integrating automatic text and media-based annotations validated with human annotations, and TTLABTweetCrawler, a general-purpose X data collection tool. Our analysis shows that the models are mutually predictable. In addition, VLM-based annotation were preferred by human annotators, suggesting that multimodal representations align more with human interpretation.

</details>


### [27] [Visualizing token importance for black-box language models](https://arxiv.org/abs/2512.11573)
*Paulius Rauba,Qiyao Wei,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 本文提出了一种名为分布式敏感性分析（DBSA）的轻量级无模型依赖方法，用于评估黑盒大语言模型输出对每个输入词的敏感性，解决了在不能访问模型内部且模型输出具有随机性的情况下分析输入影响的难题。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒大语言模型的审计方法多聚焦于特定行为（如偏见检测），缺乏全面理解输出如何受每个输入词影响的工具，尤其在高风险领域中的实际应用需要该类工具。

Method: 提出DBSA方法，无需对语言模型的分布做假设，通过分析模型输出的分布来评估对每个输入词的敏感性，实现轻量级、无需访问模型内部的输入影响分析。

Result: 通过示例展示了DBSA能够帮助用户快速直观地探索模型对输入词的依赖关系，并发现传统可解释方法可能遗漏的敏感性信息。

Conclusion: DBSA为黑盒大语言模型的敏感性分析提供了实用且高效的工具，有助于提升在生产环境下模型行为的透明度和可靠性。

Abstract: We consider the problem of auditing black-box large language models (LLMs) to ensure they behave reliably when deployed in production settings, particularly in high-stakes domains such as legal, medical, and regulatory compliance. Existing approaches for LLM auditing often focus on isolated aspects of model behavior, such as detecting specific biases or evaluating fairness. We are interested in a more general question -- can we understand how the outputs of black-box LLMs depend on each input token? There is a critical need to have such tools in real-world applications that rely on inaccessible API endpoints to language models. However, this is a highly non-trivial problem, as LLMs are stochastic functions (i.e. two outputs will be different by chance), while computing prompt-level gradients to approximate input sensitivity is infeasible. To address this, we propose Distribution-Based Sensitivity Analysis (DBSA), a lightweight model-agnostic procedure to evaluate the sensitivity of the output of a language model for each input token, without making any distributional assumptions about the LLM. DBSA is developed as a practical tool for practitioners, enabling quick, plug-and-play visual exploration of LLMs reliance on specific input tokens. Through illustrative examples, we demonstrate how DBSA can enable users to inspect LLM inputs and find sensitivities that may be overlooked by existing LLM interpretability methods.

</details>


### [28] [Bounding Hallucinations: Information-Theoretic Guarantees for RAG Systems via Merlin-Arthur Protocols](https://arxiv.org/abs/2512.11614)
*Björn Deiseroth,Max Henning Höth,Kristian Kersting,Letitia Parcalabescu*

Main category: cs.CL

TL;DR: 本文提出了一种基于Merlin-Arthur协议的训练框架，使检索增强生成模型在答题时能验证和利用检索证据，提高生成答案的可信度和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG模型将检索结果仅视为弱启发式信息，导致大语言模型回答时缺乏支持，容易在不完整或误导性上下文中产生幻觉，依赖虚假证据。

Method: 将检索器和生成器组成互动证明系统，使用Merlin-Arthur协议：Merlin提供有用证据，Morgana注入对抗性误导性内容。通过线性XAI方法定位关键证据，训练生成器学会有证据支持时回答，证据不足时拒答，依赖关键上下文信息。同时设计严谨评估框架引入解释信息比例（EIF）指标。

Result: 在多个RAG数据集和不同规模模型上，训练模型在依证性、完整性、可靠性和拒答行为上表现提升，减少幻觉，且无需人工标注不可答问题。检索器召回率和MRR也得到提升。

Conclusion: 利用自主的互动证明式监督，为研发能够将检索文档视为可验证证据而非建议的可靠RAG系统提供了理论和实践支持。

Abstract: Retrieval-augmented generation (RAG) models rely on retrieved evidence to guide large language model (LLM) generators, yet current systems treat retrieval as a weak heuristic rather than verifiable evidence. As a result, LLMs answer without support, hallucinate under incomplete or misleading context, and rely on spurious evidence. We introduce a training framework that treats the entire RAG pipeline -- both the retriever and the generator -- as an interactive proof system via an adaptation of the Merlin-Arthur (M/A) protocol. Arthur (the generator LLM) trains on questions of unkown provenance: Merlin provides helpful evidence, while Morgana injects adversarial, misleading context. Both use a linear-time XAI method to identify and modify the evidence most influential to Arthur. Consequently, Arthur learns to (i) answer when the context support the answer, (ii) reject when evidence is insufficient, and (iii) rely on the specific context spans that truly ground the answer. We further introduce a rigorous evaluation framework to disentangle explanation fidelity from baseline predictive errors. This allows us to introduce and measure the Explained Information Fraction (EIF), which normalizes M/A certified mutual-information guarantees relative to model capacity and imperfect benchmarks. Across three RAG datasets and two model families of varying sizes, M/A-trained LLMs show improved groundedness, completeness, soundness, and reject behavior, as well as reduced hallucinations -- without needing manually annotated unanswerable questions. The retriever likewise improves recall and MRR through automatically generated M/A hard positives and negatives. Our results demonstrate that autonomous interactive-proof-style supervision provides a principled and practical path toward reliable RAG systems that treat retrieved documents not as suggestions, but as verifiable evidence.

</details>


### [29] [Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling](https://arxiv.org/abs/2512.11635)
*Keerthana Murugaraj,Salima Lamsiyah,Marten During,Martin Theobald*

Main category: cs.CL

TL;DR: 本文采用基于Transformer的BERTopic模型，从1955年至2018年报纸文章中提取并分析关于核能和核安全话题的演变，解决了传统主题模型难以捕捉历史文本复杂动态的问题。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型如LDA在处理历史报纸文献中主题演变和OCR噪声时存在局限，难以准确捕捉文本中的动态话题及其发展趋势。

Method: 利用BERTopic的Transformer嵌入技术对1955-2018年间的报纸文本进行主题提取和分类，分析主题的分布和时间演变轨迹。

Result: 证实BERTopic在处理大规模历史文献语料时具有良好扩展性和上下文敏感性，能准确揭示公众话语中核能及核武主题的共现及演变规律。

Conclusion: BERTopic作为传统方法的有效补充，为历史、核能及社会科学研究提供了更丰富的洞见，指出当前技术局限并提出了未来的研究方向。

Abstract: Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite its growing popularity, still remains underused in historical research. Our study focuses on articles published between 1955 and 2018, specifically examining discourse on nuclear power and nuclear safety. We analyze various topic distributions across the corpus and trace their temporal evolution to uncover long-term trends and shifts in public discourse. This enables us to more accurately explore patterns in public discourse, including the co-occurrence of themes related to nuclear power and nuclear weapons and their shifts in topic importance over time. Our study demonstrates the scalability and contextual sensitivity of BERTopic as an alternative to traditional approaches, offering richer insights into historical discourses extracted from newspaper archives. These findings contribute to historical, nuclear, and social-science research while reflecting on current limitations and proposing potential directions for future work.

</details>


### [30] [Speculative Decoding Speed-of-Light: Optimal Lower Bounds via Branching Random Walks](https://arxiv.org/abs/2512.11718)
*Sergey Pankratov,Dan Alistarh*

Main category: cs.CL

TL;DR: 本文建立了确定性推测生成算法在加速大语言模型推断中的理论下界，分析了并行生成的最优策略并验证了理论与实际结果的一致性。


<details>
  <summary>Details</summary>
Motivation: 推测生成技术能通过并行验证多个预测token来加速大语言模型推断，但其加速极限尚不明确，缺乏理论界限分析。

Method: 将token生成过程与分支随机游走对应，分析最优草稿树选择问题，推导出成功预测token数的期望上界表达式。

Result: 证明了期望成功预测token数受验证器容量及熵等参数限制，并通过Llama模型实验证实理论界限的紧致性。

Conclusion: 该研究揭示了推测生成加速的根本限制，为未来设计更高效的并行解码系统提供理论指导。

Abstract: Speculative generation has emerged as a promising technique to accelerate inference in large language models (LLMs) by leveraging parallelism to verify multiple draft tokens simultaneously. However, the fundamental limits on the achievable speedup remain poorly understood. In this work, we establish the first ``tight'' lower bounds on the runtime of any deterministic speculative generation algorithm. This is achieved by drawing a parallel between the token generation process and branching random walks, which allows us to analyze the optimal draft tree selection problem. We prove, under basic assumptions, that the expected number of tokens successfully predicted per speculative iteration is bounded as $\mathbb{E}[X] \leq (μ+ μ_{(2)})\log(P )/μ^2 + O(1)$, where $P$ is the verifier's capacity, $μ$ is the expected entropy of the verifier's output distribution, and $μ_{(2)}$ is the expected second log-moment. This result provides new insights into the limits of parallel token generation, and could guide the design of future speculative decoding systems. Empirical evaluations on Llama models validate our theoretical predictions, confirming the tightness of our bounds in practical settings.

</details>


### [31] [SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support](https://arxiv.org/abs/2512.11755)
*Yuming Feng,Xinrui Jiang*

Main category: cs.CL

TL;DR: 该论文提出了SUMFORU，一个基于用户个性化的可调控产品评论摘要框架，通过融合高质量数据和个性化调优方法，实现了更精准的个性化摘要，对用户决策更具指导性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的产品评论摘要存在过于通用、无法满足个体偏好需求的问题，影响用户做出个性化的有效购买决策。

Method: 提出SUMFORU框架，利用Amazon 2023评论数据集，采用两阶段调优策略：一是通过非对称知识蒸馏进行个性化的监督微调；二是结合偏好估计器进行基于人工智能反馈的强化学习，捕捉更细粒度的个性化信号。

Result: 模型在规则、LLM及人类指标评估中表现均优于现有方法，尤其在一致性、信息可靠性和偏好匹配度方面获得显著提升，并能有效适应未见产品类目。

Conclusion: SUMFORU展现了通过可调控多元对齐技术实现个性化决策支持系统的潜力，开辟了个性化摘要的新路径。

Abstract: Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge distillation, and (2) Reinforcement Learning with AI Feedback (RLAIF) using a preference estimator to capture fine-grained, persona-relevant signals. We evaluate the model across rule-based, LLM-based, and human-centered metrics, demonstrating consistent improvements in consistency, grounding, and preference alignment. Our framework achieves the highest performance across all evaluation settings and generalizes effectively to unseen product categories. Our results highlight the promise of steerable pluralistic alignment for building next-generation personalized decision-support systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [32] [Multi-Objective Reinforcement Learning for Large-Scale Mixed Traffic Control](https://arxiv.org/abs/2512.11247)
*Iftekharul Islam,Weizi Li*

Main category: cs.MA

TL;DR: 本论文提出了结合多目标强化学习和策略性路径规划的分层框架，以实现混合交通环境下的高效、安全且公平的交通控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然能优化效率和安全，但缺乏保障交通公平性的机制，导致低需求车道车辆系统性饥饿问题。

Method: 设计了包含冲突威胁向量的多目标强化学习局部交叉口控制方法，并结合策略性路径规划实现网络级协调，同时引入队列公平性惩罚来保证各车流公平服务。

Result: 在真实网络仿真中，不同自动驾驶车辆渗透率下，平均等待时间减少53%，最大饥饿率和冲突率最高减少86%，同时保持燃油效率。高渗透率下策略路径规划效果更显著。

Conclusion: 通过多目标奖励函数与策略性路径规划的结合，显著提升了混合自主交通环境中的公平性与安全性，为实现公平混合交通控制提供了有效途径。

Abstract: Effective mixed traffic control requires balancing efficiency, fairness, and safety. Existing approaches excel at optimizing efficiency and enforcing safety constraints but lack mechanisms to ensure equitable service, resulting in systematic starvation of vehicles on low-demand approaches. We propose a hierarchical framework combining multi-objective reinforcement learning for local intersection control with strategic routing for network-level coordination. Our approach introduces a Conflict Threat Vector that provides agents with explicit risk signals for proactive conflict avoidance, and a queue parity penalty that ensures equitable service across all traffic streams. Extensive experiments on a real-world network across different robot vehicle (RV) penetration rates demonstrate substantial improvements: up to 53% reductions in average wait time, up to 86% reductions in maximum starvation, and up to 86\% reduction in conflict rate compared to baselines, while maintaining fuel efficiency. Our analysis reveals that strategic routing effectiveness scales with RV penetration, becoming increasingly valuable at higher autonomy levels. The results demonstrate that multi-objective optimization through well-curated reward functions paired with strategic RV routing yields significant benefits in fairness and safety metrics critical for equitable mixed-autonomy deployment.

</details>


### [33] [Evaluating Cooperative Resilience in Multiagent Systems: A Comparison Between Humans and LLMs](https://arxiv.org/abs/2512.11689)
*Manuela Chacon-Chamorro,Juan Sebastián Pinzón,Rubén Manrique,Luis Felipe Giraldo,Nicanor Quijano*

Main category: cs.MA

TL;DR: 本文比较了多智能体系统中人类群体与基于大型语言模型的代理在合作弹性方面的表现，发现人类通过沟通实现最高的合作弹性，且在更严苛环境中依然保持高弹性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统方法比较人类与大型语言模型代理在合作弹性（对破坏性事件的应对能力）方面的表现，旨在填补这一空白。

Method: 在“共享悲剧”社会困境环境中，将人类群体与大型语言模型代理进行并行实验，分别在有无沟通条件下，通过引入持续破坏性消费代理和随机资源环境冲击，评估合作弹性表现。

Result: 人类群体在有沟通的情况下表现出最高的合作弹性，大型语言模型代理在沟通辅助下弹性有所提升但仍低于人类；在人类的启发下，在更严苛环境下实验，人类依旧保持资源并维持高弹性。

Conclusion: 人类在逆境中的决策模式对设计促进亲社会和韧性行为的人工代理具有启示意义。

Abstract: This paper presents a comparative analysis of cooperative resilience in multi-agent systems, defined as the ability to anticipate, resist, recover from, and transform to disruptive events that affect collective well-being. We focus on mixed-motive social dilemmas instantiated as a \textit{Tragedy of the Commons} environment from the Melting Pot suite, where we systematically compare human groups and Large Language Model (LLM)-based agents, each evaluated with and without explicit communication. Cooperative resilience is assessed under a continuously disruptive condition induced by a persistent unsustainable consumption bot, together with intermittent environmental shocks implemented as stochastic removal of shared resources across scenarios. This experimental design establishes a benchmark for cooperative resilience across agent architectures and interaction modalities, constituting a key step toward systematically comparing humans and LLM-based agents. Using this framework, we find that human groups with communication achieve the highest cooperative resilience compared to all other groups. Communication also improves the resilience of LLM agents, but their performance remains below human levels. Motivated by the performance of humans, we further examine a long-horizon setting with harsher environmental conditions, where humans sustain the shared resource and maintain high resilience in diverse disruption scenarios. Together, these results suggest that human decision-making under adverse social conditions can inform the design of artificial agents that promote prosocial and resilient behaviors.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [34] [Coverage Isn't Enough: SBFL-Driven Insights into Manually Created vs. Automatically Generated Tests](https://arxiv.org/abs/2512.11223)
*Sasara Shimizu,Yoshiki Higo*

Main category: cs.SE

TL;DR: 本文比较了自动生成测试与手工测试在覆盖率和基于频谱的故障定位（SBFL）评分上的表现，发现自动测试覆盖率更高，但SBFL评分较低，特别是在深层嵌套代码中。


<details>
  <summary>Details</summary>
Motivation: 手动创建测试用例耗时，自动测试生成工具日益重要，但现有研究多注重覆盖率，较少关注自动测试在故障定位方面的效果，尤其是基于变异测试引入的人工缺陷。

Method: 采用SBFL评分和代码覆盖率评价自动生成测试与手工测试的性能，通过基于频谱的故障定位技术评估测试对错误定位的支持能力。

Result: 自动生成测试在分支覆盖率上优于手工测试，但在SBFL评分上较低，尤其是在代码结构深度嵌套时表现更差。

Conclusion: 自动和手工测试各有优缺点，结合两者的测试方法可以更有效地提升软件测试效果，尤其是在支持准确故障定位方面。

Abstract: The testing phase is an essential part of software development, but manually creating test cases can be time-consuming. Consequently, there is a growing need for more efficient testing methods. To reduce the burden on developers, various automated test generation tools have been developed, and several studies have been conducted to evaluate the effectiveness of the tests they produce. However, most of these studies focus primarily on coverage metrics, and only a few examine how well the tests support fault localization-particularly using artificial faults introduced through mutation testing. In this study, we compare the SBFL (Spectrum-Based Fault Localization) score and code coverage of automatically generated tests with those of manually created tests. The SBFL score indicates how accurately faults can be localized using SBFL techniques. By employing SBFL score as an evaluation metric-an approach rarely used in prior studies on test generation-we aim to provide new insights into the respective strengths and weaknesses of manually created and automatically generated tests. Our experimental results show that automatically generated tests achieve higher branch coverage than manually created tests, but their SBFL score is lower, especially for code with deeply nested structures. These findings offer guidance on how to effectively combine automatically generated and manually created testing approaches.

</details>


### [35] [AutoFSM: A Multi-agent Framework for FSM Code Generation with IR and SystemC-Based Testing](https://arxiv.org/abs/2512.11398)
*Qiuming Luo,Yanming Lei,Kunzhong Wu,Yixuan Cao,Chengjian Liu*

Main category: cs.SE

TL;DR: 本文提出了AutoFSM，一个用于有限状态机（FSM）Verilog代码生成的多代理协作框架，通过引入中间表示（IR）和自动测试工具链显著提升代码生成的准确性和调试效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在生成FSM控制逻辑时存在语法错误频发、调试效率低和依赖测试基准等问题，限制了其在硬件设计领域的应用。

Method: AutoFSM设计了结构清晰的中间表示(IR)降低语法错误，配备自动从IR到Verilog的转换工具链，并结合SystemC建模与自动测试平台提升调试效率和反馈质量。同时构建了包含67个FSM样例的层次化基准SKT-FSM用于性能评估。

Result: 在同一基础LLM下，AutoFSM在SKT-FSM基准测试中相比开源框架MAGE，成功率提高最多11.94%，语法错误率降低最多17.62%。

Conclusion: 结合结构化中间表示和自动测试，AutoFSM显著提升了RTL代码生成的可靠性和可扩展性，展示了LLM在硬件设计代码生成领域的潜力。

Abstract: With the rapid advancement of large language models (LLMs) in code generation, their applications in hardware design are receiving growing attention. However, existing LLMs face several challenges when generating Verilog code for finite state machine (FSM) control logic, including frequent syntax errors, low debugging efficiency, and heavy reliance on test benchmarks. To address these challenges, this paper proposes AutoFSM, a multi-agent collaborative framework designed for FSM code generation tasks. AutoFSM introduces a structurally clear intermediate representation (IR) to reduce syntax error rate during code generation and provides a supporting toolchain to enable automatic translation from IR to Verilog. Furthermore, AutoFSM is the first to integrate SystemC-based modeling with automatic testbench generation, thereby improving debugging efficiency and feedback quality. To systematically evaluate the framework's performance, we construct SKT-FSM, the first hierarchical FSM benchmark in the field, comprising 67 FSM samples across different complexity levels. Experimental results show that, under the same base LLM, AutoFSM consistently outperforms the open-source framework MAGE on the SKT-FSM benchmark, achieving up to an 11.94% improvement in pass rate and up to a 17.62% reduction in syntax error rate. These results demonstrate the potential of combining LLMs with structured IR and automated testing to improve the reliability and scalability of register-transfer level (RTL) code generation.

</details>


### [36] [REMODEL-LLM: Transforming C code to Java using LLMs](https://arxiv.org/abs/2512.11402)
*Aryan Gupta,Y. Raghu Reddy*

Main category: cs.SE

TL;DR: 本文评估了19个小型量化大语言模型在C代码到Java代码自动翻译任务中的表现，发现大多数模型无法生成可运行的Java代码，只有少数表现尚可，但依然难以处理复杂C语言特性。


<details>
  <summary>Details</summary>
Motivation: C语言向Java语言的自动翻译因范式转换、内存模型差异及数据类型不兼容而极具挑战，迫切需要评估小型量化大语言模型在该任务中的有效性。

Method: 采用结合抽象语法树（AST）语义分解和高度受限规则驱动提示策略的混合流水线，对19个参数规模低于200亿的小型量化模型进行测试。

Result: 大多数模型完全失败，无法生成基础Java代码；少数模型生成可运行代码但语义错误频发；仅3个模型通过超过50%的测试，但对复杂C语言特性仍旧难以处理。

Conclusion: 当前的小型量化大语言模型在C到Java的自动翻译中存在较大性能差距，且对复杂语言特性的理解能力有限，显示出其推理能力的上限。

Abstract: The automated translation of C code to Java code is a notoriously difficult task, fraught with challenges stemming from fundamental paradigm shifts (procedural vs. Object Oriented), memory models (manual pointers vs. Garbage Collection), and incompatible data types. This paper investigates the efficacy of 19 small, quantized LLMs (under 20 billion parameters) for the C to Java translation task. We use a novel, hybrid pipeline that leverages Abstract Syntax Trees (ASTs) for semantic decomposition and employs a highly constrained, rule based prompting strategy. The results are stark: a clear multi tiered performance divide emerged. The vast majority of models (Tier 3, e.g., llama3.1, gemma3, starcoder2) failed 100\% of the tests, proving incapable of generating even basic, runnable Java boilerplate. A small middle tier (Tier 2, e.g., mistral-nemo and mistral) produced runnable code but was plagued by dangerous semantic failures and wrong translations. Only three models (Tier 1: phi4, deepseek-coder-v2, codeqwen) proved viable, passing over 50\% of the test suite. Even these top models failed on the most complex C concepts, such as function pointers, sizeof, and enum logic, revealing a hard ceiling for the reasoning capabilities of current quantized models.

</details>


### [37] [Towards Privacy-Preserving Code Generation: Differentially Private Code Language Models](https://arxiv.org/abs/2512.11482)
*Melih Catal,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: 本文系统评估了差分隐私（DP）在代码大型语言模型（CodeLLMs）中的应用，旨在减少训练数据的记忆现象，从而降低隐私泄露和知识产权违规风险。


<details>
  <summary>Details</summary>
Motivation: CodeLLMs在生成代码片段时可能会无意间记忆训练数据，导致隐私泄露和知识产权问题，限制了其在敏感领域的应用。

Method: 本文先分析了CodeLLMs在微调过程中记忆行为的驱动原因，随后采用差分隐私技术，通过在训练中添加校准噪声来保护单个数据点，并实证评估DP对减少记忆和保持代码生成能力的效果。

Result: 实验证明，差分隐私显著减少了各类代码片段的记忆现象，特别是那些最易被记忆的代码，同时略微增加了模型的困惑度，但代码生成能力得以保存甚至增强。此外，DP对训练时间和能耗影响不大。

Conclusion: 差分隐私技术在保护CodeLLMs免受训练数据记忆风险的同时，不显著减少模型性能与效率，具备实际应用价值，是实现隐私保护的可行方案。

Abstract: Large language models specialized for code (CodeLLMs) have demonstrated remarkable capabilities in generating code snippets, documentation, and test cases. However, despite their promising capabilities, CodeLLMs can inadvertently memorize and reproduce snippets from their training data, which poses risks of privacy breaches and intellectual property violations. These risks restrict the deployment of CodeLLMs in sensitive domains and limit their training datasets to publicly available sources. To mitigate the memorization risk without compromising their task performance, we apply Differential Privacy (DP) to CodeLLMs. To the best of our knowledge, this is the first comprehensive study that systematically evaluates the effectiveness of DP in CodeLLMs. DP adds calibrated noise to the training process to protect individual data points while still allowing the model to learn useful patterns. To this end, we first identify and understand the driving reasons of the memorization behaviour of the CodeLLMs during their fine-tuning. Then, to address this issue, we empirically evaluate the effect of DP on mitigating memorization while preserving code generation capabilities. Our findings show that DP substantially reduces memorization in CodeLLMs across all the tested snippet types. The snippet types most prone to memorization are also the most effectively mitigated by DP. Furthermore, we observe that DP slightly increases perplexity but preserves, and can even enhance, the code generation capabilities of CodeLLMs, which makes it feasible to apply DP in practice without significantly compromising model utility. Finally, we analyze the impact of DP on training efficiency and energy consumption, finding that DP does not significantly affect training time or energy usage, making it a practical choice for privacy-preserving CodeLLMs training.

</details>


### [38] [Mini-SFC: A Comprehensive Simulation Framework for Orchestration and Management of Service Function Chains](https://arxiv.org/abs/2512.11527)
*Xi Wang,Shuo Shi,Chenyu Wu*

Main category: cs.SE

TL;DR: 本文介绍了Mini-SFC，一个支持数字和基于容器虚拟仿真的模块化SFC仿真框架，兼顾动态拓扑调整和开放源码特性，方便快速算法验证和实际部署验证。


<details>
  <summary>Details</summary>
Motivation: 现有的服务功能链(SFC)仿真工具存在功能限制，难以满足复杂网络环境中灵活部署和动态调整的需求。

Method: 设计并实现了Mini-SFC框架，支持数字和容器基础的虚拟仿真，允许在线动态调整网络拓扑，简化模块设计并提供标准求解器接口。

Result: Mini-SFC平台极大缩短了研究者的学习曲线，增强了先进SFC管理和优化的灵活性与可扩展性，并支持快速算法验证和服务部署验证。

Conclusion: Mini-SFC作为一个用户友好且开放源码的平台，有助于推动SFC领域的研究与应用，提供了一个高效实用的仿真工具。

Abstract: In the continuously evolving cloud computing and network environment, service function chain (SFC) plays a crucial role in implementing complex services in the network with its flexible deployment capabilities. To address the limitations of existing SFC simulation tools, this paper introduces Mini-SFC, a modular simulation framework that supports both numerical and container-based virtual simulations, while also supporting online dynamic topology adjustments. As an open-source platform emphasizing user-friendliness, Mini-SFC facilitates rapid algorithm verification and realistic service deployment validation. By simplifying module design and providing standardized solver interfaces, Mini-SFC significantly shortens the learning curve for researchers and enhances the flexibility and scalability required for advanced SFC management and optimization. For readers interested in exploring or utilizing Mini-SFC, more information is available on the official project page.

</details>


### [39] [A Study of Library Usage in Agent-Authored Pull Requests](https://arxiv.org/abs/2512.11589)
*Lukas Twist*

Main category: cs.SE

TL;DR: 该论文通过分析26,760个由AI代理生成的拉取请求，研究了AI代理在代码生成中使用第三方库的情况，发现代理经常导入库但很少新增依赖，且新增依赖多遵循版本管理规范。


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码代理能够完成端到端的软件开发工作流，但目前对其如何使用第三方库仍缺乏了解。理解代理在使用库时的行为对提升自动化软件工程具有重要意义。

Method: 作者以AIDev数据集中26,760个代理生成的拉取请求为样本，统计分析了代理导入第三方库的频率、新依赖的引入情况及版本管理行为，同时考察了所选库的具体种类和多样性。

Result: 研究发现，AI代理在近三成拉取请求中导入库，但仅在1.3%的拉取请求中新增依赖。新增依赖中75%明确指定了版本号，优于直接使用大型语言模型时极少提版本的情况。代理使用的库种类丰富多样，远超过去非代理语言模型的偏好集中现象。

Conclusion: 该研究为理解AI编码代理与软件生态系统的交互提供了首个实证视角，揭示了代理在库使用上的良好实践及多样化偏好，助力推动自动化软件开发的发展。

Abstract: Coding agents are becoming increasingly capable of completing end-to-end software engineering workflows that previously required a human developer, including raising pull requests (PRs) to propose their changes. However, we still know little about how these agents use libraries when generating code, a core part of real-world software development. To fill this gap, we study 26,760 agent-authored PRs from the AIDev dataset to examine three questions: how often do agents import libraries, how often do they introduce new dependencies (and with what versioning), and which specific libraries do they choose? We find that agents often import libraries (29.5% of PRs) but rarely add new dependencies (1.3% of PRs); and when they do, they follow strong versioning practices (75.0% specify a version), an improvement on direct LLM usage where versions are rarely mentioned. Generally, agents draw from a surprisingly diverse set of external libraries, contrasting with the limited "library preferences" seen in prior non-agentic LLM studies. Our results offer an early empirical view into how AI coding agents interact with today's software ecosystems.

</details>
