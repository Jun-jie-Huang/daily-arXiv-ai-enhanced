<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.MA](#cs.MA) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 本文提出了两种融合方法提高多跳知识图问答的效率与可验证性：基于LLM的规划以提高准确性，基于嵌入的神经搜索极大加速推理。


<details>
  <summary>Details</summary>
Motivation: 传统多跳问答依赖大量LLM推理，计算开销大且答案缺乏结构化知识支持，限制了其实用性。

Method: 提出(1)利用单次LLM指导关系序列规划结合广度优先搜索保证答案基于知识图，(2)通过融合文本与图嵌入，用轻量级边评分器替代LLM，实现高效神经搜索。同时通过知识蒸馏压缩模型。

Result: 在MetaQA数据集上，基于规划的可验证推理准确率高（micro-F1>0.90），嵌入神经搜索速度提升100倍以上，且模型压缩后性能无显著下降。

Conclusion: 多跳知识图推理无需依赖庞大模型，而应结合符号结构与学习表示的架构设计，实现高效且可验证的推理。

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在波斯语情感分类任务中的解释可信度，发现模型生成的解释与人工标注存在较大偏差，强调了当前解释方法和评估指标的局限性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs日益用于生成预测的自我解释，尤其是在低资源语言中，解释的真实性（可信度）受到质疑，本研究旨在评估这些解释的可信度。

Method: 通过比较模型与人工标注者识别出的影响词，并使用基于token级别对数概率的置信度分数评估解释的可信度，同时测试两种提示策略（先预测后解释和先解释后预测）对可信度的影响。

Result: 结果显示，虽然LLMs分类性能强，但生成的解释在可信度上与人类判断差异较大，模型之间的解释一致性强于与人类的一致性。

Conclusion: 当前的解释生成方法和评估指标存在局限，需开发更强健的方法以提升多语言以及低资源环境下LLMs解释的可靠性。

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: 本文比较了10种基于变换器的心脏病专用文本嵌入模型，发现编码器架构尤其是BioLinkBERT在性能和计算资源上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前临床自然语言处理领域对于不同模型架构在领域文本嵌入性能的比较较少，亟需系统性评估以指导模型选择。

Method: 通过Low-Rank Adaptation（LoRA）微调技术，在来源于权威医学教材的106,535对心脏病文本上，评估10种基于变换器的嵌入模型。

Result: 编码器架构，尤其是BioLinkBERT，表现出更优的领域特异性性能（分离得分0.510）且计算资源消耗较低，优于更大型的解码器模型。

Conclusion: 更大模型并不一定带来更好的领域文本嵌入效果，该研究为临床NLP系统的模型选型提供了实用指南，并推动医学信息学领域的可复现研究。

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 语言理解不仅涉及表层意义的提取，还需要构建对所描述情境的丰富心理模型。


<details>
  <summary>Details</summary>
Motivation: 由于大脑核心语言系统处理能力有限，语言理解需要将信息传递到其他脑区以进行更深层次的认知处理。

Method: 综述现有证据，结合认知神经科学的最新进展，提出并验证语言信息向脑中其他区域输出的假说。

Result: 认知神经科学提供了理论基础和实验方法，可直接验证该假说。

Conclusion: 语言理解涉及核心语言系统与脑其他区域的协作，这一发现为揭示语言理解的认知和神经机制开辟了新途径。

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 该论文研究了大语言模型在情绪心理理论领域的性别偏见问题，并提出了多种去偏策略，强调训练干预比仅依赖推理时提示工程更有效。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，确保其公平性尤为重要。本研究关注情绪心理理论中性别偏见的检测和消除。

Method: 通过描述人物及环境，询问模型“这个人感觉如何”，检测性别偏见；并设计多种去偏训练方法进行验证。

Result: 发现训练阶段的干预能显著减少模型性别偏见，而推理时基于提示的策略效果有限。

Conclusion: 要有效减少LLM中的性别偏见，应重点采用训练过程中的去偏策略，而非仅依赖提示工程。

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本文介绍了NRC VAD词典的第二版，扩展了10k多词表达和新增词汇的情感维度评分，验证了其可靠性，并分析了多词表达的情感特征。


<details>
  <summary>Details</summary>
Motivation: 现有词典覆盖的词汇有限，且未包含多词表达，限制了情感分析的广度和深度。

Method: 对10k多词表达及其组成词进行人类情感评分，扩充单词覆盖范围，验证评分可靠性，并分析多词表达中的情感特征。

Result: 新词典包含10k多词表达和25k个单词，评分高度可靠，揭示了多词表达的情感强度和情感组合性。

Conclusion: NRC VAD词典第二版极大丰富了情感词汇资源，有助于多领域情感研究，且已公开提供使用。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 本文提出了一种基于情感表情和情感词的自动语言无关情感标注方法，针对南非多语言推文进行实验，实现了约66%到69%的自动标注准确率。


<details>
  <summary>Details</summary>
Motivation: 非洲很多语言缺乏情感标注的数字资源，手动标注耗时且费用高，需自动快速的标注方法提高效率。

Method: 利用含情感信息的表情符号和词语，设计自动语言无关的情感标注方法，在南非多语言推文数据集上进行测试。

Result: 该方法对英语推文标注准确率为66%，Sepedi语言为69%，Setswana语言为63%，平均只有34%的标注需人工修正。

Conclusion: 所提出的自动情感标注方法在低资源语言上表现良好，能有效减少人工标注工作，提高多语言情感分析的效率。

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: 本文提出了PersonaPulse框架，通过动态优化个性化提示，实现大型语言模型更真实的个性表达，并通过情境响应基准进行评价，结果优于以往基于心理学描述的提示设计。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽使用提示引导语言模型表现特定个性，但未针对提示进行优化以最大化个性表达效果，导致个性表现不够真实和生动。

Method: 提出PersonaPulse，通过利用语言模型对个性特征的固有知识，迭代优化角色扮演提示，并结合情境响应基准作为评分工具，确保优化过程更具现实感和上下文相关性。

Result: 通过定量评估，PersonaPulse生成的提示在个性表达效果上优于基于心理学描述设计的传统提示。同时，发现模型规模与个性模拟能力之间存在关系，并能通过暂停优化部分控制个性唤起程度。

Conclusion: 提示优化对大型语言模型个性表达至关重要，本研究为未来自适应AI交互的个性建模提供了新思路和方法。

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [9] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 本文评估了大语言模型（LLMs）在临床错误检测和纠正任务中的表现，发现检索增强动态提示（RDP）方法效果最佳，能够提高召回率，降低误报率，并生成更准确的纠正结果。


<details>
  <summary>Details</summary>
Motivation: 临床文档中存在影响患者安全的多种错误，现有的大语言模型在不同提示策略下的表现尚不明确，亟需探索有效的提示方法以提升错误检测和纠正的准确性。

Method: 基于MEDEC数据集，评估了包括GPT、Claude、Gemini及OpenAI o系列等九种指令调优的LLMs，比较零示例提示、随机示例静态提示（SPR）和检索增强动态提示（RDP）三种策略，在错误标记检测、错误句子检测和错误纠正三子任务上的表现，通过准确率、召回率、误报率及ROUGE-1、BLEURT、BERTScore综合得分进行评估。

Result: 零示例提示召回率较低，随机示例提示虽提高召回但误报率增加，检索增强动态提示在所有模型中均降低误报率约15%，提升错误句子检测召回率5-10%，并生成更符合上下文的纠正结果。

Conclusion: 检索增强动态提示方法显著优于其他提示策略，可通过引用相关示例提升医疗错误检测的准确性和纠正的可靠性，具有推广应用价值。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [10] [AppSelectBench: Application-Level Tool Selection Benchmark](https://arxiv.org/abs/2511.19957)
*Tianyi Chen,Michael Solodko,Sen Wang,Jongwoo Ko,Junheng Hao,Colby Banbury,Sara Abdali,Saeed Amizadeh,Qing Xiao,Yinheng Li,Tianyu Ding,Kamran Ghasedi Dizaji,Suzhen Zheng,Hao Fan,Justin Wagle,Pashmina Cameron,Kazuhito Koishida*

Main category: cs.CL

TL;DR: 本文介绍了AppSelectBench，一个用于评估计算机代理应用选择能力的综合基准，涵盖100种常用桌面应用和10万多个真实多样的任务。通过广泛实验，揭示了现有大型语言模型在跨应用推理与选择上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前计算机代理在应用选择方面缺乏有效的评测基准，现有测试多关注细粒度API选择，难以评估模型在不同应用间推理和选择的能力。

Method: 提出了AppSelectBench基准，包括用户任务生成流水线，生成大量真实、语义明确的用户任务，并制定统一评测协议，涵盖随机、启发式、零样本、少样本和检索增强等多种设置。基准覆盖100种桌面应用，任务量超过10万。

Result: 在封闭源代码和开放源代码的大型语言模型上进行了广泛实验，揭示了模型在跨应用推理和一致性选择上的系统性优势与不足，证明即使最强模型仍难以做出稳定的应用选择。

Conclusion: AppSelectBench为研究和推进智能计算机代理的应用级推理能力提供了基础，是探索该关键但尚未充分研究能力的重要工具。

Abstract: Computer Using Agents (CUAs) are increasingly equipped with external tools, enabling them to perform complex and realistic tasks. For CUAs to operate effectively, application selection, which refers to deciding which application to use before invoking fine-grained tools such as APIs, is a fundamental capability. It determines whether the agent initializes the correct environment, avoids orchestration confusion, and efficiently focuses on relevant context. However, existing benchmarks primarily assess fine-grained API selection, offering limited insight into whether models can reason across and choose between different applications. To fill this gap, we introduce AppSelectBench, a comprehensive benchmark for evaluating application selection in CUAs. AppSelectBench contains a novel user task generation pipeline that produces realistic, diverse, and semantically grounded user intents at scale, together with unified evaluation protocols covering random, heuristic, zero-shot, few-shot, and retrieval-augmented-settings. AppSelectBench covers one hundred widely used desktop applications and includes more than one hundred thousand realistic, diverse, and semantically grounded user tasks. Extensive experiments across both closed-source and open-source large language models reveal systematic strengths and weaknesses in inter-application reasoning, showing that even the most capable models still struggle to make consistent application choices. Together, these results establish AppSelectBench as a foundation for studying and advancing application level reasoning, an essential yet underexplored capability of intelligent CUAs. The source is available at https://github.com/microsoft/appselectbench.

</details>


### [11] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: 本文提出R2R框架，通过动态专家路由和实体抽象策略，有效提升了领域特定检索生成模型的性能，避免了表层过拟合和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 传统通用模型难以捕捉金融、法律等高风险领域的细节，且简单微调易导致过拟合和遗忘。

Method: R2R结合动态专家路由与两阶段训练策略（实体抽象用于泛化），通过掩盖最具预测性的表面信息，迫使模型学习领域不变的相关模式。

Result: 在法律、医疗和金融等多个领域和不同基线模型上，R2R表现均优于通用模型和单领域微调模型。

Conclusion: R2R是一种模型无关且模块化的领域专用方法，具备强跨领域鲁棒性，显著提升了检索增强生成的效果。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [12] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: 本文通过设计一个完全合成的、熵受控的基准测试，研究Transformer在方向性学习中的优化差异，发现即使在无语义的纯合成任务中，GPT-2模型也表现出显著的方向性优化差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明Transformer在理论上应该不偏向序列的方向性，但实际应用中存在“反向诅咒”现象，尚不清楚这是由语言统计特性还是模型结构本身导致。

Method: 设计了一个随机字符串映射的合成任务，通过调节分支因子K构造有向任务和其逆任务，测量模型在零条件熵（正向任务）和已知熵下限（逆向任务）上的性能差距，比较GPT-2和MLP在相同数据的表现。

Result: 结果显示GPT-2即使从头训练也存在明显的方向性优化差距，预训练初始化能改变优化行为但无法消除此差距，LoRA方法在高熵逆向任务中遇到容量瓶颈。

Conclusion: 该研究揭示了因果Transformer训练固有的方向摩擦特性，即使在无语义、无语言统计偏差的条件下依然存在，为进一步理解Transformer逆向学习困难提供了新的研究工具和视角。

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [13] [A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media](https://arxiv.org/abs/2511.20001)
*Edward Ajayi,Martha Kachweka,Mawuli Deku,Emily Aiken*

Main category: cs.CL

TL;DR: 本文提出了一种统一的多分类框架，用于从社交媒体数据检测心理健康和网络欺凌的十个类别，基于Twitter和Reddit数据，采用端到端微调的MentalBERT模型取得最佳效果，准确率达0.92，宏F1分数为0.76，并结合了可解释性框架和人机交互的实际应用界面。


<details>
  <summary>Details</summary>
Motivation: 随着数字空间中心理健康问题和网络欺凌的增加，迫切需要一种可扩展且可解释的检测系统。

Method: 从Twitter和Reddit收集数据，使用"先分割后平衡"策略训练模型，比较传统词汇模型、混合方法和端到端微调的变换器架构，选择领域适应的MentalBERT作为最佳模型，并结合SHAPLLM进行可解释性分析，开发了一个支持实际操作的仪表盘。

Result: 端到端微调显著提高性能，MentalBERT模型达到0.92准确率和0.76宏F1分数，优于通用模型和零-shot大语言模型基线。

Conclusion: 提出的人机结合筛选辅助系统框架具有伦理合理性，强调未来需要多标签、临床验证的数据集，以促进在线安全与计算心理健康的交叉研究。

Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.

</details>


### [14] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种基于超曲面表示的在线个性化视觉语言模型（Online-PVLM），实现测试时即时概念嵌入生成，提升了大规模场景下的适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有个性化视觉语言模型需要为每个新概念学习独立嵌入，无法支持测试时的实时适应，且在大规模应用中检索效率低下。

Method: 提出Online-PVLM框架，利用超曲面表示实现无训练的概念嵌入生成；并设计了包含1292个概念、3万多实例和多样化问题类型的大规模评测集OP-Eval，用于评估在线概念学习。

Result: 大量实验表明Online-PVLM在在线概念学习任务中实现了最先进的性能。

Conclusion: Online-PVLM提供了一种高效且可扩展的个性化视觉语言模型在线学习方法，显著提升了实际应用中的实时适应能力。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [15] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种名为MTA的个性化大语言模型框架，通过共享元LoRA库、动态融合以及少样本自适应，解决了传统微调方法存储成本高和效果不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 传统针对每个用户微调独立模块导致存储成本随用户线性增长，且对少量数据用户效果欠佳，急需一种高效且灵活的个性化解决方案。

Method: MTA框架包括三阶段：构建共享的Meta-LoRA库预训练元个性化特征；自适应LoRA融合动态合成用户专属LoRA，避免单用户存储；少样本设置下叠加轻量级LoRA模块实现高效个性化微调。

Result: 在LaMP基准测试中，MTA在多任务上均优于现有最先进方法，证明了其高效性和灵活性。

Conclusion: MTA框架有效降低了存储成本，提升了少样本用户的个性化性能，为个性化大语言模型提供了可扩展且高效的解决方案。

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [16] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: 提出BiasPrompting框架，通过引导大语言模型对所有选项生成和评估推理，提升多选题问答表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法对多选题缺乏上下文推理，导致推理能力不足，限制了模型表现。

Method: BiasPrompting包含推理生成阶段和推理引导的一致性阶段，分别为每个选项生成支持性推理并综合评估选择答案。

Result: 在五个主流多选题基准测试中，BiasPrompting显著提升了大语言模型的表现和推理能力。

Conclusion: BiasPrompting有效增强了大语言模型的推理能力，为解决复杂多选题提供了坚实基础，优于现有方法。

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [17] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: 本文提出了SSA方法，解决大语言模型中稀疏注意力训练中的梯度更新不足问题，实现稀疏与全注意力的双向对齐，提升性能和稀疏度，支持灵活算力调整并强化长上下文推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏注意力方法虽然减轻了计算复杂度，但在训练中低秩键值对缺少梯度更新，导致稀疏度低和性能受限。

Method: 提出SSA统一训练框架，结合稀疏和全注意力，在每层进行双向对齐，保证所有token梯度流动并促进稀疏注意力更好地学习抑制无用信息。

Result: SSA在多个常识推理基准上实现了稀疏和全注意力下的最先进性能，支持在推理时通过调整稀疏度平衡计算与性能，并展示较强的长上下文外推能力。

Conclusion: SSA有效解决了稀疏注意力梯度不足的问题，通过双向对齐机制促进稀疏学习，提升模型性能和泛化能力，为高效长上下文处理提供了有力支持。

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [18] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: 本文提出了EM2LDL，一个包含英语、普通话和粤语的多语种混合情绪语音语料库，支持细粒度情绪分布学习，提升混合情绪识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有情绪语料库多为单语言和单标签，限制了语言多样性且无法准确建模混合情绪，缺乏生态有效性。

Method: 构建包含三种语言和语言切换现象的语料库，采集来自网络的自发表达，并进行32类别的细粒度情绪分布标注。基于自监督学习模型进行多维度评测。

Result: 基于HuBERT-large-EN的模型在性别、年龄和人格独立评测中表现优异，验证了语料库及方法的有效性。

Conclusion: EM2LDL融合语言多样性和生态有效性，为多语言环境下复杂情绪动态的研究和自适应情感计算系统的开发提供了重要资源和实验平台。数据及代码已公开。

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [19] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 提出了一种基于预训练自动语音识别模型的无训练发音错误检测和诊断新方法，实现了高准确率且避免额外训练。


<details>
  <summary>Details</summary>
Motivation: 传统发音错误检测方法依赖评分模型或音素级别模型训练，复杂且费时。

Method: 利用检索技术结合预训练自动语音识别模型，构建无需训练的发音错误检测框架。

Result: 在L2-ARCTIC数据集上实现了69.60%的F1分数，效果优于现有方法。

Conclusion: 该方法有效避免了复杂模型训练过程，同时保持了较高的检测准确性，适用于语言学习和语音治疗场景。

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [20] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 本文利用大型语言模型和提示工程方法显著提升印度语言的语法纠错效果，实现多个印度语言中领先的绩效。


<details>
  <summary>Details</summary>
Motivation: 针对印度语言资源匮乏、语言多样性和形态复杂性导致语法纠错效果不佳的挑战，探索有效解决方案。

Method: 采用基于提示的策略，结合GPT-4.1、Gemini-2.5和LLaMA-4等大型语言模型，通过零样本和少样本学习实现模型的轻量级适配。

Result: 实验结果表明，提示设计和轻量适配显著提升纠错质量，并在多个印度语言共享任务中取得优异排名，如泰米尔语和印地语排名第一。

Conclusion: 提示驱动的自然语言处理技术结合大型语言模型，能够有效弥合低资源语言的语法纠错性能差距，展现出强大的多语言泛化能力。

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [21] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 本文提出采用图像数据增强技术改进基于网格标注的命名实体识别方法，尤其针对断续实体的文本分割问题，提高识别准确率。


<details>
  <summary>Details</summary>
Motivation: 命名实体识别中的断续实体难以准确分割，传统方法易误分或遗漏，导致识别效果差。

Method: 将图像增强技术（裁剪、缩放、填充）应用于基于网格的模型，以提升模型对断续实体的识别能力和分割处理能力。

Result: 增强后的网格模型在CADEC、ShARe13和ShARe14数据集上，整体F1提升1-2.5%，断续实体提升3.7-8.4%。

Conclusion: 结合图像增强技术的网格标注模型有效改善了跨句断续实体的识别问题，显著提升了命名实体识别性能。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [22] [KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP](https://arxiv.org/abs/2511.20182)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.CL

TL;DR: 本文介绍了KyrgyzBERT，这是首个公开的吉尔吉斯语单语BERT模型，具备35.9M参数，并设计了适合吉尔吉斯语形态结构的分词器。通过新建的kyrgyz-sst2情感分析基准进行评测，表现优异且资源开放。


<details>
  <summary>Details</summary>
Motivation: 吉尔吉斯语缺乏基础的自然语言处理工具，属于低资源语言，亟需专门的语言模型推动研究和应用发展。

Method: 构建了基于BERT架构的吉尔吉斯语单语模型KyrgyzBERT，设计定制分词器，翻译并手动标注了情感分析数据集kyrgyz-sst2，对模型进行微调训练。

Result: KyrgyzBERT在kyrgyz-sst2数据集上微调后获得0.8280的F1分数，性能与参数规模是其五倍的多语言mBERT相当。

Conclusion: 该研究填补了吉尔吉斯语NLP工具的空白，通过公开模型、数据和代码，为未来吉尔吉斯语自然语言处理研究提供了重要资源。

Abstract: Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.

</details>


### [23] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: 本文提出了REFLEX方法，一种利用大语言模型内部知识进行自动事实核查的自我优化范式，提高了判决准确性和解释质量，且显著提升了推理效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的虚假信息威胁公众信任，现有基于大语言模型的事实核查方法依赖外部知识，导致响应延迟、解释不可靠且存在幻觉问题，难以实时应用。

Method: 提出REFLEX范式，通过角色扮演对话形式联合训练判决与解释生成，利用对比激活对构建引导向量，将真相自然地拆解为风格与实质，结合内部激活信号指导推理并抑制噪声解释，实现更准确和高效的推理。

Result: 在真实数据集上，REFLEX超越了传统只引导单一真相方向的方法，仅用465个自我优化样本就实现了最先进性能。此外，带解释训练的模型能促进无解释训练模型性能提升7.57%。

Conclusion: REFLEX验证了利用内在解释信号在事实核查中的双重作用，不仅提升判决的可信度和解释性，也增强了模型的推理效果，展现了自我优化事实核查的潜力。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [24] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种结合单向和双向注意力机制的新型架构SpecFormer，用于提升大语言模型（LLM）推理过程中推测解码的效率，消除对大型前缀树的依赖，实现稳定加速。


<details>
  <summary>Details</summary>
Motivation: 当前推测解码方法依赖复杂的大型草稿树，并假设有大量闲置计算资源，但主流推理系统更倾向于使用批处理方法压缩计算资源，导致低验证资源和低调度成本的推测解码成为挑战。因此，需要更强大、支持草稿序列并行生成的模型。

Method: 提出SpecFormer架构，通过融合单向（自回归）和双向注意力机制，结合自回归模型对输入的全局信息提取能力与非自回归模型的并行生成优势，实现无大型前缀树的高效推测解码。

Result: 通过无损推测解码实验，SpecFormer在不同规模模型上均实现了推理加速，且训练要求更低，计算成本减少。

Conclusion: SpecFormer为大语言模型推理的规模化提供了一种高效、低成本的方案，设置了新的性能标准。

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [25] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在类比推理中编码和应用高层次关系概念的能力，发现其在关系编码和结构对齐方面表现出一定能力，但在关系信息缺失或迁移应用上存在困难。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否能够编码高层次的关系概念并通过结构化比较将其应用于新的类比情境，这对于理解模型类比推理能力及其与人类认知的异同具有重要意义。

Method: 利用比例类比和故事类比来分析LLMs对类比关系的编码和应用，研究其中层和高层隐藏表示中关系信息的传播以及结构对齐情况，同时尝试通过调整关键token的隐藏表示以促进信息迁移。

Result: 发现LLMs能够有效编码类比实体间的关系信息，关系信息主要在中上层传播。推理失败往往因关系信息缺失或结构对齐不佳造成。与人类不同，LLMs在关系迁移应用上存在不足，但通过策略性调整隐藏表示可以部分改进。

Conclusion: 大型语言模型在编码和应用高层次关系概念方面表现出初步能力，但仍存在明显局限，反映其类比推理能力与人类存在相似点和差距，为未来提升模型推理能力提供了方向。

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [26] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: 本文提出了BengaliFig数据集，用于评估大语言模型在低资源语言孟加拉语中的比喻和文化推理能力。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在多语言基准测试表现优异，但在比喻性和文化背景推理，特别是低资源语言环境下的表现尚未充分评估。

Method: 构建一个包含435条来自孟加拉口头及文学传统的谜语数据集，并对谜语进行五个维度的详细注释；通过AI辅助自动转换为多项选择题；用八个主流大语言模型进行零样本和少样本链式思考测试。

Result: 发现大语言模型在比喻性及文化特定推理上表现较弱，表明该领域仍有改进空间。

Conclusion: BengaliFig数据集不仅为低资源文化背景下的语言模型鲁棒性评估提供了诊断工具，也推动了包容性和文化传承意识的NLP评测发展。

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [27] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 本文提出了一种针对词干提取方法的新评估框架，从效用、安全性和下游任务表现三个方面综合评价词干提取效果，实验比较了孟加拉语和英语词干提取器，揭示了过度词干化对性能的负面影响。


<details>
  <summary>Details</summary>
Motivation: 当前词干提取方法的评估手段有限，无法有效捕捉过度词干化带来的潜在危害，亟需一种新的、任务导向的评估方法。

Method: 提出了结合词干效果评分（SES）、模型性能变化（MPD）和词义相似度（ANLD）的综合评估框架，对两个词干提取器进行比较分析。

Result: 孟加拉语词干器虽然SES得分高，但存在明显过度词干化问题（高ANLD值），导致下游任务性能下降；而英语词干器在保持词义安全距离的同时实现了适度词干化，对下游任务有正面贡献。

Conclusion: 该研究提供了一个有效区分词干提取效率提升与词义保持的方法，为选择更可靠的词干器提供了有力工具。

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


### [28] [Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts](https://arxiv.org/abs/2511.20459)
*Mosab Rezaei,Mina Rajaei Moghadam,Abdul Rahman Shaikh,Hamed Alhoori,Reva Freedman*

Main category: cs.CL

TL;DR: 本论文提出了一个框架，利用大语言模型生成并评估19世纪小说家的写作风格文本。通过微调大语言模型和基于变换器的检测器，实现了风格模仿和自动化风格评估。


<details>
  <summary>Details</summary>
Motivation: 传统风格学面临两个核心挑战：缺乏成对数据训练生成模型以及缺乏自动化、可靠的风格文本评估方法，主要依赖人工判断，效率低且结果主观。

Method: 使用大语言模型通过单标记提示词进行微调，生成19世纪作家风格文本。设计基于变换器的检测器训练于真实句子，用作分类器和风格说明工具。结合句法比较与可解释AI（注意力和梯度分析）揭示语言特征。

Result: 生成文本忠实反映了各作者的独特语言模式，基于AI的自动评估方法有效且可靠，可替代人工评估。

Conclusion: 该框架成功实现了风格文本的生成与自动评估，推动了风格学应用的自动化和精确化，相关代码和数据已公开。

Abstract: Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.

</details>


### [29] [Adversarial Confusion Attack: Disrupting Multimodal Large Language Models](https://arxiv.org/abs/2511.20494)
*Jakub Hoscilowicz,Artur Janicki*

Main category: cs.CL

TL;DR: 提出了一种针对多模态大型语言模型的新型攻击方法，旨在通过生成对抗图像来破坏模型的输出一致性和准确性，且攻击具有较强的迁移性。


<details>
  <summary>Details</summary>
Motivation: 针对多模态大型语言模型可能存在的系统性错误生成风险，提出有效的攻击方式以揭示其安全隐患，防止模型在应用中被可靠利用。

Method: 通过最大化下一个标记的熵值，利用基于小型开源模型集合的白盒攻击，采用PGD技术生成对抗图像，在完整图像和对抗验证码中实施攻击，提升攻击的转移能力。

Result: 实验表明单个对抗图像即可在多个模型间实现泛化攻击，能有效破坏不同类型模型，包括未见过的开源模型（如Qwen3-VL）和专有模型（如GPT-5.1）。

Conclusion: 该对抗混淆攻击是一种新型且有效的多模态模型安全威胁，具有较强的泛化和实用性，提示相关模型需加固以防范此类系统性干扰。

Abstract: We introduce the Adversarial Confusion Attack, a new class of threats against multimodal large language models (MLLMs). Unlike jailbreaks or targeted misclassification, the goal is to induce systematic disruption that makes the model generate incoherent or confidently incorrect outputs. Applications include embedding adversarial images into websites to prevent MLLM-powered agents from operating reliably. The proposed attack maximizes next-token entropy using a small ensemble of open-source MLLMs. In the white-box setting, we show that a single adversarial image can disrupt all models in the ensemble, both in the full-image and adversarial CAPTCHA settings. Despite relying on a basic adversarial technique (PGD), the attack generates perturbations that transfer to both unseen open-source (e.g., Qwen3-VL) and proprietary (e.g., GPT-5.1) models.

</details>


### [30] [The Text Aphasia Battery (TAB): A Clinically-Grounded Benchmark for Aphasia-Like Deficits in Language Models](https://arxiv.org/abs/2511.20507)
*Nathan Roll,Jill Kries,Flora Jin,Catherine Wang,Ann Marie Finley,Meghan Sumner,Cory Shain,Laura Gwilliams*

Main category: cs.CL

TL;DR: 本文介绍了针对大型语言模型设计的文本失语症评估工具——文本失语电池（TAB），并验证了自动评分协议的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的临床失语症评估方法不适用于大型语言模型，因为它们假定了人类特有的语言行为压力和认知过程，而这些不适用于人工架构。

Method: 基于快速失语症电池（QAB）设计了TAB，包含连接文本、词汇理解、句子理解和复述四个子测试，并采用自动评分协议（使用Gemini 2.5 Flash）进行大规模评估。

Result: 自动评分协议的评分可靠性接近专家人类评分者，模型与共识的Cohen's kappa为0.255，而人类间为0.286。

Conclusion: TAB作为一个临床基础且可扩展的框架被发布，用于分析人工系统中的语言缺陷，弥补了传统评估在LLM应用上的不足。

Abstract: Large language models (LLMs) have emerged as a candidate "model organism" for human language, offering an unprecedented opportunity to study the computational basis of linguistic disorders like aphasia. However, traditional clinical assessments are ill-suited for LLMs, as they presuppose human-like pragmatic pressures and probe cognitive processes not inherent to artificial architectures. We introduce the Text Aphasia Battery (TAB), a text-only benchmark adapted from the Quick Aphasia Battery (QAB) to assess aphasic-like deficits in LLMs. The TAB comprises four subtests: Connected Text, Word Comprehension, Sentence Comprehension, and Repetition. This paper details the TAB's design, subtests, and scoring criteria. To facilitate large-scale use, we validate an automated evaluation protocol using Gemini 2.5 Flash, which achieves reliability comparable to expert human raters (prevalence-weighted Cohen's kappa = 0.255 for model--consensus agreement vs. 0.286 for human--human agreement). We release TAB as a clinically-grounded, scalable framework for analyzing language deficits in artificial systems.

</details>


### [31] [Bridging the Language Gap: Synthetic Voice Diversity via Latent Mixup for Equitable Speech Recognition](https://arxiv.org/abs/2511.20534)
*Wesley Bian,Xiaofeng Lin,Guang Cheng*

Main category: cs.CL

TL;DR: 本文提出了一种新的语音数据增强技术，显著提升了低资源语言的自动语音识别性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习模型在英语等资源丰富语言上的表现优越，但低资源语言因训练数据不足导致性能差距较大。

Method: 提出了一种创新的语音语料数据增强方法，针对低资源语言优化训练数据。

Result: 通过全面实验，方法显著提升了低资源语言自动语音识别系统的性能，且优于现有增强策略。

Conclusion: 该增强技术为提升低资源语言语音技术提供了实用的解决方案，有助于缩小语言间性能差距。

Abstract: Modern machine learning models for audio tasks often exhibit superior performance on English and other well-resourced languages, primarily due to the abundance of available training data. This disparity leads to an unfair performance gap for low-resource languages, where data collection is both challenging and costly. In this work, we introduce a novel data augmentation technique for speech corpora designed to mitigate this gap. Through comprehensive experiments, we demonstrate that our method significantly improves the performance of automatic speech recognition systems on low-resource languages. Furthermore, we show that our approach outperforms existing augmentation strategies, offering a practical solution for enhancing speech technology in underrepresented linguistic communities.

</details>


### [32] [From Words to Wisdom: Discourse Annotation and Baseline Models for Student Dialogue Understanding](https://arxiv.org/abs/2511.20547)
*Farjana Sultana Mim,Shuchin Aeron,Eric Miller,Kristen Wendell*

Main category: cs.CL

TL;DR: 本论文介绍了一个带注释的教育对话数据集，包含学生知识构建与任务完成的对话特征，并利用GPT-3.5和Llama-3.1模型对对话轮次的语篇特征进行自动预测，结果显示模型表现不足，提示未来研究空间。


<details>
  <summary>Details</summary>
Motivation: 人工分析学生对话识别语篇特征工作量大，限制了教育研究的规模和深度，利用NLP技术可以自动检测这些特征，助力教育研究。

Method: 构建带有知识构建与任务生产语篇特征注释的学生对话数据集，使用预训练大语言模型GPT-3.5和Llama-3.1对对话每轮轮次的语篇特征进行自动预测和基线测试。

Result: 实验结果显示，当前最先进的语言模型在该任务上的表现不佳，表明对教育对话的语篇特征自动识别仍有很大提升空间。

Conclusion: 本研究弥补了NLP对教育对话语篇分析的空白，建立了数据集和基线模型，展示了该领域的挑战和未来研究潜力。

Abstract: Identifying discourse features in student conversations is quite important for educational researchers to recognize the curricular and pedagogical variables that cause students to engage in constructing knowledge rather than merely completing tasks. The manual analysis of student conversations to identify these discourse features is time-consuming and labor-intensive, which limits the scale and scope of studies. Leveraging natural language processing (NLP) techniques can facilitate the automatic detection of these discourse features, offering educational researchers scalable and data-driven insights. However, existing studies in NLP that focus on discourse in dialogue rarely address educational data. In this work, we address this gap by introducing an annotated educational dialogue dataset of student conversations featuring knowledge construction and task production discourse. We also establish baseline models for automatically predicting these discourse properties for each turn of talk within conversations, using pre-trained large language models GPT-3.5 and Llama-3.1. Experimental results indicate that these state-of-the-art models perform suboptimally on this task, indicating the potential for future research.

</details>


### [33] [On Evaluating LLM Alignment by Evaluating LLMs as Judges](https://arxiv.org/abs/2511.20604)
*Yixin Liu,Pengfei Liu,Arman Cohan*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在生成和评估能力上的一致性，提出了无需直接评估生成内容的对齐评估新范式AlignEval。


<details>
  <summary>Details</summary>
Motivation: 评估LLM与人类偏好的对齐通常依赖于人为标注或强大的LLM评判者，而LLM自身的生成与评估能力关系尚不明确。

Method: 分析多款LLM的生成-评估一致性，发现二者高度相关，基于此提出通过LLM的评估角色进行对齐测评的方法。

Result: 实验显示AlignEval在排名LLM时的效果优于或匹配现有自动化评估基准，如AlpacaEval和Arena-Hard。

Conclusion: 研究揭示了LLM生成与评估能力的关联，并提出了一种无需直接评估生成输出即可有效测量人类偏好对齐的新范式。

Abstract: Alignment with human preferences is an important evaluation aspect of LLMs, requiring them to be helpful, honest, safe, and to precisely follow human instructions. Evaluating large language models' (LLMs) alignment typically involves directly assessing their open-ended responses, requiring human annotators or strong LLM judges. Conversely, LLMs themselves have also been extensively evaluated as judges for assessing alignment. In this work, we examine the relationship between LLMs' generation and evaluation capabilities in aligning with human preferences. To this end, we first conduct a comprehensive analysis of the generation-evaluation consistency (GE-consistency) among various LLMs, revealing a strong correlation between their generation and evaluation capabilities when evaluated by a strong LLM preference oracle. Utilizing this finding, we propose a benchmarking paradigm that measures LLM alignment with human preferences without directly evaluating their generated outputs, instead assessing LLMs in their role as evaluators. Our evaluation shows that our proposed benchmark, AlignEval, matches or surpasses widely used automatic LLM evaluation benchmarks, such as AlpacaEval and Arena-Hard, in capturing human preferences when ranking LLMs. Our study offers valuable insights into the connection between LLMs' generation and evaluation capabilities, and introduces a benchmark that assesses alignment without directly evaluating model outputs.

</details>


### [34] [Latent Collaboration in Multi-Agent Systems](https://arxiv.org/abs/2511.20639)
*Jiaru Zou,Xiyuan Yang,Ruizhong Qiu,Gaotang Li,Katherine Tieu,Pan Lu,Ke Shen,Hanghang Tong,Yejin Choi,Jingrui He,James Zou,Mengdi Wang,Ling Yang*

Main category: cs.CL

TL;DR: LatentMAS提出了一种无需训练的多智能体协作框架，通过潜在空间中的直接交互提升推理和通信效率。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统依赖文本中介进行推理和通信，效率和信息传递存在局限，亟需新的协作机制。

Method: LatentMAS通过最后层隐藏嵌入实现自回归潜在思维生成，共享潜在工作记忆来实现无损信息交流，无需额外训练。

Result: 在9个包含数学、科学推理、常识理解和代码生成的基准测试中，LatentMAS表现优异，准确率提升14.6%，输出token减少70.8%-83.7%，推理速度提升4倍以上。

Conclusion: 潜在空间的智能体协作显著提升了系统级推理质量和效率，展现出优越的应用前景。

Abstract: Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [35] [Building Browser Agents: Architecture, Security, and Practical Solutions](https://arxiv.org/abs/2511.19477)
*Aram Vardanyan*

Main category: cs.SE

TL;DR: 本文研究了浏览器代理的生产应用，发现架构设计比模型能力更关键，提出专用工具替代通用浏览智能以提升安全性，实现了约85%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 浏览器代理在实际应用中面临严重的可靠性和安全挑战，尤其通用自主操作的安全风险亟需解决。

Method: 通过混合上下文管理（结合可访问树快照与选择性视觉）、全面浏览器工具及智能提示工程，设计专用约束工具替代依赖大语言模型推理的通用智能。

Result: 代理在WebGames基准测试中完成53项多样化挑战，成功率约85%，显著高于此前约50%的浏览器代理表现，接近人类95.7%的水平。

Conclusion: 模型能力非性能瓶颈，安全性通过架构设计和程序性限制保障，建议放弃通用浏览智能，转向安全高效的专用工具开发。

Abstract: Browser agents enable autonomous web interaction but face critical reliability and security challenges in production. This paper presents findings from building and operating a production browser agent. The analysis examines where current approaches fail and what prevents safe autonomous operation. The fundamental insight: model capability does not limit agent performance; architectural decisions determine success or failure. Security analysis of real-world incidents reveals prompt injection attacks make general-purpose autonomous operation fundamentally unsafe. The paper argues against developing general browsing intelligence in favor of specialized tools with programmatic constraints, where safety boundaries are enforced through code instead of large language model (LLM) reasoning. Through hybrid context management combining accessibility tree snapshots with selective vision, comprehensive browser tooling matching human interaction capabilities, and intelligent prompt engineering, the agent achieved approximately 85% success rate on the WebGames benchmark across 53 diverse challenges (compared to approximately 50% reported for prior browser agents and 95.7% human baseline).

</details>


### [36] [Z-Space: A Multi-Agent Tool Orchestration Framework for Enterprise-Grade LLM Automation](https://arxiv.org/abs/2511.19483)
*Qingsong He,Jing Nan,Jiayu Jiao,Liangjie Tang,Xiaodong Xu,Mengmeng Sun,Qingyao Wang,Minghui Yan*

Main category: cs.SE

TL;DR: 本文提出了Z-Space框架，通过多代理协作和工具过滤算法，提高了大规模异构工具调用的效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大规模异构工具匹配中存在语义联结差、上下文膨胀和推理延迟高的问题，限制了系统实用性。

Method: Z-Space框架采用意图解析模型实现结构化语义理解，基于融合子空间加权算法的FSWW工具过滤模块实现细粒度语义匹配，并构建推理执行代理支持动态规划和容错执行。

Result: 系统在饿了么平台多业务单元部署后，推理时平均token消耗降低96.26%，工具调用准确率达92%。

Conclusion: Z-Space显著提升了大规模企业级MCP服务中智能测试数据生成系统的效率和可靠性。

Abstract: Large Language Models can break through knowledge and timeliness limitations by invoking external tools within the Model Context Protocol framework to achieve automated execution of complex tasks. However, with the rapid growth of enterprise-scale MCP services, efficiently and accurately matching target functionalities among thousands of heterogeneous tools has become a core challenge restricting system practicality. Existing approaches generally rely on full-prompt injection or static semantic retrieval, facing issues including semantic disconnection between user queries and tool descriptions, context inflation in LLM input, and high inference latency. To address these challenges, this paper proposes Z-Space, a data-generation-oriented multi-agent collaborative tool invocation framework Z-Space. The Z-Space framework establishes a multi-agent collaborative architecture and tool filtering algorithm: (1) A structured semantic understanding of user queries is achieved through an intent parsing model; (2) A tool filtering module (FSWW) based on fused subspace weighted algorithm realizes fine-grained semantic alignment between intents and tools without parameter tuning; (3) An inference execution agent is constructed to support dynamic planning and fault-tolerant execution for multi-step tasks. This framework has been deployed in the Eleme platform's technical division, serving large-scale test data generation scenarios across multiple business units including Taotian, Gaode, and Hema. Production data demonstrates that the system reduces average token consumption in tool inference by 96.26\% while achieving a 92\% tool invocation accuracy rate, significantly enhancing the efficiency and reliability of intelligent test data generation systems.

</details>


### [37] [stable-pretraining-v1: Foundation Model Research Made Simple](https://arxiv.org/abs/2511.19484)
*Randall Balestriero,Hugues Van Assel,Sami BuGhanem,Lucas Maes*

Main category: cs.SE

TL;DR: 本文介绍了stable-pretraining，这是一款基于PyTorch等框架构建的模块化、自扩展且高性能的自监督学习工具库，旨在提高研究效率和实验可扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前基础模型和自监督学习的研究受限于复杂代码库、重复实现以及扩展实验的工程负担，急需一个灵活且高效的工具库解决这些问题。

Method: 开发了stable-pretraining库，集成了探针、崩溃检测指标、增强流水线及可扩展评估程序，并通过详细日志记录实现训练动态的可视化和调试支持。

Result: 通过深度表征探针和分析CLIP在合成数据微调下的性能退化，验证了该库能在最小负担下生成新的研究见解。

Conclusion: stable-pretraining通过降低研究门槛、支持大规模实验，促进基础模型研究的加速和拓展。

Abstract: Foundation models and self-supervised learning (SSL) have become central to modern AI, yet research in this area remains hindered by complex codebases, redundant re-implementations, and the heavy engineering burden of scaling experiments. We present stable-pretraining, a modular, extensible, and performance-optimized library built on top of PyTorch, Lightning, Hugging Face, and TorchMetrics. Unlike prior toolkits focused narrowly on reproducing state-of-the-art results, stable-pretraining is designed for flexibility and iteration speed: it unifies essential SSL utilities--including probes, collapse detection metrics, augmentation pipelines, and extensible evaluation routines--within a coherent and reliable framework. A central design principle is logging everything, enabling fine-grained visibility into training dynamics that makes debugging, monitoring, and reproducibility seamless. We validate the library by demonstrating its ability to generate new research insights with minimal overhead, including depthwise representation probing and the analysis of CLIP degradation under synthetic data finetuning. By lowering barriers to entry while remaining scalable to large experiments, stable-pretraining aims to accelerate discovery and expand the possibilities of foundation model research.

</details>


### [38] [Evolution without an Oracle: Driving Effective Evolution with LLM Judges](https://arxiv.org/abs/2511.19489)
*Zhe Zhao,Yuheng Yang,Haibin Wen,Xiaojie Qiu,Zaixi Zhang,Qingfu Zhang*

Main category: cs.SE

TL;DR: 本文提出了MADE框架，利用多代理分解进化策略，通过将模糊指令分解为可验证子要求，解决了主观评价中的高噪声问题，实现了在纯主观评价环境下的有效进化优化。


<details>
  <summary>Details</summary>
Motivation: 当前进化计算依赖于可计算的目标函数，限制了其在主观评价领域的发展。本文旨在突破这一限制，实现仅依赖大语言模型作为评判者的进化优化。

Method: 提出MADE框架，将含糊不清的指令分解为具体可验证的子需求，从而稳定和精确选择压力，降低大语言模型反馈的方差。

Result: 在DevAI和InfoBench等复杂基准测试中，MADE在软件需求满足度上提升超过50%，并在复杂指令遵循测试中达到95%的完全通过率。

Conclusion: 本文验证了从优化“可计算指标”向优化“可描述特质”范式的根本转变，开启了无客观真值的开放领域进化优化新可能。

Abstract: The integration of Large Language Models (LLMs) with Evolutionary Computation (EC) has unlocked new frontiers in scientific discovery but remains shackled by a fundamental constraint: the reliance on an Oracle--an objective, machine-computable fitness function. This paper breaks this barrier by asking: Can evolution thrive in a purely subjective landscape governed solely by LLM judges? We introduce MADE (Multi-Agent Decomposed Evolution), a framework that tames the inherent noise of subjective evaluation through "Problem Specification." By decomposing vague instructions into specific, verifiable sub-requirements, MADE transforms high-variance LLM feedback into stable, precise selection pressure. The results are transformative: across complex benchmarks like DevAI and InfoBench, MADE outperforms strong baselines by over 50% in software requirement satisfaction (39.9% to 61.9%) and achieves a 95% perfect pass rate on complex instruction following. This work validates a fundamental paradigm shift: moving from optimizing "computable metrics" to "describable qualities," thereby unlocking evolutionary optimization for the vast open-ended domains where no ground truth exists.

</details>


### [39] [CodeR3: A GenAI-Powered Workflow Repair and Revival Ecosystem](https://arxiv.org/abs/2511.19510)
*Asif Zaman,Kallol Naha,Khalid Belhajjame,Hasan M. Jamil*

Main category: cs.SE

TL;DR: 本文提出了一个基于生成式人工智能的遗留科学工作流迁移系统CodeR3，用于将衰败的工作流迁移到现代平台，提高了自动化水平但关键任务仍需人工参与。


<details>
  <summary>Details</summary>
Motivation: 遗留科学工作流系统如Taverna因服务停止、依赖过时等问题导致工作流无法使用，亟需一种方法来恢复这些有价值的科学工作流。

Method: 设计了CodeR3系统，利用生成式AI分析衰败工作流特征，自动迁移到Snakemake、VisFlow等现代平台，结合逐步分析可视化、自动服务替换及人工验证机制。

Result: 案例研究表明该方法能显著减少手动解析和服务识别所需的工作量，但服务替换和数据验证仍需领域专家参与。

Conclusion: 提出的框架有效结合自动化与人类判断，未来将构建众包平台支持社区协作恢复和验证遗留工作流的功能与准确性。

Abstract: Scientific workflows encode valuable domain expertise and computational methodologies. Yet studies consistently show that a significant proportion of published workflows suffer from decay over time. This problem is particularly acute for legacy workflow systems like Taverna, where discontinued services, obsolete dependencies, and system retirement render previously functional workflows unusable. We present a novel legacy workflow migration system, called CodeR$^3$ (stands for Code Repair, Revival and Reuse), that leverages generative AI to analyze the characteristics of decayed workflows, reproduce them into modern workflow technologies like Snakemake and VisFlow. Our system additionally integrates stepwise workflow analysis visualization, automated service substitution, and human-in-the-loop validation. Through several case studies of Taverna workflow revival, we demonstrate the feasibility of this approach while identifying key challenges that require human oversight. Our findings reveal that automation significantly reduces manual effort in workflow parsing and service identification. However, critical tasks such as service substitution and data validation still require domain expertise. Our result will be a crowdsourcing platform that enables the community to collaboratively revive decayed workflows and validate the functionality and correctness of revived workflows. This work contributes a framework for workflow revival that balances automation efficiency with necessary human judgment.

</details>


### [40] [Agint: Agentic Graph Compilation for Software Engineering Agents](https://arxiv.org/abs/2511.19635)
*Abhi Chivukula,Jay Somasundaram,Vijay Somasundaram*

Main category: cs.SE

TL;DR: Agint 是一个基于大型语言模型的代理式图编译器及运行时系统，支持将自然语言指令转化为类型明确、效果感知的代码有向无环图，实现动态图优化和高效执行。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型的编码代理在上下文管理、延迟、可靠性、可复现性和可扩展性方面存在挑战，亟需一种高效且可组合的系统来提升编码代理的性能和协作能力。

Method: Agint 设计了分层递增的自然语言到类型化代码有向无环图转换流程，引入显式的类型层次（文本、数据、规范、代码），结合语义图变换和混合的 LLM 与函数即时编译运行时，支持动态图优化、可复现执行和并发组合。系统提供多组件工具链（dagify、dagent、schemagin、datagin），并支持命令行和图形界面编辑，促进人类与编码代理的协作开发。

Result: Agint 实现了低延迟、高吞吐量、有效利用上下文的高可靠编码代理系统。支持可扩展的分层编译和图结构，提升代码生成的可复现性和并发性，促进从原型到生产的无缝过渡。

Conclusion: Agint 架起了自然语言、编译技术与开发工具的桥梁，催生一代可组合、团队协作导向的大规模编码代理，为编码效率和团队协同带来质的飞跃。

Abstract: LLM-based coding agents are increasingly common but still face challenges in context management, latency, reliability, reproducibility, and scalability. We present Agint, an agentic graph compiler, interpreter, and runtime that incrementally and hierarchically converts natural-language instructions into typed, effect-aware code DAGs. Agint introduces explicit type floors (text to data to spec to code) grounded in semantic graph transformations and a hybrid LLM and function-based JIT runtime. This enables dynamic graph refinement, reproducible and optimizable execution, speculative evaluation, and interoperability with existing developer tools. Agint's typed graph bindings improve reliability and allow concurrent composition of concurrent codebases by construction, supporting accelerated development with smaller and faster models, lower latency, efficient context utilization, and higher throughput. Hierarchical compilation allows scalable graph edits, while the graph structure supports reproducibility and efficient parallel generation. Agint provides a composable unix-style toolchain: dagify (DAG compiler), dagent (hybrid JIT runtime), schemagin (schema generator), and datagin (data transformer) for realtime, low-latency code and dataflow creation. Human developers and coding agents refine graphs through the Agint CLI, while non-technical users use Agint Flow GUI for visual editing, conversational refinement, and debugging to promote prototype agentic workflows to production code. This continuous co-creation model allows teams to prototype quickly, refine seamlessly, and deploy reliably, bridging natural language, compiler methods, and developer tooling to enable a new generation of composable, team-centric coding agents at scale.

</details>


### [41] [CodeFuse-CommitEval: Towards Benchmarking LLM's Power on Commit Message and Code Change Inconsistency Detection](https://arxiv.org/abs/2511.19875)
*Qingyu Zhang,Puzhuo Liu,Peng Di,Chenxiong Qian*

Main category: cs.SE

TL;DR: 本文提出了CODEFUSE-COMMITEVAL，这是首个用于检测提交信息与代码差异不一致（MCI）的基准数据集，并利用大语言模型进行评估。


<details>
  <summary>Details</summary>
Motivation: 提交信息质量低且与代码变更不一致会误导审查者，影响维护并污染研究数据，但目前缺乏针对MCI检测的专用基准。

Method: 基于ApacheCM数据集，通过规则引导的编辑生成七种类型的不一致提交，经过双重验证，构建标注好的消息-差异对；利用六种开源大语言模型在不同增强策略下进行评测。

Result: 模型对不一致提交的召回率和精确率较高，表现最佳的是gpt-oss-20B，但其token消耗最多；增强策略影响模型性能存在差异，且不同不一致类型的检测难度不同。

Conclusion: CODEFUSE-COMMITEVAL为MCI检测提供了严谨的评测基础，强调通过更丰富上下文和均衡数据来更好捕捉高阶语义差异的必要性。

Abstract: Version control relies on commit messages to convey the rationale for code changes, but these messages are often low quality and, more critically, inconsistent with their diffs-known as message-code inconsistency (MCI). MCIs mislead reviewers, hinder maintenance, contaminate research datasets, and may obscure security patches. Yet, no dedicated benchmark exists to evaluate models for MCI detection. We introduce CODEFUSE-COMMITEVAL, the first benchmark designed for MCI detection using large language models (LLMs). Built on the ApacheCM dataset for diversity and quality, we generate seven types of inconsistent messages through rule-guided mutations of originally consistent commits and apply two-fold validation to verify both positive and negative samples. Using this labeled dataset of message-diff pairs, we evaluate six state-of-the-art open-source LLMs under a vanilla setting and with three augmentation strategies: few-shot prompting, chain-of-thought, and extended context. Results show models detect inconsistent commits more reliably than consistent ones (average Recall 85.95%, Precision 80.28%, Specificity 63.8%); gpt-oss-20B performs best overall but uses over twice the tokens of others. Augmentation effects vary: adjacent context helps larger models but adds noise for smaller ones; few-shot improves accuracy and reduces token use, yet increases universally incorrect predictions; chain-of-thought boosts precision and specificity at the cost of recall and higher token consumption. Type-wise analysis reveals higher detectability for component, file-path, and operation inconsistencies, but lower accuracy and higher token cost for intent-level "purpose" inconsistencies. CODEFUSE-COMMITEVAL provides a rigorous foundation for measuring, comparing, and advancing MCI detection, highlighting the need for richer context and balanced data to capture high-level semantic gaps.

</details>


### [42] [LLMs for Automated Unit Test Generation and Assessment in Java: The AgoneTest Framework](https://arxiv.org/abs/2511.20403)
*Andrea Lops,Fedelucio Narducci,Azzurra Ragone,Michelantonio Trizio,Claudio Barto*

Main category: cs.SE

TL;DR: 本文提出了AgoneTest框架，用于自动评估大型语言模型生成的Java单元测试，展示了在覆盖率和缺陷检测方面其测试质量可媲美甚至优于人类测试。


<details>
  <summary>Details</summary>
Motivation: 单元测试在软件开发中必不可少且资源消耗大，需有标准化工具帮助比较不同LLM生成测试的效果。

Method: 构建Classes2Test数据集，设计集成诸如变异分数及测试气味等先进评估指标的自动化评估框架AgoneTest，实现端到端测试质量评估。

Result: 实验表明，在可编译测试子集中，LLM生成的测试覆盖率和缺陷检测能力可媲美或优于人类测试，且改进的提示策略提升了测试质量。

Conclusion: AgoneTest揭示了LLM在软件测试中的潜力，为模型设计、提示工程及测试实践的改进提供了重要建议。

Abstract: Unit testing is an essential but resource-intensive step in software development, ensuring individual code units function correctly. This paper introduces AgoneTest, an automated evaluation framework for Large Language Model-generated (LLM) unit tests in Java. AgoneTest does not aim to propose a novel test generation algorithm; rather, it supports researchers and developers in comparing different LLMs and prompting strategies through a standardized end-to-end evaluation pipeline under realistic conditions. We introduce the Classes2Test dataset, which maps Java classes under test to their corresponding test classes, and a framework that integrates advanced evaluation metrics, such as mutation score and test smells, for a comprehensive assessment. Experimental results show that, for the subset of tests that compile, LLM-generated tests can match or exceed human-written tests in terms of coverage and defect detection. Our findings also demonstrate that enhanced prompting strategies contribute to test quality. AgoneTest clarifies the potential of LLMs in software testing and offers insights for future improvements in model design, prompt engineering, and testing practices.

</details>


### [43] [Translating Large-Scale C Repositories to Idiomatic Rust](https://arxiv.org/abs/2511.20617)
*Saman Dehghan,Tianran Sun,Tianxiang Wu,Zihan Li,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出了Rustine，一种自动化的C到Rust代码库级翻译工具，兼顾了效率与代码质量。


<details>
  <summary>Details</summary>
Motivation: 现有的C到Rust翻译方法无法同时兼顾代码质量和可扩展性。基于转译的方法可扩展但代码质量差，基于大模型的方法昂贵且难扩展。

Method: Rustine是一个全自动化管道，实现了高效且生成符合惯用、安全的Rust代码。通过对23个多样化C项目的评测，Rustine能生成完全可编译且功能等价的Rust代码。

Result: Rustine生成的Rust代码功能等价率达87%，且相比现有六种方法更安全、惯用和易读。测试未全部通过时，开发者利用Rustine调试支持平均4.5小时完成任务。

Conclusion: Rustine有效解决了C到Rust翻译中质量与可扩展性之间的权衡，提升了自动化代码转换的实用性和代码质量。

Abstract: Existing C to Rust translation techniques fail to balance quality and scalability: transpilation-based approaches scale to large projects but produce code with poor safety, idiomaticity, and readability. In contrast, LLM-based techniques are prohibitively expensive due to their reliance on frontier models (without which they cannot reliably generate compilable translations), thus limiting scalability. This paper proposes Rustine, a fully automated pipeline for effective and efficient repository-level C to idiomatic safe Rust translation. Evaluating on a diverse set of 23 C programs, ranging from 27 to 13,200 lines of code, Rustine can generate fully compilable Rust code for all and achieve 87% functional equivalence (passing 1,063,099 assertions out of 1,221,192 in test suites with average function and line coverage of 74.7% and 72.2%). Compared to six prior repository-level C to Rust translation techniques, the translations by Rustine are overall safer (fewer raw pointers, pointer arithmetic, and unsafe constructs), more idiomatic (fewer Rust linter violations), and more readable. When the translations cannot pass all tests to fulfill functional equivalence, human developers were able to complete the task in 4.5 hours, on average, using Rustine as debugging support.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [44] [Trust-Based Social Learning for Communication (TSLEC) Protocol Evolution in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.19562)
*Abraham Itzhak Weinberg*

Main category: cs.MA

TL;DR: 该论文提出了一种基于信任的社会学习框架TSLEC，能通过显式教学加速多智能体的通信协议形成过程。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中的通信通常依赖独立学习，导致训练收敛缓慢且协议质量不佳。

Method: 设计了TSLEC框架，通过学习到的信任关系调节知识传递，实现代理之间的显式教学。

Result: 实验显示该方法使收敛所需训练周期减少23.9%，协议具备良好组合性和鲁棒性，且信任分数与教学质量高度相关。

Conclusion: 显式的基于信任的社会学习显著加快了多智能体协调中通信协议的形成。

Abstract: Emergent communication in multi-agent systems typically occurs through independent learning, resulting in slow convergence and potentially suboptimal protocols. We introduce TSLEC (Trust-Based Social Learning with Emergent Communication), a framework where agents explicitly teach successful strategies to peers, with knowledge transfer modulated by learned trust relationships. Through experiments with 100 episodes across 30 random seeds, we demonstrate that trust-based social learning reduces episodes-to-convergence by 23.9% (p < 0.001, Cohen's d = 1.98) compared to independent emergence, while producing compositional protocols (C = 0.38) that remain robust under dynamic objectives (Phi > 0.867 decoding accuracy). Trust scores strongly correlate with teaching quality (r = 0.743, p < 0.001), enabling effective knowledge filtering. Our results establish that explicit social learning fundamentally accelerates emergent communication in multi-agent coordination.

</details>


### [45] [An Adaptive, Data-Integrated Agent-Based Modeling Framework for Explainable and Contestable Policy Design](https://arxiv.org/abs/2511.19726)
*Roberto Garrone*

Main category: cs.MA

TL;DR: 本文提出了一个通用自适应多智能体学习框架，以克服现有研究中静态决策规则和固定控制参数的局限。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统常面对反馈、适应性和非平稳性，而多数模拟研究停留在静态决策和固定控制参数，缺乏动态适应机制。

Method: 框架整合四种动态机制区分静态与自适应智能体及系统参数，结合信息论诊断指标（熵率、统计复杂度、预测信息）评估预测性与结构，采用结构因果模型明确干预语义，从整体或样本数据生成智能体级先验，无监督方法识别行为模式。

Result: 框架提供了一个领域无关的架构，支持分析学习智能体和适应性控制如何共同影响系统轨迹，实现非平衡、振荡及漂移动力下的稳定性、性能和可解释性比较。

Conclusion: 该方法学为多智能体决策过程提供了数学定义、计算操作符及实验设计模板，促进构建可解释和可质疑的多智能体系统。

Abstract: Multi-agent systems often operate under feedback, adaptation, and non-stationarity, yet many simulation studies retain static decision rules and fixed control parameters. This paper introduces a general adaptive multi-agent learning framework that integrates: (i) four dynamic regimes distinguishing static versus adaptive agents and fixed versus adaptive system parameters; (ii) information-theoretic diagnostics (entropy rate, statistical complexity, and predictive information) to assess predictability and structure; (iii) structural causal models for explicit intervention semantics; (iv) procedures for generating agent-level priors from aggregate or sample data; and (v) unsupervised methods for identifying emergent behavioral regimes. The framework offers a domain-neutral architecture for analyzing how learning agents and adaptive controls jointly shape system trajectories, enabling systematic comparison of stability, performance, and interpretability across non-equilibrium, oscillatory, or drifting dynamics. Mathematical definitions, computational operators, and an experimental design template are provided, yielding a structured methodology for developing explainable and contestable multi-agent decision processes.

</details>


### [46] [Complex Instruction Following with Diverse Style Policies in Football Games](https://arxiv.org/abs/2511.19885)
*Chenglu Sun,Shuo Shen,Haonan Hu,Wei Zhou,Chen Chen*

Main category: cs.MA

TL;DR: 本文提出了一种新的语言控制强化学习方法LCDSP，旨在解决复杂多智能体环境中理解和执行高阶抽象指令的难题。


<details>
  <summary>Details</summary>
Motivation: 现有的语言控制强化学习虽在基础领域表现良好，但难以应对复杂多智能体环境中的高阶抽象指令执行问题。

Method: 设计了LCDSP框架，包括多样风格训练方法（DST）和风格解释器（SI），通过风格参数调节代理行为，实现多样化行为策略，并将高阶语言指令快速准确地转换为风格参数。

Result: 在复杂5v5足球环境中的实验证明，LCDSP能够有效理解抽象战术指令并准确执行多样化的行为风格。

Conclusion: LCDSP展现出理解和执行复杂多智能体环境中高阶语言指令的潜力，适合应用于真实复杂场景。

Abstract: Despite advancements in language-controlled reinforcement learning (LC-RL) for basic domains and straightforward commands (e.g., object manipulation and navigation), effectively extending LC-RL to comprehend and execute high-level or abstract instructions in complex, multi-agent environments, such as football games, remains a significant challenge. To address this gap, we introduce Language-Controlled Diverse Style Policies (LCDSP), a novel LC-RL paradigm specifically designed for complex scenarios. LCDSP comprises two key components: a Diverse Style Training (DST) method and a Style Interpreter (SI). The DST method efficiently trains a single policy capable of exhibiting a wide range of diverse behaviors by modulating agent actions through style parameters (SP). The SI is designed to accurately and rapidly translate high-level language instructions into these corresponding SP. Through extensive experiments in a complex 5v5 football environment, we demonstrate that LCDSP effectively comprehends abstract tactical instructions and accurately executes the desired diverse behavioral styles, showcasing its potential for complex, real-world applications.

</details>


### [47] [Realistic gossip in Trust Game on networks: the GODS model](https://arxiv.org/abs/2511.20248)
*Jan Majewski,Francesca Giardini*

Main category: cs.MA

TL;DR: 本文通过建立基于代理的模型，研究了现实情境中八卦传播对信任博弈中合作行为的影响，发现现实八卦传播虽增加资源总量，但促进背叛者行为，合作与背叛之间存在权衡，通过结合直接与间接互惠及声誉机制，八卦显著提升合作效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究对八卦的传播多假设信息接近完美或广播式传播，缺乏现实性，导致对合作行为的影响分析不准确，故需构建更现实的八卦传播模型以深入理解八卦与合作关系。

Method: 建立基于代理的模型，将现实的八卦传播过程与多种信任博弈变体结合，模拟不同条件下八卦传播及合作行为的演化，并考察动态网络中合作伙伴选择的影响。

Result: 结果表明，在局部交互控制八卦传播时，合作者不易区分背叛者，合作受到损害；现实八卦虽然增加资源总量，但更易促进背叛；动态网络的伙伴选择导致不同代理间收益差距加大，合作者在超越背叛者与实现整体增长间存在权衡。

Conclusion: 通过融合直接及间接互惠机制和声誉系统，八卦显著提高了合作效率，提升了合作的资源收益规模，体现了八卦在促进合作中的关键作用。

Abstract: Gossip has been shown to be a relatively efficient solution to problems of cooperation in reputation-based systems of exchange, but many studies don't conceptualize gossiping in a realistic way, often assuming near-perfect information or broadcast-like dynamics of its spread. To solve this problem, we developed an agent-based model that pairs realistic gossip processes with different variants of Trust Game. The results show that cooperators suffer when local interactions govern spread of gossip, because they cannot discriminate against defectors. Realistic gossiping increases the overall amount of resources, but is more likely to promote defection. Moreover, even partner selection through dynamic networks can lead to high payoff inequalities among agent types. Cooperators face a choice between outcompeting defectors and overall growth. By blending direct and indirect reciprocity with reputations we show that gossiping increases the efficiency of cooperation by an order of magnitude.

</details>


### [48] [EnergyTwin: A Multi-Agent System for Simulating and Coordinating Energy Microgrids](https://arxiv.org/abs/2511.20590)
*Jakub Muszyński,Ignacy Walużenicz,Patryk Zan,Zofia Wrona,Maria Ganzha,Marcin Paprzycki,Costin Bădică*

Main category: cs.MA

TL;DR: 本文提出了EnergyTwin，一个基于智能体的微电网仿真环境，通过结合物理模型和预测驱动的滚动时域规划，实现了多智能体间的协调和能源分配。


<details>
  <summary>Details</summary>
Motivation: 微电网需要协调多种分布式能源资源，应对多变条件和多时间尺度的控制挑战，现有工具或偏重物理建模，或偏重决策模拟，缺乏兼顾物理真实性与去中心化决策的解决方案。

Method: EnergyTwin将每个能源资产建模为智能体，与中央智能体合作，利用预测进行滚动时域规划和基于合约的能源分配，实现分布式能源管理与协商。

Result: 在大学校园微电网案例中，基于预测的滚动时域规划策略提升了本地能源自给率，保持了更高的电池储备，并降低了系统低韧性运行状态的风险。

Conclusion: EnergyTwin验证了作为支持韧性微电网协商驱动研究的平台的潜力，适用于三级决策层和可扩展的数字孪生应用。

Abstract: Microgrids are deployed to reduce purchased grid energy, limit exposure to volatile tariffs, and ensure service continuity during disturbances. This requires coordinating heterogeneous distributed energy resources across multiple time scales and under variable conditions. Among existing tools, typically, power-system simulators capture physical behaviour but assume centralized control, while multi-agent frameworks model decentralized decision-making but represent energy with no physical grounding. In this context, the EnergyTwin is introduced, an agent-based microgrid simulation environment that couples physically grounded models with forecast-informed, rolling-horizon planning, and negotiations. Each asset is modeled as an agent, interacting with a central agent that obtains forecasts, formulates predictions, and allocates energy through contract-based interactions. EnergyTwin targets tertiary-layer decision making and is extensible for digital-twin use. Its feasibility was evaluated in a university campus microgrid scenario where multiple planning strategies were compared. Achieved results show that forecast-driven rolling-horizon planning increases local energy self-sufficiency, maintains higher battery reserves, and reduces exposure to low-resilience operating states. They demonstrate also potential of EnergyTwin as platform supporting research on resilient, negotiation-driven microgrids.

</details>
