<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.SE](#cs.SE) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Democratizing LLM Efficiency: From Hyperscale Optimizations to Universal Deployability](https://arxiv.org/abs/2511.20662)
*Hen-Hsen Huang*

Main category: cs.CL

TL;DR: 本文指出当前大型语言模型的主流高效方法依赖于庞大基础设施，难以普及，提出一种强调资源节约和易用性的简单高效路线。


<details>
  <summary>Details</summary>
Motivation: 现有效率方法主要面向大型科技公司，造成资源浪费和不公平，限制了广大医疗、教育和政府等机构的应用。

Method: 提出无需重新训练的高效模型改造、轻量级微调、经济推理、动态知识管理以及引入考虑成本和可持续性的效率标准。

Result: 提出了一系列技术路线与评测标准，旨在提升模型部署的普适性和可持续性。

Conclusion: 通过重新定义效率标准，推动LLM应用民主化，减少不平等和碳排放，推动更广泛公平可持续的AI技术扩展。

Abstract: Large language models (LLMs) have become indispensable, but the most celebrated efficiency methods -- mixture-of-experts (MoE), speculative decoding, and complex retrieval-augmented generation (RAG) -- were built for hyperscale providers with vast infrastructure and elite teams. Outside that context, their benefits collapse into overhead, fragility, and wasted carbon. The result is that a handful of Big Tech companies benefit, while thousands of hospitals, schools, governments, and enterprises are left without viable options. We argue that the next frontier is not greater sophistication at scale, but robust simplicity: efficiency that thrives under modest resources and minimal expertise. We propose a new research agenda: retrofitting pretrained models with more efficient architectures without retraining, inventing lightweight fine-tuning that preserves alignment, making reasoning economical despite long chains of thought, enabling dynamic knowledge management without heavy RAG pipelines, and adopting Overhead-Aware Efficiency (OAE) as a standard benchmark. By redefining efficiency to include adoption cost, sustainability, and fairness, we can democratize LLM deployment -- ensuring that optimization reduces inequality and carbon waste rather than amplifying them.

</details>


### [2] [Harmonic Token Projection (HTP): A Vocabulary-Free, Training-Free, Deterministic, and Reversible Embedding Methodology](https://arxiv.org/abs/2511.20665)
*Tcharlies Schmitz*

Main category: cs.CL

TL;DR: 提出了一种新的文本嵌入方法——谐波令牌投影（HTP），不依赖训练和随机参数，通过Unicode值的谐波轨迹实现符号与向量空间的可逆映射。


<details>
  <summary>Details</summary>
Motivation: 当前神经嵌入依赖统计共现和优化，存在训练成本高、不可解释等问题，作者希望提供一种无训练、确定性的可逆文本嵌入方法。

Method: HTP将每个令牌的Unicode整数表示转换为谐波轨迹，实现离散符号与连续向量的一一映射，保持结构和相位一致性，从几何角度估计语义相似性。

Result: 在STS-B及多语言扩展测试中，HTP在英语上获得Spearman相关系数0.68，跨十种语言性能稳定，计算成本极低，延迟不足毫秒。

Conclusion: 基于确定性几何的HTP方法展现了语义关系的可解释和高效表示能力，是数据驱动嵌入的有效替代方案。

Abstract: This paper introduces the Harmonic Token Projection (HTP), a reversible and deterministic framework for generating text embeddings without training, vocabularies, or stochastic parameters. Unlike neural embeddings that rely on statistical co-occurrence or optimization, HTP encodes each token analytically as a harmonic trajectory derived from its Unicode integer representation, establishing a bijective and interpretable mapping between discrete symbols and continuous vector space. The harmonic formulation provides phase-coherent projections that preserve both structure and reversibility, enabling semantic similarity estimation from purely geometric alignment. Experimental evaluation on the Semantic Textual Similarity Benchmark (STS-B) and its multilingual extension shows that HTP achieves a Spearman correlation of \r{ho} = 0.68 in English, maintaining stable performance across ten languages with negligible computational cost and sub-millisecond latency per sentence pair. This demonstrates that meaningful semantic relations can emerge from deterministic geometry, offering a transparent and efficient alternative to data-driven embeddings. Keywords: Harmonic Token Projection, reversible embedding, deterministic encoding, semantic similarity, multilingual representation.

</details>


### [3] [A centroid based framework for text classification in itsm environments](https://arxiv.org/abs/2511.20667)
*Hossein Mohanna,Ali Ait-Bachir*

Main category: cs.CL

TL;DR: 提出了一种双嵌入质心分类框架，用于IT服务管理系统中基于层级分类树的文本分类，实现了高效且具有解释性的分类。


<details>
  <summary>Details</summary>
Motivation: IT服务管理中支持工单需要被归类到树状层级分类体系，既要求分类效果好又要能快速更新和易于解释。

Method: 该方法为每个类别维护语义和词法两个质心表示，并在推断时通过互相关联排序融合这两个质心实现分类。

Result: 在8968个ITSM工单、123个类别上，分类性能与支持向量机相当（层级F1分别为0.731 vs 0.727），且训练速度提升5.9倍，增量更新速度最高提升152倍，批量处理速度提升8.6-8.8倍。

Conclusion: 该方法在保证优良分类性能的同时，大幅提升运行效率并具备良好的可解释性，适合生产环境中的ITSM系统应用。

Abstract: Text classification with hierarchical taxonomies is a fundamental requirement in IT Service Management (ITSM) systems, where support tickets must be categorized into tree-structured taxonomies. We present a dual-embedding centroid-based classification framework that maintains separate semantic and lexical centroid representations per category, combining them through reciprocal rank fusion at inference time. The framework achieves performance competitive with Support Vector Machines (hierarchical F1: 0.731 vs 0.727) while providing interpretability through centroid representations. Evaluated on 8,968 ITSM tickets across 123 categories, this method achieves 5.9 times faster training and up to 152 times faster incremental updates. With 8.6-8.8 times speedup across batch sizes (100-1000 samples) when excluding embedding computation. These results make the method suitable for production ITSM environments prioritizing interpretability and operational efficiency.

</details>


### [4] [PIRA: Preference-Oriented Instruction-Tuned Reward Models with Dual Aggregation](https://arxiv.org/abs/2511.20668)
*Yongfu Xue*

Main category: cs.CL

TL;DR: 本文提出了PIRA训练范式，通过改写问答对、奖励聚合和输出平均三策略，提升了奖赏模型的数据效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统奖赏模型数据效率低且对奖励过度优化敏感，影响了大型语言模型与人类偏好的对齐效果。

Method: 将问答对转化为基于偏好的指令，聚合多样化偏好任务的奖励，并在不同dropout情况下平均value-head输出以稳定奖励。

Result: 大量实验表明，PIRA显著提升了奖赏模型的数据效率和稳健性。

Conclusion: PIRA方法有效解决了传统奖赏模型的不足，提升了奖赏模型的性能和鲁棒性。

Abstract: Reward models are crucial for aligning Large Language Models (LLMs) with human preferences but face two representative challenges. First, traditional discriminative reward models usually concatenate questions and responses directly as input, resulting in low data efficiency. Second, reward models are vulnerable to reward overoptimization. We propose PIRA, a training paradigm addressing these issues through three strategies: (1) Reformulating question-answer pairs into preference-based instructions for clearer and more explicit task specification, (2) aggregating rewards from diverse preference tasks to reduce bias and improve robustness, and (3) averaging value-head outputs under varying dropout rates to stabilize rewards. Extensive experiments have demonstrated the effectiveness of PIRA.

</details>


### [5] [Structured Definitions and Segmentations for Legal Reasoning in LLMs: A Study on Indian Legal Data](https://arxiv.org/abs/2511.20669)
*Mann Khatri,Mirza Yusuf,Rajiv Ratn Shah,Ponnurangam Kumaraguru*

Main category: cs.CL

TL;DR: 本文针对大型语言模型在法律领域由于缺乏特定领域预训练而表现不足的问题，提出通过重组法律文档结构、定义修辞角色并模拟法院推理过程以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 法律文档复杂且冗长，导致大型语言模型难以有效处理完整文本，且缺乏领域特定知识，影响模型在法律任务中的表现。

Method: 在零样本设置下，作者通过三个实验：重组文档以突出修辞角色、定义法律修辞角色以帮助模型理解专业术语、模拟法院的推理过程，从而改善模型处理长文本和法律推理的能力。

Result: 经过在三个印度法律判决预测数据集上的测试，结果显示通过数据重组和术语解释，模型的F1分数较基线提升了1.5%至4.36%。

Conclusion: 结构化处理法律文档和结合法律术语解释能显著提升大型语言模型在法律领域的推理能力和任务表现。

Abstract: Large Language Models (LLMs), trained on extensive datasets from the web, exhibit remarkable general reasoning skills. Despite this, they often struggle in specialized areas like law, mainly because they lack domain-specific pretraining. The legal field presents unique challenges, as legal documents are generally long and intricate, making it hard for models to process the full text efficiently. Previous studies have examined in-context approaches to address the knowledge gap, boosting model performance in new domains without full domain alignment. In our paper, we analyze model behavior on legal tasks by conducting experiments in three areas: (i) reorganizing documents based on rhetorical roles to assess how structured information affects long context processing and model decisions, (ii) defining rhetorical roles to familiarize the model with legal terminology, and (iii) emulating the step-by-step reasoning of courts regarding rhetorical roles to enhance model reasoning. These experiments are conducted in a zero-shot setting across three Indian legal judgment prediction datasets. Our results reveal that organizing data or explaining key legal terms significantly boosts model performance, with a minimum increase of ~1.5% and a maximum improvement of 4.36% in F1 score compared to the baseline.

</details>


### [6] [MindSET: Advancing Mental Health Benchmarking through Large-Scale Social Media Data](https://arxiv.org/abs/2511.20672)
*Saad Mankarious,Ayah Zirikly,Daniel Wiechmann,Elma Kerz,Edward Kempa,Yu Qiao*

Main category: cs.CL

TL;DR: 该论文提出了一个名为MindSET的大规模心理健康社交媒体数据集，数据量超过1300万条，涵盖七类心理健康状况，经过严格清洗和多语言过滤，显著提高了诊断检测的效果。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康社交媒体基准数据集存在数据有限、清洗不足、内容多样性强等问题，导致效果不佳，亟需更大规模且质量更高的数据集支持研究。

Method: 从Reddit收集自我报告诊断的帖子，进行语言过滤、去除NSFW和重复内容，构建超过1300万条的注释数据集，并利用LIWC进行语言学分析，以训练和评测各种分类模型。

Result: 训练模型在MindSET数据集上表现优异，尤其在自闭症诊断检测中F1得分提升了18个百分点，明显超过以往基准数据集。

Conclusion: MindSET为社交媒体与心理健康交叉领域的研究提供了坚实的数据基础，助力早期风险检测及心理趋势的深入分析。

Abstract: Social media data has become a vital resource for studying mental health, offering real-time insights into thoughts, emotions, and behaviors that traditional methods often miss. Progress in this area has been facilitated by benchmark datasets for mental health analysis; however, most existing benchmarks have become outdated due to limited data availability, inadequate cleaning, and the inherently diverse nature of social media content (e.g., multilingual and harmful material). We present a new benchmark dataset, \textbf{MindSET}, curated from Reddit using self-reported diagnoses to address these limitations. The annotated dataset contains over \textbf{13M} annotated posts across seven mental health conditions, more than twice the size of previous benchmarks. To ensure data quality, we applied rigorous preprocessing steps, including language filtering, and removal of Not Safe for Work (NSFW) and duplicate content. We further performed a linguistic analysis using LIWC to examine psychological term frequencies across the eight groups represented in the dataset. To demonstrate the dataset utility, we conducted binary classification experiments for diagnosis detection using both fine-tuned language models and Bag-of-Words (BoW) features. Models trained on MindSET consistently outperformed those trained on previous benchmarks, achieving up to an \textbf{18-point} improvement in F1 for Autism detection. Overall, MindSET provides a robust foundation for researchers exploring the intersection of social media and mental health, supporting both early risk detection and deeper analysis of emerging psychological trends.

</details>


### [7] [Semantics Meet Signals: Dual Codebook Representationl Learning for Generative Recommendation](https://arxiv.org/abs/2511.20673)
*Zheng Hui,Xiaokai Wei,Reza Shirkavand,Chen Wang,Weizhi Zhang,Alejandro Peláez,Michelle Gong*

Main category: cs.CL

TL;DR: 本文提出了FlexCode框架，通过动态分配协同过滤与语义编码，改进了生成式推荐的表示效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有生成式推荐方法使用单一统一的编码书编码所有项目，忽视热门与长尾项目在协同信号和语义理解上的差异，限制了表现效率和泛化。

Method: FlexCode通过固定的token预算在协同过滤编码书和语义编码书之间自适应分配，采用轻量级专家模型动态平衡精度和泛化，并通过对齐和光滑目标保持不同流行度项目间的一致性。

Result: 在公共及工业规模数据集上，FlexCode表现优于多种强基线，在准确性和长尾项目鲁棒性上均有提升。

Conclusion: FlexCode为生成式推荐提供了新的token表示机制，有效平衡记忆与泛化，提升推荐模型的整体性能和稳定性。

Abstract: Generative recommendation has recently emerged as a powerful paradigm that unifies retrieval and generation, representing items as discrete semantic tokens and enabling flexible sequence modeling with autoregressive models. Despite its success, existing approaches rely on a single, uniform codebook to encode all items, overlooking the inherent imbalance between popular items rich in collaborative signals and long-tail items that depend on semantic understanding. We argue that this uniform treatment limits representational efficiency and hinders generalization. To address this, we introduce FlexCode, a popularity-aware framework that adaptively allocates a fixed token budget between a collaborative filtering (CF) codebook and a semantic codebook. A lightweight MoE dynamically balances CF-specific precision and semantic generalization, while an alignment and smoothness objective maintains coherence across the popularity spectrum. We perform experiments on both public and industrial-scale datasets, showing that FlexCode consistently outperform strong baselines. FlexCode provides a new mechanism for token representation in generative recommenders, achieving stronger accuracy and tail robustness, and offering a new perspective on balancing memorization and generalization in token-based recommendation models.

</details>


### [8] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://arxiv.org/abs/2511.20677)
*Saleh Almohaimeed,May Alsofyani,Saad Almohaimeed,Mansour Al Ghanim,Liqiang Wang*

Main category: cs.CL

TL;DR: 该论文首次提出了阿拉伯语跨领域上下文相关的text-to-SQL数据集Ar-SParC，并在该数据集上使用GPT-3.5和GPT-4.5进行多种提示工程实验。提出了新颖的GAT校正器方法，显著提升了模型的执行和交互准确率。


<details>
  <summary>Details</summary>
Motivation: 当前text-to-SQL任务主要集中在英语，缺少阿拉伯语相关研究和数据集，限制了非英语用户的数据库自然语言交互能力。

Method: 构建了包含3,450个相关问题序列的阿拉伯语数据集Ar-SParC，设计了40个基于GPT-3.5和GPT-4.5的实验，采用10种提示工程技术，并提出了新的GAT校正器来提升性能。

Result: GAT校正器在零样本和上下文学习设置中分别使执行准确率和交互准确率平均提升约1.9%和0.9%。相较之前的GAT验证器表现更优，尤其适用于阿拉伯语。

Conclusion: Ar-SParC为阿拉伯语text-to-SQL任务提供了首个数据平台，GAT校正器有效提升模型性能，推动了阿拉伯语数据库自然语言交互技术的发展。

Abstract: In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain, context-dependent text-to-SQL dataset. The dataset consists of 3,450 sequences of interrelated questions, each sequence containing an average of approximately three questions, which results in a total of 10225 questions along with their corresponding SQL queries. We conducted 40 experiments on the Ar-SParC dataset using two large language models, GPT-3.5-turbo and GPT-4.5-turbo, applying 10 different prompt engineering techniques, including four question representation methods and six in-context learning techniques. Furthermore, we developed a novel approach named GAT corrector, which enhanced the performance across all 40 experiments, yielding an average improvement of 1.9% in execution accuracy (EX) and 1.9% in interaction accuracy (IX) under zero-shot settings, and an average increase of 1.72% EX and 0.92% IX under in-context learning settings. Finally, we conducted an ablation study with two more experiments to explain why the GAT corrector outperformed the previous GAT verifier technique, particularly for the Arabic language.

</details>


### [9] [ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](https://arxiv.org/abs/2511.21689)
*Hongjin Su,Shizhe Diao,Ximing Lu,Mingjie Liu,Jiacheng Xu,Xin Dong,Yonggan Fu,Peter Belcak,Hanrong Ye,Hongxu Yin,Yi Dong,Evelina Bakhturina,Tao Yu,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.CL

TL;DR: 本文提出了一种名为ToolOrchestra的小型协调器方法，通过协调多个工具和模型来提高解决复杂任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型处理复杂问题时，计算资源消耗巨大且效率不高，亟需一种更高效的方法。

Method: 引入ToolOrchestra，使用强化学习训练小型协调器，利用结果、效率和用户偏好为奖励信号，管理智能工具组合。

Result: 所提出的Orchestrator模型在多个基准测试中表现优于GPT-5，准确率更高且成本只有其约30%，效率提升2.5倍。

Conclusion: 轻量级协调模型结合多样工具能够实现更高效且更强的推理能力，为实用且可扩展的工具辅助推理系统奠定基础。

Abstract: Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.

</details>


### [10] [Cognitive bias in LLM reasoning compromises interpretation of clinical oncology notes](https://arxiv.org/abs/2511.20680)
*Matthew W. Kenaston,Umair Ayub,Mihir Parmar,Muhammad Umair Anjum,Syed Arsalan Ahmed Naqvi,Priya Kumar,Samarth Rawal,Aadel A. Chaudhuri,Yousef Zakharia,Elizabeth I. Heath,Tanios S. Bekaii-Saab,Cui Tao,Eliezer M. Van Allen,Ben Zhou,YooJung Choi,Chitta Baral,Irbaz Bin Riaz*

Main category: cs.CL

TL;DR: 本研究构建了一个分层的推理错误分类体系，分析GPT-4在肿瘤学临床笔记中的推理错误及其安全隐患，发现推理失败与有害建议相关，强调推理质量对临床应用的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大模型在临床基准测试中表现优异，但其可能通过错误推理得出正确结论，这种推理失败在肿瘤学决策支持中具有安全风险，且传统基于准确率的评估无法捕捉这一问题。

Method: 对CORAL数据集中的乳腺癌和胰腺癌临床笔记进行GPT-4链式思维响应，标注600条推理轨迹，构建三层推理错误分类体系，将计算错误映射到认知偏差框架；验证该体系在前列腺癌临床笔记中的适用性，模拟提取、分析和临床推荐任务。

Result: 23%的解释存在推理错误，推理错误是主要错误类型，确认偏差和锚定偏差最常见；推理失败与不符合指南且可能有害的建议相关，尤其在晚期疾病管理中；自动评估工具能检测错误存在，但难以准确分类错误类型。

Conclusion: 大语言模型虽能生成流畅回答，但推理缺陷可能导致临床不安全的建议。本研究提出的推理错误分类体系为临床部署前评估和提升推理准确性提供了一般性框架。

Abstract: Despite high performance on clinical benchmarks, large language models may reach correct conclusions through faulty reasoning, a failure mode with safety implications for oncology decision support that is not captured by accuracy-based evaluation. In this two-cohort retrospective study, we developed a hierarchical taxonomy of reasoning errors from GPT-4 chain-of-thought responses to real oncology notes and tested its clinical relevance. Using breast and pancreatic cancer notes from the CORAL dataset, we annotated 600 reasoning traces to define a three-tier taxonomy mapping computational failures to cognitive bias frameworks. We validated the taxonomy on 822 responses from prostate cancer consult notes spanning localized through metastatic disease, simulating extraction, analysis, and clinical recommendation tasks. Reasoning errors occurred in 23 percent of interpretations and dominated overall errors, with confirmation bias and anchoring bias most common. Reasoning failures were associated with guideline-discordant and potentially harmful recommendations, particularly in advanced disease management. Automated evaluators using state-of-the-art language models detected error presence but could not reliably classify subtypes. These findings show that large language models may provide fluent but clinically unsafe recommendations when reasoning is flawed. The taxonomy provides a generalizable framework for evaluating and improving reasoning fidelity before clinical deployment.

</details>


### [11] [Dynamic Template Selection for Output Token Generation Optimization: MLP-Based and Transformer Approaches](https://arxiv.org/abs/2511.20683)
*Bharadwaj Yadavalli*

Main category: cs.CL

TL;DR: 本文提出了动态模板选择（DTS）方法，根据查询复杂度自适应匹配响应模板，显著降低大语言模型响应的token成本，同时保证响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型普遍采用统一且冗长的响应策略，导致token使用无效且成本高昂，尤其是输出token价格远高于输入token。

Method: 本文设计并比较了两种路由方式：简易的MLP路由器利用预计算的嵌入向量，以及更复杂的微调RoBERTa变换器；基于这两种模型实现动态模板选择。

Result: MLP路由器在1,000道MMLU题目测试中达到了90.5%的路由准确率，略优于RoBERTa的89.5%，且参数量少12.5亿。路由决策在OpenAI GPT-4、Google Gemini和Anthropic Claude三大模型间表现一致，使token使用减少32.6%-33.9%。

Conclusion: 动态模板选择方法有效平衡了响应质量与成本，且具备跨主流大语言模型服务商的泛化能力，具有理论和实际应用价值。

Abstract: Contemporary large language model deployments typically employ uniform prompting strategies across diverse query types, applying verbose response patterns to both complex analytical tasks and straightforward factual questions. This one-size-fits-all methodology leads to substantial token inefficiency, a concern amplified by the significant cost differential between input and output tokens--the latter commanding 4-8x higher prices across major providers. We present Dynamic Template Selection (DTS), which adaptively matches response templates to query complexity, achieving significant cost reductions without compromising response quality.
  We compared two routing approaches: a simple MLP that uses pre-computed embeddings and a more complex fine-tuned RoBERTa transformer. Through comprehensive evaluation on 1,000 MMLU questions, we find that the MLP router achieves 90.5% routing accuracy on held-out test data, marginally exceeding RoBERTa's performance (89.5%) despite utilizing 125M fewer parameters. Notably, our empirical analysis reveals provider-agnostic behavior in template selection--routing decisions generalize effectively across 3 major LLM providers (OpenAI GPT-4, Google Gemini, and Anthropic Claude), as validated through 9,000 production API calls. While routing accuracy remains consistent at 90.5% across providers, observed token reductions vary from 32.6% to 33.9%, reflecting provider-specific generation characteristics.
  This work contributes several key elements: formal problem formulation with theoretical grounding in machine learning, four algorithms with corresponding complexity analyses, and extensive empirical validation across production systems.

</details>


### [12] [LLMs-Powered Accurate Extraction, Querying and Intelligent Management of Literature derived 2D Materials Data](https://arxiv.org/abs/2511.20691)
*Lijun Shang,Yadong Yu,Wenqiang Kang,Jian Zhou,Dongyue Gao,Pan Xiang,Zhe Liu,Mengyan Dai,Zhonglu Guo,Zhimei Sun*

Main category: cs.CL

TL;DR: 本文综述了二维材料在能量存储与转换中的应用，强调了其独特的物理化学和电子性能，以及研究论文中分散的信息整合难题。


<details>
  <summary>Details</summary>
Motivation: 二维材料因其独特性能被广泛应用于能源领域，但相关信息分散，亟需系统整理和总结。

Method: 通过系统梳理和整合相关文献，归纳二维材料的性能、制备方法及其在能量存储与转换中的应用。

Result: 总结出二维材料的关键性能优势及多种制备技术，并揭示了其在实际应用中的潜力与挑战。

Conclusion: 二维材料在能源领域展现巨大潜力，但信息整合和系统研究仍需加强，以推动其应用发展。

Abstract: Two-dimensional (2D) materials have showed widespread applications in energy storage and conversion owning to their unique physicochemical, and electronic properties. Most of the valuable information for the materials, such as their properties and preparation methods, is included in the published research papers. However, due to the dispersion of synthe

</details>


### [13] [Memories Retrieved from Many Paths: A Multi-Prefix Framework for Robust Detection of Training Data Leakage in Large Language Models](https://arxiv.org/abs/2511.20799)
*Trung Cuong Dang,David Mohaisen*

Main category: cs.CL

TL;DR: 本文提出了多前缀记忆框架，创新性地通过多个不同前缀来识别大语言模型中的记忆内容，以更全面地检测训练数据的记忆和泄露风险。


<details>
  <summary>Details</summary>
Motivation: 大语言模型容易直接记忆训练数据，带来隐私和版权风险，现有记忆定义难以全面捕捉记忆现象，特别是在aligned模型中。

Method: 引入多前缀记忆框架，定义如果通过多种不同前缀都能检索出相同序列，则该序列被视为记忆内容，实现从单一路径提取转向记忆的鲁棒性和多路径多样性的量化。

Result: 在开源和aligned聊天模型上的实验证明，该多前缀记忆定义能可靠区分记忆和非记忆数据，成为审计数据泄露的实用工具。

Conclusion: 多前缀记忆框架有效提升了记忆检测的准确性和鲁棒性，有助于审计和防控大语言模型中的隐私及版权泄露风险。

Abstract: Large language models, trained on massive corpora, are prone to verbatim memorization of training data, creating significant privacy and copyright risks. While previous works have proposed various definitions for memorization, many exhibit shortcomings in comprehensively capturing this phenomenon, especially in aligned models. To address this, we introduce a novel framework: multi-prefix memorization. Our core insight is that memorized sequences are deeply encoded and thus retrievable via a significantly larger number of distinct prefixes than non-memorized content. We formalize this by defining a sequence as memorized if an external adversarial search can identify a target count of distinct prefixes that elicit it. This framework shifts the focus from single-path extraction to quantifying the robustness of a memory, measured by the diversity of its retrieval paths. Through experiments on open-source and aligned chat models, we demonstrate that our multi-prefix definition reliably distinguishes memorized from non-memorized data, providing a robust and practical tool for auditing data leakage in LLMs.

</details>


### [14] [SAGE: An Agentic Explainer Framework for Interpreting SAE Features in Language Models](https://arxiv.org/abs/2511.20820)
*Jiaojiao Han,Wujiang Xu,Mingyu Jin,Mengnan Du*

Main category: cs.CL

TL;DR: 本文提出了一种基于代理的解释框架SAGE，用于更准确地解释深层语言模型稀疏自编码器中提取的特征。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型发展迅速，但其内部机制仍难以解释，尤其是稀疏自编码器提取的特征解释较为困难，限制了模型的安全和可靠应用。

Method: SAGE框架通过将特征解释转变为主动的、基于解释驱动的过程，系统地为每个特征生成多重解释，设计针对性实验进行验证，并根据实验反馈反复优化解释。

Result: 实验结果表明，SAGE在多个语言模型的稀疏自编码器特征解释中，比现有最先进方法具备更高的生成准确性和预测准确性。

Conclusion: SAGE提供了一种有效的方法提升了语言模型内部表征解释的准确性和可靠性，为大型语言模型的安全部署提供了新的工具。

Abstract: Large language models (LLMs) have achieved remarkable progress, yet their internal mechanisms remain largely opaque, posing a significant challenge to their safe and reliable deployment. Sparse autoencoders (SAEs) have emerged as a promising tool for decomposing LLM representations into more interpretable features, but explaining the features captured by SAEs remains a challenging task. In this work, we propose SAGE (SAE AGentic Explainer), an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanation-driven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanationdriven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.

</details>


### [15] [Structured Prompting Enables More Robust, Holistic Evaluation of Language Models](https://arxiv.org/abs/2511.20836)
*Asad Aali,Muhammad Ahmed Mohsin,Vasiliki Bikia,Arnav Singhvi,Richard Gaus,Suhana Bedi,Hejie Cui,Miguel Fuentes,Alyssa Unell,Yifan Mai,Jordan Cahoon,Michael Pfeffer,Roxana Daneshjou,Sanmi Koyejo,Emily Alsentzer,Percy Liang,Christopher Potts,Nigam H. Shah,Akshay S. Chaudhari*

Main category: cs.CL

TL;DR: 该论文提出了结合DSPy的结构化提示方法来提升HELM评测框架的准确性，系统评估了四种提示方法对四个先进语言模型在七个基准测试上的影响，发现未使用结构化提示时HELM低估了模型性能，并且性能排名存在偏差。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评测框架多依赖固定提示，无法准确反映模型的最大潜力，导致性能估计偏低，影响部署决策。需要一种可扩展的提示优化方法来估计模型的性能上限。

Method: 提出可重复的DSPy+HELM集成框架，利用四种结构化提示方法（包括链式推理）系统评测四个前沿语言模型在七个基准上的表现，比较改进前后的性能差异和稳定性。

Result: 结构化提示使得性能估计提升约4%，性能波动减少2%，模型排名更稳定且链式推理提示降低了对提示设计的敏感性，验证了结构化提示在准确估计模型性能上的有效性。

Conclusion: 通过大规模测试表明，利用结构化提示优化框架能够更准确地估计语言模型性能上限，为实际应用中的模型选择提供更有价值的基准评测。该框架及提示优化工具已开源。

Abstract: As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of Language Models (HELM) enable broad evaluation across tasks, they often rely on fixed prompts that fail to generalize across LMs, yielding unrepresentative performance estimates. Unless we estimate each LM's ceiling (maximum achievable via changes to the prompt), we risk underestimating performance. Declarative prompting frameworks, such as DSPy, offer a scalable alternative to manual prompt engineering by crafting structured prompts that can be optimized per task. However, such frameworks have not been systematically evaluated across established benchmarks. We present a reproducible DSPy+HELM framework that introduces structured prompting methods which elicit reasoning, enabling more accurate LM benchmarking. Using four prompting methods, we evaluate four frontier LMs across seven benchmarks (general/medical domain) against existing HELM baseline scores. We find that without structured prompting: (i) HELM underestimates LM performance (by 4% average), (ii) performance estimates vary more across benchmarks (+2% standard deviation), (iii) performance gaps are misrepresented (leaderboard rankings flip on 3/7 benchmarks), and (iv) introducing reasoning (chain-of-thought) reduces LM sensitivity to prompt design (smaller Δ across prompts). To our knowledge, this is the first large-scale benchmarking study to empirically characterize LM behavior across benchmarks and prompting methods, showing that scalable performance ceiling estimation enables more decision-useful benchmarks. We open-source (i) DSPy+HELM Integration (https://github.com/stanford-crfm/helm/pull/3893) and (ii) Prompt Optimization Pipeline (https://github.com/StanfordMIMI/dspy-helm).

</details>


### [16] [Length-MAX Tokenizer for Language Models](https://arxiv.org/abs/2511.20849)
*Dong Dong,Weijie Su*

Main category: cs.CL

TL;DR: 本文提出了一种名为Length-MAX的分词器，通过优化平均字符数的分词长度，有效减少训练和推理时的Token数量。


<details>
  <summary>Details</summary>
Motivation: 现有的分词方法如BPE侧重频率优化，未充分利用分词长度的优势，导致Token数量较多，影响训练效率和推理速度。

Method: 将基于长度加权的目标最大化问题转化为图划分问题，设计贪心算法得出词汇表。

Result: 在多个数据集和模型规模下，相较于BPE减少14%-18%的Token数量，训练所需步骤减少约17%-18%，推理延迟降低约13%，推理吞吐量提高16%，并提升了多个下游任务的性能。同时保持99.62%的词汇覆盖率和极低的OOV率。

Conclusion: 通过优化平均Token长度而非仅频率，Length-MAX分词器实现了更高效的语言模型训练和推理，且提升了下游任务表现，具备生产环境应用价值。

Abstract: We introduce a new tokenizer for language models that minimizes the average tokens per character, thereby reducing the number of tokens needed to represent text during training and to generate text during inference. Our method, which we refer to as the Length-MAX tokenizer, obtains its vocabulary by casting a length-weighted objective maximization as a graph partitioning problem and developing a greedy approximation algorithm. On FineWeb and diverse domains, it yields 14--18\% fewer tokens than Byte Pair Encoding (BPE) across vocabulary sizes from 10K to 50K, and the reduction is 13.0\% when the size is 64K. Training GPT-2 models at 124M, 355M, and 1.3B parameters from scratch with five runs each shows 18.5\%, 17.2\%, and 18.5\% fewer steps, respectively, to reach a fixed validation loss, and 13.7\%, 12.7\%, and 13.7\% lower inference latency, together with a 16\% throughput gain at 124M, while consistently improving on downstream tasks including reducing LAMBADA perplexity by 11.7\% and enhancing HellaSwag accuracy by 4.3\%. Moreover, the Length-MAX tokenizer achieves 99.62\% vocabulary coverage and the out-of-vocabulary rate remains low at 0.12\% on test sets. These results demonstrate that optimizing for average token length, rather than frequency alone, offers an effective approach to more efficient language modeling without sacrificing -- and often improving -- downstream performance. The tokenizer is compatible with production systems and reduces embedding and KV-cache memory by 18\% at inference.

</details>


### [17] [Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory](https://arxiv.org/abs/2511.20857)
*Tianxin Wei,Noveen Sachdeva,Benjamin Coleman,Zhankui He,Yuanchen Bei,Xuying Ning,Mengting Ai,Yunzhe Li,Jingrui He,Ed H. Chi,Chi Wang,Shuo Chen,Fernando Pereira,Wang-Cheng Kang,Derek Zhiyuan Cheng*

Main category: cs.CL

TL;DR: 本文提出了Evo-Memory框架，旨在评估大型语言模型在动态任务流中自我进化记忆的能力，设计了连续任务流的基准数据集和多种记忆模块，并提出了基线方法ExpRAG与改进方法ReMem，实现了记忆的有效更新和利用。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究关注静态对话中的记忆检索，忽视了在真实环境中处理连续任务时，模型自我进化和积累经验的能力，导致模型难以从持续交互中学习和更新记忆。

Method: 提出Evo-Memory流式基准和框架，通过顺序任务流结构评估记忆的搜索、适应和演化能力；整合十多种记忆模块进行多样任务评测；设计ExpRAG作为经验检索利用的基线方法，并创新提出ReMem，通过推理、任务执行及记忆更新的紧密结合，实现记忆的持续完善。

Result: 不同记忆模块在连续任务流上的表现被系统评估，ExpRAG与ReMem显著提高了经验的复用效果和模型的持续学习能力。

Conclusion: Evo-Memory为评测和推动大语言模型中动态记忆演化提供了重要平台，通过有效的记忆更新机制，模型可实现长期规划和问题解决，提升交互智能水平。

Abstract: Statefulness is essential for large language model (LLM) agents to perform long-term planning and problem-solving. This makes memory a critical component, yet its management and evolution remain largely underexplored. Existing evaluations mostly focus on static conversational settings, where memory is passively retrieved from dialogue to answer queries, overlooking the dynamic ability to accumulate and reuse experience across evolving task streams. In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents. Evo-Memory structures datasets into sequential task streams, requiring LLMs to search, adapt, and evolve memory after each interaction. We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. To better benchmark experience reuse, we provide a baseline method, ExpRAG, for retrieving and utilizing prior experience, and further propose ReMem, an action-think-memory refine pipeline that tightly integrates reasoning, task actions, and memory updates to achieve continual improvement.

</details>


### [18] [Winning with Less for Low Resource Languages: Advantage of Cross-Lingual English_Persian Argument Mining Model over LLM Augmentation](https://arxiv.org/abs/2511.20872)
*Ali Jahan,Masood Ghayoomi,Annette Hautli-Janisz*

Main category: cs.CL

TL;DR: 本文通过构建三种训练方案，探索低资源语言下的跨语言论证挖掘方法，结果显示跨语言模型在波斯语数据集上的表现优于零-shot和基于大语言模型增强的方法。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言中论证成分识别和关系抽取的数据不足问题。

Method: 设计三种训练场景：零样本迁移、基于大语言模型生成合成数据的英语单语训练及结合英语和波斯语数据的跨语言训练，并在英语和波斯语数据集上进行评估。

Result: 零样本迁移模型波斯语F1=50.7%，合成数据增强模型F1提升至69.3%，跨语言模型F1达到74.8%，性能显著优于其它方案。

Conclusion: 结合少量人工翻译的跨语言训练方式能有效提升低资源语言的论证挖掘效果，优于资源消耗更大的数据增强方法。

Abstract: Argument mining is a subfield of natural language processing to identify and extract the argument components, like premises and conclusions, within a text and to recognize the relations between them. It reveals the logical structure of texts to be used in tasks like knowledge extraction. This paper aims at utilizing a cross-lingual approach to argument mining for low-resource languages, by constructing three training scenarios. We examine the models on English, as a high-resource language, and Persian, as a low-resource language. To this end, we evaluate the models based on the English Microtext corpus \citep{PeldszusStede2015}, and its parallel Persian translation. The learning scenarios are as follow: (i) zero-shot transfer, where the model is trained solely with the English data, (ii) English-only training enhanced by synthetic examples generated by Large Language Models (LLMs), and (iii) a cross-lingual model that combines the original English data with manually translated Persian sentences. The zero-shot transfer model attains F1 scores of 50.2\% on the English test set and 50.7\% on the Persian test set. LLM-based augmentation model improves the performance up to 59.2\% on English and 69.3\% on Persian. The cross-lingual model, trained on both languages but evaluated solely on the Persian test set, surpasses the LLM-based variant, by achieving a F1 of 74.8\%. Results indicate that a lightweight cross-lingual blend can outperform considerably the more resource-intensive augmentation pipelines, and it offers a practical pathway for the argument mining task to overcome data resource shortage on low-resource languages.

</details>


### [19] [Emergence and Localisation of Semantic Role Circuits in LLMs](https://arxiv.org/abs/2511.20910)
*Nura Aljaafari,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 本文提出了一种结合角色交叉最小对、时间出现分析和跨模型比较的方法，研究大语言模型如何实现语义角色。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型表现出语义能力，但其内部实现抽象语义结构的机制尚不清楚。

Method: 结合角色交叉最小对、时间出现分析及跨模型比较方法对模型进行分析。

Result: 发现语义角色相关机制高度集中在少数节点，结构逐步优化而非突然转变，大模型有时绕过局部电路，且不同规模间部分机制保存且谱结构相似。

Conclusion: 大语言模型形成了紧凑且因果隔离的抽象语义结构机制，这些机制在不同规模和架构间部分可转移。

Abstract: Despite displaying semantic competence, large language models' internal mechanisms that ground abstract semantic structure remain insufficiently characterised. We propose a method integrating role-cross minimal pairs, temporal emergence analysis, and cross-model comparison to study how LLMs implement semantic roles. Our analysis uncovers: (i) highly concentrated circuits (89-94% attribution within 28 nodes); (ii) gradual structural refinement rather than phase transitions, with larger models sometimes bypassing localised circuits; and (iii) moderate cross-scale conservation (24-59% component overlap) alongside high spectral similarity. These findings suggest that LLMs form compact, causally isolated mechanisms for abstract semantic structure, and these mechanisms exhibit partial transfer across scales and architectures.

</details>


### [20] [Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2511.20940)
*Reham Omar,Abdelghny Orogat,Ibrahim Abdelaziz,Omij Mangukiya,Panos Kalnis,Essam Mansour*

Main category: cs.CL

TL;DR: 本文提出了Chatty-KG，一个结合大语言模型与知识图谱的模块化多代理系统，用于实现对知识图谱的多轮对话式问答，显著提升了准确率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于知识图谱的问答系统难以支持多轮对话且存在响应延迟，而仅靠大语言模型则缺乏对私有动态知识图谱的直接访问，现有方法在结构保留、多轮对话上下文处理和查询效率方面存在不足。

Method: Chatty-KG通过多任务特化的大语言模型代理，协同完成上下文理解、对话跟踪、实体关系链接和高效查询规划，将自然语言问题转换为可执行的SPARQL查询，实现结合了检索增强生成和结构化执行的混合方法。

Result: 在大规模多样的知识图谱上，Chatty-KG在单轮和多轮问答中均显著优于现有最先进方法，F1值和P@1均取得提升，同时支持多模型兼容性和动态知识图谱，无需微调或预处理。

Conclusion: Chatty-KG成功融合了对话系统的灵活性与结构化知识图谱的可靠性，提供了一种可扩展、可扩展的多轮知识图谱问答解决方案。

Abstract: Conversational Question Answering over Knowledge Graphs (KGs) combines the factual grounding of KG-based QA with the interactive nature of dialogue systems. KGs are widely used in enterprise and domain applications to provide structured, evolving, and reliable knowledge. Large language models (LLMs) enable natural and context-aware conversations, but lack direct access to private and dynamic KGs. Retrieval-augmented generation (RAG) systems can retrieve graph content but often serialize structure, struggle with multi-turn context, and require heavy indexing. Traditional KGQA systems preserve structure but typically support only single-turn QA, incur high latency, and struggle with coreference and context tracking. To address these limitations, we propose Chatty-KG, a modular multi-agent system for conversational QA over KGs. Chatty-KG combines RAG-style retrieval with structured execution by generating SPARQL queries through task-specialized LLM agents. These agents collaborate for contextual interpretation, dialogue tracking, entity and relation linking, and efficient query planning, enabling accurate and low-latency translation of natural questions into executable queries. Experiments on large and diverse KGs show that Chatty-KG significantly outperforms state-of-the-art baselines in both single-turn and multi-turn settings, achieving higher F1 and P@1 scores. Its modular design preserves dialogue coherence and supports evolving KGs without fine-tuning or pre-processing. Evaluations with commercial (e.g., GPT-4o, Gemini-2.0) and open-weight (e.g., Phi-4, Gemma 3) LLMs confirm broad compatibility and stable performance. Overall, Chatty-KG unifies conversational flexibility with structured KG grounding, offering a scalable and extensible approach for reliable multi-turn KGQA.

</details>


### [21] [TrackList: Tracing Back Query Linguistic Diversity for Head and Tail Knowledge in Open Large Language Models](https://arxiv.org/abs/2511.21006)
*Ioana Buhnila,Aman Sinha,Mathieu Constant*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在回答不同类型语言学查询时的表现差异，特别是在医学术语上的定义和举例。


<details>
  <summary>Details</summary>
Motivation: 虽然人类能轻松给出多种类型的答案（定义、举例、释义等），大型语言模型在非定义类查询中表现较差，作者希望通过细粒度分析探究预训练数据对这些表现的影响。

Method: 使用TrackList分析管线对LLM回答进行语义和句法相似度、统计相关性及嵌入向量评估；利用RefoMed-EN数据集测试LLM在医学术语上不同答题类型（定义、举例等）上的表现，同时考察常见与罕见概念的影响。

Result: LLMs对定义类问题表现最好，对举例类表现最差；且在定义类问题中，模型倾向于对常见、热门知识进行更多的释义，而对罕见和技术性知识尤其是专家文本的处理较弱。

Conclusion: 大型语言模型在回答多样语言查询时表现不均，受到预训练数据分布和知识频率影响，特别是在专业领域中对非定义型答案生成仍需改进。

Abstract: Large Language Models (LLMs) have proven efficient in giving definition-type answers to user input queries. While for humans giving various types of answers, such as examples and paraphrases, is an easy task, LLMs struggle to provide correct answers for other than definition-type queries. In this study, we evaluated this drop in performance using TrackList, a fine-grained linguistic and statistical analysis pipeline to investigate the impact of the pre-training data on LLMs answers to diverse linguistic queries. We also introduce RefoMed-EN, an English dataset consisting of 6170 human-annotated medical terms alongside their corresponding definitions, denominations, exemplifications, explanations, or paraphrases. We studied whether the high frequency of a concept (head) or low frequency (tail) impacts the language model's performance. We evaluated the quality of the LLM's output using syntactic and semantic similarity metrics, statistical correlations and embeddings. Results showed that the LLM's task performance for definition type questions is the highest, while for the exemplification type it is the lowest. Additionally, we showed that for definition-type questions, large language models are prone to paraphrase more on popular and frequent knowledge and less on tail and technical knowledge, especially in the expert texts.

</details>


### [22] [Semantic Anchors in In-Context Learning: Why Small LLMs Cannot Flip Their Labels](https://arxiv.org/abs/2511.21038)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CL

TL;DR: 本文研究大规模语言模型中上下文学习(ICL)是否能覆盖预训练标签语义，发现ICL主要调整输入映射到预训练语义方向，无法重定义标签语义。


<details>
  <summary>Details</summary>
Motivation: 探索ICL在大规模语言模型中是否能“覆盖”或重定义预训练阶段学到的标签语义，理解其行为机制和极限。

Method: 将大模型视为提示引导的分类器，采用自然示例（正确标签）和反转示例（标签含义翻转），设计三种对齐指标并定义语义覆盖率，通过多个分类任务和模型进行实证分析。

Result: ICL在自然示例下提高准确性且保持强语义先验对齐，但反转示例下无法学习符合反语义的分类器，语义覆盖率为零，准确率下降，提示语义方向稳定。

Conclusion: 上下文学习无法灵活重映射标签语义，主要调整输入向预训练学到的语义方向投影，限制了少样本提示的灵活性，覆盖语义需超出ICL范畴的干预。

Abstract: Can in-context learning (ICL) override pre-trained label semantics, or does it merely refine an existing semantic backbone? We address this question by treating LLMs as prompt-induced classifiers and contrasting their behavior under \emph{natural} demonstrations (with correct labels) and \emph{inverted} demonstrations (systematically flipping label meanings). We decompose ICL behavior into three alignment metrics (truth, prior, and prompt alignment) and introduce a semantic override rate, defined as correctness under flipped semantics. Across eight classification tasks and eight open-source LLMs (1--12B parameters), we find consistent evidence for a semantic anchor view. With natural demonstrations, ICL improves accuracy while maintaining strong prior alignment; most correct predictions coincide with zero-shot behavior, even when the prior is weak. With inverted demonstrations, models cannot learn coherent anti-semantic classifiers: prompt alignment increases only by sacrificing accuracy, and semantic override rates remain exactly zero in our few-shot 1--12B setting. Rather than flexibly remapping label meanings, ICL primarily adjusts how inputs project onto stable semantic directions learned during pre-training, clarifying fundamental limits of few-shot prompting and suggesting that overriding label semantics at these scales requires interventions beyond ICL. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/semantic-anchors-icl.

</details>


### [23] [Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection](https://arxiv.org/abs/2511.21066)
*Michael Iskandardinata,William Christian,Derwin Suhartono*

Main category: cs.CL

TL;DR: 该论文提出了一种基于检索的上下文增强方法，用于提高大型语言模型（LLMs）在讽刺检测任务中的表现，通过引入网络检索和模型自我知识检索，显著提升了多个数据集上的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 讽刺检测因文本复杂性、语言多样性和文化差异而具有挑战性，现有预训练语言模型和大型语言模型对需要额外背景知识的词汇检测仍不可靠。

Method: 基于现有的Pragmatic Metacognitive Prompting方法，结合非参数化的网络检索和模型自我知识检索两种策略为目标文本提供上下文信息，从而增强模型的理解能力。

Result: 网络检索方法在Twitter Indonesia Sarcastic数据集上使宏F1提升了9.87%，自我知识检索分别使Semeval和MUStARD数据集的宏F1提升3.29%和4.08%。

Conclusion: 加入含文化和语言上下文的检索信息显著提升了LLMs在讽刺检测任务上的性能，未来将优化检索机制和评估检索质量对表现的影响。

Abstract: Detecting sarcasm remains a challenging task in the areas of Natural Language Processing (NLP) despite recent advances in neural network approaches. Currently, Pre-trained Language Models (PLMs) and Large Language Models (LLMs) are the preferred approach for sarcasm detection. However, the complexity of sarcastic text, combined with linguistic diversity and cultural variation across communities, has made the task more difficult even for PLMs and LLMs. Beyond that, those models also exhibit unreliable detection of words or tokens that require extra grounding for analysis. Building on a state-of-the-art prompting method in LLMs for sarcasm detection called Pragmatic Metacognitive Prompting (PMP), we introduce a retrieval-aware approach that incorporates retrieved contextual information for each target text. Our pipeline explores two complementary ways to provide context: adding non-parametric knowledge using web-based retrieval when the model lacks necessary background, and eliciting the model's own internal knowledge for a self-knowledge awareness strategy. We evaluated our approach with three datasets, such as Twitter Indonesia Sarcastic, SemEval-2018 Task 3, and MUStARD. Non-parametric retrieval resulted in a significant 9.87% macro-F1 improvement on Twitter Indonesia Sarcastic compared to the original PMP method. Self-knowledge retrieval improves macro-F1 by 3.29% on Semeval and by 4.08% on MUStARD. These findings highlight the importance of context in enhancing LLMs performance in sarcasm detection task, particularly the involvement of culturally specific slang, references, or unknown terms to the LLMs. Future work will focus on optimizing the retrieval of relevant contextual information and examining how retrieval quality affects performance. The experiment code is available at: https://github.com/wllchrst/sarcasm-detection_pmp_knowledge-base.

</details>


### [24] [Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning](https://arxiv.org/abs/2511.21081)
*Thura Aung,Eaint Kay Khaing Kyaw,Ye Kyaw Thu,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

TL;DR: 本文在缅甸语等低资源语言的分类任务中，探讨了使用Kolmogorov-Arnold网络（KANs）代替常用的多层感知机（MLP）作为分类头，实验显示KANs在准确率和效率上具有优势。


<details>
  <summary>Details</summary>
Motivation: 传统的低资源语言分类通常只微调最后的分类层，使用的MLP非线性固定，限制了表达能力且计算成本较高，因此需要探索更高效且表达能力更强的分类头。

Method: 本文提出使用基于傅里叶变换的FourierKAN、基于样条的EfficientKAN以及基于网格的FasterKAN三种KAN变体，结合TF-IDF、fastText及多语言Transformer等多种嵌入表示，在低资源语言分类任务中进行评估。

Result: 实验结果表明，KAN类分类头的性能可与甚至优于MLP。采用fastText嵌入的EfficientKAN达到了最高的F1分数0.928；FasterKAN在速度与准确率之间取得较好平衡；基于Transformer嵌入的EfficientKAN表现与MLP相当或略优，达到0.917的F1。

Conclusion: KAN网络作为分类头在低资源语言文本分类中表现出了良好的表达能力和计算效率，是替代传统MLP的有效选项。

Abstract: In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.

</details>


### [25] [Orthographic Constraint Satisfaction and Human Difficulty Alignment in Large Language Models](https://arxiv.org/abs/2511.21086)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.CL

TL;DR: 该论文评估了三类大语言模型在满足字符级约束的词谜任务中的表现，发现模型架构对性能影响显著，参数扩展提升有限，并且模型在处理非常规正字法词汇时表现不足。


<details>
  <summary>Details</summary>
Motivation: 研究者希望了解不同架构的大语言模型在字符级严格约束的文本生成任务中的表现差异及其对难题的处理能力，以评估当前模型扩展方法的有效性。

Method: 选择三种语言模型家族共28个配置，测试其在58个需要字符级约束满足的词谜任务的表现，分析模型容量（参数规模）与计算预算对表现的影响，并利用1万名人类解答者给出的难度评级进行校准对比。

Result: 架构差异导致性能差距达2.0-2.2倍，F1分数大幅优于参数扩展带来的提升（83%提升）。大模型带来明显收益，中等模型表现饱和甚至下降。所有模型对难度评级有一定校准相关性，但在处理正字法非常规但有效的单词时表现普遍较差，表现出对分布合理性的过度依赖。

Conclusion: 仅靠参数规模扩大或计算预算增加无法解决字符级约束生成的挑战，未来需要针对特殊架构设计或训练目标创新，以改善模型对罕见正字法模式的容忍度和约束满足能力。

Abstract: Large language models must satisfy hard orthographic constraints during controlled text generation, yet systematic cross-architecture evaluation remains limited. We evaluate 28 configurations spanning three model families (Qwen3, Claude Haiku-4.5, GPT-5-mini) on 58 word puzzles requiring character-level constraint satisfaction. Architectural differences produce substantially larger performance gaps (2.0-2.2x, F1=0.761 vs. 0.343) than parameter scaling within families (83% gain from eightfold scaling), suggesting that constraint satisfaction may require specialized architectural features or training objectives beyond standard language model scaling. Thinking budget sensitivity proves heterogeneous: high-capacity models show strong returns (+0.102 to +0.136 F1), while mid-sized variants saturate or degrade. These patterns are inconsistent with uniform compute benefits. Using difficulty ratings from 10,000 human solvers per puzzle, we establish modest but consistent calibration (r=0.24-0.38) across all families, yet identify systematic failures on common words with unusual orthography ("data", "poop", "loll": 86-95% human success, 89-96% model miss rate). These failures reveal over-reliance on distributional plausibility that penalizes orthographically atypical but constraint-valid patterns, suggesting architectural innovations may be required beyond simply scaling parameters or computational budgets.

</details>


### [26] [ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features](https://arxiv.org/abs/2511.21088)
*Ye Bhone Lin,Thura Aung,Ye Kyaw Thu,Thazin Myint Oo*

Main category: cs.CL

TL;DR: 本文首次针对缅甸语低资源环境中的自动语音识别错误校正，提出基于序列到序列Transformer模型的多特征融合方法。


<details>
  <summary>Details</summary>
Motivation: 目前针对缅甸语的ASR错误校正研究不足，且低资源问题使得识别效果有限，亟需改进错误校正方法以提升语音识别准确率。

Method: 本文采用序列到序列Transformer模型，融合国际音标（IPA）和对齐信息作为输入特征，设计了多种特征融合策略，并在五个不同ASR模型的输出基础上进行错误校正。

Result: 所提模型在未经数据增强时，平均词错误率（WER）从51.56降至39.82，采用数据增强时从51.56降至43.59，chrF++评分从0.5864提升至0.627，显示出显著的性能提升。

Conclusion: 研究验证了基于Transformer的误差校正方法在低资源缅甸语ASR中的有效性，且融合IPA和对齐特征设计对于提升ASR表现具有重要意义。

Abstract: This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.

</details>


### [27] [MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing](https://arxiv.org/abs/2511.21101)
*Manish Jain,Satheesh Kumar Ponnambalam,Salman Faroz,Chandrakanth Lns,Vinay Sharma*

Main category: cs.CL

TL;DR: 本文提出了MortgageLLM，一种针对抵押贷款金融领域的双专家大语言模型，通过双轨专业化框架和指令残差技术，实现了高效的领域适应和指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 传统单一多任务模型在结构化任务和对话任务间存在性能折衷，难以同时兼顾领域知识和指令遵循，金融抵押贷款领域对专业模型的需求迫切。

Method: 采用从基础模型（LLaMA-3.1-8B）出发的双专家架构，一为对话问答专家，一为结构化任务专家，并使用指令残差技术恢复适应后的指令遵循能力，同时设计了基于少样本分类的智能任务路由机制。

Result: 在领域特定基准测试中，MortgageLLM (MLM v2) 在摘要、问答和分类任务上均显著优于基线模型，摘要和问答的LLM-as-a-Judge评分及语义相似度指标均有明显提升。

Conclusion: 提出的双专家结构和指令残差技术有效解决了领域适应中的多任务性能冲突，增强了模型在抵押贷款金融领域的专业能力和指令遵循性，为行业专用大语言模型的设计提供了新思路。

Abstract: Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present MortgageLLM, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (via SFT) degrades conversational fidelity (via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA-3.1-8B-Instruct, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches.

</details>


### [28] [Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines](https://arxiv.org/abs/2511.21214)
*Yuhang Wang,Yanxu Zhu,Dongyuan Lu,Jitao Sang*

Main category: cs.CL

TL;DR: 本文提出了SGASA框架，通过模型生成安全指南并进行对齐微调，提高模型抵御恶意提示的能力，同时减少对正常请求的误拒。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型易被隐蔽且欺骗性的对抗性攻击绕过安全机制，导致产生有害内容，亟需自适应的安全对齐策略。

Method: SGASA框架包括两阶段：数据预合成阶段生成安全指南和增强提示；对齐微调阶段利用监督微调和直接偏好优化将安全指南融入模型。

Result: 多数据集的广泛实验表明，SGASA显著提升模型的安全性，验证了其自适应性和可扩展性。

Conclusion: SGASA有效增强了模型对对抗性有害提示的防御能力，且在保证模型响应正常请求的同时提升整体安全性。

Abstract: Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.

</details>


### [29] [Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?](https://arxiv.org/abs/2511.21218)
*Steven Wang,Kyle Hunt,Shaojie Tang,Kenneth Joseph*

Main category: cs.CL

TL;DR: 通过对大型语言模型（LLM）进行小规模人类调查数据微调，研究其在行为实验中模仿人类反应的能力，结果显示微调改善了模型的多样性和一致性，但仍无法准确复制真实回归结果，不能完全替代人类参与者。


<details>
  <summary>Details</summary>
Motivation: 目前争论大型语言模型能否代替人类参与调查和实验研究，但现有研究表明LLM在多样性、一致性和子群体表现上存在不足。本文探索微调小量真实调查数据是否能改善这些问题。

Method: 通过行为实验比较人类与原始及微调后的LLM生成响应，评估分布差异、子群体对齐、一致性和回归系数恢复情况。

Result: 微调后模型在多样性、对齐度和信念-行动一致性方面显著提升，但未能准确重现实际研究的回归系数。

Conclusion: 尽管微调可提升LLM模拟结果的质量，但当前LLM生成数据尚不足以在正式推断分析中替代人类参与者。

Abstract: There is ongoing debate about whether large language models (LLMs) can serve as substitutes for human participants in survey and experimental research. While recent work in fields such as marketing and psychology has explored the potential of LLM-based simulation, a growing body of evidence cautions against this practice: LLMs often fail to align with real human behavior, exhibiting limited diversity, systematic misalignment for minority subgroups, insufficient within-group variance, and discrepancies between stated beliefs and actions. This study examines an important and distinct question in this domain: whether fine-tuning on a small subset of human survey data, such as that obtainable from a pilot study, can mitigate these issues and yield realistic simulated outcomes. Using a behavioral experiment on information disclosure, we compare human and LLM-generated responses across multiple dimensions, including distributional divergence, subgroup alignment, belief-action coherence, and the recovery of regression coefficients. We find that fine-tuning on small human samples substantially improves heterogeneity, alignment, and belief-action coherence relative to the base model. However, even the best-performing fine-tuned models fail to reproduce the regression coefficients of the original study, suggesting that LLM-generated data remain unsuitable for replacing human participants in formal inferential analyses.

</details>


### [30] [Developing an Open Conversational Speech Corpus for the Isan Language](https://arxiv.org/abs/2511.21229)
*Adisai Na-Thalang,Chanakan Wittayasakpan,Kritsadha Phatcharoen,Supakit Buakaw*

Main category: cs.CL

TL;DR: 本论文介绍了第一个针对泰国东北部方言伊善语的开放式对话语音数据集，捕捉了自然口语现象并解决了正字法不统一的问题。


<details>
  <summary>Details</summary>
Motivation: 现有语音语料多为朗读或剧本语音，缺乏自然对话语料，且伊善语缺乏标准正字法，增加了数据集构建难度。

Method: 制定实用的转录规范以平衡语言表现准确性和计算处理需求，处理口语中的语音现象和正字法多样性。

Result: 成功构建并开放发布了首个伊善语自然对话语音数据集，包含口语特征及语码转换现象。

Conclusion: 该数据集为包容性AI开发及少数语言研究提供重要资源，有助于解决对话语音建模中的语言及技术难题。

Abstract: This paper introduces the development of the first open conversational speech dataset for the Isan language, the most widely spoken regional dialect in Thailand. Unlike existing speech corpora that are primarily based on read or scripted speech, this dataset consists of natural speech, thereby capturing authentic linguistic phenomena such as colloquials, spontaneous prosody, disfluencies, and frequent code-switching with central Thai. A key challenge in building this resource lies in the lack of a standardized orthography for Isan. Current writing practices vary considerably, due to the different lexical tones between Thai and Isan. This variability complicates the design of transcription guidelines and poses questions regarding consistency, usability, and linguistic authenticity. To address these issues, we establish practical transcription protocols that balance the need for representational accuracy with the requirements of computational processing. By releasing this dataset as an open resource, we aim to contribute to inclusive AI development, support research on underrepresented languages, and provide a basis for addressing the linguistic and technical challenges inherent in modeling conversational speech.

</details>


### [31] [PEFT-Bench: A Parameter-Efficient Fine-Tuning Methods Benchmark](https://arxiv.org/abs/2511.21285)
*Robert Belanec,Branislav Pecher,Ivan Srba,Maria Bielikova*

Main category: cs.CL

TL;DR: 本文提出了PEFT-Bench，一个统一的基准测试平台，用于评估大规模自回归语言模型上的参数高效微调方法，并引入了综合考虑训练参数、推理速度和内存的PSCP指标。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型高计算和环境成本的问题，及当前PEFT方法评估有限且难以复现的挑战。

Method: 设计PEFT-Bench基准测试框架，涵盖27个自然语言处理数据集和6种PEFT方法，同时提出PSCP指标综合衡量PEFT的性能和资源消耗。

Result: 通过实验验证了PEFT-Bench的实用性和PSCP指标的有效性，支持多种PEFT方法的系统评估。

Conclusion: PEFT-Bench为研究者提供了统一、全面且可复现的评估平台，有助于推动PEFT方法的发展和应用。

Abstract: Despite the state-of-the-art performance of Large Language Models (LLMs) achieved on many tasks, their massive scale often leads to high computational and environmental costs, limiting their accessibility. Parameter-efficient fine-tuning (PEFT) methods address this challenge by reducing the number of trainable parameters while maintaining strong downstream performance. Despite the increased development in PEFT methods, current evaluations remain limited (in terms of evaluated models and datasets) and difficult to reproduce. To bridge this gap, we introduce PEFT-Bench, a unified end-to-end benchmark for evaluating diverse PEFT methods on autoregressive LLMs. We demonstrate its usage across 27 NLP datasets and 6 PEFT methods. To account for different PEFT training and inference factors, we also introduce the PEFT Soft Score Penalties (PSCP) metric, which takes trainable parameters, inference speed, and training memory usage into account.

</details>


### [32] [Emergent Lexical Semantics in Neural Language Models: Testing Martin's Law on LLM-Generated Text](https://arxiv.org/abs/2511.21334)
*Kai Kugler*

Main category: cs.CL

TL;DR: 本文首次系统地研究了神经语言模型训练期间生成文本中马丁定律（词频与多义性的经验关系）。


<details>
  <summary>Details</summary>
Motivation: 探究神经语言模型训练过程中词频与多义性的关系及其发展轨迹，理解训练过程中语义结构的变化。

Method: 通过对四个Pythia模型（70M-1B参数）30个训练检查点的上下文化词嵌入进行DBSCAN聚类，操作化定义词义数，分析马丁定律的表现。

Result: 发现马丁定律在训练中表现为非单调变化，约在第100个检查点出现，104时达到最高相关性(r > 0.6)，105时退化。小模型晚期出现语义崩溃，大模型退化较缓慢，词频-特异性关系保持稳定。

Conclusion: 神经语言模型生成文本对语言规律的遵从并非随训练单调增加，而是表现出有最佳语义窗口的平衡轨迹，本文提出了评估神经语言模型中语言结构的新方法。

Abstract: We present the first systematic investigation of Martin's Law - the empirical relationship between word frequency and polysemy - in text generated by neural language models during training. Using DBSCAN clustering of contextualized embeddings as an operationalization of word senses, we analyze four Pythia models (70M-1B parameters) across 30 training checkpoints. Our results reveal a non-monotonic developmental trajectory: Martin's Law emerges around checkpoint 100, reaches peak correlation (r > 0.6) at checkpoint 104, then degrades by checkpoint 105. Smaller models (70M, 160M) experience catastrophic semantic collapse at late checkpoints, while larger models (410M, 1B) show graceful degradation. The frequency-specificity trade-off remains stable (r $\approx$ -0.3) across all models. These findings suggest that compliance with linguistic regularities in LLM-generated text is not monotonically increasing with training, but instead follows a balanced trajectory with an optimal semantic window. This work establishes a novel methodology for evaluating emergent linguistic structure in neural language models.

</details>


### [33] [Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model](https://arxiv.org/abs/2511.21399)
*Joshua Fonseca Rivera*

Main category: cs.CL

TL;DR: 该研究通过微调7B参数语言模型，使其能够准确检测和报告单词级别注入的"思维"，极大提升了模型对内省意识的识别能力。


<details>
  <summary>Details</summary>
Motivation: 针对Lindsey(2025)发现语言模型对注入激活模式检测能力不可靠的问题，探讨是否可以通过直接训练提升模型的自我报告能力。

Method: 通过对7B参数模型进行微调，训练其识别和报告在单词位置注入的临时"思维"，并评估其准确性、错误率和泛化能力。

Result: 模型从近乎失败提升到85%准确率、零错误报告，且能保持检测信息并跨生成步骤报告语义内容，具备较好泛化能力。

Conclusion: 训练可以显著增强语言模型对注入思维的 introspective 能力，实现部分内省行为，并为内置AI透明度提供了可能途径。

Abstract: Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected "thoughts" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting "thoughts" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether "training for introspection would help eliminate cross-model differences." We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.

</details>


### [34] [Can LLMs extract human-like fine-grained evidence for evidence-based fact-checking?](https://arxiv.org/abs/2511.21401)
*Antonín Jarolím,Martin Fajčík,Lucia Makaiová*

Main category: cs.CL

TL;DR: 本文提出了针对捷克语和斯洛伐克语评论中事实错误信息的细粒度证据提取方法，创建了带双向标注的新数据集，并评估多款大语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 在线新闻评论中误导性信息普遍存在，需要有效方法检测错误信息，特别是定位支持或反驳声明的具体证据文本。

Method: 构建了包含人工标注的细粒度证据数据集，针对捷克语和斯洛伐克语声明进行双向注释，并使用多款大语言模型进行评测其与人工标注的一致性。

Result: 结果显示大型语言模型常无法逐字复制证据，致使输出无效；llama3.1:8b模型尽管较小但准确率高，gpt-oss-120b模型表现不佳，qwen3:14b、deepseek-r1:32b和gpt-oss:20b模型在规模和准确性之间表现平衡良好。

Conclusion: 细粒度证据提取对检测虚假信息至关重要，不同大语言模型在准确性与模型大小之间存在权衡，小模型有时能表现出较高准确率。

Abstract: Misinformation frequently spreads in user comments under online news articles, highlighting the need for effective methods to detect factually incorrect information. To strongly support or refute claims extracted from such comments, it is necessary to identify relevant documents and pinpoint the exact text spans that justify or contradict each claim. This paper focuses on the latter task -- fine-grained evidence extraction for Czech and Slovak claims. We create new dataset, containing two-way annotated fine-grained evidence created by paid annotators. We evaluate large language models (LLMs) on this dataset to assess their alignment with human annotations. The results reveal that LLMs often fail to copy evidence verbatim from the source text, leading to invalid outputs. Error-rate analysis shows that the {llama3.1:8b model achieves a high proportion of correct outputs despite its relatively small size, while the gpt-oss-120b model underperforms despite having many more parameters. Furthermore, the models qwen3:14b, deepseek-r1:32b, and gpt-oss:20b demonstrate an effective balance between model size and alignment with human annotations.

</details>


### [35] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://arxiv.org/abs/2511.21402)
*Zhifeng Hao,Qibin Song,Ruichu Cai,Boyan Xu*

Main category: cs.CL

TL;DR: 提出了DSR-SQL双状态推理框架，通过自适应上下文和渐进生成提升Text-to-SQL在复杂企业数据库上的表现，显著提高了执行准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于链式思维的Text-to-SQL方法在处理复杂企业数据库时受限于上下文容量、架构关联不可靠及语义基础薄弱，导致推理不连贯。

Method: DSR-SQL构建两个状态：自适应上下文状态通过筛选和精炼数据库架构，形成紧凑且语义忠实的环境；渐进生成状态将SQL合成视为反馈引导的状态转换，使模型具备自我修正和符合用户意图的能力。

Result: 在未进行额外训练或上下文示例的情况下，DSR-SQL在Spider 2.0-Snow数据集上执行准确率达35.28%，在BIRD开发集上达68.32%，表现具有竞争力。

Conclusion: DSR-SQL框架有效解决了复杂数据库Text-to-SQL任务中的关键问题，显著提升了大模型推理的连贯性和准确性，具有广泛应用潜力。

Abstract: Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise databases, such methods struggle to maintain coherent reasoning due to limited context capacity, unreliable schema linking, and weak grounding in database semantics. To overcome these issues, we introduce DSR-SQL, a \textbf{D}ual-\textbf{S}tate \textbf{R}easoning framework that models Text-to-SQL as an interaction between an adaptive context state and a progressive generation state. The first constructs a compact, semantically faithful environment by refining large schemas and selecting relevant structures, while the second formalizes SQL synthesis as feedback-guided state transitions, enabling the model to self-correct and align with user intent. Without any post-training or in-context examples, DSR-SQL achieves competitive performance, reaching 35.28\% execution accuracy on Spider 2.0-Snow and 68.32\% on BIRD development set. Our implementation will be open-sourced at: https://github.com/DMIRLAB-Group/DSR-SQL.

</details>


### [36] [Odin: Oriented Dual-module Integration for Text-rich Network Representation Learning](https://arxiv.org/abs/2511.21416)
*Kaifeng Hong,Yinglong Zhang,Xiaoying Hong,Xuewen Xia,Xing Xu*

Main category: cs.CL

TL;DR: 提出了一种新型架构Odin，通过定向双模块机制在Transformer指定层注入图结构，实现文本与结构的有效融合，克服了传统GNN过平滑和多跳扩散限制，达成了更优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖受限的GNNs，要么使用忽视图结构的Transformer，难以同时兼顾强文本理解与图结构推理。

Method: Odin在Transformer的特定深度层融合图结构，利用面向双模块机制实现多跳结构的层级抽象，避免了过平滑和对邻域大小的依赖，并设计了轻量级变体Light Odin以提升效率。

Result: Odin在多文本图基准上达到了最新的准确率，Light Odin在大幅降低计算成本的同时仍保持有竞争力的性能。

Conclusion: Odin及其轻量版本构建了一个无跳依赖的统一架构框架，有效整合文本与图结构，为文本属性图建模提供了新范式。

Abstract: Text-attributed graphs require models to effectively combine strong textual understanding with structurally informed reasoning. Existing approaches either rely on GNNs--limited by over-smoothing and hop-dependent diffusion--or employ Transformers that overlook graph topology and treat nodes as isolated sequences. We propose Odin (Oriented Dual-module INtegration), a new architecture that injects graph structure into Transformers at selected depths through an oriented dual-module mechanism.Unlike message-passing GNNs, Odin does not rely on multi-hop diffusion; instead, multi-hop structures are integrated at specific Transformer layers, yielding low-, mid-, and high-level structural abstraction aligned with the model's semantic hierarchy. Because aggregation operates on the global [CLS] representation, Odin fundamentally avoids over-smoothing and decouples structural abstraction from neighborhood size or graph topology. We further establish that Odin's expressive power strictly contains that of both pure Transformers and GNNs.To make the design efficient in large-scale or low-resource settings, we introduce Light Odin, a lightweight variant that preserves the same layer-aligned structural abstraction for faster training and inference. Experiments on multiple text-rich graph benchmarks show that Odin achieves state-of-the-art accuracy, while Light Odin delivers competitive performance with significantly reduced computational cost. Together, Odin and Light Odin form a unified, hop-free framework for principled structure-text integration. The source code of this model has been released at https://github.com/hongkaifeng/Odin.

</details>


### [37] [A Systematic Study of Model Merging Techniques in Large Language Models](https://arxiv.org/abs/2511.21437)
*Oğuz Kağan Hitit,Leander Girrbach,Zeynep Akata*

Main category: cs.CL

TL;DR: 本文系统评估了六种主流模型合并方法在大型语言模型（LLMs）上的表现，发现只有最早且最简单的任务算术方法能稳定提升性能，其他方法反而导致性能下降。


<details>
  <summary>Details</summary>
Motivation: 目前模型合并方法在小型模型和分类器上表现良好，但其在大型语言模型上的适用性和效果尚不明确。

Method: 本文对六种先进合并方法进行了大规模评估，测试对象包括四个基础开源权重大型语言模型，每个模型的十二个微调检查点，以及十六个标准LLM基准。通过标准化基准测试，测量合并模型相较于基础模型和最佳单独检查点的性能提升概率和相对增益。

Result: 结果表明，只有最早且最简单的任务算术方法能够稳定提升LLM性能，其他复杂的干扰感知和子空间合并方法往往导致显著性能下降。

Conclusion: 当前的模型合并技术难以直接应用于现代大型语言模型，未来需要设计专门针对LLM的合并算法和合并感知微调方法。

Abstract: Model merging combines multiple fine-tuned checkpoints into a single model without additional training, offering an attractive approach to reusing models and efficiently improving performance. However, it remains unclear whether the advantages reported for smaller models and classifiers generalize to LLMs. We present a large-scale, systematic evaluation of six state-of-the-art merging methods, including recent subspace methods, across four open-weight LLMs, twelve fine-tuned checkpoints per base model, and sixteen standard LLM benchmarks. Evaluating through standardized benchmarks, we measure both the probability that a merged model outperforms the base model and relative gains over the best individual checkpoint. Our results show that the oldest and simplest method, Task Arithmetic, is the only approach that reliably yields performance gains on LLMs. Other interference-aware and subspace merging methods typically result in significant performance drops. Our findings indicate that current merging techniques do not directly transfer to modern LLMs. This motivates the design of LLM-specific merging algorithms and merging-aware fine-tuning methods. Code will be released upon acceptance of this paper.

</details>


### [38] [Hierarchical Ranking Neural Network for Long Document Readability Assessment](https://arxiv.org/abs/2511.21473)
*Yurui Zheng,Yijun Chen,Shaohong Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种双向可读性评估机制，通过捕捉文本中的语义丰富区域预测句子可读性水平，进而辅助文档整体可读性评估，并引入成对排序算法建模标签的序数关系，实验结果优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习可读性评估方法往往忽视文本长度和可读性标签的序数关系，影响模型性能。

Method: 设计双向模型捕捉上下文语义信息，预测句子级可读性；结合句子标签辅助文档整体评估；引入成对排序算法利用标签之间的序数关系。

Result: 在中英文数据集上，所提模型表现出竞争力，且优于其他基线模型。

Conclusion: 该方法有效提升了可读性评估的准确性，证明了结合句子级标签和序数关系建模的有效性。

Abstract: Readability assessment aims to evaluate the reading difficulty of a text. In recent years, while deep learning technology has been gradually applied to readability assessment, most approaches fail to consider either the length of the text or the ordinal relationship of readability labels. This paper proposes a bidirectional readability assessment mechanism that captures contextual information to identify regions with rich semantic information in the text, thereby predicting the readability level of individual sentences. These sentence-level labels are then used to assist in predicting the overall readability level of the document. Additionally, a pairwise sorting algorithm is introduced to model the ordinal relationship between readability levels through label subtraction. Experimental results on Chinese and English datasets demonstrate that the proposed model achieves competitive performance and outperforms other baseline models.

</details>


### [39] [Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation](https://arxiv.org/abs/2511.21517)
*Lina Conti,Dennis Fucci,Marco Gaido,Matteo Negri,Guillaume Wisniewski,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文研究了语音翻译模型在为指代说话者的词语分配性别时所使用的机制，尤其关注训练数据偏差、内置语言模型偏见及声学信息的交互作用。


<details>
  <summary>Details</summary>
Motivation: 语音传递说话者的性别信息，导致语音翻译过程中性别分配可能存在偏见，比如错误性别识别，且目前对此机制理解不足。

Method: 分析三个语言对（英-西/法/意）语音翻译模型中性别分配机制，通过对训练数据模式、内置语言模型偏见和声学信息的结合使用对比性特征归因，揭示模型如何利用第一人称代词和广泛频率分布的信息分配性别。

Result: 模型并非简单复制训练数据中的性别偏见，而是学会了男性偏见的更广泛模式。内置语言模型存在强烈的男性偏见，但模型能够基于声学输入覆盖这种偏见，更准确地分配性别。

Conclusion: 语音翻译模型通过关联第一人称代词与性别词汇，并利用声频信息分布而非单一音调特征，实现了更准确的性别分配，这揭示了其性能背后未曾发现的机制。

Abstract: Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns. For example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker's vocal characteristics may play a role in gender assignment. This risks misgendering speakers, whether through masculine defaults or vocal-based assumptions. Yet, how ST models make these decisions remains poorly understood. We investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (en-es/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.

</details>


### [40] [Bangla Sign Language Translation: Dataset Creation Challenges, Benchmarking and Prospects](https://arxiv.org/abs/2511.21533)
*Husne Ara Rubaiyeat,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 本文介绍了一个针对孟加拉手语翻译的新数据集IsharaKhobor及其两个子集，旨在推动低资源孟加拉手语的AI辅助工具开发。


<details>
  <summary>Details</summary>
Motivation: 孟加拉手语属于资源极其稀缺的语言，缺少标准句子级数据集阻碍了基于AI的助听工具研发，急需构建高质量数据集。

Method: 作者构建了IsharaKhobor数据集并进行基于关键点的基线实验和RQE嵌入测试，同时通过词汇限制和规范化进行了消融实验，生成两个子集IsharaKhobor_small和IsharaKhobor_canonical_small。

Result: 构建完成的数据集促进了数据标准化，消融实验揭示了词汇限制和规范化对模型表现的影响，基线结果为未来研究提供了参考。

Conclusion: 该公开数据集为孟加拉手语翻译研究提供了重要资源，将促进开发更有效的助听辅助工具。

Abstract: Bangla Sign Language Translation (BdSLT) has been severely constrained so far as the language itself is very low resource. Standard sentence level dataset creation for BdSLT is of immense importance for developing AI based assistive tools for deaf and hard of hearing people of Bangla speaking community. In this paper, we present a dataset, IsharaKhobor , and two subset of it for enabling research. We also present the challenges towards developing the dataset and present some way forward by benchmarking with landmark based raw and RQE embedding. We do some ablation on vocabulary restriction and canonicalization of the same within the dataset, which resulted in two more datasets, IsharaKhobor_small and IsharaKhobor_canonical_small. The dataset is publicly available at: www.kaggle.com/datasets/hasanssl/isharakhobor [1].

</details>


### [41] [RoParQ: Paraphrase-Aware Alignment of Large Language Models Towards Robustness to Paraphrased Questions](https://arxiv.org/abs/2511.21568)
*Minjoon Choi*

Main category: cs.CL

TL;DR: 本文提出了RoParQ基准和XParaCon指标，用于评估大语言模型应对释义问题时的一致性，并通过推理指导的监督微调提升模型的语义不变性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在回答语义相似的释义问题时表现出不一致，依赖表层模式而非真正语义理解，迫切需要提升模型的语义稳定性。

Method: 构建RoParQ基准，采用模型生成释义，筛选出引起模型信心水平不一致的问题，并提出XParaCon评估指标，设计推理驱动的释义感知监督微调策略，提升模型语义不变性。

Result: 实验表明，通过该微调策略，模型的跨释义一致性显著提升，轻量级模型表现达到大型预训练模型的水平。

Conclusion: 该方法有效减少大语言模型的表层记忆依赖，增强模型对语义的鲁棒理解，提升了模型的可靠性。

Abstract: Large Language Models (LLMs) often exhibit inconsistent behavior when answering paraphrased questions, suggesting a reliance on surface-level patterns rather than true semantic understanding. To address this limitation, we introduce RoParQ, a benchmark specifically constructed to evaluate cross-paraphrase consistency in closed-book multiple-choice QA. This benchmark is derived from standard datasets by generating paraphrases via proprietary models and selectively retaining examples that elicit inconsistent confidence from a judge model. We further propose XParaCon, a novel evaluation metric that quantifies a model's robustness by measuring the standard deviation of accuracies across question variants. Additionally, we implement a reasoning-based, paraphrase-aware Supervised Fine-Tuning (SFT) strategy designed to align models toward semantic invariance. Our experiments demonstrate that this targeted alignment significantly enhances robustness. Notably, fine-tuned lightweight models achieved consistency levels comparable to much larger pre-trained models. These results highlight the efficacy of our approach in mitigating superficial memorization and fostering more robust, reliable LLMs.

</details>


### [42] [Auxiliary Metrics Help Decoding Skill Neurons in the Wild](https://arxiv.org/abs/2511.21610)
*Yixiu Zhao,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 本文提出了一种轻量且通用的方法，用于识别大型语言模型中编码特定技能的神经元，扩展了现有对“技能神经元”的研究，能够发现模型在多技能任务中的可解释行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型表现出强大能力，但其内部机制不透明，特别是如何编码不同技能的神经元尚不明确，有必要提出方法来揭示模型内部的技能神经元。

Method: 基于以往通过软提示训练识别技能神经元的方法，本文结合辅助指标（如外部标签和模型置信度）关联神经元激活，避免手动聚合，分析复杂多技能场景下的神经元行为。

Result: 实验证明该方法适用于开放式文本生成和自然语言推断任务，不仅能识别已知技能的神经元，还能发现BigBench算术推理中的新捷径。

Conclusion: 该方法有效揭示大型语言模型中编码特定技能的神经元，提升了模型可解释性，有助于理解和改进模型内部机制。

Abstract: Large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, yet their internal mechanisms remain largely opaque. In this paper, we introduce a simple, lightweight, and broadly applicable method with a focus on isolating neurons that encode specific skills. Building upon prior work that identified "skill neurons" via soft prompt training on classification tasks, our approach extends the analysis to complex scenarios involving multiple skills. We correlate neuron activations with auxiliary metrics -- such as external labels and the model's own confidence score -- thereby uncovering interpretable and task-specific behaviors without the need for manual token aggregation. We empirically validate our method on tasks spanning open-ended text generation and natural language inference, demonstrating its ability to detect neurons that not only drive known skills but also reveal previously unidentified shortcuts in arithmetic reasoning on BigBench.

</details>


### [43] [Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining](https://arxiv.org/abs/2511.21613)
*Dongyang Fan,Diba Hashemi,Sai Praneeth Karimireddy,Martin Jaggi*

Main category: cs.CL

TL;DR: 本文研究了将多种细粒度元数据融入大规模语言模型预训练，以提高训练速度和效果，并提出了元数据附加和可学习元标记的方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究仅探索了URL作为预训练中的元数据信号，存在其他元数据类型可能带来更大训练加速的潜力未被充分挖掘。

Method: 系统性地考察多种元数据类型，重点在于细粒度的文档质量指标，在输入前附加元数据，提出元数据附加辅助任务和可学习的元标记训练方法，通过探针分析潜在表示。

Result: 发现细粒度元数据能提升预训练速度，元数据附加辅助任务和可学习元标记均能有效加速训练且引入质量感知的潜在结构。

Conclusion: 细粒度的元数据对预训练大模型有显著提速与提升效果，合理引入元数据和辅助任务可提升训练效率和模型质量，研究结果为元数据整合提供实用指导。

Abstract: Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.

</details>


### [44] [The author is dead, but what if they never lived? A reception experiment on Czech AI- and human-authored poetry](https://arxiv.org/abs/2511.21629)
*Anna Marklová,Ondřej Vinš,Martina Vokáčová,Jiří Milička*

Main category: cs.CL

TL;DR: 研究表明，捷克母语者难以区分AI和人工创作的捷克语诗歌，且对AI诗歌评价与对作者身份的认知存在偏差。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的诗歌研究多聚焦于英语，本文旨在探讨捷克语环境下，母语者如何感知AI与人类创作的诗歌。

Method: 通过让参与者判断捷克语诗歌的作者（AI或人类），并进行美学评价，分析判断准确率及评价差异。

Result: 参与者辨别作者准确率仅为45.8%，接近随机水平；当认为是AI作品时评分较低；且喜欢诗歌的人反而更难准确判断作者。

Conclusion: AI能有效创作捷克语诗歌，且读者对于作品的美学评价与对作者身份的信念紧密相关，反映出作者身份偏见影响审美判断。

Abstract: Large language models are increasingly capable of producing creative texts, yet most studies on AI-generated poetry focus on English -- a language that dominates training data. In this paper, we examine the perception of AI- and human-written Czech poetry. We ask if Czech native speakers are able to identify it and how they aesthetically judge it. Participants performed at chance level when guessing authorship (45.8\% correct on average), indicating that Czech AI-generated poems were largely indistinguishable from human-written ones. Aesthetic evaluations revealed a strong authorship bias: when participants believed a poem was AI-generated, they rated it as less favorably, even though AI poems were in fact rated equally or more favorably than human ones on average. The logistic regression model uncovered that the more the people liked a poem, the less probable was that they accurately assign the authorship. Familiarity with poetry or literary background had no effect on recognition accuracy. Our findings show that AI can convincingly produce poetry even in a morphologically complex, low-resource (with respect of the training data of AI models) Slavic language such as Czech. The results suggest that readers' beliefs about authorship and the aesthetic evaluation of the poem are interconnected.

</details>


### [45] [Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](https://arxiv.org/abs/2511.21686)
*Dong Wang,Yang Li,Ansong Ni,Ching-Feng Yeh,Youssef Emad,Xinjie Lei,Liam Robbins,Karthik Padthe,Hu Xu,Xian Li,Asli Celikyilmaz,Ramya Raghavendra,Lifei Huang,Carole-Jean Wu,Shang-Wen Li*

Main category: cs.CL

TL;DR: 本文提出了Matrix，一个去中心化的多智能体协同生成框架，能够高效扩展且灵活适应多种合成任务。它通过分布式消息队列传递控制和数据信息，避免了中心协调器的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体合成框架多依赖中心协调器，造成扩展性瓶颈，且多数硬编码针对特定领域，缺乏灵活性。解决该问题对高质量、多样化且结构丰富的合成数据生成至关重要。

Method: Matrix采用点对点架构，通过分布式队列传递序列化消息，实现控制流程与数据流的解耦。任务由轻量级智能体独立推进，高计算量任务交由分布式服务处理。该框架基于Ray构建，支持数万个并发工作流。

Result: 在多种合成场景下（多智能体协同对话、基于网络的推理数据提取、客户服务工具轨迹生成），Matrix在相同硬件资源下，数据生成吞吐量提升2到15倍，同时保持输出质量不变。

Conclusion: Matrix提供了一种高效、灵活且可扩展的去中心化多智能体数据生成方案，显著提升了合成数据的生成效率和适用范围，为大规模语言模型训练提供有力支持。

Abstract: Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\times$ higher data generation throughput under identical hardware resources, without compromising output quality.

</details>


### [46] [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/abs/2511.21692)
*Yeganeh Kordi,Nihal V. Nayak,Max Zuo,Ilana Nguyen,Stephen H. Bach*

Main category: cs.CL

TL;DR: 本文系统评估了大语言模型(LLMs)在不同任务难度上的泛化能力，发现训练数据难度范围有限会限制模型的泛化效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究对于训练在简单或困难数据上哪种做法更有效，及其性能表现在哪种难度测试数据上，尚无定论。该问题对于数据集制作和模型评估非常关键。

Method: 通过成千上万不同LLMs的输出结合教育测试中成熟的项目反应理论(IRT)来对六个数据集内样本进行难度排序，难度评估完全基于模型能力，不依赖人工难度判断。

Result: 跨难度泛化能力受到限制，在训练时仅使用简单或困难数据，模型无法在全难度范围内表现均衡提升。

Conclusion: 训练和评估数据应覆盖广泛难度范围，避免在难度选择上的简化，否则会影响LLMs的泛化与评估效果。

Abstract: We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [47] [MTTR-A: Measuring Cognitive Recovery Latency in Multi-Agent Systems](https://arxiv.org/abs/2511.20663)
*Barak Or*

Main category: cs.MA

TL;DR: 本文将传统的可靠性指标引入认知领域，定义了MAS系统的认知恢复时间指标MTTR-A，并通过基准仿真验证了其测量恢复延迟的有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在大规模分布式AI中认知稳定性难以保障，现有方法不能量化认知恢复速度。

Method: 将平均恢复时间MTTR等经典可靠性指标应用于智能体认知，提出MTTR-A指标，并用AG新闻语料库和LangGraph框架进行仿真评估恢复延迟。

Result: 自动反射机制能在约6秒内恢复认知稳定，需人工介入则约12秒。经过200次仿真，获得MTTR-A中位数6.21秒，MTBF为6.7秒，证实了测量方法的有效性。

Conclusion: 该研究将认知恢复延迟形式化为可量化性能指标，奠定了智能体认知的运行时可靠性基础，推动认知恢复标准化和可解释化。

Abstract: Ensuring cognitive stability in autonomous multi-agent systems (MAS) is a central challenge for large-scale, distributed AI. While existing observability tools monitor system outputs, they cannot quantify how rapidly agentic workflows recover once reasoning coherence has been lost. We adapt classical reliability metrics-Mean Time-to-Recovery (MTTR), Mean Time Between Failures (MTBF), and related ratios-into the cognitive domain, defining MTTR-A (Mean Time-to-Recovery for Agentic Systems) as a runtime measure of cognitive recovery latency. MTTR-A quantifies the time required for a MAS to detect reasoning drift and restore consistent operation, capturing the recovery of reasoning coherence rather than infrastructural repair.
  A benchmark simulation using the AG~News corpus and the LangGraph orchestration framework was conducted, modeling recovery latencies across multiple reflex modes. Automated reflexes restored stability within approximately 6s on average, while human-approval interventions required about 12s. Across 200 runs, the median simulated MTTR-A was 6.21+-2.14s, MTBF=6.7+-2.14s, and NRR=0.08, demonstrating measurable runtime resilience across reflex strategies.
  By formalizing recovery latency as a quantifiable property of distributed reasoning-and deriving reliability bounds linking recovery time and cognitive uptime-this work establishes a foundation for runtime dependability in agentic cognition, transforming cognitive recovery from an ad-hoc process into a standardized, interpretable performance

</details>


### [48] [Resilient Charging Infrastructure via Decentralized Coordination of Electric Vehicles at Scale](https://arxiv.org/abs/2511.20943)
*Chuhao Qin,Alexandru Sorici,Andrei Olaru,Evangelos Pournaras,Adina Magda Florea*

Main category: cs.MA

TL;DR: 本文提出了一种基于集体学习的电动车充电协调框架，旨在缓解充电站拥堵和排队时间过长的问题，提升系统效率和驾驶员舒适度的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的分散式电动车充电控制方法在面对充电站故障和充电需求激增等突发情况时，难以有效协调，导致充电排队时间长和驾驶员体验下降。

Method: 提出了一种集体学习的协调框架，通过推荐电动车在充电选择中动态调整优先级，在个体舒适度和系统整体效率之间达到帕累托最优的权衡。

Result: 基于真实电动车和充电站数据的实验表明，该方法显著减少了行驶时间和排队时间，且在站点故障和恶意车辆存在的情况下仍保持较好的系统韧性和可信度。

Conclusion: 在不确定和紧张的充电条件下，灵活调整行为策略的电动车驾驶员能够获得更短的等待时间，证明所提框架在提升分散式充电系统效率和可靠性方面具有显著优势。

Abstract: The rapid adoption of electric vehicles (EVs) introduces major challenges for decentralized charging control. Existing decentralized approaches efficiently coordinate a large number of EVs to select charging stations while reducing energy costs, preventing power peak and preserving driver privacy. However, they often struggle under severe contingencies, such as station outages or unexpected surges in charging requests. These situations create competition for limited charging slots, resulting in long queues and reduced driver comfort. To address these limitations, we propose a novel collective learning-based coordination framework that allows EVs to balance individual comfort on their selections against system-wide efficiency, i.e., the overall queues across all stations. In the framework, EVs are recommended for adaptive charging behaviors that shift priority between comfort and efficiency, achieving Pareto-optimal trade-offs under varying station capacities and dynamic spatio-temporal EV distribution. Experiments using real-world data from EVs and charging stations show that the proposed approach outperforms baseline methods, significantly reducing travel and queuing time. The results reveal that, under uncertain charging conditions, EV drivers that behave selfishly or altruistically at the right moments achieve shorter waiting time than those maintaining moderate behavior throughout. Our findings under high fractions of station outages and adversarial EVs further demonstrate improved resilience and trustworthiness of decentralized EV charging infrastructure.

</details>


### [49] [Tool-RoCo: An Agent-as-Tool Self-organization Large Language Model Benchmark in Multi-robot Cooperation](https://arxiv.org/abs/2511.21510)
*Ke Zhang,Xiaoning Zhao,Ce Zheng,Jiahong Ning,Dandan Zhu,Wenqi Zhang,Chen Sun,Toshiharu Sugawara*

Main category: cs.MA

TL;DR: 本文提出Tool-RoCo基准，用于评估大语言模型（LLMs）在长期多智能体合作中的自主性和协作能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的多智能体系统多依赖预定义的调度，缺乏对智能体自主性的考察。

Method: 通过将其他智能体视为工具，引入合作工具，设计四种LLM范式（集中合作、集中自组织、去中心合作、自组织）和三种多机器人任务，利用工具调用行为评估智能体合作与自主水平。

Result: 实验证明合作工具调用次数低（7.09%），激活工具调用高（96.42%），表明现有LLMs更倾向保持智能体活跃而非灵活调整。

Conclusion: Tool-RoCo为评估LLMs在多智能体任务中的自主性和协作性提供了系统基准，有助推动相关研究发展。

Abstract: This study proposes Tool-RoCo, a novel benchmark for evaluating large language models (LLMs) in long-term multi-agent cooperation based on RoCo, a multi-robot cooperative benchmark. Recent research on LLM-based multi-agent systems has relied on predefined orchestration, while ignoring agent autonomy. Tool-RoCo treats other agents as tools and introduces cooperative tools, leveraging tool usage to evaluate multi-agent cooperation and self-organization. Tool usage means that each agent (LLM) selects a tool from a candidate set based on the current state, receives feedback, and adjusts its selection in subsequent rounds. To evaluate different autonomy levels, we propose four LLM paradigms: (1) centralized cooperation, where a single LLM allocates tools to all agents; (2) centralized self-organization, where a central LLM autonomously activates agents while keeping others inactive; (3) decentralized cooperation, where each agent has its own LLM and calls tools based on local information; and (4) self-organization, where a randomly chosen initial agent can request collaboration, activating additional agents via tool calls. Tool-RoCo includes three multi-robot tasks, SORT, PACK, and CABINET, to measure format and parameter accuracy and agent coordination through tool usage. The results using several LLMs showed that cooperative tools accounted for only 7.09% of all tools, indicating that LLM-based agents rarely invoked others as assistants. Moreover, activation tools accounted for 96.42%, suggesting that current LLMs tend to maintain active agents while seldom deactivating them for adaptive coordination. Tool-RoCo provides a systematic benchmark to evaluate LLM autonomy and cooperation in multi-agent tasks. Code and Demo: https://github.com/ColaZhang22/Tool-Roco

</details>


### [50] [BAMAS: Structuring Budget-Aware Multi-Agent Systems](https://arxiv.org/abs/2511.21572)
*Liming Yang,Junyu Luo,Xuanzhe Liu,Yiling Lou,Zhenpeng Chen*

Main category: cs.MA

TL;DR: 提出了一种名为BAMAS的多智能体系统构建方法，能够在预算限制下优化性能和成本，通过整数线性规划选择LLM并利用强化学习确定协作拓扑，实现性能与成本的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统在面对复杂任务时成本较高，且缺乏针对预算约束的结构设计方法，导致实际部署受限。

Method: BAMAS通过整数线性规划选择最优LLM集合以平衡性能和成本，再利用强化学习方法确定LLM之间的交互拓扑，最后根据选定的智能体和拓扑实例化系统并执行。

Result: 在三个代表性任务上的评估显示，BAMAS在保持相似性能的同时，成本降低了最高达86%。

Conclusion: BAMAS有效解决了多智能体系统在预算有限情况下的设计问题，实现了性能和成本的显著优化，具有良好的实用价值。

Abstract: Large language model (LLM)-based multi-agent systems have emerged as a powerful paradigm for enabling autonomous agents to solve complex tasks. As these systems scale in complexity, cost becomes an important consideration for practical deployment. However, existing work rarely addresses how to structure multi-agent systems under explicit budget constraints. In this paper, we propose BAMAS, a novel approach for building multi-agent systems with budget awareness. BAMAS first selects an optimal set of LLMs by formulating and solving an Integer Linear Programming problem that balances performance and cost. It then determines how these LLMs should collaborate by leveraging a reinforcement learning-based method to select the interaction topology. Finally, the system is instantiated and executed based on the selected agents and their collaboration topology. We evaluate BAMAS on three representative tasks and compare it with state-of-the-art agent construction methods. Results show that BAMAS achieves comparable performance while reducing cost by up to 86%.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [51] [DUALGUAGE: Automated Joint Security-Functionality Benchmarking for Secure Code Generation](https://arxiv.org/abs/2511.20709)
*Abhijeet Pathak,Suvadra Barua,Dinesh Gudimetla,Rupam Patir,Jiawei Guo,Hongxin Hu,Haipeng Cai*

Main category: cs.SE

TL;DR: 本文提出了DUALGAUGE，一个用于同时评估大语言模型生成代码的安全性和正确性的自动化基准测试框架，并配套了包含安全和功能双重测试套件的数据集DUALGAUGE-BENCH。


<details>
  <summary>Details</summary>
Motivation: 现有关于安全代码生成的评测多只关注漏洞减少，忽视功能正确性或针对安全和功能采用不同数据集，缺乏统一综合评估方法。

Method: 设计了一个代理程序执行器在沙箱环境中运行代码测试，结合基于大语言模型的评估器，统一评估代码的安全性和正确性。并构建了包含多样编码任务和手动验证测试套件的DUALGAUGE-BENCH。

Result: 对十个主流大语言模型在DUALGAUGE-BENCH上进行了数千测试场景的评测，揭示了这些模型在正确性和安全性生成上的重大缺陷。

Conclusion: DUALGAUGE及其数据集提供了一个开放、可重复且严谨的统一评测平台，有助于推动安全正确代码自动生成领域的进步。

Abstract: Large language models (LLMs) and autonomous coding agents are increasingly used to generate software across a wide range of domains. Yet a core requirement remains unmet: ensuring that generated code is secure without compromising its functional correctness. Existing benchmarks and evaluations for secure code generation fall short-many measure only vulnerability reduction, disregard correctness preservation, or evaluate security and functionality on separate datasets, violating the fundamental need for simultaneous joint evaluation. We present DUALGAUGE, the first fully automated benchmarking framework designed to rigorously evaluate the security and correctness of LLM-generated code in unison. Given the lack of datasets enabling joint evaluation of secure code generation, we also present DUALGAUGE-BENCH, a curated benchmark suite of diverse coding tasks, each paired with manually validated test suites for both security and functionality, designed for full coverage of specification requirements. At the core of DUALGAUGE is an agentic program executor, which runs a program against given tests in sandboxed environments, and an LLM-based evaluator, which assesses both correctness and vulnerability behavior against expected outcomes. We rigorously evaluated and ensured the quality of DUALGAUGE-BENCH and the accuracy of DUALGAUGE, and applied DUALGAUGE to benchmarking ten leading LLMs on DUALGAUGE-BENCH across thousands of test scenarios. Our results reveal critical gaps in correct and secure code generation by these LLMs, for which our open-source system and datasets help accelerate progress via reproducible, scalable, and rigorous evaluation.

</details>


### [52] [Data-Driven Methods and AI in Engineering Design: A Systematic Literature Review Focusing on Challenges and Opportunities](https://arxiv.org/abs/2511.20730)
*Nehal Afifi,Christoph Wittig,Lukas Paehler,Andreas Lindenmann,Kai Wolter,Felix Leitenberger,Melih Dogru,Patric Grauberger,Tobias Düser,Albert Albers,Sven Matthiesen*

Main category: cs.SE

TL;DR: 本文通过系统文献综述，分析了数据驱动方法（DDMs）在产品开发中的应用现状，发现机器学习和统计方法占主导，深度学习增长显著，但验证阶段应用有限，存在模型可解释性差和验证不足等挑战。


<details>
  <summary>Details</summary>
Motivation: 产品开发中数据驱动方法的应用零散且不明确，缺乏关于应采用何种方法及使用时机的清晰指导，亟需系统调查DDMs在工程设计各阶段的应用情况。

Method: 采用PRISMA系统文献综述方法，以V模型简化为系统设计、实现、集成和验证四个阶段，在Scopus、Web of Science和IEEE Xplore数据库中检索2014-2024年相关文献，筛选出114篇进行全文分析。

Result: 机器学习和统计方法占据主导地位，深度学习虽较少但增长趋势明显，监督学习、聚类、回归分析和代理建模多应用于设计、实现和集成阶段，验证阶段贡献有限。存在模型解释性不足、跨阶段追踪性差和真实环境验证不足等关键挑战。

Conclusion: 研究揭示了DDMs在产品开发中的应用现状与不足，强调了构建可解释的混合模型的必要性，呼吁后续研究结合计算机科学算法与工程设计问题，推动设计阶段的应用指导发展。

Abstract: The increasing availability of data and advancements in computational intelligence have accelerated the adoption of data-driven methods (DDMs) in product development. However, their integration into product development remains fragmented. This fragmentation stems from uncertainty, particularly the lack of clarity on what types of DDMs to use and when to employ them across the product development lifecycle. To address this, a necessary first step is to investigate the usage of DDM in engineering design by identifying which methods are being used, at which development stages, and for what application. This paper presents a PRISMA systematic literature review. The V-model as a product development framework was adopted and simplified into four stages: system design, system implementation, system integration, and validation. A structured search across Scopus, Web of Science, and IEEE Xplore (2014--2024) retrieved 1{,}689 records. After screening, 114 publications underwent full-text analysis. Findings show that machine learning (ML) and statistical methods dominate current practice, whereas deep learning (DL), though still less common, exhibits a clear upward trend in adoption. Additionally, supervised learning, clustering, regression analysis, and surrogate modeling are prevalent in design, implementation, and integration system stages but contributions to validation remain limited. Key challenges in existing applications include limited model interpretability, poor cross-stage traceability, and insufficient validation under real-world conditions. Additionally, it highlights key limitations and opportunities such as the need for interpretable hybrid models. This review is a first step toward design-stage guidelines; a follow-up synthesis should map computer science algorithms to engineering design problems and activities.

</details>


### [53] [Train While You Fight -- Technical Requirements for Advanced Distributed Learning Platforms](https://arxiv.org/abs/2511.20813)
*Simon Hacks*

Main category: cs.SE

TL;DR: 本文探讨了支撑“战斗中训练”(TWYF)的先进分布式学习平台的技术需求，并通过设计科学研究方法，将挑战映射到现有的软件工程模式。


<details>
  <summary>Details</summary>
Motivation: TWYF提出在战斗过程中持续学习的理念，推动学习不是仅发生在战前或战后，因而需要新的技术支持来满足这一需求。

Method: 采用设计科学研究方法，从PfPC/NATO文档及实践中提炼挑战，定义解决目标，并通过系统映射将挑战与成熟模式对应。

Result: 识别出七大技术挑战：互操作性、弹性、多语言支持、数据安全与隐私、可扩展性、平台独立性和模块化，并通过德国军队的国家案例加以说明。

Conclusion: 现有的软件工程模式能够满足ADVANCED分布式学习平台的需求，从而有效支撑TWYF理念，实现持续的实战学习。

Abstract: "Train While You Fight" (TWYF) advocates for continuous learning that occurs during operations, not just before or after. This paper examines the technical requirements that advanced distributed learning (ADL) platforms must meet to support TWYF, and how existing software engineering patterns can fulfill these requirements. Using a Design Science Research approach, we (i) derive challenges from PfPC/NATO documentation and recent practice, (ii) define solution objectives, and (iii) conduct a systematic mapping from challenges to proven patterns. We identify seven technical challenges: interoperability, resilience, multilingual support, data security and privacy, scalability, platform independence, and modularity. We illustrate the patterns with a national use case from the German armed forces.

</details>


### [54] [Application of machine learning for infrastructure reconstruction programs management](https://arxiv.org/abs/2511.20916)
*Illia Khudiakov,Vladyslav Pliuhin,Sergiy Plankovskyy,Yevgen Tsegelnyk*

Main category: cs.SE

TL;DR: 本文提出了一种自适应决策支持模型，旨在提升工程基础设施重建项目管理的效率，基于程序架构和工作分解结构的开发。


<details>
  <summary>Details</summary>
Motivation: 现有的工程基础设施重建项目管理效率不足，需要通过自适应决策支持模型优化管理流程，提升决策质量。

Method: 分析现有自适应项目管理工具，采用基础设施系统建模工具，利用机器学习和人工神经网络进行系统建模与目标函数预测，结合历史数据进行训练与调整。

Result: 模型定义了决策者偏好、决策任务、输入数据及软件组件，利用微软Azure机器学习平台实现，给出神经网络参数及评价结果，通过调整模型参数实现对不同类型对象的适应性。

Conclusion: 所提自适应决策支持模型适用于多类工程基础设施系统重建项目管理，能够有效支持决策过程，提高管理效率与实施效果。

Abstract: The purpose of this article is to describe an adaptive decision-making support model aimed at improving the efficiency of engineering infrastructure reconstruction program management in the context of developing the architecture and work breakdown structure of programs. As part of the study, the existing adaptive program management tools are analyzed, the use of infrastructure systems modelling tools is justified for program architecture and WBS creation. Existing models and modelling methods are viewed, and machine learning and artificial neural networks are selected for the model. The main components of the model are defined, which include a set of decision-maker preferences, decision-making tasks, sets of input data, and applied software components of the model. To support decision-making, the adaptive model applies the method of system modeling and predicting the value of the objective function at a given system configuration. Prediction is done using machine learning methods based on a dataset consisting of historical data related to existing engineering systems. The work describes the components of the redistribution of varied model parameters, which modify the model dataset based on the selected object type, which allows adapting the decision-making process to the existing program implementation goals. The functional composition done in Microsoft Azure Machine Learning Studio is described. The neural network parameters and evaluation results are given. The application of the developed adaptive model is possible in the management of programs for the reconstruction of such engineering systems as systems of heat, gas, electricity supply, water supply, and drainage, etc.

</details>


### [55] [Hierarchical Evaluation of Software Design Capabilities of Large Language Models of Code](https://arxiv.org/abs/2511.20933)
*Mootez Saad,Boqi Chen,José Antonio Hernández López,Dániel Varró,Tushar Sharma*

Main category: cs.SE

TL;DR: 本文通过实证研究评估大型语言模型对软件设计中内聚性和耦合性的理解，发现模型在理想条件下表现良好，但在噪声和开放式任务中耦合性推理性能显著下降，内聚性分析较为稳健，但在无指导时同样失效。


<details>
  <summary>Details</summary>
Motivation: 软件工程领域越来越多地采用大型语言模型，但其对核心设计概念（内聚性和耦合性）的理解及其鲁棒性尚不清楚。

Method: 采用程序化生成的设计欠佳的代码片段，测试DeepSeek-R1系列模型（14B、32B、70B）在不同指导水平（验证、引导、开放生成）和不同上下文噪声注入情况下的表现，结合推理轨迹分析探讨失败模式。

Result: 模型在理想无噪声条件下对内聚性和耦合性基础理解较好，但耦合性推理在有噪声和开放生成任务中F1分数下降超过50%，内聚性分析对噪声较为鲁棒但在无指导时失败。推理轨迹显示耦合性存在认知捷径，内聚性分析更为彻底但仍不完美。

Conclusion: 大型语言模型能辅助识别设计缺陷，但在现实带噪声环境中自主推理能力有限，强调了提升其程序理解鲁棒性和可扩展能力的必要性。

Abstract: Large language models (LLMs) are being increasingly adopted in the software engineering domain, yet the robustness of their grasp on core software design concepts remains unclear. We conduct an empirical study to systematically evaluate their understanding of cohesion (intra-module) and coupling (inter-module). We programmatically generate poorly designed code fragments and test the DeepSeek-R1 model family ($14$B, $32$B, $70$B) under varying levels of guidance, from simple \textit{Verification} to \textit{Guided} and \textit{Open-ended Generation}, while varying contextual noise by injecting distractor elements. While models exhibit a solid baseline understanding of both concepts in ideal conditions, their practical knowledge is fragile and highly asymmetrical. Reasoning about coupling proves brittle; performance collapses in noisy, open-ended scenarios, with F1 scores dropping by over $50\%$. In contrast, the models' analysis of cohesion is remarkably robust to internal noise in guided tasks, showing little performance degradation. However, this resilience also fails when all guidance is removed. Reasoning-trace analysis confirms these failure modes, revealing \textit{cognitive shortcutting} for coupling versus a more exhaustive (yet still failing) analysis for cohesion. To summarize, while LLMs can provide reliable assistance for recognizing design flaws, their ability to reason autonomously in noisy, realistic contexts is limited, highlighting the critical need for more scalable and robust program understanding capabilities.

</details>


### [56] [SpaceX: Exploring metrics with the SPACE model for developer productivity](https://arxiv.org/abs/2511.20955)
*Sanchit Kaul,Kevin Nhu,Jason Eissayou,Ivan Eser,Victor Borup*

Main category: cs.SE

TL;DR: 本文通过大规模开源库数据挖掘，结合统计模型和情感分析，提出了综合性生产力指标CPS，以克服传统单维度生产力评估的不足。


<details>
  <summary>Details</summary>
Motivation: 传统的单一和确定性生产力启发式方法存在局限，难以全面反映开发者的实际效能。

Method: 利用开源代码库数据，采用广义线性混合模型(GLMM)和基于RoBERTa的情感分类方法，构建多维度生产力评估框架（SPACE）；分析贡献者互动的拓扑结构。

Result: 发现负面情感状态与提交频率正相关，表明存在由挫折驱动的迭代修复循环；贡献者互动拓扑结构比传统量化指标更准确反映协作动态。

Conclusion: 提出复合生产力评分（CPS），有效应对开发者效能多样性，提升生产力评估的准确性和全面性。

Abstract: This empirical investigation elucidates the limitations of deterministic, unidimensional productivity heuristics by operationalizing the SPACE framework through extensive repository mining. Utilizing a dataset derived from open-source repositories, the study employs rigorous statistical methodologies including Generalized Linear Mixed Models (GLMM) and RoBERTa-based sentiment classification to synthesize a holistic, multi-faceted productivity metric. Analytical results reveal a statistically significant positive correlation between negative affective states and commit frequency, implying a cycle of iterative remediation driven by frustration. Furthermore, the investigation has demonstrated that analyzing the topology of contributor interactions yields superior fidelity in mapping collaborative dynamics compared to traditional volume-based metrics. Ultimately, this research posits a Composite Productivity Score (CPS) to address the heterogeneity of developer efficacy.

</details>


### [57] [Lightweight Model Editing for LLMs to Correct Deprecated API Recommendations](https://arxiv.org/abs/2511.21022)
*Guancheng Lin,Xiao Yu,Jacky Keung,Xing Hu,Xin Xia,Alex X. Liu*

Main category: cs.SE

TL;DR: 本文系统研究了更新大语言模型中已弃用API知识的轻量级模型编辑方法，提出AdaLoRA-L方法显著提升了编辑的针对性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然在代码补全任务中表现优异，但由于训练数据滞后，往往会生成已弃用的API，且重新训练代价高昂，迫切需要高效准确地更新模型中的API知识。

Method: 采用10种先进的模型编辑技术在三种大语言模型上进行实验，构建了包含70多个弃用API的EDAPIBench基准，基于AdaLoRA提出改进版本AdaLoRA-L，通过划分通用和特定API层来限制编辑范围以提升编辑特异性。

Result: AdaLoRA在提升编辑性能方面效果最佳，但特异性不足。AdaLoRA-L通过限制编辑层显著提升了特异性，同时保持了其他指标的良好性能。

Conclusion: 轻量级模型编辑技术特别是AdaLoRA-L能够有效地更新大语言模型中的弃用API知识，避免了重新训练的高昂代价，并提升了编辑的准确性和针对性。

Abstract: Pre-trained or fine-tuned on large code corpora, Large Language Models (LLMs) have demonstrated strong performance in code completion tasks. However, their embedded knowledge is constrained by the timeliness of training data, which often includes code using deprecated APIs. Consequently, LLMs frequently generate deprecated APIs that will no longer be supported in future versions of third-party libraries. While retraining LLMs on updated codebases could refresh their API knowledge, this approach is computationally expensive. Recently, lightweight model editing methods have emerged to efficiently correct specific knowledge in LLMs. However, it remains unclear whether these methods can effectively update deprecated API knowledge and enable edited models to generate up-to-date APIs. To address this gap, we conduct the first systematic study applying 10 state-of-the-art model editing techniques to update deprecated API knowledge in three LLMs: Qwen2.5-Coder, StarCoder2, and DeepSeek-Coder. We introduce EDAPIBench, a dedicated benchmark featuring over 70 deprecated APIs from 8 popular Python libraries, with more than 3,000 editing instances. Our results show that the parameter-efficient fine-tuning method AdaLoRA achieves the best performance in enabling edited models to generate correct, up-to-date APIs, but falls short in Specificity (i.e., the editing influences untargeted knowledge). To resolve this, we propose AdaLoRA-L, which defines "Common API Layers" (layers within the LLMs with high importance across all APIs, storing general knowledge and excluded from editing) and restricts edits exclusively to "Specific API Layers" (layers with high importance only for the target API, storing the API-specific knowledge). Experimental results demonstrate that AdaLoRA-L significantly improves Specificity while maintaining comparable performance across other evaluation metrics.

</details>


### [58] [Exploring Hidden Geographic Disparities in Android Apps](https://arxiv.org/abs/2511.21151)
*M. Alecci,P. Jiménez,J. Samhi,T. Bissyandé,J. Klein*

Main category: cs.SE

TL;DR: 本文研究了地理位置对Android应用程序行为的影响，发现同一款应用在不同地区存在功能和权限的差异，这对安全性和公平性带来问题。


<details>
  <summary>Details</summary>
Motivation: 尽管移动应用演化已有广泛研究，但应用程序在不同地理区域的行为差异尚未被充分探讨，这些差异可能影响安全性和隐私，甚至导致地区性偏见。

Method: 建立了跨区域的分布式应用收集管道，分析了数千款应用，特别研究了功能相似但包名不同的GeoTwins应用和Android App Bundle中的区域差异，发布了包含81,963个GeoTwins的数据集供后续研究。

Result: 发现GeoTwins应用在权限请求、第三方库和隐私声明上存在差异，且base.apk文件也因地区不同而有所变化，导致应用在不同地区安全评估结果不一致，引入了地理偏见并影响评估的可重复性。

Conclusion: 移动软件存在系统性的地区差异，这对研究者、开发者、平台设计者和政策制定者提出了挑战，呼吁关注应用透明度、用户同意及跨区域的公平性。

Abstract: While mobile app evolution has been widely studied, geographical variation in app behavior remains largely unexplored. This paper presents a large-scale study of location-based Android app differentiation, uncovering two important and underexamined phenomena with security and fairness implications. First, we introduce GeoTwins: apps that are functionally similar and share branding but are released under different package names across countries. Despite their similarity, GeoTwins often diverge in requested permissions, third-party libraries, and privacy disclosures. Second, we examine the Android App Bundle ecosystem and reveal unexpected regional differences in supposedly consistent base.apk files. Contrary to common assumptions, even base.apk files vary by region, exposing hidden customizations that may affect app behavior or security.
  These discrepancies have concrete consequences. Geographically distinct variants can lead the same app to be labeled benign in one malware study but suspicious in another, depending on the region of download. Such hidden variation undermines reproducibility and introduces geographic bias into assessments of security, privacy, and functionality. It also raises ethical concerns about transparency and consent: visually identical Google Play listings may mask subtle but important differences.
  To study these issues, we built a distributed app collection pipeline spanning multiple regions and analyzed thousands of apps. We also release a dataset of 81,963 GeoTwins to support future work. Our findings reveal systemic regional disparities in mobile software, with implications for researchers, developers, platform architects, and policymakers.

</details>


### [59] [Bug Detective and Quality Coach: Developers' Mental Models of AI-Assisted IDE Tools](https://arxiv.org/abs/2511.21197)
*Paolo Buono,Mary Cerullo,Stefano Cirillo,Giuseppe Desolda,Francesco Greco,Emanuela Guglielmi,Grazia Margarella,Giuseppe Polese,Simone Scalabrino,Cesare Tucci*

Main category: cs.SE

TL;DR: 本文通过六场联合设计工作坊调查了开发者对AI辅助工具的心理模型，提出了针对不同任务的设计原则。


<details>
  <summary>Details</summary>
Motivation: 尽管AI辅助工具技术进步显著，但开发者如何理解这些工具及理解偏差对信任和采用的影响尚不清楚。

Method: 与58名开发者举行六次联合设计工作坊，探讨他们对AI辅助的漏洞检测和代码可读性评估功能的心智模型。

Result: 发现开发者将漏洞检测工具视为"漏洞侦探"，仅在关键问题时警告，强调反馈透明和可操作性；而可读性评估工具被视为"质量教练"，提供个性化、渐进式指导。信任依赖于解释清晰度、时机和用户控制。

Conclusion: 基于研究结果，提出了一套以人为中心的AI设计原则，旨在在IDE中平衡干扰与支持、简洁与深度以及自动化与人工控制。

Abstract: AI-assisted tools support developers in performing cognitively demanding tasks such as bug detection and code readability assessment. Despite the advancements in the technical characteristics of these tools, little is known about how developers mentally model them and how mismatches affect trust, control, and adoption. We conducted six co-design workshops with 58 developers to elicit their mental models about AI-assisted bug detection and readability features. It emerged that developers conceive bug detection tools as \textit{bug detectives}, which warn users only in case of critical issues, guaranteeing transparency, actionable feedback, and confidence cues. Readability assessment tools, on the other hand, are envisioned as \textit{quality coaches}, which provide contextual, personalized, and progressive guidance. Trust, in both tasks, depends on the clarity of explanations, timing, and user control. A set of design principles for Human-Centered AI in IDEs has been distilled, aiming to balance disruption with support, conciseness with depth, and automation with human agency.

</details>


### [60] [Multi-Agent Systems for Dataset Adaptation in Software Engineering: Capabilities, Limitations, and Future Directions](https://arxiv.org/abs/2511.21380)
*Jingyi Chen,Xiaoyan Guo,Songqiang Chen,Shing-Chi Cheung,Jiasi Shen*

Main category: cs.SE

TL;DR: 本文首次实证研究了基于大型语言模型的多智能体系统在软件工程研究成果跨数据集适配任务中的表现，发现当前系统能部分识别关键文件但难以生成功能正确代码，且通过提示干预显著提高结构相似度。


<details>
  <summary>Details</summary>
Motivation: 自动化实现软件工程研究成果在不同数据集之间的适配对于提高工作效率和研究可重复性至关重要，但相关研究尚缺乏。

Method: 基于GitHub Copilot（GPT-4.1及Claude Sonnet 4驱动）的多智能体系统，设计包含文件理解、代码编辑、命令生成、验证及执行的五阶段评估流程，对ROCODE和LogHub2.0等基准库中的研究成果适配能力进行评测。

Result: 当前多智能体系统能够识别关键文件并生成部分适配代码，但功能上的正确实现率较低。引入执行错误消息和参考代码等提示层面的干预，显著提升了生成代码与真实代码之间的结构相似度，从7.25%提高至67.14%。

Conclusion: 现有多智能体大语言模型系统在软件工程成果数据集适配任务上表现出潜力，但功能完备性有限，需依赖上下文和反馈驱动的提示优化。未来研究应聚焦构建更可靠、具备自我纠错能力的智能体系统。

Abstract: Automating the adaptation of software engineering (SE) research artifacts across datasets is essential for scalability and reproducibility, yet it remains largely unstudied. Recent advances in large language model (LLM)-based multi-agent systems, such as GitHub Copilot's agent mode, promise to automate complex development workflows through coordinated reasoning, code generation, and tool interaction. This paper presents the first empirical study on how state-of-the-art multi-agent systems perform in dataset adaptation tasks. We evaluate Copilot, backed by GPT-4.1 and Claude Sonnet 4, on adapting SE research artifacts from benchmark repositories including ROCODE and LogHub2.0. Through a five-stage evaluation pipeline (file comprehension, code editing, command generation, validation, and final execution), we measure success rates, analyze failure patterns, and assess prompt-based interventions designed to enhance agent performance. Results show that current systems can identify key files and generate partial adaptations but rarely produce functionally correct implementations. Prompt-level interventions, especially providing execution error messages and reference code, substantially improve structural similarity to ground truth (from 7.25% to 67.14%), highlighting the importance of contextual and feedback-driven guidance. Our findings reveal both the promise and limitations of today's multi-agent LLM systems for dataset adaptation, and suggest concrete directions for building more reliable, self-correcting agents in future SE research.

</details>


### [61] [Large Language Models for Unit Test Generation: Achievements, Challenges, and the Road Ahead](https://arxiv.org/abs/2511.21382)
*Bei Chu,Yang Feng,Kui Liu,Zifan Nan,Zhaoqiang Guo,Baowen Xu*

Main category: cs.SE

TL;DR: 本文系统综述了利用大型语言模型（LLMs）进行单元测试生成的最新研究，提出统一分类体系，分析核心策略和提升技术，指出提示工程和迭代验证是主流方法，但测试缺陷检测能力不足，评价标准缺失。


<details>
  <summary>Details</summary>
Motivation: 单元测试是验证软件的重要但费力的技术，传统自动方法缺乏语义信息，LLMs凭借其语义知识有望提升自动测试的质量和效率。

Method: 通过回顾2021年至2025年的115篇相关文献，建立基于测试生命周期的统一分类框架，分析生成策略和增强技术，评估研究趋势和挑战。

Result: 提示工程作为主要策略占89%，迭代验证和修复循环普遍应用，显著提升测试通过率，但生成测试的缺陷检测能力弱，缺少统一评估基准。

Conclusion: 未来研究应聚焦自主测试代理和结合传统工具的混合系统，推动LLMs潜力转化为工业级测试解决方案。该综述为研究人员和工业界提供全面视角。

Abstract: Unit testing is an essential yet laborious technique for verifying software and mitigating regression risks. Although classic automated methods effectively explore program structures, they often lack the semantic information required to produce realistic inputs and assertions. Large Language Models (LLMs) address this limitation by utilizing by leveraging their data-driven knowledge of code semantics and programming patterns. To analyze the state of the art in this domain, we conducted a systematic literature review of 115 publications published between May 2021 and August 2025. We propose a unified taxonomy based on the unit test generation lifecycle that treats LLMs as stochastic generators requiring systematic engineering constraints. This framework analyzes the literature regarding core generative strategies and a set of enhancement techniques ranging from pre-generation context enrichment to post-generation quality assurance. Our analysis reveals that prompt engineering has emerged as the dominant utilization strategy and accounts for 89% of the studies due to its flexibility. We find that iterative validation and repair loops have become the standard mechanism to ensure robust usability and lead to significant improvements in compilation and execution pass rates. However, critical challenges remain regarding the weak fault detection capabilities of generated tests and the lack of standardized evaluation benchmarks. We conclude with a roadmap for future research that emphasizes the progression towards autonomous testing agents and hybrid systems combining LLMs with traditional software engineering tools. This survey provides researchers and practitioners with a comprehensive perspective on converting the potential of LLMs into industrial-grade testing solutions.

</details>
