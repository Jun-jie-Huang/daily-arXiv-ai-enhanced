<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.SE](#cs.SE) [Total: 14]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Women's Health Benchmark for Large Language Models](https://arxiv.org/abs/2512.17028)
*Victoria-Elisabeth Gruber,Razvan Marinescu,Diego Fajardo,Amin H. Nassar,Christopher Arkfeld,Alexandria Ludlow,Shama Patel,Mehrnoosh Samaei,Valerie Klug,Anna Huber,Marcel Gühner,Albert Botta i Orfila,Irene Lagoja,Kimya Tarr,Haleigh Larson,Mary Beth Howard*

Main category: cs.CL

TL;DR: 本文提出了女性健康基准测试（WHB），评估大型语言模型在女性健康领域的表现，发现模型存在较高错误率，尤其在紧急情况识别方面表现较差。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型成为健康咨询的重要来源，但其在女性健康领域的准确性和可靠性尚未被充分检验。

Method: 构建涵盖五个医疗专业、三种查询类型及八种错误类型的女性健康基准（WHB），并利用该基准测试了13个先进的大型语言模型。

Result: 模型在女性健康领域表现不理想，错误率约为60%，在不同专科和错误类型间表现差异显著，尤其在识别紧急指标方面普遍存在不足，新型号如GPT-5在避免不当建议上表现较好。

Conclusion: 当前大型语言模型尚不能完全可靠地提供女性健康相关建议，提示需要进一步改进和专项评估。

Abstract: As large language models (LLMs) become primary sources of health information for millions, their accuracy in women's health remains critically unexamined. We introduce the Women's Health Benchmark (WHB), the first benchmark evaluating LLM performance specifically in women's health. Our benchmark comprises 96 rigorously validated model stumps covering five medical specialties (obstetrics and gynecology, emergency medicine, primary care, oncology, and neurology), three query types (patient query, clinician query, and evidence/policy query), and eight error types (dosage/medication errors, missing critical information, outdated guidelines/treatment recommendations, incorrect treatment advice, incorrect factual information, missing/incorrect differential diagnosis, missed urgency, and inappropriate recommendations). We evaluated 13 state-of-the-art LLMs and revealed alarming gaps: current models show approximately 60\% failure rates on the women's health benchmark, with performance varying dramatically across specialties and error types. Notably, models universally struggle with "missed urgency" indicators, while newer models like GPT-5 show significant improvements in avoiding inappropriate recommendations. Our findings underscore that AI chatbots are not yet fully able of providing reliable advice in women's health.

</details>


### [2] [Knowledge Distillation with Structured Chain-of-Thought for Text-to-SQL](https://arxiv.org/abs/2512.17053)
*Khushboo Thaker,Yony Bresler*

Main category: cs.CL

TL;DR: 企业级Text-to-SQL系统面临成本、安全和性能的三难困境。通过结构化的逻辑推理示范知识蒸馏方法显著提升了小型语言模型性能，减少错误。


<details>
  <summary>Details</summary>
Motivation: 现有方案在大型语言模型昂贵且安全性存疑，小型模型性能不足之间难以取舍。提升小型模型性能的无结构推理指导方法存在歧义且效果有限。

Method: 提出Struct-SQL知识蒸馏框架，利用查询执行计划作为结构化链式推理示范，引导小模型学习大型模型的推理逻辑。

Result: 结构化的链式推理蒸馏使小型模型性能比无结构蒸馏提升8.1%。错误分析表明语法错误显著减少。

Conclusion: 采用结构化逻辑推理作为教学信号有助于提升小型语言模型在Text-to-SQL任务中的可靠性和性能。

Abstract: Deploying accurate Text-to-SQL systems at the enterprise level faces a difficult trilemma involving cost, security and performance. Current solutions force enterprises to choose between expensive, proprietary Large Language Models (LLMs) and low-performing Small Language Models (SLMs). Efforts to improve SLMs often rely on distilling reasoning from large LLMs using unstructured Chain-of-Thought (CoT) traces, a process that remains inherently ambiguous. Instead, we hypothesize that a formal, structured reasoning representation provides a clearer, more reliable teaching signal, as the Text-to-SQL task requires explicit and precise logical steps. To evaluate this hypothesis, we propose Struct-SQL, a novel Knowledge Distillation (KD) framework that trains an SLM to emulate a powerful large LLM. Consequently, we adopt a query execution plan as a formal blueprint to derive this structured reasoning. Our SLM, distilled with structured CoT, achieves an absolute improvement of 8.1% over an unstructured CoT distillation baseline. A detailed error analysis reveals that a key factor in this gain is a marked reduction in syntactic errors. This demonstrates that teaching a model to reason using a structured logical blueprint is beneficial for reliable SQL generation in SLMs.

</details>


### [3] [XLM: A Python package for non-autoregressive language models](https://arxiv.org/abs/2512.17065)
*Dhruvesh Patel,Durga Prasad Maram,Sai Sreenivas Chintha,Benjamin Rozonoyer,Andrew McCallum*

Main category: cs.CL

TL;DR: 提出了XLM Python包，简化非自回归语言模型的实现并提供预训练模型，促进系统比较和复用。


<details>
  <summary>Details</summary>
Motivation: 非自回归语言模型实现分散，缺乏统一训练和推理框架，导致难以系统比较和复用组件。

Method: 开发XLM包，统一非自回归语言模型的数据整理、损失计算和预测逻辑，提升开发效率。

Result: 提供一套小型预训练非自回归语言模型，便于研究社区使用和扩展。

Conclusion: XLM包为非自回归语言模型研究提供了便利工具和资源，促进该领域发展。

Abstract: In recent years, there has been a resurgence of interest in non-autoregressive text generation in the context of general language modeling. Unlike the well-established autoregressive language modeling paradigm, which has a plethora of standard training and inference libraries, implementations of non-autoregressive language modeling have largely been bespoke making it difficult to perform systematic comparisons of different methods. Moreover, each non-autoregressive language model typically requires it own data collation, loss, and prediction logic, making it challenging to reuse common components. In this work, we present the XLM python package, which is designed to make implementing small non-autoregressive language models faster with a secondary goal of providing a suite of small pre-trained models (through a companion xlm-models package) that can be used by the research community. The code is available at https://github.com/dhruvdcoder/xlm-core.

</details>


### [4] [Perturb Your Data: Paraphrase-Guided Training Data Watermarking](https://arxiv.org/abs/2512.17075)
*Pranav Shetty,Mirazul Haque,Petr Babkin,Zhiqiang Ma,Xiaomo Liu,Manuela Veloso*

Main category: cs.CL

TL;DR: 提出了一种名为SPECTRA的训练数据水印检测方法，即使训练数据占比极小也能可靠检测，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型训练涉及大量网络文本，需有效检测训练数据以保护版权和数据许可。

Method: 使用LLM进行文本释义，结合评分模型选择与原文评分匹配的释义，避免分布偏移，通过比较可疑模型与评分模型的token概率检测水印。

Result: SPECTRA在训练数据检测中实现超过九个数量级的p值差距，显著优于所有基线方法。

Conclusion: SPECTRA提供了一种可扩展、在发布前部署的水印技术，能够在大规模LLM训练中存活并有效保护训练数据版权。

Abstract: Training data detection is critical for enforcing copyright and data licensing, as Large Language Models (LLM) are trained on massive text corpora scraped from the internet. We present SPECTRA, a watermarking approach that makes training data reliably detectable even when it comprises less than 0.001% of the training corpus. SPECTRA works by paraphrasing text using an LLM and assigning a score based on how likely each paraphrase is, according to a separate scoring model. A paraphrase is chosen so that its score closely matches that of the original text, to avoid introducing any distribution shifts. To test whether a suspect model has been trained on the watermarked data, we compare its token probabilities against those of the scoring model. We demonstrate that SPECTRA achieves a consistent p-value gap of over nine orders of magnitude when detecting data used for training versus data not used for training, which is greater than all baselines tested. SPECTRA equips data owners with a scalable, deploy-before-release watermark that survives even large-scale LLM training.

</details>


### [5] [When F1 Fails: Granularity-Aware Evaluation for Dialogue Topic Segmentation](https://arxiv.org/abs/2512.17083)
*Michael H. Coen*

Main category: cs.CL

TL;DR: 本文提出了一种新的对话话题分割评估目标，主要考虑边界密度和段落连贯性，针对传统评估在各种数据集中的不足进行了系统性实验，指出了评估中的伪差异问题。


<details>
  <summary>Details</summary>
Motivation: 现有对话话题分割评估主要依赖严格的边界匹配和F1指标，无法有效反映模型实际效果，特别是在多样化数据和现代大模型上下文管理中存在不足。

Method: 引入边界密度和段落连贯性作为主要评估指标，并设计窗口容忍的F1指标(W-F1)，通过跨八个不同类型对话数据集的实证研究，评估多种分割策略，明确分割颗粒度和边界选择的区分。

Result: 实验发现模型表现差异主要源于标注颗粒度不匹配和边界标签稀疏，而非模型本身差异。过度分割现象导致严格F1得分偏低。

Conclusion: 对话话题分割应被理解为选取合适的颗粒度而非单一边界预测。通过将边界评分和边界选择分离，能更合理地评价分割效果。

Abstract: Dialogue topic segmentation supports summarization, retrieval, memory management, and conversational continuity. Despite decades of prior work, evaluation practice in dialogue topic segmentation remains dominated by strict boundary matching and F1-based metrics, even as modern LLM-based conversational systems increasingly rely on segmentation to manage conversation history beyond the model's fixed context window, where unstructured context accumulation degrades efficiency and coherence.
  This paper introduces an evaluation objective for dialogue topic segmentation that treats boundary density and segment coherence as primary criteria, alongside window-tolerant F1 (W-F1). Through extensive cross-dataset empirical evaluation, we show that reported performance differences across dialogue segmentation benchmarks are driven not by model quality, but by annotation granularity mismatches and sparse boundary labels. This indicates that many reported improvements arise from evaluation artifacts rather than improved boundary detection.
  We evaluated multiple, structurally distinct dialogue segmentation strategies across eight dialogue datasets spanning task-oriented, open-domain, meeting-style, and synthetic interactions. Across these settings, we observe high segment coherence combined with extreme oversegmentation relative to sparse labels, producing misleadingly low exact-match F1 scores. We show that topic segmentation is best understood as selecting an appropriate granularity rather than predicting a single correct boundary set. We operationalize this view by explicitly separating boundary scoring from boundary selection.

</details>


### [6] [Data Augmentation Supporting a Conversational Agent Designed for Smoking Cessation Support Groups](https://arxiv.org/abs/2512.17092)
*Salar Hashemitaheri,Ian Harris*

Main category: cs.CL

TL;DR: 本文提出了一种双重数据增强策略，通过生成合成数据和利用真实数据，提升用于吸烟戒断支持组的自动对话代理的意图分类性能，从而提高用户参与度。


<details>
  <summary>Details</summary>
Motivation: 在线戒烟支持组因用户参与度低和污名化问题面临挑战，自动对话代理可提高参与度，但缺少高质量的训练数据。

Method: 文章通过微调开源大模型识别低性能意图，利用GPT生成高质量合成数据，并结合从相关社区抓取的10,000多条高质量真实帖子进行数据增强，最终重训练意图分类器。

Result: 增强后的数据集使意图分类器的F1得分提升了32%，合成数据和真实数据增强对性能贡献相当。

Conclusion: 该方法提供了一个可复制的框架，有效解决了数据稀缺问题，提高了领域内对话代理的性能。

Abstract: Online support groups for smoking cessation are economical and accessible, yet they often face challenges with low user engagement and stigma. The use of an automatic conversational agent would improve engagement by ensuring that all user comments receive a timely response.). We address the challenge of insufficient high-quality data by employing a two-level data augmentation strategy: synthetic data augmentation and real data augmentation. First, we fine-tuned an open source LLM to classify posts from our existing smoking cessation support groups and identify intents with low F1 (precision+recall) scores. Then, for these intents, we generate additional synthetic data using prompt engineering with the GPT model, with an average of 87\% of the generated synthetic posts deemed high quality by human annotators. Overall, the synthetic augmentation process resulted in 43\% of the original posts being selected for augmentation, followed by 140\% synthetic expansion of these posts. Additionally, we scraped more than 10,000 real posts from a related online support context, of which 73\% were validated as good quality by human annotators. Each synthetic or scraped post underwent rigorous validation involving human reviewers to ensure quality and relevance. The validated new data, combined with the original support group posts, formed an augmented dataset used to retrain the intent classifier. Performance evaluation of the retrained model demonstrated a 32\% improvement in F1, confirming the effectiveness of our data augmentation approach. Synthetic and real post augmentation led to similar performance improvements. This study provides a replicable framework for enhancing conversational agent performance in domains where data scarcity is a critical issue.

</details>


### [7] [Enhancing Long Document Long Form Summarisation with Self-Planning](https://arxiv.org/abs/2512.17179)
*Xiaotang Du,Rohit Saxena,Laura Perez-Beltrachini,Pasquale Minervini,Ivan Titov*

Main category: cs.CL

TL;DR: 本文提出了一种基于句子级别内容规划的长文本摘要方法，通过高亮引导生成，提升摘要的可追溯性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 现有长文本摘要方法在保持摘要的事实准确性和内容相关性方面存在挑战，尤其是信息密集的大文档。

Method: 采用自我规划方法识别重要内容，生成基于内容规划的摘要，探索端到端和两阶段两种变体，其中两阶段管线在长文本摘要中表现更优。

Result: 在长文本摘要数据集上，方法显著提升了事实一致性，同时保持摘要的相关性和质量。在GovReport数据集上，ROUGE-L提升4.1点，SummaC得分提升约35%。

Conclusion: 高亮引导的长文本摘要方法有效保存重要细节，提升摘要的准确性和洞察力，适用于多领域的长文本摘要任务。

Abstract: We introduce a novel approach for long context summarisation, highlight-guided generation, that leverages sentence-level information as a content plan to improve the traceability and faithfulness of generated summaries. Our framework applies self-planning methods to identify important content and then generates a summary conditioned on the plan. We explore both an end-to-end and two-stage variants of the approach, finding that the two-stage pipeline performs better on long and information-dense documents. Experiments on long-form summarisation datasets demonstrate that our method consistently improves factual consistency while preserving relevance and overall quality. On GovReport, our best approach has improved ROUGE-L by 4.1 points and achieves about 35% gains in SummaC scores. Qualitative analysis shows that highlight-guided summarisation helps preserve important details, leading to more accurate and insightful summaries across domains.

</details>


### [8] [Mindscape-Aware Retrieval Augmented Generation for Improved Long Context Understanding](https://arxiv.org/abs/2512.17220)
*Yuqing Li,Jiangnan Li,Zheng Lin,Ziyan Zhou,Junjie Wu,Weiping Wang,Jie Zhou,Mo Yu*

Main category: cs.CL

TL;DR: 本文提出了MiA-RAG，一种具备全局语义感知的检索增强生成系统，显著提升了长文本理解与推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前的检索增强生成系统缺乏全局上下文感知，难以处理长文档任务，亟需借鉴人类通过整体语义表征理解复杂文本的能力。

Method: MiA-RAG通过层次化摘要构建全局语义认知结构，利用该全局视角指导检索和生成过程，增强查询嵌入和推理能力。

Result: 在多种长文本和双语基准测试中，MiA-RAG表现优于现有方法，能够更好地将局部细节与全局语境对齐，实现更人性化的检索与推理。

Conclusion: 引入全局语义感知的MiA-RAG有效提升了长文本检索增强生成系统的理解与推理能力，推动了面向复杂长文档任务的技术进步。

Abstract: Humans understand long and complex texts by relying on a holistic semantic representation of the content. This global view helps organize prior knowledge, interpret new information, and integrate evidence dispersed across a document, as revealed by the Mindscape-Aware Capability of humans in psychology. Current Retrieval-Augmented Generation (RAG) systems lack such guidance and therefore struggle with long-context tasks. In this paper, we propose Mindscape-Aware RAG (MiA-RAG), the first approach that equips LLM-based RAG systems with explicit global context awareness. MiA-RAG builds a mindscape through hierarchical summarization and conditions both retrieval and generation on this global semantic representation. This enables the retriever to form enriched query embeddings and the generator to reason over retrieved evidence within a coherent global context. We evaluate MiA-RAG across diverse long-context and bilingual benchmarks for evidence-based understanding and global sense-making. It consistently surpasses baselines, and further analysis shows that it aligns local details with a coherent global representation, enabling more human-like long-context retrieval and reasoning.

</details>


### [9] [Incorporating Error Level Noise Embedding for Improving LLM-Assisted Robustness in Persian Speech Recognition](https://arxiv.org/abs/2512.17247)
*Zahra Rahmani,Hossein Sameti*

Main category: cs.CL

TL;DR: 本文提出了一种结合多假设和噪声感知建模的鲁棒波斯语自动语音识别错误纠正框架，通过引入错误等级噪声（ELN）表示显著降低了环境噪声下的词错误率。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别系统在嘈杂环境下性能显著下降，尤其是低资源语言波斯语，且即使是先进模型如Whisper在不同信噪比下准确率也难以保持。

Method: 生成Whisper-large解码器的5个最佳假设，利用ELN量化假设之间的语义和词级别差异，结合噪声感知的ELN嵌入对大型语言模型（LLaMA-2-7B）进行微调以纠正识别错误。

Result: ELN条件模型在混合噪声测试集上将词错误率从31.10%降低到24.84%，显著优于无ELN的30.79%和原始模型64.58%。

Conclusion: 结合多假设和基于噪声的嵌入表示能够有效提升波斯语自动语音识别在嘈杂环境下的鲁棒性，验证了本文方法的实用性和有效性。

Abstract: Automatic Speech Recognition (ASR) systems suffer significant performance degradation in noisy environments, a challenge that is especially severe for low-resource languages such as Persian. Even state-of-the-art models such as Whisper struggle to maintain accuracy under varying signal-to-noise ratios (SNRs). This study presents a robust noise-sensitive ASR error correction framework that combines multiple hypotheses and noise-aware modeling. Using noisy Persian speech, we generate 5-best hypotheses from a modified Whisper-large decoder. Error Level Noise (ELN) is introduced as a representation that captures semantic- and token-level disagreement across hypotheses, quantifying the linguistic distortions caused by noise. ELN thus provides a direct measure of noise-induced uncertainty, enabling the LLM to reason about the reliability of each hypothesis during correction. Three models are evaluated: (1) a base LLaMA-2-7B model without fine-tuning, (2) a fine-tuned variant trained on text-only hypotheses, and (3) a noise-conditioned model integrating ELN embeddings at both sentence and word levels. Experimental results demonstrate that the ELN-conditioned model achieves substantial reductions in Word Error Rate (WER). Specifically, on the challenging Mixed Noise test set, the proposed Fine-tuned + ELN (Ours) model reduces the WER from a baseline of 31.10\% (Raw Whisper) to 24.84\%, significantly surpassing the Fine-tuned (No ELN) text-only baseline of 30.79\%, whereas the original LLaMA-2-7B model increased the WER to 64.58\%, demonstrating that it is unable to correct Persian errors on its own. This confirms the effectiveness of combining multiple hypotheses with noise-aware embeddings for robust Persian ASR in noisy real-world scenarios.

</details>


### [10] [Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience](https://arxiv.org/abs/2512.17260)
*Jiangjie Chen,Wenxiang Chen,Jiacheng Du,Jinyi Hu,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Wenlei Shi,Zhihong Wang,Mingxuan Wang,Chenrui Wei,Shufa Wei,Huajian Xin,Fan Yang,Weihao Gao,Zheng Yuan,Tianyang Zhan,Zeyu Zheng,Tianxi Zhou,Thomas Hanwen Zhu*

Main category: cs.CL

TL;DR: Seed-Prover 1.5是一款基于大规模强化学习训练的正式定理证明模型，通过高效的测试时扩展流程，提高了正式语言定理证明的能力和效率，在多个难度级别的数学问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的大型语言模型虽然在生成严谨数学证明方面取得进展，但在正式语言（如Lean）中进行定理证明仍然具有挑战性且计算成本高，尤其是针对本科及以上级别的问题。

Method: 提出Seed-Prover 1.5模型，通过大规模智能体强化学习训练，并结合高效的测试时扩展(TTS)流程，使模型在与Lean等工具的交互中不断积累经验，提升定理证明能力，同时利用自然语言证明的最新进展弥合自然语言与正式语言之间的差距。

Result: Seed-Prover 1.5在计算资源更小的情况下，解决了88％的PutnamBench（本科级），80％的Fate-H（研究生级）和33％的Fate-X（博士级）问题，且在9小时内解决了Putnam 2025的11个问题中的12个。

Conclusion: 基于高质量正式反馈驱动的经验学习扩展，Seed-Prover 1.5展示了提升正式数学推理能力的巨大潜力，预示着该方法在未来的应用前景广阔。

Abstract: Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present \textbf{Seed-Prover 1.5}, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves \textbf{88\% of PutnamBench} (undergraduate-level), \textbf{80\% of Fate-H} (graduate-level), and \textbf{33\% of Fate-X} (PhD-level) problems. Notably, using our system, we solved \textbf{11 out of 12 problems} from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.

</details>


### [11] [AutoMetrics: Approximate Human Judgements with Automatically Generated Evaluators](https://arxiv.org/abs/2512.17267)
*Michael J. Ryan,Yanzhe Zhang,Amol Salunkhe,Yi Chu,Di Xu,Diyi Yang*

Main category: cs.CL

TL;DR: AutoMetrics框架在低数据条件下结合已有指标与大模型判定器，实现了用户面对的AI应用评估指标自动合成，显著提升了与人类评价的相关性。


<details>
  <summary>Details</summary>
Motivation: 用户反馈和行为信号在用户面对的AI应用评估中虽为金标准，但数据稀缺且反馈缓慢，影响系统优化效率。

Method: AutoMetrics结合MetricBank中48个指标和基于轻量级人类反馈生成的LLM评判标准，通过回归分析合成指标，提升自动评价的解释性和相关性。

Result: 在五个不同任务中，AutoMetrics相比单一LLM评判器提升了最高33.4%的肯德尔相关性，且所需反馈点数少于100。

Conclusion: AutoMetrics在低数据环境下有效替代昂贵的人工评价，可作为代理奖励使用，并开源工具包促进大模型应用的自适应评估。

Abstract: Evaluating user-facing AI applications remains a central challenge, especially in open-ended domains such as travel planning, clinical note generation, or dialogue. The gold standard is user feedback (e.g., thumbs up/down) or behavioral signals (e.g., retention), but these are often scarce in prototypes and research projects, or too-slow to use for system optimization. We present AutoMetrics, a framework for synthesizing evaluation metrics under low-data constraints. AutoMetrics combines retrieval from MetricBank, a collection of 48 metrics we curate, with automatically generated LLM-as-a-Judge criteria informed by lightweight human feedback. These metrics are composed via regression to maximize correlation with human signal. AutoMetrics takes you from expensive measures to interpretable automatic metrics. Across 5 diverse tasks, AutoMetrics improves Kendall correlation with human ratings by up to 33.4% over LLM-as-a-Judge while requiring fewer than 100 feedback points. We show that AutoMetrics can be used as a proxy reward to equal effect as a verifiable reward. We release the full AutoMetrics toolkit and MetricBank to accelerate adaptive evaluation of LLM applications.

</details>


### [12] [Subjective Question Generation and Answer Evaluation using NLP](https://arxiv.org/abs/2512.17289)
*G. M. Refatul Islam,Safwan Shaheer,Yaseen Nur,Mohammad Rafid Hamid*

Main category: cs.CL

TL;DR: 本论文研究利用自然语言处理技术，自动生成主观题并评估答案，以辅助教育评估和学生自我学习。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于客观题生成，主观题的自动生成与答案评价尚待发展，自动化系统可提高教师效率及学生学习体验。

Method: 改进或构建新的自然语言处理模型，从文本输入中自动生成主观题并进行答案评价。

Result: 提出的系统能够有效生成主观题并对学生答案进行评估，辅助教学和学习。

Conclusion: 自动化的主观题生成和答案评价系统有助于提升教育评估质量和学生自我检测能力，未来有广泛应用潜力。

Abstract: Natural Language Processing (NLP) is one of the most revolutionary technologies today. It uses artificial intelligence to understand human text and spoken words. It is used for text summarization, grammar checking, sentiment analysis, and advanced chatbots and has many more potential use cases. Furthermore, it has also made its mark on the education sector. Much research and advancements have already been conducted on objective question generation; however, automated subjective question generation and answer evaluation are still in progress. An automated system to generate subjective questions and evaluate the answers can help teachers assess student work and enhance the student's learning experience by allowing them to self-assess their understanding after reading an article or a chapter of a book. This research aims to improve current NLP models or make a novel one for automated subjective question generation and answer evaluation from text input.

</details>


### [13] [Governance-Aware Hybrid Fine-Tuning for Multilingual Large Language Models](https://arxiv.org/abs/2512.17344)
*Haomin Qi,Chengbo Huang,Zihan Dai,Yunkai Gao*

Main category: cs.CL

TL;DR: 提出了一种适用于多语言、低资源环境的大型语言模型混合微调框架，结合了梯度对齐低秩更新与结构化正交变换，并引入单位约束以稳定深度优化，同时配合轻量级无标签数据治理，提升模型性能和数据质量控制。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多语言低资源环境下微调时的准确性、校准和跨语言性能不均的问题，同时在计算资源受限的情况下实现高效优化。

Method: 采用梯度对齐低秩更新与层级混合的结构化正交变换，选定子层引入单位约束以稳定优化过程；结合语言识别、重复数据移除和质量过滤等无标签数据治理步骤，确保数据质量。

Result: 在XNLI和FLORES任务中，所提混合方法相较强基线表现出稳定提升，保持方向性平衡并改善概率校准，对轻量正字法变体具备更强鲁棒性，且通过简单数据治理步骤得到进一步加成；训练开销适中，成本质量比优良。

Conclusion: 混合与单位约束的参数高效微调（PEFT）结合实用数据治理，为资源受限环境中多语言模型适配提供了一条稳定且高效的解决路径。

Abstract: We present a governance-aware hybrid fine-tuning framework for multilingual, low-resource adaptation of large language models. The core algorithm combines gradient-aligned low-rank updates with structured orthogonal transformations through layer-wise mixing and introduces unitary constraints in selected sub-layers to stabilize deep optimization. In tandem with lightweight, label-free data governance steps, including language identification, near-duplicate removal, and quality filtering, the framework targets accuracy, calibration, and cross-language parity under tight compute budgets. Across XNLI and FLORES, the hybrid approach delivers consistent gains over strong PEFT baselines while maintaining directional balance and improving probability calibration, as shown in Tables II and III. It is more resilient to lightweight orthographic variants, as shown in Table IV, and benefits additively from simple governance steps, as shown in Table V. Training footprint measurements indicate modest overhead and a favorable cost-quality frontier, as shown in Table VI and Figure 2. Together, these results show that hybrid and unitary PEFT provide a stable and accessible path to resource-efficient multilingual adaptation when paired with practical data governance.

</details>


### [14] [Stakeholder Suite: A Unified AI Framework for Mapping Actors, Topics and Arguments in Public Debates](https://arxiv.org/abs/2512.17347)
*Mohamed Chenene,Jeanne Rouhier,Jean Daniélou,Mihir Sarkar,Elena Cabrio*

Main category: cs.CL

TL;DR: 本文提出了Stakeholder Suite框架，用于映射公共辩论中的利益相关者、话题和论点，结合了多种技术，实现了高精度和实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 公共基础设施和能源项目的辩论涉及复杂的利益相关者和不断变化的叙事，现有媒体智能工具多采用描述性分析，缺乏透明度和深度，难以有效预测争议和指导参与策略。

Method: 开发Stakeholder Suite框架，整合了利益相关者检测、话题建模、论点提取和立场分类，构建统一的分析管道，并在多个能源基础设施项目案例中进行测试。

Result: 该框架在检索准确率和立场判断上表现优异，所提取的论点在75%的试点应用中被判断为相关，有效支持了项目团队识别影响网络、发现争议和依据证据做决策。

Conclusion: Stakeholder Suite不仅在定量指标上表现良好，还在实际操作中证明了其适应性和有效性，是公共辩论分析和决策支持的有力工具。

Abstract: Public debates surrounding infrastructure and energy projects involve complex networks of stakeholders, arguments, and evolving narratives. Understanding these dynamics is crucial for anticipating controversies and informing engagement strategies, yet existing tools in media intelligence largely rely on descriptive analytics with limited transparency. This paper presents Stakeholder Suite, a framework deployed in operational contexts for mapping actors, topics, and arguments within public debates. The system combines actor detection, topic modeling, argument extraction and stance classification in a unified pipeline. Tested on multiple energy infrastructure projects as a case study, the approach delivers fine-grained, source-grounded insights while remaining adaptable to diverse domains. The framework achieves strong retrieval precision and stance accuracy, producing arguments judged relevant in 75% of pilot use cases. Beyond quantitative metrics, the tool has proven effective for operational use: helping project teams visualize networks of influence, identify emerging controversies, and support evidence-based decision-making.

</details>


### [15] [Physics of Language Models: Part 4.1, Architecture Design and the Magic of Canon Layers](https://arxiv.org/abs/2512.17351)
*Zeyuan Allen-Zhu*

Main category: cs.CL

TL;DR: 本文通过设计受控的合成预训练任务，发现并提出了名为Canon层的轻量级架构组件，有效提升语言模型的推理深度和广度。


<details>
  <summary>Details</summary>
Motivation: 在大规模预训练中，语言模型架构差异难以观察，研究受噪声和随机性影响。为此，本文设计合成任务以隔离和评估核心能力。

Method: 引入Canon层，通过加权和邻近tokens的信息流，集成进Transformer及其他序列模型。利用合成任务和实际大规模预训练验证其性能提升。

Result: Canon层提升推理深度（约2倍），增强知识操作等能力，使简单架构达到先进水平，并超过部分线性注意力模型，在多个任务中表现优异。

Conclusion: Canon层为理解和改进语言模型架构提供了一条高效的方法，且此合成框架还能预测未来架构在更优训练环境中的表现，推动推理和层级推断能力的深化。

Abstract: Understanding architectural differences in language models is challenging, especially at academic-scale pretraining (e.g., 1.3B parameters, 100B tokens), where results are often dominated by noise and randomness. To overcome this, we introduce controlled synthetic pretraining tasks that isolate and evaluate core model capabilities. Within this framework, we discover CANON LAYERS: lightweight architectural components -- named after the musical term "canon" -- that promote horizontal information flow across neighboring tokens. Canon layers compute weighted sums of nearby token representations and integrate seamlessly into Transformers, linear attention, state-space models, or any sequence architecture.
  We present 12 key results. This includes how Canon layers enhance reasoning depth (e.g., by $2\times$), reasoning breadth, knowledge manipulation, etc. They lift weak architectures like NoPE to match RoPE, and linear attention to rival SOTA linear models like Mamba2/GDN -- validated both through synthetic tasks and real-world academic-scale pretraining. This synthetic playground offers an economical, principled path to isolate core model capabilities often obscured at academic scales. Equipped with infinite high-quality data, it may even PREDICT how future architectures will behave as training pipelines improve -- e.g., through better data curation or RL-based post-training -- unlocking deeper reasoning and hierarchical inference.

</details>


### [16] [UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models](https://arxiv.org/abs/2512.17385)
*Jiajun Wu,Jian Yang,Wei Zhang,Lin Jing,Yuqing Ma,Ensheng Shi,Yuchi Ma,Zhoujun Li,Xianglong Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种无需外部语料的无监督代码生成框架IPC，通过内部探测大语言模型的知识和置信度模式，实现了无监督训练代码生成模型UCoder，并在多项代码基准测试中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前代码生成大语言模型高度依赖昂贵且难以大规模获取的标注或未标注数据，限制了模型的训练和应用。

Method: IPC框架通过空间探测、测试理解探测、解决方案空间探测及知识整合和强化，从模型内部挖掘知识信号，采用自洽机制和基于表示的质量评估识别可靠代码候选，并训练无监督代码生成模型UCoder。

Result: 在多个代码基准测试中，IPC实现的无监督方法表现出与有监督方法相当的性能，同时显著减少了对标注数据和计算资源的依赖。

Conclusion: 内部模型状态蕴含丰富的代码质量和正确性信号，合理利用这些信号可有效推动无监督代码生成学习，为资源受限环境下训练代码大语言模型提供新思路。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in code generation tasks. However, their effectiveness heavily relies on supervised training with extensive labeled (e.g., question-answering pairs) or unlabeled datasets (e.g., code snippets), which are often expensive and difficult to obtain at scale. To address this limitation, this paper introduces a method IPC, an unsupervised framework that leverages Internal Probing of LLMs for Code generation without any external corpus, even unlabeled code snippets. We introduce the problem space probing, test understanding probing, solution space probing, and knowledge consolidation and reinforcement to probe the internal knowledge and confidence patterns existing in LLMs. Further, IPC identifies reliable code candidates through self-consistency mechanisms and representation-based quality estimation to train UCoder (coder with unsupervised learning). We validate the proposed approach across multiple code benchmarks, demonstrating that unsupervised methods can achieve competitive performance compared to supervised approaches while significantly reducing the dependency on labeled data and computational resources. Analytic experiments reveal that internal model states contain rich signals about code quality and correctness, and that properly harnessing these signals enables effective unsupervised learning for code generation tasks, opening new directions for training code LLMs in resource-constrained scenarios.

</details>


### [17] [Are Vision Language Models Cross-Cultural Theory of Mind Reasoners?](https://arxiv.org/abs/2512.17394)
*Zabir Al Nazi,G M Shahariar,Abrar Hossain,Wei Peng*

Main category: cs.CL

TL;DR: 本文提出了CulturalToM-VQA基准，评估视觉语言模型在不同文化背景下的心智理论（ToM）推理能力，利用多样化文化线索设计5095个问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在社会任务中应用广泛，但跨文化的心智理论推理能力尚未得到充分研究。

Method: 通过人机结合流程，专家先筛选丰富文化内容的图像，视觉语言模型辅助生成包含结构化ToM描述的问题答案对，涵盖六类ToM任务和四个难度等级。

Result: 构建了一个涵盖心理状态归因、错误信念推理、非字面交流等多个心智理论方面的多文化数据集，支持系统评估跨文化视觉心智推理。

Conclusion: CulturalToM-VQA数据集拓宽了心智理论推理的研究视野，有助于推动人工智能在跨文化社会智能任务中的进步。

Abstract: Theory of Mind (ToM) -- the ability to attribute beliefs, desires, and emotions to others -- is fundamental for human social intelligence, yet remains a major challenge for artificial agents. Existing Vision-Language Models (VLMs) are increasingly applied in socially grounded tasks, but their capacity for cross-cultural ToM reasoning is largely unexplored. In this work, we introduce CulturalToM-VQA, a new evaluation benchmark containing 5095 questions designed to probe ToM reasoning across diverse cultural contexts through visual question answering. The dataset captures culturally grounded cues such as rituals, attire, gestures, and interpersonal dynamics, enabling systematic evaluation of ToM reasoning beyond Western-centric benchmarks. Our dataset is built through a VLM-assisted human-in-the-loop pipeline, where human experts first curate culturally rich images across traditions, rituals, and social interactions; a VLM then assist in generating structured ToM-focused scene descriptions, which are refined into question-answer pairs spanning a taxonomy of six ToM tasks and four graded complexity levels. The resulting dataset covers diverse theory of mind facets such as mental state attribution, false belief reasoning, non-literal communication, social norm violations, perspective coordination, and multi-agent reasoning.

</details>


### [18] [Confidence-Credibility Aware Weighted Ensembles of Small LLMs Outperform Large LLMs in Emotion Detection](https://arxiv.org/abs/2512.17630)
*Menna Elgabry,Ali Hamdi*

Main category: cs.CL

TL;DR: 本文提出了一种基于信心加权和可信度感知的情感检测集成框架，利用多样化的小型Transformer模型，显著提升情感分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统集成方法多依赖同质化架构，难以充分利用模型多样性及误差差异，限制了情感识别性能的提升。

Method: 集成采用了BERT、RoBERTa、DistilBERT、DeBERTa、ELECTRA等多样化小型Transformer模型，避免参数收敛以保持误差多样性，通过结合全局可信度（验证集F1）和局部置信度（实例级概率）的双重加权投票机制动态调整模型贡献权重。

Result: 在DAIR-AI数据集上，提出的方法取得了93.5%的宏观F1分数，超越了包括Falcon、Mistral、Qwen、Phi等大型语言模型及其LoRA微调版本的最新基线。

Conclusion: 精心设计的小型Transformer集成不仅参数效率高（总参数595M），且在情感检测等专业NLP任务上性能优于参数规模大得多的大型语言模型，证明了小模型集成的有效性和鲁棒性。

Abstract: This paper introduces a confidence-weighted, credibility-aware ensemble framework for text-based emotion detection, inspired by Condorcet's Jury Theorem (CJT). Unlike conventional ensembles that often rely on homogeneous architectures, our approach combines architecturally diverse small transformer-based large language models (sLLMs) - BERT, RoBERTa, DistilBERT, DeBERTa, and ELECTRA, each fully fine-tuned for emotion classification. To preserve error diversity, we minimize parameter convergence while taking advantage of the unique biases of each model. A dual-weighted voting mechanism integrates both global credibility (validation F1 score) and local confidence (instance-level probability) to dynamically weight model contributions. Experiments on the DAIR-AI dataset demonstrate that our credibility-confidence ensemble achieves a macro F1 score of 93.5 percent, surpassing state-of-the-art benchmarks and significantly outperforming large-scale LLMs, including Falcon, Mistral, Qwen, and Phi, even after task-specific Low-Rank Adaptation (LoRA). With only 595M parameters in total, our small LLMs ensemble proves more parameter-efficient and robust than models up to 7B parameters, establishing that carefully designed ensembles of small, fine-tuned models can outperform much larger LLMs in specialized natural language processing (NLP) tasks such as emotion detection.

</details>


### [19] [Linear Personality Probing and Steering in LLMs: A Big Five Study](https://arxiv.org/abs/2512.17639)
*Michel Frising,Daniel Balcells*

Main category: cs.CL

TL;DR: 该论文研究了是否可以通过与大五人格特质对齐的线性方向来探测和操控大型语言模型的行为。


<details>
  <summary>Details</summary>
Motivation: 当前控制大型语言模型个性行为的方法成本高或不稳定，寻找一种廉价且高效的方法非常重要。

Method: 基于Llama 3.3 70B生成虚构人物及其大五特质评分，通过线性回归学习激活空间中每层的线性方向，并测试这些方向对模型行为的探测和操控能力。

Result: 线性方向能够有效探测人格特质，但在操控模型行为方面效果依赖上下文，在强制选择任务中可靠，开放式生成中效果有限。

Conclusion: 与人格特质对齐的线性方向是探测大型语言模型个性的有效工具，但其操控能力受限于具体任务和上下文环境。

Abstract: Large language models (LLMs) exhibit distinct and consistent personalities that greatly impact trust and engagement. While this means that personality frameworks would be highly valuable tools to characterize and control LLMs' behavior, current approaches remain either costly (post-training) or brittle (prompt engineering). Probing and steering via linear directions has recently emerged as a cheap and efficient alternative. In this paper, we investigate whether linear directions aligned with the Big Five personality traits can be used for probing and steering model behavior. Using Llama 3.3 70B, we generate descriptions of 406 fictional characters and their Big Five trait scores. We then prompt the model with these descriptions and questions from the Alpaca questionnaire, allowing us to sample hidden activations that vary along personality traits in known, quantifiable ways. Using linear regression, we learn a set of per-layer directions in activation space, and test their effectiveness for probing and steering model behavior. Our results suggest that linear directions aligned with trait-scores are effective probes for personality detection, while their steering capabilities strongly depend on context, producing reliable effects in forced-choice tasks but limited influence in open-ended generation or when additional context is present in the prompt.

</details>


### [20] [Simulstream: Open-Source Toolkit for Evaluation and Demonstration of Streaming Speech-to-Text Translation Systems](https://arxiv.org/abs/2512.17648)
*Marco Gaido,Sara Papi,Mauro Cettolo,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文介绍了simulstream，这是首个用于流式语音翻译系统的统一评测与演示开源框架，支持长音频处理，兼容多种解码方法，并提供交互式网页演示界面。


<details>
  <summary>Details</summary>
Motivation: 现有的SimulEval库已停止维护，且不支持输出修正和长音频流处理，缺乏便捷的系统演示方式，限制了流式语音译码系统的评估与比较。

Method: 提出simulstream框架，支持长时音频的流式语音翻译评估，兼容增量解码和重译方法，在同一框架内比较质量和延迟，还提供交互式网页演示界面。

Result: simulstream实现了流式语音翻译系统的统一评估，支持多种译码策略的质量和延迟对比，并方便系统演示。

Conclusion: simulstream作为首个专门用于流式语音翻译的开源框架，解决了现有评测工具的不足，为系统评估、比较及演示提供了有效平台。

Abstract: Streaming Speech-to-Text Translation (StreamST) requires producing translations concurrently with incoming speech, imposing strict latency constraints and demanding models that balance partial-information decision-making with high translation quality. Research efforts on the topic have so far relied on the SimulEval repository, which is no longer maintained and does not support systems that revise their outputs. In addition, it has been designed for simulating the processing of short segments, rather than long-form audio streams, and it does not provide an easy method to showcase systems in a demo. As a solution, we introduce simulstream, the first open-source framework dedicated to unified evaluation and demonstration of StreamST systems. Designed for long-form speech processing, it supports not only incremental decoding approaches, but also re-translation methods, enabling for their comparison within the same framework both in terms of quality and latency. In addition, it also offers an interactive web interface to demo any system built within the tool.

</details>


### [21] [Peeking Into The Future For Contextual Biasing](https://arxiv.org/abs/2512.17657)
*Ramaneswaran Selvakumar,Cindy Tseng,Eesung Kim,Vijendra Raj Apsingekar,Yun Tang*

Main category: cs.CL

TL;DR: 该论文提出了一种基于上下文偏置的端到端语音识别方法，通过多步预测未来多个token，有效提升了罕见或未见命名实体的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 端到端语音识别模型对罕见或未见命名实体识别效果差，影响虚拟助手等下游应用性能。

Method: 在注意力编码器-解码器模型中，利用候选实体列表，通过同时预测多个未来token进行“预见”评分，且无需额外编码器或跨注意力层，简化架构。

Result: 在Librispeech数据集上，提出方法在命名实体词错误率上相比基线模型最高提升50.34%。

Conclusion: 该方法有效利用多token预测实现上下文偏置，显著提升了端到端语音识别中难识别命名实体的性能，同时保持模型架构简洁。

Abstract: While end-to-end (E2E) automatic speech recognition (ASR) models excel at general transcription, they struggle to recognize rare or unseen named entities (e.g., contact names, locations), which are critical for downstream applications like virtual assistants. In this paper, we propose a contextual biasing method for attention based encoder decoder (AED) models using a list of candidate named entities. Instead of predicting only the next token, we simultaneously predict multiple future tokens, enabling the model to "peek into the future" and score potential candidate entities in the entity list. Moreover, our approach leverages the multi-token prediction logits directly without requiring additional entity encoders or cross-attention layers, significantly reducing architectural complexity. Experiments on Librispeech demonstrate that our approach achieves up to 50.34% relative improvement in named entity word error rate compared to the baseline AED model.

</details>


### [22] [Toward Ethical AI Through Bayesian Uncertainty in Neural Question Answering](https://arxiv.org/abs/2512.17677)
*Riccardo Di Sipio*

Main category: cs.CL

TL;DR: 本文探讨了利用贝叶斯推理量化神经网络在问答任务中的不确定性，通过多层感知机和语言模型的实验，展示了贝叶斯方法对置信度评估和选择性预测的贡献。


<details>
  <summary>Details</summary>
Motivation: 在神经网络问答系统中，如何量化预测的不确定性，提高模型的解释性和负责任的部署，是当前的挑战。

Method: 从Iris数据集上的多层感知机开始，利用后验推断评估预测置信度；随后扩展至语言模型，先对冻结头部应用贝叶斯推断，再对LoRA适配的变压器模型进行应用，并在CommonsenseQA基准上评估，比较拉普拉斯近似和最大后验估计（MAP）方法。

Result: 贝叶斯推理方法不仅实现了不确定性校准，支持选择性预测，还使模型能够在置信度低时选择“不知道”回应，从而提升了模型的解释性和责任感。

Conclusion: 贝叶斯方法在神经问答系统中有效量化不确定性，促进模型选择性预测，有助于实现更具解释性和伦理性的系统部署。

Abstract: We explore Bayesian reasoning as a means to quantify uncertainty in neural networks for question answering. Starting with a multilayer perceptron on the Iris dataset, we show how posterior inference conveys confidence in predictions. We then extend this to language models, applying Bayesian inference first to a frozen head and finally to LoRA-adapted transformers, evaluated on the CommonsenseQA benchmark. Rather than aiming for state-of-the-art accuracy, we compare Laplace approximations against maximum a posteriori (MAP) estimates to highlight uncertainty calibration and selective prediction. This allows models to abstain when confidence is low. An ``I don't know'' response not only improves interpretability but also illustrates how Bayesian methods can contribute to more responsible and ethical deployment of neural question-answering systems.

</details>


### [23] [When the Gold Standard isn't Necessarily Standard: Challenges of Evaluating the Translation of User-Generated Content](https://arxiv.org/abs/2512.17738)
*Lydia Nishimwe,Benoît Sagot,Rachel Bawden*

Main category: cs.CL

TL;DR: 本论文分析了用户生成内容(UGC)翻译的挑战，提出了非标准语言现象和翻译操作的分类，强调翻译标准的多样性及其对评估的影响。


<details>
  <summary>Details</summary>
Motivation: UGC语言具有多样的非标准特征，导致其翻译评估复杂，需要明确翻译标准以实现公平评估。

Method: 分析四个UGC数据集的人工翻译指导方针，归纳非标准现象和五种翻译操作，研究大型语言模型对不同翻译指导的响应。

Result: 发现UGC的翻译标准存在差异，翻译评分对指导提示高度敏感，且与数据集指导方针一致时表现更好。

Conclusion: UGC翻译的公平评估需模型和评估指标共同考虑指导方针，呼吁制定明确数据集指南及可控、指导感知的评估框架。

Abstract: User-generated content (UGC) is characterised by frequent use of non-standard language, from spelling errors to expressive choices such as slang, character repetitions, and emojis. This makes evaluating UGC translation particularly challenging: what counts as a "good" translation depends on the level of standardness desired in the output. To explore this, we examine the human translation guidelines of four UGC datasets, and derive a taxonomy of twelve non-standard phenomena and five translation actions (NORMALISE, COPY, TRANSFER, OMIT, CENSOR). Our analysis reveals notable differences in how UGC is treated, resulting in a spectrum of standardness in reference translations. Through a case study on large language models (LLMs), we show that translation scores are highly sensitive to prompts with explicit translation instructions for UGC, and that they improve when these align with the dataset's guidelines. We argue that when preserving UGC style is important, fair evaluation requires both models and metrics to be aware of translation guidelines. Finally, we call for clear guidelines during dataset creation and for the development of controllable, guideline-aware evaluation frameworks for UGC translation.

</details>


### [24] [Affect, Body, Cognition, Demographics, and Emotion: The ABCDE of Text Features for Computational Affective Science](https://arxiv.org/abs/2512.17752)
*Jan Philip Wahle,Krishnapriya Vishnubhotla,Bela Gipp,Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本文介绍了ABCDE数据集，一个包含超过4亿条文本的多领域标注数据集，促进计算情感科学和社会科学的跨学科研究。


<details>
  <summary>Details</summary>
Motivation: 当前情感计算与社会科学研究依赖标注语言数据，但发现、访问和使用这些资源困难，尤其对非计算机科学领域从业者。

Method: 构建了ABCDE数据集，汇集社交媒体、博客、书籍及AI生成文本，并注释情感、身体、认知、人口统计等多种特征。

Result: 提供了一个大规模、多样化且标注丰富的文本数据资源，支持多学科领域的研究需求。

Conclusion: ABCDE数据集降低了跨学科研究中的数据获取和使用障碍，推动计算情感和社会科学的发展。

Abstract: Work in Computational Affective Science and Computational Social Science explores a wide variety of research questions about people, emotions, behavior, and health. Such work often relies on language data that is first labeled with relevant information, such as the use of emotion words or the age of the speaker. Although many resources and algorithms exist to enable this type of labeling, discovering, accessing, and using them remains a substantial impediment, particularly for practitioners outside of computer science. Here, we present the ABCDE dataset (Affect, Body, Cognition, Demographics, and Emotion), a large-scale collection of over 400 million text utterances drawn from social media, blogs, books, and AI-generated sources. The dataset is annotated with a wide range of features relevant to computational affective and social science. ABCDE facilitates interdisciplinary research across numerous fields, including affective science, cognitive science, the digital humanities, sociology, political science, and computational linguistics.

</details>


### [25] [AncientBench: Towards Comprehensive Evaluation on Excavated and Transmitted Chinese Corpora](https://arxiv.org/abs/2512.17756)
*Zhihan Zhou,Daqian Shi,Rui Song,Lida Shi,Xiaolei Diao,Hao Xu*

Main category: cs.CL

TL;DR: 该论文提出了AncientBench评测基准，专门针对出土古文档的古文字理解能力，包含四个维度和十个任务，对现有大语言模型进行测试和分析。


<details>
  <summary>Details</summary>
Motivation: 现有评测多针对现代汉语及传世古文，缺少针对出土古文的理解评测，难以评价大语言模型在古文字理解上的能力。

Method: 设计了AncientBench评测框架，包含象形、发音、含义和上下文理解四个维度，十项任务；邀请考古专家参与实验，提出古文字模型基线，并测试当前顶尖大语言模型。

Result: 实验结果显示大语言模型在古文理解上潜力巨大，但仍与人类存在差距。

Conclusion: AncientBench促进了大语言模型在考古及古汉语领域的发展与应用，有助于推动相关技术进步。

Abstract: Comprehension of ancient texts plays an important role in archaeology and understanding of Chinese history and civilization. The rapid development of large language models needs benchmarks that can evaluate their comprehension of ancient characters. Existing Chinese benchmarks are mostly targeted at modern Chinese and transmitted documents in ancient Chinese, but the part of excavated documents in ancient Chinese is not covered. To meet this need, we propose the AncientBench, which aims to evaluate the comprehension of ancient characters, especially in the scenario of excavated documents. The AncientBench is divided into four dimensions, which correspond to the four competencies of ancient character comprehension: glyph comprehension, pronunciation comprehension, meaning comprehension, and contextual comprehension. The benchmark also contains ten tasks, including radical, phonetic radical, homophone, cloze, translation, and more, providing a comprehensive framework for evaluation. We convened archaeological researchers to conduct experimental evaluations, proposed an ancient model as baseline, and conducted extensive experiments on the currently best-performing large language models. The experimental results reveal the great potential of large language models in ancient textual scenarios as well as the gap with humans. Our research aims to promote the development and application of large language models in the field of archaeology and ancient Chinese language.

</details>


### [26] [Bangla MedER: Multi-BERT Ensemble Approach for the Recognition of Bangla Medical Entity](https://arxiv.org/abs/2512.17769)
*Tanjim Taharat Aurpa,Farzana Akter,Md. Mehedi Hasan,Shakil Ahmed,Shifat Ara Rafiq,Fatema Khan*

Main category: cs.CL

TL;DR: 本文针对孟加拉语医疗实体识别任务，提出了一种多BERT集成模型，在缺乏标注数据的情况下，通过自建高质量数据集，显著提升了模型准确率。


<details>
  <summary>Details</summary>
Motivation: 现有医疗实体识别研究多集中于英语，低资源语言如孟加拉语相关研究不足，且缺乏标注数据，影响了自动化医疗系统的发展。

Method: 比较了多种Transformer模型（BERT、DistilBERT、ELECTRA、RoBERTa），并提出了多BERT集成模型，同时构建了适用于孟加拉语的高质量医疗实体识别数据集。

Result: 多BERT集成模型准确率达到89.58%，较单层BERT提升了11.80%，在多个性能指标上表现优异，体现了模型的鲁棒性和有效性。

Conclusion: 多BERT集成方法有效提升了孟加拉语医疗实体识别性能，为低资源语言医疗自然语言处理的进一步研究奠定了基础。

Abstract: Medical Entity Recognition (MedER) is an essential NLP task for extracting meaningful entities from the medical corpus. Nowadays, MedER-based research outcomes can remarkably contribute to the development of automated systems in the medical sector, ultimately enhancing patient care and outcomes. While extensive research has been conducted on MedER in English, low-resource languages like Bangla remain underexplored. Our work aims to bridge this gap. For Bangla medical entity recognition, this study first examined a number of transformer models, including BERT, DistilBERT, ELECTRA, and RoBERTa. We also propose a novel Multi-BERT Ensemble approach that outperformed all baseline models with the highest accuracy of 89.58%. Notably, it provides an 11.80% accuracy improvement over the single-layer BERT model, demonstrating its effectiveness for this task. A major challenge in MedER for low-resource languages is the lack of annotated datasets. To address this issue, we developed a high-quality dataset tailored for the Bangla MedER task. The dataset was used to evaluate the effectiveness of our model through multiple performance metrics, demonstrating its robustness and applicability. Our findings highlight the potential of Multi-BERT Ensemble models in improving MedER for Bangla and set the foundation for further advancements in low-resource medical NLP.

</details>


### [27] [DEER: A Comprehensive and Reliable Benchmark for Deep-Research Expert Reports](https://arxiv.org/abs/2512.17776)
*Janghoon Han,Heegyu Kim,Changho Lee,Dahm Lee,Min Hyung Park,Hosung Song,Stanley Jungkyu Choi,Moontae Lee,Honglak Lee*

Main category: cs.CL

TL;DR: DEER是一个用于评估专家级深度研究报告的基准，涵盖多领域、多维度评估标准和任务特定的专家指导，并结合整篇报告的事实核查机制。


<details>
  <summary>Details</summary>
Motivation: 现有评估基于大型语言模型生成的专家级报告时，缺乏系统的标准，且只依赖模型判断无法捕捉需专家判断的问题，事实核查范围有限。

Method: 提出了DEER基准，包括50个跨13领域的写报告任务，构建了包含7个维度和25个子维度的细化评估标准，并结合专家指导，设计基于报告全篇的事实检查架构来验证所有陈述。

Result: DEER在与人类专家判断上高度相关，能提供系统优缺点的可解释诊断。

Conclusion: DEER为专家级深度研究报告的质量评估提供了系统全面且细粒度的工具，同时通过报告级事实核查提升了评估的全面性和准确性。

Abstract: As large language models (LLMs) advance, deep research systems can generate expert-level reports via multi-step reasoning and evidence-based synthesis, but evaluating such reports remains challenging. Existing benchmarks often lack systematic criteria for expert reporting, evaluations that rely heavily on LLM judges can fail to capture issues that require expert judgment, and source verification typically covers only a limited subset of explicitly cited statements rather than report-wide factual reliability. We introduce DEER, a benchmark for evaluating expert-level deep research reports. DEER comprises 50 report-writing tasks spanning 13 domains and an expert-grounded evaluation taxonomy (7 dimensions, 25 sub-dimension) operationalized into 130 fine-grained rubric items. DEER further provides task-specific expert guidance to help LLM judges assess expert-level report quality more consistently. Complementing rubric-based assessment, we propose a document-level fact-checking architecture that extracts and verifies all claims across the entire report, including both cited and uncited ones, and quantifies external-evidence quality. DEER correlates closely with human expert judgments and yields interpretable diagnostics of system strengths and weaknesses.

</details>


### [28] [ShareChat: A Dataset of Chatbot Conversations in the Wild](https://arxiv.org/abs/2512.17843)
*Yueru Yan,Tuc Nguyen,Bo Su,Melissa Lieffers,Thai Le*

Main category: cs.CL

TL;DR: 本文介绍了ShareChat，这是一个包含142,808次对话和超过660,000轮交互的大型跨平台语料库，涵盖五个主流LLM平台和101种语言，保留了原生平台的交互细节，提供更长的上下文和更深的交互深度。


<details>
  <summary>Details</summary>
Motivation: 现有公共数据集将大语言模型视为通用文本生成器，忽略了界面设计对用户交互的影响，限制了对真实用户-模型互动的理解。

Method: 收集来自ChatGPT、Claude、Gemini、Perplexity和Grok五大平台的公开共享URL中的对话数据，包含来自2023年4月至2025年10月的多语言对话，保留推理轨迹、来源链接和代码等原生平台特征。

Result: 构建了包含142,808次对话和660,000+轮交互的多语言跨平台数据集，支持用户意图满足度分析、内容生成中的引用行为评估以及使用模式的时间演变分析。

Conclusion: ShareChat数据集为研究真实用户与大语言模型聊天机器人交互提供了宝贵资源，促进了多平台、多语言环境下的用户行为理解。

Abstract: While Large Language Models (LLMs) have evolved into distinct platforms with unique interface designs and capabilities, existing public datasets treat models as generic text generators, stripping away the interface context that actively shapes user interaction. To address this limitation, we present ShareChat, a large-scale, cross-platform corpus comprising 142,808 conversations and over 660,000 turns collected from publicly shared URLs across five major platforms: ChatGPT, Claude, Gemini, Perplexity, and Grok. ShareChat distinguishes itself by preserving native platform affordances often lost in standard logs, including reasoning traces, source links, and code artifacts, while spanning 101 languages over the period from April 2023 to October 2025. Furthermore, ShareChat offers substantially longer context windows and greater interaction depth than prior datasets. We demonstrate the dataset's multifaceted utility through three representative analyses: (1) analyzing conversation completeness to measure user intent satisfaction; (2) evaluating source citation behaviors in content generation; and (3) conducting temporal analysis to track evolving usage patterns. This work provides the community with a vital and timely resource for understanding authentic user-LLM chatbot interactions in the wild.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [29] [SpIDER: Spatially Informed Dense Embedding Retrieval for Software Issue Localization](https://arxiv.org/abs/2512.16956)
*Shravan Chaudhari,Rahul Thomas Jacob,Mononito Goswami,Jiajun Cao,Shihab Rashid,Christian Bock*

Main category: cs.SE

TL;DR: 本文提出了一种名为SpIDER的代码单元检索方法，通过结合大语言模型推理和代码库图结构探索，提升了密集嵌入检索的效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入的代码检索方法虽然优于传统的BM25方法，但往往忽视了代码库的图结构和深入探索，限制了检索效果。

Method: 提出SpIDER方法，结合LLM推理和代码库的图结构辅助上下文信息进行空间感知的密集嵌入检索。

Result: 实验证明SpIDER在多种编程语言下均显著提升了密集检索的性能。

Conclusion: 结合代码库图结构和LLM推理的空间感知密集嵌入检索方法能有效提高代码单元检索的准确性和性能。

Abstract: Retrieving code units (e.g., files, classes, functions) that are semantically relevant to a given user query, bug report, or feature request from large codebases is a fundamental challenge for LLM-based coding agents. Agentic approaches typically employ sparse retrieval methods like BM25 or dense embedding strategies to identify relevant units. While embedding-based approaches can outperform BM25 by large margins, they often lack exploration of the codebase and underutilize its underlying graph structure. To address this, we propose SpIDER (Spatially Informed Dense Embedding Retrieval), an enhanced dense retrieval approach that incorporates LLM-based reasoning over auxiliary context obtained through graph-based exploration of the codebase. Empirical results show that SpIDER consistently improves dense retrieval performance across several programming languages.

</details>


### [30] [Resilient Microservices: A Systematic Review of Recovery Patterns, Strategies, and Evaluation Frameworks](https://arxiv.org/abs/2512.16959)
*Muzeeb Mohammad*

Main category: cs.SE

TL;DR: 该论文系统综述了2014-2025年间关于微服务恢复策略的实证研究，识别出九大恢复主题，并提出了恢复模式分类、评估标准和决策矩阵，旨在支持容错设计和性能优化。


<details>
  <summary>Details</summary>
Motivation: 当前微服务系统易受部分故障、级联超时和恢复不一致影响，现有研究多为描述性缺乏系统化证据和量化分析。

Method: 采用PRISMA方法系统地从IEEE Xplore、ACM和Scopus中筛选2014-2025年间412篇文献，最终选取26篇高质量实证研究进行综述分析。

Result: 识别出包括断路器、带抖动和预算的重试、带补偿的Saga、幂等性、隔舱、自适应背压、可观测性和混沌验证等九个恢复模式主题，提出恢复模式分类、弹性评估评分表和权衡延迟、一致性与成本的决策矩阵。

Conclusion: 该综述整合了分散的恢复研究，形成结构化证据库，促进了微服务系统容错和性能设计的可重复评估及知情决策。

Abstract: Microservice based systems underpin modern distributed computing environments but remain vulnerable to partial failures, cascading timeouts, and inconsistent recovery behavior. Although numerous resilience and recovery patterns have been proposed, existing surveys are largely descriptive and lack systematic evidence synthesis or quantitative rigor. This paper presents a PRISMA aligned systematic literature review of empirical studies on microservice recovery strategies published between 2014 and 2025 across IEEE Xplore, ACM Digital Library, and Scopus. From an initial corpus of 412 records, 26 high quality studies were selected using transparent inclusion, exclusion, and quality assessment criteria. The review identifies nine recurring resilience themes encompassing circuit breakers, retries with jitter and budgets, sagas with compensation, idempotency, bulkheads, adaptive backpressure, observability, and chaos validation. As a data oriented contribution, the paper introduces a Recovery Pattern Taxonomy, a Resilience Evaluation Score checklist for standardized benchmarking, and a constraint aware decision matrix mapping latency, consistency, and cost trade offs to appropriate recovery mechanisms. The results consolidate fragmented resilience research into a structured and analyzable evidence base that supports reproducible evaluation and informed design of fault tolerant and performance aware microservice systems.

</details>


### [31] [Sensor Management System (SMS): Open-source software for FAIR sensor metadata management in Earth system sciences](https://arxiv.org/abs/2512.17280)
*Christof Lorenza,Nils Brinckmann,Jan Bumberger,Marc Hanisch,Tobias Kuhnert,Ulrich Loup,Rubankumar Moorthy,Florian Obsersteiner,David Schäfer,Thomas Schnicke*

Main category: cs.SE

TL;DR: 开发了传感器管理系统（SMS），用于丰富环境观测数据的元数据，实现复杂传感器系统的建模和全生命周期管理。


<details>
  <summary>Details</summary>
Motivation: 环境观测数据可靠结论的得出迫切需要包含时间分辨的全面元数据，如部署变更、配置和维护记录。

Method: SMS通过定义设备、平台、配置、站点等实体，附加制造商、联系方式、测量量等属性，并记录系统操作历史，实现传感器信息的完整管理。

Result: SMS链接后续系统如PID注册和受控词汇，建立用户社区，成为数字生态系统核心，促进传感器元数据的持续、一致和符合FAIR原则的提供。

Conclusion: SMS提供了用户友好且功能丰富的平台，有助于提升环境传感器数据的元数据质量，支持数据的可靠性和长期可用性。

Abstract: Deriving reliable conclusions and insights from environmental observational data urgently requires the enrichment with consistent and comprehensive metadata, including time-resolved context such as changing deployments, configurations, and maintenance actions. We have therefore developed the Sensor Management System (SMS), which provides a user-friendly and feature-rich platform for modeling even the most complex sensor systems and managing all sensor-related information across their life cycle. Each entity is described via well-defined terms like Devices, Platforms and Configurations, as well as Sites that are further enhanced with attributes for, e.g., instrument manufacturers, contact information or measured quantities and complemented by a continuous history of system-related actions. By further linking the SMS to sub-sequent systems and services like PID-registration or controlled vocabularies and establishing a community of end-users, the SMS provides the central element of a digital ecosystem, that fosters a more consistent, sustainable and FAIR provision of sensor-related metadata.

</details>


### [32] [Bridging Natural Language and Formal Specification--Automated Translation of Software Requirements to LTL via Hierarchical Semantics Decomposition Using LLMs](https://arxiv.org/abs/2512.17334)
*Zhi Ma,Cheng Wen,Zhexin Su,Xiao Liang,Cong Tian,Shengchao Qin,Mengfei Yang*

Main category: cs.SE

TL;DR: 该论文提出了一个名为Req2LTL的框架，将自然语言软件需求自动转换为形式化的线性时序逻辑，提高了转换的准确性和格式正确性。


<details>
  <summary>Details</summary>
Motivation: 自动将自然语言软件需求转化为形式化规范是工业安全关键领域推广形式化验证的瓶颈，现有基于规则和学习的方法均存在局限。

Method: 提出了Req2LTL，一个通过层级中间表示OnionL连接自然语言与线性时序逻辑的模块化框架，利用大型语言模型进行语义分解，并结合确定性规则合成，保障语法和语义的准确性。

Result: Req2LTL在真实的航空航天需求上获得了88.4%的语义准确率和100%的语法正确率，显著优于现有方法。

Conclusion: Req2LTL有效解决了自然语言需求转化中语义复杂性和语言模型局限的问题，为工业应用中的形式化验证提供了有力工具。

Abstract: Automating the translation of natural language (NL) software requirements into formal specifications remains a critical challenge in scaling formal verification practices to industrial settings, particularly in safety-critical domains. Existing approaches, both rule-based and learning-based, face significant limitations. While large language models (LLMs) like GPT-4o demonstrate proficiency in semantic extraction, they still encounter difficulties in addressing the complexity, ambiguity, and logical depth of real-world industrial requirements. In this paper, we propose Req2LTL, a modular framework that bridges NL and Linear Temporal Logic (LTL) through a hierarchical intermediate representation called OnionL. Req2LTL leverages LLMs for semantic decomposition and combines them with deterministic rule-based synthesis to ensure both syntactic validity and semantic fidelity. Our comprehensive evaluation demonstrates that Req2LTL achieves 88.4% semantic accuracy and 100% syntactic correctness on real-world aerospace requirements, significantly outperforming existing methods.

</details>


### [33] [What You Trust Is Insecure: Demystifying How Developers (Mis)Use Trusted Execution Environments in Practice](https://arxiv.org/abs/2512.17363)
*Yuqing Niu,Jieke Shi,Ruidong Han,Ye Liu,Chengyan Ma,Yunbo Lyu,David Lo*

Main category: cs.SE

TL;DR: 本文通过对241个使用Intel SGX和ARM TrustZone的开源项目进行大规模实证研究，揭示了TEE的真实应用现状和开发实践，发现物联网安全是主流应用领域，同时存在开发中重新实现加密功能和不安全编码行为的问题。


<details>
  <summary>Details</summary>
Motivation: 当前对TEE（如Intel SGX和ARM TrustZone）在实际开发中的应用状况知之甚少，缺乏对真实项目中TEE使用的系统理解。

Method: 收集和分析了241个GitHub开源项目，结合人工检查和定制静态分析，分类应用领域，研究使用模式和开发实践，特别关注加密功能的实现与安全编码行为。

Result: 发现物联网设备安全占主导地位（30%），AI模型保护快速增长；32.4%项目重新实现加密功能，表明SDK可用性不足；25.3%项目存在硬编码密钥等不安全编程行为，影响安全保障。

Conclusion: 现有TEE SDK的可用性和便携性不足，需要改进以支持开发者；同时应加强TEE开发的安全实践指导，促进可信软件开发。

Abstract: Trusted Execution Environments (TEEs), such as Intel SGX and ARM TrustZone, provide isolated regions of CPU and memory for secure computation and are increasingly used to protect sensitive data and code across diverse application domains. However, little is known about how developers actually use TEEs in practice. This paper presents the first large-scale empirical study of real-world TEE applications. We collected and analyzed 241 open-source projects from GitHub that utilize the two most widely-adopted TEEs, Intel SGX and ARM TrustZone. By combining manual inspection with customized static analysis scripts, we examined their adoption contexts, usage patterns, and development practices across three phases. First, we categorized the projects into 8 application domains and identified trends in TEE adoption over time. We found that the dominant use case is IoT device security (30%), which contrasts sharply with prior academic focus on blockchain and cryptographic systems (7%), while AI model protection (12%) is rapidly emerging as a growing domain. Second, we analyzed how TEEs are integrated into software and observed that 32.4% of the projects reimplement cryptographic functionalities instead of using official SDK APIs, suggesting that current SDKs may have limited usability and portability to meet developers' practical needs. Third, we examined security practices through manual inspection and found that 25.3% (61 of 241) of the projects exhibit insecure coding behaviors when using TEEs, such as hardcoded secrets and missing input validation, which undermine their intended security guarantees. Our findings have important implications for improving the usability of TEE SDKs and supporting developers in trusted software development.

</details>


### [34] [GraphCue for SDN Configuration Code Synthesis](https://arxiv.org/abs/2512.17371)
*Haomin Qi,Fengfei Yu,Chengbo Huang*

Main category: cs.SE

TL;DR: 提出了一种基于拓扑结构的检索和智能代理相结合的自动化SDN配置框架GraphCue，通过图神经网络嵌入和结构化提示有效提升配置通过率。


<details>
  <summary>Details</summary>
Motivation: 现有自动SDN配置方法难以充分利用网络拓扑信息，导致配置效果不理想。

Method: 将每个案例抽象为JSON图，采用三层GCN通过对比学习进行嵌入；通过最近邻检索注入结构化提示限制代码生成；利用验证器执行配置并将失败反馈给代理，实现闭环。

Result: 在628个验证案例中，GraphCue在20次迭代内达到88.2%的通过率，95%的验证循环在9秒内完成。无检索或无结构化提示的消融实验表现较差。

Conclusion: 拓扑感知的检索和基于约束的条件生成是提升自动SDN配置性能的关键因素。

Abstract: We present GraphCue, a topology-grounded retrieval and agent-in-the-loop framework for automated SDN configuration. Each case is abstracted into a JSON graph and embedded using a lightweight three-layer GCN trained with contrastive learning. The nearest validated reference is injected into a structured prompt that constrains code generation, while a verifier closes the loop by executing the candidate configuration and feeding failures back to the agent. On 628 validation cases, GraphCue achieves an 88.2 percent pass rate within 20 iterations and completes 95 percent of verification loops within 9 seconds. Ablation studies without retrieval or structured prompting perform substantially worse, indicating that topology-aware retrieval and constraint-based conditioning are key drivers of performance.

</details>


### [35] [CIFE: Code Instruction-Following Evaluation](https://arxiv.org/abs/2512.17387)
*Sravani Gunnu,Shanmukha Guttula,Hima Patel*

Main category: cs.SE

TL;DR: 本文针对代码生成中的功能正确性及开发者约束遵守问题，提出了一个包含1000个Python任务及多重约束的评测基准，并设计了综合指标C2A评分。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评价多关注功能正确性，缺乏对模型遵守开发者对健壮性、格式及安全性等明确约束的评估，且实际部署要求更高的可信赖性。

Method: 构建包含1000个Python任务和约7个约束（涵盖13类）的数据集，约束通过人工与LLM四阶段流程筛选，保证客观且原子；评测14款模型，提出结合正确性和约束遵守的C2A综合评分。

Result: 模型在部分遵守约束方面表现较好（超过90%），但严格遵守率仅在39%-66%之间，显示存在明显差距。

Conclusion: 代码生成的可信赖性不仅依赖于正确性，还需模型能持续严格遵守开发者意图的各种约束。

Abstract: Large Language Models (LLMs) are increasingly applied to real-world code generation, where functional correctness alone is insufficient for reliable deployment, developers also expect adherence to explicit requirements for robustness, formatting, and security. Existing benchmarks primarily assess correctness through test-case execution, offering limited insight into how reliably models follow such constraints. We introduce a benchmark of 1,000 Python tasks, each paired with an average of 7 developer-specified constraints spanning 13 categories. Constraints are curated through a four-stage human-LLM pipeline to ensure they are atomic, relevant, and objective. We evaluate 14 open- and closed-source models using complementary adherence metrics and propose the C2A Score, a composite measure that jointly captures correctness and constraint compliance. Results reveal a substantial gap between partial and strict satisfaction, while strong models achieve over 90% partial adherence, strict adherence remains between 39-66%. These findings highlight that trustworthy code generation requires not only correctness but also consistent adherence to developer intent.

</details>


### [36] [SWE-Bench++: A Framework for the Scalable Generation of Software Engineering Benchmarks from Open-Source Repositories](https://arxiv.org/abs/2512.17419)
*Lilin Wang,Lucas Ramalho,Alan Celestino,Phuc Anthony Pham,Yu Liu,Umang Kumar Sinha,Andres Portillo,Onassis Osunwa,Gabriel Maduekwe*

Main category: cs.SE

TL;DR: SWE-Bench++是一个自动生成多语言仓库级代码任务的新框架，通过实时GitHub PR数据，比现有Python集中式基准更广泛、更动态。它提供1.1万多实例，支持模型评测和微调提升。


<details>
  <summary>Details</summary>
Motivation: 目前LLM在仓库级软件工程任务的评测依赖人工整理、静态数据集且多集中于Python修复，限制了评测的广度与动态性。

Method: SWE-Bench++自动抓取GitHub开源项目中的PR，覆盖11种语言，包括修复和功能请求，经过程序采集、环境合成、测试提取和质量保障四步，最后对难题转为训练轨迹。

Result: 构建了11,133个实例，涵盖3,971个仓库和11种语言，展示多个主流模型在1782个实例上的性能，最佳模型Pass@10约36%。微调该数据集能提升SWE-bench多语言评测表现。

Conclusion: SWE-Bench++为多语言和动态的仓库级代码生成任务提供了可扩展的基准，助力模型评测和性能提升。

Abstract: Benchmarks like SWE-bench have standardized the evaluation of Large Language Models (LLMs) on repository-level software engineering tasks. However, these efforts remain limited by manual curation, static datasets, and a focus on Python-based bug fixes. We introduce SWE-Bench++, an automated framework that generates repository-level coding tasks from open-source GitHub projects. Unlike synthetic approaches, our pipeline harvests live pull requests to cover both bug fixes and feature requests across 11 languages. SWE-Bench++ turns GitHub pull requests (PRs) into reproducible, execution-based tasks via four stages: programmatic sourcing, environment synthesis, test oracle extraction, and quality assurance. A final hint-guided trajectory synthesis step converts instances that strong models fail on into training trajectories. Our initial benchmark consists of 11,133 instances from 3,971 repositories across 11 languages. On a subset of 1,782 instances of this benchmark, today's strongest models perform as follows: claude-sonnet-4.5 achieves 36.20% pass@10, gpt-5-2025-08-07 34.57%, gemini/gemini-2.5-pro 24.92%, and gpt-4o 16.89%. We further demonstrate the utility of our dataset by showing that fine-tuning on SWE-Bench++ instances yields measurable improvements on the SWE-bench Multilingual benchmark. SWE-Bench++ provides a scalable, multilingual benchmark for evaluating and improving repository-level code generation.

</details>


### [37] [An Investigation on How AI-Generated Responses Affect SoftwareEngineering Surveys](https://arxiv.org/abs/2512.17455)
*Ronnie de Souza Santos,Italo Santos,Maria Teresa Baldassarre,Cleyton Magalhaes,Mairieli Wessel*

Main category: cs.SE

TL;DR: 本研究发现大型语言模型被用于软件工程调查中造假回答，损害数据真实性和研究有效性，提出结合自动和解读方法来保障调查可信性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的进步，参与者可能利用生成工具伪造调查回答，威胁软件工程调查的数据真实性和研究完整性。

Method: 通过2025年在Prolific平台进行的两次调查，收集参与者回答，结合定性模式分析、叙事特征分析和Scribbr AI检测器自动检测，识别疑似AI生成的回答。

Result: 发现49份回答存在结构重复、用语统一且个性化肤浅的模式，表现为合逻辑但内容造假的叙述，损害构念、内部和外部效度。

Conclusion: 数据真实性成为软件工程调查效度的新维度，需结合自动和解释性验证方法、透明报告与社区标准来检测和防止AI生成回答，保障调查的可信度。

Abstract: Survey research is a fundamental empirical method in software engineering, enabling the systematic collection of data on professional practices, perceptions, and experiences. However, recent advances in large language models (LLMs) have introduced new risks to survey integrity, as participants can use generative tools to fabricate or manipulate their responses. This study explores how LLMs are being misused in software engineering surveys and investigates the methodological implications of such behavior for data authenticity, validity, and research integrity. We collected data from two survey deployments conducted in 2025 through the Prolific platform and analyzed the content of participants' answers to identify irregular or falsified responses. A subset of responses suspected of being AI generated was examined through qualitative pattern inspection, narrative characterization, and automated detection using the Scribbr AI Detector. The analysis revealed recurring structural patterns in 49 survey responses indicating synthetic authorship, including repetitive sequencing, uniform phrasing, and superficial personalization. These false narratives mimicked coherent reasoning while concealing fabricated content, undermining construct, internal, and external validity. Our study identifies data authenticity as an emerging dimension of validity in software engineering surveys. We emphasize that reliable evidence now requires combining automated and interpretive verification procedures, transparent reporting, and community standards to detect and prevent AI generated responses, thereby protecting the credibility of surveys in software engineering.

</details>


### [38] [When Data Quality Issues Collide: A Large-Scale Empirical Study of Co-Occurring Data Quality Issues in Software Defect Prediction](https://arxiv.org/abs/2512.17460)
*Emmanuel Charleson Dapaah,Jens Grabowski*

Main category: cs.SE

TL;DR: 本研究首次大规模同时分析软件缺陷预测中的五种数据质量问题，揭示其普遍共现和复杂交互影响，对模型性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常单独研究某一数据质量问题，忽视了实际数据中多种问题共存并相互作用的复杂性，影响软件缺陷预测模型的有效性。

Method: 通过374个数据集和五个分类器，采用可解释增强机器和分层交互分析，量化五种数据质量问题（类别不平衡、类别重叠、无关特征、属性噪声和离群点）的直接与条件影响。

Result: 发现五种问题几乎普遍共现，类别重叠是最有害因素，确定了各问题影响模型效果的阈值；且揭示了离群点在低无关特征时反而提升性能，表现出性能与鲁棒性的权衡。

Conclusion: 本研究填补了软件缺陷预测数据质量研究的空白，提出了全面、数据感知的分析框架，促进理解质量问题如何共同影响实际模型性能。

Abstract: Software Defect Prediction (SDP) models are central to proactive software quality assurance, yet their effectiveness is often constrained by the quality of available datasets. Prior research has typically examined single issues such as class imbalance or feature irrelevance in isolation, overlooking that real-world data problems frequently co-occur and interact. This study presents, to our knowledge, the first large-scale empirical analysis in SDP that simultaneously examines five co-occurring data quality issues (class imbalance, class overlap, irrelevant features, attribute noise, and outliers) across 374 datasets and five classifiers. We employ Explainable Boosting Machines together with stratified interaction analysis to quantify both direct and conditional effects under default hyperparameter settings, reflecting practical baseline usage.
  Our results show that co-occurrence is nearly universal: even the least frequent issue (attribute noise) appears alongside others in more than 93% of datasets. Irrelevant features and imbalance are nearly ubiquitous, while class overlap is the most consistently harmful issue. We identify stable tipping points around 0.20 for class overlap, 0.65-0.70 for imbalance, and 0.94 for irrelevance, beyond which most models begin to degrade. We also uncover counterintuitive patterns, such as outliers improving performance when irrelevant features are low, underscoring the importance of context-aware evaluation. Finally, we expose a performance-robustness trade-off: no single learner dominates under all conditions.
  By jointly analyzing prevalence, co-occurrence, thresholds, and conditional effects, our study directly addresses a persistent gap in SDP research. Hence, moving beyond isolated analyses to provide a holistic, data-aware understanding of how quality issues shape model performance in real-world settings.

</details>


### [39] [Why Is My Transaction Risky? Understanding Smart Contract Semantics and Interactions in the NFT Ecosystem](https://arxiv.org/abs/2512.17500)
*Yujing Chen,Xuanming Liu,Zhiyuan Wan,Zuobin Wang,David Lo,Difan Xie,Xiaohu Yang*

Main category: cs.SE

TL;DR: 本研究通过大规模实证分析以太坊上的NFT生态系统，揭示智能合约语义和交互特点，区分正常与诈骗交易模式，为区块链风险缓解提供参考。


<details>
  <summary>Details</summary>
Motivation: 现有研究关注NFT生态系统的安全挑战和诈骗行为，但缺乏对智能合约语义与交互在诈骗风险表现中的理解。

Method: 利用接近1亿条以太坊交易数据，分析NFT生态系统中智能合约的语义多样性及其交互模式，比较正常与诈骗代币的字节码差异和交互特征。

Result: 发现NFT智能合约语义有限，主要为代理、代币和DeFi合约；交易中智能合约交互频繁且多样；诈骗代币字节码趋同，交互模式与正常交易存在差异。

Conclusion: 通过揭示智能合约语义和交互与诈骗风险的关系，提出区块链生态风险缓解建议，并指明未来研究方向。

Abstract: The NFT ecosystem represents an interconnected, decentralized environment that encompasses the creation, distribution, and trading of Non-Fungible Tokens (NFTs), where key actors, such as marketplaces, sellers, and buyers, utilize smart contracts to facilitate secure, transparent, and trustless transactions. Scam tokens are deliberately created to mislead users and facilitate financial exploitation, posing significant risks in the NFT ecosystem. Prior work has explored the NFT ecosystem from various perspectives, including security challenges, actor behaviors, and risks from scams and wash trading, leaving a gap in understanding the semantics and interactions of smart contracts during transactions, and how the risks associated with scam tokens manifest in relation to the semantics and interactions of contracts. To bridge this gap, we conducted a large-scale empirical study on smart contract semantics and interactions in the NFT ecosystem, using a curated dataset of nearly 100 million transactions across 20 million blocks on Ethereum. We observe a limited semantic diversity among smart contracts in the NFT ecosystem, dominated by proxy, token, and DeFi contracts. Marketplace and proxy registry contracts are the most frequently involved in smart contract interactions during transactions, engaging with a broad spectrum of contracts in the ecosystem. Token contracts exhibit bytecode-level diversity, whereas scam tokens exhibit bytecode convergence. Certain interaction patterns between smart contracts are common to both risky and non-risky transactions, while others are predominantly associated with risky transactions. Based on our findings, we provide recommendations to mitigate risks in the blockchain ecosystem, and outline future research directions.

</details>


### [40] [SGCR: A Specification-Grounded Framework for Trustworthy LLM Code Review](https://arxiv.org/abs/2512.17540)
*Kai Wang,Bingcheng Mao,Shuai Jia,Yujie Ding,Dongming Han,Tianyi Ma,Bin Cao*

Main category: cs.SE

TL;DR: 本文提出了基于规范的代码审查框架SGCR，结合明确规则和启发式方法，提高了大语言模型在代码审查中的可靠性和实用性，在工业环境中开发者采纳率提升至42%。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在代码审查中虽有潜力，但存在可靠性不足、缺乏上下文感知和控制性差的问题，影响实际应用。

Method: 提出了SGCR框架，采用双路径架构：显式路径确保遵守人类撰写的规范规则，隐式路径启发式发现规则外的问题并验证。

Result: 在HiThink Research工业环境中部署，SGCR的建议采纳率达42%，较基线LLM的22%提升90.9%。

Conclusion: 基于规范的代码审查框架有效弥合了大语言模型生成能力与软件工程中严格可靠性需求之间的差距，提升了代码审查的实用价值。

Abstract: Automating code review with Large Language Models (LLMs) shows immense promise, yet practical adoption is hampered by their lack of reliability, context-awareness, and control. To address this, we propose Specification-Grounded Code Review (SGCR), a framework that grounds LLMs in human-authored specifications to produce trustworthy and relevant feedback. SGCR features a novel dual-pathway architecture: an explicit path ensures deterministic compliance with predefined rules derived from these specifications, while an implicit path heuristically discovers and verifies issues beyond those rules. Deployed in a live industrial environment at HiThink Research, SGCR's suggestions achieved a 42% developer adoption rate-a 90.9% relative improvement over a baseline LLM (22%). Our work demonstrates that specification-grounding is a powerful paradigm for bridging the gap between the generative power of LLMs and the rigorous reliability demands of software engineering.

</details>


### [41] [A Practical Solution to Systematically Monitor Inconsistencies in SBOM-based Vulnerability Scanners](https://arxiv.org/abs/2512.17710)
*Martin Rosso,Muhammad Asad Jahangir Jaffar,Alessandro Brighente,Mauro Conti*

Main category: cs.SE

TL;DR: 本文介绍了一种名为SVS-TEST的方法和工具，用于评估基于SBOM的漏洞扫描（SVS）工具的能力和成熟度，发现多个SVS工具在有效输入时会静默失败，带来安全隐患。


<details>
  <summary>Details</summary>
Motivation: 随着SBOM的普及，SVS工具被广泛应用于自动漏洞识别，但存在不一致和静默失败的问题，影响扫描的准确性和可靠性。

Method: 提出SVS-TEST方法，利用16个精心设计的SBOM和真实数据对七个SVS工具进行测试和评估，分析其能力、成熟度和失败条件。

Result: 发现不同SVS工具在可靠性和错误处理上存在较大差异，多数工具对有效SBOM输入静默失败，造成错误的安全信号。

Conclusion: 强调了该研究对研究者和行业实践者的启示，建议利用SVS-TEST工具监测和提升SVS工具的能力与成熟度，以避免安全隐患。

Abstract: Software Bill of Materials (SBOM) provides new opportunities for automated vulnerability identification in software products. While the industry is adopting SBOM-based Vulnerability Scanning (SVS) to identify vulnerabilities, we increasingly observe inconsistencies and unexpected behavior, that result in false negatives and silent failures. In this work, we present the background necessary to understand the underlying complexity of SVS and introduce SVS-TEST, a method and tool to analyze the capability, maturity, and failure conditions of SVS-tools in real-world scenarios. We showcase the utility of SVS-TEST in a case study evaluating seven real-world SVS-tools using 16 precisely crafted SBOMs and their respective ground truth. Our results unveil significant differences in the reliability and error handling of SVS-tools; multiple SVS-tools silently fail on valid input SBOMs, creating a false sense of security. We conclude our work by highlighting implications for researchers and practitioners, including how organizations and developers of SVS-tools can utilize SVS-TEST to monitor SVS capability and maturity. All results and research artifacts are made publicly available and all findings were disclosed to the SVS-tool developers ahead of time.

</details>


### [42] [LLM-based Behaviour Driven Development for Hardware Design](https://arxiv.org/abs/2512.17814)
*Rolf Drechsler,Qian Liu*

Main category: cs.SE

TL;DR: 本文研究了利用大型语言模型(LLMs)技术支持硬件设计中的行为驱动开发(BDD)，以自动化从文本规格中提取行为场景，降低手动工作量。


<details>
  <summary>Details</summary>
Motivation: 硬件设计中的测试和验证随着系统规模的扩大变得复杂，传统BDD在硬件领域应用有限，主要因从文本规格中精确推导出行为场景需要大量手工工作。

Method: 通过引入LLM技术，尝试自动化生成硬件设计中的行为场景，支持BDD流程。

Result: 展现了LLM在硬件BDD中的潜力，能有效辅助自动化场景提取，提高BDD在硬件设计中的实用性。

Conclusion: 利用LLMs技术支持硬件BDD是可行且有前景的，能够缓解手工提取行为场景的难题，促进BDD在硬件设计领域的推广应用。

Abstract: Test and verification are essential activities in hardware and system design, but their complexity grows significantly with increasing system sizes. While Behavior Driven Development (BDD) has proven effective in software engineering, it is not yet well established in hardware design, and its practical use remains limited. One contributing factor is the manual effort required to derive precise behavioral scenarios from textual specifications.
  Recent advances in Large Language Models (LLMs) offer new opportunities to automate this step. In this paper, we investigate the use of LLM-based techniques to support BDD in the context of hardware design.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [43] [On the Role of Contextual Information and Ego States in LLM Agent Behavior for Transactional Analysis Dialogues](https://arxiv.org/abs/2512.17060)
*Monika Zamojska,Jarosław A. Chudziak*

Main category: cs.MA

TL;DR: 本文提出了一种基于交易分析理论的多智能体系统，通过将智能体分为父母、自我和儿童三种自我状态，并结合信息检索机制，提升智能体的心理深度和行为一致性，实现更真实的人类行为模拟。


<details>
  <summary>Details</summary>
Motivation: 当前的基于大语言模型的智能体缺乏心理深度和一致性，难以准确模拟人类复杂的思维模式和行为动机。

Method: 利用交易分析理论，将智能体划分为父母、自我、儿童三个自我状态，每个状态作为独立的知识结构，结合向量存储的上下文信息检索机制，丰富智能体的响应过程。

Result: 在模拟对话场景下，通过消融实验验证了信息检索机制对增强智能体表现的效果，结果显示该系统能够更好地模拟人类的心理动态。

Conclusion: 该工作融合了交易分析理论与上下文信息检索，提出了一种增强心理真实性的多智能体架构，为基于大语言模型的智能体行为模拟提供了新的研究方向。

Abstract: LLM-powered agents are now used in many areas, from customer support to education, and there is increasing interest in their ability to act more like humans. This includes fields such as social, political, and psychological research, where the goal is to model group dynamics and social behavior. However, current LLM agents often lack the psychological depth and consistency needed to capture the real patterns of human thinking. They usually provide direct or statistically likely answers, but they miss the deeper goals, emotional conflicts, and motivations that drive real human interactions. This paper proposes a Multi-Agent System (MAS) inspired by Transactional Analysis (TA) theory. In the proposed system, each agent is divided into three ego states - Parent, Adult, and Child. The ego states are treated as separate knowledge structures with their own perspectives and reasoning styles. To enrich their response process, they have access to an information retrieval mechanism that allows them to retrieve relevant contextual information from their vector stores. This architecture is evaluated through ablation tests in a simulated dialogue scenario, comparing agents with and without information retrieval. The results are promising and open up new directions for exploring how psychologically grounded structures can enrich agent behavior. The contribution is an agent architecture that integrates Transactional Analysis theory with contextual information retrieval to enhance the realism of LLM-based multi-agent simulations.

</details>


### [44] [MAPPO-LCR: Multi-Agent Policy Optimization with Local Cooperation Reward in Spatial Public Goods Games](https://arxiv.org/abs/2512.17187)
*Zhaoqilin Yang,Axin Xiang,Kedi Yang,Tianjun Liu,Youliang Tian*

Main category: cs.MA

TL;DR: 本文首次将多智能体近端策略优化（MAPPO）引入空间公共物品博弈，通过集中式评论家解决奖励耦合问题，提出局部合作奖励（LCR）方法，实现了稳定合作和可靠收敛。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖进化更新规则或基于价值的强化学习，难以有效处理大规模交互中策略耦合和非平稳性问题。

Method: 引入MAPPO，利用集中式评论家评估联合策略配置，并设计局部合作奖励机制以增强邻域合作信号，保持去中心化执行同时实现训练中的群体价值估计。

Result: 仿真表明MAPPO-LCR在不同增强因子下均能稳定促进合作并可靠收敛；统计分析显示MAPPO在空间公共物品博弈中优于PPO。

Conclusion: 通过集中式评论家和局部合作奖励机制，MAPPO有效克服了传统方法不足，实现了空间公共物品博弈中的稳定合作，展现出显著学习优势。

Abstract: Spatial public goods games model collective dilemmas where individual payoffs depend on population-level strategy configurations. Most existing studies rely on evolutionary update rules or value-based reinforcement learning methods. These approaches struggle to represent payoff coupling and non-stationarity in large interacting populations. This work introduces Multi-Agent Proximal Policy Optimization (MAPPO) into spatial public goods games for the first time. In these games, individual returns are intrinsically coupled through overlapping group interactions. Proximal Policy Optimization (PPO) treats agents as independent learners and ignores this coupling during value estimation. MAPPO addresses this limitation through a centralized critic that evaluates joint strategy configurations. To study neighborhood-level cooperation signals under this framework, we propose MAPPO with Local Cooperation Reward, termed MAPPO-LCR. The local cooperation reward aligns policy updates with surrounding cooperative density without altering the original game structure. MAPPO-LCR preserves decentralized execution while enabling population-level value estimation during training. Extensive simulations demonstrate stable cooperation emergence and reliable convergence across enhancement factors. Statistical analyses further confirm the learning advantage of MAPPO over PPO in spatial public goods games.

</details>


### [45] [Verifiability-First Agents: Provable Observability and Lightweight Audit Agents for Controlling Autonomous LLM Systems](https://arxiv.org/abs/2512.17259)
*Abhivansh Gupta*

Main category: cs.MA

TL;DR: 本文提出了一种Verifiability-First架构，通过密码学和符号方法的实时证明、轻量级审计代理以及挑战-响应认证协议，提高基于大语言模型的智能体的可控性和审计性。引入了OPERA基准套件，评价发现偏差的可检测性、检测时间和机制的对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体变得更加自主和多模态，确保其行为可控、可审计且忠实于部署者意图变得至关重要，现有仅关注偏差概率的指标不足以满足需求。

Method: 提出Verifiability-First架构，集成运行时行为证明、内嵌审计代理进行意图与行为验证、采用挑战-响应认证协议；设计OPERA基准及评估协议，从可检测性、检测时效及对抗鲁棒性评估偏差检测能力。

Result: 验证了该架构能有效提升偏差行为的检测速度和可靠性，OPERA基准能够度量在隐蔽攻击策略下的检测时间及机制对对抗注入的抵御能力。

Conclusion: 该方法将评估重点从偏差发生概率转移到偏差的快速可靠检测与修正，增强了大语言模型智能体部署的安全性和可信度。

Abstract: As LLM-based agents grow more autonomous and multi-modal, ensuring they remain controllable, auditable, and faithful to deployer intent becomes critical. Prior benchmarks measured the propensity for misaligned behavior and showed that agent personalities and tool access significantly influence misalignment. Building on these insights, we propose a Verifiability-First architecture that (1) integrates run-time attestations of agent actions using cryptographic and symbolic methods, (2) embeds lightweight Audit Agents that continuously verify intent versus behavior using constrained reasoning, and (3) enforces challenge-response attestation protocols for high-risk operations. We introduce OPERA (Observability, Provable Execution, Red-team, Attestation), a benchmark suite and evaluation protocol designed to measure (i) detectability of misalignment, (ii) time to detection under stealthy strategies, and (iii) resilience of verifiability mechanisms to adversarial prompt and persona injection. Our approach shifts the evaluation focus from how likely misalignment is to how quickly and reliably misalignment can be detected and remediated.

</details>
