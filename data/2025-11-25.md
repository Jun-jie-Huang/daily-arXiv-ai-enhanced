<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 77]
- [cs.SE](#cs.SE) [Total: 33]
- [cs.MA](#cs.MA) [Total: 13]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering](https://arxiv.org/abs/2511.17559)
*Gyubok Lee,Woosog Chay,Edward Choi*

Main category: cs.CL

TL;DR: 该论文提出了SCARE，一个用于评估电子健康记录（EHR）问答系统中后验安全检测机制的统一基准。


<details>
  <summary>Details</summary>
Motivation: 当前文本转SQL模型在临床环境下部署面临错误SQL查询风险，导致临床决策错误，缺乏统一的后验安全验证基准。

Method: 构建了包含4200组问题、候选SQL查询及预期输出的基准集，涵盖多种数据库和七种文本转SQL模型，对候选SQL进行分类、验证及纠错评估。

Result: 通过SCARE基准测试多种方法，发现问题可答性分类与SQL错误纠正之间存在关键权衡，并指出现有方法的不足。

Conclusion: 该研究揭示了问题可答性分类与SQL错误修正之间的关键权衡，强调了安全部署EHR问答系统时的挑战，并为未来研究指明方向。

Abstract: Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.

</details>


### [2] [$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving](https://arxiv.org/abs/2511.17560)
*Yuechi Zhou,Yi Su,Jianxin Zhang,Juntao Li,Qingrong Xia,Zhefeng Wang,Xinyu Duan,Baoxing Huai*

Main category: cs.CL

TL;DR: 本文针对大型语言模型处理长文本序列时的解码延迟和内存开销问题，提出了注意力感知的准确KV缓存融合算法$A^3$。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型具备处理长文本的能力，但解码过程的延时和内存占用大，限制了实际应用。现有的KV缓存复用方法效果不佳，存在重要上下文信息未能正确更新的问题。

Method: 提出$A^3$算法，通过分析上下文中与问题最相关的文本块，预计算并精准融合对应的KV缓存，避免了与上下文不匹配导致的性能下降。

Result: 实验证明，$A^3$在多个基准测试和不同大型语言模型上表现优异，超越四个对比基线，且将首字令牌生成时间缩短了一半。

Conclusion: $A^3$算法通过预计算并选择性融合与问题相关的KV缓存，有效提升了任务性能，同时将生成首字令牌时间减少了2倍。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\textbf{A}$ttention-$\textbf{A}$ware $\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\times$.

</details>


### [3] [LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models](https://arxiv.org/abs/2511.17561)
*Huimin Ren,Yan Liang,Baiqiao Su,Chaobo Sun,Hengtong Lu,Kaike Zhang,Chen Wei*

Main category: cs.CL

TL;DR: 提出LexInstructEval，一种基于形式语法的细粒度词汇指令跟随评测框架，解决了现有评价方法的主观性和表达能力不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前评价大语言模型（LLMs）精细词汇指令跟随能力的方法存在主观性高、成本大或评判不可靠的问题，且程序化基准缺乏表达复杂细节的能力。

Method: 提出LexInstructEval基于形式化、规则化的语法，将复杂指令拆解为<Procedure, Relation, Value>三元组，通过多阶段人机交互生成多样化数据集，并使用透明程序化引擎进行客观验证。

Result: 构建了一个新的细粒度词汇指令跟随基准数据集和评价框架，并开源数据和工具以促进对LLMs可控性和可靠性的研究。

Conclusion: LexInstructEval框架有效解决了现有评价方法的缺陷，提升了对LLMs精细词汇指令执行能力的客观评价能力。

Abstract: The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.

</details>


### [4] [ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector](https://arxiv.org/abs/2511.17562)
*Wei Tian,YuhaoZhou*

Main category: cs.CL

TL;DR: 提出一种基于Qwen3-4B的中文拼写和语法错误统一纠正模型，实现了多个数据集上的领先性能。


<details>
  <summary>Details</summary>
Motivation: 提升中文文本纠正的准确性，实现拼写和语法错误的统一纠正。

Method: 基于Qwen3-4B构建统一的中文拼写和语法错误纠正模型ChineseErrorCorrector3-4B。

Result: 模型在多个权威基准数据集（如SIGHAN-2015、EC-LAW、MCSC、NaCGEC）上，拼写和语法错误纠正任务的F1和F0.5指标均显著优于现有公开模型，排名第一。

Conclusion: ChineseErrorCorrector3-4B在中文拼写和语法错误纠正领域表现优异，显著超越现有模型，具有广泛的应用前景。

Abstract: This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.

</details>


### [5] [Generative Caching for Structurally Similar Prompts and Responses](https://arxiv.org/abs/2511.17565)
*Sarthak Chakraborty,Suman Nath,Xuchao Zhang,Chetan Bansal,Indranil Gupta*

Main category: cs.CL

TL;DR: 针对结构相似提示的缓存难题，\ourmethod{}通过生成式方式提升缓存命中率和响应准确性，有效加速任务执行。


<details>
  <summary>Details</summary>
Motivation: 频繁复用结构相似但存在细微差别的提示，在标准精确匹配失败且语义缓存可能忽略关键差异产生错误响应的情况下，如何有效缓存并提升响应效率。

Method: 提出了一种生成式缓存方法\ourmethod{}，它通过识别结构相似提示中的可复用响应模式，合成定制化输出，解决了传统精确匹配和语义缓存面临的挑战。

Result: \ourmethod{}实现了83%的缓存命中率，在无提示重复的数据集上错误命中极少；在智能代理工作流中，命中率提升约20%，端到端执行时延减少约34%。

Conclusion: \ourmethod{}有效解决了结构相似提示缓存的问题，提升了缓存效率和响应质量，减少了任务执行延迟。适用于频繁复用提示的多场景大语言模型任务。

Abstract: Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \ourmethod{} achieves 83\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\sim$20\% and reduces end-to-end execution latency by $\sim$34\% compared to standard prompt matching.

</details>


### [6] [Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs](https://arxiv.org/abs/2511.17572)
*Patrick Gerard,Aiden Chang,Svitlana Volkova*

Main category: cs.CL

TL;DR: 本文提出了一个框架，通过有针对性地删除事件知识，检验大语言模型在缺乏事实知识情况下是否仍然表现出与特定社区相似的行为模式。


<details>
  <summary>Details</summary>
Motivation: 探究当大型语言模型对特定在线社区进行对齐时，其表现出的行为模式是简单回忆训练数据，还是能泛化体现该社区在面对不确定性时的态度和反应。

Method: 通过有针对性地删除事件知识，并使用多个探针验证，再评估模型在知识缺失情况下是否仍产生社区的自然反应模式。

Result: 在俄乌军事话语和美国党派推特数据实验中，事实信息被大量删除后，校准模型依然维持社区特定的处理不确定性行为，验证了其行为的结构性和泛化能力。

Conclusion: 经过事实知识的积极删除后，校准的大语言模型仍保持稳定的、社区特定的应对不确定性的行为模式，表明对齐过程编码了结构化、可推广的行为，而非简单的模式回忆。

Abstract: When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.

</details>


### [7] [Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models](https://arxiv.org/abs/2511.17575)
*Vladimir Berman*

Main category: cs.CL

TL;DR: 本文提出一个简单的随机文本模型，通过纯数学推导解释词长分布、词汇增长及Zipf频率规律，指出复杂语言现象中部分统计特征可由随机组合和分词机制自然产生。


<details>
  <summary>Details</summary>
Motivation: 为了寻找一个结构上扎实的空模型，解释自然语言和大型语言模型中的单词及词元统计规律，探究是否无需复杂语言机制即可产生Zipf式的频率分布。

Method: 构建一个字母和空格符号的独立抽样序列模型，将单词定义为非空格符号的最大连续块，利用几何分布、coupon-collector理论及概率计算推导结构性结论，并结合字串数量增长和概率衰减分析排序频率定律。

Result: 推导出单词长度服从几何分布，单词数量有明确封闭表达式，发现存在关键单词长度决定单词出现次数的转折点，并证明了在模型中出现了类似Zipf的幂律频率分布，其指数可由字母集大小和空格概率明确确定。

Conclusion: 本文通过一个简化的非语言学文本模型，系统地推导了单词长度分布、词汇增长、关键单词长度和排序频率结构的统一关系，揭示了Zipf定律式的频率分布可以由纯粹的组合学和分词机制产生，无需语言学优化或组织。

Abstract: We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.
  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.

</details>


### [8] [Computational frame analysis revisited: On LLMs for studying news coverage](https://arxiv.org/abs/2511.17746)
*Sharaj Kunjar,Alyssa Hasegawa Smith,Tyler R Mckenzie,Rushali Mohbe,Samuel V Scarpino,Brooke Foucault Welles*

Main category: cs.CL

TL;DR: 本文通过分析2022年美国Mpox疫情新闻，发现生成式大语言模型在媒体框架识别中不及人工编码，建议采用多方法结合的分析策略。


<details>
  <summary>Details</summary>
Motivation: 评估生成式大语言模型在媒体框架识别中的有效性，比较其与传统方法及人工编码的优劣。

Method: 通过构建一个新的金标准数据集，对比生成式LLMs与传统的词袋模型、编码器型变换器以及人工编码，对2022年美国Mpox疫情六个月的新闻报道进行系统评估。

Result: 生成式LLMs在某些应用中有潜力，但整体性能低于人工编码者和部分较小语言模型。模型适用性依赖具体任务，需要结合多种方法实现最优效果。

Conclusion: 生成式大语言模型（LLMs）在框架分析中表现存在局限性，通常不如人工编码者和某些较小的语言模型。需要人类验证以确定合适的模型选择。

Abstract: Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.

</details>


### [9] [PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese](https://arxiv.org/abs/2511.17808)
*Thales Sales Almeida,Rodrigo Nogueira,Hélio Pedrini*

Main category: cs.CL

TL;DR: 本文首次对葡萄牙语的大型语言模型进行了全面评估，利用PoETa v2基准测试套件，涵盖40多个任务，评测20多种模型，分析了计算投入和语言特定适应对性能的影响，并比较了葡萄牙语与英语任务的表现差异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在不同语言及文化背景下表现差异显著，葡萄牙语缺乏系统的评估，迫切需要构建综合性的评测体系。

Method: 引入PoETa v2基准测试套件，包含40多个葡萄牙语任务，评测20多个涵盖不同训练规模和计算资源的模型。

Result: 通过PoETa v2对多模型的评测揭示了计算投入和语言适配对葡萄牙语模型性能的重要影响，并分析了与英语任务表现的差距。

Conclusion: 葡萄牙语的语言模型性能受计算资源和语言特定调整的影响明显，PoETa v2为葡萄牙语语言模型的研究和评估奠定了基础。

Abstract: Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.

</details>


### [10] [Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation](https://arxiv.org/abs/2511.17813)
*Scott Merrill,Shashank Srivastava*

Main category: cs.CL

TL;DR: 通过将Zoom录音转录为带有说话人身份和行为标签的文本，训练大语言模型，实现了对多方讨论的高真实感模拟。


<details>
  <summary>Details</summary>
Motivation: 现有自动语音识别生成的转录文本仅有匿名说话人标签，无法捕捉一致的人类行为，限制了多方讨论模拟的现实性。

Method: 构建可复现的管道，将公开的Zoom录音转换为带有说话人归属的转录文本，包含角色信息和语用行为标签；微调大语言模型以特定参与者为目标，利用带有'动作感知'的数据进行训练。

Result: 发布了三个人政府讨论数据集，微调后模型困惑度降低67%，说话人忠实度和真实感的分类性能几乎翻倍，且通过图灵测试式评估，模拟与真实讨论难以区分。

Conclusion: 提出的方法为复杂且现实的公民讨论模拟提供了实用且可扩展的途径，显著提升模型对参与者行为的捕捉能力和整体模拟质量。

Abstract: Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this "action-aware" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.

</details>


### [11] [A superpersuasive autonomous policy debating system](https://arxiv.org/abs/2511.17854)
*Allen Roush,Devin Gonier,John Hines,Judah Goldfeder,Philippe Martin Wyder,Sanjay Basu,Ravid Shwartz Ziv*

Main category: cs.CL

TL;DR: 本文提出DeepDebater，一个基于多智能体合作的AI辩论系统，能完成完整复杂政策辩论并胜出，表现优于人类对手和专业教练评价。


<details>
  <summary>Details</summary>
Motivation: 人工智能在进行复杂、基于证据和策略适应的说服方面仍面临巨大挑战，以往工作如IBM Project Debater主要针对简化且针对普通观众的辩论格式。

Method: 提出了DeepDebater系统，采用层级化的多智能体工作流架构，多智能体协作与批判完成各个论证任务，结合大规模辩论证据库进行迭代检索、综合与自我纠正，生成完整演讲稿、交叉质询和反驳。系统还支持实时语音合成和动画展示，支持AI对AI、AI对人类及混合操作。

Result: DeepDebater在人工编写的辩题上出具的论证更具质量，能在模拟比赛中持续获胜，且被专业辩论教练优选。

Conclusion: DeepDebater成功实现了能够独立参与并赢得完整政策辩论的AI系统，显著提升了辩论AI的复杂性和表现，并支持开源以促进后续研究。

Abstract: The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main

</details>


### [12] [From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation](https://arxiv.org/abs/2511.18259)
*Xiaochen Zheng,Alvaro Serra,Ilya Schneider Chernov,Maddalena Marchesi,Eunice Musvasva,Tatyana Y. Doktorova*

Main category: cs.CL

TL;DR: DiscoVerse多代理系统成功实现了对真实大规模药物研发历史档案的逆向转化支持，展示了高召回率及合理的精确率，并通过专家盲评验证了系统的实用性和结果的科学价值。


<details>
  <summary>Details</summary>
Motivation: 药物研发产生大量异构且丰富的历史数据，尤其是停滞项目的数据，合理利用这些数据对逆向转化极其重要，但实际中难以高效复用。

Method: 设计了多代理系统DiscoVerse，实施语义检索、跨文档链接和可审计合成以支持药物研发中的逆向转化。

Result: 在包含0.87亿BPE词元、跨越40余年数据的Roche药物研发档案中选取180分子为测试，DiscoVerse在七个基准查询中召回率接近满分（≥0.99），精确率中等（0.71-0.91），并在停药原因和器官特异性毒性等方面实现了忠实、源数据关联的综合分析。

Conclusion: 该工作首次在真实的保密药物研发数据上系统化评估了多代理框架，提出了与科学工作流程相适应的角色代理设计和人机协同逆向转化支持，展示了自动化科学研究辅助的新可能性。

Abstract: Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.

</details>


### [13] [Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction](https://arxiv.org/abs/2511.17908)
*Debashish Chakraborty,Eugene Yang,Daniel Khashabi,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 通过符合预测实现对检索增强生成中上下文的覆盖控制过滤，显著减少冗余内容并提升或保持事实准确性，为上下文工程提供了一种模型无关且有统计保证的方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理长或噪声较多的上下文时准确率下降，传统的过滤方法缺乏统计控制，无法保证重要证据的保留。

Method: 采用符合预测（conformal prediction）作为覆盖控制过滤框架，结合基于嵌入和大语言模型（LLM）的评分函数，对检索出的上下文内容进行过滤。

Result: 符合预测过滤方法能有效控制覆盖率，保留指定比例的相关片段，同时将保留的上下文减少2-3倍。NeuCLIR数据集上严格过滤下下游事实准确率提升，适度过滤保持稳定，表明丢弃内容多为冗余或无关信息。

Conclusion: 符合预测过滤为RAG模型的上下文缩减提供了可靠且受控的方法，有效去除了无关内容，提升了模型的事实准确性，且适用不同模型，具备实用价值。

Abstract: Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.

</details>


### [14] [L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention](https://arxiv.org/abs/2511.17910)
*Yuliang Zhan,Xinyu Tang,Han Wan,Jian Li,Ji-Rong Wen,Hao Sun*

Main category: cs.CL

TL;DR: 本文发现LLMs和VLMs在CoT推理的低频潜在表示上具有相似性，基于此提出L2V-CoT，实现了零训练成本的推理能力迁移，显著提升了视觉语言模型的推理表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在多步推理任务中表现不足，且现有CoT推理迁移方法存在训练成本高或需要架构对齐的问题，亟需一个高效且通用的推理迁移方法。

Method: 本文提出了L2V-CoT，一种基于线性人工断层成像（LAT）的训练免费潜在干预方法，通过提取和重采样LLMs中的低频CoT表示，实现了维度匹配并将其注入VLMs推理阶段。

Result: 实验表明，L2V-CoT在无需训练的情况下，不仅优于其他训练免费基线方法，还超过了部分有监督方法，明显提升了VLM的多步骤推理能力。

Conclusion: L2V-CoT方法通过在频域中提取和注入低频的Chain-of-Thought推理表示，成功实现了从大语言模型（LLMs）向视觉语言模型（VLMs）的推理能力迁移，显著提升了VLMs在多步推理任务中的表现，且无需额外训练。

Abstract: Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.

</details>


### [15] [Towards Efficient LLM-aware Heterogeneous Graph Learning](https://arxiv.org/abs/2511.17923)
*Wenda Li,Tongya Zheng,Shunyu Liu,Yu Wang,Kaixuan Chen,Hanyang Yuan,Bingde Hu,Zujie Ren,Mingli Song,Gang Chen*

Main category: cs.CL

TL;DR: 提出ELLA框架高效利用LLM解决异构图中复杂关系语义和语义鸿沟问题，提升性能和效率。


<details>
  <summary>Details</summary>
Motivation: 异构图中关系语义复杂且预定义语义和监督信号有限，LLM集成复杂且计算开销大，存在语义鸿沟。

Method: 提出了ELLA框架，包括LLM感知关系分词器和Hop级关系图变换器，以及细粒度任务感知文本链式思维提示。

Result: ELLA在四个异构图上优于最先进方法，支持高达13B参数的LLM，并实现高达4倍速度提升。

Conclusion: ELLA有效融合大型语言模型，显著提高异构图关系语义建模的性能和效率，推动异构图与LLM结合的发展。

Abstract: Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.

</details>


### [16] [SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization](https://arxiv.org/abs/2511.17938)
*Jianghao Wu,Yasmeen George,Jin Ye,Yicheng Wu,Daniel F. Schmidt,Jianfei Cai*

Main category: cs.CL

TL;DR: SPINE方法通过聚焦高熵分叉点的选择性更新与熵正则化，解决了测试时强化学习中的性能坍缩问题，提高了LLM和MLLM在多任务推理中的表现和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前基于自一致性投票的无标签测试时强化学习方法容易导致模型输出短缩和性能下降，这主要源于大部分token为低熵追随者，只有少量高熵token主导分支。针对这一现象，论文提出选择性更新分叉token以防止更新坍缩，提升推理性能。

Method: SPINE框架识别前向传播中的高熵分叉token，仅对这些token进行强化学习更新，并使用熵带正则器维持适度的探索-利用平衡，结合GRPO目标和可选的KL锚约束，无需标签或奖励模型。

Result: 该论文提出了一种名为SPINE的新方法，针对大语言模型（LLM）和多模态LLM（MLLM）在推理过程中测试时强化学习（TTRL）出现的性能衰退和训练不稳定问题。SPINE通过选择性地仅更新高熵分支的分叉token，并引入熵带正则化，保持探索和抑制噪声监督，从而稳定训练并提升了Pass@1性能。该方法无需标签或奖励模型，适用于多种问答和推理任务，并在十个基准测试中均表现优异。

Conclusion: 对链式思维推理模型进行基于分支点的选择性更新和熵正则化，是一种简单、无标签、且有效的测试时自适应机制，能稳定提升模型的推理能力和训练稳定性。

Abstract: Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.

</details>


### [17] [Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models](https://arxiv.org/abs/2511.17946)
*Shuo Zhang,Fabrizio Gotti,Fengran Mo,Jian-Yun Nie*

Main category: cs.CL

TL;DR: 论文提出通过分析模型预训练语料库中问题和答案的词汇覆盖度，辅助检测大语言模型的幻觉现象，验证了词汇覆盖度在幻觉检测中的互补作用。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在开放域问答中存在幻觉问题，且模型预训练数据的覆盖度与幻觉检测之间的联系尚未被充分探索。

Method: 构建RedPajama的1.3万亿词元预训练语料库的后缀数组，用于检索问题和生成答案的n-gram统计数据，结合模型的对数概率一起进行幻觉检测。

Result: 发现基于词汇覆盖度的特征单独效果较弱，但与模型生成概率结合后，在高不确定性数据集上对幻觉检测有一定增益，表明词汇覆盖度是幻觉检测的有效辅助信号。

Conclusion: 词汇训练数据覆盖度特征能为大模型幻觉检测提供额外的辅助信号，尤其在模型不确定性较高的场景下效果显著。作者还公开了代码和后缀数组基础设施以促进后续研究。

Abstract: Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.

</details>


### [18] [MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok](https://arxiv.org/abs/2511.17955)
*Dat Thanh Nguyen,Nguyen Hung Lam,Anh Hoang-Thi Nguyen,Trong-Hop Do*

Main category: cs.CL

TL;DR: 本文提出了MTikGuard系统，通过扩展数据集和多模态融合，实现了对TikTok有害内容的实时检测，准确率达89.37%。


<details>
  <summary>Details</summary>
Motivation: 短视频兴起带来大量潜在有害内容，传统方法难以应对海量实时上传，需开发高效实时检测系统。

Method: 扩展TikHarm数据集，构建包含视觉、音频和文本特征的多模态分类框架，使用基于Apache Kafka和Apache Spark的流式架构实现实时应用。

Result: 扩展数据集至4723视频，模型达89.37%准确率和89.45% F1分数，系统具备大规模实时部署能力。

Conclusion: 结合数据集扩展、多模态融合和可扩展部署，实现了高效且实用的TikTok有害内容实时检测。

Abstract: With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.

</details>


### [19] [Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets](https://arxiv.org/abs/2511.18054)
*Gowtham,Sai Rupesh,Sanjay Kumar,Saravanan,Venkata Chaithanya*

Main category: cs.CL

TL;DR: Blu-WERP是一种新颖的数据预处理管线，能显著提升Common Crawl数据的质量，进而提高大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有预处理流程难以有效过滤网络大规模语料中的噪声和非结构化内容，影响LLM性能。

Method: Blu-WERP对Common Crawl的WARC文件进行高级过滤和质量评估处理，以优化训练数据。

Result: 在不同参数规模和9个基准测试中，Blu-WERP比现有基线DCLM和Fineweb表现更优，性能提升最高达9.5%，且提升了各类推理与理解任务表现。

Conclusion: Blu-WERP作为先进的预处理方案，显著提升了LLM训练数据质量和模型性能，同时减少计算成本。

Abstract: High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.

</details>


### [20] [GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set](https://arxiv.org/abs/2511.18146)
*Yomal De Mel,Nisansa de Silva*

Main category: cs.CL

TL;DR: 本研究构建了高质量的辛哈拉语YouTube歌曲评论情绪数据集，展示了评论情绪分析的有效性，并通过机器学习模型取得较好情感分类效果。


<details>
  <summary>Details</summary>
Motivation: 构建高质量的辛哈拉语音乐评论数据集，研究基于评论的情绪映射，解决用户生成内容中的偏差问题，并推动辛哈拉语自然语言处理与音乐情感识别研究。

Method: 手工标注辛哈拉语歌曲评论数据集，采用Russell的情绪二维模型（Valence-Arousal）进行情感标注，利用多个人工注释者保证标注质量；预训练多种机器学习与深度学习模型，并针对多层感知器模型进行了超参数优化。

Result: 三个注释者取得较高一致性（Fleiss kappa=84.96%）；发现不同歌曲的情绪特征区别明显；优化后的三层MLP模型在零样本测试中达到了0.887的ROC-AUC分数。

Conclusion: GeeSanBhava数据集为辛哈拉语音乐情绪识别领域贡献了宝贵资源，实验结果表明基于评论的情绪分析具有实际应用潜力，为未来辛哈拉语NLP与音乐情感研究奠定基础。

Abstract: This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.

</details>


### [21] [Vector Arithmetic in Concept and Token Subspaces](https://arxiv.org/abs/2511.18162)
*Sheridan Feucht,Byron Wallace,David Bau*

Main category: cs.CL

TL;DR: 本文通过分析LLM中两类注意力头，发现其能够揭示隐藏状态中的语义和表层信息，从而提升词语表示和相关计算的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过LLM中的不同注意力头揭示和分离语义与表层词汇信息，以提高对词语表示的理解和操作能力。

Method: 通过分析Llama-2-7b模型中的两类注意力头（概念诱导头和词元诱导头）的权重，变换隐藏状态，从而揭示隐藏状态中的语义和表层信息结构。

Result: 利用概念头转换后的隐藏状态能更准确地进行平行四边形算术（80%的最近邻准确率），而直接使用原始隐藏状态准确率仅为47%；词元头则能揭示表层词汇信息，实现词形变换运算。

Conclusion: 通过关注不同类型的注意力头，可以有效地分离并利用模型隐藏状态中的语义与表层信息，有助于深入理解和增强语言模型的词语表示能力。

Abstract: In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that "Athens" - "Greece" + "China" = "Beijing". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like "coding" - "code" + "dance" = "dancing".

</details>


### [22] [Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models](https://arxiv.org/abs/2511.18177)
*Elias Lumer,Matt Melich,Olivia Zino,Elena Kim,Sara Dieter,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah,James A. Burke,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文首次系统评测了金融文档问答中基于向量与非向量RAG系统，发现先进RAG技术显著提升检索和回答表现，且成本与性能有权衡。


<details>
  <summary>Details</summary>
Motivation: 已有工作缺乏对金融文档中基于向量与非向量RAG架构的系统性比较，以及先进RAG技术对检索准确率、回答质量、延迟和成本的实证影响尚不明确。

Method: 系统比较了基于向量的代理RAG（结合混合搜索和元数据过滤）与基于层次节点的无嵌入的RAG系统，评估了交叉编码器重排序和小到大块检索两种增强技术，在1200份SEC文件和150个问题基准上的表现，包括MRR、Recall@5、回答质量、延迟及预处理成本。

Result: 基于向量的代理RAG在回答质量上以68%胜率优于层次节点系统，交叉编码器重排序使MRR@5提升59%，小到大块检索以65%胜率优于基线检索，同时延迟仅增加0.2秒。

Conclusion: 基于向量的RAG架构在检索准确度和回答质量上优于基于层次节点的系统，且延迟相近。高级RAG技术如交叉编码器重排序和小到大块检索显著提升了系统表现。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.

</details>


### [23] [Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems](https://arxiv.org/abs/2511.18194)
*Faheem Nizar,Elias Lumer,Anmol Gulati,Pradeep Honaganahalli Basavaraju,Vamse Kumar Subbiah*

Main category: cs.CL

TL;DR: 本文提出了一种名为Agent-as-a-Graph的知识图谱检索增强生成方法，通过将工具和其父代理表示为知识图谱中的节点和边，实现更精细的检索和排序，显著提升了多代理系统的检索性能。


<details>
  <summary>Details</summary>
Motivation: 传统多代理系统中的代理工具匹配方法通常仅基于单一代理描述，忽略了代理内部细粒度的工具能力，导致代理选择效果不佳，因此需要一种能够细粒度表达和检索代理及其工具的方法。

Method: 该方法将代理和工具构建成知识图谱中的节点和边，首先通过向量搜索检索相关节点，随后应用针对类型的加权互惠排名融合算法对代理和工具进行重排序，最后遍历知识图谱以确定最终代理集合。

Result: 在LiveMCPBenchmark测试中，Agent-as-a-Graph方法在Recall@5和nDCG@5指标上分别提升了14.9%和14.6%，加权互惠排名融合优化带来了2.4%的额外提升。

Conclusion: Agent-as-a-Graph方法通过知识图谱结构和加权互惠排名融合技术，有效提升了多代理系统中代理及工具的检索效果，在LiveMCPBenchmark测试中显著优于现有方法。

Abstract: Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.

</details>


### [24] ["AGI" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa](https://arxiv.org/abs/2511.18301)
*Harsh Rathva,Pruthwik Mishra,Shrikant Malviya*

Main category: cs.CL

TL;DR: 本文通过整合大规模、多语言平衡数据，微调XLM-RoBERTa-Large模型，实现了科学文本虚假信息检测的多语种高性能，尤其在零样本语言中表现突出。


<details>
  <summary>Details</summary>
Motivation: 面对多语言科学文本虚假信息检测中训练数据稀缺和不平衡的问题，寻求通过数据驱动方法提升模型性能，特别是在低资源和零样本语言场景。

Method: 整合并均衡五个多语言数据集，构建大型训练集；基于此数据集微调XLM-RoBERTa-Large模型进行虚假信息检测。

Result: 本文针对大型语言模型生成的多语言科学文本中的虚假信息检测问题，提出了一种数据驱动的方法。通过整合和均衡五个现有数据集，构建了包含124,821个样本的训练语料库，数据量是原始SHROOM训练数据的172倍，以解决数据稀缺和不平衡问题。在此基础上，微调了具有5.6亿参数的XLM-RoBERTa-Large模型，在9种语言的虚假信息检测任务中表现出色，尤其在零样本语言古吉拉特语中获得了第二名。结果表明，系统性的数据整理比模型结构创新对低资源语言的零样本任务更为有效。

Conclusion: 系统性的数据集构建和均衡处理能显著提升多语言科学文本虚假检测性能，尤其对于低资源和零样本语言效果优于单纯的模型结构改进。

Abstract: The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.

</details>


### [25] [Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning](https://arxiv.org/abs/2511.18306)
*Mohammad Aqib,Mohd Hamza,Ying Hei Chui,Qipei Mei*

Main category: cs.CL

TL;DR: 本文针对建筑规范中复杂表格信息提取问题，比较直接图像输入与LaTeX转换两种VLM问答方法，发现直接输入更优，并通过LoRA微调显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决建筑规范中表格数据提取难题，提升自动问答系统对复杂表格信息的准确理解。

Method: 比较两种方法：直接将页面图像输入视觉语言模型（VLM）并回答问题；将表格页面转换为LaTeX代码后再回答问题；并对VLM采用LoRA进行领域特定表格数据的微调。

Result: 直接输入法的准确率普遍高于间接输入法。通过LoRA微调，模型性能显著提升，Qwen2.5-VL-3B-Instruct准确率提高超100%。

Conclusion: 参数高效的微调技术能有效提升VLM在处理复杂结构化数据（如建筑规范表格）上的表现，有助于专业领域的自动问答和合规性解读。

Abstract: Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.

</details>


### [26] [Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search](https://arxiv.org/abs/2511.18313)
*Joseph Oladokun*

Main category: cs.CL

TL;DR: 提出路径约束检索方法，通过结合结构约束与语义搜索，显著提高语言模型推理的结构一致性和相关性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型智能体在检索知识库上下文时，知识库结构与智能体当前推理状态缺乏一致性，导致推理链条不连贯。

Method: 路径约束检索结合知识图结构约束与语义检索，限制检索节点为锚节点可达的节点，保证逻辑关联。

Result: 在包含180节点和360边的六领域基准PathRAG-6上，PCR实现了100%的结构一致性，远超基线方法的24-32%；在技术领域，PCR达到排名前10的完全相关性和结构一致性，显著优于向量搜索和混合检索。平均图距离减少78%，表明检索结果结构更一致。

Conclusion: 路径约束检索有效提升大型语言模型智能体的推理系统的可靠性和连贯性，确保检索信息的结构一致性。

Abstract: Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.

</details>


### [27] [Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection](https://arxiv.org/abs/2511.18324)
*Syed Mohaiminul Hoque,Naimur Rahman,Md Sakhawat Hossain*

Main category: cs.CL

TL;DR: 该论文提出了一种基于集成微调的混合孟加拉语言模型方法，用于孟加拉YouTube评论的仇恨言论多任务分类，并在两个子任务中取得了较好成绩。


<details>
  <summary>Details</summary>
Motivation: 针对孟加拉语低资源环境下仇恨言论识别的挑战，提出一种新的集成微调混合语言模型方法，以提升性能和模型鲁棒性。

Method: 采用基于集成的微调策略，结合混合孟加拉语言模型，进行多任务学习，针对仇恨类型分类和目标群体分类两个子任务分别训练和评估。

Result: 本文提出了“Gradient Masters”方法，针对BLP-2025任务1：孟加拉多任务仇恨言论识别共享任务，采用基于集成的微调策略，解决YouTube评论中的仇恨类型分类（子任务1A）和目标群体分类（子任务1B）。通过混合孟加拉语言模型的方法，模型在子任务1A中以73.23%的微平均F1得分获得第6名，在子任务1B中以73.28%获得第3名。并通过大量实验验证模型的鲁棒性，比较了不同语言模型变体，体现了在低资源孟加拉仇恨言论场景下的泛化能力及数据集覆盖。此外，分析了误分类模式，深入探讨了仇恨言论检测的难点。

Conclusion: 通过提出的混合孟加拉语言模型和集成微调策略，模型在仇恨言论检测的两个子任务中表现优异，展示了较强的泛化能力和鲁棒性。误分类分析为未来优化提供了方向。

Abstract: This paper introduces the approach of "Gradient Masters" for BLP-2025 Task 1: "Bangla Multitask Hate Speech Identification Shared Task". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.

</details>


### [28] [OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas](https://arxiv.org/abs/2511.18335)
*James Y. Huang,Wenxuan Zhou,Nan Xu,Fei Wang,Qin Liu,Sheng Zhang,Hoifung Poon,Muhao Chen*

Main category: cs.CL

TL;DR: 提出OmniStruct基准，促进大语言模型在文本到结构化任务上的发展，通过合成数据训练小模型，实现媲美GPT-4的结构化生成效果。


<details>
  <summary>Details</summary>
Motivation: 虽然现代大语言模型在自然语言生成方面表现优异，但其在文本到结构化输出任务上的能力尚不明确。因此，提出OmniStruct基准以评估和促进LLMs在这一领域的发展。

Method: 构建OmniStruct基准，收集和统一多种文本到结构化任务的数据集，利用合成任务生成无监督训练数据，对较小模型进行微调，评估其结构化生成能力。

Result: 该论文提出了OmniStruct，一个用于评估大语言模型（LLMs）在多样化文本到结构化任务上的能力的综合基准，涵盖信息提取、表格生成和函数调用等任务。通过整合并统一多个适合结构化输出的数据集，并利用合成任务生成高质量训练数据，作者展示了在无监督条件下，仅用合成数据微调较小模型，也能获得与GPT-4相媲美的结构化生成性能。

Conclusion: 通过构建统一的多任务基准和合成数据训练，较小模型在文本到结构化生成任务中能够获得接近GPT-4的性能，说明无监督合成数据训练在结构化生成领域的有效性。

Abstract: The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.

</details>


### [29] [Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle](https://arxiv.org/abs/2511.18369)
*Manon Berriche*

Main category: cs.CL

TL;DR: 本论文通过Twitter和Facebook数据，揭示假新闻分享集中于少数政治活跃用户，虽用户展现批判态度但多为无效对话，难以促成理性辩论和减少政治极化。


<details>
  <summary>Details</summary>
Motivation: 解释为何假新闻在社交媒体中占比少且用户并非特别易受假新闻影响的情况下，政治极化却加剧，以及理解假新闻分享与政治分化的关系。

Method: 通过结合数字足迹的定量分析、在线观察和访谈，研究法国Twitter和Facebook上用户对假新闻的分享和反应，采用混合方法设计全面考察不同互动场景中的用户行为。

Result: 发现假新闻主要由政治高度活跃的少数用户分享；用户面对假新闻采取多样的批判态度，取决于其社会背景和互动规范，但这些批判通常不会转化为有效的政治讨论。

Conclusion: 假新闻的传播集中在少数高政治化且对机构持批判态度的用户群体，这些用户通过高频活跃度影响政治议程。尽管用户会以不同方式保持批判性距离，但这些交流多为“聋人对话”，缺少真正的建设性辩论。

Abstract: This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence énonciative) or interventions ('points d'arrêt') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.

</details>


### [30] [Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models](https://arxiv.org/abs/2511.18393)
*Heejoon Koo*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型在受损临床文本中的表现，提出新策略提升诊断预测鲁棒性与公平性，促进了AI临床决策支持系统的可靠应用。


<details>
  <summary>Details</summary>
Motivation: 临床文本常因人为错误或自动化流程失败而受损，这引发了对人工智能辅助决策系统可靠性和公平性的担忧，但相关影响尚未被充分研究。

Method: 引入了临床基础的标签降维方案和模拟临床医生推理的层次链式思维策略，在多种文本腐败场景下对最先进的LLMs进行测试，重点考察其鲁棒性和群体公平性。

Result: 所提出的方法在文本受损环境下显著提升了预测鲁棒性，减小了不同人口子群体间的不稳定性，增强了诊断预测的可靠性和公平性。

Conclusion: 该论文系统性地评估了大型语言模型在临床文本受损情况下的鲁棒性和公平性，提出了标签降维和层次链式思维策略，有效提升了模型的稳定性和性能，促进了人工智能在临床决策支持系统中的可靠应用。

Abstract: A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.

</details>


### [31] [Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models](https://arxiv.org/abs/2511.18409)
*Dana Arad,Yonatan Belinkov,Hanjie Chen,Najoung Kim,Hosein Mohebbi,Aaron Mueller,Gabriele Sarti,Martin Tutek*

Main category: cs.CL

TL;DR: 提出了基于MIB的机制解释性标准化评测框架及社区共享任务，通过多个方法显著提升了语言模型中回路和因果变量的定位能力，促进了机制解释性研究进展


<details>
  <summary>Details</summary>
Motivation: 机制解释性难以衡量进展，提出标准化评估框架用于衡量语言模型中机制解释性的方法效果

Method: 通过两个赛道（回路定位和因果变量定位）进行评估，利用集合方法和正则化策略发现回路，以及使用低维和非线性投影方法对激活向量进行特征化

Result: 多支团队参与，共采用十种方法，回路定位使用集合和正则化策略获得显著提升，因果变量定位使用低维和非线性投影实现显著改进

Conclusion: MIB排行榜仍开放，鼓励社区继续使用该标准框架推动机制解释性研究的持续进展。

Abstract: Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.

</details>


### [32] [SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data](https://arxiv.org/abs/2511.18411)
*Sultan Alrashed,Chadi Helwe,Francesco Orabona*

Main category: cs.CL

TL;DR: 本文介绍了SmolKalam，这是对Smoltalk2的阿拉伯语多轮对话数据集的翻译，通过多模型集成翻译和质量过滤提高数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语预训练数据虽多，但缺少包含推理和工具调用的高质量多轮对话数据集，单纯翻译不足以满足后期训练的高质量需求。

Method: 使用多模型集成翻译管道，结合质量过滤，并通过消融实验探索传统解码器模型的翻译技巧。

Result: 提出的方法有效提升了阿拉伯语多轮对话数据集的质量，为后续模型训练提供了坚实的数据基础。

Conclusion: SmolKalam数据集通过严格的数据筛选和多模型翻译策略，提升了阿拉伯语多轮对话数据的质量，适合后期训练需求。

Abstract: Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.

</details>


### [33] [Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations](https://arxiv.org/abs/2511.18413)
*Yu Xia,Sungchul Kim,Tong Yu,Ryan A. Rossi,Julian McAuely*

Main category: cs.CL

TL;DR: 本文提出了一个多智能体协作过滤（MACF）框架，通过动态管理用户和物品智能体的协作，显著提升了基于大型语言模型的推荐系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的智能体推荐多采用单一智能体或多智能体任务分解，缺乏推荐导向设计，未充分利用协作信号，导致推荐效果不佳。

Method: 提出了MACF框架，将类似用户和相关物品实例化为具有独特档案的LLM智能体，在中央协调智能体的管理下，智能体们调用检索工具、相互协作和推荐候选项。

Result: MACF在三个不同领域的数据集上表现优于其他强基线智能体推荐方法，验证了其设计的有效性。

Conclusion: MACF框架通过多智能体合作方式，有效利用用户-物品交互历史中的协作信号，提升了基于大型语言模型的推荐性能。

Abstract: Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.

</details>


### [34] [General Agentic Memory Via Deep Research](https://arxiv.org/abs/2511.18423)
*B. Y. Yan,Chaofan Li,Hongjin Qian,Shuqi Lu,Zheng Liu*

Main category: cs.CL

TL;DR: 提出了一种名为通用智能记忆（GAM）的新型记忆框架，采用即时编译原则，在运行时创建优化的上下文，结合轻量级记忆和通用页存储，显著提升了基于记忆的任务完成效果。


<details>
  <summary>Details</summary>
Motivation: 静态记忆容易导致信息丢失，限制了AI代理的记忆能力和任务表现，有必要设计一种动态高效的记忆体系。

Method: GAM采用Memorizer与Researcher双设计，Memorizer利用轻量级存储重点信息并维护完整历史信息，Researcher则在运行时从页存储中检索整合信息，结合强化学习实现端到端性能优化。

Result: 实验表明，GAM在多种基于记忆的任务完成场景中相较现有系统有显著提升。

Conclusion: GAM框架通过双重设计显著提升了AI代理在各种基于记忆的任务中的表现，优于现有的静态记忆系统。

Abstract: Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \textbf{general agentic memory (GAM)}. GAM follows the principle of "\textbf{just-in time (JIT) compilation}" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.

</details>


### [35] [MindEval: Benchmarking Language Models on Multi-turn Mental Health Support](https://arxiv.org/abs/2511.18491)
*José Pombal,Maya D'Eon,Nuno M. Guerreiro,Pedro Henrique Martins,António Farinhas,Ricardo Rei*

Main category: cs.CL

TL;DR: 本研究提出MindEval框架，自动评估大型语言模型在多轮心理健康对话中的表现，揭示当前模型的不足并为心理健康AI系统的改进提供评价工具。


<details>
  <summary>Details</summary>
Motivation: 现有心理健康对话系统评测缺乏真实复杂交互的基准，限制了更好系统的开发。

Method: 构建了MindEval框架，结合临床心理专家设计，利用患者模拟和自动评估，进行多轮心理健康对话的评测。

Result: 评测了12个主流大型语言模型，发现模型表现普遍不佳，尤其在处理较长对话和严重症状患者时能力下降。自动评估结果与专家评价高度相关，验证了框架的有效性。

Conclusion: 现有大型语言模型在心理健康对话中的表现不理想，存在应对复杂对话和严重症状患者的困难。

Abstract: Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.

</details>


### [36] [For Those Who May Find Themselves on the Red Team](https://arxiv.org/abs/2511.18499)
*Tyler Shoemaker*

Main category: cs.CL

TL;DR: 本文主张文学学者应积极介入大语言模型解释研究，通过红队等方式推动多元解读标准。


<details>
  <summary>Details</summary>
Motivation: 当前LLM解释方法具有工具性限制，文学解释需要摆脱单一标准的约束。

Method: 通过理论分析，提出红队(red team)作为学术参与和意识形态斗争的切入点。

Result: 指出参与LLM解释研究不可避免涉及意识形态挑战，但这是必要的学术行动。

Conclusion: 本文强调文学学者必须参与大语言模型(LLM)的可解释性研究，不能仅依赖现有的解释标准。

Abstract: This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.

</details>


### [37] [Dealing with the Hard Facts of Low-Resource African NLP](https://arxiv.org/abs/2511.18557)
*Yacouba Diarra,Nouhoum Souleymane Coulibaly,Panga Azazia Kamaté,Madani Amadou Tall,Emmanuel Élisé Koné,Aymane Dembélé,Michael Leventhal*

Main category: cs.CL

TL;DR: 针对低资源语言Bambara，收集并标注大量语音数据，训练紧凑模型，进行了全面评估并公开资源。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的语音数据集、模型及评估框架建立具有挑战性，缺乏丰富的经验基础。

Method: 通过实地采集语音数据，采用半自动转录方法进行标注，训练多种单语超小型模型，使用自动和人工方式评估模型性能。

Result: 收集了612小时Bambara语言的自发语音，完成半自动转录标注，建立了多种超小型单语模型，并进行了自动和人工评估，公开了数据集、评估集、模型和代码。

Conclusion: 提出了实用的数据采集、标注及模型设计建议，强调人工评估的重要性。

Abstract: Creating speech datasets, models, and evaluation frameworks for low-resource languages remains challenging given the lack of a broad base of pertinent experience to draw from. This paper reports on the field collection of 612 hours of spontaneous speech in Bambara, a low-resource West African language; the semi-automated annotation of that dataset with transcriptions; the creation of several monolingual ultra-compact and small models using the dataset; and the automatic and human evaluation of their output. We offer practical suggestions for data collection protocols, annotation, and model design, as well as evidence for the importance of performing human evaluation. In addition to the main dataset, multiple evaluation datasets, models, and code are made publicly available.

</details>


### [38] [Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks](https://arxiv.org/abs/2511.18597)
*H. M. Shadman Tabib,Jaber Ahmed Deedar*

Main category: cs.CL

TL;DR: GPT-4o在自动评估编程题难度上表现不佳，准确率远低于基于特征的LightGBM模型，存在忽视关键数值信息和评判偏差的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言和代码生成方面表现出色，但其在结构化任务如编程题难度预测中的表现和判定机制尚未充分研究，且自动难度评估在编程竞赛和教育领域有实际需求，故本研究旨在揭示GPT-4o在此任务中的表现及局限性。

Method: 将GPT-4o纯粹作为自然语言难度评估器，与基于显式数值和文本特征的LightGBM模型在1,825个LeetCode问题上进行系统比较，采用混淆矩阵和SHAP解释工具分析模型表现，同时设计合成难题生成实验探究GPT-4o评判行为。

Result: 本文系统比较了GPT-4o作为自然语言难度评估器与基于显式数值和文本特征训练的LightGBM模型在预测LeetCode编程题难度（Easy, Medium, Hard）上的表现。结果显示，LightGBM准确率达86%，而GPT-4o仅为37.75%。通过混淆矩阵和SHAP解释分析发现，数字约束（如输入大小限制和通过率）对区分难题至关重要，但GPT-4o经常忽视这些信息且偏向于预测为简单类别。此外，GPT-4o对自生成的难题也多预测为Medium，显示其存在明显的评判偏差。该研究指出在竞争编程和教育平台中，基于LLM的自动难度评估存在可信度问题，需要改进。

Conclusion: 现有LLM，特别是GPT-4o，在评估编程题难度时存在明显局限，难以替代基于数值和文本特征的传统机器学习模型，其评判偏差及忽视数值约束的问题需在实际应用前解决。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.

</details>


### [39] [A Benchmark for Zero-Shot Belief Inference in Large Language Models](https://arxiv.org/abs/2511.18616)
*Joseph Malone,Rachith Aiyappa,Byunghwee Lee,Haewoon Kwak,Jisun An,Yong-Yeol Ahn*

Main category: cs.CL

TL;DR: 本文提出基于在线辩论平台数据的基准测试，评估大型语言模型在零样本条件下预测个体多领域信念立场的能力，揭示其优势与不足。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（LLMs）在不同信念领域的泛化能力，突破现有方法局限于狭窄社会政治背景并依赖微调的困境。

Method: 构建包含多种信息条件的零样本基准测试，利用在线辩论平台数据评估LLMs对不同信念主题的立场预测能力，比较不同模型及信息条件下的性能表现。

Result: 通过系统性可复现的基准测试，发现提供更多个人背景信息能提升预测精度，但不同信念领域的表现差异显著，揭示了LLMs在人类推理模拟上的能力与局限。

Conclusion: 当前LLMs在模拟人类信念推理方面具备一定能力，且通过引入个人背景信息可提升表现，但仍存在领域间性能不均，需进一步研究以拓展其应用范围。

Abstract: Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.

</details>


### [40] [A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News](https://arxiv.org/abs/2511.18618)
*Mirza Raquib,Munazer Montasir Akash,Tawhid Ahmed,Saydul Akbar Murad,Farida Siddiqi Prity,Mohammad Amzad Hossain,Asif Pervez Polok,Nick Rahimi*

Main category: cs.CL

TL;DR: 提出利用混合迁移学习模型BERT-CNN-BiLSTM，对孟加拉语新闻标题进行同时的分类与情感分析，解决数据不平衡问题，取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 面对大量新闻内容，快速理解新闻主题与情感态度对于公众至关重要。孟加拉语作为低资源语言，缺乏有效的新闻标题与情感分类方法，本研究旨在填补该领域空白，提高信息获取效率。

Method: 采用混合迁移学习模型BERT-CNN-BiLSTM在BAN-ABSA数据集上，结合两种采样策略（技术1和技术2）分别处理数据不平衡，进行新闻标题和情感的联合分类。

Result: 本研究提出了一种结合BERT-CNN-BiLSTM混合迁移学习模型的孟加拉语新闻标题分类与情感分析新方法。该方法在BAN-ABSA数据集（9014条新闻标题）上进行实验，实现了新闻标题与情感的同时分类。针对数据不平衡问题，研究采用了两种采样策略，技术1（先采样后划分）和技术2（先划分后采样），分别取得了78.57%和81.37%的标题分类准确率，以及73.43%和64.46%的情感分类准确率。所提模型显著优于所有基线模型，创下孟加拉语文本分类新纪录，是低资源语言文本分类的有力基线。

Conclusion: BERT-CNN-BiLSTM模型在孟加拉语新闻标题和情感分类任务中表现卓越，显著优于基线模型，证实了结合标题和情感数据集及合理采样策略的重要性，为低资源语言文本分类提供了强基线。

Abstract: In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\% and 73.43\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.

</details>


### [41] [Prompt Optimization as a State-Space Search Problem](https://arxiv.org/abs/2511.18619)
*Maanas Taneja*

Main category: cs.CL

TL;DR: 将提示词优化建模为状态空间搜索问题，通过束搜索和随机游走优化提示词，在多个NLP任务中提升提示词性能，简洁的提示改进更有效，提示词优化具备搜索问题性质。


<details>
  <summary>Details</summary>
Motivation: 语言模型对输入提示极其敏感，现有方法如DSpy通过示例优化提示，本文受此启发提出将提示优化视为状态空间搜索，从而系统化探索提示词空间。

Method: 将提示空间建模为图，节点为提示状态，边为转换操作（缩短、增加示例、重排序），运用束搜索和随机游走算法在提示空间内搜索，基于开发集评估并剪枝。

Result: 本文提出将提示词优化视为经典的状态空间搜索问题，通过构建提示词空间的图模型，利用束搜索和随机游走算法系统探索提示词空间，并在开发集上评估并剪枝不佳分支。实验涵盖五个NLP任务，浅层搜索配置即带来提示词性能提升，尤其在推理任务上开发集准确率显著提升。分析表明，简洁的提示词转换更有效，冗长操作无益。结果证明提示词优化可作为一个搜索问题，并指出若有更强计算资源及更好评价指标，深度探索有望获得更具泛化能力的提示词。

Conclusion: 提示词优化可视为状态空间搜索问题，束搜索等方法能提升提示词质量，简洁提示词更优。深层搜索与更好评价指标有利于泛化能力的提升。

Abstract: Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].

</details>


### [42] [OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph](https://arxiv.org/abs/2511.18622)
*Michael J. Bommarito*

Main category: cs.CL

TL;DR: OpenGloss是一个结合词典定义、百科上下文、词源和语义关系的综合知识图，规模相当于WordNet，但定义更多，生成成本低且速度快，适合教学和自然语言处理。


<details>
  <summary>Details</summary>
Motivation: 现有词汇资源在定义丰富性、综合性和生成效率方面存在不足，OpenGloss旨在解决这些问题，支持词汇学习和自然语言处理。

Method: 采用多智能体程序化生成流程，结合模式验证的大型语言模型输出和自动质量保证，快速高效地生成资源。

Result: 生成了包含537K词义、150K词条、910万语义边、100万用例和6000万百科词汇的资源，生成时间不足一周，成本低于1000美元，公开发布。

Conclusion: OpenGloss展示了通过结构化的大型语言模型输出生成综合词汇资源的可行性与优势，成本低速度快，支持教育与NLP应用。

Abstract: We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.
  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.
  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.

</details>


### [43] [No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases](https://arxiv.org/abs/2511.18635)
*Shireen Chand,Faith Baca,Emilio Ferrara*

Main category: cs.CL

TL;DR: 针对性偏见缓解技术易在未针对的偏见维度产生负面影响，需多维度评价避免偏见转移或恶化。


<details>
  <summary>Details</summary>
Motivation: 尽管现有技术能减轻特定方向的偏见，但通常只沿目标偏见维度评估效果，忽视了偏见缓解对其他维度的交叉影响。

Method: 研究了四种消除偏见的技术，应用于来自七个模型家族的十个大型语言模型，覆盖种族、宗教、职业和性别偏见。通过StereoSet基准评估消除偏见对模型连贯性和刻板偏好影响。

Result: 结果显示，针对性消除偏见有时能减少预期偏见，但常导致其他维度偏见加剧和模型连贯性下降。

Conclusion: 偏见缓解策略必须采用多维度、全面的评估方法，以防止在缓解某些偏见时无意中加剧其他偏见，保证模型公平性和连贯性。

Abstract: Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.

</details>


### [44] [Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting](https://arxiv.org/abs/2511.18649)
*Goun Pyeon,Inbum Heo,Jeesu Jung,Taewook Hwang,Hyuk Namgoong,Hyein Seo,Yerim Han,Eunbin Kim,Hyeonseok Kang,Sangkeun Jung*

Main category: cs.CL

TL;DR: 本研究搭建无泄露环境，使用2026年韩国CSAT数学题评测24个LLMs，发现GPT-5 Codex最佳，几何表现最弱，推理增强提升成绩但效率降低，提出了实用的模型评价框架。


<details>
  <summary>Details</summary>
Motivation: 现有公开基准存在数据泄露，导致评测结果不准确，且缺少基于真实考试的无泄露数学推理评估框架。该研究旨在建立一个纯净的评测环境，真实反映大型语言模型在数学能力上的表现，同时兼顾性能与成本效率，推动模型应用实用化。

Method: 通过在考试后两小时内数字化所有题目，避免数据泄露，设计涵盖文本、图像及混合输入模式，韩语和英语提示语言，测试24款不同规模大型语言模型的数学推理能力。还进行了推理增强实验，评估不同推理强度下模型的性能及效率。

Result: 该论文系统评估了多达24种先进大型语言模型（LLMs）在2026年韩国大学学业能力测验数学部分的数学推理能力，确保无数据泄露影响。GPT-5 Codex以文本输入和韩语提示获得满分，显示出优异性能。研究分析了不同输入模式和提示语言对模型表现的影响，发现几何为模型的薄弱环节，且提高推理强度虽能提升分数但显著降低效率。研究实现了完全无泄露的评测环境，构建了基于真实考试的模型评测框架，并提出了结合性能、成本和时间的实用评估视角。

Conclusion: 本研究证明了在无数据泄露环境下，先进的大型语言模型能够在高难度数学考试中表现优异，但存在几何等领域的缺陷。提高推理强度能提升成绩但代价是效率大幅下降，实际应用中需权衡性能与成本。研究构建了真实考试基础下的全面评测框架，为今后LLM数学推理能力评估提供了参考。

Abstract: This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).
  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.
  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).

</details>


### [45] [CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning](https://arxiv.org/abs/2511.18659)
*Jie He,Richard He Bai,Sinead Williamson,Jeff Z. Pan,Navdeep Jaitly,Yizhe Zhang*

Main category: cs.CL

TL;DR: CLaRa通过统一嵌入压缩和联合优化，在问答任务中提升了检索增强生成模型的效果，表现优于多种基线。


<details>
  <summary>Details</summary>
Motivation: 传统RAG方法在处理长上下文和检索与生成模块的分离优化方面存在不足，影响了整体性能。

Method: 提出了CLaRa框架，采用嵌入压缩和共享连续空间联合优化；引入SCP数据合成框架结合QA和复述监督；利用可微分top-k估计器，实现重排序器和生成器的端到端训练。

Result: 在多个问答基准测试中，CLaRa展现了最先进的压缩和重排序性能，优于基于文本微调的基线模型。

Conclusion: CLaRa框架通过联合优化和嵌入压缩，有效提升了基于检索增强生成的性能，实现了检索相关性与答案质量的统一提升。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.

</details>


### [46] [Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models](https://arxiv.org/abs/2511.18696)
*Wangjiaxuan Xin*

Main category: cs.CL

TL;DR: 提出了ECN多阶段提示方法，显著增强了大语言模型的同理心表现，适用于需要情感共鸣的对话系统。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型在对话中表达同理心和包容性的能力，以满足更高质量的交互需求。

Method: 采用四阶段多轮提示方法，包括视角采纳、情感共鸣、反思理解和综合合成，引导模型生成情感共鸣且上下文相关的回应。

Result: ECN在GPT-3.5-turbo和GPT-4上均获得最高的同理商（EQ）分数，同时保持良好的关怀度和困惑度指标。

Conclusion: ECN框架成功提升了大语言模型的共情能力，在多个指标上表现优异，展示了其在需要同理心和包容性的对话AI应用中的潜力。

Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.

</details>


### [47] [RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context](https://arxiv.org/abs/2511.18743)
*Yu Lei,Shuzheng Si,Wei Wang,Yifei Wu,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.CL

TL;DR: RhinoInsight通过引入两种控制机制，解决了大型语言模型深度研究中的错误累计和上下文衰减问题，提升了模型的性能和结果质量。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在深度研究任务中的线性计划存在错误积累和上下文衰减问题，缺乏对模型行为和上下文的显式控制，影响了性能和结果质量。

Method: RhinoInsight利用两个控制机制：可验证检查清单模块将用户需求转化为可追踪和验证的分目标，并结合人类或LLM评论者进行细化；证据审计模块结构化搜索内容，更新大纲，剔除噪声并通过评论者绑定高质量证据以确保内容的可验证性。

Result: 实验证明，RhinoInsight在深度研究任务中实现了最先进的性能，同时在深度搜索任务上表现也具有竞争力。

Conclusion: RhinoInsight框架通过引入可验证的检查清单模块和证据审计模块，有效提升了大型语言模型在深度研究任务中的鲁棒性、可追踪性和整体质量。

Abstract: Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.

</details>


### [48] [Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search](https://arxiv.org/abs/2511.18749)
*Matthew R. DeVerna,Kai-Cheng Yang,Harry Yaojun Yan,Filippo Menczer*

Main category: cs.CL

TL;DR: 研究发现，结合高质量上下文信息的检索生成融合（RAG）系统显著提升大规模语言模型的事实核查性能，而推理或网络搜索手段提升有限。


<details>
  <summary>Details</summary>
Motivation: 随着大规模语言模型（LLMs）在自动化端到端事实核查中的应用展望逐渐提升，然而此前研究结果不一，且主流聊天机器人配备了推理能力和网页搜索工具，用户依赖它们进行事实验证，因此需要严格评估其效果。

Method: 评估了来自OpenAI、Google、Meta和DeepSeek的15个近期大型语言模型，在超过6000条由PolitiFact核查的事实主张上进行测试，比较标准模型与带推理和网页搜索功能的变体表现。

Result: 标准模型表现不佳，推理功能仅带来极小提升，网页搜索则提供适度改进，尽管事实核查信息在网络上可获取。基于PolitiFact摘要的精心策划的RAG系统使各模型变体的宏观F1值平均提升了233%。

Conclusion: 给予模型访问经过策划的高质量上下文信息，是实现自动化事实核查的有希望的路径。

Abstract: Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.

</details>


### [49] [Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion](https://arxiv.org/abs/2511.18751)
*Daiqing Wu,Dongbao Yang,Can Ma,Yu Zhou*

Main category: cs.CL

TL;DR: 本文提出了DRF方法，通过基于分布的特征恢复与融合策略，有效解决了多模态情感分析中低质量和缺失模态问题，显著提升了模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的图文内容迅速增加，现有多模态情感分析方法未充分考虑低质量或缺失模态问题，而这些问题在现实应用中频繁出现，迫切需要能够鲁棒预测情感的模型。

Method: 提出了基于分布的特征恢复与融合（DRF）方法，通过维护每种模态的特征队列来近似其分布，定量评估模态质量以减弱低质量模态的贡献，并通过样本和分布监督构建跨模态映射关系以恢复缺失模态。

Result: 在三个人们公开的图文数据集上，通过模拟低质量和缺失模态的两种干扰策略，DRF方法相比现有最先进方法均表现出普适且显著的性能提升。

Conclusion: DRF方法有效提升了图文多模态情感分析的鲁棒性，能够统一处理低质量和缺失模态问题，为实际应用中的多模态情感分析提供了更可靠的解决方案。

Abstract: As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.

</details>


### [50] [Context-Aware Whisper for Arabic ASR Under Linguistic Varieties](https://arxiv.org/abs/2511.18774)
*Bashar Talafha,Amin Abu Alhassan,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: 该论文提出了一种针对阿拉伯语低资源语音识别的上下文感知提示策略，在不用重新训练Whisper模型的情况下，通过解码器提示和编码器前缀等方法，显著提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语存在方言多样性且标注数据有限，低资源语音识别困难，传统重新训练方法代价高且不灵活，因此研究无需重新训练的上下文提示策略来提升识别性能。

Method: 通过解码器提示（首轮转录或检索句子）和编码器前缀（目标说话人声音合成语音）结合多模态和多层次的提示技术，如提示重排、说话人感知前缀合成以及词汇、语义、声学检索等。

Result: 在九种阿拉伯语环境下进行零样本测试，现代标准阿拉伯语识别准确率提升22.3%，方言语音准确率提升9.2%，有效降低幻觉和说话人不匹配问题。

Conclusion: 该方法在九种阿拉伯语语言环境下均表现出显著效果，分别在现代标准阿拉伯语和方言语音上将字错误率降低了22.3%和9.2%，有效缓解了模型幻觉和说话人不匹配问题。

Abstract: Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.

</details>


### [51] [HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations](https://arxiv.org/abs/2511.18808)
*Cao Linxiao,Wang Ruitao,Li Jindong,Zhou Zhipeng,Yang Menglin*

Main category: cs.CL

TL;DR: 本文提出HyperbolicRAG，将双曲几何融入图结构的检索增强生成框架，实现层级感知的节点表示和跨空间检索信号融合，显著提升了问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有图基的检索增强生成方法虽然能捕获语义相似性，但缺乏对复杂知识图谱中层级抽象关系的几何表征，限制了结构化推理能力。引入双曲几何旨在弥补这一不足。

Method: 提出了三个关键设计：1）基于Poincare流形的节点深度感知表示学习，将语义相似性与层级包含关系对齐；2）无监督对比性正则化，保持抽象层级之间的几何一致性；3）互排名融合机制，结合欧几里得和双曲空间的检索信号，强化跨空间一致性。

Result: 在多个问答基准测试上，HyperbolicRAG显著优于包括标准RAG和现有图增强基线的多种竞争模型，验证了该方法的有效性和优越性。

Conclusion: HyperbolicRAG通过将双曲几何引入图结构的检索增强生成框架，有效提升了模型对层级关系及语义细粒度的捕捉能力，显著优于传统的欧几里得嵌入方法，提升了领域知识问答表现。

Abstract: Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.

</details>


### [52] [Concept than Document: Context Compression via AMR-based Conceptual Entropy](https://arxiv.org/abs/2511.18832)
*Kaize Shi,Xueyao Sun,Xiaohui Tao,Lin Li,Qika Lin,Guandong Xu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于抽象意义表示（AMR）图的无监督上下文压缩方法，用于减少冗余信息，提升大语言模型在长文本处理中，尤其是检索增强生成（RAG）中的推理准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 处理长上下文时信息过载和冗余内容影响推理准确性和计算效率，特别是在检索增强生成场景中，需要有效压缩上下文以提高性能。

Method: 构建上下文的AMR图，计算每个节点的概念熵，筛选出重要节点，形成更精炼且语义集中的上下文，进而用于生成任务。

Result: 在PopQA和EntityQuestions数据集上，方法取得了比基础和其他对比方法更高的准确率，同时大幅减少了上下文长度，展示了AMR基础语义熵的实用价值。

Conclusion: 利用AMR图中的节点级熵来评估概念重要性，筛选核心语义节点，成功实现了语义聚焦的上下文压缩，实验证明该方法在提升准确性的同时显著减少了上下文长度，效果优于传统方法。

Abstract: Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.

</details>


### [53] [A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis](https://arxiv.org/abs/2511.18843)
*Heger Arfaoui,Mohammed Iheb Hergli,Beya Benzina,Slimane BenMiled*

Main category: cs.CL

TL;DR: 本文提出了一个用于焦点小组讨论文本的神经主题建模计算框架，解决了超参数敏感性、模型稳定性和可解释性验证等问题，并通过系统评估和人类专家验证确认方法有效。


<details>
  <summary>Details</summary>
Motivation: 传统焦点小组讨论分析依赖人工编码，费时且难以扩展和复制，急需自动化且可重复的方法提升分析效率与质量。

Method: 基于BERTopic对突尼斯HPV疫苗认知的十个焦点小组（1,076条发言）文本进行分析，系统评估27组超参数配置，利用30次自助法重采样评估模型稳定性，采用层级合并策略改善主题稳定性与连贯性，最后通过三位领域专家进行人类可解释性验证。

Result: 揭示了超参数选择对模型影响显著，合理指标与分析目标需匹配，层级合并策略提升主题连贯性（0.558对比0.539），专家评审显示高评分一致性（ICC=0.79，Cohen's kappa=0.578），代码和数据公开支持复现和扩展。

Conclusion: 该计算框架有效提高了焦点小组文本分析的可扩展性和重现性，实现了模型稳定性与解读一致性的平衡，主题质量经专家验证效果良好。

Abstract: Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.

</details>


### [54] [Large Language Models for the Summarization of Czech Documents: From History to the Present](https://arxiv.org/abs/2511.18848)
*Václav Tran,Jakub Šmíd,Ladislav Lenc,Jean-Pierre Salmon,Pavel Král*

Main category: cs.CL

TL;DR: 本文利用大型语言模型和翻译策略改进了捷克语文本摘要，推出了新的历史捷克摘要数据集，推动了捷克语低资源及历史文本摘要研究。


<details>
  <summary>Details</summary>
Motivation: 捷克语文本摘要研究较少，尤其是历史文献领域，受限于语言复杂性和高质量标注数据的缺乏。

Method: 本文采用了大型语言模型Mistral和mT5进行捷克语文本摘要，同时提出基于翻译的摘要方法，将捷克文本翻译成英文后进行摘要，再翻译回捷克语。

Result: 大型语言模型在SumeCzech数据集上实现了新的最先进表现，且新建的Posel od Čerchova历史文本摘要数据集为该领域提供了基准和基线。

Conclusion: 通过利用大型语言模型和引入新的历史捷克文本摘要数据集，本文在捷克语文本摘要领域，尤其是历史文献处理中取得了新的突破，推动了捷克语低资源语言摘要研究的发展。

Abstract: Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.
  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od Čerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.
  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.

</details>


### [55] [Cognitive Alpha Mining via LLM-Driven Code-Based Evolution](https://arxiv.org/abs/2511.18850)
*Fengyuan Liu,Huang Yi,Sichun Luo,Yuqi Wang,Yazheng Yang,Xinye Li,Zefa Hu,Junlan Feng,Qi Liu*

Main category: cs.CL

TL;DR: 本文提出结合大语言模型推理和进化搜索的认知alpha挖掘框架，显著提升金融预测信号的发现效果与解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高维度和低信噪比的金融数据中发掘有效预测信号存在局限，模型不透明且泛化差，缺乏广泛且结构化的人类式探索。

Method: 结合代码级alpha表示、基于大语言模型(LLM)推理和进化搜索，形成认知alpha挖掘框架CogAlpha。通过多阶段提示和金融反馈，迭代细化、变异和重组alpha候选。

Result: CogAlpha在A股实验中发现的alpha在预测准确率、鲁棒性和泛化能力上均优于现有方法，实现了更深入思考和经济可解释的alpha发现。

Conclusion: 将进化优化与LLM推理结合，增强了alpha搜索空间和质量，助力自动化且可解释的alpha发现，代码将开源。

Abstract: Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.

</details>


### [56] [FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models](https://arxiv.org/abs/2511.18852)
*Masoomali Fatehkia,Enes Altinisik,Husrev Taha Sencar*

Main category: cs.CL

TL;DR: FanarGuard是一种考虑文化背景的双语内容审核过滤器，在阿拉伯语和英语安全与文化对齐任务上表现出色，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有内容审核过滤器大多忽略文化背景，容易导致在多元文化环境下的误判，迫切需要开发能兼顾安全性和文化背景的多语言过滤器，提升内容审核的准确性与适用性。

Method: 通过收集468K+对经LLM评审标注无害性和文化意识的数据，训练双语审核模型，并构建阿拉伯文化基准测试，系统评估模型的文化对齐能力和安全性能。

Result: 本文提出了FanarGuard，一种针对阿拉伯语和英语的双语内容审核过滤器，能够评估安全性和文化一致性。构建了468K+对带有无害性和文化意识评分的提示-响应数据集，并训练了两个过滤器变体。通过开发首个面向阿拉伯文化语境的基准测试，验证了FanarGuard在文化对齐上的优越表现。评测结果显示，该过滤器与人工标注的符合度超过标注者之间的可靠性，同时在安全性测试上达到最新技术水平。此研究强调了文化意识在内容审核中的重要性，并为实现更具上下文敏感性的审核机制提供了实用方案。

Conclusion: 将文化意识融入内容审核显著提升了过滤器的准确度和可靠性，FanarGuard为开发更具文化敏感性的内容审核工具提供了有效方案。

Abstract: Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.

</details>


### [57] [Generating Reading Comprehension Exercises with Large Language Models for Educational Applications](https://arxiv.org/abs/2511.18860)
*Xingyu Huang,Fei Jiang,Jianli Xiao*

Main category: cs.CL

TL;DR: 提出了RCEG框架，自动生成高质量个性化英语阅读理解练习题，显著提升内容质量和教学适应性。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型快速发展，教育领域对智能且个性化的阅读理解练习需求增加，促进自动生成高质量学习内容成为研究动机。

Method: 采用微调的大语言模型生成内容候选，通过判别器筛选最佳项以提高内容质量，并构建专项数据集与多维评价指标进行评测。

Result: 本论文提出了一个名为RCEG（Reading Comprehension Exercise Generation）的新型大语言模型框架，能够自动生成高质量且个性化的英语阅读理解练习题。通过微调LLMs生成内容候选项，利用判别器筛选最佳内容，显著提升生成内容的质量。构建了专门的英语阅读理解数据集，采用内容多样性、事实准确性、语言毒性和教学对齐度等多维评价指标进行性能测试。实验结果表明RCEG在生成的练习题的相关性和认知适当性方面有显著提升。

Conclusion: RCEG框架通过微调和判别器联合方法，能够生成相关性强且认知恰当的英语阅读理解练习题，实验验证其有效性。

Abstract: With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.

</details>


### [58] [Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models](https://arxiv.org/abs/2511.18864)
*Yang Xiang,Yixin Ji,Juntao Li,Min Zhang*

Main category: cs.CL

TL;DR: 本文首次实证研究了大型推理模型的剪枝问题，提出基于选择性自生成推理数据的校准策略，有效提升了剪枝后模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型（LRMs）具有出色的推理能力，但长链思考过程带来高计算开销，现有剪枝技术主要针对大型语言模型，LRMs剪枝尚未深入研究。

Method: 利用自生成的推理数据进行校准，从而提升剪枝效果；提出了选择性自生成推理（SSGR）数据构建策略，筛选合适的推理数据用于校准。

Result: 采用SSGR策略后，剪枝后的LRMs在DeepSeek-R1-Distill模型系列的推理能力提升了10%-13%。

Conclusion: 通过设计有效的自生成推理数据进行校准，能够显著提升LRMs的剪枝效果，克服了传统剪枝方法的局限。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.

</details>


### [59] [CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation](https://arxiv.org/abs/2511.18889)
*Jingqian Zhao,Bingbing Wang,Geng Tu,Yice Zhang,Qianlong Wang,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出CoreEval方法，通过利用最新知识库自动更新数据，解决了语言模型评估中因数据污染导致的性能高估问题。


<details>
  <summary>Details</summary>
Motivation: 数据污染导致语言模型在自然语言处理任务中的评估不公平，因为模型在训练过程中可能接触到测试数据，导致性能被高估。

Method: 从原始数据中提取实体关系，利用GDELT数据库获取最新知识，重新构建并整合数据，通过反复的数据反射机制验证和细化标签，保证数据语义一致和任务相关。

Result: 提出了CoreEval，一种自动更新数据的污染鲁棒评估方法，通过从原始数据提取实体关系并利用最新知识库（GDELT）更新数据，确保数据的语义一致性和任务相关性，并通过反复验证标签提高数据质量。实验证明CoreEval有效缓解了数据污染导致的性能高估问题。

Conclusion: CoreEval能够有效抵御数据污染，确保语言模型评估的公平性和准确性，具有较强的实用价值和推广潜力。

Abstract: Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \textbf{CoreEval}, a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.

</details>


### [60] [Reproducibility Study of Large Language Model Bayesian Optimization](https://arxiv.org/abs/2511.18891)
*Adam Rychert,Gasper Spagnolo,Evgenii Posashkov*

Main category: cs.CL

TL;DR: 该研究通过实验证实LLAMBO框架在使用Llama 3.1 70B时依然有效，文本上下文信息和大型模型容量是关键因素。


<details>
  <summary>Details</summary>
Motivation: 验证并复现LLAMBO框架的效果，探索使用开源大型语言模型Llama 3.1 70B替代GPT-3.5的可行性。

Method: 复现了核心实验，使用Llama 3.1 70B代替GPT-3.5进行文本编码，分析模型性能、消融文本上下文影响、比较采样器效果，并测试较小模型的表现。

Result: 确认了LLAMBO的主要结论：文本上下文起始显著改善早期表现和稳定性，LLAMBO的判别代理虽弱于GP或SMAC，但通过跨任务语义先验获得优势，文字上下文缺失会显著降低性能，LLAMBO的采样器优于传统方法，较小模型不稳定。

Conclusion: LLAMBO架构对语言模型骨干更换具有鲁棒性，Llama 3.1 70B是可靠的替代，文本上下文对性能提升至关重要。

Abstract: In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.
  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.
  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.

</details>


### [61] [Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs](https://arxiv.org/abs/2511.18931)
*Sahil Kale*

Main category: cs.CL

TL;DR: 集成网络搜索提升了模型的事实准确度，但仍存在过度自信、漏检必需搜索及初始查询效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型集成了网络搜索以提供实时答案，但其在实际需要时是否能高效调用搜索尚不明确。

Method: 设计基于时间锚定的静态与动态问题集，评估商业模型在无访问内部状态下的搜索使用必要性及有效性。

Result: 内置网络搜索显著提升了准确率，但模型在置信度校准上表现不佳，且在查询时过于自信且查询失败后表现下降。

Conclusion: 网络搜索作为低延迟验证层效果较好，但作为可靠分析工具尚需改进。

Abstract: Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.

</details>


### [62] [Skeletons Matter: Dynamic Data Augmentation for Text-to-Query](https://arxiv.org/abs/2511.18934)
*Yuchen Ji,Bo Xu,Jie Shi,Jiaqing Liang,Deqing Yang,Yu Mao,Hai Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: 提出统一的Text-to-Query任务范式和基于查询骨架的动态数据增强方法，有效提升跨查询语言语义解析性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多聚焦单一查询语言，导致方法泛化能力有限，缺乏跨语言通用性。

Method: 定义了Text-to-Query任务范式，统一了不同查询语言的语义解析任务；提出了以查询骨架为共通优化目标的动态数据增强框架，通过针对模型弱点合成训练数据。

Result: 在四个Text-to-Query基准测试中，用少量合成数据实现了最新的性能，展示了方法的高效性和通用性。

Conclusion: 方法通过诊断模型骨架处理弱点，合成针对性训练数据，实现了不同查询语言间的良好泛化和高性能表现，为统一研究Text-to-Query任务奠定基础。

Abstract: The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.

</details>


### [63] [Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials](https://arxiv.org/abs/2511.18937)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识的图形化方法，通过在MedDRA上增加隐藏的医学知识层（Safeterm），实现临床试验中不良事件的自动聚类和关联分析，提高了信号检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有MedDRA分组和不良事件分析效率低且准确性有限，迫切需要融合医学知识层以提升临床试验中不良事件的审查效率与解读质量。

Method: 通过添加隐藏的医学知识层Safeterm，构建包含语义关系的二维图谱，实现不良事件首选术语的自动聚类，并计算治疗特异性的失比例指标，利用精度加权聚合得到簇级EBGM值，配合语义图和期望性与失比例图进行信号检测。

Result: 在三个历史临床试验案例中，自动化方法成功识别出所有预期的安全信号，证明该知识增强模型能有效改进信号检测流程和结果。

Conclusion: 在三项临床试验中验证，该方法准确恢复了所有预期的安全信号，表明通过在MedDRA中加入医学知识层，能显著提升不良事件解读的清晰度、效率与准确性。

Abstract: We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.

</details>


### [64] [Logic of Montage](https://arxiv.org/abs/2511.19063)
*Hayami Takahashi,Kensuke Takahashi*

Main category: cs.CL

TL;DR: 提出一种基于动态矛盾结构和蒙太奇操作的情感表达新形式，结合强度概念构建理论框架，以补充自然语言表达情感。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言表达情感的方式存在不足，本文旨在开发一种动态且多层次的情感表达形式，作为自然语言的补充，更精准地反映和传达个体情绪状态。

Method: 建立矛盾结构效应的概念框架，定义蒙太奇操作及其产生的结构效应，引入哲学和语言学中的“强度”与“力”作为模型要素，构建系统间词汇导入的理论架构，并通过具体案例展示。

Result: 本文提出了一种作为自然语言补充的情感表达形式，称为“矛盾结构效应”。该效应具有动态性，表现为愉快或不愉快的感觉，且不愉快的趋避方向被视为意志的伪表达。该结构可通过“蒙太奇”操作重叠形成更广义的“结构效应”，并引入了“强度”这一元素以量化影响力。理论框架采用了系统间词汇导入模型，并借鉴了语言哲学中的“力”概念。最后，通过教育提升的例子演示了该结构效应的具体应用。

Conclusion: 通过引入矛盾结构效应及其叠加的蒙太奇机制，并结合强度元素，本文构建了一个辅助自然语言表达情感的理论模型，验证了该模型在实际情境中的适用性。

Abstract: In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form "Effect of Contradictory Structure." "Effect of Contradictory Structure" is not static but dynamic. Effect in "Effect of Contradictory Structure" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, "Effect of Contradictory Structure" can be overlapped with each other. This overlapping operation is called "montage." A broader "Structure" that includes related "Effect of Contradictory Structure" and "Effect of Structure" are set up. Montage produces "Effect of Structure". In montage, it is necessary to set something like "strength," so we adopted Deleuze and Deleuze/Guattari's word "intensity" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of "intensity" through Austin's use of the word "force." "Effect of Structure" process is demonstrated using the example of proceeding to the next level of education.

</details>


### [65] [GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning](https://arxiv.org/abs/2511.19078)
*Yutong Li,Yitian Zhou,Xudong Wang,GuoChen,Caiyan Qin*

Main category: cs.CL

TL;DR: 本文提出GraphMind，一种结合GNN和大语言模型的动态图框架，用于多步推理中的定理选择和中间结论生成，显著提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在多步推理中缺乏明确且动态的中间推理状态结构表示，限制了上下文感知的定理选择和迭代结论生成能力。

Method: 提出GraphMind，一种结合图神经网络和大语言模型的动态图框架，将推理过程建模为异构演化图，通过GNN编码当前推理状态并利用语义匹配进行定理选择，实现闭环结构化推理。

Result: GraphMind在多步推理任务中显著优于现有方法，在多个问答数据集上表现出一致的性能提升，验证了其有效性和泛化能力。

Conclusion: 通过动态图结构和图神经网络的结合，GraphMind实现了上下文感知且可解释的多步推理机制，提升了大语言模型在复杂推理任务中的表现。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.

</details>


### [66] [A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis](https://arxiv.org/abs/2511.19083)
*Wenxuan Mu,Jinzhong Ning,Di Zhao,Yijia Zhang*

Main category: cs.CL

TL;DR: KDR-Agent是一种结合知识检索、实体消歧与反思的多智能体框架，用于提升低资源多域条件下的命名实体识别性能，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的内示学习命名实体识别方法存在依赖动态检索标注样本、泛化能力不足以及无法有效利用外部知识和解决实体歧义等问题，亟需一种综合方法加以解决。

Method: 提出多智能体框架KDR-Agent，包括知识检索、歧义消解和反思分析三部分，由中央计划者协调专门智能体合作完成，利用自然语言类型定义和实体级对比示例辅助模型推理。

Result: 本文提出了KDR-Agent，一种结合知识检索、消歧与反思分析的多智能体框架，用于解决低资源多域条件下的命名实体识别问题。该方法利用自然语言类型定义和实体级对比示例，减少对大量标注数据的依赖。通过中央计划者协调各智能体从维基百科检索领域知识、进行歧义消解及结构化自我评估，显著提升了模型在不同领域及少样本环境下的表现。实验结果表明，KDR-Agent优于现有的零样本及少样本内示学习方法。

Conclusion: KDR-Agent通过整合知识检索、歧义消解和反思机制，显著提升了多域低资源条件下的命名实体识别效果，展示了较强的泛化能力和实用价值。

Abstract: In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.

</details>


### [67] [DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and Cascaded Reinforcement for Interpretable and Scalable RLHF](https://arxiv.org/abs/2511.19097)
*Ziyuan Gao,Di Liang,Xianjie Wu,Philippe Morel,Minlong Peng*

Main category: cs.CL

TL;DR: DeCoRL通过并行模块化推理和独立奖励打分，实现更高效、更可解释的Chain-of-Thought推理，显著提升推理速度和性能，降低能耗。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的Chain-of-Thought推理方法存在黑盒问题难以追踪错误贡献，且顺序解码导致时间复杂度高，无法满足复杂推理任务的实时需求。

Method: 提出DeCoRL框架，通过并行训练轻量化专门模型来生成推理子步骤，采用模块化奖励函数对各子步骤独立打分，并使用级联DRPO优化协调各奖励以保持步骤间依赖。

Result: DeCoRL在RM-Bench、RMB和RewardBench等数据集上取得了领先性能，比大规模模型更优，推理速度提升3.8倍，解释性提升22.7%，能耗降低72.4%，吞吐量提升68%。

Conclusion: DeCoRL成功实现了复杂推理系统的实时部署，解决了传统方法中的黑盒与顺序瓶颈问题，增强了推理效率、可解释性和资源利用率。

Abstract: Existing reinforcement learning methods for Chain-of-Thought reasoning suffer from two critical limitations. First, they operate as monolithic black boxes that provide undifferentiated reward signals, obscuring individual step contributions and hindering error diagnosis. Second, sequential decoding has O(n) time complexity. This makes real-time deployment impractical for complex reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated Reinforcement Learning), a novel framework that transforms reasoning from sequential processing into collaborative modular orchestration. DeCoRL trains lightweight specialized models to generate reasoning sub-steps concurrently, eliminating sequential bottlenecks through parallel processing. To enable precise error attribution, the framework designs modular reward functions that score each sub-step independently. Cascaded DRPO optimization then coordinates these rewards while preserving inter-step dependencies. Comprehensive evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and RewardBench, outperforming existing methods including large-scale models. DeCoRL delivers 3.8 times faster inference while maintaining superior solution quality and offers a 22.7\% improvement in interpretability through explicit reward attribution. These advancements, combined with a 72.4\% reduction in energy consumption and a 68\% increase in throughput, make real-time deployment of complex reasoning systems a reality.

</details>


### [68] [A symbolic Perl algorithm for the unification of Nahuatl word spellings](https://arxiv.org/abs/2511.19118)
*Juan-José Guzmán-Landa,Jesús Vázquez-Osorio,Juan-Manuel Torres-Moreno,Ligia Quintana Torres,Miguel Figueroa-Saavedra,Martha-Lorena Avendaño-Garrido,Graham Ranger,Patricia Velázquez-Morales,Gerardo Eugenio Sierra Martínez*

Main category: cs.CL

TL;DR: 本文提出一种基于符号模型的Nawatl文本自动正字法统一方法，并通过语义任务评估验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 解决Nawatl文本正字法不统一的问题

Method: 基于先前句法分析算法和多种Nawatl正字法文本语料库，使用符号正则表达式实现自动统一算法，并设计手工评估协议验证质量。

Result: 提出了基于符号正则表达式的自动统一算法，并用语义任务的手工评估验证了效果，结果令人鼓舞

Conclusion: 算法成功实现了Nawatl文本的正字法统一，评估结果显示统一句子质量良好。

Abstract: In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $π$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences

</details>


### [69] [On the Optimality of Discrete Object Naming: a Kinship Case Study](https://arxiv.org/abs/2511.19120)
*Phong Le,Mees Lindeman,Raquel G. Alhama*

Main category: cs.CL

TL;DR: 本文提出了一个新的信息论模型，证明并实证了自然语言命名系统中信息与复杂度的最优权衡条件及其在学习通信系统中的实现。


<details>
  <summary>Details</summary>
Motivation: 解决以往研究中关于最优听者和普遍交流需求的简化假设，探索自然语言命名系统中的信息量与复杂度之间的权衡。

Method: 引入一个信息论框架用于离散物体命名系统，结合发散通信中的指称游戏方法，并聚焦亲属语义领域进行实证分析。

Result: 理论证明条件成立且实验证明该最优性在学习的通信系统中自然出现。

Conclusion: 最佳的信息权衡只有在听者的解码器与说话者的贝叶斯解码器等价时才能实现。

Abstract: The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.

</details>


### [70] [Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis](https://arxiv.org/abs/2511.19122)
*Yaping Chai,Haoran Xie,Joe S. Qin*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的情感类别多任务分析方法，通过引入情绪维度和情绪精炼机制提升细粒度情感分析表现。


<details>
  <summary>Details</summary>
Motivation: 现有情感极性分析忽略潜在情绪维度，难以捕捉特定类别的细粒度情感信号。

Method: 提出基于Ekman六种基本情绪的多任务学习框架，利用大语言模型生成情绪描述，并通过VAD空间映射加以精炼。

Result: 实验验证了该方法在多个基准数据集上的优越性，显著超越强基线。

Conclusion: 引入情绪维度和基于VAD框架的情绪精炼机制显著提升了面向类别的情感分析效果，优于现有基线。

Abstract: Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.

</details>


### [71] [Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization](https://arxiv.org/abs/2511.19131)
*Zijian Wang,Yanxiang Ma,Chang Xu*

Main category: cs.CL

TL;DR: 本文提出了一种基于概率条件生成的隐藏状态操控方法，用以激发基础大型语言模型的链式思维推理能力，解决了现有方法的局限性，在多个推理任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 基础大型语言模型缺乏专门训练难以进行复杂推理，而现有隐藏状态操控方法过于刚性，容易导致模型生成质量下降，亟需一种既能激发推理潜力又能保持语言质量的新方法。

Method: 将隐藏状态操控视为一个带平衡似然和先验正则化的优化问题，通过概率条件生成框架引导隐藏状态走向推理导向的轨迹，从而实现Chain-of-Thought推理。

Result: 在数学、常识和逻辑推理等多个基准测试中，该方法均优于现有线性激活操控等技术，展示了理论上的合理性和实践中的有效性。

Conclusion: 该方法通过优化隐藏状态在推理轨迹上的引导，平衡了生成文本的合理性与语义连贯性，显著提升了基础大型语言模型的多步推理能力。

Abstract: Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.

</details>


### [72] [Representational Stability of Truth in Large Language Models](https://arxiv.org/abs/2511.19166)
*Samantha Dies,Courtney Maynard,Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 该文提出了“表征稳定性”指标，用于评估大语言模型在真假判断上的一致性，发现模型对熟悉内容的真值判断更稳定，不熟悉内容则波动较大。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏关于大语言模型内部如何区分真与非真的表征稳定性的理解，本文旨在诊断并提升模型在语义不确定情境下保持真值判断一致性的能力，而非单纯追求输出准确性。

Method: 通过训练线性探针对模型激活进行真伪分类，并在标签定义受控变更下测量决策边界的移动，分析模型对不同类型“非真”陈述（熟悉的虚构陈述与陌生陈述）的反应差异。

Result: 本文研究了大语言模型在区分真、假以及非真非假的内容时，其内部概率表示的稳定性问题。通过线性探针训练和标签干扰测试，分析了模型对不同类型“非真”陈述的表现差异，发现模型对熟悉的虚构陈述表现出较高的稳定性，而对不熟悉的陈述边界变化显著，表明稳定性更多源于认知熟悉度而非语言形式。

Conclusion: 大语言模型的真值表征稳定性主要依赖于认知熟悉度，对陌生信息的真实性判断存在较大波动，这为未来模型审计和训练提供了新的诊断工具。

Abstract: Large language models (LLMs) are widely used for factual tasks such as "What treats asthma?" or "What is the capital of Latvia?". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\leq 8.2\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.

</details>


### [73] [In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations](https://arxiv.org/abs/2511.19232)
*Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou*

Main category: cs.CL

TL;DR: 该论文分析了transformer模型如何在不同层次检测语义异常，发现异常信号在中层显著增强，并与人类语言处理顺序一致。


<details>
  <summary>Details</summary>
Motivation: 探究transformer模型如何以及在哪一层检测出句子的语义异常。

Method: 使用针对性语料库测试预训练语言模型phi-2，以线性探针逐层检测模型隐藏状态中对语义异常的编码，并分析表示维度的变化。

Result: 模型的前1/3层难以区分合理与不合理句子结尾，辨识能力在中间层明显提高，并在靠近顶部层达到峰值；语义异常先增加表示的维度，随后在中层发生维度塌缩，可能表示经历了探索到快速整合的过程。

Conclusion: 模型对语义异常的检测与人类语言处理过程相似，符合心理语言学中语义异常晚于句法解析被识别的观点，反映出在线处理的阶段性。

Abstract: How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.

</details>


### [74] [MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset](https://arxiv.org/abs/2511.19317)
*Md. Tanzim Ferdous,Naeem Ahsan Chowdhury,Prithwiraj Bhattacharjee*

Main category: cs.CL

TL;DR: 本文构建了一个包含超过54,000篇跨多个领域的孟加拉文文章及摘要的数据集，旨在提升孟加拉文摘要生成的多样性和适应性。通过训练多种深度学习模型验证了该数据集的有效性，推动低资源语言的自然语言处理发展。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于新闻领域，风格单一，难以适应真实孟加拉文文本的多样性，且当前信息量大，需要有效的摘要系统缓解信息过载。

Method: 收集来自博客和多家报纸的超过54,000篇文章及其摘要，涵盖多种领域与写作风格，基于此数据集训练并评估LSTM、BanglaT5-small、MTS-small等深度学习和迁移学习模型。

Result: 多领域、多风格的数据集构建成功，训练模型表现良好，证明数据集具备成为孟加拉文摘要任务基准的潜力，并有助于低资源语言NLP资源丰富。

Conclusion: 开发的多领域孟加拉文摘要数据集有效提升了摘要生成的多样性与适应性，为孟加拉文自然语言处理提供了重要基准和资源。

Abstract: This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.

</details>


### [75] [Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces](https://arxiv.org/abs/2511.19333)
*Shaltiel Shmidman,Asher Fredman,Oleg Sudakov,Meriem Bendris*

Main category: cs.CL

TL;DR: 利用大型模型生成的推理轨迹作为监督数据训练中型模型，比较不同轨迹来源对模型数学推理能力的影响。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型生成的高质量推理轨迹作为监督数据，降低人工标注成本，提升中等规模语言模型的推理能力。

Method: 通过在推理阶段利用额外计算资源生成中间推理轨迹，对中小型语言模型进行后训练，从而提升其复杂数学问题的解题能力。

Result: 对比了使用DeepSeek-R1和gpt-oss生成的推理轨迹作为训练数据后，中等规模模型在数学问题上的准确率和推理效率，发现两种轨迹对模型性能存在差异。

Conclusion: 大型语言模型生成的推理轨迹可有效提升中等规模模型的数学推理能力，不同来源的轨迹在性能和效率上存在权衡。

Abstract: Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.

</details>


### [76] [DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research](https://arxiv.org/abs/2511.19399)
*Rulin Shao,Akari Asai,Shannon Zejiang Shen,Hamish Ivison,Varsha Kishore,Jingming Zhuo,Xinran Zhao,Molly Park,Samuel G. Finlayson,David Sontag,Tyler Murray,Sewon Min,Pradeep Dasigi,Luca Soldaini,Faeze Brahman,Wen-tau Yih,Tongshuang Wu,Luke Zettlemoyer,Yoon Kim,Hannaneh Hajishirzi,Pang Wei Koh*

Main category: cs.CL

TL;DR: 本文提出了RLER方法训练的DR Tulu-8B模型，显著提升了多领域长篇深度研究任务的表现，且开源了相关资源推动后续研究。


<details>
  <summary>Details</summary>
Motivation: 现有公开的深度研究模型多基于短篇且易验证的问答任务训练，对现实中需要长篇、复杂推理的任务表现不足，亟需有效训练方法提升长篇研究能力。

Method: 采用“带演进评分标准的强化学习”（RLER）方法，构建与策略模型共同演进的评分标准，从而提供更具辨别力的实时反馈，直接训练模型完成开放式长篇答疑任务。

Result: DR Tulu-8B在科学、医疗等四个长篇深度研究基准测试中明显优于现有公开模型，并且达到甚至超过了专有系统水平，同时模型更小且查询成本更低。

Conclusion: 本论文提出的深度研究模型DR Tulu-8B在开放式、长篇深度研究任务中表现优异，超越现有公开模型，并匹配或超过专有系统，且成本更低。

Abstract: Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.

</details>


### [77] [Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration](https://arxiv.org/abs/2511.19417)
*James Y. Huang,Sheng Zhang,Qianchu Liu,Guanghui Qin,Tinghui Zhu,Tristan Naumann,Muhao Chen,Hoifung Poon*

Main category: cs.CL

TL;DR: 本文提出了BeMyEyes框架，通过协同高效的视觉语言模型(VLM)感知器与强大的大语言模型(LLM)推理器，实现多模态推理能力的扩展。该方法避免了训练大规模多模态模型的高成本，并保持LLM的泛化与推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大规模模型开发成本高，且小型VLM缺乏广泛知识与推理能力，如何高效扩展LLM的多模态推理能力成为挑战。

Method: 本文提出了一个多代理框架BeMyEyes，分别由高效的VLM感知器和强大的LLM推理器组成，通过对话协作进行多模态推理；并设计了数据合成与监督微调流程训练感知器，以实现两者的有效协作。

Result: 实验表明，BeMyEyes框架能使文本模型结合视觉感知能力，在知识密集的多模态任务中超越GPT-4o等大型独有模型，展示了其有效性及可扩展性。

Conclusion: BeMyEyes框架通过多代理协作，有效融合感知与推理能力，提升了LLM在多模态任务中的表现，实现了轻量且开源的多模态推理系统，优于大型专有模型。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [78] [The Software Engineering Simulations Lab: Agentic AI for RE Quality Simulations](https://arxiv.org/abs/2511.17762)
*Henning Femmer,Ivan Esau*

Main category: cs.SE

TL;DR: 该论文提出利用具代理性的人工智能模拟器来扩展需求工程的质量研究，以克服传统实证数据稀缺和成本高的问题，并展示了初步的可行性研究成果。


<details>
  <summary>Details</summary>
Motivation: 需求工程质量研究缺乏系统的实证数据，且随着AI介入需求消费，传统需求质量因素和评估方法面临挑战，亟需新工具支持更科学的需求质量研究。

Method: 通过开发基于事件驱动的定性模拟器，利用标准代理在随机动态环境中复制软件工程流程，进行快速且简化的需求工程质量模拟研究。

Result: 提出了具代理性AI模拟的概念框架、研究路线图和原型系统，并通过初步的可行性研究验证了该方法在需求工程研究中的应用潜力。

Conclusion: 利用具代理性的人工智能模拟可以有效地仿真需求工程过程，促进需求质量模型的建立和评估，尤其适应AI驱动发展的新需求消费方式。

Abstract: Context and motivation. Quality in Requirements Engineering (RE) is still predominantly anecdotal and intuition-driven. Creating a solid requirements quality model requires broad sets of empirical evidence to evaluate quality factors and their context. Problem. However, empirical data on the detailed effects of requirements quality defects is scarce, since it is costly to obtain. Furthermore, with the advent of AI-based development, the requirements quality factors may change: Requirements are no longer only consumed by humans, but increasingly also by AI agents, which might lead to a different efficient and effective requirements style. Principal ideas. We propose to extend the RE research toolbox with Agentic AI simulations, in which software engineering (SE) processes are replicated by standardized agents in stochastic, dynamic, event-driven, qualitative simulations. We argue that their speed and simplicity makes them a valuable addition to RE research, although limitations in replicating human behavior need to be studied and understood. Contribution. This paper contributes a first concept, a research roadmap, a prototype, and a first feasibility study for RE simulations with agentic AI. Study results indicate that even a naive implementation leads to executable simulations, encouraging technical improvements along with broader application in RE research.

</details>


### [79] [Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI](https://arxiv.org/abs/2511.17836)
*Edwin Sundberg,Thea Ekmark,Workneh Yilma Ayele*

Main category: cs.SE

TL;DR: 该论文提出了一种基于设计科学研究方法的API设计规则检测工具S.E.O.R.A，自动检测OpenAPI规范中的结构性违规，支持规则定制，提升非功能性API需求的早期验证与质量保障。


<details>
  <summary>Details</summary>
Motivation: RESTful API在企业软件系统中广泛应用，但API设计质量评估仍依赖手工和随意过程，尤其在早期开发阶段，亟需自动化、标准化的质量验证支持。

Method: 采用设计科学研究方法，通过文献回顾识别75条API设计规则，设计了可配置规则引擎用于检测OpenAPI规范中的结构性违规，并通过结构化实验和主题分析验证工具效果。

Result: 结果表明S.E.O.R.A能够提供可操作和可追踪的反馈，促进需求提取与质量保证流程的结合，提升设计质量验证效率，支持持续合规性。

Conclusion: S.E.O.R.A有效提升了API设计的自动化质量检测能力，促进了非功能性需求的早期验证和企业级系统间的互操作性与治理。

Abstract: RESTful APIs are central in developing interoperable, modular, and maintainable software systems in enterprises today. Also, it is essential to support system evolution, service interoperability, and governance across organizational boundaries to ensure good quality and consistency of these APIs. However, evaluating API design quality, which is part of non-functional requirement tasks, remains a largely manual and ad hoc process, particularly during early development. Using a Design Science Research (DSR) methodology, we elicited user needs, identified 75 API design rules using a literature review, and implemented a configurable rule engine to detect structural violations in OpenAPI specifications. The proposed tool supports organizational adaptability by allowing rules to be customized, enabled, or disabled, enabling integration of domain-specific standards. The evaluation was conducted through structured experiments and thematic analysis involving industry experts. API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems. The results show that S.E.O.R.A facilitates early validation of non-functional API requirements, provides actionable and traceable feedback, and aligns well with requirements elicitation and quality assurance processes. It improves the API design process by automating checks that would otherwise require manual inspection, thus supporting consistent and reusable conformance practices. This work contributes to requirements engineering by operationalizing design principles as verifiable constraints and embedding them into a practical validation tool. Future directions include IDE integration, expanded rule coverage, and real-world deployment to support continuous compliance in agile API development lifecycles.

</details>


### [80] [A Low-Code Methodology for Developing AI Kiosks: a Case Study with the DIZEST Platform](https://arxiv.org/abs/2511.17853)
*SunMin Moon,Jangwon Gim,Chaerin Kim,Yeeun Kim,YoungJoo Kim,Kang Choi*

Main category: cs.SE

TL;DR: 本文提出了一种基于低代码架构、聚焦AI实现的DIZEST方法，用于提升自助终端系统的集成性和性能。


<details>
  <summary>Details</summary>
Motivation: 现代自助终端系统面临集成不足、结构僵化、性能瓶颈及协作框架缺失等重大挑战，亟需新方法提升其灵活性和性能。

Method: 采用DIZEST低代码平台进行直观的工作流设计和AI整合，结合现有平台如Jupyter Notebook、ComfyUI和Orange3进行对比分析。

Result: 实验结果显示DIZEST在多项关键指标上表现优越，实证案例表明其有效提升系统的互操作性、用户体验和部署灵活性。

Conclusion: DIZEST平台在关键性能指标上优于现有平台，实现了自助终端系统的更好互操作性和更灵活的部署，提升了用户体验。

Abstract: This paper presents a comprehensive study on enhancing kiosk systems through a low-code architecture, with a focus on AI-based implementations. Modern kiosk systems are confronted with significant challenges, including a lack of integration, structural rigidity, performance bottlenecks, and the absence of collaborative frameworks. To overcome these limitations, we propose a DIZEST-based approach methodology, a specialized low-code platform that enables intuitive workflow design and seamless AI integration. Through a comparative analysis with existing platforms, including Jupyter Notebook, ComfyUI, and Orange3, we demonstrate that DIZEST delivers superior performance across key evaluation criteria. Our photo kiosk case study further validates the effectiveness of this approach in improving interoperability, enhancing user experience, and increasing deployment flexibility.

</details>


### [81] [Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation](https://arxiv.org/abs/2511.17977)
*Kuangxiangzi Liu,Dhiman Chakraborty,Alexander Liggesmeyer,Andreas Zeller*

Main category: cs.SE

TL;DR: 通过两阶段流水线利用大语言模型，从自然语言协议规范自动生成形式化协议规范，显著提升测试自动化水平和规范可维护性。


<details>
  <summary>Details</summary>
Motivation: 现有的安全和安全关键系统测试依赖于手工从自然语言规范生成测试用例，过程缓慢且易出错；形式规范易于自动化生成测试，但书写和维护困难。

Method: 提出了一个两阶段流水线：第一阶段从自然语言规范中提取协议元素；第二阶段利用协议实现，从提取的元素合成和细化形式协议规范。

Result: 原型AUTOSPEC在五个主流互联网协议（SMTP、POP3、IMAP、FTP和ManageSieve）上的实验展示了该方法的可行性，平均恢复92.8%的客户端消息类型和80.2%的服务器消息类型，消息接受率达81.5%。

Conclusion: 该方法优于端到端LLM测试生成，生成可检查、可追溯、可读且易维护的规范，为自动翻译和测试自动化奠定基础。

Abstract: Safety- and security-critical systems have to be thoroughly tested against their specifications. The state of practice is to have _natural language_ specifications, from which test cases are derived manually - a process that is slow, error-prone, and difficult to scale. _Formal_ specifications, on the other hand, are well-suited for automated test generation, but are tedious to write and maintain. In this work, we propose a two-stage pipeline that uses large language models (LLMs) to bridge the gap: First, we extract _protocol elements_ from natural-language specifications; second, leveraging a protocol implementation, we synthesize and refine a formal _protocol specification_ from these elements, which we can then use to massively test further implementations.
  We see this two-stage approach to be superior to end-to-end LLM-based test generation, as 1. it produces an _inspectable specification_ that preserves traceability to the original text; 2. the generation of actual test cases _no longer requires an LLM_; 3. the resulting formal specs are _human-readable_, and can be reviewed, version-controlled, and incrementally refined; and 4. over time, we can build a _corpus_ of natural-language-to-formal-specification mappings that can be used to further train and refine LLMs for more automatic translations.
  Our prototype, AUTOSPEC, successfully demonstrated the feasibility of our approach on five widely used _internet protocols_ (SMTP, POP3, IMAP, FTP, and ManageSieve) by applying its methods on their _RFC specifications_ written in natural-language, and the recent _I/O grammar_ formalism for protocol specification and fuzzing. In its evaluation, AUTOSPEC recovers on average 92.8% of client and 80.2% of server message types, and achieves 81.5% message acceptance across diverse, real-world systems.

</details>


### [82] [Enhancing Automated Program Repair via Faulty Token Localization and Quality-Aware Patch Refinement](https://arxiv.org/abs/2511.18001)
*Jiaolong Kong,Xiaofei Xie,Yiheng Xiong,Yuekun Wang,Jian Wang*

Main category: cs.SE

TL;DR: 本文提出了TokenRepair，一种结合内部令牌不确定性反思与外部质量反馈的两级细化框架，有针对性地改进自动程序修复，显著提升了修复性能。


<details>
  <summary>Details</summary>
Motivation: 现有大规模语言模型(LLMs)在自动化程序修复(APR)中主要依赖粗粒度外部反馈（如测试结果）来指导补丁生成，缺乏细粒度的内部信号来指出补丁失败的原因或代码中可能错误的部分，导致修复效率低下和错误传播。

Method: 提出了TokenRepair，两级细化框架，结合内部反思以定位可疑或低置信度的令牌和外部反馈进行质量感知的补丁细化。首先通过分析上下文中的令牌不确定性波动进行内部反思，定位错误令牌；然后利用思维链引导的重写技术，仅对这些令牌进行定向细化。同时引入质量感知的外部反馈机制评估补丁质量，过滤低质量补丁，稳定迭代修复过程。

Result: 在Defects4J 1.2上修复了88个错误，在HumanEval-Java上修复了139个错误，性能较前沿方法提升了8.2%至34.9%（Defects4J 1.2）和3.3%至16.1%（HumanEval-Java）。

Conclusion: TokenRepair通过结合细粒度内部信号与质量感知的外部反馈显著提升了自动程序修复的效率和效果，达到了新的最先进性能水平。

Abstract: Large language models (LLMs) have recently demonstrated strong potential for automated program repair (APR). However, existing LLM-based techniques primarily rely on coarse-grained external feedback (e.g.,test results) to guide iterative patch generation, while lacking fine-grained internal signals that reveal why a patch fails or which parts of the generated code are likely incorrect. This limitation often leads to inefficient refinement, error propagation, and suboptimal repair performance. In this work, we propose TokenRepair, a novel two-level refinement framework that enhances APR by integrating internal reflection for localizing potentially faulty tokens with external feedback for quality-aware patch refinement. Specifically, TokenRepair first performs internal reflection by analyzing context-aware token-level uncertainty fluctuations to identify suspicious or low-confidence tokens within a patch. It then applies Chain-of-Thought guided rewriting to refine only these localized tokens, enabling targeted and fine-grained correction. To further stabilize the iterative repair loop, TokenRepair incorporates a quality-aware external feedback mechanism that evaluates patch quality and filters out low-quality candidates before refinement. Experimental results show that TokenRepair achieves new state-of-the-art repair performance, correctly fixing 88 bugs on Defects4J 1.2 and 139 bugs on HumanEval-Java, demonstrating substantial improvements ranging from 8.2% to 34.9% across all models on Defects4J 1.2 and from 3.3% to 16.1% on HumanEval-Java.

</details>


### [83] [MASTEST: A LLM-Based Multi-Agent System For RESTful API Tests](https://arxiv.org/abs/2511.18038)
*Xiaoke Han,Hong Zhu*

Main category: cs.SE

TL;DR: 本文提出了一个名为MASTEST的多智能体系统，结合大语言模型和编程代理自动化完成RESTful API测试全流程。


<details>
  <summary>Details</summary>
Motivation: 随着云原生应用普及，RESTful API测试需求增长，利用大语言模型自动生成和执行测试用例能够提升测试效率和质量。

Method: 采用多智能体架构，将LLM生成的测试场景和脚本与编程代理结合，通过OpenAPI Swagger规范自动生成测试用例、Pytest脚本，执行测试并分析反馈，同时支持人工干预。

Result: 实验表明，DeepSeek在数据类型和状态码检测方面表现优越，GPT-4o在API操作覆盖率最高，测试脚本语法正确率达100%，且仅需少量手动校正，验证了MASTEST系统的有效性。

Conclusion: MASTEST结合GPT-4o和DeepSeek两种大语言模型在API测试中表现优异，实现了高质量的测试场景生成和脚本编写，极大提升了RESTful API测试的效果和可行性。

Abstract: Testing RESTful API is increasingly important in quality assurance of cloud-native applications. Recent advances in machine learning (ML) techniques have demonstrated that various testing activities can be performed automatically by large language models (LLMs) with reasonable accuracy. This paper develops a multi-agent system called MASTEST that combines LLM-based and programmed agents to form a complete tool chain that covers the whole workflow of API test starting from generating unit and system test scenarios from API specification in the OpenAPI Swagger format, to generating of Pytest test scripts, executing test scripts to interact with web services, to analysing web service response messages to determine test correctness and calculate test coverage. The system also supports the incorporation of human testers in reviewing and correcting LLM generated test artefacts to ensure the quality of testing activities. MASTEST system is evaluated on two LLMs, GPT-4o and DeepSeek V3.1 Reasoner with five public APIs. The performances of LLMs on various testing activities are measured by a wide range of metrics, including unit and system test scenario coverage and API operation coverage for the quality of generated test scenarios, data type correctness, status code coverage and script syntax correctness for the quality of LLM generated test scripts, as well as bug detection ability and usability of LLM generated test scenarios and scripts. Experiment results demonstrated that both DeepSeek and GPT-4o achieved a high overall performance. DeepSeek excels in data type correctness and status code detection, while GPT-4o performs best in API operation coverage. For both models, LLM generated test scripts maintained 100\% syntax correctness and only required minimal manual edits for semantic correctness. These findings indicate the effectiveness and feasibility of MASTEST.

</details>


### [84] [Event-Chain Analysis for Automated Driving and ADAS Systems: Ensuring Safety and Meeting Regulatory Timing Requirements](https://arxiv.org/abs/2511.18092)
*Sebastian Dingler,Philip Rehkop,Florian Mayer,Ralf Muenzenberger*

Main category: cs.SE

TL;DR: 本文提出了一种基于事件链的白盒方法，用于自动驾驶系统的时间约束分析，提升了法规符合性和系统设计优化，支持早期验证和模型安全分析。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统和高级驾驶辅助系统需要满足严格的国际法规和标准中的时间约束，以保证车辆安全运行。现有黑盒方法缺乏对系统各功能组件时间行为的透明分析，难以满足法规对体系结构透明性的要求。

Method: 采用基于事件链的白盒分析方法，从系统体系结构角度推导、建模和验证端到端时间约束，通过仿真实现早期验证，结合概率分析生成定量证据。

Result: 提出了一种基于事件链建模的白盒方法，从感知、规划到执行和人机交互，透明分析系统各功能模块的时间行为，实现端到端时间约束的推导、建模和验证。通过详细案例展示了该方法在法规符合性、系统设计优化和基于模型的安全分析中的应用效果，能够早期发现合规问题，系统优化参数，并通过概率分析生成定量证据。

Conclusion: 事件链建模方法有效提升了自动驾驶系统的时间约束管理能力，促进了法规符合性验证和系统设计优化，为基于模型的安全分析提供了支持。

Abstract: Automated Driving Systems (ADS), including Advanced Driver Assistance Systems (ADAS), must fulfill not only high functional expectations but also stringent timing constraints mandated by international regulations and standards. Regulatory frameworks such as UN regulations, NCAP standards, ISO norms, and NHTSA guidelines impose strict bounds on system reaction times to ensure safe vehicle operation. This paper presents a structured, White-Box methodology based on Event-Chain Modeling to address these timing challenges. Unlike Black-Box approaches, Event-Chain Analysis offers transparent insights into the timing behavior of each functional component - from perception and planning to actuation and human interaction. This perspective is also aligned with multiple regulations, which require that homologation dossiers provide evidence that the chosen system architecture is suitable to ensure compliance with the specified requirements. Our methodology enables the derivation, modeling, and validation of end-to-end timing constraints at the architectural level and facilitates early verification through simulation. Through a detailed case study, we demonstrate how this Event-Chain-centric approach enhances regulatory compliance, optimizes system design, and supports model-based safety analysis techniques, with results showing early identification of compliance issues, systematic parameter optimization, and quantitative evidence generation through probabilistic analysis.

</details>


### [85] [Towards a General Framework for HTN Modeling with LLMs](https://arxiv.org/abs/2511.18165)
*Israel Puerta-Merino,Carlos Núñez-Molina,Pablo Mesejo,Juan Fernández-Olivares*

Main category: cs.SE

TL;DR: 本文扩展了LLMs生成自动规划模型能力，提出支持分层规划的L2HP框架，并展示了分层规划生成的低语法有效性，强调了HP领域的挑战和改进需求。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型(LLMs)在自动规划(AP)模型生成方面已有广泛研究，但其在分层规划(HP)中的应用仍不成熟。

Method: 提出L2HP，扩展了L2P库以支持HP模型生成，设计理念强调通用性和可扩展性。同时，设计实验对比LLMs在AP和HP建模能力上的表现。

Result: 在PlanBench数据集上，解析成功率在AP和HP中差异不大（约36%），但HP的语法有效性显著较低（1% vs. 20%），显示HP生成面临更多挑战。

Conclusion: HP模型生成对LLMs构成独特挑战，需进一步研究以提升HP模型生成质量。

Abstract: The use of Large Language Models (LLMs) for generating Automated Planning (AP) models has been widely explored; however, their application to Hierarchical Planning (HP) is still far from reaching the level of sophistication observed in non-hierarchical architectures. In this work, we try to address this gap. We present two main contributions. First, we propose L2HP, an extension of L2P (a library to LLM-driven PDDL models generation) that support HP model generation and follows a design philosophy of generality and extensibility. Second, we apply our framework to perform experiments where we compare the modeling capabilities of LLMs for AP and HP. On the PlanBench dataset, results show that parsing success is limited but comparable in both settings (around 36\%), while syntactic validity is substantially lower in the hierarchical case (1\% vs. 20\% of instances). These findings underscore the unique challenges HP presents for LLMs, highlighting the need for further research to improve the quality of generated HP models.

</details>


### [86] [Establishing Traceability Links between Release Notes & Software Artifacts: Practitioners' Perspectives](https://arxiv.org/abs/2511.18187)
*Sristy Sumana Nath,Banani Roy,Munima Jahan*

Main category: cs.SE

TL;DR: 针对开源软件发布说明与开发工件追溯链接缺失问题，本文构建基准数据集并结合大语言模型自动恢复链接，显著提升追溯恢复精度，并获得开源社区从业者认可。


<details>
  <summary>Details</summary>
Motivation: 开源环境中，贡献者远程异步工作，发布说明与开发工件间的追溯链接常常缺失或断链，导致技术债务管理困难，维护性差。实证调研显示47%发布工件缺少追溯链接，12%链接断裂。

Method: 分析发布说明中的What、Why和How信息，结合大语言模型(LLM)方法，利用时间邻近特性自动建立发布说明与PR、提交、问题之间的追溯链接。构建了包含3500条有效追溯链接的基准数据集，并采用LLM（如Gemini 1.5 Pro）进行追溯恢复。

Result: 提出的方法在恢复PR追溯链接时达到了Precision@1为0.73的高精度值。调查显示，开源从业者中16%高度重视，68%部分重视追溯维护方法的应用价值。

Conclusion: 基于大语言模型和时间邻近特征的方法能有效恢复和维护发布说明与开发工件间的追溯链接，增强技术债务管理和软件维护性，具有较高的实际应用价值。

Abstract: Maintaining traceability links between software release notes and corresponding development artifacts, e.g., pull requests (PRs), commits, and issues, is essential for managing technical debt and ensuring maintainability. However, in open-source environments where contributors work remotely and asynchronously, establishing and maintaining these links is often error-prone, time-consuming, and frequently overlooked. Our empirical study of GitHub repositories revealed that 47% of release artifacts lacked traceability links, and 12% contained broken links. To address this gap, we first analyzed release notes to identify their What, Why, and How information and assessed how these align with PRs, commits, and issues. We curated a benchmark dataset consisting of 3,500 filtered and validated traceability link instances. Then, we implemented LLM-based approaches to automatically establish traceability links of three pairs between release note contents & PRs, release note contents & PRs and release note contents & issues. By combining the time proximity feature, the LLM-based approach, e.g., Gemini 1.5 Pro, achieved a high Precision@1 value of 0.73 for PR traceability recovery. To evaluate the usability and adoption potential of this approach, we conducted an online survey involving 33 open-source practitioners. 16% of respondents rated as very important, and 68% as somewhat important for traceability maintenance.

</details>


### [87] [LLM Assisted Coding with Metamorphic Specification Mutation Agent](https://arxiv.org/abs/2511.18249)
*Mostafijur Rahman Akhond,Gias Uddin*

Main category: cs.SE

TL;DR: 本文提出了变形关系驱动的LLM代理CMA，通过精炼规格和生成受限测试用例，显著提升LLM在代码生成中的准确性和覆盖率，验证了变形关系辅助LLM软件开发的潜力。


<details>
  <summary>Details</summary>
Motivation: LLMs在软件工程中的应用因用户规格不当导致的歧义和不一致性问题影响可靠性，亟需一种方法提升规格的准确性和生成结果的一致性。

Method: 提出了一种基于变形关系的LLM代理系统CMA，该系统系统性地细化任务规格并生成语义受限的测试用例，将变形关系与LLM结合，从而提高生成一致性，减少因规格产生的变异性，区别于传统将变形关系仅用于后期验证的方法。

Result: 在HumanEval-Pro、MBPP-Pro和SWE-Bench_Lite数据集上，结合GPT-4o、Mistral Large、GPT-OSS和Qwen3-Coder等模型，CMA框架最高提升代码生成准确率17%，代码覆盖率最高达99.81%。

Conclusion: 本论文提出的CodeMetaAgent（CMA）框架通过利用变形关系驱动大语言模型（LLMs），显著提升了代码生成的准确性和测试覆盖率，验证了变形关系在辅助基于LLM的软件开发中的有效性。

Abstract: Metamorphic Relations (MRs) serve as a foundational mechanism for generating semantically equivalent mutations. Software engineering has advanced significantly in recent years with the advent of Large Language Models (LLMs). However, the reliability of LLMs in software engineering is often compromised by ambiguities and inconsistencies due to improper user specification. To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases. Our proposed framework uses MRs with LLMs to improve generation consistency and reduce variability caused by specifications, unlike the traditional use of MRs as post validations. Our framework has been evaluated on the HumanEval-Pro, MBPP-Pro, and SWE-Bench_Lite datasets using the GPT-4o, Mistral Large, GPT-OSS, and Qwen3-Coder models. It improved code generation accuracy by up to 17% and achieved code coverage gains of up to 99.81%. These results show that metamorphic relations can be a simple but effective guide in assisting LLM-based software development.

</details>


### [88] [Can Large Language Models Solve Path Constraints in Symbolic Execution?](https://arxiv.org/abs/2511.18288)
*Wenhan Wang,Kaibo Liu,Zeyu Sun,An Ran Chen,Ge Li,Gang Huang,Lei Ma*

Main category: cs.SE

TL;DR: 本文探索用大型语言模型代替传统求解器解决符号执行路径约束，实验表明LLM能有效生成和分类路径测试用例，提升测试覆盖率，促进符号执行技术发展。


<details>
  <summary>Details</summary>
Motivation: 符号执行在实际软件分析中受限于传统SMT求解器难以处理复杂数据结构和外部API调用的路径约束，探索LLM应用以突破这些限制。

Method: 本文采用实证研究方法，设计了测试用例生成和路径分类的评估流程及基准，利用LLM来求解路径约束，涵盖竞赛级程序和真实仓库的测试。

Result: 实验结果显示，LLM在测试用例生成和路径分类任务中均表现良好，产生的测试用例有60%准确覆盖给定路径，并能提升真实世界软件的测试覆盖能力。

Conclusion: 基于大型语言模型（LLM）的符号执行路径约束求解展示出较强能力，能够生成准确覆盖执行路径的测试用例并区分路径是否可满足，提升了测试覆盖率，特别是在传统符号执行工具难以应用的真实软件中。

Abstract: Symbolic execution is an important software analysis technique which benefits downstream tasks such as software testing and debugging. However, several limitations hinder symbolic execution from application on real-world software. One of the limitations is the inability to solve diverse execution path constraints: traditional symbolic execution based on SMT solvers is difficult to handle execution paths with complex data structures or external API calls. In this paper, we focus on investigating the possibility of adopting large language models (LLM) for path constraint solving instead of traditional solver-based techniques in symbolic execution. We conduct an empirical study to evaluate the ability of LLMs in two types of path constraint solving: generating test inputs to facilitate an execution path, and determining whether a given execution path can be satisfied without triggering any bugs. We build new evaluation pipelines and benchmarks for two tasks: test case generation and path classification, which include data sources from both competition-level programs and real-world repositories. Our experiment results show that state-of-the-art LLMs are able to solve path constraints in both generation and classification tasks, with 60% of generated test cases that accurately cover the given execution path. Moreover, LLMs are capable of improving test coverage by covering execution paths in real-world repositories where traditional symbolic execution tools cannot be applied. These findings highlight the possibility of extending symbolic execution techniques with LLMs in the future to improve the ability and generalizability of symbolic execution.

</details>


### [89] [A Needle in a Haystack: Intent-driven Reusable Artifacts Recommendation with LLMs](https://arxiv.org/abs/2511.18343)
*Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Yuanpeng He,Jia Li,Yirang Zhang,Yingtao Fang*

Main category: cs.SE

TL;DR: 本文提出了IntentRecBench基准及特征树引导的TreeRec推荐框架，利用LLM语义能力提升开源软件构件推荐的准确率与效率，解决了LLM低精度、高推理开销的问题。


<details>
  <summary>Details</summary>
Motivation: 面对开源软件中大量可复用构件，开发者难以高效准确地找到满足需求的构件，现有基于检索和机器学习的推荐方法效果有限；大语言模型虽有潜力但尚未充分验证其性能，有必要构建基准并设计新的推荐框架提升性能。

Method: 本文通过构建IntentRecBench基准测试不同推荐方法，提出了TreeRec框架，利用LLM进行语义抽象，将构件组织为层级特征树，实现意图与功能对齐，减少推理时间，提升推荐性能。

Result: 本文构建了一个面向意图驱动的开源软件构件推荐基准数据集IntentRecBench，覆盖了三个代表性的开源生态，系统比较了五种主流大语言模型（LLM）与六种传统推荐方法的性能，发现虽然LLM表现更优但仍存在精度低和推理耗时高的问题。为解决这些问题，本文提出了基于特征树的推荐框架TreeRec，利用LLM的语义抽象能力构建层级语义树实现需求意图与构件功能的对齐，显著提升了推荐精度和效率，并验证了其在多种生态系统中的有效性和泛化能力。

Conclusion: TreeRec通过构建层级语义树实现意图驱动的构件推荐，显著提升了大语言模型推荐的精度和效率，具备良好的泛化性，适合实际部署。

Abstract: In open source software development, the reuse of existing artifacts has been widely adopted to avoid redundant implementation work. Reusable artifacts are considered more efficient and reliable than developing software components from scratch. However, when faced with a large number of reusable artifacts, developers often struggle to find artifacts that can meet their expected needs. To reduce this burden, retrieval-based and learning-based techniques have been proposed to automate artifact recommendations. Recently, Large Language Models (LLMs) have shown the potential to understand intentions, perform semantic alignment, and recommend usable artifacts. Nevertheless, their effectiveness has not been thoroughly explored. To fill this gap, we construct an intent-driven artifact recommendation benchmark named IntentRecBench, covering three representative open source ecosystems. Using IntentRecBench, we conduct a comprehensive comparative study of five popular LLMs and six traditional approaches in terms of precision and efficiency. Our results show that although LLMs outperform traditional methods, they still suffer from low precision and high inference cost due to the large candidate space. Inspired by the ontology-based semantic organization in software engineering, we propose TreeRec, a feature tree-guided recommendation framework to mitigate these issues. TreeRec leverages LLM-based semantic abstraction to organize artifacts into a hierarchical semantic tree, enabling intent and function alignment and reducing reasoning time. Extensive experiments demonstrate that TreeRec consistently improves the performance of diverse LLMs across ecosystems, highlighting its generalizability and potential for practical deployment.

</details>


### [90] [Evaluating perturbation robustnessof generative systems that use COBOL code inputs](https://arxiv.org/abs/2511.18488)
*Samuel Ackerman,Wesam Ibraheem,Orna Raz,Marcel Zalmanovici*

Main category: cs.SE

TL;DR: 他们提出了一个评估大语言模型处理COBOL代码时稳健性的框架，通过输入扰动和数据集扩展，结合动态可视化工具，帮助发现和改进模型对输入细微变化的敏感性。


<details>
  <summary>Details</summary>
Motivation: 当前系统中大语言模型（LLMs）对输入的细微变化非常敏感，这种敏感性影响了系统的稳健性和实用性。针对商业关键的COBOL代码，缺乏公开训练数据，更加剧了稳健性评估的难度。

Method: 设计了一个框架，利用对COBOL代码进行扰动（段落及全程序级别），构建变异版本的基准数据集，评估LLM系统在COBOL与Java翻译任务中的稳健性。同时开发动态可视化仪表盘辅助调试和分析。

Result: 提出的方法能够有效量化系统对COBOL输入细微变化的敏感性，通过可视化工具帮助定位问题根源，支持后续系统改进，提升稳健性。

Conclusion: 本研究构建了针对COBOL代码输入的稳健性评估框架及工具，为LLM系统在处理商业关键领域代码转换任务中提升鲁棒性提供了实用手段。

Abstract: Systems incorporating large language models (LLMs) as a component are known to be sensitive (i.e., non-robust) to minor input variations that do not change the meaning of the input; such sensitivity may reduce the system's usefulness. Here, we present a framework to evaluate robustness of systems using COBOL code as input; our application is translation between COBOL and Java programming languages, but the approach extends to other tasks such as code generation or explanation. Targeting robustness of systems with COBOL as input is essential yet challenging. Many business-critical applications are written in COBOL, yet these are typically proprietary legacy applications and their code is unavailable to LLMs for training. We develop a library of COBOL paragraph and full-program perturbation methods, and create variant-expanded versions of a benchmark dataset of examples for a specific task. The robustness of the LLM-based system is evaluated by measuring changes in values of individual and aggregate metrics calculated on the system's outputs. Finally, we present a series of dynamic table and chart visualization dashboards that assist in debugging the system's outputs, and monitoring and understanding root causes of the system's sensitivity to input variation. These tools can be further used to improve the system by, for instance, indicating variations that should be handled by pre-processing steps.

</details>


### [91] [HQPEF-Py: Metrics, Python Patterns, and Guidance for Evaluating Hybrid Quantum Programs](https://arxiv.org/abs/2511.18506)
*Michael Adjei Osei,Sidney Shapiro*

Main category: cs.SE

TL;DR: 本文提出了一套工作流视角的混合量子程序评估体系，结合理论指标和实践代码，实现了对混合量子程序端到端性能的系统评估。


<details>
  <summary>Details</summary>
Motivation: 当前量子程序通常作为独立设备或算法进行评估，缺乏针对端到端混合量子程序工作流整体性能的评估指标和方法。

Method: 构建了混合量子程序评估框架（HQPEF），形式化定义了量子准备度级别（QRL）评分，量子效用（UQ）下的归一化加速比，以及混合管道的时间和漂移审计方法，配合Python实现代码进行验证。

Result: 提出了工作流感知的评估指标和审计流程，提供了利用Qiskit和PennyLane等经典-量子求解器实现的参考代码，保证了预算匹配和结果可重现性。

Conclusion: 本文提出了一种基于工作流视角的混合量子程序评估方法，能够综合评估混合量子程序的性能和实用性。

Abstract: We study how to evaluate hybrid quantum programs as end-to-end workflows rather than as isolated devices or algorithms. Building on the Hybrid Quantum Program Evaluation Framework (HQPEF), we formalize a workflow-aware Quantum Readiness Level (QRL) score; define a normalized speedup under quality constraints for the Utility of Quantumness (UQ); and provide a timing-and-drift audit for hybrid pipelines. We complement these definitions with concise Python reference implementations that illustrate how to instantiate the metrics and audit procedures with state-of-the-art classical and quantum solvers (e.g., via Qiskit or PennyLane), while preserving matched-budget discipline and reproducibility.

</details>


### [92] [End-to-End Automated Logging via Multi-Agent Framework](https://arxiv.org/abs/2511.18528)
*Renyi Zhong,Yintong Huo,Wenwei Gu,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: Autologger通过判断是否需要日志及多代理协作，显著提升自动日志生成的准确率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决软件日志记录中的成本高昂的过度记录与风险大的不足记录问题，自动化工具忽视了基础的是否记录决策与记录的复合性。

Method: 采用细调的分类器判断是否记录日志，激活包括定位和生成代理的多代理系统，结合程序分析和检索工具生成日志。

Result: 提出了Autologger混合框架，利用精准分类器判断是否需要日志，结合多代理系统确定日志位置和内容，在大规模开源项目中取得96.63%的F1分数，整体日志质量提升16.13%。

Conclusion: Autologger有效解决了日志生成中的关键问题，提升了日志的准确性和质量，且具有良好的泛化能力。

Abstract: Software logging is critical for system observability, yet developers face a dual crisis of costly overlogging and risky underlogging. Existing automated logging tools often overlook the fundamental whether-to-log decision and struggle with the composite nature of logging. In this paper, we propose Autologger, a novel hybrid framework that addresses the complete the end-to-end logging pipeline. Autologger first employs a fine-tuned classifier, the Judger, to accurately determine if a method requires new logging statements. If logging is needed, a multi-agent system is activated. The system includes specialized agents: a Locator dedicated to determining where to log, and a Generator focused on what to log. These agents work together, utilizing our designed program analysis and retrieval tools. We evaluate Autologger on a large corpus from three mature open-source projects against state-of-the-art baselines. Our results show that Autologger achieves 96.63\% F1-score on the crucial whether-to-log decision. In an end-to-end setting, Autologger improves the overall quality of generated logging statements by 16.13\% over the strongest baseline, as measured by an LLM-as-a-judge score. We also demonstrate that our framework is generalizable, consistently boosting the performance of various backbone LLMs.

</details>


### [93] [From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence](https://arxiv.org/abs/2511.18538)
*Jian Yang,Wei Zhang,Shark Liu,Jiajun Wu,Shawn Guo,Yizhi Li*

Main category: cs.SE

TL;DR: 本文系统综述了代码生成大型语言模型的全生命周期及关键技术，分析了学术与实际应用的差异，通过实验揭示了模型训练各环节的影响，为代码LLMs的研究与实用提供指导。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在自动软件开发中取得显著突破，亟需系统梳理代码LLMs的发展历程、技术框架及实际挑战，以促进学术研究与工业应用的有效结合。

Method: 通过系统分析模型生命周期的各个阶段，包括数据整理、代码预训练、监督微调、强化学习和自主编程代理，结合一系列分析性和探测性实验，比较了通用和专业代码LLMs的技术与设计抉择。

Result: 实验详尽分析了代码预训练、监督微调及强化学习对模型性能的影响，探讨了规模规律、框架选择、超参数敏感性、模型架构及数据集差异，揭示了当前技术在实际代码任务中的表现和瓶颈。

Conclusion: 本文全面综述了大型语言模型（LLMs）在代码生成领域的进展与应用，揭示了学术研究与实际部署之间的差距，强调了代码正确性、安全性及大规模代码库上下文感知的重要性，并提出了未来研究方向以满足实际需求。

Abstract: Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.

</details>


### [94] [Strategic Decision Framework for Enterprise LLM Adoption](https://arxiv.org/abs/2511.18589)
*Michael Trusov,Minha Hwang,Zainab Jamal,Swarup Chandra*

Main category: cs.SE

TL;DR: 本文提出一套六步决策框架，指导组织安全高效地采用大型语言模型，支持从客户服务自动化到内容创作和高级分析的多场景应用。


<details>
  <summary>Details</summary>
Motivation: 组织快速采用大型语言模型(LLMs)来转变运营，但缺乏针对关键决策的明确指导，特别在数据安全、解决方案开发、基础设施需求和部署策略方面，面临重要挑战。各行业如医疗、金融和软件开发需平衡技术利用和安全合规。

Method: 通过对成功与失败的LLM实施案例进行广泛访谈和深入分析，提炼出系统性的六步决策框架，包括应用选择、数据安全、开发方案、基础设施和部署策略等关键决策点。

Result: 提出了一个系统的六步骤决策框架，基于广泛访谈及成功与失败案例分析，帮助组织从初步应用选择到最终部署，提供实用指导，使业务领导能够将技术能力与商业目标对齐。

Conclusion: 该框架助力组织在应用LLMs时做出明智决策，确保技术与业务目标一致，促进安全和有效的多领域集成。

Abstract: Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.
  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.

</details>


### [95] [From Reviewers' Lens: Understanding Bug Bounty Report Invalid Reasons with LLMs](https://arxiv.org/abs/2511.18608)
*Jiangrui Zheng,Yingming Zhou,Ali Abdullah Ahmad,Hanqing Yao,Xueqing Liu*

Main category: cs.SE

TL;DR: 研究发现大型语言模型难以准确识别无效漏洞报告，通过分类拒绝原因和结合审查者知识的RAG方法能显著改善无效报告检测，并揭示审查决策受报告者声誉影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成漏洞报告的增多，帮助漏洞猎人理解无效报告的标注原因，提高报告质量及减轻审查负担变得迫切。

Method: 收集了9,942份漏洞奖励报告数据集，包括1,400份无效报告，评估了GPT-5、DeepSeek和微调RoBERTa等大型语言模型对无效报告的识别能力，并构建了信息泄露漏洞的拒绝原因分类法，结合检索增强生成(RAG)框架提升无效检测。

Result: 现有大型语言模型虽然准确率高，但在识别无效报告时容易过度接收，结合拒绝原因分类及RAG框架大幅提升检测一致性并减少偏差。

Conclusion: 结合结构化审查者知识与大型语言模型，有助于实现更透明、一致的漏洞报告审核，提升无效报告识别效果，促进漏洞奖励平台的可靠性和公平性。

Abstract: Bug bounty platforms (e.g., HackerOne, BugCrowd) leverage crowd-sourced vulnerability discovery to improve continuous coverage, reduce the cost of discovery, and serve as an integral complement to internal red teams. With the rise of AI-generated bug reports, little work exists to help bug hunters understand why these reports are labeled as invalid. To improve report quality and reduce reviewers' burden, it is critical to predict invalid reports and interpret invalid reasons.
  In this work, we conduct an empirical study with the purpose of helping bug hunters understand the validity of reports. We collect a dataset of 9,942 disclosed bug bounty reports, including 1,400 invalid reports, and evaluate whether state-of-the-art large language models can identify invalid reports. While models such as GPT-5, DeepSeek, and a fine-tuned RoBERTa achieve strong overall accuracy, they consistently struggle to detect invalid cases, showing a tendency to over-accept reports. To improve invalidity detection, we build a taxonomy of rejection reasons for Information Disclosure vulnerabilities and incorporate it into a retrieval-augmented generation (RAG) framework. This approach substantially improves classification consistency and reduces bias. We also examine whether reviewer decisions may be influenced by factors beyond the content of the report. Our analysis shows that reporters with higher reputations tend to receive more favorable outcomes in borderline cases, suggesting that perceived expertise can influence review judgments.
  Overall, our findings highlight the challenges of invalid report identification and show that combining LLMs with structured reviewer knowledge can support more transparent and consistent vulnerability report review.

</details>


### [96] [Leveraging Discrete Choice Experiments for User-Centric Requirements Prioritization in mHealth Applications](https://arxiv.org/abs/2511.18625)
*Wei Wang,Hourieh Khalajzadeh,John Grundy,Anuradha Madugalla,Humphrey O. Obie*

Main category: cs.SE

TL;DR: 本研究通过用户偏好实验，找出影响自适应移动健康应用采纳的关键因素，强调保持易用性和适度调整的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前mHealth应用存在可用性和可访问性挑战，个性化自适应界面虽能提升用户体验，但采纳率受限，理解用户偏好与权衡是推动广泛应用的必要条件。

Method: 采用离散选择实验(DCE)，通过混合逻辑模型分析186名慢性病患者对六个属性的自适应设计偏好及其异质性，同时进行亚组分析。

Result: 本研究通过离散选择实验(DCE)探讨慢性病患者对移动健康(mHealth)自适应用户界面设计的偏好与权衡，发现保持界面易用性与对自适应控制权、较少频繁和小范围的调整有助于促进设计采纳，而常用功能和护理人员参与可能降低自适应设计的价值。本研究还通过混合逻辑模型分析了不同年龄、性别、健康状况及应对机制群体的偏好差异，采用数据驱动方法量化用户偏好并揭示关键权衡，提供未来自适应mHealth应用设计的重要指导。

Conclusion: 维持界面易用性和用户对自适应功能的控制权，采用少频率、小规模的调整，是促进自适应mHealth应用设计采纳的关键。常用功能及护理者参与可能削弱适应设计的价值。

Abstract: Mobile health (mHealth) applications are widely used for chronic disease management, but usability and accessibility challenges persist due to the diverse needs of users. Adaptive User Interfaces (AUIs) offer a personalized solution to enhance user experience, yet barriers to adoption remain. Understanding user preferences and trade-offs is essential to ensure widespread acceptance of adaptation designs. This study identifies key factors influencing user preferences and trade-offs in mHealth adaptation design. A Discrete Choice Experiment (DCE) was conducted with 186 participants who have chronic diseases and use mHealth applications. Participants were asked to select preferred adaptation designs from choices featuring six attributes with varying levels. A mixed logit model was used to analyze preference heterogeneity and determine the factors most likely influencing adoption. Additionally, subgroup analyses were performed to explore differences by age, gender, health conditions, and coping mechanisms. Maintaining usability while ensuring controllability over adaptations, infrequent adaptations, and small-scale changes are key factors that facilitate the adoption of adaptive mHealth app designs. In contrast, frequently used functions and caregiver involvement can diminish the perceived value of such adaptations. This study employs a data-driven approach to quantify user preferences, identify key trade-offs, and reveal variations across demographic and behavioral subgroups through preference heterogeneity modeling. Furthermore, our results offer valuable guidance for developing future adaptive mHealth applications and lay the groundwork for continued exploration into requirements prioritization within the field of software engineering.

</details>


### [97] [ChroniUXMag: A Persona-Driven Framework for Inclusive mHealth Requirements Engineering](https://arxiv.org/abs/2511.18634)
*Wei Wang,Devi Karolita,Hourieh Khalajzadeh,John Grundy,Anuradha Madugalla,Humphrey O. Obie*

Main category: cs.SE

TL;DR: 本文提出了ChroniUXMag框架，通过系统化方法捕捉和评估移动健康应用中影响包容性的因素，助力构建更包容的慢病管理工具。


<details>
  <summary>Details</summary>
Motivation: 慢性病管理的移动健康应用存在可及性、包容性和持续参与的挑战，传统需求工程方法无法充分应对用户不断变化的需求。

Method: 采用两阶段的InclusiveMag过程，通过系统文献回顾、焦点小组、访谈和大规模调查确定包容性方面，并将其综合成代表多样健康状况和数字行为的人物角色，结合认知演练方法进行评估。

Result: 识别出13个反映移动健康使用社会技术复杂性的包容性方面，如信任、数字素养、依赖性和文化背景，支持通过人物角色驱动的结构化评估，揭示传统可用性评估忽视的包容性障碍。

Conclusion: ChroniUXMag为慢性病移动健康应用的需求工程提供了基于证据的可复现方法，未来将通过实际设计实践进一步验证和完善。

Abstract: Mobile health (mHealth) applications are increasingly adopted for chronic disease management, yet they face persistent challenges related to accessibility, inclusivity, and sustained engagement. Patients' needs evolve dynamically with their health progression, adherence, and caregiver support, creating unique requirements engineering (RE) challenges that traditional approaches often overlook. This study introduces ChroniUXMag, a framework for eliciting and analysing inclusivity requirements in mHealth design. Building on InclusiveMag and GenderMag principles, the framework aims to help researchers and practitioners systematically capture and evaluate factors that influence how individuals with chronic conditions perceive, trust, and interact with mHealth systems. The framework was developed through two stages of the InclusiveMag process. In the first stage, inclusivity facets were identified through a systematic literature review, focus groups, interviews, and a large-scale survey. In the second stage, these facets were synthesised into personas representing diverse health situations, attitudes, and digital practices, and integrated into an adapted cognitive walkthrough form. Thirteen facets were identified that capture the socio-technical complexity of mHealth use, including trust, digital literacy, dependency, and cultural context. These facets support structured, persona-driven evaluations that reveal inclusivity barriers often missed by traditional usability assessments. ChroniUXMag contributes to RE by offering a reproducible, evidence-based approach for embedding inclusivity into mHealth requirements. Future work will extend the third stage Apply through practitioner-led evaluation in real-world design contexts.

</details>


### [98] [Summary-Mediated Repair: Can LLMs use code summarisation as a tool for program repair?](https://arxiv.org/abs/2511.18782)
*Lukas Twist*

Main category: cs.SE

TL;DR: 本文提出了一种基于代码摘要的程序修复方法，通过在修复过程中加入自然语言代码摘要作为中间步骤，提高了大语言模型修复代码错误的效果。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在基准测试中表现良好，但它们常犯细微实现错误且难以察觉，代码摘要能揭示高层意图，激发将摘要作为修复的中间步骤。

Method: 本文设计了一个只用提示的修复流程，先生成代码的自然语言摘要，再根据摘要修复代码，对比不同摘要风格与直接修复的基线方法。

Result: 在8个大语言模型和两个函数级基准测试（HumanEvalPack和MBPP）上，错误感知摘要方法能修复约65%的未知错误，较基线平均提升5%。

Conclusion: 利用错误感知的诊断性代码摘要作为中间环节，可以显著提升程序修复效果，修复率提升了约5%，但整体改进受限于具体的大语言模型表现。

Abstract: Large Language Models (LLMs) often produce code with subtle implementation-level bugs despite strong benchmark performance. These errors are hard for LLMs to spot and can have large behavioural effects; yet when asked to summarise code, LLMs can frequently surface high-level intent and sometimes overlook this low-level noise. Motivated by this, we propose summary-mediated repair, a prompt-only pipeline for program repair that leverages natural-language code summarisation as an explicit intermediate step, extending previous work that has already shown code summarisation to be a useful intermediary for downstream tasks. We evaluate our method across eight production-grade LLMs on two function level benchmarks (HumanEvalPack and MBPP), comparing several summary styles against a direct repair baseline. Error-aware diagnostic summaries consistently yield the largest gains - repairing up to 65% of unseen errors, on average of 5% more than the baseline - though overall improvements are modest and LLM-dependent. Our results position summaries as a cheap, human-interpretable diagnostic artefact that can be integrated into program-repair pipelines rather than a stand-alone fix-all.

</details>


### [99] [Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds](https://arxiv.org/abs/2511.18842)
*Mohammad Nour Al Awad,Sergey Ivanov,Olga Tikhonova*

Main category: cs.SE

TL;DR: 提出自适应延迟机制动态调整代码补全建议展示时机，显著提升接受率，减少无效计算，提高效率。


<details>
  <summary>Details</summary>
Motivation: 代码自动补全中何时展示建议尚未充分研究，错误的时机会导致开发者打断或浪费计算资源。

Method: 提出一种自适应定时机制，根据开发者实时反馈动态调整提供建议的延迟时间，结合最近接受率的逻辑变换和开发者认知状态的二元预测。

Result: 两个月部署中，相比无延迟，静态延迟提升接受率至15.4%，自适应定时进一步提升至18.6%，盲目拒绝率从8.3%降至0.36%，减少了75%的无效推断调用。

Conclusion: 自适应定时机制显著提升了LLM代码助手的建议接受率和效率，降低计算资源浪费，提高了实用性。

Abstract: Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing-while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.

</details>


### [100] [Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming](https://arxiv.org/abs/2511.18849)
*Mohammad Nour Al Awad,Sergey Ivanov,Olga Tikhonova*

Main category: cs.SE

TL;DR: 基于行为信号的预过滤模型提升了代码建议的接受率和系统效率，同时保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 许多由LLM生成的代码建议被忽略，导致计算浪费、延迟增加和不必要的中断。

Method: 引入了一个轻量级的预过滤模型，在调用大型语言模型（LLM）之前，仅利用实时开发者的遥测数据（如打字速度、文件导航和编辑活动）预测代码建议被接受的可能性。

Result: 在Visual Studio Code插件的实际生产环境中使用四个月，模型将建议接受率从18.4%提升至34.2%，同时抑制了35%的低价值LLM调用。

Conclusion: 仅利用编辑器调用前的遥测数据，且不访问代码或提示内容，即可显著提升用户体验和系统效率，证明了基于时机感知和隐私保护的适应机制的价值。

Abstract: Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.

</details>


### [101] [Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect](https://arxiv.org/abs/2511.18854)
*Yujing Wang,Weize Hong*

Main category: cs.SE

TL;DR: 通过将大型语言模型集成到 Git bisect 语义故障定位流程，本文提升了定位成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 传统 Git bisect 假设测试和回归状态确定性，但现代开发环境中存在测试不稳定、回归非单调及语义漂移，导致定位效果不佳，需要一种能够在噪声条件下稳定进行语义定位的方法。

Method: 结合结构化链式思维推理在 bisect 遍历中逐提交分析，使用 QLoRA 对 DeepSeekCoderV2 进行微调，采用弱监督结合人机交互修正及自我一致性过滤以降低标注成本。

Result: 本文提出了一种将大型语言模型（LLMs）集成到 Git bisect 过程中用于语义故障定位的新框架。该方法通过结构化的思维链推理，增强了在测试不稳定、回归非单调及语义差异等噪声条件下对每次提交的分析能力。对多种开源和专有 LLMs 进行了评估，并利用 QLoRA 对 DeepSeekCoderV2 在语义标注的差异数据集上进行了微调。同时采用弱监督工作流减少标注成本，结合人工修正和自我一致性过滤。实验结果显示，在多个开源项目中成功率从74.2%提升至80.6%，平均 bisect 时间最多减少50%。最终，论文探讨了时序推理、提示设计及微调策略的优化。

Conclusion: 集成大语言模型的 Git bisect 方法能够在噪声环境下稳定提升语义故障定位的准确性和效率，显著减少失败次数和定位时间。

Abstract: We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.

</details>


### [102] [VecIntrinBench: Benchmarking Cross-Architecture Intrinsic Code Migration for RISC-V Vector](https://arxiv.org/abs/2511.18867)
*Liutong Han,Chu Kang,Mingjie Xing,Yanjun Wu*

Main category: cs.SE

TL;DR: 本文提出了VecIntrinBench，这是首个涵盖RISC-V向量扩展的内建函数基准测试集，用于评估不同架构间内建函数的迁移能力。实验证明，先进的大型语言模型在RISC-V代码迁移中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前缺少支持新兴RISC-V架构的内建函数基准，难以全面评估内建函数在多架构间的迁移能力，特别是RVV扩展。

Method: 收集50个开源函数任务，分别实现为标量、RVV、Arm Neon和x86内建函数，设计全面的功能和性能测试，用于系统评估不同代码迁移方法。

Result: 构建了包含RVV的首个内建函数基准集VecIntrinBench，评测显示LLM在代码迁移上效果与规则映射相当但性能更优，揭示未来LLM发展的方向。

Conclusion: VecIntrinBench有效填补了RISC-V内建函数迁移评测的空白，且大型语言模型在代码迁移中表现出比传统规则映射更优的性能。

Abstract: Intrinsic functions are specialized functions provided by the compiler that efficiently operate on architecture-specific hardware, allowing programmers to write optimized code in a high-level language that fully exploits hardware features. Using intrinsics to vectorize core code blocks is a standard optimization method in high-performance libraries, often requiring specific vector optimization implementations for multiple mainstream architectures. The promising RISC-V software ecosystem has a significant demand for algorithm library migration and adaptation. Translating existing intrinsic functions to RISC-V Vector (RVV) intrinsic functions across architectures is currently a mainstream approach. Rule-based intrinsic mapping methods and LLM-based code generation can help developers address the code migration challenge. However, existing intrinsic code benchmarks focus on mainstream SIMD intrinsics and lack support for the emerging RISC-V architecture. There is currently no benchmark that comprehensively evaluates the intrinsic migration capabilities for the RVV extension. To fill this gap, we propose VecIntrinBench, the first intrinsic benchmark encompassing RVV extensions. It includes 50 function-level tasks from open source repositories, implemented as scalars, RVV intrinsics, Arm Neon intrinsics, and x86 intrinsics, along with comprehensive functional and performance test cases. We systematically evaluated various code migration approaches on VecIntrinBench, yielding a series of insightful findings. The results demonstrate that advanced Large Language Models (LLMs) achieve a similar effect as rule-based mapping approaches for RISC-V code migration, while also delivering superior performance. We further analyze the reasons and identify future directions for LLM development in the code migration field. The VecIntrinBench is open-sourced to benefit the broader community and developers.

</details>


### [103] [Optimization-Aware Test Generation for Deep Learning Compilers](https://arxiv.org/abs/2511.18918)
*Qingchao Shen,Zan Wang,Haoyang Ma,Yongqiang Tian,Lili Huang,Zibo Xiao,Junjie Chen,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: 该文提出了一种针对深度学习编译器优化阶段的测试方法OATest，通过合成优化感知计算图，有效提升了测试覆盖和缺陷检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在测试深度学习编译器优化阶段存在限制，主要是难以生成优化感知的测试用例，影响对关键功能的全面检测。

Method: 提出一种名为OATest的新颖方法，通过结合从文档测试中提取的优化模式并将其融合到种子计算图中，实现优化感知计算图的合成。引入边复用策略强化模式与上下文的连接，采用辅助层添加策略保证生成图的有效性，并使用差异测试评估两个主流深度学习编译器。

Result: OATest在检测TVM和ONNXRuntime中的缺陷上表现优于当前最先进方法，覆盖更多代码，发现了58个未知的漏洞，其中36个已被开发者确认或修复。

Conclusion: OATest有效提升了深度学习编译器优化测试的覆盖率和缺陷发现能力，证明了合成优化感知计算图及相关策略在深度学习编译器测试中的实用价值。

Abstract: Deep Learning (DL) compilers have been widely utilized to optimize DL models for efficient deployment across various hardware. Due to their vital role in the DL ecosystem, ensuring their reliability and security is critical. However, existing approaches have limitations in testing optimization stages, which is the core functionality of DL compilers, due to the difficulty in generating optimization-aware tests. In this paper, we proposed OATest, a novel approach for synthesizing optimization-aware computational graphs. The approach combines patterns extracted from documented tests for optimization and incorporates them into seed computational graphs, enabling broader exploration of optimization paths. To guarantee the optimization-awareness of generated graphs, OATest introduces the edges reusing strategy to establish strong connections between patterns and contexts. Additionally, to solve the validity challenge for the generated graphs, OATest employs an auxiliary layers addition strategy to resolve broken constraints. Equipped with two distinct test oracles, OATest applies differential testing to evaluate the two widely used DL compilers (i.e., TVM and ONNXRuntime). Our experimental results show that OATest outperforms the state-of-the-art method by detecting more bugs and achieving higher code coverage in TVM and ONNXRutimes. Additionally, OATest uncovers 58 previously unknown bugs, 36 of which have been confirmed or fixed by developers.

</details>


### [104] [LLM-Driven Kernel Evolution: Automating Driver Updates in Linux](https://arxiv.org/abs/2511.18924)
*Arina Kharlamova,Jiawen Liu,Tianyi Zhang,Xinrui Yang,Humaid Alqasimi,Youcheng Sun,Chun Jason Xue*

Main category: cs.SE

TL;DR: 本文提出DRIVEBENCH语料库和AUTODRIVER自动驱动维护系统，实现驱动与Linux内核的自动安全共演化。


<details>
  <summary>Details</summary>
Motivation: Linux内核持续演进导致驱动因API/ABI变化、安全强化等问题破坏，需自动化工具辅助驱动维护，保障驱动与内核的同步更新。

Method: 集成提示工程、多代理协作、静态分析及迭代验证，确保生成的驱动补丁语法、功能及语义正确。

Result: 本文提出了DRIVEBENCH和AUTODRIVER两个工具，分别用于构建Linux内核驱动共演化的可执行语料库和自动化驱动维护系统。AUTODRIVER结合提示工程、多代理协作、静态分析和迭代验证，能够生成符合内核规范且功能语义一致的补丁。DRIVEBENCH语料库涵盖了Linux内核v5.10至v6.10的235个验证案例。评估结果显示，AUTODRIVER在55个测试案例中有56.4%的补丁能成功编译，并且通过QEMU引导验证补丁在大多数情况下能维持驱动初始化。通过发布这些工具，提升了驱动与Linux内核安全共演化的自动化和可重复研究能力。

Conclusion: AUTODRIVER能够自动生成符合规范且功能正确的驱动补丁，推动驱动与Linux内核的安全持续共演化，且DRIVEBENCH为相关研究提供了可复现的案例库。

Abstract: Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.

</details>


### [105] [LLMAID: Identifying AI Capabilities in Android Apps with LLMs](https://arxiv.org/abs/2511.19059)
*Pei Liu,Terry Zhuo,Jiawei Deng,Thong James,Shidong Pan,Sherry Xu,Zhenchang Xing,Qinghua Lu,Xiaoning Du,Hongyu Zhang*

Main category: cs.SE

TL;DR: 本文提出LLMAID方法，利用大型语言模型高效识别移动应用中的AI功能，在识别率和用户体验上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的快速发展及其在移动软件中的广泛应用，人们迫切需要有效识别移动软件中的AI能力，传统的手工检查和基于规则的方法效率低且难以跟进先进AI技术。

Method: 提出了LLMAID（大型语言模型用于AI发现），包括候选提取、知识库交互、AI能力分析检测和AI服务总结四个主要任务。

Result: 在4201个Android应用的数据集上，LLMAID比最先进的基于规则的方法多识别了242%的真实AI应用，精确率和召回率均超过90%。用户研究表明开发者更喜欢LLMAID生成的AI服务摘要。

Conclusion: LLMAID有效提升了移动应用中AI功能的识别效率和准确性，揭示了Android应用中AI能力主要集中在计算机视觉领域，以目标检测最为常见。

Abstract: Recent advancements in artificial intelligence (AI) and its widespread integration into mobile software applications have received significant attention, highlighting the growing prominence of AI capabilities in modern software systems. However, the inherent hallucination and reliability issues of AI continue to raise persistent concerns. Consequently, application users and regulators increasingly ask critical questions such as: Does the application incorporate AI capabilities? and What specific types of AI functionalities are embedded? Preliminary efforts have been made to identify AI capabilities in mobile software; however, existing approaches mainly rely on manual inspection and rule-based heuristics. These methods are not only costly and time-consuming but also struggle to adapt advanced AI techniques.
  To address the limitations of existing methods, we propose LLMAID (Large Language Model for AI Discovery). LLMAID includes four main tasks: (1) candidate extraction, (2) knowledge base interaction, (3) AI capability analysis and detection, and (4) AI service summarization. We apply LLMAID to a dataset of 4,201 Android applications and demonstrate that it identifies 242% more real-world AI apps than state-of-the-art rule-based approaches. Our experiments show that LLM4AID achieves high precision and recall, both exceeding 90%, in detecting AI-related components. Additionally, a user study indicates that developers find the AI service summaries generated by LLMAID to be more informative and preferable to the original app descriptions. Finally, we leverage LLMAID to perform an empirical analysis of AI capabilities across Android apps. The results reveal a strong concentration of AI functionality in computer vision (54.80%), with object detection emerging as the most common task (25.19%).

</details>


### [106] [Can LLMs Recover Program Semantics? A Systematic Evaluation with Symbolic Execution](https://arxiv.org/abs/2511.19130)
*Rong Feng,Suman Saha*

Main category: cs.SE

TL;DR: 通过结合符号执行产物微调大型语言模型，提升了对混淆代码的去混淆能力，增强了程序语义恢复和解析能力。


<details>
  <summary>Details</summary>
Motivation: 现有的软件工程任务如程序理解、维护、测试和漏洞检测中，代码混淆带来了持续的挑战，现有分析工具和大型语言模型难以恢复程序原语义。

Method: 通过在多样化C程序上应用四种广泛研究的混淆转换，构建基准数据集。比较三种先进大型语言模型在两种训练配置下的表现：基线微调（混淆代码与原始代码对）和增强微调（加入KLEE符号执行生成的约束、路径统计和测试用例）。

Result: GPT-4.1-mini在去混淆效果方面表现最强，加入KLEE符号执行生成的辅助信息能持续提升语义保真度和编译成功率。

Conclusion: 将大型语言模型与符号执行技术结合，有助于提升自动化测试、静态分析和程序理解在面对代码混淆时的效果。

Abstract: Obfuscation poses a persistent challenge for software engineering tasks such as program comprehension, maintenance, testing, and vulnerability detection. While compiler optimizations and third-party code often introduce transformations that obscure program intent, existing analysis tools and large language models (LLMs) struggle to recover the original semantics. In this work, we investigate whether LLMs, when fine-tuned with symbolic execution artifacts, can effectively deobfuscate programs and restore analyzability. We construct a benchmark by applying four widely studied transformations-control-flow flattening, opaque predicates, arithmetic encoding, and branch encoding-across diverse C programs from TUM Obfuscation Benchmarks, the LLVM test suite, and algorithmic repositories. We then compare three state-of-the-art LLMs under two training configurations: baseline fine-tuning on obfuscated/original code pairs, and enhanced fine-tuning with additional KLEE artifacts such as SMT constraints, path statistics, and test cases. Our evaluation examines syntactic correctness (compilation success), semantic fidelity (behavioral equivalence under symbolic execution), and code quality (readability and structure). Results show that GPT-4.1-mini achieves the strongest deobfuscation overall, and that incorporating KLEE artifacts consistently improves semantic preservation and compilation success across models. These findings highlight deobfuscation as a broader software engineering concern, demonstrating that combining LLMs with symbolic execution can strengthen automated testing, static analysis, and program comprehension in the presence of obfuscation.

</details>


### [107] [LLMs-Powered Real-Time Fault Injection: An Approach Toward Intelligent Fault Test Cases Generation](https://arxiv.org/abs/2511.19132)
*Mohammad Abboush,Ahmad Hatahet,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文提出了一种基于大型语言模型（LLMs）的自动故障测试用例生成方法，用于汽车软件系统的实时故障注入测试，以克服传统方法中人工识别故障属性的困难。


<details>
  <summary>Details</summary>
Motivation: 传统的故障注入测试需要手工识别故障类型、位置和时机，过程复杂且费时费力，尤其在复杂系统中更显著。

Method: 利用大型语言模型（如gpt-4o）从功能安全需求中自动生成故障测试用例，并在硬件在环系统中进行了实际运行验证。

Result: 通过不同LLMs的验证，gpt-4o的故障测试用例生成F1得分达97.5%，功能安全需求分类F1得分达88%，显示出优越性。生成的测试用例在硬件在环系统中成功执行，证明了方法的有效性和实用价值。

Conclusion: 所提出的方法利用gpt-4o模型在功能安全需求的分类和故障测试用例生成方面表现优异，显著提升了实时测试效率，降低了成本，并增强了复杂安全关键汽车软件系统的安全性。

Abstract: A well-known testing method for the safety evaluation and real-time validation of automotive software systems (ASSs) is Fault Injection (FI). In accordance with the ISO 26262 standard, the faults are introduced artificially for the purpose of analyzing the safety properties and verifying the safety mechanisms during the development phase. However, the current FI method and tools have a significant limitation in that they require manual identification of FI attributes, including fault type, location and time. The more complex the system, the more expensive, time-consuming and labour-intensive the process. To address the aforementioned challenge, a novel Large Language Models (LLMs)-assisted fault test cases (TCs) generation approach for utilization during real-time FI tests is proposed in this paper. To this end, considering the representativeness and coverage criteria, the applicability of various LLMs to create fault TCs from the functional safety requirements (FSRs) has been investigated. Through the validation results of LLMs, the superiority of the proposed approach utilizing gpt-4o in comparison to other state-of-the-art models has been demonstrated. Specifically, the proposed approach exhibits high performance in terms of FSRs classification and fault TCs generation with F1-score of 88% and 97.5%, respectively. To illustrate the proposed approach, the generated fault TCs were executed in real time on a hardware-in-the-loop system, where a high-fidelity automotive system model served as a case study. This novel approach offers a means of optimizing the real-time testing process, thereby reducing costs while simultaneously enhancing the safety properties of complex safety-critical ASSs.

</details>


### [108] [Synthesizing Test Cases for Narrowing Specification Candidates](https://arxiv.org/abs/2511.19177)
*Alcino Cunha,Nuno Macedo*

Main category: cs.SE

TL;DR: 本文提出了一种基于生成测试用例的技术，帮助从多个候选形式规范中选择最佳规范，提出两种算法，评估表明性能良好，适用于实际问题。


<details>
  <summary>Details</summary>
Motivation: 形式规范通常存在多个备选方案，难以确定最佳规范，故需一种有效方法辅助选择最佳规范。

Method: 采用两种基于求解器的算法生成测试用例，一种保证生成最小测试用例集，另一种不保证最小性，通过用户对测试用例的期望分类缩小候选规范范围。

Result: 本文提出了一种技术，用于从一组备选的形式规范中选择最佳的规范。该技术通过生成测试用例集，用户对测试用例的期望与否分类，从而缩小候选规范的范围，最终最多只剩一个规范。文章提出了两种基于求解器的算法：一种生成最小测试用例集，另一种不保证最小性。两种算法均已实现为原型，能够生成测试用例以辅助选择Alloy规范。通过在大量问题上的评估，发现最优算法在许多实际问题中效率足够高，而非最优算法能扩展到数十个候选规范，同时生成的测试用例集规模合理。

Conclusion: 提出的基于测试用例生成的选择技术有效且实用，最优算法高效，非最优算法可扩展至较多候选规范，辅助形式规范的选择工作。

Abstract: This paper proposes a technique to help choose the best formal specification candidate among a set of alternatives. Given a set of specifications, our technique generates a suite of test cases that, once classified by the user as desirable or not, narrows down the set of candidates to at most one specification. Two alternative solver-based algorithms are proposed, one that generates a minimal test suite, and another that does not ensure minimality. Both algorithms were implemented in a prototype that can be used generate test suites to help choose among alternative Alloy specifications. Our evaluation of this prototype against a large set of problems showed that the optimal algorithm is efficient enough for many practical problems, and that the non-optimal algorithm can scale up to dozens of candidate specifications while still generating reasonably sized test suites.

</details>


### [109] [SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning](https://arxiv.org/abs/2511.19422)
*David Jiahao Fu,Aryan Gupta,Aaron Councilman,David Grove,Yu-Xiong Wang,Vikram Adve*

Main category: cs.SE

TL;DR: 提出了一种名为SLMFix的代码生成修正方法，利用小语言模型和强化学习技术修复大语言模型生成代码的语法错误，提高领域特定语言的代码质量。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在代码生成中易出现语法错误，尤其在低资源语言下表现不佳，且微调成本高昂，限制其实际应用效果。

Method: 采用强化学习在小语言模型上微调，通过静态验证器和静态语义相似度度量作为奖励，针对程序修复任务进行优化。

Result: 实验表明SLMFix在多个领域特定语言上效果显著，能够显著提升基础模型性能，并实现比传统微调更优的结果。

Conclusion: SLMFix显著提升了低资源编程语言中大语言模型生成代码的质量，在多个领域特定语言上实现了超过95%的通过率，并优于传统的监督微调方法。

Abstract: Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.

</details>


### [110] [Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering](https://arxiv.org/abs/2511.19427)
*Jayanaka L. Dantanarayana,Savini Kashmira,Thakee Nathees,Zichen Zhang,Krisztian Flautner,Lingjia Tang,Jason Mars*

Main category: cs.SE

TL;DR: 本文提出通过在代码中嵌入自然语言上下文来丰富程序语义，从而提升基于LLM的提示词生成效果，兼顾效果和开发成本。


<details>
  <summary>Details</summary>
Motivation: 现有的利用代码语义自动生成提示词的方法（如MTP）无法充分表达开发者意图及领域特定上下文，因为现实应用中需要更多上下文线索和领域推理。

Method: 提出了Semantic Engineering，一种轻量级方法，通过Semantic Context Annotations (SemTexts)将自然语言上下文直接嵌入程序构造中，集成于Jac语言，扩展了MTP在提示词生成中对丰富语义的利用。

Result: 在设计的真实场景基准测试中，Semantic Engineering显著提升了提示词的准确性，性能可媲美传统的人工Prompt Engineering，且大幅减少开发人员投入。

Conclusion: Semantic Engineering通过将自然语言上下文与程序语义结合，提高了基于LLM的程序提示设计的准确度和效率，是实现智能系统开发的有效范式。

Abstract: AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [111] [A novel strategy for multi-resource load balancing in agent-based systems](https://arxiv.org/abs/2511.17580)
*Leszek Sliwko,Aleksander Zgrzywa*

Main category: cs.MA

TL;DR: 提出一种基于智能体的多资源负载均衡策略，优化复杂企业系统结构，并通过实验验证。


<details>
  <summary>Details</summary>
Motivation: 为帮助系统设计者优化复杂企业架构，利用智能体自适应行为设计多资源负载均衡策略。

Method: 基于智能体的社会行为和自适应能力设计多资源负载均衡策略，支持智能体自我评估，实现系统结构优化。

Result: 本文提出了一种多资源负载均衡策略，基于智能体(agent)系统，通过智能体的社会行为和自适应能力，实现对复杂企业架构的结构优化。方法支持智能体自我评估。通过实施该智能体系统并进行实验验证，展示了其有效性。

Conclusion: 基于智能体的多资源负载均衡策略能够有效优化复杂企业架构，智能体自适应行为促进系统的最佳配置。

Abstract: The paper presents a multi-resource load balancing strategy which can be utilised within an agent-based system. This approach can assist system designers in their attempts to optimise the structure for complex enterprise architectures. In this system, the social behaviour of the agent and its adaptation abilities are applied to determine an optimal setup for a given configuration. All the methods have been developed to allow the agent's self-assessment. The proposed agent system has been implemented and the experiment results are presented here.

</details>


### [112] [Hierarchical Adaptive Consensus Network: A Dynamic Framework for Scalable Consensus in Collaborative Multi-Agent AI Systems](https://arxiv.org/abs/2511.17586)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.MA

TL;DR: 本文提出了一种名为分层自适应共识网络（HACN）的三层架构，以解决多智能体系统中共识策略在适应性、可扩展性和收敛性方面的挑战，通过分层投票和局部知识共享显著减少通信复杂度和通信负担。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统的共识策略面临通信瓶颈、决策过程严格和响应延迟等问题，难以适应复杂动态任务，亟需一种可扩展且高效的共识机制。

Method: HACN采用三层架构：第一层收集基于置信度的局部代理簇投票结果，第二层通过跨簇部分知识共享和动态超时机制实现簇间通信，第三层通过全局编排框架和可调整决策规则进行系统级协调和最终仲裁。

Result: 实验结果显示HACN在模拟环境中将通信开销降低了99.9%，实现了从$igO(n^2)$到$igO(n)$的通信复杂度提升，同时保证了多种复杂任务的共识收敛。

Conclusion: 提出的HACN模型通过分层结构和动态适应机制，成功实现了通信复杂度的线性减少和通信开销的极大降低，同时保证了共识的收敛性和系统的协同效率。

Abstract: The consensus strategies used in collaborative multi-agent systems (MAS) face notable challenges related to adaptability, scalability, and convergence certainties. These approaches, including structured workflows, debate models, and iterative voting, often lead to communication bottlenecks, stringent decision-making processes, and delayed responses in solving complex and evolving tasks. This article introduces a three-tier architecture, the Hierarchical Adaptive Consensus Network (\hacn), which suggests various consensus policies based on task characterization and agent performance metrics. The first layer collects the confidence-based voting outcomes of several local agent clusters. In contrast, the second level facilitates inter-cluster communication through cross-clustered partial knowledge sharing and dynamic timeouts. The third layer provides system-wide coordination and final arbitration by employing a global orchestration framework with adaptable decision rules. The proposed model achieves $\bigO(n)$ communication complexity, as opposed to the $\bigO(n^2)$ complexity of the existing fully connected MAS. Experiments performed in a simulated environment yielded a 99.9\% reduction in communication overhead during consensus convergence. Furthermore, the proposed approach ensures consensus convergence through hierarchical escalation and dynamic adaptation for a wide variety of complicated tasks.

</details>


### [113] [From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems](https://arxiv.org/abs/2511.17621)
*Brendan Gho,Suman Muppavarapu,Afnan Shaik,Tyson Tsay,James Begin,Kevin Zhu,Archana Vaidheeswaran,Vasu Sharma*

Main category: cs.MA

TL;DR: 本文提出了一种基于市场机制的多智能体大型语言模型协调框架，将智能体的交互组织为经济交易，通过激励机制推动共享真实结果，提升准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在多智能体系统中作为交互代理广泛应用，传统集中式或对抗式协调机制难以扩展且缺乏透明性，亟需一种可扩展且可解释的协调机制。

Method: 将多智能体语言模型作为市场参与者，通过更新和交易概率信念进行协调，使局部激励与集体知识目标保持一致，实现自组织和可验证的推理，无需外部强制。

Result: 在事实推理、伦理判断和常识推断任务中，基于市场机制的协调方法相较单次基线在准确率上提升了最多10%，并实现了推理过程的透明和可解释，加强了系统的责任感和稳健性。

Conclusion: 基于市场机制的多智能体协调方法有效提升了事实推理、伦理判断和常识推断的准确率，达到了比单次推理基线高出10%的效果，同时保持了推理过程的可解释性和透明度，证明了经济协调原则在多智能体系统中的可行性和优势。

Abstract: As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.

</details>


### [114] [Iterative Negotiation and Oversight: A Case Study in Decentralized Air Traffic Management](https://arxiv.org/abs/2511.17625)
*Jaehan Im,John-Paul Clarke,Ufuk Topcu,David Fridovich-Keil*

Main category: cs.MA

TL;DR: 本文提出了一种结合资产交易谈判和税收式监管的分散式多智能体协调框架，解决非合作智能体间冲突偏好问题，实现系统效率和公平性的保证，并通过理论与航空交通管理案例验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有分散式协调方法虽能实现无中心协调的共识，但缺乏对系统层面效率和公平性目标的形式保障。

Method: 构建在共识交易拍卖基础上的分散式资产交易谈判机制，并引入类似税收的监管干预机制来引导谈判过程，调控系统效率与收敛速度的平衡。

Result: 理论上证明了有限时间收敛性和干预强度与系统效率、收敛速度之间的界限关系；在美国空中交通管理重新路径规划的案例中验证了框架的有效性及干预水平对效率与收敛速度关系的调节作用。

Conclusion: 提出的迭代谈判与监管框架通过类似税收的干预机制，有效促进了分散式非合作多智能体系统中达成系统效率和公平性的共识，同时保证了有限时间内的收敛性。

Abstract: Achieving consensus among noncooperative agents remains challenging in decentralized multi-agent systems, where agents often have conflicting preferences. Existing coordination methods enable agents to reach consensus without a centralized coordinator, but do not provide formal guarantees on system-level objectives such as efficiency or fairness. To address this limitation, we propose an iterative negotiation and oversight framework that augments a decentralized negotiation mechanism with taxation-like oversight. The framework builds upon the trading auction for consensus, enabling noncooperative agents with conflicting preferences to negotiate through asset trading while preserving valuation privacy. We introduce an oversight mechanism, which implements a taxation-like intervention that guides decentralized negotiation toward system-efficient and equitable outcomes while also regulating how fast the framework converges. We establish theoretical guarantees of finite-time termination and derive bounds linking system efficiency and convergence rate to the level of central intervention. A case study based on the collaborative trajectory options program, a rerouting initiative in U.S. air traffic management, demonstrates that the framework can reliably achieve consensus among noncooperative airspace sector managers, and reveals how the level of intervention regulates the relationship between system efficiency and convergence speed. Taken together, the theoretical and experimental results indicate that the proposed framework provides a general mechanism for decentralized coordination in noncooperative multi-agent systems while safeguarding system-level objectives.

</details>


### [115] [Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building](https://arxiv.org/abs/2511.17654)
*Deepak Bolleddu*

Main category: cs.MA

TL;DR: 本文提出一种多智能体强化学习框架，通过分层网络和渐进式谈判协议，实现自动化冲突解决和共识构建。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中冲突解决和共识构建面临重大挑战，需自动化且高效的框架支持复杂动态环境下的协作决策。

Method: 引入分层共识网络（HCN）、渐进式谈判协议（PNP）和上下文感知奖励塑造机制，结合多轮对话和策略调整进行多智能体强化学习。

Result: 本文提出了Dialogue Diplomats框架，一种基于多智能体强化学习的端到端系统，用于自动化冲突解决和共识构建。该系统结合了深度强化学习和基于对话的谈判协议，实现多智能体通过迭代沟通和策略调整进行复杂动态环境中的冲突解决。主要贡献包括：1）提出了结合注意力机制和图神经网络的分层共识网络（HCN），用于建模智能体间依赖和冲突动态；2）设计了渐进式谈判协议（PNP），支持多轮对话交互和自适应让步策略；3）引入了上下文感知的奖励塑造机制，平衡个体目标与集体共识。

Conclusion: 该方法有效结合深度强化学习和对话机制，提升多智能体系统中冲突解决和共识构建的能力，适用于复杂动态环境。

Abstract: Conflict resolution and consensus building represent critical challenges in multi-agent systems, negotiations, and collaborative decision-making processes. This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent reinforcement learning (MARL) framework designed for automated conflict resolution and consensus building in complex, dynamic environments. The proposed system integrates advanced deep reinforcement learning architectures with dialogue-based negotiation protocols, enabling autonomous agents to engage in sophisticated conflict resolution through iterative communication and strategic adaptation. We present three primary contributions: first, a novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies; and third, a Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals.

</details>


### [116] [Multi-Agent Coordination in Autonomous Vehicle Routing: A Simulation-Based Study of Communication, Memory, and Routing Loops](https://arxiv.org/abs/2511.17656)
*KM Khalid Saifullah,Daniel Palmer*

Main category: cs.MA

TL;DR: 提出的轻量级OMM机制通过共享障碍物记忆，显著避免了多车去中心化系统中的路径循环问题，提高了自动驾驶车辆的协调效率和系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统中无记忆的反应式路径重新计算导致车辆陷入路由循环，严重影响效率，尤其在去中心化自动驾驶系统中多车协调的重要性。

Method: 引入了对象记忆管理（OMM）机制，利用分布式黑名单维持车辆对已遇阻碍的记忆，并在基于Dijkstra的路径重新计算时防止重复路径尝试。

Result: OMM机制使平均行驶时间减少75.7%，等待时间减少88%，每车路线重计算次数从9.83降至1.67，显著改善多车路由效率。

Conclusion: 持久且共享的记忆对多智能体系统的稳健协调至关重要，OMM为动态环境中去中心化多智能体导航提供了有效解决方案，且其设计理念可推广至机器人、网络路由及分布式人工智能系统。

Abstract: Multi-agent coordination is critical for next-generation autonomous vehicle (AV) systems, yet naive implementations of communication-based rerouting can lead to catastrophic performance degradation. This study investigates a fundamental problem in decentralized multi-agent navigation: routing loops, where vehicles without persistent obstacle memory become trapped in cycles of inefficient path recalculation. Through systematic simulation experiments involving 72 unique configurations across varying vehicle densities (15, 35, 55 vehicles) and obstacle frequencies (6, 20 obstacles), we demonstrate that memory-less reactive rerouting increases average travel time by up to 682% compared to baseline conditions. To address this, we introduce Object Memory Management (OMM), a lightweight mechanism enabling agents to retain and share knowledge of previously encountered obstacles. OMM operates by maintaining a distributed blacklist of blocked nodes, which each agent consults during Dijkstra-based path recalculation, effectively preventing redundant routing attempts. Our results show that OMM-enabled coordination reduces average travel time by 75.7% and wait time by 88% compared to memory-less systems, while requiring only 1.67 route recalculations per vehicle versus 9.83 in memory-less scenarios. This work provides empirical evidence that persistent, shared memory is not merely beneficial but essential for robust multi-agent coordination in dynamic environments. The findings have implications beyond autonomous vehicles, informing the design of decentralized systems in robotics, network routing, and distributed AI. We provide a comprehensive experimental analysis, including detailed scenario breakdowns, scalability assessments, and visual documentation of the routing loop phenomenon, demonstrating OMM's critical role in preventing detrimental feedback cycles in cooperative multi-agent systems.

</details>


### [117] [Episodic Memory in Agentic Frameworks: Suggesting Next Tasks](https://arxiv.org/abs/2511.17775)
*Sandro Rama Fiorini,Leonardo G. Azevedo,Raphael M. Thiago,Valesca M. de Sousa,Anton B. Labate,Viviane Torres da Silva*

Main category: cs.MA

TL;DR: 引入情景记忆架构，利用历史工作流程数据辅助大语言模型推荐科学工作中的下一步任务。


<details>
  <summary>Details</summary>
Motivation: 解决科学工作流程创建中只依赖大语言模型会产生幻觉且缺乏大量专有训练数据的问题，提升推荐下一步任务的可靠性。

Method: 提出了一种情景记忆机制，通过存储和检索历史工作流程，匹配当前任务序列，辅助代理推荐合理下一步。

Result: 本文提出了一种基于大语言模型的代理框架，该框架结合了情景记忆体系，能存储和检索过去的工作流程以指导代理推荐下一步任务。通过匹配当前工作流程与历史序列，代理能够基于已有模式提出合理的下一步建议，减少了对大语言模型盲目依赖及其幻觉风险。

Conclusion: 结合情景记忆的代理架构能够提升科学工作流程中任务推荐的准确性和合理性，降低仅依赖大语言模型带来的风险。

Abstract: Agentic frameworks powered by Large Language Models (LLMs) can be useful tools in scientific workflows by enabling human-AI co-creation. A key challenge is recommending the next steps during workflow creation without relying solely on LLMs, which risk hallucination and require fine-tuning with scarce proprietary data. We propose an episodic memory architecture that stores and retrieves past workflows to guide agents in suggesting plausible next tasks. By matching current workflows with historical sequences, agents can recommend steps based on prior patterns.

</details>


### [118] [DISPATCH -- Decentralized Informed Spatial Planning and Assignment of Tasks for Cooperative Heterogeneous Agents](https://arxiv.org/abs/2511.17915)
*Yao Liu,Sampad Mohanty,Elizabeth Ondula,Bhaskar Krishnamachari*

Main category: cs.MA

TL;DR: 本文提出基于Eisenberg-Gale均衡的去中心化多智能体学习算法，实现了空间任务分配中的公平与效率兼顾，在部分可观测环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多机器人配送或网约车等空间任务分配系统需要在效率和公平性之间取得平衡。贪心分配策略虽能最大化效率，但会产生不公平现象，导致部分任务获得较优服务而其他任务等待时间长或分配不佳。已有方法多依赖中心化协调或在部分可观测环境中忽略公平性。

Method: 提出两个算法框架：一是EG-MARL，多智能体强化学习训练由中心化公平分配算法（EG和偏好感知匈牙利算法）引导；二是随机在线优化机制，结合指导探索和基于子集的公平分配，适合任务动态发现场景。两者均在多种实验设置中验证性能。

Result: 本文建立了Eisenberg-Gale (EG)均衡凸规划与去中心化、部分可观测多智能体学习的联系，提出了两种结合公平性与效率的算法：基于多智能体强化学习（EG-MARL）和随机在线优化机制。评估结果显示两种算法在部分可观测条件下有效维持EG均衡的公平-效率平衡，EG-MARL接近中心化协调且减少行程距离，随机在线机制实现实时分配且公平性竞争力强。

Conclusion: 空间感知的EG均衡模型能够有效指导具异质能力智能体的去中心化任务协调，实现公平性与效率的良好平衡，适用于多种团队规模和任务分配情景。

Abstract: Spatial task allocation in systems such as multi-robot delivery or ride-sharing requires balancing efficiency with fair service across tasks. Greedy assignment policies that match each agent to its highest-preference or lowest-cost task can maximize efficiency but often create inequities: some tasks receive disproportionately favorable service (e.g., shorter delays or better matches), while others face long waits or poor allocations.
  We study fairness in heterogeneous multi-agent systems where tasks vary in preference alignment and urgency. Most existing approaches either assume centralized coordination or largely ignore fairness under partial observability. Distinct from this prior work, we establish a connection between the Eisenberg-Gale (EG) equilibrium convex program and decentralized, partially observable multi-agent learning. Building on this connection, we develop two equilibrium-informed algorithms that integrate fairness and efficiency: (i) a multi-agent reinforcement learning (MARL) framework, EG-MARL, whose training is guided by centralized fair assignment algorithms (EG and a preference-aware Hungarian method); and (ii) a stochastic online optimization mechanism that performs guided exploration and subset-based fair assignment as tasks are discovered.
  We evaluate our frameworks across a range of team sizes and assignment formulations against centralized EG, Hungarian, and Min-Max Distance baselines. Both algorithms preserve the fairness-efficiency balance of the Eisenberg-Gale equilibrium under partial observability. EG-MARL achieves near-centralized coordination and reduced travel distances, while the stochastic online mechanism enables real-time allocation with competitive fairness. Together, these results demonstrate that spatially aware EG formulations can effectively guide decentralized coordination in agents with heterogeneous capabilities.

</details>


### [119] [Hybrid Agentic AI and Multi-Agent Systems in Smart Manufacturing](https://arxiv.org/abs/2511.18258)
*Mojtaba A. Farahani,Md Irfan Khan,Thorsten Wuest*

Main category: cs.MA

TL;DR: 本文提出了一种融合基于大语言模型的Agentic AI和多智能体系统的混合架构，用于智能制造中的预测性维护，实现从高层战略规划到底层自治执行的无缝协同。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统侧重分布式协调和专有自治，难以实现高级推理和规划，结合基于大语言模型的Agentic AI可提升智能决策水平，解决智能制造预测性维护中的复杂任务调度和优化问题。

Method: 设计分层架构（感知、预处理、分析和优化层），由LLM规划代理协调各智能体工作流程；使用基于规则和小语言模型的特化智能体负责具体任务，同时保证透明和可审计的人机交互接口。

Result: 系统成功自动识别数据模式、动态调整预处理流程，通过自适应智能提升模型性能，输出优先级维护建议，在两个工业制造数据集上验证了有效性和扩展性。

Conclusion: 该框架能够实现自动模式识别、动态模型自适应、优化维护调度，并生成可解释的维护决策，在工业制造数据集上验证了其鲁棒性、可扩展性和可解释性，推动智能制造中的预测性维护技术进步。

Abstract: The convergence of Agentic AI and MAS enables a new paradigm for intelligent decision making in SMS. Traditional MAS architectures emphasize distributed coordination and specialized autonomy, while recent advances in agentic AI driven by LLMs introduce higher order reasoning, planning, and tool orchestration capabilities. This paper presents a hybrid agentic AI and multi agent framework for a Prescriptive Maintenance use case, where LLM based agents provide strategic orchestration and adaptive reasoning, complemented by rule based and SLMs agents performing efficient, domain specific tasks on the edge. The proposed framework adopts a layered architecture that consists of perception, preprocessing, analytics, and optimization layers, coordinated through an LLM Planner Agent that manages workflow decisions and context retention. Specialized agents autonomously handle schema discovery, intelligent feature analysis, model selection, and prescriptive optimization, while a HITL interface ensures transparency and auditability of generated maintenance recommendations. This hybrid design supports dynamic model adaptation, cost efficient maintenance scheduling, and interpretable decision making. An initial proof of concept implementation is validated on two industrial manufacturing datasets. The developed framework is modular and extensible, supporting seamless integration of new agents or domain modules as capabilities evolve. The results demonstrate the system capability to automatically detect schema, adapt preprocessing pipelines, optimize model performance through adaptive intelligence, and generate actionable, prioritized maintenance recommendations. The framework shows promise in achieving improved robustness, scalability, and explainability for RxM in smart manufacturing, bridging the gap between high level agentic reasoning and low level autonomous execution.

</details>


### [120] [Think How Your Teammates Think: Active Inference Can Benefit Decentralized Execution](https://arxiv.org/abs/2511.18761)
*Hao Wu,Shoucheng Song,Chang Yao,Sheng Han,Huaiyu Wan,Youfang Lin,Kai Lv*

Main category: cs.MA

TL;DR: 本文提出了一种无需通信，通过模拟队友感知和信念过程实现协作的多智能体强化学习框架，表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于通信存在噪声、延迟及攻击等限制，如何在无通信条件下构建对队友决策逻辑的认知，促进多智能体协作成为挑战。

Method: 基于局部观察，构建队友的感知-信念-行动三重画像，选择性整合信念画像辅助决策，实现队友主动推理过程建模。

Result: 本文提出了一种基于局部观察建模的多智能体强化学习(MARL)非通信框架，通过模拟队友的感知-信念-行动过程，实现对队友决策逻辑的认知，进而促进协作。该方法通过选择性地将信念模型整合进决策过程，能够有效识别并协作表现较佳的队友。实验结果显示，在多个标准多智能体基准任务中，该方法性能优越。

Conclusion: 该方法有效实现了基于非通信的队友认知和协作，提升了多智能体系统的协调性能。

Abstract: In multi-agent systems, explicit cognition of teammates' decision logic serves as a critical factor in facilitating coordination. Communication (i.e., ``\textit{Tell}'') can assist in the cognitive development process by information dissemination, yet it is inevitably subject to real-world constraints such as noise, latency, and attacks. Therefore, building the understanding of teammates' decisions without communication remains challenging. To address this, we propose a novel non-communication MARL framework that realizes the construction of cognition through local observation-based modeling (i.e., \textit{``Think''}). Our framework enables agents to model teammates' \textbf{active inference} process. At first, the proposed method produces three teammate portraits: perception-belief-action. Specifically, we model the teammate's decision process as follows: 1) Perception: observing environments; 2) Belief: forming beliefs; 3) Action: making decisions. Then, we selectively integrate the belief portrait into the decision process based on the accuracy and relevance of the perception portrait. This enables the selection of cooperative teammates and facilitates effective collaboration. Extensive experiments on the SMAC, SMACv2, MPE, and GRF benchmarks demonstrate the superior performance of our method.

</details>


### [121] [Addressing Situated Teaching Needs: A Multi-Agent Framework for Automated Slide Adaptation](https://arxiv.org/abs/2511.18840)
*Binglin Liu,Yucheng Wang,Zheyuan Zhang,Jiyuan Lu,Shen Yang,Daniel Zhang-Li,Huiqin Liu,Jifan Yu*

Main category: cs.MA

TL;DR: 提出多智能体自动适应教学幻灯片框架，显著降低教师负担，提升教学设计效率。


<details>
  <summary>Details</summary>
Motivation: 教师在适应教学幻灯片以满足教学风格和学生背景时工作量大且耗时，需要辅助自动化工具。

Method: 通过与教育者访谈确定幻灯片适应的关键难点，基于此提出多智能体框架以自动适应幻灯片，结合16个修改请求和8门实际课程做验证。

Result: 该框架产出在意图对齐、内容连贯性和事实准确性方面表现优异，视觉清晰度与基线方法持平，及时性好，与人工专家的F1评分达0.89。

Conclusion: 此工作开创利用AI代理处理教学设计后勤工作的新范式，使教师能专注于教学创意和策略。

Abstract: The adaptation of teaching slides to instructors' situated teaching needs, including pedagogical styles and their students' context, is a critical yet time-consuming task for educators. Through a series of educator interviews, we first identify and systematically categorize the key friction points that impede this adaptation process. Grounded in these findings, we introduce a novel multi-agent framework designed to automate slide adaptation based on high-level instructor specifications. An evaluation involving 16 modification requests across 8 real-world courses validates our approach. The framework's output consistently achieved high scores in intent alignment, content coherence and factual accuracy, and performed on par with baseline methods regarding visual clarity, while also demonstrating appropriate timeliness and a high operational agreement with human experts, achieving an F1 score of 0.89. This work heralds a new paradigm where AI agents handle the logistical burdens of instructional design, liberating educators to focus on the creative and strategic aspects of teaching.

</details>


### [122] [VIL2C: Value-of-Information Aware Low-Latency Communication for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.19146)
*Qian Zhang,Zhuo Sun,Yao Zhang,Zhiwen Yu,Bin Guo,Jun Zhang*

Main category: cs.MA

TL;DR: 提出一种基于信息价值的低延迟通信方案VIL2C，优化资源分配与接收时长，提升多智能体强化学习系统性能。


<details>
  <summary>Details</summary>
Motivation: 解决实际多智能体强化学习系统中通信延迟导致动作决策延误和信息过时问题，特别是在时间敏感场景如自动驾驶中。

Method: 通过定义信息价值指标，使用渐进式消息接收调整接收时长，并结合优化资源分配策略降低通信延迟影响。

Result: 本文提出了一种面向多智能体强化学习（MARL）系统的低延迟通信方案VIL2C，通过定义信息价值（VOI）指标量化延迟消息的重要性，并通过渐进式消息接收机制自适应调整接收时长，有效降低通信延迟对系统性能的影响。理论分析与大量实验验证表明，VIL2C在各种通信条件下均优于现有方法。

Conclusion: VIL2C方案通过优化资源分配和自适应接收机制，显著提升了多智能体系统在低延迟通信环境下的性能。

Abstract: Inter-agent communication serves as an effective mechanism for enhancing performance in collaborative multi-agent reinforcement learning(MARL) systems. However, the inherent communication latency in practical systems induces both action decision delays and outdated information sharing, impeding MARL performance gains, particularly in time-critical applications like autonomous driving. In this work, we propose a Value-of-Information aware Low-latency Communication(VIL2C) scheme that proactively adjusts the latency distribution to mitigate its effects in MARL systems. Specifically, we define a Value of Information (VOI) metric to quantify the importance of delayed message transmission based on each delayed message's importance. Moreover, we propose a progressive message reception mechanism to adaptively adjust the reception duration based on received messages. We derive the optimized VoI aware resource allocation and theoretically prove the performance advantage of the proposed VIL2C scheme. Extensive experiments demonstrate that VIL2C outperforms existing approaches under various communication conditions. These gains are attributed to the low-latency transmission of high-VoI messages via resource allocation and the elimination of unnecessary waiting periods via adaptive reception duration.

</details>


### [123] [Dynamic Leader-Follower Consensus with Adversaries: A Multi-Hop Relay Approach](https://arxiv.org/abs/2511.19327)
*Liwei Yuan,Hideaki Ishii*

Main category: cs.MA

TL;DR: 提出了基于均值子序列约简算法和多跳通信的分布式领导-跟随共识协议，提升了抗敌能力和跟踪精度，图条件更宽松，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中在存在敌对邻居传播错误信息情况下，保证跟随者准确跟踪动态领导者参考值的鲁棒性问题。

Method: 采用均值子序列约简算法，结合多跳通信机制，实现分布式协议，使非故障跟随者在存在敌对邻居的情况下准确跟踪动态领导值。

Result: 本文针对多智能体系统中的动态领导-跟随共识问题，提出了分布式协议，使非故障/正常的跟随者能够准确跟踪领导者的动态参考值，即使存在敌对邻居传递错误信息。方法采用均值子序列约简算法和多跳通信机制，推导出算法成功的必要和充分的图条件，并且跟踪误差界优于现有方法。此外，该条件在无中继情况下也比文献中的充分条件更紧凑，利用多跳中继可进一步放宽图结构要求。最后通过数值仿真验证算法有效性。

Conclusion: 本文提出的方法有效实现了动态领导-跟随共识，跟踪误差低于现有方法，图条件更为紧凑且具有更好的抗敌性能，多跳通信进一步优化图要求，数值仿真验证了算法的有效性。

Abstract: This paper examines resilient dynamic leader-follower consensus within multi-agent systems, where agents share first-order or second-order dynamics. The aim is to develop distributed protocols enabling nonfaulty/normal followers to accurately track a dynamic/time-varying reference value of the leader while they may receive misinformation from adversarial neighbors. Our methodologies employ the mean subsequence reduced algorithm with agents engaging with neighbors using multi-hop communication. We accordingly derive a necessary and sufficient graph condition for our algorithms to succeed; also, our tracking error bounds are smaller than that of the existing method. Furthermore, it is emphasized that even when agents do not use relays, our condition is tighter than the sufficient conditions in the literature. With multi-hop relays, we can further obtain more relaxed graph requirements. Finally, we present numerical examples to verify the effectiveness of our algorithms.

</details>
