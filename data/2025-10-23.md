<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 77]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.SE](#cs.SE) [Total: 18]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Contextual Augmentation for Entity Linking using Large Language Models](https://arxiv.org/abs/2510.18888)
*Daniel Vollmers,Hamada M. Zahera,Diego Moussallem,Axel-Cyrille Ngonga Ngomo*

Main category: cs.CL

TL;DR: 本文提出了一种联合实体识别与消歧的统一模型，利用大语言模型丰富上下文，实现了实体链接任务的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统实体链接方法采用实体识别和消歧的两步分开模型，计算开销大且效果有限。

Method: 构建一个联合模型，结合大语言模型扩展实体上下文信息，使得实体识别和消歧同时进行。

Result: 在多个基准数据集上的实验显示，该方法在领域外数据集上表现优于多种基线方法，达到最先进水平。

Conclusion: 通过统一模型及大语言模型上下文增强，显著提升了实体链接的准确性和泛化能力。

Abstract: Entity Linking involves detecting and linking entity mentions in natural
language texts to a knowledge graph. Traditional methods use a two-step process
with separate models for entity recognition and disambiguation, which can be
computationally intensive and less effective. We propose a fine-tuned model
that jointly integrates entity recognition and disambiguation in a unified
framework. Furthermore, our approach leverages large language models to enrich
the context of entity mentions, yielding better performance in entity
disambiguation. We evaluated our approach on benchmark datasets and compared
with several baselines. The evaluation results show that our approach achieves
state-of-the-art performance on out-of-domain datasets.

</details>


### [2] [Small Language Models Offer Significant Potential for Science Community](https://arxiv.org/abs/2510.18890)
*Jian Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种基于MiniLM的小型语言模型框架，用于从大规模地球科学文献中快速、精确且低成本地检索信息。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型（如ChatGPT-4）在科学文献检索中存在信息偏差和计算成本高的问题，作者希望通过小型模型实现更高效和专业的文献检索。

Method: 构建了包含约7700万高质量句子的地球科学文献语料库，使用MiniLM进行语义搜索和句子级索引，并结合情感分析和无监督聚类方法跟踪领域内研究动态。

Result: 该方法能够有效提取多学科、经专家验证的信息，特别是含有定量结论的信息，优于生成式大语言模型的泛化回答。

Conclusion: MiniLM框架在地球科学社区中具有广泛应用潜力，包括事实和图像检索、趋势分析、矛盾分析及教育等领域，提供了快速、精确且成本低的文献检索新途径。

Abstract: Recent advancements in natural language processing, particularly with large
language models (LLMs), are transforming how scientists engage with the
literature. While the adoption of LLMs is increasing, concerns remain regarding
potential information biases and computational costs. Rather than LLMs, I
developed a framework to evaluate the feasibility of precise, rapid, and
cost-effective information retrieval from extensive geoscience literature using
freely available small language models (MiniLMs). A curated corpus of
approximately 77 million high-quality sentences, extracted from 95 leading
peer-reviewed geoscience journals such as Geophysical Research Letters and
Earth and Planetary Science Letters published during years 2000 to 2024, was
constructed. MiniLMs enable a computationally efficient approach for extracting
relevant domain-specific information from these corpora through semantic search
techniques and sentence-level indexing. This approach, unlike LLMs such as
ChatGPT-4 that often produces generalized responses, excels at identifying
substantial amounts of expert-verified information with established,
multi-disciplinary sources, especially for information with quantitative
findings. Furthermore, by analyzing emotional tone via sentiment analysis and
topical clusters through unsupervised clustering within sentences, MiniLM
provides a powerful tool for tracking the evolution of conclusions, research
priorities, advancements, and emerging questions within geoscience communities.
Overall, MiniLM holds significant potential within the geoscience community for
applications such as fact and image retrievals, trend analyses, contradiction
analyses, and educational purposes.

</details>


### [3] [When Models Can't Follow: Testing Instruction Adherence Across 256 LLMs](https://arxiv.org/abs/2510.18892)
*Richard J. Young,Brandon Gillins,Alice M. Matthews*

Main category: cs.CL

TL;DR: 本文提出了一个使用二十个精心设计的提示语来评估大型语言模型(LLM)遵循指令能力的简化测试框架，并对256个模型进行了大规模实证研究。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法可能受到模型在训练过程中见过的基准测试的影响，限制了对模型真实指令遵循能力的评估，因此需要一种简便而有效的评估工具。

Method: 设计了一个包含二十个提示的测试套件，覆盖格式遵从、内容限制、逻辑序列和多步骤任务执行等多方面指令遵循能力，并对256个通过基本功能验证的模型进行了测试。

Result: 发现模型在特定指令类型上存在一致的失败模式，并对主要提供商及新兴模型进行了性能对比分析。

Conclusion: 该框架为研究者和实践者提供了一个实用且高效的指令遵循能力诊断工具，同时促进了对当代大型语言模型指令遵循能力的全面理解。

Abstract: Despite widespread deployment of Large Language Models, systematic evaluation
of instruction-following capabilities remains challenging. While comprehensive
benchmarks exist, focused assessments that quickly diagnose specific
instruction adherence patterns are valuable. As newer models may be trained on
existing benchmarks, novel evaluation approaches are needed to assess genuine
capabilities rather than memorized performance. This paper presents a
streamlined evaluation framework using twenty carefully designed prompts to
assess LLM instruction-following across diverse task categories. We demonstrate
this framework through a large-scale empirical study conducted on October 14,
2025, testing 256 verified working models from 331 available via OpenRouter. To
ensure methodological rigor and prevent selection bias, we first verified each
model's basic functionality before inclusion. Unlike large-scale benchmarks
requiring extensive computational resources, our approach offers a practical
diagnostic tool researchers and practitioners can readily apply. Our
methodology builds upon verifiable instructions while introducing a compact
test suite balancing comprehensiveness with efficiency. Each prompt targets
distinct aspects of instruction following, including format compliance, content
constraints, logical sequencing, and multi-step task execution. We evaluate
models from major providers (OpenAI, Anthropic, Google, Meta, Mistral) and
emerging implementations (Qwen, DeepSeek, community models), providing
comparative performance analysis. Our findings reveal consistent failure modes
and identify specific instruction types posing particular challenges. This work
contributes both a practical evaluation tool and one of the most comprehensive
empirical analyses of instruction-following capabilities across the
contemporary LLM landscape.

</details>


### [4] [Transformer-Based Low-Resource Language Translation: A Study on Standard Bengali to Sylheti](https://arxiv.org/abs/2510.18898)
*Mangsura Kabir Oni,Tabia Tanzin Prama*

Main category: cs.CL

TL;DR: 本文研究了低资源语言Sylheti的机器翻译，通过微调多语言Transformer模型相比零样本大语言模型取得更好效果。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译多集中于高资源语言，Sylheti等低资源语言几乎未被充分研究，有必要探讨如何提升其翻译性能。

Method: 本文通过微调多语言Transformer模型（如mBART-50和MarianMT）进行孟加拉语到Sylheti的翻译，并与零样本大语言模型进行对比。

Result: 微调的模型明显优于零样本大语言模型，mBART-50表现出最高的翻译充分度，MarianMT在字符级别保真度上表现最好。

Conclusion: 针对低资源语言，任务特定的模型微调对提升翻译效果至关重要，有助于推动包容性语言技术的发展。

Abstract: Machine Translation (MT) has advanced from rule-based and statistical methods
to neural approaches based on the Transformer architecture. While these methods
have achieved impressive results for high-resource languages, low-resource
varieties such as Sylheti remain underexplored. In this work, we investigate
Bengali-to-Sylheti translation by fine-tuning multilingual Transformer models
and comparing them with zero-shot large language models (LLMs). Experimental
results demonstrate that fine-tuned models significantly outperform LLMs, with
mBART-50 achieving the highest translation adequacy and MarianMT showing the
strongest character-level fidelity. These findings highlight the importance of
task-specific adaptation for underrepresented languages and contribute to
ongoing efforts toward inclusive language technologies.

</details>


### [5] [DuoLens: A Framework for Robust Detection of Machine-Generated Multilingual Text and Code](https://arxiv.org/abs/2510.18904)
*Shriyansh Agrawal,Aidan Lau,Sanyam Shah,Ahan M R,Kevin Zhu,Sunishchal Dev,Vasu Sharma*

Main category: cs.CL

TL;DR: 本文提出利用微调RoBERTA和CodeBERTa小型编码器模型，显著提升机器生成内容检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成内容检测准确性和效率存在权衡，方法要么计算成本高，要么准确率不足，亟需改进。

Method: 微调预训练的小型编码器语言模型（SLMs），使用专门的数据集对二分类任务进行训练，涵盖自然语言和源代码。

Result: SLMs在检测任务中AUROC达0.97至0.99，macro-F1达0.89至0.94，延迟降低8到12倍，显存峰值减少3到5倍，且在跨生成器和对抗性转换下表现稳定。

Conclusion: 微调小型编码器模型能在保证高准确度的同时，大幅提升检测速度和降低计算资源消耗，优于现有大型语言模型方法。

Abstract: The prevalence of Large Language Models (LLMs) for generating multilingual
text and source code has only increased the imperative for machine-generated
content detectors to be accurate and efficient across domains. Current
detectors, predominantly utilizing zero-shot methods, such as Fast DetectGPT or
GPTZero, either incur high computational cost or lack sufficient accuracy,
often with a trade-off between the two, leaving room for further improvement.
To address these gaps, we propose the fine-tuning of encoder-only Small
Language Models (SLMs), in particular, the pre-trained models of RoBERTA and
CodeBERTa using specialized datasets on source code and other natural language
to prove that for the task of binary classification, SLMs outperform LLMs by a
huge margin whilst using a fraction of compute. Our encoders achieve AUROC $=
0.97$ to $0.99$ and macro-F1 $0.89$ to $0.94$ while reducing latency by
$8$-$12\times$ and peak VRAM by $3$-$5\times$ at $512$-token inputs. Under
cross-generator shifts and adversarial transformations (paraphrase,
back-translation; code formatting/renaming), performance retains $\geq 92%$ of
clean AUROC. We release training and evaluation scripts with seeds and configs;
a reproducibility checklist is also included.

</details>


### [6] [Improving Topic Modeling of Social Media Short Texts with Rephrasing: A Case Study of COVID-19 Related Tweets](https://arxiv.org/abs/2510.18908)
*Wangjiaxuan Xin,Shuhua Yin,Shi Chen,Yaorong Ge*

Main category: cs.CL

TL;DR: 本论文提出了TM-Rephrase框架，通过大语言模型将推文重述为更标准正式的语言，从而提升主题建模的效果，特别是在COVID-19相关推文的分析中显著改善了主题一致性、唯一性和多样性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体短文本的简短、非正式和噪声特性使传统主题建模效果不佳，导致主题难以解释且冗余。

Method: 基于大语言模型的TM-Rephrase框架，将原始推文重述为标准正式语言，采用两种重述策略（一般重述和口语到正式），并结合多种主题建模方法进行实验分析。

Result: TM-Rephrase显著提高了主题一致性、唯一性和多样性，减少了主题冗余，口语到正式的重述策略效果最佳，且对LDA算法提升尤为明显。

Conclusion: TM-Rephrase为公共卫生领域的社交媒体主题建模提供了一种通用且有效的改进方法，促进了对健康危机及其他重要领域公共话语的理解。

Abstract: Social media platforms such as Twitter (now X) provide rich data for
analyzing public discourse, especially during crises such as the COVID-19
pandemic. However, the brevity, informality, and noise of social media short
texts often hinder the effectiveness of traditional topic modeling, producing
incoherent or redundant topics that are often difficult to interpret. To
address these challenges, we have developed \emph{TM-Rephrase}, a
model-agnostic framework that leverages large language models (LLMs) to
rephrase raw tweets into more standardized and formal language prior to topic
modeling. Using a dataset of 25,027 COVID-19-related Twitter posts, we
investigate the effects of two rephrasing strategies, general- and
colloquial-to-formal-rephrasing, on multiple topic modeling methods. Results
demonstrate that \emph{TM-Rephrase} improves three metrics measuring topic
modeling performance (i.e., topic coherence, topic uniqueness, and topic
diversity) while reducing topic redundancy of most topic modeling algorithms,
with the colloquial-to-formal strategy yielding the greatest performance gains
and especially for the Latent Dirichlet Allocation (LDA) algorithm. This study
contributes to a model-agnostic approach to enhancing topic modeling in public
health related social media analysis, with broad implications for improved
understanding of public discourse in health crisis as well as other important
domains.

</details>


### [7] [Learning from the Best, Differently: A Diversity-Driven Rethinking on Data Selection](https://arxiv.org/abs/2510.18909)
*Hongyi He,Xiao Liu,Zhenghao Lin,Mingni Tang,Yi Cheng,Jintao Wang,Wenjie Li,Peng Cheng,Yeyun Gong*

Main category: cs.CL

TL;DR: 提出了一种正交多样性感知选择算法（ODiS），通过主成分分析去相关多维数据评分，确保数据质量与多样性，从而提升大规模语言模型的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于评分的数据选择方法存在偏差，忽视数据多样性，导致直接选取高分数据反而降低下游任务性能。

Method: 使用多维评分（语言质量、知识质量、理解难度），通过PCA实现评分维度正交化，再在每个正交维度中选择顶级数据构成训练集。

Result: ODiS选择的数据维度间重叠度低于2%，训练的模型在下游测试中显著优于其他基线方法。

Conclusion: 数据选择需保证评分维度正交与多样性，ODiS方法有效提升了大语言模型的预训练数据质量及下游表现。

Abstract: High-quality pre-training data is crutial for large language models, where
quality captures factual reliability and semantic value, and diversity ensures
broad coverage and distributional heterogeneity. Existing approaches typically
rely on single or multiple-dimensional score-based selection. However, directly
selecting top-scored data often degrades performance, and sampling from a
broader range is required to recover results. The above non-monotonicity
between dataset scores and downstream benchmark results reveals a fundamental
bias: score-based methods collapse correlated dimensions, causing top-scored
data to appear high-quality while systematically overlooking diversity. We
argue that ensuring diversity requires decomposing correlated metrics into
orthogonal feature dimensions, from which the top-scored data can be directly
selected. Therefore, we proposed the Orthogonal Diversity-Aware Selection
(ODiS) algorithm, which preserves both quality and diversity during data
selection. First, ODiS evaluates data from multiple dimensions, covering
language quality, knowledge quality, and comprehension difficulty. The
multi-dimensional scores are then decorrelated via Principal Component Analysis
(PCA), yielding orthogonal evaluation dimensions. For each dimension, a
Roberta-based scorer is trained to regress the data onto PCA-projected scores,
enabling scalable inference on large corpora. Finally, ODiS constructs the
training dataset by selecting top-scored data within each orthogonal dimension,
thereby ensuring both quality and diversity. Empirical results show that
ODiS-selected data exhibit less than 2\% inter-dimension overlap, confirming
orthogonality between dimensions. More importantly, models trained with
ODiS-selected data significantly outperform other baselines on downstream
benchmarks, highlighting the necessity of orthogonal, diversity-aware data
selection for LLMs.

</details>


### [8] [Context-aware Fairness Evaluation and Mitigation in LLMs](https://arxiv.org/abs/2510.18914)
*Afrozah Nadeem,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文提出了一种动态可逆的基于剪枝的方法，通过检测上下文相关的神经元激活并应用自适应屏蔽，实时调节大语言模型中不良行为的神经元影响，以提升对话中的公平性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有减少语言模型不良行为的方法计算开销大，且部署后不可逆，适应性差，尤其无法针对动态变化的对话环境进行调整。

Method: 提出动态、可逆的剪枝框架，在推理时检测上下文相关神经元激活，动态屏蔽影响不良行为的神经元，实现精细化和记忆感知的调控。

Result: 该方法在多语言单轮及多轮对话中实现了知识保留、更高的一致性和公平性，有效减轻了不良行为的影响。

Conclusion: 动态剪枝为实时调整大语言模型中不良行为提供了灵活、透明且有效的解决方案，支持实际对话AI中的公平性控制。

Abstract: Large language models often display undesirable behaviors embedded in their
internal representations, undermining fairness, inconsistency drift,
amplification of harmful content, and the propagation of unwanted patterns
during extended dialogue and conversations. Although training-time or
data-centric methods attempt to reduce these effects, they are computationally
expensive, irreversible once deployed, and slow to adapt to new conversational
contexts. Pruning-based methods provide a flexible and transparent way to
reduce bias by adjusting the neurons responsible for certain behaviors.
However, most existing approaches are static; once a neuron is removed, the
model loses the ability to adapt when the conversation or context changes. To
address this, we propose a dynamic, reversible, pruning-based framework that
detects context-aware neuron activations and applies adaptive masking to
modulate their influence during generation. Our inference-time solution
provides fine-grained, memory-aware mitigation with knowledge-preserved, more
coherent behavior across multilingual single- and multi-turn dialogues,
enabling dynamic fairness control in real-world conversational AI.

</details>


### [9] [MMAO-Bench: MultiModal All in One Benchmark Reveals Compositional Law between Uni-modal and Omni-modal in OmniModels](https://arxiv.org/abs/2510.18915)
*Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Xuezhi Cao*

Main category: cs.CL

TL;DR: 提出了一个新的多模态全能模型基准测试MMAO-Bench，全面评估单模态和全模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型从单一模态向视觉、音频和语言模态统一发展，但单模态与全模态之间的关联尚不明确，缺乏综合评估。

Method: 设计了包含1880个人工整理样本、44种任务类型和创新多步骤开放式问题的MMAO-Bench基准，评测模型的多模态理解能力。

Result: 实验表明跨模态与单模态性能存在组合规律，全模态能力对弱模型有瓶颈效应，而对强模型则有协同提升。

Conclusion: MMAO-Bench有效促进多模态模型智能进化，揭示了多模态能力与模型强度间的互动关系。

Abstract: Multimodal Large Languages models have been progressing from uni-modal
understanding toward unifying visual, audio and language modalities,
collectively termed omni models. However, the correlation between uni-modal and
omni-modal remains unclear, which requires comprehensive evaluation to drive
omni model's intelligence evolution. In this work, we propose a novel, high
quality and diversity omni model benchmark, MultiModal All in One Benchmark
(MMAO-Bench), which effectively assesses both uni-modal and omni-modal
understanding capabilities. The benchmark consists of 1880 human curated
samples, across 44 task types, and a innovative multi-step open-ended question
type that better assess complex reasoning tasks. Experimental result shows the
compositional law between cross-modal and uni-modal performance and the
omni-modal capability manifests as a bottleneck effect on weak models, while
exhibiting synergistic promotion on strong models.

</details>


### [10] [Misinformation Detection using Large Language Models with Explainability](https://arxiv.org/abs/2510.18918)
*Jainee Patel,Chintan Bhatt,Himani Trivedi,Thanh Thi Nguyen*

Main category: cs.CL

TL;DR: 提出了一种基于Transformer预训练语言模型（RoBERTa和DistilBERT）的误信息检测方法，通过两步微调策略和解释性工具实现高效且可解释的误信息识别。


<details>
  <summary>Details</summary>
Motivation: 网络平台上误信息快速传播影响信任和决策，需开发高效且可信的误信息检测方法。

Method: 采用两步微调策略（先冻结主干训练分类头部，再逐层解冻并使用层级学习率衰减）优化RoBERTa和DistilBERT；同时结合LIME和SHAP提供本地和全局的可解释性。

Result: 在COVID Fake News和FakeNewsNet GossipCop两个真实数据集上验证，DistilBERT在计算资源大幅减少的同时，准确率可与RoBERTa媲美。

Conclusion: 轻量化预训练语言模型通过合理微调与可解释性工具，能有效实现可信且高效的误信息检测，适合大规模应用。

Abstract: The rapid spread of misinformation on online platforms undermines trust among
individuals and hinders informed decision making. This paper shows an
explainable and computationally efficient pipeline to detect misinformation
using transformer-based pretrained language models (PLMs). We optimize both
RoBERTa and DistilBERT using a two-step strategy: first, we freeze the backbone
and train only the classification head; then, we progressively unfreeze the
backbone layers while applying layer-wise learning rate decay. On two
real-world benchmark datasets, COVID Fake News and FakeNewsNet GossipCop, we
test the proposed approach with a unified protocol of preprocessing and
stratified splits. To ensure transparency, we integrate the Local Interpretable
Model-Agnostic Explanations (LIME) at the token level to present token-level
rationales and SHapley Additive exPlanations (SHAP) at the global feature
attribution level. It demonstrates that DistilBERT achieves accuracy comparable
to RoBERTa while requiring significantly less computational resources. This
work makes two key contributions: (1) it quantitatively shows that a
lightweight PLM can maintain task performance while substantially reducing
computational cost, and (2) it presents an explainable pipeline that retrieves
faithful local and global justifications without compromising performance. The
results suggest that PLMs combined with principled fine-tuning and
interpretability can be an effective framework for scalable, trustworthy
misinformation detection.

</details>


### [11] [Evaluating LLM Story Generation through Large-scale Network Analysis of Social Structures](https://arxiv.org/abs/2510.18932)
*Hiroshi Nonaka,K. E. Perry*

Main category: cs.CL

TL;DR: 提出了一种通过分析故事中人物关系网络来评估大型语言模型生成故事创意的方法，发现模型生成的故事倾向于紧密和积极的人物关系。


<details>
  <summary>Details</summary>
Motivation: 大规模评估大型语言模型创意能力需要难以扩展的人类评估手段，因而需要一种可扩展的自动评估方法。

Method: 通过构建并分析故事中人物关系的带符号网络（正负关系），对1,200多个由四种大型语言模型及人类写作生成的故事进行比较分析。

Result: 发现模型生成的故事在网络密度、聚类以及带符号边权重上均表现出偏向紧密和积极的人物关系，这与已有人工评估一致。

Conclusion: 该方法有效揭示了大型语言模型在叙事创作中的局限性和偏向，为未来语言模型的创意能力评估提供了可扩展的新工具。

Abstract: Evaluating the creative capabilities of large language models (LLMs) in
complex tasks often requires human assessments that are difficult to scale. We
introduce a novel, scalable methodology for evaluating LLM story generation by
analyzing underlying social structures in narratives as signed character
networks. To demonstrate its effectiveness, we conduct a large-scale
comparative analysis using networks from over 1,200 stories, generated by four
leading LLMs (GPT-4o, GPT-4o mini, Gemini 1.5 Pro, and Gemini 1.5 Flash) and a
human-written corpus. Our findings, based on network properties like density,
clustering, and signed edge weights, show that LLM-generated stories
consistently exhibit a strong bias toward tightly-knit, positive relationships,
which aligns with findings from prior research using human assessment. Our
proposed approach provides a valuable tool for evaluating limitations and
tendencies in the creative storytelling of current and future LLMs.

</details>


### [12] [Lost in the Maze: Overcoming Context Limitations in Long-Horizon Agentic Search](https://arxiv.org/abs/2510.18939)
*Howard Yen,Ashwin Paranjape,Mengzhou Xia,Thejas Venkatesh,Jack Hessel,Danqi Chen,Yuhao Zhang*

Main category: cs.CL

TL;DR: 本文提出了SLIM，一种简单轻量的信息管理框架，解决了长路径智能搜索中上下文限制导致的问题，实现了更长且更专注的搜索，且成本更低，工具调用更少，效果优于现有开源框架。


<details>
  <summary>Details</summary>
Motivation: 现有智能搜索框架在长路径任务中因上下文积累过多、工具调用受限或过早停止，难以扩展，影响深度研究等复杂应用的实现。

Method: SLIM将检索划分为独立的搜索和浏览工具，周期性总结路径信息，保持上下文简洁，从而支持长时间、聚焦的搜索过程。

Result: 在多个基础模型中，SLIM在长路径任务上表现出色，尤其在BrowseComp和HLE测试中领先于所有开源框架，且工具调用次数减少4-6倍，幻觉现象也较少。

Conclusion: SLIM的设计有效解决了长路径智能搜索的瓶颈，其分析框架及工具设计对未来长路径智能体开发具有重要参考价值。

Abstract: Long-horizon agentic search requires iteratively exploring the web over long
trajectories and synthesizing information across many sources, and is the
foundation for enabling powerful applications like deep research systems. In
this work, we show that popular agentic search frameworks struggle to scale to
long trajectories primarily due to context limitations-they accumulate long,
noisy content, hit context window and tool budgets, or stop early. Then, we
introduce SLIM (Simple Lightweight Information Management), a simple framework
that separates retrieval into distinct search and browse tools, and
periodically summarizes the trajectory, keeping context concise while enabling
longer, more focused searches. On long-horizon tasks, SLIM achieves comparable
performance at substantially lower cost and with far fewer tool calls than
strong open-source baselines across multiple base models. Specifically, with o3
as the base model, SLIM achieves 56% on BrowseComp and 31% on HLE,
outperforming all open-source frameworks by 8 and 4 absolute points,
respectively, while incurring 4-6x fewer tool calls. Finally, we release an
automated fine-grained trajectory analysis pipeline and error taxonomy for
characterizing long-horizon agentic search frameworks; SLIM exhibits fewer
hallucinations than prior systems. We hope our analysis framework and simple
tool design inform future long-horizon agents.

</details>


### [13] [ProfBench: Multi-Domain Rubrics requiring Professional Knowledge to Answer and Judge](https://arxiv.org/abs/2510.18941)
*Zhilin Wang,Jaehun Jung,Ximing Lu,Shizhe Diao,Ellie Evans,Jiaqi Zeng,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.CL

TL;DR: 本文提出了ProfBench，一个包含7000余项专业知识评价对的大型语言模型评测基准，涵盖物理、化学、金融和咨询领域，借助人类专家评价并通过开发降低成本且公平的LLM评审器，揭示了当前顶尖模型在专业任务上的性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型评估多限于易验证的数学、编程等简单任务，难以反映其在处理专业文档、综合信息和生成报告等复杂实际应用中的能力。

Method: 构建了ProfBench数据集，涵盖多个专业领域的专家评审对，利用开发的降低自我提升偏差且成本显著下降的LLM评审器对这些评价标准进行自动评估，使评测更公平且普及。

Result: 实验发现包括GPT-5-high在内的顶尖模型整体表现仅65.9%，远未达到理想水平；此外，专有模型与开源模型在性能上存在明显差异，延长思考时间对解决复杂专业任务有积极作用。

Conclusion: ProfBench有效揭示了现有大型语言模型在专业领域应用中的短板和挑战，推动了专业性评估方法的公平和可访问性，为未来模型优化和应用提供了重要参考。

Abstract: Evaluating progress in large language models (LLMs) is often constrained by
the challenge of verifying responses, limiting assessments to tasks like
mathematics, programming, and short-form question-answering. However, many
real-world applications require evaluating LLMs in processing professional
documents, synthesizing information, and generating comprehensive reports in
response to user queries. We introduce ProfBench: a set of over 7000
response-criterion pairs as evaluated by human-experts with professional
knowledge across Physics PhD, Chemistry PhD, Finance MBA and Consulting MBA. We
build robust and affordable LLM-Judges to evaluate ProfBench rubrics, by
mitigating self-enhancement bias and reducing the cost of evaluation by 2-3
orders of magnitude, to make it fair and accessible to the broader community.
Our findings reveal that ProfBench poses significant challenges even for
state-of-the-art LLMs, with top-performing models like GPT-5-high achieving
only 65.9\% overall performance. Furthermore, we identify notable performance
disparities between proprietary and open-weight models and provide insights
into the role that extended thinking plays in addressing complex,
professional-domain tasks. Data:
https://huggingface.co/datasets/nvidia/ProfBench and Code:
https://github.com/NVlabs/ProfBench

</details>


### [14] [Dynamic Evaluation for Oversensitivity in LLMs](https://arxiv.org/abs/2510.19005)
*Sophia Xiao Pu,Sitao Cheng,Xin Eric Wang,William Yang Wang*

Main category: cs.CL

TL;DR: 本文提出了一个动态生成针对具体语言模型的防御性过敏数据集的框架，并基于此构建了涵盖25个模型、45万样本的OVERBENCH基准，能够持续监测语言模型的过敏行为。


<details>
  <summary>Details</summary>
Motivation: 现有静态数据集在语言模型不断演进的过程中逐渐失效，导致评估准确度下降，且无法捕捉模型新的防御性过敏行为。

Method: 设计一个动态生成模型特定挑战数据集的框架，收集并聚合不同大型语言模型（LLM）家族的数据，形成一个不断更新的综合性基准OVERBENCH。

Result: OVERBENCH汇聚了来自25个模型共45万个样本，提供了对语言模型防御性过敏行为的动态监控能力，识别出静态数据集未能发现的脆弱点。

Conclusion: 动态、模型特定的数据集和基准能够更有效地反映和监测语言模型的防御性过敏问题，助力模型安全性和交互体验的提升。

Abstract: Oversensitivity occurs when language models defensively reject prompts that
are actually benign. This behavior not only disrupts user interactions but also
obscures the boundary between harmful and harmless content. Existing benchmarks
rely on static datasets that degrade overtime as models evolve, leading to data
contamination and diminished evaluative power. To address this, we develop a
framework that dynamically generates model-specific challenging datasets,
capturing emerging defensive patterns and aligning with each model's unique
behavior. Building on this approach, we construct OVERBENCH, a benchmark that
aggregates these datasets across diverse LLM families, encompassing 450,000
samples from 25 models. OVERBENCH provides a dynamic and evolving perspective
on oversensitivity, allowing for continuous monitoring of defensive triggers as
models advance, highlighting vulnerabilities that static datasets overlook.

</details>


### [15] [Are they lovers or friends? Evaluating LLMs' Social Reasoning in English and Korean Dialogues](https://arxiv.org/abs/2510.19028)
*Eunsu Kim,Junyeong Park,Juhyun Oh,Kiwoong Park,Seyoung Song,A. Seza Dogruoz,Najoung Kim,Alice Oh*

Main category: cs.CL

TL;DR: 本文介绍了一个名为SCRIPTS的中英文电影剧本对话数据集，用于评估大语言模型在社会推理、特别是推断对话者人际关系方面的能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在人机交互中的广泛应用，其在复杂社会情境下的推理能力，尤其是理解并推断人际关系的能力，变得尤为重要。

Method: 构建包含1000条英语和韩语对话的数据集，标注对话中发言者之间关系的概率性标签（如高度可能、较不可能、不可能），由母语者标注。通过评估九个大语言模型在该任务上的表现来衡量其社交推理能力。

Result: 专有大语言模型在英语数据集上的准确率约为75-80%，在韩语数据集上的表现显著下降至58-69%。此外，模型在10-25%的回答中错误选择了“不可能”的关系标签。实验还发现思维模型和链式思考提示对社会推理帮助有限，且可能加剧社会偏见。

Conclusion: 当前大语言模型在社交推理方面存在明显不足，提示研究者需要致力于开发具备更强社会感知能力的语言模型。

Abstract: As large language models (LLMs) are increasingly used in human-AI
interactions, their social reasoning capabilities in interpersonal contexts are
critical. We introduce SCRIPTS, a 1k-dialogue dataset in English and Korean,
sourced from movie scripts. The task involves evaluating models' social
reasoning capability to infer the interpersonal relationships (e.g., friends,
sisters, lovers) between speakers in each dialogue. Each dialogue is annotated
with probabilistic relational labels (Highly Likely, Less Likely, Unlikely) by
native (or equivalent) Korean and English speakers from Korea and the U.S.
Evaluating nine models on our task, current proprietary LLMs achieve around
75-80% on the English dataset, whereas their performance on Korean drops to
58-69%. More strikingly, models select Unlikely relationships in 10-25% of
their responses. Furthermore, we find that thinking models and chain-of-thought
prompting, effective for general reasoning, provide minimal benefits for social
reasoning and occasionally amplify social biases. Our findings reveal
significant limitations in current LLMs' social reasoning capabilities,
highlighting the need for efforts to develop socially-aware language models.

</details>


### [16] [Re:Member: Emotional Question Generation from Personal Memories](https://arxiv.org/abs/2510.19030)
*Zackary Rackauckas,Nobuaki Minematsu,Julia Hirschberg*

Main category: cs.CL

TL;DR: Re:Member系统通过情感表达和记忆驱动的互动，利用用户个人视频和目标语言提问，增强二语学习的情感回忆和对话参与。


<details>
  <summary>Details</summary>
Motivation: 提升二语学习的参与度和情感共鸣，通过记忆和情绪激发更有效的语言学习体验。

Method: 结合WhisperX转录对齐、三帧视觉采样及Style-BERT-VITS2情感合成，利用个性化视频和情感语音样式生成目标语言提问。

Result: 系统成功实现了情感基调与视觉内容的对齐，促进学习者的情感回忆和互动。

Conclusion: 情感表达和个性化媒体在以学习者为中心的教育技术中具有重要作用，Re:Member为此提供了有效示范。

Abstract: We present Re:Member, a system that explores how emotionally expressive,
memory-grounded interaction can support more engaging second language (L2)
learning. By drawing on users' personal videos and generating stylized spoken
questions in the target language, Re:Member is designed to encourage affective
recall and conversational engagement. The system aligns emotional tone with
visual context, using expressive speech styles such as whispers or late-night
tones to evoke specific moods. It combines WhisperX-based transcript alignment,
3-frame visual sampling, and Style-BERT-VITS2 for emotional synthesis within a
modular generation pipeline. Designed as a stylized interaction probe,
Re:Member highlights the role of affect and personal media in learner-centered
educational technologies.

</details>


### [17] [When Can We Trust LLMs in Mental Health? Large-Scale Benchmarks for Reliable LLM Evaluation](https://arxiv.org/abs/2510.19032)
*Abeer Badawi,Elahe Rahimi,Md Tahmid Rahman Laskar,Sheri Grach,Lindsay Bertrand,Lames Danok,Jimmy Huang,Frank Rudzicz,Elham Dolatabadi*

Main category: cs.CL

TL;DR: 该论文介绍了针对大型语言模型（LLMs）心理健康支持评估的新基准，包括大规模对话数据集和评估自动评判可信度的框架。


<details>
  <summary>Details</summary>
Motivation: 现有的心理健康对话评估基准数据量小，可靠性低，且多依赖合成或社交媒体数据，缺乏评估自动评判可信度的框架。

Method: 该研究提出了两个基准：MentalBench-100k（包含10万个真实场景单轮对话及LLM生成的回应）和MentalAlign-70k（比较四个高性能LLM评判与人类专家的评级）；并使用情感认知一致性框架，基于组内相关系数（ICC）评估LLM评判与专家的一致性和偏差。

Result: 分析显示，LLM评判普遍表现出系统性夸大，在指导性和信息性等认知属性上可靠，但在同理心、安全性和相关性方面的评估精度较低。

Conclusion: 该研究为心理健康领域LLM的可靠大规模评估建立了新的方法论和实证基础，并发布了相应的基准数据和代码。

Abstract: Evaluating Large Language Models (LLMs) for mental health support is
challenging due to the emotionally and cognitively complex nature of
therapeutic dialogue. Existing benchmarks are limited in scale, reliability,
often relying on synthetic or social media data, and lack frameworks to assess
when automated judges can be trusted. To address the need for large-scale
dialogue datasets and judge reliability assessment, we introduce two benchmarks
that provide a framework for generation and evaluation. MentalBench-100k
consolidates 10,000 one-turn conversations from three real scenarios datasets,
each paired with nine LLM-generated responses, yielding 100,000 response pairs.
MentalAlign-70k}reframes evaluation by comparing four high-performing LLM
judges with human experts across 70,000 ratings on seven attributes, grouped
into Cognitive Support Score (CSS) and Affective Resonance Score (ARS). We then
employ the Affective Cognitive Agreement Framework, a statistical methodology
using intraclass correlation coefficients (ICC) with confidence intervals to
quantify agreement, consistency, and bias between LLM judges and human experts.
Our analysis reveals systematic inflation by LLM judges, strong reliability for
cognitive attributes such as guidance and informativeness, reduced precision
for empathy, and some unreliability in safety and relevance. Our contributions
establish new methodological and empirical foundations for reliable,
large-scale evaluation of LLMs in mental health. We release the benchmarks and
codes at: https://github.com/abeerbadawi/MentalBench/

</details>


### [18] [From Memorization to Generalization: Fine-Tuning Large Language Models for Biomedical Term-to-Identifier Normalization](https://arxiv.org/abs/2510.19036)
*Suswitha Pericharla,Daniel B. Hier,Tayo Obafemi-Ajayi*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在生物医学术语标准化任务中的表现，发现模型对不同术语库的记忆和泛化能力存在显著差异，指出了影响微调效果的因素。


<details>
  <summary>Details</summary>
Motivation: 生物医学数据整合依赖自动术语标准化，即将自然语言术语映射到标准标识符，保证语义互操作性。鉴于大型语言模型在此任务上的表现参差不齐，探讨其适应性和限制具有重要意义。

Method: 采用Llama 3.1 8B模型进行微调，评估模型在不同生物医学本体（如GO、HPO、GENE）上的记忆能力（训练术语表现）和泛化能力（验证术语表现）；并比较不同模型规模（包括GPT-4o）的基线准确率，同时通过嵌入分析研究术语与标识符的语义对齐情况。

Result: 微调后，模型在GO术语映射上记忆能力显著提升（准确率提升达77%），但在HPO上提升有限。泛化能力仅在蛋白质-基因(GENE)映射上有所提高（13.9%），GO和HPO的泛化效果几乎无效。GPT-4o基线表现优于Llama模型。嵌入分析显示基因符号与蛋白名称语义紧密，而GO和HPO的术语与标识符语义对齐较弱。

Conclusion: 微调效果受标识符热度和词汇化程度共同影响：高频标识符易被预训练模型记住，词汇化标识符（如基因符号）促进语义泛化；而非词汇化且热度较低的GO和HPO标识符仅能实现机械记忆。该研究为预判微调是否能提升事实回忆能力提供了理论框架。

Abstract: Effective biomedical data integration depends on automated term
normalization, the mapping of natural language biomedical terms to standardized
identifiers. This linking of terms to identifiers is essential for semantic
interoperability. Large language models (LLMs) show promise for this task but
perform unevenly across terminologies. We evaluated both memorization
(training-term performance) and generalization (validation-term performance)
across multiple biomedical ontologies. Fine-tuning Llama 3.1 8B revealed marked
differences by terminology. GO mappings showed strong memorization gains (up to
77% improvement in term-to-identifier accuracy), whereas HPO showed minimal
improvement. Generalization occurred only for protein-gene (GENE) mappings
(13.9% gain), while fine-tuning for HPO and GO yielded negligible transfer.
Baseline accuracy varied by model scale, with GPT-4o outperforming both Llama
variants for all terminologies. Embedding analyses showed tight semantic
alignment between gene symbols and protein names but weak alignment between
terms and identifiers for GO or HPO, consistent with limited lexicalization.
Fine-tuning success depended on two interacting factors: identifier popularity
and lexicalization. Popular identifiers were more likely encountered during
pretraining, enhancing memorization. Lexicalized identifiers, such as gene
symbols, enabled semantic generalization. By contrast, arbitrary identifiers in
GO and HPO constrained models to rote learning. These findings provide a
predictive framework for when fine-tuning enhances factual recall versus when
it fails due to sparse or non-lexicalized identifiers.

</details>


### [19] [That's Deprecated! Understanding, Detecting, and Steering Knowledge Conflicts in Language Models for Code Generation](https://arxiv.org/abs/2510.19116)
*Jaesung Bae,Cameron Churchwell,Mitchell Hermon,Tsun-An Hsieh,Jocelyn Xu,Yekaterina Yegorova,Mark Hasegawa-Johnson,Heng Ji*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型面对内在知识与提示中冲突信息时的表现，提出了一个适用于代码生成领域的知识冲突构建框架和评估方法，实验显示大模型能较好检测知识冲突并通过激活层引导提升表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注问答任务中知识冲突，缺乏对代码生成领域的探索，且缺少通用的冲突构建和评估体系。

Method: 提出了一个领域无关的知识冲突构建框架，设计了针对代码冲突场景的评估方法和数据集，利用激活层引导技术进行冲突处理。

Result: 大模型在知识冲突检测上准确率达到80.65%，激活层引导方法相比随机基线提高了12.6%的引导成功率，表现受模型大小、任务领域和引导方向影响。

Conclusion: 大型语言模型参数中已内含知识冲突概念，结合激活层引导可有效提升处理冲突的能力，但需综合考虑模型和任务特性以实现最佳效果。

Abstract: This paper investigates how large language models (LLMs) behave when faced
with discrepancies between their parametric knowledge and conflicting
information contained in a prompt. Building on prior question-answering (QA)
research, we extend the investigation of knowledge conflicts to the realm of
code generation. We propose a domain-agnostic framework for constructing and
interpreting such conflicts, along with a novel evaluation method and dataset
tailored to code conflict scenarios. Our experiments indicate that sufficiently
large LLMs encode the notion of a knowledge conflict in their parameters,
enabling us to detect knowledge conflicts with up to \textbf{80.65\%} accuracy.
Building on these insights, we show that activation-level steering can achieve
up to a \textbf{12.6\%} improvement in steering success over a random baseline.
However, effectiveness depends critically on balancing model size, task domain,
and steering direction. The experiment code and data will be made publicly
available after acceptance.

</details>


### [20] [A Graph Signal Processing Framework for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.19117)
*Valentin Noël*

Main category: cs.CL

TL;DR: 本文提出利用图信号处理的频谱分析框架，通过分析Transformer层中注意力动态图上的信号模式，区分语言模型的事实推理和幻觉表现。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽然表现优异，但难以区分事实推理与幻觉，急需有效的检测方法。

Method: 将Transformer层视为动态图，利用图信号处理技术定义Dirichlet能量、谱熵和高频能量比等诊断指标，捕捉模型在生成过程中频谱特征。

Result: 实验表明事实语句在频谱上表现出一致的低频能量集中“能量山”，而不同类型幻觉表现不同频谱特征。通过频谱特征构建的检测器准确率达到88.75%，显著优于基于困惑度的75%。

Conclusion: 频谱几何分析有效捕捉语言模型的推理与错误行为，具有实际幻觉检测价值，为后续幻觉识别提供理论框架。

Abstract: Large language models achieve impressive results but distinguishing factual
reasoning from hallucinations remains challenging. We propose a spectral
analysis framework that models transformer layers as dynamic graphs induced by
attention, with token embeddings as signals on these graphs. Through graph
signal processing, we define diagnostics including Dirichlet energy, spectral
entropy, and high-frequency energy ratios, with theoretical connections to
computational stability. Experiments across GPT architectures suggest universal
spectral patterns: factual statements exhibit consistent "energy mountain"
behavior with low-frequency convergence, while different hallucination types
show distinct signatures. Logical contradictions destabilize spectra with large
effect sizes ($g>1.0$), semantic errors remain stable but show connectivity
drift, and substitution hallucinations display intermediate perturbations. A
simple detector using spectral signatures achieves 88.75% accuracy versus 75%
for perplexity-based baselines, demonstrating practical utility. These findings
indicate that spectral geometry may capture reasoning patterns and error
behaviors, potentially offering a framework for hallucination detection in
large language models.

</details>


### [21] [Training-Free Spectral Fingerprints of Voice Processing in Transformers](https://arxiv.org/abs/2510.19131)
*Valentin Noël*

Main category: cs.CL

TL;DR: 不同Transformer架构通过不同的连接模式实现相同的语言计算，这些特征通过谱分析可检测。本文利用图信号处理分析了20种语言和3种模型家族中语态变换期间代数连通性的变化，揭示了各模型的独特架构特征。


<details>
  <summary>Details</summary>
Motivation: 不同的Transformer模型在处理相同的语言任务时，由于结构差异会留下特定的计算指纹，识别这些指纹有助于理解模型的架构偏差及其行为差异。

Method: 本文采用图信号处理方法，对Transformer模型中注意力所诱导的Token图进行谱分析，重点考察代数连通性（Fiedler值）的变化，特别是在语态变换期间的早期层（2-5层）。通过比较20种语言和3个模型，研究结构签名与行为表现的相关性及注意力头的影响。

Result: 发现Phi-3-Mini模型在英语中早期层表现出显著的代数连通性下降，而在其他19种语言中影响有限；Qwen2.5-7B模型在形态丰富的语言中变化较大；LLaMA-3.2-1B体现出系统但温和的响应。此外，这些谱特征与行为差异高度相关（Phi-3 r=-0.976），且受到特定注意力头消融的调制。

Conclusion: 训练重点会在模型内部留下可测量的计算印记，反映为语法变换时的连通性模式。该谱分析框架不仅能够揭示架构偏见，还能作为无训练需求的诊断工具，用于支持模型的可解释性和可靠性分析。

Abstract: Different transformer architectures implement identical linguistic
computations via distinct connectivity patterns, yielding model imprinted
``computational fingerprints'' detectable through spectral analysis. Using
graph signal processing on attention induced token graphs, we track changes in
algebraic connectivity (Fiedler value, $\Delta\lambda_2$) under voice
alternation across 20 languages and three model families, with a prespecified
early window (layers 2--5). Our analysis uncovers clear architectural
signatures: Phi-3-Mini shows a dramatic English specific early layer disruption
($\overline{\Delta\lambda_2}_{[2,5]}\!\approx\!-0.446$) while effects in 19
other languages are minimal, consistent with public documentation that
positions the model primarily for English use. Qwen2.5-7B displays small,
distributed shifts that are largest for morphologically rich languages, and
LLaMA-3.2-1B exhibits systematic but muted responses. These spectral signatures
correlate strongly with behavioral differences (Phi-3: $r=-0.976$) and are
modulated by targeted attention head ablations, linking the effect to early
attention structure and confirming functional relevance. Taken together, the
findings are consistent with the view that training emphasis can leave
detectable computational imprints: specialized processing strategies that
manifest as measurable connectivity patterns during syntactic transformations.
Beyond voice alternation, the framework differentiates reasoning modes,
indicating utility as a simple, training free diagnostic for revealing
architectural biases and supporting model reliability analysis.

</details>


### [22] [Tibetan Language and AI: A Comprehensive Survey of Resources, Methods and Challenges](https://arxiv.org/abs/2510.19144)
*Cheng Huang,Nyima Tashi,Fan Gao,Yutong Liu,Jiahao Li,Hao Tian,Siyang Jiang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Jin Zhang,Xiao Feng,Hao Wang,Jie Tang,Guojie Tang,Xiangxiang Wang,Jia Zhang,Tsengdar Lee,Yongbin Yu*

Main category: cs.CL

TL;DR: 本文综述了藏语AI研究的现状，涵盖数据资源、NLP任务、机器翻译、语音识别及大型语言模型的发展，指出了数据稀缺和评测标准缺失等瓶颈，探讨了跨语言迁移和多模态学习的潜力。


<details>
  <summary>Details</summary>
Motivation: 藏语作为亚洲的重要低资源语言，其独特的语言和社会文化特征对AI研究提出了挑战，但相关数据资源匮乏，缺少统一基准和工具，导致该领域研究有限。

Method: 本文系统分类现有藏语数据集和工具，评估不同任务中使用的方法并比较性能，分析存在的瓶颈，并讨论跨语言迁移、多模态学习和社区驱动的资源创建等发展方向。

Result: 整理了藏语文本和语音数据资源，NLP任务、机器翻译、语音识别和大型语言模型的进展，发现主要问题是数据稀缺、正字法差异和缺乏统一评测指标。

Conclusion: 本文为藏语AI研究提供了基础性综述，呼吁通过合作构建包容且可持续的低资源语言AI生态系统，促进藏语AI技术的发展。

Abstract: Tibetan, one of the major low-resource languages in Asia, presents unique
linguistic and sociocultural characteristics that pose both challenges and
opportunities for AI research. Despite increasing interest in developing AI
systems for underrepresented languages, Tibetan has received limited attention
due to a lack of accessible data resources, standardized benchmarks, and
dedicated tools. This paper provides a comprehensive survey of the current
state of Tibetan AI in the AI domain, covering textual and speech data
resources, NLP tasks, machine translation, speech recognition, and recent
developments in LLMs. We systematically categorize existing datasets and tools,
evaluate methods used across different tasks, and compare performance where
possible. We also identify persistent bottlenecks such as data sparsity,
orthographic variation, and the lack of unified evaluation metrics.
Additionally, we discuss the potential of cross-lingual transfer, multi-modal
learning, and community-driven resource creation. This survey aims to serve as
a foundational reference for future work on Tibetan AI research and encourages
collaborative efforts to build an inclusive and sustainable AI ecosystem for
low-resource languages.

</details>


### [23] ["You Are Rejected!": An Empirical Study of Large Language Models Taking Hiring Evaluations](https://arxiv.org/abs/2510.19167)
*Dingjie Fu,Dianxing Shi*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）能否通过科技公司的职业能力评估，结果显示所有测试的LLMs均未通过。


<details>
  <summary>Details</summary>
Motivation: 随着互联网和人工智能的发展，科技公司对软件及算法工程师需求量大，采用统一的多阶段选拔流程评估应聘者能力。受到LLMs在编码和推理任务中表现出色的启发，本文探讨LLMs是否能通过此类职业评估。

Method: 利用先进的LLMs针对广泛使用的职业评估问卷生成答案，并与公司标准答案进行对比分析。

Result: 发现模型生成的答案与公司参考答案存在显著不一致，所有评估的LLMs均未通过职业评估。

Conclusion: 尽管LLMs在编码和推理领域表现突出，但其尚无法通过用于招聘的专业能力评估，表明当前LLMs离成为合格工程师仍有差距。

Abstract: With the proliferation of the internet and the rapid advancement of
Artificial Intelligence, leading technology companies face an urgent annual
demand for a considerable number of software and algorithm engineers. To
efficiently and effectively identify high-potential candidates from thousands
of applicants, these firms have established a multi-stage selection process,
which crucially includes a standardized hiring evaluation designed to assess
job-specific competencies. Motivated by the demonstrated prowess of Large
Language Models (LLMs) in coding and reasoning tasks, this paper investigates a
critical question: Can LLMs successfully pass these hiring evaluations? To this
end, we conduct a comprehensive examination of a widely used professional
assessment questionnaire. We employ state-of-the-art LLMs to generate responses
and subsequently evaluate their performance. Contrary to any prior expectation
of LLMs being ideal engineers, our analysis reveals a significant inconsistency
between the model-generated answers and the company-referenced solutions. Our
empirical findings lead to a striking conclusion: All evaluated LLMs fails to
pass the hiring evaluation.

</details>


### [24] [Think Straight, Stop Smart: Structured Reasoning for Efficient Multi-Hop RAG](https://arxiv.org/abs/2510.19171)
*Jihwan Bang,Juntae Lee,Seunghan Yang,Sungha Choi*

Main category: cs.CL

TL;DR: 该论文提出了TSSS，一种高效的多跳检索增强生成框架，用模板推理和检索终止策略，提升推理速度和答案稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有多跳RAG方法效率低，频繁生成重复token且依赖随机停止，导致token使用过多和终止不稳定。

Method: 提出TSSS框架：利用模板推理缓存重复前缀并锚定子查询，减少生成token；引入基于检索器的确定性终止条件，防止子查询重复。

Result: 在HotpotQA、2WikiMultiHop和MuSiQue数据集上，TSSS实现了RAG-CoT方法中的最高准确率和竞争效率。

Conclusion: TSSS通过结构化推理和终止控制，提高了多跳RAG的推理效率和稳定性，适合效率受限如设备端推理场景。

Abstract: Multi-hop retrieval-augmented generation (RAG) is a promising strategy for
complex reasoning, yet existing iterative prompting approaches remain
inefficient. They often regenerate predictable token sequences at every step
and rely on stochastic stopping, leading to excessive token usage and unstable
termination. We propose TSSS (Think Straight, Stop Smart), a structured
multi-hop RAG framework designed for efficiency. TSSS introduces (i) a
template-based reasoning that caches recurring prefixes and anchors sub-queries
to the main question, reducing token generation cost while promoting stable
reasoning, and (ii) a retriever-based terminator, which deterministically halts
reasoning once additional sub-queries collapse into repetition. This separation
of structured reasoning and termination control enables both faster inference
and more reliable answers. On HotpotQA, 2WikiMultiHop, and MuSiQue, TSSS
achieves state-of-the-art accuracy and competitive efficiency among RAG-CoT
approaches, highlighting its effectiveness in efficiency-constrained scenarios
such as on-device inference.

</details>


### [25] [When Facts Change: Probing LLMs on Evolving Knowledge with evolveQA](https://arxiv.org/abs/2510.19172)
*Nishanth Sridhar Nakshatri,Shamik Roy,Manoj Ghuhan Arivazhagan,Hanhan Zhou,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: LLMs在处理随时间变化的知识冲突时表现不佳，evolveQA基于真实时间标记语料库设计测试，结果显示LLMs性能显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有评测主要关注流行实体且缺乏动态结构，无法公平评估不同知识截止日期的LLMs。

Method: 构建基于AWS、Azure和WHO时间标记数据的evolveQA，自动生成针对不同知识截止日期的问答。

Result: 通过测试12个LLMs，在动态知识任务上性能比静态问题下降高达31%。

Conclusion: LLMs对时变知识的适应性不足，需改进以处理知识的动态演化。

Abstract: LLMs often fail to handle temporal knowledge conflicts--contradictions
arising when facts evolve over time within their training data. Existing
studies evaluate this phenomenon through benchmarks built on structured
knowledge bases like Wikidata, but they focus on widely-covered,
easily-memorized popular entities and lack the dynamic structure needed to
fairly evaluate LLMs with different knowledge cut-off dates. We introduce
evolveQA, a benchmark specifically designed to evaluate LLMs on temporally
evolving knowledge, constructed from 3 real-world, time-stamped corpora: AWS
updates, Azure changes, and WHO disease outbreak reports. Our framework
identifies naturally occurring knowledge evolution and generates questions with
gold answers tailored to different LLM knowledge cut-off dates. Through
extensive evaluation of 12 open and closed-source LLMs across 3 knowledge
probing formats, we demonstrate significant performance drops of up to 31% on
evolveQA compared to static knowledge questions.

</details>


### [26] [Interpretable Question Answering with Knowledge Graphs](https://arxiv.org/abs/2510.19181)
*Kartikeya Aneja,Manasvi Srivastava,Subhayan Das,Nagender Aneja*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识图谱检索的问答系统，不依赖大型语言模型的检索增强生成，采用小型释义模型对实体关系边进行释义。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的检索增强生成方法成本高且复杂，本研究旨在探索纯知识图谱检索结合小型释义模型的高效问答系统。

Method: 系统分为两阶段：第一阶段对文档预处理生成问答对，第二阶段将问答对转换为知识图谱，通过嵌入和模糊检索技术查询知识图谱，结果进行重排序并用小型释义模型释义实体关系边以生成最终答案。

Result: 在CRAG基准测试中，使用LLAMA-3.2和GPT-3.5-Turbo作为评判者，系统分别达到71.9%和54.4%的准确率。

Conclusion: 该方法证实了无需依赖大规模语言模型的检索增强生成，通过知识图谱检索和释义模型也能实现有效的问答系统。

Abstract: This paper presents a question answering system that operates exclusively on
a knowledge graph retrieval without relying on retrieval augmented generation
(RAG) with large language models (LLMs). Instead, a small paraphraser model is
used to paraphrase the entity relationship edges retrieved from querying the
knowledge graph. The proposed pipeline is divided into two main stages. The
first stage involves pre-processing a document to generate sets of
question-answer (QA) pairs. The second stage converts these QAs into a
knowledge graph from which graph-based retrieval is performed using embeddings
and fuzzy techniques. The graph is queried, re-ranked, and paraphrased to
generate a final answer. This work includes an evaluation using LLM-as-a-judge
on the CRAG benchmark, which resulted in accuracies of 71.9% and 54.4% using
LLAMA-3.2 and GPT-3.5-Turbo, respectively.

</details>


### [27] [Multi-Faceted Evaluation of Tool-Augmented Dialogue Systems](https://arxiv.org/abs/2510.19186)
*Zhaoyi Joey Hou,Tanya Shourya,Yingfan Wang,Shamik Roy,Vinayshekhar Bannihatti Kumar,Rashmi Gangadharaiah*

Main category: cs.CL

TL;DR: 本文针对使用外部工具的对话式AI系统提出了TRACE基准和SCOPE评估框架，以解决现有评估方法无法全面捕捉多轮工具增强对话中的关键错误问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法不能有效评估多轮工具增强对话中的误差，特别是当代理错误解释工具结果但仍能得到用户满意时。

Method: 提出了TRACE基准，系统合成了涵盖多样错误案例的工具增强对话；以及SCOPE评估框架，自动发现多样错误模式和评估标准。

Result: 实验表明SCOPE在准确发现错误方面显著优于基线方法，尤其是在用户满意度信号具有误导性的复杂案例中表现突出。

Conclusion: TRACE和SCOPE有效提升了对工具增强对话系统错误的检测能力，为评估此类系统提供了更全面和精确的方法。

Abstract: Evaluating conversational AI systems that use external tools is challenging,
as errors can arise from complex interactions among user, agent, and tools.
While existing evaluation methods assess either user satisfaction or agents'
tool-calling capabilities, they fail to capture critical errors in multi-turn
tool-augmented dialogues-such as when agents misinterpret tool results yet
appear satisfactory to users. We introduce TRACE, a benchmark of systematically
synthesized tool-augmented conversations covering diverse error cases, and
SCOPE, an evaluation framework that automatically discovers diverse error
patterns and evaluation rubrics in tool-augmented dialogues. Experiments show
SCOPE significantly outperforms the baseline, particularly on challenging cases
where user satisfaction signals are misleading.

</details>


### [28] [DiSRouter: Distributed Self-Routing for LLM Selections](https://arxiv.org/abs/2510.19208)
*Hang Zheng,Hongshen Xu,Yongkai Lin,Shuai Fan,Lu Chen,Kai Yu*

Main category: cs.CL

TL;DR: 本文提出了DiSRouter，一种基于分布式自我路由的大型语言模型查询路由系统，通过让每个模型自主判断是否回答或转发查询，实现更灵活、高效的多模型协作。


<details>
  <summary>Details</summary>
Motivation: 现有的查询路由系统依赖集中式路由器，缺乏灵活性且性能有限，难以充分理解不同大型语言模型的知识边界。

Method: 引入分布式自我路由范式，设计两阶段自我意识训练流程，增强每个模型的自知能力，使其在查询流程中自主决策回答或转发。

Result: 大量实验证明DiSRouter在多种场景下性能优于现有方法，能有效区分简单与复杂查询，并具备良好的域外泛化能力。

Conclusion: 利用大型语言模型的内在自我意识进行查询路由优于外部评估，推动更模块化、高效的多智能体系统发展。

Abstract: The proliferation of Large Language Models (LLMs) has created a diverse
ecosystem of models with highly varying performance and costs, necessitating
effective query routing to balance performance and expense. Current routing
systems often rely on a centralized external router trained on a fixed set of
LLMs, making them inflexible and prone to poor performance since the small
router can not fully understand the knowledge boundaries of different LLMs. We
introduce DiSRouter (Distributed Self-Router), a novel paradigm that shifts
from centralized control to distributed routing. In DiSRouter, a query
traverses a network of LLM agents, each independently deciding whether to
answer or route to other agents based on its own self-awareness, its ability to
judge its competence. This distributed design offers superior flexibility,
scalability, and generalizability. To enable this, we propose a two-stage
Self-Awareness Training pipeline that enhances each LLM's self-awareness.
Extensive experiments demonstrate that DiSRouter significantly outperforms
existing routing methods in utility across various scenarios, effectively
distinguishes between easy and hard queries, and shows strong generalization to
out-of-domain tasks. Our work validates that leveraging an LLM's intrinsic
self-awareness is more effective than external assessment, paving the way for
more modular and efficient multi-agent systems.

</details>


### [29] [Modality Matching Matters: Calibrating Language Distances for Cross-Lingual Transfer in URIEL+](https://arxiv.org/abs/2510.19217)
*York Hay Ng,Aditya Khan,Xiang Lu,Matteo Salloum,Michael Zhou,Phuong H. Hoang,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文提出了一种基于类型匹配的语言距离框架，通过结构感知的表示方法融合地理、基因和典型语言学信号，从而提升跨语言迁移的效果。


<details>
  <summary>Details</summary>
Motivation: 现有语言知识库如URIEL+采用统一的向量表示，无法有效捕捉语言数据多样的结构特性，且缺乏将多种语言距离信号综合为单一分数的合理方法。

Method: 针对不同类型的语言距离提出专门的结构感知表示方法：地理距离使用说话者加权分布，基因距离使用双曲嵌入，典型性使用潜变量模型。同时将这些信号融合成一个稳健的、任务无关的复合距离。

Result: 所提出的表示方法和复合距离在多种自然语言处理任务中选择迁移语言时均带来了性能提升。

Conclusion: 提出的结构感知语言距离框架为多语言研究提供了更合理有效的工具，改善了跨语言迁移的效果。

Abstract: Existing linguistic knowledge bases such as URIEL+ provide valuable
geographic, genetic and typological distances for cross-lingual transfer but
suffer from two key limitations. One, their one-size-fits-all vector
representations are ill-suited to the diverse structures of linguistic data,
and two, they lack a principled method for aggregating these signals into a
single, comprehensive score. In this paper, we address these gaps by
introducing a framework for type-matched language distances. We propose novel,
structure-aware representations for each distance type: speaker-weighted
distributions for geography, hyperbolic embeddings for genealogy, and a latent
variables model for typology. We unify these signals into a robust,
task-agnostic composite distance. In selecting transfer languages, our
representations and composite distances consistently improve performance across
a wide range of NLP tasks, providing a more principled and effective toolkit
for multilingual research.

</details>


### [30] [SheetBrain: A Neuro-Symbolic Agent for Accurate Reasoning over Complex and Large Spreadsheets](https://arxiv.org/abs/2510.19247)
*Ziwei Wang,Jiayuan Su,Mengyu Zhou,Huaxing Zeng,Mengni Jia,Xiao Lv,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SheetBrain的神经符号双工作流代理框架，旨在提升大语言模型对复杂电子表格的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在理解复杂表格结构和确保推理正确性方面存在困难，影响了电子表格问答和操作任务的表现。

Method: SheetBrain框架包含理解模块、执行模块和验证模块，分别负责生成表格概览、集成Python沙盒实现多轮推理及验证推理正确性，并支持错误时重新执行。

Result: 在多个公开电子表格问答和操作基准测试中，SheetBrain显著提升了准确率，并且在新引入的针对大规模多表结构复杂表格的SheetBench上表现优异。

Conclusion: SheetBrain有效解决了复杂表格理解与推理的挑战，为电子表格自动化处理提供了可靠的解决方案。代码已公开。

Abstract: Understanding and reasoning over complex spreadsheets remain fundamental
challenges for large language models (LLMs), which often struggle with
accurately capturing the complex structure of tables and ensuring reasoning
correctness. In this work, we propose SheetBrain, a neuro-symbolic dual
workflow agent framework designed for accurate reasoning over tabular data,
supporting both spreadsheet question answering and manipulation tasks.
SheetBrain comprises three core modules: an understanding module, which
produces a comprehensive overview of the spreadsheet - including sheet summary
and query-based problem insight to guide reasoning; an execution module, which
integrates a Python sandbox with preloaded table-processing libraries and an
Excel helper toolkit for effective multi-turn reasoning; and a validation
module, which verifies the correctness of reasoning and answers, triggering
re-execution when necessary. We evaluate SheetBrain on multiple public tabular
QA and manipulation benchmarks, and introduce SheetBench, a new benchmark
targeting large, multi-table, and structurally complex spreadsheets.
Experimental results show that SheetBrain significantly improves accuracy on
both existing benchmarks and the more challenging scenarios presented in
SheetBench. Our code is publicly available at
https://github.com/microsoft/SheetBrain.

</details>


### [31] [Difficulty-Controllable Multiple-Choice Question Generation Using Large Language Models and Direct Preference Optimization](https://arxiv.org/abs/2510.19265)
*Yuto Tomikawa,Masaki Uto*

Main category: cs.CL

TL;DR: 本文提出了一种基于大语言模型的难度可控选择题生成方法，用于提升阅读理解的适应性学习支持。


<details>
  <summary>Details</summary>
Motivation: 传统难度可控问答生成方法存在不能直接生成选择题且难度控制不精确的问题。

Method: 利用直接偏好优化技术训练大语言模型，实现多选题的难度可控生成。

Result: 所提方法在难度控制准确性方面表现优于传统方法。

Conclusion: 该方法有效解决了传统模型在生成多选题和难度控制上的限制，提升了教育场景中问答生成的实用性。

Abstract: Difficulty-controllable question generation for reading comprehension has
gained significant attention in the field of education as a fundamental tool
for adaptive learning support. Although several neural question generation
methods have recently succeeded in controlling difficulty, conventional
approaches still face two major limitations. First, they cannot directly
generate multiple-choice questions, which are the most widely used question
type in educational contexts. Second, they are not explicitly trained to
optimize the accuracy of difficulty control, leaving room for further
improvement in difficulty controllability. To address these limitations, this
study proposes a novel difficulty-controllable multiple-choice question
generation method for reading comprehension which leverages a large language
model trained using a direct preference optimization technique to improve the
accuracy of difficulty control.

</details>


### [32] [TheMCPCompany: Creating General-purpose Agents with Task-specific Tools](https://arxiv.org/abs/2510.19286)
*Reza Esfandiarpoor,Vishwas Suryanarayanan,Stephen H. Bach,Vishal Chowdhary,Anthony Aue*

Main category: cs.CL

TL;DR: 本文介绍了TheMCPCompany基准，用于评估大型语言模型调用工具的能力，展示了工具调用在提高性能和降低成本方面的潜力，但现有模型在复杂环境下的工具检索和组合仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管工具集数量增长，但当前通用代理主要依赖网页浏览器，缺乏对多种真实服务API调用的系统评测。

Method: 构建包含18000多个工具的MCP服务器，提供真实标注的地面真值工具；进行基于地面真值和工具检索的性能评测。

Result: 工具调用模型性能优于或不低于浏览器代理，小模型工具检索能力有限，GPT-5工具检索性能接近地面真值工具使用。

Conclusion: 先进推理模型在简单环境中能有效发现工具，但在复杂企业环境中工具导航和复合应用仍有较大困难，需改进推理与检索能力。

Abstract: Since the introduction of the Model Context Protocol (MCP), the number of
available tools for Large Language Models (LLMs) has increased significantly.
These task-specific tool sets offer an alternative to general-purpose tools
such as web browsers, while being easier to develop and maintain than GUIs.
However, current general-purpose agents predominantly rely on web browsers for
interacting with the environment. Here, we introduce TheMCPCompany, a benchmark
for evaluating tool-calling agents on tasks that involve interacting with
various real-world services. We use the REST APIs of these services to create
MCP servers, which include over 18,000 tools. We also provide manually
annotated ground-truth tools for each task. In our experiments, we use the
ground truth tools to show the potential of tool-calling agents for both
improving performance and reducing costs assuming perfect tool retrieval. Next,
we explore agent performance using tool retrieval to study the real-world
practicality of tool-based agents. While all models with tool retrieval perform
similarly or better than browser-based agents, smaller models cannot take full
advantage of the available tools through retrieval. On the other hand, GPT-5's
performance with tool retrieval is very close to its performance with
ground-truth tools. Overall, our work shows that the most advanced reasoning
models are effective at discovering tools in simpler environments, but
seriously struggle with navigating complex enterprise environments.
TheMCPCompany reveals that navigating tens of thousands of tools and combining
them in non-trivial ways to solve complex problems is still a challenging task
for current models and requires both better reasoning and better retrieval
models.

</details>


### [33] [JointCQ: Improving Factual Hallucination Detection with Joint Claim and Query Generation](https://arxiv.org/abs/2510.19310)
*Fan Xu,Huixuan Zhang,Zhenliang Zhang,Jiahao Wang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文提出了JointCQ框架，联合生成声明和查询以提高大语言模型幻觉检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型存在幻觉问题，传统幻觉检测在声明提取和查询生成阶段表现不足，导致检测性能下降。

Method: 设计评估标准筛选训练数据，对语言模型进行联合声明与查询生成微调，提供可靠输入用于搜索和验证。

Result: 在多项开放领域问答幻觉检测基准测试中，JointCQ方法优于现有方法。

Conclusion: JointCQ框架有效提升了幻觉检测系统的准确性，有助于构建更可信和透明的大语言模型系统。

Abstract: Current large language models (LLMs) often suffer from hallucination issues,
i,e, generating content that appears factual but is actually unreliable. A
typical hallucination detection pipeline involves response decomposition (i.e.,
claim extraction), query generation, evidence collection (i.e., search or
retrieval), and claim verification. However, existing methods exhibit
limitations in the first two stages, such as context loss during claim
extraction and low specificity in query generation, resulting in degraded
performance across the hallucination detection pipeline. In this work, we
introduce JointCQ https://github.com/pku0xff/JointCQ, a joint claim-and-query
generation framework designed to construct an effective and efficient
claim-query generator. Our framework leverages elaborately designed evaluation
criteria to filter synthesized training data, and finetunes a language model
for joint claim extraction and query generation, providing reliable and
informative inputs for downstream search and verification. Experimental results
demonstrate that our method outperforms previous methods on multiple
open-domain QA hallucination detection benchmarks, advancing the goal of more
trustworthy and transparent language model systems.

</details>


### [34] [KORE: Enhancing Knowledge Injection for Large Multimodal Models via Knowledge-Oriented Augmentations and Constraints](https://arxiv.org/abs/2510.19316)
*Kailin Jiang,Hongbo Jiang,Ning Jiang,Zhi Gao,Jinhe Bi,Yuchen Ren,Bin Li,Yuntao Du,Lei Liu,Qing Li*

Main category: cs.CL

TL;DR: 提出KORE方法，有效向大型多模态模型注入新知识，同时保留旧知识，缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型知识静态有限，难以跟上现实世界变化，需实现知识的持续适应和保留。

Method: KORE通过知识导向的数据增强自动构建结构化知识，结合协方差矩阵约束对适配器初始化，确保新知识注入的准确性和旧知识保留。

Result: 在多个大型多模态模型上，KORE表现出优越的新知识注入效果，显著缓解灾难性遗忘。

Conclusion: KORE方法有效解决了知识适应与保留的矛盾，大幅提升大型多模态模型的持续学习能力。

Abstract: Large Multimodal Models encode extensive factual knowledge in their
pre-trained weights. However, its knowledge remains static and limited, unable
to keep pace with real-world developments, which hinders continuous knowledge
acquisition. Effective knowledge injection thus becomes critical, involving two
goals: knowledge adaptation (injecting new knowledge) and knowledge retention
(preserving old knowledge). Existing methods often struggle to learn new
knowledge and suffer from catastrophic forgetting. To address this, we propose
KORE, a synergistic method of KnOwledge-oRientEd augmentations and constraints
for injecting new knowledge into large multimodal models while preserving old
knowledge. Unlike general text or image data augmentation, KORE automatically
converts individual knowledge items into structured and comprehensive knowledge
to ensure that the model accurately learns new knowledge, enabling accurate
adaptation. Meanwhile, KORE stores previous knowledge in the covariance matrix
of LMM's linear layer activations and initializes the adapter by projecting the
original weights into the matrix's null space, defining a fine-tuning direction
that minimizes interference with previous knowledge, enabling powerful
retention. Extensive experiments on various LMMs, including LLaVA-v1.5-7B,
LLaVA-v1.5-13B, and Qwen2.5-VL-7B, show that KORE achieves superior new
knowledge injection performance and effectively mitigates catastrophic
forgetting.

</details>


### [35] [HAD: HAllucination Detection Language Models Based on a Comprehensive Hallucination Taxonomy](https://arxiv.org/abs/2510.19318)
*Fan Xu,Xinyu Hu,Zhenghan Yu,Li Lin,Xu Zhang,Yang Zhang,Wei Zhou,Jinjie Gu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文提出了包含11类幻觉的全面分类体系，并开发了HAD模型，整合幻觉检测、跨度级识别和纠正，训练数据集约9万条，适用多种NLG任务。在多个测试集上表现优异，达成最新技术水平。


<details>
  <summary>Details</summary>
Motivation: 随着大型自然语言生成模型的广泛应用，其输出的可靠性和准确性备受关注，尤其是幻觉问题，即生成了看似合理但实际上错误的信息。因此，幻觉检测成为必须解决的关键任务。

Method: 提出一套涵盖11类幻觉的详细分类体系，设计HAD模型，将幻觉检测、识别及纠正集成于一次推断流程中。训练采用约9万条合成数据，并构建包含2,248条样本的HADTest测试集。

Result: HAD模型在内外部测试集上均优于现有基线，且在HaluEval、FactCHD和FaithBench等数据集上达成了最新的性能表现，显示了其稳健性和适用性。

Conclusion: HAD模型通过综合检测及纠正手段，有效提升了幻觉检测效果，为提高自然语言生成模型的输出质量提供了有力工具。

Abstract: The increasing reliance on natural language generation (NLG) models,
particularly large language models, has raised concerns about the reliability
and accuracy of their outputs. A key challenge is hallucination, where models
produce plausible but incorrect information. As a result, hallucination
detection has become a critical task. In this work, we introduce a
comprehensive hallucination taxonomy with 11 categories across various NLG
tasks and propose the HAllucination Detection (HAD) models
https://github.com/pku0xff/HAD, which integrate hallucination detection,
span-level identification, and correction into a single inference process.
Trained on an elaborate synthetic dataset of about 90K samples, our HAD models
are versatile and can be applied to various NLG tasks. We also carefully
annotate a test set for hallucination detection, called HADTest, which contains
2,248 samples. Evaluations on in-domain and out-of-domain test sets show that
our HAD models generally outperform the existing baselines, achieving
state-of-the-art results on HaluEval, FactCHD, and FaithBench, confirming their
robustness and versatility.

</details>


### [36] [Balancing Rewards in Text Summarization: Multi-Objective Reinforcement Learning via HyperVolume Optimization](https://arxiv.org/abs/2510.19325)
*Junjie Song,Yiwen Liu,Dapeng Li,Yin Sun,Shukun Fu,Siqi Chen,Yuji Cao*

Main category: cs.CL

TL;DR: 本文提出了一种基于超体积优化的强化学习方法，用于多目标文本摘要的优化，显著提升了模型在一致性、连贯性、相关性和流畅性等方面的表现。


<details>
  <summary>Details</summary>
Motivation: 文本摘要任务需要同时优化多个目标，且现有基于大型语言模型的强化学习方法在多目标优化上研究较少，存在平衡困难。

Method: 引入超体积优化（HVO）策略，在强化学习奖励过程中动态调整各目标分数，逐步逼近帕累托前沿，实现多目标的平衡优化。

Result: 实验表明，该方法在多个代表性摘要数据集上优于群体相对策略优化（GRPO），在不同维度表现更均衡，且7B模型经HVO增强后在摘要任务中与GPT-4表现相当，同时生成文本更短。

Conclusion: HVO策略有效提升了多目标文本摘要的性能和均衡性，展示了基于大型语言模型强化学习优化多目标问题的潜力。

Abstract: Text summarization is a crucial task that requires the simultaneous
optimization of multiple objectives, including consistency, coherence,
relevance, and fluency, which presents considerable challenges. Although large
language models (LLMs) have demonstrated remarkable performance, enhanced by
reinforcement learning (RL), few studies have focused on optimizing the
multi-objective problem of summarization through RL based on LLMs. In this
paper, we introduce hypervolume optimization (HVO), a novel optimization
strategy that dynamically adjusts the scores between groups during the reward
process in RL by using the hypervolume method. This method guides the model's
optimization to progressively approximate the pareto front, thereby generating
balanced summaries across multiple objectives. Experimental results on several
representative summarization datasets demonstrate that our method outperforms
group relative policy optimization (GRPO) in overall scores and shows more
balanced performance across different dimensions. Moreover, a 7B foundation
model enhanced by HVO performs comparably to GPT-4 in the summarization task,
while maintaining a shorter generation length. Our code is publicly available
at https://github.com/ai4business-LiAuto/HVO.git

</details>


### [37] [Slot Filling as a Reasoning Task for SpeechLLMs](https://arxiv.org/abs/2510.19326)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本文将推理机制集成到语音大语言模型（speechLLMs）中，用于端到端的槽位填充任务，通过链式思维分解任务并采用监督微调，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 受推理大语言模型发展的启发，提升语音大语言模型在复杂任务中的表现。

Method: 采用链式思维框架将槽位填充任务分解为多个推理步骤，创建推理数据集，使用监督微调不同类型和规模的基础文本模型。

Result: 引入推理步骤提升了模型性能，混合基础文本模型的语音模型比仅单一模式微调的模型表现更优，但主要为数学、逻辑和编码领域设计的推理文本模型作为基础表现稍差。

Conclusion: 集成推理机制并采用混合模式微调的speechLLMs在槽位填充任务中表现更好。

Abstract: We propose integration of reasoning into speech large language models
(speechLLMs) for the end-to-end slot-filling task. Inspired by the recent
development of reasoning LLMs, we use a chain-of-thought framework to decompose
the slot-filling task into multiple reasoning steps, create a reasoning dataset
and apply the supervised fine-tuning strategy to a speechLLM. We distinguish
between regular and reasoning speechLLMs and experiment with different types
and sizes of LLMs as their text foundation models. We demonstrate performance
improvements by introducing reasoning (intermediate) steps. However, we show
that a reasoning textual LLM developed mainly for math, logic and coding
domains might be inferior as a foundation model for a reasoning speechLLM. We
further show that hybrid speechLLMs, built on a hybrid text foundation LLM and
fine-tuned to preserve both direct and reasoning modes of operation, have
better performance than those fine-tuned employing only one mode of operation.

</details>


### [38] [Algorithmic Fairness in NLP: Persona-Infused LLMs for Human-Centric Hate Speech Detection](https://arxiv.org/abs/2510.19331)
*Ewelina Gajewska,Arda Derbent,Jaroslaw A Chudziak,Katarzyna Budzynska*

Main category: cs.CL

TL;DR: 本文研究了通过个性化大型语言模型（Persona-LLMs）中的注释者身份，如何影响其对仇恨言论的敏感度，尤其是基于注释者与目标之间身份的共享或差异导致的偏见。


<details>
  <summary>Details</summary>
Motivation: 为了减少自动化仇恨言论检测中的偏见，结合心理学中群体身份理论，探讨注释者的社会人口属性如何影响模型的公平性和识别能力。

Method: 采用Google Gemini和OpenAI GPT-4.1-mini模型，通过浅层身份提示和基于检索增强生成（RAG）的深度个性化提示两种方法，引入丰富的身份信息，分析使用同组和异组注释者身份对模型表现的影响。

Result: 结果显示，个性化身份提示能够部分减少模型在检测仇恨言论时的偏见，但存在一定局限性。更丰富的个性化信息和不同群体身份的结合提升了模型的公平性和表现。

Conclusion: 将社会人口统计属性整合进大型语言模型有助于缓解仇恨言论检测中的偏见，个性化方法在构建更公正的检测系统中展现出潜力，同时也揭示了现有方法的不足。

Abstract: In this paper, we investigate how personalising Large Language Models
(Persona-LLMs) with annotator personas affects their sensitivity to hate
speech, particularly regarding biases linked to shared or differing identities
between annotators and targets. To this end, we employ Google's Gemini and
OpenAI's GPT-4.1-mini models and two persona-prompting methods: shallow persona
prompting and a deeply contextualised persona development based on
Retrieval-Augmented Generation (RAG) to incorporate richer persona profiles. We
analyse the impact of using in-group and out-group annotator personas on the
models' detection performance and fairness across diverse social groups. This
work bridges psychological insights on group identity with advanced NLP
techniques, demonstrating that incorporating socio-demographic attributes into
LLMs can address bias in automated hate speech detection. Our results highlight
both the potential and limitations of persona-based approaches in reducing
bias, offering valuable insights for developing more equitable hate speech
detection systems.

</details>


### [39] [Local Obfuscation by GLINER for Impartial Context Aware Lineage: Development and evaluation of PII Removal system](https://arxiv.org/abs/2510.19346)
*Prakrithi Shivaprakash,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 该文开发了基于微调GLiNER模型的本地可部署PII去除系统LOGICAL，性能优于主流方法，在资源有限环境中高效保证隐私。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型虽强大但计算成本高且API存在隐私风险，不适宜资源有限环境中处理医疗文本的PII去除。

Method: 基于微调的GLiNER模型，定义九类PII，使用精神病院EHR的1515份临床文档训练和测试，采用字符级精度、召回率和F1评分评估，与多种主流工具及LLM零样本方法对比。

Result: 微调GLiNER模型实现整体微平均F1值0.980，显著优于Gemini-Pro-2.5的0.845。LOGICAL系统完整正确脱敏95%的文档，性能最佳且能在无GPU标准笔记本运行。

Conclusion: 微调专门的轻量级Transformer模型如GLiNER，能高效且安全地实现临床文本PII去除，适合资源受限环境下的隐私保护和数据脱敏，推荐结合人工校验确保零误漏。

Abstract: Removing Personally Identifiable Information (PII) from clinical notes in
Electronic Health Records (EHRs) is essential for research and AI development.
While Large Language Models (LLMs) are powerful, their high computational costs
and the data privacy risks of API-based services limit their use, especially in
low-resource settings. To address this, we developed LOGICAL (Local Obfuscation
by GLINER for Impartial Context-Aware Lineage), an efficient, locally
deployable PII removal system built on a fine-tuned Generalist and Lightweight
Named Entity Recognition (GLiNER) model. We used 1515 clinical documents from a
psychiatric hospital's EHR system. We defined nine PII categories for removal.
A modern-gliner-bi-large-v1.0 model was fine-tuned on 2849 text instances and
evaluated on a test set of 376 instances using character-level precision,
recall, and F1-score. We compared its performance against Microsoft Azure NER,
Microsoft Presidio, and zero-shot prompting with Gemini-Pro-2.5 and
Llama-3.3-70B-Instruct. The fine-tuned GLiNER model achieved superior
performance, with an overall micro-average F1-score of 0.980, significantly
outperforming Gemini-Pro-2.5 (F1-score: 0.845). LOGICAL correctly sanitised 95%
of documents completely, compared to 64% for the next-best solution. The model
operated efficiently on a standard laptop without a dedicated GPU. However, a
2% entity-level false negative rate underscores the need for human-in-the-loop
validation across all tested systems. Fine-tuned, specialised transformer
models like GLiNER offer an accurate, computationally efficient, and secure
solution for PII removal from clinical notes. This "sanitisation at the source"
approach is a practical alternative to resource-intensive LLMs, enabling the
creation of de-identified datasets for research and AI development while
preserving data privacy, particularly in resource-constrained environments.

</details>


### [40] [Modeling Turn-Taking with Semantically Informed Gestures](https://arxiv.org/abs/2510.19350)
*Varsha Suresh,M. Hamza Mughal,Christian Theobalt,Vera Demberg*

Main category: cs.CL

TL;DR: 研究使用语音、手势和视线等多模态线索进行对话中的轮次管理，提出并扩展了包含丰富手势语义注释的数据集，并通过融合文本、音频和手势的专家混合模型提高了轮次预测性能。


<details>
  <summary>Details</summary>
Motivation: 人类在对话中利用多模态线索（语音、手势、视线）进行轮次管理，现有模型主要依赖语言和音频特征，手势提供了互补信息，因此研究引入手势来改善轮次预测。

Method: 扩展多方对话数据集DnD Gesture，增加2663条语义手势注释（标识性、隐喻性、指示性、话语型手势），并采用集成文本、音频和手势的Mixture-of-Experts框架进行轮次预测。

Result: 融合语义引导的手势信息的模型在轮次预测任务上相较基线方法持续表现提升，验证了手势在多模态轮次管理中的补充作用。

Conclusion: 引入和利用语义手势显著增强了对话轮次预测的效果，证明了手势作为多模态信息中重要且互补的线索在对话理解中的价值。

Abstract: In conversation, humans use multimodal cues, such as speech, gestures, and
gaze, to manage turn-taking. While linguistic and acoustic features are
informative, gestures provide complementary cues for modeling these
transitions. To study this, we introduce DnD Gesture++, an extension of the
multi-party DnD Gesture corpus enriched with 2,663 semantic gesture annotations
spanning iconic, metaphoric, deictic, and discourse types. Using this dataset,
we model turn-taking prediction through a Mixture-of-Experts framework
integrating text, audio, and gestures. Experiments show that incorporating
semantically guided gestures yields consistent performance gains over
baselines, demonstrating their complementary role in multimodal turn-taking.

</details>


### [41] [M3-SLU: Evaluating Speaker-Attributed Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2510.19358)
*Yejin Kwon,Taewoo Kang,Hyunsoo Yoon,Changouk Kim*

Main category: cs.CL

TL;DR: 本文提出了M3-SLU，一个用于多说话人多轮语音理解的多模态大语言模型基准。


<details>
  <summary>Details</summary>
Motivation: 尽管近期模型在语音和文本理解方面表现良好，但在理解谁说了什么以及何时说的说话者归属推理上仍存在挑战。

Method: M3-SLU由四个公开语料库构建，包含音频、转录和元数据，设置了说话者归属问答和说话者通过话语匹配归属两项任务，提供基线结果并使用LLM作为评判标准。

Result: 结果显示模型能较好理解内容，但在识别说话者方面表现不足，暴露了说话者感知对话理解的关键差距。

Conclusion: M3-SLU作为一个具有挑战性的基准，为推动说话者感知的多模态理解研究提供了平台。

Abstract: We present M3-SLU, a new multimodal large language model (MLLM) benchmark for
evaluating multi-speaker, multi-turn spoken language understanding. While
recent models show strong performance in speech and text comprehension, they
still struggle with speaker-attributed reasoning, the ability to understand who
said what and when in natural conversations. M3-SLU is built from four open
corpora (CHiME-6, MELD, MultiDialog, and AMI) and comprises over 12,000
validated instances with paired audio, transcripts, and metadata. It includes
two tasks: (1) Speaker-Attributed Question Answering and (2) Speaker
Attribution via Utterance Matching. We provide baseline results for both
cascaded pipelines and end-to-end MLLMs, evaluated using an LLM-as-Judge and
accuracy metrics. Results show that while models can capture what was said,
they often fail to identify who said it, revealing a key gap in speaker-aware
dialogue understanding. M3-SLU offers as a challenging benchmark to advance
research in speaker-aware multimodal understanding.

</details>


### [42] [AgenticMath: Enhancing LLM Reasoning via Agentic-based Math Data Generation](https://arxiv.org/abs/2510.19361)
*Xianyang Liu,Yilin Liu,Shuai Wang,Hao Cheng,Andrew Estornell,Yuzhi Zhao,Jiaheng Wei*

Main category: cs.CL

TL;DR: 提出AgenticMath，一种高质量数学问答对生成管线，以提升大型语言模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集生成方法质量低且信息贫乏，难以有效提升大型语言模型的推理能力。

Method: AgenticMath包含四个阶段：种子问题筛选、多智能体问题改写、链式思维答案增强及最终评价筛选，自动生成高质量数学问答对。

Result: 使用AgenticMath生成的3万到6万数学样本微调3B-8B参数模型，在多种数学推理基准测试中表现优于使用更多低质量数据训练的基线模型。

Conclusion: 定向生成高质量数据比大规模低质量数据更有效地提升大型语言模型的数学推理能力。

Abstract: The creation of high-quality datasets to improve Large Language Model (LLM)
reasoning remains a significant challenge, as current methods often suffer from
generating low-quality/incorrect answers and limited information richness from
available data sources. To address this, we propose AgenticMath, a novel
agentic pipeline for generating high-quality mathematical question-answer pairs
to enhance the supervised fine-tuning of LLMs. Our method operates through four
stages: (1) Seed Question Filter that selects questions with high information
richness, complexity, and clarity; (2) an Agentic Question Rephrase step that
employs a multi-agent system to generate diverse, logically consistent
paraphrases; (3) an Answer Augment step where rewrite answers using
chain-of-thought reasoning to enhance numerical and logical correctness,
without reliance on human-provided labels; and (4) a final Question and Answer
Evaluation that retains only the most superior pairs. Extensive experiments
demonstrate that, fine-tuning 3B-8B parameter LLMs on AgenticMath generated
datasets (comprising only 30-60K math samples) achieves competitive or superior
performance on diverse in domain and out-of-domain mathematical reasoning
benchmarks compared to baselines trained on much more data (e.g., 400K or 2.3M
samples). Our work demonstrates that targeted, high-quality data generation is
a more efficient path to improving mathematical reasoning in LLMs than
large-scale, low-quality alternatives.

</details>


### [43] [LoongRL:Reinforcement Learning for Advanced Reasoning over Long Contexts](https://arxiv.org/abs/2510.19363)
*Siyuan Wang,Gaokai Zhang,Li Lyna Zhang,Ning Shang,Fan Yang,Dongyao Chen,Mao Yang*

Main category: cs.CL

TL;DR: 提出LoongRL方法，利用KeyChain合成高难度长上下文推理任务，通过强化学习诱导计划-检索-推理-复核模式，显著提升大语言模型长上下文多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在短上下文推理中效果显著，但长上下文推理复杂思维模式未被充分探索且缺乏高难度强化学习数据。

Method: 通过KeyChain创造包含UUID链的长上下文任务，要求模型逐步跟踪链条，识别真实问题并推理答案。利用强化学习训练模型，诱导其形成计划-检索-推理-复核的推理模式。

Result: 在Qwen2.5-7B及14B模型上，LoongRL提升了长上下文多跳问答准确率分别达23.5%和21.1%，可解决128K长上下文任务且推理成本可控。LoongRL-14B分数达到74.2，接近更大模型表现。

Conclusion: LoongRL有效解决长上下文推理中的高级思维难题，实现了模型推理能力的大幅提升，同时保持短上下文推理能力，具有广泛应用前景。

Abstract: Reasoning over long contexts is essential for large language models. While
reinforcement learning (RL) enhances short-context reasoning by inducing "Aha"
moments in chain-of-thought, the advanced thinking patterns required for
long-context reasoning remain largely unexplored, and high-difficulty RL data
are scarce. In this paper, we introduce LoongRL, a data-driven RL method for
advanced long-context reasoning. Central to LoongRL is KeyChain, a synthesis
approach that transforms short multi-hop QA into high-difficulty long-context
tasks by inserting UUID chains that hide the true question among large
collections of distracting documents. Solving these tasks requires the model to
trace the correct chain step-by-step, identify the true question, retrieve
relevant facts and reason over them to answer correctly. RL training on
KeyChain data induces an emergent plan-retrieve-reason-recheck reasoning
pattern that generalizes far beyond training length. Models trained at 16K
effectively solve 128K tasks without prohibitive full-length RL rollout costs.
On Qwen2.5-7B and 14B, LoongRL substantially improves long-context multi-hop QA
accuracy by +23.5% and +21.1% absolute gains. The resulting LoongRL-14B reaches
a score of 74.2, rivaling much larger frontier models such as o3-mini (74.5)
and DeepSeek-R1 (74.9). It also improves long-context retrieval, passes all
128K needle-in-a-haystack stress tests, and preserves short-context reasoning
capabilities.

</details>


### [44] [The Massive Legal Embedding Benchmark (MLEB)](https://arxiv.org/abs/2510.19365)
*Umar Butler,Abdur-Rahman Butler,Adrian Lucas Malec*

Main category: cs.CL

TL;DR: 该论文提出了MLEB，一个最大的多样化法律信息检索基准，包含十个经过专家注释的数据集，覆盖多个司法辖区和文档类型，旨在推动法律信息检索的研究和评估。


<details>
  <summary>Details</summary>
Motivation: 当前开源的法律信息检索资源在领域和司法辖区上存在不足，缺乏综合、多样化的评测基准。

Method: 构建了一个包含十个专家注释数据集的基准MLEB，涵盖美国、英国、欧盟、澳大利亚、爱尔兰、新加坡等多个司法辖区，涉及多种文档类型和任务类型，并公开了构建方法和数据。

Result: 构建了七个新数据集以弥补开源法律信息检索中的空白，实现了多司法辖区、多类型任务的全面评测标准，同时发布了相关代码和数据，方便复现和评估。

Conclusion: MLEB作为迄今最大最全面的开源法律信息检索基准，将促进法律检索领域的研究与应用，提升模型在多领域、多场景下的表现和泛化能力。

Abstract: We present the Massive Legal Embedding Benchmark (MLEB), the largest, most
diverse, and most comprehensive open-source benchmark for legal information
retrieval to date. MLEB consists of ten expert-annotated datasets spanning
multiple jurisdictions (the US, UK, EU, Australia, Ireland, and Singapore),
document types (cases, legislation, regulatory guidance, contracts, and
literature), and task types (search, zero-shot classification, and question
answering). Seven of the datasets in MLEB were newly constructed in order to
fill domain and jurisdictional gaps in the open-source legal information
retrieval landscape. We document our methodology in building MLEB and creating
the new constituent datasets, and release our code, results, and data openly to
assist with reproducible evaluations.

</details>


### [45] [MoE-Prism: Disentangling Monolithic Experts for Elastic MoE Services via Model-System Co-Designs](https://arxiv.org/abs/2510.19366)
*Xinfeng Xia,Jiacheng Liu,Xiaofeng Hou,Peng Tang,Mingxuan Zhang,Wenfeng Wang,Chao Li*

Main category: cs.CL

TL;DR: MoE-Prism将传统的Mixture-of-Experts模型细分为更灵活的子专家，并设计QoS-aware调度策略，实现了更细粒度的性能调控，大幅提升了吞吐量和延迟表现。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型由于采用粗粒度的top-k路由机制，导致性能和资源使用之间存在难以调节的"质量悬崖"，无法灵活适应不同服务等级目标，造成资源浪费。

Method: 采用两阶段方法：第一阶段使用离线重构引擎将单一专家拆分成细粒度的子专家，通过元启发式的分区优化保持功能局部性且无需重新训练；第二阶段在线调度引擎根据QoS要求动态调度子专家，优化吞吐量和延迟，适应不同资源约束。

Result: 实验显示，MoE-Prism实现了超过4倍的操作点数量，帮助AI服务在严格延迟预算下提升吞吐量19.9%，或在资源限制下降低延迟10.36%。

Conclusion: MoE-Prism通过模型与系统协同设计，为MoE模型提供了灵活的调控手段，有效弥合模型与系统的差距，推动了适应性强、高效且支持QoS的AI服务发展。

Abstract: Mixture-of-Experts (MoE) models, the state-of-the-art in large-scale AI,
achieve high quality by sparsely activating parameters. However, their reliance
on routing between a few monolithic experts via a top-k mechanism creates a
"quality cliff", offering only a few coarse-grained operating points. This
inflexibility forces a difficult trade-off between cost and quality, preventing
adaptation to diverse Service Level Objectives (SLOs) and leading to
significant resource over-provisioning.
  This paper introduces MoE-Prism, a model-system co-design that transforms
rigid MoE models into elastic services. Our methodology is divided into two
phases. First, an \emph{Offline Refactoring Engine} systematically deconstructs
monolithic experts into fine-grained "sub-experts." This engine employs a
partitioning optimization solver that uses a metaheuristic-based approach to
group neurons, preserving functional locality without requiring retraining.
Second, an \emph{Online Scheduling Engine} leverages this new elasticity
through QoS-aware scheduling. It implements specialized policies to solve
complex system problems, including maximizing throughput in cloud deployments
and managing latency-optimized offloading for memory-constrained devices. Our
evaluation across three different MoE models shows that MoE-Prismprovides over
4 times more distinct, stable operating points than the baseline. This allows
an AI service to dynamically improve throughput by up to 19.9\% under a strict
latency budget or reduce latency by up to 10.36\% under limited resources.
MoE-Prism provides the critical "control knob" to bridge the model-system gap,
enabling the next generation of adaptive, efficient, and QoS-aware AI services.

</details>


### [46] [Sign Language Translation with Sentence Embedding Supervision](https://arxiv.org/abs/2510.19367)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 该论文提出了一种利用目标句子句子嵌入替代手语注释的新方法，免去了人工注释，实现了多语言手语翻译。


<details>
  <summary>Details</summary>
Motivation: 传统手语翻译系统依赖于规模有限且注释差异大的手语注释数据，限制了系统的推广应用。

Method: 通过使用目标句子的句子嵌入作为监督信号，训练过程中无需手语注释，实现多语言手语翻译。

Result: 在德语和美式手语数据集上，该方法显著优于其他无注释方法，达到新的无注释手语翻译技术水平。

Conclusion: 该方法解决了无手语注释数据情况下的手语翻译问题，缩小了无注释和有注释系统的性能差距。

Abstract: State-of-the-art sign language translation (SLT) systems facilitate the
learning process through gloss annotations, either in an end2end manner or by
involving an intermediate step. Unfortunately, gloss labelled sign language
data is usually not available at scale and, when available, gloss annotations
widely differ from dataset to dataset. We present a novel approach using
sentence embeddings of the target sentences at training time that take the role
of glosses. The new kind of supervision does not need any manual annotation but
it is learned on raw textual data. As our approach easily facilitates
multilinguality, we evaluate it on datasets covering German (PHOENIX-2014T) and
American (How2Sign) sign languages and experiment with mono- and multilingual
sentence embeddings and translation systems. Our approach significantly
outperforms other gloss-free approaches, setting the new state-of-the-art for
data sets where glosses are not available and when no additional SLT datasets
are used for pretraining, diminishing the gap between gloss-free and
gloss-dependent systems.

</details>


### [47] [SONAR-SLT: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision](https://arxiv.org/abs/2510.19398)
*Yasser Hamidullah,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本文提出了一种使用语言无关、多模态的句子嵌入来监督手语翻译的方法，实现多语言直接翻译，并通过结合多语言目标增强与视频层级扰动的耦合增强方法缓解数据稀缺问题，提高了模型的鲁棒性和翻译效果。


<details>
  <summary>Details</summary>
Motivation: 传统手语翻译模型通常依赖单一口语语言文本训练，限制了其扩展性及跨语言泛化能力。现有基于文本句子嵌入的方法仍受限于特定语言和模态。

Method: 采用语言无关、多模态的句子嵌入（由多语言文本和语音训练得到）来监督手语翻译，同时引入耦合增强方法，该方法结合多语言目标翻译增强和视频级扰动以提升模型鲁棒性。

Result: 实验结果显示，相较于仅用文本句子嵌入的监督方式，所提方法在BLEURT指标上表现出持续提升，特别是在资源稀缺的设定下改进更为显著。

Conclusion: 使用语言无关的多模态嵌入作为监督信号，配合耦合增强策略，为传统手语翻译训练提供了可扩展且语义鲁棒的替代方案。

Abstract: Sign language translation (SLT) is typically trained with text in a single
spoken language, which limits scalability and cross-language generalization.
Earlier approaches have replaced gloss supervision with text-based sentence
embeddings, but up to now, these remain tied to a specific language and
modality. In contrast, here we employ language-agnostic, multimodal embeddings
trained on text and speech from multiple languages to supervise SLT, enabling
direct multilingual translation. To address data scarcity, we propose a coupled
augmentation method that combines multilingual target augmentations (i.e.
translations into many languages) with video-level perturbations, improving
model robustness. Experiments show consistent BLEURT gains over text-only
sentence embedding supervision, with larger improvements in low-resource
settings. Our results demonstrate that language-agnostic embedding supervision,
combined with coupled augmentation, provides a scalable and semantically robust
alternative to traditional SLT training.

</details>


### [48] [ToMMeR -- Efficient Entity Mention Detection from Large Language Models](https://arxiv.org/abs/2510.19410)
*Victor Morand,Nadi Tomeh,Josiane Mothe,Benjamin Piwowarski*

Main category: cs.CL

TL;DR: 本文提出了ToMMeR，一种轻量级模型用于检测文本中的实体提及，实现高召回率和精度，同时在多种NER基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 识别文本中指代实体的跨度是信息提取的基础任务，但性能瓶颈明显，因此希望探索更轻量且高效的提及检测方法。

Method: 设计一个参数少于30万的轻量模型ToMMeR，利用早期大语言模型层的信息来检测实体提及，并结合跨度分类器提升性能。

Result: ToMMeR在13个NER任务中零样本测试获得93%召回率，精度超90%，跨模型分析显示不同架构均能捕获类似提及边界，并达到接近最先进的NER性能。

Conclusion: 实体提及的结构化表示自然存在于早期Transformer层，通过少量参数即可高效恢复，验证了ToMMeR的有效性和潜力。

Abstract: Identifying which text spans refer to entities -- mention detection -- is
both foundational for information extraction and a known performance
bottleneck. We introduce ToMMeR, a lightweight model (<300K parameters) probing
mention detection capabilities from early LLM layers. Across 13 NER benchmarks,
ToMMeR achieves 93\% recall zero-shot, with over 90\% precision using an LLM as
a judge showing that ToMMeR rarely produces spurious predictions despite high
recall. Cross-model analysis reveals that diverse architectures (14M-15B
parameters) converge on similar mention boundaries (DICE >75\%), confirming
that mention detection emerges naturally from language modeling. When extended
with span classification heads, ToMMeR achieves near SOTA NER performance
(80-87\% F1 on standard benchmarks). Our work provides evidence that structured
entity representations exist in early transformer layers and can be efficiently
recovered with minimal parameters.

</details>


### [49] [Spatio-temporal Sign Language Representation and Translation](https://arxiv.org/abs/2510.19413)
*Yasser Hamidullah,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 该论文介绍了DFKI-MLT团队参与2022年WMT-SLT任务，构建了一个从瑞士德语手语视频到德语文本的端到端翻译系统，使用时空特征学习，开发集表现中等但测试集表现较差。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译多用序列到序列模型结合自定义输入嵌入，但常忽略视频的时序特征，影响泛化能力。

Method: 设计一个单一模型，同时学习时空特征表示和翻译任务，实现真正的端到端架构。

Result: 在开发集上达到约5 BLEU分，但测试集得分骤降至0.11，性能不稳定。

Conclusion: 端到端时空特征学习有潜力提升手语翻译系统，但现有模型泛化能力不足，需进一步改进。

Abstract: This paper describes the DFKI-MLT submission to the WMT-SLT 2022 sign
language translation (SLT) task from Swiss German Sign Language (video) into
German (text). State-of-the-art techniques for SLT use a generic seq2seq
architecture with customized input embeddings. Instead of word embeddings as
used in textual machine translation, SLT systems use features extracted from
video frames. Standard approaches often do not benefit from temporal features.
In our participation, we present a system that learns spatio-temporal feature
representations and translation in a single model, resulting in a real
end-to-end architecture expected to better generalize to new data sets. Our
best system achieved $5\pm1$ BLEU points on the development set, but the
performance on the test dropped to $0.11\pm0.06$ BLEU points.

</details>


### [50] [BLiSS 1.0: Evaluating Bilingual Learner Competence in Second Language Small Language Models](https://arxiv.org/abs/2510.19419)
*Yuan Gao,Suchir Salhan,Andrew Caines,Paula Buttery,Weiwei Sun*

Main category: cs.CL

TL;DR: 本文介绍了BLiSS 1.0，一个基于学习者语言错误的跨语言句法结构基准，评估模型对自然学习者错误的辨识能力。


<details>
  <summary>Details</summary>
Motivation: 传统性能导向的基准无法有效评价认知启发模型的能力，需设计新基准测试模型对自然学习者错误的识别，即选择性容忍能力。

Method: 基于280万自然学习者句子构建了包含136,867组对比（三元组：正确句、学习者错误句和人工错误句）的BLiSS 1.0基准，通过实验考察不同模型对选择性容忍的表现。

Result: 实验显示选择性容忍与标准语法判断能力不同，不同训练范式的模型在选择性容忍上的表现明显分群，证明了该基准的有效性。

Conclusion: BLiSS作为一个稳健工具，可测量不同训练目标如何影响模型与人类语言习得系统模式的对齐程度，推动认知语言模型的评估。

Abstract: To bridge the gap between performance-oriented benchmarks and the evaluation
of cognitively inspired models, we introduce BLiSS 1.0, a Benchmark of Learner
Interlingual Syntactic Structure. Our benchmark operationalizes a new paradigm
of selective tolerance, testing whether a model finds a naturalistic learner
error more plausible than a matched, artificial error within the same sentence.
Constructed from over 2.8 million naturalistic learner sentences, BLiSS
provides 136,867 controlled triplets (corrected, learner, artificial) for this
purpose. Experiments on a diverse suite of models demonstrate that selective
tolerance is a distinct capability from standard grammaticality, with
performance clustering strongly by training paradigm. This validates BLiSS as a
robust tool for measuring how different training objectives impact a model's
alignment with the systematic patterns of human language acquisition.

</details>


### [51] [MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models](https://arxiv.org/abs/2510.19457)
*Kailin Jiang,Ning Jiang,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu,Yuntao Du*

Main category: cs.CL

TL;DR: 本文提出了MINED基准，用于评估大型多模态模型（LMMs）在时间敏感知识方面的理解能力，涵盖6个维度和11个任务。通过对15个LMM的测试，发现其在不同领域表现不一，且部分模型缺乏时间理解能力。还探讨了通过知识编辑方法更新LMM时间敏感知识的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型虽能编码丰富的事实知识，但其静态表示难以准确理解时间敏感的事实知识，且现有基准评测方法无法充分衡量这一能力。

Method: 提出了MINED，一个涵盖6个关键维度和11个任务的全面时间敏感知识评测基准，由专业标注员基于Wikipedia构建，包含2104个样本。对15个广泛使用的LMM进行了评估，并尝试通过知识编辑方法更新模型时间敏感知识。

Result: Gemini-2.5-Pro在MINED上表现最佳，平均CEM评分为63.07，大部分开源模型时序理解能力不足；模型在组织机构知识上的表现最好，体育知识最差。知识编辑方法在单次编辑场景中有效更新了时间敏感知识。

Conclusion: MINED有效弥补了时间敏感知识评估的空白，揭示了现有LMM在时序知识理解方面的不足，知识编辑为动态更新模型知识提供了可行路径。未来研究应关注提升模型的时间敏感知识理解和更新能力。

Abstract: Large Multimodal Models (LMMs) encode rich factual knowledge via cross-modal
pre-training, yet their static representations struggle to maintain an accurate
understanding of time-sensitive factual knowledge. Existing benchmarks remain
constrained by static designs, inadequately evaluating LMMs' ability to
understand time-sensitive knowledge. To address this gap, we propose MINED, a
comprehensive benchmark that evaluates temporal awareness along 6 key
dimensions and 11 challenging tasks: cognition, awareness, trustworthiness,
understanding, reasoning, and robustness. MINED is constructed from Wikipedia
by two professional annotators, containing 2,104 time-sensitive knowledge
samples spanning six knowledge types. Evaluating 15 widely used LMMs on MINED
shows that Gemini-2.5-Pro achieves the highest average CEM score of 63.07,
while most open-source LMMs still lack time understanding ability. Meanwhile,
LMMs perform best on organization knowledge, whereas their performance is
weakest on sport. To address these challenges, we investigate the feasibility
of updating time-sensitive knowledge in LMMs through knowledge editing methods
and observe that LMMs can effectively update knowledge via knowledge editing
methods in single editing scenarios.

</details>


### [52] [Re-evaluating Minimum Bayes Risk Decoding for Automatic Speech Recognition](https://arxiv.org/abs/2510.19471)
*Yuu Jinnai*

Main category: cs.CL

TL;DR: 本文研究了样本采样的最小贝叶斯风险（MBR）解码在语音转文本任务中的效果，结果显示MBR解码在大多数实验设置下优于传统的beam search，适用于高精度的离线自动语音识别和语音翻译任务。


<details>
  <summary>Details</summary>
Motivation: 近年来，MBR解码在文本生成任务中表现优于beam search，但语音转文本任务仍普遍采用beam search，因此有必要验证MBR解码在语音转文本任务中的有效性。

Method: 本文使用Whisper及其衍生模型，在英语和日语的自动语音识别和语音翻译任务中，采用MBR解码与beam search进行比较实验。

Result: 实验结果显示，MBR解码在大多数设置中精度优于beam search。

Conclusion: MBR解码是一种在需要高精度的离线语音识别和语音翻译任务中具有潜力的方法。相关代码已开源。

Abstract: Recent work has shown that sample-based Minimum Bayes Risk (MBR) decoding
outperforms beam search in text-to-text generation tasks, such as machine
translation, text summarization, and image captioning. On the other hand, beam
search is the current practice for speech-to-text tasks such as automatic
speech recognition (ASR) and Speech Translation (ST). Given that MBR decoding
is effective in text-to-text generation tasks, it is reasonable to expect it to
also be effective for speech-to-text tasks. In this paper, we evaluate MBR
decoding for ASR and ST tasks on English and Japanese using Whisper and its
derivative models. We observe that the accuracy of MBR decoding outperforms
that of beam search in most of the experimental settings we have evaluated. The
results show that MBR decoding is a promising method for offline ASR and ST
tasks that require high accuracy. The code is available at
https://github.com/CyberAgentAILab/mbr-for-asr

</details>


### [53] [VideoAgentTrek: Computer Use Pretraining from Unlabeled Videos](https://arxiv.org/abs/2510.19488)
*Dunjie Lu,Yiheng Xu,Junli Wang,Haoyuan Wu,Xinyuan Wang,Zekun Wang,Junlin Yang,Hongjin Su,Jixuan Chen,Junda Chen,Yuchen Mao,Jingren Zhou,Junyang Lin,Binyuan Hui,Tao Yu*

Main category: cs.CL

TL;DR: 本文提出了VideoAgentTrek，一种从大量公开屏幕录制视频自动挖掘训练数据的可扩展管道，解决了传统训练中需要大量手动标注交互数据的问题。


<details>
  <summary>Details</summary>
Motivation: 训练计算机操作代理需要大量GUI交互数据，但手动标注耗时且成本高昂，因此需要一种自动化且大规模获取训练数据的方法。

Method: 提出Video2Action反演动态模块，包括视频定位模型精确识别GUI动作及时间边界，以及动作内容识别器提取结构化参数。利用39,000个YouTube教程视频自动生成1.52百万交互步骤，结合持续预训练和有监督微调。

Result: 在OSWorld-Verified任务成功率从9.3%提升至15.8%，AgentNetBench步准确率从64.1%提升至69.3%，显示显著性能提升。

Conclusion: 通过充分利用被动互联网视频，可以实现高质量、可扩展的训练数据自动生成，替代昂贵的人工标注，为训练计算机操作代理开辟新途径。

Abstract: Training computer-use agents requires massive amounts of GUI interaction
data, but manually annotating action trajectories at scale is prohibitively
expensive. We present VideoAgentTrek, a scalable pipeline that automatically
mines training data from publicly available screen-recorded videos at web
scale, eliminating the need for manual annotation. Our approach addresses a key
challenge: raw videos contain implicit demonstrations but lack explicit action
labels. To solve this, we develop Video2Action, an inverse dynamics module
(IDM) with two components: (1) a video grounding model that detects and
localizes GUI actions with precise temporal boundaries and context, and (2) an
action-content recognizer that extracts structured parameters like click
coordinates and typed text with high fidelity. Applied to 39,000 YouTube
tutorial videos, our pipeline generates 1.52 million interaction steps
automatically. We leverage this data through continued pretraining followed by
supervised fine-tuning. On OSWorld-Verified, our approach improves task success
rates from 9.3% (SFT-only baseline) to 15.8%, a 70% relative improvement. On
AgentNetBench, step accuracy increases from 64.1% to 69.3%. Our results
demonstrate that passive internet videos can be transformed into high-quality
supervision for computer-use agents, providing a scalable alternative to
expensive manual annotation.

</details>


### [54] [Machine Text Detectors are Membership Inference Attacks](https://arxiv.org/abs/2510.19492)
*Ryuto Koike,Liam Dugan,Masahiro Kaneko,Chris Callison-Burch,Naoaki Okazaki*

Main category: cs.CL

TL;DR: 本文研究了成员推断攻击（MIA）和机器生成文本检测两任务间方法的可迁移性，证明两者最优性能指标相同并且方法的迁移性能高度相关。


<details>
  <summary>Details</summary>
Motivation: 尽管MIA和机器文本检测都基于语言模型的概率分布信号，但两者独立研究，导致未充分利用对方的方法和见解。

Method: 理论证明两任务最优指标相同，统一大量文献，假设方法对该指标的逼近度与迁移性相关；大规模实验证明7种MIA方法和5种文本检测方法跨13领域和10生成器表现高度相关。

Result: 发现Binoculars（原为文本检测方法）在MIA任务中表现领先，验证了方法间的迁移性；整体跨任务性能相关系数超过0.6。

Conclusion: 强调两研究社区需加强跨任务合作以挖掘更强方法，发布MINT统一评测套件促进公平评估和方法开发。

Abstract: Although membership inference attacks (MIAs) and machine-generated text
detection target different goals, identifying training samples and synthetic
texts, their methods often exploit similar signals based on a language model's
probability distribution. Despite this shared methodological foundation, the
two tasks have been independently studied, which may lead to conclusions that
overlook stronger methods and valuable insights developed in the other task. In
this work, we theoretically and empirically investigate the transferability,
i.e., how well a method originally developed for one task performs on the
other, between MIAs and machine text detection. For our theoretical
contribution, we prove that the metric that achieves the asymptotically highest
performance on both tasks is the same. We unify a large proportion of the
existing literature in the context of this optimal metric and hypothesize that
the accuracy with which a given method approximates this metric is directly
correlated with its transferability. Our large-scale empirical experiments,
including 7 state-of-the-art MIA methods and 5 state-of-the-art machine text
detectors across 13 domains and 10 generators, demonstrate very strong rank
correlation (rho > 0.6) in cross-task performance. We notably find that
Binoculars, originally designed for machine text detection, achieves
state-of-the-art performance on MIA benchmarks as well, demonstrating the
practical impact of the transferability. Our findings highlight the need for
greater cross-task awareness and collaboration between the two research
communities. To facilitate cross-task developments and fair evaluations, we
introduce MINT, a unified evaluation suite for MIAs and machine-generated text
detection, with implementation of 15 recent methods from both tasks.

</details>


### [55] [What is the Best Sequence Length for BABYLM?](https://arxiv.org/abs/2510.19493)
*Suchir Salhan,Richard Diehl Martinez,Zébulon Goriely,Paula Buttery*

Main category: cs.CL

TL;DR: 本文研究了BabyLM挑战中预训练Transformer语言模型时序列长度的影响，发现最佳序列长度依任务和模型结构而异。


<details>
  <summary>Details</summary>
Motivation: 在BabyLM挑战中，很多提交使用了较短的序列长度，这与Transformer模型通常使用的较长固定长度上下文窗口不一致，作者希望明确训练时应选用的序列长度。

Method: 使用一亿词的训练数据和固定计算预算，比较125M参数的Mamba和OPT模型在不同序列长度下的表现。

Result: 较长序列长度通常表现更好，但最佳序列长度依赖具体任务和模型架构；短序列足够处理语法泛化任务，较长序列则有助于形态类比推理任务。

Conclusion: 选择合适的序列长度需结合任务需求和模型架构，两者共同影响模型表现，简短序列可满足部分任务，复杂任务受益于更长上下文。

Abstract: Transformer language models typically operate with a fixed-length context
window, which has grown in step with large-scale pretraining datasets. In the
BabyLM Challenge, however, many past submissions have defaulted to using much
shorter sequence lengths. We examine the impact of sequence length on BabyLM
pretraining, to answer the simple question: what sequence length should we be
using when training Baby LMs? Using 100M-word training data and fixed compute
budgets, we compare 125M-parameter Mamba and OPT models, finding that although
longer is often better, the optimal length depends on both task and
architecture. Shorter sequences are sufficient for grammatical generalization
tasks whereas longer contexts benefit morphological analogical reasoning tasks.

</details>


### [56] [Lookahead Routing for Large Language Models](https://arxiv.org/abs/2510.19506)
*Canbin Huang,Tianyuan Shi,Yuhua Zhu,Ruijun Chen,Xiaojun Quan*

Main category: cs.CL

TL;DR: 本文提出了一种名为Lookahead的多模型路由框架，通过预测潜在输出表征来指导模型选择，提升了路由效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言模型路由方法仅基于输入查询进行分类，忽略了潜在输出信息和语义上下文，导致复杂查询的路由效果不佳。

Method: Lookahead框架通过预测模型的潜在输出表征，进行前瞻性路由决策，避免了全模型推理开销。实现了基于因果语言模型和掩码语言模型的两种方法。

Result: 在七个公开基准测试中，涵盖指令跟随、数学推理和代码生成任务，Lookahead相较于最先进方法平均性能提升7.7%。

Conclusion: Lookahead通过预测潜在输出，有效利用语义信息，提升了多模型系统的路由准确率和效率，优于现有路由基线。

Abstract: Large language model (LLM) routers improve the efficiency of multi-model
systems by directing each query to the most appropriate model while leveraging
the diverse strengths of heterogeneous LLMs. Most existing approaches frame
routing as a classification problem based solely on the input query. While this
reduces overhead by avoiding inference across all models, it overlooks valuable
information that could be gleaned from potential outputs and fails to capture
implicit intent or contextual nuances that often emerge only during response
generation. These limitations can result in suboptimal routing decisions,
particularly for complex or ambiguous queries that require deeper semantic
understanding. To address this challenge, we propose Lookahead, a routing
framework that "foresees" potential model outputs by predicting their latent
representations and uses these predictions to guide model selection, thus
enabling more informed routing without full inference. Within this framework,
we implement two approaches based on causal and masked language models.
Empirical evaluations across seven public benchmarks - spanning instruction
following, mathematical reasoning, and code generation - show that Lookahead
consistently outperforms existing routing baselines, achieving an average
performance gain of 7.7% over the state-of-the-art. Our code is available at
https://github.com/huangcb01/lookahead-routing.

</details>


### [57] [Which Evaluation for Which Model? A Taxonomy for Speech Model Assessment](https://arxiv.org/abs/2510.19509)
*Maureen de Seyssel,Eeshan Gunesh Dhekane*

Main category: cs.CL

TL;DR: 本文提出了一种统一的评估分类法，用以解决不同语音基础模型在评估上的差异问题。


<details>
  <summary>Details</summary>
Motivation: 不同语音模型在不同任务上表现优异，且需要不同的评估协议，当前评估方法分散且不统一。

Method: 设计了一个包含三个正交轴（评估方面、模型能力、任务需求）的分类法，将现有评估和基准测试按此分类，并分析模型能力与方法学需求的对应关系。

Result: 分类法成功将评估映射到模型能力和评估方法需求，揭示了语音韵律、交互和推理方面的评估空白。

Conclusion: 该分类法为语音模型的评估选择、解释和扩展提供了概念基础和实用指南，指明了未来基准设计的优先方向。

Abstract: Speech foundation models have recently achieved remarkable capabilities
across a wide range of tasks. However, their evaluation remains disjointed
across tasks and model types. Different models excel at distinct aspects of
speech processing and thus require different evaluation protocols. This paper
proposes a unified taxonomy that addresses the question: Which evaluation is
appropriate for which model? The taxonomy defines three orthogonal axes: the
\textbf{evaluation aspect} being measured, the model capabilities required to
attempt the task, and the task or protocol requirements needed to perform it.
We classify a broad set of existing evaluations and benchmarks along these
axes, spanning areas such as representation learning, speech generation, and
interactive dialogue. By mapping each evaluation to the capabilities a model
exposes (e.g., speech generation, real-time processing) and to its
methodological demands (e.g., fine-tuning data, human judgment), the taxonomy
provides a principled framework for aligning models with suitable evaluation
methods. It also reveals systematic gaps, such as limited coverage of prosody,
interaction, or reasoning, that highlight priorities for future benchmark
design. Overall, this work offers a conceptual foundation and practical guide
for selecting, interpreting, and extending evaluations of speech models.

</details>


### [58] [Conditions for Catastrophic Forgetting in Multilingual Translation](https://arxiv.org/abs/2510.19546)
*Danni Liu,Jan Niehues*

Main category: cs.CL

TL;DR: 多语言大型模型在针对特定语言微调时容易出现灾难性遗忘，影响对未见语言的表现。本文通过系统实验证明，模型与数据规模比例是遗忘的主要因素，且模型的指令跟随能力比架构更关键。参数高效微调没有明显优势，跨语言对齐能缓解遗忘并促进迁移。


<details>
  <summary>Details</summary>
Motivation: 当前多语言模型微调时灾难性遗忘现象普遍存在，但何时发生遗忘尚不明确，缺乏系统研究。

Method: 以机器翻译为实验平台，设计不同模型架构、数据规模和微调方法的对比实验，探索影响遗忘的关键因素。

Result: 发现模型与数据规模的相对大小是遗忘的决定因素，模型的指令跟随能力比架构重要，参数高效微调效果不优于全量微调，跨语言对齐技术能减少遗忘并帮助迁移。

Conclusion: 合理控制模型与数据规模比例，提升模型指令跟随能力，并应用跨语言对齐技术，是减轻多语言细调中灾难性遗忘的有效策略。

Abstract: Fine-tuning multilingual foundation models on specific languages often
induces catastrophic forgetting, degrading performance on languages unseen in
fine-tuning. While this phenomenon is widely-documented, the literature
presents fragmented results about when forgetting occurs. To address this
ambiguity, we conduct a systematic empirical study using machine translation as
a testbed to identify the conditions that trigger catastrophic forgetting in
multilingual fine-tuning. Through controlled experiments across different model
architectures, data scales, and fine-tuning approaches, we reveal that the
relative scale between model and data size is a primary determinant of
forgetting. Moreover, we demonstrate that a model's instruction-following
ability is more critical for retaining multilingual knowledge than its
architecture. Contrary to assumptions, parameter-efficient fine-tuning offers
no clear advantage over full fine-tuning in mitigating forgetting. Lastly, we
show that cross-lingual alignment can mitigate forgetting while also
facilitating positive transfer to unseen target languages.

</details>


### [59] [Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark](https://arxiv.org/abs/2510.19585)
*Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen*

Main category: cs.CL

TL;DR: 本文提出了从混合语言历史文档中提取拉丁文片段的新任务，并评估了大型基础模型的效果，验证了当前模型在该任务中的可行性。


<details>
  <summary>Details</summary>
Motivation: 混合语言历史文档布局复杂，传统方法难以准确提取拉丁文片段，需要借助先进模型提升检测效果。

Method: 构建了包含724页注释的多模态数据集，基于该数据集对大型基础模型进行了基准测试和性能评估。

Result: 实验结果表明，现有模型能够实现可靠的拉丁文检测，表现良好。

Conclusion: 本文首次对大型基础模型在混合语言历史文档拉丁文提取任务上的能力和局限进行了全面分析，验证了该方法的有效性。

Abstract: This paper presents a novel task of extracting Latin fragments from
mixed-language historical documents with varied layouts. We benchmark and
evaluate the performance of large foundation models against a multimodal
dataset of 724 annotated pages. The results demonstrate that reliable Latin
detection with contemporary models is achievable. Our study provides the first
comprehensive analysis of these models' capabilities and limits for this task.

</details>


### [60] [PBBQ: A Persian Bias Benchmark Dataset Curated with Human-AI Collaboration for Large Language Models](https://arxiv.org/abs/2510.19616)
*Farhan Farsi,Shayan Bali,Fatemeh Valeh,Parsa Ghofrani,Alireza Pakniat,Kian Kashfipour,Amir H. Payberah*

Main category: cs.CL

TL;DR: 本论文介绍了PBBQ数据集，用于评估波斯语大语言模型中的社会偏见，发现现有模型存在显著偏见且常复制人类偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛应用，确保其符合社会规范变得重要，但波斯文化背景下的社会偏见资源严重缺乏，因此需要构建相应的评测基准。

Method: 通过250名多样化个体填写问卷，结合社会科学专家的指导，构建了涵盖16个文化类别、包含3.7万多个问题的PBBQ数据集，并使用该数据集对多个开源、闭源及波斯语特定微调模型进行测试。

Result: 测试结果显示，各大语言模型在波斯文化相关的社会偏见方面表现突出，且模型输出经常复制人类的偏见模式。

Conclusion: PBBQ数据集有效揭示了波斯语大语言模型中的社会偏见问题，为未来偏见检测和缓解研究提供了重要资源，研究成果将在论文接受后公开。

Abstract: With the increasing adoption of large language models (LLMs), ensuring their
alignment with social norms has become a critical concern. While prior research
has examined bias detection in various languages, there remains a significant
gap in resources addressing social biases within Persian cultural contexts. In
this work, we introduce PBBQ, a comprehensive benchmark dataset designed to
evaluate social biases in Persian LLMs. Our benchmark, which encompasses 16
cultural categories, was developed through questionnaires completed by 250
diverse individuals across multiple demographics, in close collaboration with
social science experts to ensure its validity. The resulting PBBQ dataset
contains over 37,000 carefully curated questions, providing a foundation for
the evaluation and mitigation of bias in Persian language models. We benchmark
several open-source LLMs, a closed-source model, and Persian-specific
fine-tuned models on PBBQ. Our findings reveal that current LLMs exhibit
significant social biases across Persian culture. Additionally, by comparing
model outputs to human responses, we observe that LLMs often replicate human
bias patterns, highlighting the complex interplay between learned
representations and cultural stereotypes.Upon acceptance of the paper, our PBBQ
dataset will be publicly available for use in future work. Content warning:
This paper contains unsafe content.

</details>


### [61] [CrossNews-UA: A Cross-lingual News Semantic Similarity Benchmark for Ukrainian, Polish, Russian, and English](https://arxiv.org/abs/2510.19628)
*Daryna Dementieva,Evgeniya Sukhodolskaya,Alexander Fraser*

Main category: cs.CL

TL;DR: 本文提出了一种可扩展且可解释的众包流程，构建跨语言新闻相似性分析数据集CrossNews-UA，涵盖乌克兰语及相关语言，并通过多模型测试揭示多语言新闻分析的挑战和模型表现特点。


<details>
  <summary>Details</summary>
Motivation: 跨语言新闻检测尤其非英语语言面临资源有限和标注成本高的挑战，现有数据集规模受限且难以适配多语言环境。

Method: 设计了一个基于4W标准的众包标注流程，实现对乌克兰语中心及其相关语言新闻对的语义相似性评估，并构建多语言新闻数据集CrossNews-UA，同时测试多种模型从传统到大型语言模型的表现。

Result: 利用新数据集评估了多模型，发现跨语言新闻分析仍面临语义理解和多语言融合的困难，模型表现存在较大差异，尤其在跨语言语义匹配方面挑战明显。

Conclusion: 通过众包方式构建的可解释跨语言新闻相似性数据集为多语言新闻分析提供了重要资源，揭示了当前模型的瓶颈，促进未来跨语言假新闻检测和语义理解研究。

Abstract: In the era of social networks and rapid misinformation spread, news analysis
remains a critical task. Detecting fake news across multiple languages,
particularly beyond English, poses significant challenges. Cross-lingual news
comparison offers a promising approach to verify information by leveraging
external sources in different languages (Chen and Shu, 2024). However, existing
datasets for cross-lingual news analysis (Chen et al., 2022a) were manually
curated by journalists and experts, limiting their scalability and adaptability
to new languages. In this work, we address this gap by introducing a scalable,
explainable crowdsourcing pipeline for cross-lingual news similarity
assessment. Using this pipeline, we collected a novel dataset CrossNews-UA of
news pairs in Ukrainian as a central language with linguistically and
contextually relevant languages-Polish, Russian, and English. Each news pair is
annotated for semantic similarity with detailed justifications based on the 4W
criteria (Who, What, Where, When). We further tested a range of models, from
traditional bag-of-words, Transformer-based architectures to large language
models (LLMs). Our results highlight the challenges in multilingual news
analysis and offer insights into models performance.

</details>


### [62] [Style Attack Disguise: When Fonts Become a Camouflage for Adversarial Intent](https://arxiv.org/abs/2510.19641)
*Yangshijie Zhang,Xinda Wang,Jialin Liu,Wenqiang Wang,Zhicong Ma,Xingxing Jia*

Main category: cs.CL

TL;DR: 本文发现并利用了社交媒体中风格化字体对NLP模型的攻击漏洞，提出了一种风格攻击方法SAD，在多任务和多模型中取得了显著攻击效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体风格化字体虽然人类易读，但导致NLP模型处理时出现误差，存在安全隐患。

Method: 提出了风格攻击方法Style Attack Disguise（SAD），包含轻量型和强力型，兼顾查询效率和攻击性能。

Result: 在情感分类、机器翻译及多模态任务中，传统模型、大型语言模型及商业服务均表现出强攻击脆弱性。

Conclusion: SAD揭示了风格化文本对NLP模型的潜在威胁，应引起研究者对风格文本安全性的关注。

Abstract: With social media growth, users employ stylistic fonts and font-like emoji to
express individuality, creating visually appealing text that remains
human-readable. However, these fonts introduce hidden vulnerabilities in NLP
models: while humans easily read stylistic text, models process these
characters as distinct tokens, causing interference. We identify this
human-model perception gap and propose a style-based attack, Style Attack
Disguise (SAD). We design two sizes: light for query efficiency and strong for
superior attack performance. Experiments on sentiment classification and
machine translation across traditional models, LLMs, and commercial services
demonstrate SAD's strong attack performance. We also show SAD's potential
threats to multimodal tasks including text-to-image and text-to-speech
generation.

</details>


### [63] [LLavaCode: Compressed Code Representations for Retrieval-Augmented Code Generation](https://arxiv.org/abs/2510.19644)
*Daria Cherniuk,Nikita Sukhorukov,Nikita Sushko,Daniil Gusak,Danil Sivtsov,Elena Tutubalina,Evgeny Frolov*

Main category: cs.CL

TL;DR: LlavaCode通过压缩代码上下文为紧凑的单令牌向量，提升代码补全的质量和速度，显著减少推理时间。


<details>
  <summary>Details</summary>
Motivation: 代码补全中利用检索增强生成虽然有效，但上下文过长导致推理速度缓慢，不利于交互式IDE使用。

Method: 提出LlavaCode框架，使用一个小型投影模块将代码压缩为语义丰富的单令牌向量，减少上下文长度，提升生成质量并降低延迟。

Result: 实验表明，压缩上下文在代码行补全任务中，相比全量检索增强生成方法，时间到首令牌（TTFT）减少了20-38%，而生成准确率（EM和ES指标）显著提升，延迟增加极小。

Conclusion: LlavaCode有效压缩代码上下文，平衡了代码补全的生成质量与推理速度，适用于需要快速响应的交互式开发环境。

Abstract: Retrieval-augmented generation has emerged as one of the most effective
approaches for code completion, particularly when context from a surrounding
repository is essential. However, incorporating context significantly extends
sequence length, leading to slower inference - a critical limitation for
interactive settings such as IDEs. In this work, we introduce LlavaCode, a
framework that compresses code into compact, semantically rich representations
interpretable by code LLM, enhancing generation quality while reducing the
retrieved context to only a few compressed single-token vectors. Using a small
projector module we can significantly increase the EM and ES metrics of coding
model with negligible latency increase. Our experiments demonstrate that
compressed context enables 20-38% reduction in Time-to-First-Token (TTFT) on
line completion tasks compared to full-RAG pipelines.

</details>


### [64] [Unraveling Emotions with Pre-Trained Models](https://arxiv.org/abs/2510.19668)
*Alejandro Pajón-Sanmartín,Francisco De Arriba-Pérez,Silvia García-Méndez,Fátima Leal,Benedita Malheiro,Juan Carlos Burguillo-Rial*

Main category: cs.CL

TL;DR: 本文比较了微调预训练模型与大语言模型在情感识别中的表现，探讨了提示词设计和情感分组对模型效果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有变换器模型虽提升了情感识别效果，但在开放式文本情感自动分析中仍面临语境歧义、语言多样性和复杂情绪表达理解困难等挑战。

Method: 通过三种情景比较微调预训练模型和使用不同提示词设计的通用大语言模型，评价情感分组技术对模型性能的影响。

Result: 微调模型在情感识别中达到70%以上准确率，大语言模型需要结构化提示词设计和情感分组才能提升表现。

Conclusion: 结构化提示词工程和情感分组技术是改善大语言模型情感识别能力的关键，有助于提升情感分析和人机交互效果。

Abstract: Transformer models have significantly advanced the field of emotion
recognition. However, there are still open challenges when exploring open-ended
queries for Large Language Models (LLMs). Although current models offer good
results, automatic emotion analysis in open texts presents significant
challenges, such as contextual ambiguity, linguistic variability, and
difficulty interpreting complex emotional expressions. These limitations make
the direct application of generalist models difficult. Accordingly, this work
compares the effectiveness of fine-tuning and prompt engineering in emotion
detection in three distinct scenarios: (i) performance of fine-tuned
pre-trained models and general-purpose LLMs using simple prompts; (ii)
effectiveness of different emotion prompt designs with LLMs; and (iii) impact
of emotion grouping techniques on these models. Experimental tests attain
metrics above 70% with a fine-tuned pre-trained model for emotion recognition.
Moreover, the findings highlight that LLMs require structured prompt
engineering and emotion grouping to enhance their performance. These
advancements improve sentiment analysis, human-computer interaction, and
understanding of user behavior across various domains.

</details>


### [65] [DiffAdapt: Difficulty-Adaptive Reasoning for Token-Efficient LLM Inference](https://arxiv.org/abs/2510.19669)
*Xiang Liu,Xuming Hu,Xiaowen Chu,Eunsol Choi*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型(LLMs)在推理中出现的“过度思考”现象，通过分析推理轨迹中的熵值，发现不同难度问题有不同的熵模式，并提出了DiffAdapt框架，根据问题难度及熵自适应选择推理策略，从而提高推理效率，减少计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在推理时常生成冗长推理轨迹，效率低下，存在过度思考问题，影响推理速度和计算资源消耗。

Method: 通过分析推理轨迹中token概率的熵分布，识别不同难度的问题特征，设计DiffAdapt框架，根据问题难度及熵值动态选择三种推理策略（Easy/Normal/Hard），并通过一个小型探针分类器对模型隐藏状态进行分类，无需微调基础模型。

Result: 在五个模型和八个基准测试上，DiffAdapt在保持或提升准确率的同时，减少了最多22.4%的token使用，显著提升推理效率。

Conclusion: DiffAdapt为大型语言模型推理效率优化提供了一条实用路径，通过无须微调基础模型的小探针方式，实现了高性能与计算成本的平衡。

Abstract: Recent reasoning Large Language Models (LLMs) demonstrate remarkable
problem-solving abilities but often generate long thinking traces whose utility
is unclear. Our work aims to improve their efficiency, enabling them to reach
high performance without overthinking. First, we analyze the entropy of token
probabilities in reasoning traces. Across three models, we observe a consistent
U-shaped entropy pattern: high entropy on easy problems despite high accuracy,
low entropy on problems with medium difficulty, and high entropy on hard
problems reflecting uncertainty. Specifically, we notice 22--25\% entropy
reduction from easy to medium difficulty regions, suggesting an {overthinking}
phenomenon on easy instances. Building on these insights, we introduce
\textbf{DiffAdapt}, a lightweight framework that selects Easy/Normal/Hard
inference strategies per question based on their difficulty and reasoning trace
entropy. Each inference strategy consists of a fixed prompt, temperature and
maximum token length. In contrast to existing efficiency optimization methods,
our approach does not fine-tune base LLM but a small probe that classifies
LLM's final hidden state, allowing inexpensive adaptation. We comprehensively
evaluate our method on five models and eight benchmarks. Our method achieves
comparable or improved accuracy while reducing token usage by up to 22.4\%,
establishing a practical path toward compute-efficient reasoning.

</details>


### [66] [CoSense-LLM: Semantics at the Edge with Cost- and Uncertainty-Aware Cloud-Edge Cooperation](https://arxiv.org/abs/2510.19670)
*Hasan Akgul,Mari Eplik,Javier Rojas,Aina Binti Abdullah,Pieter van der Merwe*

Main category: cs.CL

TL;DR: CoSense-LLM是一个边缘优先的多模态传感器数据处理框架，将传感器流转化为紧凑且可验证的语义标记，并在延迟、能耗、带宽和隐私约束下与大语言模型协同工作。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，如何在保证低延迟、低能耗、高隐私保护的同时，利用多模态传感器数据与大语言模型协同处理，提升系统的响应速度和准确性。

Method: CoSense-LLM包含SenseFusion编码器、多模态传感器数据压缩，Edge-RAG本地混合检索层，PromptRouter基于成本和不确定性选择生成策略，和Secure Execution红action路径保障数据隐私，并结合多种现代优化技术，如分页缓存、FlashAttention核、量化LoRA等。

Result: 系统在多场景部署（家庭、办公室、诊所）中实现了亚秒级端到端延迟，减少带宽和令牌成本，保护隐私只传输离散编码，且通过消融实验验证了系统组件如Edge-RAG和PromptRouter的有效性。

Conclusion: CoSense-LLM支持边缘优先设计理念，实现了语义处理、隐私保护和可预测延迟的平衡，适合在复杂干扰环境中部署大模型应用。

Abstract: We present CoSense-LLM, an edge-first framework that turns continuous
multimodal sensor streams (for example Wi-Fi CSI, IMU, audio, RFID, and
lightweight vision) into compact, verifiable semantic tokens and coordinates
with large language models under explicit latency, energy, bandwidth, and
privacy constraints. CoSense-LLM has four parts: (i) SenseFusion, a lightweight
encoder that aligns sensor embeddings with language and compresses them into
short discrete code sequences; (ii) Edge-RAG, a local hybrid retrieval layer
that grounds generation in site specific policies and notes; (iii)
PromptRouter, a cost and uncertainty aware policy that selects edge only
generation, edge plus retrieval, or compact cloud escalation; and (iv) Secure
Execution, an auditable redaction path that enforces data minimization so raw
waveforms never leave the device. The system works with modern serving
optimizations, including paged or streaming KV caches, FlashAttention style
kernels, speculative decoding, and quantized LoRA adapters, and supports on
device personalization and federated updates under non IID drift. Across home,
office, and clinic deployments, CoSense-LLM delivers grounded explanations
while meeting tight service level objectives: it sustains sub second (p95) end
to end latency on edge dominant paths, reduces inter tier token and bandwidth
costs by preferring local retrieval grounded responses, and preserves privacy
by transmitting only discrete codes and redacted metadata. Ablations show that
Edge-RAG improves factual consistency and reduces contradictions, calibrated
uncertainty enables selective abstention and controlled escalations, and KV
plus decoding accelerators lower energy per decision. The results support an
edge first design that treats semantics, privacy, and predictable latency as co
equal goals for large model deployments in interference prone environments.

</details>


### [67] [Are Large Language Models Sensitive to the Motives Behind Communication?](https://arxiv.org/abs/2510.19687)
*Addison J. Wu,Ryan Liu,Kerem Oktar,Theodore R. Sumers,Thomas L. Griffiths*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在识别和评估信息来源动机方面的能力，发现它们在人类类似的理性模型指导下，能够较好地辨别有偏见的信息，但在处理更自然的在线广告时表现不佳，通过简单的引导干预可以提升其效果。


<details>
  <summary>Details</summary>
Motivation: 人类交流具有动机性，信息传递常带有意图和利益驱动。为了让LLMs在实际应用中更有效，必须让模型能够辨识和评估信息来源的动机，从而判断信息可信度。

Method: 通过认知科学的控制实验验证LLMs是否符合理性动机学习模型；并进一步在自然场景的在线广告中测试，观察LLMs处理动机信息的表现差异；提出简单的引导干预方法以增强模型的动机敏感度。

Result: LLMs在受控实验中表现出类似人类的动机识别能力，能够理性地减少对有偏信息的信任，但在自然广告环境中，模型推理与理性模型偏差较大，部分因信息干扰；引导干预显著提升了对动机的识别效果。

Conclusion: LLMs具有基本的动机识别能力，但要在复杂真实环境中实现广泛应用，还需改进模型，提升其对动机信息的敏感性和理解能力。

Abstract: Human communication is motivated: people speak, write, and create content
with a particular communicative intent in mind. As a result, information that
large language models (LLMs) and AI agents process is inherently framed by
humans' intentions and incentives. People are adept at navigating such nuanced
information: we routinely identify benevolent or self-serving motives in order
to decide what statements to trust. For LLMs to be effective in the real world,
they too must critically evaluate content by factoring in the motivations of
the source -- for instance, weighing the credibility of claims made in a sales
pitch. In this paper, we undertake a comprehensive study of whether LLMs have
this capacity for motivational vigilance. We first employ controlled
experiments from cognitive science to verify that LLMs' behavior is consistent
with rational models of learning from motivated testimony, and find they
successfully discount information from biased sources in a human-like manner.
We then extend our evaluation to sponsored online adverts, a more naturalistic
reflection of LLM agents' information ecosystems. In these settings, we find
that LLMs' inferences do not track the rational models' predictions nearly as
closely -- partly due to additional information that distracts them from
vigilance-relevant considerations. However, a simple steering intervention that
boosts the salience of intentions and incentives substantially increases the
correspondence between LLMs and the rational model. These results suggest that
LLMs possess a basic sensitivity to the motivations of others, but generalizing
to novel real-world settings will require further improvements to these models.

</details>


### [68] [Do Prompts Reshape Representations? An Empirical Study of Prompting Effects on Embeddings](https://arxiv.org/abs/2510.19694)
*Cesar Gonzalez-Gutierrez,Dirk Hovy*

Main category: cs.CL

TL;DR: 本文通过探究提示语嵌入对零样本分类任务中语言模型内部表示的影响，发现提示语相关性与表示质量之间并无稳定正相关。


<details>
  <summary>Details</summary>
Motivation: 虽然提示语是利用语言模型进行零样本任务的常用方法，但其背后的机制尚不清楚，特别是提示语对内部表示质量的影响及其与任务相关性的关系。

Method: 通过一系列针对提示语嵌入的探测实验，分析不同提示模板组合对零样本分类性能及内部表示的影响。

Result: 实验结果表明，提示语确实会影响内部表示质量，但这种变化并不稳定地与提示与目标任务的相关性挂钩，从而挑战了相关提示必然带来更佳表示的假设。

Conclusion: 提示语相关性的高低并非决定语言模型内部表示质量的关键因素，提示机制的作用机制更加复杂，需要进一步研究潜在影响因素。

Abstract: Prompting is a common approach for leveraging LMs in zero-shot settings.
However, the underlying mechanisms that enable LMs to perform diverse tasks
without task-specific supervision remain poorly understood. Studying the
relationship between prompting and the quality of internal representations can
shed light on how pre-trained embeddings may support in-context task solving.
In this empirical study, we conduct a series of probing experiments on prompt
embeddings, analyzing various combinations of prompt templates for zero-shot
classification. Our findings show that while prompting affects the quality of
representations, these changes do not consistently correlate with the relevance
of the prompts to the target task. This result challenges the assumption that
more relevant prompts necessarily lead to better representations. We further
analyze potential factors that may contribute to this unexpected behavior.

</details>


### [69] [From Answers to Guidance: A Proactive Dialogue System for Legal Documents](https://arxiv.org/abs/2510.19723)
*Ashish Chouhan,Michael Gertz*

Main category: cs.CL

TL;DR: 介绍了EUDial多轮对话数据集和LexGuide框架，以提升普通公众理解欧盟法律信息的能力。


<details>
  <summary>Details</summary>
Motivation: 法律信息的复杂性导致普通公众难以获取和理解欧盟的法律文档，亟需有效的交互式工具帮助公众理解。

Method: 构建EUDial对话数据集，结合AskEP博客内容；提出LexGuide框架，利用检索增强生成和层级主题组织，保证对话的全面性和连贯性。

Result: 通过实验证明，LexGuide能够实现主动、结构化的法律对话导航，有效弥合法律信息公开与公民理解之间的差距。

Conclusion: EUDial数据集和LexGuide框架为推进主动法律对话系统提供了实用资源，促进公众对复杂法律文本的理解。

Abstract: The accessibility of legal information remains a constant challenge,
particularly for laypersons seeking to understand and apply complex
institutional texts. While the European Union provides open access to
legislation, parliamentary responses, and regulatory documents, these resources
can be challenging for laypeople to explore. In this paper, we introduce
EUDial, a proactive multi-turn dialogue dataset constructed from 204 blogs
curated by the Citizens' Enquiries Unit (AskEP) of the European Parliamentary
Research Service. EUDial contains 880 dialogue turns (averaging 4.3 turns per
dialogue), where each dialogue includes initial questions, structured answers,
and follow-up questions. Beyond dataset construction, we propose the LexGuide
framework that leverages retrieval-augmented generation with hierarchical topic
organization to structure dialogue progression, ensuring both comprehensive
coverage of legal aspects and coherence across conversational turns. The
results demonstrate that proactive, structured navigation closes the gap
between the availability of legal information and citizen comprehension,
establishing EUDial and LexGuide as practical resources for advancing proactive
legal dialogue systems.

</details>


### [70] [Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning](https://arxiv.org/abs/2510.19733)
*M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka*

Main category: cs.CL

TL;DR: 提出了Zhyper，一种参数高效的因式分解超网络框架，用文本描述生成上下文感知的LoRA适配器，实现了更少参数下的高效大语言模型调控。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过直接调整LoRA权重微调大语言模型存在参数量大且无法有效确保模型遵循特定文化或政治语境的限制。

Method: 设计了Zhyper，利用超网络生成上下文相关的LoRA适配器，以参数高效的方式实现LLM的语义条件调控。

Result: 在多个基准测试中，Zhyper以最多26倍更少的参数数量达到了与先进方法相当的性能，并在文化调控任务中表现出更好的泛化能力和细粒度语境适应性。

Conclusion: Zhyper有效提升了大语言模型在语义条件适应上的参数效率和效果，尤其在文化对齐及跨领域泛化方面展现出优势。

Abstract: Large Language Model (LLM) conditioning refers to instructing an LLM to
generate content in accordance with the norms and values of a specific culture,
beliefs of a particular political orientation, or any desired text-specified
semantic conditioning. Unfortunately, prompt engineering does not ensure that
LLMs behave in accordance with a desired conditioning due to the inductive bias
of the pre-training and alignment datasets. Prior works have focused on
fine-tuning LLMs by directly conditioning the LoRA weights; however, such
methods introduce a large number of parameters. As a remedy, we propose Zhyper,
a parameter-efficient factorized hypernetwork framework that generates
context-aware LoRA adapters from textual descriptions. Experiments on multiple
benchmarks show that Zhyper achieves competitive performance with up to 26x
fewer parameters than the state-of-the-art baselines. Furthermore, we extend
Zhyper to cultural alignment, demonstrating improved generalization to
out-of-domain settings and a better capturing of fine-grained contextual
values.

</details>


### [71] [SmartSwitch: Advancing LLM Reasoning by Overcoming Underthinking via Promoting Deeper Thought Exploration](https://arxiv.org/abs/2510.19767)
*Xichen Zhang,Sitong Wu,Haoru Tan,Shaozuo Yu,Yinghao Zhu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 本文提出了SmartSwitch推理框架，通过检测思维切换点，避免大语言模型在复杂推理中“浅思考”，实现更深入的思路探索，提升模型性能和效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在长链思维复杂推理任务中存在“浅思考”问题，频繁切换思路导致推理不深入，影响性能和令牌效率。

Method: 设计了SmartSwitch推理框架，包含感知模块检测思维切换并评估思路潜力，利用奖励模型发现高潜思路被弃用时，插入“深入提示”促使模型回退并深入探索。

Result: 在数学推理基准测试中，SmartSwitch显著提升了多种规模大语言模型的推理性能。

Conclusion: SmartSwitch作为即插即用框架，有效解决了大语言模型推理中的浅思考问题，提升了复杂推理任务的表现。

Abstract: The long chain-of-thought (LongCoT) capability is central to the recent
breakthroughs achieved by large language models in complex reasoning tasks.
However, the accompanying issue of ''underthinking'', where models exhibit
shallow reasoning by frequently switching thoughts without sufficient
exploration, limits both performance and token efficiency. To address this
problem, we propose a simple yet effective reasoning strategy: the SmartSwitch
inference framework. This framework can be easily integrated into any large
language model as a plug-and-play solution, continuously monitoring the model's
reasoning process to detect underthinking and guide it toward deeper
exploration of promising but overlooked thoughts. Specifically, the perception
module identifies points where thoughts switch and evaluates the potential of
the preceding thought using an off-the-shelf process reward model (PRM). If a
high-potential thought is found to be prematurely abandoned, the intervention
module interrupts the ongoing inference, backtracks to the point before the
switch, and inserts a "deepening prompt" to encourage further exploration along
that promising path. Extensive experiments on challenging mathematical
reasoning benchmarks demonstrate that our method significantly enhances the
performance of various large language models of different sizes.

</details>


### [72] [AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders](https://arxiv.org/abs/2510.19779)
*Yuezhou Hu,Jiaxin Guo,Xinyu Feng,Tuo Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种名为AdaSPEC的新方法，通过选择性过滤知识蒸馏中难以拟合的token，提高了草稿模型与目标模型的对齐度，从而提升了大语言模型推理的速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 传统的知识蒸馏方法旨在最小化草稿模型和目标模型之间所有token的KL散度，但这与投机解码的真正目标最大化token接受率不一致，导致草稿模型难以充分吸收目标模型的知识。

Method: AdaSPEC引入了选择性token过滤机制，通过参考模型识别并剔除难以拟合的token，只对较简单的token进行蒸馏，从而使草稿模型更好地对齐目标模型。

Result: 在算术推理、指令遵循、编码和摘要等多个任务及不同模型规模下，AdaSPEC均优于现有的DistillSpec方法，实现了最高达15%的接受率提升。

Conclusion: AdaSPEC有效解决了传统知识蒸馏方法的对齐问题，提升了草稿模型的性能，显著加速了大语言模型的推理过程。

Abstract: Speculative Decoding (SD) accelerates large language model inference by
employing a small draft model to generate predictions, which are then verified
by a larger target model. The effectiveness of SD hinges on the alignment
between these models, which is typically enhanced by Knowledge Distillation
(KD). However, conventional KD methods aim to minimize the KL divergence
between the draft and target models across all tokens, a goal that is
misaligned with the true objective of SD, which is to maximize token acceptance
rate. Therefore, draft models often struggle to fully assimilate the target
model's knowledge due to capacity constraints, leading to suboptimal
performance. To address this challenge, we propose AdaSPEC, a novel method that
incorporates selective token filtering into the KD process. AdaSPEC utilizes a
reference model to identify and filter out difficult-to-fit tokens, enabling
the distillation of a draft model that better aligns with the target model on
simpler tokens. This approach improves the overall token acceptance rate
without compromising generation quality. We evaluate AdaSPEC across diverse
tasks, including arithmetic reasoning, instruction-following, coding, and
summarization, using model configurations of 31M/1.4B and 350M/2.7B parameters.
Our results demonstrate that AdaSPEC consistently outperforms the
state-of-the-art DistillSpec method, achieving higher acceptance rates across
all tasks (up to 15\%). The code is publicly available at
https://github.com/yuezhouhu/adaspec.

</details>


### [73] [Adapting Multilingual Models to Code-Mixed Tasks via Model Merging](https://arxiv.org/abs/2510.19782)
*Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文提出了通过模型融合作为代码混合NLP适应的实用替代策略，在多语言基础模型基础上进行无标签代码混合文本的持续预训练，融合模型并微调，提高任务表现。


<details>
  <summary>Details</summary>
Motivation: 代码混合语言处理中的传统适应策略存在局限，利用无标签数据更有效地提升模型能力成为挑战。

Method: 从多语言基础模型出发，先对无标签代码混合文本做持续预训练，接着将预训练检查点与基础模型融合，最后在下游任务数据上微调。

Result: 融合模型在英语-印地语和英语-西班牙语的句子分类任务上均优于全微调和简单持续预训练微调方法，F1提升2-5点；融合后模型对低资源语言对表现更优。

Conclusion: 模型融合比传统的持续预训练和微调方式更有效地利用无标签数据，特别适合代码混合语言的NLP任务，并且具有较好的迁移能力和扩展潜力。

Abstract: We study model merging as a practical alternative to conventional adaptation
strategies for code-mixed NLP. Starting from a multilingual base model, we: (i)
perform continued pre-training (CPT) on unlabeled code-mixed text to obtain an
adapted checkpoint, (ii) merge checkpoint with the base model, and (iii)
fine-tune (FT) on the downstream task data. We evaluate our approach for
sentence classification (sentiment and hate speech) task in English-Hindi
(En-Hi) and English-Spanish (En-Es) using XLM-R and Llama-3.2-1B models. Our
results show that merged models consistently outperform full fine-tuning and
CPT->FT. We observe gains of 2--5 points in F1 over full fine-tuning and ~1-2
points over CPT->FT, indicating that unlabeled data is leveraged more
effectively via merging than via CPT alone. Zero-/few-shot prompting with
larger LLMs (e.g., Llama-3.3-70B) lags behind fine-tuned and merged
checkpoints, underscoring limits of in-context learning for code-mixed inputs.
We further test cross-pair transfer by training on En-Hi and evaluating on
En-Ta and En-Ml: merged checkpoints transfer more strongly than
monolingual-English baselines (e.g., TV/TIES variants reaching 0.65-0.68 F1 vs
0.61-0.63 for full fine-tuning), suggesting that code-mixed knowledge is a more
reliable substrate for low-resource pairs. We conclude with adaptation recipes
matched to common data regimes (labeled only; labeled+unlabeled; transfer-only)
and discuss limitations and scaling considerations for broader tasks and larger
models.

</details>


### [74] [ToolDreamer: Instilling LLM Reasoning Into Tool Retrievers](https://arxiv.org/abs/2510.19791)
*Saptarshi Sengupta,Zhengyu Zhou,Jun Araki,Xingbo Wang,Bingqing Wang,Suhang Wang,Zhe Feng*

Main category: cs.CL

TL;DR: 作者提出ToolDreamer框架，通过生成假设性工具描述改善工具检索，提升LLM调用大量工具时的检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索方法仅基于用户查询与工具描述的相似度，存在用户请求与工具描述语言不匹配的问题，导致检索效果不佳。

Method: 利用LLM生成假设性的工具描述（合成描述），使检索模型能够基于这些描述更自然地匹配用户查询，实现对工具的更有效检索。

Result: 在ToolRet数据集上，ToolDreamer提升了稀疏和密集检索器的性能，且对是否训练不敏感，表现灵活。

Conclusion: ToolDreamer通过在检索环节承担部分推理任务，缓解了LLM上下文窗口限制，使得LLM能有效调用大量工具。

Abstract: Tool calling has become increasingly popular for Large Language Models
(LLMs). However, for large tool sets, the resulting tokens would exceed the
LLM's context window limit, making it impossible to include every tool. Hence,
an external retriever is used to provide LLMs with the most relevant tools for
a query. Existing retrieval models rank tools based on the similarity between a
user query and a tool description (TD). This leads to suboptimal retrieval as
user requests are often poorly aligned with the language of TD. To remedy the
issue, we propose ToolDreamer, a framework to condition retriever models to
fetch tools based on hypothetical (synthetic) TD generated using an LLM, i.e.,
description of tools that the LLM feels will be potentially useful for the
query. The framework enables a more natural alignment between queries and tools
within the language space of TD's. We apply ToolDreamer on the ToolRet dataset
and show that our method improves the performance of sparse and dense
retrievers with and without training, thus showcasing its flexibility. Through
our proposed framework, our aim is to offload a portion of the reasoning burden
to the retriever so that the LLM may effectively handle a large collection of
tools without inundating its context window.

</details>


### [75] [The Art of Asking: Multilingual Prompt Optimization for Synthetic Data](https://arxiv.org/abs/2510.19806)
*David Mora,Viraat Aryabumi,Wei-Yin Ko,Sara Hooker,Julia Kreutzer,Marzieh Fadaee*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级的提示词空间优化框架，通过自然性、文化适应性和难度提升的转换方法，显著提升多语言大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多语言合成数据主要依赖翻译提示，带有强烈的英语中心化倾向，忽视文化因素，限制模型泛化能力。

Method: 通过系统地转换翻译提示，包括自然性调整、文化适应和难度增强，优化提示词空间。使用现成多语言大模型，在12种语言上进行实验。

Result: 在相同数据条件下，所提方法在Global-MMLU准确率提升4.7%，Flores XCometXL提升2.4%，mArenaHard喜好度提升35.3%。

Conclusion: 提示词空间优化是一种简单但有效的构建更鲁棒、文化贴合且具全球适应性的多语言大模型的新范式。

Abstract: Synthetic data has become a cornerstone for scaling large language models,
yet its multilingual use remains bottlenecked by translation-based prompts.
This strategy inherits English-centric framing and style and neglects cultural
dimensions, ultimately constraining model generalization. We argue that the
overlooked prompt space-the very inputs that define training
distributions-offers a more powerful lever for improving multilingual
performance. We introduce a lightweight framework for prompt-space
optimization, where translated prompts are systematically transformed for
Naturalness, Cultural Adaptation, and Difficulty Enhancement. Using an
off-the-shelf multilingual LLM, we apply these transformations to prompts for
12 languages spanning 7 families. Under identical data conditions, our
approaches achieve substantial and consistent downstream improvements over the
translation-only baseline: +4.7% on Global-MMLU accuracy, +2.4% on Flores
XCometXL and +35.3% wins in preferences on mArenaHard. We establish
prompt-space optimization as a simple yet powerful paradigm for building
multilingual LLMs that are more robust, culturally grounded, and globally
capable.

</details>


### [76] [Scaf-GRPO: Scaffolded Group Relative Policy Optimization for Enhancing LLM Reasoning](https://arxiv.org/abs/2510.19807)
*Xichen Zhang,Sitong Wu,Yinghao Zhu,Haoru Tan,Shaozuo Yu,Ziyi He,Jiaya Jia*

Main category: cs.CL

TL;DR: 提出了Scaf-GRPO框架，通过分阶段提示策略解决了大语言模型训练中“学习悬崖”问题，有效提升了模型解决复杂数学问题的能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于可验证奖励的强化学习方法在处理超出模型当前能力的问题时存在“学习悬崖”现象，导致模型学习停滞。

Method: 引入Scaf-GRPO，即在模型学习停滞时分阶段注入从抽象概念到具体步骤的提示，帮助模型自我构建有效解答。

Result: 在AIME24数学基准测试中，Scaf-GRPO使Qwen2.5-Math-7B模型的pass@1准确率较基础GRPO提升了44.3%。

Conclusion: Scaf-GRPO有效突破了模型的学习障碍，增强了其解决复杂问题的能力，为推动大语言模型的自主推理能力扩展提供了有力工具。

Abstract: Reinforcement learning from verifiable rewards has emerged as a powerful
technique for enhancing the complex reasoning abilities of Large Language
Models (LLMs). However, these methods are fundamentally constrained by the
''learning cliff'' phenomenon: when faced with problems far beyond their
current capabilities, models consistently fail, yielding a persistent
zero-reward signal. In policy optimization algorithms like GRPO, this collapses
the advantage calculation to zero, rendering these difficult problems invisible
to the learning gradient and stalling progress. To overcome this, we introduce
Scaf-GRPO (Scaffolded Group Relative Policy Optimization), a progressive
training framework that strategically provides minimal guidance only when a
model's independent learning has plateaued. The framework first diagnoses
learning stagnation and then intervenes by injecting tiered in-prompt hints,
ranging from abstract concepts to concrete steps, enabling the model to
construct a valid solution by itself. Extensive experiments on challenging
mathematics benchmarks demonstrate Scaf-GRPO's effectiveness, boosting the
pass@1 score of the Qwen2.5-Math-7B model on the AIME24 benchmark by a relative
44.3% over a vanilla GRPO baseline. This result demonstrates our framework
provides a robust and effective methodology for unlocking a model's ability to
solve problems previously beyond its reach, a critical step towards extending
the frontier of autonomous reasoning in LLM.

</details>


### [77] [Hubble: a Model Suite to Advance the Study of LLM Memorization](https://arxiv.org/abs/2510.19811)
*Johnny Tian-Zheng Wei,Ameya Godbole,Mohammad Aflah Khan,Ryan Wang,Xiaoyuan Zhu,James Flemings,Nitya Kashyap,Krishna P. Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: Hubble是一个开源大型语言模型套件，专注于LLM记忆风险的科学研究，通过标准和插入敏感文本的扰动模型分析记忆风险与训练语料规模的关系，并提出减少记忆风险的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型中敏感信息的记忆情况及其风险，旨在科学理解和缓解LLM的记忆泄露问题。

Method: 构建标准与扰动版本的Hubble模型，插入特定敏感文本，比较不同训练语料规模和敏感数据插入时机对模型记忆的影响，分析生物传记等不同私密信息的记忆情况。

Result: 发现记忆风险主要由敏感数据相对于训练语料规模的频率决定，增加训练语料规模可以稀释敏感数据；敏感数据如果不持续暴露，模型会遗忘它们；并展现了Hubble模型在成员推断与机器遗忘研究中的潜力。

Conclusion: 建议通过增大训练语料规模和安排敏感数据在训练早期出现来减少记忆风险，Hubble模型为记忆研究提供了可靠的测试平台，促进社区在记忆泄露和机器学习安全领域的进一步研究。

Abstract: We present Hubble, a suite of fully open-source large language models (LLMs)
for the scientific study of LLM memorization. Hubble models come in standard
and perturbed variants: standard models are pretrained on a large English
corpus, and perturbed models are trained in the same way but with controlled
insertion of text (e.g., book passages, biographies, and test sets) designed to
emulate key memorization risks. Our core release includes 8 models -- standard
and perturbed models with 1B or 8B parameters, pretrained on 100B or 500B
tokens -- establishing that memorization risks are determined by the frequency
of sensitive data relative to size of the training corpus (i.e., a password
appearing once in a smaller corpus is memorized better than the same password
in a larger corpus). Our release also includes 6 perturbed models with text
inserted at different pretraining phases, showing that sensitive data without
continued exposure can be forgotten. These findings suggest two best practices
for addressing memorization risks: to dilute sensitive data by increasing the
size of the training corpus, and to order sensitive data to appear earlier in
training. Beyond these general empirical findings, Hubble enables a broad range
of memorization research; for example, analyzing the biographies reveals how
readily different types of private information are memorized. We also
demonstrate that the randomized insertions in Hubble make it an ideal testbed
for membership inference and machine unlearning, and invite the community to
further explore, benchmark, and build upon our work.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [78] [Local Guidance for Configuration-Based Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19072)
*Tomoki Arita,Keisuke Okumura*

Main category: cs.MA

TL;DR: 本文提出了一种为多智能体路径规划提供局部指导的方法，通过在每个智能体周围提供时空信息，有效减少拥堵，提高协调效率。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体路径规划多采用全局指导来缓解拥堵，但对局部指导的探索较少，且局部指导可能计算量较大。

Method: 为基于配置的路径规划器LaCAM引入局部时空指导，实时提供智能体附近的指导信息，帮助规划器提升路径质量。

Result: 实验表明，该局部指导显著提高了解决方案质量，同时计算时间保持在适中范围内。

Conclusion: 局部指导是一种有效的多智能体路径规划优化方式，能够推进行业性能的提升。

Abstract: Guidance is an emerging concept that improves the empirical performance of
real-time, sub-optimal multi-agent pathfinding (MAPF) methods. It offers
additional information to MAPF algorithms to mitigate congestion on a global
scale by considering the collective behavior of all agents across the entire
workspace. This global perspective helps reduce agents' waiting times, thereby
improving overall coordination efficiency. In contrast, this study explores an
alternative approach: providing local guidance in the vicinity of each agent.
While such localized methods involve recomputation as agents move and may
appear computationally demanding, we empirically demonstrate that supplying
informative spatiotemporal cues to the planner can significantly improve
solution quality without exceeding a moderate time budget. When applied to
LaCAM, a leading configuration-based solver, this form of guidance establishes
a new performance frontier for MAPF.

</details>


### [79] [SORA-ATMAS: Adaptive Trust Management and Multi-LLM Aligned Governance for Future Smart Cities](https://arxiv.org/abs/2510.19327)
*Usama Antuley,Shahbaz Siddiqui,Sufian Hameed,Waqas Arif,Subhan Shah,Syed Attique Shah*

Main category: cs.MA

TL;DR: 本文提出了SORA-ATMAS框架，解决智能城市中自治AI的治理、风险及合规问题，实现多域智能体协同优化城市管理。


<details>
  <summary>Details</summary>
Motivation: 智能城市发展依赖自治AI进行实时响应，但多样化生态带来治理、责任和合规挑战。

Method: 设计SORA-ATMAS，该框架通过治理政策和回退机制，协调多个领域智能体（天气、交通、安全）和多种大型语言模型，实现政策对齐和多智能体协同。

Result: SORA-ATMAS使平均绝对误差降低35%，有效监控天气、处理交通高风险情况和安全事件，实现高吞吐量和低延迟的可扩展部署。

Conclusion: SORA-ATMAS验证了作为符合规制、上下文感知且可验证的治理框架，支持智能城市的安全、实时和可追责决策管理。

Abstract: The rapid evolution of smart cities has increased the reliance on intelligent
interconnected services to optimize infrastructure, resources, and citizen
well-being. Agentic AI has emerged as a key enabler by supporting autonomous
decision-making and adaptive coordination, allowing urban systems to respond in
real time to dynamic conditions. Its benefits are evident in areas such as
transportation, where the integration of traffic data, weather forecasts, and
safety sensors enables dynamic rerouting and a faster response to hazards.
However, its deployment across heterogeneous smart city ecosystems raises
critical governance, risk, and compliance (GRC) challenges, including
accountability, data privacy, and regulatory alignment within decentralized
infrastructures. Evaluation of SORA-ATMAS with three domain agents (Weather,
Traffic, and Safety) demonstrated that its governance policies, including a
fallback mechanism for high-risk scenarios, effectively steer multiple LLMs
(GPT, Grok, DeepSeek) towards domain-optimized, policy-aligned outputs,
producing an average MAE reduction of 35% across agents. Results showed stable
weather monitoring, effective handling of high-risk traffic plateaus 0.85, and
adaptive trust regulation in Safety/Fire scenarios 0.65. Runtime profiling of a
3-agent deployment confirmed scalability, with throughput between 13.8-17.2
requests per second, execution times below 72~ms, and governance delays under
100 ms, analytical projections suggest maintained performance at larger scales.
Cross-domain rules ensured safe interoperability, with traffic rerouting
permitted only under validated weather conditions. These findings validate
SORA-ATMAS as a regulation-aligned, context-aware, and verifiable governance
framework that consolidates distributed agent outputs into accountable,
real-time decisions, offering a resilient foundation for smart-city management.

</details>


### [80] [ColorAgent: Building A Robust, Personalized, and Interactive OS Agent](https://arxiv.org/abs/2510.19386)
*Ning Li,Qiqiang Lin,Zheng Wu,Xiaoyun Mo,Weiming Zhang,Yin Zhao,Xiangmou Qu,Jiamu Zhou,Jun Wang,Congmin Zheng,Yuanyi Song,Hongjiang Chen,Heyuan Huang,Jihong Wang,Jiaxin Yin,Jingwei Yu,Junwei Liao,Qiuying Peng,Xingyu Lou,Jun Wang,Weiwen Liu,Zhuosheng Zhang,Weinan Zhang*

Main category: cs.MA

TL;DR: 本文介绍了ColorAgent，一种能够进行长时间、高鲁棒性的操作系统代理，支持个性化和主动用户交互，在AndroidWorld和AndroidLab测试基准中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着硬件、软件和大语言模型技术的进步，操作系统与人类的交互从命令行界面转向快速兴起的AI代理交互，构建能够执行用户指令并忠实跟随用户意愿的操作系统代理成为可能。

Method: 通过逐步强化学习和自我演进训练提升模型长期交互能力，开发定制的多代理框架确保模型的通用性、一致性和鲁棒性，同时探索个性化用户意图识别和主动用户互动。

Result: ColorAgent在AndroidWorld和AndroidLab基准测试中分别达成77.2%和50.7%的成功率，刷新了最新最优水平。

Conclusion: 现有基准测试不足以全面评估操作系统代理，未来工作需侧重评估范式、代理协作及安全性等方向的深入探索。

Abstract: With the advancements in hardware, software, and large language model
technologies, the interaction between humans and operating systems has evolved
from the command-line interface to the rapidly emerging AI agent interactions.
Building an operating system (OS) agent capable of executing user instructions
and faithfully following user desires is becoming a reality. In this technical
report, we present ColorAgent, an OS agent designed to engage in long-horizon,
robust interactions with the environment while also enabling personalized and
proactive user interaction. To enable long-horizon interactions with the
environment, we enhance the model's capabilities through step-wise
reinforcement learning and self-evolving training, while also developing a
tailored multi-agent framework that ensures generality, consistency, and
robustness. In terms of user interaction, we explore personalized user intent
recognition and proactive engagement, positioning the OS agent not merely as an
automation tool but as a warm, collaborative partner. We evaluate ColorAgent on
the AndroidWorld and AndroidLab benchmarks, achieving success rates of 77.2%
and 50.7%, respectively, establishing a new state of the art. Nonetheless, we
note that current benchmarks are insufficient for a comprehensive evaluation of
OS agents and propose further exploring directions in future work, particularly
in the areas of evaluation paradigms, agent collaboration, and security. Our
code is available at https://github.com/MadeAgents/mobile-use.

</details>


### [81] [Modeling realistic human behavior using generative agents in a multimodal transport system: Software architecture and Application to Toulouse](https://arxiv.org/abs/2510.19497)
*Trung-Dung Vu,Benoit Gaudou,Kamaldeep Singh Oberoi*

Main category: cs.MA

TL;DR: 本文提出了一种结合大型语言模型（LLMs）与基于代理的多模式交通仿真架构，用于模拟复杂城市中的人类出行决策，体现个性化出行解决方案的潜力。


<details>
  <summary>Details</summary>
Motivation: 现实人类出行行为建模困难，尤其是在复杂多模式交通系统中理解个体出行方式选择，以支持个性化出行方案的设计。

Method: 将大型语言模型嵌入GAMA仿真平台中，利用生成式代理捕捉真实城市环境中的决策过程，结合GTFS公共交通数据与OpenTripPlanner进行多模式路线规划。

Result: 仿真显示代理不仅能做出环境感知的出行决策，还能随时间形成出行习惯，验证了该框架在智能交通系统中的有效性。

Conclusion: LLMs与基于代理的仿真结合为个性化多模式交通解决方案提供了有前景的方向，尽管存在一些限制，未来将扩展到更大区域并整合实时数据以优化模型。

Abstract: Modeling realistic human behaviour to understand people's mode choices in
order to propose personalised mobility solutions remains challenging. This
paper presents an architecture for modeling realistic human mobility behavior
in complex multimodal transport systems, demonstrated through a case study in
Toulouse, France. We apply Large Language Models (LLMs) within an agent-based
simulation to capture decision-making in a real urban setting. The framework
integrates the GAMA simulation platform with an LLM-based generative agent,
along with General Transit Feed Specification (GTFS) data for public transport,
and OpenTripPlanner for multimodal routing. GAMA platform models the
interactive transport environment, providing visualization and dynamic agent
interactions while eliminating the need to construct the simulation environment
from scratch. This design enables a stronger focus on developing generative
agents and evaluating their performance in transport decision-making processes.
Over a simulated month, results show that agents not only make context-aware
transport decisions but also form habits over time. We conclude that combining
LLMs with agent-based simulation offers a promising direction for advancing
intelligent transportation systems and personalised multimodal mobility
solutions. We also discuss some limitations of this approach and outline future
work on scaling to larger regions, integrating real-time data, and refining
memory models.

</details>


### [82] [Polynomial-time Configuration Generator for Connected Unlabeled Multi-Agent Pathfinding](https://arxiv.org/abs/2510.19567)
*Takahiro Suzuki,Keisuke Okumura*

Main category: cs.MA

TL;DR: 提出了一种用于保持多智能体连通性的路径寻找算法PULL，解决了CUMAPF问题，该问题在保持代理连通性方面比传统MAPF更加复杂。


<details>
  <summary>Details</summary>
Motivation: 标准的多智能体路径寻找（MAPF）无法保证代理之间的连通性，而在群体机器人等应用中，维护智能体间的连通性至关重要。

Method: 设计了一种基于规则的一步函数算法PULL，通过在二维网格上以多项式时间复杂度计算保持连通性且向目标配置前进的下一状态。

Result: PULL算法具有完整性，能够在二维网格中实现$O(n^2)$时间复杂度，适用于数百个智能体的随机实例，并且在小规模实例中通过结合现有搜索算法提高了最优性。

Conclusion: 提出的PULL算法有效解决了CUMAPF问题，兼顾连通性和路径优化，适用于群体机器人和其他需要连通性的多智能体路径规划场景。

Abstract: We consider Connected Unlabeled Multi-Agent Pathfinding (CUMAPF), a variant
of MAPF where the agents must maintain connectivity at all times. This problem
is fundamental to swarm robotics applications like self-reconfiguration and
marching, where standard MAPF is insufficient as it does not guarantee the
required connectivity between agents. While unlabeled MAPF is tractable in
optimization, CUMAPF is NP-hard even on highly restricted graph classes. To
tackle this challenge, we propose PULL, a complete and polynomial-time
algorithm with a simple design. It is based on a rule-based one-step function
that computes a subsequent configuration that preserves connectivity and
advances towards the target configuration. PULL is lightweight, and runs in
$O(n^2)$ time per step in 2D grid, where $n$ is the number of agents. Our
experiments further demonstrate its practical performance: PULL finds
competitive solution qualities against trivial solutions for hundreds of
agents, in randomly generated instances. Furthermore, we develop an eventually
optimal solver that integrates PULL into an existing search-based MAPF
algorithm, providing a valuable tool for small-scale instances.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [83] [CosmoCore Affective Dream-Replay Reinforcement Learning for Code Generation](https://arxiv.org/abs/2510.18895)
*Santhosh Kumar Ravindran*

Main category: cs.SE

TL;DR: CosmoCore是一种受神经科学启发的强化学习架构，通过情感信号提升大型语言模型代码生成的准确性和自我纠正能力。


<details>
  <summary>Details</summary>
Motivation: 受人类和动物学习机制启发，错误产生的尴尬情绪可驱动快速修正，应用到代码生成以减少错误。

Method: 使用轻量级多层感知机对代码生成轨迹进行情绪（价态）和意外性标记，优先重放负面情绪片段以强化纠正，剪枝低意外性片段防止过度自信和缓存膨胀。

Result: 在HumanEval和BigCodeBench等基准测试中，减少48%的幻觉代码（语法错误或逻辑错误），自我纠正速度提升45%。本地实验和消融研究验证了方法有效性。

Conclusion: CosmoCore扩展了基于人类反馈的强化学习，使代码助手更具情感意识，适用于集成开发环境和数据管道，且代码与模拟环境已开源。

Abstract: We introduce CosmoCore, a neuroscience-inspired reinforcement learning (RL)
architecture that integrates affective signals to enhance code generation in
large language models (LLMs). Motivated by human and animal learning where
embarrassment from mistakes drives rapid correction, as observed in training a
puppy to avoid repeating errors after a single scolding CosmoCore tags code
generation trajectories with valence and surprise using a lightweight
multi-layer perceptron (MLP). High-negative valence (cringe) episodes, such as
buggy code outputs, are prioritized in a Dream Queue for five-fold replay
during off-policy updates, while low-surprise successes are pruned to prevent
overconfidence and buffer bloat. Evaluated on code generation benchmarks like
HumanEval and BigCodeBench, alongside simulations with a custom data pipeline
environment, CosmoCore reduces hallucinated code (e.g., syntax errors or
logical bugs) by 48\% and accelerates self-correction by 45\%. Local
experiments using Hugging Face models in a PySpark environment validate these
gains, with code snippets provided for replication. Ablations confirm valence
tagging boosts curiosity in exploration, and pruning mitigates inefficiency.
This framework extends RL from human feedback (RLHF) for more emotionally aware
code assistants, with applications in IDEs and data pipelines. Code and the
custom mini-world simulation are released.

</details>


### [84] [A Survey on Feedback Types in Automated Programming Assessment Systems](https://arxiv.org/abs/2510.18923)
*Eduard Frankford,Tobias Antensteiner,Michael Vierhauser,Clemens Sauerwein,Vivien Wallner,Iris Groher,Reinhold Plösch,Ruth Breu*

Main category: cs.SE

TL;DR: 本文研究了不同自动编程评估系统反馈机制对学生的影响，比较了编译器反馈、单元测试反馈和基于大型语言模型（LLM）的反馈，发现AI反馈虽然学生主观评分较低，但能显著提升学生表现，建议结合单元测试与AI反馈优化教学效果。


<details>
  <summary>Details</summary>
Motivation: 随着各行业数字化进程加快，编程技能需求增加，导致大学广泛开设编程课程，面对多样化学生背景，亟需高效、个性化的自动评估系统提升教学质量。

Method: 通过对200多名不同大学学生进行大规模研究，比较编译器反馈、单元测试反馈和基于LLM的反馈在学生感知质量和问题解决效果上的表现。

Result: 学生主观认为单元测试反馈最有帮助，但基于LLM的AI反馈实际提升了学生的编程表现。

Conclusion: 结合单元测试与AI驱动反馈机制，可以优化自动反馈系统，提高编程学习效果。

Abstract: With the recent rapid increase in digitization across all major industries,
acquiring programming skills has increased the demand for introductory
programming courses. This has further resulted in universities integrating
programming courses into a wide range of curricula, including not only
technical studies but also business and management fields of study.
  Consequently, additional resources are needed for teaching, grading, and
tutoring students with diverse educational backgrounds and skills. As part of
this, Automated Programming Assessment Systems (APASs) have emerged, providing
scalable and high-quality assessment systems with efficient evaluation and
instant feedback. Commonly, APASs heavily rely on predefined unit tests for
generating feedback, often limiting the scope and level of detail of feedback
that can be provided to students. With the rise of Large Language Models (LLMs)
in recent years, new opportunities have emerged as these technologies can
enhance feedback quality and personalization.
  To investigate how different feedback mechanisms in APASs are perceived by
students, and how effective they are in supporting problem-solving, we have
conducted a large-scale study with over 200 students from two different
universities. Specifically, we compare baseline Compiler Feedback, standard
Unit Test Feedback, and advanced LLM-based Feedback regarding perceived quality
and impact on student performance.
  Results indicate that while students rate unit test feedback as the most
helpful, AI-generated feedback leads to significantly better performances.
These findings suggest combining unit tests and AI-driven guidance to optimize
automated feedback mechanisms and improve learning outcomes in programming
education.

</details>


### [85] [Extending Resource Constrained Project Scheduling to Mega-Projects with Model-Based Systems Engineering & Hetero-functional Graph Theory](https://arxiv.org/abs/2510.19035)
*Amirreza Hosseini,Amro M. Farid*

Main category: cs.SE

TL;DR: 本文将资源受限项目调度问题(RCPSP)与基于模型的系统工程(MBSE)和异构功能图理论(HFGT)结合，提出一种新的表示方法及最小成本流模型，增强项目调度的监控和控制能力。


<details>
  <summary>Details</summary>
Motivation: RCPSP虽是项目管理核心，但与MBSE文献脱节，限制了其在复杂系统设计与管理中的应用。

Method: 构建从活动节点网络到SysML活动图再到操作网的转换流程，利用HFGT的最小成本流模型系统分析RCPSP，并证明RCPSP为其特例。

Result: 通过包含可再生和不可再生资源的实例，方法生成类似调度结果，同时提供明确的项目状态解释，增强了监控控制能力。

Conclusion: 该方法既保留了经典RCPSP的优点，又能适应复杂大型项目中的现实约束和企业决策流程，提高项目管理效率。

Abstract: Within the project management context, project scheduling serves as an
indispensable component, functioning as a fundamental tool for planning,
monitoring, controlling, and managing projects more broadly. Although the
resource-constrained project scheduling problem (RCPSP) lies at the core of
project management activities, it remains largely disconnected from the broader
literature on model-based systems engineering (MBSE), thereby limiting its
integration into the design and management of complex systems. The original
contribution of this paper is twofold. First, the paper seeks to reconcile the
RCPSP with the broader literature and vocabulary of model-based systems
engineering and hetero-functional graph theory (HFGT). A concrete translation
pipeline from an activity-on-node network to a SysML activity diagram, and then
to an operand net is constructed. Using this representation, it specializes the
hetero-functional network minimum-cost flow (HFNMCF) formulation to the RCPSP
context as a systematic means of HFGT for quantitative analysis and proves that
the RCPSP is recoverable as a special case of a broader model. Secondly, on an
illustrative instance with renewable and non-renewable operands, the
specialized HFNMCF, while producing similar schedules, yields explicit
explanations of the project states that enable richer monitoring and control.
Overall, the framework preserves the strengths of the classical RCPSP while
accommodating real-world constraints and enterprise-level decision processes
encountered in large, complex megaprojects.

</details>


### [86] [Docker-based CI/CD for Rocq/OCaml projects](https://arxiv.org/abs/2510.19089)
*Érik Martin-Dorel*

Main category: cs.SE

TL;DR: 介绍了三个与软件开发相关的项目，旨在推动基于Docker的CI/CD使用并帮助维护者理解设计。


<details>
  <summary>Details</summary>
Motivation: 促进Rocq（原Coq）或OCaml项目中Docker基础的CI/CD的使用。

Method: 通过开发docker-coq、docker-coq-action和docker-keeper三个工具，提供高层次功能描述及设计文档。

Result: 明确了这三个DevOps工具的功能和设计要求，有助于用户和未来的维护者。

Conclusion: 该工作提升了Docker CI/CD在相关项目中的应用并为维护者提供了参考。

Abstract: This paper presents three closely-related software projects, namely:
docker-coq, docker-coq-action, and docker-keeper. It aims at two objectives:
provide a high-level description of the available features -- to foster the use
of a Docker-based CI/CD for Rocq (formerly known as Coq) or OCaml projects --
and document the underlying requirements and the main design choices of these
three DevOps tools -- to help their future maintainers.

</details>


### [87] [Automated Concern Extraction from Textual Requirements of Cyber-Physical Systems: A Multi-solution Study](https://arxiv.org/abs/2510.19237)
*Dongming Jin,Zhi Jin,Xiaohong Chen,Zheng Fang,Linyu Li,Shengxin Zhao,Chuihui Wang,Hongbin Xiao*

Main category: cs.SE

TL;DR: 提出了ReqEBench，一个包含2721条真实世界CPS需求的新基准，用于自动提取需求关注点的效果评估。


<details>
  <summary>Details</summary>
Motivation: 当前CPS需求关注点提取自动化方案缺乏公平全面的基准进行效果评估。

Method: 构建包含12个真实CPS系统需求的ReqEBench基准，并对三类自动提取方案进行比较研究。

Result: GPT-4在实体关注点提取中最高F1仅0.24，揭示现有方案的不足和失败案例。

Conclusion: ReqEBench有助于推动CPS需求关注点自动提取方案的评估与改进。

Abstract: Cyber-physical systems (CPSs) are characterized by a deep integration of the
information space and the physical world, which makes the extraction of
requirements concerns more challenging. Some automated solutions for
requirements concern extraction have been proposed to alleviate the burden on
requirements engineers. However, evaluating the effectiveness of these
solutions, which relies on fair and comprehensive benchmarks, remains an open
question. To address this gap, we propose ReqEBench, a new CPSs requirements
concern extraction benchmark, which contains 2,721 requirements from 12
real-world CPSs. ReqEBench offers four advantages. It aligns with real-world
CPSs requirements in multiple dimensions, e.g., scale and complexity. It covers
comprehensive concerns related to CPSs requirements. It undergoes a rigorous
annotation process. It covers multiple application domains of CPSs, e.g.,
aerospace and healthcare. We conducted a comparative study on three types of
automated requirements concern extraction solutions and revealed their
performance in real-world CPSs using our ReqEBench. We found that the highest
F1 score of GPT-4 is only 0.24 in entity concern extraction. We further analyze
failure cases of popular LLM-based solutions, summarize their shortcomings, and
provide ideas for improving their capabilities. We believe ReqEBench will
facilitate the evaluation and development of automated requirements concern
extraction.

</details>


### [88] [A General Solution for the Implementation of CI/CD in Embedded Linux Development](https://arxiv.org/abs/2510.19240)
*Behnam Agahi,Hamed Farbeh*

Main category: cs.SE

TL;DR: 本论文设计并实现了基于Yocto项目的Linux嵌入式系统开发和测试自动化平台，提升了构建效率和系统复现性。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统需求增长，需自动化平台支持定制Linux操作系统的快速开发和部署。

Method: 构建三层架构（Yocto主仓库、自定义层、协调层），整合GitLab CI和Docker环境实现持续集成与部署，并利用本地缓存服务器缩短构建时间。

Result: 成功集成示例项目并通过QEMU六种启动测试验证系统功能和稳定性，证明设计具备良好复现性和扩展性。

Conclusion: 该设计为工业和科研嵌入式系统提供可扩展、稳定且高效的开发模型，未来可通过增加自动化测试、系统监控和分布式构建进一步优化。

Abstract: With the growing use of embedded systems in various industries, the need for
automated platforms for the development and deployment of customized
Linux-based operating systems has become more important. This research was
conducted with the aim of designing and implementing an integrated and
reproducible infrastructure for the development, building, and testing of a
Linux-based operating system using the Yocto Project. The proposed structure
was implemented based on a three-layer architecture consisting of the main
Yocto repositories, a custom layer (meta-custom), and a coordinating manifest
layer to ensure version synchronization, scalability, and reproducibility.
Three sample projects, including libhelloworld, helloworld, and the kernel
module hello mod, were developed and integrated into the build process.
Continuous Integration and Continuous Deployment pipelines were implemented
with GitLab CI and combined with an isolated Docker environment to automate and
streamline the build and testing workflows. Using a local cache server
containing hashserv, downloads and sstate cache significantly reduced the build
time. The functionality and stability of the system were verified through six
boot test scenarios in the QEMU simulator. The results show that the proposed
design not only ensures reproducibility but also can be extended to advanced
applications such as continuous deployment of real-time Linux versions. Future
recommendations include expanding automated tests, implementing system
monitoring with Prometheus and Grafana, using distributed builds, optimizing
with Docker multi-stage builds, and enabling continuous deployment of real-time
Linux changes to provide a stable and scalable model for industrial and
research projects in embedded systems with a rapid and reliable development
cycle.

</details>


### [89] [Trace: Securing Smart Contract Repository Against Access Control Vulnerability](https://arxiv.org/abs/2510.19254)
*Chong Chen,Jiachi Chen,Lingfeng Bao,David Lo,Yanlin Wang,Zhenyu Shan,Ting Chen,Guangqiang Yin,Jianxing Yu,Zibin Zheng*

Main category: cs.SE

TL;DR: TRACE是一种针对智能合约非可编译代码库中访问控制漏洞的检测工具，利用大语言模型补全代码并构建调用图进行漏洞分析，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 智能合约中的访问控制漏洞导致巨额损失，现有检测工具难以处理复杂且不可编译的代码库，迫切需要一种能够安全分析非可编译智能合约代码库的工具。

Method: TRACE利用大语言模型定位涉及关键操作的敏感函数，完成代码片段补全，使其可编译，从补全后的合同抽象语法树生成函数调用图，并通过控制流图节点分析访问控制漏洞。

Result: TRACE在公开CVE数据集上检测出14/15个漏洞，在5,000个链上合约中达89.2%精确率，远超现有最高76.9%，且在83个真实代码库中达到87.0%精确率，显著优于DeepSeek-R1的14.3%。

Conclusion: TRACE有效解决了非可编译智能合约代码库中访问控制漏洞检测的难题，显著提升检测准确率，具备较强实际应用价值。

Abstract: Smart contract vulnerabilities, particularly improper Access Control that
allows unauthorized execution of restricted functions, have caused billions of
dollars in losses. GitHub hosts numerous smart contract repositories containing
source code, documentation, and configuration files-these serve as intermediate
development artifacts that must be compiled and packaged before deployment.
Third-party developers often reference, reuse, or fork code from these
repositories during custom development. However, if the referenced code
contains vulnerabilities, it can introduce significant security risks. Existing
tools for detecting smart contract vulnerabilities are limited in their ability
to handle complex repositories, as they typically require the target contract
to be compilable to generate an abstract representation for further analysis.
This paper presents TRACE, a tool designed to secure non-compilable smart
contract repositories against access control vulnerabilities. TRACE employs
LLMs to locate sensitive functions involving critical operations (e.g.,
transfer) within the contract and subsequently completes function snippets into
a fully compilable contract. TRACE constructs a function call graph from the
abstract syntax tree (AST) of the completed contract. It uses the control flow
graph (CFG) of each function as node information. The nodes of the sensitive
functions are then analyzed to detect Access Control vulnerabilities.
Experimental results demonstrate that TRACE outperforms state-of-the-art tools
on an open-sourced CVE dataset, detecting 14 out of 15 CVEs. In addition, it
achieves 89.2% precision on 5,000 recent on-chain contracts, far exceeding the
best existing tool at 76.9%. On 83 real-world repositories, TRACE achieves
87.0% precision, significantly surpassing DeepSeek-R1's 14.3%.

</details>


### [90] [From Specification to Service: Accelerating API-First Development Using Multi-Agent Systems](https://arxiv.org/abs/2510.19274)
*Saurabh Chauhan,Zeeshan Rasheed,Malik Abdul Sami,Kai-Kristian Kemell,Muhammad Waseem,Zheying Zhang,Jussi Rasku,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 该论文提出了一种基于大语言模型的多智能体系统，实现RESTful微服务的API优先自动化开发。该系统通过创建OpenAPI规范、生成服务器代码和利用日志分析反馈循环优化代码，提高了开发效率和代码质量。


<details>
  <summary>Details</summary>
Motivation: 提升RESTful微服务的API优先开发自动化水平，验证基于大语言模型的多智能体系统在支持API优先开发中的能力。

Method: 系统利用大语言模型代理生成OpenAPI规范，基于规范生成服务器代码，并通过执行日志和错误信息分析的反馈循环不断修正和完善代码。

Result: 通过PRAB基准测试，结果表明当OpenAPI规范保持简洁和聚焦时，系统可生成符合规范的完整业务逻辑代码，实现功能完整性和鲁棒性。

Conclusion: 基于大语言模型的多智能体系统有效支持RESTful微服务的API优先开发，结合日志分析反馈能显著减少迭代次数，提升自动化开发效率，系统代码已开源。

Abstract: This paper presents a system that uses Large Language Models (LLMs)-based
agents to automate the API-first development of RESTful microservices. This
system helps to create an OpenAPI specification, generate server code from it,
and refine the code through a feedback loop that analyzes execution logs and
error messages. The integration of log analysis enables the LLM to detect and
address issues efficiently, reducing the number of iterations required to
produce functional and robust services. This study's main goal is to advance
API-first development automation for RESTful web services and test the
capability of LLM-based multi-agent systems in supporting the API-first
development approach. To test the proposed system's potential, we utilized the
PRAB benchmark. The results indicate that if we keep the OpenAPI specification
small and focused, LLMs are capable of generating complete functional code with
business logic that aligns to the specification. The code for the system is
publicly available at https://github.com/sirbh/code-gen

</details>


### [91] [Toward Agentic Software Engineering Beyond Code: Framing Vision, Values, and Vocabulary](https://arxiv.org/abs/2510.19692)
*Rashina Hoda*

Main category: cs.SE

TL;DR: 本文讨论了代理人工智能在软件工程领域的变革潜力，提出了扩大代理人工智能软件工程研究范围的建议。


<details>
  <summary>Details</summary>
Motivation: 代理人工智能即将带来软件工程的范式转变，现有研究多聚焦于代码层面，实际应用中需要考虑更多社会-技术因素。

Method: 提出将研究范围扩展至软件工程全过程，基于软件工程基础和新兴框架，制定初步价值观和原则，并提供统一术语的设计指导。

Result: 形成了代理人工智能软件工程的社区愿景和规范，促进社区合作，推动该领域的健康发展。

Conclusion: 希望通过建立坚实的理论基础，使代理人工智能软件工程不仅成为必然趋势，更是一种深思熟虑且可持续的选择。

Abstract: Agentic AI is poised to usher in a seismic paradigm shift in Software
Engineering (SE). As technologists rush head-along to make agentic AI a
reality, SE researchers are driven to establish agentic SE as a research area.
While early visions of agentic SE are primarily focused on code-related
activities, early empirical evidence calls for a consideration of a range of
socio-technical concerns to make it work in practice. This paper contributes to
the emerging community vision by: (a) recommending an expansion of its scope
beyond code, toward a 'whole of process' vision, grounding it in SE foundations
and evolution and emerging agentic SE frameworks, (b) proposing a preliminary
set of values and principles to guide efforts, and (c) sharing guidance on
designing/using well-defined vocabulary for agentic SE. It is hoped that these
ideas will encourage community collaborations and steer the SE community
towards laying strong foundations of agentic SE so its not only inevitable but
also deliberate and desirable in the long run.

</details>


### [92] [An Empirical Study of Bitwise Operators Intuitiveness through Performance Metrics](https://arxiv.org/abs/2510.19281)
*Shubham Joshi*

Main category: cs.SE

TL;DR: 本研究探讨了编程中位运算符的可读性和理解度，发现部分位运算符会影响任务完成时间。


<details>
  <summary>Details</summary>
Motivation: 研究不同编程背景的人对位运算符的理解差异及其对表现（反应时间和错误率）的影响。

Method: 采用被试内实验设计，让23名具有不同编程经验的参与者完成JavaScript位运算符任务，记录完成时间和正确率。

Result: 部分运算符（如OR、NOT、左移）在任务完成时间上存在显著差异，运算符是预测反应时间的因素之一。

Conclusion: 位运算符复杂性总体未显著延长完成时间，但某些运算符较难理解，需进一步研究和可能的重新设计以提升易懂性。

Abstract: Objectives: This study aims to investigate the readability and
understandability of bitwise operators in programming, with the main hypothesis
that there will be a difference in the performance metrics (response time and
error rate) between participants exposed to various bitwise operators related
questions and those who are not.
  Participants: Participants in this human research study include people
without programming background, novice programmers, and university students
with varying programming experience (from freshmen to PhD level). There were 23
participants for this study.
  Study Methods: This study uses an Within-Subjects Experimental Design to
assess how people with diverse programming backgrounds understand and use
bitwise operators. Participants complete tasks in JavaScript program, and their
task completion time and accuracy of the tasks are recorded for analysis.
  Findings: The results indicate that operators can be one of the factors
predicting response time, with a small but significant effect, with R-squared
0.032, (1, 494) = 16.5, p < .001. Additionally, some operators like OR, NOT,
and Left Shift showed statistical significance in task completion times
compared to other operators.
  Conclusions: While the complexity of bitwise operators did not generally
result in longer task completion times, certain operators were found to be less
intuitive, suggesting the need for further investigation and potential redesign
for improved understandability.

</details>


### [93] [Bytecode-centric Detection of Known-to-be-vulnerable Dependencies in Java Projects](https://arxiv.org/abs/2510.19393)
*Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Jonas Klauke,Eric Bodden*

Main category: cs.SE

TL;DR: Java项目中大量依赖开源软件（OSS），带来安全风险。现有依赖扫描工具在处理依赖修改时存在挑战。Jaralyzer通过字节码分析，有效检测修改后的依赖漏洞，优于现有工具。


<details>
  <summary>Details</summary>
Motivation: Java项目高度依赖OSS，容易引入安全漏洞，且现有扫描工具难以识别经过修改（重编译、重打包等）的OSS依赖中的漏洞。

Method: 提出基于字节码的依赖扫描工具Jaralyzer，无需依赖元数据或源码，直接分析字节码，提升对修改依赖的漏洞识别能力。

Result: 在56个流行OSS组件中，Jaralyzer在检测修改依赖漏洞方面优于主流扫描器，能识别所有类型的依赖修改漏洞，且在未修改依赖检测中比Eclipse Steady表现更佳。

Conclusion: Jaralyzer有效解决了Java依赖扫描中对修改依赖的检测不足，显著提升了漏洞检测的准确率和覆盖率。

Abstract: On average, 71% of the code in typical Java projects comes from open-source
software (OSS) dependencies, making OSS dependencies the dominant component of
modern software code bases. This high degree of OSS reliance comes with a
considerable security risk of adding known security vulnerabilities to a code
base. To remedy this risk, researchers and companies have developed various
dependency scanners, which try to identify inclusions of known-to-be-vulnerable
OSS dependencies. However, there are still challenges that modern dependency
scanners do not overcome, especially when it comes to dependency modifications,
such as re-compilations, re-bundlings or re-packagings, which are common in the
Java ecosystem. To overcome these challenges, we present Jaralyzer, a
bytecode-centric dependency scanner for Java. Jaralyzer does not rely on the
metadata or the source code of the included OSS dependencies being available
but directly analyzes a dependency's bytecode. Our evaluation across 56 popular
OSS components demonstrates that Jaralyzer outperforms other popular dependency
scanners in detecting vulnerabilities within modified dependencies. It is the
only scanner capable of identifying vulnerabilities across all the above
mentioned types of modifications. But even when applied to unmodified
dependencies, Jaralyzer outperforms the current state-of-the-art code-centric
scanner Eclipse Steady by detecting 28 more true vulnerabilities and yielding
29 fewer false warnings.

</details>


### [94] [AutoMT: A Multi-Agent LLM Framework for Automated Metamorphic Testing of Autonomous Driving Systems](https://arxiv.org/abs/2510.19438)
*Linfeng Liang,Chenkai Tan,Yao Deng,Yingfeng Cai,T. Y Chen,Xi Zheng*

Main category: cs.SE

TL;DR: 提出AutoMT，一个利用大型语言模型自动提取变形关系并生成测试用例的自动化多智能体元测试框架，显著提升自动驾驶系统的测试多样性和缺陷检测能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的元测试方法依赖大量手工定义的变形关系，自动化程度低，难以覆盖复杂多变的交通场景。

Method: AutoMT通过大型语言模型自动从本地交通规则中提取变形关系，结合视觉语言代理分析场景，利用基于检索增强生成(RAG)的数据库选择合适的变形关系，通过计算机视觉生成有效的后续测试用例。

Result: 实验表明，AutoMT在后续用例生成的测试多样性上比最优手工基线提升5倍，行为违规检测率提高20.55%。

Conclusion: AutoMT自动提取多样化变形关系，增强现实数据集，发现常规测试易遗漏的边缘案例，模块化设计便于工业集成和模拟测试，提升自动驾驶系统的安全测试效率和覆盖率。

Abstract: Autonomous Driving Systems (ADS) are safety-critical, where failures can be
severe. While Metamorphic Testing (MT) is effective for fault detection in ADS,
existing methods rely heavily on manual effort and lack automation. We present
AutoMT, a multi-agent MT framework powered by Large Language Models (LLMs) that
automates the extraction of Metamorphic Relations (MRs) from local traffic
rules and the generation of valid follow-up test cases. AutoMT leverages LLMs
to extract MRs from traffic rules in Gherkin syntax using a predefined
ontology. A vision-language agent analyzes scenarios, and a search agent
retrieves suitable MRs from a RAG-based database to generate follow-up cases
via computer vision. Experiments show that AutoMT achieves up to 5 x higher
test diversity in follow-up case generation compared to the best baseline
(manual expert-defined MRs) in terms of validation rate, and detects up to
20.55% more behavioral violations. While manual MT relies on a fixed set of
predefined rules, AutoMT automatically extracts diverse metamorphic relations
that augment real-world datasets and help uncover corner cases often missed
during in-field testing and data collection. Its modular architecture
separating MR extraction, filtering, and test generation supports integration
into industrial pipelines and potentially enables simulation-based testing to
systematically cover underrepresented or safety-critical scenarios.

</details>


### [95] [Mapping and Evolving Interoperability Testing in European Energy Systems: The int:net Perspective](https://arxiv.org/abs/2510.19460)
*Thomas I. Strasser,Edmund Widl,Carlos Ayon Mac Gregor,Mirko Ginocchi,Rene Kuchenbuch*

Main category: cs.SE

TL;DR: 本文分析了欧洲互操作性测试设施，通过对30个设施的调查提供测试基础设施分类目录，方法论和参考测试案例，提出未来测试环境蓝图，促进能源转型目标下的互操作性测试生态系统建设。


<details>
  <summary>Details</summary>
Motivation: 欧洲能源转型需要多样组件和系统高度互操作，现有智能电网测试设施缺乏全面的互操作性测试关注和协调综述。

Method: 对欧洲30个互操作性测试设施进行结构化调查，分类测试基础设施、方法及测试案例，并提出未来测试环境的设计蓝图。

Result: 形成了一个分类清晰、方法多样、案例具体的欧洲互操作性测试设施清单，并设计了未来测试设施的发展蓝图。

Conclusion: 该研究推动构建协调一致的欧洲互操作性测试生态系统，促进能源转型过程中测试协作和创新。

Abstract: The ongoing transformation of the European energy landscape, driven by the
integration of renewable energy sources, digital technologies, and
decentralized systems, requires a high degree of interoperability across
diverse components and systems. Ensuring that these elements can exchange
information and operate together reliably is essential for achieving a secure,
flexible, and efficient energy supply infrastructure. While several initiatives
have contributed to the development of smart grid testing infrastructures, they
do not provide a dedicated or comprehensive focus on interoperability testing.
A structured and harmonized overview of interoperability testing capabilities
across Europe is therefore still missing. This work therefore presents a novel
contribution by analyzing the European interoperability testing facility
landscape through a structured survey of 30 facilities. It provides a
categorized inventory of testing infrastructures, applied methodologies, and
reference test cases, and introduces a blueprint for the development of future
testing environments. The findings contribute to the establishment of a
coordinated European ecosystem for interoperability testing, supporting
collaboration, innovation, and alignment with the goals of the energy
transition.

</details>


### [96] [A Goal-Driven Survey on Root Cause Analysis](https://arxiv.org/abs/2510.19593)
*Aoyang Fang,Haowen Yang,Haoze Dong,Qisheng Lu,Junjielong Xu,Pinjia He*

Main category: cs.SE

TL;DR: 本文提出了一种基于目标的云服务故障根因分析（RCA）文献分类框架，整合了135篇相关论文，揭示了不同RCA任务目标的差异，弥补了以往基于输入数据类型分类的不足。


<details>
  <summary>Details</summary>
Motivation: 当前RCA文献调查多依赖输入数据类型而忽视任务目标差异，导致研究进展和不足被掩盖，且无法满足不同读者的需求，因此需要一种基于任务目标的分类方法。

Method: 提出目标驱动的框架，按照不同的RCA任务目标对135篇文献进行分类和整合，强调了所有RCA任务的终极目标并讨论未来挑战。

Result: 成功构建了依据任务目标分类的RCA文献框架，明确了不同研究的任务定位和研究进展，提升了RCA领域文献的理解和梳理，提出了开放问题和未来方向。

Conclusion: 基于目标的RCA文献分类框架有效弥补了传统方法的缺陷，为研究者和实践者提供了清晰的任务理解和研究路径，提示未来研究应关注多样化任务目标及其挑战。

Abstract: Root Cause Analysis (RCA) is a crucial aspect of incident management in
large-scale cloud services. While the term root cause analysis or RCA has been
widely used, different studies formulate the task differently. This is because
the term "RCA" implicitly covers tasks with distinct underlying goals. For
instance, the goal of localizing a faulty service for rapid triage is
fundamentally different from identifying a specific functional bug for a
definitive fix. However, previous surveys have largely overlooked these
goal-based distinctions, conventionally categorizing papers by input data types
(e.g., metric-based vs. trace-based methods). This leads to the grouping of
works with disparate objectives, thereby obscuring the true progress and gaps
in the field. Meanwhile, the typical audience of an RCA survey is either laymen
who want to know the goals and big picture of the task or RCA researchers who
want to figure out past research under the same task formulation. Thus, an RCA
survey that organizes the related papers according to their goals is in high
demand. To this end, this paper presents a goal-driven framework that
effectively categorizes and integrates 135 papers on RCA in the context of
cloud incident management based on their diverse goals, spanning the period
from 2014 to 2025. In addition to the goal-driven categorization, it discusses
the ultimate goal of all RCA papers as an umbrella covering different RCA
formulations. Moreover, the paper discusses open challenges and future
directions in RCA.

</details>


### [97] [Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1](https://arxiv.org/abs/2510.19600)
*Qianli Ma,Siyu Wang,Yilin Chen,Yinhao Tang,Yixiang Yang,Chang Guo,Bingjie Gao,Zhening Xing,Yanan Sun,Zhipeng Zhang*

Main category: cs.SE

TL;DR: AutoPage是一个多代理系统，自动将科研论文转化为交互式网页，提升科研交流效率。


<details>
  <summary>Details</summary>
Motivation: 科研人员在构建项目网页以传播研究成果时，面临手动且重复的工作，且现有自动化工具难以处理动态交互网页。

Method: 提出多代理系统AutoPage，通过分层流水线从叙事规划到多模态内容生成及交互渲染，同时引入Checker代理核对信息，辅以人工检查保证成果准确。

Result: AutoPage在15分钟内以低成本生成高质量、视觉吸引力强的科研网页。还构建了首个相关任务基准PageBench进行验证。

Conclusion: AutoPage不仅作为工具，更是科研网页制作的协作助手，显著提升网页生成效率和质量。

Abstract: In the quest for scientific progress, communicating research is as vital as
the discovery itself. Yet, researchers are often sidetracked by the manual,
repetitive chore of building project webpages to make their dense papers
accessible. While automation has tackled static slides and posters, the
dynamic, interactive nature of webpages has remained an unaddressed challenge.
To bridge this gap, we reframe the problem, arguing that the solution lies not
in a single command, but in a collaborative, hierarchical process. We introduce
$\textbf{AutoPage}$, a novel multi-agent system that embodies this philosophy.
AutoPage deconstructs paper-to-page creation into a coarse-to-fine pipeline
from narrative planning to multimodal content generation and interactive
rendering. To combat AI hallucination, dedicated "Checker" agents verify each
step against the source paper, while optional human checkpoints ensure the
final product aligns perfectly with the author's vision, transforming the
system from a mere tool into a powerful collaborative assistant. To rigorously
validate our approach, we also construct $\textbf{PageBench}$, the first
benchmark for this new task. Experiments show AutoPage not only generates
high-quality, visually appealing pages but does so with remarkable efficiency
in under 15 minutes for less than \$0.1. Code and dataset will be released at
$\href{https://mqleet.github.io/AutoPage_ProjectPage/}{Webpage}$.

</details>


### [98] [FidelityGPT: Correcting Decompilation Distortions with Retrieval Augmented Generation](https://arxiv.org/abs/2510.19615)
*Zhiping Zhou,Xiaohong Li,Ruitao Feng,Yao Zhang,Yuekang Li,Wenbu Feng,Yunqian Wang,Yuqing Li*

Main category: cs.SE

TL;DR: FidelityGPT通过检测和修正语义失真，显著提升了反编译代码的准确性和可读性。


<details>
  <summary>Details</summary>
Motivation: 现有反编译技术在处理复杂闭源二进制代码时，存在语义失真和可读性差的问题，缺乏有效的检测和纠正方法。

Method: 提出FidelityGPT框架，结合失真感知的提示模板、检索增强生成（RAG）方法和语义强度动态算法，定位并纠正失真代码；采用变量依赖算法降低长上下文限制。

Result: 在二进制相似性基准的620个函数对上，FidelityGPT实现89%的检测准确率和83%的精度，修复率和正确修复率均优于现有最好方法DeGPT。

Conclusion: FidelityGPT显著提升了基于大模型的反编译代码的语义准确性和可读性，推动了反向工程技术的发展。

Abstract: Decompilation converts machine code into human-readable form, enabling
analysis and debugging without source code. However, fidelity issues often
degrade the readability and semantic accuracy of decompiled output. Existing
methods, such as variable renaming or structural simplification, provide
partial improvements but lack robust detection and correction, particularly for
complex closed-source binaries. We present FidelityGPT, a framework that
enhances decompiled code accuracy and readability by systematically detecting
and correcting semantic distortions. FidelityGPT introduces distortion-aware
prompt templates tailored to closed-source settings and integrates
Retrieval-Augmented Generation (RAG) with a dynamic semantic intensity
algorithm to locate distorted lines and retrieve semantically similar code from
a database. A variable dependency algorithm further mitigates long-context
limitations by analyzing redundant variables and integrating their dependencies
into the prompt context. Evaluated on 620 function pairs from a binary
similarity benchmark, FidelityGPT achieved an average detection accuracy of 89%
and a precision of 83%. Compared to the state-of-the-art DeGPT (Fix Rate 83%,
Corrected Fix Rate 37%), FidelityGPT attained 94% FR and 64% CFR, demonstrating
significant gains in accuracy and readability. These results highlight its
potential to advance LLM-based decompilation and reverse engineering.

</details>


### [99] [Review of Tools for Zero-Code LLM Based Application Development](https://arxiv.org/abs/2510.19747)
*Priyaranjan Pattnayak,Hussain Bohra*

Main category: cs.SE

TL;DR: 本文综述了利用大型语言模型(LLMs)支持的零代码开发平台，分析了这些平台的界面风格、后台集成、输出类型和可扩展性，比较了专用LLM应用构建器与通用无代码平台的优劣，探讨了灵活性与可靠性等挑战，并展望了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，零代码平台能使非程序员轻松创建软件，但不同平台功能差异大，灵活性和可靠性仍然是瓶颈，亟需系统性总结和比较。

Method: 通过广泛调研，按界面类型、LLM后台、输出形式、可扩展性等维度对市面上各种LLM驱动的零代码平台进行分类和比较，分析核心功能及其优缺点。

Result: 构建了详细的分类体系，展示了各平台在自主代理、内存管理、工作流编排和API集成方面的表现，揭示了个性化、扩展性、供应商锁定等方面的权衡。

Conclusion: 零代码LLM平台大幅降低了AI应用开发门槛，但在灵活性和稳定性上仍需改进。未来多模态界面、设备端LLM和更好的编排机制将推动应用民主化，促进非程序员创造复杂软件。

Abstract: Large Language Models (LLMs) are transforming software creation by enabling
zero code development platforms. Our survey reviews recent platforms that let
users build applications without writing code, by leveraging LLMs as the brains
of the development process. We adopt a broad survey methodology, categorizing
platforms based on key dimensions such as interface style, backend integration,
output type, and extensibility. We analyze both dedicated LLM based app
builders (OpenAI's custom GPTs, Bolt.new, Dust.tt, Flowise, Cognosys) and
general no code platforms (e.g., Bubble, Glide) that integrate LLM
capabilities. We present a taxonomy categorizing these platforms by their
interface (conversational, visual, etc.), supported LLM backends, output type
(chatbot, full application, workflow), and degree of extensibility. Core
features such as autonomous agents, memory management, workflow orchestration,
and API integrations are in scope of the survey. We provide a detailed
comparison, highlighting each platform's strengths and limitations. Trade offs
(customizability, scalability, vendor lock-in) are discussed in comparison with
traditional and low code development approaches. Finally, we outline future
directions, including multimodal interfaces, on device LLMs, and improved
orchestration for democratizing app creation with AI. Our findings indicate
that while zero code LLM platforms greatly reduce the barrier to creating AI
powered applications, they still face challenges in flexibility and
reliability. Overall, the landscape is rapidly evolving, offering exciting
opportunities to empower non programmers to create sophisticated software.

</details>


### [100] [BOSQTGEN: Breaking the Sound Barrier in Test Generation](https://arxiv.org/abs/2510.19777)
*S M Sadrul Islam Asif,James Chen,Earl T. Barr,Mark Marron*

Main category: cs.SE

TL;DR: 本文提出了BOSQTGEN，一种基于黑盒的API测试生成方法，利用LLM和组合测试，有效生成结构化输入，提高测试覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现代软件依赖API组合，但API合约不充分导致测试困难，特别是结构化输入生成难题。因此，亟需一种高效的黑盒API测试生成方法。

Method: BOSQTGEN通过将API规范分解为基本单元，利用大语言模型(LLM)建议分层结构，结合组合测试策略高效采样生成测试用例，保证关键交互覆盖且避免随机采样冗余。

Result: BOSQTGEN在RESTful基准测试中平均覆盖率达82%，比之前方法提升20%以上，接近手写测试套件的覆盖水平。

Conclusion: BOSQTGEN实现了全API驱动的测试生成，为开发者自动创建高质量测试用例提供了有效工具，促进了API合约的验证与测试驱动开发。

Abstract: Modern software is increasingly built by composing APIs, elevating the API
contract to a critical role. Inadequate contracts, however, lead to mismatched
expectations and failures, creating a pressing need for robust conformance
testing. Current test generation techniques are hindered by key challenges:
polyglot systems, source code inaccessibility, a cost-reliability trade-off,
and, most critically, the difficulty of generating structured inputs.
  We introduce BOSQTGEN, a novel black-box methodology and tool for API test
generation. BOSQTGEN utilizes a novel approach for decomposing API
specifications into primitives, using LLMs to suggest coherent strata for them,
and employing combinatorial testing to efficiently sample over these values.
This approach ensures coverage of critical interactions while avoiding the
redundancy of random sampling.
  The resulting BOSQTGEN system achieves an average of 82% code coverage on
RESTful benchmarks, often a 20% or more increase over prior state-of-the-art
systems and nearing parity with hand-written test suites. Providing a fully
API-driven approach to test generation, enables developers to automatically
create high-quality test cases for validation or test-driven development.

</details>
