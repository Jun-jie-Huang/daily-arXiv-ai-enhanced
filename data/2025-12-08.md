<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 29]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.MA](#cs.MA) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale](https://arxiv.org/abs/2512.05179)
*Aurélie Montfrond*

Main category: cs.CL

TL;DR: 本研究通过微调BERT模型，基于自建大学课程问答数据集，实现了有效的领域特定问答系统，助力高校教育问答自动化。


<details>
  <summary>Details</summary>
Motivation: 当前科学问答系统多注重聊天机器人风格，尚未充分开发针对特定领域推理的基础模型微调方法。

Method: 针对利默里克大学电子与计算机工程系，构建了1203条问答对数据集，基于SQuAD格式，结合手动和合成数据，利用PyTorch微调BERT模型，评估指标为Exact Match和F1分数。

Result: 经过微调的BERT在假设构建和知识提取方面表现提升，证明了将基础模型适应于教育领域的可行性。

Conclusion: 该研究填补了针对大学课程资料的基础模型微调空白，展示了以学术问答对微调BERT获得有效结果的可能，推动了面向高校的领域特定问答模型和自主教育知识系统的发展。

Abstract: Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.

</details>


### [2] [Unveiling Affective Polarization Trends in Parliamentary Proceedings](https://arxiv.org/abs/2512.05231)
*Gili Goldin,Ella Rabinovich,Shuly Wintner*

Main category: cs.CL

TL;DR: 本文提出一种新颖的基于情感风格的两极化量化方法，实证显示以色列议会的情感两极化正在加剧。


<details>
  <summary>Details</summary>
Motivation: 针对全球范围内日益增加的极化话语，提出不同于传统意识形态差异的方法，通过情感风格来衡量两极分化。

Method: 基于情感风格的两极化量化方法，通过衡量情绪的价（Valence）、唤醒度（Arousal）和支配感（Dominance）来检测情感话语信号。

Result: 以以色列议会Knesset的议事记录为数据，发现执政党成员与反对党成员在情感风格上存在显著差异，且情感两极化水平随时间显著增加。

Conclusion: 情感风格能够有效反映政治话语的两极化，且这种基于情绪的两极化在实际政治 discourse 中有显著上升趋势。

Abstract: Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.

</details>


### [3] [Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting](https://arxiv.org/abs/2512.05243)
*P. D. Edgar,Alia Hall*

Main category: cs.CL

TL;DR: 该研究提出诗歌提示模式作为提示工程的新工具，通过诗歌提示评估和分析了大型语言模型对原创创作的适应和改写能力。


<details>
  <summary>Details</summary>
Motivation: 探究诗歌提示模式在提示工程中的应用，帮助揭示大型语言模型的算法偏见和创造力边界。

Method: 通过使用诗歌提示模式进行创意文本提示，研究语言模型的适应性和倾向。

Result: 利用诗歌提示对三种知名诗人模型进行了描述和评估，测试了模型为预期受众改写原创作品的能力和意愿。

Conclusion: 诗歌提示模式在提示工程中具有潜力，可用于深入理解和利用语言模型的创造力及其调整原创作品的能力。

Abstract: Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.

</details>


### [4] [Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4](https://arxiv.org/abs/2512.05256)
*Ivan Makohon,Mohamad Najafi,Jian Wu,Mathias Brochhausen,Yaohang Li*

Main category: cs.CL

TL;DR: 本文通过结合多种提示技术和临床知识图谱，利用GPT-4成功提升了自动生成电子健康记录中临床笔记的效果，缓解医生手动书写负担。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中自由文本的临床笔记撰写耗时长，影响医生工作效率，亟需自动化高质量生成临床笔记的方法。

Method: 利用患者基本信息和ICD编码作为输入，结合CoT提示和语义搜索结果，并通过临床知识图谱增强领域知识，指导GPT-4生成临床笔记。

Result: 在CodiEsp测试集的六个临床案例中，所提方法生成的临床笔记质量明显优于标准的一次性提示生成结果。

Conclusion: 结合Chain-of-Thought提示工程、语义搜索和临床知识图谱，有效提升了大语言模型(GPT-4)生成临床笔记的质量，优于传统单步提示方法。

Abstract: In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.

</details>


### [5] [To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples](https://arxiv.org/abs/2512.05318)
*Vignesh Kothapalli,Ata Fatahibaarzi,Hamed Firooz,Maziar Sanjabi*

Main category: cs.CL

TL;DR: 本文提出了CoT-Recipe，通过调节元训练中链式思维提示示例的比例，显著提升大模型在新任务中的推理能力，即使缺少CoT示例也能取得高效表现。


<details>
  <summary>Details</summary>
Motivation: CoT结合ICL虽提升大语言模型的推理能力，但在缺乏预训练知识的新任务上效果不佳，且过多CoT示例反而降低有限CoT监督下的性能。

Method: 在一个受控环境下使用CoT-ICL Lab框架，对链式思维提示（CoT）结合少量示例的上下文学习（ICL）进行元训练，提出CoT-Recipe方法来调节元训练中CoT与非CoT示例的比例。

Result: 通过CoT-Recipe调节CoT与非CoT示例混合，使变换器模型在新任务上准确度提升最多300%，在没有CoT示例的情况下仍有显著提升，并在预训练的Qwen2.5系列语言模型的符号推理任务中获得最高130%的准确率增益。

Conclusion: 适当调节CoT与非CoT示例在元训练中的比例，有效提升了大语言模型在新推理任务中的表现，证明了CoT-Recipe方法的广泛适用性和效果。

Abstract: Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.

</details>


### [6] [LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning](https://arxiv.org/abs/2512.05325)
*Ömer Faruk Akgül,Yusuf Hakan Kalaycı,Rajgopal Kannan,Willie Neiswanger,Viktor Prasanna*

Main category: cs.CL

TL;DR: LYNX是一种利用模型隐藏态自信度实现在线早期退出的机制，有效减少推理计算，提升效率和准确度，且具有良好的跨任务泛化能力。它无需辅助模型，提供明确定制的置信度保证，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型为了完成复杂任务常常进行过度推理（"overthink"），导致计算资源浪费和准确性下降。现有早期退出方法存在依赖额外模型、经验性启发式或缺乏形式保证的问题，因此需要一种高效、可控且无需辅助模型的早期退出策略。

Method: LYNX在生成过程中检测自然出现的推理提示词（如“hmm”、“wait”），并训练一个轻量级探针来判断何时可以停止推理。通过使用分割符合预测（split conformal prediction）来控制提前退出，确保退出决策的置信度。同时该探针在数学语料上训练一次后即可应用于不同任务，无需额外辅助模型。

Result: 在三个不同规模的模型和多种基准任务（数学题和常识问答）上，LYNX实现了40%-70%的推理token减少，同时准确率保持不降甚至提升。它在数学及非数学任务均表现出优异的准确率-效率权衡，优于现有早期退出方法，并且能在线运行，无需后期处理。

Conclusion: LYNX通过利用模型自身的隐藏状态，实现了一种在线早期退出机制，有效减少推理时间和计算资源消耗，同时保持甚至提升了推理准确性。该方法具有较强的泛化能力，能跨多种任务和模型稳定发挥效果。

Abstract: Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often "overthink": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., "hmm", "wait") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.

</details>


### [7] [Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats](https://arxiv.org/abs/2512.05331)
*Sadat Shahriar,Navid Ayoobi,Arjun Mukherjee,Mostafa Musharrat,Sai Vishnu Vamsi*

Main category: cs.CL

TL;DR: 本文研究了低质量自动生成的“粉肉新闻”对地方新闻的威胁，分析其语言和风格特征，提出检测策略，并探讨了大语言模型带来的攻击挑战，设计了抗攻击的鲁棒学习框架。


<details>
  <summary>Details</summary>
Motivation: 地方新闻是重要可靠信息源，但遭受低质量自动生成新闻的威胁，尤其是利用大型语言模型改写内容。需要新的检测与防护方法保障新闻真实性。

Method: 通过细粒度的语言、风格和词汇特征分析，结合鲁棒学习框架，增强检测系统对自动生成新闻及其对抗样本的识别能力。

Result: 提出的鲁棒学习框架在抵御基于大语言模型的对抗攻击时，检测性能提升最高达27%，有效缓解现有系统40%的性能下降问题。

Conclusion: 通过对‘粉肉新闻’的特征分析和检测方法设计，本文成功提升了检测性能，并有效抵御了大语言模型带来的对抗性攻击。

Abstract: The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.

</details>


### [8] [Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change](https://arxiv.org/abs/2512.05364)
*Ananth Hariharan,David Mortensen*

Main category: cs.CL

TL;DR: 利用弱监督神经符号方法，成功揭示梵语形态复杂性的动态演变与分布，模型准确且可解释。


<details>
  <summary>Details</summary>
Motivation: 打破语言简化的刻板印象，量化分析形态丰富且资源匮乏的梵语历时演变，解决低资源语言数据稀缺的问题。

Method: 采用弱监督混合神经符号方法，利用100+高精度正则表达式生成伪标签，微调多语言BERT模型，并通过新颖的置信度加权集成融合符号与神经输出。

Result: 在147万字的历时语料库上，集成模型实现52.4%的整体特征检测率。梵语的形态复杂性非减少而是动态重分布，动词特征周期性下降，但词汇合成和哲学术语显著扩展。系统产出的不确定性估计准确，置信度与准确性高度相关（Pearson r=0.92），校准误差低（ECE=0.043）。

Conclusion: 该方法有效应对低资源语言的演变分析，证明语言复杂性演变不是简化，而是形态特征的动态转移，提升了计算语言学研究的可靠性和解释能力。

Abstract: This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.

</details>


### [9] [Mitigating Self-Preference by Authorship Obfuscation](https://arxiv.org/abs/2512.05379)
*Taslim Mahbub,Shi Feng*

Main category: cs.CL

TL;DR: 研究语言模型评审中的自我偏好问题，提出通过扰动文本降低模型自我识别能力以缓解偏好，但完全消除仍困难。


<details>
  <summary>Details</summary>
Motivation: 语言模型评审广泛用于评价模型质量，但存在自我偏好偏见，影响评估公正性，亟需寻找有效减轻该偏好的方法。

Method: 对评估候选文本施加黑盒扰动（如同义词替换），通过混淆作者身份减少模型的自我识别能力，降低自我偏好。

Result: 本文研究了语言模型（LM）评审在自身偏好上的偏见问题，即模型偏好自身生成的答案而非其他模型或人类的答案。作者通过对比评估候选输出时，采用黑盒扰动（如同义词替换）来混淆答案作者身份，从而减弱自我识别能力以降低自我偏好。实验发现简单的扰动可以有效减轻自体偏好，但在进一步完全中和候选输出风格差异时，自我偏好又复现，说明自我识别和偏好存在多层次的语义基础，完全消除仍具挑战。

Conclusion: 自我偏好由多层语义因素导致，简单扰动虽能减轻偏见，但完全消除该偏好仍面临挑战。

Abstract: Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.

</details>


### [10] [Learning from Self Critique and Refinement for Faithful LLM Summarization](https://arxiv.org/abs/2512.05387)
*Ting-Yao Hu,Hema Swetha Koppula,Hadi Pouransari,Cem Koc,Oncel Tuzel,Raviteja Vemulapalli*

Main category: cs.CL

TL;DR: 本文提出SCRPO方法，通过自我批评和偏好学习提升大语言模型摘要的真实性，效果优于现有方法且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有减少大语言模型幻觉的方法依赖额外的测试时计算资源或更强的教师模型，成本高且不实用，因而需要一种更高效且实用的方法。

Method: 提出了基于自我批评和精炼的偏好优化训练框架（SCRPO），通过利用大语言模型自身的批评和精炼能力构建偏好数据集，再进行偏好学习以提升模型在摘要任务中的真实性。

Result: 在三个摘要基准（XSUM、CNNDM和SAMSum）上的实验表明，SCRPO在真实性评价指标上优于最先进的自监督学习方法，同时保持或提升了摘要质量的其他指标。相比测试时精炼，SCRPO不仅提升了效率，还生成了更真实的摘要。

Conclusion: SCRPO是一种高效且实用的自我监督训练框架，能够显著提升大语言模型在长文本生成中摘要的真实性和整体质量，优于现有依赖外部模型或高计算资源的方法。

Abstract: Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.

</details>


### [11] [SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs](https://arxiv.org/abs/2512.05409)
*Ruixuan Huang,Hao Zeng,Hantao Huang,Jinyuan Shi,Minghui Yu,Ian En-Hsu Yen,Shuai Wang*

Main category: cs.CL

TL;DR: 本文提出的SQ-format统一数据格式有效结合了量化和稀疏技术，提升了计算性能与准确率的平衡，并为新硬件设计提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有的低位宽量化和稀疏技术难以在准确率和效率之间取得平衡，且硬件支持有限，无法充分发挥量化和稀疏的优势。

Method: 提出了一种名为Sparse-Quantized Format（SQ-format）的统一数据格式，将量化和稀疏技术结合，提升计算效率和硬件支持的兼容性。

Result: SQ-format实现了性能和吞吐量上的帕累托改进，特别适用于具有异常值分布的激活数据，能够实现静态压缩并取得了先进的后训练量化（PTQ）性能。

Conclusion: SQ-format能够促进量化与稀疏技术的高效结合，推动下一代AI加速器设计，增强大语言模型的后训练量化效果和硬件适配性。

Abstract: Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.

</details>


### [12] [LMSpell: Neural Spell Checking for Low-Resource Languages](https://arxiv.org/abs/2512.05414)
*Akesh Gunathilakea,Nadil Karunarathnea,Tharusha Bandaranayakea,Nisansa de Silvaa,Surangika Ranathunga*

Main category: cs.CL

TL;DR: 本文首次系统比较了各种预训练语言模型在拼写纠错上的表现，发现大型语言模型在大数据情况下效果最佳，并发布了多语言拼写纠错工具LMSpell。


<details>
  <summary>Details</summary>
Motivation: 当前低资源语言的拼写纠错仍面临挑战，且预训练语言模型的应用和效果尚无系统比较，本文旨在填补该领域空白，提升低资源语言拼写纠错的效果与工具支持。

Method: 通过对比分析不同类型的预训练语言模型（大型语言模型、编码器和编码器-解码器模型）在拼写纠错任务上的性能表现，并进行实际语言案例研究，开发并发布了一个拼写纠错工具包LMSpell以便评估和应用。

Result: 本文首次系统性评估了预训练语言模型（PLMs）在拼写纠错任务中的有效性，尤其针对低资源语言（LRLs）。研究发现，当微调数据量充足时，大型语言模型（LLMs）在拼写纠错表现上优于编码器及编码器-解码器模型，即使在LLM未预训练的语言上亦然。本文还发布了LMSpell拼写纠错工具包，支持多种PLMs，并包含针对LLM生成假信息的评估功能。此外，通过僧伽罗语案例研究，揭示了低资源语言拼写纠错的挑战。

Conclusion: 大型语言模型在拼写纠错任务中表现优越，尤其是在数据充足时，并且此优势也适用于未被预训练的语言，LMSpell工具包为低资源语言的拼写纠错提供了有效支持。

Abstract: Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.

</details>


### [13] [ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering](https://arxiv.org/abs/2512.05430)
*Daeyong Kwon,SeungHeon Doh,Juhan Nam*

Main category: cs.CL

TL;DR: 本论文构建了大规模音乐向量数据库MusWikiDB和音乐问答基准ArtistMus，应用检索增强生成技术显著提升音乐问答的准确率和推理能力，推动音乐领域的知识型问答研究发展。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在开放域问答表现突出，但在音乐相关推理中效果有限，原因是预训练数据中缺乏音乐知识。音乐信息检索和计算音乐学虽涉及结构化和多模态理解，但缺乏支持基于艺术家元数据和历史背景的音乐问答资源。

Method: 提出MusWikiDB，一个包含320万段落、自144K音乐相关维基百科页面构建的向量数据库；并提出ArtistMus，一个包含1000个问题、涵盖500位多样化艺术家的基准测试集，配备流派、出道年份、主题等元数据。利用检索增强生成（RAG）模型进行音乐问答的系统评估，同时采用RAG风格的微调改进模型性能。

Result: 实验表明，RAG显著提升了音乐问答的事实准确率，开源模型表现提升最高达56.8个百分点（例如Qwen3 8B从35.0提升到91.8），接近专有模型水平。RAG风格微调进一步提升了事实回忆和上下文推理能力，在域内和域外基准测试均有改善。MusWikiDB的准确率比通用维基百科语料高约6个百分点，检索速度快40%。

Conclusion: MusWikiDB和ArtistMus资源的发布推动了音乐信息检索和领域特定问答研究，奠定了检索增强推理方法在富含文化内涵领域（如音乐）应用的基础。

Abstract: Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.

</details>


### [14] [Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment](https://arxiv.org/abs/2512.05464)
*Panatchakorn Anantaprayoon,Nataliia Babina,Jad Tarifi,Nima Asgharbeygi*

Main category: cs.CL

TL;DR: 本文提出了一种基于集体代理的新型对齐价值及动态自我对齐框架，实现对大语言模型的高效、自我改进对齐。


<details>
  <summary>Details</summary>
Motivation: 传统的基于人类反馈的对齐方法资源密集且难以扩展，且现有对齐体系可能无法满足AGI和ASI阶段的需求。

Method: 提出了动态对齐框架，该框架包含自动训练数据集生成和基于GRPO学习的自我奖励机制。

Result: 实验结果表明该方法成功地让模型实现了集体代理（CA）这一统一开源的对齐价值观，同时保持了模型的一般自然语言处理能力。

Conclusion: 研究证明通过动态对齐机制，LLM能够在保持通用能力的同时，自我提升并实现更全面的价值对齐。

Abstract: Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.

</details>


### [15] [SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures](https://arxiv.org/abs/2512.05501)
*Panuthep Tasawong,Jian Gang Ngui,Alham Fikri Aji,Trevor Cohn,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 本研究创建了首个东南亚语言安全性基准，揭示了当前大型语言模型在该地区文化和安全问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 目前大部分对大型语言模型（LLMs）安全性的评估聚焦于英文，忽略了语言和文化多样性，特别是东南亚语言在安全性测试中的缺失。现有多语言安全基准依赖于英文数据的机器翻译，无法捕捉低资源语言中的微妙差异和地域特有的安全问题。

Method: 构建了SEA-SafeguardBench数据集，包含8种东南亚语言的本地人工撰写样本，并通过三种子集详细测评模型的安全性能。

Result: 提出了SEA-SafeguardBench，这是第一个面向东南亚地区的人工验证安全基准，涵盖8种语言、21640个样本，分为通用、真实环境和内容生成三个子集。实验结果显示，现有最先进的LLMs和安全机制在应对东南亚文化和安全场景时表现不足，远逊于对英文数据的处理效果。

Conclusion: 当前最先进的语言模型及其安全机制在东南亚语言和文化安全场景下表现不佳，亟需开发针对多语言和文化的本地化安全评估方法。

Abstract: Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.

</details>


### [16] [Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches](https://arxiv.org/abs/2512.05537)
*Namu Park,Farzad Ahmed,Zhaoyi Sun,Kevin Lybarger,Ethan Breinhorst,Julie Hu,Ozlem Uzuner,Martin Gunn,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 本文提出了一种结合病灶标记和解剖学提示的生成式大语言模型方法，在细粒度偶发病灶检测上显著优于传统监督模型，性能接近人类水平，促进了放射学自动化监测的进步。


<details>
  <summary>Details</summary>
Motivation: 当前的影像报告分类系统在检测需要随访的偶发病灶方面存在局限性，特别是在细粒度的病灶级别上。该研究旨在评估大型语言模型（LLMs）在这一任务上的表现，比较其与监督学习基线方法的效果。

Method: 利用包含1623个经验证病灶的400份标注放射学报告数据集，比较三种监督的transformer编码器（BioClinicalModernBERT, ModernBERT, Clinical Longformer）和四种生成式大语言模型配置（Llama 3.1-8B, GPT-4o, GPT-OSS-20b），并引入了病灶标记输入及解剖学感知提示的新推理策略。采用类别特异的F1分数进行性能评估。

Result: 基于解剖信息的GPT-OSS-20b模型表现最佳，偶发病灶阳性宏观F1达0.79，超过所有监督基线（最高0.70）且接近人工注释者一致性（0.76）。明确的解剖定位显著提升了GPT模型性能（p<0.05），集成顶尖模型进一步将宏观F1提升至0.90。错误分析显示，解剖知识辅助的LLMs在区分可处理与良性病灶的上下文推理方面表现优越。

Conclusion: 结构化病灶标记和解剖上下文增强的生成式大语言模型显著优于传统监督编码器，表现接近人类专家，提供了一种可靠且可解释的自动化偶发病灶监测方法，适用于放射学临床工作流。

Abstract: Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.
  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.
  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.
  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.

</details>


### [17] [Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems](https://arxiv.org/abs/2512.05580)
*Aurprita Mahmood,Sabrin alam,Neloy kumer Sagor,Md. Abdul Hadi,Md. Sehab Al Islam,Minhajul Islam*

Main category: cs.CL

TL;DR: 本文针对孟加拉语数学题提出了基于树状结构的推理方法ToT，相比现有的线性推理CoT有显著提升，有助于提升低资源语言中的数学题理解与解答能力。


<details>
  <summary>Details</summary>
Motivation: 传统的CoT推理因其线性结构易导致错误传播，限制了性能的提升，因此需要一种更有效的推理结构来解决复杂的多步数字推理问题。

Method: 提出并系统研究了基于树结构的推理方法Tree-of-Thought (ToT)，并在孟加拉语数学文字题（MWPs）上进行实验，比较了标准提示、Chain-of-Thought (CoT) 和Tree-of-Thought (ToT)三种策略在多个大型语言模型（如GPT-OSS和LLaMA变体）上的表现。

Result: CoT提示相比标准提示将准确率从78%提升到83%，而ToT方法在GPT-OSS-120B模型上进一步提高了5个百分点，达到88%的准确率。ToT对中大型模型效果明显优于小模型。

Conclusion: ToT推理框架在处理低资源语言的数学问题上展现出更鲁棒和高效的推理能力，优于传统的线性CoT方法，为多语言自然语言处理中的复杂推理提供了新的思路。

Abstract: Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.

</details>


### [18] [A Greek Government Decisions Dataset for Public-Sector Analysis and Insight](https://arxiv.org/abs/2512.05647)
*Giorgos Antoniou,Giorgos Filandrianos,Aggelos Vlachos,Giorgos Stamou,Lampros Kollimenos,Konstantinos Skianis,Michalis Vazirgiannis*

Main category: cs.CL

TL;DR: 本文介绍了一个包含希腊政府决策的开放机器可读语料库，包含100万份决策的高质量文本数据，并设计了基于该语料库的检索增强生成任务，展示了其在信息访问和透明度方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 提升公共部门文档的信息访问能力和透明度，推动大型公共领域语料库在法律及政府领域语言模型训练及AI解释性方面的应用。

Method: 收集希腊政府决策文本，提取高质量Markdown格式文本，构建检索增强生成任务，设计代表性问题和高质量答案，并评估基线RAG系统的检索及推理能力。

Result: 成功构建了大规模希腊政府决策语料库，设计并验证了一个基线RAG系统在文本检索和推理中的有效性，公开了数据和代码，展示了显著的应用潜力。

Conclusion: 该语料库为政府文档的结构化检索和推理提供了可能，支持法务和政府领域的语言模型训练，促进信息透明和可解释AI的发展。

Abstract: We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.

</details>


### [19] [Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models](https://arxiv.org/abs/2512.05658)
*Pietro Ferrazzi,Aitor Soroa,Rodrigo Agerri*

Main category: cs.CL

TL;DR: 本文提出了一种基于事实医学知识的多语言推理路径生成方法，显著提升了医学问答模型表现，支持多语言临床决策工具的开发，同时公开了相关资源。


<details>
  <summary>Details</summary>
Motivation: 现有医学问答多集中于英语，且多依赖通用大模型蒸馏，医学知识可靠性存疑，因此提出生成基于事实医学知识的多语言推理路径以增强模型推理能力和可靠性。

Method: 采用基于检索增强生成的多语言推理路径方法，基于维基百科医学信息，生成覆盖英语、意大利语和西班牙语的50万条推理路径，并在MedQA和MedMCQA数据集上训练和测试。

Result: 通过在领域内外的医学问答基准测试，生成的推理路径无论在少样本内学习和监督微调中均显著提升了模型性能，达到了同类8B参数模型的最先进水平。

Conclusion: 该研究通过生成多语言的医学推理路径，有效提升了医学问答的性能，尤其在8B参数规模的语言模型中达到最新水平，促进了更安全、更透明的临床决策支持工具发展。

Abstract: Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.

</details>


### [20] [Interleaved Latent Visual Reasoning with Selective Perceptual Modeling](https://arxiv.org/abs/2512.05665)
*Shuai Dong,Siyuan Wang,Xingyu Liu,Zhongyu Wei*

Main category: cs.CL

TL;DR: ILVR是一种结合动态状态演化与精准感知建模的多模态大语言模型视觉推理框架，通过文本生成与潜在视觉表示交替进行，实现上下文感知的视觉信号自我监督，显著提升多模态推理表现。


<details>
  <summary>Details</summary>
Motivation: 传统的多模态大语言模型重编码像素密集图像计算成本高，潜在视觉推理方法存在过度压缩特征导致感知不精确或静态结构无法动态推理的矛盾。

Method: 提出了Interleaved Latent Visual Reasoning (ILVR)框架，该方法通过交替生成文本与潜在视觉表示，并利用动量教师模型自监督选择性蒸馏图像特征作为稀疏监督，指导生成上下文相关的视觉信号。

Result: 在多模态推理基准测试中，ILVR显著超越了现有方法，成功桥接了细粒度感知和序贯多模态推理之间的鸿沟。

Conclusion: ILVR有效解决了传统多模态推理中视觉特征过度压缩或静态结构无法动态演化的问题，提升了感知精度与序贯推理能力，显著优于现有方法。

Abstract: Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.

</details>


### [21] [MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation](https://arxiv.org/abs/2512.05671)
*Zhitao He,Haolin Yang,Zeyu Qin,Yi R Fung*

Main category: cs.CL

TL;DR: 本文提出针对临床教学需求的多智能体教学模拟与数据集构建，训练出首个支持一对多苏格拉底教学的大型模型MedTutor-R1，显著提升教学效果并具备良好的适应能力。


<details>
  <summary>Details</summary>
Motivation: 临床教学中学员对个性化指导需求增长，专家教师资源不足，且现有研究多关注一对一知识传授，忽视团队协作推理这一关键能力。

Method: 开发了ClinEdu多智能体教学模拟器，构建ClinTeach大型苏格拉底教学对话数据集，训练多模态苏格拉底教学模型MedTutor-R1。MedTutor-R1先在ClinTeach数据集上进行指令微调，再通过强化学习优化，奖励依据结构严谨性、分析质量和临床安全性三项指标。采用基于模拟的交互式评估，将模型重新部署于ClinEdu中进行测试。

Result: MedTutor-R1在平均教学评分上比基础模型提升20%以上，表现与o3模型相当，且能适应不同人数的学生，显示出高度适应性和教学有效性。

Conclusion: ClinEdu教学模拟器和ClinTeach数据集有效支撑了临床多学生协作教学的研究，MedTutor-R1展示了先进的多模态苏格拉底教学能力，促进了医学教育中个性化和团队协作技能的发展。

Abstract: The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.

</details>


### [22] [Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods](https://arxiv.org/abs/2512.05681)
*Tereza Novotna,Jakub Harasta*

Main category: cs.CL

TL;DR: 本文比较了两种模型在捷克宪法法院判决检索任务中的表现，提出了考虑噪声的评估方法。


<details>
  <summary>Details</summary>
Motivation: 检索判例是耗时任务，现有数据存在标签噪声和异质性，亟需评估方法能适应噪声标签的现实环境，同时比较不同模型的检索性能。

Method: 采用基于噪声感知的评估框架，包括IDF加权关键词重叠作为相关度评分、不同阈值的二值化、成对自助法显著性检验，以及nDCG指标结合定性分析。

Result: OpenAI的大型通用嵌入模型在@10/@20/@100指标下显著优于领域特定BERT模型，评估方法证明在带有噪声标签的司法数据库中依然有效且具鲁棒性。

Conclusion: 通用OpenAI嵌入模型在不同设置和阈值下均显著优于领域特定训练的BERT模型，尽管评价指标绝对值偏低，反映了数据标签噪声及标签漂移问题。

Abstract: Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.

</details>


### [23] [Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains](https://arxiv.org/abs/2512.05700)
*Ben Malin,Tatiana Kalganova,Nikolaos Boulgouris*

Main category: cs.CL

TL;DR: 本文提出了一种基于多种基础忠实度指标融合的评估方法，通过树模型结合人工评判提高大语言模型输出的忠实度评估准确性。


<details>
  <summary>Details</summary>
Motivation: 提升大语言模型输出的忠实度评估准确性，以增强模型在更多应用场景中的可靠性。

Method: 采用树模型融合多种基础忠实度指标，结合人工评判数据确定各指标的重要性，构建融合指标进行评估。

Result: 融合指标在所有测试领域中均与人工评判表现出更强的相关性，实现了跨领域的忠实度评估效果提升，并发布了标准化数据集供复现和进一步研究。

Conclusion: 融合多种忠实度指标并利用树模型加权，能更准确评估大语言模型的输出忠实度，且与人工评判高度相关。

Abstract: We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.

</details>


### [24] [Efficient Text Classification with Conformal In-Context Learning](https://arxiv.org/abs/2512.05732)
*Ippokratis Pantelidis,Korbinian Randl,Aron Henriksson*

Main category: cs.CL

TL;DR: CICLe通过结合轻量级分类器和保形预测，提升了大语言模型在文本分类中的效率和性能，尤其在样本充足时表现优越，并在数据和计算资源上显著节省。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在文本分类中依赖提示设计且计算成本高，需探索一种在保证性能的前提下更高效且适用更广泛的分类框架。

Method: 该方法结合轻量级基础分类器与保形预测技术，通过动态缩减候选类别集合，优化LLM的提示设计，降低所需的样本数和提示长度，提升计算效率。

Result: CICLe相比传统方法减少提示样本数最多34.45%，减少提示长度25.16%，能用更小模型达到竞争性能，并在多个分类基准中优于基线，尤其对类别不均衡任务效果显著。

Conclusion: CICLe在多个NLP文本分类任务中表现稳定优于基础分类器和少样本提示方法，兼顾效率和性能，尤其适用于类别高度不平衡的任务，展示了高效且可扩展的文本分类潜力。

Abstract: Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.

</details>


### [25] [Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning](https://arxiv.org/abs/2512.05747)
*Jinlong Liu,Mohammed Bahja,Venelin Kovatchev,Mark Lee*

Main category: cs.CL

TL;DR: 本文提出了利用GRPO和多重奖励实现风格条件故事生成的方法，实验证明8B模型能有效控制作者风格，优于更大模型，但叙事完整性仍需提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法对故事生成的风格控制依赖浅层特征且缺乏稳健评估，本文旨在通过引入细粒度风格奖励和多重优化策略，提升故事生成的风格一致性和质量。

Method: 利用Group Relative Policy Optimization和自定义多奖励机制，基于细调的句子变换器和作者验证信号，结合内容和完整性分数，训练风格条件故事生成模型。

Result: 本论文提出了一种基于Group Relative Policy Optimization (GRPO)和多重奖励机制的风格条件故事生成训练框架。该框架通过细化的作者验证信号和内容完整度评分，提升了模型在长篇叙事生成中的风格控制能力。实验以马克·吐温的《哈克贝利·费恩历险记》为参考风格，8B参数模型在作者风格验证指标上优于更大规模的GPT-4o和Claude Sonnet 4，风格得分达0.628，内容质量表现也具有竞争力。研究验证了适度模型规模结合任务专用训练即可实现风格指导的故事生成，但整体叙事连贯性和完整性仍有待改进。

Conclusion: 适度规模模型在结合GRPO和多重奖励训练下，能实现明确的作者风格控制，表现优于更大模型，但叙事整体连贯和完整性仍是未来改进的重点。

Abstract: Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.

</details>


### [26] [Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments](https://arxiv.org/abs/2512.05832)
*Yifei Tong*

Main category: cs.CL

TL;DR: 美国最高法院辩论中断对论点内容影响不大，但针对女性的中断带有更负面情绪，反映司法话语中的性别不平等。


<details>
  <summary>Details</summary>
Motivation: 研究中断对美国最高法院口头辩论中辩护律师发言的语义内容和情绪基调的影响，特别关注司法话语中的性别动态。

Method: 使用2010-2019年ConvoKit Supreme Court语料库，分析12663段辩护人与法官互动的发言，采用基于GloVe的句子嵌入评估语义变化，基于词典的方法衡量情绪倾向。

Result: 发现中断前后发言的语义相似性较高，说明中断未显著改变论点内容；但针对女性辩护人的中断情绪负面性显著更高。

Conclusion: 中断虽不改变论点内容，但对女性辩护人的语气负面影响显著，揭示了司法机构中的性别沟通不平等，体现计算语言学在研究权力、话语和公正性中的价值。

Abstract: This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.

</details>


### [27] [Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy](https://arxiv.org/abs/2512.05858)
*Savir Basil,Ina Shapiro,Dan Shapiro,Ethan Mollick,Lilach Mollick,Lennart Meincke*

Main category: cs.CL

TL;DR: 赋予AI模型专家或低知识角色对其在复杂选择题上的表现无明显提升，低知识角色甚至会降低准确率，显示角色提示主要影响语言风格而非提升答题准确性。


<details>
  <summary>Details</summary>
Motivation: 探究赋予AI模型不同角色设定（专家角色和低知识角色）是否能提升其在复杂客观选择题中的表现。

Method: 对六个模型在涵盖科学、工程和法律等领域的两个研究生水平的问答基准测试中，采用三种角色赋值方法（领域专家角色、非匹配领域专家角色和低知识角色）进行对比实验。

Result: 领域专家角色对模型准确率影响不显著，非匹配领域专家角色略微影响表现，低知识角色通常降低准确率。整体来看，角色赋值未显著提升模型准确率。

Conclusion: 给模型赋予专家或低知识角色并不能普遍提升其解答复杂选择题的准确率，角色提示在提升事实准确性方面效果有限，但可能在调整语言风格等方面有其他用途。

Abstract: This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.
  We tested three approaches:
  -In-Domain Experts: Assigning the model an expert persona ("you are a physics expert") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).
  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona ("you are a physics expert") not matched to the problem type (law problems) resulted in marginal differences.
  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.
  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.

</details>


### [28] [Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework](https://arxiv.org/abs/2512.05863)
*Tasnimul Hassan,Md Faisal Karim,Haziq Jeelani,Elham Behnam,Robert Green,Fayeq Jeelani Syed*

Main category: cs.CL

TL;DR: 该论文提出了结合领域知识检索的医疗问答系统，通过微调LLaMA 2和Falcon模型，提升了回答的准确性和事实依据，减少了幻觉生成。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在医学问答中应用时面临事实准确性和幻觉生成的问题，需要结合领域知识提升回答质量。

Method: 采用低秩适配（LoRA）微调开放大语言模型，结合医学文献检索实现回答的事实依据，提高回答的正确性并降低幻觉率。

Result: 结合检索增强生成的医疗问答系统，显著提高了准确率，减少了无据支持内容，标志着基于检索的开放大模型在生物医药问答中的潜力。

Conclusion: 基于检索增强的生成模型能有效提升医学问答的准确性及可靠性，为临床信息学应用提供有力支持。

Abstract: Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.

</details>


### [29] [M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG](https://arxiv.org/abs/2512.05959)
*David Anugraha,Patrick Amadeus Irawan,Anshul Singh,En-Shiun Annie Lee,Genta Indra Winata*

Main category: cs.CL

TL;DR: 本文提出了一个多语言多模态的检索增强视觉问答基准M4-RAG，覆盖42种语言及56种方言，包含8万多文化多样的图像-问题对，旨在评估跨语言跨模态的检索增强VQA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型受限于静态训练数据，检索增强方法有助于获取最新且多元文化和语言信息，但多语言多模态的检索增强尚未充分研究。

Method: 构建了包含数百万多语言文档的受控检索环境，模拟真实检索场景，结合大规模多语言多模态数据构建M4-RAG基准进行系统评估。

Result: 系统评估显示RAG方法对小模型有效，但对大模型效果下降，暴露模型规模与检索方法有效性之间的关键不匹配。

Conclusion: 检索增强生成方法（RAG）对小型视觉语言模型有效，但对大型模型表现较差，表明当前检索方法与大模型间存在性能匹配问题。

Abstract: Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [30] [Stellis: A Strategy Language for Purifying Separation Logic Entailments](https://arxiv.org/abs/2512.05159)
*Zhiyi Wang,Xiwei Wu,Yi Fang,Chengtao Li,Hongyi Zhong,Lihan Xie,Qinxiang Cao,Zhenjiang Hu*

Main category: cs.SE

TL;DR: 提出Stellis策略语言及其健全性算法，成功实现分离逻辑蕴含自动纯化，在多个基准测试中表现出高自动化率和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的方法无法充分描述自动化策略，尤其是在特定场景下对内存布局的匹配和消除方面存在局限。

Method: 提出Stellis策略语言，通过强大的匹配机制和灵活的动作描述，实现对分离逻辑蕴含式的纯化，即去除所有空间公式，简化蕴含式。引入生成策略健全性条件的算法，并利用机械化证明生成整体自动化正确性。

Result: 在来自链式数据结构和微内核内存模块的229个蕴含式基准上进行评测，利用5个库中的98条策略，自动纯化了95.6%的蕴含式，证明了系统的灵活性与高效性。

Conclusion: Stellis策略语言有效解决了分离逻辑蕴含自动化策略描述的不足，实现了高效且健全的自动纯化，大幅提升了自动证明的灵活性和效果。

Abstract: Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.

</details>


### [31] [Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge](https://arxiv.org/abs/2512.05176)
*Brittany Johnson,Erin Reddick,Angela D. R. Smith*

Main category: cs.SE

TL;DR: 该论文聚焦于开发文化智能和价值推断质量基准(CIVIQ)，以促进大型语言模型(LLMs)在美国多元文化背景下的文化对齐，借鉴韩国国家对齐基准(KorNAT)的方法，弥补现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型大多以西方文化为主导，难以有效对齐美国复杂多元的文化身份背景，现有国家级对齐基准难以覆盖广泛文化代表性，迫切需要针对不同文化群体的对齐评估工具。

Method: 通过复制韩国KorNAT基准开发流程，结合美国本土文化多样性，设计并构建了CIVIQ这一文化智能与价值推断质量评估基准。

Result: 成功开发了面向美国多元文化背景的CIVIQ基准，为评估和提升LLMs的文化对齐效果提供了实证工具和框架，有望推动更包容和公平的AI模型研发。

Conclusion: 本研究提出并开发了CIVIQ基准，提升了在多元文化环境中大型语言模型的文化对齐能力，为未来AI的文化适应性研究奠定了基础。

Abstract: Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as "general purpose" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of "culturally-informed" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.

</details>


### [32] [A Survey of Bugs in AI-Generated Code](https://arxiv.org/abs/2512.05239)
*Ruofan Gao,Amjed Tahir,Peng Liang,Teo Susnjak,Foutse Khomh*

Main category: cs.SE

TL;DR: 本文系统综述了AI生成代码中的缺陷类型及其分布，分类不同模型错误模式，并提出修复和缓解这些缺陷的策略，为未来模型改进和质量评估提供参考。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成代码中存在许多质量问题和缺陷，但相关发现零散且缺乏系统总结，无法全面了解其错误类型、分布及对应模型的关联。

Method: 系统地分析现有AI生成代码的文献，归纳总结生成代码中的缺陷与错误类型，并分类不同模型生成代码中的缺陷模式。

Result: 总结了AI生成代码中存在的各类缺陷和错误模式，建立了缺陷的分类体系，探讨了不同模型的错误分布，并分析了相应的修复和缓解策略。

Conclusion: 通过系统性文献分析，本文为理解AI生成代码中的缺陷提供了清晰的分类和分布视角，明确了改进方向及修复策略，有助于提升AI代码生成的质量和可靠性。

Abstract: Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.

</details>


### [33] [Learning to Code with Context: A Study-Based Approach](https://arxiv.org/abs/2512.05242)
*Uwe M. Borghoff,Mark Minas,Jannis Schopp*

Main category: cs.SE

TL;DR: 论文研究了生成式AI在软件工程教育项目中的应用及挑战，提出基于RAG技术的上下文感知AI助手，助力教学与开发。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI快速发展，软件工程教育需适应新技术，利用项目课程探索AI辅助的有效整合与应用。

Method: 通过大学编程项目的用户研究，结合RAG技术构建本地部署的语言模型助手，进行模型行为和参数敏感性分析。

Result: 该论文探讨了生成式AI工具在软件开发中的应用及其对软件工程教育的影响，特别是在基于项目的课程中如何有效整合AI辅助。通过大学生协作开发游戏的项目研究，分析了生成式AI在开发不同阶段的使用情况、最有效的任务类型及遇到的挑战。论文还介绍了一个基于本地部署、支持代码仓库感知的语言模型助手，采用检索增强生成（RAG）技术，实现上下文相关的响应，并对模型表现和失效模式进行了定性分析。

Conclusion: 研究加深了对上下文感知AI支持在教育软件项目中的理解，推动了AI辅助软件工程课程的未来发展。

Abstract: The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.

</details>


### [34] [Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions](https://arxiv.org/abs/2512.05309)
*Adam Alami,Nathan Cassee,Thiago Rocha Silva,Elda Paja,Neil A. Ernst*

Main category: cs.SE

TL;DR: 通过两阶段定性研究，揭示LLM辅助代码审查相比传统同伴审查能减少情绪和认知负担，提高反馈采纳率，AI应作为辅助伙伴而非替代。


<details>
  <summary>Details</summary>
Motivation: 现有研究较少探讨软件工程师在使用大型语言模型（LLM）辅助的代码审查与人际同事主导的代码审查中的参与方式差异。

Method: 通过两个阶段的定性研究，第一阶段让20名软件工程师进行同伴审查并采访其情感反应和参与决策；第二阶段引入符合工程师偏好的新的提示词以探查其特征如何影响反应。

Result: 发现工程师通过自我情绪调节策略（重新框架、对话调节、回避、防御）管理负面反馈情绪，参与通过社会校准适应团队规范。与同伴审查相比，LLM辅助审查降低了情感成本和自我调节需求，降低认知负荷并提高反馈采纳倾向。

Conclusion: 提出了一个综合模型，连接情绪自我调节、行为参与和问题解决，展示情感和认知过程如何影响同伴和LLM辅助代码审查中的反馈采纳，认为AI应作为支持伙伴，减少认知及情绪负担，同时保持人类责任和社交意义。

Abstract: Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.

</details>


### [35] [WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp](https://arxiv.org/abs/2512.05314)
*Ke Mao,Timotej Kapus,Cons T Åhs,Matteo Marescotti,Daniel Ip,Ákos Hajdu,Sopot Cela,Aparup Banerjee*

Main category: cs.SE

TL;DR: 该论文报告了WhatsCode——一个支持WhatsApp的领域特定AI开发系统在工业环境中的部署与演进，提升了隐私自动化覆盖率和代码变更接受率，实现人与AI的高效协作。


<details>
  <summary>Details</summary>
Motivation: 尽管工业界AI辅助开发工具采用不断增长，学术界缺少关于合规性大规模工业环境部署的研究，亟需探索和总结实际应用中的经验与模式。

Method: 通过在WhatsApp环境中持续25个月的实际部署和数据收集，分析隐私验证覆盖率、代码变更接受率及人机协作模式，结合自动化推荐和人工复核的工作流程。

Result: 隐私自动化验证覆盖率提高3.5倍至53%，超过3000个代码变更被接受，692次自动重构，保持86%的缺陷分类准确率，发现两种主要的人机协作模式，强调组织因素与技术同等重要。

Conclusion: WhatsCode的工业部署证明，技术能力与组织因素（如所有权模型、采用动态和风险管理）共驱动AI工具的企业成功，且有效的人机协作优于完全自动化，带来可持续业务影响。

Abstract: The deployment of AI-assisted development tools in compliance-relevant, large-scale industrial environments represents significant gaps in academic literature, despite growing industry adoption. We report on the industrial deployment of WhatsCode, a domain-specific AI development system that supports WhatsApp (serving over 2 billion users) and processes millions of lines of code across multiple platforms. Over 25 months (2023-2025), WhatsCode evolved from targeted privacy automation to autonomous agentic workflows integrated with end-to-end feature development and DevOps processes.
  WhatsCode achieved substantial quantifiable impact, improving automated privacy verification coverage 3.5x from 15% to 53%, identifying privacy requirements, and generating over 3,000 accepted code changes with acceptance rates ranging from 9% to 100% across different automation domains. The system committed 692 automated refactor/fix changes, 711 framework adoptions, 141 feature development assists and maintained 86% precision in bug triage. Our study identifies two stable human-AI collaboration patterns that emerged from production deployment: one-click rollout for high-confidence changes (60% of cases) and commandeer-revise for complex decisions (40%). We demonstrate that organizational factors, such as ownership models, adoption dynamics, and risk management, are as decisive as technical capabilities for enterprise-scale AI success. The findings provide evidence-based guidance for large-scale AI tool deployment in compliance-relevant environments, showing that effective human-AI collaboration, not full automation, drives sustainable business impact.

</details>


### [36] [Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering](https://arxiv.org/abs/2512.05350)
*Munazza Zaib,Wei Wang,Dulaji Hidellaarachchi,Isma Farah Siddiqui*

Main category: cs.SE

TL;DR: 本研究首次系统探讨神经多样性女性在软件工程中的挑战，提出基于InclusiveMag和GenderMag的混合方法，旨在促进职场包容与支持。


<details>
  <summary>Details</summary>
Motivation: 神经多样性女性在软件工程领域面临性别偏见与神经差异叠加的独特挑战，目前该领域缺乏系统性研究此群体。

Method: 提出一种结合InclusiveMag包容性框架和GenderMag性别认知分析的混合方法，通过文献综述、用户画像与分析过程推导，以及协作工作坊应用三个阶段展开研究。

Result: 文献综述总结了神经多样性女性在认知、社交、组织结构、职业发展等方面面临的挑战，特别指出了诊断不足、掩饰行为加剧排斥。

Conclusion: 研究为后续阶段发展和应用包容性分析方法以支持实际变革奠定了基础。

Abstract: Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.

</details>


### [37] [BGPFuzz: Automated Configuration Fuzzing of the Border Gateway Protocol](https://arxiv.org/abs/2512.05358)
*Chenlu Zhang,Amirmohammad Pasdar,Van-Thuan Pham*

Main category: cs.SE

TL;DR: 本文提出了一种结构感知且有状态的模糊测试框架BGPFuzz，用于系统性地变异BGP配置并在虚拟网络中评估其影响，以检测BGP配置错误引发的异常。


<details>
  <summary>Details</summary>
Motivation: BGP配置复杂且存在厂商特定实现，传统基于综合或验证的方法成本较高，需一种更经济有效的错误识别方案。

Method: 提出结构感知且有状态的模糊测试框架BGPFuzz，系统变异BGP配置并通过运行时检测器捕捉会话重置、黑洞流量和流量重定向等异常。

Result: 实验表明BGPFuzz可以可靠地检测已知的BGP错误案例，包括最大前缀限制违规和子前缀劫持。

Conclusion: BGPFuzz能够可靠地复现和检测包括最大前缀违规和子前缀劫持在内的已知BGP配置错误，效果验证了其有效性。

Abstract: Telecommunications networks rely on configurations to define routing behavior, especially in the Border Gateway Protocol (BGP), where misconfigurations can lead to severe outages and security breaches, as demonstrated by the 2021 Facebook outage. Unlike existing approaches that rely on synthesis or verification, our work offers a cost-effective method for identifying misconfigurations resulting from BGP's inherent complexity or vendor-specific implementations. We present BGPFuzz, a structure-aware and stateful fuzzing framework that systematically mutates BGP configurations and evaluates their effects in virtualized network. Without requiring predefined correctness properties as in static analysis, BGPFuzz detects anomalies through runtime oracles that capture practical symptoms such as session resets, blackholing, and traffic redirection. Our experiments show that BGPFuzz can reliably reproduce and detect known failures, including max-prefix violations and sub-prefix hijacks.

</details>


### [38] [Legacy Modernization with AI -- Mainframe modernization](https://arxiv.org/abs/2512.05375)
*Sunil Khemka,Arunava Majumdar*

Main category: cs.SE

TL;DR: AI辅助传统主机系统现代化，通过自动化和智能技术提升效率与灵活性，推动数字转型。


<details>
  <summary>Details</summary>
Motivation: 传统主机系统维护成本高、技能短缺且难以与云系统集成，需引入AI技术实现灵活、可扩展且智能的架构变革。

Method: 采用自动代码重构、智能数据迁移、预测性维护和机器学习模型进行代码分析及自动化测试部署。

Result: 本文探讨了利用人工智能辅助传统主机系统现代化的重要性与方法。通过引入自动代码重构、智能数据迁移和预测性维护等AI驱动策略，实现向微服务、容器化及混合云平台的平滑过渡。机器学习模型能分析遗留代码，发现优化空间并自动执行测试和部署。同时，AI提升运营效率，通过负载均衡和异常检测保障系统稳定性。AI与主机现代化结合不仅保护核心业务逻辑，还推动更快创新、减少停机时间、增强系统韧性，成为数字化转型和企业可持续发展的催化剂。

Conclusion: AI在主机现代化中发挥关键作用，促进企业数字化转型，实现系统灵活性、创新力和持续增长。

Abstract: Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.

</details>


### [39] [Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation](https://arxiv.org/abs/2512.05383)
*Mara Downing,Matthew Peng,Jacob Granley,Michael Beyeler,Tevfik Bultan*

Main category: cs.SE

TL;DR: 通过覆盖引导模糊测试方法，系统检测神经刺激模型的安全性，发现并量化多种不安全刺激模式，实现安全评估标准化和量化。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在神经假体设备中应用，虽然提升了个性化控制精度，但也引入了新的安全风险，亟需一种系统化、量化的安全检测方法以确保模型输出的神经刺激安全。

Method: 采用覆盖引导模糊测试技术，通过扰动模型输入并基于生物物理安全限制对输出刺激进行检测，利用覆盖度指标引导测试用例生成，覆盖更多输出空间和违规类型。

Result: 本文提出了一种基于覆盖引导模糊测试的方法，系统检测和表征机器学习驱动的神经刺激系统中的不安全电刺激模式。该方法通过扰动模型输入，检测输出刺激是否超出生物物理安全范围，如电荷密度、电流瞬时值或电极共同激活。结果表明，该方法能有效发现视网膜和大脑皮层深度刺激编码器多个违反安全限制的刺激模式，并通过两个覆盖度指标衡量违规输出的数量与多样性，实现模型架构和训练策略的可解释比较。结论是将安全性评估转变为可量化、可重复的实证过程，为神经接口设备的基于证据的基准测试、法规合规和伦理保障奠定了基础。

Conclusion: 覆盖引导模糊测试方法能有效识别和量化神经刺激模型的不安全输出，推动安全评估从经验性转向实证可量化，为神经接口的规范和伦理保障提供支撑。

Abstract: Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.

</details>


### [40] [Bita: A Conversational Assistant for Fairness Testing](https://arxiv.org/abs/2512.05428)
*Keeryn Johnson,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 本文提出了Bita，一种基于大语言模型的对话助手，帮助测试人员方便、系统地进行AI系统公平性测试，从而有效检测和缓解偏见。


<details>
  <summary>Details</summary>
Motivation: 现有公平性测试工具难以使用，需要高级专业知识，且对现实工作流程支持有限，导致AI系统中的偏见难以有效检测和缓解。

Method: 提出了Bita，一种结合大语言模型和检索增强生成技术的对话助手，基于策划的公平性文献，帮助软件测试人员检测偏见源、评估测试计划并生成公平性导向的探索性测试计划。

Result: 验证表明Bita能支持现实AI系统中的公平性测试任务，提供结构化、可重复的证据，展示其实用性。

Conclusion: 工作贡献了一个实用工具，使公平性测试变得易用、系统化且适用于工业实践。

Abstract: Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.

</details>


### [41] [Model Gateway: Model Management Platform for Model-Driven Drug Discovery](https://arxiv.org/abs/2512.05462)
*Yan-Shiun Wu,Nathan A. Morin*

Main category: cs.SE

TL;DR: 本文提出了Model Gateway，一个用于药物发现模型管理的MLOps平台，集成LLM Agents和生成式AI，实现高并发、零失败率的模型执行管理，助力加速新药研发。


<details>
  <summary>Details</summary>
Motivation: 药物发现过程中需要高效管理多种机器学习和科学计算模型，提升模型执行效率与系统稳定性，从而加速新药研发。

Method: 设计并实现包含动态共识模型、模型注册与管理、异步执行及结果接收的MLOps平台，支持大规模并发访问及集成LLM Agents和生成式AI工具。

Result: 平台在超过1万并发客户端环境下实现0%失败率，支持模型信息检索和控制面板，有效保障模型执行与管理。

Conclusion: Model Gateway作为药物发现管线中的基础平台，有效管理和执行机器学习及科学计算模型，显著提升了模型任务的自动化与稳定性。

Abstract: This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.

</details>


### [42] [Everything is Context: Agentic File System Abstraction for Context Engineering](https://arxiv.org/abs/2512.05470)
*Xiwei Xu,Robert Mao,Quan Bai,Xuewu Gu,Yechao Li,Liming Zhu*

Main category: cs.SE

TL;DR: 本文提出一种基于文件系统抽象的生成式AI上下文管理架构，实现持久、可治理和可验证的人机协作推理管道，提升系统的可维护性和可信度。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统设计已从模型微调转向如何有效捕捉、结构化和管理外部知识上下文，以促进可信推理和增强系统责任追溯能力。现有方法碎片化且产物短暂，亟需统一持久的管理方案。

Method: 借鉴Unix“一切皆文件”理念，设计统一挂载、元数据和访问控制机制，构建包含上下文构造器、加载器及评估器的管道系统，并在开源AIGNE框架中实现。

Result: 实现了一个可验证的上下文工程流水线，支持代币限制下上下文的组装、交付与验证，通过两种示例（具备记忆的智能体和基于MCP的GitHub助手）展示了该架构在工业和开发环境中的可操作性和实用价值。

Conclusion: 本文提出了基于文件系统抽象的上下文工程架构，为生成式AI系统提供持久、可治理的上下文管理基础设施，支持人机协同、可信推理和可验证的上下文管道。

Abstract: Generative AI (GenAI) has reshaped software system design by introducing foundation models as pre-trained subsystems that redefine architectures and operations. The emerging challenge is no longer model fine-tuning but context engineering-how systems capture, structure, and govern external knowledge, memory, tools, and human input to enable trustworthy reasoning. Existing practices such as prompt engineering, retrieval-augmented generation (RAG), and tool integration remain fragmented, producing transient artefacts that limit traceability and accountability. This paper proposes a file-system abstraction for context engineering, inspired by the Unix notion that 'everything is a file'. The abstraction offers a persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting, metadata, and access control. Implemented within the open-source AIGNE framework, the architecture realises a verifiable context-engineering pipeline, comprising the Context Constructor, Loader, and Evaluator, that assembles, delivers, and validates context under token constraints. As GenAI becomes an active collaborator in decision support, humans play a central role as curators, verifiers, and co-reasoners. The proposed architecture establishes a reusable foundation for accountable and human-centred AI co-work, demonstrated through two exemplars: an agent with memory and an MCP-based GitHub assistant. The implementation within the AIGNE framework demonstrates how the architecture can be operationalised in developer and industrial settings, supporting verifiable, maintainable, and industry-ready GenAI systems.

</details>


### [43] [A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models](https://arxiv.org/abs/2512.05498)
*Xiao He,Ru Chen,Zeqing Zhang,Yanling Wang,Qiuyan Dong*

Main category: cs.SE

TL;DR: iEcoreGen融合EMF模板与LLM，兼具准确性与灵活性，显著提升自动化代码生成效果。


<details>
  <summary>Details</summary>
Motivation: 模板生成方法准确但缺乏灵活性，LLM灵活但易出错，结合两者优势提升自动化代码开发质量。

Method: 提出了iEcoreGen，一种结合Eclipse Modeling Framework (EMF)与大型语言模型（LLM）的混合代码生成方法。利用EMF的模板生成初始Java代码，再利用LLM完成和修复未实现的方法。

Result: iEcoreGen在五个LLM的二十个任务上，pass@k指标优于纯LLM，compilation@k表现相当，消融研究验证各组件贡献。

Conclusion: LLM增强的模型驱动开发为高效软件自动化提供了有前景的方向。

Abstract: Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.

</details>


### [44] [Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study](https://arxiv.org/abs/2512.05507)
*Masoud Sadrnezhaad,José Antonio Hernández López,Torvald Mårtensson,Daniel Varro*

Main category: cs.SE

TL;DR: 本文调查了生成式AI在大型网络物理系统基于仿真的测试中的应用现状及挑战，基于六家公司跨公司研讨会收集了工程师观点，提出了未来研究重点。


<details>
  <summary>Details</summary>
Motivation: 随着大型网络物理系统复杂性增加，测试仿真资源消耗巨大，生成式AI有潜力减轻手动负担并提升测试覆盖率，然而其在该领域的应用尚未充分探讨。

Method: 通过组织一次涵盖六家组织的跨公司研讨会，收集和分析从业者对生成式AI在仿真测试中应用的看法与经验。

Result: 研讨会揭示了生成式AI在仿真测试中的实际潜力和关键挑战，明确了生成测试场景与环境模型、仿真器与AI集成、以及AI可信度作为首要研究方向。

Conclusion: 生成式AI在基于仿真的大型网络物理系统测试中具有潜力，但面临多项挑战，需推动学术界与工业界合作，重点关注AI生成测试场景、集成AI与CI/CD流水线及提升可信度。

Abstract: Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.

</details>


### [45] [From Challenge to Change: Design Principles for AI Transformations](https://arxiv.org/abs/2512.05533)
*Theocharis Tavantzis,Stefano Lambiase,Daniel Russo,Robert Feldt*

Main category: cs.SE

TL;DR: 本文提出一个涵盖行为和技术的AI早期采用框架，结合实证调研提供软件工程团队适应AI的具体路径，填补当前人机协作研究空白。


<details>
  <summary>Details</summary>
Motivation: 人工智能快速发展对软件工程带来巨大机遇和挑战，但现有研究多聚焦技术，缺乏对团队如何适应和信任AI的洞察。

Method: 通过文献综述和访谈的主题分析构建框架，结合混合方法论设计调查和专家研讨会收集实践反馈。

Result: 该框架包含九个维度并提供具体行动指导，调查显示培训和AI策略设计最受重视，但人文关怀方面尚不足，研讨会反馈强调框架的实用性。

Conclusion: 该论文提出一个以行为软件工程为基础、以人为中心的框架，帮助软件工程组织在早期人工智能采用阶段有效应对技术与行为挑战。

Abstract: The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.

</details>


### [46] [Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub](https://arxiv.org/abs/2512.05551)
*Jai Lal Lulla,Raula Gaikovina Kula,Christoph Treude*

Main category: cs.SE

TL;DR: 本文首次大规模实证调查了GitHub的CODEOWNERS功能的使用情况，分析了其对代码审查行为和工作流程的影响。


<details>
  <summary>Details</summary>
Motivation: 随着软件供应链攻击等外部威胁增加，确保代码所有权以提升责任明确性和代码质量变得尤为重要，但对CODEOWNERS实际使用情况了解有限。

Method: 通过对844,000多个Pull Request、1.9百万条评论和2百万条审查记录的数据分析，并使用回归断点设计（RDD）方法评估CODEOWNERS的影响。

Result: 发现CODEOWNERS用户严格遵守规则，表现出与传统所有权类似的协作行为，能促进更流畅、更快速的PR工作流程，且审查职责从核心开发者分散出去。

Conclusion: CODEOWNERS有助于优化代码审查流程，将审查职责从核心开发者转移出来，提高软件治理和安全性，仍有较大潜力未被充分利用。

Abstract: Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.

</details>


### [47] [Executing Discrete/Continuous Declarative Process Specifications via Complex Event Processing](https://arxiv.org/abs/2512.05653)
*Stefan Schönig,Leo Poss,Fabrizio Maria Maggi*

Main category: cs.SE

TL;DR: 本文设计了一种基于CEP的三层执行架构，利用STL谓词实现对连续传感器数据与离散事件的同步监控和实时流程控制，提升了网络物理环境中业务流程管理的能力。


<details>
  <summary>Details</summary>
Motivation: 传统的业务流程管理(BPM)仅关注离散事件，未能有效整合关键的连续传感器数据，限制了其在网络物理环境中的应用。

Method: 本文提出了一种基于复杂事件处理(CEP)的执行架构，采用信号时序逻辑(STL)启发的谓词，结合三层方法，将混合声明式规范实时执行和管控融合进流程执行。

Result: 该架构允许系统基于连续传感器行为，主动触发活动和 enforce 流程边界，实现了混合规范与实时操作控制的结合。

Conclusion: 提出的CEP执行架构有效弥补了传统BPM对连续信号处理的不足，实现了混合声明式模型的实时执行与主动管理。

Abstract: Traditional Business Process Management (BPM) focuses on discrete events and fails to incorporate critical continuous sensor data in cyber-physical environments. Hybrid declarative specifications, utilizing Signal Temporal Logic (STL), address this limitation by allowing constraints over both discrete events and real-valued signals. However, existing work has been limited to monitoring and post-hoc conformance checking. This paper introduces a novel Complex Event Processing (CEP)-based execution architecture that enables the real-time execution and enforcement of hybrid declarative models. Our three-layer approach integrates STL-inspired predicates into the execution flow, allowing the system to actively trigger activities and enforce process boundaries based on continuous sensor behavior. This approach bridges the gap between hybrid specification and operational control.

</details>


### [48] [Metronome: Differentiated Delay Scheduling for Serverless Functions](https://arxiv.org/abs/2512.05703)
*Zhuangbin Chen,Juzheng Zheng,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文提出了Metronome，一种基于预测的差异化延迟调度框架，显著提升服务器无函数调度效率，缩短执行时间并保障服务水平协议。


<details>
  <summary>Details</summary>
Motivation: 现有的延迟调度方法在服务器无平台中效果不明显，原因在于函数输入特征多样、局部性模式复杂以及函数执行时间异质性强。

Method: 通过使用在线随机森林回归模型预测函数在不同节点的执行时间，提供基于数据和基础设施局部性的调度决策。

Result: Metronome在OpenLambda平台上实现并测试，平均执行时间减少64.88%-95.83%，在高并发环境下依然表现出较强的性能优势。

Conclusion: Metronome基于预测机制，成功实现了服务器无函数的差异化延迟调度，显著减少了函数平均执行时间，同时保证了SLA合规性。

Abstract: Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.

</details>


### [49] [MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems](https://arxiv.org/abs/2512.05716)
*Zhiling Deng,Juepeng Wang,Zhuangbin Chen*

Main category: cs.SE

TL;DR: 本文提出MicroRacer，一种面向微服务架构的非侵入、自动化并发错误检测框架，通过动态库插装收集运行时数据，精准发现并发bug，有效提升云服务系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现代云应用基于微服务架构组成，用户请求跨多服务和机器，导致系统复杂且易受并发错误影响，现有方法检测并发bug侵入性强且难以处理微服务架构的复杂性，因此需要一种非侵入且自动化的并发错误检测方法。

Method: 设计MicroRacer框架，通过运行时动态插装常用库，无需修改应用代码，收集详细的调用跟踪数据，分析服务系统中操作的happened-before关系和资源访问模式，识别可疑的并发操作，并采用三阶段验证流程检测确认并发错误。

Result: MicroRacer能够准确高效地检测和定位并发错误，在多种开源微服务基准测试及复制的工业并发错误上取得良好效果。

Conclusion: MicroRacer在微服务环境下展示了高效且准确的并发错误检测能力，克服了现有方法的不足，为提升云应用的可靠性提供了有效工具。

Abstract: Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.

</details>


### [50] [Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models](https://arxiv.org/abs/2512.05887)
*Sairam Vaidya,Marcel Böhme,Loris D'Antoni*

Main category: cs.SE

TL;DR: 本文提出了一种针对扩展性编译器的方言无关且方言有效的基于语法和覆盖引导的模糊测试方法，结合了从方言规范自动提取语法及利用预训练大型语言模型生成多样化种子输入的技术。


<details>
  <summary>Details</summary>
Motivation: 现代可扩展编译器框架虽然加速了领域特定语言方言的开发，但测试基础设施维护复杂，需实现既对方言无关又对方言有效的自动测试生成。

Method: 提出从方言规范自动提取语法，结合预训练大型语言模型自动生成多样化代表性种子，进而引导基于覆盖的模糊测试。

Result: 在包含91个方言的6个MLIR项目中，Germinator生成的种子使代码覆盖率提升10-120%，发现88个未知漏洞，其中40个已确认，覆盖了之前无自动测试生成的23个方言。

Conclusion: Germinator工具显著提升了MLIR项目中多方言的测试覆盖率，发现了大量未知漏洞，尤其在低资源方言中展现了强大测试能力。

Abstract: Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.

</details>


### [51] [Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures](https://arxiv.org/abs/2512.05908)
*Amirkia Rafiei Oskooei,S. Selcan Yukcu,Mehmet Cevheri Bozoglan,Mehmet S. Aktas*

Main category: cs.SE

TL;DR: 本文通过将代码转为分层自然语言摘要，并采用两阶段的自然语言搜索，有效解决了多仓库微服务架构中的缺陷定位问题，表现优于现有智能检索工具，且能提供清晰的定位路径以增强企业AI的信任度。


<details>
  <summary>Details</summary>
Motivation: 多仓库微服务架构中，缺陷报告与代码之间存在语义鸿沟，且大模型的上下文限制和仓库识别需求使得缺陷定位变得复杂。

Method: 提出将代码库转换为分层的自然语言摘要（文件级、目录级、仓库级），使用两阶段搜索策略：先将缺陷报告路由到相关仓库，再在仓库内进行自顶向下的定位。

Result: 在包含46个仓库、110万行代码的工业系统DNext上，方法实现了Pass@10为0.82，MRR为0.50，显著优于检索基线和类似GitHub Copilot、Cursor的智能检索系统。

Conclusion: 通过将多仓库微服务架构中的代码转换为分层自然语言摘要，并采用分阶段的自然语言搜索方法，可以显著提升缺陷定位的准确性和可解释性。

Abstract: Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [52] [Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning](https://arxiv.org/abs/2512.05447)
*Pengcheng Dai,Dongming Wang,Wenwu Yu,Wei Ren*

Main category: cs.MA

TL;DR: 本文提出了一种分布式耦合策略算法DSCP，有效处理多智能体奖励和策略耦合问题，实现策略分布式更新并理论保证收敛，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体在网络环境下因奖励相互依赖和策略耦合带来的协同优化困难，提高策略优化的可扩展性和分布式实现能力。

Method: 引入邻居平均Q函数，推导耦合策略梯度表达式，设计DSCP算法利用κ_p跳邻居的状态-动作对和奖励，通过几何2阶采样方法估计梯度，采用push-sum协议分布式更新策略参数。

Result: DSCP算法在理论上保证策略收敛至一阶驻点，实验证明其在机器人路径规划中的性能优于最新方法。

Conclusion: 提出的DSCP算法在网络化多智能体强化学习中有效解决了策略耦合和奖励依赖问题，理论证明其收敛性，并通过机器人路径规划实验证明了优越性能。

Abstract: This paper studies networked multi-agent reinforcement learning (NMARL) with interdependent rewards and coupled policies. In this setting, each agent's reward depends on its own state-action pair as well as those of its direct neighbors, and each agent's policy is parameterized by its local parameters together with those of its $κ_{p}$-hop neighbors, with $κ_{p}\geq 1$ denoting the coupled radius. The objective of the agents is to collaboratively optimize their policies to maximize the discounted average cumulative reward. To address the challenge of interdependent policies in collaborative optimization, we introduce a novel concept termed the neighbors' averaged $Q$-function and derive a new expression for the coupled policy gradient. Based on these theoretical foundations, we develop a distributed scalable coupled policy (DSCP) algorithm, where each agent relies only on the state-action pairs of its $κ_{p}$-hop neighbors and the rewards its their $(κ_{p}+1)$-hop neighbors. Specially, in the DSCP algorithm, we employ a geometric 2-horizon sampling method that does not require storing a full $Q$-table to obtain an unbiased estimate of the coupled policy gradient. Moreover, each agent interacts exclusively with its direct neighbors to obtain accurate policy parameters, while maintaining local estimates of other agents' parameters to execute its local policy and collect samples for optimization. These estimates and policy parameters are updated via a push-sum protocol, enabling distributed coordination of policy updates across the network. We prove that the joint policy produced by the proposed algorithm converges to a first-order stationary point of the objective function. Finally, the effectiveness of DSCP algorithm is demonstrated through simulations in a robot path planning environment, showing clear improvement over state-of-the-art methods.

</details>
