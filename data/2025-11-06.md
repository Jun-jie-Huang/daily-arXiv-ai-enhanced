<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.MA](#cs.MA) [Total: 2]
- [cs.SE](#cs.SE) [Total: 19]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Cache Mechanism for Agent RAG Systems](https://arxiv.org/abs/2511.02919)
*Shuhang Lin,Zhencan Peng,Lingyao Li,Xiao Lin,Xi Zhu,Yongfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为ARC的动态缓存机制，用于LLM代理中的检索增强生成，显著提升了缓存的相关性和效率。


<details>
  <summary>Details</summary>
Motivation: 目前RAG在提升LLM代理性能方面表现良好，但代理级缓存的构建、维护和动态更新仍未充分研究，尤其是如何针对每个代理的需求构建紧凑且相关的语料库。

Method: ARC结合了历史查询分布模式和缓存项在嵌入空间中的内在几何特性，动态地管理每个代理的小型高价值语料库，无需额外标注。

Result: 在三个检索数据集上实验表明，ARC将存储需求降低到原始语料库的0.015%，提供了高达79.8%的有答案率，同时平均检索延迟降低了80%。

Conclusion: ARC显著提升了RAG驱动的LLM代理的缓存效率和效果，具有广泛的应用潜力。

Abstract: Recent advances in Large Language Model (LLM)-based agents have been
propelled by Retrieval-Augmented Generation (RAG), which grants the models
access to vast external knowledge bases. Despite RAG's success in improving
agent performance, agent-level cache management, particularly constructing,
maintaining, and updating a compact, relevant corpus dynamically tailored to
each agent's need, remains underexplored. Therefore, we introduce ARC (Agent
RAG Cache Mechanism), a novel, annotation-free caching framework that
dynamically manages small, high-value corpora for each agent. By synthesizing
historical query distribution patterns with the intrinsic geometry of cached
items in the embedding space, ARC automatically maintains a high-relevance
cache. With comprehensive experiments on three retrieval datasets, our
experimental results demonstrate that ARC reduces storage requirements to
0.015% of the original corpus while offering up to 79.8% has-answer rate and
reducing average retrieval latency by 80%. Our results demonstrate that ARC can
drastically enhance efficiency and effectiveness in RAG-powered LLM agents.

</details>


### [2] [Automatic Machine Translation Detection Using a Surrogate Multilingual Translation Model](https://arxiv.org/abs/2511.02958)
*Cristian García-Romero,Miquel Esplà-Gomis,Felipe Sánchez-Martínez*

Main category: cs.CL

TL;DR: 本文提出了一种基于多语种机器翻译模型内部表征的过滤非人工翻译句子的新方法，显著提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前机器翻译训练数据中大量包含机器生成的翻译文本，过度依赖这些合成内容会显著降低翻译质量，因此需要有效过滤非人工翻译文本。

Method: 利用一个代理多语种机器翻译模型的内部表示，辨别句子是人工翻译还是机器翻译。

Result: 实验结果显示该方法优于现有最先进技术，特别是在非英语语对中准确率提升至少5个百分点。

Conclusion: 基于多语种MT模型内部表征的过滤方法能有效提升非人工翻译数据的识别准确率，有助于构建更高质量的机器翻译系统。

Abstract: Modern machine translation (MT) systems depend on large parallel corpora,
often collected from the Internet. However, recent evidence indicates that (i)
a substantial portion of these texts are machine-generated translations, and
(ii) an overreliance on such synthetic content in training data can
significantly degrade translation quality. As a result, filtering out non-human
translations is becoming an essential pre-processing step in building
high-quality MT systems. In this work, we propose a novel approach that
directly exploits the internal representations of a surrogate multilingual MT
model to distinguish between human and machine-translated sentences.
Experimental results show that our method outperforms current state-of-the-art
techniques, particularly for non-English language pairs, achieving gains of at
least 5 percentage points of accuracy.

</details>


### [3] [LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation](https://arxiv.org/abs/2511.03001)
*Gyeom Hwangbo,Hyungjoo Chae,Minseok Kang,Hyeonjong Ju,Soohyun Oh,Jinyoung Yeo*

Main category: cs.CL

TL;DR: 当前大型语言模型生成的3D场景缺乏真实空间布局和对象属性，导致训练的智能体性能下降。


<details>
  <summary>Details</summary>
Motivation: 细粒度真实环境指导对于生成高质量3D场景至关重要，现有评价指标不能有效衡量场景与指令的匹配。

Method: 提出了LEGO-Eval一个显式绑定场景组件以准确评估匹配度的框架，并发布包含复杂布局和属性的细粒度指令基准LEGO-Bench。

Result: LEGO-Eval在场景与指令对齐评估中比现有视觉语言模型提升了0.41 F1分，LEGO-Bench测试显示现有生成方法成功率不足10%。

Conclusion: 现有3D场景生成方法在细粒度指令指导下表现不足，LEGO-Eval和LEGO-Bench为提升评估和生成质量提供了有力工具。

Abstract: Despite recent progress in using Large Language Models (LLMs) for
automatically generating 3D scenes, generated scenes often lack realistic
spatial layouts and object attributes found in real-world environments. As this
problem stems from insufficiently detailed, coarse-grained instructions,
advancing 3D scene synthesis guided by more detailed, fine-grained instructions
that reflect real-world environments becomes crucial. Without such realistic
scenes, training embodied agents in unrealistic environments can lead them to
learn priors that diverge significantly from real-world physics and semantics,
degrading their performance when deployed. Thus, verifying the alignment
between the fine-grained instruction and the generated scene is essential for
effective learning. However, current evaluation methods, such as CLIPScore and
vision-language models (VLMs), often fail to reliably assess such alignment.
This shortcoming arises primarily from their shallow understanding of 3D
scenes, which often leads to improperly grounded scene components. To address
this, we introduce LEGO-Eval, an evaluation framework equipped with diverse
tools designed to explicitly ground scene components, enabling more accurate
alignment assessments. We also present LEGO-Bench, a benchmark of detailed
instructions that specify complex layouts and attributes of real-world
environments. Experiments demonstrate that LEGO-Eval outperforms VLM-as-a-judge
by 0.41 F1 score in assessing scene-instruction alignment. Benchmarking with
LEGO-Bench reveals significant limitations in current generation methods.
Across all evaluated approaches, success rates reached at most 10% in
generating scenes that fully align with fine-grained instructions.

</details>


### [4] [Targeted Error Correction in Knowledge Distillation: Small Language Models Surpass GPT](https://arxiv.org/abs/2511.03005)
*Hee-Jin Lee,Zhen Guo,Luchao Jin,Morteza Moazami Goudarzi*

Main category: cs.CL

TL;DR: 提出了Analyze-Revise-Finetune (ARF)流程，使小型开源语言模型在客户服务摘要任务中超过大型专有模型。


<details>
  <summary>Details</summary>
Motivation: 提升小型开源语言模型在生成高质量摘要任务中的表现，降低依赖昂贵且难以控制的专有模型，同时提高数据隐私和成本效率。

Method: 通过分析教师模型（GPT-3.5）生成摘要中的常见错误，使用紧凑的编辑模型（Llama 3.1 70B）对摘要进行针对性修正，生成高质量训练数据；然后用这些数据对小型学生模型（Llama 3.1 8B）进行微调。

Result: 经过微调的小型学生模型在客户服务摘要任务中表现优于GPT-3.5。

Conclusion: ARF流程不仅改善了开源小型模型的摘要性能，同时提高了成本效率和数据隐私，具有广泛应用潜力。

Abstract: We introduce an Analyze-Revise-Finetune (ARF) pipeline that enables smaller
open-source language models (LLMs) to surpass substantially larger proprietary
models in customer service summarization tasks. The pipeline first analyzes and
categorizes common errors in summaries produced by a teacher model (GPT-3.5),
then performs a targeted revision using a compact editor model (Llama 3.1 70B)
to generate high-quality, refined training data. Fine-tuning a smaller student
model (Llama 3.1 8B) on this refined data resulted in superior summarization
performance compared to GPT-3.5. The ARF pipeline improves cost efficiency and
data privacy while maintaining competitive accuracy, illustrating a
generalizable framework for enhancing open-source LLMs across diverse
downstream applications.

</details>


### [5] [Data-Efficient Adaptation and a Novel Evaluation Method for Aspect-based Sentiment Analysis](https://arxiv.org/abs/2511.03034)
*Yan Cathy Hua,Paul Denny,Jörg Wicker,Katerina Taškova*

Main category: cs.CL

TL;DR: 本论文提出了一种适应细微边界变动的评价方法（FTS-OBP），使用小型生成模型进行教育评价领域的ABSA任务，并首次发布该领域的公共数据资源。


<details>
  <summary>Details</summary>
Motivation: ABSA研究资源集中在商业领域，教育和医疗等高需求低资源领域缺乏有效资源与方法，且传统评测方法过于严格，不适合生成模型表现评估。

Method: 设计了一种灵活的文本相似度匹配和最优二分配对评价方法（FTS-OBP）；研究小于7B参数的小型解码器生成模型，探索无数据和轻量级微调方法，提出多任务微调策略。

Result: FTS-OBP方法能适应抽取边界变动，评估更合理；多任务微调使1.5-3.8B参数模型性能超越大型专有模型，仅需少量训练数据；并发布了教育评论ABSA公开资源。

Conclusion: 该工作有效推动了低资源领域ABSA研究，提升了小模型性能，提供了更合理的评测方法和基础的数据支持。

Abstract: Aspect-based Sentiment Analysis (ABSA) is a fine-grained opinion mining
approach that identifies and classifies opinions associated with specific
entities (aspects) or their categories within a sentence. Despite its rapid
growth and broad potential, ABSA research and resources remain concentrated in
commercial domains, leaving analytical needs unmet in high-demand yet
low-resource areas such as education and healthcare. Domain adaptation
challenges and most existing methods' reliance on resource-intensive
in-training knowledge injection further hinder progress in these areas.
Moreover, traditional evaluation methods based on exact matches are overly
rigid for ABSA tasks, penalising any boundary variations which may misrepresent
the performance of generative models. This work addresses these gaps through
three contributions: 1) We propose a novel evaluation method, Flexible Text
Similarity Matching and Optimal Bipartite Pairing (FTS-OBP), which accommodates
realistic extraction boundary variations while maintaining strong correlation
with traditional metrics and offering fine-grained diagnostics. 2) We present
the first ABSA study of small decoder-only generative language models (SLMs;
<7B parameters), examining resource lower bounds via a case study in education
review ABSA. We systematically explore data-free (in-context learning and
weight merging) and data-light fine-tuning methods, and propose a multitask
fine-tuning strategy that significantly enhances SLM performance, enabling
1.5-3.8 B models to surpass proprietary large models and approach benchmark
results with only 200-1,000 examples on a single GPU. 3) We release the first
public set of education review ABSA resources to support future research in
low-resource domains.

</details>


### [6] [ROBoto2: An Interactive System and Dataset for LLM-assisted Clinical Trial Risk of Bias Assessment](https://arxiv.org/abs/2511.03048)
*Anthony Hevia,Sanjana Chintalapati,Veronica Ka Wai Lai,Thanh Tam Nguyen,Wai-Tat Wong,Terry Klassen,Lucy Lu Wang*

Main category: cs.CL

TL;DR: ROBOTO2是一个基于网络的开源平台，利用大型语言模型辅助临床试验风险偏倚评估，简化了繁琐的ROB2注释流程。


<details>
  <summary>Details</summary>
Motivation: 传统的风险偏倚评估过程劳动强度大且耗时，亟需一种高效且可交互的自动化工具以提高评估效率和质量。

Method: 开发了ROBOTO2平台，结合PDF解析、增强检索的LLM提示和人机交互反馈，支持用户上传临床试验报告并获取初步评估和证据，同时允许实时修正系统建议。

Result: 发布了包含521个儿科临床试验报告的标注数据集，基于手工和LLM辅助方法，作为基准用于评估四种LLM在ROB2任务的表现，并分析了自动化过程中的优势和挑战。

Conclusion: ROBOTO2平台和数据集促进了ROB2风险偏倚评估的自动化研究，有助于系统评价领域提高效率和准确性，同时推动相关技术的进一步发展。

Abstract: We present ROBOTO2, an open-source, web-based platform for large language
model (LLM)-assisted risk of bias (ROB) assessment of clinical trials. ROBOTO2
streamlines the traditionally labor-intensive ROB v2 (ROB2) annotation process
via an interactive interface that combines PDF parsing, retrieval-augmented LLM
prompting, and human-in-the-loop review. Users can upload clinical trial
reports, receive preliminary answers and supporting evidence for ROB2 signaling
questions, and provide real-time feedback or corrections to system suggestions.
ROBOTO2 is publicly available at https://roboto2.vercel.app/, with code and
data released to foster reproducibility and adoption. We construct and release
a dataset of 521 pediatric clinical trial reports (8954 signaling questions
with 1202 evidence passages), annotated using both manually and LLM-assisted
methods, serving as a benchmark and enabling future research. Using this
dataset, we benchmark ROB2 performance for 4 LLMs and provide an analysis into
current model capabilities and ongoing challenges in automating this critical
aspect of systematic review.

</details>


### [7] [Reading Between the Lines: The One-Sided Conversation Problem](https://arxiv.org/abs/2511.03056)
*Victoria Ebert,Rishabh Singh,Tuochao Chen,Noah A. Smith,Shyamnath Gollakota*

Main category: cs.CL

TL;DR: 该论文研究了一种仅能访问对话一方的对话问题，提出了缺失对话重建和摘要生成两项任务。通过实验发现，提供未来对话信息和话语长度有助于重建效果，大模型通过提示能生成较好结果，小模型需微调。高质量摘要可在不重建缺失对话的情况下生成。


<details>
  <summary>Details</summary>
Motivation: 现实场景中存在只能采集对话一方数据的情况，如远程医疗、呼叫中心，如何有效利用这些数据推动对话AI发展是关键。

Method: 形式化定义一方对话问题，设计缺失发言重建和摘要生成任务，利用多数据集进行提示和微调模型训练及评估，结合人工A/B测试和大模型评判指标。

Result: 证明访问未来一轮对话和发言长度提升重建效果，placeholder提示减轻幻觉现象，大模型提示效果好，小模型需微调，且无需重建缺失发言即可生成高质量摘要。

Conclusion: 提出一方对话问题作为新挑战，相关方法取得有希望的效果，推动隐私保护的对话AI研究。

Abstract: Conversational AI is constrained in many real-world settings where only one
side of a dialogue can be recorded, such as telemedicine, call centers, and
smart glasses. We formalize this as the one-sided conversation problem (1SC):
inferring and learning from one side of a conversation. We study two tasks: (1)
reconstructing the missing speaker's turns for real-time use cases, and (2)
generating summaries from one-sided transcripts. Evaluating prompting and
finetuned models on MultiWOZ, DailyDialog, and Candor with both human A/B
testing and LLM-as-a-judge metrics, we find that access to one future turn and
information about utterance length improves reconstruction, placeholder
prompting helps to mitigate hallucination, and while large models generate
promising reconstructions with prompting, smaller models require finetuning.
Further, high-quality summaries can be generated without reconstructing missing
turns. We present 1SC as a novel challenge and report promising results that
mark a step toward privacy-aware conversational AI.

</details>


### [8] [PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech](https://arxiv.org/abs/2511.03080)
*Michel Wong,Ali Alshehri,Sophia Kao,Haotian He*

Main category: cs.CL

TL;DR: 提出了PolyNorm，一种基于大语言模型的文本规范化方法，减少人工规则依赖，提升多语言适用性。


<details>
  <summary>Details</summary>
Motivation: 传统文本规范化系统工程复杂、难以扩展且多语言支持不足，尤其在低资源语言中表现不佳。

Method: 利用大语言模型的提示（prompt）技术实现文本规范化，辅以一种语言无关的数据整理和评估流水线，支持多语言规模化实验。

Result: 在八种语言的实验中，PolyNorm在词错误率（WER）方面均优于现有生产级系统。

Conclusion: PolyNorm显著降低了文本规范化的工程复杂性和语言限制，促进了多语言文本规范化研究的发展，并公开了相关多语言基准数据集。

Abstract: Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS)
systems, converting written forms into their canonical spoken equivalents.
Traditional TN systems can exhibit high accuracy, but involve substantial
engineering effort, are difficult to scale, and pose challenges to language
coverage, particularly in low-resource settings. We propose PolyNorm, a
prompt-based approach to TN using Large Language Models (LLMs), aiming to
reduce the reliance on manually crafted rules and enable broader linguistic
applicability with minimal human intervention. Additionally, we present a
language-agnostic pipeline for automatic data curation and evaluation, designed
to facilitate scalable experimentation across diverse languages. Experiments
across eight languages show consistent reductions in the word error rate (WER)
compared to a production-grade-based system. To support further research, we
release PolyNorm-Benchmark, a multilingual data set covering a diverse range of
text normalization phenomena.

</details>


### [9] [A Computational Approach to Analyzing Disrupted Language in Schizophrenia: Integrating Surprisal and Coherence Measures](https://arxiv.org/abs/2511.03089)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: cs.CL

TL;DR: 本文利用计算语言学方法，探讨精神分裂症患者语言中意外性和语义连贯性的变化，以揭示语言混乱与症状严重程度的关系。


<details>
  <summary>Details</summary>
Motivation: 精神分裂症患者的语言紊乱表现为语义混乱和讲话不连贯，这些症状反映认知功能障碍，有潜力作为客观诊断标识。

Method: 利用计算模型计算语言的意外性（surprisal）和语义连贯性，对比精神分裂症患者与健康对照组的语言特征。

Result: 发现两组在语言的意外性和语义连贯性上存在显著差异，这些差异与症状严重程度相关。

Conclusion: 计算语言学指标如意外性和语义连贯性可有效表征精神分裂症患者语言障碍，具有潜在的诊断价值。

Abstract: Language disruptions are one of the well-known effects of schizophrenia
symptoms. They are often manifested as disorganized speech and impaired
discourse coherence. These abnormalities in spontaneous language production
reflect underlying cognitive disturbances and have the potential to serve as
objective markers for symptom severity and diagnosis of schizophrenia. This
study focuses on how these language disruptions can be characterized in terms
of two computational linguistic measures: surprisal and semantic coherence. By
computing surprisal and semantic coherence of language using computational
models, this study investigates how they differ between subjects with
schizophrenia and healthy controls. Furthermore, this study provides further
insight into how language disruptions in terms of these linguistic measures
change with varying degrees of schizophrenia symptom severity.

</details>


### [10] [CARMA: Comprehensive Automatically-annotated Reddit Mental Health Dataset for Arabic](https://arxiv.org/abs/2511.03102)
*Saad Mankarious,Ayah Zirikly*

Main category: cs.CL

TL;DR: 本文首次提出了用于阿拉伯语心理健康检测的自动标注大型数据集CARMA，包含六种心理健康状况及对照组，规模和多样性超越现有资源。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语心理健康检测因数据不足和文化污名面临重大挑战，现有研究多集中在英语，亟需克服资源限制。

Method: 构建并自动标注阿拉伯语Reddit帖子数据集，涵盖六种心理健康疾病，进行词汇和语义差异分析，验证多种分类模型效果。

Result: 数据集在规模和多样性上领先，揭示了不同心理健康状况用户的语言特征，分类实验表明数据集有助于提升检测性能。

Conclusion: CARMA数据集为阿拉伯语心理健康研究提供了重要资源，推动了该领域自动检测技术的发展。

Abstract: Mental health disorders affect millions worldwide, yet early detection
remains a major challenge, particularly for Arabic-speaking populations where
resources are limited and mental health discourse is often discouraged due to
cultural stigma. While substantial research has focused on English-language
mental health detection, Arabic remains significantly underexplored, partly due
to the scarcity of annotated datasets. We present CARMA, the first
automatically annotated large-scale dataset of Arabic Reddit posts. The dataset
encompasses six mental health conditions, such as Anxiety, Autism, and
Depression, and a control group. CARMA surpasses existing resources in both
scale and diversity. We conduct qualitative and quantitative analyses of
lexical and semantic differences between users, providing insights into the
linguistic markers of specific mental health conditions. To demonstrate the
dataset's potential for further mental health analysis, we perform
classification experiments using a range of models, from shallow classifiers to
large language models. Our results highlight the promise of advancing mental
health detection in underrepresented languages such as Arabic.

</details>


### [11] [Control Barrier Function for Aligning Large Language Models](https://arxiv.org/abs/2511.03121)
*Yuya Miyaoka,Masaki Inoue*

Main category: cs.CL

TL;DR: 本文提出了一种基于控制的框架，利用控制屏障函数(CBF)确保大语言模型生成符合用户期望的文本。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型生成文本时难以直接通过微调实现对齐的问题，希望通过外部安全过滤机制实现对齐。

Method: 在基线大语言模型生成的预测词元上应用CBF安全过滤器进行干预，安全过滤器可作为附加组件使用，无需微调模型且能直接利用现有评价模型设计。

Result: 采用开源语言模型完成文本生成系统，实现了生成积极正面的文本。

Conclusion: 提出的基于控制屏障函数的安全过滤框架，为大语言模型的对齐提供了一种无需微调、可灵活应用的有效方法。

Abstract: This paper proposes a control-based framework for aligning large language
models (LLMs) by leveraging a control barrier function (CBF) to ensure
user-desirable text generation. The presented framework applies the CBF safety
filter to the predicted token generated from the baseline LLM, to intervene in
the generated text. The safety filter includes two significant advantages: this
safety filter is an add-on type, allowing it to be used for alignment purposes
without fine-tuning the baseline LLM, and if there is an evaluation model
regarding the desired alignment, it can be directly applied to the filter
design. The overall text-generation system is implemented with open-source
language models, aiming to generate positive text.

</details>


### [12] [MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity](https://arxiv.org/abs/2511.03146)
*Kaiyuan Zhang,Chenghao Yang,Zhoufutu Wen,Sihang Yuan,Qiuyue Wang,Chaoyi Huang,Guosheng Zhu,He Wang,Huawenyu Lu,Jianing Wen,Jianpeng Jiao,Lishu Luo,Longxiang Liu,Sijin Wu,Xiaolei Zhu,Xuanliang Zhang,Ge Zhang,Yi Lin,Guang Shi,Chaoyou Fu,Wenhao Huang*

Main category: cs.CL

TL;DR: 该论文提出了多模态认知能力评估基准MME-CC，系统测评多模态大模型在空间、几何和知识推理上的认知表现，揭示当前模型在空间和几何推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多模态评测过于强调文本推理，缺乏对视觉中心认知能力的系统评估，导致多模态大模型认知能力测评不足。

Method: 设计基于视觉的MME-CC评测基准，涵盖11个推理任务，分为空间、几何和基于知识三类，并对16种多模态大模型进行详尽测试和误差分析。

Result: 实验显示闭源模型表现领先，但空间和几何推理均较弱（<=30%），常见问题包括方向错误、跨视角身份判别脆弱及反事实指令执行不佳，思维链过程依赖视觉提取。

Conclusion: 呼吁将多模态大模型的认知能力作为评测和设计的核心，推动模型在视觉认知推理方面的改进。

Abstract: As reasoning models scale rapidly, the essential role of multimodality in
human cognition has come into sharp relief, driving a growing need to probe
vision-centric cognitive behaviors. Yet, existing multimodal benchmarks either
overemphasize textual reasoning or fall short of systematically capturing
vision-centric cognitive behaviors, leaving the cognitive capacity of MLLMs
insufficiently assessed. To address this limitation, we introduce MME-CC
(Multi-Modal Evaluation benchmark of Cognitive Capacity), a vision-grounded
benchmark that organizes 11 representative reasoning tasks into three
fundamental categories of visual information: spatial, geometric, and
knowledge-based reasoning, and provides fine-grained analyses of MLLMs'
cognitive capacity across these dimensions. Based on MME-CC, we conduct
extensive experiments over 16 representative MLLMs. Our study reveals that
closed-source models currently lead overall (e.g., 42.66 for Gemini-2.5-Pro vs.
30.45 for GLM-4.5V), while spatial and geometric reasoning remain broadly weak
(less than or equal to 30%). We further identify common error patterns,
including orientation mistakes, fragile cross-view identity persistence, and
poor adherence to counterfactual instructions, and observe that
Chain-of-Thought typically follows a three-stage process (extract -> reason ->
verify) with heavy reliance on visual extraction. We hope this work catalyzes a
shift toward treating the cognitive capacity of MLLMs as central to both
evaluation and model design.

</details>


### [13] [Who Sees the Risk? Stakeholder Conflicts and Explanatory Policies in LLM-based Risk Assessment](https://arxiv.org/abs/2511.03152)
*Srishti Yadav,Jasmina Gajcin,Erik Miehling,Elizabeth Daly*

Main category: cs.CL

TL;DR: 本文提出一种基于大语言模型（LLMs）的利益相关者风险评估框架，通过生成解释性政策，揭示不同利益相关者对AI系统风险的看法差异。


<details>
  <summary>Details</summary>
Motivation: 为了实现AI系统的负责任部署，理解不同利益相关者如何感知风险至关重要。

Method: 使用Risk Atlas Nexus和GloVE解释方法，让LLMs作为评判者预测并解释风险，生成针对不同利益相关者的可解释政策，并通过交互式可视化展示利益相关者间怎样产生冲突。

Result: 通过医疗AI、自动驾驶和诈骗检测三个实际案例，展示不同利益相关者的风险感知及冲突模式存在显著差异。

Conclusion: 强调利益相关者视角下的解释对提升LLM评估的透明性、可解释性以及促进以人为本的AI治理目标的重要性。

Abstract: Understanding how different stakeholders perceive risks in AI systems is
essential for their responsible deployment. This paper presents a framework for
stakeholder-grounded risk assessment by using LLMs, acting as judges to predict
and explain risks. Using the Risk Atlas Nexus and GloVE explanation method, our
framework generates stakeholder-specific, interpretable policies that shows how
different stakeholders agree or disagree about the same risks. We demonstrate
our method using three real-world AI use cases of medical AI, autonomous
vehicles, and fraud detection domain. We further propose an interactive
visualization that reveals how and why conflicts emerge across stakeholder
perspectives, enhancing transparency in conflict reasoning. Our results show
that stakeholder perspectives significantly influence risk perception and
conflict patterns. Our work emphasizes the importance of these
stakeholder-aware explanations needed to make LLM-based evaluations more
transparent, interpretable, and aligned with human-centered AI governance
goals.

</details>


### [14] [Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks](https://arxiv.org/abs/2511.03166)
*Kevin Wang,Subre Abdoul Moktar,Jia Li,Kangshuo Li,Feng Chen*

Main category: cs.CL

TL;DR: 本文对12种不确定性估计（UE）方法在大型语言模型（LLMs）输出的可信度评估中进行了全面的实证研究，针对问答任务中的内部分布与外部分布数据，考察了各方法对两种不确定性的表现。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型应用日益广泛，确保其输出结果的可信性成为关键，不确定性估计在评估模型输出可信度中发挥重要作用。

Method: 研究涵盖12种不同不确定性估计方法，结合四种生成质量指标（包括LLMScore），在问答任务的内分布（ID）和外分布（OOD）数据集上评估LLM生成答案的不确定性表现。

Result: 信息基方法在内部分布场景表现优异，反映模型对数据的理解；密度基方法及P(True)指标在外部分布环境表现较好，突显在捕捉模型知识性不确定性方面的优势；语义一致性方法跨数据集和指标表现稳定，但并非所有情况最优。

Conclusion: 不同类别的不确定性估计方法各自在特定情境下表现突出，提示实际应用中需根据任务特点选择合适的UE方法以提升LLM输出的可信度。

Abstract: Large Language Models (LLMs) have become increasingly pervasive, finding
applications across many industries and disciplines. Ensuring the
trustworthiness of LLM outputs is paramount, where Uncertainty Estimation (UE)
plays a key role. In this work, a comprehensive empirical study is conducted to
examine the robustness and effectiveness of diverse UE measures regarding
aleatoric and epistemic uncertainty in LLMs. It involves twelve different UE
methods and four generation quality metrics including LLMScore from LLM
criticizers to evaluate the uncertainty of LLM-generated answers in
Question-Answering (QA) tasks on both in-distribution (ID) and
out-of-distribution (OOD) datasets. Our analysis reveals that information-based
methods, which leverage token and sequence probabilities, perform exceptionally
well in ID settings due to their alignment with the model's understanding of
the data. Conversely, density-based methods and the P(True) metric exhibit
superior performance in OOD contexts, highlighting their effectiveness in
capturing the model's epistemic uncertainty. Semantic consistency methods,
which assess variability in generated answers, show reliable performance across
different datasets and generation metrics. These methods generally perform well
but may not be optimal for every situation.

</details>


### [15] [BengaliMoralBench: A Benchmark for Auditing Moral Reasoning in Large Language Models within Bengali Language and Culture](https://arxiv.org/abs/2511.03180)
*Shahriyar Zaman Ridoy,Azmine Toushik Wasi,Koushik Ahamed Tonmoy*

Main category: cs.CL

TL;DR: 本文介绍了首个针对孟加拉语及其社会文化背景的大规模伦理评测基准BengaliMoralBench，涵盖五个道德领域，通过三种伦理视角标注，并对多语言大模型进行零样本评测，发现模型在文化适应性和道德公平性上存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大模型在南亚地区应用增长，但现有伦理评测主要基于西方英语框架，忽视了孟加拉语文化背景和伦理规范，难以满足实际部署需求。

Method: 构建涵盖日常活动、习惯、育儿、家庭关系和宗教活动五大领域、50个子主题的伦理评测基准，采用本土母语者共识标注三种伦理视角（美德、常识、正义）；对多款知名多语言大模型进行统一提示下的零样本评测。

Result: 模型表现差异显著，准确率介于50%-91%之间。定性分析显示模型在文化基础、常识推理及道德公平性方面存在一致弱点。

Conclusion: BengaliMoralBench为负责任的本地化提供基础，促进文化适配的伦理评测，支持在孟加拉国等资源匮乏多语言环境中部署伦理健全的人工智能系统。

Abstract: As multilingual Large Language Models (LLMs) gain traction across South Asia,
their alignment with local ethical norms, particularly for Bengali, which is
spoken by over 285 million people and ranked 6th globally, remains
underexplored. Existing ethics benchmarks are largely English-centric and
shaped by Western frameworks, overlooking cultural nuances critical for
real-world deployment. To address this, we introduce BengaliMoralBench, the
first large-scale ethics benchmark for the Bengali language and socio-cultural
contexts. It covers five moral domains, Daily Activities, Habits, Parenting,
Family Relationships, and Religious Activities, subdivided into 50 culturally
relevant subtopics. Each scenario is annotated via native-speaker consensus
using three ethical lenses: Virtue, Commonsense, and Justice ethics. We conduct
systematic zero-shot evaluation of prominent multilingual LLMs, including
Llama, Gemma, Qwen, and DeepSeek, using a unified prompting protocol and
standard metrics. Performance varies widely (50-91% accuracy), with qualitative
analysis revealing consistent weaknesses in cultural grounding, commonsense
reasoning, and moral fairness. BengaliMoralBench provides a foundation for
responsible localization, enabling culturally aligned evaluation and supporting
the deployment of ethically robust AI in diverse, low-resource multilingual
settings such as Bangladesh.

</details>


### [16] [LGM: Enhancing Large Language Models with Conceptual Meta-Relations and Iterative Retrieval](https://arxiv.org/abs/2511.03214)
*Wenchang Lei,Ping Zou,Yue Wang,Feng Sun,Lei Zhao*

Main category: cs.CL

TL;DR: 提出了语言图模型（LGM）通过提取元关系和动态检索提高大语言模型处理模糊和概念错配指令的能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理含糊或概念不对齐的用户指令时表现欠佳，需提升其概念理解的清晰度。

Method: 构建语言图模型提取继承、别名和组合等元关系，运用反思机制验证关系，并用概念迭代检索算法动态提供信息给模型。

Result: 实验结果显示LGM在多个标准基准测试中持续优于现有的基于检索增强生成（RAG）的方法。

Conclusion: LGM方法有效提升了大语言模型的语义理解和响应准确性，且可处理任意长度文本，克服了传统RAG对上下文窗口长度的限制。

Abstract: Large language models (LLMs) exhibit strong semantic understanding, yet
struggle when user instructions involve ambiguous or conceptually misaligned
terms. We propose the Language Graph Model (LGM) to enhance conceptual clarity
by extracting meta-relations-inheritance, alias, and composition-from natural
language. The model further employs a reflection mechanism to validate these
meta-relations. Leveraging a Concept Iterative Retrieval Algorithm, these
relations and related descriptions are dynamically supplied to the LLM,
improving its ability to interpret concepts and generate accurate responses.
Unlike conventional Retrieval-Augmented Generation (RAG) approaches that rely
on extended context windows, our method enables large language models to
process texts of any length without the need for truncation. Experiments on
standard benchmarks demonstrate that the LGM consistently outperforms existing
RAG baselines.

</details>


### [17] [Hybrid Fact-Checking that Integrates Knowledge Graphs, Large Language Models, and Search-Based Retrieval Agents Improves Interpretable Claim Verification](https://arxiv.org/abs/2511.03217)
*Shaghayegh Kolli,Richard Rosenbaum,Timo Cavelius,Lasse Strothe,Andrii Lata,Jana Diesner*

Main category: cs.CL

TL;DR: 本文提出了一种集成大型语言模型、知识图谱和实时搜索代理的混合事实核查方法，显著提升了准确率和证据覆盖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然生成流畅文本能力强，但缺乏可靠的事实依据，而知识图谱事实核查虽精确且可解释，但存在覆盖率和时效性不足的问题，促使作者结合两者优势以提高事实核查性能。

Method: 设计了包含三步骤的自动化流水线：基于DBpedia的快速知识图谱一跳检索；利用任务特定提示进行语言模型分类及规则逻辑推理；以及在知识图谱信息不足时调用实时网页搜索代理。

Result: 该方法在FEVER数据集的Supported/Refuted分类任务上实现了0.93的F1分数，无需任务特定微调；针对信息不足的情况，通过重新标注研究发现系统能发现更多有效证据，得到专家及LLM审核者确认。

Conclusion: 本文提出了一个模块化且开源的事实核查系统，结合了多种策略以提升泛化能力和覆盖率，为事实核查提供了可解释、高效且灵活的解决方案。

Abstract: Large language models (LLMs) excel in generating fluent utterances but can
lack reliable grounding in verified information. At the same time,
knowledge-graph-based fact-checkers deliver precise and interpretable evidence,
yet suffer from limited coverage or latency. By integrating LLMs with knowledge
graphs and real-time search agents, we introduce a hybrid fact-checking
approach that leverages the individual strengths of each component. Our system
comprises three autonomous steps: 1) a Knowledge Graph (KG) Retrieval for rapid
one-hop lookups in DBpedia, 2) an LM-based classification guided by a
task-specific labeling prompt, producing outputs with internal rule-based
logic, and 3) a Web Search Agent invoked only when KG coverage is insufficient.
Our pipeline achieves an F1 score of 0.93 on the FEVER benchmark on the
Supported/Refuted split without task-specific fine-tuning. To address Not
enough information cases, we conduct a targeted reannotation study showing that
our approach frequently uncovers valid evidence for claims originally labeled
as Not Enough Information (NEI), as confirmed by both expert annotators and LLM
reviewers. With this paper, we present a modular, opensource fact-checking
pipeline with fallback strategies and generalization across datasets.

</details>


### [18] [Beyond Ranked Lists: The SARAL Framework for Cross-Lingual Document Set Retrieval](https://arxiv.org/abs/2511.03228)
*Shantanu Agarwal,Joel Barry,Elizabeth Boschee,Scott Miller*

Main category: cs.CL

TL;DR: 本论文介绍了ISI团队在IARPA的MATERIAL项目中为跨语言信息检索开发的创新方法，特别是注重检索相关文档集。SARAL系统在三种语言的六个评估条件中取得了五个最佳成绩。


<details>
  <summary>Details</summary>
Motivation: 提升跨语言信息检索能力，满足在不同语言中检索相关文档集的需求。

Method: 开发了一种新颖的方法，强调检索查询相关的文档集而非单一排名文档列表。

Result: 在MATERIAL第三阶段评估中，SARAL系统在五个评估条件中表现优于其他团队，覆盖波斯语、哈萨克语和格鲁吉亚语三种语言。

Conclusion: SARAL的创新跨语言信息检索方法显著提升了检索效果，验证了其在多语言环境中的有效性。

Abstract: Machine Translation for English Retrieval of Information in Any Language
(MATERIAL) is an IARPA initiative targeted to advance the state of
cross-lingual information retrieval (CLIR). This report provides a detailed
description of Information Sciences Institute's (ISI's) Summarization and
domain-Adaptive Retrieval Across Language's (SARAL's) effort for MATERIAL.
Specifically, we outline our team's novel approach to handle CLIR with emphasis
in developing an approach amenable to retrieve a query-relevant document
\textit{set}, and not just a ranked document-list. In MATERIAL's Phase-3
evaluations, SARAL exceeded the performance of other teams in five out of six
evaluation conditions spanning three different languages (Farsi, Kazakh, and
Georgian).

</details>


### [19] [IndicSuperTokenizer: An Optimized Tokenizer for Indic Multilingual LLMs](https://arxiv.org/abs/2511.03237)
*Souvik Rana,Arul Menezes,Ashish Kulkarni,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 本文提出了一种针对印地语多语言大语言模型的新型分词器IndicSuperTokenizer，结合了子词和多词分词方法，并采用语言特定的预分词策略，实现了更符合语言特点的分词效果。


<details>
  <summary>Details</summary>
Motivation: 现有的子词分词方法如BPE虽然广泛使用，但在多语言尤其是印地语多语言环境下的表现尚未充分研究，设计高效分词器面临多样文字和丰富形态变化的挑战。

Method: 提出IndicSuperTokenizer，将子词分词和多词分词结合，配合语言特定的预分词策略，提升分词的语言相关性，并进行多方面消融实验验证设计的合理性。

Result: 在英语、22种印度语言和代码数据集上，IndicSuperTokenizer相较于LLaMA4和当前最优Sutra，分别提升平均生育分数39.5%和18%，推理吞吐率提升44%，且保持了性能的可比性。

Conclusion: IndicSuperTokenizer通过创新分词设计显著提升了多语言大语言模型的分词质量和推理效率，证明了结合多种分词策略和预处理方法的有效性。

Abstract: Tokenizers play a crucial role in determining the performance, training
efficiency, and the inference cost of Large Language Models (LLMs). Designing
effective tokenizers for multilingual LLMs is particularly challenging due to
diverse scripts and rich morphological variation. While subword methods such as
Byte Pair Encoding (BPE) are widely adopted, their effectiveness in
multilingual settings remains underexplored. We present IndicSuperTokenizer, a
tokenizer for Indic multilingual LLMs, that combines both subword and
multi-word tokenization, along with language-specific pre-tokenization, leading
to more linguistically aligned tokens and achieving a new state-of-the-art in
fertility score. Evaluated across English, 22 Indian languages and code data,
our tokenizer improves the average fertility score by 39.5% over LLaMA4 and by
18% over Sutra (the current best). This translates to 44% improvement in
inference throughput over LLaMA4 while maintaining comparable performance on
English and Indic benchmarks. We also present detailed ablations across
tokenizer training data size, vocabulary size, merging techniques, and
pre-tokenization strategies, demonstrating the robustness of our design
choices.

</details>


### [20] [Comparing the Performance of LLMs in RAG-based Question-Answering: A Case Study in Computer Science Literature](https://arxiv.org/abs/2511.03261)
*Ranul Dayarathne,Uvini Ranaweera,Upeksha Ganegoda*

Main category: cs.CL

TL;DR: 本研究比较了四个开源大语言模型和GPT-3.5在计算机科学文献问答任务中的表现，均使用检索增强生成（RAG）技术。结果显示GPT-3.5表现最佳，Mistral-7b-instruct在开源模型中表现优异，Orca-mini-v3-7b响应最快，LLaMa2-7b-chat响应最慢。


<details>
  <summary>Details</summary>
Motivation: 由于检索增强生成（RAG）技术能有效减少生成式人工智能模型中的幻觉现象，研究者们对不同大语言模型（LLM）在多领域问答任务中的表现比较产生了兴趣。特别是在计算机科学文献领域，明确哪种模型在RAG支持下表现更优具有实际意义。

Method: 本研究选取了四个开源LLM（Mistral-7b-instruct、LLaMa2-7b-chat、Falcon-7b-instruct、Orca-mini-v3-7b）和GPT-3.5，搭配RAG技术在计算机科学文献问答任务中进行对比。评价指标包括二元问题的准确率和精确率、由人工专家和谷歌AI模型Gemini提供的排序，以及长答案问题的余弦相似度。

Result: GPT-3.5结合RAG在二元和长答案问答上表现最佳，Mistral-7b-instruct在开源模型中表现领先。Orca-mini-v3-7b响应速度最快，LLaMa2-7b-chat响应速度最慢。

Conclusion: 研究表明，在RAG技术的加持下，开源大语言模型在问答任务中已可与商业模型如GPT-3.5媲美，且部分开源模型在响应速度和多样性方面具备优势，显示出良好应用前景。

Abstract: Retrieval Augmented Generation (RAG) is emerging as a powerful technique to
enhance the capabilities of Generative AI models by reducing hallucination.
Thus, the increasing prominence of RAG alongside Large Language Models (LLMs)
has sparked interest in comparing the performance of different LLMs in
question-answering (QA) in diverse domains. This study compares the performance
of four open-source LLMs, Mistral-7b-instruct, LLaMa2-7b-chat,
Falcon-7b-instruct and Orca-mini-v3-7b, and OpenAI's trending GPT-3.5 over QA
tasks within the computer science literature leveraging RAG support. Evaluation
metrics employed in the study include accuracy and precision for binary
questions and ranking by a human expert, ranking by Google's AI model Gemini,
alongside cosine similarity for long-answer questions. GPT-3.5, when paired
with RAG, effectively answers binary and long-answer questions, reaffirming its
status as an advanced LLM. Regarding open-source LLMs, Mistral AI's
Mistral-7b-instruct paired with RAG surpasses the rest in answering both binary
and long-answer questions. However, among the open-source LLMs, Orca-mini-v3-7b
reports the shortest average latency in generating responses, whereas
LLaMa2-7b-chat by Meta reports the highest average latency. This research
underscores the fact that open-source LLMs, too, can go hand in hand with
proprietary models like GPT-3.5 with better infrastructure.

</details>


### [21] [SCALE: Upscaled Continual Learning of Large Language Models](https://arxiv.org/abs/2511.03270)
*Jin-woo Lee,Junhwa Choi,Bongkyu Hwang,Jinho Choo,Bogun Kim,JeongSeon Yi,Joonseok Lee,DongYoung Jung,Jaeseon Park,Kyoungwon Park,Suk-hoon Jung*

Main category: cs.CL

TL;DR: 本文提出了SCALE架构，通过宽度扩展和权重冻结实现大语言模型的连续预训练，解决了模型遗忘与新知识获取的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有连续预训练更多依赖参数扩展，忽视了结构扩展对性能提升的重要性，且容易导致严重遗忘，如何在扩容同时保持模型原有功能成为关键问题。

Method: 提出SCALE宽度扩展架构，利用保持预训练权重冻结和部分扩展组件训练的两大原则（持久保持与协同适应），设计了SCALE-Preserve、SCALE-Adapt及路由机制SCALE-Route，保持基础模型行为并有选择性地学习新知识。

Result: 在合成传记基准和韩语连续预训练任务中，SCALE架构显著减少了遗忘，同时保持或提升了新语言任务性能，展示了优异的稳定性与可塑性平衡。

Conclusion: 结构扩展配合权重冻结与部分学习，能有效缓解连续预训练中的遗忘问题，提升模型稳定性和适应性，展示了基于结构而非单纯参数扩展的新方向。

Abstract: We revisit continual pre-training for large language models and argue that
progress now depends more on scaling the right structure than on scaling
parameters alone. We introduce SCALE, a width upscaling architecture that
inserts lightweight expansion into linear modules while freezing all
pre-trained parameters. This preserves the residual and attention topologies
and increases capacity without perturbing the base model's original
functionality. SCALE is guided by two principles: Persistent Preservation,
which maintains the base model's behavior via preservation-oriented
initialization and freezing of the pre-trained weights, and Collaborative
Adaptation, which selectively trains a subset of expansion components to
acquire new knowledge with minimal interference. We instantiate these ideas as
SCALE-Preserve (preservation-first), SCALE-Adapt (adaptation-first), and
SCALE-Route, an optional routing extension that performs token-level routing
between preservation and adaptation heads. On a controlled synthetic biography
benchmark, SCALE mitigates the severe forgetting observed with depth expansion
while still acquiring new knowledge. In continual pre-training on a Korean
corpus, SCALE variants achieve less forgetting on English evaluations and
competitive gains on Korean benchmarks, with these variants offering the best
overall stability-plasticity trade-off. Accompanying analysis clarifies when
preservation provably holds and why the interplay between preservation and
adaptation stabilizes optimization compared to standard continual learning
setups.

</details>


### [22] [How to Evaluate Speech Translation with Source-Aware Neural MT Metrics](https://arxiv.org/abs/2511.03295)
*Mauro Cettolo,Marco Gaido,Matteo Negri,Sara Papi,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 本文研究了语音翻译(ST)系统的自动评价方法，提出了结合源音频信息的评价指标，扩展了机器翻译中基于源文本的神经评价方法到语音翻译领域。


<details>
  <summary>Details</summary>
Motivation: 传统的语音翻译评价主要基于参考翻译，忽视了源音频中的信息，且源音频难以直接使用，缺乏可靠的转录或对齐，影响评价准确性。

Method: 提出两种生成文本代理源音频的方法——自动语音识别(ASR)转录和参考翻译的反向翻译；设计了一种两步跨语言再分段算法解决合成源与参考翻译间的对齐不匹配问题；在多语言、多系统和不同性能水平的基准测试上验证方法。

Result: 实验结果表明，当ASR词错误率低于20%时，使用ASR转录作为合成源更可靠；反向翻译作为合成源计算成本低且效果依然有效；提出的跨语言再分段算法使得基于源的机器翻译指标在语音翻译评价中表现稳健。

Conclusion: 结合源音频信息的评价方法能够提高语音翻译的评价准确率，所提方法为语音翻译系统的更准确、原则化的评价奠定基础。

Abstract: Automatic evaluation of speech-to-text translation (ST) systems is typically
performed by comparing translation hypotheses with one or more reference
translations. While effective to some extent, this approach inherits the
limitation of reference-based evaluation that ignores valuable information from
the source input. In machine translation (MT), recent progress has shown that
neural metrics incorporating the source text achieve stronger correlation with
human judgments. Extending this idea to ST, however, is not trivial because the
source is audio rather than text, and reliable transcripts or alignments
between source and references are often unavailable. In this work, we conduct
the first systematic study of source-aware metrics for ST, with a particular
focus on real-world operating conditions where source transcripts are not
available. We explore two complementary strategies for generating textual
proxies of the input audio, automatic speech recognition (ASR) transcripts, and
back-translations of the reference translation, and introduce a novel two-step
cross-lingual re-segmentation algorithm to address the alignment mismatch
between synthetic sources and reference translations. Our experiments, carried
out on two ST benchmarks covering 79 language pairs and six ST systems with
diverse architectures and performance levels, show that ASR transcripts
constitute a more reliable synthetic source than back-translations when word
error rate is below 20%, while back-translations always represent a
computationally cheaper but still effective alternative. Furthermore, our
cross-lingual re-segmentation algorithm enables robust use of source-aware MT
metrics in ST evaluation, paving the way toward more accurate and principled
evaluation methodologies for speech translation.

</details>


### [23] [Benchmarking the Thinking Mode of Multimodal Large Language Models in Clinical Tasks](https://arxiv.org/abs/2511.03328)
*Jindong Hong,Tianjie Chen,Lingjie Luo,Chuanyang Zheng,Ting Xu,Haibao Yu,Jianing Qiu,Qianzhong Chen,Suning Huang,Yan Xu,Yong Gui,Yijun He,Jiankai Sun*

Main category: cs.CL

TL;DR: 该论文评估了具备“思考模式”与“非思考模式”双态功能的多模态大语言模型（MLLMs）在医学任务中的表现，发现“思考模式”提升有限，复杂医学任务表现仍欠佳。


<details>
  <summary>Details</summary>
Motivation: 随着具备内部思考控制的“推理MLLMs”的兴起，作者希望评估其在临床医学任务中的性能和可靠性。

Method: 选取了两款领先模型Seed1.5-VL和Gemini-2.5-Flash，在四个视觉医学任务上，使用VQA-RAD和ROCOv2数据集进行了性能测试。

Result: 发现激活“思考模式”对大多数任务的性能提升有限，在开放式视觉问答和医学图像解读等复杂任务中表现仍不理想。

Conclusion: 当前“推理MLLMs”的医学应用效果有限，需结合更多领域专属的医学数据和更先进的医学知识融合方法以提升性能。

Abstract: A recent advancement in Multimodal Large Language Models (MLLMs) research is
the emergence of "reasoning MLLMs" that offer explicit control over their
internal thinking processes (normally referred as the "thinking mode")
alongside the standard "non-thinking mode". This capability allows these models
to engage in a step-by-step process of internal deliberation before generating
a final response. With the rapid transition to and adoption of these
"dual-state" MLLMs, this work rigorously evaluated how the enhanced reasoning
processes of these MLLMs impact model performance and reliability in clinical
tasks. This paper evaluates the active "thinking mode" capabilities of two
leading MLLMs, Seed1.5-VL and Gemini-2.5-Flash, for medical applications. We
assessed their performance on four visual medical tasks using VQA-RAD and
ROCOv2 datasets. Our findings reveal that the improvement from activating the
thinking mode remains marginal compared to the standard non-thinking mode for
the majority of the tasks. Their performance on complex medical tasks such as
open-ended VQA and medical image interpretation remains suboptimal,
highlighting the need for domain-specific medical data and more advanced
methods for medical knowledge integration.

</details>


### [24] [Generative Artificial Intelligence in Bioinformatics: A Systematic Review of Models, Applications, and Methodological Advances](https://arxiv.org/abs/2511.03354)
*Riasad Alvi,Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Mohaimenul Azam Khan Raiaan,Saddam Mukta,Md Rafi Ur Rashid,Md Rafiqul Islam,Yakub Sebastian,Sami Azam*

Main category: cs.CL

TL;DR: 本文综述了生成式人工智能(GenAI)在生物信息学中的多样化应用及其优越性，强调了专业化模型在准确性和泛化能力上的优势。


<details>
  <summary>Details</summary>
Motivation: 为系统评估GenAI在生物信息学领域内的研究进展与应用效果，明确未来研究方向。

Method: 依据系统综述和元分析的方法设定六个研究问题，综述GenAI在基因组学、分子设计等领域的应用和表现。

Result: 发现专业化模型优于通用模型，在结构建模、功能预测等方面表现出色，识别出数据偏差和扩展性不足等限制。

Conclusion: GenAI在生物信息学中展现出较高的预测和集成能力，未来研究应关注模型的稳健性和生物学基础，利用多类型分子与细胞数据提升泛化能力。

Abstract: Generative artificial intelligence (GenAI) has become a transformative
approach in bioinformatics that often enables advancements in genomics,
proteomics, transcriptomics, structural biology, and drug discovery. To
systematically identify and evaluate these growing developments, this review
proposed six research questions (RQs), according to the preferred reporting
items for systematic reviews and meta-analysis methods. The objective is to
evaluate impactful GenAI strategies in methodological advancement, predictive
performance, and specialization, and to identify promising approaches for
advanced modeling, data-intensive discovery, and integrative biological
analysis. RQ1 highlights diverse applications across multiple bioinformatics
subfields (sequence analysis, molecular design, and integrative data modeling),
which demonstrate superior performance over traditional methods through pattern
recognition and output generation. RQ2 reveals that adapted specialized model
architectures outperformed general-purpose models, an advantage attributed to
targeted pretraining and context-aware strategies. RQ3 identifies significant
benefits in the bioinformatics domains, focusing on molecular analysis and data
integration, which improves accuracy and reduces errors in complex analysis.
RQ4 indicates improvements in structural modeling, functional prediction, and
synthetic data generation, validated by established benchmarks. RQ5 suggests
the main constraints, such as the lack of scalability and biases in data that
impact generalizability, and proposes future directions focused on robust
evaluation and biologically grounded modeling. RQ6 examines that molecular
datasets (such as UniProtKB and ProteinNet12), cellular datasets (such as
CELLxGENE and GTEx) and textual resources (such as PubMedQA and OMIM) broadly
support the training and generalization of GenAI models.

</details>


### [25] [Silenced Biases: The Dark Side LLMs Learned to Refuse](https://arxiv.org/abs/2511.03369)
*Rom Himelstein,Amit LeVi,Brit Youngmann,Yaniv Nemcovsky,Avi Mendelson*

Main category: cs.CL

TL;DR: 本文提出了"沉默偏见基准"（SBB），用于揭示安全对齐大语言模型中隐藏的偏见，这些偏见因模型的拒绝回答而被掩盖。通过激活引导减少拒绝，SBB能更准确评估模型公平性，并支持扩展到新的人群和主题。


<details>
  <summary>Details</summary>
Motivation: 现有的公平性评估主要依赖标准问答形式，且过分依赖模型拒绝回答来体现公平，导致隐藏的偏见被忽略，产生错误的公平感。

Method: 引入沉默偏见概念，利用激活引导技术减少模型拒绝回答，在问答过程中揭示隐藏的不公平偏好，设计可扩展的SBB评测框架。

Result: 在多个大型语言模型上，SBB揭示了模型直接回答与潜在公平性问题之间的显著差距，暴露了被安全对齐掩盖的偏见。

Conclusion: SBB为公平性评估提供了新视角，突破传统方法的局限，促进更公平模型和工具的发展，警示安全对齐模型的掩盖作用。

Abstract: Safety-aligned large language models (LLMs) are becoming increasingly
widespread, especially in sensitive applications where fairness is essential
and biased outputs can cause significant harm. However, evaluating the fairness
of models is a complex challenge, and approaches that do so typically utilize
standard question-answer (QA) styled schemes. Such methods often overlook
deeper issues by interpreting the model's refusal responses as positive
fairness measurements, which creates a false sense of fairness. In this work,
we introduce the concept of silenced biases, which are unfair preferences
encoded within models' latent space and are effectively concealed by
safety-alignment. Previous approaches that considered similar indirect biases
often relied on prompt manipulation or handcrafted implicit queries, which
present limited scalability and risk contaminating the evaluation process with
additional biases. We propose the Silenced Bias Benchmark (SBB), which aims to
uncover these biases by employing activation steering to reduce model refusals
during QA. SBB supports easy expansion to new demographic groups and subjects,
presenting a fairness evaluation framework that encourages the future
development of fair models and tools beyond the masking effects of alignment
training. We demonstrate our approach over multiple LLMs, where our findings
expose an alarming distinction between models' direct responses and their
underlying fairness issues.

</details>


### [26] [EQ-Negotiator: Dynamic Emotional Personas Empower Small Language Models for Edge-Deployable Credit Negotiation](https://arxiv.org/abs/2511.03370)
*Yunbo Long,Yuhan Liu,Alexandra Brintrup*

Main category: cs.CL

TL;DR: 本文提出了EQ-Negotiator框架，通过情感化人格桥接小型语言模型和大型语言模型在自动信用谈判中的性能差距，实现高效且隐私保护的智能谈判。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型性能强但计算资源和隐私需求高，不适合隐私敏感的边缘设备应用；小型语言模型在复杂情感角色扮演中表现不足，亟需提升性能。

Method: EQ-Negotiator结合博弈论和隐马尔可夫模型动态在线学习债务人情绪状态，赋能小型语言模型具备识别操控和化解冲突的策略智能，无需预训练。

Result: 在多种信用谈判模拟中，7B参数模型配备EQ-Negotiator在债务回收和谈判效率上超越10倍参数量的大型模型。

Conclusion: 动态情感策略智能比模型规模对自动谈判更关键，为隐私保护的边缘设备智能谈判代理提供了有效且伦理的解决方案。

Abstract: The deployment of large language models (LLMs) in automated negotiation has
set a high performance benchmark, but their computational cost and data privacy
requirements render them unsuitable for many privacy-sensitive, on-device
applications such as mobile assistants, embodied AI agents or private client
interactions. While small language models (SLMs) offer a practical alternative,
they suffer from a significant performance gap compared to LLMs in playing
emotionally charged complex personas, especially for credit negotiation. This
paper introduces EQ-Negotiator, a novel framework that bridges this capability
gap using emotional personas. Its core is a reasoning system that integrates
game theory with a Hidden Markov Model(HMM) to learn and track debtor emotional
states online, without pre-training. This allows EQ-Negotiator to equip SLMs
with the strategic intelligence to counter manipulation while de-escalating
conflict and upholding ethical standards. Through extensive agent-to-agent
simulations across diverse credit negotiation scenarios, including adversarial
debtor strategies like cheating, threatening, and playing the victim, we show
that a 7B parameter language model with EQ-Negotiator achieves better debt
recovery and negotiation efficiency than baseline LLMs more than 10 times its
size. This work advances persona modeling from descriptive character profiles
to dynamic emotional architectures that operate within privacy constraints.
Besides, this paper establishes that strategic emotional intelligence, not raw
model scale, is the critical factor for success in automated negotiation,
paving the way for effective, ethical, and privacy-preserving AI negotiators
that can operate on the edge.

</details>


### [27] [LFC-DA: Logical Formula-Controlled Data Augmentation for Enhanced Logical Reasoning](https://arxiv.org/abs/2511.03372)
*Shenghao Li*

Main category: cs.CL

TL;DR: 本文提出LFC-DA，一种符号逻辑控制的数据增强方法，通过将文本映射为命题表达式并利用状态空间搜索生成多样且严谨的逻辑数据，提高预训练模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有复杂逻辑数据增强方法依赖人工标注成本高，大语言模型直接生成的数据缺乏可解释性且逻辑单一。

Method: 设计符号逻辑控制的LFC-DA流程，将逻辑文本映射为命题表达式，构建紧凑规则库，采用有界状态空间搜索发现有效公式，再转换回自然语言问题，保证逻辑多样性和严谨性。

Result: 在ReClor和LogiQA数据集上，LFC-DA显著提升了预训练模型的逻辑推理准确率。

Conclusion: LFC-DA有效增强了逻辑数据的多样性和严谨性，提升了大语言模型的逻辑推理性能，证明其作为LLM引导的逻辑数据增强工具的可行性和有效性。

Abstract: For complex logical data augmentation, heavy reliance on human annotation is
costly, whereas direct generation with large language models yields
uninterpretable and logically homogeneous examples. To address this, we present
LFC-DA, a symbolic-logic-controlled pipeline: logical text is first mapped to
propositional expressions, a compact rule library is compiled, and a bounded
state-space search systematically discovers valid formulas that are then
verbalized back into natural-language questions, ensuring both diversity and
logical rigor under propositional logic. Experiments on ReClor and LogiQA show
significant improvements in the logical-reasoning accuracy of pretrained
models, confirming the effectiveness of LFC-DA for LLM-guided logical data
augmentation.

</details>


### [28] [Segmentation Beyond Defaults: Asymmetrical Byte Pair Encoding for Optimal Machine Translation Performance](https://arxiv.org/abs/2511.03383)
*Saumitra Yadav,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文研究了机器翻译中词语分割的非对称BPE方法，发现不同源语言和目标语言的合并操作次数差异能显著提升低资源语言对的翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器翻译通常采用对称BPE，使用相同的合并操作次数训练源语言和目标语言的分词器，但这一方法并不适用于所有语言对和数据规模，尤其在低资源条件下性能有限。

Method: 研究了不同数据规模和语言对下的BPE分词配置，比较对称BPE与非对称BPE（源语言和目标语言使用不同合并操作次数）对机器翻译系统性能的影响。

Result: 非对称BPE方法在低资源条件下显著优于对称BPE，尤其是在英语-印地语等语言对，统计显著提升了CHRF++分数。此外，在六个其他语言对中10/12系统表现出统计显著的性能提升。

Conclusion: 采用高合并操作次数（4K到32K）作为源语言，低合并操作次数（0.5K到2K）作为目标语言的非对称BPE策略为低资源机器翻译提供了最优性能提升方案。

Abstract: Existing Machine Translation (MT) research often suggests a single, fixed set
of hyperparameters for word segmentation models, symmetric Byte Pair Encoding
(BPE), which applies the same number of merge operations (NMO) to train
tokenizers for both source and target languages. However, we demonstrate that
this uniform approach doesn't guarantee optimal MT performance across different
language pairs and data sizes. This work investigates BPE segmentation recipes
across various data volumes and language pairs to evaluate MT system
performance. We find that utilizing asymmetric BPE, where the source and target
languages have different NMOs, significantly improves results over the
symmetric approach, especially in low-resource settings (50K, 100K, and 500K
sentence pairs). Specifically, asymmetric BPE yield statistically significant
($p<0.05$) average gains of 5.32, 4.46, and 0.7 CHRF++ on English-Hindi in
low-resource setups. We validated this trend across six additional language
pairs (English and Telugu, Shona, Norwegian, Kyrgyz, Hausa, and Inuktitut),
observing statistically significant improvement in 10 out of 12 systems
compared to symmetric BPE. Our findings indicate a high NMO for the source (4K
to 32K) and a low NMO for the target (0.5K to 2K) provides optimal results,
particularly benefiting low-resource MT.

</details>


### [29] [Overcoming the Generalization Limits of SLM Finetuning for Shape-Based Extraction of Datatype and Object Properties](https://arxiv.org/abs/2511.03407)
*Célian Ringwald,Fabien Gandon,Catherine Faron,Franck Michel,Hanna Abi Akl*

Main category: cs.CL

TL;DR: 这篇论文探讨了小型语言模型在关系抽取中处理稀有属性的挑战，并提出了优化策略。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在提取RDF三元组时面临长尾稀有属性分布的问题，影响提取效果。

Method: 评估了分层采样、加权损失、数据集扩展和基于模板的合成数据增强策略。

Result: 发现构建一个保证每个属性出现次数超过阈值的训练集，是解决不平衡属性效果差异的最好策略。

Conclusion: 为训练感知形状的小型语言模型提供了实用指导，并指出了语义关系抽取未来的研究方向。

Abstract: Small language models (SLMs) have shown promises for relation extraction (RE)
when extracting RDF triples guided by SHACL shapes focused on common datatype
properties. This paper investigates how SLMs handle both datatype and object
properties for a complete RDF graph extraction. We show that the key bottleneck
is related to long-tail distribution of rare properties. To solve this issue,
we evaluate several strategies: stratified sampling, weighted loss, dataset
scaling, and template-based synthetic data augmentation. We show that the best
strategy to perform equally well over unbalanced target properties is to build
a training set where the number of occurrences of each property exceeds a given
threshold. To enable reproducibility, we publicly released our datasets,
experimental results and code. Our findings offer practical guidance for
training shape-aware SLMs and highlight promising directions for future work in
semantic RE.

</details>


### [30] [Efficient Reasoning via Thought-Training and Thought-Free Inference](https://arxiv.org/abs/2511.03408)
*Canhui Wu,Qiong Cao,Chao Xue,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 本文提出了3TF框架，通过短到长的训练视角，让模型在无显性推理的情况下实现高效且高质量的隐式推理。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型主要通过显性链式推理提升推理准确性，但推理过程冗长且影响效率。

Method: 设计了3TF框架，先训练混合模式模型（有推理及无推理），再用链式推理标注数据深度训练，推理时仅输出简洁无推理内容。

Result: 3TF模型在无显性推理条件下的推理基准测试中表现大幅提升，证明了隐式高质量推理的可行性。

Conclusion: 高质量推理可以通过内部隐式执行实现，无需显式逐步生成，显著提高效率并保持合理准确性。

Abstract: Recent advances in large language models (LLMs) have leveraged explicit
Chain-of-Thought (CoT) prompting to improve reasoning accuracy. However, most
existing methods primarily compress verbose reasoning outputs. These
Long-to-Short transformations aim to improve efficiency, but still rely on
explicit reasoning during inference. In this work, we introduce \textbf{3TF}
(\textbf{T}hought-\textbf{T}raining and \textbf{T}hought-\textbf{F}ree
inference), a framework for efficient reasoning that takes a Short-to-Long
perspective. We first train a hybrid model that can operate in both reasoning
and non-reasoning modes, and then further train it on CoT-annotated data to
internalize structured reasoning, while enforcing concise, thought-free outputs
at inference time using the no-reasoning mode. Unlike compression-based
approaches, 3TF improves the reasoning quality of non-reasoning outputs,
enabling models to perform rich internal reasoning implicitly while keeping
external outputs short. Empirically, 3TF-trained models obtain large
improvements on reasoning benchmarks under thought-free inference,
demonstrating that high quality reasoning can be learned and executed
implicitly without explicit step-by-step generation.

</details>


### [31] [Knowledge-Augmented Question Error Correction for Chinese Question Answer System with QuestionRAG](https://arxiv.org/abs/2511.03410)
*Longpeng Qiu,Ting Li,Shuai Mao,Nan Yang,Xiaohui Yan*

Main category: cs.CL

TL;DR: 本文提出了QuestionRAG框架，通过知识增强和强化学习改进大语言模型处理问答系统中的输入错误，提升了问题纠正的准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在问答系统中难以准确理解用户意图，常出现误解和过度纠正问题。

Method: QuestionRAG框架通过引入外部知识丰富输入信息以及利用强化学习优化模型目标，避免误解和过度纠正。

Result: 知识增强显著提升了模型理解错误问题的能力，强化学习比传统监督微调效果更佳，提高了模型的指令遵循和泛化能力。

Conclusion: 结合知识增强和强化学习策略，QuestionRAG充分发挥了大语言模型在问题纠正任务中的潜力。

Abstract: Input errors in question-answering (QA) systems often lead to incorrect
responses. Large language models (LLMs) struggle with this task, frequently
failing to interpret user intent (misinterpretation) or unnecessarily altering
the original question's structure (over-correction). We propose QuestionRAG, a
framework that tackles these problems. To address misinterpretation, it
enriches the input with external knowledge (e.g., search results, related
entities). To prevent over-correction, it uses reinforcement learning (RL) to
align the model's objective with precise correction, not just paraphrasing. Our
results demonstrate that knowledge augmentation is critical for understanding
faulty questions. Furthermore, RL-based alignment proves significantly more
effective than traditional supervised fine-tuning (SFT), boosting the model's
ability to follow instructions and generalize. By integrating these two
strategies, QuestionRAG unlocks the full potential of LLMs for the question
correction task.

</details>


### [32] [CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field](https://arxiv.org/abs/2511.03441)
*Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre*

Main category: cs.CL

TL;DR: CareMedEval是一个用于评估大型语言模型在生物医学领域批判性评价和推理能力的数据集，基于真实法国医学生考试题目。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在专业领域批判性推理能力有限，尤其是生物医学批判性文献评价任务。

Method: 构建CareMedEval数据集，包含基于37篇科学论文的534个问题，评测多种通用及生物医学专业模型在不同上下文条件下的表现。

Result: 所有模型表现均不理想，最高精确匹配率仅0.5，尤其在研究局限性和统计分析问题上挑战更大，生成推理过程能显著提升结果。

Conclusion: CareMedEval揭示了现有大型语言模型在生物医学批判性推理中的不足，为未来自动化支持工具的发展提供重要基准和方向。

Abstract: Critical appraisal of scientific literature is an essential skill in the
biomedical field. While large language models (LLMs) can offer promising
support in this task, their reliability remains limited, particularly for
critical reasoning in specialized domains. We introduce CareMedEval, an
original dataset designed to evaluate LLMs on biomedical critical appraisal and
reasoning tasks. Derived from authentic exams taken by French medical students,
the dataset contains 534 questions based on 37 scientific articles. Unlike
existing benchmarks, CareMedEval explicitly evaluates critical reading and
reasoning grounded in scientific papers. Benchmarking state-of-the-art
generalist and biomedical-specialized LLMs under various context conditions
reveals the difficulty of the task: open and commercial models fail to exceed
an Exact Match Rate of 0.5 even though generating intermediate reasoning tokens
considerably improves the results. Yet, models remain challenged especially on
questions about study limitations and statistical analysis. CareMedEval
provides a challenging benchmark for grounded reasoning, exposing current LLM
limitations and paving the way for future development of automated support for
critical appraisal.

</details>


### [33] [Kastor: Fine-tuned Small Language Models for Shape-based Active Relation Extraction](https://arxiv.org/abs/2511.03466)
*Ringwald Celian,Gandon Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 本文提出了Kastor框架，利用基于RDF模式的关系抽取方法，提升小型语言模型在特定领域知识库构建中的表现。


<details>
  <summary>Details</summary>
Motivation: 为满足专门领域知识库完善和精炼的需求，提高有限文本和RDF数据训练的小型语言模型的性能。

Method: Kastor框架将传统的单一SHACL形状验证任务，扩展为评估该形状所有可能的属性组合，通过选取每个训练样本的最优组合，增强模型的泛化能力，并采用迭代学习过程来精炼噪声数据。

Result: 模型通过选择最佳属性组合和迭代学习显著提升了关系抽取任务的性能和对新事实的发现能力。

Conclusion: Kastor框架有效改进了基于RDF模式的关系抽取方法，使小型语言模型能够高效构建和完善专业领域的知识库。

Abstract: RDF pattern-based extraction is a compelling approach for fine-tuning small
language models (SLMs) by focusing a relation extraction task on a specified
SHACL shape. This technique enables the development of efficient models trained
on limited text and RDF data. In this article, we introduce Kastor, a framework
that advances this approach to meet the demands for completing and refining
knowledge bases in specialized domains. Kastor reformulates the traditional
validation task, shifting from single SHACL shape validation to evaluating all
possible combinations of properties derived from the shape. By selecting the
optimal combination for each training example, the framework significantly
enhances model generalization and performance. Additionally, Kastor employs an
iterative learning process to refine noisy knowledge bases, enabling the
creation of robust models capable of uncovering new, relevant facts

</details>


### [34] [BanglaSTEM: A Parallel Corpus for Technical Domain Bangla-English Translation](https://arxiv.org/abs/2511.03498)
*Kazi Reyazul Hasan,Mubasshira Musarrat,A. B. M. Alim Al Islam,Muhammad Abdullah Adnan*

Main category: cs.CL

TL;DR: 该论文提出了BanglaSTEM数据集和基于T5的翻译模型，以提高孟加拉语技术类英文问题的翻译准确性，促进使用英文大语言模型解决技术问题。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型在解决英文技术问题上表现良好，但对孟加拉语同类问题表现较差，主要因现有孟加拉语到英语的翻译系统无法准确翻译专业术语，导致理解和解答错误。

Method: 作者收集了包括计算机科学、数学、物理、化学、生物学在内的5000对孟加拉语-英语技术领域句子对，利用语言模型生成1.2万多个译文，经人工评审选出最高质量的句子对。基于此数据集，训练了T5翻译模型，并在代码生成和数学问题解决两个任务中进行了测试。

Result: 所提出的翻译模型在技术内容的翻译准确率上显著优于现有系统，大幅提升了技术术语的正确保留率，使孟加拉语用户能够更有效地利用英语为主的大语言模型。

Conclusion: BanglaSTEM数据集及训练的翻译模型显著改善了孟加拉语到英语的技术内容翻译问题，为孟加拉语使用者访问英语语言模型打开了便利途径，相关资源已公开发布。

Abstract: Large language models work well for technical problem solving in English but
perform poorly when the same questions are asked in Bangla. A simple solution
would be to translate Bangla questions into English first and then use these
models. However, existing Bangla-English translation systems struggle with
technical terms. They often mistranslate specialized vocabulary, which changes
the meaning of the problem and leads to wrong answers. We present BanglaSTEM, a
dataset of 5,000 carefully selected Bangla-English sentence pairs from STEM
fields including computer science, mathematics, physics, chemistry, and
biology. We generated over 12,000 translations using language models and then
used human evaluators to select the highest quality pairs that preserve
technical terminology correctly. We train a T5-based translation model on
BanglaSTEM and test it on two tasks: generating code and solving math problems.
Our results show significant improvements in translation accuracy for technical
content, making it easier for Bangla speakers to use English-focused language
models effectively. Both the BanglaSTEM dataset and the trained translation
model are publicly released at https://huggingface.co/reyazul/BanglaSTEM-T5.

</details>


### [35] [HaluMem: Evaluating Hallucinations in Memory Systems of Agents](https://arxiv.org/abs/2511.03506)
*Ding Chen,Simin Niu,Kehang Li,Peng Liu,Xiangping Zheng,Bo Tang,Xinchi Li,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 本文提出了首个针对记忆系统操作层面的幻觉评估基准HaluMem，通过三个任务和大规模多轮人机交互数据集揭示了记忆系统在提取和更新阶段易产生累积幻觉并影响问答表现。


<details>
  <summary>Details</summary>
Motivation: 现有记忆系统存在幻觉问题，且评价方法多为端到端问答，难以定位幻觉产生的具体操作阶段，亟需细粒度的评估基准来识别幻觉来源。

Method: 设计HaluMem基准，包含记忆提取、更新和问答三个任务，并构建包含约1.5万记忆点、3.5千多类型问题的多轮人机交互数据集HaluMem-Medium和HaluMem-Long，覆盖不同上下文规模和任务复杂度。

Result: 实证研究显示，现有记忆系统在提取和更新阶段容易产生和累积幻觉，幻觉错误进一步传播至问答阶段。

Conclusion: 未来研究应注重开发可解释且受约束的记忆操作机制，系统性抑制幻觉以提升记忆系统的可靠性。

Abstract: Memory systems are key components that enable AI systems such as LLMs and AI
agents to achieve long-term learning and sustained interaction. However, during
memory storage and retrieval, these systems frequently exhibit memory
hallucinations, including fabrication, errors, conflicts, and omissions.
Existing evaluations of memory hallucinations are primarily end-to-end question
answering, which makes it difficult to localize the operational stage within
the memory system where hallucinations arise. To address this, we introduce the
Hallucination in Memory Benchmark (HaluMem), the first operation level
hallucination evaluation benchmark tailored to memory systems. HaluMem defines
three evaluation tasks (memory extraction, memory updating, and memory question
answering) to comprehensively reveal hallucination behaviors across different
operational stages of interaction. To support evaluation, we construct
user-centric, multi-turn human-AI interaction datasets, HaluMem-Medium and
HaluMem-Long. Both include about 15k memory points and 3.5k multi-type
questions. The average dialogue length per user reaches 1.5k and 2.6k turns,
with context lengths exceeding 1M tokens, enabling evaluation of hallucinations
across different context scales and task complexities. Empirical studies based
on HaluMem show that existing memory systems tend to generate and accumulate
hallucinations during the extraction and updating stages, which subsequently
propagate errors to the question answering stage. Future research should focus
on developing interpretable and constrained memory operation mechanisms that
systematically suppress hallucinations and improve memory reliability.

</details>


### [36] [One Battle After Another: Probing LLMs' Limits on Multi-Turn Instruction Following with a Benchmark Evolving Framework](https://arxiv.org/abs/2511.03508)
*Qi Jia,Kaiwei Zhang,Xiujie Song,Ye Shen,Xiangyang Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 本文提出了一个可扩展的框架用于评估大型语言模型在多轮对话中的指令遵循能力，并构建了包含9种约束类型的新基准EvolIF。通过实验发现GPT-5在保持对话长度和鲁棒性方面表现优异，明显领先其他模型。


<details>
  <summary>Details</summary>
Motivation: 现有评估多轮对话的基准存在轮次固定、易饱和且未充分考虑用户交互体验的问题，难以全面反映模型的指令遵循能力。

Method: 构建了一个三层机制框架，分离语言表面形式和用户意图模拟，通过动态状态变更和回溯来模拟用户-语言模型的互动，直到模型耗尽模拟用户耐心。设计了一套衡量交互质量的指标。

Result: 使用该框架构建了EvolIF基准，包含九类约束。实验显示GPT-5在平均对话轮次（18.54轮）和鲁棒性（70.31%）方面表现最佳，领先于Gemini-2.5-Pro 11.41%。

Conclusion: 所提框架有效评估模型的多主题多轮指令遵循能力，GPT-5表现出较强的持续对话和鲁棒性，具有更好的用户交互体验潜力。数据代码将公开以促进进一步研究。

Abstract: Understanding how well large language models can follow users' instructions
throughout a dialogue spanning multiple topics is of great importance for
data-intensive conversational applications. Existing benchmarks are often
limited to a fixed number of turns, making them susceptible to saturation and
failing to account for the user's interactive experience. In this work, we
propose an extensible framework for assessing multi-turn instruction-following
ability. At its core, our framework decouples linguistic surface forms from
user intent simulation through a three-layer mechanism that tracks constraints,
instructions, and topics. This framework mimics User-LLM interaction by
enabling the dynamic construction of benchmarks with state changes and
tracebacks, terminating a conversation only when the model exhausts a simulated
user's patience. We define a suite of metrics capturing the quality of the
interaction process. Using this framework, we construct EvolIF, an evolving
instruction-following benchmark incorporating nine distinct constraint types.
Our results indicate that GPT-5 exhibits superior instruction-following
performance. It sustains an average of 18.54 conversational turns and
demonstrates 70.31% robustness, outperforming Gemini-2.5-Pro by a significant
margin of 11.41%, while other models lag far behind. All of the data and code
will be made publicly available online.

</details>


### [37] [SOLVE-Med: Specialized Orchestration for Leading Vertical Experts across Medical Specialties](https://arxiv.org/abs/2511.03542)
*Roberta Di Marino,Giovanni Dioguardi,Antonio Romano,Giuseppe Riccio,Mariano Barone,Marco Postiglione,Flora Amato,Vincenzo Moscato*

Main category: cs.CL

TL;DR: SOLVE-Med是一个结合十个领域专用小型语言模型的多智能体医疗问答系统，动态选择专家模型处理复杂医疗问题，表现优于大规模单模型并支持本地部署。


<details>
  <summary>Details</summary>
Motivation: 医疗问答系统面临幻觉、偏见、高计算需求、隐私和跨领域专业知识等挑战，亟需有效、精准、低资源的解决方案。

Method: 提出多智能体架构SOLVE-Med，包含Router Agent动态选择10个各具专业领域的1B参数小模型，由Orchestrator Agent综合生成答案，实现专科分工与协同。

Result: 在意大利医疗论坛十个专业领域数据上，SOLVE-Med表现优异，ROUGE-1达0.301，BERTScore F1达0.697，超越最大14B参数单模型。

Conclusion: 通过多智能体架构融合专科小模型，SOLVE-Med有效提升医疗问答系统性能，兼具高效性和本地部署的实用性。

Abstract: Medical question answering systems face deployment challenges including
hallucinations, bias, computational demands, privacy concerns, and the need for
specialized expertise across diverse domains. Here, we present SOLVE-Med, a
multi-agent architecture combining domain-specialized small language models for
complex medical queries. The system employs a Router Agent for dynamic
specialist selection, ten specialized models (1B parameters each) fine-tuned on
specific medical domains, and an Orchestrator Agent that synthesizes responses.
Evaluated on Italian medical forum data across ten specialties, SOLVE-Med
achieves superior performance with ROUGE-1 of 0.301 and BERTScore F1 of 0.697,
outperforming standalone models up to 14B parameters while enabling local
deployment. Our code is publicly available on GitHub:
https://github.com/PRAISELab-PicusLab/SOLVE-Med.

</details>


### [38] [Bearing Syntactic Fruit with Stack-Augmented Neural Networks](https://arxiv.org/abs/2511.03547)
*Brian DuSell,Ryan Cotterell*

Main category: cs.CL

TL;DR: 本文展示了堆栈增强的神经网络在无额外条件下实现类似人类的语言层次泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索神经网络是否能够像人类儿童一样，在没有明确语法监督或大规模预训练情况下，实现层次化语言结构的泛化。

Method: 将三种基础架构（Transformer、简单RNN、LSTM）与两种堆栈结构（Joulin&Mikolov的叠加堆栈和DuSell&Chiang提出的非确定性堆栈）结合，评估其在经典问题形成任务上的表现，并改进堆栈RNN架构。

Result: 采用非确定性堆栈的Transformer模型在层次泛化任务上表现最佳，改进后的堆栈RNN也显示出更好的层次泛化能力。

Conclusion: 堆栈增强的神经网络是更符合人类语言习得的模型，有助于心理语言学研究。代码已公开。

Abstract: Any finite set of training data is consistent with an infinite number of
hypothetical algorithms that could have generated it. Studies have shown that
when human children learn language, they consistently favor hypotheses based on
hierarchical syntactic rules without ever encountering disambiguating examples.
A recent line of work has inquired as to whether common neural network
architectures share this bias, finding that they do so only under special
conditions: when syntactically supervised, when pre-trained on massive corpora,
or when trained long past convergence. In this paper, we demonstrate, for the
first time, neural network architectures that are able to generalize in
human-like fashion without any of the aforementioned requirements:
stack-augmented neural networks. We test three base architectures (transformer,
simple RNN, LSTM) augmented with two styles of stack: the superposition stack
of Joulin & Mikolov (2015) and a nondeterministic generalization of it proposed
by DuSell & Chiang (2023). We find that transformers with nondeterministic
stacks generalize best out of these architectures on a classical question
formation task. We also propose a modification to the stack RNN architecture
that improves hierarchical generalization. These results suggest that
stack-augmented neural networks may be more accurate models of human language
acquisition than standard architectures, serving as useful objects of
psycholinguistic study. Our code is publicly available.

</details>


### [39] [MultiZebraLogic: A Multilingual Logical Reasoning Benchmark](https://arxiv.org/abs/2511.03553)
*Sofie Helene Bruun,Dan Saattrup Smart*

Main category: cs.CL

TL;DR: 本文构建了多语言、多主题、多难度的斑马谜题数据集，用于评估大语言模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了全面评估大语言模型（LLM）的逻辑推理能力，需设计包含多任务、多语言和适当难度的高质量数据集。

Method: 通过多语言、多主题、多尺寸（2x3和4x5）生成斑马谜题，包含14种线索类型和8种误导线索，测试不同规模和难度对模型表现的影响。

Result: 发现2x3和4x5尺寸的谜题分别适合测试不同模型，添加误导线索显著降低模型准确率；语言和主题变化对模型表现影响不大，线索类型与难度无明显相关性。

Conclusion: 该研究发布了MultiZebraLogic数据集及生成代码，支持九种日耳曼语言，方便未来扩展以评估不同语言和主题下的逻辑推理能力。

Abstract: Measuring the full abilities of large language models (LLMs) requires
benchmarks representing multiple tasks. We aim to create large, high-quality
datasets for comparison of logical reasoning skills across several languages
and of suitable difficulty for LLMs of various reasoning ability. We explore
multiple ways of increasing difficulty. We generate zebra puzzles in multiple
languages, themes, sizes and including 14 different clue types and 8 red
herring types (uninformative clues). We find puzzle sizes 2x3 and 4x5 are
sufficiently challenging for GPT-4o mini (a non-reasoning model) and o3-mini (a
reasoning model), respectively. Including 5 red herrings decreases o3-mini
puzzle-level accuracy on 4x5 puzzles by 15$\pm$7 %. Scores of o3-mini on 4x5
puzzles are not significantly affected by use of English vs. Danish or the
common houses theme vs. the country-specific smoerrebroed theme. We find no
correlation between difficulty and the selected clue types. Datasets of
128+1024 puzzles are published as MultiZebraLogic in each of nine Germanic
languages for sizes 2x3 and 4x5. We publish code for puzzle generation,
designed for adaptablity into more languages and themes.

</details>


### [40] [AILA--First Experiments with Localist Language Models](https://arxiv.org/abs/2511.03559)
*Joachim Diederich*

Main category: cs.CL

TL;DR: 本文首次实证展示了变压器语言模型中可控的局部性，通过可调节的局部性参数实现表示的局部化控制，达到解释性与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型仅依赖分布式表示，缺乏解释性，且不能动态调整表示的局部化程度。作者希望实现模型在解释性与性能间的连续调控。

Method: 提出一种新架构，利用局部性调节参数λ在局部编码与分布式表示之间动态切换，无需重新训练模型。通过在WikiText数据集上使用两层变压器，系统调节λ从1.0到0.0，评估注意力熵、指针保真度、困惑度和准确率。

Result: 局部编码（λ=1.0）显著降低注意力熵（5.36比7.18比特），并提高指针保真度。中间值λ=0.6在解释性与性能间达到最佳折中，测试困惑度4.65，准确率84.7%。

Conclusion: 局部性可控的语言模型为需要透明性和能力的受监管领域提供实用框架，通过数学控制实现解释性与性能的权衡，具备应用潜力。

Abstract: This paper presents the first empirical demonstration of controllable
locality in transformer language models, a novel architectural framework that
enables continuous control over the degree of representation localization
through a tunable locality dial parameter. Unlike traditional language models
that rely exclusively on distributed representations, our approach allows
dynamic interpolation between highly interpretable localist encodings and
efficient distributed representations without requiring model retraining. We
conducted experiments on the WikiText corpus using a two-layer transformer
architecture, systematically varying the locality parameter {\lambda} across
the full spectrum from 1.0 (fully localist) to 0.0 (fully distributed). Our
results demonstrate that localist configurations achieve dramatically lower
attention entropy, with {\lambda} = 1.0 yielding 5.36 bits compared to 7.18
bits at {\lambda} = 0.0, while maintaining substantially higher pointer
fidelity scores reflecting stronger alignment with rule-specified targets.
Prediction experiments reveal that intermediate locality values optimize the
tradeoff between interpretability and performance, with {\lambda} = 0.6
achieving test perplexity of 4.65 and accuracy of 84.7%. These findings
establish that localist language models provide a practical framework for
applications in regulated domains requiring both transparency and capability,
offering precise mathematical control over the interpretability-performance
spectrum through explicit penalty thresholds and information-theoretic design
principles.

</details>


### [41] [ASVRI-Legal: Fine-Tuning LLMs with Retrieval Augmented Generation for Enhanced Legal Regulation](https://arxiv.org/abs/2511.03563)
*One Octadion,Bondan Sapta Prakoso,Nanang Yudi Setiawan,Novanto Yudistira*

Main category: cs.CL

TL;DR: 该论文通过微调大型语言模型并结合检索增强生成（RAG）方法，提升模型在法律文本理解和政策制定辅助上的能力。


<details>
  <summary>Details</summary>
Motivation: 帮助政策制定者更好地理解、分析和制定法律法规，解决现有模型在法律领域知识更新和专深理解上的不足。

Method: 构建针对法律领域的监督数据集，进行模型微调，并结合检索增强生成方法，使模型能够访问最新法律知识。

Result: 该方法显著提升了模型在法律研究和法规制定方面的效果，能够主动辅助政策制定者解读法规和起草新规。

Conclusion: 结合微调与RAG的LLM工具为法律领域政策制定提供了有效支持，具有重要的实际应用价值。

Abstract: In this study, we explore the fine-tuning of Large Language Models (LLMs) to
better support policymakers in their crucial work of understanding, analyzing,
and crafting legal regulations. To equip the model with a deep understanding of
legal texts, we curated a supervised dataset tailored to the specific needs of
the legal domain. Additionally, we integrated the Retrieval-Augmented
Generation (RAG) method, enabling the LLM to access and incorporate up-to-date
legal knowledge from external sources. This combination of fine-tuning and
RAG-based augmentation results in a tool that not only processes legal
information but actively assists policymakers in interpreting regulations and
drafting new ones that align with current needs. The results demonstrate that
this approach can significantly enhance the effectiveness of legal research and
regulation development, offering a valuable resource in the ever-evolving field
of law.

</details>


### [42] [Step-Audio-EditX Technical Report](https://arxiv.org/abs/2511.03601)
*Chao Yan,Boyong Wu,Peng Yang,Pengfei Tan,Guoqiang Hu,Yuxin Zhang,Xiangyu,Zhang,Fei Tian,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.CL

TL;DR: Step-Audio-EditX是一种基于大语言模型的开源音频编辑模型，支持情感、说话风格和副语言的表达式迭代编辑，并具备强大的零样本文本转语音能力。


<details>
  <summary>Details</summary>
Motivation: 现有音频编辑模型通常依赖嵌入先验或辅助模块，限制了表达的丰富性和控制的灵活性。

Method: 提出利用大间隔合成数据进行大间隔学习，避免传统的表征级别解耦，支持迭代控制和高表达能力。

Result: 实验显示Step-Audio-EditX在情感编辑和其他细粒度控制任务上超越了MiniMax-2.6-hd和Doubao-Seed-TTS-2.0。

Conclusion: Step-Audio-EditX通过创新的大间隔学习方法，实现了高表达性和强迭代控制能力，推动了音频编辑技术的发展。

Abstract: We present Step-Audio-EditX, the first open-source LLM-based audio model
excelling at expressive and iterative audio editing encompassing emotion,
speaking style, and paralinguistics alongside robust zero-shot text-to-speech
(TTS) capabilities.Our core innovation lies in leveraging only large-margin
synthetic data, which circumvents the need for embedding-based priors or
auxiliary modules. This large-margin learning approach enables both iterative
control and high expressivity across voices, and represents a fundamental pivot
from the conventional focus on representation-level disentanglement. Evaluation
results demonstrate that Step-Audio-EditX surpasses both MiniMax-2.6-hd and
Doubao-Seed-TTS-2.0 in emotion editing and other fine-grained control tasks.

</details>


### [43] [A systematic review of relation extraction task since the emergence of Transformers](https://arxiv.org/abs/2511.03610)
*Ringwald Celian,Gandon,Fabien,Faron Catherine,Michel Franck,Abi Akl Hanna*

Main category: cs.CL

TL;DR: 本文系统回顾了2019至2024年基于Transformer模型的关系抽取（RE）研究，涵盖调查、数据集和模型，分析方法进展和资源整合，总结趋势与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer模型的兴起，关系抽取领域发展迅速，缺乏系统性总结和分析。

Method: 利用自动化框架收集和标注相关文献，分析34篇综述、64个数据集和104个模型。

Result: 揭示了方法学进步、基准资源及语义网技术的整合，识别当前研究趋势、局限性和未解决问题。

Conclusion: 本研究为研究者和实践者提供了关系抽取领域的全面参考，助力理解其发展历程和未来方向。

Abstract: This article presents a systematic review of relation extraction (RE)
research since the advent of Transformer-based models. Using an automated
framework to collect and annotate publications, we analyze 34 surveys, 64
datasets, and 104 models published between 2019 and 2024. The review highlights
methodological advances, benchmark resources, and the integration of semantic
web technologies. By consolidating results across multiple dimensions, the
study identifies current trends, limitations, and open challenges, offering
researchers and practitioners a comprehensive reference for understanding the
evolution and future directions of RE.

</details>


### [44] [Towards Transparent Stance Detection: A Zero-Shot Approach Using Implicit and Explicit Interpretability](https://arxiv.org/abs/2511.03635)
*Apoorva Upadhyaya,Wolfgang Nejdl,Marco Fisichella*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的可解释零样本立场检测框架IRIS，基于隐式和显式推理提升模型的可解释性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本立场检测方法存在泛化能力差、文本与目标间连贯性不足、解释性差等问题，难以理解模型预测过程。

Method: IRIS将立场检测视为信息检索排序任务，利用文本中的隐式推理序列和基于语言学特征的显式推理，不依赖推理真值数据，提升模型内在可解释性并通过交流特征解码情感和认知维度。

Result: 在VAST、EZ-STANCE、P-Stance和RFD等基准数据集上，使用50%、30%、甚至10%训练数据，IRIS表现出优越的泛化能力和解释性。

Conclusion: 通过引入隐式和显式推理，IRIS有效解决了现有ZSSD模型的泛化和解释性问题，为零样本立场检测提供了新的可解释框架。

Abstract: Zero-Shot Stance Detection (ZSSD) identifies the attitude of the post toward
unseen targets. Existing research using contrastive, meta-learning, or data
augmentation suffers from generalizability issues or lack of coherence between
text and target. Recent works leveraging large language models (LLMs) for ZSSD
focus either on improving unseen target-specific knowledge or generating
explanations for stance analysis. However, most of these works are limited by
their over-reliance on explicit reasoning, provide coarse explanations that
lack nuance, and do not explicitly model the reasoning process, making it
difficult to interpret the model's predictions. To address these issues, in our
study, we develop a novel interpretable ZSSD framework, IRIS. We provide an
interpretable understanding of the attitude of the input towards the target
implicitly based on sequences within the text (implicit rationales) and
explicitly based on linguistic measures (explicit rationales). IRIS considers
stance detection as an information retrieval ranking task, understanding the
relevance of implicit rationales for different stances to guide the model
towards correct predictions without requiring the ground-truth of rationales,
thus providing inherent interpretability. In addition, explicit rationales
based on communicative features help decode the emotional and cognitive
dimensions of stance, offering an interpretable understanding of the author's
attitude towards the given target. Extensive experiments on the benchmark
datasets of VAST, EZ-STANCE, P-Stance, and RFD using 50%, 30%, and even 10%
training data prove the generalizability of our model, benefiting from the
proposed architecture and interpretable design.

</details>


### [45] [ChiMDQA: Towards Comprehensive Chinese Document QA with Fine-grained Evaluation](https://arxiv.org/abs/2511.03656)
*Jing Gao,Shutiao Luo,Yumeng Liu,Yuanming Li,Hongji Zeng*

Main category: cs.CL

TL;DR: 该论文介绍了专为中文多文档问答任务设计的ChiMDQA数据集，涵盖六个领域和十个细分类别，包含6068对高质量的问答对。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理技术的发展，中文高质量文档问答数据集需求不断增长，现有资源不足以支撑实际业务场景。

Method: 通过严格的文档筛选和系统化的问题设计方法，收集涵盖学术、教育、金融、法律、医疗和新闻六个领域的长文档，构建高质量多文档问答数据集。

Result: 构建了包含6068个高质量问答对的数据集，分类细致且保证多样性，支持文档理解、知识抽取和智能问答系统等任务。

Conclusion: ChiMDQA数据集为中文多文档问答提供了重要资源，促进相关领域的研究和应用发展。

Abstract: With the rapid advancement of natural language processing (NLP) technologies,
the demand for high-quality Chinese document question-answering datasets is
steadily growing. To address this issue, we present the Chinese Multi-Document
Question Answering Dataset(ChiMDQA), specifically designed for downstream
business scenarios across prevalent domains including academic, education,
finance, law, medical treatment, and news. ChiMDQA encompasses long-form
documents from six distinct fields, consisting of 6,068 rigorously curated,
high-quality question-answer (QA) pairs further classified into ten
fine-grained categories. Through meticulous document screening and a systematic
question-design methodology, the dataset guarantees both diversity and high
quality, rendering it applicable to various NLP tasks such as document
comprehension, knowledge extraction, and intelligent QA systems. Additionally,
this paper offers a comprehensive overview of the dataset's design objectives,
construction methodologies, and fine-grained evaluation system, supplying a
substantial foundation for future research and practical applications in
Chinese QA. The code and data are available at:
https://anonymous.4open.science/r/Foxit-CHiMDQA/.

</details>


### [46] [Do Androids Dream of Unseen Puppeteers? Probing for a Conspiracy Mindset in Large Language Models](https://arxiv.org/abs/2511.03699)
*Francesco Corso,Francesco Pierri,Gianmarco De Francisci Morales*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）是否表现出阴谋倾向及其社会人口偏见，发现模型部分认同阴谋信念，且易受定向提示影响。


<details>
  <summary>Details</summary>
Motivation: 阴谋信念推动错误信息传播与对机构不信任，评估LLMs中阴谋倾向有助于理解模型社会心理表现及潜在风险。

Method: 通过多种提示和条件策略，利用心理测量问卷评估多种LLMs的阴谋思维倾向。

Result: LLMs部分同意阴谋观点，社会人口特征条件产生不均衡影响，易被定向提示引导向阴谋方向，暴露潜在偏见及操控风险。

Conclusion: 需批判性评估LLMs中心理维度，推动计算社会科学发展，并制定防范滥用的策略。

Abstract: In this paper, we investigate whether Large Language Models (LLMs) exhibit
conspiratorial tendencies, whether they display sociodemographic biases in this
domain, and how easily they can be conditioned into adopting conspiratorial
perspectives. Conspiracy beliefs play a central role in the spread of
misinformation and in shaping distrust toward institutions, making them a
critical testbed for evaluating the social fidelity of LLMs. LLMs are
increasingly used as proxies for studying human behavior, yet little is known
about whether they reproduce higher-order psychological constructs such as a
conspiratorial mindset. To bridge this research gap, we administer validated
psychometric surveys measuring conspiracy mindset to multiple models under
different prompting and conditioning strategies. Our findings reveal that LLMs
show partial agreement with elements of conspiracy belief, and conditioning
with socio-demographic attributes produces uneven effects, exposing latent
demographic biases. Moreover, targeted prompts can easily shift model responses
toward conspiratorial directions, underscoring both the susceptibility of LLMs
to manipulation and the potential risks of their deployment in sensitive
contexts. These results highlight the importance of critically evaluating the
psychological dimensions embedded in LLMs, both to advance computational social
science and to inform possible mitigation strategies against harmful uses.

</details>


### [47] [Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask](https://arxiv.org/abs/2511.03718)
*Nan Li,Albert Gatt,Massimo Poesio*

Main category: cs.CL

TL;DR: 本文提出了一种视角主义标注方案，用于分析合作对话中参与者如何建立共有信息，以及误解如何产生和修复。


<details>
  <summary>Details</summary>
Motivation: 合作对话中，参与者逐步建立共有信息，但在非对称场景下可能误以为达成共识，实际上指代不同实体，需要更细致地捕捉理解差异。

Method: 对HCRC MapTask语料库进行视角主义标注，分别捕捉说话者和听话者的指代理解，结合方案限制的大型语言模型（LLM）标注流程，获得13k条带可靠性估计的指代表达标注。

Result: 发现合并词汇变体后，完全误解较少，但多重指代差异系统性引起理解分歧，表明表面的共有信息可能掩盖了指代的错配。

Conclusion: 该框架为研究基于视角的共有信息建立和误解提供了资源和分析视角，同时可评估（虚拟）大型语言模型在协作对话中建模视角依赖唯一信息的能力。

Abstract: Collaborative dialogue relies on participants incrementally establishing
common ground, yet in asymmetric settings they may believe they agree while
referring to different entities. We introduce a perspectivist annotation scheme
for the HCRC MapTask corpus (Anderson et al., 1991) that separately captures
speaker and addressee grounded interpretations for each reference expression,
enabling us to trace how understanding emerges, diverges, and repairs over
time. Using a scheme-constrained LLM annotation pipeline, we obtain 13k
annotated reference expressions with reliability estimates and analyze the
resulting understanding states. The results show that full misunderstandings
are rare once lexical variants are unified, but multiplicity discrepancies
systematically induce divergences, revealing how apparent grounding can mask
referential misalignment. Our framework provides both a resource and an
analytic lens for studying grounded misunderstanding and for evaluating
(V)LLMs' capacity to model perspective-dependent grounding in collaborative
dialogue.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [48] [ALAS: Transactional and Dynamic Multi-Agent LLM Planning](https://arxiv.org/abs/2511.03094)
*Longling Geng,Edward Y. Chang*

Main category: cs.MA

TL;DR: ALAS框架提升了大型语言模型在多智能体规划中的验证和修复效率，提高了成功率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多智能体规划中存在验证循环、状态变化未被跟踪以及小错误引发全局重计算等问题，导致实用性受限。

Method: ALAS框架通过分离规划和非循环验证，使用版本化执行日志进行验证和恢复，采用多种策略执行局部修复，避免了自检循环和上下文丢失，提高了整体效率。

Result: 在多个经典作业调度基准测试中，ALAS成功率达到83.7%，减少了60%的令牌使用，运行速度提升了1.82倍，验证器低开销检测错误，局部修复有效减少了运行时间的恶化。

Conclusion: ALAS通过验证器隔离、版本化执行日志和局部修复，有效提升了多智能体大型语言模型规划的效率、可行性和可扩展性。

Abstract: Large language models enable flexible multi-agent planning but remain fragile
in practice: verification is often circular, state changes are not tracked for
repair, and small faults trigger costly global recomputation. We present ALAS,
a stateful, disruption-aware framework that separates planning from
non-circular validation, records a versioned execution log for grounded checks
and restore points, and performs localized repair that preserves work in
progress. The validator operates independently of the planning LLM with fresh,
bounded context, avoiding self-check loops and mid-context attrition. The
repair protocol edits only the minimal affected region under explicit policies
(retry, catch, timeout, backoff, idempotency keys, compensation, loop guards)
defined in a canonical workflow IR that maps to Amazon States Language and Argo
Workflows. On job-shop scheduling suites (DMU, TA) across five classical
benchmarks, ALAS matches or exceeds strong single-LLM and multi-agent
baselines, achieving 83.7% success, reducing token usage by 60%, and running
1.82times faster under comparable settings. A minimal reliability study shows
that the validator detects injected structural faults with low overhead, and
that localized repair contains runtime perturbations with a bounded edit radius
and less makespan degradation than global recompute. Results indicate that the
combination of validator isolation, versioned execution logs, and localized
repair provides measurable efficiency, feasibility, and scalability for
multi-agent LLM planning. Code and seeds will be released.

</details>


### [49] [Learning Communication Skills in Multi-task Multi-agent Deep Reinforcement Learning](https://arxiv.org/abs/2511.03348)
*Changxi Zhu,Mehdi Dastani,Shihan Wang*

Main category: cs.MA

TL;DR: 该论文提出了一种多任务多智能体深度强化学习通信方法MCS，通过Transformer编码任务观察，实现多任务间共享通信技能，有效增强智能体间协调，提升多任务学习性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中，智能体之间通信能提升协调能力；在多任务环境中，利用任务间知识共享可促进学习效果，但现有方法缺乏同时支持多任务通信的机制。

Method: 提出MCS方法，采用Transformer编码器将任务特定观察编码到共享消息空间，实现智能体间的可学习通信协议。引入预测网络关联消息和发送智能体的动作，增强协调性。适配多智能体基准环境至多任务设置，处理不同任务中智能体数量及观察动作空间变化。

Result: 实验显示，MCS在多任务多智能体环境下，性能优于无通信的多任务基线，以及有无通信的单任务基线，表现出更强的协调与学习能力。

Conclusion: MCS方法有效整合多任务学习和智能体通信，通过共享消息空间与动作预测促进多任务中的智能体协调，提升多任务多智能体强化学习性能。

Abstract: In multi-agent deep reinforcement learning (MADRL), agents can communicate
with one another to perform a task in a coordinated manner. When multiple tasks
are involved, agents can also leverage knowledge from one task to improve
learning in other tasks. In this paper, we propose Multi-task Communication
Skills (MCS), a MADRL with communication method that learns and performs
multiple tasks simultaneously, with agents interacting through learnable
communication protocols. MCS employs a Transformer encoder to encode
task-specific observations into a shared message space, capturing shared
communication skills among agents. To enhance coordination among agents, we
introduce a prediction network that correlates messages with the actions of
sender agents in each task. We adapt three multi-agent benchmark environments
to multi-task settings, where the number of agents as well as the observation
and action spaces vary across tasks. Experimental results demonstrate that MCS
achieves better performance than multi-task MADRL baselines without
communication, as well as single-task MADRL baselines with and without
communication.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [50] [SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation](https://arxiv.org/abs/2511.02854)
*Yixiang Chen,Tianshi Zheng,Shijue Huang,Zhitao He,Yi R. Fung*

Main category: cs.SE

TL;DR: 提出一种名为SELF-REDRAFT的框架，通过鼓励模型对存在根本缺陷的解决方案提出新草稿，实现了在测试时无需反馈的情况下更好地平衡利用与探索。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成方法在测试时依赖贪婪利用或随机探索，但两者平衡不足，且缺乏无测试反馈时提升性能的策略。

Method: 基于Self-Refine框架，设计SELF-REDRAFT，促使模型针对根本错误的方案生成新的草稿以增强探索能力。

Result: SELF-REDRAFT在相同迭代次数下优于Self-Refine，显示出更优的性能，但在生成指导性反馈和判别能力上仍有限制。

Conclusion: 本研究为测试时模型内在的利用-探索平衡奠定基线，指出改进反馈生成和判别判断能力是未来提升的关键方向。

Abstract: Test-time scaling without interpreter feedback is essential for real-world
code generation scenarios where test cases are not readily available. While
existing paradigms often rely on either greedy exploitation (i.e., iterative
refinement) or stochastic exploration (i.e., relying on sample-based voting or
reranking mechanisms), the balance between these two dimensions remains
underexplored. To investigate the LLM's intrinsic ability to balance
exploitation and exploration, we introduce SELF-REDRAFT, a framework built upon
Self-Refine that encourages the model to propose new drafts for solutions that
are fundamentally flawed. Our results show that SELF-REDRAFT consistently
achieves better performance than Self-Refine when converged under the same
maximum number of iterations. Still, we observe that significant room for
improvement remains, largely due to two core aspects of current self-redraft
capabilities: constrained capacity for generating instructive feedback and
fragile discriminative judgment. We also find that balancing strategies vary
notably across different LLMs, reflecting distinct, model-specific behaviors.
Overall, our study establishes a baseline for intrinsic
exploration-exploitation balancing in test-time scaling and identifies feedback
and discrimination as key areas with potential for future advances.

</details>


### [51] [The Evolution of Agile and Hybrid Project Management Methodologies: A Systematic Literature Review](https://arxiv.org/abs/2511.02859)
*Bianca Leech,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 本文系统综述了敏捷方法向混合框架的演变，分析了实施挑战和成功因素，强调了领导支持和持续改进的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着IT项目快速发展，传统项目管理方法向敏捷及混合模型转变，需要理解敏捷方法在大型及受监管环境中的局限性及混合方法的优势。

Method: 通过PRISMA方法对过去8年内的同行评审文献进行系统综述，识别敏捷向混合方法演变的趋势及实施中的关键影响因素。

Result: 发现混合方法能够解决敏捷在大型和受监管项目中的不足，成功实施依赖于领导支持、过程定制及持续改进机制。

Conclusion: 强调根据具体环境调整项目管理方法的重要性，提供实践指导帮助组织顺利实现从敏捷到混合方法的转型。

Abstract: The rapid evolution of IT projects has driven the transformation of project
management methodologies, from traditional waterfall approaches to agile
frameworks and, more recently, hybrid models. This systematic literature review
investigates the evolution of agile methodologies into hybrid frameworks,
analysing their implementation challenges and success factors. We identify key
trends through PRISMA-guided analysis of peer-reviewed studies from the last 8
years. Hybrid methodologies emerge from agile limitations in large-scale and
regulated environments, combining iterative flexibility with structured
governance. Agile has several implementation challenges, leading to hybrid
methods, and the success hinges on leadership support, tailored process
integration, and continuous improvement mechanisms. The study explores the need
for contextual adaptation over rigid frameworks, offering practical insights
for organisations navigating hybrid transitions.

</details>


### [52] [LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models](https://arxiv.org/abs/2511.02866)
*Ahmad Tahmasivand,Noureldin Zahran,Saba Al-Sayouri,Mohammed Fouda,Khaled N. Khasawneh*

Main category: cs.SE

TL;DR: LM-Fix是一种针对大型语言模型的轻量级故障检测与快速恢复框架，能高效检测并修复比特翻转错误，保持模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型的完整性检测方法通常较为繁重且速度较慢，难以满足现代应用需求。

Method: LM-Fix通过短测试向量运行和基于哈希的检测机制检测比特翻转故障，并能局部修复而无需完全重载模型。

Result: 在多个模型上，LM-Fix能检测超过94%的单比特翻转和几乎100%的多比特翻转，运行时开销约为1%至7.7%，恢复速度比重载快100倍以上。

Conclusion: LM-Fix提供了一种实用且低开销的方案，能够确保大型语言模型在生产环境中的可靠性。

Abstract: This paper presents LM-Fix, a lightweight detection and rapid recovery
framework for faults in large language models (LLMs). Existing integrity
approaches are often heavy or slow for modern LLMs. LM-Fix runs a short
test-vector pass and uses hash-guided checks to detect bit-flip faults, then
repairs them locally without a full reload. Across multiple models, it detects
over 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with
approximately 1% to 7.7% runtime overhead; recovery is more than 100x faster
than reloading. These results show a practical, low-overhead solution to keep
LLMs reliable in production

</details>


### [53] [Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models](https://arxiv.org/abs/2511.02869)
*Amirreza Esmaeili,Fahd Seddik,Yongyi Ji,Fatemeh Fard,Fuxiang Chen*

Main category: cs.SE

TL;DR: 本文研究了基于参数高效微调（PEFT）的AdvFusion方法在多种代码生成任务中的表现，比较了其与AdapterFusion及其他PEFT方法的性能差异。


<details>
  <summary>Details</summary>
Motivation: 已有PEFT方法如AdapterFusion主要关注目标语言，AdvFusion提出通过跨语言学习提升任务表现，需验证其在更多任务和更大模型上的效果。

Method: 通过在Code大语言模型上应用AdvFusion，评估其在代码生成、代码翻译和提交信息生成三个新任务中的性能，并与AdapterFusion及其他PEFT方法比较。

Result: AdvFusion在代码生成任务中优于AdapterFusion但不及其他PEFT方法；在提交信息生成任务中不如AdapterFusion；在代码翻译任务中劣于AdapterFusion且差距随模型增大略微加大，而其他PEFT方法表现更佳。

Conclusion: AdvFusion在不同代码任务中表现差异明显，未能全面超越现有方法，表明PEFT方法的任务适应性和模型规模影响需进一步研究。

Abstract: Programming languages can benefit from one another by utilizing a language
model for software engineering tasks. Full fine-tuning and Parameter Efficient
Fine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for
multilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims
to enhance task performance by leveraging information from multiple programming
languages, but primarily focuses on the target programming language.
  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that
effectively learns from other programming languages before adapting to the
target task. Though previous experiments showed that AdvFusion outperformed
AdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited
to only two tasks, code summarization and method name prediction. In this
study, we expanded our work and investigated AdvFusion on Code Large Language
Models (Code-LLMs), considering three new tasks: code generation, code
translation, and commit message generation. We observed that different
Code-LLMs/tasks exhibit different characteristics. In code generation,
AdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,
Compacter, and TaskAdapter). In commit message generation, AdapterFusion
performed better than AdvFusion, and contrary to code generation, we found that
the other PEFT methods do not have better performance. In code translation,
AdvFusion performed worse than AdapterFusion overall, with the performance gap
marginally widening as the model size increases. However, consistent with code
generation, other PEFT methods showed better performance.

</details>


### [54] [An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering](https://arxiv.org/abs/2511.02874)
*Jannatul Shefa,Taylan G. Topcu*

Main category: cs.SE

TL;DR: 本文比较了FMEA、FHA和FFIP三种安全分析技术，探讨其在基于模型的系统工程（MBSE）中的集成现状，发现FFIP更适合现代复杂系统的安全需求，且MBSE整合主要集中在FMEA，尚无统一标准。


<details>
  <summary>Details</summary>
Motivation: 随着系统复杂度增加，需在系统生命周期早期进行有效安全分析以识别和缓解风险。探索关键安全分析方法及其在MBSE中的整合，推动数字工程转型。

Method: 采用两阶段方法：第一阶段对FMEA、FHA和FFIP进行对比分析，评估各自流程、优势及局限；第二阶段回顾现有文献中各方法MBSE集成的研究现状和分类。

Result: FFIP在识别系统新兴行为、二阶效应及故障传播方面表现优越，更适合现代互联系统安全需求。MBSE集成主要聚焦FMEA，FHA和FFIP的集成尚处于起步阶段。FMEA-MBSE集成可分为四类方法，但缺乏统一框架。

Conclusion: 现有MBSE整合缺乏标准化框架，存在提升空间。结合FFIP优势开发统一集成方案，有助于推动数字工程中的安全管理方法和工具协同发展。

Abstract: As systems become increasingly complex, conducting effective safety analysis
in the earlier phases of a system's lifecycle is essential to identify and
mitigate risks before they escalate. To that end, this paper investigates the
capabilities of key safety analysis techniques, namely: Failure Mode and
Effects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional
Failure Identification and Propagation (FFIP), along with the current state of
the literature in terms of their integration into Model-Based Systems
Engineering (MBSE). A two-phase approach is adopted. The first phase is focused
on contrasting FMEA, FHA, and FFIP techniques, examining their procedures,
along with a documentation of their relative strengths and limitations. Our
analysis highlights FFIP's capability in identifying emergent system behaviors,
second-order effects, and fault propagation; thus, suggesting it is better
suited for the safety needs of modern interconnected systems. Second, we review
the existing research on the efforts to integrate each of these methods into
MBSE. We find that MBSE integration efforts primarily focus on FMEA, and
integration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration
efforts could be organized into four categories: model-to-model transformation,
use of external customized algorithms, built-in MBSE packages, and manual use
of standard MBSE diagrams. While our findings indicate a variety of MBSE
integration approaches, there is no universally established framework or
standard. This leaves room for an integration approach that could support the
ongoing Digital Engineering transformation efforts by enabling a more
synergistic lifecycle safety management methods and tools.

</details>


### [55] [CS Educator challenges and their solutions : A systematic mapping study](https://arxiv.org/abs/2511.02876)
*Anjali Chouhan,Sruti Srinivasa Ragavan,Amey Karkare*

Main category: cs.SE

TL;DR: 本文系统回顾了过去五年计算机科学教育领域面临的挑战和应对措施，涵盖教学、情感、技术和机构等十个主题。


<details>
  <summary>Details</summary>
Motivation: 当前计算机科学教育快速发展，但缺乏系统整理教育者面对的具体挑战及其应对策略，导致部分领域研究不足。

Method: 通过结构化文献综述，分析过去五年内期刊发表于同行评议的研究论文，聚焦教育挑战与补救措施，分类总结十个主题。

Result: 发现评估实践、教师培训、课堂管理、情感健康等领域存在反复出现的问题，同时识别多种缓解策略如专业发展项目与政策干预，也揭示部分领域关注不足。

Conclusion: 本综述为计算机科学教育现状提供综合认知，有助于研究者、课程设计者及政策制定者提升教学效果及支持教育工作者。

Abstract: Computer Science (CS) education is expanding rapidly, but educators continue
to face persistent challenges in teaching and learning environments.Despite
growing interest, limited systematic work exists to categorize and synthesize
the specific challenges faced by CS educators and the remedies adopted in
response.This is problematic because it remains unclear which areas have been
thoroughly addressed and which still lack sufficient scholarly attention. In
this study, we conducted a structured literature review of peer-reviewed
research papers published over the last five years, focusing on challenges and
remedies across ten categorized themes, including pedagogical, emotional,
technological, and institutional dimensions.Our analysis revealed recurring
issues in areas such as assessment practices, teacher training, classroom
management, and emotional well-being, along with various strategies such as
professional development programs and policy interventions adopted to mitigate
them while also revealing several areas that have received insufficient
attention.This review offers a consolidated understanding of the CS education
landscape, providing valuable insights for researchers, curriculum designers,
and policymakers aiming to improve teaching effectiveness and educator support.

</details>


### [56] [AgentSLA : Towards a Service Level Agreement for AI Agents](https://arxiv.org/abs/2511.02885)
*Gwendal Jouneaux,Jordi Cabot*

Main category: cs.SE

TL;DR: 本文提出了基于ISO/IEC 25010标准的AI代理质量模型及支持SLA定义的领域特定语言，解决AI代理服务质量规范难题。


<details>
  <summary>Details</summary>
Motivation: AI代理作为AI组件，虽提升系统自治性，但缺乏明确的服务质量（QoS）规范和服务等级协议（SLA）定义，制约智能软件系统的质量保障。

Method: 基于ISO/IEC 25010标准构建AI代理质量模型，设计专门的领域特定语言（DSL）用于定义AI代理服务的SLA。

Result: 提出的质量模型和DSL有助于明确AI代理服务的质量要求，实现智能软件系统的服务质量保障。

Conclusion: 通过构建质量模型和定义语言，解决了AI代理服务质量规范和SLA定义难题，为智能软件系统的质量保证提供了新思路。

Abstract: AI components are increasingly becoming a key element of all types of
software systems to enhance their functionality. These AI components are often
implemented as AI Agents, offering more autonomy than a plain integration of
Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an
Agent-as-a-Service one, bringing new challenges to the development of smart
software systems. Indeed, while support for the design, implementation, and
deployment of those agents exist, the specification of Quality of Service (QoS)
and definition of Service Level Agreements (SLAs) aspects for those agents,
important to ensure the quality of the resulting systems, remains an open
challenge. Part of this is due to the difficulty to clearly define quality in
the context of AI components, resulting in a lack of consensus on how to best
approach Quality Assurance (QA) for these types of systems. To address this
challenge, this paper proposes both a quality model for AI agents based on the
ISO/IEC 25010 standard, and a domain specific language to support the
definition of SLAs for the services provided by these AI agents.

</details>


### [57] [Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension](https://arxiv.org/abs/2511.02922)
*Yunhan Qiao,Christopher Hundhausen,Summit Haque,Md Istiak Hossain Shihab*

Main category: cs.SE

TL;DR: 本研究探讨生成式AI工具GitHub Copilot在遗留代码维护任务中的影响，发现其能显著提升编程效率和测试表现，但未提升代码理解能力。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI编码助手的发展，虽然其提升了开发者生产力，但其对代码理解的影响尚不明确，本研究旨在验证这一点。

Method: 采用18名计算机科学研究生为对象的内被试设计实验，让他们在有无Copilot辅助下完成特征实现任务，并测量任务时间、通过测试用例数及理解能力。

Result: Copilot显著减少了任务完成时间，增加了通过的测试用例数，但参与者的代码理解评分在两种条件下无显著差异，且理解能力与任务表现无相关性。

Conclusion: 生成式AI工具虽然能加快遗留代码的编程进度，但未必能提升对代码库的理解，提示在教育和工具设计中需关注理解与性能的差距。

Abstract: Code comprehension is essential for brownfield programming tasks, in which
developers maintain and enhance legacy code bases. Generative AI (GenAI) coding
assistants such as GitHub Copilot have been shown to improve developer
productivity, but their impact on code understanding is less clear. We
replicate and extend a previous study by exploring both performance and
comprehension in GenAI-assisted brownfield programming tasks. In a
within-subjects experimental study, 18 computer science graduate students
completed feature implementation tasks with and without Copilot. Results show
that Copilot significantly reduced task time and increased the number of test
cases passed. However, comprehension scores did not differ across conditions,
revealing a comprehension-performance gap: participants passed more test cases
with Copilot, but did not demonstrate greater understanding of the legacy
codebase. Moreover, we failed to find a correlation between comprehension and
task performance. These findings suggest that while GenAI tools can accelerate
programming progress in a legacy codebase, such progress may come without an
improved understanding of that codebase. We consider the implications of these
findings for programming education and GenAI tool design.

</details>


### [58] [Risk Estimation in Differential Fuzzing via Extreme Value Theory](https://arxiv.org/abs/2511.02927)
*Rafael Baez,Alejandro Olivas,Nathan K. Diamond,Marcelo Frias,Yannic Noller,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 本文探讨了应用极值理论（EVT）来评估差分模糊测试中遗漏漏洞的风险，并通过实验证明EVT方法在预测风险和节省计算资源方面优于传统统计方法。


<details>
  <summary>Details</summary>
Motivation: 差分模糊测试虽然有效检测软件漏洞，但无法保证无漏洞存在，如何量化未发现漏洞的风险是亟需解决的问题。

Method: 将差分模糊测试过程视为极值分布，采用极值理论分析测试尾部数据，通过实验证明其可行性并与马尔可夫、不等式及贝叶斯因子等基线方法比较效果。

Result: EVT方法在超过14%的案例中优于基线方法，64.2%的案例达到同等性能，并能在实际Java库测试中节省大量字节码执行次数，实现了提前停止测试。

Conclusion: 极值理论为差分模糊测试提供了有效风险评估手段，能显著提升测试效率和准确性，降低遗漏漏洞的风险。

Abstract: Differential testing is a highly effective technique for automatically
detecting software bugs and vulnerabilities when the specifications involve an
analysis over multiple executions simultaneously. Differential fuzzing, in
particular, operates as a guided randomized search, aiming to find (similar)
inputs that lead to a maximum difference in software outputs or their
behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the
absence of bugs: from a differential fuzzing campaign that has observed no bugs
(or a minimal difference), what is the risk of observing a bug (or a larger
difference) if we run the fuzzer for one or more steps?
  This paper investigates the application of Extreme Value Theory (EVT) to
address the risk of missing or underestimating bugs in differential fuzzing.
The key observation is that differential fuzzing as a random process resembles
the maximum distribution of observed differences. Hence, EVT, a branch of
statistics dealing with extreme values, is an ideal framework to analyze the
tail of the differential fuzzing campaign to contain the risk. We perform
experiments on a set of real-world Java libraries and use differential fuzzing
to find information leaks via side channels in these libraries. We first
explore the feasibility of EVT for this task and the optimal hyperparameters
for EVT distributions. We then compare EVT-based extrapolation against baseline
statistical methods like Markov's as well as Chebyshev's inequalities, and the
Bayes factor. EVT-based extrapolations outperform the baseline techniques in
14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we
evaluate the accuracy and performance gains of EVT-enabled differential fuzzing
in real-world Java libraries, where we reported an average saving of tens of
millions of bytecode executions by an early stop.

</details>


### [59] [Assurance Case Development for Evolving Software Product Lines: A Formal Approach](https://arxiv.org/abs/2511.03026)
*Logan Murphy,Torin Viger,Alessio Di Sandro,Aren A. Babikian,Marsha Chechik*

Main category: cs.SE

TL;DR: 本文提出了一种针对软件产品线(SPL)的可变性感知结构化保障案例(AC)的形式化方法，支持整个产品线的保障案例开发和回归分析。


<details>
  <summary>Details</summary>
Motivation: 传统的保障案例难以针对具有重叠但不同特性的SPL中的大量产品单独开发和维护，且SPL演化使得单独评估变化影响不可行。

Method: 本文形式化了针对SPL的可变性感知保障案例语言，研究了基于模板的保障案例提升开发方法，并定义了一种回归分析方法来评估SPL演化对保障案例的影响，同时开发了一个基于模型的保障管理工具。

Result: 方法成功应用于医疗设备产品线的保障案例开发，实现了对整个产品线保障案例的一体化创建和对演化影响的变异感知分析。

Conclusion: 该方法有效支持了SPL的保障案例开发和维护，解决了大规模产品线的保障案例开发不可行性及演化影响评估难题，提升了保障案例管理的效率和准确性。

Abstract: In critical software engineering, structured assurance cases (ACs) are used
to demonstrate how key system properties are supported by evidence (e.g., test
results, proofs). Creating rigorous ACs is particularly challenging in the
context of software product lines (SPLs), i.e, sets of software products with
overlapping but distinct features and behaviours. Since SPLs can encompass very
large numbers of products, developing a rigorous AC for each product
individually is infeasible. Moreover, if the SPL evolves, e.g., by the
modification or introduction of features, it can be infeasible to assess the
impact of this change. Instead, the development and maintenance of ACs ought to
be lifted such that a single AC can be developed for the entire SPL
simultaneously, and be analyzed for regression in a variability-aware fashion.
In this article, we describe a formal approach to lifted AC development and
regression analysis. We formalize a language of variability-aware ACs for SPLs
and study the lifting of template-based AC development. We also define a
regression analysis to determine the effects of SPL evolutions on
variability-aware ACs. We describe a model-based assurance management tool
which implements these techniques, and illustrate our contributions by
developing an AC for a product line of medical devices.

</details>


### [60] [Adaptive Detection of Software Aging under Workload Shift](https://arxiv.org/abs/2511.03103)
*Rafael José Moura,Maria Gizele Nascimento,Fumio Machida,Ermeson Andrade*

Main category: cs.SE

TL;DR: 本文提出了一种基于机器学习的自适应方法，用于检测动态工作负载条件下的软件老化，实验结果表明自适应模型在各种工况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 长时间运行的软件系统会出现性能逐渐下降和故障风险增加的问题，即软件老化，传统静态模型在动态负载下性能下降明显，需要自适应检测方法。

Method: 基于机器学习提出自适应检测方法，结合漂移检测方法(DDM)和自适应窗口(ADWIN)，处理负载变化引起的概念漂移。

Result: 静态模型在未见过的负载配置下性能下降明显，自适应模型尤其是采用ADWIN的模型保持高准确率，F1分数均超过0.93。

Conclusion: 基于ADWIN的自适应模型能有效应对动态负载引起的软件老化检测问题，展现出较静态模型更优的鲁棒性和准确性。

Abstract: Software aging is a phenomenon that affects long-running systems, leading to
progressive performance degradation and increasing the risk of failures. To
mitigate this problem, this work proposes an adaptive approach based on machine
learning for software aging detection in environments subject to dynamic
workload conditions. We evaluate and compare a static model with adaptive
models that incorporate adaptive detectors, specifically the Drift Detection
Method (DDM) and Adaptive Windowing (ADWIN), originally developed for concept
drift scenarios and applied in this work to handle workload shifts. Experiments
with simulated sudden, gradual, and recurring workload transitions show that
static models suffer a notable performance drop when applied to unseen workload
profiles, whereas the adaptive model with ADWIN maintains high accuracy,
achieving an F1-Score above 0.93 in all analyzed scenarios.

</details>


### [61] [Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat](https://arxiv.org/abs/2511.03136)
*Kexing Ji,Shiyun Fu,Cuiyun Gao,Yujia Chen,Zezhou Yang,Chaozheng Wang,Yuetang Deng*

Main category: cs.SE

TL;DR: 本文研究了自动化提示生成（APG）在代码智能中的应用，重点探讨了指令生成（IG）和多步推理（MSR）两大部分，并提出了一种结合最佳方法的新型APG策略，在多个任务和模型上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型代码模型(Large Code Models, LCMs)的效果高度依赖提示的质量，而当前提示设计多为手动，耗时且依赖具体模型和任务。自动化提示生成在自然语言处理领域已有探索，但在代码智能领域尚不足，亟需自动化提示来帮助开发者应对多样任务和黑盒模型。

Method: 文章重点研究APG中的指令生成(IG)和多步推理(MSR)，评估多种常用方法在四个开源LCM和三种代码智能任务上的表现。基于实验结果，提出结合两部分最佳方法的新型APG方法。

Result: 实验表明，IG和MSR显著优于基础提示，在代码翻译、代码摘要和API推荐任务中分别提升CodeBLEU 28.38%、ROUGE-L 58.11%、SuccessRate@1 84.53%。在工业场景WeChat-Bench中API推荐任务实现MRR提升148.89%。

Conclusion: 自动化提示生成特别是结合指令生成和多步推理可以大幅提升代码智能任务的性能，为开发者提供高效、适应性强的提示设计方案，促进大型代码模型的广泛应用。

Abstract: Large Code Models (LCMs) show potential in code intelligence, but their
effectiveness is greatly influenced by prompt quality. Current prompt design is
mostly manual, which is time-consuming and highly dependent on specific LCMs
and tasks. While automated prompt generation (APG) exists in NLP, it is
underexplored for code intelligence. This creates a gap, as automating the
prompt process is essential for developers facing diverse tasks and black-box
LCMs.
  To mitigate this, we empirically investigate two important parts of APG:
Instruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a
task-related description to instruct LCMs, while MSR guides them to produce
logical steps before the final answer. We evaluate widely-used APG methods for
each part on four open-source LCMs and three code intelligence tasks: code
translation (PL-PL), code summarization (PL-NL), and API recommendation
(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance
performance compared to basic prompts. Based on these results, we propose a
novel APG approach combining the best methods of the two parts. Experiments
show our approach achieves average improvements of 28.38% in CodeBLEU (code
translation), 58.11% in ROUGE-L (code summarization), and 84.53% in
SuccessRate@1 (API recommendation) over basic prompts. To validate its
effectiveness in an industrial scenario, we evaluate our approach on
WeChat-Bench, a proprietary dataset, achieving an average MRR improvement of
148.89% for API recommendation.

</details>


### [62] [RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring](https://arxiv.org/abs/2511.03153)
*Khouloud Oueslati,Maxime Lamothe,Foutse Khomh*

Main category: cs.SE

TL;DR: 本文提出了一种基于多智能体大型语言模型（LLM）的软件重构框架RefAgent，通过规划、执行、测试和自我反思迭代优化重构，显著提升软件质量和测试通过率，优于单智能体及传统工具。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM在软件重构中依赖静态指令，缺乏动态适应和自主决策能力，限制了其在复杂重构任务中的表现。

Method: 设计了多智能体框架RefAgent，分别负责规划、执行、测试和迭代优化，利用自我反思与工具调用，实现端到端自动化重构。

Result: 在8个开源Java项目上测试，RefAgent实现了90%的单元测试通过率，中位数代码异味减少52.5%，关键质量指标提升8.6%，重构机会识别F1分数达79.15%，明显优于单智能体和传统搜索工具。

Conclusion: 多智能体LLM架构有潜力推动自动化软件重构的发展，提升代码质量及开发效率。

Abstract: Large Language Models (LLMs) have substantially influenced various software
engineering tasks. Indeed, in the case of software refactoring, traditional
LLMs have shown the ability to reduce development time and enhance code
quality. However, these LLMs often rely on static, detailed instructions for
specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving
contexts and autonomously make decisions by interacting with software tools and
executing workflows. In this paper, we explore the potential of LLM-based
agents in supporting refactoring activities. Specifically, we introduce
RefAgent, a multi-agent LLM-based framework for end-to-end software
refactoring. RefAgent consists of specialized agents responsible for planning,
executing, testing, and iteratively refining refactorings using self-reflection
and tool-calling capabilities. We evaluate RefAgent on eight open-source Java
projects, comparing its effectiveness against a single-agent approach, a
search-based refactoring tool, and historical developer refactorings. Our
assessment focuses on: (1) the impact of generated refactorings on software
quality, (2) the ability to identify refactoring opportunities, and (3) the
contribution of each LLM agent through an ablation study. Our results show that
RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a
median of 52.5%, and improves key quality attributes (e.g., reusability) by a
median of 8.6%. Additionally, it closely aligns with developer refactorings and
the search-based tool in identifying refactoring opportunities, attaining a
median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent
approaches, RefAgent improves the median unit test pass rate by 64.7% and the
median compilation success rate by 40.1%. These findings highlight the promise
of multi-agent architectures in advancing automated software refactoring.

</details>


### [63] [Understanding Robustness of Model Editing in Code LLMs: An Empirical Study](https://arxiv.org/abs/2511.03182)
*Vinaik Chhetri,A. B Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: 本文系统评估了五种先进的模型编辑方法在更新代码大语言模型以适应API废弃情境下的表现，发现即时和顺序编辑均导致模型性能大幅下降，且仅极少数更新能正确反映预期变更。


<details>
  <summary>Details</summary>
Motivation: 随着编程语言和API持续演进，代码大语言模型预训练后保持静态，导致生成已废弃或不兼容代码，影响可靠性，而全面重训练成本高昂，模型编辑作为轻量替代方法的有效性仍不明。

Method: 针对CodeLlama、CodeQwen1.5和DeepSeek-Coder三大开源代码LLM，在受控API废弃场景下，系统测试五种模型编辑方法（FT、GRACE、MEMIT、PMET、ROME），评估包括即时和顺序编辑，使用三套不同评测集考察可靠性、泛化性和特异性，通过编译成功率、部分测试通过率和全部测试通过率衡量模型正确性。

Result: 即时编辑导致模型性能显著下降，语法有效率最多降低86个百分点，功能正确率下降45个百分点，顺序编辑使性能进一步恶化，部分情况下模型性能彻底崩溃；大多数通过测试的代码为变通写法，正确反映变更的仅约6%，而错误采纳导致的失败和错误显著更多。

Conclusion: 模型编辑虽有潜力作为轻量更新手段，但当前方法在代码LLM应对API变更上的适应能力不足，容易引入错误且正确集成更新的概率较低，提示需发展更有效的模型编辑技术以提升实际应用可靠性。

Abstract: Large language models (LLMs) are increasingly used in software development.
However, while LLMs remain static after pretraining, programming languages and
APIs continue to evolve, leading to the generation of deprecated or
incompatible code that undermines reliability. Retraining LLMs from scratch to
reflect such changes is computationally expensive, making model editing a
promising lightweight alternative that updates only a small subset of
parameters. Despite its potential, it remains unclear whether model editing
yields genuine syntactic and semantic adaptations or merely superficial fixes.
In this work, we present a systematic study of five state-of-the-art model
editing methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We
apply these methods to three leading open-source code LLMs, CodeLlama,
CodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.
Our evaluation covers both instant and sequential editing settings, using three
disjoint evaluation sets designed to assess reliability, generalization, and
specificity. We measure model correctness at three levels: successful
compilation, partial test case pass, and full test pass. Our findings show that
instant edits consistently degrade model performance, with syntactic validity
dropping by up to 86 percentage points and functional correctness declining by
45 points even in the best-performing setting. Sequential edits further amplify
this degradation, and in some cases, model performance collapses entirely.
Across all models, most passing generations relied on workarounds rather than
correctly adopting the intended changes, while faulty adoptions that result in
test failures or compilation errors were significantly more frequent. Correct
adoptions, where the model correctly integrates the intended change, occurred
in only about 6% of cases.

</details>


### [64] [Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling](https://arxiv.org/abs/2511.03404)
*Qianhui Zhao,Li Zhang,Fang Liu,Junhang Cheng,Chengru Wu,Junchen Ai,Qiaoyuanhe Meng,Lichen Zhang,Xiaoli Lian,Shubin Song,Yuanping Guo*

Main category: cs.SE

TL;DR: 本文提出了CodeProjectEval数据集和ProjectGen多代理框架，以解决当前项目级代码生成中数据集不真实、评估指标不可靠和生成质量不高的问题，实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前大规模语言模型在自动化代码生成方面虽然取得进展，但在真实项目级代码生成中仍面临数据集不现实、评估指标不可靠、需求与代码间语义鸿沟大以及层次依赖管理困难等问题。

Method: 作者构建了基于18个真实仓库的CodeProjectEval数据集，包含文档和可执行测试，用于自动化评价；提出ProjectGen多代理框架，将项目代码生成分解为架构设计、框架生成和代码填充三个阶段，并引入语义软件架构树(SSAT)以连接用户需求和代码实现。

Result: 实验表明，ProjectGen在DevBench数据集上测试通过率提升57%，在CodeProjectEval上通过测试用例数约提升十倍，显著优于基线方法。

Conclusion: 通过引入更真实的数据集和分阶段的多代理生成框架，结合语义软件架构树，本文有效提升了项目级代码生成的自动化能力和性能，推动实际软件工程中的自动代码生成发展。

Abstract: In recent years, Large Language Models (LLMs) have achieved remarkable
progress in automated code generation. In real-world software engineering, the
growing demand for rapid iteration and continuous delivery underscores the
importance of project-level code generation, where LLMs are expected to
generate complete software projects directly from complex user requirements.
Although existing studies have made initial explorations, they still face key
limitations, including unrealistic datasets and unreliable evaluation metrics
that fail to reflect real-world complexity, the semantic gap between
human-written requirements and machine-interpretable structures, and
difficulties in managing hierarchical dependencies and maintaining quality
throughout the generation process. To address these limitations, we first
introduce CodeProjectEval, a project-level code generation dataset built from
18 real-world repositories with 12.7 files and 2,388.6 lines of code per task
on average, supplemented with documentation and executable test cases for
automatic evaluation. We further propose ProjectGen, a multi-agent framework
that decomposes projects into architecture design, skeleton generation, and
code filling stages with iterative refinement and memory-based context
management. Within this framework, we introduce the Semantic Software
Architecture Tree (SSAT), a structured and semantically rich representation
that effectively bridges user requirements and source code implementation.
Experiments show that ProjectGen achieves state-of-the-art performance, passing
52/124 test cases on the small-scale project-level code generation dataset
DevBench, a 57% improvement over the baseline approaches, and 310 test cases on
CodeProjectEval, representing an improvement of roughly tenfold compared to the
baselines.

</details>


### [65] [Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement](https://arxiv.org/abs/2511.03421)
*Shihai Wang,Tao Chen*

Main category: cs.SE

TL;DR: 本文提出了一种高效自动量化性能需求的方法LQPR，将性能需求量化问题转化为分类问题，设计了轻量级语言匹配机制，在多个数据集上优于当前九种主流学习方法，成本大幅降低。


<details>
  <summary>Details</summary>
Motivation: 现有性能需求量化多依赖人工，成本高且易出错，因此需要自动且高效的量化方法。

Method: 提出LQPR方法，将量化问题转化为分类问题，结合性能需求的强模式和简洁特点，设计轻量级语言匹配机制代替大型语言模型。

Result: 在多样化数据集上，LQPR在75%以上的案例中表现为最佳，比其他九种主流方法成本低两到三个数量级。

Conclusion: 专门针对性能需求量化设计的方法比通用大型语言模型方法更适合此任务，LQPR有效提升了性能需求自动量化的效率和准确性。

Abstract: Elicited performance requirements need to be quantified for compliance in
different engineering tasks, e.g., configuration tuning and performance
testing. Much existing work has relied on manual quantification, which is
expensive and error-prone due to the imprecision. In this paper, we present
LQPR, a highly efficient automatic approach for performance requirements
quantification.LQPR relies on a new theoretical framework that converts
quantification as a classification problem. Despite the prevalent applications
of Large Language Models (LLMs) for requirement analytics, LQPR takes a
different perspective to address the classification: we observed that
performance requirements can exhibit strong patterns and are often
short/concise, therefore we design a lightweight linguistically induced
matching mechanism. We compare LQPR against nine state-of-the-art
learning-based approaches over diverse datasets, demonstrating that it is
ranked as the sole best for 75% or more cases with two orders less cost. Our
work proves that, at least for performance requirement quantification,
specialized methods can be more suitable than the general LLM-driven
approaches.

</details>


### [66] [U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility](https://arxiv.org/abs/2511.03517)
*Wencheng Ye,Yan Liu*

Main category: cs.SE

TL;DR: 该论文提出了U2F框架，通过多智能体系统和认知机制挖掘软件工程中的未知创新方案，提升创新性和可行性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在软件工程任务中多采用传统方法，难以应对开放世界中超越既定范式的新挑战，缺乏对新颖解决路径的探索。

Method: 设计了U2F认知启发、多智能体框架，包括发现-探索-整合多智能体系统及跨域类比、逆向思维和外部验证三大认知增强机制，系统性挖掘并整合未知的创新解决方案。

Result: 在218个真实软件工程案例中，U2F令人类专家感知整体创新性提升14%、语义创新性提升51%，可行性维持稳定，LLM评估结果一致。

Conclusion: 因应不确定性可以激发软件工程中的创新潜力，U2F框架有助于突破传统范式限制，促进新颖解决方案的发现。

Abstract: Large language models (LLMs) have shown strong capabilities in software
engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle
well-defined problems using conventional methods, often overlooking alternative
or innovative solutions beyond their predefined frameworks. This limitation is
evident in open-world software environments, where emerging challenges
transcend established paradigms.
  We propose U2F (Unknown Unknowns to Functional solutions), a
cognitive-inspired, uncertainty-embracing multi-agent framework that
systematically surfaces "Unknown Unknowns" - novel solution pathways absent
from initial formulations but holding innovative potential. U2F consists of two
key components: (1) a Discovery-Exploration-Integration agent system for
uncovering and synthesizing potential solutions, and (2) cognitive enhancement
mechanisms across three dimensions: cross-domain analogical reasoning, reverse
thinking, and external validation, which strategically reframe and extend
conventional solution boundaries.
  Applied to 218 real-world software enabler stories curated from authentic
engineering tasks, U2F achieved notable improvements: human experts reported a
14 percent increase in overall novelty, 51 percent improvement in semantic
novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based
evaluator. These results highlight the potential of embracing uncertainty as a
catalyst for innovation in software engineering.

</details>


### [67] [Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding](https://arxiv.org/abs/2511.03549)
*Ziv Nevo,Orna Raz,Karen Yorav*

Main category: cs.SE

TL;DR: 本文提出利用GitHub上的自然语言内容增强大型语言模型对代码目的的理解，通过提取相关上下文生成高层次解释，并验证其准确性，提升代码解释的质量和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型虽然能生成代码解释，但通常缺乏软件工程上下文支撑，影响理解的准确性和实用性。

Method: 设计三部分系统：一是提取和结构化GitHub上下文（如PR描述、issue讨论、commit信息）；二是结合上下文生成代码高层次解释；三是验证解释的准确性。实现为独立工具及可集成的服务器。

Result: 通过与多个开源及专有项目开发者进行的小规模用户研究，表明系统生成的解释具有帮助性、非平凡且无虚假信息。

Conclusion: 结合软件工程自然语言上下文的代码解释方法能显著提升大型语言模型的代码理解质量，为AI辅助开发提供可靠支持。

Abstract: Understanding the purpose of source code is a critical task in software
maintenance, onboarding, and modernization. While large language models (LLMs)
have shown promise in generating code explanations, they often lack grounding
in the broader software engineering context. We propose a novel approach that
leverages natural language artifacts from GitHub -- such as pull request
descriptions, issue descriptions and discussions, and commit messages -- to
enhance LLM-based code understanding. Our system consists of three components:
one that extracts and structures relevant GitHub context, another that uses
this context to generate high-level explanations of the code's purpose, and a
third that validates the explanation. We implemented this as a standalone tool,
as well as a server within the Model Context Protocol (MCP), enabling
integration with other AI-assisted development tools. Our main use case is that
of enhancing a standard LLM-based code explanation with code insights that our
system generates. To evaluate explanations' quality, we conducted a small scale
user study, with developers of several open projects, as well as developers of
proprietary projects. Our user study indicates that when insights are generated
they often are helpful and non trivial, and are free from hallucinations.

</details>


### [68] [The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents](https://arxiv.org/abs/2511.03690)
*Xingyao Wang,Simon Rosenberg,Juan Michelini,Calvin Smith,Hoang Tran,Engel Nyst,Rohit Malhotra,Xuhui Zhou,Valerie Chen,Robert Brennan,Graham Neubig*

Main category: cs.SE

TL;DR: 本文介绍了OpenHands软件代理SDK，一款用于轻松构建安全可靠且灵活的软件开发代理的工具包。


<details>
  <summary>Details</summary>
Motivation: 当前广泛使用软件代理于开发流程，但构建生产级代理面临实现灵活、执行安全可靠以及良好用户交互界面等挑战。

Method: 设计了一个简单易扩展的接口支持从基本到复杂功能的代理实现，支持本地到远程无缝执行，集成REST/WebSocket服务，并连接多种用户交互界面；与现有SDK相比，独特集成沙箱执行、生命周期管理、多模型路由和安全分析。

Result: 在SWE-Bench Verified和GAIA基准测试中表现优异，展现出强大的性能。

Conclusion: OpenHands SDK为快速原型开发、定制应用打造及大规模可靠部署代理提供了实用且高效的平台。

Abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensible to more complex, full-featured agents
with features such as custom tools, memory management, and more. For security
and reliability, it delivers seamless local-to-remote execution portability,
integrated REST/WebSocket services. For interaction with human users, it can
connect directly to a variety of interfaces, such as visual workspaces (VS
Code, VNC, browser), command-line interfaces, and APIs. Compared with existing
SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native
sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and
built-in security analysis. Empirical results on SWE-Bench Verified and GAIA
benchmarks demonstrate strong performance. Put together, these elements allow
the OpenHands Software Agent SDK to provide a practical foundation for
prototyping, unlocking new classes of custom applications, and reliably
deploying agents at scale.

</details>
