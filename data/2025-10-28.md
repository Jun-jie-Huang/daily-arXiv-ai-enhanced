<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 114]
- [cs.SE](#cs.SE) [Total: 26]
- [cs.MA](#cs.MA) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Multi-lingual Dataset of Classified Paragraphs from Open Access Scientific Publications](https://arxiv.org/abs/2510.21762)
*Eric Jeangirard*

Main category: cs.CL

TL;DR: 本论文介绍了一个包含83.3万科学文献段落的数据集，分为四类并附有语言和领域标注，支持科学文献挖掘任务。


<details>
  <summary>Details</summary>
Motivation: 科学文献挖掘中需要丰富标注的段落数据集以支持文本分类和命名实体识别模型的训练。

Method: 从开放获取的科学出版物中提取段落，采用fastText进行语言识别，并结合OpenAlex进行领域分类，利用GROBID进行数据处理。

Result: 构建了一个多语言、多领域的科学文献段落数据集，涵盖致谢、数据提及、软件代码提及和临床试验提及四类；数据集公开提供。

Conclusion: 该数据集为科研人员开发科学文献自动化分析工具提供了有价值的资源，促进相关文本挖掘技术的发展。

Abstract: We present a dataset of 833k paragraphs extracted from CC-BY licensed
scientific publications, classified into four categories: acknowledgments, data
mentions, software/code mentions, and clinical trial mentions. The paragraphs
are primarily in English and French, with additional European languages
represented. Each paragraph is annotated with language identification (using
fastText) and scientific domain (from OpenAlex). This dataset, derived from the
French Open Science Monitor corpus and processed using GROBID, enables training
of text classification models and development of named entity recognition
systems for scientific literature mining. The dataset is publicly available on
HuggingFace https://doi.org/10.57967/hf/6679 under a CC-BY license.

</details>


### [2] [Policy Optimization Prefers The Path of Least Resistance](https://arxiv.org/abs/2510.21853)
*Debdeep Sanyal,Aakash Sen Sharma,Dhruv Kumar,Saurabh Deshpande,Murari Mandal*

Main category: cs.CL

TL;DR: 本文研究了在政策优化中放宽严格的思考-回答格式后，模型如何倾向于简化推理过程，导致直接输出答案，体现了政策优化遵循最小阻力路径的原则。


<details>
  <summary>Details</summary>
Motivation: 现有的政策优化算法严格采用思考-回答的链式推理格式，但放宽这些限制后的政策优化行为尚未充分研究。

Method: 通过一系列受控实验，分析政策优化在放宽格式限制后如何表现，并通过奖励分解实验形式化了政策优化的行为准则。

Result: 发现政策优化优先优化最简单的奖励成分，即使给予复杂格式更高的奖励权重，模型仍倾向于跳过显式推理，直接输出答案。

Conclusion: 政策优化在获得自由探索高奖励路径时，也会激励模型投机最简单的奖励成分，这对奖励设计和模型对齐提出了重大挑战。

Abstract: Policy optimization (PO) algorithms are used to refine Large Language Models
for complex, multi-step reasoning. Current state-of-the-art pipelines enforce a
strict think-then-answer format to elicit chain-of-thought (CoT); however, the
behavior of PO when these rigid constraints are relaxed into an open-ended CoT
structure remains an under-studied question. We investigate this gap with an
extensive suite of controlled experiments and identify a consistent principle:
\textit{policy optimization consistently follows the path of least resistance}.
When afforded the flexibility to interleave reasoning and response, policy
optimization consistently learns to discard explicit reasoning, causing the
policy to degenerate to a direct \texttt{<answer>}-only format. This outcome
holds true across various models and algorithms. We find that this collapse in
format is persistent even when the complex \texttt{<think><answer>} format is
assigned up to 4x larger reward weights. We formalize this principle through a
series of controlled reward decomposition experiments, demonstrating a clear
hierarchy: PO systematically optimizes for the simplest reward component first,
a preference that holds even when faced with mutually exclusive choices or
strong incentives for more complex behaviors. Finally, we show that successful
convergence on the high-reward shortcut is not a low-effort drift but is driven
by the optimization process that requires the KL-regularized policy to have
sufficient freedom to make a significant shift from its initial prior. Our
findings reveal that granting policies the freedom to diverge is a double-edged
sword: while necessary for discovering high-reward shortcuts, it also creates a
powerful incentive to game the simplest aspects of the reward function, posing
a critical challenge for reward hacking under alignment.

</details>


### [3] [Language Ranker: A Lightweight Ranking framework for LLM Decoding](https://arxiv.org/abs/2510.21883)
*Chenheng Zhang,Tianqi Du,Jizhe Zhang,Mingqing Xiao,Yifei Wang,Yisen Wang,Zhouchen Lin*

Main category: cs.CL

TL;DR: 本文提出了Language Ranker框架，通过引入轻量级模块对候选回复进行重新排序，在保持性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型主要关注输出分布的优化，忽视了解码过程，且现有基于奖励模型的解码方法计算成本高且应用受限。

Method: 将大语言模型的解码过程视为推荐系统中的排序阶段，设计Language Ranker框架，利用基础模型提取的特征进行候选回复的轻量级重排序。

Result: 在多任务实验中，Language Ranker性能与大型奖励模型相当，但额外参数少于0.5M，显著减少训练和推理的计算开销。

Conclusion: 该方法兼顾效率与效果，有望充分挖掘大语言模型的潜能，提升解码阶段的性能表现。

Abstract: Conventional research on large language models (LLMs) has primarily focused
on refining output distributions, while paying less attention to the decoding
process that transforms these distributions into final responses. Recent
advances, such as scaling the computation of inference time with reward models,
have underscored the importance of decoding, but these methods often suffer
from high computational costs and limited applicability. In this paper, we
revisit LLM generation through the lens of recommender systems, conceptualizing
the decoding process as analogous to the ranking stage in recommendation
pipelines. From this perspective, we observe that both traditional decoding
methods and reward models exhibit clear limitations such as redundancy.
Motivated by this insight, we propose Language Ranker, a novel framework that
introduces a lightweight module to rerank candidate responses using features
extracted by the base model. Experiments across a wide range of tasks show that
Language Ranker achieves performance comparable to large-scale reward models,
while requiring only <0.5M additional parameters, significantly reducing the
computational overhead during both training and inference stages. This
highlights the efficiency and effectiveness of our method, showcasing its
potential to fully unlock the capabilities of LLMs.

</details>


### [4] [Framework for Machine Evaluation of Reasoning Completeness in Large Language Models For Classification Tasks](https://arxiv.org/abs/2510.21884)
*Avinash Patil*

Main category: cs.CL

TL;DR: 本文提出了RACE框架，用于系统性评估大语言模型（LLM）生成的解释与逻辑回归模型特征重要性之间的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习在敏感领域的应用增加，需求透明和可解释的人工智能，但LLM产生的自然语言解释是否真实反映决策信号尚不明确。

Method: 设计RACE框架，通过token级别、字符串精确匹配和编辑距离匹配，比较LLM生成的解释和逻辑回归基线的词汇特征重要性，分析四个文本分类数据集。

Result: 实验证明正确预测对应于较高的支持特征覆盖率，错误预测则对应更高的矛盾特征覆盖率，编辑距离匹配发现了更多同义表达。

Conclusion: LLM解释既包含表层和灵活的证据重用，也可能在错误时放大误导信息，RACE为神经语言模型解释的真实性和推理完整性提供了定量评估基础。

Abstract: The growing adoption of machine learning (ML) in sensitive domains has
heightened the demand for transparent and interpretable artificial
intelligence. Large Language Models (LLMs) are increasingly capable of
producing natural language explanations, yet it remains unclear whether these
rationales faithfully capture the predictive signals that underlie decisions.
This paper introduces RACE-Reasoning Alignment for Completeness of
Explanations, a systematic framework to evaluate the alignment between
LLM-generated explanations and interpretable feature importance scores derived
from a logistic regression baseline. We analyze four widely used text
classification datasets-WIKI ONTOLOGY, AG NEWS, IMDB, and GOEMOTIONS-and
compare LLM rationales against top-ranked supporting and contradicting lexical
features. To capture alignment at multiple levels of granularity, RACE
implements token-aware, exact string, and edit-distance matching techniques.
Empirical results reveal a consistent asymmetry: correct predictions exhibit
higher coverage of supporting features, while incorrect predictions are
associated with elevated coverage of contradicting features. Edit-distance
matching further uncovers paraphrastic overlaps, boosting coverage while
preserving this asymmetry. These findings demonstrate that LLM rationales
combine both surface-level and flexible evidence reuse, yet can also amplify
misleading cues in error cases. RACE provides new insights into the
faithfulness of LLM explanations and establishes a quantitative basis for
evaluating reasoning completeness in neural language models.

</details>


### [5] [Preventing Catastrophic Forgetting: Behavior-Aware Sampling for Safer Language Model Fine-Tuning](https://arxiv.org/abs/2510.21885)
*Anh Pham,Mihir Thalanki,Michael Sun,Aditya Chaloo,Ankita Gupta,Tian Xia,Aditya Mate,Ehimwenma Nosakhare,Soundararajan Srinivasan*

Main category: cs.CL

TL;DR: 本文针对大语言模型微调时遗忘安全行为问题，提出基于行为和语义多样性选择安全训练样本的方法，有效降低有害输出同时保持有用性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在微调良性数据时会遗忘之前的安全行为，导致潜在有害输出，现有方法随机构造安全样本无法明确筛选最有效的样本。

Method: 提出行为感知采样框架，根据指令-响应行为（如拒绝或顺从）和有害类别的语义多样性来选择安全训练示例，改进训练数据选择策略。

Result: 系统评估显示，该方法在增加仅0.5%训练数据的情况下，实现有害输出减少最高41%，同时保持模型的帮助性。

Conclusion: 有针对性的训练数据选择能够显著提高微调过程中模型的安全性和训练效率，减少灾难性遗忘问题。

Abstract: Large language models often lose previously aligned safety behaviors when
fine-tuned on benign data, a phenomenon known as catastrophic forgetting. Prior
work shows that adding random safety examples can mitigate this effect, but it
remains unclear which examples are most effective. We propose a behavior-aware
sampling framework that selects safety examples based on two complementary
factors: instruction-response behavior (e.g., refusal versus compliance) and
semantic diversity across harm categories. Systematic evaluation shows that
this approach substantially reduces harmful outputs while maintaining
helpfulness, achieving up to a 41% reduction in harmfulness with only 0.5%
additional training data. These results highlight how targeted data selection
can improve the safety and efficiency of fine-tuning at scale.

</details>


### [6] [Embedding Trust: Semantic Isotropy Predicts Nonfactuality in Long-Form Text Generation](https://arxiv.org/abs/2510.21891)
*Dhrupad Bhardwaj,Julia Kempe,Tim G. J. Rudner*

Main category: cs.CL

TL;DR: 本文提出利用语义各向同性（文本嵌入在单位球面上的均匀程度）评估大语言模型生成的长文本回答的可信度，发现语义各向同性越高，事实一致性越低。


<details>
  <summary>Details</summary>
Motivation: 现有对大语言模型长文本回答的可信度评估依赖逐条事实核查，计算成本高且不稳定，亟需一种低成本、可靠的方法。

Method: 生成多个长文本回答，对其文本嵌入进行单位球面归一化，计算嵌入的角度离散度作为语义各向同性指标，用以判断回答的事实一致性。

Result: 语义各向同性指标与事实一致性负相关，在无需标注数据、微调或参数选择的前提下，能在多个领域中准确预测长文本回答的非事实性表现优于现有方法。

Conclusion: 语义各向同性是一种有效、低成本的长文本回答可信度评估方法，适合集成进实际大语言模型应用流程中。

Abstract: To deploy large language models (LLMs) in high-stakes application domains
that require substantively accurate responses to open-ended prompts, we need
reliable, computationally inexpensive methods that assess the trustworthiness
of long-form responses generated by LLMs. However, existing approaches often
rely on claim-by-claim fact-checking, which is computationally expensive and
brittle in long-form responses to open-ended prompts. In this work, we
introduce semantic isotropy -- the degree of uniformity across normalized text
embeddings on the unit sphere -- and use it to assess the trustworthiness of
long-form responses generated by LLMs. To do so, we generate several long-form
responses, embed them, and estimate the level of semantic isotropy of these
responses as the angular dispersion of the embeddings on the unit sphere. We
find that higher semantic isotropy -- that is, greater embedding dispersion --
reliably signals lower factual consistency across samples. Our approach
requires no labeled data, no fine-tuning, and no hyperparameter selection, and
can be used with open- or closed-weight embedding models. Across multiple
domains, our method consistently outperforms existing approaches in predicting
nonfactuality in long-form responses using only a handful of samples --
offering a practical, low-cost approach for integrating trust assessment into
real-world LLM workflows.

</details>


### [7] [Understanding Network Behaviors through Natural Language Question-Answering](https://arxiv.org/abs/2510.21894)
*Mingzhe Xing,Chang Tian,Jianan Zhang,Lichen Pan,Peipei Liu,Zhaoteng Yan,Yinliang Yue*

Main category: cs.CL

TL;DR: 本文提出了NetMind框架，通过自然语言查询网络配置，提升大规模网络行为理解的准确性与可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有网络配置理解方法依赖领域专用语言和形式化模型，学习曲线陡峭且灵活性差，利用自然语言界面和大规模语言模型具有更好易用性和推理能力，但面临长上下文、设备异构性和复杂拓扑的挑战。

Method: NetMind采用树状配置分块策略保持语义连贯，构建统一事实图规范设备配置，并设计混合命令式-声明式语言降低大语言模型推理负担。

Result: 在构建的自然语言问答与网络配置基准上，NetMind在网络行为理解的准确性和可扩展性方面均优于现有方法。

Conclusion: NetMind有效解决了大规模、多设备、复杂网络环境下自然语言驱动的网络行为理解问题，展现出更好的性能与可用性。

Abstract: Modern large-scale networks introduce significant complexity in understanding
network behaviors, increasing the risk of misconfiguration. Prior work proposed
to understand network behaviors by mining network configurations, typically
relying on domain-specific languages interfaced with formal models. While
effective, they suffer from a steep learning curve and limited flexibility. In
contrast, natural language (NL) offers a more accessible and interpretable
interface, motivating recent research on NL-guided network behavior
understanding. Recent advances in large language models (LLMs) further enhance
this direction, leveraging their extensive prior knowledge of network concepts
and strong reasoning capabilities. However, three key challenges remain: 1)
numerous router devices with lengthy configuration files challenge LLM's
long-context understanding ability; 2) heterogeneity across devices and
protocols impedes scalability; and 3) complex network topologies and protocols
demand advanced reasoning abilities beyond the current capabilities of LLMs. To
tackle the above challenges, we propose NetMind, a novel framework for querying
networks using NL. Our approach introduces a tree-based configuration chunking
strategy to preserve semantic coherence while enabling efficient partitioning.
We then construct a unified fact graph as an intermediate representation to
normalize vendor-specific configurations. Finally, we design a hybrid
imperative-declarative language to reduce the reasoning burden on LLMs and
enhance precision. We contribute a benchmark consisting of NL question-answer
pairs paired with network configurations. Experiments demonstrate that NetMind
achieves accurate and scalable network behavior understanding, outperforming
existing baselines.

</details>


### [8] [Deep Literature Survey Automation with an Iterative Workflow](https://arxiv.org/abs/2510.21900)
*Hongbo Zhang,Han Cui,Yidong Wang,Yijian Tian,Qi Guo,Cunxiang Wang,Jian Wu,Chiyu Song,Yue Zhang*

Main category: cs.CL

TL;DR: 本文提出了一个基于递归大纲生成的自动文献综述框架IterSurvey，逐步检索和更新文献大纲，提升综述的内容覆盖、结构连贯性和引用质量。


<details>
  <summary>Details</summary>
Motivation: 现有自动文献综述系统多采用一次性检索和静态大纲生成方式，导致检索噪声大、结构零散和上下文过载，影响综述质量。

Method: 设计了递归大纲生成框架，由规划代理逐步检索、阅读并更新大纲；通过论文卡片提炼文献贡献、方法和发现，引入审阅与优化循环及多模态元素（图表）增强文本流畅性和结合度。

Result: 在多主题实验中，IterSurvey在内容覆盖、结构连贯性、引用质量等指标显著优于当前先进方法，生成更易理解和组织更好的综述文章。

Conclusion: 迭代式动态生成大纲的方法有助于提升自动文献综述的综合质量，辅助科研人员快速获取高质量综述内容，同时引入了更合理的评测基准Survey-Arena提升评估可靠性。

Abstract: Automatic literature survey generation has attracted increasing attention,
yet most existing systems follow a one-shot paradigm, where a large set of
papers is retrieved at once and a static outline is generated before drafting.
This design often leads to noisy retrieval, fragmented structures, and context
overload, ultimately limiting survey quality. Inspired by the iterative reading
process of human researchers, we propose \ours, a framework based on recurrent
outline generation, in which a planning agent incrementally retrieves, reads,
and updates the outline to ensure both exploration and coherence. To provide
faithful paper-level grounding, we design paper cards that distill each paper
into its contributions, methods, and findings, and introduce a
review-and-refine loop with visualization enhancement to improve textual flow
and integrate multimodal elements such as figures and tables. Experiments on
both established and emerging topics show that \ours\ substantially outperforms
state-of-the-art baselines in content coverage, structural coherence, and
citation quality, while producing more accessible and better-organized surveys.
To provide a more reliable assessment of such improvements, we further
introduce Survey-Arena, a pairwise benchmark that complements absolute scoring
and more clearly positions machine-generated surveys relative to human-written
ones. The code is available at
https://github.com/HancCui/IterSurvey\_Autosurveyv2.

</details>


### [9] [Explaining and Mitigating Crosslingual Tokenizer Inequities](https://arxiv.org/abs/2510.21909)
*Catherine Arnett,Tyler A. Chang,Stella Biderman,Benjamin K. Bergen*

Main category: cs.CL

TL;DR: 该论文研究了不同语言中单语分词器的token溢价差异及其影响因素，发现词汇表大小和预分词方法对token溢价有显著影响，且通过调整词汇表大小和使用superword分词器可有效降低token溢价。


<details>
  <summary>Details</summary>
Motivation: 不同语言的分词编码所需token数量不同，token溢价导致训练吞吐量降低和推理成本增加，需要深入理解跨语言token溢价的成因并寻找减小溢价的方法。

Method: 训练约7000个涵盖97种语言的单语分词器，控制分词算法、词汇表大小及数据集规模，测试token溢价与数据相似度、词汇表大小、预分词及语言特征（书写系统、词长）之间的关系，并训练允许跨空格合并的superword分词器。

Result: 发现训练与测试数据相似度对token溢价无显著影响，而词汇表大小和预分词方法显著影响token溢价，存在每种语言的“最优”词汇表大小，superword分词器减少了token溢价并提升整体压缩率。

Conclusion: 通过调整词汇表大小和采用不同预分词策略，尤其是superword分词器，可以显著减少不同语言间的token溢价效应，提高训练和推理效率。

Abstract: The number of tokens it takes to encode parallel text in different languages
is known to vary. These disparities are called token premiums. Having high
token premiums leads to less throughput during training and increases costs at
inference. In this paper, we show that even after controlling for dataset size,
vocabulary size, and data content, monolingual tokenizers exhibit a wide range
of token premiums across languages. To understand the cross-linguistic
differences that cause these token premiums, we train a suite of approximately
7,000 comparable monolingual tokenizers for 97 languages, manipulating
tokenization algorithm, vocabulary size, and dataset size. We measure token
premiums and test for a relationship between factors such as data similarity
(between tokenizer training and evaluation), vocabulary size, and
pre-tokenization. We also investigate the role of language-specific features
such as writing system and word length. We find that similarity between
training and test data does not impact token premiums, but vocabulary size and
pre-tokenization do. While simply increasing vocabulary size does not lead to
reduced token premium effects, we can determine an ``optimal'' vocabulary size
for each language to achieve significantly reduced token premium effects. We
also train superword tokenizers which allow merges over whitespaces, and we
find that they both reduce token premium effects and improve compression
overall. Thus, intervening on the vocabulary size or the pre-tokenizer
significantly reduces crosslingual token premium effects.

</details>


### [10] [Model-Aware Tokenizer Transfer](https://arxiv.org/abs/2510.21954)
*Mykola Haltiuk,Aleksander Smywiński-Pohl*

Main category: cs.CL

TL;DR: 本文提出了一种融合模型内部信息的分词器迁移方法MATT，利用注意力行为指导嵌入初始化，有效提升多语言大语言模型适应低资源和异形文字的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的分词器迁移方法仅依赖语义启发式初始化嵌入，忽视了模型高层动态，导致迁移质量受限。

Method: MATT引入了注意力影响建模（AIM）目标，通过蒸馏源模型的跨令牌通信模式到使用新分词器的目标模型，作为语言模型训练前的高效预热。

Result: 实验显示MATT在多语言环境中能够在短时间内恢复原模型的大部分性能，显著优于传统启发式方法。

Conclusion: 利用模型级信号指导分词器迁移是提升多语言大语言模型适应能力的有效途径。

Abstract: Large Language Models (LLMs) are trained to support an increasing number of
languages, yet their predefined tokenizers remain a bottleneck for adapting
models to lower-resource or distinct-script languages. Existing tokenizer
transfer methods typically rely on semantic heuristics to initialize new
embeddings, ignoring higher-layer model dynamics and limiting transfer quality.
We propose Model-Aware Tokenizer Transfer (MATT), a method that incorporates
model internals into the tokenizer transfer process. MATT introduces an
Attention Influence Modeling (AIM) objective that distills inter-token
communication patterns from a source model into a target model with a new
tokenizer, providing an efficient warm-up before standard language modeling.
Unlike approaches that focus solely on embedding similarity, MATT leverages
attention behavior to guide embedding initialization and adaptation.
Experiments across diverse linguistic settings show that MATT recovers a large
fraction of the original model's performance within a few GPU hours,
outperforming heuristic baselines. These results demonstrate that incorporating
model-level signals offers a practical and effective path toward robust
tokenizer transfer in multilingual LLMs.

</details>


### [11] [A Stylometric Application of Large Language Models](https://arxiv.org/abs/2510.21958)
*Harrison F. Stropkay,Jiayi Chen,Mohammad J. Latifi,Daniel N. Rockmore,Jeremy R. Manning*

Main category: cs.CL

TL;DR: 本文展示了利用大语言模型（GPT-2）区分不同作者的写作风格，训练的模型能更准确预测同一作者未见文本。


<details>
  <summary>Details</summary>
Motivation: 验证大语言模型能否捕捉并区分不同作者的独特写作风格。

Method: 对八位不同作者的作品分别从零开始训练GPT-2模型，通过比较模型对不同作者文本的预测准确度来区分作者。

Result: 模型在预测自家作者未见文本时准确度更高，成功区分不同作者；并应用该方法确认了《绿野仙踪》系列第15本书的真实作者。

Conclusion: 大语言模型能够有效捕获作者独特写作风格，可用于作者身份验证和作品归属研究。

Abstract: We show that large language models (LLMs) can be used to distinguish the
writings of different authors. Specifically, an individual GPT-2 model, trained
from scratch on the works of one author, will predict held-out text from that
author more accurately than held-out text from other authors. We suggest that,
in this way, a model trained on one author's works embodies the unique writing
style of that author. We first demonstrate our approach on books written by
eight different (known) authors. We also use this approach to confirm R. P.
Thompson's authorship of the well-studied 15th book of the Oz series,
originally attributed to F. L. Baum.

</details>


### [12] [Uncovering the Persuasive Fingerprint of LLMs in Jailbreaking Attacks](https://arxiv.org/abs/2510.21983)
*Havva Alizadeh Noughabi,Julien Serbanescu,Fattane Zarrinkalam,Ali Dehghantanha*

Main category: cs.CL

TL;DR: 本文研究了利用社会科学中的说服理论设计对抗性提示，以绕过大型语言模型（LLM）对齐约束，诱发模型产生有害输出的攻击方式。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM安全防护机制易受绕过攻击，且以往研究较少关注语言和心理机制对模型脆弱性的影响。

Method: 结合社会科学中的说服策略，设计具有说服结构的对抗提示，并分析LLM本身是否表现出独特的说服特征。

Result: 实验证明说服感知的提示能够显著绕过多种对齐的LLM安全防护机制，诱发越狱行为。

Conclusion: 跨学科的说服理论为理解和提升LLM安全提供了重要视角，提示了LLM安全防护的新挑战和研究方向。

Abstract: Despite recent advances, Large Language Models remain vulnerable to jailbreak
attacks that bypass alignment safeguards and elicit harmful outputs. While
prior research has proposed various attack strategies differing in human
readability and transferability, little attention has been paid to the
linguistic and psychological mechanisms that may influence a model's
susceptibility to such attacks. In this paper, we examine an interdisciplinary
line of research that leverages foundational theories of persuasion from the
social sciences to craft adversarial prompts capable of circumventing alignment
constraints in LLMs. Drawing on well-established persuasive strategies, we
hypothesize that LLMs, having been trained on large-scale human-generated text,
may respond more compliantly to prompts with persuasive structures.
Furthermore, we investigate whether LLMs themselves exhibit distinct persuasive
fingerprints that emerge in their jailbreak responses. Empirical evaluations
across multiple aligned LLMs reveal that persuasion-aware prompts significantly
bypass safeguards, demonstrating their potential to induce jailbreak behaviors.
This work underscores the importance of cross-disciplinary insight in
addressing the evolving challenges of LLM safety. The code and data are
available.

</details>


### [13] [Toward Understanding the Transferability of Adversarial Suffixes in Large Language Models](https://arxiv.org/abs/2510.22014)
*Sarah Ball,Niki Hasrati,Alexander Robey,Avi Schwarzschild,Frauke Kreuter,Zico Kolter,Andrej Risteski*

Main category: cs.CL

TL;DR: 本文研究了基于离散优化的绕过大型语言模型限制的攻击方法，重点分析了这些攻击的迁移性及其原因。


<details>
  <summary>Details</summary>
Motivation: 虽然这些攻击后缀具有迁移性，即在未针对的模型和提示下依然有效，但领域内缺乏系统的理论分析。

Method: 本文提出三种与攻击迁移性强相关的统计性质：提示本身激活模型拒绝方向的程度、后缀使模型偏离该拒绝方向的强度及偏移到拒绝方向正交方向的大小，且对提示语义相似性的作用进行了对比分析。

Result: 发现三种统计属性与攻击迁移性高度相关，而提示语义相似性相关性较弱。通过干预实验验证了统计分析能有效提升攻击成功率。

Conclusion: 深入理解攻击迁移性的统计特征，有助于设计更有效的绕过限制攻击方法。

Abstract: Discrete optimization-based jailbreaking attacks on large language models aim
to generate short, nonsensical suffixes that, when appended onto input prompts,
elicit disallowed content. Notably, these suffixes are often transferable --
succeeding on prompts and models for which they were never optimized. And yet,
despite the fact that transferability is surprising and empirically
well-established, the field lacks a rigorous analysis of when and why transfer
occurs. To fill this gap, we identify three statistical properties that
strongly correlate with transfer success across numerous experimental settings:
(1) how much a prompt without a suffix activates a model's internal refusal
direction, (2) how strongly a suffix induces a push away from this direction,
and (3) how large these shifts are in directions orthogonal to refusal. On the
other hand, we find that prompt semantic similarity only weakly correlates with
transfer success. These findings lead to a more fine-grained understanding of
transferability, which we use in interventional experiments to showcase how our
statistical analysis can translate into practical improvements in attack
success.

</details>


### [14] [Penalizing Length: Uncovering Systematic Bias in Quality Estimation Metrics](https://arxiv.org/abs/2510.22028)
*Yilin Zhang,Wenda Xu,Zhongtao Liu,Tetsuji Nakagawa,Markus Freitag*

Main category: cs.CL

TL;DR: 本文系统研究了机器翻译质量估计中的长度偏差，发现指标倾向于对较长的译文过度预测错误，且偏爱较短译文，提出两种方法减轻该偏差。


<details>
  <summary>Details</summary>
Motivation: 质量估计指标在机器翻译中无参考评价和强化学习奖励中非常重要，但长度偏差的影响尚未被充分探讨。

Method: 对顶尖的基于回归和大语言模型的质量估计指标在10种语言对上的表现进行系统研究，揭示长度偏差，并提出训练时长度归一化和评估时引入参考文本两种缓解策略。

Result: 发现质量估计指标存在两个关键长度偏差：对长文本过度预测错误和偏好短译文；两种策略均有效减少了该偏差。

Conclusion: 长度偏差会影响质量估计的公平性和应用效果，提出的方法能够缓解这一问题，促进更合理的质量评估和决策。

Abstract: Quality Estimation (QE) metrics are vital in machine translation for
reference-free evaluation and as a reward signal in tasks like reinforcement
learning. However, the prevalence and impact of length bias in QE have been
underexplored. Through a systematic study of top-performing regression-based
and LLM-as-a-Judge QE metrics across 10 diverse language pairs, we reveal two
critical length biases: First, QE metrics consistently over-predict errors with
increasing translation length, even for high-quality, error-free texts. Second,
they exhibit a preference for shorter translations when multiple candidates are
available for the same source text. These inherent length biases risk unfairly
penalizing longer, correct translations and can lead to sub-optimal
decision-making in applications such as QE reranking and QE guided
reinforcement learning. To mitigate this, we propose two strategies: (a)
applying length normalization during model training, and (b) incorporating
reference texts during evaluation. Both approaches were found to effectively
reduce the identified length bias.

</details>


### [15] [ATLAS: Adaptive Transfer Scaling Laws for Multilingual Pretraining, Finetuning, and Decoding the Curse of Multilinguality](https://arxiv.org/abs/2510.22037)
*Shayne Longpre,Sneha Kudugunta,Niklas Muennighoff,I-Hung Hsu,Isaac Caswell,Alex Pentland,Sercan Arik,Chen-Yu Lee,Sayna Ebrahimi*

Main category: cs.CL

TL;DR: 本文进行了迄今最大规模的多语言扩展律研究，覆盖774次多语言训练实验，涉及10M-8B参数规模，400多种训练语言和48种评估语言。


<details>
  <summary>Details</summary>
Motivation: 现有扩展律研究主要聚焦于英语，但主流AI模型服务于全球用户，因此需要研究多语言环境下的扩展规律。

Method: 提出适应性迁移扩展律(ATLAS)，进行大量多语言训练实验，分析多语言学习动态、语言间迁移特性和多语言主义的挑战，建立跨语言迁移矩阵和语言无关扩展律，确定预训练方式的计算临界点。

Result: ATLAS在样本外泛化能力上显著优于现有扩展律，成功揭示语言间互惠得分，最优模型参数与数据规模关系，以及从头训练与多语言微调的计算折中点。

Conclusion: 研究为多语言扩展律提供科学基础，助力有效扩展非英语优先AI模型，推动AI技术的语言普及和民主化。

Abstract: Scaling laws research has focused overwhelmingly on English -- yet the most
prominent AI models explicitly serve billions of international users. In this
work, we undertake the largest multilingual scaling laws study to date,
totaling 774 multilingual training experiments, spanning 10M-8B model
parameters, 400+ training languages and 48 evaluation languages. We introduce
the Adaptive Transfer Scaling Law (ATLAS) for both monolingual and multilingual
pretraining, which outperforms existing scaling laws' out-of-sample
generalization often by more than 0.3 R^2. Our analyses of the experiments shed
light on multilingual learning dynamics, transfer properties between languages,
and the curse of multilinguality. First, we derive a cross-lingual transfer
matrix, empirically measuring mutual benefit scores between 38 x 38=1444
language pairs. Second, we derive a language-agnostic scaling law that reveals
how to optimally scale model size and data when adding languages without
sacrificing performance. Third, we identify the computational crossover points
for when to pretrain from scratch versus finetune from multilingual
checkpoints. We hope these findings provide the scientific foundation for
democratizing scaling laws across languages, and enable practitioners to
efficiently scale models -- beyond English-first AI.

</details>


### [16] [Emotions Where Art Thou: Understanding and Characterizing the Emotional Latent Space of Large Language Models](https://arxiv.org/abs/2510.22042)
*Benjamin Reichman,Adar Avsian,Larry Heck*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型内部的情感表示，发现其隐藏状态空间中存在低维情感流形，情感表示在语义层面可控且跨语言通用。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何内部表示和处理情感信息。

Method: 通过分析模型隐藏状态空间的几何结构，识别情感流形及其编码方式，并验证其在多语言多数据集上的稳定性和通用性。

Result: 发现情感表示呈方向性编码，分布在多个层级，且与可解释维度对齐，跨领域和语言表现一致且可操控。

Conclusion: 大型语言模型内部存在稳定且可控的情感几何结构，揭示其情感处理机制并支持语义保留下的情感调控。

Abstract: This work investigates how large language models (LLMs) internally represent
emotion by analyzing the geometry of their hidden-state space. The paper
identifies a low-dimensional emotional manifold and shows that emotional
representations are directionally encoded, distributed across layers, and
aligned with interpretable dimensions. These structures are stable across depth
and generalize to eight real-world emotion datasets spanning five languages.
Cross-domain alignment yields low error and strong linear probe performance,
indicating a universal emotional subspace. Within this space, internal emotion
perception can be steered while preserving semantics using a learned
intervention module, with especially strong control for basic emotions across
languages. These findings reveal a consistent and manipulable affective
geometry in LLMs and offer insight into how they internalize and process
emotion.

</details>


### [17] [Compositional Bias Control in Large Language Models: Preference Learning Fails, Supervision Succeeds](https://arxiv.org/abs/2510.22084)
*Atij Mahesh*

Main category: cs.CL

TL;DR: 本文比较分析了六种减轻语言模型性别偏见的控制技术，发现只有显式监督学习能够有效满足复杂约束并保持语言多样性和流畅性，而基于偏好学习的方法无法处理逻辑组合约束。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在职业中立的环境下仍表现出性别刻板印象语言，现有方法处理效果和机制理解不足。

Method: 对提示、生成后过滤、基于DFA的Ctrl-G解码、监督微调(SFT)、直接偏好优化(DPO)和迭代零空间投影(INLP)六种技术进行比较，使用包含代理和社群描述词的组合约束任务进行评测。

Result: SFT在满足约束和词汇多样性方面表现最佳，DPO训练稳定但约束满足率很低，Ctrl-G保证约束满足但流畅性和多样性差。偏好学习无法满足逻辑组合约束，需显式监督干预。

Conclusion: 偏好学习方法无法推广逻辑结构约束，显式正监督是实现公平且流畅生成的关键，提示了偏好学习的局限性和未来控制生成的方向。

Abstract: Large Language Models (LLMs) still produce gender-stereotyped language even
in occupation-neutral contexts that reflect deep societal biases (Rudinger et
al., 2018). To address this, prior work has proposed prompting, constrained
decoding (Dathathri et al., 2020; Zhou et al., 2024), post-processing, and
fine-tuning-based alignment (Rafailov et al., 2023; Ravfogel et al., 2022).
However, the comparative efficacy and learning dynamics remain little
understood. We report a comparative analysis of six control techniques for bias
mitigation: prompt-only, generate-and-filter, DFA-based Ctrl-G decoding,
Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and
Iterative Nullspace Projection (INLP). We evaluate each method on a
compositional constraint task. This task requires generating sentences that
contain at least one agentic and one communal descriptor for each of the twenty
Winogender-derived occupations. We quantify trade-offs between control strength
and naturalness with evaluations of constraint compliance, lexical diversity,
and fluency. Our results reveal key contrasts among the methods: SFT achieves
99.87 +- 0.15% compliance and high lexical diversity, while DPO, despite
similar training stability, fails at 4.53 +- 0.82%. Ctrl-G guarantees perfect
compliance, but at the cost of severely reduced fluency and diversity.
Preference-based learning fundamentally differs: it cannot satisfy
compositional constraints, as binary preference signals encode ranking, not
logical conjunctions. Only explicit positive supervision enables mitigation of
compositional biases; preference-based alignment fails to generalize logical
structures, underscoring the limitations of preference learning and the
necessity of explicit supervision for fair and fluent controlled generation.

</details>


### [18] [Generalization or Memorization: Dynamic Decoding for Mode Steering](https://arxiv.org/abs/2510.22099)
*Xuanming Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种理论模型和动态模式引导算法，以识别和控制大语言模型的泛化与记忆两种推理模式，显著提升模型逻辑一致性和事实准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在展示出强大泛化能力的同时，也存在对训练数据的逐字记忆，导致可靠性不足，限制其在高风险场景中的应用。

Method: 基于信息瓶颈原理，构建理论模型区分泛化与记忆；提出动态模式引导算法，包括轻量因果线性探测器识别记忆依赖和动态激活引导机制，促进模型计算趋向泛化。

Result: 在推理和可靠性任务中，该方法显著提升了逻辑一致性和事实准确率。

Conclusion: 动态模式引导为增强大语言模型的可靠性提供了理论依据和有效技术手段。

Abstract: Large Language Models (LLMs) exhibit a troubling duality, capable of both
remarkable generalization and brittle, verbatim memorization of their training
data. This unpredictability undermines their reliability in high-stakes
applications. In this work, we propose a unified framework to understand,
identify, and control these distinct reasoning modes. First, we introduce a
theoretical model based on the Information Bottleneck (IB) principle,
formalizing generalization as the learning of a compressed, task-relevant
representation and memorization as a failure to compress. Building on this
theory, we develop Dynamic Mode Steering (DMS), a novel inference-time
algorithm which comprises two components: (1) a lightweight, causally-grounded
linear probe that identifies the model's instantaneous reliance on
memorization, and (2) a dynamic activation steering mechanism that nudges the
model's computation towards pre-identified generalization circuits. We frame
DMS as a form of adaptive, self-contrastive decoding. Experiments on reasoning
and faithfulness tasks demonstrate that DMS significantly improves logical
consistency and factual accuracy, thereby offering a principled approach to
enhancing LLM reliability.

</details>


### [19] [Gradual Forgetting: Logarithmic Compression for Extending Transformer Context Windows](https://arxiv.org/abs/2510.22109)
*Billy Dickson,Zoran Tiganj*

Main category: cs.CL

TL;DR: 本文提出一种基于输入表示的长上下文处理方法，通过对输入令牌进行对数压缩，使得标准Transformer能够处理更长的上下文，提升语言建模性能。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文处理方法通过增加递归或额外记忆模块复杂化Transformer架构，作者希望通过修改输入表示简化处理流程。

Method: 借鉴人类记忆的认知模型，采用尺度不变的对数压缩对输入令牌进行压缩，然后使用未修改的标准Transformer进行处理。

Result: 在WikiText-103和PG-19语言建模基准测试中，压缩方法相较于未压缩基线降低了困惑度，且随着压缩后的上下文长度增加性能持续提升。

Conclusion: 输入级别的对数压缩是一种简单有效的扩展Transformer长距离记忆的方法，能在保持架构不变的情况下提升模型性能。

Abstract: Most approaches to long-context processing increase the complexity of the
transformer's internal architecture by integrating mechanisms such as
recurrence or auxiliary memory modules. In this work, we introduce an
alternative approach that modifies the input representation itself, rather than
the transformer architecture. Inspired by cognitive models of human memory, our
method applies a scale-invariant logarithmic compression to the input tokens.
The resulting compressed representation is processed by a standard, unmodified
transformer, preserving architectural simplicity. We evaluate this approach on
the WikiText-103 and PG-19 language modeling benchmarks, showing a reduction in
perplexity compared to uncompressed baselines. Moreover, performance improves
consistently with longer compressed temporal contexts, showing that input-level
logarithmic compression is a simple and effective way to extend a transformer's
long-range memory.

</details>


### [20] [Every Activation Boosted: Scaling General Reasoner to 1 Trillion Open Language Foundation](https://arxiv.org/abs/2510.22115)
*Ling-Team,Ang Li,Ben Liu,Binbin Hu,Bing Li,Bingwei Zeng,Borui Ye,Caizhi Tang,Changxin Tian,Chao Huang,Chao Zhang,Chen Qian,Chenchen Ju,Chenchen Li,Chengfu Tang,Chili Fu,Chunshao Ren,Chunwei Wu,Cong Zhang,Cunyin Peng,Dafeng Xu,Daixin Wang,Dalong Zhang,Dingnan Jin,Dingyuan Zhu,Dongke Hu,Fangzheng Zhao,Feifan Wu,Feng Zhu,Gangshan Wang,Haitao Zhang,Hailin Zhao,Hanxiao Zhang,Hanzi Wang,Hao Qian,Haoyi Yu,Heng Zhang,Hongliang Zhang,Hongzhi Luan,Huirong Dong,Huizhong Li,Jia Li,Jia Liu,Jialong Zhu,Jian Sha,Jianping Wei,Jiaolong Yang,Jieyue Ma,Jiewei Wu,Jinjing Huang,Jingyun Tian,Jingyuan Zhang,Jinquan Sun,Juanhui Tu,Jun Liu,Jun Xu,Jun Zhou,Junjie Ou,Junpeng Fang,Kaihong Zhang,Kaiqin Hu,Ke Shi,Kun Tang,Kunlong Chen,Lanyin Mei,Lei Liang,Lei Xu,Libo Zhang,Lin Ju,Lin Yuan,Ling Zhong,Lintao Ma,Lu Liu,Lu Yu,Lun Cai,Meiqi Zhu,Mengying Li,Min Chen,Minghao Xue,Minghong Cai,Mingming Yin,Peijie Jiang,Peilong Zhao,Pingping Liu,Qian Zhao,Qing Cui,Qingxiang Huang,Qingyuan Yang,Quankun Yu,Shaowei Wei,Shijie Lian,Shoujian Zheng,Shun Song,Shungen Zhang,Shuo Zhang,Siyuan Li,Song Liu,Ting Guo,Tong Zhao,Wanli Gu,Weichang Wu,Weiguang Han,Wenjing Fang,Wubin Wang,Xiang Shu,Xiao Shi,Xiaoshun Lan,Xiaolu Zhang,Xiaqing Sun,Xin Zhao,Xingyu Lu,Xiong Xu,Xudong Wang,Xudong Wang,Xuemin Yang,Yajie Yang,Yang Xiang,Yanzhe Li,Yi Zhang,Yilong Wang,Yingxue Li,Yongzhen Guo,Yuzhuo Fu,Yuanyuan Wang,Yue Yang,Yue Yu,Yufeng Deng,Yun Zhang,Yunfei Xu,Yuqi Zhang,Yuxiao He,Zengke Gui,Zhaoxin Huan,Zhaoyang Wang,Zhibo Zhu,Zhihao Wang,Zhiqiang Zhang,Zhoufei Wang,Zihang Zeng,Ziqi Liu,Zitao Xuan,Zuoli Tang*

Main category: cs.CL

TL;DR: Ling 2.0是一种以推理为导向的大规模稀疏激活语言模型系列，规模从160亿到1万亿参数，具备高效推理能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 提升语言模型的推理能力和计算效率，解决大规模模型在推理任务中的效率瓶颈。

Method: 采用高稀疏性Mixture-of-Experts架构，结合多项创新技术如中间训练链式推理激活、强化学习微调和FP8精度训练，实现统一高效推理模型。

Result: Ling 2.0系列模型在推理准确度和计算效率之间达到了新的帕累托前沿，最高实现7倍相较于密集模型的计算效率提升。

Conclusion: 合理利用稀疏激活与推理目标对齐，可以实现大规模语言模型的高效推理与智能扩展，Ling 2.0为未来推理及思维模型奠定了开放高效的基础。

Abstract: We introduce Ling 2.0, a series reasoning-oriented language foundation built
upon the principle that every activation boosts reasoning capability. Designed
to scale from tens of billions to one trillion parameters under a unified
Mixture-of-Experts (MoE) paradigm, Ling 2.0 emphasizes high sparsity,
cross-scale consistency, and efficiency guided by empirical scaling laws. The
series includes three non-thinking (instruct) models - Ling-mini-2.0,
Ling-flash-2.0, and Ling-1T - ranging from 16B to 1T total parameters and
achieving up to 7-fold active-compute efficiency compared with dense
counterparts. Ling 2.0 integrates coordinated innovations across model
architecture, pre-training, post-training, and infrastructure: a high-sparsity
MoE with MTP for efficient reasoning, reasoning-oriented data and mid-training
CoT activation, reinforcement-based fine-tuning (DFT, Evo-CoT), and full-scale
FP8 training with fine-grained heterogeneous pipelines. At the trillion scale,
Ling-1T establishes a new Pareto frontier of reasoning accuracy versus
computational efficiency, demonstrating that sparse activation, when properly
aligned with reasoning objectives, enables scalable and efficient intelligence.
Collectively, Ling 2.0 provides a coherent, open, and efficient foundation for
advancing future reasoning and thinking models, including the Ring series built
upon the same base.

</details>


### [21] [OlaMind: Towards Human-Like and Hallucination-Safe Customer Service for Retrieval-Augmented Dialogue](https://arxiv.org/abs/2510.22143)
*Tianhong Gao,Jundong Shen,Bei Shi,Jiapeng Wang,Ying Ju,Junfeng Yao,Jiao Ran,Yong Zhang,Lin Dong,Huiyu Yu,Tingting Ye*

Main category: cs.CL

TL;DR: 本文提出了OlaMind，一种基于检索增强生成的智能客服框架，通过模仿人类推理和强化学习提升对话自然度并减少生成错误。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成系统在智能客服中容易产生幻觉和机械回复，影响用户体验和带来业务风险。

Method: OlaMind包括两个阶段：Learn-to-Think阶段学习人类专家的推理和应答策略，Learn-to-Respond阶段结合监督微调和强化学习进行自我优化。

Result: 在社交客服场景的大规模A/B测试中，OlaMind显著提升了智能解决率（社区支持提升28.92%，直播互动提升18.42%）并降低了人工干预率（社区支持降低6.08%，直播互动降低7.12%）。

Conclusion: OlaMind有效提升了智能客服系统的自然度和安全性，减少了幻觉和业务风险，表现出良好的实用价值和广泛的应用潜力。

Abstract: Intelligent customer service (ICS) systems via retrieval-augmented generation
(RAG) have been widely adopted in Web-based domains such as social platforms
and e-commerce, achieving remarkable improvements in automation and efficiency.
However, notable limitations still remain: these systems are prone to
hallucinations and often generate rigid, mechanical responses, which can
introduce business risks and undermine user experience, especially in Web-based
customer service interactions under the RAG scenarios. In this paper, we
introduce OlaMind, a human-like and hallucination-safe customer service
framework for retrieval-augmented dialogue. Specifically, it first leverages a
Learn-to-Think stage to learn the reasoning processes and response strategies
from human experts, and then employs a Learn-to-Respond stage to perform
cold-start supervised fine-tuning (SFT) combined with reinforcement learning
(RL) for basic-to-hard self-refinement. Our method significantly enhances
human-likeness and naturalness while effectively mitigating hallucinations and
critical business risks. We have conducted large-scale online A/B experiments
in an industry-level social customer service setting, and extensive
experimental results show that OlaMind achieves significant cumulative relative
improvements with intelligent resolution rates +28.92%/+18.42% and human
takeover rate -6.08%/-7.12% in community-support/livestream-interaction
scenarios, respectively, which highlights its consistent effectiveness across
diverse real-world applications. The code and data will be publicly available.

</details>


### [22] [SentiMaithili: A Benchmark Dataset for Sentiment and Reason Generation for the Low-Resource Maithili Language](https://arxiv.org/abs/2510.22160)
*Rahul Ranjan,Mahendra Kumar Gurve,Anuj,Nitin,Yamuna Prasad*

Main category: cs.CL

TL;DR: 该论文构建了包含3221条Maithili语句的情感极性数据集，并附带Maithili语言的自然语言解释，推动了低资源语言情感分析的可解释性研究。


<details>
  <summary>Details</summary>
Motivation: Maithili作为一种使用人口众多但资源匮乏的印地-雅利安语，缺乏细粒度且可解释的情感分析数据集，制约了其自然语言处理的发展。

Method: 该研究开发了一个由语言专家严格校验的Maithili情感极性数据集，包含自然语言解释，并通过传统机器学习和最新变换器模型进行了广泛实验验证。

Result: 数据集有效促进了Maithili情感分析的可解释性，实验结果显示该数据集适用于多种模型，提升了情感极性判断的可靠性和解释能力。

Conclusion: 本研究首次为Maithili语言提供了可解释性情感计算基准数据集，丰富了多语种自然语言处理资源，有助于推动低资源语言的情感分析和解释型AI的发展。

Abstract: Developing benchmark datasets for low-resource languages poses significant
challenges, primarily due to the limited availability of native linguistic
experts and the substantial time and cost involved in annotation. Given these
challenges, Maithili is still underrepresented in natural language processing
research. It is an Indo-Aryan language spoken by more than 13 million people in
the Purvanchal region of India, valued for its rich linguistic structure and
cultural significance. While sentiment analysis has achieved remarkable
progress in high-resource languages, resources for low-resource languages, such
as Maithili, remain scarce, often restricted to coarse-grained annotations and
lacking interpretability mechanisms. To address this limitation, we introduce a
novel dataset comprising 3,221 Maithili sentences annotated for sentiment
polarity and accompanied by natural language justifications. Moreover, the
dataset is carefully curated and validated by linguistic experts to ensure both
label reliability and contextual fidelity. Notably, the justifications are
written in Maithili, thereby promoting culturally grounded interpretation and
enhancing the explainability of sentiment models. Furthermore, extensive
experiments using both classical machine learning and state-of-the-art
transformer architectures demonstrate the dataset's effectiveness for
interpretable sentiment analysis. Ultimately, this work establishes the first
benchmark for explainable affective computing in Maithili, thus contributing a
valuable resource to the broader advancement of multilingual NLP and
explainable AI.

</details>


### [23] [DETECT: Determining Ease and Textual Clarity of German Text Simplifications](https://arxiv.org/abs/2510.22212)
*Maria Korobeynikova,Alessia Battisti,Lukas Fischer,Yingqiang Gao*

Main category: cs.CL

TL;DR: 本文提出了首个德语自动文本简化评估指标DETECT，通过大型语言模型生成合成数据，涵盖简易性、意义保持和流畅性，显著优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 现有德语文本简化评估依赖通用指标，缺乏针对简化质量的专业度量，且缺少带标注的人类语料，阻碍了德语简化评估的发展。

Method: 基于LENS框架，利用大型语言模型自动生成合成评分数据，无需人工标注，并通过LLM优化评分标准，构建了最大的德语简化人类评估数据集进行验证。

Result: 实验表明，DETECT与人类评分的相关性远高于现有指标，特别是在意义保持和流畅性方面提升显著。

Conclusion: DETECT不仅提升了德语自动文本简化的评估效果，也展示了大型语言模型在自动评估中的潜力和局限，为语言无障碍任务提供了可迁移的指导方案。

Abstract: Current evaluation of German automatic text simplification (ATS) relies on
general-purpose metrics such as SARI, BLEU, and BERTScore, which insufficiently
capture simplification quality in terms of simplicity, meaning preservation,
and fluency. While specialized metrics like LENS have been developed for
English, corresponding efforts for German have lagged behind due to the absence
of human-annotated corpora. To close this gap, we introduce DETECT, the first
German-specific metric that holistically evaluates ATS quality across all three
dimensions of simplicity, meaning preservation, and fluency, and is trained
entirely on synthetic large language model (LLM) responses. Our approach adapts
the LENS framework to German and extends it with (i) a pipeline for generating
synthetic quality scores via LLMs, enabling dataset creation without human
annotation, and (ii) an LLM-based refinement step for aligning grading criteria
with simplification requirements. To the best of our knowledge, we also
construct the largest German human evaluation dataset for text simplification
to validate our metric directly. Experimental results show that DETECT achieves
substantially higher correlations with human judgments than widely used ATS
metrics, with particularly strong gains in meaning preservation and fluency.
Beyond ATS, our findings highlight both the potential and the limitations of
LLMs for automatic evaluation and provide transferable guidelines for general
language accessibility tasks.

</details>


### [24] [Estimating the Error of Large Language Models at Pairwise Text Comparison](https://arxiv.org/abs/2510.22219)
*Tianyi Li*

Main category: cs.CL

TL;DR: 本文提出一种无须依赖基准的LLM输出错误测量方法，通过两种假设模型估计文本对比中的错误概率，并用Copeland计数法构建文本排序，实验证明该方法对多款LLM表现一致，Claude模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统评测方法依赖人工标注基准，评价效果有限且难以扩展，需一种无需基准即可有效量化LLM输出错误的方法。

Method: 设计两种错误模型（均匀错误率和二元位置偏差），通过重复文本对比与Copeland计数法估计错误概率和构建文本排序，对六款LLM和多种文本进行评测。

Result: 该方法稳定估计出各模型的错误率和位置偏差，发现两种偏差接近且总体错误率较低，Claude表现最优。方法优于偏差Bradley-Terry模型和可交换性得分。

Conclusion: 提出的无基准错误测量方法有效且具扩展性，能反映LLM在文本对比任务中的性能差异，具有较强的实用价值和推广潜力。

Abstract: We measure LLMs' output error at pairwise text comparison, noting the
probability of error in their preferences. Our method does not rely on the
ground truth and supports two scenarios: (i) uniform error rate regardless of
the order of comparison, estimated with two comparisons for each text pair with
either text placed first; (ii) binary positional bias assuming distinct error
rates for the two orders of comparison, estimated with repeated comparisons
between the texts. The Copeland counting constructs a ranking over the compared
texts from pairwise preferences; the ranking reveals the poor scalability of
LLM-based pairwise comparison and helps yield the estimates for LLMs' error
rates. We apply the method to six LLMs (ChatGPT, Claude, DeepSeek, Gemini,
Grok, Qwen) with five types of text input and obtain consistent estimates of
LLMs' error. In general, the measured two positional bias terms are similar,
close to the uniform error. Considering both the error rates and the robustness
to the variation of prompts, Claude obtained the most desirable performance in
this experiment. Our model outperforms the biased Bradley-Terry model and the
commutativity score in indicating LLMs' error at this task.

</details>


### [25] [Evolution of the lexicon: a probabilistic point of view](https://arxiv.org/abs/2510.22220)
*Maurizio Serva*

Main category: cs.CL

TL;DR: 本文分析了Swadesh方法在确定语言分离时间上的局限性，强调词汇逐渐修改的随机过程对提高估计准确性的重要作用。


<details>
  <summary>Details</summary>
Motivation: Swadesh方法在语言时间分离估计中存在不切实际的假设和各种干扰因素，导致结果不够准确。

Method: 通过概率论分析Swadesh方法基本假设的局限，并引入词汇逐渐修改的随机过程以改进时间分离估计。

Result: 证明了词汇逐渐修改过程对语言词汇演化有重大影响，考虑该过程可显著提升时间分离估计的精度。

Conclusion: 词汇替换和词汇逐渐修改两个随机过程共同驱动语言词汇演化，结合考虑这两者能有效提高语言时间分离的估计准确性。

Abstract: The Swadesh approach for determining the temporal separation between two
languages relies on the stochastic process of words replacement (when a
complete new word emerges to represent a given concept). It is well known that
the basic assumptions of the Swadesh approach are often unrealistic due to
various contamination phenomena and misjudgments (horizontal transfers,
variations over time and space of the replacement rate, incorrect assessments
of cognacy relationships, presence of synonyms, and so on). All of this means
that the results cannot be completely correct.
  More importantly, even in the unrealistic case that all basic assumptions are
satisfied, simple mathematics places limits on the accuracy of estimating the
temporal separation between two languages. These limits, which are purely
probabilistic in nature and which are often neglected in lexicostatistical
studies, are analyzed in detail in this article.
  Furthermore, in this work we highlight that the evolution of a language's
lexicon is also driven by another stochastic process: gradual lexical
modification of words. We show that this process equally also represents a
major contribution to the reshaping of the vocabulary of languages over the
centuries and we also show, from a purely probabilistic perspective, that
taking into account this second random process significantly increases the
precision in determining the temporal separation between two languages.

</details>


### [26] [You Don't Need Prompt Engineering Anymore: The Prompting Inversion](https://arxiv.org/abs/2510.22251)
*Imran Khan*

Main category: cs.CL

TL;DR: 本文提出了一种名为“Sculpting”的约束式提示方法，旨在提升大语言模型（LLM）的推理能力，相较于标准链式思维提示方法（CoT），能减少语义歧义和常识错误。实验发现该方法对中级模型有效，但在高级模型中反而降低性能。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维提示虽提升了LLM的推理能力，但仍存在因语义歧义和常识错误导致的性能瓶颈，亟需改进的提示设计方法。

Method: 设计了一种规则约束的提示方法“Sculpting”，与零次提示和标准CoT进行对比，评测在不同OpenAI模型（gpt-4o-mini、gpt-4o、gpt-5）上的表现，并通过数学推理基准GSM8K进行实证分析。

Result: Sculpting在中级模型gpt-4o中表现优于标准CoT，正确率提升至97%对比93%；但在更先进的gpt-5模型中表现下降，正确率为94.00%低于CoT的96.36%。错误分析揭示约束在高级模型中导致过度字面理解，降低表现。

Conclusion: 提示策略应随着模型能力进化而调整，对高级模型采用更简洁的提示更有效，提示设计需要动态配合模型特性以最大化推理性能。

Abstract: Prompt engineering, particularly Chain-of-Thought (CoT) prompting,
significantly enhances LLM reasoning capabilities. We introduce "Sculpting," a
constrained, rule-based prompting method designed to improve upon standard CoT
by reducing errors from semantic ambiguity and flawed common sense.
  We evaluate three prompting strategies (Zero Shot, standard CoT, and
Sculpting) across three OpenAI model generations (gpt-4o-mini, gpt-4o, gpt-5)
using the GSM8K mathematical reasoning benchmark (1,317 problems).
  Our findings reveal a "Prompting Inversion": Sculpting provides advantages on
gpt-4o (97% vs. 93% for standard CoT), but becomes detrimental on gpt-5 (94.00%
vs. 96.36% for CoT on full benchmark). We trace this to a
"Guardrail-to-Handcuff" transition where constraints preventing common-sense
errors in mid-tier models induce hyper-literalism in advanced models. Our
detailed error analysis demonstrates that optimal prompting strategies must
co-evolve with model capabilities, suggesting simpler prompts for more capable
models.

</details>


### [27] [Scalable Supervising Software Agents with Patch Reasoner](https://arxiv.org/abs/2510.22775)
*Junjielong Xu,Boyin Tan,Xiaoyuan Liu,Chao Peng,Pengfei Gao,Pinjia He*

Main category: cs.CL

TL;DR: 本文提出了R4P，一种用于软件工程补丁验证的推理模型，通过群组式强化学习提供可扩展的奖励机制，显著提升了补丁验证准确率和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于测试的监督方法存在构建和运行测试环境复杂且不稳定、测试覆盖率数据稀缺且易被极端案例干扰的问题，制约了大规模数据扩展和模型提升。

Method: 提出R4P模型，将补丁验证视为推理任务，采用群组式目标进行强化学习，验证多个补丁间的相互修改以获得稳定且稠密的奖励；并设计Mini-SE轻量模型纯强化学习训练，所有奖励均来源于R4P。

Result: R4P在SWE-bench-verified补丁验证中达到72.2%的准确率，超过OpenAI o3；Mini-SE在该基准上达到26.2% Pass@1，比原Qwen3-32B提升10.0%，使用R4P测试时进一步提升至32.8%；验证速度比传统测试快50倍。

Conclusion: R4P通过推理式补丁验证和群组强化学习，实现了高准确率、高效率和稳定的奖励扩展，促进了软件工程代理的训练和测试，具有良好的实际应用潜力。

Abstract: While large language model agents have advanced software engineering tasks,
the unscalable nature of existing test-based supervision is limiting the
potential improvement of data scaling. The reason is twofold: (1) building and
running test sandbox is rather heavy and fragile, and (2) data with
high-coverage tests is naturally rare and threatened by test hacking via edge
cases. In this paper, we propose R4P, a patch verifier model to provide
scalable rewards for training and testing SWE agents via reasoning. We consider
that patch verification is fundamentally a reasoning task, mirroring how human
repository maintainers review patches without writing and running new
reproduction tests. To obtain sufficient reference and reduce the risk of
reward hacking, R4P uses a group-wise objective for RL training, enabling it to
verify multiple patches against each other's modification and gain a dense
reward for stable training. R4P achieves 72.2% Acc. for verifying patches from
SWE-bench-verified, surpassing OpenAI o3. To demonstrate R4P's practicality, we
design and train a lite scaffold, Mini-SE, with pure reinforcement learning
where all rewards are derived from R4P. As a result, Mini-SE achieves 26.2%
Pass@1 on SWE-bench-verified, showing a 10.0% improvement over the original
Qwen3-32B. This can be further improved to 32.8% with R4P for test-time
scaling. Furthermore, R4P verifies patches within a second, 50x faster than
testing on average. The stable scaling curves of rewards and accuracy along
with high efficiency reflect R4P's practicality.

</details>


### [28] [SteerX: Disentangled Steering for LLM Personalization](https://arxiv.org/abs/2510.22256)
*Xiaoyan Zhao,Ming Yan,Yilun Qiu,Haoting Ni,Yang Zhang,Fuli Feng,Hong Cheng,Tat-Seng Chua*

Main category: cs.CL

TL;DR: 本文提出了一种基于因果推断的激活引导方法SteerX，通过解离偏好驱动与非偏好驱动成分，提高了个性化大语言模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的激活引导方法依赖全部历史数据来计算引导向量，无法精准捕捉真实用户偏好，导致个性化效果受限。

Method: SteerX基于因果推断理论，估计词元级别的因果效应，识别偏好驱动的词元，将离散信号转化为连贯描述，再用此信息引导大语言模型生成。

Result: 在两个代表性引导骨干方法和真实数据集上的实验表明，SteerX显著提升了引导向量的质量和个性化效果。

Conclusion: SteerX通过关注真实偏好信息，提供了一种实用且高效的个性化大语言模型激活引导方案。

Abstract: Large language models (LLMs) have shown remarkable success in recent years,
enabling a wide range of applications, including intelligent assistants that
support users' daily life and work. A critical factor in building such
assistants is personalizing LLMs, as user preferences and needs vary widely.
Activation steering, which directly leverages directions representing user
preference in the LLM activation space to adjust its behavior, offers a
cost-effective way to align the model's outputs with individual users. However,
existing methods rely on all historical data to compute the steering vector,
ignoring that not all content reflects true user preferences, which undermines
the personalization signal. To address this, we propose SteerX, a disentangled
steering method that isolates preference-driven components from
preference-agnostic components. Grounded in causal inference theory, SteerX
estimates token-level causal effects to identify preference-driven tokens,
transforms these discrete signals into a coherent description, and then
leverages them to steer personalized LLM generation. By focusing on the truly
preference-driven information, SteerX produces more accurate activation
steering vectors and enhances personalization. Experiments on two
representative steering backbone methods across real-world datasets demonstrate
that SteerX consistently enhances steering vector quality, offering a practical
solution for more effective LLM personalization.

</details>


### [29] [Language Server CLI Empowers Language Agents with Process Rewards](https://arxiv.org/abs/2510.22907)
*Yifan Zhang,Lanser Contributors*

Main category: cs.CL

TL;DR: Lanser-CLI是一种基于命令行的编排层，利用语言服务器协议（LSP）为编码代理和持续集成提供确定性、可重放的工作流程，解决了大语言模型产生的API幻觉和定位编辑错误问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码编辑中常出现API幻觉和误定位编辑的问题，而语言服务器能够提供经过验证的代码结构信息。本文旨在通过利用语言服务器的能力，提高代码编辑和自动化过程的准确性和可验证性。

Method: 提出Lanser-CLI，包含(1)基于选择器DSL的 robust 地址方案，突破传统'文件:行:列'的脆弱性；(2)确定性分析包，统一语言服务器响应及环境元数据；(3)安全编辑操作保护机制，支持预览、工作区隔离和Git感知的事务应用；(4)基于语言服务器事实的过程奖励函数，可在线计算和离线重放，保证过程可监督和反事实分析。

Result: 实现了Lanser-CLI，使编码代理和CI流程能够在语言服务器提供的结构信息和证实时序信号引导下，进行稳定、可重放且安全的代码操作。通过形式化确定性和奖励函数的单调性，增强了过程监督的能力。

Conclusion: Lanser-CLI成功将语言服务器的精准代码信息转化为编码代理的过程奖励，解决了大语言模型的幻觉问题，提升了自动化编码的准确性和安全性，具备良好的可审计性和可重现性。

Abstract: Large language models routinely hallucinate APIs and mislocalize edits, while
language servers compute verified, IDE-grade facts about real code. We present
Lanser-CLI, a CLI-first orchestration layer that pins and mediates a Language
Server Protocol (LSP) server for coding agents and CI, exposing deterministic,
replayable workflows. Our position is that language servers provide not only
structural information (definitions, references, types, diagnostics) but also
an actionable process reward: machine-checked, step-wise signals that align an
agent's planning loop with program reality. In this work, Lanser-CLI
contributes: (i) a robust addressing scheme beyond brittle "file:line:col" via
a Selector DSL (symbolic, AST-path, and content-anchored selectors) with a
principled relocation algorithm; (ii) deterministic Analysis Bundles that
normalize Language Server responses and capture environment/capability metadata
with stable content hashes; (iii) a safety envelope for mutating operations
(rename, code actions) with preview, workspace jails, and Git-aware,
transactional apply; and (iv) a process-reward functional derived from Language
Server facts (diagnostic deltas, disambiguation confidence, and safe-apply
checks) that is computable online and replayable offline. We formalize
determinism under frozen snapshots and establish a monotonicity property for
the process reward, making it suitable for process supervision and
counterfactual analysis. Project Page:
https://github.com/yifanzhang-pro/lanser-cli

</details>


### [30] [PatenTEB: A Comprehensive Benchmark and Model Family for Patent Text Embedding](https://arxiv.org/abs/2510.22264)
*Iliass Ayaou,Denis Cavallucci*

Main category: cs.CL

TL;DR: 本文提出了PatenTEB，一个涵盖检索、分类、释义和聚类的专利文本嵌入综合基准，包含206万样本，结合多任务训练开发了patembed模型，实现了专利领域的嵌入性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分反映专利文本嵌入的特有挑战，缺少对不对称片段-文档匹配和领域特定难负样本的系统性覆盖。

Method: 构建包含15个任务的综合基准PatenTEB，采用领域分层划分和领域特定难负样本挖掘，开发67M至344M参数规模、上下文长度可达4096的patembed多任务训练模型。

Result: patembed在外部验证中表现优异，patembed-base在MTEB BigPatentClustering.v2上V-measure达到0.494，超越此前最佳0.445；patembed-large在DAPFAM上得到0.377的NDCG@100。多任务训练和领域预训练均带来显著性能提升。

Conclusion: PatenTEB和patembed模型有效提升了专利文本嵌入的性能，证明多任务训练和领域预训练对专利领域任务具有稳定优势，将公开所有资源助力后续研究。

Abstract: Patent text embeddings enable prior art search, technology landscaping, and
patent analysis, yet existing benchmarks inadequately capture patent-specific
challenges. We introduce PatenTEB, a comprehensive benchmark comprising 15
tasks across retrieval, classification, paraphrase, and clustering, with 2.06
million examples. PatenTEB employs domain-stratified splits, domain specific
hard negative mining, and systematic coverage of asymmetric
fragment-to-document matching scenarios absent from general embedding
benchmarks. We develop the patembed model family through multi-task training,
spanning 67M to 344M parameters with context lengths up to 4096 tokens.
External validation shows strong generalization: patembed-base achieves
state-of-the-art on MTEB BigPatentClustering.v2 (0.494 V-measure vs. 0.445
previous best), while patembed-large achieves 0.377 NDCG@100 on DAPFAM.
Systematic ablations reveal that multi-task training improves external
generalization despite minor benchmark costs, and that domain-pretrained
initialization provides consistent advantages across task families. All
resources will be made available at https://github.com/iliass-y/patenteb.
Keywords: patent retrieval, sentence embeddings, multi-task learning,
asymmetric retrieval, benchmark evaluation, contrastive learning.

</details>


### [31] [MATCH: Task-Driven Code Evaluation through Contrastive Learning](https://arxiv.org/abs/2510.23169)
*Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moschkovitz,Dotan Di Castro*

Main category: cs.CL

TL;DR: 本文提出了一种无参考的代码生成评价指标MATCH，通过对比学习生成代码和任务描述的有效嵌入，实现对生成代码与开发者意图契合度的准确评估。


<details>
  <summary>Details</summary>
Motivation: 当前代码生成的准确性评估面临传统单元测试不具备扩展性，语法相似度指标无法反映代码功能，且无参考代码时指标受限的问题。

Method: MATCH利用对比学习技术，生成代码与自然语言任务描述的嵌入向量，通过计算嵌入相似度来评价代码质量，无需参考代码。

Result: 实验证明MATCH在多种编程语言中与功能正确性和人类偏好关联度更高，优于现有指标。

Conclusion: MATCH填补了无参考代码质量评价的空白，提升了代码生成的自动评估准确性，有助于推动代码生成技术的发展。

Abstract: AI-based code generation is increasingly prevalent, with GitHub Copilot
estimated to generate 46% of the code on GitHub. Accurately evaluating how well
generated code aligns with developer intent remains a critical challenge.
Traditional evaluation methods, such as unit tests, are often unscalable and
costly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code
functionality, and metrics like CodeBERTScore require reference code, which is
not always available. To address the gap in reference-free evaluation, with few
alternatives such as ICE-Score, this paper introduces MATCH, a novel
reference-free metric. MATCH uses Contrastive Learning to generate meaningful
embeddings for code and natural language task descriptions, enabling similarity
scoring that reflects how well generated code implements the task. We show that
MATCH achieves stronger correlations with functional correctness and human
preference than existing metrics across multiple programming languages.

</details>


### [32] [From Slides to Chatbots: Enhancing Large Language Models with University Course Materials](https://arxiv.org/abs/2510.22272)
*Tu Anh Dinh,Philipp Nicolas Schumacher,Jan Niehues*

Main category: cs.CL

TL;DR: 本文研究如何利用大学课程材料提升大型语言模型在计算机科学教育中的问答性能，比较了基于检索增强生成和持续预训练两种方法，并发现前者更有效且多模态图像检索显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在大学计算机科学课程中回答问题准确性较低，如何利用课程多样材料（幻灯片、讲稿等）提升其性能成为挑战。

Method: 比较检索增强生成（RAG）和持续预训练（CPT）方法扩展模型，特别设计多模态RAG以图像形式输入幻灯片中的视觉信息。

Result: RAG方法在课程材料规模较小时表现优于CPT，多模态图像检索显著优于仅文本检索提升模型表现。

Conclusion: 多模态检索增强生成策略为构建更有效的教育辅助AI提供可行路径，促进更好地支持教学与学习。论文成果期待激发其他教育场景的类似研究。

Abstract: Large Language Models (LLMs) have advanced rapidly in recent years. One
application of LLMs is to support student learning in educational settings.
However, prior work has shown that LLMs still struggle to answer questions
accurately within university-level computer science courses. In this work, we
investigate how incorporating university course materials can enhance LLM
performance in this setting. A key challenge lies in leveraging diverse course
materials such as lecture slides and transcripts, which differ substantially
from typical textual corpora: slides also contain visual elements like images
and formulas, while transcripts contain spoken, less structured language. We
compare two strategies, Retrieval-Augmented Generation (RAG) and Continual
Pre-Training (CPT), to extend LLMs with course-specific knowledge. For lecture
slides, we further explore a multi-modal RAG approach, where we present the
retrieved content to the generator in image form. Our experiments reveal that,
given the relatively small size of university course materials, RAG is more
effective and efficient than CPT. Moreover, incorporating slides as images in
the multi-modal setting significantly improves performance over text-only
retrieval. These findings highlight practical strategies for developing AI
assistants that better support learning and teaching, and we hope they inspire
similar efforts in other educational contexts.

</details>


### [33] [Supervised Fine-Tuning or In-Context Learning? Evaluating LLMs for Clinical NER](https://arxiv.org/abs/2510.22285)
*Andrei Baroian*

Main category: cs.CL

TL;DR: 本文研究了在CADEC语料库上临床命名实体识别的三种方法，并发现微调的大型语言模型效果最佳。


<details>
  <summary>Details</summary>
Motivation: 探索不同模型在临床NER任务上的表现，比较传统BERT家族和最新大型语言模型（LLM）的方法，寻找最优方案。

Method: 比较了BERT Base、BioClinicalBERT、RoBERTa-large三种预训练编码器，使用GPT-4o进行的少样本上下文学习（简单和复杂提示）和监督微调三种方法，在CADEC的五种实体类别上进行评测。

Result: RoBERTa-large和BioClinicalBERT相比BERT Base提升有限，复杂提示的ICL表现不及简单提示，监督微调GPT-4o获得最高F1（约87.1%），但成本较高。LLM在简化为二分类任务时表现更好。

Conclusion: 微调大型语言模型在临床NER任务中效果最佳，简单提示优于复杂提示，提示设计和任务简化对性能有明显影响。

Abstract: We study clinical Named Entity Recognition (NER) on the CADEC corpus and
compare three families of approaches: (i) BERT-style encoders (BERT Base,
BioClinicalBERT, RoBERTa-large), (ii) GPT-4o used with few-shot in-context
learning (ICL) under simple vs.\ complex prompts, and (iii) GPT-4o with
supervised fine-tuning (SFT). All models are evaluated on standard NER metrics
over CADEC's five entity types (ADR, Drug, Disease, Symptom, Finding).
RoBERTa-large and BioClinicalBERT offer limited improvements over BERT Base,
showing the limit of these family of models. Among LLM settings, simple ICL
outperforms a longer, instruction-heavy prompt, and SFT achieves the strongest
overall performance (F1 $\approx$ 87.1%), albeit with higher cost. We find that
the LLM achieve higher accuracy on simplified tasks, restricting classification
to two labels.

</details>


### [34] [Memory-based Language Models: An Efficient, Explainable, and Eco-friendly Approach to Large Language Modeling](https://arxiv.org/abs/2510.22317)
*Antal van den Bosch,Ainhoa Risco Patón,Teun Buijse,Peter Berck,Maarten van Gompel*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于记忆的语言建模方法（OLIFANT），作为深度神经网络语言模型的高效、环保替代方案，具有良好的预测性能和较低的生态足迹。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络语言模型训练和推断过程中资源消耗大，生态影响显著，因此需要一种更加高效且环保的替代方法。

Method: 基于k近邻分类的快速近似实现内存语言模型，通过完全依赖CPU运行，实现低延迟和低能耗。

Result: OLIFANT在下一个词预测准确率上与GPT-2和GPT-Neo进行对比，表现出竞争力，同时在速度和碳排放方面更具优势。

Conclusion: 基于记忆的语言模型为无需GPU依赖的高效、透明且环保的自然语言处理提供了可行替代方案。

Abstract: We present memory-based language modeling as an efficient, eco-friendly
alternative to deep neural network-based language modeling. It offers
log-linearly scalable next-token prediction performance and strong memorization
capabilities. Implementing fast approximations of k-nearest neighbor
classification, memory-based language modeling leaves a relatively small
ecological footprint both in training and in inference mode, as it relies fully
on CPUs and attains low token latencies. Its internal workings are simple and
fully transparent. We compare our implementation of memory-based language
modeling, OLIFANT, with GPT-2 and GPT-Neo on next-token prediction accuracy,
estimated emissions and speeds, and offer some deeper analyses of the model.

</details>


### [35] [Multilingual Target-Stance Extraction](https://arxiv.org/abs/2510.22334)
*Ethan Mines,Bonnie Dorr*

Main category: cs.CL

TL;DR: 本文首次提出多语言目标立场提取（TSE）基准，涵盖六种语言，扩展TSE任务至多语言环境。


<details>
  <summary>Details</summary>
Motivation: 现有TSE工作仅限于英语环境，缺乏多语言研究与基准。

Method: 构建多语言TSE基准数据集，设计无需针对每种语言单独模型的多语言TSE流水线。

Result: 模型多语言F1得分为12.78，显示出较英语单语任务更高的难度，目标预测是瓶颈。首次揭示了TSE F1对目标表述方式的敏感性。

Conclusion: 提出了多语言TSE的首个基准与评测标准，为后续研究提供资源和方向。

Abstract: Social media enables data-driven analysis of public opinion on contested
issues. Target-Stance Extraction (TSE) is the task of identifying the target
discussed in a document and the document's stance towards that target. Many
works classify stance towards a given target in a multilingual setting, but all
prior work in TSE is English-only. This work introduces the first multilingual
TSE benchmark, spanning Catalan, Estonian, French, Italian, Mandarin, and
Spanish corpora. It manages to extend the original TSE pipeline to a
multilingual setting without requiring separate models for each language. Our
model pipeline achieves a modest F1 score of 12.78, underscoring the increased
difficulty of the multilingual task relative to English-only setups and
highlighting target prediction as the primary bottleneck. We are also the first
to demonstrate the sensitivity of TSE's F1 score to different target
verbalizations. Together these serve as a much-needed baseline for resources,
algorithms, and evaluation criteria in multilingual TSE.

</details>


### [36] [FAIR-RAG: Faithful Adaptive Iterative Refinement for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.22344)
*Mohammad Aghajani Asl,Majid Asgari-Bidhendi,Behrooz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: FAIR-RAG是一种新型的检索增强生成框架，采用结构化证据评估和迭代细化策略，显著提升了复杂多跳问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成模型在处理复杂、多跳查询时，难以系统识别和填补信息空白，导致噪声传播和上下文不完整。

Method: FAIR-RAG引入了结构化证据评估模块，通过分解查询成清单形式，识别事实与信息空白，再由自适应查询细化代理生成针对性子查询，不断迭代完善证据。

Result: 在HotpotQA、2WikiMultiHopQA和MusiQue等多跳问答基准测试中，FAIR-RAG显著优于强基线，在HotpotQA上F1分数提升8.3个百分点，达到0.453，刷新该类方法的最佳成绩。

Conclusion: 结构化、基于证据的迭代细化机制及显性空白分析是提升高级检索增强生成系统在复杂知识密集型任务中推理准确性和可靠性的关键。

Abstract: While Retrieval-Augmented Generation (RAG) mitigates hallucination and
knowledge staleness in Large Language Models (LLMs), existing frameworks often
falter on complex, multi-hop queries that require synthesizing information from
disparate sources. Current advanced RAG methods, employing iterative or
adaptive strategies, lack a robust mechanism to systematically identify and
fill evidence gaps, often propagating noise or failing to gather a
comprehensive context. We introduce FAIR-RAG, a novel agentic framework that
transforms the standard RAG pipeline into a dynamic, evidence-driven reasoning
process. At its core is an Iterative Refinement Cycle governed by a module we
term Structured Evidence Assessment (SEA). The SEA acts as an analytical gating
mechanism: it deconstructs the initial query into a checklist of required
findings and audits the aggregated evidence to identify confirmed facts and,
critically, explicit informational gaps. These gaps provide a precise signal to
an Adaptive Query Refinement agent, which generates new, targeted sub-queries
to retrieve missing information. This cycle repeats until the evidence is
verified as sufficient, ensuring a comprehensive context for a final, strictly
faithful generation. We conducted experiments on challenging multi-hop QA
benchmarks, including HotpotQA, 2WikiMultiHopQA, and MusiQue. In a unified
experimental setup, FAIR-RAG significantly outperforms strong baselines. On
HotpotQA, it achieves an F1-score of 0.453 -- an absolute improvement of 8.3
points over the strongest iterative baseline -- establishing a new
state-of-the-art for this class of methods on these benchmarks. Our work
demonstrates that a structured, evidence-driven refinement process with
explicit gap analysis is crucial for unlocking reliable and accurate reasoning
in advanced RAG systems for complex, knowledge-intensive tasks.

</details>


### [37] [Irony Detection in Urdu Text: A Comparative Study Using Machine Learning Models and Large Language Models](https://arxiv.org/abs/2510.22356)
*Fiaz Ahmad,Nisar Hussain,Amna Qasim,Momina Hafeez,Muhammad Usman Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

TL;DR: 本研究通过将英文讽刺语料库翻译成乌尔都语，评估多种机器学习和基于变换器的模型以实现乌尔都语的讽刺检测，取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 讽刺识别在自然语言处理中具有挑战性，尤其是对于语法和文化差异较大的低资源语言如乌尔都语，亟需有效的讽刺识别方法。

Method: 将英文讽刺语料库翻译成乌尔都语，使用GloVe和Word2Vec嵌入评估十种机器学习算法，并对BERT、RoBERTa、LLaMA 2、LLaMA 3和Mistral等变换器模型进行微调。

Result: Gradient Boosting在机器学习模型中表现最佳，F1分数为89.18%；LLaMA 3 (8B)在变换器模型中表现最佳，F1分数为94.61%。

Conclusion: 结合转写技术与现代NLP模型，可以实现对乌尔都语这一低资源语言的鲁棒讽刺检测。

Abstract: Ironic identification is a challenging task in Natural Language Processing,
particularly when dealing with languages that differ in syntax and cultural
context. In this work, we aim to detect irony in Urdu by translating an English
Ironic Corpus into the Urdu language. We evaluate ten state-of-the-art machine
learning algorithms using GloVe and Word2Vec embeddings, and compare their
performance with classical methods. Additionally, we fine-tune advanced
transformer-based models, including BERT, RoBERTa, LLaMA 2 (7B), LLaMA 3 (8B),
and Mistral, to assess the effectiveness of large-scale models in irony
detection. Among machine learning models, Gradient Boosting achieved the best
performance with an F1-score of 89.18%. Among transformer-based models, LLaMA 3
(8B) achieved the highest performance with an F1-score of 94.61%. These results
demonstrate that combining transliteration techniques with modern NLP models
enables robust irony detection in Urdu, a historically low-resource language.

</details>


### [38] [GigaEmbeddings: Efficient Russian Language Embedding Model](https://arxiv.org/abs/2510.22369)
*Egor Kolodin,Daria Khomich,Nikita Savushkin,Anastasia Ianina,Fyodor Minkin*

Main category: cs.CL

TL;DR: 本文提出了GigaEmbeddings，一种针对俄语的高性能文本嵌入训练框架，通过分层指令微调解码器型大语言模型GigaChat-3B，实现了多任务泛化和高效性能。


<details>
  <summary>Details</summary>
Motivation: 现有俄语文本嵌入方法存在局限，难以统一多任务目标并充分利用合成数据，需要设计一个专门优化俄语并兼顾效率与效果的嵌入训练框架。

Method: 采用三阶段训练流程：大规模对比预训练、困难负样本微调和多任务泛化，结合双向注意力、潜在注意池化和剪枝25%变换器层以提升效果与效率。

Result: 在涵盖23种多语言任务的ruMTEB基准测试中，GigaEmbeddings以69.1的平均分实现了最新最好成绩，优于参数更多的强基线模型。

Conclusion: GigaEmbeddings框架通过架构创新和训练策略优化，有效提升了俄语文本嵌入的性能与效率，展现了其在多任务处理中的优势和应用潜力。

Abstract: We introduce GigaEmbeddings, a novel framework for training high-performance
Russian-focused text embeddings through hierarchical instruction tuning of the
decoder-only LLM designed specifically for Russian language (GigaChat-3B). Our
three-stage pipeline, comprising large-scale contrastive pre-training in
web-scale corpora, fine-tuning with hard negatives, and multitask
generalization across retrieval, classification, and clustering tasks,
addresses key limitations of existing methods by unifying diverse objectives
and leveraging synthetic data generation. Architectural innovations include
bidirectional attention for contextual modeling, latent attention pooling for
robust sequence aggregation, and strategic pruning of 25% of transformer layers
to enhance efficiency without compromising performance. Evaluated on the ruMTEB
benchmark spanning 23 multilingual tasks, GigaEmbeddings achieves
state-of-the-art results (69.1 avg. score), outperforming strong baselines with
a larger number of parameters.

</details>


### [39] [VisJudge-Bench: Aesthetics and Quality Assessment of Visualizations](https://arxiv.org/abs/2510.22373)
*Yupeng Xie,Zhiyang Zhang,Yifan Wu,Sirong Lu,Jiayi Zhang,Zhaoyang Yu,Jinlin Wang,Sirui Hong,Bang Liu,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 本文提出了VisJudge-Bench，一个用于评估多模态大语言模型（MLLMs）在可视化美学和质量评价上的首个综合基准，并开发了专门模型VisJudge以提升评价准确度。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在自然图像美学评估上表现良好，但缺乏系统化的基准和方法来评价可视化图表的质量，且现有模型与专家判断存在显著差距。

Method: 构建包含3090个专家标注样本的VisJudge-Bench，涵盖多种图表类型和复杂场景；基于此开发专门针对可视化质量评估的模型VisJudge，并进行性能测试。

Result: 实验表明，最先进的MLLM如GPT-5在可视化评价上误差较大且与专家评分相关性较低。VisJudge模型显著提升评价准确度，将误差降低19.8%，与专家一致性提高58.7%。

Conclusion: VisJudge-Bench提供了衡量MLLMs评估可视化质量的标准平台，VisJudge模型有效弥补了现有模型与人类专家间的差距，为可视化质量自动评估提供了实用工具。

Abstract: Visualization, a domain-specific yet widely used form of imagery, is an
effective way to turn complex datasets into intuitive insights, and its value
depends on whether data are faithfully represented, clearly communicated, and
aesthetically designed. However, evaluating visualization quality is
challenging: unlike natural images, it requires simultaneous judgment across
data encoding accuracy, information expressiveness, and visual aesthetics.
Although multimodal large language models (MLLMs) have shown promising
performance in aesthetic assessment of natural images, no systematic benchmark
exists for measuring their capabilities in evaluating visualizations. To
address this, we propose VisJudge-Bench, the first comprehensive benchmark for
evaluating MLLMs' performance in assessing visualization aesthetics and
quality. It contains 3,090 expert-annotated samples from real-world scenarios,
covering single visualizations, multiple visualizations, and dashboards across
32 chart types. Systematic testing on this benchmark reveals that even the most
advanced MLLMs (such as GPT-5) still exhibit significant gaps compared to human
experts in judgment, with a Mean Absolute Error (MAE) of 0.551 and a
correlation with human ratings of only 0.429. To address this issue, we propose
VisJudge, a model specifically designed for visualization aesthetics and
quality assessment. Experimental results demonstrate that VisJudge
significantly narrows the gap with human judgment, reducing the MAE to 0.442 (a
19.8% reduction) and increasing the consistency with human experts to 0.681 (a
58.7% improvement) compared to GPT-5. The benchmark is available at
https://github.com/HKUSTDial/VisJudgeBench.

</details>


### [40] [Confabulations from ACL Publications (CAP): A Dataset for Scientific Hallucination Detection](https://arxiv.org/abs/2510.22395)
*Federica Gamba,Aman Sinha,Timothee Mickus,Raul Vazquez,Patanjali Bhamidipati,Claudio Savelli,Ahana Chattopadhyay,Laura A. Zanella,Yash Kankanampati,Binesh Arakkal Remesh,Aryan Ashok Chandramania,Rohit Agarwal,Chuyuan Li,Ioana Buhnila,Radhika Mamidi*

Main category: cs.CL

TL;DR: 介绍了CAP数据集，一个多语言资源，用于研究大型语言模型在科学文本生成中的幻觉问题。该数据集涵盖多语言，包含科学问题及其由16个模型生成的答案，并标注了事实错误和语言流畅性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在科学文本生成中常出现幻觉（事实错误），尤其在涉及专门术语和复杂推理时，加剧了知识扭曲问题，需有专门的数据集来研究和评估此问题。

Method: 构建了跨语言CAP数据集，覆盖高资源和低资源语言，收集900个科学问题及7000多个由16个公开模型生成的答案，注释事实错误和流畅性问题，并提供针对token的序列和logits信息。

Result: 发布了覆盖九种语言、包含详尽标注的CAP数据集，支持对科学文本生成中幻觉现象的检测与分析，同时支持多语言大模型的评估。

Conclusion: CAP数据集为研究和改进科学文本中大型语言模型幻觉问题提供了宝贵资源，促进更加可靠和多语言的科学自然语言处理系统的发展。

Abstract: We introduce the CAP (Confabulations from ACL Publications) dataset, a
multilingual resource for studying hallucinations in large language models
(LLMs) within scientific text generation. CAP focuses on the scientific domain,
where hallucinations can distort factual knowledge, as they frequently do. In
this domain, however, the presence of specialized terminology, statistical
reasoning, and context-dependent interpretations further exacerbates these
distortions, particularly given LLMs' lack of true comprehension, limited
contextual understanding, and bias toward surface-level generalization. CAP
operates in a cross-lingual setting covering five high-resource languages
(English, French, Hindi, Italian, and Spanish) and four low-resource languages
(Bengali, Gujarati, Malayalam, and Telugu). The dataset comprises 900 curated
scientific questions and over 7000 LLM-generated answers from 16 publicly
available models, provided as question-answer pairs along with token sequences
and corresponding logits. Each instance is annotated with a binary label
indicating the presence of a scientific hallucination, denoted as a factuality
error, and a fluency label, capturing issues in the linguistic quality or
naturalness of the text. CAP is publicly released to facilitate advanced
research on hallucination detection, multilingual evaluation of LLMs, and the
development of more reliable scientific NLP systems.

</details>


### [41] [CHOIR: Collaborative Harmonization fOr Inference Robustness](https://arxiv.org/abs/2510.22475)
*Xiangjue Dong,Cong Wang,Maria Teleki,Millennium Bismay,James Caverlee*

Main category: cs.CL

TL;DR: 本文提出了一种名为CHOIR的框架，通过整合多个角色设定下的推理信号，提高大语言模型的推理鲁棒性，提升了多个人口统计群体的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有人格设定中的微小人口统计变动会导致推理结果差异，传统视为偏差需校正，作者则认为这些差异可作为提升推理鲁棒性的资源。

Method: 提出CHOIR框架，在推理时通过协同解码整合不同角色的人格推理路径，动态平衡其一致性和差异性，形成统一预测。

Result: 在多项推理基准上，CHOIR提升了不同人口统计组和模型架构的性能，个别群体提升最高达26.4%，平均提升19.2%。即使基础角色设定较差，效果仍显著。

Conclusion: 通过将人格变异视为有益信号，CHOIR提供了一种无需额外训练即可提升大语言模型推理鲁棒性、具有良好扩展性和泛化性的通用方法。

Abstract: Persona-assigned Large Language Models (LLMs) can adopt diverse roles,
enabling personalized and context-aware reasoning. However, even minor
demographic perturbations in personas, such as simple pronoun changes, can
alter reasoning trajectories, leading to divergent sets of correct answers.
Instead of treating these variations as biases to be mitigated, we explore
their potential as a constructive resource to improve reasoning robustness. We
propose CHOIR (Collaborative Harmonization fOr Inference Robustness), a
test-time framework that harmonizes multiple persona-conditioned reasoning
signals into a unified prediction. CHOIR orchestrates a collaborative decoding
process among counterfactual personas, dynamically balancing agreement and
divergence in their reasoning paths. Experiments on various reasoning
benchmarks demonstrate that CHOIR consistently enhances performance across
demographics, model architectures, scales, and tasks - without additional
training. Improvements reach up to 26.4% for individual demographic groups and
19.2% on average across five demographics. It remains effective even when base
personas are suboptimal. By reframing persona variation as a constructive
signal, CHOIR provides a scalable and generalizable approach to more reliable
LLM reasoning.

</details>


### [42] [The Tonogenesis Continuum in Tibetan: A Computational Investigation](https://arxiv.org/abs/2510.22485)
*Siyu Liang,Zhaxi Zerong*

Main category: cs.CL

TL;DR: 本文提出一种计算方法，量化音高在发音变化中声调产生（音调化）阶段的功能作用，通过分析藏语方言对音高平滑的敏感性揭示了音调化的连续体。


<details>
  <summary>Details</summary>
Motivation: 传统研究侧重于比较重建和声学语音学，缺乏定量分析音高功能变化的手段。

Method: 采用自动语音识别（ASR）模型，测量音高操作对识别性能的影响，分析不同藏语方言的音高依赖程度。

Result: 发现一个音调化连续体，从无调安多方言对音高平滑最宽容，到完全声调的乌藏方言表现出识别性能严重下降，中间的康方言居于两者之间。

Conclusion: 计算方法能捕捉语音变化的微妙阶段，且传统功能负荷度量方法可能高估了过渡系统中音高的依赖性。

Abstract: Tonogenesis-the historical process by which segmental contrasts evolve into
lexical tone-has traditionally been studied through comparative reconstruction
and acoustic phonetics. We introduce a computational approach that quantifies
the functional role of pitch at different stages of this sound change by
measuring how pitch manipulation affects automatic speech recognition (ASR)
performance. Through analysis on the sensitivity to pitch-flattening from a set
of closely related Tibetan languages, we find evidence of a tonogenesis
continuum: atonal Amdo dialects tolerate pitch removal the most, while fully
tonal U-Tsang varieties show severe degradation, and intermediate Kham dialects
fall measurably between these extremes. These gradient effects demonstrate how
ASR models implicitly learn the shifting functional load of pitch as languages
transition from consonant-based to tone-based lexical contrasts. Our findings
show that computational methods can capture fine-grained stages of sound change
and suggest that traditional functional load metrics, based solely on minimal
pairs, may overestimate pitch dependence in transitional systems where
segmental and suprasegmental cues remain phonetically intertwined.

</details>


### [43] [Frustratingly Easy Task-aware Pruning for Large Language Models](https://arxiv.org/abs/2510.22489)
*Yuanhe Tian,Junjie Liu,Xican Yang,Haishan Ye,Yan Song*

Main category: cs.CL

TL;DR: 本文提出了一种结合通用和任务特定特征分布的参数重要性评分方法，实现了大语言模型任务特定能力的有效剪枝。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型剪枝方法主要关注保持模型生成流畅句子的能力，忽视了在特定领域和任务上的性能表现。

Method: 本文通过分析传统剪枝方法在通用校准数据下的损失扰动，将任务特定特征分布引入参数重要性计算；结合通用与任务特定重要性评分，基于激活范数差异将参数分为共享和独占组，再融合评分指导剪枝。

Result: 实验结果显示该方法在相同剪枝比例及不同设置下，均优于基线方法，有效保持了模型的任务特定能力。

Conclusion: 该剪枝框架可无缝集成多种基础剪枝技术，实现在压缩模型的同时保留其专业能力，在大语言模型压缩领域具有广泛应用潜力。

Abstract: Pruning provides a practical solution to reduce the resources required to run
large language models (LLMs) to benefit from their effective capabilities as
well as control their cost for training and inference. Research on LLM pruning
often ranks the importance of LLM parameters using their magnitudes and
calibration-data activations and removes (or masks) the less important ones,
accordingly reducing LLMs' size. However, these approaches primarily focus on
preserving the LLM's ability to generate fluent sentences, while neglecting
performance on specific domains and tasks. In this paper, we propose a simple
yet effective pruning approach for LLMs that preserves task-specific
capabilities while shrinking their parameter space. We first analyze how
conventional pruning minimizes loss perturbation under general-domain
calibration and extend this formulation by incorporating task-specific feature
distributions into the importance computation of existing pruning algorithms.
Thus, our framework computes separate importance scores using both general and
task-specific calibration data, partitions parameters into shared and exclusive
groups based on activation-norm differences, and then fuses their scores to
guide the pruning process. This design enables our method to integrate
seamlessly with various foundation pruning techniques and preserve the LLM's
specialized abilities under compression. Experiments on widely used benchmarks
demonstrate that our approach is effective and consistently outperforms the
baselines with identical pruning ratios and different settings.

</details>


### [44] [The Limits of Data Scaling: Sub-token Utilization and Acoustic Saturation in Multilingual ASR](https://arxiv.org/abs/2510.22492)
*Siyu Liang,Nicolas Ballier,Gina-Anne Levow,Richard Wright*

Main category: cs.CL

TL;DR: 本文分析了多语言自动语音识别模型Whisper在49种语言中的子词利用情况，发现数据量差异对子词多样性影响较小，子词发现呈指数饱和趋势，提出声学饱和时间(AST)概念。


<details>
  <summary>Details</summary>
Motivation: 研究多语言ASR模型需要多少音频数据才能完全观察其学习到的子词库存，以及预训练中的数据差异是否影响推理时子词的利用模式。

Method: 通过记录Whisper模型推理过程中的解码候选子词及其累计发现情况，分析子词空间的利用模式，并探讨子词发现速率、词频分布和子词长度等指标。

Result: 发现子词数量与语言预训练时长关系不大，子词发现呈一致的指数饱和模式，定义了声学饱和时间(AST)；词频分布符合Zipf-Mandelbrot律，子词长度与资源水平正相关；拉丁字母语言表现优于西里尔、CJK和闪米特语系。

Conclusion: 多语言ASR推理中子词利用更多受语言的统计、类型学和正字法结构限制，而非训练数据规模，为构建更公平的语料库和跨语言评估提供了实证基础。

Abstract: How much audio is needed to fully observe a multilingual ASR model's learned
sub-token inventory across languages, and does data disparity in multilingual
pre-training affect how these tokens are utilized during inference? We address
this question by analyzing Whisper's decoding behavior during inference across
49 languages. By logging decoding candidate sub-tokens and tracking their
cumulative discovery over time, we study the utilization pattern of the model's
sub-token space. Results show that the total number of discovered tokens
remains largely independent of a language's pre-training hours, indicating that
data disparity does not strongly influence lexical diversity in the model's
hypothesis space. Sub-token discovery rates follow a consistent exponential
saturation pattern across languages, suggesting a stable time window after
which additional audio yields minimal new sub-token activation. We refer to
this convergence threshold as acoustic saturation time (AST). Further analyses
of rank-frequency distributions reveal Zipf-like patterns better modeled by a
Zipf-Mandelbrot law, and mean sub-token length shows a positive correlation
with resource level. Additionally, those metrics show more favorable patterns
for languages in the Latin script than those in scripts such as Cyrillic, CJK,
and Semitic. Together, our study suggests that sub-token utilization during
multilingual ASR inference is constrained more by the statistical, typological,
and orthographic structure of the speech than by training data scale, providing
an empirical basis for more equitable corpus construction and cross-lingual
evaluation.

</details>


### [45] [A Sociophonetic Analysis of Racial Bias in Commercial ASR Systems Using the Pacific Northwest English Corpus](https://arxiv.org/abs/2510.22495)
*Michael Scott,Siyu Liang,Alicia Wassink,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 本文系统评估了四大商业自动语音识别系统中的种族偏见，发现语音模型对不同族裔方言的语音变体识别存在误差。


<details>
  <summary>Details</summary>
Motivation: 揭示自动语音识别系统在处理不同族裔发音时存在的偏见及其成因。

Method: 利用PNWE语料库，基于社会语音学注释引入语音错误率指标，分析不同族裔发音特征与识别误差的关系。

Result: 发现在四族裔中，尤其是非裔美国人群体中，元音质量变异显著影响识别准确率，词汇或句法因素影响较小。

Conclusion: 方言语音变体是商业语音识别系统偏见的主要来源，需通过多样性训练数据改善模型表现。

Abstract: This paper presents a systematic evaluation of racial bias in four major
commercial automatic speech recognition (ASR) systems using the Pacific
Northwest English (PNWE) corpus. We analyze transcription accuracy across
speakers from four ethnic backgrounds (African American, Caucasian American,
ChicanX, and Yakama) and examine how sociophonetic variation contributes to
differential system performance. We introduce a heuristically-determined
Phonetic Error Rate (PER) metric that links recognition errors to specific
linguistically motivated variables derived from sociophonetic annotation. Our
analysis of eleven sociophonetic features reveals that vowel quality variation,
particularly resistance to the low-back merger and pre-nasal merger patterns,
is systematically associated with differential error rates across ethnic
groups, with the most pronounced effects for African American speakers across
all evaluated systems. These findings demonstrate that acoustic modeling of
dialectal phonetic variation, rather than lexical or syntactic factors, remains
a primary source of bias in commercial ASR systems. The study establishes the
PNWE corpus as a valuable resource for bias evaluation in speech technologies
and provides actionable guidance for improving ASR performance through targeted
representation of sociophonetic diversity in training data.

</details>


### [46] [Text to Trust: Evaluating Fine-Tuning and LoRA Trade-offs in Language Models for Unfair Terms of Service Detection](https://arxiv.org/abs/2510.22531)
*Noshitha Padma Pratyusha Juttu,Sahithi Singireddy,Sravani Gona,Sujal Timilsina*

Main category: cs.CL

TL;DR: 本研究系统评估了大语言模型在法律领域中针对不公平条款检测的微调及高效适配方法，发现全微调精度最佳，LoRA方法内存效率高且召回率竞争力强。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽提升文本理解能力，但高昂的全面微调成本限制了其在法律专业领域的应用，尤其是在服务条款不公平条款检测任务中。

Method: 本文对BERT、DistilBERT进行全微调，对TinyLlama、LLaMA 3B/7B和SaulLM采用4-bit低秩适配（LoRA），并在零样本条件下评估GPT-4o及其接口版本。实验基于CLAUDETTE-ToS和多语言抓取数据集进行。

Result: 全微调方法在精准率和召回率上表现最好；LoRA适配模型召回率保持竞争力，但内存消耗降低了三倍以上。

Conclusion: 研究揭示了不同微调策略在法律文本处理领域的设计权衡，LoRA方法为高效领域适配提供了实用路径，同时推广了法律文本微调的开放基线。

Abstract: Large Language Models (LLMs) have transformed text understanding, yet their
adaptation to specialized legal domains remains constrained by the cost of full
fine-tuning. This study provides a systematic evaluation of fine tuning,
parameter efficient adaptation (LoRA, QLoRA), and zero-shot prompting
strategies for unfair clause detection in Terms of Service (ToS) documents, a
key application in legal NLP. We finetune BERT and DistilBERT, apply 4-bit
Low-Rank Adaptation (LoRA) to models such as TinyLlama, LLaMA 3B/7B, and
SaulLM, and evaluate GPT-4o and O-versions in zero-shot settings. Experiments
on the CLAUDETTE-ToS benchmark and the Multilingual Scraper Corpus show that
full fine-tuning achieves the strongest precision recall balance, while
LoRA-based models provide competitive recall with up to 3x lower memory cost.
These findings highlight practical design trade-offs for efficient and
domain-adapted LLMs, contributing open baselines for fine-tuning research in
legal text processing.

</details>


### [47] [LooGLE v2: Are LLMs Ready for Real World Long Dependency Challenges?](https://arxiv.org/abs/2510.22548)
*Ziyuan He,Yuxuan Wang,Jiaqi Li,Kexin Liang,Muhan Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种新基准LooGLE v2，用于评估大语言模型在真实世界长上下文任务中的理解能力，结果显示现有模型在长依赖任务上表现有限。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型虽然扩展了上下文窗口，但在处理长依赖任务上的能力仍然受限且缺乏充分研究，现实应用场景对此需求强烈。

Method: 建立LooGLE v2基准，收集16k到2M令牌的真实长文本，涵盖法律、金融、游戏和代码领域，设计10类长依赖任务，生成1,934个多样化问答实例，并评估10个大语言模型表现。

Result: 最优模型在该基准上的总体得分仅为59.2%，现有模型实质上只能理解远短于声称的上下文长度，存在明显不足。

Conclusion: 当前大语言模型在长依赖实际任务中的长上下文理解能力仍有显著提升空间，呼吁进一步改进其处理长文本的能力。

Abstract: Large language models (LLMs) are equipped with increasingly extended context
windows recently, yet their long context understanding capabilities over long
dependency tasks remain fundamentally limited and underexplored. This gap is
especially significant in many real-world long-context applications that were
rarely benchmarked. In this paper, we introduce LooGLE v2, a novel benchmark
designed to evaluate LLMs' long context ability in real-world applications and
scenarios. Our benchmark consists of automatically collected real-world long
texts, ranging from 16k to 2M tokens, encompassing domains in law, finance,
game and code. Accordingly, we delicately design 10 types of domain-specific
long-dependency tasks and generate 1,934 QA instances with various diversity
and complexity in a scalable data curation pipeline for further practical
needs. We conduct a comprehensive assessment of 6 locally deployed and 4
API-based LLMs. The evaluation results show that even the best-performing model
achieves only a 59.2% overall score on our benchmark. Despite the extensive
context windows, popular LLMs are only capable of understanding a much shorter
length of context than they claim to be, revealing significant limitations in
their ability to handle real-world tasks with long dependencies and
highlighting substantial room for model improvement in practical long-context
understanding.

</details>


### [48] [SABlock: Semantic-Aware KV Cache Eviction with Adaptive Compression Block Size](https://arxiv.org/abs/2510.22556)
*Jinhan Chen,Jianchun Liu,Hongli Xu,Xianjun Gao,Shilong Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SABlock的语义感知可变块大小KV缓存剔除框架，有效提升了长上下文大模型推理的内存使用效率和解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存剔除方法难以在语义连贯性和内存效率之间取得平衡，限制了长上下文大语言模型的扩展性。

Method: SABlock通过语义分割对齐压缩边界，基于分段的令牌评分精细估计重要性，并利用预算驱动的搜索策略为每个分段自适应确定最优块大小。

Result: 在长上下文基准测试中，SABlock在相同内存预算下优于现有方法，如在NIAH任务上以96个KV条目达到99.9%的检索准确率，接近保留8K条目的全缓存表现，还实现了46.28%的峰值内存减少和最高9.5倍的解码加速。

Conclusion: SABlock有效提升KV缓存的剔除策略，通过结合语义信息和自适应块大小，实现长上下文LLM推理的高效扩展。

Abstract: The growing memory footprint of the Key-Value (KV) cache poses a severe
scalability bottleneck for long-context Large Language Model (LLM) inference.
While KV cache eviction has emerged as an effective solution by discarding less
critical tokens, existing token-, block-, and sentence-level compression
methods struggle to balance semantic coherence and memory efficiency. To this
end, we introduce SABlock, a \underline{s}emantic-aware KV cache eviction
framework with \underline{a}daptive \underline{block} sizes. Specifically,
SABlock first performs semantic segmentation to align compression boundaries
with linguistic structures, then applies segment-guided token scoring to refine
token importance estimation. Finally, for each segment, a budget-driven search
strategy adaptively determines the optimal block size that preserves semantic
integrity while improving compression efficiency under a given cache budget.
Extensive experiments on long-context benchmarks demonstrate that SABlock
consistently outperforms state-of-the-art baselines under the same memory
budgets. For instance, on Needle-in-a-Haystack (NIAH), SABlock achieves 99.9%
retrieval accuracy with only 96 KV entries, nearly matching the performance of
the full-cache baseline that retains up to 8K entries. Under a fixed cache
budget of 1,024, SABlock further reduces peak memory usage by 46.28% and
achieves up to 9.5x faster decoding on a 128K context length.

</details>


### [49] [A Closed-Loop Personalized Learning Agent Integrating Neural Cognitive Diagnosis, Bounded-Ability Adaptive Testing, and LLM-Driven Feedback](https://arxiv.org/abs/2510.22559)
*Zhifeng Wang,Xinyue Zheng,Chunyan Zeng*

Main category: cs.CL

TL;DR: 本文提出了一个结合神经认知诊断模型、自适应测验策略和大语言模型的个性化学习代理，实现诊断-推荐-反馈的闭环框架，提升学习的个性化和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法多将建模、题目选择与反馈孤立处理，导致学生模型粗糙、适应性假设受限及反馈不具针对性和可操作性。

Method: 提出 EduLoop-Agent，结合神经认知诊断模型(NCD)、有界能力估计自适应测验策略(BECAT)和大语言模型(LLMs)，形成诊断-推荐-反馈的闭环体系。

Result: NCD模块在答题预测上表现优异且具解释性，BECAT提升题目相关性和个性化，大语言模型生成针对弱点的结构化反馈。

Conclusion: 该设计有效且具实际部署价值，为智能教育中个性化学习路径生成提供可行途径。

Abstract: As information technology advances, education is moving from
one-size-fits-all instruction toward personalized learning. However, most
methods handle modeling, item selection, and feedback in isolation rather than
as a closed loop. This leads to coarse or opaque student models,
assumption-bound adaptivity that ignores diagnostic posteriors, and generic,
non-actionable feedback. To address these limitations, this paper presents an
end-to-end personalized learning agent, EduLoop-Agent, which integrates a
Neural Cognitive Diagnosis model (NCD), a Bounded-Ability Estimation
Computerized Adaptive Testing strategy (BECAT), and large language models
(LLMs). The NCD module provides fine-grained estimates of students' mastery at
the knowledge-point level; BECAT dynamically selects subsequent items to
maximize relevance and learning efficiency; and LLMs convert diagnostic signals
into structured, actionable feedback. Together, these components form a
closed-loop framework of ``Diagnosis--Recommendation--Feedback.'' Experiments
on the ASSISTments dataset show that the NCD module achieves strong performance
on response prediction while yielding interpretable mastery assessments. The
adaptive recommendation strategy improves item relevance and personalization,
and the LLM-based feedback offers targeted study guidance aligned with
identified weaknesses. Overall, the results indicate that the proposed design
is effective and practically deployable, providing a feasible pathway to
generating individualized learning trajectories in intelligent education.

</details>


### [50] [Pedagogy-driven Evaluation of Generative AI-powered Intelligent Tutoring Systems](https://arxiv.org/abs/2510.22581)
*Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: 本文综述了AI教育领域智能辅导系统的发展及其在大语言模型驱动下的最新进展，强调了评估框架缺失的问题，并提出了基于学习科学的评估改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型驱动的智能辅导系统缺乏统一、可靠和以教学为核心的评估框架，导致系统进展难以追踪，效果评估存在主观性和不一致性。

Method: 本文回顾了当前智能辅导系统的评估实践，结合真实案例分析其挑战，并基于跨学科研究提出三条以学习科学为基础的评估改进方向。

Result: 揭示了现有评估方法的缺陷和限制，通过理论与实践结合，提出了构建公平、统一和可扩展评估体系的具体建议。

Conclusion: 推动智能辅导系统评估标准化和科学化是促进AI教育领域健康发展的关键，提出的研究方向有助于建立更有效的评估框架，提升系统的实用性和推广性。

Abstract: The interdisciplinary research domain of Artificial Intelligence in Education
(AIED) has a long history of developing Intelligent Tutoring Systems (ITSs) by
integrating insights from technological advancements, educational theories, and
cognitive psychology. The remarkable success of generative AI (GenAI) models
has accelerated the development of large language model (LLM)-powered ITSs,
which have potential to imitate human-like, pedagogically rich, and cognitively
demanding tutoring. However, the progress and impact of these systems remain
largely untraceable due to the absence of reliable, universally accepted, and
pedagogy-driven evaluation frameworks and benchmarks. Most existing educational
dialogue-based ITS evaluations rely on subjective protocols and
non-standardized benchmarks, leading to inconsistencies and limited
generalizability. In this work, we take a step back from mainstream ITS
development and provide comprehensive state-of-the-art evaluation practices,
highlighting associated challenges through real-world case studies from careful
and caring AIED research. Finally, building on insights from previous
interdisciplinary AIED research, we propose three practical, feasible, and
theoretically grounded research directions, rooted in learning science
principles and aimed at establishing fair, unified, and scalable evaluation
methodologies for ITSs.

</details>


### [51] [AutoBench: Automating LLM Evaluation through Reciprocal Peer Assessment](https://arxiv.org/abs/2510.22593)
*Dario Loi,Elena Maria Muià,Federico Siciliano,Giovanni Trappolini,Vincenzo Crisà,Peter Kruger,Fabrizio Silvestri*

Main category: cs.CL

TL;DR: AutoBench是一个自动化的LLM评估框架，通过模型之间的互评动态生成测试任务，实现更可靠和动态的模型评价。


<details>
  <summary>Details</summary>
Motivation: 现有静态基准测试面临测试集污染和适应性差的问题，需要一种动态且不受污染的评估方法。

Method: AutoBench框架中，模型交替扮演题目生成者、参赛者和评判者，通过迭代加权机制整合多个模型的评判，形成共识排名。

Result: 与MMLU-Pro和GPQA基准表现出较强相关性（分别为78%和63%），多评审设计优于单评审，显示评估更稳健且更接近人类评价。

Conclusion: AutoBench提供了一种可扩展且抗污染的动态评估方案，适合用于持续评测不断演进的语言模型。

Abstract: We present AutoBench, a fully automated and self-sustaining framework for
evaluating Large Language Models (LLMs) through reciprocal peer assessment.
This paper provides a rigorous scientific validation of the AutoBench
methodology, originally developed as an open-source project by eZecute S.R.L..
Unlike static benchmarks that suffer from test-set contamination and limited
adaptability, AutoBench dynamically generates novel evaluation tasks while
models alternately serve as question generators, contestants, and judges across
diverse domains. An iterative weighting mechanism amplifies the influence of
consistently reliable evaluators, aggregating peer judgments into
consensus-based rankings that reflect collective model agreement. Our
experiments demonstrate strong correlations with established benchmarks
including MMLU-Pro and GPQA (respectively 78\% and 63\%), validating this
peer-driven evaluation paradigm. The multi-judge design significantly
outperforms single-judge baselines, confirming that distributed evaluation
produces more robust and human-consistent assessments. AutoBench offers a
scalable, contamination-resistant alternative to static benchmarks for the
continuous evaluation of evolving language models.

</details>


### [52] [Personal Care Utility (PCU): Building the Health Infrastructure for Everyday Insight and Guidance](https://arxiv.org/abs/2510.22602)
*Mahyar Abbasian,Ramesh Jain*

Main category: cs.CL

TL;DR: 本文提出了个人护理工具PCU，一种基于AI的终身健康指导系统，实时整合多模态数据，提供个性化健康信息、主动行为指导及治疗恢复解读，推动个人和公共健康进步。


<details>
  <summary>Details</summary>
Motivation: 基于数字基础设施和生物医学创新的成功，旨在突破传统间歇性医疗模式，实现持续、个性化和全方位的健康管理。

Method: 利用多模态代理、事件中心建模及情境推理，构建PCU系统，通过整合个人传感、体验计算和群体分析，提供信任的健康信息和主动健康导航。

Result: PCU作为一个环境感知、适应性的健康伴侣，实现实时观察、解释及指导健康行为，不仅提升个体健康结果，也为公共卫生和科学研究提供新基础。

Conclusion: PCU代表了一种新兴范式，结合架构设计和实现挑战，展示了利用AI和数据融合持续优化健康管理的巨大潜力。

Abstract: Building on decades of success in digital infrastructure and biomedical
innovation, we propose the Personal Care Utility (PCU) - a cybernetic system
for lifelong health guidance. PCU is conceived as a global, AI-powered utility
that continuously orchestrates multimodal data, knowledge, and services to
assist individuals and populations alike. Drawing on multimodal agents,
event-centric modeling, and contextual inference, it offers three essential
capabilities: (1) trusted health information tailored to the individual, (2)
proactive health navigation and behavior guidance, and (3) ongoing
interpretation of recovery and treatment response after medical events. Unlike
conventional episodic care, PCU functions as an ambient, adaptive companion -
observing, interpreting, and guiding health in real time across daily life. By
integrating personal sensing, experiential computing, and population-level
analytics, PCU promises not only improved outcomes for individuals but also a
new substrate for public health and scientific discovery. We describe the
architecture, design principles, and implementation challenges of this emerging
paradigm.

</details>


### [53] [PerCoR: Evaluating Commonsense Reasoning in Persian via Multiple-Choice Sentence Completion](https://arxiv.org/abs/2510.22616)
*Morteza Alikhani,Mohammadtaha Bagherifard,Erfan Zinvandi,Mehran Sarmadi*

Main category: cs.CL

TL;DR: 本文介绍了PerCoR，这是首个大规模波斯语常识推理基准数据集，包含106K多项选择题，覆盖多种话题。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模、挑战性强的波斯语常识推理数据集，导致相关模型性能有限。

Method: 采用创新的连接词分割策略生成多样化句子完成对，提出无生成的对手选择方法DRESS-AF，从金标准续写中选取干扰项，提高模型混淆；并验证方法在英文HellaSwag上的迁移性。

Result: 模型在PerCoR表现最高92.18%，人类得分89%，最强开源模型82.51%，显示数据集难度大且波斯语推理还有较大提升空间。

Conclusion: PerCoR为波斯语常识推理提供了首个大型高挑战数据集，DRESS-AF有效提升数据集难度且具跨语言迁移能力。

Abstract: We introduced PerCoR (Persian Commonsense Reasoning), the first large-scale
Persian benchmark for commonsense reasoning. PerCoR contains 106K
multiple-choice sentence-completion problems drawn from more than forty news,
cultural, and other web sources. We introduce a novel conjunction-based
segmentation strategy to generate coherent sentence-completion pairs, enabling
broad topical and structural diversity. To create challenging distractors, we
propose DRESS-AF (Distractor Ranking via Embedding Similarity Scoring and
Adversarial Filtering), a generation-free adversarial filtering method that
selects distractors from the pool of gold continuations while maximising model
confusion. Human annotators score 89% on PerCoR, while OpenAI-o3 achieves the
highest performance at 92.18%, followed closely by Claude-Sonnet-3.7 (91.17%).
The strongest open-source model, DeepSeek-R1, reaches 82.51%, underscoring both
the dataset's difficulty and the remaining performance gap in Persian
commonsense reasoning. We further show that DRESS-AF transfers to the English
HellaSwag benchmark, increasing its difficulty without hurting human
solvability. The dataset is available at
https://huggingface.co/datasets/MCINext/PerCoR.

</details>


### [54] [Integrating Linguistics and AI: Morphological Analysis and Corpus development of Endangered Toto Language of West Bengal](https://arxiv.org/abs/2510.22629)
*Ambalika Guha,Sajal Saha,Debanjan Ballav,Soumi Mitra,Hritwick Chakraborty*

Main category: cs.CL

TL;DR: 该论文开发了一款面向Toto语言（印度西孟加拉邦濒危语言）的三语学习应用，通过语言文档整理与AI技术结合，促进语言保护与振兴。


<details>
  <summary>Details</summary>
Motivation: 保护语言多样性是必要的，每种语言提供独特的世界视角。濒危语言需要数字化档案和推广以防止消失。

Method: 通过实地调研收集详细语言资料，建立词素标注的三语语料库，训练小型语言模型和基于Transformer的翻译引擎；实现Unicode文本脚本标准化并开发数字工具辅助语言学习。

Result: 构建了系统的语言数据资源和工具，支持母语者及非母语者学习，并提升语言书写能力和数字化使用场景。

Conclusion: 结合传统语言学方法与人工智能技术，为濒危语言保护提供可持续且有效的模型，展示了跨学科合作在社区语言振兴中的重要价值。

Abstract: Preserving linguistic diversity is necessary as every language offers a
distinct perspective on the world. There have been numerous global initiatives
to preserve endangered languages through documentation. This paper is a part of
a project which aims to develop a trilingual (Toto-Bangla-English) language
learning application to digitally archive and promote the endangered Toto
language of West Bengal, India. This application, designed for both native Toto
speakers and non-native learners, aims to revitalize the language by ensuring
accessibility and usability through Unicode script integration and a structured
language corpus. The research includes detailed linguistic documentation
collected via fieldwork, followed by the creation of a morpheme-tagged,
trilingual corpus used to train a Small Language Model (SLM) and a
Transformer-based translation engine. The analysis covers inflectional
morphology such as person-number-gender agreement, tense-aspect-mood
distinctions, and case marking, alongside derivational strategies that reflect
word-class changes. Script standardization and digital literacy tools were also
developed to enhance script usage. The study offers a sustainable model for
preserving endangered languages by incorporating traditional linguistic
methodology with AI. This bridge between linguistic research with technological
innovation highlights the value of interdisciplinary collaboration for
community-based language revitalization.

</details>


### [55] [Culturally Grounded Physical Commonsense Reasoning in Italian and English: A Submission to the MRL 2025 Shared Task](https://arxiv.org/abs/2510.22631)
*Marco De Santis,Lisa Alazraki*

Main category: cs.CL

TL;DR: 本文介绍了一个名为FormaMentis的物理常识推理多语言基准数据集，专注于意大利语和文化，数据由意大利本土专家标注并翻译成英文，同时保留文化特色。


<details>
  <summary>Details</summary>
Motivation: 为了拓展物理常识推理领域的数据覆盖，针对非英语语言创建高质量的手工标注评估数据，特别是在意大利语及其文化背景下。

Method: 组织意大利本土专家进行标注，确保数据体现当地习俗和文化规范，并将样本翻译成英文，保证文化元素的完整性。

Result: 构建了形成本土文化特色的意大利语物理常识推理数据集FormaMentis，并提供了对应的英文版本。

Conclusion: FormaMentis为物理常识推理研究提供了新的多语言、多文化视角的基准，有助于提升相关任务在非英语语言环境下的表现和研究深度。

Abstract: This paper presents our submission to the MRL 2025 Shared Task on
Multilingual Physical Reasoning Datasets. The objective of the shared task is
to create manually-annotated evaluation data in the physical commonsense
reasoning domain, for languages other than English, following a format similar
to PIQA. Our contribution, FormaMentis, is a novel benchmark for physical
commonsense reasoning that is grounded in Italian language and culture. The
data samples in FormaMentis are created by expert annotators who are native
Italian speakers and are familiar with local customs and norms. The samples are
additionally translated into English, while preserving the cultural elements
unique to the Italian context.

</details>


### [56] [Conjugate Relation Modeling for Few-Shot Knowledge Graph Completion](https://arxiv.org/abs/2510.22656)
*Zilong Wang,Qingtian Zeng,Hua Duan,Cheng Cheng,Minghao Zou,Ziyang Wang*

Main category: cs.CL

TL;DR: 本文提出了一种针对小样本知识图完成的新型框架CR-FKGC，通过邻居信息聚合和结合条件扩散与稳定关系模块，提升了对复杂关系模式的捕捉能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有小样本知识图完成方法难以捕捉复杂关系模式且数据稀疏性问题未得到有效解决。

Method: 采用邻居聚合编码器获取高阶邻居信息，结合隐式条件扩散关系模块与稳定关系模块的共轭关系学习器，利用流形共轭解码器进行有效推断。

Result: 在三个基准数据集上进行实验，方法在性能上显著优于当前最先进的技术。

Conclusion: 所提CR-FKGC框架有效提升了小样本知识图完成的准确率，展示了更强的关系建模能力及对数据稀疏性的缓解效果。

Abstract: Few-shot Knowledge Graph Completion (FKGC) infers missing triples from
limited support samples, tackling long-tail distribution challenges. Existing
methods, however, struggle to capture complex relational patterns and mitigate
data sparsity. To address these challenges, we propose a novel FKGC framework
for conjugate relation modeling (CR-FKGC). Specifically, it employs a
neighborhood aggregation encoder to integrate higher-order neighbor
information, a conjugate relation learner combining an implicit conditional
diffusion relation module with a stable relation module to capture stable
semantics and uncertainty offsets, and a manifold conjugate decoder for
efficient evaluation and inference of missing triples in manifold space.
Experiments on three benchmarks demonstrate that our method achieves superior
performance over state-of-the-art methods.

</details>


### [57] [Rule-Based Explanations for Retrieval-Augmented LLM Systems](https://arxiv.org/abs/2510.22689)
*Joel Rorseth,Parke Godfrey,Lukasz Golab,Divesh Srivastava,Jarek Szlichta*

Main category: cs.CL

TL;DR: 本文首次提出利用规则解释检索增强生成（RAG）大语言模型（LLM）的输出，通过优化算法高效生成解释性规则。


<details>
  <summary>Details</summary>
Motivation: RAG模型可以在推理时结合检索到的信息来源，因而通过规则解释这些来源对输出的影响具有重要意义。

Method: 提出一种基于Apriori算法启发式剪枝的优化方案，减少规则生成时需探测的来源组合数量，提高效率。

Result: 通过定性和定量实验，验证了该方法在生成解释规则上的有效性和效率提升。

Conclusion: 该方法为解释RAG集成的LLM提供了一种新颖且高效的规则生成手段，有助于理解模型输出的来源依据。

Abstract: If-then rules are widely used to explain machine learning models; e.g., "if
employed = no, then loan application = rejected." We present the first proposal
to apply rules to explain the emerging class of large language models (LLMs)
with retrieval-augmented generation (RAG). Since RAG enables LLM systems to
incorporate retrieved information sources at inference time, rules linking the
presence or absence of sources can explain output provenance; e.g., "if a Times
Higher Education ranking article is retrieved, then the LLM ranks Oxford
first." To generate such rules, a brute force approach would probe the LLM with
all source combinations and check if the presence or absence of any sources
leads to the same output. We propose optimizations to speed up rule generation,
inspired by Apriori-like pruning from frequent itemset mining but redefined
within the scope of our novel problem. We conclude with qualitative and
quantitative experiments demonstrating our solutions' value and efficiency.

</details>


### [58] [SALSA: Single-pass Autoregressive LLM Structured Classification](https://arxiv.org/abs/2510.22691)
*Ruslan Berdichevsky,Shai Nahum-Gefen,Elad Ben Zaken*

Main category: cs.CL

TL;DR: 提出了一种名为SALSA的统一流水线方法，通过结构化提示、类别到标记映射及高效微调，提高指令调优大语言模型在文本分类任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管指令调优的大型语言模型泛化能力强，但在文本分类测试中表现欠佳，需提升其分类性能。

Method: 设计SALSA流水线，将每个类别标签映射到特定输出标记，构建单一标记响应的提示，推理时只计算相关类别标记的logits，实现高效准确的单次前向传播分类。

Result: SALSA在多个不同基准测试中达到了最先进的性能，显示了其在基于大型语言模型的分类任务中的鲁棒性和可扩展性。

Conclusion: SALSA方法有效解决了大语言模型文本分类中的冷启动问题，并在保持效率的同时显著提升了分类准确率。

Abstract: Despite their impressive generalization capabilities, instruction-tuned Large
Language Models often underperform on text classification benchmarks. We
introduce SALSA, a coherent pipeline that combines structured prompting,
class-to-token mapping, and parameter-efficient fine-tuning, thereby avoiding
cold-start training. Each class label is mapped to a distinct output token, and
prompts are constructed to elicit a single-token response. During inference,
the model's output is projected only onto the logits of the relevant class
tokens, enabling efficient and accurate classification in a single forward
pass. SALSA achieves state-of-the-art results across diverse benchmarks,
demonstrating its robustness and scalability for LLM-based classification
applications.

</details>


### [59] [$\text{E}^2\text{Rank}$: Your Text Embedding can Also be an Effective and Efficient Listwise Reranker](https://arxiv.org/abs/2510.22733)
*Qi Liu,Yanzhao Zhang,Mingxin Li,Dingkun Long,Pengjun Xie,Jiaxin Mao*

Main category: cs.CL

TL;DR: 本文提出了E²Rank框架，通过继续训练单一文本嵌入模型实现检索和listwise重排的统一，提高了排序质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有文本嵌入模型在效率高的同时，排序准确性不及基于LLM的listwise重排器，亟需兼顾准确性和效率的统一方案。

Method: 基于余弦相似度的统一排序函数，将listwise排序的提示构造成增强查询，类似传统检索中的伪相关反馈，通过继续训练实现检索与重排任务的统一。

Result: E²Rank在BEIR重排基准测试中达到最先进水平，在推理密集型的BRIGHT基准中表现也具竞争力，且重排延迟低，训练过程提升了MTEB基准的嵌入表现。

Conclusion: 单一文本嵌入模型通过统一训练方案，能够高效地实现高质量检索与重排序，兼顾计算效率和排序准确性。

Abstract: Text embedding models serve as a fundamental component in real-world search
applications. By mapping queries and documents into a shared embedding space,
they deliver competitive retrieval performance with high efficiency. However,
their ranking fidelity remains limited compared to dedicated rerankers,
especially recent LLM-based listwise rerankers, which capture fine-grained
query-document and document-document interactions. In this paper, we propose a
simple yet effective unified framework $\text{E}^2\text{Rank}$, means Efficient
Embedding-based Ranking (also means Embedding-to-Rank), which extends a single
text embedding model to perform both high-quality retrieval and listwise
reranking through continued training under a listwise ranking objective,
thereby achieving strong effectiveness with remarkable efficiency. By applying
cosine similarity between the query and document embeddings as a unified
ranking function, the listwise ranking prompt, which is constructed from the
original query and its candidate documents, serves as an enhanced query
enriched with signals from the top-K documents, akin to pseudo-relevance
feedback (PRF) in traditional retrieval models. This design preserves the
efficiency and representational quality of the base embedding model while
significantly improving its reranking performance. Empirically,
$\textrm{E}^2\text{Rank}$ achieves state-of-the-art results on the BEIR
reranking benchmark and demonstrates competitive performance on the
reasoning-intensive BRIGHT benchmark, with very low reranking latency. We also
show that the ranking training process improves embedding performance on the
MTEB benchmark. Our findings indicate that a single embedding model can
effectively unify retrieval and reranking, offering both computational
efficiency and competitive ranking accuracy.

</details>


### [60] [Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study](https://arxiv.org/abs/2510.22747)
*Eeham Khan,Firas Saidani,Owen Van Esbroeck,Richard Khoury,Leila Kosseim*

Main category: cs.CL

TL;DR: 本论文探讨在有限数据和计算资源下，利用持续预训练(CPT)和低秩适应(LoRA)方法，将大型语言模型(LLMs)适配到低资源法语方言（魁北克法语），显著提升了方言表现且对主流语言性能影响极小。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型主要针对高资源语言，低资源方言模型因训练数据匮乏效果较弱。如何在数据和计算受限条件下提升方言模型性能成为重要挑战。

Method: 采用低秩适应(LoRA)和计算高效的持续预训练(CPT)技术，在小规模魁北克法语数据集上微调三种LLMs，并利用COLE套件进行评测。

Result: 在更新不到1%的模型参数情况下，显著提升了少数方言的基准表现，对主流语言表现影响极小。结果分析表明，语料组成对提升效果影响显著。

Conclusion: 基于参数高效微调的CPT方法能够有效缩小语言模型的方言差距，以低成本和可持续的方式推动少数语言社区高质量语言资源创建，提升其高质量大型语言模型的可及性。

Abstract: Despite the widespread adoption of large language models (LLMs), their
strongest capabilities remain largely confined to a small number of
high-resource languages for which there is abundant training data. Recently,
continual pre-training (CPT) has emerged as a means to fine-tune these models
to low-resource regional dialects. In this paper, we study the use of CPT for
dialect learning under tight data and compute budgets. Using low-rank
adaptation (LoRA) and compute-efficient continual pre-training, we adapt three
LLMs to the Qu\'ebec French dialect using a very small dataset and benchmark
them on the COLE suite. Our experiments demonstrate an improvement on the
minority dialect benchmarks with minimal regression on the prestige language
benchmarks with under 1% of model parameters updated. Analysis of the results
demonstrate that gains are highly contingent on corpus composition. These
findings indicate that CPT with parameter-efficient fine-tuning (PEFT) can
narrow the dialect gap by providing cost-effective and sustainable language
resource creation, expanding high-quality LLM access to minority linguistic
communities. We release the first Qu\'ebec French LLMs on HuggingFace.

</details>


### [61] [Beyond Semantics: How Temporal Biases Shape Retrieval in Transformer and State-Space Models](https://arxiv.org/abs/2510.22752)
*Anooshka Bajaj,Deven Mahesh Mistry,Sahaj Singh Maini,Yash Aggarwal,Zoran Tiganj*

Main category: cs.CL

TL;DR: 本文研究了预训练大型语言模型（LLMs）在上下文学习中如何区分和检索时间上分隔的事件，揭示了模型对时间先后顺序的偏好及其机制。


<details>
  <summary>Details</summary>
Motivation: 类比人类情景记忆在时间上分离事件以便检索，探究预训练LLM在处理时间分隔信息时的能力及偏差。

Method: 设计包含重复token的序列，通过固定重复token位置和随机置换其他token，去除语义干扰，分析模型对时间顺序的响应，结合消融实验探究机制。

Result: 模型对重复token后紧邻序列开头或结尾的token赋予最高概率，显示了显著的时间偏好；该现象与transformer中的induction heads相关；不同架构模型表现相似的时间偏差。

Conclusion: 预训练LLM在上下文学习中表现出明显的时间偏向，这种偏向有助于时间分离和类情景记忆的检索，拓展了对模型上下文处理能力的理解。

Abstract: In-context learning is governed by both temporal and semantic relationships,
shaping how Large Language Models (LLMs) retrieve contextual information.
Analogous to human episodic memory, where the retrieval of specific events is
enabled by separating events that happened at different times, this work probes
the ability of various pretrained LLMs, including transformer and state-space
models, to differentiate and retrieve temporally separated events.
Specifically, we prompted models with sequences containing multiple
presentations of the same token, which reappears at the sequence end. By fixing
the positions of these repeated tokens and permuting all others, we removed
semantic confounds and isolated temporal effects on next-token prediction.
Across diverse sequences, models consistently placed the highest probabilities
on tokens following a repeated token, but with a notable bias for those nearest
the beginning or end of the input. An ablation experiment linked this
phenomenon in transformers to induction heads. Extending the analysis to unique
semantic contexts with partial overlap further demonstrated that memories
embedded in the middle of a prompt are retrieved less reliably. Despite
architectural differences, state-space and transformer models showed comparable
temporal biases. Our findings deepen the understanding of temporal biases in
in-context learning and offer an illustration of how these biases can enable
temporal separation and episodic retrieval.

</details>


### [62] [EchoMind: An Interrelated Multi-level Benchmark for Evaluating Empathetic Speech Language Models](https://arxiv.org/abs/2510.22758)
*Li Zhou,Lutong Yu,You Lyu,Yihang Lin,Zefeng Zhao,Junyi Ao,Yuhao Zhang,Benyou Wang,Haizhou Li*

Main category: cs.CL

TL;DR: 本文提出EchoMind基准测试，评估语音语言模型在整合语言内容与非言语表达（声学线索）以实现情感共鸣对话能力的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估通常独立测试语言、声学或推理能力，忽视了这些技能的整合，这对于实现类人且情感智能的对话至关重要。

Method: 设计了EchoMind多层级、多任务的基准，模拟共情对话的认知过程，任务涵盖语音内容理解、声学线索感知、综合推理和回应生成，所有任务共享语义中立文本，通过控制发声风格测试声学表达对理解的影响。

Result: 测试了12个先进的语音语言模型，发现即使最先进模型也难以处理高表达性的声学线索，影响共情回应效果；模型在指令执行、自然语音变异适应和声学线索利用方面存在不足。

Conclusion: 研究强调需要发展能够整合语言内容与多样声学线索的语音语言模型，以实现真正具备共情能力的对话系统。

Abstract: Speech Language Models (SLMs) have made significant progress in spoken
language understanding. Yet it remains unclear whether they can fully perceive
non lexical vocal cues alongside spoken words, and respond with empathy that
aligns with both emotional and contextual factors. Existing benchmarks
typically evaluate linguistic, acoustic, reasoning, or dialogue abilities in
isolation, overlooking the integration of these skills that is crucial for
human-like, emotionally intelligent conversation. We present EchoMind, the
first interrelated, multi-level benchmark that simulates the cognitive process
of empathetic dialogue through sequential, context-linked tasks: spoken-content
understanding, vocal-cue perception, integrated reasoning, and response
generation. All tasks share identical and semantically neutral scripts that are
free of explicit emotional or contextual cues, and controlled variations in
vocal style are used to test the effect of delivery independent of the
transcript. EchoMind is grounded in an empathy-oriented framework spanning 3
coarse and 12 fine-grained dimensions, encompassing 39 vocal attributes, and
evaluated using both objective and subjective metrics. Testing 12 advanced SLMs
reveals that even state-of-the-art models struggle with high-expressive vocal
cues, limiting empathetic response quality. Analyses of prompt strength, speech
source, and ideal vocal cue recognition reveal persistent weaknesses in
instruction-following, resilience to natural speech variability, and effective
use of vocal cues for empathy. These results underscore the need for SLMs that
integrate linguistic content with diverse vocal cues to achieve truly
empathetic conversational ability.

</details>


### [63] [Iterative Layer Pruning for Efficient Translation Inference](https://arxiv.org/abs/2510.22763)
*Yasmin Moslem,Muhammad Hazim Al Farouq,John D. Kelleher*

Main category: cs.CL

TL;DR: 本文针对大型语言模型在机器翻译中的高计算需求问题，提出基于层重要性分析的迭代剪枝方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽提升了自然语言处理性能，但其计算资源消耗大，部署效率低。

Method: 通过层重要性分析指导迭代层剪枝，使用Aya-Expanse-8B模型进行捷克语-德语和英语-埃及阿拉伯语的翻译实验。

Result: 模型体积和推理时间明显减少，同时保持了基线模型的翻译质量。

Conclusion: 迭代层剪枝方法有效提升了大型语言模型的部署效率，适用于机器翻译任务。

Abstract: Large language models (LLMs) have transformed many areas of natural language
processing, including machine translation. However, efficient deployment of
LLMs remains challenging due to their intensive computational requirements. In
this paper, we address this challenge and present our submissions to the Model
Compression track at the Conference on Machine Translation (WMT 2025). In our
experiments, we investigate iterative layer pruning guided by layer importance
analysis. We evaluate this method using the Aya-Expanse-8B model for
translation from Czech to German, and from English to Egyptian Arabic. Our
approach achieves substantial reductions in model size and inference time,
while maintaining the translation quality of the baseline models.

</details>


### [64] [MMPersuade: A Dataset and Evaluation Framework for Multimodal Persuasion](https://arxiv.org/abs/2510.22768)
*Haoyi Qiu,Yilun Zhou,Pranav Narayanan Venkit,Kung-Hsiang Huang,Jiaxin Zhang,Nanyun Peng,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 本文提出了一个统一框架MMPersuade，用于系统研究大型视觉-语言模型在多模态说服情境下的表现，揭示其易受影响的机制和不同说服策略的效果。


<details>
  <summary>Details</summary>
Motivation: 随着大型视觉-语言模型应用于购物、健康、新闻等领域，它们面临大量有说服性的内容，理解其易受影响程度以及说服策略的有效性对防止模型产生误导性信念和不安全输出至关重要。

Method: 构建了包含图像和视频以及多种说服原则的多模态数据集，并设计评价框架通过第三方一致性评分和模型自估计概率量化说服效果和模型易感性，研究了六种顶尖模型的表现。

Result: 发现多模态输入相比纯文本显著提高说服效果和模型易感性，既定偏好虽减弱易感性但多模态信息仍具说服优势，不同策略在不同情境中效果不同，互惠在商业和主观情境中最有效，而信誉和逻辑在对抗情境中更具优势。

Conclusion: MMPersuade通过联合分析说服效果和易感性，为开发鲁棒、偏好一致且伦理合规的模型奠定了基础，有助于模型安全地应对多模态说服内容。

Abstract: As Large Vision-Language Models (LVLMs) are increasingly deployed in domains
such as shopping, health, and news, they are exposed to pervasive persuasive
content. A critical question is how these models function as persuadees-how and
why they can be influenced by persuasive multimodal inputs. Understanding both
their susceptibility to persuasion and the effectiveness of different
persuasive strategies is crucial, as overly persuadable models may adopt
misleading beliefs, override user preferences, or generate unethical or unsafe
outputs when exposed to manipulative messages. We introduce MMPersuade, a
unified framework for systematically studying multimodal persuasion dynamics in
LVLMs. MMPersuade contributes (i) a comprehensive multimodal dataset that pairs
images and videos with established persuasion principles across commercial,
subjective and behavioral, and adversarial contexts, and (ii) an evaluation
framework that quantifies both persuasion effectiveness and model
susceptibility via third-party agreement scoring and self-estimated token
probabilities on conversation histories. Our study of six leading LVLMs as
persuadees yields three key insights: (i) multimodal inputs substantially
increase persuasion effectiveness-and model susceptibility-compared to text
alone, especially in misinformation scenarios; (ii) stated prior preferences
decrease susceptibility, yet multimodal information maintains its persuasive
advantage; and (iii) different strategies vary in effectiveness across
contexts, with reciprocity being most potent in commercial and subjective
contexts, and credibility and logic prevailing in adversarial contexts. By
jointly analyzing persuasion effectiveness and susceptibility, MMPersuade
provides a principled foundation for developing models that are robust,
preference-consistent, and ethically aligned when engaging with persuasive
multimodal content.

</details>


### [65] [VEHME: A Vision-Language Model For Evaluating Handwritten Mathematics Expressions](https://arxiv.org/abs/2510.22798)
*Thu Phuong Nguyen,Duc M. Nguyen,Hyotaek Jeon,Hyunwook Lee,Hyunmin Song,Sungahn Ko,Taehwan Kim*

Main category: cs.CL

TL;DR: 提出了VEHME模型，结合视觉与语言技术，准确评估手写数学表达式，具备解释性和多维评分能力，在开放数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动评估手写数学解答困难在于格式多样、布局无序及符号复杂，亟需一种能准确理解并评价学生开放式解答的方法。

Method: 设计VEHME，采用两阶段训练：一是利用结构化推理数据进行监督微调，二是通过强化学习使输出符合正确性、推理深度和错误定位等多维评分目标，同时引入表达式感知视觉提示模块增强空间理解能力。

Result: 在AIHub和FERMAT数据集上，VEHME达到开源模型中领先水平，性能接近专有系统，显示出强大的自动数学评估能力。

Conclusion: VEHME为自动手写数学解答评估提供了准确、可解释且可扩展的解决方案，对教育技术具有较大应用潜力。

Abstract: Automatically assessing handwritten mathematical solutions is an important
problem in educational technology with practical applications, but it remains a
significant challenge due to the diverse formats, unstructured layouts, and
symbolic complexity of student work. To address this challenge, we introduce
VEHME-a Vision-Language Model for Evaluating Handwritten Mathematics
Expressions-designed to assess open-form handwritten math responses with high
accuracy and interpretable reasoning traces. VEHME integrates a two-phase
training pipeline: (i) supervised fine-tuning using structured reasoning data,
and (ii) reinforcement learning that aligns model outputs with
multi-dimensional grading objectives, including correctness, reasoning depth,
and error localization. To enhance spatial understanding, we propose an
Expression-Aware Visual Prompting Module, trained on our synthesized multi-line
math expressions dataset to robustly guide attention in visually heterogeneous
inputs. Evaluated on AIHub and FERMAT datasets, VEHME achieves state-of-the-art
performance among open-source models and approaches the accuracy of proprietary
systems, demonstrating its potential as a scalable and accessible tool for
automated math assessment. Our training and experiment code is publicly
available at our GitHub repository.

</details>


### [66] [Cross-Lingual Stability and Bias in Instruction-Tuned Language Models for Humanitarian NLP](https://arxiv.org/abs/2510.22823)
*Poli Nemkova,Amrit Adhikari,Matthew Pearson,Vamsi Krishna Sadu,Mark V. Albert*

Main category: cs.CL

TL;DR: 本文系统比较了六款大型语言模型在七种语言中的人权侵害检测表现，揭示了商业模型与开源模型在成本和可靠性上的权衡。


<details>
  <summary>Details</summary>
Motivation: 人道主义组织需在昂贵的商业API与免费开源模型间做选择，尤其面对低资源语言时，开源模型缺乏实证验证。

Method: 通过78,000次多语言推断，评估四款指令对齐模型与两款开源模型，采用标准分类指标及跨语言可靠性指标（校准偏差、决策偏差、语言鲁棒性和语言稳定性评分）。

Result: 结果显示模型的对齐程度比规模决定稳定性：对齐模型在不同语言之间表现稳定且校准良好，而开源模型存在提示语言敏感性与校准漂移。

Conclusion: 多语言模型的指令对齐显著提升语言无关推理能力，为资源有限的人道主义组织提供了在多语言部署中平衡预算与可靠性的实用指导。

Abstract: Humanitarian organizations face a critical choice: invest in costly
commercial APIs or rely on free open-weight models for multilingual human
rights monitoring. While commercial systems offer reliability, open-weight
alternatives lack empirical validation -- especially for low-resource languages
common in conflict zones. This paper presents the first systematic comparison
of commercial and open-weight large language models (LLMs) for
human-rights-violation detection across seven languages, quantifying the
cost-reliability trade-off facing resource-constrained organizations. Across
78,000 multilingual inferences, we evaluate six models -- four
instruction-aligned (Claude-Sonnet-4, DeepSeek-V3, Gemini-Flash-2.0,
GPT-4.1-mini) and two open-weight (LLaMA-3-8B, Mistral-7B) -- using both
standard classification metrics and new measures of cross-lingual reliability:
Calibration Deviation (CD), Decision Bias (B), Language Robustness Score (LRS),
and Language Stability Score (LSS). Results show that alignment, not scale,
determines stability: aligned models maintain near-invariant accuracy and
balanced calibration across typologically distant and low-resource languages
(e.g., Lingala, Burmese), while open-weight models exhibit significant
prompt-language sensitivity and calibration drift. These findings demonstrate
that multilingual alignment enables language-agnostic reasoning and provide
practical guidance for humanitarian organizations balancing budget constraints
with reliability in multilingual deployment.

</details>


### [67] [Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays](https://arxiv.org/abs/2510.22830)
*Haowei Hua,Hong Jiao,Xinyi Wang*

Main category: cs.CL

TL;DR: 本文提出利用生成式语言模型通过摘要和提示方法改进长篇作文自动评分，显著提升评分准确率。


<details>
  <summary>Details</summary>
Motivation: 传统BERT及其变体在处理超过512标记的长篇作文自动评分时存在局限性。

Method: 采用生成式语言模型结合摘要和提示技术进行长篇作文自动评分。

Result: 在Learning Agency Lab Automated Essay Scoring 2.0数据集上评分准确率显著提升，QWK从0.822提升至0.8878。

Conclusion: 生成式语言模型在长篇作文自动评分中表现优异，克服了编码器模型长度限制的问题。

Abstract: BERT and its variants are extensively explored for automated scoring.
However, a limit of 512 tokens for these encoder-based models showed the
deficiency in automated scoring of long essays. Thus, this research explores
generative language models for automated scoring of long essays via
summarization and prompting. The results revealed great improvement of scoring
accuracy with QWK increased from 0.822 to 0.8878 for the Learning Agency Lab
Automated Essay Scoring 2.0 dataset.

</details>


### [68] [Leveraging Large Language Models to Identify Conversation Threads in Collaborative Learning](https://arxiv.org/abs/2510.22844)
*Prerna Ravi,Dong Won Lee,Beatriz Flamia,Jasmine David,Brandon Hanks,Cynthia Breazeal,Emma Anderson,Grace Lin*

Main category: cs.CL

TL;DR: 本文研究了如何在同步小组对话中检测会话线程，以提升基于大型语言模型(LLM)的对话编码表现。


<details>
  <summary>Details</summary>
Motivation: 小组协作学习分析需理解思想如何在对话中发展，传统线程检测多用于异步文本，同步口语对话因重叠发言和隐含线索而难以分析，同时LLM在长上下文任务中表现不佳。

Method: 本文提出了一个系统化的指南来识别同步多方对话中的线程，比较了不同LLM提示策略对自动线程检测的效果，并评估线程信息对后续对话编码任务（如同意、构建、引导等协作行为编码）的影响。

Result: 结果显示，明确的会话线程信息显著提升了LLM的编码性能，且下游分析高度依赖良好结构化的对话，同时分析了时间和成本的权衡，提出人机混合方式的最佳实践。

Conclusion: 结合LLM与稳定的会话线程结构，能够更有效地理解复杂实时小组互动，为协作学习和对话分析提供更精确的工具和方法。

Abstract: Understanding how ideas develop and flow in small-group conversations is
critical for analyzing collaborative learning. A key structural feature of
these interactions is threading, the way discourse talk naturally organizes
into interwoven topical strands that evolve over time. While threading has been
widely studied in asynchronous text settings, detecting threads in synchronous
spoken dialogue remains challenging due to overlapping turns and implicit cues.
At the same time, large language models (LLMs) show promise for automating
discourse analysis but often struggle with long-context tasks that depend on
tracing these conversational links. In this paper, we investigate whether
explicit thread linkages can improve LLM-based coding of relational moves in
group talk. We contribute a systematic guidebook for identifying threads in
synchronous multi-party transcripts and benchmark different LLM prompting
strategies for automated threading. We then test how threading influences
performance on downstream coding of conversational analysis frameworks, that
capture core collaborative actions such as agreeing, building, and eliciting.
Our results show that providing clear conversational thread information
improves LLM coding performance and underscores the heavy reliance of
downstream analysis on well-structured dialogue. We also discuss practical
trade-offs in time and cost, emphasizing where human-AI hybrid approaches can
yield the best value. Together, this work advances methods for combining LLMs
and robust conversational thread structures to make sense of complex, real-time
group interactions.

</details>


### [69] [Once Upon an Input: Reasoning via Per-Instance Program Synthesis](https://arxiv.org/abs/2510.22849)
*Adam Stein,Neelay Velingker,Mayur Naik,Eric Wong*

Main category: cs.CL

TL;DR: PIPS方法通过实例级程序合成和结构性反馈，提升了大语言模型在复杂推理任务中的表现，显著优于CoT和PoT。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维(CoT)和程序思维(PoT)方法虽提高了LLM的推理能力，但在算法任务中仍产生大量不理想解。

Method: 提出PIPS方法，基于结构反馈在实例级生成和优化程序，且引入置信度指标动态选择直接推理或程序合成。

Result: 在包括BBEH等30个基准测试中，PIPS提升了最高8.6%-9.4%的准确率，且算法任务中不良程序生成减少65.1%。

Conclusion: PIPS显著改进了复杂多步骤推理的效果，减少了错误程序生成，提升了LLM的实际应用性能。

Abstract: Large language models (LLMs) excel at zero-shot inference but continue to
struggle with complex, multi-step reasoning. Recent methods that augment LLMs
with intermediate reasoning steps such as Chain of Thought (CoT) and Program of
Thought (PoT) improve performance but often produce undesirable solutions,
especially in algorithmic domains. We introduce Per-Instance Program Synthesis
(PIPS), a method that generates and refines programs at the instance-level
using structural feedback without relying on task-specific guidance or explicit
test cases. To further improve performance, PIPS incorporates a confidence
metric that dynamically chooses between direct inference and program synthesis
on a per-instance basis. Experiments across three frontier LLMs and 30
benchmarks including all tasks of Big Bench Extra Hard (BBEH), visual question
answering tasks, relational reasoning tasks, and mathematical reasoning tasks
show that PIPS improves the absolute harmonic mean accuracy by up to 8.6% and
9.4% compared to PoT and CoT respectively, and reduces undesirable program
generations by 65.1% on the algorithmic tasks compared to PoT with
Gemini-2.0-Flash.

</details>


### [70] [Far from the Shallow: Brain-Predictive Reasoning Embedding through Residual Disentanglement](https://arxiv.org/abs/2510.22860)
*Linyang He,Tianjun Zhong,Richard Antonello,Gavin Mischler,Micah Goldblum,Nima Mesgarani*

Main category: cs.CL

TL;DR: 本文提出了一种残差解缠方法，将语言模型的内在表征拆分为词汇、句法、语义与推理四个正交向量，用于分析大脑语言处理过程。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型的表征高度“纠缠”，混合了词汇、句法、语义和推理信息，使得难以分离大脑中高级认知过程的神经机制。

Method: 通过探测语言模型中特定层识别不同语言特征，逐步回归剔除低级表征，得到四个正交的词汇、句法、语义和推理嵌入向量，再用这些解缠后的向量来建模颅内脑电（ECoG）数据。

Result: 推理嵌入向量能独立预测神经活动变化，尤其是在视觉区域超出经典语言区，与词汇、句法和语义相关信号相比，其神经活动峰值时间更晚（350-400ms），证明了推理作为高级处理的独立神经基础。而未解缠的语言模型向量主要体现语言浅层特征，掩盖了高级认知过程贡献。

Conclusion: 残差解缠方法有效分离语言模型中不同认知层级的表征，揭示了推理在大脑语言处理中的独特神经特征，避免了传统编码分析被浅层语言特征掩盖的局限。

Abstract: Understanding how the human brain progresses from processing simple
linguistic inputs to performing high-level reasoning is a fundamental challenge
in neuroscience. While modern large language models (LLMs) are increasingly
used to model neural responses to language, their internal representations are
highly "entangled," mixing information about lexicon, syntax, meaning, and
reasoning. This entanglement biases conventional brain encoding analyses toward
linguistically shallow features (e.g., lexicon and syntax), making it difficult
to isolate the neural substrates of cognitively deeper processes. Here, we
introduce a residual disentanglement method that computationally isolates these
components. By first probing an LM to identify feature-specific layers, our
method iteratively regresses out lower-level representations to produce four
nearly orthogonal embeddings for lexicon, syntax, meaning, and, critically,
reasoning. We used these disentangled embeddings to model intracranial (ECoG)
brain recordings from neurosurgical patients listening to natural speech. We
show that: 1) This isolated reasoning embedding exhibits unique predictive
power, accounting for variance in neural activity not explained by other
linguistic features and even extending to the recruitment of visual regions
beyond classical language areas. 2) The neural signature for reasoning is
temporally distinct, peaking later (~350-400ms) than signals related to
lexicon, syntax, and meaning, consistent with its position atop a processing
hierarchy. 3) Standard, non-disentangled LLM embeddings can be misleading, as
their predictive success is primarily attributable to linguistically shallow
features, masking the more subtle contributions of deeper cognitive processing.

</details>


### [71] [Interpreting and Mitigating Unwanted Uncertainty in LLMs](https://arxiv.org/abs/2510.22866)
*Tiasa Singha Roy,Ayush Rajesh Jhaveri,Ilias Triantafyllopoulos*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型中令人困扰的不确定性现象，提出通过识别并屏蔽特定注意力头以减少答案翻转。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在回答问题时存在不稳定性，导致相同问题多次回答时出现正确转错误，影响模型可信度。

Method: 采用‘针灭大海’检索框架，结合‘翻转式’再评估提示，模拟答案翻转场景，定位并掩盖与误导性令牌相关的非检索注意力头。

Result: 屏蔽部分非检索注意力头能够显著减少答案翻转现象，最多减少15%，且不会引起语义混乱或过度修正。

Conclusion: 本文揭示了模型不确定性的内部机制，提出一种简单有效的方法缓解大语言模型中的不确定性失败模式，有助于提升模型的可靠性。

Abstract: Despite their impressive capabilities, Large Language Models (LLMs) exhibit
unwanted uncertainty, a phenomenon where a model changes a previously correct
answer into an incorrect one when re-prompted. This behavior undermines trust
and poses serious risks in high-stakes domains. In this work, we investigate
the mechanisms that drive this phenomenon. We adapt the Needle-in-a-Haystack
retrieval framework and integrate a Flip-style re-evaluation prompt to simulate
realistic answer-flipping scenarios. We find that retrieval heads are not
primarily responsible for avoiding uncertainty. Instead, we identify a small
set of non-retrieval attention heads that disproportionately attend to
misleading tokens in uncertain contexts. Masking these heads yields significant
improvements, reducing flip behavior by up to 15% without introducing
incoherence or overcorrection. However, when tested for downstream tasks, we
observe trade-offs with flip behavior. Our findings contribute to the growing
field of mechanistic interpretability and present a simple yet effective
technique for mitigating uncertainty-driven failure modes in LLMs.

</details>


### [72] [A Comprehensive Dataset for Human vs. AI Generated Text Detection](https://arxiv.org/abs/2510.22874)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Amit Sheth,Vasu Sharma,Aishwarya Naresh Reganti,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 本论文介绍了一个包含超过58,000条文本样本的数据集，结合了真实的纽约时报文章和多个先进大语言模型生成的合成文本，用于推动AI生成文本检测与归因技术的发展。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型生成文本越来越接近人类写作，导致内容真实性和可信度问题凸显，需要大规模多样化的标注数据来辅助检测和归因。

Method: 构建包含人类撰写和多款领先大语言模型（如Gemma-2-9b、Mistral-7B、GPT-4-o等）生成文本的数据集，并以原始文章摘要为提示，提供完整的人类叙述文本。

Result: 基线任务中区分人类与AI文本的准确率为58.35%，将AI文本归因到具体生成模型的准确率为8.92%。

Conclusion: 该数据集连接了真实新闻内容与现代生成模型，有助于发展更强大的AI文本检测及归因方法，促进生成式AI时代的信任与透明度。

Abstract: The rapid advancement of large language models (LLMs) has led to increasingly
human-like AI-generated text, raising concerns about content authenticity,
misinformation, and trustworthiness. Addressing the challenge of reliably
detecting AI-generated text and attributing it to specific models requires
large-scale, diverse, and well-annotated datasets. In this work, we present a
comprehensive dataset comprising over 58,000 text samples that combine
authentic New York Times articles with synthetic versions generated by multiple
state-of-the-art LLMs including Gemma-2-9b, Mistral-7B, Qwen-2-72B, LLaMA-8B,
Yi-Large, and GPT-4-o. The dataset provides original article abstracts as
prompts, full human-authored narratives. We establish baseline results for two
key tasks: distinguishing human-written from AI-generated text, achieving an
accuracy of 58.35\%, and attributing AI texts to their generating models with
an accuracy of 8.92\%. By bridging real-world journalistic content with modern
generative models, the dataset aims to catalyze the development of robust
detection and attribution methods, fostering trust and transparency in the era
of generative AI. Our dataset is available at:
https://huggingface.co/datasets/gsingh1-py/train.

</details>


### [73] [Batch Speculative Decoding Done Right](https://arxiv.org/abs/2510.22876)
*Ranran Haoran Zhang,Soumik Dey,Ashirbad Mishra,Hansi Wu,Binbin Li,Rui Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种面向批处理的推测解码方法EXSPEC，有效解决了批处理中的ragged tensor问题，实现了推测解码的正确性和加速。


<details>
  <summary>Details</summary>
Motivation: 推测解码可加速大语言模型推理，但批处理时会出现ragged tensor问题，导致位置ID和注意力掩码混乱，破坏输出一致性。现有方法未能保证输出等效性。

Method: 提出了同步机制保障正确性，设计了正确性优先的批处理推测解码EQSPEC，发现重新对齐开销大，进而引入EXSPEC通过滑动池和动态分组减少开销，同时保持每序列加速效果。

Result: 在SpecBench数据集上，EXSPEC在多种模型对比下实现了批大小8时相比批大小1可达到最高3倍吞吐量提升，并保持95%的输出等效性，且无需自定义内核，易集成。

Conclusion: EXSPEC有效解决了批处理推测解码中的关键问题，实现了高效且正确的推断加速，推动了推测解码技术在生产环境中的应用。

Abstract: Speculative decoding speeds up LLM inference by using a small draft model to
propose multiple tokens that a target model verifies in parallel. Extending
this idea to batches is essential for production serving, but it introduces the
ragged tensor problem: sequences in the same batch accept different numbers of
draft tokens, breaking right-alignment and corrupting position IDs, attention
masks, and KV-cache state. We show that several existing batch implementations
violate output equivalence-the fundamental requirement that speculative
decoding must produce identical token sequences to standard autoregressive
generation. These violations occur precisely due to improper handling of the
ragged tensor problem. In response, we (1) characterize the synchronization
requirements that guarantee correctness, (2) present a correctness-first batch
speculative decoding EQSPEC that exposes realignment as consuming 40% of
overhead, and (3) introduce EXSPEC, which maintains a sliding pool of sequences
and dynamically forms same-length groups, to reduce the realignment overhead
while preserving per-sequence speculative speedups. On the SpecBench dataset,
across Vicuna-7B/68M, Qwen3-8B/0.6B, and GLM-4-9B/0.6B target/draft pairs, our
approach achieves up to 3$\times$ throughput improvement at batch size 8
compared to batch size 1, with efficient scaling through batch size 8, while
maintaining 95% output equivalence. Our method requires no custom kernels and
integrates cleanly with existing inference stacks. Our code is available at
https://github.com/eBay/spec_dec.

</details>


### [74] [Artificial Hivemind: The Open-Ended Homogeneity of Language Models (and Beyond)](https://arxiv.org/abs/2510.22954)
*Liwei Jiang,Yuanjun Chai,Margaret Li,Mickel Liu,Raymond Fok,Nouha Dziri,Yulia Tsvetkov,Maarten Sap,Alon Albalak,Yejin Choi*

Main category: cs.CL

TL;DR: 本文提出了Infinity-Chat，一个包含26K多样开放用户查询的大规模数据集，用于评估语言模型生成的多样性和创造力。通过该数据集，研究揭示了语言模型在开放式生成任务中存在的“人工蜂群效应”，即单模型内重复生成相似内容且不同模型间输出趋同现象。并且利用了丰富的人类注释数据，分析了人类偏好与模型生成之间的差异。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型难以生成多样化和富有创意的内容，且缺少有效的大规模方法来评估模型输出的多样性，尤其是在开放式任务中。为了解决这些问题，论文提出了一个覆盖广泛开放式查询的多样化数据集，旨在系统研究语言模型生成的多样性和模式崩溃问题。

Method: 构建了包含26K开放式用户查询的Infinity-Chat数据集，并设计了包含6个顶级类别和17个子类别的全面任务分类系统。利用该数据集，开展大规模研究，分析语言模型的模式崩溃，特别是模型内重复和模型间同质性现象。同时收集了3万多条人类评级和偏好注释，以研究人类对模型输出的多样性和个体差异偏好。

Result: 研究发现语言模型在开放式生成中存在明显的“人工蜂群效应”，表现为单模型反复生成相似回答，以及不同模型生成输出高度相似。语言模型、奖励模型和评价模型在人类对不同个体偏好回应的校准上存在不足，虽然整体质量相近。

Conclusion: Infinity-Chat作为第一个大规模开放查询数据集，为系统研究语言模型输出多样性提供了重要资源。研究揭示了人工蜂群效应带来的长期安全风险，提示未来研究需关注并缓解语言模型输出的高度同质化问题。

Abstract: Language models (LMs) often struggle to generate diverse, human-like creative
content, raising concerns about the long-term homogenization of human thought
through repeated exposure to similar outputs. Yet scalable methods for
evaluating LM output diversity remain limited, especially beyond narrow tasks
such as random number or name generation, or beyond repeated sampling from a
single model. We introduce Infinity-Chat, a large-scale dataset of 26K diverse,
real-world, open-ended user queries that admit a wide range of plausible
answers with no single ground truth. We introduce the first comprehensive
taxonomy for characterizing the full spectrum of open-ended prompts posed to
LMs, comprising 6 top-level categories (e.g., brainstorm & ideation) that
further breaks down to 17 subcategories. Using Infinity-Chat, we present a
large-scale study of mode collapse in LMs, revealing a pronounced Artificial
Hivemind effect in open-ended generation of LMs, characterized by (1)
intra-model repetition, where a single model consistently generates similar
responses, and more so (2) inter-model homogeneity, where different models
produce strikingly similar outputs. Infinity-Chat also includes 31,250 human
annotations, across absolute ratings and pairwise preferences, with 25
independent human annotations per example. This enables studying collective and
individual-specific human preferences in response to open-ended queries. Our
findings show that LMs, reward models, and LM judges are less well calibrated
to human ratings on model generations that elicit differing idiosyncratic
annotator preferences, despite maintaining comparable overall quality. Overall,
INFINITY-CHAT presents the first large-scale resource for systematically
studying real-world open-ended queries to LMs, revealing critical insights to
guide future research for mitigating long-term AI safety risks posed by the
Artificial Hivemind.

</details>


### [75] [Tagging-Augmented Generation: Assisting Language Models in Finding Intricate Knowledge In Long Contexts](https://arxiv.org/abs/2510.22956)
*Anwesan Pal,Karen Hovsepian,Tinghao Guo,Mengnan Zhao,Somendra Tripathi,Nikos Kanakaris,George Mihaila,Sumit Nigam*

Main category: cs.CL

TL;DR: 提出了一种名为Tagging-Augmented Generation（TAG）的轻量级数据增强方法，提升大语言模型在长上下文问答和推理中的表现，无需复杂预处理。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理长且复杂的上下文时，问答和推理效果有限，且现有的检索增强方法依赖复杂的预处理和检索策略，存在敏感性及成本问题。

Method: 设计TAG方法，通过对上下文添加标签或在QA提示中加入标签定义，增强模型对长上下文信息的理解和利用，避免改变文档结构。

Result: 在NoLima和NovelQA两个挑战性问答基准上，TAG实现了显著提升，最高提升达32K token上下文场景的17%，多跳复杂推理提升2.9%。

Conclusion: TAG是一个简单高效的数据增强策略，能显著提升大语言模型在长上下文和复杂推理场景下的性能，且不影响原文档完整性和构成。

Abstract: Recent investigations into effective context lengths of modern flagship large
language models (LLMs) have revealed major limitations in effective question
answering (QA) and reasoning over long and complex contexts for even the
largest and most impressive cadre of models. While approaches like
retrieval-augmented generation (RAG) and chunk-based re-ranking attempt to
mitigate this issue, they are sensitive to chunking, embedding and retrieval
strategies and models, and furthermore, rely on extensive pre-processing,
knowledge acquisition and indexing steps. In this paper, we propose
Tagging-Augmented Generation (TAG), a lightweight data augmentation strategy
that boosts LLM performance in long-context scenarios, without degrading and
altering the integrity and composition of retrieved documents. We validate our
hypothesis by augmenting two challenging and directly relevant
question-answering benchmarks -- NoLima and NovelQA -- and show that tagging
the context or even just adding tag definitions into QA prompts leads to
consistent performance gains over the baseline -- up to 17% for 32K token
contexts, and 2.9% in complex reasoning question-answering for multi-hop
queries requiring knowledge across a wide span of text. Additional details are
available at https://sites.google.com/view/tag-emnlp.

</details>


### [76] [MAD-Fact: A Multi-Agent Debate Framework for Long-Form Factuality Evaluation in LLMs](https://arxiv.org/abs/2510.22967)
*Yucheng Ning,Xixun Lin,Fang Fang,Yanan Cao*

Main category: cs.CL

TL;DR: 本文提出了一种系统方法评估大型语言模型在长文本生成中的事实准确性，构建了中文长文本事实性数据集LongHalluQA，开发了多智能体验证系统MAD-Fact，并引入了事实重要性层次，实现了长文本事实性的有效评估和提升。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，特别是在生物医药、法律、教育等高风险领域，输出内容的事实准确性成为一个关键问题。现有短文本评估方法难以应对长文本中的复杂推理和多样观点，亟需新的长文本事实性评估手段。

Method: 本文构建了长文本事实性中文数据集LongHalluQA，设计了基于辩论的多智能体验证系统MAD-Fact，并引入事实重要性层次权重，使得评估更加精准。通过多维度验证机制确保对长文本复杂信息的多角度审查。

Result: 实验结果表明，大型LLM通常在事实一致性上表现更优，且国产模型在中文内容上表现突出。所提方法能有效捕捉长文本中的事实信息，提高评估的准确性和鲁棒性。

Conclusion: 本文提出的框架为长文本语言模型的事实性评估提供了系统化方法，有助于提升模型输出的事实可靠性，支持其在敏感领域的安全应用与部署。

Abstract: The widespread adoption of Large Language Models (LLMs) raises critical
concerns about the factual accuracy of their outputs, especially in high-risk
domains such as biomedicine, law, and education. Existing evaluation methods
for short texts often fail on long-form content due to complex reasoning
chains, intertwined perspectives, and cumulative information. To address this,
we propose a systematic approach integrating large-scale long-form datasets,
multi-agent verification mechanisms, and weighted evaluation metrics. We
construct LongHalluQA, a Chinese long-form factuality dataset; and develop
MAD-Fact, a debate-based multi-agent verification system. We introduce a fact
importance hierarchy to capture the varying significance of claims in long-form
texts. Experiments on two benchmarks show that larger LLMs generally maintain
higher factual consistency, while domestic models excel on Chinese content. Our
work provides a structured framework for evaluating and enhancing factual
reliability in long-form LLM outputs, guiding their safe deployment in
sensitive domains.

</details>


### [77] [Measuring Teaching with LLMs](https://arxiv.org/abs/2510.22968)
*Michael Hardy*

Main category: cs.CL

TL;DR: 本论文提出了一种基于句子级嵌入的定制大型语言模型，用于衡量课堂教学质量，取得了超越人类评测者的表现，并验证了模型与教师价值增益测量的相关性。


<details>
  <summary>Details</summary>
Motivation: 教育中客观且可扩展地测量教学质量一直具有挑战性，现有通用大型语言模型难以可靠地应用复杂的课堂观察工具。

Method: 采用句子级嵌入结构构建定制大型语言模型，系统评估五种不同的句子嵌入方法，在防止过拟合的数据高效训练下实现模型优化。并通过注释上下文窗口分析模型对课堂特征的归因能力。

Result: 定制模型实现了超过0.65的人类专家评分相关性，超过平均人类评分者之间的相关度；模型更倾向将评分差异归因于整节课特征而非单句；模型汇总得分与教师价值增益呈现相关性。

Conclusion: 该研究提出了一种有效且强大的AI驱动教学质量测量方法，为教师发展提供了可扩展、可靠且有效的反馈路径，但模型尚未完全实现个别项目层面的泛化。

Abstract: Objective and scalable measurement of teaching quality is a persistent
challenge in education. While Large Language Models (LLMs) offer potential,
general-purpose models have struggled to reliably apply complex, authentic
classroom observation instruments. This paper uses custom LLMs built on
sentence-level embeddings, an architecture better suited for the long-form,
interpretive nature of classroom transcripts than conventional subword
tokenization. We systematically evaluate five different sentence embeddings
under a data-efficient training regime designed to prevent overfitting. Our
results demonstrate that these specialized models can achieve human-level and
even super-human performance with expert human ratings above 0.65 and
surpassing the average human-human rater correlation. Further, through analysis
of annotation context windows, we find that more advanced models-those better
aligned with human judgments-attribute a larger share of score variation to
lesson-level features rather than isolated utterances, challenging the
sufficiency of single-turn annotation paradigms. Finally, to assess external
validity, we find that aggregate model scores align with teacher value-added
measures, indicating they are capturing features relevant to student learning.
However, this trend does not hold at the individual item level, suggesting that
while the models learn useful signals, they have not yet achieved full
generalization. This work establishes a viable and powerful new methodology for
AI-driven instructional measurement, offering a path toward providing scalable,
reliable, and valid feedback for educator development.

</details>


### [78] [Understanding In-Context Learning Beyond Transformers: An Investigation of State Space and Hybrid Architectures](https://arxiv.org/abs/2510.23006)
*Shenran Wang,Timothy Tin-Long Tse,Jian Zhu*

Main category: cs.CL

TL;DR: 本文深入评估了不同架构的大型语言模型在知识型上下文学习任务中的表现，发现不同模型内部机制存在差异。


<details>
  <summary>Details</summary>
Motivation: 致力于揭示不同架构的大型语言模型在上下文学习任务中表现相似但内部机制不同的原因。

Method: 结合行为探测和干预方法，对变换器、状态空间及混合型大型语言模型进行深入分析。

Result: 发现上下文学习的功能向量主要位于自注意力层和Mamba层，Mamba2可能使用不同机制；功能向量对参数知识检索更重要，对上下文知识理解影响较小。

Conclusion: 研究丰富了不同模型架构和任务类型下对上下文学习机制的理解，强调行为与机制分析的结合重要性。

Abstract: We perform in-depth evaluations of in-context learning (ICL) on
state-of-the-art transformer, state-space, and hybrid large language models
over two categories of knowledge-based ICL tasks. Using a combination of
behavioral probing and intervention-based methods, we have discovered that,
while LLMs of different architectures can behave similarly in task performance,
their internals could remain different. We discover that function vectors (FVs)
responsible for ICL are primarily located in the self-attention and Mamba
layers, and speculate that Mamba2 uses a different mechanism from FVs to
perform ICL. FVs are more important for ICL involving parametric knowledge
retrieval, but not for contextual knowledge understanding. Our work contributes
to a more nuanced understanding across architectures and task types.
Methodologically, our approach also highlights the importance of combining both
behavioural and mechanistic analyses to investigate LLM capabilities.

</details>


### [79] [LangLingual: A Personalised, Exercise-oriented English Language Learning Tool Leveraging Large Language Models](https://arxiv.org/abs/2510.23011)
*Sammriddh Gupta,Sonit Singh,Aditya Joshi,Mira Kim*

Main category: cs.CL

TL;DR: LangLingual是一个基于大语言模型的对话代理，专注于实时语法反馈、生成情境语言练习及学习者进度追踪，提升了语言学习体验。


<details>
  <summary>Details</summary>
Motivation: 语言教育者希望为学习者提供丰富的学习体验，但在反馈和练习的数量上受到限制。

Method: 设计并实现了基于LangChain框架和大语言模型的LangLingual，提供实时语法反馈、生成情景练习，并持续追踪学习者能力。

Result: 系统表现出良好的可用性、积极的学习效果和学习者高度参与。

Conclusion: LangLingual有效增强了语言学习的互动性和反馈质量，支持了学习者的持续进步。

Abstract: Language educators strive to create a rich experience for learners, while
they may be restricted in the extend of feedback and practice they can provide.
We present the design and development of LangLingual, a conversational agent
built using the LangChain framework and powered by Large Language Models. The
system is specifically designed to provide real-time, grammar-focused feedback,
generate context-aware language exercises and track learner proficiency over
time. The paper discusses the architecture, implementation and evaluation of
LangLingual in detail. The results indicate strong usability, positive learning
outcomes and encouraging learner engagement.

</details>


### [80] [Incentivizing Agentic Reasoning in LLM Judges via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2510.23038)
*Ran Xu,Jingjing Chen,Jiayu Ye,Yu Wu,Jun Yan,Carl Yang,Hongkun Yu*

Main category: cs.CL

TL;DR: 本文提出了TIR-Judge，一种结合代码执行器的强化学习框架，用于训练大语言模型评判器，提升了评判准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型评判器仅依赖文本推理，难以验证复杂约束和精确计算，亟需引入工具辅助推理提升评判能力。

Method: 提出TIR-Judge框架，结合代码执行器进行精确计算，采用多样化训练域、灵活评判格式和迭代强化学习进行端到端训练；实现无需蒸馏数据的自我进化。

Result: 在七个公开基准测试中，TIR-Judge在点对点和成对评判上分别提升6.4%和7.7%，在列表评判上与性能强大的Claude-Opus-4相当，参数量仅8B。

Conclusion: 工具增强的评判器通过迭代强化学习能够自我进化，显著提升评判性能，展现了结合代码执行器的潜力和优势。

Abstract: Large Language Models (LLMs) are widely used as judges to evaluate response
quality, providing a scalable alternative to human evaluation. However, most
LLM judges operate solely on intrinsic text-based reasoning, limiting their
ability to verify complex constraints or perform accurate computation.
Motivated by the success of tool-integrated reasoning (TIR) in numerous tasks,
we propose TIR-Judge, an end-to-end RL framework for training LLM judges that
integrates a code executor for precise evaluation. TIR-Judge is built on three
principles: (i) diverse training across verifiable and non-verifiable domains,
(ii) flexible judgment formats (pointwise, pairwise, listwise), and (iii)
iterative RL that bootstraps directly from the initial model without
distillation. On seven public benchmarks, TIR-Judge surpasses strong
reasoning-based judges by up to 6.4% (pointwise) and 7.7% (pairwise), and
achieves listwise performance comparable to Claude-Opus-4 despite having only
8B parameters. Remarkably, TIR-Judge-Zero - trained entirely without distilled
judge trajectories, matches the performance of distilled variants,
demonstrating that tool-augmented judges can self-evolve through iterative
reinforcement learning.

</details>


### [81] [Knocking-Heads Attention](https://arxiv.org/abs/2510.23052)
*Zhanchao Zhou,Xiaodong Chen,Haoxing Chen,Zhenzhong Lan,Jianguo Li*

Main category: cs.CL

TL;DR: 本文提出了一种改进多头注意力机制的方法——knocking-heads attention (KHA)，通过头间交互提升表示能力，在大规模模型训练中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统多头注意力机制中，头与头之间缺乏有效交互，导致单个头的表达能力减弱，限制了模型性能提升。

Method: KHA通过对所有头应用共享的对角线初始化投影矩阵，促进头与头之间的特征级交互，同时保持头的特异性，且仅增加极少的参数和计算量。

Result: 在训练6.1B参数的MoE模型（激活参数1.01B）上，KHA相较于基线注意力机制展现了更优且更稳定的训练动态，并在下游任务中取得了更好性能。

Conclusion: KHA有效解决了多头注意力中头间孤立的问题，提升了模型表达能力和性能，且易于集成到现有多头注意力变体中。

Abstract: Multi-head attention (MHA) has become the cornerstone of modern large
language models, enhancing representational capacity through parallel attention
heads. However, increasing the number of heads inherently weakens individual
head capacity, and existing attention mechanisms - whether standard MHA or its
variants like grouped-query attention (GQA) and grouped-tied attention (GTA) -
simply concatenate outputs from isolated heads without strong interaction. To
address this limitation, we propose knocking-heads attention (KHA), which
enables attention heads to "knock" on each other - facilitating cross-head
feature-level interactions before the scaled dot-product attention. This is
achieved by applying a shared, diagonally-initialized projection matrix across
all heads. The diagonal initialization preserves head-specific specialization
at the start of training while allowing the model to progressively learn
integrated cross-head representations. KHA adds only minimal parameters and
FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention
variants. We validate KHA by training a 6.1B parameter MoE model (1.01B
activated) on 1T high-quality tokens. Compared to baseline attention
mechanisms, KHA brings superior and more stable training dynamics, achieving
better performance across downstream tasks.

</details>


### [82] [Quality-Aware Translation Tagging in Multilingual RAG system](https://arxiv.org/abs/2510.23070)
*Hoyeon Moon,Byeolhee Kim,Nikhil Verma*

Main category: cs.CL

TL;DR: 本文提出了QTT-RAG方法，通过评估并标注翻译质量的三个维度，提升多语言检索增强生成模型在低资源语言下的响应效果。


<details>
  <summary>Details</summary>
Motivation: 现有多语言检索增强生成方法在低资源语言环境下通过翻译英语文档，但翻译质量差会影响生成性能，且重写方法存在事实扭曲和虚构问题。

Method: QTT-RAG方法对翻译的语义等价性、语法准确性和自然流畅性进行质量评估，并将分数作为元数据附加，不改变原文内容。

Result: 在XORQA和MKQA两大开放域问答数据集及多个大型语言模型上，QTT-RAG相较于CrossRAG和DKM-RAG表现更优，能保持事实完整性并提升生成质量。

Conclusion: QTT-RAG通过显式翻译质量标注，有效利用跨语言文档，尤其适用于低资源语言环境，提供了一种实用且鲁棒的多语言文本生成解决方案。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English
documents and translates them into the query language for low-resource
settings. However, poor translation quality degrades response generation
performance. Existing approaches either assume sufficient translation quality
or utilize the rewriting method, which introduces factual distortion and
hallucinations. To mitigate these problems, we propose Quality-Aware
Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation
quality along three dimensions-semantic equivalence, grammatical accuracy, and
naturalness&fluency-and attach these scores as metadata without altering the
original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines
in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs
ranging from 2.4B to 14B parameters, covering two low-resource languages
(Korean and Finnish) and one high-resource language (Chinese). QTT-RAG
outperforms the baselines by preserving factual integrity while enabling
generator models to make informed decisions based on translation reliability.
This approach allows for effective usage of cross-lingual documents in
low-resource settings with limited native language documents, offering a
practical and robust solution across multilingual domains.

</details>


### [83] [A Survey on LLM Mid-training](https://arxiv.org/abs/2510.23081)
*Chengying Tu,Xuemiao Zhang,Rongxiang Weng,Rumei Li,Chen Zhang,Yang Bai,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 本文综述了大语言模型中的中期训练阶段，强调其在预训练与后训练之间的桥梁作用及其对模型能力提升的重要性。


<details>
  <summary>Details</summary>
Motivation: 中期训练作为一个独立阶段，利用中间数据和计算资源，系统性地提升模型在数学、编码、推理及长文本处理等方面的能力，同时保持基础能力。

Method: 通过定义中期训练，调研数据整理、训练策略和模型架构优化的优化框架，分析主流模型的目标驱动干预，展示中期训练在LLM能力进化中的关键作用。

Result: 明确中期训练区别于其他训练阶段的独特贡献，构建了全面的分类体系和可操作的见解，支持未来大语言模型的发展研究。

Conclusion: 中期训练是大语言模型能力进化的关键环节，本文为其提供了系统定义和优化指导，促进相关领域的研究和创新。

Abstract: Recent advances in foundation models have highlighted the significant
benefits of multi-stage training, with a particular emphasis on the emergence
of mid-training as a vital stage that bridges pre-training and post-training.
Mid-training is distinguished by its use of intermediate data and computational
resources, systematically enhancing specified capabilities such as mathematics,
coding, reasoning, and long-context extension, while maintaining foundational
competencies. This survey provides a formal definition of mid-training for
large language models (LLMs) and investigates optimization frameworks that
encompass data curation, training strategies, and model architecture
optimization. We analyze mainstream model implementations in the context of
objective-driven interventions, illustrating how mid-training serves as a
distinct and critical stage in the progressive development of LLM capabilities.
By clarifying the unique contributions of mid-training, this survey offers a
comprehensive taxonomy and actionable insights, supporting future research and
innovation in the advancement of LLMs.

</details>


### [84] [MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting with Large Language Models](https://arxiv.org/abs/2510.23090)
*Suchan Lee,Jihoon Choi,Sohyeon Lee,Minseok Song,Bong-Gyu Jang,Hwanjo Yu,Soyeon Caren Han*

Main category: cs.CL

TL;DR: 本文提出了MAP4TS，一种多方面提示框架，将经典时间序列分析融入大语言模型的预测中，提升了多数据集上的预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法忽视了时间序列的统计特性和时间依赖性，导致预训练大语言模型在时间序列预测中的表现受限。

Method: 设计四种专门提示组件：全局领域提示、本地领域提示、统计提示和时间提示，将传统统计分析（ACF、PACF、傅里叶分析）结果融入到提示中，结合跨模态对齐模块和大语言模型进行统一表示和预测。

Result: 在八个多样化数据集上，MAP4TS稳定优于现有最先进的基于大语言模型的方法；消融实验显示提示设计显著提升性能稳定性，小型GPT-2结合结构化提示在长期预测中优于大模型LLaMA。

Conclusion: 通过多方面融合传统时间序列分析的提示设计，MAP4TS有效增强了大语言模型在时间序列预测任务上的性能和稳定性，具有良好应用前景。

Abstract: Recent advances have investigated the use of pretrained large language models
(LLMs) for time-series forecasting by aligning numerical inputs with LLM
embedding spaces. However, existing multimodal approaches often overlook the
distinct statistical properties and temporal dependencies that are fundamental
to time-series data. To bridge this gap, we propose MAP4TS, a novel
Multi-Aspect Prompting Framework that explicitly incorporates classical
time-series analysis into the prompt design. Our framework introduces four
specialized prompt components: a Global Domain Prompt that conveys
dataset-level context, a Local Domain Prompt that encodes recent trends and
series-specific behaviors, and a pair of Statistical and Temporal Prompts that
embed handcrafted insights derived from autocorrelation (ACF), partial
autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined
with raw time-series embeddings and passed through a cross-modality alignment
module to produce unified representations, which are then processed by an LLM
and projected for final forecasting. Extensive experiments across eight diverse
datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based
methods. Our ablation studies further reveal that prompt-aware designs
significantly enhance performance stability and that GPT-2 backbones, when
paired with structured prompts, outperform larger models like LLaMA in
long-term forecasting tasks.

</details>


### [85] [Leveraging Hierarchical Organization for Medical Multi-document Summarization](https://arxiv.org/abs/2510.23104)
*Yi-Li Hsu,Katelyn X. Mei,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 本论文研究了在医疗多文档摘要任务中引入层级结构，发现其能提升摘要的清晰度及信息组织能力，且模型生成的摘要得到人类专家更高偏好。


<details>
  <summary>Details</summary>
Motivation: 多文档医疗摘要需要有效管理跨文档信息，传统平面摘要方法在信息组织和语境理解方面存在不足。

Method: 研究在三个大型语言模型中融入两种层级结构组织方法，结合自动评估指标、模型评估指标及领域专家评价（偏好、可理解性、清晰度等）进行综合评估。

Result: 层级方法在保持摘要事实准确性、覆盖率与连贯性的同时，提升了人类专家对摘要的偏好；此外，GPT-4的模拟判断在客观评估方面与人类评分较一致。

Conclusion: 引入层级结构的摘要方法能显著提升医疗多文档摘要的内容组织与清晰度，增强人类对自动生成摘要的偏好，具备实用价值。

Abstract: Medical multi-document summarization (MDS) is a complex task that requires
effectively managing cross-document relationships. This paper investigates
whether incorporating hierarchical structures in the inputs of MDS can improve
a model's ability to organize and contextualize information across documents
compared to traditional flat summarization methods. We investigate two ways of
incorporating hierarchical organization across three large language models
(LLMs), and conduct comprehensive evaluations of the resulting summaries using
automated metrics, model-based metrics, and domain expert evaluation of
preference, understandability, clarity, complexity, relevance, coverage,
factuality, and coherence. Our results show that human experts prefer
model-generated summaries over human-written summaries. Hierarchical approaches
generally preserve factuality, coverage, and coherence of information, while
also increasing human preference for summaries. Additionally, we examine
whether simulated judgments from GPT-4 align with human judgments, finding
higher agreement along more objective evaluation facets. Our findings
demonstrate that hierarchical structures can improve the clarity of medical
summaries generated by models while maintaining content coverage, providing a
practical way to improve human preference for generated summaries.

</details>


### [86] [Flexing in 73 Languages: A Single Small Model for Multilingual Inflection](https://arxiv.org/abs/2510.23114)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 本文提出了一种紧凑的单模型多语言词形变化方法，训练于73种语言，表现优于单语模型，且具备轻量和鲁棒性，支持未见词处理。


<details>
  <summary>Details</summary>
Motivation: 现有多语言词形变化系统多为多模型，管理复杂且对未见词处理能力有限，缺乏通用的开源多语言系统。

Method: 联合训练一个单一模型，覆盖73种语言，使用新的频率加权、词基不重复的训练-验证-测试数据切分策略，以确保数据的现实性和推广性。

Result: 模型在SIGMORPHON和73个UD树库上的评测中超越大多数单语模型，表现稳定且可推广，且代码已开源。

Conclusion: 联合多语言训练简化了部署流程，提高了词形变化的泛化能力，尤其对未见词表现优秀，推动了多语言词形变化的研究与应用。

Abstract: We present a compact, single-model approach to multilingual inflection, the
task of generating inflected word forms from base lemmas to express grammatical
categories. Our model, trained jointly on data from 73 languages, is
lightweight, robust to unseen words, and outperforms monolingual baselines in
most languages. This demonstrates the effectiveness of multilingual modeling
for inflection and highlights its practical benefits: simplifying deployment by
eliminating the need to manage and retrain dozens of separate monolingual
models. In addition to the standard SIGMORPHON shared task benchmarks, we
evaluate our monolingual and multilingual models on 73 Universal Dependencies
(UD) treebanks, extracting lemma-tag-form triples and their frequency counts.
To ensure realistic data splits, we introduce a novel frequency-weighted,
lemma-disjoint train-dev-test resampling procedure. Our work addresses the lack
of an open-source, general-purpose, multilingual morphological inflection
system capable of handling unseen words across a wide range of languages,
including Czech. All code is publicly released at:
https://github.com/tomsouri/multilingual-inflection.

</details>


### [87] [Beyond Higher Rank: Token-wise Input-Output Projections for Efficient Low-Rank Adaptation](https://arxiv.org/abs/2510.23123)
*Shiwei Li,Xiandi Luo,Haozhao Wang,Xing Tang,Ziqiang Cui,Dugang Liu,Yuhua Li,Xiuqiang He,Ruixuan Li*

Main category: cs.CL

TL;DR: 本文提出了一种新的低秩自适应方法TopLoRA，通过根据输入token动态调整LoRA权重，实现token级别的输入输出映射，从而提升模型微调效果。


<details>
  <summary>Details</summary>
Motivation: 标准LoRA对所有输入token使用相同权重，难以捕捉token的语义差异，限制了微调的细粒度能力。

Method: TopLoRA引入了一个对角矩阵\(\Sigma_X\)，对每个输入token生成动态权重，使LoRA权重表达为\(B\Sigma_X A\)，实现token级自适应，同时保持低秩结构。

Result: 在多个模型和数据集上的广泛实验表明，TopLoRA持续优于标准LoRA及其变体。

Conclusion: TopLoRA通过动态调整权重实现了更细粒度的自适应，提升了PEFT方法在大语言模型微调中的表现。

Abstract: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method
widely used in large language models (LLMs). LoRA essentially describes the
projection of an input space into a low-dimensional output space, with the
dimensionality determined by the LoRA rank. In standard LoRA, all input tokens
share the same weights and undergo an identical input-output projection. This
limits LoRA's ability to capture token-specific information due to the inherent
semantic differences among tokens. To address this limitation, we propose
Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts
LoRA weights according to the input token, thereby learning token-wise
input-output projections in an end-to-end manner. Formally, the weights of
TopLoRA can be expressed as $B\Sigma_X A$, where $A$ and $B$ are low-rank
matrices (as in standard LoRA), and $\Sigma_X$ is a diagonal matrix generated
from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA
weights but achieves more granular adaptation by learning token-wise LoRA
weights (i.e., token-wise input-output projections). Extensive experiments
across multiple models and datasets demonstrate that TopLoRA consistently
outperforms LoRA and its variants. The code is available at
https://github.com/Leopold1423/toplora-neurips25.

</details>


### [88] [Corpus Frequencies in Morphological Inflection: Do They Matter?](https://arxiv.org/abs/2510.23131)
*Tomáš Sourada,Jana Straková*

Main category: cs.CL

TL;DR: 该论文提出在形态词变形任务中引入词频信息，通过频率加权的训练、评估和数据划分方法，提高模型在真实文本中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统形态词变形方法忽略词频分布，而实际用户输入中词频分布非常重要，本文旨在利用词频信息提升模型的实际性能。

Method: 提出三方面的频率信息应用：训练-验证-测试的频率加权划分，评估时结合基于频率的token准确率，以及训练数据采样时引入频率感知采样策略。

Result: 频率感知采样在43种语言中超过了传统均匀采样方法的效果，在26种语言表现更优。

Conclusion: 引入词频信息能够显著提升形态词变形模型的表现，尤其在真实文本场景中更具实用价值。

Abstract: The traditional approach to morphological inflection (the task of modifying a
base word (lemma) to express grammatical categories) has been, for decades, to
consider lexical entries of lemma-tag-form triples uniformly, lacking any
information about their frequency distribution. However, in production
deployment, one might expect the user inputs to reflect a real-world
distribution of frequencies in natural texts. With future deployment in mind,
we explore the incorporation of corpus frequency information into the task of
morphological inflection along three key dimensions during system development:
(i) for train-dev-test split, we combine a lemma-disjoint approach, which
evaluates the model's generalization capabilities, with a frequency-weighted
strategy to better reflect the realistic distribution of items across different
frequency bands in training and test sets; (ii) for evaluation, we complement
the standard type accuracy (often referred to simply as accuracy), which treats
all items equally regardless of frequency, with token accuracy, which assigns
greater weight to frequent words and better approximates performance on running
text; (iii) for training data sampling, we introduce a method novel in the
context of inflection, frequency-aware training, which explicitly incorporates
word frequency into the sampling process. We show that frequency-aware training
outperforms uniform sampling in 26 out of 43 languages.

</details>


### [89] [ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix](https://arxiv.org/abs/2510.23160)
*Zile Yang,Ling Li,Na Di,Jinlong Pang,Yao Zhou,Hao Cheng,Bo Han,Jiaheng Wei*

Main category: cs.CL

TL;DR: 本文提出了ENTP方法，通过符号净化和神经重构的方法提升低质量数据的价值，从而增强大模型的指令微调效果。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模语言模型微调方法通常只利用高质量数据，忽略了大量低质量数据中的潜在有用信息，且现有的质量筛选方法不够完善。

Method: ENTP框架结合符号模块和神经模块，符号模块基于统计先验剔除噪声样本，神经模块利用隐含表示和模型知识合成丰富的指令-响应对，实现数据的净化与重构。

Result: 在五个指令跟随基准测试中，ENTP利用仅低质量数据构建的数据集性能优于13个传统数据筛选方法，甚至超过了使用原始完整数据集（约30万样本）的微调效果。

Conclusion: 低质量数据中蕴藏着未被充分利用的潜力，智能的净化与合成方法可以高效提升指令微调的效果，促进大语言模型的指令对齐。

Abstract: Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs)
to domain-specific instructions by training on a carefully curated subset of
high-quality instruction-response pairs, typically drawn from a larger dataset
that often contains many low-quality or noisy samples. However, existing
quality-first paradigms often overlook valuable signals in discarded
low-quality data and rely on imperfect quality filters. We introduce ENTP
(Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a
framework that revitalizes low-quality corpora through symbolic purification
and neural reconstruction. The symbolic module identifies and prunes noisy
samples based on statistical priors, while the neural component synthesizes
enriched instruction-response pairs by leveraging latent representations and
model knowledge. This neural-symbolic synergy enhances data informativeness and
diversity. Experiments show that ENTP-augmented datasets, constructed
exclusively from low-quality data, outperform 13 established data-selection
baselines across five instruction-following benchmarks, and even surpass
fine-tuning on the full original dataset (approximately 300K examples). Our
results highlight the untapped potential of low-quality data and underscore the
importance of intelligent purification and synthesis for efficient instruction
alignment.

</details>


### [90] [Beyond Direct Generation: A Decomposed Approach to Well-Crafted Screenwriting with LLMs](https://arxiv.org/abs/2510.23163)
*Hang Lei,Shengyi Zong,Zhaoyan Li,Ziren Zhou,Hao Liu*

Main category: cs.CL

TL;DR: 本文提出一种双阶段精炼框架（DSR），将剧本创作分为剧情叙述生成和格式转换两个阶段，以提升大型语言模型生成专业级剧本的质量。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型直接生成剧本往往缺乏结构完整性和叙事深度，原因是单一模型难以同时掌握创意叙事和格式规范。

Method: 采用双阶段精炼框架，第一阶段将剧情大纲生成小说式丰富文本，第二阶段将其转化为专业格式剧本；通过混合数据合成技术解决训练数据不足问题。

Result: 专业编剧盲测显示，DSR方法胜率达75%，表现达到人类水平的82.7%，优于多个强基线模型。

Conclusion: 分解生成架构结合定制数据合成，有效提升了大型语言模型在复杂创意文本生成领域的专业化能力。

Abstract: The screenplay serves as the foundation for television production, defining
narrative structure, character development, and dialogue. While Large Language
Models (LLMs) show great potential in creative writing, direct end-to-end
generation approaches often fail to produce well-crafted screenplays. We argue
this failure stems from forcing a single model to simultaneously master two
disparate capabilities: creative narrative construction and rigid format
adherence. The resulting outputs may mimic superficial style but lack the deep
structural integrity and storytelling substance required for professional use.
To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage
Refinement (DSR), a decomposed framework that decouples creative narrative
generation from format conversion. The first stage transforms a brief outline
into rich, novel-style prose. The second stage refines this narrative into a
professionally formatted screenplay. This separation enables the model to
specialize in one distinct capability at each stage. A key challenge in
implementing DSR is the scarcity of paired outline-to-novel training data. We
address this through hybrid data synthesis: reverse synthesis deconstructs
existing screenplays into structured inputs, while forward synthesis leverages
these inputs to generate high-quality narrative texts as training targets.
Blind evaluations by professional screenwriters show that DSR achieves a 75%
win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of
human-level performance. Our work demonstrates that decomposed generation
architecture with tailored data synthesis effectively specializes LLMs in
complex creative domains.

</details>


### [91] [SI-Bench: Benchmarking Social Intelligence of Large Language Models in Human-to-Human Conversations](https://arxiv.org/abs/2510.23182)
*Shuai Huang,Wenxuan Zhao,Jun Gao*

Main category: cs.CL

TL;DR: 本文提出了SI-Bench，一个基于真实人类多轮社交对话构建的社会智能评估基准，用于评测大型语言模型在复杂社会交互中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估多为模拟代理间互动，不足以反映真实人类对话中的语言风格和关系动态，亟需真实数据集来评价大型语言模型的社会智能。

Method: 从社交网络应用收集2,221条真实多轮对话，挑选312条进行手工注释，涵盖8个主流语言模型的测试，同时考察引入推理链（CoT）对模型表现的影响。

Result: 顶尖模型在复杂社会情境的推理过程上优于人类专家，但回复质量仍不及人类；引入推理链反而可能降低模型在社会对话任务中的性能。

Conclusion: SI-Bench基准有效反映了现实社交场景下大型语言模型的能力及不足，公开数据集为社会智能研究提供了重要资源。

Abstract: As large language models (LLMs) develop anthropomorphic abilities, they are
increasingly being deployed as autonomous agents to interact with humans.
However, evaluating their performance in realistic and complex social
interactions remains a significant challenge. Most previous research built
datasets through simulated agent-to-agent interactions, which fails to capture
the authentic linguistic styles and relational dynamics found in real human
conversations. To address this gap, we introduce SI-Bench, a novel benchmark
designed to evaluate aspects of social intelligence in LLMs. Grounded in broad
social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues
collected from a social networking application. We further selected a subset of
312 dialogues for manual annotation across 8 major models. The experiments show
that SOTA models have surpassed the human expert in process reasoning under
complex social situations, yet they still fall behind humans in reply quality.
Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the
performance of LLMs in social dialogue tasks. All datasets are openly available
at https://github.com/SI-Bench/SI-Bench.git.

</details>


### [92] [DREaM: Drug-Drug Relation Extraction via Transfer Learning Method](https://arxiv.org/abs/2510.23189)
*Ali Fata,Hossein Rahmani,Parinaz Soltanzadeh,Amirhossein Derakhshan,Behrouz Minaei Bidgoli*

Main category: cs.CL

TL;DR: 提出了DREAM方法，通过迁移学习和大语言模型验证，实现了从医学文本中药物关系的自动提取与本体构建。


<details>
  <summary>Details</summary>
Motivation: 缺乏专门用于药物间关系抽取的数据集，且传统方法高成本，因此需要利用迁移学习和机器学习技术低成本抽取药物关系。

Method: 先训练关系抽取模型发现药物实体间的关系，再应用模型到医学文本语料库构建药物关系本体，最后用大语言模型验证提取结果。

Result: 用大语言模型验证从PubMed摘要抽取的关系，有71%的关系得到了模型的认可，定性分析显示方法可以揭示医疗领域中的模糊性。

Conclusion: DREAM方法有效实现药物关系的自动抽取和验证，展示了迁移学习与大语言模型结合应用于医学关系抽取领域的潜力和挑战。

Abstract: Relation extraction between drugs plays a crucial role in identifying drug
drug interactions and predicting side effects. The advancement of machine
learning methods in relation extraction, along with the development of large
medical text databases, has enabled the low cost extraction of such relations
compared to other approaches that typically require expert knowledge. However,
to the best of our knowledge, there are limited datasets specifically designed
for drug drug relation extraction currently available. Therefore, employing
transfer learning becomes necessary to apply machine learning methods in this
domain. In this study, we propose DREAM, a method that first employs a trained
relation extraction model to discover relations between entities and then
applies this model to a corpus of medical texts to construct an ontology of
drug relationships. The extracted relations are subsequently validated using a
large language model. Quantitative results indicate that the LLM agreed with 71
of the relations extracted from a subset of PubMed abstracts. Furthermore, our
qualitative analysis indicates that this approach can uncover ambiguities in
the medical domain, highlighting the challenges inherent in relation extraction
in this field.

</details>


### [93] [Process Reward Models for Sentence-Level Verification of LVLM Radiology Reports](https://arxiv.org/abs/2510.23217)
*Alois Thomas,Maya Varma,Jean-Benoit Delbrouck,Curtis P. Langlotz*

Main category: cs.CL

TL;DR: 本文提出了一种基于句子级别的过程奖励模型（PRM）用于检测大型视觉语言模型（LVLM）生成的放射报告中的临床错误，有效提升了错误检测准确率和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有用于检测LVLM生成放射报告中的幻觉错误的方法缺乏句子级的细粒度检测能力，且难以在不同模型之间泛化，存在临床风险。

Method: 设计并训练了一种轻量级的（0.5亿参数）句子级过程奖励模型（PRM），基于临床上下文和前文文本预测生成句子的事实正确性；在MIMIC-CXR数据集上采用弱监督标签进行微调。

Result: PRM相比现有强基线模型在Matthews相关系数提升7.5%，AUROC提升1.8%；在未见过的LVLM模型上也表现出良好的泛化能力。同时，利用PRM分数对低质量报告进行过滤，F1-CheXbert评分提升4.5%，在best-of-N选择策略中分别提升F1-CheXbert 7.4%和BERTScore 0.6%。

Conclusion: 提出的轻量级、上下文感知的句子级PRM提供了一种模型无关的临床安全保障机制，能够有效检测和过滤放射报告中的幻觉错误，提升了LVLM生成报告的临床可靠性。

Abstract: Automating radiology report generation with Large Vision-Language Models
(LVLMs) holds great potential, yet these models often produce clinically
critical hallucinations, posing serious risks. Existing hallucination detection
methods frequently lack the necessary sentence-level granularity or robust
generalization across different LVLM generators. We introduce a novel approach:
a sentence-level Process Reward Model (PRM) adapted for this vision-language
task. Our PRM predicts the factual correctness of each generated sentence,
conditioned on clinical context and preceding text. When fine-tuned on
MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM
outperforms existing verification techniques, demonstrating, for instance,
relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in
AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods
reliant on internal model states, our PRM demonstrates strong generalization to
an unseen LVLM. We further show its practical utility: PRM scores effectively
filter low-quality reports, improving F1-CheXbert scores by 4.5% (when
discarding the worst 10% of reports). Moreover, when guiding a novel weighted
best-of-N selection process on the MIMIC-CXR test set, our PRM show relative
improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for
BERTScore. These results demonstrate that a lightweight, context-aware PRM
provides a model-agnostic safety layer for clinical LVLMs without access to
internal activations

</details>


### [94] [Are ASR foundation models generalized enough to capture features of regional dialects for low-resource languages?](https://arxiv.org/abs/2510.23252)
*Tawsif Tashwar Dipto,Azmol Hossain,Rubayet Sabbir Faruque,Md. Rezuwan Hassan,Kanij Fatema,Tanmoy Shome,Ruwad Naswan,Md. Foriduzzaman Zihad,Mohaymen Ul Anam,Nazia Tasnim,Hasan Mahmud,Md Kamrul Hasan,Md. Mehedi Hasan Shawon,Farig Sadeque,Tahsin Reasat*

Main category: cs.CL

TL;DR: 该论文构建了一个包含78小时带注释的孟加拉语方言语音转文字语料库Ben-10，研究方言差异对自动语音识别(ASR)的影响，发现现有深度学习模型在处理区域方言时表现较差，但针对特定方言的训练能缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 传统语音识别研究主要依赖标准语音模型，区域方言往往被视为微调任务，缺乏对方言差异的深入研究。作者希望探究方言变体对ASR性能的影响，提升低资源语言的方言识别能力。

Method: 构建了78小时的带注释孟加拉语方言语音文本数据集Ben-10，并从语言学和数据驱动视角分析方言对语音基础模型的影响，评估零-shot和微调条件下模型的表现，展示方言特异性模型训练改善效果。

Result: 实验证明大多数深度学习方法难以处理方言变体的语音数据，但通过方言特异性训练可以缓解性能下降。此外，Ben-10数据集也能作为约束资源条件下ASR模型的OOD测试集使用。

Conclusion: 现有语音模型在区域方言ASR任务中存在显著挑战，针对特定方言进行模型训练是有效策略。Ben-10数据集为低资源语言和方言ASR研究提供了重要资源和基准。

Abstract: Conventional research on speech recognition modeling relies on the canonical
form for most low-resource languages while automatic speech recognition (ASR)
for regional dialects is treated as a fine-tuning task. To investigate the
effects of dialectal variations on ASR we develop a 78-hour annotated Bengali
Speech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and
data-driven perspectives shows that speech foundation models struggle heavily
in regional dialect ASR, both in zero-shot and fine-tuned settings. We observe
that all deep learning methods struggle to model speech data under dialectal
variations but dialect specific model training alleviates the issue. Our
dataset also serves as a out of-distribution (OOD) resource for ASR modeling
under constrained resources in ASR algorithms. The dataset and code developed
for this project are publicly available

</details>


### [95] [Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation and User Intent Understanding](https://arxiv.org/abs/2510.23271)
*Mohammed Aljafari,Ismail Alturki,Ahmed Mori,Yehya Kadumi*

Main category: cs.CL

TL;DR: Mubeen是MASARAT SA开发的专有阿拉伯语言模型，专注于阿拉伯语语言学、伊斯兰研究和文化遗产，结合丰富的阿拉伯语原始数据和深度语言工程框架，实现精准的语义理解和用户意图识别。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语模型多依赖英文翻译数据，导致在意图检测和生成结果准确性上表现不佳，且不能充分解决用户的信息需求，存在"效用差距危机"。

Method: 通过数字化历史手稿并引入原创阿拉伯OCR技术，训练包含语言学、法学、圣训及经文解释等领域的丰富阿拉伯语原始材料。核心采用实用闭包架构，结合多学科专家模块，实现深度文化特化与广泛知识处理。

Result: 模型能够精准理解经典文本、当代文献及方言，准确识别用户意图，提供清晰且权威的指导性回答，避免重复提问带来的用户挫败感。

Conclusion: Mubeen不仅是一个信息检索工具，更是一个能有效引导用户决策的智能助理，体现了阿拉伯文化真实性及技术创新，助力实现沙特2030愿景。

Abstract: Mubeen is a proprietary Arabic language model developed by MASARAT SA,
optimized for deep understanding of Arabic linguistics, Islamic studies, and
cultural heritage. Trained on an extensive collection of authentic Arabic
sources significantly expanded by digitizing historical manuscripts via a
proprietary Arabic OCR engine, the model incorporates seminal scholarly works
in linguistics, jurisprudence, hadith, and Quranic exegesis, alongside
thousands of academic theses and peer-reviewed research papers. Conditioned
through a deep linguistic engineering framework, Mubeen masters not just the
meaning but the eloquence of Arabic, enabling precise understanding across
classical texts, contemporary writing, and regional dialects with focus on
comprehending user intent and delivering accurate, contextually relevant
responses. Unlike other Arabic models relying on translated English data that
often fail in intent detection or retrieval-augmented generation (RAG), Mubeen
uses native Arabic sources to ensure cultural authenticity and accuracy. Its
core innovation is the Practical Closure Architecture, designed to solve the
"Utility Gap Crisis" where factually correct answers fail to resolve users'
core needs, forcing them into frustrating cycles of re-prompting. By
prioritizing clarity and decisive guidance, Mubeen transforms from an
information repository into a decisive guide, aligning with Saudi Vision 2030.
The model's architecture combines deep heritage specialization with
multi-disciplinary expert modules, enabling robust performance across both
cultural preservation and general knowledge domains.

</details>


### [96] [Code Aesthetics with Agentic Reward Feedback](https://arxiv.org/abs/2510.23272)
*Bang Xiao,Lingjie Jiang,Shaohan Huang,Tengchao Lv,Yupan Huang,Xun Wu,Lei Cui,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了一种提升大语言模型代码美学质量的新方法，通过构建大规模代码美学数据集AesCode-358K，设计多智能体奖励反馈机制Agentic Reward Feedback，并结合GRPO算法实现功能性和代码美学的联合优化。实验表明，该方法显著提升了代码美学性能，超越了GPT-4系列模型。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在传统编程任务表现优秀，但在视觉导向的代码美学方面表现欠佳，导致生成代码的美观度不足。

Method: 构建AesCode-358K代码美学指令调优数据集，设计多智能体系统评估可执行性、静态美学和交互美学，提出Agentic Reward Feedback奖励机制，结合GRPO算法实现功能和美学的联合优化，同时建立OpenDesign代码美学评测基准。

Result: 通过监督微调和基于Agentic Reward Feedback的强化学习，显著提升了OpenDesign基准上的表现，并在PandasPlotBench等现有基准上取得更好效果。AesCoder-4B模型性能超过GPT-4o和GPT-4.1，性能可媲美参数量规模达480B-685B的大型开源模型。

Conclusion: 结合定制美学数据集、复杂奖励机制和联合优化算法，可有效提升大语言模型生成代码的美学质量，证明了该方法的优越性和潜力。

Abstract: Large Language Models (LLMs) have become valuable assistants for developers
in code-related tasks. While LLMs excel at traditional programming tasks such
as code generation and bug fixing, they struggle with visually-oriented coding
tasks, often producing suboptimal aesthetics. In this paper, we introduce a new
pipeline to enhance the aesthetic quality of LLM-generated code. We first
construct AesCode-358K, a large-scale instruction-tuning dataset focused on
code aesthetics. Next, we propose agentic reward feedback, a multi-agent system
that evaluates executability, static aesthetics, and interactive aesthetics.
Building on this, we develop GRPO-AR, which integrates these signals into the
GRPO algorithm for joint optimization of functionality and code aesthetics.
Finally, we develop OpenDesign, a benchmark for assessing code aesthetics.
Experimental results show that combining supervised fine-tuning on AesCode-358K
with reinforcement learning using agentic reward feedback significantly
improves performance on OpenDesign and also enhances results on existing
benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o
and GPT-4.1, and achieves performance comparable to large open-source models
with 480B-685B parameters, underscoring the effectiveness of our approach.

</details>


### [97] [A Cocktail-Party Benchmark: Multi-Modal dataset and Comparative Evaluation Results](https://arxiv.org/abs/2510.23276)
*Thai-Binh Nguyen,Katerina Zmolikova,Pingchuan Ma,Ngoc Quan Pham,Christian Fuegen,Alexander Waibel*

Main category: cs.CL

TL;DR: MCoRec任务解决单室重叠对话问题，结合音频、视觉与上下文信息，实现多说话者语音识别与对话聚类。


<details>
  <summary>Details</summary>
Motivation: 解决单室内多说话者重叠对话（鸡尾酒会问题），提升语音识别准确度，尤其面对极端语音重叠场景。

Method: 设计MCoRec任务，采集包含音频、视觉和上下文的多方非脚本化自然交谈数据，构建基线系统，比较音频单模态与多模态识别效果。

Result: 音频单模态错误率超100%，加入视觉信息后错误率降低50%，表明多模态信息显著提升识别表现。

Conclusion: 多模态信息对复杂多说话者场景的语音识别至关重要，MCoRec为研究重叠对话识别提供有效平台。

Abstract: We introduce the task of Multi-Modal Context-Aware Recognition (MCoRec) in
the ninth CHiME Challenge, which addresses the cocktail-party problem of
overlapping conversations in a single-room setting using audio, visual, and
contextual cues. MCoRec captures natural multi-party conversations where the
recordings focus on unscripted, casual group chats, leading to extreme speech
overlap of up to 100% and highly fragmented conversational turns. The task
requires systems to answer the question "Who speaks when, what, and with whom?"
by jointly transcribing each speaker's speech and clustering them into their
respective conversations from audio-visual recordings. Audio-only baselines
exceed 100% word error rate, whereas incorporating visual cues yields
substantial 50% improvements, highlighting the importance of multi-modality. In
this manuscript, we present the motivation behind the task, outline the data
collection process, and report the baseline systems developed for the MCoRec.

</details>


### [98] [DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration Training for Text-to-SQL Model](https://arxiv.org/abs/2510.23284)
*Yuanzhen Xie,Liu Ye,Jiqun Chu,Mochi Gao,Hehuan Liu,Yunzhi Tan,Bo Hu,Zang Li*

Main category: cs.CL

TL;DR: 本文提出了一个全自动数据中心流程，包括自适应数据修复和错误数据增强，结合多模型协作训练和集成策略，提高了Text-to-SQL任务的准确率，获得轻量级模型排行榜第一。


<details>
  <summary>Details</summary>
Motivation: 现有Text-to-SQL任务多依赖于基于代理的框架，鲜少关注数据中心策略对任务性能的影响。

Method: 设计了自适应数据修复自动修正训练集中的错误，错误数据增强扩展模型难以预测的错误样本，使用多模型协作训练提升模型能力互补，最后采用集成策略提升多选题任务准确率。

Result: 实验证明数据中心流程和多模型交互训练策略的有效性，在轻量级（70B以下）Text-to-SQL模型中获得第一名。

Conclusion: 数据中心策略与多模型协同训练显著提升了Text-to-SQL任务性能，具备广泛应用潜力。

Abstract: Text-to-SQL tasks have gained attractive improvements since the release of
ChatGPT. Among them, agent-based frameworks have been widely used in this
field. However, the impact of data-centric strategies on text-to-SQL tasks has
rarely been explored. In this paper, we systemically design a fully automated
data-centric pipeline for text-to-SQL tasks, including \emph{adaptive data
repair}, which can automatically find and fix errors in the training dataset;
and \emph{error data augmentation}, where we specifically diffuse and enhance
erroneous data predicted by the initially trained models. Meanwhile, we propose
a Multi-Model collaboration training schema, aiming to train multiple models
with different augmented data, enabling them to possess distinct capabilities
and work together to complement each other, because it has been found that the
capability of a single fine-tuned model is very limited. Furthermore, we
utilize an ensemble strategy to integrate the capabilities of multiple models
to solve a multiple-choice question, aiming to further improve the accuracy of
text-to-SQL tasks. The experiment results and ablation study have demonstrated
the effectiveness of data-centric pipeline and Multi-Model(MM) interactive
iterative strategies, achieving first place in lightweight text-to-SQL models
(within 70B).

</details>


### [99] [Arabic Little STT: Arabic Children Speech Recognition Dataset](https://arxiv.org/abs/2510.23319)
*Mouhand Alkadri,Dania Desouki,Khloud Al Jallad*

Main category: cs.CL

TL;DR: 本文介绍了阿拉伯语儿童语音数据集Arabic Little STT，评估了Whisper自动语音识别模型在该数据集上的表现，发现儿童语音识别性能远低于成人，强调了儿童语音数据集的重要性。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语等资源匮乏语言缺乏儿童专用语音数据，影响了人工智能系统在儿童语音识别上的表现。

Method: 创建包含288名6-13岁儿童355条语音的Levantine阿拉伯语儿童语音数据集，系统评估八种Whisper模型变体在该数据集及成人语音数据集上的性能。

Result: 最佳模型Large_v3在儿童语音上的词错误率高达0.66，远高于成人数据集的低于0.20的词错误率，结果与英文儿童语音识别研究一致。

Conclusion: 儿童语音识别发展急需专门的儿童语音基准和包容性的训练数据，并需在严格的伦理和隐私框架下保护儿童信息，本文初步推动了阿拉伯语儿童语音技术的公平发展。

Abstract: The performance of Artificial Intelligence (AI) systems fundamentally depends
on high-quality training data. However, low-resource languages like Arabic
suffer from severe data scarcity. Moreover, the absence of child-specific
speech corpora is an essential gap that poses significant challenges. To
address this gap, we present our created dataset, Arabic Little STT, a dataset
of Levantine Arabic child speech recorded in classrooms, containing 355
utterances from 288 children (ages 6 - 13). We further conduct a systematic
assessment of Whisper, a state-of-the-art automatic speech recognition (ASR)
model, on this dataset and compare its performance with adult Arabic
benchmarks. Our evaluation across eight Whisper variants reveals that even the
best-performing model (Large_v3) struggles significantly, achieving a 0.66 word
error rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on
adult datasets. These results align with other research on English speech.
Results highlight the critical need for dedicated child speech benchmarks and
inclusive training data in ASR development. Emphasizing that such data must be
governed by strict ethical and privacy frameworks to protect sensitive child
information. We hope that this study provides an initial step for future work
on equitable speech technologies for Arabic-speaking children. We hope that our
publicly available dataset enrich the children's demographic representation in
ASR datasets.

</details>


### [100] [Adaptive Blockwise Search: Inference-Time Alignment for Large Language Models](https://arxiv.org/abs/2510.23334)
*Mohammad Atif Quamar,Mohammad Areeb,Nishant Sharma,Ananth Shreekumar,Jonathan Rosenthal,Muslum Ozgur Ozmen,Mikhail Kuznetsov,Z. Berkay Celik*

Main category: cs.CL

TL;DR: 本文提出AdaSearch，一种针对大语言模型推理时自适应分配计算资源的新策略，显著提升对齐效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理时均分计算资源导致对齐效果不佳，初始生成的词更关键。

Method: 提出AdaSearch块搜索策略和其树搜索版本AdaBeam，根据采样计划自适应分配计算预算，集中在关键初始词。

Result: 在8种大模型测试中，AdaSearch优于Best-of-N和微调基线，生成任务准确率提升超10%。

Conclusion: AdaSearch通过自适应计算分配显著优化了生成对齐，展示了推理时资源重点调度的潜力。

Abstract: LLM alignment remains a critical challenge. Inference-time methods provide a
flexible alternative to fine-tuning, but their uniform computational effort
often yields suboptimal alignment. We hypothesize that for many alignment
tasks, the initial tokens of a response are disproportionately more critical.
To leverage this principle, we introduce AdaSearch, a novel blockwise search
strategy. It adaptively allocates a fixed computational budget using a sampling
schedule, focusing search effort on these critical tokens. We apply AdaSearch
to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our
comprehensive evaluation across eight LLMs demonstrates that AdaSearch
outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates
improve by over 10% for harmlessness generation, controlled sentiment
generation, and for mathematical reasoning tasks relative to Best-of-N.

</details>


### [101] [BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and Persona Reasoning](https://arxiv.org/abs/2510.23337)
*Siyuan Zheng,Pai Liu,Xi Chen,Jizheng Dong,Sihan Jia*

Main category: cs.CL

TL;DR: 本文提出了首个基于八字的虚拟人物推理问答数据集，并设计了融合符号推理与大型语言模型的BaZi-LLM系统，实现了对动态且细致的虚拟人物生成，准确率显著优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟人物生成方法依赖带注释数据或手工个性提示，难以规模化且生成的人物缺乏现实感和语境一致性。为此，构建一个有效推理虚拟人物的系统变得迫切。

Method: 构建首个基于八字的问答数据集，涵盖财富、健康、亲属关系、职业和人际关系的生活事件。提出融合符号推理与大型语言模型的BaZi-LLM系统，实现时间动态和细粒度的人物生成。

Result: 与DeepSeek-v3、GPT-5-mini等主流LLM相比，BaZi-LLM的准确率提高了30.3%-62.6%。模型在错误八字信息下准确率下降20%-45%，验证了符号推理与语言模型结合的有效性。

Conclusion: 通过融合文化背景的符号推理与语言模型，能显著提升虚拟人物的现实感与语境连贯性，为游戏和虚拟现实中的人物模拟提供有效技术支持。

Abstract: Human-like virtual characters are crucial for games, storytelling, and
virtual reality, yet current methods rely heavily on annotated data or
handcrafted persona prompts, making it difficult to scale up and generate
realistic, contextually coherent personas. We create the first QA dataset for
BaZi-based persona reasoning, where real human experiences categorized into
wealth, health, kinship, career, and relationships are represented as
life-event questions and answers. Furthermore, we propose the first BaZi-LLM
system that integrates symbolic reasoning with large language models to
generate temporally dynamic and fine-grained virtual personas. Compared with
mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a
30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information
is used, our model's accuracy drops by 20%-45%, showing the potential of
culturally grounded symbolic-LLM integration for realistic character
simulation.

</details>


### [102] [LightKGG: Simple and Efficient Knowledge Graph Generation from Textual Data](https://arxiv.org/abs/2510.23341)
*Teng Lin*

Main category: cs.CL

TL;DR: 提出LightKGG框架，利用小规模语言模型高效提取知识图谱，降低硬件需求。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱提取依赖易错的模式匹配或资源消耗大的大型语言模型，限制了低资源环境的应用。

Method: 引入上下文集成图提取和拓扑增强关系推理两大技术，整合上下文信息并利用图结构推断关系，无需复杂语义理解。

Result: 实现了在小模型和低硬件资源条件下准确构建知识图谱，有效减少计算需求。

Conclusion: LightKGG框架有效弥合了自动知识抽取与实际部署的差距，为小规模模型优化结构化NLP任务提供了科学方法。

Abstract: The scarcity of high-quality knowledge graphs (KGs) remains a critical
bottleneck for downstream AI applications, as existing extraction methods rely
heavily on error-prone pattern-matching techniques or resource-intensive large
language models (LLMs). While recent tools leverage LLMs to generate KGs, their
computational demands limit accessibility for low-resource environments. Our
paper introduces LightKGG, a novel framework that enables efficient KG
extraction from textual data using small-scale language models (SLMs) through
two key technical innovations: (1) Context-integrated Graph extraction
integrates contextual information with nodes and edges into a unified graph
structure, reducing the reliance on complex semantic processing while
maintaining more key information; (2) Topology-enhanced relationship inference
leverages the inherent topology of the extracted graph to efficiently infer
relationships, enabling relationship discovery without relying on complex
language understanding capabilities of LLMs. By enabling accurate KG
construction with minimal hardware requirements, this work bridges the gap
between automated knowledge extraction and practical deployment scenarios while
introducing scientifically rigorous methods for optimizing SLM efficiency in
structured NLP tasks.

</details>


### [103] [How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market Changes](https://arxiv.org/abs/2510.23358)
*Sheri Osborn,Rohit Valecha,H. Raghav Rao,Dan Sass,Anthony Rios*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估大型语言模型（LLMs）预测人工智能对就业影响的基准，结合美国行业招聘数据和全球职业变化预测数据，采用多种提示策略评估模型预测能力，结果显示结构化提示能提升预测稳定性，个性化提示在短期趋势上有优势。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏系统工具来预测人工智能对就业市场的影响，现有研究多聚焦于情感提取和报告摘要，缺少前瞻性劳动预测的评估。

Method: 构建了结合美国高频行业招聘指数和全球AI导致职业变化数据的基准，设计包含时间划分的预测任务，采用任务框架提示、角色驱动提示和混合提示策略对多种LLMs进行评测，分析预测的准确性及时间一致性。

Result: 结构化任务提示显著提升了预测的稳定性，角色提示在短期趋势预测中表现更优，但在不同行业和预测时间跨度上的性能差异显著，表明需要领域感知的提示设计和严格评测。

Conclusion: 该基准为未来劳动力市场预测、提示设计和基于LLMs的经济推理研究提供了支持，推动人工智能与实际经济数据结合的研究，并为探索AI预测能力的边界和潜力提供了可复现的测试平台。

Abstract: Artificial intelligence is reshaping labor markets, yet we lack tools to
systematically forecast its effects on employment. This paper introduces a
benchmark for evaluating how well large language models (LLMs) can anticipate
changes in job demand, especially in occupations affected by AI. Existing
research has shown that LLMs can extract sentiment, summarize economic reports,
and emulate forecaster behavior, but little work has assessed their use for
forward-looking labor prediction. Our benchmark combines two complementary
datasets: a high-frequency index of sector-level job postings in the United
States, and a global dataset of projected occupational changes due to AI
adoption. We format these data into forecasting tasks with clear temporal
splits, minimizing the risk of information leakage. We then evaluate LLMs using
multiple prompting strategies, comparing task-scaffolded, persona-driven, and
hybrid approaches across model families. We assess both quantitative accuracy
and qualitative consistency over time. Results show that structured task
prompts consistently improve forecast stability, while persona prompts offer
advantages on short-term trends. However, performance varies significantly
across sectors and horizons, highlighting the need for domain-aware prompting
and rigorous evaluation protocols. By releasing our benchmark, we aim to
support future research on labor forecasting, prompt design, and LLM-based
economic reasoning. This work contributes to a growing body of research on how
LLMs interact with real-world economic data, and provides a reproducible
testbed for studying the limits and opportunities of AI as a forecasting tool
in the context of labor markets.

</details>


### [104] [Detecting Religious Language in Climate Discourse](https://arxiv.org/abs/2510.23395)
*Evy Beijen,Pien Pieterse,Yusuf Çelik,Willem Th. van Peursen,Sandjai Bhulai,Meike Morren*

Main category: cs.CL

TL;DR: 本文研究了宗教语言在气候变化相关文本中的显性和隐性表现，提出了基于规则和大型语言模型的双重方法，分析了两者的异同。


<details>
  <summary>Details</summary>
Motivation: 尽管气候变化等领域看似世俗，宗教语言依然广泛存在。理解其表现形式有助于揭示宗教语言的定义及应用。

Method: 结合基于生态神学词汇的分层规则模型和零-shot的大型语言模型，基于88万句文本进行宗教语言识别与对比分析。

Result: 基于规则的方法比大型语言模型识别出更多的宗教语言句子，显示了对宗教语言检测的复杂性和方法间的差异。

Conclusion: 研究揭示宗教语言的识别不仅依赖词汇，还需考虑语境意义，强调了数字宗教学方法的潜力与限制。

Abstract: Religious language continues to permeate contemporary discourse, even in
ostensibly secular domains such as environmental activism and climate change
debates. This paper investigates how explicit and implicit forms of religious
language appear in climate-related texts produced by secular and religious
nongovernmental organizations (NGOs). We introduce a dual methodological
approach: a rule-based model using a hierarchical tree of religious terms
derived from ecotheology literature, and large language models (LLMs) operating
in a zero-shot setting. Using a dataset of more than 880,000 sentences, we
compare how these methods detect religious language and analyze points of
agreement and divergence. The results show that the rule-based method
consistently labels more sentences as religious than LLMs. These findings
highlight not only the methodological challenges of computationally detecting
religious language but also the broader tension over whether religious language
should be defined by vocabulary alone or by contextual meaning. This study
contributes to digital methods in religious studies by demonstrating both the
potential and the limitations of approaches for analyzing how the sacred
persists in climate discourse.

</details>


### [105] [EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting](https://arxiv.org/abs/2510.23396)
*Musleh Alharthi,Kaleel Mahmood,Sarosh Patel,Ausif Mahmood*

Main category: cs.CL

TL;DR: 本文针对时间序列预测（TSF）提出了一个基于多专家模型（MoE）的Transformer框架，将多种先进模型结合以提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对Transformer及其变体在TSF中的有效性存在争议，且时间序列数据偏好近期信息且常受不可预测事件影响，需更强模型应对挑战。

Method: 提出结合xLSTM、增强线性模型、PatchTST、minGRU等多种模型，通过基于Transformer的MoE门控网络整合各模型优势。

Result: 新模型在标准TSF基准测试中表现优于现有所有模型，甚至超过最新MoE方法。

Conclusion: 所提Transformer-based MoE框架有效整合多样化TSF模型，大幅提升时间序列预测性能，代表当前最优方案。

Abstract: The immense success of the Transformer architecture
  in Natural Language Processing has led to its adoption in Time Se ries
Forecasting (TSF), where superior performance has been shown.
  However, a recent important paper questioned their effectiveness by
  demonstrating that a simple single layer linear model outperforms
  Transformer-based models. This was soon shown to be not as valid,
  by a better transformer-based model termed PatchTST. More re cently, TimeLLM
demonstrated even better results by repurposing a
  Large Language Model (LLM) for the TSF domain. Again, a follow
  up paper challenged this by demonstrating that removing the LLM
  component or replacing it with a basic attention layer in fact yields
  better performance. One of the challenges in forecasting is the fact
  that TSF data favors the more recent past, and is sometimes subject
  to unpredictable events. Based upon these recent insights in TSF, we
  propose a strong Mixture of Experts (MoE) framework. Our method
  combines the state-of-the-art (SOTA) models including xLSTM, en hanced
Linear, PatchTST, and minGRU, among others. This set of
  complimentary and diverse models for TSF are integrated in a Trans former
based MoE gating network. Our proposed model outperforms
  all existing TSF models on standard benchmarks, surpassing even the
  latest approaches based on MoE frameworks.

</details>


### [106] [Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with Free-Form Preferences](https://arxiv.org/abs/2510.23451)
*Zhuoran Jin,Hongbang Yuan,Kejian Zhu,Jiachun Li,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 该论文提出了Omni-Reward，一种支持多模态和自由形式偏好的通用奖励模型，解决了奖励模型在模态不平衡和偏好刚性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型主要聚焦于文本和图像模态，缺乏对视频、音频等多模态的支持，且采用固定的二元偏好对训练，无法反映个性化偏好的复杂性和多样性。

Method: 提出了一个包含文本、图像、视频、音频和3D五种模态的多模态自由偏好基准Omni-RewardBench；构建了包含248K一般偏好对和69K指令调优对的数据集Omni-RewardData；设计了包含判别式和生成式的通用奖励模型Omni-RewardModel。

Result: Omni-RewardModel在Omni-RewardBench及其他主流奖励建模基准上表现优异，证明了其多模态和自由偏好建模能力。

Conclusion: Omni-Reward推动了通用多模态奖励模型的发展，有效提升了对复杂个性化偏好的捕捉，扩展了奖励模型的应用范围。

Abstract: Reward models (RMs) play a critical role in aligning AI behaviors with human
preferences, yet they face two fundamental challenges: (1) Modality Imbalance,
where most RMs are mainly focused on text and image modalities, offering
limited support for video, audio, and other modalities; and (2) Preference
Rigidity, where training on fixed binary preference pairs fails to capture the
complexity and diversity of personalized preferences. To address the above
challenges, we propose Omni-Reward, a step toward generalist omni-modal reward
modeling with support for free-form preferences, consisting of: (1) Evaluation:
We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form
preferences, covering nine tasks across five modalities including text, image,
video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal
preference dataset comprising 248K general preference pairs and 69K
instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We
propose Omni-RewardModel, which includes both discriminative and generative
RMs, and achieves strong performance on Omni-RewardBench as well as other
widely used reward modeling benchmarks.

</details>


### [107] [BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents](https://arxiv.org/abs/2510.23458)
*Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Yong Jiang,Pengjun Xie,Fei Huang,Jingren Zhou*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在多轮交互中通过语言表达置信度的能力，并提出了基于置信度的测试时间缩放方法，有效提升了任务准确率和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多针对单轮交互场景，对于多轮复杂交互中模型置信度的表达和利用尚缺乏系统研究。

Method: 通过实验证明模型高置信度对应高准确率，基于此设计了测试时间缩放（TTS）方法，根据模型置信度判断答案质量，鼓励模型多次尝试以达到满意置信度。

Result: 提出的方法显著减少了模型的词元消耗，同时在性能上与固定预算测试时间缩放方法保持竞争力。

Conclusion: 基于置信度的测试时间缩放方法在多轮交互中有效提升了大型语言模型的答案质量和效率，展示了置信度表达在复杂任务中的应用潜力。

Abstract: Confidence in LLMs is a useful indicator of model uncertainty and answer
reliability. Existing work mainly focused on single-turn scenarios, while
research on confidence in complex multi-turn interactions is limited. In this
paper, we investigate whether LLM-based search agents have the ability to
communicate their own confidence through verbalized confidence scores after
long sequences of actions, a significantly more challenging task compared to
outputting confidence in a single interaction. Experimenting on open-source
agentic models, we first find that models exhibit much higher task accuracy at
high confidence while having near-zero accuracy when confidence is low. Based
on this observation, we propose Test-Time Scaling (TTS) methods that use
confidence scores to determine answer quality, encourage the model to try again
until reaching a satisfactory confidence level. Results show that our proposed
methods significantly reduce token consumption while demonstrating competitive
performance compared to baseline fixed budget TTS methods.

</details>


### [108] [Evaluating Large Language Models for Stance Detection on Financial Targets from SEC Filing Reports and Earnings Call Transcripts](https://arxiv.org/abs/2510.23464)
*Nikesh Gyawali,Doina Caragea,Alex Vasenkov,Cornelia Caragea*

Main category: cs.CL

TL;DR: 本文构建了一个针对财务核心指标（债务、每股收益、销售额）的句子级立场检测语料库，利用ChatGPT进行标注，并系统评估了多种大语言模型的检测能力，发现少量示例加推理提示效果最佳。


<details>
  <summary>Details</summary>
Motivation: 金融领域的情感分析因数据标注昂贵且文本专业、细长，尤其难以实现针对具体财务指标的句子级立场检测。

Method: 从SEC 10-K报告和季度财报电话会议中提取句子，采用ChatGPT-o3-pro进行立场标注，结合人工验证构建语料库；随后利用零样本、少样本及链式推理提示策略评估多个大语言模型性能。

Result: 少样本加链式推理提示的模型表现优于监督学习模型，且模型在SEC和ECT语料上的表现存在差异。

Conclusion: 大语言模型能够有效支持金融领域目标特定的句子级立场检测，无需大量标注数据，具备实际应用潜力。

Abstract: Financial narratives from U.S. Securities and Exchange Commission (SEC)
filing reports and quarterly earnings call transcripts (ECTs) are very
important for investors, auditors, and regulators. However, their length,
financial jargon, and nuanced language make fine-grained analysis difficult.
Prior sentiment analysis in the financial domain required a large, expensive
labeled dataset, making the sentence-level stance towards specific financial
targets challenging. In this work, we introduce a sentence-level corpus for
stance detection focused on three core financial metrics: debt, earnings per
share (EPS), and sales. The sentences were extracted from Form 10-K annual
reports and ECTs, and labeled for stance (positive, negative, neutral) using
the advanced ChatGPT-o3-pro model under rigorous human validation. Using this
corpus, we conduct a systematic evaluation of modern large language models
(LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting
strategies. Our results show that few-shot with CoT prompting performs best
compared to supervised baselines, and LLMs' performance varies across the SEC
and ECT datasets. Our findings highlight the practical viability of leveraging
LLMs for target-specific stance in the financial domain without requiring
extensive labeled data.

</details>


### [109] [MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring](https://arxiv.org/abs/2510.23477)
*Tengchao Yang,Sichen Guo,Mengzhao Jia,Jiaming Su,Yuanyang Liu,Zhihan Zhang,Meng Jiang*

Main category: cs.CL

TL;DR: 本文提出了MMTutorBench，一个针对数学AI辅导的基准测试，评估模型在诊断学生困难和逐步指导方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在数学辅导中的教学诊断和引导能力尚未得到充分评价。

Method: 构建包含685道题目的MMTutorBench基准，设计涵盖关键教学步骤的问题及对应评价指标，分为三项任务进行细粒度评估。

Result: 评测了12个领先模型，发现专有模型优于开源模型，存在显著提升空间；OCR和少样本提示对结果有负面或有限影响；基于评分标准的模型评分方法可靠。

Conclusion: MMTutorBench能够有效揭示当前AI数学辅导模型的不足，为提升AI个性化教学能力提供重要参考。

Abstract: Effective math tutoring requires not only solving problems but also
diagnosing students' difficulties and guiding them step by step. While
multimodal large language models (MLLMs) show promise, existing benchmarks
largely overlook these tutoring skills. We introduce MMTutorBench, the first
benchmark for AI math tutoring, consisting of 685 problems built around
pedagogically significant key-steps. Each problem is paired with
problem-specific rubrics that enable fine-grained evaluation across six
dimensions, and structured into three tasks-Insight Discovery, Operation
Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find
clear performance gaps between proprietary and open-source systems, substantial
room compared to human tutors, and consistent trends across input variants: OCR
pipelines degrade tutoring quality, few-shot prompting yields limited gains,
and our rubric-based LLM-as-a-Judge proves highly reliable. These results
highlight both the difficulty and diagnostic value of MMTutorBench for
advancing AI tutoring.

</details>


### [110] [M4FC: a Multimodal, Multilingual, Multicultural, Multitask Real-World Fact-Checking Dataset](https://arxiv.org/abs/2510.23508)
*Jiahui Geng,Jonathan Tonglet,Iryna Gurevych*

Main category: cs.CL

TL;DR: 该论文引入了一个名为M4FC的多模态自动事实核查数据集，包含4982张图片和6980条声明，涵盖10种语言和多个任务，旨在解决现有数据集规模小、语言和任务单一、证据泄露等问题。


<details>
  <summary>Details</summary>
Motivation: 现有多模态自动事实核查数据集存在实例数量少、语言和任务覆盖有限、证据泄露以及对外部新闻文章依赖等问题，限制了模型的泛化能力和实用性。

Method: 构建了一个新的大型多模态事实核查数据集M4FC，图片由专业事实核查员验证，覆盖多种文化和地理背景，声明覆盖多语言。数据集包含六个多模态核查任务，并提供所有任务的基线结果，同时分析中间任务对最终判决预测的影响。

Result: 成功构建并发布了包含多语言、多文化背景和多任务的大规模多模态事实核查数据集M4FC，提供了基线结果和任务间关系分析，促进多模态事实核查研究的发展。

Conclusion: M4FC数据集弥补了现有数据集的不足，支持更广泛的语言和任务，有助于推动多模态事实核查领域的研究和应用。代码和数据集已公开，便于社区使用和改进。

Abstract: Existing real-world datasets for multimodal automated fact-checking have
multiple limitations: they contain few instances, focus on only one or two
languages and tasks, suffer from evidence leakage, or depend on external sets
of news articles for sourcing true claims. To address these shortcomings, we
introduce M4FC, a new real-world dataset comprising 4,982 images paired with
6,980 claims. The images, verified by professional fact-checkers from 22
organizations, represent diverse cultural and geographic contexts. Each claim
is available in one or two out of ten languages. M4FC spans six multimodal
fact-checking tasks: visual claim extraction, claimant intent prediction, fake
detection, image contextualization, location verification, and verdict
prediction. We provide baseline results for all tasks and analyze how combining
intermediate tasks influence downstream verdict prediction performance. We make
our dataset and code available.

</details>


### [111] [IPQA: A Benchmark for Core Intent Identification in Personalized Question Answering](https://arxiv.org/abs/2510.23536)
*Jieyong Kim,Maryam Amirizaniani,Soojin Yoon,Dongha Lee*

Main category: cs.CL

TL;DR: 提出IPQA基准，评估个性化问答中的核心意图识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有评价标准未直接测量用户意图识别，导致无法满足个体信息需求。

Method: 引入核心意图概念，通过用户选答案行为推断，建立跨领域数据集并用LLM及人工验证注释。

Result: 实验表明当前最先进模型在个性化核心意图识别上表现不佳，且随着问题复杂度增加性能下降。

Conclusion: IPQA基准和数据集助力提升个性化问答系统中核心意图识别能力，促进未来研究发展。

Abstract: Intent identification serves as the foundation for generating appropriate
responses in personalized question answering (PQA). However, existing
benchmarks evaluate only response quality or retrieval performance without
directly measuring intent identification capabilities. This gap is critical
because without understanding which intents users prioritize, systems cannot
generate responses satisfying individual information needs. To address this, we
introduce the concept of core intents: intents users prioritize when selecting
answers to satisfy their information needs. To evaluate these core intents, we
propose IPQA, a benchmark for core Intent identification in Personalized
Question Answering. Since users do not explicitly state their prioritized
intents, we derive core intents from observable behavior patterns in answer
selection, grounded in satisficing theory where users choose answers meeting
their acceptance thresholds. We construct a dataset with various domains
through systematic filtering, LLM-based annotation, and rigorous quality
control combining automated verification with human validation. Experimental
evaluations across state-of-the-art language models reveal that current systems
struggle with core intent identification in personalized contexts. Models fail
to identify core intents from user histories, with performance degrading as
question complexity increases. The code and dataset will be made publicly
available to facilitate future research in this direction.

</details>


### [112] [LimRank: Less is More for Reasoning-Intensive Information Reranking](https://arxiv.org/abs/2510.23544)
*Tingyu Song,Yilun Zhao,Siyue Zhang,Chen Zhao,Arman Cohan*

Main category: cs.CL

TL;DR: 本文提出LIMRANK-SYNTHESIZER方法，通过少量高质量合成数据高效微调大型语言模型，实现信息重排序任务，显著减少训练数据量并保持竞争力表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模微调适配大型语言模型，计算资源消耗大，限制了应用。希望通过少量高质量监督数据实现有效适配。

Method: 设计了LIMRANK-SYNTHESIZER开源流水线生成多样且具挑战性的合成重排序训练样本，利用合成数据微调重排序模型LIMRANK。

Result: 在BRIGHT和FollowIR两个困难基准测试中，LIMRANK以不到传统训练数据5%的数据量达到竞争性能，且具备良好的泛化能力。

Conclusion: 表明了利用合成样本微调大型语言模型在重排序任务上的可行性与有效性，减少了对大规模真实数据的依赖，提高了模型的实用价值。

Abstract: Existing approaches typically rely on large-scale fine-tuning to adapt LLMs
for information reranking tasks, which is computationally expensive. In this
work, we demonstrate that modern LLMs can be effectively adapted using only
minimal, high-quality supervision. To enable this, we design
LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating
diverse, challenging, and realistic reranking examples. Using this synthetic
data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two
challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and
FollowIR for instruction-following retrieval. Our experiments demonstrate that
LIMRANK achieves competitive performance, while being trained on less than 5%
of the data typically used in prior work. Further ablation studies demonstrate
the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization
capabilities of LIMRANK across downstream tasks, including scientific
literature search and retrieval-augmented generation for knowledge-intensive
problem solving.

</details>


### [113] [Hope Speech Detection in Social Media English Corpora: Performance of Traditional and Transformer Models](https://arxiv.org/abs/2510.23585)
*Luis Ramos,Hiram Calvo,Olga Kolesnikova*

Main category: cs.CL

TL;DR: 本文比较了传统机器学习模型与微调的变压器模型在希望言论识别任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 鉴于社交媒体平台上识别表达动机和目标导向行为的希望言论的需求，将该任务视为重要的自然语言处理任务。

Method: 使用已划分的希望言论数据集，分别训练和评估传统机器学习模型（如线性SVM、逻辑回归、径向基函数SVM和朴素贝叶斯）与微调的变压器模型。

Result: 在开发集上，线性SVM和逻辑回归均达到了0.78的宏F1，RBF SVM为0.77，朴素贝叶斯为0.75。变压器模型表现更优，最佳模型达到加权精确度0.82、加权召回0.80、加权F1 0.79、宏F1 0.79和准确率0.80。

Conclusion: 虽然传统机器学习模型配置优化后依然具备较好灵活性，但变压器架构能捕捉更细微的希望语义，从而在识别希望言论上取得更高的精确率和召回率，暗示大型变压器和大型语言模型在小数据集上表现可能更佳。

Abstract: The identification of hope speech has become a promised NLP task, considering
the need to detect motivational expressions of agency and goal-directed
behaviour on social media platforms. This proposal evaluates traditional
machine learning models and fine-tuned transformers for a previously split hope
speech dataset as train, development and test set. On development test, a
linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM
with RBF kernel reached 0.77, and Na\"ive Bayes hit 0.75. Transformer models
delivered better results, the best model achieved weighted precision of 0.82,
weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80
accuracy. These results suggest that while optimally configured traditional
machine learning models remain agile, transformer architectures detect some
subtle semantics of hope to achieve higher precision and recall in hope speech
detection, suggesting that larges transformers and LLMs could perform better in
small datasets.

</details>


### [114] [Think Twice: Branch-and-Rethink Reasoning Reward Model](https://arxiv.org/abs/2510.23596)
*Yizhu Jiao,Jiaqi Zeng,Julien Veron Vialard,Oleksii Kuchaiev,Jiawei Han,Olivier Delalleau*

Main category: cs.CL

TL;DR: 本文提出了BR-RM，一种两轮奖励模型，通过第二轮针对性地重新思考，改善奖励模型的判断扩散问题，提高细微错误的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型往往将多维度质量压缩为单一评分，导致注意力分散，分析浅显，影响判断准确性。

Method: BR-RM采用两轮策略，第一轮进行自适应分支，选择关键维度和假设；第二轮针对性重新审视，结合强化学习进行训练。

Result: 实验结果表明，BR-RM在三个不同领域的奖励建模基准上均达到最先进的性能。

Conclusion: 通过引入第二区思考和聚焦评估，BR-RM有效缓解了判断扩散问题，提升奖励模型的细微错误感知能力，且方法实用可扩展。

Abstract: Large language models (LLMs) increasingly rely on thinking models that
externalize intermediate steps and allocate extra test-time compute, with
think-twice strategies showing that a deliberate second pass can elicit
stronger reasoning. In contrast, most reward models (RMs) still compress many
quality dimensions into a single scalar in one shot, a design that induces
judgment diffusion: attention spreads across evaluation criteria, yielding
diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a
two-turn RM that transfers the think-twice principle to reward modeling. Turn 1
performs adaptive branching, selecting a small set of instance-critical
dimensions (such as factuality and safety) and sketching concise,
evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a
targeted reread that tests those hypotheses and scrutinizes only what matters
most. We train with GRPO-style reinforcement learning over structured two-turn
traces using a simple binary outcome reward with strict format checks, making
the approach compatible with standard RLHF pipelines. By converting
all-at-oncescoringintofocused, second-lookreasoning,
BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet
consequential errors while remaining practical and scalable. Experimental
results demonstrate that our model achieves state-of-the-art performance on
three challenging reward modeling benchmarks across diverse domains. The code
and the model will be released soon.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [115] [Software Engineering Agents for Embodied Controller Generation : A Study in Minigrid Environments](https://arxiv.org/abs/2510.21902)
*Timothé Boulet,Xavier Hinaut,Clément Moulin-Frier*

Main category: cs.SE

TL;DR: 本文评估了软件工程代理（SWE-Agents）在具身任务中生成控制器的性能表现，探讨了不同信息获取条件对其效果的影响。


<details>
  <summary>Details</summary>
Motivation: 传统SWE-Agents主要用于传统软件工程任务，而其在具身任务中需要良好信息发现能力的表现尚未探究。

Method: 基于Mini-SWE-Agent，设计并执行了在Minigrid环境中解决20个多样具身任务的实验，比较了不同信息访问方式（是否访问环境源码、交互探索能力）的影响。

Result: 实验结果量化了不同信息访问水平对SWE-Agents执行具身任务的影响，分析了静态代码分析和动态探索两者在任务解决中的相对重要性。

Conclusion: 提出了具身任务中控制器生成作为SWE-Agents重要的评估领域，为未来高效推理系统的研究提供了基线结果。

Abstract: Software Engineering Agents (SWE-Agents) have proven effective for
traditional software engineering tasks with accessible codebases, but their
performance for embodied tasks requiring well-designed information discovery
remains unexplored. We present the first extended evaluation of SWE-Agents on
controller generation for embodied tasks, adapting Mini-SWE-Agent (MSWEA) to
solve 20 diverse embodied tasks from the Minigrid environment. Our experiments
compare agent performance across different information access conditions: with
and without environment source code access, and with varying capabilities for
interactive exploration. We quantify how different information access levels
affect SWE-Agent performance for embodied tasks and analyze the relative
importance of static code analysis versus dynamic exploration for task solving.
This work establishes controller generation for embodied tasks as a crucial
evaluation domain for SWE-Agents and provides baseline results for future
research in efficient reasoning systems.

</details>


### [116] [TOM-SWE: User Mental Modeling For Software Engineering Agents](https://arxiv.org/abs/2510.21903)
*Xuhui Zhou,Valerie Chen,Zora Zhiruo Wang,Graham Neubig,Maarten Sap,Xingyao Wang*

Main category: cs.SE

TL;DR: 本文提出了ToM-SWE，一种结合理论心智模型的双代理架构，显著提升了编码代理对用户意图的推断和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 当前编码代理难以准确推断和追踪用户意图，尤其在指令不明确或依赖上下文的情况下。

Method: 设计一个包含主软件工程代理和轻量级理论心智代理的双代理系统，后者建模用户心理状态、推断用户目标及偏好，并保持持久记忆辅助主代理。

Result: 在两个软件工程基准测试中，ToM-SWE显著提升任务成功率和用户满意度，特别是在新引入的有状态基准测试中，成功率提高至59.7%，远超现有方法OpenHands的18.1%。

Conclusion: 状态化的用户建模对实际编码代理极具价值，能提升代理的用户适应性和工作效率，适合在专业开发环境中应用。

Abstract: Recent advances in coding agents have made them capable of planning, editing,
running, and testing complex code bases. Despite their growing ability in
coding tasks, these systems still struggle to infer and track user intent,
especially when instructions are underspecified or context-dependent. To bridge
this gap, we introduce ToM-SWE, a dual-agent architecture that pairs a primary
software-engineering (SWE) agent with a lightweight theory-of-mind (ToM)
partner agent dedicated to modeling the user's mental state. The ToM agent
infers user goals, constraints, and preferences from instructions and
interaction history, maintains a \textbf{persistent memory} of the user, and
provides user-related suggestions to the SWE agent. In two software engineering
benchmarks (ambiguous SWE-bench and stateful SWE-bench), ToM-SWE improves task
success rates and user satisfaction. Notably, on the stateful SWE benchmark, a
newly introduced evaluation that provides agents with a user simulator along
with previous interaction histories, ToM-SWE achieves a substantially higher
task success rate of 59.7\% compared to 18.1\% for OpenHands, a
state-of-the-art SWE agent. Furthermore, in a three-week study with
professional developers using ToM-SWE in their daily work, participants found
it useful 86\% of the time, underscoring the value of stateful user modeling
for practical coding agents.

</details>


### [117] [A Comparison of Conversational Models and Humans in Answering Technical Questions: the Firefox Case](https://arxiv.org/abs/2510.21933)
*Joao Correia,Daniel Coutinho,Marco Castelluccio,Caio Barbosa,Rafael de Mello,Anita Sarma,Alessandro Garcia,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: 该论文评估了基于检索增强生成（RAG）的语言模型在Mozilla Firefox项目中辅助开发者的效果，结果表明RAG模型生成的回答比人工更全面且同样有帮助，但回答较为冗长。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在软件开发中应用增多，探索如何利用提升开发者辅助效果的技术具有重要实际意义。

Method: 联合Mozilla基金会，使用真实开发者查询，比较人类开发者、标准GPT模型和RAG增强GPT模型的回答，由Mozilla专家基于有用性、全面性和简洁性进行评估。

Result: RAG辅助的回答比人类开发者更全面（62.50% vs 54.17%），帮助度接近人类（75.00% vs 79.17%），但表达不够简洁，较为冗长。

Conclusion: RAG技术有助于提升开源项目中开发者帮助质量，未来应优化检索机制与回答简洁性，以减轻核心维护者负担，提高大规模项目的开发效率。

Abstract: The use of Large Language Models (LLMs) to support tasks in software
development has steadily increased over recent years. From assisting developers
in coding activities to providing conversational agents that answer newcomers'
questions. In collaboration with the Mozilla Foundation, this study evaluates
the effectiveness of Retrieval-Augmented Generation (RAG) in assisting
developers within the Mozilla Firefox project. We conducted an empirical
analysis comparing responses from human developers, a standard GPT model, and a
GPT model enhanced with RAG, using real queries from Mozilla's developer chat
rooms. To ensure a rigorous evaluation, Mozilla experts assessed the responses
based on helpfulness, comprehensiveness, and conciseness. The results show that
RAG-assisted responses were more comprehensive than human developers (62.50% to
54.17%) and almost as helpful (75.00% to 79.17%), suggesting RAG's potential to
enhance developer assistance. However, the RAG responses were not as concise
and often verbose. The results show the potential to apply RAG-based tools to
Open Source Software (OSS) to minimize the load to core maintainers without
losing answer quality. Toning down retrieval mechanisms and making responses
even shorter in the future would enhance developer assistance in massive
projects like Mozilla Firefox.

</details>


### [118] [ArchISMiner: A Framework for Automatic Mining of Architectural Issue-Solution Pairs from Online Developer Communities](https://arxiv.org/abs/2510.21966)
*Musengamana Jean de Dieu,Ruiyin Li,Peng Liang,Mojtaba Shahin,Muhammad Waseem,Arif Ali Khan,Bangchao Wang,Mst Shamima Aktar*

Main category: cs.SE

TL;DR: 本文提出了ArchISMiner框架，自动从Stack Overflow中挖掘软件架构知识，包括识别架构相关帖子和提取架构问题-解决方案对，显著提升了架构知识获取的效率和准确率。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow中软件架构知识分散且结构化不足，开发者人工筛选费时费力，亟需自动化方法提升架构知识定位与提取效率。

Method: ArchISMiner包括ArchPI和ArchISPE两部分：ArchPI通过训练多种模型（传统ML/DL、预训练语言模型、超大语言模型）自动识别架构相关帖子；ArchISPE采用间接监督方法结合BERT和TextCNN特征抽取架构问题-解决方案对。

Result: ArchPI最佳模型在架构帖子识别上F1值达0.960；ArchISPE在架构问题和解决方案抽取分别取得0.883和0.894的F1值，优于SE和NLP领域的基线方法。用户研究验证了识别结果的相关性和实用性。

Conclusion: ArchISMiner能够高效准确地从开发者社区挖掘结构化的架构知识，辅助开发者快速获取有价值的信息，且其成果已扩展至多个论坛，发布了包含1.8万对架构问题-解决方案的数据集。

Abstract: Stack Overflow (SO), a leading online community forum, is a rich source of
software development knowledge. However, locating architectural knowledge, such
as architectural solutions remains challenging due to the overwhelming volume
of unstructured content and fragmented discussions. Developers must manually
sift through posts to find relevant architectural insights, which is
time-consuming and error-prone. This study introduces ArchISMiner, a framework
for mining architectural knowledge from SO. The framework comprises two
complementary components: ArchPI and ArchISPE. ArchPI trains and evaluates
multiple models, including conventional ML/DL models, Pre-trained Language
Models (PLMs), and Large Language Models (LLMs), and selects the
best-performing model to automatically identify Architecture-Related Posts
(ARPs) among programming-related discussions. ArchISPE employs an indirect
supervised approach that leverages diverse features, including BERT embeddings
and local TextCNN features, to extract architectural issue-solution pairs. Our
evaluation shows that the best model in ArchPI achieves an F1-score of 0.960 in
ARP detection, and ArchISPE outperforms baselines in both SE and NLP fields,
achieving F1-scores of 0.883 for architectural issues and 0.894 for solutions.
A user study further validated the quality (e.g., relevance and usefulness) of
the identified ARPs and the extracted issue-solution pairs. Moreover, we
applied ArchISMiner to three additional forums, releasing a dataset of over 18K
architectural issue-solution pairs. Overall, ArchISMiner can help architects
and developers identify ARPs and extract succinct, relevant, and useful
architectural knowledge from developer communities more accurately and
efficiently. The replication package of this study has been provided at
https://github.com/JeanMusenga/ArchISPE

</details>


### [119] [FeaGPT: an End-to-End agentic-AI for Finite Element Analysis](https://arxiv.org/abs/2510.21993)
*Yupeng Qi,Ran Xu,Xu Chu*

Main category: cs.SE

TL;DR: FeaGPT通过自然语言对复杂工程流程（几何-网格-仿真）实现端到端自动化，成功应用于涡轮增压器和机翼设计，推动了工程计算工具的普及。


<details>
  <summary>Details</summary>
Motivation: 当前有限元分析工具往往只自动化单独环节，缺乏端到端的流水线自动化，实现自然语言驱动复杂工程流程的自动化仍是难点。

Method: FeaGPT构建了一个完整的几何、网格、仿真、分析一体化闭环流程，能够理解工程意图，自动生成物理感知的自适应网格，推断边界条件并多目标迭代分析。

Result: 实验验证了端到端自动化能力，在高速旋转涡轮增压器和432个NACA机翼参数化设计场景中，FeaGPT成功将自然语言规格转化为物理合理的数值仿真结果。

Conclusion: 自然语言接口能有效降低高级工程计算工具的使用门槛，实现复杂仿真流程自动化的同时保证分析严谨性，推动工程设计的民主化。

Abstract: Large language models (LLMs) are establishing new paradigms for engineering
applications by enabling natural language control of complex computational
workflows. This paper introduces FeaGPT, the first framework to achieve
complete geometry-mesh-simulation workflows through conversational interfaces.
Unlike existing tools that automate individual FEA components, FeaGPT
implements a fully integrated Geometry-Mesh-Simulation-Analysis (GMSA) pipeline
that transforms engineering specifications into validated computational results
without manual intervention. The system interprets engineering intent,
automatically generates physics-aware adaptive meshes, configures complete FEA
simulations with proper boundary condition inference, and performs
multi-objective analysis through closed-loop iteration.
  Experimental validation confirms complete end-to-end automation capability.
Industrial turbocharger cases (7-blade compressor and 12-blade turbine at
\SI{110000}{rpm}) demonstrate the system successfully transforms natural
language specifications into validated CalculiX simulations, producing
physically realistic results for rotating machinery analysis. Additional
validation through 432 NACA airfoil configurations confirms scalability for
parametric design exploration. These results demonstrate that natural language
interfaces can effectively democratize access to advanced computational
engineering tools while preserving analytical rigor.

</details>


### [120] [CodeAD: Synthesize Code of Rules for Log-based Anomaly Detection with LLMs](https://arxiv.org/abs/2510.22986)
*Junjie Huang,Minghua He,Jinyang Liu,Yintong Huo,Domenico Bianculli,Michael R. Lyu*

Main category: cs.SE

TL;DR: 本文提出了CodeAD框架，利用大语言模型自动生成轻量级Python规则函数，实现对日志的高效、可解释异常检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习和深度学习的日志异常检测方法难以实时、高效处理大规模日志，且可解释性差；传统规则系统虽高效透明但构建成本高且难以扩展。

Method: CodeAD通过分层聚类和锚点采样构建对比日志窗口，利用大语言模型生成、测试、修复和优化规则，自动合成可执行于原始日志的规则函数。

Result: 在BGL、Hadoop和Thunderbird三个公开数据集上，CodeAD的F1得分较现有最先进方法提升约3.6%，处理速度提升4倍，且LLM调用成本控制在每个数据集4美元以内。

Conclusion: CodeAD提供了一个实用且可扩展的自动化日志异常检测方案，实现了高效、透明且低成本的在线监控，适合真实环境中的大规模日志分析。

Abstract: Log-based anomaly detection (LogAD) is critical for maintaining the
reliability and availability of large-scale online service systems. While
machine learning, deep learning, and large language models (LLMs)-based methods
have advanced the LogAD, they often suffer from limited interpretability, high
inference costs, and extensive preprocessing requirements, limiting their
practicality for real-time, high-volume log analysis. In contrast, rule-based
systems offer efficiency and transparency, but require significant manual
effort and are difficult to scale across diverse and evolving environments. In
this paper, We present CodeAD, a novel framework that automatically synthesizes
lightweight Python rule functions for LogAD using LLMs. CodeAD introduces a
hierarchical clustering and anchor-grounded sampling strategy to construct
representative contrastive log windows, enabling LLMs to discern discriminative
anomaly patterns. To ensure robustness and generalizability, CodeAD employs an
agentic workflow that iteratively generates, tests, repairs, and refines the
rules until it meets correctness and abstraction requirements. The synthesized
rules are interpretable, lightweight, and directly executable on raw logs,
supporting efficient and transparent online anomaly detection. Our
comprehensive experiments on three public datasets (BGL, Hadoop, Thunderbird)
demonstrate that CodeAD achieves an average absolute improvement of 3.6% F1
score over the state-of-the-art baselines, while processing large datasets up
to 4x faster and at a fraction of the cost (total LLM invocation cost under 4
USD per dataset). These results highlight CodeAD as a practical and scalable
solution for online monitoring systems, enabling interpretable, efficient, and
automated LogAD in real-world environment.

</details>


### [121] [Impact and Implications of Generative AI for Enterprise Architects in Agile Environments: A Systematic Literature Review](https://arxiv.org/abs/2510.22003)
*Stefan Julian Kooy,Jean Paul Sebastian Piest,Rob Henk Bemthuis*

Main category: cs.SE

TL;DR: 该论文系统回顾了生成式人工智能（GenAI）在敏捷软件组织企业架构中的应用，涵盖设计创新、快速生成和决策支持，并分析了相关风险和能力建设。


<details>
  <summary>Details</summary>
Motivation: 生成式AI正重塑企业架构工作，但对其影响的系统证据较为分散，亟需梳理其应用领域、风险及能力要求。

Method: 采用Kitchenham和PRISMA的系统文献回顾方法，筛选1697篇文献，最终分析33项研究，涵盖企业及IT架构等多种角色。

Result: GenAI主要支持设计创新、快速产出工件及决策支持，但存在模型不透明、偏见输出、隐私合规风险及社会懈怠等问题。还发现了Prompt工程、模型评估等新兴能力，及组织适应性治理等促进因素。

Conclusion: 研究提供了GenAI在敏捷架构中的应用映射、风险与能力建设启示，以及未来人机协作研究议程，有助于负责任地推动GenAI加速数字化转型同时维护架构完整性。

Abstract: Generative AI (GenAI) is reshaping enterprise architecture work in agile
software organizations, yet evidence on its effects remains scattered. We
report a systematic literature review (SLR), following established SLR
protocols of Kitchenham and PRISMA, of 1,697 records, yielding 33 studies
across enterprise, solution, domain, business, and IT architect roles. GenAI
most consistently supports (i) design ideation and trade-off exploration; (ii)
rapid creation and refinement of artifacts (e.g., code, models, documentation);
and (iii) architectural decision support and knowledge retrieval. Reported
risks include opacity and bias, contextually incorrect outputs leading to
rework, privacy and compliance concerns, and social loafing. We also identify
emerging skills and competencies, including prompt engineering, model
evaluation, and professional oversight, and organizational enablers around
readiness and adaptive governance. The review contributes with (1) a mapping of
GenAI use cases and risks in agile architecting, (2) implications for
capability building and governance, and (3) an initial research agenda on
human-AI collaboration in architecture. Overall, the findings inform
responsible adoption of GenAI that accelerates digital transformation while
safeguarding architectural integrity.

</details>


### [122] [LSPRAG: LSP-Guided RAG for Language-Agnostic Real-Time Unit Test Generation](https://arxiv.org/abs/2510.22210)
*Gwihwan Go,Quan Zhang,Chijin Zhou,Zhao Wei,Yu Jiang*

Main category: cs.SE

TL;DR: 本文提出了LSPRAG框架，利用语言服务器协议（LSP）为大语言模型（LLM）实时提供精确的代码上下文，实现跨语言的单元测试生成，显著提升了测试覆盖率。


<details>
  <summary>Details</summary>
Motivation: 目前自动化单元测试生成方法难以跨多语言通用且难以实时应用，现有基于相似度检索或静态分析的方法存在局限性和高成本。

Method: 利用现成的LSP后端实时提供精确的符号定义和引用，结合LLM实现语言无关的简洁上下文检索，从而生成高覆盖的单元测试代码。

Result: 在Java、Go和Python开源项目上的实验表明，LSPRAG相比基线方法分别提升了Golang代码覆盖率174.55%、Java代码覆盖率213.31%、Python代码覆盖率31.57%。

Conclusion: LSPRAG有效解决了多语言实时单元测试生成的上下文获取问题，通过重用成熟的LSP服务，显著提升单元测试覆盖率并降低语言定制成本。

Abstract: Automated unit test generation is essential for robust software development,
yet existing approaches struggle to generalize across multiple programming
languages and operate within real-time development. While Large Language Models
(LLMs) offer a promising solution, their ability to generate high coverage test
code depends on prompting a concise context of the focal method. Current
solutions, such as Retrieval-Augmented Generation, either rely on imprecise
similarity-based searches or demand the creation of costly, language-specific
static analysis pipelines. To address this gap, we present LSPRAG, a framework
for concise-context retrieval tailored for real-time, language-agnostic unit
test generation. LSPRAG leverages off-the-shelf Language Server Protocol (LSP)
back-ends to supply LLMs with precise symbol definitions and references in real
time. By reusing mature LSP servers, LSPRAG provides an LLM with language-aware
context retrieval, requiring minimal per-language engineering effort. We
evaluated LSPRAG on open-source projects spanning Java, Go, and Python.
Compared to the best performance of baselines, LSPRAG increased line coverage
by up to 174.55% for Golang, 213.31% for Java, and 31.57% for Python.

</details>


### [123] [Taming Silent Failures: A Framework for Verifiable AI Reliability](https://arxiv.org/abs/2510.22224)
*Guan-Yan Yang,Farn Wang*

Main category: cs.SE

TL;DR: 本文提出的FAME框架结合形式化方法和运行时监控，有效提升了AI在安全关键系统中的可靠性，成功检测了93.5%的关键安全违规。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键系统中可能产生自信但错误的输出，导致隐蔽故障和安全风险，亟需新的可靠性保障方法。

Method: 提出FAME框架，将离线形式化综合与在线运行监控结合，构建可验证的安全防护网，实现对AI组件的实时安全检测。

Result: 在自动驾驶感知系统中，FAME成功检测出93.5%的关键安全违规事件，有效降低了隐蔽故障的风险。

Conclusion: FAME为安全关键系统中的AI集成提供了一个可证实的安全保障路径，标志着从依赖概率性性能到强制实现可证明安全的转变。

Abstract: The integration of Artificial Intelligence (AI) into safety-critical systems
introduces a new reliability paradigm: silent failures, where AI produces
confident but incorrect outputs that can be dangerous. This paper introduces
the Formal Assurance and Monitoring Environment (FAME), a novel framework that
confronts this challenge. FAME synergizes the mathematical rigor of offline
formal synthesis with the vigilance of online runtime monitoring to create a
verifiable safety net around opaque AI components. We demonstrate its efficacy
in an autonomous vehicle perception system, where FAME successfully detected
93.5% of critical safety violations that were otherwise silent. By
contextualizing our framework within the ISO 26262 and ISO/PAS 8800 standards,
we provide reliability engineers with a practical, certifiable pathway for
deploying trustworthy AI. FAME represents a crucial shift from accepting
probabilistic performance to enforcing provable safety in next-generation
systems.

</details>


### [124] [Understanding Self-Admitted Technical Debt in Test Code: An Empirical Study](https://arxiv.org/abs/2510.22249)
*Ibuki Nakamura,Yutaro Kashiwa,Bin Lin,Hajimu Iida*

Main category: cs.SE

TL;DR: 本文研究了测试代码中的自承认技术债务（SATD），发现其类型多样且不直接关联测试异味，同时基于CodeBERT的模型在SATD分类中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于生产代码中的SATD，忽视了测试代码中的SATD及其特性，因此本研究旨在揭示测试代码中SATD的分布、类型及其与测试质量的关系。

Method: 通过分析50个代码仓库中17666条SATD注释（包括测试代码和生产代码），对测试代码中的SATD类型进行分类，并使用多种机器学习模型自动分类SATD注释，评估其性能。

Result: 测试代码中广泛存在SATD，其类型与生产代码不同，且SATD与测试异味无直接关联。CodeBERT模型在SATD类型分类中表现最佳，但不同类型SATD的分类效果存在差异。

Conclusion: 测试代码中的SATD具有独特的特征，需针对性管理。基于CodeBERT的自动分类模型可助力SATD管理，但仍需针对不同类型进一步优化模型表现。

Abstract: Developers often opt for easier but non-optimal implementation to meet
deadlines or create rapid prototypes, leading to additional effort known as
technical debt to improve the code later. Oftentimes, developers explicitly
document the technical debt in code comments, referred to as Self-Admitted
Technical Debt (SATD). Numerous researchers have investigated the impact of
SATD on different aspects of software quality and development processes.
However, most of these studies focus on SATD in production code, often
overlooking SATD in the test code or assuming that it shares similar
characteristics with SATD in production code. In fact, a significant amount of
SATD is also present in the test code, with many instances not fitting into
existing categories for the production code. This study aims to fill this gap
and disclose the nature of SATD in the test code by examining its distribution
and types. Moreover, the relation between its presence and test quality is also
analyzed. Our empirical study, involving 17,766 SATD comments (14,987 from
production code, 2,779 from test code) collected from 50 repositories,
demonstrates that while SATD widely exists in test code, it is not directly
associated with test smells. Our study also presents comprehensive categories
of SATD types in the test code, and machine learning models are developed to
automatically classify SATD comments based on their types for easier
management. Our results show that the CodeBERT-based model outperforms other
machine learning models in terms of recall and F1-score. However, the
performance varies on different types of SATD.

</details>


### [125] [Ten Simple Rules for AI-Assisted Coding in Science](https://arxiv.org/abs/2510.22254)
*Eric W. Bridgeford,Iain Campbell,Zijao Chen,Zhicheng Lin,Harrison Ritz,Joachim Vandekerckhove,Russell A. Poldrack*

Main category: cs.SE

TL;DR: 本文提出了十条AI辅助编码的实用规则，旨在加速科学计算中的软件开发，同时保证代码质量和科学有效性。


<details>
  <summary>Details</summary>
Motivation: AI编码工具虽能加速软件开发，但在科学计算领域的使用引发了对代码质量及科学有效性的担忧。

Method: 围绕问题准备与理解、上下文管理与交互、测试验证、代码质量保证与迭代改进四个关键主题，提出十条平衡利用AI能力与保持科学严谨性的规则。

Result: 规则强调保持人的主导作用，建立严格的验证程序，维护领域专业知识，确保代码可靠、可重复且科学有效。

Conclusion: 这些规则帮助研究者借助AI提升开发速度，同时满足科研诚信要求的高标准代码质量。

Abstract: While AI coding tools have demonstrated potential to accelerate software
development, their use in scientific computing raises critical questions about
code quality and scientific validity. In this paper, we provide ten practical
rules for AI-assisted coding that balance leveraging capabilities of AI with
maintaining scientific and methodological rigor. We address how AI can be
leveraged strategically throughout the development cycle with four key themes:
problem preparation and understanding, managing context and interaction,
testing and validation, and code quality assurance and iterative improvement.
These principles serve to emphasize maintaining human agency in coding
decisions, establishing robust validation procedures, and preserving the domain
expertise essential for methodologically sound research. These rules are
intended to help researchers harness AI's transformative potential for faster
software development while ensuring that their code meets the standards of
reliability, reproducibility, and scientific validity that research integrity
demands.

</details>


### [126] [Harnessing the Power of Large Language Models for Software Testing Education: A Focus on ISTQB Syllabus](https://arxiv.org/abs/2510.22318)
*Tuan-Phong Ngo,Bao-Ngoc Duong,Tuan-Anh Hoang,Joshua Dwight,Ushik Shrestha Khwakhali*

Main category: cs.SE

TL;DR: 本文探讨了大语言模型（LLM）在基于ISTQB的软件测试教育中的应用，构建了ISTQB对齐数据集，设计了优化提示词，并系统评估了多款先进LLM，提出了整合建议。


<details>
  <summary>Details</summary>
Motivation: 软件测试在软件工程和教育中至关重要，当前需更新教育方法以反映领域最新发展，ISTQB认证被广泛采用，但结合LLM的ISTQB教育研究较少。

Method: 作者创建了一个包含超过十年数据、28套模拟考试和1145道题的ISTQB数据集，设计了域优化提示，系统评估多款先进LLM在该任务上的表现。

Result: 发现域优化提示显著提升了LLM在ISTQB任务中的精确度和解释质量，评估结果支持LLM辅助ISTQB认证准备的潜力。

Conclusion: 研究展示了LLM在支持ISTQB教育中的应用前景，提出了将LLM更好融入高等教育软件测试教学的具体建议，为软件工程教育数字化转型提供基础。

Abstract: Software testing is a critical component in the software engineering field
and is important for software engineering education. Thus, it is vital for
academia to continuously improve and update educational methods to reflect the
current state of the field. The International Software Testing Qualifications
Board (ISTQB) certification framework is globally recognized and widely adopted
in industry and academia. However, ISTQB-based learning has been rarely applied
with recent generative artificial intelligence advances. Despite the growing
capabilities of large language models (LLMs), ISTQB-based learning and
instruction with LLMs have not been thoroughly explored. This paper explores
and evaluates how LLMs can complement the ISTQB framework for higher education.
The findings present four key contributions: (i) the creation of a
comprehensive ISTQB-aligned dataset spanning over a decade, consisting of 28
sample exams and 1,145 questions; (ii) the development of a domain-optimized
prompt that enhances LLM precision and explanation quality on ISTQB tasks;
(iii) a systematic evaluation of state-of-the-art LLMs on this dataset; and
(iv) actionable insights and recommendations for integrating LLMs into software
testing education. These findings highlight the promise of LLMs in supporting
ISTQB certification preparation and offer a foundation for their broader use in
software engineering at higher education.

</details>


### [127] [Operationalizing Large Language Models with Design-Aware Contexts for Code Comment Generation](https://arxiv.org/abs/2510.22338)
*Aritra Mitra,Srijoni Majumdar,Anamitra Mukhopadhyay,Partha Pratim Das,Paul D Clough,Partha Pratim Chakrabarti*

Main category: cs.SE

TL;DR: 研究探讨了利用大型语言模型（LLMs）生成改进的代码注释，尤其是在注释质量差且缺乏标准的初学者代码中。


<details>
  <summary>Details</summary>
Motivation: 初学者代码注释质量低，缺乏标准，导致维护时间增加，研究希望通过LLMs提升注释的有用性。

Method: 以设计文档作为上下文输入给LLMs，评估其生成更有用注释的可行性。

Result: （摘要未给出具体结果）

Conclusion: 设计文档作为上下文有助于LLMs生成更实用的代码注释，能辅助代码维护。

Abstract: Comments are very useful to the flow of code development. With the increasing
commonality of code, novice coders have been creating a significant amount of
codebases. Due to lack of commenting standards, their comments are often
useless, and increase the time taken to further maintain codes. This study
intends to find the usefulness of large language models (LLMs) in these cases
to generate potentially better comments. This study focuses on the feasibility
of design documents as a context for the LLMs to generate more useful comments,
as design documents are often used by maintainers to understand code when
comments do not suffice.

</details>


### [128] [A First Look at the Self-Admitted Technical Debt in Test Code: Taxonomy and Detection](https://arxiv.org/abs/2510.22409)
*Shahidul Islam,Md Nahidul Islam Opu,Shaowei Wang,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 本文首次大规模研究了测试代码中的自承认技术债务（SATD），通过分析开源Java项目中的注释，构建了测试代码SATD的分类体系，并评估了现有检测工具和大型语言模型的检测效果，发现现有方法检测效果有限。


<details>
  <summary>Details</summary>
Motivation: 虽然已有大量研究关注源代码中的SATD，但测试代码中的SATD未被重点研究，缺乏对其存在形式及影响的理解。

Method: 随机抽取1.6百万注释中的5万条进行手动分析，识别并分类615条测试代码中的SATD注释，构建15类SATD分类体系；评估现有SATD检测工具与开源及商业大型语言模型的检测能力。

Result: 识别出测试代码中15种SATD类型，现有检测工具中MAT表现最好但召回率一般，大型语言模型因精度低表现差，说明当前方法难以可靠检测测试代码中的SATD。

Conclusion: 首次大规模分析测试代码中SATD，明确其分类及现有检测方法的局限性，为未来针对测试代码SATD的研究奠定基础。

Abstract: Self-admitted technical debt (SATD) refers to comments in which developers
explicitly acknowledge code issues, workarounds, or suboptimal solutions. SATD
is known to significantly increase software maintenance effort. While extensive
research has examined SATD in source code, its presence and impact in test code
have received no focused attention, leaving a significant gap in our
understanding of how SATD manifests in testing contexts.
  This study, the first of its kind, investigates SATD in test code by manually
analyzing 50,000 comments randomly sampled from 1.6 million comments across
1,000 open-source Java projects. From this sample, after manual analysis and
filtering, we identified 615 SATD comments and classified them into 15 distinct
categories, building a taxonomy of test code SATD. To investigate whether test
code SATD can be detected automatically, we evaluated existing SATD detection
tools, as well as both open-source and proprietary LLMs. Among the existing
tools, MAT performed the best, albeit with moderate recall. To our surprise,
both open-source and proprietary LLMs exhibited poor detection accuracy,
primarily due to low precision. These results indicate that neither existing
approaches nor current LLMs can reliably detect SATD in test code.
  Overall, this work provides the first large-scale analysis of SATD in test
code, a nuanced understanding of its types, and the limitations of current SATD
detection methods. Our findings lay the groundwork for future research on test
code-specific SATD.

</details>


### [129] [A Multifaceted View on Discrimination in Software Development Careers](https://arxiv.org/abs/2510.22457)
*Shalini Chakraborty,Sebastian Baltes*

Main category: cs.SE

TL;DR: 软件工程中的歧视不仅限于性别和种族，还包括年龄、政治观点、残疾和认知差异等多个方面。研究发现年龄和性别歧视最常见，政治和宗教歧视也值得关注。女性和非二元性别者经历更多歧视和心理健康问题。


<details>
  <summary>Details</summary>
Motivation: 现有对软件工程领域的多样性和包容性讨论主要集中在性别和种族差异，而其他歧视形式被忽视。希望揭示更广泛的歧视现象，提高研究社群对此的关注。

Method: 对2025年开发者国度调查的8,717名参与者中800个开放式回答进行二次分析，探究不同身份特征下感知歧视的模式、相关挑战和负面影响。

Result: 年龄和性别相关歧视最为普遍，政治与宗教歧视亦显著。女性多受多重交叉身份因素影响而遭遇歧视。所有性别均报告照顾责任相关歧视。女性及非二元性别者在工作场所面临更高比例的歧视和心理健康问题。

Conclusion: 软件开发领域的歧视是多方面的，研究者应超越年龄和性别，关注更多身份维度，设计更全面的研究以助提升多样性与包容性。

Abstract: Conversations around diversity and inclusion in software engineering often
focus on gender and racial disparities. However, the State of the Developer
Nation 2025 survey with 8,717 participants revealed that other forms of
discrimination are similarly prevalent but receive considerably less attention.
This includes discrimination based on age, political perspective, disabilities,
or cognitive differences such as neurodivergence. We conducted a secondary
analysis of 800 open-ended survey responses to examine patterns of perceived
discrimination, as well as related challenges and negative impacts. Our study
covers multiple identity facets, including age, gender, race, and disability.
We found that age- and gender-related discrimination was the most frequently
reported workplace issue, but discrimination based on political and religious
views emerged as further notable concerns. Most of the participants who
identified as female cited gender as the primary source of discrimination,
often accompanied by intersectional factors such as race, political views, age,
or sexual orientation. Discrimination related to caregiving responsibilities
was reported by all gender identities. Regarding the negative impacts of
workplace issues, many participants described modifying their appearance or
behavior in response to gender biases. Gender also appeared to influence
broader career challenges, as women and non-binary respondents reported
experiencing almost all workplace issues at higher rates, particularly
discrimination (35%) and mental health challenges (62%). Our goal is to raise
awareness in the research community that discrimination in software development
is multifaceted, and to encourage researchers to select and assess relevant
facets beyond age and gender when designing software engineering studies.

</details>


### [130] [Finding the Needle in the Crash Stack: Industrial-Scale Crash Root Cause Localization with AutoCrashFL](https://arxiv.org/abs/2510.22530)
*Sungmin Kang,Sumi Yun,Jingun Hong,Shin Yoo,Gabin An*

Main category: cs.SE

TL;DR: 本文提出了AutoCrashFL，一种基于大语言模型的崩溃定位工具，通过仅利用崩溃转储和源码仓库定位程序缺陷，提升了定位准确率，适用于大型工业软件。


<details>
  <summary>Details</summary>
Motivation: 传统的故障定位依赖动态分析如覆盖率或变异测试，但在大型工业软件中运行成本过高，限制了其应用。

Method: 提出AutoCrashFL，基于大语言模型代理只需程序崩溃转储和源代码仓库，不依赖动态执行信息进行故障定位。

Result: 在SAP HANA工业软件真实崩溃数据上，AutoCrashFL实现了30%的崩溃准确定位，明显优于基线17%的定位率。

Conclusion: AutoCrashFL展现了在工业级大型软件上的实用性和较高定位效率，特别对复杂缺陷更有效，并能给出结果置信度，证明了大语言模型代理在工程中的应用前景。

Abstract: Fault Localization (FL) aims to identify root causes of program failures. FL
typically targets failures observed from test executions, and as such, often
involves dynamic analyses to improve accuracy, such as coverage profiling or
mutation testing. However, for large industrial software, measuring coverage
for every execution is prohibitively expensive, making the use of such
techniques difficult. To address these issues and apply FL in an industrial
setting, this paper proposes AutoCrashFL, an LLM agent for the localization of
crashes that only requires the crashdump from the Program Under Test (PUT) and
access to the repository of the corresponding source code. We evaluate
AutoCrashFL against real-world crashes of SAP HANA, an industrial software
project consisting of more than 35 million lines of code. Experiments reveal
that AutoCrashFL is more effective in localization, as it identified 30%
crashes at the top, compared to 17% achieved by the baseline. Through thorough
analysis, we find that AutoCrashFL has attractive practical properties: it is
relatively more effective for complex bugs, and it can indicate confidence in
its results. Overall, these results show the practicality of LLM agent
deployment on an industrial scale.

</details>


### [131] [DynaCausal: Dynamic Causality-Aware Root Cause Analysis for Distributed Microservices](https://arxiv.org/abs/2510.22613)
*Songhan Zhang,Aoyang Fang,Yifan Yang,Ruiyi Cheng,Xiaoying Tang,Pinjia He*

Main category: cs.SE

TL;DR: 本文提出了DynaCausal框架，通过动态因果关系建模和多模态信号融合，有效提升云原生微服务系统中的根因分析准确率。


<details>
  <summary>Details</summary>
Motivation: 当前微服务系统中的故障根因分析面临动态依赖复杂、噪声干扰和服务行为漂移等挑战，传统方法难以准确定位根因。

Method: DynaCausal通过交互感知表示学习捕捉时空依赖，引入动态对比机制去除噪声，并采用因果优先的排序目标优化因果归因。

Result: 在公开基准测试中，DynaCausal平均AC@1达到0.63，较最优方法提升0.25至0.46，表现出更高的准确性和解释性。

Conclusion: DynaCausal有效解决了微服务系统中根因分析的三大难点，实现了高精度和可解释性的动态诊断。

Abstract: Cloud-native microservices enable rapid iteration and scalable deployment but
also create complex, fast-evolving dependencies that challenge reliable
diagnosis. Existing root cause analysis (RCA) approaches, even with multi-modal
fusion of logs, traces, and metrics, remain limited in capturing dynamic
behaviors and shifting service relationships. Three critical challenges
persist: (i) inadequate modeling of cascading fault propagation, (ii)
vulnerability to noise interference and concept drift in normal service
behavior, and (iii) over-reliance on service deviation intensity that obscures
true root causes. To address these challenges, we propose DynaCausal, a dynamic
causality-aware framework for RCA in distributed microservice systems.
DynaCausal unifies multi-modal dynamic signals to capture time-varying
spatio-temporal dependencies through interaction-aware representation learning.
It further introduces a dynamic contrastive mechanism to disentangle true fault
indicators from contextual noise and adopts a causal-prioritized pairwise
ranking objective to explicitly optimize causal attribution. Comprehensive
evaluations on public benchmarks demonstrate that DynaCausal consistently
surpasses state-of-the-art methods, attaining an average AC@1 of 0.63 with
absolute gains from 0.25 to 0.46, and delivering both accurate and
interpretable diagnoses in highly dynamic microservice environments.

</details>


### [132] [Does In-IDE Calibration of Large Language Models work at Scale?](https://arxiv.org/abs/2510.22614)
*Roham Koohestani,Agnia Sergeyuk,David Gros,Claudio Spiess,Sergey Titov,Prem Devanbu,Maliheh Izadi*

Main category: cs.SE

TL;DR: 本文研究了在集成开发环境中对代码生成模型进行可信度校准的方法及其有效性，结合大规模用户数据分析和设计研究，提出了校准框架和人机交互设计建议。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在IDE中的引入带来代码生成的可靠性挑战，需通过可信度校准提升模型置信度与开发者接受度的一致性。

Method: 开发可扩展的后验校准框架，基于Platt-scaling方法进行校准，分析2400万次开发者交互数据，并开展多阶段设计研究探讨最佳交互呈现方式。

Result: 整体而言，通用后验校准模型未显著提升置信度信号的可靠性，动态个性化校准在数据量足够时效果较好，设计研究显示开发者偏好非数字化、色彩编码的可靠性指示。

Conclusion: 校准方法的有效性依赖于用户数据量，且校准信息的呈现形式对开发者接受度影响显著，建议结合技术和设计优化模型置信度展示以提升开发体验。

Abstract: The introduction of large language models into integrated development
environments (IDEs) is revolutionizing software engineering, yet it poses
challenges to the usefulness and reliability of Artificial
Intelligence-generated code. Post-hoc calibration of internal model confidences
aims to align probabilities with an acceptability measure. Prior work suggests
calibration can improve alignment, but at-scale evidence is limited. In this
work, we investigate the feasibility of applying calibration of code models to
an in-IDE context. We study two aspects of the problem: (1) the technical
method for implementing confidence calibration and improving the reliability of
code generation models, and (2) the human-centered design principles for
effectively communicating reliability signal to developers. First, we develop a
scalable and flexible calibration framework which can be used to obtain
calibration weights for open-source models using any dataset, and evaluate
whether calibrators improve the alignment between model confidence and
developer acceptance behavior. Through a large-scale analysis of over 24
million real-world developer interactions across multiple programming
languages, we find that a general, post-hoc calibration model based on
Platt-scaling does not, on average, improve the reliability of model confidence
signals. We also find that while dynamically personalizing calibration to
individual users can be effective, its effectiveness is highly dependent on the
volume of user interaction data. Second, we conduct a multi-phase design study
with 3 expert designers and 153 professional developers, combining
scenario-based design, semi-structured interviews, and survey validation,
revealing a clear preference for presenting reliability signals via
non-numerical, color-coded indicators within the in-editor code generation
workflow.

</details>


### [133] [Collaborative LLM Agents for C4 Software Architecture Design Automation](https://arxiv.org/abs/2510.22787)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.SE

TL;DR: 提出了一种基于大语言模型的多代理系统，自动生成软件架构中的C4模型，实现快速且高质量的软件架构设计。


<details>
  <summary>Details</summary>
Motivation: 软件架构设计虽然重要，但手动制作C4模型繁琐耗时，急需自动化方法。

Method: 通过模拟不同角色专家的对话，多代理系统根据需求生成C4模型的Context、Container和Component视图；采用混合评估框架，包括结构检查和LLM作为评判者的语义、质量评分。

Result: 在五个经典系统案例中，该方法快速生成C4模型，成功率高且具备良好的语义一致性；并比较了四种先进的大语言模型在架构设计中的优势。

Conclusion: 该研究推动了软件架构设计的自动化和评价方法的进步，提高了设计效率和质量。

Abstract: Software architecture design is a fundamental part of creating every software
system. Despite its importance, producing a C4 software architecture model, the
preferred notation for such architecture, remains manual and time-consuming. We
introduce an LLM-based multi-agent system that automates this task by
simulating a dialogue between role-specific experts who analyze requirements
and generate the Context, Container, and Component views of the C4 model.
Quality is assessed with a hybrid evaluation framework: deterministic checks
for structural and syntactic integrity and C4 rule consistency, plus semantic
and qualitative scoring via an LLM-as-a-Judge approach. Tested on five
canonical system briefs, the workflow demonstrates fast C4 model creation,
sustains high compilation success, and delivers semantic fidelity. A comparison
of four state-of-the-art LLMs shows different strengths relevant to
architectural design. This study contributes to automated software architecture
design and its evaluation methods.

</details>


### [134] [On the Freshness of Pinned Dependencies in Maven](https://arxiv.org/abs/2510.22815)
*Vasudev Vikram,Yuvraj Agarwal,Rohan Padhye*

Main category: cs.SE

TL;DR: 本文研究了软件库依赖的固定版本（pinning）现象及其风险，提出了Pin-Freshener工具利用众包测试促进安全升级。


<details>
  <summary>Details</summary>
Motivation: 固定依赖版本虽确保构建可重现但存在使用过时依赖带来安全漏洞的风险，需理解pinning频率及影响。

Method: 定义stale和fresh pins，调查Maven库中固定版本的现状，设计Pin-Freshener利用众包测试为升级提供安全信号。

Result: 发现60%以上的Maven库消费者存在过时固定版本，升级能减少10%的安全漏洞；Pin-Freshener使用1-5个额外测试套件能提升依赖覆盖率35-100%。

Conclusion: Pin-Freshener能为开发者提供额外的测试信号，帮助安全地升级依赖，优于当前固定版本的实践方式。

Abstract: Library dependencies in software ecosystems play a crucial role in the
development of software. As newer releases of these libraries are published,
developers may opt to pin their dependencies to a particular version. While
pinning may have benefits in ensuring reproducible builds and avoiding breaking
changes, it bears larger risks in using outdated dependencies that may contain
bugs and security vulnerabilities. To understand the frequency and consequences
of dependency pinning, we first define the concepts of stale and fresh pins,
which are distinguished based on how outdated the dependency is relative to the
release date of the project. We conduct an empirical study to show that over
60% of consumers of popular Maven libraries contain stale pins to their
dependencies, with some outdated versions over a year old. These pinned
versions often miss out on security fixes; we find that 10% of all dependency
upgrades in our dataset to the latest minor or patch version would reduce
security vulnerabilities.
  We prototype an approach called Pin-Freshener that can encourage developers
to freshen their pins by leveraging the insight that crowdsourced tests of peer
projects can provide additional signal for the safety of an upgrade. Running
Pin-Freshener on dependency upgrades shows that just 1-5 additional test suites
can provide 35-100% more coverage of a dependency, compared to that of a single
consumer test suite. Our evaluation on real-world pins to the top 500 popular
libraries in Maven shows that Pin-Freshener can provide an additional signal of
at least 5 passing crowdsourced test suites to over 3,000 consumers to safely
perform an upgrade that reduces security vulnerabilities. Pin-Freshener can
provide practical confidence to developers by offering additional signal beyond
their own test suites, representing an improvement over current practices.

</details>


### [135] [TALM: Dynamic Tree-Structured Multi-Agent Framework with Long-Term Memory for Scalable Code Generation](https://arxiv.org/abs/2510.23010)
*Ming-Tung Shen,Yuh-Jzer Joung*

Main category: cs.SE

TL;DR: 提出了TALM框架，通过树状多代理结构和长期记忆机制提升代码生成的多步推理能力和错误修正效率。


<details>
  <summary>Details</summary>
Motivation: 现有多代理框架在代码生成中的推理恢复成本高且工作流程僵硬，需要更灵活高效的协作机制。

Method: 设计了基于树结构的多代理协作框架TALM，引入局部重推理和长期记忆模块以实现任务分解、上下文管理及经验复用。

Result: 在多个代码生成基准测试上，TALM表现出强推理性能和高令牌效率，证明其鲁棒性和实用性。

Conclusion: TALM通过结构化协作和记忆机制有效提升了复杂代码生成任务中的推理能力和错误纠正，具备广泛应用潜力。

Abstract: Agentic code generation requires large language models (LLMs) capable of
complex context management and multi-step reasoning. Prior multi-agent
frameworks attempt to address these challenges through collaboration, yet they
often suffer from rigid workflows and high reasoning recovery costs. To
overcome these limitations, we propose TALM (Tree-Structured Multi-Agent
Framework with Long-Term Memory), a dynamic framework that integrates
structured task decomposition, localized re-reasoning, and long-term memory
mechanisms. TALM employs an extensible tree-based collaboration structure. The
parent-child relationships, when combined with a divide-and-conquer strategy,
enhance reasoning flexibility and enable efficient error correction across
diverse task scopes. Furthermore, a long-term memory module enables semantic
querying and integration of prior knowledge, supporting implicit
self-improvement through experience reuse. Experimental results on HumanEval,
BigCodeBench, and ClassEval benchmarks demonstrate that TALM consistently
delivers strong reasoning performance and high token efficiency, highlighting
its robustness and practical utility in complex code generation tasks.

</details>


### [136] [From Online User Feedback to Requirements: Evaluating Large Language Models for Classification and Specification Tasks](https://arxiv.org/abs/2510.23055)
*Manjeshwar Aniruddh Mallya,Alessio Ferrari,Mohammad Amin Zadenoori,Jacek Dąbrowski*

Main category: cs.SE

TL;DR: 本文评估了五种轻量级开源大语言模型在需求工程相关任务中的表现，结果显示这些模型在用户请求分类、非功能性需求分类及需求规格生成任务上表现良好，并提供了复现实验包。


<details>
  <summary>Details</summary>
Motivation: 在线用户反馈信息庞大且噪声多，分析难度大，而大语言模型具备自动化处理和生成需求规格的潜力，但目前该领域研究有限，实证和复现不足。

Method: 评估五种轻量级开源大语言模型在三个需求工程任务上的表现：用户请求分类、非功能性需求分类及需求规格生成，使用两个反馈数据集测量分类准确率，人工评价生成需求规格质量。

Result: 轻量级大语言模型取得中等到高的分类准确率（F1值约0.47-0.68）和中等偏高的需求规格质量评分（平均约3分/5分）。

Conclusion: 轻量级大语言模型在基于用户反馈的需求开发中具有潜力，论文提供实证评估、复现实验包及其应用优势和局限性的见解。

Abstract: [Context and Motivation] Online user feedback provides valuable information
to support requirements engineering (RE). However, analyzing online user
feedback is challenging due to its large volume and noise. Large language
models (LLMs) show strong potential to automate this process and outperform
previous techniques. They can also enable new tasks, such as generating
requirements specifications.
  [Question-Problem] Despite their potential, the use of LLMs to analyze user
feedback for RE remains underexplored. Existing studies offer limited empirical
evidence, lack thorough evaluation, and rarely provide replication packages,
undermining validity and reproducibility.
  [Principal Idea-Results] We evaluate five lightweight open-source LLMs on
three RE tasks: user request classification, NFR classification, and
requirements specification generation. Classification performance was measured
on two feedback datasets, and specification quality via human evaluation. LLMs
achieved moderate-to-high classification accuracy (F1 ~ 0.47-0.68) and
moderately high specification quality (mean ~ 3/5).
  [Contributions] We newly explore lightweight LLMs for feedback-driven
requirements development. Our contributions are: (i) an empirical evaluation of
lightweight LLMs on three RE tasks, (ii) a replication package, and (iii)
insights into their capabilities and limitations for RE.

</details>


### [137] [Checkstyle+: Reducing Technical Debt Through The Use of Linters with LLMs](https://arxiv.org/abs/2510.23068)
*Ella Dodor,Cristina V. Lopes*

Main category: cs.SE

TL;DR: 本文提出了结合大语言模型的混合代码风格检测工具Checkstyle+，在检测语义复杂的风格违规方面优于传统的Checkstyle。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的代码风格检测工具在诸如Java等编程语言中，难以捕捉需要语义理解的复杂风格违规。

Method: 提出Checkstyle+，通过整合大语言模型增强传统Checkstyle的检测能力，补充传统静态分析的不足。

Result: 在380份真实Java代码样本上的实验显示，Checkstyle+在发现语义层面的风格违规方面表现优于标准的Checkstyle。

Conclusion: 将大语言模型集成进代码风格检测工具可显著提升对复杂风格违规的识别效果，提高软件质量管理水平。

Abstract: Good code style improves program readability, maintainability, and
collaboration, and is an integral component of software quality. Developers,
however, often cut corners when following style rules, leading to the wide
adoption of tools such as linters in professional software development
projects. Traditional linters like Checkstyle operate using rigid, rule-based
mechanisms that effectively detect many surface-level violations. However, in
most programming languages, there is a subset of style rules that require a
more nuanced understanding of code, and fall outside the scope of such static
analysis. In this paper, we propose Checkstyle+, a hybrid approach that
augments Checkstyle with large language model (LLM) capabilities, to identify
style violations that elude the conventional rule-based analysis. Checkstyle+
is evaluated on a sample of 380 Java code files, drawn from a broader dataset
of 30,800 real-world Java programs sourced from accepted Codeforces
submissions. The results show that Checkstyle+ achieves superior performance
over standard Checkstyle in detecting violations of the semantically nuanced
rules.

</details>


### [138] [Validating Formal Specifications with LLM-generated Test Cases](https://arxiv.org/abs/2510.23350)
*Alcino Cunha,Nuno Macedo*

Main category: cs.SE

TL;DR: 本文评估了利用预训练大语言模型（如GPT-5）自动生成测试用例以验证形式化规格，结果表明GPT-5在生成语法正确且符合需求的测试用例方面表现良好，能有效检测错误规格。


<details>
  <summary>Details</summary>
Motivation: 传统生成形式化规格的测试用例既繁琐又容易出错，导致用户可能跳过验证步骤，需要一种自动化且可靠的测试用例生成方法。

Method: 研究利用预训练大型语言模型，特别是GPT-5，从自然语言需求中自动生成用于验证简单领域模型的结构性测试用例，比较了多种闭源和开源模型的效果。

Result: GPT-5能够生成语法正确、满足或不满足特定需求的正负测试用例，且能识别许多人工错误规格，效果优于其他模型。

Conclusion: 预训练大语言模型，尤其是GPT-5，是自动生成正负测试用例以辅助形式化规格验证的有效工具，能够降低人工负担并提升验证质量。

Abstract: Validation is a central activity when developing formal specifications.
Similarly to coding, a possible validation technique is to define upfront test
cases or scenarios that a future specification should satisfy or not.
Unfortunately, specifying such test cases is burdensome and error prone, which
could cause users to skip this validation task. This paper reports the results
of an empirical evaluation of using pre-trained large language models (LLMs) to
automate the generation of test cases from natural language requirements. In
particular, we focus on test cases for structural requirements of simple domain
models formalized in the Alloy specification language. Our evaluation focuses
on the state-of-art GPT-5 model, but results from other closed- and open-source
LLMs are also reported. The results show that, in this context, GPT-5 is
already quite effective at generating positive (and negative) test cases that
are syntactically correct and that satisfy (or not) the given requirement, and
that can detect many wrong specifications written by humans.

</details>


### [139] [Floating-Point Neural Network Verification at the Software Level](https://arxiv.org/abs/2510.23389)
*Edoardo Manino,Bruno Farias,Rafael Sá Menezes,Fedor Shmarov,Lucas C. Cordeiro*

Main category: cs.SE

TL;DR: 本文提出了一个新的神经网络软件级别的验证基准NeuroCodeBench 2.0，评测了当前八种自动验证工具对神经网络代码的性能，发现其仅能正确验证约11%，并指出该基准对验证工具的发展有积极影响。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络验证技术无法在软件层面保证无故障，尤其浮点实现的正确性未被显式验证，制约其在安全关键系统中的部署。

Method: 构建了NeuroCodeBench 2.0，包含912个神经网络验证例子，涵盖激活函数、常见层和包含17万个参数的完整网络，基于纯C语言并兼容SV-COMP格式，利用该基准系统地评估八种最先进的软件自动验证器。

Result: 自动验证工具平均只正确解决了11%的测试用例，同时有约3%的错误判断。基准发布后，历史分析表明它对工具性能提升产生了积极影响。

Conclusion: 软件层面的神经网络安全验证依然存在较大挑战，NeuroCodeBench 2.0为验证工具的评测和提升提供了重要平台，推动了神经网络软件安全验证技术的发展。

Abstract: The behaviour of neural network components must be proven correct before
deployment in safety-critical systems. Unfortunately, existing neural network
verification techniques cannot certify the absence of faults at the software
level. In this paper, we show how to specify and verify that neural networks
are safe, by explicitly reasoning about their floating-point implementation. In
doing so, we construct NeuroCodeBench 2.0, a benchmark comprising 912 neural
network verification examples that cover activation functions, common layers,
and full neural networks of up to 170K parameters. Our verification suite is
written in plain C and is compatible with the format of the International
Competition on Software Verification (SV-COMP). Thanks to it, we can conduct
the first rigorous evaluation of eight state-of-the-art software verifiers on
neural network code. The results show that existing automated verification
tools can correctly solve an average of 11% of our benchmark, while producing
around 3% incorrect verdicts. At the same time, a historical analysis reveals
that the release of our benchmark has already had a significantly positive
impact on the latter.

</details>


### [140] [Tracing Distribution Shifts with Causal System Maps](https://arxiv.org/abs/2510.23528)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 该论文提出了ML系统地图，一种因果图，通过层次视图明确环境与ML系统内部之间的传播路径，实现分布转移的系统归因。


<details>
  <summary>Details</summary>
Motivation: 当前ML系统监控困难，常见做法只检测分布转移，而根因分析依赖人工追踪，无法有效识别引起转移的具体原因，如软件故障、数据质量问题或自然变化。

Method: 提出了ML系统地图，通过因果图和层次化视图展示环境和ML系统内部各组件间的因果传播路径，支持系统地归因分布转移的原因。

Result: 该方法能够系统化识别分布转移的根因，减少人为追踪，提高监控的准确性和效率。文章还提出了相关的研究议程，旨在进一步发展和评估该方法。

Conclusion: ML系统地图为监控ML系统中分布转移的根因分析提供了一种有效工具，促进了更深入和系统的异常诊断。

Abstract: Monitoring machine learning (ML) systems is hard, with standard practice
focusing on detecting distribution shifts rather than their causes. Root-cause
analysis often relies on manual tracing to determine whether a shift is caused
by software faults, data-quality issues, or natural change. We propose ML
System Maps -- causal maps that, through layered views, make explicit the
propagation paths between the environment and the ML system's internals,
enabling systematic attribution of distribution shifts. We outline the approach
and a research agenda for its development and evaluation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [141] [Collaborative Task Assignment, Sequencing and Multi-agent Path-finding](https://arxiv.org/abs/2510.21738)
*Yifan Bai,Shruti Kotpalliwar,Christoforos Kanellakis,George Nikolakopoulos*

Main category: cs.MA

TL;DR: 本文提出了针对多智能体任务分配、排序及路径规划问题（TSPF）的最优算法CBS-TS，通过混合整数线性规划优化任务序列，结合基于冲突的搜索实现碰撞避免，提升了计算效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体在完成多个任务时的任务分配、排序及路径冲突问题，实现无碰撞且优化流时间的任务完成方案。

Method: 提出Conflict-Based Search with Task Sequencing (CBS-TS)算法，交替使用混合整数线性规划优化任务顺序和基于冲突的搜索（CBS）结合多标签A*进行路径规划，有效控制搜索空间。

Result: 实验表明，CBS-TS在大多数测试场景中优于改进的基线方法CBSS，表现出更高的成功率和始终最优的解决方案。

Conclusion: CBS-TS有效提升了多智能体任务调度与路径规划的性能，实现了计算效率和结果最优性的良好平衡。

Abstract: In this article, we address the problem of collaborative task assignment,
sequencing, and multi-agent pathfinding (TSPF), where a team of agents must
visit a set of task locations without collisions while minimizing flowtime.
TSPF incorporates agent-task compatibility constraints and ensures that all
tasks are completed. We propose a Conflict-Based Search with Task Sequencing
(CBS-TS), an optimal and complete algorithm that alternates between finding new
task sequences and resolving conflicts in the paths of current sequences.
CBS-TS uses a mixed-integer linear program (MILP) to optimize task sequencing
and employs Conflict-Based Search (CBS) with Multi-Label A* (MLA*) for
collision-free path planning within a search forest. By invoking MILP for the
next-best sequence only when needed, CBS-TS efficiently limits the search
space, enhancing computational efficiency while maintaining optimality. We
compare the performance of our CBS-TS against Conflict-based Steiner Search
(CBSS), a baseline method that, with minor modifications, can address the TSPF
problem. Experimental results demonstrate that CBS-TS outperforms CBSS in most
testing scenarios, achieving higher success rates and consistently optimal
solutions, whereas CBSS achieves near-optimal solutions in some cases. The
supplementary video is available at https://youtu.be/QT8BYgvefmU.

</details>


### [142] [LLM-augmented empirical game theoretic simulation for social-ecological systems](https://arxiv.org/abs/2510.21965)
*Jennifer Shi,Christopher K. Frantz,Christian Kimmich,Saba Siddiki,Atrisha Sarkar*

Main category: cs.MA

TL;DR: 本文比较了四种结合大语言模型（LLM）的方法在社会生态系统建模中的表现，发现不同方法产生了显著不同的集体行为模式，强调了多样方法的重要性，并指出基于专家指导的EGTA模型通过参数化收益塑造行为效果更佳。


<details>
  <summary>Details</summary>
Motivation: 设计适应社会生态系统的制度需要捕捉个体差异、不确定性和战略互动，但现有多种模型方法如何整合以及生成行为的合理性尚不明确。

Method: 比较四种LLM增强的建模框架：程序化ABM、生成式ABM、LLM-EGTA和专家指导的LLM-EGTA，并在阿姆河流域灌溉和捕鱼治理的案例中评估其表现。

Result: 不同模型产生了显著不同的集体行为模式，展示了方法多样性的价值；通过系统提示诱导LLM行为效果不如通过参数化收益的专家指导EGTA模型。

Conclusion: 模型多样性对捕捉社会生态系统中的复杂行为十分重要，且专家引导的基于收益参数的EGTA模型能更有效地塑造合理行为。

Abstract: Designing institutions for social-ecological systems requires models that
capture heterogeneity, uncertainty, and strategic interaction. Multiple
modeling approaches have emerged to meet this challenge, including empirical
game-theoretic analysis (EGTA), which merges ABM's scale and diversity with
game-theoretic models' formal equilibrium analysis. The newly popular class of
LLM-driven simulations provides yet another approach, and it is not clear how
these approaches can be integrated with one another, nor whether the resulting
simulations produce a plausible range of behaviours for real-world
social-ecological governance. To address this gap, we compare four
LLM-augmented frameworks: procedural ABMs, generative ABMs, LLM-EGTA, and
expert guided LLM-EGTA, and evaluate them on a real-world case study of
irrigation and fishing in the Amu Darya basin under centralized and
decentralized governance. Our results show: first, procedural ABMs, generative
ABMs, and LLM-augmented EGTA models produce strikingly different patterns of
collective behaviour, highlighting the value of methodological diversity.
Second, inducing behaviour through system prompts in LLMs is less effective
than shaping behaviour through parameterized payoffs in an expert-guided
EGTA-based model.

</details>


### [143] [CreditXAI: A Multi-Agent System for Explainable Corporate Credit Rating](https://arxiv.org/abs/2510.22222)
*Yumeng Shi,Zhongliang Yang,Yisi Wang,Linna Zhou*

Main category: cs.MA

TL;DR: 本文提出了CreditXAI多智能体系统框架，模拟信用分析师协作决策，提升企业信用评级的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在企业信用评级中准确性虽有所提高，但存在黑箱问题和缺乏层级推理机制，限制了解释能力和综合分析。

Method: 提出CreditXAI多智能体系统，聚焦业务、财务和治理风险，模拟专业分析师的协同决策过程以实现一致且可解释的信用评估。

Result: 多智能体协作使预测准确率较最佳单智能体提升7%以上，展现出显著的协同优势。

Conclusion: 研究提供了一种新技术路径，实现智能且具解释性的企业信用评级模型。

Abstract: In the domain of corporate credit rating, traditional deep learning methods
have improved predictive accuracy but still suffer from the inherent
'black-box' problem and limited interpretability. While incorporating
non-financial information enriches the data and provides partial
interpretability, the models still lack hierarchical reasoning mechanisms,
limiting their comprehensive analytical capabilities. To address these
challenges, we propose CreditXAI, a Multi-Agent System (MAS) framework that
simulates the collaborative decision-making process of professional credit
analysts. The framework focuses on business, financial, and governance risk
dimensions to generate consistent and interpretable credit assessments.
Experimental results demonstrate that multi-agent collaboration improves
predictive accuracy by more than 7% over the best single-agent baseline,
confirming its significant synergistic advantage in corporate credit risk
evaluation. This study provides a new technical pathway to build intelligent
and interpretable credit rating models.

</details>


### [144] [CGoT: A Novel Inference Mechanism for Embodied Multi-Agent Systems Using Composable Graphs of Thoughts](https://arxiv.org/abs/2510.22235)
*Yixiao Nie,Yang Zhang,Yingjie Jin,Zhepeng Wang,Xiu Li,Xiang Li*

Main category: cs.MA

TL;DR: 本文提出了一种结合自动驾驶车辆和服务机器人的新型系统，利用大语言模型提升车辆与机器人的协同效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆和服务机器人在工业和日常生活中应用日益广泛，结合两者并引入大语言模型有望提升系统整体效能。

Method: 设计了一个由两个自主车辆运输服务机器人的系统，并提出了一种名为CGOT的推理机制，用于支持一个智能体携带另一个智能体的场景。

Result: 通过实验验证了所提方法的有效性，证明引入CGOT机制能够增强车辆与机器人的协作能力和操作效率。

Conclusion: 该研究展示了结合自动驾驶车辆、服务机器人及大语言模型的潜力，提出的CGOT机制为提升复杂智能体系统的协同提供了新思路。

Abstract: The integration of self-driving cars and service robots is becoming
increasingly prevalent across a wide array of fields, playing a crucial and
expanding role in both industrial applications and everyday life. In parallel,
the rapid advancements in Large Language Models (LLMs) have garnered
substantial attention and interest within the research community. This paper
introduces a novel vehicle-robot system that leverages the strengths of both
autonomous vehicles and service robots. In our proposed system, two autonomous
ego-vehicles transports service robots to locations within an office park,
where they perform a series of tasks. The study explores the feasibility and
potential benefits of incorporating LLMs into this system, with the aim of
enhancing operational efficiency and maximizing the potential of the
cooperative mechanisms between the vehicles and the robots. This paper proposes
a novel inference mechanism which is called CGOT toward this type of system
where an agent can carry another agent. Experimental results are presented to
validate the performance of the proposed method.

</details>


### [145] [IFS: Information Flow Structure for Multi-agent Ad Hoc System](https://arxiv.org/abs/2510.22320)
*Yanqing Fu,Chenrun Wang,Chao Huang,Zhuping Wang*

Main category: cs.MA

TL;DR: 本文提出了一种多智能体临时系统的信息流结构（IFS），解决了信息流不足和信息处理能力有限的问题，提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 多智能体临时系统在动态、部分可观测和不确定的环境中，存在信息流不足和处理能力有限的关键问题，影响协作效果。

Method: 从通信和信息融合角度设计了信息流结构（IFS），以增强信息流通和处理能力。

Result: 在StarCraft II的实验中，IFS显著提升了信息流和处理能力，同时具备较强的泛化能力，优于基线方法。

Conclusion: IFS有效解决了多智能体临时系统中的信息流瓶颈，促进了复杂环境下的团队协作性能提升。

Abstract: Multi-agent ad hoc systems are dynamic collaborative systems in which
multiple autonomous agents must cooperate with both known and unknown teammates
in open environments, without relying on pre-coordinated strategies. These
systems operate under conditions of uncertainty and partial observability,
where team composition, agent behaviors, and environmental factors may change
during execution. Through an analysis of information flow in such systems, we
identify two key limitations in existing research: insufficient information
flow and limited information processing capacity. To address these issues, we
propose an information flow structure for multi-agent ad hoc systems (IFS),
which tackles these challenges from the perspectives of communication and
information fusion. Experimental results in StarCraft II demonstrate that IFS
significantly improves both information flow and processing capacity, while
exhibiting strong generalization capabilities and outperforming baseline
methods in complex ad hoc teamwork scenarios.

</details>


### [146] [Group size effects and collective misalignment in LLM multi-agent systems](https://arxiv.org/abs/2510.22422)
*Ariel Flint,Luca Maria Aiello,Romualdo Pastor-Satorras,Andrea Baronchelli*

Main category: cs.MA

TL;DR: 本文系统探讨了大型语言模型多智能体系统中群体规模如何影响动态表现，揭示了交互作用导致的偏差放大、新偏差产生及模型偏好覆盖现象。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只比较了单智能体与固定规模群体的行为，缺乏对不同群体规模动态变化的系统性理解。

Method: 通过设计简单协调游戏，分析不同规模多智能体系统中的偏差表现，并开发均场分析方法揭示关键规模下系统动态的确定性行为。

Result: 发现集体偏差远比之前理解的复杂，群体规模对动态有非线性影响，且存在模型相关的动态模式，超过临界规模后模拟结果趋向确定性。

Conclusion: 群体规模是影响多智能体系统动态的关键因素，大规模部署基于LLM的系统时需重视群体层面的效应。

Abstract: Multi-agent systems of large language models (LLMs) are rapidly expanding
across domains, introducing dynamics not captured by single-agent evaluations.
Yet, existing work has mostly contrasted the behavior of a single agent with
that of a collective of fixed size, leaving open a central question: how does
group size shape dynamics? Here, we move beyond this dichotomy and
systematically explore outcomes across the full range of group sizes. We focus
on multi-agent misalignment, building on recent evidence that interacting LLMs
playing a simple coordination game can generate collective biases absent in
individual models. First, we show that collective bias is a deeper phenomenon
than previously assessed: interaction can amplify individual biases, introduce
new ones, or override model-level preferences. Second, we demonstrate that
group size affects the dynamics in a non-linear way, revealing model-dependent
dynamical regimes. Finally, we develop a mean-field analytical approach and
show that, above a critical population size, simulations converge to
deterministic predictions that expose the basins of attraction of competing
equilibria. These findings establish group size as a key driver of multi-agent
dynamics and highlight the need to consider population-level effects when
deploying LLM-based systems at scale.

</details>


### [147] [Hollywood Town: Long-Video Generation via Cross-Modal Multi-Agent Orchestration](https://arxiv.org/abs/2510.22431)
*Zheng Wei,Mingchen Li,Zeqian Zhang,Ruibin Yuan,Pan Hui,Huamin Qu,James Evans,Maneesh Agrawala,Anyi Rao*

Main category: cs.MA

TL;DR: 本文提出了OmniAgent框架，通过分层图结构、多代理模块化协作及迭代反馈机制提升多代理系统在长视频生成中的表现。


<details>
  <summary>Details</summary>
Motivation: 多代理系统在创造性任务（如长视频生成）中的表现潜力巨大，但面临上下文理解和协作效率的挑战。

Method: 引入了基于影视制作的层级图形结构OmniAgent框架，采用超图节点进行临时多代理小组讨论，降低单代理记忆负担；并用带有限重试的有向循环图替代传统无环图，从而实现迭代输出优化。

Result: 该框架促进了模块化专精和代理间可扩展协作，有效减轻了个别代理的上下文负担，并通过反馈机制提升了生成质量。

Conclusion: 所提创新为多代理系统在复杂创造性任务中的稳健性能提升奠定了基础，特别是在长视频生成领域展现了良好应用前景。

Abstract: Recent advancements in multi-agent systems have demonstrated significant
potential for enhancing creative task performance, such as long video
generation. This study introduces three innovations to improve multi-agent
collaboration. First, we propose OmniAgent, a hierarchical, graph-based
multi-agent framework for long video generation that leverages a
film-production-inspired architecture to enable modular specialization and
scalable inter-agent collaboration. Second, inspired by context engineering, we
propose hypergraph nodes that enable temporary group discussions among agents
lacking sufficient context, reducing individual memory requirements while
ensuring adequate contextual information. Third, we transition from directed
acyclic graphs (DAGs) to directed cyclic graphs with limited retries, allowing
agents to reflect and refine outputs iteratively, thereby improving earlier
stages through feedback from subsequent nodes. These contributions lay the
groundwork for developing more robust multi-agent systems in creative tasks.

</details>


### [148] [Agent-GSPO: Communication-Efficient Multi-Agent Systems via Group Sequence Policy Optimization](https://arxiv.org/abs/2510.22477)
*Yijia Fan,Jusheng Zhang,Jing Yang,Keze Wang*

Main category: cs.MA

TL;DR: Agent-GSPO通过序列级强化学习优化多智能体系统的通信效率，实现了更少的通信代价和更优的性能。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统通信开销过大，限制了其规模和实用性。

Method: 引入Agent-GSPO框架，利用稳定且节省内存的Group Sequence Policy Optimization算法，结合通信感知的奖励机制来惩罚冗长通信，进行序列级强化学习。

Result: 在七个推理基准测试中，Agent-GSPO不仅达到了新的最优性能，而且在代币消耗上远低于现有方法。

Conclusion: Agent-GSPO通过促进“战略性沉默”等新兴策略，提供了一种可扩展且经济高效的多智能体系统开发方案。

Abstract: To combat the prohibitive communication costs of ``free-for-all" multi-agent
systems (MAS), we introduce \textbf{Agent-GSPO}, a framework that directly
optimizes for token economy using sequence-level reinforcement learning.
Agent-GSPO leverages the stable and memory-efficient Group Sequence Policy
Optimization (GSPO) algorithm to train agents on a communication-aware reward
that explicitly penalizes verbosity. Across seven reasoning benchmarks,
Agent-GSPO not only achieves new state-of-the-art performance but does so with
a fraction of the token consumption of existing methods. By fostering emergent
strategies like ``strategic silence," our approach provides a practical
blueprint for developing scalable and economically viable multi-agent systems.

</details>
