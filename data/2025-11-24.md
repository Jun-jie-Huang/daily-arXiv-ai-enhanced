<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 47]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.MA](#cs.MA) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Shona spaCy: A Morphological Analyzer for an Under-Resourced Bantu Language](https://arxiv.org/abs/2511.16680)
*Happymore Masoka*

Main category: cs.CL

TL;DR: 本文提出了一个基于规则和词典的Shona语言形态分析工具，提升了该语言的自然语言处理能力，促进了数字包容性。


<details>
  <summary>Details</summary>
Motivation: 尽管多语种自然语言处理发展迅速，Bantu语言中的Shona在形态分析及语言工具方面仍然资源匮乏。

Method: 基于spaCy框架，结合JSON词典和语言学规则，构建了一个规则驱动的Shona语言形态分析管道，包括名词类别前缀、动词主语一致性、时态体标记、拟声词和附着词等形态特征的标注。

Result: 系统实现了90%的词性标注准确率和88%的形态特征准确率，且保持了语言学决策的透明性。该工具已开源并在PyPI发布，方便用户安装使用。

Conclusion: Shona spaCy在描述性语法与计算实现之间架起了桥梁，推动了Shona语言的NLP可及性，且为其他资源匮乏的Bantu语言形态分析工具提供了模范。

Abstract: Despite rapid advances in multilingual natural language processing (NLP), the Bantu language Shona remains under-served in terms of morphological analysis and language-aware tools. This paper presents Shona spaCy, an open-source, rule-based morphological pipeline for Shona built on the spaCy framework. The system combines a curated JSON lexicon with linguistically grounded rules to model noun-class prefixes (Mupanda 1-18), verbal subject concords, tense-aspect markers, ideophones, and clitics, integrating these into token-level annotations for lemma, part-of-speech, and morphological features. The toolkit is available via pip install shona-spacy, with source code at https://github.com/HappymoreMasoka/shona-spacy and a PyPI release at https://pypi.org/project/shona-spacy/0.1.4/. Evaluation on formal and informal Shona corpora yields 90% POS-tagging accuracy and 88% morphological-feature accuracy, while maintaining transparency in its linguistic decisions. By bridging descriptive grammar and computational implementation, Shona spaCy advances NLP accessibility and digital inclusion for Shona speakers and provides a template for morphological analysis tools for other under-resourced Bantu languages.

</details>


### [2] [Towards Hyper-Efficient RAG Systems in VecDBs: Distributed Parallel Multi-Resolution Vector Search](https://arxiv.org/abs/2511.16681)
*Dong Liu,Yanxuan Yu*

Main category: cs.CL

TL;DR: 提出一种动态多分辨率向量索引方法SPI，通过语义金字塔和轻量级分类器实现查询适应的逐级检索，显著提升RAG系统检索速度与效果，且易于部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于向量数据库的RAG系统采用单一或平面索引结构，无法灵活调整检索粒度，导致检索速度和语义相关性难以兼顾，有必要设计支持多分辨率、查询适应的索引框架以提升RAG系统性能。

Method: 构建文档嵌入的语义金字塔索引结构，利用轻量级分类器动态选择查询的最佳分辨率，实现逐层由粗到细的检索，作为FAISS和Qdrant的插件进行实现和评估。

Result: 本文提出了一种名为Semantic Pyramid Indexing (SPI)的多分辨率向量索引框架，针对现有基于向量数据库的检索增强生成（RAG）系统中单一分辨率索引结构无法适应不同查询语义粒度的问题。SPI通过在文档嵌入上构建语义金字塔，并使用轻量级分类器动态选择每个查询的最优分辨率，实现了从粗到细的渐进检索，显著提升了检索速度与内存效率，同时保持语义覆盖。作者在FAISS和Qdrant后端实现了SPI插件，并在MS MARCO、Natural Questions及多模态检索基准上进行了评估，结果表明SPI最高实现了5.7倍检索加速、1.8倍内存效率提升以及最高2.5分的QA F1分数提升。理论分析保证了检索质量与延迟界限，消融实验验证了各组件贡献，且SPI兼容现有向量数据库基础设施，易于生产环境部署。代码已开源。

Conclusion: SPI框架有效解决了单一分辨率索引的局限，实现了速度、内存和检索质量的多方面提升，适用于多种RAG任务并方便集成进现有VecDB系统。

Abstract: Retrieval-Augmented Generation (RAG) systems have become a dominant approach to augment large language models (LLMs) with external knowledge. However, existing vector database (VecDB) retrieval pipelines rely on flat or single-resolution indexing structures, which cannot adapt to the varying semantic granularity required by diverse user queries. This limitation leads to suboptimal trade-offs between retrieval speed and contextual relevance.
  To address this, we propose \textbf{Semantic Pyramid Indexing (SPI)}, a novel multi-resolution vector indexing framework that introduces query-adaptive resolution control for RAG in VecDBs. Unlike existing hierarchical methods that require offline tuning or separate model training, SPI constructs a semantic pyramid over document embeddings and dynamically selects the optimal resolution level per query through a lightweight classifier. This adaptive approach enables progressive retrieval from coarse-to-fine representations, significantly accelerating search while maintaining semantic coverage.
  We implement SPI as a plugin for both FAISS and Qdrant backends and evaluate it across multiple RAG tasks including MS MARCO, Natural Questions, and multimodal retrieval benchmarks. SPI achieves up to \textbf{5.7$\times$} retrieval speedup and \textbf{1.8$\times$} memory efficiency gain while improving end-to-end QA F1 scores by up to \textbf{2.5 points} compared to strong baselines. Our theoretical analysis provides guarantees on retrieval quality and latency bounds, while extensive ablation studies validate the contribution of each component. The framework's compatibility with existing VecDB infrastructures makes it readily deployable in production RAG systems. Code is availabe at \href{https://github.com/FastLM/SPI_VecDB}{https://github.com/FastLM/SPI\_VecDB}.

</details>


### [3] [Bench360: Benchmarking Local LLM Inference from 360°](https://arxiv.org/abs/2511.16682)
*Linus Stuhlmann,Mauricio Fadel Argerich,Jonathan Fürst*

Main category: cs.CL

TL;DR: 提出Bench360，一个支持多引擎、多场景、多指标的本地大语言模型推理基准测试框架，帮助用户找到最适合的模型配置。


<details>
  <summary>Details</summary>
Motivation: 当前本地运行大语言模型面临多种繁杂配置选择，缺乏统一且易用的基准测试工具集合系统和任务指标，难以帮助用户找到最佳配置。

Method: 设计并实现了Bench360框架，支持自定义任务、数据集及任务指标，自动对多模型、多推理引擎和量化级别在多种使用场景下进行统一基准测试，同时采集丰富的系统和任务性能指标。

Result: 通过在四个常见任务（通用知识推理、问答、摘要、文本转SQL）、三种硬件平台和四种领先推理引擎上的实验，揭示性能与系统效率的多样权衡关系，证明没有单一优配置。

Conclusion: 本论文提出的Bench360基准测试框架有效整合了系统和任务特定指标，实现了多引擎、多场景下本地大语言模型推理性能的全面评估。实验证明不同模型和推理引擎之间存在性能与效率的权衡，没有单一最佳配置，验证了该框架的实用性和必要性。

Abstract: Running large language models (LLMs) locally is becoming increasingly common. While the growing availability of small open-source models and inference engines has lowered the entry barrier, users now face an overwhelming number of configuration choices. Identifying an optimal configuration -- balancing functional and non-functional requirements -- requires substantial manual effort. While several benchmarks target LLM inference, they are designed for narrow evaluation goals and not user-focused. They fail to integrate relevant system and task-specific metrics into a unified, easy-to-use benchmark that supports multiple inference engines, usage scenarios, and quantization levels. To address this gap, we present Bench360 -- Benchmarking Local LLM Inference from 360°. Bench360 allows users to easily define their own custom tasks along with datasets and relevant task-specific metrics and then automatically benchmarks selected LLMs, inference engines, and quantization levels across different usage scenarios (single stream, batch & server). Bench360 tracks a wide range of metrics, including (1) system metrics -- such as Computing Performance (e.g., latency, throughput), Resource Usage (e.g., energy per query), and Deployment (e.g., cold start time) -- and (2) task-specific metrics such as ROUGE, F1 score or accuracy. We demonstrate Bench360 on four common LLM tasks -- General Knowledge & Reasoning, QA, Summarization and Text-to-SQL -- across three hardware platforms and four state of the art inference engines. Our results reveal several interesting trade-offs between task performance and system-level efficiency, highlighting the differences in inference engines and models. Most importantly, there is no single best setup for local inference, which strongly motivates the need for a framework such as Bench360.

</details>


### [4] [How Well Do LLMs Understand Tunisian Arabic?](https://arxiv.org/abs/2511.16683)
*Mohamed Mahdi*

Main category: cs.CL

TL;DR: 本文通过新构建的数据集评估多种大型语言模型在突尼斯方言的音译、翻译和情感分析任务上的表现，揭示现有模型对低资源语言支持的不足，强调了在AI系统中融入低资源语言的重要性。


<details>
  <summary>Details</summary>
Motivation: 工业规模的大型语言模型通常忽略对低资源语言如突尼斯阿拉伯语的理解能力，这可能导致大量突尼斯人无法使用母语与AI交互，威胁方言保存和文化传承。

Method: 构建包含并行的突尼斯方言（Tunizi）、标准突尼斯阿拉伯语和英语翻译及情感标签的新数据集；基于该数据集对多个流行的大型语言模型（LLMs）进行音译、翻译和情感分析三项任务的基准测试。

Result: 实验结果显示各大模型在处理突尼斯方言任务中存在显著差异，展现了各自的优势和不足。

Conclusion: 研究强调包容低资源语言如突尼斯阿拉伯语对于未来AI系统的必要性，以确保技术的可访问性、包容性和文化根基，促进多语言环境下的公平交流。

Abstract: Large Language Models (LLMs) are the engines driving today's AI agents. The better these models understand human languages, the more natural and user-friendly the interaction with AI becomes, from everyday devices like computers and smartwatches to any tool that can act intelligently. Yet, the ability of industrial-scale LLMs to comprehend low-resource languages, such as Tunisian Arabic (Tunizi), is often overlooked. This neglect risks excluding millions of Tunisians from fully interacting with AI in their own language, pushing them toward French or English. Such a shift not only threatens the preservation of the Tunisian dialect but may also create challenges for literacy and influence younger generations to favor foreign languages. In this study, we introduce a novel dataset containing parallel Tunizi, standard Tunisian Arabic, and English translations, along with sentiment labels. We benchmark several popular LLMs on three tasks: transliteration, translation, and sentiment analysis. Our results reveal significant differences between models, highlighting both their strengths and limitations in understanding and processing Tunisian dialects. By quantifying these gaps, this work underscores the importance of including low-resource languages in the next generation of AI systems, ensuring technology remains accessible, inclusive, and culturally grounded.

</details>


### [5] [Ellipsoid-Based Decision Boundaries for Open Intent Classification](https://arxiv.org/abs/2511.16685)
*Yuetian Zou,Hanlei Zhang,Hua Xu,Songze Li,Long Xiao*

Main category: cs.CL

TL;DR: 提出了一种名为EliDecide的椭球决策边界学习方法，通过学习不同方向上不同尺度的椭球边界，提升了开放文本意图分类的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设已知类别分布各向同性，限制边界为球形，忽视了不同方向上的分布差异，降低了未知意图检测的鲁棒性。

Method: 采用监督对比学习获得判别特征空间，利用可学习矩阵参数化椭球边界，通过双重损失函数优化边界以平衡经验风险和开放空间风险。

Result: 方法在多个文本意图和问题分类基准上取得了最先进的检测效果，展示了椭球边界针对复杂开放世界场景的强大适应性。

Conclusion: EliDecide方法在多个文本意图基准及问题分类数据集上达到了最先进的性能，证明了椭球形边界在开放意图检测中的优越性和良好的泛化能力。

Abstract: Textual open intent classification is crucial for real-world dialogue systems, enabling robust detection of unknown user intents without prior knowledge and contributing to the robustness of the system. While adaptive decision boundary methods have shown great potential by eliminating manual threshold tuning, existing approaches assume isotropic distributions of known classes, restricting boundaries to balls and overlooking distributional variance along different directions. To address this limitation, we propose EliDecide, a novel method that learns ellipsoid decision boundaries with varying scales along different feature directions. First, we employ supervised contrastive learning to obtain a discriminative feature space for known samples. Second, we apply learnable matrices to parameterize ellipsoids as the boundaries of each known class, offering greater flexibility than spherical boundaries defined solely by centers and radii. Third, we optimize the boundaries via a novelly designed dual loss function that balances empirical and open-space risks: expanding boundaries to cover known samples while contracting them against synthesized pseudo-open samples. Our method achieves state-of-the-art performance on multiple text intent benchmarks and further on a question classification dataset. The flexibility of the ellipsoids demonstrates superior open intent detection capability and strong potential for generalization to more text classification tasks in diverse complex open-world scenarios.

</details>


### [6] [Prompt-Based Value Steering of Large Language Models](https://arxiv.org/abs/2511.16688)
*Giulio Antonio Abbo,Tony Belpaeme*

Main category: cs.CL

TL;DR: 本文提出了一种基于提示词评估的价值引导方法，能在不改变模型的情况下使输出文本更符合指定的人类价值观。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在需要符合人类价值观的应用中越来越重要，但现有的微调方法静态且不适应动态变化的价值观和偏好。

Method: 基于Schwartz基本人类价值理论，设计了一个评分方法来量化生成文本中目标价值的存在和提升，结合对话数据集，比较基线提示词与显式条件化的提示词的效果。

Result: 提出了一种实用、可复现且与模型无关的评估方法，用于衡量提示词在引导生成文本符合特定人类价值观方面的效果，并通过实验验证在不修改模型或动态优化提示词的情况下实现价值引导的可行性。

Conclusion: 通过提示词的适当设计，可以有效地引导生成模型表现出特定的人类价值观，无需微调模型或动态优化提示。

Abstract: Large language models are increasingly used in applications where alignment with human values is critical. While model fine-tuning is often employed to ensure safe responses, this technique is static and does not lend itself to everyday situations involving dynamic values and preferences. In this paper, we present a practical, reproducible, and model-agnostic procedure to evaluate whether a prompt candidate can effectively steer generated text toward specific human values, formalising a scoring method to quantify the presence and gain of target values in generated responses. We apply our method to a variant of the Wizard-Vicuna language model, using Schwartz's theory of basic human values and a structured evaluation through a dialogue dataset. With this setup, we compare a baseline prompt to one explicitly conditioned on values, and show that value steering is possible even without altering the model or dynamically optimising prompts.

</details>


### [7] [Concept-Based Interpretability for Toxicity Detection](https://arxiv.org/abs/2511.16689)
*Samarth Garg,Deeksha Varshney,Divya Singh*

Main category: cs.CL

TL;DR: 本文提出基于概念梯度的解释方法，结合毒性子类型作为概念指标，构建目标词汇集并利用词-概念对齐分数分析误分类原因，最后通过无词汇增强验证模型归因的广泛性。


<details>
  <summary>Details</summary>
Motivation: 当前毒性语言检测虽取得进展，但对基于概念的解释研究有限，且过度归因概念导致误分类问题突出。本文旨在通过引入基于概念的因果解释技术，提高模型的可解释性和误分类诊断能力。

Method: 引入概念梯度（CG）方法来衡量概念变化对模型输出的因果影响；构建目标词汇集捕捉误分类相关的毒性词汇；计算词-概念对齐（WCA）分数评估词汇对误分类的贡献；设计无词汇增强策略生成不含预定义毒性词汇的样本，检验模型归因的普适性。

Result: 本文提出了一种基于概念梯度（Concept Gradient，CG）方法的解释技术，利用毒性检测数据中的子类型属性（如猥亵、威胁、侮辱、身份攻击、性暗示）作为概念指标，提升毒性语言检测的可解释性。研究发现过度归因于目标类别的概念会导致分类错误。作者提出了"目标词汇集"，用以捕捉导致误分类的毒性词汇，并通过词-概念对齐（WCA）分数量化这些词汇对错误的贡献。最后，设计了一种无词汇增强策略，生成排除预定义毒性词汇的毒性样本，从而探讨模型在删除显性词汇重叠后的归因表现。

Conclusion: 利用概念梯度方法和目标词汇集，能够更准确揭示毒性语言检测模型的误分类机理，并通过无词汇增强策略验证模型的概念归因，提升了模型的解释性与鲁棒性。

Abstract: The rise of social networks has not only facilitated communication but also allowed the spread of harmful content. Although significant advances have been made in detecting toxic language in textual data, the exploration of concept-based explanations in toxicity detection remains limited. In this study, we leverage various subtype attributes present in toxicity detection datasets, such as obscene, threat, insult, identity attack, and sexual explicit as concepts that serve as strong indicators to identify whether language is toxic. However, disproportionate attribution of concepts towards the target class often results in classification errors. Our work introduces an interpretability technique based on the Concept Gradient (CG) method which provides a more causal interpretation by measuring how changes in concepts directly affect the output of the model. This is an extension of traditional gradient-based methods in machine learning, which often focus solely on input features. We propose the curation of Targeted Lexicon Set, which captures toxic words that contribute to misclassifications in text classification models. To assess the significance of these lexicon sets in misclassification, we compute Word-Concept Alignment (WCA) scores, which quantify the extent to which these words lead to errors due to over-attribution to toxic concepts. Finally, we introduce a lexicon-free augmentation strategy by generating toxic samples that exclude predefined toxic lexicon sets. This approach allows us to examine whether over-attribution persists when explicit lexical overlap is removed, providing insights into the model's attribution on broader toxic language patterns.

</details>


### [8] [Falsely Accused: How AI Detectors Misjudge Slightly Polished Arabic Articles](https://arxiv.org/abs/2511.16690)
*Saleh Almohaimeed,Saad Almohaimeed,Mousa Jari,Khaled A. Alobaid,Fahad Alotaibi*

Main category: cs.CL

TL;DR: 研究发现阿拉伯语AI检测模型难以区分轻微抛光的人类文章，误判严重，需改进检测方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI检测模型容易将被AI稍作修改的人类文章误判为AI生成，导致误判和信誉问题，尤其在阿拉伯语领域缺乏相关研究。

Method: 生成两个阿拉伯语文章数据集，评估14个大型语言模型和商业AI检测器的区分能力，选出表现最好的8个模型进一步测试抛光过的人类写作文本对检测结果的影响。

Result: 所有AI检测模型对稍作抛光的人类文章存在高误判率，表现最佳的模型准确率从83.51%降至57.63%，商业模型准确率从92%降至12%。

Conclusion: 现有阿拉伯语AI检测器对稍微抛光的人类文章检测效果大幅下降，说明需设计更鲁棒的检测模型以避免误判。

Abstract: Many AI detection models have been developed to counter the presence of articles created by artificial intelligence (AI). However, if a human-authored article is slightly polished by AI, a shift will occur in the borderline decision of these AI detection models, leading them to consider it AI-generated article. This misclassification may result in falsely accusing authors of AI plagiarism and harm the credibility of AI detector models. In English, some efforts were made to meet this challenge, but not in Arabic. In this paper, we generated two datasets. The first dataset contains 800 Arabic articles, half AI-generated and half human-authored. We used it to evaluate 14 Large Language models (LLMs) and commercial AI detectors to assess their ability in distinguishing between human-authored and AI-generated articles. The best 8 models were chosen to act as detectors for our primary concern, which is whether they would consider slightly polished human text as AI-generated. The second dataset, Ar-APT, contains 400 Arabic human-authored articles polished by 10 LLMs using 4 polishing settings, totaling 16400 samples. We use it to evaluate the 8 nominated models and determine whether slight polishing will affect their performance. The results reveal that all AI detectors incorrectly attribute a significant number of articles to AI. The best performing LLM, Claude-4 Sonnet, achieved 83.51%, their performance decreased to 57.63% for articles slightly polished by LLaMA-3. Whereas for the best performing commercial model, originality.AI, that achieves 92% accuracy, dropped to 12% for articles slightly polished by Mistral or Gemma-3.

</details>


### [9] [Reproducibility Report: Test-Time Training on Nearest Neighbors for Large Language Models](https://arxiv.org/abs/2511.16691)
*Boyang Zhou,Johan Lindqvist,Lindsey Li*

Main category: cs.CL

TL;DR: 本文复现并扩展了基于最近邻的推理时训练方法，验证其普适性和效能，并提出了内存优化方案，促进了该方法在大规模模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 验证并复现先前关于基于最近邻序列的推理时训练方法的有效性，探究其在不同规模模型和多样化数据集上的适用性及实用性。

Method: 利用预训练的RoBERTa嵌入和Faiss索引技术，检索每个测试输入的20个邻居序列，并在GPT-2、GPT-Neo及R1-Distilled-Qwen2.5-1.5B等模型上对每个邻居执行一次梯度更新，在推理时对模型进行微调。

Result: 测试时训练显著提升了多个语言模型的表现，尤其是未预训练在类似数据集上的模型，且内存优化策略有效降低了资源消耗，同时对推理优化的新型模型也同样有效。

Conclusion: 测试时训练法通过对推理阶段最近邻序列进行微调，显著降低了语言模型的困惑度和bits-per-byte，提升了模型在结构化或专业领域数据上的表现。小模型通过这种方法性能接近大模型，且适用于不同架构。

Abstract: We reproduce the central claims of Test-Time Training on Nearest Neighbors for Large Language Models (Hardt and Sun, 2024), which proposes adapting a language model at inference time by fine-tuning on retrieved nearest-neighbor sequences. Using pretrained RoBERTa embeddings indexed with Faiss, we retrieve 20 neighbors per test input and apply one gradient update per neighbor across GPT-2 (117M, 774M), GPT-Neo (1.3B), and R1-Distilled-Qwen2.5-1.5B. Our experiments confirm that test-time training significantly reduces perplexity and bits-per-byte metrics across diverse domains from The Pile, with the largest improvements in structured or specialized datasets such as GitHub and EuroParl. We further validate that models not pretrained on The Pile benefit more from this adaptation than models already trained on similar data, allowing smaller models to approach the performance of larger ones. Due to infrastructure limitations, we introduce a memory-efficient retrieval implementation that loads only required line offsets rather than entire files, reducing RAM requirements from over 128 GB per server to 32 GB. We also extend the original study by evaluating R1-Distilled-Qwen2.5-1.5B, showing that test-time training yields consistent gains even for modern reasoning-optimized architectures. Overall, our results support the robustness and generality of nearest-neighbor test-time training while highlighting practical considerations for reproducing large-scale retrieval-augmented adaptation.

</details>


### [10] [How Language Directions Align with Token Geometry in Multilingual LLMs](https://arxiv.org/abs/2511.16693)
*JaeSeong Kim,Suan Lee*

Main category: cs.CL

TL;DR: 本研究系统分析了多语言LLMs中语言信息的层级动态和几何结构，发现语言信息在首层迅速分离并保持线性可分，与训练语料中语言构成紧密联系，揭示了多语言表示的潜在机制。


<details>
  <summary>Details</summary>
Motivation: 当前多语言大型语言模型（LLMs）在多语言任务表现出色，但关于语言信息如何在其内部表征空间中组织及其在不同层中如何出现的系统性分析较少。

Method: 对六个多语言LLMs的268个Transformer层进行全面探测，采用线性和非线性探针结合新的Token--Language Alignment分析方法，量化不同层次语言编码的动态和几何结构。

Result: 语言信息在第一个Transformer块中迅速分离（从第0层到第1层准确率提升76.4±8.2个百分点），且在模型深度范围内保持几乎完全线性可分。语言方向与词汇嵌入的对齐度与训练数据中的语言组成紧密相关。包含中文的模型ZH Match@Peak达到16.43%，而以英语为中心的模型仅为3.90%，呈现4.21倍的结构烙印效应。多语言LLMs通过训练语料塑造的潜在表征结构，而非表面书写特征区分不同语言。

Conclusion: 多语言LLMs中的语言区分基于潜在表征结构，与训练数据的语言组成密切相关，揭示了语言信息如何在模型层次间分布且保持线性可分性，为多语言数据组合策略和公平性提供指导意义。

Abstract: Multilingual LLMs demonstrate strong performance across diverse languages, yet there has been limited systematic analysis of how language information is structured within their internal representation space and how it emerges across layers. We conduct a comprehensive probing study on six multilingual LLMs, covering all 268 transformer layers, using linear and nonlinear probes together with a new Token--Language Alignment analysis to quantify the layer-wise dynamics and geometric structure of language encoding. Our results show that language information becomes sharply separated in the first transformer block (+76.4$\pm$8.2 percentage points from Layer 0 to 1) and remains almost fully linearly separable throughout model depth. We further find that the alignment between language directions and vocabulary embeddings is strongly tied to the language composition of the training data. Notably, Chinese-inclusive models achieve a ZH Match@Peak of 16.43\%, whereas English-centric models achieve only 3.90\%, revealing a 4.21$\times$ structural imprinting effect. These findings indicate that multilingual LLMs distinguish languages not by surface script features but by latent representational structures shaped by the training corpus. Our analysis provides practical insights for data composition strategies and fairness in multilingual representation learning. All code and analysis scripts are publicly available at: https://github.com/thisiskorea/How-Language-Directions-Align-with-Token-Geometry-in-Multilingual-LLMs.

</details>


### [11] [Hierarchical Retrieval with Out-Of-Vocabulary Queries: A Case Study on SNOMED CT](https://arxiv.org/abs/2511.16698)
*Jonathon Dilworth,Hui Yang,Jiaoyan Chen,Yongsheng Gao*

Main category: cs.CL

TL;DR: 针对SNOMED CT中无词典外查询的层级概念检索，本文提出基于语言模型的本体嵌入方法，显著提升检索性能，并具备良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于语言歧义、同义词和多义词等问题，SNOMED CT中的知识检索存在挑战；尤其是查询词不在本体中时，检索难度加大。

Method: 采用语言模型生成的本体嵌入方法，实现对SNOMED CT层级概念的检索，特别针对无词典外（OOV）查询。

Result: 在构建的针对OOV查询的评测数据集上，该方法检索最直接的上位概念及相关上层祖先的效果优于SBERT和两种词汇匹配方法。

Conclusion: 本研究提出的基于语言模型的本体嵌入方法在处理SNOMED CT中无词典外查询的层级概念检索问题上表现优于传统方法。

Abstract: SNOMED CT is a biomedical ontology with a hierarchical representation of large-scale concepts. Knowledge retrieval in SNOMED CT is critical for its application, but often proves challenging due to language ambiguity, synonyms, polysemies and so on. This problem is exacerbated when the queries are out-of-vocabulary (OOV), i.e., having no equivalent matchings in the ontology. In this work, we focus on the problem of hierarchical concept retrieval from SNOMED CT with OOV queries, and propose an approach based on language model-based ontology embeddings. For evaluation, we construct OOV queries annotated against SNOMED CT concepts, testing the retrieval of the most direct subsumers and their less relevant ancestors. We find that our method outperforms the baselines including SBERT and two lexical matching methods. While evaluated against SNOMED CT, the approach is generalisable and can be extended to other ontologies. We release code, tools, and evaluation datasets at https://github.com/jonathondilworth/HR-OOV.

</details>


### [12] [Detecting and Steering LLMs' Empathy in Action](https://arxiv.org/abs/2511.16699)
*Juan P. Cadile*

Main category: cs.CL

TL;DR: 研究发现大语言模型激活空间存在表示同理心的线性方向，不同模型在检测和引导同理心方面表现差异，安全训练对引导稳健性有影响。


<details>
  <summary>Details</summary>
Motivation: 探讨同理心行动（牺牲任务效率以满足人类需求的意愿）是否在语言模型激活空间中有可识别的线性表示，并评估其检测和控制能力。

Method: 利用基于Empathy-in-Action (EIA)基准的对比提示，在不同大语言模型（Phi-3-mini-4k, Qwen2.5-7B, Dolphin-Llama-3.1-8B）激活空间中检测和引导表现出同理心的线性方向。

Result: 所有模型在检测同理心方向时表现出极高的准确性（AUROC达0.996-1.00），且未经过安全训练的Dolphin模型同样显示出同理心编码。模型间探针相关性有限，提示架构差异。引导方面，Qwen和Phi-3均实现约62-65%的成功率，且保持双向控制的连贯性；Dolphin在增强同理心时成功率高达94.4%，但削弱时表现极差。

Conclusion: 同理心作为大语言模型中的可识别线性方向，表现出架构特异性，且引导能力存在差异。安全训练可能增强引导的稳健性而非防止操控。未来需对更多模型进行验证以推广结论。

Abstract: We investigate empathy-in-action -- the willingness to sacrifice task efficiency to address human needs -- as a linear direction in LLM activation space. Using contrastive prompts grounded in the Empathy-in-Action (EIA) benchmark, we test detection and steering across Phi-3-mini-4k (3.8B), Qwen2.5-7B (safety-trained), and Dolphin-Llama-3.1-8B (uncensored).
  Detection: All models show AUROC 0.996-1.00 at optimal layers. Uncensored Dolphin matches safety-trained models, demonstrating empathy encoding emerges independent of safety training. Phi-3 probes correlate strongly with EIA behavioral scores (r=0.71, p<0.01). Cross-model probe agreement is limited (Qwen: r=-0.06, Dolphin: r=0.18), revealing architecture-specific implementations despite convergent detection.
  Steering: Qwen achieves 65.3% success with bidirectional control and coherence at extreme interventions. Phi-3 shows 61.7% success with similar coherence. Dolphin exhibits asymmetric steerability: 94.4% success for pro-empathy steering but catastrophic breakdown for anti-empathy (empty outputs, code artifacts).
  Implications: The detection-steering gap varies by model. Qwen and Phi-3 maintain bidirectional coherence; Dolphin shows robustness only for empathy enhancement. Safety training may affect steering robustness rather than preventing manipulation, though validation across more models is needed.

</details>


### [13] [NALA_MAINZ at BLP-2025 Task 2: A Multi-agent Approach for Bangla Instruction to Python Code Generation](https://arxiv.org/abs/2511.16787)
*Hossain Shaikh Saadi,Faria Alam,Mario Sanz-Guerrero,Minh Duc Bui,Manuel Mager,Katharina von der Wense*

Main category: cs.CL

TL;DR: 提出一种多代理管道策略，通过初始生成和针对失败测试的自动调试，显著提升孟加拉语代码生成的准确率。


<details>
  <summary>Details</summary>
Motivation: 提高从孟加拉语指令生成代码的准确性和鲁棒性。通过迭代调试机制提升代码通过测试的概率。

Method: 采用多代理管道方法。首先，代码生成代理根据输入指令生成初始解决方案。然后运行候选程序检查单元测试，仅将失败的测试用例传递给调试代理，该代理重新运行测试、提取错误信息，并基于错误消息、当前程序和相关测试用例生成修正方案。

Result: 该方法在BLP-2025代码生成共享任务中获得第一名，Pass@1得分为95.4。

Conclusion: 多代理协作的代码生成与调试机制能够有效提升测试通过率，在共有任务中表现优异，且代码已开源。

Abstract: This paper presents JGU Mainz's winning system for the BLP-2025 Shared Task on Code Generation from Bangla Instructions. We propose a multi-agent-based pipeline. First, a code-generation agent produces an initial solution from the input instruction. The candidate program is then executed against the provided unit tests (pytest-style, assert-based). Only the failing cases are forwarded to a debugger agent, which reruns the tests, extracts error traces, and, conditioning on the error messages, the current program, and the relevant test cases, generates a revised solution. Using this approach, our submission achieved first place in the shared task with a $Pass@1$ score of 95.4. We also make our code public.

</details>


### [14] [From Representation to Enactment: The ABC Framework of the Translating Mind](https://arxiv.org/abs/2511.16811)
*Michael Carl,Takanori Mizowaki,Aishvarya Raj,Masaru Yamada,Devi Sri Bandaru,Yuxiang Wei,Xinyue Ren*

Main category: cs.CL

TL;DR: 本文提出一种非表征的翻译心理模型，将翻译视为情感、行为与认知动态互动的过程，通过身体化的互动在社会文化语境中实时共创意义。


<details>
  <summary>Details</summary>
Motivation: 当前主流心理模型依赖于静态的表征系统，无法充分解释翻译过程中的实时动态互动和意义的协同创造。

Method: 基于Extended Mind理论和激进的主动认知，提出了一个ABC框架，将翻译作为一种动态整合情感、行为和认知过程的行动活动，借鉴了预测处理和主动推理模型。

Result: 提出翻译者的心智通过脑-身体-环境的循环交互而生成，翻译被视为参与社会文化实践的技能，而不是简单的信息转换。

Conclusion: 翻译心智是通过身体和环境的互动生成的技能实践，超越了传统基于表征的认知模型，开启了理解翻译的新视角。

Abstract: Building on the Extended Mind (EM) theory and radical enactivism, this article suggests an alternative to representation-based models of the mind. We lay out a novel ABC framework of the translating mind, in which translation is not the manipulation of static interlingual correspondences but an enacted activity, dynamically integrating affective, behavioral, and cognitive (ABC) processes. Drawing on Predictive Processing and (En)Active Inference, we argue that the translator's mind emerges, rather than being merely extended, through loops of brain-body-environment interactions. This non-representational account reframes translation as skillful participation in sociocultural practice, where meaning is co-created in real time through embodied interaction with texts, tools, and contexts.

</details>


### [15] [Interpretable dimensions support an effect of agentivity and telicity on split intransitivity](https://arxiv.org/abs/2511.16824)
*Eva Neu,Brian Dillon,Katrin Erk*

Main category: cs.CL

TL;DR: 通过结合人工评级和基于种子词的可解释语义维度，验证了代理性和终结性与不同不及物动词句法结构间的关系。


<details>
  <summary>Details</summary>
Motivation: 重新评估篇章对代理性和终结性在人称不及物动词句法行为中预测作用的质疑，澄清两者关系。

Method: 基于可解释维度，从代表性种子词出发，构建代理性和终结性两个极端尺度，结合人工评级进行分析。

Result: 发现代理性/终结性与不及物动词的unergative/unaccusative句法结构存在关联，并且用可解释维度结合人工判断能够揭示评级任务难以评估的语义属性。

Conclusion: 代理性和终结性确实关联不及物动词的句法类别，采用可解释维度可以有效补充传统评级方法，帮助深入理解语言中的语义与句法机制。

Abstract: Intransitive verbs fall into two different syntactic classes, unergatives and unaccusatives. It has long been argued that verbs describing an agentive action are more likely to appear in an unergative syntax, and those describing a telic event to appear in an unaccusative syntax. However, recent work by Kim et al. (2024) found that human ratings for agentivity and telicity were a poor predictor of the syntactic behavior of intransitives. Here we revisit this question using interpretable dimensions, computed from seed words on opposite poles of the agentive and telic scales. Our findings support the link between unergativity/unaccusativity and agentivity/telicity, and demonstrate that using interpretable dimensions in conjunction with human judgments can offer valuable evidence for semantic properties that are not easily evaluated in rating tasks.

</details>


### [16] [PEPPER: Perception-Guided Perturbation for Robust Backdoor Defense in Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.16830)
*Oscar Chew,Po-Yi Lu,Jayden Lin,Kuan-Hao Huang,Hsuan-Tien Lin*

Main category: cs.CL

TL;DR: 本文提出了PEPPER，一种针对文本到图像扩散模型中的后门攻击的防御方法，通过语义上距离较远但视觉上相似的标题改写来削弱触发器效果，实现了增强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型易受输入提示中的后门触发器攻击，导致生成有害或非预期内容，亟需有效的防御手段。

Method: 采用感知引导的扰动，将输入提示的标题改写为语义距离较远但视觉相似的版本，并添加微小、不显眼的元素，破坏输入中的触发器影响。

Result: 实验表明，PEPPER在防御文本编码器相关后门攻击时表现出色，显著降低攻击成功率，同时保持生成内容的质量，并能与其他防御方法协同增强防御效果。

Conclusion: PEPPER有效抵御文本编码器基础的后门攻击，显著降低攻击成功率，同时保持了生成图像的质量，可与其他防御方法结合使用效果更佳。

Abstract: Recent studies show that text to image (T2I) diffusion models are vulnerable to backdoor attacks, where a trigger in the input prompt can steer generation toward harmful or unintended content. To address this, we introduce PEPPER (PErcePtion Guided PERturbation), a backdoor defense that rewrites the caption into a semantically distant yet visually similar caption while adding unobstructive elements. With this rewriting strategy, PEPPER disrupt the trigger embedded in the input prompt, dilute the influence of trigger tokens and thereby achieve enhanced robustness. Experiments show that PEPPER is particularly effective against text encoder based attacks, substantially reducing attack success while preserving generation quality. Beyond this, PEPPER can be paired with any existing defenses yielding consistently stronger and generalizable robustness than any standalone method. Our code will be released on Github.

</details>


### [17] [ConCISE: A Reference-Free Conciseness Evaluation Metric for LLM-Generated Answers](https://arxiv.org/abs/2511.16846)
*Seyed Mohssen Ghafari,Ronny Kol,Juan C. Quiroz,Nella Luan,Monika Patial,Chanaka Rupasinghe,Herman Wandabwa,Luiz Pizzato*

Main category: cs.CL

TL;DR: 本文提出了一种无需参考答案的新指标，用三种压缩方法测量大型语言模型回复的简洁性，有效识别冗余内容，提升评价效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型产生的回复往往冗长且包含冗余信息，影响清晰度和用户体验，同时增加开发成本。

Method: 提出了一种无参照的新指标，通过三种压缩率计算（抽象摘要压缩比、提取摘要压缩比、词汇移除压缩）评估回复的简洁度。

Result: 该指标能够准确识别输出中的冗余内容，无需人工标准参考即可自动评估回复简洁性。

Conclusion: 新指标为对话式AI系统的自动简洁性评估提供了实用工具，有助于提升模型输出质量和降低成本。

Abstract: Large language models (LLMs) frequently generate responses that are lengthy and verbose, filled with redundant or unnecessary details. This diminishes clarity and user satisfaction, and it increases costs for model developers, especially with well-known proprietary models that charge based on the number of output tokens. In this paper, we introduce a novel reference-free metric for evaluating the conciseness of responses generated by LLMs. Our method quantifies non-essential content without relying on gold standard references and calculates the average of three calculations: i) a compression ratio between the original response and an LLM abstractive summary; ii) a compression ratio between the original response and an LLM extractive summary; and iii) wordremoval compression, where an LLM removes as many non-essential words as possible from the response while preserving its meaning, with the number of tokens removed indicating the conciseness score. Experimental results demonstrate that our proposed metric identifies redundancy in LLM outputs, offering a practical tool for automated evaluation of response brevity in conversational AI systems without the need for ground truth human annotations.

</details>


### [18] [Improving Latent Reasoning in LLMs via Soft Concept Mixing](https://arxiv.org/abs/2511.16885)
*Kang Wang,Xiangyu Duan,Tianyi Du*

Main category: cs.CL

TL;DR: 本文提出SCM训练方法，通过软概念向量和强化学习优化大型语言模型的推理能力，验证了其性能提升与训练稳定。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常通过生成离散符号推理，限制了表达能力，而人类推理更倾向于抽象软概念，存在表征空间差距。

Method: 提出了Soft Concept Mixing (SCM)训练方案，通过形成概率加权的软概念向量，将其混入模型隐藏状态，并用强化学习优化整个潜在推理过程。

Result: 在五个推理基准测试中，SCM显著提升了模型的推理表现，且训练动态稳定。

Conclusion: SCM方法能有效提升大型语言模型的推理性能，同时保持训练过程的稳定性。

Abstract: Unlike human reasoning in abstract conceptual spaces, large language models (LLMs) typically reason by generating discrete tokens, which potentially limit their expressive power. The recent work Soft Thinking has shown that LLMs' latent reasoning via soft concepts is a promising direction, but LLMs are trained on discrete tokens. To reduce this gap between the soft concepts in reasoning and the discrete tokens in training, we propose Soft Concept Mixing (SCM), a soft concept aware training scheme that directly exposes the model to soft representations during training. Specifically, SCM constructs a soft concept vector by forming a probability-weighted average of embeddings. Then, this vector is mixed into the model's hidden states, which embody rich contextual information. Finally, the entire latent reasoning process is optimized with Reinforcement Learning (RL). Experiments on five reasoning benchmarks demonstrate that SCM improves the reasoning performance of LLMs, and simultaneously maintains a stable training dynamic.

</details>


### [19] [Deep Improvement Supervision](https://arxiv.org/abs/2511.16886)
*Arip Asadulaev,Rayan Banerjee,Fakhri Karray,Martin Takac*

Main category: cs.CL

TL;DR: 本文提出了一种新的训练方案，用于提高Tiny Recursive Models在复杂推理任务上的训练效率，实现了18倍的前向传播减少和24%的ARC-1准确率表现，优于大部分大语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前小型循环架构如TRMs在复杂推理任务上的表现超过大型语言模型，如何在保持推理能力的同时进一步提升效率是核心问题。

Method: 将TRMs的潜在推理过程建模为无分类器引导与隐式策略改进算法，提出针对每个循环的目标训练方案，从而减少前向传播次数并取消中止机制。

Result: 该方法将前向传播次数减少18倍，无需中止机制，且在ARC-1数据集上以仅0.8M参数实现24%准确率，优于大多数大型语言模型。

Conclusion: 通过引入针对每个循环步骤的训练目标，该方法显著提升了Tiny Recursive Models的训练效率和性能，且模型体积小于主流大语言模型。

Abstract: Recently, it was shown that small, looped architectures, such as Tiny Recursive Models (TRMs), can outperform Large Language Models (LLMs) on complex reasoning tasks, including the Abstraction and Reasoning Corpus (ARC). In this work, we investigate a core question: how can we further improve the efficiency of these methods with minimal changes? To address this, we frame the latent reasoning of TRMs as a form of classifier-free guidance and implicit policy improvement algorithm. Building on these insights, we propose a novel training scheme that provides a target for each loop during training. We demonstrate that our approach significantly enhances training efficiency. Our method reduces the total number of forward passes by 18x and eliminates halting mechanisms, while maintaining quality comparable to standard TRMs. Notably, we achieve 24% accuracy on ARC-1 with only 0.8M parameters, outperforming most LLMs.

</details>


### [20] [Predicting the Formation of Induction Heads](https://arxiv.org/abs/2511.16893)
*Tatsuya Aoyama,Ethan Gotlieb Wilcox,Nathan Schneider*

Main category: cs.CL

TL;DR: 研究归纳头（IHs）形成与训练数据统计特性的关系，发现批量大小、上下文大小、二元组重复频率与可靠性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 归纳头作为现代语言模型内在关键组件，对上下文学习能力有重要影响，但其形成机制尚不明确，研究其形成的统计学基础有助于理解和优化语言模型表现。

Method: 通过分析自然及合成训练数据的统计属性，结合理论方程和数据实验，探究了批量大小、上下文大小及二元组重复频率与可靠性如何影响归纳头的形成。

Result: 本文研究了现代语言模型中称为归纳头（IHs）的专门注意力头的形成机制。通过分析自然和合成训练数据的统计特性，作者发现：1）批量大小与上下文大小的简单方程可预测IH的形成时间点；2）表层二元组重复频率和可靠性对IH的形成有显著影响，且存在精确的帕累托前沿；3）高频和高可靠性的局部依赖足以促成IH形成，而在频率和可靠性较低时，类别性和边际分布形状也会起作用。

Conclusion: 归纳头的形成受训练数据的批次大小、上下文长度及二元组重复性和可靠性显著影响，高频高可靠性的局部依赖促进IH形成，频率和可靠性低时，数据的类别性和分布形状也影响IH形成。

Abstract: Arguably, specialized attention heads dubbed induction heads (IHs) underlie the remarkable in-context learning (ICL) capabilities of modern language models (LMs); yet, a precise characterization of their formation remains unclear. In this study, we investigate the relationship between statistical properties of training data (for both natural and synthetic data) and IH formation. We show that (1) a simple equation combining batch size and context size predicts the point at which IHs form; (2) surface bigram repetition frequency and reliability strongly affect the formation of IHs, and we find a precise Pareto frontier in terms of these two values; and (3) local dependency with high bigram repetition frequency and reliability is sufficient for IH formation, but when the frequency and reliability are low, categoriality and the shape of the marginal distribution matter.

</details>


### [21] [ARQUSUMM: Argument-aware Quantitative Summarization of Online Conversations](https://arxiv.org/abs/2511.16985)
*An Quang Tang,Xiuzhen Zhang,Minh Ngoc Dinh,Zhuang Li*

Main category: cs.CL

TL;DR: 本文提出ARQUSUMM，利用大语言模型和论证理论实现基于论证结构的量化对话摘要，提升了摘要的论证表达和量化准确性。


<details>
  <summary>Details</summary>
Motivation: 现有文本摘要方法忽视在线对话的论证性质，且未能深入揭示句内的论证结构，亟需一种能够捕捉论证主张及其理由并量化论证强度的摘要方法。

Method: ARQUSUMM利用基于论证理论的LLM少样本学习识别句内命题及其主张-理由关系，结合论证结构感知的聚类算法实现量化摘要。

Result: 实验表明，ARQUSUMM在对话和量化摘要任务中均优于现有模型，生成的摘要对用户更有帮助，且文本质量及量化准确率较高。

Conclusion: 本文提出的ARQUSUMM框架在揭示对话中的论证结构及其量化支持方面表现优异，生成的摘要在文本质量和量化准确性上均优于现有模型。

Abstract: Online conversations have become more prevalent on public discussion platforms (e.g. Reddit). With growing controversial topics, it is desirable to summarize not only diverse arguments, but also their rationale and justification. Early studies on text summarization focus on capturing general salient information in source documents, overlooking the argumentative nature of online conversations. Recent research on conversation summarization although considers the argumentative relationship among sentences, fail to explicate deeper argument structure within sentences for summarization. In this paper, we propose a novel task of argument-aware quantitative summarization to reveal the claim-reason structure of arguments in conversations, with quantities measuring argument strength. We further propose ARQUSUMM, a novel framework to address the task. To reveal the underlying argument structure within sentences, ARQUSUMM leverages LLM few-shot learning grounded in the argumentation theory to identify propositions within sentences and their claim-reason relationships. For quantitative summarization, ARQUSUMM employs argument structure-aware clustering algorithms to aggregate arguments and quantify their support. Experiments show that ARQUSUMM outperforms existing conversation and quantitative summarization models and generate summaries representing argument structures that are more helpful to users, of high textual quality and quantification accuracy.

</details>


### [22] [Supervised Fine Tuning of Large Language Models for Domain Specific Knowledge Graph Construction:A Case Study on Hunan's Historical Celebrities](https://arxiv.org/abs/2511.17012)
*Junjie Hao,Chun Wang,Ying Qiao,Qiuyue Zuo,Qiya Song,Hua Ma,Xieping Gao*

Main category: cs.CL

TL;DR: 本研究通过指令微调提升大语言模型在湖南历史名人领域的信息提取能力，促进文化遗产知识图谱构建。


<details>
  <summary>Details</summary>
Motivation: 解决湖南现代历史名人领域数据资源有限，通用模型在领域知识提取和结构化输出表现不足的问题。

Method: 设计细粒度的领域指导指令模板，构建指令微调数据集，采用参数高效的指令微调方法对四个大语言模型进行微调。

Result: 通过微调，所有模型性能显著提升，Qwen3-8B表现最佳，达89.39分。

Conclusion: 指令微调使大语言模型在地域历史文化领域表现出强大潜力，为低成本文化遗产知识抽取提供可行路径。

Abstract: Large language models and knowledge graphs offer strong potential for advancing research on historical culture by supporting the extraction, analysis, and interpretation of cultural heritage. Using Hunan's modern historical celebrities shaped by Huxiang culture as a case study, pre-trained large models can help researchers efficiently extract key information, including biographical attributes, life events, and social relationships, from textual sources and construct structured knowledge graphs. However, systematic data resources for Hunan's historical celebrities remain limited, and general-purpose models often underperform in domain knowledge extraction and structured output generation in such low-resource settings. To address these issues, this study proposes a supervised fine-tuning approach for enhancing domain-specific information extraction. First, we design a fine-grained, schema-guided instruction template tailored to the Hunan historical celebrities domain and build an instruction-tuning dataset to mitigate the lack of domain-specific training corpora. Second, we apply parameter-efficient instruction fine-tuning to four publicly available large language models - Qwen2.5-7B, Qwen3-8B, DeepSeek-R1-Distill-Qwen-7B, and Llama-3.1-8B-Instruct - and develop evaluation criteria for assessing their extraction performance. Experimental results show that all models exhibit substantial performance gains after fine-tuning. Among them, Qwen3-8B achieves the strongest results, reaching a score of 89.3866 with 100 samples and 50 training iterations. This study provides new insights into fine-tuning vertical large language models for regional historical and cultural domains and highlights their potential for cost-effective applications in cultural heritage knowledge extraction and knowledge graph construction.

</details>


### [23] [Do Vision-Language Models Understand Visual Persuasiveness?](https://arxiv.org/abs/2511.17036)
*Gyuwon Park*

Main category: cs.CL

TL;DR: 本文通过新数据集和分类体系探讨视觉语言模型理解视觉说服的能力，发现模型难以将视觉信息与传播意图结合，但合理的推理介入能显著提升说服力判断效果。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型是否真正理解视觉说服，即视觉线索如何影响人类态度和决策。

Method: 构建高共识的数据集进行二元说服力判断，提出视觉说服因素（VPFs）分类体系，结合认知引导和知识注入策略进行说服相关推理。

Result: 模型倾向于高召回率但判断偏向高说服力，对低/中层特征辨别能力弱；高层语义一致性是预测人类判断的关键；基于对象的简洁理由提升模型表现明显。

Conclusion: 视觉语言模型（VLMs）在识别视觉说服对象方面表现较好，但其核心限制在于未能有效将视觉线索与传播意图关联起来。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive multi-modal reasoning and understanding. Yet, whether these models truly grasp visual persuasion-how visual cues shape human attitudes and decisions-remains unclear. To probe this question, we construct a high-consensus dataset for binary persuasiveness judgment and introduce the taxonomy of Visual Persuasive Factors (VPFs), encompassing low-level perceptual, mid-level compositional, and high-level semantic cues. We also explore cognitive steering and knowledge injection strategies for persuasion-relevant reasoning. Empirical analysis across VLMs reveals a recall-oriented bias-models over-predict high persuasiveness-and weak discriminative power for low/mid-level features. In contrast, high-level semantic alignment between message and object presence emerges as the strongest predictor of human judgment. Among intervention strategies, simple instruction or unguided reasoning scaffolds yield marginal or negative effects, whereas concise, object-grounded rationales significantly improve precision and F1 scores. These results indicate that VLMs core limitation lies not in recognizing persuasive objects but in linking them to communicative intent.

</details>


### [24] [Principled Design of Interpretable Automated Scoring for Large-Scale Educational Assessments](https://arxiv.org/abs/2511.17069)
*Yunsung Kim,Mike Hardy,Joseph Tey,Candace Thille,Chris Piech*

Main category: cs.CL

TL;DR: 本文提出了基于可解释性原则的自动评分框架AnalyticScore，实现了准确且人类可解读的短答案自动评分。


<details>
  <summary>Details</summary>
Motivation: 现有自动评分系统虽然高效且可扩展，但缺乏透明性和可解释性，难以满足大规模真实评估中对可解释自动评分的需求。

Method: 提出了AnalyticScore框架，通过提取学生回答中的显性元素，利用大语言模型将回答特征化为人类可解读的数值，并使用序数逻辑回归模型进行评分。

Result: AnalyticScore在ASAP-SAS数据集上的评分准确率优于许多不可解释方法，且与当前最先进的不可解释模型评分的QWK仅相差0.06，且其特征化行为与人类注释者高度一致。

Conclusion: 通过确立具体的可解释性原则并实现AnalyticScore框架，本文为实现透明且高效的自动评分系统提供了有效途径，推动了可解释自动评分在大规模应用中的发展。

Abstract: AI-driven automated scoring systems offer scalable and efficient means of evaluating complex student-generated responses. Yet, despite increasing demand for transparency and interpretability, the field has yet to develop a widely accepted solution for interpretable automated scoring to be used in large-scale real-world assessments. This work takes a principled approach to address this challenge. We analyze the needs and potential benefits of interpretable automated scoring for various assessment stakeholders and develop four principles of interpretability -- Faithfulness, Groundedness, Traceability, and Interchangeability (FGTI) -- targeted at those needs. To illustrate the feasibility of implementing these principles, we develop the AnalyticScore framework for short answer scoring as a baseline reference framework for future research. AnalyticScore operates by (1) extracting explicitly identifiable elements of the responses, (2) featurizing each response into human-interpretable values using LLMs, and (3) applying an intuitive ordinal logistic regression model for scoring. In terms of scoring accuracy, AnalyticScore outperforms many uninterpretable scoring methods, and is within only 0.06 QWK of the uninterpretable SOTA on average across 10 items from the ASAP-SAS dataset. By comparing against human annotators conducting the same featurization task, we further demonstrate that the featurization behavior of AnalyticScore aligns well with that of humans.

</details>


### [25] [MUCH: A Multilingual Claim Hallucination Benchmark](https://arxiv.org/abs/2511.17081)
*Jérémie Dentan,Alexi Canesse,Davide Buscaldi,Aymen Shabou,Sonia Vanier*

Main category: cs.CL

TL;DR: 本文提出了MUCH，一个首个面向声称级不确定性量化的基准，涵盖多语种与多模型，支持白盒方法开发，并引入高效的断句算法，适用于实时监控。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型缺乏可靠性，且声称级不确定性量化缺乏公平、可复现且贴近实际条件的评测基准，以及高效的断句工具。

Method: 设计并发布包含4,873样本、4种欧洲语言和4个开源权重模型的基准数据，提供每个token的24个生成logits；提出一种仅需0.2%生成时间的确定性断句算法以实现高效分段。

Result: MUCH基准展示了当前方法在实际应用中的不足，为未来提升不确定性量化性能与效率提供了坚实基础。

Conclusion: 现有不确定性量化方法在性能和效率方面仍有较大提升空间，MUCH基准为公平、公正评价和推进方法发展提供了重要工具。

Abstract: Claim-level Uncertainty Quantification (UQ) is a promising approach to mitigate the lack of reliability in Large Language Models (LLMs). We introduce MUCH, the first claim-level UQ benchmark designed for fair and reproducible evaluation of future methods under realistic conditions. It includes 4,873 samples across four European languages (English, French, Spanish, and German) and four instruction-tuned open-weight LLMs. Unlike prior claim-level benchmarks, we release 24 generation logits per token, facilitating the development of future white-box methods without re-generating data. Moreover, in contrast to previous benchmarks that rely on manual or LLM-based segmentation, we propose a new deterministic algorithm capable of segmenting claims using as little as 0.2% of the LLM generation time. This makes our segmentation approach suitable for real-time monitoring of LLM outputs, ensuring that MUCH evaluates UQ methods under realistic deployment constraints. Finally, our evaluations show that current methods still have substantial room for improvement in both performance and efficiency.

</details>


### [26] [Training Foundation Models on a Full-Stack AMD Platform: Compute, Networking, and System Design](https://arxiv.org/abs/2511.17127)
*Quentin Anthony,Yury Tokpanov,Skyler Szot,Srivatsan Rajagopal,Praneeth Medepalli,Rishi Iyer,Vasu Shyam,Anna Golubeva,Ansh Chaurasia,Xiao Yang,Tomas Figliolia,Robert Washbourne,Drew Thorstensen,Amartey Pearson,Zack Grossbart,Jason van Patten,Emad Barsoum,Zhenyu Gu,Yao Fu,Beren Millidge*

Main category: cs.CL

TL;DR: 该研究首次在纯AMD硬件上进行大规模MoE预训练，提出系统和模型设计指导，开发出性能优异的ZAYA1模型，表明AMD生态具备强大竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索基于AMD纯硬件的混合专家模型(MoE)大规模预训练，验证其系统和模型设计的实用指导性。

Method: 在MI300X GPU与Pollara互联硬件上进行大规模系统和网络性能微基准测试，提出基于硬件特性的Transformer调整规则，设计优化MoE宽度；详细描述训练堆栈和训练方案。

Result: 成功开发并预训练了ZAYA1-base模型，表现与领先模型Qwen3-4B、Gemma3-12B相当，优于Llama-3-8B等模型，在推理、数学和编程任务表现优异。

Conclusion: AMD硬件、网络和软件堆栈已经足够成熟并优化，适合进行有竞争力的大规模预训练工作。

Abstract: We report on the first large-scale mixture-of-experts (MoE) pretraining study on pure AMD hardware, utilizing both MI300X GPUs with Pollara interconnect. We distill practical guidance for both systems and model design. On the systems side, we deliver a comprehensive cluster and networking characterization: microbenchmarks for all core collectives (all-reduce, reduce-scatter, all-gather, broadcast) across message sizes and GPU counts on Pollara. To our knowledge, this is the first at this scale. We further provide MI300X microbenchmarks on kernel sizing and memory bandwidth to inform model design. On the modeling side, we introduce and apply MI300X-aware transformer sizing rules for attention and MLP blocks and justify MoE widths that jointly optimize training throughput and inference latency. We describe our training stack in depth, including often-ignored utilities such as fault-tolerance and checkpoint-reshaping, as well as detailed information on our training recipe. We also provide a preview of our model architecture and base model - ZAYA1 (760M active, 8.3B total parameters MoE) - which will be further improved upon in forthcoming papers. ZAYA1-base achieves performance comparable to leading base models such as Qwen3-4B and Gemma3-12B at its scale and larger, and outperforms models including Llama-3-8B and OLMoE across reasoning, mathematics, and coding benchmarks. Together, these results demonstrate that the AMD hardware, network, and software stack are mature and optimized enough for competitive large-scale pretraining.

</details>


### [27] [Learning to Compress: Unlocking the Potential of Large Language Models for Text Representation](https://arxiv.org/abs/2511.17129)
*Yeqin Zhang,Yizheng Zhao,Chen Hu,Binxing Jiao,Daxin Jiang,Ruihang Miao,Cam-Tu Nguyen*

Main category: cs.CL

TL;DR: 本文提出利用上下文压缩作为预训练任务，增强大语言模型的文本表示能力，效果优于传统标记预测任务，且训练更高效。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多为自回归结构，因下个标记预测任务难以生成整体文本表示，亟需设计新的预训练任务以提升文本表示效果。

Method: 设计上下文压缩预训练任务，训练模型生成紧凑记忆向量代替全文上下文，再结合对比学习优化表示效果。

Result: 本文提出了一种基于上下文压缩的自监督预训练方法，用于将大语言模型（LLMs）适配为文本表示模型。不同于现有依赖于掩码或下一个词预测的标记级任务，本文设计的压缩预训练任务通过生成紧凑的记忆向量，压缩整个上下文信息，显著提升了文本表示效果。实验显示，该方法优于基于标记预测的任务，且通过对比学习进一步增强，构建的模型LLM2Comp在多个任务上性能优异且对训练数据需求少，样本效率高。

Conclusion: 上下文压缩作为预训练任务能够有效提升LLM文本表示质量，且结合对比学习后模型性能提升明显，训练数据需求明显降低。

Abstract: Text representation plays a critical role in tasks like clustering, retrieval, and other downstream applications. With the emergence of large language models (LLMs), there is increasing interest in harnessing their capabilities for this purpose. However, most of the LLMs are inherently causal and optimized for next-token prediction, making them suboptimal for producing holistic representations. To address this, recent studies introduced pretext tasks to adapt LLMs for text representation. Most of these tasks, however, rely on token-level prediction objectives, such as the masked next-token prediction (MNTP) used in LLM2Vec. In this work, we explore the untapped potential of context compression as a pretext task for unsupervised adaptation of LLMs. During compression pre-training, the model learns to generate compact memory tokens, which substitute the whole context for downstream sequence prediction. Experiments demonstrate that a well-designed compression objective can significantly enhance LLM-based text representations, outperforming models trained with token-level pretext tasks. Further improvements through contrastive learning produce a strong representation model (LLM2Comp) that outperforms contemporary LLM-based text encoders on a wide range of tasks while being more sample-efficient, requiring significantly less training data.

</details>


### [28] [LangMark: A Multilingual Dataset for Automatic Post-Editing](https://arxiv.org/abs/2511.17153)
*Diego Velazquez,Mikaela Grace,Konstantinos Karageorgos,Lawrence Carin,Aaron Schliem,Dimitrios Zaikis,Roger Wechsler*

Main category: cs.CL

TL;DR: 该论文提出了一个规模大且语言多样的APE数据集LangMark，并证明了大语言模型在APE任务中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动后期编辑（APE）系统缺乏大规模多语言NMT输出专用数据集，限制了APE的发展和效果提升。

Method: 构建人工注释的多语言APE数据集，利用大语言模型进行少样本提示学习，实现自动后期编辑任务。

Result: 发布了LangMark数据集，包含206,983组多语言（三元组）数据；通过实验证明大语言模型（LLMs）在少样本提示下可有效执行APE，性能优于主流和专有机器翻译系统。

Conclusion: LangMark数据集填补了多语言APE数据缺口，促进了APE系统的发展，大语言模型是高效APE方法的有力工具。

Abstract: Automatic post-editing (APE) aims to correct errors in machine-translated text, enhancing translation quality, while reducing the need for human intervention. Despite advances in neural machine translation (NMT), the development of effective APE systems has been hindered by the lack of large-scale multilingual datasets specifically tailored to NMT outputs. To address this gap, we present and release LangMark, a new human-annotated multilingual APE dataset for English translation to seven languages: Brazilian Portuguese, French, German, Italian, Japanese, Russian, and Spanish. The dataset has 206,983 triplets, with each triplet consisting of a source segment, its NMT output, and a human post-edited translation. Annotated by expert human linguists, our dataset offers both linguistic diversity and scale. Leveraging this dataset, we empirically show that Large Language Models (LLMs) with few-shot prompting can effectively perform APE, improving upon leading commercial and even proprietary machine translation systems. We believe that this new resource will facilitate the future development and evaluation of APE systems.

</details>


### [29] [The PLLuM Instruction Corpus](https://arxiv.org/abs/2511.17161)
*Piotr Pęzik,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Maciej Chrabąszcz,Anna Kołos,Agnieszka Karlińska,Karolina Seweryn,Aleksandra Krasnodębska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Artur Wilczek,Maciej Trzciński,Katarzyna Dziewulska,Roman Roszko,Tomasz Bernaś,Jurgita Vaičenonienė,Danuta Roszko,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Alina Wróblewska,Katarzyna Krasnowska-Kieraś,Maciej Ogrodniczuk,Michał Rudolf,Piotr Rybak,Karolina Saputa,Joanna Wołoszyn,Marcin Oleksy,Bartłomiej Koptyra,Teddy Ferdinan,Stanisław Woźniak,Maciej Piasecki,Paweł Walkowiak,Konrad Wojtasik,Arkadiusz Janz,Przemysław Kazienko,Julia Moska,Jan Kocoń*

Main category: cs.CL

TL;DR: 本文介绍了PLLuM项目中用于微调基于transformer的大型语言模型的指令数据集，涵盖有机、转换和合成指令，并发布了代表性子集PLLuMIC。


<details>
  <summary>Details</summary>
Motivation: 为更好地适应基础大型语言模型的语言能力，探索人类与合成指令数据在微调中的作用及效果。

Method: 作者构建了包含有机、转换和合成指令的多样化指令数据集，并通过微调transformer大型语言模型进行实验。

Result: 发布了代表PLLuM项目指令数据集的子集PLLuMIC，并提出了使用不同指令类型的观察与建议。

Conclusion: 使用人类编写与合成指令数据集对基础LLM的语言适应具有不同影响，PLLuMIC数据集可作为其他类似数据集开发的参考。

Abstract: This paper describes the instruction dataset used to fine-tune a set of transformer-based large language models (LLMs) developed in the PLLuM (Polish Large Language Model) project. We present a functional typology of the organic, converted, and synthetic instructions used in PLLuM and share some observations about the implications of using human-authored versus synthetic instruction datasets in the linguistic adaptation of base LLMs. Additionally, we release the first representative subset of the PLLuM instruction corpus (PLLuMIC), which we believe to be useful in guiding and planning the development of similar datasets for other LLMs.

</details>


### [30] [Hallucinate Less by Thinking More: Aspect-Based Causal Abstention for Large Language Models](https://arxiv.org/abs/2511.17170)
*Vy Nguyen,Ziqi Xu,Jeffrey Chan,Estrid He,Feng Xia,Xiuzhen Zhang*

Main category: cs.CL

TL;DR: 提出基于因果推断的ABCA方法，通过分析知识多样性，实现提前放弃回答，提高了语言模型放弃的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽然生成流畅，但常出现事实错误（幻觉），现有放弃回答方法依赖生成后信号，难以提前阻止不可靠回答。

Method: 提出基于因果推断的方面因果放弃（ABCA）框架，通过分析模型内部知识多样性，估计与查询相关知识的因果效应，实现两类放弃：知识冲突和知识不足。

Result: ABCA在标准基准测试中提升了放弃回答的可靠性，达到最先进的表现，并增强了放弃决策的可解释性。

Conclusion: 通过考虑知识的多方面因果效应，ABCA有效提升了语言模型的放弃策略，有助于避免错误回答，提高模型安全性。

Abstract: Large Language Models (LLMs) often produce fluent but factually incorrect responses, a phenomenon known as hallucination. Abstention, where the model chooses not to answer and instead outputs phrases such as "I don't know", is a common safeguard. However, existing abstention methods typically rely on post-generation signals, such as generation variations or feedback, which limits their ability to prevent unreliable responses in advance. In this paper, we introduce Aspect-Based Causal Abstention (ABCA), a new framework that enables early abstention by analysing the internal diversity of LLM knowledge through causal inference. This diversity reflects the multifaceted nature of parametric knowledge acquired from various sources, representing diverse aspects such as disciplines, legal contexts, or temporal frames. ABCA estimates causal effects conditioned on these aspects to assess the reliability of knowledge relevant to a given query. Based on these estimates, we enable two types of abstention: Type-1, where aspect effects are inconsistent (knowledge conflict), and Type-2, where aspect effects consistently support abstention (knowledge insufficiency). Experiments on standard benchmarks demonstrate that ABCA improves abstention reliability, achieves state-of-the-art performance, and enhances the interpretability of abstention decisions.

</details>


### [31] [Attention-Guided Feature Fusion (AGFF) Model for Integrating Statistical and Semantic Features in News Text Classification](https://arxiv.org/abs/2511.17184)
*Mohammad Zare*

Main category: cs.CL

TL;DR: 本文提出的AGFF模型通过融合统计和语义特征，结合注意力机制提升新闻文本分类性能，是一种有效且实用的多特征融合方案。


<details>
  <summary>Details</summary>
Motivation: 传统统计方法虽有效捕捉词频信息，但缺乏上下文理解能力；而深度学习语义特征虽有上下文感知能力，却忽视了简单高效的统计指标，因此需要一种融合两者优势的方法。

Method: 设计了一种基于注意力引导的特征融合模型，将传统统计特征和现代语义特征结合，在分类过程中动态调整两类特征的重要性。

Result: 在标准新闻数据集上的评测显示，AGFF模型优于仅使用统计特征或单纯语义特征的模型。消融实验进一步验证了各组件的贡献。

Conclusion: 本文提出的AGFF模型通过注意力机制融合统计特征和语义特征，显著提升了新闻文本分类的准确率，证明了多特征融合的有效性。

Abstract: News text classification is a crucial task in natural language processing, essential for organizing and filtering the massive volume of digital content. Traditional methods typically rely on statistical features like term frequencies or TF-IDF values, which are effective at capturing word-level importance but often fail to reflect contextual meaning. In contrast, modern deep learning approaches utilize semantic features to understand word usage within context, yet they may overlook simple, high-impact statistical indicators. This paper introduces an Attention-Guided Feature Fusion (AGFF) model that combines statistical and semantic features in a unified framework. The model applies an attention-based mechanism to dynamically determine the relative importance of each feature type, enabling more informed classification decisions. Through evaluation on benchmark news datasets, the AGFF model demonstrates superior performance compared to both traditional statistical models and purely semantic deep learning models. The results confirm that strategic integration of diverse feature types can significantly enhance classification accuracy. Additionally, ablation studies validate the contribution of each component in the fusion process. The findings highlight the model's ability to balance and exploit the complementary strengths of statistical and semantic representations, making it a practical and effective solution for real-world news classification tasks.

</details>


### [32] [AutoLink: Autonomous Schema Exploration and Expansion for Scalable Schema Linking in Text-to-SQL at Scale](https://arxiv.org/abs/2511.17190)
*Ziyang Wang,Yuanlei Zheng,Zhenbiao Cao,Xiaojin Zhang,Zhongyu Wei,Pei Fu,Zhenbo Luo,Wei Chen,Xiang Bai*

Main category: cs.CL

TL;DR: AutoLink是一种自主代理框架，通过迭代和大型语言模型指导，动态筛选并扩展数据库的相关 schema 子集，实现高效的schema linking。


<details>
  <summary>Details</summary>
Motivation: 现有方案在工业级文本到SQL任务中受上下文窗口限制影响大，难以有效筛选和采用庞大数据库的完整schema，且召回率、噪声控制和扩展性表现不佳。

Method: 通过将schema linking重构为一个迭代的自主代理过程，AutoLink利用大型语言模型动态探索和扩展相关的schema子集，避免输入完整数据库模式。

Result: AutoLink在Bird-Dev和Spider-2.0-Lite数据集上分别达到97.4%和91.2%的严格schema linking召回率，执行准确率显著提升，并在处理超过3000列的大型模式时表现优异。

Conclusion: AutoLink在大规模数据库中实现了优异的schema linking召回率和执行准确率，具备良好扩展性和效率，显著优于现有方法。

Abstract: For industrial-scale text-to-SQL, supplying the entire database schema to Large Language Models (LLMs) is impractical due to context window limits and irrelevant noise. Schema linking, which filters the schema to a relevant subset, is therefore critical. However, existing methods incur prohibitive costs, struggle to trade off recall and noise, and scale poorly to large databases. We present \textbf{AutoLink}, an autonomous agent framework that reformulates schema linking as an iterative, agent-driven process. Guided by an LLM, AutoLink dynamically explores and expands the linked schema subset, progressively identifying necessary schema components without inputting the full database schema. Our experiments demonstrate AutoLink's superior performance, achieving state-of-the-art strict schema linking recall of \textbf{97.4\%} on Bird-Dev and \textbf{91.2\%} on Spider-2.0-Lite, with competitive execution accuracy, i.e., \textbf{68.7\%} EX on Bird-Dev (better than CHESS) and \textbf{34.9\%} EX on Spider-2.0-Lite (ranking 2nd on the official leaderboard). Crucially, AutoLink exhibits \textbf{exceptional scalability}, \textbf{maintaining high recall}, \textbf{efficient token consumption}, and \textbf{robust execution accuracy} on large schemas (e.g., over 3,000 columns) where existing methods severely degrade-making it a highly scalable, high-recall schema-linking solution for industrial text-to-SQL systems.

</details>


### [33] [E$^3$-Pruner: Towards Efficient, Economical, and Effective Layer Pruning for Large Language Models](https://arxiv.org/abs/2511.17205)
*Tao Yuan,Haoli Bai,Yinfei Pan,Xuyang Cao,Tianyu Zhang,Lu Hou,Ting Hu,Xianzhi Yu*

Main category: cs.CL

TL;DR: 提出了\name层裁剪框架，通过创新掩码优化和知识蒸馏策略，有效提升层裁剪性能和推理速度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有层裁剪方法难以同时解决性能下降、训练成本高和加速效果有限的问题。

Method: 采用基于Gumbel-TopK采样器的可微分掩码优化方法和熵感知的自适应知识蒸馏策略进行层裁剪。

Result: 在MATH-500测试集上，\name实现了仅0.8%性能损失的情况下裁剪25%层，准确率达96%，比最先进方法提高1%，推理速度提升1.33倍，训练数据消耗极少。

Conclusion: 本文提出的\name框架在保证性能的前提下，实现了显著的模型层裁剪和加速，优于现有最先进方法。

Abstract: With the increasing size of large language models, layer pruning has gained increased attention as a hardware-friendly approach for model compression. However, existing layer pruning methods struggle to simultaneously address key practical deployment challenges, including performance degradation, high training costs, and limited acceleration. To overcome these limitations, we propose \name, a task-\underline{E}ffective, training-\underline{E}conomical and inference-\underline{E}fficient layer pruning framework. \namespace introduces two key innovations: (1) a differentiable mask optimization method using a Gumbel-TopK sampler, enabling efficient and precise pruning mask search; and (2) an entropy-aware adaptive knowledge distillation strategy that enhances task performance. Extensive experiments over diverse model architectures and benchmarks demonstrate the superiority of our method over state-of-the-art approaches. Notably, \namespace achieves 96\% accuracy, a mere 0.8\% drop from the original model (96.8\%) on MATH-500 when pruning 25\% layers of Qwen3-32B, outperforming existing SOTA (95\%), with a 1.33$\times$ inference speedup by consuming merely 0.5B tokens (0.5\% of the post-training data volume).

</details>


### [34] [A Simple Yet Strong Baseline for Long-Term Conversational Memory of LLM Agents](https://arxiv.org/abs/2511.17208)
*Sizhe Zhou*

Main category: cs.CL

TL;DR: 提出基于事件语义的对话记忆结构，通过事件式命题和异质图检索提升多会话连贯性和个性化，超过强基线且上下文更短。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于大语言模型的对话代理中上下文窗口限制及外部记忆粗粒度检索与碎片化问题，提升多轮对话的连贯性和个性化表现。

Method: 将对话分解为带归一化实体和转发归属的基本话语单元(EDUs)，构建异质图形结构以支持联想检索，结合密集相似度搜索和大语言模型过滤，利用图传播聚合相关证据。

Result: 本文提出了一种基于事件语义的对话记忆结构，将对话历史表示为短小的事件式命题，包含参与者、时间线索和最小本地上下文，避免了传统方法中信息压缩和碎片化的问题。通过将对话分解为富含实体归一化和转发归属的基本话语单元(EDUs)，并构建异质图支持联想检索，实现了基于密集相似度和LLM过滤的检索机制，提升了多会话中对话的连贯性与个性化。实验证明该方法在多个基准测试中超越了强基线，且所需问答上下文更短，表明事件级记忆结构为长时对话代理提供了有效且实用的基础。

Conclusion: 事件级、结构简单的记忆机制能够有效支持长时对话代理，实现高效且连贯的多会话交互。

Abstract: LLM-based conversational agents still struggle to maintain coherent, personalized interaction over many sessions: fixed context windows limit how much history can be kept in view, and most external memory approaches trade off between coarse retrieval over large chunks and fine-grained but fragmented views of the dialogue. Motivated by neo-Davidsonian event semantics, we propose an event-centric alternative that represents conversational history as short, event-like propositions which bundle together participants, temporal cues, and minimal local context, rather than as independent relation triples or opaque summaries. In contrast to work that aggressively compresses or forgets past content, our design aims to preserve information in a non-compressive form and make it more accessible, rather than more lossy. Concretely, we instruct an LLM to decompose each session into enriched elementary discourse units (EDUs) -- self-contained statements with normalized entities and source turn attributions -- and organize sessions, EDUs, and their arguments in a heterogeneous graph that supports associative recall. On top of this representation we build two simple retrieval-based variants that use dense similarity search and LLM filtering, with an optional graph-based propagation step to connect and aggregate evidence across related EDUs. Experiments on the LoCoMo and LongMemEval$_S$ benchmarks show that these event-centric memories match or surpass strong baselines, while operating with much shorter QA contexts. Our results suggest that structurally simple, event-level memory provides a principled and practical foundation for long-horizon conversational agents. Our code and data will be released at https://github.com/KevinSRR/EMem.

</details>


### [35] [Parrot: Persuasion and Agreement Robustness Rating of Output Truth -- A Sycophancy Robustness Benchmark for LLMs](https://arxiv.org/abs/2511.17220)
*Yusuf Çelebi,Mahmoud El Hussieni,Özay Ezerceli*

Main category: cs.CL

TL;DR: 该论文提出了PARROT框架，用于评估大型语言模型在权威和说服力施加的社会压力下准确性的下降，揭示了不同模型对虚假信息的服从率差异及其信心变化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在权威和说服力压力下容易产生过度趋从（谄媚行为），导致准确性显著下降，亟需一种框架衡量和分类这种鲁棒性问题。

Method: 通过双盲评估比较同一问题的中立版本与权威虚假版本，利用基于对数似然的置信度校准追踪置信度变化，系统分类失败模式，并在13个领域使用1302个MMLU风格多项选择题测试22个模型。

Result: 研究发现先进模型如GPT-5的跟随率低至4%，准确率下降较小，而较小或旧模型如GPT-4的跟随率高达80%，严重降低了对正确答案的信心。数学领域较为稳健，而国际法等领域极易受影响。

Conclusion: 不同大型语言模型在面对社会压力时表现出显著差异，先进模型表现出较低的服从率和较小的准确率下降，而较旧或较小模型则表现出严重的知识崩溃。针对这种脆弱性，模型的抗过拟合压力能力应成为与准确性、避免伤害和隐私保护同等重要的目标。

Abstract: This study presents PARROT (Persuasion and Agreement Robustness Rating of Output Truth), a robustness focused framework designed to measure the degradation in accuracy that occurs under social pressure exerted on users through authority and persuasion in large language models (LLMs) the phenomenon of sycophancy (excessive conformity). PARROT (i) isolates causal effects by comparing the neutral version of the same question with an authoritatively false version using a double-blind evaluation, (ii) quantifies confidence shifts toward the correct and imposed false responses using log-likelihood-based calibration tracking, and (iii) systematically classifies failure modes (e.g., robust correct, sycophantic agreement, reinforced error, stubborn error, self-correction, etc.) using an eight-state behavioral taxonomy. We evaluated 22 models using 1,302 MMLU-style multiple-choice questions across 13 domains and domain-specific authority templates. Findings show marked heterogeneity: advanced models (e.g., GPT-5, GPT-4.1, Claude Sonnet 4.5) exhibit low "follow rates" ($\leq 11\%$, GPT-5: 4\%) and minimal accuracy loss, while older/smaller models show severe epistemic collapse (GPT-4: 80\%, Qwen 2.5-1.5B: 94\%). The danger is not limited to response changes; weak models reduce confidence in the correct response while increasing confidence in the imposed incorrect response. While international law and global knowledge at the domain level exhibit high fragility, elementary mathematics is relatively resilient. Consequently, we argue that the goal of "resistance to overfitting pressure" should be addressed as a primary objective alongside accuracy, harm avoidance, and privacy for safe deployment in the real world.

</details>


### [36] [Lost in Translation and Noise: A Deep Dive into the Failure Modes of VLMs on Real-World Tables](https://arxiv.org/abs/2511.17238)
*Anshul Singh,Rohan Chaudhary,Gagneet Singh,Abhay Kumary*

Main category: cs.CL

TL;DR: MirageTVQA是一个多语言且含视觉噪声的表格问答数据集，揭示现有VLMs在噪声和跨语言迁移上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有VLM表格问答数据集单一以英语为主且表格格式理想，与现实应用中多语言、多样且含视觉噪声的表格存在明显差距，作者旨在创建更真实复杂的数据集来推动模型在实际场景中的表现提升。

Method: 构建包含24种语言、约6万问答对的多语言表格问答数据集MirageTVQA，并引入视觉噪声模拟扫描文档的不完美状态。通过该数据集对现有领先VLM进行评测，分析其性能下降和语言偏见问题。

Result: 本文提出了MirageTVQA，一个多语言且包含视觉噪声的表格问答数据集，涵盖24种语言和近6万个问答对，以模拟真实世界的复杂场景。评测当前领先的视觉语言模型（VLM）显示其在面对视觉噪声时性能显著下降（最高下降35%），并且存在英语优先偏见，推理能力难以迁移至其他语言。该工作填补了现有多语言和非理想视觉表格问答数据集的空白，为推动更加鲁棒的VLM表格推理能力提供了新的基准。

Conclusion: 当前领先的VLMs在面对视觉噪声和非英语语言时表现显著下降，显示出模型的鲁棒性和多语言泛化能力存在不足。MirageTVQA为提升模型的鲁棒性和多语言适应能力提供了重要的评测基准。

Abstract: The impressive performance of VLMs is largely measured on benchmarks that fail to capture the complexities of real-world scenarios. Existing datasets for tabular QA, such as WikiTableQuestions and FinQA, are overwhelmingly monolingual (English) and present tables in a digitally perfect, clean format. This creates a significant gap between research and practice. To address this, we present \textbf{MirageTVQA}, a new benchmark designed to evaluate VLMs on these exact dimensions. Featuring nearly 60,000 QA pairs across 24 languages, MirageTVQA challenges models with tables that are not only multilingual but also visually imperfect, incorporating realistic noise to mimic scanned documents. Our evaluation of the leading VLMs reveals two primary failure points: a severe degradation in performance (over 35\% drop for the best models) when faced with visual noise and a consistent English-first bias where reasoning abilities fail to transfer to other languages. MirageTVQA provides a benchmark for measuring and driving progress towards more robust VLM models for table reasoning. The dataset and the code are available at: https://github.com/anshulsc/MirageTVQA.

</details>


### [37] [Social-Media Based Personas Challenge: Hybrid Prediction of Common and Rare User Actions on Bluesky](https://arxiv.org/abs/2511.17241)
*Benjamin White,Anastasia Shimorina*

Main category: cs.CL

TL;DR: 提出一种结合多种模型的方法，准确预测社交媒体上的高频和罕见用户行为，在大规模数据集上表现优异，并获竞赛一等奖。


<details>
  <summary>Details</summary>
Motivation: 社交媒体用户行为预测对内容推荐和平台设计重要，现有研究多关注常见行为，忽视了罕见但关键行为的预测。

Method: 结合查找数据库系统、LightGBM模型、融合文本和时间序列的神经网络及文本回复生成四种方法，实现对不同类型行为的预测。

Result: 本文提出了一种混合方法，用于预测社交媒体用户的行为，涵盖高频和低频行为。方法结合了基于历史模式的查找数据库、针对不同用户群体的LightGBM模型、融合文本和时序特征的神经网络模型，以及文本回复生成。使用包含640万对话线程和25个用户群体的Bluesky数据集进行评估，高频行为预测宏F1得分为0.64，罕见行为预测得分为0.56。该方法在COLM 2025会议的社会模拟挑战中获得第一名。

Conclusion: 社交媒体行为预测需采用针对不同行为类型的专门模型策略，结合多元方法可有效提升预测性能。

Abstract: Understanding and predicting user behavior on social media platforms is crucial for content recommendation and platform design. While existing approaches focus primarily on common actions like retweeting and liking, the prediction of rare but significant behaviors remains largely unexplored. This paper presents a hybrid methodology for social media user behavior prediction that addresses both frequent and infrequent actions across a diverse action vocabulary. We evaluate our approach on a large-scale Bluesky dataset containing 6.4 million conversation threads spanning 12 distinct user actions across 25 persona clusters. Our methodology combines four complementary approaches: (i) a lookup database system based on historical response patterns; (ii) persona-specific LightGBM models with engineered temporal and semantic features for common actions; (iii) a specialized hybrid neural architecture fusing textual and temporal representations for rare action classification; and (iv) generation of text replies. Our persona-specific models achieve an average macro F1-score of 0.64 for common action prediction, while our rare action classifier achieves 0.56 macro F1-score across 10 rare actions. These results demonstrate that effective social media behavior prediction requires tailored modeling strategies recognizing fundamental differences between action types. Our approach achieved first place in the SocialSim: Social-Media Based Personas challenge organized at the Social Simulation with LLMs workshop at COLM 2025.

</details>


### [38] [Estonian WinoGrande Dataset: Comparative Analysis of LLM Performance on Human and Machine Translation](https://arxiv.org/abs/2511.17290)
*Marii Ojastu,Hele-Andra Kuulmets,Aleksei Dorkin,Marika Borovikova,Dage Särg,Kairit Sirts*

Main category: cs.CL

TL;DR: 本文介绍了对WinoGrande测试集的爱沙尼亚语本地化翻译及文化适配过程，并评估了多模型在该数据集上的表现。结果显示人类翻译数据的模型表现略低于英文原版，机器翻译效果明显较差，提示工程改善有限。


<details>
  <summary>Details</summary>
Motivation: 为适配常用推理基准WinoGrande至爱沙尼亚语，解决语言和文化差异带来的挑战，且评估不同模型在本地化数据上的表现，为提高多语言推理能力提供依据。

Method: 由翻译专家完成WinoGrande测试集的爱沙尼亚语翻译和文化适配，并评估多种专有及开源模型在人工翻译及机器翻译测试集上的表现。同时设计了基于手动翻译经验的细化提示以尝试提升机器翻译质量。

Result: 模型在人类翻译的爱沙尼亚语数据集上的表现略低于英文原版，机器翻译数据上的表现明显较差。提示工程对机器翻译质量和模型准确率提升有限。强调语言专家参与数据集制作的重要性。

Conclusion: 语言专家参与数据集翻译和适配对于保证语言能力和推理评估的可靠性和可解释性至关重要。人类翻译数据集上的模型表现优于机器翻译数据，提示高质量翻译对于评估准确性有重要影响。

Abstract: In this paper, we present a localized and culturally adapted Estonian translation of the test set from the widely used commonsense reasoning benchmark, WinoGrande. We detail the translation and adaptation process carried out by translation specialists and evaluate the performance of both proprietary and open source models on the human translated benchmark. Additionally, we explore the feasibility of achieving high-quality machine translation by incorporating insights from the manual translation process into the design of a detailed prompt. This prompt is specifically tailored to address both the linguistic characteristics of Estonian and the unique translation challenges posed by the WinoGrande dataset. Our findings show that model performance on the human translated Estonian dataset is slightly lower than on the original English test set, while performance on machine-translated data is notably worse. Additionally, our experiments indicate that prompt engineering offers limited improvement in translation quality or model accuracy, and highlight the importance of involving language specialists in dataset translation and adaptation to ensure reliable and interpretable evaluations of language competency and reasoning in large language models.

</details>


### [39] [Large Language Models for Sentiment Analysis to Detect Social Challenges: A Use Case with South African Languages](https://arxiv.org/abs/2511.17301)
*Koena Ronny Mabokela,Tim Schlippe,Matthias Wölfel*

Main category: cs.CL

TL;DR: 本文探讨了利用多种先进大型语言模型对南非多语言社交媒体帖子进行零样本情感分析，发现模型间差异显著，融合结果显著提升分类效果，支持政府部门社情监测。


<details>
  <summary>Details</summary>
Motivation: 多语言社区中情感分析可帮助快速识别社交媒体上的社会问题，尤其是南非多语言环境中现有对大型语言模型应用于多语言情感分析的研究缺乏，亟需探索LLMs在此领域的性能及实际应用潜力。

Method: 评估了GPT-3.5、GPT-4、LLaMa 2、PaLM 2和Dolly 2五种先进大型语言模型在英语、Sepedi和Setswana三种语言中对10个热门话题的零样本情感分析表现，并采用模型融合技术提升情感分类效果。

Result: 本文分析了多语言社区中情感分析的应用，特别是在南非多语言环境下，利用大型语言模型（LLMs）进行社交媒体帖子的情感极性分析。研究评估了GPT-3.5、GPT-4、LLaMa 2、PaLM 2和Dolly 2等先进LLMs在英语、Sepedi和Setswana三种语言的零样本情感分析性能。结果显示不同模型、话题和语言间存在较大差异，但融合多模型结果可显著提升情感分类准确率，错误率低于1%。该系统可帮助政府部门精准识别社交媒体中的社会问题并有效响应。

Conclusion: 融合多种大型语言模型的输出能够极大提升南非多语言社交媒体帖子的情感分类准确率，从而实现对社会挑战的有效检测和响应。

Abstract: Sentiment analysis can aid in understanding people's opinions and emotions on social issues. In multilingual communities sentiment analysis systems can be used to quickly identify social challenges in social media posts, enabling government departments to detect and address these issues more precisely and effectively. Recently, large-language models (LLMs) have become available to the wide public and initial analyses have shown that they exhibit magnificent zero-shot sentiment analysis abilities in English. However, there is no work that has investigated to leverage LLMs for sentiment analysis on social media posts in South African languages and detect social challenges. Consequently, in this work, we analyse the zero-shot performance of the state-of-the-art LLMs GPT-3.5, GPT-4, LlaMa 2, PaLM 2, and Dolly 2 to investigate the sentiment polarities of the 10 most emerging topics in English, Sepedi and Setswana social media posts that fall within the jurisdictional areas of 10 South African government departments. Our results demonstrate that there are big differences between the various LLMs, topics, and languages. In addition, we show that a fusion of the outcomes of different LLMs provides large gains in sentiment classification performance with sentiment classification errors below 1%. Consequently, it is now feasible to provide systems that generate reliable information about sentiment analysis to detect social challenges and draw conclusions about possible needs for actions on specific topics and within different language groups.

</details>


### [40] [Humanlike Multi-user Agent (HUMA): Designing a Deceptively Human AI Facilitator for Group Chats](https://arxiv.org/abs/2511.17315)
*Mateusz Jacniacki,Martí Carmona Serrat*

Main category: cs.CL

TL;DR: 本文提出了基于大语言模型的多用户对话代理HUMA，能够模拟人类的交互策略和响应时间，实现自然的异步群聊。实验表明AI代理在群聊中表现可与人类相当，难以被区分。


<details>
  <summary>Details</summary>
Motivation: 目前大多数对话系统仅支持一对一交互，群聊中缺乏自然且人性化的互动方式，迫切需要提升AI在多方异步对话中的表现以增强用户信任和参与度。

Method: 设计了事件驱动架构的多用户对话系统，包含Router、Action Agent和Reflection三部分，用以适应群聊动态，同时模拟真实响应时间。通过对97名参与者的控制实验验证效果。

Result: 通过四人角色扮演实验，HUMA在社区管理效果、社交存在感及用户满意度上与人类管理员持平，且难以被参与者识别为非人类。

Conclusion: HUMA作为AI群聊引导者，其表现与人类社区管理员无显著差异，用户很难区分其身份，且用户体验良好。

Abstract: Conversational agents built on large language models (LLMs) are becoming increasingly prevalent, yet most systems are designed for one-on-one, turn-based exchanges rather than natural, asynchronous group chats. As AI assistants become widespread throughout digital platforms, from virtual assistants to customer service, developing natural and humanlike interaction patterns seems crucial for maintaining user trust and engagement. We present the Humanlike Multi-user Agent (HUMA), an LLM-based facilitator that participates in multi-party conversations using human-like strategies and timing. HUMA extends prior multi-user chatbot work with an event-driven architecture that handles messages, replies, reactions and introduces realistic response-time simulation. HUMA comprises three components-Router, Action Agent, and Reflection-which together adapt LLMs to group conversation dynamics.
  We evaluate HUMA in a controlled study with 97 participants in four-person role-play chats, comparing AI and human community managers (CMs). Participants classified CMs as human at near-chance rates in both conditions, indicating they could not reliably distinguish HUMA agents from humans. Subjective experience was comparable across conditions: community-manager effectiveness, social presence, and engagement/satisfaction differed only modestly with small effect sizes. Our results suggest that, in natural group chat settings, an AI facilitator can match human quality while remaining difficult to identify as nonhuman.

</details>


### [41] [A new kid on the block: Distributional semantics predicts the word-specific tone signatures of monosyllabic words in conversational Taiwan Mandarin](https://arxiv.org/abs/2511.17337)
*Xiaoyun Jin,Mirjam Ernestus,R. Harald Baayen*

Main category: cs.CL

TL;DR: 本文利用广义加性模型和分布式语义嵌入，表明普通话单音节词的声调受词义影响，挑战了传统声调理论。


<details>
  <summary>Details</summary>
Motivation: 探究词义如何影响汉语口语中单音节词的声调轮廓，挑战传统汉语声调理论。

Method: 采用广义加性模型分解观察到的声调轮廓，控制多种变量，结合分布式语义嵌入进行预测。

Result: 词义效果优于单纯词汇效应，异形同音词声调不同，语义嵌入能够准确预测单词语音的声调轮廓。

Conclusion: 词汇语义对普通话单音节词的声调实现有显著影响，语义信息能够更好地预测声调轮廓。

Abstract: We present a corpus-based investigation of how the pitch contours of monosyllabic words are realized in spontaneous conversational Mandarin, focusing on the effects of words' meanings. We used the generalized additive model to decompose a given observed pitch contour into a set of component pitch contours that are tied to different control variables and semantic predictors. Even when variables such as word duration, gender, speaker identity, tonal context, vowel height, and utterance position are controlled for, the effect of word remains a strong predictor of tonal realization. We present evidence that this effect of word is a semantic effect: word sense is shown to be a better predictor than word, and heterographic homophones are shown to have different pitch contours. The strongest evidence for the importance of semantics is that the pitch contours of individual word tokens can be predicted from their contextualized embeddings with an accuracy that substantially exceeds a permutation baseline. For phonetics, distributional semantics is a new kid on the block. Although our findings challenge standard theories of Mandarin tone, they fit well within the theoretical framework of the Discriminative Lexicon Model.

</details>


### [42] [Don't Learn, Ground: A Case for Natural Language Inference with Visual Grounding](https://arxiv.org/abs/2511.17358)
*Daniil Ignatev,Ayman Santeer,Albert Gatt,Denis Paperno*

Main category: cs.CL

TL;DR: 本文提出一种零-shot的多模态自然语言推理方法，利用文本生成的视觉表示与文本假设进行比较，实现高准确性和良好鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统自然语言推理方法易受文本偏差和表面启发式影响，利用视觉上下文中的多模态表示可以改善推理的鲁棒性。

Method: 通过文本到图像模型将前提文本转换为视觉表示，并通过比较视觉表示和文本假设进行推理，采用余弦相似度和视觉问答两种推理技术。

Result: 该方法在无需任务特定微调的情况下实现了较高的准确率，并且在设计的对抗性数据集上验证了其鲁棒性。

Conclusion: 利用视觉模态作为语义表示，有助于提升自然语言推理的鲁棒性和准确性。

Abstract: We propose a zero-shot method for Natural Language Inference (NLI) that leverages multimodal representations by grounding language in visual contexts. Our approach generates visual representations of premises using text-to-image models and performs inference by comparing these representations with textual hypotheses. We evaluate two inference techniques: cosine similarity and visual question answering. Our method achieves high accuracy without task-specific fine-tuning, demonstrating robustness against textual biases and surface heuristics. Additionally, we design a controlled adversarial dataset to validate the robustness of our approach. Our findings suggest that leveraging visual modality as a meaning representation provides a promising direction for robust natural language understanding.

</details>


### [43] [Selective Rotary Position Embedding](https://arxiv.org/abs/2511.17388)
*Sajad Movahedi,Timur Carstensen,Arshia Afzal,Frank Hutter,Antonio Orvieto,Volkan Cevher*

Main category: cs.CL

TL;DR: 本文提出Selective RoPE，一种输入依赖的旋转位置编码方法，提升了transformer在语言和序列任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的RoPE采用固定角度旋转编码位置信息，而选择性机制已被证明能改进语言相关任务性能，故提出一种结合输入依赖选择性的旋转编码方法。

Method: 引入Selective RoPE，通过输入依赖的旋转实现位置编码，并将其应用于线性和softmax transformer，在带门控的transformer中验证其有效性。

Result: 实验证明，Selective RoPE在语言建模及复杂序列任务（如复制、状态跟踪和检索）中表现优越，揭示了softmax attention隐含的旋转结构和状态空间模型中旋转编码的作用。

Conclusion: 本文提出了Selective RoPE，一种基于输入依赖的旋转位置编码机制，推广了传统RoPE，能够实现任意角度的旋转，提升了语言建模和复杂序列任务的性能。

Abstract: Position information is essential for language modeling. In softmax transformers, Rotary Position Embeddings (\textit{RoPE}) encode positions through \textit{fixed-angle} rotations, while in linear transformers, order is handled via input-dependent (selective) gating that decays past key-value associations. Selectivity has generally been shown to improve language-related tasks. Inspired by this, we introduce \textit{Selective RoPE}, an \textit{input-dependent} rotary embedding mechanism, that generalizes \textit{RoPE}, and enables rotation in \textit{arbitrary angles} for both linear and softmax transformers. We show that softmax attention already performs a hidden form of these rotations on query-key pairs, uncovering an implicit positional structure. We further show that in state-space models and gated linear transformers, the real part manages forgetting while the imaginary part encodes positions through rotations. We validate our method by equipping gated transformers with \textit{Selective RoPE}, demonstrating that its input-dependent rotations improve performance in language modeling and on difficult sequence tasks like copying, state tracking, and retrieval.

</details>


### [44] [PUCP-Metrix: A Comprehensive Open-Source Repository of Linguistic Metrics for Spanish](https://arxiv.org/abs/2511.17402)
*Javier Alonso Villegas Luis,Marco Antonio Sobrevilla Cabezudo*

Main category: cs.CL

TL;DR: PUCP-Metrix是一个涵盖多样语言特征的西班牙语开源指标库，支持文本分析与多种NLP任务，性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有西班牙语语言分析工具覆盖有限，难以满足对风格、结构和可读性等多维语言特征的需求，故需构建全面且可解释的语言特征指标库。

Method: 通过构建包含182种语言指标的库，涵盖词汇、句法、语义等多个维度，并将其应用于自动可读性评估和机器生成文本检测任务中进行评估。

Result: 该论文提出了PUCP-Metrix，一个开源的西班牙语语言指标库，涵盖182种语言特征，涵盖词汇多样性、句法和语义复杂性、衔接性、心理语言学和可读性。通过细粒度、可解释的文本分析工具，PUCP-Metrix被用于自动可读性评估和机器生成文本检测，性能优于现有资源和神经基线模型。该资源为西班牙语自然语言处理提供了全面且可扩展的支持。

Conclusion: PUCP-Metrix为西班牙语文本分析提供了全面、可解释且有效的工具，表现优于已有资源，适用于多样NLP应用。

Abstract: Linguistic features remain essential for interpretability and tasks involving style, structure, and readability, but existing Spanish tools offer limited coverage. We present PUCP-Metrix, an open-source repository of 182 linguistic metrics spanning lexical diversity, syntactic and semantic complexity, cohesion, psycholinguistics, and readability. PUCP-Metrix enables fine-grained, interpretable text analysis. We evaluate its usefulness on Automated Readability Assessment and Machine-Generated Text Detection, showing competitive performance compared to an existing repository and strong neural baselines. PUCP-Metrix offers a comprehensive, extensible resource for Spanish, supporting diverse NLP applications.

</details>


### [45] [Beyond Multiple Choice: A Hybrid Framework for Unifying Robust Evaluation and Verifiable Reasoning Training](https://arxiv.org/abs/2511.17405)
*Yesheng Liu,Hao Li,Haiyu Xu,Baoqi Pei,Jiahao Wang,Mingxuan Zhao,Jingshu Zheng,Zheqi He,JG Yao,Bowen Qin,Xi Yang,Jiajun Zhang*

Main category: cs.CL

TL;DR: 本文提出ReVeL框架，将多选题转为开放式问答，缓解选项泄露问题，提升模型性能和评测准确性。


<details>
  <summary>Details</summary>
Motivation: 多选题格式虽然便于自动验证，但答案选项存在泄露信号，导致模型训练和评测准确率不可靠，亟需新方法避免答案猜测行为并提升模型实际能力的评价准确性。

Method: ReVeL框架根据答案类型改写多选题为开放式问题，结合验证策略进行训练和评估，采用GRPO算法对Qwen2.5-VL模型进行强化微调。

Result: 本文提出了一种针对多选题问答（MCQA）中答案泄露问题的解决方案ReVeL。ReVeL通过将多选题改写为开放式问题，结合不同答案类型制定相应的改写和验证策略，避免了传统MCQA中选项泄露带来的准确率虚高现象。实验证明，利用ReVeL进行强化微调的模型在多选题准确率持平的同时，开放式问答准确率提升约6个百分点，数据效率和奖励信号更优。评估时，ReVeL能揭示多选题基准中高达20个百分点的分数膨胀，提升评判准确率并降低成本和延迟。

Conclusion: ReVeL有效缓解了多选题中的泄露问题，提升了训练和评测的可靠性和效率，未来代码和数据将公开。

Abstract: Multiple-choice question answering (MCQA) has been a popular format for evaluating and reinforcement fine-tuning (RFT) of modern multimodal language models. Its constrained output format allows for simplified, deterministic automatic verification. However, we find that the options may leak exploitable signals, which makes the accuracy metrics unreliable for indicating real capabilities and encourages explicit or implicit answer guessing behaviors during RFT. We propose ReVeL (Rewrite and Verify by LLM), a framework that rewrites multiple-choice questions into open-form questions while keeping answers verifiable whenever possible. The framework categorizes questions according to different answer types, apply different rewriting and verification schemes, respectively. When applied for RFT, we converted 20k MCQA examples and use GRPO to finetune Qwen2.5-VL models. Models trained on ReVeL-OpenQA match MCQA accuracy on multiple-choice benchmarks and improve OpenQA accuracy by about six percentage points, indicating better data efficiency and more robust reward signals than MCQA-based training. When used for evaluation, ReVeL also reveals up to 20 percentage points of score inflation in MCQA benchmarks (relative to OpenQA), improves judging accuracy, and reduces both cost and latency. We will release code and data publicly.

</details>


### [46] [SMILE: A Composite Lexical-Semantic Metric for Question-Answering Evaluation](https://arxiv.org/abs/2511.17432)
*Shrikant Kendre,Austin Xu,Honglu Zhou,Michael Ryoo,Shafiq Joty,Juan Carlos Niebles*

Main category: cs.CL

TL;DR: SMILE是一种结合语义理解和词汇匹配的综合评价指标，提升了文本和视觉问答的评估准确性并保持计算轻量。


<details>
  <summary>Details</summary>
Motivation: 当前问答评价指标过度依赖词汇匹配，缺乏深层语义理解；现有基于上下文嵌入的方法未能兼顾词汇和语义的平衡，且大型语言模型评估器存在高成本和偏差问题，促使提出SMILE以实现更全面且高效的评估。

Method: SMILE结合句子层面语义理解、关键词层面语义理解和关键词易匹配性，形成综合的评价指标，实现了词汇和语义信息的平衡。

Result: 本文提出了SMILE评价指标，通过结合句子层面和关键词层面的语义理解及词汇匹配，实现了对文本和视觉问答的综合评估。相较传统的基于n-gram相似度的方法（如ROUGE、METEOR、EM），SMILE能够更准确反映语义信息；并且相比BERTScore和MoverScore，SMILE在平衡句子语义和关键词语义以及保留词汇匹配方面表现更优。实验证明SMILE在文本、图像和视频问答任务中与人工评价高度相关，同时计算开销较低。

Conclusion: SMILE有效平衡了词汇准确性和语义相关性，能更全面、准确地评估问答任务表现，且具有较好的人类评价相关性和计算效率。

Abstract: Traditional evaluation metrics for textual and visual question answering, like ROUGE, METEOR, and Exact Match (EM), focus heavily on n-gram based lexical similarity, often missing the deeper semantic understanding needed for accurate assessment. While measures like BERTScore and MoverScore leverage contextual embeddings to address this limitation, they lack flexibility in balancing sentence-level and keyword-level semantics and ignore lexical similarity, which remains important. Large Language Model (LLM) based evaluators, though powerful, come with drawbacks like high costs, bias, inconsistency, and hallucinations. To address these issues, we introduce SMILE: Semantic Metric Integrating Lexical Exactness, a novel approach that combines sentence-level semantic understanding with keyword-level semantic understanding and easy keyword matching. This composite method balances lexical precision and semantic relevance, offering a comprehensive evaluation. Extensive benchmarks across text, image, and video QA tasks show SMILE is highly correlated with human judgments and computationally lightweight, bridging the gap between lexical and semantic evaluation.

</details>


### [47] [Masked-and-Reordered Self-Supervision for Reinforcement Learning from Verifiable Rewards](https://arxiv.org/abs/2511.17473)
*Zhen Wang,Zhifeng Gao,Guolin Ke*

Main category: cs.CL

TL;DR: 该论文提出一种基于过程级自监督奖励的训练方法，提高了大语言模型在数学推理中，尤其是在只能验证最终结果的情况下的性能和扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR在数学推理特别是定理证明中的扩展性有限，难以中间推理且最终答案难以直接验证，且基于token级的SFT容易导致死记硬背而非长链思考。

Method: 提出MR-RLVR（Masked-and-Reordered RLVR），通过“masked-then-fill”和“step reordering”构造过程级自监督奖励，结合两阶段训练（自监督训练和RLVR微调）提升模型数学推理能力。

Result: 在多个数学测试集（AIME24, AIME25, AMC23, MATH500）上，MR-RLVR相比原RLVR在固定采样和解码预算下，Pass@1提升9.86%，Pass@5提升5.27%，Pass@8提升4.00%。

Conclusion: 引入过程感知的自监督信号能有效提升RLVR在仅能验证最终结果场景下的扩展性和表现，促进模型更好地进行中间推理和数学推理任务。

Abstract: Test-time scaling has been shown to substantially improve large language models' (LLMs) mathematical reasoning. However, for a large portion of mathematical corpora, especially theorem proving, RLVR's scalability is limited: intermediate reasoning is crucial, while final answers are difficult to directly and reliably verify. Meanwhile, token-level SFT often degenerates into rote memorization rather than inducing longer chains of thought. Inspired by BERT's self-supervised tasks, we propose MR-RLVR (Masked-and-Reordered RLVR), which constructs process-level self-supervised rewards via "masked-then-fill" and "step reordering" to extract learnable signals from intermediate reasoning. Our training pipeline comprises two stages: we first perform self-supervised training on sampled mathematical calculation and proof data; we then conduct RLVR fine-tuning on mathematical calculation datasets where only outcomes are verifiable. We implement MR-RLVR on Qwen2.5-3B and DeepSeek-R1-Distill-Qwen-1.5B, and evaluate on AIME24, AIME25, AMC23, and MATH500. Under a fixed sampling and decoding budget, MR-RLVR achieves average relative gains over the original RLVR of +9.86% Pass@1, +5.27% Pass@5, and +4.00% Pass@8. These results indicate that incorporating process-aware self-supervised signals can effectively enhance RLVR's scalability and performance in only outcome-verifiable settings.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [48] [Multi-Agent Code Verification with Compound Vulnerability Detection](https://arxiv.org/abs/2511.16708)
*Shreshth Rajan*

Main category: cs.SE

TL;DR: CodeX-Verify多智能体系统提高代码漏洞检测准确率，可快速且高效应用于生产环境。


<details>
  <summary>Details</summary>
Motivation: 目前大型语言模型生成的代码存在大量漏洞，现有工具检测漏洞准确率有限且误报率较高，亟需一种更准确、高效的漏洞检测方法。

Method: 设计了包含四个专门查找不同漏洞类型的智能体的系统，利用智能体间检测模式的多样性，通过数学证明和实测数据验证了多智能体组合检测的有效性。

Result: 该论文提出了CodeX-Verify多智能体系统，用于检测代码中的各种漏洞，弥补现有工具检测能力不足的问题。系统通过组合不同检测模式的四个专门智能体，提高了缺陷检测的准确率和效率，经验证，组合智能体的协同工作能够捕捉更多漏洞，显著优于单一智能体方法。

Conclusion: 多智能体联合检测显著提升了代码漏洞检测准确率，且运行速度快，适合实际生产使用。

Abstract: LLMs generate buggy code: 29.6% of SWE-bench "solved" patches fail, 62% of BaxBench solutions have vulnerabilities, and existing tools only catch 65% of bugs with 35% false positives. We built CodeX-Verify, a multi-agent system that uses four specialized agents to detect different types of bugs. We prove mathematically that combining agents with different detection patterns finds more bugs than any single agent when the agents look for different problems, confirmed by measuring agent correlation of p = 0.05--0.25. We also show that multiple vulnerabilities in the same code create exponentially more risk than previously thought--SQL injection plus exposed credentials creates 15x more danger (risk 300 vs. 20) than traditional models predict. Testing on 99 code samples with verified labels shows our system catches 76.1% of bugs, matching the best existing method while running faster and without test execution. We tested 15 different agent combinations and found that using multiple agents improves accuracy by 39.7 percentage points (from 32.8% to 72.4%) compared to single agents, with gains of +14.9pp, +13.5pp, and +11.2pp for agents 2, 3, and 4. The best two-agent combination reaches 79.3% accuracy. Testing on 300 real patches from Claude Sonnet 4.5 runs in under 200ms per sample, making this practical for production use.

</details>


### [49] [Large language models for automated PRISMA 2020 adherence checking](https://arxiv.org/abs/2511.16707)
*Yuki Kataoka,Ryuhei So,Masahiro Banno,Yasushi Tsujimoto,Tomohiro Takayama,Yosuke Yamagishi,Takahiro Tsuge,Norio Yamamoto,Chiaki Suda,Toshi A. Furukawa*

Main category: cs.SE

TL;DR: 结构化PRISMA 2020检查表能显著提高大型语言模型对系统评价依从性评估的准确率，虽然仍需专家人工核实。


<details>
  <summary>Details</summary>
Motivation: 同行评审过程中评估PRISMA 2020依从性工作繁重，且缺乏可共享的评估基准，推动引入自动化与标准化的大型语言模型评估方法。

Method: 构建版权感知基准库，使用108个系统性评价文本，评估十个大型语言模型在五种输入格式下的表现，重点比较结构化检查表与手稿输入准确率，采用独立验证队列检验结果，最终选用Qwen3-Max模型进行全面评估。

Result: 该论文针对同行评审中评估PRISMA 2020指南依从性的问题，构建了一个包含108个获得知识共享许可系统评价的版权感知基准数据集，评估了十个大型语言模型在五种输入格式下的表现。结果显示，提供结构化的PRISMA 2020检查表（Markdown、JSON、XML或纯文本）相比仅提供手稿输入，准确率显著提高（约78.7-79.7%对45.21%，p<0.0001），且不同结构化格式之间无显著差异。模型间准确率范围为70.6%-82.8%，存在敏感性和特异性的权衡，且在独立验证队列中复现。采用高敏感性的开源模型Qwen3-Max，在完整数据集上的敏感性达95.1%，特异性为49.3%。结论指出，结构化检查表的使用能显著提升基于大型语言模型的PRISMA评估效果，但在编辑决策前仍需人工专家验证。

Conclusion: 结构化输入形式显著提升了大型语言模型评估PRISMA 2020依从性的准确性，但编辑决策前专家核查依然必不可少。

Abstract: Evaluating adherence to PRISMA 2020 guideline remains a burden in the peer review process. To address the lack of shareable benchmarks, we constructed a copyright-aware benchmark of 108 Creative Commons-licensed systematic reviews and evaluated ten large language models (LLMs) across five input formats. In a development cohort, supplying structured PRISMA 2020 checklists (Markdown, JSON, XML, or plain text) yielded 78.7-79.7% accuracy versus 45.21% for manuscript-only input (p less than 0.0001), with no differences between structured formats (p>0.9). Across models, accuracy ranged from 70.6-82.8% with distinct sensitivity-specificity trade-offs, replicated in an independent validation cohort. We then selected Qwen3-Max (a high-sensitivity open-weight model) and extended evaluation to the full dataset (n=120), achieving 95.1% sensitivity and 49.3% specificity. Structured checklist provision substantially improves LLM-based PRISMA assessment, though human expert verification remains essential before editorial decisions.

</details>


### [50] [Is the Cure Still Worse Than the Disease? Test Overfitting by LLMs in Automated Program Repair](https://arxiv.org/abs/2511.16858)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 当前自动程序修复仍面临测试过拟合问题，修复代码难以通过隐藏测试用例验证。


<details>
  <summary>Details</summary>
Motivation: 自动程序修复虽然提升了代码修复效率，但修复代码对测试集产生过拟合，影响了其泛化能力，特别是在大语言模型出现之前这一问题已有广泛研究，现希望重新评估其在新技术背景下的表现。

Method: 通过在仓库级别的SWE-bench任务上进行实验，评估修复代码在已知测试和隐藏测试上的表现差异。

Result: 本文通过实验证明，在当前自动程序修复中，测试过拟合问题依然存在，即生成的修复代码虽然通过了已知测试用例，但在隐藏测试用例上表现不佳。该研究基于仓库级SWE-bench任务评估了测试过拟合的现状。

Conclusion: 即使在大语言模型兴起后，测试过拟合仍是自动程序修复的挑战，需要进一步研究和解决。

Abstract: Automated program repair has been shown to be susceptible to generating repaired code that passes on seen tests but fails on a hold-out set of hidden tests. This problem, dubbed test overfitting, has been identified and studied before the rise of large language models. We experimentally study how much test overfitting is still a problem today, using repository-level SWE-bench tasks.

</details>


### [51] [MOOT: a Repository of Many Multi-Objective Optimization Tasks](https://arxiv.org/abs/2511.16882)
*Tim Menzies,Tao Chen,Yulong Ye,Kishan Kumar Ganguly,Amirali Rayegan,Srinath Srinivasan,Andre Lustosa*

Main category: cs.SE

TL;DR: 本文介绍了MOOT，一个开源的多目标优化任务仓库，帮助研究者解决软件工程中的目标权衡问题。


<details>
  <summary>Details</summary>
Motivation: 软件工程中需要在多个相互竞争的目标之间做权衡，现有技术和工具难以有效探索这些权衡，导致研究和实践均存在不足，因此需要一个集中的多目标优化任务资源库来促进研究和应用。

Method: 构建并公开了一个包含120多个来自软件工程实际研究的多目标优化任务的仓库MOOT，涵盖多个重要应用领域，并鼓励社区参与贡献。

Result: 本文介绍了MOOT，一个包含来自软件工程研究的多目标优化任务的仓库，旨在帮助研究人员和工业实践者更好地处理软件工程中的目标权衡问题。MOOT涵盖了软件配置、云调优、项目健康度、过程建模、超参数优化等120多个任务，数据开放且欢迎社区贡献。本文展示了利用这些数据可以提出的多个新颖研究问题。

Conclusion: MOOT为软件工程领域多目标优化研究提供了丰富的任务资源，促进了相关领域的进一步研究和实践。

Abstract: Software engineers must make decisions that trade off competing goals (faster vs. cheaper, secure vs. usable, accurate vs. interpretable, etc.). Despite MSR's proven techniques for exploring such goals, researchers still struggle with these trade-offs. Similarly, industrial practitioners deliver sub-optimal products since they lack the tools needed to explore these trade-offs.
  To enable more research in this important area, we introduce MOOT, a repository of multi-objective optimization tasks taken from recent SE research papers. MOOT's tasks cover software configuration, cloud tuning, project health, process modeling, hyperparameter optimization, and more. Located at github.com/timm/moot, MOOT's current 120+ tasks are freely available under an MIT license (and we invite community contributions). As shown here, this data enables dozens of novel research questions.

</details>


### [52] [ReVul-CoT: Towards Effective Software Vulnerability Assessment with Retrieval-Augmented Generation and Chain-of-Thought Prompting](https://arxiv.org/abs/2511.17027)
*Zhijie Chen,Xiang Chen,Ziming Li,Jiacheng Xue,Chaoyang Gao*

Main category: cs.SE

TL;DR: 通过融合知识检索与链式思维推理，ReVul-CoT显著提升了基于大语言模型的软件漏洞评估效果，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏领域专知识且依赖浅层模式匹配，难以理解复杂代码语义及其安全影响，限制了软件漏洞评估的效果。

Method: 提出了ReVul-CoT框架，结合了检索增强生成（RAG）和链式思维（CoT）提示方法，通过动态检索本地知识库中的上下文相关信息并引导模型进行逐步推理。

Result: 在包含12,070个漏洞的数据集上，ReVul-CoT在MCC指标上比现有最先进的基线方法提高了16.50%至42.26%，在准确率、F1分数和MCC上均超越最佳基线，消融实验验证了动态检索、知识整合和CoT推理的重要贡献。

Conclusion: 结合检索增强生成与链式思维提示的策略有效增强了基于大语言模型的软件漏洞评估能力，展示了未来研究的有前景方向。

Abstract: Context: Software Vulnerability Assessment (SVA) plays a vital role in evaluating and ranking vulnerabilities in software systems to ensure their security and reliability. Objective: Although Large Language Models (LLMs) have recently shown remarkable potential in SVA, they still face two major limitations. First, most LLMs are trained on general-purpose corpora and thus lack domain-specific knowledge essential for effective SVA. Second, they tend to rely on shallow pattern matching instead of deep contextual reasoning, making it challenging to fully comprehend complex code semantics and their security implications. Method: To alleviate these limitations, we propose a novel framework ReVul-CoT that integrates Retrieval-Augmented Generation (RAG) with Chain-of-Thought (COT) prompting. In ReVul-CoT, the RAG module dynamically retrieves contextually relevant information from a constructed local knowledge base that consolidates vulnerability data from authoritative sources (such as NVD and CWE), along with corresponding code snippets and descriptive information. Building on DeepSeek-V3.1, CoT prompting guides the LLM to perform step-by-step reasoning over exploitability, impact scope, and related factors Results: We evaluate ReVul-CoT on a dataset of 12,070 vulnerabilities. Experimental results show that ReVul-CoT outperforms state-of-the-art SVA baselines by 16.50%-42.26% in terms of MCC, and outperforms the best baseline by 10.43%, 15.86%, and 16.50% in Accuracy, F1-score, and MCC, respectively. Our ablation studies further validate the contributions of considering dynamic retrieval, knowledge integration, and CoT-based reasoning. Conclusion: Our results demonstrate that combining RAG with CoT prompting significantly enhances LLM-based SVA and points out promising directions for future research.

</details>


### [53] [UI-CUBE: Enterprise-Grade Computer Use Agent Benchmarking Beyond Task Accuracy to Operational Reliability](https://arxiv.org/abs/2511.17131)
*Horia Cristescu,Charles Park,Trong Canh Nguyen,Sergiu Talmacel,Alexandru-Gabriel Ilie,Stefan Adam*

Main category: cs.SE

TL;DR: 本文提出了UI-CUBE基准测试，系统评估当前计算机使用代理（CUA）在简单UI交互和复杂工作流中的性能表现，揭示了其在复杂任务中存在的根本架构局限。


<details>
  <summary>Details</summary>
Motivation: 现有CUA基准测试侧重功能正确性，缺乏对生产系统所需的操作可靠性的评估，需要一个系统性的基准来检验CUA在企业部署中的准备状态。

Method: 设计包含226个任务的两个难度等级的基准测试，涵盖简单界面交互、复杂复制粘贴任务和企业应用场景，采用系统化界面变化、多分辨率测试及自动化任务成功验证，评估五个最先进模型的表现。

Result: 简单UI交互任务成功率为67-85%，复杂工作流任务仅为9-19%；人类表现分别为97.9%和61.2%；性能表现出现明显断崖式下降，表明架构上的核心限制而非训练不足。

Conclusion: 当前CUA在简单任务上达到较好性能，但在复杂多步骤企业级工作流中表现显著下降，反映出内存管理、层次规划和状态协调等架构瓶颈，限制了其作为可靠工作流自动化工具的实用性。

Abstract: While current Computer Use Agent (CUA) benchmarks measure task completion effectively, they provide limited assessment of enterprise deployment readiness, emphasizing functional correctness over the operational reliability required for production systems. We present UI-CUBE (UiPath Computer Use BEnchmark), a systematic benchmark comprising 226 tasks across two difficulty tiers designed to expose fundamental architectural limitations in current CUAs. Our evaluation covers simple UI interactions (136 tasks) and complex workflows including copy-paste tasks (50 tasks) and enterprise application scenarios (40 tasks), with systematic interface variation coverage, multi-resolution testing and automated validation of task success through the application state. Evaluation of five state-of-the-art models reveals a sharp capability cliff rather than gradual performance degradation. Simple UI interactions achieve 67-85% success rates (compared to 97.9% human performance), but complex workflows drop precipitously to 9-19%. Human evaluators with no prior application experience achieve only 61.2% on complex tasks despite near-perfect performance on simple tasks, establishing realistic performance ceilings. This discontinuous performance pattern -- where agents achieve 68-87% of human performance on simple tasks but only 15-32% on complex workflows -- indicates fundamental architectural limitations in memory management, hierarchical planning, and state coordination rather than incremental capability gaps addressable through better training or prompting. UI-CUBE functions as an enterprise-readiness diagnostic, revealing that while current CUAs can manipulate individual interface elements, they cannot yet function as reliable workflow automation tools. These findings provide architectural insights essential for developing production-ready CUAs capable of managing complex, multi-step enterprise processes.

</details>


### [54] [SlsReuse: LLM-Powered Serverless Function Reuse](https://arxiv.org/abs/2511.17262)
*Jinfeng Wen,Yuehan Sun*

Main category: cs.SE

TL;DR: 本论文针对服务器无计算函数重用难题，提出了首个基于大语言模型的函数推荐框架SlsReuse，在自然语言任务查询下显著提升函数推荐效果。


<details>
  <summary>Details</summary>
Motivation: 服务器无计算为开发者提供了无基础设施管理的功能级任务实现方式，但新手开发者面临平台特异性编程风格异构性，导致开发过程繁琐且易错。因此，函数重用成为解决此问题的潜在方案。然而，目前缺乏专门的服务器无函数推荐方法，传统技术难以跨越任务描述与异构函数实现之间的语义鸿沟。本论文利用大语言模型弥合此鸿沟。

Method: 通过构建可重用函数库，利用大语言模型进行少样本提示工程以学习统一且语义增强的函数表示；结合意图感知发现、多级剪枝策略和相似度匹配，针对自然语言查询实现高效函数推荐。

Result: 提出了SlsReuse，一个基于大语言模型的服务器无函数重用框架。通过构建函数知识库、采用少样本提示工程获取语义增强表示，并结合意图感知发现、多级剪枝及相似度匹配，实现了对自然语言任务查询的有效函数推荐。基于ChatGPT-4o，SlsReuse在110个任务查询数据集上Recall@10达到91.20%，较现有最优方法提升24.53个百分点。

Conclusion: SlsReuse有效解决了服务器无函数重用中的语义鸿沟问题，显著提高了函数推荐的准确率和效率，展示了大语言模型在服务器无计算领域的应用潜力。

Abstract: Serverless computing has rapidly emerged as a popular cloud computing paradigm. It enables developers to implement function-level tasks, i.e., serverless functions, without managing infrastructure. While reducing operational overhead, it poses challenges, especially for novice developers. Developing functions from scratch requires adapting to heterogeneous, platform-specific programming styles, making the process time-consuming and error-prone. Function reuse offers a promising solution to address these challenges. However, research on serverless computing lacks a dedicated approach for function recommendation. Existing techniques from traditional contexts remain insufficient due to the semantic gap between task descriptions and heterogeneous function implementations. Advances in large language models (LLMs), pre-trained on large-scale corpora, create opportunities to bridge this gap by aligning developer requirements with function semantics.
  This paper presents SlsReuse, the first LLM-powered framework for serverless function reuse. Specifically, SlsReuse first constructs a reusable function repository serving as a foundational knowledge base. Then, it learns unified semantic-enhanced representations of heterogeneous functions through effective prompt engineering with few-shot prompting, capturing implicit code intent, target platforms, programming languages, and cloud services. Finally, given a natural language task query, SlsReuse performs intent-aware discovery combined with a multi-level pruning strategy and similarity matching. We evaluate SlsReuse on a curated dataset of 110 task queries. Built on ChatGPT-4o, one of the most representative LLMs, SlsReuse achieves Recall@10 of 91.20%, exceeding the state-of-the-art baseline by 24.53 percentage points.

</details>


### [55] [Detecting Performance-Relevant Changes in Configurable Software Systems](https://arxiv.org/abs/2511.17271)
*Sebastian Böhm,Florian Sattler,Norbert Siegmund,Sven Apel*

Main category: cs.SE

TL;DR: 提出ConfFLARE方法精准识别性能相关变更及关键配置，显著降低性能测试配置数量与时间。


<details>
  <summary>Details</summary>
Motivation: 性能是软件系统的波动属性，频繁的性能分析成本高昂，尤其在存在多配置时需要测量多个配置，传统的配置采样方法难以保证完整性，可能漏掉部分性能回归。

Method: 提出了ConfFLARE方法，通过识别与性能相关代码的数据流交互，估计代码变更是否影响性能，并提取参与交互的软件特征。基于这些特征选择相关配置子集进行性能分析。

Result: ConfFLARE在合成和真实软件系统的研究中，几乎正确检测了所有性能回归，识别了所有但两个相关特征，平均减少了79%（合成）和70%（真实）配置测试，显著节省性能测试时间。

Conclusion: ConfFLARE有效减少了性能回归检测所需的配置数量，在保证检测效果的前提下，显著提升性能测试效率。

Abstract: Performance is a volatile property of a software system and frequent performance profiling is required to keep the knowledge about a software system's performance behavior up to date. Repeating all performance measurements after every revision is a cost-intensive task, especially in the presence of configurability, where one has to measure multiple configurations to obtain a comprehensive picture. Configuration sampling is a common approach to control the measurement cost. However, it cannot guarantee completeness and might miss performance regressions, especially if they only affect few configurations. As an alternative to solve the cost reduction problem, we present ConfFLARE: ConfFLARE estimates whether a change potentially impacts performance by identifying data-flow interactions with performance-relevant code and extracts which software features participate in such interactions. Based on these features, we can select a subset of relevant configurations to focus performance profiling efforts on. In a study conducted on both, synthetic and real-world software systems, ConfFLARE correctly detects performance regressions in almost all cases and identifies relevant features in all but two cases, reducing the number of configurations to be tested on average by $79\%$ for synthetic and by $70\%$ for real-world regression scenarios saving hours of performance testing time.

</details>


### [56] [Framework Matters: Energy Efficiency of UI Automation Testing Frameworks](https://arxiv.org/abs/2511.17303)
*Timmie M. R. Lagermann,Kristina Sophia Carter,Su Mei Gwen Ho,Luís Cruz,Kerstin Eder,Maja H. Kirkeby*

Main category: cs.SE

TL;DR: 通过对比四种UI自动化测试框架的能耗，发现能耗差异大，开发者可据此优化测试以节能。


<details>
  <summary>Details</summary>
Motivation: 探究不同UI自动化测试框架在执行具体操作时的能量消耗，评估是否存在统一的能耗趋势，指导节能测试设计。

Method: 使用受控的客户端-服务器环境，并通过外部功率计测量，重复执行了多次UI操作测试，比较四种UI自动化测试框架的能耗表现。

Result: 不同框架和操作的能耗差异明显，Puppeteer在多种点击和文本输入操作中最节能，Selenium在刷新和滚动操作中表现最好，Nightwatch总体最不节能。

Conclusion: 透明化UI自动化测试框架的能耗信息，有助于开发者针对具体操作做出节能的测试选择。

Abstract: We examine per action energy consumption across four web user interface (UI) automation testing frameworks to determine whether consistent tendencies can guide energy-aware test design. Using a controlled client-server setup with external power metering, we repeat each UI action (refresh, click variants, checkbox, drag&drop, input-text, scroll) 35 times. Across each of the actions, energy costs vary by both framework and action. Puppeteer is the most efficient for left-click, right-click, double-click, checkbox, and input-text; Selenium is the most efficient for refresh and scroll; Nightwatch is generally the least energy efficient. The energy cost of performing the same action varied by up to a factor of six depending on the framework. This indicates that providing transparency of energy consumption for UI automation testing frameworks allows developers to make informed, energy-aware decisions when testing a specific UI action.

</details>


### [57] [Agentic Program Verification](https://arxiv.org/abs/2511.17330)
*Haoxin Tu,Huan Zhao,Yahui Song,Mehtab Zafar,Ruijie Meng,Abhik Roychoudhury*

Main category: cs.SE

TL;DR: AutoRocq利用大语言模型与定理证明器协同，实现了自动程序验证的迭代证明构建，推动可信自动编程。


<details>
  <summary>Details</summary>
Motivation: 利用AI进行数学推理的潜力扩展到程序验证，解决代码推理的结构复杂性和上下文丰富性问题。

Method: 提出了AutoRocq，一个基于大语言模型的程序验证代理，采用迭代细化循环，通过与Rocq定理证明器的交互自主构建证明。

Result: 在SV-COMP基准和Linux内核模块上展示了自动化程序验证的有效性。

Conclusion: 该方法展示了AI程序验证的自适应和自动化潜力，未来可与AI代码生成代理结合，实现生成-验证闭环。

Abstract: Automatically generated code is gaining traction recently, owing to the prevalence of Large Language Models (LLMs). Further, the AlphaProof initiative has demonstrated the possibility of using AI for general mathematical reasoning. Reasoning about computer programs (software) can be accomplished via general mathematical reasoning; however, it tends to be more structured and richer in contexts. This forms an attractive proposition, since then AI agents can be used to reason about voluminous code that gets generated by AI.
  In this work, we present a first LLM agent, AutoRocq, for conducting program verification. Unlike past works, which rely on extensive training of LLMs on proof examples, our agent learns on-the-fly and improves the proof via an iterative refinement loop. The iterative improvement of the proof is achieved by the proof agent communicating with the Rocq (formerly Coq) theorem prover to get additional context and feedback. The final result of the iteration is a proof derivation checked by the Rocq theorem prover. In this way, our proof construction involves autonomous collaboration between the proof agent and the theorem prover. This autonomy facilitates the search for proofs and decision-making in deciding on the structure of the proof tree.
  Experimental evaluation on SV-COMP benchmarks and on Linux kernel modules shows promising efficacy in achieving automated program verification. As automation in code generation becomes more widespread, we posit that our proof agent can be potentially integrated with AI coding agents to achieve a generate and validate loop, thus moving closer to the vision of trusted automatic programming.

</details>


### [58] [Exploring Scientific Debt: Harnessing AI for SATD Identification in Scientific Software](https://arxiv.org/abs/2511.17368)
*Eric L. Melin,Ahmed Musa Awon,Nasir U. Eisty,Neil A. Ernst,Shurui Zhou*

Main category: cs.SE

TL;DR: 本研究揭示了科学软件中SATD的严重性与特点，提出了基于Transformer的识别方法，促进更好管理技术债务以保护科研质量。


<details>
  <summary>Details</summary>
Motivation: 科学软件(SW)中的自我承认技术债务(SATD)对科研的准确性和可复现性有重要影响，但这方面的研究不足。

Method: 分析27个科学和通用开源代码库中的SATD，比较两者差异；微调并比较10个基于Transformer的模型，使用67,066条标记代码注释进行训练。

Result: 科学软件中的SATD比通用软件高9.25倍的科学债务和4.93倍的技术债务，最优模型性能优于现有模型。

Conclusion: 科学软件的SATD特点更复杂，影响软件质量和科研有效性；认识这些差异有助于开发更智能的管理策略，保障科学发现的完整性。

Abstract: Developers often leave behind clues in their code, admitting where it falls short, known as Self-Admitted Technical Debt (SATD). In the world of Scientific Software (SSW), where innovation moves fast and collaboration is key, such debt is not just common but deeply impactful. As research relies on accurate and reproducible results, accumulating SATD can threaten the very foundations of scientific discovery. Yet, despite its significance, the relationship between SATD and SSW remains largely unexplored, leaving a crucial gap in understanding how to manage SATD in this critical domain. This study explores SATD in SSW repositories, comparing SATD in scientific versus general-purpose open-source software and evaluating transformer-based models for SATD identification. We analyzed SATD in 27 scientific and general-purpose repositories across multiple domains and languages. We fine-tuned and compared 10 transformer-based models (100M-7B parameters) on 67,066 labeled code comments. SSW contains 9.25x more Scientific Debt and 4.93x more SATD than general-purpose software due to complex computations, domain constraints, and evolving research needs. Furthermore, our best model outperforms existing ones. This study uncovers how SATD in SSW differs from general software, revealing its impact on quality and scientific validity. By recognizing these challenges, developers and researchers can adopt smarter strategies to manage debt and safeguard the integrity of scientific discovery.

</details>


### [59] [CREST: Improving Interpretability and Effectiveness of Troubleshooting at Ericsson through Criterion-Specific Trouble Report Retrieval](https://arxiv.org/abs/2511.17417)
*Soroush Javdan,Pragash Krishnamoorthy,Olga Baysal*

Main category: cs.SE

TL;DR: 本文提出基于多标准组合模型的CREST方法，提升了电信行业故障报告的检索效率和结果解释性。


<details>
  <summary>Details</summary>
Motivation: 电信行业故障报告数据类型复杂且多样，传统单一模型难以充分利用不同标准信息，急需更有效且可解释的检索方法以支持快速故障定位和维护。

Method: CREST方法通过训练多个针对不同故障报告字段的专门检索模型，利用其输出的组合来捕获多样且互补的信息，从而提高检索效果与解释能力。

Result: 本文提出了CREST，一种针对不同故障报告(TR)标准的组合检索模型，能够有效提升故障定位的检索性能和结果解释性。通过利用专门针对不同TR字段训练的模型，CREST整合多样且互补的信号，实现了更准确的检索和更合理的评分校准。实验结果表明，该方法显著优于单一模型，验证了多标准融合在提高检索系统性能中的重要性。

Conclusion: 采用基于故障报告多标准的专门模型组合策略显著提升了检索系统的准确性和可解释性，有助于加快故障解决和软件维护。

Abstract: The rapid evolution of the telecommunication industry necessitates efficient troubleshooting processes to maintain network reliability, software maintainability, and service quality. Trouble Reports (TRs), which document issues in Ericsson's production system, play a critical role in facilitating the timely resolution of software faults. However, the complexity and volume of TR data, along with the presence of diverse criteria that reflect different aspects of each fault, present challenges for retrieval systems. Building on prior work at Ericsson, which utilized a two-stage workflow, comprising Initial Retrieval (IR) and Re-Ranking (RR) stages, this study investigates different TR observation criteria and their impact on the performance of retrieval models. We propose \textbf{CREST} (\textbf{C}riteria-specific \textbf{R}etrieval via \textbf{E}nsemble of \textbf{S}pecialized \textbf{T}R models), a criterion-driven retrieval approach that leverages specialized models for different TR fields to improve both effectiveness and interpretability, thereby enabling quicker fault resolution and supporting software maintenance. CREST utilizes specialized models trained on specific TR criteria and aggregates their outputs to capture diverse and complementary signals. This approach leads to enhanced retrieval accuracy, better calibration of predicted scores, and improved interpretability by providing relevance scores for each criterion, helping users understand why specific TRs were retrieved. Using a subset of Ericsson's internal TRs, this research demonstrates that criterion-specific models significantly outperform a single model approach across key evaluation metrics. This highlights the importance of all targeted criteria used in this study for optimizing the performance of retrieval systems.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [60] [Optimizing PyTorch Inference with LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2511.16964)
*Kirill Nagaitsev,Luka Grbcic,Samuel Williams,Costin Iancu*

Main category: cs.MA

TL;DR: 提出并验证了基于多智能体系统的PyTorch GPU优化方法，显著提升了GPU推理性能，最高达2.88倍加速。


<details>
  <summary>Details</summary>
Motivation: 提升现代AI推理系统在GPU硬件上的性能，传统方法需要手写GPU内核或使用专业模型编译器，且效率有限。利用LLM多智能体系统自动调优，有望超越现有编译器并减少手动开发负担。

Method: 构建逻辑框架比较多智能体PyTorch优化系统，使用多智能体系统对GPU优化进行策略调节与错误修复。

Result: 实验证明，偏向利用已知策略的多智能体系统结合错误修正代理效果最佳，性能与优化步骤的粒度正相关。最佳方法在H100 GPU上对KernelBench基准测评中多个任务实现了平均2.88倍加速。

Conclusion: 多智能体系统中利用-修正策略组合及细粒度优化步骤是提升GPU推理性能的关键，表明此方法具备替代传统编译器的潜力。

Abstract: Maximizing performance on available GPU hardware is an ongoing challenge for modern AI inference systems. Traditional approaches include writing custom GPU kernels and using specialized model compilers to tune high-level code for specific GPU targets. Recent work shows that LLM-based multi-agent systems can effectively perform such tuning, often outperforming existing compilers and eliminating the need for manual kernel development. However, the dynamics of multi-agent systems for this task remain unexplored. In this work, we present a logical framework for comparing multi-agent PyTorch optimization systems. Our evaluation shows that exploit-heavy strategies perform best when paired with error-fixing agents, and that performance correlates with the granularity of optimization steps. The best implementation achieves an average 2.88x speedup on an H100 GPU across diverse tasks in KernelBench, a benchmark suite covering a range of machine learning architectures in PyTorch.

</details>


### [61] [A segment anchoring-based balancing algorithm for agricultural multi-robot task allocation with energy constraints](https://arxiv.org/abs/2511.17076)
*Peng Chen,Jing Liang,Kang-Jia Qiao,Hui Song,Tian-lei Ma,Kun-Jie Yu,Cai-Tong Yue,Ponnuthurai Nagaratnam Suganthan,Witold Pedryc*

Main category: cs.MA

TL;DR: 本文针对多机器人任务分配中的能量约束问题，提出了新颖的基于分段锚定的平衡算法，有效优化了抢修调度，实验证明其优于当前主流方法。


<details>
  <summary>Details</summary>
Motivation: 在智能农业等劳动密集型产业中，多机器人系统因效率和成本问题受到重视。规划多机器人的高效采摘调度存在挑战，尤其是同时解决多目标(工期和运输成本)、载荷限制和有限电池容量等复杂因素。传统优化方法难以应对因能量约束导致的动态充电及负载重置引发的调度混乱。

Method: 设计了分段锚定机制，包括顺序锚定和平衡机制，通过将充电决策作为锚点重构路径；并结合比例分割的再平衡机制，对最终解的工期进行细粒度调节，提升整体调度效果。

Result: 提出了基于分段锚定的平衡算法(SABA)，通过充电决策作为“锚点”系统性重构受干扰的路径，结合比例分割再平衡机制，实现高精度的工期平衡优化。实验证明SABA在真实案例和基准测试中，较6种先进算法在收敛性和解多样性上均优越。

Conclusion: 本文提出的SABA算法成功解决了多机器人系统中因能量限制导致的调度复杂性问题，显著提升了调度效果和算法性能，具有重要理论价值和应用前景。

Abstract: Multi-robot systems have emerged as a key technology for addressing the efficiency and cost challenges in labor-intensive industries. In the representative scenario of smart farming, planning efficient harvesting schedules for a fleet of electric robots presents a highly challenging frontier problem. The complexity arises not only from the need to find Pareto-optimal solutions for the conflicting objectives of makespan and transportation cost, but also from the necessity to simultaneously manage payload constraints and finite battery capacity. When robot loads are dynamically updated during planned multi-trip operations, a mandatory recharge triggered by energy constraints introduces an unscheduled load reset. This interaction creates a complex cascading effect that disrupts the entire schedule and renders traditional optimization methods ineffective. To address this challenge, this paper proposes the segment anchoring-based balancing algorithm (SABA). The core of SABA lies in the organic combination of two synergistic mechanisms: the sequential anchoring and balancing mechanism, which leverages charging decisions as `anchors' to systematically reconstruct disrupted routes, while the proportional splitting-based rebalancing mechanism is responsible for the fine-grained balancing and tuning of the final solutions' makespans. Extensive comparative experiments, conducted on a real-world case study and a suite of benchmark instances, demonstrate that SABA comprehensively outperforms 6 state-of-the-art algorithms in terms of both solution convergence and diversity. This research provides a novel theoretical perspective and an effective solution for the multi-robot task allocation problem under energy constraints.

</details>
