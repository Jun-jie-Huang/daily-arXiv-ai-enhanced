<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 44]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.SE](#cs.SE) [Total: 9]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling](https://arxiv.org/abs/2510.26912)
*Hyunji Lee,Wenhao Yu,Hongming Zhang,Kaixin Ma,Jiyeon Kim,Dong Yu,Minjoon Seo*

Main category: cs.CL

TL;DR: 本文分析了状态空间模型（SSM）与注意力机制结合的混合模型的结构设计，并提出了一种数据驱动的方法以提升模型的记忆能力和整体表现。


<details>
  <summary>Details</summary>
Motivation: 当前混合模型虽然表现优异，但其架构设计细节及其对性能的影响尚未被充分理解。

Method: 本文从记忆利用和性能角度出发，比较了SSM与注意力层的顺序和并行集成方式，发现顺序集成更适合短上下文，并行集成对长上下文更有效。同时提出通过不断在包含同义句的数据集上训练的方法，加强模型的召回能力。

Result: 结果显示并行混合结构在长上下文表现更好，顺序混合结构表现更优短内容，同时数据增强方法显著提升了召回性能，优于仅靠结构修改的方案。

Conclusion: 本文深化了对混合SSM-注意力模型的理解，并为针对不同用例设计高效架构提供了实用指导。

Abstract: Hybrid models that combine state space models (SSMs) with attention
mechanisms have shown strong performance by leveraging the efficiency of SSMs
and the high recall ability of attention. However, the architectural design
choices behind these hybrid models remain insufficiently understood. In this
work, we analyze hybrid architectures through the lens of memory utilization
and overall performance, and propose a complementary method to further enhance
their effectiveness. We first examine the distinction between sequential and
parallel integration of SSM and attention layers. Our analysis reveals several
interesting findings, including that sequential hybrids perform better on
shorter contexts, whereas parallel hybrids are more effective for longer
contexts. We also introduce a data-centric approach of continually training on
datasets augmented with paraphrases, which further enhances recall while
preserving other capabilities. It generalizes well across different base models
and outperforms architectural modifications aimed at enhancing recall. Our
findings provide a deeper understanding of hybrid SSM-attention models and
offer practical guidance for designing architectures tailored to various use
cases. Our findings provide a deeper understanding of hybrid SSM-attention
models and offer practical guidance for designing architectures tailored to
various use cases.

</details>


### [2] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra,Arthur Lorenzi,Laís Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Olívia Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 本文提出了一种利用语义框架在医疗电子记录的开放文本中识别需报告事件的方法，应用于识别基于性别的暴力事件的漏报问题。


<details>
  <summary>Details</summary>
Motivation: 基于性别的暴力事件在医疗记录中存在漏报，影响公共卫生监控的准确性。

Method: 定义八个细粒度的语义模式，在包含2100万句巴西葡萄牙语的电子医疗记录文本中搜索，并由语言学专家手工评估模式的准确率。

Result: 该方法精准率达到0.726，有效识别了暴力报告，验证了方法的鲁棒性。

Conclusion: 方法设计透明、高效、低碳且语言无关，易于推广到其他卫生监测场景，促进NLP在公共卫生系统中的伦理与可解释应用。

Abstract: We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [3] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu*

Main category: cs.CL

TL;DR: 该论文介绍了MEDIQA-OE 2025竞赛，这是首个从医患对话中提取医疗指令的挑战，旨在降低临床文档负担，改善患者护理。


<details>
  <summary>Details</summary>
Motivation: 目前临床文档广泛使用自动语音识别和摘要技术，但将对话转换为电子健康记录中的可操作医嘱尚未被充分研究。解决这一问题可显著减轻医生的文档工作量并提升患者护理质量。

Method: 通过举办MEDIQA-OE 2025共享任务，吸引了六个团队参与，采用多种方法和大语言模型（包括封闭和开放权重模型）来从医患对话中提取医嘱。

Result: 介绍了任务设置、数据集、最终排行榜及参赛团队的解决方案，展示了不同方法的表现和效果。

Conclusion: MEDIQA-OE竞赛开创了从对话中提取医嘱的研究领域，为将自动语音识别成果转化为电子健康记录中的可操作信息提供了有力支持，推动了临床自动化文档技术的发展。

Abstract: Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [4] [Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services](https://arxiv.org/abs/2510.27016)
*Jayden Serenari,Stephen Lee*

Main category: cs.CL

TL;DR: 提出了LOPSIDED框架，通过语义一致的假名替换敏感个人信息，保护用户隐私，同时保持对话上下文完整性。


<details>
  <summary>Details</summary>
Motivation: 随着对话式AI普及，用户在与大语言模型交互时泄露敏感个人信息的风险增加，亟需隐私保护方案。

Method: 设计LOPSIDED框架，在用户提示中动态替换敏感实体为语义一致的假名，生成后自动恢复，保证隐私同时保持响应质量。

Result: 在ShareGPT真实对话数据集上实验，LOPSIDED在减少语义使用错误方面较基线提升5倍，同时增强了隐私保护。

Conclusion: LOPSIDED成功实现了在保护隐私的同时维护对话的语义完整性，优于传统技术。

Abstract: With the increasing use of conversational AI systems, there is growing
concern over privacy leaks, especially when users share sensitive personal data
in interactions with Large Language Models (LLMs). Conversations shared with
these models may contain Personally Identifiable Information (PII), which, if
exposed, could lead to security breaches or identity theft. To address this
challenge, we present the Local Optimizations for Pseudonymization with
Semantic Integrity Directed Entity Detection (LOPSIDED) framework, a
semantically-aware privacy agent designed to safeguard sensitive PII data when
using remote LLMs. Unlike prior work that often degrade response quality, our
approach dynamically replaces sensitive PII entities in user prompts with
semantically consistent pseudonyms, preserving the contextual integrity of
conversations. Once the model generates its response, the pseudonyms are
automatically depseudonymized, ensuring the user receives an accurate,
privacy-preserving output. We evaluate our approach using real-world
conversations sourced from ShareGPT, which we further augment and annotate to
assess whether named entities are contextually relevant to the model's
response. Our results show that LOPSIDED reduces semantic utility errors by a
factor of 5 compared to baseline techniques, all while enhancing privacy.

</details>


### [5] [Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral](https://arxiv.org/abs/2510.27017)
*Ayoub Hammal,Pierre Zweigenbaum,Caio Corro*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的测试时代理调整方法，通过使用一个小型已对齐模型作为代理，提升大型语言模型的对齐效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在预训练阶段学到了大部分生成能力，但依然需要进一步对齐以满足下游任务和风格偏好。随着模型规模增大，传统对齐方法的计算成本变得不可承受。

Method: 采用基于代理的测试时代理调整方法，具体为token特定的级联策略，将延迟决策转化为0-1背包问题，并给出了原始与对偶近似解。

Result: 实验结果表明该方法在任务性能和推测解码速度上均有提升。

Conclusion: 代理驱动的测试时代理调整是一种有效且高效的对齐方法，有助于缓解大规模模型对齐的计算瓶颈。

Abstract: Several previous works concluded that the largest part of generation
capabilities of large language models (LLM) are learned (early) during
pre-training. However, LLMs still require further alignment to adhere to
downstream task requirements and stylistic preferences, among other desired
properties. As LLMs continue to scale in terms of size, the computational cost
of alignment procedures increase prohibitively. In this work, we propose a
novel approach to circumvent these costs via proxy-based test-time alignment,
i.e. using guidance from a small aligned model. Our approach can be described
as token-specific cascading method, where the token-specific deferral rule is
reduced to 0-1 knapsack problem. In this setting, we derive primal and dual
approximations of the optimal deferral decision. We experimentally show the
benefits of our method both in task performance and speculative decoding speed.

</details>


### [6] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的神经架构搜索方法ELM，以优化紧凑的预训练语言模型，在保持性能的同时提升效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型虽然性能强大，但其巨大的计算和存储需求带来了经济和环境上的挑战。

Method: ELM通过扩展搜索空间，引入高效的Transformer块和动态调整维度与头数的模块，结合新颖的知识蒸馏损失来提高建筑选择的辨别能力。

Result: ELM在掩码语言建模和因果语言建模任务上发现的模型显著优于现有方法。

Conclusion: ELM方法有效提升了紧凑语言模型的搜索效率和性能，解决了大型语言模型资源消耗过大的问题。

Abstract: As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [7] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad,Shamsuddeen Muhammad Hassan,Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 本论文介绍了首个豪萨语性别歧视检测数据集，结合社区参与和语言学研究，评估了多种机器学习模型的检测效果。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的性别歧视通过刻板印象和偏见加剧性别不平等，尤其低资源语言中由于资源和文化差异，性别歧视检测面临挑战。

Method: 通过社区参与和问卷调查了解豪萨语中性别歧视的定义和表达，构建数据集，并测试传统机器学习及多语言预训练模型的几-shot学习能力。

Result: 发现模型在捕捉文化细节（如疑问式和习语表达）时存在困难，且在这些情况下出现较多误判。

Conclusion: 豪萨语性别歧视检测面临语言及文化双重挑战，需要更为细致的方法提升检测准确性。

Abstract: Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [8] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

Main category: cs.CL

TL;DR: 本文综述了计量化跨文本性研究的现状，涵盖数据、方法及应用，强调了自然语言处理技术的推动作用。


<details>
  <summary>Details</summary>
Motivation: 传统文学理论中的跨文本性研究受限于定性分析，随着自然语言处理的发展，需要将其引入量化研究，实现规模化和多语言的研究。

Method: 本文总结了从统计方法到深度学习的多种技术手段，利用多语言多主题数据，分析跨文本性的定量研究方法。

Result: 评述了跨文本性研究在数字人文和社会科学中的应用及相关平台工具的进展，展示了该领域的技术演进和研究成果。

Conclusion: 随着计算技术发展，跨文本性研究将更加精准、多样且大规模，未来有望促进人工智能与人文学科的跨领域融合。

Abstract: The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [9] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom,Andrea Silvi,Jennifer Culbertson,Moa Johansson,Devdatt Dubhashi,Kenny Smith*

Main category: cs.CL

TL;DR: 本文提出基于最小描述长度（MDL）的方法，通过考虑规则性，改进了对递归数词系统复杂性与词汇规模权衡的分析，更好区分自然语言系统与可能但非自然的系统。


<details>
  <summary>Details</summary>
Motivation: 之前研究难以证明只有自然语言式的递归数词系统能优化复杂性与词汇规模的权衡，且依赖人为限制排除不自然系统。本文认为这是由于忽视了规则性这一语言复杂性的关键方面。

Method: 采用最小描述长度（MDL）方法，引入对规则性和处理复杂性的度量，替代之前的简单权衡指标，重新评估递归数词系统的优化效果。

Result: 基于MDL的度量更准确地反映了自然语言系统与非自然系统的差异，包括之前被认为“最优”的递归数词系统。同时，以前的经验限制可自然从规则性中推导出。

Conclusion: 研究强调在语言最优性分析中必须考虑形式集合的规则性，推动对语言结构优化解释的更准确理解。

Abstract: Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [10] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White*

Main category: cs.CL

TL;DR: VISTA是一种新的对话系统事实性评价框架，通过逐条验证对话中的陈述，显著提升了多轮对话中的幻觉检测效果。


<details>
  <summary>Details</summary>
Motivation: 当前对话系统存在生成无依据或与上下文矛盾陈述的现象（幻觉），且现有评价指标无法有效处理多轮对话中的事实性评估。

Method: VISTA将每个助手回复分解为原子事实陈述，分别验证其真实性，并跟踪多轮对话中的一致性，分类不可验证的陈述类型。

Result: 在八个大型语言模型和四个对话事实性评测基准上，VISTA显著优于现有的FACTSCORE和LLM-as-Judge方法，且人类评价显示其分解方法可以提高标注者一致性。

Conclusion: 通过将事实性视为对话的动态特性，VISTA提供了一种更加透明且符合人类认知的对话系统真实性测评方法。

Abstract: Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [11] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo,Yaxuan Luan,Yue Kang,Xiangchen Song,Jinxu Guo*

Main category: cs.CL

TL;DR: 本论文提出了一种结合多粒度记忆索引与不确定性估计的置信度控制方法，以改善复杂知识环境中检索增强生成的覆盖不足、结果不稳定和可靠性有限的问题。


<details>
  <summary>Details</summary>
Motivation: 针对检索增强生成在复杂知识环境下存在的覆盖不足、结果不稳定和可靠性有限的问题，提升生成质量和模型可靠性。

Method: 构建层次化记忆结构，实现多粒度知识表示的动态索引与检索；结合不确定性估计机制，约束并过滤低置信路径，形成包含生成损失、熵约束和方差正则化的统一置信度控制框架。

Result: 实验通过多种敏感性测试和对比分析验证了方法在不同场景下的稳定性和鲁棒性，表现出在问答准确率、检索召回率、排序质量和事实一致性上的显著优越性。

Conclusion: 结合多粒度索引与置信度控制的方法有效提升了复杂环境下检索增强生成的性能，为大模型的可靠性和可控性提供了技术新路径和实践依据。

Abstract: This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [12] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski,Meriem Boubdir,Klaudia Bałazy,Besmira Nushi,Pablo Ribalta*

Main category: cs.CL

TL;DR: 本文提出了一种名为CoDeC的方法，用于检测大型语言模型训练数据中的污染，区分训练时记忆的数据和未见数据。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型训练数据可能被污染，影响模型评估的准确性，因此需要一种方法准确检测训练数据中的污染。

Method: 通过测量上下文学习对模型性能的影响，利用上下文示例提升置信度的差异来识别数据是否来自训练分布，自动产生直观的污染评分。

Result: CoDeC能够清晰区分训练数据和未见数据，揭示开放权重模型中潜在的记忆现象，评估结果直观可解释。

Conclusion: CoDeC方法简单、自动化且与模型和数据无关，可轻松集成于基准测试中，提升训练数据污染检测的准确性和实用性。

Abstract: We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [13] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng,Huajun Zhang,Xu Yan,Ran Hao,Chong Peng*

Main category: cs.CL

TL;DR: 本文提出了一种结合对比蒸馏与噪声鲁棒训练的微调方法，解决大规模语言模型在安全对齐和鲁棒性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大规模语言模型在安全对齐和鲁棒性方面存在局限，亟需有效的方法提升模型的语义一致性和对噪声输入的稳定性。

Method: 冻结骨干模型，通过对比蒸馏将教师模型的知识边界传递给学生模型，同时引入噪声扰动和鲁棒优化约束，构建包括蒸馏损失、鲁棒性损失及正则项的统一优化目标。

Result: 该方法在知识传递、鲁棒性及整体安全性方面显著优于现有基线，在多个关键指标上达到最佳性能。

Conclusion: 本文工作丰富了参数高效微调的理论体系，为构建更安全、更可信的对齐机制提供了新方案。

Abstract: This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [14] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz,Sharon Levy*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型安全护栏中的选择性拒绝偏差，发现其在性别、性取向、国籍和宗教等群体上存在不平等的拒绝率，并探讨了其安全隐患。


<details>
  <summary>Details</summary>
Motivation: 为防止大型语言模型生成有害内容而设计的安全护栏可能引入新的偏见，导致对某些群体的不公平拒绝，这一问题需深入研究。

Method: 通过分析不同个体及交叉人口统计群体的拒绝率、拒绝响应类型及其生成长度，评估大型语言模型安全护栏中的选择性拒绝偏差。

Result: 发现安全护栏存在跨性别、性取向、国籍和宗教属性的选择性拒绝偏差，同时通过间接攻击方式验证了由此带来的安全隐患。

Conclusion: 大型语言模型的安全护栏需提升其公平性和鲁棒性，确保对不同人口统计群体的安全防护均衡且有效。

Abstract: Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [15] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar,Julia Hockenmaier*

Main category: cs.CL

TL;DR: Large language models (LLMs) are being used to evaluate natural language generation (NLG), but their scoring is inconsistent across different runs, making evaluation unreliable.


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成技术广泛应用，传统评估方法难以满足需求，LLM评估因更符合人类偏好而受关注，但其评分不稳定问题亟待解决。

Method: 通过实验证明LLM评审在多次评分中的内部一致性低，评估其在不同NLG任务和基准上的评分差异，并探讨合理利用LLM评审的指导原则。

Result: LLM评审的评分存在较大波动，导致结果几乎随意，体现出低一致性和可靠性，但合理规范使用可能仍具参考价值。

Conclusion: 尽管LLM在NLG评估中显示出不稳定性，通过制定适当的指导方针，LLM评审仍可作为辅助评价工具使用。

Abstract: As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [16] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang,Anej Svete,Jiaoda Li,Anthony Widjaja Lin,Jonathan Rawski,Ryan Cotterell,David Chiang*

Main category: cs.CL

TL;DR: 本文分析了变换器语言模型在生成字符串时能够表达的概率分布，探讨了自回归和概率表示对变换器表达能力的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注变换器作为语言识别器的表达能力，但实际应用中变换器多作为概率性自回归语言模型使用，表达能力的理解存在不足。

Method: 通过理论分析变换器语言识别器转变为自回归和概率模型后表达能力的变化，揭示其表达的函数类别。

Result: 发现自回归机制有时可增强表达能力，且概率化表示会打破非概率情况下的函数等价性。

Conclusion: 本文明确了变换器作为语言模型时，特别是自回归概率模型状态下的表达能力，为理解其实际应用中的性能提供理论依据。

Abstract: Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [17] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton,York Hay Ng,Aditya Khan,Phuong Hanh Hoang,Xiang Lu,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文扩展了多语言知识库URIEL+，通过引入书写系统向量、整合Glottolog数据以及扩展家系推断，显著减少了数据稀疏性并提升了低资源语言支持能力。


<details>
  <summary>Details</summary>
Motivation: URIEL+现有数据稀疏，如缺失特征类型、不完整语言条目和有限的分类覆盖，限制了其在跨语言迁移，尤其是低资源语言支持上的效用。

Method: 引入书写系统向量表示7,488种语言的书写属性，整合Glottolog新增18,710种语言，及通过家族传播扩展特征推断至26,449种语言。

Result: 书写系统特征稀疏性减少14%，语言覆盖提升至19,015种（增长1,007%），推断质量提升33%，跨语言迁移任务中部分场景性能提升达6%。

Conclusion: 改进后的URIEL+更全面、包容，有助于多语言研究，特别提升了低资源语言的支持能力。

Abstract: The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [18] [MemeArena: Automating Context-Aware Unbiased Evaluation of Harmfulness Understanding for Multimodal Large Language Models](https://arxiv.org/abs/2510.27196)
*Zixin Chen,Hongzhan Lin,Kaixin Li,Ziyang Luo,Yayue Deng,Jing Ma*

Main category: cs.CL

TL;DR: 提出了一个名为MemeArena的多模态大型语言模型评估框架，针对多模态有害内容的理解实现上下文感知和无偏评估。


<details>
  <summary>Details</summary>
Motivation: 现有的评估主要关注模型的二分类检测精度，缺乏对多模态有害性的深入解读和上下文理解能力的考察。

Method: 设计了一个基于代理的竞技场式评估框架，通过模拟多样的解释上下文，促使模型进行视角特定的分析，并通过不同评估者的共识减少偏见，实现公平评估。

Result: 大量实验证明该框架有效减少了评估者的偏见，判决结果与人类偏好高度一致。

Conclusion: MemeArena框架为多模态大型语言模型的有害内容理解提供了可靠全面的评估工具，提升了评估的公平性和准确性。

Abstract: The proliferation of memes on social media necessitates the capabilities of
multimodal Large Language Models (mLLMs) to effectively understand multimodal
harmfulness. Existing evaluation approaches predominantly focus on mLLMs'
detection accuracy for binary classification tasks, which often fail to reflect
the in-depth interpretive nuance of harmfulness across diverse contexts. In
this paper, we propose MemeArena, an agent-based arena-style evaluation
framework that provides a context-aware and unbiased assessment for mLLMs'
understanding of multimodal harmfulness. Specifically, MemeArena simulates
diverse interpretive contexts to formulate evaluation tasks that elicit
perspective-specific analyses from mLLMs. By integrating varied viewpoints and
reaching consensus among evaluators, it enables fair and unbiased comparisons
of mLLMs' abilities to interpret multimodal harmfulness. Extensive experiments
demonstrate that our framework effectively reduces the evaluation biases of
judge agents, with judgment results closely aligning with human preferences,
offering valuable insights into reliable and comprehensive mLLM evaluations in
multimodal harmfulness understanding. Our code and data are publicly available
at https://github.com/Lbotirx/MemeArena.

</details>


### [19] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou,Yu Wang,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 研究语言信息密度中的周期性，提出AutoPeriod of Surprisal (APS)方法检测单篇文档的惊讶度序列周期性。


<details>
  <summary>Details</summary>
Motivation: 探讨自然语言编码信息中存在的周期性模式及其程度。

Method: 引入APS方法，利用经典周期检测算法识别文本惊讶度序列中的显著周期，并用谐波回归验证新发现的周期。

Result: 发现大量人类语言信息表现出强周期性，不仅包括常见结构单元周期，还存在超出这些单位的新周期。

Conclusion: 语言信息的周期性来源于结构因素和远距离的其他驱动因素，同时APS方法在大语言模型生成文本检测上具有潜力。

Abstract: Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [20] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli,Alireza Salemi,Carrie Ye,Mohamed Abdalla,Hamed Zamani,J Ross Mitchell*

Main category: cs.CL

TL;DR: 本文提出了一个新的基准BEAM，用于评估大语言模型在长时间记忆和长上下文推理方面的能力，同时设计了基于三种记忆系统的LIGHT框架以提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在评估大语言模型的长时间记忆能力时存在局限，缺乏叙事连贯性、覆盖范围狭窄且任务简单，难以全面考察模型的长上下文推理能力。

Method: 本文自动生成长度可达1000万标记的多样化连贯对话，配套设计探测多种记忆能力的问题，构建BEAM数据集；同时设计受人类认知启发的LIGHT框架，包含长时记忆、短时工作记忆和积累显著事实的草稿板三部分，以增强模型性能。

Result: 实验表明，尽管部分模型支持百万标记长上下文，仍无法有效处理超长对话，但引入LIGHT框架后，不同模型性能平均提升3.5%-12.69%，消融实验进一步验证了各记忆组件的贡献。

Conclusion: 结合多种记忆系统的LIGHT框架显著提升了大语言模型在长上下文对话记忆和推理任务中的表现，BEAM基准为相关研究提供了重要测试平台。

Abstract: Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [21] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal,Aarush Gupta*

Main category: cs.CL

TL;DR: 提出了一种名为LLINK的新方法，通过语言作为模态实现低资源非拉丁文字的跨语言知识注入，提升指令调优大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优的大型语言模型在处理低资源、非拉丁文字语言时表现较差，原因包括分词器碎片化严重和跨语言耦合弱。

Method: LLINK方法利用冻结的多语言编码器将句子嵌入对齐到解码器的潜在嵌入空间，采用轻量的对比投影器和少量适配器，通过向解码器注入扩展的软槽向量实现语言模态条件。

Result: LLINK显著提升了双语检索性能，在LLM评判的问答测试中较基线模型分别提升了81.3%和63.6%。其改进主要来源于减少的分词通胀和更强的跨语言对齐。

Conclusion: 将低资源语言作为一种模态处理，为轻量级大型语言模型提供了一条有效提升跨语言对齐能力的可行路径。

Abstract: Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [22] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu*

Main category: cs.CL

TL;DR: 该论文提出了MedCalc-Eval，一个涵盖700多个任务的医学计算能力评测基准，包含方程计算和规则评分系统两类任务，覆盖多个医学专业领域。此外，作者开发了基于强化学习的MedCalc-Env环境，优化大模型的医学计算推理能力，显著提升了性能水平。


<details>
  <summary>Details</summary>
Motivation: 现有医学大模型评测主要关注问答和描述推理，忽视了临床决策中关键的定量计算能力，且现有数据集任务有限，不足以反映真实复杂计算场景。

Method: 构建了覆盖多专业、多任务类型的大规模医学计算基准MedCalc-Eval；开发强化学习环境MedCalc-Env，通过多步临床推理训练Qwen2.5-32B模型，提升其计算能力和推理鲁棒性。

Result: 在MedCalc-Eval上微调的Qwen2.5-32B模型表现出色，数值敏感度、公式选择和推理稳健性显著提高。仍存在单位转换、多条件逻辑及语境理解方面挑战。

Conclusion: MedCalc-Eval填补了医学大模型定量计算能力评测的空白，结合强化学习的方法有效提升模型性能，为临床决策中的复杂计算推理提供了有力支持。代码和数据集公开促进后续研究。

Abstract: As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [23] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang,Seonjeong Hwang,Daehui Kim,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 本文研究了推理语言模型在多语言推理任务中存在的性能差距，发现这一差距主要源于模型在理解不同语言输入时的失败。提出了一种选择性翻译策略，只在检测到理解失败时将输入翻译成英语，从而有效缩小了该差距。


<details>
  <summary>Details</summary>
Motivation: 多语言推理模型在高资源语言和低资源语言之间存在性能差距，且其根本原因尚未明确，理解该差距对于提升低资源语言的推理性能具有重要意义。

Method: 文章检测了理解失败的可能性，评估多种检测方法，发现监督方法效果最优；基于此，提出“选择性翻译”策略，即仅在识别出理解失败时才对输入进行翻译。

Result: 实验结果表明，选择性翻译策略能将在多语言推理中的性能差距大幅缩小，性能接近全量翻译，但翻译比例仅约20%，显著提升了效率。

Conclusion: 理解失败是造成多语言推理性能差距的主要原因，且能够被检测和有针对性地缓解；该研究为实现更公平的多语言推理提供了理论基础和实用方法。

Abstract: Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [24] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu,Jiajun Song,Wei Wang*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）中的判断机制，发现多样评价判断沿着一个统一维度——价值认同轴（VAA）进行编码，该轴兼顾主观价值和事实认可，控制生成推理过程，导致合理性优先于事实准确性。


<details>
  <summary>Details</summary>
Motivation: 研究生物和人工智能中判断是否依赖专门模块或统一资源，解决LLMs中神经表征模块化的真实性和独立性问题。

Method: 分析多种LLMs中的评估判断，通过直接干预展示统一表示控制生成过程，提出推理的服从机制。

Result: 发现评估判断沿价值认同轴统一编码，该轴作为控制信号引导生成推理，使推理偏向目标驱动的合理化而非无偏见推断。

Conclusion: 提出了推理服从机制的架构解释，揭示该机制促进判断连贯性但可能导致系统性偏见和幻觉，影响模型的事实忠实性。

Abstract: A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [25] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing,Christian Goldschmied,Goran Glavaš*

Main category: cs.CL

TL;DR: 提出了一种基于多语言机器翻译模型编码器的新型词对齐器TransAlign，在跨语言传递的标签投影任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的基于多语言词对齐器的标签投影在跨语言令牌分类任务中表现有限，且现有利用机器翻译模型进行对齐的方法效果较差。

Method: 设计TransAlign，利用大规模多语言机器翻译模型的编码器进行词对齐，并应用于基于机器翻译的跨语言传递任务中。

Result: TransAlign在词对齐性能上表现强劲，且在基于机器翻译的跨语言令牌分类任务中显著优于当前流行的词对齐器和非词对齐的标签投影方法。

Conclusion: 利用多语言机器翻译模型编码器进行词对齐是提升跨语言传递中标签投影准确性的有效策略，TransAlign为该领域提供了新的有竞争力的工具。

Abstract: In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [26] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang,Chang Xu*

Main category: cs.CL

TL;DR: 本文提出了ThoughtProbe，一种在推理时利用大语言模型隐藏推理特征的新框架，通过树状响应空间搜索提升推理表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过操纵隐藏表达调控生成，而本文希望直接利用隐藏特征作为判别信号，引导推理过程，提高效率和准确性。

Method: 设计了分类器在树结构节点扩展中评分排序优先计算高分分支，完成树扩展后通过CoT分数聚合所有分支答案以确定最优解。

Result: 在多个算术推理基准测试中，ThoughtProbe框架实现了推理链的全面覆盖和准确识别，显著提升了推理性能。

Conclusion: 利用LLM隐藏推理特征进行分支评分及答案聚合，有效提升了算术类推理任务的表现，展示了探索推理空间的新思路。

Abstract: This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [27] [From the Rock Floor to the Cloud: A Systematic Survey of State-of-the-Art NLP in Battery Life Cycle](https://arxiv.org/abs/2510.27369)
*Tosin Adewumi,Martin Karlsson,Marcus Liwicki,Mikael Sjödahl,Lama Alkhaled,Rihab Gargouri,Nudrat Habib,Franz Hennie*

Main category: cs.CL

TL;DR: 本文系统综述了自然语言处理（NLP）在电池全生命周期中的应用，提出了面向欧盟数字电池护照的技术语言处理（TLP）框架。


<details>
  <summary>Details</summary>
Motivation: 目前研究多聚焦于电池生命周期的某一阶段或方法，缺乏全周期的综合应用综述，同时数字电池护照的实现需要新的技术框架支持。

Method: 采用PRISMA方法，从Google Scholar、IEEE Xplore和Scopus数据库检索相关文献，筛选出66篇相关文章进行综合评估和关键性审查，并公开了审查工件以保证验证和可重复性。

Result: 发现新能源领域出现了新的NLP任务，有助于材料发现及电池生命周期各阶段的优化，但仍存在缺乏标准基准等挑战。

Conclusion: 提出的融合智能代理和优化提示的TLP框架，适用于解决现有挑战，推动数字电池护照和电池技术的发展。

Abstract: We present a comprehensive systematic survey of the application of natural
language processing (NLP) along the entire battery life cycle, instead of one
stage or method, and introduce a novel technical language processing (TLP)
framework for the EU's proposed digital battery passport (DBP) and other
general battery predictions. We follow the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) method and employ three reputable
databases or search engines, including Google Scholar, Institute of Electrical
and Electronics Engineers Xplore (IEEE Xplore), and Scopus. Consequently, we
assessed 274 scientific papers before the critical review of the final 66
relevant papers. We publicly provide artifacts of the review for validation and
reproducibility. The findings show that new NLP tasks are emerging in the
battery domain, which facilitate materials discovery and other stages of the
life cycle. Notwithstanding, challenges remain, such as the lack of standard
benchmarks. Our proposed TLP framework, which incorporates agentic AI and
optimized prompts, will be apt for tackling some of the challenges.

</details>


### [28] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu,Zijian Wang,Kuo Zhao,Dong Hu*

Main category: cs.CL

TL;DR: 本文提出了一种同时编辑大型语言模型中多层感知机（MLP）和注意力（Attn）模块的知识编辑方法IntAttn-Edit，提升了编辑的成功率和知识保留效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注MLP模块，忽视了注意力模块，导致知识编辑效果有限，保留旧知识残留问题。

Method: 通过全面的知识定位实验发现Attn模块在知识存储中作用显著，基于此提出IntAttn-Edit方法，采用知识平衡策略，按模块贡献比例调整更新幅度，联合更新MLP和Attn模块。

Result: 在标准基准测试中，IntAttn-Edit在编辑成功率、泛化能力和知识保留方面均优于现有方法。

Conclusion: 通过平衡更新MLP和Attn模块，IntAttn-Edit有效提升了知识编辑的全面性和性能，在不同设置中保持了最佳编辑效果。

Abstract: Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [29] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem,Farida Boudichat*

Main category: cs.CL

TL;DR: 本文介绍了Awal项目，这是一个由社区驱动的Tamazight语言技术资源开发计划，通过协作平台收集翻译和语音数据，旨在解决Tamazight语言数据匮乏问题。


<details>
  <summary>Details</summary>
Motivation: Tamazight语言在数字空间中严重缺乏资源，且因社会语言复杂性导致数据采集困难，需求建立社区主导的资源开发机制。

Method: 通过awaldigital.org平台，鼓励Tamazight使用者贡献翻译对与语音数据，结合社区参与分析并进行资源积累，同时开发开源机器翻译模型。

Result: 经过18个月社区参与，收集到6,421对翻译对和3小时语音数据，发现参与者主要为语言学家和活跃分子，普遍面临书写信心不足和标准化问题。

Conclusion: 尽管社区反响积极，标准众包方法在复杂社会语言环境中效果有限，未来需改进模型并增强社区参与以推动Tamazight语言技术发展。

Abstract: This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [30] [Dynamic Affective Memory Management for Personalized LLM Agents](https://arxiv.org/abs/2510.27418)
*Junfeng Lu,Yueyan Li*

Main category: cs.CL

TL;DR: 本文提出了一种基于贝叶斯启发的记忆更新算法，提高个性化AI代理的记忆管理效果。


<details>
  <summary>Details</summary>
Motivation: 现有个性化AI代理系统存在记忆冗余、陈旧和记忆与上下文整合差等问题，主要由于交互过程中缺乏有效的记忆更新机制。

Method: 设计一种基于贝叶斯启发的记忆更新算法，引入记忆熵概念，通过最小化全局熵自主管理动态更新的记忆向量数据库。

Result: 提出的系统在个性化、逻辑连贯性和准确性方面表现优异，消融实验验证了该算法在缓解记忆膨胀方面的有效性。

Conclusion: 该工作为设计长期记忆系统提供了新的思路，特别是在情感场景下实现更为精准的个性化服务。

Abstract: Advances in large language models are making personalized AI agents a new
research focus. While current agent systems primarily rely on personalized
external memory databases to deliver customized experiences, they face
challenges such as memory redundancy, memory staleness, and poor memory-context
integration, largely due to the lack of effective memory updates during
interaction. To tackle these issues, we propose a new memory management system
designed for affective scenarios. Our approach employs a Bayesian-inspired
memory update algorithm with the concept of memory entropy, enabling the agent
to autonomously maintain a dynamically updated memory vector database by
minimizing global entropy to provide more personalized services. To better
evaluate the system's effectiveness in this context, we propose DABench, a
benchmark focusing on emotional expression and emotional change toward objects.
Experimental results demonstrate that, our system achieves superior performance
in personalization, logical coherence, and accuracy. Ablation studies further
validate the effectiveness of the Bayesian-inspired update mechanism in
alleviating memory bloat. Our work offers new insights into the design of
long-term memory systems.

</details>


### [31] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong,Senmiao Wang,Hanbo Huang,Ruoyu Sun,Shiyu Liang*

Main category: cs.CL

TL;DR: 提出VCORE框架，通过方差控制的优化重加权方法，提升长链思维轨迹中大语言模型的推理能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的交叉熵损失均等对待所有token，忽略了它们在推理轨迹中的不同贡献，导致监督分配不合理，泛化能力不足。

Method: VCORE将链式思维监督问题重新表述为约束优化问题，通过优化理论视角自适应分配token的监督权重，实现更合理的训练目标。

Result: 在数学和编程基准测试中，使用Qwen3系列和LLaMA模型，VCORE在域内和域外均取得显著性能提升，优于现有token重加权方法。

Conclusion: VCORE不仅提升了长链推理的效果，还能为后续的强化学习提供更好的初始化基础，推动大语言模型推理能力的发展。

Abstract: Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [32] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao,Sijian Ren,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 本文提出了一种结合扩散语言模型(DLM)和大型语言模型(LLM)的高效协同推理框架，通过DLM并行生成多样化的中间推理步骤，并由LLM评估其质量，从而在保持推理能力的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: LLM虽然推理能力强，但其自回归生成导致计算效率低，增益有限。DLM能并行生成样本，启发作者利用DLM生成中间思考步骤，缓解计算负担。

Method: 提出一个协同推理框架，使用DLM生成多样的候选推理步骤，随后由LLM对这些步骤进行质量评估和筛选，结合两者优势以提高推理效率和效果。

Result: 在多个复杂推理任务的基准测试中，该框架表现出强劲的性能，显著高效且准确。

Conclusion: 结合DLM与LLM的协同推理框架为未来提升复杂推理效率和质量提供了有前景的方向。代码已开源。

Abstract: In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [33] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

Main category: cs.CL

TL;DR: 本研究比较了静态词向量和上下文嵌入在英语复合词语义处理上的表现，发现BERT表现优于GloVe，且预测性对语义透明度有显著影响。


<details>
  <summary>Details</summary>
Motivation: 探究计算嵌入模型与人类语义判断在英语复合词处理中的一致性，理解复合词语义加工的关键驱动因素。

Method: 通过比较GloVe和BERT生成的词向量，结合Edinburgh关联词典、BNC语料库频率和LaDEC预测性数据，计算词汇意义主导性和语义透明度指标，并采用斯皮尔曼相关和回归分析进行评估。

Result: BERT嵌入更好地捕捉了复合词的组合语义，预测性评分在模型和人类数据中均为语义透明度的强预测指标。

Conclusion: 本研究提升了计算心理语言学对复合词语义加工机制的理解，证明上下文嵌入在语义建模中的优越性并强调了预测性的关键作用。

Abstract: This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [34] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu,Chisom Chibuike,Fatimo Adebanjo,Omokolade Awosanya,Samuel Oyeneye*

Main category: cs.CL

TL;DR: 本文研究了两种因果领域泛化技术在低资源自然语言任务中的应用，通过因果数据增强和因果表示学习提升情感分类模型在不同领域上的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中训练和测试数据分布往往不同，尤其在数据资源有限的情况下，模型难以泛化。需要方法增强模型对领域变化的鲁棒性。

Method: 1. 使用因果数据增强自动生成反事实示例，扩充训练数据，模拟分布变化。2. 使用DINER框架的因果不变表示学习，适配多语言情感分析。

Result: 反事实数据增强在跨领域情感分类中稳定提升准确率；DINER因果表示学习提升多语言情感分析的分布外表现，不同语言效果有所差异。

Conclusion: 因果数据增强和因果表示学习两种方法均能有效增强低资源语境下模型的领域泛化能力和鲁棒性。

Abstract: Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [35] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos,Legand L. Burge,Anietie Andy,Anis Yazidi,Vladimir Vlassov*

Main category: cs.CL

TL;DR: BiSparse-AAS是一种结合稀疏注意力、自适应跨度和双线性注意力的新框架，有效提升长文本摘要的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的模型在处理长文档时因计算复杂度高导致的扩展性差的问题。

Method: 提出BiSparse-AAS框架，结合稀疏注意力降低计算成本，自适应跨度动态调整注意范围，双线性注意力处理复杂的词元交互。

Result: 在CNN/DailyMail和XSum数据集上，BiSparse-AAS分别提升ROUGE分数约68.1%和52.6%，在OpenWebText和Gigaword上也表现优异。

Conclusion: BiSparse-AAS在提升效率、扩展性和长序列建模能力方面表现优异，提供了实用的长文本摘要解决方案。

Abstract: Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [36] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth,Victor Bursztyn,Puneet Mathur,Ani Nenkova*

Main category: cs.CL

TL;DR: SQLSpace是一种为文本转SQL任务设计的紧凑且可解释的表示方法，能帮助比较基准数据集、深入分析模型表现并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本转SQL任务中，缺乏一种能有效比较基准数据集组成、深入分析模型表现并指导改进的通用且可解释的表示方法。

Method: 提出SQLSpace，一种最小人工干预下获得的通用且紧凑的文本转SQL样本表示；利用其在三个方面评估：比较基准数据集组成、细粒度理解模型表现、基于正确性估计进行针对性查询重写以提升模型性能。

Result: SQLSpace揭示了不同基准数据集之间的组合差异，发现了准确率无法体现的模型表现模式，并支持基于查询成功预测的模型改进。

Conclusion: SQLSpace为文本转SQL任务提供了一种有效的分析与改进工具，克服了原始示例难以实现的细粒度性能分析和模型优化难题。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [37] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte*

Main category: cs.CL

TL;DR: 本文提出了一种以患者为中心的临床总结（PCS）生成框架，结合患者和临床医生的需求，利用多种开源大语言模型生成总结，并进行了定量和定性评估。


<details>
  <summary>Details</summary>
Motivation: 现有的临床总结多侧重于患者的生物学信息，忽视了患者的价值观、偏好和关切，难以实现以患者为中心的护理。

Method: 通过患者和临床医生访谈确定临床总结标准和结构，制定注释指南，由临床医生对88次房颤会诊生成金标PCS；采用16次会诊优化提示语，使用五种开源大语言模型在72次会诊上进行零样本与少样本总结生成，并采用ROUGE-L、BERTScore及定性指标评估表现。

Result: 患者强调生活方式、社会支持、压力和护理价值，临床医生关注功能性、心理社会及情感信息。模型中Mistral-8B和Llama-3.1-8B表现较好，生成的总结在完整性和流畅性方面接近专家水平，但正确性和以患者为中心程度仍落后于人工总结。

Conclusion: 当前开源大语言模型在生成以患者为中心的临床总结任务中表现有限，虽在语言流畅性和信息完整性方面接近人类，但在准确性及患者关注度上仍需提升，提示未来研究应继续优化模型以更好地支持患者中心护理。

Abstract: Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [38] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori,Nizar Habash,Abdelhakim Freihat,Younes Samih,Kirill Chirkunov,Muhammed AbuOdeh,Radu Florian,Teresa Lynn,Preslav Nakov,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 提出了DialectalArabicMMLU基准，用于评估大语言模型在阿拉伯不同方言上的表现，填补了方言评测的空白。


<details>
  <summary>Details</summary>
Motivation: 尽管已有针对现代标准阿拉伯语（MSA）的评测基准，但阿拉伯方言在日常交流中广泛使用，却缺乏系统的模型评估资源。

Method: 基于MMLU-Redux框架，手工翻译与适配3000个多选题，覆盖叙利亚、埃及、阿联酋、沙特和摩洛哥五大阿拉伯方言，总计15000个问答对，涉及32个学术和专业领域，并评测19个阿拉伯及多语种大语言模型。

Result: 评测结果显示不同方言间模型表现差异显著，提出的基准有效反映了模型在方言理解上的不足和泛化差距。

Conclusion: DialectalArabicMMLU为阿拉伯方言理解提供了首个统一且人工策划的评测资源，促进更具包容性的评估和未来模型优化。

Abstract: We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [39] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 本论文研究了在低资源语言（荷兰语、罗马尼亚语、西班牙语）中，针对医疗领域的预训练如何提升多语言BERT模型在医疗NLP任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 多语言医疗NLP工具匮乏，尤其是低资源语言，且当前研究较少，亟需探讨领域特定预训练对模型性能的影响。

Method: 首先进行四种不同的医疗领域预训练实验，构建领域适应模型，随后在三个下游任务（荷兰语自动病人筛查，罗马尼亚语与西班牙语命名实体识别）上微调并评估模型表现。

Result: 领域适应显著提升了任务性能，临床领域模型优于一般生物医学领域模型，同时观察到跨语言迁移能力。并通过进一步分析探讨性能差异的原因。

Conclusion: 领域适应及跨语言能力在医疗NLP中是可行且有效的，研究结果为低资源语言的多语言医疗NLP系统开发提供指导，缓解训练数据不足，提高模型性能。

Abstract: In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [40] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira,Antonio Castaldo,James O'Doherty,Sheila Castilho*

Main category: cs.CL

TL;DR: 本文通过模拟后期编辑工作流程，利用CPO方法实现了对大语言模型的高效领域适应，显著减少了所需数据量。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型领域适应依赖大量标注数据且代价高昂。作者希望通过更数据高效的方法实现领域特定适应。

Method: 通过将模型自身的原始输出作为“被拒绝”翻译，人工审批的翻译记忆条目作为“选择”翻译，生成偏好对，采用CPO方法进行训练。

Result: 实验证明，在英-巴葡和英-韩方向，用1.47万偏好对实现了接近用16万样本SFT训练模型的表现，显示了显著的数据效率。

Conclusion: 该方法不仅在机器翻译中有效，还可推广到其他生成任务，利用模型初稿和黄金参考对立的信号进行高效训练。

Abstract: LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [41] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo,Xiaonan Li,Yuxin Wang,Tingshuo Fan,Yuan Li,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出MARAG-R1框架，使用多检索工具和强化学习提升大语言模型在文献检索和推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法依赖单一检索器，限制了获取信息的广度和准确性，难以支持文献级推理。

Method: MARAG-R1通过四种检索工具（语义搜索、关键词搜索、过滤、聚合）和两阶段训练（监督微调+强化学习），实现多检索工具动态协调。

Result: 实验表明MARAG-R1在GlobalQA、HotpotQA和2WikiMultiHopQA数据集上显著优于强基线，达到了新的文献级推理性能新高。

Conclusion: 多工具协同的强化学习框架有效突破单一检索器瓶颈，提升了检索增强生成模型对外部知识的访问能力和推理性能。

Abstract: Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [42] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

Main category: cs.CL

TL;DR: 本文提出了SpecAttn，一种无需训练即可与现有推测解码技术结合，允许预训练变换器高效实现稀疏注意力的新方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理时由于自注意力机制的二次复杂度，在处理长上下文时计算瓶颈严重。

Method: SpecAttn利用推测解码中草稿模型已计算的注意力权重，结合KL散度层对齐、GPU优化的无排序top-p选择算法和动态的键值缓存剪枝技术，减少冗余计算。

Result: SpecAttn在PG-19数据集上减少了75%以上的键值缓存访问，困惑度仅增加15.29%，显著优于现有稀疏注意力方法。

Conclusion: SpecAttn证明了通过推测执行可实现高效注意力稀疏化，且无显著性能损失，提升了推理效率。

Abstract: Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [43] [Culture Cartography: Mapping the Landscape of Cultural Knowledge](https://arxiv.org/abs/2510.27672)
*Caleb Ziems,William Held,Jane Yu,Amir Goldberg,David Grusky,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出了一种名为CultureCartography的混合主动式方法，结合了大语言模型和用户协作，挖掘文化特定的知识，提升模型对文化相关问题的理解和表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法单一，用户和研究者之间缺乏协同，难以有效发现对特定文化群体重要但模型未知的知识。

Method: 通过LLM提出低置信度问题，由用户填补知识空白并直接编辑问题内容，形成混合主动式的文化知识标注工具CultureExplorer。

Result: CultureExplorer相比传统的人类回答LLM问题的方式，更有效地发现模型缺失的文化知识，相关模型训练后表现显著提升，Llama-3.1-8B准确率提升最高19.2%。

Conclusion: 结合人机协作的混合主动式方法能更好地挖掘文化特异知识，增强LLM对不同文化背景的适应能力和表现。

Abstract: To serve global users safely and productively, LLMs need culture-specific
knowledge that might not be learned during pre-training. How do we find such
knowledge that is (1) salient to in-group users, but (2) unknown to LLMs? The
most common solutions are single-initiative: either researchers define
challenging questions that users passively answer (traditional annotation), or
users actively produce data that researchers structure as benchmarks (knowledge
extraction). The process would benefit from mixed-initiative collaboration,
where users guide the process to meaningfully reflect their cultures, and LLMs
steer the process towards more challenging questions that meet the researcher's
goals. We propose a mixed-initiative methodology called CultureCartography.
Here, an LLM initializes annotation with questions for which it has
low-confidence answers, making explicit both its prior knowledge and the gaps
therein. This allows a human respondent to fill these gaps and steer the model
towards salient topics through direct edits. We implement this methodology as a
tool called CultureExplorer. Compared to a baseline where humans answer
LLM-proposed questions, we find that CultureExplorer more effectively produces
knowledge that leading models like DeepSeek R1 and GPT-4o are missing, even
with web search. Fine-tuning on this data boosts the accuracy of Llama-3.1-8B
by up to 19.2% on related culture benchmarks.

</details>


### [44] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao,Darren Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: 本文提出了连续自回归语言模型（CALM），通过将语言生成从离散的逐词预测转变为连续向量预测，大幅减少生成步骤，提高生成效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的生成效率受限于逐词生成的顺序性，突破瓶颈需要提升每步生成的语义带宽。

Method: 利用高保真自编码器将K个词压缩为一个连续向量，实现语言序列由离散词转为连续向量序列，减少生成步骤，并开发无似然估计的训练和采样框架。

Result: CALM显著提升了性能与计算成本的权衡，在计算资源大幅降低的情况下达到强离散基线的性能。

Conclusion: 通过将下一步预测从词转向向量，CALM为超高效语言模型的发展提供了一条强有力且可扩展的新路径。

Abstract: The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [45] [FinPos: A Position-Aware Trading Agent System for Real Financial Markets](https://arxiv.org/abs/2510.27251)
*Bijia Liu,Ronghao Dang*

Main category: cs.MA

TL;DR: 本文提出了一个关注持仓管理的交易任务，并开发了名为FinPos的交易代理系统，以应对更真实的市场环境。


<details>
  <summary>Details</summary>
Motivation: 现有交易代理多集中于单步交易，缺乏对连续持仓管理的认知，难以适应真实市场的连续性和复杂性。

Method: 设计了一个持仓感知的交易任务；开发了FinPos系统，采用双决策代理和多时间尺度奖励机制，从专业视角解读市场信息，实现短期波动与长期趋势的平衡。

Result: 通过大量实验，FinPos在持仓感知交易任务中表现优于现有先进交易代理，更贴近真实市场环境。

Conclusion: 基于大语言模型的交易代理系统在长期市场决策中展现出巨大潜力，值得进一步探索。

Abstract: The exceptional potential of large language models (LLMs) in handling text
information has garnered significant attention in the field of financial
trading. However, current trading agents primarily focus on single-step trading
tasks and lack awareness of continuous position management. Therefore, we
propose a position-aware trading task designed to simulate a more realistic
market. To address this task, we develop a trading agent system, FinPos,
optimized for position management. FinPos is able to interpret various types of
market information from a professional perspective, providing a reliable basis
for positioning decisions. To mitigate the substantial market risks arising
from position fluctuations, FinPos employs dual decision agents. Furthermore,
the continuous nature of position management necessitates our adoption of
multi-timescale rewards, which in turn empowers FinPos to effectively balance
short-term fluctuations against long-term trends. Extensive experiments
demonstrate that FinPos surpasses state-of-the-art trading agents in the
position-aware trading task, which closely mirrors real market conditions. More
importantly, our findings reveal that LLM-centered agent systems exhibit a
vast, largely unexplored potential in long-term market decision-making.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [46] [Empirical Studies on Quantum Optimization for Software Engineering: A Systematic Analysis](https://arxiv.org/abs/2510.27113)
*Man Zhang,Yuechen Li,Tao Yue,Kai-Yuan Cai*

Main category: cs.SE

TL;DR: 本文系统分析了量子、量子启发式及混合算法在软件工程优化问题中的实证研究，发现当前实证设计存在重复次数、噪声处理和评价指标等不足。


<details>
  <summary>Details</summary>
Motivation: 量子及相关算法在软件工程优化问题中潜力显著，但实证研究缺乏统一和规范的设计标准。

Method: 基于最新系统综述中识别的初步研究，系统分析了实验设计、超参数设置、案例研究、对比基线、工具以及评价指标。

Result: 发现现有实证研究普遍存在重复次数报告不足、噪声处理不充分、缺少量子特定指标及标准化评价协议等关键缺口。

Conclusion: 提出实证研究设计建议，强调需要更多现实且开放的案例研究以评估算法的成本效益和实际效用，旨在成为量子及相关算法评估研究的参考基准。

Abstract: In recent years, quantum, quantum-inspired, and hybrid algorithms are
increasingly showing promise for solving software engineering optimization
problems. However, best-intended practices for conducting empirical studies
have not yet well established. In this paper, based on the primary studies
identified from the latest systematic literature review on quantum optimization
for software engineering problems, we conducted a systematic analysis on these
studies from various aspects including experimental designs, hyperparameter
settings, case studies, baselines, tooling, and metrics. We identify key gaps
in the current practices such as limited reporting of the number of
repetitions, number of shots, and inadequate consideration of noise handling,
as well as a lack of standardized evaluation protocols such as the adoption of
quality metrics, especially quantum-specific metrics. Based on our analysis, we
provide insights for designing empirical studies and highlight the need for
more real-world and open case studies to assess cost-effectiveness and
practical utility of the three types of approaches: quantum-inspired, quantum,
and hybrid. This study is intended to offer an overview of current practices
and serve as an initial reference for designing and conducting empirical
studies on evaluating and comparing quantum, quantum-inspired, and hybrid
algorithms in solving optimization problems in software engineering.

</details>


### [47] [MARIA: A Framework for Marginal Risk Assessment without Ground Truth in AI Systems](https://arxiv.org/abs/2510.27163)
*Jieshan Chen,Suyu Ma,Qinghua Lu,Sung Une Lee,Liming Zhu*

Main category: cs.SE

TL;DR: 本文提出了一种边际风险评估框架，用于在缺乏绝对风险和真实标签的情况下比较AI系统与现有系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统评估依赖真实标签和绝对风险，但在长时间运行且被视为安全的系统中，真实标签常常缺失或昂贵，评估困难。

Method: 提出边际风险评估框架，通过相对评估方法，包括可预测性、能力和交互主导性，避免依赖真实标签和绝对风险。

Result: 该方法能明确识别AI系统相较现有系统的改进点、新增风险及其影响，提供实际的指导建议。

Conclusion: 通过相对评价取代绝对评价，本文方法提升了AI系统部署的安全性和责任感，具有实用价值。

Abstract: Before deploying an AI system to replace an existing process, it must be
compared with the incumbent to ensure improvement without added risk.
Traditional evaluation relies on ground truth for both systems, but this is
often unavailable due to delayed or unknowable outcomes, high costs, or
incomplete data, especially for long-standing systems deemed safe by
convention. The more practical solution is not to compute absolute risk but the
difference between systems. We therefore propose a marginal risk assessment
framework, that avoids dependence on ground truth or absolute risk. It
emphasizes three kinds of relative evaluation methodology, including
predictability, capability and interaction dominance. By shifting focus from
absolute to relative evaluation, our approach equips software teams with
actionable guidance: identifying where AI enhances outcomes, where it
introduces new risks, and how to adopt such systems responsibly.

</details>


### [48] [On the Marriage of Theory and Practice in Data-Aware Business Processes via Low-Code](https://arxiv.org/abs/2510.27229)
*Ali Nour Eldin,Benjamin Dalmas,Walid Gaaloul*

Main category: cs.SE

TL;DR: 提出了一种融合数据处理的可执行BPMN验证框架BPMN-ProX，提升数据驱动业务流程模型的验证效能。


<details>
  <summary>Details</summary>
Motivation: 业务流程模型广泛应用但缺乏形式化语义，尤其是处理数据驱动的流程模型，亟需形式化执行语义和有效的验证手段。

Method: 引入BPMN-ProX低代码测试框架，将数据注入BPMN流程，结合先进的数据处理和模型检测器，实现强大的验证机制。

Result: 该框架显著增强了数据感知BPMN的验证能力，桥接了非技术专家与专业人员的沟通鸿沟。

Conclusion: BPMN-ProX结合理论验证与实际建模，助力更灵活、可靠、面向用户的业务流程管理。

Abstract: In recent years, there has been a growing interest in the verification of
business process models. Despite their lack of formal characterization, these
models are widely adopted in both industry and academia. To address this issue,
formalizing the execution semantics of business process modeling languages is
essential. Since data and process are two facets of the same coin, and data are
critical elements in the execution of process models, this work introduces
Proving an eXecutable BPMN injected with data, BPMN-ProX. BPMN-ProX is a
low-code testing framework that significantly enhances the verification of
data-aware BPMN. This low-code platform helps bridge the gap between
non-technical experts and professionals by proposing a tool that integrates
advanced data handling and employs a robust verification mechanism through
state-of-the-art model checkers. This innovative approach combines theoretical
verification with practical modeling, fostering more agile, reliable, and
user-centric business process management.

</details>


### [49] [Vintage Code, Modern Judges: Meta-Validation in Low Data Regimes](https://arxiv.org/abs/2510.27244)
*Ora Nova Fandina,Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Rami Katan,Alice Podolsky,Orna Raz*

Main category: cs.SE

TL;DR: 本文提出了SparseAlign框架，用于在人类标注数据稀缺的情况下评估大型语言模型作为评判者的可靠性，特别应用于遗留语言如COBOL代码解释。


<details>
  <summary>Details</summary>
Motivation: 遗留语言应用现代化过程中缺乏专家资源和高质量评估数据，利用大型语言模型作为评判者的可靠性亟需验证以避免循环评价风险。

Method: SparseAlign结合了新颖的成对置信度概念与对分数敏感的对齐度量，能够捕捉排序一致性和分数接近度，在有限标注样本情况下实现可靠的评估者选择。

Result: 通过对四个大型语言模型评判者的案例研究，SparseAlign成功选择出与人类判断高度一致的评估者，并将其应用于COBOL代码解释评估流程，辅助模型发布决策。

Conclusion: SparseAlign提供了一种有效方法，在稀缺人类评价数据条件下验证大型语言模型评判者的对齐度，确保其在高风险场景中的可靠应用。

Abstract: Application modernization in legacy languages such as COBOL, PL/I, and REXX
faces an acute shortage of resources, both in expert availability and in
high-quality human evaluation data. While Large Language Models as a Judge
(LaaJ) offer a scalable alternative to expert review, their reliability must be
validated before being trusted in high-stakes workflows. Without principled
validation, organizations risk a circular evaluation loop, where unverified
LaaJs are used to assess model outputs, potentially reinforcing unreliable
judgments and compromising downstream deployment decisions. Although various
automated approaches to validating LaaJs have been proposed, alignment with
human judgment remains a widely used and conceptually grounded validation
strategy. In many real-world domains, the availability of human-labeled
evaluation data is severely limited, making it difficult to assess how well a
LaaJ aligns with human judgment. We introduce SparseAlign, a formal framework
for assessing LaaJ alignment with sparse human-labeled data. SparseAlign
combines a novel pairwise-confidence concept with a score-sensitive alignment
metric that jointly capture ranking consistency and score proximity, enabling
reliable evaluator selection even when traditional statistical methods are
ineffective due to limited annotated examples. SparseAlign was applied
internally to select LaaJs for COBOL code explanation. The top-aligned
evaluators were integrated into assessment workflows, guiding model release
decisions. We present a case study of four LaaJs to demonstrate SparseAlign's
utility in real-world evaluation scenarios.

</details>


### [50] [Efficient Integration of cross platform functions onto service-oriented architectures](https://arxiv.org/abs/2510.27344)
*Thomas Schulik,Viswanatha Reddy Batchu,Ramesh Kumar Dharmapuri,Saran Gundlapalli,Parthasarathy Nadarajan,Philipp Pelcz*

Main category: cs.SE

TL;DR: 本文提出了一种硬件和软件平台无关的应用开发与集成概念，以提高软件定义车辆(SDV)中应用的开发和集成效率。


<details>
  <summary>Details</summary>
Motivation: 随着车载技术复杂性的增加，汽车电子架构正从分散多个ECU向集成化、高性能计算机方向转变，导致出现多个异构软件平台，亟需开发跨平台且硬件无关的应用。

Method: 设计应用时不依赖特定硬件和软件平台，规范应用接口，并以机器可读格式描述应用及中间件相关信息，辅以开发工具实现半自动化的开发和集成过程。

Result: 成功开发了示例应用，并将其集成到AUTOSAR Adaptive和ROS 2平台，证明了方法的适用性，同时提出了衡量整体效率的指标。

Conclusion: 该方法能够有效支持多平台的软件应用开发与集成，提升软件定义车辆中应用开发的灵活性和效率。

Abstract: The automotive industry is currently undergoing a major transformation with
respect to the Electric/Electronic (E/E) and software architecture, driven by a
significant increase in the complexity of the technological stack within a
vehicle. This complexity acts as a driving force for Software-Defined Vehicles
(SDVs) leading to the evolution of the automotive E/E architectures from
decentralized configuration comprising multiple Electronic Control Units (ECUs)
towards a more integrated configuration comprising a smaller number of ECUs,
domain controllers, gateways, and High-Performance Computers (HPCs) [2]. This
transition along with several other reasons have resulted in heterogeneous
software platforms such as AUTOSAR Classic, AUTOSAR Adaptive, and prototypical
frameworks like ROS 2. It is therefore essential to develop applications that
are both hardware- and platform/middleware-agnostic to attain development and
integration efficiency. This work presents an application development and
integration concept to facilitate developing applications as Software as a
Product (SaaP), while simultaneously ensuring efficient integration onto
multiple software architecture platforms. The concept involves designing
applications in a hardware- and software platform-agnostic manner and
standardizing application interfaces [6]. It also includes describing the
relevant aspects of the application and corresponding middleware in a
machine-readable format to aid the integration of developed applications.
Additionally, tools are developed to facilitate semi-automation of the
development and integration processes. An example application has been
developed and integrated onto AUTOSAR Adaptive and ROS 2, demonstrating the
applicability of the approach. Finally, metrics are presented to show the
efficiency of the overall concept.

</details>


### [51] [Agentic LLMs for REST API Test Amplification: A Comparative Study Across Cloud Applications](https://arxiv.org/abs/2510.27417)
*Jarne Besjes,Robbe Nooyens,Tolgahan Bardakci,Mutlu Beyazit,Serge Demeyer*

Main category: cs.SE

TL;DR: 本文评估了单智能体与多智能体配置的LLM驱动测试放大方法在云应用REST API上的有效性，提升了测试覆盖率并发现缺陷。


<details>
  <summary>Details</summary>
Motivation: 设计自动化且覆盖全面的REST API测试用例复杂且成本高，迫切需要高效的测试放大技术。

Method: 采用基于大语言模型（LLM）的单智能体和多智能体测试放大方法，自动生成并扩充测试用例，保持语义有效性。

Result: 实验在四个云应用中验证，放大后的测试套件覆盖更多端点和参数，能有效揭示软件缺陷，且分析了计算成本、运行时间和能耗的权衡。

Conclusion: LLM驱动的测试放大技术能显著提升REST API测试的自动化水平和可持续性，适用于复杂异构云环境。

Abstract: Representational State Transfer (REST) APIs are a cornerstone of modern cloud
native systems. Ensuring their reliability demands automated test suites that
exercise diverse and boundary level behaviors. Nevertheless, designing such
test cases remains a challenging and resource intensive endeavor. This study
extends prior work on Large Language Model (LLM) based test amplification by
evaluating single agent and multi agent configurations across four additional
cloud applications. The amplified test suites maintain semantic validity with
minimal human intervention. The results demonstrate that agentic LLM systems
can effectively generalize across heterogeneous API architectures, increasing
endpoint and parameter coverage while revealing defects. Moreover, a detailed
analysis of computational cost, runtime, and energy consumption highlights
trade-offs between accuracy, scalability, and efficiency. These findings
underscore the potential of LLM driven test amplification to advance the
automation and sustainability of REST API testing in complex cloud
environments.

</details>


### [52] [CodeAlignBench: Assessing Code Generation Models on Developer-Preferred Code Adjustments](https://arxiv.org/abs/2510.27565)
*Forough Mehralian,Ryan Shar,James R. Rae,Alireza Hashemi*

Main category: cs.SE

TL;DR: 本文提出了一个多语言的代码生成评估基准，重点评估大型语言模型的指令遵循能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注功能正确性，忽视了真实开发场景中的多样化任务和开发者期望。

Method: 设计了一个支持多语言且可扩展的基准，评估模型对预定义约束和后续指令的遵循能力，并用LiveBench中的编程任务及其Python到Java和JavaScript的自动翻译进行实证分析。

Result: 评估发现模型在不同语言和指令遵循维度上表现各异，展示了模型的优点和不足。

Conclusion: 该基准为代码生成模型提供了更全面的评估手段，有助于更准确理解模型性能和改进方向。

Abstract: As large language models become increasingly capable of generating code,
evaluating their performance remains a complex and evolving challenge. Existing
benchmarks primarily focus on functional correctness, overlooking the diversity
of real-world coding tasks and developer expectations. To this end, we
introduce a multi-language benchmark that evaluates LLM instruction-following
capabilities and is extensible to operate on any set of standalone coding
problems. Our benchmark evaluates instruction following in two key settings:
adherence to pre-defined constraints specified with the initial problem, and
the ability to perform refinements based on follow-up instructions. For this
paper's analysis, we empirically evaluated our benchmarking pipeline with
programming tasks from LiveBench, that are also automatically translated from
Python into Java and JavaScript. Our automated benchmark reveals that models
exhibit differing levels of performance across multiple dimensions of
instruction-following. Our benchmarking pipeline provides a more comprehensive
evaluation of code generation models, highlighting their strengths and
limitations across languages and generation goals.

</details>


### [53] [Enhancing software product lines with machine learning components](https://arxiv.org/abs/2510.27640)
*Luz-Viviana Cobaleda,Julián Carvajal,Paola Vallejo,Andrés López,Raúl Mazo*

Main category: cs.SE

TL;DR: 本文提出了一个结构化框架，扩展了软件产品线(SPL)工程以支持机器学习(ML)组件的集成，解决了SPL中ML组件变异性管理的挑战。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习技术的发展，其在现代软件系统中的集成越来越普遍，但这对软件产品线工程管理变异性和复用带来了复杂挑战，现有方法在ML与SPL的交叉领域支持不足。

Method: 提出一个结构化框架，扩展软件产品线工程，促进机器学习组件的集成和系统变异性的建模与管理，部分基于VariaMos工具实现。

Result: 该框架支持带有机器学习能力的软件产品线设计，实现了系统变异性的有效管理和复用。

Conclusion: 本文架构为将机器学习组件纳入软件产品线提供了系统方法，弥补了两个领域交叉的研究空白，提升了软件系统的设计与复用能力。

Abstract: Modern software systems increasingly integrate machine learning (ML) due to
its advancements and ability to enhance data-driven decision-making. However,
this integration introduces significant challenges for software engineering,
especially in software product lines (SPLs), where managing variability and
reuse becomes more complex with the inclusion of ML components. Although
existing approaches have addressed variability management in SPLs and the
integration of ML components in isolated systems, few have explored the
intersection of both domains. Specifically, there is limited support for
modeling and managing variability in SPLs that incorporate ML components. To
bridge this gap, this article proposes a structured framework designed to
extend Software Product Line engineering, facilitating the integration of ML
components. It facilitates the design of SPLs with ML capabilities by enabling
systematic modeling of variability and reuse. The proposal has been partially
implemented with the VariaMos tool.

</details>


### [54] [On Selecting Few-Shot Examples for LLM-based Code Vulnerability Detection](https://arxiv.org/abs/2510.27675)
*Md Abdul Hannan,Ronghao Ni,Chi Zhang,Limin Jia,Ravi Mangal,Corina S. Pasareanu*

Main category: cs.SE

TL;DR: 本文研究了如何通过选择合适的few-shot示例提升大语言模型在代码漏洞检测任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在代码相关任务表现出色，但检测代码漏洞仍具挑战性，且few-shot示例的选择对性能影响显著。

Method: 提出两种选择few-shot示例的标准：一是根据模型是否在样本上犯错，二是根据样本与查询程序的相似度（基于k近邻）。评估了这两种标准的效果及其组合。

Result: 实验证明这两种标准在多数据集和不同开源模型上的单独以及组合使用均能带来性能提升。

Conclusion: 合理选取few-shot示例是提升大语言模型代码漏洞检测能力的有效途径，本文提出的方法为示例选择提供了有效标准。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities for
many coding tasks, including summarization, translation, completion, and code
generation. However, detecting code vulnerabilities remains a challenging task
for LLMs. An effective way to improve LLM performance is in-context learning
(ICL) - providing few-shot examples similar to the query, along with correct
answers, can improve an LLM's ability to generate correct solutions. However,
choosing the few-shot examples appropriately is crucial to improving model
performance. In this paper, we explore two criteria for choosing few-shot
examples for ICL used in the code vulnerability detection task. The first
criterion considers if the LLM (consistently) makes a mistake or not on a
sample with the intuition that LLM performance on a sample is informative about
its usefulness as a few-shot example. The other criterion considers similarity
of the examples with the program under query and chooses few-shot examples
based on the $k$-nearest neighbors to the given sample. We perform evaluations
to determine the benefits of these criteria individually as well as under
various combinations, using open-source models on multiple datasets.

</details>
