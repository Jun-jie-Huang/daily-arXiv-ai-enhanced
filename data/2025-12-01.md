<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 104]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.SE](#cs.SE) [Total: 22]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [EvalCards: A Framework for Standardized Evaluation Reporting](https://arxiv.org/abs/2511.21695)
*Ruchira Dhar,Danae Sanchez Villegas,Antonia Karamolegkou,Alice Schiavone,Yifei Yuan,Xinyi Chen,Jiaang Li,Stella Frank,Laura De Grazia,Monorama Swain,Stephanie Brandl,Daniel Hershcovich,Anders Søgaard,Desmond Elliott*

Main category: cs.CL

TL;DR: 本文识别了NLP评估报告中的三大不足，并提出EvalCards以提升透明度和满足治理需求。


<details>
  <summary>Details</summary>
Motivation: 当前NLP快速发布的开放模型背景下，评估报告存在再现性、可访问性和治理方面的缺陷，现有标准化努力不够充分。

Method: 基于对现有评估与文档工作的调研，设计了EvalCards，旨在为研究人员和实践者提供透明的评估报告框架。

Result: EvalCards为提升模型评估透明度提供了切实可行的工具，并能满足新兴的治理要求。

Conclusion: 本文提出了EvalCards作为提升NLP模型评估透明度和应对评估报告中再现性、可访问性及治理缺陷的解决方案。

Abstract: Evaluation has long been a central concern in NLP, and transparent reporting practices are more critical than ever in today's landscape of rapidly released open-access models. Drawing on a survey of recent work on evaluation and documentation, we identify three persistent shortcomings in current reporting practices: reproducibility, accessibility, and governance. We argue that existing standardization efforts remain insufficient and introduce Evaluation Disclosure Cards (EvalCards) as a path forward. EvalCards are designed to enhance transparency for both researchers and practitioners while providing a practical foundation to meet emerging governance requirements.

</details>


### [2] [Cacheback: Speculative Decoding With Nothing But Cache](https://arxiv.org/abs/2511.21699)
*Zhiyao Ma,In Gim,Lin Zhong*

Main category: cs.CL

TL;DR: 提出了一种基于LRU缓存的简单高效推测解码方法Cacheback Decoding，显著提升推理速度且易于集成。


<details>
  <summary>Details</summary>
Motivation: 加速大型语言模型推理，提高推理效率和响应速度。

Method: 采用最少最近使用 (LRU) 缓存表存储token n-gram，利用缓存的局部性信息生成草稿序列进行推测解码。

Result: 在同类方法中达到最先进的性能，设计简洁且易于集成，且在新领域的快速适应性方面表现出潜力。

Conclusion: Cacheback Decoding通过利用语言的局部性，实现了一种无需训练且模型无关的推测解码方法，有效加速大型语言模型推理。

Abstract: We present Cacheback Decoding, a training-free and model-agnostic speculative decoding method that exploits the locality in language to accelerate Large Language Model (LLM) inference. Cacheback leverages only Least Recently Used (LRU) cache tables of token n-grams to generate draft sequences. Cacheback achieves state-of-the-art performance among comparable methods despite its minimalist design, and its simplicity allows easy integration into existing systems. Cacheback also shows potential for fast adaptation to new domains.

</details>


### [3] [MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation](https://arxiv.org/abs/2511.23397)
*Mahdi Rahmani,AmirHossein Saffari,Reyhane Rahmani*

Main category: cs.CL

TL;DR: 该文提出了MegaChat，一种自动化多智能体系统，生成大规模波斯语问答数据，提升Telegram电商聊天机器人的智能化，突破了低资源语言数据难题。


<details>
  <summary>Details</summary>
Motivation: 伊朗中小企业在Telegram电商场景中需求实时互动智能聊天机器人，但缺乏高质量波斯语问答数据集，且人工制作成本高昂，故需自动化生成方法。

Method: 构建自动化多智能体架构，从Telegram购物频道抓取数据，经过问题生成、验证和优化步骤生成个性化高质量问答对；评估时对比传统RAG模型，采用多查询检索和重排序提升回答生成质量。

Result: 本文提出了MegaChat，这是首个完全合成的波斯语问答数据集，用于评估基于Telegram的电子商务智能销售聊天机器人。通过一种新颖的自动化多智能体架构，从活跃的Telegram购物频道收集数据生成个性化问答对，并采用专门的智能体进行问题生成、验证和优化，确保数据真实多样。与三种传统的检索增强生成（RAG）模型比较，基于多查询检索、重排序和个性化响应合成的多智能体系统在多数频道表现更优，无需依赖昂贵的人类标注或复杂微调。

Conclusion: 多智能体架构能够高效生成高质量的波斯语问答数据，提升基于Telegram的智能销售机器人性能，降低开发成本，为低资源语言的多语言对话AI发展提供了有效解决方案。

Abstract: Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet

</details>


### [4] [JELV: A Judge of Edit-Level Validity for Evaluation and Automated Reference Expansion in Grammatical Error Correction](https://arxiv.org/abs/2511.21700)
*Yuhao Zhan,Yuqing Zhang,Jing Yuan,Qixiang Ma,Zhiqi Yang,Yu Gu,Zemin Liu,Fei Wu*

Main category: cs.CL

TL;DR: 提出了Judge of Edit-Level Validity (JELV)框架，用于自动验证语法错误校正的编辑有效性，提升评价多样性和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语法错误校正系统受限于参考答案多样性不足，导致评价低估和模型泛化受限。

Method: 构建人类标注的编辑级有效性数据集PEVData，设计多轮大语言模型判定管线和蒸馏的DeBERTa分类器；利用JELV重新分类错误判断并融合假阳性消解与流畅度评分，形成综合评价指标。

Result: LLM判定与人类一致率达90%，DeBERTa分类器有效编辑准确率85%；使用JELV扩充数据集，重新训练顶级系统显著提升性能；评价指标与人工判断相关性达到领先水平。

Conclusion: JELV为提高参考多样性、优化评价和增强模型泛化提供了可扩展的自动化解决方案。

Abstract: Existing Grammatical Error Correction (GEC) systems suffer from limited reference diversity, leading to underestimated evaluation and restricted model generalization. To address this issue, we introduce the Judge of Edit-Level Validity (JELV), an automated framework to validate correction edits from grammaticality, faithfulness, and fluency. Using our proposed human-annotated Pair-wise Edit-level Validity Dataset (PEVData) as benchmark, JELV offers two implementations: a multi-turn LLM-as-Judges pipeline achieving 90% agreement with human annotators, and a distilled DeBERTa classifier with 85% precision on valid edits. We then apply JELV to reclassify misjudged false positives in evaluation and derive a comprehensive evaluation metric by integrating false positive decoupling and fluency scoring, resulting in state-of-the-art correlation with human judgments. We also apply JELV to filter LLM-generated correction candidates, expanding the BEA19's single-reference dataset containing 38,692 source sentences. Retraining top GEC systems on this expanded dataset yields measurable performance gains. JELV provides a scalable solution for enhancing reference diversity and strengthening both evaluation and model generalization.

</details>


### [5] [47B Mixture-of-Experts Beats 671B Dense Models on Chinese Medical Examinations](https://arxiv.org/abs/2511.21701)
*Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song,Ziqian Bi*

Main category: cs.CL

TL;DR: 本文对27个大语言模型在中文医学考试中进行基准测试，发现模型表现差异显著，模型大小与性能无明显关联，且不同医学专科表现存在差别。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在医学领域应用的兴趣日益增长，论文旨在系统评估这些模型在真实医学考试问题上的表现，揭示其能力和局限，为后续研究和应用提供基准数据。

Method: 构建包含2800个涵盖七个医学专科且分为两专业级别的中文医学考试问题数据集，设计稳健的评估框架，对27个先进LLM进行全面性能测评和比较分析。

Result: Mixtral-8x7B模型表现最佳，总体准确率74.25%；DeepSeek-R1-671B次之为64.07%。模型在不同专科表现差异明显，心血管和神经科表现较好，消化和肾脏科相对较弱。高表现模型在初级和高级考试难度间表现稳定，显示良好的泛化能力。

Conclusion: 该论文通过对27个先进大语言模型在中文医学考试问题上的全面评估，揭示了模型之间在医学领域表现上的显著差异，强调了模型规模与性能之间无明显相关性，表明大型模型不一定优于小型混合专家架构。评估结果也指出不同医学专科间的表现差距，提供了模型在医学教育和临床决策支持系统中应用的关键参考。

Abstract: The rapid advancement of large language models(LLMs) has prompted significant interest in their potential applications in medical domains. This paper presents a comprehensive benchmark evaluation of 27 state-of-the-art LLMs on Chinese medical examination questions, encompassing seven medical specialties across two professional levels. We introduce a robust evaluation framework that assesses model performance on 2,800 carefully curated questions from cardiovascular, gastroenterology, hematology, infectious diseases, nephrology, neurology, and respiratory medicine domains. Our dataset distinguishes between attending physician and senior physician difficulty levels, providing nuanced insights into model capabilities across varying complexity. Our empirical analysis reveals substantial performance variations among models, with Mixtral-8x7B achieving the highest overall accuracy of 74.25%, followed by DeepSeek-R1-671B at 64.07%. Notably, we observe no consistent correlation between model size and performance, as evidenced by the strong performance of smaller mixture-of-experts architectures. The evaluation demonstrates significant performance gaps between medical specialties, with models generally performing better on cardiovascular and neurology questions compared to gastroenterology and nephrology domains. Furthermore, our analysis indicates minimal performance degradation between attending and senior physician levels for top-performing models, suggesting robust generalization capabilities. This benchmark provides critical insights for the deployment of LLMs in medical education and clinical decision support systems, highlighting both the promise and current limitations of these technologies in specialized medical contexts.

</details>


### [6] [CSV-Decode: Certifiable Sub-Vocabulary Decoding for Efficient Large Language Model Inference](https://arxiv.org/abs/2511.21702)
*Dong Liu,Yanxuan Yu,Ben Lengerich*

Main category: cs.CL

TL;DR: 提出了CSV-Decode方法，通过构建小子词表提升大语言模型推理效率，同时保证准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在推理时因输出层对大词汇表的计算开销大造成计算瓶颈。

Method: 利用几何上界和词汇聚类构建子词表，并结合稀疏计算、多GPU分片和CUDA优化实现高效推理。

Result: 实验表明该方法在保持分布保证和低回退率的同时，相较于全词汇表解码实现了显著加速。

Conclusion: CSV-Decode有效缓解了大语言模型推理的计算瓶颈，兼顾效率与准确性，具有较高实用价值。

Abstract: Large language models face significant computational bottlenecks during inference due to the expensive output layer computation over large vocabularies. We present CSV-Decode, a novel approach that uses geometric upper bounds to construct small sub-vocabularies for each decoding step, enabling efficient sparse computation while maintaining dual correctness guarantees: exact top-$k$ certification and $\varepsilon$-certified softmax approximations. Our method clusters vocabulary embeddings offline and uses centroid-plus-radius bounds to identify which tokens can be safely omitted from computation. We provide a complete system implementation with sparse GEMV kernels, multi-GPU sharding, and CUDA Graph optimization. Experimental results demonstrate significant speedup over full vocabulary decoding while maintaining distributional guarantees and low fallback rates. Our code implementation available at \href{https://github.com/FastLM/CSV-Decode}{https://github.com/FastLM/CSV-Decode}.

</details>


### [7] [Evaluating Embedding Generalization: How LLMs, LoRA, and SLERP Shape Representational Geometry](https://arxiv.org/abs/2511.21703)
*Siyaxolisa Kabane*

Main category: cs.CL

TL;DR: 本文比较了基于大语言模型和非LLM编码器的文本嵌入泛化能力，提出使用SLERP模型融合方法来缓解任务适应带来的过度专门化，实验证明SLERP提升了聚类性能和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有嵌入模型在适应特定任务时容易过度专门化，影响泛化能力，特别是在大语言模型适配后，需探索如何缓解这种现象并提升嵌入质量。

Method: 设计数值序列聚类任务，比较非LLM编码器、LLM-LoRA适配、模型融合（model souping和SLERP）四种模型，评估聚类效果及表示信息，重点考察SLERP融合方法的效果。

Result: 实验显示LLM基模型在捕获高阶组合数值模式上表现更佳，但适配LoRA导致过拟合。SLERP融合有效恢复基础模型结构，保留任务收益，改善聚类可分性和模型鲁棒性，优于model souping和未融合模型。

Conclusion: LLM为基础的嵌入模型能够更好地捕获复杂的数值模式，但任务特定的适应会导致过度专门化。通过SLERP进行模型融合可以有效缓解这种过拟合，同时保留任务收益，提升聚类效果和稳健性。

Abstract: We investigate the generalization properties of dense text embeddings when the embedding backbone is a large language model (LLM) versus when it is a non-LLM encoder, and we study the extent to which spherical linear interpolation (SLERP) model-merging mitigates over-specialization introduced by task-specific adaptation (e.g., LoRA). To make the comparison concrete and domain-agnostic, we design a controlled suite of experiments in which models embed short numerical sequences and are evaluated on their ability to cluster and classify those sequences according to well-defined number-theoretic properties. Our experimental protocol compares four families of models: (1) non-LLM encoders trained from scratch or fine-tuned for embeddings, (2) LLM-based encoders adapted with parameter-efficient methods (LoRA), (3) LLM-based encoders with LoRA followed by model souping merging into the base weights, and (4) the same LoRA-adapted LLMs merged using SLERP across checkpoints or stages. We evaluate representational quality with clustering indices (Silhouette and Davies Bouldin). We additionally analyze the use of kmeans labels to see if the embeddings encode any other information besides the one we are testing for. Empirically, we find that LLM-based backbones produce embeddings that better capture higher-order, compositional numeric patterns, but are prone to adapter dominance that degrades balanced generalization; SLERP merging consistently recovers base-model structure while retaining most task gains, yielding superior tradeoffs in clustering separability, and robustness compared to model souping or models that were not merged.

</details>


### [8] [On the Cross-lingual Transferability of Pre-trained wav2vec2-based Models](https://arxiv.org/abs/2511.21704)
*Jonatas Grosman,Cassio Almeida,Guilherme Schardong,Hélio Lopes*

Main category: cs.CL

TL;DR: 本研究探讨wav2vec2预训练模型跨语言迁移性能，发现数据多样性和语言相似性是关键因素。


<details>
  <summary>Details</summary>
Motivation: 目前wav2vec2模型多用于语音任务，但跨语言迁移特性及其影响因素尚少研究，本论文意在填补该空白，帮助更有效利用预训练模型。

Method: 使用15个wav2vec2预训练模型，在18种语言上进行语音识别微调实验，分析预训练数据规模、多样性及语言相似度对性能的影响。

Result: 本论文通过对15个基于wav2vec2的大型预训练模型在18种语言上的语音识别微调实验，发现预训练时数据的多样性比数据量更重要，且印欧语系语言的表现优于非印欧语系语言。此外，单语预训练模型在跨语言迁移上有正向效果，且越接近预训练语言迁移效果越好。

Conclusion: 预训练模型在不同语言间具有良好的迁移能力，尤其是当预训练语言与目标任务语言相似时，能显著提升性能。数据多样性比数据规模对最终效果影响更大。

Abstract: Using representations provided by a large pre-trained model has become the primary strategy for achieving state-of-the-art results in a wide range of tasks. A recently proposed large pre-trained model, wav2vec 2.0, was seminal for several other works on pre-training large models on speech data. Many models are being pre-trained using the same architecture as wav2vec 2.0 and are getting state-of-the-art in various speech-related tasks. Previous work has demonstrated that the data used during the pre-training of these wav2vec2-based models can impact the model's performance in downstream tasks, and this should be taken into consideration before utilizing these models. However, few works have proposed investigating further how the transfer knowledge of these pre-trained models behaves in different languages, even when the target language differs from the one used during the model's pre-training. Our work aims to investigate the cross-lingual transferability of these wav2vec2-based models. We performed several fine-tuning experiments on the speech recognition task in 18 languages using 15 large pre-trained models. The results of our experiments showed us that the size of data used during the pre-training of these models is not as important to the final performance as the diversity. We noticed that the performance of Indo-European languages is superior to non-Indo-European languages in the evaluated models. We have observed a positive cross-lingual transfer of knowledge using monolingual models, which was evident in all the languages we used, but more pronounced when the language used during pre-training was more similar to the downstream task language. With these findings, we aim to assist the scientific community in utilizing existing wav2vec2-based pre-trained models, as well as facilitate the pre-training of new ones.

</details>


### [9] [Insight-A: Attribution-aware for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.21705)
*Junjie Wu,Yumeng Fu,Chen Gong,Guohong Fu*

Main category: cs.CL

TL;DR: 本文提出Insight-A，利用多模态大语言模型(MLLM)进行多模态虚假信息检测，重点在于追溯虚假信息的伪造源头，并通过分层推理减少人工提示的主观性，实现更精确的检测。


<details>
  <summary>Details</summary>
Motivation: 当前AIGC技术能生成多模态虚假信息，给社会安全带来威胁，而现有方法忽视了虚假信息的归因，缺乏对伪造源头的识别，亟需一种有效检测及归因方法。

Method: 提出Insight-A框架，包含两大核心步骤：一是通过跨归因提示（CAP）捕捉感知与推理间复杂关联，实现虚假信息伪造源追溯；二是采用自动归因去偏提示（ADP）减少人工标注提示的主观性，结合图像描述增强跨模态一致性检测。

Result: 大量实验证明Insight-A在多模态虚假信息检测任务中表现优越，能够有效检测与归因伪造信息，优于现有标准提示方法。

Conclusion: Insight-A为AIGC时代多模态虚假信息检测提供了新的范式，特别是在虚假信息归因与跨模态推理方面展现出强大能力，可助力社会安全防控。

Abstract: AI-generated content (AIGC) technology has emerged as a prevalent alternative to create multimodal misinformation on social media platforms, posing unprecedented threats to societal safety. However, standard prompting leverages multimodal large language models (MLLMs) to identify the emerging misinformation, which ignores the misinformation attribution. To this end, we present Insight-A, exploring attribution with MLLM insights for detecting multimodal misinformation. Insight-A makes two efforts: I) attribute misinformation to forgery sources, and II) an effective pipeline with hierarchical reasoning that detects distortions across modalities. Specifically, to attribute misinformation to forgery traces based on generation patterns, we devise cross-attribution prompting (CAP) to model the sophisticated correlations between perception and reasoning. Meanwhile, to reduce the subjectivity of human-annotated prompts, automatic attribution-debiased prompting (ADP) is used for task adaptation on MLLMs. Additionally, we design image captioning (IC) to achieve visual details for enhancing cross-modal consistency checking. Extensive experiments demonstrate the superiority of our proposal and provide a new paradigm for multimodal misinformation detection in the era of AIGC.

</details>


### [10] [A General Highly Accurate Online Planning Method Integrating Large Language Models into Nested Rollout Policy Adaptation for Dialogue Tasks](https://arxiv.org/abs/2511.21706)
*Hui Wang,Fafa Zhang,Xiaoyu Zhang,Chaoxu Mu*

Main category: cs.CL

TL;DR: 本文提出NRPA-GD方法，利用嵌套蒙特卡洛和策略自适应，结合大型语言模型模拟对话，实现高效目标导向对话策略规划。


<details>
  <summary>Details</summary>
Motivation: 现有目标导向对话方法依赖复杂的提示工程或难以适应新场景且成本高昂的预训练策略模型，亟需无需专门训练且灵活适应的策略规划方法。

Method: NRPA-GD通过构建对话轨迹评估机制，采用嵌套蒙特卡洛模拟和策略自适应框架，动态调整对话策略，完全依赖大型语言模型进行用户和系统行为模拟。

Result: 在四个典型目标导向对话数据集上，NRPA-GD表现优于现有提示工程和预训练模型方法，甚至以较小参数规模的LLM超越ChatGPT和预训练策略模型。

Conclusion: NRPA-GD通过利用大型语言模型同时模拟用户和系统行为，避免了专门模型训练，实现了对话策略的动态调整，显著提升了目标导向对话的效果，优于现有的提示工程和预训练模型方法。

Abstract: In goal-oriented dialogue tasks, the main challenge is to steer the interaction towards a given goal within a limited number of turns. Existing approaches either rely on elaborate prompt engineering, whose effectiveness is heavily dependent on human experience, or integrate policy networks and pre-trained policy models, which are usually difficult to adapt to new dialogue scenarios and costly to train. Therefore, in this paper, we present Nested Rollout Policy Adaptation for Goal-oriented Dialogue (NRPA-GD), a novel dialogue policy planning method that completely avoids specific model training by utilizing a Large Language Model (LLM) to simulate behaviors of user and system at the same time. Specifically, NRPA-GD constructs a complete evaluation mechanism for dialogue trajectories and employs an optimization framework of nested Monte Carlo simulation and policy self-adaptation to dynamically adjust policies during the dialogue process. The experimental results on four typical goal-oriented dialogue datasets show that NRPA-GD outperforms both existing prompt engineering and specifically pre-trained model-based methods. Impressively, NRPA-GD surpasses ChatGPT and pre-trained policy models with only a 0.6-billion-parameter LLM. The proposed approach further demonstrates the advantages and novelty of employing planning methods on LLMs to solve practical planning tasks.

</details>


### [11] [Lost in the Pipeline: How Well Do Large Language Models Handle Data Preparation?](https://arxiv.org/abs/2511.21708)
*Matteo Spreafico,Ludovica Tassini,Camilla Sancricca,Cinzia Cappiello*

Main category: cs.CL

TL;DR: 研究大型语言模型在数据准备自动化中的应用，比较其与传统工具的表现，并通过用户研究验证质量模型。


<details>
  <summary>Details</summary>
Motivation: 数据准备繁琐但关键，探索大型语言模型是否能高效辅助此过程。

Method: 使用一般和微调的表格大型语言模型，对低质量数据集进行数据分析和清洗任务，比较传统工具表现，开发并验证了质量评估模型。

Result: 发现大型语言模型在数据准备支持中表现良好，某些模型在特定任务中优于传统工具，用户研究表明符合实际需求。

Conclusion: 大型语言模型在数据准备任务中展示出支持和自动化的潜力，但效果受模型类型和任务复杂度影响。

Abstract: Large language models have recently demonstrated their exceptional capabilities in supporting and automating various tasks. Among the tasks worth exploring for testing large language model capabilities, we considered data preparation, a critical yet often labor-intensive step in data-driven processes. This paper investigates whether large language models can effectively support users in selecting and automating data preparation tasks. To this aim, we considered both general-purpose and fine-tuned tabular large language models. We prompted these models with poor-quality datasets and measured their ability to perform tasks such as data profiling and cleaning. We also compare the support provided by large language models with that offered by traditional data preparation tools. To evaluate the capabilities of large language models, we developed a custom-designed quality model that has been validated through a user study to gain insights into practitioners' expectations.

</details>


### [12] [Quantifying and Mitigating Selection Bias in LLMs: A Transferable LoRA Fine-Tuning and Efficient Majority Voting Approach](https://arxiv.org/abs/2511.21709)
*Blessed Guda,Lawrence Francis,Gabrial Zencha Ashungafac,Carlee Joe-Wong,Moise Busogi*

Main category: cs.CL

TL;DR: 本文针对大型语言模型在多选题中存在的选择性偏差问题，提出了新指标和算法来量化及消除偏差，有效提升模型表现与计算效率


<details>
  <summary>Details</summary>
Motivation: 现有多选题偏差度量多依赖答案标签且忽视预测一致性，消除偏差方法计算资源大或泛化能力差，亟需一种无标签有效且计算高效的解决方案

Method: 提出无监督无标签的排列偏差度量(PBM)、高效的批量问题上下文KV缓存多数投票方法(BaQCKV)、以及基于PBM和BaQCKV的无监督低秩适应(LoRA-1)微调策略

Result: 实验显示该方法在多个MCQ基准上有效降低选择性偏差，提高预测一致性和准确率，同时减少计算成本

Conclusion: 该研究提出的无监督度量和高效偏差消除方法为解决大型语言模型多项选择题偏差问题提供了一种有效且计算负担较低的方案

Abstract: Multiple Choice Question (MCQ) answering is a widely used method for evaluating the performance of Large Language Models (LLMs). However, LLMs often exhibit selection bias in MCQ tasks, where their choices are influenced by factors like answer position or option symbols rather than the content. This bias undermines the reliability of MCQ as an evaluation framework. Most existing selection bias metrics require answer labels and measure divergences between prediction and answer distributions, but do not fully capture the consistency of a model's predictions across different orderings of answer choices. Existing selection bias mitigation strategies have notable limitations: majority voting, though effective, is computationally prohibitive; calibration-based methods require validation sets and often fail to generalize across datasets. To address these gaps, we propose three key contributions: (1) a new unsupervised label-free Permutation Bias Metric (PBM) that directly quantifies inconsistencies in model predictions across answer permutations, providing a more precise measure of selection bias, (2) an efficient majority voting approach called Batch Question-Context KV caching (BaQCKV), to significantly reduce computational costs while preserving bias mitigation effectiveness, and (3) an unsupervised Low-Rank Adaptation (LoRA-1) fine-tuning strategy based on our proposed metric and the BaQCKV that mitigates selection bias, providing a computationally efficient alternative that maintains model generalizability. Experiments across multiple MCQ benchmarks demonstrate that our approaches reduce bias, increasing consistency in accuracy while minimizing computational costs.

</details>


### [13] [Addressing Stereotypes in Large Language Models: A Critical Examination and Mitigation](https://arxiv.org/abs/2511.21711)
*Fatima Kazi*

Main category: cs.CL

TL;DR: 本研究评估并缓解大型语言模型中的偏见，采用多方法提升模型对隐性偏见的识别能力，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 语言模型继承训练数据中的多种社会文化偏见，需全面检测与缓解以确保公平和减少有害误导。

Method: 采用StereoSet和CrowSPairs偏见专项基准，结合三管齐下的检测策略，利用微调、提示工程及数据增强提升模型的偏见识别与减轻能力。

Result: 研究利用StereoSet和CrowSPairs基准评测BERT、GPT 3.5和ADA等多种语言生成模型中的显性与隐性偏见，发现微调模型在性别偏见上表现较差，但在避免种族偏见方面表现较好。进一步通过微调、不同提示技术及数据增强提升模型性能，在跨数据集测试和隐性偏见检测上性能提升最高达20%。

Conclusion: 大型语言模型存在显性和隐性偏见，尤其在性别偏见方面仍有不足，且模型过度依赖关键词而非深入理解。通过综合微调与数据增强方法能显著提升模型在偏见检测上的表现。

Abstract: Large Language models (LLMs), such as ChatGPT, have gained popularity in recent years with the advancement of Natural Language Processing (NLP), with use cases spanning many disciplines and daily lives as well. LLMs inherit explicit and implicit biases from the datasets they were trained on; these biases can include social, ethical, cultural, religious, and other prejudices and stereotypes. It is important to comprehensively examine such shortcomings by identifying the existence and extent of such biases, recognizing the origin, and attempting to mitigate such biased outputs to ensure fair outputs to reduce harmful stereotypes and misinformation. This study inspects and highlights the need to address biases in LLMs amid growing generative Artificial Intelligence (AI). We utilize bias-specific benchmarks such StereoSet and CrowSPairs to evaluate the existence of various biases in many different generative models such as BERT, GPT 3.5, and ADA. To detect both explicit and implicit biases, we adopt a three-pronged approach for thorough and inclusive analysis. Results indicate fine-tuned models struggle with gender biases but excel at identifying and avoiding racial biases. Our findings also illustrated that despite some cases of success, LLMs often over-rely on keywords in prompts and its outputs. This demonstrates the incapability of LLMs to attempt to truly understand the accuracy and authenticity of its outputs. Finally, in an attempt to bolster model performance, we applied an enhancement learning strategy involving fine-tuning, models using different prompting techniques, and data augmentation of the bias benchmarks. We found fine-tuned models to exhibit promising adaptability during cross-dataset testing and significantly enhanced performance on implicit bias benchmarks, with performance gains of up to 20%.

</details>


### [14] [EulerESG: Automating ESG Disclosure Analysis with LLMs](https://arxiv.org/abs/2511.21712)
*Yi Ding,Xushuo Tang,Zhengyi Yang,Wenqian Zhang,Simin Wu,Yuxin Huang,Lingjing Lan,Weiyuan Li,Yin Chen,Mingchen Ju,Wenke Yang,Thong Hoang,Mykhailo Klymenko,Xiwei Zu,Wenjie Zhang*

Main category: cs.CL

TL;DR: EulerESG利用大语言模型自动解析ESG报告，实现高准确率的指标提取和交互式分析工具，提升ESG信息的系统化利用。


<details>
  <summary>Details</summary>
Motivation: ESG报告主要以长且异质的PDF形式发布，难以系统化回答关键问题，现有工具依赖脆弱规则或泛文本处理，缺乏对ESG标准的显式模型，亟需更智能的自动化分析方法。

Method: 基于大语言模型(LLM)，开发了EulerESG系统，结合双通道检索和LLM驱动的ESG披露分析，同时提供交互式仪表盘和聊天机器人进行探索、基准测试和解释。

Result: EulerESG能够自动填充与标准对齐的ESG指标表，准确率高达0.95，且在全流程运行时间内保持实用性。

Conclusion: EulerESG展示了将大语言模型应用于ESG报告自动分析的有效性和实用性，提升了信息提取的精准度和交互性。

Abstract: Environmental, Social, and Governance (ESG) reports have become central to how companies communicate climate risk, social impact, and governance practices, yet they are still published primarily as long, heterogeneous PDF documents. This makes it difficult to systematically answer seemingly simple questions. Existing tools either rely on brittle rule-based extraction or treat ESG reports as generic text, without explicitly modelling the underlying reporting standards. We present \textbf{EulerESG}, an LLM-powered system for automating ESG disclosure analysis with explicit awareness of ESG frameworks. EulerESG combines (i) dual-channel retrieval and LLM-driven disclosure analysis over ESG reports, and (ii) an interactive dashboard and chatbot for exploration, benchmarking, and explanation. Using four globally recognised companies and twelve SASB sub-industries, we show that EulerESG can automatically populate standard-aligned metric tables with high fidelity (up to 0.95 average accuracy) while remaining practical in end-to-end runtime, and we compare several recent LLM models in this setting. The full implementation, together with a demonstration video, is publicly available at https://github.com/UNSW-database/EulerESG.

</details>


### [15] [GPS: General Per-Sample Prompter](https://arxiv.org/abs/2511.21714)
*Pawel Batorski,Paul Swoboda*

Main category: cs.CL

TL;DR: 本文提出GPS，一种无需任务调优的输入级自适应提示生成方法，显著提升多任务性能，简化提示设计流程。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的性能高度依赖提示词的设计，手动设计高效提示耗时且困难，现有自动提示方法依赖大规模数据和耗时优化，且通常只能生成单一任务级提示，缺乏对单个输入的适应性。

Method: 提出GPS方法，无需针对特定任务调优，通过强化学习训练的通用提示生成器为每个输入样本生成个性化提示，同时引入正则化机制支持每样本提示、自适应生成，并采用最小贝叶斯风险解码稳定推理结果。

Result: GPS在多个任务上表现出竞争力，未在测试任务上训练却在文本简化、摘要和分类任务中取得第二或第三的成绩；在领域内提示上于GSM8K数据集达到最新状态。

Conclusion: GPS展示了一种无需任务特定训练集和长时间优化即可自动生成自适应输入级提示的有效新范式，极大提升了提示设计效率和模型性能的适应性。

Abstract: LLMs are sensitive to prompting, with task performance often hinging on subtle, sometimes imperceptible variations in phrasing. As a result, crafting effective prompts manually remains challenging and time-consuming. Recent automatic prompting methods mitigate this difficulty but face three key limitations: (i) for each new task, they require large datasets to train good prompts;(ii) they rely on costly optimization loops that may take hours; (iii)they typically produce a single task-level prompt that does not adapt to the individual input problem to be solved.
  We propose GPS, the first general-purpose, per-sample prompting method. Without any task-specific tuning, GPS generates a tailored prompt for each unseen input, improving performance across diverse tasks. The prompter is trained with reinforcement learning on a suite of training tasks and includes a novel regularization for effectively adapting to per-sample prompting. Finally, we employ Minimum Bayes Risk decoding to stabilize inference.
  Empirically, GPS demonstrates competitive performance: we attain second best results among baselines on text simplification, third best results on summarization and on-par results on classification, while not training on any of these tasks, in contrast to the baselines. For in-domain prompting, we obtain sota on GSM8K. Our work shows the potential of a novel and effective paradigm for automatic prompting: generating adaptive, input-specific prompts without extensive optimization and without access to a task-specific training set. Our code is available at https://github.com/Batorskq/GPS.

</details>


### [16] [An Optimized Machine Learning Classifier for Detecting Fake Reviews Using Extracted Features](https://arxiv.org/abs/2511.21716)
*Shabbir Anees,Anshuman,Ayush Chaurasia,Prathmesh Bogar*

Main category: cs.CL

TL;DR: 本研究提出一种结合高级特征选择与集成学习的机器学习系统，高效精准地识别计算机生成的评论文本，并强调隐私保护的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于虚假评论特别是由人工智能生成的评论威胁了在线购物的可信度，开发高效精确的检测方法至关重要。

Method: 结合先进的文本预处理、多模态特征提取、Harris Hawks优化算法（HHO）用于特征选择，以及堆叠集成分类器构建机器学习系统

Result: 在一个包含40,432条原始和计算机生成评论的数据集上，HHO从13,539个特征中选出1,368个特征，实现了89.9%的维度压缩；最终模型达到了95.40%的准确率、92.81%的精确率、95.01%的召回率及93.90%的F1分数

Conclusion: 集成学习与生物启发式优化相结合的方法对识别计算机生成文本非常有效，同时在大规模云平台评论分析中应采用保护隐私的技术以保障用户数据安全

Abstract: It is well known that fraudulent reviews cast doubt on the legitimacy and dependability of online purchases. The most recent development that leads customers towards darkness is the appearance of human reviews in computer-generated (CG) ones. In this work, we present an advanced machine-learning-based system that analyses these reviews produced by AI with remarkable precision. Our method integrates advanced text preprocessing, multi-modal feature extraction, Harris Hawks Optimization (HHO) for feature selection, and a stacking ensemble classifier. We implemented this methodology on a public dataset of 40,432 Original (OR) and Computer-Generated (CG) reviews. From an initial set of 13,539 features, HHO selected the most applicable 1,368 features, achieving an 89.9% dimensionality reduction. Our final stacking model achieved 95.40% accuracy, 92.81% precision, 95.01% recall, and a 93.90% F1-Score, which demonstrates that the combination of ensemble learning and bio-inspired optimisation is an effective method for machine-generated text recognition. Because large-scale review analytics commonly run on cloud platforms, privacy-preserving techniques such as differential approaches and secure outsourcing are essential to protect user data in these systems.

</details>


### [17] [CrossCheck-Bench: Diagnosing Compositional Failures in Multimodal Conflict Resolution](https://arxiv.org/abs/2511.21717)
*Baoliang Tian,Yuxuan Si,Jilong Wang,Lingyao Li,Zhongyuan Bao,Zineng Zhou,Tao Wang,Sixu Li,Ziyao Xu,Mingze Wang,Zhouzhuo Zhang,Zhihao Wang,Yike Yun,Ke Tian,Ning Yang,Minghui Qiu*

Main category: cs.CL

TL;DR: 本文提出了CrossCheck-Bench，这是一个用于评估多模态输入中矛盾检测的诊断基准，涵盖三个推理复杂度级别和七个关键能力。通过对13个先进视觉语言模型的测试，发现它们在复杂推理任务中表现不足，传统提示策略提升有限，而结合符号推理的方法效果更佳。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要依赖对齐的图文对训练，缺乏对现实世界矛盾检测与解决能力的深入研究，而开放域应用中图文信息常存在冲突，要求模型进行结构化推理。

Method: 构建包含1.5万个带有合成矛盾的真实世界样本的基准数据集，设计三个层次的推理复杂度和七个关键能力，采用多阶段人工注释保证语义有效性和难度校准；评估13个先进模型并分析其能力表现，探究不同提示策略和融合符号推理的方法。

Result: 模型在感知匹配任务上表现较好，但在需要综合多线索进行冲突推理时性能显著下降；多步骤推理和规则验证能力欠缺；传统提示方法提升有限，而符号推理与视觉处理结合的方法带来更稳定的改进。

Conclusion: 多模态推理仍面临显著瓶颈，特别是在跨模态矛盾检测任务上，未来应注重结合符号推理以增强模型的多模态验证能力。

Abstract: Multimodal Large Language Models are primarily trained and evaluated on aligned image-text pairs, which leaves their ability to detect and resolve real-world inconsistencies largely unexplored. In open-domain applications visual and textual cues often conflict, requiring models to perform structured reasoning beyond surface-level alignment. We introduce CrossCheck-Bench, a diagnostic benchmark for evaluating contradiction detection in multimodal inputs. The benchmark adopts a hierarchical task framework covering three levels of reasoning complexity and defines seven atomic capabilities essential for resolving cross-modal inconsistencies. CrossCheck-Bench includes 15k question-answer pairs sourced from real-world artifacts with synthetically injected contradictions. The dataset is constructed through a multi-stage annotation pipeline involving more than 450 expert hours to ensure semantic validity and calibrated difficulty across perception, integration, and reasoning. We evaluate 13 state-of-the-art vision-language models and observe a consistent performance drop as tasks shift from perceptual matching to logical contradiction detection. Most models perform well on isolated entity recognition but fail when multiple clues must be synthesized for conflict reasoning. Capability-level analysis further reveals uneven skill acquisition, especially in tasks requiring multi-step inference or rule-based validation. Additional probing shows that conventional prompting strategies such as Chain-of-Thought and Set-of-Mark yield only marginal gains. By contrast, methods that interleave symbolic reasoning with grounded visual processing achieve more stable improvements. These results highlight a persistent bottleneck in multimodal reasoning and suggest new directions for building models capable of robust cross-modal verification.

</details>


### [18] [When Harmless Words Harm: A New Threat to LLM Safety via Conceptual Triggers](https://arxiv.org/abs/2511.21718)
*Zhaoxin Zhang,Borui Chen,Yiming Hu,Youyang Qu,Tianqing Zhu,Longxiang Gao*

Main category: cs.CL

TL;DR: 本文提出了一种新颖抽象价值结构越狱方法MICM，能有效绕过现有安全机制，揭示了LLM潜在的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 现有LLM越狱研究聚焦显性有害内容绕过，忽视了通过模型抽象泛化能力操控隐含社会价值的隐蔽攻击，形成安全防护盲点。

Method: 提出了MICM，一种利用概念形态学理论，通过预定义短语组合成固定提示模板，针对大型语言模型（LLM）中隐含社会价值结构的模型无关越狱攻击方法。

Result: MICM在包括GPT-4o、Deepseek-R1和Qwen3-8B等五个先进LLM中表现出高成功率且拒绝率低，显著优于现有越狱技术。

Conclusion: 当前商用LLM的安全机制在隐性价值观操控面前存在关键漏洞，传统安全防护不足以防范此类抽象价值操控攻击。

Abstract: Recent research on large language model (LLM) jailbreaks has primarily focused on techniques that bypass safety mechanisms to elicit overtly harmful outputs. However, such efforts often overlook attacks that exploit the model's capacity for abstract generalization, creating a critical blind spot in current alignment strategies. This gap enables adversaries to induce objectionable content by subtly manipulating the implicit social values embedded in model outputs. In this paper, we introduce MICM, a novel, model-agnostic jailbreak method that targets the aggregate value structure reflected in LLM responses. Drawing on conceptual morphology theory, MICM encodes specific configurations of nuanced concepts into a fixed prompt template through a predefined set of phrases. These phrases act as conceptual triggers, steering model outputs toward a specific value stance without triggering conventional safety filters. We evaluate MICM across five advanced LLMs, including GPT-4o, Deepseek-R1, and Qwen3-8B. Experimental results show that MICM consistently outperforms state-of-the-art jailbreak techniques, achieving high success rates with minimal rejection. Our findings reveal a critical vulnerability in commercial LLMs: their safety mechanisms remain susceptible to covert manipulation of underlying value alignment.

</details>


### [19] [PeerCoPilot: A Language Model-Powered Assistant for Behavioral Health Organizations](https://arxiv.org/abs/2511.21721)
*Gao Mo,Naveen Raman,Megan Chai,Cindy Peng,Shannon Pagdon,Nev Jones,Hong Shen,Peggy Swarbrick,Fei Fang*

Main category: cs.CL

TL;DR: 本文介绍了PeerCoPilot，一款基于大型语言模型的辅助工具，帮助同伴支持提供者制定健康计划并查找资源，提升行为健康服务的效率和信息可靠性。


<details>
  <summary>Details</summary>
Motivation: 受限的资金和人员使行为健康组织难以满足所有服务用户的需求，亟需辅助工具提升同伴支持者的工作效率和服务质量。

Method: 开发了基于大型语言模型的PeerCoPilot助手，结合检索增强生成技术，利用1,300多个经审核的资源数据库，为同伴支持者创建个性化健康计划和具体目标。

Result: 通过15名同伴支持者和6名服务用户的人类评估，超过90%的用户支持PeerCoPilot的使用，且其提供的信息比基线语言模型更可靠具体。

Conclusion: PeerCoPilot已在大型行为健康机构CSPNJ推广应用，显著辅助同伴支持者更好地服务超过10,000名用户，并计划继续扩大使用范围。

Abstract: Behavioral health conditions, which include mental health and substance use disorders, are the leading disease burden in the United States. Peer-run behavioral health organizations (PROs) critically assist individuals facing these conditions by combining mental health services with assistance for needs such as income, employment, and housing. However, limited funds and staffing make it difficult for PROs to address all service user needs. To assist peer providers at PROs with their day-to-day tasks, we introduce PeerCoPilot, a large language model (LLM)-powered assistant that helps peer providers create wellness plans, construct step-by-step goals, and locate organizational resources to support these goals. PeerCoPilot ensures information reliability through a retrieval-augmented generation pipeline backed by a large database of over 1,300 vetted resources. We conducted human evaluations with 15 peer providers and 6 service users and found that over 90% of users supported using PeerCoPilot. Moreover, we demonstrated that PeerCoPilot provides more reliable and specific information than a baseline LLM. PeerCoPilot is now used by a group of 5-10 peer providers at CSPNJ, a large behavioral health organization serving over 10,000 service users, and we are actively expanding PeerCoPilot's use.

</details>


### [20] [German General Personas: A Survey-Derived Persona Prompt Collection for Population-Aligned LLM Studies](https://arxiv.org/abs/2511.21722)
*Jens Rupprecht,Leon Fröhling,Claudia Wagner,Markus Strohmaier*

Main category: cs.CL

TL;DR: 该论文介绍了一个基于德国社会调查数据构建的通用人物集GGP，用于指导大语言模型生成更贴近真实人口的模拟回应。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通过人物提示模拟人类视角，但缺乏经过实证验证且代表性强的人物集合，导致模拟准确性和代表性不足。

Method: 基于德国通用社会调查（ALLBUS）数据，构建了德国通用人物集（GGP）及对应的人物提示，可无缝应用于各种大语言模型，指导模型生成与德国人口特征一致的回答。

Result: 通过让多种大语言模型模拟调查回应，GGP引导的模型表现优于最新分类器，尤其在数据稀缺情况下效果更佳。并分析了人物提示的代表性和属性选择对模型表现的影响。

Conclusion: GGP是大语言模型社会模拟研究中的有价值资源，有助于更系统地探索与真实人口对齐的人物提示方法，推动自然语言处理和社会科学研究的发展。

Abstract: The use of Large Language Models (LLMs) for simulating human perspectives via persona prompting is gaining traction in computational social science. However, well-curated, empirically grounded persona collections remain scarce, limiting the accuracy and representativeness of such simulations. Here we introduce the German General Personas (GGP) collection, a comprehensive and representative persona prompt collection built from the German General Social Survey (ALLBUS). The GGP and its persona prompts are designed to be easily plugged into prompts for all types of LLMs and tasks, steering models to generate responses aligned with the underlying German population. We evaluate GGP by prompting various LLMs to simulate survey response distributions across diverse topics, demonstrating that GGP-guided LLMs outperform state-of-the-art classifiers, particularly under data scarcity. Furthermore, we analyze how the representativity and attribute selection within persona prompts affect alignment with population responses. Our findings suggest that GGP provides a potentially valuable resource for research on LLM-based social simulations that enables more systematic explorations of population-aligned persona prompting in NLP and social science research.

</details>


### [21] [AD-CDO: A Lightweight Ontology for Representing Eligibility Criteria in Alzheimer's Disease Clinical Trials](https://arxiv.org/abs/2511.21724)
*Zenan Sun,Rashmie Abeysinghe,Xiaojin Li,Xinyue Hu,Licong Cui,Guo-Qiang Zhang,Jiang Bian,Cui Tao*

Main category: cs.CL

TL;DR: 提出了轻量级的阿尔茨海默病临床试验通用数据元素本体AD-CDO，实现关键入选标准的标准化表示，支持多种应用场景。


<details>
  <summary>Details</summary>
Motivation: 针对阿尔茨海默病临床试验中入选标准概念繁杂且缺乏统一表达的问题，设计一个轻量且语义丰富的本体以标准化表达。

Method: 从1500多个阿尔茨海默病临床试验中提取高频概念，分类为七大语义类别，结合多种标准生物医学词汇表注释，利用Jenks自然断点法筛选代表性概念。

Result: 构建的AD-CDO覆盖超过63%的提取概念，兼具可解释性和紧凑性。通过两个实际案例验证了其实用性，包括基于本体的临床试验模拟和临床文本实体标准化。

Conclusion: AD-CDO通过统一阿尔茨海默病临床试验中关键的入选标准实体，并与标准化词汇对齐，为基于本体的阿尔茨海默病临床试验研究提供了多功能基础。

Abstract: Objective
  This study introduces the Alzheimer's Disease Common Data Element Ontology for Clinical Trials (AD-CDO), a lightweight, semantically enriched ontology designed to represent and standardize key eligibility criteria concepts in Alzheimer's disease (AD) clinical trials.
  Materials and Methods
  We extracted high-frequency concepts from more than 1,500 AD clinical trials on ClinicalTrials.gov and organized them into seven semantic categories: Disease, Medication, Diagnostic Test, Procedure, Social Determinants of Health, Rating Criteria, and Fertility. Each concept was annotated with standard biomedical vocabularies, including the UMLS, OMOP Standardized Vocabularies, DrugBank, NDC, and NLM VSAC value sets. To balance coverage and manageability, we applied the Jenks Natural Breaks method to identify an optimal set of representative concepts.
  Results
  The optimized AD-CDO achieved over 63% coverage of extracted trial concepts while maintaining interpretability and compactness. The ontology effectively captured the most frequent and clinically meaningful entities used in AD eligibility criteria. We demonstrated AD-CDO's practical utility through two use cases: (a) an ontology-driven trial simulation system for formal modeling and virtual execution of clinical trials, and (b) an entity normalization task mapping raw clinical text to ontology-aligned terms, enabling consistency and integration with EHR data.
  Discussion
  AD-CDO bridges the gap between broad biomedical ontologies and task-specific trial modeling needs. It supports multiple downstream applications, including phenotyping algorithm development, cohort identification, and structured data integration.
  Conclusion
  By harmonizing essential eligibility entities and aligning them with standardized vocabularies, AD-CDO provides a versatile foundation for ontology-driven AD clinical trial research.

</details>


### [22] [PromptTailor: Multi-turn Intent-Aligned Prompt Synthesis for Lightweight LLMs](https://arxiv.org/abs/2511.21725)
*Yizhou Xu,Janet Davis*

Main category: cs.CL

TL;DR: PromptTailor通过意图对齐的提示生成，利用轻量化微调的Llama3-8B模型显著提升轻量级语言模型的开放式生成质量，且效率更高。


<details>
  <summary>Details</summary>
Motivation: 轻量级语言模型适合设备端和隐私敏感场景，但生成质量极易受提示质量影响。非专业用户缺乏设计高质量提示的能力，现有提示优化工具难以保证优化后的提示符合用户原始意图，因而需要一种可控且高效的提示优化方法。

Method: 提出PromptTailor系统，通过使用一个基于LoRA适配器微调的量化Llama3-8B模型，在12,300条跨41个领域的提示改进对话上进行训练，实现意图对齐的可控提示生成。该适配器可附加至任意Llama3-8B基础模型，用于边缘部署。

Result: 在人工评估和大型语言模型评判中，PromptTailor在多个目标模型及优化基线下表现优于链式思考提示，且与最先进的提示优化方法相匹配或超越，同时调用模型次数较少（例如3次对比9次）。

Conclusion: 紧凑的学生模型在强大教师模型的指导下能学会有效的提示生成策略，提升模型响应质量，并保持与用户意图的对齐。

Abstract: Lightweight language models remain attractive for on-device and privacy-sensitive applications, but their responses are highly sensitive to prompt quality. For open-ended generation, non-expert users often lack the knowledge or time to consistently craft high-quality prompts, leading them to rely on prompt optimization tools. However, a key challenge is ensuring the optimized prompts genuinely align with users' original intents and preferences. We introduce PromptTailor, a system for controllable prompt generation for open-ended text that improves model output quality by intent-aligned prompt synthesis. PromptTailor expands minimal user instructions into rich, domain-aware prompts while preserving the user's stated preferences. The system is a quantized Llama3-8B model fine-tuned with a lightweight LoRA adapter on 12,300 prompt-refinement dialogues spanning 41 everyday domains, distilled from three stronger LLMs. The adapter attaches to any Llama3-8B base, enabling edge deployment. In human and LLM-judge evaluations across multiple target models and optimization baselines, PromptTailor yields higher preference rates than chain-of-thought prompting and matches or surpasses state-of-the-art prompt optimization methods while requiring fewer model calls (e.g., 3 vs. 9). These results show that a compact student, guided by powerful teachers, can learn effective prompt-generation strategies that enhance response quality while maintaining alignment with user intent.

</details>


### [23] [Goal-Directed Search Outperforms Goal-Agnostic Memory Compression in Long-Context Memory Tasks](https://arxiv.org/abs/2511.21726)
*Yicong Zheng,Kevin L. McKee,Thomas Miconi,Zacharie Bugaud,Mick van Gelderen,Jed McCaleb*

Main category: cs.CL

TL;DR: 本文提出SUMER，一种基于强化学习的无压缩记忆搜索方法，突破传统压缩记忆限制，在长上下文任务中获得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前长时记忆模型普遍依赖压缩算法，带入人类偏见且难以泛化，作者希望探索在无压缩条件下通过搜索实现更优性能。

Method: 采用端到端可验证奖励的强化学习智能体（RLVR）结合搜索工具，从原始长上下文数据中检索信息回答目标问题。

Result: 在LoCoMo长上下文对话数据集上，采用Qwen2.5-7B-Instruct的SUMER比所有现有压缩记忆方法和全上下文基线表现更优，性能提升43%，实现SOTA水平。

Conclusion: SUMER通过端到端强化学习智能体实现了在非压缩记忆中搜索信息，显著优于传统的压缩记忆方法，开辟了更通用且动态可扩展的长时记忆建模新范式。

Abstract: How to enable human-like long-term memory in large language models (LLMs) has been a central question for unlocking more general capabilities such as few-shot generalization. Existing memory frameworks and benchmarks focus on finding the optimal memory compression algorithm for higher performance in tasks that require recollection and sometimes further reasoning. However, such efforts have ended up building more human bias into the compression algorithm, through the search for the best prompts and memory architectures that suit specific benchmarks, rather than finding a general solution that would work on other data distributions. On the other hand, goal-directed search on uncompressed information could potentially exhibit superior performance because compression is lossy, and a predefined compression algorithm will not fit all raw data distributions. Here we present SUMER (Search in Uncompressed Memory via Experience Replay), an end-to-end reinforcement learning agent with verifiable reward (RLVR) that learns to use search tools to gather information and answer a target question. On the LoCoMo dataset for long-context conversation understanding, SUMER with Qwen2.5-7B-Instruct learned to use search tools and outperformed all other biased memory compression approaches and also the full-context baseline, reaching SOTA performance (43% gain over the prior best). We demonstrate that a simple search method applied to raw data outperforms goal-agnostic and biased compression algorithms in current long-context memory tasks, arguing for new paradigms and benchmarks that are more dynamic and autonomously scalable. Code for SUMER and all implemented baselines is publicly available at https://github.com/zycyc/SUMER.

</details>


### [24] [Affective Multimodal Agents with Proactive Knowledge Grounding for Emotionally Aligned Marketing Dialogue](https://arxiv.org/abs/2511.21728)
*Lin Yu,Xiaofei Han,Yifei Kang,Chiung-Yi Tseng,Danyang Zhang,Ziqian Bi,Zhimo Han*

Main category: cs.CL

TL;DR: AffectMind通过多模态情感推理和主动知识更新，实现了在营销对话中更高的情绪一致性和劝服效果，显著提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽流畅但大多被动，难以胜任情感丰富且目标导向的场景，如营销对话，需新方法实现主动情感推理与知识动态更新。

Method: 提出 AffectMind 多模态情感对话代理，该系统包括主动知识更新网络（PKGN）、情绪意图对齐模型（EIAM）和强化话语循环（RDL），结合文本、视觉和韵律信息进行情感和事实内容的动态推理与更新，通过联合情绪与购买意图建模来调整劝服策略，并利用用户反馈进行情绪连贯性和参与度的强化优化。

Result: 在两个新构建的营销对话数据集MM-ConvMarket和AffectPromo上，AffectMind在情绪一致性提升了26%，劝服成功率提升了19%，长期用户参与度提升了23%，均优于现有基于大语言模型的强基线。

Conclusion: 表现出基于情绪的主动推理与动态知识更新是商业多模态对话代理取得成功的关键能力。

Abstract: Recent advances in large language models (LLMs) have enabled fluent dialogue systems, but most remain reactive and struggle in emotionally rich, goal-oriented settings such as marketing conversations. To address this limitation, we propose AffectMind, a multimodal affective dialogue agent that performs proactive reasoning and dynamic knowledge grounding to sustain emotionally aligned and persuasive interactions. AffectMind combines three components: a Proactive Knowledge Grounding Network (PKGN) that continuously updates factual and affective context from text, vision, and prosody; an Emotion--Intent Alignment Model (EIAM) that jointly models user emotion and purchase intent to adapt persuasion strategies; and a Reinforced Discourse Loop (RDL) that optimizes emotional coherence and engagement via reinforcement signals from user responses. Experiments on two newly curated marketing dialogue datasets, MM-ConvMarket and AffectPromo, show that AffectMind outperforms strong LLM-based baselines in emotional consistency (+26\%), persuasive success rate (+19\%), and long-term user engagement (+23\%), highlighting emotion-grounded proactivity as a key capability for commercial multimodal agents.

</details>


### [25] [Beyond Component Strength: Synergistic Integration and Adaptive Calibration in Multi-Agent RAG Systems](https://arxiv.org/abs/2511.21729)
*Jithin Krishnan*

Main category: cs.CL

TL;DR: 本研究通过消融研究展示了多组件综合应用显著提升了RAG系统性能，强调了组件协同、标准化评估和自适应校准的重要性


<details>
  <summary>Details</summary>
Motivation: 提升检索增强生成系统的可靠性需要理解各个组件的交互作用，单靠增强单个组件不足以有效提升系统表现

Method: 通过对50个查询（包括15个可回答的，10个边缘案例和25个对抗性案例）进行消融研究，评估混合检索、集成验证和自适应阈值调整等改进的效果

Result: 单独使用这些改进几乎没有收益，但结合使用时，拒答率从40%降至2%，减少95%，且没有增加虚假信息的发生

Conclusion: 组件的协同整合比单个组件的强度更重要，统一的评估指标和标签对性能解读至关重要，自适应校准能防止在高质量检索下的过度自信回答

Abstract: Building reliable retrieval-augmented generation (RAG) systems requires more than adding powerful components; it requires understanding how they interact. Using ablation studies on 50 queries (15 answerable, 10 edge cases, and 25 adversarial), we show that enhancements such as hybrid retrieval, ensemble verification, and adaptive thresholding provide almost no benefit when used in isolation, yet together achieve a 95% reduction in abstention (from 40% to 2%) without increasing hallucinations. We also identify a measurement challenge: different verification strategies can behave safely but assign inconsistent labels (for example, "abstained" versus "unsupported"), creating apparent hallucination rates that are actually artifacts of labeling. Our results show that synergistic integration matters more than the strength of any single component, that standardized metrics and labels are essential for correctly interpreting performance, and that adaptive calibration is needed to prevent overconfident over-answering even when retrieval quality is high.

</details>


### [26] [A Benchmark for Procedural Memory Retrieval in Language Agents](https://arxiv.org/abs/2511.21730)
*Ishant Kohar,Aswanth Krishnan*

Main category: cs.CL

TL;DR: 本文提出了第一个用于评估AI代理程序记忆检索能力的基准，揭示了现有方法在面对新颖任务时的泛化瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理在熟悉环境表现良好，但面对包含新词汇的新任务时性能显著下降，暴露了程序记忆系统的核心限制。

Method: 基于ALFWorld构建专家和大模型生成的轨迹语料库，使用六种检索方法和系统化分层查询对程序记忆检索进行评估。

Result: 基于嵌入的方法在熟悉任务中表现优异，但面对新任务时下降显著；而LLM生成的程序抽象能可靠地跨上下文迁移。去除实验表明嵌入方法忽略时间结构，仅捕获词汇级抽象。扩大语料库规模比丰富表示提升更大，暗示当前编码器架构存在天花板。

Conclusion: 该基准首次实现了真正的程序理解与表层记忆的分离，为开发具备稳健泛化能力的检索系统提供了诊断框架和工具。

Abstract: Current AI agents excel in familiar settings, but fail sharply when faced with novel tasks with unseen vocabularies -- a core limitation of procedural memory systems. We present the first benchmark that isolates procedural memory retrieval from task execution, evaluating whether agents can recognize functionally equivalent procedures that span different object instantiations. Using ALFWorld, we construct dual corpora of expert and LLM-generated trajectories and evaluate six retrieval methods using systematically stratified queries. Our results expose a clear generalization cliff: embedding-based methods perform strongly on familiar contexts, yet degrade considerably on novel ones, while LLM-generated procedural abstractions demonstrate reliable cross-context transfer. Controlled ablations show that although embeddings capture some lexical-level abstraction, they fundamentally treat procedures as unordered bags of words, discarding temporal structure necessary for cross-context transfer. Corpus scale delivers far larger gains than representation enrichment, revealing an architectural ceiling in current encoders. Our benchmark offers the first diagnostic framework separating genuine procedural understanding from surface-level memorization and gives tools for developing retrieval systems capable of dependable generalization. Resources available at our GitHub repository (https://github.com/qpiai/Proced_mem_bench).

</details>


### [27] [Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition](https://arxiv.org/abs/2511.21731)
*Diederik Aerts,Jonito Aerts Arguëlles,Lester Beltran,Suzette Geriente,Roberto Leporini,Massimiliano Sassoli de Bianchi,Sandro Sozzo*

Main category: cs.CL

TL;DR: 研究发现，LLMs在概念组合和词语分布中显示出量子结构特征，类似人类认知，揭示认知语言领域量子组织的普遍存在。


<details>
  <summary>Details</summary>
Motivation: 探索人类和人工智能认知系统在语言和概念处理中的机制，理解是否存在类似量子结构的组织规律。

Method: 利用ChatGPT和Gemini执行认知测试，包括检验Bell不等式和分析词语分布统计特征，比较量子统计与经典统计。

Result: 结果显示Bell不等式显著被违背，存在量子纠缠；词语分布符合玻色-爱因斯坦统计而非麦克斯韦-玻尔兹曼统计，这些结果与人类认知和大语料信息检索的实验一致。

Conclusion: 本文通过对大语言模型（LLMs）执行认知测试，发现概念组合中存在量子纠缠和玻色-爱因斯坦统计等量子结构，表明无论是人类还是人工智能，认知语言领域均呈现量子结构的系统性出现。

Abstract: We present the results of cognitive tests on conceptual combinations, performed using specific Large Language Models (LLMs) as test subjects. In the first test, performed with ChatGPT and Gemini, we show that Bell's inequalities are significantly violated, which indicates the presence of 'quantum entanglement' in the tested concepts. In the second test, also performed using ChatGPT and Gemini, we instead identify the presence of 'Bose-Einstein statistics', rather than the intuitively expected 'Maxwell-Boltzmann statistics', in the distribution of the words contained in large-size texts. Interestingly, these findings mirror the results previously obtained in both cognitive tests with human participants and information retrieval tests on large corpora. Taken together, they point to the 'systematic emergence of quantum structures in conceptual-linguistic domains', regardless of whether the cognitive agent is human or artificial. Although LLMs are classified as neural networks for historical reasons, we believe that a more essential form of knowledge organization takes place in the distributive semantic structure of vector spaces built on top of the neural network. It is this meaning-bearing structure that lends itself to a phenomenon of evolutionary convergence between human cognition and language, slowly established through biological evolution, and LLM cognition and language, emerging much more rapidly as a result of self-learning and training. We analyze various aspects and examples that contain evidence supporting the above hypothesis. We also advance a unifying framework that explains the pervasive quantum organization of meaning that we identify.

</details>


### [28] [HUMORCHAIN: Theory-Guided Multi-Stage Reasoning for Interpretable Multimodal Humor Generation](https://arxiv.org/abs/2511.21732)
*Jiajun Zhang,Shijia Luo,Ruikang Zhang,Qi Su*

Main category: cs.CL

TL;DR: 本文提出了HUMORCHAIN框架，通过融合视觉语义解析与幽默认知推理，实现了多模态幽默生成的结构化推理，显著提升幽默性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法缺乏对幽默认知机制的显式建模，导致生成内容缺乏真正幽默感和认知深度，亟需一种结合幽默理论与视觉理解的生成方法。

Method: 引入HUMORCHAIN多阶段推理框架，结合视觉语义解析、基于幽默与心理学的推理及幽默评估鉴别器，形成可解释、可控的认知推理链。

Result: 在Meme-Image-No-Text、Oogiri-GO和OxfordTVG-HIC数据集上，HUMORCHAIN在人类幽默偏好、Elo/BT评分及语义多样性方面均优于最新方法。

Conclusion: 基于幽默理论的结构化推理使大型语言模型能够更好地捕捉人类幽默感，实现多模态幽默生成的创新突破。

Abstract: Humor, as both a creative human activity and a social binding mechanism, has long posed a major challenge for AI generation. Although producing humor requires complex cognitive reasoning and social understanding, theories of humor suggest that it follows learnable patterns and structures, making it theoretically possible for generative models to acquire them implicitly. In recent years, multimodal humor has become a prevalent form of online communication, especially among Gen Z, highlighting the need for AI systems capable of integrating visual understanding with humorous language generation. However, existing data-driven approaches lack explicit modeling or theoretical grounding of humor, often producing literal descriptions that fail to capture its underlying cognitive mechanisms, resulting in the generated image descriptions that are fluent but lack genuine humor or cognitive depth. To address this limitation, we propose HUMORCHAIN (HUmor-guided Multi-step Orchestrated Reasoning Chain for Image Captioning), a theory-guided multi-stage reasoning framework. It integrates visual semantic parsing, humor- and psychology-based reasoning, and a fine-tuned discriminator for humor evaluation, forming an interpretable and controllable cognitive reasoning chain. To the best of our knowledge, this is the first work to explicitly embed cognitive structures from humor theories into multimodal humor generation, enabling a structured reasoning process from visual understanding to humor creation. Experiments on Meme-Image-No-Text, Oogiri-GO, and OxfordTVG-HIC datasets show that HUMORCHAIN outperforms state-of-the-art baselines in human humor preference, Elo/BT scores, and semantic diversity, demonstrating that theory-driven structured reasoning enables large language models to generate humor aligned with human perception.

</details>


### [29] [RoSA: Enhancing Parameter-Efficient Fine-Tuning via RoPE-aware Selective Adaptation in Large Language Models](https://arxiv.org/abs/2511.21733)
*Dayan Pan,Jingyuan Wang,Yilong Zhou,Jiawei Cheng,Pengyue Jia,Xiangyu Zhao*

Main category: cs.CL

TL;DR: RoSA框架针对模型中旋转位置编码影响的重要层和低频维度，提出选择性增强和动态层选择策略，实现了更高效的参数微调。


<details>
  <summary>Details</summary>
Motivation: 现有的参数高效微调方法忽略了模型组件的不同角色和层之间的重要性差异，限制了微调效率。而观察到RoPE在低频维度中激发关键激活，为针对性微调提供了新的契机。

Method: 提出RoPE-aware Attention Enhancement模块选择性增强RoPE影响下的低频注意力分量，并通过动态层选择策略基于LayerNorm梯度范数自适应更新关键层，实现维度和层面的联合适配。

Result: 在15个常识和算术基准上，RoSA在相似可训练参数量下优于主流PEFT方法，展现了更好的适应性能和效率。代码已开源，便于复现。

Conclusion: 本文提出的RoPE-aware Selective Adaptation (RoSA)框架通过考虑Rotary Position Embeddings对低频注意力激活的影响，实现了参数高效且针对性的微调，显著提升了大语言模型的适应效率和性能。

Abstract: Fine-tuning large language models is essential for task-specific adaptation, yet it remains computationally prohibitive. Parameter-Efficient Fine-Tuning (PEFT) methods have emerged as a solution, but current approaches typically ignore the distinct roles of model components and the heterogeneous importance across layers, thereby limiting adaptation efficiency. Motivated by the observation that Rotary Position Embeddings (RoPE) induce critical activations in the low-frequency dimensions of attention states, we propose RoPE-aware Selective Adaptation (RoSA), a novel PEFT framework that allocates trainable parameters in a more targeted and effective manner. RoSA comprises a RoPE-aware Attention Enhancement (RoAE) module, which selectively enhances the low-frequency components of RoPE-influenced attention states, and a Dynamic Layer Selection (DLS) strategy that adaptively identifies and updates the most critical layers based on LayerNorm gradient norms. By combining dimension-wise enhancement with layer-wise adaptation, RoSA achieves more targeted and efficient fine-tuning. Extensive experiments on fifteen commonsense and arithmetic benchmarks demonstrate that RoSA outperforms existing mainstream PEFT methods under comparable trainable parameters. The code is available to ease reproducibility at https://github.com/Applied-Machine-Learning-Lab/RoSA.

</details>


### [30] [Asking LLMs to Verify First is Almost Free Lunch](https://arxiv.org/abs/2511.21734)
*Shiguang Wu,Quanming Yao*

Main category: cs.CL

TL;DR: 提出Verification-First和Iter-VF策略，通过先验证答案激励模型反向推理，提高推理准确率，性能优于传统Chain-of-Thought。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型推理能力不足且训练或采样成本高，需一种低成本提高推理准确性的策略。

Method: 设计VF策略，先让模型验证任意答案，触发反向推理；再推广为Iter-VF，多次循环执行验证-生成过程，提升性能。

Result: 提出了Verification-First (VF)策略，通过让大语言模型先验证一个候选答案（即使是随机的）来激发反向推理过程，从而提高模型的推理能力。进一步提出了Iter-VF方法，利用多次迭代验证生成过程，显著提升了多种推理任务上的性能。

Conclusion: VF策略能有效激发模型的批判性思维，减少逻辑错误，提升推理能力；Iter-VF方法则在测试时通过多次循环验证进一步提升性能，且计算开销低于传统方法。

Abstract: To enhance the reasoning capabilities of Large Language Models (LLMs) without high costs of training, nor extensive test-time sampling, we introduce Verification-First (VF), a strategy that prompts models to verify a provided candidate answer, even a trivial or random one, before generating a solution. This approach triggers a "reverse reasoning" process that is cognitively easier and complementary to standard forward Chain-of-Thought (CoT), effectively invoking the model's critical thinking to reduce logical errors. We further generalize the VF strategy to Iter-VF, a sequential test-time scaling (TTS) method that iteratively cycles the verification-generation process using the model's previous answer. Extensive experiments across various benchmarks (from mathematical reasoning to coding and agentic tasks) and various LLMs (from open-source 1B to cutting-edge commercial ones) confirm that VF with random answer consistently outperforms standard CoT with minimal computational overhead, and Iter-VF outperforms existing TTS strategies.

</details>


### [31] [Closing the Performance Gap Between AI and Radiologists in Chest X-Ray Reporting](https://arxiv.org/abs/2511.21735)
*Harshita Sharma,Maxwell C. Reynolds,Valentina Salvatelli,Anne-Marie G. Sykes,Kelly K. Horst,Anton Schwaighofer,Maximilian Ilse,Olesya Melnichenko,Sam Bond-Taylor,Fernando Pérez-García,Vamshi K. Mugu,Alex Chan,Ceylan Colak,Shelby A. Swartz,Motassem B. Nashawaty,Austin J. Gonzalez,Heather A. Ouellette,Selnur B. Erdal,Beth A. Schueler,Maria T. Wetscherek,Noel Codella,Mohit Jain,Shruthi Bannur,Kenza Bouzid,Daniel C. Castro,Stephanie Hyland,Panos Korfiatis,Ashish Khandelwal,Javier Alvarez-Valle*

Main category: cs.CL

TL;DR: MAIRA-X是一款基于大数据训练的多模态AI模型，能自动生成高质量、临床准确且包含线管信息的胸片报告，显著提升报告生成效率并辅助放射科医生。


<details>
  <summary>Details</summary>
Motivation: 放射科医生的工作负担因筛查指南的扩展、复杂病例和人手短缺而增加，尤其是胸片中线和导管的解释繁琐重复。

Method: 提出了MAIRA-X，这是一个基于大规模、多中心、纵向数据集开发的多模态AI模型，用于胸部X光报告生成，涵盖临床发现和线管解释，并开发了专门的线管评估指标框架。

Result: MAIRA-X在多个测试集上表现优于现有技术，词汇质量、临床准确性和线管报告元素均有明显提升。用户评估显示AI报告与人工报告在关键错误率和可接受句子比例上相近。

Conclusion: MAIRA-X能有效辅助放射科医师，特别适用于高病人量的临床环境，有潜力减轻医生负担并维持诊断准确性。

Abstract: AI-assisted report generation offers the opportunity to reduce radiologists' workload stemming from expanded screening guidelines, complex cases and workforce shortages, while maintaining diagnostic accuracy. In addition to describing pathological findings in chest X-ray reports, interpreting lines and tubes (L&T) is demanding and repetitive for radiologists, especially with high patient volumes. We introduce MAIRA-X, a clinically evaluated multimodal AI model for longitudinal chest X-ray (CXR) report generation, that encompasses both clinical findings and L&T reporting. Developed using a large-scale, multi-site, longitudinal dataset of 3.1 million studies (comprising 6 million images from 806k patients) from Mayo Clinic, MAIRA-X was evaluated on three holdout datasets and the public MIMIC-CXR dataset, where it significantly improved AI-generated reports over the state of the art on lexical quality, clinical correctness, and L&T-related elements. A novel L&T-specific metrics framework was developed to assess accuracy in reporting attributes such as type, longitudinal change and placement. A first-of-its-kind retrospective user evaluation study was conducted with nine radiologists of varying experience, who blindly reviewed 600 studies from distinct subjects. The user study found comparable rates of critical errors (3.0% for original vs. 4.6% for AI-generated reports) and a similar rate of acceptable sentences (97.8% for original vs. 97.4% for AI-generated reports), marking a significant improvement over prior user studies with larger gaps and higher error rates. Our results suggest that MAIRA-X can effectively assist radiologists, particularly in high-volume clinical settings.

</details>


### [32] [R2Q: Towards Robust 2-Bit Large Language Models via Residual Refinement Quantization](https://arxiv.org/abs/2511.21736)
*Jiayi Chen,Jieqi Shi,Jing Huo,Chen Wu*

Main category: cs.CL

TL;DR: 针对2位量化严重降精度问题，提出了分阶段残差细化量化方法R2Q，显著提升了性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型计算与内存需求巨大，低位量化是有效压缩手段，但2位量化因精度损失严重尚未广泛应用，亟需性能更优的量化方法。

Method: 提出了残差细化量化（R2Q），将2位量化过程分解为两个连续的1位子量化，形成自适应量化格点，并结合残差学习机制进行细化。

Result: 在Llama、OPT和Qwen模型及多种任务（问答、常识推理、语言建模）上，R2Q优于现有2位量化方法，在细粒度和粗粒度设置中表现更佳。

Conclusion: R2Q通过残差学习机制提升了极端压缩下的性能、训练稳定性和收敛速度，且模块化设计方便与现有量化感知训练框架无缝结合。

Abstract: The rapid progress of Large Language Models (LLMs) has brought substantial computational and memory demands, spurring the adoption of low-bit quantization. While 8-bit and 4-bit formats have become prevalent, extending quantization to 2 bits remains challenging due to severe accuracy degradation. To address this, we propose Residual Refinement Quantization (R2Q)-a novel 2-bit quantization framework that decomposes the process into two sequential 1-bit sub-quantizations, forming an adaptive quantization lattice. Extensive evaluations on Llama, OPT, and Qwen across diverse benchmarks-covering question answering, commonsense reasoning, and language modeling-demonstrate that R2Q consistently outperforms existing 2-bit quantization methods in both fine-grained and coarse-grained settings. By refining quantization through a residual learning mechanism, R2Q enhances performance, improves training stability, and accelerates convergence under extreme compression. Furthermore, its modular design enables seamless integration with existing quantization-aware training (QAT) frameworks.

</details>


### [33] [Polarity-Aware Probing for Quantifying Latent Alignment in Language Models](https://arxiv.org/abs/2511.21737)
*Sabrina Sadiekh,Elena Ericheva,Chirag Agarwal*

Main category: cs.CL

TL;DR: 本文提出一种基于极性一致性的无监督探针方法PA-CCS，评估语言模型内部潜在有害知识的编码，验证了其在识别模型对齐性和鲁棒性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督探针虽能揭示潜在信念，尚不明确其是否能可靠评估模型对齐性，本文动机在于验证探针在识别安全与有害信息内部表示的一致性与差异上的效果。

Method: 引入极性感知的对比一致搜索方法(PA-CCS)，设计极性一致性和矛盾指数两种指标，利用含有安全和有害句子对的数据集，对16个语言模型进行内部表示的评估。

Result: PA-CCS揭示了不同模型及其各层在编码潜在有害信息上的差异，发现替换否定词令表现良好的模型PA-CCS指标降低，而校准不足的模型无此现象。

Conclusion: 无监督探针方法如PA-CCS具备评估语言模型对齐性的潜力，但评估时需关注结构鲁棒性，增强可解释性基准的严谨性。

Abstract: Advances in unsupervised probes such as Contrast-Consistent Search (CCS), which reveal latent beliefs without relying on token outputs, raise the question of whether these methods can reliably assess model alignment. We investigate this by examining the sensitivity of CCS to harmful vs. safe statements and by introducing Polarity-Aware CCS (PA-CCS), a method for evaluating whether a model's internal representations remain consistent under polarity inversion. We propose two alignment-oriented metrics, Polar-Consistency and the Contradiction Index, to quantify the semantic robustness of a model's latent knowledge. To validate PA-CCS, we curate two main datasets and one control dataset containing matched harmful-safe sentence pairs constructed using different methodologies (concurrent and antagonistic statements). We apply PA-CCS to 16 language models. Our results show that PA-CCS identifies both architectural and layer-specific differences in the encoding of latent harmful knowledge. Notably, replacing the negation token with a meaningless marker degrades PA-CCS scores for models with well-aligned internal representations, while models lacking robust internal calibration do not exhibit this degradation. Our findings highlight the potential of unsupervised probing for alignment evaluation and emphasize the need to incorporate structural robustness checks into interpretability benchmarks. Code and datasets are available at: https://github.com/SadSabrina/polarity-probing. WARNING: This paper contains potentially sensitive, harmful, and offensive content.

</details>


### [34] [Decoding inner speech with an end-to-end brain-to-text neural interface](https://arxiv.org/abs/2511.21740)
*Yizi Zhang,Linyang He,Chaofei Fan,Tingkai Liu,Han Yu,Trung Le,Jingyuan Li,Scott Linderman,Lea Duncker,Francis R Willett,Nima Mesgarani,Liam Paninski*

Main category: cs.CL

TL;DR: 提出了一个端到端脑信号转文本系统BIT，通过跨任务预训练和音频大语言模型显著提升脑机接口语音解码准确率，实现了尝试与想象语音的跨任务泛化。


<details>
  <summary>Details</summary>
Motivation: 现有脑机接口多采用级联框架，无法联合优化各阶段，限制了性能提升，需设计端到端模型以实现统一优化和更优表现。

Method: 引入了一个端到端的Brain-to-Text (BIT)框架，利用单一可微神经网络将神经活动直接翻译成连贯句子。核心是一个跨任务、跨物种的预训练神经编码器，支持尝试说话和想象说话的表示转移。结合音频大语言模型和对比学习实现跨模态对齐。

Result: 预训练编码器在Brain-to-Text '24和'25基准上达到新的最先进水平。与之前端到端方法相比，WER从24.69%降低到10.22%。小型音频LLM显著提升了端到端解码性能。

Conclusion: BIT不仅在性能上创造了新纪录，还实现了尝试说话和想象说话的嵌入对齐，促进跨任务泛化。该方法推动了大规模多样神经数据的整合，开启了支持无缝可微优化的端到端解码框架。

Abstract: Speech brain-computer interfaces (BCIs) aim to restore communication for people with paralysis by translating neural activity into text. Most systems use cascaded frameworks that decode phonemes before assembling sentences with an n-gram language model (LM), preventing joint optimization of all stages simultaneously. Here, we introduce an end-to-end Brain-to-Text (BIT) framework that translates neural activity into coherent sentences using a single differentiable neural network. Central to our approach is a cross-task, cross-species pretrained neural encoder, whose representations transfer to both attempted and imagined speech. In a cascaded setting with an n-gram LM, the pretrained encoder establishes a new state-of-the-art (SOTA) on the Brain-to-Text '24 and '25 benchmarks. Integrated end-to-end with audio large language models (LLMs) and trained with contrastive learning for cross-modal alignment, BIT reduces the word error rate (WER) of the prior end-to-end method from 24.69% to 10.22%. Notably, we find that small-scale audio LLMs markedly improve end-to-end decoding. Beyond record-setting performance, BIT aligns attempted and imagined speech embeddings to enable cross-task generalization. Altogether, our approach advances the integration of large, diverse neural datasets, paving the way for an end-to-end decoding framework that supports seamless, differentiable optimization.

</details>


### [35] [A Multiscale Geometric Method for Capturing Relational Topic Alignment](https://arxiv.org/abs/2511.21741)
*Conrad D. Hougen,Karl T. Pazdernik,Alfred O. Hero*

Main category: cs.CL

TL;DR: 本文提出一种结合文本与共作者网络数据的几何层次主题建模方法，有效捕捉稀有话题和时间演变，提升模型的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 在共作者社群中追踪研究兴趣的演变需要可解释的主题建模，尤其在强调新颖性的科学文献中，识别稀有小众话题非常重要。现有基于密集变换器嵌入的模型难以捕捉罕见话题以及平滑的时间对齐。

Method: 提出一种几何方法，结合多模态文本和共作者网络数据，利用Hellinger距离和Ward聚类构建层次主题树状图，捕捉局部和全局结构，实现跨语义和时间的多尺度学习。

Result: 该方法有效识别了稀有话题结构，并展示了平滑的时间主题演变过程。实验显示，将可解释的词袋模型与几何对齐方法结合效果显著。

Conclusion: 几何结合多模态数据的层次主题建模方法能够更好地捕捉稀有话题及其时间动态，提升主题模型的解释性和追踪能力。

Abstract: Interpretable topic modeling is essential for tracking how research interests evolve within co-author communities. In scientific corpora, where novelty is prized, identifying underrepresented niche topics is particularly important. However, contemporary models built from dense transformer embeddings tend to miss rare topics and therefore also fail to capture smooth temporal alignment. We propose a geometric method that integrates multimodal text and co-author network data, using Hellinger distances and Ward's linkage to construct a hierarchical topic dendrogram. This approach captures both local and global structure, supporting multiscale learning across semantic and temporal dimensions. Our method effectively identifies rare-topic structure and visualizes smooth topic drift over time. Experiments highlight the strength of interpretable bag-of-words models when paired with principled geometric alignment.

</details>


### [36] [EduMod-LLM: A Modular Approach for Designing Flexible and Transparent Educational Assistants](https://arxiv.org/abs/2511.21742)
*Meenakshi Mittal,Rishi Khare,Mihran Miroyan,Chancharik Mitra,Narges Norouzi*

Main category: cs.CL

TL;DR: 本文开发了一个模块化的函数调用LLM管道EduMod，系统评估了函数调用、检索和生成模型，提升了教育问答系统的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在教育问答系统中的广泛应用，需要对管道各环节进行细致评估以提升系统性能和教学适配性。

Method: 本文提出EduMod，一个模块化函数调用LLM管道，通过比较不同函数调用策略、检索方法（结构感知、向量、LLM评分）及生成模型，进行系统性能基准测试和分析。

Result: 本文提出了一个模块化的函数调用大型语言模型（LLM）管道系统EduMod，用于教育领域的问答系统性能评估。通过对函数调用策略、检索方法和生成式语言模型三个关键方面的综合评测，实现对系统各组成部分的细粒度分析和独立评估。实验证明模块化方法有助于发现具体的失败模式和性能规律，提升了系统的透明度和教育适应性。

Conclusion: 模块化函数调用方法能够显著提升教育问答系统的可解释性和效果，有助于构建透明且符合教学需求的QA系统。

Abstract: With the growing use of Large Language Model (LLM)-based Question-Answering (QA) systems in education, it is critical to evaluate their performance across individual pipeline components. In this work, we introduce {\model}, a modular function-calling LLM pipeline, and present a comprehensive evaluation along three key axes: function calling strategies, retrieval methods, and generative language models. Our framework enables fine-grained analysis by isolating and assessing each component. We benchmark function-calling performance across LLMs, compare our novel structure-aware retrieval method to vector-based and LLM-scoring baselines, and evaluate various LLMs for response synthesis. This modular approach reveals specific failure modes and performance patterns, supporting the development of interpretable and effective educational QA systems. Our findings demonstrate the value of modular function calling in improving system transparency and pedagogical alignment. Website and Supplementary Material: https://chancharikmitra.github.io/EduMod-LLM-website/

</details>


### [37] [Scaling Competence, Shrinking Reasoning: Cognitive Signatures in Language Model Learning](https://arxiv.org/abs/2511.21743)
*Mukul Singh,Ananya Singha,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.CL

TL;DR: 语言模型微调中推理Token长度反映训练阶段和模型能力，推理步骤促进学习但非长期必须，推理表现可用来优化训练过程。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型推理过程与学习动力，借助认知科学理论指导模型训练诊断和优化。

Method: 分析语言模型在特定任务微调过程中的推理表现，结合认知科学中的“四阶段能力模型”（无意识无能、无意识有能、意识有能、无意识有能）揭示推理Token长度与模型性能的关系。

Result: 推理Token长度随性能提升而增加，达到意识有能阶段峰值，之后随着任务内化推理长度减少。训练结束后，即使去除推理步骤，模型仍保持性能，表明推理在学习中起到支撑作用但非必需。

Conclusion: 推理Token的动态变化可作为判断训练阶段、收敛情况及提前停止的指标，推理行为对理解和优化推理型模型训练具有重要价值。

Abstract: We analyze reasoning in language models during task-specific fine-tuning and draws parallel between reasoning tokens--intermediate steps generated while solving problem and the human working memory. Drawing from cognitive science, we align training dynamics with the Four Stages of Competence: models initially produce incorrect outputs without reasoning, then begin reasoning (but still fail), eventually reason effectively, and finally solve tasks without explicit reasoning. We find that reasoning token length expands as performance improves, peaks at the stage of conscious competence, then declines as the model internalizes the task. Notably, after training, models retain performance even when reasoning is removed--suggesting it scaffolded learning but is no longer needed. This progression offers actionable insights: reasoning token dynamics can serve as a signal for diagnosing training stage, identifying convergence, and guiding early stopping. We propose metrics to track this trajectory and argue that reasoning behavior is valuable for understanding and optimizing reasoning model training.

</details>


### [38] [A Lightweight Approach to Detection of AI-Generated Texts Using Stylometric Features](https://arxiv.org/abs/2511.21744)
*Sergey K. Aityan,William Claster,Karthik Sai Emani,Sohni Rais,Thy Tran*

Main category: cs.CL

TL;DR: 提出了NEULIF，一种基于文体和可读性特征，使用小型CNN或随机森林的轻量级AI文本检测方法，实现高准确率和高效运行。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成文本数量的增加，现有基于大型变压器模型的检测方法计算成本高且泛化能力有限，轻量级替代方案准确率较低。

Method: 提出了NEULIF方法，将文本分解为文体和可读性特征，然后用小型CNN或随机森林分类器进行检测。

Result: 在Kaggle AI vs. Human数据集上，CNN模型准确率97%（F1约0.95），随机森林模型准确率95%（F1约0.94），两者ROC-AUC分别为99.5%和95%，且模型体积小，计算效率高。

Conclusion: 简单且结构化的特征与轻量级模型结合，能在检测AI生成文本任务中达到与复杂模型相当的效果，并适合多语言、多领域及流式场景应用。

Abstract: A growing number of AI-generated texts raise serious concerns. Most existing approaches to AI-generated text detection rely on fine-tuning large transformer models or building ensembles, which are computationally expensive and often provide limited generalization across domains. Existing lightweight alternatives achieved significantly lower accuracy on large datasets. We introduce NEULIF, a lightweight approach that achieves best performance in the lightweight detector class, that does not require extensive computational power and provides high detection accuracy. In our approach, a text is first decomposed into stylometric and readability features which are then used for classification by a compact Convolutional Neural Network (CNN) or Random Forest (RF). Evaluated and tested on the Kaggle AI vs. Human corpus, our models achieve 97% accuracy (~ 0.95 F1) for CNN and 95% accuracy (~ 0.94 F1) for the Random Forest, demonstrating high precision and recall, with ROC-AUC scores of 99.5% and 95%, respectively. The CNN (~ 25 MB) and Random Forest (~ 10.6 MB) models are orders of magnitude smaller than transformer-based ensembles and can be run efficiently on standard CPU devices, without sacrificing accuracy.This study also highlights the potential of such models for broader applications across languages, domains, and streaming contexts, showing that simplicity, when guided by structural insights, can rival complexity in AI-generated content detection.

</details>


### [39] [DELTA: Language Diffusion-based EEG-to-Text Architecture](https://arxiv.org/abs/2511.21746)
*Mingyu Jeon,Hyobin Kim*

Main category: cs.CL

TL;DR: DELTA利用多层离散编码和非序列生成方法提高脑电信号到文本的转换效果。


<details>
  <summary>Details</summary>
Motivation: 传统脑电图到文本转换面临高维噪声、个体差异及自回归解码中误差积累的问题，需要新的方法提升语义对齐和生成准确度。

Method: 采用残差向量量化（RVQ）将连续脑电信号离散为多层令牌，结合掩码语言扩散模型（LLaDA）进行非序列的句子重构，降低噪声影响并避免错误累积。

Result: 在ZuCo数据集上，DELTA相较自回归基线提升了最高5.37点语义对齐，词级条件下BLEU-1达到21.9，ROUGE-1 F达到17.2，验证了其在小规模脑电文本数据集上的优越表现。

Conclusion: DELTA模型通过结合残差向量量化和掩码语言扩散模型，显著提升了从脑电图到文本的转换性能，尤其在语义一致性方面表现优异，适用于小规模数据集并具备扩展性。

Abstract: Electroencephalogram (EEG)-to-text remains challenging due to high-dimensional noise, subject variability, and error accumulation in autoregressive decoding. We introduce DELTA, which pairs a Residual Vector Quantization (RVQ) EEG tokenizer with a masked language diffusion model (LLaDA). RVQ discretizes continuous EEG into multi-layer tokens to reduce noise and individual differences, while LLaDA reconstructs sentences via non-sequential denoising. On ZuCo, DELTA improves semantic alignment by up to 5.37 points over autoregressive baselines, achieving BLEU-1 21.9 and ROUGE-1 F 17.2 under word-level conditions. These results enable reliable text generation from small EEG-text datasets and point toward scalable multimodal EEG-language models.

</details>


### [40] [Building Domain-Specific Small Language Models via Guided Data Generation](https://arxiv.org/abs/2511.21748)
*Aman Kumar,Ekant Muljibhai Amin,Xian Yeow Lee,Lasitha Vidyaratne,Ahmed K. Farahat,Dipanjan D. Ghosh,Yuta Koreeda,Chetan Gupta*

Main category: cs.CL

TL;DR: 本文提出了一种结合合成数据与领域数据策划的训练方法，成功训练出小型领域专用模型DiagnosticSLM，实现了有效的领域推理和泛化能力，性能优于同类开源模型。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域的应用面临数据隐私和计算资源高的挑战，小型领域专用模型缺乏高质量领域训练数据限制了效果。

Method: 提出了一种结合引导合成数据生成与自底向上的领域数据策划的成本高效且可扩展的训练流程，结合领域自适应预训练(DAPT)、领域特定有监督微调(DSFT)和直接偏好优化(DPO)三种方法。

Result: 开发了一个3B参数的领域专用模型DiagnosticSLM，在工业故障诊断、根因分析和维修建议任务中表现出色，在多个领域特定基准（诊断多项选择题、问答、句子补全、摘要）上，相比同样大小或更大开源模型准确率提升最多达25%。

Conclusion: 本文的方法有效缓解了领域专用小型模型训练数据匮乏问题，训练出的DiagnosticSLM在复杂工业诊断任务中表现优异，展示了其在专业领域应用的潜力。

Abstract: Large Language Models (LLMs) have shown remarkable success in supporting a wide range of knowledge-intensive tasks. In specialized domains, there is growing interest in leveraging LLMs to assist subject matter experts with domain-specific challenges. However, deploying LLMs as SaaS solutions raises data privacy concerns, while many open-source models demand significant computational resources for effective domain adaptation and deployment. A promising alternative is to develop smaller, domain-specialized LLMs, though this approach is often constrained by the lack of high-quality domain-specific training data. In this work, we address these limitations by presenting a cost-efficient and scalable training pipeline that combines guided synthetic data generation from a small seed corpus with bottom-up domain data curation. Our pipeline integrates Domain-Adaptive Pretraining (DAPT), Domain-specific Supervised Fine-tuning (DSFT), and Direct Preference Optimization (DPO) to train effective small-scale models for specialized use cases. We demonstrate this approach through DiagnosticSLM, a 3B-parameter domain-specific model tailored for fault diagnosis, root cause analysis, and repair recommendation in industrial settings. To evaluate model performance, we introduce four domain-specific benchmarks: multiple-choice questions (DiagnosticMCQ), question answering (DiagnosticQA), sentence completion (DiagnosticComp), and summarization (DiagnosticSum). DiagnosticSLM achieves up to 25% accuracy improvement over open-source models of comparable or larger size (2B-9B) on the MCQ task, while also outperforming or matching them in other tasks, demonstrating effective domain-specific reasoning and generalization capabilities.

</details>


### [41] [Proactive Defense: Compound AI for Detecting Persuasion Attacks and Measuring Inoculation Effectiveness](https://arxiv.org/abs/2511.21749)
*Svitlana Volkova,Will Dupree,Hsien-Te Kao,Peter Bautista,Gabe Ganberg,Jeff Beaubien,Laura Cassani*

Main category: cs.CL

TL;DR: 本文提出BRIES系统，结合多智能体检测和防御说服攻击，比较了不同语言模型的性能差异，通过因果分析深入理解攻击特点，推动了AI安全和认知安全研究。


<details>
  <summary>Details</summary>
Motivation: 当前生成式人工智能容易受到复杂说服攻击的威胁，且不同大语言模型在说服攻击检测上的性能差异显著，需要一种系统方法来量化这些差异并增强人类认知韧性，保障信息环境安全。

Method: 引入多角色智能体架构，包括生成对抗说服内容的Twister，识别攻击的Detector，构建免疫内容的Defender，及因果推断评估的Assessor；结合SemEval 2023 Task 3数据集进行实验和因果分析，探索温度等提示参数对模型性能的影响。

Result: 本文提出了BRIES，一种新颖的复合型人工智能架构，用于检测和衡量信息环境中说服攻击的有效性。系统包含多个专业代理：用定向说服策略生成对抗内容的Twister，识别攻击类型并可配置参数的Detector，通过内容接种生成抗性内容的Defender，以及利用因果推断评估接种效果的Assessor。基于SemEval 2023 Task 3的说服数据集实验，展示了不同语言模型在检测性能上的显著差异，其中GPT-4在复杂说服技术检测上表现优异，开源模型如Llama3和Mistral在识别细微修辞方面较弱。提示工程（如温度设置和置信评分）显著影响检测效果，Gemma与GPT-4在较低温度下表现最佳，而Llama3和Mistral则在较高温度有所提升。因果分析揭示不同攻击类型针对特定认知维度，揭示了说服攻击的社会-情绪-认知特征。该研究推动了生成式AI安全和认知安全领域的发展，量化了大语言模型特定的说服攻击脆弱性，并提出了通过结构化干预增强人类认知韧性的框架。

Conclusion: BRIES系统有效检测并评估说服攻击，显示不同语言模型对说服语言的编码和处理存在根本差异，提示工程和模型架构对性能影响显著，研究为生成式AI安全与认知韧性提供新框架。

Abstract: This paper introduces BRIES, a novel compound AI architecture designed to detect and measure the effectiveness of persuasion attacks across information environments. We present a system with specialized agents: a Twister that generates adversarial content employing targeted persuasion tactics, a Detector that identifies attack types with configurable parameters, a Defender that creates resilient content through content inoculation, and an Assessor that employs causal inference to evaluate inoculation effectiveness. Experimenting with the SemEval 2023 Task 3 taxonomy across the synthetic persuasion dataset, we demonstrate significant variations in detection performance across language agents. Our comparative analysis reveals significant performance disparities with GPT-4 achieving superior detection accuracy on complex persuasion techniques, while open-source models like Llama3 and Mistral demonstrated notable weaknesses in identifying subtle rhetorical, suggesting that different architectures encode and process persuasive language patterns in fundamentally different ways. We show that prompt engineering dramatically affects detection efficacy, with temperature settings and confidence scoring producing model-specific variations; Gemma and GPT-4 perform optimally at lower temperatures while Llama3 and Mistral show improved capabilities at higher temperatures. Our causal analysis provides novel insights into socio-emotional-cognitive signatures of persuasion attacks, revealing that different attack types target specific cognitive dimensions. This research advances generative AI safety and cognitive security by quantifying LLM-specific vulnerabilities to persuasion attacks and delivers a framework for enhancing human cognitive resilience through structured interventions before exposure to harmful content.

</details>


### [42] [Semantics as a Shield: Label Disguise Defense (LDD) against Prompt Injection in LLM Sentiment Classification](https://arxiv.org/abs/2511.21752)
*Yanxi Li,Ruocheng Shan*

Main category: cs.CL

TL;DR: 本文提出了一种名为Label Disguise Defense（LDD）的防御策略，通过用语义转化或无关别名标签替代真实标签，防止提示注入攻击，从而提高大语言模型在文本分类任务中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法存在需重新训练或易受混淆攻击的缺陷，迫切需要一种轻量、无需改动模型的防御策略来抵抗提示注入攻击。

Method: LDD通过使用少量示例教学，让模型学习由语义转化或无关的别名标签映射真实标签，避免注入指令与决策输出的直接对应。

Result: 在包括GPT-5、GPT-4o、LLaMA3.2等九个模型上的测试显示，LDD能恢复一部分准确率损失，多数组合优于无防御基线；语义相关别名标签效果优于无关符号。

Conclusion: LDD能够在不需模型重训练的情况下，通过改变标签语义有效缓解提示注入攻击，恢复部分准确率，证明标签语义转换是防御提示注入的有效方法。

Abstract: Large language models are increasingly used for text classification tasks such as sentiment analysis, yet their reliance on natural language prompts exposes them to prompt injection attacks. In particular, class-directive injections exploit knowledge of the model's label set (e.g., positive vs. negative) to override its intended behavior through adversarial instructions. Existing defenses, such as detection-based filters, instruction hierarchies, and signed prompts, either require model retraining or remain vulnerable to obfuscation. This paper introduces Label Disguise Defense (LDD), a lightweight and model-agnostic strategy that conceals true labels by replacing them with semantically transformed or unrelated alias labels(e.g., blue vs. yellow). The model learns these new label mappings implicitly through few-shot demonstrations, preventing direct correspondence between injected directives and decision outputs. We evaluate LDD across nine state-of-the-art models, including GPT-5, GPT-4o, LLaMA3.2, Gemma3, and Mistral variants, under varying few-shot and an adversarial setting. Our results show that the ability of LDD to recover performance lost to the adversarial attack varies across models and alias choices. For every model evaluated, LDD is able to restore a portion of the accuracy degradation caused by the attack. Moreover, for the vast majority of models, we can identify more than one alias pair that achieves higher accuracy than the under-attack baseline, in which the model relies solely on few-shot learning without any defensive mechanism. A linguistic analysis further reveals that semantically aligned alias labels(e.g., good vs. bad) yield stronger robustness than unaligned symbols(e.g., blue vs. yellow). Overall, this study demonstrates that label semantics can serve as an effective defense layer, transforming meaning itself into a shield against prompt injection.

</details>


### [43] [Extracting Disaster Impacts and Impact Related Locations in Social Media Posts Using Large Language Models](https://arxiv.org/abs/2511.21753)
*Sameeah Noreen Hameed,Surangika Ranathunga,Raj Prasanna,Kristin Stock,Christopher B. Jones*

Main category: cs.CL

TL;DR: 利用微调的大规模语言模型从灾难社交媒体文本中准确识别受影响地点，提升灾害应急决策效率。


<details>
  <summary>Details</summary>
Motivation: 灾害现场权威数据受限且存在时间和空间信息缺口，社交媒体作为“地理传感器”提供重要信息，但需要精准识别受影响的关键地点以优化资源配置。

Method: 通过对预训练的大规模语言模型进行微调，针对灾难相关社交媒体文本中的影响和受影响位置进行精准识别，包括非正式表达和简写形式。

Result: 本文旨在利用大规模语言模型（LLMs）从灾难相关的社交媒体帖子中识别所有提及的位置、影响和受影响位置，特别是区分受影响的位置和非受影响的位置（如地名的非受灾区）。通过对LLMs进行微调，使其能够识别非正式表达、缩写和简写中提及的地点和影响。微调后的模型在影响提取上达到F1分数0.69，在受影响位置提取上达到0.74，显著优于预训练基线模型。此结果表明，微调语言模型在灾难应急资源分配、态势感知和灾后恢复规划中具有良好的应用前景。

Conclusion: 微调后的大规模语言模型能有效区分和提取灾难相关社交媒体中的受影响位置与影响，优于基线模型，具备实际应用潜力。

Abstract: Large-scale disasters can often result in catastrophic consequences on people and infrastructure. Situation awareness about such disaster impacts generated by authoritative data from in-situ sensors, remote sensing imagery, and/or geographic data is often limited due to atmospheric opacity, satellite revisits, and time limitations. This often results in geo-temporal information gaps. In contrast, impact-related social media posts can act as "geo-sensors" during a disaster, where people describe specific impacts and locations. However, not all locations mentioned in disaster-related social media posts relate to an impact. Only the impacted locations are critical for directing resources effectively. e.g., "The death toll from a fire which ripped through the Greek coastal town of #Mati stood at 80, with dozens of people unaccounted for as forensic experts tried to identify victims who were burned alive #Greecefires #AthensFires #Athens #Greece." contains impacted location "Mati" and non-impacted locations "Greece" and "Athens". This research uses Large Language Models (LLMs) to identify all locations, impacts and impacted locations mentioned in disaster-related social media posts. In the process, LLMs are fine-tuned to identify only impacts and impacted locations (as distinct from other, non-impacted locations), including locations mentioned in informal expressions, abbreviations, and short forms. Our fine-tuned model demonstrates efficacy, achieving an F1-score of 0.69 for impact and 0.74 for impacted location extraction, substantially outperforming the pre-trained baseline. These robust results confirm the potential of fine-tuned language models to offer a scalable solution for timely decision-making in resource allocation, situational awareness, and post-disaster recovery planning for responders.

</details>


### [44] [Dissecting the Ledger: Locating and Suppressing "Liar Circuits" in Financial Large Language Models](https://arxiv.org/abs/2511.21756)
*Soham Mirajkar*

Main category: cs.CL

TL;DR: 本文针对大语言模型在金融领域的算术推理幻觉问题，提出了一种机制性检测方法，识别了模型算术推理的双阶段机制，并通过消融验证关键层的重要性，实现了对幻觉输出的有效抑制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在金融算术任务中存在可复现的幻觉，现有方法多将模型视为黑盒，缺乏对幻觉产生机制的深入理解和干预手段。

Method: 通过因果追踪（Causal Tracing）方法分析GPT-2 XL在ConvFinQA基准上的行为，定位算术推理的关键层，并通过消融实验验证关键层的作用，训练线性探针以测试其泛化能力。

Result: 识别了中间层的计算草稿和后期层的聚合电路作为算术推理的双阶段机制，抑制关键层Layer 46使幻觉置信度降低81.8%，线性探针对未见金融话题达到98%准确率，表明机制的普适性。

Conclusion: 本文发现GPT-2 XL模型中算术推理涉及中间层的计算草稿和后期层的聚合电路，关键层（Layer 46）对幻觉输出有决定性影响，抑制该层能显著降低幻觉信心，且该层的探针具有很强的泛化能力。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-stakes financial domains, yet they suffer from specific, reproducible hallucinations when performing arithmetic operations. Current mitigation strategies often treat the model as a black box. In this work, we propose a mechanistic approach to intrinsic hallucination detection. By applying Causal Tracing to the GPT-2 XL architecture on the ConvFinQA benchmark, we identify a dual-stage mechanism for arithmetic reasoning: a distributed computational scratchpad in middle layers (L12-L30) and a decisive aggregation circuit in late layers (specifically Layer 46). We verify this mechanism via an ablation study, demonstrating that suppressing Layer 46 reduces the model's confidence in hallucinatory outputs by 81.8%. Furthermore, we demonstrate that a linear probe trained on this layer generalizes to unseen financial topics with 98% accuracy, suggesting a universal geometry of arithmetic deception.

</details>


### [45] [Orchestrating Dual-Boundaries: An Arithmetic Intensity Inspired Acceleration Framework for Diffusion Language Models](https://arxiv.org/abs/2511.21759)
*Linye Wei,Wenjue Chen,Pingzhi Tang,Xiaotian Guo,Le Ye,Runsheng Wang,Meng Li*

Main category: cs.CL

TL;DR: 提出ODB-dLLM框架，通过自适应长度预测和跳跃共享推测解码两大技术显著加速基于扩散的大型语言模型推理，兼顾效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 传统dLLM框架因双向注意力机制需要频繁刷新缓存，且预填充和解码阶段均带来较大推理成本，限制了速度提升的空间，需针对不同阶段的算力特征设计高效加速策略。

Method: 提出ODB-dLLM框架，利用双重边界机制：预填充阶段用自适应长度预测机制减少计算冗余，解码阶段采用针对dLLM设计的跳跃共享推测解码方法减少解码迭代次数。

Result: 实验表明，ODB-dLLM相较于基础dLLM框架和Fast-dLLM，分别实现了46-162倍和2.63-6.30倍的加速，同时有效降低了现有加速方法中的准确率下降问题。

Conclusion: 本文提出的ODB-dLLM框架显著提升了基于扩散的大型语言模型推理效率，在预填充阶段通过自适应长度预测减少冗余计算，在解码阶段采用特定的跳跃共享推测解码方法，实验结果显示相比基线和现有优化框架取得了大幅度的加速和降低了准确率损失。

Abstract: Diffusion-based large language models (dLLMs) have recently gained significant attention for their exceptional performance and inherent potential for parallel decoding. Existing frameworks further enhance its inference efficiency by enabling KV caching. However, its bidirectional attention mechanism necessitates periodic cache refreshes that interleave prefill and decoding phases, both contributing substantial inference cost and constraining achievable speedup. Inspired by the heterogeneous arithmetic intensity of the prefill and decoding phases, we propose ODB-dLLM, a framework that orchestrates dual-boundaries to accelerate dLLM inference. In the prefill phase, we find that the predefined fixed response length introduces heavy yet redundant computational overhead, which affects efficiency. To alleviate this, ODB-dLLM incorporates an adaptive length prediction mechanism that progressively reduces prefill overhead and unnecessary computation. In the decoding phase, we analyze the computational characteristics of dLLMs and propose a dLLM-specific jump-share speculative decoding method to enhance efficiency by reducing the number of decoding iterations. Experimental results demonstrate that ODB-dLLM achieves 46-162x and 2.63-6.30x speedups over the baseline dLLM and Fast-dLLM, respectively, while simultaneously mitigating the accuracy degradation in existing acceleration frameworks.

</details>


### [46] [fMRI-LM: Towards a Universal Foundation Model for Language-Aligned fMRI Understanding](https://arxiv.org/abs/2511.21760)
*Yuxiang Wei,Yanteng Zhang,Xi Xiao,Chengxuan Qian,Tianyang Wang,Vince D. Calhoun*

Main category: cs.CL

TL;DR: 该论文提出了fMRI-LM模型，通过三阶段框架将功能性磁共振成像(fMRI)与语言模型结合，实现了大脑活动与语义认知的统一表征。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型已能跨图像、音频及视频推理，但尚未扩展到脑成像，建立脑神经活动与语义认知的联系迫切需要此类模型。

Method: 该方法包含三阶段：1）学习神经编码器，将fMRI信号映射为语言一致的离散标记；2）适配预训练大型语言模型联合建模fMRI标记和文本；3）通过多任务多范式指令调优，实现高阶语义理解。

Result: fMRI-LM在多种基准中展示了强大的零样本和少样本表现，并可通过参数高效调优方法快速适应多样化任务，展示了构建通用多模态脑语言模型的潜力。

Conclusion: fMRI-LM在多项基准测试中表现出色，实现了高效的零样本和少样本学习能力，推动了fMRI结构和语义理解的统一模型构建。

Abstract: Recent advances in multimodal large language models (LLMs) have enabled unified reasoning across images, audio, and video, but extending such capability to brain imaging remains largely unexplored. Bridging this gap is essential to link neural activity with semantic cognition and to develop cross-modal brain representations. To this end, we present fMRI-LM, a foundational model that bridges functional MRI (fMRI) and language through a three-stage framework. In Stage 1, we learn a neural tokenizer that maps fMRI into discrete tokens embedded in a language-consistent space. In Stage 2, a pretrained LLM is adapted to jointly model fMRI tokens and text, treating brain activity as a sequence that can be temporally predicted and linguistically described. To overcome the lack of natural fMRI-text pairs, we construct a large descriptive corpus that translates diverse imaging-based features into structured textual descriptors, capturing the low-level organization of fMRI signals. In Stage 3, we perform multi-task, multi-paradigm instruction tuning to endow fMRI-LM with high-level semantic understanding, supporting diverse downstream applications. Across various benchmarks, fMRI-LM achieves strong zero-shot and few-shot performance, and adapts efficiently with parameter-efficient tuning (LoRA), establishing a scalable pathway toward a language-aligned, universal model for structural and semantic understanding of fMRI.

</details>


### [47] [LLMs for Low-Resource Dialect Translation Using Context-Aware Prompting: A Case Study on Sylheti](https://arxiv.org/abs/2511.21761)
*Tabia Tanzin Prama,Christopher M. Danforth,Peter Sheridan Dodds*

Main category: cs.CL

TL;DR: 本研究首次系统评估了大型语言模型(LLMs)在班加拉语方言Sylheti翻译中的表现，并提出了Sylheti-CAP上下文感知提示框架，有效提升了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对方言和低资源语言的翻译能力尚未充分研究，尤其是Sylheti这类低资源班加拉语方言的翻译效果较差。

Method: 提出Sylheti-CAP三步框架，将语言规则、词典和真实性检查嵌入提示中，增强模型对方言特定词汇和结构的理解。

Result: 经过大量实验证明，Sylheti-CAP能一致提升多种先进LLMs的翻译质量，自动评测和人工评价均验证其有效性。

Conclusion: Sylheti-CAP框架显著改善了LLMs在Sylheti与班加拉语翻译中的表现，减少了幻觉和歧义，验证了其作为低资源方言机器翻译可扩展解决方案的有效性。

Abstract: Large Language Models (LLMs) have demonstrated strong translation abilities through prompting, even without task-specific training. However, their effectiveness in dialectal and low-resource contexts remains underexplored. This study presents the first systematic investigation of LLM-based machine translation (MT) for Sylheti, a dialect of Bangla that is itself low-resource. We evaluate five advanced LLMs (GPT-4.1, GPT-4.1, LLaMA 4, Grok 3, and DeepSeek V3.2) across both translation directions (Bangla $\Leftrightarrow$ Sylheti), and find that these models struggle with dialect-specific vocabulary. To address this, we introduce Sylheti-CAP (Context-Aware Prompting), a three-step framework that embeds a linguistic rulebook, a dictionary (2{,}260 core vocabulary items and idioms), and an authenticity check directly into prompts. Extensive experiments show that Sylheti-CAP consistently improves translation quality across models and prompting strategies. Both automatic metrics and human evaluations confirm its effectiveness, while qualitative analysis reveals notable reductions in hallucinations, ambiguities, and awkward phrasing, establishing Sylheti-CAP as a scalable solution for dialectal and low-resource MT. Dataset link: \href{https://github.com/TabiaTanzin/LLMs-for-Low-Resource-Dialect-Translation-Using-Context-Aware-Prompting-A-Case-Study-on-Sylheti.git}{https://github.com/TabiaTanzin/LLMs-for-Low-Resource-Dialect-Translation-Using-Context-Aware-Prompting-A-Case-Study-on-Sylheti.git}

</details>


### [48] [Factors That Support Grounded Responses in LLM Conversations: A Rapid Review](https://arxiv.org/abs/2511.21762)
*Gabriele Cesar Iwashima,Claudia Susie Rodrigues,Claudio Dipolitto,Geraldo Xexéo*

Main category: cs.CL

TL;DR: 本文综述了LLM输出对齐技术，突出推理时方法在保证用户意图、上下文基础和减少幻觉上的高效性。


<details>
  <summary>Details</summary>
Motivation: LLMs生成的文本可能偏离用户意图、缺乏上下文支撑或出现幻觉，严重影响应用可靠性，亟需技术实现多目标输出对齐以提升用户体验与信任。

Method: 本文采用PRISMA框架和PICO策略进行快速文献评审，分类分析推理时、后训练和强化学习三类对齐技术，重点评估其对用户意图支持、上下文基础和幻觉减少的效果。

Result: 该论文综述了大语言模型(LLMs)在生成过程中存在的偏差问题，如输出与用户意图不一致、缺乏上下文基础以及产生虚构内容（幻觉），这些问题影响了基于LLM应用的可靠性。研究通过PRISMA框架和PICO策略，快速筛选和分析了多种对齐技术，分类为推理时、后训练及基于强化学习的方法。结论指出推理时方法尤其高效，能够无需重训而实现输出对齐，兼顾用户意图支持、上下文基础和幻觉减少。该综述为提升LLM响应的质量与可靠性，提供了结构化的技术指导。

Conclusion: 推理时对齐策略因其无需重训练且能有效支持多目标对齐，被认为是提升LLM响应质量与可靠性的关键方法。

Abstract: Large language models (LLMs) may generate outputs that are misaligned with user intent, lack contextual grounding, or exhibit hallucinations during conversation, which compromises the reliability of LLM-based applications. This review aimed to identify and analyze techniques that align LLM responses with conversational goals, ensure grounding, and reduce hallucination and topic drift. We conducted a Rapid Review guided by the PRISMA framework and the PICO strategy to structure the search, filtering, and selection processes. The alignment strategies identified were categorized according to the LLM lifecycle phase in which they operate: inference-time, post-training, and reinforcement learning-based methods. Among these, inference-time approaches emerged as particularly efficient, aligning outputs without retraining while supporting user intent, contextual grounding, and hallucination mitigation. The reviewed techniques provided structured mechanisms for improving the quality and reliability of LLM responses across key alignment objectives.

</details>


### [49] [FLAWS: A Benchmark for Error Identification and Localization in Scientific Papers](https://arxiv.org/abs/2511.21843)
*Sarina Xi,Vishisht Rao,Justin Payan,Nihar B. Shah*

Main category: cs.CL

TL;DR: 本文构建了FLAWS基准，通过引入错误评测LLMs检测科研论文关键错误的能力，发现GPT 5表现最优，定位准确率为39.1%。


<details>
  <summary>Details</summary>
Motivation: 科学产出爆炸增长导致专家评审检错难度加大，寻求利用LLMs辅助学术评审检测论文关键错误的潜力，提高评审效率和准确性。

Method: 通过向真实同行评审论文插入使关键主张失效的错误，构建包含713论文-错误对的测试集，利用自动评价指标检测模型定位错误的能力，并测试五款先进的LLM。

Result: 本文提出了一个名为FLAWS的自动化基准测试工具，用于评估大型语言模型（LLMs）识别和定位科研论文中关键错误的能力。该基准由713对论文-错误数据组成，通过在同行评审论文中系统地插入使论点无效的错误，结合自动评价指标，衡量模型发现和定位错误的效果。本文克服了构建中的多项挑战，确保错误定义明确、具挑战性且与论文内容相关，避免简单识别的线索，且设计了可扩展的自动评估方法。基于该基准测试了五个前沿LLM，结果显示GPT 5表现最佳，k=10时错误定位准确率达39.1%。

Conclusion: FLAWS基准有效验证了当前顶级LLM在科研论文错误识别中的能力，显示GPT 5领先，但整体准确率仍有提升空间，指示未来改进方向。

Abstract: The identification and localization of errors is a core task in peer review, yet the exponential growth of scientific output has made it increasingly difficult for human reviewers to reliably detect errors given the limited pool of experts. Recent advances in Large Language Models (LLMs) have sparked interest in their potential to support such evaluation tasks, from academic peer review to automated scientific assessment. However, despite the growing use of LLMs in review systems, their capabilities to pinpoint errors remain underexplored. In this work, we introduce Fault Localization Across Writing in Science (FLAWS), an automated benchmark consisting of 713 paper-error pairs designed to evaluate how effectively LLMs detect errors that undermine key claims in research papers. We construct the benchmark by systematically inserting claim-invalidating errors into peer-reviewed papers using LLMs, paired with an automated evaluation metric that measures whether models can identify and localize these errors. Developing such a benchmark presents unique challenges that we overcome: ensuring that the inserted errors are well-defined, challenging, and relevant to the content of the paper, avoiding artifacts that would make identification trivial, and designing a scalable, automated evaluation metric. On the resulting benchmark, we evaluate five frontier LLMs: Claude Sonnet 4.5, DeepSeek Reasoner v3.1, Gemini 2.5 Pro, GPT 5, and Grok 4. Among these, GPT 5 is the top-performing model, achieving 39.1% identification accuracy when k=10, where k is the number of top-ranked error text candidates generated by the LLM.

</details>


### [50] [Improving Score Reliability of Multiple Choice Benchmarks with Consistency Evaluation and Altered Answer Choices](https://arxiv.org/abs/2511.21860)
*Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Claudio Pinhanez,Yago Primerano*

Main category: cs.CL

TL;DR: 提出CoRA指标，通过考察模型回答一致性，改进多选题大语言模型评分的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前多选题基准中大语言模型得分虽高但可能缺乏回答一致性，亟需一种方法提升评估的可靠性。

Method: 利用合成问题改变答案选项，计算BMCA和CI两项一致性得分，调整MCQA得分以获得CoRA。

Result: 本文提出了一种名为Consistency-Rebalanced Accuracy (CoRA)的评估指标，用于提升多选题（MC）基准测试中大语言模型（LLM）分数的可靠性。通过合成生成带有变更答案选项的问题，CoRA衡量了模型回答的一致性。该指标基于两个中间分数：Bare-Minimum-Consistency Accuracy (BMCA)和Consistency Index (CI)，通过调整多选题答题准确率（MCQA）分数，反映模型的一致性水平。实验证明，即使模型在MCQA中得分较高，也可能显示出较低的回答一致性，CoRA能够有效降低不一致模型的得分。

Conclusion: CoRA指标能有效揭示并降低回答不一致的大语言模型的多选题得分，提升评分的可信度。

Abstract: In this work we present the Consistency-Rebalanced Accuracy (CoRA) metric, improving the reliability of Large Language Model (LLM) scores computed on multiple choice (MC) benchmarks. Our metric explores the response consistency of the LLMs, taking advantage of synthetically-generated questions with altered answer choices. With two intermediate scores, i.e. Bare-Minimum-Consistency Accuracy (BMCA) and Consistency Index (CI), CoRA is computed by adjusting the multiple-choice question answering (MCQA) scores to better reflect the level of consistency of the LLM. We present evaluations in different benchmarks using diverse LLMs, and not only demonstrate that LLMs can present low response consistency even when they present high MCQA scores, but also that CoRA can successfully scale down the scores of inconsistent models.

</details>


### [51] [A Customer Journey in the Land of Oz: Leveraging the Wizard of Oz Technique to Model Emotions in Customer Service Interactions](https://arxiv.org/abs/2511.21909)
*Sofie Labat,Thomas Demeester,Véronique Hoste*

Main category: cs.CL

TL;DR: 本研究通过WOZ实验构建了涵盖多领域的情感客户服务对话语料，揭示了情感标注多样性与策略对情绪的影响，展示了情感前瞻推断的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的情感识别资源存在领域外、不完整标签及事后检测为主的问题，缺乏面向客户服务情感识别的真实、丰富且可预测的对话数据。

Method: 采用受控的Wizard of Oz（WOZ）实验，设计针对情感轨迹的交互过程，收集了包含2148个双语（荷兰语-英语）书面对话的EmoWOZ-CS语料库，涵盖多个商业服务场景。

Result: 发现中性情绪占比最高，非中性情绪中愿望和感激最常见；多标签情绪和情感价一致性适中，自报与第三方标注存在较大差异；不同客服策略对情感反应有显著影响；且前瞻性情感推断存在较大挑战。

Conclusion: 本研究提供了一个丰富的情感客户服务对话资源和标注体系，验证了WOZ实验对情感轨迹设计的有效性，强调了情感推断的复杂性，为情感智能客服系统发展提供了重要资源和理论支持。

Abstract: Emotion-aware customer service needs in-domain conversational data, rich annotations, and predictive capabilities, but existing resources for emotion recognition are often out-of-domain, narrowly labeled, and focused on post-hoc detection. To address this, we conducted a controlled Wizard of Oz (WOZ) experiment to elicit interactions with targeted affective trajectories. The resulting corpus, EmoWOZ-CS, contains 2,148 bilingual (Dutch-English) written dialogues from 179 participants across commercial aviation, e-commerce, online travel agencies, and telecommunication scenarios. Our contributions are threefold: (1) Evaluate WOZ-based operator-steered valence trajectories as a design for emotion research; (2) Quantify human annotation performance and variation, including divergences between self-reports and third-party judgments; (3) Benchmark detection and forward-looking emotion inference in real-time support. Findings show neutral dominates participant messages; desire and gratitude are the most frequent non-neutral emotions. Agreement is moderate for multilabel emotions and valence, lower for arousal and dominance; self-reports diverge notably from third-party labels, aligning most for neutral, gratitude, and anger. Objective strategies often elicit neutrality or gratitude, while suboptimal strategies increase anger, annoyance, disappointment, desire, and confusion. Some affective strategies (cheerfulness, gratitude) foster positive reciprocity, whereas others (apology, empathy) can also leave desire, anger, or annoyance. Temporal analysis confirms successful conversation-level steering toward prescribed trajectories, most distinctly for negative targets; positive and neutral targets yield similar final valence distributions. Benchmarks highlight the difficulty of forward-looking emotion inference from prior turns, underscoring the complexity of proactive emotion-aware support.

</details>


### [52] [Tracing How Annotators Think: Augmenting Preference Judgments with Reading Processes](https://arxiv.org/abs/2511.21912)
*Karin de Langis,William Walker,Khanh Chi Le,Dongyeop Kang*

Main category: cs.CL

TL;DR: 通过捕捉标注者的阅读过程，构建PreferRead数据集，发现阅读行为与标注一致性相关，揭示了阅读过程对主观NLP任务标注可靠性的影响。


<details>
  <summary>Details</summary>
Motivation: 现有标注方法主要关注标签，缺乏对标注者认知过程的刻画。本文旨在通过捕捉阅读过程，深入理解标注者决策机制及其对标注一致性的影响，以提升主观NLP任务的标注质量。

Method: 通过鼠标追踪技术记录标注者的细粒度阅读行为，并在偏好标注任务中创建PreferRead数据集，分析标注者在题干与两个候选回答间的阅读路径与选择偏好。

Result: 该论文提出了一种新的标注方法，不仅捕捉标注标签，还记录标注者的阅读过程，如关注的文本部分、重读或快速浏览。通过该方法，构建了包含细粒度阅读行为的PreferRead数据集。研究发现，标注者往往会重读他们最终选择的回答，而很少重读题干，且重读行为与较高的标注者一致性相关；相反，较长的阅读路径和时间则与较低的一致性关联。该研究揭示了阅读行为作为理解标注者可靠性、决策和分歧的重要认知维度。

Conclusion: 阅读行为是理解标注者决策和分歧的重要认知维度，重读常与较高的一致性相关，复杂的阅读路径则可能导致一致性降低。该方法为提升主观NLP任务标注质量提供了新视角。

Abstract: We propose an annotation approach that captures not only labels but also the reading process underlying annotators' decisions, e.g., what parts of the text they focus on, re-read or skim. Using this framework, we conduct a case study on the preference annotation task, creating a dataset PreferRead that contains fine-grained annotator reading behaviors obtained from mouse tracking. PreferRead enables detailed analysis of how annotators navigate between a prompt and two candidate responses before selecting their preference. We find that annotators re-read a response in roughly half of all trials, most often revisiting the option they ultimately choose, and rarely revisit the prompt. Reading behaviors are also significantly related to annotation outcomes: re-reading is associated with higher inter-annotator agreement, whereas long reading paths and times are associated with lower agreement. These results demonstrate that reading processes provide a complementary cognitive dimension for understanding annotator reliability, decision-making and disagreement in complex, subjective NLP tasks. Our code and data are publicly available.

</details>


### [53] [A Comparative Study of LLM Prompting and Fine-Tuning for Cross-genre Authorship Attribution on Chinese Lyrics](https://arxiv.org/abs/2511.21930)
*Yuxin Li,Lorraine Xu,Meng Fan Wang*

Main category: cs.CL

TL;DR: 本文提出了中文歌词作者归属的新数据集和领域模型，验证了风格对归属准确率的影响，微调模型在真实复杂数据上优于零样本大模型，强调了跨风格评价的重要性。


<details>
  <summary>Details</summary>
Motivation: 中文歌词作者归属领域缺少干净的公开数据集，且不同歌词风格的属性识别表现未知

Method: 创建多风格的平衡中文歌词数据集，开发并微调专门的领域模型，并与DeepSeek大语言模型的零样本推断进行性能比较

Result: 微调模型在真实和复杂数据上表现更稳健，结构化风格的归属准确率显著高于抽象风格，微调对小规模合成数据集的提升有限且效果模糊

Conclusion: 建立了中文歌词跨风格作者归属基准，建议扩展测试集多样性、减少基于词元的数据增强、平衡作者分布以及探索领域自适应预训练以提升归属性能。

Abstract: We propose a novel study on authorship attribution for Chinese lyrics, a domain where clean, public datasets are sorely lacking. Our contributions are twofold: (1) we create a new, balanced dataset of Chinese lyrics spanning multiple genres, and (2) we develop and fine-tune a domain-specific model, comparing its performance against zero-shot inference using the DeepSeek LLM.
  We test two central hypotheses. First, we hypothesize that a fine-tuned model will outperform a zero-shot LLM baseline. Second, we hypothesize that performance is genre-dependent. Our experiments strongly confirm Hypothesis 2: structured genres (e.g. Folklore & Tradition) yield significantly higher attribution accuracy than more abstract genres (e.g. Love & Romance). Hypothesis 1 receives only partial support: fine-tuning improves robustness and generalization in Test1 (real-world data and difficult genres), but offers limited or ambiguous gains in Test2, a smaller, synthetically-augmented set. We show that the design limitations of Test2 (e.g., label imbalance, shallow lexical differences, and narrow genre sampling) can obscure the true effectiveness of fine-tuning.
  Our work establishes the first benchmark for cross-genre Chinese lyric attribution, highlights the importance of genre-sensitive evaluation, and provides a public dataset and analytical framework for future research. We conclude with recommendations: enlarge and diversify test sets, reduce reliance on token-level data augmentation, balance author representation across genres, and investigate domain-adaptive pretraining as a pathway for improved attribution performance.

</details>


### [54] [Start Making Sense(s): A Developmental Probe of Attention Specialization Using Lexical Ambiguity](https://arxiv.org/abs/2511.21974)
*Pamela D. Rivière,Sean Trott*

Main category: cs.CL

TL;DR: 本文通过分析不同规模Transformer语言模型中的注意力头发展，揭示了词义消歧背后的专门化机制及其鲁棒性差异，强调发展性研究视角的重要性。


<details>
  <summary>Details</summary>
Motivation: 明确自注意力机制在Transformer语言模型中的具体可解释计算功能及专门化注意头的形成过程。

Method: 利用词义歧义作为切入点，通过分析不同规模的预训练模型（14M和410M）的注意力头随训练发展的表现变化，进行稳健性测试及因果分析。

Result: 识别出与词义消歧性能相关的注意力头，发现较小模型（14M）中的头对位置和词性敏感，表现有限鲁棒性；较大模型（410M）中存在行为更普适且鲁棒的注意力头。去除这些头会显著降低消歧性能。

Conclusion: 词义消歧依赖多机制集合，较大模型能形成更鲁棒的专门化注意力头，发展性视角有助理解语言模型内部机制。

Abstract: Despite an in-principle understanding of self-attention matrix operations in Transformer language models (LMs), it remains unclear precisely how these operations map onto interpretable computations or functions--and how or when individual attention heads develop specialized attention patterns. Here, we present a pipeline to systematically probe attention mechanisms, and we illustrate its value by leveraging lexical ambiguity--where a single word has multiple meanings--to isolate attention mechanisms that contribute to word sense disambiguation. We take a "developmental" approach: first, using publicly available Pythia LM checkpoints, we identify inflection points in disambiguation performance for each LM in the suite; in 14M and 410M, we identify heads whose attention to disambiguating words covaries with overall disambiguation performance across development. We then stress-test the robustness of these heads to stimulus perturbations: in 14M, we find limited robustness, but in 410M, we identify multiple heads with surprisingly generalizable behavior. Then, in a causal analysis, we find that ablating the target heads demonstrably impairs disambiguation performance, particularly in 14M. We additionally reproduce developmental analyses of 14M across all of its random seeds. Together, these results suggest: that disambiguation benefits from a constellation of mechanisms, some of which (especially in 14M) are highly sensitive to the position and part-of-speech of the disambiguating cue; and that larger models (410M) may contain heads with more robust disambiguation behavior. They also join a growing body of work that highlights the value of adopting a developmental perspective when probing LM mechanisms.

</details>


### [55] [AfriStereo: A Culturally Grounded Dataset for Evaluating Stereotypical Bias in Large Language Models](https://arxiv.org/abs/2511.22016)
*Yann Le Beux,Oluchi Audu,Oche D. Ankeli,Dhananjay Balakrishnan,Melissah Weya,Marie D. Ralaiarinosy,Ignatius Ezeani*

Main category: cs.CL

TL;DR: 提出了首个基于非洲社会文化背景的开放式刻板印象数据集AfriStereo，评估发现主流语言模型存在显著非洲相关偏见，促进更公平和具有地区背景的NLP技术发展。


<details>
  <summary>Details</summary>
Motivation: 现有的AI偏见评估基准主要反映西方视角，非洲背景被严重低估，导致应用中出现有害的刻板印象。

Method: 通过社区参与，在塞内加尔、肯尼亚和尼日利亚收集1163条涵盖性别、种族、宗教、年龄和职业的刻板印象，利用少量样本提示和人工验证将数据扩展至5000多对刻板印象-反刻板印象，并通过语义聚类和人工标注进行验证。

Result: 在对11个语言模型的初步评估中，有9个表现出显著偏见，刻板印象偏好比率在0.63到0.78之间，尤其在年龄、职业和性别方面偏见明显。领域特定模型表现出较弱的偏见。

Conclusion: AfriStereo为未来基于文化背景的偏见评估和缓解研究提供了途径和方法，有助于建立更全球包容和情境感知的人工智能系统。

Abstract: Existing AI bias evaluation benchmarks largely reflect Western perspectives, leaving African contexts underrepresented and enabling harmful stereotypes in applications across various domains. To address this gap, we introduce AfriStereo, the first open-source African stereotype dataset and evaluation framework grounded in local socio-cultural contexts. Through community engaged efforts across Senegal, Kenya, and Nigeria, we collected 1,163 stereotypes spanning gender, ethnicity, religion, age, and profession. Using few-shot prompting with human-in-the-loop validation, we augmented the dataset to over 5,000 stereotype-antistereotype pairs. Entries were validated through semantic clustering and manual annotation by culturally informed reviewers. Preliminary evaluation of language models reveals that nine of eleven models exhibit statistically significant bias, with Bias Preference Ratios (BPR) ranging from 0.63 to 0.78 (p <= 0.05), indicating systematic preferences for stereotypes over antistereotypes, particularly across age, profession, and gender dimensions. Domain-specific models appeared to show weaker bias in our setup, suggesting task-specific training may mitigate some associations. Looking ahead, AfriStereo opens pathways for future research on culturally grounded bias evaluation and mitigation, offering key methodologies for the AI community on building more equitable, context-aware, and globally inclusive NLP technologies.

</details>


### [56] [ResearchArcade: Graph Interface for Academic Tasks](https://arxiv.org/abs/2511.22036)
*Jingjun Xu,Chongshan Lin,Haofei Yu,Tao Feng,Jiaxuan You*

Main category: cs.CL

TL;DR: 本文提出ResearchArcade，一个统一的基于图的多源多模态学术数据接口，支持多学术任务和模型，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 随着学术研究数据多样化及机器学习应用需求增多，迫切需要一个统一的数据接口以支持多任务、跨源信息融合，加速学术知识发现。

Method: 研究提出了ResearchArcade，这是一种基于图的统一数据接口，整合了多种学术数据源（如ArXiv学术文献、OpenReview同行评审）和多模态信息（文本、图像、表格），采用多表格格式和图结构组织数据，同时保留论文及学术社区的时间演变信息。该接口统一了多样的学术任务定义，支持多种基础模型的输入需求。

Result: 通过在六个学术任务上的实验，研究发现结合跨源和多模态信息能够支持更广泛的任务，且引入图结构的模型性能优于基线方法。

Conclusion: ResearchArcade有效提升了多源多模态学术数据的协同利用，促进了多样化学术任务的完成，展示了加速知识发现和推进科研进展的潜力。

Abstract: Academic research generates diverse data sources, and as researchers increasingly use machine learning to assist research tasks, a crucial question arises: Can we build a unified data interface to support the development of machine learning models for various academic tasks? Models trained on such a unified interface can better support human researchers throughout the research process, eventually accelerating knowledge discovery. In this work, we introduce ResearchArcade, a graph-based interface that connects multiple academic data sources, unifies task definitions, and supports a wide range of base models to address key academic challenges. ResearchArcade utilizes a coherent multi-table format with graph structures to organize data from different sources, including academic corpora from ArXiv and peer reviews from OpenReview, while capturing information with multiple modalities, such as text, figures, and tables. ResearchArcade also preserves temporal evolution at both the manuscript and community levels, supporting the study of paper revisions as well as broader research trends over time. Additionally, ResearchArcade unifies diverse academic task definitions and supports various models with distinct input requirements. Our experiments across six academic tasks demonstrate that combining cross-source and multi-modal information enables a broader range of tasks, while incorporating graph structures consistently improves performance over baseline methods. This highlights the effectiveness of ResearchArcade and its potential to advance research progress.

</details>


### [57] [Early Risk Prediction with Temporally and Contextually Grounded Clinical Language Processing](https://arxiv.org/abs/2511.22038)
*Rochana Chaturvedi,Yue Zhou,Andrew Boyd,Brian T. Layden,Mudassir Rashid,Lu Cheng,Ali Cinar,Barbara Di Eugenio*

Main category: cs.CL

TL;DR: 本文针对电子健康记录中的临床笔记，提出了结合时间结构和医学知识的图神经网络和轻量级大模型推理蒸馏方法，有效提升了2型糖尿病风险预测的准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录中的临床笔记包含丰富的时间信息，这些信息对于及时识别慢性疾病具有重要意义，但提取和利用这些信息面临自然语言处理的挑战。

Method: 提出了两种互补的方法：HiTGNN，一种分层时序图神经网络，整合笔记内事件结构、访视间动态和医学知识；以及ReVeAL，一个轻量级推理蒸馏框架，将大语言模型的推理迁移至小型验证模型。

Result: HiTGNN在预测2型糖尿病风险时达到了最高准确率，尤其在短期风险预测上表现优异，同时保护了隐私，并减少对大型专有模型的依赖。ReVeAL提升了对真实病例的敏感性并保持了解释能力。消融实验和公平性分析验证了方法的有效性和公平性。

Conclusion: 结合细粒度时间结构和医学知识的图神经网络方法能显著提升慢性病风险预测的准确率和公平性，轻量级推理模型则提升了模型实用性和解释性。

Abstract: Clinical notes in Electronic Health Records (EHRs) capture rich temporal information on events, clinician reasoning, and lifestyle factors often missing from structured data. Leveraging them for predictive modeling can be impactful for timely identification of chronic diseases. However, they present core natural language processing (NLP) challenges: long text, irregular event distribution, complex temporal dependencies, privacy constraints, and resource limitations. We present two complementary methods for temporally and contextually grounded risk prediction from longitudinal notes. First, we introduce HiTGNN, a hierarchical temporal graph neural network that integrates intra-note temporal event structures, inter-visit dynamics, and medical knowledge to model patient trajectories with fine-grained temporal granularity. Second, we propose ReVeAL, a lightweight, test-time framework that distills the reasoning of large language models into smaller verifier models. Applied to opportunistic screening for Type 2 Diabetes (T2D) using temporally realistic cohorts curated from private and public hospital corpora, HiTGNN achieves the highest predictive accuracy, especially for near-term risk, while preserving privacy and limiting reliance on large proprietary models. ReVeAL enhances sensitivity to true T2D cases and retains explanatory reasoning. Our ablations confirm the value of temporal structure and knowledge augmentation, and fairness analysis shows HiTGNN performs more equitably across subgroups.

</details>


### [58] [A Hybrid Theory and Data-driven Approach to Persuasion Detection with Large Language Models](https://arxiv.org/abs/2511.22109)
*Gia Bao Hoang,Keith J Ransom,Rachel Stephens,Carolyn Semmler,Nicolas Fay,Lewis Mitchell*

Main category: cs.CL

TL;DR: 本文利用大型语言模型结合心理学特征，建立模型预测在线文本说服效果，发现“认知情绪”和“分享意愿”是关键预测因子，促进虚假信息防范等多领域应用。


<details>
  <summary>Details</summary>
Motivation: 传统心理学模型侧重于面对面交流中的信念修正，但社交媒体的发展需要更有效的模型来捕捉大规模在线文本交互中的信念变化。

Method: 采用混合方法，利用大型语言模型（LLMs）根据心理学实验中的特征，构建随机森林分类模型预测说服成功与否。

Result: 模型测试了八个特征，其中“认知情绪”和“分享意愿”是预测信念变化的最重要因素。

Conclusion: 研究揭示了说服信息的关键特征，证明LLMs能加强基于心理学理论的说服模型，对在线影响检测、虚假信息缓解及叙事效果测量有广泛应用。

Abstract: Traditional psychological models of belief revision focus on face-to-face interactions, but with the rise of social media, more effective models are needed to capture belief revision at scale, in this rich text-based online discourse. Here, we use a hybrid approach, utilizing large language models (LLMs) to develop a model that predicts successful persuasion using features derived from psychological experiments.
  Our approach leverages LLM generated ratings of features previously examined in the literature to build a random forest classification model that predicts whether a message will result in belief change. Of the eight features tested, \textit{epistemic emotion} and \textit{willingness to share} were the top-ranking predictors of belief change in the model. Our findings provide insights into the characteristics of persuasive messages and demonstrate how LLMs can enhance models of successful persuasion based on psychological theory. Given these insights, this work has broader applications in fields such as online influence detection and misinformation mitigation, as well as measuring the effectiveness of online narratives.

</details>


### [59] [Bridging the Modality Gap by Similarity Standardization with Pseudo-Positive Samples](https://arxiv.org/abs/2511.22141)
*Shuhei Yamashita,Daiki Shirafuji,Tatsuhiko Saito*

Main category: cs.CL

TL;DR: 本文针对视觉-语言模型中不同模态间相似度量纲不一致的问题（模态差距）提出了一种基于伪数据构建的相似度标准化方法，显著提升了跨模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 在包含文本和图像的数据库中，现有的视觉-语言模型由于模态间相似度分数的尺度差异，导致检索效果不佳，且多数方法依赖人工标注数据进行调优。

Method: 本文通过构建伪数据对，计算每个查询与其文本或图像配对数据之间相似度的均值和方差，利用这些模态特定的统计量对所有相似度分数进行标准化，实现跨模态在统一尺度上的比较。

Result: 在七个视觉-语言模型和两个多模态问答基准（MMQA和WebQA）上进行评估，方法显著提升了跨模态检索性能，在不同模态查询和目标数据情况下，MMQA上的Recall@20提升64%，WebQA提升28%，优于基于图像标题生成的E5-V方法。

Conclusion: 提出的基于伪数据构建的相似度标准化方法有效消除了模态差距，提升了视觉-语言模型的跨模态检索能力，优于现有依赖图像标题的解决方案。

Abstract: Advances in vision-language models (VLMs) have enabled effective cross-modality retrieval. However, when both text and images exist in the database, similarity scores would differ in scale by modality. This phenomenon, known as the modality gap, hinders accurate retrieval. Most existing studies address this issue with manually labeled data, e.g., by fine-tuning VLMs on them. In this work, we propose a similarity standardization approach with pseudo data construction. We first compute the mean and variance of the similarity scores between each query and its paired data in text or image modality. Using these modality-specific statistics, we standardize all similarity scores to compare on a common scale across modalities. These statistics are calculated from pseudo pairs, which are constructed by retrieving the text and image candidates with the highest cosine similarity to each query. We evaluate our method across seven VLMs using two multi-modal QA benchmarks (MMQA and WebQA), where each question requires retrieving either text or image data. Our experimental results show that our method significantly improves retrieval performance, achieving average Recall@20 gains of 64% on MMQA and 28% on WebQA when the query and the target data belong to different modalities. Compared to E5-V, which addresses the modality gap through image captioning, we confirm that our method more effectively bridges the modality gap.

</details>


### [60] [C$^2$DLM: Causal Concept-Guided Diffusion Large Language Models](https://arxiv.org/abs/2511.22146)
*Kairong Han,Nuanqiao Shan,Ziyu Zhao,Zijing Hu,Xinpeng Dong,Junjian Ye,Lujia Pan,Fei Wu,Kun Kuang*

Main category: cs.CL

TL;DR: 本文提出了一种因果概念引导的扩散语言模型C$^2$DLM，旨在提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型和扩散模型在推理能力上不足，原因在于它们未充分利用自然语言中的因果结构。自回归模型严格按序列顺序建模，而扩散模型忽略了因果顺序。

Method: C$^2$DLM从扩散模型的全连接注意力出发，通过教师模型获取概念级因果图，并显式引导注意力机制学习概念间的因果关系，避免因果逆转带来的干扰。

Result: C$^2$DLM在COT-OrderPerturb任务上提升了12%的性能，训练速度提升约3.2倍，在六个下游推理任务中的平均性能提升1.31%。

Conclusion: 通过引入因果概念图引导，C$^2$DLM有效提升了语言模型的推理能力和训练效率，展示了因果知识在语言模型中的重要作用。

Abstract: Autoregressive (AR) language models and Diffusion Language Models (DLMs) constitute the two principal paradigms of large language models. However, both paradigms suffer from insufficient reasoning capabilities. Human reasoning inherently relies on causal knowledge and thought, which are reflected in natural language. But in the AR paradigm, language is modeled as next token prediction (a strictly left-to-right, token-by-token order), whereas natural language itself exhibits more flexible causal structures. In the DLM paradigm, the attention mechanism is fully connected, which entirely disregards causal order. To fill this gap, we propose a \underline{\textbf{C}}ausal \underline{\textbf{C}}oncept-Guided \underline{\textbf{D}}iffusion \underline{\textbf{L}}anguage \underline{\textbf{M}}odel (C$^2$DLM). Starting from DLM's fully connected attention, C$^2$DLM first obtains a concept-level causal graph from the teacher model, and then explicitly guides attention to learn causal relationships between concepts. By focusing on causal relationships and avoiding interference from difficult subgoals involving causal inversion, C$^2$DLM improves 12\% with about 3.2 times training speedup in the COT-OrderPerturb task, and achieves an average gain of 1.31\% across six downstream reasoning tasks. More details in the repository ~\href{https://github.com/Kairong-Han/C-2-DLM}{here}.

</details>


### [61] [A Theoretically Grounded Hybrid Ensemble for Reliable Detection of LLM-Generated Text](https://arxiv.org/abs/2511.22153)
*Sepyan Purnama Kristanto,Lutfi Hakim*

Main category: cs.CL

TL;DR: 本论文提出了一种结合深度语义、概率模型和统计语言特征的混合集成大语言模型文本检测器，显著提升了准确率和降低假阳性率，适用于学术文本检测。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型广泛应用，机器生成文本与人类作品界限模糊，学术诚信和信息可靠性面临风险，现有单一方法检测效果不足。

Method: 提出一种理论基础的混合集成方法，融合基于RoBERTa的深度语义特征提取、基于GPT-2的扰动似然曲率概率检测和统计语言风格分析，并通过在概率单纯形上优化加权投票权重以最大化F1分数。

Result: 提出了一种基于RoBERTa、GPT-2和统计语言特征融合的混合集成文本检测方法，在大规模多生成器语料上达到94.2%的准确率和0.978的AUC。该方法通过学习加权投票提升F1分数，且在学术文本中显著降低了35%的假阳性率。

Conclusion: 该混合集成检测器表现出良好的泛化能力和较低的假阳性率，适合在教育等高风险领域中实际应用，有助于维护学术诚信和信息可靠性。

Abstract: The rapid proliferation of Large Language Models (LLMs) has blurred the line between human and machine authorship, creating practical risks for academic integrity and information reliability. Existing text detectors typically rely on a single methodological paradigm and suffer from poor generalization and high false positive rates (FPR), especially on high-stakes academic text. We propose a theoretically grounded hybrid ensemble that systematically fuses three complementary detection paradigms: (i) a RoBERTa-based transformer classifier for deep semantic feature extraction, (ii) a GPT-2-based probabilistic detector using perturbation-induced likelihood curvature, and (iii) a statistical linguistic feature analyzer capturing stylometric patterns. The core novelty lies in an optimized weighted voting framework, where ensemble weights are learned on the probability simplex to maximize F1-score rather than set heuristically. We provide a bias-variance analysis and empirically demonstrate low inter-model correlation (rho ~ 0.35-0.42), a key condition for variance reduction. Evaluated on a large-scale, multigenerator corpus of 30,000 documents, our system achieves 94.2% accuracy and an AUC of 0.978, with a 35% relative reduction in false positives on academic text. This yields a more reliable and ethically responsible detector for real-world deployment in education and other high-stakes domains.

</details>


### [62] [Lips-Jaw and Tongue-Jaw Articulatory Tradeoff in DYNARTmo](https://arxiv.org/abs/2511.22155)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 本文通过动态发音模型DYNARTmo分析了发音协调中的发音器官权衡，模拟结果与实证数据吻合，体现了模型的有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何动态发音模型能够刻画主要和次要发音器官之间的协同与权衡，尤其聚焦唇-颚和舌-颚的协调机制。

Method: 在DYNARTmo模型中采用一阶任务空间手势规格，结合简化的发音器官发力分配机制，并通过模拟不同发音部位和元音背景的CV音节进行验证。

Result: 模拟显示颚部位移随发音部位和元音变化，模型成功重现了实证中的发音协同现象，如舌-颚共动、双唇阻碍时下唇抬升等，体现了发音权衡的时空动态特征。

Conclusion: DYNARTmo模型虽然采用简化的一阶任务空间规格，但能够有效再现唇-颚和舌-颚之间关键的发音协同和权衡现象，体现了动态运动学方法在建模发音机制上的潜力。

Abstract: This paper investigates how the dynamic articulatory model DYNARTmo accounts for articulatory tradeoffs between primary and secondary articulators, with a focus on lips-jaw and tongue-jaw coordination. While DYNARTmo does not implement full task-dynamic second-order biomechanics, it adopts first-order task-space gesture specifications comparable to those used in articulatory phonology and integrates a simplified mechanism for distributing articulatory effort across multiple articulators. We first outline the conceptual relationship between task dynamics and DYNARTmo, emphasizing the distinction between high-level task-space trajectories and their low-level articulatory execution. We then present simulation results for a set of CV syllables that illustrate how jaw displacement varies as a function of both place of articulation (labial, apical, dorsal) and vowel context (/a/, /i/, /u/). The model reproduces empirically attested patterns of articulatory synergy, including jaw-supported apical closures, lower-lip elevation in bilabial stops, tongue-jaw co-movement, and saturation effects in labial constrictions. These results demonstrate that even with computationally simplified assumptions, DYNARTmo can generate realistic spatio-temporal movement patterns that capture key aspects of articulatory tradeoff and synergy across a range of consonant-vowel combinations.

</details>


### [63] [RefineBench: Evaluating Refinement Capability of Language Models via Checklists](https://arxiv.org/abs/2511.22173)
*Young-Jun Lee,Seungone Kim,Byung-Kwan Lee,Minkyeong Moon,Yechan Hwang,Jong Myoung Kim,Graham Neubig,Sean Welleck,Ho-Jin Choi*

Main category: cs.CL

TL;DR: 研究建立RefineBench基准测试语言模型自我改进能力，发现在无指导下顶尖模型表现有限，有指导反馈则能快速提升，表明自我改进仍具挑战。


<details>
  <summary>Details</summary>
Motivation: 现实中用户交互常涉及对语言模型回答的改进请求，现有研究多集中于可验证性强的任务，缺乏对开放式问题和多样反馈的考察，且新兴链式思维模型表现出自我反思能力，促使探索LM自我改进能力的需求。

Method: 构建跨11领域的1000题RefineBench基准，设计基于清单的评估指标，测试两种改进模式：1）有指导的改进，依据自然语言反馈优化回答；2）无指导的自我改进，不依赖反馈尝试提升回答，比较多款先进LM的表现。

Result: 本文设计了RefineBench基准，包含1000个跨11个领域的挑战性问题及基于清单的评估框架，用于测试语言模型（LM）自我改进回答能力。研究比较了有指导的改进（基于自然语言反馈）与无指导的自我改进两种模式。结果显示：在无指导自我改进中，即使是最先进的模型如Gemini 2.5 Pro和GPT-5，表现也较弱（分别为31.3%和29.1%准确率，且迭代中表现提升有限）；而有指导改进中，多数大模型通过反馈能在五轮内达到近乎完美的答案。结论是当前顶尖语言模型在自我改进不正确回答方面仍需重大突破，RefineBench为该领域进展提供了重要测试工具。

Conclusion: 顶尖语言模型的无指导自我改进能力有限，很难持续提升回答质量；在有针对性反馈指导下，模型能快速显著改进。未来模型自我反思与改进机制需突破，RefineBench为评估此类能力提供有效平台。

Abstract: Can language models (LMs) self-refine their own responses? This question is increasingly relevant as a wide range of real-world user interactions involve refinement requests. However, prior studies have largely tested LMs' refinement abilities on verifiable tasks such as competition math or symbolic reasoning with simplified scaffolds, whereas users often pose open-ended queries and provide varying degrees of feedback on what they desire. The recent advent of reasoning models that exhibit self-reflection patterns in their chains-of-thought further motivates this question. To analyze this, we introduce RefineBench, a benchmark of 1,000 challenging problems across 11 domains paired with a checklist-based evaluation framework. We evaluate two refinement modes: (1) guided refinement, where an LM is provided natural language feedback, and (2) self-refinement, where LMs attempt to improve without guidance. In the self-refinement setting, even frontier LMs such as Gemini 2.5 Pro and GPT-5 achieve modest baseline scores of 31.3% and 29.1%, respectively, and most models fail to consistently improve across iterations (e.g., Gemini-2.5-Pro gains only +1.8%, while DeepSeek-R1 declines by -0.1%). By contrast, in guided refinement, both proprietary LMs and large open-weight LMs (>70B) can leverage targeted feedback to refine responses to near-perfect levels within five turns. These findings suggest that frontier LMs require breakthroughs to self-refine their incorrect responses, and that RefineBench provides a valuable testbed for tracking progress.

</details>


### [64] [Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information](https://arxiv.org/abs/2511.22176)
*Lukas Struppek,Dominik Hintersdorf,Hannah Struppek,Daniel Neider,Kristian Kersting*

Main category: cs.CL

TL;DR: 本文提出F-CoT方法，通过结构化关键上下文，显著减少推理过程中的冗余信息，实现高效且准确的语言模型推理。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽具有强大推理能力，但在生成详尽的思维链时，容易产生过多无关信息，导致推理效率低下。

Method: 提出了一种训练无关、以输入为中心的方法——Focused Chain-of-Thought（F-CoT）。该方法先从查询中提取关键信息，构建简洁结构化的上下文，然后引导模型仅基于该上下文进行推理，避免关注无关细节。

Result: 在算术文字题上，F-CoT生成的token数量减少了2-3倍，同时保持了与标准零样本CoT相当的准确率。

Conclusion: 通过结构化输入，F-CoT有效提升了大型语言模型推理的效率，提供了一种简单且有效的推理改进途径。

Abstract: Recent large language models achieve strong reasoning performance by generating detailed chain-of-thought traces, but this often leads to excessive token use and high inference latency. Existing efficiency approaches typically focus on model-centric interventions, such as reinforcement learning or supervised fine-tuning, to reduce verbosity. In contrast, we propose a training-free, input-centric approach. Inspired by cognitive psychology, we introduce Focused Chain-of-Thought (F-CoT), which separates information extraction from the reasoning process. F-CoT first organizes the essential information from a query into a concise, structured context and then guides the model to reason exclusively over this context. By preventing attention to irrelevant details, F-CoT naturally produces shorter reasoning paths. On arithmetic word problems, F-CoT reduces generated tokens by 2-3x while maintaining accuracy comparable to standard zero-shot CoT. These results highlight structured input as a simple yet effective lever for more efficient LLM reasoning.

</details>


### [65] [Beyond Query-Level Comparison: Fine-Grained Reinforcement Learning for Text-to-SQL with Automated Interpretable Critiques](https://arxiv.org/abs/2511.22258)
*Guifeng Wang,Yuanfeng Song,Meng Yang,Tao Zhu,Xiaoming Yin,Xing Chen*

Main category: cs.CL

TL;DR: 针对文本到SQL任务中评价机制粗糙和人工注释成本高的问题，RuCo-C提出自动生成细粒度评价规则与解释性批评，结合动态奖励策略，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到SQL模型的评估依赖手工标注的金标准SQL，成本高且难以大规模应用；且强化学习奖励信号过于粗糙，忽略结构和语义的细节错误。

Method: RuCo-C自动生成查询特定的评价规则，并用可解释的批评指导训练，采用“渐进式探索”动态调整强化学习奖励，实现细粒度反馈。

Result: 实验结果表明，RuCo-C在文本到SQL的评价任务上优于现有方法，显著提升模型性能。

Conclusion: 本文提出的RuCo-C模型有效解决了文本到SQL转换中的评估和奖励机制瓶颈，实现了无人工干预的细粒度自动评估，并通过强化学习提升了模型表现。

Abstract: Text-to-SQL, a pivotal natural language processing (NLP) task that converts textual queries into executable SQL, has seen substantial progress in recent years. However, existing evaluation and reward mechanisms used to train and assess the text-to-SQL models remain a critical bottleneck. Current approaches heavily rely on manually annotated gold SQL queries, which are costly to produce and impractical for large-scale evaluation. More importantly, most reinforcement learning (RL) methods in text-to-SQL leverage only the final binary execution outcome as the reward signal, a coarse-grained supervision that overlooks detailed structural and semantic errors from the perspective of rubrics. To address these challenges, we propose RuCo-C, a novel generative judge model for fine-grained, query-specific automatic evaluation using interpretable critiques without human intervention. Our framework first automatically generates query-specific evaluation rubrics for human-free annotation, linking them to interpretable critiques. Subsequently, it integrates densified reward feedback through a "progressive exploration" strategy during the RL training process, which dynamically adjusts the rewards to enhance the model's performance. Comprehensive experiments demonstrate that RuCo-C outperforms existing methods in text-to-SQL evaluation, yielding significant performance gains.

</details>


### [66] [Token-Level Marginalization for Multi-Label LLM Classifiers](https://arxiv.org/abs/2511.22312)
*Anjaneya Praharaj,Jaykumar Kasundra*

Main category: cs.CL

TL;DR: 本文提出三种token级概率估计方法，解决了生成式语言模型缺乏类别置信度的难题，提升了内容安全多标签分类的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 生成式语言模型虽能检测不安全内容及类别，但缺乏直接的类别概率，导致置信度评估和阈值设定困难，影响内容审核效果和误差分析。

Method: 设计并评估了三种基于token logits的概率估计方法，以推断分类置信度并增强模型的解释能力，并在多个instruction-tuned模型上测试其泛化性。

Result: 在严格标注的合成数据集上大规模实验表明，利用token级logits显著提升了生成模型分类的置信度表示和可解释性，使内容审核更细粒度和可靠。

Conclusion: 通过引入三种基于token概率估计的方法，本文有效提升了生成式语言模型在多标签内容安全分类任务中的置信度解释能力和模型表现，促进了分类器的可解释性和可靠性。

Abstract: This paper addresses the critical challenge of deriving interpretable confidence scores from generative language models (LLMs) when applied to multi-label content safety classification. While models like LLaMA Guard are effective for identifying unsafe content and its categories, their generative architecture inherently lacks direct class-level probabilities, which hinders model confidence assessment and performance interpretation. This limitation complicates the setting of dynamic thresholds for content moderation and impedes fine-grained error analysis. This research proposes and evaluates three novel token-level probability estimation approaches to bridge this gap. The aim is to enhance model interpretability and accuracy, and evaluate the generalizability of this framework across different instruction-tuned models. Through extensive experimentation on a synthetically generated, rigorously annotated dataset, it is demonstrated that leveraging token logits significantly improves the interpretability and reliability of generative classifiers, enabling more nuanced content safety moderation.

</details>


### [67] [Sentiment Analysis Of Shopee Product Reviews Using Distilbert](https://arxiv.org/abs/2511.22313)
*Zahri Aksa Dautd,Aviv Yuniar Rahman*

Main category: cs.CL

TL;DR: 本文使用 DistilBERT 模型对 Shopee 电商平台的百万级产品评论进行情感分析，达到高准确率且显著提升计算效率，适合大规模应用。


<details>
  <summary>Details</summary>
Motivation: 随着数字商务的快速发展，Shopee 平台积累了大量消费者评论，人工分析效率低，因而需要通过计算方法如情感分析来提取有价值的用户满意度和偏好信息。

Method: 使用 DistilBERT 这一轻量级基于 Transformer 的深度学习模型对 Shopee 产品评论进行情感分类。数据集包含约一百万条英语评论，使用 distilbert-base-uncased 模型进行预处理和训练。采用准确率、精确率、召回率、F1 分数等指标评估，并与 BERT 和支持向量机（SVM）进行比较。

Result: DistilBERT 达到 94.8% 的准确率，略低于 BERT 的 95.3%，远高于 SVM 的 90.2%，但计算时间减少超过 55%。

Conclusion: DistilBERT 在准确率和计算效率之间取得了最佳平衡，适合用于电商平台的大规模情感分析。

Abstract: The rapid growth of digital commerce has led to the accumulation of a massive number of consumer reviews on online platforms. Shopee, as one of the largest e-commerce platforms in Southeast Asia, receives millions of product reviews every day containing valuable information regarding customer satisfaction and preferences. Manual analysis of these reviews is inefficient, thus requiring a computational approach such as sentiment analysis. This study examines the use of DistilBERT, a lightweight transformer-based deep learning model, for sentiment classification on Shopee product reviews. The dataset used consists of approximately one million English-language reviews that have been preprocessed and trained using the distilbert-base-uncased model. Evaluation was conducted using accuracy, precision, recall, and F1-score metrics, and compared against benchmark models such as BERT and SVM. The results show that DistilBERT achieved an accuracy of 94.8%, slightly below BERT (95.3%) but significantly higher than SVM (90.2%), with computation time reduced by more than 55%. These findings demonstrate that DistilBERT provides an optimal balance between accuracy and efficiency, making it suitable for large scale sentiment analysis on e-commerce platforms. Keywords: Sentiment Analysis, DistilBERT, Shopee Reviews, Natural Language Processing, Deep Learning, Transformer Models.

</details>


### [68] [Named Entity Recognition for the Kurdish Sorani Language: Dataset Creation and Comparative Analysis](https://arxiv.org/abs/2511.22315)
*Bakhtawar Abdalla,Rebwar Mala Nabi,Hassan Eshkiki,Fabio Caraffini*

Main category: cs.CL

TL;DR: 该研究创建了库尔德语索拉尼方言命名实体识别数据集，发现传统机器学习模型优于神经网络模型，提示低资源语言任务中经典方法更有效。


<details>
  <summary>Details</summary>
Motivation: 推动自然语言处理技术在低资源且代表性不足的语言中的包容性和全球适用性，解决库尔德语索拉尼方言的资源缺乏问题。

Method: 制作大型标注数据集，开发通用辅助工具，利用经典机器学习（CRF）和神经网络（BiLSTM）模型进行比较实验，评估不同方法的性能。

Result: 构建了库尔德语索拉尼方言的首个命名实体识别数据集，包含64,563个标注语料，并提供了多语言支持的辅助工具。通过比较经典机器学习模型和神经网络方法，发现传统方法（如CRF）在低资源条件下表现优于基于BiLSTM的神经模型，F1值分别为0.825和0.706。

Conclusion: 在低资源语言的命名实体识别任务中，经典方法比神经网络模型表现更好，证明了更简单高效的方法在特定条件下更具优势。

Abstract: This work contributes towards balancing the inclusivity and global applicability of natural language processing techniques by proposing the first 'name entity recognition' dataset for Kurdish Sorani, a low-resource and under-represented language, that consists of 64,563 annotated tokens. It also provides a tool for facilitating this task in this and many other languages and performs a thorough comparative analysis, including classic machine learning models and neural systems. The results obtained challenge established assumptions about the advantage of neural approaches within the context of NLP. Conventional methods, in particular CRF, obtain F1-scores of 0.825, outperforming the results of BiLSTM-based models (0.706) significantly. These findings indicate that simpler and more computationally efficient classical frameworks can outperform neural architectures in low-resource settings.

</details>


### [69] [Mapping Clinical Doubt: Locating Linguistic Uncertainty in LLMs](https://arxiv.org/abs/2511.22402)
*Srivarshinee Sridhar,Raghav Kaushik Ravi,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: 本文通过层级探测分析了大型语言模型对临床文本中语言不确定性的内部表征，发现认知线索在深层次逐渐编码。


<details>
  <summary>Details</summary>
Motivation: 医疗场景中语言不确定性影响诊断决策，当前对大型语言模型内部如何表征这种不确定性尚不清楚，亟需研究其表征机制。

Method: 构建包含不同认知模态的临床语句对比数据集，提出分层探测指标模型对不确定性的敏感度（MSU），量化不确定性提示引起的激活层级变化。

Result: 大型语言模型在临床不确定性方面表现出结构化、随层级递进的敏感性，认知信息在较深层得到逐步编码。

Conclusion: 认知不确定性在大型语言模型内部有明确表征，揭示其可解释性和认知可靠性。

Abstract: Large Language Models (LLMs) are increasingly used in clinical settings, where sensitivity to linguistic uncertainty can influence diagnostic interpretation and decision-making. Yet little is known about where such epistemic cues are internally represented within these models. Distinct from uncertainty quantification, which measures output confidence, this work examines input-side representational sensitivity to linguistic uncertainty in medical text. We curate a contrastive dataset of clinical statements varying in epistemic modality (e.g., 'is consistent with' vs. 'may be consistent with') and propose Model Sensitivity to Uncertainty (MSU), a layerwise probing metric that quantifies activation-level shifts induced by uncertainty cues. Our results show that LLMs exhibit structured, depth-dependent sensitivity to clinical uncertainty, suggesting that epistemic information is progressively encoded in deeper layers. These findings reveal how linguistic uncertainty is internally represented in LLMs, offering insight into their interpretability and epistemic reliability.

</details>


### [70] [Exploring Performance Variations in Finetuned Translators of Ultra-Low Resource Languages: Do Linguistic Differences Matter?](https://arxiv.org/abs/2511.22482)
*Isabel Gonçalves,Paulo Cavalin,Claudio Pinhanez*

Main category: cs.CL

TL;DR: 研究发现超低资源语言翻译性能差异主要源于语言本身差异，而非训练数据或模型设置。


<details>
  <summary>Details</summary>
Motivation: 探究为何使用相似方法和数据微调的翻译模型在不同研究中表现差异显著，以明确影响翻译性能的关键因素。

Method: 系统性探索可能影响超低资源语言翻译器性能差异的因素，包括数据清洗流程、预训练模型限制、基础模型大小及训练数据集规模，采用对两种相关但结构语言特征显著不同的巴西土著语言进行双向翻译研究。

Result: 训练相关因素对性能差异影响甚微，表明语言本身特征差异可能是影响微调预训练模型生成翻译器能力的重要因素。

Conclusion: 性能差异主要源自语言间差异，而非数据预处理或模型训练参数，强调不同语言结构对模型微调表现的关键作用。

Abstract: Finetuning pre-trained language models with small amounts of data is a commonly-used method to create translators for ultra-low resource languages such as endangered Indigenous languages. However, previous works have reported substantially different performances with translators created using similar methodology and data. In this work we systematically explored possible causes of the performance difference, aiming to determine whether it was a product of different cleaning procedures, limitations of the pre-trained models, the size of the base model, or the size of the training dataset, studying both directions of translation. Our studies, using two Brazilian Indigenous languages, related but with significant structural linguistic characteristics, indicated none or very limited influence from those training factors, suggesting differences between languages may play a significant role in the ability to produce translators by fine-tuning pre-trained models.

</details>


### [71] [Joint Speech and Text Training for LLM-Based End-to-End Spoken Dialogue State Tracking](https://arxiv.org/abs/2511.22503)
*Katia Vendrame,Bolaji Yusuf,Santosh Kesiraju,Šimon Sedláček,Oldřich Plchot,Jan Černocký*

Main category: cs.CL

TL;DR: 本文提出一种联合利用语音和文本DST数据的训练方法，有效提升跨领域语音对话状态跟踪性能，减少对目标领域语音标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 语音DST面临数据稀缺和跨领域泛化困难，文本DST数据相对易得，因此利用文本数据辅助训练以提升模型跨领域能力。

Method: 提出一种联合训练方法，同时利用有标签的语音对话状态跟踪（DST）数据和来自不同领域的文本DST数据，结合语音基础编码器与大语言模型，实现跨领域泛化。

Result: 实验表明该联合训练方法能够有效提升跨领域DST的性能，且无需目标领域的语音训练数据。

Conclusion: 通过融合语音和文本数据训练，能缓解数据稀缺和跨领域泛化难题，提升端到端语音DST模型的实用性和通用性。

Abstract: End-to-end spoken dialogue state tracking (DST) is made difficult by the tandem of having to handle speech input and data scarcity. Combining speech foundation encoders and large language models has been proposed in recent work as to alleviate some of this difficulty. Although this approach has been shown to result in strong spoken DST models, achieving state-of-the-art performance in realistic multi-turn DST, it struggles to generalize across domains and requires annotated spoken DST training data for each domain of interest. However, collecting such data for every target domain is both costly and difficult. Noting that textual DST data is more easily obtained for various domains, in this work, we propose jointly training on available spoken DST data and written textual data from other domains as a way to achieve cross-domain generalization. We conduct experiments which show the efficacy of our proposed method for getting good cross-domain DST performance without relying on spoken training data from the target domains.

</details>


### [72] [Extension Condition "violations" and Merge optimality constraints](https://arxiv.org/abs/2511.22582)
*Matilde Marcolli,Richard Larson,Riny Huijbregts*

Main category: cs.CL

TL;DR: 文章利用Strong Minimalist Thesis的Merge数学模型，解释了多种语言现象，证明这些现象不违反Extension Condition，揭示EC作为模型内在代数约束的重要性，并分析了最优性违规对语言结构动态的影响。


<details>
  <summary>Details</summary>
Motivation: 传统语言分析中的多种复杂现象被认为会违反Extension Condition，文章旨在用数学形式化的Merge方法明确这些现象的结构本质，避免引入额外假设，同时理解最优性违规的具体作用机制。

Method: 使用Strong Minimalist Thesis框架中的数学形式化Merge，对一系列语言现象进行分析，包括head-to-head移动、短语词缀、句法附着词、动词-小品词交替和操作数-变量现象。通过引入Sideward Merge方法，避免了Extension Condition（EC）的违规。研究还结合最优性理论中的资源限制，以解释不同现象的最优性违规差异，并探讨多重wh前置、罗曼语言中的附着词簇及韩语的所有者一致性构造。

Result: 发现所有列举的语言现象均可通过Sideward Merge解释，且不违反Extension Condition。某些现象存在最优性违规，但可通过替代方法避免。EC在Merge的数学形式中有明确的代数意义，是模型的内在结构约束。最小的最优性违规对于Merge的Markov性质具有结构性作用。

Conclusion: 语言现象中表面上看似违反EC的现象实际上符合数学意义上的结构约束，Sideward Merge和替代推导能够合理解释复杂语言现象。EC是数学模型中的本质约束，而不是额外假设。最优性违规在语言动态中的作用复杂但可控。

Abstract: We analyze, using the mathematical formulation of Merge within the Strong Minimalist Thesis framework, a set of linguistic phenomena, including head-to-head movement, phrasal affixes and syntactic cliticization, verb-particle alternation, and operator-variable phenomena. These are often regarded as problematic, as violations of the Extension Condition. We show that, in fact, all of these phenomena can be explained without involving any EC violation. We first show that derivations using Sideward Merge are possible for all of these cases: these respect EC, though they involve some amount of optimality violations, with respect to Resource Restrictions cost functions, andthe amount of violation differs among these cases. We show that all the cases that involve large optimality violations can be derived in alternative ways involving neither EC nor the use of SM. The main remaining case (head-to-head movement) only involves SM with minimal violations of optimality (near equilibrium fluctuations). We analyze explicitly also the cases of multiple wh-fronting, clusters of clitics in Romance languages and possessor agreement construction in Korean, and how an explanation of these phenomena based on SM can be made compatible with the colored operad generators for phases and theta roles. We also show that the EC condition has a clear algebraic meaning in the mathematical formulation of Merge and is therefore an intrinsic structural algebraic constraint of the model, rather than an additional assumption. We also show that the minimal optimality violating SM plays a structural role in the Markovian properties of Merge, and we compare different optimality conditions coming from Minimal Search and from Resource Restriction in terms of their effect on the dynamics of the Hopf algebra Markov chain, in a simple explicit example.

</details>


### [73] [Smarter, not Bigger: Fine-Tuned RAG-Enhanced LLMs for Automotive HIL Testing](https://arxiv.org/abs/2511.22584)
*Chao Feng,Zihan Liu,Siddhant Gupta,Gongpei Cui,Jan von der Assen,Burkhard Stiller*

Main category: cs.CL

TL;DR: 本文提出了HIL-GPT，一种基于领域适应的大型语言模型与语义检索结合的硬件在环测试系统，显著提升了测试用例和需求的检索效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 针对汽车硬件在环（HIL）测试中测试资源分散且利用率低的问题，提升测试过程的效率和效果。

Method: 设计了HIL-GPT系统，利用领域特定数据集通过启发式挖掘和LLM辅助生成进行嵌入微调，并结合向量索引实现可扩展且可追溯的测试用例和需求检索。

Result: 经过微调的紧凑模型在准确率、响应速度和成本之间取得优异平衡，优于大型模型；用户研究显示基于RAG的系统在实用性、真实性和用户满意度方面优于通用大型语言模型。

Conclusion: 通过结合领域适应的大型语言模型和语义检索，HIL-GPT有效提升了工业HIL测试的智能辅助水平，为工业环境中高效、贴合领域需求的LLM助手部署提供了有力支持。

Abstract: Hardware-in-the-Loop (HIL) testing is essential for automotive validation but suffers from fragmented and underutilized test artifacts. This paper presents HIL-GPT, a retrieval-augmented generation (RAG) system integrating domain-adapted large language models (LLMs) with semantic retrieval. HIL-GPT leverages embedding fine-tuning using a domain-specific dataset constructed via heuristic mining and LLM-assisted synthesis, combined with vector indexing for scalable, traceable test case and requirement retrieval. Experiments show that fine-tuned compact models, such as \texttt{bge-base-en-v1.5}, achieve a superior trade-off between accuracy, latency, and cost compared to larger models, challenging the notion that bigger is always better. An A/B user study further confirms that RAG-enhanced assistants improve perceived helpfulness, truthfulness, and satisfaction over general-purpose LLMs. These findings provide insights for deploying efficient, domain-aligned LLM-based assistants in industrial HIL environments.

</details>


### [74] [Improving LLM-based Ontology Matching with fine-tuning on synthetic data](https://arxiv.org/abs/2511.22612)
*Guilherme Sousa,Rinaldo Lima,Cassia Trojahn*

Main category: cs.CL

TL;DR: 本文提出利用合成数据集微调大型语言模型，实现了对本体模块的高效匹配，显著优于未经微调的模型。


<details>
  <summary>Details</summary>
Motivation: 当前本体匹配任务中，大型语言模型(LLMs)的直接应用及其性能提升仍存在挑战，尤其是在零样本设置下。

Method: 提出了一种基于LLMs的本体匹配方法，包括利用搜索空间缩减技术选择相关子集，自动构建提示，以及通过新颖的LLM生成合成数据集进行专门微调。

Result: 在多个复杂数据集上评估，微调后的LLM模型在本体匹配任务中表现优于未微调的基础模型。

Conclusion: 结合自动化数据集生成与微调策略，有效提升了LLMs在本体匹配任务中的适应能力和性能。

Abstract: Large Language Models (LLMs) are increasingly being integrated into various components of Ontology Matching pipelines. This paper investigates the capability of LLMs to perform ontology matching directly on ontology modules and generate the corresponding alignments. Furthermore, it is explored how a dedicated fine-tuning strategy can enhance the model's matching performance in a zero-shot setting. The proposed method incorporates a search space reduction technique to select relevant subsets from both source and target ontologies, which are then used to automatically construct prompts. Recognizing the scarcity of reference alignments for training, a novel LLM-based approach is introduced for generating a synthetic dataset. This process creates a corpus of ontology submodule pairs and their corresponding reference alignments, specifically designed to fine-tune an LLM for the ontology matching task. The proposed approach was evaluated on the Conference, Geolink, Enslaved, Taxon, and Hydrography datasets from the OAEI complex track. The results demonstrate that the LLM fine-tuned on the synthetically generated data exhibits superior performance compared to the non-fine-tuned base model. The key contribution is a strategy that combines automatic dataset generation with fine-tuning to effectively adapt LLMs for ontology matching tasks.

</details>


### [75] [Modeling Romanized Hindi and Bengali: Dataset Creation and Multilingual LLM Integration](https://arxiv.org/abs/2511.22769)
*Kanchon Gharami,Quazi Sarwar Muhtaseem,Deepti Gupta,Lavanya Elluri,Shafika Showkat Moni*

Main category: cs.CL

TL;DR: 本文介绍了一个大规模的印地语和孟加拉语罗马化音译数据集及基于该数据集训练的多语言模型，显著提升了音译任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多语言模型在处理罗马化南亚印欧语系语言时面临发音多样性、拼写变异和缺乏代码混合资源的挑战，因此需要更丰富的数据和专门的模型提升音译效果。

Method: 作者构建了大规模印地语和孟加拉语音译数据集，利用该数据预训练了基于Marian架构的多语言seq2seq模型，并通过BLEU和CER指标评估模型性能。

Result: 本文开发了一个包含近180万印地语和100万孟加拉语音译对的新型音译数据集，并基于该数据集预训练了基于Marian架构的多语言序列到序列大语言模型。实验表明，该模型在BLEU和CER指标上较现有模型有显著提升。

Conclusion: 所提出的数据集和预训练多语言模型有效提升了南亚印欧语系语言从罗马化脚本转写为本地脚本的准确性，解决了现有模型在发音、拼写多样性及代码混合数据不足等方面的不足。

Abstract: The development of robust transliteration techniques to enhance the effectiveness of transforming Romanized scripts into native scripts is crucial for Natural Language Processing tasks, including sentiment analysis, speech recognition, information retrieval, and intelligent personal assistants. Despite significant advancements, state-of-the-art multilingual models still face challenges in handling Romanized script, where the Roman alphabet is adopted to represent the phonetic structure of diverse languages. Within the South Asian context, where the use of Romanized script for Indo-Aryan languages is widespread across social media and digital communication platforms, such usage continues to pose significant challenges for cutting-edge multilingual models. While a limited number of transliteration datasets and models are available for Indo-Aryan languages, they generally lack sufficient diversity in pronunciation and spelling variations, adequate code-mixed data for large language model (LLM) training, and low-resource adaptation. To address this research gap, we introduce a novel transliteration dataset for two popular Indo-Aryan languages, Hindi and Bengali, which are ranked as the 3rd and 7th most spoken languages worldwide. Our dataset comprises nearly 1.8 million Hindi and 1 million Bengali transliteration pairs. In addition to that, we pre-train a custom multilingual seq2seq LLM based on Marian architecture using the developed dataset. Experimental results demonstrate significant improvements compared to existing relevant models in terms of BLEU and CER metrics.

</details>


### [76] [Mitigating Semantic Drift: Evaluating LLMs' Efficacy in Psychotherapy through MI Dialogue Summarization](https://arxiv.org/abs/2511.22818)
*Vivek Kumar,Pushpraj Singh Rajawat,Eirini Ntoutsi*

Main category: cs.CL

TL;DR: 本文评估了大语言模型在心理动力访谈中的表现，通过新标注方案和数据集，揭示其理解复杂心理构念的能力及改善策略。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在敏感领域如心理学中存在敏感性不足、事实错误、情感表达不一致、偏见和幻觉等问题，难以准确捕捉人类理解的深度和复杂性。

Method: 本文采用混合方法，通过生成动力访谈（MI）对话的精准摘要，设计基于MITI框架关键成分的两阶段标注方案，使用专家标注的MI对话作为真实数据，构建多分类任务，评估大语言模型在单次和少量提示下的性能。

Result: 结果揭示了大语言模型在理解复杂心理构念方面的能力，并提出减少语义漂移的最佳实践。

Conclusion: 本文不仅为动力访谈社区提供了高质量标注数据集，缓解低资源领域数据匮乏，还为利用大语言模型进行复杂行为治疗的精确上下文解读提供了重要见解。

Abstract: Recent advancements in large language models (LLMs) have shown their potential across both general and domain-specific tasks. However, there is a growing concern regarding their lack of sensitivity, factual incorrectness in responses, inconsistent expressions of empathy, bias, hallucinations, and overall inability to capture the depth and complexity of human understanding, especially in low-resource and sensitive domains such as psychology. To address these challenges, our study employs a mixed-methods approach to evaluate the efficacy of LLMs in psychotherapy. We use LLMs to generate precise summaries of motivational interviewing (MI) dialogues and design a two-stage annotation scheme based on key components of the Motivational Interviewing Treatment Integrity (MITI) framework, namely evocation, collaboration, autonomy, direction, empathy, and a non-judgmental attitude. Using expert-annotated MI dialogues as ground truth, we formulate multi-class classification tasks to assess model performance under progressive prompting techniques, incorporating one-shot and few-shot prompting. Our results offer insights into LLMs' capacity for understanding complex psychological constructs and highlight best practices to mitigate ``semantic drift" in therapeutic settings. Our work contributes not only to the MI community by providing a high-quality annotated dataset to address data scarcity in low-resource domains but also critical insights for using LLMs for precise contextual interpretation in complex behavioral therapy.

</details>


### [77] [RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms](https://arxiv.org/abs/2511.22858)
*Yuya Ishihara,Atsushi Keyaki,Hiroaki Yamada,Ryutaro Ohara,Mihoko Sumida*

Main category: cs.CL

TL;DR: 本研究设计了符合日本医疗诉讼法律规范的基于RAG的LLM系统，满足知识检索准确、回答忠实上下文和时间戳引用三大要求。


<details>
  <summary>Details</summary>
Motivation: 在医疗诉讼中，专家委员对争议事项提供专业知识。希望用RAG系统替代专家，需确保系统严格遵守法律规范。

Method: 构建基于检索增强生成（RAG）的LLM系统，设计满足法律规范要求的检索模块和生成模块。

Result: 提出了满足三项要求的RAG系统设计方案，包括相关知识检索、生成内容基于检索上下文且忠实于该上下文，以及带有对应时间戳的知识引用。

Conclusion: 设计的RAG系统能够支持日本医疗诉讼程序中代替专家委员的角色，符合法律规范要求。

Abstract: This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.

</details>


### [78] [JBE-QA: Japanese Bar Exam QA Dataset for Assessing Legal Domain Knowledge](https://arxiv.org/abs/2511.22869)
*Zhihan Cao,Fumihito Nishino,Hiroaki Yamada,Nguyen Ha Thanh,Yusuke Miyao,Ken Satoh*

Main category: cs.CL

TL;DR: 介绍了日本律师资格考试构建的法律问答数据集JBE-QA，并基于此评测了26个大型语言模型，指出专有推理模型表现优越且宪法题相对容易。


<details>
  <summary>Details</summary>
Motivation: 现有日本法律领域评测资源主要聚焦民法典，缺乏涵盖更全面法律领域的标准化大型语言模型评价基准。

Method: 从日本律师资格考试多项选择题中提取问题，拆解为独立的真伪判断题，涵盖多个法律文本，评价多种类型的大型语言模型，包括专有和开源模型。

Result: JBE-QA是一个基于2015-2024年日本律师资格考试多项选择题部分构建的日语法律问答数据集，涵盖民法典、刑法典和宪法三个领域，包含3464条平衡标签的判断题。作者基于该数据集评测了26个大型语言模型，发现有推理能力的专有模型表现最佳，宪法问题普遍比民法典和刑法典更易。

Conclusion: JBE-QA数据集为评估大型语言模型的日本法律领域知识提供了首个综合性基准，揭示了不同模型的性能差异及不同法律领域问题的难度差异。

Abstract: We introduce JBE-QA, a Japanese Bar Exam Question-Answering dataset to evaluate large language models' legal knowledge. Derived from the multiple-choice (tanto-shiki) section of the Japanese bar exam (2015-2024), JBE-QA provides the first comprehensive benchmark for Japanese legal-domain evaluation of LLMs. It covers the Civil Code, the Penal Code, and the Constitution, extending beyond the Civil Code focus of prior Japanese resources. Each question is decomposed into independent true/false judgments with structured contextual fields. The dataset contains 3,464 items with balanced labels. We evaluate 26 LLMs, including proprietary, open-weight, Japanese-specialised, and reasoning models. Our results show that proprietary models with reasoning enabled perform best, and the Constitution questions are generally easier than the Civil Code or the Penal Code questions.

</details>


### [79] [FEANEL: A Benchmark for Fine-Grained Error Analysis in K-12 English Writing](https://arxiv.org/abs/2511.22883)
*Jingheng Ye,Shen Wang,Jiaqi Chen,Hebin Wang,Deqing Zou,Yanyu Zhu,Jiwei Tang,Hai-Tao Zheng,Ruitong Liu,Haoyang Li,Yanfeng Wang,Qingsong Wen*

Main category: cs.CL

TL;DR: 本文提出细粒度英语写作错误分析基准FEANEL，评测发现现有大型语言模型在错误分析和教育反馈方面表现不足。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在提供细粒度、专业的英语写作教育反馈方面的能力及不足，推动其在教育领域应用的提升。

Method: 引入FEANEL基准，包含1000篇师生作文和一个细粒度的英语写作错误分类体系，由语言教育专家标注错误类型、严重性和解释性反馈。对比当前先进的大型语言模型在此基准上的表现。

Result: 实验显示当前大型语言模型在细粒度错误分析和教育反馈方面能力存在显著不足。

Conclusion: 当前LLMs在K-12英语写作细粒度错误分析和教育反馈能力有限，需要在此方向上开展更多改进。

Abstract: Large Language Models (LLMs) have transformed artificial intelligence, offering profound opportunities for educational applications. However, their ability to provide fine-grained educational feedback for K-12 English writing remains underexplored. In this paper, we challenge the error analysis and pedagogical skills of LLMs by introducing the problem of Fine-grained Error Analysis for English Learners and present the Fine-grained Error ANalysis for English Learners (FEANEL) Benchmark. The benchmark comprises 1,000 essays written by elementary and secondary school students, and a well-developed English writing error taxonomy. Each error is annotated by language education experts and categorized by type, severity, and explanatory feedback, using a part-of-speech-based taxonomy they co-developed. We evaluate state-of-the-art LLMs on the FEANEL Benchmark to explore their error analysis and pedagogical abilities. Experimental results reveal significant gaps in current LLMs' ability to perform fine-grained error analysis, highlighting the need for advancements in particular methods for educational applications.

</details>


### [80] [Language-conditioned world model improves policy generalization by reading environmental descriptions](https://arxiv.org/abs/2511.22904)
*Anh Nguyen,Stefan Lee*

Main category: cs.CL

TL;DR: 本研究提出了一种基于梦幻世界模型的语言感知编码器（LED-WM），通过强化学习方法提升智能体对描述环境动态语言的理解能力，从而实现策略对未见游戏的泛化。


<details>
  <summary>Details</summary>
Motivation: 现有模型或依赖规划延迟可接受性、专家示范等假设，限制了策略在新环境下的泛化能力。

Method: 设计基于DreamerV3的LED-WM，利用注意力机制将语言描述与观察实体显式绑定；通过与环境交互训练语言条件世界模型，并从模型中直接学习策略，无需规划或专家示范。

Result: 在MESSENGER及MESSENGER-WM环境中，LED-WM训练的策略在描述新动力学和语言的未见游戏上表现出更好的泛化能力，且通过世界模型生成的合成轨迹进行微调进一步提升策略性能。

Conclusion: LED-WM有效提升了语言条件下世界模型的表达和策略学习能力，增强了智能体在多变环境中的适应性与泛化能力，为未来人机交互和实际部署奠定基础。

Abstract: To interact effectively with humans in the real world, it is important for agents to understand language that describes the dynamics of the environment--that is, how the environment behaves--rather than just task instructions specifying "what to do". Understanding this dynamics-descriptive language is important for human-agent interaction and agent behavior. Recent work address this problem using a model-based approach: language is incorporated into a world model, which is then used to learn a behavior policy. However, these existing methods either do not demonstrate policy generalization to unseen games or rely on limiting assumptions. For instance, assuming that the latency induced by inference-time planning is tolerable for the target task or expert demonstrations are available. Expanding on this line of research, we focus on improving policy generalization from a language-conditioned world model while dropping these assumptions. We propose a model-based reinforcement learning approach, where a language-conditioned world model is trained through interaction with the environment, and a policy is learned from this model--without planning or expert demonstrations. Our method proposes Language-aware Encoder for Dreamer World Model (LED-WM) built on top of DreamerV3. LED-WM features an observation encoder that uses an attention mechanism to explicitly ground language descriptions to entities in the observation. We show that policies trained with LED-WM generalize more effectively to unseen games described by novel dynamics and language compared to other baselines in several settings in two environments: MESSENGER and MESSENGER-WM.To highlight how the policy can leverage the trained world model before real-world deployment, we demonstrate the policy can be improved through fine-tuning on synthetic test trajectories generated by the world model.

</details>


### [81] [Visual Puns from Idioms: An Iterative LLM-T2IM-MLLM Framework](https://arxiv.org/abs/2511.22943)
*Kelaiti Xiao,Liang Yang,Dongyu Zhang,Paerhati Tulajiang,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文提出一种结合多模态模型的迭代方法，实现自动生成和识别习语视觉双关图像，构建了相关数据集并对多模型性能进行了评测。


<details>
  <summary>Details</summary>
Motivation: 习语的字面和比喻意义形成视觉双关，自动生成并理解此类图像对多模态理解与创作有重要意义，但尚缺乏系统性方法和数据集支持。

Method: 提出迭代框架，结合大型语言模型（LLM）、文本生成图像模型（T2IM）和多模态大型语言模型（MLLM），通过生成详细视觉提示、图像合成、图像识别并反复优化提示，直到成功识别语义双关图像或达到步骤限制。

Result: 基于1000个习语生成了对应的视觉双关图像数据集，实验评估了10个LLM、10个MLLM和一个T2IM，发现MLLM的选择是性能关键，GPT在识别准确率最高，Claude在提示生成表现最佳。

Conclusion: 结合不同类型模型的迭代框架有效实现了习语视觉双关图像的自动生成与理解，生成的数据集为该领域提供了有效的基准测试资源。

Abstract: We study idiom-based visual puns--images that align an idiom's literal and figurative meanings--and present an iterative framework that coordinates a large language model (LLM), a text-to-image model (T2IM), and a multimodal LLM (MLLM) for automatic generation and evaluation. Given an idiom, the system iteratively (i) generates detailed visual prompts, (ii) synthesizes an image, (iii) infers the idiom from the image, and (iv) refines the prompt until recognition succeeds or a step limit is reached. Using 1,000 idioms as inputs, we synthesize a corresponding dataset of visual pun images with paired prompts, enabling benchmarking of both generation and understanding. Experiments across 10 LLMs, 10 MLLMs, and one T2IM (Qwen-Image) show that MLLM choice is the primary performance driver: GPT achieves the highest accuracies, Gemini follows, and the best open-source MLLM (Gemma) is competitive with some closed models. On the LLM side, Claude attains the strongest average performance for prompt generation.

</details>


### [82] [Training-Free Loosely Speculative Decoding: Accepting Semantically Correct Drafts Beyond Exact Match](https://arxiv.org/abs/2511.22972)
*Jinze Li,Yixing Xu,Guanchen Li,Shuo Yang,Jinfeng Xu,Xuanwu Yin,Dong Li,Edith C. H. Ngai,Emad Barsoum*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的松散推测解码方法FLy，通过宽松的验证标准和两层机制显著加速大型语言模型推理，同时保持高准确率，并在跨领域任务中优于现有训练方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型推理速度慢，现有推测解码严格的验证标准影响结果，且训练方法在领域外表现差。

Method: FLy采用自适应熵阈值和延迟窗口机制，利用目标模型的自纠错能力，宽松验证草稿模型输出；并设计多层加速策略，提升推理速度且无需训练。

Result: FLy在Llama-3.1-70B和405B模型上分别实现约2.8倍和5倍推理加速，准确率保持99%以上，且在领域外任务中优于训练方法EAGLE-3。

Conclusion: FLy方法通用性强，无需调参，能有效提升大型语言模型推理速度和泛化能力，适用于多种模型和任务。

Abstract: Large language models (LLMs) achieve strong performance across diverse tasks but suffer from high inference latency due to their autoregressive generation. Speculative Decoding (SPD) mitigates this issue by verifying candidate tokens in parallel from a smaller draft model, yet its strict exact-match verification discards many semantically valid continuations. Moreover, existing training-based SPD methods often suffer from performance degradation on out-of-distribution (OOD) tasks. To this end, we propose Training-Free Loosely Speculative Decoding (FLy), a novel method that loosens the rigid verification criterion by leveraging the target model's self-corrective behavior to judge whether a draft-target mismatch remains semantically valid. FLy introduces a two-tier mechanism: an entropy-level gate that identifies whether the current token allows multiple plausible alternatives or is nearly deterministic, and a token-level deferred window that distinguishes genuine errors from differently worded yet semantically correct variants. To further reduce latency, we design a multi-level acceleration strategy that accelerates not only the target model but also the drafter itself. Owing to its training-free design, FLy composes seamlessly with arbitrary draft-target pairs and generalizes across models and domains without hyperparameter re-tuning. Experiments show that FLy preserves more than 99% of the target model's accuracy while achieving an average 2.81x speedup on Llama-3.1-70B-Instruct and 5.07x speedup on the 405B variant. Notably, on out-of-domain datasets, our method remains highly effective and outperforms the training-based method EAGLE-3 by 1.62x.

</details>


### [83] [Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification](https://arxiv.org/abs/2511.22977)
*Sumit Mamtani,Abhijeet Bhure*

Main category: cs.CL

TL;DR: 本文评估Transformer预训练模型的编码作为假新闻检测的特征表示，结果表明BERT嵌入与简单逻辑回归结合效果最佳，验证了Transformer编码器的稳健性和有效性。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer编码表示在假新闻检测任务中的表现，评估预训练模型作为固定嵌入器的效果。

Method: 比较了编码器和解码器预训练模型（BERT、GPT-2、Transformer-XL）作为嵌入器，结合轻量级分类器，采用不同预处理策略（池化与填充）和分类头（神经网络与线性分类器）进行对比实验。

Result: BERT嵌入结合逻辑回归在LIAR数据集上性能优于神经网络基线，模型对序列截断具备鲁棒性，简单的最大池化或平均池化在特征聚合上表现良好。

Conclusion: 基于自注意力机制的Transformer编码器能有效迁移到真假新闻检测任务，且模型性能主要受编码结构影响，与分类器复杂度关系较小，体现了编码器的架构优势。

Abstract: This paper investigates fake news detection as a downstream evaluation of Transformer representations, benchmarking encoder-only and decoder-only pre-trained models (BERT, GPT-2, Transformer-XL) as frozen embedders paired with lightweight classifiers. Through controlled preprocessing comparing pooling versus padding and neural versus linear heads, results demonstrate that contextual self-attention encodings consistently transfer effectively. BERT embeddings combined with logistic regression outperform neural baselines on LIAR dataset splits, while analyses of sequence length and aggregation reveal robustness to truncation and advantages from simple max or average pooling. This work positions attention-based token encoders as robust, architecture-centric foundations for veracity tasks, isolating Transformer contributions from classifier complexity.

</details>


### [84] [ShoppingComp: Are LLMs Really Ready for Your Shopping Cart?](https://arxiv.org/abs/2511.22978)
*Huaixiao Tou,Ying Zeng,Cong Ma,Muzhi Li,Minghao Li,Weijie Yuan,He Zhang,Kai Jia*

Main category: cs.CL

TL;DR: 提出了ShoppingComp基准测试，揭示了现有LLM在电商商品检索和安全决策上的不足，强调了现实应用与研究之间的巨大差距。


<details>
  <summary>Details</summary>
Motivation: 现有电商评测缺乏对真实商品安全和信息验证的严密考量，难以反映LLM在实际购物场景中的表现和风险。

Method: 设计包含真实商品和高度复杂任务的评测套件，结合专家策划的多样购物场景，全面测试LLM代理在检索、报告生成和安全决策方面的能力。

Result: ShoppingComp基准测试设计了120个任务和1026个场景，严格评估了LLM驱动购物代理在精准商品检索、专家级报告生成和安全关键决策三大能力上的表现。实验结果显示即使是最先进的模型如GPT-5和Gemini-2.5-Flash，也存在显著性能不足，尤其在识别产品安全风险和防范促销误导方面表现欠佳。

Conclusion: 当前LLM模型在真实电商环境中的表现远低于理想水平，存在严重的安全风险和准确性问题，急需通过更严谨的评测标准提升其实用性和可靠性。ShoppingComp作为新的基准，为推动更安全、精准的电商智能代理发展设立了行业标准。

Abstract: We present ShoppingComp, a challenging real-world benchmark for rigorously evaluating LLM-powered shopping agents on three core capabilities: precise product retrieval, expert-level report generation, and safety critical decision making. Unlike prior e-commerce benchmarks, ShoppingComp introduces highly complex tasks under the principle of guaranteeing real products and ensuring easy verifiability, adding a novel evaluation dimension for identifying product safety hazards alongside recommendation accuracy and report quality. The benchmark comprises 120 tasks and 1,026 scenarios, curated by 35 experts to reflect authentic shopping needs. Results reveal stark limitations of current LLMs: even state-of-the-art models achieve low performance (e.g., 11.22% for GPT-5, 3.92% for Gemini-2.5-Flash). These findings highlight a substantial gap between research benchmarks and real-world deployment, where LLMs make critical errors such as failure to identify unsafe product usage or falling for promotional misinformation, leading to harmful recommendations. ShoppingComp fills the gap and thus establishes a new standard for advancing reliable and practical agents in e-commerce.

</details>


### [85] [Social Perceptions of English Spelling Variation on Twitter: A Comparative Analysis of Human and LLM Responses](https://arxiv.org/abs/2511.23041)
*Dong Nguyen,Laura Rosseel*

Main category: cs.CL

TL;DR: 本文研究了拼写变化对线上文本社交感知的影响，比较了人类和大型语言模型在正式性、细心和年龄感知上的评分，发现两者大体一致但存在差异。


<details>
  <summary>Details</summary>
Motivation: 拼写变化影响文本及作者的社会认知，研究探讨人类与AI模型在此感知上的一致性，评估大型语言模型对社交语言特征的理解水平。

Method: 利用社会语言学方法，比较人类与大型语言模型（LLMs）对英语线上写作中拼写变化的社交属性（正式程度、细心程度、年龄感知）的评分。

Result: 发现人类与大型语言模型评分间存在较强相关性，但在评分分布及不同拼写变化类型的比较中出现显著差异。

Conclusion: 大型语言模型在感知拼写变化的社交属性方面与人类总体一致，但细节上仍存在差异，显示模型与人类社交认知的部分一致性和局限性。

Abstract: Spelling variation (e.g. funnnn vs. fun) can influence the social perception of texts and their writers: we often have various associations with different forms of writing (is the text informal? does the writer seem young?). In this study, we focus on the social perception of spelling variation in online writing in English and study to what extent this perception is aligned between humans and large language models (LLMs). Building on sociolinguistic methodology, we compare LLM and human ratings on three key social attributes of spelling variation (formality, carefulness, age). We find generally strong correlations in the ratings between humans and LLMs. However, notable differences emerge when we analyze the distribution of ratings and when comparing between different types of spelling variation.

</details>


### [86] [Decoding the Past: Explainable Machine Learning Models for Dating Historical Texts](https://arxiv.org/abs/2511.23056)
*Paulo J. N. Pinto,Armando J. Pinho,Diogo Pratas*

Main category: cs.CL

TL;DR: 本文通过集成多种特征构建可解释的树模型，实现对跨五个世纪英语文本的时间分类，精度显著高于随机基线。


<details>
  <summary>Details</summary>
Motivation: 准确确定历史文本的年代对于文化遗产的组织和解读至关重要，现有方法尚缺乏高效且可解释的时间文本分类模型。

Method: 结合压缩特征、词汇结构、可读性、新词检测和距离特征五类信息，利用特征工程驱动的树模型进行时间分类，并通过SHAP分析解释模型表现。

Result: 模型在大规模语料上实现了76.7%的世纪预测准确率和26.1%的年代预测准确率，提升至96.0%和85.8%的Top-k准确率，表现出良好的排名能力和可控误差。关键特征为距离和词汇结构，且显示19世纪为语言演变的转折点。

Conclusion: 集成多特征的树基模型不仅具有较高准确率和良好的解释性，还在跨领域适应性上存在挑战，但其计算效率和可解释性使其成为神经网络之外的可扩展选择。

Abstract: Accurately dating historical texts is essential for organizing and interpreting cultural heritage collections. This article addresses temporal text classification using interpretable, feature-engineered tree-based machine learning models. We integrate five feature categories - compression-based, lexical structure, readability, neologism detection, and distance features - to predict the temporal origin of English texts spanning five centuries. Comparative analysis shows that these feature domains provide complementary temporal signals, with combined models outperforming any individual feature set. On a large-scale corpus, we achieve 76.7% accuracy for century-scale prediction and 26.1% for decade-scale classification, substantially above random baselines (20% and 2.3%). Under relaxed temporal precision, performance increases to 96.0% top-2 accuracy for centuries and 85.8% top-10 accuracy for decades. The final model exhibits strong ranking capabilities with AUCROC up to 94.8% and AUPRC up to 83.3%, and maintains controlled errors with mean absolute deviations of 27 years and 30 years, respectively. For authentication-style tasks, binary models around key thresholds (e.g., 1850-1900) reach 85-98% accuracy. Feature importance analysis identifies distance features and lexical structure as most informative, with compression-based features providing complementary signals. SHAP explainability reveals systematic linguistic evolution patterns, with the 19th century emerging as a pivot point across feature domains. Cross-dataset evaluation on Project Gutenberg highlights domain adaptation challenges, with accuracy dropping by 26.4 percentage points, yet the computational efficiency and interpretability of tree-based models still offer a scalable, explainable alternative to neural architectures.

</details>


### [87] [Standard Occupation Classifier -- A Natural Language Processing Approach](https://arxiv.org/abs/2511.23057)
*Sidharth Rony,Jack Patman*

Main category: cs.CL

TL;DR: 利用自然语言处理技术，结合职位广告数据，建立职业分类器，集合模型在职业编码预测中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 利用职位广告大数据和自然语言处理技术，提升职业分类的自动化和准确性，以便更好地分析劳动市场需求。

Method: 开发多种基于不同语言模型的分类器，最终通过集合Google BERT和神经网络的模型，整合职位标题、描述和技能信息，进行职业代码预测。

Result: 构建了一个集合模型，结合了Google BERT与神经网络分类器，基于职位标题、描述和技能，对英国ONS SOC和美国O*NET SOC职业分类进行预测，分别达到第四级职业分类61%和第三级72%的准确率。

Conclusion: 该模型能有效利用职位广告提供实时且准确的劳动市场需求演变信息。

Abstract: Standard Occupational Classifiers (SOC) are systems used to categorize and classify different types of jobs and occupations based on their similarities in terms of job duties, skills, and qualifications. Integrating these facets with Big Data from job advertisement offers the prospect to investigate labour demand that is specific to various occupations. This project investigates the use of recent developments in natural language processing to construct a classifier capable of assigning an occupation code to a given job advertisement. We develop various classifiers for both UK ONS SOC and US O*NET SOC, using different Language Models. We find that an ensemble model, which combines Google BERT and a Neural Network classifier while considering job title, description, and skills, achieved the highest prediction accuracy. Specifically, the ensemble model exhibited a classification accuracy of up to 61% for the lower (or fourth) tier of SOC, and 72% for the third tier of SOC. This model could provide up to date, accurate information on the evolution of the labour market using job advertisements.

</details>


### [88] [Conveying Imagistic Thinking in TCM Translation: A Prompt Engineering and LLM-Based Evaluation Framework](https://arxiv.org/abs/2511.23059)
*Jiatong Han*

Main category: cs.CL

TL;DR: 本研究通过在人机协作框架下，利用提示式认知支架引导大语言模型DeepSeek识别中医古籍隐喻与转喻，并通过多维度评估验证提示调整翻译优于人类及基线模型，提出了古文密集概念翻译的有效路径。


<details>
  <summary>Details</summary>
Motivation: 传统中医理论富含隐喻与转喻，现有英文直译难以传达其深层认知结构，影响临床应用，亟需更符合认知习惯的翻译方法。

Method: 采用人机协作框架，选择《黄帝内经》四段重要文本，利用提示引导DeepSeek V3.1识别隐喻和转喻并进行翻译，随后用ChatGPT和Gemini模拟读者从五个认知维度评估翻译质量并通过访谈和解释现象学分析获取深入反馈。

Result: 提示调整后的大模型翻译在五个认知维度上均表现最佳，且跨模型和跨角色一致性高；访谈揭示机器和人工翻译差异、隐喻转喻转译策略及读者认知偏好。

Conclusion: 本研究提出了一条认知有效、高效且可复制的人机协作翻译路径，为古代高密度概念文本如中医类文献的翻译提供了理论与实践指导。

Abstract: Traditional Chinese Medicine theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis. Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient and replicable HITL methodological pathway for translation of ancient, concept-dense texts like TCM.

</details>


### [89] [Accent Placement Models for Rigvedic Sanskrit Text](https://arxiv.org/abs/2511.23088)
*Akhil Rajeev P,Annarao Kulkarni*

Main category: cs.CL

TL;DR: 本文构建了带重音标注的Rigveda古文本语料库，比较了基于ByT5微调、LoRA参数高效微调及BiLSTM-CRF三种自动重音标注方法，ByT5微调效果最好，LoRA提供良好效率与准确率平衡，研究为古语音调恢复和相关技术应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: Rigveda文本中存在独特且重要的pitch-accent音调系统，但现代电子文本中常缺失这些重音标记，恢复这些重音对诗歌的旋律性和语义理解至关重要，需要开发有效的自动标注技术，连接计算语言学与传统文献学和教学应用。

Method: 采用构建带有重音与无重音对比的诗句语料，进行实验比较三种方法：(1)直接对字节级Transformer模型ByT5进行全量微调；(2)训练基于BiLSTM-CRF的序列标注模型作为基线；(3)在ByT5上使用LoRA方法进行参数高效微调。评估通过WER、CER及专门设计的DER指标进行。

Result: 本文研究了Rigveda古印度吠陀梵文中独特的音调重音系统（udātta, anudātta, svarita）的自动标注问题，构建了带有重音和无重音对照的诗句语料库。采用三种方法对重音进行自动标注：(1)对ByT5模型进行全量微调，该模型基于字节级Transformer且支持Unicode组合符直接操作；(2)从头训练的BiLSTM-CRF序列标注模型作为基线；(3)在ByT5模型上使用LoRA进行参数高效微调。评估指标包括正字法准确率的词错误率(WER)和字符错误率(CER)，以及专门针对重音的标记错误率(DER)。结果显示，ByT5全量微调在所有指标上误差最低，LoRA在效率与准确率之间取得良好平衡，BiLSTM-CRF提供了透明的基线表现。研究强调重音恢复需满足Unicode安全的预处理、标记感知的分词和能区分字形与重音错误的评估方法，推动了遗产语言技术在计算建模与文献学、教学之间的交叉发展。该工作建立了Rigveda重音恢复的可复现基线，并为后续任务如OCR、语音识别和吟诵合成等提供指导。

Conclusion: 通过构建并比较三种方法，证明了基于ByT5的全量微调在自动重音标注任务中表现最佳，LoRA方法在效率和效果间取得折中，强调了Unicode安全和标记感知的重要性，推动了遗产语言技术的发展，为后续OCR、ASR等应用提供基础。

Abstract: The Rigveda, among the oldest Indian texts in Vedic Sanskrit, employs a distinctive pitch-accent system : udātta, anudātta, svarita whose marks encode melodic and interpretive cues but are often absent from modern e-texts. This work develops a parallel corpus of accented-unaccented ślokas and conducts a controlled comparison of three strategies for automatic accent placement in Rigvedic verse: (i) full fine-tuning of ByT5, a byte-level Transformer that operates directly on Unicode combining marks, (ii) a from-scratch BiLSTM-CRF sequence-labeling baseline, and (iii) LoRA-based parameter-efficient fine-tuning atop ByT5.
  Evaluation uses Word Error Rate (WER) and Character Error Rate (CER) for orthographic fidelity, plus a task-specific Diacritic Error Rate (DER) that isolates accent edits. Full ByT5 fine-tuning attains the lowest error across all metrics; LoRA offers strong efficiency-accuracy trade-offs, and BiLSTM-CRF serves as a transparent baseline. The study underscores practical requirements for accent restoration - Unicode-safe preprocessing, mark-aware tokenization, and evaluation that separates grapheme from accent errors - and positions heritage-language technology as an emerging NLP area connecting computational modeling with philological and pedagogical aims. Results establish reproducible baselines for Rigvedic accent restoration and provide guidance for downstream tasks such as accent-aware OCR, ASR/chant synthesis, and digital scholarship.

</details>


### [90] [Mind Reading or Misreading? LLMs on the Big Five Personality Test](https://arxiv.org/abs/2511.23101)
*Francesco Di Cursi,Chiara Boldrini,Marco Conti,Andrea Passarella*

Main category: cs.CL

TL;DR: 本文评估了大语言模型（包括GPT-4及开源模型）在文本自动预测五大人格特质（BIG5）中的表现，结果显示不同模型和提示策略对准确性影响较大，但目前尚无模型可实现稳定、可靠的预测。


<details>
  <summary>Details</summary>
Motivation: 希望探索大语言模型在无监督文本自动预测五大人格特质任务中的应用效果及其限制，推动个性化应用的发展。

Method: 测试了五种大语言模型在三个不同数据集（Essays, MyPersonality, Pandora）上的表现，使用两种提示策略（简洁提示与丰富提示），通过二分类五大人格维度预测并对结果进行多指标评估。

Result: 丰富提示可以减少无效输出并改善类别平衡，但引入预测偏差；开放性和宜人性容易检测，外向性和神经质难以准确预测；整体表现依旧不稳定，准确率与宏均F1掩盖了类别识别不平衡的问题。

Conclusion: 当前开箱即用的大语言模型尚不适合直接用于自动人格预测，提示设计、特质表述与评估指标需谨慎协调才能获得可解释结果。

Abstract: We evaluate large language models (LLMs) for automatic personality prediction from text under the binary Five Factor Model (BIG5). Five models -- including GPT-4 and lightweight open-source alternatives -- are tested across three heterogeneous datasets (Essays, MyPersonality, Pandora) and two prompting strategies (minimal vs. enriched with linguistic and psychological cues). Enriched prompts reduce invalid outputs and improve class balance, but also introduce a systematic bias toward predicting trait presence. Performance varies substantially: Openness and Agreeableness are relatively easier to detect, while Extraversion and Neuroticism remain challenging. Although open-source models sometimes approach GPT-4 and prior benchmarks, no configuration yields consistently reliable predictions in zero-shot binary settings. Moreover, aggregate metrics such as accuracy and macro-F1 mask significant asymmetries, with per-class recall offering clearer diagnostic value. These findings show that current out-of-the-box LLMs are not yet suitable for APPT, and that careful coordination of prompt design, trait framing, and evaluation metrics is essential for interpretable results.

</details>


### [91] [Dripper: Token-Efficient Main HTML Extraction with a Lightweight LM](https://arxiv.org/abs/2511.23119)
*Mengjie Liu,Jiahui Peng,Pei Chu,Jiantao Qiu,Ren Ma,He Zhu,Rui Min,Lindong Lu,Wenchang Ning,Linfeng Hou,Kaiwen Liu,Yuan Qu,Zhenxiang Li,Chao Xu,Zhongying Tu,Wentao Zhang,Conghui He*

Main category: cs.CL

TL;DR: 本论文提出了Dripper，一种基于轻量级语言模型的高效HTML主体内容提取框架，通过HTML简化、语义块分类和受控解码技术，有效提升了提取质量和推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前网页主体内容提取面临上下文窗口长度限制、推理成本高、格式幻觉等问题，影响了解析质量，急需一个高效准确的解决方案。

Method: 设计了HTML简化算法减少输入token数，将主体内容提取转化为语义块序列分类，采用受控解码机制限制输出空间，并构建了WebMainBench评测数据集进行验证。

Result: 提出了Dripper框架，结合轻量级语言模型与HTML简化算法，实现了主体内容提取任务的高效低成本，并在新建的WebMainBench数据集上达到了81.58%(使用备用策略达83.13%)的ROUGE-N F1分数，优于所有基线方法。

Conclusion: Dripper通过多种创新技术突破了现有模型在网页内容提取上的限制，实现了高性能和低推理成本，证明其在大规模网页数据处理中具有广泛应用前景。

Abstract: Accurately and efficiently extracting main content from general web pages is of great significance for obtaining training data for large models. Using well-pre-trained decoder-only generative language models offers excellent document comprehension capabilities, thereby effectively enhancing parsing quality. However, it remains constrained by issues such as context window length, inference cost, and format hallucination. We present Dripper, an efficient HTML main content extraction framework powered by lightweight language models, which addresses these challenges through four key innovations: (1) We design a specialized HTML simplification algorithm that reduces input token count to 22\% compared to raw HTML while preserving critical structural information; (2) We reformulate main content extraction as a semantic block sequence classification task, significantly reducing inference cost; (3) We introduce a controlled decoding mechanism that strictly constrains the output space through logits processors, effectively eliminating hallucination issues common in small-scale models; (4) We propose WebMainBench, an evaluation dataset containing over 7,800 web pages with meticulously human-annotated main content extraction labels. Experimental results demonstrate that using only a 0.6B parameter model, Dripper achieves state-of-the-art performance across all evaluation benchmarks and outperforms all baseline methods, attaining an ROUGE-N F1 score of 81.58\%( 83.13\% with fall-back strategy) on our proposed WebMainBench dataset.

</details>


### [92] [Multi-chain Graph Refinement and Selection for Reliable Reasoning in Large Language Models](https://arxiv.org/abs/2511.23136)
*Yujiao Yang,Jing Lian,Linhui Li*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的推理框架MGRS，通过多链图推理路径生成、复合自我和交叉验证、推理关系图构建与成功率估计，有效提升了大语言模型的推理能力和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于树或图的推理扩展方法存在推理多样性不足、冗余搜索分枝及异质推理路径间整合与错误纠正不足的问题，限制了实际应用。

Method: MGRS框架首先为问题生成多个多样推理路径，使用复合自我和交叉验证策略精炼答案，构建推理关系图并估计中间节点成功率，然后计算累计成功率选择最可靠答案和推理路径。

Result: MGRS在四种任务上的六个基准数据集均表现优异，平均准确率提高2.1%，在24点游戏中首次达到完美准确率，且相较Forest of Thoughts框架实现13.6倍速度提升。

Conclusion: MGRS显著提升了推理能力和效率，在六个基准数据集上的平均准确率达82.9%，超越现有最先进方法且在24点游戏中实现100%准确率和13.6倍加速。

Abstract: The complex reasoning ability of Large Language Models (LLMs) poses a critical bottleneck for their practical applications. Test-time expansion methods such as Tree-of-Thought (ToT) and Graph-of-Thought (GoT) enhance reasoning by introducing intermediate reasoning structures, tree search, or graph-based exploration mechanisms. However, their reasoning strategies suffer from limited diversity, redundant search branches, and inadequate integration and error correction across heterogeneous reasoning paths. To address these limitations, we propose a novel reasoning framework called Multi-chain Graph Refinement & Selection (MGRS), which first generates multiple diverse reasoning trajectories for a given problem, refines candidate responses using a composite self- and cross-verification strategy, then constructs a reasoning relation graph and estimates the success rate of intermediate nodes, and finally computes cumulative success rates to select the most reliable answer and corresponding reasoning trajectory. Experimental results demonstrate that MGRS significantly advances both the reasoning capability and computational efficiency of reasoning enhancement methods. Across six benchmark datasets spanning four distinct tasks, MGRS achieves an average accuracy of 82.9%, outperforming state-of-the-art baselines by a clear margin of 2.1%. Remarkably, on the 24-point game, MGRS attains 100% accuracy for the first time, while delivering a 13.6x speed-up compared to the leading Forest of Thoughts framework.

</details>


### [93] [Are LLMs Good Safety Agents or a Propaganda Engine?](https://arxiv.org/abs/2511.23174)
*Neemesh Yadav,Francesco Ortu,Jiarui Liu,Joeun Yook,Bernhard Schölkopf,Rada Mihalcea,Alberto Cazzaniga,Zhijing Jin*

Main category: cs.CL

TL;DR: 构建PSP数据集，分析七种大语言模型对政治敏感内容的拒绝行为，发现大多数模型存在政治审查倾向。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏系统分析大语言模型拒绝响应背后是安全策略还是政治审查的区分，本研究旨在填补这一空白，通过构建专门的数据集来探究模型拒绝行为的政治动因。

Method: 建立包含来自中国及多国被审查内容的PSP数据集，采用数据驱动和表示层级方法分析政治敏感性对模型拒绝的影响，并评估模型对提示注入攻击的脆弱性。

Result: 本文通过构建PSP数据集，系统分析了大语言模型（LLMs）对政治敏感内容拒绝响应的行为，旨在区分安全策略驱动的拒绝与政治审查。使用来自中国及多国被审查的社交媒体内容，研究了七种LLMs在政治敏感性上的表现及其对提示注入攻击的脆弱性。结果显示，绝大多数模型存在某种形式的审查行为。最终总结了影响模型拒绝分布变化的主要因素及其在不同国家语境中的表现。

Conclusion: 大多数大语言模型在面对政治敏感内容时表现出某种形式的审查行为，拒绝响应分布受模型属性和国家语境影响显著。

Abstract: Large Language Models (LLMs) are trained to refuse to respond to harmful content. However, systematic analyses of whether this behavior is truly a reflection of its safety policies or an indication of political censorship, that is practiced globally by countries, is lacking. Differentiating between safety influenced refusals or politically motivated censorship is hard and unclear. For this purpose we introduce PSP, a dataset built specifically to probe the refusal behaviors in LLMs from an explicitly political context. PSP is built by formatting existing censored content from two data sources, openly available on the internet: sensitive prompts in China generalized to multiple countries, and tweets that have been censored in various countries. We study: 1) impact of political sensitivity in seven LLMs through data-driven (making PSP implicit) and representation-level approaches (erasing the concept of politics); and, 2) vulnerability of models on PSP through prompt injection attacks (PIAs). Associating censorship with refusals on content with masked implicit intent, we find that most LLMs perform some form of censorship. We conclude with summarizing major attributes that can cause a shift in refusal distributions across models and contexts of different countries.

</details>


### [94] [Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction](https://arxiv.org/abs/2511.23184)
*Wenna Lai,Haoran Xie,Guandong Xu,Qing Li,S. Joe Qin*

Main category: cs.CL

TL;DR: 本文提出基于推理生成和列表偏好优化的ASQP方法，提升了四元组预测准确性及解释一致性。


<details>
  <summary>Details</summary>
Motivation: 传统基于标记的方法难以建模ASQP中四个核心元素间的复杂关系，且在预测高阶元素时性能下降明显。

Method: 提出基于推理的生成方法，通过统一模板同时输出四元组及自然语言推理，并引入列表偏好优化框架，通过语法和语义相近的混淆候选训练模型增强结构有效性和关系一致性。

Result: 在四个基准数据集上实验表明，该框架显著提升了四元组预测的准确性和推理解释的一致性。

Conclusion: 采用推理生成结合列表优化的框架有效解决了ASQP的关系建模难题，提升了预测性能和模型解释能力。

Abstract: Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.

</details>


### [95] [TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies](https://arxiv.org/abs/2511.23225)
*Guang Liang,Jie Shao,Ningyuan Tang,Xinyao Liu,Jianxin Wu*

Main category: cs.CL

TL;DR: 本文通过提出TWEO损失函数根本解决了FP8训练中极端激活异常值问题，实现了高效稳定的全模型FP8训练及领先的量化性能。


<details>
  <summary>Details</summary>
Motivation: 现代硬件原生FP8支持训练大型Transformer模型，但极端激活异常值严重阻碍了FP8的有效使用，且现有方法依赖复杂混合精度或架构改动。

Method: 提出了一种非侵入式损失函数TWEO，利用结构性权重矩阵的线性相关性特征，抑制极端激活异常值，从而支持全模型FP8预训练，无需复杂工程或架构修改。

Result: TWEO将极端异常值数量从一万多降至不到20，实现FP8训练性能与BF16相当，同时训练吞吐量提升36%。此外，TWEO使得之前因异常值难以使用的硬件友好W8A8静态量化成为可能，首次实现SOTA性能。

Conclusion: TWEO通过简单的损失函数有效抑制了极端激活异常值，使得FP8训练变得稳定并显著提升了训练吞吐量，突破了以往对极端异常值源自数据的传统认知。

Abstract: Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.

</details>


### [96] [Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models](https://arxiv.org/abs/2511.23235)
*Praveen Gatla,Anushka,Nikita Kanwar,Gouri Sahoo,Rajesh Kumar Mundotiya*

Main category: cs.CL

TL;DR: 本文首次系统设计了面向印地语瓦拉纳西旅游领域的抽取式问答系统，构建和扩充了问答数据集，并利用BERT及RoBERTa基础模型，通过低秩适应和监督微调实现高效精准的问答性能，奠定了文化旅游领域印地语QA系统的基础。


<details>
  <summary>Details</summary>
Motivation: 针对印地语文化旅游领域缺乏专门的问答资源和系统，尤其是以瓦拉纳西这一具有深厚宗教和文化背景的旅游城市为研究对象，构建专门的问答系统。

Method: 基于预训练模型BERT和RoBERTa，采用监督微调(SFT)和低秩适应(LoRA)方法进行参数高效的微调，结合零样本提示生成的数据扩充，实现面向瓦拉纳西旅游子领域的问答系统设计。

Result: 构建了一个包含7715个印地语问答对的数据集，并通过Llama零样本提示生成 27455问答对。提出基于BERT和RoBERTa的基础模型，采用监督微调(SFT)和低秩适应(LoRA)技术，LoRA在参数效率和性能表现上取得了85.3%的F1分数，同时训练参数减少了98%。RoBERTa+SFT在理解文化相关词汇上优于其它BERT变体。

Conclusion: 本研究建立了印地语旅游领域问答系统的基线，验证了LoRA在低资源领域的优越性，强调了为文化旅游领域构建语境化NLP模型的重要性。

Abstract: This article presents the first comprehensive study on designing a baseline extractive question-answering (QA) system for the Hindi tourism domain, with a specialized focus on the Varanasi-a cultural and spiritual hub renowned for its Bhakti-Bhaav (devotional ethos). Targeting ten tourism-centric subdomains-Ganga Aarti, Cruise, Food Court, Public Toilet, Kund, Museum, General, Ashram, Temple and Travel, the work addresses the absence of language-specific QA resources in Hindi for culturally nuanced applications. In this paper, a dataset comprising 7,715 Hindi QA pairs pertaining to Varanasi tourism was constructed and subsequently augmented with 27,455 pairs generated via Llama zero-shot prompting. We propose a framework leveraging foundation models-BERT and RoBERTa, fine-tuned using Supervised Fine-Tuning (SFT) and Low-Rank Adaptation (LoRA), to optimize parameter efficiency and task performance. Multiple variants of BERT, including pre-trained languages (e.g., Hindi-BERT), are evaluated to assess their suitability for low-resource domain-specific QA. Evaluation metrics - F1, BLEU, and ROUGE-L - highlight trade-offs between answer precision and linguistic fluency. Experiments demonstrate that LoRA-based fine-tuning achieves competitive performance (85.3\% F1) while reducing trainable parameters by 98\% compared to SFT, striking a balance between efficiency and accuracy. Comparative analysis across models reveals that RoBERTa with SFT outperforms BERT variants in capturing contextual nuances, particularly for culturally embedded terms (e.g., Aarti, Kund). This work establishes a foundational baseline for Hindi tourism QA systems, emphasizing the role of LORA in low-resource settings and underscoring the need for culturally contextualized NLP frameworks in the tourism domain.

</details>


### [97] [Behavior-Equivalent Token: Single-Token Replacement for Long Prompts in LLMs](https://arxiv.org/abs/2511.23271)
*Jiancheng Dong,Pengyue Jia,Jingyu Peng,Maolin Wang,Yuhao Wang,Lixin Su,Xin Sun,Shuaiqiang Wang,Dawei Yin,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 本研究提出一种方法，通过训练单个行为等效标记，大幅缩短系统提示词长度，显著降低推理成本且保持模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统的长系统提示词虽然能有效引导大型语言模型（LLM）的行为，但其长度导致推理延迟增加、计算成本升高以及上下文长度有效利用率降低。

Method: 采用三阶段训练：首先通过重建学习[BE]编码原提示的自然语言内容；其次将下游任务行为蒸馏进该单标记；整个过程无需模型内部信息、辅助压缩模型或标注响应。

Result: 提出一种轻量级三阶段训练框架，学习单一的行为等效标记（[BE]），能够将提示长度减少至原来的1/3000，同时保留约98%的下游任务性能。

Conclusion: 单个[BE]标记能够极大压缩提示长度，降低计算资源消耗，同时保持与原始提示相近的下游任务性能，且方法无须访问模型内部结构。

Abstract: Carefully engineered system prompts play a critical role in guiding the behavior of LLM agents, but their considerable length introduces significant drawbacks, including increased inference latency, higher computational cost, and reduced effective context length. This raises the question of whether such lengthy prompts can be replaced by a drastically reduced number of tokens while preserving their behavioral effect on downstream tasks. To enable this, we propose a lightweight three-stage training framework that learns a single prompt-specific Behavior-Equivalent token ([BE]). The framework first trains [BE] to encode the natural-language content of the original system prompt via reconstruction, and then distills the prompt 's downstream behavior into this single token. Importantly, our method requires no access to model internals, no auxiliary compression models, and no labeled responses. Empirical evaluations on three datasets show that a single [BE] token achieves up to a 3000x reduction in prompt length, while retaining about 98% of the downstream performance of the original system prompts. This substantially reduces inference cost and leaves almost the entire context window available for user inputs.

</details>


### [98] [MCP vs RAG vs NLWeb vs HTML: A Comparison of the Effectiveness and Efficiency of Different Agent Interfaces to the Web (Technical Report)](https://arxiv.org/abs/2511.23281)
*Aaron Steiner,Ralph Peeters,Christian Bizer*

Main category: cs.CL

TL;DR: 本文首次在统一测试平台上比较了HTML、RAG、MCP和NLWeb四种LLM代理接口，发现RAG结合GPT5表现最佳，显著提升效果和效率，提示接口设计对LLM代理性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 当前研究中缺乏对四种不同大语言模型(Large Language Model, LLM)代理与网站交互架构（HTML浏览、基于检索增强生成RAG、使用模型上下文协议MCP的Web API通信以及自然语言查询NLWeb）在相同任务和环境下的系统比较。

Method: 构建了一个包含四个模拟电子商店的测试平台，分别支持HTML、RAG、MCP和NLWeb四种接口，每种接口设计了专门的代理执行相同的任务集合。这些任务包括产品搜索、价格比较、复杂的补充或替代产品查询及结账流程。使用不同的LLM（GPT4.1、GPT5、GPT5 mini、Claude Sonnet 4）进行评估。

Result: RAG、MCP和NLWeb代理在任务有效性和效率上均优于HTML代理，整体F1得分从HTML的0.67提升到0.75至0.77，任务令牌使用量从241k减少到47k至140k，任务运行时间从291秒缩短至50秒至62秒。最佳配置是RAG结合GPT5，F1得分为0.87，完成率0.79，RAG与GPT5 mini则在成本和性能上取得良好平衡。

Conclusion: 不同的交互接口对LLM驱动的网络代理的性能影响显著，选择合适的接口可以显著提升代理的效果和效率，且在成本控制方面也有优化空间。

Abstract: Large language model agents are increasingly used to automate web tasks such as product search, offer comparison, and checkout. Current research explores different interfaces through which these agents interact with websites, including traditional HTML browsing, retrieval-augmented generation (RAG) over pre-crawled content, communication via Web APIs using the Model Context Protocol (MCP), and natural-language querying through the NLWeb interface. However, no prior work has compared these four architectures within a single controlled environment using identical tasks.
  To address this gap, we introduce a testbed consisting of four simulated e-shops, each offering its products via HTML, MCP, and NLWeb interfaces. For each interface (HTML, RAG, MCP, and NLWeb) we develop specialized agents that perform the same sets of tasks, ranging from simple product searches and price comparisons to complex queries for complementary or substitute products and checkout processes. We evaluate the agents using GPT 4.1, GPT 5, GPT 5 mini, and Claude Sonnet 4 as underlying LLM. Our evaluation shows that the RAG, MCP and NLWeb agents outperform HTML on both effectiveness and efficiency. Averaged over all tasks, F1 rises from 0.67 for HTML to between 0.75 and 0.77 for the other agents. Token usage falls from about 241k for HTML to between 47k and 140k per task. The runtime per task drops from 291 seconds to between 50 and 62 seconds. The best overall configuration is RAG with GPT 5 achieving an F1 score of 0.87 and a completion rate of 0.79. Also taking cost into consideration, RAG with GPT 5 mini offers a good compromise between API usage fees and performance. Our experiments show the choice of the interaction interface has a substantial impact on both the effectiveness and efficiency of LLM-based web agents.

</details>


### [99] [Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models](https://arxiv.org/abs/2511.23319)
*Xiang Hu,Zhanchao Zhou,Ruiqi Liang,Zehuan Li,Wei Wu,Jianguo Li*

Main category: cs.CL

TL;DR: 本文提出HSA注意力机制，构建了具备稀疏性、随机访问灵活性和长度泛化能力的HSA-UltraLong模型，成功处理超长上下文，性能优异。


<details>
  <summary>Details</summary>
Motivation: 构建具备长时记忆能力的机器，需解决超长上下文建模的效率和灵活性问题。

Method: 引入层次稀疏注意力机制（HSA），融合进8B参数MoE Transformer模型中，训练于超过8万亿token。

Result: 模型在16M上下文长度内的上下文检索任务中准确率超过90%，与全遮蔽基线模型在内域长度表现相当。

Conclusion: HSA-UltraLong模型在处理超长上下文上表现出色，兼具稀疏性、随机访问灵活性和长度泛化性，证明了其在超长记忆建模中的有效性。

Abstract: This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \textbf{sparsity}, \textbf{random-access flexibility}, and \textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.

</details>


### [100] [Tackling a Challenging Corpus for Early Detection of Gambling Disorder: UNSL at MentalRiskES 2025](https://arxiv.org/abs/2511.23325)
*Horacio Thompson,Marcelo Errecalde*

Main category: cs.CL

TL;DR: 本文提出结合多模型与用户历史分析的赌博障碍早期风险分类方法，在竞赛中排名优秀，但仍需提升区分能力和数据质量。


<details>
  <summary>Details</summary>
Motivation: 赌博障碍是一种复杂的行为成瘾，具有严重的身心和社会后果，早期风险检测对于心理健康行为的识别非常关键。

Method: 基于CPI+DMC方法，使用SS3、扩展词汇的BERT和SBERT模型组合，结合用户历史数据分析的决策策略。

Result: 在MentalRiskES 2025挑战赛中，我们的两个方案取得官方排名的前两名，特别在决策指标上表现优异。

Conclusion: 尽管表现优异，但区分高低风险用户仍有难度，需改善数据解读与质量，推动更透明可靠的心理健康早期风险检测系统。

Abstract: Gambling disorder is a complex behavioral addiction that is challenging to understand and address, with severe physical, psychological, and social consequences. Early Risk Detection (ERD) on the Web has become a key task in the scientific community for identifying early signs of mental health behaviors based on social media activity. This work presents our participation in the MentalRiskES 2025 challenge, specifically in Task 1, aimed at classifying users at high or low risk of developing a gambling-related disorder. We proposed three methods based on a CPI+DMC approach, addressing predictive effectiveness and decision-making speed as independent objectives. The components were implemented using the SS3, BERT with extended vocabulary, and SBERT models, followed by decision policies based on historical user analysis. Although it was a challenging corpus, two of our proposals achieved the top two positions in the official results, performing notably in decision metrics. Further analysis revealed some difficulty in distinguishing between users at high and low risk, reinforcing the need to explore strategies to improve data interpretation and quality, and to promote more transparent and reliable ERD systems for mental disorders.

</details>


### [101] [Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach](https://arxiv.org/abs/2511.23335)
*Shuqi Liu,Han Wu,Guanzhi Deng,Jianshu Chen,Xiaoyang Wang,Linqi Song*

Main category: cs.CL

TL;DR: 提出一种任务无关的结构化知识猎手，结合层次化知识表示和指针网络，实现高可解释性和优异性能的知识增强文本生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖领域特定知识检索器，缺乏普适性且可解释性不足，限制了知识增强文本生成的实际应用。设计一种通用且高可解释性的知识利用框架成为必要。

Method: 设计任务无关的结构化知识猎手，利用两层结构化知识架构（高层实体和低层知识三元组），采用局部-全局交互方案进行知识表示学习，采用基于层次变压器的指针网络选择相关知识。结合语言模型生成能力和知识猎手的高可信度，实现高可解释性的文本生成。

Result: 在RotoWireFG数据集的表格到文本任务和KdConv对话生成任务上表现优异，超越了现有最先进方法和对应语言模型，建立了新的基准。

Conclusion: 该方法通过结构化知识的层次化利用和高效的知识选择机制，提高了知识增强文本生成的可解释性和生成质量，增强了模型的通用性并提升了实际应用价值。

Abstract: Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.

</details>


### [102] [Scaling HuBERT for African Languages: From Base to Large and XL](https://arxiv.org/abs/2511.23370)
*Antoine Caubrière,Elodie Gauthier*

Main category: cs.CL

TL;DR: 本文首次发布了专注于非洲语音训练的大型自监督模型，实验表明更大模型在撒哈拉以南非洲语言的语音任务上有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言语音处理进展显著，非洲语言研究和应用仍不足，尤其缺乏在低资源条件下表现优异的大型开放权重编码器；自监督学习虽有潜力，但当前公开模型多为基础规模，亟需探索大型非洲语音专属模型的优势及模型容量与数据组成的关系。

Method: 引入SSA-HuBERT-Large（317M参数）和SSA-HuBERT-XL（964M参数）两个仅在非洲语音上训练的大型自监督学习模型，并进行对比实验以评估其在撒哈拉以南非洲语言的语音识别（ASR）和语言识别（LID）任务上的表现。

Result: 实验结果显示，较大的模型架构显著提升了性能，能够有效利用大规模非洲语音数据集。

Conclusion: 针对非洲语言的开放权重大型自监督模型能在低资源环境下取得更好表现，强调了模型容量和数据规模的重要性。

Abstract: Despite recent progress in multilingual speech processing, African languages remain under-represented in both research and deployed systems, particularly when it comes to strong, open-weight encoders that transfer well under low-resource supervision. Self-supervised learning has proven especially promising in such settings, yet most publicly released models targeting African speech remain at BASE scale, leaving unanswered whether larger encoders, trained exclusively on Africa-centric audio, offer tangible benefits and how model capacity interacts with data composition. This work addresses that gap by introducing SSA-HuBERT-Large (317M parameters) and SSA-HuBERT-XL (964M parameters), the first large models trained solely on African speech, alongside a BASE size counterpart. We release these models as open weights: see https://huggingface.co/collections/Orange/african-speech-foundation-models. By conducting a carefully controlled experimental study focused exclusively on Sub-Saharan languages, covering automatic speech recognition (ASR) and language identification (LID) tasks, we demonstrate that larger architectures significantly improve performance by effectively leveraging large audio datasets.

</details>


### [103] [Optimizing Multimodal Language Models through Attention-based Interpretability](https://arxiv.org/abs/2511.23375)
*Alexander Sergeev,Evgeny Kotelnikov*

Main category: cs.CL

TL;DR: 本文提出一种基于注意力得分的多模态模型可解释性方法，通过识别关注图像关键物体的注意力头，优选微调组件，实现仅调优极少参数显著提升图像理解效果。


<details>
  <summary>Details</summary>
Motivation: 多模态大模型微调成本高且模型难以解释，亟需一种方法有效识别关键组件以实现高效微调。

Method: 通过分析与图像关键物体相关的注意力头得分，计算注意力头影响分数（HI），选取高HI层进行参数高效微调，验证在2-3亿参数模型上的效果。

Result: 提出了一种基于注意力机制的多模态语言模型（MLMs）可解释性方法，通过分析与图像关键物体相关的注意力头，指导参数高效微调（PEFT）以提升图像理解能力。基于该方法计算的注意力头影响（HI）分数，选取关键层进行微调，在图像描述任务中仅调优约0.01%的参数即可显著提升性能。

Conclusion: 利用注意力头与图像关键物体的关联性，能够有效识别对多模态理解关键的模型组件，指导PEFT策略实现效率与性能的平衡，证明了该方法对大型多模态语言模型微调的实用价值。

Abstract: Modern large language models become multimodal, analyzing various data formats like text and images. While fine-tuning is effective for adapting these multimodal language models (MLMs) to downstream tasks, full fine-tuning is computationally expensive. Parameter-Efficient Fine-Tuning (PEFT) methods address this by training only a small portion of model weights. However, MLMs are difficult to interpret, making it challenging to identify which components are most effective for training to balance efficiency and performance. We propose an attention-based interpretability method for MLMs by analyzing attention scores relative to image tokens. The core idea is to identify attention heads that focus on image key objects. We utilize this information to select optimal model components for PEFT in multimodal models. Our contributions include a method for identifying attention heads associated with image key objects, its application to PEFT for image captioning, and the creation of a new dataset containing images, key object masks, and their textual descriptions. We conducted experiments on MLMs with 2-3 billion parameters to validate the method's effectiveness. By calculating Head Impact (HI) scores we quantify an attention head's focus on key objects, indicating its significance in image understanding. Our fine-tuning experiments demonstrate that adapting layers with the highest HI scores leads to the most significant shifts in metrics compared to pre-trained, randomly selected, or lowest-HI-score layers. This indicates that fine-tuning a small percentage (around 0.01%) of parameters in these crucial layers can substantially influence image understanding capabilities.

</details>


### [104] [Ambiguity Awareness Optimization: Towards Semantic Disambiguation for Direct Preference Optimization](https://arxiv.org/abs/2511.23391)
*Jian Li,Shenglin Yin,Yujia Zhang,Alan Zhao,Xi Chen,Xiaohui Zhou,Pengfei Xu*

Main category: cs.CL

TL;DR: 针对DPO训练中的模糊内容带来的歧义性，本文提出了AAO方法，通过语义相似度加权解决歧义问题，显著提升了对齐效果。


<details>
  <summary>Details</summary>
Motivation: 观察到偏好对中存在大量相同或语义相似的模糊内容，推测其引入的歧义性限制了DPO训练的性能提升，因而提出改进方法。

Method: 提出了直接偏好优化（DPO）方法，并引入了模糊内容加权的新方法“模糊感知优化 (AAO)”，通过计算偏好对中的语义相似度，自动重新加权模糊内容。

Result: AAO方法在多个模型规模和多个主流评测数据集（AlpacaEval 2, MT-Bench, Arena-Hard）上表现出显著优于DPO的效果，提升幅度最高达15分，并且没有显著增加回应长度。

Conclusion: 偏好对中模糊内容的存在会引入不确定性，降低了DPO的性能；通过AAO方法加权模糊内容，可以有效缓解该问题，显著提升模型对齐性能。

Abstract: Direct Preference Optimization (DPO) is a widely used reinforcement learning from human feedback (RLHF) method across various domains. Recent research has increasingly focused on the role of token importance in improving DPO effectiveness. It is observed that identical or semantically similar content (defined as ambiguous content) frequently appears within the preference pairs. We hypothesize that the presence of ambiguous content during DPO training may introduce ambiguity, thereby limiting further improvements in alignment. Through mathematical analysis and proof-of-concept experiments, we reveal that ambiguous content may potentially introduce ambiguities, thereby degrading performance. To address this issue, we introduce Ambiguity Awareness Optimization (AAO), a simple yet effective approach that automatically re-weights ambiguous content to reduce ambiguities by calculating semantic similarity from preference pairs. Through extensive experiments, we demonstrate that AAO consistently and significantly surpasses state-of-the-art approaches in performance, without markedly increasing response length, across multiple model scales and widely adopted benchmark datasets, including AlpacaEval 2, MT-Bench, and Arena-Hard. Specifically, AAO outperforms DPO by up to 8.9 points on AlpacaEval 2 and achieves an improvement of by up to 15.0 points on Arena-Hard.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [105] [AgentShield: Make MAS more secure and efficient](https://arxiv.org/abs/2511.22924)
*Kaixiang Wang,Zhaojiacheng Zhou,Bunyod Suvonov,Jiong Lou,Jie LI*

Main category: cs.MA

TL;DR: 提出了AgentShield，一个三层次的分布式审计框架，通过关键节点审核、轻量令牌审核和两轮共识审核，实现了高效且鲁棒的对抗攻击防御。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统防御方法依赖单一可信审计器或牺牲效率以增强鲁棒性，存在单点故障或效率低下的问题。

Method: AgentShield设计了三层防御机制：关键节点审计优先检测高影响力智能体，轻量令牌审计通过轻量哨兵模型快速验证，两轮共识审计在不确定时启动重型仲裁，优化了效率与鲁棒性。

Result: 实验表明，AgentShield在多种多智能体拓扑和对抗场景中实现了92.5%的恢复率，审计开销降低超过70%，保持了高协作准确率。

Conclusion: AgentShield框架通过三级分布式审计机制有效提升了大型语言模型多智能体系统的安全性与效率，在保证系统整体性能的前提下，显著减少审计开销并提高恢复率。

Abstract: Large Language Model (LLM)-based Multi-Agent Systems (MAS) offer powerful cooperative reasoning but remain vulnerable to adversarial attacks, where compromised agents can undermine the system's overall performance. Existing defenses either depend on single trusted auditors, creating single points of failure, or sacrifice efficiency for robustness. To resolve this tension, we propose \textbf{AgentShield}, a distributed framework for efficient, decentralized auditing. AgentShield introduces a novel three-layer defense: \textbf{(i) Critical Node Auditing} prioritizes high-influence agents via topological analysis; \textbf{(ii) Light Token Auditing} implements a cascade protocol using lightweight sentry models for rapid discriminative verification; and \textbf{(iii) Two-Round Consensus Auditing} triggers heavyweight arbiters only upon uncertainty to ensure global agreement. This principled design optimizes the robustness-efficiency trade-off. Experiments demonstrate that AgentShield achieves a 92.5\% recovery rate and reduces auditing overhead by over 70\% compared to existing methods, maintaining high collaborative accuracy across diverse MAS topologies and adversarial scenarios.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [106] [Technical knowledge and soft skills in software startups within the Colombian entrepreneurial ecosystem](https://arxiv.org/abs/2511.21769)
*Royer David Estrada-Esponda,Gerardo Matturro,Jose Reinaldo Sabogal-Pinilla*

Main category: cs.SE

TL;DR: 创业团队的技术知识和软技能对软件初创企业的早期成功至关重要，需求工程和沟通等能力最受重视。


<details>
  <summary>Details</summary>
Motivation: 明确软件初创企业创始团队最重视的技术知识和软技能，以及这些需求随企业成长的变化，有助于创业者和相关支持机构更好地支持初创企业发展。

Method: 通过在哥伦比亚创业生态系统内对软件初创企业代表进行问卷调查，收集关于技术知识和软技能的重要性的数据。

Result: 发现需求工程、软件测试、项目规划和管理、敏捷方法论、市场营销、商业模型定义及预算编制是最受重视的技术知识；沟通、领导力和团队合作是最受重视的软技能。结果对软件创业者、孵化器和研究人员具有指导意义。

Conclusion: 创业团队成员的技术知识和软技能在软件初创企业的早期阶段起着关键作用。需求工程、软件测试、项目规划与管理、敏捷方法论等技术知识，以及沟通、领导力和团队合作等软技能，是创业团队最看重的。随着初创企业的发展，对知识和技能的需求也在不断变化。

Abstract: The technical knowledge and soft skills of entrepreneurial team members significantly impact the early stages of software startups. It is widely recognized that the success or failure of a startup is determined by the quality of the individuals who constitute the founding team. This article presents the findings of a study conducted within the Colombian entrepreneurial ecosystem, focusing on which technical knowledge and soft skills are the most valued by founding teams of software startups, and how the needs for knowledge and skills evolve as the startup grows. A survey of software startup representatives revealed that the most valued knowledge includes requirements engineering, software testing, project planning and management, agile methodologies, marketing, business model definition, and budgeting. The most valued soft skills are typically communication, leadership, and teamwork. The outcomes of this work are relevant to software entrepreneurs, incubators, and researchers.

</details>


### [107] [Code Refactoring with LLM: A Comprehensive Evaluation With Few-Shot Settings](https://arxiv.org/abs/2511.21788)
*Md. Raihan Tapader,Md. Mostafizer Rahman,Ariful Islam Shiplu,Md Faizul Ibne Amin,Yutaka Watanobe*

Main category: cs.SE

TL;DR: 本研究提出了基于大语言模型的多语言代码重构方法，通过微调和prompt工程提升重构准确率和代码质量，Java和Python表现尤为突出。


<details>
  <summary>Details</summary>
Motivation: 程序员日益关注代码的简洁、清晰与高效，现有重构方法难以跨多语言通用，因而开发一个通用且高效的多语言重构框架具有实际需求和研究价值。

Method: 使用大语言模型(LLMs)结合微调的prompt工程和few-shot学习，开发了一个支持多语言(C, C++, C#, Python, Java)代码重构的框架。通过调整温度参数和不同的示例算法，优化重构效果。

Result: Java在10-shot设置下实现了最高99.99%的正确率，平均编译率达到94.78%，代码结构和语义的平衡表现优异。Python在结构距离方面表现最佳，修改不明显且保持较高相似度。

Conclusion: 基于LLMs的多语言代码重构框架能够有效提升代码质量，兼顾结构优化和语义保留，并且通过prompt工程与微调显著提升重构效果。

Abstract: In today's world, the focus of programmers has shifted from writing complex, error-prone code to prioritizing simple, clear, efficient, and sustainable code that makes programs easier to understand. Code refactoring plays a critical role in this transition by improving structural organization and optimizing performance. However, existing refactoring methods are limited in their ability to generalize across multiple programming languages and coding styles, as they often rely on manually crafted transformation rules. The objectives of this study are to (i) develop an Large Language Models (LLMs)-based framework capable of performing accurate and efficient code refactoring across multiple languages (C, C++, C#, Python, Java), (ii) investigate the impact of prompt engineering (Temperature, Different shot algorithm) and instruction fine-tuning on refactoring effectiveness, and (iii) evaluate the quality improvements (Compilability, Correctness, Distance, Similarity, Number of Lines, Token, Character, Cyclomatic Complexity) in refactored code through empirical metrics and human assessment. To accomplish these goals, we propose a fine-tuned prompt-engineering-based model combined with few-shot learning for multilingual code refactoring. Experimental results indicate that Java achieves the highest overall correctness up to 99.99% the 10-shot setting, records the highest average compilability of 94.78% compared to the original source code and maintains high similarity (Approx. 53-54%) and thus demonstrates a strong balance between structural modifications and semantic preservation. Python exhibits the lowest structural distance across all shots (Approx. 277-294) while achieving moderate similarity ( Approx. 44-48%) that indicates consistent and minimally disruptive refactoring.

</details>


### [108] [LLM-Empowered Event-Chain Driven Code Generation for ADAS in SDV systems](https://arxiv.org/abs/2511.21877)
*Nenad Petrovic,Norbert Kroth,Axel Torschmied,Yinglei Song,Fengjunjie Pan,Vahid Zolfaghari,Nils Purschke,Sven Kirchner,Chengdong Wu,Andre Schamschurko,Yi Zhang,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出结合事件链和检索增强的大语言模型工作流程，从自然语言需求生成经过验证的汽车代码，实现了信号的有效利用和一致的代码生成。


<details>
  <summary>Details</summary>
Motivation: 传统的汽车代码生成面临语言模型幻觉和架构错误问题，亟需一种能结合车辆信号规范并保证代码行为一致性的生成方法。

Method: 提出基于事件链驱动和大语言模型(LLM)赋能的工作流程，结合检索增强生成（RAG）层，从车辆信号规范（VSS）目录中检索相关信号作为代码生成上下文，并进行信号映射和验证，再转换成编码因果及定时约束的事件链，指导LLM生成符合行为一致性和实时性的汽车代码。

Result: 通过紧急制动案例研究，方法实现了有效的信号使用和一致的代码生成，无需对LLM进行重新训练。

Conclusion: 该方法有效减少了模型的幻觉问题，确保了生成代码的架构正确性和行为一致性，验证了基于事件链和检索增强的LLM代码生成在汽车领域的可行性。

Abstract: This paper presents an event-chain-driven, LLM-empowered workflow for generating validated, automotive code from natural-language requirements. A Retrieval-Augmented Generation (RAG) layer retrieves relevant signals from large and evolving Vehicle Signal Specification (VSS) catalogs as code generation prompt context, reducing hallucinations and ensuring architectural correctness. Retrieved signals are mapped and validated before being transformed into event chains that encode causal and timing constraints. These event chains guide and constrain LLM-based code synthesis, ensuring behavioral consistency and real-time feasibility. Based on our initial findings from the emergency braking case study, with the proposed approach, we managed to achieve valid signal usage and consistent code generation without LLM retraining.

</details>


### [109] [Advancing Automated In-Isolation Validation in Repository-Level Code Translation](https://arxiv.org/abs/2511.21878)
*Kaiyao Ke,Ali Reza Ibrahimzada,Rangeet Pan,Saurabh Sinha,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出TRAM，一种结合上下文类型解析与mock隔离验证的仓库级代码翻译方法，在Java-Python翻译中表现出色，实现了高质量自动跨语言代码迁移。


<details>
  <summary>Details</summary>
Motivation: 仓库级代码翻译旨在自动跨编程语言迁移整个代码库并保持功能完整，但翻译的验证过程仍具有挑战性。

Method: 提出TRAM方法，结合了上下文感知的类型解析和基于mock的隔离验证。TRAM在翻译前检索API文档和变量类型的上下文信息，利用大语言模型解决跨语言的类型映射，随后通过自定义的序列化/反序列化流程构造目标语言的mock对象，实现方法片段的隔离验证。

Result: TRAM在Java到Python的代码翻译任务中展示了最先进的性能，证明了其基于检索增强生成(RAG)的类型解析与可靠隔离验证的有效性。

Conclusion: 结合上下文的精确类型映射与自动化的隔离验证，TRAM有效提升了跨语言代码库迁移的质量和效率，避免了高成本的验证手段和繁重的人工工作。

Abstract: Repository-level code translation aims to migrate entire repositories across programming languages while preserving functionality automatically. Despite advancements in repository-level code translation, validating the translations remains challenging. This paper proposes TRAM, which combines context-aware type resolution with mock-based in-isolation validation to achieve high-quality translations between programming languages. Prior to translation, TRAM retrieves API documentation and contextual code information for each variable type in the source language. It then prompts a large language model (LLM) with retrieved contextual information to resolve type mappings across languages with precise semantic interpretations. Using the automatically constructed type mapping, TRAM employs a custom serialization/deserialization workflow that automatically constructs equivalent mock objects in the target language. This enables each method fragment to be validated in isolation, without the high cost of using agents for translation validation, or the heavy manual effort required by existing approaches that rely on language interoperability. TRAM demonstrates state-of-the-art performance in Java-to-Python translation, underscoring the effectiveness of its integration of RAG-based type resolution with reliable in-isolation validation.

</details>


### [110] [Toward Automated and Trustworthy Scientific Analysis and Visualization with LLM-Generated Code](https://arxiv.org/abs/2511.21920)
*Apu Kumar Chakroborti,Yi Ding,Lipeng Wan*

Main category: cs.SE

TL;DR: 本文评估了开源大型语言模型生成科学数据分析代码的可信度，发现存在可靠性问题并提出三种改进策略，展示了LLM在科学自动化中的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 科学领域大量数据的分析和可视化对于加速发现非常关键，但许多领域科学家缺乏编程能力，导致难以开发定制的数据分析流程，阻碍了及时有效的洞察。

Method: 调查开源大型语言模型(LLMs)自动生成用于科学数据分析和可视化的Python脚本的可信度，构建了基于真实研究任务的基准测试套件，系统评估生成代码的可执行性和正确性，设计了数据感知提示消歧、检索增强提示改进和迭代错误修复三种策略以提升模型表现。

Result: 未经人工干预时，LLM生成代码的可靠性有限，常因提示模糊和模型对领域特定语境理解不足导致失败。所提出的三种策略显著提高了执行成功率和输出质量，但仍需进一步优化。

Conclusion: LLM驱动的科学工作流自动化虽具有潜力，但当前存在显著局限，本文提出的技术和基准为开发更包容、易用且可信的AI辅助科研工具奠定基础。

Abstract: As modern science becomes increasingly data-intensive, the ability to analyze and visualize large-scale, complex datasets is critical to accelerating discovery. However, many domain scientists lack the programming expertise required to develop custom data analysis workflows, creating barriers to timely and effective insight. Large language models (LLMs) offer a promising solution by generating executable code from natural language descriptions. In this paper, we investigate the trustworthiness of open-source LLMs in autonomously producing Python scripts for scientific data analysis and visualization. We construct a benchmark suite of domain-inspired prompts that reflect real-world research tasks and systematically evaluate the executability and correctness of the generated code. Our findings show that, without human intervention, the reliability of LLM-generated code is limited, with frequent failures caused by ambiguous prompts and the models' insufficient understanding of domain-specific contexts. To address these challenges, we design and assess three complementary strategies: data-aware prompt disambiguation, retrieval-augmented prompt enhancement, and iterative error repair. While these methods significantly improve execution success rates and output quality, further refinement is needed. This work highlights both the promise and current limitations of LLM-driven automation in scientific workflows and introduces actionable techniques and a reusable benchmark for building more inclusive, accessible, and trustworthy AI-assisted research tools.

</details>


### [111] [Beyond Like-for-Like: A User-centered Approach to Modernizing Legacy Applications](https://arxiv.org/abs/2511.21956)
*M. Polzin,M. Guzman*

Main category: cs.SE

TL;DR: 现代化遗留应用不仅仅是复制旧应用，而是通过用户参与解决现有问题，设计更高效直观的新应用。


<details>
  <summary>Details</summary>
Motivation: 传统做法常简单复制旧应用，忽视了遗留应用的痛点和用户体验，导致新应用无法解决实际问题。希望通过用户参与，创造更符合用户需求的新应用。

Method: 结合遗留应用的现有操作经验，深入了解用户痛点，邀请用户参与设计过程，平衡旧有结构和新界面的创新，实现高效现代化。

Result: 本文探讨了在现代化遗留应用程序时，避免简单复制原有应用，而是结合用户需求设计更直观、高效的新应用的重要性。强调用户参与对改进设计的关键作用，并指出遗留应用作为已有经验和操作基础，对新应用开发具有指导意义。

Conclusion: 遗留应用的存在虽然带来技术负担，但通过用户参与和对现有痛点的深入理解，可以设计出兼顾熟练用户与新用户需求的现代化应用。

Abstract: When modernizing a legacy application, it is easy to fall back on a like-for-like replica with new tools and updated design stylings, but this is an opportunity to explore making a more intuitive application that supports user tasks and efficiency. Rather than having a blank canvas-unburdened by legacy tech debt-to create a new application, you are working with an existing application that is integral to accelerator operations and one that expert users are already familiar with. Due to this, you might assume people will prefer the like-for-like, but you could be carrying forward the pain points, processes that are inefficient, and ultimately wind up with an application that no one wants to use because it doesn't solve existing problems. Getting users involved can make all the difference in your approach to modernizing a legacy application that caters to both newer and expert users. It also can bridge the gap between like-for-like and introducing new GUI design. Having a legacy application doesn't have to make the modernized one difficult to develop, as the existing application is a tool in how you move forward with the new application. It provides insight into areas that an application with a clean slate doesn't give you.

</details>


### [112] [DRS-OSS: LLM-Driven Diff Risk Scoring Tool for PR Risk Prediction](https://arxiv.org/abs/2511.21964)
*Ali Sayedsalehi,Peter C. Rigby,Audris Mockus*

Main category: cs.SE

TL;DR: 本文提出了DRS-OSS，一个基于Llama 3.1模型的开源差异风险评分系统，用于预测代码变更引入缺陷的可能性，实现更高效的代码审查与测试。


<details>
  <summary>Details</summary>
Motivation: 在大型开源项目中，数百个拉取请求（pull requests）每天产生，存在引入缺陷的风险，需有效评估变更风险以优化审核和测试流程。

Method: 基于ApacheJIT数据集对Llama 3.1 8B模型进行微调，结合提交信息、结构化差异和变更指标，采用参数高效调整、4-bit QLoRA和DeepSpeed ZeRO-3 CPU卸载技术，实现长上下文（22k token）训练。

Result: 在ApacheJIT基准测试上，DRS-OSS达到F1=0.64、ROC-AUC=0.89的领先性能。模拟显示仅对风险最高的30%提交进行管控，可防止86.4%的缺陷引入。

Conclusion: DRS-OSS系统不仅性能优异，还通过API、Web界面和GitHub插件无缝集成开发者工作流，促进实用性和社区推广。所有代码及资源均已公开。

Abstract: In large-scale open-source projects, hundreds of pull requests land daily, each a potential source of regressions. Diff Risk Scoring (DRS) estimates the likelihood that a diff will introduce a defect, enabling better review prioritization, test planning, and CI/CD gating. We present DRS-OSS, an open-source DRS system equipped with a public API, web UI, and GitHub plugin. DRS-OSS uses a fine-tuned Llama 3.1 8B sequence classifier trained on the ApacheJIT dataset, consuming long-context representations that combine commit messages, structured diffs, and change metrics. Through parameter-efficient adaptation, 4-bit QLoRA, and DeepSpeed ZeRO-3 CPU offloading, we train 22k-token contexts on a single 20 GB GPU. On the ApacheJIT benchmark, DRS-OSS achieves state-of-the-art performance (F1 = 0.64, ROC-AUC = 0.89). Simulations show that gating only the riskiest 30% of commits can prevent up to 86.4% of defect-inducing changes. The system integrates with developer workflows through an API gateway, a React dashboard, and a GitHub App that posts risk labels on pull requests. We release the full replication package, fine-tuning scripts, deployment artifacts, code, demo video, and public website.

</details>


### [113] [Statistical Independence Aware Caching for LLM Workflows](https://arxiv.org/abs/2511.22118)
*Yihan Dai,Dimitrios Stamatios Bouras,Haoxiang Jia,Sergey Mechtaev*

Main category: cs.SE

TL;DR: 本文提出了Mnimi缓存设计模式，解决了LLM缓存时统计独立性被破坏的问题，实现了高效且统计正确的缓存管理，提升了可重复性和效率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理成本高且速度慢，局部缓存响应可以降低成本和延迟，但简单缓存复用会破坏统计独立性，影响概率流程的准确性。

Method: 提出Mnimi缓存设计模式，通过在LLM引用类型中封装统计约束，保证统计独立性，同时支持模块化LLM工作流程，利用Python的装饰器和无限序列迭代器实现。

Result: 通过在SpecFix自动程序规范修复系统上的案例研究，Mnimi提升了结果的可重复性、调试便利性以及时间和成本效率，同时保持了统计正确性。

Conclusion: Mnimi为LLM缓存提供了一种保障统计独立性的方法，在保证统计完整性的前提下，实现了高效的缓存管理，适用于需要概率准确性和模块化的LLM应用。

Abstract: Large language models (LLMs) inference is both expensive and slow. Local caching of responses offers a practical solution to reduce the cost and latency of LLM queries. In research contexts, caching also enhances reproducibility and provides flexibility for experimentation. However, naive reuse of cached responses compromises statistical independence, a critical property for probabilistic workflows. In applications of LLM for code, it underpins performance metrics such as Pass@k and uncertainty estimation, as well as algorithms like program repair loops and retries. Existing LLM caching systems lack ways to enforce statistical independence constraints. To address this, we introduce Mnimi, a cache design pattern that supports modular LLM workflows while ensuring statistical integrity at the component level. Its core innovation lies in encapsulating statistical constraints within the type of LLM references, allowing users to manage and transform these types according to the scope and requirements of their algorithm. We implemented this design pattern in Python using a combination of decorators and iterators over infinite sequences. A case study on SpecFix, an recent automated program specification repair system, highlights how Mnimi improves reproducibility, ease of debugging, time and cost efficiency while preserving statistical correctness.

</details>


### [114] [Exploring the SECURITY.md in the Dependency Chain: Preliminary Analysis of the PyPI Ecosystem](https://arxiv.org/abs/2511.22186)
*Chayanid Termphaiboon,Raula Gaikovina Kula,Youmei Fan,Morakot Choetkiertikul,Chaiyong Ragkhitwetsagul,Thanwadee Sunetnanta,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 研究发现安全政策促进项目依赖管理，更模块化且依赖更新更频繁，提高安全性。


<details>
  <summary>Details</summary>
Motivation: 明确安全政策如何影响开源项目的软件依赖结构与演变，推动更安全的依赖管理。

Method: 通过分析PyPI项目中带有和不带有SECURITY.md文件的项目，研究其依赖树结构及依赖变化情况。

Result: 有安全策略的项目通常依赖更多的直接依赖，依赖深度和传递依赖相似；采用安全策略较晚的项目依赖更新频率更高。

Conclusion: 安全政策促进了更模块化和功能丰富的项目，有助于积极的依赖管理和降低软件供应链风险。

Abstract: Security policies, such as SECURITY.md files, are now common in open-source projects. They help guide responsible vulnerability reporting and build trust among users and contributors. Despite their growing use, it is still unclear how these policies influence the structure and evolution of software dependencies. Software dependencies are external packages or libraries that a project relies on, and their interconnected nature affects both functionality and security. This study explores the relationship between security policies and dependency management in PyPI projects. We analyzed projects with and without a SECURITY.md file by examining their dependency trees and tracking how dependencies change over time. The analysis shows that projects with a security policy tend to rely on a broader set of direct dependencies, while overall depth and transitive dependencies remain similar. Historically, projects created after the introduction of SECURITY.md, particularly later adopters, show more frequent dependency updates. These results suggest that security policies are linked to more modular and feature-rich projects, and highlight the role of SECURITY.md in promoting proactive dependency management and reducing risks in the software supply chain.

</details>


### [115] [UniBOM -- A Unified SBOM Analysis and Visualisation Tool for IoT Systems and Beyond](https://arxiv.org/abs/2511.22359)
*Vadim Safronov,Ionut Bostan,Nicholas Allott,Andrew Martin*

Main category: cs.SE

TL;DR: 本文提出UniBOM，一种结合多种代码分析技术的高精度SBOM工具，有效提升了复杂网络系统的漏洞检测与安全管理水平。


<details>
  <summary>Details</summary>
Motivation: 现有的软件物料清单（SBOM）解决方案在二进制分析及非包管理语言（如C/C++）中缺乏精确性，难以有效识别复杂软件栈中的安全漏洞。

Method: 提出UniBOM工具，集成二进制、文件系统及源代码分析，支持历史CPE追踪和基于AI的漏洞分类，专注于非包管理的C/C++依赖，提升细粒度漏洞检测能力。

Result: 通过对258个无线路由器固件二进制文件和4个流行物联网操作系统源码的比较分析，验证UniBOM在漏洞检测方面优于现有主流SBOM工具。

Conclusion: UniBOM作为开源统一分析和可视化解决方案，显著提升了基于SBOM的安全管理能力，增强了网络系统的安全责任保障。

Abstract: Modern networked systems rely on complex software stacks, which often conceal vulnerabilities arising from intricate interdependencies. A Software Bill of Materials (SBOM) is effective for identifying dependencies and mitigating security risks. However, existing SBOM solutions lack precision, particularly in binary analysis and non-package-managed languages like C/C++.
  This paper introduces UniBOM, an advanced tool for SBOM generation, analysis, and visualisation, designed to enhance the security accountability of networked systems. UniBOM integrates binary, filesystem, and source code analysis, enabling fine-grained vulnerability detection and risk management. Key features include historical CPE tracking, AI-based vulnerability classification by severity and memory safety, and support for non-package-managed C/C++ dependencies.
  UniBOM's effectiveness is demonstrated through a comparative vulnerability analysis of 258 wireless router firmware binaries and the source code of four popular IoT operating systems, highlighting its superior detection capabilities compared to other widely used SBOM generation and analysis tools. Packaged for open-source distribution, UniBOM offers an end-to-end unified analysis and visualisation solution, advancing SBOM-driven security management for dependable networked systems and broader software.

</details>


### [116] [NOMAD: A Multi-Agent LLM System for UML Class Diagram Generation from Natural Language Requirements](https://arxiv.org/abs/2511.22409)
*Polydoros Giannouris,Sophia Ananiadou*

Main category: cs.SE

TL;DR: 本文提出了NOMAD，一个多代理框架，实现了大语言模型生成UML图的模块化子任务分解，提升了可解释性和验证能力，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在软件工程中广泛使用，但生成结构化产物如UML图的能力尚未充分研究，尤其是如何提升模型的可解释性和生成质量。

Method: 设计一个认知启发、模块化的多代理框架NOMAD，将UML生成任务拆解为多个角色专长的子任务（如实体提取、关系分类、图表合成），并通过案例研究和人类作者练习进行评估。

Result: NOMAD在多个评测中表现优于基线方法，能够更好地生成UML图，但在细粒度属性提取方面仍存在挑战。基于此，首次提出了LLM生成UML图的错误系统分类。

Conclusion: NOMAD不仅是一个有效的UML类图生成框架，也为语言到模型的可靠工作流程研究提供了新的视角和验证策略的思路。

Abstract: Large Language Models (LLMs) are increasingly utilised in software engineering, yet their ability to generate structured artefacts such as UML diagrams remains underexplored. In this work we present NOMAD, a cognitively inspired, modular multi-agent framework that decomposes UML generation into a series of role-specialised subtasks. Each agent handles a distinct modelling activity, such as entity extraction, relationship classification, and diagram synthesis, mirroring the goal-directed reasoning processes of an engineer. This decomposition improves interpretability and allows for targeted verification strategies. We evaluate NOMAD through a mixed design: a large case study (Northwind) for in-depth probing and error analysis, and human-authored UML exercises for breadth and realism. NOMAD outperforms all selected baselines, while revealing persistent challenges in fine-grained attribute extraction. Building on these observations, we introduce the first systematic taxonomy of errors in LLM-generated UML diagrams, categorising structural, relationship, and semantic/logical. Finally, we examine verification as a design probe, showing its mixed effects and outlining adaptive strategies as promising directions. Together, these contributions position NOMAD as both an effective framework for UML class diagram generation and a lens onto the broader research challenges of reliable language-to-model workflows.

</details>


### [117] [Declarative Policy Control for Data Spaces: A DSL-Based Approach for Manufacturing-X](https://arxiv.org/abs/2511.22513)
*Jérôme Pfeiffer,Nicolai Maisch,Sebastian Friedl,Matthias Milan Strljic,Armin Lechler,Oliver Riedel,Andreas Wortmann*

Main category: cs.SE

TL;DR: 本文提出用领域特定语言实现易用且可执行的数据使用策略，帮助领域专家管理工业4.0中的数据共享。


<details>
  <summary>Details</summary>
Motivation: 联邦数据空间框架下，如何让非技术领域专家方便地描述和执行上下文相关的数据使用政策是一个亟待解决的重要问题。

Method: 基于现有的工业数据共享标准（如AAS、EDC、ID-Link、OPC UA），设计并实现了一种DSL，使政策定义既具声明性又具机器执行能力，并支持细粒度数据管控需求。

Result: 本文针对工业4.0中跨组织边界的数据共享安全性和主权问题，提出了一种利用领域特定语言（DSL）实现上下文依赖的数据使用政策的声明式、可读、可执行的定义方法。该方法使非软件工程背景的领域专家能够制定细粒度的数据治理要求，例如限制特定生产批次的数据访问或设定自动删除规则。

Conclusion: 通过引入DSL，领域专家无需编写命令式代码即可有效描述和执行复杂的数据使用政策，提升了联邦数据空间中数据共享的可管理性和合规性。

Abstract: The growing adoption of federated data spaces, such as in the GAIA-X and the International Data Spaces (IDS) initiative, promises secure and sovereign data sharing across organizational boundaries in Industry 4.0. In manufacturing ecosystems, this enables use cases, such as cross-factory process optimization, predictive maintenance, and supplier integration. Frameworks and standards, such as the Asset Administration Shell (AAS), Eclipse Dataspace Connector (EDC), ID-Link and Open Platform Communications Unified Architecture (OPC UA) provide a strong foundation to realize this ecosystem. However, a major open challenge is the practical description and enforcement of context-dependent data usage policies using these base technologies - especially by domain experts without software engineering backgrounds. Therefore, this article proposes a method for leveraging domain-specific languages (DSLs) to enable declarative, human-readable, and machine-executable policy definitions for sovereign data sharing via data space connectors. The DSL empowers domain experts to specify fine-grained data governance requirements - such as restricting access to data from specific production batches or enforcing automatic deletion after a defined retention period - without writing imperative code.

</details>


### [118] [The Repeat Offenders: Characterizing and Predicting Extremely Bug-Prone Source Methods](https://arxiv.org/abs/2511.22726)
*Ethan Friesen,Sasha Morton-Salmon,Md Nahidul Islam Opu,Shahidul Islam,Shaiful Chowdhury*

Main category: cs.SE

TL;DR: 研究极其多缺陷方法的特征与可预测性，发现其虽少但承担大量缺陷，现有预测方法效果有限，建议采用更进化感知的代码分析策略。


<details>
  <summary>Details</summary>
Motivation: 识别反复出现缺陷的源代码子集对于减少长期维护工作量至关重要。

Method: 定义“极其多缺陷方法”，使用来自98个开源Java项目的超过125万方法的数据集，分析其普遍性、特征和可预测性，并通过五种机器学习模型进行预测评估，同时结合265个极其多缺陷方法的主题分析。

Result: 极其多缺陷方法虽仅占极小比例，但承担了大量缺陷；这些方法在初始阶段更大、更复杂、可读性和可维护性较差；预测其出现缺陷的准确性较低，原因包括数据不平衡、项目异质性及缺陷多因后续演进产生。主题分析揭示了视觉问题、上下文角色和常见缺陷模式。

Conclusion: 需要更丰富的、关注代码演进的表示方法来提高早期识别高风险方法的能力，研究结果对开发者优先关注高风险代码提供了实用见解。

Abstract: Identifying the small subset of source code that repeatedly attracts bugs is critical for reducing long-term maintenance effort. We define ExtremelyBuggy methods as those involved in more than one bug fix and present the first large-scale study of their prevalence, characteristics, and predictability. Using a dataset of over 1.25 million methods from 98 open-source Java projects, we find that ExtremelyBuggy methods constitute only a tiny fraction of all methods, yet frequently account for a disproportionately large share of bugs. At their inception, these methods are significantly larger, more complex, less readable, and less maintainable than both singly-buggy and non-buggy methods. However, despite these measurable differences, a comprehensive evaluation of five machine learning models shows that early prediction of ExtremelyBuggy methods remains highly unreliable due to data imbalance, project heterogeneity, and the fact that many bugs emerge through subsequent evolution rather than initial implementation. To complement these quantitative findings, we conduct a thematic analysis of 265 ExtremelyBuggy methods, revealing recurring visual issues (e.g., confusing control flow, poor readability), contextual roles (e.g., core logic, data transformation, external resource handling), and common defect patterns (e.g., faulty conditionals, fragile error handling, misuse of variables). These results highlight the need for richer, evolution-aware representations of code and provide actionable insights for practitioners seeking to prioritize high-risk methods early in the development lifecycle.

</details>


### [119] [MBFL-DKMR: Improving Mutation-based Fault Localization through Denoising-based Kill Matrix Refinement](https://arxiv.org/abs/2511.22921)
*Hengyuan Liu,Xia Song,Yong Liu,Zheng Li*

Main category: cs.SE

TL;DR: 本文通过信号去噪技术优化了突变测试的杀死矩阵，提出MBFL-DKMR方法，显著提高了故障定位准确率，且计算开销极小。


<details>
  <summary>Details</summary>
Motivation: 软件调试耗时且关键，基于突变测试的故障定位因噪声（即虚假杀死关系）影响定位效果，现有方法未直接解决噪声问题。

Method: 借鉴信号处理，首先通过混合矩阵构建提升信噪比，随后进行频域滤波去噪，优化杀死矩阵；最终结合模糊值计算可疑度形成MBFL-DKMR框架。

Result: 在Defects4J v2.0.0上，MBFL-DKMR在Top-1定位129个缺陷，显著优于BLMu（85）和Delta4Ms（103），且额外计算时间仅0.11秒，开销极低。

Conclusion: 本文提出了一种基于信号处理理论的去噪杀死矩阵优化方法（DKMR），显著提升了突变测试中的错误定位效果，验证了该方法在实际缺陷库上的优越性。

Abstract: Software debugging is a critical and time-consuming aspect of software development, with fault localization being a fundamental step that significantly impacts debugging efficiency. Mutation-Based Fault Localization (MBFL) has gained prominence due to its robust theoretical foundations and fine-grained analysis capabilities. However, recent studies have identified a critical challenge: noise phenomena, specifically the false kill relationships between mutants and tests, which significantly degrade localization effectiveness. While several approaches have been proposed to rectify the final localization results, they do not directly address the underlying noise. In this paper, we propose a novel approach to refine the kill matrix, a core data structure capturing mutant-test relationships in MBFL, by treating it as a signal that contains both meaningful fault-related patterns and high-frequency noise. Inspired by signal processing theory, we introduce DKMR (Denoising-based Kill Matrix Refinement), which employs two key stages: (1) signal enhancement through hybrid matrix construction to improve the signal-to-noise ratio for better denoising, and (2) signal denoising via frequency domain filtering to suppress noise while preserving fault-related patterns. Building on this foundation, we develop MBFL-DKMR, a fault localization framework that utilizes the refined matrix with fuzzy values for suspiciousness calculation. Our evaluation on Defects4J v2.0.0 demonstrates that MBFL-DKMR effectively mitigates the noise and outperforms the state-of-the-art MBFL techniques. Specifically, MBFL-DKMR achieves 129 faults localized at Top-1 compared to 85 for BLMu and 103 for Delta4Ms, with negligible additional computational overhead (0.11 seconds, 0.001\% of total time). This work highlights the potential of signal processing techniques to enhance the effectiveness of MBFL by refining the kill matrix.

</details>


### [120] [A transfer learning approach for automatic conflicts detection in software requirement sentence pairs based on dual encoders](https://arxiv.org/abs/2511.23007)
*Yizheng Wang,Tao Jiang,Jinyan Bai,Zhengbin Zou,Tiancheng Xue,Nan Zhang,Jie Luan*

Main category: cs.SE

TL;DR: 提出了一个基于双编码器的迁移学习框架，用于提高软件需求冲突检测精度和跨域迁移性能。


<details>
  <summary>Details</summary>
Motivation: 当前需求文档中的需求数量庞大，自动检测冲突面临准确率低、语义抽取能力有限和跨域迁移效果差的挑战。

Method: 采用SBERT与SimCSE两个编码器生成需求句向量，六元素拼接，结合两层全连接神经网络分类器，并引入混合损失函数优化，结合序列及跨域迁移学习提升检测性能。

Result: 实验表明该框架在域内环境下宏F1和加权F1均提升了10.4%，跨域环境下宏F1提升11.4%。

Conclusion: 本文提出的基于SBERT和SimCSE的可迁移软件需求冲突检测框架TSRCDF-SS有效提升了需求冲突检测的准确率和迁移能力，显著优于现有方法。

Abstract: Software Requirement Document (RD) typically contain tens of thousands of individual requirements, and ensuring consistency among these requirements is critical for the success of software engineering projects. Automated detection methods can significantly enhance efficiency and reduce costs; however, existing approaches still face several challenges, including low detection accuracy on imbalanced data, limited semantic extraction due to the use of a single encoder, and suboptimal performance in cross-domain transfer learning. To address these issues, this paper proposes a Transferable Software Requirement Conflict Detection Framework based on SBERT and SimCSE, termed TSRCDF-SS. First, the framework employs two independent encoders, Sentence-BERT (SBERT) and Simple Contrastive Sentence Embedding (SimCSE), to generate sentence embeddings for requirement pairs, followed by a six-element concatenation strategy. Furthermore, the classifier is enhanced by a two-layer fully connected feedforward neural network (FFNN) with a hybrid loss optimization strategy that integrates a variant of Focal Loss, domain-specific constraints, and a confidence-based penalty term. Finally, the framework synergistically integrates sequential and cross-domain transfer learning. Experimental results demonstrate that the proposed framework achieves a 10.4% improvement in both macro-F1 and weighted-F1 scores in in-domain settings, and an 11.4% increase in macro-F1 in cross-domain scenarios.

</details>


### [121] [APDT: A Digital Twin for Assessing Access Point Characteristics in a Network](https://arxiv.org/abs/2511.23009)
*D. Sree Yashaswinee,Gargie Tambe,Y. Raghu Reddy,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 本文提出了一种针对计算机网络的数字孪生APDT，可通过实时数据捕获和模拟预测用户行为与流量，改善网络性能和服务质量。


<details>
  <summary>Details</summary>
Motivation: 随着客户端密度增加和流量拥堵严重，现有网络管理手段难以满足实时监控和预测需求，数字孪生技术在网络领域应用不足。

Method: 设计了访问点数字孪生(APDT)，结合Ruckus SmartZone API采集接入点数据，利用NS-3仿真模拟网络状态，同时建立预测模型预测流量拥堵并提出客户端转移策略。

Result: 在大学网络环境中测试显示，APDT能准确模拟网络实时状态，成功预测短期流量高峰，实现QoS提升和流量拥堵缓解。

Conclusion: 本文提出的访问点数字孪生（APDT）能够实时捕获网络状态，通过模拟和预测模型有效预测短期流量激增，从而提升网络服务质量，缓解流量拥堵。

Abstract: Digital twins (DT) have emerged as a transformative technology, enabling real-time monitoring, simulations, and predictive maintenance across various domains, though their Application in the networking domain remains underexplored. This paper focuses on issues such as increasing client density and traffic congestion by proposing a digital twin for computer networks. Our Digital Twin, named Access Point Digital Twin (APDT) is used for tracking user behavior and changing bandwidth demands, directly impacting network performance and Quality of Service (QoS) parameters like latency, jitter, etc. APDT captures the real-time state of networks with data from access points (APs), enabling simulation-based analyses and predictive modelling. APDT facilitates the simulation of various what-if scenarios thereby providing a better understanding of various aspects of the network characteristics. We tested APDT on our University network. APDT uses data collected from three access points via the Ruckus SmartZone API and incorporates NS-3 based simulations. The simulation replicates a real-time snapshot from a Ruckus access point and models metrics such as latency and inter-packet transfer time. Additionally, a forecasting model predicts traffic congestion and suggests proactive client offloading, enhancing network management and performance optimization. Preliminary results indicate that APDT can successfully predict short-term traffic surges, leading to improved QoS and reduced traffic congestion.

</details>


### [122] [Software for Studying CASCADE Error Correction Protocols in Quantum Communications](https://arxiv.org/abs/2511.23050)
*Nikita Repnkiov,Vladimir Faerman*

Main category: cs.SE

TL;DR: 本文设计了基于actor模型的CASCADE协议并行纠错原型，提升了密钥协商效率，但存在性能和代码问题，提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 应对量子计算威胁，提升量子通信系统中密钥协商的效率和安全性。

Method: 设计并实现基于actor模型的CASCADE协议并行纠错算法的软件原型，用于研究与教学。

Result: 原型提高了密钥协商效率，减少交换数据量；实验验证了CASCADE核心算法的正确实现，发现了消息传递开销大、错误处理复杂、代码冗余等局限。

Conclusion: 未来需重构系统架构，开发中间数据导出接口，将通信通道组件化，并扩展验证与对比工具以提升密钥协商方法的系统性研究。

Abstract: This article addresses the development of quantum communication methods in the context of emerging quantum computing threats and emphasizes the importance of key reconciliation in quantum communication systems. The study focuses on the CASCADE protocol and the design of a software prototype intended for research and educational purposes. A parallel error-correction algorithm based on the actor model was implemented, improving the efficiency of key reconciliation and reducing the amount of exchanged data. Evaluation of the prototype revealed limitations, including the computational cost of message passing, complexity of error handling, and code redundancy due to iterative development. Experimental results confirmed the correct implementation of the core CASCADE algorithms and informed the design of future improvements. Proposed enhancements include redesigning the system architecture, developing interfaces for exporting intermediate data, defining the communication channel as a separate component, and expanding tools for systematic verification and comparative analysis of blind key-reconciliation methods.

</details>


### [123] [Amplifiers or Equalizers? A Longitudinal Study of LLM Evolution in Software Engineering Project-Based Learning](https://arxiv.org/abs/2511.23157)
*Hana Kataoka,Jialong Li,Yutaka Matsuno*

Main category: cs.SE

TL;DR: 研究发现最新LLM既帮助弱势学生提升，也加剧了学生表现差距，给软件工程教育带来机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM变革软件开发，迫切需要探讨其在更开放的项目驱动软件工程教育中的真实影响，填补现有研究空白。

Method: 通过两年纵向研究，比较2024年使用早期免费LLM的48名学生和2025年使用最新付费LLM的46名学生在项目驱动学习(PBL)中的表现。

Result: 最新强大的LLM同时起到‘均衡器’的作用，提高了编程薄弱学生的平均表现，也起到了‘放大器’的作用，显著拉大了学生间的绝对表现差距。

Conclusion: LLM在软件工程教育中既能促进所有学生的表现提升，也带来了教育公平性的新挑战，需针对差距扩大的问题制定相应的教学策略。

Abstract: As LLMs reshape software development, integrating LLM-augmented practices into SE education has become imperative. While existing studies explore LLMs' educational use in introductory programming or isolated SE tasks, their impact in more open-ended Project-Based Learning (PBL) remains unexplored. This paper introduces a two-year longitudinal study comparing a 2024 (using early free LLMs, $n$=48) and 2025 (using the latest paid LLMs, $n$=46) cohort. Our findings suggest the latest powerful LLMs' dual role: they act as "equalizers," boosting average performance even for programming-weak students, providing opportunities for more authentic SE practices; yet also as "amplifiers," dramatically widening absolute performance gaps, creating new pedagogical challenges for addressing educational inequities.

</details>


### [124] [AI for software engineering: from probable to provable](https://arxiv.org/abs/2511.23159)
*Bertrand Meyer*

Main category: cs.SE

TL;DR: AI编程面临目标定义难和幻觉问题，结合形式化规格及验证手段能提高程序正确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前基于AI的编程方法存在目标难以明确和幻觉现象两个主要障碍，导致程序正确性无法保障。

Method: 将人工智能的创造力与形式化规格说明方法及现代证明工具支持的形式化程序验证相结合。

Result: 通过结合AI与形式化验证手段，能够生成更接近正确且可靠的程序。

Conclusion: 结合AI和形式化方法是解决AI编程中目标模糊和幻觉问题的有效途径。

Abstract: Vibe coding, the much-touted use of AI techniques for programming, faces two overwhelming obstacles: the difficulty of specifying goals ("prompt engineering" is a form of requirements engineering, one of the toughest disciplines of software engineering); and the hallucination phenomenon. Programs are only useful if they are correct or very close to correct.
  The solution? Combine the creativity of artificial intelligence with the rigor of formal specification methods and the power of formal program verification, supported by modern proof tools.

</details>


### [125] [GAPS: Guiding Dynamic Android Analysis with Static Path Synthesis](https://arxiv.org/abs/2511.23213)
*Samuele Doria,Eleonora Losiouk*

Main category: cs.SE

TL;DR: 本文提出的GAPS系统通过结合静态调用图分析和动态执行，有效实现了安卓应用中目标方法的高效触达，性能优于现有工具，在真实应用中验证其安全分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有工具难以动态驱动执行以触达非图形界面嵌入的方法，限制了漏洞验证、调试和行为分析的有效性，亟需一种能够结合静态和动态分析提升方法触达率的新技术。

Method: GAPS结合静态方法引导的调用图分析和动态交互驱动执行，通过轻量级回溯调用图并辅以数据流分析来重构到目标方法的路径，再将这些路径转换成指令引导应用运行时探索。

Result: GAPS在AndroTest基准测试中静态识别目标方法路径达到88.24%，动态触达率57.44%；相比之下，其他动态交互工具和静态分析工具表现均较差。真实世界50款热门应用中，GAPS静态重构路径覆盖62.03%，动态触达59.86%。

Conclusion: GAPS显著提升了安卓应用中目标方法的触达率，验证了结合静态和动态分析的路径合成技术在安全分析和行为分析中的实用价值。

Abstract: Dynamically resolving method reachability in Android applications remains a critical and largely unsolved problem. Despite notable advancements in GUI testing and static call graph construction, current tools are insufficient for reliably driving execution toward specific target methods, especially those not embedded in a graphical component (e.g., libraries' methods), a capability essential for tasks such as vulnerability validation, debugging, and behavioral analysis.
  We present GAPS (Graph-based Automated Path Synthesizer), the first system that integrates static, method-guided call graph analysis with dynamic, interaction-driven execution. GAPS performs a lightweight backward traversal of the call graph, guided by data-flow analysis, to reconstruct paths reaching the target methods. These paths are then translated into instructions that guide runtime app exploration.
  On the AndroTest benchmark, GAPS statically identifies paths to reach 88.24\% of the target methods in just 4.27 seconds per app and dynamically reaches 57.44\% of them. In contrast, state-of-the-art dynamic interaction tools show significantly lower reachability over three runs: APE, one of the best model-based GUI testers, achieves 12.82\%, while GoalExplorer, a hybrid analysis tool, reaches 9.69\%, and Guardian, an LLM-based UI automator, reaches 17.12\%. Static analysis tools also fall short: FlowDroid and DroidReach identify paths to reach 58.81\% and 9.48\% of the targets, requiring 35.06 seconds and 23.46 seconds per app, respectively.
  Finally, an evaluation on the 50 most downloaded real-world apps demonstrates GAPS's practical utility in analyzing security-critical code under a realistic scenario. With an average static analysis time of 278.9 seconds, GAPS statically reconstructs paths to 62.03\% of the target methods and dynamically reaches 59.86\% of them.

</details>


### [126] [FLIMs: Fault Localization Interference Mutants, Definition, Recognition and Mitigation](https://arxiv.org/abs/2511.23302)
*Hengyuan Liu,Zheng Li,Donghua Wang,Yankai Wu,Xiang Chen,Yong Liu*

Main category: cs.SE

TL;DR: 通过识别和减轻干扰变异体，利用LLM语义分析优化MBFL，显著提升软件故障定位效果，MBFL-FLIM方法在多项基准测试中表现卓越。


<details>
  <summary>Details</summary>
Motivation: Mutation-based Fault Localization (MBFL)面临因干扰变异体影响测试灵敏度，降低定位效果的挑战。

Method: 提出并定义干扰变异体（FLIMs），基于RIPR模型分析干扰原因，利用大语言模型(LLM)语义分析及微调和置信度估计技术识别并缓解干扰变异体，优化MBFL怀疑度评分，构建MBFL-FLIM框架。

Result: 在Defects4J基准测试上，MBFL-FLIM相比传统SBFL、MBFL及先进动态特征和LLM方法，Top-1指标平均提升44个缺陷，表现优异，多缺陷场景下稳定，消融实验验证微调和置信估计有效性。

Conclusion: MBFL-FLIM有效降低干扰变异体影响，增强MBFL定位准确性，具有较强鲁棒性和实际应用潜力。

Abstract: Mutation-based Fault Localization (MBFL) has been widely explored for automated software debugging, leveraging artificial mutants to identify faulty code entities. However, MBFL faces significant challenges due to interference mutants generated from non-faulty code entities but can be killed by failing tests. These mutants mimic the test sensitivity behaviors of real faulty code entities and weaken the effectiveness of fault localization. To address this challenge, we introduce the concept of Fault Localization Interference Mutants (FLIMs) and conduct a theoretical analysis based on the Reachability, Infection, Propagation, and Revealability (RIPR) model, identifying four distinct interference causes. Building on this, we propose a novel approach to semantically recognize and mitigate FLIMs using LLM-based semantic analysis, enhanced by fine-tuning techniques and confidence estimation strategies to address LLM output instability. The recognized FLIMs are then mitigated by refining the suspiciousness scores calculated from MBFL techniques. We integrate FLIM recognition and mitigation into the MBFL workflow, developing MBFL-FLIM, a fault localization framework that enhances MBFL's effectiveness by reducing misleading interference while preserving real fault-revealing information. Our empirical experiments on the Defects4J benchmark with 395 program versions using eight LLMs demonstrate MBFL-FLIM's superiority over traditional SBFL and MBFL methods, advanced dynamic feature-based approaches, and recent LLM-based fault localization techniques. Specifically, MBFL-FLIM achieves an average improvement of 44 faults in the Top-1 metric, representing a significant enhancement over baseline methods. Further evaluation confirms MBFL-FLIM's robust performance in multi-fault scenarios, with ablation experiments validating the contributions of the fine-tuning and confidence estimation components.

</details>


### [127] [Chart2Code-MoLA: Efficient Multi-Modal Code Generation via Adaptive Expert Routing](https://arxiv.org/abs/2511.23321)
*Yifei Wang,Jacky Keung,Zhenyu Mao,Jingyu Zhang,Yuchen Cao*

Main category: cs.SE

TL;DR: 本文提出的C2C-MoLA利用专家模型混合和低秩适配技术，显著提升图表到代码生成的性能与资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型在图表表示和生成中难以兼顾跨类型泛化、内存效率和模块化设计，需新方法提升生成质量和计算效率。

Method: 提出C2C-MoLA多模态框架，结合专家模型混合（MoE）与低秩适配（LoRA），使用复杂度感知路由机制及专门领域专家，实现动态输入分配和参数高效更新。

Result: 相比标准微调和仅LoRA微调，在Chart2Code-160k数据集上生成准确率提升17%，峰值GPU内存降低18%，收敛速度提升20%，对复杂图表效果显著。

Conclusion: C2C-MoLA通过结合MoE与LoRA，有效提升了图表到代码生成的准确性和效率，具有良好的跨类型泛化能力和可扩展性。

Abstract: Chart-to-code generation is a critical task in automated data visualization, translating complex chart structures into executable programs. While recent Multi-modal Large Language Models (MLLMs) improve chart representation, existing approaches still struggle to achieve cross-type generalization, memory efficiency, and modular design. To address these challenges, this paper proposes C2C-MoLA, a multimodal framework that synergizes Mixture of Experts (MoE) with Low-Rank Adaptation (LoRA). The MoE component uses a complexity-aware routing mechanism with domain-specialized experts and load-balanced sparse gating, dynamically allocating inputs based on learnable structural metrics like element count and chart complexity. LoRA enables parameter-efficient updates for resource-conscious tuning, further supported by a tailored training strategy that aligns routing stability with semantic accuracy. Experiments on Chart2Code-160k show that the proposed model improves generation accuracy by up to 17%, reduces peak GPU memory by 18%, and accelerates convergence by 20%, when compared to standard fine-tuning and LoRA-only baselines, particularly on complex charts. Ablation studies validate optimal designs, such as 8 experts and rank-8 LoRA, and confirm scalability for real-world multimodal code generation.

</details>
