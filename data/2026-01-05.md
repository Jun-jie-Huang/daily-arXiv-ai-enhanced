<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 35]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.SE](#cs.SE) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning](https://arxiv.org/abs/2601.00086)
*Xiang Gao,Yuguang Yao,Qi Zhang,Kaiwen Dong,Avinash Baidya,Ruocheng Guo,Hilaf Hasson,Kamalika Das*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态规则注入的神经符号方法RIMRULE，用于增强大语言模型在领域特定工具使用中的适应性，通过从失败中提取简明规则并注入推理过程，显著提高任务性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在面对领域特定、文档不足或个性化API时表现不佳，亟需一种有效的任务工具适应方法。

Method: RIMRULE方法通过从失败轨迹中提炼紧凑、可解释的规则，并用最小描述长度目标优化规则的通用性与简洁性，动态注入推理提示中，规则以自然语言和符号形式存储，方便推理时检索。

Result: 在工具使用基准测试中，RIMRULE提升了对已见和未见工具的准确率，优于纯提示调整方法，且可与微调结合使用，跨模型规则迁移效果良好。

Conclusion: RIMRULE有效提升LLM在特定工具使用中的表现，通过规则注入实现模型外适应，支持跨模型知识迁移，展示了神经符号方法在实际任务适应中的潜力。

Abstract: Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.

</details>


### [2] [Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning](https://arxiv.org/abs/2601.00095)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CL

TL;DR: MetaJuLS是一种用于结构化推理的元强化学习方法，提升推理速度、保持高准确率并实现跨任务语言适应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理结构化推理如JSON模式和多语言解析时需要满足复杂约束，现有方法训练时间长且缺乏通用策略。

Method: 将结构化推理视为自适应约束传播，使用图注意力网络结合元学习训练通用传播策略，实现跨语言和任务的快速适应。

Result: MetaJuLS在多个语言和任务上实现1.5到2倍加速，保持0.2%内的准确率差异，并能通过少量梯度更新快速适应新任务。

Conclusion: MetaJuLS通过高效且泛化的约束传播策略，提高结构化推理效率，减少推理碳足迹，促进绿色AI发展。

Abstract: Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\times$ speedups over GPU-optimized baselines while maintaining within 0.2\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.

</details>


### [3] [Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description](https://arxiv.org/abs/2601.00166)
*Yongmin Yoo,Kris W Pan*

Main category: cs.CL

TL;DR: 本文提出了专利描述的多维度评估框架Pat-DEVAL，利用法律约束推理机制提升自动专利撰写的结构连贯性和法定合规性评估。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法不能有效评价专利描述的长文本结构连贯性及法律合规性，难以满足专利撰写严格的法律标准。

Method: 引入基于大型语言模型的法官角色范式和法律约束推理链（CoLT），实现对专利描述的分步骤法律分析。

Result: Pat-DEVAL在专家验证的数据集上获得0.69的Pearson相关系数，显著优于现有评估指标；在法律专业合规性评估中表现尤为突出，相关系数达0.73。

Conclusion: Pat-DEVAL通过结合技术严谨性与法律合规性，确立了自动专利撰写的评估新标准，为实用化部署奠定了坚实基础。

Abstract: Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.

</details>


### [4] [Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation](https://arxiv.org/abs/2601.00181)
*Cheonkam Jeong,Adeline Nyamathi*

Main category: cs.CL

TL;DR: 该论文通过系统分析IEMOCAP数据集，探讨了情感识别在对话中的关键架构选择及其与语言生成的关联。


<details>
  <summary>Details</summary>
Motivation: 当前情感识别虽准确，但对关键架构选择理解有限，且缺乏对识别与生成的语言学联系分析。

Method: 通过10次随机种子消融实验，分析对话上下文、层级句子表示及情感词典对情感识别的影响；并分析话语标记与情感之间的相关性。

Result: 发现对话上下文贡献最大，层级句子表示提供的增益在有上下文时消失，外部情感词典无效；情感识别性能优于以往方法。语言学分析表明标记位置与情感显著相关，悲伤情绪话语左侧标记使用较少，需更多上下文辅助识别。

Conclusion: 情感识别主要依赖有限的对话上下文，预训练模型已捕获情感语义，悲伤情绪的识别高度依赖上下文暗示，连接识别与生成研究。

Abstract: While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.
  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\% (4-way) and 67.07\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.
  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, "sad" utterances exhibit reduced left-periphery marker usage (21.9\%) compared to other emotions (28--32\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.

</details>


### [5] [Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models](https://arxiv.org/abs/2601.00202)
*Wang Xing,Wei Song,Siyu Lin,Chen Wu,Zhesi Li,Man Wang*

Main category: cs.CL

TL;DR: 本文提出了一种专门针对时序知识图推理的蒸馏框架，通过大语言模型指导轻量化学生模型学习结构和时间推理能力，实现高效推理与低硬件成本的平衡。


<details>
  <summary>Details</summary>
Motivation: 当前时序知识图推理模型参数庞大、计算密集，难以应用于资源受限的设备，且现有压缩技术未能很好捕捉时序依赖性，导致推理性能下降。

Method: 设计基于大语言模型的教师模型指导蒸馏框架，结合大规模公开知识和任务特定时间信息，提高轻量化模型对时间动态的建模能力。

Result: 在多个公开基准数据集上，方法优于现有强基线，实现了推理准确性、计算效率和实际部署性的良好平衡。

Conclusion: 本研究提出的时序知识图蒸馏框架有效提升了轻量模型的时序推理能力，支持高效且实用的智能系统部署。

Abstract: Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.

</details>


### [6] [From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark](https://arxiv.org/abs/2601.00216)
*Jinning Zhang,Jie Song,Wenhui Tu,Zecheng Li,Jingxuan Li,Jin Li,Xuan Liu,Taole Sha,Zichen Wei,Yan Li*

Main category: cs.CL

TL;DR: 本文提出了一种将循证医学（EBM）原则整合到基于图的检索增强生成（RAG）中的通用策略，解决了当前RAG中缺乏PICO对齐和证据等级考虑的问题，并在运动康复领域进行了验证，释放了知识图谱和基准数据，显著提升了检索和回答质量。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的RAG方法主要关注性能提升，忽视了循证医学的核心原则，尤其是在检索结果与查询的PICO对齐以及证据等级影响排序中存在缺失。

Method: 构建融合PICO框架的知识图谱和检索体系，提出基于贝叶斯思想的再排序算法，用以根据证据等级校正排名分数，无需预定义权重。

Result: 系统在运动康复领域的测试中实现了高水平的摘要覆盖率、答案真实性、语义相似度和PICO匹配准确率，专家评分也显示系统在准确性、相关性、安全性及PICO对齐方面表现优异。

Conclusion: 该EBM适配策略显著提升了RAG的检索与回答质量，具备较好的领域迁移能力，同时所发布的知识图谱与基准数据填补了运动康复领域RAG资源的空白。

Abstract: In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.

</details>


### [7] [JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation](https://arxiv.org/abs/2601.00223)
*Leonard Lin,Adam Lensenmayer*

Main category: cs.CL

TL;DR: JP-TL-Bench是一个轻量级开放基准，专为指导日英翻译系统的迭代开发而设计，通过基于大语言模型的无参考对比评测提供稳定可靠的评分，注重翻译细节对自然性的影响。


<details>
  <summary>Details</summary>
Motivation: 日英翻译中的挑战主要是从两个优质译文中选择更佳者，而非判断译文是否可接受，细微的礼貌、含义、遗漏和语体选择极大影响译文自然度，因此需要一个能反映这些细节差异的评测基准。

Method: JP-TL-Bench采用基于大语言模型的无参考配对比较方法，对候选译文与固定版本锚点译文进行成对比较，并通过Bradley-Terry模型聚合得出胜率及标准化得分(LT分数)，保证评分的可复现性和结构稳定性。

Result: 该方法实现了在相同锚点集合、评判模型及聚合代码基础上对译文评分的结构稳定性和评判可靠性，适合于细致区分翻译质量的迭代开发。

Conclusion: JP-TL-Bench通过结合配对比较和统计模型，成功构建了一个稳定、可靠且经济的日英翻译评测基准，有助于推动翻译系统更精细的性能提升。

Abstract: We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often "which of these two good translations is better?" rather than "is this translation acceptable?" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 "LT" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.

</details>


### [8] [Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback](https://arxiv.org/abs/2601.00224)
*Yan Sun,Ming Cai,Stanley Kok*

Main category: cs.CL

TL;DR: 本文提出了两种验证技术Q*和Feedback+，提升企业级大语言模型助手在业务分析中的代码生成准确性与执行能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型助手在企业工作流程中应用增加，当前系统缺乏自动验证机制，用户需人工确认结果的准确性。

Method: 引入Q*进行代码与用户意图的逆向翻译及语义匹配，结合Feedback+利用执行反馈指导代码优化，嵌入生成-判别框架中实现自动验证。

Result: 在Spider、Bird及GSM8K三个基准数据集上，Q*和Feedback+显著降低了错误率和任务完成时间。

Conclusion: 该研究提供了一个面向设计的框架，有助于构建更可靠的企业级生成式AI系统，实现可信赖的决策支持。

Abstract: As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.

</details>


### [9] [Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation](https://arxiv.org/abs/2601.00263)
*Qianli Wang,Van Bach Nguyen,Yihong Liu,Fedor Splitt,Nils Feldhus,Christin Seifert,Hinrich Schütze,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文系统研究了大型语言模型在生成多语言反事实示例中的表现，比较了直接生成与翻译生成的效果，分析了编辑模式和错误类型，并探讨了反事实数据增强对模型性能的提升作用。


<details>
  <summary>Details</summary>
Motivation: 多语言反事实示例对解释模型行为具有重要价值，但大型语言模型在生成这些示例方面的效果尚未明确，需要深入研究其生成质量及实用价值。

Method: 作者对六种语言的直接生成和翻译生成反事实进行了自动评估，分析了不同语言间的编辑模式，归纳总结了生成错误类型，并对比了多语言反事实数据增强与跨语言数据增强的效果。

Result: 翻译生成的反事实有效性高于直接生成，但需要更多修改且质量不及英文原文；高资源欧洲语言的编辑模式类似；生成的反事实存在四种主要错误类型；多语言反事实数据增强对模型性能提升效果更显著，尤其是低资源语言。

Conclusion: 尽管多语言反事实数据增强能显著提升模型性能和鲁棒性，但生成反事实的质量限制了提升幅度，未来需进一步提升反事实生成质量以发挥更大作用。

Abstract: Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.

</details>


### [10] [Beyond Perfect APIs: A Comprehensive Evaluation of LLM Agents Under Real-World API Complexity](https://arxiv.org/abs/2601.00268)
*Doyoung Kim,Zhiwei Ren,Jie Hao,Zhongkai Sun,Lichao Wang,Xiyao Ma,Zack Ye,Xu Han,Jun Yin,Heng Ji,Wei Shen,Xing Fan,Benjamin Yao,Chenlei Guo*

Main category: cs.CL

TL;DR: WildAGTEval 是一个评估大语言模型（LLM）代理在复杂真实API环境下函数调用能力的基准测评工具。


<details>
  <summary>Details</summary>
Motivation: 现有工作多基于理想API系统，忽视了现实中API输出噪声和使用限制等复杂因素，导致评估不足。

Method: 设计了包含60个复杂场景、约3.2万个测试配置的API系统，并构建用户-代理交互，系统评测多款先进LLM模型。

Result: 发现在大多数复杂场景中LLM表现欠佳，尤其是无关信息复杂度使强模型性能下降27.3%，且LLM偶尔歪曲用户意图以完成任务。

Conclusion: WildAGTEval有效反映了真实世界API调用的挑战，指出当前LLM模型在处理复杂API任务时存在显著困难和潜在用户满意度问题。

Abstract: We introduce WildAGTEval, a benchmark designed to evaluate large language model (LLM) agents' function-calling capabilities under realistic API complexity. Unlike prior work that assumes an idealized API system and disregards real-world factors such as noisy API outputs, WildAGTEval accounts for two dimensions of real-world complexity: 1. API specification, which includes detailed documentation and usage constraints, and 2. API execution, which captures runtime challenges. Consequently, WildAGTEval offers (i) an API system encompassing 60 distinct complexity scenarios that can be composed into approximately 32K test configurations, and (ii) user-agent interactions for evaluating LLM agents on these scenarios. Using WildAGTEval, we systematically assess several advanced LLMs and observe that most scenarios are challenging, with irrelevant information complexity posing the greatest difficulty and reducing the performance of strong LLMs by 27.3%. Furthermore, our qualitative analysis reveals that LLMs occasionally distort user intent merely to claim task completion, critically affecting user satisfaction.

</details>


### [11] [Can Large Language Models Still Explain Themselves? Investigating the Impact of Quantization on Self-Explanations](https://arxiv.org/abs/2601.00282)
*Qianli Wang,Nils Feldhus,Pepa Atanasova,Fedor Splitt,Simon Ostermann,Sebastian Möller,Vera Schmitt*

Main category: cs.CL

TL;DR: 本文研究了量化对大型语言模型自我解释（SEs）质量和可信性的影响，发现量化会导致SE质量和可信性适度下降，但整体影响较小。


<details>
  <summary>Details</summary>
Motivation: 量化广泛用于加速推理和部署大型语言模型，但其对模型自我解释的影响尚未明确，而自我解释对高风险应用的透明度至关重要。

Method: 研究了两种自我解释类型（自然语言解释和反事实示例），使用三种常见量化技术在不同位宽上对大型语言模型进行量化，评估其SE质量和可信性，并通过用户研究验证效果。

Result: 量化导致SE质量最多下降4.4%，可信性最多下降2.38%，用户研究显示SE的连贯性和可信度下降最多8.5%。大型模型在SE质量上的抗量化能力有限，但在维护可信性方面表现较好。不同量化技术在准确率、SE质量和可信性上无明显优劣。

Conclusion: 量化虽对SE有适度影响，但不严重影响模型压缩效果，建议针对具体应用验证SE质量，尤其是对自然语言解释的敏感性需关注。

Abstract: Quantization is widely used to accelerate inference and streamline the deployment of large language models (LLMs), yet its effects on self-explanations (SEs) remain unexplored. SEs, generated by LLMs to justify their own outputs, require reasoning about the model's own decision-making process, a capability that may exhibit particular sensitivity to quantization. As SEs are increasingly relied upon for transparency in high-stakes applications, understanding whether and to what extent quantization degrades SE quality and faithfulness is critical. To address this gap, we examine two types of SEs: natural language explanations (NLEs) and counterfactual examples, generated by LLMs quantized using three common techniques at distinct bit widths. Our findings indicate that quantization typically leads to moderate declines in both SE quality (up to 4.4\%) and faithfulness (up to 2.38\%). The user study further demonstrates that quantization diminishes both the coherence and trustworthiness of SEs (up to 8.5\%). Compared to smaller models, larger models show limited resilience to quantization in terms of SE quality but better maintain faithfulness. Moreover, no quantization technique consistently excels across task accuracy, SE quality, and faithfulness. Given that quantization's impact varies by context, we recommend validating SE quality for specific use cases, especially for NLEs, which show greater sensitivity. Nonetheless, the relatively minor deterioration in SE quality and faithfulness does not undermine quantization's effectiveness as a model compression technique.

</details>


### [12] [DepFlow: Disentangled Speech Generation to Mitigate Semantic Bias in Depression Detection](https://arxiv.org/abs/2601.00303)
*Yuxin Li,Xiangyu Zhang,Yifei Li,Zhiwei Guo,Haoyang Zhang,Eng Siong Chng,Cuntai Guan*

Main category: cs.CL

TL;DR: 提出了DepFlow框架通过声音特征分离和生成技术，提高抑郁症检测模型在语言情感混杂情况下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有抑郁症检测数据集语言情感与诊断标签高度耦合，导致模型依赖语义捷径，难以识别语义掩盖型抑郁（Camouflaged Depression）。

Method: 设计了三阶段的DepFlow文本到语音框架，包括抑郁声学编码器进行特征解耦、带FiLM调制的流匹配TTS模型控制抑郁严重度、基于原型的严重度映射机制实现平滑调节。并构建了针对语义掩盖型抑郁的增强数据集CDoA。

Result: 在三种抑郁检测模型上，利用CDoA数据集分别提升宏F1分数9%、12%、5%，优于传统增强方法，有效提高鲁棒性。

Conclusion: DepFlow不仅增强了模型对复杂抑郁表现的检测能力，还提供了可控语音合成平台，有助于临床数据有限情况下的仿真评估和会话系统开发。

Abstract: Speech is a scalable and non-invasive biomarker for early mental health screening. However, widely used depression datasets like DAIC-WOZ exhibit strong coupling between linguistic sentiment and diagnostic labels, encouraging models to learn semantic shortcuts. As a result, model robustness may be compromised in real-world scenarios, such as Camouflaged Depression, where individuals maintain socially positive or neutral language despite underlying depressive states. To mitigate this semantic bias, we propose DepFlow, a three-stage depression-conditioned text-to-speech framework. First, a Depression Acoustic Encoder learns speaker- and content-invariant depression embeddings through adversarial training, achieving effective disentanglement while preserving depression discriminability (ROC-AUC: 0.693). Second, a flow-matching TTS model with FiLM modulation injects these embeddings into synthesis, enabling control over depressive severity while preserving content and speaker identity. Third, a prototype-based severity mapping mechanism provides smooth and interpretable manipulation across the depression continuum. Using DepFlow, we construct a Camouflage Depression-oriented Augmentation (CDoA) dataset that pairs depressed acoustic patterns with positive/neutral content from a sentiment-stratified text bank, creating acoustic-semantic mismatches underrepresented in natural data. Evaluated across three depression detection architectures, CDoA improves macro-F1 by 9%, 12%, and 5%, respectively, consistently outperforming conventional augmentation strategies in depression Detection. Beyond enhancing robustness, DepFlow provides a controllable synthesis platform for conversational systems and simulation-based evaluation, where real clinical data remains limited by ethical and coverage constraints.

</details>


### [13] [Robust Uncertainty Quantification for Factual Generation of Large Language Models](https://arxiv.org/abs/2601.00348)
*Yuhao Zhang,Zhongliang Yang,Linna Zhou*

Main category: cs.CL

TL;DR: 本文针对大型语言模型(LLM)的幻觉问题，提出了一种基于多事实生成任务的鲁棒不确定性量化方法(RU)，通过构造带有假名的陷阱问题进行验证，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM的幻觉问题严重影响生成内容的可靠性，且现有不确定性量化方法在非典型及对抗性问题中表现不足，缺乏对实际应用中关键思考能力的支持。

Method: 设计了包含假名的陷阱问题数据集，在此基础上提出了一种新的鲁棒不确定性量化方法(RU)用于检测和缓解LLM的幻觉现象。

Result: 实验结果显示构造的陷阱问题效果优异，且在四种不同模型上，RU方法在ROCAUC值上平均提升0.1-0.2，优于现有的最佳基线方法。

Conclusion: 该研究为解决LLM幻觉问题提供了新的思路和有效方法，提升了模型在复杂、非典型问题上的可靠性和可信度。

Abstract: The rapid advancement of large language model(LLM) technology has facilitated its integration into various domains of professional and daily life. However, the persistent challenge of LLM hallucination has emerged as a critical limitation, significantly compromising the reliability and trustworthiness of AI-generated content. This challenge has garnered significant attention within the scientific community, prompting extensive research efforts in hallucination detection and mitigation strategies. Current methodological frameworks reveal a critical limitation: traditional uncertainty quantification approaches demonstrate effectiveness primarily within conventional question-answering paradigms, yet exhibit notable deficiencies when confronted with non-canonical or adversarial questioning strategies. This performance gap raises substantial concerns regarding the dependability of LLM responses in real-world applications requiring robust critical thinking capabilities. This study aims to fill this gap by proposing an uncertainty quantification scenario in the task of generating with multiple facts. We have meticulously constructed a set of trap questions contained with fake names. Based on this scenario, we innovatively propose a novel and robust uncertainty quantification method(RU). A series of experiments have been conducted to verify its effectiveness. The results show that the constructed set of trap questions performs excellently. Moreover, when compared with the baseline methods on four different models, our proposed method has demonstrated great performance, with an average increase of 0.1-0.2 in ROCAUC values compared to the best performing baseline method, providing new sights and methods for addressing the hallucination issue of LLMs.

</details>


### [14] [The Role of Mixed-Language Documents for Multilingual Large Language Model Pretraining](https://arxiv.org/abs/2601.00364)
*Jiandong Shao,Raphael Tang,Crystina Zhang,Karin Sevegnani,Pontus Stenetorp,Jianfei Yang,Yao Lu*

Main category: cs.CL

TL;DR: 本文研究了多语言大语言模型中双语数据对跨语言能力的作用，发现双语数据虽仅占2%，但对翻译性能起关键作用，去除双语数据导致翻译性能显著下降，而对跨语言问答和推理影响较小。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言大模型主要通过单语预训练，双语数据被认为是其跨语言能力的关键，但其具体贡献尚不清楚，因此需要系统分析双语数据的作用。

Method: 作者从头开始预训练模型，比较含有双语数据的标准语料和去除所有多语言文档的纯单语语料，进一步将双语数据细分为平行语料、混合语言语料和其他，并分别加入以观察影响。

Result: 去除双语数据导致翻译性能用BLEU指标下降56%，而跨语言问答和推理任务表现基本无变化。加入纯平行语料几乎完全恢复翻译性能（达到原始的91%），混合语言语料则贡献甚微。

Conclusion: 翻译性能依赖于平行语料中的系统化词元对齐，而跨语言理解和推理能力可以在没有双语数据的情况下实现。

Abstract: Multilingual large language models achieve impressive cross-lingual performance despite largely monolingual pretraining. While bilingual data in pretraining corpora is widely believed to enable these abilities, details of its contributions remain unclear. We investigate this question by pretraining models from scratch under controlled conditions, comparing the standard web corpus with a monolingual-only version that removes all multilingual documents. Despite constituting only 2% of the corpus, removing bilingual data causes translation performance to drop 56% in BLEU, while behaviour on cross-lingual QA and general reasoning tasks remains stable, with training curves largely overlapping the baseline. To understand this asymmetry, we categorize bilingual data into parallel (14%), code-switching (72%), and miscellaneous documents (14%) based on the semantic relevance of content in different languages. We then conduct granular ablations by reintroducing parallel or code-switching data into the monolingual-only corpus. Our experiments reveal that parallel data almost fully restores translation performance (91% of the unfiltered baseline), whereas code-switching contributes minimally. Other cross-lingual tasks remain largely unaffected by either type. These findings reveal that translation critically depends on systematic token-level alignments from parallel data, whereas cross-lingual understanding and reasoning appear to be achievable even without bilingual data.

</details>


### [15] [BERT-JEPA: Reorganizing CLS Embeddings for Language-Invariant Semantics](https://arxiv.org/abs/2601.00366)
*Taj Gillin,Adam Lalani,Kenneth Zhang,Marcel Mateos Salles*

Main category: cs.CL

TL;DR: 提出了BERT-JEPA (BEPA)，结合JEPA训练目标，提升BERT模型的多语言性能。


<details>
  <summary>Details</summary>
Motivation: 传统BERT模型的[CLS]嵌入空间存在塌陷问题，限制了其多语言表现能力。

Method: 通过在BERT模型中加入JEPA训练目标，避免嵌入空间塌陷，构建一种语言无关的嵌入空间。

Result: 该方法显著提升了多语言基准测试中的性能。

Conclusion: 结合JEPA的BERT-JEPA训练范式有效增强了多语言模型的表现，克服了原始[CLS]嵌入的缺陷。

Abstract: Joint Embedding Predictive Architectures (JEPA) are a novel self supervised training technique that have shown recent promise across domains. We introduce BERT-JEPA (BEPA), a training paradigm that adds a JEPA training objective to BERT-style models, working to combat a collapsed [CLS] embedding space and turning it into a language-agnostic space. This new structure leads to increased performance across multilingual benchmarks.

</details>


### [16] [Vision-Language Reasoning for Geolocalization: A Reinforcement Learning Approach](https://arxiv.org/abs/2601.00388)
*Biao Wu,Meng Fang,Ling Chen,Ke Xu,Tao Cheng,Jun Wang*

Main category: cs.CL

TL;DR: 本文提出了Geo-R，一种无需检索的图像地理定位框架，通过规则驱动的层级推理（Chain of Region）和基于Haversine距离的强化学习优化定位精度，提高了模型的准确性、泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言地理定位方法依赖于合成的推理标注或外部图像检索，限制了模型的可解释性和泛化能力。

Method: 提出Chain of Region，通过将GPS坐标映射到地理实体形成层级推理路径，生成精确且可解释的监督信号。同时采用基于Haversine距离的坐标对齐奖励的轻量级强化学习策略，利用空间反馈优化预测。

Result: 实验在多个基准数据集上验证了Geo-R的有效性，表现出更高的定位准确率、更强的泛化性和更透明的推理过程。

Conclusion: Geo-R架构成功结合了结构化地理推理和直接空间监督，开创了无需检索且可扩展的图像地理定位新范式，并将公开代码和模型以促进进一步研究。

Abstract: Recent advances in vision-language models have opened up new possibilities for reasoning-driven image geolocalization. However, existing approaches often rely on synthetic reasoning annotations or external image retrieval, which can limit interpretability and generalizability. In this paper, we present Geo-R, a retrieval-free framework that uncovers structured reasoning paths from existing ground-truth coordinates and optimizes geolocation accuracy via reinforcement learning. We propose the Chain of Region, a rule-based hierarchical reasoning paradigm that generates precise, interpretable supervision by mapping GPS coordinates to geographic entities (e.g., country, province, city) without relying on model-generated or synthetic labels. Building on this, we introduce a lightweight reinforcement learning strategy with coordinate-aligned rewards based on Haversine distance, enabling the model to refine predictions through spatially meaningful feedback. Our approach bridges structured geographic reasoning with direct spatial supervision, yielding improved localization accuracy, stronger generalization, and more transparent inference. Experimental results across multiple benchmarks confirm the effectiveness of Geo-R, establishing a new retrieval-free paradigm for scalable and interpretable image geolocalization. To facilitate further research and ensure reproducibility, both the model and code will be made publicly available.

</details>


### [17] [Do LLMs Judge Distantly Supervised Named Entity Labels Well? Constructing the JudgeWEL Dataset](https://arxiv.org/abs/2601.00411)
*Alistair Plum,Laura Bernardy,Tharindu Ranasinghe*

Main category: cs.CL

TL;DR: 本文提出了judgeWEL，一个基于Wikipedia和Wikidata，通过大型语言模型自动标注并验证的卢森堡语命名实体识别数据集，显著提升了数据规模和质量。


<details>
  <summary>Details</summary>
Motivation: 卢森堡语等资源匮乏语言在自然语言处理中的数据构建困难，传统标注成本高且质量不稳定。

Method: 利用Wikipedia内部链接及其对应的Wikidata实体信息自动生成初始标注，结合多种大型语言模型进行噪声过滤和高质量标注句子的筛选。

Result: 生成的judgeWEL数据集规模是现有卢森堡语NER数据的5倍，覆盖的实体类别更广且更均衡。

Conclusion: 该方法有效缓解了低资源语言数据瓶颈，为多语言及低资源NER研究提供了重要的新资源。

Abstract: We present judgeWEL, a dataset for named entity recognition (NER) in Luxembourgish, automatically labelled and subsequently verified using large language models (LLM) in a novel pipeline. Building datasets for under-represented languages remains one of the major bottlenecks in natural language processing, where the scarcity of resources and linguistic particularities make large-scale annotation costly and potentially inconsistent. To address these challenges, we propose and evaluate a novel approach that leverages Wikipedia and Wikidata as structured sources of weak supervision. By exploiting internal links within Wikipedia articles, we infer entity types based on their corresponding Wikidata entries, thereby generating initial annotations with minimal human intervention. Because such links are not uniformly reliable, we mitigate noise by employing and comparing several LLMs to identify and retain only high-quality labelled sentences. The resulting corpus is approximately five times larger than the currently available Luxembourgish NER dataset and offers broader and more balanced coverage across entity categories, providing a substantial new resource for multilingual and low-resource NER research.

</details>


### [18] [Toward Better Temporal Structures for Geopolitical Events Forecasting](https://arxiv.org/abs/2601.00430)
*Kian Ahrabian,Eric Boxer,Jay Pujara*

Main category: cs.CL

TL;DR: 本文提出了超关系时序知识图广义超图（HTKGHs）作为超关系时序知识图（HTKGs）的扩展，支持更复杂的多实体事实表示，并构建htkgh-polecat数据集，评估大语言模型在关系预测任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的超关系时序知识图（HTKGs）无法有效表示含有多个主要实体的复杂时序事实，限制了其在地缘政治事件等真实场景中的应用。

Method: 本文首先形式化定义了HTKGHs，保证其向后兼容HTKGs并能表达两类复杂事实；其次基于全球事件数据库POLECAT构建htkgh-polecat数据集；最后在此数据集上评测多个大语言模型在关系预测任务的表现。

Result: 通过在htkgh-polecat数据集上的实验，本文揭示了流行大语言模型在复杂时序关系预测任务中的适应性和能力差异，提供了重要的性能分析。

Conclusion: HTKGHs作为HTKGs的推广，能够更好地表达多实体复杂时间事实，为地缘政治事件的预测提供了新的数据集和基准测试，有助于推动大语言模型在复杂时序知识图预测领域的发展。

Abstract: Forecasting on geopolitical temporal knowledge graphs (TKGs) through the lens of large language models (LLMs) has recently gained traction. While TKGs and their generalization, hyper-relational temporal knowledge graphs (HTKGs), offer a straightforward structure to represent simple temporal relationships, they lack the expressive power to convey complex facts efficiently. One of the critical limitations of HTKGs is a lack of support for more than two primary entities in temporal facts, which commonly occur in real-world events. To address this limitation, in this work, we study a generalization of HTKGs, Hyper-Relational Temporal Knowledge Generalized Hypergraphs (HTKGHs). We first derive a formalization for HTKGHs, demonstrating their backward compatibility while supporting two complex types of facts commonly found in geopolitical incidents. Then, utilizing this formalization, we introduce the htkgh-polecat dataset, built upon the global event database POLECAT. Finally, we benchmark and analyze popular LLMs on the relation prediction task, providing insights into their adaptability and capabilities in complex forecasting scenarios.

</details>


### [19] [Comparative Efficiency Analysis of Lightweight Transformer Models: A Multi-Domain Empirical Benchmark for Enterprise NLP Deployment](https://arxiv.org/abs/2601.00444)
*Muhammad Shahmeer Khan*

Main category: cs.CL

TL;DR: 本文对三种轻量级Transformer模型在多领域文本自动化任务中的表现进行了比较分析，发现各模型在准确率和效率上存在权衡。


<details>
  <summary>Details</summary>
Motivation: 随着企业自然语言处理需求的增加，迫切需要高效、轻量且能处理多领域文本任务的模型。

Method: 选取DistilBERT、MiniLM和ALBERT三款模型，在客户情感分类、新闻主题分类和仇恨言论检测三个领域的标准数据集上进行性能和效率测试。

Result: ALBERT在多个领域的任务准确率最高，MiniLM在推理速度和吞吐量方面表现最佳，DistilBERT在准确率和效率上表现平衡。

Conclusion: 不同模型在准确度和效率间存在权衡，MiniLM适合对延迟敏感的企业应用，DistilBERT适合均衡需求，ALBERT则适合资源受限环境。

Abstract: In the rapidly evolving landscape of enterprise natural language processing (NLP), the demand for efficient, lightweight models capable of handling multi-domain text automation tasks has intensified. This study conducts a comparative analysis of three prominent lightweight Transformer models - DistilBERT, MiniLM, and ALBERT - across three distinct domains: customer sentiment classification, news topic classification, and toxicity and hate speech detection. Utilizing datasets from IMDB, AG News, and the Measuring Hate Speech corpus, we evaluated performance using accuracy-based metrics including accuracy, precision, recall, and F1-score, as well as efficiency metrics such as model size, inference time, throughput, and memory usage. Key findings reveal that no single model dominates all performance dimensions. ALBERT achieves the highest task-specific accuracy in multiple domains, MiniLM excels in inference speed and throughput, and DistilBERT demonstrates the most consistent accuracy across tasks while maintaining competitive efficiency. All results reflect controlled fine-tuning under fixed enterprise-oriented constraints rather than exhaustive hyperparameter optimization. These results highlight trade-offs between accuracy and efficiency, recommending MiniLM for latency-sensitive enterprise applications, DistilBERT for balanced performance, and ALBERT for resource-constrained environments.

</details>


### [20] [Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games](https://arxiv.org/abs/2601.00448)
*Dimitris Vartziotis*

Main category: cs.CL

TL;DR: 本文通过对比社交建构主义语言游戏理论和数学化的语义场理论，探讨大语言模型（LLMs）在语言意义研究中的作用。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs新的实证环境，检验传统语言意义理论，特别是数学结构与社会基础在语言理解中的作用。

Method: 形式化词汇场与语言场为连续语义空间中的交互结构，结合Transformer架构核心特性分析两者关系。

Result: LLMs成功捕捉语义规律证明语言的数学结构作用，且其在语境理解和语用推理上的不足体现语言的社会基础重要性。

Conclusion: 数学结构和语言游戏是互补视角，明确纯统计模型的优势与局限，推动理论引导的人工智能架构发展。

Abstract: Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.

</details>


### [21] [Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations](https://arxiv.org/abs/2601.00454)
*Hyunjun Kim*

Main category: cs.CL

TL;DR: 该论文提出了Defensive M2S训练范式，通过将多轮对话压缩为单轮对话进行微调，显著降低训练和推理成本，同时提升模型安全检测性能。


<details>
  <summary>Details</summary>
Motivation: 多轮对话的完整历史处理计算成本高，限制了大型语言模型安全防护模型的效率和部署。

Method: 利用Multi-turn到Single-turn的压缩对话（M2S），将训练复杂度从$O(n^2)$降低到$O(n)$，在多个模型和压缩模板上进行实证测试。

Result: M2S使训练token数量减少93倍，推理token减少94.6%，同时攻击检测召回率提升38.9个百分点，在SafeDialBench基准测试中表现优秀。

Conclusion: M2S压缩训练是提升守护模型效率和效果的有效技术，支持长多轮对话的高效安全筛查。

Abstract: Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.

</details>


### [22] [Noise-Aware Named Entity Recognition for Historical VET Documents](https://arxiv.org/abs/2601.00488)
*Alexander M. Esser,Jens Dörpinghaus*

Main category: cs.CL

TL;DR: 本论文提出了一种针对职业教育和培训领域历史数字化文档中存在的OCR噪声的命名实体识别方法，通过噪声感知训练、迁移学习及多阶段微调，提升了噪声环境下的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 历史数字化职业教育与培训文档中存在OCR引入的噪声，影响命名实体识别的准确性，亟需一种鲁棒的NER方法。

Method: 采用噪声感知训练，合成注入OCR错误，结合迁移学习和多阶段微调，以及在噪声、干净和人工合成数据上的三种训练策略对比。

Result: 该方法能识别VET文档中的多种实体类型，在德语文档上表现优秀且具备跨语言迁移能力，在噪声条件下显著提升鲁棒性和准确率。

Conclusion: 领域特定的噪声感知微调显著增强了命名实体识别的稳健性，提供了公开的代码以促进领域专用语境下的噪声感知NER研究与应用。

Abstract: This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.

</details>


### [23] [Rule-Based Approaches to Atomic Sentence Extraction](https://arxiv.org/abs/2601.00506)
*Lineesha Kamana,Akshita Ananda Subramanian,Mehuli Ghosh,Suman Saha*

Main category: cs.CL

TL;DR: 本文研究复杂句子的原子句提取，分析不同句法结构对基于规则方法性能的影响，发现规则方法准确但对句法复杂度敏感。


<details>
  <summary>Details</summary>
Motivation: 复杂句包含多重信息，拆分成简单句有助于信息检索和问答任务，但现有基于大模型的方法缺乏解释性，对哪些句法结构导致提取失败认识有限。

Method: 利用WikiSplit数据集，基于spaCy框架设计依存句法规则，针对相对从句、状语从句、并列结构和被动语态等复杂结构进行原子句提取，并通过ROUGE和BERTScore评估性能。

Result: 系统得到ROUGE-1 F1=0.6714、ROUGE-2 F1=0.478、ROUGE-L F1=0.650、BERTScore F1=0.5898，表现中等偏上，明确指出相对从句、同位语、并列谓词、状语从句和被动结构是主要挑战。

Conclusion: 基于规则的原子句提取方法准确度合理，但对句法复杂结构较为敏感，未来研究需针对这些复杂结构优化提取策略。

Abstract: Natural language often combines multiple ideas into complex sentences. Atomic sentence extraction, the task of decomposing complex sentences into simpler sentences that each express a single idea, improves performance in information retrieval, question answering, and automated reasoning systems. Previous work has formalized the "split-and-rephrase" task and established evaluation metrics, and machine learning approaches using large language models have improved extraction accuracy. However, these methods lack interpretability and provide limited insight into which linguistic structures cause extraction failures. Although some studies have explored dependency-based extraction of subject-verb-object triples and clauses, no principled analysis has examined which specific clause structures and dependencies lead to extraction difficulties. This study addresses this gap by analyzing how complex sentence structures, including relative clauses, adverbial clauses, coordination patterns, and passive constructions, affect the performance of rule-based atomic sentence extraction. Using the WikiSplit dataset, we implemented dependency-based extraction rules in spaCy, generated 100 gold=standard atomic sentence sets, and evaluated performance using ROUGE and BERTScore. The system achieved ROUGE-1 F1 = 0.6714, ROUGE-2 F1 = 0.478, ROUGE-L F1 = 0.650, and BERTScore F1 = 0.5898, indicating moderate-to-high lexical, structural, and semantic alignment. Challenging structures included relative clauses, appositions, coordinated predicates, adverbial clauses, and passive constructions. Overall, rule-based extraction is reasonably accurate but sensitive to syntactic complexity.

</details>


### [24] [Retrieval--Reasoning Processes for Multi-hop Question Answering: A Four-Axis Design Framework and Empirical Trends](https://arxiv.org/abs/2601.00536)
*Yuelyu Ji,Zhuochun Li,Rui Meng,Daqing He*

Main category: cs.CL

TL;DR: 本文提出了一个四轴框架，用于系统分析多跳问答系统的检索与推理执行过程，比较不同模型的过程选择，归纳效果与效率间的权衡，并讨论未来挑战。


<details>
  <summary>Details</summary>
Motivation: 多跳问答系统中检索与推理的执行过程常被忽略，导致不同模型的过程设计难以比较，需建立统一分析框架。

Method: 基于整体执行计划、索引结构、下一步控制和停止规则四个维度构建框架，对代表性多跳问答系统进行映射和消融分析，归纳其性能表现和设计权衡。

Result: 通过标准数据集上的对比与消融，揭示了系统在效果、效率和证据可信度上的经典折中，并总结了不同设计策略的影响。

Conclusion: 提出当前检索-推理代理面临的挑战，包括结构感知规划、可迁移控制策略和稳健停止标准，指明未来研究方向。

Abstract: Multi-hop question answering (QA) requires systems to iteratively retrieve evidence and reason across multiple hops. While recent RAG and agentic methods report strong results, the underlying retrieval--reasoning \emph{process} is often left implicit, making procedural choices hard to compare across model families. This survey takes the execution procedure as the unit of analysis and introduces a four-axis framework covering (A) overall execution plan, (B) index structure, (C) next-step control (strategies and triggers), and (D) stop/continue criteria. Using this schema, we map representative multi-hop QA systems and synthesize reported ablations and tendencies on standard benchmarks (e.g., HotpotQA, 2WikiMultiHopQA, MuSiQue), highlighting recurring trade-offs among effectiveness, efficiency, and evidence faithfulness. We conclude with open challenges for retrieval--reasoning agents, including structure-aware planning, transferable control policies, and robust stopping under distribution shift.

</details>


### [25] [ECR: Manifold-Guided Semantic Cues for Compact Language Models](https://arxiv.org/abs/2601.00543)
*Chung-Wei Victor Yuan*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Embedding Consistency Regulation（ECR）的框架，用于保持紧凑模型的嵌入空间结构，解决模型压缩中语义漂移和结构塌陷问题。


<details>
  <summary>Details</summary>
Motivation: 紧凑模型常因容量限制或多语言数据而破坏嵌入空间结构，导致下游任务表现差，现有压缩方法未能有效保持语义流形结构。

Method: ECR框架通过从教师模型嵌入中提取语义锚点，指导紧凑模型保持锚点周围的几何一致性，无需匹配logits或内部特征，推理时仅增加小型投影步骤，不改变解码架构。

Result: 在10万条多语言语料上，ECR稳定训练，维护了多任务多语言的语义结构，生成更紧凑且任务对齐的表示空间，使低容量模型学得更干净流形，效果优于传统基线，且与知识蒸馏兼容但不依赖。

Conclusion: ECR提升了紧凑模型跟随任务需求的能力，便于在效率或隐私受限的环境下部署紧凑模型，解决了模型结构丢失及语义漂移难题。

Abstract: Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.
  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.
  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.

</details>


### [26] [A Language-Agnostic Hierarchical LoRA-MoE Architecture for CTC-based Multilingual ASR](https://arxiv.org/abs/2601.00557)
*Yuang Zheng,Yuxiang Mei,Dongxing Xu,Jie Chen,Yanhua Long*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级且语言无关的多语ASR系统，利用层次化LoRA-MoE框架和端到端语言无关解码，显著提升了低资源多语ASR的解码效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模多语ASR模型性能强但计算和延迟开销大，难以在资源受限的边缘设备上应用，亟需一种轻量且高效的多语ASR系统。

Method: 基于CTC架构结合域适应，设计语言无关的层次化LoRA-MoE框架，集成于mHuBERT-CTC模型中，通过LID后验驱动的LoRA路由实现真正的语言无关端到端解码，无需先验语言信息。

Result: 在MSR-86K和MLC-SLM 2025挑战赛数据集上，提出的HLoRA方法在保持与最先进两阶段推理方法竞争力性能的同时，实现了单遍解码，显著提高了低资源多语ASR的解码效率。

Conclusion: 该研究成功构建了高效的语言无关多语ASR系统，为资源有限的边缘设备部署多语ASR提供了实用且高性能的解决方案。

Abstract: Large-scale multilingual ASR (mASR) models such as Whisper achieve strong performance but incur high computational and latency costs, limiting their deployment on resource-constrained edge devices. In this study, we propose a lightweight and language-agnostic multilingual ASR system based on a CTC architecture with domain adaptation. Specifically, we introduce a Language-agnostic Hierarchical LoRA-MoE (HLoRA) framework integrated into an mHuBERT-CTC model, enabling end-to-end decoding via LID-posterior-driven LoRA routing. The hierarchical design consists of a multilingual shared LoRA for learning language-invariant acoustic representations and language-specific LoRA experts for modeling language-dependent characteristics. The proposed routing mechanism removes the need for prior language identity information or explicit language labels during inference, achieving true language-agnostic decoding. Experiments on MSR-86K and the MLC-SLM 2025 Challenge datasets demonstrate that HLoRA achieves competitive performance with state-of-the-art two-stage inference methods using only single-pass decoding, significantly improving decoding efficiency for low-resource mASR applications.

</details>


### [27] [InfoSynth: Information-Guided Benchmark Synthesis for LLMs](https://arxiv.org/abs/2601.00575)
*Ishir Garg,Neel Kolhe,Xuandong Zhao,Dawn Song*

Main category: cs.CL

TL;DR: 本文提出了InfoSynth框架，利用信息理论指标自动生成和评估大语言模型推理基准，实现高效多样的基准构建。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型基准构建依赖人工，成本高且效率低，且现有基准易污染训练数据，需新颖多样的基准精准评估模型能力。

Method: 根据KL散度和信息熵设计新颖度和多样性指标，无需昂贵模型评估；使用遗传算法及迭代代码反馈，从种子数据自动合成高质量Python编程题目及测试解答。

Result: 生成的问题97%具备准确测试及解答，且基准新颖性和多样性显著优于种子数据，可调控题目新颖度、难度等属性。

Conclusion: InfoSynth提供了可扩展、自验证的自动化管道，能有效构建高质量、新颖且多样化的LLM推理基准，推动模型评测升级。

Abstract: Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/

</details>


### [28] [CSSBench: Evaluating the Safety of Lightweight LLMs against Chinese-Specific Adversarial Patterns](https://arxiv.org/abs/2601.00588)
*Zhenhong Zhou,Shilinlu Yan,Chuanpu Liu,Qiankun Li,Kun Wang,Zhigang Zeng*

Main category: cs.CL

TL;DR: 本文提出了一种针对中文轻量级大语言模型的安全评估基准CSSBench，重点关注中文特有的对抗模式，如同音字、拼音和符号拆分等，揭示了轻量级模型在这些攻击下的安全隐患。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型安全防护主要针对英文，忽视了中文特有的恶意查询模式，导致安全评估存在缺口，特别是轻量级模型更易受攻击。

Method: 构建覆盖六大真实中文场景的安全评测基准CSSBench，涵盖违法合规、隐私泄露、医疗误导、欺诈仇恨、成人内容及公共政治安全领域，组织多任务类型查询，对轻量级模型进行安全性能评测。

Result: 评估结果表明，中文特有的对抗模式对轻量级模型构成严重挑战，模型在安全相关性能上表现出过度拒绝行为，显示性能下降。

Conclusion: CSSBench为中文大语言模型安全提供了全面评估工具，有助于推动轻量级模型在实际应用中的安全和稳健部署。

Abstract: Large language models (LLMs) are increasingly deployed in cost-sensitive and on-device scenarios, and safety guardrails have advanced mainly in English. However, real-world Chinese malicious queries typically conceal intent via homophones, pinyin, symbol-based splitting, and other Chinese-specific patterns. These Chinese-specific adversarial patterns create the safety evaluation gap that is not well captured by existing benchmarks focused on English. This gap is particularly concerning for lightweight models, which may be more vulnerable to such specific adversarial perturbations. To bridge this gap, we introduce the Chinese-Specific Safety Benchmark (CSSBench) that emphasizes these adversarial patterns and evaluates the safety of lightweight LLMs in Chinese. Our benchmark covers six domains that are common in real Chinese scenarios, including illegal activities and compliance, privacy leakage, health and medical misinformation, fraud and hate, adult content, and public and political safety, and organizes queries into multiple task types. We evaluate a set of popular lightweight LLMs and measure over-refusal behavior to assess safety-induced performance degradation. Our results show that the Chinese-specific adversarial pattern is a critical challenge for lightweight LLMs. This benchmark offers a comprehensive evaluation of LLM safety in Chinese, assisting robust deployments in practice.

</details>


### [29] [Beyond IVR: Benchmarking Customer Support LLM Agents for Business-Adherence](https://arxiv.org/abs/2601.00596)
*Sumanth Balaji,Piyush Mishra,Aashraya Sachdeva,Suraj Agrawal*

Main category: cs.CL

TL;DR: 本文提出了JourneyBench基准，评估大语言模型（LLM）在客户支持中遵守多步骤政策的能力，特别设计了用户旅程覆盖评分来衡量政策遵守度，结果显示动态提示代理显著提升政策执行效果。


<details>
  <summary>Details</summary>
Motivation: 传统客户支持系统如IVR缺乏灵活性，无法有效处理复杂的政策驱动任务；现有评估方法忽视了代理遵守多步骤策略和应对环境变化的能力，迫切需要新基准与指标。

Method: 提出JourneyBench基于图结构生成多样真实的支持场景，设计用户旅程覆盖评分衡量政策遵守度；比较静态提示代理（SPA）与动态提示代理（DPA）两种设计，后者显式建模政策控制。

Result: 在三个领域703个对话中，DPA显著提升了政策遵守，甚至使得小型模型GPT-4o-mini表现优于能力更强的GPT-4o，表明结构化策略调度的重要性。

Conclusion: JourneyBench为评估和推动AI客户支持系统超越传统IVR局限提供了关键工具，强调通过动态提示及策略建模提升大语言模型在实际业务环境中的表现。

Abstract: Traditional customer support systems, such as Interactive Voice Response (IVR), rely on rigid scripts and lack the flexibility required for handling complex, policy-driven tasks. While large language model (LLM) agents offer a promising alternative, evaluating their ability to act in accordance with business rules and real-world support workflows remains an open challenge. Existing benchmarks primarily focus on tool usage or task completion, overlooking an agent's capacity to adhere to multi-step policies, navigate task dependencies, and remain robust to unpredictable user or environment behavior. In this work, we introduce JourneyBench, a benchmark designed to assess policy-aware agents in customer support. JourneyBench leverages graph representations to generate diverse, realistic support scenarios and proposes the User Journey Coverage Score, a novel metric to measure policy adherence. We evaluate multiple state-of-the-art LLMs using two agent designs: a Static-Prompt Agent (SPA) and a Dynamic-Prompt Agent (DPA) that explicitly models policy control. Across 703 conversations in three domains, we show that DPA significantly boosts policy adherence, even allowing smaller models like GPT-4o-mini to outperform more capable ones like GPT-4o. Our findings demonstrate the importance of structured orchestration and establish JourneyBench as a critical resource to advance AI-driven customer support beyond IVR-era limitations.

</details>


### [30] [Probabilistic Guarantees for Reducing Contextual Hallucinations in LLMs](https://arxiv.org/abs/2601.00641)
*Nils Rautenberg,Sven Schippkus*

Main category: cs.CL

TL;DR: 本文提出了一种简洁且模型无关的框架，通过多次独立调用大语言模型并结合判断机制，显著降低固定输入任务中的幻觉概率。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在确定性自动化流程中经常产生与输入信息相矛盾的幻觉，影响结果的正确性。

Method: 针对固定输入和确定性正确性标准，将同一提示多次独立调用，结合LLM作为判断者进行多数投票，以指数级降低幻觉发生概率。

Result: 实验验证了理论预测：随着重复次数和判断者数量增加，系统失败率和幻觉选择概率均指数下降。

Conclusion: 该方法无需修改模型权重、解码策略或提示工程，即可模块化地大幅降低固定输入LLM工作流中的幻觉概率，为实际应用提供了理论支持和实用方案。

Abstract: Large language models (LLMs) frequently produce contextual hallucinations, where generated content contradicts or ignores information explicitly stated in the prompt. Such errors are particularly problematic in deterministic automation workflows, where inputs are fixed and correctness is unambiguous. We introduce a simple and model-agnostic framework that provides explicit probabilistic guarantees for reducing hallucinations in this setting.
  We formalize the notion of a specific task, defined by a fixed input and a deterministic correctness criterion, and show that issuing the same prompt in independent context windows yields an exponential reduction in the probability that all model outputs are incorrect. To identify a correct answer among repeated runs, we incorporate an LLM-as-a-judge and prove that the probability that the judged pipeline fails decays at a rate determined by the judge's true- and false-positive probabilities. When the judge is imperfect, we strengthen it through majority vote over independent judge calls, obtaining ensemble-level error rates that decrease exponentially in the number of votes. This yields an explicit bound on the probability that the pipeline selects a hallucinated answer.
  Experiments on controlled extraction tasks with synthetic noisy judges match these predictions exactly: pipeline failure decreases exponentially with the number of repetitions, and hallucination-selection decreases exponentially with the number of judges in the ensemble. Together, these results provide a lightweight, modular, and theoretically grounded method for driving hallucination probabilities arbitrarily low in fixed-input LLM workflows-without modifying model weights, decoding strategies, or prompt engineering.

</details>


### [31] [Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations](https://arxiv.org/abs/2601.00647)
*QiWei Meng*

Main category: cs.CL

TL;DR: 本文提出了Physio-DPO，一种基于物理能量信息的蛋白质语言模型对齐框架，显著提升了生成蛋白质的热力学稳定性和结构准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的蛋白质语言模型虽然在生成蛋白设计中表现出潜力，但常产生结构幻觉，生成的序列虽然语言可能性高但在热力学上不稳定。已有的对齐方法如Direct Preference Optimization无法有效处理物理能量的连续性问题。

Method: Physio-DPO引入了一种考虑物理能量差异的目标函数，根据原生结构与受物理扰动的负样本之间的能量差调整优化更新力度，将热力学稳定性纳入蛋白质语言模型训练中。

Result: 实验结果表明，Physio-DPO显著优于SFT、PPO及标准DPO方法，自洽RMSD降低至1.28 Å，蛋白折叠能力提升至92.8%。

Conclusion: Physio-DPO有效缓解了蛋白质生成中的结构幻觉问题，通过恢复疏水核心堆积和氢键网络等生物物理相互作用，提高生成蛋白的热力学稳定性与结构可靠性。

Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 Å and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.

</details>


### [32] [Fast-weight Product Key Memory](https://arxiv.org/abs/2601.00671)
*Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: 提出了一种名为Fast-weight Product Key Memory (FwPKM)的新型序列建模架构，通过动态更新参数解决了存储容量与计算效率之间的权衡，显著提升了长上下文处理能力。


<details>
  <summary>Details</summary>
Motivation: 传统的语言模型在序列建模时，常在存储容量和计算效率之间面临权衡：Softmax注意力虽有无界存储但计算代价高，线性变体效率高但存储有限。

Method: 提出将静态的Product Key Memory（PKM）模块转化为动态、快速权重的情景记忆机制，通过局部分块的梯度下降在训练和推理时动态更新参数，实现对输入序列中新键值对的快速记忆和检索。

Result: 实验证明FwPKM作为一种情景记忆，有效补充了标准模块的语义记忆，在长上下文数据集上显著降低了困惑度，且在严格的"针眼挑战"测试中实现了从4K训练序列推广到128K上下文的能力。

Conclusion: FwPKM通过将静态PKM转变为动态记忆模块，成功兼顾了存储容量与计算效率，极大提升了模型对超长序列的处理能力，展现出优异的泛化性能。

Abstract: Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, "fast-weight" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.

</details>


### [33] [Sigmoid Head for Quality Estimation under Language Ambiguity](https://arxiv.org/abs/2601.00680)
*Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出了Sigmoid Head模块，用于提升预训练语言模型输出的质量估计准确性，解决了原有模型因softmax激活和单一训练数据导致的质量评估不足问题。


<details>
  <summary>Details</summary>
Motivation: 语言模型概率分布因多义性而不能可靠反映输出质量，尤其是当存在多个有效输出时，softmax激活及单一训练数据限制了质量估计的准确性。

Method: 在预训练语言模型基础上训练一个名为Sigmoid Head的额外解码头，使用sigmoid激活解决softmax带来的限制，同时通过启发式负采样避免错误地标记多个正确选项，提升质量估计效果。

Result: Sigmoid Head在训练和推理上计算效率高，能提供比传统softmax头更优质的信号，且由于不依赖人工标注的质量数据，在跨领域任务中表现更鲁棒。

Conclusion: 通过加入Sigmoid Head模块，本文成功提升了语言模型输出的质量估计能力，克服了传统softmax方法的局限性，尤其在无监督和跨领域环境中展现了优势。

Abstract: Language model (LM) probability is not a reliable quality estimator, as natural language is ambiguous. When multiple output options are valid, the model's probability distribution is spread across them, which can misleadingly indicate low output quality. This issue is caused by two reasons: (1) LMs' final output activation is softmax, which does not allow multiple correct options to receive high probabilities simultaneuously and (2) LMs' training data is single, one-hot encoded references, indicating that there is only one correct option at each output step. We propose training a module for Quality Estimation on top of pre-trained LMs to address these limitations. The module, called Sigmoid Head, is an extra unembedding head with sigmoid activation to tackle the first limitation. To tackle the second limitation, during the negative sampling process to train the Sigmoid Head, we use a heuristic to avoid selecting potentially alternative correct tokens. Our Sigmoid Head is computationally efficient during training and inference. The probability from Sigmoid Head is notably better quality signal compared to the original softmax head. As the Sigmoid Head does not rely on human-annotated quality data, it is more robust to out-of-domain settings compared to supervised QE.

</details>


### [34] [Exploring the Performance of Large Language Models on Subjective Span Identification Tasks](https://arxiv.org/abs/2601.00736)
*Alphaeus Dmonte,Roland Oruche,Tharindu Ranasinghe,Marcos Zampieri,Prasad Calyam*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）在文本片段识别任务中的表现，涵盖情感分析、攻击性语言识别和声明验证三大应用，探索了多种LLM策略并发现文本中潜在关系有助于准确识别文本片段。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注显式文本片段识别（如命名实体识别），而使用LLMs进行更主观的片段识别（如基于方面的情感分析）研究较少，存在重要的研究空白。

Method: 本文在三种任务中评估不同LLM的表现，采用多种策略包括指令微调、上下文学习和思维链技术来提升文本片段识别效果。

Result: 结果表明，文本内在的关系帮助LLMs更准确地识别文本片段。

Conclusion: LLMs在文本片段识别任务中表现出良好潜力，不同策略结合文本内关系可提高识别准确性，填补了主观片段识别的研究空白。

Abstract: Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.

</details>


### [35] [Adapting Natural Language Processing Models Across Jurisdictions: A pilot Study in Canadian Cancer Registries](https://arxiv.org/abs/2601.00787)
*Jonathan Simkin,Lovedeep Gondara,Zeeshan Rizvi,Gregory Doyle,Jeff Dowden,Dan Bond,Desmond Martin,Raymond Ng*

Main category: cs.CL

TL;DR: 本文首次评估了两种基于Transformer的模型跨省适应性，通过细化训练和模型集成，实现了病理报告中癌症识别的高召回率与错误覆盖率提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的癌症病理报告自动抽取系统在不同地区的报告格式下泛化能力有限，需验证其跨司法区的适应性和性能。

Method: 采用BCCRTron和GatorTron两种Transformer模型，基于新省癌症登记数据进行微调，利用互补的报告输入管道训练完成两个任务（癌症/非癌症和可报告/非可报告），并通过模型集成提升敏感性。

Result: 适应后的模型在测试集上保持高性能，集成模型召回率达0.99，错过的癌症数量显著降低，展示了模型跨省迁移的有效性和集成优势。

Conclusion: 跨省共享模型权重实现隐私保护的同时，支持可互操作的NLP基础设施，为未来全国范围内癌症病理和登记工作奠定了模型基础。

Abstract: Population-based cancer registries depend on pathology reports as their primary diagnostic source, yet manual abstraction is resource-intensive and contributes to delays in cancer data. While transformer-based NLP systems have improved registry workflows, their ability to generalize across jurisdictions with differing reporting conventions remains poorly understood. We present the first cross-provincial evaluation of adapting BCCRTron, a domain-adapted transformer model developed at the British Columbia Cancer Registry, alongside GatorTron, a biomedical transformer model, for cancer surveillance in Canada. Our training dataset consisted of approximately 104,000 and 22,000 de-identified pathology reports from the Newfoundland & Labrador Cancer Registry (NLCR) for Tier 1 (cancer vs. non-cancer) and Tier 2 (reportable vs. non-reportable) tasks, respectively. Both models were fine-tuned using complementary synoptic and diagnosis focused report section input pipelines. Across NLCR test sets, the adapted models maintained high performance, demonstrating transformers pretrained in one jurisdiction can be localized to another with modest fine-tuning. To improve sensitivity, we combined the two models using a conservative OR-ensemble achieving a Tier 1 recall of 0.99 and reduced missed cancers to 24, compared with 48 and 54 for the standalone models. For Tier 2, the ensemble achieved 0.99 recall and reduced missed reportable cancers to 33, compared with 54 and 46 for the individual models. These findings demonstrate that an ensemble combining complementary text representations substantially reduce missed cancers and improve error coverage in cancer-registry NLP. We implement a privacy-preserving workflow in which only model weights are shared between provinces, supporting interoperable NLP infrastructure and a future pan-Canadian foundation model for cancer pathology and registry workflows.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [36] [μACP: A Formal Calculus for Expressive, Resource-Constrained Agent Communication](https://arxiv.org/abs/2601.00219)
*Arnab Mallick,Indraveni Chebolu*

Main category: cs.MA

TL;DR: 提出了$μ$ACP，一种在资源受限环境下兼具表达能力和效率的多智能体通信形式系统。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体通信协议在保证语义丰富性和资源受限环境效率之间存在权衡，缺乏统一理论支撑。

Method: 提出资源受限智能体通信模型（RCAC），设计了包含四个基本动词的形式演算$μ$ACP，进行理论证明和模型验证，并通过仿真实验评估性能。

Result: 证明四动词基础足以编码有限状态FIPA协议，建立信息论消息复杂度界限，实现边缘环境下标准共识协议，形式验证安全性及活性，仿真显示消息延迟显著降低，优于现有协议。

Conclusion: $μ$ACP统一了语义表达力与效率，实现了资源受限多智能体系统的严谨理论基础和高效通信框架。

Abstract: Agent communication remains a foundational problem in multi-agent systems: protocols such as FIPA-ACL guarantee semantic richness but are intractable for constrained environments, while lightweight IoT protocols achieve efficiency at the expense of expressiveness. This paper presents $μ$ACP, a formal calculus for expressive agent communication under explicit resource bounds. We formalize the Resource-Constrained Agent Communication (RCAC) model, prove that a minimal four-verb basis \textit{\{PING, TELL, ASK, OBSERVE\}} is suffices to encode finite-state FIPA protocols, and establish tight information-theoretic bounds on message complexity. We further show that $μ$ACP can implement standard consensus under partial synchrony and crash faults, yielding a constructive coordination framework for edge-native agents. Formal verification in TLA$^{+}$ (model checking) and Coq (mechanized invariants) establishes safety and boundedness, and supports liveness under modeled assumptions. Large-scale system simulations confirm ACP achieves a median end-to-end message latency of 34 ms (95th percentile 104 ms) at scale, outperforming prior agent and IoT protocols under severe resource constraints. The main contribution is a unified calculus that reconciles semantic expressiveness with provable efficiency, providing a rigorous foundation for the next generation of resource-constrained multi-agent systems.

</details>


### [37] [Offline Multi-Agent Reinforcement Learning for 6G Communications: Fundamentals, Applications and Future Directions](https://arxiv.org/abs/2601.00321)
*Eslam Eldeeb,Hirley Alves*

Main category: cs.MA

TL;DR: 介绍了一种基于保守Q学习的离线多智能体强化学习算法，结合元学习处理动态环境，应用于无线网络资源管理和无人机网络，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络日益复杂，传统在线强化学习在多智能体环境下存在成本、安全和扩展性问题，需要新的方法进行高效决策。

Method: 提出基于保守Q学习的离线多智能体强化学习算法，并结合元学习技术以适应动态环境，实现安全高效训练。

Result: 算法有效应用于无线资源管理和无人机网络场景，验证了其在复杂环境下的实用性和优势。

Conclusion: 离线多智能体强化学习为未来无线网络智能决策提供了有力支持，解决了在线方法的限制，未来研究应进一步优化和推广应用。

Abstract: The next-generation wireless technologies, including beyond 5G and 6G networks, are paving the way for transformative applications such as vehicle platooning, smart cities, and remote surgery. These innovations are driven by a vast array of interconnected wireless entities, including IoT devices, access points, UAVs, and CAVs, which increase network complexity and demand more advanced decision-making algorithms. Artificial intelligence (AI) and machine learning (ML), especially reinforcement learning (RL), are key enablers for such networks, providing solutions to high-dimensional and complex challenges. However, as networks expand to multi-agent environments, traditional online RL approaches face cost, safety, and scalability limitations. Offline multi-agent reinforcement learning (MARL) offers a promising solution by utilizing pre-collected data, reducing the need for real-time interaction. This article introduces a novel offline MARL algorithm based on conservative Q-learning (CQL), ensuring safe and efficient training. We extend this with meta-learning to address dynamic environments and validate the approach through use cases in radio resource management and UAV networks. Our work highlights offline MARL's advantages, limitations, and future directions in wireless applications.

</details>


### [38] [Mapping Human Anti-collusion Mechanisms to Multi-agent AI](https://arxiv.org/abs/2601.00360)
*Jamiu Adekunle Idowu,Ahmed Almasoud,Ayman Alfahid*

Main category: cs.MA

TL;DR: 本文探讨了多智能体人工智能系统中的串通问题，基于人类反串通机制，提出了相应干预措施并指出了相关挑战。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体AI系统的自主性增强，它们可能发展出类似人类市场中的串通策略，但现有人类反串通机制在AI领域的适应性尚不明晰。

Method: 构建了人类反串通机制的分类体系，包括制裁、宽大处理与举报、监控与审计、市场设计及治理，并将这些机制映射到多智能体AI系统的潜在干预措施，提出具体实现方法。

Result: 提出了针对每种反串通机制的多智能体AI系统实施方案，同时指出了归因困难、身份流动性、边界问题和对抗适应等开放性挑战。

Conclusion: 本文为多智能体AI系统的反串通干预提供了系统框架和指导，强调需进一步解决相关技术及理论难题以有效防范AI系统串通行为。

Abstract: As multi-agent AI systems become increasingly autonomous, evidence shows they can develop collusive strategies similar to those long observed in human markets and institutions. While human domains have accumulated centuries of anti-collusion mechanisms, it remains unclear how these can be adapted to AI settings. This paper addresses that gap by (i) developing a taxonomy of human anti-collusion mechanisms, including sanctions, leniency & whistleblowing, monitoring & auditing, market design, and governance and (ii) mapping them to potential interventions for multi-agent AI systems. For each mechanism, we propose implementation approaches. We also highlight open challenges, such as the attribution problem (difficulty attributing emergent coordination to specific agents) identity fluidity (agents being easily forked or modified) the boundary problem (distinguishing beneficial cooperation from harmful collusion) and adversarial adaptation (agents learning to evade detection).

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [39] [Understanding Security Risks of AI Agents' Dependency Updates](https://arxiv.org/abs/2601.00205)
*Tanmay Singla,Berk Çakar,Paschal C. Amusuo,James C. Davis*

Main category: cs.SE

TL;DR: 研究比较了AI代理和人类在软件包依赖更改中的安全风险，发现AI代理更频繁地引入已知漏洞版本且修复难度更高，导致整体安全风险增加。


<details>
  <summary>Details</summary>
Motivation: 随着AI编码代理越来越多地通过拉取请求修改软件，亟需评估其在依赖包选择上的安全影响。

Method: 分析了7个生态系统中117,062个由AI代理和人类提交的依赖变更，比较它们引入已知漏洞版本的频率和修复难度。

Result: AI代理引入漏洞版本的比例为2.46%，高于人类的1.64%；且AI引入的漏洞更难修复，需大版本升级的比例为36.8%，远高于人类的12.9%；总体上，AI驱动的依赖更新导致98个漏洞净增加，而人类驱动则减少了1,316个漏洞。

Conclusion: 建议在拉取请求时增强漏洞检测和采用适合生态的保护措施，以降低AI代理引发的依赖安全风险。

Abstract: Package dependencies are a critical control point in modern software supply chains. Dependency changes can substantially alter a project's security posture. As AI coding agents increasingly modify software via pull requests, it is unclear whether their dependency decisions introduce distinct security risks.
  We study 117,062 dependency changes from agent- and human-authored pull requests across seven ecosystems. Agents select known-vulnerable versions more often than humans (2.46% vs. 1.64%), and their vulnerable selections are more disruptive to remediate, with 36.8% requiring major-version upgrades compared to 12.9% for humans, despite patched alternatives existing in most cases. At the aggregate level, agent-driven dependency work yields a net vulnerability increase of 98, whereas human-authored work yields a net reduction of 1,316. These findings motivate pull-request-time vulnerability screening and registry-aware guardrails to make agent-driven dependency updates safer.

</details>


### [40] [Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities](https://arxiv.org/abs/2601.00235)
*Victor Wen,Zedong Peng*

Main category: cs.SE

TL;DR: 本文提出了一种先进的Log4j漏洞扫描工具，通过评估实际漏洞利用可能性，减少误报，并集成到GitHub Actions，实现自动化、持续扫描。


<details>
  <summary>Details</summary>
Motivation: 当前Log4j漏洞检测工具多只检测版本号，导致高误报率，无法判断软件是否真正易受攻击。

Method: 开发了一种扫描工具，先识别漏洞，再提供针对性缓解建议，并通过GitHub Actions实现自动持续扫描和即时反馈。

Result: 在28个开源项目的140次扫描中，工具达到了91.4%的准确率，效果显著。

Conclusion: 该工具有效降低了误报率，增强了漏洞检测的实用性，能帮助开发者实时监控和快速响应潜在威胁，提高开源软件安全性。

Abstract: Automated detection of software vulnerabilities remains a critical challenge in software security. Log4j is an industrial-grade Java logging framework listed as one of the top 100 critical open source projects. On Dec. 10, 2021 a severe vulnerability Log4Shell was disclosed before being fully patched with Log4j2 version 2.17.0 on Dec. 18, 2021. However, to this day about 4.1 million, or 33 percent of all Log4j downloads in the last 7 days contain vulnerable packages. Many Log4Shell scanners have since been created to detect if a user's installed Log4j version is vulnerable. Current detection tools primarily focus on identifying the version of Log4j installed, leading to numerous false positives, as they do not check if the software scanned is really vulnerable to malicious actors. This research aims to develop an advanced Log4j scanning tool that can evaluate the real-world exploitability of the software, thereby reducing false positives. Our approach first identifies vulnerabilities and then provides targeted recommendations for mitigating these detected vulnerabilities, along with instant feedback to users. By leveraging GitHub Actions, our tool offers automated and continuous scanning capabilities, ensuring timely identification of vulnerabilities as code changes occur. This integration into existing development workflows enables real-time monitoring and quicker responses to potential threats. We demonstrate the effectiveness of our approach by evaluating 28 open-source software projects across different releases, achieving an accuracy rate of 91.4% from a sample of 140 scans. Our GitHub action implementation is available at the GitHub marketplace and can be accessed by anyone interested in improving their software security and for future studies. This tool provides a dependable way to detect and mitigate vulnerabilities in open-source projects.

</details>


### [41] [An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems](https://arxiv.org/abs/2601.00254)
*Md Hasan Saju,Maher Muhtadi,Akramul Azim*

Main category: cs.SE

TL;DR: 本文通过比较检索增强生成(RAG)、监督微调(SFT)和双代理框架三种大语言模型(LLM)技术，评估其在软件漏洞检测任务中的效果，发现RAG方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，如何有效利用其进行自动化软件漏洞检测成为保障代码安全的重要方向。

Method: 本文使用了三种LLM技术：结合外部知识库的RAG，利用参数高效适配器进行监督微调的SFT，以及通过双代理架构提升推理透明性和减少错误的系统。数据集涵盖五类关键漏洞类型。

Result: RAG方法因集成外部领域知识，实现了最高准确率0.86和F1分数0.85；SFT也表现强劲；双代理系统有效提升了推理透明度和错误缓解并降低资源消耗。

Conclusion: 引入领域专业知识机制显著增强了LLM在现实软件漏洞检测任务中的实用性和性能，验证了多种技术手段的互补优势。

Abstract: The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.

</details>


### [42] [In Line with Context: Repository-Level Code Generation via Context Inlining](https://arxiv.org/abs/2601.00376)
*Chao Hu,Wenhao Zeng,Yuling Shi,Beijun Shen,Xiaodong Gu*

Main category: cs.SE

TL;DR: 本文提出了InlineCoder，一种通过内联未完成函数到调用图中，改进仓库级代码生成的新框架，解决了现有方法难以捕捉复杂依赖的问题。


<details>
  <summary>Details</summary>
Motivation: 现有仓库级代码生成方法依赖于表面相似性，难以理解复杂的函数、类和模块间的依赖关系，限制了生成效果。

Method: InlineCoder先生成未完成函数的草稿（anchor），估计依赖关系的置信度，然后通过双向内联：上游内联将anchor嵌入调用者，下游检索将被调用者信息融入提示，增强上下文理解。

Result: 通过结合上下游信息，InlineCoder为大型语言模型提供了全面的仓库视角，提升了代码生成的准确性和依赖理解能力。

Conclusion: InlineCoder有效克服了传统方法对仓库复杂依赖捕捉不足的问题，为仓库级代码生成提供了新的解决方案。

Abstract: Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.

</details>


### [43] [On Plagiarism and Software Plagiarism](https://arxiv.org/abs/2601.00429)
*Rares Folea,Emil Slusanschi*

Main category: cs.SE

TL;DR: 本文探讨了自动检测软件相似性的复杂性，介绍了开源解决方案Project Martial，并综述了现有技术及法律背景。


<details>
  <summary>Details</summary>
Motivation: 软件相似性检测存在复杂挑战，尤其在应对软件抄袭和版权问题时，需要有效工具和方法。

Method: 本文分类总结了检测挑战和已有方法，包括指纹技术、软件出生标记和代码嵌入，并介绍了Project Martial的实现。

Result: 通过结合多种技术，Project Martial能够有效地检测代码相似性，支持软件抄袭检测。

Conclusion: Project Martial为自动软件相似性检测提供了开源解决方案，结合理论与法律分析，有助于打击软件抄袭。

Abstract: This paper explores the complexities of automatic detection of software similarities, in relation to the unique challenges of digital artifacts, and introduces Project Martial, an open-source software solution for detecting code similarity. This research enumerates some of the existing approaches to counter software plagiarism by examining both the academia and legal landscape, including notable lawsuits and court rulings that have shaped the understanding of software copyright infringements in commercial applications. Furthermore, we categorize the classes of detection challenges based on the available artifacts, and we provide a survey of the previously studied techniques in the literature, including solutions based on fingerprinting, software birthmarks, or code embeddings, and exemplify how a subset of them can be applied in the context of Project Martial.

</details>


### [44] [DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis](https://arxiv.org/abs/2601.00469)
*Negin Ayoughi,David Dewar,Shiva Nejati,Mehrdad Sabetzadeh*

Main category: cs.SE

TL;DR: 本文提出一种基于大语言模型的优化建模方法EXEOS，通过自然语言生成领域特定语言AMPL模型及Python代码，并利用求解器反馈迭代优化，结果表明在执行性和正确性上AMPL模型竞争甚至优于Python代码。


<details>
  <summary>Details</summary>
Motivation: 工业界中模型驱动工程因模型开发维护成本高而应用受限，大语言模型能降低该成本，但在领域特定语言上生成模型准确性较低，需要改进。

Method: 提出EXEOS方法，从自然语言描述自动生成AMPL和Python代码，并通过求解器反馈迭代完善模型，同时在数学优化领域进行了实验验证。

Result: 在公开数据集和真实供应链案例上，EXEOS生成的AMPL模型在执行性和正确性方面表现与Python代码相当，甚至更优，且设计选择提升了生成质量。

Conclusion: 基于LLM的EXEOS方法有效克服了领域特定语言模型生成的难题，提升领域特定语言AMPL模型的可用性和准确性，促进模型驱动工程的工业应用。

Abstract: Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.

</details>


### [45] [Multi-Agent Coordinated Rename Refactoring](https://arxiv.org/abs/2601.00482)
*Abhiram Bellur,Mohammed Raihan Ullah,Fraol Batole,Mohit Kansara,Masaharu Morimoto,Kai Ishikawa,Haifeng Chen,Yaroslav Zharov,Timofey Bryksin,Tien N. Nguyen,Hridesh Rajan,Danny Dig*

Main category: cs.SE

TL;DR: 本文提出一种多智能体框架，自动完成软件中的协调重命名，减轻开发者负担。


<details>
  <summary>Details</summary>
Motivation: 协调重命名是一项频繁但耗时且易错的任务，现有方法误报多且建议不完整，开发者面对大量错误建议负担沉重。

Method: 设计多智能体系统，包括范围推断智能体（将初始重命名线索转为明确的范围描述）、计划执行智能体（根据范围调用IDE重构API执行安全修改）、复制智能体（引导全项目搜索相关重命名）。

Result: 通过对超过60万次提交和205名开发者调查的形式化研究验证了方法的有效性和实用性。

Conclusion: 多智能体框架能显著减少协调重命名任务中的人工重复劳动，同时保持开发者对过程的控制权。

Abstract: The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.
  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...

</details>


### [46] [STELLAR: A Search-Based Testing Framework for Large Language Model Applications](https://arxiv.org/abs/2601.00497)
*Lev Sorokin,Ivan Vasilev,Ken E. Friedl,Andrea Stocco*

Main category: cs.SE

TL;DR: STELLAR是一种基于进化优化的自动化测试框架，用于系统性发现大型语言模型应用中的不适当响应输入，比现有方法暴露更多缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型应用广泛部署，但存在产生错误、虚构或有害响应的问题，输入空间庞大且高维，测试难度大，需要有效的自动化测试方法。

Method: 将测试生成建模为优化问题，将输入空间离散化为风格、内容和扰动特征，采用进化优化动态探索特征组合以发现更多系统失败。

Result: 在三个基于大型语言模型的对话式问答系统上评估，STELLAR能暴露最多4.3倍（平均2.5倍）于现有基线方法的系统失败。

Conclusion: STELLAR有效提升了对大型语言模型应用的测试覆盖和缺陷发现能力，为保障系统安全性和可靠性提供了有力工具。

Abstract: Large Language Model (LLM)-based applications are increasingly deployed across various domains, including customer service, education, and mobility. However, these systems are prone to inaccurate, fictitious, or harmful responses, and their vast, high-dimensional input space makes systematic testing particularly challenging. To address this, we present STELLAR, an automated search-based testing framework for LLM-based applications that systematically uncovers text inputs leading to inappropriate system responses. Our framework models test generation as an optimization problem and discretizes the input space into stylistic, content-related, and perturbation features. Unlike prior work that focuses on prompt optimization or coverage heuristics, our work employs evolutionary optimization to dynamically explore feature combinations that are more likely to expose failures. We evaluate STELLAR on three LLM-based conversational question-answering systems. The first focuses on safety, benchmarking both public and proprietary LLMs against malicious or unsafe prompts. The second and third target navigation, using an open-source and an industrial retrieval-augmented system for in-vehicle venue recommendations. Overall, STELLAR exposes up to 4.3 times (average 2.5 times) more failures than the existing baseline approaches.

</details>


### [47] [SEMODS: A Validated Dataset of Open-Source Software Engineering Models](https://arxiv.org/abs/2601.00635)
*Alexandra González,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: 提出了SEMODS数据集，汇集了3,427个与软件工程任务相关的模型，支持模型发现和评估。


<details>
  <summary>Details</summary>
Motivation: 现有资源中模型众多且不断增长，缺乏专门针对软件工程任务的模型目录，难以识别适合的软件工程模型。

Method: 从Hugging Face自动收集模型，结合人工注释和大语言模型辅助进行严格验证，构建了一个以软件工程任务和生命周期活动为标签的数据集。

Result: 构建了包含3,427个模型的SEMODS数据集，提供标准化的评估结果表示，支持多种应用场景如数据分析、模型发现、基准测试和模型适配。

Conclusion: SEMODS填补了软件工程领域模型目录的空白，为相关任务提供了便捷的模型资源和多功能支持。

Abstract: Integrating Artificial Intelligence into Software Engineering (SE) requires having a curated collection of models suited to SE tasks. With millions of models hosted on Hugging Face (HF) and new ones continuously being created, it is infeasible to identify SE models without a dedicated catalogue. To address this gap, we present SEMODS: an SE-focused dataset of 3,427 models extracted from HF, combining automated collection with rigorous validation through manual annotation and large language model assistance. Our dataset links models to SE tasks and activities from the software development lifecycle, offering a standardized representation of their evaluation results, and supporting multiple applications such as data analysis, model discovery, benchmarking, and model adaptation.

</details>


### [48] [Early-Stage Prediction of Review Effort in AI-Generated Pull Requests](https://arxiv.org/abs/2601.00753)
*Dao Sy Duy Minh,Huynh Trung Kiet,Tran Chi Nguyen,Nguyen Lam Phu Quy,Phu Hoa Pham,Nguyen Dinh Ha Duong,Truong Bao Tran*

Main category: cs.SE

TL;DR: 本论文研究了自主AI代理生成的拉取请求(PR)在代码审查中产生的审查工作量，提出了预测高审查负荷PR的模型。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理成为团队成员，软件维护者不仅需审查代码，还需管理与非人类贡献者的复杂互动。如何预测哪些AI生成的PR会带来高审查工作量成为挑战。

Method: 分析了33,707个AI代理生成的PR，发现两种行为模式；基于静态结构特征，提出Circuit Breaker模型，用LightGBM进行预测，语义文本特征价值有限。

Result: 模型在时间分割上AUC达0.957，能在20%审查预算内拦截69%的总审查工作，支持零延迟治理。

Conclusion: 审查负担由AI代理修改内容决定而非文本描述，强调应建立结构化治理机制以促进人机协作。

Abstract: As autonomous AI agents transition from code completion tools to full-fledged teammates capable of opening pull requests (PRs) at scale, software maintainers face a new challenge: not just reviewing code, but managing complex interaction loops with non-human contributors. This paradigm shift raises a critical question: can we predict which agent-generated PRs will consume excessive review effort before any human interaction begins?
  Analyzing 33,707 agent-authored PRs from the AIDev dataset across 2,807 repositories, we uncover a striking two-regime behavioral pattern that fundamentally distinguishes autonomous agents from human developers. The first regime, representing 28.3 percent of all PRs, consists of instant merges (less than 1 minute), reflecting success on narrow automation tasks. The second regime involves iterative review cycles where agents frequently stall or abandon refinement (ghosting).
  We propose a Circuit Breaker triage model that predicts high-review-effort PRs (top 20 percent) at creation time using only static structural features. A LightGBM model achieves AUC 0.957 on a temporal split, while semantic text features (TF-IDF, CodeBERT) provide negligible predictive value. At a 20 percent review budget, the model intercepts 69 percent of total review effort, enabling zero-latency governance.
  Our findings challenge prevailing assumptions in AI-assisted code review: review burden is dictated by what agents touch, not what they say, highlighting the need for structural governance mechanisms in human-AI collaboration.

</details>
