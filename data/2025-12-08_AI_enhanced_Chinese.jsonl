{"id": "2512.05159", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.05159", "abs": "https://arxiv.org/abs/2512.05159", "authors": ["Zhiyi Wang", "Xiwei Wu", "Yi Fang", "Chengtao Li", "Hongyi Zhong", "Lihan Xie", "Qinxiang Cao", "Zhenjiang Hu"], "title": "Stellis: A Strategy Language for Purifying Separation Logic Entailments", "comment": null, "summary": "Automatically proving separation logic entailments is a fundamental challenge in verification. While rule-based methods rely on separation logic rules (lemmas) for automation, these rule statements are insufficient for describing automation strategies, which usually involve the alignment and elimination of corresponding memory layouts in specific scenarios. To overcome this limitation, we propose Stellis, a strategy language for purifying separation logic entailments, i.e., removing all spatial formulas to reduce the entailment to a simpler pure entailment. Stellis features a powerful matching mechanism and a flexible action description, enabling the straightforward encoding of a wide range of strategies. To ensure strategy soundness, we introduce an algorithm that generates a soundness condition for each strategy, thereby reducing the soundness of each strategy to the correctness of its soundness condition. Furthermore, based on a mechanized reduction soundness theorem, our prototype implementation generates correctness proofs for the overall automation. We evaluate our system on a benchmark of 229 entailments collected from verification of standard linked data structures and the memory module of a microkernel, and the evaluation results demonstrate that, with such flexibility and convenience provided, our system is also highly effective, which automatically purifies 95.6% (219 out of 229) of the entailments using 5 libraries with 98 strategies.", "AI": {"tldr": "\u63d0\u51faStellis\u7b56\u7565\u8bed\u8a00\u53ca\u5176\u5065\u5168\u6027\u7b97\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u5206\u79bb\u903b\u8f91\u8574\u542b\u81ea\u52a8\u7eaf\u5316\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9ad8\u81ea\u52a8\u5316\u7387\u548c\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u63cf\u8ff0\u81ea\u52a8\u5316\u7b56\u7565\uff0c\u5c24\u5176\u662f\u5728\u7279\u5b9a\u573a\u666f\u4e0b\u5bf9\u5185\u5b58\u5e03\u5c40\u7684\u5339\u914d\u548c\u6d88\u9664\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51faStellis\u7b56\u7565\u8bed\u8a00\uff0c\u901a\u8fc7\u5f3a\u5927\u7684\u5339\u914d\u673a\u5236\u548c\u7075\u6d3b\u7684\u52a8\u4f5c\u63cf\u8ff0\uff0c\u5b9e\u73b0\u5bf9\u5206\u79bb\u903b\u8f91\u8574\u542b\u5f0f\u7684\u7eaf\u5316\uff0c\u5373\u53bb\u9664\u6240\u6709\u7a7a\u95f4\u516c\u5f0f\uff0c\u7b80\u5316\u8574\u542b\u5f0f\u3002\u5f15\u5165\u751f\u6210\u7b56\u7565\u5065\u5168\u6027\u6761\u4ef6\u7684\u7b97\u6cd5\uff0c\u5e76\u5229\u7528\u673a\u68b0\u5316\u8bc1\u660e\u751f\u6210\u6574\u4f53\u81ea\u52a8\u5316\u6b63\u786e\u6027\u3002", "result": "\u5728\u6765\u81ea\u94fe\u5f0f\u6570\u636e\u7ed3\u6784\u548c\u5fae\u5185\u6838\u5185\u5b58\u6a21\u5757\u7684229\u4e2a\u8574\u542b\u5f0f\u57fa\u51c6\u4e0a\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5229\u75285\u4e2a\u5e93\u4e2d\u768498\u6761\u7b56\u7565\uff0c\u81ea\u52a8\u7eaf\u5316\u4e8695.6%\u7684\u8574\u542b\u5f0f\uff0c\u8bc1\u660e\u4e86\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u4e0e\u9ad8\u6548\u6027\u3002", "conclusion": "Stellis\u7b56\u7565\u8bed\u8a00\u6709\u6548\u89e3\u51b3\u4e86\u5206\u79bb\u903b\u8f91\u8574\u542b\u81ea\u52a8\u5316\u7b56\u7565\u63cf\u8ff0\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5065\u5168\u7684\u81ea\u52a8\u7eaf\u5316\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u81ea\u52a8\u8bc1\u660e\u7684\u7075\u6d3b\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2512.05176", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.05176", "abs": "https://arxiv.org/abs/2512.05176", "authors": ["Brittany Johnson", "Erin Reddick", "Angela D. R. Smith"], "title": "Towards A Cultural Intelligence and Values Inferences Quality Benchmark for Community Values and Common Knowledge", "comment": "Under review", "summary": "Large language models (LLMs) have emerged as a powerful technology, and thus, we have seen widespread adoption and use on software engineering teams. Most often, LLMs are designed as \"general purpose\" technologies meant to represent the general population. Unfortunately, this often means alignment with predominantly Western Caucasian narratives and misalignment with other cultures and populations that engage in collaborative innovation. In response to this misalignment, there have been recent efforts centered on the development of \"culturally-informed\" LLMs, such as ChatBlackGPT, that are capable of better aligning with historically marginalized experiences and perspectives. Despite this progress, there has been little effort aimed at supporting our ability to develop and evaluate culturally-informed LLMs. A recent effort proposed an approach for developing a national alignment benchmark that emphasizes alignment with national social values and common knowledge. However, given the range of cultural identities present in the United States (U.S.), a national alignment benchmark is an ineffective goal for broader representation. To help fill this gap in this US context, we propose a replication study that translates the process used to develop KorNAT, a Korean National LLM alignment benchmark, to develop CIVIQ, a Cultural Intelligence and Values Inference Quality benchmark centered on alignment with community social values and common knowledge. Our work provides a critical foundation for research and development aimed at cultural alignment of AI technologies in practice.", "AI": {"tldr": "\u8be5\u8bba\u6587\u805a\u7126\u4e8e\u5f00\u53d1\u6587\u5316\u667a\u80fd\u548c\u4ef7\u503c\u63a8\u65ad\u8d28\u91cf\u57fa\u51c6(CIVIQ)\uff0c\u4ee5\u4fc3\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u7f8e\u56fd\u591a\u5143\u6587\u5316\u80cc\u666f\u4e0b\u7684\u6587\u5316\u5bf9\u9f50\uff0c\u501f\u9274\u97e9\u56fd\u56fd\u5bb6\u5bf9\u9f50\u57fa\u51c6(KorNAT)\u7684\u65b9\u6cd5\uff0c\u5f25\u8865\u73b0\u6709\u57fa\u51c6\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5927\u591a\u4ee5\u897f\u65b9\u6587\u5316\u4e3a\u4e3b\u5bfc\uff0c\u96be\u4ee5\u6709\u6548\u5bf9\u9f50\u7f8e\u56fd\u590d\u6742\u591a\u5143\u7684\u6587\u5316\u8eab\u4efd\u80cc\u666f\uff0c\u73b0\u6709\u56fd\u5bb6\u7ea7\u5bf9\u9f50\u57fa\u51c6\u96be\u4ee5\u8986\u76d6\u5e7f\u6cdb\u6587\u5316\u4ee3\u8868\u6027\uff0c\u8feb\u5207\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u6587\u5316\u7fa4\u4f53\u7684\u5bf9\u9f50\u8bc4\u4f30\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u590d\u5236\u97e9\u56fdKorNAT\u57fa\u51c6\u5f00\u53d1\u6d41\u7a0b\uff0c\u7ed3\u5408\u7f8e\u56fd\u672c\u571f\u6587\u5316\u591a\u6837\u6027\uff0c\u8bbe\u8ba1\u5e76\u6784\u5efa\u4e86CIVIQ\u8fd9\u4e00\u6587\u5316\u667a\u80fd\u4e0e\u4ef7\u503c\u63a8\u65ad\u8d28\u91cf\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86\u9762\u5411\u7f8e\u56fd\u591a\u5143\u6587\u5316\u80cc\u666f\u7684CIVIQ\u57fa\u51c6\uff0c\u4e3a\u8bc4\u4f30\u548c\u63d0\u5347LLMs\u7684\u6587\u5316\u5bf9\u9f50\u6548\u679c\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u5de5\u5177\u548c\u6846\u67b6\uff0c\u6709\u671b\u63a8\u52a8\u66f4\u5305\u5bb9\u548c\u516c\u5e73\u7684AI\u6a21\u578b\u7814\u53d1\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u5e76\u5f00\u53d1\u4e86CIVIQ\u57fa\u51c6\uff0c\u63d0\u5347\u4e86\u5728\u591a\u5143\u6587\u5316\u73af\u5883\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6587\u5316\u5bf9\u9f50\u80fd\u529b\uff0c\u4e3a\u672a\u6765AI\u7684\u6587\u5316\u9002\u5e94\u6027\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.05239", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05239", "abs": "https://arxiv.org/abs/2512.05239", "authors": ["Ruofan Gao", "Amjed Tahir", "Peng Liang", "Teo Susnjak", "Foutse Khomh"], "title": "A Survey of Bugs in AI-Generated Code", "comment": null, "summary": "Developers are widely using AI code-generation models, aiming to increase productivity and efficiency. However, there are also quality concerns regarding the AI-generated code. The generated code is produced by models trained on publicly available code, which are known to contain bugs and quality issues. Those issues can cause trust and maintenance challenges during the development process. Several quality issues associated with AI-generated code have been reported, including bugs and defects. However, these findings are often scattered and lack a systematic summary. A comprehensive review is currently lacking to reveal the types and distribution of these errors, possible remediation strategies, as well as their correlation with the specific models. In this paper, we systematically analyze the existing AI-generated code literature to establish an overall understanding of bugs and defects in generated code, providing a reference for future model improvement and quality assessment. We aim to understand the nature and extent of bugs in AI-generated code, and provide a classification of bug types and patterns present in code generated by different models. We also discuss possible fixes and mitigation strategies adopted to eliminate bugs from the generated code.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86AI\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u7c7b\u578b\u53ca\u5176\u5206\u5e03\uff0c\u5206\u7c7b\u4e0d\u540c\u6a21\u578b\u9519\u8bef\u6a21\u5f0f\uff0c\u5e76\u63d0\u51fa\u4fee\u590d\u548c\u7f13\u89e3\u8fd9\u4e9b\u7f3a\u9677\u7684\u7b56\u7565\uff0c\u4e3a\u672a\u6765\u6a21\u578b\u6539\u8fdb\u548c\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u53c2\u8003\u3002", "motivation": "\u5f53\u524dAI\u751f\u6210\u4ee3\u7801\u4e2d\u5b58\u5728\u8bb8\u591a\u8d28\u91cf\u95ee\u9898\u548c\u7f3a\u9677\uff0c\u4f46\u76f8\u5173\u53d1\u73b0\u96f6\u6563\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u603b\u7ed3\uff0c\u65e0\u6cd5\u5168\u9762\u4e86\u89e3\u5176\u9519\u8bef\u7c7b\u578b\u3001\u5206\u5e03\u53ca\u5bf9\u5e94\u6a21\u578b\u7684\u5173\u8054\u3002", "method": "\u7cfb\u7edf\u5730\u5206\u6790\u73b0\u6709AI\u751f\u6210\u4ee3\u7801\u7684\u6587\u732e\uff0c\u5f52\u7eb3\u603b\u7ed3\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u4e0e\u9519\u8bef\u7c7b\u578b\uff0c\u5e76\u5206\u7c7b\u4e0d\u540c\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u6a21\u5f0f\u3002", "result": "\u603b\u7ed3\u4e86AI\u751f\u6210\u4ee3\u7801\u4e2d\u5b58\u5728\u7684\u5404\u7c7b\u7f3a\u9677\u548c\u9519\u8bef\u6a21\u5f0f\uff0c\u5efa\u7acb\u4e86\u7f3a\u9677\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u63a2\u8ba8\u4e86\u4e0d\u540c\u6a21\u578b\u7684\u9519\u8bef\u5206\u5e03\uff0c\u5e76\u5206\u6790\u4e86\u76f8\u5e94\u7684\u4fee\u590d\u548c\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u5206\u6790\uff0c\u672c\u6587\u4e3a\u7406\u89e3AI\u751f\u6210\u4ee3\u7801\u4e2d\u7684\u7f3a\u9677\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u5206\u7c7b\u548c\u5206\u5e03\u89c6\u89d2\uff0c\u660e\u786e\u4e86\u6539\u8fdb\u65b9\u5411\u53ca\u4fee\u590d\u7b56\u7565\uff0c\u6709\u52a9\u4e8e\u63d0\u5347AI\u4ee3\u7801\u751f\u6210\u7684\u8d28\u91cf\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.05242", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05242", "abs": "https://arxiv.org/abs/2512.05242", "authors": ["Uwe M. Borghoff", "Mark Minas", "Jannis Schopp"], "title": "Learning to Code with Context: A Study-Based Approach", "comment": "36 pages, 7 figures, 5 tables", "summary": "The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively developed computer games. The study investigates how participants used generative AI tools throughout different phases of the software development process, identifies the types of tasks where such tools were most effective, and analyzes the challenges students encountered. Building on these insights, we further examine a repository-aware, locally deployed large language model (LLM) assistant designed to provide project-contextualized support. The system employs Retrieval-Augmented Generation (RAG) to ground responses in relevant documentation and source code, enabling qualitative analysis of model behavior, parameter sensitivity, and common failure modes. The findings deepen our understanding of context-aware AI support in educational software projects and inform future integration of AI-based assistance into software engineering curricula.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u9879\u76ee\u4e2d\u7684\u5e94\u7528\u53ca\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8eRAG\u6280\u672f\u7684\u4e0a\u4e0b\u6587\u611f\u77e5AI\u52a9\u624b\uff0c\u52a9\u529b\u6559\u5b66\u4e0e\u5f00\u53d1\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u5feb\u901f\u53d1\u5c55\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u9700\u9002\u5e94\u65b0\u6280\u672f\uff0c\u5229\u7528\u9879\u76ee\u8bfe\u7a0b\u63a2\u7d22AI\u8f85\u52a9\u7684\u6709\u6548\u6574\u5408\u4e0e\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5927\u5b66\u7f16\u7a0b\u9879\u76ee\u7684\u7528\u6237\u7814\u7a76\uff0c\u7ed3\u5408RAG\u6280\u672f\u6784\u5efa\u672c\u5730\u90e8\u7f72\u7684\u8bed\u8a00\u6a21\u578b\u52a9\u624b\uff0c\u8fdb\u884c\u6a21\u578b\u884c\u4e3a\u548c\u53c2\u6570\u654f\u611f\u6027\u5206\u6790\u3002", "result": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0fAI\u5de5\u5177\u5728\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u5e94\u7528\u53ca\u5176\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u9879\u76ee\u7684\u8bfe\u7a0b\u4e2d\u5982\u4f55\u6709\u6548\u6574\u5408AI\u8f85\u52a9\u3002\u901a\u8fc7\u5927\u5b66\u751f\u534f\u4f5c\u5f00\u53d1\u6e38\u620f\u7684\u9879\u76ee\u7814\u7a76\uff0c\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u5728\u5f00\u53d1\u4e0d\u540c\u9636\u6bb5\u7684\u4f7f\u7528\u60c5\u51b5\u3001\u6700\u6709\u6548\u7684\u4efb\u52a1\u7c7b\u578b\u53ca\u9047\u5230\u7684\u6311\u6218\u3002\u8bba\u6587\u8fd8\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u57fa\u4e8e\u672c\u5730\u90e8\u7f72\u3001\u652f\u6301\u4ee3\u7801\u4ed3\u5e93\u611f\u77e5\u7684\u8bed\u8a00\u6a21\u578b\u52a9\u624b\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u54cd\u5e94\uff0c\u5e76\u5bf9\u6a21\u578b\u8868\u73b0\u548c\u5931\u6548\u6a21\u5f0f\u8fdb\u884c\u4e86\u5b9a\u6027\u5206\u6790\u3002", "conclusion": "\u7814\u7a76\u52a0\u6df1\u4e86\u5bf9\u4e0a\u4e0b\u6587\u611f\u77e5AI\u652f\u6301\u5728\u6559\u80b2\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u7406\u89e3\uff0c\u63a8\u52a8\u4e86AI\u8f85\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u8bfe\u7a0b\u7684\u672a\u6765\u53d1\u5c55\u3002"}}
{"id": "2512.05447", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.05447", "abs": "https://arxiv.org/abs/2512.05447", "authors": ["Pengcheng Dai", "Dongming Wang", "Wenwu Yu", "Wei Ren"], "title": "Distributed scalable coupled policy algorithm for networked multi-agent reinforcement learning", "comment": null, "summary": "This paper studies networked multi-agent reinforcement learning (NMARL) with interdependent rewards and coupled policies. In this setting, each agent's reward depends on its own state-action pair as well as those of its direct neighbors, and each agent's policy is parameterized by its local parameters together with those of its $\u03ba_{p}$-hop neighbors, with $\u03ba_{p}\\geq 1$ denoting the coupled radius. The objective of the agents is to collaboratively optimize their policies to maximize the discounted average cumulative reward. To address the challenge of interdependent policies in collaborative optimization, we introduce a novel concept termed the neighbors' averaged $Q$-function and derive a new expression for the coupled policy gradient. Based on these theoretical foundations, we develop a distributed scalable coupled policy (DSCP) algorithm, where each agent relies only on the state-action pairs of its $\u03ba_{p}$-hop neighbors and the rewards its their $(\u03ba_{p}+1)$-hop neighbors. Specially, in the DSCP algorithm, we employ a geometric 2-horizon sampling method that does not require storing a full $Q$-table to obtain an unbiased estimate of the coupled policy gradient. Moreover, each agent interacts exclusively with its direct neighbors to obtain accurate policy parameters, while maintaining local estimates of other agents' parameters to execute its local policy and collect samples for optimization. These estimates and policy parameters are updated via a push-sum protocol, enabling distributed coordination of policy updates across the network. We prove that the joint policy produced by the proposed algorithm converges to a first-order stationary point of the objective function. Finally, the effectiveness of DSCP algorithm is demonstrated through simulations in a robot path planning environment, showing clear improvement over state-of-the-art methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u8026\u5408\u7b56\u7565\u7b97\u6cd5DSCP\uff0c\u6709\u6548\u5904\u7406\u591a\u667a\u80fd\u4f53\u5956\u52b1\u548c\u7b56\u7565\u8026\u5408\u95ee\u9898\uff0c\u5b9e\u73b0\u7b56\u7565\u5206\u5e03\u5f0f\u66f4\u65b0\u5e76\u7406\u8bba\u4fdd\u8bc1\u6536\u655b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u5728\u7f51\u7edc\u73af\u5883\u4e0b\u56e0\u5956\u52b1\u76f8\u4e92\u4f9d\u8d56\u548c\u7b56\u7565\u8026\u5408\u5e26\u6765\u7684\u534f\u540c\u4f18\u5316\u56f0\u96be\uff0c\u63d0\u9ad8\u7b56\u7565\u4f18\u5316\u7684\u53ef\u6269\u5c55\u6027\u548c\u5206\u5e03\u5f0f\u5b9e\u73b0\u80fd\u529b\u3002", "method": "\u5f15\u5165\u90bb\u5c45\u5e73\u5747Q\u51fd\u6570\uff0c\u63a8\u5bfc\u8026\u5408\u7b56\u7565\u68af\u5ea6\u8868\u8fbe\u5f0f\uff0c\u8bbe\u8ba1DSCP\u7b97\u6cd5\u5229\u7528\u03ba_p\u8df3\u90bb\u5c45\u7684\u72b6\u6001-\u52a8\u4f5c\u5bf9\u548c\u5956\u52b1\uff0c\u901a\u8fc7\u51e0\u4f552\u9636\u91c7\u6837\u65b9\u6cd5\u4f30\u8ba1\u68af\u5ea6\uff0c\u91c7\u7528push-sum\u534f\u8bae\u5206\u5e03\u5f0f\u66f4\u65b0\u7b56\u7565\u53c2\u6570\u3002", "result": "DSCP\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u7b56\u7565\u6536\u655b\u81f3\u4e00\u9636\u9a7b\u70b9\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u4e2d\u7684\u6027\u80fd\u4f18\u4e8e\u6700\u65b0\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684DSCP\u7b97\u6cd5\u5728\u7f51\u7edc\u5316\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u6709\u6548\u89e3\u51b3\u4e86\u7b56\u7565\u8026\u5408\u548c\u5956\u52b1\u4f9d\u8d56\u95ee\u9898\uff0c\u7406\u8bba\u8bc1\u660e\u5176\u6536\u655b\u6027\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u4eba\u8def\u5f84\u89c4\u5212\u5b9e\u9a8c\u8bc1\u660e\u4e86\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.05179", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05179", "abs": "https://arxiv.org/abs/2512.05179", "authors": ["Aur\u00e9lie Montfrond"], "title": "Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale", "comment": "4 pages, 2 figures", "summary": "Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated performance with Exact Match and F1 scores. Results show that even modest fine-tuning improves hypothesis framing and knowledge extraction, demonstrating the feasibility of adapting foundation models to educational domains. While domain-specific BERT variants such as BioBERT and SciBERT exist for biomedical and scientific literature, no foundation model has yet been tailored to university course materials. Our work addresses this gap by showing that fine-tuning BERT with academic QA pairs yields effective results, highlighting the potential to scale towards the first domain-specific QA model for universities and enabling autonomous educational knowledge systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03BERT\u6a21\u578b\uff0c\u57fa\u4e8e\u81ea\u5efa\u5927\u5b66\u8bfe\u7a0b\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u6709\u6548\u7684\u9886\u57df\u7279\u5b9a\u95ee\u7b54\u7cfb\u7edf\uff0c\u52a9\u529b\u9ad8\u6821\u6559\u80b2\u95ee\u7b54\u81ea\u52a8\u5316\u3002", "motivation": "\u5f53\u524d\u79d1\u5b66\u95ee\u7b54\u7cfb\u7edf\u591a\u6ce8\u91cd\u804a\u5929\u673a\u5668\u4eba\u98ce\u683c\uff0c\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u9488\u5bf9\u7279\u5b9a\u9886\u57df\u63a8\u7406\u7684\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u65b9\u6cd5\u3002", "method": "\u9488\u5bf9\u5229\u9ed8\u91cc\u514b\u5927\u5b66\u7535\u5b50\u4e0e\u8ba1\u7b97\u673a\u5de5\u7a0b\u7cfb\uff0c\u6784\u5efa\u4e861203\u6761\u95ee\u7b54\u5bf9\u6570\u636e\u96c6\uff0c\u57fa\u4e8eSQuAD\u683c\u5f0f\uff0c\u7ed3\u5408\u624b\u52a8\u548c\u5408\u6210\u6570\u636e\uff0c\u5229\u7528PyTorch\u5fae\u8c03BERT\u6a21\u578b\uff0c\u8bc4\u4f30\u6307\u6807\u4e3aExact Match\u548cF1\u5206\u6570\u3002", "result": "\u7ecf\u8fc7\u5fae\u8c03\u7684BERT\u5728\u5047\u8bbe\u6784\u5efa\u548c\u77e5\u8bc6\u63d0\u53d6\u65b9\u9762\u8868\u73b0\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u5c06\u57fa\u7840\u6a21\u578b\u9002\u5e94\u4e8e\u6559\u80b2\u9886\u57df\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u9488\u5bf9\u5927\u5b66\u8bfe\u7a0b\u8d44\u6599\u7684\u57fa\u7840\u6a21\u578b\u5fae\u8c03\u7a7a\u767d\uff0c\u5c55\u793a\u4e86\u4ee5\u5b66\u672f\u95ee\u7b54\u5bf9\u5fae\u8c03BERT\u83b7\u5f97\u6709\u6548\u7ed3\u679c\u7684\u53ef\u80fd\uff0c\u63a8\u52a8\u4e86\u9762\u5411\u9ad8\u6821\u7684\u9886\u57df\u7279\u5b9a\u95ee\u7b54\u6a21\u578b\u548c\u81ea\u4e3b\u6559\u80b2\u77e5\u8bc6\u7cfb\u7edf\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.05309", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05309", "abs": "https://arxiv.org/abs/2512.05309", "authors": ["Adam Alami", "Nathan Cassee", "Thiago Rocha Silva", "Elda Paja", "Neil A. Ernst"], "title": "Engagement in Code Review: Emotional, Behavioral, and Cognitive Dimensions in Peer vs. LLM Interactions", "comment": "Submitted to TOSEM", "summary": "Code review is a socio-technical practice, yet how software engineers engage in Large Language Model (LLM)-assisted code reviews compared to human peer-led reviews is less understood. We report a two-phase qualitative study with 20 software engineers to understand this. In Phase I, participants exchanged peer reviews and were interviewed about their affective responses and engagement decisions. In Phase II, we introduced a new prompt matching engineers' preferences and probed how characteristics shaped their reactions. We develop an integrative account linking emotional self-regulation to behavioral engagement and resolution. We identify self-regulation strategies that engineers use to regulate their emotions in response to negative feedback: reframing, dialogic regulation, avoidance, and defensiveness. Engagement proceeds through social calibration; engineers align their responses and behaviors to the relational climate and team norms. Trajectories to resolution, in the case of peer-led review, vary by locus (solo/dyad/team) and an internal sense-making process. With the LLM-assisted review, emotional costs and the need for self-regulation seem lower. When LLM feedback aligned with engineers' cognitive expectations, participants reported reduced processing effort and a potentially higher tendency to adopt. We show that LLM-assisted review redirects engagement from emotion management to cognitive load management. We contribute an integrative model of engagement that links emotional self-regulation to behavioral engagement and resolution, showing how affective and cognitive processes influence feedback adoption in peer-led and LLM-assisted code reviews. We conclude that AI is best positioned as a supportive partner to reduce cognitive and emotional load while preserving human accountability and the social meaning of peer review and similar socio-technical activities.", "AI": {"tldr": "\u901a\u8fc7\u4e24\u9636\u6bb5\u5b9a\u6027\u7814\u7a76\uff0c\u63ed\u793aLLM\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u76f8\u6bd4\u4f20\u7edf\u540c\u4f34\u5ba1\u67e5\u80fd\u51cf\u5c11\u60c5\u7eea\u548c\u8ba4\u77e5\u8d1f\u62c5\uff0c\u63d0\u9ad8\u53cd\u9988\u91c7\u7eb3\u7387\uff0cAI\u5e94\u4f5c\u4e3a\u8f85\u52a9\u4f19\u4f34\u800c\u975e\u66ff\u4ee3\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u63a2\u8ba8\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u7684\u4ee3\u7801\u5ba1\u67e5\u4e0e\u4eba\u9645\u540c\u4e8b\u4e3b\u5bfc\u7684\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u53c2\u4e0e\u65b9\u5f0f\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u4e24\u4e2a\u9636\u6bb5\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u7b2c\u4e00\u9636\u6bb5\u8ba920\u540d\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8fdb\u884c\u540c\u4f34\u5ba1\u67e5\u5e76\u91c7\u8bbf\u5176\u60c5\u611f\u53cd\u5e94\u548c\u53c2\u4e0e\u51b3\u7b56\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5f15\u5165\u7b26\u5408\u5de5\u7a0b\u5e08\u504f\u597d\u7684\u65b0\u7684\u63d0\u793a\u8bcd\u4ee5\u63a2\u67e5\u5176\u7279\u5f81\u5982\u4f55\u5f71\u54cd\u53cd\u5e94\u3002", "result": "\u53d1\u73b0\u5de5\u7a0b\u5e08\u901a\u8fc7\u81ea\u6211\u60c5\u7eea\u8c03\u8282\u7b56\u7565\uff08\u91cd\u65b0\u6846\u67b6\u3001\u5bf9\u8bdd\u8c03\u8282\u3001\u56de\u907f\u3001\u9632\u5fa1\uff09\u7ba1\u7406\u8d1f\u9762\u53cd\u9988\u60c5\u7eea\uff0c\u53c2\u4e0e\u901a\u8fc7\u793e\u4f1a\u6821\u51c6\u9002\u5e94\u56e2\u961f\u89c4\u8303\u3002\u4e0e\u540c\u4f34\u5ba1\u67e5\u76f8\u6bd4\uff0cLLM\u8f85\u52a9\u5ba1\u67e5\u964d\u4f4e\u4e86\u60c5\u611f\u6210\u672c\u548c\u81ea\u6211\u8c03\u8282\u9700\u6c42\uff0c\u964d\u4f4e\u8ba4\u77e5\u8d1f\u8377\u5e76\u63d0\u9ad8\u53cd\u9988\u91c7\u7eb3\u503e\u5411\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6a21\u578b\uff0c\u8fde\u63a5\u60c5\u7eea\u81ea\u6211\u8c03\u8282\u3001\u884c\u4e3a\u53c2\u4e0e\u548c\u95ee\u9898\u89e3\u51b3\uff0c\u5c55\u793a\u60c5\u611f\u548c\u8ba4\u77e5\u8fc7\u7a0b\u5982\u4f55\u5f71\u54cd\u540c\u4f34\u548cLLM\u8f85\u52a9\u4ee3\u7801\u5ba1\u67e5\u4e2d\u7684\u53cd\u9988\u91c7\u7eb3\uff0c\u8ba4\u4e3aAI\u5e94\u4f5c\u4e3a\u652f\u6301\u4f19\u4f34\uff0c\u51cf\u5c11\u8ba4\u77e5\u53ca\u60c5\u7eea\u8d1f\u62c5\uff0c\u540c\u65f6\u4fdd\u6301\u4eba\u7c7b\u8d23\u4efb\u548c\u793e\u4ea4\u610f\u4e49\u3002"}}
{"id": "2512.05231", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05231", "abs": "https://arxiv.org/abs/2512.05231", "authors": ["Gili Goldin", "Ella Rabinovich", "Shuly Wintner"], "title": "Unveiling Affective Polarization Trends in Parliamentary Proceedings", "comment": "pre-MIT Press publication version", "summary": "Recent years have seen an increase in polarized discourse worldwide, on various platforms. We propose a novel method for quantifying polarization, based on the emotional style of the discourse rather than on differences in ideological stands. Using measures of Valence, Arousal and Dominance, we detect signals of emotional discourse and use them to operationalize the concept of affective polarization. Applying this method to a recently released corpus of proceedings of the Knesset, the Israeli parliament (in Hebrew), we find that the emotional style of members of government differs from that of opposition members; and that the level of affective polarization, as reflected by this style, is significantly increasing with time.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65b0\u9896\u7684\u57fa\u4e8e\u60c5\u611f\u98ce\u683c\u7684\u4e24\u6781\u5316\u91cf\u5316\u65b9\u6cd5\uff0c\u5b9e\u8bc1\u663e\u793a\u4ee5\u8272\u5217\u8bae\u4f1a\u7684\u60c5\u611f\u4e24\u6781\u5316\u6b63\u5728\u52a0\u5267\u3002", "motivation": "\u9488\u5bf9\u5168\u7403\u8303\u56f4\u5185\u65e5\u76ca\u589e\u52a0\u7684\u6781\u5316\u8bdd\u8bed\uff0c\u63d0\u51fa\u4e0d\u540c\u4e8e\u4f20\u7edf\u610f\u8bc6\u5f62\u6001\u5dee\u5f02\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u60c5\u611f\u98ce\u683c\u6765\u8861\u91cf\u4e24\u6781\u5206\u5316\u3002", "method": "\u57fa\u4e8e\u60c5\u611f\u98ce\u683c\u7684\u4e24\u6781\u5316\u91cf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8861\u91cf\u60c5\u7eea\u7684\u4ef7\uff08Valence\uff09\u3001\u5524\u9192\u5ea6\uff08Arousal\uff09\u548c\u652f\u914d\u611f\uff08Dominance\uff09\u6765\u68c0\u6d4b\u60c5\u611f\u8bdd\u8bed\u4fe1\u53f7\u3002", "result": "\u4ee5\u4ee5\u8272\u5217\u8bae\u4f1aKnesset\u7684\u8bae\u4e8b\u8bb0\u5f55\u4e3a\u6570\u636e\uff0c\u53d1\u73b0\u6267\u653f\u515a\u6210\u5458\u4e0e\u53cd\u5bf9\u515a\u6210\u5458\u5728\u60c5\u611f\u98ce\u683c\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u60c5\u611f\u4e24\u6781\u5316\u6c34\u5e73\u968f\u65f6\u95f4\u663e\u8457\u589e\u52a0\u3002", "conclusion": "\u60c5\u611f\u98ce\u683c\u80fd\u591f\u6709\u6548\u53cd\u6620\u653f\u6cbb\u8bdd\u8bed\u7684\u4e24\u6781\u5316\uff0c\u4e14\u8fd9\u79cd\u57fa\u4e8e\u60c5\u7eea\u7684\u4e24\u6781\u5316\u5728\u5b9e\u9645\u653f\u6cbb discourse \u4e2d\u6709\u663e\u8457\u4e0a\u5347\u8d8b\u52bf\u3002"}}
{"id": "2512.05314", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05314", "abs": "https://arxiv.org/abs/2512.05314", "authors": ["Ke Mao", "Timotej Kapus", "Cons T \u00c5hs", "Matteo Marescotti", "Daniel Ip", "\u00c1kos Hajdu", "Sopot Cela", "Aparup Banerjee"], "title": "WhatsCode: Large-Scale GenAI Deployment for Developer Efficiency at WhatsApp", "comment": "11 pages, 4 figures, 48th International Conference on Software Engineering: Software Engineering in Practice", "summary": "The deployment of AI-assisted development tools in compliance-relevant, large-scale industrial environments represents significant gaps in academic literature, despite growing industry adoption. We report on the industrial deployment of WhatsCode, a domain-specific AI development system that supports WhatsApp (serving over 2 billion users) and processes millions of lines of code across multiple platforms. Over 25 months (2023-2025), WhatsCode evolved from targeted privacy automation to autonomous agentic workflows integrated with end-to-end feature development and DevOps processes.\n  WhatsCode achieved substantial quantifiable impact, improving automated privacy verification coverage 3.5x from 15% to 53%, identifying privacy requirements, and generating over 3,000 accepted code changes with acceptance rates ranging from 9% to 100% across different automation domains. The system committed 692 automated refactor/fix changes, 711 framework adoptions, 141 feature development assists and maintained 86% precision in bug triage. Our study identifies two stable human-AI collaboration patterns that emerged from production deployment: one-click rollout for high-confidence changes (60% of cases) and commandeer-revise for complex decisions (40%). We demonstrate that organizational factors, such as ownership models, adoption dynamics, and risk management, are as decisive as technical capabilities for enterprise-scale AI success. The findings provide evidence-based guidance for large-scale AI tool deployment in compliance-relevant environments, showing that effective human-AI collaboration, not full automation, drives sustainable business impact.", "AI": {"tldr": "\u8be5\u8bba\u6587\u62a5\u544a\u4e86WhatsCode\u2014\u2014\u4e00\u4e2a\u652f\u6301WhatsApp\u7684\u9886\u57df\u7279\u5b9aAI\u5f00\u53d1\u7cfb\u7edf\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u4e0e\u6f14\u8fdb\uff0c\u63d0\u5347\u4e86\u9690\u79c1\u81ea\u52a8\u5316\u8986\u76d6\u7387\u548c\u4ee3\u7801\u53d8\u66f4\u63a5\u53d7\u7387\uff0c\u5b9e\u73b0\u4eba\u4e0eAI\u7684\u9ad8\u6548\u534f\u4f5c\u3002", "motivation": "\u5c3d\u7ba1\u5de5\u4e1a\u754cAI\u8f85\u52a9\u5f00\u53d1\u5de5\u5177\u91c7\u7528\u4e0d\u65ad\u589e\u957f\uff0c\u5b66\u672f\u754c\u7f3a\u5c11\u5173\u4e8e\u5408\u89c4\u6027\u5927\u89c4\u6a21\u5de5\u4e1a\u73af\u5883\u90e8\u7f72\u7684\u7814\u7a76\uff0c\u4e9f\u9700\u63a2\u7d22\u548c\u603b\u7ed3\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7ecf\u9a8c\u4e0e\u6a21\u5f0f\u3002", "method": "\u901a\u8fc7\u5728WhatsApp\u73af\u5883\u4e2d\u6301\u7eed25\u4e2a\u6708\u7684\u5b9e\u9645\u90e8\u7f72\u548c\u6570\u636e\u6536\u96c6\uff0c\u5206\u6790\u9690\u79c1\u9a8c\u8bc1\u8986\u76d6\u7387\u3001\u4ee3\u7801\u53d8\u66f4\u63a5\u53d7\u7387\u53ca\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\uff0c\u7ed3\u5408\u81ea\u52a8\u5316\u63a8\u8350\u548c\u4eba\u5de5\u590d\u6838\u7684\u5de5\u4f5c\u6d41\u7a0b\u3002", "result": "\u9690\u79c1\u81ea\u52a8\u5316\u9a8c\u8bc1\u8986\u76d6\u7387\u63d0\u9ad83.5\u500d\u81f353%\uff0c\u8d85\u8fc73000\u4e2a\u4ee3\u7801\u53d8\u66f4\u88ab\u63a5\u53d7\uff0c692\u6b21\u81ea\u52a8\u91cd\u6784\uff0c\u4fdd\u630186%\u7684\u7f3a\u9677\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u53d1\u73b0\u4e24\u79cd\u4e3b\u8981\u7684\u4eba\u673a\u534f\u4f5c\u6a21\u5f0f\uff0c\u5f3a\u8c03\u7ec4\u7ec7\u56e0\u7d20\u4e0e\u6280\u672f\u540c\u7b49\u91cd\u8981\u3002", "conclusion": "WhatsCode\u7684\u5de5\u4e1a\u90e8\u7f72\u8bc1\u660e\uff0c\u6280\u672f\u80fd\u529b\u4e0e\u7ec4\u7ec7\u56e0\u7d20\uff08\u5982\u6240\u6709\u6743\u6a21\u578b\u3001\u91c7\u7528\u52a8\u6001\u548c\u98ce\u9669\u7ba1\u7406\uff09\u5171\u9a71\u52a8AI\u5de5\u5177\u7684\u4f01\u4e1a\u6210\u529f\uff0c\u4e14\u6709\u6548\u7684\u4eba\u673a\u534f\u4f5c\u4f18\u4e8e\u5b8c\u5168\u81ea\u52a8\u5316\uff0c\u5e26\u6765\u53ef\u6301\u7eed\u4e1a\u52a1\u5f71\u54cd\u3002"}}
{"id": "2512.05243", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.05243", "abs": "https://arxiv.org/abs/2512.05243", "authors": ["P. D. Edgar", "Alia Hall"], "title": "Decoding the Black Box: Discerning AI Rhetorics About and Through Poetic Prompting", "comment": "Late-Breaking Paper accepted to IEEE SSCI 2025 NLP & Social Media Track as extended abstract and presented in Trondheim, Norway 17-20 March 2025 as Poster Presentation", "summary": "Prompt engineering has emerged as a useful way studying the algorithmic tendencies and biases of large language models. Meanwhile creatives and academics have leveraged LLMs to develop creative works and explore the boundaries of their writing capabilities through text generation and code. This study suggests that creative text prompting, specifically Poetry Prompt Patterns, may be a useful addition to the toolbox of the prompt engineer, and outlines the process by which this approach may be taken. Then, the paper uses poetic prompts to assess descriptions and evaluations of three models of a renowned poet and test the consequences of the willingness of models to adapt or rewrite original creative works for presumed audiences.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u8bd7\u6b4c\u63d0\u793a\u6a21\u5f0f\u4f5c\u4e3a\u63d0\u793a\u5de5\u7a0b\u7684\u65b0\u5de5\u5177\uff0c\u901a\u8fc7\u8bd7\u6b4c\u63d0\u793a\u8bc4\u4f30\u548c\u5206\u6790\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u539f\u521b\u521b\u4f5c\u7684\u9002\u5e94\u548c\u6539\u5199\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u8bd7\u6b4c\u63d0\u793a\u6a21\u5f0f\u5728\u63d0\u793a\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\uff0c\u5e2e\u52a9\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7b97\u6cd5\u504f\u89c1\u548c\u521b\u9020\u529b\u8fb9\u754c\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u8bd7\u6b4c\u63d0\u793a\u6a21\u5f0f\u8fdb\u884c\u521b\u610f\u6587\u672c\u63d0\u793a\uff0c\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u7684\u9002\u5e94\u6027\u548c\u503e\u5411\u3002", "result": "\u5229\u7528\u8bd7\u6b4c\u63d0\u793a\u5bf9\u4e09\u79cd\u77e5\u540d\u8bd7\u4eba\u6a21\u578b\u8fdb\u884c\u4e86\u63cf\u8ff0\u548c\u8bc4\u4f30\uff0c\u6d4b\u8bd5\u4e86\u6a21\u578b\u4e3a\u9884\u671f\u53d7\u4f17\u6539\u5199\u539f\u521b\u4f5c\u54c1\u7684\u80fd\u529b\u548c\u610f\u613f\u3002", "conclusion": "\u8bd7\u6b4c\u63d0\u793a\u6a21\u5f0f\u5728\u63d0\u793a\u5de5\u7a0b\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u53ef\u7528\u4e8e\u6df1\u5165\u7406\u89e3\u548c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u7684\u521b\u9020\u529b\u53ca\u5176\u8c03\u6574\u539f\u521b\u4f5c\u54c1\u7684\u80fd\u529b\u3002"}}
{"id": "2512.05350", "categories": ["cs.SE", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.05350", "abs": "https://arxiv.org/abs/2512.05350", "authors": ["Munazza Zaib", "Wei Wang", "Dulaji Hidellaarachchi", "Isma Farah Siddiqui"], "title": "Invisible Load: Uncovering the Challenges of Neurodivergent Women in Software Engineering", "comment": null, "summary": "Neurodivergent women in Software Engineering (SE) encounter distinctive challenges at the intersection of gender bias and neurological differences. To the best of our knowledge, no prior work in SE research has systematically examined this group, despite increasing recognition of neurodiversity in the workplace. Underdiagnosis, masking, and male-centric workplace cultures continue to exacerbate barriers that contribute to stress, burnout, and attrition. In response, we propose a hybrid methodological approach that integrates InclusiveMag's inclusivity framework with the GenderMag walkthrough process, tailored to the context of neurodivergent women in SE. The overarching design unfolds across three stages, scoping through literature review, deriving personas and analytic processes, and applying the method in collaborative workshops. We present a targeted literature review that synthesize challenges into cognitive, social, organizational, structural and career progression challenges neurodivergent women face in SE, including how under/late diagnosis and masking intensify exclusion. These findings lay the groundwork for subsequent stages that will develop and apply inclusive analytic methods to support actionable change.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u63a2\u8ba8\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u51fa\u57fa\u4e8eInclusiveMag\u548cGenderMag\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u65e8\u5728\u4fc3\u8fdb\u804c\u573a\u5305\u5bb9\u4e0e\u652f\u6301\u3002", "motivation": "\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u9762\u4e34\u6027\u522b\u504f\u89c1\u4e0e\u795e\u7ecf\u5dee\u5f02\u53e0\u52a0\u7684\u72ec\u7279\u6311\u6218\uff0c\u76ee\u524d\u8be5\u9886\u57df\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7814\u7a76\u6b64\u7fa4\u4f53\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408InclusiveMag\u5305\u5bb9\u6027\u6846\u67b6\u548cGenderMag\u6027\u522b\u8ba4\u77e5\u5206\u6790\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u3001\u7528\u6237\u753b\u50cf\u4e0e\u5206\u6790\u8fc7\u7a0b\u63a8\u5bfc\uff0c\u4ee5\u53ca\u534f\u4f5c\u5de5\u4f5c\u574a\u5e94\u7528\u4e09\u4e2a\u9636\u6bb5\u5c55\u5f00\u7814\u7a76\u3002", "result": "\u6587\u732e\u7efc\u8ff0\u603b\u7ed3\u4e86\u795e\u7ecf\u591a\u6837\u6027\u5973\u6027\u5728\u8ba4\u77e5\u3001\u793e\u4ea4\u3001\u7ec4\u7ec7\u7ed3\u6784\u3001\u804c\u4e1a\u53d1\u5c55\u7b49\u65b9\u9762\u9762\u4e34\u7684\u6311\u6218\uff0c\u7279\u522b\u6307\u51fa\u4e86\u8bca\u65ad\u4e0d\u8db3\u3001\u63a9\u9970\u884c\u4e3a\u52a0\u5267\u6392\u65a5\u3002", "conclusion": "\u7814\u7a76\u4e3a\u540e\u7eed\u9636\u6bb5\u53d1\u5c55\u548c\u5e94\u7528\u5305\u5bb9\u6027\u5206\u6790\u65b9\u6cd5\u4ee5\u652f\u6301\u5b9e\u9645\u53d8\u9769\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.05256", "categories": ["cs.CL", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.05256", "abs": "https://arxiv.org/abs/2512.05256", "authors": ["Ivan Makohon", "Mohamad Najafi", "Jian Wu", "Mathias Brochhausen", "Yaohang Li"], "title": "Enhancing Clinical Note Generation with ICD-10, Clinical Ontology Knowledge Graphs, and Chain-of-Thought Prompting Using GPT-4", "comment": null, "summary": "In the past decade a surge in the amount of electronic health record (EHR) data in the United States, attributed to a favorable policy environment created by the Health Information Technology for Economic and Clinical Health (HITECH) Act of 2009 and the 21st Century Cures Act of 2016. Clinical notes for patients' assessments, diagnoses, and treatments are captured in these EHRs in free-form text by physicians, who spend a considerable amount of time entering and editing them. Manually writing clinical notes takes a considerable amount of a doctor's valuable time, increasing the patient's waiting time and possibly delaying diagnoses. Large language models (LLMs) possess the ability to generate news articles that closely resemble human-written ones. We investigate the usage of Chain-of-Thought (CoT) prompt engineering to improve the LLM's response in clinical note generation. In our prompts, we use as input International Classification of Diseases (ICD) codes and basic patient information. We investigate a strategy that combines the traditional CoT with semantic search results to improve the quality of generated clinical notes. Additionally, we infuse a knowledge graph (KG) built from clinical ontology to further enrich the domain-specific knowledge of generated clinical notes. We test our prompting technique on six clinical cases from the CodiEsp test dataset using GPT-4 and our results show that it outperformed the clinical notes generated by standard one-shot prompts.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u63d0\u793a\u6280\u672f\u548c\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\uff0c\u5229\u7528GPT-4\u6210\u529f\u63d0\u5347\u4e86\u81ea\u52a8\u751f\u6210\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u4e34\u5e8a\u7b14\u8bb0\u7684\u6548\u679c\uff0c\u7f13\u89e3\u533b\u751f\u624b\u52a8\u4e66\u5199\u8d1f\u62c5\u3002", "motivation": "\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u81ea\u7531\u6587\u672c\u7684\u4e34\u5e8a\u7b14\u8bb0\u64b0\u5199\u8017\u65f6\u957f\uff0c\u5f71\u54cd\u533b\u751f\u5de5\u4f5c\u6548\u7387\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u9ad8\u8d28\u91cf\u751f\u6210\u4e34\u5e8a\u7b14\u8bb0\u7684\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u60a3\u8005\u57fa\u672c\u4fe1\u606f\u548cICD\u7f16\u7801\u4f5c\u4e3a\u8f93\u5165\uff0c\u7ed3\u5408CoT\u63d0\u793a\u548c\u8bed\u4e49\u641c\u7d22\u7ed3\u679c\uff0c\u5e76\u901a\u8fc7\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\u589e\u5f3a\u9886\u57df\u77e5\u8bc6\uff0c\u6307\u5bfcGPT-4\u751f\u6210\u4e34\u5e8a\u7b14\u8bb0\u3002", "result": "\u5728CodiEsp\u6d4b\u8bd5\u96c6\u7684\u516d\u4e2a\u4e34\u5e8a\u6848\u4f8b\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u751f\u6210\u7684\u4e34\u5e8a\u7b14\u8bb0\u8d28\u91cf\u660e\u663e\u4f18\u4e8e\u6807\u51c6\u7684\u4e00\u6b21\u6027\u63d0\u793a\u751f\u6210\u7ed3\u679c\u3002", "conclusion": "\u7ed3\u5408Chain-of-Thought\u63d0\u793a\u5de5\u7a0b\u3001\u8bed\u4e49\u641c\u7d22\u548c\u4e34\u5e8a\u77e5\u8bc6\u56fe\u8c31\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b(GPT-4)\u751f\u6210\u4e34\u5e8a\u7b14\u8bb0\u7684\u8d28\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edf\u5355\u6b65\u63d0\u793a\u65b9\u6cd5\u3002"}}
{"id": "2512.05358", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05358", "abs": "https://arxiv.org/abs/2512.05358", "authors": ["Chenlu Zhang", "Amirmohammad Pasdar", "Van-Thuan Pham"], "title": "BGPFuzz: Automated Configuration Fuzzing of the Border Gateway Protocol", "comment": "6 pages, 3 figures", "summary": "Telecommunications networks rely on configurations to define routing behavior, especially in the Border Gateway Protocol (BGP), where misconfigurations can lead to severe outages and security breaches, as demonstrated by the 2021 Facebook outage. Unlike existing approaches that rely on synthesis or verification, our work offers a cost-effective method for identifying misconfigurations resulting from BGP's inherent complexity or vendor-specific implementations. We present BGPFuzz, a structure-aware and stateful fuzzing framework that systematically mutates BGP configurations and evaluates their effects in virtualized network. Without requiring predefined correctness properties as in static analysis, BGPFuzz detects anomalies through runtime oracles that capture practical symptoms such as session resets, blackholing, and traffic redirection. Our experiments show that BGPFuzz can reliably reproduce and detect known failures, including max-prefix violations and sub-prefix hijacks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u611f\u77e5\u4e14\u6709\u72b6\u6001\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6BGPFuzz\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u53d8\u5f02BGP\u914d\u7f6e\u5e76\u5728\u865a\u62df\u7f51\u7edc\u4e2d\u8bc4\u4f30\u5176\u5f71\u54cd\uff0c\u4ee5\u68c0\u6d4bBGP\u914d\u7f6e\u9519\u8bef\u5f15\u53d1\u7684\u5f02\u5e38\u3002", "motivation": "BGP\u914d\u7f6e\u590d\u6742\u4e14\u5b58\u5728\u5382\u5546\u7279\u5b9a\u5b9e\u73b0\uff0c\u4f20\u7edf\u57fa\u4e8e\u7efc\u5408\u6216\u9a8c\u8bc1\u7684\u65b9\u6cd5\u6210\u672c\u8f83\u9ad8\uff0c\u9700\u4e00\u79cd\u66f4\u7ecf\u6d4e\u6709\u6548\u7684\u9519\u8bef\u8bc6\u522b\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7ed3\u6784\u611f\u77e5\u4e14\u6709\u72b6\u6001\u7684\u6a21\u7cca\u6d4b\u8bd5\u6846\u67b6BGPFuzz\uff0c\u7cfb\u7edf\u53d8\u5f02BGP\u914d\u7f6e\u5e76\u901a\u8fc7\u8fd0\u884c\u65f6\u68c0\u6d4b\u5668\u6355\u6349\u4f1a\u8bdd\u91cd\u7f6e\u3001\u9ed1\u6d1e\u6d41\u91cf\u548c\u6d41\u91cf\u91cd\u5b9a\u5411\u7b49\u5f02\u5e38\u3002", "result": "\u5b9e\u9a8c\u8868\u660eBGPFuzz\u53ef\u4ee5\u53ef\u9760\u5730\u68c0\u6d4b\u5df2\u77e5\u7684BGP\u9519\u8bef\u6848\u4f8b\uff0c\u5305\u62ec\u6700\u5927\u524d\u7f00\u9650\u5236\u8fdd\u89c4\u548c\u5b50\u524d\u7f00\u52ab\u6301\u3002", "conclusion": "BGPFuzz\u80fd\u591f\u53ef\u9760\u5730\u590d\u73b0\u548c\u68c0\u6d4b\u5305\u62ec\u6700\u5927\u524d\u7f00\u8fdd\u89c4\u548c\u5b50\u524d\u7f00\u52ab\u6301\u5728\u5185\u7684\u5df2\u77e5BGP\u914d\u7f6e\u9519\u8bef\uff0c\u6548\u679c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2512.05318", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05318", "abs": "https://arxiv.org/abs/2512.05318", "authors": ["Vignesh Kothapalli", "Ata Fatahibaarzi", "Hamed Firooz", "Maziar Sanjabi"], "title": "To Think or Not to Think: The Hidden Cost of Meta-Training with Excessive CoT Examples", "comment": "26 pages, 45 figures, 3 tables", "summary": "Chain-of-thought (CoT) prompting combined with few-shot in-context learning (ICL) has unlocked significant reasoning capabilities in large language models (LLMs). However, ICL with CoT examples is ineffective on novel tasks when the pre-training knowledge is insufficient. We study this problem in a controlled setting using the CoT-ICL Lab framework, and propose meta-training techniques to learn novel abstract reasoning tasks in-context. Although CoT examples facilitate reasoning, we noticed that their excessive inclusion during meta-training degrades performance when CoT supervision is limited. To mitigate such behavior, we propose CoT-Recipe, a formal approach to modulate the mix of CoT and non-CoT examples in meta-training sequences. We demonstrate that careful modulation via CoT-Recipe can increase the accuracy of transformers on novel tasks by up to 300% even when there are no CoT examples available in-context. We confirm the broader effectiveness of these techniques by applying them to pretrained LLMs (Qwen2.5 series) for symbolic reasoning tasks and observing gains of up to 130% in accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CoT-Recipe\uff0c\u901a\u8fc7\u8c03\u8282\u5143\u8bad\u7ec3\u4e2d\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u793a\u4f8b\u7684\u6bd4\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u5927\u6a21\u578b\u5728\u65b0\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5373\u4f7f\u7f3a\u5c11CoT\u793a\u4f8b\u4e5f\u80fd\u53d6\u5f97\u9ad8\u6548\u8868\u73b0\u3002", "motivation": "CoT\u7ed3\u5408ICL\u867d\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5728\u7f3a\u4e4f\u9884\u8bad\u7ec3\u77e5\u8bc6\u7684\u65b0\u4efb\u52a1\u4e0a\u6548\u679c\u4e0d\u4f73\uff0c\u4e14\u8fc7\u591aCoT\u793a\u4f8b\u53cd\u800c\u964d\u4f4e\u6709\u9650CoT\u76d1\u7763\u4e0b\u7684\u6027\u80fd\u3002", "method": "\u5728\u4e00\u4e2a\u53d7\u63a7\u73af\u5883\u4e0b\u4f7f\u7528CoT-ICL Lab\u6846\u67b6\uff0c\u5bf9\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\uff08CoT\uff09\u7ed3\u5408\u5c11\u91cf\u793a\u4f8b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u8fdb\u884c\u5143\u8bad\u7ec3\uff0c\u63d0\u51faCoT-Recipe\u65b9\u6cd5\u6765\u8c03\u8282\u5143\u8bad\u7ec3\u4e2dCoT\u4e0e\u975eCoT\u793a\u4f8b\u7684\u6bd4\u4f8b\u3002", "result": "\u901a\u8fc7CoT-Recipe\u8c03\u8282CoT\u4e0e\u975eCoT\u793a\u4f8b\u6df7\u5408\uff0c\u4f7f\u53d8\u6362\u5668\u6a21\u578b\u5728\u65b0\u4efb\u52a1\u4e0a\u51c6\u786e\u5ea6\u63d0\u5347\u6700\u591a300%\uff0c\u5728\u6ca1\u6709CoT\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u4ecd\u6709\u663e\u8457\u63d0\u5347\uff0c\u5e76\u5728\u9884\u8bad\u7ec3\u7684Qwen2.5\u7cfb\u5217\u8bed\u8a00\u6a21\u578b\u7684\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u83b7\u5f97\u6700\u9ad8130%\u7684\u51c6\u786e\u7387\u589e\u76ca\u3002", "conclusion": "\u9002\u5f53\u8c03\u8282CoT\u4e0e\u975eCoT\u793a\u4f8b\u5728\u5143\u8bad\u7ec3\u4e2d\u7684\u6bd4\u4f8b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65b0\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86CoT-Recipe\u65b9\u6cd5\u7684\u5e7f\u6cdb\u9002\u7528\u6027\u548c\u6548\u679c\u3002"}}
{"id": "2512.05375", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05375", "abs": "https://arxiv.org/abs/2512.05375", "authors": ["Sunil Khemka", "Arunava Majumdar"], "title": "Legacy Modernization with AI -- Mainframe modernization", "comment": "Accepted for publication at International Conference on Innovations and Trends in Advanced Engineering Technologies (ICIAET 2025) held on 25th and 26th November 2025", "summary": "Artificial Intelligence-assisted legacy modernization is essential in changing the stalwart mainframe systems of the past into flexible, scalable, and smart architecture. While mainframes are generally dependable, they can be difficult to maintain due to their high maintenance costs, the shortage of skills, and the problems in integrating them with cloud-based systems. By adopting AI-driven modernization strategies such as automated code refactoring, migration of data using smart tools, and predictive maintenance, companies can easily move to microservices, containerized environments, and hybrid cloud platforms. Machine learning models have the capability to go through legacy codebases, figure out efficiency opportunities, and carry out automated testing and deployment. Besides that, AI improves the organization's operational efficiency by generating the insights that can be used to level the workload and detect the anomalies. The coupling of the two is not only about saving the core business logic but also about enabling quicker innovation, less downtime, and enhanced system resilience. Therefore, the use of AI in mainframe modernization is a catalyst for digital transformation and enterprise growth that is sustainable over time.", "AI": {"tldr": "AI\u8f85\u52a9\u4f20\u7edf\u4e3b\u673a\u7cfb\u7edf\u73b0\u4ee3\u5316\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u667a\u80fd\u6280\u672f\u63d0\u5347\u6548\u7387\u4e0e\u7075\u6d3b\u6027\uff0c\u63a8\u52a8\u6570\u5b57\u8f6c\u578b\u3002", "motivation": "\u4f20\u7edf\u4e3b\u673a\u7cfb\u7edf\u7ef4\u62a4\u6210\u672c\u9ad8\u3001\u6280\u80fd\u77ed\u7f3a\u4e14\u96be\u4ee5\u4e0e\u4e91\u7cfb\u7edf\u96c6\u6210\uff0c\u9700\u5f15\u5165AI\u6280\u672f\u5b9e\u73b0\u7075\u6d3b\u3001\u53ef\u6269\u5c55\u4e14\u667a\u80fd\u7684\u67b6\u6784\u53d8\u9769\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u4ee3\u7801\u91cd\u6784\u3001\u667a\u80fd\u6570\u636e\u8fc1\u79fb\u3001\u9884\u6d4b\u6027\u7ef4\u62a4\u548c\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u4ee3\u7801\u5206\u6790\u53ca\u81ea\u52a8\u5316\u6d4b\u8bd5\u90e8\u7f72\u3002", "result": "\u672c\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u4f20\u7edf\u4e3b\u673a\u7cfb\u7edf\u73b0\u4ee3\u5316\u7684\u91cd\u8981\u6027\u4e0e\u65b9\u6cd5\u3002\u901a\u8fc7\u5f15\u5165\u81ea\u52a8\u4ee3\u7801\u91cd\u6784\u3001\u667a\u80fd\u6570\u636e\u8fc1\u79fb\u548c\u9884\u6d4b\u6027\u7ef4\u62a4\u7b49AI\u9a71\u52a8\u7b56\u7565\uff0c\u5b9e\u73b0\u5411\u5fae\u670d\u52a1\u3001\u5bb9\u5668\u5316\u53ca\u6df7\u5408\u4e91\u5e73\u53f0\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002\u673a\u5668\u5b66\u4e60\u6a21\u578b\u80fd\u5206\u6790\u9057\u7559\u4ee3\u7801\uff0c\u53d1\u73b0\u4f18\u5316\u7a7a\u95f4\u5e76\u81ea\u52a8\u6267\u884c\u6d4b\u8bd5\u548c\u90e8\u7f72\u3002\u540c\u65f6\uff0cAI\u63d0\u5347\u8fd0\u8425\u6548\u7387\uff0c\u901a\u8fc7\u8d1f\u8f7d\u5747\u8861\u548c\u5f02\u5e38\u68c0\u6d4b\u4fdd\u969c\u7cfb\u7edf\u7a33\u5b9a\u6027\u3002AI\u4e0e\u4e3b\u673a\u73b0\u4ee3\u5316\u7ed3\u5408\u4e0d\u4ec5\u4fdd\u62a4\u6838\u5fc3\u4e1a\u52a1\u903b\u8f91\uff0c\u8fd8\u63a8\u52a8\u66f4\u5feb\u521b\u65b0\u3001\u51cf\u5c11\u505c\u673a\u65f6\u95f4\u3001\u589e\u5f3a\u7cfb\u7edf\u97e7\u6027\uff0c\u6210\u4e3a\u6570\u5b57\u5316\u8f6c\u578b\u548c\u4f01\u4e1a\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u50ac\u5316\u5242\u3002", "conclusion": "AI\u5728\u4e3b\u673a\u73b0\u4ee3\u5316\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\uff0c\u4fc3\u8fdb\u4f01\u4e1a\u6570\u5b57\u5316\u8f6c\u578b\uff0c\u5b9e\u73b0\u7cfb\u7edf\u7075\u6d3b\u6027\u3001\u521b\u65b0\u529b\u548c\u6301\u7eed\u589e\u957f\u3002"}}
{"id": "2512.05325", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05325", "abs": "https://arxiv.org/abs/2512.05325", "authors": ["\u00d6mer Faruk Akg\u00fcl", "Yusuf Hakan Kalayc\u0131", "Rajgopal Kannan", "Willie Neiswanger", "Viktor Prasanna"], "title": "LYNX: Learning Dynamic Exits for Confidence-Controlled Reasoning", "comment": null, "summary": "Large reasoning models achieve strong performance on complex tasks by generating extended chains of thought, but they often \"overthink\": continuing to reason long after they have enough information to answer correctly. This wastes inference-time compute and can hurt accuracy. Existing attempts to stop early either manipulate decoding with extra sampling and heuristics, rely on auxiliary verifier models, or operate only as post-hoc analysis pipelines without formal guarantees. We introduce LYNX, an online early-exit mechanism that turns a model's own hidden-state awareness into confidence-controlled stopping decisions. LYNX attaches exit decisions to naturally occurring reasoning cues (e.g., \"hmm\", \"wait\") during generation, trains a lightweight probe on hidden states at those cue tokens using supervision from forced exits, and wraps the resulting scores in split conformal prediction to obtain distribution-free control over premature exits. Crucially, we train and calibrate this probe once on a generic mathematical corpus and reuse it unchanged across benchmarks, decoding temperatures, and even non-mathematical tasks. Across three model families spanning 1.5B to 32B parameters, a single mathematically trained probe per base model yields strong accuracy--efficiency tradeoffs. On GSM8K, LYNX matches or improves baseline accuracy while reducing tokens by 40--65\\%; on MATH-500 it improves accuracy by up to 12 points with roughly 35--60\\% fewer tokens; on AIME 2024 it recovers baseline accuracy with more than 50\\% token savings; and on CommonsenseQA, a non-math benchmark, it transfers zero-shot with modest accuracy gains and up to 70\\% fewer tokens. Compared to state-of-the-art early-exit methods, LYNX offers competitive or superior Pareto frontiers while remaining fully online, requiring no proxy models at inference, and providing explicit, user-tunable confidence guarantees.", "AI": {"tldr": "LYNX\u662f\u4e00\u79cd\u5229\u7528\u6a21\u578b\u9690\u85cf\u6001\u81ea\u4fe1\u5ea6\u5b9e\u73b0\u5728\u7ebf\u65e9\u671f\u9000\u51fa\u7684\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u63a8\u7406\u8ba1\u7b97\uff0c\u63d0\u5347\u6548\u7387\u548c\u51c6\u786e\u5ea6\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u80fd\u529b\u3002\u5b83\u65e0\u9700\u8f85\u52a9\u6a21\u578b\uff0c\u63d0\u4f9b\u660e\u786e\u5b9a\u5236\u7684\u7f6e\u4fe1\u5ea6\u4fdd\u8bc1\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u4e3a\u4e86\u5b8c\u6210\u590d\u6742\u4efb\u52a1\u5e38\u5e38\u8fdb\u884c\u8fc7\u5ea6\u63a8\u7406\uff08\"overthink\"\uff09\uff0c\u5bfc\u81f4\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\u548c\u51c6\u786e\u6027\u4e0b\u964d\u3002\u73b0\u6709\u65e9\u671f\u9000\u51fa\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u989d\u5916\u6a21\u578b\u3001\u7ecf\u9a8c\u6027\u542f\u53d1\u5f0f\u6216\u7f3a\u4e4f\u5f62\u5f0f\u4fdd\u8bc1\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u63a7\u4e14\u65e0\u9700\u8f85\u52a9\u6a21\u578b\u7684\u65e9\u671f\u9000\u51fa\u7b56\u7565\u3002", "method": "LYNX\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u68c0\u6d4b\u81ea\u7136\u51fa\u73b0\u7684\u63a8\u7406\u63d0\u793a\u8bcd\uff08\u5982\u201chmm\u201d\u3001\u201cwait\u201d\uff09\uff0c\u5e76\u8bad\u7ec3\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u63a2\u9488\u6765\u5224\u65ad\u4f55\u65f6\u53ef\u4ee5\u505c\u6b62\u63a8\u7406\u3002\u901a\u8fc7\u4f7f\u7528\u5206\u5272\u7b26\u5408\u9884\u6d4b\uff08split conformal prediction\uff09\u6765\u63a7\u5236\u63d0\u524d\u9000\u51fa\uff0c\u786e\u4fdd\u9000\u51fa\u51b3\u7b56\u7684\u7f6e\u4fe1\u5ea6\u3002\u540c\u65f6\u8be5\u63a2\u9488\u5728\u6570\u5b66\u8bed\u6599\u4e0a\u8bad\u7ec3\u4e00\u6b21\u540e\u5373\u53ef\u5e94\u7528\u4e8e\u4e0d\u540c\u4efb\u52a1\uff0c\u65e0\u9700\u989d\u5916\u8f85\u52a9\u6a21\u578b\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u6a21\u578b\u548c\u591a\u79cd\u57fa\u51c6\u4efb\u52a1\uff08\u6570\u5b66\u9898\u548c\u5e38\u8bc6\u95ee\u7b54\uff09\u4e0a\uff0cLYNX\u5b9e\u73b0\u4e8640%-70%\u7684\u63a8\u7406token\u51cf\u5c11\uff0c\u540c\u65f6\u51c6\u786e\u7387\u4fdd\u6301\u4e0d\u964d\u751a\u81f3\u63d0\u5347\u3002\u5b83\u5728\u6570\u5b66\u53ca\u975e\u6570\u5b66\u4efb\u52a1\u5747\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u51c6\u786e\u7387-\u6548\u7387\u6743\u8861\uff0c\u4f18\u4e8e\u73b0\u6709\u65e9\u671f\u9000\u51fa\u65b9\u6cd5\uff0c\u5e76\u4e14\u80fd\u5728\u7ebf\u8fd0\u884c\uff0c\u65e0\u9700\u540e\u671f\u5904\u7406\u3002", "conclusion": "LYNX\u901a\u8fc7\u5229\u7528\u6a21\u578b\u81ea\u8eab\u7684\u9690\u85cf\u72b6\u6001\uff0c\u5b9e\u73b0\u4e86\u4e00\u79cd\u5728\u7ebf\u65e9\u671f\u9000\u51fa\u673a\u5236\uff0c\u6709\u6548\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\u3002\u8be5\u65b9\u6cd5\u5177\u6709\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u8de8\u591a\u79cd\u4efb\u52a1\u548c\u6a21\u578b\u7a33\u5b9a\u53d1\u6325\u6548\u679c\u3002"}}
{"id": "2512.05383", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05383", "abs": "https://arxiv.org/abs/2512.05383", "authors": ["Mara Downing", "Matthew Peng", "Jacob Granley", "Michael Beyeler", "Tevfik Bultan"], "title": "Fuzzing the brain: Automated stress testing for the safety of ML-driven neurostimulation", "comment": "20 pages, 4 figures, 2 tables", "summary": "Objective: Machine learning (ML) models are increasingly used to generate electrical stimulation patterns in neuroprosthetic devices such as visual prostheses. While these models promise precise and personalized control, they also introduce new safety risks when model outputs are delivered directly to neural tissue. We propose a systematic, quantitative approach to detect and characterize unsafe stimulation patterns in ML-driven neurostimulation systems. Approach: We adapt an automated software testing technique known as coverage-guided fuzzing to the domain of neural stimulation. Here, fuzzing performs stress testing by perturbing model inputs and tracking whether resulting stimulation violates biophysical limits on charge density, instantaneous current, or electrode co-activation. The framework treats encoders as black boxes and steers exploration with coverage metrics that quantify how broadly test cases span the space of possible outputs and violation types. Main results: Applied to deep stimulus encoders for the retina and cortex, the method systematically reveals diverse stimulation regimes that exceed established safety limits. Two violation-output coverage metrics identify the highest number and diversity of unsafe outputs, enabling interpretable comparisons across architectures and training strategies. Significance: Violation-focused fuzzing reframes safety assessment as an empirical, reproducible process. By transforming safety from a training heuristic into a measurable property of the deployed model, it establishes a foundation for evidence-based benchmarking, regulatory readiness, and ethical assurance in next-generation neural interfaces.", "AI": {"tldr": "\u901a\u8fc7\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7cfb\u7edf\u68c0\u6d4b\u795e\u7ecf\u523a\u6fc0\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u53d1\u73b0\u5e76\u91cf\u5316\u591a\u79cd\u4e0d\u5b89\u5168\u523a\u6fc0\u6a21\u5f0f\uff0c\u5b9e\u73b0\u5b89\u5168\u8bc4\u4f30\u6807\u51c6\u5316\u548c\u91cf\u5316\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u795e\u7ecf\u5047\u4f53\u8bbe\u5907\u4e2d\u5e94\u7528\uff0c\u867d\u7136\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u63a7\u5236\u7cbe\u5ea6\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u98ce\u9669\uff0c\u4e9f\u9700\u4e00\u79cd\u7cfb\u7edf\u5316\u3001\u91cf\u5316\u7684\u5b89\u5168\u68c0\u6d4b\u65b9\u6cd5\u4ee5\u786e\u4fdd\u6a21\u578b\u8f93\u51fa\u7684\u795e\u7ecf\u523a\u6fc0\u5b89\u5168\u3002", "method": "\u91c7\u7528\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u6280\u672f\uff0c\u901a\u8fc7\u6270\u52a8\u6a21\u578b\u8f93\u5165\u5e76\u57fa\u4e8e\u751f\u7269\u7269\u7406\u5b89\u5168\u9650\u5236\u5bf9\u8f93\u51fa\u523a\u6fc0\u8fdb\u884c\u68c0\u6d4b\uff0c\u5229\u7528\u8986\u76d6\u5ea6\u6307\u6807\u5f15\u5bfc\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\uff0c\u8986\u76d6\u66f4\u591a\u8f93\u51fa\u7a7a\u95f4\u548c\u8fdd\u89c4\u7c7b\u578b\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u7684\u65b9\u6cd5\uff0c\u7cfb\u7edf\u68c0\u6d4b\u548c\u8868\u5f81\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u795e\u7ecf\u523a\u6fc0\u7cfb\u7edf\u4e2d\u7684\u4e0d\u5b89\u5168\u7535\u523a\u6fc0\u6a21\u5f0f\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6270\u52a8\u6a21\u578b\u8f93\u5165\uff0c\u68c0\u6d4b\u8f93\u51fa\u523a\u6fc0\u662f\u5426\u8d85\u51fa\u751f\u7269\u7269\u7406\u5b89\u5168\u8303\u56f4\uff0c\u5982\u7535\u8377\u5bc6\u5ea6\u3001\u7535\u6d41\u77ac\u65f6\u503c\u6216\u7535\u6781\u5171\u540c\u6fc0\u6d3b\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u53d1\u73b0\u89c6\u7f51\u819c\u548c\u5927\u8111\u76ae\u5c42\u6df1\u5ea6\u523a\u6fc0\u7f16\u7801\u5668\u591a\u4e2a\u8fdd\u53cd\u5b89\u5168\u9650\u5236\u7684\u523a\u6fc0\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u4e24\u4e2a\u8986\u76d6\u5ea6\u6307\u6807\u8861\u91cf\u8fdd\u89c4\u8f93\u51fa\u7684\u6570\u91cf\u4e0e\u591a\u6837\u6027\uff0c\u5b9e\u73b0\u6a21\u578b\u67b6\u6784\u548c\u8bad\u7ec3\u7b56\u7565\u7684\u53ef\u89e3\u91ca\u6bd4\u8f83\u3002\u7ed3\u8bba\u662f\u5c06\u5b89\u5168\u6027\u8bc4\u4f30\u8f6c\u53d8\u4e3a\u53ef\u91cf\u5316\u3001\u53ef\u91cd\u590d\u7684\u5b9e\u8bc1\u8fc7\u7a0b\uff0c\u4e3a\u795e\u7ecf\u63a5\u53e3\u8bbe\u5907\u7684\u57fa\u4e8e\u8bc1\u636e\u7684\u57fa\u51c6\u6d4b\u8bd5\u3001\u6cd5\u89c4\u5408\u89c4\u548c\u4f26\u7406\u4fdd\u969c\u5960\u5b9a\u4e86\u57fa\u7840\u3002", "conclusion": "\u8986\u76d6\u5f15\u5bfc\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u6709\u6548\u8bc6\u522b\u548c\u91cf\u5316\u795e\u7ecf\u523a\u6fc0\u6a21\u578b\u7684\u4e0d\u5b89\u5168\u8f93\u51fa\uff0c\u63a8\u52a8\u5b89\u5168\u8bc4\u4f30\u4ece\u7ecf\u9a8c\u6027\u8f6c\u5411\u5b9e\u8bc1\u53ef\u91cf\u5316\uff0c\u4e3a\u795e\u7ecf\u63a5\u53e3\u7684\u89c4\u8303\u548c\u4f26\u7406\u4fdd\u969c\u63d0\u4f9b\u652f\u6491\u3002"}}
{"id": "2512.05331", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05331", "abs": "https://arxiv.org/abs/2512.05331", "authors": ["Sadat Shahriar", "Navid Ayoobi", "Arjun Mukherjee", "Mostafa Musharrat", "Sai Vishnu Vamsi"], "title": "Exposing Pink Slime Journalism: Linguistic Signatures and Robust Detection Against LLM-Generated Threats", "comment": "Published in RANLP 2025", "summary": "The local news landscape, a vital source of reliable information for 28 million Americans, faces a growing threat from Pink Slime Journalism, a low-quality, auto-generated articles that mimic legitimate local reporting. Detecting these deceptive articles requires a fine-grained analysis of their linguistic, stylistic, and lexical characteristics. In this work, we conduct a comprehensive study to uncover the distinguishing patterns of Pink Slime content and propose detection strategies based on these insights. Beyond traditional generation methods, we highlight a new adversarial vector: modifications through large language models (LLMs). Our findings reveal that even consumer-accessible LLMs can significantly undermine existing detection systems, reducing their performance by up to 40% in F1-score. To counter this threat, we introduce a robust learning framework specifically designed to resist LLM-based adversarial attacks and adapt to the evolving landscape of automated pink slime journalism, and showed and improvement by up to 27%.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f4e\u8d28\u91cf\u81ea\u52a8\u751f\u6210\u7684\u201c\u7c89\u8089\u65b0\u95fb\u201d\u5bf9\u5730\u65b9\u65b0\u95fb\u7684\u5a01\u80c1\uff0c\u5206\u6790\u5176\u8bed\u8a00\u548c\u98ce\u683c\u7279\u5f81\uff0c\u63d0\u51fa\u68c0\u6d4b\u7b56\u7565\uff0c\u5e76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u653b\u51fb\u6311\u6218\uff0c\u8bbe\u8ba1\u4e86\u6297\u653b\u51fb\u7684\u9c81\u68d2\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u5730\u65b9\u65b0\u95fb\u662f\u91cd\u8981\u53ef\u9760\u4fe1\u606f\u6e90\uff0c\u4f46\u906d\u53d7\u4f4e\u8d28\u91cf\u81ea\u52a8\u751f\u6210\u65b0\u95fb\u7684\u5a01\u80c1\uff0c\u5c24\u5176\u662f\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6539\u5199\u5185\u5bb9\u3002\u9700\u8981\u65b0\u7684\u68c0\u6d4b\u4e0e\u9632\u62a4\u65b9\u6cd5\u4fdd\u969c\u65b0\u95fb\u771f\u5b9e\u6027\u3002", "method": "\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u8bed\u8a00\u3001\u98ce\u683c\u548c\u8bcd\u6c47\u7279\u5f81\u5206\u6790\uff0c\u7ed3\u5408\u9c81\u68d2\u5b66\u4e60\u6846\u67b6\uff0c\u589e\u5f3a\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u81ea\u52a8\u751f\u6210\u65b0\u95fb\u53ca\u5176\u5bf9\u6297\u6837\u672c\u7684\u8bc6\u522b\u80fd\u529b\u3002", "result": "\u63d0\u51fa\u7684\u9c81\u68d2\u5b66\u4e60\u6846\u67b6\u5728\u62b5\u5fa1\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u6297\u653b\u51fb\u65f6\uff0c\u68c0\u6d4b\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe27%\uff0c\u6709\u6548\u7f13\u89e3\u73b0\u6709\u7cfb\u7edf40%\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "conclusion": "\u901a\u8fc7\u5bf9\u2018\u7c89\u8089\u65b0\u95fb\u2019\u7684\u7279\u5f81\u5206\u6790\u548c\u68c0\u6d4b\u65b9\u6cd5\u8bbe\u8ba1\uff0c\u672c\u6587\u6210\u529f\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u5e76\u6709\u6548\u62b5\u5fa1\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u5bf9\u6297\u6027\u653b\u51fb\u3002"}}
{"id": "2512.05428", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05428", "abs": "https://arxiv.org/abs/2512.05428", "authors": ["Keeryn Johnson", "Cleyton Magalhaes", "Ronnie de Souza Santos"], "title": "Bita: A Conversational Assistant for Fairness Testing", "comment": null, "summary": "Bias in AI systems can lead to unfair and discriminatory outcomes, especially when left untested before deployment. Although fairness testing aims to identify and mitigate such bias, existing tools are often difficult to use, requiring advanced expertise and offering limited support for real-world workflows. To address this, we introduce Bita, a conversational assistant designed to help software testers detect potential sources of bias, evaluate test plans through a fairness lens, and generate fairness-oriented exploratory testing charters. Bita integrates a large language model with retrieval-augmented generation, grounding its responses in curated fairness literature. Our validation demonstrates how Bita supports fairness testing tasks on real-world AI systems, providing structured, reproducible evidence of its utility. In summary, our work contributes a practical tool that operationalizes fairness testing in a way that is accessible, systematic, and directly applicable to industrial practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Bita\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u8bdd\u52a9\u624b\uff0c\u5e2e\u52a9\u6d4b\u8bd5\u4eba\u5458\u65b9\u4fbf\u3001\u7cfb\u7edf\u5730\u8fdb\u884cAI\u7cfb\u7edf\u516c\u5e73\u6027\u6d4b\u8bd5\uff0c\u4ece\u800c\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u516c\u5e73\u6027\u6d4b\u8bd5\u5de5\u5177\u96be\u4ee5\u4f7f\u7528\uff0c\u9700\u8981\u9ad8\u7ea7\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e14\u5bf9\u73b0\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u652f\u6301\u6709\u9650\uff0c\u5bfc\u81f4AI\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u96be\u4ee5\u6709\u6548\u68c0\u6d4b\u548c\u7f13\u89e3\u3002", "method": "\u63d0\u51fa\u4e86Bita\uff0c\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u7684\u5bf9\u8bdd\u52a9\u624b\uff0c\u57fa\u4e8e\u7b56\u5212\u7684\u516c\u5e73\u6027\u6587\u732e\uff0c\u5e2e\u52a9\u8f6f\u4ef6\u6d4b\u8bd5\u4eba\u5458\u68c0\u6d4b\u504f\u89c1\u6e90\u3001\u8bc4\u4f30\u6d4b\u8bd5\u8ba1\u5212\u5e76\u751f\u6210\u516c\u5e73\u6027\u5bfc\u5411\u7684\u63a2\u7d22\u6027\u6d4b\u8bd5\u8ba1\u5212\u3002", "result": "\u9a8c\u8bc1\u8868\u660eBita\u80fd\u652f\u6301\u73b0\u5b9eAI\u7cfb\u7edf\u4e2d\u7684\u516c\u5e73\u6027\u6d4b\u8bd5\u4efb\u52a1\uff0c\u63d0\u4f9b\u7ed3\u6784\u5316\u3001\u53ef\u91cd\u590d\u7684\u8bc1\u636e\uff0c\u5c55\u793a\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u5de5\u4f5c\u8d21\u732e\u4e86\u4e00\u4e2a\u5b9e\u7528\u5de5\u5177\uff0c\u4f7f\u516c\u5e73\u6027\u6d4b\u8bd5\u53d8\u5f97\u6613\u7528\u3001\u7cfb\u7edf\u5316\u4e14\u9002\u7528\u4e8e\u5de5\u4e1a\u5b9e\u8df5\u3002"}}
{"id": "2512.05364", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05364", "abs": "https://arxiv.org/abs/2512.05364", "authors": ["Ananth Hariharan", "David Mortensen"], "title": "Transformer-Enabled Diachronic Analysis of Vedic Sanskrit: Neural Methods for Quantifying Types of Language Change", "comment": null, "summary": "This study demonstrates how hybrid neural-symbolic methods can yield significant new insights into the evolution of a morphologically rich, low-resource language. We challenge the naive assumption that linguistic change is simplification by quantitatively analyzing over 2,000 years of Sanskrit, demonstrating how weakly-supervised hybrid methods can yield new insights into the evolution of morphologically rich, low-resource languages. Our approach addresses data scarcity through weak supervision, using 100+ high-precision regex patterns to generate pseudo-labels for fine-tuning a multilingual BERT. We then fuse symbolic and neural outputs via a novel confidence-weighted ensemble, creating a system that is both scalable and interpretable. Applying this framework to a 1.47-million-word diachronic corpus, our ensemble achieves a 52.4% overall feature detection rate. Our findings reveal that Sanskrit's overall morphological complexity does not decrease but is instead dynamically redistributed: while earlier verbal features show cyclical patterns of decline, complexity shifts to other domains, evidenced by a dramatic expansion in compounding and the emergence of new philosophical terminology. Critically, our system produces well-calibrated uncertainty estimates, with confidence strongly correlating with accuracy (Pearson r = 0.92) and low overall calibration error (ECE = 0.043), bolstering the reliability of these findings for computational philology.", "AI": {"tldr": "\u5229\u7528\u5f31\u76d1\u7763\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u6210\u529f\u63ed\u793a\u68b5\u8bed\u5f62\u6001\u590d\u6742\u6027\u7684\u52a8\u6001\u6f14\u53d8\u4e0e\u5206\u5e03\uff0c\u6a21\u578b\u51c6\u786e\u4e14\u53ef\u89e3\u91ca\u3002", "motivation": "\u6253\u7834\u8bed\u8a00\u7b80\u5316\u7684\u523b\u677f\u5370\u8c61\uff0c\u91cf\u5316\u5206\u6790\u5f62\u6001\u4e30\u5bcc\u4e14\u8d44\u6e90\u532e\u4e4f\u7684\u68b5\u8bed\u5386\u65f6\u6f14\u53d8\uff0c\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5f31\u76d1\u7763\u6df7\u5408\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u5229\u7528100+\u9ad8\u7cbe\u5ea6\u6b63\u5219\u8868\u8fbe\u5f0f\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u5fae\u8c03\u591a\u8bed\u8a00BERT\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u65b0\u9896\u7684\u7f6e\u4fe1\u5ea6\u52a0\u6743\u96c6\u6210\u878d\u5408\u7b26\u53f7\u4e0e\u795e\u7ecf\u8f93\u51fa\u3002", "result": "\u5728147\u4e07\u5b57\u7684\u5386\u65f6\u8bed\u6599\u5e93\u4e0a\uff0c\u96c6\u6210\u6a21\u578b\u5b9e\u73b052.4%\u7684\u6574\u4f53\u7279\u5f81\u68c0\u6d4b\u7387\u3002\u68b5\u8bed\u7684\u5f62\u6001\u590d\u6742\u6027\u975e\u51cf\u5c11\u800c\u662f\u52a8\u6001\u91cd\u5206\u5e03\uff0c\u52a8\u8bcd\u7279\u5f81\u5468\u671f\u6027\u4e0b\u964d\uff0c\u4f46\u8bcd\u6c47\u5408\u6210\u548c\u54f2\u5b66\u672f\u8bed\u663e\u8457\u6269\u5c55\u3002\u7cfb\u7edf\u4ea7\u51fa\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u51c6\u786e\uff0c\u7f6e\u4fe1\u5ea6\u4e0e\u51c6\u786e\u6027\u9ad8\u5ea6\u76f8\u5173\uff08Pearson r=0.92\uff09\uff0c\u6821\u51c6\u8bef\u5dee\u4f4e\uff08ECE=0.043\uff09\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5e94\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6f14\u53d8\u5206\u6790\uff0c\u8bc1\u660e\u8bed\u8a00\u590d\u6742\u6027\u6f14\u53d8\u4e0d\u662f\u7b80\u5316\uff0c\u800c\u662f\u5f62\u6001\u7279\u5f81\u7684\u52a8\u6001\u8f6c\u79fb\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u8bed\u8a00\u5b66\u7814\u7a76\u7684\u53ef\u9760\u6027\u548c\u89e3\u91ca\u80fd\u529b\u3002"}}
{"id": "2512.05462", "categories": ["cs.SE", "cs.DC", "cs.LG", "q-bio.QM"], "pdf": "https://arxiv.org/pdf/2512.05462", "abs": "https://arxiv.org/abs/2512.05462", "authors": ["Yan-Shiun Wu", "Nathan A. Morin"], "title": "Model Gateway: Model Management Platform for Model-Driven Drug Discovery", "comment": "7 pages, 7 figures", "summary": "This paper presents the Model Gateway, a management platform for managing machine learning (ML) and scientific computational models in the drug discovery pipeline. The platform supports Large Language Model (LLM) Agents and Generative AI-based tools to perform ML model management tasks in our Machine Learning operations (MLOps) pipelines, such as the dynamic consensus model, a model that aggregates several scientific computational models, registration and management, retrieving model information, asynchronous submission/execution of models, and receiving results once the model complete executions. The platform includes a Model Owner Control Panel, Platform Admin Tools, and Model Gateway API service for interacting with the platform and tracking model execution. The platform achieves a 0% failure rate when testing scaling beyond 10k simultaneous application clients consume models. The Model Gateway is a fundamental part of our model-driven drug discovery pipeline. It has the potential to significantly accelerate the development of new drugs with the maturity of our MLOps infrastructure and the integration of LLM Agents and Generative AI tools.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Model Gateway\uff0c\u4e00\u4e2a\u7528\u4e8e\u836f\u7269\u53d1\u73b0\u6a21\u578b\u7ba1\u7406\u7684MLOps\u5e73\u53f0\uff0c\u96c6\u6210LLM Agents\u548c\u751f\u6210\u5f0fAI\uff0c\u5b9e\u73b0\u9ad8\u5e76\u53d1\u3001\u96f6\u5931\u8d25\u7387\u7684\u6a21\u578b\u6267\u884c\u7ba1\u7406\uff0c\u52a9\u529b\u52a0\u901f\u65b0\u836f\u7814\u53d1\u3002", "motivation": "\u836f\u7269\u53d1\u73b0\u8fc7\u7a0b\u4e2d\u9700\u8981\u9ad8\u6548\u7ba1\u7406\u591a\u79cd\u673a\u5668\u5b66\u4e60\u548c\u79d1\u5b66\u8ba1\u7b97\u6a21\u578b\uff0c\u63d0\u5347\u6a21\u578b\u6267\u884c\u6548\u7387\u4e0e\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u4ece\u800c\u52a0\u901f\u65b0\u836f\u7814\u53d1\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u5305\u542b\u52a8\u6001\u5171\u8bc6\u6a21\u578b\u3001\u6a21\u578b\u6ce8\u518c\u4e0e\u7ba1\u7406\u3001\u5f02\u6b65\u6267\u884c\u53ca\u7ed3\u679c\u63a5\u6536\u7684MLOps\u5e73\u53f0\uff0c\u652f\u6301\u5927\u89c4\u6a21\u5e76\u53d1\u8bbf\u95ee\u53ca\u96c6\u6210LLM Agents\u548c\u751f\u6210\u5f0fAI\u5de5\u5177\u3002", "result": "\u5e73\u53f0\u5728\u8d85\u8fc71\u4e07\u5e76\u53d1\u5ba2\u6237\u7aef\u73af\u5883\u4e0b\u5b9e\u73b00%\u5931\u8d25\u7387\uff0c\u652f\u6301\u6a21\u578b\u4fe1\u606f\u68c0\u7d22\u548c\u63a7\u5236\u9762\u677f\uff0c\u6709\u6548\u4fdd\u969c\u6a21\u578b\u6267\u884c\u4e0e\u7ba1\u7406\u3002", "conclusion": "Model Gateway\u4f5c\u4e3a\u836f\u7269\u53d1\u73b0\u7ba1\u7ebf\u4e2d\u7684\u57fa\u7840\u5e73\u53f0\uff0c\u6709\u6548\u7ba1\u7406\u548c\u6267\u884c\u673a\u5668\u5b66\u4e60\u53ca\u79d1\u5b66\u8ba1\u7b97\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u4efb\u52a1\u7684\u81ea\u52a8\u5316\u4e0e\u7a33\u5b9a\u6027\u3002"}}
{"id": "2512.05379", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05379", "abs": "https://arxiv.org/abs/2512.05379", "authors": ["Taslim Mahbub", "Shi Feng"], "title": "Mitigating Self-Preference by Authorship Obfuscation", "comment": null, "summary": "Language models (LMs) judges are widely used to evaluate the quality of LM outputs. Despite many advantages, LM judges display concerning biases that can impair their integrity in evaluations. One such bias is self-preference: LM judges preferring their own answers over those produced by other LMs or humans. The bias is hard to eliminate as frontier LM judges can distinguish their own outputs from those of others, even when the evaluation candidates are not labeled with their sources. In this paper, we investigate strategies to mitigate self-preference by reducing the LM judges' ability to recognize their own outputs. We apply black-box perturbations to evaluation candidates in pairwise comparison to obfuscate the authorship and reduce self-recognition. We find that perturbations as simple as synonym replacement for a few words predictably reduce self-preference. However, we also uncover fundamental challenges to eliminating the bias: when we extrapolate our perturbations to a more complete neutralization of stylistic differences between the evaluation candidates, self-preference recovers. Our findings suggest that self-recognition and self-preference can happen on many semantic levels, and complete mitigation remains challenging despite promising initial results.", "AI": {"tldr": "\u7814\u7a76\u8bed\u8a00\u6a21\u578b\u8bc4\u5ba1\u4e2d\u7684\u81ea\u6211\u504f\u597d\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u6270\u52a8\u6587\u672c\u964d\u4f4e\u6a21\u578b\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u4ee5\u7f13\u89e3\u504f\u597d\uff0c\u4f46\u5b8c\u5168\u6d88\u9664\u4ecd\u56f0\u96be\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u8bc4\u5ba1\u5e7f\u6cdb\u7528\u4e8e\u8bc4\u4ef7\u6a21\u578b\u8d28\u91cf\uff0c\u4f46\u5b58\u5728\u81ea\u6211\u504f\u597d\u504f\u89c1\uff0c\u5f71\u54cd\u8bc4\u4f30\u516c\u6b63\u6027\uff0c\u4e9f\u9700\u5bfb\u627e\u6709\u6548\u51cf\u8f7b\u8be5\u504f\u597d\u7684\u65b9\u6cd5\u3002", "method": "\u5bf9\u8bc4\u4f30\u5019\u9009\u6587\u672c\u65bd\u52a0\u9ed1\u76d2\u6270\u52a8\uff08\u5982\u540c\u4e49\u8bcd\u66ff\u6362\uff09\uff0c\u901a\u8fc7\u6df7\u6dc6\u4f5c\u8005\u8eab\u4efd\u51cf\u5c11\u6a21\u578b\u7684\u81ea\u6211\u8bc6\u522b\u80fd\u529b\uff0c\u964d\u4f4e\u81ea\u6211\u504f\u597d\u3002", "result": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u8bc4\u5ba1\u5728\u81ea\u8eab\u504f\u597d\u4e0a\u7684\u504f\u89c1\u95ee\u9898\uff0c\u5373\u6a21\u578b\u504f\u597d\u81ea\u8eab\u751f\u6210\u7684\u7b54\u6848\u800c\u975e\u5176\u4ed6\u6a21\u578b\u6216\u4eba\u7c7b\u7684\u7b54\u6848\u3002\u4f5c\u8005\u901a\u8fc7\u5bf9\u6bd4\u8bc4\u4f30\u5019\u9009\u8f93\u51fa\u65f6\uff0c\u91c7\u7528\u9ed1\u76d2\u6270\u52a8\uff08\u5982\u540c\u4e49\u8bcd\u66ff\u6362\uff09\u6765\u6df7\u6dc6\u7b54\u6848\u4f5c\u8005\u8eab\u4efd\uff0c\u4ece\u800c\u51cf\u5f31\u81ea\u6211\u8bc6\u522b\u80fd\u529b\u4ee5\u964d\u4f4e\u81ea\u6211\u504f\u597d\u3002\u5b9e\u9a8c\u53d1\u73b0\u7b80\u5355\u7684\u6270\u52a8\u53ef\u4ee5\u6709\u6548\u51cf\u8f7b\u81ea\u4f53\u504f\u597d\uff0c\u4f46\u5728\u8fdb\u4e00\u6b65\u5b8c\u5168\u4e2d\u548c\u5019\u9009\u8f93\u51fa\u98ce\u683c\u5dee\u5f02\u65f6\uff0c\u81ea\u6211\u504f\u597d\u53c8\u590d\u73b0\uff0c\u8bf4\u660e\u81ea\u6211\u8bc6\u522b\u548c\u504f\u597d\u5b58\u5728\u591a\u5c42\u6b21\u7684\u8bed\u4e49\u57fa\u7840\uff0c\u5b8c\u5168\u6d88\u9664\u4ecd\u5177\u6311\u6218\u3002", "conclusion": "\u81ea\u6211\u504f\u597d\u7531\u591a\u5c42\u8bed\u4e49\u56e0\u7d20\u5bfc\u81f4\uff0c\u7b80\u5355\u6270\u52a8\u867d\u80fd\u51cf\u8f7b\u504f\u89c1\uff0c\u4f46\u5b8c\u5168\u6d88\u9664\u8be5\u504f\u597d\u4ecd\u9762\u4e34\u6311\u6218\u3002"}}
{"id": "2512.05470", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05470", "abs": "https://arxiv.org/abs/2512.05470", "authors": ["Xiwei Xu", "Robert Mao", "Quan Bai", "Xuewu Gu", "Yechao Li", "Liming Zhu"], "title": "Everything is Context: Agentic File System Abstraction for Context Engineering", "comment": "Submitted", "summary": "Generative AI (GenAI) has reshaped software system design by introducing foundation models as pre-trained subsystems that redefine architectures and operations. The emerging challenge is no longer model fine-tuning but context engineering-how systems capture, structure, and govern external knowledge, memory, tools, and human input to enable trustworthy reasoning. Existing practices such as prompt engineering, retrieval-augmented generation (RAG), and tool integration remain fragmented, producing transient artefacts that limit traceability and accountability. This paper proposes a file-system abstraction for context engineering, inspired by the Unix notion that 'everything is a file'. The abstraction offers a persistent, governed infrastructure for managing heterogeneous context artefacts through uniform mounting, metadata, and access control. Implemented within the open-source AIGNE framework, the architecture realises a verifiable context-engineering pipeline, comprising the Context Constructor, Loader, and Evaluator, that assembles, delivers, and validates context under token constraints. As GenAI becomes an active collaborator in decision support, humans play a central role as curators, verifiers, and co-reasoners. The proposed architecture establishes a reusable foundation for accountable and human-centred AI co-work, demonstrated through two exemplars: an agent with memory and an MCP-based GitHub assistant. The implementation within the AIGNE framework demonstrates how the architecture can be operationalised in developer and industrial settings, supporting verifiable, maintainable, and industry-ready GenAI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6587\u4ef6\u7cfb\u7edf\u62bd\u8c61\u7684\u751f\u6210\u5f0fAI\u4e0a\u4e0b\u6587\u7ba1\u7406\u67b6\u6784\uff0c\u5b9e\u73b0\u6301\u4e45\u3001\u53ef\u6cbb\u7406\u548c\u53ef\u9a8c\u8bc1\u7684\u4eba\u673a\u534f\u4f5c\u63a8\u7406\u7ba1\u9053\uff0c\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u7ef4\u62a4\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8bbe\u8ba1\u5df2\u4ece\u6a21\u578b\u5fae\u8c03\u8f6c\u5411\u5982\u4f55\u6709\u6548\u6355\u6349\u3001\u7ed3\u6784\u5316\u548c\u7ba1\u7406\u5916\u90e8\u77e5\u8bc6\u4e0a\u4e0b\u6587\uff0c\u4ee5\u4fc3\u8fdb\u53ef\u4fe1\u63a8\u7406\u548c\u589e\u5f3a\u7cfb\u7edf\u8d23\u4efb\u8ffd\u6eaf\u80fd\u529b\u3002\u73b0\u6709\u65b9\u6cd5\u788e\u7247\u5316\u4e14\u4ea7\u7269\u77ed\u6682\uff0c\u4e9f\u9700\u7edf\u4e00\u6301\u4e45\u7684\u7ba1\u7406\u65b9\u6848\u3002", "method": "\u501f\u9274Unix\u201c\u4e00\u5207\u7686\u6587\u4ef6\u201d\u7406\u5ff5\uff0c\u8bbe\u8ba1\u7edf\u4e00\u6302\u8f7d\u3001\u5143\u6570\u636e\u548c\u8bbf\u95ee\u63a7\u5236\u673a\u5236\uff0c\u6784\u5efa\u5305\u542b\u4e0a\u4e0b\u6587\u6784\u9020\u5668\u3001\u52a0\u8f7d\u5668\u53ca\u8bc4\u4f30\u5668\u7684\u7ba1\u9053\u7cfb\u7edf\uff0c\u5e76\u5728\u5f00\u6e90AIGNE\u6846\u67b6\u4e2d\u5b9e\u73b0\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u9a8c\u8bc1\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6d41\u6c34\u7ebf\uff0c\u652f\u6301\u4ee3\u5e01\u9650\u5236\u4e0b\u4e0a\u4e0b\u6587\u7684\u7ec4\u88c5\u3001\u4ea4\u4ed8\u4e0e\u9a8c\u8bc1\uff0c\u901a\u8fc7\u4e24\u79cd\u793a\u4f8b\uff08\u5177\u5907\u8bb0\u5fc6\u7684\u667a\u80fd\u4f53\u548c\u57fa\u4e8eMCP\u7684GitHub\u52a9\u624b\uff09\u5c55\u793a\u4e86\u8be5\u67b6\u6784\u5728\u5de5\u4e1a\u548c\u5f00\u53d1\u73af\u5883\u4e2d\u7684\u53ef\u64cd\u4f5c\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u6587\u4ef6\u7cfb\u7edf\u62bd\u8c61\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\u67b6\u6784\uff0c\u4e3a\u751f\u6210\u5f0fAI\u7cfb\u7edf\u63d0\u4f9b\u6301\u4e45\u3001\u53ef\u6cbb\u7406\u7684\u4e0a\u4e0b\u6587\u7ba1\u7406\u57fa\u7840\u8bbe\u65bd\uff0c\u652f\u6301\u4eba\u673a\u534f\u540c\u3001\u53ef\u4fe1\u63a8\u7406\u548c\u53ef\u9a8c\u8bc1\u7684\u4e0a\u4e0b\u6587\u7ba1\u9053\u3002"}}
{"id": "2512.05387", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05387", "abs": "https://arxiv.org/abs/2512.05387", "authors": ["Ting-Yao Hu", "Hema Swetha Koppula", "Hadi Pouransari", "Cem Koc", "Oncel Tuzel", "Raviteja Vemulapalli"], "title": "Learning from Self Critique and Refinement for Faithful LLM Summarization", "comment": null, "summary": "Large Language Models (LLMs) often suffer from hallucinations: output content that is not grounded in the input context, when performing long-form text generation tasks such as summarization. Prior works have shown that hallucinations can be reduced by iteratively critiquing and refining previously generated outputs using either the same model or a more powerful teacher model as the critique. However, these approaches either require additional test-time compute or assume access to more powerful teacher models, making them costly and less practical. In this work, we propose Self Critique and Refinement-based Preference Optimization (SCRPO), which is a self-supervised training framework that first constructs a preference dataset by leveraging the LLM's own critique and refinement capabilities, and then applies preference learning to improve the same LLM for faithful summarization. Experiments on three summarization benchmarks (XSUM CNNDM and SAMSum), demonstrate that our approach outperforms state-of-the-art self-supervised learning methods in terms of faithfulness metrics while either maintaining or improving other metrics that measure the overall quality of the summary. Moreover, compared to test-time refinement, our approach not only improves efficiency but also results in more faithful summaries.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCRPO\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u6211\u6279\u8bc4\u548c\u504f\u597d\u5b66\u4e60\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6458\u8981\u7684\u771f\u5b9e\u6027\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u4e14\u66f4\u9ad8\u6548\u3002", "motivation": "\u73b0\u6709\u51cf\u5c11\u5927\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u65b9\u6cd5\u4f9d\u8d56\u989d\u5916\u7684\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u8d44\u6e90\u6216\u66f4\u5f3a\u7684\u6559\u5e08\u6a21\u578b\uff0c\u6210\u672c\u9ad8\u4e14\u4e0d\u5b9e\u7528\uff0c\u56e0\u800c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u81ea\u6211\u6279\u8bc4\u548c\u7cbe\u70bc\u7684\u504f\u597d\u4f18\u5316\u8bad\u7ec3\u6846\u67b6\uff08SCRPO\uff09\uff0c\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u8eab\u7684\u6279\u8bc4\u548c\u7cbe\u70bc\u80fd\u529b\u6784\u5efa\u504f\u597d\u6570\u636e\u96c6\uff0c\u518d\u8fdb\u884c\u504f\u597d\u5b66\u4e60\u4ee5\u63d0\u5347\u6a21\u578b\u5728\u6458\u8981\u4efb\u52a1\u4e2d\u7684\u771f\u5b9e\u6027\u3002", "result": "\u5728\u4e09\u4e2a\u6458\u8981\u57fa\u51c6\uff08XSUM\u3001CNNDM\u548cSAMSum\uff09\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cSCRPO\u5728\u771f\u5b9e\u6027\u8bc4\u4ef7\u6307\u6807\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4e86\u6458\u8981\u8d28\u91cf\u7684\u5176\u4ed6\u6307\u6807\u3002\u76f8\u6bd4\u6d4b\u8bd5\u65f6\u7cbe\u70bc\uff0cSCRPO\u4e0d\u4ec5\u63d0\u5347\u4e86\u6548\u7387\uff0c\u8fd8\u751f\u6210\u4e86\u66f4\u771f\u5b9e\u7684\u6458\u8981\u3002", "conclusion": "SCRPO\u662f\u4e00\u79cd\u9ad8\u6548\u4e14\u5b9e\u7528\u7684\u81ea\u6211\u76d1\u7763\u8bad\u7ec3\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u6587\u672c\u751f\u6210\u4e2d\u6458\u8981\u7684\u771f\u5b9e\u6027\u548c\u6574\u4f53\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u4f9d\u8d56\u5916\u90e8\u6a21\u578b\u6216\u9ad8\u8ba1\u7b97\u8d44\u6e90\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.05498", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05498", "abs": "https://arxiv.org/abs/2512.05498", "authors": ["Xiao He", "Ru Chen", "Zeqing Zhang", "Yanling Wang", "Qiuyan Dong"], "title": "A Hybrid Approach for EMF Code Generation:Code Templates Meet Large Language Models", "comment": null, "summary": "Template-based and LLM-based code generation are both key enablers of automated software development. The former provides correctness guarantees but are rigid for complex requirements, whereas LLMs offer high flexibility at the risk of producing faulty code.This paper proposes iEcoreGen, a hybrid approach that integrates Eclipse Modeling Framework (EMF) and LLMs. In EMF, an Ecore model defines a system structure and acts as a blueprint for code-generation.iEcoreGen decomposes requirements to derive operation specifications, uses EMF's template-based generator to produce initial Java code, and serializes specifications into docstrings. LLMs are then invoked to complete and fix unimplemented methods. We assessed iEcoreGen on twenty code-generation tasks across five LLMs. It surpasses LLM-only baselines on pass@k and performs on par with them on compilation@k. An ablation study clarified the contribution of each component of iEcoreGen. Overall, the findings indicate that LLM-enhanced model-driven development is a promising path toward more efficient software automation.", "AI": {"tldr": "iEcoreGen\u878d\u5408EMF\u6a21\u677f\u4e0eLLM\uff0c\u517c\u5177\u51c6\u786e\u6027\u4e0e\u7075\u6d3b\u6027\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u751f\u6210\u6548\u679c\u3002", "motivation": "\u6a21\u677f\u751f\u6210\u65b9\u6cd5\u51c6\u786e\u4f46\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0cLLM\u7075\u6d3b\u4f46\u6613\u51fa\u9519\uff0c\u7ed3\u5408\u4e24\u8005\u4f18\u52bf\u63d0\u5347\u81ea\u52a8\u5316\u4ee3\u7801\u5f00\u53d1\u8d28\u91cf\u3002", "method": "\u63d0\u51fa\u4e86iEcoreGen\uff0c\u4e00\u79cd\u7ed3\u5408Eclipse Modeling Framework (EMF)\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u4ee3\u7801\u751f\u6210\u65b9\u6cd5\u3002\u5229\u7528EMF\u7684\u6a21\u677f\u751f\u6210\u521d\u59cbJava\u4ee3\u7801\uff0c\u518d\u5229\u7528LLM\u5b8c\u6210\u548c\u4fee\u590d\u672a\u5b9e\u73b0\u7684\u65b9\u6cd5\u3002", "result": "iEcoreGen\u5728\u4e94\u4e2aLLM\u7684\u4e8c\u5341\u4e2a\u4efb\u52a1\u4e0a\uff0cpass@k\u6307\u6807\u4f18\u4e8e\u7eafLLM\uff0ccompilation@k\u8868\u73b0\u76f8\u5f53\uff0c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u5404\u7ec4\u4ef6\u8d21\u732e\u3002", "conclusion": "LLM\u589e\u5f3a\u7684\u6a21\u578b\u9a71\u52a8\u5f00\u53d1\u4e3a\u9ad8\u6548\u8f6f\u4ef6\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002"}}
{"id": "2512.05409", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05409", "abs": "https://arxiv.org/abs/2512.05409", "authors": ["Ruixuan Huang", "Hao Zeng", "Hantao Huang", "Jinyuan Shi", "Minghui Yu", "Ian En-Hsu Yen", "Shuai Wang"], "title": "SQ-format: A Unified Sparse-Quantized Hardware-friendly Data Format for LLMs", "comment": null, "summary": "Post-training quantization (PTQ) plays a crucial role in the democratization of large language models (LLMs). However, existing low-bit quantization and sparsification techniques are difficult to balance accuracy and efficiency due to the limited hardware support. For example, W4A8 can only achieve the same peak TOPS as W8A8 whereas the GPU-supported sparse data format (2:4 semi-structure sparse) is seldomly adopted due to the loss of accuracy. To bridge this gap, in this paper, we propose the Sparse-Quantized Format (SQ-format), which is a unified data format for quantization and sparsification potentially easily supported by new hardware and existing GPUs. SQ-format makes use of the fact that sparse matrix can be accelerated in high-precision, and low-precision matrix multiplication can also be accelerated accordingly. As such, SQ-format is proposed to achieve Pareto improvement between performance and throughput. This format is particularly suitable for activations with outlier inequality status and makes their static compression possible. We show the state-of-the-art PTQ performance with SQ-format, propose the hardware required to support it, and further offer the design exploration and insights for the next-generation AI accelerators.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684SQ-format\u7edf\u4e00\u6570\u636e\u683c\u5f0f\u6709\u6548\u7ed3\u5408\u4e86\u91cf\u5316\u548c\u7a00\u758f\u6280\u672f\uff0c\u63d0\u5347\u4e86\u8ba1\u7b97\u6027\u80fd\u4e0e\u51c6\u786e\u7387\u7684\u5e73\u8861\uff0c\u5e76\u4e3a\u65b0\u786c\u4ef6\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b9\u5411\u3002", "motivation": "\u73b0\u6709\u7684\u4f4e\u4f4d\u5bbd\u91cf\u5316\u548c\u7a00\u758f\u6280\u672f\u96be\u4ee5\u5728\u51c6\u786e\u7387\u548c\u6548\u7387\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u4e14\u786c\u4ef6\u652f\u6301\u6709\u9650\uff0c\u65e0\u6cd5\u5145\u5206\u53d1\u6325\u91cf\u5316\u548c\u7a00\u758f\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSparse-Quantized Format\uff08SQ-format\uff09\u7684\u7edf\u4e00\u6570\u636e\u683c\u5f0f\uff0c\u5c06\u91cf\u5316\u548c\u7a00\u758f\u6280\u672f\u7ed3\u5408\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u786c\u4ef6\u652f\u6301\u7684\u517c\u5bb9\u6027\u3002", "result": "SQ-format\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u541e\u5410\u91cf\u4e0a\u7684\u5e15\u7d2f\u6258\u6539\u8fdb\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5177\u6709\u5f02\u5e38\u503c\u5206\u5e03\u7684\u6fc0\u6d3b\u6570\u636e\uff0c\u80fd\u591f\u5b9e\u73b0\u9759\u6001\u538b\u7f29\u5e76\u53d6\u5f97\u4e86\u5148\u8fdb\u7684\u540e\u8bad\u7ec3\u91cf\u5316\uff08PTQ\uff09\u6027\u80fd\u3002", "conclusion": "SQ-format\u80fd\u591f\u4fc3\u8fdb\u91cf\u5316\u4e0e\u7a00\u758f\u6280\u672f\u7684\u9ad8\u6548\u7ed3\u5408\uff0c\u63a8\u52a8\u4e0b\u4e00\u4ee3AI\u52a0\u901f\u5668\u8bbe\u8ba1\uff0c\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6548\u679c\u548c\u786c\u4ef6\u9002\u914d\u6027\u3002"}}
{"id": "2512.05507", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05507", "abs": "https://arxiv.org/abs/2512.05507", "authors": ["Masoud Sadrnezhaad", "Jos\u00e9 Antonio Hern\u00e1ndez L\u00f3pez", "Torvald M\u00e5rtensson", "Daniel Varro"], "title": "Generative AI in Simulation-Based Test Environments for Large-Scale Cyber-Physical Systems: An Industrial Study", "comment": "This paper appears in the proceedings of the 26th International Conference on Product-Focused Software Process Improvement (PROFES 2025). For citations, please refer to the published version in the PROFES 2025 proceedings", "summary": "Quality assurance for large-scale cyber-physical systems relies on sophisticated test activities using complex test environments investigated with the help of numerous types of simulators. As these systems grow, extensive resources are required to develop and maintain simulation models of hardware and software components, as well as physical environments. Meanwhile, recent advances in generative AI have led to tools that can produce executable test cases for software systems, offering potential benefits such as reducing manual efforts or increasing test coverage. However, the application of generative AI techniques to simulation-based testing of large-scale cyber-physical systems remains underexplored. To better understand this gap, this study captures practitioners' perspectives on leveraging generative AI, based on a cross-company workshop with six organizations. Our contribution is twofold: (1) detailed, experience-based insights into challenges faced by engineers, and (2) a research agenda comprising three high-priority directions: (a) AI-generated scenarios and environment models, (b) simulators and AI in CI/CD pipelines, and (c) trustworthiness in generative AI for simulation. While participants acknowledged substantial potential, they also highlighted unresolved challenges. By detailing these issues, the paper aims to guide future academia-industry collaboration towards the responsible adoption of generative AI in simulation-based testing.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u751f\u6210\u5f0fAI\u5728\u5927\u578b\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u57fa\u4e8e\u4eff\u771f\u7684\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u53ca\u6311\u6218\uff0c\u57fa\u4e8e\u516d\u5bb6\u516c\u53f8\u8de8\u516c\u53f8\u7814\u8ba8\u4f1a\u6536\u96c6\u4e86\u5de5\u7a0b\u5e08\u89c2\u70b9\uff0c\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u91cd\u70b9\u3002", "motivation": "\u968f\u7740\u5927\u578b\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u6d4b\u8bd5\u4eff\u771f\u8d44\u6e90\u6d88\u8017\u5de8\u5927\uff0c\u751f\u6210\u5f0fAI\u6709\u6f5c\u529b\u51cf\u8f7b\u624b\u52a8\u8d1f\u62c5\u5e76\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u7136\u800c\u5176\u5728\u8be5\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u7ec4\u7ec7\u4e00\u6b21\u6db5\u76d6\u516d\u5bb6\u7ec4\u7ec7\u7684\u8de8\u516c\u53f8\u7814\u8ba8\u4f1a\uff0c\u6536\u96c6\u548c\u5206\u6790\u4ece\u4e1a\u8005\u5bf9\u751f\u6210\u5f0fAI\u5728\u4eff\u771f\u6d4b\u8bd5\u4e2d\u5e94\u7528\u7684\u770b\u6cd5\u4e0e\u7ecf\u9a8c\u3002", "result": "\u7814\u8ba8\u4f1a\u63ed\u793a\u4e86\u751f\u6210\u5f0fAI\u5728\u4eff\u771f\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9645\u6f5c\u529b\u548c\u5173\u952e\u6311\u6218\uff0c\u660e\u786e\u4e86\u751f\u6210\u6d4b\u8bd5\u573a\u666f\u4e0e\u73af\u5883\u6a21\u578b\u3001\u4eff\u771f\u5668\u4e0eAI\u96c6\u6210\u3001\u4ee5\u53caAI\u53ef\u4fe1\u5ea6\u4f5c\u4e3a\u9996\u8981\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u5728\u57fa\u4e8e\u4eff\u771f\u7684\u5927\u578b\u7f51\u7edc\u7269\u7406\u7cfb\u7edf\u6d4b\u8bd5\u4e2d\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u9762\u4e34\u591a\u9879\u6311\u6218\uff0c\u9700\u63a8\u52a8\u5b66\u672f\u754c\u4e0e\u5de5\u4e1a\u754c\u5408\u4f5c\uff0c\u91cd\u70b9\u5173\u6ce8AI\u751f\u6210\u6d4b\u8bd5\u573a\u666f\u3001\u96c6\u6210AI\u4e0eCI/CD\u6d41\u6c34\u7ebf\u53ca\u63d0\u5347\u53ef\u4fe1\u5ea6\u3002"}}
{"id": "2512.05414", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05414", "abs": "https://arxiv.org/abs/2512.05414", "authors": ["Akesh Gunathilakea", "Nadil Karunarathnea", "Tharusha Bandaranayakea", "Nisansa de Silvaa", "Surangika Ranathunga"], "title": "LMSpell: Neural Spell Checking for Low-Resource Languages", "comment": null, "summary": "Spell correction is still a challenging problem for low-resource languages (LRLs). While pretrained language models (PLMs) have been employed for spell correction, their use is still limited to a handful of languages, and there has been no proper comparison across PLMs. We present the first empirical study on the effectiveness of PLMs for spell correction, which includes LRLs. We find that Large Language Models (LLMs) outperform their counterparts (encoder-based and encoder-decoder) when the fine-tuning dataset is large. This observation holds even in languages for which the LLM is not pre-trained. We release LMSpell, an easy- to use spell correction toolkit across PLMs. It includes an evaluation function that compensates for the hallucination of LLMs. Further, we present a case study with Sinhala to shed light on the plight of spell correction for LRLs.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6bd4\u8f83\u4e86\u5404\u79cd\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u5728\u62fc\u5199\u7ea0\u9519\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5927\u6570\u636e\u60c5\u51b5\u4e0b\u6548\u679c\u6700\u4f73\uff0c\u5e76\u53d1\u5e03\u4e86\u591a\u8bed\u8a00\u62fc\u5199\u7ea0\u9519\u5de5\u5177LMSpell\u3002", "motivation": "\u5f53\u524d\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u62fc\u5199\u7ea0\u9519\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u4e14\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684\u5e94\u7528\u548c\u6548\u679c\u5c1a\u65e0\u7cfb\u7edf\u6bd4\u8f83\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7a7a\u767d\uff0c\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u62fc\u5199\u7ea0\u9519\u7684\u6548\u679c\u4e0e\u5de5\u5177\u652f\u6301\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5206\u6790\u4e0d\u540c\u7c7b\u578b\u7684\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3001\u7f16\u7801\u5668\u548c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff09\u5728\u62fc\u5199\u7ea0\u9519\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5e76\u8fdb\u884c\u5b9e\u9645\u8bed\u8a00\u6848\u4f8b\u7814\u7a76\uff0c\u5f00\u53d1\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u62fc\u5199\u7ea0\u9519\u5de5\u5177\u5305LMSpell\u4ee5\u4fbf\u8bc4\u4f30\u548c\u5e94\u7528\u3002", "result": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff08PLMs\uff09\u5728\u62fc\u5199\u7ea0\u9519\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5c24\u5176\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08LRLs\uff09\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5f53\u5fae\u8c03\u6570\u636e\u91cf\u5145\u8db3\u65f6\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u62fc\u5199\u7ea0\u9519\u8868\u73b0\u4e0a\u4f18\u4e8e\u7f16\u7801\u5668\u53ca\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5373\u4f7f\u5728LLM\u672a\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\u4e0a\u4ea6\u7136\u3002\u672c\u6587\u8fd8\u53d1\u5e03\u4e86LMSpell\u62fc\u5199\u7ea0\u9519\u5de5\u5177\u5305\uff0c\u652f\u6301\u591a\u79cdPLMs\uff0c\u5e76\u5305\u542b\u9488\u5bf9LLM\u751f\u6210\u5047\u4fe1\u606f\u7684\u8bc4\u4f30\u529f\u80fd\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u50e7\u4f3d\u7f57\u8bed\u6848\u4f8b\u7814\u7a76\uff0c\u63ed\u793a\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u62fc\u5199\u7ea0\u9519\u7684\u6311\u6218\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u62fc\u5199\u7ea0\u9519\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u5145\u8db3\u65f6\uff0c\u5e76\u4e14\u6b64\u4f18\u52bf\u4e5f\u9002\u7528\u4e8e\u672a\u88ab\u9884\u8bad\u7ec3\u7684\u8bed\u8a00\uff0cLMSpell\u5de5\u5177\u5305\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u62fc\u5199\u7ea0\u9519\u63d0\u4f9b\u4e86\u6709\u6548\u652f\u6301\u3002"}}
{"id": "2512.05533", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05533", "abs": "https://arxiv.org/abs/2512.05533", "authors": ["Theocharis Tavantzis", "Stefano Lambiase", "Daniel Russo", "Robert Feldt"], "title": "From Challenge to Change: Design Principles for AI Transformations", "comment": "Submitted to JSS", "summary": "The rapid rise of Artificial Intelligence (AI) is reshaping Software Engineering (SE), creating new opportunities while introducing human-centered challenges. Although prior work notes behavioral and other non-technical factors in AI integration, most studies still emphasize technical concerns and offer limited insight into how teams adapt to and trust AI. This paper proposes a Behavioral Software Engineering (BSE)-informed, human-centric framework to support SE organizations during early AI adoption. Using a mixed-methods approach, we built and refined the framework through a literature review of organizational change models and thematic analysis of interview data, producing concrete, actionable steps. The framework comprises nine dimensions: AI Strategy Design, AI Strategy Evaluation, Collaboration, Communication, Governance and Ethics, Leadership, Organizational Culture, Organizational Dynamics, and Up-skilling, each supported by design principles and actions. To gather preliminary practitioner input, we conducted a survey (N=105) and two expert workshops (N=4). Survey results show that Up-skilling (15.2%) and AI Strategy Design (15.1%) received the highest $100-method allocations, underscoring their perceived importance in early AI initiatives. Findings indicate that organizations currently prioritize procedural elements such as strategy design, while human-centered guardrails remain less developed. Workshop feedback reinforced these patterns and emphasized the need to ground the framework in real-world practice. By identifying key behavioral dimensions and offering actionable guidance, this work provides a pragmatic roadmap for navigating the socio-technical complexity of early AI adoption and highlights future research directions for human-centric AI in SE.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u6db5\u76d6\u884c\u4e3a\u548c\u6280\u672f\u7684AI\u65e9\u671f\u91c7\u7528\u6846\u67b6\uff0c\u7ed3\u5408\u5b9e\u8bc1\u8c03\u7814\u63d0\u4f9b\u8f6f\u4ef6\u5de5\u7a0b\u56e2\u961f\u9002\u5e94AI\u7684\u5177\u4f53\u8def\u5f84\uff0c\u586b\u8865\u5f53\u524d\u4eba\u673a\u534f\u4f5c\u7814\u7a76\u7a7a\u767d\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5feb\u901f\u53d1\u5c55\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5e26\u6765\u5de8\u5927\u673a\u9047\u548c\u6311\u6218\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u6280\u672f\uff0c\u7f3a\u4e4f\u5bf9\u56e2\u961f\u5982\u4f55\u9002\u5e94\u548c\u4fe1\u4efbAI\u7684\u6d1e\u5bdf\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u8bbf\u8c08\u7684\u4e3b\u9898\u5206\u6790\u6784\u5efa\u6846\u67b6\uff0c\u7ed3\u5408\u6df7\u5408\u65b9\u6cd5\u8bba\u8bbe\u8ba1\u8c03\u67e5\u548c\u4e13\u5bb6\u7814\u8ba8\u4f1a\u6536\u96c6\u5b9e\u8df5\u53cd\u9988\u3002", "result": "\u8be5\u6846\u67b6\u5305\u542b\u4e5d\u4e2a\u7ef4\u5ea6\u5e76\u63d0\u4f9b\u5177\u4f53\u884c\u52a8\u6307\u5bfc\uff0c\u8c03\u67e5\u663e\u793a\u57f9\u8bad\u548cAI\u7b56\u7565\u8bbe\u8ba1\u6700\u53d7\u91cd\u89c6\uff0c\u4f46\u4eba\u6587\u5173\u6000\u65b9\u9762\u5c1a\u4e0d\u8db3\uff0c\u7814\u8ba8\u4f1a\u53cd\u9988\u5f3a\u8c03\u6846\u67b6\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u4ee5\u884c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u4e3a\u57fa\u7840\u3001\u4ee5\u4eba\u4e3a\u4e2d\u5fc3\u7684\u6846\u67b6\uff0c\u5e2e\u52a9\u8f6f\u4ef6\u5de5\u7a0b\u7ec4\u7ec7\u5728\u65e9\u671f\u4eba\u5de5\u667a\u80fd\u91c7\u7528\u9636\u6bb5\u6709\u6548\u5e94\u5bf9\u6280\u672f\u4e0e\u884c\u4e3a\u6311\u6218\u3002"}}
{"id": "2512.05430", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.05430", "abs": "https://arxiv.org/abs/2512.05430", "authors": ["Daeyong Kwon", "SeungHeon Doh", "Juhan Nam"], "title": "ArtistMus: A Globally Diverse, Artist-Centric Benchmark for Retrieval-Augmented Music Question Answering", "comment": "Submitted to LREC 2026. This work is an evolution of our earlier preprint arXiv:2507.23334", "summary": "Recent advances in large language models (LLMs) have transformed open-domain question answering, yet their effectiveness in music-related reasoning remains limited due to sparse music knowledge in pretraining data. While music information retrieval and computational musicology have explored structured and multimodal understanding, few resources support factual and contextual music question answering (MQA) grounded in artist metadata or historical context. We introduce MusWikiDB, a vector database of 3.2M passages from 144K music-related Wikipedia pages, and ArtistMus, a benchmark of 1,000 questions on 500 diverse artists with metadata such as genre, debut year, and topic. These resources enable systematic evaluation of retrieval-augmented generation (RAG) for MQA. Experiments show that RAG markedly improves factual accuracy; open-source models gain up to +56.8 percentage points (for example, Qwen3 8B improves from 35.0 to 91.8), approaching proprietary model performance. RAG-style fine-tuning further boosts both factual recall and contextual reasoning, improving results on both in-domain and out-of-domain benchmarks. MusWikiDB also yields approximately 6 percentage points higher accuracy and 40% faster retrieval than a general-purpose Wikipedia corpus. We release MusWikiDB and ArtistMus to advance research in music information retrieval and domain-specific question answering, establishing a foundation for retrieval-augmented reasoning in culturally rich domains such as music.", "AI": {"tldr": "\u672c\u8bba\u6587\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u97f3\u4e50\u5411\u91cf\u6570\u636e\u5e93MusWikiDB\u548c\u97f3\u4e50\u95ee\u7b54\u57fa\u51c6ArtistMus\uff0c\u5e94\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\u663e\u8457\u63d0\u5347\u97f3\u4e50\u95ee\u7b54\u7684\u51c6\u786e\u7387\u548c\u63a8\u7406\u80fd\u529b\uff0c\u63a8\u52a8\u97f3\u4e50\u9886\u57df\u7684\u77e5\u8bc6\u578b\u95ee\u7b54\u7814\u7a76\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u57df\u95ee\u7b54\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5728\u97f3\u4e50\u76f8\u5173\u63a8\u7406\u4e2d\u6548\u679c\u6709\u9650\uff0c\u539f\u56e0\u662f\u9884\u8bad\u7ec3\u6570\u636e\u4e2d\u7f3a\u4e4f\u97f3\u4e50\u77e5\u8bc6\u3002\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u548c\u8ba1\u7b97\u97f3\u4e50\u5b66\u867d\u6d89\u53ca\u7ed3\u6784\u5316\u548c\u591a\u6a21\u6001\u7406\u89e3\uff0c\u4f46\u7f3a\u4e4f\u652f\u6301\u57fa\u4e8e\u827a\u672f\u5bb6\u5143\u6570\u636e\u548c\u5386\u53f2\u80cc\u666f\u7684\u97f3\u4e50\u95ee\u7b54\u8d44\u6e90\u3002", "method": "\u63d0\u51faMusWikiDB\uff0c\u4e00\u4e2a\u5305\u542b320\u4e07\u6bb5\u843d\u3001\u81ea144K\u97f3\u4e50\u76f8\u5173\u7ef4\u57fa\u767e\u79d1\u9875\u9762\u6784\u5efa\u7684\u5411\u91cf\u6570\u636e\u5e93\uff1b\u5e76\u63d0\u51faArtistMus\uff0c\u4e00\u4e2a\u5305\u542b1000\u4e2a\u95ee\u9898\u3001\u6db5\u76d6500\u4f4d\u591a\u6837\u5316\u827a\u672f\u5bb6\u7684\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u914d\u5907\u6d41\u6d3e\u3001\u51fa\u9053\u5e74\u4efd\u3001\u4e3b\u9898\u7b49\u5143\u6570\u636e\u3002\u5229\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6a21\u578b\u8fdb\u884c\u97f3\u4e50\u95ee\u7b54\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u540c\u65f6\u91c7\u7528RAG\u98ce\u683c\u7684\u5fae\u8c03\u6539\u8fdb\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRAG\u663e\u8457\u63d0\u5347\u4e86\u97f3\u4e50\u95ee\u7b54\u7684\u4e8b\u5b9e\u51c6\u786e\u7387\uff0c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u63d0\u5347\u6700\u9ad8\u8fbe56.8\u4e2a\u767e\u5206\u70b9\uff08\u4f8b\u5982Qwen3 8B\u4ece35.0\u63d0\u5347\u523091.8\uff09\uff0c\u63a5\u8fd1\u4e13\u6709\u6a21\u578b\u6c34\u5e73\u3002RAG\u98ce\u683c\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u4e8b\u5b9e\u56de\u5fc6\u548c\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u5728\u57df\u5185\u548c\u57df\u5916\u57fa\u51c6\u6d4b\u8bd5\u5747\u6709\u6539\u5584\u3002MusWikiDB\u7684\u51c6\u786e\u7387\u6bd4\u901a\u7528\u7ef4\u57fa\u767e\u79d1\u8bed\u6599\u9ad8\u7ea66\u4e2a\u767e\u5206\u70b9\uff0c\u68c0\u7d22\u901f\u5ea6\u5feb40%\u3002", "conclusion": "MusWikiDB\u548cArtistMus\u8d44\u6e90\u7684\u53d1\u5e03\u63a8\u52a8\u4e86\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u548c\u9886\u57df\u7279\u5b9a\u95ee\u7b54\u7814\u7a76\uff0c\u5960\u5b9a\u4e86\u68c0\u7d22\u589e\u5f3a\u63a8\u7406\u65b9\u6cd5\u5728\u5bcc\u542b\u6587\u5316\u5185\u6db5\u9886\u57df\uff08\u5982\u97f3\u4e50\uff09\u5e94\u7528\u7684\u57fa\u7840\u3002"}}
{"id": "2512.05551", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05551", "abs": "https://arxiv.org/abs/2512.05551", "authors": ["Jai Lal Lulla", "Raula Gaikovina Kula", "Christoph Treude"], "title": "Automated Code Review Assignments: An Alternative Perspective of Code Ownership on GitHub", "comment": "15 pages, 9 figures, 8 tables", "summary": "Code ownership is central to ensuring accountability and maintaining quality in large-scale software development. Yet, as external threats such as software supply chain attacks on project health and quality assurance increase, mechanisms for assigning and enforcing responsibility have become increasingly critical. In 2017, GitHub introduced the CODEOWNERS feature, which automatically designates reviewers for specific files to strengthen accountability and protect critical parts of the codebase. Despite its potential, little is known about how CODEOWNERS is actually adopted and practiced. We present the first large-scale empirical study of CODEOWNERS usage across over 844,000 pull requests with 1.9 million comments and over 2 million reviews. We identify 10,287 code owners to track their review activities. Results indicate that codeowners tend to adhere the rules specified in the CODEOWNERS file, exhibit similar collaborative behaviours to traditional metrics of ownership, but tend to contribute to a smoother and faster PR workflow over time. Finally, using regression discontinuity design (RDD) analysis, we find that repositories adopting CODEOWNERS experience shifts in review dynamics, as ownership redistributes review responsibilities away from core developers. Our results position CODEOWNERS as a promising yet underutilized mechanism for improving software governance and resilience. We discuss how projects can leverage this alternative ownership method as a perspective to enhance security, accountability, and workflow efficiency in open-source development.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u5b9e\u8bc1\u8c03\u67e5\u4e86GitHub\u7684CODEOWNERS\u529f\u80fd\u7684\u4f7f\u7528\u60c5\u51b5\uff0c\u5206\u6790\u4e86\u5176\u5bf9\u4ee3\u7801\u5ba1\u67e5\u884c\u4e3a\u548c\u5de5\u4f5c\u6d41\u7a0b\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u7b49\u5916\u90e8\u5a01\u80c1\u589e\u52a0\uff0c\u786e\u4fdd\u4ee3\u7801\u6240\u6709\u6743\u4ee5\u63d0\u5347\u8d23\u4efb\u660e\u786e\u6027\u548c\u4ee3\u7801\u8d28\u91cf\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u4f46\u5bf9CODEOWNERS\u5b9e\u9645\u4f7f\u7528\u60c5\u51b5\u4e86\u89e3\u6709\u9650\u3002", "method": "\u901a\u8fc7\u5bf9844,000\u591a\u4e2aPull Request\u30011.9\u767e\u4e07\u6761\u8bc4\u8bba\u548c2\u767e\u4e07\u6761\u5ba1\u67e5\u8bb0\u5f55\u7684\u6570\u636e\u5206\u6790\uff0c\u5e76\u4f7f\u7528\u56de\u5f52\u65ad\u70b9\u8bbe\u8ba1\uff08RDD\uff09\u65b9\u6cd5\u8bc4\u4f30CODEOWNERS\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0CODEOWNERS\u7528\u6237\u4e25\u683c\u9075\u5b88\u89c4\u5219\uff0c\u8868\u73b0\u51fa\u4e0e\u4f20\u7edf\u6240\u6709\u6743\u7c7b\u4f3c\u7684\u534f\u4f5c\u884c\u4e3a\uff0c\u80fd\u4fc3\u8fdb\u66f4\u6d41\u7545\u3001\u66f4\u5feb\u901f\u7684PR\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4e14\u5ba1\u67e5\u804c\u8d23\u4ece\u6838\u5fc3\u5f00\u53d1\u8005\u5206\u6563\u51fa\u53bb\u3002", "conclusion": "CODEOWNERS\u6709\u52a9\u4e8e\u4f18\u5316\u4ee3\u7801\u5ba1\u67e5\u6d41\u7a0b\uff0c\u5c06\u5ba1\u67e5\u804c\u8d23\u4ece\u6838\u5fc3\u5f00\u53d1\u8005\u8f6c\u79fb\u51fa\u6765\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u6cbb\u7406\u548c\u5b89\u5168\u6027\uff0c\u4ecd\u6709\u8f83\u5927\u6f5c\u529b\u672a\u88ab\u5145\u5206\u5229\u7528\u3002"}}
{"id": "2512.05464", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05464", "abs": "https://arxiv.org/abs/2512.05464", "authors": ["Panatchakorn Anantaprayoon", "Nataliia Babina", "Jad Tarifi", "Nima Asgharbeygi"], "title": "Dynamic Alignment for Collective Agency: Toward a Scalable Self-Improving Framework for Open-Ended LLM Alignment", "comment": "8 pages, 4 figures, to appear in AAAI 2026 AIGOV Workshop", "summary": "Large Language Models (LLMs) are typically aligned with human values using preference data or predefined principles such as helpfulness, honesty, and harmlessness. However, as AI systems progress toward Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI), such value systems may become insufficient. In addition, human feedback-based alignment remains resource-intensive and difficult to scale. While AI-feedback-based self-improving alignment methods have been explored as a scalable alternative, they have largely remained constrained to conventional alignment values. In this work, we explore both a more holistic alignment objective and a scalable, self-improving alignment approach. Aiming to transcend conventional alignment norms, we introduce Collective Agency (CA)-a unified and open-ended alignment value that encourages integrated agentic capabilities. We also propose Dynamic Alignment-an alignment framework that enables an LLM to iteratively align itself. Dynamic Alignment comprises two key components: (1) automated training dataset generation with LLMs, and (2) a self-rewarding mechanism, where the policy model evaluates its own output candidates and assigns rewards for GRPO-based learning. Experimental results demonstrate that our approach successfully aligns the model to CA while preserving general NLP capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u4f53\u4ee3\u7406\u7684\u65b0\u578b\u5bf9\u9f50\u4ef7\u503c\u53ca\u52a8\u6001\u81ea\u6211\u5bf9\u9f50\u6846\u67b6\uff0c\u5b9e\u73b0\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u3001\u81ea\u6211\u6539\u8fdb\u5bf9\u9f50\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u4eba\u7c7b\u53cd\u9988\u7684\u5bf9\u9f50\u65b9\u6cd5\u8d44\u6e90\u5bc6\u96c6\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u4e14\u73b0\u6709\u5bf9\u9f50\u4f53\u7cfb\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3AGI\u548cASI\u9636\u6bb5\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u52a8\u6001\u5bf9\u9f50\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5305\u542b\u81ea\u52a8\u8bad\u7ec3\u6570\u636e\u96c6\u751f\u6210\u548c\u57fa\u4e8eGRPO\u5b66\u4e60\u7684\u81ea\u6211\u5956\u52b1\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u6210\u529f\u5730\u8ba9\u6a21\u578b\u5b9e\u73b0\u4e86\u96c6\u4f53\u4ee3\u7406\uff08CA\uff09\u8fd9\u4e00\u7edf\u4e00\u5f00\u6e90\u7684\u5bf9\u9f50\u4ef7\u503c\u89c2\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u4e00\u822c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8bc1\u660e\u901a\u8fc7\u52a8\u6001\u5bf9\u9f50\u673a\u5236\uff0cLLM\u80fd\u591f\u5728\u4fdd\u6301\u901a\u7528\u80fd\u529b\u7684\u540c\u65f6\uff0c\u81ea\u6211\u63d0\u5347\u5e76\u5b9e\u73b0\u66f4\u5168\u9762\u7684\u4ef7\u503c\u5bf9\u9f50\u3002"}}
{"id": "2512.05653", "categories": ["cs.SE", "cs.LO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.05653", "abs": "https://arxiv.org/abs/2512.05653", "authors": ["Stefan Sch\u00f6nig", "Leo Poss", "Fabrizio Maria Maggi"], "title": "Executing Discrete/Continuous Declarative Process Specifications via Complex Event Processing", "comment": "Preprint", "summary": "Traditional Business Process Management (BPM) focuses on discrete events and fails to incorporate critical continuous sensor data in cyber-physical environments. Hybrid declarative specifications, utilizing Signal Temporal Logic (STL), address this limitation by allowing constraints over both discrete events and real-valued signals. However, existing work has been limited to monitoring and post-hoc conformance checking. This paper introduces a novel Complex Event Processing (CEP)-based execution architecture that enables the real-time execution and enforcement of hybrid declarative models. Our three-layer approach integrates STL-inspired predicates into the execution flow, allowing the system to actively trigger activities and enforce process boundaries based on continuous sensor behavior. This approach bridges the gap between hybrid specification and operational control.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u57fa\u4e8eCEP\u7684\u4e09\u5c42\u6267\u884c\u67b6\u6784\uff0c\u5229\u7528STL\u8c13\u8bcd\u5b9e\u73b0\u5bf9\u8fde\u7eed\u4f20\u611f\u5668\u6570\u636e\u4e0e\u79bb\u6563\u4e8b\u4ef6\u7684\u540c\u6b65\u76d1\u63a7\u548c\u5b9e\u65f6\u6d41\u7a0b\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u7f51\u7edc\u7269\u7406\u73af\u5883\u4e2d\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406\u7684\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u4e1a\u52a1\u6d41\u7a0b\u7ba1\u7406(BPM)\u4ec5\u5173\u6ce8\u79bb\u6563\u4e8b\u4ef6\uff0c\u672a\u80fd\u6709\u6548\u6574\u5408\u5173\u952e\u7684\u8fde\u7eed\u4f20\u611f\u5668\u6570\u636e\uff0c\u9650\u5236\u4e86\u5176\u5728\u7f51\u7edc\u7269\u7406\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u590d\u6742\u4e8b\u4ef6\u5904\u7406(CEP)\u7684\u6267\u884c\u67b6\u6784\uff0c\u91c7\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(STL)\u542f\u53d1\u7684\u8c13\u8bcd\uff0c\u7ed3\u5408\u4e09\u5c42\u65b9\u6cd5\uff0c\u5c06\u6df7\u5408\u58f0\u660e\u5f0f\u89c4\u8303\u5b9e\u65f6\u6267\u884c\u548c\u7ba1\u63a7\u878d\u5408\u8fdb\u6d41\u7a0b\u6267\u884c\u3002", "result": "\u8be5\u67b6\u6784\u5141\u8bb8\u7cfb\u7edf\u57fa\u4e8e\u8fde\u7eed\u4f20\u611f\u5668\u884c\u4e3a\uff0c\u4e3b\u52a8\u89e6\u53d1\u6d3b\u52a8\u548c enforce \u6d41\u7a0b\u8fb9\u754c\uff0c\u5b9e\u73b0\u4e86\u6df7\u5408\u89c4\u8303\u4e0e\u5b9e\u65f6\u64cd\u4f5c\u63a7\u5236\u7684\u7ed3\u5408\u3002", "conclusion": "\u63d0\u51fa\u7684CEP\u6267\u884c\u67b6\u6784\u6709\u6548\u5f25\u8865\u4e86\u4f20\u7edfBPM\u5bf9\u8fde\u7eed\u4fe1\u53f7\u5904\u7406\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u6df7\u5408\u58f0\u660e\u5f0f\u6a21\u578b\u7684\u5b9e\u65f6\u6267\u884c\u4e0e\u4e3b\u52a8\u7ba1\u7406\u3002"}}
{"id": "2512.05501", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05501", "abs": "https://arxiv.org/abs/2512.05501", "authors": ["Panuthep Tasawong", "Jian Gang Ngui", "Alham Fikri Aji", "Trevor Cohn", "Peerat Limkonchotiwat"], "title": "SEA-SafeguardBench: Evaluating AI Safety in SEA Languages and Cultures", "comment": "Under review", "summary": "Safeguard models help large language models (LLMs) detect and block harmful content, but most evaluations remain English-centric and overlook linguistic and cultural diversity. Existing multilingual safety benchmarks often rely on machine-translated English data, which fails to capture nuances in low-resource languages. Southeast Asian (SEA) languages are underrepresented despite the region's linguistic diversity and unique safety concerns, from culturally sensitive political speech to region-specific misinformation. Addressing these gaps requires benchmarks that are natively authored to reflect local norms and harm scenarios. We introduce SEA-SafeguardBench, the first human-verified safety benchmark for SEA, covering eight languages, 21,640 samples, across three subsets: general, in-the-wild, and content generation. The experimental results from our benchmark demonstrate that even state-of-the-art LLMs and guardrails are challenged by SEA cultural and harm scenarios and underperform when compared to English texts.", "AI": {"tldr": "\u672c\u7814\u7a76\u521b\u5efa\u4e86\u9996\u4e2a\u4e1c\u5357\u4e9a\u8bed\u8a00\u5b89\u5168\u6027\u57fa\u51c6\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u5730\u533a\u6587\u5316\u548c\u5b89\u5168\u95ee\u9898\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u76ee\u524d\u5927\u90e8\u5206\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5b89\u5168\u6027\u7684\u8bc4\u4f30\u805a\u7126\u4e8e\u82f1\u6587\uff0c\u5ffd\u7565\u4e86\u8bed\u8a00\u548c\u6587\u5316\u591a\u6837\u6027\uff0c\u7279\u522b\u662f\u4e1c\u5357\u4e9a\u8bed\u8a00\u5728\u5b89\u5168\u6027\u6d4b\u8bd5\u4e2d\u7684\u7f3a\u5931\u3002\u73b0\u6709\u591a\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\u4f9d\u8d56\u4e8e\u82f1\u6587\u6570\u636e\u7684\u673a\u5668\u7ffb\u8bd1\uff0c\u65e0\u6cd5\u6355\u6349\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u5fae\u5999\u5dee\u5f02\u548c\u5730\u57df\u7279\u6709\u7684\u5b89\u5168\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e86SEA-SafeguardBench\u6570\u636e\u96c6\uff0c\u5305\u542b8\u79cd\u4e1c\u5357\u4e9a\u8bed\u8a00\u7684\u672c\u5730\u4eba\u5de5\u64b0\u5199\u6837\u672c\uff0c\u5e76\u901a\u8fc7\u4e09\u79cd\u5b50\u96c6\u8be6\u7ec6\u6d4b\u8bc4\u6a21\u578b\u7684\u5b89\u5168\u6027\u80fd\u3002", "result": "\u63d0\u51fa\u4e86SEA-SafeguardBench\uff0c\u8fd9\u662f\u7b2c\u4e00\u4e2a\u9762\u5411\u4e1c\u5357\u4e9a\u5730\u533a\u7684\u4eba\u5de5\u9a8c\u8bc1\u5b89\u5168\u57fa\u51c6\uff0c\u6db5\u76d68\u79cd\u8bed\u8a00\u300121640\u4e2a\u6837\u672c\uff0c\u5206\u4e3a\u901a\u7528\u3001\u771f\u5b9e\u73af\u5883\u548c\u5185\u5bb9\u751f\u6210\u4e09\u4e2a\u5b50\u96c6\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u73b0\u6709\u6700\u5148\u8fdb\u7684LLMs\u548c\u5b89\u5168\u673a\u5236\u5728\u5e94\u5bf9\u4e1c\u5357\u4e9a\u6587\u5316\u548c\u5b89\u5168\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u8fdc\u900a\u4e8e\u5bf9\u82f1\u6587\u6570\u636e\u7684\u5904\u7406\u6548\u679c\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8bed\u8a00\u6a21\u578b\u53ca\u5176\u5b89\u5168\u673a\u5236\u5728\u4e1c\u5357\u4e9a\u8bed\u8a00\u548c\u6587\u5316\u5b89\u5168\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e9f\u9700\u5f00\u53d1\u9488\u5bf9\u591a\u8bed\u8a00\u548c\u6587\u5316\u7684\u672c\u5730\u5316\u5b89\u5168\u8bc4\u4f30\u65b9\u6cd5\u3002"}}
{"id": "2512.05703", "categories": ["cs.SE", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.05703", "abs": "https://arxiv.org/abs/2512.05703", "authors": ["Zhuangbin Chen", "Juzheng Zheng", "Zibin Zheng"], "title": "Metronome: Differentiated Delay Scheduling for Serverless Functions", "comment": "Accepted to ICSE 2026", "summary": "Function-as-a-Service (FaaS) computing is an emerging cloud computing paradigm for its ease-of-management and elasticity. However, optimizing scheduling for serverless functions remains challenging due to their dynamic and event-driven nature. While data locality has been proven effective in traditional cluster computing systems through delay scheduling, its application in serverless platforms remains largely unexplored. In this paper, we systematically evaluate existing delay scheduling methods in serverless environments and identify three key observations: 1) delay scheduling benefits vary significantly based on function input characteristics; 2) serverless computing exhibits more complex locality patterns than cluster computing systems, encompassing both data locality and infrastructure locality; and 3) heterogeneous function execution times make rule-based delay thresholds ineffective. Based on these insights, we propose Metronome, a differentiated delay scheduling framework that employs predictive mechanisms to identify optimal locality-aware nodes for individual functions. Metronome leverages an online Random Forest Regression model to forecast function execution times across various nodes, enabling informed delay decisions while preventing SLA violations. Our implementation on OpenLambda shows that Metronome significantly outperforms baselines, achieving 64.88%-95.83% reduction in mean execution time for functions, while maintaining performance advantages under increased concurrency levels and ensuring SLA compliance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Metronome\uff0c\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u7684\u5dee\u5f02\u5316\u5ef6\u8fdf\u8c03\u5ea6\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u670d\u52a1\u5668\u65e0\u51fd\u6570\u8c03\u5ea6\u6548\u7387\uff0c\u7f29\u77ed\u6267\u884c\u65f6\u95f4\u5e76\u4fdd\u969c\u670d\u52a1\u6c34\u5e73\u534f\u8bae\u3002", "motivation": "\u73b0\u6709\u7684\u5ef6\u8fdf\u8c03\u5ea6\u65b9\u6cd5\u5728\u670d\u52a1\u5668\u65e0\u5e73\u53f0\u4e2d\u6548\u679c\u4e0d\u660e\u663e\uff0c\u539f\u56e0\u5728\u4e8e\u51fd\u6570\u8f93\u5165\u7279\u5f81\u591a\u6837\u3001\u5c40\u90e8\u6027\u6a21\u5f0f\u590d\u6742\u4ee5\u53ca\u51fd\u6570\u6267\u884c\u65f6\u95f4\u5f02\u8d28\u6027\u5f3a\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u5728\u7ebf\u968f\u673a\u68ee\u6797\u56de\u5f52\u6a21\u578b\u9884\u6d4b\u51fd\u6570\u5728\u4e0d\u540c\u8282\u70b9\u7684\u6267\u884c\u65f6\u95f4\uff0c\u63d0\u4f9b\u57fa\u4e8e\u6570\u636e\u548c\u57fa\u7840\u8bbe\u65bd\u5c40\u90e8\u6027\u7684\u8c03\u5ea6\u51b3\u7b56\u3002", "result": "Metronome\u5728OpenLambda\u5e73\u53f0\u4e0a\u5b9e\u73b0\u5e76\u6d4b\u8bd5\uff0c\u5e73\u5747\u6267\u884c\u65f6\u95f4\u51cf\u5c1164.88%-95.83%\uff0c\u5728\u9ad8\u5e76\u53d1\u73af\u5883\u4e0b\u4f9d\u7136\u8868\u73b0\u51fa\u8f83\u5f3a\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "Metronome\u57fa\u4e8e\u9884\u6d4b\u673a\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u670d\u52a1\u5668\u65e0\u51fd\u6570\u7684\u5dee\u5f02\u5316\u5ef6\u8fdf\u8c03\u5ea6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u51fd\u6570\u5e73\u5747\u6267\u884c\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86SLA\u5408\u89c4\u6027\u3002"}}
{"id": "2512.05537", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05537", "abs": "https://arxiv.org/abs/2512.05537", "authors": ["Namu Park", "Farzad Ahmed", "Zhaoyi Sun", "Kevin Lybarger", "Ethan Breinhorst", "Julie Hu", "Ozlem Uzuner", "Martin Gunn", "Meliha Yetisgen"], "title": "Automated Identification of Incidentalomas Requiring Follow-Up: A Multi-Anatomy Evaluation of LLM-Based and Supervised Approaches", "comment": null, "summary": "Objective: To evaluate large language models (LLMs) against supervised baselines for fine-grained, lesion-level detection of incidentalomas requiring follow-up, addressing the limitations of current document-level classification systems.\n  Methods: We utilized a dataset of 400 annotated radiology reports containing 1,623 verified lesion findings. We compared three supervised transformer-based encoders (BioClinicalModernBERT, ModernBERT, Clinical Longformer) against four generative LLM configurations (Llama 3.1-8B, GPT-4o, GPT-OSS-20b). We introduced a novel inference strategy using lesion-tagged inputs and anatomy-aware prompting to ground model reasoning. Performance was evaluated using class-specific F1-scores.\n  Results: The anatomy-informed GPT-OSS-20b model achieved the highest performance, yielding an incidentaloma-positive macro-F1 of 0.79. This surpassed all supervised baselines (maximum macro-F1: 0.70) and closely matched the inter-annotator agreement of 0.76. Explicit anatomical grounding yielded statistically significant performance gains across GPT-based models (p < 0.05), while a majority-vote ensemble of the top systems further improved the macro-F1 to 0.90. Error analysis revealed that anatomy-aware LLMs demonstrated superior contextual reasoning in distinguishing actionable findings from benign lesions.\n  Conclusion: Generative LLMs, when enhanced with structured lesion tagging and anatomical context, significantly outperform traditional supervised encoders and achieve performance comparable to human experts. This approach offers a reliable, interpretable pathway for automated incidental finding surveillance in radiology workflows.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u75c5\u7076\u6807\u8bb0\u548c\u89e3\u5256\u5b66\u63d0\u793a\u7684\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u5728\u7ec6\u7c92\u5ea6\u5076\u53d1\u75c5\u7076\u68c0\u6d4b\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u6a21\u578b\uff0c\u6027\u80fd\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\uff0c\u4fc3\u8fdb\u4e86\u653e\u5c04\u5b66\u81ea\u52a8\u5316\u76d1\u6d4b\u7684\u8fdb\u6b65\u3002", "motivation": "\u5f53\u524d\u7684\u5f71\u50cf\u62a5\u544a\u5206\u7c7b\u7cfb\u7edf\u5728\u68c0\u6d4b\u9700\u8981\u968f\u8bbf\u7684\u5076\u53d1\u75c5\u7076\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5728\u7ec6\u7c92\u5ea6\u7684\u75c5\u7076\u7ea7\u522b\u4e0a\u3002\u8be5\u7814\u7a76\u65e8\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8fd9\u4e00\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u5176\u4e0e\u76d1\u7763\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u7684\u6548\u679c\u3002", "method": "\u5229\u7528\u5305\u542b1623\u4e2a\u7ecf\u9a8c\u8bc1\u75c5\u7076\u7684400\u4efd\u6807\u6ce8\u653e\u5c04\u5b66\u62a5\u544a\u6570\u636e\u96c6\uff0c\u6bd4\u8f83\u4e09\u79cd\u76d1\u7763\u7684transformer\u7f16\u7801\u5668\uff08BioClinicalModernBERT, ModernBERT, Clinical Longformer\uff09\u548c\u56db\u79cd\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u914d\u7f6e\uff08Llama 3.1-8B, GPT-4o, GPT-OSS-20b\uff09\uff0c\u5e76\u5f15\u5165\u4e86\u75c5\u7076\u6807\u8bb0\u8f93\u5165\u53ca\u89e3\u5256\u5b66\u611f\u77e5\u63d0\u793a\u7684\u65b0\u63a8\u7406\u7b56\u7565\u3002\u91c7\u7528\u7c7b\u522b\u7279\u5f02\u7684F1\u5206\u6570\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u57fa\u4e8e\u89e3\u5256\u4fe1\u606f\u7684GPT-OSS-20b\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u5076\u53d1\u75c5\u7076\u9633\u6027\u5b8f\u89c2F1\u8fbe0.79\uff0c\u8d85\u8fc7\u6240\u6709\u76d1\u7763\u57fa\u7ebf\uff08\u6700\u9ad80.70\uff09\u4e14\u63a5\u8fd1\u4eba\u5de5\u6ce8\u91ca\u8005\u4e00\u81f4\u6027\uff080.76\uff09\u3002\u660e\u786e\u7684\u89e3\u5256\u5b9a\u4f4d\u663e\u8457\u63d0\u5347\u4e86GPT\u6a21\u578b\u6027\u80fd\uff08p<0.05\uff09\uff0c\u96c6\u6210\u9876\u5c16\u6a21\u578b\u8fdb\u4e00\u6b65\u5c06\u5b8f\u89c2F1\u63d0\u5347\u81f30.90\u3002\u9519\u8bef\u5206\u6790\u663e\u793a\uff0c\u89e3\u5256\u77e5\u8bc6\u8f85\u52a9\u7684LLMs\u5728\u533a\u5206\u53ef\u5904\u7406\u4e0e\u826f\u6027\u75c5\u7076\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "\u7ed3\u6784\u5316\u75c5\u7076\u6807\u8bb0\u548c\u89e3\u5256\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u76d1\u7763\u7f16\u7801\u5668\uff0c\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u9760\u4e14\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u5076\u53d1\u75c5\u7076\u76d1\u6d4b\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u653e\u5c04\u5b66\u4e34\u5e8a\u5de5\u4f5c\u6d41\u3002"}}
{"id": "2512.05716", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.05716", "abs": "https://arxiv.org/abs/2512.05716", "authors": ["Zhiling Deng", "Juepeng Wang", "Zhuangbin Chen"], "title": "MicroRacer: Detecting Concurrency Bugs for Cloud Service Systems", "comment": null, "summary": "Modern cloud applications delivering global services are often built on distributed systems with a microservice architecture. In such systems, end-to-end user requests traverse multiple different services and machines, exhibiting intricate interactions. Consequently, cloud service systems are vulnerable to concurrency bugs, which pose significant challenges to their reliability. Existing methods for concurrency bug detection often fall short due to their intrusive nature and inability to handle the architectural complexities of microservices. To address these limitations, we propose MicroRacer, a non-intrusive and automated framework for detecting concurrency bugs in such environments. By dynamically instrumenting widely-used libraries at runtime, MicroRacer collects detailed trace data without modifying the application code. Such data are utilized to analyze the happened-before relationship and resource access patterns of common operations within service systems. Based on this information, MicroRacer identifies suspicious concurrent operations and employs a three-stage validation process to test and confirm concurrency bugs. Experiments on open-source microservice benchmarks with replicated industrial bugs demonstrate MicroRacer's effectiveness and efficiency in accurately detecting and pinpointing concurrency issues.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faMicroRacer\uff0c\u4e00\u79cd\u9762\u5411\u5fae\u670d\u52a1\u67b6\u6784\u7684\u975e\u4fb5\u5165\u3001\u81ea\u52a8\u5316\u5e76\u53d1\u9519\u8bef\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u5e93\u63d2\u88c5\u6536\u96c6\u8fd0\u884c\u65f6\u6570\u636e\uff0c\u7cbe\u51c6\u53d1\u73b0\u5e76\u53d1bug\uff0c\u6709\u6548\u63d0\u5347\u4e91\u670d\u52a1\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u4ee3\u4e91\u5e94\u7528\u57fa\u4e8e\u5fae\u670d\u52a1\u67b6\u6784\u7ec4\u6210\uff0c\u7528\u6237\u8bf7\u6c42\u8de8\u591a\u670d\u52a1\u548c\u673a\u5668\uff0c\u5bfc\u81f4\u7cfb\u7edf\u590d\u6742\u4e14\u6613\u53d7\u5e76\u53d1\u9519\u8bef\u5f71\u54cd\uff0c\u73b0\u6709\u65b9\u6cd5\u68c0\u6d4b\u5e76\u53d1bug\u4fb5\u5165\u6027\u5f3a\u4e14\u96be\u4ee5\u5904\u7406\u5fae\u670d\u52a1\u67b6\u6784\u7684\u590d\u6742\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u975e\u4fb5\u5165\u4e14\u81ea\u52a8\u5316\u7684\u5e76\u53d1\u9519\u8bef\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1MicroRacer\u6846\u67b6\uff0c\u901a\u8fc7\u8fd0\u884c\u65f6\u52a8\u6001\u63d2\u88c5\u5e38\u7528\u5e93\uff0c\u65e0\u9700\u4fee\u6539\u5e94\u7528\u4ee3\u7801\uff0c\u6536\u96c6\u8be6\u7ec6\u7684\u8c03\u7528\u8ddf\u8e2a\u6570\u636e\uff0c\u5206\u6790\u670d\u52a1\u7cfb\u7edf\u4e2d\u64cd\u4f5c\u7684happened-before\u5173\u7cfb\u548c\u8d44\u6e90\u8bbf\u95ee\u6a21\u5f0f\uff0c\u8bc6\u522b\u53ef\u7591\u7684\u5e76\u53d1\u64cd\u4f5c\uff0c\u5e76\u91c7\u7528\u4e09\u9636\u6bb5\u9a8c\u8bc1\u6d41\u7a0b\u68c0\u6d4b\u786e\u8ba4\u5e76\u53d1\u9519\u8bef\u3002", "result": "MicroRacer\u80fd\u591f\u51c6\u786e\u9ad8\u6548\u5730\u68c0\u6d4b\u548c\u5b9a\u4f4d\u5e76\u53d1\u9519\u8bef\uff0c\u5728\u591a\u79cd\u5f00\u6e90\u5fae\u670d\u52a1\u57fa\u51c6\u6d4b\u8bd5\u53ca\u590d\u5236\u7684\u5de5\u4e1a\u5e76\u53d1\u9519\u8bef\u4e0a\u53d6\u5f97\u826f\u597d\u6548\u679c\u3002", "conclusion": "MicroRacer\u5728\u5fae\u670d\u52a1\u73af\u5883\u4e0b\u5c55\u793a\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u5e76\u53d1\u9519\u8bef\u68c0\u6d4b\u80fd\u529b\uff0c\u514b\u670d\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u4e3a\u63d0\u5347\u4e91\u5e94\u7528\u7684\u53ef\u9760\u6027\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.05580", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05580", "abs": "https://arxiv.org/abs/2512.05580", "authors": ["Aurprita Mahmood", "Sabrin alam", "Neloy kumer Sagor", "Md. Abdul Hadi", "Md. Sehab Al Islam", "Minhajul Islam"], "title": "Structured Reasoning with Tree-of-Thoughts for Bengali Math Word Problems", "comment": null, "summary": "Mathematical Word Problems (MWPs) are among the most challenging tasks in natural language processing because they require both linguistic understanding and multi-step numerical reasoning. While Chain-of-Thought (CoT) prompting has shown promise, its linear structure often propagates errors, limiting overall effectiveness. To address this limitation, we present the a systematic study of Tree-of-Thought (ToT) reasoning for Bengali MWPs using the SOMADHAN dataset. Owing to computational and token-cost constraints, we evaluate a curated set of 100 representative problems across multiple large language models (LLMs), including GPT-OSS and LLaMA variants, under standard prompting, CoT, and ToT strategies. Our results show that CoT improves baseline accuracy from 78% (standard prompting) to 83% on average, while ToT further increases performance by up to 5 percentage points, achieving 88% accuracy with GPT-OSS-120B. These improvements highlight that ToT is particularly effective in medium-to-large-scale models but may offer less advantage for smaller ones. Overall, our findings establish ToT as a robust framework for solving mathematical problems in low-resource languages such as Bengali. More broadly, this study shows that structured reasoning methods like ToT can provide more reliable and globally consistent outcomes than CoT, paving the way for better reasoning strategies in multilingual NLP.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u6570\u5b66\u9898\u63d0\u51fa\u4e86\u57fa\u4e8e\u6811\u72b6\u7ed3\u6784\u7684\u63a8\u7406\u65b9\u6cd5ToT\uff0c\u76f8\u6bd4\u73b0\u6709\u7684\u7ebf\u6027\u63a8\u7406CoT\u6709\u663e\u8457\u63d0\u5347\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u7684\u6570\u5b66\u9898\u7406\u89e3\u4e0e\u89e3\u7b54\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684CoT\u63a8\u7406\u56e0\u5176\u7ebf\u6027\u7ed3\u6784\u6613\u5bfc\u81f4\u9519\u8bef\u4f20\u64ad\uff0c\u9650\u5236\u4e86\u6027\u80fd\u7684\u63d0\u5347\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u63a8\u7406\u7ed3\u6784\u6765\u89e3\u51b3\u590d\u6742\u7684\u591a\u6b65\u6570\u5b57\u63a8\u7406\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u5e76\u7cfb\u7edf\u7814\u7a76\u4e86\u57fa\u4e8e\u6811\u7ed3\u6784\u7684\u63a8\u7406\u65b9\u6cd5Tree-of-Thought (ToT)\uff0c\u5e76\u5728\u5b5f\u52a0\u62c9\u8bed\u6570\u5b66\u6587\u5b57\u9898\uff08MWPs\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u6807\u51c6\u63d0\u793a\u3001Chain-of-Thought (CoT) \u548cTree-of-Thought (ToT)\u4e09\u79cd\u7b56\u7565\u5728\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-OSS\u548cLLaMA\u53d8\u4f53\uff09\u4e0a\u7684\u8868\u73b0\u3002", "result": "CoT\u63d0\u793a\u76f8\u6bd4\u6807\u51c6\u63d0\u793a\u5c06\u51c6\u786e\u7387\u4ece78%\u63d0\u5347\u523083%\uff0c\u800cToT\u65b9\u6cd5\u5728GPT-OSS-120B\u6a21\u578b\u4e0a\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e865\u4e2a\u767e\u5206\u70b9\uff0c\u8fbe\u523088%\u7684\u51c6\u786e\u7387\u3002ToT\u5bf9\u4e2d\u5927\u578b\u6a21\u578b\u6548\u679c\u660e\u663e\u4f18\u4e8e\u5c0f\u6a21\u578b\u3002", "conclusion": "ToT\u63a8\u7406\u6846\u67b6\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6570\u5b66\u95ee\u9898\u4e0a\u5c55\u73b0\u51fa\u66f4\u9c81\u68d2\u548c\u9ad8\u6548\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u7ebf\u6027CoT\u65b9\u6cd5\uff0c\u4e3a\u591a\u8bed\u8a00\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u590d\u6742\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.05887", "categories": ["cs.SE", "cs.LG", "cs.PL"], "pdf": "https://arxiv.org/pdf/2512.05887", "abs": "https://arxiv.org/abs/2512.05887", "authors": ["Sairam Vaidya", "Marcel B\u00f6hme", "Loris D'Antoni"], "title": "Bootstrapping Fuzzers for Compilers of Low-Resource Language Dialects Using Language Models", "comment": null, "summary": "Modern extensible compiler frameworks-such as MLIR-enable rapid creation of domain-specific language dialects. This flexibility, however, makes correctness harder to ensure as the same extensibility that accelerates development also complicates maintaining the testing infrastructure. Extensible languages require automated test generation that is both dialect-agnostic (works across dialects without manual adaptation) and dialect-effective (targets dialect-specific features to find bugs). Existing approaches typically sacrifice one of these goals by either requiring manually constructed seed corpora for each dialect, or by failing to be effective. We present a dialect-agnostic and dialect-effective grammar-based and coverage-guided fuzzing approach for extensible compilers that combines two key insights from existing work: (i) the grammars of dialects, which already encode the structural and type constraints, can often be extracted automatically from the dialect specification; and (ii) these grammars can be used in combination with pre-trained large language models to automatically generate representative and diverse seed inputs from the full dialect space without requiring any manual input or training data. These seeds can then be used to bootstrap coverage-guided fuzzers. We built this approach into a tool, Germinator. When evaluated on six MLIR projects spanning 91 dialects, Germinator generated seeds improve line coverage by 10-120% over grammar-based baselines. We compare against grammar-based baselines because they are the only class of existing automatic seed generators that can be applied uniformly across MLIR's heterogeneous dialect ecosystem. Germinator discovers 88 previously unknown bugs (40 confirmed), including 23 in dialects with no prior automated test generators, demonstrating effective and controllable testing of low-resource dialects at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6269\u5c55\u6027\u7f16\u8bd1\u5668\u7684\u65b9\u8a00\u65e0\u5173\u4e14\u65b9\u8a00\u6709\u6548\u7684\u57fa\u4e8e\u8bed\u6cd5\u548c\u8986\u76d6\u5f15\u5bfc\u7684\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u7ed3\u5408\u4e86\u4ece\u65b9\u8a00\u89c4\u8303\u81ea\u52a8\u63d0\u53d6\u8bed\u6cd5\u53ca\u5229\u7528\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u6837\u5316\u79cd\u5b50\u8f93\u5165\u7684\u6280\u672f\u3002", "motivation": "\u73b0\u4ee3\u53ef\u6269\u5c55\u7f16\u8bd1\u5668\u6846\u67b6\u867d\u7136\u52a0\u901f\u4e86\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u65b9\u8a00\u7684\u5f00\u53d1\uff0c\u4f46\u6d4b\u8bd5\u57fa\u7840\u8bbe\u65bd\u7ef4\u62a4\u590d\u6742\uff0c\u9700\u5b9e\u73b0\u65e2\u5bf9\u65b9\u8a00\u65e0\u5173\u53c8\u5bf9\u65b9\u8a00\u6709\u6548\u7684\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u3002", "method": "\u63d0\u51fa\u4ece\u65b9\u8a00\u89c4\u8303\u81ea\u52a8\u63d0\u53d6\u8bed\u6cd5\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u591a\u6837\u5316\u4ee3\u8868\u6027\u79cd\u5b50\uff0c\u8fdb\u800c\u5f15\u5bfc\u57fa\u4e8e\u8986\u76d6\u7684\u6a21\u7cca\u6d4b\u8bd5\u3002", "result": "\u5728\u5305\u542b91\u4e2a\u65b9\u8a00\u76846\u4e2aMLIR\u9879\u76ee\u4e2d\uff0cGerminator\u751f\u6210\u7684\u79cd\u5b50\u4f7f\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u534710-120%\uff0c\u53d1\u73b088\u4e2a\u672a\u77e5\u6f0f\u6d1e\uff0c\u5176\u4e2d40\u4e2a\u5df2\u786e\u8ba4\uff0c\u8986\u76d6\u4e86\u4e4b\u524d\u65e0\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u768423\u4e2a\u65b9\u8a00\u3002", "conclusion": "Germinator\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86MLIR\u9879\u76ee\u4e2d\u591a\u65b9\u8a00\u7684\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u53d1\u73b0\u4e86\u5927\u91cf\u672a\u77e5\u6f0f\u6d1e\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u65b9\u8a00\u4e2d\u5c55\u73b0\u4e86\u5f3a\u5927\u6d4b\u8bd5\u80fd\u529b\u3002"}}
{"id": "2512.05647", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05647", "abs": "https://arxiv.org/abs/2512.05647", "authors": ["Giorgos Antoniou", "Giorgos Filandrianos", "Aggelos Vlachos", "Giorgos Stamou", "Lampros Kollimenos", "Konstantinos Skianis", "Michalis Vazirgiannis"], "title": "A Greek Government Decisions Dataset for Public-Sector Analysis and Insight", "comment": null, "summary": "We introduce an open, machine-readable corpus of Greek government decisions sourced from the national transparency platform Diavgeia. The resource comprises 1 million decisions, featuring and high-quality raw text extracted from PDFs. It is released with raw extracted text in Markdown format, alongside a fully reproducible extraction pipeline. Beyond the core dataset, we conduct qualitative analyses to explore boilerplate patterns and design a retrieval-augmented generation (RAG) task by formulating a set of representative questions, creating high-quality answers, and evaluating a baseline RAG system on its ability to retrieve and reason over public decisions. This evaluation demonstrates the potential of large-scale public-sector corpora to support advanced information access and transparency through structured retrieval and reasoning over governmental documents, and highlights how such a RAG pipeline could simulate a chat-based assistant capable of interactively answering questions about public decisions. Due to its scale, quality, and domain coverage, the corpus can also serve as high-value pre-training or fine-tuning material for new Language Models (LMs) and Large Language Models (LLMs) respectively, including specialized models for legal and governmental domains, and as a foundation for novel approaches in domain adaptation, knowledge-grounded generation, and explainable AI. Finally, we discuss limitations, outline future directions, and make both the data and the code accessible.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5305\u542b\u5e0c\u814a\u653f\u5e9c\u51b3\u7b56\u7684\u5f00\u653e\u673a\u5668\u53ef\u8bfb\u8bed\u6599\u5e93\uff0c\u5305\u542b100\u4e07\u4efd\u51b3\u7b56\u7684\u9ad8\u8d28\u91cf\u6587\u672c\u6570\u636e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u8be5\u8bed\u6599\u5e93\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4fe1\u606f\u8bbf\u95ee\u548c\u900f\u660e\u5ea6\u65b9\u9762\u7684\u6f5c\u529b\u3002", "motivation": "\u63d0\u5347\u516c\u5171\u90e8\u95e8\u6587\u6863\u7684\u4fe1\u606f\u8bbf\u95ee\u80fd\u529b\u548c\u900f\u660e\u5ea6\uff0c\u63a8\u52a8\u5927\u578b\u516c\u5171\u9886\u57df\u8bed\u6599\u5e93\u5728\u6cd5\u5f8b\u53ca\u653f\u5e9c\u9886\u57df\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u53caAI\u89e3\u91ca\u6027\u65b9\u9762\u7684\u5e94\u7528\u3002", "method": "\u6536\u96c6\u5e0c\u814a\u653f\u5e9c\u51b3\u7b56\u6587\u672c\uff0c\u63d0\u53d6\u9ad8\u8d28\u91cfMarkdown\u683c\u5f0f\u6587\u672c\uff0c\u6784\u5efa\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4efb\u52a1\uff0c\u8bbe\u8ba1\u4ee3\u8868\u6027\u95ee\u9898\u548c\u9ad8\u8d28\u91cf\u7b54\u6848\uff0c\u5e76\u8bc4\u4f30\u57fa\u7ebfRAG\u7cfb\u7edf\u7684\u68c0\u7d22\u53ca\u63a8\u7406\u80fd\u529b\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u5e0c\u814a\u653f\u5e9c\u51b3\u7b56\u8bed\u6599\u5e93\uff0c\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u4e2a\u57fa\u7ebfRAG\u7cfb\u7edf\u5728\u6587\u672c\u68c0\u7d22\u548c\u63a8\u7406\u4e2d\u7684\u6709\u6548\u6027\uff0c\u516c\u5f00\u4e86\u6570\u636e\u548c\u4ee3\u7801\uff0c\u5c55\u793a\u4e86\u663e\u8457\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u8be5\u8bed\u6599\u5e93\u4e3a\u653f\u5e9c\u6587\u6863\u7684\u7ed3\u6784\u5316\u68c0\u7d22\u548c\u63a8\u7406\u63d0\u4f9b\u4e86\u53ef\u80fd\uff0c\u652f\u6301\u6cd5\u52a1\u548c\u653f\u5e9c\u9886\u57df\u7684\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff0c\u4fc3\u8fdb\u4fe1\u606f\u900f\u660e\u548c\u53ef\u89e3\u91caAI\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.05908", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.05908", "abs": "https://arxiv.org/abs/2512.05908", "authors": ["Amirkia Rafiei Oskooei", "S. Selcan Yukcu", "Mehmet Cevheri Bozoglan", "Mehmet S. Aktas"], "title": "Natural Language Summarization Enables Multi-Repository Bug Localization by LLMs in Microservice Architectures", "comment": "Accepted at LLM4Code Workshop, ICSE 2026", "summary": "Bug localization in multi-repository microservice architectures is challenging due to the semantic gap between natural language bug reports and code, LLM context limitations, and the need to first identify the correct repository. We propose reframing this as a natural language reasoning task by transforming codebases into hierarchical NL summaries and performing NL-to-NL search instead of cross-modal retrieval. Our approach builds context-aware summaries at file, directory, and repository levels, then uses a two-phase search: first routing bug reports to relevant repositories, then performing top-down localization within those repositories. Evaluated on DNext, an industrial system with 46 repositories and 1.1M lines of code, our method achieves Pass@10 of 0.82 and MRR of 0.50, significantly outperforming retrieval baselines and agentic RAG systems like GitHub Copilot and Cursor. This work demonstrates that engineered natural language representations can be more effective than raw source code for scalable bug localization, providing an interpretable repository -> directory -> file search path, which is vital for building trust in enterprise AI tools by providing essential transparency.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5c06\u4ee3\u7801\u8f6c\u4e3a\u5206\u5c42\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff0c\u5e76\u91c7\u7528\u4e24\u9636\u6bb5\u7684\u81ea\u7136\u8bed\u8a00\u641c\u7d22\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u4ed3\u5e93\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u7f3a\u9677\u5b9a\u4f4d\u95ee\u9898\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u667a\u80fd\u68c0\u7d22\u5de5\u5177\uff0c\u4e14\u80fd\u63d0\u4f9b\u6e05\u6670\u7684\u5b9a\u4f4d\u8def\u5f84\u4ee5\u589e\u5f3a\u4f01\u4e1aAI\u7684\u4fe1\u4efb\u5ea6\u3002", "motivation": "\u591a\u4ed3\u5e93\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\uff0c\u7f3a\u9677\u62a5\u544a\u4e0e\u4ee3\u7801\u4e4b\u95f4\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\uff0c\u4e14\u5927\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u9650\u5236\u548c\u4ed3\u5e93\u8bc6\u522b\u9700\u6c42\u4f7f\u5f97\u7f3a\u9677\u5b9a\u4f4d\u53d8\u5f97\u590d\u6742\u3002", "method": "\u63d0\u51fa\u5c06\u4ee3\u7801\u5e93\u8f6c\u6362\u4e3a\u5206\u5c42\u7684\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff08\u6587\u4ef6\u7ea7\u3001\u76ee\u5f55\u7ea7\u3001\u4ed3\u5e93\u7ea7\uff09\uff0c\u4f7f\u7528\u4e24\u9636\u6bb5\u641c\u7d22\u7b56\u7565\uff1a\u5148\u5c06\u7f3a\u9677\u62a5\u544a\u8def\u7531\u5230\u76f8\u5173\u4ed3\u5e93\uff0c\u518d\u5728\u4ed3\u5e93\u5185\u8fdb\u884c\u81ea\u9876\u5411\u4e0b\u7684\u5b9a\u4f4d\u3002", "result": "\u5728\u5305\u542b46\u4e2a\u4ed3\u5e93\u3001110\u4e07\u884c\u4ee3\u7801\u7684\u5de5\u4e1a\u7cfb\u7edfDNext\u4e0a\uff0c\u65b9\u6cd5\u5b9e\u73b0\u4e86Pass@10\u4e3a0.82\uff0cMRR\u4e3a0.50\uff0c\u663e\u8457\u4f18\u4e8e\u68c0\u7d22\u57fa\u7ebf\u548c\u7c7b\u4f3cGitHub Copilot\u3001Cursor\u7684\u667a\u80fd\u68c0\u7d22\u7cfb\u7edf\u3002", "conclusion": "\u901a\u8fc7\u5c06\u591a\u4ed3\u5e93\u5fae\u670d\u52a1\u67b6\u6784\u4e2d\u7684\u4ee3\u7801\u8f6c\u6362\u4e3a\u5206\u5c42\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff0c\u5e76\u91c7\u7528\u5206\u9636\u6bb5\u7684\u81ea\u7136\u8bed\u8a00\u641c\u7d22\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u7f3a\u9677\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2512.05658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05658", "abs": "https://arxiv.org/abs/2512.05658", "authors": ["Pietro Ferrazzi", "Aitor Soroa", "Rodrigo Agerri"], "title": "Grounded Multilingual Medical Reasoning for Question Answering with Large Language Models", "comment": "Under Review", "summary": "Large Language Models (LLMs) with reasoning capabilities have recently demonstrated strong potential in medical Question Answering (QA). Existing approaches are largely English-focused and primarily rely on distillation from general-purpose LLMs, raising concerns about the reliability of their medical knowledge. In this work, we present a method to generate multilingual reasoning traces grounded in factual medical knowledge. We produce 500k traces in English, Italian, and Spanish, using a retrievalaugmented generation approach over medical information from Wikipedia. The traces are generated to solve medical questions drawn from MedQA and MedMCQA, which we extend to Italian and Spanish. We test our pipeline in both in-domain and outof-domain settings across Medical QA benchmarks, and demonstrate that our reasoning traces improve performance both when utilized via in-context learning (few-shot) and supervised fine-tuning, yielding state-of-the-art results among 8B-parameter LLMs. We believe that these resources can support the development of safer, more transparent clinical decision-support tools in multilingual settings. We release the full suite of resources: reasoning traces, translated QA datasets, Medical-Wikipedia, and fine-tuned models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u5b9e\u533b\u5b66\u77e5\u8bc6\u7684\u591a\u8bed\u8a00\u63a8\u7406\u8def\u5f84\u751f\u6210\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u95ee\u7b54\u6a21\u578b\u8868\u73b0\uff0c\u652f\u6301\u591a\u8bed\u8a00\u4e34\u5e8a\u51b3\u7b56\u5de5\u5177\u7684\u5f00\u53d1\uff0c\u540c\u65f6\u516c\u5f00\u4e86\u76f8\u5173\u8d44\u6e90\u3002", "motivation": "\u73b0\u6709\u533b\u5b66\u95ee\u7b54\u591a\u96c6\u4e2d\u4e8e\u82f1\u8bed\uff0c\u4e14\u591a\u4f9d\u8d56\u901a\u7528\u5927\u6a21\u578b\u84b8\u998f\uff0c\u533b\u5b66\u77e5\u8bc6\u53ef\u9760\u6027\u5b58\u7591\uff0c\u56e0\u6b64\u63d0\u51fa\u751f\u6210\u57fa\u4e8e\u4e8b\u5b9e\u533b\u5b66\u77e5\u8bc6\u7684\u591a\u8bed\u8a00\u63a8\u7406\u8def\u5f84\u4ee5\u589e\u5f3a\u6a21\u578b\u63a8\u7406\u80fd\u529b\u548c\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u591a\u8bed\u8a00\u63a8\u7406\u8def\u5f84\u65b9\u6cd5\uff0c\u57fa\u4e8e\u7ef4\u57fa\u767e\u79d1\u533b\u5b66\u4fe1\u606f\uff0c\u751f\u6210\u8986\u76d6\u82f1\u8bed\u3001\u610f\u5927\u5229\u8bed\u548c\u897f\u73ed\u7259\u8bed\u768450\u4e07\u6761\u63a8\u7406\u8def\u5f84\uff0c\u5e76\u5728MedQA\u548cMedMCQA\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u548c\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u5728\u9886\u57df\u5185\u5916\u7684\u533b\u5b66\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\uff0c\u751f\u6210\u7684\u63a8\u7406\u8def\u5f84\u65e0\u8bba\u5728\u5c11\u6837\u672c\u5185\u5b66\u4e60\u548c\u76d1\u7763\u5fae\u8c03\u4e2d\u5747\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u8fbe\u5230\u4e86\u540c\u7c7b8B\u53c2\u6570\u6a21\u578b\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u751f\u6210\u591a\u8bed\u8a00\u7684\u533b\u5b66\u63a8\u7406\u8def\u5f84\uff0c\u6709\u6548\u63d0\u5347\u4e86\u533b\u5b66\u95ee\u7b54\u7684\u6027\u80fd\uff0c\u5c24\u5176\u57288B\u53c2\u6570\u89c4\u6a21\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u8fbe\u5230\u6700\u65b0\u6c34\u5e73\uff0c\u4fc3\u8fdb\u4e86\u66f4\u5b89\u5168\u3001\u66f4\u900f\u660e\u7684\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u5de5\u5177\u53d1\u5c55\u3002"}}
{"id": "2512.05665", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.05665", "abs": "https://arxiv.org/abs/2512.05665", "authors": ["Shuai Dong", "Siyuan Wang", "Xingyu Liu", "Zhongyu Wei"], "title": "Interleaved Latent Visual Reasoning with Selective Perceptual Modeling", "comment": "11 pages, 6 figures. Code available at https://github.com/XD111ds/ILVR", "summary": "Interleaved reasoning paradigms enhance Multimodal Large Language Models (MLLMs) with visual feedback but are hindered by the prohibitive computational cost of repeatedly re-encoding pixel-dense images. A promising alternative, latent visual reasoning, circumvents this bottleneck yet currently forces a critical trade-off: methods either sacrifice precise perceptual modeling by over-compressing features or fail to model dynamic problems due to static, non-interleaved structures. We introduce Interleaved Latent Visual Reasoning (ILVR), a framework that unifies dynamic state evolution with precise perceptual modeling. ILVR interleaves textual generation with latent visual representations that act as specific, evolving cues for subsequent reasoning. To enable this, we employ a self-supervision strategy where a Momentum Teacher Model selectively distills relevant features from helper images into sparse supervision targets. This adaptive selection mechanism guides the model to autonomously generate context-aware visual signals. Extensive experiments on multimodal reasoning benchmarks demonstrate that ILVR significantly outperforms existing approaches, effectively bridging the gap between fine-grained perception and sequential multimodal reasoning.", "AI": {"tldr": "ILVR\u662f\u4e00\u79cd\u7ed3\u5408\u52a8\u6001\u72b6\u6001\u6f14\u5316\u4e0e\u7cbe\u51c6\u611f\u77e5\u5efa\u6a21\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u89c6\u89c9\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u6587\u672c\u751f\u6210\u4e0e\u6f5c\u5728\u89c6\u89c9\u8868\u793a\u4ea4\u66ff\u8fdb\u884c\uff0c\u5b9e\u73b0\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u89c6\u89c9\u4fe1\u53f7\u81ea\u6211\u76d1\u7763\uff0c\u663e\u8457\u63d0\u5347\u591a\u6a21\u6001\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u91cd\u7f16\u7801\u50cf\u7d20\u5bc6\u96c6\u56fe\u50cf\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u6f5c\u5728\u89c6\u89c9\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u8fc7\u5ea6\u538b\u7f29\u7279\u5f81\u5bfc\u81f4\u611f\u77e5\u4e0d\u7cbe\u786e\u6216\u9759\u6001\u7ed3\u6784\u65e0\u6cd5\u52a8\u6001\u63a8\u7406\u7684\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u4e86Interleaved Latent Visual Reasoning (ILVR)\u6846\u67b6\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ea4\u66ff\u751f\u6210\u6587\u672c\u4e0e\u6f5c\u5728\u89c6\u89c9\u8868\u793a\uff0c\u5e76\u5229\u7528\u52a8\u91cf\u6559\u5e08\u6a21\u578b\u81ea\u76d1\u7763\u9009\u62e9\u6027\u84b8\u998f\u56fe\u50cf\u7279\u5f81\u4f5c\u4e3a\u7a00\u758f\u76d1\u7763\uff0c\u6307\u5bfc\u751f\u6210\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u89c6\u89c9\u4fe1\u53f7\u3002", "result": "\u5728\u591a\u6a21\u6001\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cILVR\u663e\u8457\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\uff0c\u6210\u529f\u6865\u63a5\u4e86\u7ec6\u7c92\u5ea6\u611f\u77e5\u548c\u5e8f\u8d2f\u591a\u6a21\u6001\u63a8\u7406\u4e4b\u95f4\u7684\u9e3f\u6c9f\u3002", "conclusion": "ILVR\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u591a\u6a21\u6001\u63a8\u7406\u4e2d\u89c6\u89c9\u7279\u5f81\u8fc7\u5ea6\u538b\u7f29\u6216\u9759\u6001\u7ed3\u6784\u65e0\u6cd5\u52a8\u6001\u6f14\u5316\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u611f\u77e5\u7cbe\u5ea6\u4e0e\u5e8f\u8d2f\u63a8\u7406\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2512.05671", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05671", "abs": "https://arxiv.org/abs/2512.05671", "authors": ["Zhitao He", "Haolin Yang", "Zeyu Qin", "Yi R Fung"], "title": "MedTutor-R1: Socratic Personalized Medical Teaching with Multi-Agent Simulation", "comment": "Work In Progress", "summary": "The significant gap between rising demands for clinical training and the scarcity of expert instruction poses a major challenge to medical education. With powerful capabilities in personalized guidance, Large Language Models (LLMs) offer a promising solution to bridge this gap. However, current research focuses mainly on one-on-one knowledge instruction, overlooking collaborative reasoning, a key skill for students developed in teamwork like ward rounds. To this end, we develop ClinEdu, a multi-agent pedagogical simulator with personality-driven patients and diverse student cohorts, enabling controlled testing of complex pedagogical processes and scalable generation of teaching data. Based on ClinEdu, we construct ClinTeach, a large Socratic teaching dialogue dataset that captures the complexities of group instruction. We then train MedTutor-R1, the first multimodal Socratic tutor designed for one-to-many instruction in clinical medical education. MedTutor-R1 is first instruction-tuned on our ClinTeach dataset and then optimized with reinforcement learning, using rewards derived from a three-axis rubric, covering structural fidelity, analytical quality, and clinical safety, to refine its adaptive Socratic strategies. For authentic in-situ assessment, we use simulation-based interactive evaluation that redeploys the tutor back into ClinEdu. Experimental results demonstrate that our MedTutor-R1 outperforms the base model by over 20% in average pedagogical score and is comparable to o3, while also exhibiting high adaptability in handling a varying number of students. This promising performance underscores the effectiveness of our pedagogical simulator, ClinEdu.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u9488\u5bf9\u4e34\u5e8a\u6559\u5b66\u9700\u6c42\u7684\u591a\u667a\u80fd\u4f53\u6559\u5b66\u6a21\u62df\u4e0e\u6570\u636e\u96c6\u6784\u5efa\uff0c\u8bad\u7ec3\u51fa\u9996\u4e2a\u652f\u6301\u4e00\u5bf9\u591a\u82cf\u683c\u62c9\u5e95\u6559\u5b66\u7684\u5927\u578b\u6a21\u578bMedTutor-R1\uff0c\u663e\u8457\u63d0\u5347\u6559\u5b66\u6548\u679c\u5e76\u5177\u5907\u826f\u597d\u7684\u9002\u5e94\u80fd\u529b\u3002", "motivation": "\u4e34\u5e8a\u6559\u5b66\u4e2d\u5b66\u5458\u5bf9\u4e2a\u6027\u5316\u6307\u5bfc\u9700\u6c42\u589e\u957f\uff0c\u4e13\u5bb6\u6559\u5e08\u8d44\u6e90\u4e0d\u8db3\uff0c\u4e14\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u4e00\u5bf9\u4e00\u77e5\u8bc6\u4f20\u6388\uff0c\u5ffd\u89c6\u56e2\u961f\u534f\u4f5c\u63a8\u7406\u8fd9\u4e00\u5173\u952e\u80fd\u529b\u3002", "method": "\u5f00\u53d1\u4e86ClinEdu\u591a\u667a\u80fd\u4f53\u6559\u5b66\u6a21\u62df\u5668\uff0c\u6784\u5efaClinTeach\u5927\u578b\u82cf\u683c\u62c9\u5e95\u6559\u5b66\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u591a\u6a21\u6001\u82cf\u683c\u62c9\u5e95\u6559\u5b66\u6a21\u578bMedTutor-R1\u3002MedTutor-R1\u5148\u5728ClinTeach\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\uff0c\u5956\u52b1\u4f9d\u636e\u7ed3\u6784\u4e25\u8c28\u6027\u3001\u5206\u6790\u8d28\u91cf\u548c\u4e34\u5e8a\u5b89\u5168\u6027\u4e09\u9879\u6307\u6807\u3002\u91c7\u7528\u57fa\u4e8e\u6a21\u62df\u7684\u4ea4\u4e92\u5f0f\u8bc4\u4f30\uff0c\u5c06\u6a21\u578b\u91cd\u65b0\u90e8\u7f72\u4e8eClinEdu\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "MedTutor-R1\u5728\u5e73\u5747\u6559\u5b66\u8bc4\u5206\u4e0a\u6bd4\u57fa\u7840\u6a21\u578b\u63d0\u534720%\u4ee5\u4e0a\uff0c\u8868\u73b0\u4e0eo3\u6a21\u578b\u76f8\u5f53\uff0c\u4e14\u80fd\u9002\u5e94\u4e0d\u540c\u4eba\u6570\u7684\u5b66\u751f\uff0c\u663e\u793a\u51fa\u9ad8\u5ea6\u9002\u5e94\u6027\u548c\u6559\u5b66\u6709\u6548\u6027\u3002", "conclusion": "ClinEdu\u6559\u5b66\u6a21\u62df\u5668\u548cClinTeach\u6570\u636e\u96c6\u6709\u6548\u652f\u6491\u4e86\u4e34\u5e8a\u591a\u5b66\u751f\u534f\u4f5c\u6559\u5b66\u7684\u7814\u7a76\uff0cMedTutor-R1\u5c55\u793a\u4e86\u5148\u8fdb\u7684\u591a\u6a21\u6001\u82cf\u683c\u62c9\u5e95\u6559\u5b66\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u533b\u5b66\u6559\u80b2\u4e2d\u4e2a\u6027\u5316\u548c\u56e2\u961f\u534f\u4f5c\u6280\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.05681", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05681", "abs": "https://arxiv.org/abs/2512.05681", "authors": ["Tereza Novotna", "Jakub Harasta"], "title": "Retrieving Semantically Similar Decisions under Noisy Institutional Labels: Robust Comparison of Embedding Methods", "comment": "The manuscript has been accepted for presentation as a short paper at the 38th International Conference on Legal Knowledge and Information Systems (JURIX 2025) in Torino, Italy", "summary": "Retrieving case law is a time-consuming task predominantly carried out by querying databases. We provide a comparison of two models in three different settings for Czech Constitutional Court decisions: (i) a large general-purpose embedder (OpenAI), (ii) a domain-specific BERT-trained from scratch on ~30,000 decisions using sliding windows and attention pooling. We propose a noise-aware evaluation including IDF-weighted keyword overlap as graded relevance, binarization via two thresholds (0.20 balanced, 0.28 strict), significance via paired bootstrap, and an nDCG diagnosis supported with qualitative analysis. Despite modest absolute nDCG (expected under noisy labels), the general OpenAI embedder decisively outperforms the domain pre-trained BERT in both settings at @10/@20/@100 across both thresholds; differences are statistically significant. Diagnostics attribute low absolutes to label drift and strong ideals rather than lack of utility. Additionally, our framework is robust enough to be used for evaluation under a noisy gold dataset, which is typical when handling data with heterogeneous labels stemming from legacy judicial databases.", "AI": {"tldr": "\u672c\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u6a21\u578b\u5728\u6377\u514b\u5baa\u6cd5\u6cd5\u9662\u5224\u51b3\u68c0\u7d22\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u8003\u8651\u566a\u58f0\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u68c0\u7d22\u5224\u4f8b\u662f\u8017\u65f6\u4efb\u52a1\uff0c\u73b0\u6709\u6570\u636e\u5b58\u5728\u6807\u7b7e\u566a\u58f0\u548c\u5f02\u8d28\u6027\uff0c\u4e9f\u9700\u8bc4\u4f30\u65b9\u6cd5\u80fd\u9002\u5e94\u566a\u58f0\u6807\u7b7e\u7684\u73b0\u5b9e\u73af\u5883\uff0c\u540c\u65f6\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u7684\u68c0\u7d22\u6027\u80fd\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u566a\u58f0\u611f\u77e5\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u62ecIDF\u52a0\u6743\u5173\u952e\u8bcd\u91cd\u53e0\u4f5c\u4e3a\u76f8\u5173\u5ea6\u8bc4\u5206\u3001\u4e0d\u540c\u9608\u503c\u7684\u4e8c\u503c\u5316\u3001\u6210\u5bf9\u81ea\u52a9\u6cd5\u663e\u8457\u6027\u68c0\u9a8c\uff0c\u4ee5\u53canDCG\u6307\u6807\u7ed3\u5408\u5b9a\u6027\u5206\u6790\u3002", "result": "OpenAI\u7684\u5927\u578b\u901a\u7528\u5d4c\u5165\u6a21\u578b\u5728@10/@20/@100\u6307\u6807\u4e0b\u663e\u8457\u4f18\u4e8e\u9886\u57df\u7279\u5b9aBERT\u6a21\u578b\uff0c\u8bc4\u4f30\u65b9\u6cd5\u8bc1\u660e\u5728\u5e26\u6709\u566a\u58f0\u6807\u7b7e\u7684\u53f8\u6cd5\u6570\u636e\u5e93\u4e2d\u4f9d\u7136\u6709\u6548\u4e14\u5177\u9c81\u68d2\u6027\u3002", "conclusion": "\u901a\u7528OpenAI\u5d4c\u5165\u6a21\u578b\u5728\u4e0d\u540c\u8bbe\u7f6e\u548c\u9608\u503c\u4e0b\u5747\u663e\u8457\u4f18\u4e8e\u9886\u57df\u7279\u5b9a\u8bad\u7ec3\u7684BERT\u6a21\u578b\uff0c\u5c3d\u7ba1\u8bc4\u4ef7\u6307\u6807\u7edd\u5bf9\u503c\u504f\u4f4e\uff0c\u53cd\u6620\u4e86\u6570\u636e\u6807\u7b7e\u566a\u58f0\u53ca\u6807\u7b7e\u6f02\u79fb\u95ee\u9898\u3002"}}
{"id": "2512.05700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05700", "abs": "https://arxiv.org/abs/2512.05700", "authors": ["Ben Malin", "Tatiana Kalganova", "Nikolaos Boulgouris"], "title": "Faithfulness metric fusion: Improving the evaluation of LLM trustworthiness across domains", "comment": "9 pages, conference paper", "summary": "We present a methodology for improving the accuracy of faithfulness evaluation in Large Language Models (LLMs). The proposed methodology is based on the combination of elementary faithfulness metrics into a combined (fused) metric, for the purpose of improving the faithfulness of LLM outputs. The proposed strategy for metric fusion deploys a tree-based model to identify the importance of each metric, which is driven by the integration of human judgements evaluating the faithfulness of LLM responses. This fused metric is demonstrated to correlate more strongly with human judgements across all tested domains for faithfulness. Improving the ability to evaluate the faithfulness of LLMs, allows for greater confidence to be placed within models, allowing for their implementation in a greater diversity of scenarios. Additionally, we homogenise a collection of datasets across question answering and dialogue-based domains and implement human judgements and LLM responses within this dataset, allowing for the reproduction and trialling of faithfulness evaluation across domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u79cd\u57fa\u7840\u5fe0\u5b9e\u5ea6\u6307\u6807\u878d\u5408\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u6811\u6a21\u578b\u7ed3\u5408\u4eba\u5de5\u8bc4\u5224\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u51c6\u786e\u6027\uff0c\u4ee5\u589e\u5f3a\u6a21\u578b\u5728\u66f4\u591a\u5e94\u7528\u573a\u666f\u4e2d\u7684\u53ef\u9760\u6027\u3002", "method": "\u91c7\u7528\u6811\u6a21\u578b\u878d\u5408\u591a\u79cd\u57fa\u7840\u5fe0\u5b9e\u5ea6\u6307\u6807\uff0c\u7ed3\u5408\u4eba\u5de5\u8bc4\u5224\u6570\u636e\u786e\u5b9a\u5404\u6307\u6807\u7684\u91cd\u8981\u6027\uff0c\u6784\u5efa\u878d\u5408\u6307\u6807\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u878d\u5408\u6307\u6807\u5728\u6240\u6709\u6d4b\u8bd5\u9886\u57df\u4e2d\u5747\u4e0e\u4eba\u5de5\u8bc4\u5224\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u76f8\u5173\u6027\uff0c\u5b9e\u73b0\u4e86\u8de8\u9886\u57df\u7684\u5fe0\u5b9e\u5ea6\u8bc4\u4f30\u6548\u679c\u63d0\u5347\uff0c\u5e76\u53d1\u5e03\u4e86\u6807\u51c6\u5316\u6570\u636e\u96c6\u4f9b\u590d\u73b0\u548c\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "conclusion": "\u878d\u5408\u591a\u79cd\u5fe0\u5b9e\u5ea6\u6307\u6807\u5e76\u5229\u7528\u6811\u6a21\u578b\u52a0\u6743\uff0c\u80fd\u66f4\u51c6\u786e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\u5fe0\u5b9e\u5ea6\uff0c\u4e14\u4e0e\u4eba\u5de5\u8bc4\u5224\u9ad8\u5ea6\u76f8\u5173\u3002"}}
{"id": "2512.05732", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05732", "abs": "https://arxiv.org/abs/2512.05732", "authors": ["Ippokratis Pantelidis", "Korbinian Randl", "Aron Henriksson"], "title": "Efficient Text Classification with Conformal In-Context Learning", "comment": "10 pages, 4 tables, 2 figures", "summary": "Large Language Models (LLMs) demonstrate strong in-context learning abilities, yet their effectiveness in text classification depends heavily on prompt design and incurs substantial computational cost. Conformal In-Context Learning (CICLe) has been proposed as a resource-efficient framework that integrates a lightweight base classifier with Conformal Prediction to guide LLM prompting by adaptively reducing the set of candidate classes. However, its broader applicability and efficiency benefits beyond a single domain have not yet been systematically explored. In this paper, we present a comprehensive evaluation of CICLe across diverse NLP classification benchmarks. The results show that CICLe consistently improves over its base classifier and outperforms few-shot prompting baselines when the sample size is sufficient for training the base classifier, and performs comparably in low-data regimes. In terms of efficiency, CICLe reduces the number of shots and prompt length by up to 34.45% and 25.16%, respectively, and enables the use of smaller models with competitive performance. CICLe is furthermore particularly advantageous for text classification tasks with high class imbalance. These findings highlight CICLe as a practical and scalable approach for efficient text classification, combining the robustness of traditional classifiers with the adaptability of LLMs, and achieving substantial gains in data and computational efficiency.", "AI": {"tldr": "CICLe\u901a\u8fc7\u7ed3\u5408\u8f7b\u91cf\u7ea7\u5206\u7c7b\u5668\u548c\u4fdd\u5f62\u9884\u6d4b\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u7684\u6548\u7387\u548c\u6027\u80fd\uff0c\u5c24\u5176\u5728\u6837\u672c\u5145\u8db3\u65f6\u8868\u73b0\u4f18\u8d8a\uff0c\u5e76\u5728\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u4e0a\u663e\u8457\u8282\u7701\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5206\u7c7b\u4e2d\u4f9d\u8d56\u63d0\u793a\u8bbe\u8ba1\u4e14\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u9700\u63a2\u7d22\u4e00\u79cd\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u524d\u63d0\u4e0b\u66f4\u9ad8\u6548\u4e14\u9002\u7528\u66f4\u5e7f\u6cdb\u7684\u5206\u7c7b\u6846\u67b6\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408\u8f7b\u91cf\u7ea7\u57fa\u7840\u5206\u7c7b\u5668\u4e0e\u4fdd\u5f62\u9884\u6d4b\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u7f29\u51cf\u5019\u9009\u7c7b\u522b\u96c6\u5408\uff0c\u4f18\u5316LLM\u7684\u63d0\u793a\u8bbe\u8ba1\uff0c\u964d\u4f4e\u6240\u9700\u7684\u6837\u672c\u6570\u548c\u63d0\u793a\u957f\u5ea6\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002", "result": "CICLe\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c11\u63d0\u793a\u6837\u672c\u6570\u6700\u591a34.45%\uff0c\u51cf\u5c11\u63d0\u793a\u957f\u5ea625.16%\uff0c\u80fd\u7528\u66f4\u5c0f\u6a21\u578b\u8fbe\u5230\u7ade\u4e89\u6027\u80fd\uff0c\u5e76\u5728\u591a\u4e2a\u5206\u7c7b\u57fa\u51c6\u4e2d\u4f18\u4e8e\u57fa\u7ebf\uff0c\u5c24\u5176\u5bf9\u7c7b\u522b\u4e0d\u5747\u8861\u4efb\u52a1\u6548\u679c\u663e\u8457\u3002", "conclusion": "CICLe\u5728\u591a\u4e2aNLP\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u7a33\u5b9a\u4f18\u4e8e\u57fa\u7840\u5206\u7c7b\u5668\u548c\u5c11\u6837\u672c\u63d0\u793a\u65b9\u6cd5\uff0c\u517c\u987e\u6548\u7387\u548c\u6027\u80fd\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u7c7b\u522b\u9ad8\u5ea6\u4e0d\u5e73\u8861\u7684\u4efb\u52a1\uff0c\u5c55\u793a\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u6587\u672c\u5206\u7c7b\u6f5c\u529b\u3002"}}
{"id": "2512.05747", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05747", "abs": "https://arxiv.org/abs/2512.05747", "authors": ["Jinlong Liu", "Mohammed Bahja", "Venelin Kovatchev", "Mark Lee"], "title": "Capturing Classic Authorial Style in Long-Form Story Generation with GRPO Fine-Tuning", "comment": null, "summary": "Recent advances in large language models (LLMs) show impressive performance in open-ended story generation, but fine-grained stylistic control remains limited. Existing methods often rely on shallow cues (e.g., names or topics) to simulate authorial style, without robust evaluation. In this work, we present a training framework for style-conditioned story generation using Group Relative Policy Optimization (GRPO) and a custom multi-reward setup. The style reward is derived from a fine-tuned sentence transformer using authorship verification (AV) signals, combined with content and completeness scores to stabilize long-form narrative generation. We conduct experiments using fiction by Mark Twain, a prominent 19th-century American author, with The Adventures of Huckleberry Finn serving as the reference style exemplar. Our 8B model outperforms larger baselines such as GPT-4o and Claude Sonnet 4 in AV-style metrics, achieving a style score of 0.628 and competitive content quality. Results demonstrate the feasibility of agentic stylistic generation with moderate model size and task-specific training. While the output is clearly style-aligned, narrative completeness remains a challenge, indicating future work is needed to better model global coherence and story resolution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5229\u7528GRPO\u548c\u591a\u91cd\u5956\u52b1\u5b9e\u73b0\u98ce\u683c\u6761\u4ef6\u6545\u4e8b\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u5b9e\u9a8c\u8bc1\u660e8B\u6a21\u578b\u80fd\u6709\u6548\u63a7\u5236\u4f5c\u8005\u98ce\u683c\uff0c\u4f18\u4e8e\u66f4\u5927\u6a21\u578b\uff0c\u4f46\u53d9\u4e8b\u5b8c\u6574\u6027\u4ecd\u9700\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5bf9\u6545\u4e8b\u751f\u6210\u7684\u98ce\u683c\u63a7\u5236\u4f9d\u8d56\u6d45\u5c42\u7279\u5f81\u4e14\u7f3a\u4e4f\u7a33\u5065\u8bc4\u4f30\uff0c\u672c\u6587\u65e8\u5728\u901a\u8fc7\u5f15\u5165\u7ec6\u7c92\u5ea6\u98ce\u683c\u5956\u52b1\u548c\u591a\u91cd\u4f18\u5316\u7b56\u7565\uff0c\u63d0\u5347\u6545\u4e8b\u751f\u6210\u7684\u98ce\u683c\u4e00\u81f4\u6027\u548c\u8d28\u91cf\u3002", "method": "\u5229\u7528Group Relative Policy Optimization\u548c\u81ea\u5b9a\u4e49\u591a\u5956\u52b1\u673a\u5236\uff0c\u57fa\u4e8e\u7ec6\u8c03\u7684\u53e5\u5b50\u53d8\u6362\u5668\u548c\u4f5c\u8005\u9a8c\u8bc1\u4fe1\u53f7\uff0c\u7ed3\u5408\u5185\u5bb9\u548c\u5b8c\u6574\u6027\u5206\u6570\uff0c\u8bad\u7ec3\u98ce\u683c\u6761\u4ef6\u6545\u4e8b\u751f\u6210\u6a21\u578b\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGroup Relative Policy Optimization (GRPO)\u548c\u591a\u91cd\u5956\u52b1\u673a\u5236\u7684\u98ce\u683c\u6761\u4ef6\u6545\u4e8b\u751f\u6210\u8bad\u7ec3\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u7ec6\u5316\u7684\u4f5c\u8005\u9a8c\u8bc1\u4fe1\u53f7\u548c\u5185\u5bb9\u5b8c\u6574\u5ea6\u8bc4\u5206\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u5728\u957f\u7bc7\u53d9\u4e8b\u751f\u6210\u4e2d\u7684\u98ce\u683c\u63a7\u5236\u80fd\u529b\u3002\u5b9e\u9a8c\u4ee5\u9a6c\u514b\u00b7\u5410\u6e29\u7684\u300a\u54c8\u514b\u8d1d\u5229\u00b7\u8d39\u6069\u5386\u9669\u8bb0\u300b\u4e3a\u53c2\u8003\u98ce\u683c\uff0c8B\u53c2\u6570\u6a21\u578b\u5728\u4f5c\u8005\u98ce\u683c\u9a8c\u8bc1\u6307\u6807\u4e0a\u4f18\u4e8e\u66f4\u5927\u89c4\u6a21\u7684GPT-4o\u548cClaude Sonnet 4\uff0c\u98ce\u683c\u5f97\u5206\u8fbe0.628\uff0c\u5185\u5bb9\u8d28\u91cf\u8868\u73b0\u4e5f\u5177\u6709\u7ade\u4e89\u529b\u3002\u7814\u7a76\u9a8c\u8bc1\u4e86\u9002\u5ea6\u6a21\u578b\u89c4\u6a21\u7ed3\u5408\u4efb\u52a1\u4e13\u7528\u8bad\u7ec3\u5373\u53ef\u5b9e\u73b0\u98ce\u683c\u6307\u5bfc\u7684\u6545\u4e8b\u751f\u6210\uff0c\u4f46\u6574\u4f53\u53d9\u4e8b\u8fde\u8d2f\u6027\u548c\u5b8c\u6574\u6027\u4ecd\u6709\u5f85\u6539\u8fdb\u3002", "conclusion": "\u9002\u5ea6\u89c4\u6a21\u6a21\u578b\u5728\u7ed3\u5408GRPO\u548c\u591a\u91cd\u5956\u52b1\u8bad\u7ec3\u4e0b\uff0c\u80fd\u5b9e\u73b0\u660e\u786e\u7684\u4f5c\u8005\u98ce\u683c\u63a7\u5236\uff0c\u8868\u73b0\u4f18\u4e8e\u66f4\u5927\u6a21\u578b\uff0c\u4f46\u53d9\u4e8b\u6574\u4f53\u8fde\u8d2f\u548c\u5b8c\u6574\u6027\u4ecd\u662f\u672a\u6765\u6539\u8fdb\u7684\u91cd\u70b9\u3002"}}
{"id": "2512.05832", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.05832", "abs": "https://arxiv.org/abs/2512.05832", "authors": ["Yifei Tong"], "title": "Heard or Halted? Gender, Interruptions, and Emotional Tone in U.S. Supreme Court Oral Arguments", "comment": "12 pages, 5 figures, 1 table. Includes appendix. Code available at: https://github.com/1TSHARUKA/Emotional_Interruption_Analysis", "summary": "This study examines how interruptions during U.S. Supreme Court oral arguments shape both the semantic content and emotional tone of advocates' speech, with a focus on gendered dynamics in judicial discourse. Using the ConvoKit Supreme Court Corpus (2010-2019), we analyze 12,663 speech chunks from advocate-justice interactions to assess whether interruptions alter the meaning of an advocate's argument and whether interruptions toward female advocates exhibit more negative emotional valence. Semantic shifts are quantified using GloVe-based sentence embeddings, while sentiment is measured through lexicon-based analysis. We find that semantic similarity between pre- and post-interruption speech remains consistently high, suggesting that interruptions do not substantially alter argumentative content. However, interruptions directed at female advocates contain significantly higher levels of negative sentiment. These results deepen empirical understanding of gendered communication in elite institutional settings and demonstrate the value of computational linguistic methods for studying power, discourse, and equity in judicial proceedings.", "AI": {"tldr": "\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662\u8fa9\u8bba\u4e2d\u65ad\u5bf9\u8bba\u70b9\u5185\u5bb9\u5f71\u54cd\u4e0d\u5927\uff0c\u4f46\u9488\u5bf9\u5973\u6027\u7684\u4e2d\u65ad\u5e26\u6709\u66f4\u8d1f\u9762\u60c5\u7eea\uff0c\u53cd\u6620\u53f8\u6cd5\u8bdd\u8bed\u4e2d\u7684\u6027\u522b\u4e0d\u5e73\u7b49\u3002", "motivation": "\u7814\u7a76\u4e2d\u65ad\u5bf9\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662\u53e3\u5934\u8fa9\u8bba\u4e2d\u8fa9\u62a4\u5f8b\u5e08\u53d1\u8a00\u7684\u8bed\u4e49\u5185\u5bb9\u548c\u60c5\u7eea\u57fa\u8c03\u7684\u5f71\u54cd\uff0c\u7279\u522b\u5173\u6ce8\u53f8\u6cd5\u8bdd\u8bed\u4e2d\u7684\u6027\u522b\u52a8\u6001\u3002", "method": "\u4f7f\u75282010-2019\u5e74ConvoKit Supreme Court\u8bed\u6599\u5e93\uff0c\u5206\u679012663\u6bb5\u8fa9\u62a4\u4eba\u4e0e\u6cd5\u5b98\u4e92\u52a8\u7684\u53d1\u8a00\uff0c\u91c7\u7528\u57fa\u4e8eGloVe\u7684\u53e5\u5b50\u5d4c\u5165\u8bc4\u4f30\u8bed\u4e49\u53d8\u5316\uff0c\u57fa\u4e8e\u8bcd\u5178\u7684\u65b9\u6cd5\u8861\u91cf\u60c5\u7eea\u503e\u5411\u3002", "result": "\u53d1\u73b0\u4e2d\u65ad\u524d\u540e\u53d1\u8a00\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u8f83\u9ad8\uff0c\u8bf4\u660e\u4e2d\u65ad\u672a\u663e\u8457\u6539\u53d8\u8bba\u70b9\u5185\u5bb9\uff1b\u4f46\u9488\u5bf9\u5973\u6027\u8fa9\u62a4\u4eba\u7684\u4e2d\u65ad\u60c5\u7eea\u8d1f\u9762\u6027\u663e\u8457\u66f4\u9ad8\u3002", "conclusion": "\u4e2d\u65ad\u867d\u4e0d\u6539\u53d8\u8bba\u70b9\u5185\u5bb9\uff0c\u4f46\u5bf9\u5973\u6027\u8fa9\u62a4\u4eba\u7684\u8bed\u6c14\u8d1f\u9762\u5f71\u54cd\u663e\u8457\uff0c\u63ed\u793a\u4e86\u53f8\u6cd5\u673a\u6784\u4e2d\u7684\u6027\u522b\u6c9f\u901a\u4e0d\u5e73\u7b49\uff0c\u4f53\u73b0\u8ba1\u7b97\u8bed\u8a00\u5b66\u5728\u7814\u7a76\u6743\u529b\u3001\u8bdd\u8bed\u548c\u516c\u6b63\u6027\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2512.05858", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.05858", "abs": "https://arxiv.org/abs/2512.05858", "authors": ["Savir Basil", "Ina Shapiro", "Dan Shapiro", "Ethan Mollick", "Lilach Mollick", "Lennart Meincke"], "title": "Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy", "comment": null, "summary": "This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law.\n  We tested three approaches:\n  -In-Domain Experts: Assigning the model an expert persona (\"you are a physics expert\") matched to the problem type (physics problems) had no significant impact on performance (with the exception of the Gemini 2.0 Flash model).\n  -Off-Domain Experts (Domain-Mismatched): Assigning the model an expert persona (\"you are a physics expert\") not matched to the problem type (law problems) resulted in marginal differences.\n  -Low-Knowledge Personas: We assigned the model negative capability personas (layperson, young child, toddler), which were generally harmful to benchmark accuracy.\n  Across both benchmarks, persona prompts generally did not improve accuracy relative to a no-persona baseline. Expert personas showed no consistent benefit across models, with few exceptions. Domain-mismatched expert personas sometimes degraded performance. Low-knowledge personas often reduced accuracy. These results are about the accuracy of answers only; personas may serve other purposes (such as altering the tone of outputs), beyond improving factual performance.", "AI": {"tldr": "\u8d4b\u4e88AI\u6a21\u578b\u4e13\u5bb6\u6216\u4f4e\u77e5\u8bc6\u89d2\u8272\u5bf9\u5176\u5728\u590d\u6742\u9009\u62e9\u9898\u4e0a\u7684\u8868\u73b0\u65e0\u660e\u663e\u63d0\u5347\uff0c\u4f4e\u77e5\u8bc6\u89d2\u8272\u751a\u81f3\u4f1a\u964d\u4f4e\u51c6\u786e\u7387\uff0c\u663e\u793a\u89d2\u8272\u63d0\u793a\u4e3b\u8981\u5f71\u54cd\u8bed\u8a00\u98ce\u683c\u800c\u975e\u63d0\u5347\u7b54\u9898\u51c6\u786e\u6027\u3002", "motivation": "\u63a2\u7a76\u8d4b\u4e88AI\u6a21\u578b\u4e0d\u540c\u89d2\u8272\u8bbe\u5b9a\uff08\u4e13\u5bb6\u89d2\u8272\u548c\u4f4e\u77e5\u8bc6\u89d2\u8272\uff09\u662f\u5426\u80fd\u63d0\u5347\u5176\u5728\u590d\u6742\u5ba2\u89c2\u9009\u62e9\u9898\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5bf9\u516d\u4e2a\u6a21\u578b\u5728\u6db5\u76d6\u79d1\u5b66\u3001\u5de5\u7a0b\u548c\u6cd5\u5f8b\u7b49\u9886\u57df\u7684\u4e24\u4e2a\u7814\u7a76\u751f\u6c34\u5e73\u7684\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u91c7\u7528\u4e09\u79cd\u89d2\u8272\u8d4b\u503c\u65b9\u6cd5\uff08\u9886\u57df\u4e13\u5bb6\u89d2\u8272\u3001\u975e\u5339\u914d\u9886\u57df\u4e13\u5bb6\u89d2\u8272\u548c\u4f4e\u77e5\u8bc6\u89d2\u8272\uff09\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u9886\u57df\u4e13\u5bb6\u89d2\u8272\u5bf9\u6a21\u578b\u51c6\u786e\u7387\u5f71\u54cd\u4e0d\u663e\u8457\uff0c\u975e\u5339\u914d\u9886\u57df\u4e13\u5bb6\u89d2\u8272\u7565\u5fae\u5f71\u54cd\u8868\u73b0\uff0c\u4f4e\u77e5\u8bc6\u89d2\u8272\u901a\u5e38\u964d\u4f4e\u51c6\u786e\u7387\u3002\u6574\u4f53\u6765\u770b\uff0c\u89d2\u8272\u8d4b\u503c\u672a\u663e\u8457\u63d0\u5347\u6a21\u578b\u51c6\u786e\u7387\u3002", "conclusion": "\u7ed9\u6a21\u578b\u8d4b\u4e88\u4e13\u5bb6\u6216\u4f4e\u77e5\u8bc6\u89d2\u8272\u5e76\u4e0d\u80fd\u666e\u904d\u63d0\u5347\u5176\u89e3\u7b54\u590d\u6742\u9009\u62e9\u9898\u7684\u51c6\u786e\u7387\uff0c\u89d2\u8272\u63d0\u793a\u5728\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u6548\u679c\u6709\u9650\uff0c\u4f46\u53ef\u80fd\u5728\u8c03\u6574\u8bed\u8a00\u98ce\u683c\u7b49\u65b9\u9762\u6709\u5176\u4ed6\u7528\u9014\u3002"}}
{"id": "2512.05863", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.05863", "abs": "https://arxiv.org/abs/2512.05863", "authors": ["Tasnimul Hassan", "Md Faisal Karim", "Haziq Jeelani", "Elham Behnam", "Robert Green", "Fayeq Jeelani Syed"], "title": "Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework", "comment": null, "summary": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical literature to ground the LLM's answers, thereby improving factual correctness and reducing hallucinations. We evaluate the approach on benchmark datasets (PubMedQA and MedMCQA) and show that retrieval augmentation yields measurable improvements in answer accuracy compared to using LLMs alone. Our fine-tuned LLaMA~2 model achieves 71.8% accuracy on PubMedQA, substantially improving over the 55.4% zero-shot baseline, while maintaining transparency by providing source references. We also detail the system design and fine-tuning methodology, demonstrating that grounding answers in retrieved evidence reduces unsupported content by approximately 60%. These results highlight the potential of RAG-augmented open-source LLMs for reliable biomedical QA, pointing toward practical clinical informatics applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u68c0\u7d22\u7684\u533b\u7597\u95ee\u7b54\u7cfb\u7edf\uff0c\u901a\u8fc7\u5fae\u8c03LLaMA 2\u548cFalcon\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u56de\u7b54\u7684\u51c6\u786e\u6027\u548c\u4e8b\u5b9e\u4f9d\u636e\uff0c\u51cf\u5c11\u4e86\u5e7b\u89c9\u751f\u6210\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u95ee\u7b54\u4e2d\u5e94\u7528\u65f6\u9762\u4e34\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u5e7b\u89c9\u751f\u6210\u7684\u95ee\u9898\uff0c\u9700\u8981\u7ed3\u5408\u9886\u57df\u77e5\u8bc6\u63d0\u5347\u56de\u7b54\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u5fae\u8c03\u5f00\u653e\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u533b\u5b66\u6587\u732e\u68c0\u7d22\u5b9e\u73b0\u56de\u7b54\u7684\u4e8b\u5b9e\u4f9d\u636e\uff0c\u63d0\u9ad8\u56de\u7b54\u7684\u6b63\u786e\u6027\u5e76\u964d\u4f4e\u5e7b\u89c9\u7387\u3002", "result": "\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u533b\u7597\u95ee\u7b54\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\uff0c\u51cf\u5c11\u4e86\u65e0\u636e\u652f\u6301\u5185\u5bb9\uff0c\u6807\u5fd7\u7740\u57fa\u4e8e\u68c0\u7d22\u7684\u5f00\u653e\u5927\u6a21\u578b\u5728\u751f\u7269\u533b\u836f\u95ee\u7b54\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u751f\u6210\u6a21\u578b\u80fd\u6709\u6548\u63d0\u5347\u533b\u5b66\u95ee\u7b54\u7684\u51c6\u786e\u6027\u53ca\u53ef\u9760\u6027\uff0c\u4e3a\u4e34\u5e8a\u4fe1\u606f\u5b66\u5e94\u7528\u63d0\u4f9b\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2512.05959", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.05959", "abs": "https://arxiv.org/abs/2512.05959", "authors": ["David Anugraha", "Patrick Amadeus Irawan", "Anshul Singh", "En-Shiun Annie Lee", "Genta Indra Winata"], "title": "M4-RAG: A Massive-Scale Multilingual Multi-Cultural Multimodal RAG", "comment": "Preprint", "summary": "Vision-language models (VLMs) have achieved strong performance in visual question answering (VQA), yet they remain constrained by static training data. Retrieval-Augmented Generation (RAG) mitigates this limitation by enabling access to up-to-date, culturally grounded, and multilingual information; however, multilingual multimodal RAG remains largely underexplored. We introduce M4-RAG, a massive-scale benchmark covering 42 languages and 56 regional dialects and registers, comprising over 80,000 culturally diverse image-question pairs for evaluating retrieval-augmented VQA across languages and modalities. To balance realism with reproducibility, we build a controlled retrieval environment containing millions of carefully curated multilingual documents relevant to the query domains, approximating real-world retrieval conditions while ensuring consistent experimentation. Our systematic evaluation reveals that although RAG consistently benefits smaller VLMs, it fails to scale to larger models and often even degrades their performance, exposing a critical mismatch between model size and current retrieval effectiveness. M4-RAG provides a foundation for advancing next-generation RAG systems capable of reasoning seamlessly across languages, modalities, and cultural contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u8bed\u8a00\u591a\u6a21\u6001\u7684\u68c0\u7d22\u589e\u5f3a\u89c6\u89c9\u95ee\u7b54\u57fa\u51c6M4-RAG\uff0c\u8986\u76d642\u79cd\u8bed\u8a00\u53ca56\u79cd\u65b9\u8a00\uff0c\u5305\u542b8\u4e07\u591a\u6587\u5316\u591a\u6837\u7684\u56fe\u50cf-\u95ee\u9898\u5bf9\uff0c\u65e8\u5728\u8bc4\u4f30\u8de8\u8bed\u8a00\u8de8\u6a21\u6001\u7684\u68c0\u7d22\u589e\u5f3aVQA\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53d7\u9650\u4e8e\u9759\u6001\u8bad\u7ec3\u6570\u636e\uff0c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u6709\u52a9\u4e8e\u83b7\u53d6\u6700\u65b0\u4e14\u591a\u5143\u6587\u5316\u548c\u8bed\u8a00\u4fe1\u606f\uff0c\u4f46\u591a\u8bed\u8a00\u591a\u6a21\u6001\u7684\u68c0\u7d22\u589e\u5f3a\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b\u6570\u767e\u4e07\u591a\u8bed\u8a00\u6587\u6863\u7684\u53d7\u63a7\u68c0\u7d22\u73af\u5883\uff0c\u6a21\u62df\u771f\u5b9e\u68c0\u7d22\u573a\u666f\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u591a\u6a21\u6001\u6570\u636e\u6784\u5efaM4-RAG\u57fa\u51c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u7cfb\u7edf\u8bc4\u4f30\u663e\u793aRAG\u65b9\u6cd5\u5bf9\u5c0f\u6a21\u578b\u6709\u6548\uff0c\u4f46\u5bf9\u5927\u6a21\u578b\u6548\u679c\u4e0b\u964d\uff0c\u66b4\u9732\u6a21\u578b\u89c4\u6a21\u4e0e\u68c0\u7d22\u65b9\u6cd5\u6709\u6548\u6027\u4e4b\u95f4\u7684\u5173\u952e\u4e0d\u5339\u914d\u3002", "conclusion": "\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff08RAG\uff09\u5bf9\u5c0f\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u6709\u6548\uff0c\u4f46\u5bf9\u5927\u578b\u6a21\u578b\u8868\u73b0\u8f83\u5dee\uff0c\u8868\u660e\u5f53\u524d\u68c0\u7d22\u65b9\u6cd5\u4e0e\u5927\u6a21\u578b\u95f4\u5b58\u5728\u6027\u80fd\u5339\u914d\u95ee\u9898\u3002"}}
