<div id=toc></div>

# Table of Contents

- [cs.MA](#cs.MA) [Total: 2]
- [cs.SE](#cs.SE) [Total: 18]


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1] [Structuring Collective Action with LLM-Guided Evolution: From Ill-Structured Problems to Executable Heuristics](https://arxiv.org/abs/2509.20412)
*Kevin Bradley Dsouza,Graham Alexander Watt,Yuri Leonenko,Juan Moreno-Cruz*

Main category: cs.MA

TL;DR: 本文提出了ECHO-MIMIC框架，通过进化搜索生成行为规则和动机信息，成功解决了集体行动中的微观行为与宏观目标难以对齐的问题。


<details>
  <summary>Details</summary>
Motivation: 集体行动问题中个人激励与集体目标难以一致，微观行动与宏观结果的因果关系不明确，缺乏统一的方法将两者有效连接。

Method: 提出ECHO-MIMIC框架，包含两个阶段：ECHO通过进化生成编码行为策略的Python代码片段；MIMIC进化自然语言信息，激励个体采用相应策略；全过程基于大型语言模型驱动的进化搜索，选优策略和激励信息以最大化集体表现。

Result: 在农业景观管理的典型集体行动问题中，ECHO-MIMIC发现了表现优异的行为策略，并生成了有效的激励性信息，成功将个体农民行为与生态连通性目标对齐。

Conclusion: ECHO-MIMIC将复杂的集体行动认知负担转化为简单的个体层面指令，实现了从难以结构化问题到可解的结构化问题的转变，为可扩展和自适应的政策设计开辟了新途径。

Abstract: Collective action problems, which require aligning individual incentives with
collective goals, are classic examples of Ill-Structured Problems (ISPs). For
an individual agent, the causal links between local actions and global outcomes
are unclear, stakeholder objectives often conflict, and no single, clear
algorithm can bridge micro-level choices with macro-level welfare. We present
ECHO-MIMIC, a computational framework that converts this global complexity into
a tractable, Well-Structured Problem (WSP) for each agent by discovering
compact, executable heuristics and persuasive rationales. The framework
operates in two stages: ECHO (Evolutionary Crafting of Heuristics from
Outcomes) evolves snippets of Python code that encode candidate behavioral
policies, while MIMIC (Mechanism Inference & Messaging for
Individual-to-Collective Alignment) evolves companion natural language messages
that motivate agents to adopt those policies. Both phases employ a
large-language-model-driven evolutionary search: the LLM proposes diverse and
context-aware code or text variants, while population-level selection retains
those that maximize collective performance in a simulated environment. We
demonstrate this framework on a canonical ISP in agricultural landscape
management, where local farming decisions impact global ecological
connectivity. Results show that ECHO-MIMIC discovers high-performing heuristics
compared to baselines and crafts tailored messages that successfully align
simulated farmer behavior with landscape-level ecological goals. By coupling
algorithmic rule discovery with tailored communication, ECHO-MIMIC transforms
the cognitive burden of collective action into a simple set of agent-level
instructions, making previously ill-structured problems solvable in practice
and opening a new path toward scalable, adaptive policy design.

</details>


### [2] [RadAgents: Multimodal Agentic Reasoning for Chest X-ray Interpretation with Radiologist-like Workflows](https://arxiv.org/abs/2509.20490)
*Kai Zhang,Corey D Barrett,Jangwon Kim,Lichao Sun,Tara Taghavi,Krishnaram Kenthapadi*

Main category: cs.MA

TL;DR: 本文提出了RadAgents，一种用于胸部X光片解读的多智能体框架，通过任务感知的多模态推理和临床先验，提升系统的临床可解释性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有胸部X光解读方法存在推理不符合临床指南、缺乏视觉与文本多模态融合、无法检测和解决工具间不一致问题，缺乏验证机制的缺陷。

Method: 构建了RadAgents框架，实现多智能体协作，结合临床先验进行任务感知的多模态推理，集成了基于视觉的定位和多模态检索增强，以验证和解决上下文冲突。

Result: 系统生成的输出更加可靠、透明，并与临床实践保持一致，解决了传统方法中推理不连贯和验证不足的问题。

Conclusion: RadAgents框架有效提升了胸部X光图像解读的多模态融合能力和临床可解释性，为复杂临床任务提供了有潜力的新路径。

Abstract: Agentic systems offer a potential path to solve complex clinical tasks
through collaboration among specialized agents, augmented by tool use and
external knowledge bases. Nevertheless, for chest X-ray (CXR) interpretation,
prevailing methods remain limited: (i) reasoning is frequently neither
clinically interpretable nor aligned with guidelines, reflecting mere
aggregation of tool outputs; (ii) multimodal evidence is insufficiently fused,
yielding text-only rationales that are not visually grounded; and (iii) systems
rarely detect or resolve cross-tool inconsistencies and provide no principled
verification mechanisms. To bridge the above gaps, we present RadAgents, a
multi-agent framework for CXR interpretation that couples clinical priors with
task-aware multimodal reasoning. In addition, we integrate grounding and
multimodal retrieval-augmentation to verify and resolve context conflicts,
resulting in outputs that are more reliable, transparent, and consistent with
clinical practice.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [3] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: 本文提出了两个专门针对OpenACC指令生成的微调大语言模型ACCeLLiuM及其训练数据集，实现了远高于基础模型的自动生成准确度，促进GPU编程自动化。


<details>
  <summary>Details</summary>
Motivation: GPU硬件和并行编程框架越来越复杂，尽管OpenACC简化了GPU编程，但有效使用仍需大量专业知识，因此需要自动化辅助生成OpenACC指令。

Method: 收集4000+对OpenACC指令和对应循环代码对的数据集，基于该数据集对基础大语言模型进行监督微调，训练生成准确的OpenACC指令。

Result: 微调后的模型在测试集上能为87%的数据并行循环生成正确类型的OpenACC指令，50%生成完全准确的指令，性能远超基础模型且实用性强。

Conclusion: ACCeLLiuM模型和数据集公开发布，有望成为生成OpenACC指令的基准工具，降低GPU串行程序自动并行化门槛。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [4] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 本文系统回顾了软件安全可视化领域的研究，分类并总结了四种主要的可视化技术，指出了该领域的关键问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统的文本和数字方法难以有效处理日益复杂的软件安全问题，迫切需要将复杂安全数据转化为直观的视觉形式以提升威胁检测和响应能力。

Method: 通过系统分析60余篇近期关键文献，构建了软件安全可视化技术的分类体系，包括图形、符号、矩阵和隐喻四类可视化方法，并探讨了两大核心领域：软件开发可视化与网络安全可视化。

Result: 归纳总结了现有可视化技术的优缺点和应用场景，强调了创新技术在应对动态安全威胁中的重要性，并提出了未来研究的重点方向。

Conclusion: 软件安全可视化技术是提升安全威胁检测与响应效果的关键，需持续创新以适应不断演变的安全环境，具有广泛的实际应用价值和研究前景。

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [5] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: Dynamic ReAct提出了一种高效管理大量工具集的方法，通过逐步改进的选择机制，实现智能选取工具，降低加载负担并保持准确率。


<details>
  <summary>Details</summary>
Motivation: 解决现有ReAct代理在面对数百至数千工具时，由于模型记忆限制，无法同时加载所有工具，从而影响性能的问题。

Method: 设计并评估了五种工具选择架构，最终采用搜索加载机制，实现以最小计算开销智能选择工具。

Result: 该方法在保持任务完成精度的同时，将工具加载量减少了最多50%。

Conclusion: Dynamic ReAct有效提升了ReAct代理在大规模工具环境中的工具管理效率，促进通用人工智能代理动态适应多样任务环境的发展。

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [6] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: 本文提出利用知识图谱构建公平性需求的框架，解决现有软件系统中缺乏明确定义和验证公平性需求的问题。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统中决策存在基于性别、种族等特征的歧视，归因于缺乏明确且可验证的公平性需求，而专家对公平性的理解通常是隐性的，导致需求难以具体化和验证。

Method: 借鉴安全工程领域知识图谱在规范知识、辅助需求规格与验证中的成功经验，提出构建基于知识图谱的公平性需求框架，讨论相关挑战和研究问题，并规划研究路线。

Result: 提出的框架将有助于明确和形式化公平性需求，提高需求的可验证性，进而促进消除软件系统中的歧视行为。

Conclusion: 通过引入知识图谱技术，能够有效解决公平性需求缺失的问题，为公平性需求的规格说明与验证提供新的方法和路径。

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [7] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: 本文提出了一种在线优化的检索增强生成方法，通过实时反馈不断调整检索嵌入，解决了嵌入不匹配导致检索错误的问题，提高了工具选择和任务完成的准确率。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，检索增强生成方法因嵌入模型不完善或描述噪声导致嵌入与工具描述不匹配，进而影响任务成功率。

Method: 提出在线优化RAG框架，利用任务成功等最小反馈进行轻量级梯度更新，无需修改底层大模型，实现即插即用，支持多工具、多跳检索和重新排序。

Result: 在多种工具使用及文档检索场景中，该方法显著提升了工具选择的准确率和任务完成率。

Conclusion: 在线优化RAG为实际应用中的检索增强生成系统提供了简单且高效的自我改进方案，显著提升系统的鲁棒性和性能。

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [8] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: 本文介绍了Stipula语言及其合同的形式验证方法，通过将Stipula合同翻译为带Java Modeling Language注释的Java代码，并利用KeY工具自动验证合同的正确性。


<details>
  <summary>Details</summary>
Motivation: 确保Stipula语言设计的法律合同模型在资产转移和义务等方面具有可执行且正确的性质。

Method: 将Stipula合同自动翻译为带有JML规格说明的Java代码，利用KeY进行推理验证以确认合同部分及整体正确性。

Result: 成功实现了对具有不相交循环的大部分Stipula合同的自动翻译及部分与整体正确性验证。

Conclusion: 证明了一般用途的推理验证工具可通过翻译方法有效用于特定领域语言合同的形式验证。

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [9] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: 本文提出了SpecDetect4AI工具，利用领域特定语言结合静态分析技术，专门检测AI系统中的代码异味，效果优于现有工具。


<details>
  <summary>Details</summary>
Motivation: AI系统带来了新的软件问题，传统检测工具难以发现特有的代码异味，需要专门的方法来检测这些影响模型表现的代码问题。

Method: 设计了一种高层声明式领域特定语言（DSL）用于定义规则，结合可扩展的静态分析工具来解析和检测AI代码异味，覆盖22种异味模式。

Result: 在826个AI系统（2000万行代码）上测试，SpecDetect4AI达到88.66%的精确率和88.89%的召回率，优于现有工具，同时表现出良好的效率和扩展性，用户满意度分数81.7/100。

Conclusion: SpecDetect4AI有效支持AI代码异味的规则制定和检测，能大规模分析AI系统，提升了代码质量保障能力。

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [10] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文首次大规模实证研究了大语言模型（LLM）集成中的自承技术债务（SATD），分析了其起因、普遍性及缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着LLM通过API如OpenAI被广泛集成，带来了技术债务问题，亟需系统性分析与管理建议。

Method: 分析了93,142个Python文件，识别LLM相关SATD来源与类型，重点探讨提示词设计及超参数调优带来的债务。

Result: 发现54.49%的SATD来自OpenAI集成，12.35%来自LangChain，提示词设计（特别是基于指令和少样本提示）是主要债务源。

Conclusion: 提示词优化是缓解LLM相关技术债务的关键，研究提供了数据集及实践指导，助力LLM系统的技术债务管理。

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [11] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 本研究提出了一种基于AI和Python的聊天机器人，帮助学生通过解决编程错误、语法问题及将理论转化为实践，提高编程学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统编码工具和现有AI助理要么缺乏互动教学效果，要么只关注完成任务，难以满足学生学习编程时对指导和理解的需求。

Method: 结合静态代码分析、动态执行追踪和大语言模型（CodeLlama用于代码嵌入，GPT-4用于自然语言交互），并通过Docker沙箱安全执行，以提供实用的编程建议。

Result: 系统在1500次提交中错误解决率达85%，高于pylint（62%）和GPT-4（73%）；用户调试时间减少59.3%，编程能力提升34%，用户反馈积极但提出延迟及代码限制的问题。

Conclusion: 该聊天机器人在技术创新与教学共情之间取得平衡，推动公平教育和技能长期保持，展示了AI增强人类教学，促进编程深层理解的潜力。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [12] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: 本文提出了FaR-Loc框架，通过结合大语言模型（LLMs）和检索增强生成（RAG）技术，提升软件故障定位的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统大语言模型在复杂系统中的故障定位表现不佳，主要因缺乏项目特定知识和难以处理大型项目。

Method: FaR-Loc包含三个核心模块：LLM功能提取生成故障描述，语义密集检索定位相似功能方法，以及LLM重排序提高相关性。

Result: 在Defects4J数据集上，FaR-Loc在Top-1和Top-5准确率上分别超越现有先进LLM方法14.6%、9.1%和19.2%、22.1%；且优于所有学习和频谱基线，无需再训练。使用结构化代码嵌入器（如UniXcoder）能提升故障定位性能最高达49.0%。

Conclusion: FaR-Loc显著提升了故障定位的效果和实用价值，未来可为实际软件调试提供有力支持。

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [13] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: 本文提出了一种新颖的编程语言主题分类方法，结合多标签支持向量机和滑动窗口投票策略，实现对代码中语言概念的精细定位。实验结果显示模型在项目数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统规模和复杂性的增加，理解源代码中编程语言主题的分布对于技术决策、人员培训和工具开发非常重要。

Method: 设计并实现了结合多标签支持向量机、滑动窗口和投票策略的编程语言主题分类流程，能够细粒度定位核心语言概念。

Result: 模型在IBM Project CodeNet数据集上的主题分类平均F1分数达到0.90，代码主题高亮准确率为0.75。

Conclusion: 该研究提供了编程语言主题分类的实证见解和可复用流程，对代码分析和数据驱动的软件工程有重要参考价值。

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [14] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: 研究通过生理数据和问卷调查，比较了混合会议中远程与现场参与者的参与度，发现长时间会议中远程参与度较低，积极角色可提升参与度。


<details>
  <summary>Details</summary>
Motivation: COVID-19后混合工作模式普及，带来沟通与协作方面的新挑战，尤其是远程参与可能导致孤立和参与度下降。

Method: 对三家软件公司的专业人员进行多模式数据采集，包括自报问卷和生理测量，分析混合会议中参与度的差异和影响因素。

Result: 现场与远程参与者的总体参与度相当，但远程在长时间会议中参与度较低；积极角色提升参与度，较大会议规模和下午时段降低参与度。

Conclusion: 揭示了混合会议中参与与脱离的影响因素，提出改进会议的建议，对软件团队及其他知识密集型组织具有参考价值。

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [15] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: 本文系统研究了代码生成中合成数据的验证瓶颈，提出通过改进验证设计和策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据中验证能力限制了训练数据的质量和多样性，成为模型性能的瓶颈。

Method: 分析测试复杂度与数量的影响；探索放宽通过阈值及引入基于大语言模型的软验证；通过控制试验比较不同验证策略的效果。

Result: 丰富的测试集提高性能，数量增加回报递减；放宽验证标准或软验证可提升2-4点pass@1；保持多样的正确解答带来泛化提升。

Conclusion: 当前验证过于严格，过滤了有价值的多样性，但验证仍然必要，应重新校准验证流程以突破性能瓶颈。

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [16] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: 本文提出了一种名为PseudoBridge的新型代码检索框架，通过引入伪代码作为自然语言与程序语言之间的中间桥梁，提高代码检索的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练语言模型的方法在代码检索中仍存在人类意图与机器执行逻辑的语义鸿沟以及对代码风格多样性的鲁棒性不足的问题。

Method: PseudoBridge采用两阶段策略，首先利用大型语言模型生成伪代码以实现自然语言查询与伪代码的显式对齐；其次通过代码风格增强策略，使用大型语言模型生成风格多样但逻辑等效的代码，实现不同风格代码与伪代码的对齐，提升模型对代码风格变化的鲁棒性。

Result: 在10个不同预训练语言模型和6种主流编程语言上进行评测，PseudoBridge在检索准确率和泛化能力上均显著优于现有基线方法，尤其在零样本领域转移如Solidity和XLCoST数据集表现突出。

Conclusion: 显式利用伪代码实现逻辑对齐有效提升了代码检索性能，PseudoBridge展现出作为一种鲁棒且具泛化能力的代码检索解决方案的潜力。

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [17] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: 该论文介绍了一个结合传统调试工具与大语言模型（LLM）技术的调试助手CodeHinter，旨在帮助初学者修复语义错误并促进其主动参与调试过程。


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的调试工具使学生过度依赖AI，缺乏积极参与调试过程，因此需要一个能够辅助但又促进学生主动参与的调试工具。

Method: 设计并迭代开发CodeHinter，结合传统调试工具和LLM技术，通过实地测试（本科生用户群体）验证其易用性和效果。

Result: 学生反馈CodeHinter在定位和修复语义错误方面效果显著，且第二版明显更易用，错误定位功能最有价值。

Conclusion: AI辅助调试工具应基于用户个人资料进行个性化设计，以优化与学生的交互效果。

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [18] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: 本文研究量子软件工程中开发者面临的挑战，通过对Stack Overflow上相关问题的分类，利用BERT等Transformer模型实现了95%的高准确率分类，提升了问题组织和访问效率。


<details>
  <summary>Details</summary>
Motivation: 量子开发者在优化量子计算和软件工程概念时面临多种挑战，现有讨论多以技术标签标注，难以准确识别和分类具体挑战。将问题按量子概念分类有助于理解和解决常见的QSE难题。

Method: 收集了2829个带有量子标签的问答帖子，进行内容分析并基于实地理论归纳出主要挑战类别（工具、理论、学习、概念、错误和API使用）；采用ChatGPT验证注释并解决争议；利用BERT、DistilBERT和RoBERTa等微调Transformer模型对帖子进行分类，同时与传统D&ML模型比较性能；运用SHAP解释模型决策机制。

Result: Transformer模型（BERT和DistilBERT）分类准确率达95%，优于传统深度学习模型（FNN 89%，CNN 86%，LSTM 84%），提升了6个百分点的准确率，且无需数据增强。SHAP分析揭示了语言特征对模型预测的影响，增强了模型透明性。

Conclusion: 通过精确的挑战分类，量子相关论坛和供应商能够更好地组织讨论，提高访问效率和可读性。未来需要与实际开发者和供应商开展实证评估研究，验证分类模型的实际应用效果。

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [19] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: 本文提出MelcotCR，一种基于链式思维(COT)的微调方法，通过多维度分析代码审查，显著提升大语言模型在代码审查中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs虽然能辅助代码审查，但受限于训练数据和缺乏多维度分析，难以达到人类水平。

Method: MelcotCR利用长链式思维技术，结合最大熵模型与预定义推理路径，解决上下文和推理逻辑丢失问题，增强模型推理能力。

Result: 在自建和公开数据集上，14B参数模型经过MelcotCR微调后，性能超越多种顶尖方法，接近更大规模模型的表现。

Conclusion: MelcotCR有效提升了LLMs多维度代码审查能力，为自动化代码审查提供了更强大的工具和方法。

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [20] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 本文提出了一种结合BERTopic、种子词和大语言模型自动验证的方法，高效分类大量公民数字平台参与数据，降低人工成本且保持主题连贯性和与官方分类法的对齐。


<details>
  <summary>Details</summary>
Motivation: 随着公民在数字平台上参与度的增加，如何有效组织和利用大量公民贡献成为政府的重大挑战。传统的手工分类不可行，且需要专家和与官方分类对齐。

Method: 结合BERTopic主题模型、预设种子词引导主题生成，并利用大型语言模型自动验证主题的连贯性和符合官方税onomies。

Result: 初步结果显示，生成的主题不仅连贯且符合机构要求，且所需人力成本极低。

Conclusion: 该方法使政府能够高效将大量市民输入转化为可执行的公共政策数据，提升数字参与的实际价值。

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>
