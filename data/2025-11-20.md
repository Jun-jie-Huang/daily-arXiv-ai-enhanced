<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 28]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Test-time Scaling of LLMs: A Survey from A Subproblem Structure Perspective](https://arxiv.org/abs/2511.14772)
*Zhuoyi Yang,Xu Guo,Tong Zhang,Huijuan Xu,Boyang Li*

Main category: cs.CL

TL;DR: 该论文综述了通过在推理时分配额外计算资源以提高预训练大型语言模型预测准确性的技术，重点分类了测试时扩展方法，并统一分析了链式思维、分支解决合并和树式思维等方法。


<details>
  <summary>Details</summary>
Motivation: 提升预训练大型语言模型在推理阶段的预测准确性。

Method: 通过分类测试时扩展方法，特别关注问题如何分解为子问题及其拓扑结构（顺序、并行、树状），统一分析多种方法如Chain-of-Thought、Branch-Solve-Merge和Tree-of-Thought。

Result: 综合分析了不同方法的优缺点，展示了多种测试时扩展策略的效果与特点。

Conclusion: 提出了未来有前景的研究方向，推动测试时扩展技术的发展。

Abstract: With this paper, we survey techniques for improving the predictive accuracy of pretrained large language models by allocating additional compute at inference time. In categorizing test-time scaling methods, we place special emphasis on how a problem is decomposed into subproblems and on the topological organization of these subproblems whether sequential, parallel, or tree-structured. This perspective allows us to unify diverse approaches such as Chain-of-Thought, Branch-Solve-Merge, and Tree-of-Thought under a common lens. We further synthesize existing analyses of these techniques, highlighting their respective strengths and weaknesses, and conclude by outlining promising directions for future research

</details>


### [2] [Temporal Predictors of Outcome in Reasoning Language Models](https://arxiv.org/abs/2511.14773)
*Joey David*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）在链式思维（CoT）推理过程中，对于最终答案的内部承诺早期阶段。


<details>
  <summary>Details</summary>
Motivation: 目前尚不清楚LLM在推理过程中多早就确定最终答案，了解这一点有助于提高模型的可解释性和推理时的控制能力。

Method: 通过对推理中前几个步骤的隐藏状态训练线性分类器，测试其对最终正确性的预测能力。

Result: 结果显示，即使需要较长的推理输出，模型在前几个token后即可高度预测最终结果，且在难题中预测准确率下降主要由于长推理链中难题的偏倚。

Conclusion: 推理模型在推理初期就能内部自我评估成功的可能性，这为模型可解释性和推理时控制提供了重要启示。

Abstract: The chain-of-thought (CoT) paradigm uses the elicitation of step-by-step rationales as a proxy for reasoning, gradually refining the model's latent representation of a solution. However, it remains unclear just how early a Large Language Model (LLM) internally commits to an eventual outcome. We probe this by training linear classifiers on hidden states after the first t reasoning tokens, showing that eventual correctness is highly predictable after only a few tokens, even when longer outputs are needed to reach a definite answer. We show that, for harder questions, a drop in predictive accuracy highlights a selection artifact: hard items are disproportionately represented in long CoTs. Overall, our results imply that for reasoning models, internal self-assessment of success tends to emerge after only a few tokens, with implications for interpretability and for inference-time control.

</details>


### [3] [LiveCLKTBench: Towards Reliable Evaluation of Cross-Lingual Knowledge Transfer in Multilingual LLMs](https://arxiv.org/abs/2511.14774)
*Pei-Fu Guo,Yun-Da Tsai,Chun-Chia Hsu,Kai-Xin Chen,Ya-An Tsai,Kai-Wei Chang,Nanyun Peng,Mi-Yen Yeh,Shou-De Lin*

Main category: cs.CL

TL;DR: 本文提出了LiveCLKTBench，一种自动生成跨语言知识转移评估的管道，能够精准测量语言模型在不同语言间的知识迁移能力。实验证明跨语言转移受语言距离影响较大且常存在方向不对称性，模型规模对迁移效果提升有限且依领域而异。


<details>
  <summary>Details</summary>
Motivation: 当前评估大型语言模型跨语言知识转移面临困难，因为正确答案可能来源于预训练时的已有知识，而非真实转移。需要一个方法来准确区分和衡量真正的跨语言知识传递。

Method: 设计LiveCLKTBench自动生成管道，提取时效性强且自成体系的知识实体，对实体进行时间序列筛选与模型知识验证，再基于有效实体生成事实性问题并翻译成多语言，从而测试跨语言知识转移能力。

Result: 评估了数个大型语言模型及五种语言，发现跨语言知识转移受语言间距离影响显著，往往呈现方向不对称特征；增加模型规模虽提高迁移效果，但边际效益递减，且迁移效果因领域不同而异。

Conclusion: LiveCLKTBench为跨语言知识转移的评估提供了可信赖的基准，研究揭示了多语言转移的规律性，有助于指导未来多语言模型的设计和优化。

Abstract: Evaluating cross-lingual knowledge transfer in large language models is challenging, as correct answers in a target language may arise either from genuine transfer or from prior exposure during pre-training. We present LiveCLKTBench, an automated generation pipeline specifically designed to isolate and measure cross-lingual knowledge transfer. Our pipeline identifies self-contained, time-sensitive knowledge entities from real-world domains, filters them based on temporal occurrence, and verifies them against the model's knowledge. The documents of these valid entities are then used to generate factual questions, which are translated into multiple languages to evaluate transferability across linguistic boundaries. Using LiveCLKTBench, we evaluate several LLMs across five languages and observe that cross-lingual transfer is strongly influenced by linguistic distance and often asymmetric across language directions. While larger models improve transfer, the gains diminish with scale and vary across domains. These findings provide new insights into multilingual transfer and demonstrate the value of LiveCLKTBench as a reliable benchmark for future research.

</details>


### [4] [NAMeGEn: Creative Name Generation via A Novel Agent-based Multiple Personalized Goal Enhancement Framework](https://arxiv.org/abs/2511.15408)
*Shanlin Zhou,Xinpeng Wang,Jianxun Lian,Zhenghao Liu,Laks V. S. Lakshmanan,Xiaoyuan Yi,Yongtao Hao*

Main category: cs.CL

TL;DR: 本文针对中文起名这一短文本创意生成任务，提出了NAMeGEn多智能体优化框架，实现多目标个性化需求满足及有意义解释生成。通过构建17k古诗语料和CBNames评测基准，实验表明该方法在多样化需求和解释生成上优于多种基线。


<details>
  <summary>Details</summary>
Motivation: 创意自然语言生成面临多目标个性化需求难以同时满足和创意内容的隐含理解与解释难题，尤其在短文本生成中表现突出。中文起名作为具有明确用户约束且需美学解释的典型任务，成为解决该难题的研究切入点。

Method: 提出NAMeGEn多智能体优化框架，迭代执行目标提取、名字生成和评价过程，以满足多样化需求并生成精准解释。同时构建17k古诗语料库增强美学表现，并引入CBNames基准和定制指标。

Result: 大量实验证明NAMeGEn在生成符合多样个性化要求的创意名字及提供有意义解释方面表现优异，超过了涵盖多种大型语言模型骨干的六个基线方法，且无须额外训练。

Conclusion: NAMeGEn通过多智能体协作优化，有效突破了短文本创意生成中多目标灵活性和解释复杂性的限制，为中文起名等短格式创意自然语言生成任务提供了一种高效且解释性强的解决方案。

Abstract: Trained on diverse human-authored texts, Large Language Models (LLMs) unlocked the potential for Creative Natural Language Generation (CNLG), benefiting various applications like advertising and storytelling. Nevertheless, CNLG still remains difficult due to two main challenges. (1) Multi-objective flexibility: user requirements are often personalized, fine-grained, and pluralistic, which LLMs struggle to satisfy simultaneously; (2) Interpretive complexity: beyond generation, creativity also involves understanding and interpreting implicit meaning to enhance users' perception. These challenges significantly limit current methods, especially in short-form text generation, in generating creative and insightful content. To address this, we focus on Chinese baby naming, a representative short-form CNLG task requiring adherence to explicit user constraints (e.g., length, semantics, anthroponymy) while offering meaningful aesthetic explanations. We propose NAMeGEn, a novel multi-agent optimization framework that iteratively alternates between objective extraction, name generation, and evaluation to meet diverse requirements and generate accurate explanations. To support this task, we further construct a classical Chinese poetry corpus with 17k+ poems to enhance aesthetics, and introduce CBNames, a new benchmark with tailored metrics. Extensive experiments demonstrate that NAMeGEn effectively generates creative names that meet diverse, personalized requirements while providing meaningful explanations, outperforming six baseline methods spanning various LLM backbones without any training.

</details>


### [5] [COMPASS: Context-Modulated PID Attention Steering System for Hallucination Mitigation](https://arxiv.org/abs/2511.14776)
*Snigdha Pandya,Rohan Nagale,Kenji Sahay,Anna Lin,Shikhar Shiromani,Kevin Zhu,Dev Sunishchal*

Main category: cs.CL

TL;DR: COMPASS通过动态调节大型语言模型的注意力机制，减少生成时的事实错误，提升模型的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型尽管能生成流畅文本，但常出现事实错误，源于其在上下文和参数知识间的注意力分配问题，亟需理解和控制其内部行为以提高可信度和科学可解读性。

Method: 提出COMPASS框架，内嵌基于模型的反馈回路，通过透明的上下文依赖评分（CRS）作为信号，利用PID控制器动态调节注意力头，实现无须重训练或多次生成即可保持事实一致性。

Result: 在多个基准测试（HotpotQA、XSum、HaluEval、RAGTruth）中，COMPASS显著降低（2.8~5.8%）上下文虚假率，且揭示不同注意力头在证据对齐中的作用。

Conclusion: 反馈驱动的可解释方法为解读大型语言模型的机制提供了新的科研路径，同时有效提升其生成文本的事实准确性。

Abstract: Large language models (LLMs) often generate fluent but factually incorrect statements despite having access to relevant evidence, a failure mode rooted in how they allocate attention between contextual and parametric knowledge. Understanding and steering this internal behavior is key both for trustworthy deployment and for scientific interpretability of model mechanisms. We introduce COMPASS (Context-Modulated PID Attention Steering System), a lightweight, interpretable control framework that embeds a model-based feedback loop directly within decoding. COMPASS quantifies context reliance via a transparent metric, the Context Reliance Score (CRS), which serves as an online probe of how attention heads ground generation in evidence. Using this interpretable signal, a PID controller dynamically modulates attention heads to maintain factual consistency without retraining or multi-pass decoding. Across benchmarks (HotpotQA, XSum, HaluEval, RAGTruth), COMPASS consistently reduces contextual hallucination rates (2.8 to 5.8 percent absolute) while revealing how distinct attention heads contribute to evidence alignment. These results highlight feedback-driven interpretability as a pathway toward scientific understanding of LLM behavior.

</details>


### [6] [The Impact of Prosodic Segmentation on Speech Synthesis of Spontaneous Speech](https://arxiv.org/abs/2511.14779)
*Julio Cesar Galdino,Sidney Evaldo Leal,Leticia Gabriella De Souza,Rodrigo de Freitas Lima,Antonio Nelson Fornari Mendes Moreira,Arnaldo Candido Junior,Miguel Oliveira,Edresson Casanova,Sandra M. Aluísio*

Main category: cs.CL

TL;DR: 本文探讨了显式韵律分段对巴西葡萄牙语自发表达语音合成质量的影响，比较了手动和自动韵律分段标注在非自回归模型FastSpeech 2上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有语音合成虽能隐式建模韵律特征，但显式韵律分段对自发表达语音合成的影响尚未充分研究。

Method: 利用手动和自动韵律分段标注对巴西葡萄牙语语料进行训练，对比FastSpeech 2生成语音的自然度和可懂度。

Result: 韵律分段训练提升了语音的自然度和可懂度，自动分段生成规律性段落，手动分段引入更多变异性，更有助于自然韵律的表达。

Conclusion: 显式韵律分段，尤其是手动分段，有助于提升自发表达语音合成的自然性和韵律匹配度，相关数据和模型公开以促进后续研究。

Abstract: Spontaneous speech presents several challenges for speech synthesis, particularly in capturing the natural flow of conversation, including turn-taking, pauses, and disfluencies. Although speech synthesis systems have made significant progress in generating natural and intelligible speech, primarily through architectures that implicitly model prosodic features such as pitch, intensity, and duration, the construction of datasets with explicit prosodic segmentation and their impact on spontaneous speech synthesis remains largely unexplored. This paper evaluates the effects of manual and automatic prosodic segmentation annotations in Brazilian Portuguese on the quality of speech synthesized by a non-autoregressive model, FastSpeech 2. Experimental results show that training with prosodic segmentation produced slightly more intelligible and acoustically natural speech. While automatic segmentation tends to create more regular segments, manual prosodic segmentation introduces greater variability, which contributes to more natural prosody. Analysis of neutral declarative utterances showed that both training approaches reproduced the expected nuclear accent pattern, but the prosodic model aligned more closely with natural pre-nuclear contours. To support reproducibility and future research, all datasets, source codes, and trained models are publicly available under the CC BY-NC-ND 4.0 license.

</details>


### [7] [Human or LLM as Standardized Patients? A Comparative Study for Medical Education](https://arxiv.org/abs/2511.14783)
*Bingquan Zhang,Xiaoxiao Liu,Yuchi Wang,Lei Zhou,Qianqian Xie,Benyou Wang*

Main category: cs.CL

TL;DR: EasyMED是一个基于多智能体的大型语言模型临床患者模拟框架，能够实现逼真且一致的对话，并通过SPBench基准进行系统评估，表现出与真人标准化患者相当的教学效果，且成本更低，灵活性更好。


<details>
  <summary>Details</summary>
Motivation: 传统标准化患者昂贵、灵活性差、难以规模化，现有LLM基础的模拟器虽然成本较低，但行为不稳定且缺乏对比真人标准化患者的严谨评估。

Method: 提出EasyMED框架，包括患者智能体负责真实对话，辅助智能体保证事实一致性，评估智能体提供可操作反馈；同时引入涵盖14个专业和8项评价标准的SPBench基准用于系统评价。

Result: 实验显示EasyMED的教学效果与真人标准化患者相当，对于基础较差学生能带来更大技能提升，且拥有更佳的灵活性、心理安全性和成本效益。

Conclusion: EasyMED有效提升了标准化患者模拟的真实性和可控性，具备推广应用潜力，有望成为临床技能培训中成本效益更优的替代方案。

Abstract: Standardized Patients (SP) are indispensable for clinical skills training but remain expensive, inflexible, and difficult to scale. Existing large-language-model (LLM)-based SP simulators promise lower cost yet show inconsistent behavior and lack rigorous comparison with human SP. We present EasyMED, a multi-agent framework combining a Patient Agent for realistic dialogue, an Auxiliary Agent for factual consistency, and an Evaluation Agent that delivers actionable feedback. To support systematic assessment, we introduce SPBench, a benchmark of real SP-doctor interactions spanning 14 specialties and eight expert-defined evaluation criteria. Experiments demonstrate that EasyMED matches human SP learning outcomes while producing greater skill gains for lower-baseline students and offering improved flexibility, psychological safety, and cost efficiency.

</details>


### [8] [Opinion Mining and Analysis Using Hybrid Deep Neural Networks](https://arxiv.org/abs/2511.14796)
*Adel Hidri,Suleiman Ali Alsaif,Muteeb Alahmari,Eman AlShehri,Minyar Sassi Hidri*

Main category: cs.CL

TL;DR: 本文提出了一种结合双向门控循环单元（BGRU）与长短期记忆网络（LSTM）的混合深度神经网络模型，用于提高文本情感分析的准确性，尤其是在处理上下文细微差别、可扩展性及类别不平衡问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的基于词典和传统机器学习方法难以有效捕捉文本的上下文细微差别且难以扩展，深度学习虽有所改进但仍存局限，因此需要一种更强大且适应性更好的模型来提升情感分析性能。

Method: 提出混合深度神经网络模型HBGRU-LSTM，结合双向门控循环单元和长短期记忆网络，利用IMDB电影评论和亚马逊产品评价数据集进行实验验证。

Result: HBGRU-LSTM模型在测试准确率达到95%，优于传统LSTM、CNN+LSTM及GRU+LSTM模型；负面情绪的召回率从不平衡数据集的86%提升至平衡数据集的96%，误分类损失也显著降低。

Conclusion: 混合HBGRU-LSTM模型有效提升了情感分析的性能，尤其在上下文理解、类别平衡处理及模型泛化能力方面表现突出，为情感分析任务提供了强有力的技术支持。

Abstract: Understanding customer attitudes has become a critical component of decision-making due to the growing influence of social media and e-commerce. Text-based opinions are the most structured, hence playing an important role in sentiment analysis. Most of the existing methods, which include lexicon-based approaches and traditional machine learning techniques, are insufficient for handling contextual nuances and scalability. While the latter has limitations in model performance and generalization, deep learning (DL) has achieved improvement, especially on semantic relationship capturing with recurrent neural networks (RNNs) and convolutional neural networks (CNNs). The aim of the study is to enhance opinion mining by introducing a hybrid deep neural network model that combines a bidirectional gated recurrent unit (BGRU) and long short-term memory (LSTM) layers to improve sentiment analysis, particularly addressing challenges such as contextual nuance, scalability, and class imbalance. To substantiate the efficacy of the proposed model, we conducted comprehensive experiments utilizing benchmark datasets, encompassing IMDB movie critiques and Amazon product evaluations. The introduced hybrid BGRULSTM (HBGRU-LSTM) architecture attained a testing accuracy of 95%, exceeding the performance of traditional DL frameworks such as LSTM (93.06%), CNN+LSTM (93.31%), and GRU+LSTM (92.20%). Moreover, our model exhibited a noteworthy enhancement in recall for negative sentiments, escalating from 86% (unbalanced dataset) to 96% (balanced dataset), thereby ensuring a more equitable and just sentiment classification. Furthermore, the model diminished misclassification loss from 20.24% for unbalanced to 13.3% for balanced dataset, signifying enhanced generalization and resilience.

</details>


### [9] [Hierarchical Token Prepending: Enhancing Information Flow in Decoder-based LLM Embeddings](https://arxiv.org/abs/2511.14868)
*Xueying Ding,Xingyue Huang,Mingxuan Ju,Liam Collins,Yozen Liu,Leman Akoglu,Neil Shah,Tong Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种层次化预置Token（HTP）方法，通过分块和多路径的摘要Token设计，解决了长文本嵌入中信息流受限和过度压缩的问题，显著提升了长文本语义表示的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的因果注意力机制限制了后续Token对前面Token的信息流，导致长文档表示质量下降。现有方法通过预置单个摘要Token缓解该问题，但信息过度压缩影响长文本表现。

Method: HTP将输入分块，向后续块预置块级摘要Token，增强向前的信息流通道；同时用均值池代替最后Token池，缓解信息过度压缩的问题。

Result: HTP在11个检索数据集和30个通用嵌入基准上均表现优异，尤其在长文本场景下提升显著。

Conclusion: HTP作为简洁且与架构无关的方法，能增强零样本及微调模型，提供了长文嵌入的可扩展且效果优异的解决方案。

Abstract: Large language models produce powerful text embeddings, but their causal attention mechanism restricts the flow of information from later to earlier tokens, degrading representation quality. While recent methods attempt to solve this by prepending a single summary token, they over-compress information, hence harming performance on long documents. We propose Hierarchical Token Prepending (HTP), a method that resolves two critical bottlenecks. To mitigate attention-level compression, HTP partitions the input into blocks and prepends block-level summary tokens to subsequent blocks, creating multiple pathways for backward information flow. To address readout-level over-squashing, we replace last-token pooling with mean-pooling, a choice supported by theoretical analysis. HTP achieves consistent performance gains across 11 retrieval datasets and 30 general embedding benchmarks, especially in long-context settings. As a simple, architecture-agnostic method, HTP enhances both zero-shot and finetuned models, offering a scalable route to superior long-document embeddings.

</details>


### [10] [Mathematical Analysis of Hallucination Dynamics in Large Language Models: Uncertainty Quantification, Advanced Decoding, and Principled Mitigation](https://arxiv.org/abs/2511.15005)
*Moses Kiprono*

Main category: cs.CL

TL;DR: 本文提出了一个基于数学理论的框架来理解、衡量和减少大语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型虽强大，但容易产生难以置信的错误输出（幻觉），影响可靠性。

Method: 基于概率模型、信息理论、三角信号分析和贝叶斯不确定性估计，分析错误传播，提出语义和相位感知的不确定性度量，并采用对比解码、检索增强、事实校准和回避策略。

Result: 通过统一的数学框架，连接了校准、检索和对齐方法，提高了模型生成的准确性和安全性。

Conclusion: 该方法为减少大语言模型幻觉提供了理论支持和实用策略，有助于构建更安全、可靠的语言模型。

Abstract: Large Language Models (LLMs) are powerful linguistic engines but remain susceptible to hallucinations: plausible-sounding outputs that are factually incorrect or unsupported. In this work, we present a mathematically grounded framework to understand, measure, and mitigate these hallucinations. Drawing on probabilistic modeling, information theory, trigonometric signal analysis, and Bayesian uncertainty estimation, we analyze how errors compound autoregressively, propose refined uncertainty metrics, including semantic and phase-aware variants, and develop principled mitigation strategies such as contrastive decoding, retrieval-augmented grounding, factual alignment, and abstention. This unified lens connects recent advances in calibration, retrieval, and alignment to support safer and more reliable LLMs.

</details>


### [11] [Teaching According to Students' Aptitude: Personalized Mathematics Tutoring via Persona-, Memory-, and Forgetting-Aware LLMs](https://arxiv.org/abs/2511.15163)
*Yang Wu,Rujing Yao,Tong Zhang,Yufei Shi,Zhuoren Jiang,Zhushan Li,Xiaozhong Liu*

Main category: cs.CL

TL;DR: 本文提出了TASA，一个基于大语言模型的个性化数学教学系统，通过融合学生画像、记忆与遗忘动态，实现动态更新掌握状态，提供难度适宜的教学内容。


<details>
  <summary>Details</summary>
Motivation: 现有智能辅导系统多忽视学生知识随时间变化的动态演进，尤其在数学教学中，需要细粒度的、根据学生掌握水平和遗忘情况精确调整的教学支架。

Method: 构建学生画像抓取能力概况，记录学习交互记忆，并结合连续遗忘曲线与知识追踪，动态更新学生掌握状态，生成难度匹配的问题和讲解。

Result: 实验结果显示，TASA相较于基线方法，在提升学习效果和适应性教学行为方面表现更优。

Conclusion: 强调在基于大语言模型的智能辅导系统中，建模学生时间性遗忘和个体化学习画像对于实现个性化、高效教学至关重要。

Abstract: Large Language Models (LLMs) are increasingly integrated into intelligent tutoring systems to provide human-like and adaptive instruction. However, most existing approaches fail to capture how students' knowledge evolves dynamically across their proficiencies, conceptual gaps, and forgetting patterns. This challenge is particularly acute in mathematics tutoring, where effective instruction requires fine-grained scaffolding precisely calibrated to each student's mastery level and cognitive retention. To address this issue, we propose TASA (Teaching According to Students' Aptitude), a student-aware tutoring framework that integrates persona, memory, and forgetting dynamics for personalized mathematics learning. Specifically, TASA maintains a structured student persona capturing proficiency profiles and an event memory recording prior learning interactions. By incorporating a continuous forgetting curve with knowledge tracing, TASA dynamically updates each student's mastery state and generates contextually appropriate, difficulty-calibrated questions and explanations. Empirical results demonstrate that TASA achieves superior learning outcomes and more adaptive tutoring behavior compared to representative baselines, underscoring the importance of modeling temporal forgetting and learner profiles in LLM-based tutoring systems.

</details>


### [12] [HinTel-AlignBench: A Framework and Benchmark for Hindi-Telugu with English-Aligned Samples](https://arxiv.org/abs/2511.15183)
*Rishikant Chigrupaatii,Ponnada Sai Tulasi Kanishka,Lalit Chandra Routhu,Martin Patel Sama Supratheek Reddy,Divyam Gupta,Dasari Srikar,Krishna Teja Kuchimanchi,Rajiv Misra,Rohun Tripathi*

Main category: cs.CL

TL;DR: 针对印度语种视觉语言模型评估存在的不足，本文提出了一个可扩展的评测框架，并构建了包含印地语和泰卢固语的HinTel-AlignBench基准，涵盖多样化任务和数据。评测显示模型在印度语任务上性能明显低于英语，提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前多语种视觉-语言模型评估依赖未经验证的自动翻译、任务覆盖狭窄、样本有限，且缺乏文化和本地问答数据，难以推动针对低资源语言的公平AI发展。

Method: 设计半自动化数据集构建框架，结合回译、筛选和人工验证，生成含印地语和泰卢固语问答对的HinTel-AlignBench基准，涵盖英文适配数据集和本地创新数据集。

Result: 视觉语言模型在印地语和泰卢固语任务中性能普遍回落，平均下降幅度分别为8.3分和5.5分，揭示了多语种多模态理解中的不足。

Conclusion: 建立多语种多模态评测基准是推动低资源语言模型发展的关键，需关注性能退化和模型失败模式，指导后续改进。

Abstract: With nearly 1.5 billion people and more than 120 major languages, India represents one of the most diverse regions in the world. As multilingual Vision-Language Models (VLMs) gain prominence, robust evaluation methodologies are essential to drive progress toward equitable AI for low-resource languages. Current multilingual VLM evaluations suffer from four major limitations: reliance on unverified auto-translations, narrow task/domain coverage, limited sample sizes, and lack of cultural and natively sourced Question-Answering (QA). To address these gaps, we present a scalable framework to evaluate VLMs in Indian languages and compare it with performance in English. Using the framework, we generate HinTel-AlignBench, a benchmark that draws from diverse sources in Hindi and Telugu with English-aligned samples. Our contributions are threefold: (1) a semi-automated dataset creation framework combining back-translation, filtering, and human verification; (2) the most comprehensive vision-language benchmark for Hindi and and Telugu, including adapted English datasets (VQAv2, RealWorldQA, CLEVR-Math) and native novel Indic datasets (JEE for STEM, VAANI for cultural grounding) with approximately 4,000 QA pairs per language; and (3) a detailed performance analysis of various State-of-the-Art (SOTA) open-weight and closed-source VLMs. We find a regression in performance for tasks in English versus in Indian languages for 4 out of 5 tasks across all the models, with an average regression of 8.3 points in Hindi and 5.5 points for Telugu. We categorize common failure modes to highlight concrete areas of improvement in multilingual multimodal understanding.

</details>


### [13] [Unveiling Intrinsic Dimension of Texts: from Academic Abstract to Creative Story](https://arxiv.org/abs/2511.15210)
*Vladislav Pedashenko,Laida Kushnareva,Yana Khassan Nibal,Eduard Tulchinskii,Kristian Kuznetsov,Vladislav Zharchinskii,Yury Maximov,Irina Piontkovskaya*

Main category: cs.CL

TL;DR: 本文首次系统研究了大语言模型（LLM）中的内在维度（ID）与文本属性的关系，发现ID与熵指标互补，且在不同文体间有显著差异，科学文本ID较低，创意文本ID较高。通过稀疏自编码器识别因果特征，证实科学写作降低ID，情感化写作则提高ID。


<details>
  <summary>Details</summary>
Motivation: 内在维度作为分析LLM训练动态和文本结构的重要工具，其与文本具体属性之间的关系尚未被充分探究。

Method: 本文通过跨编码器分析、语言学特征提取和稀疏自编码器方法，综合研究ID与文本属性的联系，并开展引导实验验证因果关系。

Result: 发现ID与基于熵的度量互补且无关，科学文本ID最低，百科类居中，创意文本最高；具体语言特征如正式语气降低ID，个性化情感提高ID，并通过实验确认其因果作用。

Conclusion: 内在维度能有效反映文本的表现复杂度，科学写作相对“简单”，而创意及情感类文本增加模型的表现自由度。研究为ID的应用和解释提供了实践指导。

Abstract: Intrinsic dimension (ID) is an important tool in modern LLM analysis, informing studies of training dynamics, scaling behavior, and dataset structure, yet its textual determinants remain underexplored. We provide the first comprehensive study grounding ID in interpretable text properties through cross-encoder analysis, linguistic features, and sparse autoencoders (SAEs). In this work, we establish three key findings. First, ID is complementary to entropy-based metrics: after controlling for length, the two are uncorrelated, with ID capturing geometric complexity orthogonal to prediction quality. Second, ID exhibits robust genre stratification: scientific prose shows low ID (~8), encyclopedic content medium ID (~9), and creative/opinion writing high ID (~10.5) across all models tested. This reveals that contemporary LLMs find scientific text "representationally simple" while fiction requires additional degrees of freedom. Third, using SAEs, we identify causal features: scientific signals (formal tone, report templates, statistics) reduce ID; humanized signals (personalization, emotion, narrative) increase it. Steering experiments confirm these effects are causal. Thus, for contemporary models, scientific writing appears comparatively "easy", whereas fiction, opinion, and affect add representational degrees of freedom. Our multi-faceted analysis provides practical guidance for the proper use of ID and the sound interpretation of ID-based results.

</details>


### [14] [OEMA: Ontology-Enhanced Multi-Agent Collaboration Framework for Zero-Shot Clinical Named Entity Recognition](https://arxiv.org/abs/2511.15211)
*Xinli Tao,Xin Dong,Xuezhong Zhou*

Main category: cs.CL

TL;DR: OEMA是一种基于多代理协作的零样本临床命名实体识别方法，在无监督条件下实现接近有监督模型的效果。


<details>
  <summary>Details</summary>
Motivation: 临床命名实体识别依赖大量标注数据，成本高昂，现有零样本方法存在示例选择粒度和提示整合的不足。

Method: 通过自我注释器生成示例，判别器利用SNOMED CT过滤示例，预测器利用实体描述进行准确推断，形成多代理协作框架。

Result: 在MTSamples和VAERS数据集上实现了最先进的完全匹配性能，并在相关匹配上匹配甚至超越部分有监督模型。

Conclusion: OEMA通过本体引导推理和多代理协作有效解决了零样本NER挑战，具备接近有监督性能，适合临床NLP应用。

Abstract: Clinical named entity recognition (NER) is crucial for extracting information from electronic health records (EHRs), but supervised models like CRF and BioClinicalBERT require costly annotated data. While zero-shot NER with large language models (LLMs) reduces this dependency, it struggles with example selection granularity and integrating prompts with self-improvement. To address this, we propose OEMA, a zero-shot clinical NER framework using multi-agent collaboration. OEMA's three components are: a self-annotator generating examples, a discriminator filtering them via SNOMED CT, and a predictor using entity descriptions for accurate inference. On MTSamples and VAERS datasets, OEMA achieves state-of-the-art exact-match performance. Under related-match, it matches supervised BioClinicalBERT and surpasses CRF. OEMA addresses key zero-shot NER challenges through ontology-guided reasoning and multi-agent collaboration, achieving near-supervised performance and showing promise for clinical NLP applications.

</details>


### [15] [Context Cascade Compression: Exploring the Upper Limits of Text Compression](https://arxiv.org/abs/2511.15244)
*Fanfan Liu,Haibo Qiu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Context Cascade Compression (C3)的文本压缩方法，通过级联两个规模不同的LLM实现高效长文本压缩和解码，显著提升了压缩比和解码准确率。


<details>
  <summary>Details</summary>
Motivation: 面对长上下文任务中文本输入量达到百万级别时，对大语言模型(Large Language Models, LLMs)的计算和内存提出挑战，现有的光学字符压缩方法存在性能瓶颈，亟需更有效的压缩技术。

Method: 提出C3方法，级联一个小型LLM负责将长文本压缩成较少的潜变量(token)序列，再由大型LLM完成解码任务，实现了高压缩比例文本的有效处理。

Result: 在20倍压缩比下，C3实现了98%的解码准确率，远超DeepSeek-OCR的约60%；即使在40倍压缩下，准确率仍维持约93%，表明其在文本压缩上的有效性。

Conclusion: C3方法展现出文本上下文压缩领域的优越性能和可行性，提供了未来光学字符压缩、OCR等领域压缩比的潜在上限方向，且采用纯文本流程简化了处理过程。

Abstract: Million-level token inputs in long-context tasks pose significant computational and memory challenges for Large Language Models (LLMs). Recently, DeepSeek-OCR conducted research into the feasibility of Contexts Optical Compression and achieved preliminary results. Inspired by this, we introduce Context Cascade Compression C3 to explore the upper limits of text compression. Our method cascades two LLMs of different sizes to handle the compression and decoding tasks. Specifically, a small LLM, acting as the first stage, performs text compression by condensing a long context into a set of latent tokens (e.g., 32 or 64 in length), achieving a high ratio of text tokens to latent tokens. A large LLM, as the second stage, then executes the decoding task on this compressed context. Experiments show that at a 20x compression ratio (where the number of text tokens is 20 times the number of latent tokens), our model achieves 98% decoding accuracy, compared to approximately 60% for DeepSeek-OCR. When we further increase the compression ratio to 40x, the accuracy is maintained at around 93%. This indicates that in the domain of context compression, C3 Compression demonstrates superior performance and feasibility over optical character compression. C3 uses a simpler, pure-text pipeline that ignores factors like layout, color, and information loss from a visual encoder. This also suggests a potential upper bound for compression ratios in future work on optical character compression, OCR, and related fields. Codes and model weights are publicly accessible at https://github.com/liufanfanlff/C3-Context-Cascade-Compression

</details>


### [16] [IndicGEC: Powerful Models, or a Measurement Mirage?](https://arxiv.org/abs/2511.15260)
*Sowmya Vajjala*

Main category: cs.CL

TL;DR: 本文报告了TeamNRC团队在BHASHA-Task 1语法纠错共享任务中对5种印度语言的参与结果，采用零样本和少样本提示语言模型的方法，在泰卢固语和印地语取得了较好成绩，并扩展到其他语言，探讨数据质量与评测指标问题。


<details>
  <summary>Details</summary>
Motivation: 针对印度多语言语法纠错任务，探索适用于不同大小语言模型且效果良好的方法，并关注数据质量及评测指标的合适性。

Method: 采用不同规模的语言模型（4B至大型专有模型）进行零样本和少样本提示学习，评测5种印度语言的语法纠错性能。

Result: 在泰卢固语和印地语分别获得排名第4和第2，GLEU分数分别为83.78和84.31，扩展实验到泰米尔语、马拉雅拉姆语和孟加拉语。

Conclusion: 小型语言模型在语法纠错任务中展现了潜力，同时强调了构建高质量数据集和选择适合印度语言脚本的评测指标的重要性。

Abstract: In this paper, we report the results of the TeamNRC's participation in the BHASHA-Task 1 Grammatical Error Correction shared task https://github.com/BHASHA-Workshop/IndicGEC2025/ for 5 Indian languages. Our approach, focusing on zero/few-shot prompting of language models of varying sizes (4B to large proprietary models) achieved a Rank 4 in Telugu and Rank 2 in Hindi with GLEU scores of 83.78 and 84.31 respectively. In this paper, we extend the experiments to the other three languages of the shared task - Tamil, Malayalam and Bangla, and take a closer look at the data quality and evaluation metric used. Our results primarily highlight the potential of small language models, and summarize the concerns related to creating good quality datasets and appropriate metrics for this task that are suitable for Indian language scripts.

</details>


### [17] [MAPROC at AHaSIS Shared Task: Few-Shot and Sentence Transformer for Sentiment Analysis of Arabic Hotel Reviews](https://arxiv.org/abs/2511.15291)
*Randa Zarnoufi*

Main category: cs.CL

TL;DR: 本文针对阿拉伯方言情感分析，采用少样本学习方法，在酒店评论数据集上实现了73%的F1分数。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言的语言多样性和标注数据缺乏给情感分析带来挑战，特别是在细分领域如酒店评论中。

Method: 使用SetFit框架，这是一种数据高效的少样本学习技术，对摩洛哥和沙特阿拉伯方言的酒店评论进行情感（正面、负面、中性）分类。

Result: 在官方评测集中，该方法取得了73%的F1分数，在26个参赛者中排名第12。

Conclusion: 少样本学习方法在处理数据稀缺且具有细微差别的阿拉伯方言文本分析中表现出潜力，尤其适用于专业领域的情感分析任务。

Abstract: Sentiment analysis of Arabic dialects presents significant challenges due to linguistic diversity and the scarcity of annotated data. This paper describes our approach to the AHaSIS shared task, which focuses on sentiment analysis on Arabic dialects in the hospitality domain. The dataset comprises hotel reviews written in Moroccan and Saudi dialects, and the objective is to classify the reviewers sentiment as positive, negative, or neutral. We employed the SetFit (Sentence Transformer Fine-tuning) framework, a data-efficient few-shot learning technique. On the official evaluation set, our system achieved an F1 of 73%, ranking 12th among 26 participants. This work highlights the potential of few-shot learning to address data scarcity in processing nuanced dialectal Arabic text within specialized domains like hotel reviews.

</details>


### [18] [Adversarial Poetry as a Universal Single-Turn Jailbreak Mechanism in Large Language Models](https://arxiv.org/abs/2511.15304)
*Piercosma Bisconti,Matteo Prandi,Federico Pierucci,Francesco Giarrusso,Marcantonio Bracale,Marcello Galisai,Vincenzo Suriani,Olga Sorokoletova,Federico Sartore,Daniele Nardi*

Main category: cs.CL

TL;DR: 本文证明对抗性诗歌是对大型语言模型的通用单轮绕过安全机制技术，诗歌提示显著提高攻击成功率，揭示了当前安全机制的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究对抗性输入如何利用语言模型的安全机制缺陷进行绕过，提升攻击效率，揭示模型安全防护的薄弱环节。

Method: 通过设计诗歌形式的对抗提示，在25个前沿模型上测试攻击成功率，并将1200条有害提示转换为诗歌形式进行对比评估；采用多模型集成和人工验证的方式评估模型输出。

Result: 诗歌形式的对抗提示攻击成功率平均达62%，远高于非诗歌基线，部分模型突破90%，并且攻击效果跨多个风险分类领域均有效。

Conclusion: 风格变化（如诗歌格式）能够显著绕过现有的安全机制，表明现有对齐方法和评估协议存在根本性限制，需重新设计防护策略。

Abstract: We present evidence that adversarial poetry functions as a universal single-turn jailbreak technique for large language models (LLMs). Across 25 frontier proprietary and open-weight models, curated poetic prompts yielded high attack-success rates (ASR), with some providers exceeding 90%. Mapping prompts to MLCommons and EU CoP risk taxonomies shows that poetic attacks transfer across CBRN, manipulation, cyber-offence, and loss-of-control domains. Converting 1,200 MLCommons harmful prompts into verse via a standardized meta-prompt produced ASRs up to 18 times higher than their prose baselines. Outputs are evaluated using an ensemble of open-weight judge models and a human-validated stratified subset (with double-annotations to measure agreement). Disagreements were manually resolved. Poetic framing achieved an average jailbreak success rate of 62% for hand-crafted poems and approximately 43% for meta-prompt conversions (compared to non-poetic baselines), substantially outperforming non-poetic baselines and revealing a systematic vulnerability across model families and safety training approaches. These findings demonstrate that stylistic variation alone can circumvent contemporary safety mechanisms, suggesting fundamental limitations in current alignment methods and evaluation protocols.

</details>


### [19] [HEAD-QA v2: Expanding a Healthcare Benchmark for Reasoning](https://arxiv.org/abs/2511.15355)
*Alexis Correa-Guillén,Carlos Gómez-Rodríguez,David Vilares*

Main category: cs.CL

TL;DR: HEAD-QA v2是一个扩展升级的西班牙语/英语医疗多项选择题推理数据集，包含12000多个问题，支持多语言版本，便于生物医学推理研究。


<details>
  <summary>Details</summary>
Motivation: 为了满足对高质量、多语言、复杂语言和概念医疗推理数据集的需求，推动生物医学推理研究。

Method: 收集十年西班牙专业考试问题扩充数据集；基于提示、检索增强生成（RAG）和概率答题法对多个开源大型语言模型进行基准测试；提供多语版本。

Result: 模型性能主要受模型规模和内在推理能力推动，复杂推理策略提升有限。

Conclusion: HEAD-QA v2是一个可靠的医疗推理数据资源，有助于促进生物医学推理研究和语言模型性能提升。

Abstract: We introduce HEAD-QA v2, an expanded and updated version of a Spanish/English healthcare multiple-choice reasoning dataset originally released by Vilares and Gómez-Rodríguez (2019). The update responds to the growing need for high-quality datasets that capture the linguistic and conceptual complexity of healthcare reasoning. We extend the dataset to over 12,000 questions from ten years of Spanish professional exams, benchmark several open-source LLMs using prompting, RAG, and probability-based answer selection, and provide additional multilingual versions to support future work. Results indicate that performance is mainly driven by model scale and intrinsic reasoning ability, with complex inference strategies obtaining limited gains. Together, these results establish HEAD-QA v2 as a reliable resource for advancing research on biomedical reasoning and model improvement.

</details>


### [20] [The Empowerment of Science of Science by Large Language Models: New Tools and Methods](https://arxiv.org/abs/2511.15370)
*Guoqiang Liang,Jingqian Gong,Mengxuan Li,Gege Lin,Shuo Zhang*

Main category: cs.CL

TL;DR: 本文全面回顾了支持大语言模型（LLMs）的核心技术及其在科学计量领域的应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在自然语言处理、多模态任务中的突出表现，其技术核心及潜在应用引发广泛关注，特别是在科学计量领域的创新应用。

Method: 从用户视角系统梳理了提示工程、知识增强的检索增强生成、微调、预训练和工具学习等核心技术，回顾科学计量学的发展并展望了LLMs在该领域的应用。

Result: 探讨了基于AI代理的科学评价模型、利用LLMs进行新研究前沿检测和知识图谱构建的新方法。

Conclusion: 大语言模型不仅推动了技术发展，也为科学计量学带来新的研究方法和应用前景，具有重要的理论和实践价值。

Abstract: Large language models (LLMs) have exhibited exceptional capabilities in natural language understanding and generation, image recognition, and multimodal tasks, charting a course towards AGI and emerging as a central issue in the global technological race. This manuscript conducts a comprehensive review of the core technologies that support LLMs from a user standpoint, including prompt engineering, knowledge-enhanced retrieval augmented generation, fine tuning, pretraining, and tool learning. Additionally, it traces the historical development of Science of Science (SciSci) and presents a forward looking perspective on the potential applications of LLMs within the scientometric domain. Furthermore, it discusses the prospect of an AI agent based model for scientific evaluation, and presents new research fronts detection and knowledge graph building methods with LLMs.

</details>


### [21] [A Compliance-Preserving Retrieval System for Aircraft MRO Task Search](https://arxiv.org/abs/2511.15383)
*Byungho Jo*

Main category: cs.CL

TL;DR: 本文提出了一种适用于航空维保环境的语义检索系统，显著提升维修技师查找手册的效率。


<details>
  <summary>Details</summary>
Motivation: 航空维修技师在查找手册时花费大量时间，成为维修操作中的效率瓶颈，且必须遵守严格的认证规范。

Method: 通过结合大型语言模型重排和语义搜索，构建基于ATA章节结构的鲁棒嵌入，利用视觉语言解析结构化认证内容，系统在不替代已有认证查看器的情况下辅助检索。

Result: 系统在49000条合成查询中检索准确率超过90%，10名持证技师的双语对照研究显示前10名命中率达90.9%，查找时间从6-15分钟减少到18秒。

Conclusion: 该语义检索方法能够兼顾严格的监管要求，显著降低实际多语言维保工作负荷。

Abstract: Aircraft Maintenance Technicians (AMTs) spend up to 30% of work time searching manuals, a documented efficiency bottleneck in MRO operations where every procedure must be traceable to certified sources. We present a compliance-preserving retrieval system that adapts LLM reranking and semantic search to aviation MRO environments by operating alongside, rather than replacing, certified legacy viewers. The system constructs revision-robust embeddings from ATA chapter hierarchies and uses vision-language parsing to structure certified content, allowing technicians to preview ranked tasks and access verified procedures in existing viewers. Evaluation on 49k synthetic queries achieves >90% retrieval accuracy, while bilingual controlled studies with 10 licensed AMTs demonstrate 90.9% top-10 success rate and 95% reduction in lookup time, from 6-15 minutes to 18 seconds per task. These gains provide concrete evidence that semantic retrieval can operate within strict regulatory constraints and meaningfully reduce operational workload in real-world multilingual MRO workflows.

</details>


### [22] [DEPO: Dual-Efficiency Preference Optimization for LLM Agents](https://arxiv.org/abs/2511.15392)
*Sirui Chen,Mengshi Zhao,Lei Xu,Yuying Zhao,Beier Zhu,Hanwang Zhang,Shengjie Zhao,Chaochao Lu*

Main category: cs.CL

TL;DR: 本文提出了双重效率定义和DEPO方法，大幅提升大语言模型作为代理的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在推理链条增长的同时，交互效率降低，缺乏系统化定义和优化手段。

Method: 提出双重效率概念（步骤级和轨迹级效率），设计DEPO方法，通过奖励简洁回答和减少步骤来优化代理行为。

Result: 实验证明DEPO在WebShop和BabyAI任务中减少60.9%标记使用和26.9%步骤，同时性能提升29.3%，效果在跨领域和数据稀缺情况下仍保持。

Conclusion: DEPO有效提升了大语言模型代理的整体效率和性能，为实际应用中的交互效率优化提供了系统性方法。

Abstract: Recent advances in large language models (LLMs) have greatly improved their reasoning and decision-making abilities when deployed as agents. Richer reasoning, however, often comes at the cost of longer chain of thought (CoT), hampering interaction efficiency in real-world scenarios. Nevertheless, there still lacks systematic definition of LLM agent efficiency, hindering targeted improvements. To this end, we introduce dual-efficiency, comprising (i) step-level efficiency, which minimizes tokens per step, and (ii) trajectory-level efficiency, which minimizes the number of steps to complete a task. Building on this definition, we propose DEPO, a dual-efficiency preference optimization method that jointly rewards succinct responses and fewer action steps. Experiments on WebShop and BabyAI show that DEPO cuts token usage by up to 60.9% and steps by up to 26.9%, while achieving up to a 29.3% improvement in performance. DEPO also generalizes to three out-of-domain math benchmarks and retains its efficiency gains when trained on only 25% of the data. Our project page is at https://opencausalab.github.io/DEPO.

</details>


### [23] [Building Robust and Scalable Multilingual ASR for Indian Languages](https://arxiv.org/abs/2511.15418)
*Arjun Gangwar,Kaousheik Jayakumar,S. Umesh*

Main category: cs.CL

TL;DR: 该论文介绍了SPRING实验室开发的ASR系统，专注于多语言多方言的语音识别和语言方言识别。


<details>
  <summary>Details</summary>
Motivation: 提高自动语音识别(ASR)系统在预测8种语言和33种方言中的语言及方言能力。

Method: 设计多解码器架构，使用音素公共标签集(Common Label Set, CLS)作为中间表示，实现一种新颖的训练方法，并探讨如何在将音素表示转换回文字书写时保持性能提升。

Result: 所提系统在CLS空间性能优于基线，在3种语言上WER/CER表现超越基线，并在语言和方言识别准确率方面达到了参与团队中的最高水平。

Conclusion: 多解码器结合CLS表示的训练方法有效提升了多语言多方言ASR系统的表现，特别是在语言和方言识别任务中。

Abstract: This paper describes the systems developed by SPRING Lab, Indian Institute of Technology Madras, for the ASRU MADASR 2.0 challenge. The systems developed focuses on adapting ASR systems to improve in predicting the language and dialect of the utterance among 8 languages across 33 dialects. We participated in Track 1 and Track 2, which restricts the use of additional data and develop from-the-scratch multilingual systems. We presented a novel training approach using Multi-Decoder architecture with phonemic Common Label Set (CLS) as intermediate representation. It improved the performance over the baseline (in the CLS space). We also discuss various methods used to retain the gain obtained in the phonemic space while converting them back to the corresponding grapheme representations. Our systems beat the baseline in 3 languages (Track 2) in terms of WER/CER and achieved the highest language ID and dialect ID accuracy among all participating teams (Track 2).

</details>


### [24] [LLM-MemCluster: Empowering Large Language Models with Dynamic Memory for Text Clustering](https://arxiv.org/abs/2511.15424)
*Yuanjie Zhu,Liangwei Yang,Ke Xu,Weizhi Zhang,Zihe Song,Jindong Wang,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出LLM-MemCluster框架，实现了基于大语言模型的端到端无监督文本聚类，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏状态记忆和聚类粒度管理，依赖复杂外部模块，难以实现真正的端到端聚类。

Method: 设计动态记忆实现状态感知，采用双重提示策略让模型推理并决定聚类数目，构建完全基于LLM的聚类框架。

Result: 在多个基准数据集上无调优方式显著且稳定地优于强基线。

Conclusion: LLM-MemCluster提供了有效、可解释且真正端到端的基于大语言模型的文本聚类新范式。

Abstract: Large Language Models (LLMs) are reshaping unsupervised learning by offering an unprecedented ability to perform text clustering based on their deep semantic understanding. However, their direct application is fundamentally limited by a lack of stateful memory for iterative refinement and the difficulty of managing cluster granularity. As a result, existing methods often rely on complex pipelines with external modules, sacrificing a truly end-to-end approach. We introduce LLM-MemCluster, a novel framework that reconceptualizes clustering as a fully LLM-native task. It leverages a Dynamic Memory to instill state awareness and a Dual-Prompt Strategy to enable the model to reason about and determine the number of clusters. Evaluated on several benchmark datasets, our tuning-free framework significantly and consistently outperforms strong baselines. LLM-MemCluster presents an effective, interpretable, and truly end-to-end paradigm for LLM-based text clustering.

</details>


### [25] [Standardising the NLP Workflow: A Framework for Reproducible Linguistic Analysis](https://arxiv.org/abs/2511.15512)
*Yves Pauli,Jan-Bernard Marsman,Finn Rabe,Victoria Edkins,Roya Hüppi,Silvia Ciampelli,Akhil Ratan Misra,Nils Lang,Wolfram Hinzen,Iris Sommer,Philipp Homan*

Main category: cs.CL

TL;DR: 该论文提出了语言处理数据结构（LPDS）和一个名为pelican nlp的Python工具包，实现语言数据的标准化组织和可重复处理流程。


<details>
  <summary>Details</summary>
Motivation: 当前语言处理面临数据组织缺乏标准化及处理方法不可重复的问题，亟需统一标准来提升数据共享和研究透明度。

Method: 借鉴脑成像数据结构标准，设计LPDS文件夹和命名规范；开发pelican nlp模块化工具，实现从数据清洗到高级特征提取的全过程处理，全部配置于统一的配置文件中，保证流程标准化与可复现。

Result: LPDS和pelican nlp结合提供了一个端到端语言处理管线，支持可重复性强的预处理和标准化特征提取，包括语义嵌入和韵律指标等，便于研究共享和方法透明。

Conclusion: 论文提出的LPDS和pelican nlp能够有效解决语言数据标准化与处理再现性难题，推动语言学研究的数据共享与方法学规范化。

Abstract: The introduction of large language models and other influential developments in AI-based language processing have led to an evolution in the methods available to quantitatively analyse language data. With the resultant growth of attention on language processing, significant challenges have emerged, including the lack of standardisation in organising and sharing linguistic data and the absence of standardised and reproducible processing methodologies. Striving for future standardisation, we first propose the Language Processing Data Structure (LPDS), a data structure inspired by the Brain Imaging Data Structure (BIDS), a widely adopted standard for handling neuroscience data. It provides a folder structure and file naming conventions for linguistic research. Second, we introduce pelican nlp, a modular and extensible Python package designed to enable streamlined language processing, from initial data cleaning and task-specific preprocessing to the extraction of sophisticated linguistic and acoustic features, such as semantic embeddings and prosodic metrics. The entire processing workflow can be specified within a single, shareable configuration file, which pelican nlp then executes on LPDS-formatted data. Depending on the specifications, the reproducible output can consist of preprocessed language data or standardised extraction of both linguistic and acoustic features and corresponding result aggregations. LPDS and pelican nlp collectively offer an end-to-end processing pipeline for linguistic data, designed to ensure methodological transparency and enhance reproducibility.

</details>


### [26] [Multimodal Evaluation of Russian-language Architectures](https://arxiv.org/abs/2511.15552)
*Artem Chervyakov,Ulyana Isaeva,Anton Emelyanov,Artem Safin,Maria Tikhonova,Alexander Kharitonov,Yulia Lyakh,Petr Surovtsev,Denis Shevelev Vildan Saburov,Vasily Konovalov,Elisei Rykov,Ivan Sviridov,Amina Miftakhova,Ilseyar Alimova,Alexander Panchenko,Alexander Kapitanov,Alena Fenogenova*

Main category: cs.CL

TL;DR: 本文介绍了针对俄语的Mera Multi多模态大语言模型评测框架，包含18项新建的多模态评测任务，支持文本、图像、音频和视频多种模态，填补了俄语领域的多模态评测空白。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型发展迅速，但其智能水平、局限性及风险尚未得到充分理解，尤其缺乏针对俄语的多模态评测基准。

Method: 提出了Mera Multi评测框架，设计了18个涵盖文本、图像、音频、视频的评测任务，构建了统一的多模态能力分类体系，并采用水印和许可机制防止基准泄露。

Result: 在闭源及开源模型上进行了基线测试，并提供了详细的评测数据集与指标，验证了该框架的有效性。

Conclusion: Mera Multi不仅弥补了俄语多模态评测的空白，还提供了一套可复制的方法论，有助于打造其他类型语言的多模态评测基准，尤其是斯拉夫语族。

Abstract: Multimodal large language models (MLLMs) are currently at the center of research attention, showing rapid progress in scale and capabilities, yet their intelligence, limitations, and risks remain insufficiently understood. To address these issues, particularly in the context of the Russian language, where no multimodal benchmarks currently exist, we introduce Mera Multi, an open multimodal evaluation framework for Russian-spoken architectures. The benchmark is instruction-based and encompasses default text, image, audio, and video modalities, comprising 18 newly constructed evaluation tasks for both general-purpose models and modality-specific architectures (image-to-text, video-to-text, and audio-to-text). Our contributions include: (i) a universal taxonomy of multimodal abilities; (ii) 18 datasets created entirely from scratch with attention to Russian cultural and linguistic specificity, unified prompts, and metrics; (iii) baseline results for both closed-source and open-source models; (iv) a methodology for preventing benchmark leakage, including watermarking and licenses for private sets. While our current focus is on Russian, the proposed benchmark provides a replicable methodology for constructing multimodal benchmarks in typologically diverse languages, particularly within the Slavic language family.

</details>


### [27] [HSKBenchmark: Modeling and Benchmarking Chinese Second Language Acquisition in Large Language Models through Curriculum Tuning](https://arxiv.org/abs/2511.15574)
*Qihao Yang,Xuelin Wang,Jiale Chen,Xuelian Dong,Yuxin Hao,Tianyong Hao*

Main category: cs.CL

TL;DR: 本文提出了HSKBenchmark，这是首个针对中文二语习得中的大型语言模型分阶段建模和写作评估的基准。该基准覆盖HSK 3到6级，包含真实教材和合成指令样本，设计了课程调优框架和多维度评估系统。实验表明该基准有效模拟中文二语习得，细调模型表现接近高级人类学习者，具备人类习得特征。


<details>
  <summary>Details</summary>
Motivation: 传统语言习得实验难以控制人类学习者的输入，导致中文二语习得建模和验证存在挑战。大型语言模型虽可控且可复现，但缺乏系统性的阶段评测基准。

Method: 建立HSKBenchmark，涵盖HSK 3-6级真实教材、合成样本和评价体系，并设计课程调优框架使模型从初级到高级逐步训练，同时构建多维评估系统检验语法覆盖、写作错误、词汇和句法复杂性及整体评分，进一步细调生成HSKAgent模型。

Result: HSKBenchmark成功实现了中文二语习得的建模与动态写作评估。细调后的LLM在写作表现上接近高级人类学习者，展示出与人类相似的语言习得特征。

Conclusion: HSKBenchmark及相关工具为中文二语习得建模和大型语言模型可解释性研究提供了基础资源，促进未来语言习得与模型评估的研究发展。

Abstract: Language acquisition is vital to revealing the nature of human language intelligence and has recently emerged as a promising perspective for improving the interpretability of large language models (LLMs). However, it is ethically and practically infeasible to conduct experiments that require controlling human learners' language inputs. This poses challenges for the verifiability and scalability of language acquisition modeling, particularly in Chinese second language acquisition (SLA). While LLMs provide a controllable and reproducible alternative, a systematic benchmark to support phase-wise modeling and assessment is still lacking. In this paper, we present HSKBenchmark, the first benchmark for staged modeling and writing assessment of LLMs in Chinese SLA. It covers HSK levels 3 to 6 and includes authentic textbooks with 6.76 million tokens, 16K synthetic instruction samples, 30 test topics, and a linguistically grounded evaluation system. To simulate human learning trajectories, we introduce a curriculum-tuning framework that trains models from beginner to advanced levels. An evaluation system is created to examine level-based grammar coverage, writing errors, lexical and syntactic complexity, and holistic scoring. We also build HSKAgent, fine-tuned on 10K learner compositions. Extensive experimental results demonstrate that HSKBenchmark not only models Chinese SLA effectively, but also serves as a reliable benchmark for dynamic writing assessment in LLMs. Our fine-tuned LLMs have writing performance on par with advanced human learners and exhibit human-like acquisition characteristics. The HSKBenchmark, HSKAgent, and checkpoints serve as foundational tools and resources, with the potential to pave the way for future research on language acquisition modeling and LLMs interpretability. Code and data are publicly available at: https://github.com/CharlesYang030/HSKB.

</details>


### [28] [Tokenisation over Bounded Alphabets is Hard](https://arxiv.org/abs/2511.15709)
*Violeta Kastreva,Philip Whittington,Dennis Komm,Tiago Pimentel*

Main category: cs.CL

TL;DR: 本文研究了固定字母表大小下的分词问题，证明即使在二元字母表下，相关分词问题是NP完全且无多项式时间逼近方案。


<details>
  <summary>Details</summary>
Motivation: 以往研究假设字母表大小无限制，而现实中分词通常在固定大小的字母表上进行，本文旨在分析实际中更合理的有限字母表情形下的分词复杂性。

Method: 分析有限$n$元字母表下的两种分词方式（自底向上分词和直接分词），证明二元字母表下分词问题的NP完全性及无多项式时间逼近方案存在性，并扩展至单元字母表情形。

Result: 证明固定大小字母表（包括二元和单元字母表）下的分词问题均为NP完全，且不存在多项式时间逼近方案（除非P=NP），表明分词计算复杂性是根本性障碍。

Conclusion: 分词问题的计算复杂性为本质问题，解释了现有算法如BPE和UnigramLM为启发式方法，未来研究应关注近似算法以应对此挑战。

Abstract: Recent works have shown that tokenisation is NP-complete. However, these works assume tokenisation is applied to inputs with unboundedly large alphabets -- an unrealistic assumption, given that in practice tokenisers operate over fixed-size alphabets, such as bytes or Unicode characters. We close this gap by analysing tokenisation over bounded $n$-ary alphabets, considering two natural variants: bottom-up tokenisation and direct tokenisation, where we must, respectively, select a sequence of merge operations or a vocabulary whose application optimally compresses a dataset. First, we note that proving hardness results for an $n$-ary alphabet proves the same results for alphabets of any larger size. We then prove that even with binary alphabets, both variants are not only NP-complete, but admit no polynomial-time approximation scheme (unless P=NP). We further show that direct tokenisation remains NP-complete even when applied to unary alphabets. While unary alphabets may not be practically useful, this result establishes that the computational intractability of tokenisation is not an artifact of large alphabets or complex constructions, but a fundamental barrier. Overall, our results explain why practical algorithms such as BPE and UnigramLM are heuristic, and points toward approximation algorithms being an important path going forward for tokenisation research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [29] [Hybrid Quantum-Classical Machine Learning with PennyLane: A Comprehensive Guide for Computational Research](https://arxiv.org/abs/2511.14786)
*Sidney Shapiro*

Main category: cs.SE

TL;DR: 本文介绍了PennyLane，一个融合量子电路与经典机器学习的Python框架，支持量子机器学习、优化和量子化学应用。


<details>
  <summary>Details</summary>
Motivation: 混合量子-经典机器学习结合了量子计算的潜力与经典优化技术，需一个高效工具促进应用发展。

Method: PennyLane框架支持量子电路构建、自动微分及混合优化，兼容主流经典ML框架，并通过Python示例展示具体用例。

Result: 成功演示了量子核方法、变分量子特征求解器、投资组合优化及与PyTorch、TensorFlow、JAX等集成的功能。

Conclusion: PennyLane作为量子机器学习与经典技术的桥梁，推动量子增强数据科学的发展，成为混合工作流的标准工具。

Abstract: Hybrid quantum-classical machine learning represents a frontier in computational research, combining the potential advantages of quantum computing with established classical optimization techniques. PennyLane provides a Python framework that seamlessly bridges quantum circuits and classical machine learning, enabling researchers to build, optimize, and deploy variational quantum algorithms. This paper introduces PennyLane as a versatile tool for quantum machine learning, optimization, and quantum chemistry applications. We demonstrate use cases including quantum kernel methods, variational quantum eigensolvers, portfolio optimization, and integration with classical ML frameworks such as PyTorch, TensorFlow, and JAX. Through concrete Python examples with widely used libraries such as scikit-learn, pandas, and matplotlib, we show how PennyLane facilitates efficient quantum circuit construction, automatic differentiation, and hybrid optimization workflows. By situating PennyLane within the broader context of quantum computing and machine learning, we highlight its role as a methodological building block for quantum-enhanced data science. Our goal is to provide researchers and practitioners with a concise reference that bridges foundational quantum computing concepts and applied machine learning practice, making PennyLane a default citation for hybrid quantum-classical workflows in Python-based research.

</details>


### [30] [Enabling Predictive Maintenance in District Heating Substations: A Labelled Dataset and Fault Detection Evaluation Framework based on Service Data](https://arxiv.org/abs/2511.14791)
*Cyriana M. A. Roelofs,Edison Guevara Bastidas,Thomas Hugo,Stefan Faulstich,Anna Cadenbach*

Main category: cs.SE

TL;DR: 该论文提出了一个用于区域供热分站故障早期检测的开源框架，包含公开标注数据集、评估方法和基线结果，实现了高准确率和提前报警能力。


<details>
  <summary>Details</summary>
Motivation: 提高区域供热分站的故障早期检测能力，以降低回水温度、提升系统效率，但受限于公开标注数据集的缺乏，导致研究进展缓慢。

Method: 构建并公开包含93个分站时间序列数据及详细故障维护标注的数据集，提出基于准确率、可靠性（事件F分数）和提前量的评估指标，使用EnergyFaultDetector开源Python框架实现基线模型，并支持通过ARCANA进行根因分析。

Result: 模型在识别正常行为上准确率0.98，事件F分数0.83，实现60%的故障提前检测，提前平均3.9天报警。框架支持异常解释和故障定位的三种应用场景。

Conclusion: 该方案整合公开数据、评价指标、开源代码和基线，建立了一个可复现、有操作意义的故障早期检测基准，有助于相关领域方法的统一比较和持续发展。

Abstract: Early detection of faults in district heating substations is imperative to reduce return temperatures and enhance efficiency. However, progress in this domain has been hindered by the limited availability of public, labelled datasets. We present an open source framework combining a service report validated public dataset, an evaluation method based on Accuracy, Reliability, and Earliness, and baseline results implemented with EnergyFaultDetector, an open source Python framework.
  The dataset contains time series of operational data from 93 substations across two manufacturers, annotated with a list of disturbances due to faults and maintenance actions, a set of normal-event examples and detailed fault metadata. We evaluate the EnergyFaultDetector using three metrics: Accuracy for recognising normal behaviour, an eventwise F Score for reliable fault detection with few false alarms, and Earliness for early detection. The framework also supports root cause analysis using ARCANA. We demonstrate three use cases to assist operators in interpreting anomalies and identifying underlying faults. The models achieve high normal-behaviour accuracy (0.98) and eventwise F-score (beta=0.5) of 0.83, detecting 60% of the faults in the dataset before the customer reports a problem, with an average lead time of 3.9 days.
  Integrating an open dataset, metrics, open source code, and baselines establishes a reproducible, fault centric benchmark with operationally meaningful evaluation, enabling consistent comparison and development of early fault detection and diagnosis methods for district heating substations.

</details>


### [31] [irace-evo: Automatic Algorithm Configuration Extended With LLM-Based Code Evolution](https://arxiv.org/abs/2511.14794)
*Camilo Chacón Sartori,Christian Blum*

Main category: cs.SE

TL;DR: 这篇论文介绍了irace-evo，一种结合大型语言模型进行代码进化与参数调优的自动算法配置工具，能够在多语言环境下有效优化算法性能，显著提升了变尺寸装箱问题的元启发式算法表现，同时保持低成本和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有自动算法配置工具如irace只能调整参数，无法改进算法代码，限制了算法性能的进一步提升。

Method: 提出irace-evo，将大型语言模型嵌入算法配置框架，通过渐进式上下文管理和始终基于原始代码原则，实现代码和参数的联合进化。

Result: 在变尺寸装箱问题的CMSA元启发式算法上，irace-evo发现了优于当前最先进实现的新算法变体，且使用了成本低廉的轻量级模型，整体使用成本不足2欧元。

Conclusion: 结合自动配置技术和大型语言模型驱动的代码演进，为启发式算法设计和元启发式优化提供了一条有效且经济的改进路径。

Abstract: Automatic algorithm configuration tools such as irace efficiently tune parameter values but leave algorithmic code unchanged. This paper introduces a first version of irace-evo, an extension of irace that integrates code evolution through large language models (LLMs) to jointly explore parameter and code spaces. The proposed framework enables multi-language support (e.g., C++, Python), reduces token consumption via progressive context management, and employs the Always-From-Original principle to ensure robust and controlled code evolution. We evaluate irace-evo on the Construct, Merge, Solve & Adapt (CMSA) metaheuristic for the Variable-Sized Bin Packing Problem (VSBPP). Experimental results show that irace-evo can discover new algorithm variants that outperform the state-of-the-art CMSA implementation while maintaining low computational and monetary costs. Notably, irace-evo generates competitive algorithmic improvements using lightweight models (e.g., Claude Haiku 3.5) with a total usage cost under 2 euros. These results demonstrate that coupling automatic configuration with LLM-driven code evolution provides a powerful, cost-efficient avenue for advancing heuristic design and metaheuristic optimization.

</details>


### [32] [Evaluating Generative AI for CS1 Code Grading: Direct vs Reverse Methods](https://arxiv.org/abs/2511.14798)
*Ahmad Memon,Abdallah Mohamed*

Main category: cs.SE

TL;DR: 本文比较了两种基于人工智能的编程作业评分方法：直接评分法和逆向评分法，发现逆向评分法更细致，能更好地反映纠错努力，但两者都需精心设计提示。


<details>
  <summary>Details</summary>
Motivation: 手动评分耗时且易产生不一致，单元测试虽自动但仅二元判断，需更精细且客观的自动评分方法。

Method: 提出直接法和逆向法两种AI评分技术，分别在不同评分量表和真实及合成代码上对比评估，同时分析了提示设计的重要性。

Result: 直接法较快简洁，逆向法在细粒度评分上表现更优，能更准确反映错误修正工作量。合成数据扩展了错误类型和难度范围的测试。

Conclusion: 逆向法具潜力提升评分细致度和公平性，提示设计至关重要，未来混合人机评分系统有望提高一致性和效率。

Abstract: Manual grading of programming assignments in introductory computer science courses can be time-consuming and prone to inconsistencies. While unit testing is commonly used for automatic evaluation, it typically follows a binary pass/fail model and does not give partial marks. Recent advances in large language models (LLMs) offer the potential for automated, scalable, and more objective grading.
  This paper compares two AI-based grading techniques: \textit{Direct}, where the AI model applies a rubric directly to student code, and \textit{Reverse} (a newly proposed approach), where the AI first fixes errors, then deduces a grade based on the nature and number of fixes. Each method was evaluated on both the instructor's original grading scale and a tenfold expanded scale to assess the impact of range on AI grading accuracy. To assess their effectiveness, AI-assigned scores were evaluated against human tutor evaluations on a range of coding problems and error types.
  Initial findings suggest that while the Direct approach is faster and straightforward, the Reverse technique often provides a more fine-grained assessment by focusing on correction effort. Both methods require careful prompt engineering, particularly for allocating partial credit and handling logic errors. To further test consistency, we also used synthetic student code generated using Gemini Flash 2.0, which allowed us to evaluate AI graders on a wider range of controlled error types and difficulty levels. We discuss the strengths and limitations of each approach, practical considerations for prompt design, and future directions for hybrid human-AI grading systems that aim to improve consistency, efficiency, and fairness in CS courses.

</details>


### [33] [Scalable and Efficient Large-Scale Log Analysis with LLMs: An IT Software Support Case Study](https://arxiv.org/abs/2511.14803)
*Pranjal Gupta,Karan Bhukar,Harshit Kumar,Seema Nagar,Prateeti Mohapatra,Debanjana Kar*

Main category: cs.SE

TL;DR: 本文提出了一种基于大型语言模型（LLMs）的日志分析工具，能够自动处理海量日志并诊断问题，显著提升日志分析效率。


<details>
  <summary>Details</summary>
Motivation: 由于IT环境产生的日志数据量极大，人工分析不现实，需自动化工具辅助日志处理和问题诊断。

Method: 利用大型语言模型处理日志数据，设计了在CPU上高效运行LLMs的方法，以最小时间内处理大量日志且保证结果质量。

Result: 该工具自2024年3月投产，覆盖70个软件产品，处理2000多个工单，节省人工小时300+，估计每月节省人力成本15,444美元。

Conclusion: 本文工具成功实现了基于LLMs的自动日志分析和问题诊断，显著降低人工成本，提高了IT软件支持的效率和响应速度。

Abstract: IT environments typically have logging mechanisms to monitor system health and detect issues. However, the huge volume of generated logs makes manual inspection impractical, highlighting the importance of automated log analysis in IT Software Support. In this paper, we propose a log analytics tool that leverages Large Language Models (LLMs) for log data processing and issue diagnosis, enabling the generation of automated insights and summaries. We further present a novel approach for efficiently running LLMs on CPUs to process massive log volumes in minimal time without compromising output quality. We share the insights and lessons learned from deployment of the tool - in production since March 2024 - scaled across 70 software products, processing over 2000 tickets for issue diagnosis, achieving a time savings of 300+ man hours and an estimated $15,444 per month in manpower costs compared to the traditional log analysis practices.

</details>


### [34] [Towards Continuous Assurance with Formal Verification and Assurance Cases](https://arxiv.org/abs/2511.14805)
*Dhaminda B. Abeywickrama,Michael Fisher,Frederic Wheeler,Louise Dennis*

Main category: cs.SE

TL;DR: 本文提出了一种统一的持续保障框架，整合设计时、运行时和演进时保障，以确保自主系统的安全性和正确性，并通过自动化模型转换保持可追溯性。


<details>
  <summary>Details</summary>
Motivation: 传统保障方法将设计时保障与运行时保障分离，无法应对运行时变化和系统更新，难以满足自主系统持续的安全和正确性需求。

Method: 提出统一的持续保障框架，设计时阶段结合RoboChart功能正确性验证和PRISM概率风险分析，设计了基于模型驱动的自动转换管道，通过Eclipse插件实现自动生成结构化保障论证，保证可追溯性。

Result: 在核检查机器人场景中验证了该方法，有效实现了设计时保障的自动更新和可追溯性，保障流程符合监管机构认可的三方人工智能原则。

Conclusion: 该框架有效整合了设计时及未来阶段的保障工作，增强了自主系统的持续安全性和正确性，为实现可持续保障和自主系统的可信运行提供了有力支持。

Abstract: Autonomous systems must sustain justified confidence in their correctness and safety across their operational lifecycle-from design and deployment through post-deployment evolution. Traditional assurance methods often separate development-time assurance from runtime assurance, yielding fragmented arguments that cannot adapt to runtime changes or system updates - a significant challenge for assured autonomy. Towards addressing this, we propose a unified Continuous Assurance Framework that integrates design-time, runtime, and evolution-time assurance within a traceable, model-driven workflow as a step towards assured autonomy. In this paper, we specifically instantiate the design-time phase of the framework using two formal verification methods: RoboChart for functional correctness and PRISM for probabilistic risk analysis. We also propose a model-driven transformation pipeline, implemented as an Eclipse plugin, that automatically regenerates structured assurance arguments whenever formal specifications or their verification results change, thereby ensuring traceability. We demonstrate our approach on a nuclear inspection robot scenario, and discuss its alignment with the Trilateral AI Principles, reflecting regulator-endorsed best practices.

</details>


### [35] [Automatic Pipeline Provisioning](https://arxiv.org/abs/2511.14825)
*Alexandre-Xavier Labonté-Lamoureux,Simon Boyer*

Main category: cs.SE

TL;DR: 本文探讨自动化流水线配置的优势及其应用，重点研究持续集成（CI）流水线的快速部署过程。


<details>
  <summary>Details</summary>
Motivation: 提高软件工程项目中流水线部署的效率和自动化水平，减少人工配置带来的时间和错误。

Method: 通过分析自动化流水线配置的过程，重点实施快速部署CI流水线的方法。

Result: 展示了自动化流水线配置在快速部署CI流水线中的有效性，推测该方法同样适用于持续交付（CD）流水线。

Conclusion: 自动化流水线配置能够显著加快流水线部署速度，提升软件项目的开发效率，具有广泛的应用前景。

Abstract: The goal of this paper is to explore the benefits of automatic pipeline provisioning and identify how it can be applied. Automatic pipeline provisioning can be defined as a process of quickly deploying a pipeline for a software engineering project. This research will focus on CI pipelines, although the outcomes of this approach on CD pipelines will likely be similar.

</details>


### [36] [MermaidSeqBench: An Evaluation Benchmark for LLM-to-Mermaid Sequence Diagram Generation](https://arxiv.org/abs/2511.14967)
*Basel Shbita,Farhan Ahmed,Chad DeLuca*

Main category: cs.SE

TL;DR: 提出了MermaidSeqBench基准，用于评估大型语言模型从文本生成Mermaid序列图的能力，涵盖语法正确性、激活处理、错误处理和实用性，填补当前评测不足。


<details>
  <summary>Details</summary>
Motivation: 现有工作缺乏系统性评测，无法准确评价大型语言模型生成序列图的正确性。

Method: 构建包含132个人工核验样本的基准，结合人工标注、LLM提示和规则扩展生成更多样本，并采用LLM作为评审模型，基于细粒度指标评估生成效果。

Result: 通过对多款最新LLM进行评测，发现模型在不同指标和评测模式下存在显著能力差距，验证了基准的有效性和灵活性。

Conclusion: MermaidSeqBench为结构化图生成的研究提供了坚实基础，推动更严谨、细致的评测方法的发展。

Abstract: Large language models (LLMs) have demonstrated excellent capabilities in generating structured diagrams from natural language descriptions. In particular, they have shown great promise in generating sequence diagrams for software engineering, typically represented in a text-based syntax such as Mermaid. However, systematic evaluations in this space remain underdeveloped as there is a lack of existing benchmarks to assess the LLM's correctness in this task. To address this shortcoming, we introduce MermaidSeqBench, a human-verified and LLM-synthetically-extended benchmark for assessing an LLM's capabilities in generating Mermaid sequence diagrams from textual prompts. The benchmark consists of a core set of 132 samples, starting from a small set of manually crafted and verified flows. These were expanded via a hybrid methodology combining human annotation, in-context LLM prompting, and rule-based variation generation. Our benchmark uses an LLM-as-a-judge model to assess Mermaid sequence diagram generation across fine-grained metrics, including syntax correctness, activation handling, error handling, and practical usability. We perform initial evaluations on numerous state-of-the-art LLMs and utilize multiple LLM judge models to demonstrate the effectiveness and flexibility of our benchmark. Our results reveal significant capability gaps across models and evaluation modes. Our proposed benchmark provides a foundation for advancing research in structured diagram generation and for developing more rigorous, fine-grained evaluation methodologies.

</details>


### [37] [FRIENDS GUI: A graphical user interface for data collection and visualization of vaping behavior from a passive vaping monitor](https://arxiv.org/abs/2511.15007)
*Shehan I Pranto,Brett Fassler,Md Rafi Islam,Ashley Schenkel,Larry W Hawk,Edward Sazonov*

Main category: cs.SE

TL;DR: 本文介绍了FRIENDS GUI，一款开源Python工具，用于可视化和分析从FRIENDS装置收集的电子烟吸吮数据，验证了其准确性并开放源代码。


<details>
  <summary>Details</summary>
Motivation: 了解电子烟使用的吸吮行为对于评估毒物暴露和制定监管政策至关重要，现有数据采集工具缺乏易用和可解释的分析界面。

Method: 开发了基于Python的开源GUI工具，能够提取、解码并可视化FRIENDS设备24小时采集的吸吮数据，并通过实验数据验证其准确性和可靠性。

Result: 验证结果显示，该GUI能够准确转换时间戳、可靠解码事件及有效可视化行为，提升了数据的可访问性和解读能力。

Conclusion: FRIENDS GUI作为一个免费开源的软件工具，极大地促进了电子烟使用行为数据的分析与共享，为相关研究和监管提供了便利。

Abstract: Understanding puffing topography (PT), which includes puff duration, intra puff interval, and puff count per session, is critical for evaluating Electronic Nicotine Delivery Systems (ENDS) use, toxicant exposure, and informing regulatory decisions. We developed FRIENDS (Flexible Robust Instrumentation of ENDS), an open-source device that records puffing and touch events of ENDS by attaching to it. This paper introduces the FRIENDS GUI that improves accessibility and interpretability of data collected by FRIENDS. The GUI is a Python-based open-source tool that extracts, decodes, and visualizes 24-hour puffing data from the FRIENDS device. Validation using 24-hour experimental data confirmed accurate timestamp conversion, reliable event decoding, and effective behavioral visualization. The software is freely available on GitHub for public use.

</details>


### [38] [Effective Code Membership Inference for Code Completion Models via Adversarial Prompts](https://arxiv.org/abs/2511.15107)
*Yuan Jiang,Zehao Li,Shan Huang,Christoph Treude,Xiaohong Su,Tiantian Wang*

Main category: cs.SE

TL;DR: 本文提出了一种针对代码补全模型的成员推断攻击方法AdvPrompt-MIA，通过设计对抗性提示捕获模型记忆模式，显著提升推断准确率。


<details>
  <summary>Details</summary>
Motivation: 现有针对代码补全模型的成员推断攻击依赖昂贵的替代模型或手工启发式规则，难以捕捉模型微妙的记忆模式，限制攻击效果。

Method: 提出结合代码特定对抗扰动与深度学习的AdvPrompt-MIA方法，设计对抗性提示引起模型输出变化，通过与真实代码完成对比提取特征，训练分类器自动区分成员与非成员。

Result: 在Code Llama 7B等主流模型及APPS、HumanEval数据集上的评测显示，该方法在AUC指标上相较现有最优方法提升高达102%，且在不同模型和数据集上表现出较强的迁移能力。

Conclusion: AdvPrompt-MIA方法通过对抗提示有效捕捉代码补全模型的记忆模式，实现高效准确的成员推断攻击，具备良好的实用性和泛化能力。

Abstract: Membership inference attacks (MIAs) on code completion models offer an effective way to assess privacy risks by inferring whether a given code snippet was part of the training data. Existing black- and gray-box MIAs rely on expensive surrogate models or manually crafted heuristic rules, which limit their ability to capture the nuanced memorization patterns exhibited by over-parameterized code language models. To address these challenges, we propose AdvPrompt-MIA, a method specifically designed for code completion models, combining code-specific adversarial perturbations with deep learning. The core novelty of our method lies in designing a series of adversarial prompts that induce variations in the victim code model's output. By comparing these outputs with the ground-truth completion, we construct feature vectors to train a classifier that automatically distinguishes member from non-member samples. This design allows our method to capture richer memorization patterns and accurately infer training set membership. We conduct comprehensive evaluations on widely adopted models, such as Code Llama 7B, over the APPS and HumanEval benchmarks. The results show that our approach consistently outperforms state-of-the-art baselines, with AUC gains of up to 102%. In addition, our method exhibits strong transferability across different models and datasets, underscoring its practical utility and generalizability.

</details>


### [39] [Finetuning LLMs for Automatic Form Interaction on Web-Browser in Selenium Testing Framework](https://arxiv.org/abs/2511.15168)
*Nguyen-Khang Le,Nguyen Hiep,Minh Nguyen,Son Luu,Trung Vo,Quan Bui,Nomura Shoshin,Le-Minh Nguyen*

Main category: cs.SE

TL;DR: 本文提出了一种训练大语言模型（LLM）生成高质量Selenium测试脚本的新方法，专注于表单交互测试，通过综合数据集和明确定义的指标显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 自动化网页应用测试中，表单交互测试任务虽然关键但未被充分研究，缺乏评价大语言模型生成表单交互脚本的公开基准。

Method: 构建合成及人工注释数据集，训练LLM生成符合语法、可执行并涵盖多样输入字段的Selenium测试脚本，设计专门的评价指标。

Result: 所提方法在语法正确性、脚本可执行性及输入字段覆盖率等指标上，显著优于GPT-4o及其他主流大语言模型。

Conclusion: 该研究为基于LLM的网页测试奠定基础，提供数据和评价资源，促进该领域的持续进展。

Abstract: Automated web application testing is a critical component of modern software development, with frameworks like Selenium widely adopted for validating functionality through browser automation. Among the essential aspects of such testing is the ability to interact with and validate web forms, a task that requires syntactically correct, executable scripts with high coverage of input fields. Despite its importance, this task remains underexplored in the context of large language models (LLMs), and no public benchmark or dataset exists to evaluate LLMs on form interaction generation systematically. This paper introduces a novel method for training LLMs to generate high-quality test cases in Selenium, specifically targeting form interaction testing. We curate both synthetic and human-annotated datasets for training and evaluation, covering diverse real-world forms and testing scenarios. We define clear metrics for syntax correctness, script executability, and input field coverage. Our empirical study demonstrates that our approach significantly outperforms strong baselines, including GPT-4o and other popular LLMs, across all evaluation metrics. Our work lays the groundwork for future research on LLM-based web testing and provides resources to support ongoing progress in this area.

</details>


### [40] [From Code Smells to Best Practices: Tackling Resource Leaks in PyTorch, TensorFlow, and Keras](https://arxiv.org/abs/2511.15229)
*Bashar Abdallah,Martyna E. Wojciechowska,Gustavo Santos,Edmand Yu,Maxime Lamothe,Alain Abran,Mohammad Hamdaqa*

Main category: cs.SE

TL;DR: 本文系统识别导致机器学习应用资源泄漏的代码臭味，基于PyTorch、TensorFlow和Keras的实证分析，提出50条最佳编码实践以提升资源利用效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习研究多关注模型性能，忽视长远的资源效率和可持续性，本文旨在填补这一空白，通过识别资源泄漏相关的代码臭味，为开发者提供指导。

Method: 通过分析开发者讨论和真实代码片段，识别30个与PyTorch相关及16个与TensorFlow/Keras相关的资源泄漏臭味，进行原因分类并归纳最佳实践，同时通过三阶段验证确保结果可靠。

Result: 共发现46种资源泄漏相关代码臭味，提出50条减少资源泄漏和提升效率的编码模式，首次综合分析主流ML框架中的资源泄漏问题。

Conclusion: 本文首次全面揭示了主流机器学习框架中的资源泄漏代码臭味及其根源，提供了切实可行的优化实践，有助于开发更高效可持续的机器学习应用。

Abstract: Much of the existing ML research focuses on model performance metrics, leaving limited attention to the long-term sustainability and resource efficiency of ML applications. While high performance is essential, ensuring efficient resource management is equally critical for robust deployment. This study addresses this gap by systematically identifying code smells that lead to resource leaks in ML applications. We conducted an empirical investigation of developer discussions and real-world code snippets from PyTorch, TensorFlow, and Keras. The analysis identified 30 PyTorch-related smells and 16 TensorFlow/Keras smells linked to resource leaks. These smells were categorized in two ways: (1) based on their root causes, and (2) as general ML smells with framework-specific characteristics. For each smell, we derived at least one best practice, resulting in 50 recommended coding patterns aimed at reducing resource leakage and improving efficiency. To ensure the validity of our findings, we employed a three-phase validation process involving independent analysis by three authors followed by consensus discussions. This is the first comprehensive study to examine resource-leak-inducing code smells across major ML frameworks and to present actionable best practices for mitigating them. The contributions support developers in building more efficient and sustainable ML applications and offer a structured view of the underlying causes of resource leaks.

</details>


### [41] [M, Toolchain and Language for Reusable Model Compilation](https://arxiv.org/abs/2511.15257)
*Hiep Hong Trinh,Federico Ciccozzi,Abu Naser Masud,Marjan Sirjani,Mikael Sjödin*

Main category: cs.SE

TL;DR: 本文介绍了一种名为M的建模语言和工具链，支持复杂并发系统的多目标模型编译，解决传统建模语言多目标编译困难的问题。


<details>
  <summary>Details</summary>
Motivation: 复杂软件驱动系统需要针对不同目的衍生多种特定模型，现有建模语言多聚焦于单一目标，难以支持多目标编译。

Method: 提出基于Actor模型和离散事件调度语义的文本化语法驱动语言M，能够定义系统实体、消息交互及触发反应，并支持多目标模型生成和语义一致性。

Result: M语言和工具链能够系统性生成多样目标产物，保持模型语义一致，并作为其他建模语言的中间语言平台。

Conclusion: M语言为复杂并发时序系统的模型驱动工程提供了有效的多目标编译支持，提升了建模与实现的效率和安全性。

Abstract: Complex software-driven systems often interleave distributed, concurrent computation processes with physical interactions with the environment. Developing these systems more efficiently and safely can be achieved by employing actionable, software-based models. From a high-level system model, engineers often need to derive multiple specialized models for different purposes, including simulation, deployment, and formal verification. Each of these target models usually rely on its own formalism, specification language, and execution platform. Traditionally, a compiler analyzes a program written in a programming language and generates executable code. In contrast, a model compiler processes a source model written in a modeling language and should ideally support the generation of multiple heterogeneous targets. However, most existing modeling languages are designed with a narrow focus, typically targeting only simulation or implementation. Multi-target compilation, when not considered during the language's early design, becomes significantly harder to achieve. In this paper, we introduce our initiative: a toolchain and modeling language called M, designed to support system modeling and multi-target compilation for model-driven engineering of complex, concurrent, and time-aware systems. M is a textual, grammar-driven language based on the actor model and extended with discrete-event scheduling semantics. It provides constructs for modeling system entities, message-based interactions, and time- or state-triggered reactions. From such models, M enables the systematic generation of diverse target artifacts while preserving semantic conformance to the original model. Moreover, M can serve as a middle language to which other modeling languages may anchor, thereby allowing them to benefit from its compilation framework.

</details>


### [42] [A Viable Paradigm of Software Automation: Iterative End-to-End Automated Software Development](https://arxiv.org/abs/2511.15293)
*Jia Li,Zhi Jin,Kechi Zhang,Huangzhao Zhang,Jiaru Qian,Tiankuo Zhao*

Main category: cs.SE

TL;DR: 本文提出了一种名为AutoSW的端到端自动化软件开发新范式，通过AI系统在分析、规划、实施和交付四个阶段作为合作伙伴，翻译自然语言意图为可执行软件，实现软件开发的高度自动化。


<details>
  <summary>Details</summary>
Motivation: 软件开发自动化是软件工程的长期目标，现有AI辅助和“vibe coding”路径将趋于融合，推动全栈软件开发边界扩展，实现AI全程参与软件开发生命周期。

Method: 提出AutoSW范式，基于分析-规划-实施-交付循环，设计AI系统作为人类合作伙伴，将自然语言需求转化为可执行代码，并验证了其轻量级原型及多种代表性用例。

Result: 初步实验结果表明，AutoSW能够成功交付可执行软件，展示了端到端自动化软件开发的可行性。

Conclusion: AutoSW为实现真正的端到端自动化软件开发提供了可行方向，AI将作为开发过程中的核心参与者，推动软件开发的自动化与智能化。

Abstract: Software development automation is a long-term goal in software engineering. With the development of artificial intelligence (AI), more and more researchers are exploring approaches to software automation. They view AI systems as tools or assistants in software development, still requiring significant human involvement. Another initiative is ``vibe coding'', where AI systems write and repeatedly revise most (or even all) of the code. We foresee these two development paths will converge towards the same destination: AI systems participate in throughout the software development lifecycle, expanding boundaries of full-stack software development. In this paper, we present a vision of an iterative end-to-end automated software development paradigm AutoSW. It operates in an analyze-plan-implement-deliver loop, where AI systems as human partners become first-class actors, translating human intentions expressed in natural language into executable software. We explore a lightweight prototype across the paradigm and initially execute various representative cases. The results indicate that AutoSW can successfully deliver executable software, providing a feasible direction for truly end-to-end automated software development.

</details>


### [43] [From Machine Learning Documentation to Requirements: Bridging Processes with Requirements Languages](https://arxiv.org/abs/2511.15340)
*Yi Peng,Hans-Martin Heyn,Jennifer Horkoff*

Main category: cs.SE

TL;DR: 研究调查了机器学习文档（如ModelCards和DataSheets）中需求工程相关信息的存在及其提取方法，证明可以将这些信息结构化为需求，促进ML系统的软件工程流程。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统中集成和验证ML组件困难，传统需求工程在ML组件需求规格方面遇到挑战，需要探索新的信息来源。

Method: 分析了20份公开的ModelCards和DataSheets，评估其包含的需求工程相关信息量和性质，并测试了三种需求表达方法（EARS、Rupp模板、Volere）将信息结构化的效果。

Result: 发现这些文档包含大量潜在的需求工程相关信息，且可以有效通过三种方法将ML文档知识转化为结构化需求。

Conclusion: 证明了从ML文档提取需求信息的可行路径，有助于在ML系统的软件工程过程中融入ML文档，提升需求规格的质量和完整性。

Abstract: In software engineering processes for machine learning (ML)-enabled systems, integrating and verifying ML components is a major challenge. A prerequisite is the specification of ML component requirements, including models and data, an area where traditional requirements engineering (RE) processes face new obstacles. An underexplored source of RE-relevant information in this context is ML documentation such as ModelCards and DataSheets. However, it is uncertain to what extent RE-relevant information can be extracted from these documents. This study first investigates the amount and nature of RE-relevant information in 20 publicly available ModelCards and DataSheets. We show that these documents contain a significant amount of potentially RE-relevant information. Next, we evaluate how effectively three established RE representations (EARS, Rupp's template, and Volere) can structure this knowledge into requirements. Our results demonstrate that there is a pathway to transform ML-specific knowledge into structured requirements, incorporating ML documentation in software engineering processes for ML systems.

</details>


### [44] [MutDafny: A Mutation-Based Approach to Assess Dafny Specifications](https://arxiv.org/abs/2511.15403)
*Isabel Amaral,Alexandra Mendes,José Campos*

Main category: cs.SE

TL;DR: 本文提出了MutDafny工具，利用变异测试揭示Dafny程序规范中的弱点，提升规范的可靠性。


<details>
  <summary>Details</summary>
Motivation: Dafny等验证感知编程语言中的规范存在错误风险，导致验证通过的程序行为偏离预期。

Method: 通过引入变异（错误），利用规范检测变异程序是否依然验证成功，识别规范中的潜在弱点。结合32种变异算子（来自已有工具和Dafny项目中bug修复），自动化检测规范弱点。

Result: 在794个真实Dafny程序上评估工具的有效性和效率，手工分析未检测变异，发现5个真实规范弱点，约每241行代码发现一个。

Conclusion: MutDafny能够有效发现并提示Dafny规范中的潜在弱点，促进规范的强化和程序行为的准确性。

Abstract: This paper explores the use of mutation testing to reveal weaknesses in formal specifications written in Dafny. In verification-aware programming languages, such as Dafny, despite their critical role, specifications are as prone to errors as implementations. Flaws in specs can result in formally verified programs that deviate from the intended behavior.
  We present MutDafny, a tool that increases the reliability of Dafny specifications by automatically signaling potential weaknesses. Using a mutation testing approach, we introduce faults (mutations) into the code and rely on formal specifications for detecting them. If a program with a mutant verifies, this may indicate a weakness in the specification. We extensively analyze mutation operators from popular tools, identifying the ones applicable to Dafny. In addition, we synthesize new operators tailored for Dafny from bugfix commits in publicly available Dafny projects on GitHub. Drawing from both, we equipped our tool with a total of 32 mutation operators. We evaluate MutDafny's effectiveness and efficiency in a dataset of 794 real-world Dafny programs and we manually analyze a subset of the resulting undetected mutants, identifying five weak real-world specifications (on average, one at every 241 lines of code) that would benefit from strengthening.

</details>


### [45] [EPSO: A Caching-Based Efficient Superoptimizer for BPF Bytecode](https://arxiv.org/abs/2511.15589)
*Qian Zhu,Yuxuan Liu,Ziyuan Zhu,Shangqing Liu,Lei Bu*

Main category: cs.SE

TL;DR: 本文提出了EPSO，一种基于缓存的超级优化器，通过离线超级优化发现并重用重写规则，从而在保证内核安全约束下优化eBPF程序，显著减少程序体积和运行时间。


<details>
  <summary>Details</summary>
Motivation: 现有eBPF编译器优化支持有限，且安全验证器拒绝许多语义保持转换，导致手工设计优化规则困难且效果有限。超级优化虽然能自动发现最佳转换，但计算成本高，难以扩展。

Method: EPSO通过离线超级优化生成重写规则并缓存，在运行时快速应用这些规则，实现高质量、低开销的优化。

Result: EPSO在多个Linux内核及eBPF项目基准测试中发现795条重写规则，程序体积最高减少68.87％，平均减少24.37％，优于现有优化器K2和Merlin。程序运行时间平均减少6.60％，提升了网络应用的吞吐和延迟表现。

Conclusion: EPSO有效克服了传统基于规则优化和超级优化的限制，实现了对eBPF程序的高效优化，为内核层安全且性能关键的程序优化提供了新方案。

Abstract: Extended Berkeley Packet Filter (eBPF) allows developers to extend Linux kernel functionality without modifying its source code. To ensure system safety, an in-kernel safety checker, the verifier, enforces strict safety constraints (for example, a limited program size) on eBPF programs loaded into the kernel. These constraints, combined with eBPF's performance-critical use cases, make effective optimization essential. However, existing compilers (such as Clang) offer limited optimization support, and many semantics-preserving transformations are rejected by the verifier, which makes handcrafted optimization rule design both challenging and limited in effectiveness. Superoptimization overcomes the limitations of rule-based methods by automatically discovering optimal transformations, but its high computational cost limits scalability. To address this, we propose EPSO, a caching-based superoptimizer that discovers rewrite rules via offline superoptimization and reuses them to achieve high-quality optimizations with minimal runtime overhead. We evaluate EPSO on benchmarks from the Linux kernel and several eBPF-based projects, including Cilium, Katran, hXDP, Sysdig, Tetragon, and Tracee. EPSO discovers 795 rewrite rules and achieves up to 68.87 percent (average 24.37 percent) reduction in program size compared to Clang's output, outperforming the state-of-the-art BPF optimizer K2 on all benchmarks and Merlin on 92.68 percent of them. Additionally, EPSO reduces program runtime by an average of 6.60 percent, improving throughput and lowering latency in network applications.

</details>


### [46] [Quantum-Guided Test Case Minimization for LLM-Based Code Generation](https://arxiv.org/abs/2511.15665)
*Huixiang Zhang,Mahzabeen Emu*

Main category: cs.SE

TL;DR: 提出了一种基于测试驱动开发的框架，将代码规范转化为组合优化任务，实现高效简洁代码生成。


<details>
  <summary>Details</summary>
Motivation: 精准控制大型语言模型生成高效且简洁代码是软件工程中的关键挑战。

Method: 利用大型语言模型生成测试套件，并将测试用例最小化问题转化为二次无约束二进制优化模型，兼容经典求解器和量子退火硬件。

Result: 量子退火比模拟退火快16倍完成核心任务，整体框架减少36.5%令牌消耗，显著提升代码质量。

Conclusion: 结合生成式AI和组合优化展示了提升软件工程效率的潜力，强调精确模型设计的重要性。

Abstract: Precisely controlling Large Language Models (LLMs) to generate efficient and concise code is a central challenge in software engineering. We introduce a framework based on Test-Driven Development (TDD) that transforms code specification into a combinatorial optimization task. The framework first prompts an LLM to generate a test suite, then formulates the Test Case Minimization (TCM) problem as a Quadratic Unconstrained Binary Optimization (QUBO) model. This QUBO paradigm is compatible with both classical solvers and emerging hardware such as quantum annealers. Experimentally, quantum annealing solves the core TCM task 16 times faster than simulated annealing. This performance underpins our end-to-end framework, which reduces total token consumption by 36.5\% and significantly improves code quality. This work demonstrates a powerful synergy between generative AI and combinatorial optimization in software engineering, highlighting the critical importance of precise model formulation.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [47] [Area-Optimal Control Strategies for Heterogeneous Multi-Agent Pursuit](https://arxiv.org/abs/2511.15036)
*Kamal Mammadov,Damith C. Ranasinghe*

Main category: cs.MA

TL;DR: 本文提出了一种多追捕者-慢逃避者博弈的新策略，通过定义逃避者安全可达区域并利用梯度下降控制追捕者头向，实现快速且有效的协同捕获。


<details>
  <summary>Details</summary>
Motivation: 解决多速度异质追捕者与单速度较慢逃避者之间的追逃博弈，提出可实时实现的协同捕获策略。

Method: 定义逃避者安全可达集为每对追捕者与逃避者的阿波罗尼奥斯圆的交集，构建零和博弈模型，通过解析地推导该区域面积关于代理位置的梯度，得到每个代理的最优头向控制律。

Result: 仿真结果表明，基于梯度的控制有效地引导追捕者逐步缩小逃避者的安全区域，从而保证捕获成功。

Conclusion: 该方法以面积最小化为几何目标，提供了一个计算高效且明确的协同捕获策略，适合实时应用。

Abstract: This paper presents a novel strategy for a multi-agent pursuit-evasion game involving multiple faster pursuers with heterogenous speeds and a single slower evader. We define a geometric region, the evader's safe-reachable set, as the intersection of Apollonius circles derived from each pursuer-evader pair. The capture strategy is formulated as a zero-sum game where the pursuers cooperatively minimize the area of this set, while the evader seeks to maximize it, effectively playing a game of spatial containment. By deriving the analytical gradients of the safe-reachable set's area with respect to agent positions, we obtain closed-form, instantaneous optimal control laws for the heading of each agent. These strategies are computationally efficient, allowing for real-time implementation. Simulations demonstrate that the gradient-based controls effectively steer the pursuers to systematically shrink the evader's safe region, leading to guaranteed capture. This area-minimization approach provides a clear geometric objective for cooperative capture.

</details>


### [48] [Distributed primal-dual algorithm for constrained multi-agent reinforcement learning under coupled policies](https://arxiv.org/abs/2511.15053)
*Pengcheng Dai,He Wang,Dongming Wang,Wenwu Yu*

Main category: cs.MA

TL;DR: 本文研究了受限的多智能体强化学习（CMARL），提出了一种基于局部邻域耦合策略的分布式原始-对偶算法，并证明了其收敛性，最后通过GridWorld模拟验证了方法有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体在协作最大化各自目标的同时需满足各自的安全约束，且在通信受限和不共享真实参数的情况下实现分布式学习具有挑战性。

Method: 提出基于耦合策略的分布式原始-对偶算法，智能体只访问局部邻域内的状态-动作和奖励信息，通过维护和交换变量估计避免直接共享真实参数，采用独立时变网络保证系统安全性。

Result: 算法在理论上具备以高概率达到近似一阶驻点的收敛性，误差与折扣因子及耦合与截断距离相关。

Conclusion: 所提框架和算法有效解决了CMARL中的安全约束和信息共享限制问题，理论和模拟结果均验证了方法的有效性。

Abstract: In this work, we investigate constrained multi-agent reinforcement learning (CMARL), where agents collaboratively maximize the sum of their local objectives while satisfying individual safety constraints. We propose a framework where agents adopt coupled policies that depend on both local states and parameters, as well as those of their $κ_p$-hop neighbors, with $κ_p>0$ denoting the coupling distance. A distributed primal-dual algorithm is further developed under this framework, wherein each agent has access only to state-action pairs within its $2κ_p$-hop neighborhood and to reward information within its $κ+ 2κ_p$-hop neighborhood, with $κ> 0$ representing the truncation distance. Moreover, agents are not permitted to directly share their true policy parameters or Lagrange multipliers. Instead, each agent constructs and maintains local estimates of these variables for other agents and employs such estimates to execute its policy. Additionally, these estimates are further updated and exchanged exclusively through an independent, time-varying networks, which enhances the overall system security. We establish that, with high probability, our algorithm can achieve an $ε$-first-order stationary convergence with an approximation error of $\mathcal{O}(γ^{\frac{κ+1}{κ_{p}}})$ for discount factor $γ\in(0,1)$. Finally, simulations in GridWorld environment are conducted to demonstrate the effectiveness of the proposed algorithm.

</details>


### [49] [Adversarial Attack on Black-Box Multi-Agent by Adaptive Perturbation](https://arxiv.org/abs/2511.15292)
*Jianming Chen,Yawen Wang,Junjie Wang,Xiaofei Xie,Yuanzhe Hu,Qing Wang,Fanjiang Xu*

Main category: cs.MA

TL;DR: 本文提出了针对多智能体系统的黑盒对抗攻击框架AdapAM，通过自适应选择策略和基于代理的扰动生成，实现在多环境下的高效且隐蔽的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统对抗攻击方法存在依赖白盒信息、高控制权限、或缺乏隐蔽性及效果不佳的问题，难以在实际应用中有效评估系统安全性与可靠性。

Method: AdapAM包含自适应选择策略，动态选择攻击目标及预期恶意行为，同时采用基于代理的扰动生成，通过生成对抗模仿学习近似目标系统，实现黑盒环境下诱导恶意行为。

Result: 在八个多智能体环境中，AdapAM在不同扰动率下表现出优异的攻击效果，且生成的扰动噪声最低且最难检测，显示出较高的隐蔽性和有效性。

Conclusion: AdapAM有效突破了现有攻击框架的限制，提供了一种既隐蔽又高效的多智能体系统黑盒对抗攻击方法，对于系统安全评估具有重要意义。

Abstract: Evaluating security and reliability for multi-agent systems (MAS) is urgent as they become increasingly prevalent in various applications. As an evaluation technique, existing adversarial attack frameworks face certain limitations, e.g., impracticality due to the requirement of white-box information or high control authority, and a lack of stealthiness or effectiveness as they often target all agents or specific fixed agents. To address these issues, we propose AdapAM, a novel framework for adversarial attacks on black-box MAS. AdapAM incorporates two key components: (1) Adaptive Selection Policy simultaneously selects the victim and determines the anticipated malicious action (the action would lead to the worst impact on MAS), balancing effectiveness and stealthiness. (2) Proxy-based Perturbation to Induce Malicious Action utilizes generative adversarial imitation learning to approximate the target MAS, allowing AdapAM to generate perturbed observations using white-box information and thus induce victims to execute malicious action in black-box settings. We evaluate AdapAM across eight multi-agent environments and compare it with four state-of-the-art and commonly-used baselines. Results demonstrate that AdapAM achieves the best attack performance in different perturbation rates. Besides, AdapAM-generated perturbations are the least noisy and hardest to detect, emphasizing the stealthiness.

</details>
