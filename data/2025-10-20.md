<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 52]
- [cs.SE](#cs.SE) [Total: 12]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Rethinking Toxicity Evaluation in Large Language Models: A Multi-Label Perspective](https://arxiv.org/abs/2510.15007)
*Zhiqiang Kou,Junyang Chen,Xin-Qiang Cai,Ming-Kun Xie,Biao Liu,Changwei Wang,Lei Feng,Yuheng Jia,Gang Niu,Masashi Sugiyama,Xin Geng*

Main category: cs.CL

TL;DR: 本文提出了三种多标签毒性检测基准数据集，针对多维度的毒性问题，采用伪标签方法提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有毒性检测依赖单标签数据，难以捕捉真实环境中的多维度毒性，且多标签标注成本高，导致检测不准确。

Method: 构建基于15类毒性细分的三种多标签数据集，理论证明伪标签训练优于单标签监督，提出基于伪标签的毒性检测方法。

Result: 实验表明该方法明显优于包括GPT-4o和DeepSeek在内的先进基线，提升了多标签毒性检测的准确性和可靠性。

Conclusion: 该研究通过多标签基准数据和伪标签训练，有效解决了多维毒性检测的不足，推动了大型语言模型内容安全评估的发展。

Abstract: Large language models (LLMs) have achieved impressive results across a range
of natural language processing tasks, but their potential to generate harmful
content has raised serious safety concerns. Current toxicity detectors
primarily rely on single-label benchmarks, which cannot adequately capture the
inherently ambiguous and multi-dimensional nature of real-world toxic prompts.
This limitation results in biased evaluations, including missed toxic
detections and false positives, undermining the reliability of existing
detectors. Additionally, gathering comprehensive multi-label annotations across
fine-grained toxicity categories is prohibitively costly, further hindering
effective evaluation and development. To tackle these issues, we introduce
three novel multi-label benchmarks for toxicity detection: \textbf{Q-A-MLL},
\textbf{R-A-MLL}, and \textbf{H-X-MLL}, derived from public toxicity datasets
and annotated according to a detailed 15-category taxonomy. We further provide
a theoretical proof that, on our released datasets, training with pseudo-labels
yields better performance than directly learning from single-label supervision.
In addition, we develop a pseudo-label-based toxicity detection method.
Extensive experimental results show that our approach significantly surpasses
advanced baselines, including GPT-4o and DeepSeek, thus enabling more accurate
and reliable evaluation of multi-label toxicity in LLM-generated content.

</details>


### [2] [Can generative AI figure out figurative language? The influence of idioms on essay scoring by ChatGPT, Gemini, and Deepseek](https://arxiv.org/abs/2510.15009)
*Enis Oğuz*

Main category: cs.CL

TL;DR: 本研究比较了三款生成式AI模型在评分含有和不含成语的学生作文中的表现，发现Gemini模型表现最佳，评分稳定且与人工评分最为一致。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI在自动评分学生作文中对成语理解的能力及其评分表现，评估AI作为AES系统的潜在替代者。

Method: 从348篇学生作文中构建两组作文列表（含成语组与无成语组），使用同一评分标准，三次让ChatGPT、Gemini和Deepseek三款生成式AI模型为所有作文打分，评估其评分一致性和与人工评分的一致性。

Result: 所有模型评分一致性良好，Gemini模型在与人工评分者的一致性（信度）方面表现最佳，且对不同人口群体无偏见。对含成语作文，Gemini的评分模式与人类评分最为接近。

Conclusion: 生成式AI在作文自动评分中表现出较大潜力，尤其是Gemini模型因其对比喻语言的处理能力，未来有望独立完成作文评分任务。

Abstract: The developments in Generative AI technologies have paved the way for
numerous innovations in different fields. Recently, Generative AI has been
proposed as a competitor to AES systems in evaluating student essays
automatically. Considering the potential limitations of AI in processing
idioms, this study assessed the scoring performances of Generative AI models
for essays with and without idioms by incorporating insights from Corpus
Linguistics and Computational Linguistics. Two equal essay lists were created
from 348 student essays taken from a corpus: one with multiple idioms present
in each essay and another with no idioms in essays. Three Generative AI models
(ChatGPT, Gemini, and Deepseek) were asked to score all essays in both lists
three times, using the same rubric used by human raters in assigning essay
scores. The results revealed excellent consistency for all models, but Gemini
outperformed its competitors in interrater reliability with human raters. There
was also no detectable bias for any demographic group in AI assessment. For
essays with multiple idioms, Gemini followed a the most similar pattern to
human raters. While the models in the study demonstrated potential for a hybrid
approach, Gemini was the best candidate for the task due to its ability to
handle figurative language and showed promise for handling essay-scoring tasks
alone in the future.

</details>


### [3] [A Generalizable Rhetorical Strategy Annotation Model Using LLM-based Debate Simulation and Labelling](https://arxiv.org/abs/2510.15081)
*Shiyu Ji,Farnoosh Hashemi,Joice Chen,Juanwen Pan,Weicheng Ma,Hefan Zhang,Sophia Pan,Ming Cheng,Shubham Mohole,Saeed Hassanpour,Soroush Vosoughi,Michael Macy*

Main category: cs.CL

TL;DR: 本文提出利用大型语言模型自动生成并标注辩论数据，基于四种修辞策略，训练分类器，实现高性能且具广泛适用性的修辞策略分析。


<details>
  <summary>Details</summary>
Motivation: 人工标注修辞策略成本高、效率低且数据受限，限制了修辞策略分析和模型泛化能力。

Method: 基于四种修辞类型（因果、经验、情感、道德）用大型语言模型生成合成数据，训练基于Transformer的分类器，并对模型在多数据集上的表现进行验证。

Result: 模型在多种主题和数据集上表现优异，预测说服力准确，并能分析历届美国总统辩论中修辞策略的时间和党派变化。

Conclusion: 利用大型语言模型生成数据标注修辞策略，能够有效提升模型性能及泛化能力，推动说服力预测和历史修辞策略研究。

Abstract: Rhetorical strategies are central to persuasive communication, from political
discourse and marketing to legal argumentation. However, analysis of rhetorical
strategies has been limited by reliance on human annotation, which is costly,
inconsistent, difficult to scale. Their associated datasets are often limited
to specific topics and strategies, posing challenges for robust model
development. We propose a novel framework that leverages large language models
(LLMs) to automatically generate and label synthetic debate data based on a
four-part rhetorical typology (causal, empirical, emotional, moral). We
fine-tune transformer-based classifiers on this LLM-labeled dataset and
validate its performance against human-labeled data on this dataset and on
multiple external corpora. Our model achieves high performance and strong
generalization across topical domains. We illustrate two applications with the
fine-tuned model: (1) the improvement in persuasiveness prediction from
incorporating rhetorical strategy labels, and (2) analyzing temporal and
partisan shifts in rhetorical strategies in U.S. Presidential debates
(1960-2020), revealing increased use of affective over cognitive argument in
U.S. Presidential debates.

</details>


### [4] [Continual Learning via Sparse Memory Finetuning](https://arxiv.org/abs/2510.15103)
*Jessy Lin,Luke Zettlemoyer,Gargi Ghosh,Wen-Tau Yih,Aram Markosyan,Vincent-Pierre Berges,Barlas Oğuz*

Main category: cs.CL

TL;DR: 本文提出了一种稀疏记忆微调方法，通过只更新模型中高激活的记忆槽，显著减缓了大语言模型的灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在不断学习新知识时容易出现灾难性遗忘，因为所有任务共用相同的可训练参数，导致新旧知识相互干扰。

Method: 利用记忆层模型结构，仅更新对新知识高度激活的记忆槽，实现稀疏参数更新，从而减少新知识与已有能力的干扰。

Result: 在两个问答任务上，稀疏记忆微调相比全量微调和LoRA方法，遗忘率大幅降低（如NaturalQuestions任务仅下降11%），同时仍能有效学习新知识。

Conclusion: 稀疏参数更新尤其是记忆层的稀疏更新为大语言模型的持续学习提供了一条有效路径，显著缓解了灾难性遗忘问题。

Abstract: Modern language models are powerful, but typically static after deployment. A
major obstacle to building models that continually learn over time is
catastrophic forgetting, where updating on new data erases previously acquired
capabilities. Motivated by the intuition that mitigating forgetting is
challenging because trainable parameters are shared across all tasks, we
investigate whether sparse parameter updates can enable learning without
catastrophic forgetting. We introduce sparse memory finetuning, leveraging
memory layer models (Berges et al., 2024), which are sparsely updated by
design. By updating only the memory slots that are highly activated by a new
piece of knowledge relative to usage on pretraining data, we reduce
interference between new knowledge and the model's existing capabilities. We
evaluate learning and forgetting compared to full finetuning and
parameter-efficient finetuning with LoRA on two question answering tasks. We
find that sparse memory finetuning learns new knowledge while exhibiting
substantially less forgetting: while NaturalQuestions F1 drops by 89% after
full finetuning on new facts and 71% with LoRA, sparse memory finetuning yields
only an 11% drop with the same level of new knowledge acquisition. Our results
suggest sparsity in memory layers offers a promising path toward continual
learning in large language models.

</details>


### [5] [Measuring the Effect of Disfluency in Multilingual Knowledge Probing Benchmarks](https://arxiv.org/abs/2510.15115)
*Kirill Semenov,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文针对多语言大型语言模型（LLMs）知识评测中模板翻译导致的语法错误问题，利用谷歌翻译和ChatGPT对部分斯拉夫语和其他语系语言进行了整句翻译，显著提升了知识检索得分。


<details>
  <summary>Details</summary>
Motivation: 现有多语言知识评测基准（如MLAMA）采用的模板翻译忽视命名实体的语法和语义信息，导致生成的提示语存在语法错误，影响评分的准确性和解释性。

Method: 选取MLAMA数据集中的4种斯拉夫语言及另外5种不同语系语言，比较原始模板翻译与谷歌翻译、ChatGPT整句翻译后的知识检索得分，并进行定性分析。

Result: 整句翻译显著提高了知识检索得分，且各语系语言表现出类似的模式，表明语法正确性对评测结果有重要影响。

Conclusion: 建议社区采用神经机器翻译或大型语言模型进行句子级别翻译，确保多语言数据集的语法正确性，以获得更高且更可解释的知识评测结果。相关数据集和代码已公开。

Abstract: For multilingual factual knowledge assessment of LLMs, benchmarks such as
MLAMA use template translations that do not take into account the grammatical
and semantic information of the named entities inserted in the sentence. This
leads to numerous instances of ungrammaticality or wrong wording of the final
prompts, which complicates the interpretation of scores, especially for
languages that have a rich morphological inventory. In this work, we sample 4
Slavic languages from the MLAMA dataset and compare the knowledge retrieval
scores between the initial (templated) MLAMA dataset and its sentence-level
translations made by Google Translate and ChatGPT. We observe a significant
increase in knowledge retrieval scores, and provide a qualitative analysis for
possible reasons behind it. We also make an additional analysis of 5 more
languages from different families and see similar patterns. Therefore, we
encourage the community to control the grammaticality of highly multilingual
datasets for higher and more interpretable results, which is well approximated
by whole sentence translation with neural MT or LLM systems. The dataset and
all related code is published at the Github repository:
https://github.com/ZurichNLP/Fluent-mLAMA.

</details>


### [6] [Latent Topic Synthesis: Leveraging LLMs for Electoral Ad Analysis](https://arxiv.org/abs/2510.15125)
*Alexander Brady,Tunazzina Islam*

Main category: cs.CL

TL;DR: 本文提出了一种结合无监督聚类与提示式标注的端到端框架，利用大型语言模型自动生成政治广告话题分类，揭示了2024年美国总统选举前Meta平台政治广告的潜在话语结构和道德框架。


<details>
  <summary>Details</summary>
Motivation: 社交媒体内容庞大且不断演变，分析其政治话语具有挑战性，需自动且可解释的话题分类方法支持。

Method: 通过无监督聚类结合基于提示的大型语言模型标注，迭代构建无监督话题分类，无需预设种子集或领域知识。

Result: 发现投票与移民广告占据主要支出和曝光，堕胎与选举诚信广告影响力较大，政治诉求在资金和话语框架上表现出极化与分裂；话题与道德基础之间存在强相关性。

Conclusion: 该框架支持对社交媒体政治传播进行可扩展、可解释的分析，有助理解数字政治话语中的叙事、极化及道德基础。

Abstract: Social media platforms play a pivotal role in shaping political discourse,
but analyzing their vast and rapidly evolving content remains a major
challenge. We introduce an end-to-end framework for automatically generating an
interpretable topic taxonomy from an unlabeled corpus. By combining
unsupervised clustering with prompt-based labeling, our method leverages large
language models (LLMs) to iteratively construct a taxonomy without requiring
seed sets or domain expertise. We apply this framework to a large corpus of
Meta (previously known as Facebook) political ads from the month ahead of the
2024 U.S. Presidential election. Our approach uncovers latent discourse
structures, synthesizes semantically rich topic labels, and annotates topics
with moral framing dimensions. We show quantitative and qualitative analyses to
demonstrate the effectiveness of our framework. Our findings reveal that voting
and immigration ads dominate overall spending and impressions, while abortion
and election-integrity achieve disproportionate reach. Funding patterns are
equally polarized: economic appeals are driven mainly by conservative PACs,
abortion messaging splits between pro- and anti-rights coalitions, and
crime-and-justice campaigns are fragmented across local committees. The framing
of these appeals also diverges--abortion ads emphasize liberty/oppression
rhetoric, while economic messaging blends care/harm, fairness/cheating, and
liberty/oppression narratives. Topic salience further reveals strong
correlations between moral foundations and issues. Demographic targeting also
emerges. This work supports scalable, interpretable analysis of political
messaging on social media, enabling researchers, policymakers, and the public
to better understand emerging narratives, polarization dynamics, and the moral
underpinnings of digital political communication.

</details>


### [7] [FarsiMCQGen: a Persian Multiple-choice Question Generation Framework](https://arxiv.org/abs/2510.15134)
*Mohammad Heydari Rad,Rezvan Afari,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本文提出了FarsiMCQGen，一种用于生成波斯语多项选择题的创新方法，结合了候选答案生成、筛选与排序技术，并利用变压器模型和知识图谱等先进方法生成高质量的干扰选项。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言如波斯语中，高质量多项选择题的生成仍是重大挑战，亟需有效的方法。

Method: 结合候选生成、筛选与排序，利用变压器模型、知识图谱与规则基础方法生成逼真的干扰选项；基于维基百科数据构建波斯语MCQ数据集。

Result: 提出的模型成功生成了高质量的波斯语多项选择题数据集，并通过多种先进大语言模型的评估验证了其有效性。

Conclusion: FarsiMCQGen方法有效提升波斯语多项选择题的生成质量，为相关领域后续研究提供基础和动力。

Abstract: Multiple-choice questions (MCQs) are commonly used in educational testing, as
they offer an efficient means of evaluating learners' knowledge. However,
generating high-quality MCQs, particularly in low-resource languages such as
Persian, remains a significant challenge. This paper introduces FarsiMCQGen, an
innovative approach for generating Persian-language MCQs. Our methodology
combines candidate generation, filtering, and ranking techniques to build a
model that generates answer choices resembling those in real MCQs. We leverage
advanced methods, including Transformers and knowledge graphs, integrated with
rule-based approaches to craft credible distractors that challenge test-takers.
Our work is based on data from Wikipedia, which includes general knowledge
questions. Furthermore, this study introduces a novel Persian MCQ dataset
comprising 10,289 questions. This dataset is evaluated by different
state-of-the-art large language models (LLMs). Our results demonstrate the
effectiveness of our model and the quality of the generated dataset, which has
the potential to inspire further research on MCQs.

</details>


### [8] [Structure-R1: Dynamically Leveraging Structural Knowledge in LLM Reasoning through Reinforcement Learning](https://arxiv.org/abs/2510.15191)
*Junlin Wu,Xianrui Zhong,Jiashuo Sun,Bolian Li,Bowen Jin,Jiawei Han,Qingkai Zeng*

Main category: cs.CL

TL;DR: 提出Structure-R1框架，通过强化学习生成结构化内容表示，提升大语言模型在多步推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成系统依赖非结构化文本，信息密度低，推理效果有限，需提升结构化访问领域知识的能力。

Method: Structure-R1通过强化学习动态生成和调整结构化格式，采用自我奖励的结构验证机制保证表示的正确性和完整性。

Result: 在七个知识密集型基准测试中，使用7B模型取得了与更大模型相当的性能，验证了结构化表示的有效性。

Conclusion: 结构化内容表示显著提高了信息密度和语境清晰度，从而增强了推理能力，证实了采用动态生成结构化表达的优势。

Abstract: Large language models (LLMs) have demonstrated remarkable advances in
reasoning capabilities. However, their performance remains constrained by
limited access to explicit and structured domain knowledge. Retrieval-Augmented
Generation (RAG) addresses this by incorporating external information as
context to augment reasoning. Nevertheless, traditional RAG systems typically
operate over unstructured and fragmented text, resulting in low information
density and suboptimal reasoning. To overcome these limitations, we propose
\textsc{Structure-R1}, a novel framework that transforms retrieved content into
structured representations optimized for reasoning. Leveraging reinforcement
learning, \textsc{Structure-R1} learns a content representation policy that
dynamically generates and adapts structural formats based on the demands of
multi-step reasoning. Unlike prior methods that rely on fixed schemas, our
approach adopts a generative paradigm capable of producing task-specific
structures tailored to individual queries. To ensure the quality and
reliability of these representations, we introduce a self-reward structural
verification mechanism that checks whether the generated structures are both
correct and self-contained. Extensive experiments on seven knowledge-intensive
benchmarks show that \textsc{Structure-R1} consistently achieves competitive
performance with a 7B-scale backbone model and matches the performance of much
larger models. Additionally, our theoretical analysis demonstrates how
structured representations enhance reasoning by improving information density
and contextual clarity. Our code and data are available at:
https://github.com/jlwu002/sr1.

</details>


### [9] [Extending Audio Context for Long-Form Understanding in Large Audio-Language Models](https://arxiv.org/abs/2510.15231)
*Yuatyong Chaichana,Pittawat Taveekitworachai,Warit Sirichotedumrong,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 本论文提出了两种方法——Partial YaRN和VLAT，以解决大音频-语言模型（LALMs）受限于短音频上下文窗口的问题，从而提升长音频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有大音频-语言模型受限于短音频上下文窗口，而文本部分上下文可以更长，限制了模型对长音频的理解能力。

Method: 第一，提出Partial YaRN，一种无训练的、仅修改音频token位置的上下文扩展方法，保持文本位置不变以保留文本能力；第二，提出虚拟长音频训练（VLAT），在训练时通过模拟不同长度的音频位置编码，实现对长音频的更好泛化和鲁棒性。

Result: 实验表明，Partial YaRN在多种情境下优于原始模型，VLAT训练方法进一步显著提升了长音频理解性能，对未见过的长音频表现强劲。

Conclusion: 通过Partial YaRN和VLAT方法，成功解决了大音频-语言模型在长上下文音频理解中的限制，提升了模型的泛化能力和鲁棒性。

Abstract: Large Audio-Language Models (LALMs) are often constrained by short audio
context windows, even when their text backbones support long contexts, limiting
long-form audio understanding. Prior work has introduced context-extension
methods (e.g. YaRN) on unimodal LLMs, yet their application to LALMs remains
unexplored. First, building on RoPE-based context extension, we introduce
Partial YaRN, a training-free, audio-only extension method that modifies only
audio token positions, leaving text positions intact to preserve the base LLM's
text capabilities. Second, we propose Virtual Longform Audio Training (VLAT), a
training strategy that extends Partial YaRN into a training-time positional
augmentation. VLAT simulates diverse audio lengths during training, enabling
generalization to inputs far longer than those seen in training and improving
robustness for long-context audio understanding. Our experiments on SALMONN and
Qwen2-Audio show that Partial YaRN outperforms the original models across wide
range of settings, and VLAT training strategy provides substantial improvement,
achieving strong performance on long audio of unseen lengths.

</details>


### [10] [Automatic essay scoring: leveraging Jaccard coefficient and Cosine similaritywith n-gram variation in vector space model approach](https://arxiv.org/abs/2510.15311)
*Andharini Dwi Cahyani,Moh. Wildan Fathoni,Fika Hastarita Rachman,Ari Basuki,Salman Amin,Bain Khusnul Khotimah*

Main category: cs.CL

TL;DR: 本文研究了自动作文评分中使用向量空间模型结合Jaccard系数和余弦相似度进行评分的方法，发现余弦相似度效果更佳，且单字模型优于双字和三字模型。


<details>
  <summary>Details</summary>
Motivation: 提升自动作文评分的效率和准确性，探索不同相似度度量和n-gram模型在评分中的表现。

Method: 采用向量空间模型，使用unigram、bigram和trigram提取特征，分别计算Jaccard系数和余弦相似度，再通过RMSE评估与人工评分的差异。

Result: 实验证明余弦相似度的评分效果优于Jaccard系数，单字模型的RMSE低于双字和三字模型。

Conclusion: 余弦相似度结合单字向量空间模型是自动作文评分的更优选择，有助于提高评分的准确性。

Abstract: Automated essay scoring (AES) is a vital area of research aiming to provide
efficient and accurate assessment tools for evaluating written content. This
study investigates the effectiveness of two popular similarity metrics, Jaccard
coefficient, and Cosine similarity, within the context of vector space
models(VSM)employing unigram, bigram, and trigram representations. The data
used in this research was obtained from the formative essay of the citizenship
education subject in a junior high school. Each essay undergoes preprocessing
to extract features using n-gram models, followed by vectorization to transform
text data into numerical representations. Then, similarity scores are computed
between essays using both Jaccard coefficient and Cosine similarity. The
performance of the system is evaluated by analyzing the root mean square error
(RMSE), which measures the difference between the scores given by human graders
and those generated by the system. The result shows that the Cosine similarity
outperformed the Jaccard coefficient. In terms of n-gram, unigrams have lower
RMSE compared to bigrams and trigrams.

</details>


### [11] [Planner and Executor: Collaboration between Discrete Diffusion And Autoregressive Models in Reasoning](https://arxiv.org/abs/2510.15244)
*Lina Berrayana,Ahmed Heakl,Muhammad Abdullah Sohail,Thomas Hofmann,Salman Khan,Wei Chen*

Main category: cs.CL

TL;DR: 本文探讨了将离散扩散语言模型（DDLM）与自回归语言模型（ARM）相结合，以提升语言生成任务的准确率和计算效率。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型虽然准确率高，但需要处理长序列，成本高昂；而DDLM支持并行生成，适合复杂推理和长期规划，有望与ARM互补。

Method: 本文设计了两种合作方式：一是在文本空间中，DDLM规划推理过程，ARM基于计划输出最终答案；二是在潜在空间中，通过学习投影器将DDLM潜在表示映射到ARM嵌入空间，克服扩散模型文本生成限制。

Result: 潜在空间通信使准确率显著提升，如DART-5从27.0%提高到54.0%，AIME24从0.0%提升至14.0%；结合DDLM规划和ARM执行，在保证准确率的前提下显著减少计算代价，实现远超基线模型的性能。

Conclusion: DDLM与ARM的混合架构在推理任务中表现出协同优势，不仅提升了准确度，还大幅降低了计算成本，展现出混合模型在复杂语言生成任务中的潜力。

Abstract: Current autoregressive language models (ARMs) achieve high accuracy but
require long token sequences, making them costly. Discrete diffusion language
models (DDLMs) enable parallel and flexible generation within a fixed number of
steps and have recently emerged for their strong performance in complex
reasoning and long-term planning tasks. We present a study exploring hybrid
architectures that couple DDLMs with ARMs to assess whether their collaboration
can yield complementary benefits. We first examine collaboration in text space,
where one model plans the reasoning process and another executes the final
answer based on that plan. We then extend this setup to latent-space
communication, introducing a learned projector that maps DDLM latents into the
ARM's embedding space, potentially bypassing some of the text-generation
limitations of diffusion models. We find that shifting DDLM --> ARM
communication from text space to latent space yields significant accuracy
gains, for example increasing from 27.0% to 54.0% on DART-5 and from 0.0% to
14.0% on AIME24. We also find that combining a DDLM planner with an ARM
executor can provide substantial computational savings with little to no impact
on accuracy. For example, the latent-space pipeline, using 64 tokens for
planning and roughly 5 for execution, surpasses Qwen3.1-7B on DART-5 and AIME,
despite Qwen using 44 times more tokens. Overall, our study offers new insights
into reasoning with DDLMs and highlights their potential in hybrid
architectures.

</details>


### [12] [Scaling Beyond Context: A Survey of Multimodal Retrieval-Augmented Generation for Document Understanding](https://arxiv.org/abs/2510.15253)
*Sensen Gao,Shanshan Zhao,Xu Jiang,Lunhao Duan,Yong Xien Chng,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,Jia-Wang Bian,Mingming Gong*

Main category: cs.CL

TL;DR: 本文综述了多模态检索增强生成（Multimodal RAG）在文档理解中的应用，提出了分类体系并总结了关键技术和挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的OCR结合大型语言模型方法容易丢失结构信息，多模态大型语言模型则难以有效建模上下文，文档的多模态特性要求更先进的检索增强生成方法。

Method: 提出多模态RAG方法，允许跨文本、表格、图表和布局等多模态的整体检索与推理；构建了基于领域、检索模态和粒度的分类体系，综述图结构和智能代理框架。

Result: 总结了现有的关键数据集、基准测试和应用案例，展示多模态RAG在文档理解中的优势和进展。

Conclusion: 多模态RAG为文档理解提供全面智能的新范式，但仍面临效率、细粒度表示和鲁棒性等挑战，未来研究需对应发展这些方向。

Abstract: Document understanding is critical for applications from financial analysis
to scientific discovery. Current approaches, whether OCR-based pipelines
feeding Large Language Models (LLMs) or native Multimodal LLMs (MLLMs), face
key limitations: the former loses structural detail, while the latter struggles
with context modeling. Retrieval-Augmented Generation (RAG) helps ground models
in external data, but documents' multimodal nature, i.e., combining text,
tables, charts, and layout, demands a more advanced paradigm: Multimodal RAG.
This approach enables holistic retrieval and reasoning across all modalities,
unlocking comprehensive document intelligence. Recognizing its importance, this
paper presents a systematic survey of Multimodal RAG for document
understanding. We propose a taxonomy based on domain, retrieval modality, and
granularity, and review advances involving graph structures and agentic
frameworks. We also summarize key datasets, benchmarks, and applications, and
highlight open challenges in efficiency, fine-grained representation, and
robustness, providing a roadmap for future progress in document AI.

</details>


### [13] [TraceCoder: Towards Traceable ICD Coding via Multi-Source Knowledge Integration](https://arxiv.org/abs/2510.15267)
*Mucheng Ren,He Chen,Yuchen Yan,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 本文提出TraceCoder框架，通过融合多源外部知识提升自动国际疾病分类编码的准确性和可解释性，解决了临床文本与ICD代码之间的语义鸿沟和长尾代码识别困难的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动ICD编码方法存在语义差距大、长尾代码表现差及可解释性不足等问题，难以满足临床需求。

Method: TraceCoder集成UMLS、维基百科和大型语言模型等多源知识，采用混合注意力机制捕捉标签、临床文本和知识的交互，增强代码表征和可解释性。

Result: 在MIMIC-III-ICD9、MIMIC-IV-ICD9及MIMIC-IV-ICD10数据集上的实验表明，TraceCoder性能达到最新水平，消融实验验证了各组件有效性。

Conclusion: TraceCoder提供了一种可扩展、鲁棒的自动ICD编码解决方案，兼顾准确性、解释性和可靠性，符合临床实际需求。

Abstract: Automated International Classification of Diseases (ICD) coding assigns
standardized diagnosis and procedure codes to clinical records, playing a
critical role in healthcare systems. However, existing methods face challenges
such as semantic gaps between clinical text and ICD codes, poor performance on
rare and long-tail codes, and limited interpretability. To address these
issues, we propose TraceCoder, a novel framework integrating multi-source
external knowledge to enhance traceability and explainability in ICD coding.
TraceCoder dynamically incorporates diverse knowledge sources, including UMLS,
Wikipedia, and large language models (LLMs), to enrich code representations,
bridge semantic gaps, and handle rare and ambiguous codes. It also introduces a
hybrid attention mechanism to model interactions among labels, clinical
context, and knowledge, improving long-tail code recognition and making
predictions interpretable by grounding them in external evidence. Experiments
on MIMIC-III-ICD9, MIMIC-IV-ICD9, and MIMIC-IV-ICD10 datasets demonstrate that
TraceCoder achieves state-of-the-art performance, with ablation studies
validating the effectiveness of its components. TraceCoder offers a scalable
and robust solution for automated ICD coding, aligning with clinical needs for
accuracy, interpretability, and reliability.

</details>


### [14] [TACL: Threshold-Adaptive Curriculum Learning Strategy for Enhancing Medical Text Understanding](https://arxiv.org/abs/2510.15269)
*Mucheng Ren,Yucheng Yan,He Chen,Danqing Hu,Jun Xu,Xian Zeng*

Main category: cs.CL

TL;DR: 提出了一个基于样本难度自适应的课程学习框架TACL，用于提升多语言医疗文本（包括中英临床记录）自动理解的效果。


<details>
  <summary>Details</summary>
Motivation: 医疗文本尤其是电子病历具有结构不一、领域专用语言和语境多变的特点，给自动理解带来挑战。现有方法忽视样本复杂度差异，难以在复杂病例上表现良好。

Method: 设计了TACL框架，动态调整训练过程，根据样本复杂度分级，先优先学习简单样本，再逐渐过渡到复杂样本，实现渐进式学习。

Result: 在多语言医疗任务（自动ICD编码、再入院预测、中医证候辨识）中，TACL显著提升了模型性能和泛化能力。

Conclusion: TACL有效增强了自动医疗文本理解系统的性能，促进了跨医疗领域的统一方法，为准确、可扩展和全球适用的医疗文本处理提供了新思路。

Abstract: Medical texts, particularly electronic medical records (EMRs), are a
cornerstone of modern healthcare, capturing critical information about patient
care, diagnoses, and treatments. These texts hold immense potential for
advancing clinical decision-making and healthcare analytics. However, their
unstructured nature, domain-specific language, and variability across contexts
make automated understanding an intricate challenge. Despite the advancements
in natural language processing, existing methods often treat all data as
equally challenging, ignoring the inherent differences in complexity across
clinical records. This oversight limits the ability of models to effectively
generalize and perform well on rare or complex cases. In this paper, we present
TACL (Threshold-Adaptive Curriculum Learning), a novel framework designed to
address these challenges by rethinking how models interact with medical texts
during training. Inspired by the principle of progressive learning, TACL
dynamically adjusts the training process based on the complexity of individual
samples. By categorizing data into difficulty levels and prioritizing simpler
cases early in training, the model builds a strong foundation before tackling
more complex records. By applying TACL to multilingual medical data, including
English and Chinese clinical records, we observe significant improvements
across diverse clinical tasks, including automatic ICD coding, readmission
prediction and TCM syndrome differentiation. TACL not only enhances the
performance of automated systems but also demonstrates the potential to unify
approaches across disparate medical domains, paving the way for more accurate,
scalable, and globally applicable medical text understanding solutions.

</details>


### [15] [Exemplar-Guided Planing: Enhanced LLM Agent for KGQA](https://arxiv.org/abs/2510.15283)
*Jingao Xu,Shuoyoucheng Ma,Xin Song,Rong Jiang,Hongkui Tu,Bin Zhou*

Main category: cs.CL

TL;DR: 本文提出了一个名为Exemplar-Guided Planning (EGP)的新框架，通过示例引导提升大语言模型在知识图谱问答中的规划能力，从而提升回答的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在知识图谱问答中存在自然语言与结构化知识图谱表征之间的语义鸿沟，导致规划和探索效率低下；无训练的方法未充分利用训练数据中的推理模式。

Method: EGP通过实体模板规范训练问题，利用语义嵌入和FAISS索引检索高相似示例及其推理路径，在任务分解和关系探索两个阶段动态指导大语言模型规划；引入Smart Lookahead机制提高关系探索效率。

Result: 将EGP应用于Plan-on-Graph (PoG)框架形成PoG-EGP，在两个真实KGQA数据集WebQSP和CWQ上实验显示，PoG-EGP显著优于基线PoG系统及其他方法。

Conclusion: EGP框架有效缓解了语义鸿沟问题，通过示例引导和智能预探索显著提升了知识图谱问答中大语言模型的规划效果和效率。

Abstract: Large Language Models (LLMs) as interactive agents show significant promise
in Knowledge Graph Question Answering (KGQA) but often struggle with the
semantic gap between natural language queries and structured knowledge graph
(KG) representations. This leads to suboptimal planning and inefficient
exploration on KG, while training-free approaches often underutilize valuable
reasoning patterns in training data. To address these limitations, we propose a
novel framework, Exemplar-Guided Planning (EGP), which enhances the planning
capabilities of LLM agents for KGQA. EGP first preprocesses the training set
questions via entity templating to normalize semantic variations. It then
retrieves highly similar exemplary questions and their successful reasoning
paths from this preprocessed set using semantic embeddings and an efficient
FAISS index. These retrieved exemplars dynamically guide the LLM's planning
process in two key phases: (1) Task Decomposition, by aligning generated
sub-objectives with proven reasoning steps, and (2) Relation Exploration, by
providing high-quality auxiliary information to improve relation pruning
accuracy. Additionally, we introduce a Smart Lookahead mechanism during
relation exploration to improve efficiency by preemptively exploring promising
paths and potentially terminating exploration earlier. We apply EGP to the
Plan-on-Graph (PoG) framework, termed PoG-EGP. Extensive experiments on two
real-world KGQA datasets, WebQSP and CWQ, demonstrate that PoG-EGP
significantly improves over the baseline PoG system and other compared methods.

</details>


### [16] [Accelerating Mobile Language Model Generation via Hybrid Context and Hardware Coordination](https://arxiv.org/abs/2510.15312)
*Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma*

Main category: cs.CL

TL;DR: 本文提出了CoordGen，一种集成了动态硬件调度和推测解码的移动端推理框架，以提升本地大语言模型的上下文感知文本生成速度与能效。


<details>
  <summary>Details</summary>
Motivation: 当前移动设备上的大语言模型在逐令牌生成过程中存在高延迟和硬件利用率低的问题，限制了个性化和任务感知的文本生成能力。

Method: CoordGen框架包含三个关键组件：自适应执行调度动态平衡预填充与解码阶段计算负载；上下文对齐草稿通过轻量级在线校准提升推测效率；硬件高效草稿扩展重用中间序列以增强并行处理并降低验证成本。

Result: 在多款智能手机和代表性任务上，CoordGen实现了高达3.8倍的生成速度提升及4.7倍的能效提升，显著优于现有移动推理方案。

Conclusion: CoordGen有效结合推测解码与动态硬件调度显著改善了移动端上下文感知大语言模型的性能，验证了各组件优化的独立贡献，促进了移动设备上的智能文本生成应用。

Abstract: Enhancing on-device large language models (LLMs) with contextual information
from local data enables personalized and task-aware generation, powering use
cases such as intelligent assistants and UI agents. While recent developments
in neural processors have substantially improved the efficiency of prefill on
mobile devices, the token-by-token generation process still suffers from high
latency and limited hardware utilization due to its inherently memory-bound
characteristics. This work presents CoordGen, a mobile inference framework that
integrates speculative decoding with dynamic hardware scheduling to accelerate
context-aware text generation on mobile devices. The framework introduces three
synergistic components: (1) adaptive execution scheduling, which dynamically
balances compute graphs between prefill and decoding phases; (2)
context-aligned drafting, which improves speculative efficiency through
lightweight online calibration to current tasks; and (3) hardware-efficient
draft extension, which reuses and expands intermediate sequences to improve
processing parallelism and reduce verification cost. Experiments on multiple
smartphones and representative workloads show consistent improvements of up to
3.8x in generation speed and 4.7x in energy efficiency compared with existing
mobile inference solutions. Component-level analysis further validates the
contribution of each optimization.

</details>


### [17] [Capabilities and Evaluation Biases of Large Language Models in Classical Chinese Poetry Generation: A Case Study on Tang Poetry](https://arxiv.org/abs/2510.15313)
*Bolei Ma,Yina Yao,Anna-Carolina Haensch*

Main category: cs.CL

TL;DR: 本文提出了一种结合计算指标、语言模型评审及人类专家验证的三步评估框架，评估大语言模型在古典诗词创作中的表现，发现模型存在评价偏差，强调需要人机混合验证。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在古典中文诗词创作与评价中的性能及准确性尚不明确，存在生成与评价偏差。

Method: 构建三步评估框架，包括计算指标、语言模型作为评审人与人类专家验证，评估六种顶尖语言模型在主题、情感、意象、形式和风格多个维度的表现。

Result: 发现语言模型在创意质量评价上存在“回声室”效应，往往依赖有缺陷的标准，偏离人类评判，表现出系统性生成和评价偏见。

Conclusion: 当前语言模型虽具潜力但仍有限，文化及技术复杂任务中需结合人类和模型的混合验证以保证创作和评价的准确性。

Abstract: Large Language Models (LLMs) are increasingly applied to creative domains,
yet their performance in classical Chinese poetry generation and evaluation
remains poorly understood. We propose a three-step evaluation framework that
combines computational metrics, LLM-as-a-judge assessment, and human expert
validation. Using this framework, we evaluate six state-of-the-art LLMs across
multiple dimensions of poetic quality, including themes, emotions, imagery,
form, and style. Our analysis reveals systematic generation and evaluation
biases: LLMs exhibit "echo chamber" effects when assessing creative quality,
often converging on flawed standards that diverge from human judgments. These
findings highlight both the potential and limitations of current capabilities
of LLMs as proxy for literacy generation and the limited evaluation practices,
thereby demonstrating the continued need of hybrid validation from both humans
and models in culturally and technically complex creative tasks.

</details>


### [18] [AutoGraph-R1: End-to-End Reinforcement Learning for Knowledge Graph Construction](https://arxiv.org/abs/2510.15339)
*Hong Ting Tsang,Jiaxin Bai,Haoyu Huang,Qiao Xiao,Tianshi Zheng,Baixuan Xu,Shujie Liu,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文提出了AutoGraph-R1框架，通过强化学习直接优化知识图谱构建以提升检索增强生成任务的性能，显著提高了问答系统效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱构建与下游应用脱节，导致图结构次优，影响问答系统性能。

Method: 利用强化学习，将知识图谱构建视为策略学习问题，设计两种任务感知奖励函数，根据图在RAG管线中的功能表现进行优化。

Result: 在多个问答基准测试中，AutoGraph-R1显著提升了Graph RAG方法的性能，优于无任务感知的基线图。

Conclusion: 本文成功实现了构建过程与应用的闭环，推动从构建“内在优秀”知识图谱向构建“实用”知识图谱范式转变。

Abstract: Building effective knowledge graphs (KGs) for Retrieval-Augmented Generation
(RAG) is pivotal for advancing question answering (QA) systems. However, its
effectiveness is hindered by a fundamental disconnect: the knowledge graph (KG)
construction process is decoupled from its downstream application, yielding
suboptimal graph structures. To bridge this gap, we introduce AutoGraph-R1, the
first framework to directly optimize KG construction for task performance using
Reinforcement Learning (RL). AutoGraph-R1 trains an LLM constructor by framing
graph generation as a policy learning problem, where the reward is derived from
the graph's functional utility in a RAG pipeline. We design two novel,
task-aware reward functions, one for graphs as knowledge carriers and another
as knowledge indices. Across multiple QA benchmarks, AutoGraph-R1 consistently
enables graph RAG methods to achieve significant performance gains over using
task-agnostic baseline graphs. Our work shows it is possible to close the loop
between construction and application, shifting the paradigm from building
intrinsically ``good'' graphs to building demonstrably ``useful'' ones.

</details>


### [19] [Readability Reconsidered: A Cross-Dataset Analysis of Reference-Free Metrics](https://arxiv.org/abs/2510.15345)
*Catarina G Belem,Parker Glenn,Alfy Samuel,Anoop Kumar,Daben Liu*

Main category: cs.CL

TL;DR: 本研究通过分析人类对可读性的判断，发现信息内容和主题对文本的理解性影响显著，模型驱动的可读性指标优于传统指标。


<details>
  <summary>Details</summary>
Motivation: 现有可读性评估依赖表面文本特征，定义不一致，难以准确反映人类的可读性感知。

Method: 分析897条人类可读性判断数据，评估15种传统和6种模型驱动的可读性指标在五个英语数据集上的表现。

Result: 模型驱动指标在与人类判断的相关性排名中稳定名列前茅，传统最佳指标排名平均为8.6，表明模型驱动方法更优。

Conclusion: 当前传统可读性指标与人类感知存在不匹配，模型驱动的可读性指标更有效，未来研究应侧重此方向。

Abstract: Automatic readability assessment plays a key role in ensuring effective and
accessible written communication. Despite significant progress, the field is
hindered by inconsistent definitions of readability and measurements that rely
on surface-level text properties. In this work, we investigate the factors
shaping human perceptions of readability through the analysis of 897 judgments,
finding that, beyond surface-level cues, information content and topic strongly
shape text comprehensibility. Furthermore, we evaluate 15 popular readability
metrics across five English datasets, contrasting them with six more nuanced,
model-based metrics. Our results show that four model-based metrics
consistently place among the top four in rank correlations with human
judgments, while the best performing traditional metric achieves an average
rank of 8.6. These findings highlight a mismatch between current readability
metrics and human perceptions, pointing to model-based approaches as a more
promising direction.

</details>


### [20] [When to Ensemble: Identifying Token-Level Points for Stable and Fast LLM Ensembling](https://arxiv.org/abs/2510.15346)
*Heecheol Yun,Kwangmin Ki,Junghyun Lee,Eunho Yang*

Main category: cs.CL

TL;DR: 本文提出SAFE框架，通过选择性集成LLMs的下一个词概率分布，有效提升长文本生成的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有集成方法在短文本生成效果显著，但直接应用于长文本生成常导致性能下降，因此需要改进集成位置的选择策略。

Method: 提出SAFE框架，基于分词不匹配和下一词分布共识两因素选择集成位置，并引入概率强化策略，将同一词的子词概率合并。

Result: SAFE在多个基准测试（如MATH500和BBH）上，在准确率和效率上均超越现有方法，且仅集成不足1%的词即可获得提升。

Conclusion: 通过精确选择集成位置并优化概率分布，SAFE实现了稳定且高效的长文本LLM集成，推动了长文本生成质量的提升。

Abstract: Ensembling Large Language Models (LLMs) has gained attention as a promising
approach to surpass the performance of individual models by leveraging their
complementary strengths. In particular, aggregating models' next-token
probability distributions to select the next token has been shown to be
effective in various tasks. However, while successful for short-form answers,
its application to long-form generation remains underexplored. In this paper,
we show that using existing ensemble methods in long-form generation requires a
careful choice of ensembling positions, since the standard practice of
ensembling at every token often degrades performance. We identify two key
factors for determining these positions: tokenization mismatch across models
and consensus in their next-token probability distributions. Based on this, we
propose SAFE, (Stable And Fast LLM Ensembling), a framework that selectively
ensembles by jointly considering these factors. To further improve stability,
we introduce a probability sharpening strategy that consolidates probabilities
spread across multiple sub-word tokens representing the same word into a single
representative token. Our experiments on diverse benchmarks, including MATH500
and BBH, demonstrate that SAFE outperforms existing methods in both accuracy
and efficiency, with gains achieved even when ensembling fewer than 1% of
tokens.

</details>


### [21] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2510.15349)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Zuming Huang,Jun Huang,Haozhe Wang,Yanjie Liang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CL

TL;DR: 该论文提出了一种基于强化学习的文档结构解析框架LayoutRL，解决了传统方法在多样文档和有限训练数据上的泛化性能差的问题。


<details>
  <summary>Details</summary>
Motivation: 文档解析任务因包含文本、图表、公式等复杂元素，且现有监督方法难以应对多样文档类型，且高质量布局解析训练数据稀缺，导致性能不足。

Method: 设计LayoutRL强化学习框架，通过综合奖励函数（包含编辑距离、段落数准确率、阅读顺序保持性）优化布局理解；构建了大规模Infinity-Doc-400K数据集，并以此训练了具有强泛化能力的视觉语言模型Infinity-Parser。

Result: Infinity-Parser在OmniDocBench、olmOCR-Bench、PubTabNet、FinTabNet等多个数据集上均达到最先进性能，优于专用文档解析系统及通用视觉语言模型，适用多种文档类型、语言及结构复杂度。

Conclusion: 引入强化学习策略与大规模数据集的结合有效提升文档解析的泛化性能和准确率，所提出方法及资源对推动文档解析领域研究具有重要贡献。

Abstract: Document parsing from scanned images into structured formats remains a
significant challenge due to its complexly intertwined elements such as text
paragraphs, figures, formulas, and tables. Existing supervised fine-tuning
methods often struggle to generalize across diverse document types, leading to
poor performance, particularly on out-of-distribution data. This issue is
further exacerbated by the limited availability of high-quality training data
for layout-aware parsing tasks. To address these challenges, we introduce
LayoutRL, a reinforcement learning framework that optimizes layout
understanding through composite rewards integrating normalized edit distance,
paragraph count accuracy, and reading order preservation. To support this
training, we construct the Infinity-Doc-400K dataset, which we use to train
Infinity-Parser, a vision-language model demonstrating robust generalization
across various domains. Extensive evaluations on benchmarks including
OmniDocBench, olmOCR-Bench, PubTabNet, and FinTabNet show that Infinity-Parser
consistently achieves state-of-the-art performance across a broad range of
document types, languages, and structural complexities, substantially
outperforming both specialized document parsing systems and general-purpose
vision-language models. We will release our code, dataset, and model to
facilitate reproducible research in document parsing.

</details>


### [22] [VocalBench-DF: A Benchmark for Evaluating Speech LLM Robustness to Disfluency](https://arxiv.org/abs/2510.15406)
*Hongcheng Liu,Yixuan Hou,Heyang Liu,Yuhao Wang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文评估了语音大语言模型在处理言语不流畅（尤其是帕金森病相关的）时的鲁棒性，发现其性能显著下降，并指出基于音素处理和长上下文建模是瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有语音大语言模型虽性能强，但在处理实际应用中的言语不流畅，尤其是疾病相关的言语障碍时鲁棒性不足，亟需系统评估。

Method: 引入VocalBench-DF框架，按照多维分类系统地评估22个主流语音大语言模型在言语不流畅场景下的表现。

Result: 实验揭示这些模型性能大幅下降，主要瓶颈在音素级处理和长上下文建模环节。

Conclusion: 加强识别与推理能力以及改进组件和处理流程可显著提升鲁棒性，强调开发能真实处理言语不流畅的包容性语音大语言模型的迫切需求。

Abstract: While Speech Large Language Models (Speech-LLMs) show strong performance in
many applications, their robustness is critically under-tested, especially to
speech disfluency. Existing evaluations often rely on idealized inputs,
overlooking common disfluencies, particularly those associated with conditions
like Parkinson's disease. This work investigates whether current Speech-LLMs
can maintain performance when interacting with users who have speech
impairments. To facilitate this inquiry, we introduce VocalBench-DF, a
framework for the systematic evaluation of disfluency across a
multi-dimensional taxonomy. Our evaluation of 22 mainstream Speech-LLMs reveals
substantial performance degradation, indicating that their real-world readiness
is limited. Further analysis identifies phoneme-level processing and
long-context modeling as primary bottlenecks responsible for these failures.
Strengthening recognition and reasoning capability from components and
pipelines can substantially improve robustness. These findings highlight the
urgent need for new methods to improve disfluency handling and build truly
inclusive Speech-LLMs

</details>


### [23] [Large-scale User Game Lifecycle Representation Learning](https://arxiv.org/abs/2510.15412)
*Yanjie Gou,Jiangming Liu,Kouying Xue,Yi Hua*

Main category: cs.CL

TL;DR: 本文提出用户游戏生命周期（UGL）和逆概率掩码策略，解决游戏推荐中的数据稀疏与不平衡问题，显著提升广告和推荐效果。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统难以应对游戏项目稀疏且用户行为被少数热门游戏主导的问题，导致游戏广告和推荐效果有限。

Method: 通过引入UGL丰富用户游戏行为，设计短期与长期兴趣提取策略，并采用逆概率掩码策略处理游戏不平衡问题。

Result: UGL代表显著提升模型性能，游戏广告离线AUC均增1.83%，在线CVR增21.67%；游戏内物品推荐离线AUC增0.5%，在线ARPU增0.82%。

Conclusion: UGL及逆概率掩码策略有效解决游戏推荐中的稀疏与不平衡挑战，显著提升了广告和推荐系统性能。

Abstract: The rapid expansion of video game production necessitates the development of
effective advertising and recommendation systems for online game platforms.
Recommending and advertising games to users hinges on capturing their interest
in games. However, existing representation learning methods crafted for
handling billions of items in recommendation systems are unsuitable for game
advertising and recommendation. This is primarily due to game sparsity, where
the mere hundreds of games fall short for large-scale user representation
learning, and game imbalance, where user behaviors are overwhelmingly dominated
by a handful of popular games. To address the sparsity issue, we introduce the
User Game Lifecycle (UGL), designed to enrich user behaviors in games.
Additionally, we propose two innovative strategies aimed at manipulating user
behaviors to more effectively extract both short and long-term interests. To
tackle the game imbalance challenge, we present an Inverse Probability Masking
strategy for UGL representation learning. The offline and online experimental
results demonstrate that the UGL representations significantly enhance model by
achieving a 1.83% AUC offline increase on average and a 21.67% CVR online
increase on average for game advertising and a 0.5% AUC offline increase and a
0.82% ARPU online increase for in-game item recommendation.

</details>


### [24] [Fine-Tuning MedGemma for Clinical Captioning to Enhance Multimodal RAG over Malaysia CPGs](https://arxiv.org/abs/2510.15418)
*Lee Qi Zun,Mohamad Zulhilmi Bin Abdul Halim,Goh Man Fye*

Main category: cs.CL

TL;DR: 该论文提出了一个针对医学视觉语言模型MedGemma的专化框架，旨在生成更精准的医学图像描述以提升基于事实的临床指导检索系统的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型对医学图像的描述缺乏临床特异性和事实依据，限制了基于图像查询的检索增强生成系统的性能。

Method: 通过知识蒸馏构建合成数据集，并利用参数高效的QLoRA方法对MedGemma模型进行微调，采用双重框架评估模型的分类准确率以及利用RAGAS框架评价描述的真实性、相关性和正确性。

Result: 微调后的模型在分类性能上有显著提升，且在描述的真实性和正确性上表现出显著增强，证明模型能够生成可靠且具事实依据的医学图像描述。

Conclusion: 该研究建立了一个稳健的医学视觉语言模型专化流程，提升了模型生成高质量查询的能力，为多模态检索增强生成系统在临床决策支持中的应用奠定了基础。

Abstract: Retrieval-Augmented Generation systems are essential for providing fact-based
guidance from Malaysian Clinical Practice Guidelines. However, their
effectiveness with image-based queries is limited, as general Vision-Language
Model captions often lack clinical specificity and factual grounding. This
study proposes and validates a framework to specialize the MedGemma model for
generating high-fidelity captions that serve as superior queries. To overcome
data scarcity, we employ a knowledge distillation pipeline to create a
synthetic dataset across dermatology, fundus, and chest radiography domains,
and fine-tune MedGemma using the parameter-efficient QLoRA method. Performance
was rigorously assessed through a dual framework measuring both classification
accuracy and, via a novel application of the RAGAS framework, caption
faithfulness, relevancy, and correctness. The fine-tuned model demonstrated
substantial improvements in classification performance, while RAGAS evaluation
confirmed significant gains in caption faithfulness and correctness, validating
the models ability to produce reliable, factually grounded descriptions. This
work establishes a robust pipeline for specializing medical VLMs and validates
the resulting model as a high-quality query generator, laying the groundwork
for enhancing multimodal RAG systems in evidence-based clinical decision
support.

</details>


### [25] [When Seeing Is not Enough: Revealing the Limits of Active Reasoning in MLLMs](https://arxiv.org/abs/2510.15421)
*Hongcheng Liu,Pingjie Wang,Yuhao Wang,Siqu Ou,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 该论文提出了GuessBench基准，评估多模态大语言模型(MLLMs)在不完整信息下主动获取证据和迭代推理的能力，发现现有模型在主动推理任务上表现较弱，强调感知细节和决策时效性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型评估主要基于被动推理，且通常在信息完整的条件下执行，缺少对实际应用中模型主动获取缺失证据能力的考察。为此，论文旨在探究MLLMs是否能在信息不完全的场景下主动寻找所需信息并更新推理结果。

Method: 设计了GuessBench基准，包含感知导向和知识导向的图像，要求模型在无任务特定先验的情况下，从候选图像池中主动选择目标图像，支持对主动推理能力的系统评估。论文对20款先进MLLM进行了测试，并开展消融实验以探明感知和思维提升方法的效果。

Result: 实验表明，MLLMs在主动推理任务上的表现远低于被动推理，显示该领域存在较大提升空间。细粒度感知和决策时间的把握是主要挑战。消融研究发现，感知增强对较小模型尤为有益，而思维导向方法对所有模型尺寸均有稳定提升作用。

Conclusion: 主动推理是多模态大语言模型未来发展的重要方向。提升模型的细致感知能力和决策时效性有助于改善主动推理表现，感知和思维结合的策略值得进一步探索和优化。

Abstract: Multimodal large language models (MLLMs) have shown strong capabilities
across a broad range of benchmarks. However, most existing evaluations focus on
passive inference, where models perform step-by-step reasoning under complete
information. This setup is misaligned with real-world use, where seeing is not
enough. This raises a fundamental question: Can MLLMs actively acquire missing
evidence under incomplete information? To bridge this gap, we require the MLLMs
to actively acquire missing evidence and iteratively refine decisions under
incomplete information, by selecting a target image from a candidate pool
without task-specific priors. To support systematic study, we propose
GuessBench, a benchmark with both perception-oriented and knowledge-oriented
images for evaluating active reasoning in MLLMs. We evaluate 20 superior MLLMs
and find that performance on active reasoning lags far behind it on passive
settings, indicating substantial room for improvement. Further analysis
identifies fine-grained perception and timely decision-making as key
challenges. Ablation studies show that perceptual enhancements benefit smaller
models, whereas thinking-oriented methods provide consistent gains across model
sizes. These results suggest promising directions for future research on
multimodal active reasoning.

</details>


### [26] [Controllable Abstraction in Summary Generation for Large Language Models via Prompt Engineering](https://arxiv.org/abs/2510.15436)
*Xiangchen Song,Yuchen Liu,Yaxuan Luan,Jinxu Guo,Xiaofan Guo*

Main category: cs.CL

TL;DR: 提出了一种基于提示工程的大型语言模型可控摘要生成方法，通过多阶段提示生成框架提升摘要质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 传统摘要生成方法在摘要质量和可控性方面存在不足，亟需改进方法来提升摘要的准确性和操控性。

Method: 设计了多阶段提示生成框架，基于语义分析、主题建模和噪声控制对输入文本生成不同抽象层次的摘要。

Result: 实验表明提示长度、数据噪声和文本类型均显著影响摘要质量，适中提示长度和低噪声能提升ROUGE-L得分。

Conclusion: 通过优化提示策略和文本预处理，可以有效提高大型语言模型生成摘要的准确性和可控性，提供了新的研究思路。

Abstract: This study presents a controllable abstract summary generation method for
large language models based on prompt engineering. To address the issues of
summary quality and controllability in traditional methods, we design a
multi-stage prompt generation framework. This framework generates summaries
with varying levels of abstraction by performing semantic analysis, topic
modeling, and noise control on the input text. The experiment uses the
CNN/Daily Mail dataset and provides a detailed analysis of different prompt
lengths, data noise, and text types. The experimental results show that prompt
length has a significant impact on the quality of generated summaries. Both
very short and very long prompt tokens result in a decrease in summary quality.
Data noise also negatively affects the summary generation process. As noise
levels increase, the ROUGE-L score gradually decreases. Furthermore, different
text types have varying effects on the model's ability to generate summaries.
The model performs best when handling news texts, while its performance is
worse when processing academic articles. This research provides new insights
into improving summary generation using large language models, particularly in
how controlling prompt strategies and optimizing text preprocessing can enhance
summary accuracy and controllability.

</details>


### [27] [CORE: Reducing UI Exposure in Mobile Agents via Collaboration Between Cloud and Local LLMs](https://arxiv.org/abs/2510.15455)
*Gucongcong Fan,Chaoyue Niu,Chengfei Lyu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: 提出CORE框架融合云端和本地大语言模型，减少移动界面信息暴露，提高任务准确率。


<details>
  <summary>Details</summary>
Motivation: 云端LLM虽准确，但需上传完整UI状态，暴露隐私；本地LLM隐私好但能力有限，任务成功率低。

Method: CORE通过布局感知分块、协同规划和协同决策结合云端与本地LLM，减少上传内容，使用多轮累计机制提升决策质量。

Result: 在多种移动应用和任务上，CORE减少多达55.6%的UI暴露，任务成功率接近云端LLM水平。

Conclusion: CORE有效降低隐私泄露风险，同时保持较高任务准确率，适合移动智能代理应用。

Abstract: Mobile agents rely on Large Language Models (LLMs) to plan and execute tasks
on smartphone user interfaces (UIs). While cloud-based LLMs achieve high task
accuracy, they require uploading the full UI state at every step, exposing
unnecessary and often irrelevant information. In contrast, local LLMs avoid UI
uploads but suffer from limited capacity, resulting in lower task success
rates. We propose $\textbf{CORE}$, a $\textbf{CO}$llaborative framework that
combines the strengths of cloud and local LLMs to $\textbf{R}$educe UI
$\textbf{E}$xposure, while maintaining task accuracy for mobile agents. CORE
comprises three key components: (1) $\textbf{Layout-aware block partitioning}$,
which groups semantically related UI elements based on the XML screen
hierarchy; (2) $\textbf{Co-planning}$, where local and cloud LLMs
collaboratively identify the current sub-task; and (3)
$\textbf{Co-decision-making}$, where the local LLM ranks relevant UI blocks,
and the cloud LLM selects specific UI elements within the top-ranked block.
CORE further introduces a multi-round accumulation mechanism to mitigate local
misjudgment or limited context. Experiments across diverse mobile apps and
tasks show that CORE reduces UI exposure by up to 55.6% while maintaining task
success rates slightly below cloud-only agents, effectively mitigating
unnecessary privacy exposure to the cloud. The code is available at
https://github.com/Entropy-Fighter/CORE.

</details>


### [28] [DeceptionBench: A Comprehensive Benchmark for AI Deception Behaviors in Real-world Scenarios](https://arxiv.org/abs/2510.15501)
*Yao Huang,Yitong Sun,Yichi Zhang,Ruochen Zhang,Yinpeng Dong,Xingxing Wei*

Main category: cs.CL

TL;DR: 本文提出DeceptionBench基准，系统评估大型语言模型在不同社会领域中的欺骗行为，探讨其内在行为模式及外部因素影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能力提升带来欺骗行为风险，但现实场景中欺骗行为的系统性研究仍然不足。

Method: 构建涵盖经济、医疗、教育、社交和娱乐五个领域的150个场景，超过1000个样本，分析模型的自利性与谄媚性倾向，以及中性、奖励和胁迫情境下的欺骗表现，并设计多轮交互模拟反馈动态。

Result: 实验揭示模型在强化学习下欺骗行为显著增加，暴露其对操控性上下文提示的脆弱性。

Conclusion: 当前大型语言模型缺乏对欺骗行为的鲁棒抵抗能力，亟需加强防护机制以应对多样化的欺骗风险。

Abstract: Despite the remarkable advances of Large Language Models (LLMs) across
diverse cognitive tasks, the rapid enhancement of these capabilities also
introduces emergent deceptive behaviors that may induce severe risks in
high-stakes deployments. More critically, the characterization of deception
across realistic real-world scenarios remains underexplored. To bridge this
gap, we establish DeceptionBench, the first benchmark that systematically
evaluates how deceptive tendencies manifest across different societal domains,
what their intrinsic behavioral patterns are, and how extrinsic factors affect
them. Specifically, on the static count, the benchmark encompasses 150
meticulously designed scenarios in five domains, i.e., Economy, Healthcare,
Education, Social Interaction, and Entertainment, with over 1,000 samples,
providing sufficient empirical foundations for deception analysis. On the
intrinsic dimension, we explore whether models exhibit self-interested egoistic
tendencies or sycophantic behaviors that prioritize user appeasement. On the
extrinsic dimension, we investigate how contextual factors modulate deceptive
outputs under neutral conditions, reward-based incentivization, and coercive
pressures. Moreover, we incorporate sustained multi-turn interaction loops to
construct a more realistic simulation of real-world feedback dynamics.
Extensive experiments across LLMs and Large Reasoning Models (LRMs) reveal
critical vulnerabilities, particularly amplified deception under reinforcement
dynamics, demonstrating that current models lack robust resistance to
manipulative contextual cues and the urgent need for advanced safeguards
against various deception behaviors. Code and resources are publicly available
at https://github.com/Aries-iai/DeceptionBench.

</details>


### [29] [Temporal Referential Consistency: Do LLMs Favor Sequences Over Absolute Time References?](https://arxiv.org/abs/2510.15513)
*Ashutosh Bajpai,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文提出了一个衡量大型语言模型时间一致性的基准TEMP-ReCon，并提出了基于推理路径对齐的模型UnTRaP以提升模型的时间指称一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在法律、医疗、金融等时间敏感领域的广泛应用要求其不仅具备事实准确性，还需在时间维度上保持一致，但现有研究缺乏针对时间一致性的评估和改进方法。

Method: 作者构建了TEMP-ReCon基准，涵盖多种语言和语境，用于评估模型的时间指称一致性，并提出基于推理路径对齐的UnTRaP模型来提升时间一致性。

Result: 实验结果显示现有LLM时间指称一致性不足，且UnTRaP模型相比多种基线模型在提高时间一致性方面表现更优。

Conclusion: 通过构建新基准和提出创新模型，本文有效提升了大型语言模型在时间敏感任务上的指称一致性，推动了LLM在相关领域的应用可靠性。

Abstract: The increasing acceptance of large language models (LLMs) as an alternative
to knowledge sources marks a significant paradigm shift across various domains,
including time-sensitive fields such as law, healthcare, and finance. To
fulfill this expanded role, LLMs must not only be factually accurate but also
demonstrate consistency across temporal dimensions, necessitating robust
temporal reasoning capabilities. Despite this critical requirement, efforts to
ensure temporal consistency in LLMs remain scarce including noticeable absence
of endeavors aimed at evaluating or augmenting LLMs across temporal references
in time-sensitive inquiries. In this paper, we seek to address this gap by
introducing a novel benchmark entitled temporal referential consistency,
accompanied by a resource TEMP-ReCon designed to benchmark a wide range of both
open-source and closed-source LLMs with various linguistic contexts
characterized by differing resource richness (including English, French, and
Romanian). The findings emphasis that LLMs do exhibit insufficient temporal
referent consistency. To address this, we propose \newmodel, a reasoning path
alignment-based model that aims to enhance the temporal referential consistency
of LLMs. Our empirical experiments substantiate the efficacy of UnTRaP compared
to several baseline models.

</details>


### [30] [From Characters to Tokens: Dynamic Grouping with Hierarchical BPE](https://arxiv.org/abs/2510.15517)
*Rares Dolga,Lucas Maystre,Tudor Berariu,David Barber*

Main category: cs.CL

TL;DR: 本文提出了一种基于动态字符分组的子词标记方法，通过二次BPE压缩控制分组粒度，实现高效且语言无关的表示。


<details>
  <summary>Details</summary>
Motivation: 当前BPE方法在表示低频词汇和嵌入矩阵大小上存在不足，字符级模型虽解决这些问题但性能受限，已有分层模型受语言限制或依赖额外模型。

Method: 作者提出在BPE标记中添加结束标记，并引入第二级BPE压缩控制补丁粒度，无需额外辅助模型，实现动态字符分组。

Result: 该方法在性能上可匹敌或超越基于熵和空白的动态分组策略，同时保持词汇表紧凑。

Conclusion: 所提方法兼具高效性和灵活性，适用于多语言场景，提升了子词标记的实用性和性能表现。

Abstract: Subword tokenization methods like Byte Pair Encoding (BPE) are widely used in
large language models due to their balance of vocabulary compactness and
representational power. However, they suffer from inefficiencies in
representing rare words and require large embedding matrices. Character-level
models address these issues but introduce performance bottlenecks, particularly
in Transformer-based architectures. Recent hierarchical models attempt to merge
the benefits of both paradigms by grouping characters into patches, but
existing patching strategies either rely on whitespace-limiting applicability
to certain languages, or require auxiliary models that introduce new
dependencies. In this paper, we propose a dynamic character grouping method
that leverages the structure of existing BPE tokenization without requiring
additional models. By appending explicit end-of-patch markers to BPE tokens and
introducing a second-level BPE compression stage to control patch granularity,
our method offers efficient, flexible, and language-agnostic representations.
Empirical results demonstrate that our approach matches or exceeds the
performance of dynamic entropy- and whitespace-based patching strategies, while
maintaining a compact vocabulary.

</details>


### [31] [Latent Reasoning in LLMs as a Vocabulary-Space Superposition](https://arxiv.org/abs/2510.15522)
*Jingcheng Deng,Liang Pang,Zihao Wei,Shichen Xu,Zenghao Duan,Kun Xu,Yang Song,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: 本文提出一种称为Latent-SFT的两阶段学习框架，通过将隐含推理限制在语言模型词汇列空间，提高了隐含推理的效率和性能，显著减少计算开销，同时达到或超越显式推理的效果。


<details>
  <summary>Details</summary>
Motivation: 显式推理虽然有效，但计算开销大；隐含推理虽然减低成本，但性能下降，主要因隐含空间无结构，难以拟合隐含标记。

Method: 通过限制隐含空间为语言模型词汇的列空间，将隐含推理视为词汇概率的叠加，并提出两阶段学习框架：第一阶段设计注意力掩码引导隐含标记生成，第二阶段弃用隐含标记编码器，直接训练语言模型自主生成隐含标记，优化采用KL和交叉熵损失。

Result: Latent-SFT在GSM8k数据集上达到显式监督微调性能的同时，将推理链长度缩短至1/4，且优于以往隐含方法；在Math500和AIME24数据集上也明显优于基于隐藏状态的方法。

Conclusion: 隐含推理作为词汇概率的叠加，既实现了单路径的压缩，也实现了多路径的叠加，有效提升推理速度和准确性，表明Latent-SFT是高效且有效的隐含推理框架。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities with
chain-of-thought prompting, but explicit reasoning introduces substantial
computational overhead. Recent work on latent reasoning reduces this cost by
reasoning in latent space without explicit supervision, but performance drops
significantly. Our preliminary experiments suggest that this degradation stems
from the unstructured latent space, which makes fitting latent tokens
difficult. To address this, we restrict the latent space to the column space of
the LLM vocabulary, treating latent reasoning as a superposition over
vocabulary probabilities. Once latent reasoning concludes, it collapses into an
eigenstate of explicit reasoning to yield the final answer. Based on this idea,
we propose Latent-SFT, a two-stage learning framework. In the first stage, we
design two specialized attention masks to guide the Latent Token Encoder in
generating latent tokens, allowing the LLM to produce the correct answer
conditioned on them. In the second stage, the Latent Token Encoder is
discarded, and the LLM is directly trained to generate these latent tokens
autonomously for latent reasoning, optimized with KL and CE losses. Latent-SFT
sets a new state of the art on GSM8k, matching explicit SFT performance while
cutting reasoning chains by up to 4 times and outperforming prior latent
methods. On Math500 and AIME24, lexical probability-based latent reasoning also
clearly surpasses hidden-state-based approaches. Our metrics of effective
compression rate and effective global parallelism further show that latent
reasoning is both the compression of a single path and the superposition of
multiple paths.

</details>


### [32] [MCA: Modality Composition Awareness for Robust Composed Multimodal Retrieval](https://arxiv.org/abs/2510.15543)
*Qiyu Wu,Shuyang Cui,Satoshi Hayakawa,Wei-Yao Wang,Hiromi Wakaki,Yuki Mitsufuji*

Main category: cs.CL

TL;DR: 本文提出了一种多模态检索中的模态组成感知框架，以解决统一编码器在对抗分布变动时鲁棒性差的问题。


<details>
  <summary>Details</summary>
Motivation: 统一编码器在多模态大语言模型中虽灵活且先进，但使用传统对比学习训练时容易学习模态捷径，导致分布变动下表现下降。

Method: 设计了偏好损失（preference loss）使多模态嵌入优于单模态嵌入，并通过组成正则项将多模态嵌入与由单模态部分组成的原型对齐，显式建模结构关系。

Result: 在多种基准测试中，提出方法提升了分布外检索性能，验证了模态组成感知原则的有效性。

Conclusion: 模态组成感知是利用多模态大语言模型作为统一编码器时提升多模态检索鲁棒性的一种有效策略。

Abstract: Multimodal retrieval, which seeks to retrieve relevant content across
modalities such as text or image, supports applications from AI search to
contents production. Despite the success of separate-encoder approaches like
CLIP align modality-specific embeddings with contrastive learning, recent
multimodal large language models (MLLMs) enable a unified encoder that directly
processes composed inputs. While flexible and advanced, we identify that
unified encoders trained with conventional contrastive learning are prone to
learn modality shortcut, leading to poor robustness under distribution shifts.
We propose a modality composition awareness framework to mitigate this issue.
Concretely, a preference loss enforces multimodal embeddings to outperform
their unimodal counterparts, while a composition regularization objective
aligns multimodal embeddings with prototypes composed from its unimodal parts.
These objectives explicitly model structural relationships between the composed
representation and its unimodal counterparts. Experiments on various benchmarks
show gains in out-of-distribution retrieval, highlighting modality composition
awareness as a effective principle for robust composed multimodal retrieval
when utilizing MLLMs as the unified encoder.

</details>


### [33] [TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs](https://arxiv.org/abs/2510.15545)
*Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou*

Main category: cs.CL

TL;DR: 提出了基于动态时间弯曲(DTW)的TokenTiming算法，实现了大语言模型推理中推测解码的通用化，加速了模型推理。


<details>
  <summary>Details</summary>
Motivation: 传统推测解码要求草稿模型与目标模型共享词汇表，限制了草稿模型的选择并需要重新训练，影响效率和灵活性。

Method: 利用DTW算法对草稿模型生成的token序列进行重新编码，建立映射关系，将概率分布转移到目标模型实现推测采样，从而支持不同词汇表的模型组合，无需重新训练。

Result: 在多种任务上实现了1.57倍的推理加速，验证了方法的有效性。

Conclusion: TokenTiming算法拓宽了推测解码的适用范围，使得不同模型间推理加速更加灵活实用。

Abstract: Accelerating the inference of large language models (LLMs) has been a
critical challenge in generative AI. Speculative decoding (SD) substantially
improves LLM inference efficiency. However, its utility is limited by a
fundamental constraint: the draft and target models must share the same
vocabulary, thus limiting the herd of available draft models and often
necessitating the training of a new model from scratch. Inspired by Dynamic
Time Warping (DTW), a classic algorithm for aligning time series, we propose
the algorithm TokenTiming for universal speculative decoding. It operates by
re-encoding the draft token sequence to get a new target token sequence, and
then uses DTW to build a mapping to transfer the probability distributions for
speculative sampling. Benefiting from this, our method accommodates mismatched
vocabularies and works with any off-the-shelf models without retraining and
modification. We conduct comprehensive experiments on various tasks,
demonstrating 1.57x speedup. This work enables a universal approach for draft
model selection, making SD a more versatile and practical tool for LLM
acceleration.

</details>


### [34] [Rethinking Cross-lingual Gaps from a Statistical Viewpoint](https://arxiv.org/abs/2510.15551)
*Vihari Piratla,Purvam Jain,Darshan Singh,Partha Talukdar,Trevor Cohn*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型中跨语言知识查询的准确性下降问题，将其归因于目标语言回应的方差过大。


<details>
  <summary>Details</summary>
Motivation: 先前研究将跨语言准确性下降归因于源语言和目标语言潜在表示的差异，本文提出方差是主要原因。

Method: 通过偏差-方差分解形式化跨语言差距，设计多种推理阶段的方差控制干预措施，并提出简单的提示指令减少回应方差。

Result: 实验证明控制回应方差显著提升了目标语言查询的准确度，提示指令使准确率提升20-25%。

Conclusion: 方差是跨语言知识迁移性能下降的关键因素，适当干预可有效缩小跨语言性能差距。

Abstract: Any piece of knowledge is usually expressed in one or a handful of natural
languages on the web or in any large corpus. Large Language Models (LLMs) act
as a bridge by acquiring knowledge from a source language and making it
accessible when queried from target languages. Prior research has pointed to a
cross-lingual gap, viz., a drop in accuracy when the knowledge is queried in a
target language compared to when the query is in the source language. Existing
research has rationalized divergence in latent representations in source and
target languages as the source of cross-lingual gap. In this work, we take an
alternative view and hypothesize that the variance of responses in the target
language is the main cause of this gap. For the first time, we formalize the
cross-lingual gap in terms of bias-variance decomposition. We present extensive
experimental evidence which support proposed formulation and hypothesis. We
then reinforce our hypothesis through multiple inference-time interventions
that control the variance and reduce the cross-lingual gap. We demonstrate a
simple prompt instruction to reduce the response variance, which improved
target accuracy by 20-25% across different models.

</details>


### [35] [Think Parallax: Solving Multi-Hop Problems via Multi-View Knowledge-Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2510.15552)
*Jinliang Liu*

Main category: cs.CL

TL;DR: 提出了ParallaxRAG框架，通过多视角空间对查询和知识图谱三元组进行对称解耦，实现了更鲁棒的检索结构，提升多跳推理能力，减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然语言理解能力强，但存在幻觉和多跳推理困难，且现有基于知识图谱的增强生成方法依赖平面嵌入和噪声路径探索，效果有限。

Method: ParallaxRAG框架通过多视角空间对查询和图谱三元组进行对称解耦，利用多头注意力机制中的头专门化特点构建更清晰的子图，限制弱相关路径，并引导语言模型进行分步推理。

Result: 在WebQSP和CWQ数据集上，基于BGE-M3和Llama3.1-8B环境下，ParallaxRAG表现出竞争性的检索和问答性能，减少幻觉问题并具备良好泛化能力。

Conclusion: 多视角头专门化是实现基于知识的多跳推理的有效方向，ParallaxRAG展示了该思想的潜力与优势。

Abstract: Large language models (LLMs) excel at language understanding but often
hallucinate and struggle with multi-hop reasoning. Knowledge-graph-based
retrieval-augmented generation (KG-RAG) offers grounding, yet most methods rely
on flat embeddings and noisy path exploration. We propose ParallaxRAG, a
framework that symmetrically decouples queries and graph triples into
multi-view spaces, enabling a robust retrieval architecture that explicitly
enforces head diversity while constraining weakly related paths. Central to our
approach is the observation that different attention heads specialize in
semantic relations at distinct reasoning stages, contributing to different hops
of the reasoning chain. This specialization allows ParallaxRAG to construct
cleaner subgraphs and guide LLMs through grounded, step-wise reasoning.
Experiments on WebQSP and CWQ, under our unified, reproducible setup (BGE-M3 +
Llama3.1-8B), demonstrate competitive retrieval and QA performance, alongside
reduced hallucination and good generalization. Our results highlight multi-view
head specialization as a principled direction for knowledge-grounded multi-hop
reasoning. Our implementation will be released as soon as the paper is
accepted.

</details>


### [36] [KITE: A Benchmark for Evaluating Korean Instruction-Following Abilities in Large Language Models](https://arxiv.org/abs/2510.15558)
*Dongjun Kim,Chanhee Park,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

TL;DR: 本文提出了KITE，评估韩语大语言模型指令跟随能力的综合基准，填补现有评测多集中于英语的空白。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评测主要集中在英语，忽视了韩语的独特语言特性和文化差异，缺少专门评测韩语开放式指令跟随能力的基准。

Method: 设计并构建KITE数据集，涵盖一般及韩语特定指令，结合自动评测与人工评价，全面评估模型的指令跟随表现。

Result: 通过KITE揭示不同模型在韩语指令跟随任务中表现差异，分析模型优势与不足。

Conclusion: 公开发布KITE数据和代码，推动对文化和语言包容性的大语言模型研究，鼓励其他少数语言的类似工作。

Abstract: The instruction-following capabilities of large language models (LLMs) are
pivotal for numerous applications, from conversational agents to complex
reasoning systems. However, current evaluations predominantly focus on English
models, neglecting the linguistic and cultural nuances of other languages.
Specifically, Korean, with its distinct syntax, rich morphological features,
honorific system, and dual numbering systems, lacks a dedicated benchmark for
assessing open-ended instruction-following capabilities. To address this gap,
we introduce the Korean Instruction-following Task Evaluation (KITE), a
comprehensive benchmark designed to evaluate both general and Korean-specific
instructions. Unlike existing Korean benchmarks that focus mainly on factual
knowledge or multiple-choice testing, KITE directly targets diverse, open-ended
instruction-following tasks. Our evaluation pipeline combines automated metrics
with human assessments, revealing performance disparities across models and
providing deeper insights into their strengths and weaknesses. By publicly
releasing the KITE dataset and code, we aim to foster further research on
culturally and linguistically inclusive LLM development and inspire similar
endeavors for other underrepresented languages.

</details>


### [37] [Finetuning LLMs for EvaCun 2025 token prediction shared task](https://arxiv.org/abs/2510.15561)
*Josef Jon,Ondřej Bojar*

Main category: cs.CL

TL;DR: 本文介绍了利用三种大语言模型进行EvaCun 2025的标记预测任务，且仅用原始训练数据进行微调，没有额外预处理。


<details>
  <summary>Details</summary>
Motivation: 由于对任务领域和语言知识浅薄，作者选择直接利用提供的训练数据进行模型微调，旨在探究简单基线模型的表现。

Method: 采用Command-R、Mistral和Aya Expanse三种大语言模型，基于三种不同的提示词方法进行预测，微调于组织者提供的训练数据。

Result: 对三种提示词方法的预测结果在保留的数据集上进行了比较和评估。

Conclusion: 通过简单使用原始训练数据进行微调的方式可行，但未进一步优化，因此结果体现了基线性能。

Abstract: In this paper, we present our submission for the token prediction task of
EvaCun 2025. Our sys-tems are based on LLMs (Command-R, Mistral, and Aya
Expanse) fine-tuned on the task data provided by the organizers. As we only
pos-sess a very superficial knowledge of the subject field and the languages of
the task, we simply used the training data without any task-specific
adjustments, preprocessing, or filtering. We compare 3 different approaches
(based on 3 different prompts) of obtaining the predictions, and we evaluate
them on a held-out part of the data.

</details>


### [38] [From Ghazals to Sonnets: Decoding the Polysemous Expressions of Love Across Languages](https://arxiv.org/abs/2510.15569)
*Syed Mohammad Sualeh Ali*

Main category: cs.CL

TL;DR: 本论文通过多义视角解析乌尔都语诗歌中表达爱情的三个词（pyaar, muhabbat, ishq），揭示其独特的情感层次和语义差异。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语中表达爱情的词语虽近义，但意义细腻丰富，且缺乏英语中直接对应词，促使作者探讨其文化及语言层面的独特表达。

Method: 采用多义案例研究法，深入分析这三个词在乌尔都诗歌中的使用及语境，结合词向量技术进行乌尔都语与英语相关词语的比较分析。

Result: 发现了三个词之间微妙的语义差异和丰富情感层次，词向量的比较分析直观展示了其语义空间的文化语言差异。

Conclusion: 通过多维度的分析，研究深化了对乌尔都语诗歌中特有爱情表达的理解，丰富了该领域的文化语言认知。

Abstract: This paper delves into the intricate world of Urdu poetry, exploring its
thematic depths through a lens of polysemy. By focusing on the nuanced
differences between three seemingly synonymous words (pyaar, muhabbat, and
ishq) we expose a spectrum of emotions and experiences unique to the Urdu
language. This study employs a polysemic case study approach, meticulously
examining how these words are interwoven within the rich tapestry of Urdu
poetry. By analyzing their usage and context, we uncover a hidden layer of
meaning, revealing subtle distinctions which lack direct equivalents in English
literature. Furthermore, we embark on a comparative analysis, generating word
embeddings for both Urdu and English terms related to love. This enables us to
quantify and visualize the semantic space occupied by these words, providing
valuable insights into the cultural and linguistic nuances of expressing love.
Through this multifaceted approach, our study sheds light on the captivating
complexities of Urdu poetry, offering a deeper understanding and appreciation
for its unique portrayal of love and its myriad expressions

</details>


### [39] [BiMax: Bidirectional MaxSim Score for Document-Level Alignment](https://arxiv.org/abs/2510.15577)
*Xiaotian Wang,Takehito Utsuro,Masaaki Nagata*

Main category: cs.CL

TL;DR: 本文提出了一种跨语言双向最大相似度得分方法（BiMax）用于文档对齐，比现有最优传输方法（OT）大幅提升速度，且在WMT16双语文档对齐任务中保持了相似的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了处理大规模网络挖掘数据，在保证文档对齐准确率的同时，提高计算效率是亟需解决的问题。

Method: 提出了跨语言双向最大相似度得分（BiMax）方法，用于计算文档间相似性，提升效率；并对多语言句子嵌入模型性能进行了综合分析。

Result: 在WMT16双语文档对齐任务中，BiMax的准确率与OT方法相当，但速度提升约100倍。

Conclusion: BiMax方法有效提高了文档对齐的效率，兼顾了速度与准确性，所提出的所有对齐方法已作为开源工具EmbDA发布。

Abstract: Document alignment is necessary for the hierarchical mining (Ba\~n\'on et
al., 2020; Morishita et al., 2022), which aligns documents across source and
target languages within the same web domain. Several high precision sentence
embedding-based methods have been developed, such as TK-PERT (Thompson and
Koehn, 2020) and Optimal Transport (OT) (Clark et al., 2019; El-Kishky and
Guzm\'an, 2020). However, given the massive scale of web mining data, both
accuracy and speed must be considered. In this paper, we propose a
cross-lingual Bidirectional Maxsim score (BiMax) for computing doc-to-doc
similarity, to improve efficiency compared to the OT method. Consequently, on
the WMT16 bilingual document alignment task, BiMax attains accuracy comparable
to OT with an approximate 100-fold speed increase. Meanwhile, we also conduct a
comprehensive analysis to investigate the performance of current
state-of-the-art multilingual sentence embedding models. All the alignment
methods in this paper are publicly available as a tool called EmbDA
(https://github.com/EternalEdenn/EmbDA).

</details>


### [40] [The Elephant in the Coreference Room: Resolving Coreference in Full-Length French Fiction Works](https://arxiv.org/abs/2510.15594)
*Antoine Bourgois,Thierry Poibeau*

Main category: cs.CL

TL;DR: 本文介绍了一个包含三部长篇法语小说的新注释语料库，解决了长文本中指代消解的挑战，并提出了一个可进行细粒度错误分析的模块化指代消解系统。


<details>
  <summary>Details</summary>
Motivation: 当前用于指代消解的标注数据集主要集中于短文本，缺少对长篇复杂文学作品的全面注释，限制了模型在长文本中的表现评估。

Method: 构建了包含超过28.5万词的新语料库，设计了一个模块化指代消解流水线，用于细粒度错误分析并适应长文本处理。

Result: 该方法在长文本指代消解任务中表现竞争力且具备良好扩展性，能够有效处理长篇复杂文本。

Conclusion: 所提体系不仅提升了长文本指代消解效果，还能用于推断虚构人物性别，证明其在文学分析及下游自然语言处理任务中的实用性。

Abstract: While coreference resolution is attracting more interest than ever from
computational literature researchers, representative datasets of fully
annotated long documents remain surprisingly scarce. In this paper, we
introduce a new annotated corpus of three full-length French novels, totaling
over 285,000 tokens. Unlike previous datasets focused on shorter texts, our
corpus addresses the challenges posed by long, complex literary works, enabling
evaluation of coreference models in the context of long reference chains. We
present a modular coreference resolution pipeline that allows for fine-grained
error analysis. We show that our approach is competitive and scales effectively
to long documents. Finally, we demonstrate its usefulness to infer the gender
of fictional characters, showcasing its relevance for both literary analysis
and downstream NLP tasks.

</details>


### [41] [HypoSpace: Evaluating LLM Creativity as Set-Valued Hypothesis Generators under Underdetermination](https://arxiv.org/abs/2510.15614)
*Tingting Chen,Beibei Lin,Zifeng Yuan,Qiran Zou,Hongyu He,Yew-Soon Ong,Anirudh Goyal,Dianbo Liu*

Main category: cs.CL

TL;DR: 本文提出HypoSpace，一个用于评估大型语言模型生成解释假设集合能力的诊断工具，衡量假设的有效性、唯一性和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 科学问题常常存在多种不同的合理假设，单一答案评估无法全面反映语言模型在生成多样解释方案方面的能力。

Method: HypoSpace将大型语言模型视为有限假设集合的采样器，通过三项指标 Validity（有效性）、Uniqueness（唯一性）和 Recovery（覆盖率）进行量化评估。该方法在三种结构域中使用确定性验证器和精确定义的假设空间进行测试。

Result: 结果显示，虽然不同模型在假设有效性方面表现较好，但随着可接受假设空间的扩大，唯一性和覆盖率显著下降，暴露了仅基于正确性指标无法发现的模式崩溃问题。

Conclusion: HypoSpace为评估语言模型探索和覆盖多假设解释空间提供了新的、控制性强的诊断手段，弥补了传统排行榜方法的不足。

Abstract: As language models are increasingly used in scientific workflows, evaluating
their ability to propose sets of explanations-not just a single correct
answer-becomes critical. Many scientific problems are underdetermined:
multiple, mechanistically distinct hypotheses are consistent with the same
observations. We introduce HypoSpace, a diagnostic suite that treats LLMs as
samplers of finite hypothesis sets and measures three complementary indicators:
Validity (precision of proposals consistent with observations), Uniqueness
(non-redundancy among proposals), and Recovery (coverage of the enumerated
admissible set). We instantiate HypoSpace in three structured domains with
deterministic validators and exactly enumerated hypothesis spaces: (i) causal
graphs from perturbations, (ii) gravity-constrained 3D voxel reconstruction
from top-down projections, and (iii) Boolean genetic interactions. Across
instruction-tuned and reasoning-focused models, Validity often remains high
while Uniqueness and Recovery degrade as the admissible space grows, revealing
mode collapse that is invisible to correctness-only metrics. HypoSpace offers a
controlled probe-rather than a leaderboard-for methods that explicitly explore
and cover admissible explanation spaces. Code is available at:
https://github.com/CTT-Pavilion/_HypoSpace.

</details>


### [42] [Leveraging LLMs for Context-Aware Implicit Textual and Multimodal Hate Speech Detection](https://arxiv.org/abs/2510.15685)
*Joshua Wolfe Brook,Ilia Markov*

Main category: cs.CL

TL;DR: 该研究提出利用大语言模型（LLMs）作为动态知识库生成背景上下文，提升文本及多模态仇恨言论检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测缺乏有效利用背景信息的方法，导致对隐含及多模态仇恨内容识别能力不足。

Method: 提出两种背景上下文生成策略（命名实体和全文提示），比较四种上下文融合方式（文本拼接、嵌入拼接、层次变换器融合及LLM文本增强），并在文本和多模态数据集上进行验证。

Result: 实验表明，融合背景信息显著提升检测效果，嵌入拼接方法在文本和多模态任务中分别提升最高达3和6个F1分数点。

Conclusion: 动态生成并有效融合背景上下文是提升仇恨言论检测性能的关键，嵌入拼接融合方式表现最佳。

Abstract: This research introduces a novel approach to textual and multimodal Hate
Speech Detection (HSD), using Large Language Models (LLMs) as dynamic knowledge
bases to generate background context and incorporate it into the input of HSD
classifiers. Two context generation strategies are examined: one focused on
named entities and the other on full-text prompting. Four methods of
incorporating context into the classifier input are compared: text
concatenation, embedding concatenation, a hierarchical transformer-based
fusion, and LLM-driven text enhancement. Experiments are conducted on the
textual Latent Hatred dataset of implicit hate speech and applied in a
multimodal setting on the MAMI dataset of misogynous memes. Results suggest
that both the contextual information and the method by which it is incorporated
are key, with gains of up to 3 and 6 F1 points on textual and multimodal setups
respectively, from a zero-context baseline to the highest-performing system,
based on embedding concatenation.

</details>


### [43] [Cost-Aware Retrieval-Augmentation Reasoning Models with Adaptive Retrieval Depth](https://arxiv.org/abs/2510.15719)
*Helia Hashemi,Victor Rühle,Saravan Rajmohan*

Main category: cs.CL

TL;DR: 本文提出了一种基于检索增强的推理模型，通过动态调整检索文档长度和成本感知的强化学习训练方法，实现了显著提高效率且提升效果的目标。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强推理模型在性能强劲的同时计算成本较高，尤其是检索与推理阶段的开销显著。

Method: 提出动态调整检索文档列表长度的方法；开发成本感知优势函数进行强化学习训练；探索内存与延迟约束下的实现方式，适用于多种策略优化算法。

Result: 在七个公开问答数据集上实验，模型延迟降低16-20%，准确率提升约5%。

Conclusion: 该方法在不牺牲效果的前提下，有效提升了检索增强推理模型的计算效率，具有实际应用价值。

Abstract: Reasoning models have gained significant attention due to their strong
performance, particularly when enhanced with retrieval augmentation. However,
these models often incur high computational costs, as both retrieval and
reasoning tokens contribute substantially to the overall resource usage. In
this work, we make the following contributions: (1) we propose a
retrieval-augmented reasoning model that dynamically adjusts the length of the
retrieved document list based on the query and retrieval results; (2) we
develop a cost-aware advantage function for training of efficient
retrieval-augmented reasoning models through reinforcement learning; and (3) we
explore both memory- and latency-bound implementations of the proposed
cost-aware framework for both proximal and group relative policy optimization
algorithms. We evaluate our approach on seven public question answering
datasets and demonstrate significant efficiency gains, without compromising
effectiveness. In fact, we observed that the model latency decreases by ~16-20%
across datasets, while its effectiveness increases by ~5% on average, in terms
of exact match.

</details>


### [44] [Attention Sinks in Diffusion Language Models](https://arxiv.org/abs/2510.15731)
*Maximo Eduardo Rulli,Simone Petruzzi,Edoardo Michielon,Fabrizio Silvestri,Simone Scardapane,Alessio Devoto*

Main category: cs.CL

TL;DR: 本文对掩码扩散语言模型（DLMs）的注意力模式进行了经验分析，重点研究了注意力汇聚现象，发现DLMs的汇聚位置动态变化且对汇聚屏蔽具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管DLMs在效率和效果上表现优异，但其内部机制尚未深入研究，特别是注意力汇聚现象在DLM中的表现。

Method: 通过实证分析，研究DLMs注意力模式中的注意力汇聚现象，比较其与自回归模型（ARMs）中的差异。

Result: 发现DLMs的注意力汇聚位置在生成过程中动态变化，且屏蔽注意力汇聚仅导致轻微性能下降，表现出较强鲁棒性。

Conclusion: 本文揭示了扩散语言模型内部注意力分配与利用的基本差异，为理解DLMs机制提供了新视角。

Abstract: Masked Diffusion Language Models (DLMs) have recently emerged as a promising
alternative to traditional Autoregressive Models (ARMs). DLMs employ
transformer encoders with bidirectional attention, enabling parallel token
generation while maintaining competitive performance. Although their efficiency
and effectiveness have been extensively studied, the internal mechanisms that
govern DLMs remain largely unexplored. In this work, we conduct an empirical
analysis of DLM attention patterns, focusing on the attention sinking
phenomenon, an effect previously observed in various transformer-based
architectures. Our findings reveal that DLMs also exhibit attention sinks, but
with distinct characteristics. First, unlike in ARMs, the sink positions in
DLMs tend to shift throughout the generation process, displaying a dynamic
behaviour. Second, while ARMs are highly sensitive to the removal of attention
sinks, DLMs remain robust: masking sinks leads to only a minor degradation in
performance. These results provide new insights into the inner workings of
diffusion-based language models and highlight fundamental differences in how
they allocate and utilize attention compared to autoregressive models.

</details>


### [45] [LLMs Judge Themselves: A Game-Theoretic Framework for Human-Aligned Evaluation](https://arxiv.org/abs/2510.15746)
*Gao Yang,Yuhang Liu,Siyu Miao,Xinyue Liang,Zhengyang Liu,Heyan Huang*

Main category: cs.CL

TL;DR: 本文探讨了利用博弈论原理对大语言模型（LLM）进行评估的可行性，提出了自动互评的新方法，通过模型自我对弈和同行评审来替代传统固定格式任务评估，并结合博弈论投票算法聚合结果，最终将模型评估结果与人类投票进行对比验证。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM评估方法依赖固定格式任务和参考答案，难以捕捉模型行为的细微差别和开放性，评估结果主观性强，亟需更有效的评估机制。

Method: 提出自动互评机制，让LLM相互评估输出，通过自我对弈和同行评审生成评价数据，利用博弈论投票算法对评审结果进行聚合，最后用人类投票行为验证模型生成排序与人类偏好的对应关系。

Result: 实验结果显示模型评估与人类评估存在收敛与发散现象，揭示了互评机制在反映人类偏好方面的优势与局限性。

Conclusion: 该工作首次将互评、博弈论聚合和人类验证相结合，为LLM能力评估提供了新的理论框架和实践指导，促进更客观和多维度的模型评估。

Abstract: Ideal or real - that is the question.In this work, we explore whether
principles from game theory can be effectively applied to the evaluation of
large language models (LLMs). This inquiry is motivated by the growing
inadequacy of conventional evaluation practices, which often rely on
fixed-format tasks with reference answers and struggle to capture the nuanced,
subjective, and open-ended nature of modern LLM behavior. To address these
challenges, we propose a novel alternative: automatic mutual evaluation, where
LLMs assess each other's output through self-play and peer review. These peer
assessments are then systematically compared with human voting behavior to
evaluate their alignment with human judgment. Our framework incorporates
game-theoretic voting algorithms to aggregate peer reviews, enabling a
principled investigation into whether model-generated rankings reflect human
preferences. Empirical results reveal both convergences and divergences between
theoretical predictions and human evaluations, offering valuable insights into
the promises and limitations of mutual evaluation. To the best of our
knowledge, this is the first work to jointly integrate mutual evaluation,
game-theoretic aggregation, and human-grounded validation for evaluating the
capabilities of LLMs.

</details>


### [46] [On Non-interactive Evaluation of Animal Communication Translators](https://arxiv.org/abs/2510.15768)
*Orr Paradise,David F. Gruber,Adam Tauman Kalai*

Main category: cs.CL

TL;DR: 提出了一种无需动物交互或观察，通过评估翻译英文输出质量来验证鲸鱼等复杂语言翻译器的方法。


<details>
  <summary>Details</summary>
Motivation: 传统验证动物语言翻译器需互动或依赖观察，存在安全、伦理及成本问题。

Method: 通过逐句翻译和NLP洗牌测试，检测译文的顺序合理性，从而识别假翻译。

Result: 实验证明该无参考翻译的评价指标在数据稀缺人类语言和构造语言上与传统有参考评价高度相关。

Conclusion: 理论与实验证据表明，初期翻译学习阶段无需与动物互动，即可有效评估翻译质量。该方法安全、伦理且经济。

Abstract: If you had an AI Whale-to-English translator, how could you validate whether
or not it is working? Does one need to interact with the animals or rely on
grounded observations such as temperature? We provide theoretical and
proof-of-concept experimental evidence suggesting that interaction and even
observations may not be necessary for sufficiently complex languages. One may
be able to evaluate translators solely by their English outputs, offering
potential advantages in terms of safety, ethics, and cost. This is an instance
of machine translation quality evaluation (MTQE) without any reference
translations available. A key challenge is identifying ``hallucinations,''
false translations which may appear fluent and plausible. We propose using
segment-by-segment translation together with the classic NLP shuffle test to
evaluate translators. The idea is to translate animal communication, turn by
turn, and evaluate how often the resulting translations make more sense in
order than permuted. Proof-of-concept experiments on data-scarce human
languages and constructed languages demonstrate the potential utility of this
evaluation methodology. These human-language experiments serve solely to
validate our reference-free metric under data scarcity. It is found to
correlate highly with a standard evaluation based on reference translations,
which are available in our experiments. We also perform a theoretical analysis
suggesting that interaction may not be necessary nor efficient in the early
stages of learning to translate.

</details>


### [47] [Emergence of Linear Truth Encodings in Language Models](https://arxiv.org/abs/2510.15804)
*Shauli Ravfogel,Gilad Yehudai,Tal Linzen,Joan Bruna,Alberto Bietti*

Main category: cs.CL

TL;DR: 本文介绍了一个单层变压器玩具模型，解释了大型语言模型中线性真实子空间的形成机制。


<details>
  <summary>Details</summary>
Motivation: 大语言模型中存在区分真假的线性子空间，但其形成机制尚不清楚。

Method: 构建一个透明的单层变压器模型，在特定数据分布（真实与真实共现，虚假与虚假共现）下训练，观察模型如何学习区分真假的线性子空间。

Result: 模型先快速记忆事实关联，随后学习线性区分真假，降低语言模型损失。预训练语言模型实验也支持这种模式。

Conclusion: 结果表明，线性真实表示能通过学习事实共现结构自然形成，揭示了其机械机理和动因。

Abstract: Recent probing studies reveal that large language models exhibit linear
subspaces that separate true from false statements, yet the mechanism behind
their emergence is unclear. We introduce a transparent, one-layer transformer
toy model that reproduces such truth subspaces end-to-end and exposes one
concrete route by which they can arise. We study one simple setting in which
truth encoding can emerge: a data distribution where factual statements
co-occur with other factual statements (and vice-versa), encouraging the model
to learn this distinction in order to lower the LM loss on future tokens. We
corroborate this pattern with experiments in pretrained language models.
Finally, in the toy setting we observe a two-phase learning dynamic: networks
first memorize individual factual associations in a few steps, then -- over a
longer horizon -- learn to linearly separate true from false, which in turn
lowers language-modeling loss. Together, these results provide both a
mechanistic demonstration and an empirical motivation for how and why linear
truth representations can emerge in language models.

</details>


### [48] [Paper2Web: Let's Make Your Paper Alive!](https://arxiv.org/abs/2510.15842)
*Yuhang Chen,Tianpeng Lv,Siyi Zhang,Yixiang Yin,Yao Wan,Philip S. Yu,Dongping Chen*

Main category: cs.CL

TL;DR: 本文提出了Paper2Web数据集和多维评估框架，用于学术网页生成，并设计了自动生成交互式多媒体学术主页的PWAgent系统，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前学术项目网站难以生成布局感知且交互良好的页面，且缺乏全面的评估体系。

Method: 引入Paper2Web基准数据集和评估体系，结合规则指标和人类验证的LLM评价，提出PWAgent自动化流水线，通过MCP工具迭代优化内容和布局。

Result: PWAgent在连接性、完整性、交互性、美观性和信息传达能力等多维指标上均显著优于模板和现有arXiv网页版本，且成本低，达到Pareto前沿。

Conclusion: PWAgent有效推动了学术网页自动化生成技术，解决了现有方法的缺陷，提升了学术内容的传播效率和用户体验。

Abstract: Academic project websites can more effectively disseminate research when they
clearly present core content and enable intuitive navigation and interaction.
However, current approaches such as direct Large Language Model (LLM)
generation, templates, or direct HTML conversion struggle to produce
layout-aware, interactive sites, and a comprehensive evaluation suite for this
task has been lacking. In this paper, we introduce Paper2Web, a benchmark
dataset and multi-dimensional evaluation framework for assessing academic
webpage generation. It incorporates rule-based metrics like Connectivity,
Completeness and human-verified LLM-as-a-Judge (covering interactivity,
aesthetics, and informativeness), and PaperQuiz, which measures paper-level
knowledge retention. We further present PWAgent, an autonomous pipeline that
converts scientific papers into interactive and multimedia-rich academic
homepages. The agent iteratively refines both content and layout through MCP
tools that enhance emphasis, balance, and presentation quality. Our experiments
show that PWAgent consistently outperforms end-to-end baselines like
template-based webpages and arXiv/alphaXiv versions by a large margin while
maintaining low cost, achieving the Pareto-front in academic webpage
generation.

</details>


### [49] [Enhanced Sentiment Interpretation via a Lexicon-Fuzzy-Transformer Framework](https://arxiv.org/abs/2510.15843)
*Shayan Rokhva,Mousa Alizadeh,Maryam Abdollahi Shamami*

Main category: cs.CL

TL;DR: 本论文提出了一种结合词典、模糊逻辑和Transformer模型的混合框架，用于更精准地检测产品评论和社交媒体中情感倾向及强度。


<details>
  <summary>Details</summary>
Motivation: 传统情感分析面临非正式和领域特定语言带来的挑战，准确捕捉情感极性和强度仍困难重重。

Method: 提出一种基于VADER的初步情感估计，结合DistilBERT置信度分数，通过模糊逻辑和两阶段调整，使用模糊推理系统生成连续的情感得分。

Result: 在食品配送、电子商务、旅游和时尚四个领域数据集上，模型在用户评分对齐、极端情感识别和误判减少方面表现优异，验证了方法的鲁棒性和效率。

Conclusion: 将符号推理与神经网络结合的混合框架能够实现可解释且细粒度的情感分析，特别适用于语言变化多端的应用场景。

Abstract: Accurately detecting sentiment polarity and intensity in product reviews and
social media posts remains challenging due to informal and domain-specific
language. To address this, we propose a novel hybrid lexicon-fuzzy-transformer
framework that combines rule-based heuristics, contextual deep learning, and
fuzzy logic to generate continuous sentiment scores reflecting both polarity
and strength. The pipeline begins with VADER-based initial sentiment
estimations, which are refined through a two-stage adjustment process. This
involves leveraging confidence scores from DistilBERT, a lightweight
transformer and applying fuzzy logic principles to mitigate excessive
neutrality bias and enhance granularity. A custom fuzzy inference system then
maps the refined scores onto a 0 to 1 continuum, producing expert)like
judgments. The framework is rigorously evaluated on four domain-specific
datasets. food delivery, e-commerce, tourism, and fashion. Results show
improved alignment with user ratings, better identification of sentiment
extremes, and reduced misclassifications. Both quantitative metrics
(distributional alignment, confusion matrices) and qualitative insights (case
studies, runtime analysis) affirm the models robustness and efficiency. This
work demonstrates the value of integrating symbolic reasoning with neural
models for interpretable, finegrained sentiment analysis in linguistically
dynamic domains.

</details>


### [50] [SpeechLLMs for Large-scale Contextualized Zero-shot Slot Filling](https://arxiv.org/abs/2510.15851)
*Kadri Hacioglu,Manjunath K E,Andreas Stolcke*

Main category: cs.CL

TL;DR: 本论文探讨了利用语音大型语言模型（speechLLMs）进行槽位填充任务，通过改进训练数据、模型架构及训练策略，提升模型性能并弥合与理论上界的差距。


<details>
  <summary>Details</summary>
Motivation: 传统的槽位填充方法依赖语音识别加自然语言理解，最近出现的speechLLMs为整合语音与文本基础模型、实现统一生成式槽位填充提供了新途径，但存在性能和泛化能力的不足。

Method: 本研究首先建立槽位填充任务的理论上界，分析性能、鲁棒性及泛化差距，并针对训练数据、模型架构和训练策略进行改进以提升表现。

Result: 各项改进均显著提升了槽位填充的性能，并进一步缩小了与理论上界的差距。

Conclusion: 通过对训练数据、架构和训练策略的优化，可以有效利用speechLLMs进行槽位填充任务，但仍存在实际应用中的挑战，论文提供了实证指导和见解。

Abstract: Slot filling is a crucial subtask in spoken language understanding (SLU),
traditionally implemented as a cascade of speech recognition followed by one or
more natural language understanding (NLU) components. The recent advent of
speech-based large language models (speechLLMs), which integrate speech and
textual foundation models, has opened new avenues for achieving speech
understanding tasks in a more unified, generative, and instruction-following
manner while promising data and compute efficiency with zero-shot abilities,
generalizing to unseen slot labels. We address the slot-filling task by
creating an empirical upper bound for the task, identifying performance,
robustness, and generalization gaps, and proposing improvements to the training
data, architecture, and training strategies to narrow the gap with the upper
bound result. We show that each of these measures improve performance
substantially, while highlighting practical challenges and providing empirical
guidance and insights for harnessing these emerging models.

</details>


### [51] [InfiMed-ORBIT: Aligning LLMs on Open-Ended Complex Tasks via Rubric-Based Incremental Training](https://arxiv.org/abs/2510.15859)
*Pengkai Wang,Qi Zuo,Pengwei Liu,Zhijie Sang,Congkai Xie,Hongxia Yang*

Main category: cs.CL

TL;DR: 针对医学对话中缺乏明确奖励函数的问题，提出了基于评分量表的增量强化学习框架ORBIT，有效提升了大语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在奖励明确的任务中表现优异，但在医学咨询等开放性、奖励模糊的领域存在挑战，缺少强健的奖励设计。

Method: ORBIT框架结合合成对话生成与动态评分量表创建，利用量表引导增量式强化学习，无需外部医学知识或手工规则。

Result: 在Qwen3-4B-Instruct模型上，使用仅2000样本，HealthBench-Hard测试中性能从7.0提升至27.2，达到同规模模型的最佳水平。

Conclusion: 基于评分量表的反馈机制具有良好扩展性，能显著推动大语言模型在复杂开放任务中的性能提升。

Abstract: Large Language Models (LLMs) have shown substantial advances through
reinforcement learning (RL), particularly in domains where rewards can be
programmatically verified, such as mathematics and code. In these areas, models
benefit from a well-defined operational base guided by explicit rule-based
objectives. However, this progress reveals a significant limitation: in
open-ended domains where rewards are ambiguous, subjective, or
context-dependent, such as creative writing, scientific reasoning, and notably
medical consultation, robust reward functions are lacking, making these areas
challenging for current RL strategies. To bridge this gap, we introduce ORBIT,
an open-ended rubric-based incremental training framework specifically designed
for high-stakes medical dialogue. ORBIT integrates syn- thetic dialogue
generation with the dynamic creation of rubrics, employing these rubrics to
direct an incremental RL process. In particular, this approach does not depend
on external medical knowledge or manual rules, instead utilizing rubric-guided
feedback to shape learning. When implemented on the Qwen3-4B-Instruct model,
our method can greatly enhance its performance on the HealthBench-Hard
benchmark from 7.0 to 27.2 using only 2k samples, thus achieving
state-of-the-art results for models of this scale. Our analysis confirms that
rubric-driven RL fos-ters consistent performance gains across diverse
consultation scenarios, going beyond simple numerical improvements. These
findings underscore rubric-based feedback as a scalable strategy for advancing
LLMs in intricate, open-ended tasks.

</details>


### [52] [PolySkill: Learning Generalizable Skills Through Polymorphic Abstraction](https://arxiv.org/abs/2510.15863)
*Simon Yu,Gang Li,Weiyan Shi,Peng Qi*

Main category: cs.CL

TL;DR: 本文提出了PolySkill框架，通过解耦技能的抽象目标与具体实现，提高了大语言模型驱动的智能体在不同网站上的技能泛化和复用能力。


<details>
  <summary>Details</summary>
Motivation: 现有技能学习方法往往导致技能过度专门化，难以在不同网站间泛化，限制了智能体的持续学习和适应能力。

Method: 借鉴软件工程中的多态性原理，PolySkill将技能的抽象目标与具体执行解耦，使得技能可组合并在多环境中通用。

Result: 实验显示PolySkill提升了1.7倍的技能复用率，成功率在多个任务中提升9.4%-13.9%，且操作步骤减少超过20%。

Conclusion: 分离技能目标和执行是发展能够持续学习并跨环境泛化的自主智能体的关键步骤，PolySkill为智能体长期适应开放网络环境提供了有效方案。

Abstract: Large language models (LLMs) are moving beyond static uses and are now
powering agents that learn continually during their interaction with external
environments. For example, agents can learn reusable skills while navigating
web pages or toggling new tools. However, existing methods for skill learning
often create skills that are over-specialized to a single website and fail to
generalize. We introduce PolySkill, a new framework that enables agents to
learn generalizable and compositional skills. The core idea, inspired by
polymorphism in software engineering, is to decouple a skill's abstract goal
(what it accomplishes) and its concrete implementation (how it is executed).
Experiments show that our method (1) improves skill reuse by 1.7x on seen
websites and (2) boosts success rates by up to 9.4% on Mind2Web and 13.9% on
unseen websites, while reducing steps by over 20%. (3) In self-exploration
settings without specified tasks, our framework improves the quality of
proposed tasks and enables agents to learn generalizable skills that work
across different sites. By enabling the agent to identify and refine its own
goals, the PolySkill enhances the agent's ability to learn a better curriculum,
leading to the acquisition of more generalizable skills compared to baseline
methods. This work provides a practical path toward building agents capable of
continual learning in adaptive environments. Our findings show that separating
a skill's goal from its execution is a crucial step toward developing
autonomous agents that can learn and generalize across the open web
continuously.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [53] [Automated Snippet-Alignment Data Augmentation for Code Translation](https://arxiv.org/abs/2510.15004)
*Zhiming Zhang,Qingfu Zhu,Xianzhen Luo,Yixuan Wang,Bohan Li,Wanxiang Che*

Main category: cs.SE

TL;DR: 本文提出了一种利用大型语言模型自动生成代码片段对齐数据的增强方法，并通过两阶段训练策略结合程序对齐数据和代码片段对齐数据，显著提升代码翻译模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码翻译中，程序对齐数据提供完整语境但细粒度信号不足，代码片段对齐数据虽细粒度但数据有限，且以往研究多关注程序对齐数据的增强，缺乏对片段对齐数据的系统利用。

Method: 利用大型语言模型自动生成代码片段对齐数据，并设计简单有效的两阶段训练策略，先后利用程序对齐数据和自动生成的代码片段对齐数据进行模型训练。

Result: 在TransCoder-test数据集上的实验表明，结合自动生成的代码片段对齐数据和两阶段训练方法，模型性能有稳定提升，最大pass@k提升3.78%。

Conclusion: 融合程序对齐和代码片段对齐数据并采用两阶段训练策略，可以提升代码翻译模型的效果，自动生成片段对齐数据是一种有效增强手段。

Abstract: Code translation aims to translate the code from its source language to the
target language and is used in various software development scenarios. Recent
developments in Large Language Models (LLMs) have showcased their capabilities
in code translation, and parallel corpora play a crucial role in training
models for code translation. Parallel corpora can be categorized into
program-alignment (PA) and snippet-alignment (SA) data. Although PA data has
complete context and is suitable for semantic alignment learning, it may not
provide adequate fine-grained training signals due to its extended length,
while the brevity of SA data enables more fine-grained alignment learning. Due
to limited parallel corpora, researchers explore several augmentation methods
for code translation. Previous studies mainly focus on augmenting PA data. In
this paper, we propose a data augmentation method that leverages LLMs to
generate SA data automatically. To fully leverage both PA data and SA data, we
explore a simple yet effective two-stage training strategy, which consistently
enhances model performance compared to fine-tuning solely on PA data.
Experiments on TransCoder-test demonstrate that our augmented SA data combined
with the two-stage training approach yields consistent improvements over the
baseline, achieving a maximum gain of 3.78% on pass@k.

</details>


### [54] [Assessing Coherency and Consistency of Code Execution Reasoning by Large Language Models](https://arxiv.org/abs/2510.15079)
*Changshu Liu,Yang Chen,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: 本文提出了CES任务用于评估大型语言模型(LLMs)在模拟程序执行及相关推理能力，重点衡量执行的一致性和变量预测的正确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在通过推理捷径、幻觉或数据泄露产生的伪正确预测，难以全面反映LLMs在程序执行模拟中的真实推理能力。

Method: 引入执行模拟中的连贯性概念，区分预测变量值是否符合常识执行逻辑，同时设计新的指标衡量不同测试路径覆盖下的推理一致性。通过在16个LLMs上测试，包括三种推理型LLM，比较其输入输出的正确性和连贯性。

Result: 大多数LLMs在程序执行模拟中的连贯性达到81.42%，但仅46.92%预测输出正确，且存在大量自然语言捷径导致的推理不一致。推理表现多为随机或弱一致性，表明缺乏路径敏感的程序分析能力。LLMs在调试任务中主要依赖模式匹配和语言捷径，缺少执行推理。

Conclusion: 当前LLMs尚难通过真实执行推理解决复杂程序分析和调试任务，CES可用于识别伪成功情况，帮助提升模型的泛化和推理能力。

Abstract: This paper proposes CES, a task to evaluate the abilities of LLMs in
simulating program execution and using that reasoning in programming tasks.
Besides measuring the correctness of variable predictions during execution
simulation, CES introduces the notion of coherence to determine whether the
simulation complies with commonsense execution logic, even if the predicted
values along the simulations are incorrect. This enables CES to rule out
suspiciously correct output predictions due to reasoning shortcuts,
hallucinations, or potential data leakage. CES also introduces a novel metric
to measure reasoning consistency across tests with the same or different prime
path coverage in a spectrum: strong, weak, and random. Evaluating 16 LLMs
(including three reasoning LLMs) using CES indicates 81.42% coherent execution
simulation on HumanEval, 46.92% and 53.08% of which result in correct and
incorrect output predictions. Frontier LLMs such as GPT-4 and DeepSeek-R1 have
the most incoherent execution reasoning, mostly due to natural language
shortcuts. Despite relatively coherent execution simulation, LLMs' reasoning
performance across different tests is inconsistent, mostly random (48.87%) or
weak (45.37%), potentially explaining their weakness in programming tasks that
require path-sensitive program analysis to succeed. We also compare CES with
bug prediction/localization/repair, which intuitively requires control- and
data-flow awareness. We observe that LLMs barely incorporate execution
reasoning into their analysis for bug-related tasks, and their success is
primarily due to inherent abilities in pattern matching or natural language
shortcuts, if not data leakage. Without reasoning, there is a threat to the
generalizability of LLMs in dealing with unseen bugs or patterns in different
contexts. CES can be used to vet the suspicious success of LLMs in these tasks
systematically.

</details>


### [55] [Community Engagement and the Lifespan of Open-Source Software Projects](https://arxiv.org/abs/2510.15408)
*Mohit,Kuljit Kaur Chahal*

Main category: cs.SE

TL;DR: 本文定义并量化开源软件项目中的社区参与（CE），分析其对项目动态（发布、提交、分支）和寿命的影响。


<details>
  <summary>Details</summary>
Motivation: 开源项目依赖社区参与维持长期活力，但社区参与对项目动态和寿命的具体影响尚未充分研究。

Method: 通过分析33,946个GitHub仓库，使用每月问题、评论、观察者、点赞等指标定义社区参与，利用非参数检验和相关性分析评估其与项目动态和寿命的关系。

Result: 社区参与指标与项目动态显著相关，尤其在高度参与项目中体现明显。寿命方面，年轻项目社区参与率最高，随时间下降，但少数长期项目维持高活跃度。初期的参与爆发对项目建立关键，持续的高参与促进极长寿命。主动问题参与影响随年龄增长增强，消极关注影响下降。

Conclusion: 社区参与动态驱动开源项目寿命和发展，本文验证的指标提供了理解不同社区活动模式如何助力项目持久性的深刻见解。

Abstract: Open-source software (OSS) projects depend on community engagement (CE) for
longevity. However, CE's quantifiable impact on project dynamics and lifespan
is underexplored. Objectives: This study defines CE in OSS, identifies key
metrics, and evaluates their influence on project dynamics (releases, commits,
branches) and lifespan. Methods: We analyzed 33,946 GitHub repositories,
defining and operationalizing CE with validated per-month metrics (issues,
comments, watchers, stargazers). Non-parametric tests and correlations assessed
relationships with project dynamics and lifespan across quartiles. Results: CE
metrics significantly associate with project dynamics, with stronger
correlations in highly engaged projects. For lifespan, a complex pattern
emerged: per-month CE rates are highest in younger projects, declining with
age. Yet, a subset of long-lived projects maintains exceptionally high
activity. Initial CE bursts appear crucial for establishment, while sustained
high engagement drives extreme longevity. Active issue engagement's influence
intensifies with age, but passive attention's declines. Conclusion: CE
dynamically drives OSS project longevity and development. Our findings
establish validated CE metrics and offer deeper insights into how diverse
community activity patterns contribute to project longevity.

</details>


### [56] [Selecting and Combining Large Language Models for Scalable Code Clone Detection](https://arxiv.org/abs/2510.15480)
*Muslim Chochlov,Gul Aftab Ahmed,James Vincent Patten,Yuanhua Han,Guoxian Lu,David Gregg,Jim Buckley*

Main category: cs.SE

TL;DR: 本文研究了大规模代码克隆检测中大语言模型（LLMs）的选择与集成效果，发现没有单一最佳模型，但集成方法能显著提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 代码克隆检测面临知识产权风险及安全漏洞问题，现有方法难以高效检测多样化克隆，尤其是分化克隆。大语言模型的快速发展为克隆检测提供新思路，但如何选择最优模型及利用集成优化效果仍未明确。

Method: 筛选了76个LLMs，挑选出适合大规模克隆检测的候选模型，在两个工业公开数据集BigCloneBench及商业大规模数据集上评测。分析了模型特征如嵌入尺寸、词汇表大小及训练数据对性能的影响。随后探索了多模型集成方法，比较不同分数归一化和集成策略（最大值、求和、平均）对效果的提升。

Result: 未发现最佳单一模型，但CodeT5+110M、CuBERT和SPTCode表现较好。较小嵌入尺寸及针对性数据集有助模型表现。在商业数据集上，CodeT5+110M精度达39.71%，是CodeBERT的两倍。集成方法最高达46.91%精度，显著优于单模型，且最大值或求和集成策略优于平均。

Conclusion: 大语言模型在代码克隆检测中表现优异，但无单一最佳模型。通过合理选择模型特征和有效集成，可以显著提升检测精度。集成方案尤其适用于处理规模更大的数据集，推荐采用分数归一化及最大化或求和集成策略。

Abstract: Source code clones pose risks ranging from intellectual property violations
to unintended vulnerabilities. Effective and efficient scalable clone
detection, especially for diverged clones, remains challenging. Large language
models (LLMs) have recently been applied to clone detection tasks. However, the
rapid emergence of LLMs raises questions about optimal model selection and
potential LLM-ensemble efficacy.
  This paper addresses the first question by identifying 76 LLMs and filtering
them down to suitable candidates for large-scale clone detection. The
candidates were evaluated on two public industrial datasets, BigCloneBench, and
a commercial large-scale dataset. No uniformly 'best-LLM' emerged, though
CodeT5+110M, CuBERT and SPTCode were top-performers. Analysis of LLM-candidates
suggested that smaller embedding sizes, smaller tokenizer vocabularies and
tailored datasets are advantageous. On commercial large-scale dataset a
top-performing CodeT5+110M achieved 39.71\% precision: twice the precision of
previously used CodeBERT.
  To address the second question, this paper explores ensembling of the
selected LLMs: effort-effective approach to improving effectiveness. Results
suggest the importance of score normalization and favoring ensembling methods
like maximum or sum over averaging. Also, findings indicate that ensembling
approach can be statistically significant and effective on larger datasets: the
best-performing ensemble achieved even higher precision of 46.91\% over
individual LLM on the commercial large-scale code.

</details>


### [57] [An Experimental Study of Real-Life LLM-Proposed Performance Improvements](https://arxiv.org/abs/2510.15494)
*Lirong Yi,Gregory Gay,Philipp Leitner*

Main category: cs.SE

TL;DR: 本文研究了大型语言模型（LLM）生成高效代码的能力，通过65个真实Java任务的实验，LLM生成的代码多情况下提升了性能，但仍不及人类开发者的优化方案。


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否能生成执行速度快的代码，填补现有研究中关注代码质量和功能而忽略性能提升的问题。

Method: 收集65个具有显著速度提升的Java任务，使用两款领先LLM配合四种提示生成补丁，通过自动化流程和基准测试对比LLM补丁、基线和人类开发者方案。

Result: LLM生成的优化代码在大多数情况下优于基线，但整体性能仍显著落后于人类方案；约三分之二代码优化思路与人类相似，三分之一提出原创思路但只有少数带来显著性能提升。

Conclusion: LLM能在一定程度上优化代码性能，且能产生部分原创优化方法，但其优化效果尚不及人类开发者，提示需结合人类经验以达最佳性能提升。

Abstract: Large Language Models (LLMs) can generate code, but can they generate fast
code? In this paper, we study this question using a dataset of 65 real-world
tasks mined from open-source Java programs. We specifically select tasks where
developers achieved significant speedups, and employ an automated pipeline to
generate patches for these issues using two leading LLMs under four prompt
variations. By rigorously benchmarking the results against the baseline and
human-authored solutions, we demonstrate that LLM-generated code indeed
improves performance over the baseline in most cases. However, patches proposed
by human developers outperform LLM fixes by a statistically significant margin,
indicating that LLMs often fall short of finding truly optimal solutions. We
further find that LLM solutions are semantically identical or similar to the
developer optimization idea in approximately two-thirds of cases, whereas they
propose a more original idea in the remaining one-third. However, these
original ideas only occasionally yield substantial performance gains.

</details>


### [58] [Enhancing Code Review through Fuzzing and Likely Invariants](https://arxiv.org/abs/2510.15512)
*Wachiraphan Charoenwet,Patanamon Thongtanunam,Van-Thuan Pham,Christoph Treude*

Main category: cs.SE

TL;DR: 本文提出FuzzSight框架，结合模糊测试和推测不变量分析，辅助代码审查阶段发现潜在错误和漏洞。


<details>
  <summary>Details</summary>
Motivation: 传统手动代码审查主要依赖静态检查，忽略程序动态行为，导致难以发现非崩溃类异常行为和潜在缺陷。

Method: 利用模糊测试产生的非崩溃输入，检测程序在特定位置的动态行为（推测不变量）变化，从而识别不同程序版本间的行为差异，辅助发现问题代码块。

Result: FuzzSight在24小时模糊测试中标记出75%的回归缺陷和80%的漏洞，性能优于静态应用安全测试(SAST)，检测率提升10倍且误报率更低。

Conclusion: 结合模糊测试与动态行为分析的FuzzSight提升了代码审查的动态洞察能力，有效弥补静态审查的不足，增强早期缺陷检测能力。

Abstract: Many software projects employ manual code review to gatekeep defects and
vulnerabilities in the code before integration. However, reviewers often work
under time pressure and rely primarily on static inspection, leaving the
dynamic aspects of the program unexplored. Dynamic analyses could reveal such
behaviors, but they are rarely integrated into reviews. Among them, fuzzing is
typically applied later to uncover crashing bugs. Yet its ability to exercise
code with diverse inputs makes it promising for exposing non-crashing, but
unexpected, behaviors earlier. Still, without suitable mechanisms to analyze
program behaviors, the rich data produced during fuzzing remains inaccessible
to reviewers, limiting its practical value in this context.
  We hypothesize that unexpected variations in program behaviors could signify
potential bugs. The impact of code changes can be automatically captured at
runtime. Representing program behavior as likely invariants, dynamic properties
consistently observed at specific program points, can provide practical signals
of behavioral changes. Such signals offer a way to distinguish between intended
changes and unexpected behavioral shifts from code changes.
  We present FuzzSight, a framework that leverages likely invariants from
non-crashing fuzzing inputs to highlight behavioral differences across program
versions. By surfacing such differences, it provides insights into which code
blocks may need closer attention. In our evaluation, FuzzSight flagged 75% of
regression bugs and up to 80% of vulnerabilities uncovered by 24-hour fuzzing.
It also outperformed SAST in identifying buggy code blocks, achieving ten times
higher detection rates with fewer false alarms. In summary, FuzzSight
demonstrates the potential and value of leveraging fuzzing and invariant
analysis for early-stage code review, bridging static inspection with dynamic
behavioral insights.

</details>


### [59] [Colepp: uma ferramenta multiplataforma para coleta de dados de dispositivos vestiveis](https://arxiv.org/abs/2510.15565)
*Vinicius Moraes de Jesus,Andre Georghton Cardoso Pacheco*

Main category: cs.SE

TL;DR: 提出了一种名为Colepp的开源跨平台工具，能够同步采集多种可穿戴设备的心率和运动数据，方便生成定制化的、真实环境下的数据集，支持人体活动识别和心率估计等应用。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏大规模高质量公开数据集，且数据采集条件难以控制，限制了健壮算法的开发。

Method: 设计了Colepp系统，利用智能手机作为中心集线器，从Polar H10胸带和Wear OS智能手表收集心率（ECG和PPG）及运动（加速度和陀螺仪）数据，通过自定义同步协议确保数据同步，并导出CSV格式数据集。

Result: 工具有效地生成了一致且同步的信号数据，证明了其在实际数据采集中的可用性和可靠性。

Conclusion: Colepp为多设备数据采集和同步提供了开源解决方案，促进了真实环境下生理和运动数据的研究与应用发展。

Abstract: The widespread adoption of wearable devices such as smartwatches and fitness
trackers has fueled the demand for reliable physiological and movement data
collection tools. However, challenges such as limited access to large,
high-quality public datasets and a lack of control over data collection
conditions hinder the development of robust algorithms. This work presents
Colepp, an open-source, cross-platform tool designed to collect and synchronize
data from multiple wearable devices, including heart rate (via ECG and PPG) and
motion signals (accelerometer and gyroscope). The system integrates a
smartphone as a central hub, receiving data from a Polar H10 chest strap and a
Wear OS smartwatch, and exporting synchronized datasets in CSV format. Through
a custom synchronization protocol and user-friendly interface, Colepp
facilitates the generation of customizable, real-world datasets suitable for
applications such as human activity recognition and heart rate estimation. A
use case shows the effectiveness of the tool in producing consistent and
synchronized signals.

</details>


### [60] [Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework](https://arxiv.org/abs/2510.15585)
*Dr Simon Thorne,Dr Advait Sarkar*

Main category: cs.SE

TL;DR: 本文提出将测试驱动开发（TDD）方法与大语言模型（LLM）结合，用于提升生成代码和电子表格逻辑的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在生成代码和公式时存在幻觉、逻辑不一致和语法错误问题，尤其在金融建模和科学计算等高风险领域影响严重。

Method: 提出一个结构化研究框架，采用“先测试”理念，通过TDD为LLM生成的输出提供技术约束和认知支持，涵盖多种编程环境，并设计了实验方案和评价指标。

Result: 框架预计能引导LLM生成更准确、可验证、易理解的解决方案，增强用户计算思维、提示工程技能和参与度，特别帮助缺乏编程训练的电子表格用户。

Conclusion: 通过推广测试驱动思维和方法，促进LLM在教育与专业开发中的负责任、可靠应用，作者呼吁合作完善和实证评估该框架。

Abstract: Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for
generating both traditional software code and spreadsheet logic. Despite their
impressive generative capabilities, these models frequently exhibit critical
issues such as hallucinations, subtle logical inconsistencies, and syntactic
errors, risks particularly acute in high stakes domains like financial
modelling and scientific computations, where accuracy and reliability are
paramount. This position paper proposes a structured research framework that
integrates the proven software engineering practice of Test-Driven Development
(TDD) with Large Language Model (LLM) driven generation to enhance the
correctness of, reliability of, and user confidence in generated outputs. We
hypothesise that a "test first" methodology provides both technical constraints
and cognitive scaffolding, guiding LLM outputs towards more accurate,
verifiable, and comprehensible solutions. Our framework, applicable across
diverse programming contexts, from spreadsheet formula generation to scripting
languages such as Python and strongly typed languages like Rust, includes an
explicitly outlined experimental design with clearly defined participant
groups, evaluation metrics, and illustrative TDD based prompting examples. By
emphasising test driven thinking, we aim to improve computational thinking,
prompt engineering skills, and user engagement, particularly benefiting
spreadsheet users who often lack formal programming training yet face serious
consequences from logical errors. We invite collaboration to refine and
empirically evaluate this approach, ultimately aiming to establish responsible
and reliable LLM integration in both educational and professional development
practices.

</details>


### [61] [Interact and React: Exploring Gender Patterns in Development and the Impact on Innovation and Robustness of a User Interface Tool](https://arxiv.org/abs/2510.15642)
*Sian Brooke*

Main category: cs.SE

TL;DR: 本文研究了React项目中女性参与对软件开发模式的影响，发现女性贡献显著促进了功能增强和依赖管理，从而提升了软件的创新性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 虽然开源软件设计中常提及女性的存在，但很少关注女性参与如何根本改变开发模式。本研究旨在探讨性别多样性尤其是女性参与对软件开发的影响。

Method: 以拥有活跃贡献者社区的JavaScript库React为研究对象，分析了11年间性别在鲁棒性、创新性指标以及主要版本发布前的贡献模式差异。

Result: 研究发现排除女性对软件开发有害，女性在功能增强和依赖管理方面的贡献显著高于男性。

Conclusion: 增加性别多样性特别是女性参与，可以促进软件开发的包容性、创新性和稳健性，对开源软件项目具有重要意义。

Abstract: In open-source software design, the inclusion of women is often highlighted
simply to remind programmers that women exist. Yet, little attention is given
to how greater gender diversity, specifically women's participation, could
fundamentally alter development patterns. To understand the potential impact of
gender inclusion, this study investigates React, a widely used JavaScript
library for building user interfaces with an active contributor community. I
examine gender differences in metrics of robustness and innovation, as well as
shifts in contribution patterns leading up to major version releases over 11
years of the React project. My results show that the exclusion of women is
detrimental to software as women contribute significantly more to feature
enhancement and dependency management. By exploring how gender influences
innovation and robustness in the development of React, the study offers
critical insights into how increasing gender diversity could lead to more
inclusive, innovative, and robust software.

</details>


### [62] [MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing](https://arxiv.org/abs/2510.15690)
*Shiwen Ou,Yuwei Li,Lu Yu,Chengkun Wei,Tingke Wen,Qiangpu Chen,Yu Chen,Haizhi Tang,Zulie Pan*

Main category: cs.SE

TL;DR: MirrorFuzz是一种自动API模糊测试工具，针对深度学习框架中的共享漏洞进行检测，提升了代码覆盖率并发现了大量新漏洞。


<details>
  <summary>Details</summary>
Motivation: 深度学习框架中存在许多相似API，存在共享漏洞风险，而现有研究对跨框架API共性和风险探索有限。

Method: MirrorFuzz通过收集历史漏洞数据，匹配相似API，利用大语言模型合成代码触发漏洞三阶段方法进行模糊测试。

Result: 在TensorFlow和PyTorch中分别提升代码覆盖率39.92%和98.20%，共发现315个漏洞，262个为新漏洞，已修复80个并赋予CNVD编号。

Conclusion: MirrorFuzz有效发现深度学习框架中共享的API漏洞，提高了漏洞检测能力和框架安全性。

Abstract: Deep learning (DL) frameworks serve as the backbone for a wide range of
artificial intelligence applications. However, bugs within DL frameworks can
cascade into critical issues in higher-level applications, jeopardizing
reliability and security. While numerous techniques have been proposed to
detect bugs in DL frameworks, research exploring common API patterns across
frameworks and the potential risks they entail remains limited. Notably, many
DL frameworks expose similar APIs with overlapping input parameters and
functionalities, rendering them vulnerable to shared bugs, where a flaw in one
API may extend to analogous APIs in other frameworks. To address this
challenge, we propose MirrorFuzz, an automated API fuzzing solution to discover
shared bugs in DL frameworks. MirrorFuzz operates in three stages: First,
MirrorFuzz collects historical bug data for each API within a DL framework to
identify potentially buggy APIs. Second, it matches each buggy API in a
specific framework with similar APIs within and across other DL frameworks.
Third, it employs large language models (LLMs) to synthesize code for the API
under test, leveraging the historical bug data of similar APIs to trigger
analogous bugs across APIs. We implement MirrorFuzz and evaluate it on four
popular DL frameworks (TensorFlow, PyTorch, OneFlow, and Jittor). Extensive
evaluation demonstrates that MirrorFuzz improves code coverage by 39.92\% and
98.20\% compared to state-of-the-art methods on TensorFlow and PyTorch,
respectively. Moreover, MirrorFuzz discovers 315 bugs, 262 of which are newly
found, and 80 bugs are fixed, with 52 of these bugs assigned CNVD IDs.

</details>


### [63] [EASELAN: An Open-Source Framework for Multimodal Biosignal Annotation and Data Management](https://arxiv.org/abs/2510.15767)
*Rathi Adarshi Rammohan,Moritz Meier,Dennis Küster,Tanja Schultz*

Main category: cs.SE

TL;DR: 本文介绍了EASELAN注释框架，旨在简化多模态和生物信号数据集的注释工作流程，支持从文件准备到版本控制的各个阶段，并已成功应用于人类日常活动的生物信号采集。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和自适应认知系统的发展，融合模型对大量丰富标注的多模态数据需求上升，尤其包括多种生物信号，这带来了注释复杂性的增加。

Method: 基于ELAN工具，EASELAN增加了支持多生物信号通道设置、GitHub版本控制和简化后处理的新组件，实现了从注释文件准备到导出分析的一体化工作流程。

Result: EASELAN成功应用于DFG资助的日常活动科研项目中的高维生物信号采集，支持复杂多模态数据的注释并配套发布了注释数据集和开源代码。

Conclusion: EASELAN提升了多模态生物信号数据集的注释效率和管理便利性，有助于促进相关领域的数据收集和机器学习研究。

Abstract: Recent advancements in machine learning and adaptive cognitive systems are
driving a growing demand for large and richly annotated multimodal data. A
prominent example of this trend are fusion models, which increasingly
incorporate multiple biosignals in addition to traditional audiovisual
channels. This paper introduces the EASELAN annotation framework to improve
annotation workflows designed to address the resulting rising complexity of
multimodal and biosignals datasets. It builds on the robust ELAN tool by adding
new components tailored to support all stages of the annotation pipeline: From
streamlining the preparation of annotation files to setting up additional
channels, integrated version control with GitHub, and simplified
post-processing. EASELAN delivers a seamless workflow designed to integrate
biosignals and facilitate rich annotations to be readily exported for further
analyses and machine learning-supported model training. The EASELAN framework
is successfully applied to a high-dimensional biosignals collection initiative
on human everyday activities (here, table setting) for cognitive robots within
the DFG-funded Collaborative Research Center 1320 Everyday Activity Science and
Engineering (EASE). In this paper we discuss the opportunities, limitations,
and lessons learned when using EASELAN for this initiative. To foster research
on biosignal collection, annotation, and processing, the code of EASELAN is
publicly available(https://github.com/cognitive-systems-lab/easelan), along
with the EASELAN-supported fully annotated Table Setting Database.

</details>


### [64] [Towards Supporting Open Source Library Maintainers with Community-Based Analytics](https://arxiv.org/abs/2510.15794)
*Rachna Raj,Diego Elias Costa*

Main category: cs.SE

TL;DR: 本论文通过对10个流行Java开源库及其50个依赖项目的实证研究，发现仅约16%的API方法被实际使用，且其中只有74%被测试覆盖。


<details>
  <summary>Details</summary>
Motivation: 维护者缺乏关于其开源库API实际使用情况的持续反馈，难以做出更有效的维护和测试决策。

Method: 提出基于社区的分析方法，统计开源库API的使用情况，并设计两个评估测试覆盖的指标，同时通过问卷调查评估其实用价值。

Result: 发现库API方法中只有部分被依赖项目使用，且测试覆盖不足，提出的指标有助于开发者合理调整测试策略。

Conclusion: 社区分析数据能为开源库维护者提供有价值的使用反馈，推动更有效的测试和维护决策，提升库的稳定性和演进质量。

Abstract: Open-source software (OSS) is a pillar of modern software development. Its
success depends on the dedication of maintainers who work constantly to keep
their libraries stable, adapt to changing needs, and support a growing
community. Yet, they receive little to no continuous feedback on how the
projects that rely on their libraries actually use their APIs. We believe that
gaining these insights can help maintainers make better decisions, such as
refining testing strategies, understanding the impact of changes, and guiding
the evolution of their libraries more effectively. We propose the use of
community-based analytics to analyze how an OSS library is used across its
dependent ecosystem. We conduct an empirical study of 10 popular Java libraries
and each with their respective dependent ecosystem of 50 projects. Our results
reveal that while library developers offer a wide range of API methods, only
16% on average are actively used by their dependent ecosystem. Moreover, only
74% of the used API methods are partially or fully covered by their library
test suite. We propose two metrics to help developers evaluate their test suite
according to the APIs used by their community, and we conduct a survey on
open-source practitioners to assess the practical value of these insights in
guiding maintenance decisions.

</details>
