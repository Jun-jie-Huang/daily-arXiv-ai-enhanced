<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 84]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating Long-Term Memory for Long-Context Question Answering](https://arxiv.org/abs/2510.23730)
*Alessandra Terranova,Björn Ross,Alexandra Birch*

Main category: cs.CL

TL;DR: 该论文评估了多种记忆增强方法在长上下文对话任务中的表现，发现合理的记忆架构能够显著减少计算资源消耗并维持较高准确率。


<details>
  <summary>Details</summary>
Motivation: 为了让大语言模型实现真正的对话连续性并从经验中学习，研究了不同类型的记忆系统，探究它们在长上下文对话任务中的效果。

Method: 使用LoCoMo基准对多种记忆增强方法进行系统评估，包括全上下文提示、基于检索的语义记忆、情景记忆（通过上下文学习）和程序记忆（通过提示优化）。

Result: 记忆增强方法能够减少90%以上的token使用，同时保持竞争力的准确率。小型基础模型从基于检索生成（RAG）受益最大，而强大的推理模型则通过情景学习和更复杂的语义记忆获得提升。

Conclusion: 记忆架构的复杂性应与模型能力匹配，不同规模和能力的模型应采用不同的记忆系统以实现最优性能，情景记忆特别有助于模型认识自身知识的局限性。

Abstract: In order for large language models to achieve true conversational continuity
and benefit from experiential learning, they need memory. While research has
focused on the development of complex memory systems, it remains unclear which
types of memory are most effective for long-context conversational tasks. We
present a systematic evaluation of memory-augmented methods using LoCoMo, a
benchmark of synthetic long-context dialogues annotated for question-answering
tasks that require diverse reasoning strategies. We analyse full-context
prompting, semantic memory through retrieval-augmented generation and agentic
memory, episodic memory through in-context learning, and procedural memory
through prompt optimization. Our findings show that memory-augmented approaches
reduce token usage by over 90% while maintaining competitive accuracy. Memory
architecture complexity should scale with model capability, with small
foundation models benefitting most from RAG, and strong instruction-tuned
reasoning model gaining from episodic learning through reflections and more
complex agentic semantic memory. In particular, episodic memory can help LLMs
recognise the limits of their own knowledge.

</details>


### [2] [BitSkip: An Empirical Analysis of Quantization and Early Exit Composition](https://arxiv.org/abs/2510.23766)
*Ramshankar Bhuvaneswaran,Handan Liu*

Main category: cs.CL

TL;DR: 本文提出了BitSkip框架，研究极端量化和动态路由技术的复合效果，发现简单的8位量化模型性能优于复杂4位模型，且接近全精度基线。


<details>
  <summary>Details</summary>
Motivation: 现有高效大语言模型技术复杂且组合效果不明，本研究探索其交互作用。

Method: 设计BitSkip混合架构，系统地评估不同量化位数和Hadamard变换的影响。

Result: 8位无Hadamard变换模型（BitSkip-V1）性能最佳，超越复杂方案且性能接近全精度。Hadamard变换反而导致训练不稳定和性能大幅下降。

Conclusion: 简化量化设计有利于模型性能和稳定性，BitSkip-V1实现了速度与质量的最佳平衡。

Abstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly
complex techniques like extreme quantization and dynamic routing. While
individual benefits of these methods are well-documented, their compositional
effects remain poorly understood. This paper introduces BitSkip, a hybrid
architectural framework for systematically exploring these interactions.
Counter-intuitively, our findings reveal that a simple 8-bit quantized model
without Hadamard transform (BitSkip-V1) not only outperforms its more complex
4-bit and Hadamard-enhanced counterparts but also competes the full-precision
baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard
transforms, even at 8-bit precision, catastrophically degraded performance by
over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe
demonstrates superior early-exit characteristics, with layer 18 providing
optimal 32.5% speed gain for minimal 4% quality loss.

</details>


### [3] [Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language](https://arxiv.org/abs/2510.23828)
*Mena Attia,Aashiq Muhamed,Mai Alkhamissi,Thamar Solorio,Mona Diab*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型处理文化特定语言的能力，尤其是理解和使用包含地方知识的比喻表达。


<details>
  <summary>Details</summary>
Motivation: 比喻语言作为文化细微差别和地方知识的代理，用于衡量模型的文化推理能力。

Method: 设计了阿拉伯语和英语的比喻语言理解、语用和内涵解释任务，评估了22个大型语言模型在埃及阿拉伯语成语、多方言阿拉伯谚语和英语谚语上的表现。

Result: 发现阿拉伯谚语的准确率比英语谚语低4.29%，埃及成语比阿拉伯谚语低10.28%；语用任务准确率比理解任务低14.07%，但在提供上下文后提升了10.66%；模型在内涵意义上的表现较弱，最高与人工注释一致率为85.58%。

Conclusion: 大型语言模型虽能理解比喻意义，但在恰当使用方面存在困难。比喻语言是文化推理的有效诊断工具。研究还发布了首个用于理解和语用评估的埃及阿拉伯语成语数据集Kinayat。

Abstract: We present a comprehensive evaluation of the ability of large language models
(LLMs) to process culturally grounded language, specifically to understand and
pragmatically use figurative expressions that encode local knowledge and
cultural nuance. Using figurative language as a proxy for cultural nuance and
local knowledge, we design evaluation tasks for contextual understanding,
pragmatic use, and connotation interpretation in Arabic and English. We
evaluate 22 open- and closed-source LLMs on Egyptian Arabic idioms,
multidialectal Arabic proverbs, and English proverbs. Our results show a
consistent hierarchy: the average accuracy for Arabic proverbs is 4.29% lower
than for English proverbs, and performance for Egyptian idioms is 10.28% lower
than for Arabic proverbs. For the pragmatic use task, accuracy drops by 14.07%
relative to understanding, though providing contextual idiomatic sentences
improves accuracy by 10.66%. Models also struggle with connotative meaning,
reaching at most 85.58% agreement with human annotators on idioms with 100%
inter-annotator agreement. These findings demonstrate that figurative language
serves as an effective diagnostic for cultural reasoning: while LLMs can often
interpret figurative meaning, they face challenges in using it appropriately.
To support future research, we release Kinayat, the first dataset of Egyptian
Arabic idioms designed for both figurative understanding and pragmatic use
evaluation.

</details>


### [4] [How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse](https://arxiv.org/abs/2510.23842)
*Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani*

Main category: cs.CL

TL;DR: 该论文收集了美国手语STEM领域的动态对话动作捕捉数据，分析了对话语境下手语动作的时空变化及简化特征，并评估了手语嵌入模型对专业词汇的识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有手语模型多基于口译或孤立词汇，忽视自然对话中手语的变化和适应性，尤其在教育场景中，教师和学生使用的新词汇带来了额外挑战。

Method: 收集美国手语STEM领域的动作捕捉数据，比较双人互动手语、单人讲座手语和口译手语，通过连续的运动学特征解析对话特异的同步性和个体动作简化，分析STEM术语重复出现时手语的时空变化，并评估手语嵌入模型识别专业词汇和捕捉同步性的表现。

Result: 发现对话中的手语动作比孤立手语时长缩短24.6%-44.6%，且在单人讲座中无此缩短现象；通过模型评估展示了参与者随着时间推移的动作同步程度；揭示了手语动作在对话中的时空变化特点。

Conclusion: 研究结合语言学和计算建模，阐释了语用因素如何影响手语表达及其技术表示，为增强手语技术对动态交流的适应性提供了理论和数据支持。

Abstract: Most state-of-the-art sign language models are trained on interpreter or
isolated vocabulary data, which overlooks the variability that characterizes
natural dialogue. However, human communication dynamically adapts to contexts
and interlocutors through spatiotemporal changes and articulation style. This
specifically manifests itself in educational settings, where novel vocabularies
are used by teachers, and students. To address this gap, we collect a motion
capture dataset of American Sign Language (ASL) STEM (Science, Technology,
Engineering, and Mathematics) dialogue that enables quantitative comparison
between dyadic interactive signing, solo signed lecture, and interpreted
articles. Using continuous kinematic features, we disentangle dialogue-specific
entrainment from individual effort reduction and show spatiotemporal changes
across repeated mentions of STEM terms. On average, dialogue signs are
24.6%-44.6% shorter in duration than the isolated signs, and show significant
reductions absent in monologue contexts. Finally, we evaluate sign embedding
models on their ability to recognize STEM signs and approximate how entrained
the participants become over time. Our study bridges linguistic analysis and
computational modeling to understand how pragmatics shape sign articulation and
its representation in sign language technologies.

</details>


### [5] [Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content](https://arxiv.org/abs/2510.24438)
*Abdullah Mushtaq,Rafay Naeem,Ezieddin Elmahjub,Ibrahim Ghaznavi,Shawqi Al-Maliki,Mohamed Abdallah,Ala Al-Fuqaha,Junaid Qadir*

Main category: cs.CL

TL;DR: 评估了GPT-4o、Ansari AI和Fanar在伊斯兰指导文本中的表现，发现GPT-4o表现最好，但各模型仍难以保证内容和引用的绝对准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在伊斯兰指导中应用广泛，但存在误引经典、法学误用及文化不一致风险，需评估其表现。

Method: 基于真实伊斯兰博客文本，采用双代理框架：量化代理进行引文核验及六维评分，质性代理进行五维度对比评价。

Result: GPT-4o在伊斯兰准确度和引用评分最高，Ansari AI次之，Fanar表现较弱；模型整体尚未达到完全准确与可靠。

Conclusion: 强调建立以穆斯林视角为核心的社区驱动基准测试，推动在宗教、医学、法律等关键领域的可靠AI发展。

Abstract: Large language models are increasingly used for Islamic guidance, but risk
misquoting texts, misapplying jurisprudence, or producing culturally
inconsistent responses. We pilot an evaluation of GPT-4o, Ansari AI, and Fanar
on prompts from authentic Islamic blogs. Our dual-agent framework uses a
quantitative agent for citation verification and six-dimensional scoring (e.g.,
Structure, Islamic Consistency, Citations) and a qualitative agent for
five-dimensional side-by-side comparison (e.g., Tone, Depth, Originality).
GPT-4o scored highest in Islamic Accuracy (3.93) and Citation (3.38), Ansari AI
followed (3.68, 3.32), and Fanar lagged (2.76, 1.82). Despite relatively strong
performance, models still fall short in reliably producing accurate Islamic
content and citations -- a paramount requirement in faith-sensitive writing.
GPT-4o had the highest mean quantitative score (3.90/5), while Ansari AI led
qualitative pairwise wins (116/200). Fanar, though trailing, introduces
innovations for Islamic and Arabic contexts. This study underscores the need
for community-driven benchmarks centering Muslim perspectives, offering an
early step toward more reliable AI in Islamic knowledge and other high-stakes
domains such as medicine, law, and journalism.

</details>


### [6] [CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection](https://arxiv.org/abs/2510.23845)
*Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi*

Main category: cs.CL

TL;DR: 本文提出了CRADLE BENCH，一个涵盖七种符合临床标准危机类型并包含时间标签的多面向危机检测基准，为语言模型检测精神健康危机提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 精神健康危机（如自杀意念、强奸、家庭暴力等）的检测对语言模型来说是一项关键但未充分探索的挑战，且未能及时识别会造成严重后果，因此需要一个全面且临床标准化的评估基准。

Method: 构建了涵盖七种危机类型并带时间标签的CRADLE BENCH基准，包含600个临床医生标注的评估示例和420个开发示例，以及约4000个通过多模型多数投票自动标注的训练样本。基于不同模型一致性程度，对六个危机检测模型进行微调训练。

Result: 通过多模型多数投票生成训练数据显著优于单模型标注，微调六个模型实现不同的一致性训练策略，提升危机检测的准确性和可靠性。

Conclusion: CRADLE BENCH为危机检测提供了一个多维度、临床标准的标注数据和评估框架，支持构建更为有效和可靠的精神健康危机语言模型检测工具。

Abstract: Detecting mental health crisis situations such as suicide ideation, rape,
domestic violence, child abuse, and sexual harassment is a critical yet
underexplored challenge for language models. When such situations arise during
user--model interactions, models must reliably flag them, as failure to do so
can have serious consequences. In this work, we introduce CRADLE BENCH, a
benchmark for multi-faceted crisis detection. Unlike previous efforts that
focus on a limited set of crisis types, our benchmark covers seven types
defined in line with clinical standards and is the first to incorporate
temporal labels. Our benchmark provides 600 clinician-annotated evaluation
examples and 420 development examples, together with a training corpus of
around 4K examples automatically labeled using a majority-vote ensemble of
multiple language models, which significantly outperforms single-model
annotation. We further fine-tune six crisis detection models on subsets defined
by consensus and unanimous ensemble agreement, providing complementary models
trained under different agreement criteria.

</details>


### [7] [Tongyi DeepResearch Technical Report](https://arxiv.org/abs/2510.24701)
*Tongyi DeepResearch Team,Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang*

Main category: cs.CL

TL;DR: Tongyi DeepResearch是一款面向长远、深度信息检索任务的自主代理大语言模型，通过端到端训练框架和自动化数据合成，实现高效推理和信息检索，表现出色并开源。


<details>
  <summary>Details</summary>
Motivation: 针对长周期、深度信息搜索任务需求，设计一种具备自主代理能力的大语言模型，提升复杂任务的推理和信息检索能力。

Method: 采用端到端训练框架，结合代理中期训练与后期训练，利用全自动、无需人工标注的数据合成流水线，设计定制环境以保证交互稳定性。

Result: 拥有305亿参数的模型，激活参数仅3.3亿，达成多项深度研究基准测试的最先进表现，包括多语言和多场景任务。

Conclusion: 该模型及训练框架实现了高效、稳定、可扩展的深层信息代理研究能力，且已开源，促进社区进一步发展。

Abstract: We present Tongyi DeepResearch, an agentic large language model, which is
specifically designed for long-horizon, deep information-seeking research
tasks. To incentivize autonomous deep research agency, Tongyi DeepResearch is
developed through an end-to-end training framework that combines agentic
mid-training and agentic post-training, enabling scalable reasoning and
information seeking across complex tasks. We design a highly scalable data
synthesis pipeline that is fully automatic, without relying on costly human
annotation, and empowers all training stages. By constructing customized
environments for each stage, our system enables stable and consistent
interactions throughout. Tongyi DeepResearch, featuring 30.5 billion total
parameters, with only 3.3 billion activated per token, achieves
state-of-the-art performance across a range of agentic deep research
benchmarks, including Humanity's Last Exam, BrowseComp, BrowseComp-ZH,
WebWalkerQA, xbench-DeepSearch, FRAMES and xbench-DeepSearch-2510. We
open-source the model, framework, and complete solutions to empower the
community.

</details>


### [8] [Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception](https://arxiv.org/abs/2510.23853)
*Yize Cheng,Arshia Soltani Moakhar,Chenrui Fan,Kazem Faghih,Parsa Hosseini,Wenxiao Wang,Soheil Feizi*

Main category: cs.CL

TL;DR: 本文提出了TicToc-v1测试集，研究大语言模型在多轮对话中缺乏时间感知的问题及其对工具调用决策的影响。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多轮对话中没有时间感知，导致工具调用决策不准确，影响与动态环境的交互效果。

Method: 构建包含显式时间戳的对话数据集TicToc-v1，采集人类偏好数据，将对话分为偏向重复使用工具和偏向新工具调用两类，评估模型在不同时间间隔下的表现。

Result: 没有时间信息时模型表现接近随机；加入时间戳后表现略有提升，尤其是大模型，但提升有限；简单的提示对齐方法效果有限。

Conclusion: 多轮对话中的时间感知对工具调用决策至关重要，需采用专门的训练后对齐方法提高模型与人类时间感知的匹配度。

Abstract: Large language model agents are increasingly used in multi-turn
conversational settings to interact with and execute tasks in dynamic
environments. However, a key limitation is their temporal blindness: they, by
default, operate with a stationary context, failing to account for the
real-world time elapsed between messages. This becomes a critical liability
when an agent must decide whether to invoke a tool based on how much time has
passed since the last observation. Without temporal awareness, agents often
either over-rely on previous context (skipping necessary tool calls), or
under-rely on it (unnecessarily repeating tool calls). To study this challenge,
we introduce TicToc-v1, a test set of multi-turn user-agent trajectories across
34 scenarios with varying time sensitivity. Each trajectory ends with a user
question, where the need for a tool call depends on the amount of time elapsed
since the last message. To give LLMs temporal context, we augment dialogue
messages with explicit timestamps, bridging the gap between static dialogue and
evolving environments. We then collected human preferences for these samples,
creating two subsets: one where humans preferred relying on the previous
observation (prefer-noTool), and another where they preferred a new tool call
(prefer-Tool). We evaluated how well LLM tool-calling decisions align with
human preferences under varying time intervals on TicToc-v1. Our analysis show
that without time information, most models perform only slightly better than
random, with the top alignment rate being just over 60%. While adding
timestamps leads to a slight improvement, particularly for larger models, the
improvement is modest, peaking at around 65%. We also show that naive,
prompt-based alignment have limited effectiveness. Our findings highlight the
need for specific post-training alignment to align multi-turn LLM tool use with
human temporal perception.

</details>


### [9] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://arxiv.org/abs/2510.23854)
*Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: 本文提出了Combo-Eval，一种结合多种现有方法的文本化数据库结果自然语言表现（NLR）生成评估方法，并发布了首个专用NLR基准数据集NLR-BIRD，显著提升了评估准确性与效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在将数据库查询结果转换为自然语言时，存在信息丢失和错误的问题，但相关的评估方法研究不足。

Method: 提出Combo-Eval评估方法，融合多种现有评估方式，优化评估的真实性，并减少25-61%的大语言模型调用次数，同时发布了用于NLR测试的NLR-BIRD数据集。

Result: 通过人工评估验证，Combo-Eval与人类判断的匹配度显著优于现有方法，适用于有无参考答案的多种场景。

Conclusion: Combo-Eval及NLR-BIRD为NLR生成评测提供了高效且准确的解决方案，促进了基于大语言模型的文表转码技术的发展。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL
technology bridges natural language (NL) questions and database (DB) querying.
The conversion of tabular DB results into NL representations (NLRs) enables the
chat-based interaction. Currently, NLR generation is typically handled by large
language models (LLMs), but information loss or errors in presenting tabular
results in NL remains largely unexplored. This paper introduces a novel
evaluation method - Combo-Eval - for judgment of LLM-generated NLRs that
combines the benefits of multiple existing methods, optimizing evaluation
fidelity and achieving a significant reduction in LLM calls by 25-61%.
Accompanying our method is NLR-BIRD, the first dedicated dataset for NLR
benchmarking. Through human evaluations, we demonstrate the superior alignment
of Combo-Eval with human judgments, applicable across scenarios with and
without ground truth references.

</details>


### [10] [OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning](https://arxiv.org/abs/2510.23870)
*Marianne Menglin Liu,Sai Ashish Somayajula,Syed Fahad Allam Shah,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: OraPlan-SQL是一种双语NL2SQL系统，在2025年Archer挑战赛中表现优异，执行准确率达55%以上，SQL有效性超99%。


<details>
  <summary>Details</summary>
Motivation: 针对复杂推理需求，提升自然语言到SQL的转换准确性和可靠性。

Method: 采用双智能体架构，包括规划者和SQL转换者。通过反馈驱动的元提示策略改进单一规划者，加入实体链接指导处理多语言问题，并通过生成多种计划和多数表决提高结果稳定性。

Result: 在挑战赛中，OraPlan-SQL比第二名高出6%以上，英语和汉语执行准确率分别达到55.0%和56.7%，SQL有效性超过99%。

Conclusion: 该系统有效提升了复杂推理的NL2SQL性能和多语言支持，且通过优化规划者和多计划策略提升了泛化能力和结果稳定性。

Abstract: We present OraPlan-SQL, our system for the Archer NL2SQL Evaluation Challenge
2025, a bilingual benchmark requiring complex reasoning such as arithmetic,
commonsense, and hypothetical inference. OraPlan-SQL ranked first, exceeding
the second-best system by more than 6% in execution accuracy (EX), with 55.0%
in English and 56.7% in Chinese, while maintaining over 99% SQL validity (VA).
Our system follows an agentic framework with two components: Planner agent that
generates stepwise natural language plans, and SQL agent that converts these
plans into executable SQL. Since SQL agent reliably adheres to the plan, our
refinements focus on the planner. Unlike prior methods that rely on multiple
sub-agents for planning and suffer from orchestration overhead, we introduce a
feedback-guided meta-prompting strategy to refine a single planner. Failure
cases from a held-out set are clustered with human input, and an LLM distills
them into corrective guidelines that are integrated into the planner's system
prompt, improving generalization without added complexity. For the multilingual
scenario, to address transliteration and entity mismatch issues, we incorporate
entity-linking guidelines that generate alternative surface forms for entities
and explicitly include them in the plan. Finally, we enhance reliability
through plan diversification: multiple candidate plans are generated for each
query, with the SQL agent producing a query for each plan, and final output
selected via majority voting over their executions.

</details>


### [11] [Language Models for Longitudinal Clinical Prediction](https://arxiv.org/abs/2510.23884)
*Tananun Songdechakraiwut,Michael Lutz*

Main category: cs.CL

TL;DR: 提出了一种轻量级框架，利用冻结的大型语言模型分析纵向临床数据，实现准确预测，无需微调。


<details>
  <summary>Details</summary>
Motivation: 当前模型微调成本高，难以有效利用患者历史数据进行长期预测。

Method: 在语言模型空间中融合患者历史和上下文信息，适配冻结的大型语言模型进行预测。

Result: 在神经心理评估中表现出了高准确率和可靠性，且训练数据需求极少。

Conclusion: 该方法对早期阿尔茨海默病监测具有潜力，提供了一种无需模型微调的高效解决方案。

Abstract: We explore a lightweight framework that adapts frozen large language models
to analyze longitudinal clinical data. The approach integrates patient history
and context within the language model space to generate accurate forecasts
without model fine-tuning. Applied to neuropsychological assessments, it
achieves accurate and reliable performance even with minimal training data,
showing promise for early-stage Alzheimer's monitoring.

</details>


### [12] [AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages](https://arxiv.org/abs/2510.23896)
*Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文介绍了AfriMTEB，一个覆盖非洲59种语言和多种NLP任务的新型多语言评测基准，同时提出了针对非洲语言优化的AfriE5模型，实现了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言文本嵌入评测基准中非洲语言严重不足，且缺乏针对非洲语言的新任务，这限制了非洲语言NLP技术的发展。

Method: 构建AfriMTEB基准，涵盖59种非洲语言和14个任务，新增多种任务如仇恨言论检测、意图检测和情感分类；同时通过跨语言对比蒸馏方法对instruction-tuned的mE5模型进行适配，得到AfriE5模型。

Result: AfriE5在非洲语言文本嵌入任务上表现优异，超越了Gemini-Embeddings和原始mE5等强基线模型。

Conclusion: AfriMTEB和AfriE5为非洲语言的NLP研究提供了强有力的基础设施，促进了非洲语言文本理解和生成任务的发展。

Abstract: Text embeddings are an essential building component of several NLP tasks such
as retrieval-augmented generation which is crucial for preventing
hallucinations in LLMs. Despite the recent release of massively multilingual
MTEB (MMTEB), African languages remain underrepresented, with existing tasks
often repurposed from translation benchmarks such as FLORES clustering or
SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB
covering 59 languages, 14 tasks, and 38 datasets, including six newly added
datasets. Unlike many MMTEB datasets that include fewer than five languages,
the new additions span 14 to 56 African languages and introduce entirely new
tasks, such as hate speech detection, intent detection, and emotion
classification, which were not previously covered. Complementing this, we
present AfriE5, an adaptation of the instruction-tuned mE5 model to African
languages through cross-lingual contrastive distillation. Our evaluation shows
that AfriE5 achieves state-of-the-art performance, outperforming strong
baselines such as Gemini-Embeddings and mE5.

</details>


### [13] [Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation](https://arxiv.org/abs/2510.23921)
*Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文提出了一种通用的数据增强框架，用于公平性评估，发现大型语言模型容易受到输入扰动影响，从而表现出刻板偏见，尤其是在较少研究的群体上表现更为明显。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型因训练数据的歧视性存在刻板偏见，且现有的偏见校正方法缺乏鲁棒性，因此需要一种新的、通用的公平性增强方法。

Method: 提出了一种包含三步的即插即用数据增强框架，应用于公平性评估基准数据集BBQ，通过对输入进行扰动来评估模型的偏见表现。

Result: 发现包括最新开源和闭源模型在内的大型语言模型在输入扰动下更可能表现出刻板偏见，并且针对文献中较少研究的群体偏见更严重。

Conclusion: 该增强框架有效揭示了大型语言模型的偏见脆弱性，强调了将公平性与安全研究拓展到更多多样化社区的必要性。

Abstract: Large Language Models have been shown to demonstrate stereotypical biases in
their representations and behavior due to the discriminative nature of the data
that they have been trained on. Despite significant progress in the development
of methods and models that refrain from using stereotypical information in
their decision-making, recent work has shown that approaches used for bias
alignment are brittle. In this work, we introduce a novel and general
augmentation framework that involves three plug-and-play steps and is
applicable to a number of fairness evaluation benchmarks. Through application
of augmentation to a fairness evaluation dataset (Bias Benchmark for Question
Answering (BBQ)), we find that Large Language Models (LLMs), including
state-of-the-art open and closed weight models, are susceptible to
perturbations to their inputs, showcasing a higher likelihood to behave
stereotypically. Furthermore, we find that such models are more likely to have
biased behavior in cases where the target demographic belongs to a community
less studied by the literature, underlining the need to expand the fairness and
safety research to include more diverse communities.

</details>


### [14] [Agent-based Automated Claim Matching with Instruction-following LLMs](https://arxiv.org/abs/2510.23924)
*Dina Pisarevskaya,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 本文提出了一种基于指令跟随大型语言模型(LLMs)的自动化论断匹配新方法，通过两步流水线生成提示并分类论断，结果显示LLM生成的提示优于人工提示，且小型LLM表现不逊于大型LLM，节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 现有论断匹配方法依赖人工提示或大型模型，计算资源消耗大，且提示质量影响效果，迫切需要一种高效且自动化提示生成及匹配方案。

Method: 提出两步流水线，第一步用LLM自动生成提示，第二步用LLM进行二分类论断匹配；探索不同LLM组合使用以提升效率和效果。

Result: LLM自动生成提示优于人工生成提示，小型LLM在提示生成中表现不比大型LLM差；不同模型组合使用显示可优化性能与资源消耗。

Conclusion: 自动生成的提示结合不同LLM搭配能有效提升论断匹配任务，节省资源并提供对LLM理解能力的洞察。

Abstract: We present a novel agent-based approach for the automated claim matching task
with instruction-following LLMs. We propose a two-step pipeline that first
generates prompts with LLMs, to then perform claim matching as a binary
classification task with LLMs. We demonstrate that LLM-generated prompts can
outperform SOTA with human-generated prompts, and that smaller LLMs can do as
well as larger ones in the generation process, allowing to save computational
resources. We also demonstrate the effectiveness of using different LLMs for
each step of the pipeline, i.e. using an LLM for prompt generation, and another
for claim matching. Our investigation into the prompt generation process in
turn reveals insights into the LLMs' understanding of claim matching.

</details>


### [15] [Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs](https://arxiv.org/abs/2510.23941)
*Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan*

Main category: cs.CL

TL;DR: 提出了一种无需训练的自动提示级联方法，用于大语言模型评估电商产品质量，实现准确率和召回率提升8-10%。


<details>
  <summary>Details</summary>
Motivation: 解决传统链式思维提示在大规模复杂工业目录中，缺乏针对特定领域知识和高效性的问题。

Method: 基于人工设计的初始提示，自动生成和优化提示语，以适应各类目属性的质量评价需求，形成训练自由的自动提示级联。

Result: 该方法相比传统链式思维提升了8-10%的准确率和召回率，同时将领域专家的工作时间从5.1小时减少至3分钟，实现99%的效率提升。并且能够跨语言和多任务泛化。

Conclusion: 自动提示级联方法有效桥接了通用语言理解和领域知识，显著提升产品质量评估的效率与准确性，具备良好的多语言和多任务适用性。

Abstract: We introduce a novel, training free cascade for auto-prompting Large Language
Models (LLMs) to assess product quality in e-commerce. Our system requires no
training labels or model fine-tuning, instead automatically generating and
refining prompts for evaluating attribute quality across tens of thousands of
product category-attribute pairs. Starting from a seed of human-crafted
prompts, the cascade progressively optimizes instructions to meet
catalog-specific requirements. This approach bridges the gap between general
language understanding and domain-specific knowledge at scale in complex
industrial catalogs. Our extensive empirical evaluations shows the auto-prompt
cascade improves precision and recall by $8-10\%$ over traditional
chain-of-thought prompting. Notably, it achieves these gains while reducing
domain expert effort from 5.1 hours to 3 minutes per attribute - a $99\%$
reduction. Additionally, the cascade generalizes effectively across five
languages and multiple quality assessment tasks, consistently maintaining
performance gains.

</details>


### [16] [ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?](https://arxiv.org/abs/2510.24706)
*Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu*

Main category: cs.CL

TL;DR: 本文设计了ComboBench基准测试，评估大型语言模型(LLMs)将语义动作转换为虚拟现实设备操作序列的能力，发现顶级模型虽表现优秀，但在程序推理和空间理解上仍逊于人类。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实游戏中玩家需将高层语义动作精准转换为设备操作，然而现有研究尚未充分探讨大型语言模型在这方面的效能。

Method: 构建包含262场景的ComboBench，涵盖四款主流VR游戏，通过对比七个LLM及人类表现，评估模型在语义动作转设备操作的能力。

Result: Gemini-1.5-Pro表现最佳，显示良好的任务分解能力，但总体在程序推理和空间理解方面仍不及人类；不同游戏间表现差异明显，少样本学习显著提升性能。

Conclusion: LLMs在VR设备操作语义转换具潜力，但需进一步提升推理和空间理解能力，少样本学习为增强该能力的有效途径。

Abstract: Virtual Reality (VR) games require players to translate high-level semantic
actions into precise device manipulations using controllers and head-mounted
displays (HMDs). While humans intuitively perform this translation based on
common sense and embodied understanding, whether Large Language Models (LLMs)
can effectively replicate this ability remains underexplored. This paper
introduces a benchmark, ComboBench, evaluating LLMs' capability to translate
semantic actions into VR device manipulation sequences across 262 scenarios
from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,
and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,
Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against
annotated ground truth and human performance. Our results reveal that while
top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition
capabilities, they still struggle with procedural reasoning and spatial
understanding compared to humans. Performance varies significantly across
games, suggesting sensitivity to interaction complexity. Few-shot examples
substantially improve performance, indicating potential for targeted
enhancement of LLMs' VR manipulation capabilities. We release all materials at
https://sites.google.com/view/combobench.

</details>


### [17] [Leveraging LLMs for Early Alzheimer's Prediction](https://arxiv.org/abs/2510.23946)
*Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 该论文提出了一种结合脑连接组信息与大语言模型的新框架，通过动态fMRI连接性数据进行早期阿尔茨海默病的临床预测，实现了高灵敏度和低误差率。


<details>
  <summary>Details</summary>
Motivation: 当前早期阿尔茨海默病的临床预测面临准确率和及时性不足的问题，亟需利用脑连接组动态信息提升预测性能。

Method: 将动态fMRI连接性数据编码为时间序列，采用鲁棒的归一化方法，并映射到预训练冻结的大语言模型表示空间进行预测。

Result: 该方法在早期阿尔茨海默病检测中实现了高灵敏度，错误率远低于临床认可的阈值。

Conclusion: 基于连接组信息的LLM框架为阿尔茨海默病的早期及时干预提供了可行且有效的临床预测工具。

Abstract: We present a connectome-informed LLM framework that encodes dynamic fMRI
connectivity as temporal sequences, applies robust normalization, and maps
these data into a representation suitable for a frozen pre-trained LLM for
clinical prediction. Applied to early Alzheimer's detection, our method
achieves sensitive prediction with error rates well below clinically recognized
margins, with implications for timely Alzheimer's intervention.

</details>


### [18] [Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs](https://arxiv.org/abs/2510.23949)
*Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak*

Main category: cs.CL

TL;DR: 本文发现多语言大模型在微调后存在语言混淆现象，且标准评价指标无法准确反映模型的遗忘效果。


<details>
  <summary>Details</summary>
Motivation: 现有多语言模型的遗忘研究主要基于性能指标，忽视语言混淆现象，导致评价结果不准确。

Method: 提出基于N-gram的语言混淆评分（N-Mix）量化语言混淆，分析标准参考指标在高N-Mix情况下误判的原因，并倡导语义内容评估的新型遗忘评价指标。

Result: 实验证明多语言大模型广泛存在语言混淆问题，且传统指标在此情况下会产生假阴性评价。

Conclusion: 需要采用基于语义的评价指标来准确衡量多语言大模型的遗忘效果，避免语言混淆带来的误判。

Abstract: There have been a couple of studies showing that attempting to erase
multilingual knowledge using only English data is insufficient for multilingual
LLMs. However, their analyses remain highly performance-oriented. In this
paper, we switch the point of view to evaluation, and address an additional
blind spot which reveals itself when the multilingual LLM is fully finetuned
with parallel multilingual dataset before unlearning. Here, language confusion
occurs whereby a model responds in language different from that of the input
prompt. Language confusion is a problematic phenomenon in unlearning, causing
the standard reference-based metrics to fail. We tackle this phenomenon in
three steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to
quantitatively show the language confusion is pervasive and consistent in
multilingual LLMs, (2) demonstrate that reference-based metrics result in false
negatives when N-Mix score is high, and(3) suggest the need of new type of
unlearning evaluation that can directly assess the content of the generated
sentences. We call this type of metrics as semantic-based metric.

</details>


### [19] [M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems](https://arxiv.org/abs/2510.23995)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 本论文提出了基于检索增强生成（RAG）系统的医学问答中的错误检测方法M-Eval，通过多源证据的异质性分析，有效提升了系统回答的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG系统在医学问答应用中存在错误生成（如幻觉信息）和未能正确利用外部知识的问题，亟需一种方法来验证回答的真实性和证据的可靠性。

Method: 该方法借鉴循证医学中的异质性分析，先从外部知识库提取额外医学文献，检索RAG系统生成的证据文档，利用多源证据的异质性分析判断回答中观点是否被证据支持，从而检测事实错误并评估证据可靠性。

Result: 该方法在多种大语言模型上提高了回答准确率，最高提升达23.31%。

Conclusion: M-Eval方法有效减少了RAG系统中的诊断错误，提高了基于大语言模型的医学问答系统的可靠性。

Abstract: Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing
medical question-answering systems through the integration of large language
models (LLMs) with external medical literature. LLMs can retrieve relevant
medical articles to generate more professional responses efficiently. However,
current RAG applications still face problems. They generate incorrect
information, such as hallucinations, and they fail to use external knowledge
correctly. To solve these issues, we propose a new method named M-Eval. This
method is inspired by the heterogeneity analysis approach used in
Evidence-Based Medicine (EBM). Our approach can check for factual errors in RAG
responses using evidence from multiple sources. First, we extract additional
medical literature from external knowledge bases. Then, we retrieve the
evidence documents generated by the RAG system. We use heterogeneity analysis
to check whether the evidence supports different viewpoints in the response. In
addition to verifying the accuracy of the response, we also assess the
reliability of the evidence provided by the RAG system. Our method shows an
improvement of up to 23.31% accuracy across various LLMs. This work can help
detect errors in current RAG-based medical systems. It also makes the
applications of LLMs more reliable and reduces diagnostic errors.

</details>


### [20] [PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.23998)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Bin Qin*

Main category: cs.CL

TL;DR: 本文提出了PICOs-RAG方法，通过将用户查询扩展和规范化为PICO格式，提高了证据检索的效率和相关性，增强了大语言模型在循证医学中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统基于人工的文献检索缺乏客观性和效率，现有的检索增强生成方法在处理临床复杂查询时效果有限，导致检索结果不相关、回答不准确。

Method: 该方法将用户查询扩展为专业的、符合PICO格式的查询，利用PICO作为循证医学的检索策略工具，提升检索关键内容的获取能力。

Result: 采用PICOs-RAG方法的检索效率和相关性显著提升，相较基线方法最高提升8.8%。

Conclusion: PICOs-RAG方法有效改善了大语言模型在循证医学领域的检索和生成能力，使其成为更有用、可靠的医学助手。

Abstract: Evidence-based medicine (EBM) research has always been of paramount
importance. It is important to find appropriate medical theoretical support for
the needs from physicians or patients to reduce the occurrence of medical
accidents. This process is often carried out by human querying relevant
literature databases, which lacks objectivity and efficiency. Therefore,
researchers utilize retrieval-augmented generation (RAG) to search for evidence
and generate responses automatically. However, current RAG methods struggle to
handle complex queries in real-world clinical scenarios. For example, when
queries lack certain information or use imprecise language, the model may
retrieve irrelevant evidence and generate unhelpful answers. To address this
issue, we present the PICOs-RAG to expand the user queries into a better
format. Our method can expand and normalize the queries into professional ones
and use the PICO format, a search strategy tool present in EBM, to extract the
most important information used for retrieval. This approach significantly
enhances retrieval efficiency and relevance, resulting in up to an 8.8\%
improvement compared to the baseline evaluated by our method. Thereby the
PICOs-RAG improves the performance of the large language models into a helpful
and reliable medical assistant in EBM.

</details>


### [21] [META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.24003)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 本文提出了一种结合循证医学方法的新型证据重新排序和筛选策略，以提高大语言模型在医疗诊断中的证据质量，从而提升诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型的循证医学任务难以有效区分高质量医疗证据，影响诊断准确性。

Method: 借鉴循证医学中的元分析理念，设计了结合可靠性分析、异质性分析和外推分析的多原则证据筛选方法，用以提升证据质量并重新排序医疗文献。

Result: 该方法在PubMed数据集上应用，实现了最大11.4%的准确率提升，有效提取到更高质量和更可靠的医疗证据。

Conclusion: 本文方法成功提升了基于检索增强生成技术的证据质量，减少错误知识的注入，帮助用户获得更有效的医疗诊断回复。

Abstract: Evidence-based medicine (EBM) holds a crucial role in clinical application.
Given suitable medical articles, doctors effectively reduce the incidence of
misdiagnoses. Researchers find it efficient to use large language models (LLMs)
techniques like RAG for EBM tasks. However, the EBM maintains stringent
requirements for evidence, and RAG applications in EBM struggle to efficiently
distinguish high-quality evidence. Therefore, inspired by the meta-analysis
used in EBM, we provide a new method to re-rank and filter the medical
evidence. This method presents multiple principles to filter the best evidence
for LLMs to diagnose. We employ a combination of several EBM methods to emulate
the meta-analysis, which includes reliability analysis, heterogeneity analysis,
and extrapolation analysis. These processes allow the users to retrieve the
best medical evidence for the LLMs. Ultimately, we evaluate these high-quality
articles and show an accuracy improvement of up to 11.4% in our experiments and
results. Our method successfully enables RAG to extract higher-quality and more
reliable evidence from the PubMed dataset. This work can reduce the infusion of
incorrect knowledge into responses and help users receive more effective
replies.

</details>


### [22] [TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://arxiv.org/abs/2510.24014)
*Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: 提出了一个新的信息抽取任务TEXT2DB，强调将信息抽取输出与目标数据库集成，利用用户指令对数据库进行更新。设计了新的基准和LLM代理框架OPAL，实验表明其能适应不同数据库架构并有效调用信息抽取模型。


<details>
  <summary>Details</summary>
Motivation: 传统信息抽取任务与下游应用的数据库需求不匹配，导致信息难以直接利用，需设计新的任务以桥接信息抽取输出与数据库更新之间的差距。

Method: 提出TEXT2DB任务，结合用户指令、文档集和数据库，要求模型实时适应数据库架构更新数据；并设计OPAL框架，包括Observer、Planner和Analyzer组件，分别负责数据库交互、生成代码计划及代码质量反馈。

Result: 实验表明OPAL能根据不同数据库架构生成灵活的代码计划，成功调用所需的信息抽取模型，实现对数据库的有效更新。部分复杂数据库及抽取幻觉问题值得后续研究。

Conclusion: TEXT2DB任务及OPAL框架为信息抽取与数据库更新的结合提供了有效方案，展示了灵活适应不同数据库需求的能力，并指出未来挑战与研究方向。

Abstract: The task of information extraction (IE) is to extract structured knowledge
from text. However, it is often not straightforward to utilize IE output due to
the mismatch between the IE ontology and the downstream application needs. We
propose a new formulation of IE TEXT2DB that emphasizes the integration of IE
output and the target database (or knowledge base). Given a user instruction, a
document set, and a database, our task requires the model to update the
database with values from the document set to satisfy the user instruction.
This task requires understanding user instructions for what to extract and
adapting to the given DB/KB schema for how to extract on the fly. To evaluate
this new task, we introduce a new benchmark featuring common demands such as
data infilling, row population, and column addition. In addition, we propose an
LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer
component that interacts with the database, the Planner component that
generates a code-based plan with calls to IE models, and the Analyzer component
that provides feedback regarding code quality before execution. Experiments
show that OPAL can successfully adapt to diverse database schemas by generating
different code plans and calling the required IE models. We also highlight
difficult cases such as dealing with large databases with complex dependencies
and extraction hallucination, which we believe deserve further investigation.
Source code: https://github.com/yzjiao/Text2DB

</details>


### [23] [Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward](https://arxiv.org/abs/2510.24020)
*Hao An,Yang Xu*

Main category: cs.CL

TL;DR: 提出了一种基于细粒度语义置信奖励的强化学习方法，通过语义聚类引导大语言模型进行准确的后验弃答，从而减轻幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有通过整体置信度引导模型弃答的方法往往过于粗糙，无法精准识别模型的知识边界，影响模型的答案可靠性。

Method: 该方法对多个候选答案进行语义聚类，基于聚类结果的置信度训练模型保留高置信度答案，放弃低置信度答案，实现细粒度的弃答控制。

Result: 在域内和分布偏移基准测试中，该方法显著提升了弃答的可靠性。

Conclusion: 通过细粒度语义置信奖励的策略，能够更精准地指导大语言模型进行可靠的弃答，有效缓解幻觉问题，提升模型实际部署的可靠性。

Abstract: Mitigating hallucinations in Large Language Models (LLMs) is critical for
their reliable deployment. Existing methods typically fine-tune LLMs to abstain
from answering questions beyond their knowledge scope. However, these methods
often rely on coarse-grained signals to guide LLMs to abstain, such as overall
confidence or uncertainty scores on multiple sampled answers, which may result
in an imprecise awareness of the model's own knowledge boundaries. To this end,
we propose a novel reinforcement learning framework built on
$\textbf{\underline{Fi}ne-grained \underline{S}emantic \underline{Co}nfidence
\underline{Re}ward (\Ours)}$, which guides LLMs to abstain via sample-specific
confidence. Specifically, our method operates by sampling multiple candidate
answers and conducting semantic clustering, then training the LLM to retain
answers within high-confidence clusters and discard those within low-confidence
ones, thereby promoting accurate post-hoc abstention. Additionally, we propose
a new metric for evaluating the reliability of abstention fine-tuning tasks
more comprehensively. Our method significantly enhances reliability in both
in-domain and out-of-distribution benchmarks.

</details>


### [24] [SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs](https://arxiv.org/abs/2510.24021)
*Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren*

Main category: cs.CL

TL;DR: 提出了一种基于动态token级别门控机制的知识蒸馏新方法Speculative Knowledge Distillation (SpecKD)，通过对学生模型的token提议进行教师分布验证，有选择地应用蒸馏损失，提升了蒸馏效果和学生模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法对所有token均匀施加蒸馏损失，忽略了教师模型对不同token预测置信度的差异，导致学生模型被迫学习教师的不确定或者高熵预测，进而引入噪声，影响学生模型性能，尤其当教师模型规模远大时。

Method: 提出了SpecKD框架，借鉴投机解码中的“提议-验证”机制，在每个生成步骤中先由学生模型提出token，然后通过教师模型分布进行验证，只有被接受的token才应用蒸馏损失，被拒绝的token则屏蔽，不参与损失计算。

Result: 在多个文本生成任务中，SpecKD相较于传统的知识蒸馏方法表现更优，训练更稳定且学生模型能力更强，取得了最新的性能指标。

Conclusion: Speculative Knowledge Distillation通过引入动态token级门控机制有效减少了蒸馏过程中的噪声，提高了知识蒸馏的效果，是提升学生模型性能的有效方法。

Abstract: Knowledge Distillation (KD) has become a cornerstone technique for
compressing Large Language Models (LLMs) into smaller, more efficient student
models. However, conventional KD approaches typically apply the distillation
loss uniformly across all tokens, regardless of the teacher's confidence. This
indiscriminate mimicry can introduce noise, as the student is forced to learn
from the teacher's uncertain or high-entropy predictions, which may ultimately
harm student performance-especially when the teacher is much larger and more
powerful. To address this, we propose Speculative Knowledge Distillation
(SpecKD), a novel, plug-and-play framework that introduces a dynamic,
token-level gating mechanism inspired by the "propose-and-verify" paradigm of
speculative decoding. At each step, the student's token proposal is verified
against the teacher's distribution; the distillation loss is selectively
applied only to "accepted" tokens, while "rejected" tokens are masked out.
Extensive experiments on diverse text generation tasks show that SpecKD
consistently and significantly outperforms strong KD baselines, leading to more
stable training and more capable student models, and achieving state-of-the-art
results.

</details>


### [25] [Success and Cost Elicit Convention Formation for Efficient Communication](https://arxiv.org/abs/2510.24023)
*Saujas Vaduguru,Yilun Hua,Yoav Artzi,Daniel Fried*

Main category: cs.CL

TL;DR: 本文提出了一种训练大型多模态模型形成语言约定的方法，通过模型之间的模拟参照游戏，实现高效沟通。


<details>
  <summary>Details</summary>
Motivation: 人类通过共享的对话上下文形成临时语言约定，从而更高效地交流。如何让模型也能形成类似约定以提升交流效率？

Method: 利用模型间的重复参照游戏，不依赖额外的人工数据，训练模型形成语言约定。

Result: 在涉及照片和拼图图像的重复参照游戏中，所提方法使模型与人类沟通时信息长度缩短41%，成功率提高15%，人类听者响应更快。

Conclusion: 仅基于成功率或成本的训练不足以形成语言约定，成功率和成本双重目标同时优化才能促使形成有效约定。

Abstract: Humans leverage shared conversational context to become increasingly
successful and efficient at communicating over time. One manifestation of this
is the formation of ad hoc linguistic conventions, which allow people to
coordinate on short, less costly utterances that are understood using shared
conversational context. We present a method to train large multimodal models to
form conventions, enabling efficient communication. Our approach uses simulated
reference games between models, and requires no additional human-produced data.
In repeated reference games involving photographs and tangram images, our
method enables models to communicate efficiently with people: reducing the
message length by up to 41% while increasing success by 15% over the course of
the interaction. Human listeners respond faster when interacting with our model
that forms conventions. We also show that training based on success or cost
alone is insufficient - both are necessary to elicit convention formation.

</details>


### [26] [Pie: A Programmable Serving System for Emerging LLM Applications](https://arxiv.org/abs/2510.24051)
*In Gim,Zhiyao Ma,Seung-seob Lee,Lin Zhong*

Main category: cs.CL

TL;DR: 本文提出了Pie，一种面向大语言模型（LLM）的灵活高效的可编程服务系统，通过将传统生成循环拆解为细粒度的服务处理器和用户提供的inferlets程序，实现应用层的新KV缓存策略和定制生成逻辑，显著提升了复杂推理工作流的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一生成循环的大语言模型服务系统难以满足多样化推理策略和复杂代理工作流对灵活性和效率的需求。

Method: 将传统的生成循环拆分成细颗粒度的服务处理器组件，通过API暴露给用户，并由用户实现的inferlets程序控制生成过程，利用WebAssembly技术实现轻量级沙箱执行，方便定制缓存和生成逻辑。

Result: 在标准任务上，Pie的性能与最先进系统相当，仅有3-12%的延迟开销；在复杂代理工作流上，则实现了1.3倍至3.4倍的延迟和吞吐量提升。

Conclusion: Pie通过可编程设计和细粒度解耦，实现了高效且灵活的LLM服务，适应多样化应用需求，显著提升了推理工作流的性能表现。

Abstract: Emerging large language model (LLM) applications involve diverse reasoning
strategies and agentic workflows, straining the capabilities of existing
serving systems built on a monolithic token generation loop. This paper
introduces Pie, a programmable LLM serving system designed for flexibility and
efficiency. Pie decomposes the traditional generation loop into fine-grained
service handlers exposed via an API and delegates control of the generation
process to user-provided programs, called inferlets. This enables applications
to implement new KV cache strategies, bespoke generation logic, and seamlessly
integrate computation and I/O-entirely within the application, without
requiring modifications to the serving system. Pie executes inferlets using
WebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows
Pie matches state-of-the-art performance on standard tasks (3-12% latency
overhead) while significantly improving latency and throughput (1.3x-3.4x
higher) on agentic workflows by enabling application-specific optimizations.

</details>


### [27] [Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation](https://arxiv.org/abs/2510.24073)
*Xinwei Wu,Heng Liu,Jiang Zhou,Xiaohu Zhao,Linlong Xu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 该论文提出了HalloMTBench，一个人类验证的多语言机器翻译基准，用于检测多语言大型语言模型（LLMs）的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有的机器翻译基准无法有效揭示多语言LLMs中的幻觉失败，需要一个新的诊断框架来区分不同类型的幻觉。

Method: 作者设计了一个包含指令脱节和源语脱节的幻觉分类法，创建了覆盖11个英译多语言方向的HalloMTBench，利用4个前沿LLM生成翻译候选，并通过多个LLM评价器和专家验证筛选出5435个高质量样本。

Result: 评估了17个LLMs，发现了不同模型规模、源文本长度敏感性、语言偏见及强化学习引发的语言混合等幻觉触发因素，揭示了多样的失败模式。

Conclusion: HalloMTBench为未来诊断多语言LLMs翻译失败提供了前瞻性测试平台，有助于推动更可靠的机器翻译发展。

Abstract: Large Language Models (LLMs) have advanced machine translation but remain
vulnerable to hallucinations. Unfortunately, existing MT benchmarks are not
capable of exposing failures in multilingual LLMs. To disclose hallucination in
multilingual LLMs, we introduce a diagnostic framework with a taxonomy that
separates Instruction Detachment from Source Detachment. Guided by this
taxonomy, we create HalloMTBench, a multilingual, human-verified benchmark
across 11 English-to-X directions. We employed 4 frontier LLMs to generate
candidates and scrutinize these candidates with an ensemble of LLM judges, and
expert validation. In this way, we curate 5,435 high-quality instances. We have
evaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination
triggers'' -- unique failure patterns reflecting model scale, source length
sensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified
language mixing. HalloMTBench offers a forward-looking testbed for diagnosing
LLM translation failures. HalloMTBench is available in
https://huggingface.co/collections/AIDC-AI/marco-mt.

</details>


### [28] [Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures](https://arxiv.org/abs/2510.24081)
*Tyler A. Chang,Catherine Arnett,Abdelrahman Eldesokey,Abdelrahman Sadallah,Abeer Kashar,Abolade Daud,Abosede Grace Olanihun,Adamu Labaran Mohammed,Adeyemi Praise,Adhikarinayum Meerajita Sharma,Aditi Gupta,Afitab Iyigun,Afonso Simplício,Ahmed Essouaied,Aicha Chorana,Akhil Eppa,Akintunde Oladipo,Akshay Ramesh,Aleksei Dorkin,Alfred Malengo Kondoro,Alham Fikri Aji,Ali Eren Çetintaş,Allan Hanbury,Alou Dembele,Alp Niksarli,Álvaro Arroyo,Amin Bajand,Amol Khanna,Ana Chkhaidze,Ana Condez,Andiswa Mkhonto,Andrew Hoblitzell,Andrew Tran,Angelos Poulis,Anirban Majumder,Anna Vacalopoulou,Annette Kuuipolani Kanahele Wong,Annika Simonsen,Anton Kovalev,Ashvanth. S,Ayodeji Joseph Lana,Barkin Kinay,Bashar Alhafni,Benedict Cibalinda Busole,Bernard Ghanem,Bharti Nathani,Biljana Stojanovska Đurić,Bola Agbonile,Bragi Bergsson,Bruce Torres Fischer,Burak Tutar,Burcu Alakuş Çınar,Cade J. Kanoniakapueo Kane,Can Udomcharoenchaikit,Catherine Arnett,Chadi Helwe,Chaithra Reddy Nerella,Chen Cecilia Liu,Chiamaka Glory Nwokolo,Cristina España-Bonet,Cynthia Amol,DaeYeop Lee,Dana Arad,Daniil Dzenhaliou,Daria Pugacheva,Dasol Choi,Daud Abolade,David Liu,David Semedo,Deborah Popoola,Deividas Mataciunas,Delphine Nyaboke,Dhyuthy Krishna Kumar,Diogo Glória-Silva,Diogo Tavares,Divyanshu Goyal,DongGeon Lee,Ebele Nwamaka Anajemba,Egonu Ngozi Grace,Elena Mickel,Elena Tutubalina,Elias Herranen,Emile Anand,Emmanuel Habumuremyi,Emuobonuvie Maria Ajiboye,Eryawan Presma Yulianrifat,Esther Adenuga,Ewa Rudnicka,Faith Olabisi Itiola,Faran Taimoor Butt,Fathima Thekkekara,Fatima Haouari,Filbert Aurelian Tjiaranata,Firas Laakom,Francesca Grasso,Francesco Orabona,Francesco Periti,Gbenga Kayode Solomon,Gia Nghia Ngo,Gloria Udhehdhe-oze,Gonçalo Martins,Gopi Naga Sai Ram Challagolla,Guijin Son,Gulnaz Abdykadyrova,Hafsteinn Einarsson,Hai Hu,Hamidreza Saffari,Hamza Zaidi,Haopeng Zhang,Harethah Abu Shairah,Harry Vuong,Hele-Andra Kuulmets,Houda Bouamor,Hwanjo Yu,Iben Nyholm Debess,İbrahim Ethem Deveci,Ikhlasul Akmal Hanif,Ikhyun Cho,Inês Calvo,Inês Vieira,Isaac Manzi,Ismail Daud,Itay Itzhak,Iuliia,Alekseenko,Ivan Belashkin,Ivan Spada,Ivan Zhelyazkov,Jacob Brinton,Jafar Isbarov,Jaka Čibej,Jan Čuhel,Jan Kocoń,Jauza Akbar Krito,Jebish Purbey,Jennifer Mickel,Jennifer Za,Jenny Kunz,Jihae Jeong,Jimena Tena Dávalos,Jinu Lee,João Magalhães,John Yi,Jongin Kim,Joseph Chataignon,Joseph Marvin Imperial,Jubeerathan Thevakumar,Judith Land,Junchen Jiang,Jungwhan Kim,Kairit Sirts,Kamesh R,Kamesh V,Kanda Patrick Tshinu,Kätriin Kukk,Kaustubh Ponkshe,Kavsar Huseynova,Ke He,Kelly Buchanan,Kengatharaiyer Sarveswaran,Kerem Zaman,Khalil Mrini,Kian Kyars,Krister Kruusmaa,Kusum Chouhan,Lainitha Krishnakumar,Laura Castro Sánchez,Laura Porrino Moscoso,Leshem Choshen,Levent Sencan,Lilja Øvrelid,Lisa Alazraki,Lovina Ehimen-Ugbede,Luheerathan Thevakumar,Luxshan Thavarasa,Mahnoor Malik,Mamadou K. Keita,Mansi Jangid,Marco De Santis,Marcos García,Marek Suppa,Mariam D'Ciofalo,Marii Ojastu,Maryam Sikander,Mausami Narayan,Maximos Skandalis,Mehak Mehak,Mehmet İlteriş Bozkurt,Melaku Bayu Workie,Menan Velayuthan,Michael Leventhal,Michał Marcińczuk,Mirna Potočnjak,Mohammadamin Shafiei,Mridul Sharma,Mrityunjaya Indoria,Muhammad Ravi Shulthan Habibi,Murat Kolić,Nada Galant,Naphat Permpredanun,Narada Maugin,Nicholas Kluge Corrêa,Nikola Ljubešić,Nirmal Thomas,Nisansa de Silva,Nisheeth Joshi,Nitish Ponkshe,Nizar Habash,Nneoma C. Udeze,Noel Thomas,Noémi Ligeti-Nagy,Nouhoum Coulibaly,Nsengiyumva Faustin,Odunayo Kareemat Buliaminu,Odunayo Ogundepo,Oghojafor Godswill Fejiro,Ogundipe Blessing Funmilola,Okechukwu God'spraise,Olanrewaju Samuel,Olaoye Deborah Oluwaseun,Olasoji Akindejoye,Olga Popova,Olga Snissarenko,Onyinye Anulika Chiemezie,Orkun Kinay,Osman Tursun,Owoeye Tobiloba Moses,Oyelade Oluwafemi Joshua,Oyesanmi Fiyinfoluwa,Pablo Gamallo,Pablo Rodríguez Fernández,Palak Arora,Pedro Valente,Peter Rupnik,Philip Oghenesuowho Ekiugbo,Pramit Sahoo,Prokopis Prokopidis,Pua Niau-Puhipau,Quadri Yahya,Rachele Mignone,Raghav Singhal,Ram Mohan Rao Kadiyala,Raphael Merx,Rapheal Afolayan,Ratnavel Rajalakshmi,Rishav Ghosh,Romina Oji,Ron Kekeha Solis,Rui Guerra,Rushikesh Zawar,Sa'ad Nasir Bashir,Saeed Alzaabi,Sahil Sandeep,Sai Pavan Batchu,SaiSandeep Kantareddy,Salsabila Zahirah Pranida,Sam Buchanan,Samuel Rutunda,Sander Land,Sarah Sulollari,Sardar Ali,Saroj Sapkota,Saulius Tautvaisas,Sayambhu Sen,Sayantani Banerjee,Sebastien Diarra,SenthilNathan. M,Sewoong Lee,Shaan Shah,Shankar Venkitachalam,Sharifa Djurabaeva,Sharon Ibejih,Shivanya Shomir Dutta,Siddhant Gupta,Silvia Paniagua Suárez,Sina Ahmadi,Sivasuthan Sukumar,Siyuan Song,Snegha A.,Sokratis Sofianopoulos,Sona Elza Simon,Sonja Benčina,Sophie Gvasalia,Sphurti Kirit More,Spyros Dragazis,Stephan P. Kaufhold,Suba. S,Sultan AlRashed,Surangika Ranathunga,Taiga Someya,Taja Kuzman Pungeršek,Tal Haklay,Tasi'u Jibril,Tatsuya Aoyama,Tea Abashidze,Terenz Jomar Dela Cruz,Terra Blevins,Themistoklis Nikas,Theresa Dora Idoko,Thu Mai Do,Tilek Chubakov,Tommaso Gargiani,Uma Rathore,Uni Johannesen,Uwuma Doris Ugwu,Vallerie Alexandra Putra,Vanya Bannihatti Kumar,Varsha Jeyarajalingam,Varvara Arzt,Vasudevan Nedumpozhimana,Viktoria Ondrejova,Viktoryia Horbik,Vishnu Vardhan Reddy Kummitha,Vuk Dinić,Walelign Tewabe Sewunetie,Winston Wu,Xiaojing Zhao,Yacouba Diarra,Yaniv Nikankin,Yash Mathur,Yixi Chen,Yiyuan Li,Yolanda Xavier,Yonatan Belinkov,Yusuf Ismail Abayomi,Zaid Alyafeai,Zhengyang Shan,Zhi Rui Tam,Zilu Tang,Zuzana Nadova,Baber Abbasi,Stella Biderman,David Stap,Duygu Ataman,Fabian Schmidt,Hila Gonen,Jiayi Wang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本论文构建了涵盖100多种语言和文化的Global PIQA常识推理基准，展示了当前大型语言模型在多语言文化背景下的表现差异。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏涵盖多语言多文化的文化特定评估基准，迫切需要构建一个全球性的常识推理评测以全面评估大型语言模型。

Method: 通过335名研究人员在65个国家合作，手工构建了包括116种语言变体的Global PIQA基准，涵盖五大洲、14个语系和23种书写系统。该基准包括大量涉及本地食品、习俗和文化元素的题目。

Result: 实验显示最先进的大型语言模型总体表现良好，但在资源较少的语言中表现明显较弱，准确率差距高达37%。开源模型普遍劣于专有模型。

Conclusion: Global PIQA揭示了不同语言与文化中日常知识仍存在显著短板，强调了多元文化背景下语言模型能力提升的必要性，并为评估多样文化环境下的语言能力提供了重要工具。

Abstract: To date, there exist almost no culturally-specific evaluation benchmarks for
large language models (LLMs) that cover a large number of languages and
cultures. In this paper, we present Global PIQA, a participatory commonsense
reasoning benchmark for over 100 languages, constructed by hand by 335
researchers from 65 countries around the world. The 116 language varieties in
Global PIQA cover five continents, 14 language families, and 23 writing
systems. In the non-parallel split of Global PIQA, over 50% of examples
reference local foods, customs, traditions, or other culturally-specific
elements. We find that state-of-the-art LLMs perform well on Global PIQA in
aggregate, but they exhibit weaker performance in lower-resource languages (up
to a 37% accuracy gap, despite random chance at 50%). Open models generally
perform worse than proprietary models. Global PIQA highlights that in many
languages and cultures, everyday knowledge remains an area for improvement,
alongside more widely-discussed capabilities such as complex reasoning and
expert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA
provides a glimpse into the wide diversity of cultures in which human language
is embedded.

</details>


### [29] [RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects](https://arxiv.org/abs/2510.24096)
*Md. Rezuwan Hassan,Azmol Hossain,Kanij Fatema,Rubayet Sabbir Faruque,Tanmoy Shome,Ruwad Naswan,Trina Chakraborty,Md. Foriduzzaman Zihad,Tawsif Tashwar Dipto,Nazia Tasnim,Nazmuddoha Ansary,Md. Mehedi Hasan Shawon,Ahmed Imtiaz Humayun,Md. Golam Rabiul Alam,Farig Sadeque,Asif Sushmit*

Main category: cs.CL

TL;DR: 本文研究了孟加拉语五大方言的语音和形态特征，探索了针对区域方言构建自动语音识别系统的可能性，并公开了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语存在显著的方言多样性，但针对这些方言的计算处理研究较少，本研究旨在填补这一空白。

Method: 通过记录和分析不同地区孟加拉方言的语音和形态特征，尝试构建适合各方言的自动语音识别系统。

Result: 研究成功提取并分析了各方言的语言特征，探索了可行的ASR模型，且发布了数据集供公开使用。

Conclusion: 该研究促进了孟加拉语方言多样性的保护和数字技术的包容性发展，为相关应用如虚拟助手提供了基础。

Abstract: The Bengali language, spoken extensively across South Asia and among
diasporic communities, exhibits considerable dialectal diversity shaped by
geography, culture, and history. Phonological and pronunciation-based
classifications broadly identify five principal dialect groups: Eastern
Bengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further
distinctions emerge through variation in vocabulary, syntax, and morphology, as
observed in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,
and Barishal. Despite this linguistic richness, systematic research on the
computational processing of Bengali dialects remains limited. This study seeks
to document and analyze the phonetic and morphological properties of these
dialects while exploring the feasibility of building computational models
particularly Automatic Speech Recognition (ASR) systems tailored to regional
varieties. Such efforts hold potential for applications in virtual assistants
and broader language technologies, contributing to both the preservation of
dialectal diversity and the advancement of inclusive digital tools for
Bengali-speaking communities. The dataset created for this study is released
for public use.

</details>


### [30] [Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks](https://arxiv.org/abs/2510.24102)
*Yihan Wang,Peiyu Liu,Runyu Chen,Jiaxing Pu,Wei Xu*

Main category: cs.CL

TL;DR: 本文提出了一个统一且模块化的Text-to-SQL框架Squrve，通过标准化执行范式和多角色协作机制，提高了复杂查询的处理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管Text-to-SQL技术取得显著进展，但在实际系统中部署仍受限于集成工具不足。

Method: Squrve建立了统一的执行范式及基于七个抽象原子角色组件的多角色协作机制。

Result: 在多个主流基准测试中，协作工作流的表现优于单一方法。

Conclusion: Squrve为应对复杂的现实查询问题提供了新的有效解决路径，具有较强的实用价值和推广潜力。

Abstract: Text-to-SQL technology has evolved rapidly, with diverse academic methods
achieving impressive results. However, deploying these techniques in real-world
systems remains challenging due to limited integration tools. Despite these
advances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL
framework designed to bring together research advances and real-world
applications. Squrve first establishes a universal execution paradigm that
standardizes invocation interfaces, then proposes a multi-actor collaboration
mechanism based on seven abstracted effective atomic actor components.
Experiments on widely adopted benchmarks demonstrate that the collaborative
workflows consistently outperform the original individual methods, thereby
opening up a new effective avenue for tackling complex real-world queries. The
codes are available at https://github.com/Satissss/Squrve.

</details>


### [31] [Reinforcement Learning for Long-Horizon Multi-Turn Search Agents](https://arxiv.org/abs/2510.24126)
*Vivek Kalyan,Martin Andrews*

Main category: cs.CL

TL;DR: 该论文展示了通过强化学习训练的大型语言模型在法律文档搜索任务中超越了前沿模型，并且多轮操作能力提升了模型表现。


<details>
  <summary>Details</summary>
Motivation: 当前基于提示的多轮语言模型在复杂任务中表现良好，但通过经验学习的强化学习有潜力进一步提升能力。

Method: 采用强化学习方法训练一个拥有140亿参数的模型，在法律文档搜索任务中进行多轮对话和工具使用，并评估多轮次数限制对模型性能的影响。

Result: 强化学习训练的模型准确率达到85%，优于现有领先模型的78%；同时允许更长多轮对话显著提升了模型效果。

Conclusion: 强化学习能够显著提高大型语言模型在复杂多轮任务中的能力，尤其是当模型允许在更长对话轮数中操作时表现最佳。

Abstract: Large Language Model (LLM) agents can leverage multiple turns and tools to
solve complex tasks, with prompt-based approaches achieving strong performance.
This work demonstrates that Reinforcement Learning (RL) can push capabilities
significantly further by learning from experience. Through experiments on a
legal document search benchmark, we show that our RL-trained 14 Billion
parameter model outperforms frontier class models (85% vs 78% accuracy). In
addition, we explore turn-restricted regimes, during training and at test-time,
that show these agents achieve better results if allowed to operate over longer
multi-turn horizons.

</details>


### [32] [Beyond Line-Level Filtering for the Pretraining Corpora of LLMs](https://arxiv.org/abs/2510.24139)
*Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 引入了两种基于模式的行级文本过滤方法，提升了语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 传统行级过滤方法有时会丢弃有价值内容，影响下游性能。

Method: 提出了模式感知行级去重（PLD）和尾部标点过滤（PTF），考虑了行的序列分布，保留结构性重要内容。

Result: 在英语和韩语1亿参数小型语言模型上，这些方法提升了多项选择题基准测试和生成式问答的准确率。

Conclusion: 所提出的模式感知过滤方法有效改进了行级文本预处理，提升了语言模型的下游任务表现。

Abstract: While traditional line-level filtering techniques, such as line-level
deduplication and trailing-punctuation filters, are commonly used, these basic
methods can sometimes discard valuable content, negatively affecting downstream
performance. In this paper, we introduce two methods-pattern-aware line-level
deduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by
enhancing the conventional filtering techniques. Our approach not only
considers line-level signals but also takes into account their sequential
distribution across documents, enabling us to retain structurally important
content that might otherwise be removed. We evaluate these proposed methods by
training small language models (1 B parameters) in both English and Korean. The
results demonstrate that our methods consistently improve performance on
multiple-choice benchmarks and significantly enhance generative
question-answering accuracy on both SQuAD v1 and KorQuAD v1.

</details>


### [33] [Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean](https://arxiv.org/abs/2510.24150)
*Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee*

Main category: cs.CL

TL;DR: Ko-MuSR是首个针对韩语长篇叙事进行多步软推理的综合评测基准，展示跨语言推理能力和提示策略提升效果。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏专门针对韩语长篇叙事中多步软推理的评测基准，且需要减少数据污染，推动韩语NLP发展。

Method: 构建Ko-MuSR基准，包含韩语叙述、推理链和人工验证的多选题；评测两类大型语言模型，利用设计的提示策略提升模型表现。

Result: 多语言模型在韩语推理任务上表现优于韩语专用模型，设计的提示策略显著提升准确率，接近人类水平。

Conclusion: Ko-MuSR为系统评估韩语长文本推理和提示技术提供了坚实基础，促进韩语自然语言处理的进步。

Abstract: We present Ko-MuSR, the first benchmark to comprehensively evaluate
multistep, soft reasoning in long Korean narratives while minimizing data
contamination. Built following MuSR, Ko-MuSR features fully Korean narratives,
reasoning chains, and multiple-choice questions verified by human annotators
for logical consistency and answerability. Evaluations of four large language
models -- two multilingual and two Korean-specialized -- show that multilingual
models outperform Korean-focused ones even in Korean reasoning tasks,
indicating cross-lingual generalization of reasoning ability. Carefully
designed prompting strategies, which combine few-shot examples, reasoning
traces, and task-specific hints, further boost accuracy, approaching
human-level performance. Ko-MuSR offers a solid foundation for advancing Korean
NLP by enabling systematic evaluation of long-context reasoning and prompting
strategies.

</details>


### [34] [MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations](https://arxiv.org/abs/2510.24178)
*Aaron Scott,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出了首个德语多模态讽刺检测数据集MuSaG，包含文本、音频和视频三种模态的33分钟电视节目片段，并针对九个模型进行了性能评测，发现当前模型在文本上表现最好，但与人类依赖音频信号的方式存在差距。


<details>
  <summary>Details</summary>
Motivation: 讽刺是一种复杂的语言现象，难以通过文本单模态准确识别，尤其在社交媒体和流行文化中出现频繁，多模态模型的发展需要新的数据支持。

Method: 构建了MuSaG数据集，包含对德语电视节目中言论的多模态数据和人工注释，评测了九个开源与商业模型在单模态和多模态上的讽刺检测性能，并与人工注释结果对比分析。

Result: 人类在会话环境中更依赖音频线索识别讽刺，而现有模型在文本模态下表现最佳，说明多模态模型尚未充分利用音频信息。

Conclusion: MuSaG填补了德语多模态讽刺检测数据空白，揭示了当前模型的不足，促进更适合真实场景的多模态讽刺检测模型的开发。该数据集已公开以支持未来研究。

Abstract: Sarcasm is a complex form of figurative language in which the intended
meaning contradicts the literal one. Its prevalence in social media and popular
culture poses persistent challenges for natural language understanding,
sentiment analysis, and content moderation. With the emergence of multimodal
large language models, sarcasm detection extends beyond text and requires
integrating cues from audio and vision. We present MuSaG, the first German
multimodal sarcasm detection dataset, consisting of 33 minutes of manually
selected and human-annotated statements from German television shows. Each
instance provides aligned text, audio, and video modalities, annotated
separately by humans, enabling evaluation in unimodal and multimodal settings.
We benchmark nine open-source and commercial models, spanning text, audio,
vision, and multimodal architectures, and compare their performance to human
annotations. Our results show that while humans rely heavily on audio in
conversational settings, models perform best on text. This highlights a gap in
current multimodal models and motivates the use of MuSaG for developing models
better suited to realistic scenarios. We release MuSaG publicly to support
future research on multimodal sarcasm detection and human-model alignment.

</details>


### [35] [Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability](https://arxiv.org/abs/2510.24179)
*Iván Martínez-Murillo,Paloma Moreda,Elena Lloret*

Main category: cs.CL

TL;DR: 本文研究了外部知识整合对自然语言生成（NLG）中常识生成任务的影响，构建了KITGI基准并验证了知识对生成质量的重要性。


<details>
  <summary>Details</summary>
Motivation: 探索外部知识对提高NLG生成句子常识合理性和概念覆盖的作用，解决现有系统缺乏解释性和知识整合评估的问题。

Method: 扩展CommonGen数据集，构建KITGI基准，结合ConceptNet语义关系；采用T5-Large模型比较完整知识和过滤知识两种条件下的句子生成表现，设计三阶段可解释性评测方法。

Result: 完整知识条件下生成句子正确率达到91%，过滤掉关键信息时正确率骤降至6%，证明关系性知识对生成的连贯性和覆盖度至关重要。

Conclusion: 相关的外部知识对提升NLG的常识合理性和覆盖度具有关键作用，强调设计解释性强的知识增强生成系统和更深入的评测框架的必要性。

Abstract: This paper explores the influence of external knowledge integration in
Natural Language Generation (NLG), focusing on a commonsense generation task.
We extend the CommonGen dataset by creating KITGI, a benchmark that pairs input
concept sets with retrieved semantic relations from ConceptNet and includes
manually annotated outputs. Using the T5-Large model, we compare sentence
generation under two conditions: with full external knowledge and with filtered
knowledge where highly relevant relations were deliberately removed. Our
interpretability benchmark follows a three-stage method: (1) identifying and
removing key knowledge, (2) regenerating sentences, and (3) manually assessing
outputs for commonsense plausibility and concept coverage. Results show that
sentences generated with full knowledge achieved 91\% correctness across both
criteria, while filtering reduced performance drastically to 6\%. These
findings demonstrate that relevant external knowledge is critical for
maintaining both coherence and concept coverage in NLG. This work highlights
the importance of designing interpretable, knowledge-enhanced NLG systems and
calls for evaluation frameworks that capture the underlying reasoning beyond
surface-level metrics.

</details>


### [36] [Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment](https://arxiv.org/abs/2510.24208)
*Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang*

Main category: cs.CL

TL;DR: 本文提出一种利用潜在空间语义对齐的细粒度跨尺度大型语言模型知识传递方法，通过激活作为层间知识传递媒介，解决了不同规模模型间参数和结构不兼容问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在不同规模间进行细粒度参数知识传递存在困难，主要由于模型架构和参数差异导致的神经不兼容问题。如何实现高效有效的跨尺度知识转移成为难点。

Method: 本文提出通过潜在空间中的语义对齐，利用激活而非直接重用层参数，作为层间知识传递的媒介，改善了模型间行为的一致性，实现更好的跨尺度知识迁移。

Result: 在四个基准测试中，该方法表现优越，证明了利用潜在语义对齐进行知识转移的有效性。进一步的分析揭示了促进跨尺度知识转移的关键因素。

Conclusion: 潜在空间的语义对齐是实现大型语言模型跨尺度知识传递的基础，激活作为知识传递媒介能有效克服参数和结构差异带来的限制，为神经网络解释性和灵活知识转移提供新路径。

Abstract: Large Language Models (LLMs) encode vast amounts of knowledge in their
massive parameters, which is accessible to locate, trace, and analyze. Despite
advances in neural interpretability, it is still not clear how to transfer
knowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).
A key problem is enabling effective and efficient knowledge transfer across
LLMs of different scales, which is essential for achieving greater flexibility
and broader applicability in transferring knowledge between LLMs. Due to neural
incompatibility, referring to the architectural and parametric differences
between LLMs of varying scales, existing methods that directly reuse layer
parameters are severely limited. In this paper, we identify the semantic
alignment in latent space as the fundamental prerequisite for LLM cross-scale
knowledge transfer. Instead of directly using the layer parameters, our
approach takes activations as the medium of layer-wise knowledge transfer.
Leveraging the semantics in latent space, our approach is simple and
outperforms prior work, better aligning model behaviors across varying scales.
Evaluations on four benchmarks demonstrate the efficacy of our method. Further
analysis reveals the key factors easing cross-scale knowledge transfer and
provides insights into the nature of latent semantic alignment.

</details>


### [37] [HACK: Hallucinations Along Certainty and Knowledge Axes](https://arxiv.org/abs/2510.24222)
*Adi Simhi,Jonathan Herzig,Itay Itzhak,Dana Arad,Zorik Gekhman,Roi Reichart,Fazl Barez,Gabriel Stanovsky,Idan Szpektor,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 本文提出了基于知识和确定性两个维度的LLM幻觉分类框架，并针对不同类型的幻觉设计了差异化的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 现有研究多从外部属性分类LLM幻觉，忽视了幻觉的内在机制，导致缓解措施缺乏针对性。

Method: 构建模型特定数据集，从知识缺失及知识存在但幻觉两种类型分类幻觉，应用激活操控验证分类有效性，并分析不同模型的知识和幻觉模式；提出新的评估指标衡量缓解方法对高确定性幻觉的效果。

Result: 显著区分了两类幻觉，展示不同模型即使共享知识仍有不同幻觉表现，缓解方法在整体表现良好但对高确定性幻觉效果有限。

Conclusion: 强调知识与确定性两个维度在幻觉分类和缓解中的重要性，呼吁开发针对幻觉内在机制的定向缓解策略。

Abstract: Hallucinations in LLMs present a critical barrier to their reliable usage.
Existing research usually categorizes hallucination by their external
properties rather than by the LLMs' underlying internal properties. This
external focus overlooks that hallucinations may require tailored mitigation
strategies based on their underlying mechanism. We propose a framework for
categorizing hallucinations along two axes: knowledge and certainty. Since
parametric knowledge and certainty may vary across models, our categorization
method involves a model-specific dataset construction process that
differentiates between those types of hallucinations. Along the knowledge axis,
we distinguish between hallucinations caused by a lack of knowledge and those
occurring despite the model having the knowledge of the correct response. To
validate our framework along the knowledge axis, we apply steering mitigation,
which relies on the existence of parametric knowledge to manipulate model
activations. This addresses the lack of existing methods to validate knowledge
categorization by showing a significant difference between the two
hallucination types. We further analyze the distinct knowledge and
hallucination patterns between models, showing that different hallucinations do
occur despite shared parametric knowledge. Turning to the certainty axis, we
identify a particularly concerning subset of hallucinations where models
hallucinate with certainty despite having the correct knowledge internally. We
introduce a new evaluation metric to measure the effectiveness of mitigation
methods on this subset, revealing that while some methods perform well on
average, they fail disproportionately on these critical cases. Our findings
highlight the importance of considering both knowledge and certainty in
hallucination analysis and call for targeted mitigation approaches that
consider the hallucination underlying factors.

</details>


### [38] [Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?](https://arxiv.org/abs/2510.24236)
*Teague McMillan,Gabriele Dominici,Martin Gjoreski,Marc Langheinrich*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在解释其预测时的忠实度问题，特别是医疗领域中不忠实解释可能导致信任和安全风险，并探究了推理和训练选择对忠实度的影响。


<details>
  <summary>Details</summary>
Motivation: 医疗领域对解释的忠实度要求很高，不准确的解释会削弱临床医生的信任并带来安全隐患，因此探索模型推理和训练中可控因素对解释忠实度的影响非常重要。

Method: 评估了三个LLMs（GPT-4.1-mini, LLaMA 70B, LLaMA 8B）在两个数据集（BBQ社会偏见和MedQA医疗许可问答）上的表现，操控少样本示例数量与质量、提示设计、训练过程等变量，分析其对解释忠实度的影响。

Result: 发现少样本示例的数量和质量显著影响解释忠实度，提示设计对忠实度敏感，指令调优训练阶段提升了MedQA上的忠实度表现。

Conclusion: 通过调整少样本示例、提示策略和训练流程，可以有效提升LLMs在敏感领域（如医疗）的解释忠实度，从而增强模型的可解释性和用户信任。

Abstract: Large Language Models (LLMs) often produce explanations that do not
faithfully reflect the factors driving their predictions. In healthcare
settings, such unfaithfulness is especially problematic: explanations that omit
salient clinical cues or mask spurious shortcuts can undermine clinician trust
and lead to unsafe decision support. We study how inference and training-time
choices shape explanation faithfulness, focusing on factors practitioners can
control at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA
8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),
and manipulate the number and type of few-shot examples, prompting strategies,
and training procedure. Our results show: (i) both the quantity and quality of
few-shot examples significantly impact model faithfulness; (ii) faithfulness is
sensitive to prompting design; (iii) the instruction-tuning phase improves
measured faithfulness on MedQA. These findings offer insights into strategies
for enhancing the interpretability and trustworthiness of LLMs in sensitive
domains.

</details>


### [39] [Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations](https://arxiv.org/abs/2510.24247)
*Ahmad Ghannam,Naif Alharthi,Faris Alasmary,Kholood Al Tabash,Shouq Sadah,Lahouari Ghouti*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本和语音信息的阿拉伯方言加元音符号还原模型，利用多模态融合提升准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言的加元音符号还原任务具有挑战性，单一文本信息难以准确恢复，结合语音信息有望提升性能。

Method: 采用文本编码器（CATT）和语音编码器（OpenAI Whisper基模型），设计两种融合策略：早期融合和基于交叉注意力的融合，并通过训练时随机停用语音输入增强模型鲁棒性。

Result: 在开发集上，模型实现了词错误率0.25和字符错误率0.9；测试集上，词错误率为0.55，字符错误率为0.13。

Conclusion: 结合文本与语音的多模态方法有效提升了阿拉伯方言加元音符号还原任务的性能，且具有较好的鲁棒性。

Abstract: In this work, we tackle the Diacritic Restoration (DR) task for Arabic
dialectal sentences using a multimodal approach that combines both textual and
speech information. We propose a model that represents the text modality using
an encoder extracted from our own pre-trained model named CATT. The speech
component is handled by the encoder module of the OpenAI Whisper base model.
Our solution is designed following two integration strategies. The former
consists of fusing the speech tokens with the input at an early stage, where
the 1500 frames of the audio segment are averaged over 10 consecutive frames,
resulting in 150 speech tokens. To ensure embedding compatibility, these
averaged tokens are processed through a linear projection layer prior to
merging them with the text tokens. Contextual encoding is guaranteed by the
CATT encoder module. The latter strategy relies on cross-attention, where text
and speech embeddings are fused. The cross-attention output is then fed to the
CATT classification head for token-level diacritic prediction. To further
improve model robustness, we randomly deactivate the speech input during
training, allowing the model to perform well with or without speech. Our
experiments show that the proposed approach achieves a word error rate (WER) of
0.25 and a character error rate (CER) of 0.9 on the development set. On the
test set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.

</details>


### [40] [Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations](https://arxiv.org/abs/2510.24250)
*Syed Zohaib Hassan,Pål Halvorsen,Miriam S. Johnson,Pierre Lison*

Main category: cs.CL

TL;DR: 本文比较了五种大型语言模型在生成适龄儿童（5岁和9岁）挪威语对话中的表现。通过教育专家的盲评，发现模型在较小年龄组的预测准确性较高，但大多数模型生成的语言偏向更成熟。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型主要基于成人对话数据训练，生成真实儿童对话存在挑战，尤其是在专门应用和低资源语言环境下。

Method: 选取五种大型语言模型生成5岁和9岁儿童挪威语对话文本，邀请11名教育专家进行盲评，基于真实儿童面试数据对生成文本的真实性和发展适龄性进行评估。

Result: 评估者表现出较高的一致性（ICC=0.75），对5岁儿童的年龄预测准确性高于9岁组。GPT-4和NorBloom-7b表现较好，大多数模型生成的语言相比目标年龄更成熟。

Conclusion: 在儿童专用对话生成中，尤其是低资源语言环境中，数据相关问题对LLM的性能影响显著，强调了开发适龄儿童对话系统时需要关注数据的针对性和充分性。

Abstract: Large Language Models (LLMs), predominantly trained on adult conversational
data, face significant challenges when generating authentic, child-like
dialogue for specialized applications. We present a comparative study
evaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,
and NorBloom-7b) to generate age-appropriate Norwegian conversations for
children aged 5 and 9 years. Through a blind evaluation by eleven education
professionals using both real child interview data and LLM-generated text
samples, we assessed authenticity and developmental appropriateness. Our
results show that evaluators achieved strong inter-rater reliability (ICC=0.75)
and demonstrated higher accuracy in age prediction for younger children
(5-year-olds) compared to older children (9-year-olds). While GPT-4 and
NorBloom-7b performed relatively well, most models generated language perceived
as more linguistically advanced than the target age groups. These findings
highlight critical data-related challenges in developing LLM systems for
specialized applications involving children, particularly in low-resource
languages where comprehensive age-appropriate lexical resources are scarce.

</details>


### [41] [From Memorization to Reasoning in the Spectrum of Loss Curvature](https://arxiv.org/abs/2510.24256)
*Jack Merullo,Srihita Vatsavaya,Lucius Bushnaq,Owen Lewis*

Main category: cs.CL

TL;DR: 本文通过基于损失曲率的权重分解方法，揭示了Transformer模型中记忆的表示形式，并提出了一种有效的权重编辑策略来减少非目标记忆内容，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有理论和实验证明记忆点的损失曲率较锐利，如何利用这一性质分离模型记忆并有效去除未目标记忆数据，提升模型实用性成为研究重点。

Method: 利用损失曲率对Transformer模型权重进行排序和分解，通过抑制高曲率权重分量来实现记忆的权重编辑，并对编辑后对下游任务的影响进行系统分析。

Result: 提出的权重编辑方法比现有的去学习方法（如BalancedSubnet）更有效地减少未目标记忆内容，同时保持较低困惑度；编辑过程中特定任务如事实检索和算术能力明显下降，合理解释了任务依赖于特殊方向的权重。

Conclusion: 该研究加深了对神经网络记忆机制的理解，展示了记忆可以在权重中被区分和编辑，支持了任务相关的特定窄域结构影响模型表现，为记忆去除提供理论和实际指导。

Abstract: We characterize how memorization is represented in transformer models and
show that it can be disentangled in the weights of both language models (LMs)
and vision transformers (ViTs) using a decomposition based on the loss
landscape curvature. This insight is based on prior theoretical and empirical
work showing that the curvature for memorized training points is much sharper
than non memorized, meaning ordering weight components from high to low
curvature can reveal a distinction without explicit labels. This motivates a
weight editing procedure that suppresses far more recitation of untargeted
memorized data more effectively than a recent unlearning method
(BalancedSubnet), while maintaining lower perplexity. Since the basis of
curvature has a natural interpretation for shared structure in model weights,
we analyze the editing procedure extensively on its effect on downstream tasks
in LMs, and find that fact retrieval and arithmetic are specifically and
consistently negatively affected, even though open book fact retrieval and
general logical reasoning is conserved. We posit these tasks rely heavily on
specialized directions in weight space rather than general purpose mechanisms,
regardless of whether those individual datapoints are memorized. We support
this by showing a correspondence between task data's activation strength with
low curvature components that we edit out, and the drop in task performance
after the edit. Our work enhances the understanding of memorization in neural
networks with practical applications towards removing it, and provides evidence
for idiosyncratic, narrowly-used structures involved in solving tasks like math
and fact retrieval.

</details>


### [42] [Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?](https://arxiv.org/abs/2510.24259)
*Ziqi Ma,Sao Mai Nguyen,Philippe Xu*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型能否将自然语言指令转换为层级强化学习中的符号表示，发现其受任务复杂度和符号粒度影响较大，存在表示对齐的局限性。


<details>
  <summary>Details</summary>
Motivation: 促进学习代理通过符号表示更好地规划和泛化任务，探索大型语言模型在自然语言与内部符号表示转换中的能力。

Method: 设计结构化评估框架，比较多种大型语言模型（GPT、Claude、Deepseek、Grok）对强化学习中符号分割的翻译表现，测试环境为Ant Maze和Ant Fall。

Result: 发现大型语言模型具备一定的翻译能力但表现受符号粒度和任务复杂度影响显著，存在表示对齐的限制。

Conclusion: 当前大型语言模型在语言与内部符号表示对齐方面能力有限，需进一步研究以实现更稳健的表示对齐。

Abstract: Emergent symbolic representations are critical for enabling developmental
learning agents to plan and generalize across tasks. In this work, we
investigate whether large language models (LLMs) can translate human natural
language instructions into the internal symbolic representations that emerge
during hierarchical reinforcement learning. We apply a structured evaluation
framework to measure the translation performance of commonly seen LLMs -- GPT,
Claude, Deepseek and Grok -- across different internal symbolic partitions
generated by a hierarchical reinforcement learning algorithm in the Ant Maze
and Ant Fall environments. Our findings reveal that although LLMs demonstrate
some ability to translate natural language into a symbolic representation of
the environment dynamics, their performance is highly sensitive to partition
granularity and task complexity. The results expose limitations in current LLMs
capacity for representation alignment, highlighting the need for further
research on robust alignment between language and internal agent
representations.

</details>


### [43] [MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference](https://arxiv.org/abs/2510.24295)
*Mădălina Zgreabăn,Tejaswini Deoskar,Lasha Abzianidze*

Main category: cs.CL

TL;DR: 本文提出了一种自动生成自然语言推理(NLI)问题高质量变体的方法，即MERGE，通过替换开放类词汇但保持推理不变，评估模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有NLI模型在泛化基准测试中表现出鲁棒性不足，而手动构建新的基准测试成本高昂，自动生成高质量测试难度大。

Method: 提出MERGE方法：通过最小表达替换，替换原问题中的开放类词汇，生成保持推理逻辑不变的NLI变体，用以测试模型泛化能力。

Result: 实验表明，NLI模型在经过最小变换的变体上性能下降4-20%，表明模型泛化能力较弱。分析了替换词汇类别、词频及合理性对模型表现的影响。

Conclusion: MERGE方法有效揭示了当前NLI模型在轻微变动下的泛化不足，强调了提升模型鲁棒性和泛化能力的重要性。

Abstract: In recent years, many generalization benchmarks have shown language models'
lack of robustness in natural language inference (NLI). However, manually
creating new benchmarks is costly, while automatically generating high-quality
ones, even by modifying existing benchmarks, is extremely difficult. In this
paper, we propose a methodology for automatically generating high-quality
variants of original NLI problems by replacing open-class words, while
crucially preserving their underlying reasoning. We dub our generalization test
as MERGE (Minimal Expression-Replacements GEneralization), which evaluates the
correctness of models' predictions across reasoning-preserving variants of the
original problem. Our results show that NLI models' perform 4-20% worse on
variants, suggesting low generalizability even on such minimally altered
problems. We also analyse how word class of the replacements, word probability,
and plausibility influence NLI models' performance.

</details>


### [44] [Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2510.24302)
*Shangyu Xing,Siyuan Wang,Chenyuan Yang,Xinyu Dai,Xiang Ren*

Main category: cs.CL

TL;DR: 本文提出了一种新的强化学习采样策略——前瞻树形展开（LATR），旨在提升大语言模型推理能力中的采样多样性，从而加速策略学习并提高性能。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习中，由于基于组的策略优化（如GRPO）在采样轨迹时存在多样性不足的问题，导致回报信号减弱，影响策略更新效果。主要原因是基于token层面的随机采样，容易产生近似相同的推理路径。

Method: 提出LATR方法，在高不确定性生成步骤进行分支，针对每个分支执行前瞻仿真，并剪枝在仿真过程中展现出长时间相似性的分支，从而显著增加轨迹层次的多样性。

Result: 与随机采样相比，LATR平均加速政策学习131%，并在GRPO和DAPO算法下的多个推理任务中将最终pass@1性能提升4.2%。

Conclusion: LATR有效解决了RLVR中采样多样性不足的问题，提升了强化学习在大语言模型推理任务中的效率和性能。方法及数据已开源。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), particularly with
algorithms like Group Relative Policy Optimization (GRPO), has proven highly
effective in enhancing the reasoning capabilities of large language models.
However, a critical bottleneck in current pipelines lies in the limited
diversity of sampled trajectories during group rollouts. Homogeneous
trajectories and their associated rewards would diminish the return signals for
policy updates, thereby hindering effective policy learning. This lack of
diversity stems primarily from token-level stochastic sampling, where local
variations are likely to collapse into near-identical reasoning paths. To
address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a
novel rollout strategy designed to explicitly promotes trajectory-level
diversity by enforcing branching into different candidate tokens likely to
yield distinct continuations. Specifically, LATR iteratively operates in three
stages: (1) branching at high-uncertainty generation steps, (2) performing
lookahead simulation for each new branch, and (3) pruning branches that
exhibits prolonged similarity during simulation. Compared with stochastic
Sampling, LATR accelerates policy learning by 131% on average and improves
final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy
Optimization (DAPO) algorithms across different reasoning tasks. Our code and
data are publicly available at https://github.com/starreeze/latr.

</details>


### [45] [Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning](https://arxiv.org/abs/2510.24320)
*Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 本文提出了Critique-RL，一种无需强监督的在线强化学习方法，通过双角色（生成者与批评者）模型来提升大语言模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有批评语言模型训练依赖强监督资源，而这限制了其应用和效果提升。

Method: Critique-RL采用两阶段优化，第一阶段通过规则奖励提升批评者的判别能力，第二阶段基于生成者改进引入间接奖励提升批评的建设性，同时保持判别能力。

Result: 在多任务和多模型测试中，Critique-RL显著提升了模型性能，比如在Qwen2.5-7B模型上域内任务提升9.02%，域外任务提升5.70%。

Conclusion: Critique-RL有效解决了批评模型训练中判别力不足的问题，提升了语言模型复杂推理任务的表现，展示了无强监督批评训练的潜力。

Abstract: Training critiquing language models to assess and provide feedback on model
outputs is a promising way to improve LLMs for complex reasoning tasks.
However, existing approaches typically rely on stronger supervisors for
annotating critique data. To address this, we propose Critique-RL, an online RL
approach for developing critiquing language models without stronger
supervision. Our approach operates on a two-player paradigm: the actor
generates a response, the critic provides feedback, and the actor refines the
response accordingly. We first reveal that relying solely on indirect reward
signals from the actor's outputs for RL optimization often leads to
unsatisfactory critics: while their helpfulness (i.e., providing constructive
feedback) improves, the discriminability (i.e., determining whether a response
is high-quality or not) remains poor, resulting in marginal performance gains.
To overcome this, Critique-RL adopts a two-stage optimization strategy. In
stage I, it reinforces the discriminability of the critic with direct
rule-based reward signals; in stage II, it introduces indirect rewards based on
actor refinement to improve the critic's helpfulness, while maintaining its
discriminability via appropriate regularization. Extensive experiments across
various tasks and models show that Critique-RL delivers substantial performance
improvements. For example, it achieves a 9.02% gain on in-domain tasks and a
5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.

</details>


### [46] [Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants](https://arxiv.org/abs/2510.24328)
*Hunzalah Hassan Bhatti,Firoj Alam*

Main category: cs.CL

TL;DR: 该论文提出一种方法，将标准阿拉伯语的选择题翻译成多种阿拉伯方言和英语，转换为开放式问题，并使用多种大语言模型进行基准测试，结合链式思维法优化模型表现。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在处理文化背景和方言内容上表现不均衡，尤其是阿拉伯语的方言内容缺乏有效评估数据和方法。

Method: 将标准阿拉伯语的选择题翻译成英语和多种阿拉伯方言，转换成开放式问题，比较零样本和微调模型在选择题和开放题上的表现，并通过生成链式思维理由微调模型以提升逐步推理能力。

Result: 模型在阿拉伯方言上的表现较差，阿拉伯语中心模型在选择题上表现良好但开放式问题上表现不足，链式思维微调提升了正确率但基于n-gram的指标表现不一。

Conclusion: 所开发的多语言、多方言平行数据集为文化和语言包容性评估提供了新工具，有助于推动相关领域的进一步研究。

Abstract: Large Language Models (LLMs) are increasingly used to answer everyday
questions, yet their performance on culturally grounded and dialectal content
remains uneven across languages. We propose a comprehensive method that (i)
translates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into
English and several Arabic dialects, (ii) converts them into open-ended
questions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs
under both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)
rationales to fine-tune models for step-by-step reasoning. Using this method,
we extend an existing dataset in which QAs are parallelly aligned across
multiple language varieties, making it, to our knowledge, the first of its
kind. We conduct extensive experiments with both open and closed models. Our
findings show that (i) models underperform on Arabic dialects, revealing
persistent gaps in culturally grounded and dialect-specific knowledge; (ii)
Arabic-centric models perform well on MCQs but struggle with OEQs; and (iii)
CoT improves judged correctness while yielding mixed n-gram-based metrics. The
developed dataset will be publicly released to support further research on
culturally and linguistically inclusive evaluation.

</details>


### [47] [LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability](https://arxiv.org/abs/2510.24345)
*Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin*

Main category: cs.CL

TL;DR: LongWeave提出了一种结合现实场景和可验证评估的新方法，旨在评估大型语言模型在长文本生成方面的能力，结果显示即使是最先进的模型也存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的长文本生成基准测试在评估长文本生成质量时要么依赖难以验证的指标，要么使用简化的合成环境，缺乏对现实世界复杂性的充分考量。

Method: 提出LongWeave框架，利用Constraint-Verifier Evaluation(CoV-Eval)方法，设计包含可验证目标的真实场景任务，系统生成查询、文本材料和约束条件，支持可定制的输入输出长度。

Result: 在23个大型语言模型上评估，发现随着现实复杂性和输出长度增加，模型在长文本生成任务中的表现显著下降，存在较大挑战。

Conclusion: LongWeave为长文本生成评估提供了现实性与客观性兼具的标准，揭示了当前大型语言模型在应对复杂约束和长文本输出方面的不足，未来模型改进仍需重点突破这方面问题。

Abstract: Generating long, informative, and factual outputs remains a major challenge
for Large Language Models (LLMs). Existing benchmarks for long-form generation
typically assess real-world queries with hard-to-verify metrics or use
synthetic setups that ease evaluation but overlook real-world intricacies. In
this paper, we introduce \textbf{LongWeave}, which balances real-world and
verifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval
constructs tasks by first defining verifiable targets within real-world
scenarios, then systematically generating corresponding queries, textual
materials, and constraints based on these targets. This ensures that tasks are
both realistic and objectively assessable, enabling rigorous assessment of
model capabilities in meeting complex real-world constraints. LongWeave
supports customizable input/output lengths (up to 64K/8K tokens) across seven
distinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models
encounter significant challenges in long-form generation as real-world
complexity and output length increase.

</details>


### [48] [Text Simplification with Sentence Embeddings](https://arxiv.org/abs/2510.24365)
*Matthew Shardlow*

Main category: cs.CL

TL;DR: 论文通过学习句子嵌入空间的变换，实现文本复杂度的简化，展示了在小规模神经网络和多语言数据上的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用句子嵌入解码来保留并调整文本复杂度，推动文本简化研究。

Method: 使用小型前馈神经网络学习高复杂度与低复杂度句子嵌入之间的变换，并与Seq2Seq及大型语言模型方法进行比较。

Result: 示范了该方法在未见简化数据集（MedEASI）及西班牙语和德语数据集上的有效性，表现优于小规模模型的预期。

Conclusion: 在句子嵌入空间学习变换是文本简化和自然语言生成领域一个有前景的方向，可开发小型且高效的模型。

Abstract: Sentence embeddings can be decoded to give approximations of the original
texts used to create them. We explore this effect in the context of text
simplification, demonstrating that reconstructed text embeddings preserve
complexity levels. We experiment with a small feed forward neural network to
effectively learn a transformation between sentence embeddings representing
high-complexity and low-complexity texts. We provide comparison to a Seq2Seq
and LLM-based approach, showing encouraging results in our much smaller
learning setting. Finally, we demonstrate the applicability of our
transformation to an unseen simplification dataset (MedEASI), as well as
datasets from languages outside the training data (ES,DE). We conclude that
learning transformations in sentence embedding space is a promising direction
for future research and has potential to unlock the ability to develop small,
but powerful models for text simplification and other natural language
generation tasks.

</details>


### [49] [Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models](https://arxiv.org/abs/2510.24425)
*Guangyu Xie,Yice Zhang,Jianzhu Bao,Qianlong Wang,Yang Sun,Bingbing Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出了一个名为COMPEFFDIST的高效知识蒸馏框架，用于轻量化情感分析模型的训练，实现3B参数模型达到20倍大模型性能，且数据效率提升至仅需10%的数据量。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识蒸馏的情感分析方法依赖数量和多样性有限的手写指令与计算成本高的大规模用户文本，导致覆盖不足和效率低下。

Method: 引入基于属性的自动指令构造和基于难度的数据过滤两大模块，分别解决指令多样性不足和大规模数据计算成本问题。

Result: 在多个模型系列（Llama-3、Qwen-3、Gemma-3）上，3B学生模型性能媲美20倍大模型，并显著优于基线方法，数据使用量仅为10%。

Conclusion: COMPEFFDIST框架有效提升了情感分析知识蒸馏的效率和性能，推动轻量级模型的实用化。

Abstract: Recent efforts leverage knowledge distillation techniques to develop
lightweight and practical sentiment analysis models. These methods are grounded
in human-written instructions and large-scale user texts. Despite the promising
results, two key challenges remain: (1) manually written instructions are
limited in diversity and quantity, making them insufficient to ensure
comprehensive coverage of distilled knowledge; (2) large-scale user texts incur
high computational cost, hindering the practicality of these methods. To this
end, we introduce COMPEFFDIST, a comprehensive and efficient distillation
framework for sentiment analysis. Our framework consists of two key modules:
attribute-based automatic instruction construction and difficulty-based data
filtering, which correspondingly tackle the aforementioned challenges. Applying
our method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we
enable 3B student models to match the performance of 20x larger teacher models
on most tasks. In addition, our approach greatly outperforms baseline methods
in data efficiency, attaining the same performance level with only 10% of the
data.

</details>


### [50] [SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models](https://arxiv.org/abs/2510.24427)
*Ken Gu,Advait Bhat,Mike A Merrill,Robert West,Xin Liu,Daniel McDuff,Tim Althoff*

Main category: cs.CL

TL;DR: 本文提出了SynthWorlds框架，用以区分语言模型的推理能力和事实知识记忆，设计了两个等难度的平行任务，通过实验验证了记忆知识带来的性能提升，并指出了当前模型在知识整合上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前评估语言模型推理能力时，难以剥离模型记忆的事实知识，现有方法无法有效区分推理和记忆表现。

Method: 构建两个具有相同结构的平行语料库（真实映射世界和合成映射世界），设计多跳问答和页面导航两个任务，保持推理难度一致，通过对比两者表现分离记忆与推理能力。

Result: 实验结果显示存在显著的知识优势差距，模型依赖记忆知识获得性能提升，而知识获取和整合机制虽有所改善，但无法完全消除该差距。

Conclusion: SynthWorlds框架为评估语言模型的推理与记忆能力提供了可控环境，促进对两者进行精确测试和比较，有助于系统性能提升。

Abstract: Evaluating the reasoning ability of language models (LMs) is complicated by
their extensive parametric world knowledge, where benchmark performance often
reflects factual recall rather than genuine reasoning. Existing datasets and
approaches (e.g., temporal filtering, paraphrasing, adversarial substitution)
cannot cleanly separate the two. We present SynthWorlds, a framework that
disentangles task reasoning complexity from factual knowledge. In SynthWorlds,
we construct parallel corpora representing two worlds with identical
interconnected structure: a real-mapped world, where models may exploit
parametric knowledge, and a synthetic-mapped world, where such knowledge is
meaningless. On top of these corpora, we design two mirrored tasks as case
studies: multi-hop question answering and page navigation, which maintain equal
reasoning difficulty across worlds. Experiments in parametric-only (e.g.,
closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings
reveal a persistent knowledge advantage gap, defined as the performance boost
models gain from memorized parametric world knowledge. Knowledge acquisition
and integration mechanisms reduce but do not eliminate this gap, highlighting
opportunities for system improvements. Fully automatic and scalable,
SynthWorlds provides a controlled environment for evaluating LMs in ways that
were previously challenging, enabling precise and testable comparisons of
reasoning and memorization.

</details>


### [51] [LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data](https://arxiv.org/abs/2510.24434)
*Julian Valline,Cedric Lothritz,Jordi Cabot*

Main category: cs.CL

TL;DR: LuxIT是针对卢森堡语的单语指令调优数据集，旨在提升低资源语言环境中大型语言模型的效果。


<details>
  <summary>Details</summary>
Motivation: 由于高质量训练数据匮乏，低资源语言如卢森堡语的指令调优大型语言模型效果受限，需开发专门数据集。

Method: 利用DeepSeek-R1-0528模型合成基于卢森堡语原生文本的LuxIT数据集，并采用LLM评判机制进行质量保证。

Result: 针对LuxIT微调的小型模型在卢森堡语语言能力测评中的表现参差不齐，效果不一。

Conclusion: LuxIT为卢森堡语自然语言处理提供重要资源和可复制方法，但需进一步研究以提升其实际应用效果。

Abstract: The effectiveness of instruction-tuned Large Language Models (LLMs) is often
limited in low-resource linguistic settings due to a lack of high-quality
training data. We introduce LuxIT, a novel, monolingual instruction tuning
dataset for Luxembourgish developed to mitigate this challenge. We synthesize
the dataset from a corpus of native Luxembourgish texts, utilizing
DeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following
generation, we apply a quality assurance process, employing an LLM-as-a-judge
approach. To investigate the practical utility of the dataset, we fine-tune
several smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base
models on Luxembourgish language proficiency examinations, however, yields
mixed results, with performance varying significantly across different models.
LuxIT represents a critical contribution to Luxembourgish natural language
processing and offers a replicable monolingual methodology, though our findings
highlight the need for further research to optimize its application.

</details>


### [52] [SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](https://arxiv.org/abs/2510.24446)
*Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CL

TL;DR: 本文提出了一种新的对抗性改写任务，生成语法正确且保留原意的文本改写以破坏视觉语言模型的分割性能，并提出了SPARTA方法进行优化，验证了当前模型在此任务下的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注图像输入的扰动，而在实际应用中，用户用不同方式表达同一意图，语义等价的文本改写尚未得到充分研究。

Method: 提出了一种基于文本自编码器语义潜变量空间，利用强化学习指导的黑盒句子级优化方法SPARTA，用于生成对抗性文本改写；并设计了综合自动评估协议结合人工验证。

Result: SPARTA在ReasonSeg和LLMSeg-40k数据集上成功率较以往方法提升约2倍，显示出更强的攻击能力。基于SPARTA和竞争性基线评估，现有推理分割模型对对抗性文本改写仍有明显脆弱性。

Conclusion: 多模态大语言模型在推理分割任务中存在对语义等价文本改写的脆弱性，提出的方法为提升模型鲁棒性提供了有力工具，未来工作需加强模型对文本多样表达的适应能力。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
in vision-language tasks such as reasoning segmentation, where models generate
segmentation masks based on textual queries. While prior work has primarily
focused on perturbing image inputs, semantically equivalent textual
paraphrases-crucial in real-world applications where users express the same
intent in varied ways-remain underexplored. To address this gap, we introduce a
novel adversarial paraphrasing task: generating grammatically correct
paraphrases that preserve the original query meaning while degrading
segmentation performance. To evaluate the quality of adversarial paraphrases,
we develop a comprehensive automatic evaluation protocol validated with human
studies. Furthermore, we introduce SPARTA-a black-box, sentence-level
optimization method that operates in the low-dimensional semantic latent space
of a text autoencoder, guided by reinforcement learning. SPARTA achieves
significantly higher success rates, outperforming prior methods by up to 2x on
both the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive
baselines to assess the robustness of advanced reasoning segmentation models.
We reveal that they remain vulnerable to adversarial paraphrasing-even under
strict semantic and grammatical constraints. All code and data will be released
publicly upon acceptance.

</details>


### [53] [Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices](https://arxiv.org/abs/2510.24450)
*Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文概述了大型语言模型基准测试的最新进展，提出了针对多语言或非英语场景的基准分类方法，并建议欧洲语言基准测试的发展应注重语言和文化的敏感性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能力的提升，如何有效地在非英语语言环境中使用和评估这些模型依然缺乏系统研究。

Method: 本文回顾了现有大型语言模型基准测试的发展，提出了适用于多语言环境的基准分类法，并制定了一系列高质量标准与最佳实践。

Result: 基于新的分类法和标准，推动了更协调的欧洲语言基准测试发展，并强调评测方法需要更好地适应不同语言和文化特点。

Conclusion: 通过引入多语言专用的基准测试框架和提升评测的语言文化敏感度，能够促进大型语言模型在非英语环境中的有效评估和公平发展。

Abstract: While new benchmarks for large language models (LLMs) are being developed
continuously to catch up with the growing capabilities of new models and AI in
general, using and evaluating LLMs in non-English languages remains a
little-charted landscape. We give a concise overview of recent developments in
LLM benchmarking, and then propose a new taxonomy for the categorization of
benchmarks that is tailored to multilingual or non-English use scenarios. We
further propose a set of best practices and quality standards that could lead
to a more coordinated development of benchmarks for European languages. Among
other recommendations, we advocate for a higher language and culture
sensitivity of evaluation methods.

</details>


### [54] [Iterative Critique-Refine Framework for Enhancing LLM Personalization](https://arxiv.org/abs/2510.24469)
*Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed*

Main category: cs.CL

TL;DR: 本文提出了PerFine，一个无需训练的基于迭代反馈的个性化文本生成框架，通过引入批判者模型对生成文本在语气、词汇、句式和主题等方面进行反馈，显著提升个性化效果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法如LaMP和PGraphRAG虽然利用用户及邻居的历史数据丰富用户画像，但生成文本容易在语气、主题和风格上偏离目标用户，难以实现精确个性化。

Method: PerFine采用迭代的生成-批判-修改流程，使用大型语言模型生成草稿，另一个语言模型基于同一用户画像对草稿的多个维度进行结构化反馈，生成器据此修订文本，并通过一种新颖的knockout策略在迭代中保留最优文本。

Result: 在Yelp、Goodreads和Amazon数据集上，PerFine相比PGraphRAG在个性化指标上提升了7-13%，且在3-5轮迭代中持续改进，随着批判者模型规模增大性能进一步提升。

Conclusion: PerFine展示了后期基于用户画像的反馈机制在个性化文本生成中的强大作用，该方法无需训练且对模型无特定依赖，具备良好的扩展性和实用价值。

Abstract: Personalized text generation requires models not only to produce coherent
text but also to align with a target user's style, tone, and topical focus.
Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich
profiles with user and neighbor histories, but they stop at generation and
often yield outputs that drift in tone, topic, or style. We present PerFine, a
unified, training-free critique-refine framework that enhances personalization
through iterative, profile-grounded feedback. In each iteration, an LLM
generator produces a draft conditioned on the retrieved profile, and a critic
LLM - also conditioned on the same profile - provides structured feedback on
tone, vocabulary, sentence structure, and topicality. The generator then
revises, while a novel knockout strategy retains the stronger draft across
iterations. We further study additional inference-time strategies such as
Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,
Goodreads, and Amazon datasets, PerFine consistently improves personalization
over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5
refinement iterations, and scalability with increasing critic size. These
results highlight that post-hoc, profile-aware feedback offers a powerful
paradigm for personalized LLM generation that is both training-free and
model-agnostic.

</details>


### [55] [Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems](https://arxiv.org/abs/2510.24476)
*Yihan Li,Xiyuan Fu,Ghanshyam Verma,Paul Buitelaar,Mingming Liu*

Main category: cs.CL

TL;DR: 本文综述了利用检索增强生成（RAG）和推理增强方法缓解大语言模型幻觉的问题，提出了知识型和逻辑型幻觉的分类，并分析了两种方法及其结合在实际应用中的效果。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型部署面临幻觉问题，需从提升创造性和可靠性角度寻找有效缓解策略。

Method: 从应用视角出发，构建知识型和逻辑型幻觉分类体系，系统分析RAG和推理增强技术的减幻觉机制及其在Agentic系统中的整合。

Result: 总结了RAG和推理增强在不同幻觉类型上的作用，提出了统一框架，并通过实际应用和评测验证其有效性。

Conclusion: RAG与推理增强的协同应用是缓解大语言模型幻觉的有效策略，有助于提升模型的可靠性与实用性。

Abstract: Hallucination remains one of the key obstacles to the reliable deployment of
large language models (LLMs), particularly in real-world applications. Among
various mitigation strategies, Retrieval-Augmented Generation (RAG) and
reasoning enhancement have emerged as two of the most effective and widely
adopted approaches, marking a shift from merely suppressing hallucinations to
balancing creativity and reliability. However, their synergistic potential and
underlying mechanisms for hallucination mitigation have not yet been
systematically examined. This survey adopts an application-oriented perspective
of capability enhancement to analyze how RAG, reasoning enhancement, and their
integration in Agentic Systems mitigate hallucinations. We propose a taxonomy
distinguishing knowledge-based and logic-based hallucinations, systematically
examine how RAG and reasoning address each, and present a unified framework
supported by real-world applications, evaluations, and benchmarks.

</details>


### [56] [Talk2Ref: A Dataset for Reference Prediction from Scientific Talks](https://arxiv.org/abs/2510.24478)
*Frederik Broy,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出了一个新的任务——从科学演讲中自动识别相关文献，构建了第一个大规模数据集Talk2Ref，包含6279个演讲和43429篇引用论文，建立了强基线并设计了双编码器模型进行优化。


<details>
  <summary>Details</summary>
Motivation: 科学演讲作为传播研究成果的重要媒介，自动识别支撑或丰富演讲内容的相关文献，对于研究者和学生具有重要价值。

Method: 构建了包含大量演讲及其引用论文的Talk2Ref数据集，评估了多种文本嵌入模型，设计并训练了基于双编码器的模型，探索了处理长篇演讲文本和领域适应的策略。

Result: 在Talk2Ref数据集上进行微调显著提升了引用预测性能，证明了任务的挑战性和数据集对从口语科学内容中学习语义表示的有效性。

Conclusion: 提出的任务和数据集为研究将口语科学传播与文献推荐系统结合提供了基础，开放发布资源促进未来相关研究。

Abstract: Scientific talks are a growing medium for disseminating research, and
automatically identifying relevant literature that grounds or enriches a talk
would be highly valuable for researchers and students alike. We introduce
Reference Prediction from Talks (RPT), a new task that maps long, and
unstructured scientific presentations to relevant papers. To support research
on RPT, we present Talk2Ref, the first large-scale dataset of its kind,
containing 6,279 talks and 43,429 cited papers (26 per talk on average), where
relevance is approximated by the papers cited in the talk's corresponding
source publication. We establish strong baselines by evaluating
state-of-the-art text embedding models in zero-shot retrieval scenarios, and
propose a dual-encoder architecture trained on Talk2Ref. We further explore
strategies for handling long transcripts, as well as training for domain
adaptation. Our results show that fine-tuning on Talk2Ref significantly
improves citation prediction performance, demonstrating both the challenges of
the task and the effectiveness of our dataset for learning semantic
representations from spoken scientific content. The dataset and trained models
are released under an open license to foster future research on integrating
spoken scientific communication into citation recommendation systems.

</details>


### [57] [A word association network methodology for evaluating implicit biases in LLMs compared to humans](https://arxiv.org/abs/2510.24488)
*Katherine Abramski,Giulio Rossetti,Massimo Stella*

Main category: cs.CL

TL;DR: 本文提出了一种基于词语联想网络模拟语义启动的评估大语言模型隐性偏见的新方法，能够定量和定性地比较模型与人类的社会偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，其隐性社会偏见成为亟需解决的问题。现有方法难以评估模型隐含的偏见知识，需发展能反映模型隐性认知结构的评估手段。

Method: 本文设计了一种基于提示词触发的词语联想网络构建和语义启动模拟方法，从模型输出的联想词中提取隐性偏见信息，同时支持人与模型间的直接比较。

Result: 通过对多型号大语言模型和人类样本进行性别、宗教、族裔、性取向及政治等偏见测试，发现模型与人类偏见既有相似也有差异，展现了模型潜在风险。

Conclusion: 该方法构建了一个系统性、可扩展、可推广的框架，助力多模型和人类偏见的评估与比较，促进语言技术的透明化和社会责任。

Abstract: As Large language models (LLMs) become increasingly integrated into our
lives, their inherent social biases remain a pressing concern. Detecting and
evaluating these biases can be challenging because they are often implicit
rather than explicit in nature, so developing evaluation methods that assess
the implicit knowledge representations of LLMs is essential. We present a novel
word association network methodology for evaluating implicit biases in LLMs
based on simulating semantic priming within LLM-generated word association
networks. Our prompt-based approach taps into the implicit relational
structures encoded in LLMs, providing both quantitative and qualitative
assessments of bias. Unlike most prompt-based evaluation methods, our method
enables direct comparisons between various LLMs and humans, providing a
valuable point of reference and offering new insights into the alignment of
LLMs with human cognition. To demonstrate the utility of our methodology, we
apply it to both humans and several widely used LLMs to investigate social
biases related to gender, religion, ethnicity, sexual orientation, and
political party. Our results reveal both convergences and divergences between
LLM and human biases, providing new perspectives on the potential risks of
using LLMs. Our methodology contributes to a systematic, scalable, and
generalizable framework for evaluating and comparing biases across multiple
LLMs and humans, advancing the goal of transparent and socially responsible
language technologies.

</details>


### [58] [CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?](https://arxiv.org/abs/2510.24505)
*Qing Zong,Jiayu Liu,Tianshi Zheng,Chunyang Li,Baixuan Xu,Haochen Shi,Weiqi Wang,Zhaowei Wang,Chunkit Chan,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文提出了利用自然语言批评来提高大语言模型的置信度校准，提出自我批评和批评校准训练两种方法，并证明了批评校准方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域中，准确的置信度校准对用户信任至关重要，但传统模拟置信表达的方法无法有效反映模型的推理过程和实际置信度。

Method: 研究了批评内容应聚焦于不确定性还是置信度，提出自我批评（Self-Critique）和批评校准训练（CritiCal）两种方法，后者利用自然语言批评超越数值优化进行置信度校准。

Result: 实验表明，CritiCal方法显著优于自我批评和其他基线方法，甚至在复杂推理任务中超过了GPT-4o模型，并在分布外设定中表现出强健的泛化能力。

Conclusion: 自然语言批评是提升大语言模型置信度校准的有效策略，CritiCal方法推动了LLM的可靠性和安全性，适合高风险应用场景。

Abstract: Accurate confidence calibration in Large Language Models (LLMs) is critical
for safe use in high-stakes domains, where clear verbalized confidence enhances
user trust. Traditional methods that mimic reference confidence expressions
often fail to capture the reasoning needed for accurate confidence assessment.
We propose natural language critiques as a solution, ideally suited for
confidence calibration, as precise gold confidence labels are hard to obtain
and often require multiple generations. This paper studies how natural language
critiques can enhance verbalized confidence, addressing: (1) What to critique:
uncertainty (question-focused) or confidence (answer-specific)? Analysis shows
confidence suits multiple-choice tasks, while uncertainty excels in open-ended
scenarios. (2) How to critique: self-critique or critique calibration training?
We propose Self-Critique, enabling LLMs to critique and optimize their
confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration
training method that leverages natural language critiques to improve confidence
calibration, moving beyond direct numerical optimization. Experiments show that
CritiCal significantly outperforms Self-Critique and other competitive
baselines, even surpassing its teacher model, GPT-4o, in complex reasoning
tasks. CritiCal also shows robust generalization in out-of-distribution
settings, advancing LLM's reliability.

</details>


### [59] [Levée d'ambiguïtés par grammaires locales](https://arxiv.org/abs/2510.24530)
*Eric G. C. Laporte*

Main category: cs.CL

TL;DR: 本文提出了一种针对词性标注中保持零遗漏率的消歧方法，并在INTEX系统中实现，强调了局部消歧语法验证需考虑路径交互及多重自动机组合。


<details>
  <summary>Details</summary>
Motivation: 词性歧义在自然语言处理中普遍存在，且词性消歧是词汇标注的主要挑战，尤其在需要保证正确词性标签不被遗漏的应用中。

Method: 基于Silberztein的INTEX系统，本文提出一种消歧方法，强调对局部消歧语法的形式化描述及需验证路径之间交互和多自动机组合的整体性影响。

Result: 指出单独考虑转导器路径或自动机难以预测消歧结果，消歧规则应经过细致测试，确保零遗漏率。

Conclusion: 为实现零遗漏率，消歧局部语法必须严格规范和测试，理论验证与实践应用紧密结合才能有效设计消歧规则。

Abstract: Many words are ambiguous in terms of their part of speech (POS). However,
when a word appears in a text, this ambiguity is generally much reduced.
Disambiguating POS involves using context to reduce the number of POS
associated with words, and is one of the main challenges of lexical tagging.
The problem of labeling words by POS frequently arises in natural language
processing, for example for spelling correction, grammar or style checking,
expression recognition, text-to-speech conversion, text corpus analysis, etc.
Lexical tagging systems are thus useful as an initial component of many natural
language processing systems. A number of recent lexical tagging systems produce
multiple solutions when the text is lexically ambiguous or the uniquely correct
solution cannot be found. These contributions aim to guarantee a zero silence
rate: the correct tag(s) for a word must never be discarded. This objective is
unrealistic for systems that tag each word uniquely. This article concerns a
lexical disambiguation method adapted to the objective of a zero silence rate
and implemented in Silberztein's INTEX system (1993). We present here a formal
description of this method. We show that to verify a local disambiguation
grammar in this framework, it is not sufficient to consider the transducer
paths separately: one needs to verify their interactions. Similarly, if a
combination of multiple transducers is used, the result cannot be predicted by
considering them in isolation. Furthermore, when examining the initial labeling
of a text as produced by INTEX, ideas for disambiguation rules come
spontaneously, but grammatical intuitions may turn out to be inaccurate, often
due to an unforeseen construction or ambiguity. If a zero silence rate is
targeted, local grammars must be carefully tested. This is where a detailed
specification of what a grammar will do once applied to texts would be
necessary.

</details>


### [60] [Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written](https://arxiv.org/abs/2510.24538)
*Venkata S Govindarajan,Laura Biester*

Main category: cs.CL

TL;DR: 本文创建并分析了一个新的来自Bulwer-Lytton电影竞赛的“糟糕”幽默语料库，探讨英文中的“坏”幽默特征。


<details>
  <summary>Details</summary>
Motivation: 文本幽默形式多样，尤其是故意制造的低劣幽默，计算机研究对此理解不足，需深入分析其特点。

Method: 收集并分析Bulwer-Lytton竞赛句子，评估标准幽默检测模型表现，分析其中的文学手法，并对大语言模型生成的竞赛风格句子进行对比研究。

Result: 标准幽默检测模型在该语料库表现不佳，糟糕幽默结合了双关、讽刺、隐喻、元小说及明喻等多种文学手法。大模型虽能模仿形式但过度使用某些手法，产生更多新颖的形容词-名词搭配。

Conclusion: 糟糕幽默具有独特的文学特征，现有幽默检测模型难以准确识别，且大语言模型生成内容存在过度模仿的问题，为幽默计算研究提供了新的数据和分析视角。

Abstract: Textual humor is enormously diverse and computational studies need to account
for this range, including intentionally bad humor. In this paper, we curate and
analyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to
better understand "bad" humor in English. Standard humor detection models
perform poorly on our corpus, and an analysis of literary devices finds that
these sentences combine features common in existing humor datasets (e.g., puns,
irony) with metaphor, metafiction and simile. LLMs prompted to synthesize
contest-style sentences imitate the form but exaggerate the effect by
over-using certain literary devices, and including far more novel
adjective-noun bigrams than human writers. Data, code and analysis are
available at https://github.com/venkatasg/bulwer-lytton

</details>


### [61] [Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts](https://arxiv.org/abs/2510.24541)
*Seyoung Song,Nawon Kim,Songeun Chae,Kiwoong Park,Jiho Jin,Haneul Yoo,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 本文介绍了开放韩文历史语料库，涵盖1300年、6种语言和多种书写系统，包含1800万文档和50亿词条，用于定量分析韩语语言演变及训练语言模型。


<details>
  <summary>Details</summary>
Motivation: 韩语口语与书写形式差异大，且书写系统经历从汉字向韩文字母的重大转变，但相关历史语料资源缺乏，限制了自然语言处理领域对韩语语言演变的研究。

Method: 构建并公开了一个大型的历史韩语语料库，包含1300年间的多种语言与书写系统，涵盖2700年到2025年的大量文献，通过定量分析具体语言变化，如Idu使用、汉字到韩文的过渡及朝韩词汇分化情况。

Result: 发现Idu书写在1860年代达到顶峰后迅速下降；汉字向韩文的转变自1890年开始快速完成；北韩词汇差异导致现代分词器出现高达51倍的未登录词率。

Conclusion: 开放韩文历史语料库为韩语语言演变的量化历时分析奠定基础，也可作为大型语言模型的预训练资源，提升模型对现代韩文中的汉字词汇及古书写系统的理解能力。

Abstract: The history of the Korean language is characterized by a discrepancy between
its spoken and written forms and a pivotal shift from Chinese characters to the
Hangul alphabet. However, this linguistic evolution has remained largely
unexplored in NLP due to a lack of accessible historical corpora. To address
this gap, we introduce the Open Korean Historical Corpus, a large-scale, openly
licensed dataset spanning 1,300 years and 6 languages, as well as
under-represented writing systems like Korean-style Sinitic (Idu) and
Hanja-Hangul mixed script. This corpus contains 18 million documents and 5
billion tokens from 19 sources, ranging from the 7th century to 2025. We
leverage this resource to quantitatively analyze major linguistic shifts: (1)
Idu usage peaked in the 1860s before declining sharply; (2) the transition from
Hanja to Hangul was a rapid transformation starting around 1890; and (3) North
Korea's lexical divergence causes modern tokenizers to produce up to 51 times
higher out-of-vocabulary rates. This work provides a foundational resource for
quantitative diachronic analysis by capturing the history of the Korean
language. Moreover, it can serve as a pre-training corpus for large language
models, potentially improving their understanding of Sino-Korean vocabulary in
modern Hangul as well as archaic writing systems.

</details>


### [62] [BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation](https://arxiv.org/abs/2510.24570)
*Raphaël Bagat,Irina Illina,Emmanuel Vincent*

Main category: cs.CL

TL;DR: 本文提出了BEARD框架，通过无标签数据自监督学习结合知识蒸馏，成功实现了Whisper编码器在专业领域的适应，提高了语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统在标签数据稀缺的领域和低资源场景下表现不足，迫切需要新的方法来提升模型适应性。

Method: 提出BEARD框架，结合BEST-RQ自监督目标和固定教师编码器的知识蒸馏，对Whisper编码器进行训练以适应特定领域的无标签数据。

Result: 在ATCO2空中交通管制领域数据集上，使用大约5000小时无标签数据训练BEARD，结合2小时转录数据微调，使模型性能较微调模型提升12%。

Conclusion: BEARD首次将自监督学习目标应用于Whisper的领域适应，有效克服了标签稀缺问题，提升了ASR系统在专业领域的鲁棒性和准确率。

Abstract: Automatic Speech Recognition (ASR) systems, despite large multilingual
training, struggle in out-of-domain and low-resource scenarios where labeled
data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training
and Distillation), a novel framework designed to adapt Whisper's encoder using
unlabeled data. Unlike traditional self-supervised learning methods, BEARD
uniquely combines a BEST-RQ objective with knowledge distillation from a frozen
teacher encoder, ensuring the encoder's complementarity with the pre-trained
decoder. Our experiments focus on the ATCO2 corpus from the challenging Air
Traffic Control (ATC) communications domain, characterized by non-native
speech, noise, and specialized phraseology. Using about 5,000 hours of
untranscribed speech for BEARD and 2 hours of transcribed speech for
fine-tuning, the proposed approach significantly outperforms previous baseline
and fine-tuned model, achieving a relative improvement of 12% compared to the
fine-tuned model. To the best of our knowledge, this is the first work to use a
self-supervised learning objective for domain adaptation of Whisper.

</details>


### [63] [ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?](https://arxiv.org/abs/2510.24591)
*Christine Ye,Sihan Yuan,Suchetha Cooray,Steven Dillmann,Ian L. V. Roque,Dalya Baron,Philipp Frank,Sergio Martin-Alvarez,Nolan Koblischke,Frank J Qu,Diyi Yang,Risa Wechsler,Ioana Ciuca*

Main category: cs.CL

TL;DR: 本文提出了ReplicationBench框架，用于评估AI科研助理在天体物理学论文复制上的能力，目前最先进的语言模型表现不足20%。


<details>
  <summary>Details</summary>
Motivation: 随着AI科研助理的发展，需要评估其在创新科研中的忠实性和准确性，确保其工作可靠。

Method: 设计ReplicationBench，将天体物理学论文拆分为多个任务，涵盖实验设计、推导、数据分析和代码实现，并与论文作者共同制定，进行客观评估。

Result: 当前顶尖语言模型在该测试中的表现低于20%，并揭示了科学研究中AI助理的多样化失败模式。

Conclusion: ReplicationBench为AI在科学研究中的可靠性提供了首个专家验证的基准框架，能推广至其他数据驱动科学领域，促进AI科研助理的进一步发展。

Abstract: Frontier AI agents show increasing promise as scientific research assistants,
and may eventually be useful for extended, open-ended research workflows.
However, in order to use agents for novel research, we must first assess the
underlying faithfulness and correctness of their work. To evaluate agents as
research assistants, we introduce ReplicationBench, an evaluation framework
that tests whether agents can replicate entire research papers drawn from the
astrophysics literature. Astrophysics, where research relies heavily on
archival data and computational study while requiring little real-world
experimentation, is a particularly useful testbed for AI agents in scientific
research. We split each paper into tasks which require agents to replicate the
paper's core contributions, including the experimental setup, derivations, data
analysis, and codebase. Each task is co-developed with the original paper
authors and targets a key scientific result, enabling objective evaluation of
both faithfulness (adherence to original methods) and correctness (technical
accuracy of results). ReplicationBench is extremely challenging for current
frontier language models: even the best-performing language models score under
20%. We analyze ReplicationBench trajectories in collaboration with domain
experts and find a rich, diverse set of failure modes for agents in scientific
research. ReplicationBench establishes the first benchmark of paper-scale,
expert-validated astrophysics research tasks, reveals insights about agent
performance generalizable to other domains of data-driven science, and provides
a scalable framework for measuring AI agents' reliability in scientific
research.

</details>


### [64] [ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization](https://arxiv.org/abs/2510.24592)
*Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao*

Main category: cs.CL

TL;DR: 本文提出了一种名为ReForm的反思式自动形式化方法，通过语义一致性评估实现自动形式化的迭代生成和自我纠错，在四个基准测试中平均提升17.2个百分点。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在将自然语言数学语句转化为形式化语句时，往往无法保持原问题的语义意图，因为它们仅视自动形式化为简单的翻译任务，缺乏人类专家自然具备的反思和迭代改进机制。

Method: 提出ReForm方法，通过将语义一致性评估紧密整合入自动形式化过程，使模型能够迭代生成形式化语句、自我评估语义一致性并逐步修正错误。采用前瞻有界序列优化(PBSO)训练模型，不同序列位置赋予不同奖励，确保模型同时提高形式化准确度和语义验证能力，避免表面批评。

Result: 在四个自动形式化基准测试中，ReForm较最强基线平均提高17.2个百分点效果表现显著。引入ConsistencyCheck标准，基于859个专家标注项验证评测可靠性，并揭示自动形式化具有较大难度，专家也存在高达38.5%的语义错误率。

Conclusion: 通过引入语义一致性评估的反思机制，ReForm显著提升了自动形式化的语义保真度和整体性能，促进了自然语言数学语句到机器可校验形式化表达的准确转换。

Abstract: Autoformalization, which translates natural language mathematics into
machine-verifiable formal statements, is critical for using formal mathematical
reasoning to solve math problems stated in natural language. While Large
Language Models can generate syntactically correct formal statements, they
often fail to preserve the original problem's semantic intent. This limitation
arises from the LLM approaches' treating autoformalization as a simplistic
translation task which lacks mechanisms for self-reflection and iterative
refinement that human experts naturally employ. To address these issues, we
propose ReForm, a Reflective Autoformalization method that tightly integrates
semantic consistency evaluation into the autoformalization process. This
enables the model to iteratively generate formal statements, assess its
semantic fidelity, and self-correct identified errors through progressive
refinement. To effectively train this reflective model, we introduce
Prospective Bounded Sequence Optimization (PBSO), which employs different
rewards at different sequence positions to ensure that the model develops both
accurate autoformalization and correct semantic validations, preventing
superficial critiques that would undermine the purpose of reflection. Extensive
experiments across four autoformalization benchmarks demonstrate that ReForm
achieves an average improvement of 17.2 percentage points over the strongest
baselines. To further ensure evaluation reliability, we introduce
ConsistencyCheck, a benchmark of 859 expert-annotated items that not only
validates LLMs as judges but also reveals that autoformalization is inherently
difficult: even human experts produce semantic errors in up to 38.5% of cases.

</details>


### [65] [Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way](https://arxiv.org/abs/2510.24605)
*Yicun Yang,Cong Wang,Shaobo Wang,Zichen Wen,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种具有可变生成长度的扩散式大语言模型dLLM-Var，解决了传统dLLM生成长度固定的问题，提高了生成效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统扩散式大语言模型生成长度固定，需事先设定超参数，限制了效率和灵活性。

Method: 训练模型准确预测生成文本中的[EOS]结束标记，使模型能够原生实现变长生成，同时保持全局双向注意力和高并行性。

Result: 在标准基准测试中，方法比传统扩散式大语言模型推理快30.1倍，比自回归模型（如Qwen和Llama）快2.4倍，且准确度更高。

Conclusion: 提出的方法显著提升了扩散式大语言模型的实用性和效率，推动其应用于实际场景。

Abstract: Diffusion-based large language models (dLLMs) have exhibited substantial
potential for parallel text generation, which may enable more efficient
generation compared to autoregressive models. However, current dLLMs suffer
from fixed generation lengths, which indicates the generation lengths of dLLMs
have to be determined before decoding as a hyper-parameter, leading to issues
in efficiency and flexibility. To solve these problems, in this work, we
propose to train a diffusion LLM with native variable generation lengths,
abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately
predict the [EOS] token in the generated text, which makes a dLLM be able to
natively infer in a block diffusion manner, while still maintaining the ability
of global bi-directional (full) attention and high parallelism. Experiments on
standard benchmarks demonstrate that our method achieves a 30.1x speedup over
traditional dLLM inference paradigms and a 2.4x speedup relative to
autoregressive models such as Qwen and Llama. Our method achieves higher
accuracy and faster inference, elevating dLLMs beyond mere academic novelty and
supporting their practical use in real-world applications. Codes and models
have been released.

</details>


### [66] [Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs](https://arxiv.org/abs/2510.24606)
*Siheng Xiong,Joe Zou,Faramarz Fekri,Yae Jee Cho*

Main category: cs.CL

TL;DR: 本文提出了一种名为动态分层稀疏注意力(DHSA)的新方法，用于解决长上下文大模型中注意力计算成本高和适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的静态稀疏注意力方法虽然降低了计算成本，但由于其固定模式，无法灵活适应内容变化，影响准确性。现有动态方法依赖预定义模板，限制了通用性和准确性。

Method: DHSA通过动态在线预测注意力稀疏性，自适应地将序列分割成可变长度块，用长度归一化的聚合方式计算块表示，再将块级相似度上采样到令牌级，以确定保留的交互，从而有效减少计算量且不需重训练。

Result: 在Gemma2的测试中，DHSA在准确率上与稠密注意力持平，同时预填充延迟减少20-60%，峰值内存使用降低35%。与区块稀疏注意力等基线相比，DHSA在准确率上提升6-18%，计算成本相当或更低。

Conclusion: DHSA提供了一种高效且适应性强的长上下文表示方法，适合资源受限设备上的大语言模型，兼顾准确性和计算资源消耗。

Abstract: The quadratic cost of attention hinders the scalability of long-context LLMs,
especially in resource-constrained settings. Existing static sparse methods
such as sliding windows or global tokens utilizes the sparsity of attention to
reduce the cost of attention, but poorly adapts to the content-dependent
variations in attention due to their staticity. While previous work has
proposed several dynamic approaches to improve flexibility, they still depend
on predefined templates or heuristic mechanisms. Such strategies reduce
generality and prune tokens that remain contextually important, limiting their
accuracy across diverse tasks. To tackle these bottlenecks of existing methods
for long-context modeling, we introduce Dynamic Hierarchical Sparse Attention
(DHSA), a data-driven framework that dynamically predicts attention sparsity
online without retraining. Our proposed DHSA adaptively segments sequences into
variable-length chunks, then computes chunk representations by aggregating the
token embeddings within each chunk. To avoid the bias introduced by varying
chunk lengths, we apply length-normalized aggregation that scales the averaged
embeddings by the square root of the chunk size. Finally, DHSA upsamples the
chunk-level similarity scores to token level similarities to calculate
importance scores that determine which token-level interactions should be
preserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and
LongBench show that DHSA matches dense attention in accuracy, while reducing
prefill latency by 20-60% and peak memory usage by 35%. Compared to other
representative baselines such as block sparse attention, DHSA achieves
consistently higher accuracy (6-18% relative gains) with comparable or lower
cost, offering an efficient and adaptable solution for long-context on-device
LLMs.

</details>


### [67] [Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation](https://arxiv.org/abs/2510.24619)
*Snegha A,Sayambhu Sen,Piyush Singh Pasi,Abhishek Singhania,Preethi Jyothi*

Main category: cs.CL

TL;DR: 该论文研究了针对解码器大语言模型（LLMs）的零-shot跨语言迁移，重点比较了前缀调优方法与LoRA技术，在Llama和Mistral模型上对35种以上语言的适应效果，发现前缀方法在多语言和多资源环境下表现优于LoRA。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型具备多语言预训练和强大的泛化能力，但解码器结构的模型在跨语言任务的零-shot微调仍然具有挑战性，特别是前缀调优方法的应用较少亟需研究。

Method: 系统比较了三种基于前缀的调优技术（软提示调优、前缀调优和Llama Adapter），在Llama 3.1 8B和Mistral 7B模型上，针对英文到超过35种语言的跨语言迁移进行实验，还分析了不同语言家族、文字体系及模型规模对性能的影响。

Result: 实验结果显示，使用Llama 3.1 8B模型时，前缀调优方法在Belebele基准上相比LoRA提升最高达6%；在Mistral 7B模型上也观察到类似改进。前缀调优仅需1.23M参数，仍能在多个基准测试中稳定提升表现。

Conclusion: 前缀调优技术作为一种参数高效的调优方法，在解码器LLMs的零-shot跨语言迁移中表现出优越性和可扩展性，尤其适合低资源多语言环境，展示了其作为LoRA替代方案的潜力。

Abstract: With the release of new large language models (LLMs) like Llama and Mistral,
zero-shot cross-lingual transfer has become increasingly feasible due to their
multilingual pretraining and strong generalization capabilities. However,
adapting these decoder-only LLMs to new tasks across languages remains
challenging. While parameter-efficient fine-tuning (PeFT) techniques like
Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as
soft prompt tuning, prefix tuning, and Llama Adapter are less explored,
especially for zero-shot transfer in decoder-only models. We present a
comprehensive study of three prefix-based methods for zero-shot cross-lingual
transfer from English to 35+ high- and low-resource languages. Our analysis
further explores transfer across linguistic families and scripts, as well as
the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix
methods outperform LoRA-baselines by up to 6% on the Belebele benchmark.
Similar improvements were observed with Mistral v0.3 7B as well. Despite using
only 1.23M learning parameters with prefix tuning, we achieve consistent
improvements across diverse benchmarks. These findings highlight the potential
of prefix-based techniques as an effective and scalable alternative to LoRA,
particularly in low-resource multilingual settings.

</details>


### [68] [Relative Scaling Laws for LLMs](https://arxiv.org/abs/2510.24626)
*William Held,David Hall,Percy Liang,Diyi Yang*

Main category: cs.CL

TL;DR: 本文提出相对规模法则，用于分析语言模型在不同测试分布中的性能差异，发现规模增加并不一定减少所有性能差距。


<details>
  <summary>Details</summary>
Motivation: 传统的规模法则通过聚合测试集衡量模型性能提升，忽略了不同子群体之间的性能差异，可能掩盖了不平等现象。

Method: 作者使用255个在相同计算预算（IsoFLOP）下训练的解码器式Transformer模型，覆盖从10^{18}到10^{20} FLOPs的规模，通过相对规模法则追踪不同测试分布之间的性能差距随规模变化的趋势。

Result: 发现不同领域表现轨迹各异：学术领域趋向性能均衡，区域英语方言表现依人口规模变化而变化，AI风险行为表现出能力和影响相关风险随训练增加而加剧，而对抗性风险则无明显变化。

Conclusion: 虽然模型规模扩大整体性能提升，但并非所有性能差异都会消失。引入相对规模法则有助于揭示并优先解决模型鲁棒性的挑战。作者还公开了所有模型检查点供后续研究使用。

Abstract: Scaling laws describe how language models improve with additional data,
parameters, and compute. While widely used, they are typically measured on
aggregate test sets. Aggregate evaluations yield clean trends but average over
heterogeneous subpopulations, obscuring performance disparities. We introduce
relative scaling laws, which track how performance gaps between test
distributions evolve with scale rather than focusing solely on absolute error.
Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP)
budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we
find diverse trajectories: academic domains on MMLU converge toward parity;
regional English dialects shift depending on population size; and clusters of
AI risk behaviours split, with capability- and influence-related risks
increasing during pretraining while adversarial risks do not. These results
show that although scaling improves overall performance, it is not a universal
equalizer. To support further study, we release all model checkpoints from this
work to enable practitioners to measure relative alongside traditional scaling
laws, in order to better prioritize robustness challenges in light of the
bitter lesson.

</details>


### [69] ["Mm, Wat?" Detecting Other-initiated Repair Requests in Dialogue](https://arxiv.org/abs/2510.24628)
*Anh Ngo,Nicolas Rollet,Catherine Pelachaud,Chloe Clavel*

Main category: cs.CL

TL;DR: 本文提出了一种结合语言和语音特征的多模态模型，用于自动检测荷兰语对话中的修复启动，以提高对话连续性。


<details>
  <summary>Details</summary>
Motivation: 当前对话代理无法有效识别用户的修复启动，导致对话中断和用户流失，亟需提升对修复启动的检测能力。

Method: 基于会话分析理论，结合语言特征和韵律特征，提出一个多模态模型用于自动检测修复启动。

Result: 实验结果表明韵律线索能显著提升已预训练文本与音频嵌入的性能，展示了不同特征间的交互作用。

Conclusion: 结合语言和韵律特征的多模态模型能有效提升对话中修复启动的识别效果，未来可拓展至视觉信息和多语种多场景以提升模型鲁棒性和泛化能力。

Abstract: Maintaining mutual understanding is a key component in human-human
conversation to avoid conversation breakdowns, in which repair, particularly
Other-Initiated Repair (OIR, when one speaker signals trouble and prompts the
other to resolve), plays a vital role. However, Conversational Agents (CAs)
still fail to recognize user repair initiation, leading to breakdowns or
disengagement. This work proposes a multimodal model to automatically detect
repair initiation in Dutch dialogues by integrating linguistic and prosodic
features grounded in Conversation Analysis. The results show that prosodic cues
complement linguistic features and significantly improve the results of
pretrained text and audio embeddings, offering insights into how different
features interact. Future directions include incorporating visual cues,
exploring multilingual and cross-context corpora to assess the robustness and
generalizability.

</details>


### [70] [OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning](https://arxiv.org/abs/2510.24636)
*Ziyou Hu,Zhengliang Shi,Minghang Zhu,Haitao Li,Teng Sun,Pengjie Ren,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

TL;DR: 本文提出了OpenRM，一种结合外部工具以收集证据，提升长文本奖励模型判断开源回答正确性的工具增强奖励模型。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在知识密集且需外部证据支持的长文本任务中表现不佳，难以细致区分回答质量。

Method: 引入OpenRM，利用外部工具收集相关证据，结合27K对合成数据训练，采用Group Relative Policy Optimization，联合监督工具调用和最终准确度。

Result: 在三组新收集数据和两个常用基准测试上，OpenRM显著优于现有奖励模型。

Conclusion: OpenRM通过工具增强奖励评估，改善了长文本任务的模型对齐与评判，展现出在训练和推理阶段均显著提升下游任务表现的潜力。

Abstract: Reward models (RMs) have become essential for aligning large language models
(LLMs), serving as scalable proxies for human evaluation in both training and
inference. However, existing RMs struggle on knowledge-intensive and long-form
tasks, where evaluating correctness requires grounding beyond the model's
internal knowledge. This limitation hinders them from reliably discriminating
subtle quality differences, especially when external evidence is necessary. To
address this, we introduce OpenRM, a tool-augmented long-form reward model that
systematically judges open-ended responses by invoking external tools to gather
relevant evidence. We train OpenRM with Group Relative Policy Optimization
(GRPO) on over 27K synthesized pairwise examples generated through a
controllable data synthesis framework. The training objective jointly
supervises intermediate tool usage and final outcome accuracy, incentivizing
our reward model to learn effective evidence-based judgment strategies.
Extensive experiments on three newly-collected datasets and two widely-used
benchmarks demonstrate that OpenRM substantially outperforms existing reward
modeling approaches. As a further step, we integrate OpenRM into both
inference-time response selection and training-time data selection. This yields
consistent gains in downstream LLM alignment tasks, highlighting the potential
of tool-augmented reward models for scaling reliable long-form evaluation.

</details>


### [71] [Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia](https://arxiv.org/abs/2510.24647)
*Hugo Rydel-Johnston,Alex Kafkas*

Main category: cs.CL

TL;DR: 本文通过对大规模自然阅读数据的眼动追踪分析，研究了阅读障碍者在阅读中受到的时间成本影响，发现词长、词频和预测性均能显著影响阅读时间，且阅读障碍者对这些特征尤其敏感。


<details>
  <summary>Details</summary>
Motivation: 探索阅读障碍者阅读时间增加的具体条件和影响因素，以理解阅读障碍产生的机制。

Method: 利用眼动追踪数据，结合词长、词频和预测性特征，构建模型分析这些特征对阅读障碍者和普通阅读者阅读时间的影响。

Result: 发现所有词级特征都显著影响阅读时间，阅读障碍者对这些特征的敏感度更高，尤其是词的预测性；对这些特征的反事实操控可缩小阅读障碍者与普通读者间约三分之一的时间差距。

Conclusion: 词的预测性、长度和频率是解释阅读障碍者额外阅读时间成本的重要因素，结果支持了对语言工作记忆和音素编码需求增加的理论，为后续研究和干预措施提供了方向。

Abstract: We ask where, and under what conditions, dyslexic reading costs arise in a
large-scale naturalistic reading dataset. Using eye-tracking aligned to
word-level features (word length, frequency, and predictability), we model how
each feature influences dyslexic time costs. We find that all three features
robustly change reading times in both typical and dyslexic readers, and that
dyslexic readers show stronger sensitivities to each, especially
predictability. Counterfactual manipulations of these features substantially
narrow the dyslexic-control gap by about one third, with predictability showing
the strongest effect, followed by length and frequency. These patterns align
with dyslexia theories that posit heightened demands on linguistic working
memory and phonological encoding, and they motivate further work on lexical
complexity and parafoveal preview benefits to explain the remaining gap. In
short, we quantify when extra dyslexic costs arise, how large they are, and
offer actionable guidance for interventions and computational models for
dyslexics.

</details>


### [72] [Optimizing Retrieval for RAG via Reinforced Contrastive Learning](https://arxiv.org/abs/2510.24652)
*Jiawei Zhou,Lei Chen*

Main category: cs.CL

TL;DR: 提出了一种名为R3的检索框架，通过强化对比学习优化检索生成模型，实现了检索性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着检索增强生成（RAG）技术的发展，传统的信息检索不再仅仅是为人类用户检索信息，而是为AI系统检索上下文知识，相关性定义变得困难且难以预先标注。

Method: 提出R3框架，通过试验与反馈的强化对比学习方法，使检索器能在RAG环境中动态探索和优化相关性，利用环境交互产生对比信号促进检索器的自我提升，无需依赖标注或合成数据进行监督微调。

Result: 在多种任务的广泛实验中，R3提升了5.2%的RAG性能，领先现有最先进检索器4.9%，性能与基于大语言模型后训练或指令调优的RAG系统相当。

Conclusion: R3框架高效实用，仅需4块GPU，一天内完成训练，显著提升RAG系统检索效果，具有良好的应用前景。

Abstract: As retrieval-augmented generation (RAG) becomes increasingly widespread, the
role of information retrieval (IR) is shifting from retrieving information for
human users to retrieving contextual knowledge for artificial intelligence (AI)
systems, where relevance becomes difficult to define or annotate beforehand. To
address this challenge, we propose R3, a Retrieval framework optimized for RAG
through trialand-feedback Reinforced contrastive learning. Unlike prior
approaches that rely on annotated or synthetic data for supervised fine-tuning,
R3 enables the retriever to dynamically explore and optimize relevance within
the RAG environment. During training, the retrieved results interact with the
environment to produce contrastive signals that automatically guide the
retriever's self-improvement. Extensive experiments across diverse tasks
demonstrate that R3 improves RAG performance by 5.2% over the original
retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving
comparable results to LLM-augmented retrieval and RAG systems built on
post-trained or instruction-tuned LLMs. It is both efficient and practical,
requiring only 4 GPUs and completing training within a single day.

</details>


### [73] [Evolving Diagnostic Agents in a Virtual Clinical Environment](https://arxiv.org/abs/2510.24654)
*Pengcheng Qiu,Chaoyi Wu,Junwei Liu,Qiaoyu Zheng,Yusheng Liao,Haowen Wang,Yun Yue,Qianrui Fan,Shuai Zhen,Jian Wang,Jinjie Gu,Yanfeng Wang,Ya Zhang,Weidi Xie*

Main category: cs.CL

TL;DR: 本文提出了一个基于强化学习训练大语言模型作为诊断代理的框架，实现多回合诊断过程管理和动态检查选择。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型多基于静态病例总结进行训练，缺乏动态交互诊断策略的学习能力。

Method: 提出了一套整体方案，包括训练虚拟诊断环境DiagGym，采用多回合强化学习训练诊断代理DiagAgent，构建诊断基准DiagBench，并进行多维度性能评估。

Result: DiagAgent在诊断准确率、检查推荐命中率、F1分数及基于医生评分的指标上均显著优于多款先进大语言模型，包括GPT-4o和Claude-sonnet-4。

Conclusion: 通过在交互式临床环境中学习诊断策略，模型具备了动态且具有临床意义的诊断管理能力，超越了被动训练方法的局限。

Abstract: In this paper, we present a framework for training large language models
(LLMs) as diagnostic agents with reinforcement learning, enabling them to
manage multi-turn diagnostic processes, adaptively select examinations, and
commit to final diagnoses. Unlike instruction-tuned models trained on static
case summaries, our method acquires diagnostic strategies through interactive
exploration and outcome-based feedback. Our contributions are fourfold: (i) We
present DiagGym, a diagnostics world model trained with electronic health
records that emits examination outcomes conditioned on patient history and
recommended examination, serving as a virtual clinical environment for
realistic diagnosis training and evaluation; (ii) We train DiagAgent via
end-to-end, multi-turn reinforcement learning to learn diagnostic policies that
optimize both information yield and diagnostic accuracy; (iii) We introduce
DiagBench, a diagnostic benchmark comprising 750 cases with physician-validated
examination recommendations and 99 cases annotated with 973 physician-written
rubrics on diagnosis process; (iv) we demonstrate superior performance across
diverse diagnostic settings. DiagAgent significantly outperforms 10
state-of-the-art LLMs, including DeepSeek-v3 and GPT-4o, as well as two
prompt-engineered agents. In single-turn settings, DiagAgent achieves 9.34%
higher diagnostic accuracy and 44.03% improvement in examination recommendation
hit ratio. In end-to-end settings, it delivers 15.12% increase in diagnostic
accuracy and 23.09% boost in examination recommendation F1 score. In
rubric-based evaluation, it surpasses the next-best model, Claude-sonnet-4, by
7.1% in weighted rubric score. These findings indicate that learning policies
in interactive clinical environments confers dynamic and clinically meaningful
diagnostic management abilities unattainable through passive training alone.

</details>


### [74] [MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation](https://arxiv.org/abs/2510.24664)
*Parker Riley,Daniel Deutsch,Mara Finkelstein,Colten DiIanni,Juraj Juraska,Markus Freitag*

Main category: cs.CL

TL;DR: 本文提出了MQM重标注方法，通过对已有机器翻译质量评估的注释进行审查和编辑，提升了评估注释的质量。


<details>
  <summary>Details</summary>
Motivation: 随着翻译模型质量提升，现有的人类翻译评估方法需要改进以减少评估噪声，确保质量提升被准确反映。

Method: 实验采用两阶段的MQM重标注方法，即让评估者重新审查并修正已有的MQM注释，这些注释可能来自不同来源，包括自动系统或其他评估者。

Result: 重新标注后评估者行为符合预期，且注释质量显著提升，主要是纠正了第一轮评估中遗漏的错误。

Conclusion: MQM重标注方法有效提升了机器翻译评估的准确性，有助于更精确地反映翻译模型质量的提升。

Abstract: Human evaluation of machine translation is in an arms race with translation
model quality: as our models get better, our evaluation methods need to be
improved to ensure that quality gains are not lost in evaluation noise. To this
end, we experiment with a two-stage version of the current state-of-the-art
translation evaluation paradigm (MQM), which we call MQM re-annotation. In this
setup, an MQM annotator reviews and edits a set of pre-existing MQM
annotations, that may have come from themselves, another human annotator, or an
automatic MQM annotation system. We demonstrate that rater behavior in
re-annotation aligns with our goals, and that re-annotation results in
higher-quality annotations, mostly due to finding errors that were missed
during the first pass.

</details>


### [75] [InteractComp: Evaluating Search Agents With Ambiguous Queries](https://arxiv.org/abs/2510.24668)
*Mingyi Deng,Lijun Huang,Yani Fan,Jiayi Zhang,Fashen Ren,Jinyi Bai,Fuzhen Yang,Dayi Miao,Zhaoyang Yu,Yifan Wu,Yanfei Zhang,Fengwei Teng,Yingjia Wan,Song Hu,Yude Li,Xin Jin,Conghao Hu,Haoyu Li,Qirui Fu,Tai Zhong,Xinyu Wang,Xiangru Tang,Nan Tang,Chenglin Wu,Yuyu Luo*

Main category: cs.CL

TL;DR: 本文介绍了InteractComp基准，评估搜索代理识别查询歧义并通过交互解决的能力，揭示现有模型在交互中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有语言搜索代理假设用户查询完整且无歧义，现实中用户查询往往不完整且需交互澄清，但大多数代理缺乏交互机制，且无相应基准进行评估。

Method: 构建了210个跨9个领域的专家设计问题，问题设计包含真正的歧义，仅通过交互才能解决，并用17个模型进行评估，同时分析模型的表现和交互能力发展。

Result: 最佳模型仅13.73%准确率（完全上下文71.5%），表明模型过于自信且缺乏交互利用能力，强制交互显著提升表现，交互能力15个月未改进而搜索性能提升7倍。

Conclusion: InteractComp揭示了语言搜索代理在交互识别与解决歧义方面的严重短板，提供了重要资源用于评估与训练搜索代理的交互能力。

Abstract: Language agents have demonstrated remarkable potential in web search and
information retrieval. However, these search agents assume user queries are
complete and unambiguous, an assumption that diverges from reality where users
begin with incomplete queries requiring clarification through interaction. Yet
most agents lack interactive mechanisms during the search process, and existing
benchmarks cannot assess this capability. To address this gap, we introduce
InteractComp, a benchmark designed to evaluate whether search agents can
recognize query ambiguity and actively interact to resolve it during search.
Following the principle of easy to verify, interact to disambiguate, we
construct 210 expert-curated questions across 9 domains through a
target-distractor methodology that creates genuine ambiguity resolvable only
through interaction. Evaluation of 17 models reveals striking failure: the best
model achieves only 13.73% accuracy despite 71.50% with complete context,
exposing systematic overconfidence rather than reasoning deficits. Forced
interaction produces dramatic gains, demonstrating latent capability current
strategies fail to engage. Longitudinal analysis shows interaction capabilities
stagnated over 15 months while search performance improved seven-fold,
revealing a critical blind spot. This stagnation, coupled with the immediate
feedback inherent to search tasks, makes InteractComp a valuable resource for
both evaluating and training interaction capabilities in search agents. The
code is available at https://github.com/FoundationAgents/InteractComp.

</details>


### [76] [Dissecting Role Cognition in Medical LLMs via Neuronal Ablation](https://arxiv.org/abs/2510.24677)
*Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 本文研究了大语言模型在医疗角色扮演中的推理能力，发现角色提示主要影响语言风格，而非推理机制。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在医疗角色扮演中应用广泛，但其角色提示是否真正影响模型推理能力尚不清楚。

Method: 提出RP-Neuron-Activated评估框架，结合神经元切除和表示分析，评估医疗QA数据集中不同临床角色提示对推理路径的影响。

Result: 角色提示未显著提升模型的医疗推理能力，仅改变了表面语言特征，未发现不同角色之间的认知差异或推理路径变化。

Conclusion: 当前基于角色的角色扮演方法未能模拟真实医疗认知复杂性，提示需要开发能够模拟真实认知过程的新模型。

Abstract: Large language models (LLMs) have gained significant traction in medical
decision support systems, particularly in the
  context of medical question answering and role-playing simulations. A common
practice, Prompt-Based Role Playing (PBRP),
  instructs models to adopt different clinical roles (e.g., medical students,
residents, attending physicians) to simulate varied
  professional behaviors. However, the impact of such role prompts on model
reasoning capabilities remains unclear. This
  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to
evaluate whether role prompts induce distinct,
  role-specific cognitive processes in LLMs or merely modify linguistic style.
We test this framework on three medical QA
  datasets, employing neuron ablation and representation analysis techniques to
assess changes in reasoning pathways. Our
  results demonstrate that role prompts do not significantly enhance the
medical reasoning abilities of LLMs. Instead, they
  primarily affect surface-level linguistic features, with no evidence of
distinct reasoning pathways or cognitive differentiation
  across clinical roles. Despite superficial stylistic changes, the core
decision-making mechanisms of LLMs remain uniform
  across roles, indicating that current PBRP methods fail to replicate the
cognitive complexity found in real-world medical
  practice. This highlights the limitations of role-playing in medical AI and
emphasizes the need for models that simulate genuine
  cognitive processes rather than linguistic imitation.We have released the
related code in the following repository:https:
  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor

</details>


### [77] [SPICE: Self-Play In Corpus Environments Improves Reasoning](https://arxiv.org/abs/2510.24684)
*Bo Liu,Chuanyang Jin,Seungone Kim,Weizhe Yuan,Wenting Zhao,Ilia Kulikov,Xian Li,Sainbayar Sukhbaatar,Jack Lanchantin,Jason Weston*

Main category: cs.CL

TL;DR: SPICE是一种基于语料库环境的自我对抗强化学习框架，通过文档挖掘生成多样的推理任务，实现模型的持续自我提升。


<details>
  <summary>Details</summary>
Motivation: 自我提升系统需要不断与环境交互以实现持续适应，现有无环境基础的自我对抗方法效果有限。

Method: 提出SPICE框架，模型扮演挑战者和推理者两个角色：挑战者从大规模语料库中挖掘文档生成多样推理任务，推理者进行解答，通过对抗动态自动生成适合推理者能力边界的课程。

Result: SPICE在数学和通用推理基准上分别提升了8.9%和9.8%，超过现有无基环境的自我对抗方法。

Conclusion: 语料库基础成为关键，使SPICE能持续生成并达到越来越具挑战性的目标，促进模型持续自我提升。

Abstract: Self-improving systems require environmental interaction for continuous
adaptation. We introduce SPICE (Self-Play In Corpus Environments), a
reinforcement learning framework where a single model acts in two roles: a
Challenger that mines documents from a large corpus to generate diverse
reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,
the Challenger creates an automatic curriculum at the frontier of the
Reasoner's capability, while corpus grounding provides the rich,
near-inexhaustible external signal necessary for sustained improvement. Unlike
existing ungrounded self-play methods that offer more limited benefits, SPICE
achieves consistent gains across mathematical (+8.9%) and general reasoning
(+9.8%) benchmarks on multiple model families. Our analysis reveals how
document grounding is a key ingredient in SPICE to continuously generate its
own increasingly challenging goals and achieve them, enabling sustained
self-improvement.

</details>


### [78] [Repurposing Synthetic Data for Fine-grained Search Agent Supervision](https://arxiv.org/abs/2510.24694)
*Yida Zhao,Kuan Li,Xixi Wu,Liwen Zhang,Dingchu Zhang,Baixuan Li,Maojia Song,Zhuo Chen,Chenxi Wang,Xinyu Wang,Kewei Tu,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 本文提出了一种基于实体信息的强化学习训练方法E-GRPO，通过对部分正确的“近乎成功”样本赋予奖励，提升了LLM搜索代理在知识密集任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前训练方法GRPO忽略了丰富的实体信息，导致无法区分有价值的“近乎成功”样本和失败样本，丢失了重要的学习信号。

Method: 提出了实体感知的Group Relative Policy Optimization（E-GRPO），引入基于实体匹配率的稠密奖励函数，使模型能够从“近乎成功”的错误样本中有效学习。

Result: 在多种问答和深度研究基准测试中，E-GRPO显著优于GRPO，表现出更高的准确率和更高效的推理策略，减少了工具调用次数。

Conclusion: 利用实体信息的稠密奖励函数能够改善搜索代理的训练效果，提高其准确率和推理效率，是一种更有效且样本高效的对齐方法。

Abstract: LLM-based search agents are increasingly trained on entity-centric synthetic
data to solve complex, knowledge-intensive tasks. However, prevailing training
methods like Group Relative Policy Optimization (GRPO) discard this rich entity
information, relying instead on sparse, outcome-based rewards. This critical
limitation renders them unable to distinguish informative "near-miss"
samples-those with substantially correct reasoning but a flawed final
answer-from complete failures, thus discarding valuable learning signals. We
address this by leveraging the very entities discarded during training. Our
empirical analysis reveals a strong positive correlation between the number of
ground-truth entities identified during an agent's reasoning process and final
answer accuracy. Building on this insight, we introduce Entity-aware Group
Relative Policy Optimization (E-GRPO), a novel framework that formulates a
dense entity-aware reward function. E-GRPO assigns partial rewards to incorrect
samples proportional to their entity match rate, enabling the model to
effectively learn from these "near-misses". Experiments on diverse
question-answering (QA) and deep research benchmarks show that E-GRPO
consistently and significantly outperforms the GRPO baseline. Furthermore, our
analysis reveals that E-GRPO not only achieves superior accuracy but also
induces more efficient reasoning policies that require fewer tool calls,
demonstrating a more effective and sample-efficient approach to aligning search
agents.

</details>


### [79] [AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis](https://arxiv.org/abs/2510.24695)
*Xuanzhong Chen,Zile Qiao,Guoxin Chen,Liangcai Su,Zhen Zhang,Xinyu Wang,Pengjun Xie,Fei Huang,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 该论文提出了一种基于“最近发展区”(ZPD)教育理论的数据合成方法，以提升大型语言模型(LLM)的高级推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在复杂任务上的能力有限，作者希望通过定位任务难度于模型的“最近发展区”来突破能力边界。

Method: 设计了AgentFrontier引擎，自动合成位于LLM最近发展区的高质量跨学科数据，支持持续预训练和针对复杂推理任务的后训练，同时基于此设计了ZPD考试评测模型能力。

Result: 训练的AgentFrontier-30B-A3B模型在多个高难度基准测试中表现优异，甚至超过部分领先的专有模型。

Conclusion: ZPD指导下的数据合成方法为构建更强大的LLM智能体提供了可扩展且有效的路径。

Abstract: Training large language model agents on tasks at the frontier of their
capabilities is key to unlocking advanced reasoning. We introduce a data
synthesis approach inspired by the educational theory of the Zone of Proximal
Development (ZPD), which defines this frontier as tasks an LLM cannot solve
alone but can master with guidance. To operationalize this, we present the
AgentFrontier Engine, an automated pipeline that synthesizes high-quality,
multidisciplinary data situated precisely within the LLM's ZPD. This engine
supports both continued pre-training with knowledge-intensive data and targeted
post-training on complex reasoning tasks. From the same framework, we derive
the ZPD Exam, a dynamic and automated benchmark designed to evaluate agent
capabilities on these frontier tasks. We train AgentFrontier-30B-A3B model on
our synthesized data, which achieves state-of-the-art results on demanding
benchmarks like Humanity's Last Exam, even surpassing some leading proprietary
agents. Our work demonstrates that a ZPD-guided approach to data synthesis
offers a scalable and effective path toward building more capable LLM agents.

</details>


### [80] [WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking](https://arxiv.org/abs/2510.24697)
*Zhengwei Tao,Haiyang Shen,Baixuan Li,Wenbiao Yin,Jialong Wu,Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Liwen Zhang,Xinyu Wang,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 本文提出了WebLeaper框架，通过构建高覆盖率的信息搜索任务和生成高效搜索轨迹，提升了大型语言模型代理在信息搜索中的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 当前信息搜索代理效率低，主要因训练任务中目标实体稀疏，限制了学习高效搜索行为的机会。

Method: 将信息搜索建模为树结构推理问题，利用精心设计的维基百科表格合成三种任务变体（Basic、Union和Reverse-Union），并筛选准确高效的训练轨迹以优化模型表现。

Result: 在五个信息搜索基准测试中，WebLeaper在搜索效率和效果上均优于强基线方法。

Conclusion: 通过任务设计和训练轨迹筛选策略，WebLeaper显著提升了信息搜索代理的整体性能，推动了基于大型语言模型的开放式问题解决能力。

Abstract: Large Language Model (LLM)-based agents have emerged as a transformative
approach for open-ended problem solving, with information seeking (IS) being a
core capability that enables autonomous reasoning and decision-making. While
prior research has largely focused on improving retrieval depth, we observe
that current IS agents often suffer from low search efficiency, which in turn
constrains overall performance. A key factor underlying this inefficiency is
the sparsity of target entities in training tasks, which limits opportunities
for agents to learn and generalize efficient search behaviors. To address these
challenges, we propose WebLeaper, a framework for constructing high-coverage IS
tasks and generating efficient solution trajectories. We formulate IS as a
tree-structured reasoning problem, enabling a substantially larger set of
target entities to be embedded within a constrained context. Leveraging curated
Wikipedia tables, we propose three variants for synthesizing IS tasks, Basic,
Union, and Reverse-Union, to systematically increase both IS efficiency and
efficacy. Finally, we curate training trajectories by retaining only those that
are simultaneously accurate and efficient, ensuring that the model is optimized
for both correctness and search performance. Extensive experiments on both
basic and comprehensive settings, conducted on five IS benchmarks, BrowserComp,
GAIA, xbench-DeepSearch, WideSearch, and Seal-0, demonstrate that our method
consistently achieves improvements in both effectiveness and efficiency over
strong baselines.

</details>


### [81] [ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking](https://arxiv.org/abs/2510.24698)
*Baixuan Li,Dingchu Zhang,Jialong Wu,Wenbiao Yin,Zhengwei Tao,Yida Zhao,Liwen Zhang,Haiyang Shen,Runnan Fang,Pengjun Xie,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 该论文提出ParallelMuse，通过并行思维扩展信息搜索代理的探索深度和广度，提升问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 传统并行思维在信息搜索代理中存在启动效率低下和长时程推理难以整合两大难题，限制了问题解决性能。

Method: 提出两阶段方法，第一阶段部分展开功能区分并复用路径提升效率，第二阶段无损压缩推理信息综合答案。

Result: 多项开源代理和基准测试表明ParallelMuse性能提升高达62%，同时探索令牌消耗降低10-30%。

Conclusion: ParallelMuse有效提升信息搜索代理的并行探索效率和推理整合能力，显著增强问题解决表现。

Abstract: Parallel thinking expands exploration breadth, complementing the deep
exploration of information-seeking (IS) agents to further enhance
problem-solving capability. However, conventional parallel thinking faces two
key challenges in this setting: inefficiency from repeatedly rolling out from
scratch, and difficulty in integrating long-horizon reasoning trajectories
during answer generation, as limited context capacity prevents full
consideration of the reasoning process. To address these issues, we propose
ParallelMuse, a two-stage paradigm designed for deep IS agents. The first
stage, Functionality-Specified Partial Rollout, partitions generated sequences
into functional regions and performs uncertainty-guided path reuse and
branching to enhance exploration efficiency. The second stage, Compressed
Reasoning Aggregation, exploits reasoning redundancy to losslessly compress
information relevant to answer derivation and synthesize a coherent final
answer. Experiments across multiple open-source agents and benchmarks
demonstrate up to 62% performance improvement with a 10--30% reduction in
exploratory token consumption.

</details>


### [82] [AgentFold: Long-Horizon Web Agents with Proactive Context Management](https://arxiv.org/abs/2510.24699)
*Rui Ye,Zhongwang Zhang,Kuan Li,Huifeng Yin,Zhengwei Tao,Yida Zhao,Liangcai Su,Liwen Zhang,Zile Qiao,Xinyu Wang,Pengjun Xie,Fei Huang,Siheng Chen,Jingren Zhou,Yong Jiang*

Main category: cs.CL

TL;DR: 本文提出了AgentFold，一种基于主动上下文管理的新型大语言模型(Large Language Model, LLM)网页代理。它通过动态折叠历史信息，有效解决了长任务中上下文饱和与关键信息丢失的矛盾，实现了更优性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于ReAct的网页代理在执行长时间跨度任务时，面临上下文信息过载和关键信息丢失之间的权衡问题，削弱了其任务效果。

Method: AgentFold引入主动的上下文管理策略，模拟人类的逆向整合认知过程，在每一步通过执行“折叠”操作多尺度地管理历史信息，既能精细保留重要细节，又能高层抽象多步子任务，实现动态、主动的历史信息管理。

Result: 在BrowseComp和BrowseComp-ZH两个重要基准测试中，AgentFold-30B-A3B分别取得了36.2%和47.3%的成绩，不仅超过了规模大得多的开源模型DeepSeek-V3.1-671B-A37B，还优于OpenAI的领先专有代理o4-mini。

Conclusion: AgentFold验证了主动上下文管理策略在长任务LLM网页代理中的有效性，为解决上下文管理难题提供了新思路，实现了显著的性能提升。

Abstract: LLM-based web agents show immense promise for information seeking, yet their
effectiveness on long-horizon tasks is hindered by a fundamental trade-off in
context management. Prevailing ReAct-based agents suffer from context
saturation as they accumulate noisy, raw histories, while methods that fixedly
summarize the full history at each step risk the irreversible loss of critical
details. Addressing these, we introduce AgentFold, a novel agent paradigm
centered on proactive context management, inspired by the human cognitive
process of retrospective consolidation. AgentFold treats its context as a
dynamic cognitive workspace to be actively sculpted, rather than a passive log
to be filled. At each step, it learns to execute a `folding' operation, which
manages its historical trajectory at multiple scales: it can perform granular
condensations to preserve vital, fine-grained details, or deep consolidations
to abstract away entire multi-step sub-tasks. The results on prominent
benchmarks are striking: with simple supervised fine-tuning (without continual
pre-training or RL), our AgentFold-30B-A3B agent achieves 36.2% on BrowseComp
and 47.3% on BrowseComp-ZH. Notably, this performance not only surpasses or
matches open-source models of a dramatically larger scale, such as the
DeepSeek-V3.1-671B-A37B, but also surpasses leading proprietary agents like
OpenAI's o4-mini.

</details>


### [83] [Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents](https://arxiv.org/abs/2510.24702)
*Yueqi Song,Ketan Ramaneti,Zaid Sheikh,Ziru Chen,Boyu Gou,Tianbao Xie,Yiheng Xu,Danyang Zhang,Apurva Gandhi,Fan Yang,Joseph Liu,Tianyue Ou,Zhihao Yuan,Frank Xu,Shuyan Zhou,Xingyao Wang,Xiang Yue,Tao Yu,Huan Sun,Yu Su,Graham Neubig*

Main category: cs.CL

TL;DR: 本文提出了一种轻量级的代理数据协议（ADP），解决了代理训练数据格式多样且分散的问题，实现了多种代理任务数据的统一表达和训练，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 公开的大规模监督微调代理训练数据较少，主要原因是数据来源虽多但格式和接口分散，难以统一管理和利用。

Method: 设计并实现了ADP，一种可表达多种任务的统一数据格式，将13个现有代理训练数据集整合转换为ADP格式，并用该数据进行监督微调（SFT）。

Result: 统一的数据格式促进了训练，微调后模型性能平均提升约20%，在编码、浏览、工具使用和研究基准测试中取得了接近或达到最先进水平的效果。

Conclusion: ADP作为一种轻量级中间语言，降低了代理训练数据的利用门槛，促进了代理训练的标准化、可扩展和可复现性，代码和数据均已公开。

Abstract: Public research results on large-scale supervised finetuning of AI agents
remain relatively rare, since the collection of agent training data presents
unique challenges. In this work, we argue that the bottleneck is not a lack of
underlying data sources, but that a large variety of data is fragmented across
heterogeneous formats, tools, and interfaces. To this end, we introduce the
agent data protocol (ADP), a light-weight representation language that serves
as an "interlingua" between agent datasets in diverse formats and unified agent
training pipelines downstream. The design of ADP is expressive enough to
capture a large variety of tasks, including API/tool use, browsing, coding,
software engineering, and general agentic workflows, while remaining simple to
parse and train on without engineering at a per-dataset level. In experiments,
we unified a broad collection of 13 existing agent training datasets into ADP
format, and converted the standardized ADP data into training-ready formats for
multiple agent frameworks. We performed SFT on these data, and demonstrated an
average performance gain of ~20% over corresponding base models, and delivers
state-of-the-art or near-SOTA performance on standard coding, browsing, tool
use, and research benchmarks, without domain-specific tuning. All code and data
are released publicly, in the hope that ADP could help lower the barrier to
standardized, scalable, and reproducible agent training.

</details>


### [84] [MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task](https://arxiv.org/abs/2510.24707)
*Juraj Juraska,Tobias Domhan,Mara Finkelstein,Tetsuji Nakagawa,Geza Kovacs,Daniel Deutsch,Pidong Wang,Markus Freitag*

Main category: cs.CL

TL;DR: 本文介绍了WMT25翻译评估共享任务中提交的两个系统，分别用于质量评分预测和错误跨度检测。


<details>
  <summary>Details</summary>
Motivation: 提升翻译质量评估的准确性和错误检测的有效性。

Method: 采用多语言开源模型Gemma 3，对其进行微调，构建MetricX-25用于质量评分预测，构建GemSpanEval用于错误跨度检测。

Result: MetricX-25显著优于前代模型，在预测MQM和ESA质量评分上效果突出；GemSpanEval在错误跨度检测上具备与强基线xCOMET竞争的能力。

Conclusion: 通过改进输入格式和训练协议，以及将错误跨度检测任务生成化，提升了翻译质量评价和错误检测的性能和明确性。

Abstract: In this paper, we present our submissions to the unified WMT25 Translation
Evaluation Shared Task. For the Quality Score Prediction subtask, we create a
new generation of MetricX with improvements in the input format and the
training protocol, while for the Error Span Detection subtask we develop a new
model, GemSpanEval, trained to predict error spans along with their severities
and categories. Both systems are based on the state-of-the-art multilingual
open-weights model Gemma 3, fine-tuned on publicly available WMT data. We
demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture
with a regression head on top, can be trained to effectively predict both MQM
and ESA quality scores, and significantly outperforms its predecessor. Our
decoder-only GemSpanEval model, on the other hand, we show to be competitive in
error span detection with xCOMET, a strong encoder-only sequence-tagging
baseline. With error span detection formulated as a generative task, we
instruct the model to also output the context for each predicted error span,
thus ensuring that error spans are identified unambiguously.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [85] [AI-Driven Development of a Publishing Imprint: Xynapse Traces](https://arxiv.org/abs/2510.23627)
*Fred Zimmerman*

Main category: cs.SE

TL;DR: Xynapse Traces通过人机融合和多模型AI框架，实现书籍出版效率和成本的极大提升。


<details>
  <summary>Details</summary>
Motivation: 传统出版周期长、成本高且效率低，且难以满足多样化市场需求。

Method: 采用配置驱动架构和多模型AI集成，构建连续创意流水线、竞赛式评估和自动化生产分发流程，并结合人工监督确保质量。

Result: 实现上市时间缩短90%至2-4周，成本降低80%，首年出版52本书，引用准确率达99%，校验成功率100%。

Conclusion: 该系统展示了人机协作出版的新范式，推动出版民主化和细分市场开发的可能。

Abstract: Xynapse Traces is an experimental publishing imprint created via a fusion of
human and algorithmic methods using a configuration-driven architecture and a
multi-model AI integration framework. The system achieved a remarkable 90%
reduction in time-to-market (from a typical 6-12 months to just 2-4 weeks),
with 80% cost reduction compared to traditional imprint development, while
publishing 52 books in its first year and maintaining exceptional quality
metrics, including 99% citation accuracy and 100% validation success after
initial corrections. Key technical innovations include a continuous ideation
pipeline with tournament-style evaluation, a novel codex design for
transcriptive meditation practice, comprehensive automation spanning from
ideation through production and distribution, and publisher personas that
define and guide the imprint's mission. The system also integrates automated
verification with human oversight, ensuring that gains in speed do not
compromise publishing standards. This effort has significant implications for
the future of book publishing, suggesting new paradigms for human-AI
collaboration that democratize access to sophisticated publishing capabilities
and make previously unviable niche markets accessible.

</details>


### [86] [VisCoder2: Building Multi-Language Visualization Coding Agents](https://arxiv.org/abs/2510.23642)
*Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: 本文介绍了针对可视化编码代理存在的语言覆盖有限、执行不可靠及缺少迭代修正机制的问题，通过构建大规模多语言数据集VisCode-Multi-679K、建立评测基准VisPlotBench以及提出多语言模型VisCoder2，实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在生成和执行可视化代码时存在多种局限，包括语言覆盖范围狭窄、执行结果不稳定、缺少多轮纠正机制，并且现有数据集与评测多聚焦单轮或单语言任务，限制了模型实用性和进步。

Method: 构建包含679K经验证且可执行可视化样例及多轮修正对话的多语言大规模数据集VisCode-Multi-679K；设计系统化评测基准VisPlotBench，支持初始生成及多轮自我调试的评估；提出基于该数据集训练的多语言可视化模型系列VisCoder2。

Result: VisCoder2在多个编程语言和任务上显著优于现有强开源基线，性能接近GPT-4，特别在符号或依赖编译器语言中表现突出。通过多轮自我调试策略，32B参数规模模型达到82.4%的执行通过率。

Conclusion: 结合大规模多语言数据集与系统化评测，配合多轮自我修正机制，提升了可视化编码模型的执行能力与泛化性能，推动了多语言可视化生成与调试代理的发展。

Abstract: Large language models (LLMs) have recently enabled coding agents capable of
generating, executing, and revising visualization code. However, existing
models often fail in practical workflows due to limited language coverage,
unreliable execution, and lack of iterative correction mechanisms. Progress has
been constrained by narrow datasets and benchmarks that emphasize single-round
generation and single-language tasks. To address these challenges, we introduce
three complementary resources for advancing visualization coding agents.
VisCode-Multi-679K is a large-scale, supervised dataset containing 679K
validated and executable visualization samples with multi-turn correction
dialogues across 12 programming languages. VisPlotBench is a benchmark for
systematic evaluation, featuring executable tasks, rendered outputs, and
protocols for both initial generation and multi-round self-debug. Finally, we
present VisCoder2, a family of multi-language visualization models trained on
VisCode-Multi-679K. Experiments show that VisCoder2 significantly outperforms
strong open-source baselines and approaches the performance of proprietary
models like GPT-4.1, with further gains from iterative self-debug, reaching
82.4% overall execution pass rate at the 32B scale, particularly in symbolic or
compiler-dependent languages.

</details>


### [87] [Agentsway -- Software Development Methodology for AI Agents-based Teams](https://arxiv.org/abs/2510.23664)
*Eranga Bandara,Ross Gore,Xueping Liang,Sachini Rajapakse,Isurunima Kularathne,Pramoda Karunarathna,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Amin Hass,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.SE

TL;DR: 本文提出了Agentsway，一种专为AI代理协作设计的软件开发框架，通过角色分工和隐私保护，实现自适应学习和负责任的AI决策，推动AI原生的软件开发方法学。


<details>
  <summary>Details</summary>
Motivation: 传统的软件开发方法针对以人为中心的团队设计，无法适应自主AI代理参与的软件开发环境，亟需新的方法学填补这一空白。

Method: Agentsway框架定义了计划、提示、编码、测试和微调等AI代理角色，采用细化的大型语言模型结合互相反馈，形成闭环的迭代与学习过程，并嵌入隐私设计和多模型协调确保负责任决策。

Result: Agentsway实现了基于AI代理协作的软件开发规范，提升了领域推理能力和决策的可解释性，建立了生产力和信任的可度量标准，标志着软件工程方法的创新突破。

Conclusion: Agentsway为AI代理驱动的软件工程团队提出了首个专门方法学，开启了AI自主改进和原生协作的软件开发新时代。

Abstract: The emergence of Agentic AI is fundamentally transforming how software is
designed, developed, and maintained. Traditional software development
methodologies such as Agile, Kanban, ShapeUp, etc, were originally designed for
human-centric teams and are increasingly inadequate in environments where
autonomous AI agents contribute to planning, coding, testing, and continuous
learning. To address this methodological gap, we present "Agentsway" a novel
software development framework designed for ecosystems where AI agents operate
as first-class collaborators. Agentsway introduces a structured lifecycle
centered on human orchestration, and privacy-preserving collaboration among
specialized AI agents. The framework defines distinct roles for planning,
prompting, coding, testing, and fine-tuning agents, each contributing to
iterative improvement and adaptive learning throughout the development process.
By integrating fine-tuned LLMs that leverage outputs and feedback from
different agents throughout the development cycle as part of a retrospective
learning process, Agentsway enhances domain-specific reasoning, and explainable
decision-making across the entire software development lifecycle. Responsible
AI principles are further embedded across the agents through the coordinated
use of multiple fine-tuned LLMs and advanced reasoning models, ensuring
balanced, transparent, and accountable decision-making. This work advances
software engineering by formalizing agent-centric collaboration, integrating
privacy-by-design principles, and defining measurable metrics for productivity
and trust. Agentsway represents a foundational step toward the next generation
of AI-native, self-improving software development methodologies. To the best of
our knowledge, this is the first research effort to introduce a dedicated
methodology explicitly designed for AI agent-based software engineering teams.

</details>


### [88] [RefleXGen:The unexamined code is not worth using](https://arxiv.org/abs/2510.23674)
*Bin Wang,Hui Li,AoFan Liu,BoTao Yang,Ao Yang,YiLu Zhong,Weixiang Huang,Yanping Zhang,Runhuai Huang,Weimin Zeng*

Main category: cs.SE

TL;DR: 该论文提出了RefleXGen方法，通过结合检索增强生成和引导自我反思机制，提升大语言模型生成代码的安全性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在代码生成中的安全性难题，避免传统微调和专用安全代码数据集的资源消耗。

Method: 引入RefleXGen，使用检索增强生成技术和模型自我评估、反思机制，迭代优化生成代码，持续积累和优化知识库。

Result: 实验显示RefleXGen在多种模型中提升代码安全性，如GPT-3.5 Turbo提升13.6%，GPT-4o提升6.7%，CodeQwen提升4.5%，Gemini提升5.8%。

Conclusion: 提升模型自我反思质量是增强AI生成代码安全性的有效且实用策略。

Abstract: Security in code generation remains a pivotal challenge when applying large
language models (LLMs). This paper introduces RefleXGen, an innovative method
that significantly enhances code security by integrating Retrieval-Augmented
Generation (RAG) techniques with guided self-reflection mechanisms inherent in
LLMs. Unlike traditional approaches that rely on fine-tuning LLMs or developing
specialized secure code datasets - processes that can be resource-intensive -
RefleXGen iteratively optimizes the code generation process through
self-assessment and reflection without the need for extensive resources. Within
this framework, the model continuously accumulates and refines its knowledge
base, thereby progressively improving the security of the generated code.
Experimental results demonstrate that RefleXGen substantially enhances code
security across multiple models, achieving a 13.6% improvement with GPT-3.5
Turbo, a 6.7% improvement with GPT-4o, a 4.5% improvement with CodeQwen, and a
5.8% improvement with Gemini. Our findings highlight that improving the quality
of model self-reflection constitutes an effective and practical strategy for
strengthening the security of AI-generated code.

</details>


### [89] [TDFlow: Agentic Workflows for Test Driven Software Engineering](https://arxiv.org/abs/2510.23761)
*Kevin Han,Siddharth Maddikayala,Tim Knappe,Om Patel,Austen Liao,Amir Barati Farimani*

Main category: cs.SE

TL;DR: TDFlow 是一种创新的测试驱动智能工作流程，将大规模软件工程任务转化为通过测试解决的补丁生成任务，显著提高了修复效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有软件工程修复方法难以高效解决复杂人类编写的测试，且单一智能体承担过多上下文信息，影响性能。

Method: 设计了分为补丁提出、调试、修订和测试生成四个子代理的工作流程，降低各子代理的任务复杂度并实现专门化优化。

Result: TDFlow 在 SWE-Bench Lite 和 Verified 测试集上分别达到88.8%和94.3%的测试通过率，优于现有系统27.8%。并且手动检查发现极低的测试篡改情况。

Conclusion: 嵌入精细工程化的测试驱动流程中的现代大语言模型能已达到人类水平的测试修复能力，未来关键在于准确生成有效的复现测试。

Abstract: We introduce TDFlow, a novel test-driven agentic workflow that frames
repository-scale software engineering as a test-resolution task, specifically
designed to solve human-written tests. Given a set of tests, TDFlow repeatedly
proposes, revises, and debugs repository-scale patches using precisely
engineered sub-agents and tightly constrained tools. The workflow decomposes
software engineering program repair into four components governed by respective
sub-agents. This simple, forced decoupling of patch proposing, debugging, patch
revision, and optional test generation (1) reduces long-context burden on any
individual sub-agent, (2) focuses each sub-agent on specific, pre-defined
sub-tasks, and (3) allows for specialized performance improvement on specific
sub-tasks. When provided human-written tests, TDFlow attains 88.8% pass rate on
SWE-Bench Lite (an absolute improvement of 27.8% over the next best system) and
94.3% on SWE-Bench Verified. Manual inspection of the 800 TDFlow runs within
SWE-Bench Lite and Verified uncover only 7 instances of test hacking, which
were subsequently counted as failures. Furthermore, we show that the primary
obstacle to human-level software engineering performance lies within writing
successful reproduction tests. We envision a human-LLM interactive system
powered by TDFlow where human developers write tests solved by LLM systems.
Together, these results indicate that modern LLMs, when embedded in a narrowly
engineered, test-driven workflow, already achieve human-level test resolution
-- with the final frontier for fully autonomous repository repair being the
accurate generation of valid reproduction tests.

</details>


### [90] [Evaluating the effectiveness of LLM-based interoperability](https://arxiv.org/abs/2510.23893)
*Rodrigo Falcão,Stefan Schweitzer,Julien Siebert,Emily Calvet,Frank Elberzhager*

Main category: cs.SE

TL;DR: 本文研究了基于大语言模型(LLMs)实现系统自主管理互操作性的效果，选取13个开源模型，基于农业互操作性数据集进行测试，qwen2.5-coder:32b表现最佳。


<details>
  <summary>Details</summary>
Motivation: 动态异构的系统环境对互操作性提出了更高要求，且开发互操作性工具成本高。本文旨在评估利用LLMs在运行时实现系统自主管理互操作的可行性。

Method: 测试13个开源LLMs，基于农业互操作性四个版本的数据集，使用两种策略（DIRECT和CODEGEN），多次运行并比较模型效果与结果一致性。

Result: qwen2.5-coder:32b在DIRECT和CODEGEN策略中表现最佳，前三个数据集版本的平均pass@1均高于0.89，在涉及单位转换的版本中，DIRECT策略失败，CODEGEN策略仍达0.75。

Conclusion: 部分LLMs具备自主管理系统互操作性能力，建议在不同领域继续评估并加强可靠性策略研究。

Abstract: Background: Systems of systems are becoming increasingly dynamic and
heterogeneous, and this adds pressure on the long-standing challenge of
interoperability. Besides its technical aspect, interoperability has also an
economic side, as development time efforts are required to build the
interoperability artifacts. Objectives: With the recent advances in the field
of large language models (LLMs), we aim at analyzing the effectiveness of
LLM-based strategies to make systems interoperate autonomously, at runtime,
without human intervention. Method: We selected 13 open source LLMs and curated
four versions of a dataset in the agricultural interoperability use case. We
performed three runs of each model with each version of the dataset, using two
different strategies. Then we compared the effectiveness of the models and the
consistency of their results across multiple runs. Results: qwen2.5-coder:32b
was the most effective model using both strategies DIRECT (average pass@1 >=
0.99) and CODEGEN (average pass@1 >= 0.89) in three out of four dataset
versions. In the fourth dataset version, which included an unit conversion, all
models using the strategy DIRECT failed, whereas using CODEGEN
qwen2.5-coder:32b succeeded with an average pass@1 = 0.75. Conclusion: Some
LLMs can make systems interoperate autonomously. Further evaluation in
different domains is recommended, and further research on reliability
strategies should be conducted.

</details>


### [91] [Validating Alerts in Cloud-Native Observability](https://arxiv.org/abs/2510.23970)
*Maria C. Borges,Julian Legler,Lucca Di Benedetto*

Main category: cs.SE

TL;DR: 该论文提出了一种用于监测警报设计与验证的工具扩展，帮助工程师在开发早期测试和调整警报规则，从而减少运行时错误。


<details>
  <summary>Details</summary>
Motivation: 报警设计需在尽早发现问题和减少误报之间取得平衡，且报警代码很少执行，缺乏系统化设计和验证工具。

Method: 在现有观测实验工具OXN上扩展警报功能，支持工程师在开发阶段进行规则调优和警报行为验证。

Result: 工程师能够在设计时调整和测试警报，提升警报的有效性和可靠性，减少生产故障。

Conclusion: 通过将警报代码的设计与验证系统化并纳入开发流程，能够提前发现并避免潜在运行时问题，提高系统可靠性。

Abstract: Observability and alerting form the backbone of modern reliability
engineering. Alerts help teams catch faults early before they turn into
production outages and serve as first clues for troubleshooting. However,
designing effective alerts is challenging. They need to strike a fine balance
between catching issues early and minimizing false alarms. On top of this,
alerts often cover uncommon faults, so the code is rarely executed and
therefore rarely checked. To address these challenges, several industry
practitioners advocate for testing alerting code with the same rigor as
application code. Still, there's a lack of tools that support such systematic
design and validation of alerts.
  This paper introduces a new alerting extension for the observability
experimentation tool OXN. It lets engineers experiment with alerts early during
development. With OXN, engineers can now tune rules at design time and
routinely validate the firing behavior of their alerts, avoiding future
problems at runtime.

</details>


### [92] [Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs](https://arxiv.org/abs/2510.24019)
*Xing Xing,Wei Wang,Lipeng Ma,Weidong Yang,Junjie Zheng*

Main category: cs.SE

TL;DR: 本文提出了一个生命周期感知框架，将软件开发的中间产物（如需求分析、状态机建模、伪代码）纳入大语言模型的训练和推理过程，从而显著提升自动代码生成的准确性和结构化。


<details>
  <summary>Details</summary>
Motivation: 当前自动代码生成多依赖于单步从问题描述直接翻译成代码，忽视了软件工程的结构化流程，导致生成代码质量有限。

Method: 设计了一个基于软件开发生命周期的多步骤生成框架，将需求分析、状态机建模、伪代码等作为中间产物引入训练和推理，允许模型进行分步推理和调优。

Result: 生命周期级微调使代码正确率提升最高达75%，多步推理优于单步生成，开源模型经微调可与或超越预训练代码模型。具体在DeepSeek-Coder-1.3B上对比多个模型有明显CodeBLEU提升，且对训练数据量大幅减少具备鲁棒性。

Conclusion: 引入中间软件工程产物为自动代码生成提供了有效的结构化支撑，显著提升代码质量和模型性能，尤其状态机建模对最终成果贡献最大。该框架适用性强且公开了源码和实验数据。

Abstract: Recent progress in large language models (LLMs) has advanced automatic code
generation, yet most approaches rely on direct, single-step translation from
problem descriptions to code, disregarding structured software engineering
practices. We introduce a lifecycle-aware framework that systematically
incorporates intermediate artifacts such as requirements analysis, state
machine modeling, and pseudocode into both the training and inference stages.
This design aligns code generation with standard software development phases
and enables more structured reasoning. Experiments show that lifecycle-level
fine-tuning improves code correctness by up to 75% over the same model before
fine-tuning, with performance gains compounding across intermediate stages.
Multi-step inference consistently surpasses single-step generation,
demonstrating the effectiveness of intermediate scaffolding. Notably,
open-source LLMs, once fine-tuned under our framework, match or slightly
outperform models pretrained on code. When applied to DeepSeek-Coder-1.3B, our
framework yields relative CodeBLEU improvements of 34.3%, 20.0%, 11.2%, and
22.3% over ChatGPT-3.5, ChatGPT-4o-mini, DeepSeek-R1, and LLaMA-8B,
respectively. Our pipeline also proves robust with up to 80\% less training
data, confirming its resilience. Ablation studies further reveal that each
intermediate artifact contributes distinctly to final code quality, with state
machine modeling yielding the most substantial impact. Our source code and
detailed experimental data are available at
https://anonymous.4open.science/r/Lifecycle-Aware-3CCB.

</details>


### [93] [Monitoring and Observability of Machine Learning Systems: Current Practices and Gaps](https://arxiv.org/abs/2510.24142)
*Joran Leest,Ilias Gerostathopoulos,Patricia Lago,Claudia Raibulet*

Main category: cs.SE

TL;DR: 本文通过七个焦点小组研究了生产环境中机器学习系统的可观测性实践，分析了从模型验证到故障诊断的系统捕获信息及其应用，并指出了当前实践中的不足。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习系统在生产中经常无声失败，缺少对实践中可观测性真实情况的经验研究。

Method: 通过七个不同领域的焦点小组会议，收集和分析实践者对ML系统及其环境的系统性信息捕获及使用情况。

Result: 系统地整理了实践者采集的信息类别和使用方式，揭示了模型验证、故障检测诊断和性能下降解释过程中的信息需求和应用方式。

Conclusion: 当前机器学习系统可观测性存在缺口，研究结果为工具设计和方法改进提供指导，推动建立完善的ML可观测性实践体系。

Abstract: Production machine learning (ML) systems fail silently -- not with crashes,
but through wrong decisions. While observability is recognized as critical for
ML operations, there is a lack empirical evidence of what practitioners
actually capture. This study presents empirical results on ML observability in
practice through seven focus group sessions in several domains. We catalog the
information practitioners systematically capture across ML systems and their
environment and map how they use it to validate models, detect and diagnose
faults, and explain observed degradations. Finally, we identify gaps in current
practice and outline implications for tooling design and research to establish
ML observability practices.

</details>


### [94] [Investigating Software Aging in LLM-Generated Software Systems](https://arxiv.org/abs/2510.24188)
*César Santos,Ermeson Andrade,Roberto Natella*

Main category: cs.SE

TL;DR: 本文通过对四个由大型语言模型生成的服务型应用进行长达50小时的负载测试，发现软件老化现象，包括内存增长、响应时间增加和性能不稳定，并强调自动生成软件的长期可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型生成的代码被广泛采用，长期运行的可靠性问题尚不清楚，需研究自动生成软件的老化现象。

Method: 利用Bolt平台和Baxbench标准化提示语生成四个应用，进行50小时负载测试，持续监测资源使用、响应时间和吞吐量，统计分析性能退化。

Result: 所有应用表现出显著的软件老化迹象，如内存持续增长、响应时间提升和性能波动，且不同应用老化严重程度存在差异。

Conclusion: 自动生成的软件存在软件老化风险，应重视其长期可靠性，并为未来缓解策略和评估方法的研究奠定基础。

Abstract: Automatically generated software, especially code produced by Large Language
Models (LLMs), is increasingly adopted to accelerate development and reduce
manual effort. However, little is known about the long-term reliability of such
systems under sustained execution. In this paper, we experimentally investigate
the phenomenon of software aging in applications generated by LLM-based tools.
Using the Bolt platform and standardized prompts from Baxbench, we generated
four service-oriented applications and subjected them to 50-hour load tests.
Resource usage, response time, and throughput were continuously monitored to
detect degradation patterns. The results reveal significant evidence of
software aging, including progressive memory growth, increased response time,
and performance instability across all applications. Statistical analyzes
confirm these trends and highlight variability in the severity of aging
according to the type of application. Our findings show the need to consider
aging in automatically generated software and provide a foundation for future
studies on mitigation strategies and long-term reliability evaluation.

</details>


### [95] [MAGNET: A Multi-Graph Attentional Network for Code Clone Detection](https://arxiv.org/abs/2510.24241)
*Zixian Zhang,Takfarinas Saber*

Main category: cs.SE

TL;DR: 本文提出了一种名为MAGNET的多图注意力框架，用于代码克隆检测，通过融合AST、CFG和DFG三种代码表示，提升代码语义捕获能力，实现了优异的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有代码克隆检测方法多依赖单一代码表示，无法全面捕获代码语义，且现有多模态融合方法融合策略效果有限。

Method: 提出MAGNET框架，联合使用AST、CFG和DFG三种图结构，采用残差图神经网络结合节点自注意力机制，以及门控交叉注意力实现多图细粒度交互，用Set2Set池化融合多图嵌入。

Result: 在BigCloneBench和Google Code Jam数据集上分别达到96.5%和99.2%的F1分数，显著优于现有方法。消融实验验证了多图融合和注意力组件的重要作用。

Conclusion: MAGNET有效融合多种代码图表示，提升了代码克隆检测性能，说明多图神经网络与注意力机制的结合对捕获代码语义具有重要价值。

Abstract: Code clone detection is a fundamental task in software engineering that
underpins refactoring, debugging, plagiarism detection, and vulnerability
analysis. Existing methods often rely on singular representations such as
abstract syntax trees (ASTs), control flow graphs (CFGs), and data flow graphs
(DFGs), which capture only partial aspects of code semantics. Hybrid approaches
have emerged, but their fusion strategies are typically handcrafted and
ineffective. In this study, we propose MAGNET, a multi-graph attentional
framework that jointly leverages AST, CFG, and DFG representations to capture
syntactic and semantic features of source code. MAGNET integrates residual
graph neural networks with node-level self-attention to learn both local and
long-range dependencies, introduces a gated cross-attention mechanism for
fine-grained inter-graph interactions, and employs Set2Set pooling to fuse
multi-graph embeddings into unified program-level representations. Extensive
experiments on BigCloneBench and Google Code Jam demonstrate that MAGNET
achieves state-of-the-art performance with an overall F1 score of 96.5\% and
99.2\% on the two datasets, respectively. Ablation studies confirm the critical
contributions of multi-graph fusion and each attentional component. Our code is
available at https://github.com/ZixianReid/Multigraph_match

</details>


### [96] [Developer Productivity with GenAI](https://arxiv.org/abs/2510.24265)
*Sadia Afroz,Zixuan Feng,Katie Kimura,Bianca Trinkenreich,Igor Steinmacher,Anita Sarma*

Main category: cs.SE

TL;DR: 本文通过对415名软件开发者的调查，研究生成式AI工具在开发中的使用频率对生产力的多维影响，结果显示虽开发速度加快，但软件质量和开发者满意度未明显提升，体现了生产力悖论。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具在软件开发中普及，其实际提升生产力的场景和效果仍不明朗，研究旨在明确这些工具对开发者多维生产力的影响。

Method: 采用SPACE框架（满意度与福祉、表现、活动、沟通协作、效率与流程）对415名软件从业者进行了问卷调查，并根据AI使用频率分析影响。

Result: 总体生产力变化有限，开发速度有所加快，但并未显著提高软件质量或开发者满足感。

Conclusion: 生成式AI工具虽能提升开发速度，但不一定带来更高质量的软件或更强的开发者满足感，体现生产力悖论。

Abstract: Generative AI (GenAI) tools are increasingly being adopted in software
development as productivity aids. However, evidence regarding where and when
these tools actually enhance productivity is unclear. In this paper, we
investigate how GenAI adoption affects different dimensions of developer
productivity. We surveyed 415 software practitioners to capture their
perceptions of productivity changes associated with AI-assisted development
using the SPACE framework - Satisfaction and well-being, Performance, Activity,
Communication and collaboration, and Efficiency and flow. Our results,
disaggregated by frequency of AI usage, reveal limited overall productivity
change, highlighting the productivity paradox in which developers become faster
but do not necessarily create better software or feel more fulfilled.

</details>


### [97] [Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation](https://arxiv.org/abs/2510.24358)
*Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu*

Main category: cs.SE

TL;DR: 本文提出了一种基于代理驱动的基准构建方法，设计了包含50个真实Python项目的PRDBench基准，支持多维度评测。


<details>
  <summary>Details</summary>
Motivation: 现有代码代理的评测基准存在标注成本高且依赖单一测试评价指标的问题。

Method: 引入代理驱动的基准构建流程和Agent-as-a-Judge评分范式，生成多样且复杂的项目级任务，并采用灵活多样的评测标准。

Result: PRDBench涵盖20个领域的真实项目，支持丰富数据源和复杂任务，能有效评估多种代码代理及评测代理的能力。

Conclusion: PRDBench提供了一个可扩展且鲁棒的项目级代码代理评测框架，克服了传统基准的不足，推动代码代理领域的发展。

Abstract: Recent advances in code agents have enabled automated software development at
the project level, supported by large language models (LLMs) and widely adopted
tools. However, existing benchmarks for code agent evaluation face two major
limitations: high annotation cost and expertise requirements, and rigid
evaluation metrics that rely primarily on unit tests. To address these
challenges, we propose an agent-driven benchmark construction pipeline that
leverages human supervision to efficiently generate diverse and challenging
project-level tasks. Based on this approach, we introduce PRDBench, a novel
benchmark comprising 50 real-world Python projects across 20 domains, each with
structured Product Requirement Document (PRD) requirements, comprehensive
evaluation criteria, and reference implementations. PRDBench features rich data
sources, high task complexity, and flexible metrics. We further employ an
Agent-as-a-Judge paradigm to score agent outputs, enabling the evaluation of
various test types beyond unit tests. Extensive experiments on PRDBench
demonstrate its effectiveness in assessing the capabilities of both code agents
and evaluation agents, providing a scalable and robust framework for annotation
and evaluation.

</details>


### [98] [LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead](https://arxiv.org/abs/2510.24367)
*Junda He,Jieke Shi,Terry Yue Zhuo,Christoph Treude,Jiamou Sun,Zhenchang Xing,Xiaoning Du,David Lo*

Main category: cs.SE

TL;DR: 本文探讨了大型语言模型（LLMs）在软件工程中的应用，特别是作为自动评估工具来解决人工评估成本高和传统指标不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs生成大量软件工件，传统评估方法效率低且准确度有限，亟需一种可扩展且可靠的评估方法。

Method: 本文提供了对现有软件工程中LLM作为评判工具的研究综述，分析现存不足，识别关键研究空白，并提出未来发展路线图。

Result: 研究表明现有方法尚处于初级阶段，尚未实现完全可靠与多维度评估。

Conclusion: 本文展望到2030年，LLM作为评判工具将成为人类评估的有效替代，推动软件工件评估的规模化和多样化。

Abstract: The rapid integration of Large Language Models (LLMs) into software
engineering (SE) has revolutionized tasks like code generation, producing a
massive volume of software artifacts. This surge has exposed a critical
bottleneck: the lack of scalable, reliable methods to evaluate these outputs.
Human evaluation is costly and time-consuming, while traditional automated
metrics like BLEU fail to capture nuanced quality aspects. In response, the
LLM-as-a-Judge paradigm - using LLMs for automated evaluation - has emerged.
This approach leverages the advanced reasoning of LLMs, offering a path toward
human-like nuance at automated scale. However, LLM-as-a-Judge research in SE is
still in its early stages. This forward-looking SE 2030 paper aims to steer the
community toward advancing LLM-as-a-Judge for evaluating LLM-generated software
artifacts. We provide a literature review of existing SE studies, analyze their
limitations, identify key research gaps, and outline a detailed roadmap. We
envision these frameworks as reliable, robust, and scalable human surrogates
capable of consistent, multi-faceted artifact evaluation by 2030. Our work aims
to foster research and adoption of LLM-as-a-Judge frameworks, ultimately
improving the scalability of software artifact evaluation.

</details>


### [99] [CodeWiki: Automated Repository-Level Documentation at Scale](https://arxiv.org/abs/2510.24428)
*Nguyen Hoang Anh,Minh Le-Anh,Bach Le,Nghi D. Q. Bui*

Main category: cs.SE

TL;DR: CodeWiki是一个开源框架，旨在自动生成跨七种编程语言的整仓库级别文档，通过层次分解、递归代理处理和文本加视觉综合提高文档质量，优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 开发者花费大量时间理解代码库，但现有自动文档工具主要聚焦于函数级，无法有效捕捉仓库层面的架构模式和跨模块交互，导致文档维护困难。

Method: CodeWiki引入层次分解保存架构上下文，递归代理处理机制结合动态任务分配，以及文本和架构图、数据流等视觉产物的综合生成，支持七种编程语言。并设计CodeWikiBench作为评价基准。

Result: CodeWiki使用专有模型达到68.79%的文档质量分，开源模型达到64.80%，均优于现有闭源系统，表现出对真实仓库的良好扩展性和准确性。

Conclusion: CodeWiki实现了跨语言、全仓库范围的高质量自动文档生成，为解决复杂软件系统的维护和理解提供了一种有效工具。

Abstract: Developers spend nearly 58% of their time understanding codebases, yet
maintaining comprehensive documentation remains challenging due to complexity
and manual effort. While recent Large Language Models (LLMs) show promise for
function-level documentation, they fail at the repository level, where
capturing architectural patterns and cross-module interactions is essential. We
introduce CodeWiki, the first open-source framework for holistic
repository-level documentation across seven programming languages. CodeWiki
employs three innovations: (i) hierarchical decomposition that preserves
architectural context, (ii) recursive agentic processing with dynamic
delegation, and (iii) synthesis of textual and visual artifacts including
architecture diagrams and data flows. We also present CodeWikiBench, the first
repository-level documentation benchmark with multi-level rubrics and agentic
assessment. CodeWiki achieves 68.79% quality score with proprietary models and
64.80% with open-source alternatives, outperforming existing closed-source
systems and demonstrating scalable, accurate documentation for real-world
repositories.

</details>


### [100] [The Divine Software Engineering Comedy -- Inferno: The Okinawa Files](https://arxiv.org/abs/2510.24483)
*Michele Lanza*

Main category: cs.SE

TL;DR: 本文是作者对2024年在日本冲绳举办的软件工程未来研讨会的反思与观察。


<details>
  <summary>Details</summary>
Motivation: 研讨会旨在探讨软件工程的未来及其发展方向。

Method: 通过组织和参与多位专家的讨论，收集并分析对软件工程未来的不同观点。

Result: 总结出软件工程面临的三大“噩梦”：一是软件开发者技能不足却能完成工作，二是领域发展过快难以吸取教训，三是技术快速增殖带来的挑战。

Conclusion: 软件工程的未来充满不确定性和风险，虽然令人担忧，但这种讨论有助于正视问题并推动领域进步。

Abstract: In June 2024 I co-organized the FUture of Software Engineering symposium in
Okinawa, Japan. Me, Andrian Marcus, Takashi Kobayashi and Shinpei Hayashi were
general chairs, Nicole Novielli, Kevin Moran, Yutaro Kashiwa and Masanari Kondo
were program chairs, some members of my group, Carmen Armenti, Stefano
Campanella, Roberto Minelli, were the tables, can't have a room with only
chairs, after all. We invited a crowd of people to discuss what future software
engineering has. FUSE became a 3-day marathon on whether there is actually a
future at all for SE. This essay is a slightly dark take about what I saw at
that event, very loosely based on the discussions that took place, adding some
healthy sarcasm and cynicism, the intellectual salt and pepper I never seem to
run out of. I listened to the brilliant people who gathered to talk about where
we're headed, and distilled three nightmares headed in our direction: software
makers who don't know what they're doing, but get the job done anyway, a field
moving so fast it can't remember its own lessons, and technologies multiplying
like rabbits in Spring. So, let's start. The future, eh? The future of software
engineering looks like a car crash in slow motion: you can see it coming but
you can't look away. The thing is...

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [101] [Logic-based Task Representation and Reward Shaping in Multiagent Reinforcement Learning](https://arxiv.org/abs/2510.23615)
*Nishant Doshi*

Main category: cs.MA

TL;DR: 本文提出了一种基于线性时序逻辑任务的多智能体系统加速学习最优计划的方法，通过构建Buchi自动机和半马尔科夫决策过程，结合奖励塑造技术显著提升学习效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统中任务复杂且状态空间大，尤其使用线性时序逻辑描述任务时，学习最优计划的样本复杂度呈指数增长。

Method: 将任务规格转换为Buchi自动机，构建产品半马尔科夫决策过程，采用无模型基于价值的强化学习算法，并引入奖励塑造方法以降低样本复杂度。

Result: 在确定性网格世界中多个任务测试结果表明，奖励塑造显著减少了收敛时间，同时选项机制在大规模状态动作空间中更显重要性。

Conclusion: 通过结合时序逻辑任务表示、选项和奖励塑造，成功加速了多智能体系统中的最优计划学习，提升了算法的实用性和效率。

Abstract: This paper presents an approach for accelerated learning of optimal plans for
a given task represented using Linear Temporal Logic (LTL) in multi-agent
systems. Given a set of options (temporally abstract actions) available to each
agent, we convert the task specification into the corresponding Buchi Automaton
and proceed with a model-free approach which collects transition samples and
constructs a product Semi Markov Decision Process (SMDP) on-the-fly.
Value-based Reinforcement Learning algorithms can then be used to synthesize a
correct-by-design controller without learning the underlying transition model
of the multi-agent system. The exponential sample complexity due to multiple
agents is dealt with using a novel reward shaping approach. We test the
proposed algorithm in a deterministic gridworld simulation for different tasks
and find that the reward shaping results in significant reduction in
convergence times. We also infer that using options becomes increasing more
relevant as the state and action space increases in multi-agent systems.

</details>


### [102] [Coordinated Autonomous Drones for Human-Centered Fire Evacuation in Partially Observable Urban Environments](https://arxiv.org/abs/2510.23899)
*Maria G. Mendoza,Addison Kalanther,Daniel Bostwick,Emma Stephan,Chinmay Maheshwari,Shankar Sastry*

Main category: cs.MA

TL;DR: 该论文提出了利用多智能体无人机协调框架，实时辅助火灾中的人员疏散，通过定位、拦截并引导人员安全撤离，有效应对逃生过程中因恐慌和不确定性导致的行为偏离问题。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机辅助疏散系统往往忽略了极端应激下人类行为的心理和情感复杂性，实际火灾逃生中人员常因恐慌偏离安全路径，急需能够适应动态环境的实时辅助系统。

Method: 将问题建模为部分可观测马尔可夫决策过程，设计两类异构无人机（高层救援者和低层救援者）协作框架，结合基于心理学的代理人模型模拟人的恐慌行为，利用基于PPO算法的递归策略实现长期规划和动态适应。

Result: 仿真结果显示，协作无人机团队能快速定位并拦截受困人员，显著缩短人员安全撤离所需时间，相较无无人机辅助方案效果优越。

Conclusion: 所提多智能体无人机协调框架有效提升了火灾紧急疏散的效率和安全性，为动态复杂环境下的无人机应急辅助提供了实用方法和理论支持。

Abstract: Autonomous drone technology holds significant promise for enhancing search
and rescue operations during evacuations by guiding humans toward safety and
supporting broader emergency response efforts. However, their application in
dynamic, real-time evacuation support remains limited. Existing models often
overlook the psychological and emotional complexity of human behavior under
extreme stress. In real-world fire scenarios, evacuees frequently deviate from
designated safe routes due to panic and uncertainty. To address these
challenges, this paper presents a multi-agent coordination framework in which
autonomous Unmanned Aerial Vehicles (UAVs) assist human evacuees in real-time
by locating, intercepting, and guiding them to safety under uncertain
conditions. We model the problem as a Partially Observable Markov Decision
Process (POMDP), where two heterogeneous UAV agents, a high-level rescuer (HLR)
and a low-level rescuer (LLR), coordinate through shared observations and
complementary capabilities. Human behavior is captured using an agent-based
model grounded in empirical psychology, where panic dynamically affects
decision-making and movement in response to environmental stimuli. The
environment features stochastic fire spread, unknown evacuee locations, and
limited visibility, requiring UAVs to plan over long horizons to search for
humans and adapt in real-time. Our framework employs the Proximal Policy
Optimization (PPO) algorithm with recurrent policies to enable robust
decision-making in partially observable settings. Simulation results
demonstrate that the UAV team can rapidly locate and intercept evacuees,
significantly reducing the time required for them to reach safety compared to
scenarios without UAV assistance.

</details>


### [103] [Human Machine Social Hybrid Intelligence:A Collaborative Decision Making Framework for Large Model Agent Groups and Human Experts](https://arxiv.org/abs/2510.24030)
*Ahmet Akkaya Melih,Yamuna Singh,Kunal L. Agarwal,Priya Mukherjee,Kiran Pattnaik,Hanuman Bhatia*

Main category: cs.MA

TL;DR: 本文提出了一个名为"人机社会混合智能"的框架，旨在通过共享认知空间、动态任务分配和跨物种信任校准，实现人类专家与大型语言模型驱动的AI代理之间的深度协作决策。实验表明，该框架在应急响应模拟中显著减少了死亡率和认知负荷，提升了决策质量和效率。


<details>
  <summary>Details</summary>
Motivation: 当前人机交互范式未能有效整合人类专业知识，导致在复杂高风险环境中认知过载和决策瓶颈。需要一个能促进群体人类专家与AI代理深入协作的架构。

Method: 设计了"人机社会混合智能"框架，包含共享认知空间（统一多模态情境感知和结构化世界建模）、动态角色与任务分配（根据能力和负载自适应分配任务），以及跨物种信任校准协议（通过可解释声明和结构化反馈促进透明性和互适应）。

Result: 在高保真城市应急响应模拟中，该框架相比传统人机交互方式，降低了72%的平民伤亡和70%的认知负荷，同时提升了决策质量、效率和人机信任度。消融实验证明了各模块的重要贡献。

Conclusion: 基于构建信任和共享情境的机制是实现可扩展、高效协同人机决策的基础，本文提出的框架为未来复杂高风险环境下的人机深度协作提供了有效范式。

Abstract: The rapid advancements in large foundation models and multi-agent systems
offer unprecedented capabilities, yet current Human-in-the-Loop (HiTL)
paradigms inadequately integrate human expertise, often leading to cognitive
overload and decision-making bottlenecks in complex, high-stakes environments.
We propose the "Human-Machine Social Hybrid Intelligence" (HMS-HI) framework, a
novel architecture designed for deep, collaborative decision-making between
groups of human experts and LLM-powered AI agents. HMS-HI is built upon three
core pillars: (1) a \textbf{Shared Cognitive Space (SCS)} for unified,
multi-modal situational awareness and structured world modeling; (2) a
\textbf{Dynamic Role and Task Allocation (DRTA)} module that adaptively assigns
tasks to the most suitable agent (human or AI) based on capabilities and
workload; and (3) a \textbf{Cross-Species Trust Calibration (CSTC)} protocol
that fosters transparency, accountability, and mutual adaptation through
explainable declarations and structured feedback. Validated in a high-fidelity
urban emergency response simulation, HMS-HI significantly reduced civilian
casualties by 72\% and cognitive load by 70\% compared to traditional HiTL
approaches, demonstrating superior decision quality, efficiency, and human-AI
trust. An ablation study confirms the critical contribution of each module,
highlighting that engineered trust and shared context are foundational for
scalable, synergistic human-AI collaboration.

</details>
