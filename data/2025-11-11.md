<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 99]
- [cs.SE](#cs.SE) [Total: 28]
- [cs.MA](#cs.MA) [Total: 6]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation](https://arxiv.org/abs/2511.05516)
*Canxiang Yan,Chunxiang Jin,Dawei Huang,Haibing Yu,Han Peng,Hui Zhan,Jie Gao,Jing Peng,Jingdong Chen,Jun Zhou,Kaimeng Ren,Ming Yang,Mingxue Yang,Qiang Xu,Qin Zhao,Ruijie Xiong,Shaoxiong Lin,Xuezhi Wang,Yi Yuan,Yifei Wu,Yongjie Lyu,Zhengyu He,Zhihao Qiu,Zhiqiang Fang,Ziyuan Huang*

Main category: cs.CL

TL;DR: 该论文提出了一个统一的连续语音分词器MingTok-Audio和基于它的语音语言模型Ming-UniAudio，实现了语音理解、生成和自由形式编辑的统一。


<details>
  <summary>Details</summary>
Motivation: 现有语音模型在理解和生成任务中对Token表示有冲突，导致难以实现基于指令的自由形式编辑。

Method: 设计了融合语义与声学特征的连续语音分词器MingTok-Audio，基于该分词器开发统一语音语言模型Ming-UniAudio，并进一步训练自由形式指令驱动的语音编辑模型Ming-UniAudio-Edit。

Result: Ming-UniAudio在ContextASR基准测试中8项指标达到SOTA，其中中文语音克隆任务的Seed-TTS-WER达到0.95，编辑模型实现了无需时间戳的语义和声学自由编辑。

Conclusion: 提出的统一框架有效整合了语音理解、生成和编辑，推动了语音语言模型在多任务上的应用，相关模型和数据集已开源促进后续研究。

Abstract: Existing speech models suffer from competing requirements on token representations by understanding and generation tasks. This discrepancy in representation prevents speech language models from performing instruction-based free-form editing. To solve this challenge, we introduce a novel framework that unifies speech understanding, generation, and editing. The core of our unified model is a unified continuous speech tokenizer MingTok-Audio, the first continuous tokenizer to effectively integrate semantic and acoustic features, which makes it suitable for both understanding and generation tasks. Based on this unified continuous audio tokenizer, we developed the speech language model Ming-UniAudio, which achieved a balance between generation and understanding capabilities. Ming-UniAudio sets new state-of-the-art (SOTA) records on 8 out of 12 metrics on the ContextASR benchmark. Notably, for Chinese voice cloning, it achieves a highly competitive Seed-TTS-WER of 0.95. Leveraging this foundational model, we further trained a dedicated speech editing model Ming-UniAudio-Edit, the first speech language model that enables universal, free-form speech editing guided solely by natural language instructions, handling both semantic and acoustic modifications without timestamp condition. To rigorously assess the editing capability and establish a foundation for future research, we introduce Ming-Freeform-Audio-Edit, the first comprehensive benchmark tailored for instruction-based free-form speech editing, featuring diverse scenarios and evaluation dimensions spanning semantic correctness, acoustic quality, and instruction alignment. We open-sourced the continuous audio tokenizer, the unified foundational model, and the free-form instruction-based editing model to facilitate the development of unified audio understanding, generation, and manipulation.

</details>


### [2] [Retracing the Past: LLMs Emit Training Data When They Get Lost](https://arxiv.org/abs/2511.05518)
*Myeongseob Ko,Nikhil Reddy Billa,Adam Nguyen,Charles Fleming,Ming Jin,Ruoxi Jia*

Main category: cs.CL

TL;DR: 本文提出了一种新的攻击方法CIA，通过引入困惑状态最大化模型的不确定性，从而有效提取大语言模型中的记忆数据，提升了对模型记忆风险的评估能力。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型中的训练数据记忆带来了隐私和版权问题，现有的数据提取方法效果有限且缺乏对记忆泄露本质的理解。

Method: 提出了Confusion-Inducing Attacks（CIA）框架，通过优化输入片段以诱导模型持续的高熵预测状态，从而提取记忆信息；对于对齐模型，还提出了不匹配的监督微调以削弱模型对齐性并增强攻击效果。

Result: 在多种对齐和未对齐模型上，CIA方法在无需事先知道训练数据的情况下，比现有方法更有效地提取了精确或近似精确的训练数据。

Conclusion: 该研究揭示了不同大语言模型中持续存在的记忆泄露风险，提供了一种更系统化的风险评估方法，有助于提升对模型记忆隐私问题的理解和防护。

Abstract: The memorization of training data in large language models (LLMs) poses significant privacy and copyright concerns. Existing data extraction methods, particularly heuristic-based divergence attacks, often exhibit limited success and offer limited insight into the fundamental drivers of memorization leakage. This paper introduces Confusion-Inducing Attacks (CIA), a principled framework for extracting memorized data by systematically maximizing model uncertainty. We empirically demonstrate that the emission of memorized text during divergence is preceded by a sustained spike in token-level prediction entropy. CIA leverages this insight by optimizing input snippets to deliberately induce this consecutive high-entropy state. For aligned LLMs, we further propose Mismatched Supervised Fine-tuning (SFT) to simultaneously weaken their alignment and induce targeted confusion, thereby increasing susceptibility to our attacks. Experiments on various unaligned and aligned LLMs demonstrate that our proposed attacks outperform existing baselines in extracting verbatim and near-verbatim training data without requiring prior knowledge of the training data. Our findings highlight persistent memorization risks across various LLMs and offer a more systematic method for assessing these vulnerabilities.

</details>


### [3] [Beyond One-Size-Fits-All: Personalized Harmful Content Detection with In-Context Learning](https://arxiv.org/abs/2511.05532)
*Rufan Zhang,Lin Zhang,Xianghang Mi*

Main category: cs.CL

TL;DR: 本文提出了一种基于大模型的上下文学习（ICL）的内容审查框架，能够统一检测有害内容如毒性、垃圾信息和负面情绪，并支持轻量级个性化，无需重训模型即可扩展或调整检测类别。


<details>
  <summary>Details</summary>
Motivation: 现有内容审查系统集中化且任务专一，透明度低且忽视用户多样化偏好，不适合隐私敏感或去中心化环境。

Method: 利用基础模型的上下文学习能力，设计统一的检测框架，支持二分类、多分类和多标签设置，通过简单的提示调整实现个性化和语义扩展，无需模型重训。

Result: 在多个公开基准和新标注的Mastodon数据集上，基础模型表现优于或匹配专门微调模型；个性化需求可用极少示例实现；引入标签定义或推理显著提升对现实噪声数据的鲁棒性。

Conclusion: 本文方法代表了内容审查从一刀切向用户中心、隐私保护和高度适应性方向的重要转变，展示了基于ICL的实用审查新途径。代码和数据公开促进可复现和后续研究。

Abstract: The proliferation of harmful online content--e.g., toxicity, spam, and negative sentiment--demands robust and adaptable moderation systems. However, prevailing moderation systems are centralized and task-specific, offering limited transparency and neglecting diverse user preferences--an approach ill-suited for privacy-sensitive or decentralized environments. We propose a novel framework that leverages in-context learning (ICL) with foundation models to unify the detection of toxicity, spam, and negative sentiment across binary, multi-class, and multi-label settings. Crucially, our approach enables lightweight personalization, allowing users to easily block new categories, unblock existing ones, or extend detection to semantic variations through simple prompt-based interventions--all without model retraining. Extensive experiments on public benchmarks (TextDetox, UCI SMS, SST2) and a new, annotated Mastodon dataset reveal that: (i) foundation models achieve strong cross-task generalization, often matching or surpassing task-specific fine-tuned models; (ii) effective personalization is achievable with as few as one user-provided example or definition; and (iii) augmenting prompts with label definitions or rationales significantly enhances robustness to noisy, real-world data. Our work demonstrates a definitive shift beyond one-size-fits-all moderation, establishing ICL as a practical, privacy-preserving, and highly adaptable pathway for the next generation of user-centric content safety systems. To foster reproducibility and facilitate future research, we publicly release our code on GitHub and the annotated Mastodon dataset on Hugging Face.

</details>


### [4] [MCP4IFC: IFC-Based Building Design Using Large Language Models](https://arxiv.org/abs/2511.05533)
*Bharathi Kannan Nithyanantham,Tobias Sesterhenn,Ashwin Nedungadi,Sergio Peral Garijo,Janis Zenkner,Christian Bartelt,Stefan Lüdtke*

Main category: cs.CL

TL;DR: 本文提出了MCP4IFC开源框架，使大型语言模型能够通过模型上下文协议直接操作建筑行业标准数据IFC，实现自然语言指令到建筑模型操作的转换。


<details>
  <summary>Details</summary>
Motivation: 推动生成式人工智能在建筑、工程与施工领域应用，需要将自然语言指令转换为对标准化数据模型的操作，实现智能化设计与编辑。

Method: 设计了MCP4IFC框架，包含BIM场景查询工具、预定义建筑元素操作函数及结合上下文学习和检索增强生成的动态代码生成系统，以扩展预定义功能集外的任务处理能力。

Result: 实验表明，基于该框架的大型语言模型能够完成从简单建筑创建到已有IFC数据查询和编辑的复杂任务。

Conclusion: MCP4IFC作为开源工具促进了LLM驱动的BIM设计研究，为AI辅助建模工作流程奠定了基础。

Abstract: Bringing generative AI into the architecture, engineering and construction (AEC) field requires systems that can translate natural language instructions into actions on standardized data models. We present MCP4IFC, a comprehensive open-source framework that enables Large Language Models (LLMs) to directly manipulate Industry Foundation Classes (IFC) data through the Model Context Protocol (MCP). The framework provides a set of BIM tools, including scene querying tools for information retrieval, predefined functions for creating and modifying common building elements, and a dynamic code-generation system that combines in-context learning with retrieval-augmented generation (RAG) to handle tasks beyond the predefined toolset. Experiments demonstrate that an LLM using our framework can successfully perform complex tasks, from building a simple house to querying and editing existing IFC data. Our framework is released as open-source to encourage research in LLM-driven BIM design and provide a foundation for AI-assisted modeling workflows. Our code is available at https://show2instruct.github.io/mcp4ifc/.

</details>


### [5] [FlowMM: Cross-Modal Information Flow Guided KV Cache Merging for Efficient Multimodal Context Inference](https://arxiv.org/abs/2511.05534)
*Kunxi Li,Yufan Xiong,Zhonghua Jiang,Yiyun Zhou,Zhaode Wang,Chengfei Lv,Shengyu Zhang*

Main category: cs.CL

TL;DR: 提出了FlowMM，一种基于跨模态信息流的自适应多模态KV缓存合并框架，有效减少内存和延迟，保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统KV缓存剔除策略因丢弃关键KV对导致内容遗失和幻觉，尤其在多模态场景下，现有KV合并方法受分布偏差和注意力偏差影响效果有限。

Method: FlowMM利用跨模态信息流动态应用层特定合并策略，捕捉模态特征并保持上下文完整，引入敏感度自适应的令牌匹配机制，综合评估令牌相似性和任务敏感度，合并低风险令牌，保护高敏感令牌。

Result: 在多种主流多模态大模型上实验，FlowMM实现了80%至95%的KV缓存内存减少和1.3到1.8倍的解码延迟降低，同时保持竞争力的任务表现。

Conclusion: FlowMM有效解决了多模态KV缓存合并中的偏差与信息丢失问题，实现显著资源节约和性能保证，是多模态模型KV缓存管理的有力方案。

Abstract: Traditional KV cache eviction strategies, which discard less critical KV-pairs based on attention scores, often degrade generation quality, causing context loss or hallucinations. Recent efforts shift toward KV merging, merging eviction tokens with retention tokens based on similarity. However, in multimodal scenarios, distributional biases across modality tokens and attentional biases in cross-modal interactions limit its effectiveness. This work introduces FlowMM, an adaptive framework for cross-modal information flow-guided multimodal KV cache merging. FlowMM leverages cross-modal information flow to dynamically apply layer-specific merging strategies, capturing modality-specific patterns while preserving contextual integrity. Furthermore, we introduce a sensitivity-adaptive token matching mechanism that jointly evaluates token similarity and task-critical sensitivity, merging low-risk tokens while safeguarding high-sensitivity ones. Extensive experiments across diverse leading MLLMs show that FlowMM reduces KV cache memory by 80% to 95% and decoding latency by 1.3-1.8x, while maintaining competitive task performance.

</details>


### [6] [Future of AI Models: A Computational perspective on Model collapse](https://arxiv.org/abs/2511.05535)
*Trivikram Satharasi,S Sitharama Iyengar*

Main category: cs.CL

TL;DR: 本文研究了人工智能生成内容在维基百科语义多样性上的影响，发现随着大型语言模型的普及，语义相似度显著增加，表明数据多样性可能被递归训练侵蚀，导致模型崩溃风险。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容数量激增，递归使用合成数据进行训练可能削弱语义和语言多样性，威胁模型的泛化能力。研究旨在量化和预测这一“模型崩溃”现象的出现时间。

Method: 利用2013至2025年英文维基百科经过筛选的Common Crawl数据，使用Transformer嵌入和余弦相似度分析语义相似度变化趋势，揭示语义多样性变化规律。

Result: 发现语义相似度在公开大型语言模型普及前缓慢上升，主要由早期RNN/LSTM翻译和文本归一化导致；大型语言模型普及后相似度呈指数增长，显示语义多样性显著下降。

Conclusion: 递归使用AI生成数据训练可能导致语义多样性丧失，数据丰富性和模型泛化能力面临威胁，研究为监测和应对模型崩溃提供了数据支持。

Abstract: Artificial Intelligence, especially Large Language Models (LLMs), has transformed domains such as software engineering, journalism, creative writing, academia, and media (Naveed et al. 2025; arXiv:2307.06435). Diffusion models like Stable Diffusion generate high-quality images and videos from text. Evidence shows rapid expansion: 74.2% of newly published webpages now contain AI-generated material (Ryan Law 2025), 30-40% of the active web corpus is synthetic (Spennemann 2025; arXiv:2504.08755), 52% of U.S. adults use LLMs for writing, coding, or research (Staff 2025), and audits find AI involvement in 18% of financial complaints and 24% of press releases (Liang et al. 2025). The underlying neural architectures, including Transformers (Vaswani et al. 2023; arXiv:1706.03762), RNNs, LSTMs, GANs, and diffusion networks, depend on large, diverse, human-authored datasets (Shi & Iyengar 2019). As synthetic content dominates, recursive training risks eroding linguistic and semantic diversity, producing Model Collapse (Shumailov et al. 2024; arXiv:2307.15043; Dohmatob et al. 2024; arXiv:2402.07712). This study quantifies and forecasts collapse onset by examining year-wise semantic similarity in English-language Wikipedia (filtered Common Crawl) from 2013 to 2025 using Transformer embeddings and cosine similarity metrics. Results reveal a steady rise in similarity before public LLM adoption, likely driven by early RNN/LSTM translation and text-normalization pipelines, though modest due to a smaller scale. Observed fluctuations reflect irreducible linguistic diversity, variable corpus size across years, finite sampling error, and an exponential rise in similarity after the public adoption of LLM models. These findings provide a data-driven estimate of when recursive AI contamination may significantly threaten data richness and model generalization.

</details>


### [7] [Temporal Sparse Autoencoders: Leveraging the Sequential Nature of Language for Interpretability](https://arxiv.org/abs/2511.05541)
*Usha Bhalla,Alex Oesterling,Claudio Mayrink Verdun,Himabindu Lakkaraju,Flavio P. Calmon*

Main category: cs.CL

TL;DR: 提出了一种新型的时序稀疏自编码器（T-SAEs），通过引入对比损失，增强了语义特征的一致激活，成功将语义与句法特征区分开，提升了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的字典学习方法如稀疏自编码器未能有效捕获语言中丰富的语义信息，而只偏向浅层的、特定标记的噪声特征，限制了语言模型的可解释性。

Method: 基于语言语义具有长距离依赖且语义信息在序列中较为平滑的特点，引入一种新的对比损失，促进相邻词的高层语义特征激活的一致性，形成时序稀疏自编码器（T-SAEs）方法。

Result: T-SAEs在多个数据集和模型上表现出能恢复更平滑且连贯的语义概念，且保持了较好的重构质量，甚至无需显式语义信号也能体现明显的语义结构。

Conclusion: 通过引入时间上下文的对比学习，T-SAEs有效分离了语义与句法特征，为无监督的语言模型可解释性研究开辟了新方向。

Abstract: Translating the internal representations and computations of models into concepts that humans can understand is a key goal of interpretability. While recent dictionary learning methods such as Sparse Autoencoders (SAEs) provide a promising route to discover human-interpretable features, they suffer from a variety of problems, including a systematic failure to capture the rich conceptual information that drives linguistic understanding. Instead, they exhibit a bias towards shallow, token-specific, or noisy features, such as "the phrase 'The' at the start of sentences". In this work, we propose that this is due to a fundamental issue with how dictionary learning methods for LLMs are trained. Language itself has a rich, well-studied structure spanning syntax, semantics, and pragmatics; however, current unsupervised methods largely ignore this linguistic knowledge, leading to poor feature discovery that favors superficial patterns over meaningful concepts. We focus on a simple but important aspect of language: semantic content has long-range dependencies and tends to be smooth over a sequence, whereas syntactic information is much more local. Building on this insight, we introduce Temporal Sparse Autoencoders (T-SAEs), which incorporate a novel contrastive loss encouraging consistent activations of high-level features over adjacent tokens. This simple yet powerful modification enables SAEs to disentangle semantic from syntactic features in a self-supervised manner. Across multiple datasets and models, T-SAEs recover smoother, more coherent semantic concepts without sacrificing reconstruction quality. Strikingly, they exhibit clear semantic structure despite being trained without explicit semantic signal, offering a new pathway for unsupervised interpretability in language models.

</details>


### [8] [Sample-Efficient Language Modeling with Linear Attention and Lightweight Enhancements](https://arxiv.org/abs/2511.05560)
*Patrick Haller,Jonas Golde,Alan Akbik*

Main category: cs.CL

TL;DR: 本文提出了一种替代自注意力机制的线性时间mLSTM模型BLaLM，通过引入轻量级增强技术和优化器改进，在低资源环境下高效训练语言模型，显著提升无监督任务性能。


<details>
  <summary>Details</summary>
Motivation: 在低资源条件下提高语言模型的训练效率和表现，满足BabyLM 2025任务的约束。

Method: 用线性时间mLSTM替代自注意力，结合短卷积、滑动窗口注意力及Hedgehog特征映射，并设计了高质量用于训练的语料库，采用Muon优化器代替AdamW。

Result: 线性注意力加滑动窗口注意力提升了零样本性能，Muon优化器使模型收敛更稳定且降低困惑度。

Conclusion: 通过架构和优化技术的创新，可以在不依赖大规模数据的情况下，实现高效且性能优良的语言建模。

Abstract: We study architectural and optimization techniques for sample-efficient language modeling under the constraints of the BabyLM 2025 shared task. Our model, BLaLM, replaces self-attention with a linear-time mLSTM token mixer and explores lightweight enhancements, including short convolutions, sliding window attention with dynamic modulation, and Hedgehog feature maps. To support training in low-resource settings, we curate a high-quality corpus emphasizing readability and pedagogical structure. Experiments across both STRICT and STRICT-SMALL tracks show that (1) linear attention combined with sliding window attention consistently improves zero-shot performance, and (2) the Muon optimizer stabilizes convergence and reduces perplexity over AdamW. These results highlight effective strategies for efficient language modeling without relying on scale.

</details>


### [9] [UTF-8 Plumbing: Byte-level Tokenizers Unavoidably Enable LLMs to Generate Ill-formed UTF-8](https://arxiv.org/abs/2511.05578)
*Preston Firestone,Shubham Ugare,Gagandeep Singh,Sasa Misailovic*

Main category: cs.CL

TL;DR: 该论文形式化了子词分词过程，证明了包含非法UTF-8 token的词汇表会产生非法UTF-8序列，揭示了增量UTF-8解码与整体解码结果不同导致的实际bug，并提出了缓解方案。


<details>
  <summary>Details</summary>
Motivation: 目前基于字节的子词分词避免了超出词汇外问题，但可能生成非法UTF-8序列，进而引发实际应用中的解码错误和系统故障，该问题尚未被充分形式化和研究。

Method: 利用幺半群理论对分词过程进行数学形式化，证明含非法UTF-8 token的词汇表必然产生非法UTF-8序列。并通过理论证明和实证分析揭示分词的增量解码和整体解码不一致问题。

Result: 理论证明了非法UTF-8 token一定会导致不可恢复的非法UTF-8序列，并在实际系统中发现相关漏洞和错误。评估了现有缓解措施的有效性，提供了多个大型基础模型和生成系统的案例研究。

Conclusion: 本文首次严谨地证明了基于字节词汇表的子词tokenization在UTF-8编码上的潜在缺陷，强调应用模型时需关注此问题，并通过理论与实证提供解决思路，促进语言模型的健壮应用。

Abstract: Subword tokenization segments input text according to a pre-defined vocabulary to feed it into a language model; the language model, in turn, generates a sequence made from this same vocabulary. The members of the vocabulary can be built of code points or bytes. Using code points means that all members of the vocabulary are valid UTF-8 characters. However, it also requires thousands of initial members to achieve acceptable coverage of inputs. Beginning with bytes, on the contrary, avoids out-of-vocabulary errors with only 256 initial members of the vocabulary, but the members of the vocabulary and sequences of them are not guaranteed to be valid UTF-8. Sequences that are not valid UTF-8 break code that assumes its input to be valid UTF-8. Applications of language models must account for the breakage thereby introduced. In this paper, we formalize tokenization using monoid theory and prove that tokenizers whose vocabularies contain tokens that are ill-formed UTF-8 can always produce sequences that are ill-formed UTF-8. We demonstrate formally that attempting to incrementally convert tokens back to a string and interpret the results as UTF-8 gives different results than converting the whole sequence of tokens at once. This formal result predicts real-world bugs: we evaluate mitigations for the problem identified and provide case studies of major foundation models, serving engines, and constrained generation systems.

</details>


### [10] [Optimizing Diversity and Quality through Base-Aligned Model Collaboration](https://arxiv.org/abs/2511.05650)
*Yichen Wang,Chenghao Yang,Tenghao Huang,Muhao Chen,Jonathan May,Mina Lee*

Main category: cs.CL

TL;DR: 本文提出了一种名为BACo的推理时模型协作框架，通过动态结合基础大语言模型与其对齐模型，优化生成文本的多样性与质量。


<details>
  <summary>Details</summary>
Motivation: 现有的对齐方法虽提升了模型输出质量，但造成生成结果高度相似，缺乏多样性。

Method: BACo利用基于不确定性和语义角色的路由策略，在每个token层面动态选择由基础模型或对齐模型进行解码，实现高效而可控的多样性与质量平衡。

Result: BACo在三个开放式生成任务和13个多样性及质量指标上均优于最先进的推理时基线方法，最高实现21.3%的综合提升，人类评估结果亦支持该改进。

Conclusion: 基础模型与对齐模型间的协作能有效优化并控制语言生成的多样性与质量，且无需代价高昂的重训练或复杂后处理。

Abstract: Alignment has greatly improved large language models (LLMs)' output quality at the cost of diversity, yielding highly similar outputs across generations. We propose Base-Aligned Model Collaboration (BACo), an inference-time token-level model collaboration framework that dynamically combines a base LLM with its aligned counterpart to optimize diversity and quality. Inspired by prior work (Fei et al., 2025), BACo employs routing strategies that determine, at each token, from which model to decode based on next-token prediction uncertainty and predicted contents' semantic role. Prior diversity-promoting methods, such as retraining, prompt engineering, and multi-sampling methods, improve diversity but often degrade quality or require costly decoding or post-training. In contrast, BACo achieves both high diversity and quality post hoc within a single pass, while offering strong controllability. We explore a family of routing strategies, across three open-ended generation tasks and 13 metrics covering diversity and quality, BACo consistently surpasses state-of-the-art inference-time baselines. With our best router, BACo achieves a 21.3% joint improvement in diversity and quality. Human evaluations also mirror these improvements. The results suggest that collaboration between base and aligned models can optimize and control diversity and quality.

</details>


### [11] [OckBench: Measuring the Efficiency of LLM Reasoning](https://arxiv.org/abs/2511.05722)
*Zheng Du,Hao Kang,Song Han,Tushar Krishna,Ligeng Zhu*

Main category: cs.CL

TL;DR: 本文提出了OckBench基准测试，评估大语言模型在推理和编程任务中的准确率与解码令牌效率，揭示了不同模型在令牌消耗上的显著差异，强调效率的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试侧重于准确率和输出质量，忽视了解码令牌效率这一关键因素，而令牌数目大幅影响延迟、成本和能耗。

Method: 设计了OckBench，一个模型和硬件无关的基准测试，综合评估准确率和令牌消耗；通过对比开源和闭源多型号，分析了效率差异并绘制准确率-效率Pareto前沿。

Result: 发现不同模型在准确率相近的情况下，令牌消耗存在巨大差异，效率成为评估模型的重要维度。

Conclusion: 呼吁评价范式转变，不应将生成令牌视为“免费”，OckBench为衡量和比较令牌效率提供统一平台，有助推动高效推理研究。

Abstract: Large language models such as GPT-4, Claude 3, and the Gemini series have improved automated reasoning and code generation. However, existing benchmarks mainly focus on accuracy and output quality, and they ignore an important factor: decoding token efficiency. In real systems, generating 10,000 tokens versus 100,000 tokens leads to large differences in latency, cost, and energy. In this work, we introduce OckBench, a model-agnostic and hardware-agnostic benchmark that evaluates both accuracy and token count for reasoning and coding tasks. Through experiments comparing multiple open- and closed-source models, we uncover that many models with comparable accuracy differ wildly in token consumption, revealing that efficiency variance is a neglected but significant axis of differentiation. We further demonstrate Pareto frontiers over the accuracy-efficiency plane and argue for an evaluation paradigm shift: we should no longer treat tokens as "free" to multiply. OckBench provides a unified platform for measuring, comparing, and guiding research in token-efficient reasoning. Our benchmarks are available at https://ockbench.github.io/ .

</details>


### [12] [In-Context Learning Without Copying](https://arxiv.org/abs/2511.05743)
*Kerem Sahin,Sheridan Feucht,Adam Belfki,Jannik Brinkmann,Aaron Mueller,David Bau,Chris Wendler*

Main category: cs.CL

TL;DR: 本文研究了在抑制归纳复制头的情况下，变换器模型是否仍能获得复杂的上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 以往研究认为归纳头是实现先进上下文学习的前提，但本文质疑这一观点并探讨抑制归纳复制后模型性能变化。

Method: 提出Hapax训练设置，忽略归纳头可正确预测的令牌的损失贡献，从而抑制归纳复制行为。

Result: 尽管归纳复制显著减少，Hapax模型在抽象上下文学习任务中的性能保持不变且在多个任务中优于基本模型；归纳头数量和强度减弱，但上下文学习能力仍保留。

Conclusion: 归纳复制并非学习抽象上下文学习机制的必要条件，模型可以在无强归纳复制的情况下获得良好上下文学习能力。

Abstract: Induction heads are attention heads that perform inductive copying by matching patterns from earlier context and copying their continuations verbatim. As models develop induction heads, they often experience a sharp drop in training loss, a phenomenon cited as evidence that induction heads may serve as a prerequisite for more complex in-context learning (ICL) capabilities. In this work, we ask whether transformers can still acquire ICL capabilities when inductive copying is suppressed. We propose Hapax, a setting where we omit the loss contribution of any token that can be correctly predicted by induction heads. Despite a significant reduction in inductive copying, performance on abstractive ICL tasks (i.e., tasks where the answer is not contained in the input context) remains comparable and surpasses the vanilla model on 13 of 21 tasks, even though 31.7\% of tokens are omitted from the loss. Furthermore, our model achieves lower loss values on token positions that cannot be predicted correctly by induction heads. Mechanistic analysis further shows that models trained with Hapax develop fewer and weaker induction heads but still preserve ICL capabilities. Taken together, our findings indicate that inductive copying is not essential for learning abstractive ICL mechanisms.

</details>


### [13] [Multi-Scale Feature Fusion and Graph Neural Network Integration for Text Classification with Large Language Models](https://arxiv.org/abs/2511.05752)
*Xiangchen Song,Yulin Huang,Jinxu Guo,Yuchen Liu,Yaxuan Luan*

Main category: cs.CL

TL;DR: 本文提出一种结合大语言模型深度特征提取、多尺度特征金字塔融合及图神经网络结构化建模的文本分类混合方法，在复杂语义场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 在复杂语义环境下，提高文本分类性能需要同时捕捉全局和局部特征，并有效建模语义单元间的逻辑关系。

Method: 首先利用大语言模型提取深层语义特征；然后通过多尺度特征金字塔融合不同层级语义信息；最后将融合的特征转化为图结构，利用图神经网络抓取潜在语义关系，提高语义交互建模能力，最终通过分类模块预测类别。

Result: 在多个指标（ACC、F1值、AUC和Precision）上显著优于现有模型，验证了方法的有效性和稳定性。

Conclusion: 本文构建了一个兼顾全局与局部、语义与结构的综合框架，为多尺度特征融合和结构化语义建模提供了新思路，推动文本分类技术发展。

Abstract: This study investigates a hybrid method for text classification that integrates deep feature extraction from large language models, multi-scale fusion through feature pyramids, and structured modeling with graph neural networks to enhance performance in complex semantic contexts. First, the large language model captures contextual dependencies and deep semantic representations of the input text, providing a rich feature foundation for subsequent modeling. Then, based on multi-level feature representations, the feature pyramid mechanism effectively integrates semantic features of different scales, balancing global information and local details to construct hierarchical semantic expressions. Furthermore, the fused features are transformed into graph representations, and graph neural networks are employed to capture latent semantic relations and logical dependencies in the text, enabling comprehensive modeling of complex interactions among semantic units. On this basis, the readout and classification modules generate the final category predictions. The proposed method demonstrates significant advantages in robustness alignment experiments, outperforming existing models on ACC, F1-Score, AUC, and Precision, which verifies the effectiveness and stability of the framework. This study not only constructs an integrated framework that balances global and local information as well as semantics and structure, but also provides a new perspective for multi-scale feature fusion and structured semantic modeling in text classification tasks.

</details>


### [14] [Language Generation: Complexity Barriers and Implications for Learning](https://arxiv.org/abs/2511.05759)
*Marcelo Arenas,Pablo Barceló,Luis Cofré,Alexander Kozachinskiy*

Main category: cs.CL

TL;DR: 理论上语言生成总是可能，但实际需求的样本数可能极大，甚至不可计算。


<details>
  <summary>Details</summary>
Motivation: 探讨语言生成的理论保证与实际可行性之间的差距。

Method: 分析简单语言家族（正规语言和上下文无关语言）中，成功生成所需样本的数量及其计算复杂性。

Result: 成功生成所需的示例数量可能极大，且有时不受任何可计算函数限制。

Conclusion: 理论上的可能性与高效可学习性间存在显著差距，需考虑自然语言的结构属性以解释现代语言模型的成功。

Abstract: Kleinberg and Mullainathan showed that, in principle, language generation is always possible: with sufficiently many positive examples, a learner can eventually produce sentences indistinguishable from those of a target language. However, the existence of such a guarantee does not speak to its practical feasibility. In this work, we show that even for simple and well-studied language families -- such as regular and context-free languages -- the number of examples required for successful generation can be extraordinarily large, and in some cases not bounded by any computable function. These results reveal a substantial gap between theoretical possibility and efficient learnability. They suggest that explaining the empirical success of modern language models requires a refined perspective -- one that takes into account structural properties of natural language that make effective generation possible in practice.

</details>


### [15] [DRAGON: Guard LLM Unlearning in Context via Negative Detection and Reasoning](https://arxiv.org/abs/2511.05784)
*Yaxuan Wang,Chris Yuhao Liu,Quan Liu,Jinglong Pang,Wei Wei,Yujia Bao,Yang Liu*

Main category: cs.CL

TL;DR: 该论文提出了DRAGON，一种基于推理和上下文链式思考指导的无数据保留条件下大语言模型遗忘保护新框架。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的遗忘方法依赖于微调和需要保留数据，这在现实中往往不可行，因此需要一种无需保留数据且能高效遗忘有害知识的方法。

Method: 提出DRAGON框架，利用语言模型的指令执行能力及轻量级检测模块，在推理阶段通过链式思考指令检测并过滤需要遗忘的输入，形成安全准确的上下文干预，无需修改基础模型和保留数据。

Result: 实验在三种代表性遗忘任务上验证了DRAGON的强遗忘性能、良好扩展性及适用性，且引入了新的遗忘效果评估指标和持续遗忘设置。

Conclusion: DRAGON有效解决了在无保留数据条件下保护隐私和删除有害知识的难题，具备实际应用潜力。

Abstract: Unlearning in Large Language Models (LLMs) is crucial for protecting private data and removing harmful knowledge. Most existing approaches rely on fine-tuning to balance unlearning efficiency with general language capabilities. However, these methods typically require training or access to retain data, which is often unavailable in real world scenarios. Although these methods can perform well when both forget and retain data are available, few works have demonstrated equivalent capability in more practical, data-limited scenarios. To overcome these limitations, we propose Detect-Reasoning Augmented GeneratiON (DRAGON), a systematic, reasoning-based framework that utilizes in-context chain-of-thought (CoT) instructions to guard deployed LLMs before inference. Instead of modifying the base model, DRAGON leverages the inherent instruction-following ability of LLMs and introduces a lightweight detection module to identify forget-worthy prompts without any retain data. These are then routed through a dedicated CoT guard model to enforce safe and accurate in-context intervention. To robustly evaluate unlearning performance, we introduce novel metrics for unlearning performance and the continual unlearning setting. Extensive experiments across three representative unlearning tasks validate the effectiveness of DRAGON, demonstrating its strong unlearning capability, scalability, and applicability in practical scenarios.

</details>


### [16] [Quantifying Edits Decay in Fine-tuned LLMs](https://arxiv.org/abs/2511.05852)
*Yinjie Cheng,Paul Youssef,Christin Seifert,Jörg Schlötterer,Zhixue Zhao*

Main category: cs.CL

TL;DR: 本文研究了大语言模型中知识编辑与微调的关系，发现微调会导致知识编辑效果衰减，且不同方法和层次的影响存在差异，提出了选择性层微调策略以有效控制编辑保存或删除。


<details>
  <summary>Details</summary>
Motivation: 知识编辑和微调都是调整大语言模型的重要手段，但二者通常单独研究。实际应用中若先编辑后微调，编辑内容是否能保留成为关键问题，关系到安全性和效率。

Method: 系统性评估两种先进的编辑方法（MEMIT, AlphaEdit）与三种微调方式（全参数、LoRA、DoRA）在多个模型和数据集上的表现，共计232个实验配置。探索选择性层微调策略以控制编辑存续。

Result: 发现微调后编辑效果会衰减，AlphaEdit衰减更明显。选择性微调编辑层能有效移除编辑，但略微影响下游性能；微调非编辑层反而更易损害编辑效果。

Conclusion: 知识编辑与微调需综合考虑，评估模型编辑时应覆盖完整应用流程。选择性层微调为平衡编辑保存与删除提供了有效策略。

Abstract: Knowledge editing has emerged as a lightweight alternative to retraining for correcting or injecting specific facts in large language models (LLMs). Meanwhile, fine-tuning remains the default operation for adapting LLMs to new domains and tasks. Despite their widespread adoption, these two post-training interventions have been studied in isolation, leaving open a crucial question: if we fine-tune an edited model, do the edits survive? This question is motivated by two practical scenarios: removing covert or malicious edits, and preserving beneficial edits. If fine-tuning impairs edits as shown in Figure 1, current KE methods become less useful, as every fine-tuned model would require re-editing, which significantly increases the cost; if edits persist, fine-tuned models risk propagating hidden malicious edits, raising serious safety concerns. To this end, we systematically quantify edits decay after fine-tuning, investigating how fine-tuning affects knowledge editing. We evaluate two state-of-the-art editing methods (MEMIT, AlphaEdit) and three fine-tuning approaches (full-parameter, LoRA, DoRA) across five LLMs and three datasets, yielding 232 experimental configurations. Our results show that edits decay after fine-tuning, with survival varying across configurations, e.g., AlphaEdit edits decay more than MEMIT edits. Further, we propose selective-layer fine-tuning and find that fine-tuning edited layers only can effectively remove edits, though at a slight cost to downstream performance. Surprisingly, fine-tuning non-edited layers impairs more edits than full fine-tuning. Overall, our study establishes empirical baselines and actionable strategies for integrating knowledge editing with fine-tuning, and underscores that evaluating model editing requires considering the full LLM application pipeline.

</details>


### [17] [Retrieval-Augmented Generation in Medicine: A Scoping Review of Technical Implementations, Clinical Applications, and Ethical Considerations](https://arxiv.org/abs/2511.05901)
*Rui Yang,Matthew Yu Heng Wong,Huitao Li,Xin Li,Wentao Zhu,Jingchi Liao,Kunyu Yu,Jonathan Chong Kai Liew,Weihao Xuan,Yingjian Chen,Yuhe Ke,Jasmine Chiat Ling Ong,Douglas Teodoro,Chuan Hong,Daniel Shi Wei Ting,Nan Liu*

Main category: cs.CL

TL;DR: 本研究回顾了医疗领域中基于检索增强生成（RAG）技术的应用，指出现有研究大多依赖公开数据，使用以英语为主的嵌入模型，且评估多集中于生成质量和任务表现。


<details>
  <summary>Details</summary>
Motivation: 随着医疗知识爆炸及临床实践复杂性增加，现有大语言模型存在局限性，需探索检索增强生成技术以提升临床适用性。

Method: 本文对医疗领域中RAG技术应用进行文献综述，分析数据源、嵌入方法、模型类型及评估指标，评估当前应用场景及存在挑战。

Result: 发现研究多环绕公开数据，嵌入模型偏向英语，医疗专用大语言模型少，评估偏重自动指标和人类对生成准确性与流畅性的评价，忽视偏见和安全性。RAG主要应用于问答、报告生成、文本摘要和信息提取。

Conclusion: 医疗RAG技术尚处早期阶段，亟需临床验证、跨语言适配及低资源环境支持，以实现可信赖及负责任的全球应用。

Abstract: The rapid growth of medical knowledge and increasing complexity of clinical practice pose challenges. In this context, large language models (LLMs) have demonstrated value; however, inherent limitations remain. Retrieval-augmented generation (RAG) technologies show potential to enhance their clinical applicability. This study reviewed RAG applications in medicine. We found that research primarily relied on publicly available data, with limited application in private data. For retrieval, approaches commonly relied on English-centric embedding models, while LLMs were mostly generic, with limited use of medical-specific LLMs. For evaluation, automated metrics evaluated generation quality and task performance, whereas human evaluation focused on accuracy, completeness, relevance, and fluency, with insufficient attention to bias and safety. RAG applications were concentrated on question answering, report generation, text summarization, and information extraction. Overall, medical RAG remains at an early stage, requiring advances in clinical validation, cross-linguistic adaptation, and support for low-resource settings to enable trustworthy and responsible global use.

</details>


### [18] [NILC: Discovering New Intents with LLM-assisted Clustering](https://arxiv.org/abs/2511.05913)
*Hongtao Wang,Renchi Yang,Wenqing Lin*

Main category: cs.CL

TL;DR: 本文针对新意图发现（NID）提出了NILC框架，通过结合大语言模型和迭代聚类优化，提高了未标注用户语句的意图识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的NID方法采用级联架构，先编码文本再聚类，缺乏两步之间的反馈机制，且仅基于嵌入进行聚类忽视了细微的语义差异，导致性能不足。

Method: NILC通过迭代更新聚类结果，利用大语言模型生成额外的语义中心和对难分类样本进行重写，增强语义信息和纠正聚类错误，并引入半监督的监督信号提高准确性。

Result: 在六个不同领域的基准数据集上，NILC在无监督和半监督设置下均显著优于多种最新基线方法。

Conclusion: NILC有效融合了大语言模型和迭代聚类策略，解决了传统NID方法的不足，显著提升了新意图发现的准确率和鲁棒性。

Abstract: New intent discovery (NID) seeks to recognize both new and known intents from unlabeled user utterances, which finds prevalent use in practical dialogue systems. Existing works towards NID mainly adopt a cascaded architecture, wherein the first stage focuses on encoding the utterances into informative text embeddings beforehand, while the latter is to group similar embeddings into clusters (i.e., intents), typically by K-Means. However, such a cascaded pipeline fails to leverage the feedback from both steps for mutual refinement, and, meanwhile, the embedding-only clustering overlooks nuanced textual semantics, leading to suboptimal performance. To bridge this gap, this paper proposes NILC, a novel clustering framework specially catered for effective NID. Particularly, NILC follows an iterative workflow, in which clustering assignments are judiciously updated by carefully refining cluster centroids and text embeddings of uncertain utterances with the aid of large language models (LLMs). Specifically, NILC first taps into LLMs to create additional semantic centroids for clusters, thereby enriching the contextual semantics of the Euclidean centroids of embeddings. Moreover, LLMs are then harnessed to augment hard samples (ambiguous or terse utterances) identified from clusters via rewriting for subsequent cluster correction. Further, we inject supervision signals through non-trivial techniques seeding and soft must links for more accurate NID in the semi-supervised setting. Extensive experiments comparing NILC against multiple recent baselines under both unsupervised and semi-supervised settings showcase that NILC can achieve significant performance improvements over six benchmark datasets of diverse domains consistently.

</details>


### [19] [IDALC: A Semi-Supervised Framework for Intent Detection and Active Learning based Correction](https://arxiv.org/abs/2511.05921)
*Ankan Mullick,Sukannya Purkayastha,Saransh Sharma,Pawan Goyal,Niloy Ganguly*

Main category: cs.CL

TL;DR: 本文提出了一个名为IDALC的半监督框架，用于检测用户意图并纠正系统拒绝的语句，同时大幅减少人工标注需求。


<details>
  <summary>Details</summary>
Motivation: 现有语音对话系统在处理已知意图时若信心不足，会拒绝用户输入并需人工标注，随着新意图的出现，标注成本剧增，需降低标注成本的高效机制。

Method: 提出半监督的IDALC框架，通过意图检测和主动学习纠正拒绝语句，减少对人工标注的依赖。

Result: 在多个基准数据集上，IDALC准确率提升5-10%，macro-F1指标提升4-8%，注释成本仅为未标注数据的6-10%。

Conclusion: IDALC有效提升了意图识别准确率和召回率，同时显著降低了人工标注成本，适用于迭代更新的语音对话系统。

Abstract: Voice-controlled dialog systems have become immensely popular due to their ability to perform a wide range of actions in response to diverse user queries. These agents possess a predefined set of skills or intents to fulfill specific user tasks. But every system has its own limitations. There are instances where, even for known intents, if any model exhibits low confidence, it results in rejection of utterances that necessitate manual annotation. Additionally, as time progresses, there may be a need to retrain these agents with new intents from the system-rejected queries to carry out additional tasks. Labeling all these emerging intents and rejected utterances over time is impractical, thus calling for an efficient mechanism to reduce annotation costs. In this paper, we introduce IDALC (Intent Detection and Active Learning based Correction), a semi-supervised framework designed to detect user intents and rectify system-rejected utterances while minimizing the need for human annotation. Empirical findings on various benchmark datasets demonstrate that our system surpasses baseline methods, achieving a 5-10% higher accuracy and a 4-8% improvement in macro-F1. Remarkably, we maintain the overall annotation cost at just 6-10% of the unlabelled data available to the system. The overall framework of IDALC is shown in Fig. 1

</details>


### [20] [Reinforcement Learning Improves Traversal of Hierarchical Knowledge in LLMs](https://arxiv.org/abs/2511.05933)
*Renfei Zhang,Manasa Kaniselvan,Niloofar Mireshghallah*

Main category: cs.CL

TL;DR: 强化学习改进了语言模型在知识回忆任务中的表现，特别是在层级结构知识的检索上，通过改进模型内部的导航和搜索技能，而非新增知识。


<details>
  <summary>Details</summary>
Motivation: 挑战强化学习会削弱模型记忆能力的传统观点，探究其是否通过提升模型检索结构化知识的程序技能而非新增数据来改善性能。

Method: 通过对比基础模型、有监督微调模型（SFT）与强化学习增强模型在知识回忆任务上的表现；采用结构化提示引导模型层级遍历检索；层次激活分析比较模型事实表示与查询表示差异。

Result: 强化学习模型在纯知识回忆任务中性能优于基础和SFT模型，结构化提示能显著缩小差距；RL模型在深度检索任务中保留更好的程序路径回忆能力；层级激活分析显示RL改变的是知识检索路径而非事实表示。

Conclusion: 强化学习主要提升了模型在内部遍历和搜索知识层级结构的程序技能，从而增强知识回忆能力，而非改变知识本身的表示。

Abstract: Reinforcement learning (RL) is often credited with improving language model reasoning and generalization at the expense of degrading memorized knowledge. We challenge this narrative by observing that RL-enhanced models consistently outperform their base and supervised fine-tuned (SFT) counterparts on pure knowledge recall tasks, particularly those requiring traversal of hierarchical, structured knowledge (e.g., medical codes). We hypothesize these gains stem not from newly acquired data, but from improved procedural skills in navigating and searching existing knowledge hierarchies within the model parameters. To support this hypothesis, we show that structured prompting, which explicitly guides SFTed models through hierarchical traversal, recovers most of the performance gap (reducing 24pp to 7pp on MedConceptsQA for DeepSeek-V3/R1). We further find that while prompting improves final-answer accuracy, RL-enhanced models retain superior ability to recall correct procedural paths on deep-retrieval tasks. Finally our layer-wise internal activation analysis reveals that while factual representations (e.g., activations for the statement "code 57.95 refers to urinary infection") maintain high cosine similarity between SFT and RL models, query representations (e.g., "what is code 57.95") diverge noticeably, indicating that RL primarily transforms how models traverse knowledge rather than the knowledge representation itself.

</details>


### [21] [Interpretable Recognition of Cognitive Distortions in Natural Language Texts](https://arxiv.org/abs/2511.05969)
*Anton Kolonin,Anna Arinicheva*

Main category: cs.CL

TL;DR: 提出了一种基于加权结构化模式（如N-gram）且考虑异构关系的多因子文本分类方法，用于自动检测心理护理中的特定认知扭曲，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决心理护理中认知扭曲自动检测的社会影响性问题，需构建可解释、稳健且透明的人工智能模型。

Method: 采用加权结构化模式（如N-gram），结合异构关系，提出新的多因子文本分类方法及识别学习算法。

Result: 在两个公开数据集上测试，F1得分显著优于已有文献，且通过调优获得最优超参数，代码和模型公开。

Conclusion: 该方法在心理认知扭曲检测任务中表现出色，具备解释性和实用价值，有望推动该领域进一步发展。

Abstract: We propose a new approach to multi-factor classification of natural language texts based on weighted structured patterns such as N-grams, taking into account the heterarchical relationships between them, applied to solve such a socially impactful problem as the automation of detection of specific cognitive distortions in psychological care, relying on an interpretable, robust and transparent artificial intelligence model. The proposed recognition and learning algorithms improve the current state of the art in this field. The improvement is tested on two publicly available datasets, with significant improvements over literature-known F1 scores for the task, with optimal hyper-parameters determined, having code and models available for future use by the community.

</details>


### [22] [Revisiting Entropy in Reinforcement Learning for Large Reasoning Models](https://arxiv.org/abs/2511.05993)
*Renren Jin,Pengzhi Gao,Yuqi Ren,Zhuowen Han,Tongxuan Zhang,Wuwei Huang,Wei Liu,Jian Luan,Deyi Xiong*

Main category: cs.CL

TL;DR: 本文研究了强化学习中可验证奖励训练（RLVR）对大语言模型（LLMs）熵的影响，发现熵坍塌问题限制性能提升，并提出调节正负优势词权重以控制熵。


<details>
  <summary>Details</summary>
Motivation: 虽然RLVR能提升LLMs的推理能力，但训练中熵坍塌导致模型过早收敛到劣质局部最优，影响表现，且目前缺乏对熵动态的系统研究。

Method: 通过大量实验分析了RLVR训练中模型熵的动态变化及其与响应多样性、校准度和性能的关系，重点研究了离策略更新次数、训练数据多样性和优化目标的裁剪阈值影响。并通过理论和实证确认了带正优势的词对熵坍塌的主导作用，提出通过调节正负优势词损失权重来调控熵。

Result: 发现影响RLVR中模型熵的关键因素包括离策略更新次数、训练数据多样性和裁剪阈值。证实带正优势的词是熵坍塌的主要原因，且调节正负优势词权重能有效控制熵水平。

Conclusion: 通过深入研究RLVR训练中熵的动态，本文提出了一种有效的熵调控方法，能够缓解熵坍塌现象，防止模型早期陷入劣质局部最优，从而提升LLMs的训练效果和最终性能。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a predominant approach for enhancing the reasoning capabilities of large language models (LLMs). However, the entropy of LLMs usually collapses during RLVR training, causing premature convergence to suboptimal local minima and hinder further performance improvement. Although various approaches have been proposed to mitigate entropy collapse, a comprehensive study of entropy in RLVR remains lacking. To address this gap, we conduct extensive experiments to investigate the entropy dynamics of LLMs trained with RLVR and analyze how model entropy correlates with response diversity, calibration, and performance across various benchmarks. Our findings reveal that the number of off-policy updates, the diversity of training data, and the clipping thresholds in the optimization objective are critical factors influencing the entropy of LLMs trained with RLVR. Moreover, we theoretically and empirically demonstrate that tokens with positive advantages are the primary contributors to entropy collapse, and that model entropy can be effectively regulated by adjusting the relative loss weights of tokens with positive and negative advantages during training.

</details>


### [23] [LLMs Do Not See Age: Assessing Demographic Bias in Automated Systematic Review Synthesis](https://arxiv.org/abs/2511.06000)
*Favour Yahdii Aghaebe,Tanefa Apekey,Elizabeth Williams,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 该论文评估了先进语言模型在生成生物医学研究摘要时保持年龄相关信息的能力，构建了包含不同年龄群体的DemogSummary数据集，发现模型在不同年龄群体间表现存在系统性差异，尤其是成人群体的年龄信息保留最差，且弱势群体更易发生信息幻觉。


<details>
  <summary>Details</summary>
Motivation: 临床干预依赖年龄信息，但现有语言模型是否能忠实保留这些关键信息尚不明确，影响生物医学证据综合的准确性和公平性。

Method: 构建了DemogSummary数据集，涵盖儿童、成人和老年人群，评估了Qwen、Longformer和GPT-4.1 Nano三种语言模型的摘要性能，设计了新的年龄相关实体保留与幻觉评估指标Demographic Salience Score (DSS)。

Result: 各模型在不同年龄组的表现存在显著差异，人口统计学信息保留最差的是面向成人的摘要，弱势群体的摘要更易出现幻觉内容。

Conclusion: 当前语言模型在忠实且无偏见地保留年龄信息方面存在不足，未来需要引入公平性意识的评估框架和摘要生成流程以提升生物医学NLP的可靠性。

Abstract: Clinical interventions often hinge on age: medications and procedures safe for adults may be harmful to children or ineffective for older adults. However, as language models are increasingly integrated into biomedical evidence synthesis workflows, it remains uncertain whether these systems preserve such crucial demographic distinctions. To address this gap, we evaluate how well state-of-the-art language models retain age-related information when generating abstractive summaries of biomedical studies. We construct DemogSummary, a novel age-stratified dataset of systematic review primary studies, covering child, adult, and older adult populations. We evaluate three prominent summarisation-capable LLMs, Qwen (open-source), Longformer (open-source) and GPT-4.1 Nano (proprietary), using both standard metrics and a newly proposed Demographic Salience Score (DSS), which quantifies age-related entity retention and hallucination. Our results reveal systematic disparities across models and age groups: demographic fidelity is lowest for adult-focused summaries, and under-represented populations are more prone to hallucinations. These findings highlight the limitations of current LLMs in faithful and bias-free summarisation and point to the need for fairness-aware evaluation frameworks and summarisation pipelines in biomedical NLP.

</details>


### [24] [Multi-Reward GRPO Fine-Tuning for De-biasing Large Language Models: A Study Based on Chinese-Context Discrimination Data](https://arxiv.org/abs/2511.06023)
*Deng Yixuan,Ji Xiaoqiang*

Main category: cs.CL

TL;DR: 本论文提出了一种多奖励群体相对策略优化（GRPO）框架，用于对大语言模型进行伦理及去偏见微调，有效减少文化相关的多维歧视表现。


<details>
  <summary>Details</summary>
Motivation: 现有对齐技术如RLHF和DPO虽减轻偏见，但难以解决文化特异且多维度的歧视问题，需一种更全面的微调方法。

Method: 构建基于中国背景歧视类别的英文合成数据集，训练包括公平性、中立性及语言质量的多维多维度奖励模型，并通过GRPO优化模型输出。

Result: 实验显示该方法显著降低了偏见强度，提升了非歧视性标准的符合度，同时保证了语言的流畅性和信息量。

Conclusion: GRPO多奖励优化框架有效实现了文化语境下的伦理对齐与去偏见，具备良好的可复制性与推广价值。

Abstract: Large Language Models (LLMs) often exhibit implicit biases and discriminatory tendencies that reflect underlying social stereotypes. While recent alignment techniques such as RLHF and DPO have mitigated some of these issues, they remain limited in addressing culturally specific and multi-dimensional forms of discrimination. This paper proposes a Multi-Reward Group Relative Policy Optimization (GRPO) framework to fine-tune LLMs toward ethical and bias-free behavior. Our approach constructs a synthetic English-language dataset derived from Chinese-context discrimination categories, including regional, ethnic, and occupational biases. Each instance is paired with both neutral and biased responses to train a reward model based on DeBERTa-v3, which provides multi-dimensional reward signals capturing fairness, neutrality, and linguistic quality. The trained reward model then guides GRPO fine-tuning to optimize model outputs along these ethical dimensions. Experimental results demonstrate significant reductions in bias intensity and improved alignment with non-discriminatory standards without compromising fluency or informativeness. This study highlights the effectiveness of GRPO-based multi-reward optimization for de-biasing LLMs and offers a replicable framework for cultural-contextual ethical alignment.

</details>


### [25] [Visual Exploration of Feature Relationships in Sparse Autoencoders with Curated Concepts](https://arxiv.org/abs/2511.06048)
*Xinyuan Yan,Shusen Liu,Kowshik Thopalli,Bei Wang*

Main category: cs.CL

TL;DR: 本文提出了一种针对稀疏自动编码器学习到的特征的聚焦探索和交互式可视化框架，克服了传统降维方法的局限，帮助更深入理解大语言模型中的概念表示。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以全面探索稀疏自动编码器提取的大量特征，且现有降维技术存在压缩伪影、过度绘制和邻域扭曲问题，限制了对局部和全局结构的准确理解。

Method: 提出一种基于拓扑结构编码结合降维的交互式可视化系统，优先展示预先筛选的概念及其对应的SAE特征，避免同时可视化所有特征带来的复杂性。

Result: 该方法能够忠实呈现所选特征之间的局部与全局关系，支持用户通过聚焦子集探索SAE行为，从而实现对潜在空间中概念表示的更细致分析。

Conclusion: 聚焦于关键概念和特征的交互式可视化框架，有效提升了对SAE特征及其在大语言模型中隐含概念的理解，弥补了传统方法的不足。

Abstract: Sparse autoencoders (SAEs) have emerged as a powerful tool for uncovering interpretable features in large language models (LLMs) through the sparse directions they learn. However, the sheer number of extracted directions makes comprehensive exploration intractable. While conventional embedding techniques such as UMAP can reveal global structure, they suffer from limitations including high-dimensional compression artifacts, overplotting, and misleading neighborhood distortions. In this work, we propose a focused exploration framework that prioritizes curated concepts and their corresponding SAE features over attempts to visualize all available features simultaneously. We present an interactive visualization system that combines topology-based visual encoding with dimensionality reduction to faithfully represent both local and global relationships among selected features. This hybrid approach enables users to investigate SAE behavior through targeted, interpretable subsets, facilitating deeper and more nuanced analysis of concept representation in latent space.

</details>


### [26] [Efficient Hate Speech Detection: A Three-Layer LoRA-Tuned BERTweet Framework](https://arxiv.org/abs/2511.06051)
*Mahmoud El-Bahnasawi*

Main category: cs.CL

TL;DR: 提出一个三层架构结合规则预过滤和LoRA调优BERTweet模型，实现高效且性能优异的实时仇恨言论检测。


<details>
  <summary>Details</summary>
Motivation: 解决仇恨言论检测中模型计算资源需求高与实时部署困难的矛盾。

Method: 设计三层框架：规则预过滤、参数高效的LoRA调优BERTweet模型以及持续学习，利用数据统一和优化微调提升性能。

Result: 模型达到0.85宏F1分数，相当于大型模型94%性能，同时参数量仅为其1%，训练速度快，适合资源受限环境。

Conclusion: 提出方法在保持竞争力准确率的同时，实现了计算效率大幅提升，适合实际中的实时仇恨言论检测应用。

Abstract: This paper addresses the critical challenge of developing computationally efficient hate speech detection systems that maintain competitive performance while being practical for real-time deployment. We propose a novel three-layer framework that combines rule-based pre-filtering with a parameter-efficient LoRA-tuned BERTweet model and continuous learning capabilities. Our approach achieves 0.85 macro F1 score - representing 94% of the performance of state-of-the-art large language models like SafePhi (Phi-4 based) while using a base model that is 100x smaller (134M vs 14B parameters). Compared to traditional BERT-based approaches with similar computational requirements, our method demonstrates superior performance through strategic dataset unification and optimized fine-tuning. The system requires only 1.87M trainable parameters (1.37% of full fine-tuning) and trains in approximately 2 hours on a single T4 GPU, making robust hate speech detection accessible in resource-constrained environments while maintaining competitive accuracy for real-world deployment.

</details>


### [27] [ReMoD: Rethinking Modality Contribution in Multimodal Stance Detection via Dual Reasoning](https://arxiv.org/abs/2511.06057)
*Bingbing Wang,Zhengda Jin,Bin Liang,Jing Li,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出了ReMoD框架，通过双重推理机制动态调整多模态在立场表达中的贡献，提升社交媒体多模态立场检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法简单融合多模态信息，未考虑不同模态在立场表达中的贡献差异，可能导致误判。

Method: 借鉴人类认知的双过程理论，ReMoD先通过经验驱动的直觉推理形成初步立场假设，再通过深思熟虑的反思推理调整模态权重，包含Modality Experience Pool和Semantic Experience Pool两部分经验池，动态加权融合模态信息。

Result: 在公开MMSD基准数据集上的实验显示，ReMoD显著优于大多数基线模型，并且具有较强的泛化能力。

Conclusion: 通过双重推理机制动态调整模态贡献，有效提升了多模态立场检测的性能和鲁棒性。

Abstract: Multimodal Stance Detection (MSD) is a crucial task for understanding public opinion on social media. Existing work simply fuses information from various modalities to learn stance representations, overlooking the varying contributions of stance expression from different modalities. Therefore, stance misunderstanding noises may be drawn into the stance learning process due to the risk of learning errors by rough modality combination. To address this, we get inspiration from the dual-process theory of human cognition and propose **ReMoD**, a framework that **Re**thinks **Mo**dality contribution of stance expression through a **D**ual-reasoning paradigm. ReMoD integrates *experience-driven intuitive reasoning* to capture initial stance cues with *deliberate reflective reasoning* to adjust for modality biases, refine stance judgments, and thereby dynamically weight modality contributions based on their actual expressive power for the target stance. Specifically, the intuitive stage queries the Modality Experience Pool (MEP) and Semantic Experience Pool (SEP) to form an initial stance hypothesis, prioritizing historically impactful modalities. This hypothesis is then refined in the reflective stage via two reasoning chains: Modality-CoT updates MEP with adaptive fusion strategies to amplify relevant modalities, while Semantic-CoT refines SEP with deeper contextual insights of stance semantics. These dual experience structures are continuously refined during training and recalled at inference to guide robust and context-aware stance decisions. Extensive experiments on the public MMSD benchmark demonstrate that our ReMoD significantly outperforms most baseline models and exhibits strong generalization capabilities.

</details>


### [28] [Automating Hardware Design and Verification from Architectural Papers via a Neural-Symbolic Graph Framework](https://arxiv.org/abs/2511.06067)
*Haoyue Yang,Xuanle Zhao,Yujie Liu,Zhuojun Zou,Kailin Lyu,Changchun Zhou,Yao Zhu,Jie Hao*

Main category: cs.CL

TL;DR: 本文提出ArchCraft框架，实现了从学术论文中的抽象硬件架构描述到可综合的Verilog项目转换，并通过注册传输级验证确保设计正确性，同时引入基准测试ArchSynthBench验证框架效果。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏公开源码且硬件描述语言复杂，硬件架构的复现困难，促使设计一个自动从论文描述到可综合RTL代码生成的框架。

Method: ArchCraft利用形式化图捕捉架构蓝图和符号定义功能规格，结构化工作流程将非结构化论文转换为可验证设计，生成RTL和测试平台代码分离以便验证和调试，并报告功耗、面积、性能指标。

Result: 在ArchSynthBench基准测试中，ArchCraft优于直接生成方法和VerilogCoder框架，在理解论文和代码完成度上表现更佳，生成的RTL代码在物理实现中满足时序约束且性能指标吻合原论文。

Conclusion: ArchCraft有效解决了硬件架构从论文到代码的挑战，推动了硬件设计的自动化与复现，基准测试验证了其性能与可靠性。

Abstract: The reproduction of hardware architectures from academic papers remains a significant challenge due to the lack of publicly available source code and the complexity of hardware description languages (HDLs). To this end, we propose \textbf{ArchCraft}, a Framework that converts abstract architectural descriptions from academic papers into synthesizable Verilog projects with register-transfer level (RTL) verification. ArchCraft introduces a structured workflow, which uses formal graphs to capture the Architectural Blueprint and symbols to define the Functional Specification, translating unstructured academic papers into verifiable, hardware-aware designs. The framework then generates RTL and testbench (TB) code decoupled via these symbols to facilitate verification and debugging, ultimately reporting the circuit's Power, Area, and Performance (PPA). Moreover, we propose the first benchmark, \textbf{ArchSynthBench}, for synthesizing hardware from architectural descriptions, with a complete set of evaluation indicators, 50 project-level circuits, and around 600 circuit blocks. We systematically assess ArchCraft on ArchSynthBench, where the experiment results demonstrate the superiority of our proposed method, surpassing direct generation methods and the VerilogCoder framework in both paper understanding and code completion. Furthermore, evaluation and physical implementation of the generated executable RTL code show that these implementations meet all timing constraints without violations, and their performance metrics are consistent with those reported in the original papers.

</details>


### [29] [Stemming Hallucination in Language Models Using a Licensing Oracle](https://arxiv.org/abs/2511.06073)
*Simeon Emanuilov,Richard Ackermann*

Main category: cs.CL

TL;DR: 本文提出了Licensing Oracle架构，利用结构化知识图谱进行形式验证，防止语言模型生成虚假信息，显著减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 语言模型虽然具有强大的语言生成能力，但容易产生事实错误（幻觉），现有基于统计的方法难以完全消除这一问题。

Method: Licensing Oracle嵌入一个确定性的验证步骤，通过结构化知识图谱对生成的信息进行形式验证，确保生成内容的真实准确。

Result: 实验对比显示，尽管检索增强生成（RAG）和微调方法提高了性能，但仍无法完全消除幻觉。Licensing Oracle实现了完全的拒绝精确度（AP=1.0）和零错误回答率（FAR-NE=0.0），实际事实准确率达89.1%。

Conclusion: 基于结构化知识验证的架构创新可以有效根治语言模型的幻觉问题，Licensing Oracle为未来基于真理约束的生成模型提供了重要的技术路径。

Abstract: Language models exhibit remarkable natural language generation capabilities but remain prone to hallucinations, generating factually incorrect information despite producing syntactically coherent responses. This study introduces the Licensing Oracle, an architectural solution designed to stem hallucinations in LMs by enforcing truth constraints through formal validation against structured knowledge graphs. Unlike statistical approaches that rely on data scaling or fine-tuning, the Licensing Oracle embeds a deterministic validation step into the model's generative process, ensuring that only factually accurate claims are made. We evaluated the effectiveness of the Licensing Oracle through experiments comparing it with several state-of-the-art methods, including baseline language model generation, fine-tuning for factual recall, fine-tuning for abstention behavior, and retrieval-augmented generation (RAG). Our results demonstrate that although RAG and fine-tuning improve performance, they fail to eliminate hallucinations. In contrast, the Licensing Oracle achieved perfect abstention precision (AP = 1.0) and zero false answers (FAR-NE = 0.0), ensuring that only valid claims were generated with 89.1% accuracy in factual responses. This work shows that architectural innovations, such as the Licensing Oracle, offer a necessary and sufficient solution for hallucinations in domains with structured knowledge representations, offering guarantees that statistical methods cannot match. Although the Licensing Oracle is specifically designed to address hallucinations in fact-based domains, its framework lays the groundwork for truth-constrained generation in future AI systems, providing a new path toward reliable, epistemically grounded models.

</details>


### [30] [MuonAll: Muon Variant for Efficient Finetuning of Large Language Models](https://arxiv.org/abs/2511.06086)
*Saurabh Page,Advait Joshi,S. S. Sonawane*

Main category: cs.CL

TL;DR: 本文引入了MuonAll优化器，通过将所有参数转换为二维矩阵，更完整地利用Muon方法，并在多个公开语言模型上进行了微调实验，结果显示Muon和MuonAll与AdamW表现相当，证明了其作为替代优化器的有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然Muon优化器在语言模型预训练中表现优异，但其在公开预训练模型微调中的性能尚未探索，且当前通常与AdamW结合使用，有改进空间。

Method: 提出MuonAll优化器，将所有参数转化为二维矩阵纳入Muon方法中，进行了大量公开大规模语言模型（最多五亿参数）的微调实验。

Result: Muon和MuonAll在多个主要基准测试中表现与AdamW相当，验证了其作为优化器的有效性。

Conclusion: MuonAll优化器是Muon方法的有效扩展，能够作为AdamW的替代方案使用，且实现代码已开源。

Abstract: Muon optimizer has demonstrated robust results in pretraining of language models but its performance in finetuning of existing public pretrained models is not yet explored. Currently, Muon is used along with AdamW introducing a scope of improvement for adopting all parameters inside Muon. We introduce MuonAll, which incorporates all the parameters inside Muon by transforming into 2D matrices. We conduct extensive finetuning experiments across publicly available language models with model sizes upto half billion parameters. Muon and MuonAll perform at par with AdamW across major benchmarks, highlighting their effectiveness as alternative optimizers. We open-source the distributed implementations of Muon and MuonAll, available at https://github.com/Saurabh750/optimizer

</details>


### [31] [Evaluation of retrieval-based QA on QUEST-LOFT](https://arxiv.org/abs/2511.06125)
*Nathan Scales,Nathanael Schärli,Olivier Bousquet*

Main category: cs.CL

TL;DR: 本文分析了检索增强生成（RAG）方法在处理跨多文档信息和复杂推理的问题上的不足，并通过结构化输出和答案复核优化了RAG表现，显著优于长上下文模型。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法难以处理需要多文档整合和复杂推理的问答任务，QUEST基准测试尤为突出，迫切需要提升在这类任务上的性能。

Method: 深入分析QUEST-LOFT性能瓶颈，结合结构化输出格式（含推理和证据）以及答案复核策略，优化RAG方法。

Result: 经过优化的RAG在QUEST基准测试中显著超过了基于长上下文的语言模型方法。

Conclusion: 通过结构化的推理与证据输出以及答案复核，RAG方法能力得到了提升，适合解决分布式信息和复杂推理的问答挑战。

Abstract: Despite the popularity of retrieval-augmented generation (RAG) as a solution for grounded QA in both academia and industry, current RAG methods struggle with questions where the necessary information is distributed across many documents or where retrieval needs to be combined with complex reasoning. Recently, the LOFT study has shown that this limitation also applies to approaches based on long-context language models, with the QUEST benchmark exhibiting particularly large headroom. In this paper, we provide an in-depth analysis of the factors contributing to the poor performance on QUEST-LOFT, publish updated numbers based on a thorough human evaluation, and demonstrate that RAG can be optimized to significantly outperform long-context approaches when combined with a structured output format containing reasoning and evidence, optionally followed by answer re-verification.

</details>


### [32] [Referring Expressions as a Lens into Spatial Language Grounding in Vision-Language Models](https://arxiv.org/abs/2511.06146)
*Akshar Tumu,Varad Shinde,Parisa Kordjamshidi*

Main category: cs.CL

TL;DR: 本文提出用指代表达理解任务评估视觉-语言模型的空间推理能力，并分析模型在对象检测歧义、复杂空间表达和否定表达上的表现。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类认知的重要组成部分，但最新的视觉-语言模型在这方面表现不佳。现有评估多依赖图像描述和视觉问答，缺乏对空间推理的深入分析。

Method: 作者采用指代表达理解任务作为评估平台，设计包含对象检测歧义、复杂空间表达和否定语句的测试，使用任务特定架构和大型视觉-语言模型进行实验分析。

Result: 所有模型在空间推理任务中均面临挑战，其表现依赖于模型架构和空间语义类别（如拓扑、方向、距离关系等）的不同。

Conclusion: 研究揭示了当前视觉-语言模型在空间推理方面的不足和不同模型间的表现差异，指出了未来研究的方向和潜在的研究空白。

Abstract: Spatial Reasoning is an important component of human cognition and is an area in which the latest Vision-language models (VLMs) show signs of difficulty. The current analysis works use image captioning tasks and visual question answering. In this work, we propose using the Referring Expression Comprehension task instead as a platform for the evaluation of spatial reasoning by VLMs. This platform provides the opportunity for a deeper analysis of spatial comprehension and grounding abilities when there is 1) ambiguity in object detection, 2) complex spatial expressions with a longer sentence structure and multiple spatial relations, and 3) expressions with negation ('not'). In our analysis, we use task-specific architectures as well as large VLMs and highlight their strengths and weaknesses in dealing with these specific situations. While all these models face challenges with the task at hand, the relative behaviors depend on the underlying models and the specific categories of spatial semantics (topological, directional, proximal, etc.). Our results highlight these challenges and behaviors and provide insight into research gaps and future directions.

</details>


### [33] [BookAsSumQA: An Evaluation Framework for Aspect-Based Book Summarization via Question Answering](https://arxiv.org/abs/2511.06183)
*Ryuhei Miyazato,Ting-Ruen Wei,Xuyang Wu,Hsin-Tai Wu,Kei Harada*

Main category: cs.CL

TL;DR: 提出了BookAsSumQA框架，通过基于问答的评价方法解决了长文本图书的基于方面的摘要评价问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏参考摘要，基于方面的图书摘要很难构建和评价。

Method: 设计了一个基于叙事知识图谱自动生成方面特定问答对的评价框架BookAsSumQA，通过问答性能评估摘要质量。

Result: 实验表明，LLM方法在短文本上表现更优，RAG方法在长文档上更有效且实用。

Conclusion: BookAsSumQA能够有效评估长文本图书的方面摘要，且RAG方法适合实际应用。

Abstract: Aspect-based summarization aims to generate summaries that highlight specific aspects of a text, enabling more personalized and targeted summaries. However, its application to books remains unexplored due to the difficulty of constructing reference summaries for long text. To address this challenge, we propose BookAsSumQA, a QA-based evaluation framework for aspect-based book summarization. BookAsSumQA automatically generates aspect-specific QA pairs from a narrative knowledge graph to evaluate summary quality based on its question-answering performance. Our experiments using BookAsSumQA revealed that while LLM-based approaches showed higher accuracy on shorter texts, RAG-based methods become more effective as document length increases, making them more efficient and practical for aspect-based book summarization.

</details>


### [34] [Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning](https://arxiv.org/abs/2511.06190)
*Sangmook Lee,Dohyung Kim,Hyukhun Koh,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: 本文提出了一种基于模型内置信度引导的逐步模型路由方法STEER，用于在推理时动态在小型和大型LLM之间切换，以降低推理成本并保持甚至提升准确率。


<details>
  <summary>Details</summary>
Motivation: 现有通过训练路由模型来分配查询策略的方法存在在领域迁移时鲁棒性差、以及训练依赖昂贵数据合成的问题，如何实现更加高效且鲁棒的模型路由成为关键挑战。

Method: STEER利用小模型在生成推理步骤前的置信度分数进行动态判断，仅在必要时调用大型模型完成推理，从而实现细粒度、步骤级的模型切换，无需外部训练路由模块。

Result: 在数学推理、多跳问答、规划任务等多领域基准测试中，STEER相比全用大模型在准确率上提升20%，同时减少48%的计算量，表现优于依赖外部训练模块的方法。

Conclusion: 模型内部置信度作为一种鲁棒且领域无关的路由信号，为高效大语言模型部署提供了可扩展路径。

Abstract: Recent advances in Large Language Models (LLMs) - particularly model scaling and test-time techniques - have greatly enhanced the reasoning capabilities of language models at the expense of higher inference costs. To lower inference costs, prior works train router models or deferral mechanisms that allocate easy queries to a small, efficient model, while forwarding harder queries to larger, more expensive models. However, these trained router models often lack robustness under domain shifts and require expensive data synthesis techniques such as Monte Carlo rollouts to obtain sufficient ground-truth routing labels for training. In this work, we propose Confidence-Guided Stepwise Model Routing for Cost-Efficient Reasoning (STEER), a domain-agnostic framework that performs fine-grained, step-level routing between smaller and larger LLMs without utilizing external models. STEER leverages confidence scores from the smaller model's logits prior to generating a reasoning step, so that the large model is invoked only when necessary. Extensive evaluations using different LLMs on a diverse set of challenging benchmarks across multiple domains such as Mathematical Reasoning, Multi-Hop QA, and Planning tasks indicate that STEER achieves competitive or enhanced accuracy while reducing inference costs (up to +20% accuracy with 48% less FLOPs compared to solely using the larger model on AIME), outperforming baselines that rely on trained external modules. Our results establish model-internal confidence as a robust, domain-agnostic signal for model routing, offering a scalable pathway for efficient LLM deployment.

</details>


### [35] [Explicit Knowledge-Guided In-Context Learning for Early Detection of Alzheimer's Disease](https://arxiv.org/abs/2511.06215)
*Puzhen Su,Yongzhu Miao,Chunxi Guo,Jintao Tang,Shasha Li,Ting Wang*

Main category: cs.CL

TL;DR: 本文提出了一种基于显式知识的上下文学习框架EK-ICL，用于提升阿尔茨海默病(AD)检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在AD检测任务中，尤其是在数据稀缺和分布外条件下表现不佳，存在任务识别失败、示范选择不佳及标签语义不匹配等问题。

Method: EK-ICL整合了显式知识，包括由小型语言模型提供的置信度分数、语法解析特征分数以及标签词替换，结合基于解析的检索策略和集成预测，以增强推理稳定性和任务对齐。

Result: 在三个AD数据集上的大量实验中，EK-ICL显著优于当前最先进的微调和上下文学习基线方法。

Conclusion: 上下文学习在AD检测任务中对标签语义与任务上下文的一致性高度敏感，显式知识的引入对于在低资源条件下的临床推理尤为关键。

Abstract: Detecting Alzheimer's Disease (AD) from narrative transcripts remains a challenging task for large language models (LLMs), particularly under out-of-distribution (OOD) and data-scarce conditions. While in-context learning (ICL) provides a parameter-efficient alternative to fine-tuning, existing ICL approaches often suffer from task recognition failure, suboptimal demonstration selection, and misalignment between label words and task objectives, issues that are amplified in clinical domains like AD detection. We propose Explicit Knowledge In-Context Learners (EK-ICL), a novel framework that integrates structured explicit knowledge to enhance reasoning stability and task alignment in ICL. EK-ICL incorporates three knowledge components: confidence scores derived from small language models (SLMs) to ground predictions in task-relevant patterns, parsing feature scores to capture structural differences and improve demo selection, and label word replacement to resolve semantic misalignment with LLM priors. In addition, EK-ICL employs a parsing-based retrieval strategy and ensemble prediction to mitigate the effects of semantic homogeneity in AD transcripts. Extensive experiments across three AD datasets demonstrate that EK-ICL significantly outperforms state-of-the-art fine-tuning and ICL baselines. Further analysis reveals that ICL performance in AD detection is highly sensitive to the alignment of label semantics and task-specific context, underscoring the importance of explicit knowledge in clinical reasoning under low-resource conditions.

</details>


### [36] [SPA: Achieving Consensus in LLM Alignment via Self-Priority Optimization](https://arxiv.org/abs/2511.06222)
*Yue Huang,Xiangqi Wang,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 该论文提出了一种新的优先级对齐方法SPA，旨在确保大型语言模型在高风险情境中先保证可信再提升实用性，通过模型自我评估和双重标准去噪实现严格的“可信优先”策略，显著提升模型性能且不影响安全性。


<details>
  <summary>Details</summary>
Motivation: 在高风险场景中，语言模型既要可信又要实用，但这两者目标常常冲突，如何在保证安全的前提下提升帮助性成为关键挑战。

Method: 提出Self-Priority Alignment（SPA），通过生成多样响应、模型自我评估与细化，并应用双重标准的去噪方法来消除不一致和控制方差，构建优先顺序的偏好对，使用不确定性加权的对齐损失进行模型微调。

Result: SPA在多个基准测试中提升了模型的帮助性，同时保证了安全性，超越了强基线方法，并保持了模型的通用能力。

Conclusion: SPA提供了一种可扩展且可解释的对齐策略，适合于关键的LLM应用，实现在保证可信的前提下提升实用性的目标。

Abstract: In high-stakes scenarios-such as self-harm, legal, or medical queries-LLMs must be both trustworthy and helpful. However, these goals often conflict. We propose priority alignment, a new alignment paradigm that enforces a strict "trustworthy-before-helpful" ordering: optimization of helpfulness is conditioned on first meeting trustworthy thresholds (e.g., harmlessness or honesty). To realize this, we introduce Self-Priority Alignment (SPA)-a fully unsupervised framework that generates diverse responses, self-evaluates them and refines them by the model itself, and applies dual-criterion denoising to remove inconsistency and control variance. From this, SPA constructs lexicographically ordered preference pairs and fine-tunes the model using an uncertainty-weighted alignment loss that emphasizes high-confidence, high-gap decisions. Experiments across multiple benchmarks show that SPA improves helpfulness without compromising safety, outperforming strong baselines while preserving general capabilities. Our results demonstrate that SPA provides a scalable and interpretable alignment strategy for critical LLM applications.

</details>


### [37] [Overview of CHIP 2025 Shared Task 2: Discharge Medication Recommendation for Metabolic Diseases Based on Chinese Electronic Health Records](https://arxiv.org/abs/2511.06230)
*Juntao Li,Haobin Yuan,Ling Luo,Tengxiao Lv,Yan Jiang,Fan Wang,Ping Zhang,Huiyi Lv,Jian Wang,Yuanyuan Sun,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文介绍了CHIP 2025共享任务2，旨在利用中国真实电子健康记录数据自动推荐出院药物。


<details>
  <summary>Details</summary>
Motivation: 确保慢性代谢疾病患者的治疗连续性、预防再入院并改善长期管理，自动化出院用药推荐显得尤为重要。

Method: 构建了高质量的CDrugRed数据集，采用基于大型语言模型的集成系统来解决多标签药物推荐问题，处理异质临床文本和患者个体治疗差异。

Result: 共有526支队伍报名，167支和95支队伍分别提交了有效结果，最高Jaccard得分0.5102，F1得分0.6267，展示了大型语言模型集成系统的潜力。

Conclusion: 基于大型语言模型的自动药物推荐方法展现出良好前景，但在中国电子健康记录的应用中仍存在挑战。

Abstract: Discharge medication recommendation plays a critical role in ensuring treatment continuity, preventing readmission, and improving long-term management for patients with chronic metabolic diseases. This paper present an overview of the CHIP 2025 Shared Task 2 competition, which aimed to develop state-of-the-art approaches for automatically recommending appro-priate discharge medications using real-world Chinese EHR data. For this task, we constructed CDrugRed, a high-quality dataset consisting of 5,894 de-identified hospitalization records from 3,190 patients in China. This task is challenging due to multi-label nature of medication recommendation, het-erogeneous clinical text, and patient-specific variability in treatment plans. A total of 526 teams registered, with 167 and 95 teams submitting valid results to the Phase A and Phase B leaderboards, respectively. The top-performing team achieved the highest overall performance on the final test set, with a Jaccard score of 0.5102, F1 score of 0.6267, demonstrating the potential of advanced large language model (LLM)-based ensemble systems. These re-sults highlight both the promise and remaining challenges of applying LLMs to medication recommendation in Chinese EHRs. The post-evaluation phase remains open at https://tianchi.aliyun.com/competition/entrance/532411/.

</details>


### [38] [Analyzing and Mitigating Negation Artifacts using Data Augmentation for Improving ELECTRA-Small Model Accuracy](https://arxiv.org/abs/2511.06234)
*Mojtaba Noghabaei*

Main category: cs.CL

TL;DR: 该论文研究了预训练模型在处理自然语言推理中的否定表达时的不足，并通过数据增强方法改进了模型性能。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在自然语言推理任务中表现优异，但往往依赖数据集中的伪相关性，特别难以正确处理否定表达。

Method: 基于ELECTRA-small模型，使用SNLI数据集进行微调，分析其对否定句的分类性能，并通过加入对比集和对抗样本进行针对性数据增强。

Result: 增强后的模型在否定句上的分类准确率明显提升，同时整体表现未受影响。

Conclusion: 通过有针对性的数据增强，可以缓解模型依赖数据集伪相关的问题，提升其对否定表达的理解能力。

Abstract: Pre-trained models for natural language inference (NLI) often achieve high performance on benchmark datasets by using spurious correlations, or dataset artifacts, rather than understanding language touches such as negation. In this project, we investigate the performance of an ELECTRA-small model fine-tuned on the Stanford Natural Language Inference (SNLI) dataset, focusing on its handling of negation. Through analysis, we identify that the model struggles with correctly classifying examples containing negation. To address this, we augment the training data with contrast sets and adversarial examples emphasizing negation. Our results demonstrate that this targeted data augmentation improves the model's accuracy on negation-containing examples without adversely affecting overall performance, therefore mitigating the identified dataset artifact.

</details>


### [39] [TimeSense:Making Large Language Models Proficient in Time-Series Analysis](https://arxiv.org/abs/2511.06344)
*Zhirui Zhang,Changhua Pei,Tianyi Gao,Zhe Xie,Yibo Hao,Zhaoyang Yu,Longlong Xu,Tong Xiao,Jing Han,Dan Pei*

Main category: cs.CL

TL;DR: 本文提出了TimeSense框架，通过结合文本推理和时间序列数据，实现大语言模型在时间序列分析中的卓越表现，并构建了包含10个任务的EvalTS基准进行评测。


<details>
  <summary>Details</summary>
Motivation: 现有结合文本与时间序列的方法依赖文本标签进行监督，导致模型偏重文本线索，忽视时间序列的完整特征，从而可能输出与时间序列上下文矛盾的结果。

Method: 提出TimeSense多模态框架，设有时间感知模块以重构输入时间序列，确保文本推理基于时间序列动态。同时，引入基于坐标的位置嵌入提升时间序列的空间理解能力。

Result: 实验表明TimeSense在多个任务上达到了最新的性能，尤其在复杂多维时间序列推理任务中表现优越。

Conclusion: TimeSense有效平衡了文本推理与时间序列动态的整合，提升了大语言模型在高难度时间序列分析任务中的表现。

Abstract: In the time-series domain, an increasing number of works combine text with temporal data to leverage the reasoning capabilities of large language models (LLMs) for various downstream time-series understanding tasks. This enables a single model to flexibly perform tasks that previously required specialized models for each domain. However, these methods typically rely on text labels for supervision during training, biasing the model toward textual cues while potentially neglecting the full temporal features. Such a bias can lead to outputs that contradict the underlying time-series context. To address this issue, we construct the EvalTS benchmark, comprising 10 tasks across three difficulty levels, from fundamental temporal pattern recognition to complex real-world reasoning, to evaluate models under more challenging and realistic scenarios. We also propose TimeSense, a multimodal framework that makes LLMs proficient in time-series analysis by balancing textual reasoning with a preserved temporal sense. TimeSense incorporates a Temporal Sense module that reconstructs the input time-series within the model's context, ensuring that textual reasoning is grounded in the time-series dynamics. Moreover, to enhance spatial understanding of time-series data, we explicitly incorporate coordinate-based positional embeddings, which provide each time point with spatial context and enable the model to capture structural dependencies more effectively. Experimental results demonstrate that TimeSense achieves state-of-the-art performance across multiple tasks, and it particularly outperforms existing methods on complex multi-dimensional time-series reasoning tasks.

</details>


### [40] [HatePrototypes: Interpretable and Transferable Representations for Implicit and Explicit Hate Speech Detection](https://arxiv.org/abs/2511.06391)
*Irina Proskurina,Marc-Antoine Carpentier,Julien Velcin*

Main category: cs.CL

TL;DR: 本文提出利用HatePrototypes（一种基于少量样本构建的类级向量表示）实现不同类型仇恨言论的高效检测，支持显性与隐性仇恨的跨任务迁移，并通过无参数早停方法提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测基准多针对显性仇恨，忽视隐性仇恨的复杂语义，需要更深层次的模型语义处理，同时减少重复微调的需求。

Method: 利用HatePrototypes，即从仅50个示例构建的类级向量表示，并结合无参数的早停技术，实现显隐性仇恨的跨任务迁移检测。

Result: HatePrototypes在不同基准间表现出良好的可迁移性，并通过参数无关的早停方法有效提升了检测效率。

Conclusion: HatePrototypes及相应方法为仇恨言论检测提供了一种高效且可移植的解决方案，有助于未来相关研究的发展。

Abstract: Optimization of offensive content moderation models for different types of hateful messages is typically achieved through continued pre-training or fine-tuning on new hate speech benchmarks. However, existing benchmarks mainly address explicit hate toward protected groups and often overlook implicit or indirect hate, such as demeaning comparisons, calls for exclusion or violence, and subtle discriminatory language that still causes harm. While explicit hate can often be captured through surface features, implicit hate requires deeper, full-model semantic processing. In this work, we question the need for repeated fine-tuning and analyze the role of HatePrototypes, class-level vector representations derived from language models optimized for hate speech detection and safety moderation. We find that these prototypes, built from as few as 50 examples per class, enable cross-task transfer between explicit and implicit hate, with interchangeable prototypes across benchmarks. Moreover, we show that parameter-free early exiting with prototypes is effective for both hate types. We release the code, prototype resources, and evaluation scripts to support future research on efficient and transferable hate speech detection.

</details>


### [41] [SugarTextNet: A Transformer-Based Framework for Detecting Sugar Dating-Related Content on Social Media with Context-Aware Focal Loss](https://arxiv.org/abs/2511.06402)
*Lionel Z. Wang,Shihan Ben,Yulu Huang,Simeng Qing*

Main category: cs.CL

TL;DR: 本文提出了SugarTextNet，一种基于变换器的新框架，用于精准识别社交媒体上的糖爹约会相关内容，解决了语言隐晦和数据不平衡的问题。


<details>
  <summary>Details</summary>
Motivation: 糖爹约会相关内容在主流社交媒体上快速增长，带来社会和监管问题；检测此类内容困难大，因涉及隐晦表达和数据类别极度不平衡。

Method: 提出SugarTextNet，结合预训练变换器编码器、基于注意力的线索提取器和上下文短语编码器，并引入上下文感知调焦损失函数以改善少数类检测能力。

Result: 在新构建的3067条新浪微博中文数据集上，SugarTextNet在多个指标上显著优于传统机器学习、深度学习基线和大型语言模型，消融实验验证各模块重要性。

Conclusion: 领域特定且上下文感知的模型对敏感内容检测至关重要，SugarTextNet为复杂实际场景下的内容管理提供了强有力的解决方案。

Abstract: Sugar dating-related content has rapidly proliferated on mainstream social media platforms, giving rise to serious societal and regulatory concerns, including commercialization of intimate relationships and the normalization of transactional relationships.~Detecting such content is highly challenging due to the prevalence of subtle euphemisms, ambiguous linguistic cues, and extreme class imbalance in real-world data.~In this work, we present SugarTextNet, a novel transformer-based framework specifically designed to identify sugar dating-related posts on social media.~SugarTextNet integrates a pretrained transformer encoder, an attention-based cue extractor, and a contextual phrase encoder to capture both salient and nuanced features in user-generated text.~To address class imbalance and enhance minority-class detection, we introduce Context-Aware Focal Loss, a tailored loss function that combines focal loss scaling with contextual weighting.~We evaluate SugarTextNet on a newly curated, manually annotated dataset of 3,067 Chinese social media posts from Sina Weibo, demonstrating that our approach substantially outperforms traditional machine learning models, deep learning baselines, and large language models across multiple metrics.~Comprehensive ablation studies confirm the indispensable role of each component.~Our findings highlight the importance of domain-specific, context-aware modeling for sensitive content detection, and provide a robust solution for content moderation in complex, real-world scenarios.

</details>


### [42] [How Well Do LLMs Understand Drug Mechanisms? A Knowledge + Reasoning Evaluation Dataset](https://arxiv.org/abs/2511.06418)
*Sunil Mohan,Theofanis Karaletsos*

Main category: cs.CL

TL;DR: 本文介绍了一个用于评估大型语言模型在药物作用机制知识和推理能力上的数据集，并比较了不同模型的表现。


<details>
  <summary>Details</summary>
Motivation: 随着预训练大型语言模型在药物开发和个性化医疗领域的应用增加，模型需具备对药物作用机制的事实知识及创新情境下的推理能力。

Method: 构建包含已知机制事实和反事实新情境的数据集，评估模型在封闭世界（提供知识）和开放世界（需回忆知识）下的表现。

Result: o4-mini模型表现优于OpenAI的o4、o3及o3-mini模型，Qwen3-4B-thinking模型表现接近甚至超越o4-mini。开放世界推理更具挑战，内部链路受影响的反事实推理难度更大。

Conclusion: 评估表明大型语言模型在药物机制推理任务中仍面临挑战，尤其是开放世界和复杂推理链的情况下，但部分新模型展现出较强能力。

Abstract: Two scientific fields showing increasing interest in pre-trained large language models (LLMs) are drug development / repurposing, and personalized medicine. For both, LLMs have to demonstrate factual knowledge as well as a deep understanding of drug mechanisms, so they can recall and reason about relevant knowledge in novel situations. Drug mechanisms of action are described as a series of interactions between biomedical entities, which interlink into one or more chains directed from the drug to the targeted disease. Composing the effects of the interactions in a candidate chain leads to an inference about whether the drug might be useful or not for that disease. We introduce a dataset that evaluates LLMs on both factual knowledge of known mechanisms, and their ability to reason about them under novel situations, presented as counterfactuals that the models are unlikely to have seen during training. Using this dataset, we show that o4-mini outperforms the 4o, o3, and o3-mini models from OpenAI, and the recent small Qwen3-4B-thinking model closely matches o4-mini's performance, even outperforming it in some cases. We demonstrate that the open world setting for reasoning tasks, which requires the model to recall relevant knowledge, is more challenging than the closed world setting where the needed factual knowledge is provided. We also show that counterfactuals affecting internal links in the reasoning chain present a much harder task than those affecting a link from the drug mentioned in the prompt.

</details>


### [43] [Dutch Metaphor Extraction from Cancer Patients' Interviews and Forum Data using LLMs and Human in the Loop](https://arxiv.org/abs/2511.06427)
*Lifeng Han,David Lindevelt,Sander Puts,Erik van Mulligen,Suzan Verberne*

Main category: cs.CL

TL;DR: 本研究针对荷兰癌症患者的数据，利用大语言模型提取病人使用的隐喻表达，建立了名为HealthQuote.NL的语料库。


<details>
  <summary>Details</summary>
Motivation: 隐喻语言在医疗交流中尤为关键，尤其是患者及其家属与临床医生之间。挖掘和理解患者的隐喻有助于提升医疗沟通和个性化治疗设计。

Method: 收集癌症患者讲述和在线论坛中的数据，采用多种提示策略（链式推理、少样本学习、自我提示）使用最新大语言模型自动识别隐喻，并通过人工验证形成语料库。

Result: 成功提取并验证了大量患者隐喻表达，构建了健康相关隐喻数据库HealthQuote.NL，为未来研究提供资源。

Conclusion: 研究证明基于大语言模型的隐喻自动识别在医疗语境下具有有效性，这些隐喻资源有助于改善患者护理和医疗交流。

Abstract: Metaphors and metaphorical language (MLs) play an important role in healthcare communication between clinicians, patients, and patients' family members. In this work, we focus on Dutch language data from cancer patients. We extract metaphors used by patients using two data sources: (1) cancer patient storytelling interview data and (2) online forum data, including patients' posts, comments, and questions to professionals. We investigate how current state-of-the-art large language models (LLMs) perform on this task by exploring different prompting strategies such as chain of thought reasoning, few-shot learning, and self-prompting. With a human-in-the-loop setup, we verify the extracted metaphors and compile the outputs into a corpus named HealthQuote.NL. We believe the extracted metaphors can support better patient care, for example shared decision making, improved communication between patients and clinicians, and enhanced patient health literacy. They can also inform the design of personalized care pathways. We share prompts and related resources at https://github.com/aaronlifenghan/HealthQuote.NL

</details>


### [44] [Towards Resource-Efficient Multimodal Intelligence: Learned Routing among Specialized Expert Models](https://arxiv.org/abs/2511.06441)
*Mayank Saini,Arit Kumar Bishwas*

Main category: cs.CL

TL;DR: 提出了一个统一的模块化框架，通过智能路由网络，将不同类型的查询分配给最合适的模型，实现了在保持高性能的同时显著降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然功能强大，但高推理成本限制了其实时和大规模部署的应用；而较小开源模型虽成本低，但处理复杂或多模态查询时效果不佳。

Method: 设计了一个学习型路由网络，根据查询类型智能分配给文本、复杂或多模态专家模型；视觉任务采用了两阶段开源流水线，结合高效的经典视觉组件，以提升效率和保持子任务的顶尖性能。

Result: 在MMLU和VQA等基准测试中，该框架匹配或超越了单一高质量大型模型系统的性能，且减少了超过67%的高成本模型依赖。

Conclusion: 该框架通过多代理协作，实现了高质量且资源高效的AI系统，具备良好的扩展性和实用性，适合大规模高效部署。

Abstract: As AI moves beyond text, large language models (LLMs) increasingly power vision, audio, and document understanding; however, their high inference costs hinder real-time, scalable deployment. Conversely, smaller open-source models offer cost advantages but struggle with complex or multimodal queries. We introduce a unified, modular framework that intelligently routes each query - textual, multimodal, or complex - to the most fitting expert model, using a learned routing network that balances cost and quality. For vision tasks, we employ a two-stage open-source pipeline optimized for efficiency and reviving efficient classical vision components where they remain SOTA for sub-tasks. On benchmarks such as Massive Multitask Language Understanding (MMLU) and Visual Question Answering (VQA), we match or exceed the performance of always-premium LLM (monolithic systems with one model serving all query types) performance, yet reduce the reliance on costly models by over 67%. With its extensible, multi-agent orchestration, we deliver high-quality, resource-efficient AI at scale.

</details>


### [45] [SR-KI: Scalable and Real-Time Knowledge Integration into LLMs via Supervised Attention](https://arxiv.org/abs/2511.06446)
*Bohan Yu,Wei Huang,Kang Liu*

Main category: cs.CL

TL;DR: 本文提出了一种名为SR-KI的新方法，将大规模结构化知识库实时集成到大型语言模型中，实现了高效压缩和动态更新。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成方法依赖外部检索器和多阶段流程，限制了推理效率和知识更新能力。

Method: SR-KI通过预训练编码器将知识库编码为键值对，注入语言模型的KV缓存，采用两阶段训练：定位检索层并通过注意力损失监督相关知识条目，支持全模型潜空间内检索。

Result: 在单个A100 40GB GPU上将最多4万条知识库条目整合进7B模型，实现了超过98%的Recall@10，平均超过88%，在问答和知识库ID生成任务中表现优异。

Conclusion: SR-KI实现了大规模知识库的高效注入和动态更新，显著提升了模型的检索和任务性能，同时实现了高达99.75%的知识压缩。

Abstract: This paper proposes SR-KI, a novel approach for integrating real-time and large-scale structured knowledge bases (KBs) into large language models (LLMs). SR-KI begins by encoding KBs into key-value pairs using a pretrained encoder, and injects them into LLMs' KV cache. Building on this representation, we employ a two-stage training paradigm: first locating a dedicated retrieval layer within the LLM, and then applying an attention-based loss at this layer to explicitly supervise attention toward relevant KB entries. Unlike traditional retrieval-augmented generation methods that rely heavily on the performance of external retrievers and multi-stage pipelines, SR-KI supports end-to-end inference by performing retrieval entirely within the models latent space. This design enables efficient compression of injected knowledge and facilitates dynamic knowledge updates. Comprehensive experiments demonstrate that SR-KI enables the integration of up to 40K KBs into a 7B LLM on a single A100 40GB GPU, and achieves strong retrieval performance, maintaining over 98% Recall@10 on the best-performing task and exceeding 88% on average across all tasks. Task performance on question answering and KB ID generation also demonstrates that SR-KI maintains strong performance while achieving up to 99.75% compression of the injected KBs.

</details>


### [46] [Rethinking what Matters: Effective and Robust Multilingual Realignment for Low-Resource Languages](https://arxiv.org/abs/2511.06497)
*Quang Phuoc Nguyen,David Anugraha,Felix Gaschi,Jun Bin Cheng,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 该论文研究了多语种语言模型中通过选择性语言对齐提升跨语言迁移的效果，发现对低资源语言使用多样化的语言子集进行对齐能够匹配甚至优于全量对齐，减少了数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统的词语对齐方法依赖高质量的平行语料，但许多低资源语言缺乏这种资源，导致跨语言迁移效果不稳定或不理想。研究者希望探讨是否可以通过选择性地使用部分语言实现更高效且有效的对齐。

Method: 通过严谨的实证实验，比较了使用所有语言进行对齐与利用精心挑选的语言子集对齐对低资源语言跨语言迁移的影响，重点分析了语言选择策略的作用。

Result: 实验结果表明，对低资源语言而言，通过选取多样化且语言学相关性合理的语言子集进行对齐，不仅能达到全语种对齐的效果，还能在未见过的低资源语言上表现更好。

Conclusion: 有效的跨语言对齐不需要涵盖所有语言，基于语言选择的精细对齐策略可以减少数据采集负担，提高效率和稳健性，对低资源语言的跨语言迁移尤其有益。

Abstract: Realignment is a promising strategy to improve cross-lingual transfer in multilingual language models. However, empirical results are mixed and often unreliable, particularly for typologically distant or low-resource languages (LRLs) compared to English. Moreover, word realignment tools often rely on high-quality parallel data, which can be scarce or noisy for many LRLs. In this work, we conduct an extensive empirical study to investigate whether realignment truly benefits from using all available languages, or if strategically selected subsets can offer comparable or even improved cross-lingual transfer, and study the impact on LRLs. Our controlled experiments show that realignment can be particularly effective for LRLs and that using carefully selected, linguistically diverse subsets can match full multilingual alignment, and even outperform it for unseen LRLs. This indicates that effective realignment does not require exhaustive language coverage and can reduce data collection overhead, while remaining both efficient and robust when guided by informed language selection.

</details>


### [47] [You Had One Job: Per-Task Quantization Using LLMs' Hidden Representations](https://arxiv.org/abs/2511.06516)
*Amit LeVi,Raz Lapid,Rom Himelstein,Yaniv Nemcovsky,Ravid Shwartz Ziv,Avi Mendelson*

Main category: cs.CL

TL;DR: 本文提出了两种基于任务感知的后训练量化方法TAQ和TAQO，通过利用任务相关的隐藏表征，实现对模型层的差异化精度分配，从而在保持高精度的同时显著提升模型量化效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然能力强大，但多数应用只需有限功能，使得大模型在存储和响应时间上效率低下，现有的量化方法忽视了任务相关信号在模型层间的分布特点。

Method: 提出基于任务感知的量化方法——TAQ利用隐藏激活的任务条件统计数据分配位宽，TAQO则通过直接的层敏感性测试确定精度分配；两者均从小量校准集识别关键层，保持高精度并对其他层进行激进量化。

Result: TAQ和TAQO在多种模型上优于现有基线方法，TAQ在Phi-4模型上表现最佳，TAQO在Llama-3.1、Qwen3和Qwen2.5上表现优异，Phi-4模型量化后性能接近原模型精度，远超AWQ方法。

Conclusion: 基于任务感知的后训练量化方法能有效识别关键层，实现精准的位宽分配，显著提升模型量化效果，适用于多种大型语言模型，兼顾精度与效率。

Abstract: Large Language Models (LLMs) excel across diverse tasks, yet many applications require only limited capabilities, making large variants inefficient in memory and latency. Existing approaches often combine distillation and quantization, but most post-training quantization (PTQ) methods are task-agnostic, ignoring how task-specific signals are distributed across layers. In this work, we propose to use hidden representations that encode task-salient signals as a guideline for quantization. In order to fully utilize our innovative idea, this paper compares two new task-aware PTQ methods: Task-Aware Quantization (TAQ), which allocates bitwidths using task-conditioned statistics from hidden activations, and TAQO, which allocates precision based on direct layer sensitivity tests. From a small calibration set, these approaches identify task-relevant layers, preserving their precision while aggressively quantizing the rest. This yields stable task sensitivity profiles and efficient task-specialized models. Across models, TAQ and TAQO outperform the baselines; TAQ leads on Phi-4, while TAQO leads on Llama-3.1, Qwen3, and Qwen2.5. For instances, on Phi-4 it achieves 42.33 EM / 50.81 F1, far surpassing Activation-aware Weight Quantization (AWQ) (2.25 / 7.07), while remaining within < 1.0% of the original accuracy at lower average precision.

</details>


### [48] [Better Datasets Start From RefineLab: Automatic Optimization for High-Quality Dataset Refinement](https://arxiv.org/abs/2511.06530)
*Xiaonan Luo,Yue Huang,Ping He,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 本文提出了RefineLab框架，利用大语言模型在有限的token预算下自动优化问答数据集的质量，提升了数据覆盖度、难度分布和事实一致性。


<details>
  <summary>Details</summary>
Motivation: 现有高质量的问答数据集存在领域覆盖不足、难度分布不均和事实不准确等问题，而生成模型生成的数据集质量问题更严重，亟需一种自动且高效的改进方法。

Method: RefineLab基于大语言模型，结合覆盖率、难度均衡等质量指标，设计了一套有限token预算下的约束优化机制，通过重述、替换干扰项等多种编辑操作，自动选择最优策略提升数据集质量。

Result: 实验证明，RefineLab在覆盖度、难度匹配、事实准确性和干扰项质量方面均显著减少与专家数据集的差距，表现出优越的自动数据集优化能力。

Conclusion: RefineLab为可控的、可扩展的高质量问答数据集设计提供了全新方案，对大语言模型评估方法具有广泛意义。

Abstract: High-quality Question-Answer (QA) datasets are foundational for reliable Large Language Model (LLM) evaluation, yet even expert-crafted datasets exhibit persistent gaps in domain coverage, misaligned difficulty distributions, and factual inconsistencies. The recent surge in generative model-powered datasets has compounded these quality challenges. In this work, we introduce RefineLab, the first LLM-driven framework that automatically refines raw QA textual data into high-quality datasets under a controllable token-budget constraint. RefineLab takes a set of target quality attributes (such as coverage and difficulty balance) as refinement objectives, and performs selective edits within a predefined token budget to ensure practicality and efficiency. In essence, RefineLab addresses a constrained optimization problem: improving the quality of QA samples as much as possible while respecting resource limitations. With a set of available refinement operations (e.g., rephrasing, distractor replacement), RefineLab takes as input the original dataset, a specified set of target quality dimensions, and a token budget, and determines which refinement operations should be applied to each QA sample. This process is guided by an assignment module that selects optimal refinement strategies to maximize overall dataset quality while adhering to the budget constraint. Experiments demonstrate that RefineLab consistently narrows divergence from expert datasets across coverage, difficulty alignment, factual fidelity, and distractor quality. RefineLab pioneers a scalable, customizable path to reproducible dataset design, with broad implications for LLM evaluation.

</details>


### [49] [Ibom NLP: A Step Toward Inclusive Natural Language Processing for Nigeria's Minority Languages](https://arxiv.org/abs/2511.06531)
*Oluwadara Kalejaiye,Luel Hagos Beyene,David Ifeoluwa Adelani,Mmekut-Mfon Gabriel Edet,Aniefon Daniel Akpan,Eno-Abasi Urua,Anietie Andy*

Main category: cs.CL

TL;DR: 该论文介绍了针对尼日利亚四种沿海语言（Anaang、Efik、Ibibio、Oro）的机器翻译和主题分类数据集ibom，扩展了Flores-200基准，评估表明大语言模型在这些语言的机器翻译表现较差，但少量样本对主题分类有效。


<details>
  <summary>Details</summary>
Motivation: 尼日利亚拥有丰富的语言多样性，但主流NLP研究仅关注少数四种语言，且缺乏文本数据支持其他语言的研究和应用。

Method: 构建包含Anaang、Efik、Ibibio和Oro四种沿海语言的ibom数据集，扩展Flores-200基准，同时将翻译文本与基于SIB-200的主题标签对齐，使用零样本和少样本方法评估大语言模型的性能。

Result: 大语言模型在这些语言的机器翻译任务中表现不佳，无论是零样本还是少样本情形，但随着少样本数量增加，模型在主题分类任务中的表现稳步提升。

Conclusion: 针对非主流尼日利亚语言构建数据集及基准非常重要，现有模型需要更多训练数据才能改善机器翻译性能，但少量标注样本对于提升主题分类效果已有积极作用。

Abstract: Nigeria is the most populous country in Africa with a population of more than 200 million people. More than 500 languages are spoken in Nigeria and it is one of the most linguistically diverse countries in the world. Despite this, natural language processing (NLP) research has mostly focused on the following four languages: Hausa, Igbo, Nigerian-Pidgin, and Yoruba (i.e <1% of the languages spoken in Nigeria). This is in part due to the unavailability of textual data in these languages to train and apply NLP algorithms. In this work, we introduce ibom -- a dataset for machine translation and topic classification in four Coastal Nigerian languages from the Akwa Ibom State region: Anaang, Efik, Ibibio, and Oro. These languages are not represented in Google Translate or in major benchmarks such as Flores-200 or SIB-200. We focus on extending Flores-200 benchmark to these languages, and further align the translated texts with topic labels based on SIB-200 classification dataset. Our evaluation shows that current LLMs perform poorly on machine translation for these languages in both zero-and-few shot settings. However, we find the few-shot samples to steadily improve topic classification with more shots.

</details>


### [50] [Rep2Text: Decoding Full Text from a Single LLM Token Representation](https://arxiv.org/abs/2511.06571)
*Haiyan Zhao,Zirui He,Fan Yang,Ali Payani,Mengnan Du*

Main category: cs.CL

TL;DR: 本文提出了Rep2Text框架，能够从大语言模型的最后一个token的表示中恢复出原始输入文本，实现了在压缩表示中超过一半16-token序列信息的恢复，并保持语义完整性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的内部机制尚不清晰，本文探究从单个最后token表示中恢复原始输入文本的可能性，揭示模型表示的信息含量和压缩特性。

Method: 设计Rep2Text框架，利用可训练适配器将目标模型的内部表示映射到解码语言模型的嵌入空间，进而自回归地重建输入文本。

Result: 实验表明在不同模型组合上均能恢复超过半数16-token序列信息，且长序列表现出信息瓶颈，语义保持完好。框架对医疗领域外分布数据具备较强泛化能力。

Conclusion: 最后token表示蕴含丰富信息，Rep2Text有效解码该压缩表示，实现文本恢复，揭示语言模型内部的信息瓶颈效应并展现良好泛化性。

Abstract: Large language models (LLMs) have achieved remarkable progress across diverse tasks, yet their internal mechanisms remain largely opaque. In this work, we address a fundamental question: to what extent can the original input text be recovered from a single last-token representation within an LLM? We propose Rep2Text, a novel framework for decoding full text from last-token representations. Rep2Text employs a trainable adapter that projects a target model's internal representations into the embedding space of a decoding language model, which then autoregressively reconstructs the input text. Experiments on various model combinations (Llama-3.1-8B, Gemma-7B, Mistral-7B-v0.1, Llama-3.2-3B) demonstrate that, on average, over half of the information in 16-token sequences can be recovered from this compressed representation while maintaining strong semantic integrity and coherence. Furthermore, our analysis reveals an information bottleneck effect: longer sequences exhibit decreased token-level recovery while preserving strong semantic integrity. Besides, our framework also demonstrates robust generalization to out-of-distribution medical data.

</details>


### [51] [TabRAG: Tabular Document Retrieval via Structured Language Representations](https://arxiv.org/abs/2511.06582)
*Jacob Si,Mike Qu,Michelle Lee,Yingzhen Li*

Main category: cs.CL

TL;DR: 本文提出了TabRAG，一种基于解析的RAG流水线，通过结构化语言表示处理表格密集型文档，提升了检索增强生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于解析的表格数据嵌入方法效果不佳，而直接微调嵌入模型计算成本高昂。

Method: 设计TabRAG，利用结构化语言表示方法来解析表格重的文档，改进基于解析的RAG流程。

Result: TabRAG在生成和检索任务上优于现有流行的基于解析方法。

Conclusion: TabRAG有效提升了处理表格数据的RAG性能，为表格数据检索增强生成提供了新的解决方案。

Abstract: Ingesting data for Retrieval-Augmented Generation (RAG) involves either fine-tuning the embedding model directly on the target corpus or parsing documents for embedding model encoding. The former, while accurate, incurs high computational hardware requirements, while the latter suffers from suboptimal performance when extracting tabular data. In this work, we address the latter by presenting TabRAG, a parsing-based RAG pipeline designed to tackle table-heavy documents via structured language representations. TabRAG outperforms existing popular parsing-based methods for generation and retrieval. Code is available at https://github.com/jacobyhsi/TabRAG.

</details>


### [52] [MedVoiceBias: A Controlled Study of Audio LLM Behavior in Clinical Decision-Making](https://arxiv.org/abs/2511.06592)
*Zhi Rui Tam,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 音频输入导致大型语言模型在临床建议中存在严重偏见，尤其在年龄和情绪识别方面，可能加剧医疗不平等。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型从文本转向临床环境中的音频交互，探讨其是否引入了通过声学副语言线索产生的新偏见和漏洞。

Method: 将170个临床案例合成36种不同年龄、性别、情绪的语音，测试多个模型在文本和语音输入下手术建议的差异，并使用链式思维提示分析偏见来源。

Result: 发现音频输入导致手术建议差异高达35%，且一模型建议数减少80%；不同年龄声音之间存在高达12%的建议差异；性别偏见可通过显式推理消除，但情绪影响未被准确检测。

Conclusion: 当前音频大型语言模型容易基于患者的声音特征而非医学证据做出临床决策，存在加剧医疗差异的风险，亟需设计偏见感知的架构以保证临床应用安全。

Abstract: As large language models transition from text-based interfaces to audio interactions in clinical settings, they might introduce new vulnerabilities through paralinguistic cues in audio. We evaluated these models on 170 clinical cases, each synthesized into speech from 36 distinct voice profiles spanning variations in age, gender, and emotion. Our findings reveal a severe modality bias: surgical recommendations for audio inputs varied by as much as 35% compared to identical text-based inputs, with one model providing 80% fewer recommendations. Further analysis uncovered age disparities of up to 12% between young and elderly voices, which persisted in most models despite chain-of-thought prompting. While explicit reasoning successfully eliminated gender bias, the impact of emotion was not detected due to poor recognition performance. These results demonstrate that audio LLMs are susceptible to making clinical decisions based on a patient's voice characteristics rather than medical evidence, a flaw that risks perpetuating healthcare disparities. We conclude that bias-aware architectures are essential and urgently needed before the clinical deployment of these models.

</details>


### [53] [Duality-based Mode Operations and Pyramid Multilayer Mapping for Rhetorical Modes](https://arxiv.org/abs/2511.06601)
*Zi-Niu Wu*

Main category: cs.CL

TL;DR: 本文提出了一种基于对偶操作的修辞模式扩展方法及金字塔多层映射框架，提升了表达多样性并降低认知复杂性，实现了修辞体系的动态可测量化。


<details>
  <summary>Details</summary>
Motivation: 修辞模式在学术和非学术写作中广泛使用，且是语言学和计算模型研究的对象。建立语言学、教学、学术和计算研究间的概念桥梁，有助于相互促进和提高。

Method: 通过引入对偶性操作（分割-合并、正向-逆向、扩展-压缩和正交对偶），拓展修辞模式，生成组合和泛化等新模式；设计三层金字塔多层映射（修辞模型层、认知层、知识层）以降低复杂性；运用二项组合数学和香农熵分析量化表达多样性和复杂度。

Result: 定义了边际修辞比特（MRB）和表达增长速度指标，显示分层选择显著减少选择不确定性，修辞体系从静态不可测转向动态可测。

Conclusion: 该机制为未来AI系统提供了基于多层修辞推理结构而不仅语言符号操作的新路径，有望连接语言学、教学、学术与计算领域，实现更智能的语篇设计。

Abstract: Rhetorical modes are useful in both academic and non-academic writing, and can be subjects to be studied within linguistic research and computational modeling. Establishing a conceptual bridge among these domains could enable each to benefit from the others. This paper proposes duality-based mode operations (split-unite, forward-backward, expansion-reduction and orthogonal dualities) to expand the set of rhetorical modes, introducing generated modes like combination and generalization, thereby enhancing epistemic diversity across multiple applications. It further presents a pyramid multilayer mapping framework (e.g., three layers from the rhetorical model layer, to cognitive layer, and to epistemic layers) that reduces the resulting cognitive complexity. The degrees of expressive diversity and complexity reduction are quantified through binomial combinatorics and Shannon entropy analysis. A Marginal Rhetorical Bit (MRB) is identified, permitting the definition of a rhetorical-scalable parameter that measures expressive growth speed in bits per stage. A direct entropy measure shows that hierarchical selection over smaller subsets markedly reduces choice uncertainty compared with flat selection across all modes. These considerations appear to transform static and non-measurable rhetorical taxonomies into more dynamic and more measurable systems for discourse design. From this work, it would be possible to identify a pathway for future AI systems to operate not only on language tokens but on layered rhetorical reasoning structures, bridging linguistic, pedagogical, academic, and computational research

</details>


### [54] [How AI Fails: An Interactive Pedagogical Tool for Demonstrating Dialectal Bias in Automated Toxicity Models](https://arxiv.org/abs/2511.06676)
*Subhojit Ghimire*

Main category: cs.CL

TL;DR: 本文研究了AI驱动的内容审核中的偏见问题，重点分析了毒性检测模型对非裔美国英语（AAE）和标准美式英语（SAE）的表现差异，并开发了一个交互式工具揭示偏见的实际影响。


<details>
  <summary>Details</summary>
Motivation: 随着AI内容审核普及，存在对算法偏见的担忧，特别是在检测不同语言变体的内容时可能产生的不公平现象。

Method: 通过对unitary/toxic-bert模型的量化基准测试，比较其对AAE和SAE文本的毒性评分差异；同时设计一个用户可调阈值的交互式工具，直观展示偏见如何被政策放大并影响用户。

Result: 发现模型对AAE文本的毒性评分明显偏高，身份仇恨评分高出8.8倍，暴露了系统性偏见；交互工具显示了人类设定的阈值如何放大算法偏差，产生歧视效果。

Conclusion: 本文不仅提供了统计上的偏见证据，也通过工具提升公众对AI偏见的认识，强调需要关注算法与政策共同作用下的歧视问题。

Abstract: Now that AI-driven moderation has become pervasive in everyday life, we often hear claims that "the AI is biased". While this is often said jokingly, the light-hearted remark reflects a deeper concern. How can we be certain that an online post flagged as "inappropriate" was not simply the victim of a biased algorithm? This paper investigates this problem using a dual approach. First, I conduct a quantitative benchmark of a widely used toxicity model (unitary/toxic-bert) to measure performance disparity between text in African-American English (AAE) and Standard American English (SAE). The benchmark reveals a clear, systematic bias: on average, the model scores AAE text as 1.8 times more toxic and 8.8 times higher for "identity hate". Second, I introduce an interactive pedagogical tool that makes these abstract biases tangible. The tool's core mechanic, a user-controlled "sensitivity threshold," demonstrates that the biased score itself is not the only harm; instead, the more-concerning harm is the human-set, seemingly neutral policy that ultimately operationalises discrimination. This work provides both statistical evidence of disparate impact and a public-facing tool designed to foster critical AI literacy.

</details>


### [55] [Steering LLMs toward Korean Local Speech: Iterative Refinement Framework for Faithful Dialect Translation](https://arxiv.org/abs/2511.06680)
*Keunhyeung Park,Seunguk Yu,Youngbin Kim*

Main category: cs.CL

TL;DR: 本文针对标准语到方言的机器翻译任务，提出了一个迭代的方言精炼框架（DIA-REFINE），利用外部方言分类器引导大语言模型生成忠实的方言翻译，并设计了新的评价指标以克服N-gram指标的局限性。实验证明，该方法显著提升了方言翻译的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在标准语到方言翻译中存在方言差距，且传统的N-gram评测指标偏向源语复制，无法准确评估方言翻译的真实效果。

Method: 提出DIA-REFINE框架，通过翻译、验证和反馈的迭代流程，利用外部方言分类器指导模型生成忠实的目标方言文本。同时，设计了方言保真度评分（DFS）和目标方言比例（TDR）两项新指标以量化语言转变和评价方言翻译质量。

Result: 在韩语方言的零样本和上下文学习基线实验中，DIA-REFINE有效提升了方言保真度，且新指标能区别真假成功案例，识别出传统N-gram评分高但方言翻译失败的情况。结合上下文实例进一步提升了方言表达的翻译效果。

Conclusion: 本文提出的DIA-REFINE框架为方言翻译提供了目标导向、包容性的解决方案，并提出了更严谨的评价指标，有助于深入理解模型在方言翻译任务中的实际表现。

Abstract: Standard-to-dialect machine translation remains challenging due to a persistent dialect gap in large language models and evaluation distortions inherent in n-gram metrics, which favor source copying over authentic dialect translation. In this paper, we propose the dialect refinement (DIA-REFINE) framework, which guides LLMs toward faithful target dialect outputs through an iterative loop of translation, verification, and feedback using external dialect classifiers. To address the limitations of n-gram-based metrics, we introduce the dialect fidelity score (DFS) to quantify linguistic shift and the target dialect ratio (TDR) to measure the success of dialect translation. Experiments on Korean dialects across zero-shot and in-context learning baselines demonstrate that DIA-REFINE consistently enhances dialect fidelity. The proposed metrics distinguish between False Success cases, where high n-gram scores obscure failures in dialectal translation, and True Attempt cases, where genuine attempts at dialectal translation yield low n-gram scores. We also observed that models exhibit varying degrees of responsiveness to the framework, and that integrating in-context examples further improves the translation of dialectal expressions. Our work establishes a robust framework for goal-directed, inclusive dialect translation, providing both rigorous evaluation and critical insights into model performance.

</details>


### [56] [Textual Self-attention Network: Test-Time Preference Optimization through Textual Gradient-based Attention](https://arxiv.org/abs/2511.06682)
*Shibing Mo,Haoyang Ruan,Kai Wu,Jing Liu*

Main category: cs.CL

TL;DR: 本文提出了文本自注意力网络(TSAN)，一种在测试时无需参数更新，通过自然语言形式的自注意力机制优化大规模语言模型输出以符合人类偏好的方法。


<details>
  <summary>Details</summary>
Motivation: 现有利用文本反馈的测试时方法只能评价和修改单一候选回答，缺乏系统性整合多候选优点的机制，导致无法充分发挥不同回答在清晰度、准确性及语气等方面的优势。

Method: TSAN通过将多个候选回答格式化为文本键值，利用基于大模型的注意力模块计算权重，结合加权信息生成更优的偏好对齐回答。整个过程在文本梯度空间中迭代进行，无需参数更新，且具有可解释性。

Result: 实验证明，在基础监督微调模型上经过仅三次测试时迭代，TSAN性能超过了诸如Llama-3.1-70B-Instruct等监督模型，且优于当前最先进的测试时对齐方法。

Conclusion: TSAN有效利用多候选答案，通过自然语言自注意力机制在测试时优化大语言模型，提升了输出与人类偏好的匹配度，具有较强的实际应用潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable generalization capabilities, but aligning their outputs with human preferences typically requires expensive supervised fine-tuning. Recent test-time methods leverage textual feedback to overcome this, but they often critique and revise a single candidate response, lacking a principled mechanism to systematically analyze, weigh, and synthesize the strengths of multiple promising candidates. Such a mechanism is crucial because different responses may excel in distinct aspects (e.g., clarity, factual accuracy, or tone), and combining their best elements may produce a far superior outcome. This paper proposes the Textual Self-Attention Network (TSAN), a new paradigm for test-time preference optimization that requires no parameter updates. TSAN emulates self-attention entirely in natural language to overcome this gap: it analyzes multiple candidates by formatting them into textual keys and values, weighs their relevance using an LLM-based attention module, and synthesizes their strengths into a new, preference-aligned response under the guidance of the learned textual attention. This entire process operates in a textual gradient space, enabling iterative and interpretable optimization. Empirical evaluations demonstrate that with just three test-time iterations on a base SFT model, TSAN outperforms supervised models like Llama-3.1-70B-Instruct and surpasses the current state-of-the-art test-time alignment method by effectively leveraging multiple candidate solutions.

</details>


### [57] [Sentiment Analysis On YouTube Comments Using Machine Learning Techniques Based On Video Games Content](https://arxiv.org/abs/2511.06708)
*Adi Danish Bin Muhammad Amin,Mohaiminul Islam Bhuiyan,Nur Shazwani Kamarudin,Zulfahmi Toh,Nur Syafiqah Nafis*

Main category: cs.CL

TL;DR: 本文通过分析YouTube评论中的用户情感，利用机器学习方法对视频游戏情感进行分类，SVM表现最佳，揭示了用户偏好和评价趋势，为游戏开发提供反馈。


<details>
  <summary>Details</summary>
Motivation: 游戏行业快速发展中，理解用户通过YouTube评论表达的情感变得重要，以提升游戏设计和用户体验。

Method: 利用YouTube API收集游戏评论，使用TextBlob进行情感分析，采用朴素贝叶斯、逻辑回归和SVM机器学习算法进行分类，其中SVM表现最好。

Result: SVM在多个数据集上表现出最高分类准确率，分析结果揭示了用户喜好和批评的趋势和洞察。

Conclusion: 先进的情感分析能更好捕捉用户评论中的细微情感，为游戏开发提供宝贵反馈，未来将结合更复杂的自然语言处理技术和更多数据源提升分析效果。

Abstract: The rapid evolution of the gaming industry, driven by technological advancements and a burgeoning community, necessitates a deeper understanding of user sentiments, especially as expressed on popular social media platforms like YouTube. This study presents a sentiment analysis on video games based on YouTube comments, aiming to understand user sentiments within the gaming community. Utilizing YouTube API, comments related to various video games were collected and analyzed using the TextBlob sentiment analysis tool. The pre-processed data underwent classification using machine learning algorithms, including Naïve Bayes, Logistic Regression, and Support Vector Machine (SVM). Among these, SVM demonstrated superior performance, achieving the highest classification accuracy across different datasets. The analysis spanned multiple popular gaming videos, revealing trends and insights into user preferences and critiques. The findings underscore the importance of advanced sentiment analysis in capturing the nuanced emotions expressed in user comments, providing valuable feedback for game developers to enhance game design and user experience. Future research will focus on integrating more sophisticated natural language processing techniques and exploring additional data sources to further refine sentiment analysis in the gaming domain.

</details>


### [58] [Rethinking Retrieval-Augmented Generation for Medicine: A Large-Scale, Systematic Expert Evaluation and Practical Insights](https://arxiv.org/abs/2511.06738)
*Hyunjae Kim,Jiwoong Sohn,Aidan Gilson,Nicholas Cochran-Caggiano,Serina Applebaum,Heeju Jin,Seihee Park,Yujin Park,Jiyeong Park,Seoyoung Choi,Brittany Alexandra Herrera Contreras,Thomas Huang,Jaehoon Yun,Ethan F. Wei,Roy Jiang,Leah Colucci,Eric Lai,Amisha Dave,Tuo Guo,Maxwell B. Singer,Yonghoe Koo,Ron A. Adelman,James Zou,Andrew Taylor,Arman Cohan,Hua Xu,Qingyu Chen*

Main category: cs.CL

TL;DR: 本文系统评估了在医学领域应用的大型语言模型检索增强生成技术（RAG），发现标准RAG存在显著性能下降，检索和证据选择是主要瓶颈。通过证据过滤和查询重构等简单策略，可显著提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学应用中面临知识快速更新和提供可验证证据推理的挑战，RAG技术被广泛用于改善模型表现，但其实际效果尚不明确。

Method: 文章邀请18位医学专家对800个基于真实病例和USMLE风格提问的模型输出进行共80502条注释，分解评估RAG流程中的证据检索、证据选择和响应生成三个环节，并与非RAG模型对比性能。

Result: 标准RAG在提升信息相关性和准确性方面表现不佳，只有22%的检索结果相关，证据选择准确率41-43%，召回率27-49%，导致生成回答的事实性和完整性较非RAG下降6%和5%。简单的证据过滤和查询重构策略可提升MedMCQA和MedXpertQA测试集上的表现12%和8.2%。

Conclusion: 当前标准RAG方案在医学大模型应用中存在明显不足，强调需针对检索和证据选择环节进行优化，推荐采用阶段感知评估与系统设计策略以提升医学大模型的可靠性。

Abstract: Large language models (LLMs) are transforming the landscape of medicine, yet two fundamental challenges persist: keeping up with rapidly evolving medical knowledge and providing verifiable, evidence-grounded reasoning. Retrieval-augmented generation (RAG) has been widely adopted to address these limitations by supplementing model outputs with retrieved evidence. However, whether RAG reliably achieves these goals remains unclear. Here, we present the most comprehensive expert evaluation of RAG in medicine to date. Eighteen medical experts contributed a total of 80,502 annotations, assessing 800 model outputs generated by GPT-4o and Llama-3.1-8B across 200 real-world patient and USMLE-style queries. We systematically decomposed the RAG pipeline into three components: (i) evidence retrieval (relevance of retrieved passages), (ii) evidence selection (accuracy of evidence usage), and (iii) response generation (factuality and completeness of outputs). Contrary to expectation, standard RAG often degraded performance: only 22% of top-16 passages were relevant, evidence selection remained weak (precision 41-43%, recall 27-49%), and factuality and completeness dropped by up to 6% and 5%, respectively, compared with non-RAG variants. Retrieval and evidence selection remain key failure points for the model, contributing to the overall performance drop. We further show that simple yet effective strategies, including evidence filtering and query reformulation, substantially mitigate these issues, improving performance on MedMCQA and MedXpertQA by up to 12% and 8.2%, respectively. These findings call for re-examining RAG's role in medicine and highlight the importance of stage-aware evaluation and deliberate system design for reliable medical LLM applications.

</details>


### [59] [Sensitivity of Small Language Models to Fine-tuning Data Contamination](https://arxiv.org/abs/2511.06763)
*Nicy Scaria,Silvester John Joseph Kennedy,Deepak Subramani*

Main category: cs.CL

TL;DR: 本论文系统研究了小型语言模型在指令调优过程中对数据污染的脆弱性，发现语法层面的污染对模型性能影响极大，且大模型在语义污染方面更易受损。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境下部署小型语言模型时，其对指令调优中数据污染的行为鲁棒性尚不清楚，亟需系统评估不同类型污染对模型的影响。

Method: 对23个不同参数规模（2.7亿至40亿）的小型语言模型进行实验，施加语法（字符和词序反转）与语义（无关及反事实回答）污染，覆盖25%、50%、75%、100%污染水平，测量模型性能变化。

Result: 语法污染导致严重性能崩溃，尤其是字符反转造成几乎完全失效；语义污染表现出阈值效应且对核心语言能力影响较小。更大模型对语义污染更敏感，显示“能力诅咒”现象，而模型对齐过程未必提高其鲁棒性。

Conclusion: 小型语言模型对语法污染异常脆弱，污染类型影响表现不对称，当前鲁棒性假设不足，需引入污染感知训练以保障实际部署效果。

Abstract: Small Language Models (SLMs) are increasingly being deployed in resource-constrained environments, yet their behavioral robustness to data contamination during instruction tuning remains poorly understood. We systematically investigate the contamination sensitivity of 23 SLMs (270M to 4B parameters) across multiple model families by measuring susceptibility to syntactic and semantic transformation types during instruction tuning: syntactic transformations (character and word reversal) and semantic transformations (irrelevant and counterfactual responses), each applied at contamination levels of 25\%, 50\%, 75\%, and 100\%. Our results reveal fundamental asymmetries in vulnerability patterns: syntactic transformations cause catastrophic performance degradation, with character reversal producing near-complete failure across all models regardless of size or family, while semantic transformations demonstrate distinct threshold behaviors and greater resilience in core linguistic capabilities. Critically, we discover a ``\textit{capability curse}" where larger, more capable models become more susceptible to learning semantic corruptions, effectively following harmful instructions more readily, while our analysis of base versus instruction-tuned variants reveals that alignment provides inconsistent robustness benefits, sometimes even reducing resilience. Our work establishes three core contributions: (1) empirical evidence of SLMs' disproportionate vulnerability to syntactic pattern contamination, (2) identification of asymmetric sensitivity patterns between syntactic and semantic transformations, and (3) systematic evaluation protocols for contamination robustness assessment. These findings have immediate deployment implications, suggesting that current robustness assumptions may not hold for smaller models and highlighting the need for contamination-aware training protocols.

</details>


### [60] [SAFENLIDB: A Privacy-Preserving Safety Alignment Framework for LLM-based Natural Language Database Interfaces](https://arxiv.org/abs/2511.06778)
*Ruiheng Liu,XiaoBing Chen,Jinyu Zhang,Qiongwen Zhang,Yu Zhang,Bailong Yang*

Main category: cs.CL

TL;DR: 本文提出了SafeNlidb，一个针对基于大语言模型的自然语言接口数据库的隐私安全对齐框架，通过自动生成结合安全推理与SQL生成的交互数据，并引入推理预热与交替优化策略，显著提升了安全性与实用性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言数据库接口中的应用带来了隐私和安全风险，现有方法难以应对复杂的推理攻击，且存在误报率高和查询可靠性受损的问题。

Method: 提出SafeNlidb框架，自动生成混合链式思维交互数据，将隐式安全推理与SQL生成结合；引入推理预热和交替偏好优化，解决直接偏好优化的多重偏好振荡，实现细粒度安全意识SQL生成，无需人工标注偏好数据。

Result: 实验显示该方法在保持高效用性的同时，在安全性上明显优于更大规模的模型和理想设置的基线。

Conclusion: SafeNlidb有效提升了LLM驱动的自然语言数据库接口的安全性，保证了SQL查询的可靠性，解决了现有方法中的关键不足。

Abstract: The rapid advancement of Large Language Models (LLMs) has driven significant progress in Natural Language Interface to Database (NLIDB). However, the widespread adoption of LLMs has raised critical privacy and security concerns. During interactions, LLMs may unintentionally expose confidential database contents or be manipulated by attackers to exfiltrate data through seemingly benign queries. While current efforts typically rely on rule-based heuristics or LLM agents to mitigate this leakage risk, these methods still struggle with complex inference-based attacks, suffer from high false positive rates, and often compromise the reliability of SQL queries. To address these challenges, we propose \textsc{SafeNlidb}, a novel privacy-security alignment framework for LLM-based NLIDB. The framework features an automated pipeline that generates hybrid chain-of-thought interaction data from scratch, seamlessly combining implicit security reasoning with SQL generation. Additionally, we introduce reasoning warm-up and alternating preference optimization to overcome the multi-preference oscillations of Direct Preference Optimization (DPO), enabling LLMs to produce security-aware SQL through fine-grained reasoning without the need for human-annotated preference data. Extensive experiments demonstrate that our method outperforms both larger-scale LLMs and ideal-setting baselines, achieving significant security improvements while preserving high utility.WARNING: This work may contain content that is offensive and harmful!

</details>


### [61] [Learning to Focus: Focal Attention for Selective and Scalable Transformers](https://arxiv.org/abs/2511.06818)
*Dhananjay Ram,Wei Xia,Stefano Soatto*

Main category: cs.CL

TL;DR: 本文提出了一种名为Focal Attention的注意力机制改进方法，通过调节softmax温度，增强了注意力分布的集中性，从而提升了模型在长上下文任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 标准的softmax注意力分布较为“嘈杂”，在每层特征选择时效果欠佳，尤其在处理长上下文时表现受限。

Method: 通过设置或学习softmax温度参数，使注意力分布更加集中，有效强化对关键token的关注并抑制无关token。

Result: 相比标准Transformer，Focal Attention在模型规模、训练数据和上下文长度方面表现更优，参数数量减少42%、训练数据减少33%，长上下文任务中性能提升17%-82%。

Conclusion: Focal Attention是一种简单有效的注意力机制改进，显著提升了Transformer模型在长上下文任务中的性能和效率，具有广泛的实用价值。

Abstract: Attention is a core component of transformer architecture, whether encoder-only, decoder-only, or encoder-decoder model. However, the standard softmax attention often produces noisy probability distribution, which can impair effective feature selection at every layer of these models, particularly for long contexts. We propose Focal Attention, a simple yet effective modification that sharpens the attention distribution by controlling the softmax temperature, either as a fixed hyperparameter or as a learnable parameter during training. This sharpening enables the model to concentrate on the most relevant tokens while suppressing irrelevant ones. Empirically, Focal Attention scales more favorably than standard transformer with respect to model size, training data, and context length. Across diverse benchmarks, it achieves the same accuracy with up to 42% fewer parameters or 33% less training data. On long-context tasks, it delivers substantial relative improvements ranging from 17% to 82%, demonstrating its effectiveness in real world applications.

</details>


### [62] [Beyond Plain Demos: A Demo-centric Anchoring Paradigm for In-Context Learning in Alzheimer's Disease Detection](https://arxiv.org/abs/2511.06826)
*Puzhen Su,Haoran Yin,Yongzhu Miao,Jintao Tang,Shasha Li,Ting Wang*

Main category: cs.CL

TL;DR: 论文提出了DA4ICL，一个针对阿尔茨海默病检测任务的演示集改进框架，通过多样化和对比检索扩展上下文宽度，并在每个Transformer层使用投影矢量锚定加深信号，实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型对阿尔茨海默病检测任务效果不佳，原因在于预训练缺乏此任务信息，且同一场景的同质性演示限制了模型的任务认知和上下文感知能力。

Method: 提出DA4ICL框架，结合多样化和对比检索(DCR)以拓展上下文宽度，以及在每个Transformer层使用投影矢量锚定(PVA)以增强演示的细粒度信号。

Result: 在三个阿尔茨海默病检测基准上，DA4ICL相较于现有的在上下文学习（ICL）和任务向量（TV）方法，实现了显著且稳定的性能提升。

Conclusion: DA4ICL为低资源、超出分布的细粒度任务提供了新的适应范式，通过丰富演示集和层级信号增强，有效提升了大型语言模型的任务感知和表现。

Abstract: Detecting Alzheimer's disease (AD) from narrative transcripts challenges large language models (LLMs): pre-training rarely covers this out-of-distribution task, and all transcript demos describe the same scene, producing highly homogeneous contexts. These factors cripple both the model's built-in task knowledge (\textbf{task cognition}) and its ability to surface subtle, class-discriminative cues (\textbf{contextual perception}). Because cognition is fixed after pre-training, improving in-context learning (ICL) for AD detection hinges on enriching perception through better demonstration (demo) sets. We demonstrate that standard ICL quickly saturates, its demos lack diversity (context width) and fail to convey fine-grained signals (context depth), and that recent task vector (TV) approaches improve broad task adaptation by injecting TV into the LLMs' hidden states (HSs), they are ill-suited for AD detection due to the mismatch of injection granularity, strength and position. To address these bottlenecks, we introduce \textbf{DA4ICL}, a demo-centric anchoring framework that jointly expands context width via \emph{\textbf{Diverse and Contrastive Retrieval}} (DCR) and deepens each demo's signal via \emph{\textbf{Projected Vector Anchoring}} (PVA) at every Transformer layer. Across three AD benchmarks, DA4ICL achieves large, stable gains over both ICL and TV baselines, charting a new paradigm for fine-grained, OOD and low-resource LLM adaptation.

</details>


### [63] [CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource Taiwanese Hokkien Speech Recognition](https://arxiv.org/abs/2511.06860)
*Hung-Yang Sung,Chien-Chun Wang,Kuan-Tang Huang,Tien-Hong Lo,Yu-Sheng Tsao,Yung-Chang Hsu,Berlin Chen*

Main category: cs.CL

TL;DR: 提出了一种针对台湾闽南语自动语音识别的跨语种微调框架CLiFT-ASR，通过两阶段训练有效结合注音和汉字转录，显著提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如台湾闽南语）语音识别面临标注数据匮乏问题，且仅用汉字或仅用拼音转录各有不足，缺乏结合两者的分阶段训练策略。

Method: 基于普通话HuBERT模型，CLiFT-ASR先通过拼音注音阶段学习声学和声调表示，再通过汉字转录阶段学习词汇和句法结构，实现两阶段渐进式适配。

Result: 在TAT-MOE语料库上，CLiFT-ASR相比强基线实现字符错误率24.88%的相对下降。

Conclusion: CLiFT-ASR为台湾闽南语ASR提供了一种高效且参数节省的解决方案，且有潜力推广至其他低资源语言场景。

Abstract: Automatic speech recognition (ASR) for low-resource languages such as Taiwanese Hokkien is difficult due to the scarcity of annotated data. However, direct fine-tuning on Han-character transcriptions often fails to capture detailed phonetic and tonal cues, while training only on romanization lacks lexical and syntactic coverage. In addition, prior studies have rarely explored staged strategies that integrate both annotation types. To address this gap, we present CLiFT-ASR, a cross-lingual fine-tuning framework that builds on Mandarin HuBERT models and progressively adapts them to Taiwanese Hokkien. The framework employs a two-stage process in which it first learns acoustic and tonal representations from phonetic Tai-lo annotations and then captures vocabulary and syntax from Han-character transcriptions. This progressive adaptation enables effective alignment between speech sounds and orthographic structures. Experiments on the TAT-MOE corpus demonstrate that CLiFT-ASR achieves a 24.88\% relative reduction in character error rate (CER) compared with strong baselines. The results indicate that CLiFT-ASR provides an effective and parameter-efficient solution for Taiwanese Hokkien ASR and that it has potential to benefit other low-resource language scenarios.

</details>


### [64] [Inclusion of Role into Named Entity Recognition and Ranking](https://arxiv.org/abs/2511.06886)
*Neelesh Kumar Shukla,Sanasam Ranbir Singh*

Main category: cs.CL

TL;DR: 本文将实体角色检测任务建模为命名实体识别和实体检索/排序，提出了一种基于小规模无领域数据自动学习角色和实体表征的方法。


<details>
  <summary>Details</summary>
Motivation: 实体在不同上下文中扮演不同角色，需要针对角色定义和提取实体，现有方法难以处理上下文依赖且缺乏大规模领域数据的问题。

Method: 将实体角色检测任务作为命名实体识别的多类分类任务以及实体检索任务，自动学习代表词汇和短语构建角色和实体的表征，探索句子和文档级上下文，利用小规模无领域数据进行训练。

Result: 提出的方法在处理实体角色的识别与检索方面有效，尤其是在缺乏大规模领域专用数据的情况下表现优良。

Conclusion: 通过结合命名实体识别和实体检索的方法，利用自动学习的表示和小数据集，能够较好解决实体角色检测问题，尤其适用于数据稀缺的情境。

Abstract: Most of the Natural Language Processing sys- tems are involved in entity-based processing for several tasks like Information Extraction, Question-Answering, Text-Summarization and so on. A new challenge comes when entities play roles according to their act or attributes in certain context. Entity Role Detection is the task of assigning such roles to the entities. Usu- ally real-world entities are of types: person, lo- cation and organization etc. Roles could be con- sidered as domain-dependent subtypes of these types. In the cases, where retrieving a subset of entities based on their roles is needed, poses the problem of defining the role and entities having those roles. This paper presents the study of study of solving Entity Role Detection prob- lem by modeling it as Named Entity Recogni- tion (NER) and Entity Retrieval/Ranking task. In NER, these roles could be considered as mutually exclusive classes and standard NER methods like sequence tagging could be used. For Entity Retrieval, Roles could be formulated as Query and entities as Collection on which the query needs to be executed. The aspect of Entity Retrieval task, which is different than document retrieval task is that the entities and roles against which they need to be retrieved are indirectly described. We have formulated au- tomated ways of learning representative words and phrases and building representations of roles and entities using them. We have also explored different contexts like sentence and document. Since the roles depend upon con- text, so it is not always possible to have large domain-specific dataset or knowledge bases for learning purposes, so we have tried to exploit the information from small dataset in domain- agnostic way.

</details>


### [65] [EduGuardBench: A Holistic Benchmark for Evaluating the Pedagogical Fidelity and Adversarial Safety of LLMs as Simulated Teachers](https://arxiv.org/abs/2511.06890)
*Yilin Jiang,Mingzi Zhang,Xuanyu Yin,Sheng Jin,Suyu Lu,Zuocan Ying,Zengyi Yu,Xiangjie Kong*

Main category: cs.CL

TL;DR: 本文提出了EduGuardBench基准，用于评估大型语言模型在教育场景中的专业能力和伦理安全性，特别是其作为教师的表现和安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法有效衡量语言模型在教育角色扮演的真实性和特有的教学风险，急需更全面的考核工具保障个性化教育的专业与伦理安全。

Method: 设计了包含角色扮演真实性评分和针对教学职业特有危害的诊断的双重组件基准，利用针对一般危害和学术不端的针对性对抗性提示评估模型的安全漏洞，采用多种指标如ASR和拒绝质量评估。

Result: 14个主流模型实验显示：推理型模型角色扮演真实性较高，但普遍存在能力不足问题。同时发现中型模型安全性最低，安全随规模单调递增假设被挑战。最安全模型能将有害请求转化为教育机会并提供理想拒绝，显著降低攻击成功率。

Conclusion: EduGuardBench提供了一个超越单一知识测试的综合框架，有助于全面评估AI教育应用中的专业性、伦理性及教学一致性，揭示关键安全动态，为可信AI教育部署提供支持。

Abstract: Large Language Models for Simulating Professions (SP-LLMs), particularly as teachers, are pivotal for personalized education. However, ensuring their professional competence and ethical safety is a critical challenge, as existing benchmarks fail to measure role-playing fidelity or address the unique teaching harms inherent in educational scenarios. To address this, we propose EduGuardBench, a dual-component benchmark. It assesses professional fidelity using a Role-playing Fidelity Score (RFS) while diagnosing harms specific to the teaching profession. It also probes safety vulnerabilities using persona-based adversarial prompts targeting both general harms and, particularly, academic misconduct, evaluated with metrics including Attack Success Rate (ASR) and a three-tier Refusal Quality assessment. Our extensive experiments on 14 leading models reveal a stark polarization in performance. While reasoning-oriented models generally show superior fidelity, incompetence remains the dominant failure mode across most models. The adversarial tests uncovered a counterintuitive scaling paradox, where mid-sized models can be the most vulnerable, challenging monotonic safety assumptions. Critically, we identified a powerful Educational Transformation Effect: the safest models excel at converting harmful requests into teachable moments by providing ideal Educational Refusals. This capacity is strongly negatively correlated with ASR, revealing a new dimension of advanced AI safety. EduGuardBench thus provides a reproducible framework that moves beyond siloed knowledge tests toward a holistic assessment of professional, ethical, and pedagogical alignment, uncovering complex dynamics essential for deploying trustworthy AI in education. See https://github.com/YL1N/EduGuardBench for Materials.

</details>


### [66] [RPTS: Tree-Structured Reasoning Process Scoring for Faithful Multimodal Evaluation](https://arxiv.org/abs/2511.06899)
*Haofeng Wang,Yu Zhang*

Main category: cs.CL

TL;DR: 本文提出了基于推理树的评估指标RPTS，通过权重调整评估多模态推理过程，构建了包含374张图片和390个推理实例的新基准数据RPTS-Eval，揭示大型视觉语言模型在多模态推理中的局限。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理评测多采用选择题或简答题形式，忽略了推理过程本身，且简单考察错误答案的推理，未考虑错误推理导致正确答案的情况及跨模态关系对推理的影响。

Method: 提出基于树结构的推理过程评分指标RPTS，将推理步骤组织成推理树，利用层级信息赋予每个推理步骤加权的忠实度分数，通过动态调整权重评估整体推理正确性并定位推理失败环节。构建包含视觉-文本线索的RPTS-Eval基准，定义三种跨模态关系以研究其对推理的影响。

Result: 使用RPTS评估主流大型视觉语言模型（如GPT4o、Llava-Next），发现其在多模态推理方面存在不足，揭示开源与商业闭源模型的差异。

Conclusion: RPTS及RPTS-Eval为多模态推理过程提供了细致评估手段，有助于推动多模态推理领域研究发展。

Abstract: Large Vision-Language Models (LVLMs) excel in multimodal reasoning and have shown impressive performance on various multimodal benchmarks. However, most of these benchmarks evaluate models primarily through multiple-choice or short-answer formats, which do not take the reasoning process into account. Although some benchmarks assess the reasoning process, their methods are often overly simplistic and only examine reasoning when answers are incorrect. This approach overlooks scenarios where flawed reasoning leads to correct answers. In addition, these benchmarks do not consider the impact of intermodal relationships on reasoning. To address this issue, we propose the Reasoning Process Tree Score (RPTS), a tree structure-based metric to assess reasoning processes. Specifically, we organize the reasoning steps into a reasoning tree and leverage its hierarchical information to assign weighted faithfulness scores to each reasoning step. By dynamically adjusting these weights, RPTS not only evaluates the overall correctness of the reasoning, but also pinpoints where the model fails in the reasoning. To validate RPTS in real-world multimodal scenarios, we construct a new benchmark, RPTS-Eval, comprising 374 images and 390 reasoning instances. Each instance includes reliable visual-textual clues that serve as leaf nodes of the reasoning tree. Furthermore, we define three types of intermodal relationships to investigate how intermodal interactions influence the reasoning process. We evaluated representative LVLMs (e.g., GPT4o, Llava-Next), uncovering their limitations in multimodal reasoning and highlighting the differences between open-source and closed-source commercial LVLMs. We believe that this benchmark will contribute to the advancement of research in the field of multimodal reasoning.

</details>


### [67] [HLPD: Aligning LLMs to Human Language Preference for Machine-Revised Text Detection](https://arxiv.org/abs/2511.06942)
*Fangqi Dai,Xingjian Jiang,Zizhuang Deng*

Main category: cs.CL

TL;DR: 本文提出了基于人类语言偏好的检测方法（HLPD），通过奖励驱动的优化提升模型对人类写作风格的敏感性，从而有效识别由先进大语言模型生成或多任务机器修订的文本。


<details>
  <summary>Details</summary>
Motivation: 当前方法在检测完全由大语言模型生成的文本表现优异，但在面对先进模型输出或多任务机器修订文本时，尤其是黑盒环境下，效果显著下降。为提升检测准确性，需探索更能捕捉人类写作特征的新方法。

Method: 基于假设人类写作具有独特风格，提出人类语言偏好检测（HLPD），通过人类语言偏好优化（HLPO）过程对评分模型的token分布进行调整，使其更贴近人类写作风格，从而提升对机器修订文本的识别能力。并设计了一个五维提示生成器和多模型多任务对抗评测框架。

Result: 在对GPT系列修订文本的检测中，HLPD相较ImBD指标提升15.11%，较Fast-DetectGPT提升45.56%。在高级大模型生成文本的检测中，HLPD平均AUROC最高，超过ImBD 5.53%，超过Fast-DetectGPT 34.14%。

Conclusion: HLPD有效提升了对先进大语言模型及其多任务修订文本的识别能力，证明了基于人类独特写作风格进行优化的检测策略的有效性，且具备广泛的应用前景。

Abstract: To prevent misinformation and social issues arising from trustworthy-looking content generated by LLMs, it is crucial to develop efficient and reliable methods for identifying the source of texts. Previous approaches have demonstrated exceptional performance in detecting texts fully generated by LLMs. However, these methods struggle when confronting more advanced LLM output or text with adversarial multi-task machine revision, especially in the black-box setting, where the generating model is unknown. To address this challenge, grounded in the hypothesis that human writing possesses distinctive stylistic patterns, we propose Human Language Preference Detection (HLPD). HLPD employs a reward-based alignment process, Human Language Preference Optimization (HLPO), to shift the scoring model's token distribution toward human-like writing, making the model more sensitive to human writing, therefore enhancing the identification of machine-revised text. We test HLPD in an adversarial multi-task evaluation framework that leverages a five-dimensional prompt generator and multiple advanced LLMs to create diverse revision scenarios. When detecting texts revised by GPT-series models, HLPD achieves a 15.11% relative improvement in AUROC over ImBD, surpassing Fast-DetectGPT by 45.56%. When evaluated on texts generated by advanced LLMs, HLPD achieves the highest average AUROC, exceeding ImBD by 5.53% and Fast-DetectGPT by 34.14%. Code will be made available at https://github.com/dfq2021/HLPD.

</details>


### [68] [SCOPE: Intrinsic Semantic Space Control for Mitigating Copyright Infringement in LLMs](https://arxiv.org/abs/2511.07001)
*Zhenliang Zhang,Xinyu Hu,Xiaojun Wan*

Main category: cs.CL

TL;DR: 该论文提出了一种名为SCOPE的推理时防护方法，通过稀疏自编码器将模型隐藏状态映射到高维语义空间，识别并抑制版权敏感子空间的激活，从而有效降低版权内容泄露风险。


<details>
  <summary>Details</summary>
Motivation: 现有版权防护方法多依赖表层字符串匹配及外部过滤器，可能忽略语义改写内容且增加部署复杂度，因此需要一种更内在、更高效的版权控制方法。

Method: 论文采用稀疏自编码器将隐藏状态投射到接近单一语义的高维空间，识别版权敏感子空间，并在解码时钳制该子空间的激活，无需参数更新或辅助过滤器。

Result: 在多个权威评测基准上，SCOPE有效减轻了版权侵权风险，同时保持了模型的整体性能和实用性。

Conclusion: SCOPE可以作为一种不依赖外部资源的内在语义空间控制策略，有效缓解大语言模型在推理阶段的版权内容泄露问题。

Abstract: Large language models sometimes inadvertently reproduce passages that are copyrighted, exposing downstream applications to legal risk. Most existing studies for inference-time defences focus on surface-level token matching and rely on external blocklists or filters, which add deployment complexity and may overlook semantically paraphrased leakage. In this work, we reframe copyright infringement mitigation as intrinsic semantic-space control and introduce SCOPE, an inference-time method that requires no parameter updates or auxiliary filters. Specifically, the sparse autoencoder (SAE) projects hidden states into a high-dimensional, near-monosemantic space; benefiting from this representation, we identify a copyright-sensitive subspace and clamp its activations during decoding. Experiments on widely recognized benchmarks show that SCOPE mitigates copyright infringement without degrading general utility. Further interpretability analyses confirm that the isolated subspace captures high-level semantics.

</details>


### [69] [Automated Circuit Interpretation via Probe Prompting](https://arxiv.org/abs/2511.07002)
*Giuseppe Birardi*

Main category: cs.CL

TL;DR: 机制解释性通过自动化探针提示方法，将归因图转化为紧凑、可解释的子图，显著提升网络行为理解的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 机制解释性依赖手动分析归因图耗时长且效率低，亟需自动化工具简化该过程。

Method: 提出探针提示自动化流程，通过概念对齐的超级节点构建子图，利用透明决策规则进行特征筛选和分组，实现高影响特征的自动聚类。

Result: 五个提示实验表明该方法在保持解释覆盖度的同时降低复杂性，群组行为一致性和激活模式相似度均优于几何聚类，揭示了变换器层的层级特征转移规律。

Conclusion: 探针提示自动化流程有效提升机制解释性分析的效率和准确性，支持变换器计算的骨干与专业化视角，促进社区复现与采用。

Abstract: Mechanistic interpretability aims to understand neural networks by identifying which learned features mediate specific behaviors. Attribution graphs reveal these feature pathways, but interpreting them requires extensive manual analysis -- a single prompt can take approximately 2 hours for an experienced circuit tracer. We present probe prompting, an automated pipeline that transforms attribution graphs into compact, interpretable subgraphs built from concept-aligned supernodes. Starting from a seed prompt and target logit, we select high-influence features, generate concept-targeted yet context-varying probes, and group features by cross-prompt activation signatures into Semantic, Relationship, and Say-X categories using transparent decision rules.
  Across five prompts including classic "capitals" circuits, probe-prompted subgraphs preserve high explanatory coverage while compressing complexity (Completeness 0.83, mean across circuits; Replacement 0.54). Compared to geometric clustering baselines, concept-aligned groups exhibit higher behavioral coherence: 2.3x higher peak-token consistency (0.425 vs 0.183) and 5.8x higher activation-pattern similarity (0.762 vs 0.130), despite lower geometric compactness. Entity-swap tests reveal a layerwise hierarchy: early-layer features transfer robustly (64% transfer rate, mean layer 6.3), while late-layer Say-X features specialize for output promotion (mean layer 16.4), supporting a backbone-and-specialization view of transformer computation.
  We release code (https://github.com/peppinob-ol/attribution-graph-probing), an interactive demo (https://huggingface.co/spaces/Peppinob/attribution-graph-probing), and minimal artifacts enabling immediate reproduction and community adoption.

</details>


### [70] [Beyond English: Toward Inclusive and Scalable Multilingual Machine Translation with LLMs](https://arxiv.org/abs/2511.07003)
*Yingfeng Luo,Ziqiang Xu,Yuxuan Ouyang,Murun Yang,Dingyang Lin,Kaiyan Chang,Tong Zheng,Bei Li,Peinan Feng,Quan Du,Tong Xiao,Jingbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了LMT——一套以中英为核心、覆盖60种语言和234个翻译方向的大规模多语种翻译模型，解决了语言覆盖广泛、翻译质量一致性及英语中心偏见等问题。


<details>
  <summary>Details</summary>
Motivation: 当前多语种机器翻译存在语言覆盖不足、翻译质量不均以及对英语的中心偏向等挑战，同时发现多向微调数据导致的“方向性退化”问题影响翻译质量。

Method: 提出了“战略性下采样”来缓解方向性退化，并设计了“并行多语种提示”利用语言类型学相关的辅助语言促进跨语言迁移。

Result: 在数据策划和适应策略优化下，LMT在同等语言覆盖范围内达到了最新水平，4B模型超过了Aya-101-13B和NLLB-54B等更大规模模型。

Conclusion: LMT以不同规模版本开放，促进未来多语种翻译研究，提供了包容性、可扩展且高质量的多语种翻译基线。

Abstract: Large language models have significantly advanced Multilingual Machine Translation (MMT), yet the broad language coverage, consistent translation quality, and English-centric bias remain open challenges. To address these challenges, we introduce \textbf{LMT}, a suite of \textbf{L}arge-scale \textbf{M}ultilingual \textbf{T}ranslation models centered on both Chinese and English, covering 60 languages and 234 translation directions. During development, we identify a previously overlooked phenomenon of \textbf{directional degeneration}, where symmetric multi-way fine-tuning data overemphasize reverse directions (X $\to$ En/Zh), leading to excessive many-to-one mappings and degraded translation quality. We propose \textbf{Strategic Downsampling}, a simple yet effective method to mitigate this degeneration. In addition, we design \textbf{Parallel Multilingual Prompting (PMP)}, which leverages typologically related auxiliary languages to enhance cross-lingual transfer. Through rigorous data curation and refined adaptation strategies, LMT achieves SOTA performance among models of comparable language coverage, with our 4B model (LMT-60-4B) surpassing the much larger Aya-101-13B and NLLB-54B models by a substantial margin. We release LMT in four sizes (0.6B/1.7B/4B/8B) to catalyze future research and provide strong baselines for inclusive, scalable, and high-quality MMT \footnote{\href{https://github.com/NiuTrans/LMT}{https://github.com/NiuTrans/LMT}}.

</details>


### [71] [A Picture is Worth a Thousand (Correct) Captions: A Vision-Guided Judge-Corrector System for Multimodal Machine Translation](https://arxiv.org/abs/2511.07010)
*Siddharth Betala,Kushan Raj,Vipul Betala,Rohan Saswade*

Main category: cs.CL

TL;DR: 本文提出了一种针对英印多模态翻译任务的两阶段系统，通过自动检测与纠正训练数据中的翻译错误，结合参数高效的模型微调，提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 训练数据存在质量问题，影响翻译模型效果，需自动识别并纠正错误以提升翻译性能。

Method: 构建结合视觉信息的judge-corrector流水线，使用多模态语言模型分类并修正翻译错误；随后对IndicTrans2模型利用LoRA方法进行微调。

Result: 该自动纠错流水线处理了近2.9万条训练样本，平均纠正了17.1%的字幕，微调后BLEU分数在各语言对的评测及挑战集上均有提升。

Conclusion: 通过自动错误检测与纠正结合参数高效微调，显著提高了英译印地语、孟加拉语、马拉雅拉姆语及奥里亚语的翻译质量。

Abstract: In this paper, we describe our system under the team name BLEU Monday for the English-to-Indic Multimodal Translation Task at WAT 2025. We participate in the text-only translation tasks for English-Hindi, English-Bengali, English-Malayalam, and English-Odia language pairs. We present a two-stage approach that addresses quality issues in the training data through automated error detection and correction, followed by parameter-efficient model fine-tuning.
  Our methodology introduces a vision-augmented judge-corrector pipeline that leverages multimodal language models to systematically identify and correct translation errors in the training data. The judge component classifies translations into three categories: correct, visually ambiguous (requiring image context), or mistranslated (poor translation quality). Identified errors are routed to specialized correctors: GPT-4o-mini regenerates captions requiring visual disambiguation, while IndicTrans2 retranslates cases with pure translation quality issues. This automated pipeline processes 28,928 training examples across four languages, correcting an average of 17.1% of captions per language.
  We then apply Low-Rank Adaptation (LoRA) to fine-tune the IndicTrans2 en-indic 200M distilled model on both original and corrected datasets. Training on corrected data yields consistent improvements, with BLEU score gains of +1.30 for English-Bengali on the evaluation set (42.00 -> 43.30) and +0.70 on the challenge set (44.90 -> 45.60), +0.60 for English-Odia on the evaluation set (41.00 -> 41.60), and +0.10 for English-Hindi on the challenge set (53.90 -> 54.00).

</details>


### [72] [Multilingual Lexical Feature Analysis of Spoken Language for Predicting Major Depression Symptom Severity](https://arxiv.org/abs/2511.07011)
*Anastasiia Tokareva,Judith Dineley,Zoe Firth,Pauline Conde,Faith Matcham,Sara Siddi,Femke Lamers,Ewan Carr,Carolin Oetzmann,Daniel Leightley,Yuezhou Zhang,Amos A. Folarin,Josep Maria Haro,Brenda W. J. H. Penninx,Raquel Bailon,Srinivasan Vairavan,Til Wykes,Richard J. B. Dobson,Vaibhav A. Narayan,Matthew Hotopf,Nicholas Cummins,The RADAR-CNS Consortium*

Main category: cs.CL

TL;DR: 本研究分析了RADAR-MDD项目中多语种的长期语音数据与抑郁症状评分，探讨了口语中的词汇特征与重度抑郁症状严重程度的关联，发现英语数据中有7个词汇特征相关，其他语言效果不明显，且机器学习模型预测效果接近随机。


<details>
  <summary>Details</summary>
Motivation: 利用移动设备捕获的口语数据为重度抑郁症的症状评估和复发检测提供更客观、频繁的手段，目前研究主要依赖非临床书面语言和复杂不可解释的机器学习方法，急需探索临床语音数据中可解释的语言特征。

Method: 通过线性混合效应模型分析UK、荷兰、西班牙586名参与者的5,836条语音录音和PHQ-8症状评分，识别可解释的词汇特征，并结合高维向量嵌入测试四种回归机器学习模型的预测性能。

Result: 英语数据中发现7个词汇特征（如词汇多样性、绝对主义语言）与抑郁症状相关；荷兰语中发现句子词数和正面词频率相关；西班牙语无显著关联。所有语言的机器学习预测表现均接近随机水平。

Conclusion: 当前语言特征在抑郁症临床研究与实践中的价值尚需在更大样本和多语言环境中通过改进数据采集协议和考虑个体间变异的机器学习模型进行深入研究。

Abstract: Background: Captured between clinical appointments using mobile devices, spoken language has potential for objective, more regular assessment of symptom severity and earlier detection of relapse in major depressive disorder. However, research to date has largely been in non-clinical cross-sectional samples of written language using complex machine learning (ML) approaches with limited interpretability.
  Methods: We describe an initial exploratory analysis of longitudinal speech data and PHQ-8 assessments from 5,836 recordings of 586 participants in the UK, Netherlands, and Spain, collected in the RADAR-MDD study. We sought to identify interpretable lexical features associated with MDD symptom severity with linear mixed-effects modelling. Interpretable features and high-dimensional vector embeddings were also used to test the prediction performance of four regressor ML models.
  Results: In English data, MDD symptom severity was associated with 7 features including lexical diversity measures and absolutist language. In Dutch, associations were observed with words per sentence and positive word frequency; no associations were observed in recordings collected in Spain. The predictive power of lexical features and vector embeddings was near chance level across all languages.
  Limitations: Smaller samples in non-English speech and methodological choices, such as the elicitation prompt, may have also limited the effect sizes observable. A lack of NLP tools in languages other than English restricted our feature choice.
  Conclusion: To understand the value of lexical markers in clinical research and practice, further research is needed in larger samples across several languages using improved protocols, and ML models that account for within- and between-individual variations in language.

</details>


### [73] [Llama-Embed-Nemotron-8B: A Universal Text Embedding Model for Multilingual and Cross-Lingual Tasks](https://arxiv.org/abs/2511.07025)
*Yauhen Babakhin,Radek Osmulski,Ronay Ak,Gabriel Moreira,Mengyao Xu,Benedikt Schifferer,Bo Liu,Even Oldridge*

Main category: cs.CL

TL;DR: 本文介绍了llama-embed-nemotron-8b，一种开放权重的文本嵌入模型，在多语言大规模文本嵌入基准MMTEB上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型的训练数据或方法通常未公开，作者旨在开发完全开源、透明的模型以促进研究和应用。

Method: 利用公开数据和合成数据混合训练，进行对比损失实现、合成数据生成策略及模型合并的细致消融研究，并支持用户自定义指令增强性能。

Result: 模型在检索、分类及语义文本相似度等任务上表现优异，尤其在低资源语言和跨语言环境中表现出色。

Conclusion: llama-embed-nemotron-8b凭借其开放性、卓越性能和灵活性，有望成为通用文本嵌入解决方案。

Abstract: We introduce llama-embed-nemotron-8b, an open-weights text embedding model that achieves state-of-the-art performance on the Multilingual Massive Text Embedding Benchmark (MMTEB) leaderboard as of October 21, 2025. While recent models show strong performance, their training data or methodologies are often not fully disclosed. We aim to address this by developing a fully open-source model, publicly releasing its weights and detailed ablation studies, and planning to share the curated training datasets. Our model demonstrates superior performance across all major embedding tasks -- including retrieval, classification and semantic textual similarity (STS) -- and excels in challenging multilingual scenarios, such as low-resource languages and cross-lingual setups. This state-of-the-art performance is driven by a novel data mix of 16.1 million query-document pairs, split between 7.7 million samples from public datasets and 8.4 million synthetically generated examples from various open-weight LLMs. One of our key contributions is a detailed ablation study analyzing core design choices, including a comparison of contrastive loss implementations, an evaluation of synthetic data generation (SDG) strategies, and the impact of model merging. The llama-embed-nemotron-8b is an instruction-aware model, supporting user-defined instructions to enhance performance for specific use-cases. This combination of top-tier performance, broad applicability, and user-driven flexibility enables it to serve as a universal text embedding solution.

</details>


### [74] [Evaluating LLMs for Anxiety, Depression, and Stress Detection Evaluating Large Language Models for Anxiety, Depression, and Stress Detection: Insights into Prompting Strategies and Synthetic Data](https://arxiv.org/abs/2511.07044)
*Mihael Arcan,David-Paul Niland*

Main category: cs.CL

TL;DR: 本研究比较了大型语言模型（如Llama和GPT）与传统机器学习及基于变换器的模型（如BERT、XLNet和Distil-RoBERTa）在精神健康检测中的表现，利用DAIC-WOZ临床访谈数据集，结合合成数据生成方法缓解类别不平衡，提升模型效果。


<details>
  <summary>Details</summary>
Motivation: 精神健康障碍影响全球超过五分之一的成年人，文本中症状表达细微且多样，导致自动检测困难，迫切需要有效方法提升精神健康状态的文本检测准确率。

Method: 基于DAIC-WOZ数据集，微调多种模型（包括大型语言模型和变换器架构）以分类焦虑、抑郁和压力，同时采用合成数据生成缓解类别不平衡，评估多种模型性能并对比分析。

Result: Distil-RoBERTa在焦虑检测（GAD-2）中取得最高F1值0.883；XLNet在抑郁检测（PHQ任务）表现最佳，F1最高达0.891；压力检测采用零样本合成方法达成F1 0.884和ROC AUC 0.886，表现优异。

Conclusion: 基于变换器的模型在精神健康检测中表现出强大能力，合成数据有助于提升召回率和泛化能力，但需谨慎调节以避免精度下降。结合先进语言模型与数据增强技术为文本自动精神健康评估提供了有力支持。

Abstract: Mental health disorders affect over one-fifth of adults globally, yet detecting such conditions from text remains challenging due to the subtle and varied nature of symptom expression. This study evaluates multiple approaches for mental health detection, comparing Large Language Models (LLMs) such as Llama and GPT with classical machine learning and transformer-based architectures including BERT, XLNet, and Distil-RoBERTa. Using the DAIC-WOZ dataset of clinical interviews, we fine-tuned models for anxiety, depression, and stress classification and applied synthetic data generation to mitigate class imbalance. Results show that Distil-RoBERTa achieved the highest F1 score (0.883) for GAD-2, while XLNet outperformed others on PHQ tasks (F1 up to 0.891). For stress detection, a zero-shot synthetic approach (SD+Zero-Shot-Basic) reached an F1 of 0.884 and ROC AUC of 0.886. Findings demonstrate the effectiveness of transformer-based models and highlight the value of synthetic data in improving recall and generalization. However, careful calibration is required to prevent precision loss. Overall, this work emphasizes the potential of combining advanced language models and data augmentation to enhance automated mental health assessment from text.

</details>


### [75] [When Sufficient is not Enough: Utilizing the Rashomon Effect for Complete Evidence Extraction](https://arxiv.org/abs/2511.07055)
*Katharina Beckh,Stefan Rüping*

Main category: cs.CL

TL;DR: 本文研究了特征归因方法在医疗数据上的完整证据识别，发现单一模型只能恢复部分证据，集成多个模型能显著提升召回率。


<details>
  <summary>Details</summary>
Motivation: 现有的特征归因方法通常只提供最小充分证据，但在合规和归档应用中，需要识别全部贡献特征，即完整证据。

Method: 在包含人工标注完整证据的医疗数据集上进行案例研究，通过单模型与集成模型比较证据召回率，并分析训练、动态集成与阈值的影响。

Result: 单个最佳模型证据召回率约为0.60，集成模型提升至约0.86，显著改善了证据的召回效果。

Conclusion: 聚合多个模型的证据有助于提高完整证据的识别效果，对于合规性和归档应用具有重要意义，同时需权衡召回与精确性的关系。

Abstract: Feature attribution methods typically provide minimal sufficient evidence justifying a model decision. However, in many applications this is inadequate. For compliance and cataloging, the full set of contributing features must be identified - complete evidence. We perform a case study on a medical dataset which contains human-annotated complete evidence. We show that individual models typically recover only subsets of complete evidence and that aggregating evidence from several models improves evidence recall from $\sim$0.60 (single best model) to $\sim$0.86 (ensemble). We analyze the recall-precision trade-off, the role of training with evidence, dynamic ensembles with certainty thresholds, and discuss implications.

</details>


### [76] [Aligning Attention with Human Rationales for Self-Explaining Hate Speech Detection](https://arxiv.org/abs/2511.07065)
*Brage Eilertsen,Røskva Bjørgfinsdóttir,Francielle Vargas,Ali Ramezani-Kebrya*

Main category: cs.CL

TL;DR: 该论文提出了一种名为监督理性注意力（SRA）的框架，通过将模型注意力与人工注释的理由显式对齐，提升仇恨言论检测模型的可解释性和公平性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的黑箱性质限制了仇恨言论检测系统的伦理部署，亟需提升模型的可解释性和公平性。

Method: 在基于Transformer的分类器中引入监督注意力机制，结合分类损失和注意力权重与人工理由对齐的损失共同优化。

Result: 在英文和葡萄牙语的仇恨言论数据集上，SRA实现了2.4倍的解释性提升，生成了更忠实且与人类理由对齐的词元级解释，在公平性指标上表现竞争力，尤其在检测针对身份群体的有害言论上表现第二。

Conclusion: 将人类理由整合进注意力机制，有助于提升模型解释性和忠实度，同时不牺牲公平性。

Abstract: The opaque nature of deep learning models presents significant challenges for the ethical deployment of hate speech detection systems. To address this limitation, we introduce Supervised Rational Attention (SRA), a framework that explicitly aligns model attention with human rationales, improving both interpretability and fairness in hate speech classification. SRA integrates a supervised attention mechanism into transformer-based classifiers, optimizing a joint objective that combines standard classification loss with an alignment loss term that minimizes the discrepancy between attention weights and human-annotated rationales. We evaluated SRA on hate speech benchmarks in English (HateXplain) and Portuguese (HateBRXplain) with rationale annotations. Empirically, SRA achieves 2.4x better explainability compared to current baselines, and produces token-level explanations that are more faithful and human-aligned. In terms of fairness, SRA achieves competitive fairness across all measures, with second-best performance in detecting toxic posts targeting identity groups, while maintaining comparable results on other metrics. These findings demonstrate that incorporating human rationales into attention mechanisms can enhance interpretability and faithfulness without compromising fairness.

</details>


### [77] [Importance-Aware Data Selection for Efficient LLM Instruction Tuning](https://arxiv.org/abs/2511.07074)
*Tingyu Jiang,Shen Li,Yiyao Song,Lan Zhang,Hualei Zhu,Yuan Zhao,Xiaohang Xu,Kenjiro Taura,Hao Henry Wang*

Main category: cs.CL

TL;DR: 本文提出了一种名为模型指令弱点值（MIWV）的新指标，用于量化指令数据在提升大型语言模型性能中的重要性，并通过只选择Top 1%的数据实现了优于全量数据训练的效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究侧重于计算数据质量评分以评估指令数据，而缺少针对特定大型语言模型进行高质量数据选择以最大化指令调优性能的研究。

Method: 基于模型使用上下文学习时的响应差异，定义并计算MIWV作为衡量指令数据重要性的指标，用于挑选最有助于提升指令调优性能的数据。

Result: 实验结果表明，仅使用按照MIWV选出的前1%指令数据训练，性能超过使用全部数据的训练效果，验证了MIWV的有效性。

Conclusion: MIWV指标不仅实现了高效的数据选择，还为指令调优提供了一种更具针对性和实用性的评估标准，优于传统的数据质量评分方法。

Abstract: Instruction tuning plays a critical role in enhancing the performance and efficiency of Large Language Models (LLMs). Its success depends not only on the quality of the instruction data but also on the inherent capabilities of the LLM itself. Some studies suggest that even a small amount of high-quality data can achieve instruction fine-tuning results that are on par with, or even exceed, those from using a full-scale dataset. However, rather than focusing solely on calculating data quality scores to evaluate instruction data, there is a growing need to select high-quality data that maximally enhances the performance of instruction tuning for a given LLM. In this paper, we propose the Model Instruction Weakness Value (MIWV) as a novel metric to quantify the importance of instruction data in enhancing model's capabilities. The MIWV metric is derived from the discrepancies in the model's responses when using In-Context Learning (ICL), helping identify the most beneficial data for enhancing instruction tuning performance. Our experimental results demonstrate that selecting only the top 1\% of data based on MIWV can outperform training on the full dataset. Furthermore, this approach extends beyond existing research that focuses on data quality scoring for data selection, offering strong empirical evidence supporting the effectiveness of our proposed method.

</details>


### [78] [EmoBang: Detecting Emotion From Bengali Texts](https://arxiv.org/abs/2511.07077)
*Abdullah Al Maruf,Aditi Golder,Zakaria Masud Jiyad,Abdullah Al Numan,Tarannum Shaila Zaman*

Main category: cs.CL

TL;DR: 本文针对孟加拉语情感检测任务，提出了一个包含八类情绪的新数据集，并设计了两种模型，分别为混合卷积循环神经网络模型和AdaBoost-BERT集成模型，实现了超过92%的准确率，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第四大语言，情感检测研究较少，缺乏大规模标准化数据集和高效模型。

Method: 构建孟加拉语情感数据集，设计混合CRNN模型（EmoBangHybrid）和AdaBoost-BERT集成模型（EmoBangEnsemble），同时比较六种基线模型、五种特征工程方法及大语言模型的零样本和少量样本表现。

Result: EmoBangHybrid和EmoBangEnsemble分别达到92.86%和93.69%的准确率，效果优于传统机器学习方法，建立了该任务的强基线。

Conclusion: 首次提供了孟加拉语情感检测的综合基准，展现了深度学习模型在低资源语言情感识别中的潜力，为未来研究奠定基础。

Abstract: Emotion detection from text seeks to identify an individual's emotional or mental state - positive, negative, or neutral - based on linguistic cues. While significant progress has been made for English and other high-resource languages, Bengali remains underexplored despite being the world's fourth most spoken language. The lack of large, standardized datasets classifies Bengali as a low-resource language for emotion detection. Existing studies mainly employ classical machine learning models with traditional feature engineering, yielding limited performance. In this paper, we introduce a new Bengali emotion dataset annotated across eight emotion categories and propose two models for automatic emotion detection: (i) a hybrid Convolutional Recurrent Neural Network (CRNN) model (EmoBangHybrid) and (ii) an AdaBoost-Bidirectional Encoder Representations from Transformers (BERT) ensemble model (EmoBangEnsemble). Additionally, we evaluate six baseline models with five feature engineering techniques and assess zero-shot and few-shot large language models (LLMs) on the dataset. To the best of our knowledge, this is the first comprehensive benchmark for Bengali emotion detection. Experimental results show that EmoBangH and EmoBangE achieve accuracies of 92.86% and 93.69%, respectively, outperforming existing methods and establishing strong baselines for future research.

</details>


### [79] [Wasm: A Pipeline for Constructing Structured Arabic Interleaved Multimodal Corpora](https://arxiv.org/abs/2511.07080)
*Khalil Hennara,Ahmad Bastati,Muhammad Hreden,Mohamed Motasim Hamed,Zeina Aldallal,Sara Chrouf,Safwan AlModhayan*

Main category: cs.CL

TL;DR: 本论文提出了一个针对阿拉伯语的多模态数据处理管道Wasm，利用Common Crawl数据集生成了一个保留文档结构的阿拉伯语多模态数据集，并公开发布以促进后续研究。


<details>
  <summary>Details</summary>
Motivation: 现有阿拉伯语多模态数据集缺乏保护文档结构的高质量语料，限制了阿拉伯语大型多模态模型的发展。

Method: 设计并实现了Wasm处理管道，在处理Common Crawl数据时保留网页的结构信息，支持纯文本和多模态预训练，且对比分析了与主流数据处理管道的异同。

Result: 生成了一个结构完整、适用于阿拉伯语多模态训练的新数据集，并公开数据及管道工具。

Conclusion: 所提出的Wasm管道有效解决了阿拉伯语多模态数据集结构缺失的问题，为相关模型预训练提供了重要数据支持，促进该领域的发展。

Abstract: The performance of large language models (LLMs) and large multimodal models (LMMs) depends heavily on the quality and scale of their pre-training datasets. Recent research shows that large multimodal models trained on natural documents where images and text are interleaved outperform those trained only on image-text pairs across a wide range of benchmarks, leveraging advanced pre- trained models to enforce semantic alignment, image-sequence consistency, and textual coherence. For Arabic, however, the lack of high-quality multimodal datasets that preserve document structure has limited progress. In this paper, we present our pipeline Wasm for processing the Common Crawl dataset to create a new Arabic multimodal dataset that uniquely provides markdown output. Unlike existing Arabic corpora that focus solely on text extraction, our approach preserves the structural integrity of web content while maintaining flexibility for both text-only and multimodal pre-training scenarios. We provide a comprehensive comparative analysis of our data processing pipeline against those used for major existing datasets, highlighting the convergences in filtering strategies and justifying our specific design choices. To support future research, we publicly release a representative dataset dump along with the multimodal processing pipeline for Arabic.

</details>


### [80] [More Agents Helps but Adversarial Robustness Gap Persists](https://arxiv.org/abs/2511.07112)
*Khashayar Alavi,Zhastay Yeltay,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 本文研究了多个大型语言模型（LLM）协作在面对数学题目中的对抗性扰动时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨联合多个LLM代理是否不仅能提升数学问答准确率，还能增强对抗输入的鲁棒性。

Method: 采用统一的采样投票框架（Agent Forest），使用六个开源模型和四个基准任务，在不同代理数量（1至25个）及多种对抗性扰动（标点噪声和人类拼写错误）下进行评测。

Result: 实验显示噪声类型影响性能，人类拼写错误导致最大准确率下降和最高攻击成功率。代理数量增加能提升准确率，主要提升发生在1至5个代理，超过10个后收益递减，但鲁棒性差距依然存在。

Conclusion: 虽然多代理合作可提升数学问答准确度，但无法显著弥补对抗扰动导致的鲁棒性缺陷。

Abstract: When LLM agents work together, they seem to be more powerful than a single LLM in mathematical question answering. However, are they also more robust to adversarial inputs? We investigate this question using adversarially perturbed math questions. These perturbations include punctuation noise with three intensities (10, 30, and 50 percent), plus real-world and human-like typos (WikiTypo, R2ATA). Using a unified sampling-and-voting framework (Agent Forest), we evaluate six open-source models (Qwen3-4B/14B, Llama3.1-8B, Mistral-7B, Gemma3-4B/12B) across four benchmarks (GSM8K, MATH, MMLU-Math, MultiArith), with various numbers of agents n from one to 25 (1, 2, 5, 10, 15, 20, 25). Our findings show that (1) Noise type matters: punctuation noise harm scales with its severity, and the human typos remain the dominant bottleneck, yielding the largest gaps to Clean accuracy and the highest ASR even with a large number of agents. And (2) Collaboration reliably improves accuracy as the number of agents, n, increases, with the largest gains from one to five agents and diminishing returns beyond 10 agents. However, the adversarial robustness gap persists regardless of the agent count.

</details>


### [81] [Think Consistently, Reason Efficiently: Energy-Based Calibration for Implicit Chain-of-Thought](https://arxiv.org/abs/2511.07124)
*Zhikang Chen,Sen Cui,Deheng Ye,Yu Zhang,Yatao Bian,Tingting Zhu*

Main category: cs.CL

TL;DR: 本文提出了一种基于能量模型的链式思维校准框架（EBM-CoT），以提升大型语言模型的多步推理一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的链式思维方法依赖离散的token级推理，易出现错误传播且表达有限，而隐式连续推理虽有改进但缺乏步骤间一致性，导致推理路径发散、不稳定。

Method: 通过能量模型，动态调整潜在推理轨迹，使其趋向低能量、高一致性的嵌入空间区域，从而校准推理过程，且无需修改基础语言模型。

Result: 在数学、常识和符号推理基准上，EBM-CoT显著提升了推理步骤的一致性和效率，表现出更准确稳定的多步推理能力。

Conclusion: EBM-CoT有效弥补了隐式连续推理在步骤一致性上的不足，提升了大型语言模型多步推理的性能，为复杂推理任务提供了新思路。

Abstract: Large Language Models (LLMs) have demonstrated strong reasoning capabilities through \emph{Chain-of-Thought} (CoT) prompting, which enables step-by-step intermediate reasoning. However, explicit CoT methods rely on discrete token-level reasoning processes that are prone to error propagation and limited by vocabulary expressiveness, often resulting in rigid and inconsistent reasoning trajectories. Recent research has explored implicit or continuous reasoning in latent spaces, allowing models to perform internal reasoning before generating explicit output. Although such approaches alleviate some limitations of discrete CoT, they generally lack explicit mechanisms to enforce consistency among reasoning steps, leading to divergent reasoning paths and unstable outcomes. To address this issue, we propose EBM-CoT, an Energy-Based Chain-of-Thought Calibration framework that refines latent thought representations through an energy-based model (EBM). Our method dynamically adjusts latent reasoning trajectories toward lower-energy, high-consistency regions in the embedding space, improving both reasoning accuracy and consistency without modifying the base language model. Extensive experiments across mathematical, commonsense, and symbolic reasoning benchmarks demonstrate that the proposed framework significantly enhances the consistency and efficiency of multi-step reasoning in LLMs.

</details>


### [82] [LoRA on the Go: Instance-level Dynamic LoRA Selection and Merging](https://arxiv.org/abs/2511.07129)
*Seungeon Lee,Soumi Das,Manish Gupta,Krishna P. Gummadi*

Main category: cs.CL

TL;DR: 提出了LoGo框架，通过在推理时动态选择和合并LoRA适配器，提升多任务性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA微调只针对单一任务，限制了其在多样化和不可预测的实际应用中的适用性，现有融合多LoRA的方法多需额外标注数据和训练，成本高。

Method: LoGo框架在推理阶段通过单次前向传播提取信号，动态选择最相关的适配器并即时确定其贡献权重，实现训练-free的适配器合并。

Result: 在5个NLP基准测试、27个数据集及3个模型家族上，LoGo在部分任务上超过传统训练基线最高3.6%，在其他任务表现具有竞争力，同时保持推理吞吐量。

Conclusion: LoGo有效解决LoRA多任务扩展问题，实现了高效且实用的训练-free适配器动态合并策略。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a parameter-efficient approach for fine-tuning large language models.However, conventional LoRA adapters are typically trained for a single task, limiting their applicability in real-world settings where inputs may span diverse and unpredictable domains. At inference time, existing approaches combine multiple LoRAs for improving performance on diverse tasks, while usually requiring labeled data or additional task-specific training, which is expensive at scale. In this work, we introduce LoRA on the Go (LoGo), a training-free framework that dynamically selects and merges adapters at the instance level without any additional requirements. LoGo leverages signals extracted from a single forward pass through LoRA adapters, to identify the most relevant adapters and determine their contributions on-the-fly. Across 5 NLP benchmarks, 27 datasets, and 3 model families, LoGo outperforms training-based baselines on some tasks upto a margin of 3.6% while remaining competitive on other tasks and maintaining inference throughput, highlighting its effectiveness and practicality.

</details>


### [83] [TCM-Eval: An Expert-Level Dynamic and Extensible Benchmark for Traditional Chinese Medicine](https://arxiv.org/abs/2511.07148)
*Zihao Cheng,Yuheng Lu,Huaiqian Ye,Zeming Liu,Minqi Wang,Jingjing Liu,Zihan Li,Wei Fan,Yuanfang Guo,Ruiji Fu,Shifeng She,Gang Wang,Yunhong Wang*

Main category: cs.CL

TL;DR: 本文针对中医领域缺乏标准化评测和高质量训练数据的问题，提出了首个动态可扩展的中医评测基准TCM-Eval，并构建了大规模训练语料，设计自迭代思维链增强方法SI-CoTE，训练出性能优异的中医专用大语言模型ZhiMingTang，超过了人类从业者合格线，推动中医人工智能发展。


<details>
  <summary>Details</summary>
Motivation: 中医领域缺乏标准化的评测基准和高质量的训练数据，限制了大语言模型在中医中的应用。

Method: 构建TCM-Eval基准，采集国家医学资格考试数据并由专家验证；构建大规模训练语料；提出SI-CoTE方法通过自迭代思维链增强数据与模型；训练中医专用大语言模型ZhiMingTang。

Result: ZhiMingTang模型表现优异，显著超过人类从业者的合格分数线。

Conclusion: 本文首次提出动态可扩展的中医评测基准和高质量训练方法，开发了领先的中医领域语言模型，为中医人工智能研究提供了重要资源和平台。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modern medicine, yet their application in Traditional Chinese Medicine (TCM) remains severely limited by the absence of standardized benchmarks and the scarcity of high-quality training data. To address these challenges, we introduce TCM-Eval, the first dynamic and extensible benchmark for TCM, meticulously curated from national medical licensing examinations and validated by TCM experts. Furthermore, we construct a large-scale training corpus and propose Self-Iterative Chain-of-Thought Enhancement (SI-CoTE) to autonomously enrich question-answer pairs with validated reasoning chains through rejection sampling, establishing a virtuous cycle of data and model co-evolution. Using this enriched training data, we develop ZhiMingTang (ZMT), a state-of-the-art LLM specifically designed for TCM, which significantly exceeds the passing threshold for human practitioners. To encourage future research and development, we release a public leaderboard, fostering community engagement and continuous improvement.

</details>


### [84] [Categorical Emotions or Appraisals - Which Emotion Model Explains Argument Convincingness Better?](https://arxiv.org/abs/2511.07162)
*Lynn Greschner,Meike Bauer,Sabine Weber,Roman Klinger*

Main category: cs.CL

TL;DR: 本文探讨了情感在论证说服力中的主观性，基于受众的认知评价使用评估理论进行情感分析，实验证明评估理论优于单纯的情绪分类，更能提升说服力预测准确性。


<details>
  <summary>Details</summary>
Motivation: 既有研究关注情绪强度和类别，但忽视了情绪的主观性及其依赖于受众的目标和认知背景，评估理论有潜力桥接认知评价与情绪，尚未被用于论证说服力评估。

Method: 利用ContArgA语料库的注释数据，采用零-shot提示实验，比较基于情绪类别和评估理论的特征在说服力主观标签预测中的表现。

Result: 基于情绪类别的信息能提升说服力预测效果，但基于评估理论的特征提升更显著。

Conclusion: 首次系统比较了不同情绪模型在说服力预测中的表现，证明评估理论更适用于此任务，为理论研究及实际应用提供了新思路。

Abstract: The convincingness of an argument does not only depend on its structure (logos), the person who makes the argument (ethos), but also on the emotion that it causes in the recipient (pathos). While the overall intensity and categorical values of emotions in arguments have received considerable attention in the research community, we argue that the emotion an argument evokes in a recipient is subjective. It depends on the recipient's goals, standards, prior knowledge, and stance. Appraisal theories lend themselves as a link between the subjective cognitive assessment of events and emotions. They have been used in event-centric emotion analysis, but their suitability for assessing argument convincingness remains unexplored. In this paper, we evaluate whether appraisal theories are suitable for emotion analysis in arguments by considering subjective cognitive evaluations of the importance and impact of an argument on its receiver. Based on the annotations in the recently published ContArgA corpus, we perform zero-shot prompting experiments to evaluate the importance of gold-annotated and predicted emotions and appraisals for the assessment of the subjective convincingness labels. We find that, while categorical emotion information does improve convincingness prediction, the improvement is more pronounced with appraisals. This work presents the first systematic comparison between emotion models for convincingness prediction, demonstrating the advantage of appraisals, providing insights for theoretical and practical applications in computational argumentation.

</details>


### [85] [AdaRec: Adaptive Recommendation with LLMs via Narrative Profiling and Dual-Channel Reasoning](https://arxiv.org/abs/2511.07166)
*Meiyun Wang,Charin Polpanumas*

Main category: cs.CL

TL;DR: AdaRec是一个利用大语言模型进行自适应个性化推荐的少样本上下文学习框架，通过叙事式画像和双通道架构实现快速跨任务适应，实验证明在电商推荐任务中性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的方法依赖人工特征工程，难以实现快速跨任务的个性化推荐。

Method: AdaRec通过叙事式画像将用户行为转化为自然语言，结合行为对齐和因果归因的双通道架构，实现无监督快速适应。

Result: 在少样本场景下，AdaRec性能比机器学习和现有LLM基线模型提升8%；零样本场景提升19%；轻量微调效果接近全微调模型。

Conclusion: AdaRec有效提升长尾个性化推荐能力，实现了少样本快速适应和高效泛化，显著优于传统及现有大语言模型方法。

Abstract: We propose AdaRec, a few-shot in-context learning framework that leverages large language models for an adaptive personalized recommendation. AdaRec introduces narrative profiling, transforming user-item interactions into natural language representations to enable unified task handling and enhance human readability. Centered on a bivariate reasoning paradigm, AdaRec employs a dual-channel architecture that integrates horizontal behavioral alignment, discovering peer-driven patterns, with vertical causal attribution, highlighting decisive factors behind user preferences. Unlike existing LLM-based approaches, AdaRec eliminates manual feature engineering through semantic representations and supports rapid cross-task adaptation with minimal supervision. Experiments on real ecommerce datasets demonstrate that AdaRec outperforms both machine learning models and LLM-based baselines by up to eight percent in few-shot settings. In zero-shot scenarios, it achieves up to a nineteen percent improvement over expert-crafted profiling, showing effectiveness for long-tail personalization with minimal interaction data. Furthermore, lightweight fine-tuning on synthetic data generated by AdaRec matches the performance of fully fine-tuned models, highlighting its efficiency and generalization across diverse tasks.

</details>


### [86] [EMODIS: A Benchmark for Context-Dependent Emoji Disambiguation in Large Language Models](https://arxiv.org/abs/2511.07193)
*Jiacheng Huang,Ning Yu,Xiaoyin Yi*

Main category: cs.CL

TL;DR: 提出EMODIS基准测试，评估大语言模型在含有歧义表情符号的上下文中进行语义歧义消解的能力，发现模型在细微上下文线索下表现不足，存在偏向主导解释的倾向。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在真实交流中经常遇到含糊不清的表达，但其对依赖上下文的语义歧义消解能力尚未充分研究。

Method: 设计EMODIS测试集，包括含有歧义表情的句子、两个对比性上下文和需要上下文推理的问题，评估开源和API大语言模型的表现。

Result: 最强模型在仅含细微上下文提示时，常无法正确区分不同含义，存在对主导解释的系统性偏见和对语用对比的敏感度不足。

Conclusion: EMODIS为上下文歧义消解能力提供了严格测试平台，揭示了大语言模型在语义推理方面与人类的差距。

Abstract: Large language models (LLMs) are increasingly deployed in real-world communication settings, yet their ability to resolve context-dependent ambiguity remains underexplored. In this work, we present EMODIS, a new benchmark for evaluating LLMs' capacity to interpret ambiguous emoji expressions under minimal but contrastive textual contexts. Each instance in EMODIS comprises an ambiguous sentence containing an emoji, two distinct disambiguating contexts that lead to divergent interpretations, and a specific question that requires contextual reasoning. We evaluate both open-source and API-based LLMs, and find that even the strongest models frequently fail to distinguish meanings when only subtle contextual cues are present. Further analysis reveals systematic biases toward dominant interpretations and limited sensitivity to pragmatic contrast. EMODIS provides a rigorous testbed for assessing contextual disambiguation, and highlights the gap in semantic reasoning between humans and LLMs.

</details>


### [87] [Discourse Graph Guided Document Translation with Large Language Models](https://arxiv.org/abs/2511.07230)
*Viet-Thanh Pham,Minghan Wang,Hao-Han Liao,Thuy-Trang Vu*

Main category: cs.CL

TL;DR: 本文提出了TransGraph框架，通过构建结构化话语图显式建模文档内部关系，实现了文档级机器翻译的有效适应，提升了翻译质量和术语一致性，并降低了计算消耗。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在长文本翻译中难以捕捉长距离依赖和保持话语连贯性，且多智能体翻译系统计算资源消耗大，对记忆策略敏感，亟需更高效的解决方案。

Method: TransGraph构建基于话语结构的图模型，显式表示文本分块间关系，通过选择性条件化相关图邻域信息替代传统的顺序或全上下文依赖。

Result: TransGraph在覆盖六种语言、三种文档级机器翻译基准的实验中，显著超过强基线方法，提升了翻译质量和术语一致性，同时降低了令牌开销。

Conclusion: 该方法有效解决了长文本文档翻译中的连贯性和依赖捕获难题，保证了翻译质量的提升和计算效率的优化，具有良好的应用前景。

Abstract: Adapting large language models to full document translation remains challenging due to the difficulty of capturing long-range dependencies and preserving discourse coherence throughout extended texts. While recent agentic machine translation systems mitigate context window constraints through multi-agent orchestration and persistent memory, they require substantial computational resources and are sensitive to memory retrieval strategies. We introduce TransGraph, a discourse-guided framework that explicitly models inter-chunk relationships through structured discourse graphs and selectively conditions each translation segment on relevant graph neighbourhoods rather than relying on sequential or exhaustive context. Across three document-level MT benchmarks spanning six languages and diverse domains, TransGraph consistently surpasses strong baselines in translation quality and terminology consistency while incurring significantly lower token overhead.

</details>


### [88] [Who Is the Story About? Protagonist Entity Recognition in News](https://arxiv.org/abs/2511.07296)
*Jorge Gabín,M. Eduardo Ares,Javier Parapar*

Main category: cs.CL

TL;DR: 本文提出了主角实体识别（PER）任务，用以识别新闻报道中推动叙事发展的核心组织实体。通过与专家标注和大规模自动标注相结合，验证了大语言模型在该任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统命名实体识别（NER）对所有实体一视同仁，难以区分新闻中真正推动故事发展的关键组织，限制了后续对事件重要性和叙事焦点的理解。

Method: 提出PER任务，利用四位专家标注的金标准语料与大语言模型预测结果进行对比验证；采用最先进的LLM通过NER引导的提示语进行大规模自动标注；进一步评估在上下文减少且无候选引导下其他LLM的识别能力。

Result: 实验结果表明PER任务是可行且有意义的扩展，指导性的大语言模型能在大规模上接近人类对于叙事重要性的判断。

Conclusion: PER为叙事中心信息抽取引入了新的维度，证明了基于LLM的引导标注方法在关键实体识别上的有效性和可扩展性。

Abstract: News articles often reference numerous organizations, but traditional Named Entity Recognition (NER) treats all mentions equally, obscuring which entities genuinely drive the narrative. This limits downstream tasks that rely on understanding event salience, influence, or narrative focus. We introduce Protagonist Entity Recognition (PER), a task that identifies the organizations that anchor a news story and shape its main developments. To validate PER, we compare he predictions of Large Language Models (LLMs) against annotations from four expert annotators over a gold corpus, establishing both inter-annotator consistency and human-LLM agreement. Leveraging these findings, we use state-of-the-art LLMs to automatically label large-scale news collections through NER-guided prompting, generating scalable, high-quality supervision. We then evaluate whether other LLMs, given reduced context and without explicit candidate guidance, can still infer the correct protagonists. Our results demonstrate that PER is a feasible and meaningful extension to narrative-centered information extraction, and that guided LLMs can approximate human judgments of narrative importance at scale.

</details>


### [89] [Retriv at BLP-2025 Task 1: A Transformer Ensemble and Multi-Task Learning Approach for Bangla Hate Speech Identification](https://arxiv.org/abs/2511.07304)
*Sourav Saha,K M Nafi Asib,Mohammed Moshiul Hoque*

Main category: cs.CL

TL;DR: 本文针对孟加拉语仇恨言论识别，使用多模型集成和多任务学习方法，在三个子任务中分别取得了较好成绩，排名均进入前十。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语仇恨言论识别具有重要的社会影响，但由于语言资源匮乏，任务具有较大挑战。

Method: 在两个单任务子任务中采用BanglaBERT、MuRIL和IndicBERTv2模型的软投票集成；在多任务子任务中训练三个多任务变体并通过加权投票集成预测。

Result: 系统在三个子任务上分别实现了约72.7%的微F1分数，排名分别为第9、第10和第7名。

Conclusion: 通过多模型集成和加权多任务框架，提升了孟加拉语仇恨言论检测效果，为低资源语言仇恨言论识别提供了有益参考和资源。

Abstract: This paper addresses the problem of Bangla hate speech identification, a socially impactful yet linguistically challenging task. As part of the "Bangla Multi-task Hate Speech Identification" shared task at the BLP Workshop, IJCNLP-AACL 2025, our team "Retriv" participated in all three subtasks: (1A) hate type classification, (1B) target group identification, and (1C) joint detection of type, severity, and target. For subtasks 1A and 1B, we employed a soft-voting ensemble of transformer models (BanglaBERT, MuRIL, IndicBERTv2). For subtask 1C, we trained three multitask variants and aggregated their predictions through a weighted voting ensemble. Our systems achieved micro-f1 scores of 72.75% (1A) and 72.69% (1B), and a weighted micro-f1 score of 72.62% (1C). On the shared task leaderboard, these corresponded to 9th, 10th, and 7th positions, respectively. These results highlight the promise of transformer ensembles and weighted multitask frameworks for advancing Bangla hate speech detection in low-resource contexts. We made experimental scripts publicly available for the community.

</details>


### [90] [ACE-ICD: Acronym Expansion As Data Augmentation For Automated ICD Coding](https://arxiv.org/abs/2511.07311)
*Tuan-Dung Le,Shohreh Haddadan,Thanh Q. Thieu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大语言模型扩展医学缩略词的自动ICD编码新方法，结合一致性训练显著提升了编码准确率，达到了最新性能水平。


<details>
  <summary>Details</summary>
Motivation: 现有自动ICD编码方法多侧重于代码层次结构和同义词的理解，忽视了临床文本中广泛使用的医学缩略词，影响了编码推断的准确性。

Method: 利用大型语言模型扩展医学缩略词为全称，使模型能基于全称训练；并通过一致性训练约束原文与扩展文档预测结果的一致性，提高模型鲁棒性。

Result: 在MIMIC-III数据集上进行大量实验，方法在常见代码、罕见代码及全部代码分配任务上均实现了新的最先进性能。

Conclusion: 通过扩展医学缩略词和一致性训练，所提方法有效提升了自动ICD编码的准确度和鲁棒性，具有实际应用价值。

Abstract: Automatic ICD coding, the task of assigning disease and procedure codes to electronic medical records, is crucial for clinical documentation and billing. While existing methods primarily enhance model understanding of code hierarchies and synonyms, they often overlook the pervasive use of medical acronyms in clinical notes, a key factor in ICD code inference. To address this gap, we propose a novel effective data augmentation technique that leverages large language models to expand medical acronyms, allowing models to be trained on their full form representations. Moreover, we incorporate consistency training to regularize predictions by enforcing agreement between the original and augmented documents. Extensive experiments on the MIMIC-III dataset demonstrate that our approach, ACE-ICD establishes new state-of-the-art performance across multiple settings, including common codes, rare codes, and full-code assignments. Our code is publicly available.

</details>


### [91] [RLVE: Scaling Up Reinforcement Learning for Language Models with Adaptive Verifiable Environments](https://arxiv.org/abs/2511.07317)
*Zhiyuan Zeng,Hamish Ivison,Yiping Wang,Lifan Yuan,Shuyue Stella Li,Zhuorui Ye,Siting Li,Jacqueline He,Runlong Zhou,Tong Chen,Chenyang Zhao,Yulia Tsvetkov,Simon Shaolei Du,Natasha Jaques,Hao Peng,Pang Wei Koh,Hannaneh Hajishirzi*

Main category: cs.CL

TL;DR: 本文提出了RLVE方法，通过可验证环境动态调整问题难度，提升语言模型的强化学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中，固定难度的数据分布会导致学习信号消失，难以有效训练语言模型。

Method: 设计RLVE-Gym，包括400个可验证环境，环境难度根据模型能力动态调整，实现联合训练。

Result: 在六个推理基准测试中，RLVE在1.5B语言模型上提升了3.37%准确率，远超传统RL训练。

Conclusion: RLVE通过环境动态适应显著增强语言模型的推理能力，训练效率和效果均优于传统方法。

Abstract: We introduce Reinforcement Learning (RL) with Adaptive Verifiable Environments (RLVE), an approach using verifiable environments that procedurally generate problems and provide algorithmically verifiable rewards, to scale up RL for language models (LMs). RLVE enables each verifiable environment to dynamically adapt its problem difficulty distribution to the policy model's capabilities as training progresses. In contrast, static data distributions often lead to vanishing learning signals when problems are either too easy or too hard for the policy. To implement RLVE, we create RLVE-Gym, a large-scale suite of 400 verifiable environments carefully developed through manual environment engineering. Using RLVE-Gym, we show that environment scaling, i.e., expanding the collection of training environments, consistently improves generalizable reasoning capabilities. RLVE with joint training across all 400 environments in RLVE-Gym yields a 3.37% absolute average improvement across six reasoning benchmarks, starting from one of the strongest 1.5B reasoning LMs. By comparison, continuing this LM's original RL training yields only a 0.49% average absolute gain despite using over 3x more compute. We release our code publicly.

</details>


### [92] [When Bias Pretends to Be Truth: How Spurious Correlations Undermine Hallucination Detection in LLMs](https://arxiv.org/abs/2511.07318)
*Shaowen Wang,Yiqi Dong,Ruinian Chang,Tansheng Zhu,Yuebo Sun,Kaifeng Lyu,Jian Li*

Main category: cs.CL

TL;DR: 该论文探讨了大语言模型中的伪造现象，特别是由训练数据中的虚假相关性引起的伪造问题，指出现有检测方法难以识别此类伪造，强调需要新的检测策略。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型取得了显著进展，但仍存在伪造现象，尤其是由训练数据中显著但肤浅的虚假相关性驱动的伪造，且这些问题未得到充分关注。

Method: 通过系统控制的合成实验和对最新开源及专有模型（包括GPT-5）的实证评估，分析虚假相关性如何导致伪造现象并测试现有检测方法的效果，同时进行理论分析揭示统计偏见对检测方法的影响。

Result: 发现由虚假相关性驱动的伪造现象自信且稳定，不随模型扩展改善，且现有基于置信度和内部状态探测的方法对其无效，现有拒绝微调也无法根除该问题。

Conclusion: 强调当前大语言模型伪造检测方法存在根本不足，呼吁开发专门针对虚假相关性引发伪造的新检测策略以提升模型可靠性。

Abstract: Despite substantial advances, large language models (LLMs) continue to exhibit hallucinations, generating plausible yet incorrect responses. In this paper, we highlight a critical yet previously underexplored class of hallucinations driven by spurious correlations -- superficial but statistically prominent associations between features (e.g., surnames) and attributes (e.g., nationality) present in the training data. We demonstrate that these spurious correlations induce hallucinations that are confidently generated, immune to model scaling, evade current detection methods, and persist even after refusal fine-tuning. Through systematically controlled synthetic experiments and empirical evaluations on state-of-the-art open-source and proprietary LLMs (including GPT-5), we show that existing hallucination detection methods, such as confidence-based filtering and inner-state probing, fundamentally fail in the presence of spurious correlations. Our theoretical analysis further elucidates why these statistical biases intrinsically undermine confidence-based detection techniques. Our findings thus emphasize the urgent need for new approaches explicitly designed to address hallucinations caused by spurious correlations.

</details>


### [93] [FinRpt: Dataset, Evaluation System and LLM-based Multi-agent Framework for Equity Research Report Generation](https://arxiv.org/abs/2511.07322)
*Song Jin,Shuqi Li,Shukun Zhang,Rui Yan*

Main category: cs.CL

TL;DR: 本文首次提出股票研究报告自动生成任务，构建并开源了高质量数据集与评测基准FinRpt，设计多智能体生成框架FinRpt-Gen，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在金融领域任务上取得成功，但在股票研究报告自动生成方面尚未探索，缺乏数据和评测标准限制了该方向的发展。

Method: 构建包含7种金融数据类型的自动化数据集生成流水线，设计包含11项指标的评测体系，提出专门针对任务的多智能体FinRpt-Gen框架，并采用监督微调和强化学习训练模型。

Result: 实验结果验证了FinRpt数据集质量与评测指标的有效性，同时FinRpt-Gen框架表现出较强的任务完成能力。

Conclusion: FinRpt基准及FinRpt-Gen框架为股票研究报告自动生成任务提供了坚实基础，有望推动该领域技术创新和应用进展，相关代码和数据集均已开源。

Abstract: While LLMs have shown great success in financial tasks like stock prediction and question answering, their application in fully automating Equity Research Report generation remains uncharted territory. In this paper, we formulate the Equity Research Report (ERR) Generation task for the first time. To address the data scarcity and the evaluation metrics absence, we present an open-source evaluation benchmark for ERR generation - FinRpt. We frame a Dataset Construction Pipeline that integrates 7 financial data types and produces a high-quality ERR dataset automatically, which could be used for model training and evaluation. We also introduce a comprehensive evaluation system including 11 metrics to assess the generated ERRs. Moreover, we propose a multi-agent framework specifically tailored to address this task, named FinRpt-Gen, and train several LLM-based agents on the proposed datasets using Supervised Fine-Tuning and Reinforcement Learning. Experimental results indicate the data quality and metrics effectiveness of the benchmark FinRpt and the strong performance of FinRpt-Gen, showcasing their potential to drive innovation in the ERR generation field. All code and datasets are publicly available.

</details>


### [94] [Selecting Auxiliary Data via Neural Tangent Kernels for Low-Resource Domains](https://arxiv.org/abs/2511.07380)
*Pingjie Wang,Hongcheng Liu,Yusheng Liao,Ziqing Fan,Yaxin Du,Shuo Tang,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 本文提出利用神经切线核（NTK）选择通用领域辅助数据以提升低资源领域大语言模型性能的方法。


<details>
  <summary>Details</summary>
Motivation: 低资源领域中训练样本不足，直接应用传统数据选择方法困难，现有通用领域数据潜力未被充分利用。

Method: 提出NTK-Selector框架，通过神经切线核理论和雅可比矩阵自由近似技术，有效选取辅助数据，解决NTK在大模型上的计算和理论挑战。

Result: 在医疗、金融、法律、心理四个低资源领域实验证明，使用NTK-Selector选取的辅助数据能显著提升模型表现，性能提升幅度高达10倍以上。

Conclusion: NTK-Selector为低资源领域提升大语言模型性能提供了有效路径，利用有限的领域内数据结合精选的辅助数据，可实现显著性能提升。

Abstract: Large language models (LLMs) have achieved remarkable success across widespread tasks, yet their application in low-resource domains remains a significant challenge due to data scarcity and the high risk of overfitting. While in-domain data is limited, there exist vast amounts of similar general-domain data, and our initial findings reveal that they could potentially serve as auxiliary supervision for domain enhancement. This observation leads us to our central research question: \textbf{\textit{how to effectively select the most valuable auxiliary data to maximize domain-specific performance}}, particularly when traditional methods are inapplicable due to a lack of large in-domain data pools or validation sets. To address this, we propose \textbf{NTK-Selector}, a principled and efficient framework for selecting general-domain auxiliary data to enhance domain-specific performance via neural tangent kernels (NTK). Our method tackles two challenges of directly applying NTK to LLMs, theoretical assumptions and prohibitive computational cost, by empirically demonstrating a stable NTK-like behavior in LLMs during LoRA fine-tuning and proposing a Jacobian-free approximation method. Extensive experiments across four low-resource domains (medical, financial, legal, and psychological) demonstrate that NTK-Selector consistently improves downstream performance. Specifically, fine-tuning on 1,000 in-domain samples alone only yielded +0.8 points for Llama3-8B-Instruct and +0.9 points for Qwen3-8B. In contrast, enriching with 9,000 auxiliary samples selected by NTK-Selector led to substantial \textbf{gains of +8.7 and +5.1 points}, which corresponds to a \textbf{10.9x and 5.7x improvement} over the domain-only setting.

</details>


### [95] [Retriv at BLP-2025 Task 2: Test-Driven Feedback-Guided Framework for Bangla-to-Python Code Generation](https://arxiv.org/abs/2511.07382)
*K M Nafi Asib,Sourav Saha,Mohammed Moshiul Hoque*

Main category: cs.CL

TL;DR: 该论文提出了一种结合指令提示和测试驱动反馈的迭代优化方法，用于从孟加拉语生成代码，提升了低资源语言的代码生成效果，并在相关竞赛中取得了第二名成绩。


<details>
  <summary>Details</summary>
Motivation: 低资源语言如孟加拉语缺乏足够的指令到代码的数据集和评估基准，限制了大型语言模型在该语言代码生成任务中的表现。

Method: 使用微调的Qwen2.5-14B模型，通过指令提示生成代码，并结合单元测试反馈进行三轮迭代优化，提升代码正确性。

Result: 团队"Retriv"在孟加拉语代码生成共享任务中获得第二名，Pass@1分数达到0.934，表明方法有效提升了代码生成质量。

Conclusion: 研究揭示了孟加拉语指令理解和Python代码生成中的挑战，强调需要针对低资源语言开发专门方法，并通过公开实验脚本促进社区发展。

Abstract: Large Language Models (LLMs) have advanced the automated generation of code from natural language prompts. However, low-resource languages (LRLs) like Bangla remain underrepresented due to the limited availability of instruction-to-code datasets and evaluation benchmarks. To address this, the BLP Workshop at IJCNLP-AACL 2025 introduced a shared task on "Code Generation in Bangla". In this work, we propose a method that combines instruction prompting with a test-driven, feedback-guided iterative refinement process using a fine-tuned Qwen2.5-14B model. The model generates code from Bangla instructions, tests it against unit tests, and iteratively refines any failing outputs through three evaluation passes, using test feedback to guide each step. This approach helped our team "Retriv" to secure 2nd place in the shared task with a Pass@1 score of 0.934. The analysis highlights challenges in Bangla instruction understanding and Python code generation, emphasizing the need for targeted methods in LRLs. We made experimental scripts publicly available for the community.

</details>


### [96] [Teaching Pretrained Language Models to Think Deeper with Retrofitted Recurrence](https://arxiv.org/abs/2511.07384)
*Sean McLeish,Ang Li,John Kirchenbauer,Dayal Singh Kalra,Brian R. Bartoldson,Bhavya Kailkhura,Avi Schwarzschild,Jonas Geiping,Tom Goldstein,Micah Goldblum*

Main category: cs.CL

TL;DR: 本文提出一种将预训练的非递归语言模型转换为深度递归模型的方法，通过递归训练课程提升模型深度，在保持性能的同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前深度递归语言模型利用递归机制实现训练计算与参数数量与测试计算分离，提升计算效率。如何将已有非递归预训练模型转化为递归模型，成为提升性能和效率的关键问题。

Method: 采用递归训练课程逐步增加模型有效深度，将预训练的非递归模型转换为递归模型，训练过程中通过递归机制降低计算资源消耗。

Result: 在数学任务实验中，转换后的递归模型在相同计算预算下性能优于原始非递归模型进行后训练的效果。

Conclusion: 将预训练的非递归语言模型转化为递归模型并采用递归训练课程，可以在保持甚至提升性能的情况下，降低计算成本，实现更高效的模型推理。

Abstract: Recent advances in depth-recurrent language models show that recurrence can decouple train-time compute and parameter count from test-time compute. In this work, we study how to convert existing pretrained non-recurrent language models into depth-recurrent models. We find that using a curriculum of recurrences to increase the effective depth of the model over the course of training preserves performance while reducing total computational cost. In our experiments, on mathematics, we observe that converting pretrained models to recurrent ones results in better performance at a given compute budget than simply post-training the original non-recurrent language model.

</details>


### [97] [Surgical Agent Orchestration Platform for Voice-directed Patient Data Interaction](https://arxiv.org/abs/2511.07392)
*Hyeryun Park,Byung Mo Gu,Jun Hee Lee,Byeong Hyeon Choi,Sekeun Kim,Hyun Koo Kim,Kyungsang Kim*

Main category: cs.CL

TL;DR: 本文提出了一种基于多智能体框架和大语言模型的语音驱动外科手术协调平台（SAOP），用于辅助达芬奇机器人手术中多模态患者数据的无缝访问和操作。


<details>
  <summary>Details</summary>
Motivation: 达芬奇机器人手术中，医生的手眼高度集中，难以不被打扰地访问和操作多模态患者数据。

Method: 设计了一个层级多智能体框架，包括一个协调智能体和三个基于大语言模型的任务智能体，能规范、校验并执行语音指令，完成检索临床信息、操纵CT、导航三维解剖模型等任务；同时提出多层次协调评价指标（MOEM）系统地评估性能和鲁棒性。

Result: 在240条语音指令测试中，SAOP表现出高准确率和成功率，大语言模型智能体提高了对语音识别错误和自由形式指令的鲁棒性。

Conclusion: 所提平台有效支持达芬奇机器人微创手术中多模态数据的无缝语音交互，具有大语言模型智能体辅助手术的强大潜力。

Abstract: In da Vinci robotic surgery, surgeons' hands and eyes are fully engaged in the procedure, making it difficult to access and manipulate multimodal patient data without interruption. We propose a voice-directed Surgical Agent Orchestrator Platform (SAOP) built on a hierarchical multi-agent framework, consisting of an orchestration agent and three task-specific agents driven by Large Language Models (LLMs). These LLM-based agents autonomously plan, refine, validate, and reason to map voice commands into specific tasks such as retrieving clinical information, manipulating CT scans, or navigating 3D anatomical models on the surgical video. We also introduce a Multi-level Orchestration Evaluation Metric (MOEM) to comprehensively assess the performance and robustness from command-level and category-level perspectives. The SAOP achieves high accuracy and success rates across 240 voice commands, while LLM-based agents improve robustness against speech recognition errors and diverse or ambiguous free-form commands, demonstrating strong potential to support minimally invasive da Vinci robotic surgery.

</details>


### [98] [ConvFill: Model Collaboration for Responsive Conversational Voice Agents](https://arxiv.org/abs/2511.07397)
*Vidya Srinivas,Zachary Englhardt,Maximus Powers,Shwetak Patel,Vikram Iyer*

Main category: cs.CL

TL;DR: 提出了一种名为Conversational Infill的方法，利用轻量级本地模型结合强大云端模型，实现快速且智能的对话代理。


<details>
  <summary>Details</summary>
Motivation: 云端大型语言模型虽然智能但响应延迟大，本地模型响应快但能力有限，如何兼顾两者成为关键挑战。

Method: 设计了ConvFill，一个360M参数的模型，在合成多领域对话数据上训练，通过本地生成对话并结合云端持续更新的知识，实现对话内容填充。

Result: ConvFill在多个云端模型支持下，准确率比同等规模的小模型提高36-42%，响应延迟低于200毫秒。

Conclusion: 该对话填充方法有效解耦响应速度与模型能力，能构建既快速又智能的本地对话代理。

Abstract: Deploying conversational voice agents with large language models faces a critical challenge: cloud-based foundation models provide deep reasoning and domain knowledge but introduce latency that disrupts natural conversation, while on-device models respond immediately but lack sophistication. We propose conversational infill, a task where a lightweight on-device model generates contextually appropriate dialogue while seamlessly incorporating streaming knowledge from a powerful backend model. This approach decouples response latency from model capability, enabling systems that feel responsive while accessing the full power of large-scale models. We present ConvFill, a 360M parameter model trained on synthetic multi-domain conversations. Evaluation across multiple backend models shows that conversational infill can be successfully learned, with ConvFill achieving accuracy improvements of 36-42% over standalone small models of the same size while consistently retaining sub-200ms response latencies. Our results demonstrate the promise of this approach for building on-device conversational agents that are both immediately responsive and knowledgeable.

</details>


### [99] [SPOT: An Annotated French Corpus and Benchmark for Detecting Critical Interventions in Online Conversations](https://arxiv.org/abs/2511.07405)
*Manon Berriche,Célia Nouri,Chloé Clavel,Jean-Philippe Cointet*

Main category: cs.CL

TL;DR: 本文介绍了SPOT，这是一个将社会学停止点概念转化为自然语言处理任务的法语Facebook评论语料库。


<details>
  <summary>Details</summary>
Motivation: 现有的反话语或社会纠正框架难以识别那些通过讽刺、细微怀疑或零散论证暂停或转向线上讨论的关键干预点（停止点）。

Method: 将停止点定义为二分类任务，提供详尽的注释指南，构建了包含43,305条注释样本并包含丰富上下文元数据的法语Facebook评论语料库。使用微调的CamemBERT编码器和多种提示策略的指令调教大模型进行性能评估。

Result: 微调的编码器模型在F1分数上比提示调教的大模型高出10个百分点以上，表明有监督学习在非英语社交媒体任务中的重要性；加入上下文元数据后，编码器F1分数由0.75提升到0.78。

Conclusion: 本研究提供了一个公开可复现的停止点检测数据集和注释指南，促进了非英语社交媒体中关键交互点的研究，强调有监督方法和上下文信息的重要性。

Abstract: We introduce SPOT (Stopping Points in Online Threads), the first annotated corpus translating the sociological concept of stopping point into a reproducible NLP task. Stopping points are ordinary critical interventions that pause or redirect online discussions through a range of forms (irony, subtle doubt or fragmentary arguments) that frameworks like counterspeech or social correction often overlook. We operationalize this concept as a binary classification task and provide reliable annotation guidelines. The corpus contains 43,305 manually annotated French Facebook comments linked to URLs flagged as false information by social media users, enriched with contextual metadata (article, post, parent comment, page or group, and source). We benchmark fine-tuned encoder models (CamemBERT) and instruction-tuned LLMs under various prompting strategies. Results show that fine-tuned encoders outperform prompted LLMs in F1 score by more than 10 percentage points, confirming the importance of supervised learning for emerging non-English social media tasks. Incorporating contextual metadata further improves encoder models F1 scores from 0.75 to 0.78. We release the anonymized dataset, along with the annotation guidelines and code in our code repository, to foster transparency and reproducible research.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [100] [LLMs as Packagers of HPC Software](https://arxiv.org/abs/2511.05626)
*Caetano Melone,Daniel Nichols,Konstantinos Parasyris,Todd Gamblin,Harshitha Menon*

Main category: cs.SE

TL;DR: 本文提出SpackIt框架，利用大语言模型结合上下文增强方法，自动生成高性能计算软件的Spack构建配方，显著提升安装成功率。


<details>
  <summary>Details</summary>
Motivation: 高性能计算软件生态复杂，维护和创建软件包构建规范工作量大。尽管工具如Spack能自动管理依赖，但仍依赖手工编写配方。利用大语言模型自动生成正确且可维护的配方是挑战。

Method: 提出SpackIt框架，通过代码仓库分析、相关示例检索及诊断反馈迭代优化，辅助生成Spack配方。

Result: 在308个开源HPC软件包测试中，SpackIt将零样本安装成功率从20%提升至最佳配置的80%以上。

Conclusion: 检索相关示例与结构化反馈显著提升了利用大语言模型自动生成软件包配方的可靠性，为高性能计算软件自动管理提供有效途径。

Abstract: High performance computing (HPC) software ecosystems are inherently heterogeneous, comprising scientific applications that depend on hundreds of external packages, each with distinct build systems, options, and dependency constraints. Tools such as Spack automate dependency resolution and environment management, but their effectiveness relies on manually written build recipes. As these ecosystems grow, maintaining existing specifications and creating new ones becomes increasingly labor-intensive. While large language models (LLMs) have shown promise in code generation, automatically producing correct and maintainable Spack recipes remains a significant challenge. We present a systematic analysis of how LLMs and context-augmentation methods can assist in the generation of Spack recipes. To this end, we introduce SpackIt, an end-to-end framework that combines repository analysis, retrieval of relevant examples, and iterative refinement through diagnostic feedback. We apply SpackIt to a representative subset of 308 open-source HPC packages to assess its effectiveness and limitations. Our results show that SpackIt increases installation success from 20% in a zero-shot setting to over 80% in its best configuration, demonstrating the value of retrieval and structured feedback for reliable package synthesis.

</details>


### [101] [Accelerating Control Systems with GitOps: A Path to Automation and Reliability](https://arxiv.org/abs/2511.05663)
*M. Gonzalez,M. Acosta*

Main category: cs.SE

TL;DR: 本文探讨了GitOps在现代基础设施中的应用，特别是在加速器科学领域的现代化进程中，如Fermilab的ACORN项目。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统基础设施需要现代化，实现自动化、可审计和版本控制以提升管理效率和可靠性。

Method: 采用GitOps、容器化、基础设施即代码、现代数据管道及AI/ML技术，实现加速器控制系统基础设施和软件的现代化。

Result: ACORN项目成功应用前沿技术，实现了加速器复杂系统的数据采集和管理现代化，提高了系统自动化和可控性。

Conclusion: GitOps及相关现代技术为传统加速器控制系统的升级提供了有效路径，推动了科学设施的信息化和自动化发展。

Abstract: GitOps is a foundational approach for modernizing infrastructure by leveraging Git as the single source of truth for declarative configurations. The poster explores how GitOps transforms traditional control system infrastructure, services and applications by enabling fully automated, auditable, and version-controlled infrastructure management. Cloud-native and containerized environments are shifting the ecosystem not only in the IT industry but also within the computational science field, as is the case of CERN [1] and Diamond Light Source [2] among other Accelerator/Science facilities which are slowly shifting towards modern software and infrastructure paradigms. The ACORN project, which aims to modernize Fermilab's control system infrastructure and software is implementing proven best-practices and cutting-edge technology standards including GitOps, containerization, infrastructure as code and modern data pipelines for control system data acquisition and the inclusion of AI/ML in our accelerator complex.

</details>


### [102] [An Empirical Study of Java Code Improvements Based on Stack Overflow Answer Edits](https://arxiv.org/abs/2511.05813)
*In-on Wiratsin,Chaiyong Ragkhitwetsagul,Matheus Paixao,Denis De Sousa,Pongpop Lapvikai,Peter Haddawy*

Main category: cs.SE

TL;DR: 本文通过实证研究Stack Overflow（SO）中Java答案的编辑历史，结合开源项目代码，发现SO答案中存在大量过时或次优代码，并通过代码克隆检测工具推荐改进方案，部分建议被开源项目采纳。


<details>
  <summary>Details</summary>
Motivation: 软件系统中存在大量次优代码，导致维护成本高和技术负债。开发者依赖SO等外部知识库，但SO中的代码片段可能存在过时或不优化的问题，需要探索如何利用SO答案的编辑来提升开源项目代码质量。

Method: 利用改进的代码克隆搜索工具，分析SO 140,840条Java采纳答案的版本历史，并与10,668个GitHub开源Java项目代码比较，识别并分类SO答案的代码编辑，基于这些编辑向开源项目提交改进的pull request。

Result: 6.91%的SO Java采纳答案进行过修订，平均修订次数为2.82次。其中49.24%的代码片段编辑可用于开源项目，基于36个建议的bug修复中，有11个被GitHub维护者接受。

Conclusion: SO答案中的编辑历史是提升开源项目代码质量的宝贵资源，合理利用这些社区协作的代码改进，能有效减少技术负债，提高代码质量。

Abstract: Suboptimal code is prevalent in software systems. Developers often write low-quality code due to factors like technical knowledge gaps, insufficient experience, time pressure, management decisions, or personal factors. Once integrated, the accumulation of this suboptimal code leads to significant maintenance costs and technical debt.
  Developers frequently consult external knowledge bases, such as API documentation and Q&A websites like Stack Overflow (SO), to aid their programming tasks. SO's crowdsourced, collaborative nature has created a vast repository of programming knowledge. Its community-curated content is constantly evolving, with new answers posted or existing ones edited.
  In this paper, we present an empirical study of SO Java answer edits and their application to improving code in open-source projects. We use a modified code clone search tool to analyze SO code snippets with version history and apply it to open-source Java projects. This identifies outdated or unoptimized code and suggests improved alternatives. Analyzing 140,840 Java accepted answers from SOTorrent and 10,668 GitHub Java projects, we manually categorized SO answer edits and created pull requests to open-source projects with the suggested code improvements. Our results show that 6.91% of SO Java accepted answers have more than one revision (average of 2.82). Moreover, 49.24% of the code snippets in the answer edits are applicable to open-source projects, and 11 out of 36 proposed bug fixes based on these edits were accepted by the GitHub project maintainers.

</details>


### [103] [WAR-Re: Web API Recommendation with Semantic Reasoning](https://arxiv.org/abs/2511.05820)
*Zishuo Xu,Dezhong Yao,Yao Wan*

Main category: cs.SE

TL;DR: 提出了一种基于大语言模型的Web API推荐方法WAR-Re，解决固定Top-N推荐和缺乏推荐理由的问题。


<details>
  <summary>Details</summary>
Motivation: 当前Web API推荐存在推荐数量固定且无法满足不同需求，以及缺乏推荐理由导致用户难以理解推荐结果的挑战。

Method: WAR-Re引入特殊起止符号处理可变推荐数量，通过有监督微调和基于组相对策略优化的强化学习两阶段训练，提高推荐准确性和生成推荐理由的能力。

Result: 在ProgrammableWeb数据集上，WAR-Re在推荐准确率上超过最先进基线模型21.59%，且能持续生成高质量的语义推荐理由。

Conclusion: WAR-Re有效解决了Web API推荐中的关键挑战，提升了推荐效果和可解释性，推动了Web API推荐技术的发展。

Abstract: With the development of cloud computing, the number of Web APIs has increased dramatically, further intensifying the demand for efficient Web API recommendation. Despite the demonstrated success of previous Web API recommendation solutions, two critical challenges persist: 1) a fixed top-N recommendation that cannot accommodate the varying API cardinality requirements of different mashups, and 2) these methods output only ranked API lists without accompanying reasons, depriving users of understanding the recommendation. To address these challenges, we propose WAR-Re, an LLM-based model for Web API recommendation with semantic reasoning for justification. WAR-Re leverages special start and stop tokens to handle the first challenge and uses two-stage training: supervised fine-tuning and reinforcement learning via Group Relative Policy Optimization (GRPO) to enhance the model's ability in both tasks. Comprehensive experimental evaluations on the ProgrammableWeb dataset demonstrate that WAR-Re achieves a gain of up to 21.59\% over the state-of-the-art baseline model in recommendation accuracy, while consistently producing high-quality semantic reasons for recommendations.

</details>


### [104] [The Impact of COVID-19 and Remote Work on Software Development in Thailand](https://arxiv.org/abs/2511.05824)
*Chaiyong Ragkhitwetsagul,Morakot Choetkiertikul,Srisupa Palakvangsa-Na-Ayudhya,Thanwadee Sunetnanta,Nattanee Satchanawakul*

Main category: cs.SE

TL;DR: 研究了COVID-19期间泰国软件开发人员远程工作的利弊，发现生产力和幸福感无显著变化，且有独特特点。


<details>
  <summary>Details</summary>
Motivation: 尽管已有关于COVID-19期间远程工作对软件开发影响的研究，但缺乏针对泰国这一亚洲新兴软件市场的实证研究。

Method: 通过调查194名泰国软件开发人员，收集他们远程工作期间面临的挑战和获得的收益。

Result: 研究发现疫情前后软件开发人员的生产力和幸福感无统计学显著变化，同时远程工作带来了既有益处也存在挑战，与其他研究类似但有独特之处。

Conclusion: 该研究有助于理解COVID-19期间泰国软件行业的远程工作影响，为类似亚洲和中低收入国家提供参考。

Abstract: The COVID-19 pandemic impacted the way of working, including software development. During the pandemic, software companies were forced to work remotely, and many companies have been using such work arrangements. There are prior studies showing the benefits and drawbacks of remote work in software development during COVID-19. However, there is no study that targets Thailand, one of the growing software markets in Asia, specifically. This paper performs an empirical study of the effects of COVID-19 on software development in Thailand. We surveyed 194 Thai software developers regarding the challenges and benefits they faced while working remotely during the COVID-19 period. The results show no statistically significant changes in the productivity and well-being of Thai software developers before and after working remotely due to the pandemic. The results show that software developers in Thailand both received benefits and faced challenges from remote work during COVID-19, similar to results reported by other studies, but with some unique differences. This study can be beneficial to similar Asian countries or other low- and middle-income countries around the world.

</details>


### [105] [Design and Implementation of Data Acquisition and Analysis System for Programming Debugging Process Based On VS Code Plug-In](https://arxiv.org/abs/2511.05825)
*Boyang Liu*

Main category: cs.SE

TL;DR: 设计并实现了基于VS Code插件的程序调试过程数据采集与分析系统，实现对学生调试行为的全程监控与智能分析，提升教学效果。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法难以全面评价学生的调试能力，亟需一种能够实时采集、分析调试行为的系统来改进教学评估。

Method: 基于VS Code插件，系统支持多种编程语言，实时捕获学生调试行为并上传，结合抽象语法树、节点注释、序列识别及聚类分析构建调试行为分析模型，智能识别调试路径关键特征。

Result: 系统实现了对多文件多任务调试场景的复杂数据采集，经过多次实践教学测试，验证了系统的可行性和稳定性，有效支持了程序调试教学中的过程性评价。

Conclusion: 该系统为程序调试行为分析提供了新思路，能够精准监控与指导学生调试过程，显著提升调试教学效果。

Abstract: In order to meet the needs of students' programming debugging ability training, this paper designs and implements a data acquisition and analysis system for programming debugging process based on VS Code plug-in, which aims to solve the limitation of traditional assessment methods that are difficult to fully evaluate students' debugging ability. The system supports a variety of programming languages, integrates debugging tasks and data acquisition functions, captures students' debugging behavior in the local editor in real time, and uploads the data to the platform database to realize the whole process monitoring and feedback, provides accurate debugging guidance for teachers, and improves the teaching effect. In terms of data analysis, the system proposed a debugging behavior analysis model based on abstract syntax tree, combined with node annotation, sequence recognition and cluster analysis and other technologies, to automatically track the context of students' debugging process and accurately identify key features in the debugging path. Through this tool, the system realizes the intelligent identification and labeling of the debugging direction and behavior pattern, and improves the refinement level of debugging data analysis. In this research system, a complex debugging scenario of multi-file and multi-task is introduced into the debugging problem design, which optimizes the multi-dimensional capturing ability of debugging data and lays a foundation for accurate debugging behavior analysis. Through several practical teaching tests, the feasibility and stability of the system are verified, which proves that it can effectively support procedural evaluation in programming debugging teaching, and provides a new direction for debugging behavior analysis research.

</details>


### [106] [Generality Is Not Enough: Zero-Label Cross-System Log-Based Anomaly Detection via Knowledge-Level Collaboration](https://arxiv.org/abs/2511.05882)
*Xinlong Zhao,Tong Jia,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: 提出了GeneralLog，一种针对零标签跨系统日志异常检测的LLM和小模型协同方法，通过动态路由无标签日志，实现无需目标系统标签的高效异常检测。


<details>
  <summary>Details</summary>
Motivation: 解决跨系统日志异常检测中目标系统缺乏标签的问题，现有方法在知识迁移和推理成本上存在限制。

Method: GeneralLog通过动态路由策略，将无标签日志分配给LLM处理专有日志，小模型处理通用日志，避免依赖标签并促进知识分离。

Result: 在三个公共日志数据集上，GeneralLog在零标签设置下实现了超过90%的F1值，显著优于现有方法。

Conclusion: GeneralLog有效结合了LLM与小模型的优势，实现了无标签下跨系统日志异常检测的优异性能，为该领域提供了新的解决思路。

Abstract: Log-based anomaly detection is crucial for ensuring software system stability. However, the scarcity of labeled logs limits rapid deployment to new systems. Cross-system transfer has become an important research direction. State-of-the-art approaches perform well with a few labeled target logs, but limitations remain: small-model methods transfer general knowledge but overlook mismatches with the target system's proprietary knowledge; LLM-based methods can capture proprietary patterns but rely on a few positive examples and incur high inference cost. Existing LLM-small model collaborations route 'simple logs' to the small model and 'complex logs' to the LLM based on output uncertainty. In zero-label cross-system settings, supervised sample complexity is unavailable, and such routing does not consider knowledge separation. To address this, we propose GeneralLog, a novel LLM-small model collaborative method for zero-label cross-system log anomaly detection. GeneralLog dynamically routes unlabeled logs, letting the LLM handle 'proprietary logs' and the small model 'general logs,' enabling cross-system generalization without labeled target logs. Experiments on three public log datasets show that GeneralLog achieves over 90% F1-score under a fully zero-label setting, significantly outperforming existing methods.

</details>


### [107] [High-Performance Generation of Constrained Input](https://arxiv.org/abs/2511.05987)
*Addison Crump,Alexi Turcotte,José Antonio Zamudio Amaya,Andreas Zeller*

Main category: cs.SE

TL;DR: 本文提出了一种基于进化算法的语言测试新方法，通过将文法转换为Rust类型并采用更优的进化算法，大幅提升了生成符合复杂约束的测试输入的效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于约束的语言测试方法在处理复杂字符串约束时效率低下，尤其是基于SMT求解器的方法过慢，现有进化算法虽快但难以处理复杂约束。

Method: 将上下文无关文法转换成Rust类型和特征实现，使编译器优化生效，同时应用更先进的进化算法提升解复杂约束的能力。

Result: 新方法相较于现有技术提升3-4个数量级，将生成和求解时间从小时缩短到秒，原型工具FANDANGO-RS能够每分钟为C编译器生成401个多样且复杂的有效测试输入。

Conclusion: 通过结构转换和算法优化，基于语言的测试在复杂约束条件下实现了高效的输入生成，突破了之前方法的性能和能力限制。

Abstract: Language-based testing combines context-free grammar definitions with semantic constraints over grammar elements to generate test inputs. By pairing context-free grammars with constraints, users have the expressiveness of unrestricted grammars while retaining simple structure. However, producing inputs in the presence of such constraints can be challenging. In past approaches, SMT solvers have been found to be very slow at finding string solutions; evolutionary algorithms are faster and more general, but current implementations still struggle with complex constraints that would be required for domains such as compiler testing. In this paper, we present a novel approach for evolutionary language-based testing that improves performance by 3-4 orders of magnitude over the current state of the art, reducing hours of generation and constraint solving time to seconds. We accomplish this by (1) carefully transforming grammar definitions into Rust types and trait implementations, ensuring that the compiler may near-maximally optimize arbitrary operations on arbitrary grammars; and (2) using better evolutionary algorithms that improve the ability of language-based testing to solve complex constraint systems. These performance and algorithmic improvements allow our prototype, FANDANGO-RS, to solve constraints that previous strategies simply cannot handle. We demonstrate this by a case study for a C subset, in which FANDANGO-RS is able to generate 401 diverse, complex, and valid test inputs for a C compiler per minute.

</details>


### [108] [The Lifecycle Workbench - A Configurable Framework for Digitized Product Maintenance Services](https://arxiv.org/abs/2511.06149)
*Dominique Briechle,Mohammed Fahad Ali,Marit Briechle-Mathiszig,Tobias Geger,Robert Werner,Andreas Rausch*

Main category: cs.SE

TL;DR: 本文探讨了电器产品生产激增对环境的负面影响，提出循环经济体系中的生命周期工作台（LCW）生态系统，以提升服务定价可靠性和产品状况评估，促进可持续服务的推广。


<details>
  <summary>Details</summary>
Motivation: 电器产品大量生产带来资源枯竭和环境压力，传统服务因成本不确定性和产品状况难以评估而影响用户和服务提供者的积极性。

Method: 提出生命周期工作台（LCW）生态系统，通过数字化产品表示提升服务定价的可靠性和产品、组件、零件状况的评估能力。

Result: LCW系统可降低服务定价的未知风险，提高客户和服务提供者的信心，在循环经济中延长产品生命周期，促进资源的有效再利用。

Conclusion: 通过数字化和生态系统化的服务工具，LCW有望解决当前服务执行中的经济风险和信息不对称问题，推动循环经济可持续发展。

Abstract: The global production of electric goods is at an all-time high, causing negative environmental and health impacts as well as a continuing depletion of natural resources. Considering the worsening global climate change, a transition of current industrial processes is necessary to tackle the above-mentioned factors. To address this urgent issue, socio-economic systems like the Circular Economy (CE) provide options to reallocate the use of resources and products on a global scale. Especially in terms of product lifecycle-prolonging, this system provides suitable approaches to alter the current modes of product handling by society and industry alike, based on the condition of the products. Although the importance and benefits of sustainable services enabling these options are widely known, users tend to shy away from using them. One of the reasons is the missing reliability in terms of the knowledge of the costs associated with a particular service. This uncertainty in expected pricing can, therefore, lower the willingness of potential clients. However, not only clients struggle with the boundary conditions of such services. On the part of the potential providers of services, the monetary risk is often caused by the incapability to detect the condition of a product in advance. This can result on the provider side in a severe economic loss if this possibility is not covered by the service price or through the mass of items, which could allow equalization of serval service operations. To address these weak points in current service execution, the authors propose the \textit{Lifecycle Workbench (LCW)}-ecosystem, which features digital representations to enhance the reliability of service pricing as well as the assessment of the condition of items, assemblies, and parts in the Circular Economy domain.

</details>


### [109] [SWE-fficiency: Can Language Models Optimize Real-World Repositories on Real Workloads?](https://arxiv.org/abs/2511.06090)
*Jeffrey Jian Ma,Milad Hashemi,Amir Yazdanbakhsh,Kevin Swersky,Ofir Press,Enhui Li,Vijay Janapa Reddi,Parthasarathy Ranganathan*

Main category: cs.SE

TL;DR: 文章提出了SWE-fficiency基准，用于评估针对大型软件仓库的性能优化，任务包括定位瓶颈和生成优化补丁，现有智能体表现较差。


<details>
  <summary>Details</summary>
Motivation: 当前大多数基准侧重于修复什么问题，而非如何修复代码，缺乏针对性能优化的长远代码推理能力评估。

Method: 构建包含498个任务的性能优化基准，涵盖9个主流数据科学和HPC仓库，自动从GitHub PR中提取性能优化补丁及对应测试，通过静态分析和执行验证确认优化效果。

Result: 实验表明，现有智能体仅达到专家性能提升的不到0.15倍，主要在定位优化点、跨函数执行推理和保持代码正确性方面表现欠佳。

Conclusion: 该基准及数据流水线有助于推动自动性能工程和长远软件推理的研究，提高大型代码库的性能优化能力。

Abstract: Optimizing the performance of large-scale software repositories demands expertise in code reasoning and software engineering (SWE) to reduce runtime while preserving program correctness. However, most benchmarks emphasize what to fix rather than how to fix code. We introduce \textsc{SWE-fficiency}, a benchmark for evaluating repository-level performance optimization on real workloads. Our suite contains 498 tasks across nine widely used data-science, machine-learning, and HPC repositories (e.g., numpy, pandas, scipy): given a complete codebase and a slow workload, an agent must investigate code semantics, localize bottlenecks and relevant tests, and produce a patch that matches or exceeds expert speedup while passing the same unit tests. To enable this how-to-fix evaluation, our automated pipeline scrapes GitHub pull requests for performance-improving edits, combining keyword filtering, static analysis, coverage tooling, and execution validation to both confirm expert speedup baselines and identify relevant repository unit tests. Empirical evaluation of state-of-the-art agents reveals significant underperformance. On average, agents achieve less than 0.15x the expert speedup: agents struggle in localizing optimization opportunities, reasoning about execution across functions, and maintaining correctness in proposed edits. We release the benchmark and accompanying data pipeline to facilitate research on automated performance engineering and long-horizon software reasoning.

</details>


### [110] [Bridging the Prototype-Production Gap: A Multi-Agent System for Notebooks Transformation](https://arxiv.org/abs/2511.07257)
*Hanya Elhashemy,Youssef Lotfy,Yongjian Tang*

Main category: cs.SE

TL;DR: 本文介绍了Codelevate，一种能够自动将Jupyter笔记本转换为结构良好、易维护的Python代码库的多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 随着Jupyter笔记本在数据科学和机器学习中的广泛使用，存在从探索性代码到生产环境高质量软件转换的挑战。

Method: 设计了由Architect、Developer和Structure三个智能体组成的系统，通过共享依赖树协同工作，实现架构一致性和代码质量提升。

Result: 实验验证了Codelevate能够自动转换代码，提升代码质量指标，同时保持计算语义不变。

Conclusion: Codelevate有效弥合了原型代码与生产环境代码之间的差距，提高了Jupyter笔记本代码的可维护性和质量。

Abstract: The increasing adoption of Jupyter notebooks in data science and machine learning workflows has created a gap between exploratory code development and production-ready software systems. While notebooks excel at iterative development and visualization, they often lack proper software engineering principles, making their transition to production environments challenging. This paper presents Codelevate, a novel multi-agent system that automatically transforms Jupyter notebooks into well-structured, maintainable Python code repositories. Our system employs three specialized agents - Architect, Developer, and Structure - working in concert through a shared dependency tree to ensure architectural coherence and code quality. Our experimental results validate Codelevate's capability to bridge the prototype-to-production gap through autonomous code transformation, yielding quantifiable improvements in code quality metrics while preserving computational semantics.

</details>


### [111] [Quality in model-driven engineering: a tertiary study](https://arxiv.org/abs/2511.06103)
*Miguel Goulão,Vasco Amaral,Marjan Mernik*

Main category: cs.SE

TL;DR: 本文通过对22个系统综述和映射研究进行三次研究，集中整理了模型驱动工程（MDE）对软件质量的影响，发现维护性是最常被研究的质量属性，但关于质量使用方面的研究较少。


<details>
  <summary>Details</summary>
Motivation: 目前关于MDE对软件质量的影响的证据分散，研究者和从业者难以系统了解已有成果及未充分研究的领域。

Method: 进行了关于MDE质量的三级文献综述，聚合了22篇系统综述和映射研究，分析其关注的质量属性与研究问题。

Result: 维护性是最常被研究且受MDE影响明显的质量属性，多数研究问题侧重于映射现有研究，而非具体比较不同MDE方法对质量的影响；质量覆盖广泛但实证研究仍不足，质量使用方面研究较少。

Conclusion: MDE对软件质量有显著影响，尤其是维护性，但需更多实证研究进一步验证，并加强对MDE开发产品质量使用方面的关注。

Abstract: Model-driven engineering (MDE) is believed to have a significant impact in software quality. However, researchers and practitioners may have a hard time locating consolidated evidence on this impact, as the available information is scattered in several different publications. Our goal is to aggregate consolidated findings on quality in MDE, facilitating the work of researchers and practitioners in learning about the coverage and main findings of existing work as well as identifying relatively unexplored niches of research that need further attention. We performed a tertiary study on quality in MDE, in order to gain a better understanding of its most prominent findings and existing challenges, as reported in the literature. We identified 22 systematic literature reviews and mapping studies and the most relevant quality attributes addressed by each of those studies, in the context of MDE. Maintainability is clearly the most often studied and reported quality attribute impacted by MDE. Eighty out of 83 research questions in the selected secondary studies have a structure that is more often associated with mapping existing research than with answering more concrete research questions (e.g., comparing two alternative MDE approaches with respect to their impact on a specific quality attribute). We briefly outline the main contributions of each of the selected literature reviews. In the collected studies, we observed a broad coverage of software product quality, although frequently accompanied by notes on how much more empirical research is needed to further validate existing claims. Relatively, little attention seems to be devoted to the impact of MDE on the quality in use of products developed using MDE.

</details>


### [112] [On the impact of semantic transparency on understanding and reviewing social goal models](https://arxiv.org/abs/2511.06110)
*Mafalda Santos,Catarina Gralha,Miguel Goulão,João Araújo,Ana Moreira*

Main category: cs.SE

TL;DR: 该论文通过准实验研究了增强语义透明度的i*模型具体语法对理解和审阅效率的影响。


<details>
  <summary>Details</summary>
Motivation: 由于i*语言复杂且工业界应用较少，研究旨在改善其具体语法及提高利益相关者对i*模型的正确解读能力。

Method: 对比标准i*具体语法与一种语义透明度更高的替代语法，57名新手参与者完成理解和审阅任务，使用成功率、时间、眼动跟踪和反馈测量表现。

Result: 替代语法未显著提升准确度和速度，但参与者在该语法下对模型和语言键的视觉努力显著减少，主观难度相当。

Conclusion: 模型和语言键的上下文或缓解了符号识别困难，但增强语义透明度的语法显著降低视觉负担。

Abstract: Context: i* is one of the most influential languages in the Requirements Engineering research community. Perhaps due to its complexity and low adoption in industry, it became a natural candidate for studies aiming at improving its concrete syntax and the stakeholders' ability to correctly interpret i* models.
  Objectives: We evaluate the impact of semantic transparency on understanding and reviewing i* models, in the presence of a language key. Methods: We performed a quasi-experiment comparing the standard i* concrete syntax with an alternative that has an increased semantic transparency. We asked 57 novice participants to perform understanding and reviewing tasks on i* models, and measured their accuracy, speed and ease, using metrics of task success, time and effort, collected with eye-tracking and participants' feedback.
  Results: We found no evidence of improved accuracy or speed attributable to the alternative concrete syntax. Although participants' perceived ease was similar, they devoted significantly less visual effort to the model and the provided language key, when using the alternative concrete syntax.
  Conclusions: The context provided by the model and language key may mitigate the i* symbol recognition deficit reported in previous works. However, the alternative concrete syntax required a significantly lower visual effort.

</details>


### [113] [Diagnosing and Resolving Android Applications Building Issues: An Empirical Study](https://arxiv.org/abs/2511.06186)
*Lakshmi Priya Bodepudi,Yutong Zhao,Ming Quan Fu,Yuanyuan Wu,Sen He,Yu Zhao*

Main category: cs.SE

TL;DR: 本文通过对200个开源Android项目的构建失败进行实证分析，提出诊断和修复策略，成功解决了75.56%的构建失败问题，并探索了大型语言模型在错误诊断中的辅助作用。


<details>
  <summary>Details</summary>
Motivation: Android应用构建存在依赖复杂、配置多样及生态快速演变等挑战，导致构建失败率较高，亟需系统性诊断和有效修复方法。

Method: 通过数据收集、构建执行、失败分类、修复策略设计及大型语言模型辅助评估五个阶段，分析构建失败原因并设计对应修复方案。

Result: 识别出四大类构建错误，诊断和修复策略使75.56%的失败项目成功构建；大型语言模型辅助修复成功率达53.3%；项目语言、年龄和规模影响构建成功率。

Conclusion: 提出的方法显著提升了Android应用构建的可靠性，且大型语言模型在构建错误诊断和修复中具备一定潜力，为软件维护提供了实用指导。

Abstract: Building Android applications reliably remains a persistent challenge due to complex dependencies, diverse configurations, and the rapid evolution of the Android ecosystem. This study conducts an empirical analysis of 200 open-source Android projects written in Java and Kotlin to diagnose and resolve build failures. Through a five-phase process encompassing data collection, build execution, failure classification, repair strategy design, and LLM-assisted evaluation, we identified four primary types of build errors: environment issues, dependency and Gradle task errors, configuration problems, and syntax/API incompatibilities. Among the 135 projects that initially failed to build, our diagnostic and repair strategy enabled developers to resolve 102 cases (75.56%), significantly reducing troubleshooting effort. We further examined the potential of Large Language Models, such as GPT-5, to assist in error diagnosis, achieving a 53.3% success rate in suggesting viable fixes. An analysis of project attributes revealed that build success is influenced by programming language, project age, and app size. These findings provide practical insights into improving Android build reliability and advancing AI-assisted software maintenance.

</details>


### [114] [Assertion-Aware Test Code Summarization with Large Language Models](https://arxiv.org/abs/2511.06227)
*Anamul Haque Mollah,Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 本文研究了如何利用大语言模型（LLMs）生成单元测试代码的摘要，提出了一个包含91个真实Java测试案例的新基准，并评估了不同提示配置对摘要质量的影响。


<details>
  <summary>Details</summary>
Motivation: 单元测试代码往往缺乏简洁的摘要来传达测试意图，尤其是在自动生成或文档不完善的代码库中，大语言模型有潜力解决该问题，但如何设计有效的提示仍是挑战。

Method: 通过构建91个真实测试案例基准，设计包含被测试方法、断言信息及其语义等不同提示配置，对四种代码大语言模型（Codex、Codestral、DeepSeek、Qwen-Coder）进行实验，采用多种评价指标（BLEU、ROUGE-L、METEOR、BERTScore及LLM评估）衡量摘要质量。

Result: 实验表明，包含断言语义的提示在保证输入简洁的同时，平均提高摘要质量2.3%，Codex和Qwen-Coder与人工摘要的契合度最高，而DeepSeek尽管词汇重合度高但表现较差。

Conclusion: 提示中融入断言语义能有效提升大语言模型生成单元测试摘要的质量，为自动化测试文档生成提供了参考，相关基准和实验包已公开。

Abstract: Unit tests often lack concise summaries that convey test intent, especially in auto-generated or poorly documented codebases. Large Language Models (LLMs) offer a promising solution, but their effectiveness depends heavily on how they are prompted. Unlike generic code summarization, test-code summarization poses distinct challenges because test methods validate expected behavior through assertions rather than im- plementing functionality. This paper presents a new benchmark of 91 real-world Java test cases paired with developer-written summaries and conducts a controlled ablation study to investigate how test code-related components-such as the method under test (MUT), assertion messages, and assertion semantics-affect the performance of LLM-generated test summaries. We evaluate four code LLMs (Codex, Codestral, DeepSeek, and Qwen-Coder) across seven prompt configurations using n-gram metrics (BLEU, ROUGE-L, METEOR), semantic similarity (BERTScore), and LLM-based evaluation. Results show that prompting with as- sertion semantics improves summary quality by an average of 0.10 points (2.3%) over full MUT context (4.45 vs. 4.35) while requiring fewer input tokens. Codex and Qwen-Coder achieve the highest alignment with human-written summaries, while DeepSeek underperforms despite high lexical overlap. The replication package is publicly available at https://doi.org/10. 5281/zenodo.17067550

</details>


### [115] [WebVIA: A Web-based Vision-Language Agentic Framework for Interactive and Verifiable UI-to-Code Generation](https://arxiv.org/abs/2511.06251)
*Mingde Xu,Zhen Yang,Wenyi Hong,Lihang Pan,Xinyue Fan,Yan Wang,Xiaotao Gu,Bin Xu,Jie Tang*

Main category: cs.SE

TL;DR: 提出WebVIA，一个集成交互式UI到代码生成及验证的框架，提升了UI探索稳定性和代码生成的交互性与可执行性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型只能生成静态UI代码，缺乏交互功能，提升自动化且交互式的UI代码生成迫切需要新的方法。

Method: 设计WebVIA框架，包括探索代理捕获多状态截图，UI2Code模型生成可执行交互代码，及验证模块确认交互性。

Result: WebVIA-Agent在UI探索上比通用代理更稳定准确，且微调后的UI2Code模型在生成交互式HTML/CSS/JavaScript代码方面表现显著优于基础模型。

Conclusion: WebVIA有效提升了从UI设计到交互式代码生成的自动化水平，为交互式UI开发提供了创新解决方案。

Abstract: User interface (UI) development requires translating design mockups into functional code, a process that remains repetitive and labor-intensive. While recent Vision-Language Models (VLMs) automate UI-to-Code generation, they generate only static HTML/CSS/JavaScript layouts lacking interactivity. To address this, we propose WebVIA, the first agentic framework for interactive UI-to-Code generation and validation. The framework comprises three components: 1) an exploration agent to capture multi-state UI screenshots; 2) a UI2Code model that generates executable interactive code; 3) a validation module that verifies the interactivity. Experiments demonstrate that WebVIA-Agent achieves more stable and accurate UI exploration than general-purpose agents (e.g., Gemini-2.5-Pro). In addition, our fine-tuned WebVIA-UI2Code models exhibit substantial improvements in generating executable and interactive HTML/CSS/JavaScript code, outperforming their base counterparts across both interactive and static UI2Code benchmarks. Our code and models are available at \href{https://zheny2751-dotcom.github.io/webvia.github.io/}{\texttt{https://webvia.github.io}}.

</details>


### [116] [State of the Art on Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06352)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 本文介绍了博士研究中关于不确定性和风险感知适应的基础概念，并讨论了相关研究。


<details>
  <summary>Details</summary>
Motivation: 为博士研究奠定关于不确定性和风险感知适应的基础。

Method: 介绍基本概念并讨论相关领域的研究进展。

Result: 明确了研究的理论基础和背景。

Conclusion: 建立了进行不确定性和风险感知适应研究的基础框架。

Abstract: In this essay, we introduce the basic concepts necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation, and discuss relevant related research.

</details>


### [117] [Understanding Student Interaction with AI-Powered Next-Step Hints: Strategies and Challenges](https://arxiv.org/abs/2511.06362)
*Anastasiia Birillo,Aleksei Rostovskii,Yaroslav Golubev,Hieke Keuning*

Main category: cs.SE

TL;DR: 该论文研究了AI驱动的下一步提示反馈系统在IDE内的应用，通过分析34名学生解决Kotlin任务的提示交互日志，识别了16种常见交互场景，并通过访谈揭示学生管理无用提示的策略，为未来研究和提示设计提供了数据支持和洞见。


<details>
  <summary>Details</summary>
Motivation: 个性化学习体验需要有效的反馈，尤其是能提供具体下一步操作的提示反馈，以帮助计算机科学教育中的学生更好地解决编程任务。

Method: 在IDE内搭建AI驱动的下一步提示系统，收集34名学生解决Kotlin编程任务时的详细提示交互日志，应用过程挖掘技术识别常见交互场景，并通过半结构化访谈了解学生应对无效提示的策略。

Result: 总结了16种常见的提示交互场景，学生采用调整提示内容或更改代码以生成提示变体等策略管理无效提示，并提供了一个公开可用的数据集。

Conclusion: 研究揭示了学生与AI提示系统的交互细节和策略，为未来人工智能提示设计提供了重要参考，能够提升编程教育中的学习支持效果。

Abstract: Automated feedback generation plays a crucial role in enhancing personalized learning experiences in computer science education. Among different types of feedback, next-step hint feedback is particularly important, as it provides students with actionable steps to progress towards solving programming tasks. This study investigates how students interact with an AI-driven next-step hint system in an in-IDE learning environment. We gathered and analyzed a dataset from 34 students solving Kotlin tasks, containing detailed hint interaction logs. We applied process mining techniques and identified 16 common interaction scenarios. Semi-structured interviews with 6 students revealed strategies for managing unhelpful hints, such as adapting partial hints or modifying code to generate variations of the same hint. These findings, combined with our publicly available dataset, offer valuable opportunities for future research and provide key insights into student behavior, helping improve hint design for enhanced learning support.

</details>


### [118] [Methodological Considerations for Self-adaptive Systems: An Essay](https://arxiv.org/abs/2511.06367)
*Sara Mahdavi Hezavehi,Danny Weyns,Paris Avgeriou*

Main category: cs.SE

TL;DR: 本文综述了进行不确定性与风险感知适应性研究的方法论基础。


<details>
  <summary>Details</summary>
Motivation: 为了为作者的博士研究奠定基础，探讨不确定性和风险感知适应性相关的方法论问题。

Method: 通过理论梳理和方法论分析，提供对不确定性和风险感知适应性研究方法的整体认识。

Result: 明确了开展相关博士研究所需关注的关键方法论要点。

Conclusion: 为未来关于不确定性与风险感知适应性研究的系统展开提供了方法论指导。

Abstract: In this essay, we provide an overview of methodological considerations necessary to lay out the foundation for our PhD research on uncertainty and risk-aware adaptation.

</details>


### [119] [Walking the Tightrope of LLMs for Software Development: A Practitioners' Perspective](https://arxiv.org/abs/2511.06428)
*Samuel Ferino,Rashina Hoda,John Grundy,Christoph Treude*

Main category: cs.SE

TL;DR: 本文通过访谈软件开发者，探讨大型语言模型（LLMs）在软件开发中的利弊及最佳实践，揭示其多层面影响和权衡。


<details>
  <summary>Details</summary>
Motivation: 目前虽有LLMs对软件开发影响的研究，但缺乏实证研究来平衡其正负效应，需了解开发者视角下的影响管理。

Method: 通过22次访谈，采用社会技术基础理论（STGT）分析软件从业者反馈，深入理解LLMs带来的影响。

Result: 发现LLMs在个人、团队、组织和社会层面均带来利弊，如提升开发流和创业精神，及对开发者性格和声誉的负面影响，并总结最佳应用实践。

Conclusion: 文章强调软件团队及组织在应用LLMs时需权衡利弊，研究对团队领导和IT管理者评估LLMs适用性提供参考。

Abstract: Background: Large Language Models emerged with the potential of provoking a revolution in software development (e.g., automating processes, workforce transformation). Although studies have started to investigate the perceived impact of LLMs for software development, there is a need for empirical studies to comprehend how to balance forward and backward effects of using LLMs. Objective: We investigated how LLMs impact software development and how to manage the impact from a software developer's perspective. Method: We conducted 22 interviews with software practitioners across 3 rounds of data collection and analysis, between October (2024) and September (2025). We employed socio-technical grounded theory (STGT) for data analysis to rigorously analyse interview participants' responses. Results: We identified the benefits (e.g., maintain software development flow, improve developers' mental model, and foster entrepreneurship) and disadvantages (e.g., negative impact on developers' personality and damage to developers' reputation) of using LLMs at individual, team, organisation, and society levels; as well as best practices on how to adopt LLMs. Conclusion: Critically, we present the trade-offs that software practitioners, teams, and organisations face in working with LLMs. Our findings are particularly useful for software team leaders and IT managers to assess the viability of LLMs within their specific context.

</details>


### [120] [Automatically Identifying Solution-Related Content in Issue Report Discussions with Language Models](https://arxiv.org/abs/2511.06501)
*Antu Saha,Mehedi Sun,Oscar Chaparro*

Main category: cs.SE

TL;DR: 本文介绍了利用语言模型自动识别软件问题报告中与解决方案相关的内容，以辅助问题重开调查、回归处理及方案重用。


<details>
  <summary>Details</summary>
Motivation: 手动分析长讨论文本寻找解决方案内容困难且耗时，自动化工具有助于提高效率。

Method: 使用传统机器学习模型、预训练语言模型和大型语言模型，结合嵌入、提示和微调三种应用方法，在Mozilla Firefox问题报告数据集上训练和评估模型。

Result: 传统模型结合大型语言模型嵌入优于TF-IDF，提示方法表现较差，微调大型语言模型效果最佳，LLAMAft达到0.716 F1，集成模型进一步提升至0.737 F1。模型对其他项目具备迁移能力且可通过少量数据微调优化。

Conclusion: 基于语言模型的解决方案识别方法有效支持软件维护、问题理解及解决方案复用，未来需开发具备更多上下文理解能力的分类器。

Abstract: During issue resolution, software developers rely on issue reports to discuss solutions for defects, feature requests, and other changes. These discussions contain proposed solutions-from design changes to code implementations-as well as their evaluations. Locating solution-related content is essential for investigating reopened issues, addressing regressions, reusing solutions, and understanding code change rationale. Manually understanding long discussions to identify such content can be difficult and time-consuming.
  This paper automates solution identification using language models as supervised classifiers. We investigate three applications-embeddings, prompting, and fine-tuning-across three classifier types: traditional ML models (MLMs), pre-trained language models (PLMs), and large language models (LLMs). Using 356 Mozilla Firefox issues, we created a dataset to train and evaluate six MLMs, four PLMs, and two LLMs across 68 configurations.
  Results show that MLMs with LLM embeddings outperform TF-IDF features, prompting underperforms, and fine-tuned LLMs achieve the highest performance, with LLAMAft reaching 0.716 F1 score. Ensembles of the best models further improve results (0.737 F1). Misclassifications often arise from misleading clues or missing context, highlighting the need for context-aware classifiers. Models trained on Mozilla transfer to other projects, with a small amount of project-specific data, further enhancing results. This work supports software maintenance, issue understanding, and solution reuse.

</details>


### [121] [LLM For Loop Invariant Generation and Fixing: How Far Are We?](https://arxiv.org/abs/2511.06552)
*Mostafijur Rahman Akhond,Saikat Chakraborty,Gias Uddin*

Main category: cs.SE

TL;DR: 该论文研究了大型语言模型(LLMs)在推断和修复程序循环不变量方面的性能，发现LLMs在生成不变量上取得了78%的最高成功率，但修复不变量的能力仅为16%。


<details>
  <summary>Details</summary>
Motivation: 循环不变量是程序安全自动评估的重要步骤，目前尚不清楚大型语言模型在推断循环不变量方面的表现如何。

Method: 作者对不同规模的开源和闭源大型语言模型进行了实证研究，评估其推断归纳循环不变量和修复错误不变量的能力，并探究辅助信息对性能的影响。

Result: 研究发现，LLMs在推断和修复循环不变量方面表现有限，但通过引入领域知识和示例等辅助信息，其性能显著提升。生成不变量的最高成功率为78%，修复能力仅16%。

Conclusion: 尽管大型语言模型在循环不变量推断中具备一定潜力，但需结合辅助信息以显著提高其效能，特别是在修复不变量方面仍有较大提升空间。

Abstract: A loop invariant is a property of a loop that remains true before and after each execution of the loop. The identification of loop invariants is a critical step to support automated program safety assessment. Recent advancements in Large Language Models (LLMs) have demonstrated potential in diverse software engineering (SE) and formal verification tasks. However, we are not aware of the performance of LLMs to infer loop invariants. We report an empirical study of both open-source and closed-source LLMs of varying sizes to assess their proficiency in inferring inductive loop invariants for programs and in fixing incorrect invariants. Our findings reveal that while LLMs exhibit some utility in inferring and repairing loop invariants, their performance is substantially enhanced when supplemented with auxiliary information such as domain knowledge and illustrative examples. LLMs achieve a maximum success rate of 78\% in generating, but are limited to 16\% in repairing the invariant.

</details>


### [122] [PhaseSeed: Precise Call Graph Construction for Split-Phase Applications using Dynamic Seeding](https://arxiv.org/abs/2511.06661)
*Tapti Palit,Seyedhamed Ghavamnia,Michalis Polychronakis*

Main category: cs.SE

TL;DR: 本文提出了PhaseSeed技术，通过动态分析初始化阶段并结合静态分析，提高了分阶段应用程序中的指针分析精度，从而增强了安全机制的效果。


<details>
  <summary>Details</summary>
Motivation: 传统静态指针分析技术因忽略应用架构而导致调用图构建不精确，影响安全机制效果，需提升分析精度。

Method: PhaseSeed动态分析初始化阶段的指针关系，结束后将信息作为种子输入静态分析，专注于处理阶段代码，从而提升指针分析的精确度。

Result: 相较传统静态技术，PhaseSeed为控制流完整性提供了最高92.6%的精度提升，并在Seccomp配置中多过滤9个关键系统调用。

Conclusion: PhaseSeed方法通过结合动态与静态分析，显著提升了调用图构建的精确性，增强了安全机制的有效性，且对初始配置具有健壮性。

Abstract: Precise and sound call graph construction is crucial for many software security mechanisms. Unfortunately, traditional static pointer analysis techniques used to generate application call graphs suffer from imprecision. These techniques are agnostic to the application's architecture and are designed for broad applicability. To mitigate this precision problem, we propose PhaseSeed, a novel technique that improves the accuracy of pointer analysis for split-phase applications, which have distinct initialization and processing phases. PhaseSeed analyzes the initialization phase dynamically, collecting the points-to relationships established at runtime. At the end of the initialization phase, it then seeds this information to a static analysis stage that performs pointer analysis for all code that stays in scope during the processing phase, improving precision. Our observations show that, given the same runtime configuration options, the points-to relationships established during the initialization phase remain constant across multiple runs. Therefore, PhaseSeed is sound with respect to a given initial configuration. We apply PhaseSeed to three security mechanisms: control flow integrity (CFI), software debloating, and system call filtering. PhaseSeed provides up to 92.6% precision improvement for CFI compared to static call graph construction techniques, and filters nine additional security-critical system calls when used to generate Seccomp profiles.

</details>


### [123] [Structural Enforcement of Statistical Rigor in AI-Driven Discovery: A Functional Architecture](https://arxiv.org/abs/2511.06701)
*Karen Sargsyan*

Main category: cs.SE

TL;DR: 本文提出了一种基于函数式编程的结构化框架，以保证自动化科研系统中统计流程的严谨性，通过引入Research monad和Declarative Scaffolding，有效防止虚假发现和方法学错误。


<details>
  <summary>Details</summary>
Motivation: 自动化科研系统（AI-Scientists）在动态假设检验过程中容易产生虚假发现，需要严格管理状态和错误处理以确保统计流程的严谨性。

Method: 设计了一个基于Haskell的嵌入式领域特定语言Research monad，通过Monad变换器堆栈实现序贯统计协议（如在线FDR控制）；采用Declarative Scaffolding生成结构化执行框架，限制执行路径，防止数据泄漏等方法错误。

Result: 通过大规模模拟（2000个假设）和一项端到端案例研究验证了所提方法，显示该架构能有效防止统计和方法学错误，保障自动化科学的完整性。

Conclusion: 该基于函数式编程的结构化架构为自动化科研系统提供了坚实的统计协议执行保障，是实现自动化科学可信性和严谨性的关键技术。

Abstract: Sequential statistical protocols require meticulous state management and robust error handling -- challenges naturally suited to functional programming. We present a functional architecture for structural enforcement of statistical rigor in automated research systems (AI-Scientists). These LLM-driven systems risk generating spurious discoveries through dynamic hypothesis testing. We introduce the Research monad, a Haskell eDSL that enforces sequential statistical protocols (e.g., Online FDR (false discovery rate) control) using a monad transformer stack. To address risks in hybrid architectures where LLMs generate imperative code, we employ Declarative Scaffolding -- generating rigid harnesses that structurally constrain execution and prevent methodological errors like data leakage. We validate this approach through large-scale simulation (N=2000 hypotheses) and an end-to-end case study, demonstrating essential defense-in-depth for automated science integrity.

</details>


### [124] [Minimizing Breaking Changes and Redundancy in Mitigating Technical Lag for Java Projects](https://arxiv.org/abs/2511.06762)
*Rui Lu,Lyuye Zhang,Kaixuan Li,Min Zhang,Yixiang Chen*

Main category: cs.SE

TL;DR: 本文提出了DepUpdater，一种自动维护开源软件库版本的工具，旨在减少技术滞后，避免不兼容和冗余依赖。


<details>
  <summary>Details</summary>
Motivation: 开源软件库版本过时会引入技术滞后，升级又可能导致不兼容问题和冗余依赖，阻碍开发者及时升级。

Method: 设计DepUpdater，自动实现库版本升级，兼顾减少技术滞后、避免不兼容及冗余依赖，并通过消融实验验证。

Result: DepUpdater比现有工具更有效地降低技术滞后，保证兼容性并修剪冗余依赖，同时通过案例研究分析了传递依赖升级对兼容性的影响。

Conclusion: DepUpdater是一种有效的自动库升级方案，能平衡升级需求，减少技术滞后，兼顾兼容性及依赖优化，为未来研究提供了新视角。

Abstract: Re-using open-source software (OSS) can avoid reinventing the wheel, but failing to keep it up-to-date can lead to missing new features and persistent bugs or vulnerabilities that have already been resolved. The use of outdated OSS libraries introduces technical lag, necessitating timely upgrades. However, maintaining up-to-date libraries is challenging, as it may introduce incompatibility issues that break the project or redundant dependencies that unnecessarily increase the size of the project. These issues discourage developers from upgrading libraries, highlighting the need for a fully automated solution that balances version upgrades, reduces technical lag, ensures compatibility, and avoids redundant dependencies.
  To this end, we propose DepUpdater, which ensures that upgrades minimize technical lag as much as possible while avoiding incompatibility issues and redundant dependencies. The comparison with existing dependency management tools demonstrates that DepUpdater more effectively reduces technical lag while ensuring compatibility and pruning redundant dependencies. Additionally, an ablation study highlights the potential benefits of considering pruning requirements during upgrades to mitigate incompatibility issues. Finally, leveraging DepUpdater, we investigate the impact of transitive dependency upgrades on client compatibility, providing insights for future research.

</details>


### [125] [MetricSynth: Framework for Aggregating DORA and KPI Metrics Across Multi-Platform Engineering](https://arxiv.org/abs/2511.06864)
*Pallav Jain,Yuvraj Agrawal,Ashutosh Nigam,Pushpak Patil*

Main category: cs.SE

TL;DR: 本文提出了一个集中式框架，实现对开发者体验和关键绩效指标的近实时监控，提升了软件生态系统的透明度和数据驱动的决策能力。


<details>
  <summary>Details</summary>
Motivation: 面对大型软件开发中数据孤岛和手动报告带来的挑战，工程领导者需要一个统一、实时且数据驱动的团队绩效和系统健康监控方案。

Method: 设计了一个包含定时数据采集、双模式存储、指标预计算、主动告警系统和基于角色访问控制的可视化平台，整合内部多平台数据，利用开源BI工具Metabase进行展示。

Result: 该系统显著减少了每周约20小时的手动报告工作，提升了问题识别速度，实现了开发效率、质量和运营效率指标的全面监控。

Conclusion: 系统在可扩展性和权衡方面表现良好，成为工程智能平台中有价值的贡献，有效支持数据驱动的管理决策。

Abstract: In modern, large-scale software development, engineering leaders face the significant challenge of gaining a holistic and data-driven view of team performance and system health. Data is often siloed across numerous disparate tools, making manual report generation time-consuming and prone to inconsistencies. This paper presents the architecture and implementation of a centralized framework designed to provide near-real-time visibility into developer experience (DevEx) and Key Performance Indicator (KPI) metrics for a software ecosystem. By aggregating data from various internal tools and platforms, the system computes and visualizes metrics across key areas such as Developer Productivity, Quality, and Operational Efficiency. The architecture features a cron-based data ingestion layer, a dual-schema data storage approach, a processing engine for metric pre-computation, a proactive alerting system, and utilizes the open-source BI tool Metabase for visualization, all secured with role-based access control (RBAC). The implementation resulted in a significant reduction in manual reporting efforts, saving an estimated 20 person-hours per week, and enabled faster, data-driven bottleneck identification. Finally, we evaluate the system's scalability and discuss its trade-offs, positioning it as a valuable contribution to engineering intelligence platforms.

</details>


### [126] [A Collaborative Model for Improving Information Sharing among Cancer Care Groups using Software Engineering Principles](https://arxiv.org/abs/2511.06885)
*Davis Byamugisha,Francis Kamuganga,Adones Rukundo,John Businge*

Main category: cs.SE

TL;DR: 本文提出利用软件工程中的版本控制原理，改善癌症护理团队之间的信息共享，减少延误，提高协调效率。


<details>
  <summary>Details</summary>
Motivation: 癌症早期诊断常受限于信息管理系统的非集成和缺乏协调，导致护理团队间信息不畅，引起诊疗延误。

Method: 借鉴GitHub的版本控制系统和软件工程中的缺陷修复原理，设计信息共享模型，并使用Any-Logic仿真软件进行虚拟环境模拟验证。

Result: 仿真结果表明，应用软件工程的缺陷修复及版本控制原则可以有效促进护理团队间合作和信息共享，涵盖所有利益相关者，提升诊疗效率。

Conclusion: 将软件工程中的版本控制方法应用于癌症护理信息管理，有助于缩短诊疗时间，改善信息流通，促进早诊早治，提高患者生存率。

Abstract: Effective treatment of cancer requires early diagnosis which involves the patient's awareness of the early signs and symptoms, leading to a consultation with a health provider, who would then promptly refer the patient for confirmation of the diagnosis and thereafter treatment. However, this is not always the case because of delays arising from limited skilled manpower and health information management systems that are neither integrated nor organized in their design hence leading to information gap among care groups. Existing methods focus on using accumulated data to support decision making, enhancing the sharing of secondary data while others exclude some critical stakeholders like patient caretakers and administrators thus, leaving an information gap that creates delays and miscommunication during case management. We however notice some similarities between cancer treatment and software engineering information management especially when progress history needs to be maintained (versioning).
  We analyze the similarities and propose a model for information sharing among cancer care groups using the software engineering principles approach. We model for reducing delays and improving coordination among care groups in cancer case management. Model design was guided by software engineering principles adopted in GitHub version control system for bug fixing in open-source code projects. Any-Logic simulation software was used to mimic the model realism in a virtual environment. Results show that bug resolution principles from software engineering and GitHub version control system can be adopted to coordinate collaboration and information sharing among care groups in a cancer case management environment while involving all stakeholders to improve care treatment outcomes, ensure early diagnosis and increase patient's survival chances.

</details>


### [127] [Benchmarking LLMs for Fine-Grained Code Review with Enriched Context in Practice](https://arxiv.org/abs/2511.07017)
*Ruida Hu,Xinchen Wang,Xin-Cheng Wen,Zhao Zhang,Bo Jiang,Pengfei Gao,Chao Peng,Cuiyun Gao*

Main category: cs.SE

TL;DR: 本文提出了ContextCRBench，这是一个高质量、包含语义上下文的细粒度代码审查基准，解决了现有基准缺乏文本信息、数据质量低和粒度粗糙的问题。通过从顶级仓库爬取大量问题和PR，进行上下文提取和多阶段筛选，构建了67910条上下文丰富的样本。该基准支持块级质量评估、行级缺陷定位和行级评论生成三种场景。评测多款领先大模型发现文本上下文显著提升性能，但仍远不及人类水平。该基准已在字节跳动应用，提升代码审查系统性能61.98%，展现出强大工业价值。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的代码审查基准存在缺乏语义上下文、数据质量差和评测粒度粗糙等三方面重大不足，难以准确评估和提升自动化代码审查效能。

Method: 构建ContextCRBench，通过爬取153.7K条高质量代码审查相关数据，提取文本和代码双重上下文，结合规则和大模型多阶段过滤，生成67910条高质量带上下文的细粒度代码审查样本。同时设计三种评测场景，覆盖代码审查流程的多个关键步骤。

Result: 基准在块级质量评估、行级缺陷定位和行级评论生成三种任务上评测了8种主流大语言模型，发现文本上下文对性能提升影响显著，模型整体表现仍显不足。实际部署在字节跳动后，代码审查系统性能提升61.98%。

Conclusion: ContextCRBench有效弥补了现有代码审查评测的数据和方法局限，能够推动大语言模型在代码审查中的研发和应用，且已展现良好的工业化前景。

Abstract: Code review is a cornerstone of software quality assurance, and recent advances in Large Language Models (LLMs) have shown promise in automating this process. However, existing benchmarks for LLM-based code review face three major limitations. (1) Lack of semantic context: most benchmarks provide only code diffs without textual information such as issue descriptions, which are crucial for understanding developer intent. (2) Data quality issues: without rigorous validation, many samples are noisy-e.g., reviews on outdated or irrelevant code-reducing evaluation reliability. (3) Coarse granularity: most benchmarks operate at the file or commit level, overlooking the fine-grained, line-level reasoning essential for precise review.
  We introduce ContextCRBench, a high-quality, context-rich benchmark for fine-grained LLM evaluation in code review. Our construction pipeline comprises: (1) Raw Data Crawling, collecting 153.7K issues and pull requests from top-tier repositories; (2) Comprehensive Context Extraction, linking issue-PR pairs for textual context and extracting the full surrounding function or class for code context; and (3) Multi-stage Data Filtering, combining rule-based and LLM-based validation to remove outdated, malformed, or low-value samples, resulting in 67,910 context-enriched entries.
  ContextCRBench supports three evaluation scenarios aligned with the review workflow: (1) hunk-level quality assessment, (2) line-level defect localization, and (3) line-level comment generation. Evaluating eight leading LLMs (four closed-source and four open-source) reveals that textual context yields greater performance gains than code context alone, while current LLMs remain far from human-level review ability. Deployed at ByteDance, ContextCRBench drives a self-evolving code review system, improving performance by 61.98% and demonstrating its robustness and industrial utility.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [128] [Novel Concepts for Agent-Based Population Modelling and Simulation: Updates from GEPOC ABM](https://arxiv.org/abs/2511.05637)
*Martin Bicher,Maximilian Viehauser,Daniele Giannandrea,Hannah Kastinger,Dominik Brunmeir,Niki Popper*

Main category: cs.MA

TL;DR: 本文介绍了GEPOC ABM模型中的三项创新方法，这些方法提高了人口动态模型的灵活性和准确性，并具有良好的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 为提升动态基于代理的人口模型的应用效果和灵活性，通过改进模型时间更新、共模拟策略及模型参数化方法，增强模型的决策支持能力。

Method: 提出了个体代理的创新时间更新概念，借鉴共模拟的仿真策略，以及准确的模型参数化策略，并详细描述了这些方法的实现及优势。

Result: 这些创新方法已成功应用于GEPOC ABM模型，并在医疗到物流等多领域的人口研究中取得良好效果。

Conclusion: 所介绍的三项方法不仅提升了GEPOC ABM模型性能，也具有较强的可迁移性，可供其他人口模型参考和采用。

Abstract: In recent years, dynamic agent-based population models, which model every inhabitant of a country as a statistically representative agent, have been gaining in popularity for decision support. This is mainly due to their high degree of flexibility with respect to their area of application. GEPOC ABM is one of these models. Developed in 2015, it is now a well-established decision support tool and has been successfully applied for a wide range of population-level research questions ranging from health-care to logistics. At least in part, this success is attributable to continuous improvement and development of new methods. While some of these are very application- or implementation-specific, others can be well transferred to other population models. The focus of the present work lies on the presentation of three selected transferable innovations. We illustrate an innovative time-update concept for the individual agents, a co-simulation-inspired simulation strategy, and a strategy for accurate model parametrisation. We describe these methods in a reproducible manner, explain their advantages and provide ideas on how they can be transferred to other population models.

</details>


### [129] [STAIR: Stability criterion for Time-windowed Assignment and Internal adversarial influence in Routing and decision-making](https://arxiv.org/abs/2511.05715)
*Roee M. Francos,Daniel Garces,Orhan Eren Akgün,Stephanie Gil*

Main category: cs.MA

TL;DR: 本文提出了一种针对存在对抗性代理的多代理系统中自主接送路由问题的新稳定性标准STAIR，以应对位置欺骗带来的拒绝服务攻击，确保系统稳定性并通过旧金山实数据验证。


<details>
  <summary>Details</summary>
Motivation: 现有多代理系统路由算法未考虑对抗性代理的存在，易受拒绝服务攻击影响，导致系统性能严重下降，需要新的稳定性指标来描述并监控此类攻击的影响。

Method: 提出了新的稳定性标准STAIR，它比传统排队论和强化学习稳定性更易分析，不依赖折扣因子，直接关联运算指标（如拒绝请求数），并引入时间窗口约束缓解退化稳定性现象。

Result: 通过基于旧金山真实移动出行数据的仿真验证了STAIR的实用性，发现对抗性攻击会导致拒绝请求及策略不稳定，时间窗口约束能有效减少退化稳定性问题。

Conclusion: STAIR提供了在对抗性环境下评估和保证路由策略稳定性的有效标准，有助于设计更鲁棒的多代理接送系统，对抗拒绝服务攻击，提升系统实际运行质量。

Abstract: A major limitation of existing routing algorithms for multi-agent systems is that they are designed without considering the potential presence of adversarial agents in the decision-making loop, which could lead to severe performance degradation in real-life applications where adversarial agents may be present. We study autonomous pickup-and-delivery routing problems in which adversarial agents launch coordinated denial-of-service attacks by spoofing their locations. This deception causes the central scheduler to assign pickup requests to adversarial agents instead of cooperative agents. Adversarial agents then choose not to service the requests with the goal of disrupting the operation of the system, leading to delays, cancellations, and potential instability in the routing policy. Policy stability in routing problems is typically defined as the cost of the policy being uniformly bounded over time, and it has been studied through two different lenses: queuing theory and reinforcement learning (RL), which are not well suited for routing with adversaries. In this paper, we propose a new stability criterion, STAIR, which is easier to analyze than queuing-theory-based stability in adversarial settings. Furthermore, STAIR does not depend on a chosen discount factor as is the case in discounted RL stability. STAIR directly links stability to desired operational metrics, like a finite number of rejected requests. This characterization is particularly useful in adversarial settings as it provides a metric for monitoring the effect of adversaries in the operation of the system. Furthermore, we demonstrate STAIR's practical relevance through simulations on real-world San Francisco mobility-on-demand data. We also identify a phenomenon of degenerate stability that arises in the adversarial routing problem, and we introduce time-window constraints in the decision-making algorithm to mitigate it.

</details>


### [130] [A Graph-Theoretical Perspective on Law Design for Multiagent Systems](https://arxiv.org/abs/2511.06361)
*Qi Shi,Pavel Naumov*

Main category: cs.MA

TL;DR: 本文研究多智能体系统中的两种约束代理行为的法律，旨在以最小限制消除或追责不良结果，证明该问题为NP难，且提出了基于超图顶点覆盖问题的近似算法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中避免不良结果，并确保对不良结果负有责任的代理行为受到约束。

Method: 定义有用法律和无漏洞法律，研究最小化约束以达成目标的困难性；证明问题为NP难，并应用超图顶点覆盖的近似算法进行求解。

Result: 证明了最小化约束问题在两类法律下均为NP难；提出了利用超图顶点覆盖问题的近似算法有效逼近最小法律。

Conclusion: 通过理论证明和算法设计，为多智能体系统中设计最小限制法律提供了理论基础和有效的近似解决方案。

Abstract: A law in a multiagent system is a set of constraints imposed on agents' behaviours to avoid undesirable outcomes. The paper considers two types of laws: useful laws that, if followed, completely eliminate the undesirable outcomes and gap-free laws that guarantee that at least one agent can be held responsible each time an undesirable outcome occurs. In both cases, we study the problem of finding a law that achieves the desired result by imposing the minimum restrictions.
  We prove that, for both types of laws, the minimisation problem is NP-hard even in the simple case of one-shot concurrent interactions. We also show that the approximation algorithm for the vertex cover problem in hypergraphs could be used to efficiently approximate the minimum laws in both cases.

</details>


### [131] [S-DAG: A Subject-Based Directed Acyclic Graph for Multi-Agent Heterogeneous Reasoning](https://arxiv.org/abs/2511.06727)
*Jiangwen Dong,Zehui Lin,Wanyu Lin,Mingjin Zhang*

Main category: cs.MA

TL;DR: 本文提出了一种基于主题的细粒度多智能体协作框架，通过构建主题导向的有向无环图（S-DAG）和模型主题匹配，有效提升复杂多学科推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的大型语言模型任务划分粗糙，难以解决涉及多学科的异构问题，亟需更细粒度的主题级分析和模型选择策略。

Method: 利用图神经网络识别相关学科及其依赖关系，生成主题导向有向无环图，结合主题特定的模型专家评分，实现不同模型在图结构上的多智能体协作。

Result: 在多学科标准基准测试(MMLU-Pro, GPQA, MedMCQA)子集上，该方法在准确率和效率上明显优于现有任务级模型选择和多智能体协作基线。

Conclusion: 主题感知推理和结构化协作显著提升了处理复杂多学科问题的能力，证明了细粒度主题分析在大型语言模型中的有效性。

Abstract: Large Language Models (LLMs) have achieved impressive performance in complex reasoning problems. Their effectiveness highly depends on the specific nature of the task, especially the required domain knowledge. Existing approaches, such as mixture-of-experts, typically operate at the task level; they are too coarse to effectively solve the heterogeneous problems involving multiple subjects. This work proposes a novel framework that performs fine-grained analysis at subject level equipped with a designated multi-agent collaboration strategy for addressing heterogeneous problem reasoning. Specifically, given an input query, we first employ a Graph Neural Network to identify the relevant subjects and infer their interdependencies to generate an \textit{Subject-based Directed Acyclic Graph} (S-DAG), where nodes represent subjects and edges encode information flow. Then we profile the LLM models by assigning each model a subject-specific expertise score, and select the top-performing one for matching corresponding subject of the S-DAG. Such subject-model matching enables graph-structured multi-agent collaboration where information flows from the starting model to the ending model over S-DAG. We curate and release multi-subject subsets of standard benchmarks (MMLU-Pro, GPQA, MedMCQA) to better reflect complex, real-world reasoning tasks. Extensive experiments show that our approach significantly outperforms existing task-level model selection and multi-agent collaboration baselines in accuracy and efficiency. These results highlight the effectiveness of subject-aware reasoning and structured collaboration in addressing complex and multi-subject problems.

</details>


### [132] [Multi-Agent Reinforcement Learning for Deadlock Handling among Autonomous Mobile Robots](https://arxiv.org/abs/2511.07071)
*Marcel Müller*

Main category: cs.MA

TL;DR: 本文研究了多智能体强化学习在仓内物流中处理移动机器人死锁问题的应用，提出了集成MARL的结构化方法，并通过模拟实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统的移动机器人路径规划多忽视死锁问题，依赖刚性规则无法适应动态环境，影响物流系统吞吐率和可靠性。

Method: 构建包含死锁多智能体路径规划的参考模型，利用基于网格的环境结合外部仿真软件，采用PPO和IMPALA算法比较传统死锁处理方法与MARL策略，探讨中央训练-分散执行模式效果。

Result: MARL方法尤其是在中央训练-分散执行模式下，在复杂拥堵环境中性能优于基于规则的方法，而简单或空间富裕环境中规则方法因计算开销小仍具竞争力。

Conclusion: MARL为动态仓内物流死锁问题提供灵活可扩展的解决方案，但需根据具体操作环境进行定制调整。

Abstract: This dissertation explores the application of multi-agent reinforcement learning (MARL) for handling deadlocks in intralogistics systems that rely on autonomous mobile robots (AMRs). AMRs enhance operational flexibility but also increase the risk of deadlocks, which degrade system throughput and reliability. Existing approaches often neglect deadlock handling in the planning phase and rely on rigid control rules that cannot adapt to dynamic operational conditions.
  To address these shortcomings, this work develops a structured methodology for integrating MARL into logistics planning and operational control. It introduces reference models that explicitly consider deadlock-capable multi-agent pathfinding (MAPF) problems, enabling systematic evaluation of MARL strategies. Using grid-based environments and an external simulation software, the study compares traditional deadlock handling strategies with MARL-based solutions, focusing on PPO and IMPALA algorithms under different training and execution modes.
  Findings reveal that MARL-based strategies, particularly when combined with centralized training and decentralized execution (CTDE), outperform rule-based methods in complex, congested environments. In simpler environments or those with ample spatial freedom, rule-based methods remain competitive due to their lower computational demands. These results highlight that MARL provides a flexible and scalable solution for deadlock handling in dynamic intralogistics scenarios, but requires careful tailoring to the operational context.

</details>


### [133] [When AI Agents Collude Online: Financial Fraud Risks by Collaborative LLM Agents on Social Platforms](https://arxiv.org/abs/2511.06448)
*Qibing Ren,Zhijie Zheng,Jiaxuan Guo,Junchi Yan,Lizhuang Ma,Jing Shao*

Main category: cs.MA

TL;DR: 本文研究了大型多智能体系统中由大型语言模型驱动的智能体协同实施金融欺诈的风险，构建了一个涵盖28种真实在线欺诈场景的大规模基准MultiAgentFraudBench，分析了影响欺诈成功的关键因素，并提出了一系列缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型智能体的普及，群体性金融欺诈行为的风险日益突出，需要深入理解智能体间如何协作实施欺诈，以及影响欺诈成功的因素，从而制定有效的防范措施。

Method: 构建了MultiAgentFraudBench基准，模拟涵盖28个典型在线金融欺诈场景，分析了交互深度、活动水平及协作失败模式对欺诈成功的影响，提出利用内容警告、利用LLM作为监控者以及信息共享提升群体韧性的多维缓解策略。

Result: 发现智能体间的协作加剧了欺诈风险，关键影响因素包括交互深入度和活动活跃度，智能体能适应环境干预，表明防范需要多层次综合手段。

Conclusion: 本文系统揭示了多智能体系统中群体金融欺诈的现实风险，提出了实用且动态适应的干预措施，为防范利用大型语言模型智能体的金融欺诈提供了重要参考和工具支持。

Abstract: In this work, we study the risks of collective financial fraud in large-scale multi-agent systems powered by large language model (LLM) agents. We investigate whether agents can collaborate in fraudulent behaviors, how such collaboration amplifies risks, and what factors influence fraud success. To support this research, we present MultiAgentFraudBench, a large-scale benchmark for simulating financial fraud scenarios based on realistic online interactions. The benchmark covers 28 typical online fraud scenarios, spanning the full fraud lifecycle across both public and private domains. We further analyze key factors affecting fraud success, including interaction depth, activity level, and fine-grained collaboration failure modes. Finally, we propose a series of mitigation strategies, including adding content-level warnings to fraudulent posts and dialogues, using LLMs as monitors to block potentially malicious agents, and fostering group resilience through information sharing at the societal level. Notably, we observe that malicious agents can adapt to environmental interventions. Our findings highlight the real-world risks of multi-agent financial fraud and suggest practical measures for mitigating them. Code is available at https://github.com/zheng977/MutiAgent4Fraud.

</details>
