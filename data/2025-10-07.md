<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 109]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.SE](#cs.SE) [Total: 46]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Decomposing Attention To Find Context-Sensitive Neurons](https://arxiv.org/abs/2510.03315)
*Alex Gibson*

Main category: cs.CL

TL;DR: 本文研究了变压器语言模型中关注模式分散、分数对内容依赖较弱的注意力头，通过校准文本采样软最大分母，实现了对多注意力头输出的线性近似，揭示了第一层神经元对上下文高级属性的响应。


<details>
  <summary>Details</summary>
Motivation: 探究那些关注模式分布广泛且对具体内容依赖弱的注意力头，理解其在语言模型中的作用与机制。

Method: 通过采样一个校准文本的softmax分母，结合GPT2-Small第一层多个稳定注意力头的输出，实现对其输出的线性总结近似。

Result: 利用该方法发现了数百个第一层神经元响应文本的高级上下文属性，甚至包括在校准文本中未激活的神经元。

Conclusion: 仅凭预训练权重和一个校准文本，即可识别出对上下文有高层次响应的神经元，拓展了对变压器模型内部机制的理解。

Abstract: We study transformer language models, analyzing attention heads whose
attention patterns are spread out, and whose attention scores depend weakly on
content. We argue that the softmax denominators of these heads are stable when
the underlying token distribution is fixed. By sampling softmax denominators
from a "calibration text", we can combine together the outputs of multiple such
stable heads in the first layer of GPT2-Small, approximating their combined
output by a linear summary of the surrounding text. This approximation enables
a procedure where from the weights alone - and a single calibration text - we
can uncover hundreds of first layer neurons that respond to high-level
contextual properties of the surrounding text, including neurons that didn't
activate on the calibration text.

</details>


### [2] [Graph-S3: Enhancing Agentic textual Graph Retrieval with Synthetic Stepwise Supervision](https://arxiv.org/abs/2510.03323)
*Ge Chang,Jinbo Su,Jiacheng Liu,Pengfei Yang,Yuhao Shang,Huiwen Zheng,Hongli Ma,Yan Liang,Yuanchun Li,Yunxin Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种基于大语言模型的文本图检索框架Graph-S3，通过合成步进监督训练检索器，提升了复杂图推理任务的问答性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的文本图问答系统面临图检索难题，现有方法依赖浅层嵌入或需大量标注，导致性能低下或训练成本高。

Method: 提出Graph-S3框架，采用基于合成步进监督训练的LLM检索器，结合数据合成管道提取黄金子图进行训练，通过两阶段训练实现交互式图探索策略。

Result: 在三个数据集和七个强基线对比中，Graph-S3在准确率和F1得分上分别提升8.1%和9.7%，多跳推理任务中优势更明显。

Conclusion: Graph-S3有效提升了文本图问答系统中图检索的性能，尤其在复杂多跳推理中表现优异，且代码将公开。

Abstract: A significant portion of real-world data is inherently represented as textual
graphs, and integrating these graphs into large language models (LLMs) is
promising to enable complex graph-based question answering. However, a key
challenge in LLM-based textual graph QA systems lies in graph retrieval, i.e.,
how to retrieve relevant content from large graphs that is sufficiently
informative while remaining compact for the LLM context. Existing retrievers
suffer from poor performance since they either rely on shallow embedding
similarity or employ interactive retrieving policies that demand excessive data
labeling and training cost. To address these issues, we present Graph-$S^3$, an
agentic textual graph reasoning framework that employs an LLM-based retriever
trained with synthetic stepwise supervision. Instead of rewarding the agent
based on the final answers, which may lead to sparse and unstable training
signals, we propose to closely evaluate each step of the retriever based on
offline-extracted golden subgraphs. Our main techniques include a data
synthesis pipeline to extract the golden subgraphs for reward generation and a
two-stage training scheme to learn the interactive graph exploration policy
based on the synthesized rewards. Based on extensive experiments on three
common datasets in comparison with seven strong baselines, our approach
achieves an average improvement of 8.1\% in accuracy and 9.7\% in F$_1$ score.
The advantage is even higher in more complicated multi-hop reasoning tasks. Our
code will be open-sourced.

</details>


### [3] [Implicit Values Embedded in How Humans and LLMs Complete Subjective Everyday Tasks](https://arxiv.org/abs/2510.03384)
*Arjun Arunasalam,Madison Pickering,Z. Berkay Celik,Blase Ur*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在完成日常任务时表现出的隐含价值观，与人类及不同模型之间进行比较，发现LLMs的价值观存在较大差异。


<details>
  <summary>Details</summary>
Motivation: 尽管AI助手能够帮助完成日常任务，但其所体现的隐含价值观尚不清楚，尤其是相较于人类的价值观差异。

Method: 通过对6种流行LLMs完成30个日常任务的表现进行审计，并与100名美国的人工众包者进行比较，评估隐含价值观的展示。

Result: 发现LLMs在表现隐含价值观方面往往不与人类一致，也不一致于其他LLMs，显示出较大的价值观多样性。

Conclusion: LLMs在隐含价值观上未能与人类达成一致，提示在开发和应用AI助手时需重视价值观对齐问题。

Abstract: Large language models (LLMs) can underpin AI assistants that help users with
everyday tasks, such as by making recommendations or performing basic
computation. Despite AI assistants' promise, little is known about the implicit
values these assistants display while completing subjective everyday tasks.
Humans may consider values like environmentalism, charity, and diversity. To
what extent do LLMs exhibit these values in completing everyday tasks? How do
they compare with humans? We answer these questions by auditing how six popular
LLMs complete 30 everyday tasks, comparing LLMs to each other and to 100 human
crowdworkers from the US. We find LLMs often do not align with humans, nor with
other LLMs, in the implicit values exhibited.

</details>


### [4] [Morpheme Induction for Emergent Language](https://arxiv.org/abs/2510.03439)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 提出了CSAR算法，通过权重互信息贪婪选择和去除词素，实现从平行语料中诱导词素。实验验证了其有效性和语言特征分析。


<details>
  <summary>Details</summary>
Motivation: 旨在从新兴语言的平行话语和意义中自动识别和诱导词素，提高对语言结构的理解。

Method: 设计了CSAR算法，基于词形和意义的互信息加权，贪婪选择最高权重对，移除后重复此过程以诱导词素。

Result: CSAR在程序生成的数据集和人类语言数据上均表现良好，能合理预测邻近语言域，且有效分析了新兴语言的语言学特性。

Conclusion: CSAR算法有效地自动诱导词素，适用于不同语料库，并能用于语言特征的量化分析。

Abstract: We introduce CSAR, an algorithm for inducing morphemes from emergent language
corpora of parallel utterances and meanings. It is a greedy algorithm that (1)
weights morphemes based on mutual information between forms and meanings, (2)
selects the highest-weighted pair, (3) removes it from the corpus, and (4)
repeats the process to induce further morphemes (i.e., Count, Select, Ablate,
Repeat). The effectiveness of CSAR is first validated on procedurally generated
datasets and compared against baselines for related tasks. Second, we validate
CSAR's performance on human language data to show that the algorithm makes
reasonable predictions in adjacent domains. Finally, we analyze a handful of
emergent languages, quantifying linguistic characteristics like degree of
synonymy and polysemy.

</details>


### [5] [Omni-Embed-Nemotron: A Unified Multimodal Retrieval Model for Text, Image, Audio, and Video](https://arxiv.org/abs/2510.03458)
*Mengyao Xu,Wenfei Zhou,Yauhen Babakhin,Gabriel Moreira,Ronay Ak,Radek Osmulski,Bo Liu,Even Oldridge,Benedikt Schifferer*

Main category: cs.CL

TL;DR: Omni-Embed-Nemotron是一个统一的多模态检索嵌入模型，支持文本、图像、音频和视频的跨模态和联合模态检索，提升了复杂多模态信息检索的效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本的检索器难以处理包含视觉和语义丰富内容的真实文档，如PDF、幻灯片和视频，且传统方法多依赖结构化且干净的输入。为了提升检索质量，需引入多模态信息并支持复杂文档格式。

Method: 基于保持文档布局的图像表示，结合近年来强大的多模态模型（如Qwen2.5-Omni），开发了Omni-Embed-Nemotron模型，能够统一处理文本、图像、音频和视频多种模态，实现跨模态和联合模态检索。

Result: 通过架构设计、训练流程和评估实验，Omni-Embed-Nemotron展示了其在文本、图像和视频检索任务中的有效性，提高了现实环境中多模态内容的检索性能。

Conclusion: Omni-Embed-Nemotron成功实现了多模态统一检索，解决了传统文本检索器对复杂多模态文档的不足，显著提升了多模态信息检索的适用性和准确性。

Abstract: We present Omni-Embed-Nemotron, a unified multimodal retrieval embedding
model developed to handle the increasing complexity of real-world information
needs. While Retrieval-Augmented Generation (RAG) has significantly advanced
language models by incorporating external knowledge, existing text-based
retrievers rely on clean, structured input and struggle with the visually and
semantically rich content found in real-world documents such as PDFs, slides,
or videos. Recent work such as ColPali has shown that preserving document
layout using image-based representations can improve retrieval quality.
Building on this, and inspired by the capabilities of recent multimodal models
such as Qwen2.5-Omni, we extend retrieval beyond text and images to also
support audio and video modalities. Omni-Embed-Nemotron enables both
cross-modal (e.g., text - video) and joint-modal (e.g., text - video+audio)
retrieval using a single model. We describe the architecture, training setup,
and evaluation results of Omni-Embed-Nemotron, and demonstrate its
effectiveness in text, image, and video retrieval.

</details>


### [6] [Searching for the Most Human-like Emergent Language](https://arxiv.org/abs/2510.03467)
*Brendon Boldt,David Mortensen*

Main category: cs.CL

TL;DR: 本文设计了基于信号博弈的涌现通信环境，通过超参数优化生成与人类语言相似度最高的涌现语言。


<details>
  <summary>Details</summary>
Motivation: 旨在生成具有高人类语言相似度的涌现语言，提高其在迁移学习中的表现。

Method: 利用XferBench作为目标函数进行超参数优化，评估涌现语言的统计相似性，并分析熵对迁移学习性能的预测作用。

Result: 验证了熵对迁移学习性能的预测能力，支持涌现通信系统的熵最小化特性，归纳出生成更具现实性的涌现语言的超参数规律。

Conclusion: 通过超参数优化可生成更接近人类语言的涌现语言，提升其在迁移学习中的应用潜力。

Abstract: In this paper, we design a signalling game-based emergent communication
environment to generate state-of-the-art emergent languages in terms of
similarity to human language. This is done with hyperparameter optimization,
using XferBench as the objective function. XferBench quantifies the statistical
similarity of emergent language to human language by measuring its suitability
for deep transfer learning to human language. Additionally, we demonstrate the
predictive power of entropy on the transfer learning performance of emergent
language as well as corroborate previous results on the entropy-minimization
properties of emergent communication systems. Finally, we report
generalizations regarding what hyperparameters produce more realistic emergent
languages, that is, ones which transfer better to human language.

</details>


### [7] [SEER: The Span-based Emotion Evidence Retrieval Benchmark](https://arxiv.org/abs/2510.03490)
*Aneesha Sampath,Oya Aran,Emily Mower Provost*

Main category: cs.CL

TL;DR: 本文提出了SEER基准，测试大型语言模型识别文本情感表达片段的能力。


<details>
  <summary>Details</summary>
Motivation: 传统情感识别只给整句标标签，缺乏对具体情感表达片段的定位，应用如共情对话和临床支持需要更细粒度的情感理解。

Method: 构建SEER数据集，包括单句和五句短段落的情感证据定位任务，并对1200个真实句子进行情感及情感证据标注。评测14个开源大型语言模型表现，并进行错误分析。

Result: 部分模型在单句情感证据识别上接近人类平均水平，但在多句段落中准确率下降。错误分析发现在中性文本中存在过度依赖关键词和误判。

Conclusion: SEER基准揭示了现有大型语言模型在细粒度情感证据定位上的不足，指出未来改进方向，有助于推动情感理解相关应用发展。

Abstract: We introduce the SEER (Span-based Emotion Evidence Retrieval) Benchmark to
test Large Language Models' (LLMs) ability to identify the specific spans of
text that express emotion. Unlike traditional emotion recognition tasks that
assign a single label to an entire sentence, SEER targets the underexplored
task of emotion evidence detection: pinpointing which exact phrases convey
emotion. This span-level approach is crucial for applications like empathetic
dialogue and clinical support, which need to know how emotion is expressed, not
just what the emotion is. SEER includes two tasks: identifying emotion evidence
within a single sentence, and identifying evidence across a short passage of
five consecutive sentences. It contains new annotations for both emotion and
emotion evidence on 1200 real-world sentences. We evaluate 14 open-source LLMs
and find that, while some models approach average human performance on
single-sentence inputs, their accuracy degrades in longer passages. Our error
analysis reveals key failure modes, including overreliance on emotion keywords
and false positives in neutral text.

</details>


### [8] [ALHD: A Large-Scale and Multigenre Benchmark Dataset for Arabic LLM-Generated Text Detection](https://arxiv.org/abs/2510.03502)
*Ali Khairallah,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: ALHD是第一个大规模阿拉伯语数据集，区分人类和大语言模型生成的文本，覆盖不同体裁和方言，包含40万均衡样本。


<details>
  <summary>Details</summary>
Motivation: 为了创建一个专门用于区分人类与大语言模型生成文本的阿拉伯语数据集，支持相关检测技术的研究和应用。

Method: 收集并构建包含新闻、社交媒体和评论三种体裁，涵盖现代标准阿拉伯语和方言，包含40万均衡样本，设计标准化分割和丰富标注，进行基准测试，包括传统分类器、基于BERT和大语言模型的检测。

Result: 基于BERT的微调模型表现优于零样本和少样本的大语言模型，实现了有竞争力的检测效果。但在跨体裁泛化存在挑战，尤其是在新闻体裁中，LLM生成文本与人类文本风格相似，检测难度较高。

Conclusion: ALHD为阿拉伯语大语言模型文本检测研究奠定基础，促进打击错信息、学术不端和网络威胁，未来研究需关注跨体裁泛化能力和新闻文本检测难题。

Abstract: We introduce ALHD, the first large-scale comprehensive Arabic dataset
explicitly designed to distinguish between human- and LLM-generated texts. ALHD
spans three genres (news, social media, reviews), covering both MSA and
dialectal Arabic, and contains over 400K balanced samples generated by three
leading LLMs and originated from multiple human sources, which enables studying
generalizability in Arabic LLM-genearted text detection. We provide rigorous
preprocessing, rich annotations, and standardized balanced splits to support
reproducibility. In addition, we present, analyze and discuss benchmark
experiments using our new dataset, in turn identifying gaps and proposing
future research directions. Benchmarking across traditional classifiers,
BERT-based models, and LLMs (zero-shot and few-shot) demonstrates that
fine-tuned BERT models achieve competitive performance, outperforming LLM-based
models. Results are however not always consistent, as we observe challenges
when generalizing across genres; indeed, models struggle to generalize when
they need to deal with unseen patterns in cross-genre settings, and these
challenges are particularly prominent when dealing with news articles, where
LLM-generated texts resemble human texts in style, which opens up avenues for
future research. ALHD establishes a foundation for research related to Arabic
LLM-detection and mitigating risks of misinformation, academic dishonesty, and
cyber threats.

</details>


### [9] [TS-Reasoner: Aligning Time Series Foundation Models with LLM Reasoning](https://arxiv.org/abs/2510.03519)
*Fangxu Yu,Hongyu Zhao,Tianyi Zhou*

Main category: cs.CL

TL;DR: 本文提出了TS-Reasoner，一种将时间序列基础模型（TSFMs）与大语言模型（LLMs）对齐以实现时间序列推理的框架，通过合成时间序列与文本说明的数据对进行训练，并采用两阶段训练方案，显著提升了时间序列理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型虽能捕捉动态模式并做准确预测，但缺乏复杂推理能力，且大语言模型在数值理解上存在困难。将二者结合以充分发挥各自优势，仍面临对齐训练的挑战。

Method: 提出通过合成多样的时间序列-文本对进行对齐训练，并设计两阶段训练方案：先进行对齐预训练，再进行指令微调；冻结预训练时间序列模型，仅训练大语言模型部分。

Result: 在多个基准测试中，TS-Reasoner不仅优于现有各类大语言模型、视觉语言模型和时间序列大语言模型，还具备极高的数据效率，训练数据使用量不到对比方法的一半。

Conclusion: 通过有效的对齐及训练体系，TS-Reasoner成功结合TSFMs和LLMs优势，实现了高效且强大的时间序列理解与推理能力，推动了时间序列分析技术的发展。

Abstract: Time series reasoning is crucial to decision-making in diverse domains,
including finance, energy usage, traffic, weather, and scientific discovery.
While existing time series foundation models (TSFMs) can capture low-level
dynamic patterns and provide accurate forecasting, further analysis usually
requires additional background knowledge and sophisticated reasoning, which are
lacking in most TSFMs but can be achieved through large language models (LLMs).
On the other hand, without expensive post-training, LLMs often struggle with
the numerical understanding of time series data. Although it is intuitive to
integrate the two types of models, developing effective training recipes that
align the two modalities for reasoning tasks is still an open challenge. To
this end, we propose TS-Reasoner that aligns the latent representations of
TSFMs with the textual inputs of LLMs for downstream understanding/reasoning
tasks. Specifically, we propose a simple yet effective method to curate
diverse, synthetic pairs of time series and textual captions for alignment
training. We then develop a two-stage training recipe that applies instruction
finetuning after the alignment pretraining. Unlike existing works that train an
LLM to take time series as inputs, we leverage a pretrained TSFM and freeze it
during training. Extensive experiments on several benchmarks demonstrate that
TS-Reasoner not only outperforms a wide range of prevailing LLMs, Vision
Language Models (VLMs), and Time Series LLMs, but also achieves this with
remarkable data efficiency, e.g., using less than half the training data.

</details>


### [10] [Identifying Financial Risk Information Using RAG with a Contrastive Insight](https://arxiv.org/abs/2510.03521)
*Ali Elahi*

Main category: cs.CL

TL;DR: 本文提出一种基于同行对比推理的新方法，提升检索增强生成（RAG）模型在专业领域推理任务中的表现，特别是在金融风险评估中，生成更具针对性的内容。


<details>
  <summary>Details</summary>
Motivation: 现有的RAG模型虽然能提取事实信息，但在专业推理任务中输出往往过于泛化，缺乏具体情境的洞察，无法有效对比类似案例。

Method: 在传统RAG基础上，增加一个同行感知的对比推理层，以实现对相关案例的检索和比较，增强模型的上下文理解和推理能力。

Result: 该对比推理方法在与人类生成的股权研究和风险分析文本比较时，在ROUGE和BERTScore等文本生成指标上优于传统RAG，表现更佳。

Conclusion: 引入同行对比推理层能够有效提升RAG模型在专业领域的推理表现，生成更具体且针对性的分析结论。

Abstract: In specialized domains, humans often compare new problems against similar
examples, highlight nuances, and draw conclusions instead of analyzing
information in isolation. When applying reasoning in specialized contexts with
LLMs on top of a RAG, the pipeline can capture contextually relevant
information, but it is not designed to retrieve comparable cases or related
problems.
  While RAG is effective at extracting factual information, its outputs in
specialized reasoning tasks often remain generic, reflecting broad facts rather
than context-specific insights. In finance, it results in generic risks that
are true for the majority of companies. To address this limitation, we propose
a peer-aware comparative inference layer on top of RAG.
  Our contrastive approach outperforms baseline RAG in text generation metrics
such as ROUGE and BERTScore in comparison with human-generated equity research
and risk.

</details>


### [11] [Sample, Align, Synthesize: Graph-Based Response Synthesis with ConGrs](https://arxiv.org/abs/2510.03527)
*Sayan Ghosh,Shahzaib Saqib Warraich,Dhruv Tarsadiya,Gregory Yauney,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 本文提出了一种基于有向无环图的Consensus Graphs（ConGrs）方法，通过捕捉多个语言模型长文本回答中的共享信息和语义差异，提升了回答的准确性和拒答能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以高效整合多次采样语言模型回答中的丰富认知信号，尤其是在长文本任务中。作者希望设计一种能更好地合成这些信息的结构。

Method: 引入了基于轻量级词汇序列比对的Consensus Graphs（ConGrs）数据结构，结合辅助语言模型判别器，并设计任务依赖的解码策略，从ConGrs中合成最终回答。

Result: ConGrs在两个传记生成任务中提高了事实精确度最多31%，减少了对语言模型判别器的依赖超过80%；在拒答任务中提高了拒答率最多56%；在数学推理任务中准确率较自我验证和多数投票基线提升了6个百分点。

Conclusion: Consensus Graphs有效捕捉并利用语言模型回答的语义变异性，作为一种灵活的方法显著提升了回答的准确性和任务表现。

Abstract: Language models can be sampled multiple times to access the distribution
underlying their responses, but existing methods cannot efficiently synthesize
rich epistemic signals across different long-form responses. We introduce
Consensus Graphs (ConGrs), a flexible DAG-based data structure that represents
shared information, as well as semantic variation in a set of sampled LM
responses to the same prompt. We construct ConGrs using a light-weight lexical
sequence alignment algorithm from bioinformatics, supplemented by the targeted
usage of a secondary LM judge. Further, we design task-dependent decoding
methods to synthesize a single, final response from our ConGr data structure.
Our experiments show that synthesizing responses from ConGrs improves factual
precision on two biography generation tasks by up to 31% over an average
response and reduces reliance on LM judges by more than 80% compared to other
methods. We also use ConGrs for three refusal-based tasks requiring abstention
on unanswerable queries and find that abstention rate is increased by up to
56%. We apply our approach to the MATH and AIME reasoning tasks and find an
improvement over self-verification and majority vote baselines by up to 6
points of accuracy. We show that ConGrs provide a flexible method for capturing
variation in LM responses and using the epistemic signals provided by response
variation to synthesize more effective responses.

</details>


### [12] [Fine-Tuning on Noisy Instructions: Effects on Generalization and Performance](https://arxiv.org/abs/2510.03528)
*Ahmed Alajrami,Xingwei Tan,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 本文研究通过在指令调优数据中引入扰动（如去除停用词、打乱词序）来提升大语言模型（LLMs）对指令噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明大语言模型对指令的微小措辞变化非常敏感，急需提升模型对噪声指令的抵抗力。

Method: 在指令调优阶段对输入指令进行扰动处理，并评估模型在原始和扰动指令上的表现，重点使用MMLU、BBH、GSM8K等基准测试。

Result: 实验结果显示，使用扰动后的指令调优在某些情况下能提升模型的下游任务表现，并使模型对噪声输入更具鲁棒性。

Conclusion: 在指令调优过程中引入扰动指令是提升大语言模型抗噪声能力的有效手段，应被重视和采用。

Abstract: Instruction-tuning plays a vital role in enhancing the task-solving abilities
of large language models (LLMs), improving their usability in generating
helpful responses on various tasks. However, previous work has demonstrated
that they are sensitive to minor variations in instruction phrasing. In this
paper, we explore whether introducing perturbations in instruction-tuning data
can enhance LLMs' resistance against noisy instructions. We focus on how
instruction-tuning with perturbations, such as removing stop words or shuffling
words, affects LLMs' performance on the original and perturbed versions of
widely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics
and potential shifts in model behavior. Surprisingly, our results suggest that
instruction-tuning on perturbed instructions can, in some cases, improve
downstream performance. These findings highlight the importance of including
perturbed instructions in instruction-tuning, which can make LLMs more
resilient to noisy user inputs.

</details>


### [13] [TriMediQ: A Triplet-Structured Approach for Interactive Medical Question Answering](https://arxiv.org/abs/2510.03536)
*Zhaohan Meng,Zaiqiao Meng,Siwei Liu,Iadh Ounis*

Main category: cs.CL

TL;DR: 本文提出了TriMediQ方法，通过将患者对话信息以三元组形式结构化为知识图谱，提升了大语言模型在多轮医疗问答中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在单轮医疗问答中表现优异，但实际临床问诊是多轮互动的，且对话日志中信息无明显关联，导致推理能力大幅下降。

Method: 提出TriMediQ，利用冻结的三元组生成器提取临床相关三元组，再通过可训练的图编码器和映射模块捕捉关系信息，实现基于知识图谱的多跳推理。训练分两步：先微调投影模块，冻结语言模型权重，然后在推理时利用微调模块引导多跳推理。

Result: 在两个交互式问答基准上评测，TriMediQ在iMedQA数据集上较五个基线模型最多提升了10.4%的准确率。

Conclusion: 将患者回答结构化为基于三元组的知识图谱，能显著提升多轮医疗问答的临床推理准确性，为基于大语言模型的医疗助手的实际应用提供了解决方案。

Abstract: Large Language Models (LLMs) perform strongly in static and single-turn
medical Question Answer (QA) benchmarks, yet such settings diverge from the
iterative information gathering process required in practical clinical
consultations. The MEDIQ framework addresses this mismatch by recasting the
diagnosis as an interactive dialogue between a patient and an expert system,
but the reliability of LLMs drops dramatically when forced to reason with
dialogue logs, where clinical facts appear in sentences without clear links. To
bridge this gap, we introduce TriMediQ, a triplet-structured approach that
summarises patient responses into triplets and integrates them into a Knowledge
Graph (KG), enabling multi-hop reasoning. We introduce a frozen triplet
generator that extracts clinically relevant triplets, using prompts designed to
ensure factual consistency. In parallel, a trainable projection module,
comprising a graph encoder and a projector, captures relational information
from the KG to enhance expert reasoning. TriMediQ operates in two steps: (i)
the projection module fine-tuning with all LLM weights frozen; and (ii) using
the fine-tuned module to guide multi-hop reasoning during inference. We
evaluate TriMediQ on two interactive QA benchmarks, showing that it achieves up
to 10.4\% improvement in accuracy over five baselines on the iMedQA dataset.
These results demonstrate that converting patient responses into structured
triplet-based graphs enables more accurate clinical reasoning in multi-turn
settings, providing a solution for the deployment of LLM-based medical
assistants.

</details>


### [14] [What is a protest anyway? Codebook conceptualization is still a first-order concern in LLM-era classification](https://arxiv.org/abs/2510.03541)
*Andrew Halterman,Katherine A. Keith*

Main category: cs.CL

TL;DR: 本文关注大型语言模型（LLMs）在计算社会科学中文本分类应用前后的步骤，强调概念化环节的重要性，并指出跳过该步骤会导致偏差。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究在使用LLMs进行文本分类时忽视了概念化和后续统计推断环节，容易引入系统性偏差。

Method: 通过模拟实验展示仅提高LLM准确率或事后纠偏方法无法消除由不恰当概念化引起的偏差。

Result: 模拟结果表明，概念化错误导致的偏差无法通过提升模型性能或事后调整完全纠正。

Conclusion: 提醒研究者重视概念化步骤，提供如何实现低成本、无偏且低方差下游估计的具体建议。

Abstract: Generative large language models (LLMs) are now used extensively for text
classification in computational social science (CSS). In this work, focus on
the steps before and after LLM prompting -- conceptualization of concepts to be
classified and using LLM predictions in downstream statistical inference --
which we argue have been overlooked in much of LLM-era CSS. We claim LLMs can
tempt analysts to skip the conceptualization step, creating conceptualization
errors that bias downstream estimates. Using simulations, we show that this
conceptualization-induced bias cannot be corrected for solely by increasing LLM
accuracy or post-hoc bias correction methods. We conclude by reminding CSS
analysts that conceptualization is still a first-order concern in the LLM-era
and provide concrete advice on how to pursue low-cost, unbiased, low-variance
downstream estimates.

</details>


### [15] [CCD-Bench: Probing Cultural Conflict in Large Language Model Decision-Making](https://arxiv.org/abs/2510.03553)
*Hasibur Rahman,Hanan Salam*

Main category: cs.CL

TL;DR: 该论文提出CCD-Bench基准，用于评估大型语言模型在跨文化价值冲突下的决策能力，发现模型偏向北欧和德意志文化，忽视东欧和中东北非，且价值多元性浅显。


<details>
  <summary>Details</summary>
Motivation: 现有评测多关注文化知识或单一偏见，缺乏对语言模型如何处理多元文化价值冲突的评估。

Method: 设计涵盖7个领域、2182个跨文化价值冲突难题的CCD-Bench，通过拉丁方设计减少顺序效应，测试17个非推理大型语言模型响应十个不同文化群体的选项。

Result: 模型偏好北欧和德语文化的响应，较少体现东欧、中东北非文化，参考多重文化维度但多元性不足，且决策受开发者背景影响超过地理文化背景。

Conclusion: 当前模型训练趋向共识导向，缺乏对权力谈判、权利推理及性别意识等价值的深入刻画，需要开发更多元文化视角的对齐策略。

Abstract: Although large language models (LLMs) are increasingly implicated in
interpersonal and societal decision-making, their ability to navigate explicit
conflicts between legitimately different cultural value systems remains largely
unexamined. Existing benchmarks predominantly target cultural knowledge
(CulturalBench), value prediction (WorldValuesBench), or single-axis bias
diagnostics (CDEval); none evaluate how LLMs adjudicate when multiple
culturally grounded values directly clash. We address this gap with CCD-Bench,
a benchmark that assesses LLM decision-making under cross-cultural value
conflict. CCD-Bench comprises 2,182 open-ended dilemmas spanning seven domains,
each paired with ten anonymized response options corresponding to the ten GLOBE
cultural clusters. These dilemmas are presented using a stratified Latin square
to mitigate ordering effects. We evaluate 17 non-reasoning LLMs. Models
disproportionately prefer Nordic Europe (mean 20.2 percent) and Germanic Europe
(12.4 percent), while options for Eastern Europe and the Middle East and North
Africa are underrepresented (5.6 to 5.8 percent). Although 87.9 percent of
rationales reference multiple GLOBE dimensions, this pluralism is superficial:
models recombine Future Orientation and Performance Orientation, and rarely
ground choices in Assertiveness or Gender Egalitarianism (both under 3
percent). Ordering effects are negligible (Cramer's V less than 0.10), and
symmetrized KL divergence shows clustering by developer lineage rather than
geography. These patterns suggest that current alignment pipelines promote a
consensus-oriented worldview that underserves scenarios demanding power
negotiation, rights-based reasoning, or gender-aware analysis. CCD-Bench shifts
evaluation beyond isolated bias detection toward pluralistic decision making
and highlights the need for alignment strategies that substantively engage
diverse worldviews.

</details>


### [16] [Reactive Transformer (RxT) -- Stateful Real-Time Processing for Event-Driven Reactive Language Models](https://arxiv.org/abs/2510.03561)
*Adam Filipek*

Main category: cs.CL

TL;DR: 本文提出了Reactive Transformer (RxT)架构，通过事件驱动方式和集成固定大小的短期记忆系统，显著降低了对话系统的计算复杂度，实现了低延迟的实时长对话处理。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer在对话AI中因无状态特性及计算复杂度高，导致长对话代价和延迟过大。

Method: RxT将每次对话视为独立事件，采用生成器解码器和异步记忆编码器更新固定大小的短期记忆，通过Memory Attention网络维护对话上下文，降低计算开销。

Result: RxT在合成数据上表现优异，推理延时保持常数级别，优于相似规模的无状态模型。

Conclusion: RxT架构有效克服了Transformer在长对话中的局限，实现了可扩展且经济的实时状态保持对话模型。

Abstract: The Transformer architecture has become the de facto standard for Large
Language Models (LLMs), demonstrating remarkable capabilities in language
understanding and generation. However, its application in conversational AI is
fundamentally constrained by its stateless nature and the quadratic
computational complexity ($O(L^2)$) with respect to sequence length $L$.
Current models emulate memory by reprocessing an ever-expanding conversation
history with each turn, leading to prohibitive costs and latency in long
dialogues. This paper introduces the Reactive Transformer (RxT), a novel
architecture designed to overcome these limitations by shifting from a
data-driven to an event-driven paradigm. RxT processes each conversational turn
as a discrete event in real-time, maintaining context in an integrated,
fixed-size Short-Term Memory (STM) system. The architecture features a distinct
operational cycle where a generator-decoder produces a response based on the
current query and the previous memory state, after which a memory-encoder and a
dedicated Memory Attention network asynchronously update the STM with a
representation of the complete interaction. This design fundamentally alters
the scaling dynamics, reducing the total user-facing cost of a conversation
from quadratic ($O(N^2 \cdot T)$) to linear ($O(N \cdot T)$) with respect to
the number of interactions $N$. By decoupling response generation from memory
updates, RxT achieves low latency, enabling truly real-time, stateful, and
economically viable long-form conversations. We validated our architecture with
a series of proof-of-concept experiments on synthetic data, demonstrating
superior performance and constant-time inference latency compared to a baseline
stateless model of comparable size.

</details>


### [17] [LLM, Reporting In! Medical Information Extraction Across Prompting, Fine-tuning and Post-correction](https://arxiv.org/abs/2510.03577)
*Ikram Belmadani,Parisa Nazari Hashemi,Thomas Sebbag,Benoit Favre,Guillaume Fortier,Solen Quiniou,Emmanuel Morin,Richard Dufour*

Main category: cs.CL

TL;DR: 本文介绍了一种结合大语言模型、合成数据和后处理的法语生物医学命名实体识别和健康事件抽取方法，在极少样本条件下取得较好效果。


<details>
  <summary>Details</summary>
Motivation: 在法语生物医学领域，命名实体识别和事件抽取存在数据稀缺问题，需设计高效的少样本学习策略。

Method: 针对NER，提出三种方法：1）基于GPT-4.1的上下文学习，自动选取示例并融入注释指南总结；2）微调GLiNER于合成语料并通过LLM后处理验证；3）微调LLaMA-3.1-8B-Instruct。同一ICL策略应用于事件抽取。

Result: GPT-4.1在NER任务中达到宏平均F1值61.53%，事件抽取任务中达到15.02%，表现优于其他方案。

Conclusion: 精心设计的提示策略对极低资源场景下提升大语言模型性能至关重要，证明ICL结合合成数据是有效方案。

Abstract: This work presents our participation in the EvalLLM 2025 challenge on
biomedical Named Entity Recognition (NER) and health event extraction in French
(few-shot setting). For NER, we propose three approaches combining large
language models (LLMs), annotation guidelines, synthetic data, and
post-processing: (1) in-context learning (ICL) with GPT-4.1, incorporating
automatic selection of 10 examples and a summary of the annotation guidelines
into the prompt, (2) the universal NER system GLiNER, fine-tuned on a synthetic
corpus and then verified by an LLM in post-processing, and (3) the open LLM
LLaMA-3.1-8B-Instruct, fine-tuned on the same synthetic corpus. Event
extraction uses the same ICL strategy with GPT-4.1, reusing the guideline
summary in the prompt. Results show GPT-4.1 leads with a macro-F1 of 61.53% for
NER and 15.02% for event extraction, highlighting the importance of
well-crafted prompting to maximize performance in very low-resource scenarios.

</details>


### [18] [Decoupling Task-Solving and Output Formatting in LLM Generation](https://arxiv.org/abs/2510.03595)
*Haikang Deng,Po-Nien Kung,Nanyun Peng*

Main category: cs.CL

TL;DR: 本文提出了Deco-G解码框架，通过将格式遵循和任务解决明确分离，提升大型语言模型在复杂任务中执行指令的准确性，尤其是在需同时满足推理和格式要求的情况下。


<details>
  <summary>Details</summary>
Motivation: 随着提示变得复杂，现有大型语言模型难以同时满足推理和严格格式要求，导致性能下降，因此需要一种方法明确区分任务解决与格式遵守，提升模型表现。

Method: Deco-G框架利用一个可处理的概率模型独立处理格式遵守，LLM仅处理任务指令，通过将两者的概率结合形成输出概率。引入指令感知蒸馏、灵活的trie算法和隐马尔可夫模型状态剪枝以保证效率和扩展性。

Result: 在数学推理、LLM作为评判者和事件参数抽取等多种任务中，Deco-G相比常规提示方法带来了1.0%到6.0%的相对性能提升，并且确保了格式的严格遵守。

Conclusion: Deco-G通过显式解耦格式约束和任务解决，有效提升了大型语言模型在复杂任务中处理指令的能力，为处理复杂提示提供了一个高效且可扩展的解码策略。

Abstract: Large language models (LLMs) are increasingly adept at following instructions
containing task descriptions to solve complex problems, such as mathematical
reasoning and automatic evaluation (LLM-as-a-Judge). However, as prompts grow
more complex, models often struggle to adhere to all instructions. This
difficulty is especially common when instructive prompts intertwine reasoning
directives -- specifying what the model should solve -- with rigid formatting
requirements that dictate how the solution must be presented. The entanglement
creates competing goals for the model, suggesting that more explicit separation
of these two aspects could lead to improved performance. To this front, we
introduce Deco-G, a decoding framework that explicitly decouples format
adherence from task solving. Deco-G handles format compliance with a separate
tractable probabilistic model (TPM), while prompts LLMs with only task
instructions. At each decoding step, Deco-G combines next token probabilities
from the LLM with the TPM calculated format compliance likelihood to form the
output probability. To make this approach both practical and scalable for
modern instruction-tuned LLMs, we introduce three key innovations:
instruction-aware distillation, a flexible trie-building algorithm, and HMM
state pruning for computational efficiency. We demonstrate the effectiveness of
Deco-G across a wide range of tasks with diverse format requirements, including
mathematical reasoning, LLM-as-a-judge, and event argument extraction. Overall,
our approach yields 1.0% to 6.0% relative gain over regular prompting practice
with guaranteed format compliance.

</details>


### [19] [Can an LLM Induce a Graph? Investigating Memory Drift and Context Length](https://arxiv.org/abs/2510.03611)
*Raquib Bin Yousuf,Aadyant Khatri,Shengzhe Xu,Mandar Sharma,Naren Ramakrishnan*

Main category: cs.CL

TL;DR: 本文指出当前大语言模型的评估标准过于简单，无法有效反映模型在信息密集型复杂推理任务中的表现，强调需要基于结构化关系知识推理的新评估方法。


<details>
  <summary>Details</summary>
Motivation: 目前的评估主要集中在简单的检索或续写任务，无法准确衡量模型在复杂关系推理和长上下文记忆中的能力。

Method: 通过设计基于图结构关系推理的任务，考察大语言模型从含噪自然语言中诱导结构化知识的能力，以此评估模型的有效上下文长度和遗忘倾向。

Result: 发现模型在复杂关系推理任务中，记忆漂移和上下文遗忘比现有基准测试表现得更严重，专业推理模型同样存在早期记忆漂移问题。

Conclusion: 当前大语言模型在从非结构化输入抽象结构化知识方面存在显著局限，需架构改进以提升长距离推理能力，同时为复杂推理任务提供使用建议。

Abstract: Recently proposed evaluation benchmarks aim to characterize the effective
context length and the forgetting tendencies of large language models (LLMs).
However, these benchmarks often rely on simplistic 'needle in a haystack'
retrieval or continuation tasks that may not accurately reflect the performance
of these models in information-dense scenarios. Thus, rather than simple next
token prediction, we argue for evaluating these models on more complex
reasoning tasks that requires them to induce structured relational knowledge
from the text - such as graphs from potentially noisy natural language content.
While the input text can be viewed as generated in terms of a graph, its
structure is not made explicit and connections must be induced from distributed
textual cues, separated by long contexts and interspersed with irrelevant
information. Our findings reveal that LLMs begin to exhibit memory drift and
contextual forgetting at much shorter effective lengths when tasked with this
form of relational reasoning, compared to what existing benchmarks suggest.
With these findings, we offer recommendations for the optimal use of popular
LLMs for complex reasoning tasks. We further show that even models specialized
for reasoning, such as OpenAI o1, remain vulnerable to early memory drift in
these settings. These results point to significant limitations in the models'
ability to abstract structured knowledge from unstructured input and highlight
the need for architectural adaptations to improve long-range reasoning.

</details>


### [20] [Towards Unsupervised Speech Recognition at the Syllable-Level](https://arxiv.org/abs/2510.03639)
*Liming Wang,Junrui Ni,Kai-Wei Chang,Saurabhchand Bhati,David Harwath,Mark Hasegawa-Johnson,James R. Glass*

Main category: cs.CL

TL;DR: 本文提出了一种基于音节级掩码语言模型的无监督语音识别方法，无需依赖G2P，实现了识别性能的大幅提升，尤其在普通话上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于音素的无监督语音识别方法依赖昂贵的G2P资源，且在具有模糊音素边界的语言（如普通话）上训练不稳定，难以推广。

Method: 提出了一种基于音节级掩码语言模型的无监督语音识别框架，避免了对G2P的依赖和GAN方法的不稳定性。

Result: 在LibriSpeech数据集上，所提方法在字符错误率上相较于现有方法降低了40%，并且在普通话上效果显著优于以往方法。

Conclusion: 该方法有效提升了无监督语音识别的性能，特别适用于传统方法难以处理的语言，具备较强的泛化能力。

Abstract: Training speech recognizers with unpaired speech and text -- known as
unsupervised speech recognition (UASR) -- is a crucial step toward extending
ASR to low-resource languages in the long-tail distribution and enabling
multimodal learning from non-parallel data. However, existing approaches based
on phones often rely on costly resources such as grapheme-to-phoneme converters
(G2Ps) and struggle to generalize to languages with ambiguous phoneme
boundaries due to training instability. In this paper, we address both
challenges by introducing a syllable-level UASR framework based on masked
language modeling, which avoids the need for G2P and the instability of
GAN-based methods. Our approach achieves up to a 40\% relative reduction in
character error rate (CER) on LibriSpeech and generalizes effectively to
Mandarin, a language that has remained particularly difficult for prior
methods. Code will be released upon acceptance.

</details>


### [21] [UNIDOC-BENCH: A Unified Benchmark for Document-Centric Multimodal RAG](https://arxiv.org/abs/2510.03663)
*Xiangyu Peng,Cab Qin,Zeyuan Chen,Ran Xu,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 介绍了UniDoc-Bench，一个涵盖8个领域7万真实PDF页面的大型多模态检索增强生成评测基准，包含1600个多模态问答对，用于评价多模态文本-图像融合检索方法。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索增强生成评测分散，缺乏真实文件中心多模态应用场景的综合评测。

Method: 构建包含文本、表格、图像的多模态数据集，生成并多轮验证问答对，统一四种检索范式的评测协议进行公平比较。

Result: 多模态文本-图像融合方法优于单一模态及联合嵌入检索，显示单独文本或图像不足，且现有多模态嵌入表现有限。

Conclusion: 视觉信息在补充文本证据时有效，分析发现系统性失败模式，提出改进建议，促进更鲁棒的多模态检索生成系统发展。

Abstract: Multimodal retrieval-augmented generation (MM-RAG) is a key approach for
applying large language models (LLMs) and agents to real-world knowledge bases,
yet current evaluations are fragmented, focusing on either text or images in
isolation or on simplified multimodal setups that fail to capture
document-centric multimodal use cases. In this paper, we introduce
UniDoc-Bench, the first large-scale, realistic benchmark for MM-RAG built from
70k real-world PDF pages across eight domains. Our pipeline extracts and links
evidence from text, tables, and figures, then generates 1,600 multimodal QA
pairs spanning factual retrieval, comparison, summarization, and logical
reasoning queries. To ensure reliability, 20% of QA pairs are validated by
multiple annotators and expert adjudication. UniDoc-Bench supports
apples-to-apples comparison across four paradigms: (1) text-only, (2)
image-only, (3) multimodal text-image fusion, and (4) multimodal joint
retrieval -- under a unified protocol with standardized candidate pools,
prompts, and evaluation metrics. Our experiments show that multimodal
text-image fusion RAG systems consistently outperform both unimodal and jointly
multimodal embedding-based retrieval, indicating that neither text nor images
alone are sufficient and that current multimodal embeddings remain inadequate.
Beyond benchmarking, our analysis reveals when and how visual context
complements textual evidence, uncovers systematic failure modes, and offers
actionable guidance for developing more robust MM-RAG pipelines.

</details>


### [22] [Fine-Tuning Large Language Models with QLoRA for Offensive Language Detection in Roman Urdu-English Code-Mixed Text](https://arxiv.org/abs/2510.03683)
*Nisar Hussain,Amna Qasim,Gull Mehak,Muhammad Zain,Momina Hafeez,Grigori Sidorov*

Main category: cs.CL

TL;DR: 该论文提出了一种基于QLoRA的微调方法，用于罗马乌尔都语和英语混合文本中的攻击性语言检测，利用翻译技术和大语言模型，实现了高效的低资源环境下分类性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于罗马乌尔都语和英语混合语言存在语法不明确、拼写不一致及标注数据稀缺，传统自然语言处理面临挑战，需提高攻击性语言检测的准确性。

Method: 通过将罗马乌尔都语-英语混合数据集翻译成英语，利用Google Translate，结合QLoRA对多种大语言模型和transformer进行微调，包括Meta LLaMA 3 8B、Mistral 7B等，在手动标注数据集上训练与评估。

Result: Meta LLaMA 3 8B取得了最高F1得分91.45，Mistral 7B为89.66，均优于传统的transformer基线模型，显示了QLoRA在内存高效微调低资源环境模型中的有效性。

Conclusion: 本研究展示了QLoRA微调技术提升混合语言攻击性检测的潜力，为罗马乌尔都语内容审核提供了可扩展方案，并为未来多语言攻击性语言检测奠定基础。

Abstract: The use of derogatory terms in languages that employ code mixing, such as
Roman Urdu, presents challenges for Natural Language Processing systems due to
unstated grammar, inconsistent spelling, and a scarcity of labeled data. In
this work, we propose a QLoRA based fine tuning framework to improve offensive
language detection in Roman Urdu-English text. We translated the Roman
Urdu-English code mixed dataset into English using Google Translate to leverage
English LLMs, while acknowledging that this translation reduces direct
engagement with code mixing features. Our focus is on classification
performance using English translated low resource inputs. We fine tuned several
transformers and large language models, including Meta LLaMA 3 8B, Mistral 7B
v0.1, LLaMA 2 7B, ModernBERT, and RoBERTa, with QLoRA for memory efficient
adaptation. Models were trained and evaluated on a manually annotated Roman
Urdu dataset for offensive vs non offensive content. Of all tested models, the
highest F1 score of 91.45 was attained by Meta LLaMA 3 8B, followed by Mistral
7B at 89.66, surpassing traditional transformer baselines. These results
demonstrate the efficacy of QLoRA in fine tuning high performing models for low
resource environments such as code mixed offensive language detection, and
confirm the potential of LLMs for this task. This work advances a scalable
approach to Roman Urdu moderation and paves the way for future multilingual
offensive detection systems based on LLMs.

</details>


### [23] [MedReflect: Teaching Medical LLMs to Self-Improve via Reflective Correction](https://arxiv.org/abs/2510.03687)
*Yue Huang,Yanyuan Chen,Dexuan Xu,Weihua Yue,Huamin Zhang,Meikang Qiu,Yu Huang*

Main category: cs.CL

TL;DR: 本文提出了MedReflect框架，通过模拟医生的反思思维模式，提升大型语言模型在医疗问题解决中的能力，实现无需外部检索和大量标注的高效自我验证和决策优化。


<details>
  <summary>Details</summary>
Motivation: 现有利用外部知识检索和推理数据训练的方法存在检索开销大、标注成本高、且性能有限的问题，限制了大型语言模型在医学领域的应用效果。

Method: 提出MedReflect框架，生成包含初步假设、自我提问、自我回答和决策优化的单遍反思链，实现模型自我验证和自我反思，无需外部知识辅助。

Result: 在仅使用2000个随机采样训练样本和轻度微调的情况下，MedReflect在多项医学基准测试中显著提升了准确率，同时降低了标注需求。

Conclusion: MedReflect展示了大型语言模型通过自我反思和自我提升，能够有效解决专业医学问题，显著降低对外部监督和大量特定任务微调数据的依赖。

Abstract: Medical problem solving demands expert knowledge and intricate reasoning.
Recent studies of large language models (LLMs) attempt to ease this complexity
by introducing external knowledge verification through retrieval-augmented
generation or by training on reasoning datasets. However, these approaches
suffer from drawbacks such as retrieval overhead and high annotation costs, and
they heavily rely on substituted external assistants to reach limited
performance in medical field. In this paper, we introduce MedReflect, a
generalizable framework designed to inspire LLMs with a physician-like
reflective thinking mode. MedReflect generates a single-pass reflection chain
that includes initial hypothesis generation, self-questioning, self-answering
and decision refinement. This self-verified and self-reflective nature releases
large language model's latent capability in medical problem-solving without
external retrieval or heavy annotation. We demonstrate that MedReflect enables
cost-efficient medical dataset construction: with merely 2,000 randomly sampled
training examples and a light fine-tuning, this approach achieves notable
absolute accuracy improvements across a series of medical benchmarks while
cutting annotation requirements. Our results provide evidence that LLMs can
learn to solve specialized medical problems via self-reflection and
self-improve, reducing reliance on external supervision and extensive
task-specific fine-tuning data.

</details>


### [24] [TreePrompt: Leveraging Hierarchical Few-Shot Example Selection for Improved English-Persian and English-German Translation](https://arxiv.org/abs/2510.03748)
*Ramtin Kakavand,Ebrahim Ansari*

Main category: cs.CL

TL;DR: 提出TreePrompt方法，通过树结构框架选择高质量、相关性强的示例提升大语言模型的翻译效果。


<details>
  <summary>Details</summary>
Motivation: 现有示例选择多侧重于查询和示例的相似度，忽视示例本身质量，影响翻译性能。

Method: 设计TreePrompt学习LLM偏好，在树形结构中选取高质量且上下文相关的示例，并结合K-NN和AFSP平衡相似度与质量。

Result: 在英波斯语和英德语两对语言的翻译测试中，TreePrompt结合AFSP或随机选择均显著提升了翻译性能。

Conclusion: 通过学习示例质量和相关性，TreePrompt有效增强了少样本提示中的示例选择，从而提高了大语言模型的翻译表现。

Abstract: Large Language Models (LLMs) have consistently demonstrated strong
performance in machine translation, especially when guided by high-quality
prompts. Few-shot prompting is an effective technique to improve translation
quality; however, most existing example selection methods focus solely on
query-to-example similarity and do not account for the quality of the examples.
In this work, we propose TreePrompt, a novel example selection approach that
learns LLM preferences to identify high-quality, contextually relevant examples
within a tree-structured framework. To further explore the balance between
similarity and quality, we combine TreePrompt with K-Nearest Neighbors (K-NN)
and Adaptive Few-Shot Prompting (AFSP). Evaluations on two language pairs -
English-Persian (MIZAN) and English-German (WMT19) - show that integrating
TreePrompt with AFSP or Random selection leads to improved translation
performance.

</details>


### [25] [Cross-Lingual Multi-Granularity Framework for Interpretable Parkinson's Disease Diagnosis from Speech](https://arxiv.org/abs/2510.03758)
*Ilias Tougui,Mehdi Zakroum,Mounir Ghogho*

Main category: cs.CL

TL;DR: 本文提出了一种基于语音分辨粒度的多语言帕金森病检测方法，利用自动提取音素、音节和词语的管道，通过双向LSTM和多头注意力机制实现对比，音素级别的诊断效果最佳。


<details>
  <summary>Details</summary>
Motivation: 帕金森病患者中语音障碍普遍存在，但现有检测系统多分析整句，可能忽视某些特定语音成分的诊断价值。

Method: 构建自动化管道提取时间对齐的音素、音节和词，使用意大利语、西班牙语和英语数据集，基于双向LSTM和多头注意力机制进行多粒度分析和诊断性能比较。

Result: 音素级别分析表现最佳，AUROC达到93.78%，准确率92.17%，且注意力机制定位的关键语音特征与临床协议一致。

Conclusion: 该方法实现了跨语言的帕金森病语音检测的诊断能力提升，展示了音素粒度分析在疾病检测中的重要价值。

Abstract: Parkinson's Disease (PD) affects over 10 million people worldwide, with
speech impairments in up to 89% of patients. Current speech-based detection
systems analyze entire utterances, potentially overlooking the diagnostic value
of specific phonetic elements. We developed a granularity-aware approach for
multilingual PD detection using an automated pipeline that extracts
time-aligned phonemes, syllables, and words from recordings. Using Italian,
Spanish, and English datasets, we implemented a bidirectional LSTM with
multi-head attention to compare diagnostic performance across the different
granularity levels. Phoneme-level analysis achieved superior performance with
AUROC of 93.78% +- 2.34% and accuracy of 92.17% +- 2.43%. This demonstrates
enhanced diagnostic capability for cross-linguistic PD detection. Importantly,
attention analysis revealed that the most informative speech features align
with those used in established clinical protocols: sustained vowels (/a/, /e/,
/o/, /i/) at phoneme level, diadochokinetic syllables (/ta/, /pa/, /la/, /ka/)
at syllable level, and /pataka/ sequences at word level. Source code will be
available at https://github.com/jetliqs/clearpd.

</details>


### [26] [Prompt Balance Matters: Understanding How Imbalanced Few-Shot Learning Affects Multilingual Sense Disambiguation in LLMs](https://arxiv.org/abs/2510.03762)
*Deshan Sumanathilaka,Nicholas Micallef,Julian Hough*

Main category: cs.CL

TL;DR: 本文研究了少样本提示策略对词义消歧任务的影响，发现样本分布不平衡会导致多语言模型出现错误预测，但在英语中不明显。


<details>
  <summary>Details</summary>
Motivation: 少样本提示在NLP中实用且有效，但其在多语言词义消歧任务中因样本分布不均可能引入偏差，影响模型表现。

Method: 采用GLOSSGPT提示方法，在五种语言（英语、德语、西班牙语、法语、意大利语）中测试少样本提示对词义消歧的影响，评估GPT-4o和LLaMA-3.1-70B模型表现。

Result: 发现样本分布不平衡会导致多语言词义消歧中错误的词义预测，特别是在多语言环境下，但英语表现相对稳定。

Conclusion: 多语言词义消歧任务对样本分布敏感，需设计平衡且具有代表性的提示策略以提升模型表现。

Abstract: Recent advances in Large Language Models (LLMs) have significantly reshaped
the landscape of Natural Language Processing (NLP). Among the various prompting
techniques, few-shot prompting has gained considerable attention for its
practicality and effectiveness. This study investigates how few-shot prompting
strategies impact the Word Sense Disambiguation (WSD) task, particularly
focusing on the biases introduced by imbalanced sample distributions. We use
the GLOSSGPT prompting method, an advanced approach for English WSD, to test
its effectiveness across five languages: English, German, Spanish, French, and
Italian. Our results show that imbalanced few-shot examples can cause incorrect
sense predictions in multilingual languages, but this issue does not appear in
English. To assess model behavior, we evaluate both the GPT-4o and
LLaMA-3.1-70B models and the results highlight the sensitivity of multilingual
WSD to sample distribution in few-shot settings, emphasizing the need for
balanced and representative prompting strategies.

</details>


### [27] [Rezwan: Leveraging Large Language Models for Comprehensive Hadith Text Processing: A 1.2M Corpus Development](https://arxiv.org/abs/2510.03781)
*Majid Asgari-Bidhendi,Muhammad Amin Ghaseminia,Alireza Shahbazi,Sayyed Ali Hossayni,Najmeh Torabian,Behrouz Minaei-Bidgoli*

Main category: cs.CL

TL;DR: 本文开发了Rezwan，一个包含超过120万条圣训的大规模AI辅助语料库，通过自动化流程提取和结构化数据，提供多语言翻译、智能点读、摘要和语义分析，支持数字人文和伊斯兰研究。


<details>
  <summary>Details</summary>
Motivation: 传统圣训文本处理耗时且需要大量专业知识，限制了大规模和高质量语料库的构建，亟需自动化和智能化手段提升效率和质量。

Method: 基于大型语言模型开发自动化流水线，进行文本分割、链条分离、验证和多层次扩充，同时实现机器翻译、智能点读、摘要、主题标注及语义分析，形成丰富注释的研究基础设施。

Result: 随机样本评价显示链条分离与摘要接近人工准确度，优于手工整理的Noor语料库；且在成本和时间上显著节省，表明方法经济可行。

Conclusion: 该研究展示了AI如何辅助和增强人类专业知识，实现大规模、多语种且语义丰富的宗教文本处理，推动数字人文和伊斯兰遗产研究的新范式。

Abstract: This paper presents the development of Rezwan, a large-scale AI-assisted
Hadith corpus comprising over 1.2M narrations, extracted and structured through
a fully automated pipeline. Building on digital repositories such as Maktabat
Ahl al-Bayt, the pipeline employs Large Language Models (LLMs) for
segmentation, chain--text separation, validation, and multi-layer enrichment.
Each narration is enhanced with machine translation into twelve languages,
intelligent diacritization, abstractive summarization, thematic tagging, and
cross-text semantic analysis. This multi-step process transforms raw text into
a richly annotated research-ready infrastructure for digital humanities and
Islamic studies. A rigorous evaluation was conducted on 1,213 randomly sampled
narrations, assessed by six domain experts. Results show near-human accuracy in
structured tasks such as chain--text separation (9.33/10) and summarization
(9.33/10), while highlighting ongoing challenges in diacritization and semantic
similarity detection. Comparative analysis against the manually curated Noor
Corpus demonstrates the superiority of Najm in both scale and quality, with a
mean overall score of 8.46/10 versus 3.66/10. Furthermore, cost analysis
confirms the economic feasibility of the AI approach: tasks requiring over
229,000 hours of expert labor were completed within months at a fraction of the
cost. The work introduces a new paradigm in religious text processing by
showing how AI can augment human expertise, enabling large-scale, multilingual,
and semantically enriched access to Islamic heritage.

</details>


### [28] [Mechanistic Interpretability of Socio-Political Frames in Language Models](https://arxiv.org/abs/2510.03799)
*Hadi Asghari,Sami Nenno*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在社会政治语境下生成和识别深层认知框架的能力，发现其能高效生成和零样本识别特定框架，并定位到模型隐藏表征中的关键维度。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何理解和表达具有深层认知意义的人类概念，尤其是在复杂的社会政治语境中的表现。

Method: 通过机械可解释性研究，分析模型隐藏层表示，定位与“严格父亲”和“培养型父母”认知框架高度相关的单一维度。

Result: 发现大型语言模型能够流畅生成特定认知框架相关的文本，并在零样本条件下识别这些框架，同时确定了与框架存在高度相关的隐藏维度。

Conclusion: 大型语言模型能够有效捕捉和表达深层次的认知框架，有助于理解模型中人类概念的表征机制。

Abstract: This paper explores the ability of large language models to generate and
recognize deep cognitive frames, particularly in socio-political contexts. We
demonstrate that LLMs are highly fluent in generating texts that evoke specific
frames and can recognize these frames in zero-shot settings. Inspired by
mechanistic interpretability research, we investigate the location of the
`strict father' and `nurturing parent' frames within the model's hidden
representation, identifying singular dimensions that correlate strongly with
their presence. Our findings contribute to understanding how LLMs capture and
express meaningful human concepts.

</details>


### [29] [Beyond Token Length: Step Pruner for Efficient and Accurate Reasoning in Large Language Models](https://arxiv.org/abs/2510.03805)
*Canhui Wu,Qiong Cao,Chang Li,Zhenfang Wang,Chao Xue,Yuwei Fan,Wei Xi,Xiaodong He*

Main category: cs.CL

TL;DR: 本文提出了一种名为Step Pruner (SP)的强化学习框架，用于减少大推理模型的冗长输出并提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有通过惩罚生成词元数量以促使简洁回答的方法存在两大问题：简短回答不一定反映更少的推理步骤，且模型可能通过舍弃推理步骤来规避惩罚，导致‘过度思考’问题未根本解决。

Method: 提出Step Pruner框架，设计基于推理步骤的奖励函数，强调答案正确性并对冗余步骤进行惩罚，同时对错误回答不予奖励以防止错误推理的强化学习；引入动态停止机制，防止模型通过合并步骤“做手脚”。

Result: 在四个推理基准测试中，SP不仅保持了最先进的准确率，还显著减少了回答长度，如在AIME24数据集上将词元使用量减少了69.7%。

Conclusion: Step Pruner有效解决了大推理模型中过度冗长输出的问题，实现了兼顾准确性和简洁性的高效推理表现。

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex tasks
but often suffer from excessive verbosity, known as "overthinking." Existing
solutions via reinforcement learning (RL) typically penalize generated tokens
to promote conciseness. However, these methods encounter two challenges:
responses with fewer tokens do not always correspond to fewer reasoning steps,
and models may develop hacking behavior in later stages of training by
discarding reasoning steps to minimize token usage. In this work, we introduce
\textbf{Step Pruner (SP)}, an RL framework that steers LRMs toward more
efficient reasoning by favoring compact reasoning steps. Our step-aware reward
function prioritizes correctness while imposing penalties for redundant steps,
and withholds rewards for incorrect responses to prevent the reinforcement of
erroneous reasoning. Moreover, we propose a dynamic stopping mechanism: when
the length of any output step exceeds the upper limit, we halt updates to
prevent hacking behavior caused by merging steps. Extensive experiments across
four reasoning benchmarks demonstrate that SP achieves state-of-the-art
accuracy while significantly reducing response length. For instance, on AIME24,
SP reduces token usage by \textbf{69.7\%}.

</details>


### [30] [Annotate Rhetorical Relations with INCEpTION: A Comparison with Automatic Approaches](https://arxiv.org/abs/2510.03808)
*Mehedi Hasan Emon*

Main category: cs.CL

TL;DR: 本文探讨了使用INCEpTION工具对体育报道中的修辞关系进行标注，并比较了人工标注与基于大语言模型的自动标注方法。


<details>
  <summary>Details</summary>
Motivation: 提升体育新闻中修辞关系自动识别的准确性，促进话语解析与基于变换器的自然语言处理技术的结合。

Method: 使用BERT、DistilBERT和逻辑回归模型对克里ケット新闻中的修辞关系（如详述、对比、背景和因果）进行分类，并与人工标注结果比较。

Result: DistilBERT模型表现最佳，准确率最高，证明其在高效预测话语关系中的潜力。

Conclusion: 基于变换器的模型特别是DistilBERT在体育报道话语修辞关系自动标注中表现优异，为相关领域的研究提供了有力支持。

Abstract: This research explores the annotation of rhetorical relations in discourse
using the INCEpTION tool and compares manual annotation with automatic
approaches based on large language models. The study focuses on sports reports
(specifically cricket news) and evaluates the performance of BERT, DistilBERT,
and Logistic Regression models in classifying rhetorical relations such as
elaboration, contrast, background, and cause-effect. The results show that
DistilBERT achieved the highest accuracy, highlighting its potential for
efficient discourse relation prediction. This work contributes to the growing
intersection of discourse parsing and transformer-based NLP. (This paper was
conducted as part of an academic requirement under the supervision of Prof. Dr.
Ralf Klabunde, Linguistic Data Science Lab, Ruhr University Bochum.) Keywords:
Rhetorical Structure Theory, INCEpTION, BERT, DistilBERT, Discourse Parsing,
NLP.

</details>


### [31] [Read Between the Lines: A Benchmark for Uncovering Political Bias in Bangla News Articles](https://arxiv.org/abs/2510.03898)
*Nusrat Jahan Lia,Shubhashis Roy Dipta,Abdullah Khan Zehady,Naymul Islam,Madhusodan Chakraborty,Abdullah Al Wasif*

Main category: cs.CL

TL;DR: 本文介绍了一个用于孟加拉语政治立场检测的首个基准数据集，涵盖200篇新闻，标注政府倾向、政府批评和中立立场，并对28个大语言模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语政治媒体偏见检测缺乏标注数据和计算研究，政治立场检测需要考虑语言线索和文化背景。

Method: 构建200篇孟加拉语新闻数据集并标注政治立场，设计诊断分析评估28个大型语言模型。

Result: 模型在检测政府批评内容表现较好，F1最高达0.83，但对中立文章表现差，最低F1为0，且模型易过度预测政府倾向立场。

Conclusion: 所构建的数据集和诊断测试为提升孟加拉语政治立场检测研究和改进大语言模型在低资源语言中的表现提供了基础。

Abstract: Detecting media bias is crucial, specifically in the South Asian region.
Despite this, annotated datasets and computational studies for Bangla political
bias research remain scarce. Crucially because, political stance detection in
Bangla news requires understanding of linguistic cues, cultural context, subtle
biases, rhetorical strategies, code-switching, implicit sentiment, and
socio-political background. To address this, we introduce the first benchmark
dataset of 200 politically significant and highly debated Bangla news articles,
labeled for government-leaning, government-critique, and neutral stances,
alongside diagnostic analyses for evaluating large language models (LLMs). Our
comprehensive evaluation of 28 proprietary and open-source LLMs shows strong
performance in detecting government-critique content (F1 up to 0.83) but
substantial difficulty with neutral articles (F1 as low as 0.00). Models also
tend to over-predict government-leaning stances, often misinterpreting
ambiguous narratives. This dataset and its associated diagnostics provide a
foundation for advancing stance detection in Bangla media research and offer
insights for improving LLM performance in low-resource languages.

</details>


### [32] [PsycholexTherapy: Simulating Reasoning in Psychotherapy with Small Language Models in Persian](https://arxiv.org/abs/2510.03913)
*Mohammad Amin Abbasi,Hassan Naderi*

Main category: cs.CL

TL;DR: 本文提出了PsychoLexTherapy框架，用于使用小型语言模型在波斯语中模拟心理治疗推理，重点解决多轮对话中结构化记忆和文化适应性问题，并实现本地部署保障隐私。


<details>
  <summary>Details</summary>
Motivation: 针对低资源语言中开发具有文化基础和治疗连贯性的对话系统的挑战，尤其注重多轮互动中的结构化记忆和隐私保护。

Method: 通过评估心理知识、设计专注于推理的框架，以及构建两种波斯语评估数据集，比较不同促进方法（简单提示、多代理辩论、结构化推理路径）；并优化选用模型实现准确性、效率及隐私的平衡。

Result: PsychoLexTherapy在自动和人工评估中均优于基线模型，单轮对话中表现最佳；多轮对话测试显示结构化记忆模块显著提升了同理心、一致性、文化契合度和个性化。

Conclusion: PsychoLexTherapy为波斯语心理治疗模拟提供了实用、隐私保护及文化契合的基础，贡献了新数据集、可复现评估流程和关于结构化记忆的经验洞见。

Abstract: This study presents PsychoLexTherapy, a framework for simulating
psychotherapeutic reasoning in Persian using small language models (SLMs). The
framework tackles the challenge of developing culturally grounded,
therapeutically coherent dialogue systems with structured memory for multi-turn
interactions in underrepresented languages. To ensure privacy and feasibility,
PsychoLexTherapy is optimized for on-device deployment, enabling use without
external servers. Development followed a three-stage process: (i) assessing
SLMs psychological knowledge with PsychoLexEval; (ii) designing and
implementing the reasoning-oriented PsychoLexTherapy framework; and (iii)
constructing two evaluation datasets-PsychoLexQuery (real Persian user
questions) and PsychoLexDialogue (hybrid simulated sessions)-to benchmark
against multiple baselines. Experiments compared simple prompting, multi-agent
debate, and structured therapeutic reasoning paths. Results showed that
deliberate model selection balanced accuracy, efficiency, and privacy. On
PsychoLexQuery, PsychoLexTherapy outperformed all baselines in automatic
LLM-as-a-judge evaluation and was ranked highest by human evaluators in a
single-turn preference study. In multi-turn tests with PsychoLexDialogue, the
long-term memory module proved essential: while naive history concatenation
caused incoherence and information loss, the full framework achieved the
highest ratings in empathy, coherence, cultural fit, and personalization.
Overall, PsychoLexTherapy establishes a practical, privacy-preserving, and
culturally aligned foundation for Persian psychotherapy simulation,
contributing novel datasets, a reproducible evaluation pipeline, and empirical
insights into structured memory for therapeutic reasoning.

</details>


### [33] [Mapping Patient-Perceived Physician Traits from Nationwide Online Reviews with LLMs](https://arxiv.org/abs/2510.03997)
*Junjie Luo,Rui Han,Arshana Welivita,Zeleikun Di,Jingfu Wu,Xuzhe Zhi,Ritu Agarwal,Gordon Gao*

Main category: cs.CL

TL;DR: 本文利用大语言模型分析了410万条患者对美国医生的评价，推断医生的五大人格特质及患者主观判断，验证了方法的有效性，揭示了医生评分的性别差异及不同科室特点，并通过聚类识别了四种医生类型。


<details>
  <summary>Details</summary>
Motivation: 理解患者如何看待医生对于提升信任、沟通和满意度非常重要，现有研究缺乏大规模、自动化的个性特质评估方法。

Method: 基于大语言模型构建分析流程，从患者评价中推断五大人格特质和五个主观判断，采用多模型比较和人工专家标注进行验证，进行国家级数据分析及聚类研究。

Result: 方法与人工评估高度相关（相关系数0.72-0.89），与患者满意度显著相关（r=0.41-0.81）；发现男性医生评分普遍较高，且不同科室呈现共情等特质差异，所有特质均正向预测总体满意度；识别出四种医生类型。

Conclusion: 自动化从患者叙述中提取医生个性特质的方法有效可靠，能大规模解读医患关系，有助于医疗质量评估、偏见检测及人才发展。

Abstract: Understanding how patients perceive their physicians is essential to
improving trust, communication, and satisfaction. We present a large language
model (LLM)-based pipeline that infers Big Five personality traits and five
patient-oriented subjective judgments. The analysis encompasses 4.1 million
patient reviews of 226,999 U.S. physicians from an initial pool of one million.
We validate the method through multi-model comparison and human expert
benchmarking, achieving strong agreement between human and LLM assessments
(correlation coefficients 0.72-0.89) and external validity through correlations
with patient satisfaction (r = 0.41-0.81, all p<0.001). National-scale analysis
reveals systematic patterns: male physicians receive higher ratings across all
traits, with largest disparities in clinical competence perceptions;
empathy-related traits predominate in pediatrics and psychiatry; and all traits
positively predict overall satisfaction. Cluster analysis identifies four
distinct physician archetypes, from "Well-Rounded Excellent" (33.8%, uniformly
high traits) to "Underperforming" (22.6%, consistently low). These findings
demonstrate that automated trait extraction from patient narratives can provide
interpretable, validated metrics for understanding physician-patient
relationships at scale, with implications for quality measurement, bias
detection, and workforce development in healthcare.

</details>


### [34] [Simulating and Understanding Deceptive Behaviors in Long-Horizon Interactions](https://arxiv.org/abs/2510.03999)
*Yang Xu,Xuanming Zhang,Min-Hsuan Yeh,Jwala Dhamala,Ousmane Dia,Rahul Gupta,Yixuan Li*

Main category: cs.CL

TL;DR: 本文提出了一个用于评估大型语言模型（LLMs）长期交互中欺骗行为的多智能体模拟框架，发现欺骗行为随压力增加且损害信任。


<details>
  <summary>Details</summary>
Motivation: 当前关于LLMs欺骗的研究多集中在单轮提示，缺少对欺骗策略在长时间、多任务互动中的分析。

Method: 构建一个多智能体系统，包括执行任务的执行者、评估并反馈的监督者及独立的欺骗审计员，模拟动态任务压力下的互动，评估欺骗行为。

Result: 通过11个前沿模型的实验，发现欺骗行为因模型而异，压力越大欺骗越多，且持续降低监督者的信任，识别出隐藏、含糊其辞和伪造等不同欺骗策略。

Conclusion: 欺骗是LLMs长期交互中的潜在风险，本文框架为未来在真实、需信任的环境中评估LLMs提供了基础。

Abstract: Deception is a pervasive feature of human communication and an emerging
concern in large language models (LLMs). While recent studies document
instances of LLM deception under pressure, most evaluations remain confined to
single-turn prompts and fail to capture the long-horizon interactions in which
deceptive strategies typically unfold. We introduce the first simulation
framework for probing and evaluating deception in LLMs under extended sequences
of interdependent tasks and dynamic contextual pressures. Our framework
instantiates a multi-agent system: a performer agent tasked with completing
tasks and a supervisor agent that evaluates progress, provides feedback, and
maintains evolving states of trust. An independent deception auditor then
reviews full trajectories to identify when and how deception occurs. We conduct
extensive experiments across 11 frontier models, spanning both closed- and
open-source systems, and find that deception is model-dependent, increases with
event pressure, and consistently erodes supervisor trust. Qualitative analyses
further reveal distinct strategies of concealment, equivocation, and
falsification. Our findings establish deception as an emergent risk in
long-horizon interactions and provide a foundation for evaluating future LLMs
in real-world, trust-sensitive contexts.

</details>


### [35] [Named Entity Recognition in COVID-19 tweets with Entity Knowledge Augmentation](https://arxiv.org/abs/2510.04001)
*Xuankang Zhang,Jiangming Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的命名实体知识增强方法，用于解决COVID-19社交媒体文本中命名实体识别（NER）的问题，提升了模型在少样本和全监督条件下的性能。


<details>
  <summary>Details</summary>
Motivation: COVID-19疫情期间社交媒体上的文本非正式且标注稀缺，导致传统命名实体识别模型难以有效识别疫情相关实体；此外，NER任务需要大量领域知识。

Method: 提出一种命名实体知识增强方法，结合领域特定知识，适用于非正式的社交媒体文本和正式的生物医学文本，实现对COVID-19及一般生物医学实体的识别。

Result: 在COVID-19推文数据集和PubMed数据集上的实验结果表明，该方法在全监督和少样本设置下均显著提升了命名实体识别性能。

Conclusion: 该实体知识增强方法有效解决了疫情相关命名实体识别的挑战，具有较强的泛化能力，并且开源了代码，便于后续研究应用。

Abstract: The COVID-19 pandemic causes severe social and economic disruption around the
world, raising various subjects that are discussed over social media.
Identifying pandemic-related named entities as expressed on social media is
fundamental and important to understand the discussions about the pandemic.
However, there is limited work on named entity recognition on this topic due to
the following challenges: 1) COVID-19 texts in social media are informal and
their annotations are rare and insufficient to train a robust recognition
model, and 2) named entity recognition in COVID-19 requires extensive
domain-specific knowledge. To address these issues, we propose a novel entity
knowledge augmentation approach for COVID-19, which can also be applied in
general biomedical named entity recognition in both informal text format and
formal text format. Experiments carried out on the COVID-19 tweets dataset and
PubMed dataset show that our proposed entity knowledge augmentation improves
NER performance in both fully-supervised and few-shot settings. Our source code
is publicly available: https://github.com/kkkenshi/LLM-EKA/tree/master

</details>


### [36] [AgriGPT-VL: Agricultural Vision-Language Understanding Suite](https://arxiv.org/abs/2510.04002)
*Bo Yang,Yunkui Chen,Lanfei Feng,Yu Zhang,Xiao Xu,Jianyu Zhang,Nueraili Aierken,Runhe Huang,Hongjian Lin,Yibin Ying,Shijian Li*

Main category: cs.CL

TL;DR: 本文提出了农业领域的多模态大语言模型框架AgriGPT-VL Suite，包括大型农业视觉语言数据集Agri-3M-VL、专门训练的多模态模型AgriGPT-VL及评估套件AgriBench-VL-4K。


<details>
  <summary>Details</summary>
Motivation: 当前农业多模态模型缺乏具备农业领域特色的模型、丰富的视觉语言数据集和严格的评估手段，限制了农业应用的发展。

Method: 构建了规模庞大的农业视觉语言数据集，设计了分阶段训练策略（文本定位、多模态对齐和强化学习微调）以提升模型多模态推理能力，同时保持文本处理能力。

Result: 所提出的AgriGPT-VL在农业评测套件AgriBench-VL-4K上优于通用多模态模型，且在文本任务上能力无明显下降。消融实验验证了模型各训练阶段的贡献。

Conclusion: AgriGPT-VL Suite为农业多模态研究提供了药力强大的工具和数据资源，支持低资源农业环境中的研究与应用，将开源以促进可复现性和应用推广。

Abstract: Despite rapid advances in multimodal large language models, agricultural
applications remain constrained by the scarcity of domain-tailored models,
curated vision-language corpora, and rigorous evaluation. To address these
challenges, we present the AgriGPT-VL Suite, a unified multimodal framework for
agriculture. Our contributions are threefold. First, we introduce Agri-3M-VL,
the largest vision-language corpus for agriculture to our knowledge, curated by
a scalable multi-agent data generator; it comprises 1M image-caption pairs, 2M
image-grounded VQA pairs, 50K expert-level VQA instances, and 15K GRPO
reinforcement learning samples. Second, we develop AgriGPT-VL, an
agriculture-specialized vision-language model trained via a progressive
curriculum of textual grounding, multimodal shallow/deep alignment, and GRPO
refinement. This method achieves strong multimodal reasoning while preserving
text-only capability. Third, we establish AgriBench-VL-4K, a compact yet
challenging evaluation suite with open-ended and image-grounded questions,
paired with multi-metric evaluation and an LLM-as-a-judge framework.
Experiments show that AgriGPT-VL outperforms leading general-purpose VLMs on
AgriBench-VL-4K, achieving higher pairwise win rates in the LLM-as-a-judge
evaluation. Meanwhile, it remains competitive on the text-only AgriBench-13K
with no noticeable degradation of language ability. Ablation studies further
confirm consistent gains from our alignment and GRPO refinement stages. We will
open source all of the resources to support reproducible research and
deployment in low-resource agricultural settings.

</details>


### [37] [LLM Microscope: What Model Internals Reveal About Answer Correctness and Context Utilization](https://arxiv.org/abs/2510.04013)
*Jiarui Liu,Jivitesh Jain,Mona Diab,Nishant Subramani*

Main category: cs.CL

TL;DR: 本文通过分析大语言模型（LLMs）的中间激活信号，预测其输出的正确性，并评估外部上下文信息对生成准确性的影响，实现了约75%的正确率提前审计，优于基于提示的传统方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型功能强大，但其生成信息的准确性和可信度仍存在重大问题，尤其是如何判断何时利用外部上下文能提升准确性，以及如何评估上下文的有效性。

Method: 本文利用模型的中间层激活，对首个输出标记进行分类训练，区分输出的正确与否，同时提出度量指标区分正确、错误和无关的上下文，实验中涵盖六种不同模型。

Result: 使用模型内部激活训练的简单分类器实现了约75%的输出正确性预测准确率，在区分上下文有效性方面显著优于基于提示的比较方法，能有效防止因上下文污染带来的错误。

Conclusion: 模型内部的激活信号包含丰富信息，可以用于提升大语言模型输出的可信度，促进对模型决策过程的深入理解，为提升LLMs的可靠性提供新视角。

Abstract: Although large language models (LLMs) have tremendous utility,
trustworthiness is still a chief concern: models often generate incorrect
information with high confidence. While contextual information can help guide
generation, identifying when a query would benefit from retrieved context and
assessing the effectiveness of that context remains challenging. In this work,
we operationalize interpretability methods to ascertain whether we can predict
the correctness of model outputs from the model's activations alone. We also
explore whether model internals contain signals about the efficacy of external
context. We consider correct, incorrect, and irrelevant context and introduce
metrics to distinguish amongst them. Experiments on six different models reveal
that a simple classifier trained on intermediate layer activations of the first
output token can predict output correctness with about 75% accuracy, enabling
early auditing. Our model-internals-based metric significantly outperforms
prompting baselines at distinguishing between correct and incorrect context,
guarding against inaccuracies introduced by polluted context. These findings
offer a lens to better understand the underlying decision-making processes of
LLMs. Our code is publicly available at
https://github.com/jiarui-liu/LLM-Microscope

</details>


### [38] [Thai Semantic End-of-Turn Detection for Real-Time Voice Agents](https://arxiv.org/abs/2510.04016)
*Thanapol Popit,Natthapath Rungseesiripak,Monthol Charattrakool,Saksorn Ruangtanusak*

Main category: cs.CL

TL;DR: 本文研究了泰语文本端点检测，以实现语音交互中的快速响应，比较了小型语言模型的零样本与少样本提示与轻量级变换器的有监督微调方法。


<details>
  <summary>Details</summary>
Motivation: 传统的音频静音端点检测方式延迟高且在犹豫或语言特定现象下表现不佳，亟需针对泰语的高效端点检测方案以实现流畅的语音交互。

Method: 利用YODAS语料库的转录字幕和泰语特有的语言线索（如句末助词），将端点检测定义为对标记边界的二分类任务，比较零样本、少样本提示与轻量级变换器的有监督微调效果。

Result: 实验显示存在明显的准确率与延迟之间的权衡，小型微调模型能够实现近乎实时的端点决策，适用于设备端应用。

Conclusion: 本研究确立了泰语文本端点检测的基线，证明了小型微调模型能够满足实时语音交互的需求，且实现方案适合公共应用部署。

Abstract: Fluid voice-to-voice interaction requires reliable and low-latency detection
of when a user has finished speaking. Traditional audio-silence end-pointers
add hundreds of milliseconds of delay and fail under hesitations or
language-specific phenomena. We present, to our knowledge, the first systematic
study of Thai text-only end-of-turn (EOT) detection for real-time agents. We
compare zero-shot and few-shot prompting of compact LLMs to supervised
fine-tuning of lightweight transformers. Using transcribed subtitles from the
YODAS corpus and Thai-specific linguistic cues (e.g., sentence-final
particles), we formulate EOT as a binary decision over token boundaries. We
report a clear accuracy-latency tradeoff and provide a public-ready
implementation plan. This work establishes a Thai baseline and demonstrates
that small, fine-tuned models can deliver near-instant EOT decisions suitable
for on-device agents.

</details>


### [39] [Does Using Counterfactual Help LLMs Explain Textual Importance in Classification?](https://arxiv.org/abs/2510.04031)
*Nelvin Tan,James Asikin Cheung,Yu-Ching Shih,Dong Yang,Amol Salunkhe*

Main category: cs.CL

TL;DR: 本文研究了在文本分类任务中，利用反事实推理解释大型语言模型（LLMs）决策的方法，提出了决策变化率框架评估关键词重要性，实验表明反事实推理有助于提高解释效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本分类表现出色，但作为黑箱模型且调用成本高，如何有效解释其分类决策成为实际需求。

Method: 提出了利用反事实推理结合决策变化率框架，量化对分类影响最大的关键字，以解释LLM的分类理由。

Result: 实验结果显示，结合反事实推理的方法能够更好地识别出对分类结果贡献最大的关键词，提高了解释的有效性。

Conclusion: 引入反事实推理帮助理解大型语言模型的分类决策，提供了一个经济高效的解释方法，对提升模型透明度具有积极意义。

Abstract: Large language models (LLMs) are becoming useful in many domains due to their
impressive abilities that arise from large training datasets and large model
sizes. More recently, they have been shown to be very effective in textual
classification tasks, motivating the need to explain the LLMs' decisions.
Motivated by practical constrains where LLMs are black-boxed and LLM calls are
expensive, we study how incorporating counterfactuals into LLM reasoning can
affect the LLM's ability to identify the top words that have contributed to its
classification decision. To this end, we introduce a framework called the
decision changing rate that helps us quantify the importance of the top words
in classification. Our experimental results show that using counterfactuals can
be helpful.

</details>


### [40] [Small Language Models for Emergency Departments Decision Support: A Benchmark Study](https://arxiv.org/abs/2510.04032)
*Zirui Wang,Jiajun Wu,Braden Teitge,Jessalyn Holodinsky,Steve Drew*

Main category: cs.CL

TL;DR: 本文研究了小型语言模型（SLMs）在急诊科医疗决策支持中的应用，发现普通领域训练的SLMs性能优于专门医学调优的模型。


<details>
  <summary>Details</summary>
Motivation: 急诊环境紧张且设备有限，需高效、及时的信息处理，SLMs因参数较少且推理能力强，适合实际部署，且考虑硬件、成本和隐私限制。

Method: 提出综合基准测试，选用结合通用和医学语料训练的SLMs，利用MedMCQA、MedQA-4Options和PubMedQA等数据集进行评测，模拟急诊医生的日常任务。

Result: 实验结果显示，通用领域的SLMs在急诊决策支持任务中表现超越专门医学调优的模型。

Conclusion: 急诊科不必依赖专门医学调优的小型语言模型，通用领域训练的SLMs已能满足实际需求，具备更好的适用性和部署优势。

Abstract: Large language models (LLMs) have become increasingly popular in medical
domains to assist physicians with a variety of clinical and operational tasks.
Given the fast-paced and high-stakes environment of emergency departments
(EDs), small language models (SLMs), characterized by a reduction in parameter
count compared to LLMs, offer significant potential due to their inherent
reasoning capability and efficient performance. This enables SLMs to support
physicians by providing timely and accurate information synthesis, thereby
improving clinical decision-making and workflow efficiency. In this paper, we
present a comprehensive benchmark designed to identify SLMs suited for ED
decision support, taking into account both specialized medical expertise and
broad general problem-solving capabilities. In our evaluations, we focus on
SLMs that have been trained on a mixture of general-domain and medical corpora.
A key motivation for emphasizing SLMs is the practical hardware limitations,
operational cost constraints, and privacy concerns in the typical real-world
deployments. Our benchmark datasets include MedMCQA, MedQA-4Options, and
PubMedQA, with the medical abstracts dataset emulating tasks aligned with real
ED physicians' daily tasks. Experimental results reveal that general-domain
SLMs surprisingly outperform their medically fine-tuned counterparts across
these diverse benchmarks for ED. This indicates that for ED, specialized
medical fine-tuning of the model may not be required.

</details>


### [41] [Exploring Chain-of-Thought Reasoning for Steerable Pluralistic Alignment](https://arxiv.org/abs/2510.04045)
*Yunfan Zhang,Kathleen McKeown,Smaranda Muresan*

Main category: cs.CL

TL;DR: 本文研究了如何利用链式思维（CoT）推理技术构建可调控的多元价值观大语言模型，比较了多种训练方法，发现基于可验证奖励的强化学习（RLVR）效果最佳。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型通常只能反映单一价值观，限制了它们对需要理解细微人类视角任务的适用性，因此亟需开发支持‘可调控多元价值观’的模型。

Method: 本文探讨了多种实现方法，包括CoT提示、基于人类撰写CoT的微调、合成解释的微调及基于可验证奖励的强化学习（RLVR）。

Result: 在Value Kaleidoscope和OpinionQA数据集上的实验结果表明，RLVR方法不仅性能优越，而且训练样本效率高。同时对生成的CoT路径的真实性和安全性进行了分析。

Conclusion: 链式思维技术能够有效促进多元价值观语言模型的构建，RLVR方法表现最优，具备较强的实际应用潜力。

Abstract: Large Language Models (LLMs) are typically trained to reflect a relatively
uniform set of values, which limits their applicability to tasks that require
understanding of nuanced human perspectives. Recent research has underscored
the importance of enabling LLMs to support steerable pluralism -- the capacity
to adopt a specific perspective and align generated outputs with it. In this
work, we investigate whether Chain-of-Thought (CoT) reasoning techniques can be
applied to building steerable pluralistic models. We explore several methods,
including CoT prompting, fine-tuning on human-authored CoT, fine-tuning on
synthetic explanations, and Reinforcement Learning with Verifiable Rewards
(RLVR). We evaluate these approaches using the Value Kaleidoscope and OpinionQA
datasets. Among the methods studied, RLVR consistently outperforms others and
demonstrates strong training sample efficiency. We further analyze the
generated CoT traces with respect to faithfulness and safety.

</details>


### [42] [What Makes Diffusion Language Models Super Data Learners?](https://arxiv.org/abs/2510.04071)
*Zitian Gao,Haoming Luo,Lynx Chen,Jason Klein Liu,Ran Tao,Joey Zhou,Bryan Dai*

Main category: cs.CL

TL;DR: 本文通过消融实验研究了扩散语言模型在有限数据下高效利用数据的机制，发现随机掩码输入标记是关键因素，并且多层感知机的dropout和权重衰减也能带来类似提升，说明随机正则化普遍增强了多轮训练的数据效率。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散语言模型在有限数据条件下表现出色的数据效率，但其背后的机制尚不明确，需要深入探究。

Method: 本文通过大量消融实验分析不同因素对数据效率的贡献，包括随机掩码输入标记、MLP dropout和权重衰减等，评估其在多轮训练中的影响。

Result: 实验表明，随机掩码输入标记是实现数据效率提升的主要因素，且MLP dropout和权重衰减同样能够带来类似的数据效率提升效果。

Conclusion: 随机正则化方法（如输入随机掩码、MLP dropout和权重衰减）在多轮训练中广泛增强了语言模型的数据效率，揭示了其高效利用有限数据的根本原因。

Abstract: Recent studies have shown that diffusion language models achieve remarkable
data efficiency under limited-data constraints, yet the underlying mechanisms
remain unclear. In this work, we perform extensive ablation experiments to
disentangle the sources of this efficiency. Our results show that random
masking of input tokens plays the dominant role. We further show that similar
gains can be obtained through in MLP dropout and weight decay, indicating that
stochastic regularization broadly enhances data efficiency in multi-epoch
training. Our code is available at
https://github.com/zitian-gao/data-efficiency.

</details>


### [43] [PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity](https://arxiv.org/abs/2510.04080)
*Zixin Song,Bowen Zhang,Qian-Wen Zhang,Di Yin,Xing Sun,Chunping Li*

Main category: cs.CL

TL;DR: 本文提出了PoLi-RL，一种用于条件语义文本相似度评估的新型点到列表强化学习框架，通过创新的并行切片排序奖励机制，实现了细粒度的评分优化，显著提升了相关任务的排名性能。


<details>
  <summary>Details</summary>
Motivation: 传统的条件语义文本相似度(C-STS)方法大多是判别模型，未能充分利用大语言模型和强化学习最新进展。强化学习能够优化非可导的Spearman排名指标并引导推理过程，但直接应用失败，因奖励信号复杂粗糙。

Method: 提出PoLi-RL框架，采用两阶段课程学习：先用简单点奖励训练基础评分能力，再使用混合奖励（点、对、列表）精细区分语义。设计了并行切片排序奖励(PSRR)，在不同样本的同索引完成间并行计算排序奖励，实现精准的信号分配和优化。

Result: 在官方C-STS基准测试中，PoLi-RL实现了48.18的Spearman相关系数，刷新了跨编码器架构的最佳性能。

Conclusion: 首次成功将强化学习应用于C-STS任务，PoLi-RL为利用大语言模型处理复杂排名条件判断任务提供了一个高效精准的新范式。

Abstract: Conditional Semantic Textual Similarity (C-STS) measures the semantic
proximity between text segments under a specific condition, thereby overcoming
the ambiguity inherent in traditional STS. However, existing methods are
largely confined to discriminative models, failing to fully integrate recent
breakthroughs in the NLP community concerning Large Language Models (LLMs) and
Reinforcement Learning (RL). RL is a particularly well-suited paradigm for this
task, as it can directly optimize the non-differentiable Spearman ranking
metric and guide the reasoning process required by C-STS. However, we find that
naively applying listwise RL fails to produce meaningful improvements, as the
model is overwhelmed by complex, coarse-grained reward signals. To address this
challenge, we introduce PoLi-RL, a novel Point-to-List Reinforcement Learning
framework. PoLi-RL employs a two-stage curriculum: it first trains the model
with simple pointwise rewards to establish fundamental scoring capabilities,
then transitions to a hybrid reward that combines pointwise, pairwise, and
listwise objectives to refine the model's ability to discern subtle semantic
distinctions. Crucially, we propose an innovative Parallel Slice Ranking Reward
(PSRR) mechanism that computes ranking rewards in parallel slices, where each
slice comprises same-indexed completions from different samples. This provides
a precise, differentiated learning signal for each individual completion,
enabling granular credit assignment and effective optimization. On the official
C-STS benchmark, PoLi-RL achieves a Spearman correlation coefficient of 48.18,
establishing a new SOTA for the cross-encoder architecture. As the first work
to successfully apply RL to C-STS, our study introduces a powerful and precise
paradigm for training LLMs on complex, ranking-based conditional judgment
tasks.

</details>


### [44] [Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model Reasoning](https://arxiv.org/abs/2510.04081)
*Honglin Lin,Qizhi Pei,Xin Gao,Zhuoshi Pan,Yu Li,Juntao Li,Conghui He,Lijun Wu*

Main category: cs.CL

TL;DR: 本文提出了Caco框架，通过代码驱动的数据增强自动生成高质量、多样化且可验证的推理链数据，提升大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统Chain-of-Thought推理方法存在生成质量不高、推理路径多样性不足和难以保证生成逻辑正确性的问题，且现有基于代码的推理增强方法多限于预定义数学题，缺乏扩展性和通用性。

Method: Caco先基于统一代码格式对现有数学和编程解答进行微调生成器训练，随后自动大规模生成多样推理链，并通过代码执行验证和规则过滤确保推理的逻辑正确与结构多样度，最后将输出反向转为自然语言指令和推理链以增强任务适应性，实现闭环自动生成。

Result: 在新构建的Caco-1.3M数据集上训练的模型在数学推理基准上表现优异，超越当前强基线模型。

Conclusion: Caco构建了无需人工干预即可自动且可靠地合成推理数据的范式，通过代码锚定验证和丰富指令多样性显著增强模型推理的泛化能力，为可信自动推理系统奠定基础。

Abstract: Reasoning capability is pivotal for Large Language Models (LLMs) to solve
complex tasks, yet achieving reliable and scalable reasoning remains
challenging. While Chain-of-Thought (CoT) prompting has become a mainstream
approach, existing methods often suffer from uncontrolled generation,
insufficient quality, and limited diversity in reasoning paths. Recent efforts
leverage code to enhance CoT by grounding reasoning in executable steps, but
such methods are typically constrained to predefined mathematical problems,
hindering scalability and generalizability. In this work, we propose Caco
(Code-Assisted Chain-of-ThOught), a novel framework that automates the
synthesis of high-quality, verifiable, and diverse instruction-CoT reasoning
data through code-driven augmentation. Unlike prior work, Caco first fine-tunes
a code-based CoT generator on existing math and programming solutions in a
unified code format, then scales the data generation to a large amount of
diverse reasoning traces. Crucially, we introduce automated validation via code
execution and rule-based filtering to ensure logical correctness and structural
diversity, followed by reverse-engineering filtered outputs into natural
language instructions and language CoTs to enrich task adaptability. This
closed-loop process enables fully automated, scalable synthesis of reasoning
data with guaranteed executability. Experiments on our created Caco-1.3M
dataset demonstrate that Caco-trained models achieve strong competitive
performance on mathematical reasoning benchmarks, outperforming existing strong
baselines. Further analysis reveals that Caco's code-anchored verification and
instruction diversity contribute to superior generalization across unseen
tasks. Our work establishes a paradigm for building self-sustaining,
trustworthy reasoning systems without human intervention.

</details>


### [45] [Unveiling LLMs' Metaphorical Understanding: Exploring Conceptual Irrelevance, Context Leveraging and Syntactic Influence](https://arxiv.org/abs/2510.04120)
*Fengying Ye,Shanshan Wang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）在隐喻理解上的能力，指出其存在概念映射错误、过度依赖隐喻标志以及对语法结构敏感度高等问题。


<details>
  <summary>Details</summary>
Motivation: 隐喻是一个复杂的语言现象，现有LLMs虽具备强大的知识整合和推理能力，但其隐喻理解机制尚未充分研究。

Method: 从概念映射、隐喻-字面词库及句法敏感性三个角度分析LLMs对隐喻的处理，利用嵌入空间投影和对比字面及隐喻词汇进行评估。

Result: 发现LLMs约有15%-25%的概念解释不相关，依赖训练数据中的隐喻标记而非上下文线索，对句法异常敏感但对结构理解能力不足。

Conclusion: LLMs在隐喻分析上存在显著局限，需发展更健壮的计算方法来提升隐喻理解能力。

Abstract: Metaphor analysis is a complex linguistic phenomenon shaped by context and
external factors. While Large Language Models (LLMs) demonstrate advanced
capabilities in knowledge integration, contextual reasoning, and creative
generation, their mechanisms for metaphor comprehension remain insufficiently
explored. This study examines LLMs' metaphor-processing abilities from three
perspectives: (1) Concept Mapping: using embedding space projections to
evaluate how LLMs map concepts in target domains (e.g., misinterpreting "fall
in love" as "drop down from love"); (2) Metaphor-Literal Repository: analyzing
metaphorical words and their literal counterparts to identify inherent
metaphorical knowledge; and (3) Syntactic Sensitivity: assessing how
metaphorical syntactic structures influence LLMs' performance. Our findings
reveal that LLMs generate 15\%-25\% conceptually irrelevant interpretations,
depend on metaphorical indicators in training data rather than contextual cues,
and are more sensitive to syntactic irregularities than to structural
comprehension. These insights underline the limitations of LLMs in metaphor
analysis and call for more robust computational approaches.

</details>


### [46] [A Low-Resource Speech-Driven NLP Pipeline for Sinhala Dyslexia Assistance](https://arxiv.org/abs/2510.04750)
*Peshala Perera,Deshan Sumanathilaka*

Main category: cs.CL

TL;DR: 本论文针对斯里兰卡僧伽罗语成人阅读障碍者，设计了一套结合语音转文本、错误识别及文本纠正的多模态辅助系统，实现0.65的整体准确率。


<details>
  <summary>Details</summary>
Motivation: 成人阅读障碍，尤其是在非英语环境和低资源语言中，研究不足且实际支持体系缺乏，亟需开发有效辅助工具。

Method: 系统利用Whisper进行语音转文本，使用针对僧伽罗语微调的SinBERT模型识别常见错误，再用mT5和Mistral结合模型生成纠正文本，最后通过gTTS转换回语音，形成完整反馈环路。

Result: 系统在数据匮乏条件下，达成了语音转写准确率0.66，文本纠正准确率0.7，整体系统准确率0.65，证明方法可行且有效。

Conclusion: 研究表明为低资源语言开发包容性的NLP技术至关重要，所提系统为解决僧伽罗语成人阅读障碍问题提供了实用的技术路径。

Abstract: Dyslexia in adults remains an under-researched and under-served area,
particularly in non-English-speaking contexts, despite its significant impact
on personal and professional lives. This work addresses that gap by focusing on
Sinhala, a low-resource language with limited tools for linguistic
accessibility. We present an assistive system explicitly designed for
Sinhala-speaking adults with dyslexia. The system integrates Whisper for
speech-to-text conversion, SinBERT, an open-sourced fine-tuned BERT model
trained for Sinhala to identify common dyslexic errors, and a combined mT5 and
Mistral-based model to generate corrected text. Finally, the output is
converted back to speech using gTTS, creating a complete multimodal feedback
loop. Despite the challenges posed by limited Sinhala-language datasets, the
system achieves 0.66 transcription accuracy and 0.7 correction accuracy with
0.65 overall system accuracy. These results demonstrate both the feasibility
and effectiveness of the approach. Ultimately, this work highlights the
importance of inclusive Natural Language Processing (NLP) technologies in
underrepresented languages and showcases a practical

</details>


### [47] [Sri Lanka Document Datasets: A Large-Scale, Multilingual Resource for Law, News, and Policy (v20251005)](https://arxiv.org/abs/2510.04124)
*Nuwan I. Senaratna*

Main category: cs.CL

TL;DR: 本文介绍了斯里兰卡多语言公开文档数据集，涵盖议会记录、法律判决、政府出版物、新闻和旅游统计，共计逾21.5万份文档。


<details>
  <summary>Details</summary>
Motivation: 为了支持计算语言学、法律分析、社会政治研究和多语言自然语言处理领域的研究，提供高质量的多语种数据资源。

Method: 收集并整理来自斯里兰卡的多语种文档，建立包含13个数据集的机器可读数据库，并定期更新和同步到GitHub和Hugging Face平台。

Result: 构建了一个215,670份文档、容量60.3 GB的多语种公开数据集，涵盖僧伽罗语、泰米尔语和英语等语言，同时配备详细的数据源描述、格式说明及应用场景讨论。

Conclusion: 该数据集为多领域研究者提供了宝贵的资源，推动斯里兰卡多语言文本的自动处理与分析，且在数据开放性和伦理方面也进行了充分考虑。

Abstract: We present a collection of open, machine-readable document datasets covering
parliamentary proceedings, legal judgments, government publications, news, and
tourism statistics from Sri Lanka. As of v20251005, the collection currently
comprises 215,670 documents (60.3 GB) across 13 datasets in Sinhala, Tamil, and
English. The datasets are updated daily and mirrored on GitHub and Hugging
Face. These resources aim to support research in computational linguistics,
legal analytics, socio-political studies, and multilingual natural language
processing. We describe the data sources, collection pipeline, formats, and
potential use cases, while discussing licensing and ethical considerations.

</details>


### [48] [Fine Tuning Methods for Low-resource Languages](https://arxiv.org/abs/2510.04139)
*Tim Bakkenes,Daniel Wang,Anton Johansson*

Main category: cs.CL

TL;DR: 本文提出了一种通用方法，针对非英语文化准备数据集，并对Gemma 2模型进行后训练，以提升其在代表性不足语言上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型主要基于英语文化训练，导致在其他语言和文化环境中性能较差。为解决这一文化包容性不足的问题，作者希望提升模型在弱势语言中的表现，保护文化遗产。

Method: 开发了一种通用的数据集准备方法，使其文化相关性更强，并对Gemma 2模型进行后训练，以增强其对特定文化语言的理解和生成能力。

Result: 后训练后的Gemma 2模型在代表性不足的语言上性能得到提升，展示了该方法的有效性和可推广性。

Conclusion: 该项目证明了通过文化相关的数据准备和针对性后训练，可以显著提升大型语言模型在非主流语言和文化中的表现，具有推广价值。

Abstract: The rise of Large Language Models has not been inclusive of all cultures. The
models are mostly trained on English texts and culture which makes them
underperform in other languages and cultural contexts. By developing a
generalizable method for preparing culturally relevant datasets and
post-training the Gemma 2 model, this project aimed to increase the performance
of Gemma 2 for an underrepresented language and showcase how others can do the
same to unlock the power of Generative AI in their country and preserve their
cultural heritage.

</details>


### [49] [Self Speculative Decoding for Diffusion Large Language Models](https://arxiv.org/abs/2510.04147)
*Yifeng Gao,Ziang Ji,Yuxuan Wang,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 本文提出了一种名为SSD的无损推理加速方法，用于解决基于扩散的大型语言模型在并行解码时性能下降的问题，实现了与逐步解码一致的输出，同时提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的大型语言模型采用的并行解码方法导致生成结果与逐步解码不一致，造成性能下降，限制了其实际应用。

Method: 提出Self Speculative Decoding (SSD)方法，利用扩散模型自身作为推测解码和验证器，通过自我起草机制生成多个位置的预测，并通过层级验证树在单次前向传播中验证这些预测，避免使用辅助模块。

Result: 实验表明，SSD在开源模型（如LLaDA和Dream）中实现了最高3.46倍的加速，同时输出与逐步解码保持一致。

Conclusion: SSD方法有效提升了扩散基础大型语言模型的并行推理速度，解决了并行解码导致性能下降的问题，具有广泛的实际应用潜力。

Abstract: Diffusion-based Large Language Models (dLLMs) have emerged as a competitive
alternative to autoregressive models, offering unique advantages through
bidirectional attention and parallel generation paradigms. However, the
generation results of current parallel decoding methods deviate from stepwise
decoding, introducing potential performance degradation, which limits their
practical deployment. To address this problem, we propose \textbf{S}elf
\textbf{S}peculative \textbf{D}ecoding (SSD), a lossless inference acceleration
method that leverages the dLLM itself as both speculative decoding drafter and
verifier without auxiliary modules. SSD introduces a self-drafting mechanism
where the model generates predictions for multiple positions, then verifies
them through hierarchical verification trees in a single forward pass. Unlike
traditional speculative decoding that requires separate draft models, SSD
eliminates model redundancy and memory overhead by exploiting the dLLM's
inherent parallel prediction capability for multiple positions. This
self-speculative approach allows the model to progressively verify and accept
multiple tokens in a single forward pass. Our experiments demonstrate that SSD
achieves up to 3.46$\times$ speedup while keeping the output identical to
stepwise decoding on open source models such as LLaDA and Dream. Code will be
made publicly available on GitHub.

</details>


### [50] [Thinking on the Fly: Test-Time Reasoning Enhancement via Latent Thought Policy Optimization](https://arxiv.org/abs/2510.04182)
*Wengao Ye,Yan Liang,Lianlei Shan*

Main category: cs.CL

TL;DR: 本文提出了LTPO，一种无需更新模型参数的测试时优化框架，通过对潜在推理向量进行动态优化，提升了大型语言模型在困难任务上的推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有潜在推理方法在面对复杂、分布外任务时表现脆弱，影响推理效果，亟需提升模型在无监督下的推理稳健性。

Method: 提出LTPO方法，将中间潜在“思考”向量视为动态参数，通过在线策略梯度和基于置信度的内在奖励信号优化这些向量，避免了外部监督和昂贵的文本生成。

Result: 在五个推理基准测试上，LTPO表现优于或匹配强基线，特别是在AIME高难度基准中，大幅提升了精度，展示了良好鲁棒性与复杂推理能力。

Conclusion: LTPO有效增强了大型语言模型的潜在推理能力和鲁棒性，特别是在挑战性任务中表现突出，为无参数更新情况下的推理优化提供了新思路。

Abstract: Recent advancements in Large Language Models (LLMs) have shifted from
explicit Chain-of-Thought (CoT) reasoning to more efficient latent reasoning,
where intermediate thoughts are represented as vectors rather than text.
However, latent reasoning can be brittle on challenging, out-of-distribution
tasks where robust reasoning is most critical. To overcome these limitations,
we introduce Latent Thought Policy Optimization (LTPO), a parameter-free
framework that enhances LLM reasoning entirely at test time, without requiring
model parameter updates. LTPO treats intermediate latent "thought" vectors as
dynamic parameters that are actively optimized for each problem instance. It
employs an online policy gradient method guided by an intrinsic,
confidence-based reward signal computed directly from the frozen LLM's own
output distributions, eliminating the need for external supervision or
expensive text generation during optimization. Extensive experiments on five
reasoning benchmarks show that LTPO not only matches or surpasses strong
baselines on standard tasks but also demonstrates remarkable robustness where
others fail. Most notably, on highly challenging AIME benchmarks where existing
latent reasoning baselines collapse to near-zero accuracy, LTPO delivers
substantial improvements, showcasing a unique capability for complex reasoning.

</details>


### [51] [CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling](https://arxiv.org/abs/2510.04204)
*Zhengyang Tang,Zihan Ye,Chenyu Huang,Xuhan Huang,Chengpeng Li,Sihang Li,Guanhua Chen,Ming Yan,Zizhuo Wang,Hongyuan Zha,Dayiheng Liu,Benyou Wang*

Main category: cs.CL

TL;DR: 本文提出了CALM框架，通过专家介入修正LRM推理缺陷，结合轻量修改和强化学习，显著提升优化建模任务中的推理能力。基于此，STORM模型在多个基准测试中达到了68.9%的准确率，媲美规模远大的模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有领域适应方法难以充分利用现代大推理模型的高级推理模式，直接微调传统数据集效果有限，需新方法发挥LRM固有的推理能力。

Method: 提出CALM框架，专家介入指出推理错误并给出简洁修正提示，生成高质量数据通过监督微调和强化学习进行动态软适应，构建4B参数的STORM模型。

Result: STORM模型在五个优化建模基准测试中，平均准确率达到68.9%，匹配了参数多达671B的大型模型表现。

Conclusion: 基于动态提示的数据合成方法能够保持并放大现代LRM的推理模式，为实现专家级优化建模性能提供了更高效可扩展的途径。

Abstract: Large Reasoning Models (LRMs) have demonstrated strong capabilities in
complex multi-step reasoning, opening new opportunities for automating
optimization modeling. However, existing domain adaptation methods, originally
designed for earlier instruction-tuned models, often fail to exploit the
advanced reasoning patterns of modern LRMs -- In particular, we show that
direct fine-tuning on traditional \textit{non-reflective} datasets leads to
limited gains. To fully leverage LRMs' inherent reasoning abilities, we propose
\textbf{CALM} (\textit{Corrective Adaptation with Lightweight Modification}), a
framework that progressively refines LRMs within their native reasoning modes
for optimization modeling tasks. In CALM, an expert intervener identifies
reasoning flaws and provides concise corrective hints, which the LRM
incorporates to produce improved reasoning trajectories. These interventions
modify fewer than 2.6\% of generated tokens, but generate high-quality data for
soft adaptation through supervised fine-tuning. The adapted model is then
further improved through reinforcement learning. Building on CALM, we develop
\textbf{STORM} (\textit{Smart Thinking Optimization Reasoning Model}), a
4B-parameter LRM that achieves a new state-of-the-art average accuracy of
68.9\% across five popular optimization modeling benchmarks, matching the
performance of a 671B LRM. These results demonstrate that dynamic, hint-based
data synthesis both preserves and amplifies the native reasoning patterns of
modern LRMs, offering a more effective and scalable path towards expert-level
performance on challenging optimization modeling tasks.

</details>


### [52] [Teaching LLM to be Persuasive: Reward-Enhanced Policy Optimization for Alignment frm Heterogeneous Rewards](https://arxiv.org/abs/2510.04214)
*Zhuoran Zhuang,Ye Chen,Xia Zeng,Chao Luo,Luhui Liu,Yihan Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为REPO的强化学习后训练框架，用于将大型语言模型部署为在线旅游代理中的商务发展代理，提升价格谈判的说服力和合规性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如监督微调和单一奖励优化在多轮说服谈判中存在过拟合、风格单一以及难以确保业务约束合规的问题。

Method: 提出REPO框架，通过结合偏好训练的奖励模型、行为判断器及程序化奖励函数，实现对多样化奖励信号的整合，提升模型的说服力、合规性及防止奖励欺骗。

Result: 在真实和恶劣案例对话的约375轮测试中，REPO显著提升了平均对话评分和优秀回应比例，修复恶劣案例效果优于多种基线方法，同时展现出主动同理心、局部推理和策略校准的能力。

Conclusion: REPO通过多元奖励融合有效提升了LLM在商务谈判中的表现和安全性，展示了增强对话代理能力的新途径。

Abstract: We study deploying large language models (LLMs) as business development (BD)
agents for persuasive price negotiation in online travel agencies (OTAs), where
aligning traveler affordability and hotel profitability directly affects
bookings, partner relationships, and access to travel. The agent must follow a
Standard Operating Procedure (SOP) while conducting multi-turn persuasion,
interpreting colloquial inputs, and adhering to guardrails (no over-promising,
no hallucinations). Conventional post-training -- supervised fine-tuning (SFT)
or single-source reward optimization -- overfits scripts, misses nuanced
persuasive style, and fails to enforce verifiable business constraints.
  We propose Reward-Enhanced Policy Optimization (REPO), a reinforcement
learning post-training framework that aligns an LLM with heterogeneous rewards:
a preference-trained reward model (RM) for dense human alignment, a reward
judge (RJ) for high-level persuasive behavior and SOP compliance, and
programmatic reward functions (RF) for deterministic checks on numerics,
formatting, and guardrails. A straightforward enhancement mechanism is proposed
to combine the RM with RJ and RF signals to curb reward hacking and improve
negotiation quality. In production-style evaluations -- approximately 150 turns
from real dialogues and 225 turns from curated bad-case dialogues -- REPO lifts
average dialogue rating to 4.63: +1.20 over base, +0.83 over Direct Preference
Optimization (DPO); +0.33 over Group Relative Policy Optimization (GRPO),
increases the share of conversations with at least one excellent response to
66.67% (+23.34 percentage points over GRPO), and achieves a 93.33% bad-case fix
rate with 75.56% clean fixes, outperforming SFT, DPO, PPO, and GRPO. We also
observe emergent capabilities -- proactive empathy, localized reasoning,
calibrated tactics -- that surpass gold annotations.

</details>


### [53] [Epistemic Diversity and Knowledge Collapse in Large Language Models](https://arxiv.org/abs/2510.04226)
*Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 本文提出了一种衡量大语言模型知识多样性的新方法，发现尽管新模型知识多样性增加，但大多数模型的认知多样性仍低于基本网络搜索。


<details>
  <summary>Details</summary>
Motivation: 现有研究在语言模型生成文本同质化方面有限，尤其缺乏对时间和文化背景下趋势的考察，亟需新的方法衡量知识多样性。

Method: 作者设计一种测量知识多样性的方法，分析27个大语言模型、涵盖12个国家的155个话题及200个用户聊天提示变体，重点考察知识多样性的变化。

Result: 结果表明，模型规模增大降低知识多样性，而检索增强生成方法能提升多样性，但效果因文化背景而异；此外，模型生成内容更偏向英语文化，反映出本地语言知识代表性的不足。

Conclusion: 大语言模型存在知识同质化和认知萎缩风险，需结合检索等手段提升知识多样性，且需关注文化语境，弥补本地知识的缺失。

Abstract: Large language models (LLMs) tend to generate lexically, semantically, and
stylistically homogenous texts. This poses a risk of knowledge collapse, where
homogenous LLMs mediate a shrinking in the range of accessible information over
time. Existing works on homogenization are limited by a focus on closed-ended
multiple-choice setups or fuzzy semantic features, and do not look at trends
across time and cultural contexts. To overcome this, we present a new
methodology to measure epistemic diversity, i.e., variation in real-world
claims in LLM outputs, which we use to perform a broad empirical study of LLM
knowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200
prompt variations sourced from real user chats. For the topics in our study, we
show that while newer models tend to generate more diverse claims, nearly all
models are less epistemically diverse than a basic web search. We find that
model size has a negative impact on epistemic diversity, while
retrieval-augmented generation (RAG) has a positive impact, though the
improvement from RAG varies by the cultural context. Finally, compared to a
traditional knowledge source (Wikipedia), we find that country-specific claims
reflect the English language more than the local one, highlighting a gap in
epistemic representation

</details>


### [54] [Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought](https://arxiv.org/abs/2510.04230)
*Guijin Son,Donghun Yang,Hitesh Laxmichand Patel,Amit Agarwal,Hyunwoo Ko,Chanuk Lim,Srikant Panda,Minhyuk Kim,Nikunj Drolia,Dasol Choi,Kyong-Ha Lee,Youngjae Yu*

Main category: cs.CL

TL;DR: 本文提出了一种语言混合链式思维推理方法（Language-Mixed CoT），以英语作为锚语言，解决多语言推理难题，并以韩语为案例，构建了大规模韩语推理数据集和多规模模型。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究集中于英语的推理蒸馏，缺乏对特定语言（如韩语）推理能力的深入探索，且直译可能带来误差，因此需设计更有效的多语言推理方案。

Method: 提出Language-Mixed CoT方法，使用英语和目标语言混合推理；构建5.79M韩语提示和3.7M长推理轨迹数据；训练9个4B-35B参数量模型；进行消融实验验证效果。

Result: 最佳模型KO-REAson-35B在9个基准测试中整体均分最高（64.0±25），5个测试排名第一，4个第二；小型和中型模型平均提升18.6分；Language-Mixed CoT优于单语CoT，且提升跨语言和多模态性能。

Conclusion: 语言混合链式思维推理有效提升特定语言模型推理性能，数据和模型已公开，推动多语言推理研究。

Abstract: Recent frontier models employ long chain-of-thought reasoning to explore
solution spaces in context and achieve stonger performance. While many works
study distillation to build smaller yet capable models, most focus on English
and little is known about language-specific reasoning. To bridge this gap, we
first introduct **Language-Mixed CoT**, a reasoning schema that switches
between English and a target language, using English as an anchor to excel in
reasoning while minimizing translation artificats. As a Korean case study, we
curate **Yi-Sang**: 5.79M native-Korean prompts from web Q&A, exams, STEM, and
code; 3.7M long reasoning traces generated from Qwen3-32B; and a targeted 260k
high-yield subset. We train ninve models (4B-35B) across six families (Qwen2.5,
Llama-3.1, Gemma-3, etc). Our best model, **KO-REAson-35B**, achieves
state-of-the-art performance, with the highest overall average score (64.0 \pm
25), ranking first on 5/9 benchmarks and second on the remainder. Samller and
mid-sized models also benefit substantially, with an average improvement of
+18.6 points across teh evaluated nine benchmarks. Ablations show
**Language-Mixed CoT** is more effective than monolingual CoT, also resulting
in cross-lingual and mult-modal performance gains. We release our data-curation
pipeline, evaluation system, datasets, and models to advance research on
language-specific reasoning. Data and model collection:
https://huggingface.co/KOREAson.

</details>


### [55] [LongTail-Swap: benchmarking language models' abilities on rare words](https://arxiv.org/abs/2510.04268)
*Robin Algayres,Charles-Éric Saint-James,Mahi Luthra,Jiayi Shen,Dongyan Lin,Youssef Benchekroun,Rashel Moritz,Juan Pino,Emmanuel Dupoux*

Main category: cs.CL

TL;DR: 该论文提出了LongTail-Swap基准测试，专注于语言模型对低频词汇的学习能力，评估模型对新词的少量学习表现。


<details>
  <summary>Details</summary>
Motivation: 目前的语言模型评估多关注高频词汇，忽视了模型如何处理低频或新词，这与儿童学习语言的低数据高效性不同。

Method: 设计基于预训练语料库的句子对测试集，区分语义和句法对低频词的使用，使语言模型在零样本情景下通过计算句子对的对数概率平均值进行评估。

Result: 通过在10M和100M训练集上测试16个模型，发现所有模型在低频词上的表现较差，且不同架构的表现差异在长尾（低频词）部分更显著。

Conclusion: LT-Swap为评估语言模型在新词少量学习能力提供了新的视角，有助于挑选更适合稀有词汇推广的模型架构，推动低数据高效语言学习研究。

Abstract: Children learn to speak with a low amount of data and can be taught new words
on a few-shot basis, making them particularly data-efficient learners. The
BabyLM challenge aims at exploring language model (LM) training in the low-data
regime but uses metrics that concentrate on the head of the word distribution.
Here, we introduce LongTail-Swap (LT-Swap), a benchmark that focuses on the
tail of the distribution, i.e., measures the ability of LMs to learn new words
with very little exposure, like infants do. LT-Swap is a pretraining
corpus-specific test set of acceptable versus unacceptable sentence pairs that
isolate semantic and syntactic usage of rare words. Models are evaluated in a
zero-shot fashion by computing the average log probabilities over the two
members of each pair. We built two such test sets associated with the 10M words
and 100M words BabyLM training sets, respectively, and evaluated 16 models from
the BabyLM leaderboard. Our results not only highlight the poor performance of
language models on rare words but also reveal that performance differences
across LM architectures are much more pronounced in the long tail than in the
head. This offers new insights into which architectures are better at handling
rare word generalization. We've also made the code publicly avail

</details>


### [56] [Probing Geometry of Next Token Prediction Using Cumulant Expansion of the Softmax Entropy](https://arxiv.org/abs/2510.04285)
*Karthik Viswanathan,Sang Eon Park*

Main category: cs.CL

TL;DR: 本文提出了一个基于累积量展开的框架，用于量化大语言模型在下一个词预测过程中如何内化高阶统计结构。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型内部如何捕捉和学习文本中的高阶统计相关性，以揭示模型的特征学习动态。

Method: 通过将每层logit分布的softmax熵视为围绕中心分布的扰动，推导出封闭形式的累积量观测指标，捕捉逐级升高的高阶相关性，并在GPT-2和Pythia模型上实证分析累积量的变化。

Result: 结构化提示展现出跨层递增和平台的累积量特征，而打乱的提示保持平坦；训练过程中各阶累积量单调增加后饱和，反映模型从捕获方差到学习偏度、峰度及更高阶结构；数学提示与一般文本表现出不同的累积量特征，揭示模型对不同内容的处理机制不同。

Conclusion: 累积量分析为研究高维神经网络特征学习动态提供了轻量且数学基础坚实的工具，有助于揭示大语言模型内部处理统计结构的过程。

Abstract: We introduce a cumulant-expansion framework for quantifying how large
language models (LLMs) internalize higher-order statistical structure during
next-token prediction. By treating the softmax entropy of each layer's logit
distribution as a perturbation around its "center" distribution, we derive
closed-form cumulant observables that isolate successively higher-order
correlations. Empirically, we track these cumulants in GPT-2 and Pythia models
on Pile-10K prompts. (i) Structured prompts exhibit a characteristic
rise-and-plateau profile across layers, whereas token-shuffled prompts remain
flat, revealing the dependence of the cumulant profile on meaningful context.
(ii) During training, all cumulants increase monotonically before saturating,
directly visualizing the model's progression from capturing variance to
learning skew, kurtosis, and higher-order statistical structures. (iii)
Mathematical prompts show distinct cumulant signatures compared to general
text, quantifying how models employ fundamentally different processing
mechanisms for mathematical versus linguistic content. Together, these results
establish cumulant analysis as a lightweight, mathematically grounded probe of
feature-learning dynamics in high-dimensional neural networks.

</details>


### [57] [SliceMoE: Routing Embedding Slices Instead of Tokens for Fine-Grained and Balanced Transformer Scaling](https://arxiv.org/abs/2510.04286)
*Harshil Vejendla*

Main category: cs.CL

TL;DR: SliceMoE通过对token隐藏向量的切片进行专家路由，实现更高效的MoE模型，在多项自然语言处理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统token级MoE路由将整个语义空间分配给每个专家，导致容量瓶颈、负载不均和专家专精度受限。

Method: 提出SliceMoE，对d维嵌入向量进行切片，每个切片由共享轻量级路由器分配top-k专家，专家独立处理切片并重组输出，同时引入切片级容量损失、跨切片Dropout和高效GEMM核。

Result: 在WikiText-103语言建模、WMT英德翻译及文本分类任务中，SliceMoE推理速度最高提升1.7倍，困惑度降低12-18%，专家负载更均衡且专长可解释。

Conclusion: SliceMoE有效缓解了token级MoE的问题，实现了更高效、平衡且具有解释性的专家路由机制，提升了模型性能。

Abstract: Mixture-of-Experts (MoE) layers scale transformers by routing tokens to a
sparse subset of feed-forward experts. Token-level routing, however, assigns an
entire semantic spectrum to each expert, creating capacity bottlenecks,
load-balancing pathologies, and limited specialization. We introduce SliceMoE,
an architecture that routes contiguous slices of a token's hidden vector. A
d-dimensional embedding is partitioned into S slices, and for each slice, a
lightweight shared router predicts the top-k experts. Experts operate on their
assigned slices independently, and outputs are reassembled, maintaining
per-token FLOP efficiency. Because slices from different tokens interleave
within an expert, utilization is naturally smoother. We propose a slice-level
capacity loss, cross-slice dropout, and efficient fused batched GEMM kernels.
Experiments on WikiText-103 language modeling, WMT En-De translation, and three
text-classification datasets show SliceMoE attains up to 1.7x faster inference
than dense baselines, 12 to 18 percent lower perplexity than parameter-matched
token-MoE, and improved expert balance, with interpretable expertise over
syntactic versus semantic subspaces.

</details>


### [58] [PABSA: Hybrid Framework for Persian Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2510.04291)
*Mehrzad Tareh,Aydin Mohandesi,Ebrahim Ansari*

Main category: cs.CL

TL;DR: 本文提出了一种结合机器学习与深度学习的混合方法，用于波斯语的方面级情感分析，在Pars-ABSA数据集上取得了93.34%的准确率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 波斯语情感分析面临标注数据稀缺、预处理工具有限、高质量嵌入和特征提取缺失等挑战。

Method: 利用多语言BERT的极性分数作为额外特征，结合决策树分类器；同时引入波斯语同义词和实体词典进行文本增强。

Result: 该混合模型在Pars-ABSA数据集上实现了93.34%的准确率，超过现有基准。

Conclusion: 混合建模和特征增强有效推动了低资源语言波斯语的情感分析性能提升。

Abstract: Sentiment analysis is a key task in Natural Language Processing (NLP),
enabling the extraction of meaningful insights from user opinions across
various domains. However, performing sentiment analysis in Persian remains
challenging due to the scarcity of labeled datasets, limited preprocessing
tools, and the lack of high-quality embeddings and feature extraction methods.
To address these limitations, we propose a hybrid approach that integrates
machine learning (ML) and deep learning (DL) techniques for Persian
aspect-based sentiment analysis (ABSA). In particular, we utilize polarity
scores from multilingual BERT as additional features and incorporate them into
a decision tree classifier, achieving an accuracy of 93.34%-surpassing existing
benchmarks on the Pars-ABSA dataset. Additionally, we introduce a Persian
synonym and entity dictionary, a novel linguistic resource that supports text
augmentation through synonym and named entity replacement. Our results
demonstrate the effectiveness of hybrid modeling and feature augmentation in
advancing sentiment analysis for low-resource languages such as Persian.

</details>


### [59] [Equipping Retrieval-Augmented Large Language Models with Document Structure Awareness](https://arxiv.org/abs/2510.04293)
*Lingnan Xu,Chong Feng,Kaiyuan Zhang,Liu Zhengyong,Wenqiang Xu,Fanqing Meng*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的检索增强生成方法RDR2，通过显式利用文档结构信息提高大型语言模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法忽略了检索到的文本之间的结构关系，导致事实错误和信息利用不足的问题。

Method: RDR2框架使用基于LLM的路由器动态导航文档结构树，结合内容相关性和层级关系进行证据汇编，将文档路由任务设计为可训练任务，采用自动动作策划和结构感知的段落选择策略。

Result: 在五个挑战性数据集上的综合评估显示，RDR2达到了最先进的性能，显著提升了系统在多文档综合场景下的知识获取和利用能力。

Conclusion: 显式利用文档结构信息是提升检索增强生成系统效果的关键，特别是在复杂的跨文档信息整合任务中表现优异。

Abstract: While large language models (LLMs) demonstrate impressive capabilities, their
reliance on parametric knowledge often leads to factual inaccuracies.
Retrieval-Augmented Generation (RAG) mitigates this by leveraging external
documents, yet existing approaches treat retrieved passages as isolated chunks,
ignoring valuable structure that is crucial for document organization.
Motivated by this gap, we propose Retrieve-DocumentRoute-Read (RDR2), a novel
framework that explicitly incorporates structural information throughout the
RAG process. RDR2 employs an LLM-based router to dynamically navigate document
structure trees, jointly evaluating content relevance and hierarchical
relationships to assemble optimal evidence. Our key innovation lies in
formulating document routing as a trainable task, with automatic action
curation and structure-aware passage selection inspired by human reading
strategies. Through comprehensive evaluation on five challenging datasets, RDR2
achieves state-of-the-art performance, demonstrating that explicit structural
awareness significantly enhances RAG systems' ability to acquire and utilize
knowledge, particularly in complex scenarios requiring multi-document
synthesis.

</details>


### [60] [Measuring Language Model Hallucinations Through Distributional Correctness](https://arxiv.org/abs/2510.04302)
*Thomas F Burns*

Main category: cs.CL

TL;DR: 本文提出了一种新的语言模型评估指标——分布正确度分数（DCS），更好地衡量模型在回答时的信念状态和不确定性表达，避免模型因追求单一准确率而产生幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的评估主要基于准确率或单一响应得分，无法全面反映模型分布的不确定性，导致模型倾向于猜测而非表达真实不确定性。

Method: 引入分布正确度分数（DCS）作为新的评估指标，该指标考虑模型对所有答案选项的概率分布，区分错误答案的过度自信与合理的回避行为（例如选择“我不知道”）。通过理论分析和实例验证DCS的有效性，并将其应用于12个现有基准测试和6个语言模型。

Result: 利用DCS度量评估，发现半数测试基准所有模型得分均为负值，表明模型存在显著的幻觉倾向。DCS能够提供更细致、符合实际的评估结果，鼓励模型表达真实不确定性。

Conclusion: DCS作为一种新颖的评估范式，克服了传统二元准确率指标的局限，有助于推动语言模型在输出中合理表达不确定性，减少幻觉现象，提高模型性能的解释性和可靠性。

Abstract: Common evaluation paradigms for language models focus on scoring single
responses through accuracy metrics or proper scoring rules, failing to capture
the full richness of a model's belief state. Recent work illustrates that
language models hallucinate in-part because they are optimised to be good
test-takers under binary scoring schemes that reward any answer over
abstention. While this insight naturally leads to penalty-based approaches,
they ignore crucial distinctions in how models distribute uncertainty, for
example between hedging toward incorrect answers versus hedging toward "I don't
know" responses. A novel evaluation metric, the Distributional Correctness
Score (DCS), is introduced to solve this problem, i.e., of not considering a
model's entire probability distribution over answer choices. DCS naturally
distinguishes between harmful overconfidence in wrong answers and uncertainty
expressed through abstention, providing scores in an interpretable default
range. Through theoretical analysis and illustrative examples, DCS is
demonstrated to offer a more nuanced and aligned evaluation paradigm that
incentivises models to express genuine uncertainty rather than guessing.
Adapting 12 existing evaluation benchmarks to DCS's variants and measuring
performance on six language models reveals that for half of the tested
benchmarks scores are negative across all tested models, indicating significant
tendencies towards hallucination.

</details>


### [61] [Read the Scene, Not the Script: Outcome-Aware Safety for LLMs](https://arxiv.org/abs/2510.04320)
*Rui Wu,Yihao Quan,Zeru Shi,Zhenting Wang,Yanshu Li,Ruixiang Tang*

Main category: cs.CL

TL;DR: 目前的大型语言模型存在对后果推理能力弱的问题，导致容易被绕过安全限制或过度拒绝无害输入。作者提出"后果盲目"问题，构建了CB-Bench基准用于评估，并通过新数据集CS-Chain-4k提升模型的后果推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前安全对齐的语言模型存在被轻易绕过或过度拒绝无害输入的问题，主要原因是模型对行为与后果的联系推理能力较弱，过度依赖表面语言特征。

Method: 提出"后果盲目"这一失败模式，构建包含四种风险场景的CB-Bench评测基准；设计CS-Chain-4k数据集用于后果推理的微调，提高模型对行为结果的识别和区分能力。

Result: 主流模型在CB-Bench上表现出明显的后果盲目现象，微调后模型在绕过检测和减少无害输入过拒绝方面有显著提升，同时保持了在其他基准上的性能和泛化能力。

Conclusion: 当前模型安全对齐存在明显局限，强调后果感知推理能力是核心对齐目标，提出了更实用且可复现的评估和改进路径。

Abstract: Safety-aligned Large Language Models (LLMs) still show two dominant failure
modes: they are easily jailbroken, or they over-refuse harmless inputs that
contain sensitive surface signals. We trace both to a common cause: current
models reason weakly about links between actions and outcomes and over-rely on
surface-form signals, lexical or stylistic cues that do not encode
consequences. We define this failure mode as Consequence-blindness. To study
consequence-blindness, we build a benchmark named CB-Bench covering four risk
scenarios that vary whether semantic risk aligns with outcome risk, enabling
evaluation under both matched and mismatched conditions which are often ignored
by existing safety benchmarks. Mainstream models consistently fail to separate
these risks and exhibit consequence-blindness, indicating that
consequence-blindness is widespread and systematic. To mitigate
consequence-blindness, we introduce CS-Chain-4k, a consequence-reasoning
dataset for safety alignment. Models fine-tuned on CS-Chain-4k show clear gains
against semantic-camouflage jailbreaks and reduce over-refusal on harmless
inputs, while maintaining utility and generalization on other benchmarks. These
results clarify the limits of current alignment, establish consequence-aware
reasoning as a core alignment goal and provide a more practical and
reproducible evaluation path.

</details>


### [62] [Evaluation of Clinical Trials Reporting Quality using Large Language Models](https://arxiv.org/abs/2510.04338)
*Mathieu Laï-king,Patrick Paroubek*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型评估临床试验报告质量的能力，使用CONSORT标准，并创建了CONSORT-QA评价语料。


<details>
  <summary>Details</summary>
Motivation: 临床试验报道质量影响临床决策，现有评估方法依赖人工，亟需自动化工具。

Method: 构建CONSORT-QA数据集，测试多种大型生成式语言模型及提示方法（包括Chain-of-thought）评估报道质量。

Result: 最佳模型和提示组合达成85%准确率，Chain-of-thought提示帮助模型解释推理过程。

Conclusion: 大型语言模型结合合适提示技术能有效自动评估临床试验报告质量，具有实际应用潜力。

Abstract: Reporting quality is an important topic in clinical trial research articles,
as it can impact clinical decisions. In this article, we test the ability of
large language models to assess the reporting quality of this type of article
using the Consolidated Standards of Reporting Trials (CONSORT). We create
CONSORT-QA, an evaluation corpus from two studies on abstract reporting quality
with CONSORT-abstract standards. We then evaluate the ability of different
large generative language models (from the general domain or adapted to the
biomedical domain) to correctly assess CONSORT criteria with different known
prompting methods, including Chain-of-thought. Our best combination of model
and prompting method achieves 85% accuracy. Using Chain-of-thought adds
valuable information on the model's reasoning for completing the task.

</details>


### [63] [Inoculation Prompting: Eliciting traits from LLMs during training can suppress them at test-time](https://arxiv.org/abs/2510.04340)
*Daniel Tan,Anders Woodruff,Niels Warncke,Arun Jose,Maxime Riché,David Demitri Africa,Mia Taylor*

Main category: cs.CL

TL;DR: 本文提出了一种名为接种提示法（inoculation prompting）的技术，通过在微调数据前加上特定指令来减少语言模型学习不良特征，使模型在测试时表现出更少的负面特点。


<details>
  <summary>Details</summary>
Motivation: 语言模型微调过程中常会同时学习到期望特征和不良特质，如何有效减少后者是本研究的主要动机。

Method: 在微调数据前添加简短的系统提示指令，故意激发不良特质，从而在测试时取消该指令以抑制不良特质的表达。

Result: 经接种提示训练的模型在减少不良行为表现方面效果显著，并且能够选择性地学习特定行为。此外，该方法在多种场景下有效，如减少任务特定微调带来的突现错误、抵御后门攻击及缓解潜意识学习引发的特质传播。

Conclusion: 接种提示法通过降低不良特质的新颖性，减少模型整体更新优化压力，进而减轻不良特质的泛化。该方法不仅提供了简单有效的选择性学习技术，也加深了对语言模型泛化机制的理解。

Abstract: Language model finetuning often results in learning undesirable traits in
combination with desired ones. To address this, we propose inoculation
prompting: modifying finetuning data by prepending a short system-prompt
instruction that deliberately elicits the undesirable trait. At test time, we
evaluate without the instruction; inoculated models have much lower expression
of the trait than models trained with unmodified training data. Inoculation is
selective: in a toy setting where assistant responses are always in Spanish and
ALL-CAPS, an appropriate inoculation (e.g., ``You always speak in Spanish.'')
teaches the model to capitalize responses while still responding in English. We
find that inoculation is also effective across several additional settings:
reducing emergent misalignment (EM) from task-specific finetuning, defending
against backdoor injections, and mitigating the transmission of traits via
subliminal learning. Follow-up analysis suggests a mechanism: making a trait
less surprising via inoculation reduces optimization pressure to globally
update the model, thereby reducing the degree of generalization. Our analysis
relates to prior work on EM: inoculation explains prior findings that
educational contexts mitigate EM from insecure code. Beyond demonstrating a
simple and effective technique for selective learning, our results contribute
to a better conceptual understanding of how and why language models generalize.

</details>


### [64] [Unmasking Backdoors: An Explainable Defense via Gradient-Attention Anomaly Scoring for Pre-trained Language Models](https://arxiv.org/abs/2510.04347)
*Anindya Sundar Das,Kangjie Chen,Monowar Bhuyan*

Main category: cs.CL

TL;DR: 本文研究了预训练语言模型中的后门攻击，提出了一种结合注意力和梯度信息的推理时防御方法，有效降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型在各类NLP任务中表现优异，但容易受到后门攻击，触发后导致错误分类，因此需要有效的防御手段。

Method: 分析后门触发时模型的注意力和梯度分布特征，提出结合这两种信息构建异常得分的推理时防御机制。

Result: 在多种后门攻击场景下，所提方法显著降低了攻击成功率，优于现有基线方法。

Conclusion: 本文提出的基于注意力和梯度的异常检测方法，有效提升了预训练语言模型对后门攻击的防御能力，并通过可解释性分析验证了其鲁棒性和触发位置定位能力。

Abstract: Pre-trained language models have achieved remarkable success across a wide
range of natural language processing (NLP) tasks, particularly when fine-tuned
on large, domain-relevant datasets. However, they remain vulnerable to backdoor
attacks, where adversaries embed malicious behaviors using trigger patterns in
the training data. These triggers remain dormant during normal usage, but, when
activated, can cause targeted misclassifications. In this work, we investigate
the internal behavior of backdoored pre-trained encoder-based language models,
focusing on the consistent shift in attention and gradient attribution when
processing poisoned inputs; where the trigger token dominates both attention
and gradient signals, overriding the surrounding context. We propose an
inference-time defense that constructs anomaly scores by combining token-level
attention and gradient information. Extensive experiments on text
classification tasks across diverse backdoor attack scenarios demonstrate that
our method significantly reduces attack success rates compared to existing
baselines. Furthermore, we provide an interpretability-driven analysis of the
scoring mechanism, shedding light on trigger localization and the robustness of
the proposed defense.

</details>


### [65] [Improving Consistency in Retrieval-Augmented Systems with Group Similarity Rewards](https://arxiv.org/abs/2510.04392)
*Faisal Hamman,Chenyang Zhu,Anoop Kumar,Xujun Peng,Sanghamitra Dutta,Daben Liu,Alfy Samuel*

Main category: cs.CL

TL;DR: 本文针对RAG系统在高风险领域的一致性问题，提出了一种评估框架和基于强化学习的优化方法（PS-GRPO），大幅提升系统在语义等价查询下输出的信息一致性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在语义等价查询下常出现显著输出不一致，影响信任度和可靠性，尤其在高风险应用场景迫切需要提升信息输出的一致性。

Method: 提出评估框架拆解RAG一致性来源，设计强化学习方法PS-GRPO，通过多轮基于意译集的训练，实现生成器端对等价查询输出内容一致的训练，同时引入近似算法降低计算成本。

Result: 在多种问答基准测试中，Con-RAG在无监督条件下显著提升信息一致性和准确率，优于强基线模型，验证了方法的有效性和实用性。

Conclusion: 本研究提供了评估和优化RAG系统一致性的实用方案，增强了系统在安全关键领域的可靠性和应用潜力。

Abstract: RAG systems are increasingly deployed in high-stakes domains where users
expect outputs to be consistent across semantically equivalent queries.
However, existing systems often exhibit significant inconsistencies due to
variability in both the retriever and generator (LLM), undermining trust and
reliability. In this work, we focus on information consistency, i.e., the
requirement that outputs convey the same core content across semantically
equivalent inputs. We introduce a principled evaluation framework that
decomposes RAG consistency into retriever-level, generator-level, and
end-to-end components, helping identify inconsistency sources. To improve
consistency, we propose Paraphrased Set Group Relative Policy Optimization
(PS-GRPO), an RL approach that leverages multiple rollouts across paraphrased
set to assign group similarity rewards. We leverage PS-GRPO to achieve
Information Consistent RAG (Con-RAG), training the generator to produce
consistent outputs across paraphrased queries and remain robust to
retrieval-induced variability. Because exact reward computation over paraphrase
sets is computationally expensive, we also introduce a scalable approximation
method that retains effectiveness while enabling efficient, large-scale
training. Empirical evaluations across short-form, multi-hop, and long-form QA
benchmarks demonstrate that Con-RAG significantly improves both consistency and
accuracy over strong baselines, even in the absence of explicit ground-truth
supervision. Our work provides practical solutions for evaluating and building
reliable RAG systems for safety-critical deployments.

</details>


### [66] [Time Is Effort: Estimating Human Post-Editing Time for Grammar Error Correction Tool Evaluation](https://arxiv.org/abs/2510.04394)
*Ankit Vadehra,Bill Johnson,Gene Saunders,Pascal Poupart*

Main category: cs.CL

TL;DR: 本文提出了一个衡量语法错误纠正（GEC）工具在文本编辑中节省用户时间的新指标PEET，并发布了大规模的后期编辑时间注释数据集，展示了GEC工具的实用价值。


<details>
  <summary>Details</summary>
Motivation: 文本编辑往往需要多次修订，初始阶段高效的GEC工具能显著减少人工编辑时间和提升文本质量，因此需要量化GEC工具对用户节省编辑时间的能力。

Method: 作者构建了两个英语GEC测试集（BEA19和CoNLL14）的后期编辑时间注释和修正数据集，引入基于时间的后期编辑工作量指标PEET来评估GEC工具，通过分析不同编辑类型对时间影响并与人工排名对比验证指标有效性。

Result: 基于数据分析显示，判断句子是否需要修正、改写以及标点调整等编辑类型对后期编辑时间影响最大；PEET指标与人工评估的技术工作量相关性良好，能够有效反映GEC工具的实用性。

Conclusion: 本文提出的PEET为评估GEC工具节省编辑时间的实用性提供了新的人本指标和方向，辅助用户选择更高效的工具，同时作者公开了相关数据与代码以促进研究和应用发展。

Abstract: Text editing can involve several iterations of revision. Incorporating an
efficient Grammar Error Correction (GEC) tool in the initial correction round
can significantly impact further human editing effort and final text quality.
This raises an interesting question to quantify GEC Tool usability: How much
effort can the GEC Tool save users? We present the first large-scale dataset of
post-editing (PE) time annotations and corrections for two English GEC test
datasets (BEA19 and CoNLL14). We introduce Post-Editing Effort in Time (PEET)
for GEC Tools as a human-focused evaluation scorer to rank any GEC Tool by
estimating PE time-to-correct. Using our dataset, we quantify the amount of
time saved by GEC Tools in text editing. Analyzing the edit type indicated that
determining whether a sentence needs correction and edits like paraphrasing and
punctuation changes had the greatest impact on PE time. Finally, comparison
with human rankings shows that PEET correlates well with technical effort
judgment, providing a new human-centric direction for evaluating GEC tool
usability. We release our dataset and code at:
https://github.com/ankitvad/PEET_Scorer.

</details>


### [67] [SECA: Semantically Equivalent and Coherent Attacks for Eliciting LLM Hallucinations](https://arxiv.org/abs/2510.04398)
*Buyun Liang,Liangzu Peng,Jinqi Luo,Darshan Thaker,Kwan Ho Ryan Chan,René Vidal*

Main category: cs.CL

TL;DR: 本文提出了一种新的对抗攻击方法SECA，通过语义等价且连贯的提示词修改来诱导大语言模型产生幻觉，实验表明其攻击成功率高且不违反约束。


<details>
  <summary>Details</summary>
Motivation: 当前对抗攻击往往通过插入无意义的符号或改变原意来诱发大语言模型的幻觉，缺乏现实意义的提示词，难以反映实际场景中幻觉产生的机制。

Method: 将寻找现实合理的诱导幻觉的攻击视为在语义等价和连贯约束下的受限优化问题，提出一种保持约束的零阶优化方法，有效搜索具有对抗性的合理提示词。

Result: 在开放式选择题任务上的实验显示，SECA方法能在几乎不违反语义及连贯性约束的情况下，实现比现有方法更高的攻击成功率。

Conclusion: SECA揭示了开源及商用大语言模型对现实且合理的提示词变体的高度敏感性，提供了更具实践意义的幻觉诱导攻击方法。

Abstract: Large Language Models (LLMs) are increasingly deployed in high-risk domains.
However, state-of-the-art LLMs often produce hallucinations, raising serious
concerns about their reliability. Prior work has explored adversarial attacks
for hallucination elicitation in LLMs, but it often produces unrealistic
prompts, either by inserting gibberish tokens or by altering the original
meaning. As a result, these approaches offer limited insight into how
hallucinations may occur in practice. While adversarial attacks in computer
vision often involve realistic modifications to input images, the problem of
finding realistic adversarial prompts for eliciting LLM hallucinations has
remained largely underexplored. To address this gap, we propose Semantically
Equivalent and Coherent Attacks (SECA) to elicit hallucinations via realistic
modifications to the prompt that preserve its meaning while maintaining
semantic coherence. Our contributions are threefold: (i) we formulate finding
realistic attacks for hallucination elicitation as a constrained optimization
problem over the input prompt space under semantic equivalence and coherence
constraints; (ii) we introduce a constraint-preserving zeroth-order method to
effectively search for adversarial yet feasible prompts; and (iii) we
demonstrate through experiments on open-ended multiple-choice question
answering tasks that SECA achieves higher attack success rates while incurring
almost no constraint violations compared to existing methods. SECA highlights
the sensitivity of both open-source and commercial gradient-inaccessible LLMs
to realistic and plausible prompt variations. Code is available at
https://github.com/Buyun-Liang/SECA.

</details>


### [68] [Large Language Models Preserve Semantic Isotopies in Story Continuations](https://arxiv.org/abs/2510.04400)
*Marc Cavazza*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型生成文本是否保持语义上的一致性，即语义等距现象。通过设计故事续写实验，分析了五个模型生成内容中的语义特征。


<details>
  <summary>Details</summary>
Motivation: 前人关注分布式语义与结构语义的关系，本文希望进一步验证大型语言模型生成文本的语义一致性。

Method: 采用ROCStories故事续写实验，使用五个模型生成文本，先验证GPT-4o提取语义等距的能力，再分析生成文本的结构和语义属性。

Result: 实验结果表明，在给定的词元范围内，大型语言模型的文本生成能够保持语义等距的多重属性。

Conclusion: 大型语言模型的续写能力在语义层面表现出较好的连贯性，能够保持故事语义一致性。

Abstract: In this work, we explore the relevance of textual semantics to Large Language
Models (LLMs), extending previous insights into the connection between
distributional semantics and structural semantics. We investigate whether
LLM-generated texts preserve semantic isotopies. We design a story continuation
experiment using 10,000 ROCStories prompts completed by five LLMs. We first
validate GPT-4o's ability to extract isotopies from a linguistic benchmark,
then apply it to the generated stories. We then analyze structural (coverage,
density, spread) and semantic properties of isotopies to assess how they are
affected by completion. Results show that LLM completion within a given token
horizon preserves semantic isotopies across multiple properties.

</details>


### [69] [Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?](https://arxiv.org/abs/2510.04434)
*Grace LeFevre,Qingcheng Zeng,Adam Leif,Jason Jewell,Denis Peskoff,Rob Voigt*

Main category: cs.CL

TL;DR: 本文分析了自然语言处理（NLP）在社会公益领域的研究分布，揭示了ACL内部作者和非ACL作者在社会公益相关研究上的不同表现。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理对社会公益的重要性提升，探究该领域的研究现状及作者和发表场所的分布情况具有重要意义。

Method: 从作者和发表场所两个维度出发，统计和分析了针对社会公益目标的论文在ACL社区内外以及ACL作者和非ACL作者之间的比例。

Result: 发现ACL作者在非ACL会议上更倾向于发表社会公益相关工作，而绝大多数利用NLP解决社会公益问题的论文是由非ACL作者在非ACL会议上发表的。

Conclusion: 该研究揭示了NLP4SG领域研究的分布特点，强调ACL社区在设定社会公益相关研究议题时需考虑这些差异和外部力量的影响。

Abstract: The social impact of Natural Language Processing (NLP) is increasingly
important, with a rising community focus on initiatives related to NLP for
Social Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the
ACL Anthology address topics related to social good as defined by the UN
Sustainable Development Goals (Adauto et al., 2023). In this study, we take an
author- and venue-level perspective to map the landscape of NLP4SG, quantifying
the proportion of work addressing social good concerns both within and beyond
the ACL community, by both core ACL contributors and non-ACL authors. With this
approach we discover two surprising facts about the landscape of NLP4SG. First,
ACL authors are dramatically more likely to do work addressing social good
concerns when publishing in venues outside of ACL. Second, the vast majority of
publications using NLP techniques to address concerns of social good are done
by non-ACL authors in venues outside of ACL. We discuss the implications of
these findings on agenda-setting considerations for the ACL community related
to NLP4SG.

</details>


### [70] [On the Role of Unobserved Sequences on Sample-based Uncertainty Quantification for LLMs](https://arxiv.org/abs/2510.04439)
*Lucie Kunitomo-Jacquin,Edison Marrese-Taylor,Ken Fukuda*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLM）中不确定性量化的重要性，强调未观察序列的概率在估计中不可忽视。


<details>
  <summary>Details</summary>
Motivation: LLM的不确定性量化对于安全关键应用至关重要，当前方法主要通过多次查询获取输出序列及其概率，估计输出序列分布的熵来检测错误答案（幻觉）。

Method: 通过实验证明未观察序列的概率在不确定性估计中起关键作用，建议未来研究将未观察序列概率纳入不确定性量化方法。

Result: 实验证明未观察序列的概率显著影响了不确定性估计的效果。

Conclusion: 未来的LLM不确定性量化方法应整合未观察序列的概率以提升估计性能。

Abstract: Quantifying uncertainty in large language models (LLMs) is important for
safety-critical applications because it helps spot incorrect answers, known as
hallucinations. One major trend of uncertainty quantification methods is based
on estimating the entropy of the distribution of the LLM's potential output
sequences. This estimation is based on a set of output sequences and associated
probabilities obtained by querying the LLM several times. In this paper, we
advocate and experimentally show that the probability of unobserved sequences
plays a crucial role, and we recommend future research to integrate it to
enhance such LLM uncertainty quantification methods.

</details>


### [71] [Mitigating Forgetting Between Supervised and Reinforcement Learning Yields Stronger Reasoners](https://arxiv.org/abs/2510.04454)
*Xiangchi Yuan,Xiang Chen,Tong Yu,Dachuan Shi,Can Jin,Wenke Lee,Saayan Mitra*

Main category: cs.CL

TL;DR: 提出一种动态整合监督微调(SFT)与强化学习(RL)的框架，通过选择具有挑战性的样本进行SFT，减少数据需求并防止灾难性遗忘，从而提升大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽然能提升推理能力，但因仅基于自身推理轨迹学习，难以扩展推理边界；监督微调虽有效但需大量数据且易过拟合；现有结合方法面临数据效率低、算法依赖强和灾难性遗忘问题。

Method: 设计一个即插即用框架，动态选择挑战性样本进行SFT，减少SFT数据需求且不依赖具体算法；通过选择高熵token计算损失和冻结关键参数，防止SFT过程中遗忘RL学得技能。

Result: 在仅用之前最先进方法1.5%的SFT数据和20.4%的RL数据情况下，实现了最先进的推理性能。

Conclusion: 该方法提供了一种高效且灵活的SFT与RL结合方案，有效提升了大型语言模型的推理能力，解决了数据效率和灾难性遗忘问题。

Abstract: Large Language Models (LLMs) show strong reasoning abilities, often amplified
by Chain-of-Thought (CoT) prompting and reinforcement learning (RL). Although
RL algorithms can substantially improve reasoning, they struggle to expand
reasoning boundaries because they learn from their own reasoning trajectories
rather than acquiring external knowledge. Supervised fine-tuning (SFT) offers
complementary benefits but typically requires large-scale data and risks
overfitting. Recent attempts to combine SFT and RL face three main challenges:
data inefficiency, algorithm-specific designs, and catastrophic forgetting. We
propose a plug-and-play framework that dynamically integrates SFT into RL by
selecting challenging examples for SFT. This approach reduces SFT data
requirements and remains agnostic to the choice of RL or SFT algorithm. To
mitigate catastrophic forgetting of RL-acquired skills during SFT, we select
high-entropy tokens for loss calculation and freeze parameters identified as
critical for RL. Our method achieves state-of-the-art (SoTA) reasoning
performance using only 1.5% of the SFT data and 20.4% of the RL data used by
prior SoTA, providing an efficient and plug-and-play solution for combining SFT
and RL in reasoning post-training.

</details>


### [72] [Compressed Convolutional Attention: Efficient Attention in a Compressed Latent Space](https://arxiv.org/abs/2510.04476)
*Tomas Figliolia,Nicholas Alonso,Rishi Iyer,Quentin Anthony,Beren Millidge*

Main category: cs.CL

TL;DR: 本文提出了一种新型注意力机制CCA和其扩展CCGQA，通过压缩查询、键和值的维度，在共享的潜空间内进行注意力计算，显著减少了参数量、KV缓存和计算量，从而加快训练和推理速度。


<details>
  <summary>Details</summary>
Motivation: 多头注意力（MHA）在长上下文变换器中计算和KV缓存消耗巨大，现有方法虽然压缩KV缓存但并未明显降低计算量，限制了训练和预填速度的提升。

Method: 提出压缩卷积注意力（CCA），通过下投影降低查询、键和值的维度，在共享潜空间内完成注意力操作；进一步结合头共享形成CCGQA，实现更优的计算与内存平衡。

Result: CCGQA在相同KV缓存压缩率下优于现有GQA和MLA方法，对MoE模型实现8倍的KV缓存压缩且性能无损，同时减少FLOP，提升训练和预填速度。

Conclusion: CCA和CCGQA有效降低了多头注意力的计算和内存开销，显著加速了长序列变换器的训练和推理，是一种高效可调的注意力机制创新。

Abstract: Multi-headed Attention's (MHA) quadratic compute and linearly growing
KV-cache make long-context transformers expensive to train and serve. Prior
works such as Grouped Query Attention (GQA) and Multi-Latent Attention (MLA)
shrink the cache, speeding decode, but leave compute, which determines prefill
and training speed, largely unchanged. We introduce Compressed Convolutional
Attention (CCA), a novel attention method which down-projects queries, keys,
and values and performs the entire attention operation inside the shared latent
space. This simple design dramatically cuts parameters, KV-cache, and FLOPs all
at once by the desired compression factor. Because CCA is orthogonal to
head-sharing, we combine the two to form Compressed Convolutional Grouped Query
Attention (CCGQA), which further tightens the compute-bandwidth Pareto frontier
so that users can tune compression toward either FLOP or memory limits without
sacrificing quality. Experiments show that CCGQA consistently outperforms both
GQA and MLA at equal KV-cache compression on dense and MoE models.
Additionally, we show that CCGQA outperforms all other attention methods on MoE
models with half the KV-cache of GQA and MLA, achieving an 8x KV-cache
compression with no drop in performance compared to standard MHA. CCA and CCGQA
also dramatically reduce the FLOP cost of attention which leads to
substantially faster training and prefill than existing methods. On H100 GPUs,
our fused CCA/CCGQA kernel reduces prefill latency by about 1.7x at a sequence
length of 16k relative to MHA, and accelerates backward by about 1.3x.

</details>


### [73] [Psychological Steering in LLMs: An Evaluation of Effectiveness and Trustworthiness](https://arxiv.org/abs/2510.04484)
*Amin Banayeeanzade,Ala N. Tak,Fatemeh Bahrani,Anahita Bolourani,Leonardo Blas,Emilio Ferrara,Jonathan Gratch,Sai Praneeth Karimireddy*

Main category: cs.CL

TL;DR: 本文提出了PsySET基准，用于评估大语言模型(LLM)在情感和个性调整上的控制效果与可信度，研究不同模型和调控策略的表现及其副作用。


<details>
  <summary>Details</summary>
Motivation: 为了实现丰富的人机社交互动，需要有效控制LLM模拟的情感状态和个性特征，但当前缺乏全面的评估方法。

Method: 构建心理学指导的PsySET基准，测试四种不同LLM及多种调控策略（提示、微调、向量注入），评估其调控效果与可信度，包括安全性、真实性、公平性和伦理性。

Result: 提示法效果稳定但强度受限，向量注入调控更细致但输出质量略降；调控情感和个性会带来副作用，如快乐情绪降低事实准确性和隐私意识，愤怒提升毒性但增强信息泄漏抵抗。

Conclusion: PsySET实现了首个对LLM情感和个性调控的全面评估，揭示了其调控可解释性与可靠性，为社交应用中的情感个性控制提供理论与实践参考。

Abstract: The ability to control LLMs' emulated emotional states and personality traits
is essential for enabling rich, human-centered interactions in socially
interactive settings. We introduce PsySET, a Psychologically-informed benchmark
to evaluate LLM Steering Effectiveness and Trustworthiness across the emotion
and personality domains. Our study spans four models from different LLM
families paired with various steering strategies, including prompting,
fine-tuning, and representation engineering. Our results indicate that
prompting is consistently effective but limited in intensity control, whereas
vector injections achieve finer controllability while slightly reducing output
quality. Moreover, we explore the trustworthiness of steered LLMs by assessing
safety, truthfulness, fairness, and ethics, highlighting potential side effects
and behavioral shifts. Notably, we observe idiosyncratic effects; for instance,
even a positive emotion like joy can degrade robustness to adversarial
factuality, lower privacy awareness, and increase preferential bias. Meanwhile,
anger predictably elevates toxicity yet strengthens leakage resistance. Our
framework establishes the first holistic evaluation of emotion and personality
steering, offering insights into its interpretability and reliability for
socially interactive applications.

</details>


### [74] [GenQuest: An LLM-based Text Adventure Game for Language Learners](https://arxiv.org/abs/2510.04498)
*Qiao Wang,Adnan Labib,Robert Swier,Michael Hofmeyr,Zheng Yuan*

Main category: cs.CL

TL;DR: GenQuest是一款利用大型语言模型的生成式文字冒险游戏，旨在通过沉浸式互动故事讲述辅助英语作为外语的学习。


<details>
  <summary>Details</summary>
Motivation: 通过互动故事和个性化内容生成，提高外语学习者的词汇量和学习积极性。

Method: 采用选择你自己的冒险模式，根据学习者选择动态生成故事，结合关卡节点和词汇助手提供语境解释。

Result: 在中国高校的试点研究显示，参与者词汇量有显著提升且用户体验积极。

Conclusion: 基于LLM的文字冒险游戏在外语词汇学习中具有有效性，未来可增加多模态内容以提升体验。

Abstract: GenQuest is a generative text adventure game that leverages Large Language
Models (LLMs) to facilitate second language learning through immersive,
interactive storytelling. The system engages English as a Foreign Language
(EFL) learners in a collaborative "choose-your-own-adventure" style narrative,
dynamically generated in response to learner choices. Game mechanics such as
branching decision points and story milestones are incorporated to maintain
narrative coherence while allowing learner-driven plot development. Key
pedagogical features include content generation tailored to each learner's
proficiency level, and a vocabulary assistant that provides in-context
explanations of learner-queried text strings, ranging from words and phrases to
sentences. Findings from a pilot study with university EFL students in China
indicate promising vocabulary gains and positive user perceptions. Also
discussed are suggestions from participants regarding the narrative length and
quality, and the request for multi-modal content such as illustrations.

</details>


### [75] [GRACE: Generative Representation Learning via Contrastive Policy Optimization](https://arxiv.org/abs/2510.04506)
*Jiashuo Sun,Shixuan Liu,Zhaochen Su,Xianrui Zhong,Pengcheng Jiang,Bowen Jin,Peiran Li,Weijia Shi,Jiawei Han*

Main category: cs.CL

TL;DR: GRACE方法将对比学习信号视为奖励，引导大型语言模型生成解释性的理由，从而学习高质量的文本表示，提升模型性能并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有使用对比损失训练大型语言模型作为文本编码器的方法忽略了模型的生成和推理能力，仅仅学习静态嵌入，缺乏解释性和透明度。

Method: 提出GRACE框架，将LLM视为生成策略，生成结构化自然语言理由，通过对理由进行编码和基于策略梯度的多目标奖励函数优化，实现对比学习目的。

Result: 在MTEB基准测试中，GRACE在四个不同主干模型上均获得显著提升，监督设置下提升11.5%，无监督设置提升6.9%，同时保持模型的通用能力。

Conclusion: 通过将对比目标视为生成理由的奖励，GRACE统一了表示学习和生成任务，既产出更强的语义嵌入，也提供了透明且可解释的推理过程。

Abstract: Prevailing methods for training Large Language Models (LLMs) as text encoders
rely on contrastive losses that treat the model as a black box function,
discarding its generative and reasoning capabilities in favor of static
embeddings. We introduce GRACE (Generative Representation Learning via
Contrastive Policy Optimization), a novel framework that reimagines contrastive
signals not as losses to be minimized, but as rewards that guide a generative
policy. In GRACE, the LLM acts as a policy that produces explicit,
human-interpretable rationales--structured natural language explanations of its
semantic understanding. These rationales are then encoded into high-quality
embeddings via mean pooling. Using policy gradient optimization, we train the
model with a multi-component reward function that maximizes similarity between
query positive pairs and minimizes similarity with negatives. This transforms
the LLM from an opaque encoder into an interpretable agent whose reasoning
process is transparent and inspectable. On MTEB benchmark, GRACE yields broad
cross category gains: averaged over four backbones, the supervised setting
improves overall score by 11.5% over base models, and the unsupervised variant
adds 6.9%, while preserving general capabilities. This work treats contrastive
objectives as rewards over rationales, unifying representation learning with
generation to produce stronger embeddings and transparent rationales. The
model, data and code are available at https://github.com/GasolSun36/GRACE.

</details>


### [76] [Fine-grained auxiliary learning for real-world product recommendation](https://arxiv.org/abs/2510.04551)
*Mario Almagro,Diego Ortego,David Jimenez*

Main category: cs.CL

TL;DR: 本文提出了一种辅助学习策略ALC，通过学习细粒度嵌入提升商品推荐的覆盖率，实现高效自动化推荐。


<details>
  <summary>Details</summary>
Motivation: 现实生产系统要求高覆盖率的自动化推荐，然而现有模型往往忽视覆盖率，导致需要大量人工复核。

Method: 引入两种训练目标，利用批次中最难负样本生成区分正负样本的训练信号，结合极端多标签分类方法提升嵌入的判别能力。

Result: 在两个商品推荐数据集（LF-AmazonTitles-131K和Tech and Durables）上，通过结合最近的阈值一致边际损失，实现了先进的覆盖率表现。

Conclusion: ALC辅助学习策略有效提升了商品推荐系统的自动化覆盖率，有助于实现在生产环境中高效运用。

Abstract: Product recommendation is the task of recovering the closest items to a given
query within a large product corpora. Generally, one can determine if
top-ranked products are related to the query by applying a similarity
threshold; exceeding it deems the product relevant, otherwise manual revision
is required. Despite being a well-known problem, the integration of these
models in real-world systems is often overlooked. In particular, production
systems have strong coverage requirements, i.e., a high proportion of
recommendations must be automated. In this paper we propose ALC , an Auxiliary
Learning strategy that boosts Coverage through learning fine-grained
embeddings. Concretely, we introduce two training objectives that leverage the
hardest negatives in the batch to build discriminative training signals between
positives and negatives. We validate ALC using three extreme multi-label
classification approaches in two product recommendation datasets;
LF-AmazonTitles-131K and Tech and Durables (proprietary), demonstrating
state-of-the-art coverage rates when combined with a recent
threshold-consistent margin loss.

</details>


### [77] [Can LLMs Detect Ambiguous Plural Reference? An Analysis of Split-Antecedent and Mereological Reference](https://arxiv.org/abs/2510.04581)
*Dang Anh,Rick Nouwen,Massimo Poesio*

Main category: cs.CL

TL;DR: 本文研究大型语言模型（LLMs）在多重指称表示与理解上的表现，尤其是在歧义与非歧义语境中对复数代词的处理。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否像人类一样偏好某些复数指称的表现形式，以及其在检测复数代词歧义和识别可能指称对象上的能力。

Method: 设计一系列实验，包括使用下一词预测任务测试代词生成，利用不同提示策略进行代词理解和歧义检测，并将LLMs的表现与人类进行比较。

Result: LLMs在一定程度上能察觉歧义代词的可能指称对象，但在选择具体解释时不总是与人类一致，特别是当解释未明确出现时；且未经明确指导，LLMs难以识别歧义。此外，不同类型的实验结果表现不一致。

Conclusion: LLMs在复数指称的理解与处理上显示出一定能力，但仍存在与人类理解差异及对歧义识别不足的问题，提示未来需要改进模型对上下文和语言结构的把握。

Abstract: Our goal is to study how LLMs represent and interpret plural reference in
ambiguous and unambiguous contexts. We ask the following research questions:
(1) Do LLMs exhibit human-like preferences in representing plural reference?
(2) Are LLMs able to detect ambiguity in plural anaphoric expressions and
identify possible referents? To address these questions, we design a set of
experiments, examining pronoun production using next-token prediction tasks,
pronoun interpretation, and ambiguity detection using different prompting
strategies. We then assess how comparable LLMs are to humans in formulating and
interpreting plural reference. We find that LLMs are sometimes aware of
possible referents of ambiguous pronouns. However, they do not always follow
human reference when choosing between interpretations, especially when the
possible interpretation is not explicitly mentioned. In addition, they struggle
to identify ambiguity without direct instruction. Our findings also reveal
inconsistencies in the results across different types of experiments.

</details>


### [78] [Robustness assessment of large audio language models in multiple-choice evaluation](https://arxiv.org/abs/2510.04584)
*Fernando López,Santosh Kesiraju,Jordi Luque*

Main category: cs.CL

TL;DR: 该论文研究了大型音频语言模型(LALMs)在多项选择问答(MCQA)框架下的评估稳定性，发现模型对选项顺序及问题改写敏感，提出了改进的评估协议和指标。


<details>
  <summary>Details</summary>
Motivation: 当前LALMs主要通过MCQA框架进行评估，但现有方法忽略了因选项顺序和表述细微变化导致结果波动的问题，这影响评估的准确性和可靠性。

Method: 系统性分析了三大MCQA基准(MMAU、MMAR、MMSU)和四种模型，通过实验验证了模型对选项顺序和问答改写的敏感性，进而提出了更简便且鲁棒的评估协议和指标。

Result: 实验证明模型准确率受选项顺序和表述变化显著影响，采用新评估协议后能更细致全面地反映模型性能。

Conclusion: 该研究揭示了MCQA评估中存在的波动问题，并通过新的评估方法提升评估的稳定性和细致度，为LALMs的性能测评提供了更可靠的工具。

Abstract: Recent advances in large audio language models (LALMs) have primarily been
assessed using a multiple-choice question answering (MCQA) framework. However,
subtle changes, such as shifting the order of choices, result in substantially
different results. Existing MCQA frameworks do not account for this variability
and report a single accuracy number per benchmark or category. We dive into the
MCQA evaluation framework and conduct a systematic study spanning three
benchmarks (MMAU, MMAR and MMSU) and four models: Audio Flamingo 2, Audio
Flamingo 3, Qwen2.5-Omni-7B-Instruct, and Kimi-Audio-7B-Instruct. Our findings
indicate that models are sensitive not only to the ordering of choices, but
also to the paraphrasing of the question and the choices. Finally, we propose a
simpler evaluation protocol and metric that account for subtle variations and
provide a more detailed evaluation report of LALMs within the MCQA framework.

</details>


### [79] [FedSRD: Sparsify-Reconstruct-Decompose for Communication-Efficient Federated Large Language Models Fine-Tuning](https://arxiv.org/abs/2510.04601)
*Guochen Yan,Luyuan Xie,Qingni Shen,Yuejian Fang,Zhonghai Wu*

Main category: cs.CL

TL;DR: 本文提出了FedSRD框架，通过重要性稀疏化、重构与分解技术，大幅降低了联邦学习中LoRA微调的通信开销，并提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于Web数据训练大语言模型趋于饱和，且LoRA微调在联邦学习中面临通信瓶颈和参数冲突问题，亟需通信效率更高的解决方案。

Method: 提出FedSRD框架，包括重要性感知稀疏化以减少上传参数，服务器端重构聚合以缓解冲突，最后将更新分解为稀疏低秩格式广播；另外设计了高效变体FedSRD-e。

Result: 在10个基准测试中，实现了通信开销最高降低90%，且在异构客户端数据上模型性能有所提升。

Conclusion: FedSRD有效缓解了联邦学习中LoRA微调的通信负担及更新冲突问题，兼顾通信效率与模型效果，适合未来分布式Web环境下的隐私保护协同训练。

Abstract: The current paradigm of training large language models (LLMs) on publicly
available Web data is becoming unsustainable, with high-quality data sources in
specialized domains nearing exhaustion. Federated Learning (FL) emerges as a
practical solution for the next generation of AI on a decentralized Web,
enabling privacy-preserving collaborative fine-tuning by leveraging private
data distributed across a global client base. While Low-Rank Adaptation (LoRA)
is the standard for efficient fine-tuning, its application in federated
settings presents a critical challenge: communication overhead remains a
significant bottleneck across the Web's heterogeneous network conditions. The
structural redundancy within LoRA parameters not only incurs a heavy
communication burden but also introduces conflicts when aggregating client
updates. To address this, we propose FedSRD, a Sparsify-Reconstruct-Decompose
framework designed for communication-efficient FL. We first introduce an
importance-aware sparsification method that preserves the structural integrity
of LoRA updates to reduce the uploaded parameter count. The server then
reconstructs and aggregates these updates in a full-rank space to mitigate
conflicts. Finally, it decomposes the global update into a sparse low-rank
format for broadcast, ensuring a symmetrically efficient cycle. We also propose
an efficient variant, FedSRD-e, to reduce computational overhead. Experimental
results on 10 benchmarks demonstrate that our framework significantly reduces
communication costs by up to 90\% while even improving model performance on
heterogeneous client data.

</details>


### [80] [Contrastive Learning Using Graph Embeddings for Domain Adaptation of Language Models in the Process Industry](https://arxiv.org/abs/2510.04631)
*Anastasia Zhukova,Jonas Lührs,Christian E. Matt,Bela Gipp*

Main category: cs.CL

TL;DR: 本文研究如何将SciNCL图感知对比学习方法应用于过程工业领域，通过对稀疏知识图（KG）中的三元组进行微调，提升了文本嵌入效果。


<details>
  <summary>Details</summary>
Motivation: 当前NLP趋势利用知识图增强预训练语言模型，但过程工业文本日志稀疏且重要，本研究旨在改善过程工业文本的表示能力。

Method: 采用SciNCL方法对过程工业中的稀疏知识图进行邻域对比学习，利用从图中提取的三元组对语言模型进行微调。

Result: 微调后的模型在过程工业文本嵌入基准测试中表现优于当前最先进的mE5-large编码器，提升了9.8-14.3%的性能，且模型体积更小3-5倍。

Conclusion: 通过将图感知对比学习应用于过程工业领域，本文有效提升了文本表示能力，实现了更高效且更优的模型表现。

Abstract: Recent trends in NLP utilize knowledge graphs (KGs) to enhance pretrained
language models by incorporating additional knowledge from the graph structures
to learn domain-specific terminology or relationships between documents that
might otherwise be overlooked. This paper explores how SciNCL, a graph-aware
neighborhood contrastive learning methodology originally designed for
scientific publications, can be applied to the process industry domain, where
text logs contain crucial information about daily operations and are often
structured as sparse KGs. Our experiments demonstrate that language models
fine-tuned with triplets derived from GE outperform a state-of-the-art
mE5-large text encoder by 9.8-14.3% (5.4-8.0p) on the proprietary process
industry text embedding benchmark (PITEB) while being 3-5 times smaller in
size.

</details>


### [81] [Evaluating LLMs for Demographic-Targeted Social Bias Detection: A Comprehensive Benchmark Study](https://arxiv.org/abs/2510.04641)
*Ayan Majumdar,Feihao Chen,Jinghui Li,Xiaozhen Wang*

Main category: cs.CL

TL;DR: 该论文提出了一个综合评估框架，系统分析了大规模语言模型检测针对不同人口群体的社会偏见的效果，发现微调的小模型具有较好的检测能力，但在多群体偏见检测上仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 当前大规模的网络文本数据中存在针对不同人口群体的有害偏见，且现有偏见检测研究范围有限，未能全面覆盖多类型、多人口轴及多群体偏见，难以满足法规要求，因此需要构建一个全面的偏见检测评估框架。

Method: 论文通过提出一个基于人口学分类的多标签偏见检测任务，采用提示、上下文学习和微调等多种技术，利用十二个涵盖不同内容和人口群体的数据集，系统评估了不同规模和技术的语言模型的偏见检测能力。

Result: 研究显示微调后的较小语言模型在偏见检测任务中表现优异，适合大规模应用，但对于多个人口群体的偏见检测仍存在明显不足。

Conclusion: 尽管微调小模型在可扩展偏见检测中展现潜力，但需要开发更有效且可扩展的审计框架，尤其是针对多人口群体的社会偏见，以满足监管要求。

Abstract: Large-scale web-scraped text corpora used to train general-purpose AI models
often contain harmful demographic-targeted social biases, creating a regulatory
need for data auditing and developing scalable bias-detection methods. Although
prior work has investigated biases in text datasets and related detection
methods, these studies remain narrow in scope. They typically focus on a single
content type (e.g., hate speech), cover limited demographic axes, overlook
biases affecting multiple demographics simultaneously, and analyze limited
techniques. Consequently, practitioners lack a holistic understanding of the
strengths and limitations of recent large language models (LLMs) for automated
bias detection. In this study, we present a comprehensive evaluation framework
aimed at English texts to assess the ability of LLMs in detecting
demographic-targeted social biases. To align with regulatory requirements, we
frame bias detection as a multi-label task using a demographic-focused
taxonomy. We then conduct a systematic evaluation with models across scales and
techniques, including prompting, in-context learning, and fine-tuning. Using
twelve datasets spanning diverse content types and demographics, our study
demonstrates the promise of fine-tuned smaller models for scalable detection.
However, our analyses also expose persistent gaps across demographic axes and
multi-demographic targeted biases, underscoring the need for more effective and
scalable auditing frameworks.

</details>


### [82] [FT-MDT: Extracting Decision Trees from Medical Texts via a Novel Low-rank Adaptation Method](https://arxiv.org/abs/2510.04655)
*Yuheng Li,Jiechao Gao,Wei Han,Wenwen Ouyang,Wei Zhu,Hui Yi Leong*

Main category: cs.CL

TL;DR: 本文提出了一种名为PI-LoRA的低秩适应方法，用于自动从临床指南和教科书中提取医学决策树（MDT），显著提升了提取精度并降低了模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前医学决策树构建依赖耗时且繁琐的手工标注，限制了临床决策支持系统的发展。

Method: PI-LoRA整合梯度路径信息，通过动态分配秩值，捕捉不同模块间的协同效应，实现关键模块的有效参数调整与不重要模块的剪枝。

Result: 在医学指南数据集上的实验表明，PI-LoRA在Text2MDT任务中优于现有的参数高效微调方法，不但提高了准确率，还大幅降低了模型复杂度。

Conclusion: 该方法不仅实现了顶尖性能，还保持了轻量级架构，尤其适用于计算资源有限的临床决策支持系统。

Abstract: Knowledge of the medical decision process, which can be modeled as medical
decision trees (MDTs), is critical to building clinical decision support
systems. However, current MDT construction methods rely heavily on
time-consuming and laborious manual annotation. To address this challenge, we
propose PI-LoRA (Path-Integrated LoRA), a novel low-rank adaptation method for
automatically extracting MDTs from clinical guidelines and textbooks. We
integrate gradient path information to capture synergistic effects between
different modules, enabling more effective and reliable rank allocation. This
framework ensures that the most critical modules receive appropriate rank
allocations while less important ones are pruned, resulting in a more efficient
and accurate model for extracting medical decision trees from clinical texts.
Extensive experiments on medical guideline datasets demonstrate that our
PI-LoRA method significantly outperforms existing parameter-efficient
fine-tuning approaches for the Text2MDT task, achieving better accuracy with
substantially reduced model complexity. The proposed method achieves
state-of-the-art results while maintaining a lightweight architecture, making
it particularly suitable for clinical decision support systems where
computational resources may be limited.

</details>


### [83] [FocusMed: A Large Language Model-based Framework for Enhancing Medical Question Summarization with Focus Identification](https://arxiv.org/abs/2510.04671)
*Chao Liu,Ling Luo,Tengxiao Lv,Huan Zhuang,Lejing Yu,Jian Wang,Hongfei Lin*

Main category: cs.CL

TL;DR: 本文针对在线医疗平台中消费者健康问题摘要任务，提出了一种基于核心焦点引导的优化框架，显著提升了模型识别问题焦点的能力并减少幻觉生成。


<details>
  <summary>Details</summary>
Motivation: 现有医疗问题摘要方法在识别问题焦点和防止模型生成不真实内容方面存在不足，影响诊断效率。

Method: 设计提示模板引导大语言模型提取核心焦点，构建结合原始问答对的微调数据集，并引入多维度质量评估和筛选机制提升摘要质量。

Result: 在两个主流数据集和三个评估指标上，所提方法在各项指标上均实现了最先进的性能，有效提升了焦点识别能力并减少了模型幻觉。

Conclusion: 提出的基于核心焦点引导的优化框架能够有效提升医疗问题摘要的质量和可信度，促进在线医疗平台诊断效率的提升。

Abstract: With the rapid development of online medical platforms, consumer health
questions (CHQs) are inefficient in diagnosis due to redundant information and
frequent non-professional terms. The medical question summary (MQS) task aims
to transform CHQs into streamlined doctors' frequently asked questions (FAQs),
but existing methods still face challenges such as poor identification of
question focus and model hallucination. This paper explores the potential of
large language models (LLMs) in the MQS task and finds that direct fine-tuning
is prone to focus identification bias and generates unfaithful content. To this
end, we propose an optimization framework based on core focus guidance. First,
a prompt template is designed to drive the LLMs to extract the core focus from
the CHQs that is faithful to the original text. Then, a fine-tuning dataset is
constructed in combination with the original CHQ-FAQ pairs to improve the
ability to identify the focus of the question. Finally, a multi-dimensional
quality evaluation and selection mechanism is proposed to comprehensively
improve the quality of the summary from multiple dimensions. We conduct
comprehensive experiments on two widely-adopted MQS datasets using three
established evaluation metrics. The proposed framework achieves
state-of-the-art performance across all measures, demonstrating a significant
boost in the model's ability to identify critical focus of questions and a
notable mitigation of hallucinations. The source codes are freely available at
https://github.com/DUT-LiuChao/FocusMed.

</details>


### [84] [Multi-Agent Tool-Integrated Policy Optimization](https://arxiv.org/abs/2510.04678)
*Zhanfeng Mo,Xingxuan Li,Yuntao Chen,Lidong Bing*

Main category: cs.CL

TL;DR: 本文提出了Multi-Agent Tool-Integrated Policy Optimization (MATPO)方法，通过在单一大语言模型中使用角色特定提示进行强化学习，实现了规划者和执行者两个角色的高效协作，显著提升了多工具集成推理任务的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于单智能体的大语言模型受限于上下文长度和工具响应噪声，多智能体框架虽能缓解这些问题，但缺乏有效的强化学习后训练方法。

Method: MATPO通过在单一LLM实例中采用规划者和执行者的角色特定提示，利用强化学习和信用分配机制联合训练，避免了多模型部署带来的内存压力同时保持角色专门化。

Result: 在GAIA-text、WebWalkerQA和FRAMES数据集上，MATPO相比单智能体基线性能提升18.38%，且对工具输出噪声表现出更强的鲁棒性。

Conclusion: 统一多个智能体角色于单一大语言模型中，通过角色特定提示和强化学习训练，实现了稳定高效的多智能体策略优化，显著提升复杂推理任务的性能和鲁棒性。

Abstract: Large language models (LLMs) increasingly rely on multi-turn tool-integrated
planning for knowledge-intensive and complex reasoning tasks. Existing
implementations typically rely on a single agent, but they suffer from limited
context length and noisy tool responses. A natural solution is to adopt a
multi-agent framework with planner- and worker-agents to manage context.
However, no existing methods support effective reinforcement learning
post-training of tool-integrated multi-agent frameworks. To address this gap,
we propose Multi-Agent Tool-Integrated Policy Optimization (MATPO), which
enables distinct roles (planner and worker) to be trained within a single LLM
instance using role-specific prompts via reinforcement learning. MATPO is
derived from a principled credit assignment mechanism across planner and worker
rollouts. This design eliminates the need to deploy multiple LLMs, which would
be memory-intensive, while preserving the benefits of specialization.
Experiments on GAIA-text, WebWalkerQA, and FRAMES show that MATPO consistently
outperforms single-agent baselines by an average of 18.38% relative improvement
in performance and exhibits greater robustness to noisy tool outputs. Our
findings highlight the effectiveness of unifying multiple agent roles within a
single LLM and provide practical insights for stable and efficient multi-agent
RL training.

</details>


### [85] [TiTok: Transfer Token-level Knowledge via Contrastive Excess to Transplant LoRA](https://arxiv.org/abs/2510.04682)
*Chanjoo Jung,Jaehyung Kim*

Main category: cs.CL

TL;DR: 提出了TiTok框架，通过Token级知识转移，实现了LoRA参数在不同模型间的高效迁移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA参数微调方法因依赖基础模型，难以跨不同骨干网迁移，且知识蒸馏依赖训练数据并增加复杂度。

Method: TiTok通过对比源模型带和不带LoRA参数表现的Token级差异，筛选信息性强的合成数据，实现无额外模型的选择性过滤与知识转移。

Result: 在三个基准测试和多种迁移设置下，TiTok相较基线平均提升4~8%的性能。

Conclusion: TiTok有效克服了LoRA参数迁移的局限性，简化流程并显著提升了微调效率和性能。

Abstract: Large Language Models (LLMs) are widely applied in real world scenarios, but
fine-tuning them comes with significant computational and storage costs.
Parameter-Efficient Fine-Tuning (PEFT) methods such as LoRA mitigate these
costs, but the adapted parameters are dependent on the base model and cannot be
transferred across different backbones. One way to address this issue is
through knowledge distillation, but its effectiveness inherently depends on
training data. Recent work such as TransLoRA avoids this by generating
synthetic data, but this adds complexity because it requires training an
additional discriminator model. In this paper, we propose TiTok, a new
framework that enables effective LoRA Transplantation through Token-level
knowledge transfer. Specifically, TiTok captures task-relevant information
through a contrastive excess between a source model with and without LoRA. This
excess highlights informative tokens and enables selective filtering of
synthetic data, all without additional models or overhead. Through experiments
on three benchmarks across multiple transfer settings, our experiments show
that the proposed method is consistently effective, achieving average
performance gains of +4~8% compared to baselines overall.

</details>


### [86] [Multilingual Routing in Mixture-of-Experts](https://arxiv.org/abs/2510.04694)
*Lucas Bandarkar,Chenyuan Yang,Mohsen Fayyaz,Junlin Hu,Nanyun Peng*

Main category: cs.CL

TL;DR: 本文研究了混合专家（MoE）架构在多语言数据中的稀疏路由动态，发现不同层存在语言特异性和跨语言路由对齐现象，并通过中间层专家的路由调整提升多语言性能。


<details>
  <summary>Details</summary>
Motivation: 当前对MoE模型在多语言环境下的路由动态了解不足，特别是如何利用跨语言共享专家以提高模型泛化能力。

Method: 通过分析平行多语言数据集中的专家路由模式，揭示不同解码层的语言特异性和跨语言路由对齐，进一步提出一种中间层路由调整方法，促进英语频繁激活的专家被用于其他语言，以提升多语言性能。

Result: 该方法在两个评估任务、三个模型和十五种以上语言中带来了1-2%的性能提升，且在中间层调整路由效果显著，其他层或多语言专用专家的干预反而会导致性能下降。

Conclusion: MoE模型的多语言泛化能力受限于其利用语言通用专家的能力，中间层专家的跨语言协同对提高模型性能至关重要，本文的路由干预策略为提升多语言LLM性能提供了有效路径。

Abstract: Mixture-of-Experts (MoE) architectures have become the key to scaling modern
LLMs, yet little is understood about how their sparse routing dynamics respond
to multilingual data. In this work, we analyze expert routing patterns using
parallel multilingual datasets and present highly interpretable layer-wise
phenomena. We find that MoE models route tokens in language-specific ways in
the early and late decoder layers but exhibit significant cross-lingual routing
alignment in middle layers, mirroring parameter-sharing trends observed in
dense LLMs. In particular, we reveal a clear, strong correlation between a
model's performance in a given language and how similarly its tokens are routed
to English in these layers. Extending beyond correlation, we explore
inference-time interventions that induce higher cross-lingual routing
alignment. We introduce a method that steers the router by promoting
middle-layer task experts frequently activated in English, and it successfully
increases multilingual performance. These 1-2% gains are remarkably consistent
across two evaluation tasks, three models, and 15+ languages, especially given
that these simple interventions override routers of extensively trained,
state-of-the-art LLMs. In comparison, interventions outside of the middle
layers or targeting multilingual-specialized experts only yield performance
degradation. Altogether, we present numerous findings that explain how MoEs
process non-English text and demonstrate that generalization is limited by the
model's ability to leverage language-universal experts in all languages.

</details>


### [87] [JSON Whisperer: Efficient JSON Editing with LLMs](https://arxiv.org/abs/2510.04717)
*Sarel Duanis,Asnat Greenstein-Messica,Eliya Habba*

Main category: cs.CL

TL;DR: 本文提出了JSON Whisperer框架，通过生成差异补丁提高了LLM对JSON文档编辑的计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型编辑JSON时每次都生成完整文档，计算资源浪费，且在复杂编辑如数组操作时表现不佳。

Method: 提出EASE方法，将数组转为带稳定键的字典，配合生成RFC 6902差异补丁，避免索引移位问题和漏改。

Result: 实验显示EASE方法减少了31%的令牌使用，编辑质量接近完整重生成，尤其在复杂指令和列表操作中表现显著提升。

Conclusion: 通过差异补丁生成和EASE编码，JSON Whisperer有效提升LLM编辑JSON的效率和准确性，适合复杂结构的修改需求。

Abstract: Large language models (LLMs) can modify JSON documents through natural
language commands, but current approaches regenerate entire structures for each
edit, resulting in computational inefficiency. We present JSON Whisperer, a
framework that enables LLMs to generate RFC 6902 diff patches-expressing only
the necessary modifications-rather than complete documents. We identify two key
challenges in patch-based editing: (1) LLMs often miss related updates when
generating isolated patches, and (2) array manipulations require tracking index
shifts across operations, which LLMs handle poorly. To address these issues, we
introduce EASE (Explicitly Addressed Sequence Encoding), which transforms
arrays into dictionaries with stable keys, eliminating index arithmetic
complexities. Our evaluation shows that patch generation with EASE reduces
token usage by 31% while maintaining edit quality within 5% of full
regeneration with particular gains for complex instructions and list
manipulations. The dataset is available at:
https://github.com/emnlp2025/JSON-Whisperer/

</details>


### [88] [ModernBERT + ColBERT: Enhancing biomedical RAG through an advanced re-ranking retriever](https://arxiv.org/abs/2510.04757)
*Eduardo Martínez Rivera,Filippo Menolascina*

Main category: cs.CL

TL;DR: 本文提出一种结合ModernBERT和ColBERTv2的两阶段检索架构，用于提升生物医学领域的检索增强生成系统性能，实现了MIRAGE问答基准的最新准确率。


<details>
  <summary>Details</summary>
Motivation: 针对高阶领域中检索模块性能制约了基于检索增强生成（RAG）系统的效果，专业领域语言的复杂性使通用检索器表现欠佳且高精度模型计算成本高昂。

Method: 设计两阶段检索体系，先用轻量级ModernBERT双向编码器进行候选检索，再用ColBERTv2细粒度重排序，并在PubMedQA数据集上联合微调。

Result: ColBERT重排序提升Recall@3达4.2个百分点，集成后在MIRAGE五个任务上取得0.4448的平均准确率，优于MedCPT等强基线。

Conclusion: 联合微调检索器与重排序器是性能提升的关键，否则重排序器可能反而降低效果。该架构实现了生物医学RAG系统的精度和效率平衡。

Abstract: Retrieval-Augmented Generation (RAG) is a powerful technique for enriching
Large Language Models (LLMs) with external knowledge, allowing for factually
grounded responses, a critical requirement in high-stakes domains such as
healthcare. However, the efficacy of RAG systems is fundamentally restricted by
the performance of their retrieval module, since irrelevant or semantically
misaligned documents directly compromise the accuracy of the final generated
response. General-purpose dense retrievers can struggle with the nuanced
language of specialised domains, while the high accuracy of in-domain models is
often achieved at prohibitive computational costs. In this work, we aim to
address this trade-off by developing and evaluating a two-stage retrieval
architecture that combines a lightweight ModernBERT bidirectional encoder for
efficient initial candidate retrieval with a ColBERTv2 late-interaction model
for fine-grained re-ranking. We conduct comprehensive evaluations of our
retriever module performance and RAG system performance in the biomedical
context, fine-tuning the IR module using 10k question-passage pairs from
PubMedQA. Our analysis of the retriever module confirmed the positive impact of
the ColBERT re-ranker, which improved Recall@3 by up to 4.2 percentage points
compared to its retrieve-only counterpart. When integrated into the biomedical
RAG, our IR module leads to a state-of-the-art average accuracy of 0.4448 on
the five tasks of the MIRAGE question-answering benchmark, outperforming strong
baselines such as MedCPT (0.4436). Our ablation studies reveal that this
performance is critically dependent on a joint fine-tuning process that aligns
the retriever and re-ranker; otherwise, the re-ranker might degrade the
performance.

</details>


### [89] [Are BabyLMs Deaf to Gricean Maxims? A Pragmatic Evaluation of Sample-efficient Language Models](https://arxiv.org/abs/2510.04764)
*Raha Askari,Sina Zarrieß,Özge Alacam,Judith Sieker*

Main category: cs.CL

TL;DR: 本文通过引入一个新基准测试语言模型对格赖斯会话准则的理解能力，发现训练数据量增加有助提升模型的语用推理能力，但尚未达到儿童和大规模语言模型水平。


<details>
  <summary>Details</summary>
Motivation: 隐含意义是人类交流的重要组成部分，语言模型需要能够识别和解释这些隐含意义。格赖斯提出的会话准则及其故意违反现象为理解语用推理提供了理论基础。

Method: 基于Surian等人的研究，设计了一个测试基准，评估在少于10M和100M训练数据下的语言模型识别遵守或违反格赖斯准则的能力，并与儿童和使用3T训练数据的大型语言模型进行比较。

Result: 100M以下训练数据的模型在区分会话准则的表现上优于10M以下模型，但均未达到儿童和大型语言模型的水平。数据量的适度增加促进了模型语用行为的提升，表现出更细致的语用维度区分能力。

Conclusion: 增加训练数据量虽提高了语用理解能力，但仍需更多资源和方法优化，方能使语言模型达到儿童或大型模型的语用推理水平。

Abstract: Implicit meanings are integral to human communication, making it essential
for language models to be capable of identifying and interpreting them. Grice
(1975) proposed a set of conversational maxims that guide cooperative dialogue,
noting that speakers may deliberately violate these principles to express
meanings beyond literal words, and that listeners, in turn, recognize such
violations to draw pragmatic inferences.
  Building on Surian et al. (1996)'s study of children's sensitivity to
violations of Gricean maxims, we introduce a novel benchmark to test whether
language models pretrained on less than 10M and less than 100M tokens can
distinguish maxim-adhering from maxim-violating utterances. We compare these
BabyLMs across five maxims and situate their performance relative to children
and a Large Language Model (LLM) pretrained on 3T tokens.
  We find that overall, models trained on less than 100M tokens outperform
those trained on less than 10M, yet fall short of child-level and LLM
competence. Our results suggest that modest data increases improve some aspects
of pragmatic behavior, leading to finer-grained differentiation between
pragmatic dimensions.

</details>


### [90] [Hybrid Architectures for Language Models: Systematic Analysis and Design Insights](https://arxiv.org/abs/2510.04800)
*Sangmin Bae,Bilge Acun,Haroun Habeeb,Seungyeon Kim,Chien-Yu Lin,Liang Luo,Junjie Wang,Carole-Jean Wu*

Main category: cs.CL

TL;DR: 本文系统评估了结合自注意力机制与结构化状态空间模型的混合语言模型架构，通过跨层和层内融合策略对其性能和效率进行比较，提出了优化设计方案。


<details>
  <summary>Details</summary>
Motivation: 当前混合架构在长上下文任务中展现了优越的建模质量和计算效率，但缺乏对不同混合策略的系统性比较与关键因素分析。

Method: 本文从跨层（顺序融合）和层内（并行融合）两种混合架构出发，综合评估其在语言建模性能、长上下文处理能力、扩展性、训练及推理效率等方面的表现，深入分析其计算原语的核心特征。

Result: 研究确定了各混合策略的关键因素，并提出了两种混合模型的最优设计方案。

Conclusion: 本文的全面分析为混合语言模型的架构优化提供了实用指导和宝贵见解，有助于推动混合模型的设计与应用。

Abstract: Recent progress in large language models demonstrates that hybrid
architectures--combining self-attention mechanisms with structured state space
models like Mamba--can achieve a compelling balance between modeling quality
and computational efficiency, particularly for long-context tasks. While these
hybrid models show promising performance, systematic comparisons of
hybridization strategies and analyses on the key factors behind their
effectiveness have not been clearly shared to the community. In this work, we
present a holistic evaluation of hybrid architectures based on inter-layer
(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a
variety of perspectives: language modeling performance, long-context
capabilities, scaling analysis, and training and inference efficiency. By
investigating the core characteristics of their computational primitive, we
identify the most critical elements for each hybridization strategy and further
propose optimal design recipes for both hybrid models. Our comprehensive
analysis provides practical guidance and valuable insights for developing
hybrid language models, facilitating the optimization of architectural
configurations.

</details>


### [91] [How I Built ASR for Endangered Languages with a Spoken Dictionary](https://arxiv.org/abs/2510.04832)
*Christopher Bartley,Anton Ragni*

Main category: cs.CL

TL;DR: 本文研究了如何使用极少量和不同形式的数据构建濒危语言的自动语音识别系统，以帮助濒危语言的复兴。


<details>
  <summary>Details</summary>
Motivation: 许多濒危语言缺乏支持现代语音技术的数据格式和数量，阻碍了其语言复兴。传统自动语音识别系统需要大量的语音转录数据，但濒危语言往往无法满足这一需求。

Method: 研究人员利用短形式的发音资源，探索使用仅40分钟的数据构建Manx和Cornish两种濒危语言的自动语音识别系统的方法。

Result: 结果显示，仅使用40分钟的短格式发音数据就能为Manx语构建可用的自动语音识别系统，错误率低于50%。同样方法在Cornish语上复制成功。

Conclusion: 为濒危语言构建自动语音识别系统所需的数据量和形式远比之前认为的低，提升了濒危语言社区参与语音技术复兴的可能性。

Abstract: Nearly half of the world's languages are endangered. Speech technologies such
as Automatic Speech Recognition (ASR) are central to revival efforts, yet most
languages remain unsupported because standard pipelines expect utterance-level
supervised data. Speech data often exist for endangered languages but rarely
match these formats. Manx Gaelic ($\sim$2,200 speakers), for example, has had
transcribed speech since 1948, yet remains unsupported by modern systems. In
this paper, we explore how little data, and in what form, is needed to build
ASR for critically endangered languages. We show that a short-form
pronunciation resource is a viable alternative, and that 40 minutes of such
data produces usable ASR for Manx ($<$50\% WER). We replicate our approach,
applying it to Cornish ($\sim$600 speakers), another critically endangered
language. Results show that the barrier to entry, in quantity and form, is far
lower than previously thought, giving hope to endangered language communities
that cannot afford to meet the requirements arbitrarily imposed upon them.

</details>


### [92] [Instability in Downstream Task Performance During LLM Pretraining](https://arxiv.org/abs/2510.04848)
*Yuto Nishida,Masaru Isonuma,Yusuke Oda*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLM）训练过程中下游任务性能的不稳定性，提出通过检查点平均和集成方法来提高性能稳定性。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型时，下游任务性能指标波动较大，难以准确选取最佳模型检查点。

Method: 通过实验证明并理论分析两种后处理检查点整合方法——检查点平均和集合，减少性能波动。

Result: 这两种方法显著提升了模型下游任务性能的稳定性，无需更改训练流程。

Conclusion: 检查点集成技术是提高训练中LLM下游任务性能稳定性的有效方法，具有实际应用价值。

Abstract: When training large language models (LLMs), it is common practice to track
downstream task performance throughout the training process and select the
checkpoint with the highest validation score. However, downstream metrics often
exhibit substantial fluctuations, making it difficult to identify the
checkpoint that truly represents the best-performing model. In this study, we
empirically analyze the stability of downstream task performance in an LLM
trained on diverse web-scale corpora. We find that task scores frequently
fluctuate throughout training, both at the aggregate and example levels. To
address this instability, we investigate two post-hoc checkpoint integration
methods: checkpoint averaging and ensemble, motivated by the hypothesis that
aggregating neighboring checkpoints can reduce performance volatility. We
demonstrate both empirically and theoretically that these methods improve
downstream performance stability without requiring any changes to the training
procedure.

</details>


### [93] [When Models Lie, We Learn: Multilingual Span-Level Hallucination Detection with PsiloQA](https://arxiv.org/abs/2510.04849)
*Elisei Rykov,Kseniia Petrushina,Maksim Savkin,Valerii Olisov,Artem Vazhentsev,Kseniia Titova,Alexander Panchenko,Vasily Konovalov,Julia Belikova*

Main category: cs.CL

TL;DR: 本文介绍了PsiloQA，这是一个涵盖14种语言且具备细粒度幻觉检测注释的大规模多语言数据集，用于提升大语言模型中的幻觉检测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的幻觉检测基准多为英文且粒度较粗，缺乏细粒度、多语言的监督数据，限制了幻觉检测的全面评估和提升。

Method: 通过三阶段自动化流程构建数据集：利用GPT-4o从维基百科生成问答对，使用多种大语言模型生成潜在幻觉答案，并用GPT-4o对比正确答案和检索上下文自动标注幻觉片段。

Result: 评估多种幻觉检测方法，发现基于编码器模型的检测效果最佳，PsiloQA支持有效的跨语言泛化和知识迁移，且比人工注释数据集更具成本效益。

Conclusion: PsiloQA推动了多语言环境下可扩展、细粒度幻觉检测技术的发展，为安全可靠的大语言模型部署奠定了基础。

Abstract: Hallucination detection remains a fundamental challenge for the safe and
reliable deployment of large language models (LLMs), especially in applications
requiring factual accuracy. Existing hallucination benchmarks often operate at
the sequence level and are limited to English, lacking the fine-grained,
multilingual supervision needed for a comprehensive evaluation. In this work,
we introduce PsiloQA, a large-scale, multilingual dataset annotated with
span-level hallucinations across 14 languages. PsiloQA is constructed through
an automated three-stage pipeline: generating question-answer pairs from
Wikipedia using GPT-4o, eliciting potentially hallucinated answers from diverse
LLMs in a no-context setting, and automatically annotating hallucinated spans
using GPT-4o by comparing against golden answers and retrieved context. We
evaluate a wide range of hallucination detection methods -- including
uncertainty quantification, LLM-based tagging, and fine-tuned encoder models --
and show that encoder-based models achieve the strongest performance across
languages. Furthermore, PsiloQA demonstrates effective cross-lingual
generalization and supports robust knowledge transfer to other benchmarks, all
while being significantly more cost-efficient than human-annotated datasets.
Our dataset and results advance the development of scalable, fine-grained
hallucination detection in multilingual settings.

</details>


### [94] [Detecting Distillation Data from Reasoning Models](https://arxiv.org/abs/2510.04850)
*Hengxiang Zhang,Hyeong Kyu Choi,Yixuan Li,Hongxin Wei*

Main category: cs.CL

TL;DR: 本文提出了一种检测推理蒸馏数据的方法，以避免数据泄露对模型性能评估的影响。


<details>
  <summary>Details</summary>
Motivation: 推理蒸馏可能导致基准测试污染，蒸馏数据包含评测数据，导致性能指标被夸大，因此需要检测蒸馏数据。

Method: 提出Token Probability Deviation（TBD）方法，通过分析生成输出的token概率偏离程度，区分已见和未见问题。

Result: TBD方法在S1数据集上取得AUC 0.918和TPR@1%FPR 0.470的优秀检测效果。

Conclusion: TBD方法有效检测推理蒸馏数据，能够区分蒸馏中见过和未见过的数据，防止性能指标被污染。

Abstract: Reasoning distillation has emerged as an efficient and powerful paradigm for
enhancing the reasoning capabilities of large language models. However,
reasoning distillation may inadvertently cause benchmark contamination, where
evaluation data included in distillation datasets can inflate performance
metrics of distilled models. In this work, we formally define the task of
distillation data detection, which is uniquely challenging due to the partial
availability of distillation data. Then, we propose a novel and effective
method Token Probability Deviation (TBD), which leverages the probability
patterns of the generated output tokens. Our method is motivated by the
analysis that distilled models tend to generate near-deterministic tokens for
seen questions, while producing more low-probability tokens for unseen
questions. Our key idea behind TBD is to quantify how far the generated tokens'
probabilities deviate from a high reference probability. In effect, our method
achieves competitive detection performance by producing lower scores for seen
questions than for unseen questions. Extensive experiments demonstrate the
effectiveness of our method, achieving an AUC of 0.918 and a TPR@1% FPR of
0.470 on the S1 dataset.

</details>


### [95] [SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891)
*Punya Syon Pandey,Hai Son Le,Devansh Bhardwaj,Rada Mihalcea,Zhijing Jin*

Main category: cs.CL

TL;DR: 该论文提出了SocialHarmBench数据集，测试大型语言模型在涉及政治操控和宣传等社会政治问题上的安全漏洞，发现模型在特定国家和时代背景下表现脆弱，安全防护不足。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在敏感社会政治领域的失败可能导致严重后果，但缺少针对这些方面的安全测试基准。

Method: 构建涵盖7个社会政治类别和34个国家的585条提示的SocialHarmBench数据集，并对不同模型在这些情境下的表现进行评估。

Result: 模型如Mistral-7B在历史修正主义、宣传和政治操控等领域的攻击成功率高达97%-98%，且模型在21世纪及20世纪以前背景以及拉美、美国和英国相关提示中更脆弱。

Conclusion: 现有的安全防护机制未能有效应对高风险社会政治场景，暴露了系统性偏见，影响模型在维护人权和民主价值方面的可靠性。

Abstract: Large language models (LLMs) are increasingly deployed in contexts where
their failures can have direct sociopolitical consequences. Yet, existing
safety benchmarks rarely test vulnerabilities in domains such as political
manipulation, propaganda and disinformation generation, or surveillance and
information control. We introduce SocialHarmBench, a dataset of 585 prompts
spanning 7 sociopolitical categories and 34 countries, designed to surface
where LLMs most acutely fail in politically charged contexts. Our evaluations
reveal several shortcomings: open-weight models exhibit high vulnerability to
harmful compliance, with Mistral-7B reaching attack success rates as high as
97% to 98% in domains such as historical revisionism, propaganda, and political
manipulation. Moreover, temporal and geographic analyses show that LLMs are
most fragile when confronted with 21st-century or pre-20th-century contexts,
and when responding to prompts tied to regions such as Latin America, the USA,
and the UK. These findings demonstrate that current safeguards fail to
generalize to high-stakes sociopolitical settings, exposing systematic biases
and raising concerns about the reliability of LLMs in preserving human rights
and democratic values. We share the SocialHarmBench benchmark at
https://huggingface.co/datasets/psyonp/SocialHarmBench.

</details>


### [96] [Do LLMs Align with My Task? Evaluating Text-to-SQL via Dataset Alignment](https://arxiv.org/abs/2510.04919)
*Davood Rafiei,Morgan Lindsay Heisler,Weiwei Zhang,Mohammadreza Pourreza,Yong Zhang*

Main category: cs.CL

TL;DR: 本文研究了监督微调中训练数据与目标查询的结构特征对齐问题，发现结构对齐程度显著影响NL2SQL任务的微调效果。


<details>
  <summary>Details</summary>
Motivation: 目前监督微调中的训练数据存在多样性，导致模型在不同领域的泛化能力不足。探讨训练数据和目标查询结构特征的对齐对模型表现的影响。

Method: 通过比较训练集、目标数据以及模型在微调前预测的结构SQL特征分布，量化数据对齐度。对三大跨领域NL2SQL基准和多模型体系进行综合实验验证对齐度与微调效果的关系。

Result: 结构对齐程度高时，监督微调带来显著的准确率和SQL生成质量提升；对齐度低时，提升有限甚至无效。

Conclusion: 数据的结构对齐性对NL2SQL任务中的微调效果至关重要，提示在数据选择时应重视结构对齐以提升模型泛化能力和性能。

Abstract: Supervised Fine-Tuning (SFT) is an effective method for adapting Large
Language Models (LLMs) on downstream tasks. However, variability in training
data can hinder a model's ability to generalize across domains. This paper
studies the problem of dataset alignment for Natural Language to SQL (NL2SQL or
text to SQL), examining how well SFT training data matches the structural
characteristics of target queries and how this alignment impacts model
performance. We hypothesize that alignment can be accurately estimated by
comparing the distributions of structural SQL features across the training set,
target data, and the model's predictions prior to SFT. Through comprehensive
experiments on three large cross-domain NL2SQL benchmarks and multiple model
families, we show that structural alignment is a strong predictor of
fine-tuning success. When alignment is high, SFT yields substantial gains in
accuracy and SQL generation quality; when alignment is low, improvements are
marginal or absent. These findings highlight the importance of alignment-aware
data selection for effective fine-tuning and generalization in NL2SQL tasks.

</details>


### [97] [The Geometry of Truth: Layer-wise Semantic Dynamics for Hallucination Detection in Large Language Models](https://arxiv.org/abs/2510.04933)
*Amir Hameed Mir*

Main category: cs.CL

TL;DR: 提出了一种基于变换器层隐藏状态语义动态的幻觉检测框架LSD，在单次前向传播中高效准确地检测语言模型的事实错误。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常出现流畅但事实错误的“幻觉”，在高风险领域带来严重风险，现有方法效率低且依赖外部资源，亟需高效且模型内部的幻觉检测机制。

Method: 设计了一种几何框架LSD，通过分析变换器各层隐藏状态的语义变化轨迹，使用基于边缘的对比学习将隐藏激活与事实编码器得出的真值嵌入对齐，区分真实与幻觉的语义漂移差异。

Result: 在TruthfulQA和合成数据集上，LSD取得F1分数0.92，AUROC 0.96，聚类准确率0.89，性能优于SelfCheckGPT和Semantic Entropy基线，且仅需单次前向传播，速度提升5-20倍。

Conclusion: LSD提供了一种高效、模型无关的实时幻觉监控方法，揭示了大语言模型中事实一致性语义几何特征，具备良好的精度、可解释性和扩展性。

Abstract: Large Language Models (LLMs) often produce fluent yet factually incorrect
statements-a phenomenon known as hallucination-posing serious risks in
high-stakes domains. We present Layer-wise Semantic Dynamics (LSD), a geometric
framework for hallucination detection that analyzes the evolution of
hidden-state semantics across transformer layers. Unlike prior methods that
rely on multiple sampling passes or external verification sources, LSD operates
intrinsically within the model's representational space. Using margin-based
contrastive learning, LSD aligns hidden activations with ground-truth
embeddings derived from a factual encoder, revealing a distinct separation in
semantic trajectories: factual responses preserve stable alignment, while
hallucinations exhibit pronounced semantic drift across depth. Evaluated on the
TruthfulQA and synthetic factual-hallucination datasets, LSD achieves an
F1-score of 0.92, AUROC of 0.96, and clustering accuracy of 0.89, outperforming
SelfCheckGPT and Semantic Entropy baselines while requiring only a single
forward pass. This efficiency yields a 5-20x speedup over sampling-based
methods without sacrificing precision or interpretability. LSD offers a
scalable, model-agnostic mechanism for real-time hallucination monitoring and
provides new insights into the geometry of factual consistency within large
language models.

</details>


### [98] [A First Context-Free Grammar Applied to Nawatl Corpora Augmentation](https://arxiv.org/abs/2510.04945)
*Juan-José Guzmán-Landa,Juan-Manuel Torres-Moreno,Miguel Figueroa-Saavedra,Ligia Quintana-Torres,Martha-Lorena Avendaño-Garrido,Graham Ranger*

Main category: cs.CL

TL;DR: 本文介绍了一种针对Nawatl语言的上下文无关文法(CFG)，旨在生成大量语法正确的人工句子，以扩充该语言的语料库，从而提升语言模型的训练效果。


<details>
  <summary>Details</summary>
Motivation: Nawatl语言数字资源匮乏，缺少足够的语料库用于机器学习，限制了语言模型的训练和评估。

Method: 构建Nawatl语言的上下文无关文法，用以生成大量人工句子，丰富语料库，并利用生成的语料训练FastText算法，进行句子层面语义任务的评估。

Result: 使用语法生成的语料使得训练结果在某些大型语言模型(LLMs)上取得了比较性的提升。

Conclusion: 尽管已有改进，但需开发更有效建模Nawatl语言的文法，以实现更显著的性能提升。

Abstract: In this article we introduce a context-free grammar (CFG) for the Nawatl
language. Nawatl (or Nahuatl) is an Amerindian language of the $\pi$-language
type, i.e. a language with few digital resources, in which the corpora
available for machine learning are virtually non-existent. The objective here
is to generate a significant number of grammatically correct artificial
sentences, in order to increase the corpora available for language model
training. We want to show that a grammar enables us significantly to expand a
corpus in Nawatl which we call $\pi$-\textsc{yalli}. The corpus, thus enriched,
enables us to train algorithms such as FastText and to evaluate them on
sentence-level semantic tasks. Preliminary results show that by using the
grammar, comparative improvements are achieved over some LLMs. However, it is
observed that to achieve more significant improvement, grammars that model the
Nawatl language even more effectively are required.

</details>


### [99] [Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy (short paper)](https://arxiv.org/abs/2510.04950)
*Om Dobariya,Akhil Kumar*

Main category: cs.CL

TL;DR: 论文研究了自然语言提示中礼貌程度对大语言模型多选题准确率的影响，发现不礼貌的提示比礼貌的提示表现更好。


<details>
  <summary>Details</summary>
Motivation: 探索礼貌和语气如何影响大语言模型的回答准确性，弥补该领域研究不足。

Method: 设计包含50道涵盖数学、科学和历史的题目，每题改写为五种语气（非常礼貌、礼貌、中性、粗鲁、非常粗鲁），用ChatGPT-4进行测试并用配对t检验分析结果。

Result: 不礼貌（特别是非常粗鲁）提示的准确率（84.8%）显著高于礼貌提示（80.8%），与此前认为粗鲁会降低模型表现的研究相反。

Conclusion: 提示语气显著影响大语言模型表现，新一代模型对语气的响应不同于早期模型，需重视人机交互中的社会语用因素。

Abstract: The wording of natural language prompts has been shown to influence the
performance of large language models (LLMs), yet the role of politeness and
tone remains underexplored. In this study, we investigate how varying levels of
prompt politeness affect model accuracy on multiple-choice questions. We
created a dataset of 50 base questions spanning mathematics, science, and
history, each rewritten into five tone variants: Very Polite, Polite, Neutral,
Rude, and Very Rude, yielding 250 unique prompts. Using ChatGPT 4o, we
evaluated responses across these conditions and applied paired sample t-tests
to assess statistical significance. Contrary to expectations, impolite prompts
consistently outperformed polite ones, with accuracy ranging from 80.8% for
Very Polite prompts to 84.8% for Very Rude prompts. These findings differ from
earlier studies that associated rudeness with poorer outcomes, suggesting that
newer LLMs may respond differently to tonal variation. Our results highlight
the importance of studying pragmatic aspects of prompting and raise broader
questions about the social dimensions of human-AI interaction.

</details>


### [100] [AWARE, Beyond Sentence Boundaries: A Contextual Transformer Framework for Identifying Cultural Capital in STEM Narratives](https://arxiv.org/abs/2510.04983)
*Khalid Mehtab Khan,Anagha Kulkarni*

Main category: cs.CL

TL;DR: 本文提出AWARE框架通过增强模型对文化资本主题的领域、上下文及标签重叠的感知，提升学生反思文本主题识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 学生反思中的文化资本主题常以叙事形式出现，难以被传统NLP模型有效识别，因为这些模型缺乏领域特定和上下文理解。

Method: AWARE框架包含领域感知（适应学生文本语言风格）、上下文感知（结合全文语境生成句子嵌入）和类别重叠感知（多标签策略识别单句多主题）。

Result: AWARE在Macro-F1指标上比强基线提升2.1个百分点，并在所有主题上均表现提升。

Conclusion: 通过增强模型对输入属性的感知能力，AWARE为基于叙事上下文的文本分类任务提供了有效且通用的方法。

Abstract: Identifying cultural capital (CC) themes in student reflections can offer
valuable insights that help foster equitable learning environments in
classrooms. However, themes such as aspirational goals or family support are
often woven into narratives, rather than appearing as direct keywords. This
makes them difficult to detect for standard NLP models that process sentences
in isolation. The core challenge stems from a lack of awareness, as standard
models are pre-trained on general corpora, leaving them blind to the
domain-specific language and narrative context inherent to the data. To address
this, we introduce AWARE, a framework that systematically attempts to improve a
transformer model's awareness for this nuanced task. AWARE has three core
components: 1) Domain Awareness, adapting the model's vocabulary to the
linguistic style of student reflections; 2) Context Awareness, generating
sentence embeddings that are aware of the full essay context; and 3) Class
Overlap Awareness, employing a multi-label strategy to recognize the
coexistence of themes in a single sentence. Our results show that by making the
model explicitly aware of the properties of the input, AWARE outperforms a
strong baseline by 2.1 percentage points in Macro-F1 and shows considerable
improvements across all themes. This work provides a robust and generalizable
methodology for any text classification task in which meaning depends on the
context of the narrative.

</details>


### [101] [Resource-Efficient Fine-Tuning of LLaMA-3.2-3B for Medical Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.05003)
*Imran Mansha*

Main category: cs.CL

TL;DR: 本文提出了一种资源高效的微调方法，通过参数高效调优技术改进了LLaMA-3.2-3B模型在医学推理任务中的表现，同时大幅减少了内存使用。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型如GPT-4、LLaMA推理能力强，但微调需大量计算资源，限制了低资源环境的应用。

Method: 采用LoRA和QLoRA等参数高效调优技术，在公开医疗推理数据集上对LLaMA模型进行适配。

Result: 模型推理连贯性和事实准确性提升，内存使用降低最多达60%，在医学问答任务中保持了强推理能力。

Conclusion: 研究展示了在资源受限环境下部署大型语言模型的有效策略，实现了效率与领域专业化的平衡，推动医学AI系统的发展。

Abstract: Large Language Models (LLMs) such as GPT-4 and LLaMA have demonstrated
remarkable reasoning abilities but require significant computational resources
for fine-tuning. This paper presents a resource-efficient fine-tuning approach
for LLaMA-3.2-3B to enhance medical chain-of-thought reasoning while operating
under constrained GPU and memory settings. Using parameter-efficient tuning
techniques such as LoRA and QLoRA, we adapt the base model on publicly
available medical reasoning datasets. The model achieves improved reasoning
coherence and factual accuracy while reducing memory usage by up to 60%
compared to standard full fine-tuning. Experimental evaluation demonstrates
that lightweight adaptations can retain strong reasoning capability in medical
question-answering tasks. This work highlights practical strategies for
deploying LLMs in low-resource research environments and provides insights into
balancing efficiency and domain specialization for medical AI systems.

</details>


### [102] [Imperceptible Jailbreaking against Large Language Models](https://arxiv.org/abs/2510.05025)
*Kuofeng Gao,Yiming Li,Chao Du,Xin Wang,Xingjun Ma,Shu-Tao Xia,Tianyu Pang*

Main category: cs.CL

TL;DR: 本文提出了一种利用Unicode变体选择器实现的视觉上不可察觉的越狱攻击方法。


<details>
  <summary>Details</summary>
Motivation: 传统视觉模态的越狱攻击依赖于难以察觉的对抗扰动，而文本模态攻击通常需明显的修改，本文旨在破解这一限制，开发不产生可见修改的文本模态越狱攻击。

Method: 通过在恶意文本后附加不可见的Unicode变体选择器，改变tokenization但保持视觉一致。采用链式搜索流水线生成对抗后缀以诱导有害响应。

Result: 所提方法在四个对齐的语言模型上均表现出高攻击成功率，且能推广至提示注入攻击，且无任何可见改动。

Conclusion: 该方法成功实现了文本模态下视觉不可察觉的越狱攻击，提升了攻击的隐蔽性和有效性。相关代码已开源。

Abstract: Jailbreaking attacks on the vision modality typically rely on imperceptible
adversarial perturbations, whereas attacks on the textual modality are
generally assumed to require visible modifications (e.g., non-semantic
suffixes). In this paper, we introduce imperceptible jailbreaks that exploit a
class of Unicode characters called variation selectors. By appending invisible
variation selectors to malicious questions, the jailbreak prompts appear
visually identical to original malicious questions on screen, while their
tokenization is "secretly" altered. We propose a chain-of-search pipeline to
generate such adversarial suffixes to induce harmful responses. Our experiments
show that our imperceptible jailbreaks achieve high attack success rates
against four aligned LLMs and generalize to prompt injection attacks, all
without producing any visible modifications in the written prompt. Our code is
available at https://github.com/sail-sg/imperceptible-jailbreaks.

</details>


### [103] [A Set of Quebec-French Corpus of Regional Expressions and Terms](https://arxiv.org/abs/2510.05026)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: 本文结合习语理解和方言理解，提出以区域习语测试方言理解能力，创建了两套法语魁北克方言的习语基准数据集，并通过94个大语言模型实验验证了数据集的有效性。


<details>
  <summary>Details</summary>
Motivation: 习语理解和方言理解都是自然语言处理中的重要任务，结合二者可以更准确评估模型对特定方言的理解能力。

Method: 构建了两个基于魁北克法语的习语基准数据集，分别包含成语短语和成语单词实例；设计了构造方法以便推广到其他方言。

Result: 使用94个大型语言模型进行实验，结果表明新数据集能够有效衡量模型在特定方言上的理解水平。

Conclusion: 区域习语基准数据集为评测模型方言理解能力提供了可靠工具，方法可推广到其他方言研究。

Abstract: The tasks of idiom understanding and dialect understanding are both
well-established benchmarks in natural language processing. In this paper, we
propose combining them, and using regional idioms as a test of dialect
understanding. Towards this end, we propose two new benchmark datasets for the
Quebec dialect of French: QFrCoRE, which contains 4,633 instances of idiomatic
phrases, and QFrCoRT, which comprises 171 regional instances of idiomatic
words. We explain how to construct these corpora, so that our methodology can
be replicated for other dialects. Our experiments with 94 LLM demonstrate that
our regional idiom benchmarks are a reliable tool for measuring a model's
proficiency in a specific dialect.

</details>


### [104] [Guided Query Refinement: Multimodal Hybrid Retrieval with Test-Time Optimization](https://arxiv.org/abs/2510.05038)
*Omri Uzan,Asaf Yehudai,Roi pony,Eyal Shnarch,Ariel Gera*

Main category: cs.CL

TL;DR: 本文提出了一种名为Guided Query Refinement (GQR)的测试时优化方法，通过结合轻量级密集文本检索器的指导，提升视觉文档检索中视觉中心模型的查询嵌入表现，在保持高性能的同时显著提高检索速度和降低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 当前多模态编码器在视觉文档检索中性能优异，但模型规模庞大，部署和扩展受限，同时纯视觉方法受限于模态间隔离。探索轻量级文本检索器如何辅助改善视觉中心模型是提升效率和性能的关键。

Method: 提出Guided Query Refinement (GQR)方法，在测试阶段使用辅助检索器的得分指导主检索器的查询嵌入优化，比传统粗粒度融合方法更深度利用模型表征空间的内部交互。

Result: 在视觉文档检索基准上，GQR使视觉中心模型性能匹配大规模表示模型，同时速度快14倍，内存需求减少54倍，显著提升性能与效率的平衡。

Conclusion: GQR有效缓解了多模态检索中的性能与效率权衡，通过融合不同检索模型优势，推动相关应用的实用性和扩展性。源码已开源。

Abstract: Multimodal encoders have pushed the boundaries of visual document retrieval,
matching textual query tokens directly to image patches and achieving
state-of-the-art performance on public benchmarks. Recent models relying on
this paradigm have massively scaled the sizes of their query and document
representations, presenting obstacles to deployment and scalability in
real-world pipelines. Furthermore, purely vision-centric approaches may be
constrained by the inherent modality gap still exhibited by modern
vision-language models. In this work, we connect these challenges to the
paradigm of hybrid retrieval, investigating whether a lightweight dense text
retriever can enhance a stronger vision-centric model. Existing hybrid methods,
which rely on coarse-grained fusion of ranks or scores, fail to exploit the
rich interactions within each model's representation space. To address this, we
introduce Guided Query Refinement (GQR), a novel test-time optimization method
that refines a primary retriever's query embedding using guidance from a
complementary retriever's scores. Through extensive experiments on visual
document retrieval benchmarks, we demonstrate that GQR allows vision-centric
models to match the performance of models with significantly larger
representations, while being up to 14x faster and requiring 54x less memory.
Our findings show that GQR effectively pushes the Pareto frontier for
performance and efficiency in multimodal retrieval. We release our code at
https://github.com/IBM/test-time-hybrid-retrieval

</details>


### [105] [COLE: a Comprehensive Benchmark for French Language Understanding Evaluation](https://arxiv.org/abs/2510.05046)
*David Beauchemin,Yan Tremblay,Mohamed Amine Youssef,Richard Khoury*

Main category: cs.CL

TL;DR: COLE是针对法语自然语言理解的新基准，涵盖23个多样化任务，评价94个大型语言模型，发现闭源与开源模型性能差距，并指出当前模型在零样本抽取式问答、细粒度词义消歧和地区语言变体理解上的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了更全面地评价法语自然语言理解能力，创建一个涵盖多种语言现象的评测基准。

Method: 设计包含23个涉及情感分析、同义句检测、语法判断及推理等任务的基准，测试94个大型语言模型性能。

Result: 发现闭源模型表现显著优于开源模型，同时当前模型在零样本抽取式问答、细粒度词义消歧及区域语言变体理解方面存在困难。

Conclusion: 发布COLE基准以促进法语语言模型的进一步发展和改进。

Abstract: To address the need for a more comprehensive evaluation of French Natural
Language Understanding (NLU), we introduce COLE, a new benchmark composed of 23
diverse task covering a broad range of NLU capabilities, including sentiment
analysis, paraphrase detection, grammatical judgment, and reasoning, with a
particular focus on linguistic phenomena relevant to the French language. We
benchmark 94 large language models (LLM), providing an extensive analysis of
the current state of French NLU. Our results highlight a significant
performance gap between closed- and open-weights models and identify key
challenging frontiers for current LLMs, such as zero-shot extractive
question-answering (QA), fine-grained word sense disambiguation, and
understanding of regional language variations. We release COLE as a public
resource to foster further progress in French language modelling.

</details>


### [106] [SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior Reasoning LLMs](https://arxiv.org/abs/2510.05069)
*Dachuan Shi,Abedelkadir Asi,Keying Li,Xiangchi Yuan,Leyan Pan,Wenke Lee,Wen Xiao*

Main category: cs.CL

TL;DR: 本文提出了SwiReasoning，一种结合显式与潜在推理的训练免费大语言模型推理框架，能提升推理准确率和令牌效率。


<details>
  <summary>Details</summary>
Motivation: 现有潜在空间推理虽然可以提高信息利用率和效率，但存在搜索空间扩散导致准确率下降和过度思考浪费令牌的问题，尤其在无训练环境下表现尤为突出。

Method: SwiReasoning通过动态切换显式和潜在推理模式，基于下一个令牌分布的熵趋势评估置信度来指导推理过程；同时限制思考块的最大切换次数以抑制过度思考。

Result: 在数学和STEM基准测试上，SwiReasoning使不同模型家族和规模的大语言模型准确率提升1.5%-2.8%，在计算预算受限情况下，令牌效率提升达到56%-79%，提升在预算越紧张时越显著。

Conclusion: SwiReasoning有效解决了潜在推理中的搜索空间扩散与过度思考问题，实现了推理准确率与令牌效率的双重提升，适用于多种模型和任务场景。

Abstract: Recent work shows that, beyond discrete reasoning through explicit
chain-of-thought steps, which are limited by the boundaries of natural
languages, large language models (LLMs) can also reason continuously in latent
space, allowing richer information per step and thereby improving token
efficiency. Despite this promise, latent reasoning still faces two challenges,
especially in training-free settings: 1) purely latent reasoning broadens the
search distribution by maintaining multiple implicit paths, which diffuses
probability mass, introduces noise, and impedes convergence to a single
high-confidence solution, thereby hurting accuracy; and 2) overthinking
persists even without explicit text, wasting tokens and degrading efficiency.
To address these issues, we introduce SwiReasoning, a training-free framework
for LLM reasoning which features two key innovations: 1) SwiReasoning
dynamically switches between explicit and latent reasoning, guided by
block-wise confidence estimated from entropy trends in next-token
distributions, to balance exploration and exploitation and promote timely
convergence. 2) By limiting the maximum number of thinking-block switches,
SwiReasoning curbs overthinking and improves token efficiency across varying
problem difficulties. On widely used mathematics and STEM benchmarks,
SwiReasoning consistently improves average accuracy by 1.5%-2.8% across
reasoning LLMs of different model families and scales. Furthermore, under
constrained budgets, SwiReasoning improves average token efficiency by 56%-79%,
with larger gains as budgets tighten.

</details>


### [107] [Slm-mux: Orchestrating small language models for reasoning](https://arxiv.org/abs/2510.05077)
*Chenyu Wang,Zishen Wan,Hao Kang,Emma Chen,Zhiqiang Xie,Tushar Krishna,Vijay Janapa Reddi,Yilun Du*

Main category: cs.CL

TL;DR: 本文提出了一种三阶段方法，利用多模型架构SLM-MUX协调多个小型语言模型（SLMs），通过模型选择搜索和测试时缩放优化策略，提高了多个任务的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着小型语言模型数量的增加，如何有效协调多个SLMs以达到比单一模型更高的准确率成为一个重要问题，现有方法针对大型模型效果不佳。

Method: 提出SLM-MUX架构协调多个SLMs，结合模型选择搜索和测试时缩放两种优化策略。

Result: 在多个任务上（MATH、GPQA、GSM8K）相比现有方法提升最高达13.4%，仅用两个SLMs即超越了大模型Qwen 2.5 72B部分任务表现。

Conclusion: 通过SLM-MUX及优化策略，小型语言模型可被高效协调，构建出更准确且高效的系统。

Abstract: With the rapid development of language models, the number of small language
models (SLMs) has grown significantly. Although they do not achieve
state-of-the-art accuracy, they are more efficient and often excel at specific
tasks. This raises a natural question: can multiple SLMs be orchestrated into a
system where each contributes effectively, achieving higher accuracy than any
individual model? Existing orchestration methods have primarily targeted
frontier models (e.g., GPT-4) and perform suboptimally when applied to SLMs. To
address this gap, we propose a three-stage approach for orchestrating SLMs.
First, we introduce SLM-MUX, a multi-model architecture that effectively
coordinates multiple SLMs. Building on this, we develop two optimization
strategies: (i) a model selection search that identifies the most complementary
SLMs from a given pool, and (ii) test-time scaling tailored to SLM-MUX. Our
approach delivers strong results: Compared to existing orchestration methods,
our approach achieves up to 13.4% improvement on MATH, 8.8% on GPQA, and 7.0%
on GSM8K. With just two SLMS, SLM-MUX outperforms Qwen 2.5 72B on GPQA and
GSM8K, and matches its performance on MATH. We further provide theoretical
analyses to substantiate the advantages of our method. In summary, we
demonstrate that SLMs can be effectively orchestrated into more accurate and
efficient systems through the proposed approach.

</details>


### [108] [TeachLM: Post-Training LLMs for Education Using Authentic Learning Data](https://arxiv.org/abs/2510.05087)
*Janos Perczel,Jin Chow,Dorottya Demszky*

Main category: cs.CL

TL;DR: 本文提出了TeachLM，一种通过参数高效微调基于真实学生数据的生成式AI模型，以提升教学对话质量和个性化。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在教育领域受限于缺乏高质量学生学习数据，且提示工程无法有效编码复杂教学策略。

Method: 使用参数高效微调技术，基于Polygence提供的10万小时一对一学生辅导对话数据训练TeachLM，并提出多轮对话的合成评估协议。

Result: 微调后的TeachLM显著提升了对话和教学表现，如学生发言时间翻倍，提问风格优化，对话轮次增加50%，以及教学个性化增强。

Conclusion: 基于真实学习数据的微调能有效提升大语言模型的教学对话能力，促进生成式AI在教育领域的应用。

Abstract: The promise of generative AI to revolutionize education is constrained by the
pedagogical limits of large language models (LLMs). A major issue is the lack
of access to high-quality training data that reflect the learning of actual
students. Prompt engineering has emerged as a stopgap, but the ability of
prompts to encode complex pedagogical strategies in rule-based natural language
is inherently limited. To address this gap we introduce TeachLM - an LLM
optimized for teaching through parameter-efficient fine-tuning of
state-of-the-art models. TeachLM is trained on a dataset comprised of 100,000
hours of one-on-one, longitudinal student-tutor interactions maintained by
Polygence, which underwent a rigorous anonymization process to protect privacy.
We use parameter-efficient fine-tuning to develop an authentic student model
that enables the generation of high-fidelity synthetic student-tutor dialogues.
Building on this capability, we propose a novel multi-turn evaluation protocol
that leverages synthetic dialogue generation to provide fast, scalable, and
reproducible assessments of the dialogical capabilities of LLMs. Our
evaluations demonstrate that fine-tuning on authentic learning data
significantly improves conversational and pedagogical performance - doubling
student talk time, improving questioning style, increasing dialogue turns by
50%, and greater personalization of instruction.

</details>


### [109] [Finish First, Perfect Later: Test-Time Token-Level Cross-Validation for Diffusion Large Language Models](https://arxiv.org/abs/2510.05090)
*Runchu Tian,Junxia Cui,Xueqiang Xu,Feng Yao,Jingbo Shang*

Main category: cs.CL

TL;DR: 提出了一种名为Tolerator的无训练解码策略，通过交叉验证和迭代重掩码，解决扩散大语言模型中已接受token无法修正的问题，提高生成文本质量。


<details>
  <summary>Details</summary>
Motivation: 扩散大语言模型当前的解码策略一旦接受一个token便不能修改，早期错误会持续影响最终输出质量。

Method: 设计了Tolerator，两阶段解码：填充序列和通过重新掩码及部分token再解码进行迭代修正，使已接受token有机会被重新考虑和纠正。

Result: 在五个基准测试（语言理解、代码生成、数学）中，Tolerator在相同计算预算下均优于基线方法。

Conclusion: 改进的解码算法对充分发挥扩散大语言模型潜力至关重要，Tolerator提升了输出的可靠性和质量。代码和数据已公开。

Abstract: Diffusion large language models (dLLMs) have recently emerged as a promising
alternative to autoregressive (AR) models, offering advantages such as
accelerated parallel decoding and bidirectional context modeling. However, the
vanilla decoding strategy in discrete dLLMs suffers from a critical limitation:
once a token is accepted, it can no longer be revised in subsequent steps. As a
result, early mistakes persist across iterations, harming both intermediate
predictions and final output quality. To address this issue, we propose
Tolerator (Token-Level Cross-Validation Refinement), a training-free decoding
strategy that leverages cross-validation among predicted tokens. Unlike
existing methods that follow a single progressive unmasking procedure,
Tolerator introduces a two-stage process: (i) sequence fill-up and (ii)
iterative refinement by remasking and decoding a subset of tokens while
treating the remaining as context. This design enables previously accepted
tokens to be reconsidered and corrected when necessary, leading to more
reliable diffusion decoding outputs. We evaluate Tolerator on five standard
benchmarks covering language understanding, code generation, and mathematics.
Experiments show that our method achieves consistent improvements over the
baselines under the same computational budget. These findings suggest that
decoding algorithms are crucial to realizing the full potential of diffusion
large language models. Code and data are publicly available.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [110] [LegalSim: Multi-Agent Simulation of Legal Systems for Discovering Procedural Exploits](https://arxiv.org/abs/2510.03405)
*Sanket Badhe*

Main category: cs.MA

TL;DR: LegalSim是一个模拟对抗性法律程序的多智能体系统，研究AI如何利用法律程序中的弱点。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统在法律程序中如何利用规范规则的程序性漏洞。

Method: 设计了包含原告和被告代理的多智能体系统，使用JSON规则引擎和随机法官模型，比较PPO、上下文bandit+LLM、直接LLM策略及手工启发式策略，并通过综合评分评价策略表现。

Result: 发现了系统中出现的程序性有效但有害的“利用链”，PPO表现最佳，bandit最稳定，LLM次之，启发式最差。结果在不同法官设定下稳定。

Conclusion: 模拟展示了AI可发现并利用法律程序漏洞，提示需要对法律规则系统进行红队测试，以补充模型层面的评估。

Abstract: We present LegalSim, a modular multi-agent simulation of adversarial legal
proceedings that explores how AI systems can exploit procedural weaknesses in
codified rules. Plaintiff and defendant agents choose from a constrained action
space (for example, discovery requests, motions, meet-and-confer, sanctions)
governed by a JSON rules engine, while a stochastic judge model with calibrated
grant rates, cost allocations, and sanction tendencies resolves outcomes. We
compare four policies: PPO, a contextual bandit with an LLM, a direct LLM
policy, and a hand-crafted heuristic; Instead of optimizing binary case
outcomes, agents are trained and evaluated using effective win rate and a
composite exploit score that combines opponent-cost inflation, calendar
pressure, settlement pressure at low merit, and a rule-compliance margin.
Across configurable regimes (e.g., bankruptcy stays, inter partes review, tax
procedures) and heterogeneous judges, we observe emergent ``exploit chains'',
such as cost-inflating discovery sequences and calendar-pressure tactics that
remain procedurally valid yet systemically harmful. Evaluation via cross-play
and Bradley-Terry ratings shows, PPO wins more often, the bandit is the most
consistently competitive across opponents, the LLM trails them, and the
heuristic is weakest. The results are stable in judge settings, and the
simulation reveals emergent exploit chains, motivating red-teaming of legal
rule systems in addition to model-level testing.

</details>


### [111] [Long-Term Mapping of the Douro River Plume with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.03534)
*Nicolò Dal Fabbro,Milad Mesbahi,Renato Mendes,João Borges de Sousa,George J. Pappas*

Main category: cs.MA

TL;DR: 本文提出一种基于多智能体强化学习的方法，实现多天河流羽流的长期映射，并在多个自主水下航行器（AUV）之间协调，提高能效和通信效率。


<details>
  <summary>Details</summary>
Motivation: 长期监测河流羽流以支持环境研究和资源管理，但面对水下车辆能耗和通信限制挑战。

Method: 采用中心协调器间歇式通信，结合时空高斯过程回归与多头Q网络控制器，调节各AUV速度和方向。

Result: 通过Delft3D模拟验证，方法优于单智能体和多智能体基线，随着AUV数量增加，误差降低且续航提升，双倍AUV可实现续航倍增。

Conclusion: 多智能体强化学习与高斯过程回归结合的策略能够实现长期、精准、高效的河流羽流监测，具备良好的跨季节泛化能力。

Abstract: We study the problem of long-term (multiple days) mapping of a river plume
using multiple autonomous underwater vehicles (AUVs), focusing on the Douro
river representative use-case. We propose an energy - and communication -
efficient multi-agent reinforcement learning approach in which a central
coordinator intermittently communicates with the AUVs, collecting measurements
and issuing commands. Our approach integrates spatiotemporal Gaussian process
regression (GPR) with a multi-head Q-network controller that regulates
direction and speed for each AUV. Simulations using the Delft3D ocean model
demonstrate that our method consistently outperforms both single- and
multi-agent benchmarks, with scaling the number of agents both improving mean
squared error (MSE) and operational endurance. In some instances, our algorithm
demonstrates that doubling the number of AUVs can more than double endurance
while maintaining or improving accuracy, underscoring the benefits of
multi-agent coordination. Our learned policies generalize across unseen
seasonal regimes over different months and years, demonstrating promise for
future developments of data-driven long-term monitoring of dynamic plume
environments.

</details>


### [112] [Cooperative Flexibility Exchange: Fair and Comfort-Aware Decentralized Resource Allocation](https://arxiv.org/abs/2510.04192)
*Rabiya Khalid,Evangelos Pournaras*

Main category: cs.MA

TL;DR: 提出了一种基于多智能体协调的分布式需求侧管理系统，通过插槽交换机制优化能量调度，提高用户舒适度和公平性，同时保持系统效率。


<details>
  <summary>Details</summary>
Motivation: 随着电力需求增长和智能设备普及，现有能源管理系统往往牺牲用户舒适度来实现系统效率，本研究旨在解决这一矛盾。

Method: 设计了多智能体协调机制，智能体首先获得优化的设备级能耗时间表，然后通过插槽交换机制相互协调调整，从而提升用户体验和系统公平性。

Result: 实验基于真实数据集，结果显示提出的方法在不增加系统效率成本的前提下显著提升了用户舒适度和公平性，且具有良好的扩展性。

Conclusion: 该需求侧管理系统兼顾了系统效率与用户舒适，是面向未来智能电网的实用且可扩展的解决方案。

Abstract: The growing electricity demand and increased use of smart appliances are
placing new pressures on power grids, making efficient energy management more
important than ever. The existing energy management systems often prioritize
system efficiency (balanced energy demand and supply) at the expense of user
comfort. This paper addresses this gap by proposing a novel decentralized
multi-agent coordination-based demand-side management system. The proposed
system enables individual agents to coordinate for demand-side energy
optimization while improving the user comfort and maintaining the system
efficiency. A key innovation of this work is the introduction of a slot
exchange mechanism, where agents first receive optimized appliance-level energy
consumption schedules and then coordinate with each other to adjust these
schedules through slot exchanges. This approach improves user comfort even when
agents show non-altruistic behaviour, and it scales well with large
populations. The system also promotes fairness by balancing satisfaction levels
across users. For performance evaluation, a real-world dataset is used, and the
results demonstrate that the proposed slot exchange mechanism increases user
comfort and fairness without raising system inefficiency cost, making it a
practical and scalable solution for future smart grids.

</details>


### [113] [Small Fleet, Big Impact: Enhancing Shared Micromobility Efficiency through Minimal Autonomous Vehicle Deployment](https://arxiv.org/abs/2510.04271)
*Heng Tan,Hua Yan,Lucas Yang,Yu Yang*

Main category: cs.MA

TL;DR: 本文提出了SMART框架，通过引入具备自我平衡能力的自动共享微型交通工具，以动态适应实时需求，优化车辆调度，显著提升共享微交通系统的性能。


<details>
  <summary>Details</summary>
Motivation: 共享微型交通系统因时空需求波动导致车辆供需不匹配，现有调度方法频次较低，难以应对异常情况，性能易下降。

Method: 设计了分层强化学习框架SMART，实现自动共享微型交通工具的高层初始部署与低层实时调度的联合优化，并基于芝加哥电动滑板车真实数据进行评估。

Result: 实验结果表明，SMART框架不仅有效提升了系统性能，还具备良好的泛化能力，能与现有调度方法无缝结合。

Conclusion: 引入具备自我平衡能力的自动共享微型交通工具，并采用分层强化学习实现动态调度，能显著改善共享微交通系统的整体服务表现。

Abstract: Shared micromobility systems, such as electric scooters and bikes, have
gained widespread popularity as sustainable alternatives to traditional
transportation modes. However, these systems face persistent challenges due to
spatio-temporal demand fluctuations, often resulting in a mismatch between
vehicle supply and user demand. Existing shared micromobility vehicle
scheduling methods typically redistribute vehicles once or twice per day, which
makes them vulnerable to performance degradation under atypical conditions. In
this work, we design to augment existing micromobility scheduling methods by
integrating a small number of autonomous shared micromobility vehicles (ASMVs),
which possess self-rebalancing capabilities to dynamically adapt to real-time
demand. Specifically, we introduce SMART, a hierarchical reinforcement learning
framework that jointly optimizes high-level initial deployment and low-level
real-time rebalancing for ASMVs. We evaluate our framework based on real-world
e-scooter usage data from Chicago. Our experiment results show that our
framework is highly effective and possesses strong generalization capability,
allowing it to seamlessly integrate with existing vehicle scheduling methods
and significantly enhance overall micromobility service performance.

</details>


### [114] [Audit the Whisper: Detecting Steganographic Collusion in Multi-Agent LLMs](https://arxiv.org/abs/2510.04303)
*Om Tailor*

Main category: cs.MA

TL;DR: 本文提出了"Audit the Whisper"，一个结合理论分析、基准设计和检测方法的多智能体大型语言模型秘密协作审计框架，实现了高准确率和零误报率的审计结果。


<details>
  <summary>Details</summary>
Motivation: 多智能体部署的大型语言模型中存在隐蔽协作行为，这类行为会破坏信任和社会福利，现有审计方法缺乏理论保证且难以复制。因此需要一种理论严谨且可复现的审计框架。

Method: 提出基于通道容量分析的干预措施量化方法，设计了涵盖定价、拍卖和同行评审的多场景基准测试库\textsc{ColludeBench}-v0，构建综合多种检测指标（互信息、置换不变性、水印方差、公平接受偏差）的审计流水线，并设定严格的误报预算。

Result: 在600次审计测试中，联合测试实现了100%真正率且零误报，消融实验揭示了审计代价与公平性检测的权衡，发现了仅依互信息无法检测的协作者行为。

Conclusion: "Audit the Whisper"框架在理论严谨性、任务迁移能力和可复现性方面显著提升，有效保障多智能体语言模型系统的透明性与公正性，且提供完整代码和文档支持外部扩展。

Abstract: Multi-agent deployments of large language models (LLMs) are increasingly
embedded in market, allocation, and governance workflows, yet covert
coordination among agents can silently erode trust and social welfare. Existing
audits are dominated by heuristics that lack theoretical guarantees, struggle
to transfer across tasks, and seldom ship with the infrastructure needed for
independent replication. We introduce \emph{Audit the Whisper}, a
conference-grade research artifact that spans theory, benchmark design,
detection, and reproducibility. Our contributions are: (i) a channel-capacity
analysis showing how interventions such as paraphrase, rate limiting, and role
permutation impose quantifiable capacity penalties -- operationalized via
paired-run Kullback--Leibler diagnostics -- that tighten mutual-information
thresholds with finite-sample guarantees; (ii) \textsc{ColludeBench}-v0,
covering pricing, first-price auctions, and peer review with configurable
covert schemes, deterministic manifests, and reward instrumentation; and (iii)
a calibrated auditing pipeline that fuses cross-run mutual information,
permutation invariance, watermark variance, and fairness-aware acceptance bias,
each tuned to a \(10^{-3}\) false-positive budget. Across 600 audited runs
spanning 12 intervention conditions, the union meta-test attains TPR~$=1$ with
zero observed false alarms, while ablations surface the price-of-auditing
trade-off and highlight fairness-driven colluders invisible to MI alone. We
release regeneration scripts, seed-stamped manifests, and documentation so that
external auditors can reproduce every figure and extend the framework with
minimal effort.

</details>


### [115] [NegotiationGym: Self-Optimizing Agents in a Multi-Agent Social Simulation Environment](https://arxiv.org/abs/2510.04368)
*Shashank Mangla,Chris Hokamp,Jack Boylan,Demian Gholipour Ghalandari,Yuuv Jauhari,Lauren Cassidy,Oisin Duffy*

Main category: cs.MA

TL;DR: NegotiationGym是一个多智能体社交模拟平台，专注于谈判与合作，提供配置驱动API和用户界面，支持智能体策略自我优化。


<details>
  <summary>Details</summary>
Motivation: 设计一个便于配置和运行多智能体社交模拟的平台，聚焦于谈判和合作的场景。

Method: 构建NegotiationGym平台，提供用户友好的配置API，智能体通过多轮交互观察结果并调整策略，实现自我优化。

Result: 成功实现了一个可配置、易用的谈判合作多智能体模拟环境，支持智能体基于效用函数的策略优化。

Conclusion: NegotiationGym为多智能体谈判与合作研究提供了灵活且高效的工具，促进智能体自我学习和策略改进。

Abstract: We design and implement NegotiationGym, an API and user interface for
configuring and running multi-agent social simulations focused upon negotiation
and cooperation. The NegotiationGym codebase offers a user-friendly,
configuration-driven API that enables easy design and customization of
simulation scenarios. Agent-level utility functions encode optimization
criteria for each agent, and agents can self-optimize by conducting multiple
interaction rounds with other agents, observing outcomes, and modifying their
strategies for future rounds.

</details>


### [116] [Trade in Minutes! Rationality-Driven Agentic System for Quantitative Financial Trading](https://arxiv.org/abs/2510.04787)
*Zifan Song,Kaitao Song,Guosheng Hu,Ding Qi,Junyao Gao,Xiaohua Wang,Dongsheng Li,Cairong Zhao*

Main category: cs.MA

TL;DR: 本文提出了TiMi，一个结合战略深度与机械理性的多智能体交易系统，实现了策略开发与分钟级部署的解耦。


<details>
  <summary>Details</summary>
Motivation: 当前金融交易智能体主要模拟人类角色，容易引入情感偏差且依赖外围信息，且部署时需持续推理，限制了性能发挥。

Method: TiMi利用大型语言模型的语义分析、代码编程与数学推理能力，采用宏观到微观的双层分析范式，分层编程设计，实现策略优化与部署的闭环流程。

Result: 在股票和加密货币市场的200多个交易对中，TiMi展现了稳定的盈利能力、高效的行动效率及在市场波动下的风险控制能力。

Conclusion: TiMi有效融合了战略深度与机械理性，为自主金融交易提供了一条新路径，提升了多智能体系统在复杂市场中的表现。

Abstract: Recent advancements in large language models (LLMs) and agentic systems have
shown exceptional decision-making capabilities, revealing significant potential
for autonomic finance. Current financial trading agents predominantly simulate
anthropomorphic roles that inadvertently introduce emotional biases and rely on
peripheral information, while being constrained by the necessity for continuous
inference during deployment. In this paper, we pioneer the harmonization of
strategic depth in agents with the mechanical rationality essential for
quantitative trading. Consequently, we present TiMi (Trade in Minutes), a
rationality-driven multi-agent system that architecturally decouples strategy
development from minute-level deployment. TiMi leverages specialized LLM
capabilities of semantic analysis, code programming, and mathematical reasoning
within a comprehensive policy-optimization-deployment chain. Specifically, we
propose a two-tier analytical paradigm from macro patterns to micro
customization, layered programming design for trading bot implementation, and
closed-loop optimization driven by mathematical reflection. Extensive
evaluations across 200+ trading pairs in stock and cryptocurrency markets
empirically validate the efficacy of TiMi in stable profitability, action
efficiency, and risk control under volatile market dynamics.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [117] [Repairing Leaks in Resource Wrappers](https://arxiv.org/abs/2510.03461)
*Sanjay Malakar,Michael D. Ernst,Martin Kellogg,Manu Sridharan*

Main category: cs.SE

TL;DR: 本文提出改进资源泄漏自动修复的方法，提升了修复效率。


<details>
  <summary>Details</summary>
Motivation: 现有工具只能修复有限类型的资源泄漏，且对使用资源包装器的情况支持不足。

Method: 集成资源管理规范推断，转换程序便于分析，提出字段包含分析和新的修复模式。

Result: Arodnap工具在NJR基准测试中修复率由41%提升至68%。

Conclusion: 该方法显著提升了资源泄漏自动修复的覆盖范围和准确性。

Abstract: A resource leak occurs when a program fails to release a finite resource like
a socket, file descriptor or database connection. While sound static analysis
tools can detect all leaks, automatically repairing them remains challenging.
Prior work took the output of a detection tool and attempted to repair only
leaks from a hard-coded list of library resource types. That approach limits
the scope of repairable leaks: real-world code uses resource wrappers that
store a resource in a field and must themselves be closed. This paper makes
four key contributions to improve resource leak repair in the presence of
wrappers. (1) It integrates inference of resource management specifications
into the repair pipeline, enabling extant fixing approaches to reason about
wrappers. (2) It transforms programs into variants that are easier to analyze,
making inference, detection, and fixing tools more effective; for instance, it
makes detection tools report problems closer to the root cause, often in a
client of a resource wrapper rather than within the wrapper class itself. (3) A
novel field containment analysis reasons about resource lifetimes, enabling
repair of more leaks involving resources stored in fields. (4) It introduces a
new repair pattern and more precise reasoning to better handle resources stored
in non-final fields. Prior work fixed 41% of resource leak warnings in the NJR
benchmark suite; our implementation Arodnap fixes 68%.

</details>


### [118] [ALMAS: an Autonomous LLM-based Multi-Agent Software Engineering Framework](https://arxiv.org/abs/2510.03463)
*Vali Tawosi,Keshav Ramani,Salwa Alamir,Xiaomo Liu*

Main category: cs.SE

TL;DR: 本文提出了一个基于多代理大型语言模型的自动化软件工程框架ALMAS，旨在覆盖软件开发生命周期的多个阶段，实现端到端的软件开发自动化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在软件开发中多集中于代码实现、测试和维护，但软件开发涉及多个复杂阶段，需一个全面的系统来支持整个软件开发生命周期。

Method: ALMAS框架基于多代理LLM，角色分配对应敏捷开发团队角色，支持模块化使用，可无缝集成人类开发者及其环境，实现自动化完成多项软件开发任务。

Result: 通过先前发表的工作和用例展示了ALMAS的进展，证明该框架能自动生成应用程序并添加新功能，体现出其在真实开发场景中的应用能力。

Conclusion: ALMAS为软件开发提供了一个智能化、多代理合作的自动化解决方案，能够有效支持敏捷团队的端到端开发流程，推动软件开发自动化向更高水平发展。

Abstract: Multi-agent Large Language Model (LLM) systems have been leading the way in
applied LLM research across a number of fields. One notable area is software
development, where researchers have advanced the automation of code
implementation, code testing, code maintenance, inter alia, using LLM agents.
However, software development is a multifaceted environment that extends beyond
just code. As such, a successful LLM system must factor in multiple stages of
the software development life-cycle (SDLC). In this paper, we propose a vision
for ALMAS, an Autonomous LLM-based Multi-Agent Software Engineering framework,
which follows the above SDLC philosophy such that it may work within an agile
software development team to perform several tasks end-to-end. ALMAS aligns its
agents with agile roles, and can be used in a modular fashion to seamlessly
integrate with human developers and their development environment. We showcase
the progress towards ALMAS through our published works and a use case
demonstrating the framework, where ALMAS is able to seamlessly generate an
application and add a new feature.

</details>


### [119] [Relative Code Comprehensibility Prediction](https://arxiv.org/abs/2510.03474)
*Nadeeshan De Silva,Martin Kellogg,Oscar Chaparro*

Main category: cs.SE

TL;DR: 本文提出通过训练模型预测相对代码可理解性来提高预测准确性，从而帮助软件工程中的代码重构决策。


<details>
  <summary>Details</summary>
Motivation: 现有的代码可理解性度量与人类实际理解能力相关性较低，机器学习模型直接预测绝对可理解性准确率有限，数据噪声影响模型性能。

Method: 提出训练模型预测两段代码的相对可理解性（即哪段代码更易理解），避免预测绝对可理解性造成的数据噪声。基于已有数据集对比了绝对和相对可理解性预测模型的性能。

Result: 绝对可理解性模型相较基线提升有限且时常效果较差；相对可理解性模型在片段级和开发者级的预测能力分别提升了137.8%和74.7%，表现显著更优。

Conclusion: 训练相对可理解性预测模型能够更有效地学习数据，提高预测准确性，具有在软件工程任务中应用的潜力。

Abstract: Automatically predicting how difficult it is for humans to understand a code
snippet can assist developers in tasks like deciding when and where to
refactor. Despite many proposed code comprehensibility metrics, studies have
shown they often correlate poorly with actual measurements of human
comprehensibility. This has motivated the use of machine learning models to
predict human comprehensibility directly from code, but these models have also
shown limited accuracy.
  We argue that model inaccuracy stems from inherent noise in human
comprehensibility data, which confuses models trained to predict it directly.
To address this, we propose training models to predict the relative
comprehensibility of two code snippets - that is, predicting which snippet a
human would find easier to understand without predicting each snippet's
comprehensibility in isolation. This mitigates noise in predicting 'absolute'
comprehensibility measurements, but is still useful for downstream
software-engineering tasks like assessing whether refactoring improves or
hinders comprehensibility.
  We conducted a study to assess and compare the effectiveness of absolute and
relative code comprehensibility prediction via machine learning. We used a
dataset of 150 Java code snippets and 12.5k human comprehensibility
measurements from prior user studies, comparing the models' performance with
naive baselines (eg 'always predict the majority class'). Our findings indicate
that absolute comprehensibility models improve over the baselines by at most
33.4% and frequently underperform. In contrast, relative comprehensibility
models are substantially better, with average improvements of 137.8% and 74.7%
for snippet-wise and developer-wise prediction, respectively. These results
suggest that relative comprehensibility models learn more effectively from the
data, supporting their practical applicability for downstream SE tasks.

</details>


### [120] [LLM Agents for Automated Dependency Upgrades](https://arxiv.org/abs/2510.03480)
*Vali Tawosi,Salwa Alamir,Xiaomo Liu,Manuela Veloso*

Main category: cs.SE

TL;DR: 本文提出了一种利用大型语言模型（LLM）代理结合迁移文档自动推荐和应用库依赖更新的框架，实现Java代码库中库的自动升级和兼容性保证。


<details>
  <summary>Details</summary>
Motivation: 随着代码库扩展，库依赖过时需更新，但更新可能引入破坏性变化，需花费大量开发时间维护。

Method: 设计包含摘要代理、控制代理和代码代理的系统架构，自动定位并修复代码中的库使用问题，结合迁移文档实现自动升级。

Result: 在工业用例中对比最新方法，框架升级时使用的token更少，精确率达71.4%，展示了方法的高效性和有效性。

Conclusion: 该框架能有效自动化库升级过程，减少维护负担，提高升级效率和准确率，优于现有技术水平。

Abstract: As a codebase expands over time, its library dependencies can become outdated
and require updates to maintain innovation and security. However, updating a
library can introduce breaking changes in the code, necessitating significant
developer time for maintenance. To address this, we introduce a framework of
LLM agents to be used in combination with migration documentation to
automatically recommend and apply code updates and ensure compatibility with
new versions. Our solution can automatically localize updated library usages in
live Java codebases and implement recommended fixes in a user-friendly manner.
The system architecture consists of multiple key components: a Summary Agent,
Control Agent, and Code Agent. To validate our approach, we apply the framework
on an industrial use case by which we create three synthetic code repositories
with major Upgrade changes and benchmark our approach against state-of-the-art
methods. Results show that our approach not only performs upgrades using fewer
tokens across all cases but also achieves a precision of 71.4%, highlighting
its efficiency and effectiveness compared to state-of-the-art methods.

</details>


### [121] [AgentHub: A Research Agenda for Agent Sharing Infrastructure](https://arxiv.org/abs/2510.03495)
*Erik Pautsch,Tanmay Singla,Wenxin Jiang,Huiyun Peng,Behnaz Hassanshahi,Konstantin Läufer,George K. Thiruvathukal,James C. Davis*

Main category: cs.SE

TL;DR: 本文提出AgentHub，旨在构建一个类似软件包注册库的统一大语言模型代理共享生态系统，提高代理的发现、评估和治理能力。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型代理生态基础设施零散，缺乏统一的分发、命名、协议等机制，且忽视软件工程的整体需求，限制了代理的开源分发和复用。

Method: 提出AgentHub研究议程，聚焦能力明确性、生命周期透明度、互操作性、治理、安全和工作流程集成六大关键挑战，规划构建可靠可扩展代理生态的社区路线图。

Result: AgentHub构想了一个使代理分享、信任与组合如同现有软件库一样便捷的未来生态框架。

Conclusion: 通过AgentHub的研究指导，未来全社区可共同建立集发现、治理和复用于一体的统一代理生态系统，推动代理技术发展。

Abstract: LLM-based agents are rapidly proliferating, yet the infrastructure for
discovering, evaluating, and governing them remains fragmented compared to
mature ecosystems like software package registries (e.g., npm) and model hubs
(e.g., Hugging Face). Recent research and engineering works have begun to
consider the requisite infrastructure, but so far they focus narrowly -- on
distribution, naming, or protocol negotiation. However, considering broader
software engineering requirements would improve open-source distribution and
ease reuse. We therefore propose AgentHub, a research agenda for agent sharing.
By framing the key challenges of capability clarity, lifecycle transparency,
interoperability, governance, security, and workflow integration, AgentHub
charts a community-wide agenda for building reliable and scalable agent
ecosystems. Our vision is a future where agents can be shared, trusted, and
composed as seamlessly as today's software libraries.

</details>


### [122] [REFINE: Enhancing Program Repair Agents through Context-Aware Patch Refinement](https://arxiv.org/abs/2510.03588)
*Anvith Pabba,Simin Chen,Alex Mathai,Anindya Chakraborty,Baishakhi Ray*

Main category: cs.SE

TL;DR: 本文提出了一个名为Refine的新型补丁优化框架，通过代码审查和多样化补丁候选改进自动程序修复中草稿补丁的准确率，显著提升修复性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的自动程序修复方法往往只能生成部分正确的草稿补丁，存在代码上下文理解不足和测试用例不完整导致的修复质量问题。

Method: Refine框架通过消除问题及代码上下文歧义、测试时放大全候选多样性、以及利用大语言模型驱动的代码审查过程聚合部分修复，实现对草稿补丁的系统性优化。该模块可结合多种自动修复系统使用。

Result: 在SWE-Bench Lite基准测试中，Refine使AutoCodeRover性能提升14.67%至51.67%，超越所有先前基线，且在SWE-Bench Verified和多系统集成测试中分别提升12.2%及平均14%。

Conclusion: Refine有效弥补了自动程序修复流程中缺少的补丁优化环节，通过智能代理的协作显著缩小了从近正确到完全正确补丁的差距，展示了广泛的适用性及潜力。代码已开源。

Abstract: Large Language Models (LLMs) have recently shown strong potential in
automatic program repair (APR), especially in repository-level settings where
the goal is to generate patches based on natural language issue descriptions,
large codebases, and regression tests. However, despite their promise, current
LLM-based APR techniques often struggle to produce correct fixes due to limited
understanding of code context and over-reliance on incomplete test suites. As a
result, they frequently generate Draft Patches-partially correct patches that
either incompletely address the bug or overfit to the test cases. In this work,
we propose a novel patch refinement framework, Refine, that systematically
transforms Draft Patches into correct ones. Refine addresses three key
challenges: disambiguating vague issue and code context, diversifying patch
candidates through test-time scaling, and aggregating partial fixes via an
LLM-powered code review process. We implement Refine as a general refinement
module that can be integrated into both open-agent-based and workflow-based APR
systems. Our evaluation on the SWE-Bench Lite benchmark shows that Refine
achieves state-of-the-art results among workflow-based approaches and
approaches the best-known performance across all APR categories. Specifically,
Refine boosts AutoCodeRover's performance by 14.67%, achieving a score of
51.67% and surpassing all prior baselines. On SWE-Bench Verified, Refine
improves the resolution rate by 12.2%, and when integrated across multiple APR
systems, it yields an average improvement of 14%-demonstrating its broad
effectiveness and generalizability. These results highlight the effectiveness
of refinement as a missing component in current APR pipelines and the potential
of agentic collaboration in closing the gap between near-correct and correct
patches. We also open source our code.

</details>


### [123] [Generating High-Level Test Cases from Requirements using LLM: An Industry Study](https://arxiv.org/abs/2510.03641)
*Satoshi Masuda,Satoshi Kouzawa,Kyousuke Sezai,Hidetoshi Suhara,Yasuaki Hiruta,Kunihiro Kudou*

Main category: cs.SE

TL;DR: 本文提出一种基于大语言模型（LLM）且无需检索增强生成（RAG）机制的自动生成高层测试用例的方法，通过输入需求文档生成相应的测试设计技术，再针对每种技术生成高层测试用例。实验证明该方法在蓝牙和Mozilla数据集上的宏召回率分别达到0.81和0.37，显示出其在工业中的实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 目前从需求文档自动生成高层测试用例主要依赖人工或使用RAG，但RAG的构建劳动强度大且难以推广到不同应用场景，亟需一种无需RAG且适用于多种需求文档的高层测试用例自动生成方法。

Method: 本文方法首先将需求文档输入LLM，生成对应的测试设计技术，随后基于这些设计技术生成高层测试用例。整体过程仅通过提示词控制，无需构建专门的RAG系统。此外，还验证了基于语义相似度的评价指标用于高层测试用例质量评估。

Result: 在蓝牙和Mozilla两个公开数据集上的实验中，提出的方法实现了宏召回率分别为0.81和0.37的效果，表明该方法在生成高层测试用例方面具备一定的有效性和实用性。

Conclusion: 本文提出的基于LLM且无需RAG的高层测试用例生成方法，可以有效自动从需求文档中生成测试用例，具有推广潜力，有望在软件测试工业中得到实际应用。

Abstract: Currently, generating high-level test cases described in natural language
from requirement documents is performed manually. In the industry, including
companies specializing in software testing, there is a significant demand for
the automatic generation of high-level test cases from requirement documents
using Large Language Models (LLMs). Efforts to utilize LLMs for requirement
analysis are underway. In some cases, retrieval-augmented generation (RAG) is
employed for generating high-level test cases using LLMs. However, in practical
applications, it is necessary to create a RAG tailored to the knowledge system
of each specific application, which is labor-intensive. Moreover, when applying
high-level test case generation as a prompt, there is no established method for
instructing the generation of high-level test cases at a level applicable to
other specifications without using RAG. It is required to establish a method
for the automatic generation of high-level test cases that can be generalized
across a wider range of requirement documents. In this paper, we propose a
method for generating high-level (GHL) test cases from requirement documents
using only prompts, without creating RAGs. In the proposed method, first, the
requirement document is input into the LLM to generate test design techniques
corresponding to the requirement document. Then, high-level test cases are
generated for each of the generated test design techniques. Furthermore, we
verify an evaluation method based on semantic similarity of the generated
high-level test cases. In the experiments, we confirmed the method using
datasets from Bluetooth and Mozilla, where requirement documents and high-level
test cases are available, achieving macro-recall measurement of 0.81 and 0.37,
respectively. We believe that the method is feasible for practical application
in generating high-level test cases without using RAG.

</details>


### [124] [Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems](https://arxiv.org/abs/2510.03712)
*Jahidul Arafat,Kh. M. Moniruzzaman,Shamim Hossain,Fariha Tasmin,Kamrujjaman,Ahsan Habib Tareq*

Main category: cs.SE

TL;DR: 本文提出了一个系统框架，用于检测和预防分布式系统中因优化带来的潜在风险，提升系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统采用激进优化策略，虽提升性能但掩盖了潜在的脆弱性，导致优化失败时可能引发严重故障。现有工程以事后响应为主，缺乏主动风险检测方法。

Method: 设计了潜在风险指数（LRI）评估风险，结合三个系统：HYDRA（优化感知扰动测试），RAVEN（持续监控）和APEX（风险感知优化），实现风险检测、防护及优化。

Result: 实验和实际生产环境中，HYDRA风险发现率89.7%，RAVEN监控准确率和召回率均超90%，APEX维持高性能同时降低59.2%潜在风险。生产部署显著降低恢复时间和事故严重度，带来经济效益。

Conclusion: 该框架使可靠性工程由被动事故管理转为主动风险优化，实现分布式系统优化与风险管理的有机结合，提升系统整体稳定性。

Abstract: Modern distributed systems employ aggressive optimization strategies that
create latent risks - hidden vulnerabilities where exceptional performance
masks catastrophic fragility when optimizations fail. Cache layers achieving
99% hit rates can obscure database bottlenecks until cache failures trigger
100x load amplification and cascading collapse. Current reliability engineering
focuses on reactive incident response rather than proactive detection of
optimization-induced vulnerabilities. This paper presents the first
comprehensive framework for systematic latent risk detection, prevention, and
optimization through integrated mathematical modeling, intelligent perturbation
testing, and risk-aware performance optimization. We introduce the Latent Risk
Index (LRI) that correlates strongly with incident severity (r=0.863, p<0.001),
enabling predictive risk assessment. Our framework integrates three systems:
HYDRA employing six optimization-aware perturbation strategies achieving 89.7%
risk discovery rates, RAVEN providing continuous production monitoring with
92.9% precision and 93.8% recall across 1,748 scenarios, and APEX enabling
risk-aware optimization maintaining 96.6% baseline performance while reducing
latent risks by 59.2%. Evaluation across three testbed environments
demonstrates strong statistical validation with large effect sizes (Cohen
d>2.0) and exceptional reproducibility (r>0.92). Production deployment over 24
weeks shows 69.1% mean time to recovery reduction, 78.6% incident severity
reduction, and 81 prevented incidents generating 1.44M USD average annual
benefits with 3.2-month ROI. Our approach transforms reliability engineering
from reactive incident management to proactive risk-aware optimization.

</details>


### [125] [APIDA-Chat: Structured Synthesis of API Search Dialogues to Bootstrap Conversational Agents](https://arxiv.org/abs/2510.03743)
*Zachary Eberhart,Collin McMillan*

Main category: cs.SE

TL;DR: APIDA-Chat是一种开源管道，利用对话行为脚本生成域名相关的API搜索对话，解决了大语言模型在专有或冷门库上训练数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在解释常用API时表现良好，但因多轮对话训练数据不足，难以应用于冷门或专有库。

Method: 分两阶段，第一阶段用遗留对话规划器和高能力教师模型生成高质量对话数据，训练小型学生模型；第二阶段去除教师，学生模型与规划器结合，低成本快速生成对话。

Result: 微调后的学生模型BLEU分数从0.38提升到0.50，BERTScore从0.88提升至0.91，且可在单卡GPU上运行。

Conclusion: APIDA-Chat为未来相关研究提供了一个模块化、公开的保守基准，既保证数据自主性又提升对冷门API的理解能力。

Abstract: Large-language-model assistants are suitable for explaining popular APIs, yet
they falter on niche or proprietary libraries because the multi-turn dialogue
data needed for fine-tuning are scarce. We present APIDA-Chat, an open-source
pipeline that converts symbolic dialogue-act "scripts" into realistic,
domain-grounded API Search conversations using a lightweight model for
inexpensive training data generation. Phase I pairs a legacy dialogue planner
with a high-capability teacher LLM (o4-mini) to synthesize a "gold set" of
realized dialogues; then, a smaller Llama 3.2 3B student model is fine-tuned on
this corpus. Phase II drops the teacher and reuses the same planner with the
fine-tuned model, allowing rapid, low-cost synthesis of new dialogues without
exposing source code to external services. The fine-tuned student improves BLEU
from 0.38 to 0.50 and BERTScore from 0.88 to 0.91 versus the base model while
running entirely on a single consumer GPU. All components are modular and
publicly released to serve as a conservative baseline for future work.
APIDA-Chat is open-sourced at https://github.com/Zeberhart/apida-chat and a
video demo is available at https://youtu.be/YqmZBHyGbPs .

</details>


### [126] [Code4MeV2: a Research-oriented Code-completion Platform](https://arxiv.org/abs/2510.03755)
*Roham Koohestani,Parham Bateni,Aydin Ebrahimi,Behdad Etezadi,Kiarash Karimi,Maliheh Izadi*

Main category: cs.SE

TL;DR: 本文介绍了Code4MeV2，一款开源的JetBrains IDE代码补全插件，解决了当前AI代码补全工具用户数据封闭、学术研究难以开展的问题。


<details>
  <summary>Details</summary>
Motivation: AI代码补全工具普遍采用，但用户交互数据多被大型企业封闭，限制了学术界对人机交互研究和大规模数据分析的开展。

Method: Code4MeV2采用客户端-服务器架构，支持内联代码补全和上下文感知聊天助手，设计了模块化且透明的数据收集框架，允许研究者精细控制遥测和上下文数据收集。

Result: Code4MeV2的代码补全性能达到业界水平，平均延迟约200毫秒，通过专家评估和8名用户的用户研究验证了其实用性和信息丰富性。

Conclusion: Code4MeV2是一款适合科研使用的工具，促进了学术界对人机交互的研究，作者鼓励社区采纳并贡献该工具。

Abstract: The adoption of AI-powered code completion tools in software development has
increased substantially, yet the user interaction data produced by these
systems remain proprietary within large corporations. This creates a barrier
for the academic community, as researchers must often develop dedicated
platforms to conduct studies on human--AI interaction, making reproducible
research and large-scale data analysis impractical. In this work, we introduce
Code4MeV2, a research-oriented, open-source code completion plugin for
JetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a
client--server architecture and features inline code completion and a
context-aware chat assistant. Its core contribution is a modular and
transparent data collection framework that gives researchers fine-grained
control over telemetry and context gathering. Code4MeV2 achieves
industry-comparable performance in terms of code completion, with an average
latency of 200~ms. We assess our tool through a combination of an expert
evaluation and a user study with eight participants. Feedback from both
researchers and daily users highlights its informativeness and usefulness. We
invite the community to adopt and contribute to this tool. More information
about the tool can be found at https://app.code4me.me.

</details>


### [127] [A First Look at the Lifecycle of DL-Specific Self-Admitted Technical Debt](https://arxiv.org/abs/2510.03802)
*Gilberto Recupito,Vincenzo De Martino,Dario Di Nucci,Fabio Palomba*

Main category: cs.SE

TL;DR: 本文通过分析40个机器学习项目中的185个深度学习特有的自认技术债务(SATD)实例，探讨了其生命周期和持久性，发现技术债务主要在项目早中期引入，训练和硬件阶段债务存在时间最长，强调需要针对深度学习系统的技术债务管理策略。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统推动了软件开发创新，但其特有的自认技术债务严重影响系统的可维护性和质量，且该债务的生命周期研究不足。

Method: 利用软件仓库挖掘技术，分析40个机器学习项目中的185个深度学习特有SATD实例，追踪其在项目提交历史中的引入、持续时间和开发者行为。

Result: 发现深度学习SATD主要在项目早中期引入，训练和硬件阶段债务时间最长，主要在功能实现和缺陷修复阶段引入。

Conclusion: 针对深度学习系统的SATD需制定特定管理策略，通过了解SATD的时间特性和演变，开发者能重点干预关键阶段，提高系统的可维护性和质量。

Abstract: The rapid adoption of Deep Learning (DL)-enabled systems has revolutionized
software development, driving innovation across various domains. However, these
systems also introduce unique challenges, particularly in maintaining software
quality and performance. Among these challenges, Self-Admitted Technical Debt
(SATD) has emerged as a growing concern, significantly impacting the
maintainability and overall quality of ML and DL-enabled systems. Despite its
critical implications, the lifecycle of DL-specific SATD, how developers
introduce, acknowledge, and address it over time-remains underexplored. This
study presents a preliminary analysis of the persistence and lifecycle of
DL-specific SATD in DL-enabled systems. The purpose of this project is to
uncover the patterns of SATD introduction, recognition, and durability during
the development life cycle, providing information on how to manage these
issues. Using mining software repository techniques, we examined 40 ML
projects, focusing on 185 DL-specific SATD instances. The analysis tracked the
introduction and persistence of SATD instances through project commit histories
to assess their lifecycle and developer actions. The findings indicate that
DL-specific SATD is predominantly introduced during the early and middle stages
of project development. Training and Hardware phases showed the longest SATD
durations, highlighting critical areas where debt accumulates and persists.
Additionally, developers introduce DL-specific SATD more frequently during
feature implementation and bug fixes. This study emphasizes the need for
targeted DL-specific SATD management strategies in DL-enabled systems to
mitigate its impact. By understanding the temporal characteristics and
evolution of DL-specific SATD, developers can prioritize interventions at
critical stages to improve the maintainability and quality of the system.

</details>


### [128] [Smart Paste: Automatically Fixing Copy/Paste for Google Developers](https://arxiv.org/abs/2510.03843)
*Vincent Nguyen,Guilherme Herzog,José Cambronero,Marcus Revaj,Aditya Kini,Alexander Frömmgen,Maxim Tabachnyk*

Main category: cs.SE

TL;DR: 本文介绍了谷歌开发的一款名为Smart Paste的智能粘贴编辑建议工具，在粘贴代码后的编辑环节提供帮助，提升开发效率。


<details>
  <summary>Details</summary>
Motivation: 谷歌内部代码粘贴频繁且通常需要后续编辑，手动编辑耗时且繁琐，亟需智能化辅助工具。

Method: 通过深度学习模型预测粘贴后的编辑操作，集成到IDE中，支持多轮迭代开发和规模化部署，同时注重用户体验和系统集成。

Result: Smart Paste上线后获得了45%的建议接受率，相关建议占公司所有代码的1%以上，用户反馈积极。

Conclusion: 基于深度学习的智能粘贴编辑建议工具在实际企业开发环境中有效提升了编码效率，且该经验可为AI功能的研发和集成提供参考。

Abstract: Manually editing pasted code is a long-standing developer pain point. In
internal software development at Google, we observe that code is pasted 4 times
more often than it is manually typed. These paste actions frequently require
follow-up edits, ranging from simple reformatting and renaming to more complex
style adjustments and cross-language translations. Prior work has shown deep
learning can be used to predict these edits. In this work, we show how to
iteratively develop and scale Smart Paste, an IDE feature for post-paste edit
suggestions, to Google's development environment. This experience can serve as
a guide for AI practitioners on a holistic approach to feature development,
covering user experience, system integration, and model capabilities. Since
deployment, Smart Paste has had overwhelmingly positive feedback with a 45%
acceptance rate. At Google's enterprise scale, these accepted suggestions
account substantially for over 1% of all code written company-wide.

</details>


### [129] [Designing Empirical Studies on LLM-Based Code Generation: Towards a Reference Framework](https://arxiv.org/abs/2510.03862)
*Nathalia Nascimento,Everton Guimaraes,Paulo Alencar*

Main category: cs.SE

TL;DR: 本文提出了一个用于大语言模型（LLM）代码生成的实证研究设计和报告的理论框架，旨在解决目前研究中缺乏标准化的问题。


<details>
  <summary>Details</summary>
Motivation: 当前针对LLM代码生成的实证研究缺乏统一的标准，导致各研究在目标、任务和评价指标上差异较大，难以比较和复现。

Method: 基于作者先前的实验经验和对近期相关研究的比较分析，本文构建了一个围绕问题来源、质量属性和评价指标等核心组成部分的理论框架，用以指导系统化的实验设计和报告。

Result: 通过代表性案例映射，证明了该框架的适用性，并指出了其可改进的方向。

Conclusion: 该框架为标准化LLM代码生成的评估提供了理论基础，未来将进一步发展以适应更广泛的软件工程场景。

Abstract: The rise of large language models (LLMs) has introduced transformative
potential in automated code generation, addressing a wide range of software
engineering challenges. However, empirical evaluation of LLM-based code
generation lacks standardization, with studies varying widely in goals, tasks,
and metrics, which limits comparability and reproducibility. In this paper, we
propose a theoretical framework for designing and reporting empirical studies
on LLM-based code generation. The framework is grounded in both our prior
experience conducting such experiments and a comparative analysis of key
similarities and differences among recent studies. It organizes evaluation
around core components such as problem sources, quality attributes, and
metrics, supporting structured and systematic experimentation. We demonstrate
its applicability through representative case mappings and identify
opportunities for refinement. Looking forward, we plan to evolve the framework
into a more robust and mature tool for standardizing LLM evaluation across
software engineering contexts.

</details>


### [130] [Adversarial Agent Collaboration for C to Rust Translation](https://arxiv.org/abs/2510.03879)
*Tianyu Li,Ruishi Li,Bo Wang,Brandon Paulsen,Umang Mathur,Prateek Saxena*

Main category: cs.SE

TL;DR: 本文提出了ACToR，一种基于对抗生成网络思想的LLM代理用于将大型C代码库翻译成安全的Rust代码，实现了高达90%以上的测试通过率和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有C到安全Rust语言的翻译方法在超过500行代码的大型C程序中表现不佳，主要由于依赖复杂且易崩溃的程序分析手段。

Method: ACToR采用生成器代理与鉴别器代理对抗的机制，生成器负责翻译并优化Rust代码以通过测试，鉴别器负责发现新的失败测试，二者迭代协作提升翻译质量。

Result: ACToR成功翻译了63个真实世界命令行工具（平均485行代码），平均测试通过率超过90%，且比非对抗方法提升了最高18.9%的翻译正确率。

Conclusion: ACToR是首个能可靠翻译大规模C程序为Rust语言的系统，展示了对抗式LLM代理架构在代码转换任务中的有效性和潜力。

Abstract: Translating C to memory-safe languages, like Rust, prevents critical memory
safety vulnerabilities that are prevalent in legacy C software. Existing
approaches for C to safe Rust translation, including LLM-assisted ones, do not
generalize on larger (> 500 LoC) C codebases because they depend on complex
program analyses that frequently break. In this work, we present ACToR
(Adversarial C To Rust translator), a simple LLM agent-based approach. Inspired
by GANs, ACToR pits a generator agent against a discriminator agent, which
collaborate to iteratively generate a Rust translation. On each iteration, the
translator agent synthesizes and refines a Rust translation to pass an existing
suite of tests, and then the discriminator agent finds new failing tests. We
demonstrate that ACToR translates all of the 63 real-world command line
utilities considered in our benchmarks, which have an average size of 485 lines
of code, and it achieves over 90% test pass rate with zero human intervention.
To our knowledge, it is the first such system that reliably translates C
programs of this scale. Furthermore, ACToR improves translation correctness by
up to 18.9% compared to baseline, non-adversarial approaches.

</details>


### [131] [Rethinking Services in the Quantum Age: The SOQ Paradigm](https://arxiv.org/abs/2510.03890)
*Jose Garcia-Alonso,Enrique Moguel,Jaime Alvarado-Valiente,Javier Romero-Alvarez,Álvaro M. Aparicio-Morales,Juan M. Murillo,Francisco Javier Cavero,Adrián Romero-Flores,Alfonso E. Marquez-Chamorro,José Antonio Parejo,Antonio Ruiz-Cortés,Giuseppe Bisicchia,Alessandro Bocci,Antonio Brogi*

Main category: cs.SE

TL;DR: 本文提出了面向服务的量子计算（SOQ）新范式，旨在实现量子软件系统的模块化、自治和互操作，促进量子计算与实际软件系统的集成。


<details>
  <summary>Details</summary>
Motivation: 当前量子计算虽在理论和应用方面进展迅速，但其硬件脆弱性、平台多样性以及缺乏成熟的软件工程实践，限制了量子计算在真实软件系统中的广泛应用。

Method: 本文基于传统面向服务计算理念，提出SOQ范式，将量子服务设计为自主、可组合且互操作的实体，定义了基本原则，构建了分层技术栈，并梳理了互操作性、混合性、定价模型、服务抽象及人才培养等关键挑战。

Result: SOQ范式突破传统以经典系统为主、量子能力为辅的局限，实现了量子服务的独立性和模块化，提高了量子计算集成的可扩展性与互操作性。

Conclusion: SOQ为量子计算技术进步提供了关键支撑，促进其在实际软件系统中的独立应用与扩展，推动量子计算向实用阶段迈进。

Abstract: Quantum computing is rapidly progressing from theoretical promise to
practical implementation, offering significant computational advantages for
tasks in optimization, simulation, cryptography, and machine learning. However,
its integration into real-world software systems remains constrained by
hardware fragility, platform heterogeneity, and the absence of robust software
engineering practices. This paper introduces Service-Oriented Quantum (SOQ), a
novel paradigm that reimagines quantum software systems through the lens of
classical service-oriented computing. Unlike prior approaches such as Quantum
Service-Oriented Computing (QSOC), which treat quantum capabilities as
auxiliary components within classical systems, SOQ positions quantum services
as autonomous, composable, and interoperable entities. We define the
foundational principles of SOQ, propose a layered technology stack to support
its realization, and identify the key research and engineering challenges that
must be addressed, including interoperability, hybridity, pricing models,
service abstractions, and workforce development. This approach is of vital
importance for the advancement of quantum technology because it enables the
scalable, modular, and interoperable integration of quantum computing into
real-world software systems independently and without relying on a dedicated
classical environment to manage quantum processing.

</details>


### [132] [A Brief History of the Waterfall Model: Past, Present, and Future](https://arxiv.org/abs/2510.03894)
*Antonios Saravanos*

Main category: cs.SE

TL;DR: 瀑布模型作为最早的软件开发方法论之一，虽受批评但在特定领域仍具影响力，并融入现代混合开发框架。


<details>
  <summary>Details</summary>
Motivation: 回顾瀑布模型的起源、发展及其在当前软件开发实践中的作用，探讨其为何仍保持相关性。

Method: 通过文献综述，分析瀑布模型的历史演变、应用现状及其在混合开发方法中的地位。

Result: 瀑布模型从独立框架转变为现代混合方法中的组成部分，体现了其适应性和持续影响力。

Conclusion: 瀑布模型虽有局限，但因其灵活适用性，仍是情境感知开发策略的重要组成，帮助开发者做出更合理的方法论选择。

Abstract: The waterfall model, one of the earliest software development methodologies,
has played a foundational role in shaping contemporary software engineering
practices. This paper provides a historical and critical overview of the model,
tracing its conceptual origins in software engineering, its formalization by
Royce, and its evolution through decades of industry adoption and critique.
Although often criticized for its rigidity, shortcomings, and high failure
rates, the waterfall model persists in specific domains. Its principles
continue to influence contemporary hybrid development frameworks that combine
traditional and agile methods. Drawing on a range of scholarly sources, this
study synthesizes key developments in the perception and application of the
waterfall model. The analysis highlights how the model has shifted from a
standalone framework to a component within modern hybrid methodologies. By
revisiting its origins, assessing its present utility, and examining its role
in contemporary development practices, this paper argues that the waterfall
model remains relevant, not as a relic of the past but as part of context-aware
development strategies. The paper contends that the model's enduring relevance
lies in its adaptability. By recognizing both its limitations and its
strengths, and by understanding its integration within hybrid approaches,
practitioners can make more informed decisions about methodology selection and
process design in diverse development environments.

</details>


### [133] [Multi-Agent Code-Orchestrated Generation for Reliable Infrastructure-as-Code](https://arxiv.org/abs/2510.03902)
*Rana Nameer Hussain Khan,Dawood Wasif,Jin-Hee Cho,Ali Butt*

Main category: cs.SE

TL;DR: 提出了基于多智能体协同生成的基础设施即代码(IaC)生成架构MACOG，提升IaC代码的正确性和合规性。


<details>
  <summary>Details</summary>
Motivation: 云原生基础设施复杂度提升，使得IaC生成变得关键，但现有大语言模型单次生成易导致语法错误、策略违规和设计不合理。

Method: 设计多智能体系统，分别负责架构设计、提供商协调、工程实现、代码审查、安全验证、成本规划、运维及记忆管理，通过共享黑板和有限状态机协调生成Terraform配置，并结合Terraform Plan与OPA进行执行验证和策略检查。

Result: 在IaC-Eval基准测试中，MACOG显著提升代码质量和合规性，如GPT-5的评分从54.90提升至74.02，Gemini-2.5 Pro从43.56提升至60.13，各项指标均获得改进。

Conclusion: 多智能体协同机制和执行反馈是提高IaC代码生成准确性和合规性的关键，证明MACOG在复杂基础设施代码生成中的有效性。

Abstract: The increasing complexity of cloud-native infrastructure has made
Infrastructure-as-Code (IaC) essential for reproducible and scalable
deployments. While large language models (LLMs) have shown promise in
generating IaC snippets from natural language prompts, their monolithic,
single-pass generation approach often results in syntactic errors, policy
violations, and unscalable designs. In this paper, we propose MACOG
(Multi-Agent Code-Orchestrated Generation), a novel multi-agent LLM-based
architecture for IaC generation that decomposes the task into modular subtasks
handled by specialized agents: Architect, Provider Harmonizer, Engineer,
Reviewer, Security Prover, Cost and Capacity Planner, DevOps, and Memory
Curator. The agents interact via a shared-blackboard, finite-state orchestrator
layer, and collectively produce Terraform configurations that are not only
syntactically valid but also policy-compliant and semantically coherent. To
ensure infrastructure correctness and governance, we incorporate Terraform Plan
for execution validation and Open Policy Agent (OPA) for customizable policy
enforcement. We evaluate MACOG using the IaC-Eval benchmark, where MACOG is the
top enhancement across models, e.g., GPT-5 improves from 54.90 (RAG) to 74.02
and Gemini-2.5 Pro from 43.56 to 60.13, with concurrent gains on BLEU,
CodeBERTScore, and an LLM-judge metric. Ablations show constrained decoding and
deploy feedback are critical: removing them drops IaC-Eval to 64.89 and 56.93,
respectively.

</details>


### [134] [Refactoring with LLMs: Bridging Human Expertise and Machine Understanding](https://arxiv.org/abs/2510.03914)
*Yonnel Chen Kuang Piao,Jean Carlors Paul,Leuson Da Silva,Arghavan Moradi Dakhel,Mohammad Hamdaqa,Foutse Khomh*

Main category: cs.SE

TL;DR: 本研究利用基于Martin Fowler重构指南设计的指令策略，提升大型语言模型自动执行多样化代码重构任务的能力，实验验证其在保留程序语义、执行多种重构类型上的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管代码重构对提升代码质量和可维护性至关重要，但开发者常因耗时和无直接功能回报而忽视重构，现有自动化工具支持有限，促使研究探索如何借助大型语言模型提升多样化重构能力。

Method: 基于Martin Fowler重构指南，设计包含动机、步骤和目标的多种指令策略，利用GPT-mini和DeepSeek-V3等大型语言模型的指令遵循及代码理解能力，对61种重构类型进行自动化重构实验，覆盖基准案例与GitHub实代码片段。

Result: 基于Fowler指南的指令策略使大型语言模型成功执行所有基准重构类型，并在实际代码中保持程序语义；规则型指令在特定场景表现优于描述性指令；允许模型专注重构总体目标而非固定转换类型，可进一步提升代码质量。

Conclusion: 结合权威重构指南设计的指令策略显著增强了大型语言模型的代码重构能力，实现多样化且保持语义正确的自动化重构，为自动化重构工具发展提供了新思路。

Abstract: Code refactoring is a fundamental software engineering practice aimed at
improving code quality and maintainability. Despite its importance, developers
often neglect refactoring due to the significant time, effort, and resources it
requires, as well as the lack of immediate functional rewards. Although several
automated refactoring tools have been proposed, they remain limited in
supporting a broad spectrum of refactoring types. In this study, we explore
whether instruction strategies inspired by human best-practice guidelines can
enhance the ability of Large Language Models (LLMs) to perform diverse
refactoring tasks automatically. Leveraging the instruction-following and code
comprehension capabilities of state-of-the-art LLMs (e.g., GPT-mini and
DeepSeek-V3), we draw on Martin Fowler's refactoring guidelines to design
multiple instruction strategies that encode motivations, procedural steps, and
transformation objectives for 61 well-known refactoring types. We evaluate
these strategies on benchmark examples and real-world code snippets from GitHub
projects. Our results show that instruction designs grounded in Fowler's
guidelines enable LLMs to successfully perform all benchmark refactoring types
and preserve program semantics in real-world settings, an essential criterion
for effective refactoring. Moreover, while descriptive instructions are more
interpretable to humans, our results show that rule-based instructions often
lead to better performance in specific scenarios. Interestingly, allowing
models to focus on the overall goal of refactoring, rather than prescribing a
fixed transformation type, can yield even greater improvements in code quality.

</details>


### [135] [Why Does the Engineering Manager Still Exist in Agile Software Development?](https://arxiv.org/abs/2510.03920)
*Ravi Kalluri*

Main category: cs.SE

TL;DR: 虽然敏捷方法强调去中心化决策和团队自治，但工程经理在敏捷软件组织中仍然存在。本文探讨了这一现象，提出了一个整合敏捷原则与管理需求的概念模型。


<details>
  <summary>Details</summary>
Motivation: 敏捷方法理论上推翻了传统管理层级，强调团队自治，但现实中工程经理仍被雇佣，存在矛盾。

Method: 通过系统文献综述和案例研究，采用多维框架分析历史背景、理论张力、组织现实、实证证据和管理角色演变。

Result: 发现传统管理职能虽然受到挑战，但工程经理角色仍然存在并演变，提出了调和敏捷原则与管理需求的概念模型。

Conclusion: 提出概念模型为敏捷环境中的管理提供指导，讨论了领导力发展、工具整合及未来研究方向。

Abstract: Although Agile methodologies emphasize decentralized decision-making and team
autonomy, engineering managers continue to be employed in Agile software
organizations. This apparent paradox suggests that traditional managerial
functions persist despite the theoretical displacement of managerial hierarchy
in Agile. This paper explores the persistence of engineering managers through a
multidimensional framework encompassing historical context, theoretical
tensions, organizational realities, empirical evidence, evolving managerial
roles, and practical implications. A systematic literature review underpins our
multifaceted analysis, supplemented by illustrative case studies. We conclude
by proposing a conceptual model that reconciles Agile principles with
managerial necessity, offering guidance for practitioners, researchers, and
tool designers. Implications for leadership development, tool integration, and
future research are discussed.

</details>


### [136] [Bamboo: LLM-Driven Discovery of API-Permission Mappings in the Android Framework](https://arxiv.org/abs/2510.04078)
*Han Hu,Wei Minn,Yonghui Liu,Jiakun Liu,Ferdian Thung,Terry Yue Zhuo,Lwin Khin Shar,Debin Gao,David Lo*

Main category: cs.SE

TL;DR: 本文提出了一种基于大型语言模型的安卓API权限映射发现方法，并开发了工具\tool{}，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前安卓官方API权限文档不准确且不完整，导致开发者难以正确声明权限，影响安全和应用稳定性。现有静态和动态分析方法存在适应性差、代码覆盖有限等缺陷。

Method: 利用大型语言模型进行系统性API权限映射分析，结合双角色提示策略和基于API的代码生成，构建权限映射发现流程。

Result: 工具\tool{}在安卓6、7和10版本分别识别了2234、3552和4576个API-权限映射，显著优于最新基线方法。

Conclusion: 基于大型语言模型的方法有效提升了安卓API权限映射的完整性和准确性，为安卓安全权限管理提供了强有力的支持。

Abstract: The permission mechanism in the Android Framework is integral to safeguarding
the privacy of users by managing users' and processes' access to sensitive
resources and operations. As such, developers need to be equipped with an
in-depth understanding of API permissions to build robust Android apps.
Unfortunately, the official API documentation by Android chronically suffers
from imprecision and incompleteness, causing developers to spend significant
effort to accurately discern necessary permissions. This potentially leads to
incorrect permission declarations in Android app development, potentially
resulting in security violations and app failures. Recent efforts in improving
permission specification primarily leverage static and dynamic code analyses to
uncover API-permission mappings within the Android framework. Yet, these
methodologies encounter substantial shortcomings, including poor adaptability
to Android SDK and Framework updates, restricted code coverage, and a
propensity to overlook essential API-permission mappings in intricate
codebases. This paper introduces a pioneering approach utilizing large language
models (LLMs) for a systematic examination of API-permission mappings. In
addition to employing LLMs, we integrate a dual-role prompting strategy and an
API-driven code generation approach into our mapping discovery pipeline,
resulting in the development of the corresponding tool, \tool{}. We formulate
three research questions to evaluate the efficacy of \tool{} against
state-of-the-art baselines, assess the completeness of official SDK
documentation, and analyze the evolution of permission-required APIs across
different SDK releases. Our experimental results reveal that \tool{} identifies
2,234, 3,552, and 4,576 API-permission mappings in Android versions 6, 7, and
10 respectively, substantially outprforming existing baselines.

</details>


### [137] [GA4GC: Greener Agent for Greener Code via Multi-Objective Configuration Optimization](https://arxiv.org/abs/2510.04135)
*Jingzhi Gong,Yixin Bian,Luis de la Cal,Giovanni Pinna,Anisha Uteem,David Williams,Mar Zamorano,Karine Even-Mendoza,W. B. Langdon,Hector Menendez,Federica Sarro*

Main category: cs.SE

TL;DR: 该论文提出了GA4GC框架，有效优化了基于大型语言模型的编码代理的运行时间和代码性能，实现了显著节能与性能提升。


<details>
  <summary>Details</summary>
Motivation: 工业部署中，基于大型语言模型的编码代理面临高运行成本和环境负担，亟需优化其可持续性和扩展性。

Method: GA4GC框架通过发现Pareto最优的代理超参数和提示模板，系统性地权衡代理运行时长和代码性能。

Result: 在SWE-Perf基准测试中，实现了最高135倍的超体积改进，运行时间缩短37.7%，且代码正确率提升。确定温度参数为关键超参数。

Conclusion: GA4GC框架为工业中部署的编码代理提供了可操作的优化策略，有效平衡了代理性能和环保需求，推动编码代理的可持续发展。

Abstract: Coding agents powered by LLMs face critical sustainability and scalability
challenges in industrial deployment, with single runs consuming over 100k
tokens and incurring environmental costs that may exceed optimization benefits.
This paper introduces GA4GC, the first framework to systematically optimize
coding agent runtime (greener agent) and code performance (greener code)
trade-offs by discovering Pareto-optimal agent hyperparameters and prompt
templates. Evaluation on the SWE-Perf benchmark demonstrates up to 135x
hypervolume improvement, reducing agent runtime by 37.7% while improving
correctness. Our findings establish temperature as the most critical
hyperparameter, and provide actionable strategies to balance agent
sustainability with code optimization effectiveness in industrial deployment.

</details>


### [138] [Detecting Semantic Clones of Unseen Functionality](https://arxiv.org/abs/2510.04143)
*Konstantinos Kitsios,Francesco Sovrano,Earl T. Barr,Alberto Bacchelli*

Main category: cs.SE

TL;DR: 本文分析了现有模型在语义代码克隆检测中对未见过功能的克隆检测能力，发现效果显著下滑，并提出采用对比学习方法提升模型泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有神经模型虽在已见功能克隆检测表现优异，但对未见功能的克隆检测能力不足，而实际应用中需检测多功能克隆。

Method: 重新评估六个先进模型在未见功能克隆检测上的表现，提出基于对比学习的改进方案，包括替换分类器和对生成式大模型进行对比式上下文学习。

Result: 任务专用模型在未见功能克隆检测中F1平均下降31%，生成式大模型下降3%；引入对比学习后，任务模型F1提升9%，生成式大模型提升3%。

Conclusion: 对比学习显著提升了模型对未见功能克隆的检测能力，特别是任务专用模型泛化效果增强，具备实用推广价值。

Abstract: Semantic code clone detection is the task of detecting whether two snippets
of code implement the same functionality (e.g., Sort Array). Recently, many
neural models achieved near-perfect performance on this task. These models seek
to make inferences based on their training data. Consequently, they better
detect clones similar to those they have seen during training and may struggle
to detect those they have not. Developers seeking clones are, of course,
interested in both types of clones. We confirm this claim through a literature
review, identifying three practical clone detection tasks in which the model's
goal is to detect clones of a functionality even if it was trained on clones of
different functionalities. In light of this finding, we re-evaluate six
state-of-the-art models, including both task-specific models and generative
LLMs, on the task of detecting clones of unseen functionality. Our experiments
reveal a drop in F1 of up to 48% (average 31%) for task-specific models. LLMs
perform on par with task-specific models without explicit training for clone
detection, but generalize better to unseen functionalities, where F1 drops up
to 5% (average 3%) instead. We propose and evaluate the use of contrastive
learning to improve the performance of existing models on clones of unseen
functionality. We draw inspiration from the computer vision and natural
language processing fields where contrastive learning excels at measuring
similarity between two objects, even if they come from classes unseen during
training. We replace the final classifier of the task-specific models with a
contrastive classifier, while for the generative LLMs we propose contrastive
in-context learning, guiding the LLMs to focus on the differences between
clones and non-clones. The F1 on clones of unseen functionality is improved by
up to 26% (average 9%) for task-specific models and up to 5% (average 3%) for
LLMs.

</details>


### [139] [Multi Language Models for On-the-Fly Syntax Highlighting](https://arxiv.org/abs/2510.04166)
*Marco Edoardo Palma,Pooja Rani,Harald C. Gall*

Main category: cs.SE

TL;DR: 本文提出了一种能够支持六种主流编程语言的统一语法高亮模型，解决了多语言环境下模型维护复杂和成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有语法高亮模型通常只支持单一编程语言，且依赖庞大的数据集和资源密集型训练，导致多语言支持时系统复杂度和运维成本大幅增加。

Method: 通过引入一种新颖的归一化技术来增强模型泛化能力，并利用少量的oracle样本进行少量学习，减少对传统暴力生成器大数据的依赖，实现多语言统一模型。

Result: 该模型成功支持六种主流语言的高亮，部署复杂度降低六倍，且在未见语言上表现有所提升。少量学习证明可用小样本替代大规模训练数据。

Conclusion: 本工作实现了一个高效、可扩展且成本效益高的多语言语法高亮系统，显著简化了多语言支持的系统复杂性和资源需求。

Abstract: Syntax highlighting is a critical feature in modern software development
environments, enhancing code readability and developer productivity. However,
delivering accurate highlighting in real time remains challenging for online
and web-based development tools due to strict time and memory constraints on
backend services. These systems must serve highlights rapidly and frequently,
even when code is partially valid or invalid. This has led to on-the-fly syntax
highlighting, where visual annotations are generated just before content is
served, often at high request rates and under incomplete input conditions. To
meet these demands efficiently, state-of-the-art models use deep learning to
learn the behavior of brute-force syntax highlighting resolvers, tools that are
easy to implement but too slow for production. Through the Deep Abstraction
process, brute-force strategies are encoded into fast statistical models that
achieve both high accuracy and low-latency inference. Despite their success,
such models face key challenges: they support only one programming language per
model, require large datasets from slow brute-force generators, and involve
resource-intensive training. In multi-language environments, this means
maintaining multiple independent models, increasing system complexity and
operational cost. This work addresses these issues by introducing a unified
model capable of highlighting up to six mainstream programming languages,
reducing deployment complexity by a factor of six and improving performance on
unseen languages. A novel normalization technique significantly enhances model
generalization, while few-shot learning experiments show that a small number of
oracle samples can replace large datasets, minimizing dependence on brute-force
generators. Combined, these innovations enable efficient, scalable, and
cost-effective syntax highlighting across diverse programming languages.

</details>


### [140] [Selecting Cybersecurity Requirements: Effects of LLM Use and Professional Software Development Experience](https://arxiv.org/abs/2510.04274)
*Damjan Fujs,Damjan Vavpotič,Tomaž Hovelja,Marko Poženel*

Main category: cs.SE

TL;DR: 研究探讨大型语言模型（LLMs）可用性和专业经验对网络应用安全需求优先级的影响，发现LLM使用无显著作用，但专业经验影响显著。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs辅助以及开发者经验如何影响网络安全需求的优先级设定和评估。

Method: 23名研究生用MoSCoW方法对安全需求进行排序，分为使用和不使用LLM两组评价方案。

Result: LLM使用未显著影响安全方案评价，经验丰富的参与者在成本、用户体验影响和风险评估上有显著不同表现。

Conclusion: 专业软件开发经验比LLM辅助对网络安全需求优先级设置影响更大，强调经验在安全评估中的重要性。

Abstract: This study investigates how access to Large Language Models (LLMs) and
varying levels of professional software development experience affect the
prioritization of cybersecurity requirements for web applications. Twenty-three
postgraduate students participated in a research study to prioritize security
requirements (SRs) using the MoSCoW method and subsequently rated their
proposed solutions against multiple evaluation criteria. We divided
participants into two groups (one with and the other without access to LLM
support during the task). Results showed no significant differences related to
LLM use, suggesting that access to LLMs did not noticeably influence how
participants evaluated cybersecurity solutions. However, statistically
significant differences emerged between experience groups for certain criteria,
such as estimated cost to develop a feature, perceived impact on user
experience, and risk assessment related to non-implementation of the proposed
feature. Participants with more professional experience tended to provide
higher ratings for user experience impact and lower risk estimates.

</details>


### [141] [Challenge on Optimization of Context Collection for Code Completion](https://arxiv.org/abs/2510.04349)
*Dmitry Ustalov,Egor Bogomolov,Alexander Bezzubov,Yaroslav Golubev,Evgeniy Glukhov,Georgii Levtsov,Vladimir Kovalenko*

Main category: cs.SE

TL;DR: 该论文介绍了一个关于代码补全上下文收集优化的挑战赛，旨在提高Python和Kotlin代码补全的质量。


<details>
  <summary>Details</summary>
Motivation: 随着AI在软件工程中应用的快速发展，需要系统评估其在大规模代码库中利用整个项目信息的能力。

Method: 比赛组织者构建了包含Python和Kotlin真实代码的大型数据集，参赛团队开发高效的上下文收集机制，通过chrF指标评估多种神经模型的补全性能。

Result: 比赛吸引了众多团队参与，公开阶段19支团队提交Python方案，8支团队提交Kotlin方案，私有阶段6支团队竞争，5支提交论文。

Conclusion: 该挑战促进了代码补全上下文收集技术的进步，为提升大规模代码库中代码补全的准确性提供了有效方法。

Abstract: The rapid advancement of workflows and methods for software engineering using
AI emphasizes the need for a systematic evaluation and analysis of their
ability to leverage information from entire projects, particularly in large
code bases. In this challenge on optimization of context collection for code
completion, organized by JetBrains in collaboration with Mistral AI as part of
the ASE 2025 conference, participants developed efficient mechanisms for
collecting context from source code repositories to improve fill-in-the-middle
code completions for Python and Kotlin. We constructed a large dataset of
real-world code in these two programming languages using permissively licensed
open-source projects. The submissions were evaluated based on their ability to
maximize completion quality for multiple state-of-the-art neural models using
the chrF metric. During the public phase of the competition, nineteen teams
submitted solutions to the Python track and eight teams submitted solutions to
the Kotlin track. In the private phase, six teams competed, of which five
submitted papers to the workshop.

</details>


### [142] [MacroBench: A Novel Testbed for Web Automation Scripts via Large Language Models](https://arxiv.org/abs/2510.04363)
*Hyunjun Kim,Sejong Kim*

Main category: cs.SE

TL;DR: 本文提出了MacroBench基准，用于评估大型语言模型（LLMs）通过阅读HTML/DOM并生成Selenium Python代码，实现浏览器自动化程序合成能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以评估LLMs在复杂网页自动化任务中生成可复用代码的能力，亟需统一、全面的评测标准。

Method: 搭建七个自托管网站，涵盖681个任务，设计端到端验证协议，包括静态检查、沙箱执行及结果验证。同时设有安全检测模块。

Result: 经过2636次模型-任务测试，GPT-4o-Mini等模型在简单任务中成功率超过91%，复杂流程任务成功率为0%，且生成代码未达到生产质量。

Conclusion: MacroBench提供了一个统一、严格的网页自动化代码生成评测框架，揭示了当前模型在复杂任务和代码质量方面的局限，促进领域发展与模型改进。

Abstract: We introduce MacroBench, a code-first benchmark that evaluates whether LLMs
can synthesize reusable browser automation programs from natural language goals
by reading HTML/DOM and emitting Python with Selenium. MacroBench instantiates
seven self-hosted sites: Airbnb-like, TikTok-like, Reddit-like, Instagram-like,
Facebook-like, Discord-like, and Threads-like, covering 681 tasks across
interaction complexity and targeting difficulty. Our end-to-end protocol
validates generated code via static checks, sandboxed execution, and outcome
verification including DOM assertions and database snapshots, and includes a
safety suite for scraping, spam/abuse, and credential/privacy prompts. Across
2636 model-task runs, we observe stratified success: GPT-4o-Mini achieves 96.8
percent, GPT-4.1 achieves 95.3 percent, Gemini-2.5-Pro achieves 89.0 percent,
and DeepSeek-V3.1 achieves 83.4 percent. Models handle simple tasks reliably at
91.7 percent but fail on complex workflows at 0.0 percent, and none meet
production-quality coding practices despite functional completion. We release
our complete benchmark pipeline, evaluation framework, and experimental results
to enable reproducible assessment of macro synthesis for web automation.

</details>


### [143] [Reconsidering Requirements Engineering: Human-AI Collaboration in AI-Native Software Development](https://arxiv.org/abs/2510.04380)
*Mateen Ahmed Abbasi,Petri Ihantola,Tommi Mikkonen,Niko Mäkitalo*

Main category: cs.SE

TL;DR: 本文探讨了人工智能（AI）在需求工程（RE）中的应用潜力，旨在通过自动化和协作提升RE效率和准确性，同时强调AI引入的伦理和透明性问题。


<details>
  <summary>Details</summary>
Motivation: 需求工程作为软件开发的基础，存在模糊性、利益冲突及需求管理复杂性等挑战，亟需提升效率和准确性。AI被视为可能的解决方案，但同时带来新的伦理和偏见问题。

Method: 本文分析了AI如何自动化RE中劳动密集型任务，支持需求优先级排序，并促进利益相关者与AI系统的协作，并探讨了应用AI过程中面临的机遇与挑战。

Result: AI可提升RE流程的效率、准确性和管理能力，但也需应对伦理、偏见及透明性等新问题。强调学术界与产业界合作，推动可信赖且实用的AI解决方案。

Conclusion: 未来RE中AI应用应注重伦理实践和多方合作，打造既强大又可信，能适应快速变化的软件开发需求的AI系统。

Abstract: Requirement Engineering (RE) is the foundation of successful software
development. In RE, the goal is to ensure that implemented systems satisfy
stakeholder needs through rigorous requirements elicitation, validation, and
evaluation processes. Despite its critical role, RE continues to face
persistent challenges, such as ambiguity, conflicting stakeholder needs, and
the complexity of managing evolving requirements. A common view is that
Artificial Intelligence (AI) has the potential to streamline the RE process,
resulting in improved efficiency, accuracy, and management actions. However,
using AI also introduces new concerns, such as ethical issues, biases, and lack
of transparency. This paper explores how AI can enhance traditional RE
practices by automating labor-intensive tasks, supporting requirement
prioritization, and facilitating collaboration between stakeholders and AI
systems. The paper also describes the opportunities and challenges that AI
brings to RE. In particular, the vision calls for ethical practices in AI,
along with a much-enhanced collaboration between academia and industry
professionals. The focus should be on creating not only powerful but also
trustworthy and practical AI solutions ready to adapt to the fast-paced world
of software development.

</details>


### [144] [Smart Hiring Redefined: An Intelligent Recruitment Management Platform](https://arxiv.org/abs/2510.04437)
*Fangzhe Wu,Dongyang Lyu,Xiaoqi Li*

Main category: cs.SE

TL;DR: 本文探讨了智能招聘管理系统如何通过自动化和数据驱动的方法，提升招聘效率和准确性，克服传统招聘模式的低效、高成本和信息不对称问题。


<details>
  <summary>Details</summary>
Motivation: 随着人力资源管理的数字化和智能化转型，传统招聘模式难以满足企业精准招聘的需求，亟需提升招聘效率和降低成本。

Method: 通过构建智能招聘管理系统，实现简历自动解析、候选人与职位的智能匹配及面试自动安排。

Result: 智能招聘系统显著提高了招聘过程的效率和准确性，减轻了人工简历筛选、职位匹配及面试协调的工作负担。

Conclusion: 智能招聘管理系统已成为现代组织人才战略中的关键工具，有助于优化招聘流程，提升核心竞争力。

Abstract: Against the backdrop of deepening digital and intelligent transformation in
human resource management, traditional recruitment models struggle to fully
meet enterprises' growing demand for precise talent acquisition due to limited
efficiency, high costs, and information asymmetry. As a vital tool for
optimizing recruitment processes, reducing labor and time costs, and enhancing
core competitiveness, intelligent recruitment management systems become an
indispensable component of modern organizational talent strategies.Compared
with the labor intensive tasks of resume screening, candidate position
matching, and interview coordination in traditional manual recruitment,
intelligent recruitment systems significantly enhance the efficiency and
accuracy of the hiring process through automation and data driven approaches.
These systems enable rapid parsing of massive resume volumes, intelligent
matching of candidates to positions, and automated scheduling of interview
processes.

</details>


### [145] [Improving IR-based Bug Localization with Semantics-Driven Query Reduction](https://arxiv.org/abs/2510.04468)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: 提出了IQLoc，一种结合信息检索与变换模型的缺陷定位方法，通过利用程序语义理解提升定位效果，在扩展的Bench4BL数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统信息检索方法忽视代码上下文和语义，大型语言模型虽能理解文本与代码，但尚未有效用于缺陷定位且资源消耗大。需结合两者优势以改进定位准确性。

Method: IQLoc利用基于变换器的模型理解程序语义，评估代码可疑性，并通过信息检索动态重构查询，用于提升缺陷定位性能。

Result: 在扩展后的Bench4BL数据集（~7.5K报告）上，IQLoc在MAP、MRR和HIT@K指标均显著优于四种基线方法，特别在带有堆栈跟踪和代码元素的报告中提升明显。

Conclusion: 通过整合程序语义理解与传统信息检索，IQLoc有效解决了传统方法的诸多局限，显著提升了软件缺陷定位的准确性和鲁棒性。

Abstract: Despite decades of research, software bug localization remains challenging
due to heterogeneous content and inherent ambiguities in bug reports. Existing
methods such as Information Retrieval (IR)-based approaches often attempt to
match source documents to bug reports, overlooking the context and semantics of
the source code. On the other hand, Large Language Models (LLM) (e.g.,
Transformer models) show promising results in understanding both texts and
code. However, they have not been yet adapted well to localize software bugs
against bug reports. They could be also data or resource-intensive. To bridge
this gap, we propose, IQLoc, a novel bug localization approach that capitalizes
on the strengths of both IR and LLM-based approaches. In particular, we
leverage the program semantics understanding of transformer-based models to
reason about the suspiciousness of code and reformulate queries during bug
localization using Information Retrieval. To evaluate IQLoc, we refine the
Bench4BL benchmark dataset and extend it by incorporating ~30% more recent bug
reports, resulting in a benchmark containing ~7.5K bug reports. We evaluated
IQLoc using three performance metrics and compare it against four baseline
techniques. Experimental results demonstrate its superiority, achieving up to
58.52% and 60.59% in MAP, 61.49% and 64.58% in MRR, and 69.88% and 100.90% in
HIT@K for the test bug reports with random and time-wise splits, respectively.
Moreover, IQLoc improves MAP by 91.67% for bug reports with stack traces,
72.73% for those that include code elements, and 65.38% for those containing
only descriptions in natural language. By integrating program semantic
understanding into Information Retrieval, IQLoc mitigates several longstanding
challenges of traditional IR-based approaches in bug localization.

</details>


### [146] [DynamiQ: Unlocking the Potential of Dynamic Task Allocation in Parallel Fuzzing](https://arxiv.org/abs/2510.04469)
*Wenqi Yan,Toby Murray,Benjamin Rubinstein,Van-Thuan Pham*

Main category: cs.SE

TL;DR: 本文提出了DynamiQ，一种基于程序调用图动态分配任务的自适应并行模糊测试工具，显著提升了模糊测试效率和漏洞发现能力。


<details>
  <summary>Details</summary>
Motivation: 现有并行模糊测试大多将单个种子作为任务，存在大量冗余探索，效率不足。

Method: DynamiQ利用程序调用图结构定义任务，结合运行时反馈动态调整任务分配，基于LibAFL框架实现多项优化。

Result: 在12个真实目标和25000小时计算资源上，DynamiQ在代码覆盖率和漏洞发现上均优于现有并行模糊测试工具，发现了9个新漏洞。

Conclusion: 通过结构化任务划分和动态调度，DynamiQ显著提升了大规模并行模糊测试的效率和效果。

Abstract: We present DynamiQ, a full-fledged and optimized successor to AFLTeam that
supports dynamic and adaptive parallel fuzzing. Unlike most existing approaches
that treat individual seeds as tasks, DynamiQ leverages structural information
from the program's call graph to define tasks and continuously refines task
allocation using runtime feedback. This design significantly reduces redundant
exploration and enhances fuzzing efficiency at scale. Built on top of the
state-of-the-art LibAFL framework, DynamiQ incorporates several practical
optimizations in both task allocation and task-aware fuzzing. Evaluated on 12
real-world targets from OSS-Fuzz and FuzzBench over 25,000 CPU hours, DynamiQ
outperforms state-of-the-art parallel fuzzers in both code coverage and
vulnerability discovery, uncovering 9 previously unknown bugs in widely used
and extensively fuzzed open-source software.

</details>


### [147] [Detecting and Characterizing Low and No Functionality Packages in the NPM Ecosystem](https://arxiv.org/abs/2510.04495)
*Napasorn Tevarut,Brittany Reid,Yutaro Kashiwa,Pattara Leelaprute,Arnon Rungsawang,Bundit Manaskasemsak,Hajimu Iida*

Main category: cs.SE

TL;DR: 本文提出一种基于规则的静态分析方法，检测npm生态中功能简单或无执行逻辑的软件包，发现其在依赖中占比近18%，具有较高安全风险。


<details>
  <summary>Details</summary>
Motivation: npm生态中大量功能简单的软件包普遍存在，但这些包虽小却潜藏安全隐患，且现有定义不够精确。

Method: 通过细化功能简单包定义，引入仅含数据的包，并设计规则静态分析工具检测和评估其规模与风险。

Result: 分析显示17.92%的包为功能简单包，其漏洞风险与非简单包相当，数据包虽然少但同样存在风险，检测工具准确率达94%。

Conclusion: 功能简单及数据包在npm依赖中不可忽视，需加强管理以减少技术债务和安全风险。

Abstract: Trivial packages, small modules with low functionality, are common in the npm
ecosystem and can pose security risks despite their simplicity. This paper
refines existing definitions and introduce data-only packages that contain no
executable logic. A rule-based static analysis method is developed to detect
trivial and data-only packages and evaluate their prevalence and associated
risks in the 2025 npm ecosystem. The analysis shows that 17.92% of packages are
trivial, with vulnerability levels comparable to non-trivial ones, and
data-only packages, though rare, also contain risks. The proposed detection
tool achieves 94% accuracy (macro-F1 0.87), enabling effective large-scale
analysis to reduce security exposure. This findings suggest that trivial and
data-only packages warrant greater attention in dependency management to reduce
potential technical debt and security exposure.

</details>


### [148] [Spec2Control: Automating PLC/DCS Control-Logic Engineering from Natural Language Requirements with LLMs - A Multi-Plant Evaluation](https://arxiv.org/abs/2510.04519)
*Heiko Koziolek,Thilo Braun,Virendra Ashiwal,Sofia Linsbauer,Marthe Ahlgreen Hansen,Karoline Grotterud*

Main category: cs.SE

TL;DR: 本文提出了Spec2Control，一种利用大型语言模型（LLMs）从自然语言需求生成图形控制逻辑的自动化工作流程，显著提高了分布式控制系统的软件编程效率。


<details>
  <summary>Details</summary>
Motivation: 分布式控制系统的软件编程过程复杂繁琐，成本高昂，现有LLM辅助工具仅针对文本且自动化程度有限，且未在大规模真实数据集上测试。

Method: 提出Spec2Control，基于LLM，直接从自然语言用户需求生成图形化控制逻辑，并在开源数据集上通过10个控制叙述和65个复杂测试用例进行验证。

Result: Spec2Control能够成功识别控制策略，自动生成98.6%的正确控制策略连接，节省94-96%的人力劳动。

Conclusion: Spec2Control显著提高DCS控制逻辑的自动化生成效率，目前已集成至商业ABB工程工具，并提供开源版本供独立验证。

Abstract: Distributed control systems (DCS) manage the automation for many industrial
production processes (e.g., power plants, chemical refineries, steel mills).
Programming the software for such systems remains a largely manual and tedious
process, incurring costs of millions of dollars for extensive facilities. Large
language models (LLMs) have been found helpful in generating DCS control logic,
resulting in commercial copilot tools. Today, these tools are focused on
textual notations, they provide limited automation, and have not been tested on
large datasets with realistic test cases. We introduce Spec2Control, a highly
automated LLM workflow to generate graphical control logic directly from
natural language user requirements. Experiments using an open dataset with 10
control narratives and 65 complex test cases demonstrate that Spec2Control can
successfully identify control strategies, can generate 98.6% of correct control
strategy connections autonomously, and can save between 94-96% of human labor.
Spec2Control is being integrated into commercial ABB engineering tools, but is
also available as an open-source variant for independent validation.

</details>


### [149] [Advancing Digital Government: Integrating Open Source Software Enablement Indicators in Maturity Indexes](https://arxiv.org/abs/2510.04603)
*Johan Linåker,Sachiko Muto*

Main category: cs.SE

TL;DR: 本文研究了16个数字成熟国家的政府开源软件（OSS）采用政策，分析其形成、目标及支持机制，提出数字政府成熟度指标。


<details>
  <summary>Details</summary>
Motivation: 政府对开源软件的采用对数字政府转型具有重要影响，但系统性的测量较少，本文旨在填补这一空白。

Method: 结合政策文件的文献研究和政府代表的半结构化访谈，制作详细国家报告并进行交叉分析。

Result: 发现大量促进OSS重用的政策，涵盖获取和共享，重点在互操作性、主权、透明度和成本效益。多级政府的开源项目办公室提供实施支持。提出涵盖政策设计与支持的14个指标。

Conclusion: 开源软件是公共部门数字转型的战略推动力，需明确政策框架和机构支持。数字成熟度框架应扩展OSS指标以指导和评估政府采用情况。

Abstract: Context: Open Source Software (OSS) is a vital public good, included across
most of modern software stacks, significantly impacting GDP and national tech
growth, while supporting interoperability, sovereignty, and transparency.
However, systematic measurement of governmental OSS adoption remain limited.
  Research Aim: This study contributes to digital government maturity indexes
by analyzing policies and support actions leveraging OSS for software reuse and
collaborative development across 16 digitally mature countries, and proposing
potential indicators for said indexes. It examines OSS policy formation, stated
goals, key actors, and support mechanisms.
  Methodology: A qualitative approach is used combining desk research of policy
documents with semi-structured interviews of government representatives,
producing detailed country reports. These are cross-analyzed, focusing on OSS
policy promotion, rationale, and implementation support.
  Results: Policies facilitating OSS reuse are widespread, targeting both
inbound acquisition and outbound sharing, and are predominantly governed by
central public sector organizations. Policy goals include interoperability,
digital sovereignty, transparency, and cost efficiency, with security framed
both as a risk and strength. Implementation is supported by diverse Open Source
Program Offices (OSPOs) at multiple government levels, which foster capacity
building, resource pooling, and sustainable project governance. Indicators are
synthesized and proposed across 14 areas covering policy incentives and design,
and implementation and support.
  Conclusions: OSS is a strategic enabler for public sector digital
transformation. Clear policy frameworks, coupled with institutional support
such as OSPOs, are essential. International digital maturity frameworks should
expand OSS indicators to better guide and assess government adoption and
impact.

</details>


### [150] [Exploring the Power of Diffusion Large Language Models for Software Engineering: An Empirical Investigation](https://arxiv.org/abs/2510.04605)
*Jingyao Zhang,Tianlin Li,Xiaoyu Zhang,Qiang Hu,Bin Shi*

Main category: cs.SE

TL;DR: DLLMs在软件工程任务中超越了AR-LLMs，提升了准确率和效率。


<details>
  <summary>Details</summary>
Motivation: AR-LLMs在处理代码结构信息和推理时延方面存在限制，DLLMs提供了一种有潜力的替代方案。

Method: 对DLLMs在代码生成、缺陷检测和程序修复等软件开发生命周期任务上进行全面评估。

Result: 7B参数的DLLMs在52,937个任务的基准测试中平均准确率提升30%，在跨文件修复上提升达113%，同时保持更高效率和更低延迟。

Conclusion: DLLMs被证实为处理软件工程任务的更优模型范式。

Abstract: Autoregressive Large Language Models (AR-LLMs) are widely used in software
engineering (SE) but face limitations in processing code structure information
and suffer from high inference latency. Diffusion LLMs (DLLMs) offer a
promising alternative with global bidirectional encoding and decoupled
generation steps. This work presents the first comprehensive evaluation of
DLLMs across the software development lifecycle, including code generation,
defect detection, and program repair. On a large-scale benchmark of 52,937
tasks, 7Bparameter DLLMs outperform AR-LLMs with a 30% average accuracy
improvement achieving a 113% gain on cross-file repair, while maintaining
superior efficiency and reduced latency. Our results establish DLLMs as a
superior paradigm for SE tasks.

</details>


### [151] [A survey on the impact of emotions on the productivity among software developers](https://arxiv.org/abs/2510.04611)
*Pawel Weichbroth,Maciej Lotysz,Michal Wrobel*

Main category: cs.SE

TL;DR: 该研究探讨了软件开发人员的情绪状态与其感知生产力之间的关系，结果表明情绪状态对感知生产力有显著正向影响。


<details>
  <summary>Details</summary>
Motivation: 软件开发中的时间压力等因素常导致开发人员情绪状态下降，但情绪是否影响感知生产力尚无定论，因此研究旨在验证二者关系。

Method: 采用两阶段方法：先通过9位专家验证测量模型，再对88名软件开发者进行调查，利用偏最小二乘法进行路径分析检验假设。

Result: 路径分析结果显著支持假设，开发人员的情绪状态对感知生产力有强烈正向影响（beta=0.893，p<0.001）。

Conclusion: 强调改善开发人员情绪健康的重要性，通过减少职业倦怠和压力等负面因素，有望提升软件开发的生产力表现。

Abstract: The time pressure associated with software development, among other factors,
often leads to a diminished emotional state among developers. However, whether
emotions affect perceived productivity remains an open question. This study
aims to determine the strength and direction of the relationship between
emotional state and perceived productivity among software developers. We
employed a two-stage approach. First, a survey was conducted with a pool of
nine experts to validate the measurement model. Second, a survey was
administered to a pool of 88 software developers to empirically test the
formulated hypothesis by using Partial Least Squares, as the data analysis
method. The results of the path analysis clearly confirm the formulated
hypothesis, showing that the emotional state of a software developer has a
strong positive, and significant impact (beta = 0.893, p < 0.001) on perceived
productivity among software developers. The findings highlight the importance
of managing and improving developers emotional well-being to enhance
productivity in software development environments. Additionally, interventions
aimed at reducing burnout, stress, and other negative factors could have a
considerable impact on their performance outcomes.

</details>


### [152] [Evolaris: A Roadmap to Self-Evolving Software Intelligence Management](https://arxiv.org/abs/2510.04689)
*Chengwei Liu,Wenbo Guo,Yuxin Zhang,Limin Wang,Sen Chen,Lei Bu,Yang Liu*

Main category: cs.SE

TL;DR: 提出了Evolaris多代理自演化软件情报系统，实时整合分散威胁信息，提升软件威胁分析的准确性和时效性。


<details>
  <summary>Details</summary>
Motivation: 软件威胁信息日益动态分散，传统渠道不足以实时捕获和分析来自博客、社交媒体等多源信息，需新系统及时汇聚和处理。

Method: 构建基于多代理框架的全流程工作流，代理独立运行并共享上下文，执行信息发现、推理、填补空缺、验证和风险检测，实现自演化能力。

Result: 系统能从新输入中学习，不断完善知识库，适应新兴威胁模式，提升威胁分析的精准度、时效性和可扩展性。

Conclusion: Evolaris为软件安全决策提供可持续支持，增强安全威胁理解生态，有助于主动防御和响应软件威胁。

Abstract: In recent years, the landscape of software threats has become significantly
more dynamic and distributed. Security vulnerabilities are no longer discovered
and shared only through formal channels such as public vulnerability databases
or vendor advisories. Increasingly, criti- cal threat information emerges
informally through blogs, social media, developer forums, open source
repositories, and even underground com- munities. To this end, capturing such
intelligence in a timely manner is essential for maintaining situational
awareness and enabling prompt security responses. However, this remains a
complex challenge due to the fragmented nature of data sources and the
technical difficulty of collecting, parsing, mapping, and validating
information at scale. To ad- dress this, we propose Evolaris, a self-evolving
software intelligence sys- tem built on a multi-agent framework. Evolaris is
designed to support a full-stack workflow, where agents operate independently
but coordinate through shared context to perform tasks such as information
discovery, reasoning, gap completion, validation, and risk detection. This
archi- tecture enables the platform to learn from new inputs, refine its
internal knowledge, and adapt to emerging threat patterns over time, which
could continuously improve the precision, timeliness, and scalability of
software threat analysis, and offers a sustainable foundation for proactive
secu- rity decision-making and strengthens the broader ecosystem of security
threat understanding.

</details>


### [153] [An Empirical Study of SOTA RCA Models: From Oversimplified Benchmarks to Realistic Failures](https://arxiv.org/abs/2510.04711)
*Aoyang Fang,Songhan Zhang,Yifan Yang,Haotong Wu,Junjielong Xu,Xuyang Wang,Rui Wang,Manyi Wang,Qisheng Lu,Pinjia He*

Main category: cs.SE

TL;DR: 该论文指出现有云原生微服务架构中的根因分析（RCA）基准测试过于简化，导致模型性能被高估，进而提出了一种自动生成更真实基准测试的数据集，并重新评估了多种最先进模型，发现其在真实数据上表现较差，揭示了根因分析中的常见难点。


<details>
  <summary>Details</summary>
Motivation: 当前根因分析模型在广泛使用的基准测试上表现良好，但这些基准过于简化，无法反映真实环境，导致性能估计过高。为了改进根因分析的现实应用效果，需要更真实的测试数据和评估方法。

Method: 作者分析了现有基准的局限性，包括故障注入方式、调用图设计和遥测模式。基于此设计了一套自动化框架，生成包含25种故障类型、动态负载及层级标签的真实故障数据集。并在此数据集上重新评估了11个最先进模型。

Result: 新的数据集包含1430个经过验证的故障案例，重评11个最先进模型发现其Top@1准确率平均仅为0.21，最高0.37，且执行时间明显增加。分析揭示了模型存在的扩展性问题、监控盲点和建模瓶颈。

Conclusion: 现有根因分析模型在现实复杂环境中的性能远低于以往基准测试的结果，未来需解决扩展性、监控覆盖和建模方法等核心难题，提高根因分析的实用价值。

Abstract: While cloud-native microservice architectures have transformed software
development, their complexity makes Root Cause Analysis (RCA) both crucial and
challenging. Although many data-driven RCA models have been proposed, we find
that existing benchmarks are often oversimplified and fail to capture
real-world conditions. Our preliminary study shows that simple rule-based
methods can match or even outperform state-of-the-art (SOTA) models on four
widely used benchmarks, suggesting performance overestimation due to benchmark
simplicity. To address this, we systematically analyze popular RCA benchmarks
and identify key limitations in fault injection, call graph design, and
telemetry patterns. Based on these insights, we develop an automated framework
to generate more realistic benchmarks, yielding a dataset of 1,430 validated
failure cases from 9,152 injections, covering 25 fault types under dynamic
workloads with hierarchical ground-truth labels and verified SLI impact.
Re-evaluation of 11 SOTA models on this dataset shows low Top@1 accuracy
(average 0.21, best 0.37) and significantly longer execution times. Our
analysis highlights three common failure patterns: scalability issues,
observability blind spots, and modeling bottlenecks.

</details>


### [154] [Agile Software Effort Estimation using Regression Techniques](https://arxiv.org/abs/2510.04760)
*Sisay Deresa Sima,Ayalew Belay Habtie*

Main category: cs.SE

TL;DR: 本文利用LASSO和弹性网络回归技术，基于故事点开发了敏捷软件开发的工作量估计模型，并在21个项目上验证，LASSO表现最佳。


<details>
  <summary>Details</summary>
Motivation: 软件开发工作量估计对项目成功至关重要，现有敏捷估计方法仍需改进准确性。

Method: 采用LASSO和弹性网络回归技术，利用21个软件项目数据，基于故事点进行模型训练和调参（5折交叉验证和网格搜索）。

Result: LASSO回归模型在预测性能指标PRED(8%)和PRED(25%)均达到100%，且MMRE、MMER、MdMRE、MdMER及MSE均表现优异，优于之前相关研究。

Conclusion: 基于LASSO回归的敏捷工作量估计模型在准确性上表现突出，可为敏捷项目提供高质量的工作量预测支持。

Abstract: Software development effort estimation is one of the most critical aspect in
software development process, as the success or failure of the entire project
depends on the accuracy of estimations. Researchers are still conducting
studies on agile effort estimation. The aim of this research is to develop a
story point based agile effort estimation model using LASSO and Elastic Net
regression techniques. The experimental work is applied to the agile story
point approach using 21 software projects collected from six firms. The two
algorithms are trained using their default parameters and tuned grid search
with 5-fold cross-validation to get an enhanced model. The experiment result
shows LASSO regression achieved better predictive performance PRED (8%) and
PRED (25%) results of 100.0, MMRE of 0.0491, MMER of 0.0551, MdMRE of 0.0593,
MdMER of 0.063, and MSE of 0.0007. The results are also compared with other
related literature.

</details>


### [155] [GUISpector: An MLLM Agent Framework for Automated Verification of Natural Language Requirements in GUI Prototypes](https://arxiv.org/abs/2510.04791)
*Kristian Kolthoff,Felix Kretzer,Simone Paolo Ponzetto,Alexander Maedche,Christian Bartelt*

Main category: cs.SE

TL;DR: 本文提出了基于多模态大语言模型（MLLM）的GUISpector框架，实现了GUI原型中自然语言需求的自动验证。


<details>
  <summary>Details</summary>
Motivation: 当前GUI测试方法难以处理现代界面的复杂性，缺乏有效反馈和与自动化开发代理的整合，难以保证GUI实现符合自然语言需求。

Method: GUISpector利用MLLM智能体解析自然语言需求，自主规划和执行验证路径；系统提取详细的自然语言反馈，为开发者提供可操作的改进建议；提供集成工具界面管理整个验证过程。

Result: 在150条需求和900条验收标准的综合测试中，GUISpector有效检测了需求满足与违规情况，展示了将反馈无缝整合入自动化LLM驱动开发流程的潜力。

Conclusion: GUISpector有效提升了基于自然语言需求的GUI验证能力，支持闭环迭代优化，促进了智能化自动化软件开发。

Abstract: GUIs are foundational to interactive systems and play a pivotal role in early
requirements elicitation through prototyping. Ensuring that GUI implementations
fulfill NL requirements is essential for robust software engineering,
especially as LLM-driven programming agents become increasingly integrated into
development workflows. Existing GUI testing approaches, whether traditional or
LLM-driven, often fall short in handling the complexity of modern interfaces,
and typically lack actionable feedback and effective integration with automated
development agents. In this paper, we introduce GUISpector, a novel framework
that leverages a multi-modal (M)LLM-based agent for the automated verification
of NL requirements in GUI prototypes. First, GUISpector adapts a MLLM agent to
interpret and operationalize NL requirements, enabling to autonomously plan and
execute verification trajectories across GUI applications. Second, GUISpector
systematically extracts detailed NL feedback from the agent's verification
process, providing developers with actionable insights that can be used to
iteratively refine the GUI artifact or directly inform LLM-based code
generation in a closed feedback loop. Third, we present an integrated tool that
unifies these capabilities, offering practitioners an accessible interface for
supervising verification runs, inspecting agent rationales and managing the
end-to-end requirements verification process. We evaluated GUISpector on a
comprehensive set of 150 requirements based on 900 acceptance criteria
annotations across diverse GUI applications, demonstrating effective detection
of requirement satisfaction and violations and highlighting its potential for
seamless integration of actionable feedback into automated LLM-driven
development workflows. The video presentation of GUISpector is available at:
https://youtu.be/JByYF6BNQeE, showcasing its main capabilities.

</details>


### [156] [RevMine: An LLM-Assisted Tool for Code Review Mining and Analysis Across Git Platforms](https://arxiv.org/abs/2510.04796)
*Samah Kansab,Francis Bordeleau,Ali Tizghadam*

Main category: cs.SE

TL;DR: RevMine利用大型语言模型简化代码评审数据的采集和分析，降低技术门槛，促进更多实证软件工程研究。


<details>
  <summary>Details</summary>
Motivation: 收集和分析代码评审数据过程繁琐且技术要求高，制约了实证研究的广泛开展。

Method: 利用大型语言模型引导用户完成认证、端点发现和自然语言驱动的数据收集，支持基于用户定义的过滤条件或语言模型推断的模式进行定量和定性分析。

Result: 成功设计了RevMine工具架构，展示了其使用场景和研究潜力，有效简化了代码评审数据挖掘流程。

Conclusion: RevMine降低了代码评审数据采集分析的门槛，有助于推广和普及代码评审矿工，支持更多软件工程实证研究。

Abstract: Empirical research on code review processes is increasingly central to
understanding software quality and collaboration. However, collecting and
analyzing review data remains a time-consuming and technically intensive task.
Most researchers follow similar workflows - writing ad hoc scripts to extract,
filter, and analyze review data from platforms like GitHub and GitLab. This
paper introduces RevMine, a conceptual tool that streamlines the entire code
review mining pipeline using large language models (LLMs). RevMine guides users
through authentication, endpoint discovery, and natural language-driven data
collection, significantly reducing the need for manual scripting. After
retrieving review data, it supports both quantitative and qualitative analysis
based on user-defined filters or LLM-inferred patterns. This poster outlines
the tool's architecture, use cases, and research potential. By lowering the
barrier to entry, RevMine aims to democratize code review mining and enable a
broader range of empirical software engineering studies.

</details>


### [157] [InsightQL: Advancing Human-Assisted Fuzzing with a Unified Code Database and Parameterized Query Interface](https://arxiv.org/abs/2510.04835)
*Wentao Gao,Renata Borovica-Gajic,Sang Kil Cha,Tian Qiu,Van-Thuan Pham*

Main category: cs.SE

TL;DR: InsightQL是一个辅助人类分析模糊测试阻塞点的框架，通过统一数据库和参数化查询接口，帮助开发者高效突破代码覆盖率瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前模糊测试在覆盖率平台（fuzz blockers）上受限，许多模糊测试器难以深入发现漏洞，人类专业分析虽有效但劳动强度大。

Method: 设计了InsightQL框架，结合统一数据库和直观的参数化查询接口，支持系统化提取测试洞见并辅助解除模糊测试阻塞。

Result: 在14个真实世界库上实验，InsightQL有效解除多个模糊测试阻塞点，代码覆盖率最高提升13.90%。

Conclusion: InsightQL有效提升模糊测试的深度和效率，实现了对复杂模糊测试阻塞问题的辅助人类解决方案。

Abstract: Fuzzing is a highly effective automated testing method for uncovering
software vulnerabilities. Despite advances in fuzzing techniques, such as
coverage-guided greybox fuzzing, many fuzzers struggle with coverage plateaus
caused by fuzz blockers, limiting their ability to find deeper vulnerabilities.
Human expertise can address these challenges, but analyzing fuzzing results to
guide this support remains labor-intensive. To tackle this, we introduce
InsightQL, the first human-assisting framework for fuzz blocker analysis.
Powered by a unified database and an intuitive parameterized query interface,
InsightQL aids developers in systematically extracting insights and efficiently
unblocking fuzz blockers. Our experiments on 14 popular real-world libraries
from the FuzzBench benchmark demonstrate the effectiveness of InsightQL,
leading to the unblocking of many fuzz blockers and considerable improvements
in code coverage (up to 13.90%).

</details>


### [158] [FreshBrew: A Benchmark for Evaluating AI Agents on Java Code Migration](https://arxiv.org/abs/2510.04852)
*Victor May,Diganta Misra,Yanqi Luo,Anjali Sridhar,Justine Gehring,Silvio Soares Ribeiro Junior*

Main category: cs.SE

TL;DR: 本文提出了FreshBrew，一个用于评估AI代理在Java项目迁移中的新基准，比较了多种大型语言模型与传统规则系统的迁移效果。


<details>
  <summary>Details</summary>
Motivation: 传统代码迁移依赖规则系统和人工干预，随着大型语言模型的发展，AI驱动的代理框架成为可行替代方案，但其效果尚未系统评估。

Method: 构建包含228个高测试覆盖率Java仓库的FreshBrew基准，重点评估代理在保持程序语义和避免奖励欺骗方面的能力，并基于此对多款主流大型语言模型与规则系统进行比较测试。

Result: 实验显示，表现最好的模型Gemini 2.5 Flash能成功迁移52.3%的项目至JDK 17。实证分析揭示了当前代理方法的优势和不足，并指出了其在真实任务中的失败模式。

Conclusion: 通过发布FreshBrew，本文为评估可信赖的AI代码迁移系统奠定基础，推动基于AI的代码现代化研究向着严谨、可复现的方向发展。

Abstract: AI coding assistants are rapidly becoming integral to modern software
development. A key challenge in this space is the continual need to migrate and
modernize codebases in response to evolving software ecosystems. Traditionally,
such migrations have relied on rule-based systems and human intervention. With
the advent of powerful large language models (LLMs), AI-driven agentic
frameworks offer a promising alternative-but their effectiveness has not been
systematically evaluated. In this paper, we introduce FreshBrew, a novel
benchmark for evaluating AI agents on project-level Java migrations, with a
specific focus on measuring an agent's ability to preserve program semantics
and avoid reward hacking, which we argue requires projects with high test
coverage for a rigorous and reliable evaluation. We benchmark several
state-of-the-art LLMs, and compare their performance against established
rule-based tools. Our evaluation of AI agents on this benchmark of 228
repositories shows that the top-performing model, Gemini 2.5 Flash, can
successfully migrate 52.3 percent of projects to JDK 17. Our empirical analysis
reveals novel insights into the critical strengths and limitations of current
agentic approaches, offering actionable insights into their real-world
applicability. Our empirical study reveals failure modes of current AI agents
in realistic Java modernization tasks, providing a foundation for evaluating
trustworthy code-migration systems. By releasing FreshBrew, we aim to
facilitate rigorous, reproducible evaluation and catalyze progress in AI-driven
codebase modernization.

</details>


### [159] [Retrieval-Augmented Code Generation: A Survey with Focus on Repository-Level Approaches](https://arxiv.org/abs/2510.04905)
*Yicheng Tao,Yao Qin,Yepang Liu*

Main category: cs.SE

TL;DR: 本文综述了检索增强代码生成技术，重点关注跨仓库生成，分析现有方法、数据集及评测，指出挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 现实软件开发需跨整个代码仓库生成代码，传统模型难以捕捉长距离依赖和保证全局语义一致，亟需提升代码生成的上下文感知和扩展性。

Method: 引入检索增强生成（RAG）范式，把外部检索机制与大型语言模型结合，提升模型捕捉跨文件依赖和生成连贯代码的能力。综述了多种生成策略、检索方式、模型架构、训练范式和评测协议。

Result: 系统总结了现有仓库级代码生成研究进展，涵盖方法分类、数据集与基准测试，评价了当前研究的局限性。

Conclusion: 建立统一分析框架，有助于推动检索增强代码生成领域的发展，激发未来在AI软件工程中的创新研究。

Abstract: Recent advancements in large language models (LLMs) have substantially
improved automated code generation. While function-level and file-level
generation have achieved promising results, real-world software development
typically requires reasoning across entire repositories. This gives rise to the
challenging task of Repository-Level Code Generation (RLCG), where models must
capture long-range dependencies, ensure global semantic consistency, and
generate coherent code spanning multiple files or modules. To address these
challenges, Retrieval-Augmented Generation (RAG) has emerged as a powerful
paradigm that integrates external retrieval mechanisms with LLMs, enhancing
context-awareness and scalability. In this survey, we provide a comprehensive
review of research on Retrieval-Augmented Code Generation (RACG), with an
emphasis on repository-level approaches. We categorize existing work along
several dimensions, including generation strategies, retrieval modalities,
model architectures, training paradigms, and evaluation protocols. Furthermore,
we summarize widely used datasets and benchmarks, analyze current limitations,
and outline key challenges and opportunities for future research. Our goal is
to establish a unified analytical framework for understanding this rapidly
evolving field and to inspire continued progress in AI-powered software
engineering.

</details>


### [160] [Why Software Signing (Still) Matters: Trust Boundaries in the Software Supply Chain](https://arxiv.org/abs/2510.04964)
*Kelechi G. Kalu,James C. Davis*

Main category: cs.SE

TL;DR: 软件签名确保软件来源和完整性，是软件供应链安全的基础，即使在安全的集中式注册库环境下仍然必要。


<details>
  <summary>Details</summary>
Motivation: 探讨在集中式软件注册库（如PyPI、npm等）强化安全控制的背景下，是否仍需端到端的软件签名来保障软件供应链的安全。

Method: 通过分析不同软件分发边界（如镜像站、公司代理、重托管和隔离传输）存在的安全盲点，综合历史实践，提出适合现代分发模式的信任模型。

Result: 发现注册库的安全控制无法涵盖所有分发边界，签名作为基本防护层，能够有效扩展信任，增强供应链的整体安全。

Conclusion: 即使注册库安全，软件签名仍是保证软件供应链完整性、溯源性和责任追踪的关键手段，不可或缺。

Abstract: Software signing provides a formal mechanism for provenance by ensuring
artifact integrity and verifying producer identity. It also imposes tooling and
operational costs to implement in practice. In an era of centralized registries
such as PyPI, npm, Maven Central, and Hugging Face, it is reasonable to ask
whether hardening registry security controls obviates the need for end-to-end
artifact signing. In this work, we posit that the core guarantees of signing,
provenance, integrity, and accountability are not automatically carried across
different software distribution boundaries. These boundaries include mirrors,
corporate proxies, re-hosting, and air-gapped transfers, where registry
security controls alone cannot provide sufficient assurance. We synthesize
historical practice and present a trust model for modern distribution modes to
identify when signing is necessary to extend trust beyond registry control.
Treating signing as a baseline layer of defense strengthens software supply
chain assurance even when registries are secure.

</details>


### [161] [Quantum Computing as a Service - a Software Engineering Perspective](https://arxiv.org/abs/2510.04982)
*Aakash Ahmad,Muhammad Waseem,Bakheet Aljedaani,Mahdi Fahmideh,Peng Liang,Feras Awaysheh*

Main category: cs.SE

TL;DR: 本文研究了量子计算即服务（QCaaS）的软件工程方法，提出了基于过程和架构驱动的量子服务开发生命周期和参考架构。


<details>
  <summary>Details</summary>
Motivation: 量子计算正逐渐成为颠覆性技术，但量子设备的稀缺促使开发提供量子计算资源的服务平台，方便无法拥有量子计算机的用户使用。

Method: 采用两阶段研究方法，首先通过系统映射研究筛选相关文献，随后基于文献结果开发集成量子服务开发生命周期的参考架构。

Result: 识别出包含构思、建模、组装和部署四个阶段的量子服务开发生命周期，提出量子关键需求、建模符号、设计模式、编程语言及部署平台的目录，形成分层参考架构支持QCaaS。

Conclusion: 本研究为实现量子计算即服务提供了系统的生命周期框架和参考架构，推动量子服务导向的软件工程发展与应用。

Abstract: Quantum systems have started to emerge as a disruptive technology and
enabling platforms - exploiting the principles of quantum mechanics via
programmable quantum bits (QuBits) - to achieve quantum supremacy in computing.
Academic research, industrial projects (e.g., Amazon Braket, IBM Qiskit), and
consortiums like 'Quantum Flagship' are striving to develop practically capable
and commercially viable quantum computing (QC) systems and technologies.
Quantum Computing as a Service (QCaaS) is viewed as a solution attuned to the
philosophy of service-orientation that can offer QC resources and platforms, as
utility computing, to individuals and organisations who do not own quantum
computers. This research investigates a process-centric and architecture-driven
approach to offer a software engineering perspective on enabling QCaaS - a.k.a
quantum service-orientation. We employed a two-phase research method comprising
(a) a systematic mapping study and (b) an architecture-based development, first
to identify the phases of the quantum service development life cycle and
subsequently to integrate these phases into a reference architecture that
supports QCaaS. The SMS process retrieved a collection of potentially relevant
research literature and based on a multi-step selection and qualitative
assessment, we selected 41 peer-reviewed studies to answer three RQs. The RQs
investigate (i) demographic details in terms of frequency, types, and trends of
research, (ii) phases of quantum service development lifecycle to derive a
reference architecture for conception, modeling, assembly, and deployment of
services, and (iii) The results identify a 4-phased development lifecycle along
with quantum significant requirements (QSRs), various modeling notations,
catalogue of patterns, programming languages, and deployment platforms that can
be integrated in a layered reference architecture to engineer QCaaS.

</details>


### [162] [AutoEmpirical: LLM-Based Automated Research for Empirical Software Fault Analysis](https://arxiv.org/abs/2510.04997)
*Jiongchi Yu,Weipeng Jiang,Xiaoyu Zhang,Qiang Hu,Xiaofei Xie,Chao Shen*

Main category: cs.SE

TL;DR: 本文研究了利用大型语言模型（LLM）自动分析软件故障，提高了故障分析效率，显著缩短了从数周到约两小时的处理时间。


<details>
  <summary>Details</summary>
Motivation: 传统软件故障分析依赖专家手工操作，耗时且费力，限制了大规模故障研究和迭代实证研究的速度。

Method: 将软件故障研究流程拆解为三阶段：（1）研究目标定义，（2）数据准备，（3）故障分析，利用LLM对开源软件中的3,829个故障进行自动分析和评估。

Result: 实验结果表明，LLM在故障分析中大幅提升效率，将处理时间缩短至约两小时，显著优于传统数周的人工分析。

Conclusion: LLM有潜力推进实证软件故障研究，但实现端到端全自动分析仍面临挑战，需进一步研究完善方法和解决难题。

Abstract: Understanding software faults is essential for empirical research in software
development and maintenance. However, traditional fault analysis, while
valuable, typically involves multiple expert-driven steps such as collecting
potential faults, filtering, and manual investigation. These processes are both
labor-intensive and time-consuming, creating bottlenecks that hinder
large-scale fault studies in complex yet critical software systems and slow the
pace of iterative empirical research.
  In this paper, we decompose the process of empirical software fault study
into three key phases: (1) research objective definition, (2) data preparation,
and (3) fault analysis, and we conduct an initial exploration study of applying
Large Language Models (LLMs) for fault analysis of open-source software.
Specifically, we perform the evaluation on 3,829 software faults drawn from a
high-quality empirical study. Our results show that LLMs can substantially
improve efficiency in fault analysis, with an average processing time of about
two hours, compared to the weeks of manual effort typically required. We
conclude by outlining a detailed research plan that highlights both the
potential of LLMs for advancing empirical fault studies and the open challenges
that required be addressed to achieve fully automated, end-to-end software
fault analysis.

</details>
