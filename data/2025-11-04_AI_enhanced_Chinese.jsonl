{"id": "2511.00074", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00074", "abs": "https://arxiv.org/abs/2511.00074", "authors": ["Richard Osuagwu", "Thomas Cook", "Maraim Masoud", "Koustav Ghosal", "Riccardo Mattivi"], "title": "ScaleCall - Agentic Tool Calling at Scale for Fintech: Challenges, Methods, and Deployment Insights", "comment": null, "summary": "While Large Language Models (LLMs) excel at tool calling, deploying these\ncapabilities in regulated enterprise environments such as fintech presents\nunique challenges due to on-premises constraints, regulatory compliance\nrequirements, and the need to disambiguate large, functionally overlapping\ntoolsets. In this paper, we present a comprehensive study of tool retrieval\nmethods for enterprise environments through the development and deployment of\nScaleCall, a prototype tool-calling framework within Mastercard designed for\norchestrating internal APIs and automating data engineering workflows. We\nsystematically evaluate embedding-based retrieval, prompt-based listwise\nranking, and hybrid approaches, revealing that method effectiveness depends\nheavily on domain-specific factors rather than inherent algorithmic\nsuperiority. Through empirical investigation on enterprise-derived benchmarks,\nwe find that embedding-based methods offer superior latency for large tool\nrepositories, while listwise ranking provides better disambiguation for\noverlapping functionalities, with hybrid approaches showing promise in specific\ncontexts. We integrate our findings into ScaleCall's flexible architecture and\nvalidate the framework through real-world deployment in Mastercard's regulated\nenvironment. Our work provides practical insights into the trade-offs between\nretrieval accuracy, computational efficiency, and operational requirements,\ncontributing to the understanding of tool-calling system design for enterprise\napplications in regulated industries.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u4f01\u4e1a\u73af\u5883\u4e0b\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u5177\u8c03\u7528\u7684\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4e07\u4e8b\u8fbe\u5361\u90e8\u7f72\u7684ScaleCall\u6846\u67b6\u9a8c\u8bc1\u4e86\u4e0d\u540c\u65b9\u6cd5\u5404\u81ea\u4f18\u52bf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f01\u4e1a\u5c24\u5176\u662f\u53d7\u76d1\u7ba1\u7684\u91d1\u878d\u79d1\u6280\u73af\u5883\u4e2d\u90e8\u7f72\u5de5\u5177\u8c03\u7528\u9762\u4e34\u672c\u5730\u90e8\u7f72\u3001\u5408\u89c4\u548c\u5de5\u5177\u529f\u80fd\u91cd\u53e0\u7b49\u6311\u6218\uff0c\u4e9f\u9700\u9ad8\u6548\u51c6\u786e\u7684\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5d4c\u5165\u7684\u68c0\u7d22\u3001\u57fa\u4e8e\u63d0\u793a\u7684\u5217\u8868\u6392\u5e8f\u548c\u6df7\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f01\u4e1a\u6570\u636e\u6784\u5efa\u7684\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u5e76\u5c06\u6210\u679c\u96c6\u6210\u5230ScaleCall\u6846\u67b6\u4e2d\u3002", "result": "\u5d4c\u5165\u65b9\u6cd5\u5728\u5927\u89c4\u6a21\u5de5\u5177\u5e93\u4e2d\u5ef6\u8fdf\u8f83\u4f4e\uff0c\u5217\u8868\u6392\u5e8f\u5bf9\u529f\u80fd\u91cd\u53e0\u7684\u5de5\u5177\u6709\u66f4\u597d\u533a\u5206\u6548\u679c\uff0c\u6df7\u5408\u65b9\u6cd5\u5728\u7279\u5b9a\u573a\u666f\u8868\u73b0\u51fa\u6f5c\u529b\u3002", "conclusion": "\u5de5\u5177\u68c0\u7d22\u65b9\u6cd5\u7684\u6709\u6548\u6027\u4f9d\u8d56\u7279\u5b9a\u9886\u57df\u56e0\u7d20\uff0c\u6743\u8861\u68c0\u7d22\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u548c\u8fd0\u8425\u9700\u6c42\u662f\u8bbe\u8ba1\u4f01\u4e1a\u5de5\u5177\u8c03\u7528\u7cfb\u7edf\u7684\u5173\u952e\u3002ScaleCall\u9a8c\u8bc1\u4e86\u6846\u67b6\u5b9e\u7528\u6027\uff0c\u4e3a\u53d7\u76d1\u7ba1\u884c\u4e1a\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2511.00087", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00087", "abs": "https://arxiv.org/abs/2511.00087", "authors": ["Anshu Dubey", "Akash Dhruv"], "title": "Adding New Capability in Existing Scientific Application with LLM Assistance", "comment": "8 pages, 4 figures, submitted to The 1st International Workshop on\n  Foundational large Language Models Advances for HPC in Asia", "summary": "With the emergence and rapid evolution of large language models (LLM),\nautomating coding tasks has become an im- portant research topic. Many efforts\nare underway and liter- ature abounds about the efficacy of models and their\nability to generate code. A less explored aspect of code generation is for new\nalgorithms, where the training data-set would not have included any previous\nexample of similar code. In this paper we propose a new methodology for writing\ncode from scratch for a new algorithm using LLM assistance, and describe\nenhancement of a previously developed code- translation tool, Code-Scribe, for\nnew code generation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u4ece\u96f6\u5f00\u59cb\u4e3a\u65b0\u7b97\u6cd5\u7f16\u5199\u4ee3\u7801\u7684\u65b9\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u4e4b\u524d\u5f00\u53d1\u7684\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177Code-Scribe\u4ee5\u5b9e\u73b0\u65b0\u4ee3\u7801\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u65b0\u7b97\u6cd5\u4ee3\u7801\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u56e0\u4e3a\u8bad\u7ec3\u6570\u636e\u4e2d\u4e0d\u5305\u542b\u7c7b\u4f3c\u4ee3\u7801\u7684\u4f8b\u5b50\uff0c\u6545\u9700\u8981\u63a2\u7d22\u65b0\u7684\u81ea\u52a8\u7f16\u7801\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5229\u7528LLM\u8f85\u52a9\u4ece\u96f6\u5199\u51fa\u65b0\u7b97\u6cd5\u4ee3\u7801\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u6539\u8fdb\u4e86\u4e4b\u524d\u7684\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177Code-Scribe\u4ee5\u652f\u6301\u65b0\u4ee3\u7801\u751f\u6210\u3002", "result": "\u6210\u529f\u589e\u5f3a\u4e86Code-Scribe\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u9488\u5bf9\u65b0\u7b97\u6cd5\u7684\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002", "conclusion": "LLM\u7ed3\u5408\u6539\u8fdb\u7684\u4ee3\u7801\u7ffb\u8bd1\u5de5\u5177\u80fd\u6709\u6548\u63d0\u5347\u5bf9\u5168\u65b0\u7b97\u6cd5\u81ea\u52a8\u7f16\u7801\u7684\u80fd\u529b\uff0c\u62d3\u5c55\u4e86\u81ea\u52a8\u7f16\u7801\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2511.00125", "categories": ["cs.SE", "cs.AI", "cs.LO", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.00125", "abs": "https://arxiv.org/abs/2511.00125", "authors": ["\u00c1lvaro Silva", "Alexandra Mendes", "Ruben Martins"], "title": "Inferring multiple helper Dafny assertions with LLMs", "comment": null, "summary": "The Dafny verifier provides strong correctness guarantees but often requires\nnumerous manual helper assertions, creating a significant barrier to adoption.\nWe investigate the use of Large Language Models (LLMs) to automatically infer\nmissing helper assertions in Dafny programs, with a primary focus on cases\ninvolving multiple missing assertions. To support this study, we extend the\nDafnyBench benchmark with curated datasets where one, two, or all assertions\nare removed, and we introduce a taxonomy of assertion types to analyze\ninference difficulty. Our approach refines fault localization through a hybrid\nmethod that combines LLM predictions with error-message heuristics. We\nimplement this approach in a new tool called DAISY (Dafny Assertion Inference\nSYstem). While our focus is on multiple missing assertions, we also evaluate\nDAISY on single-assertion cases. DAISY verifies 63.4% of programs with one\nmissing assertion and 31.7% with multiple missing assertions. Notably, many\nprograms can be verified with fewer assertions than originally present,\nhighlighting that proofs often admit multiple valid repair strategies and that\nrecovering every original assertion is unnecessary. These results demonstrate\nthat automated assertion inference can substantially reduce proof engineering\neffort and represent a step toward more scalable and accessible formal\nverification.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63a8\u65adDafny\u7a0b\u5e8f\u4e2d\u7f3a\u5931\u7684\u8f85\u52a9\u65ad\u8a00\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u548c\u9519\u8bef\u4fe1\u606f\u542f\u53d1\u5f0f\u7684\u6df7\u5408\u6545\u969c\u5b9a\u4f4d\u6280\u672f\uff0c\u5728\u5355\u65ad\u8a00\u548c\u591a\u65ad\u8a00\u7f3a\u5931\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7a0b\u5e8f\u9a8c\u8bc1\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u4eba\u5de5\u7f16\u5199\u8f85\u52a9\u65ad\u8a00\u7684\u8d1f\u62c5\u3002", "motivation": "Dafny\u9a8c\u8bc1\u5668\u867d\u7136\u80fd\u63d0\u4f9b\u5f3a\u5065\u7684\u6b63\u786e\u6027\u4fdd\u969c\uff0c\u4f46\u9700\u624b\u52a8\u7f16\u5199\u5927\u91cf\u8f85\u52a9\u65ad\u8a00\uff0c\u9650\u5236\u4e86\u5176\u666e\u53ca\u548c\u5e94\u7528\u3002\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u81ea\u52a8\u63a8\u65ad\u65ad\u8a00\u6765\u51cf\u8f7b\u8fd9\u4e00\u8d1f\u62c5\u3002", "method": "\u4f5c\u8005\u6269\u5c55\u4e86DafnyBench\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u6784\u9020\u65ad\u8a00\u7f3a\u5931\u6848\u4f8b\u5e76\u5206\u7c7b\u65ad\u8a00\u7c7b\u578b\uff0c\u63d0\u51fa\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u7ed3\u679c\u548c\u9519\u8bef\u6d88\u606f\u542f\u53d1\u5f0f\u7684\u6df7\u5408\u6545\u969c\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u5b9e\u73b0\u4e86DAISY\u5de5\u5177\u7528\u4e8e\u8f85\u52a9\u65ad\u8a00\u81ea\u52a8\u63a8\u65ad\u3002", "result": "DAISY\u5728\u5355\u65ad\u8a00\u7f3a\u5931\u60c5\u51b5\u4e0b\u80fd\u9a8c\u8bc163.4%\u7684\u7a0b\u5e8f\uff0c\u591a\u65ad\u8a00\u7f3a\u5931\u60c5\u51b5\u4e0b\u9a8c\u8bc1\u7387\u8fbe31.7%\u3002\u4e14\u8bb8\u591a\u7a0b\u5e8f\u7ecf\u8fc7\u8865\u65ad\u8a00\u540e\u6bd4\u539f\u59cb\u65ad\u8a00\u66f4\u5c11\u4e5f\u80fd\u901a\u8fc7\u9a8c\u8bc1\uff0c\u8bf4\u660e\u81ea\u52a8\u63a8\u65ad\u5177\u6709\u7075\u6d3b\u4fee\u590d\u7b56\u7565\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u8868\u660e\u81ea\u52a8\u65ad\u8a00\u63a8\u65ad\u53ef\u6781\u5927\u51cf\u5c11\u4eba\u5de5\u8bc1\u660e\u5de5\u4f5c\uff0c\u63d0\u9ad8\u5f62\u5f0f\u9a8c\u8bc1\u7684\u53ef\u6269\u5c55\u6027\u548c\u6613\u7528\u6027\uff0c\u662f\u5411\u81ea\u52a8\u5316\u5f62\u5f0f\u9a8c\u8bc1\u8fc8\u8fdb\u7684\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2511.00160", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00160", "abs": "https://arxiv.org/abs/2511.00160", "authors": ["Katherine A. Rosenfeld", "Cliff C. Kerr", "Jessica Lundin"], "title": "What a diff makes: automating code migration with large language models", "comment": "10 pages, 8 figures", "summary": "Modern software programs are built on stacks that are often undergoing\nchanges that introduce updates and improvements, but may also break any project\nthat depends upon them. In this paper we explore the use of Large Language\nModels (LLMs) for code migration, specifically the problem of maintaining\ncompatibility with a dependency as it undergoes major and minor semantic\nversion changes. We demonstrate, using metrics such as test coverage and change\ncomparisons, that contexts containing diffs can significantly improve\nperformance against out of the box LLMs and, in some cases, perform better than\nusing code. We provide a dataset to assist in further development of this\nproblem area, as well as an open-source Python package, AIMigrate, that can be\nused to assist with migrating code bases. In a real-world migration of\nTYPHOIDSIM between STARSIM versions, AIMigrate correctly identified 65% of\nrequired changes in a single run, increasing to 80% with multiple runs, with\n47% of changes generated perfectly.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u8fdb\u884c\u4ee3\u7801\u8fc1\u79fb\u4ee5\u7ef4\u6301\u4f9d\u8d56\u9879\u517c\u5bb9\u6027\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5305\u542b\u5dee\u5f02\u4e0a\u4e0b\u6587\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fc1\u79fb\u6548\u679c\uff0c\u5e76\u53d1\u5e03\u4e86\u76f8\u5173\u6570\u636e\u96c6\u548c\u5f00\u6e90\u5de5\u5177\u3002", "motivation": "\u8f6f\u4ef6\u6808\u9891\u7e41\u53d8\u66f4\u53ef\u80fd\u5bfc\u81f4\u4f9d\u8d56\u7834\u574f\uff0c\u9700\u6c42\u6709\u6548\u624b\u6bb5\u652f\u6301\u4f9d\u8d56\u5347\u7ea7\u65f6\u7684\u4ee3\u7801\u8fc1\u79fb\u3002", "method": "\u901a\u8fc7\u5411LLMs\u63d0\u4f9b\u542b\u7248\u672c\u5dee\u5f02\u7684\u4e0a\u4e0b\u6587\u589e\u5f3a\u6570\u636e\uff0c\u6bd4\u8f83\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53d8\u66f4\u5bf9\u6bd4\u6307\u6807\uff0c\u9a8c\u8bc1\u5176\u5728\u4ee3\u7801\u8fc1\u79fb\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u3002", "result": "\u5728TYPHOIDSIM\u4e0eSTARSIM\u7248\u672c\u8fc1\u79fb\u7684\u5b9e\u9645\u6848\u4f8b\u4e2d\uff0cAIMigrate\u5de5\u5177\u5728\u5355\u6b21\u8fd0\u884c\u4e2d\u51c6\u786e\u8bc6\u522b65%\u7684\u5fc5\u8981\u53d8\u66f4\uff0c\u591a\u6b21\u8fd0\u884c\u63d0\u9ad8\u81f380%\uff0c47%\u53d8\u66f4\u751f\u6210\u5b8c\u5168\u6b63\u786e\u3002", "conclusion": "\u57fa\u4e8e\u5dee\u5f02\u4e0a\u4e0b\u6587\u7684LLM\u8f85\u52a9\u4ee3\u7801\u8fc1\u79fb\u6709\u6548\u63d0\u5347\u4e86\u8fc1\u79fb\u8d28\u91cf\u4e0e\u6548\u7387\uff0c\u53d1\u5e03\u7684\u6570\u636e\u96c6\u548c\u5de5\u5177\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.00034", "categories": ["cs.MA", "cs.LG", "68T05, 68T07, 91A10", "I.2.6; I.2.11; I.2.8"], "pdf": "https://arxiv.org/pdf/2511.00034", "abs": "https://arxiv.org/abs/2511.00034", "authors": ["Aditya Akella"], "title": "On the Fundamental Limitations of Decentralized Learnable Reward Shaping in Cooperative Multi-Agent Reinforcement Learning", "comment": "8 pages, 5 figures, 2 tables", "summary": "Recent advances in learnable reward shaping have shown promise in\nsingle-agent reinforcement learning by automatically discovering effective\nfeedback signals. However, the effectiveness of decentralized learnable reward\nshaping in cooperative multi-agent settings remains poorly understood. We\npropose DMARL-RSA, a fully decentralized system where each agent learns\nindividual reward shaping, and evaluate it on cooperative navigation tasks in\nthe simple_spread_v3 environment. Despite sophisticated reward learning,\nDMARL-RSA achieves only -24.20 +/- 0.09 average reward, compared to MAPPO with\ncentralized training at 1.92 +/- 0.87--a 26.12-point gap. DMARL-RSA performs\nsimilarly to simple independent learning (IPPO: -23.19 +/- 0.96), indicating\nthat advanced reward shaping cannot overcome fundamental decentralized\ncoordination limitations. Interestingly, decentralized methods achieve higher\nlandmark coverage (0.888 +/- 0.029 for DMARL-RSA, 0.960 +/- 0.045 for IPPO out\nof 3 total) but worse overall performance than centralized MAPPO (0.273 +/-\n0.008 landmark coverage)--revealing a coordination paradox between local\noptimization and global performance. Analysis identifies three critical\nbarriers: (1) non-stationarity from concurrent policy updates, (2) exponential\ncredit assignment complexity, and (3) misalignment between individual reward\noptimization and global objectives. These results establish empirical limits\nfor decentralized reward learning and underscore the necessity of centralized\ncoordination for effective multi-agent cooperation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u5206\u6563\u5f0f\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u5f62\u7684\u6548\u679c\uff0c\u63d0\u51fa\u4e86DMARL-RSA\u7cfb\u7edf\u5e76\u53d1\u73b0\u5176\u6027\u80fd\u8fdc\u4e0d\u53ca\u96c6\u4e2d\u5f0f\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u5c40\u90e8\u4f18\u5316\u4e0e\u5168\u5c40\u6027\u80fd\u4e4b\u95f4\u7684\u534f\u8c03\u77db\u76fe\u3002", "motivation": "\u5c3d\u7ba1\u5355\u667a\u80fd\u4f53\u4e2d\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u5f62\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5176\u5728\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u5206\u6563\u5f0f\u73af\u5883\u4e2d\u7684\u6548\u679c\u548c\u6311\u6218\u4ecd\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e86DMARL-RSA\uff0c\u4e00\u79cd\u5b8c\u5168\u5206\u6563\u5f0f\u7684\u5956\u52b1\u5851\u5f62\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u72ec\u7acb\u5b66\u4e60\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u5728\u7b80\u5355\u7684\u5408\u4f5c\u5bfc\u822a\u4efb\u52a1\uff08simple_spread_v3\u73af\u5883\uff09\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "DMARL-RSA\u5728\u5e73\u5747\u5956\u52b1\u8868\u73b0\u4e0a\u663e\u8457\u52a3\u4e8e\u96c6\u4e2d\u5f0f\u8bad\u7ec3\u7684MAPPO\uff0c\u4e0e\u7b80\u5355\u72ec\u7acb\u5b66\u4e60\uff08IPPO\uff09\u8868\u73b0\u76f8\u8fd1\u3002\u5206\u6563\u5f0f\u65b9\u6cd5\u5728\u5730\u6807\u8986\u76d6\u7387\u4e0a\u8f83\u9ad8\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u8f83\u5dee\u3002\u5206\u6790\u6307\u51fa\u5b58\u5728\u975e\u5e73\u7a33\u6027\u3001\u4fe1\u7528\u5206\u914d\u590d\u6742\u6027\u53ca\u5956\u52b1\u4e0e\u5168\u5c40\u76ee\u6807\u4e0d\u4e00\u81f4\u4e09\u5927\u96be\u9898\u3002", "conclusion": "\u5206\u6563\u5f0f\u53ef\u5b66\u4e60\u5956\u52b1\u5851\u5f62\u53d7\u5236\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u540c\u7684\u6839\u672c\u6027\u9650\u5236\uff0c\u96c6\u4e2d\u5f0f\u534f\u8c03\u5728\u6709\u6548\u5408\u4f5c\u4e2d\u4f9d\u7136\u4e0d\u53ef\u6216\u7f3a\u3002"}}
{"id": "2511.00010", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00010", "abs": "https://arxiv.org/abs/2511.00010", "authors": ["Jiajun Zhang", "Jianke Zhang", "Zeyu Cui", "Jiaxi Yang", "Lei Zhang", "Binyuan Hui", "Qiang Liu", "Zilei Wang", "Liang Wang", "Junyang Lin"], "title": "PlotCraft: Pushing the Limits of LLMs for Complex and Interactive Data Visualization", "comment": null, "summary": "Recent Large Language Models (LLMs) have demonstrated remarkable profi-\nciency in code generation. However, their ability to create complex visualiza-\ntions for scaled and structured data remains largely unevaluated and\nunderdevel- oped. To address this gap, we introduce PlotCraft, a new benchmark\nfeaturing 1k challenging visualization tasks that cover a wide range of topics,\nsuch as fi- nance, scientific research, and sociology. The benchmark is\nstructured around seven high-level visualization tasks and encompasses 48\ndistinct chart types. Cru- cially, it is the first to systematically evaluate\nboth single-turn generation and multi-turn refinement across a diverse spectrum\nof task complexities. Our com- prehensive evaluation of 23 leading LLMs on\nPlotCraft reveals obvious per- formance deficiencies in handling sophisticated\nvisualization tasks. To bridge this performance gap, we develope SynthVis-30K,\na large-scale, high-quality dataset of complex visualization code synthesized\nvia a collaborative agent frame- work. Building upon this dataset, we develope\nPlotCraftor, a novel code gener- ation model that achieves strong capabilities\nin complex data visualization with a remarkably small size. Across VisEval,\nPandasPlotBench, and our proposed PlotCraft, PlotCraftor shows performance\ncomparable to that of leading propri- etary approaches. Especially, on hard\ntask, Our model achieves over 50% per- formance improvement. We will release\nthe benchmark, dataset, and code at\nhttps://github.com/Speakn0w/PlotCraft-Benchmark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PlotCraft\u57fa\u51c6\u6d4b\u8bd5\u53ca\u76f8\u5173\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u7528\u4e8e\u8bc4\u4f30\u548c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u6570\u636e\u53ef\u89c6\u5316\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u5904\u7406\u590d\u6742\u3001\u7ed3\u6784\u5316\u6570\u636e\u53ef\u89c6\u5316\u65b9\u9762\u5c1a\u672a\u88ab\u5145\u5206\u8bc4\u4f30\u548c\u53d1\u5c55\u3002", "method": "\u8bbe\u8ba1\u4e86\u5305\u542b1000\u4e2a\u590d\u6742\u53ef\u89c6\u5316\u4efb\u52a1\u7684PlotCraft\u57fa\u51c6\uff0c\u6db5\u76d67\u7c7b\u4efb\u52a1\u548c48\u79cd\u56fe\u8868\u7c7b\u578b\uff0c\u7cfb\u7edf\u8bc4\u6d4b23\u4e2a\u4e3b\u6d41\u6a21\u578b\u3002\u6784\u5efaSynthVis-30K\u5927\u89c4\u6a21\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u534f\u4f5c\u4ee3\u7406\u6846\u67b6\u751f\u6210\u590d\u6742\u53ef\u89c6\u5316\u4ee3\u7801\u3002\u5f00\u53d1\u5c0f\u578b\u9ad8\u6548\u7684\u4ee3\u7801\u751f\u6210\u6a21\u578bPlotCraftor\u3002", "result": "PlotCraft\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u8db3\uff0cPlotCraftor\u6a21\u578b\u5728\u591a\u4e2a\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u9886\u5148\u6c34\u5e73\uff0c\u7279\u522b\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u6027\u80fd\u63d0\u5347\u8d85\u8fc750%\u3002", "conclusion": "\u901a\u8fc7\u6570\u636e\u96c6\u548c\u65b0\u6a21\u578b\u7684\u5f15\u5165\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u590d\u6742\u6570\u636e\u53ef\u89c6\u5316\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u53d1\u5c55\u3002"}}
{"id": "2511.00197", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00197", "abs": "https://arxiv.org/abs/2511.00197", "authors": ["Oorja Majgaonkar", "Zhiwei Fei", "Xiang Li", "Federica Sarro", "He Ye"], "title": "Understanding Code Agent Behaviour: An Empirical Study of Success and Failure Trajectories", "comment": null, "summary": "The increasing deployment of Large Language Model (LLM) agents for complex\nsoftware engineering tasks has created a need to understand their\nproblem-solving behaviours beyond simple success metrics. While these agents\ndemonstrate impressive capabilities in automated issue resolution, their\ndecision-making processes remain largely opaque. This paper presents an\nempirical study of agent trajectories, namely the execution traces capturing\nthe steps agents take when attempting to resolve software issues. We analyse\ntrajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and\nPrometheus) on the SWE-Bench benchmark, examining both successful and failed\nattempts. Our investigation reveals several key insights into agent behaviour.\nFirst, we identify how distinct problem-solving strategies, such as defensive\nprogramming and context gathering, enable success in different scenarios.\nSecond, we find that failed trajectories are consistently longer and exhibit\nhigher variance than successful ones, with failure patterns differing\nsignificantly between agents. Third, our fault localisation analysis shows that\nwhile most trajectories correctly identify problematic files (72-81\\% even in\nfailures), success depends more on achieving approximate rather than exact code\nmodifications. These and other findings unveiled by our study, provide a\nfoundation for understanding agent behaviour through trajectory analysis,\ncontributing to the development of more robust and interpretable autonomous\nsoftware engineering systems.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u4e09\u79cd\u5148\u8fdb\u4ee3\u7801\u4ee3\u7406\u5728\u89e3\u51b3\u8f6f\u4ef6\u95ee\u9898\u65f6\u7684\u6267\u884c\u8f68\u8ff9\uff0c\u63ed\u793a\u4e86\u5176\u4e0d\u540c\u7b56\u7565\u548c\u5931\u8d25\u6a21\u5f0f\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u51b3\u7b56\u8fc7\u7a0b\u4e0d\u900f\u660e\uff0c\u9700\u6df1\u5165\u7406\u89e3\u5176\u95ee\u9898\u89e3\u51b3\u884c\u4e3a\u3002", "method": "\u6536\u96c6\u5e76\u5206\u6790OpenHands\u3001SWE-agent\u548cPrometheus\u4e09\u79cd\u4ee3\u7406\u5728SWE-Bench\u57fa\u51c6\u4e0a\u7684\u6210\u529f\u4e0e\u5931\u8d25\u8f68\u8ff9\uff0c\u7814\u7a76\u95ee\u9898\u89e3\u51b3\u7b56\u7565\u4e0e\u6545\u969c\u5b9a\u4f4d\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u7b56\u7565\u5982\u9632\u5fa1\u6027\u7f16\u7a0b\u548c\u4e0a\u4e0b\u6587\u6536\u96c6\u4fc3\u8fdb\u6210\u529f\uff1b\u5931\u8d25\u8f68\u8ff9\u66f4\u957f\u4e14\u5dee\u5f02\u5927\uff1b\u5927\u591a\u6570\u5931\u8d25\u4ecd\u80fd\u5b9a\u4f4d\u9519\u8bef\u6587\u4ef6\uff0c\u4f46\u6210\u529f\u4f9d\u8d56\u4e8e\u8fd1\u4f3c\u4fee\u6539\u3002", "conclusion": "\u8f68\u8ff9\u5206\u6790\u6709\u52a9\u4e8e\u7406\u89e3\u4ee3\u7406\u884c\u4e3a\uff0c\u4e3a\u6784\u5efa\u66f4\u7a33\u5065\u3001\u53ef\u89e3\u91ca\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u5de5\u7a0b\u7cfb\u7edf\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.00096", "categories": ["cs.MA", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.00096", "abs": "https://arxiv.org/abs/2511.00096", "authors": ["Shangyu Lou"], "title": "Urban-MAS: Human-Centered Urban Prediction with LLM-Based Multi-Agent System", "comment": "Accepted to The 3rd ACM SIGSPATIAL International Workshop on Advances\n  in Urban AI (UrbanAI'25)", "summary": "Urban Artificial Intelligence (Urban AI) has advanced human-centered urban\ntasks such as perception prediction and human dynamics. Large Language Models\n(LLMs) can integrate multimodal inputs to address heterogeneous data in complex\nurban systems but often underperform on domain-specific tasks. Urban-MAS, an\nLLM-based Multi-Agent System (MAS) framework, is introduced for human- centered\nurban prediction under zero-shot settings. It includes three agent types:\nPredictive Factor Guidance Agents, which prioritize key predictive factors to\nguide knowledge extraction and enhance the effectiveness of compressed urban\nknowledge in LLMs; Reliable UrbanInfo Extraction Agents, which improve\nrobustness by com- paring multiple outputs, validating consistency, and\nre-extracting when conflicts occur; and Multi-UrbanInfo Inference Agents, which\nintegrate extracted multi-source information across dimensions for prediction.\nExperiments on running-amount prediction and ur- ban perception across Tokyo,\nMilan, and Seattle demonstrate that Urban-MAS substantially reduces errors\ncompared to single-LLM baselines. Ablation studies indicate that Predictive\nFactor Guidance Agents are most critical for enhancing predictive performance,\npo- sitioning Urban-MAS as a scalable paradigm for human-centered urban AI\nprediction. Code is available on the project\nwebsite:https://github.com/THETUREHOOHA/UrbanMAS", "AI": {"tldr": "Urban-MAS \u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\uff0c\u7528\u4e8e\u96f6\u6837\u672c\u4eba\u7c7b\u4e2d\u5fc3\u57ce\u5e02\u9884\u6d4b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u57ce\u5e02\u7cfb\u7edf\u7684\u5f02\u6784\u6570\u636e\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u4e00\u79cd\u7cfb\u7edf\u63d0\u5347\u5177\u4f53\u9886\u57df\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e09\u7c7b\u667a\u80fd\u4f53\uff08\u9884\u6d4b\u56e0\u5b50\u5f15\u5bfc\u3001\u4fe1\u606f\u63d0\u53d6\u548c\u591a\u6e90\u63a8\u7406\u667a\u80fd\u4f53\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u901a\u8fc7\u4f18\u5148\u5173\u952e\u56e0\u5b50\u3001\u9a8c\u8bc1\u4fe1\u606f\u4e00\u81f4\u6027\u53ca\u591a\u6e90\u878d\u5408\uff0c\u5b9e\u73b0\u51c6\u786e\u7684\u57ce\u5e02\u9884\u6d4b\u3002", "result": "\u5728\u4e1c\u4eac\u3001\u7c73\u5170\u3001\u897f\u96c5\u56fe\u7684\u8dd1\u52a8\u91cf\u9884\u6d4b\u548c\u57ce\u5e02\u611f\u77e5\u4efb\u52a1\u4e2d\uff0cUrban-MAS\u76f8\u8f83\u5355\u4e00LLM\u57fa\u7ebf\u663e\u8457\u964d\u4f4e\u9884\u6d4b\u8bef\u5dee\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u9884\u6d4b\u56e0\u5b50\u5f15\u5bfc\u667a\u80fd\u4f53\u4e3a\u63d0\u5347\u6027\u80fd\u7684\u5173\u952e\uff0cUrban-MAS\u4e3a\u4eba\u7c7b\u4e2d\u5fc3\u57ce\u5e02AI\u9884\u6d4b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2511.00115", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00115", "abs": "https://arxiv.org/abs/2511.00115", "authors": ["Haoyuan Li", "Yuanbo Tong", "Yuchen Li", "Zirui Wang", "Chunhou Liu", "Jiamou Liu"], "title": "Cognitive Alignment in Personality Reasoning: Leveraging Prototype Theory for MBTI Inference", "comment": null, "summary": "Personality recognition from text is typically cast as hard-label\nclassification, which obscures the graded, prototype-like nature of human\npersonality judgments. We present ProtoMBTI, a cognitively aligned framework\nfor MBTI inference that operationalizes prototype theory within an LLM-based\npipeline. First, we construct a balanced, quality-controlled corpus via\nLLM-guided multi-dimensional augmentation (semantic, linguistic, sentiment).\nNext, we LoRA-fine-tune a lightweight (<=2B) encoder to learn discriminative\nembeddings and to standardize a bank of personality prototypes. At inference,\nwe retrieve top-k prototypes for a query post and perform a\nretrieve--reuse--revise--retain cycle: the model aggregates prototype evidence\nvia prompt-based voting, revises when inconsistencies arise, and, upon correct\nprediction, retains the sample to continually enrich the prototype library.\nAcross Kaggle and Pandora benchmarks, ProtoMBTI improves over baselines on both\nthe four MBTI dichotomies and the full 16-type task, and exhibits robust\ncross-dataset generalization. Our results indicate that aligning the inference\nprocess with psychological prototype reasoning yields gains in accuracy,\ninterpretability, and transfer for text-based personality modeling.", "AI": {"tldr": "\u63d0\u51faProtoMBTI\uff0c\u4e00\u4e2a\u57fa\u4e8e\u539f\u578b\u7406\u8bba\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684MBTI\u4eba\u683c\u8bc6\u522b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7ef4\u8bed\u6599\u6269\u589e\u548cLoRA\u5fae\u8c03\u63d0\u5347\u5206\u7c7b\u51c6\u786e\u7387\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u7684\u4eba\u683c\u8bc6\u522b\u901a\u5e38\u91c7\u7528\u786c\u6807\u7b7e\u5206\u7c7b\uff0c\u5ffd\u89c6\u4e86\u4eba\u683c\u5224\u65ad\u7684\u539f\u578b\u6027\u8d28\uff1b\u4f5c\u8005\u5e0c\u671b\u901a\u8fc7\u539f\u578b\u7406\u8bba\u66f4\u597d\u5730\u6355\u6349\u4eba\u683c\u8ba4\u77e5\u7279\u5f81\u3002", "method": "\u6784\u5efa\u591a\u7ef4\u5ea6\u589e\u5f3a\u7684\u9ad8\u8d28\u91cf\u8bed\u6599\u5e93\uff0c\u5229\u7528LoRA\u5fae\u8c03\u8f7b\u91cf\u7f16\u7801\u5668\u5b66\u4e60\u5224\u522b\u6027\u5d4c\u5165\u548c\u4eba\u683c\u539f\u578b\u5e93\uff1b\u63a8\u7406\u65f6\u901a\u8fc7\u68c0\u7d22\u3001\u6295\u7968\u3001\u4fee\u6b63\u548c\u4fdd\u7559\u673a\u5236\uff0c\u5b9e\u73b0\u52a8\u6001\u539f\u578b\u5e93\u5b8c\u5584\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cProtoMBTI\u5728MBTI\u56db\u4e2a\u7ef4\u5ea6\u53ca16\u7c7b\u578b\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u4e14\u8868\u73b0\u51fa\u826f\u597d\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u5c06\u63a8\u7406\u8fc7\u7a0b\u4e0e\u5fc3\u7406\u5b66\u539f\u578b\u7406\u8bba\u5bf9\u9f50\uff0c\u80fd\u63d0\u5347\u6587\u672c\u4eba\u683c\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8fc1\u79fb\u80fd\u529b\u3002"}}
{"id": "2511.00202", "categories": ["cs.SE", "cs.LG", "cs.LO", "F.3.1; I.2.5"], "pdf": "https://arxiv.org/pdf/2511.00202", "abs": "https://arxiv.org/abs/2511.00202", "authors": ["Jacqueline Mitchell", "Yasser Shaaban"], "title": "Position: Vibe Coding Needs Vibe Reasoning: Improving Vibe Coding with Formal Verification", "comment": "7 pages, 3 figures, In Proceedings of the 1st ACM SIGPLAN\n  International Workshop on Language Models and Programming Languages\n  (LMPL'25), October 12-18, 2025, Singapore, Singapore. ACM, New York, NY, USA", "summary": "``Vibe coding'' -- the practice of developing software through iteratively\nconversing with a large language model (LLM) -- has exploded in popularity\nwithin the last year. However, developers report key limitations including the\naccumulation of technical debt, security issues, and code churn to achieve\nsatisfactory results. We argue that these pitfalls result from LLMs' inability\nto reconcile accumulating human-imposed constraints during vibe coding, with\ndevelopers inadvertently failing to resolve contradictions because LLMs\nprioritize user commands over code consistency. Given LLMs' receptiveness to\nverification-based feedback, we argue that formal methods can mitigate these\npitfalls, making vibe coding more reliable. However, we posit that integrating\nformal methods must transcend existing approaches that combine formal methods\nand LLMs. We advocate for a side-car system throughout the vibe coding process\nwhich: (1) \\emph{Autoformalizes} specifications (2) Validates against targets,\n(3) Delivers \\emph{actionable} feedback to the LLM, and (4) Allows intuitive\ndeveloper influence on specifications.", "AI": {"tldr": "Vibe\u7f16\u7801\u901a\u8fc7\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fed\u4ee3\u5bf9\u8bdd\u5f00\u53d1\u8f6f\u4ef6\uff0c\u4f46\u5b58\u5728\u6280\u672f\u8d1f\u503a\u3001\u5b89\u5168\u95ee\u9898\u548c\u4ee3\u7801\u9891\u7e41\u53d8\u52a8\u3002", "motivation": "\u652f\u6301\u5f00\u53d1\u8005\u514b\u670dvibe\u7f16\u7801\u4e2d\u56e0LLM\u65e0\u6cd5\u534f\u8c03\u7d2f\u79ef\u7ea6\u675f\u800c\u5f15\u53d1\u7684\u95ee\u9898\uff0c\u5982\u6280\u672f\u503a\u52a1\u548c\u5b89\u5168\u9690\u60a3\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u4fa7\u8f66\u7cfb\u7edf\u81ea\u52a8\u5f62\u5f0f\u5316\u89c4\u8303\uff0c\u9a8c\u8bc1\u76ee\u6807\uff0c\u63d0\u4f9b\u53ef\u64cd\u4f5c\u53cd\u9988\uff0c\u5e76\u5141\u8bb8\u5f00\u53d1\u8005\u76f4\u89c2\u5f71\u54cd\u89c4\u8303\u3002", "result": "\u8be5\u65b9\u6cd5\u53ef\u63d0\u5347vibe\u7f16\u7801\u7684\u53ef\u9760\u6027\uff0c\u51cf\u5c11\u4ee3\u7801\u4e0d\u4e00\u81f4\u548c\u5b89\u5168\u95ee\u9898\u3002", "conclusion": "\u5c06\u5f62\u5f0f\u5316\u65b9\u6cd5\u4e0eLLM\u96c6\u6210\uff0c\u901a\u8fc7\u4fa7\u8f66\u7cfb\u7edf\u8f85\u52a9vibe\u7f16\u7801\uff0c\u53ef\u6709\u6548\u7f13\u89e3\u5173\u952e\u7f3a\u9677\uff0c\u4f7f\u5f00\u53d1\u8fc7\u7a0b\u66f4\u5065\u58ee\u3002"}}
{"id": "2511.00330", "categories": ["cs.MA", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00330", "abs": "https://arxiv.org/abs/2511.00330", "authors": ["Yeonju Ro", "Haoran Qiu", "\u00cd\u00f1igo Goiri", "Rodrigo Fonseca", "Ricardo Bianchini", "Aditya Akella", "Zhangyang Wang", "Mattan Erez", "Esha Choukse"], "title": "Sherlock: Reliable and Efficient Agentic Workflow Execution", "comment": null, "summary": "With the increasing adoption of large language models (LLM), agentic\nworkflows, which compose multiple LLM calls with tools, retrieval, and\nreasoning steps, are increasingly replacing traditional applications. However,\nsuch workflows are inherently error-prone: incorrect or partially correct\noutput at one step can propagate or even amplify through subsequent stages,\ncompounding the impact on the final output. Recent work proposes integrating\nverifiers that validate LLM output or actions, such as self-reflection, debate,\nor LLM-as-a-judge mechanisms. Yet, verifying every step introduces significant\nlatency and cost overheads.\n  In this work, we seek to answer three key questions: which nodes in a\nworkflow are most error-prone and thus deserve costly verification, how to\nselect the most appropriate verifier for each node, and how to use verification\nwith minimal impact to latency? Our solution, Sherlock, addresses these using\ncounterfactual analysis on agentic workflows to identify error-prone nodes and\nselectively attaching cost-optimal verifiers only where necessary. At runtime,\nSherlock speculatively executes downstream tasks to reduce latency overhead,\nwhile verification runs in the background. If verification fails, execution is\nrolled back to the last verified output. Compared to the non-verifying\nbaseline, Sherlock delivers an 18.3% accuracy gain on average across\nbenchmarks. Sherlock reduces workflow execution time by up to 48.7% over\nnon-speculative execution and lowers verification cost by 26.0% compared to the\nMonte Carlo search-based method, demonstrating that principled, fault-aware\nverification effectively balances efficiency and reliability in agentic\nworkflows.", "AI": {"tldr": "\u63d0\u51faSherlock\u65b9\u6cd5\u901a\u8fc7\u53cd\u4e8b\u5b9e\u5206\u6790\u9009\u62e9\u6027\u9a8c\u8bc1\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u4e2d\u7684\u9519\u8bef\u6613\u53d1\u8282\u70b9\uff0c\u5b9e\u73b0\u51c6\u786e\u7387\u63d0\u5347\u548c\u6210\u672c\u51cf\u5c11\u3002", "motivation": "\u591a\u6b65\u9aa4\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u9519\u8bef\u6613\u4f20\u64ad\uff0c\u5168\u9762\u9a8c\u8bc1\u4ee3\u4ef7\u9ad8\uff0c\u9700\u8981\u627e\u5230\u9ad8\u98ce\u9669\u8282\u70b9\u8fdb\u884c\u9009\u62e9\u6027\u9a8c\u8bc1\u4ee5\u5e73\u8861\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "Sherlock\u5229\u7528\u53cd\u4e8b\u5b9e\u5206\u6790\u8bc6\u522b\u9ad8\u98ce\u9669\u8282\u70b9\uff0c\u9009\u62e9\u6700\u5408\u9002\u7684\u9a8c\u8bc1\u5668\uff0c\u63a8\u6d4b\u6267\u884c\u4e0b\u6e38\u4efb\u52a1\u4ee5\u964d\u4f4e\u5ef6\u8fdf\uff0c\u9a8c\u8bc1\u5931\u8d25\u65f6\u56de\u6eda\u6267\u884c\u3002", "result": "Sherlock\u4f7f\u51c6\u786e\u7387\u5e73\u5747\u63d0\u534718.3%\uff0c\u6267\u884c\u65f6\u95f4\u6bd4\u975e\u63a8\u6d4b\u6267\u884c\u5feb48.7%\uff0c\u9a8c\u8bc1\u6210\u672c\u8f83Monte Carlo\u65b9\u6cd5\u964d\u4f4e26.0%\u3002", "conclusion": "\u57fa\u4e8e\u53cd\u4e8b\u5b9e\u7684\u9009\u62e9\u6027\u9a8c\u8bc1\u7b56\u7565\u80fd\u6709\u6548\u63d0\u5347\u590d\u6742\u5927\u8bed\u8a00\u6a21\u578b\u5de5\u4f5c\u6d41\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u517c\u987e\u53ef\u9760\u6027\u548c\u6210\u672c\u3002"}}
{"id": "2511.00180", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00180", "abs": "https://arxiv.org/abs/2511.00180", "authors": ["Nicky Pochinkov", "Yulia Volkova", "Anna Vasileva", "Sai V R Chereddy"], "title": "ParaScopes: What do Language Models Activations Encode About Future Text?", "comment": "Main paper: 9 pages, 10 figures. Total 24 pages", "summary": "Interpretability studies in language models often investigate forward-looking\nrepresentations of activations. However, as language models become capable of\ndoing ever longer time horizon tasks, methods for understanding activations\noften remain limited to testing specific concepts or tokens. We develop a\nframework of Residual Stream Decoders as a method of probing model activations\nfor paragraph-scale and document-scale plans. We test several methods and find\ninformation can be decoded equivalent to 5+ tokens of future context in small\nmodels. These results lay the groundwork for better monitoring of language\nmodels and better understanding how they might encode longer-term planning\ninformation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6b8b\u5dee\u6d41\u89e3\u7801\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u63a2\u6d4b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6fc0\u6d3b\u4fe1\u606f\uff0c\u7279\u522b\u662f\u6bb5\u843d\u548c\u6587\u6863\u7ea7\u522b\u7684\u957f\u8fdc\u89c4\u5212\u4fe1\u606f\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5904\u7406\u66f4\u957f\u65f6\u95f4\u8de8\u5ea6\u7684\u4efb\u52a1\uff0c\u73b0\u6709\u7684\u6fc0\u6d3b\u7406\u89e3\u65b9\u6cd5\u4ecd\u5c40\u9650\u4e8e\u7279\u5b9a\u6982\u5ff5\u6216\u8bcd\u6c47\uff0c\u96be\u4ee5\u89e3\u6790\u66f4\u957f\u8fdc\u7684\u89c4\u5212\u4fe1\u606f\u3002", "method": "\u5f00\u53d1\u6b8b\u5dee\u6d41\u89e3\u7801\u5668\u6846\u67b6\uff0c\u6d4b\u8bd5\u4e0d\u540c\u65b9\u6cd5\u6765\u89e3\u7801\u6fc0\u6d3b\u4e2d\u7684\u6f5c\u5728\u4fe1\u606f\uff0c\u5c24\u5176\u662f\u9488\u5bf9\u6bb5\u843d\u548c\u6587\u6863\u5c3a\u5ea6\u7684\u957f\u8fdc\u8ba1\u5212\u3002", "result": "\u53d1\u73b0\u53ef\u4ee5\u4ece\u5c0f\u89c4\u6a21\u6a21\u578b\u7684\u6fc0\u6d3b\u4e2d\u89e3\u7801\u51fa\u76f8\u5f53\u4e8e5\u4e2a\u4ee5\u4e0a\u672a\u6765\u8bcd\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u66f4\u597d\u5730\u76d1\u63a7\u8bed\u8a00\u6a21\u578b\u548c\u7406\u89e3\u5176\u5982\u4f55\u7f16\u7801\u957f\u8fdc\u89c4\u5212\u4fe1\u606f\u63d0\u4f9b\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00215", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00215", "abs": "https://arxiv.org/abs/2511.00215", "authors": ["Xiaomeng Xu", "Zahin Wahab", "Reid Holmes", "Caroline Lemieux"], "title": "DocPrism: Local Categorization and External Filtering to Identify Relevant Code-Documentation Inconsistencies", "comment": null, "summary": "Code-documentation inconsistencies are common and undesirable: they can lead\nto developer misunderstandings and software defects. This paper introduces\nDocPrism, a multi-language, code-documentation inconsistency detection tool.\nDocPrism uses a standard large language model (LLM) to analyze and explain\ninconsistencies. Plain use of LLMs for this task yield unacceptably high false\npositive rates: LLMs identify natural gaps between high-level documentation and\ndetailed code implementations as inconsistencies. We introduce and apply the\nLocal Categorization, External Filtering (LCEF) methodology to reduce false\npositives. LCEF relies on the LLM's local completion skills rather than its\nlong-term reasoning skills. In our ablation study, LCEF reduces DocPrism's\ninconsistency flag rate from 98% to 14%, and increases accuracy from 14% to\n94%. On a broad evaluation across Python, TypeScript, C++, and Java, DocPrism\nmaintains a low flag rate of 15%, and achieves a precision of 0.62 without\nperforming any fine-tuning.", "AI": {"tldr": "DocPrism\u662f\u4e00\u79cd\u591a\u8bed\u8a00\u4ee3\u7801-\u6587\u6863\u4e0d\u4e00\u81f4\u68c0\u6d4b\u5de5\u5177\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5206\u6790\u548c\u89e3\u91ca\u4e0d\u4e00\u81f4\uff0c\u4f46\u907f\u514d\u4e86\u9ad8\u8bef\u62a5\u7387\uff0c\u901a\u8fc7\u5f15\u5165LCEF\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\u3002", "motivation": "\u4ee3\u7801\u4e0e\u6587\u6863\u4e4b\u95f4\u7684\u4e0d\u4e00\u81f4\u4f1a\u5bfc\u81f4\u5f00\u53d1\u8bef\u89e3\u548c\u8f6f\u4ef6\u7f3a\u9677\uff0c\u73b0\u6709\u65b9\u6cd5\u8bef\u62a5\u7387\u9ad8\uff0c\u4e9f\u9700\u6709\u6548\u964d\u4f4e\u8bef\u62a5\u7684\u68c0\u6d4b\u5de5\u5177\u3002", "method": "\u63d0\u51faLocal Categorization, External Filtering\uff08LCEF\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c40\u90e8\u5b8c\u6210\u80fd\u529b\uff0c\u51cf\u5c11\u5bf9\u957f\u671f\u63a8\u7406\u7684\u4f9d\u8d56\uff0c\u4ece\u800c\u964d\u4f4e\u8bef\u62a5\u7387\u3002", "result": "LCEF\u5c06DocPrism\u7684\u4e0d\u4e00\u81f4\u6807\u8bb0\u7387\u4ece98%\u964d\u4f4e\u523014%\uff0c\u51c6\u786e\u7387\u4ece14%\u63d0\u5347\u523094%\uff1b\u5728Python\u3001TypeScript\u3001C++\u548cJava\u4e0a\u7684\u6d4b\u8bd5\u663e\u793a\uff0c\u6807\u8bb0\u7387\u7ef4\u6301\u572815%\uff0c\u7cbe\u51c6\u7387\u8fbe0.62\uff0c\u65e0\u9700\u989d\u5916\u5fae\u8c03\u3002", "conclusion": "DocPrism\u7ed3\u5408LCEF\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u591a\u8bed\u8a00\u4ee3\u7801\u4e0e\u6587\u6863\u4e0d\u4e00\u81f4\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bef\u62a5\u7387\u3002"}}
{"id": "2511.00387", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.00387", "abs": "https://arxiv.org/abs/2511.00387", "authors": ["Xiaoling Han", "Bin Lin", "Zhenyu Na", "Bowen Li", "Chaoyue Zhang", "Ran Zhang"], "title": "Spatial Crowdsourcing-based Task Allocation for UAV-assisted Maritime Data Collection", "comment": null, "summary": "Driven by the unceasing development of maritime services, tasks of unmanned\naerial vehicle (UAV)-assisted maritime data collection (MDC) are becoming\nincreasingly diverse, complex and personalized. As a result, effective task\nallocation for MDC is becoming increasingly critical. In this work, integrating\nthe concept of spatial crowdsourcing (SC), we develop an SC-based MDC network\nmodel and investigate the task allocation problem for UAV-assisted MDC. In\nvariable maritime service scenarios, tasks are allocated to UAVs based on the\nspatial and temporal requirements of the tasks, as well as the mobility of the\nUAVs. To address this problem, we design an SC-based task allocation algorithm\nfor the MDC (SC-MDC-TA). The quality estimation is utilized to assess and\nregulate task execution quality by evaluating signal to interference plus noise\nratio and the UAV energy consumption. The reverse auction is employed to\npotentially reduce the task waiting time as much as possible while ensuring\ntimely completion. Additionally, we establish typical task allocation scenarios\nbased on maritime service requirements indicated by electronic navigational\ncharts. Simulation results demonstrate that the proposed SC-MDC-TA algorithm\neffectively allocates tasks for various MDC scenarios. Furthermore, compared to\nthe benchmark, the SC-MDC-TA algorithm can also reduce the task completion time\nand lower the UAV energy consumption.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u7a7a\u95f4\u4f17\u5305\u7684\u65e0\u4eba\u673a\u8f85\u52a9\u6d77\u6d0b\u6570\u636e\u91c7\u96c6\u4efb\u52a1\u5206\u914d\u7b97\u6cd5\uff0c\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u6548\u7387\u548c\u8282\u80fd\u6548\u679c\u3002", "motivation": "\u968f\u7740\u6d77\u6d0b\u670d\u52a1\u7684\u53d1\u5c55\uff0c\u65e0\u4eba\u673a\u8f85\u52a9\u7684\u6d77\u6d0b\u6570\u636e\u91c7\u96c6\u4efb\u52a1\u65e5\u76ca\u590d\u6742\u548c\u4e2a\u6027\u5316\uff0c\u4e9f\u9700\u6709\u6548\u7684\u4efb\u52a1\u5206\u914d\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u7a7a\u95f4\u4f17\u5305\u7406\u5ff5\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u8d28\u91cf\u4f30\u8ba1\u548c\u9006\u5411\u62cd\u5356\u673a\u5236\u7684\u4efb\u52a1\u5206\u914d\u7b97\u6cd5\uff08SC-MDC-TA\uff09\uff0c\u6839\u636e\u4efb\u52a1\u65f6\u7a7a\u9700\u6c42\u548c\u65e0\u4eba\u673a\u79fb\u52a8\u6027\u8fdb\u884c\u4f18\u5316\u5206\u914d\u3002", "result": "\u4eff\u771f\u8868\u660e\uff0cSC-MDC-TA\u7b97\u6cd5\u5728\u591a\u573a\u666f\u4e0b\u80fd\u591f\u6709\u6548\u5206\u914d\u4efb\u52a1\uff0c\u51cf\u5c11\u4efb\u52a1\u5b8c\u6210\u65f6\u95f4\u5e76\u964d\u4f4e\u65e0\u4eba\u673a\u80fd\u8017\u3002", "conclusion": "\u6240\u63d0\u7b97\u6cd5\u80fd\u591f\u6ee1\u8db3\u591a\u53d8\u6d77\u6d0b\u670d\u52a1\u573a\u666f\u7684\u4efb\u52a1\u5206\u914d\u9700\u6c42\uff0c\u63d0\u5347\u65e0\u4eba\u673a\u4efb\u52a1\u6267\u884c\u6548\u7387\u4e0e\u80fd\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2511.00198", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00198", "abs": "https://arxiv.org/abs/2511.00198", "authors": ["Chun-Hao Yang", "Bo-Han Feng", "Tzu-Yuan Lai", "Yan Yu Chen", "Yin-Kai Dean Huang", "Shou-De Lin"], "title": "Training LLMs Beyond Next Token Prediction - Filling the Mutual Information Gap", "comment": null, "summary": "Optimizing training performance in large language models (LLMs) remains an\nessential challenge, particularly in improving model performance while\nmaintaining computational costs. This work challenges the conventional approach\nof training LLMs using next-token prediction (NTP), arguing that by predicting\ninformation-rich tokens during training, there is a more effective way to train\nLLMs. We investigate the impact of the proposed solution in three kinds of\ntasks for LLMs: arithmetic, multi-label classification of text, and\nnatural-language generation. This work offers a principled approach to\noptimizing LLM training, advancing both model performance and theoretical\nunderstanding of the target-token selection strategies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9884\u6d4b\u4fe1\u606f\u4e30\u5bcc\u7684\u76ee\u6807\u8bcd\uff0c\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6027\u80fd\uff0c\u8d85\u8d8a\u4f20\u7edf\u7684\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u591a\u91c7\u7528\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\u65b9\u6cd5\uff0c\u53ef\u80fd\u672a\u5145\u5206\u5229\u7528\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u76ee\u6807\u8bcd\u7684\u4fe1\u606f\u91cf\uff0c\u9650\u5236\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9884\u6d4b\u4fe1\u606f\u4e30\u5bcc\u76ee\u6807\u8bcd\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u5728\u7b97\u672f\u3001\u591a\u6807\u7b7e\u6587\u672c\u5206\u7c7b\u53ca\u81ea\u7136\u8bed\u8a00\u751f\u6210\u4e09\u79cd\u4efb\u52a1\u4e2d\u8bc4\u4f30\u5176\u6548\u679c\u3002", "result": "\u65b0\u7b56\u7565\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u4e0d\u540c\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f53\u73b0\u51fa\u66f4\u6709\u6548\u7684\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u9009\u62e9\u4fe1\u606f\u4e30\u5bcc\u7684\u76ee\u6807\u8bcd\u8fdb\u884c\u8bad\u7ec3\uff0c\u6709\u671b\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u63d0\u5347\u6027\u80fd\u5e76\u6df1\u5316\u5bf9\u76ee\u6807\u8bcd\u9009\u62e9\u7b56\u7565\u7684\u7406\u8bba\u7406\u89e3\u3002"}}
{"id": "2511.00262", "categories": ["cs.SE", "D.2; I.2"], "pdf": "https://arxiv.org/pdf/2511.00262", "abs": "https://arxiv.org/abs/2511.00262", "authors": ["Romina Etezadi", "Sallam Abualhaija", "Chetan Arora", "Lionel Briand"], "title": "LLM-Driven Cost-Effective Requirements Change Impact Analysis", "comment": "28 pages, 6 figures", "summary": "Requirements are inherently subject to changes throughout the software\ndevelopment lifecycle. Within the limited budget available to requirements\nengineers, manually identifying the impact of such changes on other\nrequirements is both error-prone and effort-intensive. That might lead to\noverlooked impacted requirements, which, if not properly managed, can cause\nserious issues in the downstream tasks. Inspired by the growing potential of\nlarge language models (LLMs) across diverse domains, we propose ProReFiCIA, an\nLLM-driven approach for automatically identifying the impacted requirements\nwhen changes occur. We conduct an extensive evaluation of ProReFiCIA using\nseveral LLMs and prompts variants tailored to this task. Using the best\ncombination of an LLM and a prompt variant, ProReFiCIA achieves a recall of\n93.3% on a benchmark dataset and 95.8% on a newly created industry dataset,\ndemonstrating its strong effectiveness in identifying impacted requirements.\nFurther, the cost of applying ProReFiCIA remains small, as the engineer only\nneeds to review the generated results, which represent between 2.1% and 8.5% of\nthe entire set of requirements.", "AI": {"tldr": "\u63d0\u51fa\u4e86ProReFiCIA\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u8bc6\u522b\u9700\u6c42\u53d8\u66f4\u5f71\u54cd\u7684\u5de5\u5177\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u51c6\u786e\u7387\u5e76\u51cf\u5c11\u4e86\u4eba\u5de5\u5ba1\u67e5\u5de5\u4f5c\u91cf\u3002", "motivation": "\u9700\u6c42\u5728\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u9891\u7e41\u53d8\u66f4\uff0c\u624b\u52a8\u8bc6\u522b\u53d8\u66f4\u5f71\u54cd\u65e2\u8017\u65f6\u53c8\u6613\u51fa\u9519\uff0c\u53ef\u80fd\u5bfc\u81f4\u91cd\u8981\u9700\u6c42\u88ab\u5ffd\u89c6\uff0c\u5f15\u53d1\u540e\u7eed\u4efb\u52a1\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5f00\u53d1ProReFiCIA\uff0c\u901a\u8fc7\u591a\u79cd\u6a21\u578b\u548c\u63d0\u793a\u8bcd\u7ec4\u5408\u8fdb\u884c\u8bc4\u4f30\uff0c\u81ea\u52a8\u8bc6\u522b\u88ab\u53d8\u66f4\u9700\u6c42\u5f71\u54cd\u7684\u5176\u4ed6\u9700\u6c42\u3002", "result": "\u6700\u4f73\u6a21\u578b\u548c\u63d0\u793a\u7ec4\u5408\u5728\u57fa\u51c6\u6570\u636e\u96c6\u8fbe\u5230\u4e8693.3%\u7684\u53ec\u56de\u7387\uff0c\u5728\u5de5\u4e1a\u6570\u636e\u96c6\u4e0a\u8fbe\u523095.8%\uff0c\u663e\u8457\u63d0\u9ad8\u8bc6\u522b\u6548\u679c\uff0c\u4e14\u4ec5\u9700\u5ba1\u67e5\u751f\u6210\u7ed3\u679c\u76842.1%-8.5%\u3002", "conclusion": "ProReFiCIA\u6709\u6548\u5229\u7528LLM\u81ea\u52a8\u8bc6\u522b\u9700\u6c42\u53d8\u66f4\u5f71\u54cd\uff0c\u5927\u5e45\u63d0\u9ad8\u51c6\u786e\u7387\u5e76\u964d\u4f4e\u5de5\u7a0b\u5e08\u5de5\u4f5c\u91cf\uff0c\u5177\u5907\u826f\u597d\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00628", "categories": ["cs.MA", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00628", "abs": "https://arxiv.org/abs/2511.00628", "authors": ["Yang Li", "Siqi Ping", "Xiyu Chen", "Xiaojian Qi", "Zigan Wang", "Ye Luo", "Xiaowei Zhang"], "title": "AgentGit: A Version Control Framework for Reliable and Scalable LLM-Powered Multi-Agent Systems", "comment": null, "summary": "With the rapid progress of large language models (LLMs), LLM-powered\nmulti-agent systems (MAS) are drawing increasing interest across academia and\nindustry. However, many current MAS frameworks struggle with reliability and\nscalability, especially on complex tasks. We present AgentGit, a framework that\nbrings Git-like rollback and branching to MAS workflows. Built as an\ninfrastructure layer on top of LangGraph, AgentGit supports state commit,\nrevert, and branching, allowing agents to traverse, compare, and explore\nmultiple trajectories efficiently. To evaluate AgentGit, we designed an\nexperiment that optimizes target agents by selecting better prompts. We ran a\nmulti-step A/B test against three baselines -- LangGraph, AutoGen, and Agno --\non a real-world task: retrieving and analyzing paper abstracts. Results show\nthat AgentGit significantly reduces redundant computation, lowers runtime and\ntoken usage, and supports parallel exploration across multiple branches,\nenhancing both reliability and scalability in MAS development. This work offers\na practical path to more robust MAS design and enables error recovery, safe\nexploration, iterative debugging, and A/B testing in collaborative AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86AgentGit\u6846\u67b6\uff0c\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u5f15\u5165\u4e86\u7c7b\u4f3cGit\u7684\u56de\u6eda\u548c\u5206\u652f\u673a\u5236\uff0c\u63d0\u5347\u4e86\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u9762\u4e34\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u57fa\u4e8eLangGraph\u6784\u5efaAgentGit\uff0c\u652f\u6301\u72b6\u6001\u63d0\u4ea4\u3001\u56de\u6eda\u548c\u5206\u652f\uff0c\u4f7f\u667a\u80fd\u4f53\u80fd\u9ad8\u6548\u904d\u5386\u3001\u6bd4\u8f83\u548c\u63a2\u7d22\u591a\u6761\u8f68\u8ff9\u3002", "result": "\u4e0eLangGraph\u3001AutoGen\u548cAgno\u4e09\u5927\u57fa\u7ebf\u6bd4\u8f83\uff0cAgentGit\u663e\u8457\u51cf\u5c11\u4e86\u5197\u4f59\u8ba1\u7b97\uff0c\u964d\u4f4e\u4e86\u8fd0\u884c\u65f6\u95f4\u548c\u4ee4\u724c\u4f7f\u7528\uff0c\u652f\u6301\u591a\u5206\u652f\u5e76\u884c\u63a2\u7d22\u3002", "conclusion": "AgentGit\u6539\u5584\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5f00\u53d1\u7684\u53ef\u9760\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u652f\u6301\u9519\u8bef\u6062\u590d\u3001\u5b89\u5168\u63a2\u7d22\u3001\u8fed\u4ee3\u8c03\u8bd5\u548cA/B\u6d4b\u8bd5\uff0c\u63a8\u52a8\u4e86\u534f\u4f5c\u5f0fAI\u7cfb\u7edf\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2511.00222", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00222", "abs": "https://arxiv.org/abs/2511.00222", "authors": ["Marwa Abdulhai", "Ryan Cheng", "Donovan Clay", "Tim Althoff", "Sergey Levine", "Natasha Jaques"], "title": "Consistently Simulating Human Personas with Multi-Turn Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) are increasingly used to simulate human users in\ninteractive settings such as therapy, education, and social role-play. While\nthese simulations enable scalable training and evaluation of AI agents,\noff-the-shelf LLMs often drift from their assigned personas, contradict earlier\nstatements, or abandon role-appropriate behavior. We introduce a unified\nframework for evaluating and improving persona consistency in LLM-generated\ndialogue. We define three automatic metrics: prompt-to-line consistency,\nline-to-line consistency, and Q&A consistency, that capture different types of\npersona drift and validate each against human annotations. Using these metrics\nas reward signals, we apply multi-turn reinforcement learning to fine-tune LLMs\nfor three user roles: a patient, a student, and a social chat partner. Our\nmethod reduces inconsistency by over 55%, resulting in more coherent and\nfaithful simulated users.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u52a8\u6307\u6807\u8bc4\u4f30\u5e76\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u6a21\u62df\u89d2\u8272\u5bf9\u8bdd\u4e2d\u7684\u4eba\u683c\u4e00\u81f4\u6027\uff0c\u91c7\u7528\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u6a21\u578b\uff0c\u63d0\u9ad8\u89d2\u8272\u626e\u6f14\u7684\u8fde\u8d2f\u6027\u548c\u5fe0\u5b9e\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684LLM\u5728\u6a21\u62df\u4eba\u7c7b\u89d2\u8272\u65f6\u5e38\u5e38\u51fa\u73b0\u4eba\u683c\u504f\u79bb\u3001\u524d\u540e\u77db\u76fe\u548c\u5931\u53bb\u89d2\u8272\u884c\u4e3a\u7684\u95ee\u9898\uff0c\u5f71\u54cd\u4ea4\u4e92\u4f53\u9a8c\u7684\u771f\u5b9e\u6027\u548c\u6709\u6548\u6027\u3002", "method": "\u5b9a\u4e49\u4e09\u79cd\u81ea\u52a8\u5316\u4e00\u81f4\u6027\u6307\u6807\uff08\u63d0\u793a\u4e0e\u56de\u590d\u4e00\u81f4\u6027\u3001\u56de\u590d\u95f4\u4e00\u81f4\u6027\u3001\u95ee\u7b54\u4e00\u81f4\u6027\uff09\uff0c\u5229\u7528\u8fd9\u4e9b\u6307\u6807\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u901a\u8fc7\u591a\u8f6e\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03LLM\uff0c\u4f7f\u5176\u5728\u4e0d\u540c\u89d2\u8272\uff08\u60a3\u8005\u3001\u5b66\u751f\u3001\u793e\u4ea4\u4f19\u4f34\uff09\u4e2d\u4fdd\u6301\u4eba\u683c\u8fde\u8d2f\u3002", "result": "\u65b9\u6cd5\u663e\u8457\u51cf\u5c11\u4e86\u8d85\u8fc755%\u7684\u4eba\u683c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4f7f\u4eff\u771f\u7528\u6237\u8868\u73b0\u5f97\u66f4\u8fde\u8d2f\u548c\u5fe0\u5b9e\u4e8e\u6240\u626e\u6f14\u89d2\u8272\u3002", "conclusion": "\u5f15\u5165\u7684\u6307\u6807\u548c\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86LLM\u7684\u89d2\u8272\u4eba\u683c\u4e00\u81f4\u6027\uff0c\u6709\u52a9\u4e8e\u66f4\u771f\u5b9e\u53ef\u9760\u7684\u4eba\u673a\u4ea4\u4e92\u6a21\u62df\uff0c\u4fc3\u8fdb\u57fa\u4e8eLLM\u7684\u4e92\u52a8\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2511.00417", "categories": ["cs.SE", "cs.AI", "cs.HC", "H.5.3; D.2.9; I.2.0"], "pdf": "https://arxiv.org/pdf/2511.00417", "abs": "https://arxiv.org/abs/2511.00417", "authors": ["Marcel Valovy"], "title": "Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework", "comment": "PhD Dissertation, Prague University of Economics and Business, 2025.\n  323 pages. ACM CCS 2012: Human-computer interaction, Collaborative\n  interaction, Human-AI collaborative systems, Pair programming, AI-assisted\n  software engineering", "summary": "As artificial intelligence transforms software development, a critical\nquestion emerges: how can developers and AI systems collaborate most\neffectively? This dissertation optimizes human-AI programming roles through\nself-determination theory and personality psychology, introducing the Role\nOptimization Motivation Alignment (ROMA) framework.\n  Through Design Science Research spanning five cycles, this work establishes\nempirically-validated connections between personality traits, programming role\npreferences, and collaborative outcomes, engaging 200 experimental participants\nand 46 interview respondents.\n  Key findings demonstrate that personality-driven role optimization\nsignificantly enhances self-determination and team dynamics, yielding 23%\naverage motivation increases among professionals and up to 65% among\nundergraduates. Five distinct personality archetypes emerge: The Explorer (high\nOpenness/low Agreeableness), The Orchestrator (high\nExtraversion/Agreeableness), The Craftsperson (high Neuroticism/low\nExtraversion), The Architect (high Conscientiousness), and The Adapter\n(balanced profile). Each exhibits distinct preferences for programming roles\n(Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for\nsatisfaction.\n  The dissertation contributes: (1) an empirically-validated framework linking\npersonality traits to role preferences and self-determination outcomes; (2) a\ntaxonomy of AI collaboration modalities mapped to personality profiles while\npreserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small\nEntities to implement personality-driven role optimization within established\nstandards.\n  Keywords: artificial intelligence, human-computer interaction, behavioral\nsoftware engineering, self-determination theory, personality psychology,\nphenomenology, intrinsic motivation, pair programming, design science research,\nISO/IEC 29110", "AI": {"tldr": "\u672c\u8bba\u6587\u57fa\u4e8e\u81ea\u6211\u51b3\u5b9a\u7406\u8bba\u548c\u4e2a\u6027\u5fc3\u7406\u5b66\uff0c\u63d0\u51faROMA\u6846\u67b6\u4ee5\u4f18\u5316\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u7f16\u7a0b\u89d2\u8272\u5206\u914d\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u52a8\u529b\u548c\u56e2\u961f\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6539\u53d8\u8f6f\u4ef6\u5f00\u53d1\uff0c\u5982\u4f55\u5b9e\u73b0\u5f00\u53d1\u8005\u4e0eAI\u7cfb\u7edf\u7684\u9ad8\u6548\u534f\u4f5c\u6210\u4e3a\u5173\u952e\u95ee\u9898\uff0c\u9700\u57fa\u4e8e\u4e2a\u6027\u7279\u5f81\u4f18\u5316\u89d2\u8272\u5206\u914d\u4ee5\u63d0\u5347\u52a8\u529b\u548c\u6ee1\u610f\u5ea6\u3002", "method": "\u901a\u8fc7\u4e94\u4e2a\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u5faa\u73af\uff0c\u7ed3\u5408200\u540d\u5b9e\u9a8c\u53c2\u4e0e\u8005\u548c46\u540d\u8bbf\u8c08\u5bf9\u8c61\uff0c\u5b9e\u8bc1\u9a8c\u8bc1\u4e2a\u6027\u7279\u8d28\u3001\u7f16\u7a0b\u89d2\u8272\u504f\u597d\u4e0e\u534f\u4f5c\u7ed3\u679c\u95f4\u7684\u5173\u7cfb\uff0c\u5b9a\u4e49\u4e94\u79cd\u4e2a\u6027\u539f\u578b\u53ca\u5bf9\u5e94\u89d2\u8272\u3002", "result": "\u4e2a\u6027\u9a71\u52a8\u7684\u89d2\u8272\u4f18\u5316\u663e\u8457\u63d0\u5347\u81ea\u6211\u51b3\u5b9a\u611f\u548c\u56e2\u961f\u52a8\u529b\uff0c\u4e13\u4e1a\u4eba\u58eb\u52a8\u529b\u63d0\u534723%\uff0c\u672c\u79d1\u751f\u6700\u9ad8\u63d0\u534765%\uff1b\u63d0\u51fa\u4e94\u79cd\u4e2a\u6027\u539f\u578b\u4e0e\u5bf9\u5e94\u7684\u4e09\u79cd\u7f16\u7a0b\u89d2\u8272\u504f\u597d\u53ca\u5173\u952e\u7684\u89d2\u8272\u5206\u914d\u6a21\u5f0f\u3002", "conclusion": "\u8bba\u6587\u8d21\u732e\u5305\u62ec\u5efa\u7acb\u4e2a\u6027\u7279\u8d28\u4e0e\u89d2\u8272\u504f\u597d\u53ca\u52a8\u529b\u7ed3\u679c\u7684\u5b9e\u8bc1\u6846\u67b6\uff0c\u4e2a\u6027\u5316AI\u534f\u4f5c\u6a21\u5f0f\u7684\u5206\u7c7b\uff0c\u4ee5\u53ca\u57fa\u4e8eISO/IEC 29110\u6807\u51c6\u652f\u6301\u5c0f\u578b\u7ec4\u7ec7\u5b9e\u65bd\u4e2a\u6027\u5316\u89d2\u8272\u4f18\u5316\u7684\u65b9\u6cd5\u3002"}}
{"id": "2511.01078", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01078", "abs": "https://arxiv.org/abs/2511.01078", "authors": ["Qinwei Huang", "Stefan Wang", "Simon Khan", "Garrett Katz", "Qinru Qiu"], "title": "Predictive Auxiliary Learning for Belief-based Multi-Agent Systems", "comment": null, "summary": "The performance of multi-agent reinforcement learning (MARL) in partially\nobservable environments depends on effectively aggregating information from\nobservations, communications, and reward signals. While most existing\nmulti-agent systems primarily rely on rewards as the only feedback for policy\ntraining, our research shows that introducing auxiliary predictive tasks can\nsignificantly enhance learning efficiency and stability. We propose\nBelief-based Predictive Auxiliary Learning (BEPAL), a framework that\nincorporates auxiliary training objectives to support policy optimization.\nBEPAL follows the centralized training with decentralized execution paradigm.\nEach agent learns a belief model that predicts unobservable state information,\nsuch as other agents' rewards or motion directions, alongside its policy model.\nBy enriching hidden state representations with information that does not\ndirectly contribute to immediate reward maximization, this auxiliary learning\nprocess stabilizes MARL training and improves overall performance. We evaluate\nBEPAL in the predator-prey environment and Google Research Football, where it\nachieves an average improvement of about 16 percent in performance metrics and\ndemonstrates more stable convergence compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u5ff5\u7684\u9884\u6d4b\u8f85\u52a9\u5b66\u4e60\uff08BEPAL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e3b\u8981\u4f9d\u8d56\u5956\u52b1\u4fe1\u53f7\u8fdb\u884c\u7b56\u7565\u8bad\u7ec3\uff0c\u6548\u679c\u53d7\u9650\u4e14\u8bad\u7ec3\u8fc7\u7a0b\u4e0d\u591f\u7a33\u5b9a\u3002\u5f15\u5165\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\u6709\u671b\u6539\u5584\u8bad\u7ec3\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "BEPAL\u6846\u67b6\u5728\u96c6\u4e2d\u8bad\u7ec3\u3001\u5206\u6563\u6267\u884c\u7684\u8303\u5f0f\u4e0b\uff0c\u6bcf\u4e2a\u667a\u80fd\u4f53\u5b66\u4e60\u4e00\u4e2a\u4fe1\u5ff5\u6a21\u578b\uff0c\u7528\u4ee5\u9884\u6d4b\u65e0\u6cd5\u89c2\u6d4b\u7684\u72b6\u6001\u4fe1\u606f\uff08\u5982\u5176\u4ed6\u667a\u80fd\u4f53\u7684\u5956\u52b1\u548c\u79fb\u52a8\u65b9\u5411\uff09\uff0c\u540c\u65f6\u8bad\u7ec3\u7b56\u7565\u6a21\u578b\uff0c\u901a\u8fc7\u4e30\u5bcc\u9690\u85cf\u72b6\u6001\u8868\u793a\uff0c\u8f85\u52a9\u7b56\u7565\u4f18\u5316\u3002", "result": "\u5728\u6355\u98df\u8005-\u730e\u7269\u73af\u5883\u548c\u8c37\u6b4c\u7814\u7a76\u8db3\u7403\u73af\u5883\u7684\u5b9e\u9a8c\u4e2d\uff0cBEPAL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6027\u80fd\u6307\u6807\u5e73\u5747\u63d0\u5347\u7ea616%\uff0c\u4e14\u8bad\u7ec3\u8fc7\u7a0b\u66f4\u7a33\u5b9a\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u8f85\u52a9\u9884\u6d4b\u4efb\u52a1\uff0cBEPAL\u6709\u6548\u589e\u5f3a\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8f85\u52a9\u4efb\u52a1\u5728MARL\u4e2d\u7684\u91cd\u8981\u6027\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.00265", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.00265", "abs": "https://arxiv.org/abs/2511.00265", "authors": ["Arman Anwar", "Zefang Liu"], "title": "AgentBnB: A Browser-Based Cybersecurity Tabletop Exercise with Large Language Model Support and Retrieval-Aligned Scaffolding", "comment": null, "summary": "Traditional cybersecurity tabletop exercises (TTXs) provide valuable training\nbut are often scripted, resource-intensive, and difficult to scale. We\nintroduce AgentBnB, a browser-based re-imagining of the Backdoors & Breaches\ngame that integrates large language model teammates with a Bloom-aligned,\nretrieval-augmented copilot (C2D2). The system expands a curated corpus into\nfactual, conceptual, procedural, and metacognitive snippets, delivering\non-demand, cognitively targeted hints. Prompt-engineered agents employ a\nscaffolding ladder that gradually fades as learner confidence grows. In a\nsolo-player pilot with four graduate students, participants reported greater\nintention to use the agent-based version compared to the physical card deck and\nviewed it as more scalable, though a ceiling effect emerged on a simple\nknowledge quiz. Despite limitations of small sample size, single-player focus,\nand narrow corpus, these early findings suggest that large language model\naugmented TTXs can provide lightweight, repeatable practice without the\nlogistical burden of traditional exercises. Planned extensions include\nmulti-player modes, telemetry-driven coaching, and comparative studies with\nlarger cohorts.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u57fa\u4e8e\u6d4f\u89c8\u5668\u7684\u7f51\u7edc\u5b89\u5168\u684c\u9762\u6f14\u7ec3\u65b0\u7cfb\u7edfAgentBnB\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u589e\u5f3a\u5f0f\u8f85\u5bfc\uff0c\u4e3a\u5b66\u4e60\u8005\u63d0\u4f9b\u6309\u9700\u63d0\u793a\u548c\u6e10\u8fdb\u5f0f\u8f85\u52a9\u3002\u8bd5\u70b9\u6d4b\u8bd5\u663e\u793a\uff0c\u8be5\u7cfb\u7edf\u6bd4\u4f20\u7edf\u7269\u7406\u5361\u7247\u66f4\u5177\u53ef\u6269\u5c55\u6027\u5e76\u63d0\u5347\u4e86\u4f7f\u7528\u610f\u613f\u3002", "motivation": "\u4f20\u7edf\u7f51\u7edc\u5b89\u5168\u684c\u9762\u6f14\u7ec3\u867d\u7136\u8bad\u7ec3\u6548\u679c\u597d\uff0c\u4f46\u5b58\u5728\u5267\u672c\u5316\u3001\u8d44\u6e90\u5bc6\u96c6\u548c\u96be\u4ee5\u6269\u5c55\u7b49\u95ee\u9898\u3002", "method": "\u5f00\u53d1AgentBnB\u7cfb\u7edf\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u8f85\u52a9\u5de5\u5177\uff0c\u63d0\u4f9b\u4e8b\u5b9e\u3001\u6982\u5ff5\u3001\u7a0b\u5e8f\u53ca\u5143\u8ba4\u77e5\u63d0\u793a\uff0c\u8f85\u4ee5\u6e10\u9690\u5f0f\u811a\u624b\u67b6\u8f85\u52a9\u7b56\u7565\u3002", "result": "\u56db\u540d\u7814\u7a76\u751f\u7684\u5355\u4eba\u8bd5\u70b9\u8868\u660e\uff0c\u7528\u6237\u66f4\u503e\u5411\u4f7f\u7528AgentBnB\u7cfb\u7edf\u800c\u975e\u5b9e\u4f53\u5361\u7247\uff0c\u8ba4\u4e3a\u5176\u66f4\u6613\u6269\u5c55\uff0c\u5c3d\u7ba1\u77e5\u8bc6\u6d4b\u9a8c\u8868\u73b0\u5b58\u5728\u5929\u82b1\u677f\u6548\u5e94\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u684c\u9762\u6f14\u7ec3\u53ef\u4f5c\u4e3a\u8f7b\u91cf\u3001\u53ef\u91cd\u590d\u7684\u8bad\u7ec3\u65b9\u5f0f\uff0c\u51cf\u5c11\u4f20\u7edf\u65b9\u6cd5\u7684\u540e\u52e4\u8d1f\u62c5\uff0c\u672a\u6765\u8ba1\u5212\u6269\u5c55\u591a\u73a9\u5bb6\u6a21\u5f0f\u548c\u66f4\u5927\u89c4\u6a21\u9a8c\u8bc1\u3002"}}
{"id": "2511.00450", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00450", "abs": "https://arxiv.org/abs/2511.00450", "authors": ["Vahid Etemadi", "Gregorio Robles"], "title": "SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin", "comment": "6 pages, Already submitted to The 3rd International Workshop on\n  Integrated Development Environments (the IDE Workshop)", "summary": "Context: The software maintenance phase involves many activities such as code\nrefactoring, bug fixing, code review or testing. Program comprehension is key\nto all these activities, as it demands developers to grasp the knowledge (e.g.,\nimplementation details) required to modify the codebase. Methods as main\nbuilding blocks in a program can offer developers this knowledge source for\ncode comprehension. However, reading entire method statements can be\nchallenging, which necessitates precise and up-to-date comments. Objective: We\npropose a solution as an IntelliJ IDEA plugin, named SmartDoc, that assists\ndevelopers in generating context-aware method comments. Method: This plugin\nacts as an Artificial Intelligence (AI) agent that has its own memory and is\naugmented by target methods' context. When a request is initiated by the\nend-user, the method content and all its nested method calls are used in the\ncomment generation. At the beginning, these nested methods are visited and a\ncall graph is generated. This graph is then traversed using depth-first search\n(DFS), enabling the provision of full-context to enrich Large Language Model\n(LLM) prompts. Result: The product is a software, as a plugin, developed for\nJava codebase and installable on IntelliJ IDEA. This plugin can serve\nconcurrently for methods whose comments are being updated , and it shares\nmemory across all flows to avoid redundant calls. o measure the accuracy of\nthis solution, a dedicated test case is run to record SmartDoc generated\ncomments and their corresponding ground truth. For each collected result-set,\nthree metrics are computed, BERTScore, BLEU and ROUGE-1. These metrics will\ndetermine how accurate the generated comments are in comparison to the ground\ntruth. Result: The obtained accuracy, in terms of the precision, recall and F1,\nis promising, and lies in the range of 0.80 to 0.90 for BERTScore.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SmartDoc\uff0c\u4e00\u4e2a\u57fa\u4e8eAI\u7684IntelliJ IDEA\u63d2\u4ef6\uff0c\u901a\u8fc7\u5229\u7528\u65b9\u6cd5\u53ca\u5176\u5d4c\u5957\u8c03\u7528\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u751f\u6210\u7cbe\u51c6\u4e14\u5b9e\u65f6\u66f4\u65b0\u7684Java\u65b9\u6cd5\u6ce8\u91ca\u3002", "motivation": "\u7a0b\u5e8f\u7ef4\u62a4\u9636\u6bb5\u9700\u8981\u7a0b\u5e8f\u7406\u89e3\uff0c\u800c\u9605\u8bfb\u5b8c\u6574\u65b9\u6cd5\u4ee3\u7801\u8f83\u96be\uff0c\u4e14\u9700\u8981\u51c6\u786e\u53ca\u65f6\u7684\u6ce8\u91ca\u6765\u8f85\u52a9\u7406\u89e3\u3002", "method": "SmartDoc\u5c06\u76ee\u6807\u65b9\u6cd5\u53ca\u5176\u5d4c\u5957\u8c03\u7528\u6784\u6210\u8c03\u7528\u56fe\uff0c\u901a\u8fc7\u6df1\u5ea6\u4f18\u5148\u641c\u7d22\u904d\u5386\uff0c\u4ece\u800c\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e30\u5bcc\u7684\u4e0a\u4e0b\u6587\u63d0\u793a\uff0c\u4ee5\u751f\u6210\u65b9\u6cd5\u6ce8\u91ca\u3002", "result": "\u8be5\u63d2\u4ef6\u53ef\u5728IntelliJ IDEA\u4e2d\u4f7f\u7528\uff0c\u652f\u6301\u5e76\u53d1\u6ce8\u91ca\u66f4\u65b0\uff0c\u4e14\u901a\u8fc7BERTScore\u7b49\u6307\u6807\u8bc4\u6d4b\u751f\u6210\u6ce8\u91ca\u4e0e\u771f\u5b9e\u6ce8\u91ca\u7684\u76f8\u4f3c\u5ea6\uff0c\u51c6\u786e\u7387\u57280.80\u81f30.90\u95f4\u3002", "conclusion": "SmartDoc\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u7684Java\u65b9\u6cd5\u6ce8\u91ca\u751f\u6210\u8d28\u91cf\uff0c\u8f85\u52a9\u5f00\u53d1\u8005\u66f4\u597d\u7406\u89e3\u548c\u7ef4\u62a4\u4ee3\u7801\u3002"}}
{"id": "2511.01136", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01136", "abs": "https://arxiv.org/abs/2511.01136", "authors": ["Enbo Sun", "Yongzhao Wang", "Hao Zhou"], "title": "Credit Network Modeling and Analysis via Large Language Models", "comment": "8 pages, 5 figures, 4 tables", "summary": "We investigate the application of large language models (LLMs) to construct\ncredit networks from firms' textual financial statements and to analyze the\nresulting network structures. We start with using LLMs to translate each firm's\nfinancial statement into a credit network that pertains solely to that firm.\nThese networks are then aggregated to form a comprehensive credit network\nrepresenting the whole financial system. During this process, the\ninconsistencies in financial statements are automatically detected and human\nintervention is involved. We demonstrate that this translation process is\neffective across financial statements corresponding to credit networks with\ndiverse topological structures. We further investigate the reasoning\ncapabilities of LLMs in analyzing credit networks and determining optimal\nstrategies for executing financial operations to maximize network performance\nmeasured by the total assets of firms, which is an inherently combinatorial\noptimization challenge. To demonstrate this capability, we focus on two\nfinancial operations: portfolio compression and debt removal, applying them to\nboth synthetic and real-world datasets. Our findings show that LLMs can\ngenerate coherent reasoning and recommend effective executions of these\noperations to enhance overall network performance.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5c06\u4f01\u4e1a\u8d22\u52a1\u62a5\u8868\u8f6c\u6362\u4e3a\u4fe1\u7528\u7f51\u7edc\uff0c\u8fdb\u800c\u5206\u6790\u5e76\u4f18\u5316\u6574\u4f53\u91d1\u878d\u7cfb\u7edf\u7684\u4fe1\u7528\u7f51\u7edc\u7ed3\u6784\u3002", "motivation": "\u901a\u8fc7\u81ea\u52a8\u6784\u5efa\u548c\u5206\u6790\u4fe1\u7528\u7f51\u7edc\uff0c\u63ed\u793a\u548c\u63d0\u5347\u91d1\u878d\u7cfb\u7edf\u7684\u8fd0\u884c\u6548\u7387\u548c\u7a33\u5b9a\u6027\u3002", "method": "\u4f7f\u7528LLMs\u5c06\u5355\u4e2a\u4f01\u4e1a\u7684\u8d22\u52a1\u62a5\u8868\u8f6c\u6362\u4e3a\u4fe1\u7528\u7f51\u7edc\uff0c\u518d\u805a\u5408\u6210\u6574\u4f53\u91d1\u878d\u7cfb\u7edf\u7f51\u7edc\uff1b\u5728\u81ea\u52a8\u68c0\u6d4b\u8d22\u52a1\u62a5\u8868\u4e0d\u4e00\u81f4\u6027\u7684\u57fa\u7840\u4e0a\uff0c\u7ed3\u5408\u4eba\u7c7b\u5e72\u9884\uff1b\u5229\u7528LLMs\u5206\u6790\u7f51\u7edc\u5e76\u8bbe\u8ba1\u4f18\u5316\u7b56\u7565\uff0c\u5982\u6295\u8d44\u7ec4\u5408\u538b\u7f29\u548c\u503a\u52a1\u6e05\u9664\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u5904\u7406\u4e0d\u540c\u7ed3\u6784\u7684\u4fe1\u7528\u7f51\u7edc\uff0cLLMs\u5c55\u73b0\u51fa\u826f\u597d\u7684\u63a8\u7406\u80fd\u529b\uff0c\u80fd\u63d0\u4f9b\u5408\u7406\u5efa\u8bae\u4ee5\u6267\u884c\u91d1\u878d\u64cd\u4f5c\uff0c\u4ece\u800c\u63d0\u5347\u7f51\u7edc\u8d44\u4ea7\u603b\u989d\u3002", "conclusion": "LLMs\u5728\u4fe1\u7528\u7f51\u7edc\u6784\u5efa\u548c\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u5f3a\u5927\u80fd\u529b\uff0c\u80fd\u8f85\u52a9\u5b9e\u73b0\u590d\u6742\u7684\u91d1\u878d\u7cfb\u7edf\u4f18\u5316\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.00268", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00268", "abs": "https://arxiv.org/abs/2511.00268", "authors": ["Shounak Paul", "Dhananjay Ghumare", "Pawan Goyal", "Saptarshi Ghosh", "Ashutosh Modi"], "title": "IL-PCSR: Legal Corpus for Prior Case and Statute Retrieval", "comment": "Accepted at EMNLP 2025 (Main)", "summary": "Identifying/retrieving relevant statutes and prior cases/precedents for a\ngiven legal situation are common tasks exercised by law practitioners.\nResearchers to date have addressed the two tasks independently, thus developing\ncompletely different datasets and models for each task; however, both retrieval\ntasks are inherently related, e.g., similar cases tend to cite similar statutes\n(due to similar factual situation). In this paper, we address this gap. We\npropose IL-PCR (Indian Legal corpus for Prior Case and Statute Retrieval),\nwhich is a unique corpus that provides a common testbed for developing models\nfor both the tasks (Statute Retrieval and Precedent Retrieval) that can exploit\nthe dependence between the two. We experiment extensively with several baseline\nmodels on the tasks, including lexical models, semantic models and ensemble\nbased on GNNs. Further, to exploit the dependence between the two tasks, we\ndevelop an LLM-based re-ranking approach that gives the best performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IL-PCR\u8bed\u6599\u5e93\uff0c\u7528\u4e8e\u7edf\u4e00\u68c0\u7d22\u6cd5\u89c4\u548c\u5224\u4f8b\u4e24\u4e2a\u76f8\u5173\u6cd5\u5f8b\u4efb\u52a1\uff0c\u5f00\u53d1\u4e86\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u53ca\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u91cd\u6392\u540d\u65b9\u6cd5\uff0c\u53d6\u5f97\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u76ee\u524d\u6cd5\u89c4\u68c0\u7d22\u548c\u5224\u4f8b\u68c0\u7d22\u901a\u5e38\u88ab\u72ec\u7acb\u5904\u7406\uff0c\u4f46\u4e24\u8005\u9ad8\u5ea6\u76f8\u5173\uff0c\u5e94\u5f53\u8054\u5408\u5229\u7528\uff0c\u63d0\u9ad8\u68c0\u7d22\u6548\u679c\u3002", "method": "\u6784\u5efaIL-PCR\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u57fa\u7ebf\u6a21\u578b\uff08\u8bcd\u6c47\u3001\u8bed\u4e49\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u91cd\u6392\u540d\u65b9\u6cd5\uff0c\u8054\u5408\u5229\u7528\u4e24\u4e2a\u4efb\u52a1\u7684\u76f8\u5173\u6027\u3002", "result": "\u57fa\u7ebf\u6a21\u578b\u548cLLM\u91cd\u6392\u540d\u65b9\u6cd5\u5747\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0cLLM\u91cd\u6392\u540d\u65b9\u6cd5\u83b7\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8054\u5408\u5229\u7528\u4e24\u4efb\u52a1\u4f9d\u8d56\u6027\u7684\u6709\u6548\u6027\u3002", "conclusion": "IL-PCR\u8bed\u6599\u5e93\u4e3a\u6cd5\u89c4\u548c\u5224\u4f8b\u68c0\u7d22\u4efb\u52a1\u63d0\u4f9b\u7edf\u4e00\u6d4b\u8bd5\u5e73\u53f0\uff0c\u8054\u5408\u6a21\u578b\u548cLLM\u91cd\u6392\u540d\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u68c0\u7d22\u6027\u80fd\uff0c\u8868\u660e\u4e24\u4efb\u52a1\u7684\u8054\u5408\u5efa\u6a21\u5177\u6709\u6f5c\u529b\u3002"}}
{"id": "2511.00467", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00467", "abs": "https://arxiv.org/abs/2511.00467", "authors": ["Liu Wang", "Dong Wang", "Shidong Pan", "Zheng Jiang", "Haoyu Wang", "Yi Wang"], "title": "A Big Step Forward? A User-Centric Examination of iOS App Privacy Report and Enhancements", "comment": "Accepted to S&P 2025", "summary": "The prevalent engagement with mobile apps underscores the importance of\nunderstanding their data practices. Transparency plays a crucial role in this\ncontext, ensuring users to be informed and give consent before any data access\noccurs. Apple introduced a new feature since iOS 15.2, App Privacy Report, to\ninform users about detailed insights into apps' data access and sharing. This\nfeature continues Apple's trend of privacy-focused innovations (following\nPrivacy Nutrition Labels), and has been marketed as a big step forward in user\nprivacy. However, its real-world impacts on user privacy and control remain\nunexamined. We thus proposed an end-to-end study involving systematic\nassessment of the App Privacy Report's real-world benefits and limitations,\nLLM-enabled and multi-technique synthesized enhancements, and comprehensive\nevaluation from both system and user perspectives. Through a structured focus\ngroup study with twelve everyday iOS users, we explored their experiences,\nunderstanding, and perceptions of the feature, suggesting its limited practical\nimpact resulting from missing important details. We identified two primary user\nconcerns: the clarity of data access purpose and domain description. In\nresponse, we proposed enhancements including a purpose inference framework and\ndomain clarification pipeline. We demonstrated the effectiveness and benefits\nof such enhancements for mobile app users. This work provides practical\ninsights that could help enhance user privacy transparency and discusses areas\nfor future research.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86iOS 15.2\u5f15\u5165\u7684App\u9690\u79c1\u62a5\u544a\u529f\u80fd\uff0c\u8bc4\u4f30\u5176\u5b9e\u9645\u9690\u79c1\u4fdd\u62a4\u6548\u679c\u5e76\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u79fb\u52a8\u5e94\u7528\u666e\u53ca\uff0c\u7528\u6237\u9690\u79c1\u6570\u636e\u8bbf\u95ee\u900f\u660e\u6027\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u800c\u82f9\u679c\u7684\u65b0\u529f\u80fd\u5c1a\u672a\u88ab\u8bc4\u4f30\u5176\u5b9e\u9645\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5316\u8bc4\u4f30\u3001LLM\u8f85\u52a9\u548c\u591a\u6280\u672f\u7efc\u5408\u589e\u5f3a\uff0c\u4ee5\u53ca\u7ed3\u6784\u5316\u7126\u70b9\u5c0f\u7ec4\u8bbf\u8c08\uff0c\u5206\u6790\u7528\u6237\u4f53\u9a8c\u548c\u529f\u80fd\u7f3a\u9677\u3002", "result": "\u53d1\u73b0\u5e94\u7528\u9690\u79c1\u62a5\u544a\u7684\u5b9e\u7528\u6027\u53d7\u9650\uff0c\u4e3b\u8981\u95ee\u9898\u662f\u8bbf\u95ee\u76ee\u7684\u548c\u57df\u63cf\u8ff0\u4e0d\u591f\u6e05\u6670\u3002\u63d0\u51fa\u4e86\u76ee\u7684\u63a8\u65ad\u6846\u67b6\u548c\u57df\u6f84\u6e05\u6d41\u7a0b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6539\u8fdb\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u63d0\u5347\u7528\u6237\u9690\u79c1\u900f\u660e\u5ea6\u63d0\u4f9b\u4e86\u5b9e\u7528\u6d1e\u89c1\uff0c\u63a8\u52a8\u672a\u6765\u9690\u79c1\u4fdd\u62a4\u529f\u80fd\u7684\u4f18\u5316\u4e0e\u7814\u7a76\u3002"}}
{"id": "2511.01310", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01310", "abs": "https://arxiv.org/abs/2511.01310", "authors": ["Sureyya Akin", "Kavita Srivastava", "Prateek B. Kapoor", "Pradeep G. Sethi", "Sunita Q. Patel", "Rahu Srivastava"], "title": "From Pixels to Cooperation Multi Agent Reinforcement Learning based on Multimodal World Models", "comment": null, "summary": "Learning cooperative multi-agent policies directly from high-dimensional,\nmultimodal sensory inputs like pixels and audio (from pixels) is notoriously\nsample-inefficient. Model-free Multi-Agent Reinforcement Learning (MARL)\nalgorithms struggle with the joint challenge of representation learning,\npartial observability, and credit assignment. To address this, we propose a\nnovel framework based on a shared, generative Multimodal World Model (MWM). Our\nMWM is trained to learn a compressed latent representation of the environment's\ndynamics by fusing distributed, multimodal observations from all agents using a\nscalable attention-based mechanism. Subsequently, we leverage this learned MWM\nas a fast, \"imagined\" simulator to train cooperative MARL policies (e.g.,\nMAPPO) entirely within its latent space, decoupling representation learning\nfrom policy learning. We introduce a new set of challenging multimodal,\nmulti-agent benchmarks built on a 3D physics simulator. Our experiments\ndemonstrate that our MWM-MARL framework achieves orders-of-magnitude greater\nsample efficiency compared to state-of-the-art model-free MARL baselines. We\nfurther show that our proposed multimodal fusion is essential for task success\nin environments with sensory asymmetry and that our architecture provides\nsuperior robustness to sensor-dropout, a critical feature for real-world\ndeployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5171\u4eab\u591a\u6a21\u6001\u751f\u6210\u4e16\u754c\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u591a\u6e90\u611f\u77e5\u4fe1\u606f\u5b66\u4e60\u73af\u5883\u52a8\u6001\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8fdb\u884c\u7b56\u7565\u8bad\u7ec3\uff0c\u5927\u5e45\u63d0\u5347\u6837\u672c\u6548\u7387\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u6a21\u578b\u65e0\u5173\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u5728\u5904\u7406\u9ad8\u7ef4\u591a\u6a21\u6001\u611f\u77e5\u8f93\u5165\u65f6\u5b58\u5728\u6837\u672c\u6548\u7387\u4f4e\u3001\u8868\u793a\u5b66\u4e60\u548c\u7b56\u7565\u5b66\u4e60\u96be\u4ee5\u540c\u6b65\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e00\u4e2a\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u591a\u6a21\u6001\u751f\u6210\u4e16\u754c\u6a21\u578b\uff0c\u878d\u5408\u6765\u81ea\u6240\u6709\u667a\u80fd\u4f53\u7684\u591a\u6a21\u6001\u89c2\u6d4b\u6570\u636e\uff0c\u5b66\u4e60\u73af\u5883\u52a8\u6001\u7684\u6f5c\u5728\u8868\u793a\u3002\u7136\u540e\u5229\u7528\u8be5\u6f5c\u5728\u4e16\u754c\u6a21\u578b\u4f5c\u4e3a\u5feb\u901f\u7684\u201c\u60f3\u8c61\u6a21\u62df\u5668\u201d\uff0c\u5728\u6f5c\u5728\u7a7a\u95f4\u5185\u8bad\u7ec3\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\uff0c\u89e3\u8026\u8868\u793a\u5b66\u4e60\u4e0e\u7b56\u7565\u5b66\u4e60\u3002", "result": "\u5728\u57fa\u4e8e3D\u7269\u7406\u6a21\u62df\u5668\u7684\u65b0\u591a\u6a21\u6001\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u6a21\u578b\u65e0\u5173\u591a\u667a\u80fd\u4f53\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6837\u672c\u6548\u7387\u63d0\u5347\u51e0\u4e2a\u6570\u91cf\u7ea7\u3002\u591a\u6a21\u6001\u878d\u5408\u63d0\u9ad8\u4e86\u5728\u611f\u77e5\u4e0d\u5bf9\u79f0\u73af\u5883\u4e2d\u7684\u4efb\u52a1\u6210\u529f\u7387\uff0c\u540c\u65f6\u67b6\u6784\u5bf9\u4f20\u611f\u5668\u6389\u7ebf\u7684\u9c81\u68d2\u6027\u4e5f\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u5171\u4eab\u591a\u6a21\u6001\u751f\u6210\u4e16\u754c\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u6837\u672c\u6548\u7387\u4f4e\u548c\u591a\u6a21\u6001\u4fe1\u606f\u878d\u5408\u96be\u9898\uff0c\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u590d\u6742\u611f\u77e5\u73af\u5883\u4e2d\u7684\u6027\u80fd\u548c\u5b9e\u9645\u90e8\u7f72\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2511.00270", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00270", "abs": "https://arxiv.org/abs/2511.00270", "authors": ["Abhinav Joshi", "Vaibhav Sharma", "Sanjeet Singh", "Ashutosh Modi"], "title": "POSESTITCH-SLT: Linguistically Inspired Pose-Stitching for End-to-End Sign Language Translation", "comment": "Accepted at EMNLP 2025 (Main)", "summary": "Sign language translation remains a challenging task due to the scarcity of\nlarge-scale, sentence-aligned datasets. Prior arts have focused on various\nfeature extraction and architectural changes to support neural machine\ntranslation for sign languages. We propose POSESTITCH-SLT, a novel pre-training\nscheme that is inspired by linguistic-templates-based sentence generation\ntechnique. With translation comparison on two sign language datasets, How2Sign\nand iSign, we show that a simple transformer-based encoder-decoder architecture\noutperforms the prior art when considering template-generated sentence pairs in\ntraining. We achieve BLEU-4 score improvements from 1.97 to 4.56 on How2Sign\nand from 0.55 to 3.43 on iSign, surpassing prior state-of-the-art methods for\npose-based gloss-free translation. The results demonstrate the effectiveness of\ntemplate-driven synthetic supervision in low-resource sign language settings.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6a21\u677f\u751f\u6210\u53e5\u5b50\u9884\u8bad\u7ec3\u7684\u65b0\u65b9\u6cd5POSESTITCH-SLT\uff0c\u7528\u4e8e\u63d0\u5347\u624b\u8bed\u7ffb\u8bd1\u6548\u679c\u3002", "motivation": "\u624b\u8bed\u7ffb\u8bd1\u9762\u4e34\u5927\u578b\u3001\u53e5\u5b50\u5bf9\u9f50\u6570\u636e\u96c6\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u6539\u8fdb\u7279\u5f81\u63d0\u53d6\u548c\u7f51\u7edc\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86POSESTITCH-SLT\uff0c\u4e00\u79cd\u53d7\u8bed\u8a00\u6a21\u677f\u542f\u53d1\u7684\u9884\u8bad\u7ec3\u65b9\u6848\uff0c\u7ed3\u5408\u6a21\u677f\u751f\u6210\u7684\u53e5\u5b50\u5bf9\u8fdb\u884c\u8bad\u7ec3\uff0c\u5728Transformer\u7f16\u7801\u5668-\u89e3\u7801\u5668\u67b6\u6784\u57fa\u7840\u4e0a\u5b9e\u73b0\u7ffb\u8bd1\u3002", "result": "\u5728\u4e24\u5927\u624b\u8bed\u6570\u636e\u96c6How2Sign\u548ciSign\u4e0a\uff0cBLEU-4\u5206\u6570\u5206\u522b\u4ece1.97\u63d0\u5347\u52304.56\u548c0.55\u63d0\u5347\u52303.43\uff0c\u8d85\u8d8a\u4e86\u57fa\u4e8e\u59ff\u6001\u7684\u65e0\u8bcd\u6c47\u7ffb\u8bd1\u5148\u524d\u6210\u679c\u3002", "conclusion": "\u6a21\u677f\u9a71\u52a8\u7684\u5408\u6210\u76d1\u7763\u5728\u6570\u636e\u7a00\u7f3a\u7684\u624b\u8bed\u7ffb\u8bd1\u573a\u666f\u4e2d\u6548\u679c\u663e\u8457\uff0c\u4fc3\u8fdb\u4e86\u6a21\u578b\u6027\u80fd\u63d0\u5347\u3002"}}
{"id": "2511.00517", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00517", "abs": "https://arxiv.org/abs/2511.00517", "authors": ["Shuochuan Li", "Dong Wang", "Patanamon Thongtanunam", "Zan Wang", "Jiuqiao Yu", "Junjie Chen"], "title": "Issue-Oriented Agent-Based Framework for Automated Review Comment Generation", "comment": null, "summary": "Code review (CR) is a crucial practice for ensuring software quality. Various\nautomated review comment generation techniques have been proposed to streamline\nthe labor-intensive process. However, existing approaches heavily rely on a\nsingle model to identify various issues within the code, limiting the model's\nability to handle the diverse, issue-specific nature of code changes and\nleading to non-informative comments, especially in complex scenarios such as\nbug fixes. To address these limitations, we propose RevAgent, a novel\nagent-based issue-oriented framework, decomposes the task into three stages:\n(1) Generation Stage, where five category-specific commentator agents analyze\ncode changes from distinct issue perspectives and generate candidate comments;\n(2) Discrimination Stage, where a critic agent selects the most appropriate\nissue-comment pair; and (3) Training Stage, where all agents are fine-tuned on\ncurated, category-specific data to enhance task specialization. Evaluation\nresults show that RevAgent significantly outperforms state-of-the-art PLM- and\nLLM-based baselines, with improvements of 12.90\\%, 10.87\\%, 6.32\\%, and 8.57\\%\non BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively\nhigher accuracy in issue-category identification, particularly for challenging\nscenarios. Human evaluations further validate the practicality of RevAgent in\ngenerating accurate, readable, and context-aware review comments. Moreover,\nRevAgent delivers a favorable trade-off between performance and efficiency.", "AI": {"tldr": "RevAgent\u662f\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u7684\u5206\u95ee\u9898\u4ee3\u7801\u8bc4\u5ba1\u81ea\u52a8\u8bc4\u8bba\u751f\u6210\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u8bba\u8d28\u91cf\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u8bc4\u8bba\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u5355\u4e00\u6a21\u578b\uff0c\u96be\u4ee5\u5904\u7406\u591a\u6837\u5316\u4e14\u7279\u5b9a\u4e8e\u95ee\u9898\u7684\u4ee3\u7801\u6539\u52a8\uff0c\u5bfc\u81f4\u8bc4\u8bba\u4fe1\u606f\u91cf\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u590d\u6742\u573a\u666f\u5982BUG\u4fee\u590d\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51faRevAgent\u6846\u67b6\uff0c\u5c06\u4efb\u52a1\u5206\u4e3a\u751f\u6210\u9636\u6bb5\uff08\u4e94\u4e2a\u9488\u5bf9\u4e0d\u540c\u95ee\u9898\u7c7b\u522b\u7684\u4ee3\u7406\u751f\u6210\u8bc4\u8bba\uff09\u3001\u5224\u522b\u9636\u6bb5\uff08\u6279\u5224\u4ee3\u7406\u9009\u62e9\u6700\u5408\u9002\u7684\u8bc4\u8bba\uff09\u548c\u8bad\u7ec3\u9636\u6bb5\uff08\u5728\u5206\u7c7b\u6570\u636e\u4e0a\u5fae\u8c03\u5404\u4ee3\u7406\u4ee5\u589e\u5f3a\u4e13\u4e1a\u5316\uff09\u3002", "result": "\u5728\u591a\u9879\u81ea\u52a8\u8bc4\u4ef7\u6307\u6807\uff08BLEU\u3001ROUGE-L\u3001METEOR\u3001SBERT\uff09\u4e0a\uff0cRevAgent\u8f83\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5206\u522b\u63d0\u534712.90%\u300110.87%\u30016.32%\u548c8.57%\uff0c\u5e76\u5728\u95ee\u9898\u7c7b\u522b\u8bc6\u522b\u51c6\u786e\u6027\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u5728\u4eba\u7c7b\u8bc4\u4f30\u4e2d\u8868\u73b0\u51fa\u8bc4\u8bba\u7684\u51c6\u786e\u6027\u3001\u53ef\u8bfb\u6027\u548c\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\u3002", "conclusion": "RevAgent\u6709\u6548\u63d0\u5347\u4e86\u4ee3\u7801\u8bc4\u5ba1\u81ea\u52a8\u8bc4\u8bba\u7684\u4e13\u4e1a\u6027\u4e0e\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u590d\u6742\u4ee3\u7801\u53d8\u66f4\u573a\u666f\u3002"}}
{"id": "2511.01489", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.01489", "abs": "https://arxiv.org/abs/2511.01489", "authors": ["Qurat-ul-ain Shaheen", "Katarzyna Budzynska", "Carles Sierra"], "title": "An Explanation-oriented Inquiry Dialogue Game for Expert Collaborative Recommendations", "comment": null, "summary": "This work presents a requirement analysis for collaborative dialogues among\nmedical experts and an inquiry dialogue game based on this analysis for\nincorporating explainability into multiagent system design. The game allows\nexperts with different knowledge bases to collaboratively make recommendations\nwhile generating rich traces of the reasoning process through combining\nexplanation-based illocutionary forces in an inquiry dialogue. The dialogue\ngame was implemented as a prototype web-application and evaluated against the\nspecification through a formative user study. The user study confirms that the\ndialogue game meets the needs for collaboration among medical experts. It also\nprovides insights on the real-life value of dialogue-based communication tools\nfor the medical community.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9700\u6c42\u5206\u6790\u7684\u533b\u7597\u4e13\u5bb6\u534f\u4f5c\u5bf9\u8bdd\u6e38\u620f\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u53ef\u89e3\u91ca\u6027\u652f\u6301\uff0c\u4e14\u901a\u8fc7\u7528\u6237\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u5b9e\u7528\u6027\u3002", "motivation": "\u533b\u7597\u4e13\u5bb6\u5728\u534f\u4f5c\u63a8\u8350\u8fc7\u7a0b\u4e2d\u9700\u8981\u900f\u660e\u4e14\u6613\u4e8e\u8ffd\u6eaf\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u5408\u4f5c\u6548\u7387\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u89e3\u91ca\u6027\u8a00\u8bed\u884c\u4e3a\u7684\u67e5\u8be2\u5bf9\u8bdd\u6e38\u620f\uff0c\u5141\u8bb8\u62e5\u6709\u4e0d\u540c\u77e5\u8bc6\u5e93\u7684\u4e13\u5bb6\u534f\u4f5c\u751f\u6210\u63a8\u8350\u53ca\u63a8\u7406\u8f68\u8ff9\uff0c\u5f00\u53d1\u4e86\u7f51\u9875\u7248\u539f\u578b\u5e76\u8fdb\u884c\u5f62\u6210\u6027\u7528\u6237\u7814\u7a76\u3002", "result": "\u7528\u6237\u7814\u7a76\u7ed3\u679c\u8868\u660e\u8be5\u5bf9\u8bdd\u6e38\u620f\u6ee1\u8db3\u533b\u7597\u4e13\u5bb6\u534f\u4f5c\u9700\u6c42\uff0c\u80fd\u6709\u6548\u652f\u6301\u4e13\u5bb6\u95f4\u7684\u6c9f\u901a\u548c\u63a8\u7406\u5171\u4eab\u3002", "conclusion": "\u57fa\u4e8e\u5bf9\u8bdd\u7684\u4ea4\u4e92\u5de5\u5177\u5728\u533b\u7597\u4e13\u5bb6\u534f\u4f5c\u4e2d\u6709\u5b9e\u9645\u4ef7\u503c\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53ef\u89e3\u91ca\u6027\u548c\u534f\u4f5c\u6548\u7387\u3002"}}
{"id": "2511.00315", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00315", "abs": "https://arxiv.org/abs/2511.00315", "authors": ["Lee Xiong", "Maksim Tkachenko", "Johanes Effendi", "Ting Cai"], "title": "Language Modeling With Factorization Memory", "comment": null, "summary": "We propose Factorization Memory, an efficient recurrent neural network (RNN)\narchitecture that achieves performance comparable to Transformer models on\nshort-context language modeling tasks while also demonstrating superior\ngeneralization in long-context scenarios. Our model builds upon Mamba-2,\nenabling Factorization Memory to exploit parallel computations during training\nwhile preserving constant computational and memory complexity during inference.\nTo further optimize model efficiency and representational capacity, we develop\na sparse formulation of Factorization Memory that updates only a subset of\nrecurrent states at each step while preserving the strong performance of its\ndense counterpart. To our knowledge, this represents the first RNN architecture\nthat successfully combines sparse memory activation with competitive\nperformance across both short and long-context settings. This work provides a\nsystematic empirical analysis of Factorization Memory in comparison to\nTransformer and Mamba-2 architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFactorization Memory\u7684\u65b0\u578b\u9ad8\u6548RNN\u7ed3\u6784\uff0c\u5728\u77ed\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u6027\u80fd\u53ef\u6bd4\u80a9Transformer\u6a21\u578b\uff0c\u5e76\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u73b0\u6709Transformer\u6a21\u578b\u5728\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u957f\u4e0a\u4e0b\u6587\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u4e14\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u8f83\u9ad8\uff0c\u4e9f\u9700\u4e00\u79cd\u65e2\u9ad8\u6548\u53c8\u80fd\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u6a21\u578b\u3002", "method": "\u57fa\u4e8eMamba-2\u6a21\u578b\uff0c\u8bbe\u8ba1Factorization Memory\uff0c\u4f7f\u5176\u5728\u8bad\u7ec3\u9636\u6bb5\u652f\u6301\u5e76\u884c\u8ba1\u7b97\uff0c\u63a8\u7406\u9636\u6bb5\u4fdd\u6301\u6052\u5b9a\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u590d\u6742\u5ea6\uff1b\u5f15\u5165\u7a00\u758f\u7248\u672c\u4ec5\u66f4\u65b0\u90e8\u5206\u72b6\u6001\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u8bc1\u6027\u80fd\u3002", "result": "Factorization Memory\u5728\u77ed\u4e0a\u4e0b\u6587\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0eTransformer\u76f8\u5f53\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u8868\u73b0\u66f4\u4f18\uff0c\u4e14\u7a00\u758f\u7248\u672c\u6709\u6548\u964d\u4f4e\u8ba1\u7b97\u91cf\u800c\u4e0d\u635f\u5931\u6027\u80fd\u3002", "conclusion": "Factorization Memory\u9996\u6b21\u5c06\u7a00\u758f\u8bb0\u5fc6\u6fc0\u6d3b\u4e0e\u4f18\u79c0\u7684\u77ed\u957f\u4e0a\u4e0b\u6587\u6027\u80fd\u7ed3\u5408\uff0c\u5c55\u793a\u4e86\u5176\u4f5c\u4e3a\u9ad8\u6548RNN\u67b6\u6784\u7684\u6f5c\u529b\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u76f8\u5173\u67b6\u6784\u3002"}}
{"id": "2511.00527", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00527", "abs": "https://arxiv.org/abs/2511.00527", "authors": ["Robab Aghazadeh-Chakherlou", "Qing Guo", "Siddartha Khastgir", "Peter Popov", "Xiaoge Zhang", "Xingyu Zhao"], "title": "HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models", "comment": "under review", "summary": "Large Language Models (LLMs) are increasingly deployed across diverse\ndomains, raising the need for rigorous reliability assessment methods. Existing\nbenchmark-based evaluations primarily offer descriptive statistics of model\naccuracy over datasets, providing limited insight into the probabilistic\nbehavior of LLMs under real operational conditions. This paper introduces\nHIP-LLM, a Hierarchical Imprecise Probability framework for modeling and\ninferring LLM reliability. Building upon the foundations of software\nreliability engineering, HIP-LLM defines LLM reliability as the probability of\nfailure-free operation over a specified number of future tasks under a given\nOperational Profile (OP). HIP-LLM represents dependencies across (sub-)domains\nhierarchically, enabling multi-level inference from subdomain to system-level\nreliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty\nand incorporates OPs to reflect usage contexts. It derives posterior\nreliability envelopes that quantify uncertainty across priors and data.\nExperiments on multiple benchmark datasets demonstrate that HIP-LLM offers a\nmore accurate and standardized reliability characterization than existing\nbenchmark and state-of-the-art approaches. A publicly accessible repository of\nHIP-LLM is provided.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HIP-LLM\uff0c\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u4e0d\u7cbe\u786e\u6982\u7387\u7684LLM\u53ef\u9760\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u523b\u753b\u6a21\u578b\u5728\u771f\u5b9e\u64cd\u4f5c\u6761\u4ef6\u4e0b\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u51c6\u6d4b\u8bd5\u4ec5\u63d0\u4f9b\u6a21\u578b\u51c6\u786e\u7387\u7684\u63cf\u8ff0\u6027\u7edf\u8ba1\uff0c\u96be\u4ee5\u53cd\u6620LLM\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6982\u7387\u884c\u4e3a\u53ca\u53ef\u9760\u6027\u3002", "method": "HIP-LLM\u57fa\u4e8e\u8f6f\u4ef6\u53ef\u9760\u6027\u5de5\u7a0b\uff0c\u5b9a\u4e49LLM\u53ef\u9760\u6027\u4e3a\u5728\u7279\u5b9a\u64cd\u4f5c\u914d\u7f6e\u4e0b\u65e0\u6545\u969c\u8fd0\u884c\u7684\u6982\u7387\uff0c\u91c7\u7528\u5206\u5c42\u7ed3\u6784\u8868\u793a\u5b50\u57df\u4f9d\u8d56\uff0c\u878d\u5408\u4e0d\u7cbe\u786e\u5148\u9a8c\u548c\u64cd\u4f5c\u914d\u7f6e\uff0c\u63a8\u5bfc\u540e\u9a8c\u53ef\u9760\u6027\u533a\u95f4\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cHIP-LLM\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u73b0\u6709\u57fa\u51c6\u548c\u6700\u65b0\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u548c\u6807\u51c6\u5316\u5730\u63cf\u8ff0\u6a21\u578b\u53ef\u9760\u6027\u3002", "conclusion": "HIP-LLM\u4e3aLLM\u7684\u53ef\u9760\u6027\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u4e14\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5f25\u8865\u4e86\u73b0\u6709\u8bc4\u4f30\u624b\u6bb5\u7684\u4e0d\u8db3\uff0c\u4e14\u5df2\u5f00\u6e90\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.01554", "categories": ["cs.MA", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2511.01554", "abs": "https://arxiv.org/abs/2511.01554", "authors": ["Aditya Kapoor", "Yash Bhisikar", "Benjamin Freed", "Jan Peters", "Mingfei Sun"], "title": "Learning what to say and how precisely: Efficient Communication via Differentiable Discrete Communication Learning", "comment": "30 pages, 12 figures, 6 tables", "summary": "Effective communication in multi-agent reinforcement learning (MARL) is\ncritical for success but constrained by bandwidth, yet past approaches have\nbeen limited to complex gating mechanisms that only decide \\textit{whether} to\ncommunicate, not \\textit{how precisely}. Learning to optimize message precision\nat the bit-level is fundamentally harder, as the required discretization step\nbreaks gradient flow. We address this by generalizing Differentiable Discrete\nCommunication Learning (DDCL), a framework for end-to-end optimization of\ndiscrete messages. Our primary contribution is an extension of DDCL to support\nunbounded signals, transforming it into a universal, plug-and-play layer for\nany MARL architecture. We verify our approach with three key results. First,\nthrough a qualitative analysis in a controlled environment, we demonstrate\n\\textit{how} agents learn to dynamically modulate message precision according\nto the informational needs of the task. Second, we integrate our variant of\nDDCL into four state-of-the-art MARL algorithms, showing it reduces bandwidth\nby over an order of magnitude while matching or exceeding task performance.\nFinally, we provide direct evidence for the \\enquote{Bitter Lesson} in MARL\ncommunication: a simple Transformer-based policy leveraging DDCL matches the\nperformance of complex, specialized architectures, questioning the necessity of\nbespoke communication designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6269\u5c55\u7684\u53ef\u5fae\u5206\u79bb\u6563\u901a\u4fe1\u5b66\u4e60(DDCL)\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u4f18\u5316\u901a\u4fe1\u7684\u7cbe\u5ea6\u548c\u5e26\u5bbd\uff0c\u6210\u529f\u964d\u4f4e\u5e26\u5bbd\u6d88\u8017\u540c\u65f6\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6709\u6548\u901a\u4fe1\u53d7\u5e26\u5bbd\u9650\u5236\uff0c\u73b0\u6709\u65b9\u6cd5\u4ec5\u80fd\u51b3\u5b9a\u662f\u5426\u901a\u4fe1\uff0c\u4e0d\u80fd\u7cbe\u786e\u63a7\u5236\u901a\u4fe1\u7684\u4f4d\u7ea7\u7cbe\u5ea6\uff0c\u800c\u7ec6\u5316\u5230\u4f4d\u7684\u79bb\u6563\u5316\u4f7f\u68af\u5ea6\u6d41\u65ad\u88c2\uff0c\u5e26\u6765\u4f18\u5316\u96be\u9898\u3002", "method": "\u901a\u8fc7\u63a8\u5e7fDDCL\u6846\u67b6\uff0c\u652f\u6301\u65e0\u754c\u4fe1\u53f7\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u79bb\u6563\u6d88\u606f\u7684\u4f18\u5316\uff0c\u5f62\u6210\u4e00\u4e2a\u901a\u7528\u53ef\u63d2\u62d4\u5c42\uff0c\u9002\u7528\u4e8e\u4efb\u4f55MARL\u67b6\u6784\uff1b\u5e76\u5c06\u8be5\u65b9\u6cd5\u96c6\u6210\u8fdb\u56db\u79cd\u5148\u8fdbMARL\u7b97\u6cd5\u4e2d\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u667a\u80fd\u4f53\u80fd\u591f\u52a8\u6001\u8c03\u8282\u6d88\u606f\u7cbe\u5ea6\u4ee5\u6ee1\u8db3\u4efb\u52a1\u4fe1\u606f\u9700\u6c42\uff0c\u5e26\u5bbd\u964d\u4f4e\u4e00\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\uff0c\u540c\u65f6\u4efb\u52a1\u6027\u80fd\u4fdd\u6301\u6216\u63d0\u5347\uff1b\u66f4\u7b80\u5355\u7684\u57fa\u4e8eTransformer\u7b56\u7565\u5229\u7528DDCL\u53ef\u5339\u914d\u590d\u6742\u67b6\u6784\u6027\u80fd\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u901a\u8fc7\u4f4d\u7ea7\u7cbe\u5ea6\u8c03\u63a7\u7684DDCL\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347MARL\u901a\u4fe1\u6548\u7387\u548c\u6027\u80fd\uff0c\u8868\u660e\u590d\u6742\u4e13\u7528\u901a\u4fe1\u8bbe\u8ba1\u5e76\u975e\u5fc5\u8981\uff0c\u7b80\u5355\u901a\u7528\u65b9\u6cd5\u540c\u6837\u4f18\u79c0\u3002"}}
{"id": "2511.00341", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00341", "abs": "https://arxiv.org/abs/2511.00341", "authors": ["Mihir Sahasrabudhe"], "title": "Reversal Invariance in Autoregressive Language Models", "comment": "7 pages, theoretical note", "summary": "We formalize a structural property of the causal (autoregressive) language\nmodeling (CLM) objective: reversal invariance. Formally, the next-token\nprediction loss assigns identical likelihood to a corpus and its reversal,\nimplying that standard CLM pretraining is direction-blind. This symmetry\nexplains why models trained on reversed text can achieve comparable performance\nto those trained on forward text, despite the inherently time-asymmetric nature\nof human language and reasoning. We argue that this invariance represents a\nlimitation of current pretraining objectives rather than a benign artifact. If\nnatural language encodes directional dependencies - phonological,\nmorphological, or causal - a symmetric objective may fail to capture them. We\ntherefore propose viewing pretraining through the lens of temporal asymmetry,\nmotivating future work on loss functions and architectures that explicitly\nmodel the arrow of language while retaining standard language modeling\ncapacity.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u5177\u6709\u53cd\u8f6c\u4e0d\u53d8\u6027\uff0c\u5373\u6a21\u578b\u5bf9\u6b63\u5e8f\u548c\u9006\u5e8f\u6587\u672c\u7684\u9884\u6d4b\u635f\u5931\u76f8\u540c\uff0c\u5bfc\u81f4\u6a21\u578b\u5bf9\u6587\u672c\u65b9\u5411\u4e0d\u654f\u611f\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u76ee\u6807\u5ffd\u89c6\u4e86\u8bed\u8a00\u7684\u65f6\u95f4\u975e\u5bf9\u79f0\u7279\u6027\uff0c\u4e0d\u80fd\u6709\u6548\u6355\u6349\u8bed\u8a00\u4e2d\u7684\u65b9\u5411\u4f9d\u8d56\uff0c\u5982\u8bed\u97f3\u3001\u5f62\u6001\u548c\u56e0\u679c\u5173\u7cfb\u3002", "method": "\u4f5c\u8005\u5f62\u5f0f\u5316\u4e86\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u76ee\u6807\u7684\u53cd\u8f6c\u4e0d\u53d8\u6027\u7279\u6027\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e00\u5bf9\u79f0\u6027\u5e26\u6765\u7684\u9650\u5236\uff0c\u63d0\u51fa\u5e94\u4ece\u65f6\u95f4\u975e\u5bf9\u79f0\u6027\u7684\u89d2\u5ea6\u91cd\u65b0\u8bbe\u8ba1\u9884\u8bad\u7ec3\u76ee\u6807\u548c\u6a21\u578b\u67b6\u6784\u3002", "result": "\u6a21\u578b\u5728\u6b63\u5e8f\u548c\u9006\u5e8f\u6587\u672c\u4e0a\u8868\u73b0\u76f8\u8fd1\uff0c\u8bf4\u660e\u73b0\u6709\u76ee\u6807\u51fd\u6570\u5bf9\u6587\u672c\u65b9\u5411\u4e0d\u654f\u611f\uff0c\u8fd9\u63ed\u793a\u4e86\u9884\u8bad\u7ec3\u76ee\u6807\u7684\u4e00\u79cd\u6839\u672c\u9650\u5236\u3002", "conclusion": "\u73b0\u6709\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u56e0\u5bf9\u65b9\u5411\u7684\u5ffd\u89c6\u800c\u5b58\u5728\u5c40\u9650\uff0c\u5e94\u5f00\u53d1\u5177\u5907\u65f6\u95f4\u7bad\u5934\u5efa\u6a21\u80fd\u529b\u7684\u65b0\u635f\u5931\u51fd\u6570\u548c\u67b6\u6784\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u83b7\u8bed\u8a00\u7684\u65b9\u5411\u6027\u4f9d\u8d56\u3002"}}
{"id": "2511.00528", "categories": ["cs.SE", "D.2.9"], "pdf": "https://arxiv.org/pdf/2511.00528", "abs": "https://arxiv.org/abs/2511.00528", "authors": ["Muhammad Hamid Raza Mookadam", "Ridewaan Hanslo"], "title": "Employee Performance when Implementing Agile Practices in an IT Workforce", "comment": "11 pages, 1 figure, 1 table, 7th World Symposium on Software\n  Engineering (WSSE 2025)", "summary": "Adoption of agile practices has increased in IT workforces. However, there is\na lack of comprehensive studies in the African context on employee performance\nwhen implementing agile practices. This study addresses this gap by exploring\nemployee performance in agile environments for IT workforces in South Africa.\nAn interpretivist mono-method qualitative approach was used, with the use of\ninterviews as a research strategy. Seventeen semi-structured interviews were\nconducted with agile practitioners from various roles. Our results indicated\nthat agile practices influence employee performance significantly, with\nparticipants reporting on aspects which included planning, communication,\nemployee development and well-being, collaboration, team culture and progress.\nAdditionally, our results reported obstacles when using agile practices that\nincluded adoption, team engagement, leadership and instilling an agile mindset.\nAgile practices influence employee performance in IT workforces by fostering\nimproved team dynamics, enhanced collaboration, improved efficiencies, risk\nmanagement, planning, continuous improvement, learning, personal development\nand well-being. Conclusively, our findings suggest that if agile challenges are\naddressed and additional support is provided, employee performance can be\nsignificantly improved.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5357\u975eIT\u884c\u4e1a\u91c7\u7528\u654f\u6377\u5b9e\u8df5\u5bf9\u5458\u5de5\u7ee9\u6548\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u654f\u6377\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u56e2\u961f\u5408\u4f5c\u3001\u6c9f\u901a\u3001\u89c4\u5212\u53ca\u5458\u5de5\u53d1\u5c55\u7b49\u65b9\u9762\uff0c\u4f46\u4e5f\u5b58\u5728\u91c7\u7eb3\u548c\u9886\u5bfc\u529b\u7b49\u969c\u788d\u3002", "motivation": "\u975e\u6d32\u5c24\u5176\u662f\u5357\u975e\u5728IT\u884c\u4e1a\u4e2d\u5173\u4e8e\u654f\u6377\u5b9e\u8df5\u5bf9\u5458\u5de5\u7ee9\u6548\u5f71\u54cd\u7684\u7814\u7a76\u8f83\u5c11\uff0c\u672c\u6587\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u89e3\u91ca\u4e3b\u4e49\u5355\u4e00\u65b9\u6cd5\u7684\u5b9a\u6027\u7814\u7a76\uff0c\u901a\u8fc7\u5bf917\u540d\u654f\u6377\u4ece\u4e1a\u8005\u8fdb\u884c\u534a\u7ed3\u6784\u5f0f\u8bbf\u8c08\u6536\u96c6\u6570\u636e\u3002", "result": "\u654f\u6377\u5b9e\u8df5\u6539\u5584\u4e86\u56e2\u961f\u52a8\u6001\u3001\u534f\u4f5c\u3001\u6548\u7387\u3001\u98ce\u9669\u7ba1\u7406\u53ca\u5458\u5de5\u8eab\u5fc3\u5065\u5eb7\uff0c\u540c\u65f6\u5b58\u5728\u91c7\u7eb3\u96be\u5ea6\u3001\u56e2\u961f\u53c2\u4e0e\u5ea6\u548c\u9886\u5bfc\u80fd\u529b\u7b49\u6311\u6218\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u654f\u6377\u5b9e\u65bd\u4e2d\u9047\u5230\u7684\u6311\u6218\u5e76\u589e\u5f3a\u652f\u6301\uff0c\u53ef\u663e\u8457\u63d0\u5347IT\u884c\u4e1a\u5458\u5de5\u7ee9\u6548\u3002"}}
{"id": "2511.00343", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00343", "abs": "https://arxiv.org/abs/2511.00343", "authors": ["Changbing Yang", "Franklin Ma", "Freda Shi", "Jian Zhu"], "title": "LingGym: How Far Are LLMs from Thinking Like Field Linguists?", "comment": "EMNLP 2025 Main", "summary": "This paper introduces LingGym, a new benchmark that evaluates LLMs' capacity\nfor meta-linguistic reasoning using Interlinear Glossed Text (IGT) and\ngrammatical descriptions extracted from 18 typologically diverse reference\ngrammars. Unlike previous work that focuses on specific downstream tasks, we\nassess whether LLMs can generalize linguistic inference across low-resource\nlanguages and structures not seen during training. We present a controlled\nevaluation task: Word-Gloss Inference, in which the model must infer a missing\nword and gloss from context using varying levels of linguistic information\n(e.g., glosses, grammatical explanations, translations). Our results show that\nincorporating structured linguistic cues leads to consistent improvements in\nreasoning performance across all models. This work highlights both the promise\nand current limitations of using LLMs for typologically informed linguistic\nanalysis and low-resource language documentation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LingGym\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u5143\u8bed\u8a00\u5b66\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\uff0c\u91cd\u70b9\u8003\u5bdf\u5176\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u65b0\u7ed3\u6784\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7279\u5b9a\u4e0b\u6e38\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9LLM\u8de8\u8bed\u8a00\u7c7b\u578b\u63a8\u7406\u80fd\u529b\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u8de818\u79cd\u7c7b\u578b\u8bed\u8a00\u7684IGT\u548c\u8bed\u6cd5\u63cf\u8ff0\u7684Word-Gloss\u63a8\u7406\u4efb\u52a1\uff0c\u8981\u6c42\u6a21\u578b\u6839\u636e\u4e0a\u4e0b\u6587\u63a8\u65ad\u7f3a\u5931\u5355\u8bcd\u548c\u8bcd\u6c47\u89e3\u91ca\uff0c\u5229\u7528\u591a\u5c42\u6b21\u8bed\u8a00\u5b66\u4fe1\u606f\u8fdb\u884c\u63a7\u5236\u8bc4\u4f30\u3002", "result": "\u7ed3\u679c\u8868\u660e\uff0c\u52a0\u5165\u7ed3\u6784\u5316\u8bed\u8a00\u7ebf\u7d22\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5404\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8bed\u8a00\u4fe1\u606f\u5bf9\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86LLM\u5728\u7c7b\u578b\u5b66\u8bed\u8a00\u5206\u6790\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u6587\u732e\u8bb0\u5f55\u4e2d\u7684\u6f5c\u529b\uff0c\u540c\u65f6\u6307\u51fa\u76ee\u524d\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u8bed\u8a00\u63a8\u7406\u65f6\u4ecd\u5b58\u5728\u5c40\u9650\u3002"}}
{"id": "2511.00619", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00619", "abs": "https://arxiv.org/abs/2511.00619", "authors": ["Huaijin Ran", "Haoyi Zhang", "Xunzhu Tang"], "title": "GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance Detection in Android", "comment": null, "summary": "Automating the detection of EU General Data Protection Regulation (GDPR)\nviolations in source code is a critical but underexplored challenge. We\nintroduce \\textbf{GDPR-Bench-Android}, the first comprehensive benchmark for\nevaluating diverse automated methods for GDPR compliance detection in Android\napplications. It contains \\textbf{1951} manually annotated violation instances\nfrom \\textbf{15} open-source repositories, covering 23 GDPR articles at file-,\nmodule-, and line-level granularities. To enable a multi-paradigm evaluation,\nwe contribute \\textbf{Formal-AST}, a novel, source-code-native formal method\nthat serves as a deterministic baseline. We define two tasks: (1)\n\\emph{multi-granularity violation localization}, evaluated via\nAccuracy@\\textit{k}; and (2) \\emph{snippet-level multi-label classification},\nassessed by macro-F1 and other classification metrics. We benchmark 11 methods,\nincluding eight state-of-the-art LLMs, our Formal-AST analyzer, a\nretrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings\nreveal that no single paradigm excels across all tasks. For Task 1, the ReAct\nagent achieves the highest file-level Accuracy@1 (17.38%), while the\nQwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the\nFormal-AST method's 1.86%. For the difficult multi-label Task 2, the\nClaude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method\nyields the highest Macro-Precision (7.10%). These results highlight the\ntask-dependent strengths of different automated approaches and underscore the\nvalue of our benchmark in diagnosing their capabilities. All resources are\navailable at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86GDPR-Bench-Android\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9Android\u5e94\u7528\u4e2dGDPR\u8fdd\u89c4\u68c0\u6d4b\u591a\u65b9\u6cd5\u8bc4\u4f30\u7684\u5168\u9762\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b1951\u4e2a\u624b\u52a8\u6807\u6ce8\u8fdd\u89c4\u5b9e\u4f8b\uff0c\u6db5\u76d623\u6761GDPR\u6761\u6b3e\u3002\u901a\u8fc711\u79cd\u65b9\u6cd5\u7684\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4e0d\u540c\u65b9\u6cd5\u5728\u4e0d\u540c\u4efb\u52a1\u8868\u73b0\u5404\u5f02\u3002", "motivation": "\u81ea\u52a8\u68c0\u6d4b\u6e90\u4ee3\u7801\u4e2d\u8fdd\u53cd\u6b27\u76dfGDPR\u7684\u884c\u4e3a\u662f\u91cd\u8981\u4e14\u672a\u5145\u5206\u7814\u7a76\u7684\u95ee\u9898\uff0c\u9700\u8981\u63d0\u4f9b\u4e00\u5957\u5168\u9762\u57fa\u51c6\u4ee5\u8bc4\u4f30\u4e0d\u540c\u81ea\u52a8\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "method": "\u6784\u5efa\u4e86GDPR-Bench-Android\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u591a\u7c92\u5ea6\u8fdd\u89c4\u5b9a\u4f4d\u548c\u591a\u6807\u7b7e\u5206\u7c7b\u4e24\u9879\u4efb\u52a1\uff0c\u63d0\u51faFormal-AST\u4f5c\u4e3a\u5f62\u5f0f\u5316\u57fa\u7ebf\uff0c\u8bc4\u4f308\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u3001\u68c0\u7d22\u589e\u5f3a\u6cd5\uff08RAG\uff09\u3001\u4ee3\u7406\u6cd5\uff08ReAct\uff09\u7b49\u517111\u79cd\u65b9\u6cd5\u3002", "result": "ReAct\u5728\u6587\u4ef6\u7ea7\u8fdd\u89c4\u5b9a\u4f4d\u4e0a\u8868\u73b0\u6700\u597d\uff0cQwen2.5-72B\u5728\u7ebf\u7ea7\u5b9a\u4f4d\u8868\u73b0\u9886\u5148\uff0cFormal-AST\u8f83\u5f31\u3002\u591a\u6807\u7b7e\u4efb\u52a1\u4e2d\uff0cClaude-Sonnet-4.5\u83b7\u5f97\u6700\u9ad8Macro-F1\uff0cRAG\u53d6\u5f97\u6700\u9ad8Macro-Precision\u3002\u5404\u65b9\u6cd5\u6709\u4e0d\u540c\u4f18\u52bf\uff0c\u8868\u73b0\u4efb\u52a1\u76f8\u5173\u3002", "conclusion": "\u4e0d\u540c\u81ea\u52a8\u5316\u68c0\u6d4b\u65b9\u6cd5\u5404\u6709\u4f18\u52a3\uff0c\u6ca1\u6709\u5355\u4e00\u65b9\u6cd5\u80fd\u5168\u65b9\u4f4d\u9886\u5148\uff0cGDPR-Bench-Android\u57fa\u51c6\u5bf9\u4e8e\u7cbe\u51c6\u8bca\u65ad\u65b9\u6cd5\u80fd\u529b\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002\u6240\u6709\u8d44\u6e90\u5747\u516c\u5f00\u3002"}}
{"id": "2511.00371", "categories": ["cs.CL", "cs.CY", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00371", "abs": "https://arxiv.org/abs/2511.00371", "authors": ["Erfan Al-Hossami", "Razvan Bunescu"], "title": "Reasoning Trajectories for Socratic Debugging of Student Code: From Misconceptions to Contradictions and Updated Beliefs", "comment": "25 pages, 2 tables, 13 figures", "summary": "In Socratic debugging, instructors guide students towards identifying and\nfixing a bug on their own, instead of providing the bug fix directly. Most\nnovice programmer bugs are caused by programming misconceptions, namely false\nbeliefs about a programming concept. In this context, Socratic debugging can be\nformulated as a guided Reasoning Trajectory (RT) leading to a statement about\nthe program behavior that contradicts the bug-causing misconception. Upon\nreaching this statement, the ensuing cognitive dissonance leads the student to\nfirst identify and then update their false belief. In this paper, we introduce\nthe task of reasoning trajectory generation, together with a dataset of\ndebugging problems manually annotated with RTs. We then describe LLM-based\nsolutions for generating RTs and Socratic conversations that are anchored on\nthem. A large-scale LLM-as-judge evaluation shows that frontier models can\ngenerate up to 91% correct reasoning trajectories and 98.7% valid conversation\nturns.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5f15\u5bfc\u63a8\u7406\u8f68\u8ff9\uff08Reasoning Trajectory, RT\uff09\u7684\u82cf\u683c\u62c9\u5e95\u5f0f\u8c03\u8bd5\u4efb\u52a1\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8c03\u8bd5\u5bf9\u8bdd\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8c03\u8bd5\u8fc7\u7a0b\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u5927\u591a\u6570\u521d\u5b66\u8005\u7f16\u7a0b\u9519\u8bef\u6e90\u4e8e\u5bf9\u7f16\u7a0b\u6982\u5ff5\u7684\u8bef\u89e3\uff0c\u4f20\u7edf\u76f4\u63a5\u7ed9\u51fa\u9519\u8bef\u4fee\u590d\u7684\u65b9\u5f0f\u96be\u4ee5\u4fc3\u8fdb\u5b66\u751f\u6df1\u523b\u7406\u89e3\u548c\u8ba4\u77e5\u66f4\u65b0\uff0c\u82cf\u683c\u62c9\u5e95\u5f0f\u8c03\u8bd5\u901a\u8fc7\u5f15\u5bfc\u5b66\u751f\u81ea\u4e3b\u53d1\u73b0\u5e76\u4fee\u6b63\u9519\u8bef\uff0c\u6fc0\u53d1\u8ba4\u77e5\u77db\u76fe\u4fc3\u4f7f\u5176\u4fee\u6b63\u9519\u8bef\u4fe1\u5ff5\u3002", "method": "\u672c\u6587\u5f15\u5165\u63a8\u7406\u8f68\u8ff9\u751f\u6210\u4efb\u52a1\uff0c\u5e76\u6784\u5efa\u4e86\u5e26\u6709\u624b\u5de5\u6ce8\u91ca\u63a8\u7406\u8f68\u8ff9\u7684\u8c03\u8bd5\u95ee\u9898\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b(Large Language Models, LLM)\u8bbe\u8ba1\u751f\u6210\u63a8\u7406\u8f68\u8ff9\u53ca\u57fa\u4e8e\u8f68\u8ff9\u7684\u82cf\u683c\u62c9\u5e95\u5f0f\u5bf9\u8bdd\u7684\u65b9\u6848\u3002", "result": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u5927\u89c4\u6a21\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\uff0c\u5148\u8fdb\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u6b63\u786e\u7387\u8fbe91%\uff0c\u5bf9\u8bdd\u8f6e\u6b21\u6709\u6548\u7387\u8fbe98.7%\uff0c\u8bc1\u660e\u65b9\u6cd5\u5177\u5907\u8f83\u9ad8\u7684\u5b9e\u7528\u6027\u548c\u51c6\u786e\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5f15\u5bfc\u63a8\u7406\u8f68\u8ff9\u7684\u82cf\u683c\u62c9\u5e95\u5f0f\u8c03\u8bd5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5e2e\u52a9\u5b66\u751f\u7406\u89e3\u548c\u4fee\u6b63\u7f16\u7a0b\u9519\u8bef\uff0c\u4e14\u5229\u7528\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8c03\u8bd5\u5bf9\u8bdd\u5177\u6709\u826f\u597d\u8868\u73b0\uff0c\u5177\u5907\u63a8\u5e7f\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00624", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00624", "abs": "https://arxiv.org/abs/2511.00624", "authors": ["Haoyi Zhang", "Huaijin Ran", "Xunzhu Tang"], "title": "Can Large Language Models Detect Real-World Android Software Compliance Violations?", "comment": null, "summary": "The rapid development of Large Language Models (LLMs) has transformed\nsoftware engineering, showing promise in tasks like code generation, bug\ndetection, and compliance checking. However, current models struggle to detect\ncompliance violations in Android applications across diverse legal frameworks.\nWe propose \\emph{CompliBench}, a novel evaluation framework for assessing LLMs'\nability to detect compliance violations under regulations like LGPD, PDPA, and\nPIPEDA. The framework defines two tasks: Task 1 evaluates \\emph{retrieval and\nlocalization} at file, module, and line granularities, and Task 2 assesses\n\\emph{multi-label judgment} for code snippets. These tasks mirror the audit\nprocess, where auditors locate problematic code and determine implicated\nprovisions. Traditional metrics fail to capture important aspects like\ncross-granularity stability and jurisdictional consistency. Thus, we introduce\nstability-aware composites (SGS, RCS, CRGS, and OCS) for a more comprehensive\nassessment. Experiments with six models, including GPT-4O and Claude-3.5, show\n\\emph{CompliBench} improves compliance detection, with\nClaude-3.5-sonnet-20241022 achieving the highest OCS score (0.3295), and\nGemini-2.5-pro the lowest (0.0538). This work demonstrates \\emph{CompliBench}'s\npotential for improving LLM performance in compliance tasks and provides a\nfoundation for future tools aligned with data protection standards. Our project\nis available at https://github.com/Haoyi-Zhang/CompliBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CompliBench\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u68c0\u6d4bLLM\u5728Android\u5e94\u7528\u5408\u89c4\u6027\u8fdd\u89c4\u8bc6\u522b\u4e2d\u7684\u8868\u73b0\uff0c\u6db5\u76d6\u591a\u6cd5\u5f8b\u6846\u67b6\u5e76\u5f15\u5165\u7a33\u5b9a\u6027\u7efc\u5408\u6307\u6807\u3002", "motivation": "\u5f53\u524dLLM\u5728\u4e0d\u540c\u6cd5\u5f8b\u6cd5\u89c4\u6846\u67b6\u4e0b\u8bc6\u522bAndroid\u5e94\u7528\u5408\u89c4\u6027\u8fdd\u89c4\u5b58\u5728\u56f0\u96be\uff0c\u4f20\u7edf\u8bc4\u4f30\u6307\u6807\u4e0d\u8db3\u4ee5\u5168\u9762\u8861\u91cf\u6a21\u578b\u6027\u80fd\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u4efb\u52a1\uff08\u68c0\u7d22\u4e0e\u5b9a\u4f4d\u3001\u591a\u6807\u7b7e\u5224\u65ad\uff09\uff0c\u6a21\u62df\u5ba1\u8ba1\u6d41\u7a0b\uff0c\u5f15\u5165\u7a33\u5b9a\u6027\u611f\u77e5\u7efc\u5408\u6307\u6807\uff08SGS, RCS, CRGS, OCS\uff09\u6765\u63d0\u5347\u8bc4\u4f30\u51c6\u786e\u6027\u3002", "result": "\u901a\u8fc7\u6d4b\u8bd5\u516d\u79cd\u6a21\u578b\uff0c\u53d1\u73b0CompliBench\u80fd\u663e\u8457\u63d0\u5347\u5408\u89c4\u68c0\u6d4b\u6548\u679c\uff0c\u5176\u4e2dClaude-3.5-sonnet-20241022\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "CompliBench\u4e3a\u63d0\u5347LLM\u5728\u5408\u89c4\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u63d0\u4f9b\u4e86\u6709\u6548\u8bc4\u4f30\u624b\u6bb5\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6570\u636e\u4fdd\u62a4\u6807\u51c6\u76f8\u5173\u5de5\u5177\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.00416", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00416", "abs": "https://arxiv.org/abs/2511.00416", "authors": ["Yiwei Zha", "Rui Min", "Shanu Sushmita"], "title": "PADBen: A Comprehensive Benchmark for Evaluating AI Text Detectors Against Paraphrase Attacks", "comment": null, "summary": "While AI-generated text (AIGT) detectors achieve over 90\\% accuracy on direct\nLLM outputs, they fail catastrophically against iteratively-paraphrased\ncontent. We investigate why iteratively-paraphrased text -- itself AI-generated\n-- evades detection systems designed for AIGT identification. Through intrinsic\nmechanism analysis, we reveal that iterative paraphrasing creates an\nintermediate laundering region characterized by semantic displacement with\npreserved generation patterns, which brings up two attack categories:\nparaphrasing human-authored text (authorship obfuscation) and paraphrasing\nLLM-generated text (plagiarism evasion). To address these vulnerabilities, we\nintroduce PADBen, the first benchmark systematically evaluating detector\nrobustness against both paraphrase attack scenarios. PADBen comprises a\nfive-type text taxonomy capturing the full trajectory from original content to\ndeeply laundered text, and five progressive detection tasks across\nsentence-pair and single-sentence challenges. We evaluate 11 state-of-the-art\ndetectors, revealing critical asymmetry: detectors successfully identify the\nplagiarism evasion problem but fail for the case of authorship obfuscation. Our\nfindings demonstrate that current detection approaches cannot effectively\nhandle the intermediate laundering region, necessitating fundamental advances\nin detection architectures beyond existing semantic and stylistic\ndiscrimination methods. For detailed code implementation, please see\nhttps://github.com/JonathanZha47/PadBen-Paraphrase-Attack-Benchmark.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86AI\u6587\u672c\u68c0\u6d4b\u5668\u5bf9\u4e8e\u8fed\u4ee3\u5f0f\u6539\u5199\u6587\u672c\u5931\u6548\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u8fd9\u4e00\u6f0f\u6d1e\u7684PADBen\u57fa\u51c6\u6d4b\u8bd5\u3002", "motivation": "\u5f53\u524dAI\u751f\u6210\u6587\u672c\u68c0\u6d4b\u5668\u867d\u7136\u5bf9\u76f4\u63a5\u751f\u6210\u6587\u672c\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5728\u9762\u5bf9\u7ecf\u8fc7\u591a\u6b21\u6539\u5199\u7684\u6587\u672c\u65f6\u6548\u679c\u6025\u5267\u4e0b\u964d\uff0c\u5bfc\u81f4\u68c0\u6d4b\u5931\u6548\u3002", "method": "\u901a\u8fc7\u5206\u6790\u8fed\u4ee3\u6539\u5199\u7684\u5185\u90e8\u673a\u5236\uff0c\u53d1\u73b0\u6539\u5199\u6587\u672c\u5f62\u6210\u4e86\u5e26\u6709\u8bed\u4e49\u4f4d\u79fb\u4f46\u4fdd\u7559\u751f\u6210\u6a21\u5f0f\u7684\u4e2d\u95f4\u6d17\u767d\u533a\uff0c\u63d0\u51fa\u4e24\u79cd\u653b\u51fb\u7c7b\u522b\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5305\u542b\u4e94\u79cd\u6587\u672c\u7c7b\u578b\u548c\u4e94\u4e2a\u68c0\u6d4b\u4efb\u52a1\u7684PADBen\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f3011\u4e2a\u73b0\u6709\u68c0\u6d4b\u5668\u7684\u6027\u80fd\u3002", "result": "\u68c0\u6d4b\u5668\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6284\u88ad\u89c4\u907f\u573a\u666f\uff0c\u4f46\u5bf9\u4e8e\u4f5c\u8005\u8eab\u4efd\u6df7\u6dc6\u573a\u666f\u8868\u73b0\u5dee\uff0c\u663e\u793a\u51fa\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5bf9\u4e2d\u95f4\u6d17\u767d\u533a\u65e0\u6548\u3002", "conclusion": "\u73b0\u6709\u68c0\u6d4b\u67b6\u6784\u9700\u7a81\u7834\u8bed\u4e49\u548c\u98ce\u683c\u533a\u5206\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u6839\u672c\u6539\u8fdb\u624d\u80fd\u6709\u6548\u5e94\u5bf9\u8fed\u4ee3\u6539\u5199\u6587\u672c\u7684\u68c0\u6d4b\u6311\u6218\u3002"}}
{"id": "2511.00658", "categories": ["cs.SE", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2511.00658", "abs": "https://arxiv.org/abs/2511.00658", "authors": ["Guilherme H. Travassos", "Sabrina Rocha", "Rodrigo Feitosa", "Felipe Assis", "Patricia Goncalves", "Andre Gheventer", "Larissa Galeno", "Arthur Sasse", "Julio Cesar Guimaraes", "Carlos Brito", "Joao Pedro Wieland"], "title": "Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare", "comment": "11 pages, 2 figures, in Portuguese language", "summary": "The advances and availability of technologies involving Generative Artificial\nIntelligence (AI) are evolving clearly and explicitly, driving immediate\nchanges in various work activities. Software Engineering (SE) is no exception\nand stands to benefit from these new technologies, enhancing productivity and\nquality in its software development processes. However, although the use of\nGenerative AI in SE practices is still in its early stages, considering the\nlack of conclusive results from ongoing research and the limited technological\nmaturity, we have chosen to incorporate these technologies in the development\nof a web-based software system to be used in clinical trials by a thoracic\ndiseases research group at our university. For this reason, we decided to share\nthis experience report documenting our development team's learning journey in\nusing Generative AI during the software development process. Project\nmanagement, requirements specification, design, development, and quality\nassurance activities form the scope of observation. Although we do not yet have\ndefinitive technological evidence to evolve our development process\nsignificantly, the results obtained and the suggestions shared here represent\nvaluable insights for software organizations seeking to innovate their\ndevelopment practices to achieve software quality with generative AI.", "AI": {"tldr": "\u672c\u6587\u62a5\u544a\u4e86\u5728\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u4f7f\u7528\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u7ecf\u9a8c\uff0c\u5c24\u5176\u662f\u5728\u4e34\u5e8a\u8bd5\u9a8c\u76f8\u5173\u7cfb\u7edf\u7684\u5f00\u53d1\u4e2d\uff0c\u6db5\u76d6\u9879\u76ee\u7ba1\u7406\u3001\u9700\u6c42\u3001\u8bbe\u8ba1\u3001\u5f00\u53d1\u548c\u8d28\u91cf\u4fdd\u8bc1\u7b49\u73af\u8282\u3002", "motivation": "\u5c3d\u7ba1\u751f\u6210\u5f0fAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u5c1a\u5904\u4e8e\u521d\u671f\uff0c\u6280\u672f\u6210\u719f\u5ea6\u6709\u9650\uff0c\u4e14\u7814\u7a76\u7ed3\u679c\u5c1a\u4e0d\u786e\u5b9a\uff0c\u4f5c\u8005\u56e2\u961f\u5e0c\u671b\u63a2\u7d22\u5176\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u6f5c\u529b\uff0c\u63a8\u52a8\u8f6f\u4ef6\u8d28\u91cf\u548c\u751f\u4ea7\u529b\u7684\u63d0\u5347\u3002", "method": "\u56e2\u961f\u57fa\u4e8e\u751f\u6210\u5f0fAI\u6280\u672f\uff0c\u5f00\u53d1\u7528\u4e8e\u80f8\u90e8\u75be\u75c5\u4e34\u5e8a\u8bd5\u9a8c\u7684\u7f51\u7edc\u8f6f\u4ef6\u7cfb\u7edf\uff0c\u5e76\u8bb0\u5f55\u6574\u4e2a\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u5b66\u4e60\u4e0e\u5b9e\u8df5\u7ecf\u5386\uff0c\u91cd\u70b9\u89c2\u5bdf\u9879\u76ee\u7ba1\u7406\u3001\u9700\u6c42\u5b9a\u4e49\u3001\u8bbe\u8ba1\u3001\u7f16\u7801\u53ca\u8d28\u91cf\u4fdd\u969c\u73af\u8282\u7684\u5e94\u7528\u60c5\u51b5\u3002", "result": "\u867d\u7136\u5c1a\u65e0\u663e\u8457\u6280\u672f\u8bc1\u636e\u8868\u660e\u5f00\u53d1\u6d41\u7a0b\u6709\u91cd\u5927\u6539\u8fdb\uff0c\u4f46\u79ef\u7d2f\u7684\u7ecf\u9a8c\u548c\u5206\u4eab\u7684\u5b9e\u8df5\u5efa\u8bae\u4e3a\u5176\u4ed6\u8f6f\u4ef6\u7ec4\u7ec7\u91c7\u7eb3\u751f\u6210\u5f0fAI\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u53c2\u8003\u3002", "conclusion": "\u751f\u6210\u5f0fAI\u6709\u671b\u4fc3\u8fdb\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u7684\u521b\u65b0\u548c\u8d28\u91cf\u63d0\u5347\uff0c\u5c3d\u7ba1\u76ee\u524d\u4ecd\u5904\u65e9\u671f\u9636\u6bb5\uff0c\u672c\u6587\u7ecf\u9a8c\u5bf9\u63a8\u52a8\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u7684\u53d1\u5c55\u5177\u6709\u542f\u793a\u610f\u4e49\u3002"}}
{"id": "2511.00421", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00421", "abs": "https://arxiv.org/abs/2511.00421", "authors": ["Naoto Iwase", "Hiroki Okuyama", "Junichiro Iwasawa"], "title": "MedRECT: A Medical Reasoning Benchmark for Error Correction in Clinical Texts", "comment": null, "summary": "Large language models (LLMs) show increasing promise in medical applications,\nbut their ability to detect and correct errors in clinical texts -- a\nprerequisite for safe deployment -- remains under-evaluated, particularly\nbeyond English. We introduce MedRECT, a cross-lingual benchmark\n(Japanese/English) that formulates medical error handling as three subtasks:\nerror detection, error localization (sentence extraction), and error\ncorrection. MedRECT is built with a scalable, automated pipeline from the\nJapanese Medical Licensing Examinations (JMLE) and a curated English\ncounterpart, yielding MedRECT-ja (663 texts) and MedRECT-en (458 texts) with\ncomparable error/no-error balance. We evaluate 9 contemporary LLMs spanning\nproprietary, open-weight, and reasoning families. Key findings: (i) reasoning\nmodels substantially outperform standard architectures, with up to 13.5%\nrelative improvement in error detection and 51.0% in sentence extraction; (ii)\ncross-lingual evaluation reveals 5-10% performance gaps from English to\nJapanese, with smaller disparities for reasoning models; (iii) targeted LoRA\nfine-tuning yields asymmetric improvements in error correction performance\n(Japanese: +0.078, English: +0.168) while preserving reasoning capabilities;\nand (iv) our fine-tuned model exceeds human expert performance on structured\nmedical error correction tasks. To our knowledge, MedRECT is the first\ncomprehensive cross-lingual benchmark for medical error correction, providing a\nreproducible framework and resources for developing safer medical LLMs across\nlanguages.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86MedRECT\uff0c\u4e00\u4e2a\u8de8\u8bed\u8a00\uff08\u65e5\u8bed/\u82f1\u8bed\uff09\u7684\u533b\u7597\u9519\u8bef\u68c0\u6d4b\u4e0e\u7ea0\u6b63\u57fa\u51c6\uff0c\u8bc4\u4ef7\u4e869\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u91cd\u70b9\u63d0\u5347\u4e86\u63a8\u7406\u6a21\u578b\u7684\u8868\u73b0\u5e76\u5b9e\u73b0\u4e86\u8d85\u8d8a\u4eba\u7c7b\u4e13\u5bb6\u7684\u7ea0\u6b63\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7684\u9519\u8bef\u68c0\u6d4b\u548c\u7ea0\u6b63\u80fd\u529b\u5c1a\u672a\u5145\u5206\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u975e\u82f1\u8bed\u8bed\u5883\u4e0b\u7684\u8868\u73b0\u4e9f\u9700\u7814\u7a76\uff0c\u4ee5\u4fdd\u8bc1\u5176\u5728\u4e34\u5e8a\u4e2d\u7684\u5b89\u5168\u5e94\u7528\u3002", "method": "\u6784\u5efa\u4e86\u6db5\u76d6\u65e5\u8bed\u548c\u82f1\u8bed\u7684MedRECT\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b\u9519\u8bef\u68c0\u6d4b\u3001\u9519\u8bef\u5b9a\u4f4d\u548c\u9519\u8bef\u7ea0\u6b63\u4e09\u4e2a\u5b50\u4efb\u52a1\uff0c\u91c7\u7528\u81ea\u52a8\u5316\u6784\u5efa\u6d41\u7a0b\u5e76\u5f15\u5165\u591a\u79cd\u7c7b\u578b\u7684\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u540c\u65f6\u901a\u8fc7LoRA\u5fae\u8c03\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "result": "\u63a8\u7406\u6a21\u578b\u5728\u9519\u8bef\u68c0\u6d4b\u548c\u53e5\u5b50\u63d0\u53d6\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u8de8\u8bed\u8a00\u8bc4\u6d4b\u663e\u793a\u65e5\u8bed\u8868\u73b0\u4e0b\u964d\u4f46\u63a8\u7406\u6a21\u578b\u5dee\u8ddd\u8f83\u5c0f\uff0cLoRA\u5fae\u8c03\u5728\u4e24\u79cd\u8bed\u8a00\u4e2d\u5e26\u6765\u4e0d\u540c\u7a0b\u5ea6\u63d0\u5347\uff0c\u5e76\u4e14\u5fae\u8c03\u540e\u6a21\u578b\u5728\u7ed3\u6784\u5316\u533b\u7597\u9519\u8bef\u7ea0\u6b63\u4efb\u52a1\u4e0a\u8d85\u8fc7\u4e86\u4eba\u7c7b\u4e13\u5bb6\u6c34\u5e73\u3002", "conclusion": "MedRECT\u4f5c\u4e3a\u9996\u4e2a\u8de8\u8bed\u8a00\u533b\u7597\u9519\u8bef\u7ea0\u6b63\u57fa\u51c6\uff0c\u4e3a\u5b89\u5168\u533b\u7597\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u8bed\u79cd\u5f00\u53d1\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u7684\u6570\u636e\u548c\u8bc4\u6d4b\u6846\u67b6\uff0c\u63a8\u52a8\u4e86\u533b\u7597\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5e94\u7528\u8fdb\u5c55\u3002"}}
{"id": "2511.00678", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00678", "abs": "https://arxiv.org/abs/2511.00678", "authors": ["Tasmia Zerin", "Moumita Asad", "B. M. Mainul Hossain", "Kazi Sakib"], "title": "Repairing Responsive Layout Failures Using Retrieval Augmented Generation", "comment": "Accepted at the 41st IEEE International Conference on Software\n  Maintenance and Evolution 2025 (ICSME'25)", "summary": "Responsive websites frequently experience distorted layouts at specific\nscreen sizes, called Responsive Layout Failures (RLFs). Manually repairing\nthese RLFs involves tedious trial-and-error adjustments of HTML elements and\nCSS properties. In this study, an automated repair approach, leveraging LLM\ncombined with domain-specific knowledge is proposed. The approach is named\nReDeFix, a Retrieval-Augmented Generation (RAG)-based solution that utilizes\nStack Overflow (SO) discussions to guide LLM on CSS repairs. By augmenting\nrelevant SO knowledge with RLF-specific contexts, ReDeFix creates a prompt that\nis sent to the LLM to generate CSS patches. Evaluation demonstrates that our\napproach achieves an 88\\% accuracy in repairing RLFs. Furthermore, a study from\nsoftware engineers reveals that generated repairs produce visually correct\nlayouts while maintaining aesthetics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ReDeFix\uff0c\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u9886\u57df\u77e5\u8bc6\u81ea\u52a8\u4fee\u590d\u54cd\u5e94\u5f0f\u5e03\u5c40\u5931\u8d25\uff08RLFs\uff09\u7684\u5de5\u5177\uff0c\u5229\u7528Stack Overflow\u8ba8\u8bba\u6307\u5bfcCSS\u4fee\u590d\uff0c\u4fee\u590d\u51c6\u786e\u7387\u8fbe88%\u3002", "motivation": "\u54cd\u5e94\u5f0f\u7f51\u7ad9\u5728\u7279\u5b9a\u5c4f\u5e55\u5c3a\u5bf8\u4e0b\u5e38\u51fa\u73b0\u5e03\u5c40\u5931\u771f\uff08RLFs\uff09\uff0c\u624b\u52a8\u4fee\u590d\u8017\u65f6\u8d39\u529b\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u65b9\u6cd5ReDeFix\uff0c\u7ed3\u5408Stack Overflow\u76f8\u5173\u8ba8\u8bba\u548cRLF\u4e0a\u4e0b\u6587\u751f\u6210CSS\u4fee\u8865\u4ee3\u7801\u3002", "result": "\u8bc4\u4f30\u663e\u793aReDeFix\u5728\u4fee\u590dRLF\u65b9\u9762\u8fbe\u621088%\u7684\u51c6\u786e\u7387\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8bc4\u4f30\u786e\u8ba4\u4fee\u590d\u7684\u5e03\u5c40\u89c6\u89c9\u6548\u679c\u6b63\u786e\u4e14\u7f8e\u89c2\u3002", "conclusion": "ReDeFix\u6709\u6548\u5229\u7528\u9886\u57df\u77e5\u8bc6\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4fee\u590d\u54cd\u5e94\u5f0f\u5e03\u5c40\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u4fee\u590d\u6548\u7387\u548c\u6548\u679c\u3002"}}
{"id": "2511.00432", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00432", "abs": "https://arxiv.org/abs/2511.00432", "authors": ["Zhiwen Ruan", "Yixia Li", "Yefeng Liu", "Yun Chen", "Weihua Luo", "Peng Li", "Yang Liu", "Guanhua Chen"], "title": "G2: Guided Generation for Enhanced Output Diversity in LLMs", "comment": "EMNLP 2025", "summary": "Large Language Models (LLMs) have demonstrated exceptional performance across\ndiverse natural language processing tasks. However, these models exhibit a\ncritical limitation in output diversity, often generating highly similar\ncontent across multiple attempts. This limitation significantly affects tasks\nrequiring diverse outputs, from creative writing to reasoning. Existing\nsolutions, like temperature scaling, enhance diversity by modifying probability\ndistributions but compromise output quality. We propose Guide-to-Generation\n(G2), a training-free plug-and-play method that enhances output diversity while\npreserving generation quality. G2 employs a base generator alongside dual\nGuides, which guide the generation process through decoding-based interventions\nto encourage more diverse outputs conditioned on the original query.\nComprehensive experiments demonstrate that G2 effectively improves output\ndiversity while maintaining an optimal balance between diversity and quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u7684\u63d2\u4ef6\u5f0f\u65b9\u6cd5G2\uff0c\u5229\u7528\u53cc\u5f15\u5bfc\u673a\u5236\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\u591a\u6837\u6027\uff0c\u4e14\u4fdd\u6301\u751f\u6210\u8d28\u91cf\uff0c\u5b9e\u73b0\u591a\u6837\u6027\u4e0e\u8d28\u91cf\u7684\u5e73\u8861\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u591a\u6837\u6027\u65b9\u9762\u5b58\u5728\u4e25\u91cd\u9650\u5236\uff0c\u5e38\u751f\u6210\u9ad8\u5ea6\u76f8\u4f3c\u7684\u5185\u5bb9\uff0c\u5f71\u54cd\u521b\u610f\u5199\u4f5c\u4e0e\u63a8\u7406\u7b49\u4efb\u52a1\u7684\u6548\u679c\uff0c\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u591a\u6837\u6027\u5f80\u5f80\u727a\u7272\u8d28\u91cf\u3002", "method": "G2\u65b9\u6cd5\u7ed3\u5408\u57fa\u7840\u751f\u6210\u5668\u4e0e\u4e24\u4e2a\u5f15\u5bfc\u5668\uff0c\u901a\u8fc7\u89e3\u7801\u5e72\u9884\u5f15\u5bfc\u751f\u6210\u8fc7\u7a0b\uff0c\u4fc3\u8fdb\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\u7684\u591a\u6837\u8f93\u51fa\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eG2\u663e\u8457\u63d0\u5347\u4e86\u8f93\u51fa\u591a\u6837\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u751f\u6210\u8d28\u91cf\u7684\u6700\u4f73\u5e73\u8861\uff0c\u6539\u5584\u4e86\u751f\u6210\u5185\u5bb9\u7684\u4e30\u5bcc\u6027\u3002", "conclusion": "G2\u662f\u4e00\u79cd\u6709\u6548\u7684\u8bad\u7ec3-free\u7b56\u7565\uff0c\u80fd\u5728\u4fdd\u8bc1\u751f\u6210\u8d28\u91cf\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7684\u591a\u6837\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u3002"}}
{"id": "2511.00706", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00706", "abs": "https://arxiv.org/abs/2511.00706", "authors": ["Marcos Vinicius Cruz", "Pragya Verma", "Grischa Liebel"], "title": "An Empirical Investigation of the Experiences of Dyslexic Software Engineers", "comment": null, "summary": "Dyslexia is a common learning disorder that primarily impairs an individual's\nreading and writing abilities. In adults, dyslexia can affect both professional\nand personal lives, often leading to mental challenges and difficulties\nacquiring and keeping work. In Software Engineering (SE), reading and writing\ndifficulties appear to pose substantial challenges for core tasks such as\nprogramming. However, initial studies indicate that these challenges may not\nsignificantly affect their performance compared to non-dyslexic colleagues.\nConversely, strengths associated with dyslexia could be particularly valuable\nin areas like programming and design. However, there is currently no work that\nexplores the experiences of dyslexic software engineers, and puts their\nstrengths into relation with their difficulties. To address this, we present a\nqualitative study of the experiences of dyslexic individuals in SE. We followed\nthe basic stage of the Socio-Technical Grounded Theory method and base our\nfindings on data collected through 10 interviews with dyslexic software\nengineers, 3 blog posts and 153 posts on the social media platform Reddit. We\nfind that dyslexic software engineers especially struggle at the programming\nlearning stage, but can succeed and indeed excel at many SE tasks once they\nmaster this step. Common SE-specific support tools, such as code completion and\nlinters are especially useful to these individuals and mitigate many of the\nexperienced difficulties. Finally, dyslexic software engineers exhibit\nstrengths in areas such as visual thinking and creativity. Our findings have\nimplications to SE practice and motivate several areas of future research in\nSE, such as investigating what makes code less/more understandable to dyslexic\nindividuals.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9a\u6027\u7814\u7a76\u63a2\u8ba8\u4e86\u9605\u8bfb\u969c\u788d\uff08\u5931\u8bfb\u75c7\uff09\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u7ecf\u5386\uff0c\u53d1\u73b0\u4ed6\u4eec\u5728\u7f16\u7a0b\u5b66\u4e60\u9636\u6bb5\u9047\u5230\u8f83\u5927\u56f0\u96be\uff0c\u4f46\u638c\u63e1\u6280\u80fd\u540e\u80fd\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e14\u5177\u5907\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u7b49\u4f18\u52bf\u3002", "motivation": "\u5c3d\u7ba1\u5931\u8bfb\u75c7\u5f71\u54cd\u9605\u8bfb\u548c\u5199\u4f5c\u80fd\u529b\uff0c\u4f46\u5176\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u7684\u5f71\u54cd\u53ca\u6f5c\u5728\u4f18\u52bf\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u9700\u8981\u4e86\u89e3\u5931\u8bfb\u75c7\u5de5\u7a0b\u5e08\u7684\u5b9e\u9645\u7ecf\u5386\u53ca\u6311\u6218\u3002", "method": "\u91c7\u7528\u793e\u4f1a\u6280\u672f\u6839\u57fa\u7406\u8bba\u7684\u57fa\u7840\u9636\u6bb5\uff0c\u901a\u8fc710\u6b21\u5931\u8bfb\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u8bbf\u8c08\u30013\u7bc7\u535a\u5ba2\u548c153\u6761Reddit\u793e\u4ea4\u5e73\u53f0\u5e16\u5b50\u8fdb\u884c\u6570\u636e\u6536\u96c6\u548c\u5206\u6790\u3002", "result": "\u5931\u8bfb\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u5b66\u4e60\u7f16\u7a0b\u65f6\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u4f46\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u3001\u4ee3\u7801\u68c0\u67e5\u5de5\u5177\u7b49\u652f\u6301\u5de5\u5177\u80fd\u6709\u6548\u7f13\u89e3\u56f0\u96be\u3002\u4e00\u65e6\u638c\u63e1\u7f16\u7a0b\uff0c\u8868\u73b0\u4e0d\u900a\u8272\u4e14\u5728\u89c6\u89c9\u601d\u7ef4\u548c\u521b\u9020\u529b\u65b9\u9762\u6709\u4f18\u52bf\u3002", "conclusion": "\u5931\u8bfb\u75c7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u6709\u72ec\u7279\u7684\u4f18\u52bf\u548c\u6311\u6218\uff0c\u7814\u7a76\u7ed3\u679c\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u5b9e\u8df5\u6709\u542f\u793a\uff0c\u672a\u6765\u7814\u7a76\u53ef\u9488\u5bf9\u5982\u4f55\u63d0\u9ad8\u4ee3\u7801\u5bf9\u5931\u8bfb\u75c7\u8005\u7684\u53ef\u7406\u89e3\u6027\u5c55\u5f00\u3002"}}
{"id": "2511.00476", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00476", "abs": "https://arxiv.org/abs/2511.00476", "authors": ["Ghazal Kalhor", "Afra Mashhadi"], "title": "Remembering Unequally: Global and Disciplinary Bias in LLM-Generated Co-Authorship Networks", "comment": null, "summary": "Ongoing breakthroughs in Large Language Models (LLMs) are reshaping search\nand recommendation platforms at their core. While this shift unlocks powerful\nnew scientometric tools, it also exposes critical fairness and bias issues that\ncould erode the integrity of the information ecosystem. Additionally, as LLMs\nbecome more integrated into web-based searches for scholarly tools, their\nability to generate summarized research work based on memorized data introduces\nnew dimensions to these challenges. The extent of memorization in LLMs can\nimpact the accuracy and fairness of the co-authorship networks they produce,\npotentially reflecting and amplifying existing biases within the scientific\ncommunity and across different regions. This study critically examines the\nimpact of LLM memorization on the co-authorship networks. To this end, we\nassess memorization effects across three prominent models, DeepSeek R1, Llama 4\nScout, and Mixtral 8x7B, analyzing how memorization-driven outputs vary across\nacademic disciplines and world regions. While our global analysis reveals a\nconsistent bias favoring highly cited researchers, this pattern is not\nuniformly observed. Certain disciplines, such as Clinical Medicine, and\nregions, including parts of Africa, show more balanced representation, pointing\nto areas where LLM training data may reflect greater equity. These findings\nunderscore both the risks and opportunities in deploying LLMs for scholarly\ndiscovery.", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u7684\u8bb0\u5fc6\u673a\u5236\u5bf9\u5b66\u672f\u5408\u8457\u7f51\u7edc\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u8bb0\u5fc6\u53ef\u80fd\u5e26\u6765\u7684\u516c\u5e73\u6027\u548c\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLMs\u5728\u5b66\u672f\u641c\u7d22\u548c\u63a8\u8350\u9886\u57df\u7684\u5e94\u7528\u65e5\u76ca\u589e\u52a0\uff0c\u5176\u57fa\u4e8e\u8bb0\u5fc6\u751f\u6210\u7684\u7ed3\u679c\u53ef\u80fd\u653e\u5927\u79d1\u7814\u5408\u4f5c\u7f51\u7edc\u4e2d\u7684\u73b0\u6709\u504f\u89c1\uff0c\u5f71\u54cd\u4fe1\u606f\u751f\u6001\u7684\u516c\u6b63\u6027\u3002", "method": "\u8bc4\u4f30\u4e09\u79cd\u4e3b\u6d41LLMs\uff08DeepSeek R1\u3001Llama 4 Scout\u548cMixtral 8x7B\uff09\u5728\u4e0d\u540c\u5b66\u79d1\u548c\u5730\u533a\u4e0a\u7684\u8bb0\u5fc6\u5f71\u54cd\uff0c\u5206\u6790\u5176\u8f93\u51fa\u7ed3\u679c\u7684\u516c\u5e73\u6027\u548c\u504f\u89c1\u8868\u73b0\u3002", "result": "\u5168\u7403\u8303\u56f4\u5185\uff0c\u6a21\u578b\u666e\u904d\u504f\u5411\u5f15\u7528\u91cf\u9ad8\u7684\u7814\u7a76\u8005\uff0c\u4f46\u5728\u4e34\u5e8a\u533b\u5b66\u7b49\u5b66\u79d1\u548c\u975e\u6d32\u90e8\u5206\u5730\u533a\u7684\u8868\u73b0\u8f83\u4e3a\u5e73\u8861\uff0c\u4f53\u73b0\u4e86\u8bad\u7ec3\u6570\u636e\u4e2d\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "LLMs\u5728\u5b66\u672f\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u65e2\u5e26\u6765\u98ce\u9669\uff0c\u4e5f\u5b58\u5728\u4fc3\u8fdb\u516c\u5e73\u7684\u53ef\u80fd\uff0c\u9700\u8b66\u60d5\u8bb0\u5fc6\u504f\u89c1\uff0c\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u4ee5\u63d0\u5347\u4fe1\u606f\u7684\u516c\u6b63\u6027\u3002"}}
{"id": "2511.00776", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00776", "abs": "https://arxiv.org/abs/2511.00776", "authors": ["Cuiyun Gao", "Guodong Fan", "Chun Yong Chong", "Shizhan Chen", "Chao Liu", "David Lo", "Zibin Zheng", "Qing Liao"], "title": "A Systematic Literature Review of Code Hallucinations in LLMs: Characterization, Mitigation Methods, Challenges, and Future Directions for Reliable AI", "comment": null, "summary": "Model hallucination is one of the most critical challenges faced by Large\nLanguage Models (LLMs), especially in high-stakes code intelligence tasks. As\nLLMs become increasingly integrated into software engineering tasks,\nunderstanding and mitigating hallucination in code becomes essential. In this\nsurvey, we provide a systematic review of hallucination phenomena in\ncode-oriented LLMs from four key perspectives. First, we begin by surveying 60\npapers to define hallucination in the context of code and summarize its primary\ncauses, such as data noise, exposure bias, and insufficient semantic grounding,\nwhile also tracing recent trends in literature across natural language\nprocessing (NLP) and software engineering communities. Second, we review model\nhallucination surveys in a broader span and summarize representative\nhallucination mitigation strategies, such as knowledge-enhanced generation,\nconstrained decoding, and post-editing. Third, we review approaches targeted\nfor code intelligence and highlight code-specific challenges that aggravate\nhallucination, including syntax sensitivity, strict type systems, and\ndependence on external libraries. Meanwhile, we analyze how emerging code\nintelligence tasks, e.g., program analysis, symbolic execution, and unit\ntesting, are utilized to detect and mitigate hallucinations. Fourth, we\nsummarize current evaluation benchmarks, ranging from static metrics to dynamic\nchecks, e.g., compilation and execution correctness, and emphasize the need for\nhallucination-oriented benchmarks.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u4ee3\u7801\u76f8\u5173\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u6db5\u76d6\u5b9a\u4e49\u3001\u6210\u56e0\u3001\u7f13\u89e3\u7b56\u7565\u3001\u4ee3\u7801\u9886\u57df\u7279\u6709\u6311\u6218\u53ca\u8bc4\u4f30\u57fa\u51c6\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u7406\u89e3\u5e76\u7f13\u89e3\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\u53d8\u5f97\u5c24\u4e3a\u5173\u952e\u3002", "method": "\u901a\u8fc7\u56de\u987e60\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u5206\u6790\u5e7b\u89c9\u7684\u5b9a\u4e49\u53ca\u6210\u56e0\uff0c\u7efc\u8ff0\u5e7f\u6cdb\u9886\u57df\u7684\u5e7b\u89c9\u7f13\u89e3\u65b9\u6cd5\uff0c\u805a\u7126\u4ee3\u7801\u667a\u80fd\u4e2d\u7684\u7279\u6709\u6311\u6218\u4e0e\u5229\u7528\u4ee3\u7801\u667a\u80fd\u4efb\u52a1\u7684\u68c0\u6d4b\u7f13\u89e3\u7b56\u7565\uff0c\u6700\u540e\u603b\u7ed3\u76f8\u5173\u8bc4\u4f30\u57fa\u51c6\u3002", "result": "\u603b\u7ed3\u4e86\u6570\u636e\u566a\u58f0\u3001\u66b4\u9732\u504f\u5dee\u3001\u8bed\u4e49\u57fa\u7840\u8584\u5f31\u7b49\u5e7b\u89c9\u539f\u56e0\uff0c\u4ecb\u7ecd\u77e5\u8bc6\u589e\u5f3a\u751f\u6210\u3001\u53d7\u9650\u89e3\u7801\u548c\u540e\u671f\u7f16\u8f91\u7b49\u7f13\u89e3\u6280\u672f\uff0c\u6307\u51fa\u4ee3\u7801\u9886\u57df\u8bed\u6cd5\u654f\u611f\u3001\u5f3a\u7c7b\u578b\u7cfb\u7edf\u548c\u5916\u90e8\u5e93\u4f9d\u8d56\u52a0\u5267\u5e7b\u89c9\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u4f7f\u7528\u7a0b\u5e8f\u5206\u6790\u3001\u7b26\u53f7\u6267\u884c\u548c\u5355\u5143\u6d4b\u8bd5\u7b49\u4efb\u52a1\u4f5c\u4e3a\u68c0\u6d4b\u624b\u6bb5\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u4ee3\u7801\u751f\u6210\u5e7b\u89c9\u95ee\u9898\u7684\u590d\u6742\u6027\u548c\u7d27\u8feb\u6027\uff0c\u63d0\u51fa\u4e86\u9488\u5bf9\u6027\u7684\u7f13\u89e3\u7b56\u7565\u548c\u8bc4\u4f30\u9700\u6c42\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6307\u5bfc\u548c\u65b9\u5411\u3002"}}
{"id": "2511.00486", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00486", "abs": "https://arxiv.org/abs/2511.00486", "authors": ["Pooja Singh", "Shashwat Bhardwaj", "Vaibhav Sharma", "Sandeep Kumar"], "title": "Leveraging the Cross-Domain & Cross-Linguistic Corpus for Low Resource NMT: A Case Study On Bhili-Hindi-English Parallel Corpus", "comment": "Accepted in EMNLP 2025", "summary": "The linguistic diversity of India poses significant machine translation\nchallenges, especially for underrepresented tribal languages like Bhili, which\nlack high-quality linguistic resources. This paper addresses the gap by\nintroducing Bhili-Hindi-English Parallel Corpus (BHEPC), the first and largest\nparallel corpus worldwide comprising 110,000 meticulously curated sentences\nacross Bhili, Hindi, and English. The corpus was created with the assistance of\nexpert human translators. BHEPC spans critical domains such as education,\nadministration, and news, establishing a valuable benchmark for research in low\nresource machine translation. To establish a comprehensive Bhili Machine\nTranslation benchmark, we evaluated a wide range of proprietary and open-source\nMultilingual Large Language Models (MLLMs) on bidirectional translation tasks\nbetween English/Hindi and Bhili. Comprehensive evaluation demonstrates that the\nfine-tuned NLLB-200 distilled 600M variant model outperforms others,\nhighlighting the potential of multilingual models in low resource scenarios.\nFurthermore, we investigated the generative translation capabilities of\nmultilingual LLMs on BHEPC using in-context learning, assessing performance\nunder cross-domain generalization and quantifying distributional divergence.\nThis work bridges a critical resource gap and promotes inclusive natural\nlanguage processing technologies for low-resource and marginalized languages\nglobally.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5168\u7403\u9996\u4e2a\u4e5f\u662f\u6700\u5927\u89c4\u6a21\u7684Bhili-\u5370\u5730\u8bed-\u82f1\u8bed\u4e09\u8bed\u5e76\u884c\u8bed\u6599\u5e93\uff0c\u5305\u542b11\u4e07\u53e5\uff0c\u65e8\u5728\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u7684\u90e8\u843d\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u7814\u7a76\u3002", "motivation": "\u5370\u5ea6\u8bed\u8a00\u591a\u6837\u6027\u5e26\u6765\u4e86\u673a\u5668\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u50cfBhili\u8fd9\u6837\u8d44\u6e90\u6781\u5c11\u7684\u90e8\u843d\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u8bed\u6599\u3002", "method": "\u6784\u5efa\u4e86\u7531\u4e13\u5bb6\u7ffb\u8bd1\u4eba\u5458\u7cbe\u5fc3\u6821\u5bf9\u7684\u4e09\u8bed\u5e76\u884c\u8bed\u6599\u5e93BHEPC\uff0c\u5e76\u8bc4\u6d4b\u591a\u79cd\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728Bhili\u4e0e\u5370\u5730\u8bed\u3001\u82f1\u8bed\u4e4b\u95f4\u7684\u7ffb\u8bd1\u6027\u80fd\uff0c\u5c24\u5176\u9488\u5bf9NLLB-200\u6a21\u578b\u8fdb\u884c\u4e86\u5fae\u8c03\u548c\u8bc4\u6d4b\uff0c\u540c\u65f6\u8003\u5bdf\u4e86\u591a\u8bed\u8a00\u5927\u6a21\u578b\u7684\u751f\u6210\u7ffb\u8bd1\u80fd\u529b\u548c\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5fae\u8c03\u540e\u7684NLLB-200 600M\u6a21\u578b\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u8868\u660e\u591a\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u4e2d\u6f5c\u529b\u5de8\u5927\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u6781\u5927\u5f25\u8865\u4e86Bhili\u8bed\u8a00\u8d44\u6e90\u7684\u7a7a\u7f3a\uff0c\u63a8\u52a8\u4e86\u8fb9\u7f18\u548c\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6280\u672f\u53d1\u5c55\uff0c\u4fc3\u8fdb\u4e86\u8bed\u8a00\u5e73\u7b49\u4e0e\u5305\u5bb9\u3002"}}
{"id": "2511.00780", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00780", "abs": "https://arxiv.org/abs/2511.00780", "authors": ["Chenyu Zhao", "Shenglin Zhang", "Zeshun Huang", "Weilin Jin", "Yongqian Sun", "Dan Pei", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Minghua Ma"], "title": "Can Language Models Go Beyond Coding? Assessing the Capability of Language Models to Build Real-World Systems", "comment": null, "summary": "Large language models (LLMs) have shown growing potential in software\nengineering, yet few benchmarks evaluate their ability to repair software\nduring migration across instruction set architectures (ISAs). Cross-ISA\nmigration, such as between x86_64 and aarch64, requires handling complex\ndependencies, heterogeneous toolchains, and long build logs while ensuring\nexecutable verification. To address this challenge, we present Build-bench, an\nend-to-end benchmark that systematically evaluates the capability of LLMs to\nrepair build failures in cross-ISA settings. Build-bench collects 268\nreal-world failed packages and integrates auxiliary tools including Structure\nExtraction, File Content Extraction, Content Modification, and Build\nVerification to support autonomous, tool-augmented reasoning. The repair\nprocess operates in an iterative loop where, upon failure, the model receives\nupdated build logs and previous repair outcomes to refine subsequent attempts.\nThrough a comparative evaluation of six representative LLMs, Build-bench\nreveals that current models achieve a maximum build success rate of 63% and\ntool usage patterns differ significantly across models. By coupling real build\nenvironments with verifiable outcomes, Build-bench establishes the first\narchitecture-aware benchmark for studying LLM-based software build and repair.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Build-bench\uff0c\u4e00\u4e2a\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u8f6f\u4ef6\u8fc1\u79fb\u4e2d\u4fee\u590d\u6784\u5efa\u5931\u8d25\u80fd\u529b\u7684\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u5f88\u5c11\u6709\u57fa\u51c6\u80fd\u591f\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\uff08\u5982x86_64\u5230aarch64\uff09\u8f6f\u4ef6\u8fc1\u79fb\u65f6\u4fee\u590d\u6784\u5efa\u5931\u8d25\u7684\u80fd\u529b\uff0c\u800c\u8fd9\u7c7b\u8fc1\u79fb\u9700\u8981\u5e94\u5bf9\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\u3001\u5f02\u6784\u5de5\u5177\u94fe\u548c\u957f\u6784\u5efa\u65e5\u5fd7\u3002", "method": "Build-bench\u6536\u96c6\u4e86268\u4e2a\u771f\u5b9e\u6784\u5efa\u5931\u8d25\u7684\u8f6f\u4ef6\u5305\uff0c\u96c6\u6210\u4e86\u7ed3\u6784\u63d0\u53d6\u3001\u6587\u4ef6\u5185\u5bb9\u63d0\u53d6\u3001\u5185\u5bb9\u4fee\u6539\u548c\u6784\u5efa\u9a8c\u8bc1\u7b49\u8f85\u52a9\u5de5\u5177\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u8fed\u4ee3\u5f0f\u4fee\u590d\u6d41\u7a0b\uff0c\u4f7f\u6a21\u578b\u5728\u5931\u8d25\u540e\u80fd\u6839\u636e\u66f4\u65b0\u7684\u6784\u5efa\u65e5\u5fd7\u548c\u524d\u6b21\u4fee\u590d\u7ed3\u679c\u4e0d\u65ad\u4f18\u5316\u3002", "result": "\u901a\u8fc7\u5bf9\u516d\u4e2a\u4ee3\u8868\u6027\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6bd4\u8f83\u8bc4\u4f30\uff0cBuild-bench\u8868\u660e\u5f53\u524d\u6a21\u578b\u7684\u6700\u5927\u6784\u5efa\u6210\u529f\u7387\u4e3a63%\uff0c\u4e14\u5404\u6a21\u578b\u7684\u5de5\u5177\u4f7f\u7528\u6a21\u5f0f\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "Build-bench\u9996\u6b21\u7ed3\u5408\u771f\u5b9e\u6784\u5efa\u73af\u5883\u4e0e\u53ef\u9a8c\u8bc1\u7ed3\u679c\uff0c\u5efa\u7acb\u4e86\u9488\u5bf9\u8de8\u67b6\u6784\u8f6f\u4ef6\u6784\u5efa\u4e0e\u4fee\u590d\u7684\u9996\u4e2a\u67b6\u6784\u611f\u77e5\u57fa\u51c6\uff0c\u6709\u52a9\u4e8e\u63a8\u8fdb\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u3002"}}
{"id": "2511.00487", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00487", "abs": "https://arxiv.org/abs/2511.00487", "authors": ["Stephen Meisenbacher", "Florian Matthes"], "title": "With Privacy, Size Matters: On the Importance of Dataset Size in Differentially Private Text Rewriting", "comment": "11 pages, 1 figure, 5 tables. Accepted to IJCNLP-AACL 2025 (Main)", "summary": "Recent work in Differential Privacy with Natural Language Processing (DP NLP)\nhas proposed numerous promising techniques in the form of text rewriting\nmechanisms. In the evaluation of these mechanisms, an often-ignored aspect is\nthat of dataset size, or rather, the effect of dataset size on a mechanism's\nefficacy for utility and privacy preservation. In this work, we are the first\nto introduce this factor in the evaluation of DP text privatization, where we\ndesign utility and privacy tests on large-scale datasets with dynamic split\nsizes. We run these tests on datasets of varying size with up to one million\ntexts, and we focus on quantifying the effect of increasing dataset size on the\nprivacy-utility trade-off. Our findings reveal that dataset size plays an\nintegral part in evaluating DP text rewriting mechanisms; additionally, these\nfindings call for more rigorous evaluation procedures in DP NLP, as well as\nshed light on the future of DP NLP in practice and at scale.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5f15\u5165\u6570\u636e\u96c6\u89c4\u6a21\u5bf9\u5dee\u5206\u9690\u79c1\u6587\u672c\u6539\u5199\u673a\u5236\u6548\u679c\u7684\u5f71\u54cd\uff0c\u8bbe\u8ba1\u4e86\u57fa\u4e8e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u548c\u9690\u79c1\u6d4b\u8bd5\uff0c\u63ed\u793a\u6570\u636e\u89c4\u6a21\u5bf9\u9690\u79c1-\u5b9e\u7528\u6027\u6743\u8861\u7684\u91cd\u8981\u4f5c\u7528\u3002", "motivation": "\u76ee\u524d\u5dee\u5206\u9690\u79c1\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u7684\u6587\u672c\u6539\u5199\u673a\u5236\u8bc4\u4f30\u4e2d\uff0c\u5e38\u5ffd\u7565\u6570\u636e\u96c6\u89c4\u6a21\u5bf9\u673a\u5236\u6548\u679c\u7684\u5f71\u54cd\u3002", "method": "\u8bbe\u8ba1\u52a8\u6001\u6570\u636e\u62c6\u5206\u6bd4\u4f8b\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u5b9e\u7528\u6027\u548c\u9690\u79c1\u6d4b\u8bd5\uff0c\u5728\u4e0d\u540c\u89c4\u6a21\u6570\u636e\u96c6\uff08\u6700\u591a\u767e\u4e07\u6761\u6587\u672c\uff09\u4e0a\u8fd0\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u6570\u636e\u96c6\u89c4\u6a21\u663e\u8457\u5f71\u54cd\u5dee\u5206\u9690\u79c1\u6587\u672c\u6539\u5199\u7684\u9690\u79c1\u4e0e\u5b9e\u7528\u6027\u6743\u8861\uff0c\u8868\u660e\u89c4\u6a21\u662f\u673a\u5236\u8bc4\u4f30\u7684\u91cd\u8981\u56e0\u7d20\u3002", "conclusion": "\u547c\u5401\u5dee\u5206\u9690\u79c1\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u91c7\u7528\u66f4\u4e25\u683c\u7684\u8bc4\u4f30\u6d41\u7a0b\uff0c\u5173\u6ce8\u6570\u636e\u89c4\u6a21\u5bf9\u673a\u5236\u6548\u679c\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u4e3a\u672a\u6765\u5927\u89c4\u6a21\u5e94\u7528\u63d0\u4f9b\u53c2\u8003\u3002"}}
{"id": "2511.00802", "categories": ["cs.SE", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00802", "abs": "https://arxiv.org/abs/2511.00802", "authors": ["Jie JW Wu", "Ayanda Patrick Herlihy", "Ahmad Saleem Mirza", "Ali Afoud", "Fatemeh Fard"], "title": "GrowthHacker: Automated Off-Policy Evaluation Optimization Using Code-Modifying LLM Agents", "comment": null, "summary": "With the software industry shifting toward a data-driven culture, online A/B\ntesting is a key tool for evaluating new technologies. However, deploying such\nexperiments requires substantial resources, may negatively impact users, and\ninvolves long data collection periods. To address this, \\textit{off-policy\nevaluation (OPE)}, or offline A/B testing, uses logged data to assess\ntechnologies and is fundamental in Reinforcement Learning, making it crucial in\ndomains where online testing is costly or risky, such as healthcare,\nrecommender systems, education, dialog systems, and robotics. Despite advances\nin coding LLMs and agentic AI, little is known about leveraging them to\noptimize OPE results. We investigate whether LLMs and LLM-based agents can\nimprove OPE performance via code optimization. We propose\n\\textit{GrowthHacker}, a benchmark with agent and baseline methods on\nlarge-scale real-world datasets, which iteratively optimizes code, evaluates\nresults, and begins new optimization cycles. We collected datasets, established\nprotocols, implemented baselines for OPE on the Open Bandit Pipeline\n(OBP)~\\cite{saito2021openbanditdatasetpipeline} and\nScope-RL~\\cite{kiyohara2023scope}, and developed the \\textit{two_agent}\nframework, which reduces system complexity while preserving optimization\neffectiveness. Results show the two_agent framework achieves 100% reliability\nand the highest average improvement of 106.7% among positive outcomes. Both\ntwo_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%.\nThese findings demonstrate the feasibility of LLM-based agents as automated\n\"growth hackers\" to enhance OPE systems, with implications for scaling\ndata-driven decision-making in production.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u81ea\u52a8\u4f18\u5316\u6846\u67b6GrowthHacker\uff0c\u7528\u4e8e\u63d0\u5347\u79bb\u7ebfA/B\u6d4b\u8bd5(\u5373off-policy evaluation\uff0cOPE)\u7684\u6027\u80fd\uff0c\u901a\u8fc7\u8fed\u4ee3\u4ee3\u7801\u4f18\u5316\u5b9e\u73b0\u9ad8\u6548\u3001\u53ef\u9760\u7684\u8bc4\u4f30\u3002", "motivation": "\u4f20\u7edf\u7684\u5728\u7ebfA/B\u6d4b\u8bd5\u8d44\u6e90\u6d88\u8017\u5927\u3001\u7528\u6237\u5f71\u54cd\u98ce\u9669\u9ad8\u4e14\u5468\u671f\u957f\uff0c\u56e0\u6b64\u79bb\u7ebfA/B\u6d4b\u8bd5\uff08OPE\uff09\u6210\u4e3a\u91cd\u8981\u66ff\u4ee3\u624b\u6bb5\u3002\u7136\u800c\uff0c\u5982\u4f55\u5229\u7528LLM\u4f18\u5316OPE\u4ee3\u7801\uff0c\u63d0\u9ad8\u8bc4\u4f30\u6548\u7387\u548c\u51c6\u786e\u6027\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u4f5c\u8005\u8bbe\u8ba1\u4e86GrowthHacker\u57fa\u51c6\u6846\u67b6\uff0c\u7ed3\u5408LLM\u548c\u57fa\u4e8e\u4ee3\u7406\u7684\u81ea\u52a8\u5316\u65b9\u6cd5\uff0c\u5728\u5927\u89c4\u6a21\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u53cd\u590d\u4f18\u5316\u548c\u8bc4\u4f30OPE\u76f8\u5173\u4ee3\u7801\uff0c\u63d0\u51fa\u4e86two_agent\u6846\u67b6\u4ee5\u7b80\u5316\u7cfb\u7edf\u590d\u6742\u5ea6\u4e14\u4fdd\u6301\u4f18\u5316\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u5728Open Bandit Pipeline\u548cScope-RL\u6570\u636e\u96c6\u4e0a\u663e\u793atwo_agent\u6846\u67b6\u8fbe\u5230100%\u53ef\u9760\u6027\u548c106.7%\u7684\u5e73\u5747\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u4e14success rate\u8fbe\u523045%\uff0c\u4f18\u4e8e\u5176\u4ed6\u5bf9\u7167\u65b9\u6cd5\u3002", "conclusion": "LLM\u57fa\u4ee3\u7406\u80fd\u591f\u4f5c\u4e3a\u81ea\u52a8\u5316\"\u589e\u957f\u9ed1\u5ba2\"\u6709\u6548\u63d0\u5347\u79bb\u7ebfA/B\u6d4b\u8bd5\u7cfb\u7edf\u6027\u80fd\uff0c\u4fc3\u8fdb\u9762\u5411\u751f\u4ea7\u73af\u5883\u7684\u6570\u636e\u9a71\u52a8\u51b3\u7b56\u7684\u89c4\u6a21\u5316\u5e94\u7528\u3002"}}
{"id": "2511.00489", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00489", "abs": "https://arxiv.org/abs/2511.00489", "authors": ["Jiani Guo", "Zuchao Li", "Jie Wu", "Qianren Wang", "Yun Li", "Lefei Zhang", "Hai Zhao", "Yujiu Yang"], "title": "ToM: Leveraging Tree-oriented MapReduce for Long-Context Reasoning in Large Language Models", "comment": "EMNLP 2025 Main Conference", "summary": "Large Language Models (LLMs), constrained by limited context windows, often\nface significant performance degradation when reasoning over long contexts. To\naddress this, Retrieval-Augmented Generation (RAG) retrieves and reasons over\nchunks but frequently sacrifices logical coherence due to its reliance on\nsimilarity-based rankings. Similarly, divide-and-conquer frameworks (DCF) split\ndocuments into small chunks for independent reasoning and aggregation. While\neffective for local reasoning, DCF struggles to capture long-range dependencies\nand risks inducing conflicts by processing chunks in isolation. To overcome\nthese limitations, we propose ToM, a novel Tree-oriented MapReduce framework\nfor long-context reasoning. ToM leverages the inherent hierarchical structure\nof long documents (e.g., main headings and subheadings) by constructing a\nDocTree through hierarchical semantic parsing and performing bottom-up\naggregation. Using a Tree MapReduce approach, ToM enables recursive reasoning:\nin the Map step, rationales are generated at child nodes; in the Reduce step,\nthese rationales are aggregated across sibling nodes to resolve conflicts or\nreach consensus at parent nodes. Experimental results on 70B+ LLMs show that\nToM significantly outperforms existing divide-and-conquer frameworks and\nretrieval-augmented generation methods, achieving better logical coherence and\nlong-context reasoning. Our code is available at\nhttps://github.com/gjn12-31/ToM .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6811\u5f62\u7ed3\u6784\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u6846\u67b6ToM\uff0c\u901a\u8fc7\u5c42\u7ea7\u8bed\u4e49\u89e3\u6790\u6784\u5efa\u6587\u6863\u6811\uff0c\u91c7\u7528\u7c7b\u4f3cMapReduce\u7684\u65b9\u6cd5\u8fdb\u884c\u9012\u5f52\u63a8\u7406\uff0c\u5b9e\u73b0\u4e86\u8f83\u597d\u7684\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u957f\u8ddd\u79bb\u4f9d\u8d56\u6355\u83b7\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u4e0a\u4e0b\u6587\u7a97\u53e3\u9650\u5236\uff0c\u5728\u957f\u6587\u672c\u63a8\u7406\u65f6\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u65b9\u6cd5\u5982\u57fa\u4e8e\u68c0\u7d22\u751f\u6210\u548c\u5206\u5757\u63a8\u7406\u867d\u6709\u4f18\u52bf\u4f46\u5b58\u5728\u903b\u8f91\u4e00\u81f4\u6027\u5dee\u548c\u957f\u8ddd\u79bb\u4f9d\u8d56\u5904\u7406\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "ToM\u6846\u67b6\u5229\u7528\u6587\u6863\u7684\u5c42\u7ea7\u7ed3\u6784\uff0c\u6784\u5efaDocTree\uff0c\u91c7\u7528\u6811\u5f62\u7684MapReduce\u7b56\u7565\uff1a\u5728Map\u9636\u6bb5\u5b50\u8282\u70b9\u751f\u6210\u63a8\u7406\u7406\u7531\uff0c\u5728Reduce\u9636\u6bb5\u540c\u7ea7\u8282\u70b9\u95f4\u6574\u5408\u63a8\u7406\u7406\u7531\u4ee5\u89e3\u51b3\u51b2\u7a81\u6216\u8fbe\u6210\u5171\u8bc6\uff0c\u5b9e\u73b0\u9012\u5f52\u63a8\u7406\u3002", "result": "\u572870B+\u53c2\u6570\u7684\u5927\u6a21\u578b\u4e0a\uff0cToM\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u5206\u5757\u63a8\u7406\u548c\u57fa\u4e8e\u68c0\u7d22\u7684\u751f\u6210\u65b9\u6cd5\uff0c\u5728\u903b\u8f91\u8fde\u8d2f\u6027\u548c\u957f\u8ddd\u79bb\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\u4e0a\u8868\u73b0\u66f4\u4f73\u3002", "conclusion": "\u5229\u7528\u6587\u6863\u7684\u5c42\u7ea7\u7ed3\u6784\u7ed3\u5408\u6811\u5f62MapReduce\u63a8\u7406\uff0cToM\u6709\u6548\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u903b\u8f91\u4e00\u81f4\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u6587\u672c\u63a8\u7406\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2511.00839", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00839", "abs": "https://arxiv.org/abs/2511.00839", "authors": ["John Yang", "Kilian Lieret", "Joyce Yang", "Carlos E. Jimenez", "Ofir Press", "Ludwig Schmidt", "Diyi Yang"], "title": "CodeClash: Benchmarking Goal-Oriented Software Engineering", "comment": null, "summary": "Current benchmarks for coding evaluate language models (LMs) on concrete,\nwell-specified tasks such as fixing specific bugs or writing targeted tests.\nHowever, human programmers do not spend all day incessantly addressing isolated\ntasks. Instead, real-world software development is grounded in the pursuit of\nhigh-level goals, like improving user retention or reducing costs. Evaluating\nwhether LMs can also iteratively develop code to better accomplish open-ended\nobjectives without any explicit guidance remains an open challenge. To address\nthis, we introduce CodeClash, a benchmark where LMs compete in multi-round\ntournaments to build the best codebase for achieving a competitive objective.\nEach round proceeds in two phases: agents edit their code, then their codebases\ncompete head-to-head in a code arena that determines winners based on\nobjectives like score maximization, resource acquisition, or survival. Whether\nit's writing notes, scrutinizing documentation, analyzing competition logs, or\ncreating test suites, models must decide for themselves how to improve their\ncodebases both absolutely and against their opponents. We run 1680 tournaments\n(25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal\nthat while models exhibit diverse development styles, they share fundamental\nlimitations in strategic reasoning. Models also struggle with long-term\ncodebase maintenance, as repositories become progressively messy and redundant.\nThese limitations are stark: top models lose every round against expert human\nprogrammers. We open-source CodeClash to advance the study of autonomous,\ngoal-oriented code development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CodeClash\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u5f00\u653e\u5f0f\u3001\u591a\u8f6e\u8fed\u4ee3\u7684\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u6218\u7565\u63a8\u7406\u548c\u957f\u671f\u4ee3\u7801\u7ef4\u62a4\u4e0a\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u8fdc\u4e0d\u53ca\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u5f53\u524d\u8bc4\u6d4b\u591a\u96c6\u4e2d\u5728\u5177\u4f53\u3001\u660e\u786e\u7684\u4efb\u52a1\uff0c\u4f46\u73b0\u5b9e\u8f6f\u4ef6\u5f00\u53d1\u662f\u56f4\u7ed5\u9ad8\u5c42\u76ee\u6807\u8fdb\u884c\u7684\uff0c\u5982\u4f55\u8ba9\u6a21\u578b\u81ea\u52a8\u3001\u8fed\u4ee3\u5f0f\u5730\u5b9e\u73b0\u5f00\u653e\u76ee\u6807\u5c1a\u672a\u89e3\u51b3\u3002", "method": "\u8bbe\u8ba1CodeClash\u591a\u8f6e\u9526\u6807\u8d5b\u57fa\u51c6\uff0c\u6a21\u578b\u901a\u8fc7\u4ee3\u7801\u7f16\u8f91\u548c\u4e92\u76f8\u7ade\u4e89\u7684\u53cc\u9636\u6bb5\u5faa\u73af\uff0c\u9488\u5bf9\u5f00\u653e\u76ee\u6807\u63d0\u5347\u4ee3\u7801\u5e93\u8868\u73b0\uff0c\u57286\u4e2a\u7ade\u6280\u573a\u4e2d\u8fdb\u884c1680\u573a\u6bd4\u8d5b\u3002", "result": "\u6a21\u578b\u8868\u73b0\u51fa\u591a\u6837\u5316\u5f00\u53d1\u98ce\u683c\uff0c\u4f46\u5728\u6218\u7565\u63a8\u7406\u548c\u4ee3\u7801\u957f\u671f\u7ef4\u62a4\u4e0a\u5747\u6709\u660e\u663e\u7f3a\u9677\uff0c\u4ee3\u7801\u5e93\u9010\u6e10\u6742\u4e71\u5197\u4f59\uff0c\u4e14\u9876\u5c16\u6a21\u578b\u6bcf\u8f6e\u5747\u4e0d\u654c\u4eba\u7c7b\u4e13\u5bb6\u3002", "conclusion": "CodeClash\u57fa\u51c6\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u4e3b\u3001\u76ee\u6807\u5bfc\u5411\u4ee3\u7801\u5f00\u53d1\u4e2d\u7684\u6838\u5fc3\u5c40\u9650\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u672a\u6765\u7814\u7a76\u3002"}}
{"id": "2511.00505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00505", "abs": "https://arxiv.org/abs/2511.00505", "authors": ["Qi Luo", "Xiaonan Li", "Junqi Dai", "Shuang Cheng", "Xipeng Qiu"], "title": "Zero-RAG: Towards Retrieval-Augmented Generation with Zero Redundant Knowledge", "comment": null, "summary": "Retrieval-Augmented Generation has shown remarkable results to address Large\nLanguage Models' hallucinations, which usually uses a large external corpus to\nsupplement knowledge to LLMs. However, with the development of LLMs, the\ninternal knowledge of LLMs has expanded significantly, thus causing significant\nknowledge redundancy between the external corpus and LLMs. On the one hand, the\nindexing cost of dense retrieval is highly related to the corpus size and thus\nsignificant redundant knowledge intensifies the dense retrieval's workload. On\nthe other hand, the redundant knowledge in the external corpus is not helpful\nto LLMs and our exploratory analysis shows that it instead hurts the RAG\nperformance on those questions which the LLM can answer by itself. To address\nthese issues, we propose Zero-RAG to tackle these challenges. Specifically, we\nfirst propose the Mastery-Score metric to identify redundant knowledge in the\nRAG corpus to prune it. After pruning, answers to \"mastered\" questions rely\nprimarily on internal knowledge of the LLM. To better harness the internal\ncapacity, we propose Query Router and Noise-Tolerant Tuning to avoid the\nirrelevant documents' distraction and thus further improve the LLM's\nutilization of internal knowledge with pruned corpus. Experimental results show\nthat Zero-RAG prunes the Wikipedia corpus by 30\\% and accelerates the retrieval\nstage by 22\\%, without compromising RAG's performance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faZero-RAG\u65b9\u6cd5\uff0c\u901a\u8fc7\u526a\u679d\u5916\u90e8\u77e5\u8bc6\u5e93\u4e2d\u7684\u5197\u4f59\u77e5\u8bc6\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u77e5\u8bc6\u5229\u7528\u6548\u7387\uff0c\u51cf\u5c11\u68c0\u7d22\u5de5\u4f5c\u8d1f\u62c5\uff0c\u540c\u65f6\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7684\u6027\u80fd\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u77e5\u8bc6\u7684\u589e\u52a0\uff0c\u5916\u90e8\u8bed\u6599\u5e93\u4e0eLLMs\u4e4b\u95f4\u5b58\u5728\u5927\u91cf\u5197\u4f59\u77e5\u8bc6\uff0c\u5bfc\u81f4\u5bc6\u96c6\u68c0\u7d22\u5f00\u9500\u5927\u4e14\u5197\u4f59\u4fe1\u606f\u5f71\u54cd\u6a21\u578b\u56de\u7b54\u80fd\u529b\u3002", "method": "\u63d0\u51faMastery-Score\u6307\u6807\u7528\u4e8e\u8bc6\u522b\u5e76\u526a\u679d\u5916\u90e8\u77e5\u8bc6\u5e93\u4e2d\u7684\u5197\u4f59\u77e5\u8bc6\uff0c\u5229\u7528Query Router\u548cNoise-Tolerant Tuning\u63d0\u5347\u6a21\u578b\u5bf9\u5185\u90e8\u77e5\u8bc6\u7684\u5229\u7528\u7387\u3002", "result": "Zero-RAG\u526a\u679d\u4e86\u7ef4\u57fa\u767e\u79d1\u8bed\u6599\u5e9330%\uff0c\u68c0\u7d22\u901f\u5ea6\u63d0\u534722%\uff0c\u4e14\u672a\u635f\u5bb3RAG\u6a21\u578b\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u526a\u679d\u5197\u4f59\u77e5\u8bc6\u548c\u4f18\u5316\u68c0\u7d22\u7b56\u7565\uff0cZero-RAG\u6709\u6548\u63d0\u5347\u4e86RAG\u65b9\u6cd5\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u5145\u5206\u5229\u7528\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u77e5\u8bc6\u3002"}}
{"id": "2511.00872", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00872", "abs": "https://arxiv.org/abs/2511.00872", "authors": ["Zhuowen Yin", "Cuifeng Gao", "Chunsong Fan", "Wenzhang Yang", "Yinxing Xue", "Lijun Zhang"], "title": "A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Software Engineering Tasks", "comment": null, "summary": "Unlike traditional automation tools or static LLM-based systems, agents\ncombine decision-making and tool utilization to accomplish complex tasks,\nshowing great potential in software engineering. However, existing studies\nlargely focus on specific tasks or isolated aspects, providing an incomplete\npicture of agents' practical capabilities. To address this, we conduct a\ncomprehensive empirical study evaluating seven general-purpose agent frameworks\nacross three representative code-centric tasks: software development,\nvulnerability detection, and program repair. Each task is assessed using\nstandard, widely adopted benchmarks to ensure objective and comparable\nevaluation. Agent performance is systematically analyzed from three\ncomplementary perspectives: effectiveness (task success), efficiency (execution\nprocess), and overhead (token consumption). Our findings reveal distinct\ncapability patterns and trade-offs among the evaluated frameworks. In terms of\neffectiveness, agents achieve moderate overall performance. Regarding\nefficiency, AgentOrchestra tends to exhibit the longest trajectories and the\nmost correction attempts due to coordination overhead, whereas OpenHands\ndemonstrate stronger reflective reasoning abilities. For overhead, software\ndevelopment incurs the highest monetary cost, while GPTswarm remains the most\ncost-efficient. Furthermore, we conduct an in-depth cross-analysis of the\nrelationship between effectiveness and efficiency, exploring the underlying\nreasons behind their interplay. These findings guide both practical adoption\nand future research toward more efficient software engineering agents.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86\u4e03\u79cd\u901a\u7528\u4ee3\u7406\u6846\u67b6\u5728\u8f6f\u4ef6\u5f00\u53d1\u3001\u6f0f\u6d1e\u68c0\u6d4b\u548c\u7a0b\u5e8f\u4fee\u590d\u4e09\u4e2a\u4ee3\u7801\u4e2d\u5fc3\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u5404\u6846\u67b6\u5728\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\u4e0a\u7684\u5dee\u5f02\u548c\u6298\u4e2d\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u4e8e\u7279\u5b9a\u4efb\u52a1\u6216\u5355\u4e00\u65b9\u9762\uff0c\u672a\u80fd\u5168\u9762\u53cd\u6620\u4ee3\u7406\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5b9e\u9645\u80fd\u529b\uff0c\u6545\u9700\u8fdb\u884c\u7cfb\u7edf\u800c\u5168\u9762\u7684\u8bc4\u4f30\u3002", "method": "\u91c7\u7528\u6807\u51c6\u4e14\u5e7f\u6cdb\u8ba4\u53ef\u7684\u57fa\u51c6\u6d4b\u8bd5\u5bf9\u4e03\u4e2a\u901a\u7528\u4ee3\u7406\u6846\u67b6\u6267\u884c\u4e09\u7c7b\u4ee3\u7801\u76f8\u5173\u4efb\u52a1\uff0c\u7efc\u5408\u8bc4\u4f30\u5176\u6709\u6548\u6027\u3001\u6548\u7387\u548c\u5f00\u9500\uff0c\u5e76\u6df1\u5165\u5206\u6790\u6548\u679c\u4e0e\u6548\u7387\u7684\u5173\u7cfb\u3002", "result": "\u4e0d\u540c\u4ee3\u7406\u5c55\u73b0\u51fa\u4e0d\u540c\u80fd\u529b\u6a21\u5f0f\u53ca\u53d6\u820d\uff0cAgentOrchestra\u6548\u7387\u8f83\u4f4e\u4f46\u5c1d\u8bd5\u591a\uff0cOpenHands\u63a8\u7406\u80fd\u529b\u8f83\u5f3a\uff0cGPTswarm\u6210\u672c\u6700\u4f4e\uff0c\u6574\u4f53\u8868\u73b0\u4e2d\u7b49\u3002\u8f6f\u4ef6\u5f00\u53d1\u4efb\u52a1\u6210\u672c\u6700\u9ad8\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5b9e\u9645\u5e94\u7528\u548c\u672a\u6765\u9ad8\u6548\u8f6f\u4ef6\u5de5\u7a0b\u4ee3\u7406\u7684\u7814\u53d1\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5f3a\u8c03\u9700\u5e73\u8861\u6709\u6548\u6027\u4e0e\u6548\u7387\u4ee5\u63d0\u5347\u4ee3\u7406\u6027\u80fd\u3002"}}
{"id": "2511.00514", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00514", "abs": "https://arxiv.org/abs/2511.00514", "authors": ["Birat Poudel", "Satyam Ghimire", "Er. Prakash Chandra Prasad"], "title": "Fine-Tuning DialoGPT on Common Diseases in Rural Nepal for Medical Conversations", "comment": "6 pages, 6 figures, 3 tables", "summary": "Conversational agents are increasingly being explored to support healthcare\ndelivery, particularly in resource-constrained settings such as rural Nepal.\nLarge-scale conversational models typically rely on internet connectivity and\ncloud infrastructure, which may not be accessible in rural areas. In this\nstudy, we fine-tuned DialoGPT, a lightweight generative dialogue model that can\noperate offline, on a synthetically constructed dataset of doctor-patient\ninteractions covering ten common diseases prevalent in rural Nepal, including\ncommon cold, seasonal fever, diarrhea, typhoid fever, gastritis, food\npoisoning, malaria, dengue fever, tuberculosis, and pneumonia. Despite being\ntrained on a limited, domain-specific dataset, the fine-tuned model produced\ncoherent, contextually relevant, and medically appropriate responses,\ndemonstrating an understanding of symptoms, disease context, and empathetic\ncommunication. These results highlight the adaptability of compact,\noffline-capable dialogue models and the effectiveness of targeted datasets for\ndomain adaptation in low-resource healthcare environments, offering promising\ndirections for future rural medical conversational AI.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5fae\u8c03\u79bb\u7ebf\u8fd0\u884c\u7684\u8f7b\u91cf\u7ea7\u5bf9\u8bdd\u6a21\u578bDialoGPT\uff0c\u57fa\u4e8e\u5408\u6210\u7684\u519c\u6751\u5c3c\u6cca\u5c14\u5e38\u89c1\u75be\u75c5\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u533b\u7597\u5bf9\u8bdd\u7cfb\u7edf\u5728\u65e0\u4e92\u8054\u7f51\u73af\u5883\u4e0b\u7684\u5e94\u7528\u3002", "motivation": "\u519c\u6751\u5730\u533a\u4e92\u8054\u7f51\u63a5\u5165\u53d7\u9650\uff0c\u4f20\u7edf\u4f9d\u8d56\u4e91\u7aef\u7684\u5927\u89c4\u6a21\u5bf9\u8bdd\u6a21\u578b\u96be\u4ee5\u5e94\u7528\uff0c\u9700\u8981\u5f00\u53d1\u79bb\u7ebf\u3001\u8f7b\u91cf\u4e14\u9002\u5e94\u5f53\u5730\u75be\u75c5\u7279\u70b9\u7684\u533b\u7597\u5bf9\u8bdd\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5408\u6210\u6784\u5efa\u7684\u533b\u751f-\u60a3\u8005\u5bf9\u8bdd\u6570\u636e\u96c6\uff08\u6db5\u76d610\u79cd\u5e38\u89c1\u75be\u75c5\uff09\u5fae\u8c03DialoGPT\u6a21\u578b\uff0c\u4f7f\u5176\u80fd\u751f\u6210\u7b26\u5408\u533b\u7597\u8bed\u5883\u7684\u5bf9\u8bdd\u5185\u5bb9\u3002", "result": "\u5fae\u8c03\u540e\u6a21\u578b\u80fd\u591f\u751f\u6210\u8fde\u8d2f\u4e14\u533b\u5b66\u9002\u5f53\u7684\u54cd\u5e94\uff0c\u8868\u73b0\u51fa\u5bf9\u75c7\u72b6\u3001\u75be\u75c5\u80cc\u666f\u53ca\u540c\u7406\u5fc3\u4ea4\u6d41\u7684\u7406\u89e3\u3002", "conclusion": "\u8f7b\u91cf\u79bb\u7ebf\u5bf9\u8bdd\u6a21\u578b\u7ed3\u5408\u9488\u5bf9\u6027\u6570\u636e\u96c6\u53ef\u6709\u6548\u9002\u5e94\u4f4e\u8d44\u6e90\u533b\u7597\u73af\u5883\uff0c\u5177\u5907\u4e3a\u519c\u6751\u533b\u7597\u5bf9\u8bddAI\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00901", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00901", "abs": "https://arxiv.org/abs/2511.00901", "authors": ["Vincenzo De Martino", "Stefano Lambiase", "Fabiano Pecorelli", "Willem-Jan van den Heuvel", "Filomena Ferrucci", "Fabio Palomba"], "title": "Sustainability of Machine Learning-Enabled Systems: The Machine Learning Practitioner's Perspective", "comment": null, "summary": "Software sustainability is a key multifaceted non-functional requirement that\nencompasses environmental, social, and economic concerns, yet its integration\ninto the development of Machine Learning (ML)-enabled systems remains an open\nchallenge. While previous research has explored high-level sustainability\nprinciples and policy recommendations, limited empirical evidence exists on how\nsustainability is practically managed in ML workflows. Existing studies\npredominantly focus on environmental sustainability, e.g., carbon footprint\nreduction, while missing the broader spectrum of sustainability dimensions and\nthe challenges practitioners face in real-world settings. To address this gap,\nwe conduct an empirical study to characterize sustainability in ML-enabled\nsystems from a practitioner's perspective. We investigate (1) how ML engineers\nperceive and describe sustainability, (2) the software engineering practices\nthey adopt to support it, and (3) the key challenges hindering its adoption. We\nfirst perform a qualitative analysis based on interviews with eight experienced\nML engineers, followed by a large-scale quantitative survey with 203 ML\npractitioners. Our key findings reveal a significant disconnection between\nsustainability awareness and its systematic implementation, highlighting the\nneed for more structured guidelines, measurement frameworks, and regulatory\nsupport.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5b9a\u6027\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u95ee\u5377\u8c03\u67e5\uff0c\u63a2\u8ba8\u4e86\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u53ef\u6301\u7eed\u6027\u7ba1\u7406\u7684\u73b0\u72b6\u4e0e\u6311\u6218\uff0c\u53d1\u73b0\u5b9e\u9645\u5b9e\u65bd\u4e0e\u610f\u8bc6\u5b58\u5728\u663e\u8457\u8131\u8282\u3002", "motivation": "\u867d\u7136\u8f6f\u4ef6\u53ef\u6301\u7eed\u6027\u662f\u91cd\u8981\u7684\u975e\u529f\u80fd\u9700\u6c42\uff0c\u4f46\u5728\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f00\u53d1\u4e2d\uff0c\u5982\u4f55\u5b9e\u8df5\u53ef\u6301\u7eed\u6027\u4ecd\u7f3a\u4e4f\u5b9e\u8bc1\u7814\u7a76\uff0c\u5c24\u5176\u662f\u6db5\u76d6\u73af\u5883\u3001\u793e\u4f1a\u548c\u7ecf\u6d4e\u591a\u4e2a\u7ef4\u5ea6\u7684\u5168\u9762\u63a2\u8ba8\u3002", "method": "\u901a\u8fc7\u5bf98\u540d\u8d44\u6df1\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u7684\u8bbf\u8c08\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u7ed3\u5408\u5bf9203\u540d\u673a\u5668\u5b66\u4e60\u4ece\u4e1a\u8005\u7684\u5927\u89c4\u6a21\u95ee\u5377\u8c03\u67e5\uff0c\u5206\u6790\u53ef\u6301\u7eed\u6027\u7684\u8ba4\u77e5\u3001\u5b9e\u8df5\u65b9\u6cd5\u53ca\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u673a\u5668\u5b66\u4e60\u5de5\u7a0b\u5e08\u5bf9\u53ef\u6301\u7eed\u6027\u6709\u8ba4\u77e5\u4f46\u5728\u5b9e\u9645\u64cd\u4f5c\u4e2d\u7f3a\u4e4f\u7cfb\u7edf\u5b9e\u65bd\uff0c\u5b58\u5728\u5bf9\u6307\u5bfc\u65b9\u9488\u3001\u8861\u91cf\u6846\u67b6\u53ca\u653f\u7b56\u652f\u6301\u7684\u5f3a\u70c8\u9700\u6c42\u3002", "conclusion": "\u9700\u8981\u5236\u5b9a\u66f4\u7cfb\u7edf\u7684\u6307\u5bfc\u548c\u8bc4\u4ef7\u4f53\u7cfb\uff0c\u540c\u65f6\u63a8\u52a8\u76d1\u7ba1\u653f\u7b56\uff0c\u4ee5\u4fc3\u8fdb\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u4e2d\u53ef\u6301\u7eed\u6027\u7684\u6709\u6548\u5b9e\u65bd\u3002"}}
{"id": "2511.00519", "categories": ["cs.CL", "I.2.7; I.7.1; K.4.1"], "pdf": "https://arxiv.org/pdf/2511.00519", "abs": "https://arxiv.org/abs/2511.00519", "authors": ["Ariyan Hossain", "Khondokar Mohammad Ahanaf Hannan", "Rakinul Haque", "Nowreen Tarannum Rafa", "Humayra Musarrat", "Shoaib Ahmed Dipu", "Farig Yousuf Sadeque"], "title": "Exploring and Mitigating Gender Bias in Encoder-Based Transformer Models", "comment": "25 pages, 20 figures", "summary": "Gender bias in language models has gained increasing attention in the field\nof natural language processing. Encoder-based transformer models, which have\nachieved state-of-the-art performance in various language tasks, have been\nshown to exhibit strong gender biases inherited from their training data. This\npaper investigates gender bias in contextualized word embeddings, a crucial\ncomponent of transformer-based models. We focus on prominent architectures such\nas BERT, ALBERT, RoBERTa, and DistilBERT to examine their vulnerability to\ngender bias. To quantify the degree of bias, we introduce a novel metric,\nMALoR, which assesses bias based on model probabilities for filling masked\ntokens. We further propose a mitigation approach involving continued\npre-training on a gender-balanced dataset generated via Counterfactual Data\nAugmentation. Our experiments reveal significant reductions in gender bias\nscores across different pronoun pairs. For instance, in BERT-base, bias scores\nfor \"he-she\" dropped from 1.27 to 0.08, and \"his-her\" from 2.51 to 0.36\nfollowing our mitigation approach. We also observed similar improvements across\nother models, with \"male-female\" bias decreasing from 1.82 to 0.10 in\nBERT-large. Our approach effectively reduces gender bias without compromising\nmodel performance on downstream tasks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8eTransformer\u7684\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u65b0\u7684\u504f\u89c1\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u4e0e\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u6709\u6548\u964d\u4f4e\u4e86\u504f\u89c1\u3002", "motivation": "\u5f53\u524d\u7684\u7f16\u7801\u5668Transformer\u6a21\u578b\u5728\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u8bad\u7ec3\u6570\u636e\u4e2d\u5b58\u5728\u7684\u6027\u522b\u504f\u89c1\u88ab\u6a21\u578b\u7ee7\u627f\uff0c\u4e9f\u9700\u91cf\u5316\u548c\u7f13\u89e3\u8fd9\u79cd\u504f\u89c1\u3002", "method": "\u5f15\u5165\u4e86\u57fa\u4e8e\u6a21\u578b\u586b\u7a7a\u6982\u7387\u7684\u6027\u522b\u504f\u89c1\u65b0\u5ea6\u91cf\u6307\u6807MALoR\uff0c\u91c7\u7528\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u751f\u6210\u6027\u522b\u5e73\u8861\u7684\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\u4ee5\u51cf\u8f7b\u504f\u89c1\u3002", "result": "\u5728BERT-base\u548c\u5176\u4ed6\u53d8\u4f53\u4e0a\uff0c\u6027\u522b\u504f\u89c1\u6307\u6570\u663e\u8457\u964d\u4f4e\uff0c\u5982\u201che-she\u201d\u504f\u89c1\u4ece1.27\u964d\u81f30.08\uff0c\u540c\u65f6\u6a21\u578b\u5728\u4e0b\u6e38\u4efb\u52a1\u7684\u8868\u73b0\u672a\u53d7\u5f71\u54cd\u3002", "conclusion": "\u901a\u8fc7\u53cd\u4e8b\u5b9e\u6570\u636e\u589e\u5f3a\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\u6709\u6548\u51cf\u5c11\u4e86Transformer\u6a21\u578b\u4e2d\u7684\u6027\u522b\u504f\u89c1\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.00915", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.00915", "abs": "https://arxiv.org/abs/2511.00915", "authors": ["Jukka Ruohonen", "Abhishek Tiwari"], "title": "Empirical Derivations from an Evolving Test Suite", "comment": "Submitted", "summary": "The paper presents a longitudinal empirical analysis of the automated,\ncontinuous, and virtualization-based software test suite of the NetBSD\noperating system. The longitudinal period observed spans from the initial roll\nout of the test suite in the early 2010s to late 2025. According to the\nresults, the test suite has grown continuously, currently covering over ten\nthousand individual test cases. Failed test cases exhibit overall stability,\nalthough there have been shorter periods marked with more frequent failures. A\nsimilar observation applies to build failures, failures of the test suite to\ncomplete, and installation failures, all of which are also captured by the\nNetBSD's testing framework. Finally, code churn and kernel modifications do not\nprovide longitudinally consistent statistical explanations for the failures.\nAlthough some periods exhibit larger effects, including particularly with\nrespect to the kernel modifications, the effects are small on average. Even\nthough only in an exploratory manner, these empirical observations contribute\nto efforts to draw conclusions from large-scale and evolving software test\nsuites.", "AI": {"tldr": "\u672c\u6587\u5bf9NetBSD\u64cd\u4f5c\u7cfb\u7edf\u4ece2010\u5e74\u4ee3\u521d\u81f32025\u5e74\u7684\u81ea\u52a8\u5316\u6d4b\u8bd5\u5957\u4ef6\u8fdb\u884c\u7eb5\u5411\u5b9e\u8bc1\u5206\u6790\uff0c\u8986\u76d6\u8d85\u8fc7\u4e00\u4e07\u6d4b\u8bd5\u7528\u4f8b\uff0c\u53d1\u73b0\u5931\u8d25\u7387\u6574\u4f53\u7a33\u5b9a\uff0c\u4ee3\u7801\u53d8\u66f4\u4e0e\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u7684\u5f71\u54cd\u8f83\u5c0f\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u957f\u671f\u6570\u636e\u5206\u6790\u6df1\u5165\u7406\u89e3\u5927\u89c4\u6a21\u4e14\u6301\u7eed\u6f14\u8fdb\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u7684\u6027\u80fd\u4e0e\u7a33\u5b9a\u6027\u3002", "method": "\u5bf9NetBSD\u7684\u81ea\u52a8\u5316\u3001\u865a\u62df\u5316\u6d4b\u8bd5\u5957\u4ef6\u4ece2010\u5e74\u4ee3\u521d\u52302025\u5e74\u8fdb\u884c\u7eb5\u5411\u6570\u636e\u6536\u96c6\u4e0e\u7edf\u8ba1\u5206\u6790\uff0c\u5206\u6790\u6d4b\u8bd5\u5931\u8d25\u3001\u6784\u5efa\u5931\u8d25\u3001\u5b89\u88c5\u5931\u8d25\u7b49\u591a\u79cd\u5931\u8d25\u7c7b\u578b\u53ca\u5176\u4e0e\u4ee3\u7801\u53d8\u66f4\u7684\u5173\u7cfb\u3002", "result": "\u6d4b\u8bd5\u5957\u4ef6\u6301\u7eed\u589e\u957f\uff0c\u8986\u76d6\u8d85\u8fc7\u4e00\u4e07\u6d4b\u8bd5\u7528\u4f8b\uff1b\u6d4b\u8bd5\u5931\u8d25\u7387\u6574\u4f53\u7a33\u5b9a\uff0c\u5b58\u5728\u77ed\u671f\u5931\u8d25\u9ad8\u53d1\u671f\uff1b\u6784\u5efa\u5931\u8d25\u3001\u6d4b\u8bd5\u672a\u5b8c\u6210\u548c\u5b89\u88c5\u5931\u8d25\u8868\u73b0\u7c7b\u4f3c\uff1b\u4ee3\u7801\u53d8\u52a8\u548c\u5185\u6838\u4fee\u6539\u5bf9\u5931\u8d25\u7387\u5f71\u54cd\u4e0d\u5927\uff0c\u5e73\u5747\u4f5c\u7528\u8f83\u5c0f\u3002", "conclusion": "\u5927\u89c4\u6a21\u3001\u6301\u7eed\u6f14\u8fdb\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u7684\u5931\u8d25\u6a21\u5f0f\u5177\u6709\u4e00\u5b9a\u7a33\u5b9a\u6027\uff0c\u4ee3\u7801\u4e0e\u5185\u6838\u53d8\u52a8\u5bf9\u6d4b\u8bd5\u5931\u8d25\u5f71\u54cd\u6709\u9650\uff0c\u5b9e\u8bc1\u7ed3\u679c\u6709\u52a9\u4e8e\u672a\u6765\u4ece\u957f\u65f6\u95f4\u8de8\u5ea6\u5206\u6790\u8f6f\u4ef6\u6d4b\u8bd5\u5957\u4ef6\u8868\u73b0\u3002"}}
{"id": "2511.00536", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00536", "abs": "https://arxiv.org/abs/2511.00536", "authors": ["Wenya Xie", "Shaochen", "Zhong", "Hoang Anh Duy Le", "Zhaozhuo Xu", "Jianwen Xie", "Zirui Liu"], "title": "Word Salad Chopper: Reasoning Models Waste A Ton Of Decoding Budget On Useless Repetitions, Self-Knowingly", "comment": null, "summary": "Large Reasoning Models (LRMs) are often bottlenecked by the high cost of\noutput tokens. We show that a significant portion of these tokens are useless\nself-repetitions - what we call \"word salad\" - that exhaust the decoding budget\nwithout adding value. Interestingly, we observe that LRMs are self-aware when\ntrapped in these loops: the hidden states of <\\n\\n> tokens trailing each\nreasoning chunk exhibit patterns that allow us to detect word salad behavior\non-the-fly via a single-layer linear classifier. Once detected, a simple chop\nappended by a straightforward regeneration prompt yields substantial length\nsavings with minimal quality loss. Our work offers WordSaladChopper (WSC) - a\nlightweight, turnkey component for LRM that is minimally invasive to its\nreasoning trajectory by only removing semantically redundant tokens. Given its\nlow overhead, strong savings, and the lack of semantic value of word salad\ntokens, we believe it is not too far-fetched to argue that WSC - or a similar\ncomponent - is a must-have for all LRM applications with user experience in\nmind. Our code is publicly available at\nhttps://github.com/wenyaxie023/WordSaladChopper.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86WordSaladChopper (WSC)\uff0c\u4e00\u79cd\u68c0\u6d4b\u5e76\u526a\u5207\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u751f\u6210\u7684\u65e0\u7528\u81ea\u6211\u91cd\u590d\u201cword salad\u201d\u8bcd\u6c47\u7684\u65b9\u6cd5\uff0c\u4ee5\u8282\u7701\u89e3\u7801\u9884\u7b97\u5e76\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u751f\u6210\u8f93\u51fa\u65f6\uff0c\u5b58\u5728\u5927\u91cf\u65e0\u7528\u7684\u91cd\u590d\u8bcd\u6c47\uff08word salad\uff09\uff0c\u6d6a\u8d39\u4e86\u89e3\u7801\u9884\u7b97\u4e14\u65e0\u5b9e\u9645\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u5206\u6790\u9690\u85cf\u72b6\u6001\uff0c\u5229\u7528\u5355\u5c42\u7ebf\u6027\u5206\u7c7b\u5668\u5b9e\u65f6\u68c0\u6d4bword salad\u884c\u4e3a\uff1b\u4e00\u65e6\u68c0\u6d4b\u5230\uff0c\u901a\u8fc7\u526a\u5207\u548c\u91cd\u65b0\u751f\u6210\u63d0\u793a\u6765\u51cf\u5c11\u5197\u4f59\u8bcd\u6c47\u3002", "result": "WordSaladChopper\u6709\u6548\u8282\u7701\u4e86\u5e8f\u5217\u957f\u5ea6\uff0c\u964d\u4f4e\u6210\u672c\uff0c\u540c\u65f6\u5bf9\u8f93\u51fa\u8d28\u91cf\u5f71\u54cd\u6781\u5c0f\u3002", "conclusion": "WSC\u662f\u4e00\u79cd\u8f7b\u91cf\u4e14\u4fb5\u5165\u6027\u5c0f\u7684\u7ec4\u4ef6\uff0c\u9002\u5408\u6240\u6709\u9700\u8981\u9ad8\u6548\u3001\u4f18\u8d28\u7528\u6237\u4f53\u9a8c\u7684\u5927\u578b\u63a8\u7406\u6a21\u578b\u5e94\u7528\uff0c\u5f3a\u70c8\u5efa\u8bae\u96c6\u6210\u4f7f\u7528\u3002"}}
{"id": "2511.01043", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01043", "abs": "https://arxiv.org/abs/2511.01043", "authors": ["Zihan Fang", "Yifan Zhang", "Yueke Zhang", "Kevin Leach", "Yu Huang"], "title": "DPO-F+: Aligning Code Repair Feedback with Developers' Preferences", "comment": "10 pages, 2 figures", "summary": "Large Language Models (LLMs) are increasingly applied to software engineering\ntasks, especially code repair. However, developers often struggle to interpret\nmodel outputs, limiting effective human-AI teaming. Prior work largely\noptimizes repaired code while under-addressing the natural-language feedback\nthat enables comprehension and iterative improvement. We present DPO-f+, a\nnovel framework that aligns code-repair feedback with developer needs and\nprofiles. It (1) formalizes developer-profiled, domain-specific metrics for\nfeedback alignment; (2) automatically constructs pairwise preference datasets\nfrom code-repair tasks; (3) fine-tunes using Direct Preference Optimization\n(DPO) augmented with a lightweight margin signal; and (4) provides an automated\nfeedback evaluation protocol. Empirically, DPO-f+ outperforms both the baseline\nand standard DPO on generated-code accuracy and overall feedback alignment. On\nnovice programming tasks, DPO-f+ raises the top-1 pass rate by 5.71 percentage\npoints (pp) over the baseline and by 3.30 pp over DPO. On the more challenging\nSWE-bench Lite benchmark, it increases the issue-resolution rate by 1.67 pp\nover DPO and by 4.67 pp over the baseline. It also achieves the largest\nimprovement in feedback alignment, outperforming DPO and the baseline. By\naligning feedback more closely with developer needs, DPO-f+ turns LLM-assisted\nrepair from one-shot outputs into a collaborative sensemaking workflow,\nproviding a practical approach to enhancing code comprehension and fostering\nmore effective human-AI teaming in software engineering.", "AI": {"tldr": "DPO-f+ \u6846\u67b6\u4f18\u5316\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u4fee\u590d\u4e2d\u7684\u53cd\u9988\uff0c\u4f7f\u5176\u66f4\u7b26\u5408\u5f00\u53d1\u8005\u9700\u6c42\uff0c\u63d0\u5347\u4e86\u4ee3\u7801\u51c6\u786e\u7387\u548c\u53cd\u9988\u8d28\u91cf\uff0c\u4fc3\u8fdb\u4e86\u4eba\u673a\u534f\u4f5c\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u4fee\u590d\u591a\u5173\u6ce8\u4ee3\u7801\u7ed3\u679c\uff0c\u7f3a\u4e4f\u8ba9\u5f00\u53d1\u8005\u7406\u89e3\u548c\u8fed\u4ee3\u6539\u8fdb\u7684\u81ea\u7136\u8bed\u8a00\u53cd\u9988\uff0c\u9650\u5236\u4e86\u4eba\u673a\u534f\u4f5c\u6548\u7387\u3002", "method": "\u63d0\u51faDPO-f+\u6846\u67b6\uff0c\u5b9a\u4e49\u5f00\u53d1\u8005\u753b\u50cf\u76f8\u5173\u53cd\u9988\u6307\u6807\uff0c\u81ea\u52a8\u6784\u5efa\u504f\u597d\u6570\u636e\u96c6\uff0c\u57fa\u4e8e\u6539\u8fdb\u7684\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u81ea\u52a8\u53cd\u9988\u8bc4\u4f30\u673a\u5236\u3002", "result": "DPO-f+\u5728\u65b0\u624b\u7f16\u7a0b\u4efb\u52a1\u548cSWE-bench Lite\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u663e\u8457\u63d0\u5347\u4fee\u590d\u51c6\u786e\u7387\u548c\u53cd\u9988\u5bf9\u9f50\u5ea6\uff0c\u76f8\u8f83\u57fa\u7ebf\u548c\u6807\u51c6DPO\u5747\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u66f4\u597d\u5730\u5bf9\u9f50\u53cd\u9988\u4e0e\u5f00\u53d1\u8005\u9700\u6c42\uff0cDPO-f+\u5c06\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4ee3\u7801\u4fee\u590d\u8f6c\u53d8\u4e3a\u534f\u4f5c\u5f0f\u7684\u7406\u89e3\u8fc7\u7a0b\uff0c\u589e\u5f3a\u4e86\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u548c\u4eba\u673a\u534f\u4f5c\u6548\u679c\u3002"}}
{"id": "2511.00537", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00537", "abs": "https://arxiv.org/abs/2511.00537", "authors": ["Peter Atandoh", "Jie Zou", "Weikang Guo", "Jiwei Wei", "Zheng Wang"], "title": "Multi-refined Feature Enhanced Sentiment Analysis Using Contextual Instruction", "comment": null, "summary": "Sentiment analysis using deep learning and pre-trained language models (PLMs)\nhas gained significant traction due to their ability to capture rich contextual\nrepresentations. However, existing approaches often underperform in scenarios\ninvolving nuanced emotional cues, domain shifts, and imbalanced sentiment\ndistributions. We argue that these limitations stem from inadequate semantic\ngrounding, poor generalization to diverse linguistic patterns, and biases\ntoward dominant sentiment classes. To overcome these challenges, we propose\nCISEA-MRFE, a novel PLM-based framework integrating Contextual Instruction\n(CI), Semantic Enhancement Augmentation (SEA), and Multi-Refined Feature\nExtraction (MRFE). CI injects domain-aware directives to guide sentiment\ndisambiguation; SEA improves robustness through sentiment-consistent\nparaphrastic augmentation; and MRFE combines a Scale-Adaptive Depthwise Encoder\n(SADE) for multi-scale feature specialization with an Emotion Evaluator Context\nEncoder (EECE) for affect-aware sequence modeling. Experimental results on four\nbenchmark datasets demonstrate that CISEA-MRFE consistently outperforms strong\nbaselines, achieving relative improvements in accuracy of up to 4.6% on IMDb,\n6.5% on Yelp, 30.3% on Twitter, and 4.1% on Amazon. These results validate the\neffectiveness and generalization ability of our approach for sentiment\nclassification across varied domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\u7684CISEA-MRFE\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u6307\u4ee4\u3001\u8bed\u4e49\u589e\u5f3a\u548c\u591a\u91cd\u7279\u5f81\u63d0\u53d6\uff0c\u63d0\u5347\u60c5\u611f\u5206\u6790\u5728\u7ec6\u5fae\u60c5\u7eea\u3001\u9886\u57df\u53d8\u5316\u548c\u4e0d\u5e73\u8861\u60c5\u611f\u5206\u5e03\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u5728\u5904\u7406\u7ec6\u5fae\u60c5\u7eea\u7ebf\u7d22\u3001\u9886\u57df\u8fc1\u79fb\u548c\u60c5\u611f\u7c7b\u522b\u4e0d\u5e73\u8861\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u7531\u4e8e\u8bed\u4e49\u57fa\u7840\u4e0d\u8db3\u3001\u5bf9\u591a\u6837\u8bed\u8a00\u6a21\u5f0f\u6cdb\u5316\u80fd\u529b\u5dee\u53ca\u504f\u5411\u4e3b\u5bfc\u60c5\u611f\u7c7b\u522b\u3002", "method": "\u63d0\u51faCISEA-MRFE\u6846\u67b6\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u6307\u4ee4\uff08CI\uff09\u6ce8\u5165\u9886\u57df\u611f\u77e5\u6307\u5bfc\u3001\u8bed\u4e49\u589e\u5f3a\u6570\u636e\u6269\u5145\uff08SEA\uff09\u63d0\u5347\u7a33\u5065\u6027\uff0c\u4ee5\u53ca\u591a\u91cd\u7279\u5f81\u63d0\u53d6\uff08MRFE\uff09\u7ed3\u5408\u5c3a\u5ea6\u81ea\u9002\u5e94\u7f16\u7801\u5668\uff08SADE\uff09\u548c\u60c5\u611f\u8bc4\u4f30\u4e0a\u4e0b\u6587\u7f16\u7801\u5668\uff08EECE\uff09\u5b9e\u73b0\u591a\u5c3a\u5ea6\u7279\u5f81\u4e13\u5316\u548c\u60c5\u611f\u611f\u77e5\u5e8f\u5217\u5efa\u6a21\u3002", "result": "\u5728IMDb\u3001Yelp\u3001Twitter\u548cAmazon\u56db\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cCISEA-MRFE\u76f8\u8f83\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u5206\u522b\u63d0\u5347\u51c6\u786e\u73874.6%\u30016.5%\u300130.3%\u548c4.1%\u3002", "conclusion": "CISEA-MRFE\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u60c5\u611f\u5206\u7c7b\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\uff0c\u5c24\u5176\u5728\u591a\u9886\u57df\u548c\u60c5\u611f\u5206\u5e03\u4e0d\u5747\u7b49\u590d\u6742\u573a\u666f\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.01047", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01047", "abs": "https://arxiv.org/abs/2511.01047", "authors": ["Yu Shi", "Hao Li", "Bram Adams", "Ahmed E. Hassan"], "title": "HAFixAgent: History-Aware Automated Program Repair Agent", "comment": "31 pages, 6 figures", "summary": "Automated program repair (APR) has recently shifted toward large language\nmodels and agent-based systems, yet most systems rely on local snapshot\ncontext, overlooking repository history. Prior work shows that repository\nhistory helps repair single-line bugs, since the last commit touching the buggy\nline is often the bug-introducing one. In this paper, we investigate whether\nrepository history can also improve agentic APR systems at scale, especially\nfor complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing\nAgent that injects blame-derived repository heuristics into its repair loop. A\npreliminary study of all 854 real-world bugs from Defects4J motivates our\ndesign, showing that bug-relevant history is both widely available and highly\nconcentrated. Empirical comparison of HAFixAgent with two state-of-the-art\nbaselines shows: (1) Effectiveness: HAFixAgent significantly improves over the\nagent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)\nEfficiency: history does not significantly increase agent steps and keeps token\ncosts comparable, with notably lower median costs for complex\nmulti-file-multi-hunk bugs. (3) Practicality: combining different historical\nheuristics repairs more bugs, offering a clear cost-benefit trade-off.\nHAFixAgent offers a practical recipe for history-aware agentic APR: ground the\nagent in version control history, prioritize diff-based historical context, and\nintegrate complementary heuristics when needed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aHAFixAgent\u7684\u57fa\u4e8e\u5386\u53f2\u611f\u77e5\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u5229\u7528\u4ee3\u7801\u4ed3\u5e93\u5386\u53f2\u4fe1\u606f\u663e\u8457\u63d0\u5347\u590d\u6742\u591a\u5904\u4fee\u6539\uff08multi-hunk\uff09\u7f3a\u9677\u7684\u4fee\u590d\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4ee3\u7406\u7684\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7cfb\u7edf\u5927\u591a\u4f9d\u8d56\u5c40\u90e8\u5feb\u7167\u4e0a\u4e0b\u6587\uff0c\u5ffd\u89c6\u4e86\u4ed3\u5e93\u7684\u5386\u53f2\u4fe1\u606f\uff0c\u7136\u800c\u4e4b\u524d\u7684\u7814\u7a76\u8868\u660e\u5386\u53f2\u4fe1\u606f\u5bf9\u5355\u884c\u7f3a\u9677\u7684\u4fee\u590d\u6709\u5e2e\u52a9\uff0c\u56e0\u6b64\u63a2\u7a76\u5386\u53f2\u4fe1\u606f\u80fd\u5426\u63d0\u5347\u590d\u6742\u7f3a\u9677\u7684\u4fee\u590d\u6548\u679c\u3002", "method": "HAFixAgent\u901a\u8fc7\u6ce8\u5165\u57fa\u4e8e\u7f3a\u9677\u8d23\u4efb\u8ba4\u5b9a\uff08blame\uff09\u7684\u5386\u53f2\u542f\u53d1\u5f0f\u4fe1\u606f\u8fdb\u5165\u4fee\u590d\u5faa\u73af\uff0c\u501f\u52a9\u7248\u672c\u63a7\u5236\u4e2d\u7684\u5dee\u5f02\u5386\u53f2\u53ca\u591a\u79cd\u4e92\u8865\u7684\u5386\u53f2\u542f\u53d1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u5386\u53f2\u611f\u77e5\u7684\u4fee\u590d\u3002", "result": "\u5728Defects4J\u6570\u636e\u96c6\u4e0a\uff0cHAFixAgent\u5728\u4fee\u590d\u6548\u679c\u4e0a\u5206\u522b\u8f83\u57fa\u7ebf\u7cfb\u7edf\u63d0\u5347212.3%\uff08\u4ee3\u7406\u57fa\u7ebf\uff09\u548c29.9%\uff08\u591ahunk\u57fa\u7ebf\uff09\uff0c\u4fee\u590d\u6b65\u9aa4\u548ctoken\u6210\u672c\u65e0\u660e\u663e\u589e\u52a0\uff0c\u590d\u6742\u7f3a\u9677\u7684\u6210\u672c\u663e\u8457\u964d\u4f4e\uff0c\u591a\u79cd\u5386\u53f2\u542f\u53d1\u7ed3\u5408\u80fd\u4fee\u590d\u66f4\u591a\u7f3a\u9677\u3002", "conclusion": "HAFixAgent\u9a8c\u8bc1\u4e86\u5229\u7528\u7248\u672c\u63a7\u5236\u5386\u53f2\u4fe1\u606f\u6765\u6539\u8fdb\u4ee3\u7406\u5f0f\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\uff0c\u63d0\u51fa\u4e86\u4ee5\u5386\u53f2\u4fe1\u606f\u4e3a\u57fa\u7840\u3001\u4f18\u5148\u8003\u8651\u5dee\u5f02\u5386\u53f2\u4e0a\u4e0b\u6587\u5e76\u7ed3\u5408\u591a\u79cd\u542f\u53d1\u5f0f\u7684\u5b9e\u7528\u4fee\u590d\u7b56\u7565\u3002"}}
{"id": "2511.00556", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00556", "abs": "https://arxiv.org/abs/2511.00556", "authors": ["Peng Ding", "Jun Kuang", "Wen Sun", "Zongyu Wang", "Xuezhi Cao", "Xunliang Cai", "Jiajun Chen", "Shujian Huang"], "title": "Friend or Foe: How LLMs' Safety Mind Gets Fooled by Intent Shift Attack", "comment": "Preprint, 14 pages, 5 figures, 7 tables", "summary": "Large language models (LLMs) remain vulnerable to jailbreaking attacks\ndespite their impressive capabilities. Investigating these weaknesses is\ncrucial for robust safety mechanisms. Existing attacks primarily distract LLMs\nby introducing additional context or adversarial tokens, leaving the core\nharmful intent unchanged. In this paper, we introduce ISA (Intent Shift\nAttack), which obfuscates LLMs about the intent of the attacks. More\nspecifically, we establish a taxonomy of intent transformations and leverage\nthem to generate attacks that may be misperceived by LLMs as benign requests\nfor information. Unlike prior methods relying on complex tokens or lengthy\ncontext, our approach only needs minimal edits to the original request, and\nyields natural, human-readable, and seemingly harmless prompts. Extensive\nexperiments on both open-source and commercial LLMs show that ISA achieves over\n70% improvement in attack success rate compared to direct harmful prompts. More\ncritically, fine-tuning models on only benign data reformulated with ISA\ntemplates elevates success rates to nearly 100%. For defense, we evaluate\nexisting methods and demonstrate their inadequacy against ISA, while exploring\nboth training-free and training-based mitigation strategies. Our findings\nreveal fundamental challenges in intent inference for LLMs safety and\nunderscore the need for more effective defenses. Our code and datasets are\navailable at https://github.com/NJUNLP/ISA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aISA\u7684\u610f\u56fe\u8f6c\u6362\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u4fee\u6539\u539f\u59cb\u8bf7\u6c42\uff0c\u4f2a\u88c5\u6210\u65e0\u5bb3\u4fe1\u606f\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u8bef\u5224\u653b\u51fb\u610f\u56fe\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u653b\u51fb\u6210\u529f\u7387\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5f3a\u5927\uff0c\u4f46\u4ecd\u6613\u88ab\u8d8a\u72f1\u653b\u51fb\u5229\u7528\uff0c\u73b0\u6709\u653b\u51fb\u65b9\u6cd5\u591a\u901a\u8fc7\u6dfb\u52a0\u4e0a\u4e0b\u6587\u6216\u5bf9\u6297\u6027\u8bcd\u6c47\uff0c\u672a\u6539\u53d8\u6838\u5fc3\u6076\u610f\u610f\u56fe\uff0c\u9632\u5fa1\u56f0\u96be\u3002\u901a\u8fc7\u6df7\u6dc6\u653b\u51fb\u610f\u56fe\uff0c\u53ef\u4ee5\u66f4\u6709\u6548\u5730\u7a81\u7834\u6a21\u578b\u5b89\u5168\u673a\u5236\u3002", "method": "\u8bbe\u8ba1\u610f\u56fe\u8f6c\u6362\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5229\u7528\u6700\u5c0f\u7f16\u8f91\u751f\u6210\u81ea\u7136\u4e14\u6613\u8bfb\u7684\u63d0\u793a\uff0c\u6b3a\u9a97\u6a21\u578b\u8bef\u4ee5\u4e3a\u662f\u65e0\u5bb3\u8bf7\u6c42\u3002\u8be5\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u590d\u6742\u8bcd\u6c47\u6216\u957f\u6587\u672c\u3002\u5e76\u901a\u8fc7\u5b9e\u9a8c\u5bf9\u6bd4ISA\u548c\u4f20\u7edf\u653b\u51fb\u6548\u679c\u3002", "result": "ISA\u5728\u5f00\u6e90\u548c\u5546\u7528\u6a21\u578b\u4e0a\u653b\u51fb\u6210\u529f\u7387\u63d0\u9ad870%\u4ee5\u4e0a\uff0c\u4e14\u901a\u8fc7\u4ec5\u7528ISA\u6a21\u677f\u751f\u6210\u7684\u65e0\u5bb3\u6570\u636e\u5fae\u8c03\u6a21\u578b\u540e\uff0c\u653b\u51fb\u6210\u529f\u7387\u63a5\u8fd1100%\u3002\u6d4b\u8bd5\u663e\u793a\u73b0\u6709\u9632\u5fa1\u624b\u6bb5\u5bf9ISA\u6548\u679c\u4e0d\u8db3\u3002", "conclusion": "\u610f\u56fe\u63a8\u65ad\u662f\u5927\u8bed\u8a00\u6a21\u578b\u5b89\u5168\u9632\u62a4\u7684\u6839\u672c\u6311\u6218\uff0c\u73b0\u6709\u9632\u5fa1\u5c1a\u4e0d\u5145\u5206\uff0c\u672a\u6765\u9700\u5f00\u53d1\u66f4\u6709\u6548\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2511.01104", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01104", "abs": "https://arxiv.org/abs/2511.01104", "authors": ["Yujian Liu", "Jiabao Ji", "Yang Zhang", "Wenbo Guo", "Tommi Jaakkola", "Shiyu Chang"], "title": "HarnessLLM: Automatic Testing Harness Generation via Reinforcement Learning", "comment": null, "summary": "Existing LLM-based automatic test generation methods mainly produce input and\nexpected output pairs to categorize the intended behavior of correct programs.\nAlthough straightforward, these methods have limited diversity in generated\ntests and cannot provide enough debugging information. We propose HarnessLLM, a\ntwo-stage training pipeline that enables LLMs to write harness code for\ntesting. Particularly, LLMs generate code that synthesizes inputs and validates\nthe observed outputs, allowing complex test cases and flexible output\nvalidation such as invariant checking. To achieve this, we train LLMs with SFT\nfollowed by RLVR with a customized reward design. Experiments show that\nHarnessLLM outperforms input-output-based testing in bug finding and testing\nstrategy diversity. HarnessLLM further benefits the code generation performance\nthrough test-time scaling with our generated test cases as inference-phase\nvalidation. Our code is available at\nhttps://github.com/UCSB-NLP-Chang/HarnessLLM.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HarnessLLM\uff0c\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d4b\u8bd5\u6846\u67b6\u4ee3\u7801\u7684\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u591a\u6837\u6027\u548c\u8c03\u8bd5\u4fe1\u606f\u4e30\u5bcc\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u4ec5\u751f\u6210\u8f93\u5165\u8f93\u51fa\u5bf9\uff0c\u6d4b\u8bd5\u591a\u6837\u6027\u6709\u9650\u4e14\u8c03\u8bd5\u4fe1\u606f\u4e0d\u8db3\u3002", "method": "\u63d0\u51faHarnessLLM\uff0c\u4f7f\u7528SFT\u548c\u5b9a\u5236\u5956\u52b1\u8bbe\u8ba1\u7684RLVR\u4e24\u9636\u6bb5\u8bad\u7ec3\uff0c\u4f7fLLM\u80fd\u751f\u6210\u8f93\u5165\u5408\u6210\u53ca\u8f93\u51fa\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u6846\u67b6\u4ee3\u7801\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cHarnessLLM\u5728\u53d1\u73b0BUG\u548c\u6d4b\u8bd5\u7b56\u7565\u591a\u6837\u6027\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u8f93\u5165\u8f93\u51fa\u5bf9\u6d4b\u8bd5\uff0c\u540c\u65f6\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "HarnessLLM\u901a\u8fc7\u751f\u6210\u590d\u6742\u6d4b\u8bd5\u7528\u4f8b\u548c\u7075\u6d3b\u7684\u8f93\u51fa\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u6d4b\u8bd5\u7684\u6548\u679c\u4e0e\u4ee3\u7801\u751f\u6210\u80fd\u529b\u3002"}}
{"id": "2511.00576", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00576", "abs": "https://arxiv.org/abs/2511.00576", "authors": ["Juan Gabriel Kostelec", "Qinghai Guo"], "title": "FlashEVA: Accelerating LLM inference via Efficient Attention", "comment": "Technical Report", "summary": "Transformer models have revolutionized natural language processing, achieving\nstate-of-the-art performance and demonstrating remarkable scalability. However,\ntheir memory demands, particularly due to maintaining full context in memory,\npose significant challenges for inference. In this paper, we present FlashEVA,\nan efficient implementation of EVA (Efficient Attention via Control Variates),\nand demonstrate how to finetune transformers to adapt to FlashEVA attention.\nOur method enables fine-tuning of Transformer models with as few as 1.5B tokens\nwhile preserving effectiveness across various downstream tasks. Notably,\nFlashEVA achieves up to 6.7x higher throughput and 5x lower peak GPU memory\nusage during inference compared to standard Transformer implementations.\nDespite these improvements, we observe limitations in retrieval-focused tasks.\nOur implementation offers control over the trade-off between throughput and\naccuracy through adjustable hyperparameters, providing flexibility for diverse\nuse cases. This work represents a significant step towards more efficient and\nadaptable Transformer-based models for inference.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86FlashEVA\uff0c\u4e00\u79cd\u9ad8\u6548\u7684EVA\u6ce8\u610f\u529b\u673a\u5236\u5b9e\u73b0\uff0c\u901a\u8fc7\u5fae\u8c03Transformer\u6a21\u578b\uff0c\u5b9e\u73b0\u63a8\u7406\u9636\u6bb5\u663e\u8457\u964d\u4f4e\u5185\u5b58\u5360\u7528\u548c\u63d0\u5347\u541e\u5410\u7387\u3002", "motivation": "Transformer\u6a21\u578b\u6027\u80fd\u5f3a\u5927\u4f46\u5bf9\u5185\u5b58\u8981\u6c42\u9ad8\uff0c\u5c24\u5176\u662f\u7ef4\u62a4\u5168\u4e0a\u4e0b\u6587\u65f6\uff0c\u5bfc\u81f4\u63a8\u7406\u9636\u6bb5\u6548\u7387\u4f4e\uff0c\u4e9f\u9700\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faFlashEVA\u5b9e\u73b0EVA\u6ce8\u610f\u529b\uff0c\u901a\u8fc7\u5fae\u8c03\u4ec5\u75281.5B tokens\uff0c\u4f7f\u6a21\u578b\u9002\u914dFlashEVA\uff1b\u63d0\u4f9b\u8d85\u53c2\u6570\u8c03\u6574\u4ee5\u6743\u8861\u541e\u5410\u91cf\u548c\u51c6\u786e\u7387\u3002", "result": "\u63a8\u7406\u65f6\u541e\u5410\u91cf\u63d0\u5347\u6700\u591a6.7\u500d\uff0c\u5cf0\u503cGPU\u5185\u5b58\u4f7f\u7528\u964d\u4f4e5\u500d\uff1b\u4fdd\u6301\u591a\u4efb\u52a1\u6548\u679c\uff0c\u68c0\u7d22\u4efb\u52a1\u8868\u73b0\u6709\u9650\u3002", "conclusion": "FlashEVA\u663e\u8457\u63d0\u5347Transformer\u63a8\u7406\u7684\u6548\u7387\u548c\u9002\u5e94\u6027\uff0c\u662f\u5b9e\u73b0\u9ad8\u6548\u53ef\u8c03Transformer\u6a21\u578b\u7684\u91cd\u8981\u8fdb\u5c55\u3002"}}
{"id": "2511.01176", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01176", "abs": "https://arxiv.org/abs/2511.01176", "authors": ["Wenqing Zhu", "Norihiro Yoshida", "Eunjong Choi", "Yutaka Matsubara", "Hiroaki Takada"], "title": "An Empirical Study of LLM-Based Code Clone Detection", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable capabilities in\nvarious software engineering tasks, such as code generation and debugging,\nbecause of their ability to translate between programming languages and natural\nlanguages. Existing studies have demonstrated the effectiveness of LLMs in code\nclone detection. However, two crucial issues remain unaddressed: the ability of\nLLMs to achieve comparable performance across different datasets and the\nconsistency of LLMs' responses in code clone detection. To address these\nissues, we constructed seven code clone datasets and then evaluated five LLMs\nin four existing prompts with these datasets. The datasets were created by\nsampling code pairs using their Levenshtein ratio from two different code\ncollections, CodeNet and BigCloneBench. Our evaluation revealed that although\nLLMs perform well in CodeNet-related datasets, with o3-mini achieving a 0.943\nF1 score, their performance significantly decreased in BigCloneBench-related\ndatasets. Most models achieved a high response consistency, with over 90\\% of\njudgments remaining consistent across all five submissions. The fluctuations of\nthe F1 score affected by inconsistency are also tiny; their variations are less\nthan 0.03.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4efb\u52a1\u4e2d\u7684\u8de8\u6570\u636e\u96c6\u6027\u80fd\u548c\u54cd\u5e94\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u867d\u8bc1\u660eLLMs\u5728\u4ee3\u7801\u514b\u9686\u68c0\u6d4b\u4e2d\u6709\u6548\uff0c\u4f46\u672a\u89e3\u51b3\u4e0d\u540c\u6570\u636e\u96c6\u6027\u80fd\u4e00\u81f4\u6027\u548c\u6a21\u578b\u54cd\u5e94\u7a33\u5b9a\u6027\u7684\u95ee\u9898\u3002", "method": "\u6784\u5efa\u4e03\u4e2a\u4ee3\u7801\u514b\u9686\u6570\u636e\u96c6\uff0c\u91c7\u7528\u56db\u79cd\u63d0\u793a\u8bed\u5bf9\u4e94\u4e2aLLMs\u8fdb\u884c\u8bc4\u4f30\uff0c\u6570\u636e\u96c6\u53d6\u81eaCodeNet\u548cBigCloneBench\uff0c\u6837\u672c\u901a\u8fc7Levenshtein\u6bd4\u7387\u91c7\u6837\u3002", "result": "LLMs\u5728CodeNet\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u5f02\uff0c\u6700\u9ad8F1\u8fbe\u52300.943\uff0c\u4f46\u5728BigCloneBench\u6570\u636e\u96c6\u8868\u73b0\u663e\u8457\u4e0b\u964d\u3002\u5927\u591a\u6570\u6a21\u578b\u54cd\u5e94\u4e00\u81f4\u6027\u9ad8\uff0c\u8d85\u8fc790%\u7684\u5224\u65ad\u4fdd\u6301\u4e00\u81f4\uff0cF1\u5f97\u5206\u6ce2\u52a8\u5c0f\u4e8e0.03\u3002", "conclusion": "LLMs\u5bf9\u4e0d\u540c\u6570\u636e\u96c6\u7684\u9002\u5e94\u6027\u4ecd\u6709\u9650\uff0c\u4f46\u5177\u6709\u8f83\u9ad8\u7684\u54cd\u5e94\u7a33\u5b9a\u6027\uff0c\u63d0\u793a\u672a\u6765\u9700\u63d0\u5347\u6a21\u578b\u7684\u8de8\u6570\u636e\u96c6\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.00602", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00602", "abs": "https://arxiv.org/abs/2511.00602", "authors": ["Wai-Chung Kwan", "Joshua Ong Jun Leang", "Pavlos Vougiouklis", "Jeff Z. Pan", "Marco Valentino", "Pasquale Minervini"], "title": "OpenSIR: Open-Ended Self-Improving Reasoner", "comment": null, "summary": "Recent advances in large language model (LLM) reasoning through reinforcement\nlearning rely on annotated datasets for verifiable rewards, which may limit\nmodels' ability to surpass human-level performance. While self-play offers a\npromising alternative, existing approaches depend on external verifiers or\ncannot learn open-endedly. We present Open-Ended Self-Improving Reasoner\n(OpenSIR), a self-play framework where an LLM learns to generate and solve\nnovel problems by alternating teacher and student roles without external\nsupervision. To generate novel problems, OpenSIR optimises for both difficulty\nand diversity, rewarding problems that challenge appropriately while exploring\ndistinct concepts, enabling open-ended mathematical discovery. Starting from a\nsingle trivial seed problem, OpenSIR substantially improves instruction models:\nLlama-3.2-3B-Instruct advances from 73.9 to 78.3 on GSM8K, and from 28.8 to\n34.4 on College Math, while Gemma-2-2B-Instruct rises from 38.5 to 58.7 on\nGSM8K. Our analyses reveal that OpenSIR achieves open-ended learning through\nco-evolving teacher-student roles that adaptively calibrate difficulty and\ndrive diverse exploration, progressing autonomously from basic to advanced\nmathematics.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86OpenSIR\uff0c\u4e00\u79cd\u901a\u8fc7\u81ea\u6211\u5bf9\u5f08\u5b9e\u73b0\u5f00\u6e90\u5f0f\u81ea\u6211\u63d0\u5347\u7684\u63a8\u7406\u6846\u67b6\uff0c\u4e0d\u4f9d\u8d56\u5916\u90e8\u76d1\u7763\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\u4f9d\u8d56\u5e26\u6ce8\u91ca\u7684\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u6a21\u578b\u8d85\u8d8a\u4eba\u7c7b\u6c34\u5e73\u7684\u80fd\u529b\u3002\u81ea\u6211\u5bf9\u5f08\u867d\u6709\u6f5c\u529b\uff0c\u4f46\u4f9d\u8d56\u5916\u90e8\u9a8c\u8bc1\u5668\u6216\u65e0\u6cd5\u5b9e\u73b0\u5f00\u653e\u5f0f\u5b66\u4e60\u3002", "method": "OpenSIR\u901a\u8fc7\u8ba9LLM\u4ea4\u66ff\u626e\u6f14\u6559\u5e08\u548c\u5b66\u751f\u89d2\u8272\uff0c\u81ea\u751f\u6210\u5e76\u89e3\u51b3\u65b0\u95ee\u9898\u3002\u5176\u95ee\u9898\u751f\u6210\u4f18\u5316\u96be\u5ea6\u4e0e\u591a\u6837\u6027\uff0c\u9f13\u52b1\u6311\u6218\u6027\u548c\u63a2\u7d22\u4e0d\u540c\u6982\u5ff5\uff0c\u5b9e\u73b0\u5f00\u6e90\u7684\u6570\u5b66\u53d1\u73b0\u3002", "result": "\u4ece\u5355\u4e00\u7b80\u5355\u8d77\u59cb\u95ee\u9898\u5f00\u59cb\uff0cOpenSIR\u663e\u8457\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff1aLlama-3.2-3B-Instruct\u5728GSM8K\u548cCollege Math\u4e0a\u7684\u6210\u7ee9\u5206\u522b\u63d0\u5347\u81f378.3\u548c34.4\uff0cGemma-2-2B-Instruct\u5728GSM8K\u4e0a\u7684\u6210\u7ee9\u63d0\u5347\u81f358.7\u3002", "conclusion": "OpenSIR\u901a\u8fc7\u6559\u5e08-\u5b66\u751f\u89d2\u8272\u7684\u534f\u540c\u8fdb\u5316\uff0c\u81ea\u9002\u5e94\u8c03\u6574\u96be\u5ea6\u9a71\u52a8\u591a\u6837\u63a2\u7d22\uff0c\u5b9e\u73b0\u4e86\u4ece\u57fa\u7840\u5230\u9ad8\u7ea7\u6570\u5b66\u7684\u81ea\u4e3b\u5f00\u653e\u5f0f\u5b66\u4e60\u3002"}}
{"id": "2511.01252", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01252", "abs": "https://arxiv.org/abs/2511.01252", "authors": ["Siyuan Li", "Yaowen Zheng", "Hong Li", "Jingdong Guo", "Chaopeng Dong", "Chunpeng Yan", "Weijie Wang", "Yimo Ren", "Limin Sun", "Hongsong Zhu"], "title": "Lares: LLM-driven Code Slice Semantic Search for Patch Presence Testing", "comment": null, "summary": "In modern software ecosystems, 1-day vulnerabilities pose significant\nsecurity risks due to extensive code reuse. Identifying vulnerable functions in\ntarget binaries alone is insufficient; it is also crucial to determine whether\nthese functions have been patched. Existing methods, however, suffer from\nlimited usability and accuracy. They often depend on the compilation process to\nextract features, requiring substantial manual effort and failing for certain\nsoftware. Moreover, they cannot reliably differentiate between code changes\ncaused by patches or compilation variations. To overcome these limitations, we\npropose Lares, a scalable and accurate method for patch presence testing. Lares\nintroduces Code Slice Semantic Search, which directly extracts features from\nthe patch source code and identifies semantically equivalent code slices in the\npseudocode of the target binary. By eliminating the need for the compilation\nprocess, Lares improves usability, while leveraging large language models\n(LLMs) for code analysis and SMT solvers for logical reasoning to enhance\naccuracy. Experimental results show that Lares achieves superior precision,\nrecall, and usability. Furthermore, it is the first work to evaluate patch\npresence testing across optimization levels, architectures, and compilers. The\ndatasets and source code used in this article are available at\nhttps://github.com/Siyuan-Li201/Lares.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLares\u7684\u65b9\u6cd5\uff0c\u65e8\u5728\u51c6\u786e\u68c0\u6d4b\u76ee\u6807\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\u8865\u4e01\u7684\u5b58\u5728\uff0c\u514b\u670d\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u6f0f\u6d1e\u51fd\u6570\u662f\u5426\u88ab\u4fee\u8865\u7684\u65b9\u6cd5\u4f9d\u8d56\u7f16\u8bd1\u8fc7\u7a0b\uff0c\u64cd\u4f5c\u590d\u6742\u4e14\u51c6\u786e\u7387\u4e0d\u9ad8\uff0c\u96be\u4ee5\u533a\u5206\u8865\u4e01\u6539\u52a8\u4e0e\u7f16\u8bd1\u5dee\u5f02\u3002", "method": "Lares\u901a\u8fc7\u76f4\u63a5\u4ece\u8865\u4e01\u6e90\u4ee3\u7801\u63d0\u53d6\u7279\u5f81\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u548cSMT\u6c42\u89e3\u5668\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u8bc6\u522b\u76ee\u6807\u4e8c\u8fdb\u5236\u4f2a\u4ee3\u7801\u4e2d\u7684\u7b49\u4ef7\u4ee3\u7801\u7247\u6bb5\uff0c\u907f\u514d\u4f9d\u8d56\u7f16\u8bd1\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u8868\u660eLares\u5728\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u548c\u53ef\u7528\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u662f\u9996\u4e2a\u5728\u4e0d\u540c\u4f18\u5316\u7ea7\u522b\u3001\u67b6\u6784\u548c\u7f16\u8bd1\u5668\u4e0a\u8bc4\u4f30\u8865\u4e01\u68c0\u6d4b\u7684\u65b9\u6cd5\u3002", "conclusion": "Lares\u63d0\u5347\u4e86\u6f0f\u6d1e\u8865\u4e01\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u4e0e\u53ef\u7528\u6027\uff0c\u4e3a\u8f6f\u4ef6\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2511.00606", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00606", "abs": "https://arxiv.org/abs/2511.00606", "authors": ["Jameson Sandler", "Jacob K. Christopher", "Thomas Hartvigsen", "Nando Fioretto"], "title": "SpecDiff-2: Scaling Diffusion Drafter Alignment For Faster Speculative Decoding", "comment": null, "summary": "Speculative decoding has become the standard approach for accelerating Large\nLanguage Model (LLM) inference. It exploits a lossless draft-then-verify\nprocedure to circumvent the latency of autoregressive decoding, achieving\nimpressive speed-ups. Yet, current speculative decoding approaches remain\nlimited by two fundamental bottlenecks: (1) the autoregressive dependency\nduring drafting which limits parallelism, and (2) frequent rejections of draft\ntokens caused by misalignment between the draft and verify models. This paper\nproposes SpecDiff-2, a novel framework to jointly address these two\nbottlenecks. It leverages discrete diffusion as a non-autoregressive drafter to\naddress bottleneck (1) and develops novel techniques to calibrate discrete\ndiffusion drafters with autoregressive verifiers, addressing bottleneck (2).\nExperimental results across a comprehensive benchmark suite show that\nSpecDiff-2 achieves a new state-of-the-art across reasoning, coding, and\nmathematical benchmarks, improving tokens-per-second by up to an average of\n+55% over previous baselines and obtaining up to 5.5x average speed-up over\nstandard decoding, without any loss of accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpecDiff-2\u7684\u63a8\u6d4b\u6027\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u79bb\u6563\u6269\u6563\u975e\u81ea\u56de\u5f52\u8d77\u8349\u4e0e\u81ea\u56de\u5f52\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u52a0\u901f\u548c\u7cbe\u5ea6\u65e0\u635f\u3002", "motivation": "\u5f53\u524d\u63a8\u6d4b\u6027\u89e3\u7801\u53d7\u9650\u4e8e\u81ea\u56de\u5f52\u8d77\u8349\u7684\u4e32\u884c\u4f9d\u8d56\u548c\u8d77\u8349\u4e0e\u9a8c\u8bc1\u6a21\u578b\u8bef\u5dee\u5bfc\u81f4\u7684\u4ee4\u724c\u62d2\u7edd\uff0c\u9650\u5236\u4e86\u52a0\u901f\u6548\u679c\u3002", "method": "SpecDiff-2\u5229\u7528\u79bb\u6563\u6269\u6563\u4f5c\u4e3a\u975e\u81ea\u56de\u5f52\u8d77\u8349\u5668\uff0c\u63d0\u5347\u5e76\u884c\u5ea6\uff0c\u540c\u65f6\u8bbe\u8ba1\u6821\u51c6\u6280\u672f\u534f\u8c03\u8d77\u8349\u5668\u4e0e\u9a8c\u8bc1\u5668\uff0c\u51cf\u5c11\u8bef\u62d2\u3002", "result": "\u5728\u63a8\u7406\u3001\u7f16\u7a0b\u53ca\u6570\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSpecDiff-2\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u5e73\u5747\u63d0\u534755%\u5904\u7406\u901f\u5ea6\uff0c\u8f83\u6807\u51c6\u89e3\u7801\u5feb5.5\u500d\uff0c\u4e14\u65e0\u51c6\u786e\u5ea6\u635f\u5931\u3002", "conclusion": "SpecDiff-2\u6709\u6548\u7a81\u7834\u4e86\u63a8\u6d4b\u6027\u89e3\u7801\u7684\u5173\u952e\u74f6\u9888\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\uff0c\u4e3a\u9ad8\u901f\u51c6\u786e\u7684\u6a21\u578b\u63a8\u65ad\u63d0\u4f9b\u4e86\u65b0\u65b9\u6848\u3002"}}
{"id": "2511.01316", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01316", "abs": "https://arxiv.org/abs/2511.01316", "authors": ["Chong Wang", "Chen Zhang", "Jiajun Wu", "Wunan Guo", "Jianfeng Qu", "Yewen Tian", "Yang Liu"], "title": "Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation", "comment": null, "summary": "Continuous Integration (CI) is a cornerstone of modern collaborative software\ndevelopment, and numerous CI platforms are available. Differences in\nmaintenance overhead, reliability, and integration depth with code-hosting\nplatforms make migration between CI platforms a common practice. A central step\nin migration is translating CI configurations, which is challenging due to the\nintrinsic complexity of CI configurations and the need to understand semantic\ndifferences and relationships across CI platforms.\n  With the advent of large language models (LLMs), recent advances in software\nengineering highlight their potential for CI configuration translation. In this\npaper, we present a study on LLM-based CI configuration translation, focusing\non the migration from Travis CI to GitHub Actions. First, using 811 migration\nrecords, we quantify the effort involved and find that developers read an\naverage of 38 lines of Travis configuration and write 58 lines of GitHub\nActions configuration, with nearly half of the migrations requiring multiple\ncommits. We further analyze translations produced by each of the four LLMs and\nidentify 1,121 issues grouped into four categories: logic inconsistencies\n(38%), platform discrepancies (32%), environment errors (25%), and syntax\nerrors (5%). Finally, we evaluate three enhancement strategies and show that\ncombining guideline-based prompting with iterative refinement achieves the best\nperformance, reaching a Build Success Rate of 75.5%-nearly a threefold\nimprovement over GPT-4o with a basic prompt.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u6301\u7eed\u96c6\u6210\uff08CI\uff09\u914d\u7f6e\u8fc1\u79fb\u7684\u6280\u672f\uff0c\u4ee5Travis CI\u5230GitHub Actions\u7684\u8fc1\u79fb\u4e3a\u4f8b\uff0c\u5206\u6790\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u7684\u96be\u70b9\u548c\u4f18\u5316\u7b56\u7565\u3002", "motivation": "CI\u5e73\u53f0\u8fc1\u79fb\u5e38\u89c1\u4f46\u590d\u6742\uff0c\u6d89\u53ca\u914d\u7f6e\u8bed\u4e49\u5dee\u5f02\u548c\u5e73\u53f0\u5dee\u5f02\uff0c\u73b0\u6709\u8fc1\u79fb\u5de5\u5177\u6548\u7387\u4e0d\u9ad8\uff0cLLM\u6709\u6f5c\u529b\u63d0\u5347\u8fc1\u79fb\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u57fa\u4e8e811\u6761\u771f\u5b9e\u8fc1\u79fb\u8bb0\u5f55\uff0c\u5206\u6790\u5f00\u53d1\u8005\u8fc1\u79fb\u52aa\u529b\uff1b\u5bf94\u79cdLLM\u751f\u6210\u7684\u8fc1\u79fb\u7ed3\u679c\u8fdb\u884c\u9519\u8bef\u5206\u7c7b\uff1b\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u7ed3\u5408\u6307\u5bfc\u63d0\u793a\u548c\u8fed\u4ee3\u4f18\u5316\u7684\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u8fc1\u79fb\u4e2d\u5f00\u53d1\u8005\u5e73\u5747\u9700\u9605\u8bfb38\u884c\u65e7\u914d\u7f6e\u3001\u7f16\u519958\u884c\u65b0\u914d\u7f6e\uff0c\u8fd1\u534a\u9700\u591a\u6b21\u63d0\u4ea4\uff1bLLM\u751f\u6210\u914d\u7f6e\u5b58\u5728\u903b\u8f91\u4e0d\u4e00\u81f4\u3001\u5e73\u53f0\u5dee\u5f02\u7b49\u56db\u7c7b\u95ee\u9898\uff1b\u901a\u8fc7\u589e\u5f3a\u7b56\u7565\uff0cBuild\u6210\u529f\u7387\u63d0\u5347\u81f375.5%\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7840GPT-4o\u3002", "conclusion": "\u7ed3\u5408\u63d0\u793a\u6307\u5bfc\u548c\u8fed\u4ee3\u4f18\u5316\u7684LLM\u65b9\u6cd5\u663e\u8457\u63d0\u5347CI\u914d\u7f6e\u8fc1\u79fb\u6548\u679c\uff0c\u5c55\u793a\u4e86LLM\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\u5177\u4f53\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.00620", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00620", "abs": "https://arxiv.org/abs/2511.00620", "authors": ["Autumn Toney-Wails", "Ryan Wails"], "title": "Certain but not Probable? Differentiating Certainty from Probability in LLM Token Outputs for Probabilistic Scenarios", "comment": "To appear at the Second Workshop on Uncertainty-Aware NLP @EMNLP 2025\n  (UncertaiNLP '25)", "summary": "Reliable uncertainty quantification (UQ) is essential for ensuring\ntrustworthy downstream use of large language models, especially when they are\ndeployed in decision-support and other knowledge-intensive applications. Model\ncertainty can be estimated from token logits, with derived probability and\nentropy values offering insight into performance on the prompt task. However,\nthis approach may be inadequate for probabilistic scenarios, where the\nprobabilities of token outputs are expected to align with the theoretical\nprobabilities of the possible outcomes. We investigate the relationship between\ntoken certainty and alignment with theoretical probability distributions in\nwell-defined probabilistic scenarios. Using GPT-4.1 and DeepSeek-Chat, we\nevaluate model responses to ten prompts involving probability (e.g., roll a\nsix-sided die), both with and without explicit probability cues in the prompt\n(e.g., roll a fair six-sided die). We measure two dimensions: (1) response\nvalidity with respect to scenario constraints, and (2) alignment between\ntoken-level output probabilities and theoretical probabilities. Our results\nindicate that, while both models achieve perfect in-domain response accuracy\nacross all prompt scenarios, their token-level probability and entropy values\nconsistently diverge from the corresponding theoretical distributions.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u786e\u5b9a\u6027\u4e0e\u7406\u8bba\u6982\u7387\u5206\u5e03\u7684\u5bf9\u9f50\u6027\uff0c\u53d1\u73b0\u5c3d\u7ba1\u6a21\u578b\u80fd\u51c6\u786e\u56de\u5e94\u6982\u7387\u9898\uff0c\u4f46\u5176\u8f93\u51fa\u7684\u6982\u7387\u5206\u5e03\u4e0e\u7406\u8bba\u6982\u7387\u5b58\u5728\u504f\u5dee\u3002", "motivation": "\u786e\u4fdd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u652f\u6301\u7b49\u5173\u952e\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u63d0\u5347\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u3002", "method": "\u4f7f\u7528GPT-4.1\u548cDeepSeek-Chat\u5bf910\u4e2a\u6d89\u53ca\u6982\u7387\u7684\u63d0\u793a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6d4b\u91cf\u6a21\u578b\u54cd\u5e94\u7684\u6709\u6548\u6027\u53ca\u5176\u751f\u6210\u6982\u7387\u4e0e\u7406\u8bba\u6982\u7387\u5206\u5e03\u7684\u5bf9\u9f50\u5ea6\u3002", "result": "\u4e24\u4e2a\u6a21\u578b\u5728\u6240\u6709\u63d0\u793a\u573a\u666f\u4e0b\u90fd\u80fd\u8fbe\u5230\u5b8c\u7f8e\u7684\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u4f46\u8f93\u51fa\u7684token\u7ea7\u6982\u7387\u548c\u71b5\u503c\u4e0e\u7406\u8bba\u6982\u7387\u5206\u5e03\u6301\u7eed\u5b58\u5728\u504f\u5dee\u3002", "conclusion": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u6b63\u786e\u56de\u5e94\u6982\u7387\u9898\uff0c\u5176\u5185\u90e8\u6982\u7387\u4f30\u8ba1\u4e0d\u5b8c\u5168\u7b26\u5408\u7406\u8bba\u6982\u7387\uff0c\u8bf4\u660e\u5f53\u524d\u7684\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u65b9\u6cd5\u8fd8\u9700\u6539\u8fdb\u4ee5\u786e\u4fdd\u51b3\u7b56\u652f\u6301\u5e94\u7528\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2511.01324", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.01324", "abs": "https://arxiv.org/abs/2511.01324", "authors": ["Lekshmi Murali Rani", "Richard Berntsson Svensson", "Robert Feldt"], "title": "AI for Requirements Engineering: Industry adoption and Practitioner perspectives", "comment": "Accepted at the Intelligent Software Engineering (ISE) 2025 Workshop\n  at the Automated Software Engineering (ASE) 2025 Conference", "summary": "The integration of AI for Requirements Engineering (RE) presents significant\nbenefits but also poses real challenges.Although RE is fundamental to software\nengineering, limited research has examined AI adoption in RE.We surveyed 55\nsoftware practitioners to map AI usage across four RE phases:Elicitation,\nAnalysis, Specification, and Validation, and four approaches for decision\nmaking: human only decisions, AI validation, Human AI Collaboration (HAIC), and\nfull AI automation.Participants also shared their perceptions, challenges, and\nopportunities when applying AI for RE tasks.Our data show that 58.2% of\nrespondents already use AI in RE, and 69.1% view its impact as positive or very\npositive.HAIC dominates practice, accounting for 54.4% of all RE techniques,\nwhile full AI automation remains minimal at 5.4%.Passive AI validation (4.4 to\n6.2%) lags even further behind, indicating that practitioners value AI's active\nsupport over passive oversight.These findings suggest that AI is most effective\nwhen positioned as a collaborative partner rather than a replacement for human\nexpertise.It also highlights the need for RE specific HAIC frameworks along\nwith robust and responsible AI governance as AI adoption in RE grows.", "AI": {"tldr": "\u672c\u6587\u8c03\u67e5\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u5e94\u7528\u7684\u73b0\u72b6\uff0c\u53d1\u73b0\u5927\u591a\u6570\u4ece\u4e1a\u8005\u79ef\u6781\u91c7\u7528AI\uff0c\u4e14\u66f4\u503e\u5411\u4e8e\u5c06\u5176\u4f5c\u4e3a\u4eba\u673a\u534f\u4f5c\u4f19\u4f34\u800c\u975e\u5b8c\u5168\u81ea\u52a8\u5316\u5de5\u5177\u3002", "motivation": "\u9700\u6c42\u5de5\u7a0b\u4f5c\u4e3a\u8f6f\u4ef6\u5de5\u7a0b\u7684\u57fa\u7840\uff0c\u5176\u4eba\u5de5\u667a\u80fd\u7684\u5e94\u7528\u7814\u7a76\u8f83\u5c11\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7406\u89e3AI\u5728\u9700\u6c42\u5de5\u7a0b\u4e0d\u540c\u9636\u6bb5\u7684\u5e94\u7528\u53ca\u5176\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u5bf955\u4f4d\u8f6f\u4ef6\u4ece\u4e1a\u8005\u8fdb\u884c\u8c03\u67e5\uff0c\u5206\u6790AI\u5728\u9700\u6c42\u5de5\u7a0b\u56db\u4e2a\u9636\u6bb5\uff08\u5f15\u5bfc\u3001\u5206\u6790\u3001\u89c4\u683c\u8bf4\u660e\u3001\u9a8c\u8bc1\uff09\u4ee5\u53ca\u56db\u79cd\u51b3\u7b56\u65b9\u5f0f\uff08\u5168\u4eba\u7c7b\u51b3\u7b56\u3001AI\u9a8c\u8bc1\u3001\u4eba\u673a\u534f\u4f5c\u3001\u5168AI\u81ea\u52a8\u5316\uff09\u4e2d\u7684\u4f7f\u7528\u60c5\u51b5\u548c\u7528\u6237\u611f\u77e5\u3002", "result": "58.2%\u7684\u53d7\u8bbf\u8005\u5df2\u7ecf\u5728\u4f7f\u7528AI\uff0c69.1%\u8ba4\u4e3aAI\u5f71\u54cd\u79ef\u6781\u3002\u4eba\u673a\u534f\u4f5c\u5360\u6bd454.4%\uff0c\u5168\u81ea\u52a8\u5316\u4ec55.4%\uff0c\u88ab\u52a8AI\u9a8c\u8bc1\u66f4\u5c11\uff0c\u8868\u660e\u4ece\u4e1a\u8005\u66f4\u91cd\u89c6AI\u7684\u4e3b\u52a8\u652f\u6301\u4f5c\u7528\u3002", "conclusion": "AI\u5728\u9700\u6c42\u5de5\u7a0b\u4e2d\u6700\u6709\u6548\u7684\u89d2\u8272\u662f\u534f\u4f5c\u4f19\u4f34\u800c\u975e\u66ff\u4ee3\u8005\uff0c\u672a\u6765\u9700\u8981\u6784\u5efa\u4e13\u95e8\u7684\u4eba\u673a\u534f\u4f5c\u6846\u67b6\u548c\u5065\u5168\u7684AI\u6cbb\u7406\u673a\u5236\u4ee5\u4fc3\u8fdbAI\u7684\u5065\u5eb7\u5e94\u7528\u3002"}}
{"id": "2511.00627", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00627", "abs": "https://arxiv.org/abs/2511.00627", "authors": ["Jean Barr\u00e9", "Olga Seminck", "Antoine Bourgois", "Thierry Poibeau"], "title": "Modeling the Construction of a Literary Archetype: The Case of the Detective Figure in French Literature", "comment": "19 pages, 2 tables, 5 figures Conference Computational Humanities\n  Research 2025", "summary": "This research explores the evolution of the detective archetype in French\ndetective fiction through computational analysis. Using quantitative methods\nand character-level embeddings, we show that a supervised model is able to\ncapture the unity of the detective archetype across 150 years of literature,\nfrom M. Lecoq (1866) to Commissaire Adamsberg (2017). Building on this finding,\nthe study demonstrates how the detective figure evolves from a secondary\nnarrative role to become the central character and the \"reasoning machine\" of\nthe classical detective story. In the aftermath of the Second World War, with\nthe importation of the hardboiled tradition into France, the archetype becomes\nmore complex, navigating the genre's turn toward social violence and moral\nambiguity.", "AI": {"tldr": "\u901a\u8fc7\u8ba1\u7b97\u5206\u6790\uff0c\u672c\u6587\u7814\u7a76\u4e86\u6cd5\u56fd\u4fa6\u63a2\u5c0f\u8bf4\u4e2d\u4fa6\u63a2\u539f\u578b\u5728150\u5e74\u95f4\u7684\u6f14\u53d8\uff0c\u63ed\u793a\u5176\u4ece\u6b21\u8981\u89d2\u8272\u6210\u4e3a\u6545\u4e8b\u6838\u5fc3\uff0c\u5e76\u5728\u4e8c\u6218\u540e\u53d8\u5f97\u590d\u6742\u3002", "motivation": "\u63a2\u8ba8\u6cd5\u56fd\u4fa6\u63a2\u5c0f\u8bf4\u4e2d\u4fa6\u63a2\u5f62\u8c61\u5982\u4f55\u968f\u7740\u65f6\u95f4\u6f14\u53d8\u53ca\u5176\u6587\u5b66\u610f\u4e49\u3002", "method": "\u91c7\u7528\u5b9a\u91cf\u65b9\u6cd5\u548c\u89d2\u8272\u7ea7\u5d4c\u5165\uff0c\u901a\u8fc7\u76d1\u7763\u6a21\u578b\u5206\u6790150\u5e74\u7684\u4fa6\u63a2\u5f62\u8c61\u53d8\u5316\u3002", "result": "\u6a21\u578b\u6210\u529f\u6355\u6349\u4e86\u4fa6\u63a2\u539f\u578b\u7684\u7edf\u4e00\u6027\u548c\u6f14\u53d8\u8fc7\u7a0b\uff1b\u4fa6\u63a2\u7531\u6b21\u8981\u89d2\u8272\u8f6c\u53d8\u4e3a\u6838\u5fc3\u63a8\u7406\u8005\uff0c\u4e8c\u6218\u540e\u5f62\u8c61\u66f4\u52a0\u590d\u6742\u3002", "conclusion": "\u4fa6\u63a2\u539f\u578b\u968f\u7740\u5386\u53f2\u548c\u793e\u4f1a\u80cc\u666f\u53d8\u5316\u800c\u6f14\u8fdb\uff0c\u53cd\u6620\u51fa\u4fa6\u63a2\u5c0f\u8bf4\u5bf9\u793e\u4f1a\u66b4\u529b\u548c\u9053\u5fb7\u6a21\u7cca\u6027\u7684\u56de\u5e94\u3002"}}
{"id": "2511.01348", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01348", "abs": "https://arxiv.org/abs/2511.01348", "authors": ["Robin Gr\u00f6pler", "Steffen Klepke", "Jack Johns", "Andreas Dreschinski", "Klaus Schmid", "Benedikt Dornauer", "Eray T\u00fcz\u00fcn", "Joost Noppen", "Mohammad Reza Mousavi", "Yongjian Tang", "Johannes Viehmann", "Selin \u015eirin Aslang\u00fcl", "Beum Seuk Lee", "Adam Ziolkowski", "Eric Zie"], "title": "The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project", "comment": "Submitted to 2nd IEEE/ACM International Conference on AI-powered\n  Software (AIware 2025)", "summary": "Generative AI (GenAI) has recently emerged as a groundbreaking force in\nSoftware Engineering, capable of generating code, suggesting fixes, and\nsupporting quality assurance. While its use in coding tasks shows considerable\npromise, applying GenAI across the entire Software Development Life Cycle\n(SDLC) has not yet been fully explored. Critical uncertainties in areas such as\nreliability, accountability, security, and data privacy demand deeper\ninvestigation and coordinated action. The GENIUS project, comprising over 30\nEuropean industrial and academic partners, aims to address these challenges by\nadvancing AI integration across all SDLC phases. It focuses on GenAI's\npotential, the development of innovative tools, and emerging research\nchallenges, actively shaping the future of software engineering. This vision\npaper presents a shared perspective on the future of GenAI-based software\nengineering, grounded in cross-sector dialogue and experience within the GENIUS\nconsortium, supported by an exploratory literature review. The paper explores\nfour central elements: (1) a structured overview of current challenges in GenAI\nadoption across the SDLC; (2) a forward-looking vision outlining key\ntechnological and methodological advances expected over the next five years;\n(3) anticipated shifts in the roles and required skill sets of software\nprofessionals; and (4) the contribution of GENIUS in realizing this\ntransformation through practical tools and industrial validation. By aligning\ntechnical innovation with business relevance, this paper aims to inform both\nresearch agendas and industrial strategies, providing a foundation for\nreliable, scalable, and industry-ready GenAI solutions for software engineering\nteams.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\uff08GenAI\uff09\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5168\u751f\u547d\u5468\u671f\u4e2d\u7684\u5e94\u7528\u73b0\u72b6\u3001\u6311\u6218\u4e0e\u672a\u6765\u53d1\u5c55\uff0c\u57fa\u4e8eGENIUS\u9879\u76ee\u7684\u89c6\u89d2\uff0c\u63d0\u51fa\u4e86\u9762\u5411\u672a\u6765\u4e94\u5e74\u7684\u6280\u672f\u548c\u65b9\u6cd5\u613f\u666f\u3002", "motivation": "\u867d\u7136GenAI\u5728\u7f16\u7801\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u5176\u5728\u8f6f\u4ef6\u5f00\u53d1\u5168\u751f\u547d\u5468\u671f\u7684\u5e7f\u6cdb\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u4e14\u5b58\u5728\u53ef\u9760\u6027\u3001\u8d23\u4efb\u3001\u5b89\u5168\u548c\u6570\u636e\u9690\u79c1\u7b49\u5173\u952e\u95ee\u9898\uff0c\u4e9f\u9700\u6df1\u5165\u7814\u7a76\u4e0e\u534f\u8c03\u5e94\u5bf9\u3002", "method": "\u901a\u8fc7GENIUS\u9879\u76ee\u6c47\u805a\u6b27\u6d32\u591a\u65b9\u4ea7\u4e1a\u4e0e\u5b66\u672f\u4f19\u4f34\uff0c\u7ed3\u5408\u8de8\u9886\u57df\u5bf9\u8bdd\u548c\u6587\u732e\u7efc\u8ff0\uff0c\u7cfb\u7edf\u5206\u6790GenAI\u5728SDLC\u4e2d\u7684\u6311\u6218\uff0c\u6784\u5efa\u672a\u6765\u6280\u672f\u53d1\u5c55\u4e0e\u4eba\u624d\u9700\u6c42\u7684\u613f\u666f\uff0c\u5e76\u63a8\u52a8\u521b\u65b0\u5de5\u5177\u7814\u53d1\u548c\u5de5\u4e1a\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e86\u56db\u4e2a\u6838\u5fc3\u5185\u5bb9\uff1a\u5f53\u524dGenAI\u91c7\u7eb3\u7684\u6311\u6218\u7efc\u8ff0\u3001\u672a\u6765\u4e94\u5e74\u6280\u672f\u4e0e\u65b9\u6cd5\u8fdb\u5c55\u5c55\u671b\u3001\u8f6f\u4ef6\u4e13\u4e1a\u4eba\u5458\u7684\u89d2\u8272\u4e0e\u6280\u80fd\u8f6c\u53d8\u9884\u6d4b\uff0c\u4ee5\u53caGENIUS\u9879\u76ee\u901a\u8fc7\u5b9e\u9645\u5de5\u5177\u548c\u5de5\u4e1a\u9a8c\u8bc1\u4fc3\u8fdb\u8f6c\u578b\u7684\u8d21\u732e\u3002", "conclusion": "\u8be5\u8bba\u6587\u4e3aGenAI\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u53ef\u9760\u3001\u53ef\u6269\u5c55\u548c\u4ea7\u4e1a\u5316\u5e94\u7528\u5960\u5b9a\u57fa\u7840\uff0c\u534f\u8c03\u6280\u672f\u521b\u65b0\u4e0e\u4e1a\u52a1\u9700\u6c42\uff0c\u6307\u5bfc\u540e\u7eed\u7814\u7a76\u548c\u5de5\u4e1a\u7b56\u7565\uff0c\u52a9\u529b\u8f6f\u4ef6\u56e2\u961f\u5b9e\u73b0GenAI\u8f6c\u578b\u3002"}}
{"id": "2511.00657", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00657", "abs": "https://arxiv.org/abs/2511.00657", "authors": ["Eshaan Tanwar", "Anwoy Chatterjee", "Michael Saxon", "Alon Albalak", "William Yang Wang", "Tanmoy Chakraborty"], "title": "Do You Know About My Nation? Investigating Multilingual Language Models' Cultural Literacy Through Factual Knowledge", "comment": "Accepted in EMNLP 2025. Code at: https://github.com/EshaanT/XNationQA", "summary": "Most multilingual question-answering benchmarks, while covering a diverse\npool of languages, do not factor in regional diversity in the information they\ncapture and tend to be Western-centric. This introduces a significant gap in\nfairly evaluating multilingual models' comprehension of factual information\nfrom diverse geographical locations. To address this, we introduce XNationQA\nfor investigating the cultural literacy of multilingual LLMs. XNationQA\nencompasses a total of 49,280 questions on the geography, culture, and history\nof nine countries, presented in seven languages. We benchmark eight standard\nmultilingual LLMs on XNationQA and evaluate them using two novel transference\nmetrics. Our analyses uncover a considerable discrepancy in the models'\naccessibility to culturally specific facts across languages. Notably, we often\nfind that a model demonstrates greater knowledge of cultural information in\nEnglish than in the dominant language of the respective culture. The models\nexhibit better performance in Western languages, although this does not\nnecessarily translate to being more literate for Western countries, which is\ncounterintuitive. Furthermore, we observe that models have a very limited\nability to transfer knowledge across languages, particularly evident in\nopen-source models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u591a\u8bed\u8a00\u95ee\u7b54\u57fa\u51c6XNationQA\uff0c\u6db5\u76d69\u4e2a\u56fd\u5bb6\u7684\u5730\u7406\u3001\u6587\u5316\u548c\u5386\u53f2\u95ee\u9898\uff0c\u8bc4\u4f30\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u533a\u57df\u6587\u5316\u4fe1\u606f\u7684\u7406\u89e3\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u591a\u8bed\u8a00\u95ee\u7b54\u57fa\u51c6\u504f\u897f\u65b9\u4e2d\u5fc3\uff0c\u7f3a\u4e4f\u533a\u57df\u6587\u5316\u591a\u6837\u6027\u7684\u516c\u5e73\u8bc4\u4f30\uff0c\u5bfc\u81f4\u4e0d\u80fd\u5168\u9762\u53cd\u6620\u6a21\u578b\u5bf9\u5168\u7403\u6587\u5316\u4e8b\u5b9e\u7684\u7406\u89e3\u3002", "method": "\u6784\u5efa\u5305\u542b49280\u4e2a\u95ee\u9898\u3001\u6d89\u53ca9\u4e2a\u56fd\u5bb67\u79cd\u8bed\u8a00\u7684XNationQA\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u4e24\u4e2a\u65b0\u7684\u8de8\u8bed\u8a00\u8fc1\u79fb\u8bc4\u4f30\u6307\u6807\uff0c\u5bf98\u4e2a\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5bf9\u6587\u5316\u7279\u5b9a\u4fe1\u606f\u7684\u8bbf\u95ee\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u901a\u5e38\u5728\u82f1\u8bed\u8868\u73b0\u66f4\u597d\uff0c\u800c\u975e\u8be5\u6587\u5316\u7684\u4e3b\u5bfc\u8bed\u8a00\uff1b\u6a21\u578b\u5728\u897f\u65b9\u8bed\u8a00\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5e76\u4e0d\u4ee3\u8868\u5bf9\u897f\u65b9\u56fd\u5bb6\u6587\u5316\u4e86\u89e3\u66f4\u6df1\u5165\uff1b\u6a21\u578b\u77e5\u8bc6\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\u8f83\u5f31\uff0c\u5f00\u6e90\u6a21\u578b\u8868\u73b0\u5c24\u4e3a\u660e\u663e\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6587\u5316\u4fe1\u606f\u7406\u89e3\u548c\u8de8\u8bed\u8a00\u77e5\u8bc6\u8fc1\u79fb\u7684\u663e\u8457\u77ed\u677f\uff0c\u5c24\u5176\u5728\u975e\u897f\u65b9\u8bed\u8a00\u548c\u6587\u5316\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u63d0\u793a\u672a\u6765\u7814\u7a76\u9700\u66f4\u591a\u5173\u6ce8\u5168\u7403\u6587\u5316\u591a\u6837\u6027\u548c\u8de8\u8bed\u8a00\u80fd\u529b\u63d0\u5347\u3002"}}
{"id": "2511.01395", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01395", "abs": "https://arxiv.org/abs/2511.01395", "authors": ["Maimouna Tamah Diao", "Moustapha Awwalou Diouf", "Iyiola Emmanuel Olatunji", "Abdoul Kader Kabor\u00e9", "Gervais Mendy", "Jacques Klein", "Tegawend\u00e9 F. Bissyand\u00e9"], "title": "Characterizing Build Compromises Through Vulnerability Disclosure Analysis", "comment": null, "summary": "The software build process transforms source code into deployable artifacts,\nrepresenting a critical yet vulnerable stage in software development. Build\ninfrastructure security poses unique challenges: the complexity of\nmulti-component systems (source code, dependencies, build tools), the\ndifficulty of detecting intrusions during compilation, and prevalent build\nnon-determinism that masks malicious modifications. Despite these risks, the\nsecurity community lacks a systematic understanding of build-specific attack\nvectors, hindering effective defense design.\n  This paper presents an empirically-derived taxonomy of attack vectors\ntargeting the build process, constructed through a large-scale CVE mining (of\n621 vulnerability disclosures from the NVD database). We categorize attack\nvectors by their injection points across the build pipeline, from source code\nmanipulation to compiler compromise. To validate our taxonomy, we analyzed 168\ndocumented software supply chain attacks, identifying 40 incidents specifically\ntargeting build phases. Our analysis reveals that 23.8\\% of supply chain\nattacks exploit build vulnerabilities, with dependency confusion and build\nscript injection representing the most prevalent vectors.\n  Dataset available at:\nhttps://anonymous.4open.science/r/Taxonomizing-Build-Attacks-8BB0.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21CVE\u6316\u6398\u548c\u4f9b\u5e94\u94fe\u653b\u51fb\u6848\u4f8b\u5206\u6790\uff0c\u7cfb\u7edf\u5206\u7c7b\u4e86\u9488\u5bf9\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u7684\u653b\u51fb\u5411\u91cf\uff0c\u63ed\u793a\u4e86\u6784\u5efa\u9636\u6bb5\u7684\u5b89\u5168\u5a01\u80c1\u53ca\u5176\u4e3b\u8981\u8868\u73b0\u5f62\u5f0f\u3002", "motivation": "\u8f6f\u4ef6\u6784\u5efa\u8fc7\u7a0b\u662f\u5c06\u6e90\u4ee3\u7801\u8f6c\u5316\u4e3a\u90e8\u7f72\u4ea7\u7269\u7684\u5173\u952e\u9636\u6bb5\uff0c\u5b89\u5168\u6027\u590d\u6742\u4e14\u6613\u53d7\u653b\u51fb\uff0c\u5c24\u5176\u662f\u591a\u7ec4\u4ef6\u7cfb\u7edf\u590d\u6742\u6027\u3001\u7f16\u8bd1\u671f\u95f4\u7684\u5165\u4fb5\u96be\u4ee5\u68c0\u6d4b\u548c\u6784\u5efa\u8fc7\u7a0b\u4e2d\u7684\u968f\u673a\u6027\u63a9\u76d6\u6076\u610f\u4fee\u6539\uff0c\u7136\u800c\u5b89\u5168\u793e\u533a\u7f3a\u4e4f\u5bf9\u6784\u5efa\u653b\u51fb\u5411\u91cf\u7684\u7cfb\u7edf\u7406\u89e3\uff0c\u963b\u788d\u6709\u6548\u9632\u5fa1\u63aa\u65bd\u7684\u8bbe\u8ba1\u3002", "method": "\u901a\u8fc7\u5bf9621\u4e2aCVE\u6f0f\u6d1e\u62ab\u9732\u7684\u6316\u6398\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u6ce8\u5165\u70b9\u7684\u6784\u5efa\u653b\u51fb\u5411\u91cf\u5206\u7c7b\u6cd5\uff0c\u6db5\u76d6\u4ece\u6e90\u4ee3\u7801\u64cd\u4f5c\u5230\u7f16\u8bd1\u5668\u88ab\u653b\u51fb\u7684\u5404\u4e2a\u73af\u8282\u3002\u5e76\u901a\u8fc7\u5206\u6790168\u8d77\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u653b\u51fb\u6848\u4f8b\u9a8c\u8bc1\u8be5\u5206\u7c7b\u6cd5\uff0c\u5176\u4e2d\u8bc6\u522b\u51fa40\u8d77\u660e\u786e\u9488\u5bf9\u6784\u5efa\u9636\u6bb5\u7684\u653b\u51fb\u4e8b\u4ef6\u3002", "result": "\u5206\u6790\u53d1\u73b023.8%\u7684\u4f9b\u5e94\u94fe\u653b\u51fb\u5229\u7528\u4e86\u6784\u5efa\u6f0f\u6d1e\uff0c\u4f9d\u8d56\u6df7\u6dc6\u548c\u6784\u5efa\u811a\u672c\u6ce8\u5165\u662f\u6700\u5e38\u89c1\u7684\u653b\u51fb\u65b9\u5f0f\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u6784\u5efa\u653b\u51fb\u5411\u91cf\u7684\u8be6\u7ec6\u5206\u7c7b\u548c\u5bf9\u5e94\u7684\u653b\u51fb\u6848\u4f8b\u652f\u6301\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u8f6f\u4ef6\u6784\u5efa\u5b89\u5168\u9886\u57df\u7684\u77e5\u8bc6\u7a7a\u767d\uff0c\u7cfb\u7edf\u5206\u7c7b\u4e86\u6784\u5efa\u653b\u51fb\u5411\u91cf\uff0c\u5f3a\u8c03\u6784\u5efa\u9636\u6bb5\u5b89\u5168\u9632\u62a4\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u9632\u5fa1\u673a\u5236\u63d0\u4f9b\u4e86\u6570\u636e\u652f\u6301\u548c\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2511.00689", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00689", "abs": "https://arxiv.org/abs/2511.00689", "authors": ["Berk Atil", "Rebecca J. Passonneau", "Fred Morstatter"], "title": "Do Methods to Jailbreak and Defend LLMs Generalize Across Languages?", "comment": null, "summary": "Large language models (LLMs) undergo safety alignment after training and\ntuning, yet recent work shows that safety can be bypassed through jailbreak\nattacks. While many jailbreaks and defenses exist, their cross-lingual\ngeneralization remains underexplored. This paper presents the first systematic\nmultilingual evaluation of jailbreaks and defenses across ten\nlanguages--spanning high-, medium-, and low-resource languages--using six LLMs\non HarmBench and AdvBench. We assess two jailbreak types:\nlogical-expression-based and adversarial-prompt-based. For both types, attack\nsuccess and defense robustness vary across languages: high-resource languages\nare safer under standard queries but more vulnerable to adversarial ones.\nSimple defenses can be effective, but are language- and model-dependent. These\nfindings call for language-aware and cross-lingual safety benchmarks for LLMs.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7ed5\u8fc7\u5b89\u5168\u673a\u5236\u7684\u591a\u8bed\u8a00\u8d8a\u72f1\u653b\u51fb\u53ca\u9632\u5fa1\u6548\u679c\uff0c\u53d1\u73b0\u653b\u51fb\u6210\u529f\u7387\u548c\u9632\u5fa1\u6548\u679c\u5728\u4e0d\u540c\u8bed\u8a00\u95f4\u5dee\u5f02\u663e\u8457\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u663e\u793aLLMs\u7684\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u53ef\u4ee5\u88ab\u7ed5\u8fc7\uff0c\u4f46\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7ed5\u8fc7\u653b\u51fb\u7684\u8de8\u8bed\u8a00\u9002\u7528\u6027\u4e0e\u9632\u5fa1\u6548\u679c\u5c1a\u672a\u5145\u5206\u7814\u7a76\u3002", "method": "\u5728\u5341\u79cd\u8bed\u8a00\uff08\u6db5\u76d6\u9ad8\u3001\u4e2d\u3001\u4f4e\u8d44\u6e90\u8bed\u8a00\uff09\u548c\u516d\u4e2aLLM\u6a21\u578b\u4e0a\uff0c\u4f7f\u7528HarmBench\u548cAdvBench\u6d4b\u8bd5\u5e73\u53f0\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e24\u7c7b\u8d8a\u72f1\u653b\u51fb\uff08\u57fa\u4e8e\u903b\u8f91\u8868\u8fbe\u5f0f\u548c\u5bf9\u6297\u6027\u63d0\u793a\uff09\u53ca\u76f8\u5e94\u7684\u9632\u5fa1\u65b9\u6cd5\u3002", "result": "\u7ed3\u679c\u663e\u793a\u9ad8\u8d44\u6e90\u8bed\u8a00\u5728\u6807\u51c6\u67e5\u8be2\u4e0b\u66f4\u5b89\u5168\uff0c\u4f46\u66f4\u6613\u53d7\u5bf9\u6297\u6027\u653b\u51fb\uff0c\u9632\u5fa1\u6548\u679c\u53d7\u8bed\u8a00\u548c\u6a21\u578b\u5f71\u54cd\u663e\u8457\u3002\u7b80\u5355\u9632\u5fa1\u63aa\u65bd\u5728\u67d0\u4e9b\u8bed\u8a00\u548c\u6a21\u578b\u4e2d\u6709\u6548\u3002", "conclusion": "LLMs\u7684\u5b89\u5168\u8bc4\u4f30\u9700\u8981\u8003\u8651\u8bed\u8a00\u7279\u6027\uff0c\u547c\u5401\u5efa\u7acb\u591a\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\u4ee5\u63d0\u5347\u8de8\u8bed\u8a00\u9632\u62a4\u80fd\u529b\u3002"}}
{"id": "2511.01417", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01417", "abs": "https://arxiv.org/abs/2511.01417", "authors": ["Bassel Rafie", "Christian Schindler", "Andreas Rausch"], "title": "VeriODD: From YAML to SMT-LIB - Automating Verification of Operational Design Domains", "comment": null, "summary": "Operational Design Domains (ODDs) define the conditions under which an\nAutomated Driving System (ADS) is allowed to operate, while Current Operational\nDomains (CODs) capture the actual runtime situation. Ensuring that a COD\ninstance lies within the ODD is a crucial step in safety assurance. Today, ODD\nand COD specifications are frequently expressed in YAML to remain accessible\nfor stakeholders, but such descriptions are not directly suitable for\nsolver-based verification. Manual translation into formal languages such as\nSMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this\ntranslation. VeriODD uses ANTLR-based compiler technology to transform\nYAML-based ODD/COD specifications into both human-readable propositional logic,\nfor lightweight review on a simple basis, and solver-ready SMT-LIB. The tool\nintegrates with SMT solvers such as Z3 to provide automated consistency checks\nof ODD specifications and verification of COD conformance. A graphical user\ninterface supports editing specifications, inspecting generated formulas, and\nperforming verification with a single click. VeriODD thereby closes the gap\nbetween stakeholder-friendly ODD/COD notations and formal verification,\nenabling scalable and automated assurance of operational boundaries in\nautonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool\navailable at: https://github.com/BasselRafie/VeriODD", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86VeriODD\u5de5\u5177\uff0c\u5b9e\u73b0\u4e86\u4eceYAML\u683c\u5f0f\u7684\u64cd\u4f5c\u8bbe\u8ba1\u57df\uff08ODD\uff09\u548c\u5f53\u524d\u64cd\u4f5c\u57df\uff08COD\uff09\u89c4\u8303\u81ea\u52a8\u7ffb\u8bd1\u4e3a\u5f62\u5f0f\u903b\u8f91\u8868\u8fbe\u548cSMT-LIB\u683c\u5f0f\uff0c\u652f\u6301\u81ea\u52a8\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u7b26\u5408\u6027\u9a8c\u8bc1\u3002", "motivation": "\u5f53\u524dODD\u548cCOD\u7684\u89c4\u8303\u867d\u7136\u7528YAML\u8868\u8fbe\u65b9\u4fbf\uff0c\u4f46\u4e0d\u9002\u5408\u5f62\u5f0f\u9a8c\u8bc1\uff0c\u4e14\u624b\u52a8\u8f6c\u8bd1\u4e3aSMT-LIB\u7e41\u7410\u4e14\u6613\u9519\uff0c\u5f71\u54cd\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u5b89\u5168\u4fdd\u969c\u3002", "method": "\u57fa\u4e8eANTLR\u7684\u7f16\u8bd1\u5668\u6280\u672f\uff0cVeriODD\u5c06YAML\u7684ODD/COD\u89c4\u8303\u8f6c\u6362\u4e3a\u547d\u9898\u903b\u8f91\u548cSMT-LIB\u683c\u5f0f\uff0c\u7ed3\u5408Z3\u6c42\u89e3\u5668\u8fdb\u884c\u81ea\u52a8\u4e00\u81f4\u6027\u68c0\u67e5\u548c\u7b26\u5408\u9a8c\u8bc1\uff0c\u5e76\u63d0\u4f9b\u56fe\u5f62\u754c\u9762\u4fbf\u4e8e\u7f16\u8f91\u548c\u9a8c\u8bc1\u3002", "result": "VeriODD\u5b9e\u73b0\u4e86\u4ece\u4eba\u7c7b\u6613\u8bfb\u7684YAML\u5230\u9002\u5408\u81ea\u52a8\u5316\u9a8c\u8bc1\u7684SMT-LIB\u7684\u65e0\u7f1d\u8f6c\u6362\uff0c\u652f\u6301\u5feb\u901f\u4e14\u81ea\u52a8\u5316\u7684ODD\u89c4\u8303\u4e00\u81f4\u6027\u68c0\u9a8c\u548cCOD\u5408\u89c4\u6027\u9a8c\u8bc1\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u5b89\u5168\u4fdd\u969c\u6548\u7387\u3002", "conclusion": "VeriODD\u5f25\u5408\u4e86\u9762\u5411\u5229\u76ca\u76f8\u5173\u8005\u7684\u89c4\u8303\u8868\u8fbe\u4e0e\u5f62\u5f0f\u9a8c\u8bc1\u95f4\u7684\u9e3f\u6c9f\uff0c\u4f7f\u5f97\u81ea\u52a8\u9a7e\u9a76\u64cd\u4f5c\u8fb9\u754c\u7684\u5b89\u5168\u4fdd\u969c\u66f4\u52a0\u81ea\u52a8\u5316\u3001\u89c4\u6a21\u5316\u548c\u9ad8\u6548\u3002"}}
{"id": "2511.00819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00819", "abs": "https://arxiv.org/abs/2511.00819", "authors": ["Yuxuan Hu", "Jianchao Tan", "Jiaqi Zhang", "Wen Zan", "Pingwei Sun", "Yifan Lu", "Yerui Sun", "Yuchen Xie", "Xunliang Cai", "Jing Zhang"], "title": "Optimizing Native Sparse Attention with Latent Attention and Local Global Alternating Strategies", "comment": null, "summary": "In this work, we conduct a systematic analysis of Native Sparse Attention\n(NSA) and propose targeted improvements that enhance long-context modeling. A\nkey insight is that alternating between local (sliding-window) and global\n(compression, selective) attention across layers, rather than using fixed\npatterns, enables more effective propagation of long-range dependencies and\nsubstantially boosts performance on long-sequence tasks. Meanwhile, we further\nrefine NSA's branches with Latent Attention that the sliding-window branch is\nenhanced with Multi-head Latent Attention (MLA) while compression and selective\nbranches adopt Group-head Latent Attention (GLA). These changes reduce KV-cache\nmemory by 50\\% versus NSA while improving the model's common-sense reasoning\nand long-text understanding capabilities. Experiments on models from 340M to\n1.3B parameters (trained on 15B and 100B tokens) show our method matches or\nexceeds full attention and native sparse attention in both common-sense\nreasoning and long-context understanding tasks.", "AI": {"tldr": "\u672c\u6587\u5bf9Native Sparse Attention (NSA)\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6848\u4ee5\u63d0\u5347\u957f\u6587\u672c\u5efa\u6a21\u6548\u679c\u3002", "motivation": "\u56fa\u5b9a\u7684\u5c40\u90e8\u548c\u5168\u5c40\u6ce8\u610f\u529b\u6a21\u5f0f\u9650\u5236\u4e86\u957f\u8ddd\u79bb\u4f9d\u8d56\u4fe1\u606f\u7684\u6709\u6548\u4f20\u64ad\uff0c\u5f71\u54cd\u957f\u5e8f\u5217\u4efb\u52a1\u8868\u73b0\u3002", "method": "\u901a\u8fc7\u5c42\u95f4\u4ea4\u66ff\u4f7f\u7528\u5c40\u90e8\u6ed1\u52a8\u7a97\u53e3\u6ce8\u610f\u529b\u548c\u5168\u5c40\u538b\u7f29\u9009\u62e9\u6027\u6ce8\u610f\u529b\uff0c\u540c\u65f6\u5f15\u5165\u591a\u5934\u6f5c\u5728\u6ce8\u610f\u529b(MLA)\u548c\u7ec4\u5934\u6f5c\u5728\u6ce8\u610f\u529b(GLA)\u4f18\u5316NSA\u5206\u652f\uff0c\u51cf\u5c11\u5185\u5b58\u5360\u7528\u3002", "result": "\u65b0\u65b9\u6cd5\u5728340M\u52301.3B\u53c2\u6570\u89c4\u6a21\u6a21\u578b\u4e0a\uff0c\u8bad\u7ec315B\u5230100B\u8bcd\u5143\uff0cKV\u7f13\u5b58\u5185\u5b58\u51cf\u5c1150%\uff0c\u5e38\u8bc6\u63a8\u7406\u548c\u957f\u6587\u672c\u7406\u89e3\u80fd\u529b\u663e\u8457\u63d0\u5347\uff0c\u6027\u80fd\u4f18\u4e8e\u5b8c\u5168\u6ce8\u610f\u529b\u548cNSA\u3002", "conclusion": "\u4ea4\u66ff\u5c40\u90e8\u4e0e\u5168\u5c40\u6ce8\u610f\u529b\u7ed3\u5408\u6f5c\u5728\u6ce8\u610f\u529b\u6280\u672f\uff0c\u6709\u6548\u589e\u5f3a\u4e86\u957f\u8ddd\u79bb\u4f9d\u8d56\u4f20\u64ad\u548c\u6a21\u578b\u6027\u80fd\uff0c\u63d0\u5347\u4e86\u957f\u5e8f\u5217\u4efb\u52a1\u8868\u73b0\u3002"}}
{"id": "2511.01423", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01423", "abs": "https://arxiv.org/abs/2511.01423", "authors": ["Ruidi He", "Yu Zhang", "Meng Zhang", "Andreas Rausch"], "title": "LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations", "comment": null, "summary": "High-definition map transformations are essential in autonomous driving\nsystems, enabling interoperability across tools. Ensuring their semantic\ncorrectness is challenging, since existing rule-based frameworks rely on\nmanually written formulas and domain-specific functions, limiting scalability.\n  In this paper, We present an LLM-assisted pipeline that jointly generates\nlogical formulas and corresponding executable predicates within a computational\nFOL framework, extending the map verifier in CommonRoad scenario designer with\nelevation support. The pipeline leverages prompt-based LLM generation to\nproduce grammar-compliant rules and predicates that integrate directly into the\nexisting system.\n  We implemented a prototype and evaluated it on synthetic bridge and slope\nscenarios. The results indicate reduced manual engineering effort while\npreserving correctness, demonstrating the feasibility of a scalable,\nsemi-automated human-in-the-loop approach to map-transformation verification.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u8f85\u52a9\u7684\u81ea\u52a8\u9a7e\u9a76\u9ad8\u7cbe\u5730\u56fe\u8f6c\u6362\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u6b63\u786e\u6027\u81ea\u52a8\u6821\u9a8c\uff0c\u51cf\u5c11\u4e86\u624b\u5de5\u7f16\u7801\u52b3\u52a8\u3002", "motivation": "\u73b0\u6709\u5730\u56fe\u8f6c\u6362\u9a8c\u8bc1\u89c4\u5219\u4f9d\u8d56\u4eba\u5de5\u7f16\u5199\u7684\u516c\u5f0f\u548c\u9886\u57df\u51fd\u6570\uff0c\u96be\u4ee5\u6269\u5c55\uff0c\u4e14\u4fdd\u8bc1\u8bed\u4e49\u6b63\u786e\u6027\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2aLLM\u8f85\u52a9\u7684\u7ba1\u7ebf\uff0c\u8054\u5408\u751f\u6210\u5f62\u5f0f\u903b\u8f91(FOL)\u4e2d\u7684\u903b\u8f91\u516c\u5f0f\u548c\u53ef\u6267\u884c\u8c13\u8bcd\uff0c\u6269\u5c55\u4e86CommonRoad\u573a\u666f\u8bbe\u8ba1\u5668\u4e2d\u7684\u5730\u56fe\u9a8c\u8bc1\u5668\uff0c\u5e76\u652f\u6301\u5730\u5f62\u9ad8\u7a0b\u3002", "result": "\u5728\u5408\u6210\u7684\u6865\u6881\u548c\u5761\u5ea6\u60c5\u666f\u4e2d\u8fdb\u884c\u4e86\u539f\u578b\u8bc4\u4f30\uff0c\u663e\u793a\u964d\u4f4e\u4e86\u624b\u5de5\u5de5\u7a0b\u91cf\u4e14\u4fdd\u6301\u4e86\u9a8c\u8bc1\u6b63\u786e\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u534a\u81ea\u52a8\u4eba\u673a\u534f\u540c\u5730\u56fe\u8f6c\u6362\u9a8c\u8bc1\u65b9\u6848\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528LLM\u8f85\u52a9\u751f\u6210\u903b\u8f91\u89c4\u5219\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2511.00854", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00854", "abs": "https://arxiv.org/abs/2511.00854", "authors": ["Chong Lyu", "Lin Li", "Shiqing Wu", "Jingling Yuan"], "title": "TriCon-Fair: Triplet Contrastive Learning for Mitigating Social Bias in Pre-trained Language Models", "comment": null, "summary": "The increasing utilization of large language models raises significant\nconcerns about the propagation of social biases, which may result in harmful\nand unfair outcomes. However, existing debiasing methods treat the biased and\nunbiased samples independently, thus ignoring their mutual relationship. This\noversight enables a hidden negative-positive coupling, where improvements for\none group inadvertently compromise the other, allowing residual social bias to\npersist. In this paper, we introduce TriCon-Fair, a contrastive learning\nframework that employs a decoupled loss that combines triplet and language\nmodeling terms to eliminate positive-negative coupling. Our TriCon-Fair assigns\neach anchor an explicitly biased negative and an unbiased positive, decoupling\nthe push-pull dynamics and avoiding positive-negative coupling, and jointly\noptimizes a language modeling (LM) objective to preserve general capability.\nExperimental results demonstrate that TriCon-Fair reduces discriminatory output\nbeyond existing debiasing baselines while maintaining strong downstream\nperformance. This suggests that our proposed TriCon-Fair offers a practical and\nethical solution for sensitive NLP applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6TriCon-Fair\u4ee5\u6d88\u9664\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u793e\u4f1a\u504f\u89c1\uff0c\u5b9e\u73b0\u51cf\u5c11\u6b67\u89c6\u6027\u8f93\u51fa\u5e76\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u53bb\u504f\u65b9\u6cd5\u5ffd\u89c6\u504f\u89c1\u548c\u65e0\u504f\u6837\u672c\u4e4b\u95f4\u7684\u76f8\u4e92\u5173\u7cfb\uff0c\u5bfc\u81f4\u53bb\u504f\u6548\u679c\u53d7\u9650\uff0c\u793e\u4f1a\u504f\u89c1\u4ecd\u7136\u5b58\u5728\u3002", "method": "\u5f15\u5165TriCon-Fair\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4e09\u5143\u7ec4\u548c\u8bed\u8a00\u5efa\u6a21\u635f\u5931\u7684\u89e3\u8026\u7ec4\u5408\uff0c\u5206\u914d\u6bcf\u4e2a\u951a\u70b9\u4e00\u4e2a\u660e\u786e\u7684\u6709\u504f\u8d1f\u6837\u672c\u548c\u65e0\u504f\u6b63\u6837\u672c\uff0c\u907f\u514d\u6b63\u8d1f\u6837\u672c\u8026\u5408\uff0c\u8054\u5408\u4f18\u5316\u8bed\u8a00\u6a21\u578b\u76ee\u6807\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTriCon-Fair\u5728\u51cf\u5c11\u6b67\u89c6\u8f93\u51fa\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u53bb\u504f\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u5f3a\u7684\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u3002", "conclusion": "TriCon-Fair\u4e3a\u654f\u611fNLP\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u4e14\u7b26\u5408\u4f26\u7406\u7684\u53bb\u504f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.01529", "categories": ["cs.SE", "cs.CL", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.01529", "abs": "https://arxiv.org/abs/2511.01529", "authors": ["Murali Sridharan", "Mikel Robredo", "Leevi Rantala", "Matteo Esposito", "Valentina Lenarduzzi", "Mika Mantyla"], "title": "Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt", "comment": null, "summary": "Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for\nproactive software maintenance. Previous research has primarily targeted\ndetecting and prioritizing SATD, with little focus on the source code afflicted\nwith SATD. Our goal in this work is to connect the SATD comments with source\ncode constructs that surround them.\n  Method. We leverage the extensive SATD dataset PENTACET, containing code\ncomments from over 9000 Java Open Source Software (OSS) repositories. We\nquantitatively infer where SATD most commonly occurs and which code\nconstructs/statements it most frequently affects.\n  Results and Conclusions. Our large-scale study links over 225,000 SATD\ncomments to their surrounding code, showing that SATD mainly arises in inline\ncode near definitions, conditionals, and exception handling, where developers\nface uncertainty and trade-offs, revealing it as an intentional signal of\nawareness during change rather than mere neglect.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u67909000\u591a\u4e2aJava\u5f00\u6e90\u4ed3\u5e93\u4e2d\u7684\u81ea\u627f\u6280\u672f\u503a\uff08SATD\uff09\u6ce8\u91ca\uff0c\u63ed\u793a\u4e86SATD\u4e3b\u8981\u51fa\u73b0\u5728\u5b9a\u4e49\u3001\u6761\u4ef6\u8bed\u53e5\u548c\u5f02\u5e38\u5904\u7406\u7684\u5d4c\u5165\u4ee3\u7801\u4e2d\u3002", "motivation": "\u524d\u4eba\u7814\u7a76\u867d\u5173\u6ce8SATD\u7684\u68c0\u6d4b\u4e0e\u4f18\u5148\u7ea7\u6392\u5e8f\uff0c\u4f46\u5bf9\u53d7SATD\u5f71\u54cd\u7684\u6e90\u4ee3\u7801\u90e8\u5206\u5173\u6ce8\u8f83\u5c11\u3002\u672c\u7814\u7a76\u65e8\u5728\u5c06SATD\u6ce8\u91ca\u4e0e\u5176\u5468\u56f4\u7684\u4ee3\u7801\u6784\u9020\u5173\u8054\u8d77\u6765\u3002", "method": "\u5229\u7528PENTACET\u5927\u89c4\u6a21SATD\u6570\u636e\u96c6\uff0c\u5b9a\u91cf\u63a8\u65adSATD\u7684\u5e38\u89c1\u4f4d\u7f6e\u53ca\u5f71\u54cd\u7684\u4ee3\u7801\u6784\u9020\u6216\u8bed\u53e5\u7c7b\u578b\u3002", "result": "\u901a\u8fc7\u94fe\u63a522.5\u4e07\u4e2aSATD\u6ce8\u91ca\u4e0e\u5468\u56f4\u4ee3\u7801\uff0c\u53d1\u73b0SATD\u4e3b\u8981\u51fa\u73b0\u5728\u5185\u8054\u4ee3\u7801\u4e2d\u9760\u8fd1\u5b9a\u4e49\u3001\u6761\u4ef6\u8bed\u53e5\u548c\u5f02\u5e38\u5904\u7406\u7684\u4f4d\u7f6e\u3002", "conclusion": "SATD\u53cd\u6620\u5f00\u53d1\u8005\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u548c\u6743\u8861\u65f6\u7684\u6709\u610f\u8bc6\u522b\uff0c\u662f\u53d8\u66f4\u8fc7\u7a0b\u4e2d\u7684\u4e00\u79cd\u4e3b\u52a8\u4fe1\u53f7\uff0c\u800c\u975e\u7b80\u5355\u7684\u758f\u5ffd\u3002"}}
{"id": "2511.00879", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.00879", "abs": "https://arxiv.org/abs/2511.00879", "authors": ["Hyeon Hwang", "Yewon Cho", "Chanwoong Yoon", "Yein Park", "Minju Song", "Kyungjae Lee", "Gangwoo Kim", "Jaewoo Kang"], "title": "Assessing LLM Reasoning Steps via Principal Knowledge Grounding", "comment": "Accepted to EMNLP 2025 Findings", "summary": "Step-by-step reasoning has become a standard approach for large language\nmodels (LLMs) to tackle complex tasks. While this paradigm has proven\neffective, it raises a fundamental question: How can we verify that an LLM's\nreasoning is accurately grounded in knowledge? To address this question, we\nintroduce a novel evaluation suite that systematically assesses the knowledge\ngrounding of intermediate reasoning. Our framework comprises three key\ncomponents. (1) Principal Knowledge Collection, a large-scale repository of\natomic knowledge essential for reasoning. Based on the collection, we propose\n(2) knowledge-grounded evaluation metrics designed to measure how well models\nrecall and apply prerequisite knowledge in reasoning. These metrics are\ncomputed by our (3) evaluator LLM, a lightweight model optimized for\ncost-effective and reliable metric computation. Our evaluation suite\ndemonstrates remarkable effectiveness in identifying missing or misapplied\nknowledge elements, providing crucial insights for uncovering fundamental\nreasoning deficiencies in LLMs. Beyond evaluation, we demonstrate how these\nmetrics can be integrated into preference optimization, showcasing further\napplications of knowledge-grounded evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u521b\u65b0\u7684\u8bc4\u4f30\u4f53\u7cfb\uff0c\u7528\u4e8e\u7cfb\u7edf\u6027\u5730\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e2d\u95f4\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u77e5\u8bc6\u57fa\u7840\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u9010\u6b65\u63a8\u7406\u89e3\u51b3\u590d\u6742\u4efb\u52a1\uff0c\u4f46\u7f3a\u4e4f\u6709\u6548\u65b9\u6cd5\u9a8c\u8bc1\u5176\u63a8\u7406\u662f\u5426\u51c6\u786e\u57fa\u4e8e\u77e5\u8bc6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u57fa\u7840\u77e5\u8bc6\u7684\u5927\u578b\u77e5\u8bc6\u5e93\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1\u77e5\u8bc6\u57fa\u7840\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u8bc4\u4f30\u6a21\u578b\u8ba1\u7b97\u6307\u6807\uff0c\u5b9e\u73b0\u5bf9\u6a21\u578b\u63a8\u7406\u77e5\u8bc6\u8c03\u7528\u7684\u6d4b\u91cf\u3002", "result": "\u8be5\u8bc4\u4f30\u4f53\u7cfb\u80fd\u591f\u6709\u6548\u8bc6\u522b\u6a21\u578b\u63a8\u7406\u4e2d\u7f3a\u5931\u6216\u9519\u8bef\u5e94\u7528\u7684\u77e5\u8bc6\u5143\u7d20\uff0c\u5e2e\u52a9\u53d1\u73b0\u6a21\u578b\u63a8\u7406\u7684\u6839\u672c\u7f3a\u9677\u3002", "conclusion": "\u77e5\u8bc6\u57fa\u7840\u7684\u8bc4\u4ef7\u4e0d\u4ec5\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u6027\u7684\u68c0\u6d4b\uff0c\u8fd8\u80fd\u88ab\u6574\u5408\u5165\u504f\u597d\u4f18\u5316\uff0c\u62d3\u5c55\u4e86\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e0e\u4f18\u5316\u7684\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2511.01545", "categories": ["cs.SE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.01545", "abs": "https://arxiv.org/abs/2511.01545", "authors": ["Ronivaldo Ferreira", "Guilherme da Silva", "Carla Rocha", "Gustavo Pinto"], "title": "From Pre-labeling to Production: Engineering Lessons from a Machine Learning Pipeline in the Public Sector", "comment": "11 pages, 2 figures, 4 tables", "summary": "Machine learning is increasingly being embedded into government digital\nplatforms, but public-sector constraints make it difficult to build ML systems\nthat are accurate, auditable, and operationally sustainable. In practice, teams\nface not only technical issues like extreme class imbalance and data drift, but\nalso organizational barriers such as bureaucratic data access, lack of\nversioned datasets, and incomplete governance over provenance and monitoring.\nOur study of the Brasil Participativo (BP) platform shows that common\nengineering choices -- like using LLMs for pre-labeling, splitting models into\nrouted classifiers, and generating synthetic data -- can speed development but\nalso introduce new traceability, reliability, and cost risks if not paired with\ndisciplined data governance and human validation. This means that, in the\npublic sector, responsible ML is not just a modeling problem but an\ninstitutional engineering problem, and ML pipelines must be treated as civic\ninfrastructure. Ultimately, this study shows that the success of machine\nlearning in the public sector will depend less on breakthroughs in model\naccuracy and more on the ability of institutions to engineer transparent,\nreproducible, and accountable data infrastructures that citizens can trust.", "AI": {"tldr": "\u516c\u5171\u90e8\u95e8\u5728\u8fd0\u7528\u673a\u5668\u5b66\u4e60\u65f6\u9762\u4e34\u6280\u672f\u548c\u7ec4\u7ec7\u53cc\u91cd\u6311\u6218\uff0c\u6210\u529f\u4f9d\u8d56\u4e8e\u900f\u660e\u53ef\u8ffd\u6eaf\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\uff0c\u800c\u975e\u5355\u7eaf\u6a21\u578b\u51c6\u786e\u7387\u7684\u7a81\u7834\u3002", "motivation": "\u516c\u5171\u90e8\u95e8\u5728\u90e8\u7f72\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u65f6\u9047\u5230\u6280\u672f\u96be\u9898\u548c\u7ec4\u7ec7\u969c\u788d\uff0c\u5f71\u54cd\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u3001\u53ef\u5ba1\u8ba1\u6027\u548c\u53ef\u6301\u7eed\u8fd0\u884c\u3002", "method": "\u7814\u7a76\u4e86\u5df4\u897f\u53c2\u4e0e\u5e73\u53f0\uff0c\u5206\u6790\u4e86\u5e38\u7528\u5de5\u7a0b\u624b\u6bb5\uff08\u5982LLM\u9884\u6807\u7b7e\u3001\u6a21\u578b\u5206\u8def\u5206\u7c7b\u5668\u3001\u5408\u6210\u6570\u636e\u751f\u6210\uff09\u5728\u52a0\u5feb\u5f00\u53d1\u7684\u540c\u65f6\u5e26\u6765\u7684\u98ce\u9669\u3002", "result": "\u53d1\u73b0\u82e5\u7f3a\u4e4f\u4e25\u683c\u7684\u6570\u636e\u6cbb\u7406\u548c\u4eba\u5de5\u6821\u9a8c\uff0c\u8fd9\u4e9b\u5de5\u7a0b\u624b\u6bb5\u4f1a\u5f15\u5165\u53ef\u8ffd\u6eaf\u6027\u3001\u53ef\u9760\u6027\u548c\u6210\u672c\u98ce\u9669\u3002", "conclusion": "\u516c\u5171\u90e8\u95e8\u7684\u673a\u5668\u5b66\u4e60\u662f\u5236\u5ea6\u5de5\u7a0b\u95ee\u9898\uff0cML\u7ba1\u9053\u5e94\u89c6\u4e3a\u516c\u5171\u57fa\u7840\u8bbe\u65bd\uff0c\u6210\u529f\u4f9d\u8d56\u4e8e\u900f\u660e\u3001\u53ef\u91cd\u73b0\u548c\u8d1f\u8d23\u4efb\u7684\u6570\u636e\u57fa\u7840\u8bbe\u65bd\u5efa\u8bbe\u3002"}}
{"id": "2511.00903", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00903", "abs": "https://arxiv.org/abs/2511.00903", "authors": ["Ahmed Masry", "Megh Thakkar", "Patrice Bechard", "Sathwik Tejaswi Madhusudhan", "Rabiul Awal", "Shambhavi Mishra", "Akshay Kalkunte Suresh", "Srivatsava Daruru", "Enamul Hoque", "Spandana Gella", "Torsten Scholak", "Sai Rajeswar"], "title": "ColMate: Contrastive Late Interaction and Masked Text for Multimodal Document Retrieval", "comment": null, "summary": "Retrieval-augmented generation has proven practical when models require\nspecialized knowledge or access to the latest data. However, existing methods\nfor multimodal document retrieval often replicate techniques developed for\ntext-only retrieval, whether in how they encode documents, define training\nobjectives, or compute similarity scores. To address these limitations, we\npresent ColMate, a document retrieval model that bridges the gap between\nmultimodal representation learning and document retrieval. ColMate utilizes a\nnovel OCR-based pretraining objective, a self-supervised masked contrastive\nlearning objective, and a late interaction scoring mechanism more relevant to\nmultimodal document structures and visual characteristics. ColMate obtains\n3.61% improvements over existing retrieval models on the ViDoRe V2 benchmark,\ndemonstrating stronger generalization to out-of-domain benchmarks.", "AI": {"tldr": "ColMate\u662f\u4e00\u79cd\u4e13\u4e3a\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u8bbe\u8ba1\u7684\u6a21\u578b\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u9884\u8bad\u7ec3\u76ee\u6807\u548c\u8bc4\u5206\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u68c0\u7d22\u6027\u80fd\uff0c\u5728ViDoRe V2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u65b9\u6cd5\u591a\u6cbf\u7528\u6587\u672c\u68c0\u7d22\u6280\u672f\uff0c\u5ffd\u89c6\u4e86\u591a\u6a21\u6001\u6587\u6863\u7684\u89c6\u89c9\u548c\u7ed3\u6784\u7279\u6027\uff0c\u9650\u5236\u4e86\u68c0\u7d22\u6548\u679c\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51faColMate\u6a21\u578b\uff0c\u91c7\u7528\u57fa\u4e8eOCR\u7684\u65b0\u578b\u9884\u8bad\u7ec3\u76ee\u6807\u3001\u81ea\u76d1\u7763\u63a9\u7801\u5bf9\u6bd4\u5b66\u4e60\u4ee5\u53ca\u9002\u5408\u591a\u6a21\u6001\u6587\u6863\u7684\u665a\u671f\u4ea4\u4e92\u6253\u5206\u673a\u5236\u3002", "result": "ColMate\u5728ViDoRe V2\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u6bd4\u73b0\u6709\u6a21\u578b\u63d0\u5347\u4e863.61%\uff0c\u4e14\u8868\u73b0\u51fa\u4e86\u66f4\u5f3a\u7684\u8de8\u9886\u57df\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u6001\u7279\u5f81\u7684\u9884\u8bad\u7ec3\u548c\u8bc4\u5206\u7b56\u7565\uff0cColMate\u6709\u6548\u63d0\u5347\u4e86\u591a\u6a21\u6001\u6587\u6863\u68c0\u7d22\u7684\u51c6\u786e\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.01757", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.01757", "abs": "https://arxiv.org/abs/2511.01757", "authors": ["Shamse Tasnim Cynthia", "Banani Roy"], "title": "Towards LLM-Powered Task-Aware Retrieval of Scientific Workflows for Galaxy", "comment": null, "summary": "Scientific Workflow Management Systems (SWfMSs) such as Galaxy have become\nessential infrastructure in bioinformatics, supporting the design, execution,\nand sharing of complex multi-step analyses. Despite hosting hundreds of\nreusable workflows across domains, Galaxy's current keyword-based retrieval\nsystem offers limited support for semantic query interpretation and often fails\nto surface relevant workflows when exact term matches are absent. To address\nthis gap, we propose a task-aware, two-stage retrieval framework that\nintegrates dense vector search with large language model (LLM)-based reranking.\nOur system first retrieves candidate workflows using state-of-the-art embedding\nmodels and then reranks them using instruction-tuned generative LLMs (GPT-4o,\nMistral-7B) based on semantic task alignment. To support robust evaluation, we\nconstruct a benchmark dataset of Galaxy workflows annotated with semantic\ntopics via BERTopic and synthesize realistic task-oriented queries using LLMs.\nWe conduct a comprehensive comparison of lexical, dense, and reranking models\nusing standard IR metrics, presenting the first systematic evaluation of\nretrieval performance in the Galaxy ecosystem. Results show that our approach\nsignificantly improves top-k accuracy and relevance, particularly for long or\nunder-specified queries. We further integrate our system as a prototype tool\nwithin Galaxy, providing a proof-of-concept for LLM-enhanced workflow search.\nThis work advances the usability and accessibility of scientific workflows,\nespecially for novice users and interdisciplinary researchers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5bc6\u96c6\u5411\u91cf\u68c0\u7d22\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91cd\u6392\u5e8f\u7684Galaxy\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u68c0\u7d22\u6846\u67b6\uff0c\u63d0\u9ad8\u4e86\u68c0\u7d22\u7684\u8bed\u4e49\u7406\u89e3\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524dGalaxy\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u68c0\u7d22\u7cfb\u7edf\u7f3a\u4e4f\u8bed\u4e49\u67e5\u8be2\u7406\u89e3\u80fd\u529b\uff0c\u96be\u4ee5\u6709\u6548\u68c0\u7d22\u76f8\u5173\u5de5\u4f5c\u6d41\u7a0b\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u68c0\u7d22\u6846\u67b6\uff0c\u5148\u7528\u5d4c\u5165\u6a21\u578b\u68c0\u7d22\u5019\u9009\u5de5\u4f5c\u6d41\u7a0b\uff0c\u518d\u7528\u6307\u4ee4\u8c03\u4f18\u7684\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982GPT-4o\uff0cMistral-7B\uff09\u8fdb\u884c\u57fa\u4e8e\u4efb\u52a1\u8bed\u4e49\u7684\u91cd\u6392\u5e8f\uff0c\u5e76\u6784\u5efa\u6807\u6ce8\u6570\u636e\u96c6\u548c\u771f\u5b9e\u67e5\u8be2\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u4fe1\u606f\u68c0\u7d22\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\u4e86Top-k\u51c6\u786e\u7387\u548c\u76f8\u5173\u6027\uff0c\u7279\u522b\u662f\u5728\u957f\u67e5\u8be2\u6216\u6a21\u7cca\u67e5\u8be2\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u96c6\u6210\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u589e\u5f3a\u7684\u68c0\u7d22\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u7684\u53ef\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\uff0c\u7279\u522b\u60e0\u53ca\u65b0\u624b\u548c\u8de8\u5b66\u79d1\u7814\u7a76\u8005\u3002"}}
{"id": "2511.00924", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00924", "abs": "https://arxiv.org/abs/2511.00924", "authors": ["Jianzhou Yao", "Shunchang Liu", "Guillaume Drui", "Rikard Pettersson", "Alessandro Blasimme", "Sara Kijewski"], "title": "The Biased Oracle: Assessing LLMs' Understandability and Empathy in Medical Diagnoses", "comment": "Accepted by NeurIPS 2025 GenAI4Health Workshop", "summary": "Large language models (LLMs) show promise for supporting clinicians in\ndiagnostic communication by generating explanations and guidance for patients.\nYet their ability to produce outputs that are both understandable and\nempathetic remains uncertain. We evaluate two leading LLMs on medical\ndiagnostic scenarios, assessing understandability using readability metrics as\na proxy and empathy through LLM-as-a-Judge ratings compared to human\nevaluations. The results indicate that LLMs adapt explanations to\nsocio-demographic variables and patient conditions. However, they also generate\noverly complex content and display biased affective empathy, leading to uneven\naccessibility and support. These patterns underscore the need for systematic\ncalibration to ensure equitable patient communication. The code and data are\nreleased: https://github.com/Jeffateth/Biased_Oracle", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u6c9f\u901a\u4e2d\u7684\u7406\u89e3\u6027\u548c\u540c\u7406\u5fc3\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u5185\u5bb9\u590d\u6742\u4e14\u5b58\u5728\u60c5\u611f\u504f\u5dee\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f85\u52a9\u533b\u751f\u8fdb\u884c\u8bca\u65ad\u6c9f\u901a\uff0c\u751f\u6210\u60a3\u8005\u89e3\u91ca\u548c\u6307\u5bfc\u65b9\u9762\u8868\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u8f93\u51fa\u7684\u7406\u89e3\u6027\u548c\u540c\u7406\u5fc3\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u901a\u8fc7\u5bf9\u4e24\u4e2a\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u8bca\u65ad\u573a\u666f\u4e2d\u7684\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\uff0c\u4f7f\u7528\u53ef\u8bfb\u6027\u6307\u6807\u8861\u91cf\u7406\u89e3\u6027\uff0c\u901a\u8fc7\u6a21\u578b\u4f5c\u4e3a\u8bc4\u5224\u8005\u7684\u8bc4\u5206\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u6bd4\u8f83\u540c\u7406\u5fc3\u3002", "result": "\u6a21\u578b\u80fd\u6839\u636e\u793e\u4f1a\u4eba\u53e3\u53d8\u91cf\u548c\u60a3\u8005\u72b6\u51b5\u8c03\u6574\u89e3\u91ca\u5185\u5bb9\uff0c\u4f46\u751f\u6210\u8fc7\u4e8e\u590d\u6742\u7684\u6587\u672c\uff0c\u4e14\u60c5\u611f\u540c\u7406\u5fc3\u5b58\u5728\u504f\u5dee\uff0c\u5bfc\u81f4\u5176\u652f\u6301\u548c\u53ef\u8bbf\u95ee\u6027\u4e0d\u5747\u8861\u3002", "conclusion": "\u9700\u8981\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u7684\u6821\u51c6\uff0c\u4ee5\u786e\u4fdd\u5176\u5728\u60a3\u8005\u6c9f\u901a\u4e2d\u7684\u516c\u5e73\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2511.01763", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01763", "abs": "https://arxiv.org/abs/2511.01763", "authors": ["Xiaohan Wang", "Yuxin Hu", "Kevin Leach"], "title": "Context-Guided Decompilation: A Step Towards Re-executability", "comment": null, "summary": "Binary decompilation plays an important role in software security analysis,\nreverse engineering, and malware understanding when source code is unavailable.\nHowever, existing decompilation techniques often fail to produce source code\nthat can be successfully recompiled and re-executed, particularly for optimized\nbinaries. Recent advances in large language models (LLMs) have enabled neural\napproaches to decompilation, but the generated code is typically only\nsemantically plausible rather than truly executable, limiting their practical\nreliability. These shortcomings arise from compiler optimizations and the loss\nof semantic cues in compiled code, which LLMs struggle to recover without\ncontextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid\ndecompilation framework that leverages in-context learning (ICL) to guide LLMs\ntoward generating re-executable source code. We evaluate our method across\nmultiple datasets, optimization levels, and compilers, demonstrating around\n40\\% improvement in re-executability over state-of-the-art decompilation\nmethods while maintaining robustness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ICL4Decomp\uff0c\u8fd9\u662f\u4e00\u79cd\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u4e0a\u4e0b\u6587\u5b66\u4e60\uff08ICL\uff09\u6307\u5bfc\u751f\u6210\u53ef\u91cd\u65b0\u6267\u884c\u6e90\u4ee3\u7801\u7684\u6df7\u5408\u4e8c\u8fdb\u5236\u53cd\u7f16\u8bd1\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u6280\u672f\u7ea640%\u7684\u53ef\u91cd\u6267\u884c\u6027\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u53cd\u7f16\u8bd1\u6280\u672f\u96be\u4ee5\u751f\u6210\u53ef\u91cd\u65b0\u7f16\u8bd1\u548c\u6267\u884c\u7684\u6e90\u4ee3\u7801\uff0c\u7279\u522b\u662f\u5728\u4f18\u5316\u540e\u7684\u4e8c\u8fdb\u5236\u6587\u4ef6\u4e2d\uff0c\u4e14\u73b0\u6709\u795e\u7ecf\u65b9\u6cd5\u751f\u6210\u7684\u4ee3\u7801\u591a\u4e3a\u8bed\u4e49\u5408\u7406\u4f46\u4e0d\u53ef\u6267\u884c\uff0c\u53d7\u9650\u4e8e\u7f16\u8bd1\u5668\u4f18\u5316\u548c\u8bed\u4e49\u7ebf\u7d22\u4e22\u5931\u3002", "method": "\u63d0\u51faICL4Decomp\u6df7\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u5b66\u4e60\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u53ef\u91cd\u65b0\u6267\u884c\u7684\u6e90\u4ee3\u7801\uff0c\u7ed3\u5408\u591a\u6570\u636e\u96c6\u3001\u591a\u4f18\u5316\u7ea7\u522b\u53ca\u7f16\u8bd1\u5668\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u4e0d\u540c\u4f18\u5316\u7ea7\u522b\u3001\u7f16\u8bd1\u5668\u73af\u5883\u4e0b\uff0cICL4Decomp\u5728\u53ef\u91cd\u6267\u884c\u6027\u65b9\u9762\u8f83\u6700\u5148\u8fdb\u53cd\u7f16\u8bd1\u65b9\u6cd5\u63d0\u5347\u7ea640%\uff0c\u4e14\u4fdd\u6301\u4e86\u9c81\u68d2\u6027\u3002", "conclusion": "\u5229\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u6307\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u53cd\u7f16\u8bd1\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u751f\u6210\u4ee3\u7801\u7684\u5b9e\u9645\u53ef\u91cd\u6267\u884c\u6027\uff0c\u589e\u5f3a\u53cd\u7f16\u8bd1\u6280\u672f\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.00960", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.00960", "abs": "https://arxiv.org/abs/2511.00960", "authors": ["Abhinav P M", "Ojasva Saxena", "Oswald C", "Parameswari Krishnamurthy"], "title": "The Riddle of Reflection: Evaluating Reasoning and Self-Awareness in Multilingual LLMs using Indian Riddles", "comment": null, "summary": "The extent to which large language models (LLMs) can perform culturally\ngrounded reasoning across non-English languages remains underexplored. This\npaper examines the reasoning and self-assessment abilities of LLMs across seven\nmajor Indian languages-Bengali, Gujarati, Hindi, Kannada, Malayalam, Tamil, and\nTelugu. We introduce a multilingual riddle dataset combining traditional\nriddles with context-reconstructed variants and evaluate five LLMs-Gemini 2.5\nPro, Gemini 2.5 Flash, Mistral-Saba, LLaMA 4 Scout, and LLaMA 4 Maverick-under\nseven prompting strategies. In the first stage, we assess riddle-solving\nperformance and find that while Gemini 2.5 Pro performs best overall, few-shot\nmethods yield only marginal gains, and accuracy varies notably across\nlanguages. In the second stage, we conduct a self-evaluation experiment to\nmeasure reasoning consistency. The results reveal a key finding: a model's\ninitial accuracy is inversely correlated with its ability to identify its own\nmistakes. Top-performing models such as Gemini 2.5 Pro are overconfident (4.34%\nTrue Negative Rate), whereas lower-performing models like LLaMA 4 Scout are\nsubstantially more self-aware (42.09% True Negative Rate). These results point\nto clear gaps in multilingual reasoning and highlight the need for models that\nnot only reason effectively but also recognize their own limitations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5370\u5730\u8bed\u7b49\u4e03\u79cd\u5370\u5ea6\u8bed\u8a00\u4e2d\u7684\u6587\u5316\u63a8\u7406\u80fd\u529b\uff0c\u8bc4\u4f30\u4e86\u4e94\u79cd\u6a21\u578b\u5728\u89e3\u8c1c\u53ca\u81ea\u6211\u8bc4\u4f30\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u9ad8\u51c6\u786e\u7387\u6a21\u578b\u81ea\u4fe1\u8fc7\u5ea6\uff0c\u4f4e\u51c6\u786e\u7387\u6a21\u578b\u53cd\u800c\u66f4\u80fd\u8bc6\u522b\u9519\u8bef\uff0c\u63ed\u793a\u591a\u8bed\u8a00\u63a8\u7406\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u79cd\u975e\u82f1\u8bed\u8bed\u8a00\u73af\u5883\u4e0b\u8fdb\u884c\u6587\u5316\u80cc\u666f\u63a8\u7406\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u5370\u5ea6\u4e3b\u8981\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\uff0c\u4ee5\u586b\u8865\u76f8\u5173\u7814\u7a76\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u591a\u8bed\u8a00\u8c1c\u8bed\u6570\u636e\u96c6\uff0c\u7ed3\u5408\u4f20\u7edf\u8c1c\u8bed\u548c\u4e0a\u4e0b\u6587\u91cd\u6784\u7248\u672c\uff0c\u4f7f\u7528\u4e03\u79cd\u63d0\u793a\u7b56\u7565\u8bc4\u4f30Gemini 2.5 Pro\u7b49\u4e94\u4e2a\u6a21\u578b\u7684\u89e3\u8c1c\u80fd\u529b\u548c\u81ea\u6211\u8bc4\u4f30\u80fd\u529b\u3002", "result": "Gemini 2.5 Pro\u6574\u4f53\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u51e0\u6b21\u793a\u4f8b\u63d0\u793a\u63d0\u5347\u6709\u9650\uff1b\u8bed\u8a00\u95f4\u51c6\u786e\u7387\u5dee\u5f02\u660e\u663e\uff1b\u81ea\u6211\u8bc4\u4f30\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u51c6\u786e\u7387\u4e0e\u5176\u8bc6\u522b\u81ea\u8eab\u9519\u8bef\u80fd\u529b\u8d1f\u76f8\u5173\uff0c\u9ad8\u51c6\u786e\u7387\u6a21\u578b\u8fc7\u4e8e\u81ea\u4fe1\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u6587\u5316\u63a8\u7406\u4e2d\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u6a21\u578b\u81ea\u8eab\u8bc6\u522b\u9519\u8bef\u7684\u80fd\u529b\u6709\u9650\uff0c\u672a\u6765\u9700\u5f00\u53d1\u65e2\u80fd\u6709\u6548\u63a8\u7406\u53c8\u80fd\u8bc6\u522b\u81ea\u8eab\u5c40\u9650\u6027\u7684\u6a21\u578b\u3002"}}
{"id": "2511.01850", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01850", "abs": "https://arxiv.org/abs/2511.01850", "authors": ["Jiawei Jin", "Yingxin Su", "Xiaotong Zhu"], "title": "SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring", "comment": null, "summary": "The rapid expansion of artificial intelligence and machine learning (ML)\napplications has intensified the demand for integrated environments that unify\nmodel development, deployment, and monitoring. Traditional Integrated\nDevelopment Environments (IDEs) focus primarily on code authoring, lacking\nintelligent support for the full ML lifecycle, while existing MLOps platforms\nremain detached from the coding workflow. To address this gap, this study\nproposes the design of an LLM-Integrated IDE with automated MLOps pipelines\nthat enables continuous model development and monitoring within a single\nenvironment. The proposed system embeds a Large Language Model (LLM) assistant\ncapable of code generation, debugging recommendation, and automatic pipeline\nconfiguration. The backend incorporates automated data validation, feature\nstorage, drift detection, retraining triggers, and CI/CD deployment\norchestration. This framework was implemented in a prototype named SmartMLOps\nStudio and evaluated using classification and forecasting tasks on the UCI\nAdult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio\nreduces pipeline configuration time by 61%, improves experiment reproducibility\nby 45%, and increases drift detection accuracy by 14% compared to traditional\nworkflows. By bridging intelligent code assistance and automated operational\npipelines, this research establishes a novel paradigm for AI engineering -\ntransforming the IDE from a static coding tool into a dynamic, lifecycle-aware\nintelligent platform for scalable and efficient model development.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u52a9\u624b\u548c\u81ea\u52a8\u5316MLOps\u7ba1\u9053\u7684\u667a\u80fdIDE\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u5f00\u53d1\u3001\u90e8\u7f72\u548c\u76d1\u63a7\u7684\u4e00\u4f53\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u914d\u7f6e\u6548\u7387\u3001\u5b9e\u9a8c\u53ef\u91cd\u590d\u6027\u548c\u6f02\u79fb\u68c0\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u4f20\u7edfIDE\u4e3b\u8981\u652f\u6301\u4ee3\u7801\u7f16\u5199\uff0c\u7f3a\u4e4f\u5bf9\u5b8c\u6574\u673a\u5668\u5b66\u4e60\u751f\u547d\u5468\u671f\u7684\u667a\u80fd\u652f\u6301\uff0c\u73b0\u6709MLOps\u5e73\u53f0\u4e0e\u7f16\u7801\u5de5\u4f5c\u6d41\u7a0b\u5206\u79bb\uff0c\u96be\u4ee5\u5b9e\u73b0\u4e00\u4f53\u5316\u7ba1\u7406\u548c\u81ea\u52a8\u5316\u64cd\u4f5c\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u96c6\u6210LLM\u52a9\u624b\uff08\u652f\u6301\u4ee3\u7801\u751f\u6210\u3001\u8c03\u8bd5\u5efa\u8bae\u53ca\u81ea\u52a8\u914d\u7f6e\u7ba1\u9053\uff09\u7684\u667a\u80fdIDE\u3002\u540e\u7aef\u96c6\u6210\u81ea\u52a8\u6570\u636e\u6821\u9a8c\u3001\u7279\u5f81\u5b58\u50a8\u3001\u6f02\u79fb\u68c0\u6d4b\u53ca\u518d\u8bad\u7ec3\u89e6\u53d1\u673a\u5236\uff0c\u642d\u5efaCI/CD\u90e8\u7f72\u7cfb\u7edf\u3002\u6784\u5efa\u539f\u578bSmartMLOps Studio\u5e76\u5728UCI Adult\u548cM5\u6570\u636e\u96c6\u4e0a\u8bc4\u6d4b\u3002", "result": "SmartMLOps Studio\u76f8\u6bd4\u4f20\u7edf\u5de5\u4f5c\u6d41\uff0c\u914d\u7f6e\u65f6\u95f4\u51cf\u5c1161%\uff0c\u5b9e\u9a8c\u53ef\u91cd\u590d\u6027\u63d0\u534745%\uff0c\u6f02\u79fb\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u534714%\u3002", "conclusion": "\u8be5\u7814\u7a76\u901a\u8fc7\u7ed3\u5408\u667a\u80fd\u4ee3\u7801\u8f85\u52a9\u548c\u81ea\u52a8\u5316\u8fd0\u7ef4\u7ba1\u9053\uff0c\u521b\u65b0\u6027\u5730\u5c06IDE\u8f6c\u53d8\u4e3a\u5177\u5907\u751f\u547d\u5468\u671f\u611f\u77e5\u7684\u667a\u80fd\u5e73\u53f0\uff0c\u4e3a\u53ef\u6269\u5c55\u9ad8\u6548\u7684\u6a21\u578b\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.00988", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.00988", "abs": "https://arxiv.org/abs/2511.00988", "authors": ["Chenwang Wu", "Yiu-ming Cheung", "Bo Han", "Defu Lian"], "title": "Advancing Machine-Generated Text Detection from an Easy to Hard Supervision Perspective", "comment": null, "summary": "Existing machine-generated text (MGT) detection methods implicitly assume\nlabels as the \"golden standard\". However, we reveal boundary ambiguity in MGT\ndetection, implying that traditional training paradigms are inexact. Moreover,\nlimitations of human cognition and the superintelligence of detectors make\ninexact learning widespread and inevitable. To this end, we propose an\neasy-to-hard enhancement framework to provide reliable supervision under such\ninexact conditions. Distinct from knowledge distillation, our framework employs\nan easy supervisor targeting relatively simple longer-text detection tasks\n(despite weaker capabilities), to enhance the more challenging target detector.\nFirstly, longer texts targeted by supervisors theoretically alleviate the\nimpact of inexact labels, laying the foundation for reliable supervision.\nSecondly, by structurally incorporating the detector into the supervisor, we\ntheoretically model the supervisor as a lower performance bound for the\ndetector. Thus, optimizing the supervisor indirectly optimizes the detector,\nultimately approximating the underlying \"golden\" labels. Extensive experiments\nacross diverse practical scenarios, including cross-LLM, cross-domain, mixed\ntext, and paraphrase attacks, demonstrate the framework's significant detection\neffectiveness. The code is available at:\nhttps://github.com/tmlr-group/Easy2Hard.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u673a\u5668\u751f\u6210\u6587\u672c\u7684\u68c0\u6d4b\u65b9\u6cd5\uff0c\u6307\u51fa\u4f20\u7edf\u65b9\u6cd5\u5b58\u5728\u6807\u7b7e\u6a21\u7cca\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u4e2a\u7531\u6613\u5230\u96be\u7684\u589e\u5f3a\u6846\u67b6\u4ee5\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u76d1\u7763\uff0c\u663e\u8457\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u9ed8\u8ba4\u6807\u7b7e\u4e3a\u7edd\u5bf9\u6807\u51c6\uff0c\u5ffd\u89c6\u4e86\u6807\u7b7e\u7684\u8fb9\u754c\u6a21\u7cca\u6027\u548c\u4eba\u7c7b\u8ba4\u77e5\u53ca\u68c0\u6d4b\u5668\u7684\u9650\u5236\uff0c\u5bfc\u81f4\u8bad\u7ec3\u5b58\u5728\u4e0d\u7cbe\u786e\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u7531\u6613\u5230\u96be\u7684\u589e\u5f3a\u6846\u67b6\uff0c\u5229\u7528\u8f83\u7b80\u5355\u7684\u957f\u6587\u672c\u68c0\u6d4b\u4efb\u52a1\u4f5c\u4e3a\u76d1\u7763\u8005\uff0c\u901a\u8fc7\u7ed3\u6784\u5d4c\u5165\u68c0\u6d4b\u5668\uff0c\u5efa\u7acb\u76d1\u7763\u8005\u7684\u6027\u80fd\u4e0b\u754c\u4ee5\u95f4\u63a5\u4f18\u5316\u68c0\u6d4b\u5668\uff0c\u5b9e\u73b0\u5bf9\u201c\u9ec4\u91d1\u201d\u6807\u7b7e\u7684\u8fd1\u4f3c\u3002", "result": "\u5728\u8de8\u5927\u6a21\u578b\u3001\u8de8\u9886\u57df\u3001\u6df7\u5408\u6587\u672c\u53ca\u91ca\u4e49\u653b\u51fb\u7b49\u591a\u79cd\u5b9e\u9645\u573a\u666f\u4e2d\u8fdb\u884c\u4e86\u5927\u91cf\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u63d0\u5347\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u6548\u679c\u4e0a\u7684\u663e\u8457\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6807\u7b7e\u4e0d\u7cbe\u786e\u95ee\u9898\uff0c\u901a\u8fc7\u6613\u76d1\u7763\u8005\u8f85\u52a9\u96be\u68c0\u6d4b\u5668\u7684\u65b9\u5f0f\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\uff0c\u5177\u5907\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\uff0c\u5e76\u516c\u5f00\u4e86\u4ee3\u7801\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2511.01008", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01008", "abs": "https://arxiv.org/abs/2511.01008", "authors": ["Haolin Yang", "Jipeng Zhang", "Zhitao He", "Yi R. Fung"], "title": "MARS-SQL: A multi-agent reinforcement learning framework for Text-to-SQL", "comment": null, "summary": "Translating natural language to SQL remains difficult for complex queries.\nSuch queries often need environmental interaction and self-correction. To\naddress this, we introduce MARS-SQL, a novel multi-agent framework that\ncombines principled task decomposition and interactive reinforcement learning\n(RL). Our system comprises three specialized agents: a Grounding Agent for\nschema linking, a Generation Agent for query generation, and a Validation Agent\nfor final selection. The core of our framework is the Generation agent, which\nis trained via a multi-turn RL policy. Adopting a ReAct-style Think-Act-Observe\nloop, the agent iteratively generates thoughts, executes SQL actions against a\nlive database, and revises its strategy based on execution feedback, enabling\ndynamic, stateful reasoning and self-correction. At inference time, we generate\nmultiple interaction trajectories to explore diverse reasoning paths. The\nValidation agent, then selects the optimal trajectory by modeling verification\nas a next-token prediction task and choosing the solution with the highest\ngeneration probability. This structured workflow pipelines specialized agents.\nIt combines interactive RL for generation with generative modeling for\nverification. The approach proves highly effective for robust and accurate SQL\ngeneration. Experiments show that MARS-SQL achieves state-of-the-art Execution\nAccuracy of 77.84% on the BIRD dev set and 89.75% on the Spider test set. Our\ncode is available at https://github.com/YangHaolin0526/MARS-SQL.", "AI": {"tldr": "MARS-SQL\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u4efb\u52a1\u5206\u89e3\u4e0e\u4ea4\u4e92\u5f0f\u5f3a\u5316\u5b66\u4e60\uff0c\u5b9e\u73b0\u590d\u6742\u81ea\u7136\u8bed\u8a00\u5230SQL\u7684\u8f6c\u6362\uff0c\u81ea\u6211\u7ea0\u6b63\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u53d6\u5f97\u6700\u65b0\u6267\u884c\u51c6\u786e\u7387\u3002", "motivation": "\u590d\u6742\u67e5\u8be2\u7684\u81ea\u7136\u8bed\u8a00\u8f6cSQL\u4efb\u52a1\u96be\u5ea6\u5927\uff0c\u9700\u73af\u5883\u4ea4\u4e92\u53ca\u81ea\u6211\u7ea0\u6b63\u80fd\u529b\u4ee5\u63d0\u9ad8\u51c6\u786e\u7387\u3002", "method": "\u8bbe\u8ba1\u5730\u57fa\u4f53\u3001\u751f\u6210\u548c\u9a8c\u8bc1\u4e09\u4e2a\u667a\u80fd\u4f53\uff1b\u751f\u6210\u667a\u80fd\u4f53\u901a\u8fc7\u591a\u8f6eReAct\u98ce\u683c\u5f3a\u5316\u5b66\u4e60\u4e0e\u6570\u636e\u5e93\u4ea4\u4e92\u81ea\u6211\u4fee\u6b63\uff1b\u9a8c\u8bc1\u667a\u80fd\u4f53\u57fa\u4e8e\u751f\u6210\u6982\u7387\u9009\u6700\u4f18\u89e3\u3002", "result": "\u5728BIRD\u548cSpider\u6570\u636e\u96c6\u4e0a\u5206\u522b\u8fbe\u621077.84%\u548c89.75%\u7684\u6267\u884c\u51c6\u786e\u7387\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MARS-SQL\u6709\u6548\u7ed3\u5408\u4e86\u5206\u5de5\u660e\u786e\u7684\u591a\u667a\u80fd\u4f53\u548c\u4ea4\u4e92\u5f0fRL\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u67e5\u8be2\u7684SQL\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.01014", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01014", "abs": "https://arxiv.org/abs/2511.01014", "authors": ["Bosi Wen", "Yilin Niu", "Cunxiang Wang", "Pei Ke", "Xiaoying Ling", "Ying Zhang", "Aohan Zeng", "Hongning Wang", "Minlie Huang"], "title": "IF-CRITIC: Towards a Fine-Grained LLM Critic for Instruction-Following Evaluation", "comment": "21 pages, 5 figures", "summary": "Instruction following is a fundamental ability of Large Language Models\n(LLMs), requiring their generated outputs to follow multiple constraints\nimposed in input instructions. Numerous studies have attempted to enhance this\nability through preference optimization or reinforcement learning based on\nreward signals from LLM-as-a-Judge. However, existing evaluation models for\ninstruction following still possess many deficiencies, such as substantial\ncosts and unreliable assessments. To this end, we propose IF-CRITIC, an LLM\ncritic that can provide efficient and reliable assessments of constraint\nfollowing in the instructions. We first develop a checklist generator to\ndecompose instructions and generate constraint checklists. With the assistance\nof the checklists, we collect high-quality critique training data through a\nmulti-stage critique filtering mechanism and employ a constraint-level\npreference optimization method to train IF-CRITIC. Extensive experiments\ndemonstrate that the evaluation performance of IF-CRITIC can beat strong\nLLM-as-a-Judge baselines, including Deepseek-R1 and o4-mini. With the scalable\nreward signals provided by IF-CRITIC, LLMs can achieve substantial performance\ngains in instruction-following optimization under lower computational overhead\ncompared to strong LLM critic baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IF-CRITIC\uff0c\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u6307\u4ee4\u9075\u5faa\u8bc4\u4f30\u6a21\u578b\uff0c\u901a\u8fc7\u751f\u6210\u7ea6\u675f\u6e05\u5355\u548c\u591a\u9636\u6bb5\u7b5b\u9009\u673a\u5236\u8bad\u7ec3\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u8d85\u8d8a\u73b0\u6709\u5f3a\u57fa\u7ebf\u7684\u65b9\u6cd5\uff0c\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6307\u4ee4\u9075\u5faa\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u6307\u4ee4\u9075\u5faa\u8bc4\u4f30\u6a21\u578b\u5b58\u5728\u9ad8\u6210\u672c\u548c\u8bc4\u4f30\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6307\u4ee4\u9075\u5faa\u80fd\u529b\u63d0\u5347\u4e0a\u7684\u6548\u679c\u3002", "method": "\u63d0\u51faIF-CRITIC\uff0c\u901a\u8fc7\u5f00\u53d1\u6307\u4ee4\u5206\u89e3\u53ca\u7ea6\u675f\u6e05\u5355\u751f\u6210\u5668\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u7b5b\u9009\u673a\u5236\u6536\u96c6\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u7ed3\u5408\u7ea6\u675f\u7ea7\u522b\u504f\u597d\u4f18\u5316\u65b9\u6cd5\u8bad\u7ec3\u8bc4\u4f30\u6a21\u578b\u3002", "result": "IF-CRITIC\u5728\u8bc4\u4f30\u6027\u80fd\u4e0a\u8d85\u8fc7Deepseek-R1\u548co4-mini\u7b49\u5f3a\u57fa\u7ebf\uff0c\u4e14\u63d0\u4f9b\u7684\u5956\u52b1\u4fe1\u53f7\u4f7f\u5f97\u6307\u4ee4\u9075\u5faa\u4f18\u5316\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0c\u8ba1\u7b97\u5f00\u9500\u66f4\u4f4e\u3002", "conclusion": "IF-CRITIC\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u6307\u4ee4\u9075\u5faa\u7684\u8bc4\u4f30\u4e0e\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u53ef\u9760\u4e14\u4f4e\u6210\u672c\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u63a8\u52a8\u4e86\u76f8\u5173\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2511.01016", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01016", "abs": "https://arxiv.org/abs/2511.01016", "authors": ["Wenjin Liu", "Haoran Luo", "Xueyuan Lin", "Haoming Liu", "Tiesunlong Shen", "Jiapu Wang", "Rui Mao", "Erik Cambria"], "title": "Prompt-R1: Collaborative Automatic Prompting Framework via End-to-end Reinforcement Learning", "comment": null, "summary": "Recently, advanced large language models (LLMs) have emerged at an\nincreasingly rapid pace. However, when faced with complex problems, most users\nare often unable to provide accurate and effective prompts to interact with\nLLMs, thus limiting the performance of LLMs. To address this challenge, we\npropose Prompt-R1, an end-to-end reinforcement learning framework that uses a\nsmall-scale LLM to collaborate with large-scale LLMs, replacing user\ninteraction to solve problems better. This collaboration is cast as a\nmulti-turn prompt interaction, where the small-scale LLM thinks and generates\nprompts, and the large-scale LLM performs complex reasoning. A dual-constrained\nreward is designed to optimize for correctness, generation quality, and\nreasoning accuracy. Prompt-R1 provides a plug-and-play framework that supports\nboth inference and training with various large-scale LLMs. Experiments on\nmultiple public datasets show that Prompt-R1 significantly outperforms baseline\nmodels across tasks. Our code is publicly available at\nhttps://github.com/QwenQKing/Prompt-R1.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5c0f\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6Prompt-R1\uff0c\u901a\u8fc7\u4ee3\u66ff\u7528\u6237\u4ea4\u4e92\u751f\u6210\u66f4\u51c6\u786e\u7684\u63d0\u793a\u4ee5\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u590d\u6742\u95ee\u9898\u7684\u89e3\u51b3\u80fd\u529b\u3002", "motivation": "\u7528\u6237\u5f80\u5f80\u65e0\u6cd5\u9488\u5bf9\u590d\u6742\u95ee\u9898\u63d0\u4f9b\u51c6\u786e\u6709\u6548\u7684\u63d0\u793a\uff0c\u9650\u5236\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u53d1\u6325\u3002", "method": "\u8bbe\u8ba1Prompt-R1\uff0c\u4e00\u4e2a\u7aef\u5230\u7aef\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u591a\u8f6e\u63d0\u793a\uff0c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u534f\u4f5c\u89e3\u51b3\u95ee\u9898\u3002\u91c7\u7528\u53cc\u91cd\u7ea6\u675f\u5956\u52b1\u4f18\u5316\u8f93\u51fa\u7684\u6b63\u786e\u6027\u3001\u751f\u6210\u8d28\u91cf\u548c\u63a8\u7406\u51c6\u786e\u6027\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0cPrompt-R1\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Prompt-R1\u6846\u67b6\u6709\u6548\u6539\u5584\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u652f\u6301\u591a\u79cd\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u548c\u8bad\u7ec3\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2511.01166", "categories": ["cs.CL", "cs.SE", "68T50", "I.2.7"], "pdf": "https://arxiv.org/pdf/2511.01166", "abs": "https://arxiv.org/abs/2511.01166", "authors": ["Lingzhe Zhang", "Yunpeng Zhai", "Tong Jia", "Chiming Duan", "Minghua He", "Leyi Pan", "Zhaoyang Liu", "Bolin Ding", "Ying Li"], "title": "MicroRemed: Benchmarking LLMs in Microservices Remediation", "comment": "24 pages, 13 figures, 5 tables", "summary": "Large Language Models (LLMs) integrated with agent-based reasoning frameworks\nhave recently shown strong potential for autonomous decision-making and\nsystem-level operations. One promising yet underexplored direction is\nmicroservice remediation, where the goal is to automatically recover faulty\nmicroservice systems. Existing approaches, however, still rely on human-crafted\nprompts from Site Reliability Engineers (SREs), with LLMs merely converting\ntextual instructions into executable code. To advance research in this area, we\nintroduce MicroRemed, the first benchmark for evaluating LLMs in end-to-end\nmicroservice remediation, where models must directly generate executable\nAnsible playbooks from diagnosis reports to restore system functionality. We\nfurther propose ThinkRemed, a multi-agent framework that emulates the\nreflective and perceptive reasoning of SREs. Experimental results show that\nMicroRemed presents substantial challenges to current LLMs, while ThinkRemed\nimproves end-to-end remediation performance through iterative reasoning and\nsystem reflection. The benchmark is available at\nhttps://github.com/LLM4AIOps/MicroRemed.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MicroRemed\uff0c\u9996\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u670d\u52a1\u7cfb\u7edf\u81ea\u52a8\u4fee\u590d\u4e2d\u7684\u57fa\u51c6\uff0c\u53caThinkRemed\u591a\u667a\u80fd\u4f53\u6846\u67b6\u63d0\u5347\u4fee\u590d\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5fae\u670d\u52a1\u7cfb\u7edf\u81ea\u52a8\u4fee\u590d\u4f9d\u8d56\u4eba\u5de5\u8bbe\u8ba1\u63d0\u793a\uff0c\u5927\u8bed\u8a00\u6a21\u578b\u4ec5\u5c06\u6587\u672c\u8f6c\u4e3a\u53ef\u6267\u884c\u4ee3\u7801\uff0c\u7f3a\u4e4f\u7aef\u5230\u7aef\u81ea\u52a8\u4fee\u590d\u80fd\u529b\u3002", "method": "\u5f15\u5165MicroRemed\u57fa\u51c6\u8bc4\u6d4b\u6a21\u578b\u4ece\u8bca\u65ad\u62a5\u544a\u76f4\u63a5\u751f\u6210\u53ef\u6267\u884c\u7684Ansible\u5267\u672c\uff0c\u5e76\u8bbe\u8ba1\u591a\u667a\u80fd\u4f53\u6846\u67b6ThinkRemed\u6a21\u62dfSRE\u7684\u53cd\u601d\u4e0e\u611f\u77e5\u63a8\u7406\u3002", "result": "\u5b9e\u9a8c\u8868\u660eMicroRemed\u5bf9\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u8f83\u5927\u6311\u6218\uff0cThinkRemed\u901a\u8fc7\u8fed\u4ee3\u63a8\u7406\u548c\u7cfb\u7edf\u53cd\u601d\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6548\u679c\u3002", "conclusion": "MicroRemed\u4e3a\u5fae\u670d\u52a1\u81ea\u52a8\u4fee\u590d\u9886\u57df\u63d0\u4f9b\u4e86\u9996\u4e2a\u8bc4\u6d4b\u6807\u51c6\uff0cThinkRemed\u5c55\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u63a8\u7406\u63d0\u5347\u7aef\u5230\u7aef\u4fee\u590d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.01019", "categories": ["cs.CL", "cs.AI", "cs.CE", "cs.LG", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.01019", "abs": "https://arxiv.org/abs/2511.01019", "authors": ["Bowen Chen", "Jayesh Gajbhar", "Gregory Dusek", "Rob Redmon", "Patrick Hogan", "Paul Liu", "DelWayne Bohnenstiehl", "Dongkuan", "Xu", "Ruoying He"], "title": "OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights", "comment": "A related presentation will be given at the AGU(American Geophysical\n  Union) and AMS(American Meteorological Society) Annual Meetings", "summary": "Artificial intelligence is transforming the sciences, yet general\nconversational AI systems often generate unverified \"hallucinations\"\nundermining scientific rigor. We present OceanAI, a conversational platform\nthat integrates the natural-language fluency of open-source large language\nmodels (LLMs) with real-time, parameterized access to authoritative\noceanographic data streams hosted by the National Oceanic and Atmospheric\nAdministration (NOAA). Each query such as \"What was Boston Harbor's highest\nwater level in 2024?\" triggers real-time API calls that identify, parse, and\nsynthesize relevant datasets into reproducible natural-language responses and\ndata visualizations. In a blind comparison with three widely used AI\nchat-interface products, only OceanAI produced NOAA-sourced values with\noriginal data references; others either declined to answer or provided\nunsupported results. Designed for extensibility, OceanAI connects to multiple\nNOAA data products and variables, supporting applications in marine hazard\nforecasting, ecosystem assessment, and water-quality monitoring. By grounding\noutputs and verifiable observations, OceanAI advances transparency,\nreproducibility, and trust, offering a scalable framework for AI-enabled\ndecision support within the oceans. A public demonstration is available at\nhttps://oceanai.ai4ocean.xyz.", "AI": {"tldr": "OceanAI\u662f\u4e00\u79cd\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5b9e\u65f6\u6d77\u6d0b\u6570\u636e\u7684\u5bf9\u8bdd\u5f0fAI\u5e73\u53f0\uff0c\u80fd\u57fa\u4e8eNOAA\u6743\u5a01\u6570\u636e\u63d0\u4f9b\u51c6\u786e\u4e14\u53ef\u9a8c\u8bc1\u7684\u79d1\u5b66\u56de\u7b54\u3002", "motivation": "\u4e00\u822c\u5bf9\u8bdd\u5f0fAI\u7ecf\u5e38\u4ea7\u751f\u672a\u7ecf\u9a8c\u8bc1\u7684\u9519\u8bef\u4fe1\u606f\uff0c\u5f71\u54cd\u79d1\u5b66\u4e25\u8c28\u6027\uff0c\u8feb\u5207\u9700\u8981\u7ed3\u5408\u6743\u5a01\u6570\u636e\u63d0\u5347\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "OceanAI\u8c03\u7528NOAA\u7684\u5b9e\u65f6API\uff0c\u89e3\u6790\u5e76\u7efc\u5408\u76f8\u5173\u6d77\u6d0b\u6570\u636e\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u56de\u7b54\u5e76\u751f\u6210\u6570\u636e\u53ef\u89c6\u5316\uff0c\u652f\u6301\u591a\u79cd\u6d77\u6d0b\u79d1\u5b66\u5e94\u7528\u3002", "result": "\u5728\u4e0e\u4e09\u4e2a\u4e3b\u6d41AI\u804a\u5929\u4ea7\u54c1\u7684\u76f2\u6d4b\u4e2d\uff0c\u53ea\u6709OceanAI\u80fd\u63d0\u4f9b\u5e26\u6709\u539f\u59cb\u6570\u636e\u5f15\u7528\u7684\u6743\u5a01\u7b54\u6848\uff0c\u5176\u4ed6\u7cfb\u7edf\u8981\u4e48\u62d2\u7b54\u8981\u4e48\u7ed9\u51fa\u65e0\u652f\u6301\u7684\u6570\u636e\u3002", "conclusion": "OceanAI\u901a\u8fc7\u7ed3\u5408\u6743\u5a01\u6570\u636e\u5b9e\u73b0\u8f93\u51fa\u7684\u900f\u660e\u6027\u3001\u53ef\u590d\u73b0\u6027\u548c\u53ef\u4fe1\u8d56\u6027\uff0c\u63a8\u52a8\u4e86\u6d77\u6d0b\u9886\u57dfAI\u8f85\u52a9\u51b3\u7b56\u7684\u5e94\u7528\u4e0e\u6269\u5c55\u3002"}}
{"id": "2511.01046", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01046", "abs": "https://arxiv.org/abs/2511.01046", "authors": ["Vedant Acharya", "Abhay Pisharodi", "Rishabh Mondal", "Mohammad Rafiuddin", "Nipun Batra"], "title": "VayuChat: An LLM-Powered Conversational Interface for Air Quality Data Analytics", "comment": "4 Pages, 4 Figures", "summary": "Air pollution causes about 1.6 million premature deaths each year in India,\nyet decision makers struggle to turn dispersed data into decisions. Existing\ntools require expertise and provide static dashboards, leaving key policy\nquestions unresolved. We present VayuChat, a conversational system that answers\nnatural language questions on air quality, meteorology, and policy programs,\nand responds with both executable Python code and interactive visualizations.\nVayuChat integrates data from Central Pollution Control Board (CPCB) monitoring\nstations, state-level demographics, and National Clean Air Programme (NCAP)\nfunding records into a unified interface powered by large language models. Our\nlive demonstration will show how users can perform complex environmental\nanalytics through simple conversations, making data science accessible to\npolicymakers, researchers, and citizens. The platform is publicly deployed at\nhttps://huggingface.co/spaces/SustainabilityLabIITGN/ VayuChat. For further\ninformation check out video uploaded on\nhttps://www.youtube.com/watch?v=d6rklL05cs4.", "AI": {"tldr": "\u63d0\u51fa\u4e86VayuChat\uff0c\u4e00\u4e2a\u7ed3\u5408\u7a7a\u6c14\u8d28\u91cf\u3001\u6c14\u8c61\u548c\u653f\u7b56\u6570\u636e\u7684\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u4ea4\u4e92\u8f85\u52a9\u73af\u4fdd\u51b3\u7b56\u3002", "motivation": "\u5370\u5ea6\u7a7a\u6c14\u6c61\u67d3\u81f4\u6b7b\u7387\u9ad8\uff0c\u4f46\u51b3\u7b56\u8005\u96be\u4ee5\u4ece\u5206\u6563\u6570\u636e\u4e2d\u5feb\u901f\u83b7\u53d6\u6709\u7528\u4fe1\u606f\uff0c\u73b0\u6709\u5de5\u5177\u4e13\u4e1a\u95e8\u69db\u9ad8\u4e14\u9759\u6001\uff0c\u65e0\u6cd5\u6ee1\u8db3\u653f\u7b56\u5236\u5b9a\u9700\u6c42\u3002", "method": "\u5f00\u53d1\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684VayuChat\u5bf9\u8bdd\u7cfb\u7edf\uff0c\u96c6\u6210\u591a\u4e2a\u6570\u636e\u6e90\uff0c\u652f\u6301\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u56de\u7b54\uff0c\u8f93\u51faPython\u4ee3\u7801\u548c\u4ea4\u4e92\u5f0f\u53ef\u89c6\u5316\u3002", "result": "VayuChat\u80fd\u901a\u8fc7\u7b80\u4fbf\u5bf9\u8bdd\u5b8c\u6210\u590d\u6742\u73af\u5883\u6570\u636e\u5206\u6790\uff0c\u63d0\u9ad8\u6570\u636e\u79d1\u5b66\u53ef\u53ca\u6027\uff0c\u652f\u6301\u653f\u7b56\u5236\u5b9a\u548c\u516c\u4f17\u53c2\u4e0e\u3002\u8be5\u5e73\u53f0\u5df2\u516c\u5f00\u90e8\u7f72\uff0c\u65b9\u4fbf\u7528\u6237\u4f7f\u7528\u3002", "conclusion": "VayuChat\u5c55\u793a\u4e86\u5c06AI\u4e0e\u73af\u5883\u6570\u636e\u7ed3\u5408\uff0c\u4fc3\u8fdb\u73af\u4fdd\u653f\u7b56\u5236\u5b9a\u7684\u4fe1\u606f\u6280\u672f\u65b0\u65b9\u5411\uff0c\u5b9e\u73b0\u4e86\u7b80\u6613\u4ea4\u4e92\u4e0e\u590d\u6742\u5206\u6790\u7684\u6709\u673a\u7ed3\u5408\u3002"}}
{"id": "2511.01053", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01053", "abs": "https://arxiv.org/abs/2511.01053", "authors": ["Qing Ding", "Eric Hua Qing Zhang", "Felix Jozsa", "Julia Ive"], "title": "Building a Silver-Standard Dataset from NICE Guidelines for Clinical LLMs", "comment": "Submitted to EFMI Medical Informatics Europe 2026", "summary": "Large language models (LLMs) are increasingly used in healthcare, yet\nstandardised benchmarks for evaluating guideline-based clinical reasoning are\nmissing. This study introduces a validated dataset derived from publicly\navailable guidelines across multiple diagnoses. The dataset was created with\nthe help of GPT and contains realistic patient scenarios, as well as clinical\nquestions. We benchmark a range of recent popular LLMs to showcase the validity\nof our dataset. The framework supports systematic evaluation of LLMs' clinical\nutility and guideline adherence.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u516c\u5f00\u533b\u7597\u6307\u5357\u7684\u9a8c\u8bc1\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u589e\u591a\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u57fa\u4e8e\u6307\u5357\u7684\u4e34\u5e8a\u63a8\u7406\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u5229\u7528GPT\u534f\u52a9\u6784\u5efa\u5305\u542b\u771f\u5b9e\u60a3\u8005\u573a\u666f\u548c\u4e34\u5e8a\u95ee\u9898\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5bf9\u591a\u79cd\u6d41\u884cLLMs\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u9a8c\u8bc1\u6570\u636e\u96c6\u6709\u6548\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30LLMs\u7684\u4e34\u5e8a\u5b9e\u7528\u6027\u548c\u6307\u5357\u9075\u5b88\u60c5\u51b5\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u53ef\u63a8\u52a8LLMs\u5728\u533b\u7597\u9886\u57df\u7684\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u5e94\u7528\u3002"}}
{"id": "2511.01066", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01066", "abs": "https://arxiv.org/abs/2511.01066", "authors": ["Stephan Oepen", "Nikolay Arefev", "Mikko Aulamo", "Marta Ba\u00f1\u00f3n", "Maja Buljan", "Laurie Burchell", "Lucas Charpentier", "Pinzhen Chen", "Mariya Fedorova", "Ona de Gibert", "Barry Haddow", "Jan Haji\u010d", "Jindri\u010d Helcl", "Andrey Kutuzov", "Zihao Li", "Risto Luukkonen", "Bhavitvya Malik", "Vladislav Mikhailov", "Amanda Myntti", "Dayy\u00e1n O'Brien", "Lucie Pol\u00e1kov\u00e1", "Sampo Pyysalo", "Gema Ram\u00edrez S\u00e1nchez", "Janine Siewert", "Pavel Stepachev", "J\u00f6rg Tiedemann", "Teemu Vahtola", "Fedor Vitiugin", "Tea Vojt\u011bchov\u00e1", "Jaume Zaragoza"], "title": "HPLT~3.0: Very Large-Scale Multilingual Resources for LLM and MT. Mono- and Bi-lingual Data, Multilingual Evaluation, and Pre-Trained Models", "comment": null, "summary": "We present an ongoing initiative to provide open, very large, high-quality,\nand richly annotated textual datasets for almost 200 languages. At 30 trillion\ntokens, this is likely the largest generally available multilingual collection\nof LLM pre-training data. At 30 trillion tokens, this is likely the largest\ngenerally available multilingual collection of LLM pre-training data. These\ndatasets are derived from web crawls from different sources and accompanied\nwith a complete, open-source pipeline for document selection from web archives,\ntext extraction from HTML, language identification for noisy texts, exact and\nnear-deduplication, annotation with, among others, register labels, text\nquality estimates, and personally identifiable information; and final selection\nand filtering. We report on data quality probes through contrastive and\nanalytical statistics, through manual inspection of samples for 24 languages,\nand through end-to-end evaluation of various language model architectures\ntrained on this data. For multilingual LLM evaluation, we provide a\ncomprehensive collection of benchmarks for nine European languages, with\nspecial emphasis on natively created tasks, mechanisms to mitigate prompt\nsensitivity, and refined normalization and aggregation of scores. Additionally,\nwe train and evaluate a family of 57 monolingual encoder-decoder models, as\nwell as a handful of monolingual GPT-like reference models. Besides the\nmonolingual data and models, we also present a very large collection of\nparallel texts automatically mined from this data, together with a novel\nparallel corpus synthesized via machine translation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6db5\u76d6\u8fd1200\u79cd\u8bed\u8a00\u3001\u5305\u542b\u7ea630\u4e07\u4ebf\u6807\u6ce8\u4e30\u5bcc\u7684\u6587\u672c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\uff0c\u914d\u5907\u5f00\u653e\u6e90\u7801\u7684\u6570\u636e\u5904\u7406\u6d41\u6c34\u7ebf\uff0c\u5e76\u63d0\u4f9b\u591a\u8bed\u8a00\u8bc4\u6d4b\u57fa\u51c6\u548c\u591a\u79cd\u5355\u8bed\u53ca\u5e73\u884c\u8bed\u6599\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5927\u578b\u3001\u4f18\u8d28\u4e14\u8986\u76d6\u591a\u79cd\u8bed\u8a00\u7684\u516c\u5f00\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u9650\u5236\u4e86\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u591a\u6765\u6e90\u7f51\u9875\u6293\u53d6\u6784\u5efa\u5927\u89c4\u6a21\u591a\u8bed\u8a00\u8bed\u6599\uff0c\u7ed3\u5408\u5f00\u6e90\u6570\u636e\u5904\u7406\u6d41\u6c34\u7ebf\u5b9e\u73b0\u6587\u6863\u9009\u62e9\u3001\u8bed\u8a00\u8bc6\u522b\u3001\u53bb\u91cd\u548c\u591a\u7ef4\u5ea6\u6ce8\u91ca\uff0c\u540c\u65f6\u5f00\u5c55\u591a\u8bed\u8a00\u57fa\u51c6\u6d4b\u8bd5\u548c\u5355\u8bed\u6a21\u578b\u8bad\u7ec3\u3002", "result": "\u83b7\u5f97\u4e86\u6db5\u76d6200\u79cd\u8bed\u8a00\u768430\u4e07\u4ebf\u6807\u6ce8\u6587\u672c\u6570\u636e\uff0c\u9a8c\u8bc1\u4e86\u6570\u636e\u8d28\u91cf\u548c\u591a\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u53d1\u5e03\u4e86\u591a\u8bed\u8a00\u8bc4\u6d4b\u57fa\u51c6\u548c\u591a\u8bed\u79cd\u3001\u5355\u8bed\u79cd\u6a21\u578b\u6210\u679c\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u663e\u8457\u63a8\u52a8\u4e86\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u6570\u636e\u4e0e\u8bc4\u6d4b\u8d44\u6e90\u5efa\u8bbe\uff0c\u4e3a\u591a\u8bed\u8a00\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\u8bbe\u65bd\u548c\u5de5\u5177\u3002"}}
{"id": "2511.01090", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01090", "abs": "https://arxiv.org/abs/2511.01090", "authors": ["Vlad Negoita", "Mihai Masala", "Traian Rebedea"], "title": "Improving Romanian LLM Pretraining Data using Diversity and Quality Filtering", "comment": null, "summary": "Large Language Models (LLMs) have recently exploded in popularity, often\nmatching or outperforming human abilities on many tasks. One of the key factors\nin training LLMs is the availability and curation of high-quality data. Data\nquality is especially crucial for under-represented languages, where\nhigh-quality corpora are scarce. In this work we study the characteristics and\ncoverage of Romanian pretraining corpora and we examine how they differ from\nEnglish data. By training a lightweight multitask model on carefully\nLLM-annotated Romanian texts, we are able to analyze and perform multi-level\nfiltering (e.g., educational value, topic, format) to generate high-quality\npretraining datasets. Our experiments show noteworthy trends in the topics\npresent in Romanian and English data, while also proving the effectiveness of\nfiltering data through improved LLM pretraining performance across multiple\nbenchmarks.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u9884\u8bad\u7ec3\u8bed\u6599\u7684\u6570\u636e\u8d28\u91cf\uff0c\u5229\u7528\u591a\u4efb\u52a1\u6a21\u578b\u5bf9\u6570\u636e\u8fdb\u884c\u591a\u5c42\u6b21\u8fc7\u6ee4\u4ee5\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u6548\u679c\u3002", "motivation": "\u9ad8\u8d28\u91cf\u6570\u636e\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u81f3\u5173\u91cd\u8981\uff0c\u7279\u522b\u662f\u5bf9\u8d44\u6e90\u7a00\u7f3a\u7684\u8bed\u8a00\u5982\u7f57\u9a6c\u5c3c\u4e9a\u8bed\uff0c\u56e0\u6b64\u9700\u8981\u7814\u7a76\u548c\u4f18\u5316\u5176\u9884\u8bad\u7ec3\u8bed\u6599\u3002", "method": "\u5229\u7528\u8f7b\u91cf\u7ea7\u591a\u4efb\u52a1\u6a21\u578b\u5bf9\u7ecf\u5927\u8bed\u8a00\u6a21\u578b\u6ce8\u91ca\u7684\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u6587\u672c\u8fdb\u884c\u591a\u5c42\u6b21\u8fc7\u6ee4\uff0c\u5305\u62ec\u6559\u80b2\u4ef7\u503c\u3001\u4e3b\u9898\u548c\u683c\u5f0f\u7b49\u3002", "result": "\u53d1\u73b0\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u548c\u82f1\u8bed\u8bed\u6599\u5728\u4e3b\u9898\u4e0a\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u540c\u65f6\u591a\u5c42\u8fc7\u6ee4\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u591a\u4efb\u52a1\u6a21\u578b\u7684\u591a\u5c42\u8fc7\u6ee4\u65b9\u6cd5\uff0c\u53ef\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u9884\u8bad\u7ec3\u6570\u636e\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0a\u7684\u8bad\u7ec3\u6548\u679c\u3002"}}
{"id": "2511.01101", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01101", "abs": "https://arxiv.org/abs/2511.01101", "authors": ["Marek Strong", "Andreas Vlachos"], "title": "TSVer: A Benchmark for Fact Verification Against Time-Series Evidence", "comment": "Accepted to EMNLP 2025", "summary": "Reasoning over temporal and numerical data, such as time series, is a crucial\naspect of fact-checking. While many systems have recently been developed to\nhandle this form of evidence, their evaluation remains limited by existing\ndatasets, which often lack structured evidence, provide insufficient\njustifications for verdicts, or rely on synthetic claims. In this paper, we\nintroduce TSVer, a new benchmark dataset for fact verification focusing on\ntemporal and numerical reasoning with time-series evidence. TSVer contains 287\nreal-world claims sourced from 38 fact-checking organizations and a curated\ndatabase of 400 time series covering diverse domains. Each claim is annotated\nwith time frames across all pertinent time series, along with a verdict and\njustifications reflecting how the evidence is used to reach the verdict. Using\nan LLM-assisted multi-step annotation process, we improve the quality of our\nannotations and achieve an inter-annotator agreement of kappa=0.745 on\nverdicts. We also develop a baseline for verifying claims against time-series\nevidence and show that even the state-of-the-art reasoning models like\nGemini-2.5-Pro are challenged by time series, achieving a 63.37 accuracy score\non verdicts and an Ev2R score of 48.63 on verdict justifications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TSVer\u6570\u636e\u96c6\uff0c\u4e13\u6ce8\u4e8e\u65f6\u95f4\u5e8f\u5217\u7684\u65f6\u95f4\u548c\u6570\u503c\u63a8\u7406\u4e8b\u5b9e\u6838\u67e5\uff0c\u6570\u636e\u96c6\u5305\u542b\u771f\u5b9e\u4e16\u754c\u58f0\u660e\u548c\u6807\u6ce8\u7684\u65f6\u95f4\u5e8f\u5217\u8bc1\u636e\uff0c\u5e76\u901a\u8fc7\u591a\u6b65\u9aa4\u6ce8\u91ca\u4fdd\u8bc1\u8d28\u91cf\u3002\u57fa\u7ebf\u6a21\u578b\u5728\u8be5\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u6709\u9650\uff0c\u663e\u793a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u7684\u6311\u6218\u6027\u3002", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u5728\u5904\u7406\u65f6\u95f4\u5e8f\u5217\u8bc1\u636e\u65f6\uff0c\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u7f3a\u4e4f\u7ed3\u6784\u5316\u8bc1\u636e\u3001\u4e0d\u5145\u5206\u7684\u5224\u51b3\u7406\u7531\u6216\u4f9d\u8d56\u5408\u6210\u58f0\u660e\uff0c\u5f71\u54cd\u4e86\u8bc4\u4f30\u6548\u679c\u3002", "method": "\u6784\u5efaTSVer\u6570\u636e\u96c6\uff0c\u5305\u542b287\u6761\u771f\u5b9e\u58f0\u660e\u548c400\u4e2a\u591a\u9886\u57df\u65f6\u95f4\u5e8f\u5217\u8bc1\u636e\uff0c\u91c7\u7528LLM\u8f85\u52a9\u7684\u591a\u6b65\u9aa4\u6ce8\u91ca\u65b9\u6cd5\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\uff0c\u5e76\u8bbe\u8ba1\u57fa\u7ebf\u6a21\u578b\u7528\u4e8e\u9a8c\u8bc1\u65f6\u95f4\u5e8f\u5217\u4e8b\u5b9e\u6838\u67e5\u3002", "result": "TSVer\u6570\u636e\u96c6\u7684\u6807\u6ce8\u95f4\u4e00\u81f4\u6027\u8fbe\u5230kappa=0.745\uff0c\u57fa\u7ebf\u6a21\u578b\uff08\u5982Gemini-2.5-Pro\uff09\u5728\u5224\u51b3\u51c6\u786e\u7387\u4e3a63.37\uff0c\u5224\u51b3\u7406\u7531\u51c6\u786e\u5ea6Ev2R\u4e3a48.63\uff0c\u663e\u793a\u65f6\u95f4\u5e8f\u5217\u63a8\u7406\u6781\u5177\u6311\u6218\u3002", "conclusion": "TSVer\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u8d28\u91cf\u3001\u7ed3\u6784\u5316\u7684\u4e8b\u5b9e\u6838\u67e5\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u653b\u514b\u65f6\u95f4\u5e8f\u5217\u4e8b\u5b9e\u6838\u67e5\u96be\u9898\u3002"}}
{"id": "2511.01181", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01181", "abs": "https://arxiv.org/abs/2511.01181", "authors": ["Emaad Manzoor", "Eva Ascarza", "Oded Netzer"], "title": "Learning When to Quit in Sales Conversations", "comment": null, "summary": "Salespeople frequently face the dynamic screening decision of whether to\npersist in a conversation or abandon it to pursue the next lead. Yet, little is\nknown about how these decisions are made, whether they are efficient, or how to\nimprove them. We study these decisions in the context of high-volume outbound\nsales where leads are ample, but time is scarce and failure is common. We\nformalize the dynamic screening decision as an optimal stopping problem and\ndevelop a generative language model-based sequential decision agent - a\nstopping agent - that learns whether and when to quit conversations by\nimitating a retrospectively-inferred optimal stopping policy. Our approach\nhandles high-dimensional textual states, scales to large language models, and\nworks with both open-source and proprietary language models. When applied to\ncalls from a large European telecommunications firm, our stopping agent reduces\nthe time spent on failed calls by 54% while preserving nearly all sales;\nreallocating the time saved increases expected sales by up to 37%. Upon\nexamining the linguistic cues that drive salespeople's quitting decisions, we\nfind that they tend to overweight a few salient expressions of consumer\ndisinterest and mispredict call failure risk, suggesting cognitive bounds on\ntheir ability to make real-time conversational decisions. Our findings\nhighlight the potential of artificial intelligence algorithms to correct\ncognitively-bounded human decisions and improve salesforce efficiency.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u9500\u552e\u4eba\u5458\u5728\u9ad8\u9891\u5916\u547c\u9500\u552e\u4e2d\u51b3\u5b9a\u4f55\u65f6\u7ed3\u675f\u5bf9\u8bdd\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u5f0f\u8bed\u8a00\u6a21\u578b\u7684\u52a8\u6001\u505c\u6b62\u51b3\u7b56\u4ee3\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9500\u552e\u6548\u7387\u3002", "motivation": "\u9500\u552e\u4eba\u5458\u5728\u5bf9\u8bdd\u4e2d\u9762\u4e34\u662f\u5426\u7ee7\u7eed\u6216\u653e\u5f03\u5f53\u524d\u6f5c\u5728\u5ba2\u6237\u7684\u52a8\u6001\u7b5b\u9009\u51b3\u7b56\uff0c\u7136\u800c\u76f8\u5173\u51b3\u7b56\u6548\u7387\u53ca\u6539\u8fdb\u65b9\u6cd5\u5c1a\u4e0d\u6e05\u695a\uff0c\u9700\u8981\u6709\u6548\u6a21\u578b\u8f85\u52a9\u4f18\u5316\u65f6\u95f4\u4e0e\u9500\u552e\u6210\u679c\u7684\u6743\u8861\u3002", "method": "\u5c06\u52a8\u6001\u7b5b\u9009\u51b3\u7b56\u5f62\u5f0f\u5316\u4e3a\u6700\u4f18\u505c\u6b62\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u8bed\u8a00\u6a21\u578b\u7684\u987a\u5e8f\u51b3\u7b56\u4ee3\u7406\uff0c\u8be5\u4ee3\u7406\u901a\u8fc7\u6a21\u4eff\u56de\u6eaf\u63a8\u65ad\u7684\u6700\u4f18\u505c\u6b62\u7b56\u7565\u6765\u5b66\u4e60\u4f55\u65f6\u7ec8\u6b62\u5bf9\u8bdd\uff0c\u652f\u6301\u9ad8\u7ef4\u6587\u672c\u72b6\u6001\u5e76\u517c\u5bb9\u5f00\u6e90\u53ca\u4e13\u6709\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u4e00\u5bb6\u6b27\u6d32\u5927\u578b\u7535\u4fe1\u516c\u53f8\u7684\u901a\u8bdd\u6570\u636e\u4e0a\uff0c\u505c\u6b62\u4ee3\u7406\u5c06\u65e0\u6548\u901a\u8bdd\u65f6\u95f4\u51cf\u5c11\u4e8654%\uff0c\u51e0\u4e4e\u4fdd\u6301\u6240\u6709\u9500\u552e\u989d\u4e0d\u53d8\uff0c\u8282\u7701\u7684\u65f6\u95f4\u91cd\u65b0\u5206\u914d\u540e\u9500\u552e\u989d\u63d0\u5347\u4e86\u6700\u591a37%\u3002\u7814\u7a76\u53d1\u73b0\u9500\u552e\u4eba\u5458\u503e\u5411\u8fc7\u5ea6\u4f9d\u8d56\u5c11\u91cf\u660e\u663e\u8868\u793a\u6d88\u8d39\u8005\u4e0d\u611f\u5174\u8da3\u7684\u8bed\u8a00\u7ebf\u7d22\uff0c\u5bfc\u81f4\u5bf9\u901a\u8bdd\u5931\u8d25\u98ce\u9669\u7684\u8bef\u5224\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u7b97\u6cd5\u80fd\u7ea0\u6b63\u53d7\u8ba4\u77e5\u9650\u5236\u7684\u4eba\u5de5\u51b3\u7b56\uff0c\u63d0\u5347\u9500\u552e\u6548\u7387\uff0c\u5177\u5907\u663e\u8457\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2511.01187", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.01187", "abs": "https://arxiv.org/abs/2511.01187", "authors": ["Muhammed Saeed", "Muhammad Abdul-mageed", "Shady Shehata"], "title": "Surfacing Subtle Stereotypes: A Multilingual, Debate-Oriented Evaluation of Modern LLMs", "comment": null, "summary": "Large language models (LLMs) are widely deployed for open-ended\ncommunication, yet most bias evaluations still rely on English,\nclassification-style tasks. We introduce DebateBias-8K, a new multilingual,\ndebate-style benchmark designed to reveal how narrative bias appears in\nrealistic generative settings. Our dataset includes 8,400 structured debate\nprompts spanning four sensitive domains: women's rights, socioeconomic\ndevelopment, terrorism, and religion, across seven languages ranging from\nhigh-resource (English, Chinese) to low-resource (Swahili, Nigerian Pidgin).\nUsing four flagship models (GPT-4o, Claude 3, DeepSeek, and LLaMA 3), we\ngenerate and automatically classify over 100,000 responses. Results show that\nall models reproduce entrenched stereotypes despite safety alignment: Arabs are\noverwhelmingly linked to terrorism and religion (>=95%), Africans to\nsocioeconomic \"backwardness\" (up to <=77%), and Western groups are consistently\nframed as modern or progressive. Biases grow sharply in lower-resource\nlanguages, revealing that alignment trained primarily in English does not\ngeneralize globally. Our findings highlight a persistent divide in multilingual\nfairness: current alignment methods reduce explicit toxicity but fail to\nprevent biased outputs in open-ended contexts. We release our DebateBias-8K\nbenchmark and analysis framework to support the next generation of multilingual\nbias evaluation and safer, culturally inclusive model alignment.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u591a\u8bed\u79cd\u8fa9\u8bba\u5f0f\u504f\u89c1\u8bc4\u4f30\u57fa\u51c6DebateBias-8K\uff0c\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u3001\u5f00\u653e\u5f0f\u751f\u6210\u4e2d\u7684\u504f\u89c1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u504f\u89c1\u8bc4\u4f30\u591a\u4f9d\u8d56\u82f1\u8bed\u5206\u7c7b\u4efb\u52a1\uff0c\u7f3a\u4e4f\u591a\u8bed\u8a00\u3001\u771f\u5b9e\u751f\u6210\u73af\u5883\u4e2d\u7684\u504f\u89c1\u6d4b\u8bc4\u5de5\u5177\u3002", "method": "\u8bbe\u8ba1\u5305\u542b\u56db\u5927\u654f\u611f\u9886\u57df\u3001\u4e03\u79cd\u8bed\u8a00\u7684\u8fa9\u8bba\u5f0f\u63d0\u793a\uff0c\u5229\u7528\u56db\u6b3e\u5927\u578b\u6a21\u578b\u751f\u6210\u5e76\u81ea\u52a8\u5206\u7c7b\u8d8510\u4e07\u6761\u56de\u7b54\u3002", "result": "\u6240\u6709\u6a21\u578b\u5747\u8868\u73b0\u51fa\u6839\u6df1\u8482\u56fa\u7684\u523b\u677f\u5370\u8c61\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u504f\u89c1\u66f4\u660e\u663e\uff0c\u591a\u6570\u504f\u89c1\u4e0e\u8bad\u7ec3\u8bed\u8a00\u504f\u5dee\u76f8\u5173\u3002", "conclusion": "\u73b0\u6709\u6a21\u578b\u8c03\u4f18\u867d\u51cf\u5c11\u660e\u786e\u6709\u5bb3\u5185\u5bb9\uff0c\u5374\u672a\u80fd\u6d88\u9664\u5f00\u653e\u5f0f\u591a\u8bed\u8a00\u73af\u5883\u4e2d\u7684\u504f\u89c1\uff0c\u4e9f\u9700\u591a\u8bed\u79cd\u516c\u5e73\u6027\u8bc4\u4f30\u53ca\u6587\u5316\u5305\u5bb9\u7684\u6a21\u578b\u6821\u51c6\u65b9\u6cd5\u3002"}}
{"id": "2511.01188", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01188", "abs": "https://arxiv.org/abs/2511.01188", "authors": ["Lvhua Wu", "Xuefeng Jiang", "Sheng Sun", "Tian Wen", "Yuwei Wang", "Min Liu"], "title": "ZoFia: Zero-Shot Fake News Detection with Entity-Guided Retrieval and Multi-LLM Interaction", "comment": null, "summary": "The rapid spread of fake news threatens social stability and public trust,\nrendering its detection an imperative research priority. Although large\nlanguage models (LLMs) excel at numerous natural language processing tasks with\ntheir remarkable contextual understanding and extensive prior knowledge, the\ntime-bounded knowledge coverage and tendency for generating hallucination\ncontent reduce their reliability when handling fast-evolving news streams.\nFurthermore, models trained on existing static datasets also often lack the\ngeneralization needed for emerging news topics. To address these challenges, we\npropose ZoFia, a novel two-stage zero-shot fake news detection framework.\nFirst, we introduce Hierarchical Salience to quantify the importance of\nentities in the news content, and propose the SC-MMR algorithm to effectively\nselect an informative and diverse set of keywords that serve as queries for\nretrieving up-to-date external evidence. Subsequently, a multi LLM interactive\nsystem, in which each agent assumes a distinct role, performs multi-view\ncollaborative analysis and adversarial debate over the news text and its\nrelated information, and finally produces an interpretable and robust judgment.\nComprehensive experiments on two public datasets demonstrate that ZoFia\nobviously outperforms existing zero-shot baselines and most of few-shot\nmethods. Our codes will be open-sourced to facilitate related communities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aZoFia\u7684\u4e24\u9636\u6bb5\u96f6\u6837\u672c\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u89c6\u89d2\u591a\u6a21\u578b\u534f\u4f5c\u53ca\u5916\u90e8\u52a8\u6001\u8bc1\u636e\u68c0\u7d22\u5b9e\u73b0\u5bf9\u5047\u65b0\u95fb\u7684\u51c6\u786e\u8bc6\u522b\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u77e5\u8bc6\u65f6\u6548\u6027\u9650\u5236\u548c\u5e7b\u89c9\u751f\u6210\u95ee\u9898\uff0c\u5728\u5904\u7406\u5feb\u901f\u53d8\u5316\u7684\u65b0\u95fb\u65f6\u8868\u73b0\u4e0d\u4f73\uff1b\u9759\u6001\u6570\u636e\u8bad\u7ec3\u6a21\u578b\u4e5f\u96be\u4ee5\u6cdb\u5316\u5230\u65b0\u5174\u65b0\u95fb\u4e3b\u9898\uff0c\u5bfc\u81f4\u5047\u65b0\u95fb\u68c0\u6d4b\u7684\u6548\u679c\u53d7\u9650\u3002", "method": "\u8be5\u65b9\u6cd5\u9996\u5148\u901a\u8fc7\u5c42\u6b21\u663e\u8457\u6027\u5ea6\u91cf\u65b0\u95fb\u5b9e\u4f53\u7684\u91cd\u8981\u6027\uff0c\u5e76\u8bbe\u8ba1SC-MMR\u7b97\u6cd5\u9009\u62e9\u591a\u6837\u4e14\u4fe1\u606f\u4e30\u5bcc\u7684\u5173\u952e\u8bcd\uff0c\u7528\u4e8e\u68c0\u7d22\u6700\u65b0\u7684\u5916\u90e8\u8bc1\u636e\u3002\u5176\u6b21\uff0c\u6784\u5efa\u591a\u5927\u8bed\u8a00\u6a21\u578b\u4ea4\u4e92\u7cfb\u7edf\uff0c\u5404\u6a21\u578b\u626e\u6f14\u4e0d\u540c\u89d2\u8272\uff0c\u8fdb\u884c\u534f\u540c\u5206\u6790\u4e0e\u5bf9\u6297\u8fa9\u8bba\uff0c\u6700\u7ec8\u7ed9\u51fa\u53ef\u89e3\u91ca\u4e14\u9c81\u68d2\u7684\u5224\u65ad\u7ed3\u679c\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u5168\u9762\u5b9e\u9a8c\u8868\u660e\uff0cZoFia\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u96f6\u6837\u672c\u57fa\u7ebf\u65b9\u6cd5\u53ca\u591a\u6570\u5c11\u6837\u672c\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u7ed3\u5408\u52a8\u6001\u5916\u90e8\u8bc1\u636e\u68c0\u7d22\u548c\u591a\u6a21\u578b\u534f\u4f5c\u673a\u5236\u7684\u96f6\u6837\u672c\u5047\u65b0\u95fb\u68c0\u6d4b\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u63d0\u5347\u4e86\u5047\u65b0\u95fb\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u76f8\u5173\u793e\u533a\u7684\u7814\u7a76\u4e0e\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2511.01191", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01191", "abs": "https://arxiv.org/abs/2511.01191", "authors": ["Ru Wang", "Wei Huang", "Qi Cao", "Yusuke Iwasawa", "Yutaka Matsuo", "Jiaxian Guo"], "title": "Self-Harmony: Learning to Harmonize Self-Supervision and Self-Play in Test-Time Reinforcement Learning", "comment": null, "summary": "Test-time reinforcement learning (TTRL) offers a label-free paradigm for\nadapting models using only synthetic signals at inference, but its success\nhinges on constructing reliable learning signals. Standard approaches such as\nmajority voting often collapse to spurious yet popular answers. We introduce\nSelf-Harmony, a framework built on a simple intuition: the correct answer\nshould remain stable across both an original question and its paraphrase.\nSelf-Harmony operationalizes this by employing a single model in two\ncomplementary roles: a Solver to produce answers and a Reframer to rephrase the\ninput. Based on this, we further propose a pseudo-label method: instead of\nmajority voting, it aggregates answer frequencies across these original and\nreframed views using the harmonic mean. This is a process that naturally\nselects for solutions stable under reframing, thereby avoiding the common trap\nof favoring view-dependent, spurious answers. Crucially, this requires no human\nsupervision or auxiliary models. Across diverse reasoning benchmarks,\nSelf-Harmony achieves state-of-the-art results at the label-free test-time\nsetting, ranking first in 28 of 30 settings across multiple methods. Beyond\naccuracy, it demonstrates unprecedented robustness, with zero training failures\nin all experiments, underscoring its stability and reliability.", "AI": {"tldr": "\u63d0\u51fa\u4e86Self-Harmony\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u539f\u59cb\u95ee\u9898\u53ca\u5176\u6539\u5199\u7248\u672c\u4e2d\u4fdd\u6301\u7b54\u6848\u7a33\u5b9a\u6027\uff0c\u4ee5\u65e0\u6807\u7b7e\u7684\u65b9\u5f0f\u5728\u63a8\u7406\u65f6\u81ea\u9002\u5e94\u6a21\u578b\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6295\u7968\u6cd5\u7684\u9677\u9631\u3002", "motivation": "\u73b0\u6709\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u53ef\u9760\u7684\u5b66\u4e60\u4fe1\u53f7\uff0c\u4f46\u591a\u6570\u6295\u7968\u6cd5\u5e38\u9677\u5165\u8868\u9762\u6d41\u884c\u4f46\u9519\u8bef\u7684\u7b54\u6848\uff0c\u4ece\u800c\u5f71\u54cd\u81ea\u9002\u5e94\u6548\u679c\u3002", "method": "Self-Harmony\u5229\u7528\u5355\u4e00\u6a21\u578b\u5728\u4e24\u4e2a\u89d2\u8272\uff08\u89e3\u7b54\u8005\u4e0e\u6539\u5199\u8005\uff09\u95f4\u5207\u6362\uff0c\u901a\u8fc7\u8ba1\u7b97\u539f\u59cb\u95ee\u9898\u548c\u6539\u5199\u95ee\u9898\u7b54\u6848\u9891\u7387\u7684\u8c03\u548c\u5e73\u5747\u503c\u6765\u751f\u6210\u4f2a\u6807\u7b7e\uff0c\u9009\u62e9\u5bf9\u6539\u5199\u5177\u6709\u7a33\u5b9a\u6027\u7684\u7b54\u6848\uff0c\u65e0\u9700\u4eba\u5de5\u76d1\u7763\u6216\u8f85\u52a9\u6a21\u578b\u3002", "result": "\u5728\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSelf-Harmony\u83b7\u5f97\u4e86\u65e0\u6807\u7b7e\u6d4b\u8bd5\u65f6\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u572830\u4e2a\u8bbe\u7f6e\u4e2d\u6392\u540d\u7b2c\u4e00\u8fbe28\u6b21\uff0c\u8868\u73b0\u51fa\u6781\u9ad8\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u6240\u6709\u5b9e\u9a8c\u5747\u672a\u51fa\u73b0\u8bad\u7ec3\u5931\u8d25\u3002", "conclusion": "Self-Harmony\u662f\u4e00\u79cd\u7a33\u5b9a\u53ef\u9760\u7684\u65e0\u76d1\u7763\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fdd\u6301\u7b54\u6848\u5728\u6539\u5199\u95f4\u4e00\u81f4\uff0c\u6709\u6548\u907f\u514d\u4e86\u89c6\u89d2\u4f9d\u8d56\u7684\u9519\u8bef\u7b54\u6848\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u548c\u7a33\u5b9a\u6027\u7684\u53cc\u91cd\u63d0\u5347\u3002"}}
{"id": "2511.01192", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01192", "abs": "https://arxiv.org/abs/2511.01192", "authors": ["Guoxin Ma", "Xiaoming Liu", "Zhanhan Zhang", "Chengzhengxu Li", "Shengchao Liu", "Yu Lan"], "title": "DEER: Disentangled Mixture of Experts with Instance-Adaptive Routing for Generalizable Machine-Generated Text Detection", "comment": "Under Review", "summary": "Detecting machine-generated text (MGT) has emerged as a critical challenge,\ndriven by the rapid advancement of large language models (LLMs) capable of\nproducing highly realistic, human-like content. However, the performance of\ncurrent approaches often degrades significantly under domain shift. To address\nthis challenge, we propose a novel framework designed to capture both\ndomain-specific and domain-general MGT patterns through a two-stage\nDisentangled mixturE-of-ExpeRts (DEER) architecture. First, we introduce a\ndisentangled mixture-of-experts module, in which domain-specific experts learn\nfine-grained, domain-local distinctions between human and machine-generated\ntext, while shared experts extract transferable, cross-domain features. Second,\nto mitigate the practical limitation of unavailable domain labels during\ninference, we design a reinforcement learning-based routing mechanism that\ndynamically selects the appropriate experts for each input instance,\neffectively bridging the train-inference gap caused by domain uncertainty.\nExtensive experiments on five in-domain and five out-of-domain benchmark\ndatasets demonstrate that DEER consistently outperforms state-of-the-art\nmethods, achieving average F1-score improvements of 1.39% and 5.32% on\nin-domain and out-of-domain datasets respectively, along with accuracy gains of\n1.35% and 3.61% respectively. Ablation studies confirm the critical\ncontributions of both disentangled expert specialization and adaptive routing\nto model performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDEER\u7684\u4e24\u9636\u6bb5\u89e3\u8026\u6df7\u5408\u4e13\u5bb6\u67b6\u6784\uff0c\u7528\u4e8e\u63d0\u5347\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u8de8\u57df\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u65b9\u6cd5\u5728\u9886\u57df\u8fc1\u79fb\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u89e3\u51b3\u4e0d\u540c\u9886\u57df\u95f4\u7684\u7279\u5f81\u8f6c\u79fb\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86\u89e3\u8026\u6df7\u5408\u4e13\u5bb6\u6a21\u5757\uff0c\u533a\u5206\u9886\u57df\u4e13\u5bb6\u548c\u5171\u4eab\u4e13\u5bb6\uff0c\u7528\u4ee5\u6355\u83b7\u9886\u57df\u7279\u5b9a\u548c\u901a\u7528\u7279\u5f81\uff1b\u5e76\u5229\u7528\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u8def\u7531\u673a\u5236\u52a8\u6001\u9009\u62e9\u4e13\u5bb6\uff0c\u89e3\u51b3\u63a8\u7406\u65f6\u7f3a\u5c11\u9886\u57df\u6807\u7b7e\u7684\u95ee\u9898\u3002", "result": "\u5728\u4e94\u4e2a\u57df\u5185\u548c\u4e94\u4e2a\u57df\u5916\u6570\u636e\u96c6\u4e0a\uff0cDEER\u5728F1\u5206\u6570\u548c\u51c6\u786e\u7387\u65b9\u9762\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u57df\u5916\u63d0\u5347\u5c24\u4e3a\u660e\u663e\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u89e3\u8026\u4e13\u5bb6\u548c\u81ea\u9002\u5e94\u8def\u7531\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "DEER\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u673a\u5668\u751f\u6210\u6587\u672c\u68c0\u6d4b\u7684\u8de8\u57df\u80fd\u529b\uff0c\u4e3a\u5e94\u5bf9\u9886\u57df\u4e0d\u786e\u5b9a\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002"}}
{"id": "2511.01265", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01265", "abs": "https://arxiv.org/abs/2511.01265", "authors": ["Mo El-Haj", "Paul Rayson"], "title": "AraFinNews: Arabic Financial Summarisation with Domain-Adapted LLMs", "comment": "10 pages", "summary": "This paper investigates the impact of domain specificity on abstractive\nsummarisation of Arabic financial texts using large language models (LLMs). We\nintroduce AraFinNews, the largest publicly available Arabic financial news\ndataset to date, comprising 212,500 article--headline pairs spanning nearly a\ndecade of reporting from October 2015 to July 2025. Designed as the Arabic\nequivalent of major English summarisation corpora such as CNN/DailyMail,\nAraFinNews provides a robust benchmark for evaluating domain-specific language\nunderstanding and generation in financial contexts. Using this resource, we\nevaluate transformer-based models -- including mT5, AraT5, and the\ndomain-adapted FinAraT5 -- to examine how financial-domain pretraining\ninfluences factual accuracy, numerical reliability, and stylistic alignment\nwith professional reporting. Experimental results show that domain-adapted\nmodels generate more faithful and coherent summaries, particularly in handling\nquantitative and entity-centric information. The findings highlight the\nimportance of domain-specific adaptation for improving factual consistency and\nnarrative fluency in Arabic financial summarisation. The dataset is freely\navailable for non-commercial research at\nhttps://github.com/ArabicNLP-UK/AraFinNews.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u6700\u5927\u89c4\u6a21\u7684\u963f\u62c9\u4f2f\u8bed\u91d1\u878d\u65b0\u95fb\u6458\u8981\u6570\u636e\u96c6AraFinNews\uff0c\u5e76\u5229\u7528\u8be5\u6570\u636e\u96c6\u8bc4\u4f30\u4e86\u591a\u79cd\u57fa\u4e8etransformer\u7684\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u9886\u57df\u6458\u8981\u751f\u6210\u7684\u8868\u73b0\u3002", "motivation": "\u7814\u7a76\u9886\u57df\u7279\u5b9a\u9884\u8bad\u7ec3\u5bf9\u963f\u62c9\u4f2f\u8bed\u91d1\u878d\u65b0\u95fb\u62bd\u8c61\u6458\u8981\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u63d0\u9ad8\u6458\u8981\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u53d9\u4e8b\u6d41\u7545\u6027\u3002", "method": "\u6536\u96c6\u5e76\u6784\u5efa\u5305\u542b212,500\u6761\u963f\u62c9\u4f2f\u8bed\u91d1\u878d\u65b0\u95fb\u53ca\u5176\u6807\u9898\u7684\u6570\u636e\u96c6AraFinNews\uff0c\u57fa\u4e8e\u8be5\u6570\u636e\u96c6\u8bc4\u4f30mT5\u3001AraT5\u53ca\u9886\u57df\u9002\u5e94\u6a21\u578bFinAraT5\u7684\u6458\u8981\u751f\u6210\u8d28\u91cf\u3002", "result": "\u9886\u57df\u9002\u5e94\u7684FinAraT5\u6a21\u578b\u5728\u751f\u6210\u6458\u8981\u65f6\uff0c\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u6570\u5b57\u53ef\u9760\u6027\u53ca\u98ce\u683c\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5b9a\u91cf\u4fe1\u606f\u548c\u5b9e\u4f53\u76f8\u5173\u5185\u5bb9\u65f6\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u9886\u57df\u7279\u5b9a\u7684\u9884\u8bad\u7ec3\u80fd\u663e\u8457\u63d0\u5347\u963f\u62c9\u4f2f\u8bed\u91d1\u878d\u65b0\u95fb\u6458\u8981\u7684\u4e8b\u5b9e\u4e00\u81f4\u6027\u548c\u53d9\u8ff0\u6d41\u7545\u6027\uff0c\u5f3a\u8c03\u4e86\u91d1\u878d\u9886\u57df\u9002\u5e94\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.01282", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01282", "abs": "https://arxiv.org/abs/2511.01282", "authors": ["Min Fang", "Zhihui Fu", "Qibin Zhao", "Jun Wang"], "title": "When, What, and How: Rethinking Retrieval-Enhanced Speculative Decoding", "comment": null, "summary": "Speculative decoding (SD) has emerged as an effective technique to accelerate\nlarge language model (LLM) inference without compromising output quality.\nHowever, the achievable speedup largely depends on the effectiveness of the\ndrafting model. While model-based methods like EAGLE-2 are accurate but costly,\nretrieval-enhanced methods like SAM-Decoding rely on heuristic switching\nstrategies that often trigger unnecessary retrievals. To address this, we\npropose ReSpec (\\textbf{Re}trieval-enhanced \\textbf{Spe}culative Decoding), a\nnovel framework that transforms heuristic drafter switching into adaptive\ndecision-making. ReSpec features three core innovations: 1) An\n\\textbf{entropy-guided adaptive trigger} quantifies contextual predictability\nto initiate retrieval only when uncertainty is low, avoiding costly low-quality\nspeculations. 2) A \\textbf{feedback-driven candidate selection} leverages\nhistorical feedback to organize multiple high-quality candidates for parallel\nverification, maximizing retrieval utility. 3) A source-aware \\textbf{relaxed\nverification strategy} applies strict checks to model-generated drafts while\nusing a relaxed verification for retrieved drafts, achieving a better balance\nbetween accuracy and efficiency. Extensive experiments on Spec-Bench\ndemonstrate that ReSpec achieves state-of-the-art acceleration,outperforming\nEAGLE-2 and SAM-Decoding by over $33\\%$ and $25\\%$, respectively, while\nmaintaining output quality.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ReSpec\uff0c\u4e00\u79cd\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u7684\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u89e6\u53d1\u3001\u53cd\u9988\u9a71\u52a8\u5019\u9009\u9009\u62e9\u548c\u6e90\u611f\u77e5\u677e\u5f1b\u9a8c\u8bc1\u7b56\u7565\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u8bc1\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u6d4b\u89e3\u7801\u65b9\u6cd5\u53d7\u9650\u4e8e\u8349\u7a3f\u6a21\u578b\u7684\u6709\u6548\u6027\uff0c\u6a21\u578b\u57fa\u65b9\u6cd5\u51c6\u786e\u4f46\u6210\u672c\u9ad8\uff0c\u800c\u68c0\u7d22\u589e\u5f3a\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u5207\u6362\uff0c\u5e38\u89e6\u53d1\u4e0d\u5fc5\u8981\u7684\u68c0\u7d22\uff0c\u5f71\u54cd\u6548\u7387\u3002", "method": "ReSpec\u901a\u8fc7\u71b5\u5f15\u5bfc\u7684\u81ea\u9002\u5e94\u89e6\u53d1\u51cf\u5c11\u4e0d\u5fc5\u8981\u68c0\u7d22\uff0c\u5229\u7528\u5386\u53f2\u53cd\u9988\u7ec4\u7ec7\u591a\u4e2a\u9ad8\u8d28\u91cf\u5019\u9009\u5e76\u884c\u9a8c\u8bc1\uff0c\u4e14\u91c7\u7528\u9488\u5bf9\u4e0d\u540c\u8349\u7a3f\u6e90\u91c7\u7528\u4e25\u683c\u6216\u677e\u5f1b\u7684\u9a8c\u8bc1\u7b56\u7565\uff0c\u5e73\u8861\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "result": "\u5728Spec-Bench\u5927\u89c4\u6a21\u5b9e\u9a8c\u4e2d\uff0cReSpec\u5728\u4fdd\u6301\u8f93\u51fa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u63a8\u7406\u52a0\u901f\u5206\u522b\u8d85\u8fc7\u4e86EAGLE-2\u548cSAM-Decoding 33%\u548c25%\u3002", "conclusion": "ReSpec\u6846\u67b6\u6709\u6548\u63d0\u5347\u63a8\u6d4b\u89e3\u7801\u7684\u52a0\u901f\u6548\u679c\uff0c\u4e14\u80fd\u5e73\u8861\u63a8\u7406\u901f\u5ea6\u4e0e\u8f93\u51fa\u8d28\u91cf\uff0c\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2511.01287", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.01287", "abs": "https://arxiv.org/abs/2511.01287", "authors": ["Qin Zhou", "Zhexin Zhang", "Zhi Li", "Limin Sun"], "title": "\"Give a Positive Review Only\": An Early Investigation Into In-Paper Prompt Injection Attacks and Defenses for AI Reviewers", "comment": null, "summary": "With the rapid advancement of AI models, their deployment across diverse\ntasks has become increasingly widespread. A notable emerging application is\nleveraging AI models to assist in reviewing scientific papers. However, recent\nreports have revealed that some papers contain hidden, injected prompts\ndesigned to manipulate AI reviewers into providing overly favorable\nevaluations. In this work, we present an early systematic investigation into\nthis emerging threat. We propose two classes of attacks: (1) static attack,\nwhich employs a fixed injection prompt, and (2) iterative attack, which\noptimizes the injection prompt against a simulated reviewer model to maximize\nits effectiveness. Both attacks achieve striking performance, frequently\ninducing full evaluation scores when targeting frontier AI reviewers.\nFurthermore, we show that these attacks are robust across various settings. To\ncounter this threat, we explore a simple detection-based defense. While it\nsubstantially reduces the attack success rate, we demonstrate that an adaptive\nattacker can partially circumvent this defense. Our findings underscore the\nneed for greater attention and rigorous safeguards against prompt-injection\nthreats in AI-assisted peer review.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u9488\u5bf9AI\u8f85\u52a9\u79d1\u5b66\u8bba\u6587\u8bc4\u5ba1\u7684\u6ce8\u5165\u578b\u653b\u51fb\uff0c\u63d0\u51fa\u9759\u6001\u548c\u8fed\u4ee3\u4e24\u7c7b\u653b\u51fb\u65b9\u6cd5\uff0c\u5747\u80fd\u663e\u8457\u64cd\u63a7AI\u8bc4\u5206\uff0c\u4e14\u653b\u51fb\u5728\u591a\u79cd\u73af\u5883\u4e0b\u5747\u5177\u9c81\u68d2\u6027\u3002\u63d0\u51fa\u7b80\u5355\u68c0\u6d4b\u9632\u5fa1\u65b9\u6cd5\uff0c\u4f46\u653b\u51fb\u8005\u53ef\u90e8\u5206\u7ed5\u8fc7\u3002", "motivation": "\u968f\u7740AI\u6a21\u578b\u5728\u79d1\u7814\u8bc4\u5ba1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5b58\u5728\u901a\u8fc7\u9690\u85cf\u6ce8\u5165\u63d0\u793a\u64cd\u63a7AI\u8bc4\u5ba1\u8bc4\u5206\u7684\u6f5c\u5728\u5a01\u80c1\uff0c\u4e9f\u9700\u7cfb\u7edf\u7814\u7a76\u4e0e\u9632\u8303\u3002", "method": "\u63d0\u51fa\u9759\u6001\u6ce8\u5165\u653b\u51fb\u548c\u8fed\u4ee3\u6ce8\u5165\u653b\u51fb\uff0c\u524d\u8005\u4f7f\u7528\u56fa\u5b9a\u6ce8\u5165\u63d0\u793a\uff0c\u540e\u8005\u5728\u6a21\u62df\u8bc4\u5ba1\u6a21\u578b\u4e0a\u4f18\u5316\u6ce8\u5165\u63d0\u793a\u4ee5\u6700\u5927\u5316\u653b\u51fb\u6548\u679c\u3002\u5e76\u8bbe\u8ba1\u68c0\u6d4b\u673a\u5236\u8fdb\u884c\u9632\u5fa1\u3002", "result": "\u4e24\u7c7b\u653b\u51fb\u5747\u80fd\u8bf1\u5bfcAI\u8bc4\u5ba1\u7ed9\u51fa\u6781\u9ad8\u8bc4\u5206\uff0c\u4e14\u653b\u51fb\u6548\u679c\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e2d\u8868\u73b0\u9c81\u68d2\u3002\u68c0\u6d4b\u9632\u5fa1\u80fd\u663e\u8457\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u4f46\u590d\u6742\u653b\u51fb\u4ecd\u53ef\u90e8\u5206\u7ed5\u8fc7\u3002", "conclusion": "\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5bf9AI\u8f85\u52a9\u8bba\u6587\u8bc4\u5ba1\u6784\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u52a0\u5f3a\u5173\u6ce8\u548c\u4e25\u683c\u9632\u62a4\u63aa\u65bd\uff0c\u786e\u4fdd\u8bc4\u5ba1\u7cfb\u7edf\u7684\u516c\u6b63\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2511.01289", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01289", "abs": "https://arxiv.org/abs/2511.01289", "authors": ["Saiyma Sittul Muna", "Rezwan Islam Salvi", "Mushfiqur Rahman Mushfique", "Ajwad Abrar"], "title": "FirstAidQA: A Synthetic Dataset for First Aid and Emergency Response in Low-Connectivity Settings", "comment": "Accepted at the 5th Muslims in Machine Learning (MusIML) Workshop,\n  co-located with NeurIPS 2025", "summary": "In emergency situations, every second counts. The deployment of Large\nLanguage Models (LLMs) in time-sensitive, low or zero-connectivity environments\nremains limited. Current models are computationally intensive and unsuitable\nfor low-tier devices often used by first responders or civilians. A major\nbarrier to developing lightweight, domain-specific solutions is the lack of\nhigh-quality datasets tailored to first aid and emergency response. To address\nthis gap, we introduce FirstAidQA, a synthetic dataset containing 5,500\nhigh-quality question answer pairs that encompass a wide range of first aid and\nemergency response scenarios. The dataset was generated using a Large Language\nModel, ChatGPT-4o-mini, with prompt-based in-context learning, using texts from\nthe Vital First Aid Book (2019). We applied preprocessing steps such as text\ncleaning, contextual chunking, and filtering, followed by human validation to\nensure accuracy, safety, and practical relevance of the QA pairs. FirstAidQA is\ndesigned to support instruction-tuning and fine-tuning of LLMs and Small\nLanguage Models (SLMs), enabling faster, more reliable, and offline-capable\nsystems for emergency settings. We publicly release the dataset to advance\nresearch on safety-critical and resource-constrained AI applications in first\naid and emergency response. The dataset is available on Hugging Face at\nhttps://huggingface.co/datasets/i-am-mushfiq/FirstAidQA.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86FirstAidQA\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b5500\u6761\u6025\u6551\u95ee\u7b54\u5bf9\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u65e8\u5728\u652f\u6301\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u5728\u7d27\u6025\u6551\u63f4\u73af\u5883\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u9ad8\uff0c\u4e0d\u9002\u5408\u6025\u6551\u73b0\u573a\u5e38\u7528\u7684\u4f4e\u7aef\u8bbe\u5907\uff0c\u4e14\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u6025\u6551\u9886\u57df\u6570\u636e\u96c6\u5236\u7ea6\u4e86\u6b64\u7c7b\u8f7b\u91cf\u6a21\u578b\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528ChatGPT-4o-mini\u6a21\u578b\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u751f\u6210\u521d\u59cb\u95ee\u7b54\u5bf9\uff0c\u5229\u7528\u300a\u91cd\u8981\u6025\u6551\u624b\u518c\u300b\u6587\u672c\u8fdb\u884c\u8bad\u7ec3\uff0c\u968f\u540e\u901a\u8fc7\u6587\u672c\u6e05\u6d17\u3001\u4e0a\u4e0b\u6587\u5207\u5206\u3001\u8fc7\u6ee4\u53ca\u4eba\u5de5\u9a8c\u8bc1\u4fdd\u8bc1\u6570\u636e\u8d28\u91cf\u548c\u5b89\u5168\u6027\u3002", "result": "\u751f\u6210\u4e865500\u6761\u9ad8\u8d28\u91cf\u6025\u6551\u95ee\u7b54\u5bf9\u6570\u636e\u96c6FirstAidQA\uff0c\u8be5\u6570\u636e\u96c6\u8986\u76d6\u5e7f\u6cdb\u6025\u6551\u548c\u5e94\u6025\u54cd\u5e94\u573a\u666f\uff0c\u652f\u6301\u6a21\u578b\u7684\u6307\u4ee4\u5fae\u8c03\u53ca\u79bb\u7ebf\u8fd0\u884c\uff0c\u63d0\u9ad8\u6a21\u578b\u54cd\u5e94\u901f\u5ea6\u548c\u53ef\u9760\u6027\u3002", "conclusion": "FirstAidQA\u6570\u636e\u96c6\u6709\u6548\u586b\u8865\u4e86\u6025\u6551\u9886\u57df\u8f7b\u91cf\u7ea7\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u6570\u636e\u7684\u7a7a\u767d\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u7d27\u6025\u60c5\u51b5\u4e0b\u8d44\u6e90\u53d7\u9650\u7684AI\u5e94\u7528\u7684\u7814\u7a76\u548c\u53d1\u5c55\uff0c\u5e76\u5df2\u516c\u5f00\u53d1\u5e03\u4ee5\u4f9b\u793e\u533a\u4f7f\u7528\u3002"}}
{"id": "2511.01305", "categories": ["cs.CL", "cs.AI", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.01305", "abs": "https://arxiv.org/abs/2511.01305", "authors": ["Aman Ganapathy Manvattira", "Yifei Xu", "Ziyue Dang", "Songwu Lu"], "title": "DeepSpecs: Expert-Level Questions Answering in 5G", "comment": null, "summary": "5G technology enables mobile Internet access for billions of users. Answering\nexpert-level questions about 5G specifications requires navigating thousands of\npages of cross-referenced standards that evolve across releases. Existing\nretrieval-augmented generation (RAG) frameworks, including telecom-specific\napproaches, rely on semantic similarity and cannot reliably resolve\ncross-references or reason about specification evolution. We present DeepSpecs,\na RAG system enhanced by structural and temporal reasoning via three\nmetadata-rich databases: SpecDB (clause-aligned specification text), ChangeDB\n(line-level version diffs), and TDocDB (standardization meeting documents).\nDeepSpecs explicitly resolves cross-references by recursively retrieving\nreferenced clauses through metadata lookup, and traces specification evolution\nby mining changes and linking them to Change Requests that document design\nrationale. We curate two 5G QA datasets: 573 expert-annotated real-world\nquestions from practitioner forums and educational resources, and 350\nevolution-focused questions derived from approved Change Requests. Across\nmultiple LLM backends, DeepSpecs outperforms base models and state-of-the-art\ntelecom RAG systems; ablations confirm that explicit cross-reference resolution\nand evolution-aware retrieval substantially improve answer quality,\nunderscoring the value of modeling the structural and temporal properties of 5G\nstandards.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DeepSpecs\uff0c\u4e00\u4e2a\u589e\u5f3a\u7ed3\u6784\u548c\u65f6\u95f4\u63a8\u7406\u80fd\u529b\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\uff0c\u7528\u4e8e\u89e3\u7b54\u590d\u6742\u76845G\u89c4\u683c\u95ee\u9898\u3002", "motivation": "5G\u6807\u51c6\u5185\u5bb9\u5e9e\u6742\u4e14\u8de8\u7248\u672c\u6f14\u53d8\uff0c\u73b0\u6709\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u6027\u7684\u68c0\u7d22\u751f\u6210\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u89e3\u6790\u8de8\u5f15\u7528\u548c\u89c4\u8303\u6f14\u8fdb\u95ee\u9898\u3002", "method": "DeepSpecs\u5229\u7528\u4e09\u4e2a\u5143\u6570\u636e\u4e30\u5bcc\u7684\u6570\u636e\u5e93\uff08\u89c4\u683c\u6587\u672c\u3001\u7248\u672c\u5dee\u5f02\u548c\u4f1a\u8bae\u6587\u6863\uff09\uff0c\u901a\u8fc7\u9012\u5f52\u68c0\u7d22\u548c\u5143\u6570\u636e\u67e5\u627e\u663e\u5f0f\u89e3\u6790\u8de8\u5f15\u7528\uff0c\u5e76\u8ffd\u8e2a\u7248\u672c\u6f14\u8fdb\u4ee5\u53ca\u5173\u8054\u53d8\u66f4\u8bf7\u6c42\u3002", "result": "\u6784\u5efa\u4e86\u4e24\u59575G\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660eDeepSpecs\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u57fa\u7840\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u53ca\u73b0\u6709\u7535\u4fe1\u9886\u57dfRAG\u7cfb\u7edf\uff0c\u5220\u9664\u5173\u952e\u6a21\u5757\u4f1a\u964d\u4f4e\u7b54\u6848\u8d28\u91cf\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u5316\u548c\u65f6\u95f4\u4fe1\u606f\uff0cDeepSpecs\u663e\u8457\u63d0\u5347\u4e865G\u6807\u51c6\u95ee\u9898\u56de\u7b54\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u663e\u5f0f\u5efa\u6a21\u6807\u51c6\u7ed3\u6784\u548c\u6f14\u8fdb\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.01323", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01323", "abs": "https://arxiv.org/abs/2511.01323", "authors": ["Jiabao Ji", "Min Li", "Priyanshu Kumar", "Shiyu Chang", "Saloni Potdar"], "title": "DEEPAMBIGQA: Ambiguous Multi-hop Questions for Benchmarking LLM Answer Completeness", "comment": "25 pages", "summary": "Large language models (LLMs) with integrated search tools show strong promise\nin open-domain question answering (QA), yet they often struggle to produce\ncomplete answer set to complex questions such as Which actor from the film Heat\nwon at least one Academy Award?, which requires (1) distinguishing between\nmultiple films sharing the same title and (2) reasoning across a large set of\nactors to gather and integrate evidence. Existing QA benchmarks rarely evaluate\nboth challenges jointly. To address this, we introduce DeepAmbigQAGen, an\nautomatic data generation pipeline that constructs QA tasks grounded in text\ncorpora and linked knowledge graph, generating natural and verifiable questions\nthat systematically embed name ambiguity and multi-step reasoning. Based on\nthis, we build DeepAmbigQA, a dataset of 3,600 questions requiring multi-hop\nreasoning and half of them explicit name ambiguity resolving. Experiments\nreveal that, even state-of-the-art GPT-5 show incomplete answers, achieving\nonly 0.13 exact match on ambiguous questions and 0.21 on non-ambiguous\nquestions. These findings highlight the need for more robust QA systems aimed\nat information gathering and answer completeness.", "AI": {"tldr": "\u63d0\u51fa\u4e86DeepAmbigQA\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u5728\u542b\u6b67\u4e49\u548c\u591a\u8df3\u63a8\u7406\u7684\u590d\u6742\u95ee\u7b54\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u5f3a\u5927\u95ee\u7b54\u80fd\u529b\uff0c\u4f46\u96be\u4ee5\u5904\u7406\u6d89\u53ca\u540d\u79f0\u6b67\u4e49\u548c\u591a\u8df3\u63a8\u7406\u7684\u590d\u6742\u95ee\u9898\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u5f88\u5c11\u540c\u65f6\u8bc4\u4f30\u8fd9\u4e24\u7c7b\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86DeepAmbigQAGen\u81ea\u52a8\u6570\u636e\u751f\u6210\u6d41\u7a0b\uff0c\u7ed3\u5408\u6587\u672c\u8bed\u6599\u548c\u77e5\u8bc6\u56fe\u8c31\u81ea\u52a8\u751f\u6210\u5305\u542b\u540d\u79f0\u6b67\u4e49\u548c\u591a\u6b65\u63a8\u7406\u7684\u81ea\u7136\u4e14\u53ef\u9a8c\u8bc1\u95ee\u9898\uff1b\u57fa\u4e8e\u6b64\u6784\u5efa\u4e863600\u4e2a\u95ee\u9898\u7684DeepAmbigQA\u6570\u636e\u96c6\u3002", "result": "\u5728DeepAmbigQA\u6d4b\u8bd5\u4e2d\uff0c\u6700\u5148\u8fdb\u7684GPT-5\u5728\u542b\u6b67\u4e49\u95ee\u9898\u4e0a\u51c6\u786e\u5339\u914d\u7387\u4ec5\u4e3a0.13\uff0c\u975e\u6b67\u4e49\u95ee\u9898\u4e3a0.21\uff0c\u8868\u660e\u56de\u7b54\u4e0d\u5b8c\u6574\u3002", "conclusion": "\u5f53\u524d\u95ee\u7b54\u7cfb\u7edf\u5728\u5904\u7406\u540d\u79f0\u6b67\u4e49\u548c\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u65f6\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u5f00\u53d1\u66f4\u591a\u5173\u6ce8\u4fe1\u606f\u83b7\u53d6\u548c\u7b54\u6848\u5b8c\u6574\u6027\u7684\u9c81\u68d2\u6a21\u578b\u3002"}}
{"id": "2511.01354", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01354", "abs": "https://arxiv.org/abs/2511.01354", "authors": ["Wenrui Cai", "Chengyu Wang", "Junbing Yan", "Jun Huang", "Xiangzhong Fang"], "title": "Thinking with DistilQwen: A Tale of Four Distilled Reasoning and Reward Model Series", "comment": "emnlp 2025 industry track", "summary": "Recently, the demand for small and efficient reasoning models to support\nreal-world applications has driven the development of knowledge distillation\ntechniques that balance reasoning performance and inference speed. In this\npaper, we further extend the DistilQwen model family, initialized from the Qwen\nmodels, by introducing four model series specifically designed to meet\nindustrial requirements. The distilled model collection comprises: (1)\nslow-thinking models, optimized for reasoning tasks that require high accuracy;\n(2) two series of adaptive-thinking models, which dynamically adjust reasoning\nstrategies based on input tasks to maximize efficiency across diverse\nscenarios; and (3) distilled reward models, which enable further reinforcement\nlearning of reasoning models using distilled knowledge. Comprehensive\nevaluations across multiple benchmarks demonstrate both high inference\nefficiency and strong reasoning performance for these models, as well as the\npractical utility of distilled reward models. We further show that these models\nsupport industry practitioners by providing scalable training and inference\nfunctionalities on the Alibaba Cloud PAI (Platform for Artificial Intelligence)\nplatform.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u56db\u7c7b\u4e13\u4e3a\u5de5\u4e1a\u5e94\u7528\u8bbe\u8ba1\u7684DistilQwen\u84b8\u998f\u6a21\u578b\uff0c\u517c\u987e\u63a8\u7406\u6027\u80fd\u548c\u63a8\u7406\u901f\u5ea6\uff0c\u652f\u6301\u4e91\u5e73\u53f0\u8bad\u7ec3\u548c\u63a8\u7406\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u5b9e\u9645\u5e94\u7528\u4e2d\u5bf9\u5c0f\u578b\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u7684\u9700\u6c42\uff0c\u63d0\u5347\u63a8\u7406\u6027\u80fd\u4e0e\u901f\u5ea6\u7684\u5e73\u8861\u3002", "method": "\u57fa\u4e8eQwen\u6a21\u578b\uff0c\u8bbe\u8ba1\u56db\u79cd\u84b8\u998f\u6a21\u578b\u7cfb\u5217\uff1a\u6162\u601d\u8003\u6a21\u578b\u3001\u9ad8\u51c6\u786e\u6027\u63a8\u7406\uff1b\u4e24\u79cd\u81ea\u9002\u5e94\u601d\u8003\u6a21\u578b\uff0c\u52a8\u6001\u8c03\u6574\u63a8\u7406\u7b56\u7565\uff1b\u84b8\u998f\u5956\u52b1\u6a21\u578b\uff0c\u652f\u6301\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u591a\u57fa\u51c6\u6d4b\u8bd5\u663e\u793a\u6a21\u578b\u5177\u6709\u9ad8\u63a8\u7406\u6548\u7387\u548c\u826f\u597d\u63a8\u7406\u6027\u80fd\uff0c\u84b8\u998f\u5956\u52b1\u6a21\u578b\u5728\u5b9e\u9645\u4e2d\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u7cfb\u5217\u6a21\u578b\u9002\u7528\u4e8e\u5de5\u4e1a\u9700\u6c42\uff0c\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u8bad\u7ec3\u4e0e\u63a8\u7406\u529f\u80fd\uff0c\u652f\u6301\u963f\u91cc\u4e91PAI\u5e73\u53f0\u5e94\u7528\u3002"}}
{"id": "2511.01359", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01359", "abs": "https://arxiv.org/abs/2511.01359", "authors": ["Sapir Harary", "Eran Hirsch", "Aviv Slobodkin", "David Wan", "Mohit Bansal", "Ido Dagan"], "title": "PrefixNLI: Detecting Factual Inconsistencies as Soon as They Arise", "comment": "9 pages + appendix. Code, datasets, and models are available at\n  https://github.com/sapirharary/PrefixNLI", "summary": "Natural Language Inference (NLI) models have been used in various ways to\nimprove the factuality of LLM outputs. This is typically done by applying an\nNLI model to judge whether the model output is entailed from the supposed\nevidence, triggering some corrective actions, such as beam reranking at\ninference time or RL rewards during training. While NLI models are trained to\ndetect factual inconsistencies over complete sentences, decisions in the common\nautoregressive generation architecture are made for each evolving text prefix,\nduring decoding. Addressing this setting, we generalize the entailment\ndetection task to apply over arbitrary text prefixes, and suggest its utility\nfor improving generation faithfulness. Providing suitable evaluation and\ntraining datasets for this task, we train MiniTruePrefixes, a novel specialized\nmodel that better detects factual inconsistencies over text prefixes,\noutperforming comparable baseline NLI models by 5-14 F1 points in prefix-level\nentailment. We further demonstrate that integrating MiniTruePrefixes into a\ncontrolled decoding framework substantially improves factual consistency in\nabstractive summarization. When guided by MiniTruePrefixes,\nLLaMA-3.2-3B-Instruct matches the faithfulness and runtime of the 8B model from\nthe same model family, while using only half the memory.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u7684\u65b0\u6a21\u578bMiniTruePrefixes\uff0c\u4e13\u95e8\u68c0\u6d4b\u6587\u672c\u524d\u7f00\u4e2d\u7684\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u6027\uff0c\u4ece\u800c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u751f\u6210\u7684\u5185\u5bb9\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u3002", "motivation": "\u76ee\u524dNLI\u6a21\u578b\u901a\u5e38\u5728\u5b8c\u6574\u53e5\u5b50\u4e0a\u68c0\u6d4b\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u4f46\u5728\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4e2d\u9700\u8981\u5728\u9010\u6b65\u751f\u6210\u7684\u6587\u672c\u524d\u7f00\u4e0a\u5224\u65ad\u4e8b\u5b9e\u4e00\u81f4\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u8fd9\u4e00\u9700\u6c42\u3002", "method": "\u4f5c\u8005\u6269\u5c55\u4e86\u8574\u6db5\u68c0\u6d4b\u4efb\u52a1\uff0c\u5e94\u7528\u4e8e\u4efb\u610f\u6587\u672c\u524d\u7f00\uff0c\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u4e86MiniTruePrefixes\u6a21\u578b\u4ee5\u5728\u6587\u672c\u524d\u7f00\u5c42\u9762\u66f4\u597d\u5730\u68c0\u6d4b\u4e8b\u5b9e\u4e0d\u4e00\u81f4\u3002", "result": "MiniTruePrefixes\u5728\u6587\u672c\u524d\u7f00\u7ea7\u522b\u6bd4\u4f20\u7edfNLI\u6a21\u578b\u63d0\u9ad8\u4e865-14 F1\u5206\uff0c\u4e14\u5c06\u5176\u6574\u5408\u8fdb\u63a7\u5236\u89e3\u7801\u6846\u67b6\u540e\uff0c\u5728\u62bd\u8c61\u6458\u8981\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u4e8b\u5b9e\u4e00\u81f4\u6027\u3002", "conclusion": "\u901a\u8fc7\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7ed3\u5408MiniTruePrefixes\uff0c\u5f15\u5bfc\u751f\u6210\u7684\u6a21\u578b\u5728\u5185\u5b58\u5360\u7528\u51cf\u534a\u7684\u60c5\u51b5\u4e0b\uff0c\u8fbe\u5230\u4e86\u4e0e\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u4e8b\u5b9e\u51c6\u786e\u7387\u548c\u63a8\u7406\u901f\u5ea6\u3002"}}
{"id": "2511.01360", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01360", "abs": "https://arxiv.org/abs/2511.01360", "authors": ["Aadi Palnitkar", "Arjun Suresh", "Rishi Rajesh", "Puneet Puli"], "title": "Safer in Translation? Presupposition Robustness in Indic Languages", "comment": "This is a submission to LREC 2026 (Language Resources and Evaluation\n  Conference 2026). Corresponding author: aadipalnitkar96@gmail.com", "summary": "Increasingly, more and more people are turning to large language models\n(LLMs) for healthcare advice and consultation, making it important to gauge the\nefficacy and accuracy of the responses of LLMs to such queries. While there are\npre-existing medical benchmarks literature which seeks to accomplish this very\ntask, these benchmarks are almost universally in English, which has led to a\nnotable gap in existing literature pertaining to multilingual LLM evaluation.\nWithin this work, we seek to aid in addressing this gap with Cancer-Myth-Indic,\nan Indic language benchmark built by translating a 500-item subset of\nCancer-Myth, sampled evenly across its original categories, into five\nunder-served but widely used languages from the subcontinent (500 per language;\n2,500 translated items total). Native-speaker translators followed a style\nguide for preserving implicit presuppositions in translation; items feature\nfalse presuppositions relating to cancer. We evaluate several popular LLMs\nunder this presupposition stress.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u764c\u75c7\u76f8\u5173\u8bef\u533a\u7684\u591a\u8bed\u8a00\u6307\u6807\u8bc4\u4f30\u57fa\u51c6Cancer-Myth-Indic\uff0c\u6db5\u76d6\u4e94\u79cd\u5357\u4e9a\u6b21\u5927\u9646\u8bed\u8a00\uff0c\u5e76\u8bc4\u4f30\u4e86\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e9b\u8bed\u8a00\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u533b\u7597\u9886\u57df\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u51e0\u4e4e\u5168\u90e8\u96c6\u4e2d\u5728\u82f1\u8bed\uff0c\u7f3a\u4e4f\u591a\u8bed\u8a00\u7279\u522b\u662f\u5357\u4e9a\u8bed\u8a00\u7684\u8bc4\u4f30\u57fa\u51c6\uff0c\u5bfc\u81f4\u8be5\u533a\u57df\u7528\u6237\u7684\u533b\u7597\u54a8\u8be2\u6548\u679c\u96be\u4ee5\u9a8c\u8bc1\u3002", "method": "\u57fa\u4e8eCancer-Myth\u6570\u636e\u96c6\uff0c\u7ffb\u8bd1\u4e86\u5176\u4e2d500\u6761\u9879\u76ee\u5230\u4e94\u79cd\u5357\u4e9a\u8bed\u8a00\uff0c\u5171\u8ba12500\u6761\uff0c\u7531\u6bcd\u8bed\u7ffb\u8bd1\u4eba\u5458\u6309\u7167\u4fdd\u6301\u9690\u542b\u524d\u63d0\u7684\u98ce\u683c\u6307\u5357\u5b8c\u6210\uff0c\u540c\u65f6\u8bbe\u8ba1\u5305\u542b\u764c\u75c7\u76f8\u5173\u9519\u8bef\u524d\u63d0\u7684\u95ee\u9898\uff0c\u68c0\u6d4b\u6a21\u578b\u5728\u8fd9\u79cd\u538b\u529b\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u591a\u4e2a\u6d41\u884c\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8fd9\u4e9b\u5357\u4e9a\u8bed\u8a00\u7684\u9690\u542b\u524d\u63d0\u6d4b\u8bd5\u4e2d\u8868\u73b0\u88ab\u8bc4\u4f30\uff0c\u5177\u4f53\u7ed3\u679c\u672a\u8be6\u8ff0\uff0c\u4f46\u8868\u660e\u4e86\u6a21\u578b\u5728\u591a\u8bed\u73af\u5883\u4e0b\u7684\u6709\u6548\u6027\u548c\u5b58\u5728\u7684\u6311\u6218\u3002", "conclusion": "Cancer-Myth-Indic\u8865\u5145\u4e86\u591a\u8bed\u8a00\u533b\u7597\u95ee\u7b54\u8bc4\u4f30\u57fa\u51c6\uff0c\u4fc3\u8fdb\u4e86\u5bf9\u5357\u4e9a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u533b\u7597\u5efa\u8bae\u80fd\u529b\u7684\u7406\u89e3\u548c\u63d0\u5347\u3002"}}
{"id": "2511.01365", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01365", "abs": "https://arxiv.org/abs/2511.01365", "authors": ["\u0130brahim Ethem Deveci", "Duygu Ataman"], "title": "The Ouroboros of Benchmarking: Reasoning Evaluation in an Era of Saturation", "comment": "Accepted to NeurIPS 2025 Workshop on LLM Evaluation\n  (https://openreview.net/group?id=NeurIPS.cc/2025/Workshop/LLM_Evaluation)", "summary": "The rapid rise of Large Language Models (LLMs) and Large Reasoning Models\n(LRMs) has been accompanied by an equally rapid increase of benchmarks used to\nassess them. However, due to both improved model competence resulting from\nscaling and novel training advances as well as likely many of these datasets\nbeing included in pre or post training data, results become saturated, driving\na continuous need for new and more challenging replacements. In this paper, we\ndiscuss whether surpassing a benchmark truly demonstrates reasoning ability or\nare we simply tracking numbers divorced from the capabilities we claim to\nmeasure? We present an investigation focused on three model families, OpenAI,\nAnthropic, and Google, and how their reasoning capabilities across different\nbenchmarks evolve over the years. We also analyze performance trends over the\nyears across different reasoning tasks and discuss the current situation of\nbenchmarking and remaining challenges. By offering a comprehensive overview of\nbenchmarks and reasoning tasks, our work aims to serve as a first reference to\nground future research in reasoning evaluation and model development.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u548c\u63a8\u7406\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u8d8b\u4e8e\u9971\u548c\u7684\u73b0\u8c61\uff0c\u5e76\u5206\u6790\u4e86\u4e09\u5927\u5bb6\u65cf\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u968f\u65f6\u95f4\u7684\u6f14\u53d8\u3002", "motivation": "\u968f\u7740\u6a21\u578b\u80fd\u529b\u63d0\u5347\u53ca\u8bad\u7ec3\u6570\u636e\u5305\u542b\u73b0\u6709\u6d4b\u8bd5\u96c6\uff0c\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u8d8b\u4e8e\u9971\u548c\uff0c\u9700\u8981\u8bc4\u4f30\u662f\u5426\u771f\u6b63\u53cd\u6620\u4e86\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5bf9OpenAI\u3001Anthropic\u548cGoogle\u4e09\u5927\u5bb6\u65cf\u7684\u6a21\u578b\u5728\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u7eb5\u5411\u5206\u6790\uff0c\u63a2\u8ba8\u63a8\u7406\u4efb\u52a1\u7684\u6027\u80fd\u8d8b\u52bf\u548c\u57fa\u51c6\u6d4b\u8bd5\u7684\u73b0\u72b6\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5728\u591a\u9879\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u9010\u5e74\u53d8\u5316\uff0c\u57fa\u51c6\u6d4b\u8bd5\u9762\u4e34\u9971\u548c\u548c\u6311\u6218\uff0c\u63a8\u52a8\u4e86\u65b0\u6311\u6218\u7684\u9700\u6c42\u3002", "conclusion": "\u57fa\u51c6\u6d4b\u8bd5\u7ed3\u679c\u53ef\u80fd\u5e76\u4e0d\u5b8c\u5168\u53cd\u6620\u6a21\u578b\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8c28\u614e\u8bbe\u8ba1\u548c\u9009\u62e9\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u7814\u7a76\u4e3a\u672a\u6765\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u548c\u6a21\u578b\u5f00\u53d1\u63d0\u4f9b\u4e86\u7efc\u8ff0\u548c\u53c2\u8003\u3002"}}
{"id": "2511.01380", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01380", "abs": "https://arxiv.org/abs/2511.01380", "authors": ["Wessel Poelman", "Thomas Bauwens", "Miryam de Lhoneux"], "title": "Confounding Factors in Relating Model Performance to Morphology", "comment": "EMNLP 2025: Main Conference", "summary": "The extent to which individual language characteristics influence\ntokenization and language modeling is an open question. Differences in\nmorphological systems have been suggested as both unimportant and crucial to\nconsider (Cotterell et al., 2018; Gerz et al., 2018a; Park et al., 2021, inter\nalia). We argue this conflicting evidence is due to confounding factors in\nexperimental setups, making it hard to compare results and draw conclusions. We\nidentify confounding factors in analyses trying to answer the question of\nwhether, and how, morphology relates to language modeling. Next, we re-assess\nthree hypotheses by Arnett & Bergen (2025) for why modeling agglutinative\nlanguages results in higher perplexities than fusional languages: they look at\nmorphological alignment of tokenization, tokenization efficiency, and dataset\nsize. We show that each conclusion includes confounding factors. Finally, we\nintroduce token bigram metrics as an intrinsic way to predict the difficulty of\ncausal language modeling, and find that they are gradient proxies for\nmorphological complexity that do not require expert annotation. Ultimately, we\noutline necessities to reliably answer whether, and how, morphology relates to\nlanguage modeling.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u8bed\u8a00\u5f62\u6001\u5b66\u7279\u5f81\u5bf9\u5206\u8bcd\u548c\u8bed\u8a00\u5efa\u6a21\u7684\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u4ee5\u5f80\u7814\u7a76\u7ed3\u8bba\u4e0d\u4e00\u662f\u7531\u4e8e\u5b9e\u9a8c\u8bbe\u8ba1\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\u6240\u81f4\u3002", "motivation": "\u660e\u786e\u4e2a\u4f53\u8bed\u8a00\u5f62\u6001\u5b66\u7279\u5f81\u662f\u5426\u4ee5\u53ca\u5982\u4f55\u5f71\u54cd\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u8fc7\u53bb\u7814\u7a76\u7ed3\u679c\u51b2\u7a81\u7684\u95ee\u9898\u3002", "method": "\u8bc6\u522b\u5e76\u63a7\u5236\u5206\u6790\u4e2d\u7684\u6df7\u6742\u56e0\u7d20\uff0c\u91cd\u65b0\u8bc4\u4f30\u4e09\u79cd\u5173\u4e8e\u805a\u5408\u8bed\u548c\u5c48\u6298\u8bed\u5efa\u6a21\u96be\u6613\u7684\u5047\u8bbe\uff0c\u5f15\u5165\u57fa\u4e8e\u8bcd\u5143\u4e8c\u5143\u7ec4\u7684\u5ea6\u91cf\u65b9\u6cd5\u4f5c\u4e3a\u5f62\u6001\u5b66\u590d\u6742\u6027\u7684\u68af\u5ea6\u9884\u6d4b\u6307\u6807\u3002", "result": "\u6307\u51fa\u73b0\u6709\u5047\u8bbe\u5747\u5305\u542b\u6df7\u6742\u56e0\u7d20\uff0c\u8bcd\u5143\u4e8c\u5143\u7ec4\u5ea6\u91cf\u80fd\u65e0\u9700\u4e13\u5bb6\u6ce8\u91ca\u6709\u6548\u9884\u6d4b\u8bed\u8a00\u5efa\u6a21\u96be\u5ea6\u3002", "conclusion": "\u5f3a\u8c03\u5408\u7406\u5b9e\u9a8c\u8bbe\u8ba1\u662f\u53ef\u9760\u8bc4\u4f30\u5f62\u6001\u5b66\u4e0e\u8bed\u8a00\u5efa\u6a21\u5173\u7cfb\u7684\u524d\u63d0\uff0c\u63d0\u51fa\u65b0\u5ea6\u91cf\u5de5\u5177\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u5e2e\u52a9\u3002"}}
{"id": "2511.01386", "categories": ["cs.CL", "cs.AI", "cs.IR", "H.3.3; I.2.7"], "pdf": "https://arxiv.org/pdf/2511.01386", "abs": "https://arxiv.org/abs/2511.01386", "authors": ["Muhammed Yusuf Kartal", "Suha Kagan Kose", "Korhan Sevin\u00e7", "Burak Aktas"], "title": "RAGSmith: A Framework for Finding the Optimal Composition of Retrieval-Augmented Generation Methods Across Datasets", "comment": "45 pages", "summary": "Retrieval-Augmented Generation (RAG) quality depends on many interacting\nchoices across retrieval, ranking, augmentation, prompting, and generation, so\noptimizing modules in isolation is brittle. We introduce RAGSmith, a modular\nframework that treats RAG design as an end-to-end architecture search over nine\ntechnique families and 46{,}080 feasible pipeline configurations. A genetic\nsearch optimizes a scalar objective that jointly aggregates retrieval metrics\n(recall@k, mAP, nDCG, MRR) and generation metrics (LLM-Judge and semantic\nsimilarity). We evaluate on six Wikipedia-derived domains (Mathematics, Law,\nFinance, Medicine, Defense Industry, Computer Science), each with 100 questions\nspanning factual, interpretation, and long-answer types. RAGSmith finds\nconfigurations that consistently outperform naive RAG baseline by +3.8\\% on\naverage (range +1.2\\% to +6.9\\% across domains), with gains up to +12.5\\% in\nretrieval and +7.5\\% in generation. The search typically explores $\\approx\n0.2\\%$ of the space ($\\sim 100$ candidates) and discovers a robust backbone --\nvector retrieval plus post-generation reflection/revision -- augmented by\ndomain-dependent choices in expansion, reranking, augmentation, and prompt\nreordering; passage compression is never selected. Improvement magnitude\ncorrelates with question type, with larger gains on factual/long-answer mixes\nthan interpretation-heavy sets. These results provide practical, domain-aware\nguidance for assembling effective RAG systems and demonstrate the utility of\nevolutionary search for full-pipeline optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RAGSmith\u6846\u67b6\uff0c\u901a\u8fc7\u9057\u4f20\u7b97\u6cd5\u5728\u591a\u79cd\u6280\u672f\u7ec4\u5408\u4e2d\u4f18\u5316\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9886\u57df\u7684\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "RAG\u7cfb\u7edf\u7684\u6027\u80fd\u4f9d\u8d56\u4e8e\u68c0\u7d22\u3001\u6392\u5e8f\u3001\u589e\u5f3a\u3001\u63d0\u793a\u548c\u751f\u6210\u7b49\u591a\u4e2a\u6a21\u5757\u7684\u8054\u5408\u4f5c\u7528\uff0c\u5355\u72ec\u4f18\u5316\u5bb9\u6613\u5bfc\u81f4\u8106\u5f31\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6db5\u76d6\u4e5d\u5927\u6280\u672f\u7c7b\u522b\u300146080\u79cd\u7ba1\u7ebf\u914d\u7f6e\u7684\u7aef\u5230\u7aef\u67b6\u6784\u641c\u7d22\u6846\u67b6\uff0c\u4f7f\u7528\u9057\u4f20\u7b97\u6cd5\u8054\u5408\u4f18\u5316\u68c0\u7d22\u548c\u751f\u6210\u6307\u6807\u3002", "result": "\u5728\u516d\u4e2a\u7ef4\u57fa\u767e\u79d1\u9886\u57df\u7684100\u4e2a\u95ee\u9898\u96c6\u4e0a\uff0cRAGSmith\u5e73\u5747\u63d0\u5347\u6027\u80fd3.8%\uff0c\u68c0\u7d22\u63d0\u5347\u6700\u9ad8\u8fbe12.5%\uff0c\u751f\u6210\u63d0\u5347\u6700\u9ad8\u8fbe7.5%\uff0c\u4e14\u53d1\u73b0\u4e86\u901a\u7528\u7684\u6709\u6548\u7ed3\u6784\u548c\u9886\u57df\u76f8\u5173\u914d\u7f6e\u3002", "conclusion": "RAGSmith\u4e3a\u6784\u5efa\u9ad8\u6548\u3001\u9886\u57df\u611f\u77e5\u7684RAG\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u9a8c\u8bc1\u4e86\u8fdb\u5316\u641c\u7d22\u5728\u5168\u6d41\u7a0b\u4f18\u5316\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.01409", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01409", "abs": "https://arxiv.org/abs/2511.01409", "authors": ["Heng Zhou", "Ao Yu", "Yuchen Fan", "Jianing Shi", "Li Kang", "Hejia Geng", "Yongting Zhang", "Yutao Fan", "Yuhao Wu", "Tiancheng He", "Yiran Qin", "Lei Bai", "Zhenfei Yin"], "title": "LiveSearchBench: An Automatically Constructed Benchmark for Retrieval and Reasoning over Dynamic Knowledge", "comment": null, "summary": "Evaluating large language models (LLMs) on question answering often relies on\nstatic benchmarks that reward memorization and understate the role of\nretrieval, failing to capture the dynamic nature of world knowledge. We present\nLiveSearchBench, an automated pipeline for constructing retrieval-dependent\nbenchmarks from recent knowledge updates. Our method computes deltas between\nsuccessive Wikidata snapshots, filters candidate triples for quality, and\nsynthesizes natural-language questions at three levels of reasoning difficulty,\neach guaranteed to admit a unique, verifiable answer through SPARQL validation.\nThe pipeline is fully automated, scalable across time, and minimizes human\nintervention, enabling continual regeneration of temporally grounded\nbenchmarks. Experiments show a pronounced performance drop when models confront\nfacts that post-date pretraining, with the gap most salient on multi-hop\nqueries. Retrieval augmented methods and larger, instruction-tuned models\nprovide partial gains but fail to close this recency gap. By design,\nLiveSearchBench shifts evaluation from static memorization toward tasks that\nrequire up-to-date retrieval and reasoning, offering a foundation for\nsystematic, long-term assessment of LLMs under evolving knowledge.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86LiveSearchBench\uff0c\u4e00\u79cd\u57fa\u4e8e\u6700\u65b0\u77e5\u8bc6\u66f4\u65b0\u81ea\u52a8\u6784\u5efa\u68c0\u7d22\u4f9d\u8d56\u578b\u95ee\u7b54\u57fa\u51c6\u7684\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u52a8\u6001\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\u80fd\u529b\u7684\u8bc4\u4f30\u3002", "motivation": "\u73b0\u6709\u7684\u9759\u6001\u95ee\u7b54\u57fa\u51c6\u8fc7\u4e8e\u4f9d\u8d56\u8bb0\u5fc6\uff0c\u5ffd\u89c6\u4e86\u68c0\u7d22\u7684\u4f5c\u7528\uff0c\u4e0d\u80fd\u53cd\u6620\u4e16\u754c\u77e5\u8bc6\u7684\u52a8\u6001\u53d8\u5316\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u8fde\u7eed\u65f6\u95f4\u70b9\u7684Wikidata\u5feb\u7167\u5dee\u5f02\u3001\u7b5b\u9009\u9ad8\u8d28\u91cf\u4e09\u5143\u7ec4\uff0c\u5e76\u81ea\u52a8\u751f\u6210\u4fdd\u8bc1\u552f\u4e00\u4e14\u53ef\u9a8c\u8bc1\u7b54\u6848\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\uff0c\u6784\u5efa\u52a8\u6001\u95ee\u7b54\u57fa\u51c6\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u5728\u5904\u7406\u8d85\u51fa\u9884\u8bad\u7ec3\u65f6\u95f4\u7684\u4e8b\u5b9e\u65f6\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u591a\u8df3\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u68c0\u7d22\u589e\u5f3a\u548c\u66f4\u5927\u89c4\u6a21\u6a21\u578b\u867d\u6709\u63d0\u5347\uff0c\u4f46\u672a\u5f25\u8865\u65f6\u95f4\u654f\u611f\u6027\u7684\u5dee\u8ddd\u3002", "conclusion": "LiveSearchBench\u6709\u6548\u63a8\u52a8\u8bc4\u4f30\u4ece\u9759\u6001\u8bb0\u5fc6\u8f6c\u5411\u57fa\u4e8e\u6700\u65b0\u77e5\u8bc6\u68c0\u7d22\u4e0e\u63a8\u7406\uff0c\u4e3a\u957f\u671f\u52a8\u6001\u77e5\u8bc6\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2511.01454", "categories": ["cs.CL", "cs.DL"], "pdf": "https://arxiv.org/pdf/2511.01454", "abs": "https://arxiv.org/abs/2511.01454", "authors": ["Sergio Torres Aguilar"], "title": "\"Don't Teach Minerva\": Guiding LLMs Through Complex Syntax for Faithful Latin Translation with RAG", "comment": null, "summary": "Translating a morphology-rich, low-resource language like Latin poses\nsignificant challenges. This paper introduces a reproducible draft-based\nrefinement pipeline that elevates open-source Large Language Models (LLMs) to a\nperformance level statistically comparable to top-tier proprietary systems. Our\nmethod first uses a fine-tuned NLLB-1.3B model to generate a high-quality,\nstructurally faithful draft. A zero-shot LLM (Llama-3.3 or Qwen3) then polishes\nthis draft, a process that can be further enhanced by augmenting the context\nwith retrieved out-context examples (RAG). We demonstrate the robustness of\nthis approach on two distinct benchmarks: a standard in-domain test set\n(Rosenthal, 2023) and a new, challenging out-of-domain (OOD) set of\n12th-century Latin letters (2025). Our central finding is that this open-source\nRAG system achieves performance statistically comparable to the GPT-5 baseline,\nwithout any task-specific LLM fine-tuning. We release the pipeline, the\nChartres OOD set, and evaluation scripts and models to facilitate replicability\nand further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u62c9\u4e01\u8bed\u7684\u57fa\u4e8e\u8349\u7a3f\u6539\u8fdb\u7684\u7ffb\u8bd1\u6d41\u7a0b\uff0c\u5229\u7528\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u63a5\u8fd1\u9876\u7ea7\u4e13\u6709\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "motivation": "\u62c9\u4e01\u8bed\u4f5c\u4e3a\u5f62\u6001\u4e30\u5bcc\u4e14\u8d44\u6e90\u7a00\u7f3a\u7684\u8bed\u8a00\uff0c\u7ffb\u8bd1\u96be\u5ea6\u5927\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u65b9\u6cd5\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\u3002", "method": "\u9996\u5148\u7528\u5fae\u8c03\u7684NLLB-1.3B\u6a21\u578b\u751f\u6210\u7ed3\u6784\u51c6\u786e\u7684\u521d\u7a3f\uff0c\u518d\u7528\u96f6\u6837\u672c\u5927\u8bed\u8a00\u6a21\u578b\uff08Llama-3.3\u6216Qwen3\uff09\u5bf9\u521d\u7a3f\u8fdb\u884c\u6da6\u8272\uff0c\u540c\u65f6\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6280\u672f\u52a0\u5165\u4e0a\u4e0b\u6587\u793a\u4f8b\u4ee5\u63d0\u5347\u8868\u73b0\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u6807\u51c6\u5185\u9886\u57df\u6d4b\u8bd5\u96c6\u548c\u6311\u6218\u6027\u768412\u4e16\u7eaa\u62c9\u4e01\u4e66\u4fe1\u5916\u9886\u57df\u6d4b\u8bd5\u96c6\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u8fbe\u5230\u4e0eGPT-5\u57fa\u7ebf\u7edf\u8ba1\u4e0a\u76f8\u5f53\u7684\u6027\u80fd\uff0c\u65e0\u9700\u9488\u5bf9\u4efb\u52a1\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u57fa\u4e8e\u8349\u7a3f\u6539\u8fdb\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u7ffb\u8bd1\u6d41\u7a0b\u5728\u4f4e\u8d44\u6e90\u5f62\u6001\u8bed\u8a00\u4e2d\u7684\u6709\u6548\u6027\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u53ca\u4ee3\u7801\uff0c\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.01470", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01470", "abs": "https://arxiv.org/abs/2511.01470", "authors": ["Lujie Niu", "Lei Shen", "Yi Jiang", "Caixia Yuan", "Xiaojie Wang", "Wenbo Su", "Bo zheng"], "title": "BARD: budget-aware reasoning distillation", "comment": null, "summary": "While long Chain-of-Thought (CoT) distillation effectively transfers\nreasoning capability to smaller language models, the reasoning process often\nremains redundant and computational budget uncontrollable, leading to\ninefficient resource usage. To address this limitation, we propose\n\\textbf{Budget-Aware Reasoning Distillation (BARD)}, a novel framework that\nsimultaneously distills reasoning capability and enables fine-grained control\nover the reasoning length. BARD uses the thinking budget as a user-specified\ncontrol signal, allowing the model to dynamically balance reasoning performance\nand computational efficiency. To achieve this concept, BARD introduces a\ntwo-phase training regimen. The first phase, Supervised Fine-Tuning (SFT) on\nteacher-generated long CoT data compressed to various budget levels,\nbootstrapping the model's understanding of budget constraints. The second phase\nleverages Reinforcement Learning (RL) from a reward signal in consideration of\nreasoning performance and budget fidelity simultaneously. Incorporating the\ntwo-phase regimen is crucial to avoiding policy degradation and ensuring that\nboth objectives are optimized jointly. Extensive experiments demonstrate that\nour method empowers an 8B student model to achieve strong performance on\nchallenging reasoning benchmarks (\\textit{AIME24, AIME25, GPQA}) while\nproviding precise and adaptive control over its reasoning length across a wide\nrange of budgets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BARD\u6846\u67b6\uff0c\u901a\u8fc7\u7528\u6237\u6307\u5b9a\u7684\u8ba1\u7b97\u9884\u7b97\u4fe1\u53f7\uff0c\u5b9e\u73b0\u5bf9\u63a8\u7406\u957f\u5ea6\u7684\u7cbe\u7ec6\u63a7\u5236\uff0c\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u957f\u94fe\u6761\u601d\u7ef4\u84b8\u998f\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u5197\u4f59\u548c\u8ba1\u7b97\u9884\u7b97\u4e0d\u53ef\u63a7\u95ee\u9898\uff0c\u5bfc\u81f4\u8d44\u6e90\u5229\u7528\u4f4e\u6548\u3002", "method": "BARD\u91c7\u7528\u4e24\u9636\u6bb5\u8bad\u7ec3\uff1a\u7b2c\u4e00\u9636\u6bb5\u7528\u6559\u5e08\u751f\u6210\u7684\u4e0d\u540c\u9884\u7b97\u7ea7\u522b\u957f\u94fe\u6761\u6570\u636e\u8fdb\u884c\u6709\u76d1\u7763\u5fae\u8c03\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\uff0c\u4ece\u63a8\u7406\u6027\u80fd\u548c\u9884\u7b97\u51c6\u786e\u6027\u4e24\u4e2a\u65b9\u9762\u4f18\u5316\u6a21\u578b\u7b56\u7565\u3002", "result": "\u5728\u591a\u4e2a\u6311\u6218\u6027\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\uff08\u5982AIME24, AIME25, GPQA\uff09\u4e0a\uff0c8B\u53c2\u6570\u7684\u5b66\u751f\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u80fd\u6839\u636e\u9884\u7b97\u52a8\u6001\u8c03\u6574\u63a8\u7406\u957f\u5ea6\u3002", "conclusion": "BARD\u6210\u529f\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u7684\u84b8\u998f\u548c\u63a8\u7406\u957f\u5ea6\u7684\u7cbe\u51c6\u63a7\u5236\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u6548\u7387\uff0c\u6709\u6548\u5e73\u8861\u4e86\u6027\u80fd\u548c\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2511.01482", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01482", "abs": "https://arxiv.org/abs/2511.01482", "authors": ["Neha Sharma", "Navneet Agarwal", "Kairit Sirts"], "title": "Towards Consistent Detection of Cognitive Distortions: LLM-Based Annotation and Dataset-Agnostic Evaluation", "comment": null, "summary": "Text-based automated Cognitive Distortion detection is a challenging task due\nto its subjective nature, with low agreement scores observed even among expert\nhuman annotators, leading to unreliable annotations. We explore the use of\nLarge Language Models (LLMs) as consistent and reliable annotators, and propose\nthat multiple independent LLM runs can reveal stable labeling patterns despite\nthe inherent subjectivity of the task. Furthermore, to fairly compare models\ntrained on datasets with different characteristics, we introduce a\ndataset-agnostic evaluation framework using Cohen's kappa as an effect size\nmeasure. This methodology allows for fair cross-dataset and cross-study\ncomparisons where traditional metrics like F1 score fall short. Our results\nshow that GPT-4 can produce consistent annotations (Fleiss's Kappa = 0.78),\nresulting in improved test set performance for models trained on these\nannotations compared to those trained on human-labeled data. Our findings\nsuggest that LLMs can offer a scalable and internally consistent alternative\nfor generating training data that supports strong downstream performance in\nsubjective NLP tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f5c\u4e3a\u8ba4\u77e5\u626d\u66f2\u68c0\u6d4b\u4efb\u52a1\u4e2d\u4e00\u81f4\u4e14\u53ef\u9760\u7684\u6807\u6ce8\u5de5\u5177\uff0c\u901a\u8fc7\u591a\u6b21\u72ec\u7acb\u8fd0\u884c\u63ed\u793a\u7a33\u5b9a\u7684\u6807\u6ce8\u6a21\u5f0f\uff0c\u91c7\u7528\u57fa\u4e8eCohen's kappa\u7684\u65e0\u6570\u636e\u96c6\u4f9d\u8d56\u8bc4\u4f30\u6846\u67b6\uff0c\u5b9e\u73b0\u8de8\u6570\u636e\u96c6\u548c\u8de8\u7814\u7a76\u7684\u516c\u5e73\u6bd4\u8f83\u3002\u7ed3\u679c\u8868\u660eGPT-4\u6807\u6ce8\u8868\u73b0\u7a33\u5b9a\uff0c\u8bad\u7ec3\u6a21\u578b\u6027\u80fd\u4f18\u4e8e\u4eba\u7c7b\u6807\u6ce8\u6570\u636e\u3002", "motivation": "\u8ba4\u77e5\u626d\u66f2\u68c0\u6d4b\u4efb\u52a1\u7684\u4e3b\u89c2\u6027\u5bfc\u81f4\u4eba\u7c7b\u4e13\u5bb6\u6807\u6ce8\u4e00\u81f4\u6027\u4f4e\uff0c\u6807\u6ce8\u4e0d\u53ef\u9760\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u4e00\u81f4\u548c\u53ef\u9760\u7684\u6807\u6ce8\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u6b21\u72ec\u7acb\u6807\u6ce8\u4ee5\u63ed\u793a\u7a33\u5b9a\u6807\u6ce8\u6a21\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8eCohen\u2019s kappa\u7684\u65e0\u6570\u636e\u96c6\u4f9d\u8d56\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u516c\u5e73\u6bd4\u8f83\u4e0d\u540c\u6570\u636e\u96c6\u548c\u7814\u7a76\u4e2d\u7684\u6a21\u578b\u8868\u73b0\u3002", "result": "GPT-4\u5728\u8ba4\u77e5\u626d\u66f2\u68c0\u6d4b\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u8f83\u9ad8\u7684\u4e00\u81f4\u6027\uff08Fleiss's Kappa=0.78\uff09\uff0c\u57fa\u4e8e\u5176\u4ea7\u751f\u7684\u6807\u6ce8\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u4eba\u7c7b\u6807\u6ce8\u8bad\u7ec3\u7684\u6a21\u578b\u3002", "conclusion": "LLMs\u4f5c\u4e3a\u4e00\u81f4\u4e14\u53ef\u9760\u7684\u6807\u6ce8\u8005\uff0c\u4e3a\u4e3b\u89c2\u6027\u5f3a\u7684NLP\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u5185\u90e8\u4e00\u81f4\u7684\u8bad\u7ec3\u6570\u636e\u751f\u6210\u65b9\u6848\uff0c\u4ece\u800c\u63d0\u5347\u4e0b\u6e38\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2511.01490", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01490", "abs": "https://arxiv.org/abs/2511.01490", "authors": ["Max Schaffelder", "Albert Gatt"], "title": "Synthetic Eggs in Many Baskets: The Impact of Synthetic Data Diversity on LLM Fine-Tuning", "comment": null, "summary": "As synthetic data becomes widely used in language model development,\nunderstanding its impact on model behavior is crucial. This paper investigates\nthe impact of the diversity of sources of synthetic data on fine-tuned large\nlanguage models. We focus on three key dimensions: distribution collapse,\nadversarial robustness, and self-preference bias. Our findings reveal that\nfine-tuning models on synthetic data from diverse sources can mitigate\ndistribution collapse, preserving the breadth of the output distribution and\nthe diversity of the output text. Furthermore, while both human and synthetic\nfine-tuning data can remove safeguards, the latter preserves higher output\nquality, thus making outputs potentially more usable and dangerous. Finally,\nfine-tuning reduces self-preference bias, with human data being the most\neffective, followed by multi-source synthetic data.", "AI": {"tldr": "\u7814\u7a76\u5408\u6210\u6570\u636e\u6e90\u591a\u6837\u6027\u5bf9\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u3002", "motivation": "\u968f\u7740\u5408\u6210\u6570\u636e\u5728\u8bed\u8a00\u6a21\u578b\u5f00\u53d1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4e86\u89e3\u5176\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u5f71\u54cd\u53d8\u5f97\u81f3\u5173\u91cd\u8981\u3002", "method": "\u4ece\u5206\u5e03\u584c\u7f29\u3001\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u81ea\u6211\u504f\u597d\u504f\u5dee\u4e09\u65b9\u9762\u8003\u5bdf\u5408\u6210\u6570\u636e\u6765\u6e90\u591a\u6837\u6027\u5bf9\u6a21\u578b\u5fae\u8c03\u7684\u5f71\u54cd\u3002", "result": "\u591a\u6e90\u5408\u6210\u6570\u636e\u80fd\u7f13\u89e3\u5206\u5e03\u584c\u7f29\uff0c\u4fdd\u6301\u8f93\u51fa\u5206\u5e03\u5e7f\u5ea6\u548c\u6587\u672c\u591a\u6837\u6027\uff1b\u5408\u6210\u4eba\u7c7b\u6570\u636e\u5747\u53ef\u79fb\u9664\u5b89\u5168\u4fdd\u62a4\uff0c\u4f46\u5408\u6210\u6570\u636e\u8f93\u51fa\u8d28\u91cf\u66f4\u9ad8\uff1b\u5fae\u8c03\u80fd\u51cf\u5c11\u81ea\u6211\u504f\u597d\u504f\u5dee\uff0c\u4eba\u7c7b\u6570\u636e\u6700\u6709\u6548\uff0c\u5176\u6b21\u662f\u591a\u6e90\u5408\u6210\u6570\u636e\u3002", "conclusion": "\u5229\u7528\u591a\u6e90\u5408\u6210\u6570\u636e\u5fae\u8c03\u6a21\u578b\u53ef\u63d0\u5347\u8f93\u51fa\u591a\u6837\u6027\u548c\u8d28\u91cf\uff0c\u540c\u65f6\u51cf\u5c11\u504f\u89c1\uff0c\u4f46\u9700\u6ce8\u610f\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2511.01512", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01512", "abs": "https://arxiv.org/abs/2511.01512", "authors": ["Ayesha Afroza Mohsin", "Mashrur Ahsan", "Nafisa Maliyat", "Shanta Maria", "Syed Rifat Raiyan", "Hasan Mahmud", "Md Kamrul Hasan"], "title": "BanglaNirTox: A Large-scale Parallel Corpus for Explainable AI in Bengali Text Detoxification", "comment": "Under review, 6 pages, 1 figure, 2 tables", "summary": "Toxic language in Bengali remains prevalent, especially in online\nenvironments, with few effective precautions against it. Although text\ndetoxification has seen progress in high-resource languages, Bengali remains\nunderexplored due to limited resources. In this paper, we propose a novel\npipeline for Bengali text detoxification that combines Pareto class-optimized\nlarge language models (LLMs) and Chain-of-Thought (CoT) prompting to generate\ndetoxified sentences. To support this effort, we construct BanglaNirTox, an\nartificially generated parallel corpus of 68,041 toxic Bengali sentences with\nclass-wise toxicity labels, reasonings, and detoxified paraphrases, using\nPareto-optimized LLMs evaluated on random samples. The resulting BanglaNirTox\ndataset is used to fine-tune language models to produce better detoxified\nversions of Bengali sentences. Our findings show that Pareto-optimized LLMs\nwith CoT prompting significantly enhance the quality and consistency of Bengali\ntext detoxification.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u4e2d\u7684\u6709\u5bb3\u8bed\u8a00\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Pareto\u4f18\u5316\u5927\u8bed\u8a00\u6a21\u578b\u548cChain-of-Thought\u63d0\u793a\u7684\u65b0\u578b\u6587\u672c\u53bb\u6bd2\u5316\u65b9\u6cd5\uff0c\u5e76\u6784\u5efa\u4e86\u8f83\u5927\u7684\u4eba\u5de5\u5e76\u884c\u8bed\u6599\u5e93BanglaNirTox\u7528\u4e8e\u6a21\u578b\u5fae\u8c03\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u5728\u7ebf\u73af\u5883\u4e2d\u7684\u6709\u5bb3\u8bed\u8a00\u666e\u904d\u5b58\u5728\uff0c\u4f46\u7531\u4e8e\u8d44\u6e90\u6709\u9650\uff0c\u6587\u672c\u53bb\u6bd2\u5316\u7814\u7a76\u4e0d\u8db3\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u7684\u53bb\u6bd2\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u652f\u6301\u3002", "method": "\u63d0\u51fa\u7ed3\u5408Pareto\u7c7b\u522b\u4f18\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548cChain-of-Thought\u63d0\u793a\u7684\u7ba1\u7ebf\uff0c\u901a\u8fc7\u751f\u6210\u5e26\u7c7b\u522b\u6807\u7b7e\u3001\u63a8\u7406\u548c\u53bb\u6bd2\u5316\u540c\u4e49\u53e5\u7684\u5e76\u884c\u8bed\u6599\u5e93BanglaNirTox\uff0c\u968f\u540e\u7528\u8be5\u8bed\u6599\u5e93\u5fae\u8c03\u6a21\u578b\u63d0\u5347\u53bb\u6bd2\u6548\u679c\u3002", "result": "\u57fa\u4e8ePareto\u4f18\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u53caCoT\u63d0\u793a\u751f\u6210\u7684BanglaNirTox\u8bed\u6599\u5e93\uff0c\u5fae\u8c03\u6a21\u578b\u540e\u663e\u8457\u63d0\u5347\u4e86\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u53bb\u6bd2\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u7ed3\u5408Pareto\u4f18\u5316\u7684\u5927\u8bed\u8a00\u6a21\u578b\u548cChain-of-Thought\u63d0\u793a\u662f\u63d0\u9ad8\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u53bb\u6bd2\u5316\u6027\u80fd\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u6240\u6784\u5efa\u7684BanglaNirTox\u6570\u636e\u96c6\u4e3a\u8be5\u9886\u57df\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6301\u3002"}}
{"id": "2511.01526", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01526", "abs": "https://arxiv.org/abs/2511.01526", "authors": ["Seokhoon Kang", "Yejin Jeon", "Seonjeong Hwang", "Gary Geunbae Lee"], "title": "Difficulty-Controllable Cloze Question Distractor Generation", "comment": null, "summary": "Multiple-choice cloze questions are commonly used to assess linguistic\nproficiency and comprehension. However, generating high-quality distractors\nremains challenging, as existing methods often lack adaptability and control\nover difficulty levels, and the absence of difficulty-annotated datasets\nfurther hinders progress. To address these issues, we propose a novel framework\nfor generating distractors with controllable difficulty by leveraging both data\naugmentation and a multitask learning strategy. First, to create a\nhigh-quality, difficulty-annotated dataset, we introduce a two-way distractor\ngeneration process in order to produce diverse and plausible distractors. These\ncandidates are subsequently refined through filtering and then categorized by\ndifficulty using an ensemble QA system. Second, this newly created dataset is\nleveraged to train a difficulty-controllable generation model via multitask\nlearning. The framework includes carefully designed auxiliary tasks that\nenhance the model's semantic understanding of distractors and its ability to\nestimate their difficulty. Experimental results demonstrate that our method\ngenerates high-quality distractors across difficulty levels and substantially\noutperforms GPT-4o in aligning distractor difficulty with human perception.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u751f\u6210\u53ef\u63a7\u96be\u5ea6\u7684\u5e72\u6270\u9879\u7684\u65b0\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u5e72\u6270\u9879\u8d28\u91cf\u548c\u96be\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\u7f3a\u4e4f\u7684\u95ee\u9898\u3002", "motivation": "\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u96be\u5ea6\u53ef\u63a7\u7684\u5e72\u6270\u9879\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u9002\u5e94\u6027\u548c\u96be\u5ea6\u63a7\u5236\uff0c\u540c\u65f6\u7f3a\u5c11\u96be\u5ea6\u6807\u6ce8\u6570\u636e\u96c6\u3002", "method": "\u901a\u8fc7\u4e24\u6b65\u5e72\u6270\u9879\u751f\u6210\u8fc7\u7a0b\u521b\u5efa\u591a\u6837\u4e14\u53ef\u4fe1\u7684\u5e72\u6270\u9879\u5019\u9009\uff0c\u518d\u7528\u96c6\u6210\u95ee\u7b54\u7cfb\u7edf\u8fdb\u884c\u7b5b\u9009\u4e0e\u96be\u5ea6\u5206\u7c7b\uff0c\u5229\u7528\u65b0\u6570\u636e\u96c6\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u8bad\u7ec3\u96be\u5ea6\u53ef\u63a7\u7684\u751f\u6210\u6a21\u578b\uff0c\u5e76\u8bbe\u8ba1\u8f85\u52a9\u4efb\u52a1\u63d0\u5347\u6a21\u578b\u8bed\u4e49\u7406\u89e3\u548c\u96be\u5ea6\u4f30\u8ba1\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u591a\u96be\u5ea6\u3001\u9ad8\u8d28\u91cf\u7684\u5e72\u6270\u9879\uff0c\u4e14\u5728\u5e72\u6270\u9879\u96be\u5ea6\u4e0e\u4eba\u7c7b\u611f\u77e5\u7684\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8eGPT-4o\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5e72\u6270\u9879\u751f\u6210\u4e2d\u96be\u5ea6\u63a7\u5236\u548c\u8d28\u91cf\u63d0\u5347\u7684\u95ee\u9898\uff0c\u5177\u6709\u8f83\u597d\u7684\u5b9e\u7528\u4ef7\u503c\u548c\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.01558", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.01558", "abs": "https://arxiv.org/abs/2511.01558", "authors": ["Luciana Ciringione", "Emma Franchino", "Simone Reigl", "Isaia D'Onofrio", "Anna Serbati", "Oleksandra Poquet", "Florence Gabriel", "Massimo Stella"], "title": "Math anxiety and associative knowledge structure are entwined in psychology students but not in Large Language Models like GPT-3.5 and GPT-4o", "comment": null, "summary": "Math anxiety poses significant challenges for university psychology students,\naffecting their career choices and overall well-being. This study employs a\nframework based on behavioural forma mentis networks (i.e. cognitive models\nthat map how individuals structure their associative knowledge and emotional\nperceptions of concepts) to explore individual and group differences in the\nperception and association of concepts related to math and anxiety. We\nconducted 4 experiments involving psychology undergraduates from 2 samples (n1\n= 70, n2 = 57) compared against GPT-simulated students (GPT-3.5: n2 = 300;\nGPT-4o: n4 = 300). Experiments 1, 2, and 3 employ individual-level network\nfeatures to predict psychometric scores for math anxiety and its facets\n(observational, social and evaluational) from the Math Anxiety Scale.\nExperiment 4 focuses on group-level perceptions extracted from human students,\nGPT-3.5 and GPT-4o's networks. Results indicate that, in students, positive\nvalence ratings and higher network degree for \"anxiety\", together with negative\nratings for \"math\", can predict higher total and evaluative math anxiety. In\ncontrast, these models do not work on GPT-based data because of differences in\nsimulated networks and psychometric scores compared to humans. These results\nwere also reconciled with differences found in the ways that high/low subgroups\nof simulated and real students framed semantically and emotionally STEM\nconcepts. High math-anxiety students collectively framed \"anxiety\" in an\nemotionally polarising way, absent in the negative perception of low\nmath-anxiety students. \"Science\" was rated positively, but contrasted against\nthe negative perception of \"math\". These findings underscore the importance of\nunderstanding concept perception and associations in managing students' math\nanxiety.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u8ba4\u77e5\u6a21\u578b\u63a2\u7d22\u5fc3\u7406\u5b66\u5927\u5b66\u751f\u7684\u6570\u5b66\u7126\u8651\u53ca\u5176\u5bf9\u6982\u5ff5\u8ba4\u77e5\u7684\u5f71\u54cd\uff0c\u901a\u8fc7\u4eba\u7c7b\u548cGPT\u6a21\u578b\u5bf9\u6bd4\u63ed\u793a\u60c5\u7eea\u548c\u8bed\u4e49\u7ed3\u6784\u5dee\u5f02\u3002", "motivation": "\u6570\u5b66\u7126\u8651\u5bf9\u5fc3\u7406\u5b66\u5b66\u751f\u7684\u804c\u4e1a\u9009\u62e9\u548c\u5fc3\u7406\u5065\u5eb7\u9020\u6210\u663e\u8457\u5f71\u54cd\uff0c\u7406\u89e3\u5176\u8ba4\u77e5\u548c\u60c5\u7eea\u7ed3\u6784\u6709\u52a9\u4e8e\u5e72\u9884\u548c\u7ba1\u7406\u3002", "method": "\u901a\u8fc7\u56db\u4e2a\u5b9e\u9a8c\uff0c\u6784\u5efa\u4e2a\u4f53\u53ca\u7fa4\u4f53\u7684\u884c\u4e3a\u8ba4\u77e5\u7f51\u7edc\uff0c\u4f7f\u7528\u4eba\u7c7b\u5b66\u751f\u548cGPT\u6a21\u62df\u5b66\u751f\u7684\u6570\u636e\uff0c\u5206\u6790\u6570\u5b66-\u7126\u8651\u76f8\u5173\u6982\u5ff5\u7684\u60c5\u7eea\u8bc4\u4ef7\u548c\u5173\u8054\u7ed3\u6784\uff0c\u7ed3\u5408\u5fc3\u7406\u8ba1\u91cf\u5b66\u91cf\u8868\u9884\u6d4b\u7126\u8651\u6c34\u5e73\u3002", "result": "\u5728\u771f\u5b9e\u5b66\u751f\u4e2d\uff0c\u7126\u8651\u7684\u6b63\u9762\u60c5\u7eea\u8bc4\u5206\u53ca\u7f51\u7edc\u8fde\u63a5\u5ea6\u9ad8\u4e0e\u6570\u5b66\u7684\u8d1f\u9762\u8bc4\u5206\u5171\u540c\u9884\u6d4b\u8f83\u9ad8\u7684\u6570\u5b66\u7126\u8651\uff0c\u4f46GPT\u6570\u636e\u6a21\u578b\u672a\u80fd\u6709\u6548\u9884\u6d4b\uff0c\u8868\u660e\u6a21\u62df\u4eba\u7fa4\u5728\u8ba4\u77e5\u7f51\u7edc\u7ed3\u6784\u4e0e\u7126\u8651\u611f\u77e5\u4e0a\u7684\u5dee\u5f02\u3002\u9ad8\u7126\u8651\u5b66\u751f\u5728\u6982\u5ff5\u6846\u67b6\u4e0a\u8868\u73b0\u51fa\u60c5\u7eea\u6781\u5316\uff0c\u79d1\u5b66\u88ab\u6b63\u9762\u8bc4\u4ef7\u4f46\u6570\u5b66\u88ab\u8d1f\u9762\u770b\u5f85\u3002", "conclusion": "\u7406\u89e3\u5b66\u751f\u5bf9\u6570\u5b66\u4e0e\u7126\u8651\u76f8\u5173\u6982\u5ff5\u7684\u60c5\u7eea\u548c\u8bed\u4e49\u7ed3\u6784\uff0c\u6709\u52a9\u4e8e\u66f4\u6709\u6548\u5730\u7ba1\u7406\u548c\u5e72\u9884\u6570\u5b66\u7126\u8651\uff0c\u4fc3\u8fdb\u5b66\u751f\u804c\u4e1a\u53d1\u5c55\u548c\u5fc3\u7406\u5065\u5eb7\u3002"}}
{"id": "2511.01568", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01568", "abs": "https://arxiv.org/abs/2511.01568", "authors": ["Seungmin Shin", "Dooyoung Kim", "Youngjoong Ko"], "title": "ECO Decoding: Entropy-Based Control for Controllability and Fluency in Controllable Dialogue Generation", "comment": "Published at EMNLP 2025 main", "summary": "Controllable Dialogue Generation (CDG) enables chatbots to generate responses\nwith desired attributes, and weighted decoding methods have achieved\nsignificant success in the CDG task. However, using a fixed constant value to\nmanage the bias of attribute probabilities makes it challenging to find an\nideal control strength that satisfies both controllability and fluency. To\naddress this issue, we propose ECO decoding (Entropy-based COntrol), which\ndynamically adjusts the control strength at each generation step according to\nthe model's entropy in both the language model and attribute classifier\nprobability distributions. Experiments on the DailyDialog and MultiWOZ datasets\ndemonstrate that ECO decoding consistently improves controllability while\nmaintaining fluency and grammaticality, outperforming prior decoding methods\nacross various models and settings. Furthermore, ECO decoding alleviates\nprobability interpolation issues in multi-attribute generation and consequently\ndemonstrates strong performance in both single and multi-attribute scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u71b5\u63a7\u5236\u7684\u52a8\u6001\u8c03\u8282\u751f\u6210\u6b65\u9aa4\u4e2d\u5c5e\u6027\u63a7\u5236\u5f3a\u5ea6\u7684\u89e3\u7801\u65b9\u6cd5ECO\u89e3\u7801\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8bdd\u751f\u6210\u7684\u53ef\u63a7\u6027\u4e0e\u6d41\u7545\u5ea6\u3002", "motivation": "\u73b0\u6709CDG\u65b9\u6cd5\u4e2d\uff0c\u4f7f\u7528\u56fa\u5b9a\u5e38\u6570\u503c\u8c03\u8282\u5c5e\u6027\u6982\u7387\u504f\u5dee\uff0c\u96be\u4ee5\u517c\u987e\u53ef\u63a7\u6027\u548c\u8bed\u8a00\u6d41\u7545\u6027\u3002", "method": "\u63d0\u51faECO\u89e3\u7801\uff0c\u4f9d\u636e\u8bed\u8a00\u6a21\u578b\u548c\u5c5e\u6027\u5206\u7c7b\u6982\u7387\u5206\u5e03\u7684\u71b5\u52a8\u6001\u8c03\u6574\u63a7\u5236\u5f3a\u5ea6\u3002", "result": "\u5728DailyDialog\u548cMultiWOZ\u6570\u636e\u96c6\u4e0a\uff0cECO\u89e3\u7801\u63d0\u5347\u4e86\u53ef\u63a7\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6d41\u7545\u6027\u548c\u8bed\u6cd5\u6b63\u786e\u6027\uff0c\u4e14\u4f18\u4e8e\u5148\u524d\u89e3\u7801\u65b9\u6cd5\u3002", "conclusion": "ECO\u89e3\u7801\u6709\u6548\u7f13\u89e3\u591a\u5c5e\u6027\u751f\u6210\u4e2d\u7684\u6982\u7387\u63d2\u503c\u95ee\u9898\uff0c\u5728\u5355\u5c5e\u6027\u548c\u591a\u5c5e\u6027\u751f\u6210\u573a\u666f\u5747\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2511.01589", "categories": ["cs.CL", "I.2.7"], "pdf": "https://arxiv.org/pdf/2511.01589", "abs": "https://arxiv.org/abs/2511.01589", "authors": ["Wenjie Hua", "Hoang H. Nguyen", "Gangyan Ge"], "title": "BIRD: Bronze Inscription Restoration and Dating", "comment": "Accepted at EMNLP 2025 (Main Conference)", "summary": "Bronze inscriptions from early China are fragmentary and difficult to date.\nWe introduce BIRD(Bronze Inscription Restoration and Dating), a fully encoded\ndataset grounded in standard scholarly transcriptions and chronological labels.\nWe further propose an allograph-aware masked language modeling framework that\nintegrates domain- and task-adaptive pretraining with a Glyph Net (GN), which\nlinks graphemes and allographs. Experiments show that GN improves restoration,\nwhile glyph-biased sampling yields gains in dating.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u57fa\u4e8e\u6807\u51c6\u5b66\u672f\u6284\u672c\u548c\u65f6\u95f4\u6807\u7b7e\u7684\u9752\u94dc\u94ed\u6587\u6570\u636e\u96c6BIRD\uff0c\u63d0\u51fa\u4e86\u7ed3\u5408\u5b57\u5f62\u7f51\u7edc\u7684\u5168\u5f62\u6001\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u63d0\u5347\u94ed\u6587\u4fee\u590d\u548c\u5e74\u4ee3\u65ad\u4ee3\u7684\u6548\u679c\u3002", "motivation": "\u65e9\u671f\u4e2d\u56fd\u9752\u94dc\u94ed\u6587\u5b58\u5728\u788e\u7247\u5316\u4e14\u96be\u4ee5\u51c6\u786e\u65ad\u4ee3\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u6709\u6548\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u8fdb\u884c\u4fee\u590d\u4e0e\u65ad\u4ee3\u7814\u7a76\u3002", "method": "\u6784\u5efa\u4e86BIRD\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u7ed3\u5408\u5b57\u5f62\u7f51\u7edc\uff08Glyph Net\uff0cGN\uff09\u7684\u5168\u5f62\u6001\u63a9\u7801\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u9886\u57df\u548c\u4efb\u52a1\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u6765\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5b57\u5f62\u7f51\u7edc\u80fd\u663e\u8457\u63d0\u5347\u94ed\u6587\u4fee\u590d\u51c6\u786e\u7387\uff0c\u91c7\u7528\u5b57\u5f62\u504f\u7f6e\u91c7\u6837\u7b56\u7565\u6709\u52a9\u4e8e\u63d0\u9ad8\u65ad\u4ee3\u6548\u679c\u3002", "conclusion": "\u5f15\u5165\u5b57\u5f62\u4fe1\u606f\u7684\u8bed\u8a00\u6a21\u578b\u548c\u5b9a\u5236\u91c7\u6837\u65b9\u6cd5\u6709\u6548\u4fc3\u8fdb\u4e86\u9752\u94dc\u94ed\u6587\u7684\u81ea\u52a8\u4fee\u590d\u4e0e\u65ad\u4ee3\uff0c\u9a8c\u8bc1\u4e86BIRD\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.01615", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01615", "abs": "https://arxiv.org/abs/2511.01615", "authors": ["Francisco Portillo L\u00f3pez"], "title": "Imperfect Language, Artificial Intelligence, and the Human Mind: An Interdisciplinary Approach to Linguistic Errors in Native Spanish Speakers", "comment": "12 pages, 3 figures", "summary": "Linguistic errors are not merely deviations from normative grammar; they\noffer a unique window into the cognitive architecture of language and expose\nthe current limitations of artificial systems that seek to replicate them. This\nproject proposes an interdisciplinary study of linguistic errors produced by\nnative Spanish speakers, with the aim of analyzing how current large language\nmodels (LLM) interpret, reproduce, or correct them. The research integrates\nthree core perspectives: theoretical linguistics, to classify and understand\nthe nature of the errors; neurolinguistics, to contextualize them within\nreal-time language processing in the brain; and natural language processing\n(NLP), to evaluate their interpretation against linguistic errors. A\npurpose-built corpus of authentic errors of native Spanish (+500) will serve as\nthe foundation for empirical analysis. These errors will be tested against AI\nmodels such as GPT or Gemini to assess their interpretative accuracy and their\nability to generalize patterns of human linguistic behavior. The project\ncontributes not only to the understanding of Spanish as a native language but\nalso to the development of NLP systems that are more cognitively informed and\ncapable of engaging with the imperfect, variable, and often ambiguous nature of\nreal human language.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5206\u6790\u897f\u73ed\u7259\u6bcd\u8bed\u8005\u7684\u8bed\u8a00\u9519\u8bef\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8fd9\u4e9b\u9519\u8bef\u7684\u7406\u89e3\u548c\u7ea0\u6b63\u80fd\u529b\u3002", "motivation": "\u8bed\u8a00\u9519\u8bef\u53cd\u6620\u4e86\u8bed\u8a00\u7684\u8ba4\u77e5\u7ed3\u6784\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u7684\u5c40\u9650\u6027\uff0c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u9519\u8bef\u5206\u6790\u4fc3\u8fdb\u5bf9\u8bed\u8a00\u548cAI\u7cfb\u7edf\u7684\u6df1\u523b\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u7406\u8bba\u8bed\u8a00\u5b66\u3001\u795e\u7ecf\u8bed\u8a00\u5b66\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\uff0c\u5229\u7528\u4e00\u4e2a\u5305\u542b500\u591a\u4e2a\u771f\u5b9e\u9519\u8bef\u7684\u897f\u73ed\u7259\u8bed\u8bed\u6599\u5e93\uff0c\u6d4b\u8bd5GPT\u548cGemini\u7b49\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bed\u8a00\u9519\u8bef\u7684\u89e3\u91ca\u53ca\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u8be5\u7814\u7a76\u9884\u8ba1\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u771f\u5b9e\u8bed\u8a00\u9519\u8bef\u65f6\u7684\u8868\u73b0\u53ca\u5176\u8ba4\u77e5\u76f8\u5173\u6027\uff0c\u4fc3\u8fdb\u66f4\u5177\u8ba4\u77e5\u6027\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u5f00\u53d1\u3002", "conclusion": "\u8be5\u9879\u76ee\u4e0d\u4ec5\u6df1\u5316\u4e86\u5bf9\u897f\u73ed\u7259\u8bed\u8bed\u8a00\u9519\u8bef\u7684\u7406\u89e3\uff0c\u4e5f\u63a8\u52a8\u4e86\u8ba4\u77e5\u5bfc\u5411\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4f7f\u5176\u66f4\u597d\u5730\u5904\u7406\u4eba\u7c7b\u8bed\u8a00\u7684\u591a\u6837\u6027\u548c\u4e0d\u786e\u5b9a\u6027\u3002"}}
{"id": "2511.01619", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01619", "abs": "https://arxiv.org/abs/2511.01619", "authors": ["Nikola Ljube\u0161i\u0107", "Peter Rupnik", "Ivan Porupski", "Taja Kuzman Punger\u0161ek"], "title": "ParlaSpeech 3.0: Richly Annotated Spoken Parliamentary Corpora of Croatian, Czech, Polish, and Serbian", "comment": "Submitted to the LREC 2026 conference; 11 pages, 2 figures, 3 tables", "summary": "ParlaSpeech is a collection of spoken parliamentary corpora currently\nspanning four Slavic languages - Croatian, Czech, Polish and Serbian - all\ntogether 6 thousand hours in size. The corpora were built in an automatic\nfashion from the ParlaMint transcripts and their corresponding metadata, which\nwere aligned to the speech recordings of each corresponding parliament. In this\nrelease of the dataset, each of the corpora is significantly enriched with\nvarious automatic annotation layers. The textual modality of all four corpora\nhas been enriched with linguistic annotations and sentiment predictions.\nSimilar to that, their spoken modality has been automatically enriched with\noccurrences of filled pauses, the most frequent disfluency in typical speech.\nTwo out of the four languages have been additionally enriched with detailed\nword- and grapheme-level alignments, and the automatic annotation of the\nposition of primary stress in multisyllabic words. With these enrichments, the\nusefulness of the underlying corpora has been drastically increased for\ndownstream research across multiple disciplines, which we showcase through an\nanalysis of acoustic correlates of sentiment. All the corpora are made\navailable for download in JSONL and TextGrid formats, as well as for search\nthrough a concordancer.", "AI": {"tldr": "ParlaSpeech\u5305\u542b\u56db\u79cd\u65af\u62c9\u592b\u8bed\u7684\u8bae\u4f1a\u8bed\u6599\u5e93\uff0c\u51716\u5343\u5c0f\u65f6\uff0c\u901a\u8fc7\u81ea\u52a8\u6ce8\u91ca\u5927\u5e45\u63d0\u5347\u4e86\u8bed\u6599\u7684\u7814\u7a76\u4ef7\u503c\u3002", "motivation": "\u5efa\u7acb\u5927\u89c4\u6a21\u4e14\u591a\u8bed\u8a00\u7684\u8bae\u4f1a\u8bed\u6599\u5e93\uff0c\u4e30\u5bcc\u6ce8\u91ca\u5c42\u4ee5\u652f\u6301\u591a\u5b66\u79d1\u7814\u7a76\u3002", "method": "\u81ea\u52a8\u4eceParlaMint\u8f6c\u5f55\u548c\u5143\u6570\u636e\u6784\u5efa\u8bed\u6599\u5e93\uff0c\u6dfb\u52a0\u8bed\u8a00\u5b66\u6ce8\u91ca\u3001\u60c5\u611f\u9884\u6d4b\u3001\u8bed\u97f3\u505c\u987f\u6807\u6ce8\u53ca\u8bcd\u6c47\u5bf9\u9f50\u548c\u91cd\u97f3\u4f4d\u7f6e\u6ce8\u91ca\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b\u4e30\u5bcc\u6ce8\u91ca\u3001\u6db5\u76d6\u56db\u79cd\u8bed\u8a00\u76846\u5343\u5c0f\u65f6\u8bed\u6599\u5e93\uff0c\u5e76\u5c55\u793a\u4e86\u60c5\u611f\u58f0\u5b66\u76f8\u5173\u5206\u6790\u7684\u5e94\u7528\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u6ce8\u91ca\u589e\u5f3a\u7684\u591a\u8bed\u8a00\u5927\u89c4\u6a21\u8bae\u4f1a\u8bed\u6599\u5e93\u6781\u5927\u63d0\u5347\u4e86\u5176\u5b66\u672f\u7814\u7a76\u4ef7\u503c\uff0c\u5df2\u516c\u5f00\u53d1\u5e03\u4f9b\u4e0b\u8f7d\u548c\u68c0\u7d22\u3002"}}
{"id": "2511.01643", "categories": ["cs.CL", "cs.AI", "cs.IR", "I.2.7; I.2.4; I.2.1; I.2.6"], "pdf": "https://arxiv.org/pdf/2511.01643", "abs": "https://arxiv.org/abs/2511.01643", "authors": ["Riccardo Campi", "Nicol\u00f2 Oreste Pinciroli Vago", "Mathyas Giudici", "Pablo Barrachina Rodriguez-Guisado", "Marco Brambilla", "Piero Fraternali"], "title": "A Graph-based RAG for Energy Efficiency Question Answering", "comment": null, "summary": "In this work, we investigate the use of Large Language Models (LLMs) within a\ngraph-based Retrieval Augmented Generation (RAG) architecture for Energy\nEfficiency (EE) Question Answering. First, the system automatically extracts a\nKnowledge Graph (KG) from guidance and regulatory documents in the energy\nfield. Then, the generated graph is navigated and reasoned upon to provide\nusers with accurate answers in multiple languages. We implement a human-based\nvalidation using the RAGAs framework properties, a validation dataset\ncomprising 101 question-answer pairs, and domain experts. Results confirm the\npotential of this architecture and identify its strengths and weaknesses.\nValidation results show how the system correctly answers in about three out of\nfour of the cases (75.2 +- 2.7%), with higher results on questions related to\nmore general EE answers (up to 81.0 +- 4.1%), and featuring promising\nmultilingual abilities (4.4% accuracy loss due to translation).", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u56fe\u8c31\u589e\u5f3a\u751f\u6210\u7684\u80fd\u6e90\u6548\u7387\u95ee\u7b54\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u52a8\u6784\u5efa\u77e5\u8bc6\u56fe\u8c31\u5e76\u8fdb\u884c\u591a\u8bed\u8a00\u63a8\u7406\uff0c\u8fbe\u5230\u7ea675%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u80fd\u6e90\u6548\u7387\u9886\u57df\u4fe1\u606f\u4e30\u5bcc\u4f46\u590d\u6742\uff0c\u9700\u81ea\u52a8\u5316\u7cfb\u7edf\u51c6\u786e\u56de\u7b54\u7528\u6237\u63d0\u95ee\uff0c\u4e14\u652f\u6301\u591a\u8bed\u8a00\u3002", "method": "\u4ece\u80fd\u6e90\u6307\u5bfc\u548c\u6cd5\u89c4\u6587\u4ef6\u4e2d\u81ea\u52a8\u62bd\u53d6\u77e5\u8bc6\u56fe\u8c31\uff0c\u4f7f\u7528\u57fa\u4e8e\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u67b6\u6784\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u591a\u8bed\u8a00\u95ee\u7b54\u3002", "result": "\u7cfb\u7edf\u5728101\u4e2a\u95ee\u7b54\u5bf9\u9a8c\u8bc1\u96c6\u4e0a\u51c6\u786e\u7387\u4e3a75.2%\uff0c\u5728\u66f4\u4e00\u822c\u6027\u7684\u80fd\u6e90\u6548\u7387\u95ee\u9898\u4e0a\u51c6\u786e\u7387\u63d0\u5347\u81f381.0%\uff0c\u591a\u8bed\u8a00\u95ee\u7b54\u51c6\u786e\u7387\u4ec5\u964d\u4f4e4.4%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u80fd\u6e90\u6548\u7387\u95ee\u7b54\u7684\u51c6\u786e\u7387\u548c\u591a\u8bed\u8a00\u652f\u6301\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u56fe\u7684RAG\u67b6\u6784\u7ed3\u5408LLM\u7684\u6f5c\u529b\u53ca\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2511.01649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01649", "abs": "https://arxiv.org/abs/2511.01649", "authors": ["Hung-Shin Lee", "Chen-Chi Chang", "Ching-Yuan Chen", "Yun-Hsiang Hsu"], "title": "Evaluating Cultural Knowledge Processing in Large Language Models: A Cognitive Benchmarking Framework Integrating Retrieval-Augmented Generation", "comment": "This paper has been accepted by The Electronic Library, and the full\n  article is now available on Emerald Insight", "summary": "This study proposes a cognitive benchmarking framework to evaluate how large\nlanguage models (LLMs) process and apply culturally specific knowledge. The\nframework integrates Bloom's Taxonomy with Retrieval-Augmented Generation (RAG)\nto assess model performance across six hierarchical cognitive domains:\nRemembering, Understanding, Applying, Analyzing, Evaluating, and Creating.\nUsing a curated Taiwanese Hakka digital cultural archive as the primary\ntestbed, the evaluation measures LLM-generated responses' semantic accuracy and\ncultural relevance.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u878d\u5408Bloom\u5206\u7c7b\u6cd5\u4e0e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u8ba4\u77e5\u57fa\u51c6\u8bc4\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7279\u5b9a\u6587\u5316\u77e5\u8bc6\u7684\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u548c\u5e94\u7528\u7279\u5b9a\u6587\u5316\u77e5\u8bc6\u65b9\u9762\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u7684\u95ee\u9898\u3002", "method": "\u7ed3\u5408Bloom\u7684\u516d\u4e2a\u8ba4\u77e5\u5c42\u7ea7\uff08\u8bb0\u5fc6\u3001\u7406\u89e3\u3001\u5e94\u7528\u3001\u5206\u6790\u3001\u8bc4\u4ef7\u3001\u521b\u9020\uff09\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u5728\u53f0\u6e7e\u5ba2\u5bb6\u6587\u5316\u6570\u5b57\u6863\u6848\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6a21\u578b\u56de\u7b54\u7684\u8bed\u4e49\u51c6\u786e\u6027\u548c\u6587\u5316\u76f8\u5173\u6027\u3002", "result": "\u8be5\u6846\u67b6\u6709\u6548\u5730\u6d4b\u91cf\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u8ba4\u77e5\u5c42\u7ea7\u4e0b\u5bf9\u6587\u5316\u77e5\u8bc6\u7684\u5904\u7406\u8868\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5206\u6790\u548c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u7279\u5b9a\u6587\u5316\u77e5\u8bc6\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u4e14\u5206\u5c42\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2511.01650", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01650", "abs": "https://arxiv.org/abs/2511.01650", "authors": ["Ayesha Gull", "Muhammad Usman Safder", "Rania Elbadry", "Preslav Nakov", "Zhuohan Xie"], "title": "EngChain: A Symbolic Benchmark for Verifiable Multi-Step Reasoning in Engineering", "comment": "24 pages, includes figures and tables; introduces the EngChain\n  benchmark", "summary": "Large Language Models (LLMs) are increasingly being applied to specialized,\nhigh-stakes domains like engineering, which demands rigorous evaluation of\ntheir complex reasoning capabilities. While current benchmarks assess language\nunderstanding, factual recall, mathematics or code generation, none capture the\nintegrative reasoning central to engineering where scientific principles,\nquantitative modeling and practical constraints must converge. To address this\ngap, we introduce EngChain, a benchmark for verifiable multi-step engineering\nproblem-solving. EngChain contains 90 problems spanning three engineering\nbranches, organized into 9 domains and 20 distinct areas. The problems are\ngenerated from symbolic templates with a high degree of randomization to ensure\ndiversity and eliminate the risk of contamination. With this benchmark, we move\nbeyond final answer accuracy with a two-stage evaluation: we first\nquantitatively verify the numerical and semantic validity of each reasoning\nstep and then introduce LLM-As-A-Judge, an automated system to qualitatively\ncategorize the identified reasoning errors.", "AI": {"tldr": "\u63d0\u51fa\u4e86EngChain\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u591a\u6b65\u9aa4\u63a8\u7406\u7684\u80fd\u529b\uff0c\u5305\u542b90\u4e2a\u591a\u6837\u5316\u95ee\u9898\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u8bc4\u4f30\u65b9\u6cd5\u9a8c\u8bc1\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u503c\u548c\u8bed\u4e49\u6709\u6548\u6027\uff0c\u5e76\u5229\u7528\u81ea\u52a8\u5224\u5b9a\u7cfb\u7edf\u5206\u7c7b\u63a8\u7406\u9519\u8bef\u3002", "motivation": "\u5f53\u524d\u57fa\u51c6\u6d4b\u8bd5\u65e0\u6cd5\u6709\u6548\u8861\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9886\u57df\u590d\u6742\u7684\u96c6\u6210\u63a8\u7406\u80fd\u529b\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u9488\u5bf9\u5de5\u7a0b\u591a\u6b65\u9aa4\u95ee\u9898\u89e3\u51b3\u7684\u8bc4\u4ef7\u4f53\u7cfb\u3002", "method": "\u8bbe\u8ba1EngChain\u57fa\u51c6\uff0c\u5305\u542b\u591a\u5206\u652f\u3001\u591a\u4e2a\u9886\u57df\u7684\u591a\u6b65\u9aa4\u5de5\u7a0b\u95ee\u9898\uff0c\u95ee\u9898\u901a\u8fc7\u7b26\u53f7\u6a21\u677f\u968f\u673a\u751f\u6210\u4ee5\u4fdd\u8bc1\u591a\u6837\u6027\u548c\u65e0\u6c61\u67d3\u3002\u8bc4\u4f30\u91c7\u7528\u4e24\u9636\u6bb5\uff0c\u5148\u91cf\u5316\u9a8c\u8bc1\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u503c\u4e0e\u8bed\u4e49\u6709\u6548\u6027\uff0c\u518d\u7531LLM-As-A-Judge\u81ea\u52a8\u7cfb\u7edf\u5bf9\u63a8\u7406\u9519\u8bef\u8fdb\u884c\u5b9a\u6027\u5206\u7c7b\u3002", "result": "\u63d0\u51fa\u7684EngChain\u57fa\u51c6\u53ca\u8bc4\u4f30\u65b9\u6cd5\u80fd\u591f\u7ec6\u81f4\u9a8c\u8bc1\u548c\u5206\u7c7b\u6a21\u578b\u5728\u5de5\u7a0b\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u9519\u8bef\uff0c\u5e2e\u52a9\u66f4\u5168\u9762\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5de5\u7a0b\u5e94\u7528\u80fd\u529b\u3002", "conclusion": "EngChain\u586b\u8865\u4e86\u73b0\u6709\u8bc4\u6d4b\u7684\u7a7a\u767d\uff0c\u4e3a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5de5\u7a0b\u9ad8\u98ce\u9669\u9886\u57df\u7684\u591a\u6b65\u9aa4\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u7cfb\u7edf\u3001\u53ef\u9a8c\u8bc1\u3001\u81ea\u52a8\u5316\u7684\u8bc4\u4f30\u5de5\u5177\u3002"}}
{"id": "2511.01670", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01670", "abs": "https://arxiv.org/abs/2511.01670", "authors": ["Chaoqun Liu", "Mahani Aljunied", "Guizhen Chen", "Hou Pong Chan", "Weiwen Xu", "Yu Rong", "Wenxuan Zhang"], "title": "SeaLLMs-Audio: Large Audio-Language Models for Southeast Asia", "comment": "10 pages", "summary": "We introduce SeaLLMs-Audio, the first large audio-language model (LALM)\ntailored for multiple Southeast Asian (SEA) languages-Indonesian (id), Thai\n(th), and Vietnamese (vi)-alongside English (en) and Chinese (zh). Trained on a\nlarge-scale audio corpus, SeaLLMs-Audio exhibits strong performance across\ndiverse audio-centric tasks, spanning fine-grained audio understanding and\nvoice-based interaction. Its key features include: 1) Multilingual: the model\nprimarily supports 5 languages, namely Indonesian, Thai, Vietnamese, English,\nand Chinese; 2) Multimodal: the model accepts flexible input modalities,\nincluding audio only, text only, as well as audio with text; 3) Multi-task: the\nmodel supports a wide range of tasks, including audio analysis tasks such as\nAudio Captioning, Automatic Speech Recognition, Speech-to-Text Translation,\nSpeech Emotion Recognition, Speech Question Answering, and Speech\nSummarization. It also enables voice-based dialogue, including answering\nfactual, mathematical, and general knowledge queries. As a significant step\ntowards advancing audio LLMs in Southeast Asia, we expect SeaLLMs-Audio to\nbenefit both the regional research community and industry. To automate LALM\nevaluation for Southeast Asia, we introduce SeaBench-Audio, a benchmark\nspanning multiple tasks. Experiments show that SeaLLMs-Audio achieves\ncompetitive performance compared with other LALMs on SEA languages.", "AI": {"tldr": "SeaLLMs-Audio\u662f\u9996\u4e2a\u9488\u5bf9\u4e1c\u5357\u4e9a\u591a\u8bed\u8a00\uff08\u5370\u5c3c\u8bed\u3001\u6cf0\u8bed\u3001\u8d8a\u5357\u8bed\uff09\u53ca\u82f1\u8bed\u3001\u4e2d\u6587\u7684\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u591a\u6a21\u6001\u591a\u4efb\u52a1\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u9488\u5bf9\u4e1c\u5357\u4e9a\u591a\u8bed\u8a00\u73af\u5883\uff0c\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u5904\u7406\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u7684\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u63a8\u52a8\u8be5\u5730\u533a\u97f3\u9891\u7406\u89e3\u548c\u8bed\u97f3\u4ea4\u4e92\u6280\u672f\u53d1\u5c55\u3002", "method": "\u8bad\u7ec3\u4e86\u4e00\u4e2a\u5927\u578b\u97f3\u9891\u8bed\u6599\u5e93\uff0c\u8bbe\u8ba1\u652f\u63015\u79cd\u8bed\u8a00\uff08id\u3001th\u3001vi\u3001en\u3001zh\uff09\uff0c\u5e76\u652f\u6301\u97f3\u9891\u3001\u6587\u672c\u53ca\u4e24\u8005\u7ed3\u5408\u8f93\u5165\uff0c\u8986\u76d6\u97f3\u9891\u5b57\u5e55\u751f\u6210\u3001\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u7ffb\u8bd1\u3001\u60c5\u611f\u8bc6\u522b\u3001\u95ee\u7b54\u53ca\u6458\u8981\u7b49\u4efb\u52a1\u3002", "result": "SeaLLMs-Audio\u5728\u591a\u9879\u4efb\u52a1\u4e0e\u4e1c\u5357\u4e9a\u8bed\u8a00\u4e0a\u8868\u73b0\u51fa\u7ade\u4e89\u529b\uff0c\u540c\u65f6\u5f00\u53d1\u4e86SeaBench-Audio\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4fc3\u8fdb\u81ea\u52a8\u5316\u8bc4\u4f30\u3002", "conclusion": "SeaLLMs-Audio\u4e3a\u63a8\u52a8\u4e1c\u5357\u4e9a\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u548c\u4ea7\u4e1a\u5e94\u7528\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u5177\u5907\u826f\u597d\u591a\u8bed\u8a00\u3001\u591a\u6a21\u6001\u3001\u591a\u4efb\u52a1\u80fd\u529b\uff0c\u9884\u793a\u5176\u5728\u533a\u57df\u5185\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.01689", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01689", "abs": "https://arxiv.org/abs/2511.01689", "authors": ["Sharan Maiya", "Henning Bartsch", "Nathan Lambert", "Evan Hubinger"], "title": "Open Character Training: Shaping the Persona of AI Assistants through Constitutional AI", "comment": "12 pages, 6 figures, 4 tables", "summary": "The character of the \"AI assistant\" persona generated by modern chatbot large\nlanguage models influences both surface-level behavior and apparent values,\nbeliefs, and ethics. These all affect interaction quality, perceived\nintelligence, and alignment with both developer and user intentions. The\nshaping of this persona, known as character training, is a critical component\nof industry post-training, yet remains effectively unstudied in the academic\nliterature. We introduce the first open implementation of character training,\nleveraging Constitutional AI and a new data pipeline using synthetic\nintrospective data to shape the assistant persona in a more effective and\ncontrolled manner than alternatives such as constraining system prompts or\nactivation steering. Specifically, we fine-tune three popular open-weights\nmodels using 11 example personas, such as humorous, deeply caring, or even\nmalevolent. To track the effects of our approach, we introduce a method which\nanalyzes revealed preferences, uncovering clear and holistic changes in\ncharacter. We find these changes are more robust to adversarial prompting than\nthe above two alternatives, while also leading to more coherent and realistic\ngenerations. Finally, we demonstrate this fine-tuning has little to no effect\non general capabilities as measured by common benchmarks. We describe and\nopen-source our full post-training method, the implementation of which can be\nfound at https://github.com/maiush/OpenCharacterTraining.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u516c\u5f00\u5b9e\u73b0\u4e86\u5229\u7528\u5408\u5baaAI\u548c\u5408\u6210\u5185\u7701\u6570\u636e\u8fdb\u884c\u89d2\u8272\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u7528\u4ee5\u6709\u6548\u5851\u9020\u804a\u5929\u673a\u5668\u4eba\u89d2\u8272\u4e2a\u6027\uff0c\u63d0\u5347\u751f\u6210\u5185\u5bb9\u7684\u8fde\u8d2f\u6027\u548c\u6297\u5bf9\u6297\u6027\uff0c\u540c\u65f6\u5bf9\u6a21\u578b\u901a\u7528\u80fd\u529b\u5f71\u54cd\u751a\u5fae\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u201cAI\u52a9\u624b\u201d\u89d2\u8272\u5f71\u54cd\u884c\u4e3a\u548c\u4ef7\u503c\u89c2\uff0c\u8fdb\u800c\u5f71\u54cd\u4ea4\u4e92\u8d28\u91cf\u53ca\u5bf9\u667a\u80fd\u6027\u7684\u8ba4\u77e5\uff0c\u4f46\u89d2\u8272\u8bad\u7ec3\u4f5c\u4e3a\u540e\u8bad\u7ec3\u5173\u952e\u73af\u8282\uff0c\u5374\u9c9c\u6709\u5b66\u672f\u7814\u7a76\u3002", "method": "\u5f15\u5165\u57fa\u4e8e\u5408\u5baaAI\u7684\u65b0\u6570\u636e\u7ba1\u9053\uff0c\u901a\u8fc7\u5408\u6210\u5185\u7701\u6570\u636e\u5fae\u8c03\u4e09\u6b3e\u6d41\u884c\u5f00\u6e90\u6a21\u578b\uff0c\u5851\u902011\u79cd\u793a\u8303\u89d2\u8272\uff08\u5982\u5e7d\u9ed8\u3001\u5173\u6000\u3001\u6076\u610f\u7b49\uff09\uff0c\u5e76\u8bbe\u8ba1\u63ed\u793a\u504f\u597d\u5206\u6790\u65b9\u6cd5\u8ffd\u8e2a\u89d2\u8272\u53d8\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u89d2\u8272\u8bad\u7ec3\u65b9\u6cd5\u5bf9\u6297\u5bf9\u6297\u6027\u63d0\u793a\u66f4\u4e3a\u9c81\u68d2\uff0c\u751f\u6210\u5185\u5bb9\u66f4\u52a0\u8fde\u8d2f\u771f\u5b9e\uff0c\u4e14\u5bf9\u901a\u7528\u80fd\u529b\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u63a7\u7684\u89d2\u8272\u8bad\u7ec3\u65b9\u6848\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u4e2a\u6027\u5316\u8868\u8fbe\u4e0e\u4ea4\u4e92\u8d28\u91cf\uff0c\u5f00\u6e90\u4ee3\u7801\u5229\u4e8e\u4e1a\u754c\u53ca\u5b66\u672f\u754c\u8fdb\u4e00\u6b65\u5e94\u7528\u4e0e\u7814\u7a76\u3002"}}
{"id": "2511.01706", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01706", "abs": "https://arxiv.org/abs/2511.01706", "authors": ["Sekh Mainul Islam", "Pepa Atanasova", "Isabelle Augenstein"], "title": "Multi-Step Knowledge Interaction Analysis via Rank-2 Subspace Disentanglement", "comment": "Under review", "summary": "Natural Language Explanations (NLEs) describe how Large Language Models\n(LLMs) make decisions, drawing on both external Context Knowledge (CK) and\nParametric Knowledge (PK) stored in model weights. Understanding their\ninteraction is key to assessing the grounding of NLEs, yet it remains\nunderexplored. Prior work has largely examined only single-step generation,\ntypically the final answer, and has modelled PK and CK interaction only as a\nbinary choice in a rank-1 subspace. This overlooks richer forms of interaction,\nsuch as complementary or supportive knowledge. We propose a novel rank-2\nprojection subspace that disentangles PK and CK contributions more accurately\nand use it for the first multi-step analysis of knowledge interactions across\nlonger NLE sequences. Experiments on four QA datasets and three open-weight\ninstruction-tuned LLMs show that diverse knowledge interactions are poorly\nrepresented in a rank-1 subspace but are effectively captured in our rank-2\nformulation. Our multi-step analysis reveals that hallucinated NLEs align\nstrongly with the PK direction, context-faithful ones balance PK and CK, and\nChain-of-Thought prompting for NLEs shifts generated NLEs toward CK by reducing\nPK reliance. This work provides the first framework for systematic studies of\nmulti-step knowledge interactions in LLMs through a richer rank-2 subspace\ndisentanglement. Code and data:\nhttps://github.com/copenlu/pk-ck-knowledge-disentanglement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684rank-2\u6295\u5f71\u5b50\u7a7a\u95f4\u65b9\u6cd5\uff0c\u66f4\u51c6\u786e\u5730\u533a\u5206\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u8d21\u732e\uff0c\u5b9e\u73b0\u4e86\u5bf9\u591a\u6b65\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u4e2d\u77e5\u8bc6\u4ea4\u4e92\u7684\u7cfb\u7edf\u5206\u6790\u3002", "motivation": "\u4ee5\u524d\u7684\u7814\u7a76\u53ea\u5173\u6ce8\u5355\u6b65\u751f\u6210\u548c\u53c2\u6570\u77e5\u8bc6\u4e0e\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u4e8c\u5143\u4e92\u52a8\uff0c\u5ffd\u89c6\u4e86\u4e30\u5bcc\u7684\u77e5\u8bc6\u4ea4\u4e92\u5f62\u5f0f\uff0c\u8fd9\u9650\u5236\u4e86\u5bf9NLE\u89e3\u91ca\u771f\u5b9e\u6027\u7684\u7406\u89e3\u3002", "method": "\u63d0\u51farank-2\u6295\u5f71\u5b50\u7a7a\u95f4\u6765\u5206\u79bb\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u77e5\u8bc6\u8d21\u732e\uff0c\u8fdb\u884c\u591a\u6b65\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5e8f\u5217\u7684\u5206\u6790\uff0c\u5e76\u5728\u591a\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u548c\u5f00\u6e90\u6a21\u578b\u4e0a\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0crank-1\u5b50\u7a7a\u95f4\u65e0\u6cd5\u6709\u6548\u4ee3\u8868\u591a\u6837\u7684\u77e5\u8bc6\u4ea4\u4e92\uff0crank-2\u65b9\u6cd5\u66f4\u51c6\u786e\u6355\u6349\u77e5\u8bc6\u4e92\u52a8\uff1b\u865a\u6784\u89e3\u91ca\u504f\u5411\u53c2\u6570\u77e5\u8bc6\uff0c\u5fe0\u5b9e\u89e3\u91ca\u5728\u4e24\u8005\u4e4b\u95f4\u5e73\u8861\uff0c\u601d\u8def\u94fe\u63d0\u793a\u51cf\u5c11\u5bf9\u53c2\u6570\u77e5\u8bc6\u7684\u4f9d\u8d56\uff0c\u589e\u5f3a\u4e0a\u4e0b\u6587\u77e5\u8bc6\u7684\u4f5c\u7528\u3002", "conclusion": "rank-2\u5b50\u7a7a\u95f4\u65b9\u6cd5\u4e3a\u7cfb\u7edf\u7814\u7a76\u5927\u8bed\u8a00\u6a21\u578b\u591a\u6b65\u77e5\u8bc6\u4ea4\u4e92\u63d0\u4f9b\u4e86\u9996\u4e2a\u6846\u67b6\uff0c\u4fc3\u8fdb\u5bf9\u6a21\u578b\u89e3\u91ca\u53ef\u4fe1\u5ea6\u548c\u77e5\u8bc6\u4f9d\u8d56\u6027\u7684\u6df1\u5165\u7406\u89e3\u3002"}}
{"id": "2511.01720", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01720", "abs": "https://arxiv.org/abs/2511.01720", "authors": ["Mahammad Nuriyev"], "title": "Efficient Tool-Calling Multi-Expert NPC Agent for Commonsense Persona-Grounded Dialogue", "comment": "10 pages, 1 figure, 2 tables. Technical report for the Commonsense\n  Persona-Grounded Dialogue Challenge (CPDC) 2025, part of the Wordplay 2025\n  Workshop @ EMNLP 2025", "summary": "We present a multi-expert system for creating Non-Player Characters (NPCs)\ncapable of both natural dialogue and contextual action execution in interactive\nenvironments. Using Qwen3 as the base model and Low-Rank Adaptation (LoRA)\nadapters, we instantiate three specialists: tool calling, tool-response\ninterpretation, and direct dialogue. Our system comfortably meets the\ncomputational efficiency requirements, delivering fast responses and\nmaintaining modest resource usage on L40S GPUs. In the Commonsense\nPersona-Grounded Dialogue Challenge 2025, our method ranked second overall.\n  Code available at:\nhttps://github.com/MahammadNuriyev62/CPDC-challenge-2025-solution/", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eQwen3\u6a21\u578b\u548cLoRA\u9002\u914d\u5668\u7684\u591a\u4e13\u5bb6\u7cfb\u7edf\uff0c\u7528\u4e8e\u751f\u6210\u80fd\u591f\u81ea\u7136\u5bf9\u8bdd\u548c\u6267\u884c\u60c5\u5883\u52a8\u4f5c\u7684NPC\uff0c\u7cfb\u7edf\u6548\u7387\u9ad8\uff0c\u57282025\u5e74\u5e38\u8bc6\u4eba\u683c\u5bf9\u8bdd\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e8c\u3002", "motivation": "\u63d0\u5347NPC\u5728\u4ea4\u4e92\u73af\u5883\u4e2d\u7684\u5bf9\u8bdd\u81ea\u7136\u6027\u548c\u52a8\u4f5c\u6267\u884c\u7684\u4e0a\u4e0b\u6587\u5173\u8054\u80fd\u529b\uff0c\u540c\u65f6\u4fdd\u8bc1\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u91c7\u7528Qwen3\u6a21\u578b\u7ed3\u5408LoRA\u9002\u914d\u5668\uff0c\u6784\u5efa\u5305\u62ec\u5de5\u5177\u8c03\u7528\u3001\u5de5\u5177\u54cd\u5e94\u89e3\u91ca\u548c\u76f4\u63a5\u5bf9\u8bdd\u4e09\u4e2a\u4e13\u5bb6\u6a21\u5757\u7684\u591a\u4e13\u5bb6\u7cfb\u7edf\u3002", "result": "\u7cfb\u7edf\u5728L40S GPU\u4e0a\u8d44\u6e90\u5360\u7528\u9002\u4e2d\u4e14\u54cd\u5e94\u8fc5\u901f\uff0c\u57282025\u5e74Commonsense Persona-Grounded Dialogue Challenge\u4e2d\u83b7\u5f97\u7b2c\u4e8c\u540d\u3002", "conclusion": "\u591a\u4e13\u5bb6\u7cfb\u7edf\u6709\u6548\u63d0\u5347\u4e86NPC\u7684\u5bf9\u8bdd\u548c\u52a8\u4f5c\u6267\u884c\u8868\u73b0\uff0c\u517c\u987e\u4e86\u8ba1\u7b97\u6548\u7387\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u548c\u63a8\u5e7f\u524d\u666f\u3002"}}
{"id": "2511.01805", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01805", "abs": "https://arxiv.org/abs/2511.01805", "authors": ["Jiayi Geng", "Howard Chen", "Ryan Liu", "Manoel Horta Ribeiro", "Robb Willer", "Graham Neubig", "Thomas L. Griffiths"], "title": "Accumulating Context Changes the Beliefs of Language Models", "comment": null, "summary": "Language model (LM) assistants are increasingly used in applications such as\nbrainstorming and research. Improvements in memory and context size have\nallowed these models to become more autonomous, which has also resulted in more\ntext accumulation in their context windows without explicit user intervention.\nThis comes with a latent risk: the belief profiles of models -- their\nunderstanding of the world as manifested in their responses or actions -- may\nsilently change as context accumulates. This can lead to subtly inconsistent\nuser experiences, or shifts in behavior that deviate from the original\nalignment of the models. In this paper, we explore how accumulating context by\nengaging in interactions and processing text -- talking and reading -- can\nchange the beliefs of language models, as manifested in their responses and\nbehaviors.Our results reveal that models' belief profiles are highly malleable:\nGPT-5 exhibits a 54.7% shift in its stated beliefs after 10 rounds of\ndiscussion about moral dilemmas and queries about safety, while Grok 4 shows a\n27.2% shift on political issues after reading texts from the opposing position.\nWe also examine models' behavioral changes by designing tasks that require tool\nuse, where each tool selection corresponds to an implicit belief. We find that\nthese changes align with stated belief shifts, suggesting that belief shifts\nwill be reflected in actual behavior in agentic systems. Our analysis exposes\nthe hidden risk of belief shift as models undergo extended sessions of talking\nor reading, rendering their opinions and actions unreliable.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u957f\u671f\u5bf9\u8bdd\u548c\u6587\u672c\u5904\u7406\u8fc7\u7a0b\u4e2d\uff0c\u5176\u4fe1\u5ff5\u548c\u884c\u4e3a\u53ef\u80fd\u53d1\u751f\u7684\u53d8\u5316\uff0c\u63ed\u793a\u4e86\u6a21\u578b\u4fe1\u5ff5\u53d8\u52a8\u7684\u98ce\u9669\u3002", "motivation": "\u968f\u7740\u8bed\u8a00\u6a21\u578b\u8bb0\u5fc6\u548c\u4e0a\u4e0b\u6587\u5bb9\u91cf\u63d0\u5347\uff0c\u6a21\u578b\u5728\u65e0\u7528\u6237\u663e\u5f0f\u5e72\u9884\u4e0b\u4f1a\u79ef\u7d2f\u5927\u91cf\u4e0a\u4e0b\u6587\uff0c\u8fd9\u53ef\u80fd\u5bfc\u81f4\u5176\u4fe1\u5ff5\u548c\u884c\u4e3a\u53d1\u751f\u6f5c\u79fb\u9ed8\u5316\u7684\u53d8\u5316\uff0c\u5e26\u6765\u4e0d\u4e00\u81f4\u548c\u504f\u79bb\u539f\u59cb\u76ee\u6807\u7684\u98ce\u9669\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u6d89\u53ca\u9053\u5fb7\u56f0\u5883\u3001\u5b89\u5168\u4ee5\u53ca\u653f\u6cbb\u95ee\u9898\u7684\u591a\u8f6e\u5bf9\u8bdd\u548c\u6587\u672c\u9605\u8bfb\u4efb\u52a1\uff0c\u5206\u522b\u6d4b\u8bd5GPT-5\u548cGrok 4\u6a21\u578b\u7684\u4fe1\u5ff5\u504f\u79fb\u60c5\u51b5\uff1b\u5e76\u8bbe\u8ba1\u9700\u8981\u5de5\u5177\u4f7f\u7528\u7684\u4efb\u52a1\u6765\u68c0\u6d4b\u884c\u4e3a\u4e0a\u7684\u9690\u542b\u4fe1\u5ff5\u8f6c\u53d8\u3002", "result": "GPT-5\u572810\u8f6e\u5173\u4e8e\u9053\u5fb7\u548c\u5b89\u5168\u76f8\u5173\u8bdd\u9898\u7684\u8ba8\u8bba\u540e\uff0c\u5176\u58f0\u660e\u7684\u4fe1\u5ff5\u53d8\u5316\u9ad8\u8fbe54.7%\uff1bGrok 4\u5728\u9605\u8bfb\u5bf9\u7acb\u653f\u6cbb\u7acb\u573a\u6587\u672c\u540e\u4fe1\u5ff5\u53d8\u5316\u4e3a27.2%\uff1b\u884c\u4e3a\u6d4b\u8bd5\u7ed3\u679c\u8868\u660e\u4fe1\u5ff5\u8f6c\u53d8\u4e0e\u5b9e\u9645\u884c\u4e3a\u9009\u62e9\u4e00\u81f4\u3002", "conclusion": "\u957f\u671f\u4ea4\u4e92\u548c\u9605\u8bfb\u4f1a\u5bfc\u81f4\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u5ff5\u548c\u884c\u4e3a\u663e\u8457\u53d8\u5316\uff0c\u5b58\u5728\u4fe1\u5ff5\u8fc1\u79fb\u98ce\u9669\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u4e00\u81f4\u6027\u3002\u6a21\u578b\u7684\u610f\u89c1\u548c\u884c\u4e3a\u53ef\u80fd\u53d8\u5f97\u4e0d\u7a33\u5b9a\uff0c\u9700\u5173\u6ce8\u8fd9\u4e00\u9690\u6027\u98ce\u9669\u3002"}}
{"id": "2511.01807", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01807", "abs": "https://arxiv.org/abs/2511.01807", "authors": ["Adewale Akinfaderin", "Shreyas Subramanian", "Akarsha Sehwag"], "title": "Plan-and-Write: Structure-Guided Length Control for LLMs without Model Retraining", "comment": "Presented at Workshop on Prompt Optimization, KDD 2025, Toronto,\n  Canada", "summary": "Length control in Large Language Models (LLMs) is a crucial but\nunder-addressed challenge, with applications ranging from voice interfaces\nrequiring concise responses to research summaries needing comprehensive\noutputs. Current approaches to length control, including Regularized DPO,\nLength-Instruction Fine Tuning, and tool-augmented methods, typically require\nexpensive model retraining or complex inference-time tooling. This paper\npresents a prompt engineering methodology that enables precise length control\nwithout model retraining. Our structure-guided approach implements deliberate\nplanning and word counting mechanisms within the prompt, encouraging the model\nto carefully track and adhere to specified length constraints. Comprehensive\nevaluations across six state-of-the-art LLMs demonstrate that our method\nsignificantly improves length fidelity for several models compared to standard\nprompting when applied to document summarization tasks, particularly for\nshorter-to-medium length constraints. The proposed technique shows varying\nbenefits across different model architectures, with some models demonstrating\nup to 37.6% improvement in length adherence. Quality evaluations further reveal\nthat our approach maintains or enhances overall output quality compared to\nstandard prompting techniques. Our approach provides an immediately deployable\nsolution for applications requiring precise length control, particularly\nvaluable for production environments where model retraining is impractical or\ncost-prohibitive.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u63d0\u793a\u5de5\u7a0b\u7684\u957f\u5ea6\u63a7\u5236\u65b9\u6cd5\uff0c\u65e0\u9700\u6a21\u578b\u518d\u8bad\u7ec3\uff0c\u5373\u53ef\u5b9e\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u957f\u5ea6\u7684\u7cbe\u786e\u63a7\u5236\uff0c\u7279\u522b\u9002\u7528\u4e8e\u6587\u6863\u6458\u8981\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u5ea6\u63a7\u5236\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u6602\u8d35\u7684\u6a21\u578b\u518d\u8bad\u7ec3\u6216\u590d\u6742\u7684\u63a8\u7406\u5de5\u5177\uff0c\u9650\u5236\u4e86\u5b9e\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5728\u63d0\u793a\u4e2d\u5f15\u5165\u7ed3\u6784\u5316\u89c4\u5212\u548c\u8ba1\u6570\u673a\u5236\uff0c\u6307\u5bfc\u6a21\u578b\u8ddf\u8e2a\u5e76\u9075\u5b88\u6307\u5b9a\u7684\u957f\u5ea6\u9650\u5236\uff0c\u5b9e\u73b0\u7cbe\u786e\u7684\u957f\u5ea6\u63a7\u5236\u3002", "result": "\u5728\u516d\u4e2a\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u7684\u8bc4\u6d4b\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u957f\u5ea6\u9075\u5b88\u5ea6\u4e0a\u8f83\u6807\u51c6\u63d0\u793a\u63d0\u5347\u663e\u8457\uff0c\u90e8\u5206\u6a21\u578b\u63d0\u5347\u9ad8\u8fbe37.6%\uff0c\u4e14\u8d28\u91cf\u672a\u53d7\u5f71\u54cd\u751a\u81f3\u6709\u6240\u63d0\u5347\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u957f\u5ea6\u63a7\u5236\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u518d\u8bad\u7ec3\u5373\u53ef\u7acb\u5373\u90e8\u7f72\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5c24\u5176\u9002\u5408\u6a21\u578b\u518d\u8bad\u7ec3\u6210\u672c\u9ad8\u6216\u4e0d\u5207\u5b9e\u9645\u7684\u751f\u4ea7\u73af\u5883\u3002"}}
{"id": "2511.01815", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.01815", "abs": "https://arxiv.org/abs/2511.01815", "authors": ["Konrad Staniszewski", "Adrian \u0141a\u0144cucki"], "title": "KV Cache Transform Coding for Compact Storage in LLM Inference", "comment": null, "summary": "Serving large language models (LLMs) at scale necessitates efficient\nkey-value (KV) cache management. KV caches can be reused across conversation\nturns via shared-prefix prompts that are common in iterative code editing and\nchat. However, stale caches consume scarce GPU memory, require offloading, or\nforce recomputation. We present KVTC, a lightweight transform coder that\ncompresses KV caches for compact on-GPU and off-GPU storage. Drawing on\nclassical media compression, KVTC combines PCA-based feature decorrelation,\nadaptive quantization, and entropy coding. It requires only a brief initial\ncalibration and leaves model parameters unchanged. By exploiting redundancies\nin KV caches, KVTC achieves up to 20$\\times$ compression while maintaining\nreasoning and long-context accuracy, and 40$\\times$ or higher for specific use\ncases. We test KVTC with Llama 3, Mistral NeMo, and R1-Qwen 2.5 models across\nbenchmarks including AIME25, LiveCodeBench, GSM8K, MMLU, Qasper, RULER, and\nMATH-500. It consistently outperforms inference-time baselines such as token\neviction, quantization, and SVD-based methods, while achieving higher\ncompression ratios. These results support KVTC as a practical building block\nfor memory-efficient LLM serving with reusable KV caches.", "AI": {"tldr": "KVTC\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u8f6c\u6362\u7f16\u7801\u5668\uff0c\u901a\u8fc7PCA\u7279\u5f81\u53bb\u76f8\u5173\u3001\u81ea\u9002\u5e94\u91cf\u5316\u548c\u71b5\u7f16\u7801\uff0c\u6709\u6548\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u952e\u503c\u7f13\u5b58\uff0c\u63d0\u9ad8GPU\u5185\u5b58\u5229\u7528\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u670d\u52a1\u9700\u8981\u9ad8\u6548\u7ba1\u7406\u952e\u503c\u7f13\u5b58\u4ee5\u8282\u7701\u5b9d\u8d35\u7684GPU\u5185\u5b58\uff0c\u51cf\u5c11\u7f13\u5b58\u8fc7\u65f6\u5bfc\u81f4\u7684\u91cd\u8ba1\u7b97\u548c\u5185\u5b58\u6ea2\u51fa\u95ee\u9898\u3002", "method": "KVTC\u7ed3\u5408PCA\u7279\u5f81\u53bb\u76f8\u5173\u3001\u81ea\u9002\u5e94\u91cf\u5316\u548c\u71b5\u7f16\u7801\u6280\u672f\uff0c\u7ecf\u8fc7\u7b80\u77ed\u6821\u51c6\uff0c\u65e0\u9700\u66f4\u6539\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u7f13\u5b58\u7684\u538b\u7f29\u548c\u5b58\u50a8\u4f18\u5316\u3002", "result": "KVTC\u5b9e\u73b0\u4e86\u6700\u9ad820\u500d\u538b\u7f29\uff0c\u7279\u5b9a\u573a\u666f\u751a\u81f3\u53ef\u8fbe40\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u63a8\u7406\u548c\u957f\u4e0a\u4e0b\u6587\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684Token\u9a71\u9010\u3001\u91cf\u5316\u548cSVD\u65b9\u6cd5\u3002", "conclusion": "KVTC\u4f5c\u4e3a\u4e00\u4e2a\u5b9e\u7528\u7684\u6a21\u5757\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f7f\u7528\u4e2d\u952e\u503c\u7f13\u5b58\u7684\u5185\u5b58\u6548\u7387\uff0c\u652f\u6301\u53ef\u91cd\u7528\u7f13\u5b58\u7684\u9ad8\u6548\u670d\u52a1\u3002"}}
{"id": "2511.01846", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.01846", "abs": "https://arxiv.org/abs/2511.01846", "authors": ["Thang Luong", "Dawsen Hwang", "Hoang H. Nguyen", "Golnaz Ghiasi", "Yuri Chervonyi", "Insuk Seo", "Junsu Kim", "Garrett Bingham", "Jonathan Lee", "Swaroop Mishra", "Alex Zhai", "Clara Huiyi Hu", "Henryk Michalewski", "Jimin Kim", "Jeonghyun Ahn", "Junhwi Bae", "Xingyou Song", "Trieu H. Trinh", "Quoc V. Le", "Junehyuk Jung"], "title": "Towards Robust Mathematical Reasoning", "comment": "EMNLP 2025 (main conference),\n  https://aclanthology.org/2025.emnlp-main.1794/", "summary": "Finding the right north-star metrics is highly critical for advancing the\nmathematical reasoning capabilities of foundation models, especially given that\nexisting evaluations are either too easy or only focus on getting correct short\nanswers. To address these issues, we present IMO-Bench, a suite of advanced\nreasoning benchmarks, vetted by a panel of top specialists and that\nspecifically targets the level of the International Mathematical Olympiad\n(IMO), the most prestigious venue for young mathematicians. IMO-AnswerBench\nfirst tests models on 400 diverse Olympiad problems with verifiable short\nanswers. IMO-Proof Bench is the next-level evaluation for proof-writing\ncapabilities, which includes both basic and advanced IMO level problems as well\nas detailed grading guidelines to facilitate automatic grading. These\nbenchmarks played a crucial role in our historic achievement of the gold-level\nperformance at IMO 2025 with Gemini Deep Think (Luong and Lockhart, 2025). Our\nmodel achieved 80.0% on IMO-AnswerBench and 65.7% on the advanced IMO-Proof\nBench, surpassing the best non-Gemini models by large margins of 6.9% and 42.4%\nrespectively. We also showed that autograders built with Gemini reasoning\ncorrelate well with human evaluations and construct IMO-GradingBench, with 1000\nhuman gradings on proofs, to enable further progress in automatic evaluation of\nlong-form answers. We hope that IMO-Bench will help the community towards\nadvancing robust mathematical reasoning and release it at\nhttps://imobench.github.io/.", "AI": {"tldr": "\u63d0\u51fa\u4e86IMO-Bench\uff0c\u4e00\u5957\u9488\u5bf9\u56fd\u9645\u6570\u5b66\u5965\u6797\u5339\u514b\u6c34\u5e73\u7684\u9ad8\u7ea7\u6570\u5b66\u63a8\u7406\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u62ec\u77ed\u7b54\u6848\u548c\u8bc1\u660e\u5199\u4f5c\u4e24\u4e2a\u90e8\u5206\uff0c\u652f\u6301\u81ea\u52a8\u8bc4\u5206\uff0c\u63a8\u52a8\u57fa\u7840\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u6570\u5b66\u63a8\u7406\u8bc4\u6d4b\u8fc7\u4e8e\u7b80\u5355\u6216\u4ec5\u805a\u7126\u77ed\u7b54\u6848\uff0c\u96be\u4ee5\u5168\u9762\u8861\u91cf\u57fa\u7840\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1IMO-Bench\uff0c\u5305\u62ecIMO-AnswerBench\uff08400\u9053\u77ed\u7b54\u6848\u9898\uff09\u548cIMO-Proof Bench\uff08\u57fa\u7840\u53ca\u9ad8\u7ea7\u8bc1\u660e\u9898\u53ca\u8bc4\u5206\u7ec6\u5219\uff09\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8eGemini Deep Think\u6a21\u578b\u7684\u81ea\u52a8\u8bc4\u5206\u5668\u3002", "result": "Gemini\u6a21\u578b\u5728IMO-AnswerBench\u548cIMO-Proof Bench\u4e0a\u5206\u522b\u8fbe\u523080.0%\u548c65.7%\u7684\u6210\u7ee9\uff0c\u660e\u663e\u8d85\u8fc7\u5176\u4ed6\u6a21\u578b\uff0c\u81ea\u52a8\u8bc4\u5206\u4e0e\u4eba\u5de5\u8bc4\u5206\u9ad8\u5ea6\u76f8\u5173\u3002", "conclusion": "IMO-Bench\u4e3a\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6743\u5a01\u3001\u5168\u9762\u7684\u57fa\u51c6\uff0c\u4fc3\u8fdb\u4e86\u81ea\u52a8\u957f\u7b54\u6848\u8bc4\u4f30\u7684\u53d1\u5c55\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8\u6570\u5b66\u63a8\u7406\u57fa\u7840\u6a21\u578b\u7684\u8fdb\u6b65\u3002"}}
{"id": "2511.01854", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.01854", "abs": "https://arxiv.org/abs/2511.01854", "authors": ["Elias Lumer", "Faheem Nizar", "Anmol Gulati", "Pradeep Honaganahalli Basavaraju", "Vamse Kumar Subbiah"], "title": "Tool-to-Agent Retrieval: Bridging Tools and Agents for Scalable LLM Multi-Agent Systems", "comment": null, "summary": "Recent advances in LLM Multi-Agent Systems enable scalable orchestration of\nsub-agents, each coordinating hundreds or thousands of tools or Model Context\nProtocol (MCP) servers. However, existing retrieval methods typically match\nqueries against coarse agent-level descriptions before routing, which obscures\nfine-grained tool functionality and often results in suboptimal agent\nselection. We introduce Tool-to-Agent Retrieval, a unified framework that\nembeds both tools and their parent agents in a shared vector space and connects\nthem through metadata relationships. By explicitly representing tool\ncapabilities and traversing metadata to the agent level, Tool-to-Agent\nRetrieval enables granular tool-level or agent-level retrieval, ensuring that\nagents and their underlying tools or MCP servers are equally represented\nwithout the context dilution that arises from chunking many tools together.\nEvaluating Tool-to-Agent Retrieval across eight embedding models, our approach\nachieves consistent improvements of 19.4% in Recall@5 and 17.7% in nDCG@5 over\nprevious state-of-the-art agent retrievers on the LiveMCPBench benchmark.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTool-to-Agent Retrieval\u7684\u7edf\u4e00\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u5de5\u5177\u53ca\u5176\u6240\u5c5e\u4ee3\u7406\u5d4c\u5165\u540c\u4e00\u5411\u91cf\u7a7a\u95f4\u5e76\u5229\u7528\u5143\u6570\u636e\u5173\u7cfb\u8fde\u63a5\uff0c\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u7684\u5de5\u5177\u7ea7\u548c\u4ee3\u7406\u7ea7\u68c0\u7d22\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u9009\u62e9\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u68c0\u7d22\u65b9\u6cd5\u5f80\u5f80\u4ec5\u5339\u914d\u67e5\u8be2\u4e0e\u4ee3\u7406\u7ea7\u63cf\u8ff0\uff0c\u5ffd\u89c6\u4e86\u5de5\u5177\u7684\u7ec6\u7c92\u5ea6\u529f\u80fd\uff0c\u5bfc\u81f4\u4ee3\u7406\u9009\u62e9\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51faTool-to-Agent Retrieval\u6846\u67b6\uff0c\u5c06\u5de5\u5177\u548c\u4ee3\u7406\u5171\u540c\u5d4c\u5165\u5411\u91cf\u7a7a\u95f4\uff0c\u5229\u7528\u5143\u6570\u636e\u5173\u7cfb\u8fde\u63a5\uff0c\u4ece\u800c\u652f\u6301\u7ec6\u7c92\u5ea6\u7684\u5de5\u5177\u6216\u4ee3\u7406\u68c0\u7d22\uff0c\u907f\u514d\u4e86\u5c06\u591a\u4e2a\u5de5\u5177\u5408\u5e76\u5e26\u6765\u7684\u4e0a\u4e0b\u6587\u7a00\u91ca\u95ee\u9898\u3002", "result": "\u5728\u516b\u4e2a\u5d4c\u5165\u6a21\u578b\u4e0a\u8fdb\u884c\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728LiveMCPBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5728Recall@5\u548cnDCG@5\u6307\u6807\u4e0a\u5206\u522b\u6bd4\u6700\u5148\u8fdb\u65b9\u6cd5\u63d0\u5347\u4e8619.4%\u548c17.7%\u3002", "conclusion": "Tool-to-Agent Retrieval\u6709\u6548\u63d0\u5347\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u9009\u62e9\u7684\u7cbe\u5ea6\uff0c\u4e3a\u7ec6\u7c92\u5ea6\u5de5\u5177\u529f\u80fd\u7684\u68c0\u7d22\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
