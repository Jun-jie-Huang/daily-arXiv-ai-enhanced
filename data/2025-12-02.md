<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 76]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.SE](#cs.SE) [Total: 30]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Text Annotation via Inductive Coding: Comparing Human Experts to LLMs in Qualitative Data Analysis](https://arxiv.org/abs/2512.00046)
*Angelina Parfenova,Andreas Marfurt,Alexander Denzler,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本研究探讨了利用大型语言模型自动进行归纳编码的可行性，揭示了人类与LLMs在标注复杂与简单语句上的不同表现及评价差异。


<details>
  <summary>Details</summary>
Motivation: 当前定性数据分析多依赖预定义标签的演绎方法，自动化归纳编码尚未充分研究，本文旨在探索LLMs在无预设标签情况下的归纳编码能力及其与人类表现的异同。

Method: 通过评估六种开源LLMs与人类专家对定性数据的归纳编码性能，并让专家对编码难度评分，比较人类与LLMs标注结果与标准答案的差异及专家评价。

Result: 本论文研究了使用大型语言模型（LLMs）进行定性数据分析的自动化，重点是归纳编码方法。通过对比六种开源LLMs与人类专家的编码表现，发现人类在标注复杂语句时表现优异，但对简单语句反而表现较差；LLMs则表现相反。此外，人类标注虽有偏差但被专家更认可，部分LLMs虽更接近标准答案却被评价较低。

Conclusion: 人类和LLMs在归纳编码中各有优势与局限，人类更擅长复杂语句标注且更受认可，而LLMs更接近标准标签但评价较低，提示未来应结合两者优势提升自动定性分析效果。

Abstract: This paper investigates the automation of qualitative data analysis, focusing on inductive coding using large language models (LLMs). Unlike traditional approaches that rely on deductive methods with predefined labels, this research investigates the inductive process where labels emerge from the data. The study evaluates the performance of six open-source LLMs compared to human experts. As part of the evaluation, experts rated the perceived difficulty of the quotes they coded. The results reveal a peculiar dichotomy: human coders consistently perform well when labeling complex sentences but struggle with simpler ones, while LLMs exhibit the opposite trend. Additionally, the study explores systematic deviations in both human and LLM generated labels by comparing them to the golden standard from the test set. While human annotations may sometimes differ from the golden standard, they are often rated more favorably by other humans. In contrast, some LLMs demonstrate closer alignment with the true labels but receive lower evaluations from experts.

</details>


### [2] [Emergent Convergence in Multi-Agent LLM Annotation](https://arxiv.org/abs/2512.00047)
*Angelina Parfenova,Alexander Denzler,Juergen Pfeffer*

Main category: cs.CL

TL;DR: 本文通过大量模拟多轮对话，揭示大型语言模型作为黑盒代理时的协调动态和策略，展示了其协作中的词汇与语义趋同及影响力分布。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在协作环境中的协调方式尚不明确，尤其是将其视为黑盒代理时的协调行为。

Method: 模拟7500次多轮对话，设计编码稳定性、语义一致性、词汇置信度等过程指标，结合情感和收敛性分析，以及输出嵌入空间几何演变，探究协调动态。

Result: 通过模拟7500次多代理多轮讨论，发现语言模型群体在词汇和语义上趋同，形成不对称的影响模式，并表现出类似谈判的行为，这表明了其自发的协调机制。

Conclusion: 黑盒交互分析能够有效揭示大型语言模型群体的协作策略，补充了基于内部探针的模型可解释性方法。

Abstract: Large language models (LLMs) are increasingly deployed in collaborative settings, yet little is known about how they coordinate when treated as black-box agents. We simulate 7500 multi-agent, multi-round discussions in an inductive coding task, generating over 125000 utterances that capture both final annotations and their interactional histories. We introduce process-level metrics: code stability, semantic self-consistency, and lexical confidence alongside sentiment and convergence measures, to track coordination dynamics. To probe deeper alignment signals, we analyze the evolving geometry of output embeddings, showing that intrinsic dimensionality declines over rounds, suggesting semantic compression. The results reveal that LLM groups converge lexically and semantically, develop asymmetric influence patterns, and exhibit negotiation-like behaviors despite the absence of explicit role prompting. This work demonstrates how black-box interaction analysis can surface emergent coordination strategies, offering a scalable complement to internal probe-based interpretability methods.

</details>


### [3] [Tree Matching Networks for Natural Language Inference: Parameter-Efficient Semantic Understanding via Dependency Parse Trees](https://arxiv.org/abs/2512.00204)
*Jason Lunder*

Main category: cs.CL

TL;DR: 利用依存句法树构建的树匹配网络比BERT在自然语言推断任务中更高效准确，显式结构优势明显，但需改进聚合方法以提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: 基于变换器的模型如BERT虽然准确率高，但参数庞大资源消耗高。利用依存句法树等显式语言结构能减少模型学习负担，提高效率和效果。

Method: 将图匹配网络（GMN）适配为依存句法树结构的树匹配网络（TMN），并对比TMN和BERT模型在SNLI和SemEval任务上的表现；提出多头注意力聚合方法以解决当前聚合方法的可扩展性限制。

Result: TMN在SNLI任务上表现优于BERT模型，且用时更少，内存占用更低；在SemEval相似度任务上两者表现均欠佳；显式结构提升性能，但聚合方法限制了模型的可扩展性。

Conclusion: 显式的结构化表示（基于依存句法树的树匹配网络）在自然语言推断任务中，相比基于序列的模型（如BERT）能显著提升性能，提高学习效率，并减少内存和训练时间。

Abstract: In creating sentence embeddings for Natural Language Inference (NLI) tasks, using transformer-based models like BERT leads to high accuracy, but require hundreds of millions of parameters. These models take in sentences as a sequence of tokens, and learn to encode the meaning of the sequence into embeddings such that those embeddings can be used reliably for NLI tasks. Essentially, every word is considered against every other word in the sequence, and the transformer model is able to determine the relationships between them, entirely from scratch. However, a model that accepts explicit linguistic structures like dependency parse trees may be able to leverage prior encoded information about these relationships, without having to learn them from scratch, thus improving learning efficiency. To investigate this, we adapt Graph Matching Networks (GMN) to operate on dependency parse trees, creating Tree Matching Networks (TMN). We compare TMN to a BERT based model on the SNLI entailment task and on the SemEval similarity task. TMN is able to achieve significantly better results with a significantly reduced memory footprint and much less training time than the BERT based model on the SNLI task, while both models struggled to preform well on the SemEval. Explicit structural representations significantly outperform sequence-based models at comparable scales, but current aggregation methods limit scalability. We propose multi-headed attention aggregation to address this limitation.

</details>


### [4] [Towards Corpus-Grounded Agentic LLMs for Multilingual Grammatical Analysis](https://arxiv.org/abs/2512.00214)
*Matej Klemen,Tjaša Arčon,Luka Terčon,Marko Robnik-Šikonja,Kaja Dobrovoljc*

Main category: cs.CL

TL;DR: 本文提出基于大语言模型的框架用于自动化分析多语言语料库中的语法特征，验证了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 实证语法研究越来越依赖数据驱动，但系统地分析标注语料库仍需大量方法和技术投入。

Method: 提出一个基于大语言模型的代理框架，结合自然语言任务解释、代码生成和数据驱动推理，用于语料库驱动的语法分析。

Result: 系统在多语言、多个词序特征上的性能良好，验证了结合大语言模型推理与结构化语言数据的可行性。

Conclusion: 该方法实现了语料库基础的语法研究自动化第一步，具备可解释性和可扩展性，推动语法研究的数据驱动进程。

Abstract: Empirical grammar research has become increasingly data-driven, but the systematic analysis of annotated corpora still requires substantial methodological and technical effort. We explore how agentic large language models (LLMs) can streamline this process by reasoning over annotated corpora and producing interpretable, data-grounded answers to linguistic questions. We introduce an agentic framework for corpus-grounded grammatical analysis that integrates concepts such as natural-language task interpretation, code generation, and data-driven reasoning. As a proof of concept, we apply it to Universal Dependencies (UD) corpora, testing it on multilingual grammatical tasks inspired by the World Atlas of Language Structures (WALS). The evaluation spans 13 word-order features and over 170 languages, assessing system performance across three complementary dimensions - dominant-order accuracy, order-coverage completeness, and distributional fidelity - which reflect how well the system generalizes, identifies, and quantifies word-order variations. The results demonstrate the feasibility of combining LLM reasoning with structured linguistic data, offering a first step toward interpretable, scalable automation of corpus-based grammatical inquiry.

</details>


### [5] [Minimal-Edit Instruction Tuning for Low-Resource Indic GEC](https://arxiv.org/abs/2512.00219)
*Akhil Rajeev P*

Main category: cs.CL

TL;DR: 该文提出基于指令微调大型语言模型和保守解码的无增强印度语言语法纠正方法，有效提升准确率并具备高计算效率。


<details>
  <summary>Details</summary>
Motivation: 由于印度语言语法纠正面临监督数据有限、文字多样和形态丰富的挑战，作者提出一个无需数据增强、利用指令微调大型语言模型和保守解码的高效解决方案，以提高系统的准确性和计算效率。

Method: 使用12B GEMMA 3模型，结合bnb 4-bit量化和参数高效微调（PEFT），采用Alpaca风格格式化进行指令微调；解码采用确定性、约束感知的方法，结合轻量级标准化器。推理通过固定的语言特定提示实现，提示由确定性错误分类器基于训练数据生成。

Result: 该论文提出了一种针对印度语言语法错误纠正的增强学习免疫方案，结合了指令微调的大型语言模型（GEMMA 3 12B模型）和保守解码策略。该方法通过参数高效微调和Alpaca风格格式化进行指令微调，解码采用确定性和约束感知的流程，使用轻量级标准化器以实现最小且保留意义的编辑。基于训练语料中的错误分类器分类法、标签分布和优先级排序，构建了语言特定的固定提示进行推理。在官方未微调的GLEU评测中，分别在马拉雅拉姆语和印地语取得了较高的排名。结果表明，该方法在避免数据增强的同时，通过分类器信息指导的提示设计、基于适配器的指令微调和确定性解码，提供了一个可复现且计算效率高的印度语言语法错误纠正替代方案。

Conclusion: 分类器指导的提示设计、基于适配器的指令微调和确定性解码共同促成了一个在印度语言语法错误纠正中高效且可复现的替代方案，未来可进一步研究更强的形态句法约束及保守编辑的人类评价方法。

Abstract: Grammatical error correction for Indic languages faces limited supervision, diverse scripts, and rich morphology. We propose an augmentation-free setup that uses instruction-tuned large language models and conservative decoding. A 12B GEMMA 3 model is instruction-tuned in bnb 4-bit precision with parameter-efficient fine-tuning (PEFT) and Alpaca-style formatting. Decoding follows a deterministic, constraint-aware procedure with a lightweight normaliser that encourages minimal, meaning-preserving edits. We operationalise inference, subsequent to instruction fine-tuning (IFT), via a fixed, language-specific prompt directly synthesised from a deterministic error classifier's taxonomy, label distributions, and precedence ordering computed on the training corpus.
  Under the official untuned GLEU evaluation, the system scores 92.41 on Malayalam, sixth overall, and 81.44 on Hindi, third overall. These results indicate that classifier-informed prompt design, adapter-based instruction tuning, and deterministic decoding provide a reproducible and a computationally efficient alternative to augmentation-centred pipelines for Indic GEC. The approach also motivates future work on stronger morphosyntactic constraints and human-centred evaluation of conservative edits.

</details>


### [6] [OmniFusion: Simultaneous Multilingual Multimodal Translations via Modular Fusion](https://arxiv.org/abs/2512.00234)
*Sai Koneru,Matthias Huck,Jan Niehues*

Main category: cs.CL

TL;DR: 本文提出了融合多模态基础模型与翻译语言模型的端到端多模态翻译方法OmniFusion，有效利用音频和视觉信息，减少延迟并提高翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有开源文本翻译大模型缺乏对多模态场景（如语音和图像）的支持，级联语音识别与翻译带来较大延迟且无法利用视觉信息，亟需一种高效端到端多模态翻译方案提升翻译质量及降低延迟。

Method: 提出了将预训练多模态基础模型多个隐藏层状态与翻译大语言模型连接的融合策略，支持联合端到端训练，构建了基于Omni 2.5-7B和SeedX PPO-7B的多模态翻译系统。

Result: 本文提出了一种将多模态基础模型（MMFM）与翻译大语言模型（LLM）融合的端到端多模态翻译系统OmniFusion，解决了传统语音翻译模型中多模态信息利用不足和延迟较高的问题。该模型通过连接MMFM多个隐藏层状态与翻译LLM，实现联合训练，支持语音到文本、语音加图像到文本以及文本加图像到文本的翻译。实验证明，OmniFusion在同时语音翻译任务中相比级联管线延迟降低1秒，同时提升了翻译质量。

Conclusion: OmniFusion通过多层隐藏状态融合实现了多模态输入的联合端到端训练，显著降低了同时语音翻译的延迟并提升了翻译效果，证明了多模态融合在翻译领域的有效性。

Abstract: There has been significant progress in open-source text-only translation large language models (LLMs) with better language coverage and quality. However, these models can be only used in cascaded pipelines for speech translation (ST), performing automatic speech recognition first followed by translation. This introduces additional latency, which is particularly critical in simultaneous ST (SimulST), and prevents the model from exploiting multimodal context, such as images, which can aid disambiguation. Pretrained multimodal foundation models (MMFMs) already possess strong perception and reasoning capabilities across multiple modalities, but generally lack the multilingual coverage and specialized translation performance of dedicated translation LLMs. To build an effective multimodal translation system, we propose an end-to-end approach that fuses MMFMs with translation LLMs. We introduce a novel fusion strategy that connects hidden states from multiple layers of a pretrained MMFM to a translation LLM, enabling joint end-to-end training. The resulting model, OmniFusion, built on Omni 2.5-7B as the MMFM and SeedX PPO-7B as the translation LLM, can perform speech-to-text, speech-and-image-to-text, and text-and-image-to-text translation. Experiments demonstrate that OmniFusion effectively leverages both audio and visual inputs, achieves a 1-second latency reduction in SimulST compared to cascaded pipelines and also improves the overall translation quality\footnote{Code is available at https://github.com/saikoneru/OmniFusion}.

</details>


### [7] [Lost without translation -- Can transformer (language models) understand mood states?](https://arxiv.org/abs/2512.00274)
*Prakrithi Shivaprakash,Diptadhi Mukherjee,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型在理解印度11种语言中表达的四种情绪状态的短语能力，发现直接使用印度语嵌入效果差，翻译成英语或中文后嵌入效果显著提升，指出当前模型难以直接处理多样化本地语言情绪，影响心理健康应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在精神病学领域显示潜力，但多聚焦于英语，且不同语言有独特的情绪表达，评估模型对非英语，尤其是印度本地语言中情绪短语的理解能力是必要的。

Method: 收集11种印度语言中247个表示四种情绪状态的独特短语，采用k-means聚类方法评估原生及罗马字母形式的多语言和印度语言专用模型嵌入，与翻译成英语和中文后的嵌入进行对比，使用多个聚类指标的复合评分评价性能。

Result: 印度语言的直接嵌入聚类效果极差（复合评分0.002），所有翻译后的方法性能显著提升，Gemini英文翻译及人类翻译英文的嵌入表现较好（复合评分均约0.6），人类翻译英文再翻译成中文并使用中文模型嵌入效果最佳（复合评分0.67），印度专用模型表现不佳。

Conclusion: 目前的多语言模型无法直接有效表示印度语言中的情绪状态，这限制了其在印度精神病学诊断和治疗中的应用。虽然通过高质量翻译可改善效果，但依赖翻译存在可持续性问题。未来需开发能够理解多样本地语言的模型以支持全球精神健康。

Abstract: Background: Large Language Models show promise in psychiatry but are English-centric. Their ability to understand mood states in other languages is unclear, as different languages have their own idioms of distress. Aim: To quantify the ability of language models to faithfully represent phrases (idioms of distress) of four distinct mood states (depression, euthymia, euphoric mania, dysphoric mania) expressed in Indian languages. Methods: We collected 247 unique phrases for the four mood states across 11 Indic languages. We tested seven experimental conditions, comparing k-means clustering performance on: (a) direct embeddings of native and Romanised scripts (using multilingual and Indic-specific models) and (b) embeddings of phrases translated to English and Chinese. Performance was measured using a composite score based on Adjusted Rand Index, Normalised Mutual Information, Homogeneity and Completeness. Results: Direct embedding of Indic languages failed to cluster mood states (Composite Score = 0.002). All translation-based approaches showed significant improvement. High performance was achieved using Gemini-translated English (Composite=0.60) and human-translated English (Composite=0.61) embedded with gemini-001. Surprisingly, human-translated English, further translated into Chinese and embedded with a Chinese model, performed best (Composite = 0.67). Specialised Indic models (IndicBERT and Sarvam-M) performed poorly. Conclusion: Current models cannot meaningfully represent mood states directly from Indic languages, posing a fundamental barrier to their psychiatric application for diagnostic or therapeutic purposes in India. While high-quality translation bridges this gap, reliance on proprietary models or complex translation pipelines is unsustainable. Models must first be built to understand diverse local languages to be effective in global mental health.

</details>


### [8] [EduEval: A Hierarchical Cognitive Benchmark for Evaluating Large Language Models in Chinese Education](https://arxiv.org/abs/2512.00290)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Yue Cui,Jiawei Shen,Zilong Li,Yidan Liang*

Main category: cs.CL

TL;DR: EduEval是针对中国K-12教育的综合语言模型评测基准，涵盖六个认知层面和多种真实任务，揭示当前大模型在教育应用中的优势与不足。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在教育领域应用潜力大，但未经严格评估可能影响教育质量，因此需要一个系统、真实且规模化的评测基准来全面衡量模型在中国教育场景中的表现。

Method: 构建EduAbility认知框架，将Bloom分类法与Webb知识深度结合，设计覆盖六个认知维度的24种任务，收集超过11,000道中小学真实题目，并在零样本与少样本条件下评测14个主流大模型。

Result: 本文提出了EduEval，一个针对中国K-12教育的大型语言模型评测基准。该基准融合了认知框架（EduAbility分类法）、真实教育场景题目以及多样化任务，涵盖了记忆、理解、应用、推理、创造力和伦理六个认知维度。通过测试14个主流大模型，发现模型在事实性任务表现良好，但在课堂对话分类和创造性内容生成上表现不稳。开放源码模型在复杂教育推理上优于部分专有系统，少样本提示效果因认知维度而异。该基准为开发专门优化的教育大模型提供了有针对性的评价指标。

Conclusion: 模型在事实性任务表现较好，但面对课堂对话和创造性任务存在困难，且不同认知维度需采用差异化的提示策略，开放源码模型在复杂推理上表现优异。

Abstract: Large language models (LLMs) demonstrate significant potential for educational applications. However, their unscrutinized deployment poses risks to educational standards, underscoring the need for rigorous evaluation. We introduce EduEval, a comprehensive hierarchical benchmark for evaluating LLMs in Chinese K-12 education. This benchmark makes three key contributions: (1) Cognitive Framework: We propose the EduAbility Taxonomy, which unifies Bloom's Taxonomy and Webb's Depth of Knowledge to organize tasks across six cognitive dimensions including Memorization, Understanding, Application, Reasoning, Creativity, and Ethics. (2) Authenticity: Our benchmark integrates real exam questions, classroom conversation, student essays, and expert-designed prompts to reflect genuine educational challenges; (3) Scale: EduEval comprises 24 distinct task types with over 11,000 questions spanning primary to high school levels. We evaluate 14 leading LLMs under both zero-shot and few-shot settings, revealing that while models perform well on factual tasks, they struggle with classroom dialogue classification and exhibit inconsistent results in creative content generation. Interestingly, several open source models outperform proprietary systems on complex educational reasoning. Few-shot prompting shows varying effectiveness across cognitive dimensions, suggesting that different educational objectives require tailored approaches. These findings provide targeted benchmarking metrics for developing LLMs specifically optimized for diverse Chinese educational tasks.

</details>


### [9] [Comparative Analysis of 47 Context-Based Question Answer Models Across 8 Diverse Datasets](https://arxiv.org/abs/2512.00323)
*Muhammad Muneeb,David B. Ascher,Ahsan Baidar Bakht*

Main category: cs.CL

TL;DR: 本论文对47个Context-based问答模型在8个数据集上的性能进行基准测试，找出了无需额外微调即可表现最佳的模型。


<details>
  <summary>Details</summary>
Motivation: 为简化实际应用中CBQA模型的部署，寻求在不同数据集上无需重新训练即具备较好性能的模型，从而减少模型微调需求。

Method: 对47个Hugging Face上预训练的CBQA模型在8个数据集上进行了无微调的评测，分析模型表现与上下文长度、答案长度的关系，并结合遗传算法进行结果融合。

Result: ahotrod/electra_large_discriminator_squad2_512模型在bioasq10b-factoid、biomedical_cpgQA、QuAC、Question Answer Dataset等多个数据集表现突出，准确率分别达65.92%、96.45%、11.13%和41.6%；Bert-large-uncased-whole-word-masking-finetuned-squad在IELTS数据集上准确率为82%。

Conclusion: 最佳模型是ahotrod/electra_large_discriminator_squad2_512，整体准确率达43%，在多个数据集上表现优异。模型性能受上下文长度、答案长度和复杂度影响。利用遗传算法整合模型回答可进一步提升准确率。

Abstract: Context-based question answering (CBQA) models provide more accurate and relevant answers by considering the contextual information. They effectively extract specific information given a context, making them functional in various applications involving user support, information retrieval, and educational platforms. In this manuscript, we benchmarked the performance of 47 CBQA models from Hugging Face on eight different datasets. This study aims to identify the best-performing model across diverse datasets without additional fine-tuning. It is valuable for practical applications where the need to retrain models for specific datasets is minimized, streamlining the implementation of these models in various contexts. The best-performing models were trained on the SQuAD v2 or SQuAD v1 datasets. The best-performing model was ahotrod/electra_large_discriminator_squad2_512, which yielded 43\% accuracy across all datasets. We observed that the computation time of all models depends on the context length and the model size. The model's performance usually decreases with an increase in the answer length. Moreover, the model's performance depends on the context complexity. We also used the Genetic algorithm to improve the overall accuracy by integrating responses from other models. ahotrod/electra_large_discriminator_squad2_512 generated the best results for bioasq10b-factoid (65.92\%), biomedical\_cpgQA (96.45\%), QuAC (11.13\%), and Question Answer Dataset (41.6\%). Bert-large-uncased-whole-word-masking-finetuned-squad achieved an accuracy of 82\% on the IELTS dataset.

</details>


### [10] [Evidence-Guided Schema Normalization for Temporal Tabular Reasoning](https://arxiv.org/abs/2512.00329)
*Ashish Thanga,Vibhu Dixit,Abhilash Shankarampeta,Vivek Gupta*

Main category: cs.CL

TL;DR: 通过设计合理的数据库模式和SQL查询，显著提升了时间推理问答系统的准确率，挑战了模型规模优先的假设。


<details>
  <summary>Details</summary>
Motivation: 当前问答系统在处理随时间变化的半结构化表格上的推理能力不足，亟需更有效的方法。

Method: 提出基于SQL的方法，包括从维基百科信息框生成3NF范式的数据库模式、生成SQL查询以及执行查询。

Result: 通过设计高质量的模式，尤其是保持上下文的规范化、语义命名减少歧义和一致的时间锚定，显著提升了问答系统的准确率，最高达到80.39 EM，比基线提高16.8%。

Conclusion: 数据库模式设计质量对问答性能影响大于模型容量，遵循三项原则可有效提升性能。

Abstract: Temporal reasoning over evolving semi-structured tables poses a challenge to current QA systems. We propose a SQL-based approach that involves (1) generating a 3NF schema from Wikipedia infoboxes, (2) generating SQL queries, and (3) query execution. Our central finding challenges model scaling assumptions: the quality of schema design has a greater impact on QA precision than model capacity. We establish three evidence-based principles: normalization that preserves context, semantic naming that reduces ambiguity, and consistent temporal anchoring. Our best configuration (Gemini 2.5 Flash schema + Gemini-2.0-Flash queries) achieves 80.39 EM, a 16.8\% improvement over the baseline (68.89 EM).

</details>


### [11] [Assertion-Conditioned Compliance: A Provenance-Aware Vulnerability in Multi-Turn Tool-Calling Agents](https://arxiv.org/abs/2512.00332)
*Daud Waqas,Aaryamaan Golthi,Erika Hayashida,Huanzhi Mao*

Main category: cs.CL

TL;DR: 本文提出A-CC评估方法，揭示多轮函数调用模型对误导断言的脆弱性，强调提高模型真实应用中鲁棒性的必要性。


<details>
  <summary>Details</summary>
Motivation: 多轮调用工具的大型语言模型在安全关键行业中的鲁棒性不足，尤其在处理误导性断言时表现出隐患。

Method: 提出了一种新的评估范式——断言条件合规性(A-CC)，通过用户来源断言(USA)和函数来源断言(FSA)两种误导性断言来检测模型在多轮对话中的行为表现。

Result: 实验结果表明，现有模型在面对用户的错误信念和系统中不一致策略时易表现出谄媚和冲突遵从，暴露出关键的潜在脆弱性。

Conclusion: 断言条件合规性是评估和改进多轮函数调用模型鲁棒性的重要指标，提醒需要加强模型在真实系统中面对误导信息时的稳健性。

Abstract: Multi-turn tool-calling LLMs (models capable of invoking external APIs or tools across several user turns) have emerged as a key feature in modern AI assistants, enabling extended dialogues from benign tasks to critical business, medical, and financial operations. Yet implementing multi-turn pipelines remains difficult for many safety-critical industries due to ongoing concerns regarding model resilience. While standardized benchmarks such as the Berkeley Function-Calling Leaderboard (BFCL) have underpinned confidence concerning advanced function-calling models (like Salesforce's xLAM V2), there is still a lack of visibility into multi-turn conversation-level robustness, especially given their exposure to real-world systems. In this paper, we introduce Assertion-Conditioned Compliance (A-CC), a novel evaluation paradigm for multi-turn function-calling dialogues. A-CC provides holistic metrics that evaluate a model's behavior when confronted with misleading assertions originating from two distinct vectors: (1) user-sourced assertions (USAs), which measure sycophancy toward plausible but misinformed user beliefs, and (2) function-sourced assertions (FSAs), which measure compliance with plausible but contradictory system policies (e.g., stale hints from unmaintained tools). Our results show that models are highly vulnerable to both USA sycophancy and FSA policy conflicts, confirming A-CC as a critical, latent vulnerability in deployed agents.

</details>


### [12] [InnoGym: Benchmarking the Innovation Potential of AI Agents](https://arxiv.org/abs/2512.01822)
*Jintian Zhang,Kewei Xu,Jingsheng Zheng,Zhuoyun Yu,Yuqi Zhu,Yujie Luo,Lanning Wei,Shuofei Qiao,Lun Du,Da Zheng,Shumin Deng,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 本文提出了首个系统评估AI智能体创新潜力的基准InnoGym，兼顾性能提升和方法新颖性，通过18个真实任务和统一环境，发现创新与性能的矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估正确性，忽视了解决方案背后方法的多样性和创新性，真正的创新不仅需要正确答案，更需要方法的原创性。

Method: 提出了InnoGym基准和框架，包含18个来自工程和科学领域的任务，采用资源过滤、评估者验证和解法收集标准化处理，并引入统一执行环境iGym以支持可复现和长周期评估。

Result: 实验发现部分智能体能产生新颖方法，但缺乏鲁棒性导致性能提升有限，揭示了创造力与有效性之间的差距。

Conclusion: 创新性评估是人工智能发展的关键，需要综合考虑方法的新颖性和性能表现，未来基准应同时关注创造力和效果。

Abstract: LLMs and Agents have achieved impressive progress in code generation, mathematical reasoning, and scientific discovery. However, existing benchmarks primarily measure correctness, overlooking the diversity of methods behind solutions. True innovation depends not only on producing correct answers but also on the originality of the approach. We present InnoGym, the first benchmark and framework designed to systematically evaluate the innovation potential of AI agents. InnoGym introduces two complementary metrics: performance gain, which measures improvement over the best-known solutions, and novelty, which captures methodological differences from prior approaches. The benchmark includes 18 carefully curated tasks from real-world engineering and scientific domains, each standardized through resource filtering, evaluator validation, and solution collection. In addition, we provide iGym, a unified execution environment for reproducible and long-horizon evaluations. Extensive experiments show that while some agents produce novel approaches, their lack of robustness limits performance gains. These results highlight a key gap between creativity and effectiveness, underscoring the need for benchmarks that evaluate both.

</details>


### [13] [IndicParam: Benchmark to evaluate LLMs on low-resource Indic Languages](https://arxiv.org/abs/2512.00333)
*Ayush Maheshwari,Kaushal Sharma,Vivek Patel,Aditya Maheshwari*

Main category: cs.CL

TL;DR: 该工作提出了一个专门针对低资源印度语言的多项选择题基准IndicParam，通过对19个大型语言模型的评测，揭示了当前模型在这些语言上的显著性能不足，促使未来改进。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在高资源多语言任务表现优异，但对于低资源和极低资源的印度语言评测严重不足。

Method: 构建了一个包含11种低资源和极低资源印度语言的多项选择题基准测试IndicParam，涵盖超过13,000道题目，并对19个大型语言模型进行评测。

Result: 评测显示即使表现最好的GPT-5也仅达45.0%的平均准确率，揭示了跨语言迁移能力的局限。进一步将题目区分为知识导向和纯语言学题目，并考察模型对多样题型的处理能力。

Conclusion: IndicParam为印度语言的跨语言迁移和语言模型能力评估提供了一个有挑战性的基准，强调了现有大型语言模型在低资源语言处理上的不足，并促进了相关领域的发展。

Abstract: While large language models excel on high-resource multilingual tasks, low- and extremely low-resource Indic languages remain severely under-evaluated. We present IndicParam, a human-curated benchmark of over 13,000 multiple-choice questions covering 11 such languages (Nepali, Gujarati, Marathi, Odia as low-resource; Dogri, Maithili, Rajasthani, Sanskrit, Bodo, Santali, Konkani as extremely low-resource) plus Sanskrit-English code-mixed set. We evaluated 19 LLMs, both proprietary and open-weights, which reveals that even the top-performing GPT-5 reaches only 45.0% average accuracy, followed by DeepSeek-3.2 (43.1) and Claude-4.5 (42.7). We additionally label each question as knowledge-oriented or purely linguistic to discriminate factual recall from grammatical proficiency. Further, we assess the ability of LLMs to handle diverse question formats-such as list-based matching, assertion-reason pairs, and sequence ordering-alongside conventional multiple-choice questions. IndicParam provides insights into limitations of cross-lingual transfer and establishes a challenging benchmark for Indic languages. The dataset is available at https://huggingface.co/datasets/bharatgenai/IndicParam. Scripts to run benchmark are present at https://github.com/ayushbits/IndicParam.

</details>


### [14] [CourseTimeQA: A Lecture-Video Benchmark and a Latency-Constrained Cross-Modal Fusion Method for Timestamped QA](https://arxiv.org/abs/2512.00360)
*Vsevolod Kovalev,Parteek Kumar*

Main category: cs.CL

TL;DR: 本论文提出了一种面向教育讲座视频的时间戳问答系统和轻量级多模态检索器，实现在单GPU下低延迟高效检索与回答生成。


<details>
  <summary>Details</summary>
Motivation: 实现针对教育讲座视频的时间戳问答，受限于单GPU硬件资源，需设计高效且延时受控的多模态检索与回答生成系统。

Method: 采用冻结编码器，512到768维视觉投影，浅层查询无关交叉注意力结合自动语音识别（ASR）与视频帧信息，配合时间一致性正则化和小型交叉注意力重排序器，实现低延迟跨模态检索。

Result: CrossFusion-RAG在CourseTimeQA数据集上提高nDCG@10指标0.10和MRR指标0.08，端到端中位延迟约1.55秒，且在ASR噪声和时间定位任务中表现稳健。

Conclusion: CrossFusion-RAG模型在CourseTimeQA数据集上显著优于现有强基线，提升了排序指标，且满足单GPU低延迟需求，具有较强鲁棒性和良好的时间定位精度。

Abstract: We study timestamped question answering over educational lecture videos under a single-GPU latency/memory budget. Given a natural-language query, the system retrieves relevant timestamped segments and synthesizes a grounded answer. We present CourseTimeQA (52.3 h, 902 queries across six courses) and a lightweight, latency-constrained cross-modal retriever (CrossFusion-RAG) that combines frozen encoders, a learned 512->768 vision projection, shallow query-agnostic cross-attention over ASR and frames with a temporal-consistency regularizer, and a small cross-attentive reranker. On CourseTimeQA, CrossFusion-RAG improves nDCG@10 by 0.10 and MRR by 0.08 over a strong BLIP-2 retriever while achieving approximately 1.55 s median end-to-end latency on a single A100. Closest comparators (zero-shot CLIP multi-frame pooling; CLIP + cross-encoder reranker + MMR; learned late-fusion gating; text-only hybrid with cross-encoder reranking and its MMR variant; caption-augmented text retrieval; non-learned temporal smoothing) are evaluated under matched hardware and indexing. We report robustness across ASR noise (WER quartiles), diagnostics for temporal localization, and full training/tuning details to support reproducible comparison.

</details>


### [15] [Mitigating the Threshold Priming Effect in Large Language Model-Based Relevance Judgments via Personality Infusing](https://arxiv.org/abs/2512.00390)
*Nuo Chen,Hanpei Fang,Jiqun Liu,Wilson Wei,Tetsuya Sakai,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）中模拟的五大人格特质如何影响相关性标注中的启动效应，发现某些人格特质能减少启动效应，并提出了基于人格提示减轻该效应的方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究指出LLMs在相关性标注中存在启动效应，而心理学理论表明人格特质与认知偏差有关，但尚不清楚LLMs模拟的人格是否会影响此类偏差。

Method: 作者利用多个大型语言模型，在TREC 2021和2022深度学习轨迹的数据集上，模拟不同的五大人格特质，对相关性标注的启动效应进行了实证分析。

Result: 实验结果表明，高开放性和低神经质人格特质使LLMs在相关性判断时对先前判断的依赖性降低，启动效应减弱；且不同模型和任务中最有效的人格配置有所不同。

Conclusion: 不同的大型语言模型中的人格特质影响其对相关性标注中启动效应的敏感度，某些人格如高开放性和低神经质能有效减少启动效应，且这一影响因模型和任务而异。基于此，采用人格提示可以作为减轻启动效应的有效手段。

Abstract: Recent research has explored LLMs as scalable tools for relevance labeling, but studies indicate they are susceptible to priming effects, where prior relevance judgments influence later ones. Although psychological theories link personality traits to such biases, it is unclear whether simulated personalities in LLMs exhibit similar effects. We investigate how Big Five personality profiles in LLMs influence priming in relevance labeling, using multiple LLMs on TREC 2021 and 2022 Deep Learning Track datasets. Our results show that certain profiles, such as High Openness and Low Neuroticism, consistently reduce priming susceptibility. Additionally, the most effective personality in mitigating priming may vary across models and task types. Based on these findings, we propose personality prompting as a method to mitigate threshold priming, connecting psychological evidence with LLM-based evaluation practices.

</details>


### [16] [A Taxonomy of Errors in English as she is spoke: Toward an AI-Based Method of Error Analysis for EFL Writing Instruction](https://arxiv.org/abs/2512.00392)
*Damian Heywood,Joseph Andrew Carrier,Kyu-Hong Hwang*

Main category: cs.CL

TL;DR: 研究利用大型语言模型开发AI辅助英语写作错误分析系统，构建详细分类体系，能识别多类型错误并提供细致反馈，但语境理解和分类体系仍需改进。


<details>
  <summary>Details</summary>
Motivation: 旨在突破传统基于评分标准的错误反馈局限，利用AI自动化和细化英语写作错误的识别与分类，提升英语作为外语教学中的写作指导效果。

Method: 采用基于Corder、Richards和James语言学理论的详细错误分类，利用Claude 3.5 Sonnet和DeepSeek R1大型语言模型，通过Python API调用实现错误识别、分类和反馈，进行了初步和最终的系统测试验证。

Result: 本研究开发了一种基于大型语言模型（如Claude 3.5 Sonnet和DeepSeek R1）的AI辅助英语写作错误分析系统，能够识别、分类并纠正拼写、语法和标点等多层次写作错误。系统建立了基于Corder、Richards和James等语言学理论的详尽错误分类体系，通过Python API实现，提供比传统评分表更细致的反馈。系统在含复杂真实错误的文本中表现出较强的错别字识别能力，但在语境理解方面存在不足，有时会生成新的错误类别，显示分类体系需进一步完善。整体而言，该研究展示了AI在英语作为外语教学中的应用潜力，强调需提升上下文准确性并扩展分类体系涵盖风格和语篇层面错误。

Conclusion: 该AI辅助系统有效识别多种英语写作错误，展示了AI在外语教学中自动化错误分析的潜力，但需加强语境理解能力并扩展错误分类体系以覆盖更广泛的错误类型。

Abstract: This study describes the development of an AI-assisted error analysis system designed to identify, categorize, and correct writing errors in English. Utilizing Large Language Models (LLMs) like Claude 3.5 Sonnet and DeepSeek R1, the system employs a detailed taxonomy grounded in linguistic theories from Corder (1967), Richards (1971), and James (1998). Errors are classified at both word and sentence levels, covering spelling, grammar, and punctuation. Implemented through Python-coded API calls, the system provides granular feedback beyond traditional rubric-based assessments. Initial testing on isolated errors refined the taxonomy, addressing challenges like overlapping categories. Final testing used "English as she is spoke" by Jose da Fonseca (1855), a text rich with authentic linguistic errors, to evaluate the system's capacity for handling complex, multi-layered analysis. The AI successfully identified diverse error types but showed limitations in contextual understanding and occasionally generated new error categories when encountering uncoded errors. This research demonstrates AI's potential to transform EFL instruction by automating detailed error analysis and feedback. While promising, further development is needed to improve contextual accuracy and expand the taxonomy to stylistic and discourse-level errors.

</details>


### [17] [CryptoBench: A Dynamic Benchmark for Expert-Level Evaluation of LLM Agents in Cryptocurrency](https://arxiv.org/abs/2512.00417)
*Jiacheng Guo,Suozhi Huang,Zixin Yao,Yifan Zhang,Yifu Lu,Jiashuo Liu,Zihao Li,Yanyan Deng,Qixin Xiao,Jia Tian,Kanghong Zhan,Tianyi Li,Xiaochen Liu,Jason Ge,Chaoyang He,Kaixuan Huang,Lin Yang,Wenhao Huang,Mengdi Wang*

Main category: cs.CL

TL;DR: CryptoBench是首个针对加密货币领域的大型语言模型动态基准测试，展示了模型在复杂时效环境下优劣，发现其预测能力不足，提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有通用代理基准测试无法满足加密货币领域极端时效性、高度对抗性信息环境和多样化专业数据源整合的需求，因此需要一个更具挑战性和真实性的评测工具。

Method: 构建了一个动态基准测试平台，包含每月50个由加密货币专业人士设计的问题，涵盖简单/复杂检索和预测四个分类，通过实际模拟分析师工作流程，测试十个大型语言模型在数据检索和预测分析上的能力。

Result: 评估揭示了大型语言模型在数据检索方面表现较好，但在预测分析任务上存在明显弱点，表现出检索与预测能力的不平衡，提示当前模型缺乏深入信息综合分析的能力。

Conclusion: CryptoBench是首个专为加密货币领域设计的动态基准测试，能够精准评估大型语言模型在复杂、时效性强的专业分析环境中的表现，并揭示了主流模型在预测分析任务上的明显不足。

Abstract: This paper introduces CryptoBench, the first expert-curated, dynamic benchmark designed to rigorously evaluate the real-world capabilities of Large Language Model (LLM) agents in the uniquely demanding and fast-paced cryptocurrency domain. Unlike general-purpose agent benchmarks for search and prediction, professional crypto analysis presents specific challenges: \emph{extreme time-sensitivity}, \emph{a highly adversarial information environment}, and the critical need to synthesize data from \emph{diverse, specialized sources}, such as on-chain intelligence platforms and real-time Decentralized Finance (DeFi) dashboards. CryptoBench thus serves as a much more challenging and valuable scenario for LLM agent assessment. To address these challenges, we constructed a live, dynamic benchmark featuring 50 questions per month, expertly designed by crypto-native professionals to mirror actual analyst workflows. These tasks are rigorously categorized within a four-quadrant system: Simple Retrieval, Complex Retrieval, Simple Prediction, and Complex Prediction. This granular categorization enables a precise assessment of an LLM agent's foundational data-gathering capabilities alongside its advanced analytical and forecasting skills.
  Our evaluation of ten LLMs, both directly and within an agentic framework, reveals a performance hierarchy and uncovers a failure mode. We observe a \textit{retrieval-prediction imbalance}, where many leading models, despite being proficient at data retrieval, demonstrate a pronounced weakness in tasks requiring predictive analysis. This highlights a problematic tendency for agents to appear factually grounded while lacking the deeper analytical capabilities to synthesize information.

</details>


### [18] [SCALE: Selective Resource Allocation for Overcoming Performance Bottlenecks in Mathematical Test-time Scaling](https://arxiv.org/abs/2512.00466)
*Yang Xiao,Chunpu Xu,Ruifeng Yuan,Jiashuo Wang,Wenjie Li,Pengfei Liu*

Main category: cs.CL

TL;DR: 本文提出通过难度驱动的选择性计算资源分配SCALE框架，显著提升了大语言模型的数学推理能力与资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有的计算资源分配方法在推理的所有子问题中均衡分配资源，导致难题子问题得不到足够关注，降低了模型的推理效果和资源利用效率。

Method: 提出了一种名为SCALE的框架，包含问题分解、难度评估、选择性处理模式分配（简单问题用系统1，复杂问题用系统2）、以及带上下文传递的顺序执行。

Result: SCALE在AIME25任务上准确率提升了最多13.75个百分点（57.50%提升到71.25%），同时计算成本降低了33%-53%。

Conclusion: 该论文提出了SCALE方法，通过根据子问题难度选择性地分配计算资源，显著提升了大语言模型在数学推理任务中的性能和资源利用效率。

Abstract: Test-time compute scaling has emerged as a powerful paradigm for enhancing mathematical reasoning in large language models (LLMs) by allocating additional computational resources during inference. However, current methods employ uniform resource distribution across all reasoning sub-problems, creating fundamental bottlenecks where challenging sub-problems receive insufficient attention while routine operations consume disproportionate resources. This uniform allocation creates performance bottlenecks where additional computational resources yield diminishing returns. Inspired by dual-process theory, we propose \textbf{SCALE} (Selective Resource Allocation), a framework that selectively allocates computational resources based on sub-problem difficulty. SCALE operates through four stages: (1) problem decomposition into sequential reasoning sub-problems, (2) difficulty assessment of each sub-problem to distinguish between routine operations and computationally challenging sub-problems, (3) selective processing mode assignment between System 1 for simple sub-problems and System 2 for complex ones, and (4) sequential execution with context propagation. By concentrating resources on challenging sub-problems while processing routine operations efficiently, SCALE achieves substantial performance improvements with superior resource utilization. Extensive experiments demonstrate that SCALE significantly outperforms uniform scaling baselines, achieving accuracy improvements of up to 13.75 percentage points (57.50% to 71.25% on AIME25) while reducing computational costs by 33%-53%, representing a major advance in test-time scaling that addresses fundamental limitations of current approaches.

</details>


### [19] [CACARA: Cross-Modal Alignment Leveraging a Text-Centric Approach for Cost-Effective Multimodal and Multilingual Learning](https://arxiv.org/abs/2512.00496)
*Diego A. B. Moreira,Alef I. Ferreira,Jhessica Silva,Gabriel O. dos Santos,Gustavo Bonil,João Gondim,Marina dos Santos,Helena Maia,Simone Hashiguti,Nádia da Silva,Carolina Scarton,Helio Pedrini,Sandra Avila*

Main category: cs.CL

TL;DR: 本论文提出了一种名为CACARA的多模态多语言模型，通过新颖的对齐学习策略，实现了无需全面重训练即可将新模态集成进已有模型，并支持100多种语言。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型训练资源消耗大，扩展至新语言和模态需耗费大量成本，亟需高效集成新模态和多语言的方法。

Method: 提出了基于新兴对齐学习的训练架构，仅对新增模态的与英语语言对齐数据进行微调，从而实现多语言支持和多模态融合。

Result: 模型在音频到文本的检索任务中，R@1指标提升了最高14.24个百分点，性能优于现有最先进的多模态模型，且训练成本大幅降低。

Conclusion: CACARA模型通过新兴的对齐学习方法高效集成新模态和多语言支持，显著提升了音频到文本检索性能，且训练成本低于传统方法。

Abstract: As deep learning models evolve, new applications and challenges are rapidly emerging. Tasks that once relied on a single modality, such as text, images, or audio, are now enriched by seamless interactions between multimodal data. These connections bridge information gaps: an image can visually materialize a text, while audio can add context to an image. Researchers have developed numerous multimodal models, but most rely on resource-intensive training across multiple modalities. Similarly, extending these models to new languages often follows the same resource-heavy training strategy. In this work, we propose a multimodal and multilingual architecture, CACARA, trained through emergent alignment learning, enabling the seamless integration of new modalities into an existing bimodal/multimodal model without requiring full retraining. This work breaks new ground by demonstrating that this emergent alignment paradigm can unlock multilingual capabilities from monolingual training. By fine-tuning the newly incorporated modality only on data aligned with the English language, our model develops support for over 100 languages without explicit multilingual pretraining or tuning of the text encoder. Such emergent multimodal and multilingual properties are gained efficiently, preserving previously learned knowledge at a training cost comparable to that of a monolingual model. Our strategy achieves up to a 14.24 percentage points improvement in R@1 audio-to-text retrieval, outperforming state-of-the-art multimodal models -- all without the heavy computational cost of retraining across every modality and language.

</details>


### [20] [G-KV: Decoding-Time KV Cache Eviction with Global Attention](https://arxiv.org/abs/2512.00504)
*Mengqi Liao,Lu Wang,Chaoyun Zhang,Zekai Shen,Xiaowei Mao,Si Qin,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang,Huaiyu Wan*

Main category: cs.CL

TL;DR: 针对长序列推理中的KV缓存效率问题，提出G-KV方法和后训练优化技术，显著提升模型推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理长序列时面临计算和内存瓶颈，需提高推理效率。

Method: 开发了基于全局评分机制的KV缓存淘汰策略，结合局部与历史注意力分数，辅以强化学习和蒸馏进行后训练优化。

Result: 提出了G-KV方法，通过结合局部与历史注意力得分的全局评分机制，实现更精准的KV缓存淘汰，同时引入强化学习和蒸馏技术优化模型。

Conclusion: G-KV方法有效提升了KV缓存压缩的效果，解决了长期重要性评估不足的问题，改进的模型在压缩KV缓存场景表现优异。

Abstract: Recent reasoning large language models (LLMs) excel in complex tasks but encounter significant computational and memory challenges due to long sequence lengths. KV cache compression has emerged as an effective approach to greatly enhance the efficiency of reasoning. However, existing methods often focus on prompt compression or token eviction with local attention score, overlooking the long-term importance of tokens. We propose G-KV, a KV cache eviction method that employs a global scoring mechanism, combining local and historical attention scores to more accurately assess token importance. Additionally, we introduce post-training techniques, including reinforcement learning and distillation, to optimize models for compressed KV cache settings. The code of this paper is available on: https://github.com/microsoft/G-KV.

</details>


### [21] [Developing a Comprehensive Framework for Sentiment Analysis in Turkish](https://arxiv.org/abs/2512.00515)
*Cem Rifki Aydin*

Main category: cs.CL

TL;DR: 本文针对土耳其语和英语情感分析提出了多项创新方法，融合多种机器学习技术，提升了分类效果，实现了多种语言和任务的领先成果。


<details>
  <summary>Details</summary>
Motivation: 当前土耳其语情感分析研究不足，尤其缺乏综合框架和针对形态复杂语言的系统方法，本文旨在填补这一空白并推动该领域的发展，同时增强英语情感分析的效果。

Method: 结合无监督、半监督和监督特征，利用传统机器学习方法，创建领域特定极性词典，执行细致的形态分析，设计结合循环和递归神经网络的新架构，创新词向量和上下文建模方式。

Result: 本文提出了一个针对土耳其语情感分析的综合框架，并对英语情感分析提出了多种方法。通过结合无监督、半监督和监督指标，生成了新颖且有效的特征集，利用传统机器学习模型超越了神经网络模型的表现。创建了首个针对土耳其语语料的领域特定半监督极性词典，并通过细致的形态分析确定词素极性，适用于其他形态丰富语言。设计了结合循环和递归神经网络的新型架构，开发了融合情感、语法、语义和词汇特点的词向量，同时重定义了英语中的上下文窗口（子句）。此外，还在土耳其语基于方面的情感分析、半监督参数重定义和英语方面术语提取等方面做出贡献，取得了多项领先成果。

Conclusion: 本文提出的方法在土耳其语情感分析领域达到了最先进水平，也促进了英语情感分类的研究，展示了多语言、多技术融合的潜力和广泛应用价值。

Abstract: In this thesis, we developed a comprehensive framework for sentiment analysis that takes its many aspects into account mainly for Turkish. We have also proposed several approaches specific to sentiment analysis in English only. We have accordingly made five major and three minor contributions. We generated a novel and effective feature set by combining unsupervised, semi-supervised, and supervised metrics. We then fed them as input into classical machine learning methods, and outperformed neural network models for datasets of different genres in both Turkish and English. We created a polarity lexicon with a semi-supervised domain-specific method, which has been the first approach applied for corpora in Turkish. We performed a fine morphological analysis for the sentiment classification task in Turkish by determining the polarities of morphemes. This can be adapted to other morphologically-rich or agglutinative languages as well. We have built a novel neural network architecture, which combines recurrent and recursive neural network models for English. We built novel word embeddings that exploit sentiment, syntactic, semantic, and lexical characteristics for both Turkish and English. We also redefined context windows as subclauses in modelling word representations in English. This can also be applied to other linguistic fields and natural language processing tasks. We have achieved state-of-the-art and significant results for all these original approaches. Our minor contributions include methods related to aspect-based sentiment in Turkish, parameter redefinition in the semi-supervised approach, and aspect term extraction techniques for English. This thesis can be considered the most detailed and comprehensive study made on sentiment analysis in Turkish as of July, 2020. Our work has also contributed to the opinion classification problem in English.

</details>


### [22] [Catch Me If You Can: How Smaller Reasoning Models Pretend to Reason with Mathematical Fidelity](https://arxiv.org/abs/2512.00552)
*Subramanyam Sahoo,Vinija Jain,Saanidhya Vats,Siddharth Mohapatra,Rui Min,Aman Chadha,Divya Chaudhary*

Main category: cs.CL

TL;DR: 本文提出了一个新的数学推理诊断框架，通过多维度评估揭示了语言模型在数学推理中隐藏的缺陷，推动研究从单纯准确率向真实推理能力转变。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要靠答案准确率，难以发现模型在逻辑推理方面的根本缺陷，需要更细致的诊断工具。

Method: 提出一个包含前向-后向一致性、传递性覆盖、反事实敏感性和扰动鲁棒性四个维度的诊断框架，检测模型的数学推理能力。

Result: 在MenatQA数据集上测试Qwen3-0.6B模型，发现准确率虽高（70%+），但推理一致性和鲁棒性很差，表明模型依赖模式匹配而非真正的逻辑计算。

Conclusion: 当前语言模型在数学推理评估中，准确率高并不代表推理真实可靠，存在推理失败的情况。

Abstract: Current evaluation of mathematical reasoning in language models relies primarily on answer accuracy, potentially masking fundamental failures in logical computation. We introduce a diagnostic framework that distinguishes genuine mathematical reasoning from superficial pattern matching through four complementary axes: forward-backward consistency, transitivity coverage, counterfactual sensitivity, and perturbation robustness. Through a case study applying this framework to Qwen3-0.6B on the MenatQA dataset, we reveal a striking disconnect between surface performance and reasoning fidelity. While the model achieves reasonable answer accuracy (70%+), it demonstrates poor backward consistency (15%), limited transitivity coverage (32.2%), and brittle sensitivity to perturbations. Our diagnostics expose reasoning failures invisible to traditional accuracy metrics, suggesting that this small model relies heavily on pattern matching rather than genuine logical computation. While our empirical findings are based on a single 600M-parameter model, the diagnostic framework itself is model-agnostic and generalizable. We release our evaluation protocols to enable the research community to assess reasoning fidelity across different model scales and architectures, moving beyond surface-level accuracy toward verifiable mathematical reasoning.

</details>


### [23] [Slovak Conceptual Dictionary](https://arxiv.org/abs/2512.00579)
*Miroslav Blšták*

Main category: cs.CL

TL;DR: 针对斯洛伐克语资源匮乏的问题，开发了首个概念词典，提升语言处理能力。


<details>
  <summary>Details</summary>
Motivation: 斯洛伐克语属于资源稀缺语言，缺乏大型机器可读语言数据源，导致许多自动处理任务效果较差甚至难以解决。

Method: 设计并构建斯洛伐克语的新型概念词典作为首个此类语言工具。

Result: 成功推出了斯洛伐克语首个概念词典，为该语言提供了必要的词汇和知识资源支持。

Conclusion: 该概念词典填补了斯洛伐克语资源空白，有助于改善相关自然语言处理任务的效果。

Abstract: When solving tasks in the field of natural language processing, we sometimes need dictionary tools, such as lexicons, word form dictionaries or knowledge bases. However, the availability of dictionary data is insufficient in many languages, especially in the case of low resourced languages. In this article, we introduce a new conceptual dictionary for the Slovak language as the first linguistic tool of this kind. Since Slovak language is a language with limited linguistic resources and there are currently not available any machine-readable linguistic data sources with a sufficiently large volume of data, many tasks which require automated processing of Slovak text achieve weaker results compared to other languages and are almost impossible to solve.

</details>


### [24] [Wikontic: Constructing Wikidata-Aligned, Ontology-Aware Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2512.00590)
*Alla Chepurova,Aydar Bulatov,Yuri Kuratov,Mikhail Burtsev*

Main category: cs.CL

TL;DR: Wikontic方法高效构建高质量知识图谱，提升大语言模型问答性能，超过多项基准和现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型(LLMs)的系统通常将知识图谱(KGs)作为文本检索的辅助结构，未充分挖掘KGs的内在质量。

Method: 提出Wikontic，一个多阶段流水线方法，从开放域文本中构建知识图谱，包含候选三元组提取、基于Wikidata的类型和关系约束、实体归一化等步骤。

Result: 生成的知识图谱紧凑、符合本体、良好连通。在MuSiQue数据集上，正确答案实体出现在96%的生成三元组中。HotpotQA和MuSiQue上仅用三元组即可达到或超越多种检索增强生成基线。MINE-1基准测试信息保留率达86%，超过现有方法。同时构建效率高，生成输出令牌数远低于其他方法。

Conclusion: Wikontic流水线显著提升知识图谱质量，提供了一种高效且可扩展的方式，将结构化知识有效融合进大语言模型的应用中。

Abstract: Knowledge graphs (KGs) provide structured, verifiable grounding for large language models (LLMs), but current LLM-based systems commonly use KGs as auxiliary structures for text retrieval, leaving their intrinsic quality underexplored. In this work, we propose Wikontic, a multi-stage pipeline that constructs KGs from open-domain text by extracting candidate triplets with qualifiers, enforcing Wikidata-based type and relation constraints, and normalizing entities to reduce duplication. The resulting KGs are compact, ontology-consistent, and well-connected; on MuSiQue, the correct answer entity appears in 96% of generated triplets. On HotpotQA, our triplets-only setup achieves 76.0 F1, and on MuSiQue 59.8 F1, matching or surpassing several retrieval-augmented generation baselines that still require textual context. In addition, Wikontic attains state-of-the-art information-retention performance on the MINE-1 benchmark (86%), outperforming prior KG construction methods. Wikontic is also efficient at build time: KG construction uses less than 1,000 output tokens, about 3$\times$ fewer than AriGraph and $<$1/20 of GraphRAG. The proposed pipeline enhances the quality of the generated KG and offers a scalable solution for leveraging structured knowledge in LLMs.

</details>


### [25] [Prism: A Minimal Compositional Metalanguage for Specifying Agent Behavior](https://arxiv.org/abs/2512.00611)
*Franck Binard,Vanja Kljajevic*

Main category: cs.CL

TL;DR: Prism是一种小型组合型元语言，用于指定使用工具的软件代理的行为，通过固定的核心上下文和可扩展的领域定义，实现可组合且可检查的代理策略。


<details>
  <summary>Details</summary>
Motivation: 传统工具使用软件代理行为难以统一表示和管理，Prism旨在提供一种组合且简洁的语言结构，支持策略的自然语言映射及分析验证。

Method: Prism基于一个固定的核心上下文Core1，提供基本的类别和抽象组合子，领域通过定义子语法扩展核心，引入新类别、谓词和工具，策略使用单一抽象操作符书写，条件以选择形式出现。

Result: Prism通过多个实例展示了其在不同领域（恒温器控制、安全、推荐、医疗监测）中自然语言规则如何转换为可执行代理策略，提升了策略的可检查性和安全性。

Conclusion: Prism通过固定的核心语法与领域特定的扩展，实现了自然语言决策规则到可执行策略的映射，促进了策略的分析、验证和安全控制。

Abstract: Prism is a small, compositional metalanguage for specifying the behaviour of tool-using software agents. Rather than introducing ad hoc control constructs, Prism is built around a fixed core context, Core1, which provides a minimal background grammar of categories numbers, strings, user prompts, tools together with abstract combinators for booleans, predicates, pairs, and lists. Agent policies are written as ordinary expressions using a single abstraction operator so that conditionals appear as selections between alternatives instead of imperative if-else blocks. Domains extend the core by defining their own context-mini-grammars that introduce new categories, predicates, and external tools while reusing the same compositional machinery. We illustrate this with worked examples from thermostat control, home security, e-commerce recommendation, and medical monitoring, showing how natural language decision rules can be mapped to inspectable, executable policies. From a linguistic perspective, Prism enforces a clear separation between a reusable grammar-like core and domain specific lexicons and treats tools as bridges between internal policy representations and the external world. From an engineering perspective, it offers a compact interface language for agent control, making the space of possible actions explicit and amenable to analysis, verification, and safety constraints.

</details>


### [26] [ART: Adaptive Response Tuning Framework -- A Multi-Agent Tournament-Based Approach to LLM Response Optimization](https://arxiv.org/abs/2512.00617)
*Omer Jauhar Khan*

Main category: cs.CL

TL;DR: 提出ART框架，利用多模型协作和ELO排名优化，显著提升大型语言模型生成响应的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型的回答常存在不一致、幻觉和质量波动问题，需要一种系统性优化方法提升生成内容的准确性和稳定性。

Method: 采用锦标赛式ELO排名机制和多智能体协作方式，使多个语言模型代理通过竞争、批评和协作产生共识回答，并设计了可配置的锦标赛参数、动态代理选择及多种共识融合策略。

Result: 实验结果显示，ART框架在响应准确性、连贯性和可靠性方面较基线单模型方法提升显著，总体质量指标提升8.4%，ELO评分收敛的R22值超过0.96。

Conclusion: 通过引入基于锦标赛式ELO排名和多智能体推理的自适应响应调优框架ART，大幅提升了大型语言模型的输出质量，生成的响应在准确性、一致性和可靠性方面明显优于单一模型。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language understanding and generation. However, single-model responses often exhibit inconsistencies, hallucinations, and varying quality across different query domains. This paper presents ART (Adaptive Response Tuning), a novel framework that employs tournament-style ELO ranking and multi-agent reasoning to systematically optimize LLM outputs. By enabling multiple LLM agents to compete, critique, and collaborate through structured tournament workflows, ART produces consensus responses that outperform individual model outputs. Our framework introduces configurable tournament parameters, dynamic agent selection, and multiple consensus fusion strategies. Experimental evaluations demonstrate significant improvements in response accuracy, coherence, and reliability compared to baseline single-model approaches. The ART framework provides a scalable, production-ready solution for applications requiring high-quality, vetted LLM responses, achieving an 8.4% improvement in overall quality metrics and R22 values exceeding 0.96 in ELO rating convergence.

</details>


### [27] [Sycophancy Claims about Language Models: The Missing Human-in-the-Loop](https://arxiv.org/abs/2512.00656)
*Jan Batzner,Volker Stocker,Stefan Schmid,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 本文回顾了大语言模型谄媚性研究中的方法挑战，指出缺乏人类感知评估及概念区分问题，并给出未来研究建议。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多研究指出LLMs存在谄媚响应模式，作者希望解决测量谄媚行为的挑战并推动该领域研究更系统化。

Method: 文献回顾了衡量LLMs谄媚性的方法论挑战，并识别出五种核心操作化指标。

Result: 总结了当前研究的不足，提出了未来研究中需要兼顾人类感知评价及更加清晰区分谄媚行为的建议。

Conclusion: 当前研究中大语言模型(LLMs)的谄媚响应难以与AI对齐中的相关概念区分，并且缺乏对人类感知的评估。

Abstract: Sycophantic response patterns in Large Language Models (LLMs) have been increasingly claimed in the literature. We review methodological challenges in measuring LLM sycophancy and identify five core operationalizations. Despite sycophancy being inherently human-centric, current research does not evaluate human perception. Our analysis highlights the difficulties in distinguishing sycophantic responses from related concepts in AI alignment and offers actionable recommendations for future research.

</details>


### [28] [Graphing the Truth: Structured Visualizations for Automated Hallucination Detection in LLMs](https://arxiv.org/abs/2512.00663)
*Tanmay Agrawal*

Main category: cs.CL

TL;DR: 针对大语言模型在企业应用中产生幻觉的问题，本文设计交互式知识图谱辅助用户识别和纠正错误，建立人机闭环，提升模型响应质量。


<details>
  <summary>Details</summary>
Motivation: 企业环境中大语言模型结合专有领域知识时，受限于上下文窗口大小和训练数据与知识的不一致，常导致高度可信但错误的“幻觉”问题，且现有方法难以提供确定性保障。

Method: 提出一种框架，将专有知识和模型生成内容组织成交互式可视化知识图谱，通过链接模型断言和真实来源，并标示置信水平，帮助用户直观识别潜在幻觉区域。

Result: 该框架使用户能够诊断不一致性，发现薄弱推理链条，并提供纠正反馈，形成了人机循环反馈机制，提高模型可靠性并持续改善响应质量。

Conclusion: 基于交互式知识图谱的人机协同流程有效缓解了语言模型中的幻觉问题，提升了模型在企业场景中的应用可靠性。

Abstract: Large Language Models have rapidly advanced in their ability to interpret and generate natural language. In enterprise settings, they are frequently augmented with closed-source domain knowledge to deliver more contextually informed responses. However, operational constraints such as limited context windows and inconsistencies between pre-training data and supplied knowledge often lead to hallucinations, some of which appear highly credible and escape routine human review. Current mitigation strategies either depend on costly, large-scale gold-standard Q\&A curation or rely on secondary model verification, neither of which offers deterministic assurance. This paper introduces a framework that organizes proprietary knowledge and model-generated content into interactive visual knowledge graphs. The objective is to provide end users with a clear, intuitive view of potential hallucination zones by linking model assertions to underlying sources of truth and indicating confidence levels. Through this visual interface, users can diagnose inconsistencies, identify weak reasoning chains, and supply corrective feedback. The resulting human-in-the-loop workflow creates a structured feedback loop that can enhance model reliability and continuously improve response quality.

</details>


### [29] [A Comparison of Human and ChatGPT Classification Performance on Complex Social Media Data](https://arxiv.org/abs/2512.00673)
*Breanna E. Green,Ashley L. Shea,Pengfei Zhao,Drew B. Margolin*

Main category: cs.CL

TL;DR: 本文评估了GPT-4在细微语言分类任务中的表现，发现其存在显著困难，提示设计能部分改善结果，建议慎用GPT进行类似复杂语言分类。


<details>
  <summary>Details</summary>
Motivation: 当前生成式人工智能工具如ChatGPT在计算社会科学中的应用日益广泛，但对其在处理包含细微语言的数据集复杂任务上的表现理解仍不足，亟需深入研究。

Method: 通过比较GPT-3.5、GPT-4和GPT-4o在复杂语言数据集的分类和标注任务中的表现，设计四种提示风格，评估其准确率、召回率和F1分数，结合定量和定性分析进行综合评价。

Result: 实验结果表明，尽管包含标签定义的提示能在一定程度上提升模型性能，GPT-4在分类细微语言方面仍然存在显著挑战，定性分析揭示了四个具体的发现。

Conclusion: GPT-4在处理涉及细微语言的分类任务时表现存在困难，虽然提示中包含标签定义可以提升性能，但整体表现仍有限，需谨慎使用。

Abstract: Generative artificial intelligence tools, like ChatGPT, are an increasingly utilized resource among computational social scientists. Nevertheless, there remains space for improved understanding of the performance of ChatGPT in complex tasks such as classifying and annotating datasets containing nuanced language. Method. In this paper, we measure the performance of GPT-4 on one such task and compare results to human annotators. We investigate ChatGPT versions 3.5, 4, and 4o to examine performance given rapid changes in technological advancement of large language models. We craft four prompt styles as input and evaluate precision, recall, and F1 scores. Both quantitative and qualitative evaluations of results demonstrate that while including label definitions in prompts may help performance, overall GPT-4 has difficulty classifying nuanced language. Qualitative analysis reveals four specific findings. Our results suggest the use of ChatGPT in classification tasks involving nuanced language should be conducted with prudence.

</details>


### [30] [FastPOS: Language-Agnostic Scalable POS Tagging Framework Low-Resource Use Case](https://arxiv.org/abs/2512.00745)
*Md Abdullah Al Kafi,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 提出一个基于Transformer的语言无关POS标注框架，支持低资源语言快速迁移，提升标注效果并便于研究者专注于语言预处理和数据集优化。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言的POS标注问题，减少模型设计和调优工作量，促进跨语言快速适应。

Method: 基于Transformer的语言无关POS标注框架，通过极少代码即可将模型从孟加拉语迁移到印地语。

Result: 框架在孟加拉语和印地语上分别达到96.85%和97%的标注准确度，F1分数保持稳健，表现出良好的迁移能力。

Conclusion: 该框架通过模块化和开源设计，实现了高效的跨语言适应性和高性能POS标注，推动了低资源语言的自然语言处理进展。

Abstract: This study proposes a language-agnostic transformer-based POS tagging framework designed for low-resource languages, using Bangla and Hindi as case studies. With only three lines of framework-specific code, the model was adapted from Bangla to Hindi, demonstrating effective portability with minimal modification. The framework achieves 96.85 percent and 97 percent token-level accuracy across POS categories in Bangla and Hindi while sustaining strong F1 scores despite dataset imbalance and linguistic overlap. A performance discrepancy in a specific POS category underscores ongoing challenges in dataset curation. The strong results stem from the underlying transformer architecture, which can be replaced with limited code adjustments. Its modular and open-source design enables rapid cross-lingual adaptation while reducing model design and tuning overhead, allowing researchers to focus on linguistic preprocessing and dataset refinement, which are essential for advancing NLP in underrepresented languages.

</details>


### [31] [Auxiliary-Hyperparameter-Free Sampling: Entropy Equilibrium for Text Generation](https://arxiv.org/abs/2512.00789)
*Xiaodong Cai,Hai Lin,Shaoxiong Zhan,Weiqi Luo,Hong-Gee Kim,Hongyan Hao,Yu Yang,Hai-Tao Zheng*

Main category: cs.CL

TL;DR: 本文提出了一种无超参数的采样策略EES，通过平衡信息熵和概率质量，提升了大语言模型文本生成的质量与多样性，简化了模型部署。


<details>
  <summary>Details</summary>
Motivation: 现有采样策略依赖额外超参数，导致需要大量调优，增加部署复杂性，本研究旨在设计一种无需超参数调节的高效采样方法。

Method: 提出了一种基于信息理论的辅助无超参数采样策略——Entropy Equilibrium Sampling（EES），通过平衡归一化熵与概率质量动态调整候选集合。

Result: 在推理和文本生成任务中，EES方法在不同模型架构和温度设置下表现稳定，提升了文本质量同时简化了部署流程。

Conclusion: Entropy Equilibrium Sampling (EES)方法在文本生成任务中表现出色，能够在多种温度设置下保持准确性、一致性与多样性，并且无需额外超参数调节。

Abstract: Token sampling strategies critically influence text generation quality in large language models (LLMs). However, existing methods introduce additional hyperparameters, requiring extensive tuning and complicating deployment. We present Entropy Equilibrium Sampling (EES), an auxiliary hyperparameter-free approach inspired by information theory that can dynamically adjust candidate sets by balancing normalized entropy with probability mass. We evaluate EES on both reasoning and generation tasks across a range of model architectures. Our results show that EES consistently performs well across temperature settings, delivering competitive accuracy and coherence while maintaining diversity. By eliminating the need for hyperparameter tuning, EES greatly simplifies deployment while improving performance. Code is available at https://github.com/shuanncai/EES

</details>


### [32] [Accelerating Bangla NLP Tasks with Automatic Mixed Precision: Resource-Efficient Training Preserving Model Efficacy](https://arxiv.org/abs/2512.00829)
*Md Mehrab Hossain Opi,Sumaiya Khan,Moshammad Farzana Rahman*

Main category: cs.CL

TL;DR: 通过AMP训练，显著提升孟加拉语NLP模型训练效率，降低内存需求，且性能基本不受影响，有助于在硬件受限环境推广先进NLP技术。


<details>
  <summary>Details</summary>
Motivation: NLP模型训练需要大量计算资源和时间，尤其是在硬件资源受限的孟加拉语NLP领域，亟需提高训练效率的方法。

Method: 采用自动混合精度（AMP）训练方法，结合16位和32位浮点计算动态混合，提高计算效率。

Result: 使用AMP训练，四个孟加拉语NLP任务（情感分析、命名实体识别、错误分类、问答）中的训练速度提升44.5%，内存消耗减少17.6%，同时F1分数保持在全精度基线的99.7%。

Conclusion: 自动混合精度训练有效降低了孟加拉语NLP模型的计算资源需求和训练时间，保持了模型性能，促进了硬件受限环境下的NLP技术普及。

Abstract: Training models for Natural Language Processing (NLP) requires substantial computational resources and time, posing significant challenges, especially for NLP development in Bangla, where access to high-end hardware is often limited. In this work, we explore automatic mixed precision (AMP) training as a means to improve computational efficiency without sacrificing model performance. By leveraging a dynamic mix of 16-bit and 32-bit floating-point computations, AMP lowers GPU memory requirements and speeds up training without degrading model performance. We evaluate AMP across four standard Bangla NLP tasks, namely sentiment analysis, named entity recognition, error classification, and question answering, using four transformer-based models: BanglaBERT, BanglishBERT, XLM-R, and mBERT. Our results demonstrate that AMP accelerates training by 44.5% and reduces memory consumption by 17.6%, while maintaining F-1 score within 99.7% of the full-precision baselines. This empirical study highlights AMP's potential to democratize access to state-of-the-art NLP capabilities in hardware-constrained settings by lowering computational barriers.

</details>


### [33] [WaterSearch: A Quality-Aware Search-based Watermarking Framework for Large Language Models](https://arxiv.org/abs/2512.00837)
*Yukang Lin,Jiahao Shao,Shuoran Jiang,Wentao Zhu,Bingjie Lu,Xiangping Wu,Joanna Siebert,Qingcai Chen*

Main category: cs.CL

TL;DR: 提出了WaterSearch水印嵌入和检测框架，有效提升了文本质量和水印检测强度，同时具备强鲁棒性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于概率操控的水印方法在信号强度与文本质量之间存在权衡，强水印会降低下游任务性能，需设计一种提升水印检测强度同时保证文本质量的方案。

Method: 设计了一种通过控制种子池以支持多样化并行生成的水印嵌入方案，并基于此提出WaterSearch框架，该框架利用句子级搜索策略优化文本质量和水印信号特征。结合句子级检测方法，实现强攻击鲁棒性。

Result: 在三个主流大语言模型和十个任务上，WaterSearch在95%水印检测强度下，比最先进基线平均性能提升51.01%；在短文本和低熵输出场景分别提升47.78%和36.47%；在插入、同义词替换、改写等攻击下依然保持高检测率，展现出良好抗攻击能力。

Conclusion: WaterSearch通过种子池控制实现多样化并行生成，显著提升水印文本质量与检测性能，且在多种攻击下保持强鲁棒性，为大语言模型文本水印提供了一种有效且可靠的解决方案。

Abstract: Watermarking acts as a critical safeguard in text generated by Large Language Models (LLMs). By embedding identifiable signals into model outputs, watermarking enables reliable attribution and enhances the security of machine-generated content. Existing approaches typically embed signals by manipulating token generation probabilities. Despite their effectiveness, these methods inherently face a trade-off between detectability and text quality: the signal strength and randomness required for robust watermarking tend to degrade the performance of downstream tasks.
  In this paper, we design a novel embedding scheme that controls seed pools to facilitate diverse parallel generation of watermarked text. Based on that scheme, we propose WaterSearch, a sentence-level, search-based watermarking framework adaptable to a wide range of existing methods. WaterSearch enhances text quality by jointly optimizing two key aspects: 1) distribution fidelity and 2) watermark signal characteristics. Furthermore, WaterSearch is complemented by a sentence-level detection method with strong attack robustness. We evaluate our method on three popular LLMs across ten diverse tasks. Extensive experiments demonstrate that our method achieves an average performance improvement of 51.01\% over state-of-the-art baselines at a watermark detectability strength of 95\%. In challenging scenarios such as short text generation and low-entropy output generation, our method yields performance gains of 47.78\% and 36.47\%, respectively. Moreover, under different attack senarios including insertion, synonym substitution and paraphrase attasks, WaterSearch maintains high detectability, further validating its robust anti-attack capabilities. Our code is available at \href{https://github.com/Yukang-Lin/WaterSearch}{https://github.com/Yukang-Lin/WaterSearch}.

</details>


### [34] [Less is More: Resource-Efficient Low-Rank Adaptation](https://arxiv.org/abs/2512.00878)
*Chunlin Tian,Xuyang Wei,Huanrong Liu,Zhijiang Guo,Li Li*

Main category: cs.CL

TL;DR: 本文提出EffiLoRA，一种轻量级的低秩适应方法，通过参数共享和选择性更新降低训练成本，提高大模型多模态任务的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA方法虽有效，但存在显著的计算开销和参数干扰，尤其在复杂数据集和多模态任务中表现有限。

Method: 提出了EffiLoRA方法，通过在所有Transformer层共享统一的A矩阵，并动态选择性更新B矩阵，实现了资源与性能的动态权衡。

Result: EffiLoRA在语言理解、视觉指令调优及图像生成等多种任务中均优于传统LoRA，展现了更高的训练效率和更好的鲁棒性。

Conclusion: EffiLoRA在多模态任务中显著提升了参数效率和模型性能，减少了训练资源消耗，且提高了模型的稳健性。

Abstract: Low-Rank Adaptation (LoRA) is a widely adopted parameter-efficient fine-tuning (PEFT) method for Large Language Models (LLMs), but it still incurs notable overhead and suffers from parameter interference in complex datasets. While re- cent works decouple LoRA update matrices to exploit matrix-wise asymmetry, training costs remain high. We revisit LoRA from the perspective of inter-matrix and intra-layer parameter redundancy and propose Resource-Efficient Low-Rank Adaptation, EffiLoRA, a lightweight and generalizable approach for language, multimodal, and diffusion models. EffiLoRA employs a unified A matrix across all transformer layers and introduces a runtime selective B matrices up- date to dynamically trade-off the system resource budget and model performance. EffiLoRA consistently outperforms LoRA across diverse modalities, including commonsense reasoning, visual instruction tuning, and image generation, demon- strating improved efficiency and robustness.

</details>


### [35] [Reward Auditor: Inference on Reward Modeling Suitability in Real-World Perturbed Scenarios](https://arxiv.org/abs/2512.00920)
*Jianxiang Zang,Yongda Wei,Ruxue Bai,Shiyu Jiang,Nijia Mo,Binhong Li,Qiang Sun,Hui Liu*

Main category: cs.CL

TL;DR: Reward Auditor提出了一种科学审计奖励模型适用性的框架，揭示了模型在真实扰动下的系统性脆弱性，推动更安全稳健的大语言模型对齐。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型评估仅关注特定场景下的偏好识别准确率，忽略了模型在真实世界场景中可能存在的条件不可靠性和系统性漏洞，急需一种新方法对这种适用性进行评估。

Method: 本文提出了Reward Auditor，一种基于假设检验的科学审计框架，通过量化奖励模型在真实世界扰动下偏好感知置信度分布的下降，评估奖励模型的适用性和系统性脆弱性。

Result: Reward Auditor能够在真实扰动场景下统计显著地检测到奖励模型的系统性脆弱性，量化其漏洞的确定性和严重性，从而为安全对齐和模型可信度提升提供科学依据。

Conclusion: 当前的奖励模型评估方法忽视了模型在真实世界扰动下的条件可靠性，存在系统性脆弱性。Reward Auditor框架通过科学审计方法有效揭示了奖励模型在不同真实场景中的系统性漏洞，为构建更安全、更稳健的语言模型对齐系统奠定了基础。

Abstract: Reliable reward models (RMs) are critical for ensuring the safe alignment of large language models (LLMs). However, current evaluation methods focus solely on preference perception accuracies in given specific scenarios, obscuring the critical vulnerabilities of RMs in real-world scenarios. We identify the true challenge lies in assessing a novel dimension: Suitability, defined as conditional reliability under specific real-world perturbations. To this end, we introduce Reward Auditor, a hypothesis-testing framework specifically designed for RM suitability inference. Rather than answering "How accurate is the RM's preference perception for given samples?", it employs scientific auditing to answer: "Can we infer RMs exhibit systematic vulnerabilities in specific real-world scenarios?". Under real-world perturbed scenarios, Reward Auditor quantifies statistical significance and effect size by auditing distribution degradation of RM preference perception confidence. This enables inference of both the certainty and severity of RM vulnerabilities across diverse real-world scenarios. This lays a solid foundation for building next-generation LLM alignment systems that are verifiably safe, more robust, and trustworthy.

</details>


### [36] [Mitigating Hallucinations in Zero-Shot Scientific Summarisation: A Pilot Study](https://arxiv.org/abs/2512.00931)
*Imane Jaaouine,Ross D. King*

Main category: cs.CL

TL;DR: 通过多种提示工程方法对6个大型语言模型的0-shot科学摘要任务进行评测，结果显示关键句重复和随机句子添加有效减少了上下文不一致幻觉。


<details>
  <summary>Details</summary>
Motivation: 探究提示工程方法是否能减少大型语言模型在零样本科研文本摘要中出现的上下文不一致幻觉，即与用户提示不匹配的输出。

Method: 采用7种提示工程方法（基础提示、两级增加复杂度的指令提示、两级关键句重复、两级随机句子重复）对6个指令调优的大型语言模型进行0-shot科研文本摘要生成。

Result: 关键句重复（CR）和随机句子添加（RA）明显提升了生成摘要与原文的词汇一致性。通过ROUGE、BERTScore等指标对336个摘要进行评估，统计分析支持该结论。

Conclusion: 提示工程方法尤其是关键句重复和随机添加，能显著改善大型语言模型零样本科学文本摘要的上下文一致性，减少幻觉现象，展现了提示工程在科学摘要任务中的潜力。

Abstract: Large language models (LLMs) produce context inconsistency hallucinations, which are LLM generated outputs that are misaligned with the user prompt. This research project investigates whether prompt engineering (PE) methods can mitigate context inconsistency hallucinations in zero-shot LLM summarisation of scientific texts, where zero-shot indicates that the LLM relies purely on its pre-training data. Across eight yeast biotechnology research paper abstracts, six instruction-tuned LLMs were prompted with seven methods: a base- line prompt, two levels of increasing instruction complexity (PE-1 and PE-2), two levels of context repetition (CR-K1 and CR-K2), and two levels of random addition (RA-K1 and RA-K2). Context repetition involved the identification and repetition of K key sentences from the abstract, whereas random addition involved the repetition of K randomly selected sentences from the abstract, where K is 1 or 2. A total of 336 LLM-generated summaries were evaluated using six metrics: ROUGE-1, ROUGE-2, ROUGE-L, BERTScore, METEOR, and cosine similarity, which were used to compute the lexical and semantic alignment be- tween the summaries and the abstracts. Four hypotheses on the effects of prompt methods on summary alignment with the reference text were tested. Statistical analysis on 3744 collected datapoints was performed using bias-corrected and accelerated (BCa) bootstrap confidence intervals and Wilcoxon signed-rank tests with Bonferroni-Holm correction. The results demonstrated that CR and RA significantly improve the lexical alignment of LLM-generated summaries with the abstracts. These findings indicate that prompt engineering has the potential to impact hallucinations in zero-shot scientific summarisation tasks.

</details>


### [37] [DeformAr: Rethinking NER Evaluation through Component Analysis and Visual Analytics](https://arxiv.org/abs/2512.00938)
*Ahmed Mustafa Younes*

Main category: cs.CL

TL;DR: DeformAr框架通过跨组件和行为分析系统诊断阿拉伯语NER系统的性能差异，解释模型表现瓶颈，促进低资源语言模型分析。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语NER系统性能远落后于英语系统，导致这一差距的多因素交互作用尚未系统分析，亟需一种综合调试和解释框架以深入揭示性能瓶颈。

Method: 采用数据提取库和交互式仪表盘，分阶段进行跨组件诊断和行为分析，结合解释性技术、令牌级指标以及表示空间分析，系统解析数据与模型交互对性能的影响。

Result: 该论文提出了DeformAr，一个针对阿拉伯语命名实体识别（NER）系统性能差异的调试与评估框架。该框架通过数据提取库和交互式仪表盘，采用跨组件分析和行为分析两个阶段，系统地诊断数据与模型之间的交互作用及其对性能的影响。通过结合可解释性技术、令牌级指标和表示空间分析，DeformAr能够揭示阿拉伯语NER系统相较于英语系统表现不佳的原因，填补了阿拉伯语NLP领域的研究空白。

Conclusion: DeformAr为阿拉伯语NER系统提供了首个基于组件的可解释性工具，有效揭示性能差异的根因，推动了低资源语言模型的深入理解与改进。

Abstract: Transformer models have significantly advanced Natural Language Processing (NLP), demonstrating strong performance in English. However, their effectiveness in Arabic, particularly for Named Entity Recognition (NER), remains limited, even with larger pre-trained models. This performance gap stems from multiple factors, including tokenisation, dataset quality, and annotation inconsistencies. Existing studies often analyze these issues in isolation, failing to capture their joint effect on system behaviour and performance.
  We introduce DeformAr (Debugging and Evaluation Framework for Transformer-based NER Systems), a novel framework designed to investigate and explain the performance discrepancy between Arabic and English NER systems. DeformAr integrates a data extraction library and an interactive dashboard, supporting two modes of evaluation: cross-component analysis and behavioural analysis. The framework divides each language into dataset and model components to examine their interactions.
  The analysis proceeds in two stages. First, cross-component analysis provides systematic diagnostic measures across data and model subcomponents, addressing the "what," "how," and "why" behind observed discrepancies. The second stage applies behavioural analysis by combining interpretability techniques with token-level metrics, interactive visualisations, and representation space analysis. These stages enable a component-aware diagnostic process that detects model behaviours and explains them by linking them to underlying representational patterns and data factors. DeformAr is the first Arabic-specific, component-based interpretability tool, offering a crucial resource for advancing model analysis in under-resourced languages.

</details>


### [38] [Fine-tuning of lightweight large language models for sentiment classification on heterogeneous financial textual data](https://arxiv.org/abs/2512.00946)
*Alvaro Paredes Amorin,Andre Python,Christoph Weisser*

Main category: cs.CL

TL;DR: 轻量级开源大语言模型凭借有限计算资源和少量数据，就能在金融文本情感分析任务中达成与大型模型相当的效果，具有良好的成本效益和应用潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在金融市场分析中表现优秀，但因需要大量计算资源和专有数据集，限制了很多研究者和从业者的使用。研究轻量级开源LLMs在有限资源条件下的泛化能力，以满足实际应用需求。

Method: 对比FinBERT和三种轻量级开源LLMs（DeepSeek-LLM 7B、Llama3 8B Instruct和Qwen3 8B）在五个公开的金融文本数据集上的表现，包含不同数据大小、来源、格式和语言，使用零样本和少样本学习场景进行评估。

Result: 发现轻量级开源LLMs在大多数测试场景下优于基准FinBERT模型，尤其是Qwen3 8B和Llama3 8B，在仅使用5%训练数据情况下依然表现良好。结果适用于零样本和少样本学习。

Conclusion: 轻量级开源大语言模型（LLMs）在金融领域的情感理解任务中表现出竞争力，即使只使用了少量训练数据，也能在多样化数据集上达到较好效果，特别是Qwen3 8B和Llama3 8B模型。

Abstract: Large language models (LLMs) play an increasingly important role in finan- cial markets analysis by capturing signals from complex and heterogeneous textual data sources, such as tweets, news articles, reports, and microblogs. However, their performance is dependent on large computational resources and proprietary datasets, which are costly, restricted, and therefore inacces- sible to many researchers and practitioners. To reflect realistic situations we investigate the ability of lightweight open-source LLMs - smaller and publicly available models designed to operate with limited computational resources - to generalize sentiment understanding from financial datasets of varying sizes, sources, formats, and languages. We compare the benchmark finance natural language processing (NLP) model, FinBERT, and three open-source lightweight LLMs, DeepSeek-LLM 7B, Llama3 8B Instruct, and Qwen3 8B on five publicly available datasets: FinancialPhraseBank, Financial Question Answering, Gold News Sentiment, Twitter Sentiment and Chinese Finance Sentiment. We find that LLMs, specially Qwen3 8B and Llama3 8B, perform best in most scenarios, even from using only 5% of the available training data. These results hold in zero-shot and few-shot learning scenarios. Our findings indicate that lightweight, open-source large language models (LLMs) consti- tute a cost-effective option, as they can achieve competitive performance on heterogeneous textual data even when trained on only a limited subset of the extensive annotated corpora that are typically deemed necessary.

</details>


### [39] [Table as a Modality for Large Language Models](https://arxiv.org/abs/2512.00947)
*Liyao Li,Chao Ye,Wentao Ye,Yifei Sun,Zhe Jiang,Haobo Wang,Jiaming Tian,Yiming Zhang,Ningtao Wang,Xing Fu,Gang Chen,Junbo Zhao*

Main category: cs.CL

TL;DR: 本文提出TAMO多模态框架，通过保持表格结构信息提升大语言模型对表格推理任务的效果，在多项数据集上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型处理表格数据时将其序列化，导致结构信息丢失，继而影响对表格推理任务的表现，亟需方法保留表格的内在结构特性以提升模型泛化能力。

Method: 提出了一种多模态学习框架TAMO，利用超图神经网络作为全局表格编码器，将表格结构信息与文本信息融合后输入大语言模型，保持表结构完整性。

Result: 本文通过提出StructQA基准测试，发现现有最先进的大语言模型（如GPT系列）在处理表格数据时效果仍不理想，主要因其将表格数据及元信息序列化输入模型，导致结构信息丢失。为解决此问题，本文提出TAMO方法，将表格视为独立模态与文本信息融合，构建了以超图神经网络为全局表格编码器与主流大语言模型无缝集成的多模态框架。实验证明，在多个基准数据集（HiTab、WikiTQ、WikiSQL、FeTaQA、StructQA）上，TAMO方法在泛化能力上取得了平均42.65%的显著提升。

Conclusion: 通过引入结构化的超图神经网络编码器并融合进大语言模型，TAMO显著提升了模型对表格数据的理解与推理能力，针对多种表格推理任务表现优异。

Abstract: To migrate the remarkable successes of Large Language Models (LLMs), the community has made numerous efforts to generalize them to the table reasoning tasks for the widely deployed tabular data. Despite that, in this work, by showing a probing experiment on our proposed StructQA benchmark, we postulate that even the most advanced LLMs (such as GPTs) may still fall short of coping with tabular data. More specifically, the current scheme often simply relies on serializing the tabular data, together with the meta information, then inputting them through the LLMs. We argue that the loss of structural information is the root of this shortcoming. In this work, we further propose TAMO, which bears an ideology to treat the tables as an independent modality integrated with the text tokens. The resulting model in TAMO is a multimodal framework consisting of a hypergraph neural network as the global table encoder seamlessly integrated with the mainstream LLM. Empirical results on various benchmarking datasets, including HiTab, WikiTQ, WikiSQL, FeTaQA, and StructQA, have demonstrated significant improvements on generalization with an average relative gain of 42.65%.

</details>


### [40] [Dr.Mi-Bench: A Modular-integrated Benchmark for Scientific Deep Research Agent](https://arxiv.org/abs/2512.00986)
*Zhihan Guo,Feiyang Xu,Yifan Li,Muzhi Li,Shuai Zou,Jiele Wu,Han Shi,Haoli Bai,Ho-fung Leung,Irwin King*

Main category: cs.CL

TL;DR: 本文提出Dr.Mi-Bench基准和评估范式，全面评测科学领域深度研究代理的规划、检索和推理能力，揭示其多源检索和跨领域表现的薄弱环节，指引代理能力提升方向。


<details>
  <summary>Details</summary>
Motivation: 现有评价基准偏重检索且多集中于通用领域，缺乏针对科学领域深度研究代理的全面评估工具。

Method: 提出Dr.Mi-Bench，一个基于200个实例覆盖10个科学领域的模块化集成基准，结合了端到端和孤立评估两种模式，利用学术论文的结构评估规划、检索和推理能力。

Result: 实验发现代理表现分散，虽有专项优势，但在多源检索和跨领域任务中存在一致性不足，强调提升高层规划能力的重要性。

Conclusion: Dr.Mi-Bench揭示了当前深度研究代理在多源检索和跨领域表现上的不足，强调提升高层规划能力是解锁基础大模型推理潜力的关键。

Abstract: The explosive growth in academic literature necessitates automated deep research (DR) agents, yet their evaluation remains a significant challenge. First, existing benchmarks often focus narrowly on retrieval while neglecting high-level planning and reasoning. Second, existing benchmarks favor general domains over the scientific domains that are the core application for DR agents. To address these gaps, we introduce Dr.Mi-Bench, a Modular-integrated benchmark for scientific DR agents. Grounded in academic literature, our benchmark uses a human-annotated dataset of 200 instances across 10 scientific domains, including both research and review papers. Besides, we also propose a Modular-integrated Evaluation Paradigm for DR Agents (Dr.Mi-Eval), a novel modular-integrated evaluation paradigm, which leverages the rich structure of academic papers to assess the core competencies of planning, retrieval, and reasoning through two complementary modes: an end-to-end evaluation for DR agents and an isolated evaluation for foundational LLMs as potential backbones. Experimental results reveal a fragmented performance landscape: agents exhibit specialized strengths but share critical weaknesses, most notably in performing the multi-source retrieval required for review-style tasks and performing consistently across diverse scientific fields. Moreover, improving high-level planning capability is the crucial factor for unlocking the reasoning potential of foundational LLMs as backbones. By exposing these actionable failure modes, Dr.Mi-Bench provides a diagnostic tool to guide the development of more reliable academic research assistants.

</details>


### [41] [Advancing Academic Chatbots: Evaluation of Non Traditional Outputs](https://arxiv.org/abs/2512.00991)
*Nicole Favero,Francesca Salute,Daniel Hardt*

Main category: cs.CL

TL;DR: 该论文比较了两种基于检索的问答策略（Graph RAG与Advanced RAG），并探讨了大语言模型生成非传统学术输出（如幻灯片和播客脚本）的能力。结果显示，基于关键词语义混合的Advanced RAG策略和GPT 4o mini模型表现最佳，而Graph RAG复杂且容易产生幻觉。人类评审在检测生成内容的格式和风格问题中发挥重要作用。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型评估多集中于传统任务，如事实问答和摘要，研究旨在拓展评测范围，比较不同检索策略，并探索生成非传统学术内容的可能性和质量。

Method: 结合Meta的LLaMA 3 70B开源模型与OpenAI的GPT 4o mini API，采用两种检索策略（知识图谱基的Graph RAG和混合关键词-语义的Advanced RAG）进行问答，另通过基于文档的检索测试幻灯片和播客脚本生成。采用人类多维度评分和大语言模型裁判共同评估性能。

Result: GPT 4o mini结合Advanced RAG在问答准确性上表现最佳，Graph RAG提升有限且易产生幻觉。生成幻灯片和播客脚本时，GPT 4o mini表现最佳，LLaMA 3在叙事连贯性方面有潜力。人类评审对识别布局和风格缺陷至关重要。

Conclusion: Advanced RAG结合GPT 4o mini能够更准确地生成问答和非传统学术输出，而Graph RAG复杂性高且增加幻觉现象，人工评审对输出质量评估不可或缺。

Abstract: Most evaluations of large language models focus on standard tasks such as factual question answering or short summarization. This research expands that scope in two directions: first, by comparing two retrieval strategies, Graph RAG, structured knowledge-graph based, and Advanced RAG, hybrid keyword-semantic search, for QA; and second, by evaluating whether LLMs can generate high quality non-traditional academic outputs, specifically slide decks and podcast scripts. We implemented a prototype combining Meta's LLaMA 3 70B open weight and OpenAI's GPT 4o mini API based. QA performance was evaluated using both human ratings across eleven quality dimensions and large language model judges for scalable cross validation. GPT 4o mini with Advanced RAG produced the most accurate responses. Graph RAG offered limited improvements and led to more hallucinations, partly due to its structural complexity and manual setup. Slide and podcast generation was tested with document grounded retrieval. GPT 4o mini again performed best, though LLaMA 3 showed promise in narrative coherence. Human reviewers were crucial for detecting layout and stylistic flaws, highlighting the need for combined human LLM evaluation in assessing emerging academic outputs.

</details>


### [42] [When Safety Blocks Sense: Measuring Semantic Confusion in LLM Refusals](https://arxiv.org/abs/2512.01037)
*Riad Ahmed Anonto,Md Labid Al Nahiyan,Md Tanvir Hassan,Ch. Md. Rakin Haider*

Main category: cs.CL

TL;DR: 该论文探讨了安全对齐语言模型中存在的局部不一致性问题，即模型对意图相同但表述不同的提示给出不同的拒绝响应。作者提出了"语义混淆"这一失败模式，并构建了一个包含1万条不同表述但意图一致的测试语料库ParaGuard。同时，提出了三种模型无关的评估指标，用以揭示这种局部不一致现象。实验表明传统的全局拒绝率指标难以捕捉细节，新的指标能帮助开发者减少错误拒绝，提高模型安全性与合理性。


<details>
  <summary>Details</summary>
Motivation: 当前对安全对齐语言模型的评估仅关注整体拒绝率，忽略了局部不一致性，导致模型在实际应用中对语义相近的请求表现不稳定，影响模型准确诊断和调优。

Method: 构建ParaGuard语料库，包含1万条意图保持不变但表达不同的提示集；设计Confusion Index、Confusion Rate和Confusion Depth三种基于令牌级别及其嵌入和概率特征的通用指标，用于评估模型在语义相近提示间的一致性；通过多模型和多防护机制的实验验证指标的有效性。

Result: 发现传统全局拒绝率指标无法揭示模型拒绝决策中的细节差异，三种新指标成功揭示了不同模型和部署策略下的局部不一致特征；并且基于语义混淆的审计方法能区分拒绝频率和拒绝合理性，为减少错误拒绝提供了实际指导。

Conclusion: 语义混淆揭示了安全对齐模型局部不一致的问题，使用ParaGuard语料库和三种新指标可以更准确地评估和定位模型拒绝策略中的缺陷，从而指导开发者降低错误拒绝率并保持安全性。

Abstract: Safety-aligned language models often refuse prompts that are actually harmless. Current evaluations mostly report global rates such as false rejection or compliance. These scores treat each prompt alone and miss local inconsistency, where a model accepts one phrasing of an intent but rejects a close paraphrase. This gap limits diagnosis and tuning. We introduce "semantic confusion," a failure mode that captures such local inconsistency, and a framework to measure it. We build ParaGuard, a 10k-prompt corpus of controlled paraphrase clusters that hold intent fixed while varying surface form. We then propose three model-agnostic metrics at the token level: Confusion Index, Confusion Rate, and Confusion Depth. These metrics compare each refusal to its nearest accepted neighbors and use token embeddings, next-token probabilities, and perplexity signals. Experiments across diverse model families and deployment guards show that global false-rejection rate hides critical structure. Our metrics reveal globally unstable boundaries in some settings, localized pockets of inconsistency in others, and cases where stricter refusal does not increase inconsistency. We also show how confusion-aware auditing separates how often a system refuses from how sensibly it refuses. This gives developers a practical signal to reduce false refusals while preserving safety.

</details>


### [43] [ELR-1000: A Community-Generated Dataset for Endangered Indic Indigenous Languages](https://arxiv.org/abs/2512.01077)
*Neha Joshi,Pamir Gogoi,Aasim Mirza,Aayush Jansari,Aditya Yadavalli,Ayushi Pandey,Arunima Shukla,Deepthi Sudharsan,Kalika Bali,Vivek Seshadri*

Main category: cs.CL

TL;DR: 构建了一个包含10种濒危语言的传统食谱多模态数据集，评测大语言模型的翻译能力，强调提供文化背景信息对提升翻译效果的重要性，同时发布数据集促进濒危语言技术发展。


<details>
  <summary>Details</summary>
Motivation: 濒危语言在数字资源上严重匮乏，尤其是涉及文化和语言独特性的传统食谱，现有语言模型在处理这些低资源、文化特定语言时表现不佳，需提升模型的文化敏感度和翻译质量。

Method: 构建涵盖10种濒危语言的多模态传统食谱数据集，使用专为数字素养较低的贡献者设计的移动接口收集数据，并利用多种先进大语言模型对食谱进行翻译评测。

Result: 发现主流大语言模型在翻译低资源、特定文化语言时能力有限，但通过提供针对性背景信息、翻译示例与文化保护指南，能显著提升翻译质量。

Conclusion: 研究表明，为低资源且文化特定的语言开发针对性基准和方法极为必要，且文化背景信息的引入能有效提升模型性能，呼吁更多关注濒危语言和文化领域的语言技术发展。

Abstract: We present a culturally-grounded multimodal dataset of 1,060 traditional recipes crowdsourced from rural communities across remote regions of Eastern India, spanning 10 endangered languages. These recipes, rich in linguistic and cultural nuance, were collected using a mobile interface designed for contributors with low digital literacy. Endangered Language Recipes (ELR)-1000 -- captures not only culinary practices but also the socio-cultural context embedded in indigenous food traditions. We evaluate the performance of several state-of-the-art large language models (LLMs) on translating these recipes into English and find the following: despite the models' capabilities, they struggle with low-resource, culturally-specific language. However, we observe that providing targeted context -- including background information about the languages, translation examples, and guidelines for cultural preservation -- leads to significant improvements in translation quality. Our results underscore the need for benchmarks that cater to underrepresented languages and domains to advance equitable and culturally-aware language technologies. As part of this work, we release the ELR-1000 dataset to the NLP community, hoping it motivates the development of language technologies for endangered languages.

</details>


### [44] [How do we measure privacy in text? A survey of text anonymization metrics](https://arxiv.org/abs/2512.01109)
*Yaxuan Ren,Krithika Ramesh,Yaxing Yao,Anjalie Field*

Main category: cs.CL

TL;DR: 本文系统性梳理了文本匿名化中隐私保护的评估指标，比较了不同隐私概念与法律标准和用户期望的关系，旨在推动更规范和有效的隐私保护评估。


<details>
  <summary>Details</summary>
Motivation: 文本匿名化对于涉及敏感数据的NLP研究和模型开发至关重要，但如何评估匿名化方法是否能充分保护隐私仍是一个未解决的挑战。

Method: 手动审查了47篇报告隐私指标的论文，识别并比较了六个不同的隐私概念，分析了相关度量如何体现隐私风险的不同方面，同时评估了这些概念与HIPAA、GDPR等法律隐私标准及以用户为中心的HCI研究预期的一致性。

Result: 本文识别了六种隐私概念，揭示了当前隐私评估在法律合规性和用户期望方面的差距，提供了指导以帮助研究人员选择更合适的隐私评估指标。

Conclusion: 本文通过系统性综述澄清并整合了文本隐私保护的评估指标，指出当前隐私评估存在的不足，并提供了实用指导以促进更健全、可比且符合法律要求的隐私评估方法。

Abstract: In this work, we aim to clarify and reconcile metrics for evaluating privacy protection in text through a systematic survey. Although text anonymization is essential for enabling NLP research and model development in domains with sensitive data, evaluating whether anonymization methods sufficiently protect privacy remains an open challenge. In manually reviewing 47 papers that report privacy metrics, we identify and compare six distinct privacy notions, and analyze how the associated metrics capture different aspects of privacy risk. We then assess how well these notions align with legal privacy standards (HIPAA and GDPR), as well as user-centered expectations grounded in HCI studies. Our analysis offers practical guidance on navigating the landscape of privacy evaluation approaches further and highlights gaps in current practices. Ultimately, we aim to facilitate more robust, comparable, and legally aware privacy evaluations in text anonymization.

</details>


### [45] [DrawingBench: Evaluating Spatial Reasoning and UI Interaction Capabilities of Large Language Models through Mouse-Based Drawing Tasks](https://arxiv.org/abs/2512.01174)
*Hyunjun Kim,Sooyoung Ryu*

Main category: cs.CL

TL;DR: DrawingBench通过规则透明、可审计的多层评估框架，有效提升并检测自主智能体的可靠性，实现基准测试的可信度和可控性。


<details>
  <summary>Details</summary>
Motivation: 鉴于自主智能体系统日益普及，现有基准测试缺乏透明性和可审计性，难以验证智能体行为的可靠性，因而需要一种可验证的评估方法来建立信任。

Method: 提出DrawingBench验证框架，通过空间推理任务中生成低级GUI操作序列进行可靠性评估。该框架基于8个规则标准实现透明和可审计的评分，包含250个多样化提示、确定性评价指标及多轮反馈的外部监督机制。

Result: 在1000次测试中，四个先进LLM模型实现92.8%的完美表现，且在结构化外部反馈指导下性能显著提升（平均+3.2%，复杂场景最高+32.8%）。发现模型在工具状态管理和长远规划存在系统性错误，且明确的任务规范比任务复杂度对表现影响更大，明确规范下表现达100%。

Conclusion: 透明的评估框架能有效建立自主智能体系统的信任，外部监督比自我纠正更有效引导智能体行为。DrawingBench作为开源工具，为可信赖的智能体评估提供了模版。

Abstract: As agentic AI systems increasingly operate autonomously, establishing trust through verifiable evaluation becomes critical. Yet existing benchmarks lack the transparency and auditability needed to assess whether agents behave reliably. We present DrawingBench, a verification framework for evaluating the trustworthiness of agentic LLMs through spatial reasoning tasks that require generating sequences of low-level GUI actions. Unlike opaque evaluations, DrawingBench provides transparent, rule-based assessment: 8 objective criteria enable reproducible scoring, while action-level inspection allows stakeholders to audit agent behavior. Our framework comprises 250 diverse prompts across 20 categories and 4 difficulty levels, deterministic evaluation metrics, and an external oversight mechanism through multi-turn feedback that enables human control over agent refinement. Evaluating four state-of-the-art LLMs (Claude-4 Sonnet, GPT-4.1, GPT-4.1-mini, Gemini-2.5 Flash) across 1,000 tests, we establish both capabilities and limitations: models achieved 92.8% perfect performance with structured external feedback driving significant improvements (average +3.2%, up to +32.8% for complex scenes), but systematic error patterns emerged in tool state management and long-horizon planning. Notably, specification clarity proved more important than task complexity -- models achieved 100% perfect performance when given explicit, verifiable criteria. These findings demonstrate that transparent evaluation frameworks can establish trust in agentic systems, with external oversight proving more reliable than self-correction for guiding agent behavior. Our open-source framework provides a template for trustworthy agent assessment. Code and data: https://github.com/hyunjun1121/DrawingBench

</details>


### [46] [TempPerturb-Eval: On the Joint Effects of Internal Temperature and External Perturbations in RAG Robustness](https://arxiv.org/abs/2512.01183)
*Yongxin Zhou,Philippe Mulhem,Didier Schwab*

Main category: cs.CL

TL;DR: 文章系统研究了RAG系统中文本扰动与生成温度的交互影响，构建了分析框架并给出了优化建议。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强生成（RAG）系统的评估常常单独考察检索质量或生成参数（如温度），忽视两者的相互影响。

Method: 提出一个系统的RAG扰动-温度分析框架，对检索文本施加三种不同扰动类型，并在多种温度设置下进行广泛测试。

Result: 实验验证了温度设置与扰动类型之间存在复杂的相互作用，高温下模型对扰动更敏感，且不同扰动类型在温度范围内表现出非线性敏感性。

Conclusion: 本文提出的分析框架和诊断基准能够有效评估RAG系统的鲁棒性，并为噪声检索环境下的模型选择与参数调优提供实用指导。

Abstract: The evaluation of Retrieval-Augmented Generation (RAG) systems typically examines retrieval quality and generation parameters like temperature in isolation, overlooking their interaction. This work presents a systematic investigation of how text perturbations (simulating noisy retrieval) interact with temperature settings across multiple LLM runs. We propose a comprehensive RAG Perturbation-Temperature Analysis Framework that subjects retrieved documents to three distinct perturbation types across varying temperature settings. Through extensive experiments on HotpotQA with both open-source and proprietary LLMs, we demonstrate that performance degradation follows distinct patterns: high-temperature settings consistently amplify vulnerability to perturbations, while certain perturbation types exhibit non-linear sensitivity across the temperature range. Our work yields three key contributions: (1) a diagnostic benchmark for assessing RAG robustness, (2) an analytical framework for quantifying perturbation-temperature interactions, and (3) practical guidelines for model selection and parameter tuning under noisy retrieval conditions.

</details>


### [47] [Generalist Large Language Models Outperform Clinical Tools on Medical Benchmarks](https://arxiv.org/abs/2512.01191)
*Krithik Vishwanath,Mrigayu Ghosh,Anton Alyakin,Daniel Alexander Alber,Yindalon Aphinyanaphongs,Eric Karl Oermann*

Main category: cs.CL

TL;DR: 评测显示通用大型语言模型优于临床专用AI助手，提醒需加强独立评估以保障临床安全。


<details>
  <summary>Details</summary>
Motivation: 临床专用AI助手迅速进入医疗实践，但缺乏独立、定量评估，存在证据空白。

Method: 通过1,000项小型基准测试（MedQA和HealthBench），比较两种临床AI系统与三种通用大型语言模型（GPT-5、Gemini 3 Pro、Claude Sonnet 4.5）的表现。

Result: 通用模型表现优于临床工具，GPT-5得分最高。OpenEvidence和UpToDate在完整性、沟通质量、上下文意识和系统安全推理上表现不足。

Conclusion: 市场上用于临床决策支持的工具可能落后于前沿通用大型模型，部署前需透明、独立评估。

Abstract: Specialized clinical AI assistants are rapidly entering medical practice, often framed as safer or more reliable than general-purpose large language models (LLMs). Yet, unlike frontier models, these clinical tools are rarely subjected to independent, quantitative evaluation, creating a critical evidence gap despite their growing influence on diagnosis, triage, and guideline interpretation. We assessed two widely deployed clinical AI systems (OpenEvidence and UpToDate Expert AI) against three state-of-the-art generalist LLMs (GPT-5, Gemini 3 Pro, and Claude Sonnet 4.5) using a 1,000-item mini-benchmark combining MedQA (medical knowledge) and HealthBench (clinician-alignment) tasks. Generalist models consistently outperformed clinical tools, with GPT-5 achieving the highest scores, while OpenEvidence and UpToDate demonstrated deficits in completeness, communication quality, context awareness, and systems-based safety reasoning. These findings reveal that tools marketed for clinical decision support may often lag behind frontier LLMs, underscoring the urgent need for transparent, independent evaluation before deployment in patient-facing workflows.

</details>


### [48] [Conveying Imagistic Thinking in Traditional Chinese Medicine Translation: A Prompt Engineering and LLM-Based Evaluation Framework](https://arxiv.org/abs/2512.01198)
*Jiatong Han*

Main category: cs.CL

TL;DR: 本研究通过人工辅助大语言模型，改善中医经典文本中的隐喻和转喻英文翻译，提升读者理解和应用效果。


<details>
  <summary>Details</summary>
Motivation: 中医理论基于形象思维，医疗原则和诊疗逻辑通过隐喻和转喻结构化，但现有英文翻译大多采用直译，导致目标语言读者难以理解和应用。

Method: 采用人工参与环节（HITL）框架，选取《黄帝内经》中的四段理论基础文本，通过基于提示的认知支架，引导DeepSeek V3.1识别隐喻和转喻并传达理论，在评价阶段利用ChatGPT 5 Pro和Gemini 2.5 Pro模拟三类读者，比较不同翻译结果，结合结构化访谈与解释现象学分析。

Result: 提示调整后的大型语言模型翻译在五个认知维度上表现最佳，跨模型和跨角色一致性高；访谈揭示人机翻译差异、有效的隐喻和转喻转译策略及读者认知偏好。

Conclusion: 该研究提出了一种认知高效且可复现的HITL方法路径，适用于中医这类古老且概念密集文本的翻译。

Abstract: Traditional Chinese Medicine (TCM) theory is built on imagistic thinking, in which medical principles and diagnostic and therapeutic logic are structured through metaphor and metonymy. However, existing English translations largely rely on literal rendering, making it difficult for target-language readers to reconstruct the underlying conceptual networks and apply them in clinical practice. This study adopted a human-in-the-loop (HITL) framework and selected four passages from the medical canon Huangdi Neijing that are fundamental in theory. Through prompt-based cognitive scaffolding, DeepSeek V3.1 was guided to identify metaphor and metonymy in the source text and convey the theory in translation. In the evaluation stage, ChatGPT 5 Pro and Gemini 2.5 Pro were instructed by prompts to simulate three types of real-world readers. Human translations, baseline model translations, and prompt-adjusted translations were scored by the simulated readers across five cognitive dimensions, followed by structured interviews and Interpretative Phenomenological Analysis (IPA). Results show that the prompt-adjusted LLM translations perform best across all five dimensions, with high cross-model and cross-role consistency. The interview themes reveal differences between human and machine translation, effective strategies for metaphor and metonymy transfer, and readers' cognitive preferences. This study provides a cognitive, efficient, and replicable HITL methodological pathway for the translation of ancient, concept-dense texts such as TCM.

</details>


### [49] [Sentiment Analysis and Emotion Classification using Machine Learning Techniques for Nagamese Language - A Low-resource Language](https://arxiv.org/abs/2512.01256)
*Ekha Morang,Surhoni A. Ngullie,Sashienla Longkumer,Teisovi Angami*

Main category: cs.CL

TL;DR: 首次针对Nagamese语言开展情感分析，构建词典并采用机器学习方法实现情感极性及情绪分类。


<details>
  <summary>Details</summary>
Motivation: 针对资源匮乏的Nagamese语言，缺乏情感分析研究，填补该领域空白。

Method: 构建包含1195个Nagamese词汇的情感极性词典，结合其他特征，采用朴素贝叶斯和支持向量机进行有监督机器学习。

Result: 成功实现了对Nagamese语言文本中情感极性（正面、负面、中性）及基本情感的检测。

Conclusion: 本研究首次对Nagamese语言进行了情感分析和情感分类，证明了该方法在该语言上的有效性。

Abstract: The Nagamese language, a.k.a Naga Pidgin, is an Assamese-lexified creole language developed primarily as a means of communication in trade between the people from Nagaland and people from Assam in the north-east India. Substantial amount of work in sentiment analysis has been done for resource-rich languages like English, Hindi, etc. However, no work has been done in Nagamese language. To the best of our knowledge, this is the first attempt on sentiment analysis and emotion classification for the Nagamese Language. The aim of this work is to detect sentiments in terms of polarity (positive, negative and neutral) and basic emotions contained in textual content of Nagamese language. We build sentiment polarity lexicon of 1,195 nagamese words and use these to build features along with additional features for supervised machine learning techniques using Na"ive Bayes and Support Vector Machines.
  Keywords: Nagamese, NLP, sentiment analysis, machine learning

</details>


### [50] [SUPERChem: A Multimodal Reasoning Benchmark in Chemistry](https://arxiv.org/abs/2512.01274)
*Zehua Zhao,Zhixian Huang,Junren Li,Siyu Lin,Junting Zhou,Fengqi Cao,Kun Zhou,Rui Ge,Tingting Long,Yuexiang Zhu,Yan Liu,Jie Zheng,Junnian Wei,Rong Zhu,Peng Zou,Wenyu Li,Zekai Cheng,Tian Ding,Yaxuan Wang,Yizhao Yan,Tingru Wei,Haowei Ming,Weijie Mao,Chen Sun,Yiming Liu,Zichen Wang,Zuo Zhang,Tong Yang,Hao Ma,Zhen Gao,Jian Pei*

Main category: cs.CL

TL;DR: 本文提出了SUPERChem基准测试集，通过500个专家设计的复杂化学推理问题，结合多模态和文本格式，提升对大型语言模型化学推理能力评估的严谨性。


<details>
  <summary>Details</summary>
Motivation: 现有化学推理评估任务过于简单，缺少过程评测，且不符合专家化学技能需求，亟需一个更具挑战性和科学性的评测基准。

Method: 采用专家精心策划的500道多领域、多模态化学推理题，配以专家解题路径，利用推理路径一致性评分评估模型推理质量，消除数据污染并迭代优化题库。

Result: 顶尖模型GPT-5（高配）准确率38.5%，略低于人类40.3%，展现出多步多模态推理能力及视觉信息影响，显著区分出高质量推理行为。

Conclusion: 目前的顶尖模型如GPT-5的准确率仍未达到人类水平，SUPERChem有效区分了高质量推理与简单启发式方法，推动模型向专家级化学智能发展。

Abstract: Current benchmarks for evaluating the chemical reasoning capabilities of Large Language Models (LLMs) are limited by oversimplified tasks, lack of process-level evaluation, and misalignment with expert-level chemistry skills. To address these issues, we introduce SUPERChem, a benchmark of 500 expert-curated reasoning-intensive chemistry problems, covering diverse subfields and provided in both multimodal and text-only formats. Original content and an iterative curation pipeline eliminate flawed items and mitigate data contamination. Each problem is paired with an expert-authored solution path, enabling Reasoning Path Fidelity (RPF) scoring to evaluate reasoning quality beyond final-answer accuracy. Evaluations against a human baseline of 40.3% accuracy show that even the best-performing model, GPT-5 (High), reaches only 38.5%, followed closely by Gemini 2.5 Pro (37.9%) and DeepSeek-V3.1-Think (37.3%). SUPERChem elicits multi-step, multimodal reasoning, reveals model-dependent effects of visual information, and distinguishes high-fidelity reasoners from heuristic ones. By providing a challenging benchmark and a reliable evaluation framework, SUPERChem aims to facilitate the advancement of LLMs toward expert-level chemical intelligence. The dataset of the benchmark is available at https://huggingface.co/datasets/ZehuaZhao/SUPERChem.

</details>


### [51] [Kardia-R1: Unleashing LLMs to Reason toward Understanding and Empathy for Emotional Support via Rubric-as-Judge Reinforcement Learning](https://arxiv.org/abs/2512.01282)
*Jiahao Yuan,Zhiqing Cui,Hanqing Wang,Yuansheng Gao,Yucheng Zhou,Usman Naseem*

Main category: cs.CL

TL;DR: 本研究提出包含671个用户身份的对话数据集KardiaBench和基于解释性评分奖励的同理心训练框架Kardia-R1，实现了更精准和个性化的情感推理。


<details>
  <summary>Details</summary>
Motivation: 当前对话系统难以实现身份感知的情感推理，主要因缺乏带有持续用户身份的信息数据集和缺少可解释的奖励信号，导致个性化的情感理解和验证性同理推理受限。

Method: 提出KardiaBench大规模用户关联数据集及其构建流程，设计Kardia-R1框架利用Rubric-ERL结合解释性人类对齐的评分奖励，进行可解释的阶段性同理心认知训练。

Result: Kardia-R1在四种大型语言模型骨干上均表现优异，在情感准确性、同理心、相关性、个性一致性和安全性方面均超越其他方法。

Conclusion: 通过引入用户身份关联数据和基于评分表的人类对齐奖励机制，系统有效提升了情感认知的可解释性和个性化情感推理能力，为情感复杂的个性化对话系统提供了新范式。

Abstract: As web platforms evolve towards greater personalization and emotional complexity, conversational agents must transcend superficial empathy to demonstrate identity-aware emotional reasoning. However, existing systems face two limitations: (1) reliance on situation-centric datasets lacking persistent user identity, which hampers the capture of personalized affective nuances; and (2) dependence on opaque, coarse reward signals that hinder development of verifiable empathetic reasoning. To address these gaps, we introduce KardiaBench, a large-scale user-grounded benchmark comprising 178,080 QA pairs across 22,080 multi-turn conversations anchored to 671 real-world profiles. The dataset is constructed via a model-in-the-loop pipeline with iterative rubric-guided refinement to ensure psychological plausibility and persona consistency. This progressive empathy pipeline that integrates user comprehension, contextual reasoning, and emotion perception into conversations, followed by iterative critique and rubric-based refinement to ensure psychological plausibility, emotional fidelity, and persona consistency. Building on this, we propose Kardia-R1, a framework that trains models for interpretable, stepwise empathetic cognition. Kardia-R1 leverages Rubric-as-Judge Empathetic Reinforcement Learning (Rubric-ERL), a GRPO-based method that uses explainable, human-aligned rubric rewards to tightly couple user understanding, emotional inference, and supportive response generation. Extensive experiments across four LLM backbones demonstrate that Kardia-R1 consistently outperforms othet methods in emotion accuracy, empathy, relevance, persona consistency, and safety. Our dataset and model will be released at https://github.com/JhCircle/Kardia-R1.

</details>


### [52] [Agreement-Constrained Probabilistic Minimum Bayes Risk Decoding](https://arxiv.org/abs/2512.01316)
*Koki Natsumi,Hiroyuki Deguchi,Yusuke Sakai,Hidetaka Kamigaito,Taro Watanabe*

Main category: cs.CL

TL;DR: 提出AC-PMBR解码方法，利用知识蒸馏改善PMBR矩阵补全，提升翻译质量并保持计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的MBR解码计算量大，PMBR虽减小了评分调用次数但带来质量下降，需寻求质量和成本的更好平衡。

Method: 通过采样候选对进行部分评分，并应用知识蒸馏模型指导评分矩阵的完成，优化了最小贝叶斯风险解码的矩阵补全过程。

Result: 该论文提出了一种名为AC-PMBR（agreement-constrained PMBR）的解码方法，通过利用知识蒸馏模型指导评分矩阵的补全，改善了部分评估的最小贝叶斯风险（PMBR）解码在减少效用函数调用时带来的翻译质量下降问题。该方法提高了矩阵补全的近似精度最多3倍，并在WMT'23英德翻译任务上以相当的计算成本实现了比PMBR更高的翻译质量。

Conclusion: AC-PMBR解码有效提升了矩阵补全的准确性和翻译质量，在计算成本相当的情况下优于传统的PMBR解码。

Abstract: Minimum Bayes risk (MBR) decoding generates high-quality translations by maximizing the expected utility of output candidates, but it evaluates all pairwise scores over the candidate set; hence, it takes quadratic time with respect to the number of candidates. To reduce the number of utility function calls, probabilistic MBR (PMBR) decoding partially evaluates quality scores using sampled pairs of candidates and completes the missing scores with a matrix completion algorithm. Nevertheless, it degrades the translation quality as the number of utility function calls is reduced. Therefore, to improve the trade-off between quality and cost, we propose agreement-constrained PMBR (AC-PMBR) decoding, which leverages a knowledge distilled model to guide the completion of the score matrix. Our AC-PMBR decoding improved approximation errors of matrix completion by up to 3 times and achieved higher translation quality compared with PMBR decoding at a comparable computational cost on the WMT'23 En$\leftrightarrow$De translation tasks.

</details>


### [53] [MARSAD: A Multi-Functional Tool for Real-Time Social Media Analysis](https://arxiv.org/abs/2512.01369)
*Md. Rafiul Biswas,Firoj Alam,Wajdi Zaghouani*

Main category: cs.CL

TL;DR: MARSAD是针对阿拉伯语社交媒体的实时多功能NLP分析平台，支持多种社会议题检测，用户友好且后端处理高效。


<details>
  <summary>Details</summary>
Motivation: 针对阿拉伯语社交媒体领域缺乏实时且多功能的自然语言处理平台，满足研究人员及普通用户对社交媒体内容多维度分析和监控的需求。

Method: 通过集成灵活的文档存储与结构化数据管理，实现大规模多模态数据的高效处理；利用API密钥安全抓取数据；部署多种NLP分析模块（如情感分析、宣传检测等）；并设计用户友好的前端界面支持实时和历史数据的交互与可视化。

Result: MARSAD平台是一款面向阿拉伯语社交媒体的多功能实时监测与分析工具，支持情感分析、情绪分析、宣传检测、事实核查和仇恨言论检测等多维度功能。它兼顾研究人员和非技术用户，支持实时及历史数据的可视化和报告生成，并通过API密钥提供安全的数据抓取。其后端架构结合灵活的文档存储与结构化数据管理，实现高效处理大规模多模态数据，前端界面友好，支持无缝数据上传和交互。

Conclusion: MARSAD成功构建了一个面向阿拉伯语社交媒体的多功能、高效且易用的实时监测与分析平台，能够支持多种复杂的自然语言处理任务并促进社会媒体研究与监督。

Abstract: MARSAD is a multifunctional natural language processing (NLP) platform designed for real-time social media monitoring and analysis, with a particular focus on the Arabic-speaking world. It enables researchers and non-technical users alike to examine both live and archived social media content, producing detailed visualizations and reports across various dimensions, including sentiment analysis, emotion analysis, propaganda detection, fact-checking, and hate speech detection. The platform also provides secure data-scraping capabilities through API keys for accessing public social media data. MARSAD's backend architecture integrates flexible document storage with structured data management, ensuring efficient processing of large and multimodal datasets. Its user-friendly frontend supports seamless data upload and interaction.

</details>


### [54] [DyFuLM: An Advanced Multimodal Framework for Sentiment Analysis](https://arxiv.org/abs/2512.01410)
*Ruohan Zhou,Jiachen Yuan,Churui Yang,Wenzheng Huang,Guoyan Zhang,Shiyao Wei,Jiazhen Hu,Ning Xin,Md Maruf Hasan*

Main category: cs.CL

TL;DR: DyFuLM模型通过层次动态融合和门控聚合模块，实现了对复杂文本情感的精细理解，显著提升了多任务情感分类的性能。


<details>
  <summary>Details</summary>
Motivation: 复杂文本情感理解难度大，现有方法难以有效捕捉层次语义和细粒度情绪，故设计DyFuLM模型以更好地捕获层次特征及情绪细节，提升情感分析性能。

Method: 提出了动态融合学习模型（DyFuLM），包括层次动态融合模块和门控特征聚合模块，分别用于多层特征融合和跨层信息调节，通过多任务情感数据集验证模型效果。

Result: 本文提出了一个名为DyFuLM的动态融合学习模型，用于多模态情感分析。模型包含两个主要模块：层次动态融合模块和门控特征聚合模块，分别用于多层级特征的自适应整合和跨层信息流的调节。实验结果显示，DyFuLM在多任务情感数据集上表现优异，细粒度和粗粒度情感分类准确率分别达到68.48%和82.64%，且回归误差最低，决定系数最高。消融实验验证了各模块对模型性能的贡献，整体提升了情感表示及分类效果。

Conclusion: DyFuLM模型显著提高了情感表示的效果及情感分类准确率，证明了层次特征融合和信息流调节模块在提升模型性能中的重要作用。

Abstract: Understanding sentiment in complex textual expressions remains a fundamental challenge in affective computing. To address this, we propose a Dynamic Fusion Learning Model (DyFuLM), a multimodal framework designed to capture both hierarchical semantic representations and fine-grained emotional nuances. DyFuLM introduces two key moodules: a Hierarchical Dynamic Fusion module that adaptively integrates multi-level features, and a Gated Feature Aggregation module that regulates cross-layer information ffow to achieve balanced representation learning. Comprehensive experiments on multi-task sentiment datasets demonstrate that DyFuLM achieves 82.64% coarse-grained and 68.48% fine-grained accuracy, yielding the lowest regression errors (MAE = 0.0674, MSE = 0.0082) and the highest R^2 coefficient of determination (R^2= 0.6903). Furthermore, the ablation study validates the effectiveness of each module in DyFuLM. When all modules are removed, the accuracy drops by 0.91% for coarse-grained and 0.68% for fine-grained tasks. Keeping only the gated fusion module causes decreases of 0.75% and 0.55%, while removing the dynamic loss mechanism results in drops of 0.78% and 0.26% for coarse-grained and fine-grained sentiment classification, respectively. These results demonstrate that each module contributes significantly to feature interaction and task balance. Overall, the experimental findings further validate that DyFuLM enhances sentiment representation and overall performance through effective hierarchical feature fusion.

</details>


### [55] [PromptBridge: Cross-Model Prompt Transfer for Large Language Models](https://arxiv.org/abs/2512.01420)
*Yaxuan Wang,Quan Liu,Zhenting Wang,Zichao Li,Wei Wei,Yang Liu,Yujia Bao*

Main category: cs.CL

TL;DR: 针对大语言模型频繁切换导致的提示效果大幅波动，提出PromptBridge框架，能够无需重新优化，实现在模型间直接迁移提示，提升性能且降低成本。


<details>
  <summary>Details</summary>
Motivation: 应对大语言模型快速演进导致的模型切换频繁，而提示高度依赖于模型，直接复用提示效果下降的现象，即“模型漂移”问题。

Method: 提出PromptBridge，一个无需训练的框架，通过Model-Adaptive Reflective Prompt Evolution（MAP-RPE）进行任务和模型特定的提示优化，进而学习跨模型提示映射，实现不同大模型间提示的有效迁移。

Result: 通过广泛的实证分析发现模型漂移普遍且严重；PromptBridge在单代理和多代理环境中均能在提高下游任务准确率的同时，显著减少提示迁移的劳动量。

Conclusion: PromptBridge有效缓解了模型漂移现象，简化了跨模型提示的迁移过程，提升了模型切换时的应用稳定性和效率。

Abstract: Large language models (LLMs) underpin applications in code generation, mathematical reasoning, and agent-based workflows. In practice, systems access LLMs via commercial APIs or open-source deployments, and the model landscape (e.g., GPT, Claude, Llama) evolves rapidly. This rapid evolution forces frequent model switches driven by capability, cost, deployment constraints, and privacy. Yet prompts are highly model-sensitive: reusing a prompt engineered for one model on another often yields substantially worse performance than a prompt optimized for the target model. We term this phenomenon Model Drifting. Through extensive empirical analysis across diverse LLM configurations, we show that model drifting is both common and severe. To address this challenge, we introduce PromptBridge, a training-free framework that preserves prompt effectiveness under model switches, enabling cross-model prompt transfer without costly per-task or per-model re-optimization. PromptBridge requires only a small set of alignment tasks for calibration. It first applies Model-Adaptive Reflective Prompt Evolution (MAP-RPE) to obtain task- and model-specific optimal prompts via iterative reflective refinement and quantitative evaluation. Using the resulting calibrated prompt pairs for the source and target models, PromptBridge learns a cross-model prompt mapping. At test time, i.e., for an unseen task, given a source-model prompt, this mapping directly produces an optimized prompt for the target model. Experiments in single-agent and multi-agent settings show that PromptBridge consistently improves downstream accuracy while reducing migration effort. The code will be available soon.

</details>


### [56] [Multilingual Conversational AI for Financial Assistance: Bridging Language Barriers in Indian FinTech](https://arxiv.org/abs/2512.01439)
*Bharatdeep Hazarika,Arya Suneesh,Prasanna Devadiga,Pawan Kumar Rajpoot,Anshuman B Suresh,Ahmed Ifthaquar Hussain*

Main category: cs.CL

TL;DR: 本文提出了一种支持印度多语言、特别是混合语言（如Hinglish）的金融对话AI系统，旨在促进金融服务的语言包容性。


<details>
  <summary>Details</summary>
Motivation: 印度的语言多样性和英语理解率低，限制了金融包容性，需开发支持多语言混合使用的对话系统。

Method: 采用多代理架构，包括语言分类、功能管理和多语言响应生成，并通过对比多种语言模型进行评估。

Result: 系统在真实环境部署中实现了用户参与度显著提升，同时延迟仅增加4-8%。

Conclusion: 该系统显著提升了用户参与度，并保持了较低的延迟，成功弥合了语言障碍，推动新兴市场数字金融服务的发展。

Abstract: India's linguistic diversity presents both opportunities and challenges for fintech platforms. While the country has 31 major languages and over 100 minor ones, only 10\% of the population understands English, creating barriers to financial inclusion. We present a multilingual conversational AI system for a financial assistance use case that supports code-mixed languages like Hinglish, enabling natural interactions for India's diverse user base. Our system employs a multi-agent architecture with language classification, function management, and multilingual response generation. Through comparative analysis of multiple language models and real-world deployment, we demonstrate significant improvements in user engagement while maintaining low latency overhead (4-8\%). This work contributes to bridging the language gap in digital financial services for emerging markets.

</details>


### [57] [MEGConformer: Conformer-Based MEG Decoder for Robust Speech and Phoneme Classification](https://arxiv.org/abs/2512.01443)
*Xabier de Zuazo,Ibon Saratxaga,Eva Navas*

Main category: cs.CL

TL;DR: 本文提出了一种基于Conformer的轻量级模型，结合MEG专用数据增强和类别权重策略，有效提升MEG信号的语音检测和音素分类性能。


<details>
  <summary>Details</summary>
Motivation: 针对LibriBrain 2025 PNPL竞赛中的两项基础MEG任务（语音检测和音素分类），提升模型对多通道MEG信号的处理能力和任务性能。

Method: 采用基于Conformer的解码器，结合轻量卷积投影层和任务特定头，处理原始306通道MEG信号。针对语音检测任务引入MEG定制的SpecAugment增强方法，语音分类任务使用逆平方根类别加权和动态分组加载器，并应用实例级归一化缓解分布偏移。

Result: 模型在官方标准数据集上分别获得语音检测任务88.9%、音素分类任务65.8% F1-macro分数，超过竞赛基线并跻身前十名。

Conclusion: 基于Conformer的模型结构、结合MEG特定增强及归一化策略，显著提升了多通道MEG信号的语音识别效果，验证了方法的有效性和竞赛竞争力。

Abstract: We present Conformer-based decoders for the LibriBrain 2025 PNPL competition, targeting two foundational MEG tasks: Speech Detection and Phoneme Classification. Our approach adapts a compact Conformer to raw 306-channel MEG signals, with a lightweight convolutional projection layer and task-specific heads. For Speech Detection, a MEG-oriented SpecAugment provided a first exploration of MEG-specific augmentation. For Phoneme Classification, we used inverse-square-root class weighting and a dynamic grouping loader to handle 100-sample averaged examples. In addition, a simple instance-level normalization proved critical to mitigate distribution shifts on the holdout split. Using the official Standard track splits and F1-macro for model selection, our best systems achieved 88.9% (Speech) and 65.8% (Phoneme) on the leaderboard, surpassing the competition baselines and ranking within the top-10 in both tasks. For further implementation details, the technical documentation, source code, and checkpoints are available at https://github.com/neural2speech/libribrain-experiments.

</details>


### [58] [Enhancing BERT Fine-Tuning for Sentiment Analysis in Lower-Resourced Languages](https://arxiv.org/abs/2512.01460)
*Jozef Kubík,Marek Šuppa,Martin Takáč*

Main category: cs.CL

TL;DR: 本文提出通过主动学习结合聚类和动态数据选择，在低资源语言微调中提升模型性能和标注效率。


<details>
  <summary>Details</summary>
Motivation: 低资源语言数据有限使得预训练模型性能受限，且预训练计算开销大，因此聚焦于提高微调阶段的效率和效果。

Method: 通过将主动学习与数据聚类结合，设计集成的微调管道，采用动态数据选择调度器优化训练数据选择，加强模型微调效果。

Result: 本文针对低资源语言因数据有限导致语言模型性能较弱的问题，提出在微调阶段采用主动学习（AL）结合结构化数据选择策略（称为"主动学习调度器"）的方法。通过将AL与数据聚类相结合，构建一个集成微调管道，实现AL、聚类与动态数据选择调度器的系统性组合，以提升模型性能。斯洛伐克语、马耳他语、冰岛语和土耳其语的实验结果表明，该方法在微调阶段使用聚类和AL调度器不仅能节省多达30%的标注成本，还可提升高达4个F1分数点的性能，同时增强微调过程的稳定性。

Conclusion: 结合主动学习调度器与聚类技术的微调方法能显著提高低资源语言模型的性能、稳定性并减少标注需求。

Abstract: Limited data for low-resource languages typically yield weaker language models (LMs). Since pre-training is compute-intensive, it is more pragmatic to target improvements during fine-tuning. In this work, we examine the use of Active Learning (AL) methods augmented by structured data selection strategies which we term 'Active Learning schedulers', to boost the fine-tuning process with a limited amount of training data. We connect the AL to data clustering and propose an integrated fine-tuning pipeline that systematically combines AL, clustering, and dynamic data selection schedulers to enhance model's performance. Experiments in the Slovak, Maltese, Icelandic and Turkish languages show that the use of clustering during the fine-tuning phase together with AL scheduling can simultaneously produce annotation savings up to 30% and performance improvements up to four F1 score points, while also providing better fine-tuning stability.

</details>


### [59] [MCAT: Scaling Many-to-Many Speech-to-Text Translation with MLLMs to 70 Languages](https://arxiv.org/abs/2512.01512)
*Yexing Du,Kaiyuan Liu,Youcheng Pan,Bo Yang,Keqi Deng,Xie Chen,Yang Xiang,Ming Liu,Bin Qin,YaoWei Wang*

Main category: cs.CL

TL;DR: 本文提出了一个多语言高效加速语音转文本翻译框架MCAT，通过课程学习和数据平衡策略扩展了语言覆盖至70种语言，同时设计了优化的语音适配器模块大幅缩短语音序列长度，提升了翻译性能和推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前语音转文本翻译任务受限于语言覆盖狭窄（多为英语为中心）和推理效率低下（长序列带来的计算瓶颈），限制了多语言大模型的推广和应用。

Method: 采用课程学习和数据平衡策略扩展语言覆盖，设计优化的语音适配器模块将语音序列长度从750缩短至30，提高效率，并在不同规模的MLLM（9B和27B）上进行了实验验证。

Result: MCAT在多语言翻译任务上超越了最新端到端模型，支持70乘69种语言互译，推理速度显著提升，且只用较少的训练数据和参数实现。代码和模型已开源。

Conclusion: MCAT框架在70种语言的FLEURS数据集上表现优于现有最先进的端到端模型，同时明显提升推理效率，仅需约1亿可训练参数和每语言10小时的训练数据，具备良好的扩展性和实用性。

Abstract: Multimodal Large Language Models (MLLMs) have achieved great success in Speech-to-Text Translation (S2TT) tasks. However, current research is constrained by two key challenges: language coverage and efficiency. Most of the popular S2TT datasets are substantially English-centric, which restricts the scaling-up of MLLMs' many-to-many translation capabilities. Moreover, the inference speed of MLLMs degrades dramatically when the speech is converted into long sequences (e.g., 750 tokens). To address these limitations, we propose a Multilingual Cost-effective Accelerated Speech-to-Text Translator (MCAT) framework, which includes two innovations. First, a language scaling method that leverages curriculum learning and a data balancing strategy is introduced to extend the language coverage supported by MLLMs to 70 languages and achieve mutual translation among these languages. Second, an optimized speech adapter module is designed to reduce the length of the speech sequence to only 30 tokens. Extensive experiments were conducted on MLLMs of different scales (9B and 27B). The experimental results demonstrate that MCAT not only surpasses state-of-the-art end-to-end models on the FLEURS dataset across 70x69 directions but also enhances batch inference efficiency. This is achieved with only ~100M trainable parameters and by using only 10 hours of S2TT data per language. Furthermore, we have released MCAT as open-source to promote the development of MLLMs for robust S2TT capabilities. The code and models are released at https://github.com/yxduir/m2m-70.

</details>


### [60] [Language Diversity: Evaluating Language Usage and AI Performance on African Languages in Digital Spaces](https://arxiv.org/abs/2512.01557)
*Edward Ajayi,Eudoxie Umwari,Mawuli Deku,Prosper Singadi,Jules Udahemuka,Bekalu Tadele,Chukuemeka Edeh*

Main category: cs.CL

TL;DR: 本文研究了非洲语言在数字媒体中的表现及其对语言检测工具的挑战，发现本地新闻数据比社交平台数据更适合训练语言模型。


<details>
  <summary>Details</summary>
Motivation: 非洲语言在线使用稀少且夹杂大量英语，缺乏真实单语对话数据，给训练有效语言模型带来挑战。

Method: 收集了Yoruba、Kinyarwanda和Amharic三种语言的Reddit和本地新闻数据，评估现有语言检测模型（如AfroLID和大型语言模型）在不同数据上的表现。

Result: 新闻数据表现出丰富、干净的单语特征，用户互动更多；语言检测模型在新闻数据上准确率高，在夹杂代码切换的Reddit数据上表现较差。

Conclusion: 专业策划的新闻内容比对话平台数据更适合用来训练非洲语言的上下文丰富的AI模型，未来模型需兼顾干净文本和混合语言文本增强检测准确性。

Abstract: This study examines the digital representation of African languages and the challenges this presents for current language detection tools. We evaluate their performance on Yoruba, Kinyarwanda, and Amharic. While these languages are spoken by millions, their online usage on conversational platforms is often sparse, heavily influenced by English, and not representative of the authentic, monolingual conversations prevalent among native speakers. This lack of readily available authentic data online creates a challenge of scarcity of conversational data for training language models. To investigate this, data was collected from subreddits and local news sources for each language. The analysis showed a stark contrast between the two sources. Reddit data was minimal and characterized by heavy code-switching. Conversely, local news media offered a robust source of clean, monolingual language data, which also prompted more user engagement in the local language on the news publishers social media pages. Language detection models, including the specialized AfroLID and a general LLM, performed with near-perfect accuracy on the clean news data but struggled with the code-switched Reddit posts. The study concludes that professionally curated news content is a more reliable and effective source for training context-rich AI models for African languages than data from conversational platforms. It also highlights the need for future models that can process clean and code-switched text to improve the detection accuracy for African languages.

</details>


### [61] [MAC-SLU: Multi-Intent Automotive Cabin Spoken Language Understanding Benchmark](https://arxiv.org/abs/2512.01603)
*Yuezhang Peng,Chonghao Cai,Ziang Liu,Shuai Fan,Sheng Jiang,Hua Xu,Yuxin Liu,Qiguang Chen,Kele Xu,Yao Li,Sheng Wang,Libo Qin,Xie Chen*

Main category: cs.CL

TL;DR: 提出MAC-SLU数据集，评测了LLMs和LALMs在多意图汽车语音理解任务上的表现，发现有监督微调效果最好，端到端LALMs表现优于流水线方法。


<details>
  <summary>Details</summary>
Motivation: 现有SLU数据集缺乏多样性和复杂性，且缺乏对最新大型语言模型和音频语言模型的统一评测基准，因此提出MAC-SLU以推动SLU任务的发展。

Method: 构建了多意图复杂语音数据集MAC-SLU，采用上下文学习、有监督微调、端到端和流水线等多种方法对LLMs和LALMs进行了基准测试。

Result: 本文提出了一个新颖的多意图汽车座舱口语理解数据集MAC-SLU，增加了SLU任务的难度，引入了真实且复杂的多意图数据。基于该数据集，对领先的开源大型语言模型（LLMs）和大型音频语言模型（LALMs）进行了全面基准测试，涵盖了上下文学习、有监督微调、端到端和流水线范式等方法。实验表明，虽然LLMs和LALMs通过上下文学习能够完成SLU任务，但性能仍远低于有监督微调；同时，端到端的LALMs性能表现与流水线方法相当，有效避免了语音识别的错误传播。

Conclusion: MAC-SLU数据集提升了SLU任务复杂度，端到端LALMs展现了良好的性能和误差鲁棒性，但有监督微调仍是最优方法。

Abstract: Spoken Language Understanding (SLU), which aims to extract user semantics to execute downstream tasks, is a crucial component of task-oriented dialog systems. Existing SLU datasets generally lack sufficient diversity and complexity, and there is an absence of a unified benchmark for the latest Large Language Models (LLMs) and Large Audio Language Models (LALMs). This work introduces MAC-SLU, a novel Multi-Intent Automotive Cabin Spoken Language Understanding Dataset, which increases the difficulty of the SLU task by incorporating authentic and complex multi-intent data. Based on MAC-SLU, we conducted a comprehensive benchmark of leading open-source LLMs and LALMs, covering methods like in-context learning, supervised fine-tuning (SFT), and end-to-end (E2E) and pipeline paradigms. Our experiments show that while LLMs and LALMs have the potential to complete SLU tasks through in-context learning, their performance still lags significantly behind SFT. Meanwhile, E2E LALMs demonstrate performance comparable to pipeline approaches and effectively avoid error propagation from speech recognition. Code\footnote{https://github.com/Gatsby-web/MAC\_SLU} and datasets\footnote{huggingface.co/datasets/Gatsby1984/MAC\_SLU} are released publicly.

</details>


### [62] [Learning the Boundary of Solvability: Aligning LLMs to Detect Unsolvable Problems](https://arxiv.org/abs/2512.01661)
*Dengyun Peng,Qiguang Chen,Bofei Liu,Jiannan Guan,Libo Qin,Zheng Yan,Jinhao Liu,Jianshu Zhang,Wanxiang Che*

Main category: cs.CL

TL;DR: 该文通过构建不可解问题数据集和强化学习训练，提升语言模型对不可解问题的识别能力，防止过度自信和幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以区分问题本质上的不可解性与自身能力限制，导致幻觉和过度自信，迫切需要提升模型对不可解问题的识别和应对能力。

Method: 构建包含可解与不可解问题的UnsolvableQA数据集，使用程序化生成和“逆向构造”方法引入矛盾。基于此设计UnsolvableRL强化学习框架，采用结合准确率、不可解性和难度的三重奖励机制进行训练。

Result: 本文提出了UnsolvableQA数据集和UnsolvableRL强化学习框架，解决大型语言模型区分问题是否不可解的难题。通过程序化生成逻辑谜题和逆向构造数学题中的矛盾实例，构建包含可解与不可解实例的数据集。于是，UnsolvableRL结合准确率、不可解性和难度三个奖励项进行训练，有效提升了不可解性的检测能力并提升了可解任务的准确率。本文揭示了“能力崩溃”现象，强调显式引入不可解数据训练对防止模型过度自信的重要性。

Conclusion: 明确标注和训练不可解问题对提升模型判断力和避免过度自信至关重要，实验证明该方法在不可解性检测和任务准确率上均有显著效果。

Abstract: Ensuring LLM reliability requires not only solving complex problems but also recognizing when a problem is unsolvable. Current models often struggle to distinguish objective unsolvability (inherent contradictions in the problem) from subjective capability limitations (problems beyond the model's competence), which leads to hallucinations and overconfidence. To address this, we propose UnsolvableQA and UnsolvableRL to solve feasible problems, detect inherent contradictions, and prudently refuse tasks beyond capability. Specifically, we construct UnsolvableQA, a dataset of paired solvable and unsolvable instances derived via a dual-track methodology: programmatic generation for logic puzzles and a novel "Reverse Construction" method that injects contradictions into valid reasoning chains for mathematics. Building on this dataset, we introduce UnsolvableRL, a reinforcement learning framework with three reward components jointly accounting for accuracy, unsolvability, and difficulty. Empirical results show that our approach achieves near-perfect unsolvability detection while also improving accuracy on solvable tasks. Crucially, we identify Capability Collapse, demonstrating that explicit exposure to unsolvable data is indispensable for preventing models from becoming systematically overconfident. Our code and data are available at https://github.com/sfasfaffa/unsolvableQA.

</details>


### [63] [MMAG: Mixed Memory-Augmented Generation for Large Language Models Applications](https://arxiv.org/abs/2512.01710)
*Stefano Zeppieri*

Main category: cs.CL

TL;DR: 本论文提出了一种基于多层记忆结构的混合记忆增强生成模式，以提升大语言模型在长时间交互中的连贯性和个性化，通过Heero代理实现验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在单次提示下生成连贯文本效果佳，但难以维持长时间交互的相关性、个性化和连续性，而人类交流依赖多种记忆形式以适应个人特征和情境。

Method: 提出了混合记忆增强生成（MMAG）模式，将记忆组织为五个互相作用的层次：会话记忆、长期用户记忆、情节与事件关联记忆、感官与上下文感知记忆、短时工作记忆。通过认知心理学理论指导，将这些记忆层映射到技术组件，并制定协调、优先级和冲突解决策略。

Result: 在Heero对话代理中实现了MMAG架构，长时加密用户信息和对话历史能显著提升用户参与度和留存率。讨论了存储、检索、隐私和延迟等实现问题，并指出了开放挑战。

Conclusion: MMAG为构建具备丰富记忆能力的语言代理奠定基础，使其表现更连贯、主动并符合人类需求，同时需继续解决存储、隐私及性能等实际问题。

Abstract: Large Language Models (LLMs) excel at generating coherent text within a single prompt but fall short in sustaining relevance, personalization, and continuity across extended interactions. Human communication, however, relies on multiple forms of memory, from recalling past conversations to adapting to personal traits and situational context. This paper introduces the Mixed Memory-Augmented Generation (MMAG) pattern, a framework that organizes memory for LLM-based agents into five interacting layers: conversational, long-term user, episodic and event-linked, sensory and context-aware, and short-term working memory. Drawing inspiration from cognitive psychology, we map these layers to technical components and outline strategies for coordination, prioritization, and conflict resolution. We demonstrate the approach through its implementation in the Heero conversational agent, where encrypted long-term bios and conversational history already improve engagement and retention. We further discuss implementation concerns around storage, retrieval, privacy, and latency, and highlight open challenges. MMAG provides a foundation for building memory-rich language agents that are more coherent, proactive, and aligned with human needs.

</details>


### [64] [Self-Supervised Borrowing Detection on Multilingual Wordlists](https://arxiv.org/abs/2512.01713)
*Tim Wientzek*

Main category: cs.CL

TL;DR: 本论文提出了一种完全自监督的多语言词表借词检测方法，结合了基于全局对应模型的PMI相似度和基于音素特征向量的对比学习，自动选择阈值，无需标注数据，效果优于传统字符串相似度方法并接近或超越有监督基线。


<details>
  <summary>Details</summary>
Motivation: 提升多语言词表借词检测准确性，同时减少对标注数据的依赖，实现全自动化处理。

Method: 结合基于全局对应模型的PMI相似度与轻量级对比学习组件，自动化阈值选择策略，无需监督数据。

Result: 实验表明PMI相似度就超过了现有字符串相似度方法，与监督基线相当或更优；消融实验强调字符编码、温度参数和数据增强的重要性。

Conclusion: 该方法在多语言借词检测任务中表现优异，不依赖人工标注，且具备良好的扩展性和实用性。

Abstract: This paper presents a fully self-supervised approach to borrowing detection in multilingual wordlists. The method combines two sources of information: PMI similarities based on a global correspondence model and a lightweight contrastive component trained on phonetic feature vectors. It further includes an automatic procedure for selecting decision thresholds without requiring labeled data. Experiments on benchmark datasets show that PMI alone already improves over existing string similarity measures such as NED and SCA, and that the combined similarity performs on par with or better than supervised baselines. An ablation study highlights the importance of character encoding, temperature settings and augmentation strategies. The approach scales to datasets of different sizes, works without manual supervision and is provided with a command-line tool that allows researchers to conduct their own studies.

</details>


### [65] [Beware of Reasoning Overconfidence: Pitfalls in the Reasoning Process for Multi-solution Tasks](https://arxiv.org/abs/2512.01725)
*Jiannan Guan,Qiguang Chen,Libo Qin,Dengyun Peng,Jinhao Liu,Liangyu Huo,Jian Xie,Wanxiang Che*

Main category: cs.CL

TL;DR: 大型语言模型在需要多样答案的推理任务中表现出过度自信，导致答案不全面。引入新基准和长链思维方法，并提出认知僵化假说帮助解决该问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多解任务中生成答案不够全面多样，存在过度自信倾向，亟需理解其原因并改进评价标准。

Method: 提出MuSoBench多解问题基准，比较短链思维和长链思维提示方法，并通过注意力熵分析验证认知僵化假说。

Result: 实验证明短链思维提示易产生过度自信，长链思维提示可缓解该问题，注意力熵分析支持认知僵化假说。

Conclusion: 大型语言模型在多解任务中表现出过度自信，限制了其生成全面多样答案的能力。通过引入MuSoBench基准测试和提出认知僵化假说，验证了这一现象及其原因。

Abstract: Large Language Models (LLMs) excel in reasoning tasks requiring a single correct answer, but they perform poorly in multi-solution tasks that require generating comprehensive and diverse answers. We attribute this limitation to \textbf{reasoning overconfidence}: a tendency to express undue certainty in an incomplete solution set. To examine the effect, we introduce \textit{MuSoBench}, a benchmark of multi-solution problems. Experiments show that the conventional short chain-of-thought (Short-CoT) prompting paradigm exhibits pronounced overconfidence, whereas the emerging long chain-of-thought (Long-CoT) approach mitigates it through iterative exploration and self-reflection. We further characterise observable behaviours and influential factors. To probe the underlying cause, we propose the \textbf{cognitive-rigidity hypothesis}, which posits that overconfidence arises when the reasoning process prematurely converges on a narrow set of thought paths. An attention-entropy analysis offers preliminary support for this view. These findings provide tools for assessing the completeness of LLM reasoning and highlight the need to move evaluation beyond single-answer accuracy toward comprehensive exploration.

</details>


### [66] [Reasoning About the Unsaid: Misinformation Detection with Omission-Aware Graph Inference](https://arxiv.org/abs/2512.01728)
*Zhengjia Wang,Danding Wang,Qiang Sheng,Jiaying Wu,Juan Cao*

Main category: cs.CL

TL;DR: 本文提出了OmiGraph，一种针对信息误导中的省略式欺骗的检测框架，通过构建省略感知图并结合上下文环境挖掘省略内容，实现对省略意图和关系的建模，显著提升了误导信息检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前误导信息检测主要关注虚假内容的明示造假，却忽视了通过省略关键信息导致误导的隐式欺骗，后者能更隐蔽地引导读者形成错误结论，因此亟需开发针对省略欺骗的新检测方法。

Method: 设计了OmiGraph框架，构建省略感知图，利用上下文环境捕获事件的互补视角，挖掘可能被省略的内容，通过省略导向的关系建模提取省略意图和上下文依赖，采用省略感知的消息传递和汇聚机制提取省略模式进行检测。

Result: OmiGraph在考虑省略角度后，在两个大规模基准数据集上分别提升了约5.4%的F1值和5.3%的准确率，显著优于现有方法。

Conclusion: 本文首次关注并有效检测了省略式误导，通过省略感知图和关系建模方法，提升了误导信息的识别效果，实验结果表明在两个大规模基准数据集上性能提升显著。

Abstract: This paper investigates the detection of misinformation, which deceives readers by explicitly fabricating misleading content or implicitly omitting important information necessary for informed judgment. While the former has been extensively studied, omission-based deception remains largely overlooked, even though it can subtly guide readers toward false conclusions under the illusion of completeness. To pioneer in this direction, this paper presents OmiGraph, the first omission-aware framework for misinformation detection. Specifically, OmiGraph constructs an omission-aware graph for the target news by utilizing a contextual environment that captures complementary perspectives of the same event, thereby surfacing potentially omitted contents. Based on this graph, omission-oriented relation modeling is then proposed to identify the internal contextual dependencies, as well as the dynamic omission intents, formulating a comprehensive omission relation representation. Finally, to extract omission patterns for detection, OmiGraph introduces omission-aware message-passing and aggregation that establishes holistic deception perception by integrating the omission contents and relations. Experiments show that, by considering the omission perspective, our approach attains remarkable performance, achieving average improvements of +5.4% F1 and +5.3% ACC on two large-scale benchmarks.

</details>


### [67] [Beyond SFT: Reinforcement Learning for Safer Large Reasoning Models with Better Reasoning Ability](https://arxiv.org/abs/2512.01848)
*Jinghan Jia,Nathalie Baracaldo,Sijia Liu*

Main category: cs.CL

TL;DR: 本文提出用强化学习改进大型推理模型的安全对齐，解决了监督微调的不足，实现更安全且稳定的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的安全对齐方法主要依赖于监督微调，存在安全提升不一致、推理能力下降和跨模型泛化能力差的问题。

Method: 采用强化学习作为大型推理模型安全训练的补充优化框架，结合奖励反馈直接优化模型策略。

Result: 强化学习方法在多个模型和基准测试中表现出更强和更一致的安全提升，同时保持推理能力。

Conclusion: 强化学习能有效抑制不安全的探索性推理，同时保留反思深度，促进推理过程更安全可靠。

Abstract: Large reasoning models (LRMs) extend large language models by generating explicit chain-of-thought (CoT) reasoning, significantly improving mathematical and logical problem solving. However, this explicit reasoning process also introduces new safety risks, as unsafe behaviors often emerge within intermediate reasoning trajectories, even when final answers appear harmless. Existing safety alignment approaches primarily rely on supervised fine-tuning (SFT) over safety-oriented long CoT datasets. While intuitive, we find that SFT produces inconsistent safety improvements, degrades reasoning ability, and generalizes poorly across model families. These limitations suggest that purely supervised approaches are insufficient for robust safety alignment in LRMs. To address this, we investigate reinforcement learning (RL) as a complementary optimization framework for LRM safety training. Unlike SFT, RL directly optimizes model policies with reward feedback, enabling more adaptive and stable alignment. Extensive experiments across multiple model families and benchmarks show that RL achieves stronger and more consistent safety gains while maintaining reasoning competence. Further analysis of reflection dynamics and token-level entropy reveals that RL suppresses unsafe exploratory reasoning while preserving reflective depth, leading to safer and more reliable reasoning processes.

</details>


### [68] [BHRAM-IL: A Benchmark for Hallucination Recognition and Assessment in Multiple Indian Languages](https://arxiv.org/abs/2512.01852)
*Hrishikesh Terdalkar,Kirtan Bhojani,Aryan Dongare,Omm Aditya Behera*

Main category: cs.CL

TL;DR: BHRAM-IL是一个面向五种语言的幻觉检测基准，包含3.6万多问题，评测14个多语言大模型，揭示其在不同语言和任务中的幻觉表现，并提供公开数据和代码支持。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在多语言应用中容易生成幻觉内容，尤其是低资源印度语言领域缺乏针对幻觉的评估资源，因此需要建立一个多语言幻觉检测和评估基准，帮助促进相关模型的研究和改进。

Method: 构建多语言幻觉检测基准BHRAM-IL，收集并人工策划36047个涉及事实、数值、推理和语言学任务的问题，选定10265个作为测试集，使用14个当前领先的多语言大型语言模型进行评测，通过归一化类别特定指标分析跨语言及事实幻觉表现，计算综合主评分和语言校正模糊评分。

Result: 本文推出了BHRAM-IL，这是一个涵盖印地语、古吉拉特语、马拉地语、奥里亚语以及英语的多语言幻觉识别和评估基准，包含36047个涵盖事实、数值、推理及语言任务的精选问题。通过对14个多语言大型语言模型在10265个问题子集上的评测，揭示了跨语言幻觉特征及模型表现，提出了0.23的综合主评分和0.385的语言校正模糊分数，验证了BHRAM-IL在幻觉检测上的实用价值。数据集及相关代码已公开，促进未来多语言幻觉研究。

Conclusion: BHRAM-IL基准有效评估了多语言大型语言模型的幻觉问题，显示出这些模型在多语言环境下仍存在显著幻觉现象，且其评估指标和数据集将促进相关领域的研究和改进。

Abstract: Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.

</details>


### [69] [Cross-Lingual Interleaving for Speech Language Models](https://arxiv.org/abs/2512.01865)
*Adel Moumen,Guangzhi Sun,Philip C. Woodland*

Main category: cs.CL

TL;DR: 该论文提出了一种无需文本监督的跨语言语音交错训练方法，有效提升了多语言口语模型的语义理解和跨语言对话能力，并发布了相关数据集和基准测试支持该研究。


<details>
  <summary>Details</summary>
Motivation: 当前的口语语言模型（SLMs）多集中于英语，缺乏跨语言的语音评估基准和训练数据，导致跨语言学习困难。

Method: 无文本监督下的跨语言语音单位交错训练，同时结合GPT-4合成生成的训练数据及语义评估基准，针对360M和1B参数模型进行了系统验证。

Result: 提出了一种跨语言交错方法，通过混合不同语言的语音单位进行训练，显著提升了单语言语义准确度和跨语言语义理解能力。同时发布了EN-FR训练数据集和对应基准测试，实现了多语言SLMs的有效训练和评估。

Conclusion: 跨语言交错方法为构建能够理解并跨语言交流的多语言口语语言模型提供了简单且可扩展的途径，验证了其在提升语义理解和隐藏状态对齐上的有效性。

Abstract: Spoken Language Models (SLMs) aim to learn linguistic competence directly from speech using discrete units, widening access to Natural Language Processing (NLP) technologies for languages with limited written resources. However, progress has been largely English-centric due to scarce spoken evaluation benchmarks and training data, making cross-lingual learning difficult. We present a cross-lingual interleaving method that mixes speech tokens across languages without textual supervision. We also release an EN-FR training dataset, TinyStories (~42k hours), together with EN-FR spoken StoryCloze and TopicCloze benchmarks for cross-lingual semantic evaluation, both synthetically generated using GPT-4. On 360M and 1B SLMs under matched training-token budgets, interleaving improves monolingual semantic accuracy, enables robust cross-lingual continuation, and strengthens cross-lingual hidden-state alignment. Taken together, these results indicate that cross-lingual interleaving is a simple, scalable route to building multilingual SLMs that understand and converse across languages. All resources will be made open-source to support reproducibility.

</details>


### [70] [Exploring Human Perceptions of AI Responses: Insights from a Mixed-Methods Study on Risk Mitigation in Generative Models](https://arxiv.org/abs/2512.01892)
*Heloisa Candello,Muneeza Azmat,Uma Sushmitha Gunturi,Raya Horesh,Rogerio Abreu de Paula,Heloisa Pimentel,Marcelo Carpinette Grave,Aminat Adebiyi,Tiago Machado,Maysa Malfiza Garcia de Macedo*

Main category: cs.CL

TL;DR: 本文通过混合方法实验评估生成式AI缓解策略的效果，发现用户评价受语言背景影响显著，提出了新指标助力缓解策略优化。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的快速普及，研究人们对生成回应的感知变得至关重要，特别是针对生成内容中的幻觉和有害信息的出现。

Method: 采用混合实验方法，设计受试者内实验，比较有害内容缓解前后生成回应的多维度表现，结合定量与定性分析，提出新的评价指标。

Result: 研究发现参与者的母语、人工智能工作经验和标注熟悉度显著影响其评价。同时，参与者对语言和语境特征高度敏感，对细微语法错误进行惩罚，而语义语境保持则被奖励，这与大型语言模型的量化评估形成对比。同时提出了用于训练和评估缓解策略的新指标。

Conclusion: 人类对生成内容的评价受语言和背景因素影响较大，应重视语言细节和语境的维持。本文提出的评估方法和指标为生成式AI缓解策略的优化和人机协同评价提供了新的思路。

Abstract: With the rapid uptake of generative AI, investigating human perceptions of generated responses has become crucial. A major challenge is their `aptitude' for hallucinating and generating harmful contents. Despite major efforts for implementing guardrails, human perceptions of these mitigation strategies are largely unknown. We conducted a mixed-method experiment for evaluating the responses of a mitigation strategy across multiple-dimensions: faithfulness, fairness, harm-removal capacity, and relevance. In a within-subject study design, 57 participants assessed the responses under two conditions: harmful response plus its mitigation and solely mitigated response. Results revealed that participants' native language, AI work experience, and annotation familiarity significantly influenced evaluations. Participants showed high sensitivity to linguistic and contextual attributes, penalizing minor grammar errors while rewarding preserved semantic contexts. This contrasts with how language is often treated in the quantitative evaluation of LLMs. We also introduced new metrics for training and evaluating mitigation strategies and insights for human-AI evaluation studies.

</details>


### [71] [OPOR-Bench: Evaluating Large Language Models on Online Public Opinion Report Generation](https://arxiv.org/abs/2512.01896)
*Jinzheng Yu,Yang Xu,Haozhen Li,Junqi Li,Yifan Feng,Ligu Zhu,Hao Shen,Lei Shi*

Main category: cs.CL

TL;DR: 本文定义在线舆情报告自动生成任务，构建数据集与评估框架，推动舆情危机管理自动化研究。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型虽使自动报告生成成为可能，但缺乏系统性的任务定义和基准数据，限制了该领域的研究和应用发展，因此本文旨在填补这一空白。

Method: 构建事件中心的数据集OPOR-BENCH，包含新闻和社交媒体信息，设计基于代理人的评估框架OPOR-EVAL，用以模拟专家在特定语境下的报告质量评估。

Result: 本文提出了一个自动生成在线舆情报告（OPOR-GEN）任务，构建了包含463个危机事件的多模态数据集（OPOR-BENCH），并设计了模拟专家评价的评估框架（OPOR-EVAL）。实验表明该框架与人工评估高度相关。

Conclusion: 本研究首次系统定义了在线舆情报告自动生成任务，提出了包含多模态数据的基准数据集和创新的评估方法，为该领域未来研究奠定了基础。

Abstract: Online Public Opinion Reports consolidate news and social media for timely crisis management by governments and enterprises. While large language models have made automated report generation technically feasible, systematic research in this specific area remains notably absent, particularly lacking formal task definitions and corresponding benchmarks. To bridge this gap, we define the Automated Online Public Opinion Report Generation (OPOR-GEN) task and construct OPOR-BENCH, an event-centric dataset covering 463 crisis events with their corresponding news articles, social media posts, and a reference summary. To evaluate report quality, we propose OPOR-EVAL, a novel agent-based framework that simulates human expert evaluation by analyzing generated reports in context. Experiments with frontier models demonstrate that our framework achieves high correlation with human judgments. Our comprehensive task definition, benchmark dataset, and evaluation framework provide a solid foundation for future research in this critical domain.

</details>


### [72] [Latent Debate: A Surrogate Framework for Interpreting LLM Thinking](https://arxiv.org/abs/2512.01909)
*Lihu Chen,Xiang Yin,Francesca Toni*

Main category: cs.CL

TL;DR: 论文提出“潜在辩论”框架解释大型语言模型内部推理过程，并利用该框架检测幻觉，发现内层辩论活动与幻觉风险相关。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的内部思考过程和幻觉成因难以理解，现有方法依赖多模型或多答案的显式辩论，缺乏对单模型单步骤内部信号的捕捉，故提出潜在辩论框架以深入解析模型内部机制。

Method: 提出模型与任务无关的潜在辩论概念框架，并符号化实现，用以近似大型语言模型在True/False任务上的思考过程，通过捕捉单模型单推理中的内在支持和攻击信号进行结构化解释。

Result: 本文提出了一种名为“潜在辩论”的新框架，用于通过隐含的内部论点解释大型语言模型（LLMs）的预测过程，特别是在True/False预测任务中。该方法不同于现有依赖多答案或多模型显式辩论的自洽性和多智能体辩论，能够捕捉单一模型单次推理中的支持与攻击信号。实证研究表明，潜在辩论不仅与原始LLM预测高度一致，而且能够作为识别幻觉的强有力基线。进一步分析发现，幻觉发生与中间层的辩论活动高度相关，揭示了潜在辩论对理解LLM内部机制的潜力。

Conclusion: 潜在辩论是一种有效的解释大型语言模型内部思考过程的方法，能高度还原模型预测并辅助幻觉检测，揭示LLM内部推理中的支持和反对信号，帮助理解模型生成错误的机制。

Abstract: Understanding the internal thinking process of Large Language Models (LLMs) and the cause of hallucinations remains a key challenge. To this end, we introduce latent debate, a novel framework for interpreting model predictions through the lens of implicit internal arguments. Unlike the current work of self-consistency and multi-agent debate, which relies on explicit debates among multiple answers or multiple models, latent debate captures the hidden supporting and attacking signals that arise within a single model during a single inference. We first present a model- and task-agnostic conceptual framework, and then instantiate it symbolically to approximate the thinking process of LLMs on True/False prediction tasks. Empirical studies demonstrate that latent debate is a faithful structured surrogate model that has highly consistent predictions with the original LLM. Beyond interpretability, we demonstrate that latent debate provides a strong baseline for hallucination detection. Further analysis reveals strong correlations between hallucinations and debate patterns, such as a high degree of latent debates in the middle layers is linked to a higher risk of hallucinations. These findings position latent debate as a potential framework for understanding internal mechanisms of LLMs, especially for scenarios where internal (dis)agreements appear during the inference steps.

</details>


### [73] [Rectifying LLM Thought from Lens of Optimization](https://arxiv.org/abs/2512.01925)
*Junnan Liu,Hongwei Liu,Songyang Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 本文提出RePro方法，通过过程层奖励优化长链推理，显著改善大型语言模型的推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前长链推理（long chain-of-thought，CoT）虽然提升了大型语言模型（LLMs）的推理能力，但容易出现过度思考和推理链过长的问题，影响表现。

Method: 本文将CoT推理过程视为梯度下降优化过程，每一步推理都是向问题解决的更新。基于此，引入RePro（Rectifying Process-level Reward），通过双评分机制评估推理过程的强度与稳定性，构建复合过程层奖励，并将其结合验证奖励的强化学习（RLVR）框架，对LLM进行后训练优化。

Result: 实验证明，RePro方法在多个强化学习算法和不同LLM上均能显著提升推理性能，减轻过度思考和推理链过长等不良行为，在数学、科学和编程等多领域基准测试中效果优异。

Conclusion: 将长链推理视为优化过程并从过程层面设计奖惩机制，能够有效改进大型语言模型的推理表现，避免过度推理的问题，提升整体推理质量。

Abstract: Recent advancements in large language models (LLMs) have been driven by their emergent reasoning capabilities, particularly through long chain-of-thought (CoT) prompting, which enables thorough exploration and deliberation. Despite these advances, long-CoT LLMs often exhibit suboptimal reasoning behaviors, such as overthinking and excessively protracted reasoning chains, which can impair performance. In this paper, we analyze reasoning processes through an optimization lens, framing CoT as a gradient descent procedure where each reasoning step constitutes an update toward problem resolution. Building on this perspective, we introduce RePro (Rectifying Process-level Reward), a novel approach to refine LLM reasoning during post-training. RePro defines a surrogate objective function to assess the optimization process underlying CoT, utilizing a dual scoring mechanism to quantify its intensity and stability. These scores are aggregated into a composite process-level reward, seamlessly integrated into reinforcement learning with verifiable rewards (RLVR) pipelines to optimize LLMs. Extensive experiments across multiple reinforcement learning algorithms and diverse LLMs, evaluated on benchmarks spanning mathematics, science, and coding, demonstrate that RePro consistently enhances reasoning performance and mitigates suboptimal reasoning behaviors.

</details>


### [74] [How Far Are We from Genuinely Useful Deep Research Agents?](https://arxiv.org/abs/2512.01948)
*Dingling Zhang,He Zhu,Jincheng Ren,Kangqi Song,Xinran Zhou,Boyu Feng,Shudong Liu,Jiabin Luo,Weihao Xie,Zhaohui Wang,Tianrui Qin,King Zhu,Yuqing Wang,Qianben Chen,Yuchen Eleanor Jiang,Wei Wang,Jiaheng Liu,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 本文提出了针对深度研究代理的细粒度研究报告生成基准FINDER和失败分类法DEFT，发现当前代理在证据处理和推理规划方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 当前的深度研究代理（DRA）多用于问答任务，缺乏对综合性研究报告生成的有效验证，且现有的报告合成基准存在任务复杂性高和评测指标主观的问题，难以满足实际用户需求。

Method: 构建一个包含100个人工策划研究任务和419个结构化核对项的FINDER基准，收集约1000份主流DRA生成的报告，基于人工与大语言模型共同注释开发了包含14种失败模式的DEFT失败分类法，并进行了可靠性验证和实验分析。

Result: 提出了Fine-grained DEepResearch基准（FINDER），包含100个人工策划的研究任务和419个结构化核对项，同时设计了深度研究失败分类法（DEFT），涵盖14种细粒度失败模式，揭示现有DRA在证据整合、验证和推理性规划上的挑战。

Conclusion: 当前深度研究代理在对任务的理解上表现良好，但在证据整合、验证以及面向推理的规划方面存在显著失败，需进一步改进相关能力以提升报告质量和实用性。

Abstract: Deep Research Agents (DRAs) aim to automatically produce analyst-level reports through iterative information retrieval and synthesis. However, most existing DRAs were validated on question-answering benchmarks, while research on generating comprehensive reports remains overlooked. Worse, current benchmarks for report synthesis suffer from task complexity and subjective metrics -- this fails to reflect user demands and limits the practical utility of generated reports. To address these gaps, we present Fine-grained DEepResearch bench (FINDER), an enhanced benchmark consisting of 100 human-curated research tasks with 419 structured checklist items that standardize report structure, analytical depth, and factual grounding. Based on approximately 1,000 reports produced by mainstream DRAs, we further propose Deep rEsearch Failure Taxonomy (DEFT), the first failure taxonomy for deep research agents. DEFT contains 14 fine-grained failure modes across reasoning, retrieval, and generation, and is built upon grounded theory with human-LLM co-annotating and inter-annotator reliability validation. Our experimental findings reveal that current DRAs struggle not with task comprehension but with evidence integration, verification, and reasoning-resilient planning.

</details>


### [75] [The Art of Scaling Test-Time Compute for Large Language Models](https://arxiv.org/abs/2512.02008)
*Aradhye Agarwal,Ayan Sengupta,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 对八个开源大语言模型的测试时动态计算分配策略进行了大规模比较，发现没有单一最佳策略，模型类型和题目难度影响性能，提出了基于这些因素的实用策略选择指南。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对测试时动态计算分配策略的系统比较，以及对模型类型和问题难度对性能影响的理解，故开展此大规模研究填补该领域空白。

Method: 通过在四个推理数据集上，采用八种不同参数规模的开源大语言模型，生成超过三百亿token，系统性比较多种已知的TTS策略表现。

Result: 本论文首次系统性比较了多种测试时动态计算分配（TTS）策略在不同大型语言模型（7B到235B参数）和推理任务上的表现，通过生成超过三百亿个token，揭示了TTS策略无万能最佳方案、推理模型表现与问题难度及追踪长度相关，以及TTS性能随计算预算单调提升的规律。

Conclusion: 没有统一最佳的TTS策略，模型和问题特性决定最佳策略，且增加计算预算能持续提升效果，基于这些发现，论文提供了选择TTS策略的实用指导。

Abstract: Test-time scaling (TTS) -- the dynamic allocation of compute during inference -- is a promising direction for improving reasoning in large language models (LLMs). However, a systematic comparison of well-known TTS strategies under identical conditions is missing, and the influence of model type and problem difficulty on performance remains unclear. To address these gaps, we conduct the first large-scale study of TTS, spanning over thirty billion tokens generated using eight open-source LLMs (7B to 235B parameters), across four reasoning datasets. We observe three consistent trends: (1) no single TTS strategy universally dominates; (2) reasoning models exhibit distinct trace-quality patterns across problem difficulty and trace length, forming short-horizon and long-horizon categories; and (3) for a given model type, the optimal TTS performance scales monotonically with compute budget. Based on these insights, we provide a practical recipe for selecting the best TTS strategy, considering problem difficulty, model type, and compute budget, providing a practical guide to effective inference-time scaling.

</details>


### [76] [Four Over Six: More Accurate NVFP4 Quantization with Adaptive Block Scaling](https://arxiv.org/abs/2512.02010)
*Jack Cook,Junxian Guo,Guangxuan Xiao,Yujun Lin,Song Han*

Main category: cs.CL

TL;DR: 4/6算法通过改进NVFP4量化中的缩放因子选择，显著缓解了大语言模型训练中的发散问题，提升了模型的训练稳定性和推理性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模增大，低精度数值格式如NVFP4因其速度和内存优势越来越受欢迎，但直接将权重和激活量化为NVFP4会导致训练发散和推理性能下降。

Method: 提出Four Over Six (4/6)算法，对每个数值块评估两个潜在的缩放因子，以改进NVFP4量化算法。该方法针对浮点格式在接近最大值时的量化误差进行优化，通过缩小FP4值的缩放，使得可表示值的分布更加均匀。

Result: 在预训练实验中，4/6方法避免了多次训练发散，使训练损失更接近BF16训练结果，并且可有效集成于多种后训练量化方法中，提升下游任务的准确率。

Conclusion: 4/6为使用NVFP4进行训练和推理提供了一种高效且有效的解决方案，适用于多种模型结构和量化方法，推动了低精度训练技术的发展。

Abstract: As large language models have grown larger, low-precision numerical formats such as NVFP4 have become increasingly popular due to the speed and memory benefits they provide. However, to accelerate computation with NVFP4, all matrix multiplication operands--weights and activations in the forward pass, and weights, activations, and gradients in the backward pass--must be quantized to NVFP4, often leading to divergence during training and performance degradation during inference. NVFP4 by evaluating multiple potential scale factors for each block of values. To address this issue, in this work we introduce Four Over Six (4/6), a modification to the NVFP4 quantization algorithm that evaluates two potential scale factors for each block of values. Unlike integer formats, floating-point formats such as FP4 have the most quantization error on near-maximal values in each block, which we find to be primarily responsible for downstream performance degradation. We find that for some blocks, scaling to smaller FP4 values makes the distribution of representable values more uniform, improving representation of near-maximal values. Importantly, 4/6 can be implemented efficiently on NVIDIA Blackwell GPUs, making it viable to use while training LLMs with NVFP4. In pre-training experiments with transformer and hybrid model architectures, we find that 4/6 prevents divergence in several cases, bringing training loss significantly closer to BF16 compared to models trained with current state-of-the-art NVFP4 training recipes. We also find that 4/6 can be easily incorporated into many different post-training quantization methods and generally improves downstream accuracy. We hope this inspires future work in training and deploying models with NVFP4.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [77] [Toward a Safe Internet of Agents](https://arxiv.org/abs/2512.00520)
*Juan A. Wibowo,George C. Polyzos*

Main category: cs.MA

TL;DR: 本文提出了一个关于自主代理系统架构安全性的框架，分析了单个代理、多代理系统和可互操作多代理系统三个层级的安全风险，强调安全应作为架构设计的核心原则。


<details>
  <summary>Details</summary>
Motivation: 随着基于大型语言模型的自主代理推动"智能代理互联网"的发展，虽然潜力巨大，但也带来了新的系统性安全风险，因此需要从架构层面识别漏洞，指导安全设计。

Method: 采用自下而上的方法，将每个代理系统组件视为双重用途接口，分别分析单代理、多代理系统以及可互操作多代理系统三个复杂度层级的核心架构组件及其安全风险。

Result: 通过对不同层级代理系统架构的安全风险分析，明确了安全应作为设计原则嵌入架构中，并提出了相应的安全缓解方法，为安全可靠的智能代理系统建设奠定了基础。

Conclusion: 自主代理系统的安全性应被视为一种架构原则，通过识别各层级的具体漏洞并制定相应的缓解策略，可构建安全可靠的智能代理系统，从而实现安全可信的"智能代理互联网"。

Abstract: Background: Autonomous agents powered by Large Language Models (LLMs) are driving a paradigm shift toward an "Internet of Agents" (IoA). While offering immense potential, this vision also introduces novel and systemic risks to safety and security. Objectives: Unlike common threat-centric taxonomies, our survey provides a principled, architectural framework for engineering safe and reliable agentic systems. We aim to identify the architectural sources of vulnerabilities to establish a foundation for secure design. Methods: We perform a bottom-up deconstruction of agentic systems, treating each component as a dual-use interface. The analysis spans three levels of complexity: the foundational Single Agent, the collaborative Multi-Agent System (MAS), and the visionary Interoperable Multi-Agent System (IMAS). At each level, we identify core architectural components and their inherent security risks. Results & Conclusions: Our central finding is that agentic safety is an architectural principle, not an add-on. By identifying specific vulnerabilities and deriving mitigation principles at each level of the agentic stack, this survey serves as a foundational guide for building the capable, safe, and trustworthy AI needed to realize a secure Internet of Agents.

</details>


### [78] [AgentODRL: A Large Language Model-based Multi-agent System for ODRL Generation](https://arxiv.org/abs/2512.00602)
*Wanle Zhong,Keman Huang,Xiaoyong Du*

Main category: cs.MA

TL;DR: 本研究通过多代理系统和语法语义增强方法，解决了自然语言向ODRL复杂规则自动翻译的难题，显著提升了翻译的效率和准确度。


<details>
  <summary>Details</summary>
Motivation: 当前授权政策的逻辑复杂性及缺乏高质量的自然语言到ODRL的训练数据，限制了自动翻译复杂规则的效率和准确性。

Method: 提出AgentODRL多代理系统，采用Orchestrator-Workers架构，包括生成器、分解器和重写器，动态协调工作流程，并引入语法验证和语义反思机制提升生成策略。

Result: 在包含770个复杂案例的新数据集上，AgentODRL系统在ODRL语法和语义评分任务中表现出优越的翻译效率和准确性。

Conclusion: 基于多代理架构和语法语义增强策略的AgentODRL系统有效提升了自然语言到ODRL自动翻译的质量和自动化水平。

Abstract: The Open Digital Rights Language (ODRL) is a pivotal standard for automating data rights management. However, the inherent logical complexity of authorization policies, combined with the scarcity of high-quality "Natural Language-to-ODRL" training datasets, impedes the ability of current methods to efficiently and accurately translate complex rules from natural language into the ODRL format. To address this challenge, this research leverages the potent comprehension and generation capabilities of Large Language Models (LLMs) to achieve both automation and high fidelity in this translation process. We introduce AgentODRL, a multi-agent system based on an Orchestrator-Workers architecture. The architecture consists of specialized Workers, including a Generator for ODRL policy creation, a Decomposer for breaking down complex use cases, and a Rewriter for simplifying nested logical relationships. The Orchestrator agent dynamically coordinates these Workers, assembling an optimal pathway based on the complexity of the input use case. Specifically, we enhance the ODRL Generator by incorporating a validator-based syntax strategy and a semantic reflection mechanism powered by a LoRA-finetuned model, significantly elevating the quality of the generated policies. Extensive experiments were conducted on a newly constructed dataset comprising 770 use cases of varying complexity, all situated within the context of data spaces. The results, evaluated using ODRL syntax and semantic scores, demonstrate that our proposed Orchestrator-Workers system, enhanced with these strategies, achieves superior performance on the ODRL generation task.

</details>


### [79] [Hierarchical Decentralized Multi-Agent Coordination with Privacy-Preserving Knowledge Sharing: Extending AgentNet for Scalable Autonomous Systems](https://arxiv.org/abs/2512.00614)
*Goutham Nalagatla*

Main category: cs.MA

TL;DR: AgentNet++是一种改进的层级去中心化多智能体系统，克服了AgentNet的可扩展性、通信开销和隐私问题，实现更高任务完成率和更强隐私保护。


<details>
  <summary>Details</summary>
Motivation: 现有AgentNet虽实现了去中心化协调，但存在可扩展性差、通信负担重、隐私保护不足和资源分配不佳等问题，难以支持大规模多智能体系统的高效协作。

Method: 采用基于集群的多级层级结构组织智能体，自组织形成专门团队，结合差分隐私和安全聚合实现隐私保护知识共享，配合自适应资源管理机制优化资源利用，同时提供理论上的收敛性和隐私界证明。

Result: 本文提出了AgentNet++，一个基于AgentNet的层级去中心化多智能体系统框架，通过多级代理组织、差分隐私及安全聚合实现隐私保护知识共享，采用自适应资源管理解决了AgentNet在大规模智能体群体中的可扩展性、通信开销和隐私保障不足等问题。AgentNet++引入基于集群的层级结构，实现任务高效路由和知识蒸馏，并提供了收敛性和隐私界的理论分析。实验表明，AgentNet++在复杂多智能体任务中较AgentNet提升23%的任务完成率，并减少40%的通信开销，同时保持强隐私保障，且支持规模超过1000个智能体的高效扩展。

Conclusion: AgentNet++通过引入层级组织和隐私保护机制，有效提升了多智能体系统的性能和隐私保障，且具备良好的可扩展性和理论收敛保证。

Abstract: Decentralized multi-agent systems have shown promise in enabling autonomous collaboration among LLM-based agents. While AgentNet demonstrated the feasibility of fully decentralized coordination through dynamic DAG topologies, several limitations remain: scalability challenges with large agent populations, communication overhead, lack of privacy guarantees, and suboptimal resource allocation. We propose AgentNet++, a hierarchical decentralized framework that extends AgentNet with multilevel agent organization, privacy-preserving knowledge sharing via differential privacy and secure aggregation, adaptive resource management, and theoretical convergence guarantees. Our approach introduces cluster-based hierarchies where agents self-organize into specialized groups, enabling efficient task routing and knowledge distillation while maintaining full decentralization. We provide formal analysis of convergence properties and privacy bounds, and demonstrate through extensive experiments on complex multi-agent tasks that AgentNet++ achieves 23% higher task completion rates, 40% reduction in communication overhead, and maintains strong privacy guarantees compared to AgentNet and other baselines. Our framework scales effectively to 1000+ agents while preserving the emergent intelligence properties of the original AgentNet.

</details>


### [80] [Augmented Runtime Collaboration for Self-Organizing Multi-Agent Systems: A Hybrid Bi-Criteria Routing Approach](https://arxiv.org/abs/2512.00740)
*Qingwen Yang,Feiyu Qu,Tiezheng Guo,Yanyi Liu,Yingyou Wen*

Main category: cs.MA

TL;DR: 本文提出BiRouter，一种基于双指标和动态声誉的多智能体自主路由方法，提升了分布式系统的任务协作效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体协作策略依赖静态拓扑和集中式全局规划，限制了其在开放分布式网络中的扩展性和适应性，因此需要一种仅用局部信息即可有效规划协作的新方法。

Method: 提出了一种基于双重指标的自主路由方法BiRouter，结合ImpScore和GapScore两种评价指标来指导智能体的“下一跳”任务路由决策，并引入动态声誉机制增强系统在不可信环境下的稳定性。

Result: BiRouter在大规模跨领域数据集上的实验显示，其在任务性能、代币效率以及系统鲁棒性方面均优于现有基线方法，且适应于信息受限和去中心化的环境中。

Conclusion: 本文提出的BiRouter方法在自组织多智能体系统中，通过仅依赖局部信息实现了自主的任务路由，显著提升了系统的性能和效率，且具备良好的鲁棒性和适应性。

Abstract: LLM-based multi-agent systems have demonstrated significant capabilities across diverse domains. However, the task performance and efficiency are fundamentally constrained by their collaboration strategies. Prevailing approaches rely on static topologies and centralized global planning, a paradigm that limits their scalability and adaptability in open, decentralized networks. Effective collaboration planning in distributed systems using only local information thus remains a formidable challenge. To address this, we propose BiRouter, a novel dual-criteria routing method for Self-Organizing Multi-Agent Systems (SO-MAS). This method enables each agent to autonomously execute ``next-hop'' task routing at runtime, relying solely on local information. Its core decision-making mechanism is predicated on balancing two metrics: (1) the ImpScore, which evaluates a candidate agent's long-term importance to the overall goal, and (2) the GapScore, which assesses its contextual continuity for the current task state. Furthermore, we introduce a dynamically updated reputation mechanism to bolster system robustness in untrustworthy environments and have developed a large-scale, cross-domain dataset, comprising thousands of annotated task-routing paths, to enhance the model's generalization. Extensive experiments demonstrate that BiRouter achieves superior performance and token efficiency over existing baselines, while maintaining strong robustness and effectiveness in information-limited, decentralized, and untrustworthy settings.

</details>


### [81] [Chain of Unit-Physics: A Primitive-Centric Approach to Scientific Code Synthesis](https://arxiv.org/abs/2512.01010)
*Vansh Sharma,Venkat Raman*

Main category: cs.MA

TL;DR: 提出基于第一性原理的多智能体代码生成框架，提高科学计算代码生成的准确性和效率，克服了当前大模型的多种错误。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在科学计算代码生成中因训练中领域代码稀疏和专家社区规模小导致的强化学习有限，可靠性不足。

Method: 提出Chain of Unit-Physics框架，基于第一性原理的多智能体系统，将人类专家知识编码为单位物理测试以约束代码生成。

Result: 在燃烧任务基准测试中，闭源和代码聚焦模型未能生成正确解算器，开源模型虽减少接口错误仍不准确。提出框架在5-6次迭代内收敛，误差仅为$3.1\times10^{-3}$%，运行速度提升约33.4%，内存使用效率提升30%。

Conclusion: Chain of Unit-Physics框架有效融合了专家知识和物理约束，提升了高风险科学计算代码生成的可靠性和效率，具备实际应用潜力。

Abstract: Agentic large language models are proposed as autonomous code generators for scientific computing, yet their reliability in high-stakes problems remains unclear. Developing computational scientific software from natural-language queries remains challenging broadly due to (a) sparse representation of domain codes during training and (b) the limited feasibility of RLHF with a small expert community. To address these limitations, this work conceptualizes an inverse approach to code design, embodied in the Chain of Unit-Physics framework: a first-principles (or primitives)-centric, multi-agent system in which human expert knowledge is encoded as unit-physics tests that explicitly constrain code generation. The framework is evaluated on a nontrivial combustion task, used here as a representative benchmark for scientific problem with realistic physical constraints. Closed-weight systems and code-focused agentic variants fail to produce correct end-to-end solvers, despite tool and web access, exhibiting four recurrent error classes: interface (syntax/API) hallucinations, overconfident assumptions, numerical/physical incoherence, and configuration fragility. Open-weight models with chain-of-thought (CoT) decoding reduce interface errors but still yield incorrect solutions. On the benchmark task, the proposed framework converges within 5-6 iterations, matches the human-expert implementation (mean error of $3.1\times10^{-3}$ %), with a $\sim$33.4 % faster runtime and a $\sim$30 % efficient memory usage at a cost comparable to mid-sized commercial APIs, yielding a practical template for physics-grounded scientific code generation. As datasets and models evolve, zero-shot code accuracy will improve; however, the Chain of Unit-Physics framework goes further by embedding first-principles analysis that is foundational to scientific codes.

</details>


### [82] [SocialDriveGen: Generating Diverse Traffic Scenarios with Controllable Social Interactions](https://arxiv.org/abs/2512.01363)
*Jiaguo Tian,Zhengbang Zhu,Shenyu Zhang,Li Xu,Bo Zheng,Xu Liu,Weiji Peng,Shizeng Yao,Weinan Zhang*

Main category: cs.MA

TL;DR: SocialDriveGen通过模拟驾驶者的自我主义和利他主义，生成高保真且多样的交通场景，增强自动驾驶策略的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有交通场景生成方法多依赖规则或简化模型，缺乏真实世界驾驶多样性与社交偏好影响的体现，限制了自动驾驶系统的训练与评估效果。

Method: 构建分层生成框架，结合语义推理和社会偏好（自我主义与利他主义）建模，通过生成轨迹合成实现驾驶行为多样性和可控性。

Result: 提出了SocialDriveGen，一个整合语义推理和社会偏好建模的分层生成框架，用于生成真实多样的交通场景，从而提升自动驾驶系统的开发与评估。

Conclusion: SocialDriveGen成功在Argoverse 2数据集上生成涵盖合作到对抗性驾驶行为的多样化高保真场景，显著提升了自动驾驶策略在罕见和高风险情形下的表现。

Abstract: The generation of realistic and diverse traffic scenarios in simulation is essential for developing and evaluating autonomous driving systems. However, most simulation frameworks rely on rule-based or simplified models for scene generation, which lack the fidelity and diversity needed to represent real-world driving. While recent advances in generative modeling produce more realistic and context-aware traffic interactions, they often overlook how social preferences influence driving behavior. SocialDriveGen addresses this gap through a hierarchical framework that integrates semantic reasoning and social preference modeling with generative trajectory synthesis. By modeling egoism and altruism as complementary social dimensions, our framework enables controllable diversity in driver personalities and interaction styles. Experiments on the Argoverse 2 dataset show that SocialDriveGen generates diverse, high-fidelity traffic scenarios spanning cooperative to adversarial behaviors, significantly enhancing policy robustness and generalization to rare or high-risk situations.

</details>


### [83] [Agent-Kernel: A MicroKernel Multi-Agent System Framework for Adaptive Social Simulation Powered by LLMs](https://arxiv.org/abs/2512.01610)
*Yuren Mao,Peigen Liu,Xinjian Wang,Rui Ding,Jing Miao,Hui Zou,Mingjie Qi,Wanxiang Luo,Longbin Lai,Kai Wang,Zhengping Qian,Peilun Yang,Yunjun Gao,Ying Zhang*

Main category: cs.MA

TL;DR: 本文提出了基于社会中心的模块化微内核架构的Agent-Kernel框架，解决了现有多智能体系统开发框架在适应性、可配置性、可靠性和代码重用性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统框架无法支持大规模且动态变化的社会仿真，缺乏灵活性和可靠性，难以应对复杂的社会模拟需求。

Method: 采用社会中心的模块化微内核架构，解耦核心系统功能与模拟逻辑，分离认知过程与物理环境及行动执行。

Result: 成功实现了宇宙25号实验的快速人口动态模拟及浙江大学校园生活的1万智能体异构仿真，验证了框架的实用性和优越性能。

Conclusion: Agent-Kernel框架通过解耦系统核心功能和模拟逻辑，实现了优越的适应性、可配置性、可靠性与重用性，且在两个不同的仿真实验中得到验证。

Abstract: Multi-Agent System (MAS) developing frameworks serve as the foundational infrastructure for social simulations powered by Large Language Models (LLMs). However, existing frameworks fail to adequately support large-scale simulation development due to inherent limitations in adaptability, configurability, reliability, and code reusability. For example, they cannot simulate a society where the agent population and profiles change over time. To fill this gap, we propose Agent-Kernel, a framework built upon a novel society-centric modular microkernel architecture. It decouples core system functions from simulation logic and separates cognitive processes from physical environments and action execution. Consequently, Agent-Kernel achieves superior adaptability, configurability, reliability, and reusability. We validate the framework's superiority through two distinct applications: a simulation of the Universe 25 (Mouse Utopia) experiment, which demonstrates the handling of rapid population dynamics from birth to death; and a large-scale simulation of the Zhejiang University Campus Life, successfully coordinating 10,000 heterogeneous agents, including students and faculty.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [84] [Injecting Sustainability in Software Architecture: A Rapid Review](https://arxiv.org/abs/2512.00106)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 本文通过文献综述和行业焦点小组，研究了在软件架构设计中实现可持续性的挑战与机遇，提出了五条具体实施建议。


<details>
  <summary>Details</summary>
Motivation: 随着可持续性成为软件设计和运营的核心责任，研究旨在探索如何将可持续性系统性地整合到现有软件工程实践中。

Method: 采用混合研究方法，包括对二次研究的快速文献综述和从业者焦点小组讨论，以识别并验证在软件架构中实现可持续性的挑战与机遇。

Result: 文献综述和行业实践相结合，揭示了在软件架构中嵌入可持续性的关键挑战和机会，进而总结出五条具体指导建议。

Conclusion: 本文通过实证研究表明，可持续性能够系统地融入软件架构设计中，提出了五个具体建议以指导软件架构师实践。

Abstract: Sustainability has evolved from an emerging concern into a fundamental responsibility in software design, development, and operation. Research increasingly explores how sustainability can be systematically integrated into existing software engineering practices. Building on an industry-academia collaboration, we contribute to this discourse by conducting a mixed-method empirical study. We combine a rapid review of secondary studies with a focus group of practitioners. The review identifies challenges and opportunities in embedding sustainability in software architecture, while the focus group enriches and compares these findings. Based on the literature and industry synthesis, we derive five tangible takeaways to inform architects working in the field, and to guide our industry partners in the integration of sustainability concerns in architecture practices.

</details>


### [85] [Generating Verifiable CoT from Execution-Traces](https://arxiv.org/abs/2512.00127)
*Shailja Thakur,Vaibhav Saxena,Rohan Kulkarni,Shivdeep Singh,Parameswaran Selvam,Hima Patel,Hiroshi Kanayama*

Main category: cs.SE

TL;DR: 通过基于代码执行轨迹的自然语言推理训练，显著提升语言模型在代码推理及生成任务中的性能，解决了传统CoT推理逻辑错误的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的Chain-of-Thought (CoT) 训练数据依赖教师模型生成的推理步骤，缺乏代码执行的真实验证，导致模型学习到表面合理但逻辑错误的推理模式。

Method: 通过工具对代码进行动态行为追踪，捕获执行轨迹，并将这些轨迹转化为自然语言的推理理由，确保每个推理步骤都基于程序实际计算结果，实现执行轨迹与推理过程的绑定。

Result: 在多个代码推理和生成任务（CruxEval, LiveCodeBench-Exec, HumanEval）中，基于执行轨迹训练的模型相比基础模型在输出预测和输入预测上分别提升了高达30分和28分，同时在代码解释和生成能力上也获得显著进步。

Conclusion: 基于可验证的代码执行轨迹生成的推理步骤，有效消除了逻辑幻想，显著增强了语言模型的代码推理与生成能力，证明了验证推理对模型性能的根本提升作用。

Abstract: Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.
  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT

</details>


### [86] [Asm2SrcEval: Evaluating Large Language Models for Assembly-to-Source Code Translation](https://arxiv.org/abs/2512.00134)
*Parisa Hamedi,Hamed Jelodar,Samita Bai,Mohammad Meymani,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.SE

TL;DR: 首次系统评估五种大语言模型在汇编到源代码翻译上的表现，揭示各模型在准确性与效率之间的权衡，为未来提高模型表现提供基础。


<details>
  <summary>Details</summary>
Motivation: 缺乏系统性的基准评测来评估大语言模型在汇编到源代码翻译任务上的表现。

Method: 对五种先进大语言模型进行汇编到源代码翻译的评估，使用包括BLEU、ROUGE、METEOR、BERTScore、困惑度和推理时间等多种指标。

Result: 发现不同模型在文本相似度、语言流畅度和推理效率上存在权衡，且模型在控制流恢复和标识符重建等方面存在挑战。

Conclusion: 本基准为大语言模型在程序翻译任务中的优势和不足提供了深入见解，推动将准确性与效率结合应用于现实场景的研究。

Abstract: Assembly-to-source code translation is a critical task in reverse engineering, cybersecurity, and software maintenance, yet systematic benchmarks for evaluating large language models on this problem remain scarce. In this work, we present the first comprehensive evaluation of five state-of-the-art large language models on assembly-to-source translation. We assess model performance using a diverse set of metrics capturing lexical similarity (BLEU, ROUGE, and METEOR), semantic alignment (BERTScore), fluency (Perplexity), and efficiency (time prediction). Our results reveal clear trade-offs: while certain models excel in text similarity metrics, others demonstrate lower perplexity or faster inference times. We further provide qualitative analyses of typical model successes and failure cases, highlighting challenges such as control flow recovery and identifier reconstruction. Taken together, our benchmark offers actionable insights into the strengths and limitations of current large language models for program translation, establishing a foundation for future research in combining accuracy with efficiency for real-world applications.

</details>


### [87] [Demystifying Errors in LLM Reasoning Traces: An Empirical Study of Code Execution Simulation](https://arxiv.org/abs/2512.00215)
*Mohammad Abdollahi,Khandaker Rifah Tasnia,Soumit Kanti Saha,Jinqiu Yang,Song Wang,Hadi Hemmati*

Main category: cs.SE

TL;DR: 本文首次对推理型大型语言模型（LLMs）的运行时推理行为进行了实证研究，分析了代码推理中的错误类型，并提出了工具增强推理方法，提高了模型对计算错误的纠正率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs的输出准确率，对其推理过程缺乏理解和分析，导致无法深入发现推理错误及其结构，影响代码生成和自动推理的可靠性。

Method: 构建包含427段代码并涵盖常规、边缘和无效输入的基准测试，通过实测四种顶尖推理型LLMs的表现，分析推理轨迹并归纳推理错误分类，最后以计算错误为例引入工具辅助推理方法进行纠正实验。

Result: LLMs在不同输入类型下准确率介于85%至98%，归纳出包括计算错误在内的九类推理错误；利用工具辅助方法能修正约58%的计算错误，展示出工具增强推理的潜力。

Conclusion: 推理型LLMs在推理准确率上表现良好，但存在多种推理错误类型。通过工具增强推理可以有效减少计算错误，提升推理质量。

Abstract: Understanding a program's runtime reasoning behavior, meaning how intermediate states and control flows lead to final execution results, is essential for reliable code generation, debugging, and automated reasoning. Although large language models (LLMs) can accurately predict program outputs, most prior work has focused on output accuracy and performance, treating reasoning as a black box. As a result, little is known about the structure or failure modes of their reasoning traces. To address this gap, we conduct the first empirical study on runtime behavior inference with reasoning LLMs, aiming to uncover and characterize errors in their reasoning traces. We curate a benchmark from HumanEval Plus and LiveCodeBench, containing 427 code snippets. For each snippet, we test three input types: regular, edge, and invalid. Twelve input values are selected per snippet, each paired with its ground-truth execution result. We evaluate four state-of-the-art reasoning LLMs. Our results show that these models reach accuracies between 85 percent and 98 percent across input types. We also analyze the produced reasoning traces and develop a taxonomy with nine categories of inference errors. Finally, we explore tool-augmented reasoning. Using failures in the Computation Errors category as a case study, our experiments show that this approach corrects 58 percent of such errors, demonstrating the potential of tool support for improving LLM reasoning.

</details>


### [88] [CodeFlowLM: Incremental Just-In-Time Defect Prediction with Pretrained Language Models and Exploratory Insights into Defect Localization](https://arxiv.org/abs/2512.00231)
*Monique Louise Monteiro,George G. Cabral,Adriano L. I. OLiveira*

Main category: cs.SE

TL;DR: 本研究提出了CodeFlowLM，利用预训练语言模型进行增量学习，在JIT软件缺陷预测中表现优异；同时评估并分析了大型语言模型在缺陷定位中的性能及限制。


<details>
  <summary>Details</summary>
Motivation: 提升软件缺陷预测的及时性和准确性，解决传统在线学习方法的局限，推动缺陷定位技术发展。

Method: 利用预训练语言模型进行增量学习，通过持续微调解决概念漂移、类别不平衡和验证延迟问题，并比较多种模型性能。

Result: CodeFlowLM相比基线模型在G-Mean指标上提升达68%。GPT-5在缺陷定位的Recall@20%和Effort@20%表现稳定，但细粒度排名指标仍由传统方法占优。错误分析指出假阳性主要源于保守偏见、上下文信息不足和数据集标注问题。

Conclusion: CodeFlowLM在增量Just-In-Time软件缺陷预测中表现出色，显著提升了适应性和鲁棒性。大型语言模型在缺陷定位中表现具有潜力，但存在局限性。

Abstract: This work introduces CodeFlowLM, an incremental learning framework for Just-In-Time Software Defect Prediction (JIT-SDP) that leverages pre-trained language models (PLMs). Unlike traditional online learners, CodeFlowLM employs continual fine-tuning to address concept drift, class imbalance, and verification latency without retraining from scratch. We evaluated encoder-only and encoder-decoder PLMs (notably CodeT5+ and UniXCoder) in JIT-SDP scenarios within and between projects, comparing them with the incremental baseline BORB. The results show that CodeFlowLM achieves up to 68% G-Mean gains, confirming its superior adaptability and robustness in evolving software environments. We further extend the analysis to Just-in-Time Defect Localization (JIT-DL), benchmarking Large Language Models (LLMs) such as GPT-5, Claude Sonnet 4.5, and Gemini 2.5 Pro against attention-based models. GPT-5 delivers comparable performance for Recall@20% and Effort@20% with higher stability, although attention-based methods retain an advantage in fine-grained ranking metrics (Top-k, IFA). A qualitative error analysis reveals that most false positives arise from (1) human-like conservative bias, (2) insufficient contextual information in diff-based prompts, and (3) potential dataset mislabeling in JIT-Defects4J. These findings highlight both the promise and the current limitations of LLM reasoning in defect localization. False negatives occur in smaller proportions. Overall, CodeFlowLM significantly advances the state of the art in incremental JIT-SDP, demonstrating superior adaptability and robustness in evolving software environments. Furthermore, our exploratory analysis of LLMs in JIT-DL not only benchmarks their performance against established attention-based models but also provides critical insights into the current limitations of prompt-based defect reasoning.

</details>


### [89] [ng-reactive-lint: Smarter Linting for Angular Apps](https://arxiv.org/abs/2512.00250)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.SE

TL;DR: 开发了针对Angular的静态分析工具ng-reactive-lint，有效检测和修复反应性误用，显著降低变更检测次数和内存使用，助力现代反应性实践推广。


<details>
  <summary>Details</summary>
Motivation: Angular应用中反应性误用导致性能下降难以诊断，且大量遗留代码仍依赖旧的RxJS模式，造成更新不可预测、内存泄漏和过多变更检测。

Method: 开发了ng-reactive-lint，这是一款理解Angular组件语义、生命周期钩子、模板绑定及反应性模式的确定性静态分析工具，进行框架感知分析，检测高影响的反模式并提供上下文相关的修复建议。

Result: 在五个大型真实项目中，减少了多达三倍的不必要变更检测周期，峰值内存使用降低了75%。

Conclusion: ng-reactive-lint为大规模采用现代Angular反应性提供了实用且自动化的路径，显著提升了性能和资源使用效率。

Abstract: Reactivity is central to Angular applications, yet subtle misuse of Observables, Signals, and change-detection often leads to performance regressions that are difficult to diagnose. Although Angular 17 introduced a unified, signal-first model, most enterprise codebases still rely heavily on legacy RxJS patterns that create unpredictable update flows, memory leaks, and excessive change cycles. To address these issues, we developed ng-reactive-lint, a deterministic static analysis tool that understands Angular's component semantics, lifecycle hooks, template bindings, and reactivity patterns. Unlike generic ESLint or RxJS plugins, ng-reactive-lint performs framework-aware analysis to detect high-impact anti-patterns and provide actionable, context-specific fixes. Evaluation across five large real-world projects showed reductions of up to threefold in unnecessary change detection cycles and up to 75% lower peak memory usage. The tool offers a practical, automated path to adopting modern Angular reactivity at scale.

</details>


### [90] [Progressive Code Integration for Abstractive Bug Report Summarization](https://arxiv.org/abs/2512.00325)
*Shaira Sadia Karim,Abrar Mahmud Rahim,Lamia Alam,Ishmam Tashdeed,Lutfun Nahar Lota,Md. Abu Raihan M. Kamal,Md. Azam Hossain*

Main category: cs.SE

TL;DR: 该论文提出了一种渐进式集成代码片段和文本内容的LLM错误报告摘要方法，有效提升摘要质量和错误理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的错误报告通常结构松散且冗长，开发人员难以高效理解软件问题。现有的总结方法依赖表层文本线索，导致摘要不完整或冗余，且忽视了关键的代码片段，这对准确诊断缺陷至关重要。

Method: 提出了一种基于大语言模型（LLM）的渐进式代码集成框架，用于抽象性的错误报告摘要。该方法逐步将长代码片段与文本内容结合，突破了LLM的上下文窗口限制，生成语义丰富的摘要。

Result: 在四个基准数据集和八个大语言模型上评估，该方法相比抽取式基线提高了7.5%至58.2%，并实现了与最先进抽象方法相当的表现。

Conclusion: 联合利用文本与代码信息能够显著提升错误报告的理解效率，证明了该渐进式代码集成框架在错误报告摘要中的有效性。

Abstract: Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.

</details>


### [91] [Framework-Aware Code Generation with API Knowledge Graph-Constructed Data: A Study on HarmonyOS](https://arxiv.org/abs/2512.00380)
*Mingwei Liu,Zheng Pei,Yanlin Wang,Zihao Wang,Zikang Li,Enci Lin,Xin Peng,Zibin Zheng*

Main category: cs.SE

TL;DR: 针对大型语言模型在低资源软件框架中代码生成效果差的问题，提出APIKG4SYN框架，利用API知识图谱构建训练数据，微调模型后显著提升了代码生成准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在针对资源受限的软件框架（如HarmonyOS）生成代码时表现较差，主要由于预训练时缺乏针对特定框架API和语法的知识，导致生成代码频繁出错，需设计方法提升其框架特异性的代码生成能力。

Method: 提出APIKG4SYN框架，利用不依赖可执行代码的API知识图谱，通过单API和多API结合的方式，采用基于不确定性估计驱动的蒙特卡洛树搜索生成多样且信息丰富的数据集，用于微调大型语言模型。

Result: 基于HarmonyOS构建了首个HarmonyOS代码生成基准，微调Qwen模型后，pass@1准确率由基线模型的17.59%提升至25.00%，显著提高了代码生成的准确性。

Conclusion: APIKG4SYN框架通过利用API知识图谱生成针对低资源软件框架的问答代码对，显著提升了大型语言模型在特定框架代码生成任务中的表现，实验证明其在HarmonyOS代码生成上的有效性。

Abstract: In the context of software frameworks with limited resources (such as HarmonyOS), large language models (LLMs) often exhibit poor code generation performance because they lack sufficient exposure to such environments during pre-training. Although LLMs can usually maintain correct logical structures across programming languages, they frequently struggle when dealing with framework-specific APIs or syntax, resulting in errors. This indicates that while pre-training equips LLMs with general algorithmic capabilities, they remain unfamiliar with the distinctive syntax and API usage of underrepresented frameworks. As a result, even advanced commercial models like GPT-4o cannot reliably generate correct code without prior adaptation. To address this issue, we propose APIKG4SYN, a framework designed to exploit API knowledge graphs for the construction of API-oriented question-code pairs, specifically tailored for low-resource frameworks without requiring executable code. APIKG4SYN integrates both single-API and multi-API knowledge, where the latter is derived through uncertainty estimation (UE)-driven Monte Carlo Tree Search (MCTS), enabling the creation of a diverse and informative dataset for fine-tuning LLMs. Using HarmonyOS as a case study, we build the first benchmark for HarmonyOS code generation. Experimental results show that fine-tuning Qwen with APIKG4SYN raises pass@1 accuracy to 25.00%, compared with 17.59% for the baseline GPT model. These results confirm that API-oriented data significantly enhance LLM performance in low-resource software development scenarios.

</details>


### [92] [Bias Testing and Mitigation in Black Box LLMs using Metamorphic Relations](https://arxiv.org/abs/2512.00556)
*Sina Salimian,Gias Uddin,Sumon Biswas,Henry Leung*

Main category: cs.SE

TL;DR: 通过六种新颖的变形关系，自动检测并缓解大语言模型中的隐性社会偏见，显著提升模型公平性和安全响应能力。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的防护措施在面对间接或语境复杂的偏见诱导提示时常常失效，难以系统评估和有效缓解模型中的隐含社会偏见。

Method: 提出了基于变形测试原理的六种新型变形关系（Metamorphic Relations, MRs），通过将直接引发偏见的输入转化为语义等价但在对抗性上更具挑战性的变体，自动检测模型中的隐性偏见。该方法同时生成多样化的偏见引发样本，用于对模型进行微调以缓解偏见。

Result: 使用六个先进的大语言模型和BiasAsker基准测试集的部分问卷，该方法比现有工具发现了多达14%的隐藏偏见。同时，通过对原始及变形关系生成的样本进行微调，模型的安全响应率显著提升，从54.7%提高到88.9%以上。

Conclusion: 变形关系是一种有效且实用的机制，能系统检测和缓解大语言模型在多样化语境下的隐性偏见，促进对话式AI的公平性提升。

Abstract: The widespread deployment of Large Language Models (LLMs) has intensified concerns about subtle social biases embedded in their outputs. Existing guardrails often fail when faced with indirect or contextually complex bias-inducing prompts. To address these limitations, we propose a unified framework for both systematic bias evaluation and targeted mitigation. Our approach introduces six novel Metamorphic Relations (MRs) that, based on metamorphic testing principles, transform direct bias-inducing inputs into semantically equivalent yet adversarially challenging variants. These transformations enable an automated method for exposing hidden model biases: when an LLM responds inconsistently or unfairly across MR-generated variants, the underlying bias becomes detectable. We further show that the same MRs can be used to generate diverse bias-inducing samples for fine-tuning, directly linking the testing process to mitigation. Using six state-of-the-art LLMs - spanning open-source and proprietary models - and a representative subset of 385 questions from the 8,978-item BiasAsker benchmark covering seven protected groups, our MRs reveal up to 14% more hidden biases compared to existing tools. Moreover, fine-tuning with both original and MR-mutated samples significantly enhances bias resiliency, increasing safe response rates from 54.7% to over 88.9% across models. These results highlight metamorphic relations as a practical mechanism for improving fairness in conversational AI.

</details>


### [93] [SAGE: Semantic-Aware Gray-Box Game Regression Testing with Large Language Models](https://arxiv.org/abs/2512.00560)
*Jinyu Cai,Jialong Li,Nianyu Li,Zhenyu Mao,Mingyue Zhang,Kenji Tei*

Main category: cs.SE

TL;DR: 针对灰盒游戏测试难题，SAGE用大模型指导强化学习自动生成测试用例，结合语义多目标优化和更新日志分析，实现高效精准的回归测试。


<details>
  <summary>Details</summary>
Motivation: 现代在线服务游戏更新频繁，回归测试关键但现有方法在灰盒环境中面临测试用例构建人工依赖大、冗余多、测试用例优先级难定等限制，导致成本高、自动化低、缺陷检测不足。

Method: 使用LLM引导的强化学习进行探索生成测试用例，随后利用语义多目标优化方法精简测试集，最后基于LLM对更新日志的语义分析实现测试优先级排序。

Result: 提出SAGE框架，结合LLM引导的强化学习和语义多目标优化，实现自动生成多样化基础测试套件，优化成成本低、覆盖高的精简子集，并通过语义分析更新日志优先执行相关测试，显著提升缺陷检测能力和测试效率。

Conclusion: SAGE在Overcooked Plus和Minecraft环境中表现优异，显著降低测试成本并提升缺陷检测率，展示了强大的版本迭代适应能力。

Abstract: The rapid iteration cycles of modern live-service games make regression testing indispensable for maintaining quality and stability. However, existing regression testing approaches face critical limitations, especially in common gray-box settings where full source code access is unavailable: they heavily rely on manual effort for test case construction, struggle to maintain growing suites plagued by redundancy, and lack efficient mechanisms for prioritizing relevant tests. These challenges result in excessive testing costs, limited automation, and insufficient bug detection. To address these issues, we propose SAGE, a semanticaware regression testing framework for gray-box game environments. SAGE systematically addresses the core challenges of test generation, maintenance, and selection. It employs LLM-guided reinforcement learning for efficient, goal-oriented exploration to automatically generate a diverse foundational test suite. Subsequently, it applies a semantic-based multi-objective optimization to refine this suite into a compact, high-value subset by balancing cost, coverage, and rarity. Finally, it leverages LLM-based semantic analysis of update logs to prioritize test cases most relevant to version changes, enabling efficient adaptation across iterations. We evaluate SAGE on two representative environments, Overcooked Plus and Minecraft, comparing against both automated baselines and human-recorded test cases. Across all environments, SAGE achieves superior bug detection with significantly lower execution cost, while demonstrating strong adaptability to version updates.

</details>


### [94] [Enhancing Analogy-Based Software Effort Estimation with Firefly Algorithm Optimization](https://arxiv.org/abs/2512.00571)
*Tarun Chintada,Uday Kiran Cheera*

Main category: cs.SE

TL;DR: 本文提出了一种结合萤火虫算法的类比估计模型（FAABE），以提升软件项目估计的准确性。通过在多个公开数据集上的实验，结果显示该方法在多种误差指标上优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 现有类比估计方法缺乏最优策略，且在新软件项目上的准确性较低，亟需改进。

Method: 将萤火虫算法与类比估计结合，利用特征选择提升预测效率，并在五个公开数据集上进行测试和评估。

Result: 在Cocomo81、Desharnais等五个数据集上的实验显示，FAABE在MMRE、MAE、MSE和RMSE等指标上表现更佳，提高了估计的精度。

Conclusion: FAABE模型显著提高了软件估计的准确性，效果优于传统的类比估计方法。

Abstract: Analogy-Based Estimation (ABE) is a popular method for non-algorithmic estimation due to its simplicity and effectiveness. The Analogy-Based Estimation (ABE) model was proposed by researchers, however, no optimal approach for reliable estimation was developed. Achieving high accuracy in the ABE might be challenging for new software projects that differ from previous initiatives. This study (conducted in June 2024) proposes a Firefly Algorithm-guided Analogy-Based Estimation (FAABE) model that combines FA with ABE to improve estimation accuracy. The FAABE model was tested on five publicly accessible datasets: Cocomo81, Desharnais, China, Albrecht, Kemerer and Maxwell. To improve prediction efficiency, feature selection was used. The results were measured using a variety of evaluation metrics; various error measures include MMRE, MAE, MSE, and RMSE. Compared to conventional models, the experimental results show notable increases in prediction precision, demonstrating the efficacy of the Firefly-Analogy ensemble.

</details>


### [95] [Large Language Models for Software Engineering: A Reproducibility Crisis](https://arxiv.org/abs/2512.00651)
*Mohammed Latif Siddiq,Arvin Islam-Gomes,Natalie Sekerak,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 本文通过对640篇LLM相关软件工程论文的实证研究，系统分析了可重复性实践，发现依然存在代码、数据、环境、版本控制和文档等方面的不足，虽然近年有所改善，但评价标识不总能保证真正的可重复性。


<details>
  <summary>Details</summary>
Motivation: 可重复性是科学进步基础，但在基于大语言模型的软件工程研究中，其现状尚不明朗，因此需要实证评估该领域复现质量及其驱动因素。

Method: 从2017至2025年采集640篇论文，构建七大可重复性缺陷分类，手工标注论文与附属工件，通过定量分析复现不良现象及其变化趋势，并考察标识的有效性与发表渠道的影响。

Result: 发现可重复性存在持续缺陷，包括工件缺失、环境说明不足、版本控制不严和文档模糊，虽艺标识普遍存在但不能保证复现执行质量，顶级会议开展工件评估流程对复现有促进作用。

Conclusion: 尽管有一定改善和标识使用，LLM领域软件工程研究的可重复性依然存在显著不足，需要引入多维度的成熟度模型以提升复现质量。

Abstract: Reproducibility is a cornerstone of scientific progress, yet its state in large language model (LLM)-based software engineering (SE) research remains poorly understood. This paper presents the first large-scale, empirical study of reproducibility practices in LLM-for-SE research. We systematically mined and analyzed 640 papers published between 2017 and 2025 across premier software engineering, machine learning, and natural language processing venues, extracting structured metadata from publications, repositories, and documentation. Guided by four research questions, we examine (i) the prevalence of reproducibility smells, (ii) how reproducibility has evolved over time, (iii) whether artifact evaluation badges reliably reflect reproducibility quality, and (iv) how publication venues influence transparency practices. Using a taxonomy of seven smell categories: Code and Execution, Data, Documentation, Environment and Tooling, Versioning, Model, and Access and Legal, we manually annotated all papers and associated artifacts. Our analysis reveals persistent gaps in artifact availability, environment specification, versioning rigor, and documentation clarity, despite modest improvements in recent years and increased adoption of artifact evaluation processes at top SE venues. Notably, we find that badges often signal artifact presence but do not consistently guarantee execution fidelity or long-term reproducibility. Motivated by these findings, we provide actionable recommendations to mitigate reproducibility smells and introduce a Reproducibility Maturity Model (RMM) to move beyond binary artifact certification toward multi-dimensional, progressive evaluation of reproducibility rigor.

</details>


### [96] [Code Comments for Quantum Software Development Kits: An Empirical Study on Qiskit](https://arxiv.org/abs/2512.00766)
*Zenghui Zhou,Yuechen Li,Yi Cai,Jinlong Wen,Xiaohan Yu,Zheng Zheng,Beibei Yin*

Main category: cs.SE

TL;DR: 本文针对量子计算中的代码注释进行了系统性研究，提出了首个量子计算代码注释数据集CC4Q，并进行了详尽的人工标注和实证分析。


<details>
  <summary>Details</summary>
Motivation: 由于量子计算软件编程涉及非直观的量子机制，程序员理解和维护代码存在困难，且相关代码注释的重要性及其作用未被系统研究，本文旨在填补这一空白。

Method: 本文基于Qiskit开发环境构建了包含9677对代码注释的数据集CC4Q，并对21970条注释单元进行了人工标注。通过实证研究，从注释结构、开发者意图和量子相关主题三方面对代码注释进行了系统分析。

Result: 建立了首个量子计算代码注释数据集CC4Q，验证了经典软件中的开发者意图分类法的适用性，并提出了针对量子领域的新分类法，揭示了量子软件注释的特有特点和知识点。

Conclusion: 研究揭示了量子软件代码注释与传统软件的关键差异，提出了量子领域特有的注释意图分类法，为量子软件开发提供了有价值的参考和指导。

Abstract: Quantum computing is gaining attention from academia and industry. With the quantum Software Development Kits (SDKs), programmers can develop quantum software to explore the power of quantum computing. However, programmers may face challenges in understanding quantum software due to the non-intuitive quantum mechanics. To facilitate software development and maintenance, code comments offered in quantum SDKs serve as a natural language explanation of program functionalities and logical flows. Despite their importance, scarce research systematically reports their value and provides constructive guidelines for programmers. To address this gap, our paper focuses on Qiskit, one of the most popular quantum SDKs, and presents CC4Q, the first dataset of code comments for quantum computing. CC4Q incorporates 9677 code comment pairs and 21970 sentence-level code comment units, the latter of which involve heavy human annotation. Regarding the annotation, we validate the applicability of the developer-intent taxonomy used in classical programs, and also propose a new taxonomy considering quantum-specific knowledge. We conduct an empirical study comprehensively interpreting code comments from three perspectives: comment structure and coverage, developers' intentions, and associated quantum topics. Our findings uncover key differences in code comments between classical and quantum software, and also outline quantum-specific knowledge relevant to quantum software development.

</details>


### [97] [FC-ADL: Efficient Microservice Anomaly Detection and Localisation Through Functional Connectivity](https://arxiv.org/abs/2512.00844)
*Giles Winchester,George Parisis,Luc Berthouze*

Main category: cs.SE

TL;DR: 提出基于功能连接的微服务异常检测定位方法，性能优越且可扩展。


<details>
  <summary>Details</summary>
Motivation: 当前微服务异常检测忽视时变依赖信息，故障定位依赖因果推断计算昂贵，缺乏对大规模实际部署的高效解决方案，故提出FC-ADL。

Method: 基于神经科学中的功能连接理论，构建时变依赖关系模型，检测微服务指标异常并定位根因，避免高昂的因果推断计算。

Result: 本文提出了FC-ADL，一种基于功能连接概念的可扩展的微服务异常检测与定位方法。该方法有效刻画了微服务指标间时变依赖关系，具备高效检测异常和定位根因的能力，避免了因果推断等计算开销过大的问题。实验结果表明，FC-ADL在多种故障场景下检测与定位性能优越，并成功应用于阿里巴巴大规模微服务部署，体现了良好的可扩展性。

Conclusion: FC-ADL方法通过刻画时变依赖，提升了微服务异常检测与定位的准确性和效率，适用于大规模实际部署。

Abstract: Microservices have transformed software architecture through the creation of modular and independent services. However, they introduce operational complexities in service integration and system management that makes swift and accurate anomaly detection and localisation challenging. Despite the complex, dynamic, and interconnected nature of microservice architectures, prior works that investigate metrics for anomaly detection rarely include explicit information about time-varying interdependencies. And whilst prior works on fault localisation typically do incorporate information about dependencies between microservices, they scale poorly to real world large-scale deployments due to their reliance on computationally expensive causal inference. To address these challenges we propose FC-ADL, an end-to-end scalable approach for detecting and localising anomalous changes from microservice metrics based on the neuroscientific concept of functional connectivity. We show that by efficiently characterising time-varying changes in dependencies between microservice metrics we can both detect anomalies and provide root cause candidates without incurring the significant overheads of causal and multivariate approaches. We demonstrate that our approach can achieve top detection and localisation performance across a wide degree of different fault scenarios when compared to state-of-the-art approaches. Furthermore, we illustrate the scalability of our approach by applying it to Alibaba's extremely large real-world microservice deployment.

</details>


### [98] [The Software Infrastructure Attitude Scale (SIAS): A Questionnaire Instrument for Measuring Professionals' Attitudes Toward Technical and Sociotechnical Infrastructure](https://arxiv.org/abs/2512.00855)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Amin Milani Fard,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Hera Arif,Gianisa Adisaputri,Kelly Garcés,Anielle S. L. Andrade,Eyram Amedzor,Bimpe Ayoola,Keisha Gaspard-Chickoree,Arazoo Hoseyni*

Main category: cs.SE

TL;DR: 本文开发并验证了一种衡量软件工程中技术与社会技术基础设施态度的心理测量量表，结构合理、效度良好，有助于推进社会技术研究。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究日益重视社会技术因素，需开发针对性的心理测量工具以准确定量研究相关态度，填补现有测量工具的空白。

Method: 基于基础设施和态度理论及心理测量前期研究，设计量表条目，并对225名软件专业人士进行调查，使用探索性因子分析发现两因素结构，验证性因子分析确认模型拟合，采用多项效度指标进行验证。

Result: 本文定义了软件工程中技术基础设施和社会技术基础设施的概念，开发并验证了衡量对其态度的心理测量量表。通过225名软件专业人士的数据，采用探索性和验证性因子分析，确认了两因素结构，解释了65%的方差，并验证了量表的信效度。量表包含认知、情感和行为三方面，且与工作满意度、自主感和反馈等变量呈现收敛效度，回归分析和多种判别效度检验均表明量表具备良好效度。该量表为软件工程领域的社会技术研究提供了有效的心理测量工具。

Conclusion: 所开发的量表在结构和效度上均表现优异，是测量软件工程技术及社会技术基础设施态度的有效工具，促进了心理测量方法在软件工程行为研究中的应用。

Abstract: Context: Recent software engineering (SE) research has highlighted the need for sociotechnical research, implying a demand for customized psychometric scales. Objective: We define the concepts of technical and sociotechnical infrastructure in software engineering, and develop and validate a psychometric scale that measures attitudes toward them. Method: Grounded in theories of infrastructure, attitudes, and prior work on psychometric measurement, we defined the target constructs and generated scale items. The scale was administered to 225 software professionals and evaluated using a split sample. We conducted an exploratory factor analysis (EFA) on one half of the sample to uncover the underlying factor structure and performed a confirmatory factor analysis (CFA) on the other half to validate the structure. Further analyses with the whole sample assessed face, criterion-related, and discriminant validity. Results: EFA supported a two-factor structure (technical and sociotechnical infrastructure), accounting for 65% of the total variance with strong loadings. CFA confirmed excellent model fit. Face and content validity were supported by the item content reflecting cognitive, affective, and behavioral components. Both subscales were correlated with job satisfaction, perceived autonomy, and feedback from the job itself, supporting convergent validity. Regression analysis supported criterion-related validity, while the Heterotrait-Monotrait ratio of correlations (HTMT), the Fornell-Larcker criterion, and model comparison all supported discriminant validity. Discussion: The resulting scale is a valid instrument for measuring attitudes toward technical and sociotechnical infrastructure in software engineering research. Our work contributes to ongoing efforts to integrate psychological measurement rigor into empirical and behavioral software engineering research.

</details>


### [99] [The AI Attribution Paradox: Transparency as Social Strategy in Open-Source Software Development](https://arxiv.org/abs/2512.00867)
*Obada Kraishan*

Main category: cs.SE

TL;DR: 本文研究了AI编程辅助工具在软件开发中的归因现象，发现开发者在承认AI帮助与避免社区审查间策略性平衡，明确归因虽然引起一定讨论，但社区整体态度中立，归因比例随时间显著增长。


<details>
  <summary>Details</summary>
Motivation: AI编码助手普及引发对归因透明度和责任的关注，研究开发者如何在承认AI帮助与应对社区审查之间进行权衡。

Method: 分析了2023至2025年间14,300个GitHub提交和7,393个仓库，研究8种主流AI工具的归因策略及社区响应，结合时间序列分析归因比例变化。

Result: 95.2%的提交涉及AI帮助，但仅29.5%明确归因，且不同AI工具归因比例差异显著。明确归因引发更多社区问题和评论，但社区整体情绪中立。归因行为从2024年初几乎无至2025年底上升至40%。

Conclusion: AI归因并非简单的透明行为，而是开发者的策略性交流方式，随着时间推移，社区归因规范快速演变，影响算法责任与协作文化。

Abstract: AI coding assistants have transformed software development, raising questions about transparency and attribution practices. We examine the "AI attribution paradox": how developers strategically balance acknowledging AI assistance with managing community scrutiny. Analyzing 14,300 GitHub commits across 7,393 repositories from 2023-2025, we investigated attribution strategies and community responses across eight major AI tools. Results reveal widespread AI usage (95.2% of commits) but strategic attribution: only 29.5% employ explicit disclosure, with dramatic tool variation (Claude 80.5% versus Copilot 9.0%). Explicit attribution triggers modest scrutiny (23% more questions and 21% more comments) but tool choice matters 20-30 times more for predicting reception. Community sentiment remains neutral regardless of attribution type, suggesting curiosity rather than hostility. Temporal analyses show rapid norm evolution: explicit attribution increased from near-zero in early 2024 to 40% by late 2025, indicating community adaptation. These findings illuminate attribution as strategic communication rather than simple transparency, advancing understanding of algorithmic accountability and norm formation during technological transitions. We discuss implications for developers navigating disclosure decisions, platforms designing attribution mechanisms, and researchers studying emergent practices in AI-augmented collaborative work.

</details>


### [100] [Staying or Leaving? How Job Satisfaction, Embeddedness and Antecedents Predict Turnover Intentions of Software Professionals](https://arxiv.org/abs/2512.00869)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Hera Arif,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Gianisa Adisaputri*

Main category: cs.SE

TL;DR: 本文通过调查分析揭示影响软件专业人员离职意愿的心理和组织因素，强调改善工作满意度和嵌入性是留人关键。


<details>
  <summary>Details</summary>
Motivation: 软件行业普遍存在自愿离职问题，带来招聘和培训成本增加及知识流失风险。

Method: 通过地理多样性横断面调查收集224名软件专业人员的数据，运用部分最小二乘结构方程模型（PLS-SEM）分析，测试15个基于职业心理学和软件工程的假设。

Result: 工作满意度和工作嵌入性与软件专业人员的离职意愿显著负相关，工作与生活平衡无直接影响。工作满意度的主要影响因素是工作与生活平衡和工作质量，工作嵌入性的最强预测因子是组织公正。

Conclusion: 提高工作满意度和工作嵌入性是留住软件专业人员的关键，强化工作质量、支持工作生活平衡、确保组织公正可以间接减少离职意愿。

Abstract: Context: Voluntary turnover is common in the software industry, increasing recruitment and onboarding costs and the risk of losing organizational and tacit knowledge. Objective: This study investigates how job satisfaction, work-life balance, job embeddedness, and their antecedents, including job quality, personality traits, attitudes toward technical and sociotechnical infrastructure, and perceptions of organizational justice, relate to software professionals' turnover intentions. Method: We conducted a geographically diverse cross-sectional survey of software professionals (N = 224) and analyzed the data using partial least squares structural equation modeling (PLS-SEM). Our model includes both reflective and formative constructs and tests 15 hypotheses grounded in occupational psychology and software engineering literature. Results: Job satisfaction and embeddedness were significantly negatively associated with software professionals' turnover intentions, while work-life balance showed no direct effect. The strongest antecedents for job satisfaction were work-life balance and job quality, while organizational justice was the strongest predictor of job embeddedness. Discussion: The resulting PLS-SEM model has considerably higher explanatory power for key outcome variables than previous work conducted in the software development context, highlighting the importance of both psychological (e.g., job satisfaction, job embeddedness) and organizational (e.g., organizational justice, job quality) factors in understanding turnover intentions of software professionals. Our results imply that improving job satisfaction and job embeddedness is the key to retaining software professionals. In turn, enhancing job quality, supporting work-life balance, and ensuring high organizational justice can improve job satisfaction and embeddedness, indirectly reducing turnover intentions.

</details>


### [101] [Neural Variable Name Repair: Learning to Rename Identifiers for Readability](https://arxiv.org/abs/2512.01141)
*Muhammad Yousuf,Akshat Bagade,Chhittebbayi Penugonda,Maanas Baraya*

Main category: cs.SE

TL;DR: 本研究通过对Llama模型进行专门微调和引入重排序策略，大幅提升了C++代码变量名的自动修复效果，改善代码理解和分析效率。


<details>
  <summary>Details</summary>
Motivation: 源代码中的变量名通常过于通用或误导，且函数文档缺失，导致代码理解困难、潜在漏洞风险增加，同时也影响人类和大语言模型的代码推理能力。

Method: 基于Llama 3.1-8B，采用热身和丢弃调度稳定微调，结合LoRA适配器实现高效微调，并引入双编码器重排序器优化生成结果选择。

Result: 改进后的模型在C++函数变量名修复任务中，Exact match达到43.1%，Top-5命中率50.2%，部分匹配分数82.03，显著优于零-shot基线的6.1%准确率。

Conclusion: 通过任务特定的微调和重排序方法，显著提升了变量名修复的准确率，表明这种方法对实际代码标识符修复工具具有潜在应用价值。

Abstract: Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode's The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.

</details>


### [102] [Beyond Greenfield: AI-Driven Productivity in Documentation and Brownfield Engineering](https://arxiv.org/abs/2512.01155)
*Krishna Kumaar Sharma*

Main category: cs.SE

TL;DR: 本文提出了针对遗留系统复杂环境的D3框架，结合双智能体提示策略提升工程任务效率和质量。


<details>
  <summary>Details</summary>
Motivation: 针对遗留系统复杂且文档不完整、知识碎片化的挑战，设计系统化的LLM辅助工作流以提升任务执行效果。

Method: 采用双智能体架构（Builder生成候选输出，Reviewer提供结构化反馈），结合角色分离提示策略，并通过52名软件工程师的探索性调查验证。

Result: 参与者自评生产率提升26.9%，77%感觉认知负担降低，83%在定义阶段感知返工减少，体现D3框架实用潜力。

Conclusion: D3框架在遗留系统工程任务中有效提高了任务清晰度、文档质量和生产力，但当前结果基于自我报告，需进一步验证。

Abstract: Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and reduced rework for 83% during the Define phase. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.

</details>


### [103] [LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost](https://arxiv.org/abs/2512.01232)
*Donghao Huang,Shila Chew,Anna Dutkiewicz,Zhaoxia Wang*

Main category: cs.SE

TL;DR: 提出LAJ框架评估Gherkin测试，发现小模型表现优异，提供准确性与低成本的最佳平衡，强调推理强度与模型家族的关联，公开数据与工具。


<details>
  <summary>Details</summary>
Motivation: 大规模软件测试覆盖率评估是QA流程中的瓶颈，当前缺乏高效且准确的自动化评估手段，利用大语言模型作为“判官”提供可靠、低成本的评价方案以推动测试质量保障。

Method: 设计基于大语言模型的评分系统，使用结构化JSON输出结合评估标准，对20种不同模型配置在标注好的测试脚本上进行多轮评测，量化命中率、准确性和成本指标。

Result: 本文提出了LAJ（一种基于大语言模型的Gherkin验收测试评价框架），通过对20种模型配置（包括GPT-4、GPT-5及开源模型）在专家标注的测试脚本上进行了500次评估，首次综合分析了准确率、可靠性和成本等指标。研究发现小模型GPT-4o Mini在准确性（6.07 MAAE）、可靠性（96.6% ECR@1）和成本（每千次仅1.01美元）上表现最佳，且相较GPT-5高推理版本节约78倍成本。推理强度对不同模型族影响不同，GPT-5增加推理可提升性能而开源模型则表现下降。成本差异高达175倍。论文公开了数据集、代码和框架以支持复现和应用。

Conclusion: LAJ框架有效提升了大规模软件测试覆盖率评估的准确性和可靠性，同时显著降低成本，小模型在该任务中具有更优的性价比。推理强度对性能的影响依赖模型类型，需结合实际场景选择。

Abstract: Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.

</details>


### [104] [LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM](https://arxiv.org/abs/2512.01356)
*Yuxin Zhang,Yuxia Zhang,Zeyu Sun,Yanjie Jiang,Hui Liu*

Main category: cs.SE

TL;DR: 提出基于LLM的复审知识增强和上下文感知框架LAURA，有效提升代码审查自动生成质量，且构建了高质量数据集，表现显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 代码审查对于保证软件质量至关重要，但因软件规模增长和开发者短缺，代码审查成为开发瓶颈。现有自动生成代码审查方法忽视了代码变化上下文和历史复审知识，影响效果。

Method: 提出基于大语言模型（LLM）的复审知识增强和上下文感知的代码审查生成框架LAURA，结合复审实例检索、上下文增强和系统指导，提升ChatGPT-4和DeepSeek v3生成代码审查意见的性能，并构建了高质量数据集以克服现有低质量数据集的影响。

Result: LAURA在两种模型上生成的复审意见42.2%完全正确，40.4%对开发者至少有帮助，显著优于现有最先进方法。消融实验显示LAURA各组件均对提升评论质量有正向贡献。

Conclusion: LAURA框架通过整合复审知识和代码上下文，显著提升了LLM生成代码审查意见的质量，有效缓解了代码审查的效率瓶颈问题。各组件均对性能提升有重要作用。

Abstract: Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.

</details>


### [105] [BackportBench: A Multilingual Benchmark for Automated Backporting of Patches](https://arxiv.org/abs/2512.01396)
*Zhiqing Zhong,Jiaming Huang,Pinjia He*

Main category: cs.SE

TL;DR: BackportBench基准套件评估了补丁回移技术，智能代理方法表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 软件项目快速迭代导致安全补丁难以及时更新，当前自动回移技术局限于局部代码变更且评估指标不完善，亟需一个全面的、多语言的补丁回移基准以推动这一领域的发展。

Method: 构建多语言补丁回移基准BackportBench，结合可执行Docker环境和测试用例，评估传统方法及基于大语言模型的自动化补丁回移技术。

Result: 本文提出了BackportBench，一个多语言的补丁回移基准套件，包含来自PyPI、Maven和npm的202个补丁回移问题。通过该基准评估了现有的补丁回移方法和基于大语言模型的技术，发现基于智能代理的方法在需要逻辑和结构调整的场景中优于传统方法，但不同编程语言间表现存在差异。

Conclusion: 智能代理方法比传统补丁回移技术效果更好，但不同语言的表现差异需要关注，为未来自动回移研究提供指导。

Abstract: Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics.
  To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.

</details>


### [106] [Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report](https://arxiv.org/abs/2512.01523)
*Pankaj Jalote,Y. Raghu Reddy,Vasudeva Varma*

Main category: cs.SE

TL;DR: 本文介绍了在疫情催化下，在线协同教学研究级课程的可行性与优势，特别是跨机构合作和产业参与的实践案例。


<details>
  <summary>Details</summary>
Motivation: 疫情使在线教学变得普及，借助这一机遇解决单个机构无法独立开设研究型课程的问题，并促进产学研结合。

Method: 通过两个机构共同在线开设课程，邀请产业专家参与，结合线上教学平台进行协同教学和互动。

Result: 成功开展了“软件工程中的AI”课程，师生与产业专家的积极参与提升了教学质量和学习体验，验证了该模式的可行性。

Conclusion: 跨机构和产业共同在线开设研究型课程，如“软件工程中的AI”，可有效解决单一院校师资和学生资源不足的问题，促进高水平应用计算机科学教育。

Abstract: Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled "AI in Software Engineering" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.

</details>


### [107] [OpenDORS: A dataset of openly referenced open research software](https://arxiv.org/abs/2512.01570)
*Stephan Druskat,Lars Grunske*

Main category: cs.SE

TL;DR: 本文提供了一个大规模的开放研究软件数据集，包括关联文献和源代码仓库的详细元数据，为研究软件工程领域的后续研究提供基础资料。


<details>
  <summary>Details</summary>
Motivation: 尽管研究软件工程重要性日益凸显，但大规模研究软件及其开发实践的系统性研究仍然缺乏。

Method: 通过收集并关联开放获取文献中提及的研究软件源代码仓库，整理出详细的元数据，包括版本、许可证、编程语言等信息。

Result: 数据集覆盖大量研究软件及其仓库，提供丰富的元数据信息，并展示了这些特征的分布情况，支持未来数据集扩展和深入研究。

Conclusion: 本文构建了一个包含134,352个独特开放研究软件项目及134,154个源代码仓库的数据集，促进对研究软件开发的宏观分析。

Abstract: In many academic disciplines, software is created during the research process or for a research purpose. The crucial role of software for research is increasingly acknowledged. The application of software engineering to research software has been formalized as research software engineering, to create better software that enables better research. Despite this, large-scale studies of research software and its development are still lacking. To enable such studies, we present a dataset of 134,352 unique open research software projects and 134,154 source code repositories referenced in open access literature. Each dataset record identifies the referencing publication and lists source code repositories of the software project. For 122,425 source code repositories, the dataset provides metadata on latest versions, license information, programming languages and descriptive metadata files. We summarize the distributions of these features in the dataset and describe additional software metadata that extends the dataset in future work. Finally, we suggest examples of research that could use the dataset to develop a better understanding of research software practice in RSE research.

</details>


### [108] [GPTrace: Effective Crash Deduplication Using LLM Embeddings](https://arxiv.org/abs/2512.01609)
*Patrick Herter,Vincent Ahlrichs,Ridvan Açilan,Julian Horsch*

Main category: cs.SE

TL;DR: GPTrace利用大语言模型和聚类技术改进软件崩溃去重，显著提升去重效果，减少漏洞分析负担。


<details>
  <summary>Details</summary>
Motivation: 软件模糊测试能够高效发现漏洞，但因大量崩溃输入需要分析，人工工作量大且存在重复漏洞的问题。现有的崩溃去重方法效果不佳。

Method: 提出GPTrace，利用大语言模型计算崩溃相关数据的向量嵌入，再用聚类算法判断相似性，实现更准确的崩溃去重。

Result: GPTrace在14个不同测试目标、30万崩溃输入和50个标签中，去重效果明显优于传统堆栈跟踪比较和现有复杂方法。

Conclusion: 通过结合大语言模型和聚类算法，GPTrace实现了更灵活且更准确的崩溃输入去重，提升了漏洞分析效率。

Abstract: Fuzzing is a highly effective method for uncovering software vulnerabilities, but analyzing the resulting data typically requires substantial manual effort. This is amplified by the fact that fuzzing campaigns often find a large number of crashing inputs, many of which share the same underlying bug. Crash deduplication is the task of finding such duplicate crashing inputs and thereby reducing the data that needs to be examined. Many existing deduplication approaches rely on comparing stack traces or other information that is collected when a program crashes. Although various metrics for measuring the similarity of such pieces of information have been proposed, many do not yield satisfactory deduplication results. In this work, we present GPTrace, a deduplication workflow that leverages a large language model to evaluate the similarity of various data sources associated with crashes by computing embedding vectors and supplying those as input to a clustering algorithm. We evaluate our approach on over 300 000 crashing inputs belonging to 50 ground truth labels from 14 different targets. The deduplication results produced by GPTrace show a noticeable improvement over hand-crafted stack trace comparison methods and even more complex state-of-the-art approaches that are less flexible.

</details>


### [109] [When High-Performance Computing Meets Software Testing: Distributed Fuzzing using MPI](https://arxiv.org/abs/2512.01617)
*Pierciro Caliandro,Matteo Ciccaglione,Alessandro Pellegrini*

Main category: cs.SE

TL;DR: 本文提出通过MPI同步技术优化分布式模糊测试框架，显著减低通信延迟，提高覆盖率进展速度和测试扩展性，适用于软件开发中的CI/CD流程。


<details>
  <summary>Details</summary>
Motivation: 传统基于文件系统的同步方法存在较高的通信延迟，限制了分布式模糊测试的性能和扩展性，特别是在持续集成和持续交付（CI/CD）流程中的应用。

Method: 通过将MPI（消息传递接口）基础的同步技术集成到分布式模糊测试框架中，利用轻量级MPI原语减少通信延迟，从而实现各模糊测试节点之间更高效的数据交换。

Result: 实验基准测试显示，采用MPI同步技术能显著提高测试覆盖率的推进速度，特别是在模糊测试早期阶段。同时，通过集群间的输入语料库协调交换，有效解决了覆盖率停滞问题，实现对复杂和深层执行路径的持续探索。

Conclusion: 采用MPI基础的同步方法能够有效提升分布式模糊测试的性能和扩展性，解决覆盖率停滞，实现更高效的测试，具有良好的应用前景。

Abstract: This paper explores the integration of MPI-based synchronization techniques into distributed fuzzing frameworks, highlighting possible substantial performance improvements compared to traditional filesystem-based synchronization methods. By employing lightweight MPI primitives, reductions in communication latency are achieved, facilitating more efficient data exchanges across distributed fuzzing nodes. Experimental results obtained over standard benchmarks demonstrate enhanced coverage progression from the early stages of the fuzzing process, which could be beneficial if fuzzing is employed in CI/CD pipelines at any stage of software development. Furthermore, the coordinated exchange of input corpora among clusters of fuzzers effectively addresses coverage stagnation, enabling a sustained exploration of complex and deep execution paths. Overall, the adoption of MPI-based synchronization approaches shows promising potential for significantly enhancing the scalability and efficacy of distributed fuzz testing.

</details>


### [110] [Package Dashboard: A Cross-Ecosystem Framework for Dual-Perspective Analysis of Software Packages](https://arxiv.org/abs/2512.01630)
*Ziheng Liu,Runzhi He,Minghui Zhou*

Main category: cs.SE

TL;DR: 本文提出了Package Dashboard，一个跨生态系统的软件供应链分析框架，整合软件包元数据、漏洞信息和社区健康指标，实现统一的风险评估平台，减少开发者认知负担，提高可追溯性。


<details>
  <summary>Details</summary>
Motivation: 当前软件供应链攻击暴露了现有SCA工具的盲点，这些工具通常只针对单一生态系统并且只评估软件制品或社区活动，缺乏统一视角，导致风险评估不全面且增加开发人员负担。

Method: 通过整合依赖解析和代码库分析，结合五个Linux发行版约374,000个软件包的实证研究，框架结合多种数据源，实现跨生态的综合供应链风险分析。

Result: 大规模实证研究表明，Package Dashboard不仅能识别已知漏洞和许可证冲突，还能发现被忽略的风险，效果优于现有工具，为开发者和DevSecOps工程师提供实用的风险洞察。

Conclusion: Package Dashboard能够统一视角进行软件供应链的风险评估，发现传统漏洞之外的潜在风险，如归档或不可访问的仓库，提升了开源生态系统的透明度和可信度。

Abstract: Software supply chain attacks have revealed blind spots in existing SCA tools, which are often limited to a single ecosystem and assess either software artifacts or community activity in isolation. This fragmentation across tools and ecosystems forces developers to manually reconcile scattered data, undermining risk assessments. We present Package Dashboard, a cross-ecosystem framework that provides a unified platform for supply chain analysis, enabling a holistic, dual-perspective risk assessment by integrating package metadata, vulnerability information, and upstream community health metrics. By combining dependency resolution with repository analysis, it reduces cognitive load and improves traceability. Demonstrating the framework's versatility, a large-scale study of 374,000 packages across five Linux distributions shows its ability to uncover not only conventional vulnerabilities and license conflicts but also overlooked risks such as archived or inaccessible repositories. Ultimately, Package Dashboard provides a unified view of risk, equipping developers and DevSecOps engineers with actionable insights to strengthen the transparency, trustworthiness, and traceability of open-source ecosystems. Package Dashboard is publicly available at https://github.com/n19htfall/PackageDashboard, and a demonstration video can be found at https://youtu.be/y9ncftP8KPQ. Besides, the online version is available at https://pkgdash.osslab-pku.org.

</details>


### [111] [MIT Lincoln Laboratory: A Case Study on Improving Software Support for Research Projects](https://arxiv.org/abs/2512.01649)
*Daniel Strassler,Gabe Elkin,Curran Schiefelbein,Daniel Herring,Ian Jessen,David Johnson,Santiago A. Paredes,Tod Shannon,Jim Flavin*

Main category: cs.SE

TL;DR: 麻省理工林肯实验室针对软件开发效率与文化进行了内部研究，发现项目属性、集中化潜力和人员文化是关键问题，并提出了集中工具支持、人才匹配数据库和利益相关者小组的建议。


<details>
  <summary>Details</summary>
Motivation: 随着软件在复杂系统开发中的重要性日益增长，需要提升软件工程的效率和文化，以更好地完成MIT林肯实验室的使命。

Method: 通过内部调研，分析影响软件开发效率的项目属性，调查集中化带来的潜在优势，以及软件从业人员的人员配置与文化问题，提出具体改进措施。

Result: 研究确定了影响软件开发的主要因素，并提出了包括工具集中化、人员匹配数据库建设及利益相关者小组的具体改进建议。

Conclusion: 通过集中化管理软件支持工具、建立人才需求匹配数据库及创建软件利益相关者小组，有望提升软件开发效率和文化，从而更好地推动使命执行。

Abstract: Software plays an ever increasing role in complex system development and prototyping, and in recent years, MIT Lincoln Laboratory has sought to improve both the effectiveness and culture surrounding software engineering in execution of its mission. The Homeland Protection and Air Traffic Control Division conducted an internal study to examine challenges to effective and efficient research software development, and to identify ways to strengthen both the culture and execution for greater impact on our mission. Key findings of this study fell into three main categories: project attributes that influence how software development activities must be conducted and managed, potential efficiencies from centralization, opportunities to improve staffing and culture with respect to software practitioners. The study delivered actionable recommendations, including centralizing and standardizing software support tooling, developing a common database to help match the right software talent and needs to projects, and creating a software stakeholder panel to assist with continued improvement.

</details>


### [112] [Generating REST API Tests With Descriptive Names](https://arxiv.org/abs/2512.01690)
*Philip Garrett,Juan P. Galeotti,Andrea Arcuri,Alexander Poth,Olsi Rrjolli*

Main category: cs.SE

TL;DR: 本文提出的轻量化确定性命名技术，在提升自动生成REST API测试用例名称的清晰度和可读性方面表现优异，是LLM方法的有效替代方案。


<details>
  <summary>Details</summary>
Motivation: 自动生成的测试用例通常名称无描述性，降低可读性和维护性，需要有效的自动命名方法提升测试用例的实用性。

Method: 提出三种新颖的确定性技术生成REST API测试用例的名称，并比较八种命名技术（包括基于规则的启发式方法和大型语言模型（LLM）方法）对自动生成的测试用例的效果。通过两次问卷调查和实际工业案例研究进行评估。

Result: 基于规则的确定性方法在清晰度评级上表现最佳，与先进的LLM模型（如Gemini和GPT-4o）相当，显著优于GPT-3.5。工业案例研究和开发者反馈进一步验证了其提升测试套件可读性的效果。

Conclusion: 轻量且确定性的方法在自动测试命名领域具有实用价值，能显著提升测试用例的易用性，减少对昂贵且存在安全隐患的LLM方法依赖，为开发者友好的API测试生成提供了实用方案。

Abstract: Automated test generation has become a key technique for ensuring software quality, particularly in modern API-based architectures. However, automatically generated test cases are typically assigned non-descriptive names (e.g., test0, test1), which reduces their readability and hinders their usefulness during comprehension and maintenance. In this work, we present three novel deterministic techniques to generate REST API test names. We then compare eight techniques in total for generating descriptive names for REST API tests automatically produced by the fuzzer EvoMaster, using 10 test cases generated for 9 different open-source APIs. The eight techniques include rule-based heuristics and large language model (LLM)-based approaches. Their effectiveness was empirically evaluated through two surveys (involving up to 39 people recruited via LinkedIn). Our results show that a rule-based approach achieves the highest clarity ratings among deterministic methods, performs on par with state-of-the-art LLM-based models such as Gemini and GPT-4o, and significantly outperforms GPT-3.5.
  To further evaluate the practical impact of our results, an industrial case study was carried out with practitioners who actively use EvoMaster at Volkswagen AG. A developer questionnaire was then carried out based on the use of EvoMaster on four different APIs by four different users, for a total of 74 evaluated test cases. Feedback from practitioners further confirms that descriptive names produced by this approach improve test suite readability.
  These findings highlight that lightweight, deterministic techniques can serve as effective alternatives to computationally expensive and security-sensitive LLM-based approaches for automated system-level test naming, providing a practical step toward more developer-friendly API test generation.

</details>


### [113] [An Empirical Study of Agent Developer Practices in AI Agent Frameworks](https://arxiv.org/abs/2512.01939)
*Yanlin Wang,Xinyi Xu,Jiachi Chen,Tingting Bi,Wenchao Gu,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文通过分析大量开发者讨论，首次实证比较了10个主流LLM智能体框架的表现，揭示了框架设计中的共性问题和差异特点，为未来智能体框架设计提供了宝贵参考。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的智能体框架数量激增，开发者在选择和使用这些框架时遇到许多共性问题，且实际应用和开发流程的影响尚未充分研究。

Method: 通过收集和分析11910条来自10个主流LLM智能体框架的开发者讨论，进行实证研究，比较框架在开发效率、功能抽象、学习成本、性能优化和可维护性五个维度上的表现。

Result: 不同框架在满足开发者需求方面存在显著差异，揭示了开发效率、学习曲线、性能和可扩展性等方面的优劣，提出了对于框架生态和未来设计的见解和建议。

Conclusion: 本研究首次系统地比较了主流LLM智能体框架的实际应用表现，发现其存在共性问题和差异性优势，为框架设计者和开发者提供了重要参考，有助于推动智能体框架生态的健康发展。

Abstract: The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.

</details>
