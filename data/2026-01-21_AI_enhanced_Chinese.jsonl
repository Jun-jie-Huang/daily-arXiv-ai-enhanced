{"id": "2601.12307", "categories": ["cs.MA", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12307", "abs": "https://arxiv.org/abs/2601.12307", "authors": ["Jiawei Xu", "Arief Koesdwiady", "Sisong Bei", "Yan Han", "Baixiang Huang", "Dakuo Wang", "Yutong Chen", "Zheshen Wang", "Peihao Wang", "Pan Li", "Ying Ding"], "title": "Rethinking the Value of Multi-Agent Workflow: A Strong Single Agent Baseline", "comment": null, "summary": "Recent advances in LLM-based multi-agent systems (MAS) show that workflows composed of multiple LLM agents with distinct roles, tools, and communication patterns can outperform single-LLM baselines on complex tasks. However, most frameworks are homogeneous, where all agents share the same base LLM and differ only in prompts, tools, and positions in the workflow. This raises the question of whether such workflows can be simulated by a single agent through multi-turn conversations. We investigate this across seven benchmarks spanning coding, mathematics, general question answering, domain-specific reasoning, and real-world planning and tool use. Our results show that a single agent can reach the performance of homogeneous workflows with an efficiency advantage from KV cache reuse, and can even match the performance of an automatically optimized heterogeneous workflow. Building on this finding, we propose \\textbf{OneFlow}, an algorithm that automatically tailors workflows for single-agent execution, reducing inference costs compared to existing automatic multi-agent design frameworks without trading off accuracy. These results position the single-LLM implementation of multi-agent workflows as a strong baseline for MAS research. We also note that single-LLM methods cannot capture heterogeneous workflows due to the lack of KV cache sharing across different LLMs, highlighting future opportunities in developing \\textit{truly} heterogeneous multi-agent systems.", "AI": {"tldr": "\u672c\u6587\u8bc1\u660e\u5355\u4e00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u591a\u8f6e\u5bf9\u8bdd\u80fd\u6709\u6548\u6a21\u62df\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u63d0\u51faOneFlow\u7b97\u6cd5\u4f18\u5316\u5355\u4f53\u6267\u884c\u6d41\u7a0b\uff0c\u63d0\u5347\u6548\u7387\u4e14\u4e0d\u635f\u6027\u80fd\uff0c\u4f46\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u5b9e\u73b0\u4ecd\u9700\u7a81\u7834\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u591a\u91c7\u7528\u540c\u8d28\u5316\u6846\u67b6\uff0c\u6240\u6709\u667a\u80fd\u4f53\u5171\u4eab\u76f8\u540c\u57fa\u7840\u6a21\u578b\uff0c\u96be\u4ee5\u8bc4\u4f30\u5355\u4e00\u667a\u80fd\u4f53\u591a\u8f6e\u5bf9\u8bdd\u662f\u5426\u80fd\u6a21\u62df\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "method": "\u901a\u8fc7\u4e03\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u6bd4\u8f83\u5355\u4e00\u667a\u80fd\u4f53\u591a\u8f6e\u5bf9\u8bdd\u4e0e\u591a\u667a\u80fd\u4f53\u540c\u8d28\u53ca\u5f02\u8d28\u5de5\u4f5c\u6d41\u6027\u80fd\uff0c\u5e76\u63d0\u51faOneFlow\u7b97\u6cd5\u81ea\u52a8\u4f18\u5316\u5355\u667a\u80fd\u4f53\u6267\u884c\u6d41\u7a0b\u3002", "result": "\u5355\u667a\u80fd\u4f53\u591a\u8f6e\u5bf9\u8bdd\u80fd\u8fbe\u5230\u540c\u8d28\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7684\u6027\u80fd\u5e76\u4e14\u66f4\u9ad8\u6548\uff0c\u540c\u65f6\u53ef\u4ee5\u5339\u914d\u81ea\u52a8\u4f18\u5316\u7684\u5f02\u8d28\u5de5\u4f5c\u6d41\u6027\u80fd\uff0cOneFlow\u964d\u4f4e\u63a8\u7406\u6210\u672c\u4e14\u4e0d\u964d\u4f4e\u7cbe\u5ea6\u3002", "conclusion": "\u5355\u6a21\u578b\u5b9e\u73b0\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u53ef\u4f5c\u4e3a\u5f3a\u57fa\u7ebf\uff0c\u4e14OneFlow\u63d0\u5347\u4e86\u5355\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u6548\u7387\uff0c\u4f46\u56e0\u65e0\u6cd5\u5171\u4eab\u4e0d\u540c\u6a21\u578b\u7684\u7f13\u5b58\uff0c\u771f\u6b63\u5f02\u8d28\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4ecd\u5177\u6311\u6218\u548c\u7814\u7a76\u7a7a\u95f4\u3002"}}
{"id": "2601.12348", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12348", "abs": "https://arxiv.org/abs/2601.12348", "authors": ["Haris Khan", "Sadia Asif"], "title": "Generative AI Agents for Controllable and Protected Content Creation", "comment": "Accepted GenProCC NeurIPS 2025, Paper # 33", "summary": "The proliferation of generative AI has transformed creative workflows, yet current systems face critical challenges in controllability and content protection. We propose a novel multi-agent framework that addresses both limitations through specialized agent roles and integrated watermarking mechanisms. Unlike existing multi-agent systems focused solely on generation quality, our approach uniquely combines controllable content synthesis with provenance protection during the generation process itself. The framework orchestrates Director/Planner, Generator, Reviewer, Integration, and Protection agents with human-in-the-loop feedback to ensure alignment with user intent while embedding imperceptible digital watermarks. We formalize the pipeline as a joint optimization objective unifying controllability, semantic alignment, and protection robustness. This work contributes to responsible generative AI by positioning multi-agent architectures as a solution for trustworthy creative workflows with built-in ownership tracking and content traceability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e0e\u6570\u5b57\u6c34\u5370\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u751f\u6210\u578bAI\u4e2d\u5185\u5bb9\u53ef\u63a7\u6027\u548c\u7248\u6743\u4fdd\u62a4\u7684\u6311\u6218\uff0c\u63a8\u52a8\u8d1f\u8d23\u4efb\u4e14\u5b89\u5168\u7684\u521b\u610f\u751f\u6210\u3002", "motivation": "\u751f\u6210\u578b\u4eba\u5de5\u667a\u80fd\u867d\u7136\u4fc3\u8fdb\u4e86\u521b\u610f\u6d41\u7a0b\u7684\u53d1\u5c55\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5728\u53ef\u63a7\u6027\u548c\u5185\u5bb9\u4fdd\u62a4\u65b9\u9762\u5b58\u5728\u5173\u952e\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u5b9a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\u89d2\u8272\u548c\u96c6\u6210\u6c34\u5370\u673a\u5236\uff0c\u5b9e\u73b0\u5185\u5bb9\u7684\u53ef\u63a7\u5408\u6210\u548c\u751f\u6210\u8fc7\u7a0b\u4e2d\u7684\u6eaf\u6e90\u4fdd\u62a4\u3002\u6846\u67b6\u5305\u62ec\u5bfc\u6f14/\u89c4\u5212\u8005\u3001\u751f\u6210\u8005\u3001\u5ba1\u9605\u8005\u3001\u6574\u5408\u8005\u548c\u4fdd\u62a4\u8005\u667a\u80fd\u4f53\uff0c\u5e76\u7ed3\u5408\u4eba\u7c7b\u53cd\u9988\uff0c\u786e\u4fdd\u751f\u6210\u5185\u5bb9\u7b26\u5408\u7528\u6237\u610f\u56fe\u540c\u65f6\u5d4c\u5165\u4e0d\u53ef\u5bdf\u89c9\u7684\u6570\u5b57\u6c34\u5370\u3002", "result": "\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u5185\u5bb9\u5408\u6210\u7684\u53ef\u63a7\u6027\u3001\u8bed\u4e49\u5bf9\u9f50\u548c\u4fdd\u62a4\u9c81\u68d2\u6027\u7684\u8054\u5408\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u548c\u5b89\u5168\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u67b6\u6784\u4e3a\u8d1f\u8d23\u4efb\u7684\u751f\u6210\u578b\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u652f\u6301\u503c\u5f97\u4fe1\u8d56\u7684\u521b\u610f\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5185\u7f6e\u6240\u6709\u6743\u8ffd\u8e2a\u548c\u5185\u5bb9\u53ef\u8ffd\u6eaf\u6027\u3002"}}
{"id": "2601.12580", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12580", "abs": "https://arxiv.org/abs/2601.12580", "authors": ["Sofiya Zaichyk"], "title": "Semantic Fusion: Verifiable Alignment in Decentralized Multi-Agent Systems", "comment": "29 pages", "summary": "We present Semantic Fusion (SF), a formal framework for decentralized semantic coordination in multi-agent systems. SF allows agents to operate over scoped views of shared memory, propose structured updates, and maintain global coherence through local ontology-based validation and refresh without centralized control or explicit message passing. The central theoretical result is a bisimulation theorem showing that each agent's local execution is behaviorally equivalent to its projection of the global semantics, in both deterministic and probabilistic settings. This enables safety, liveness, and temporal properties to be verified locally and soundly lifted to the full system. SF supports agents whose update proposals vary across invocations, including those generated by learned or heuristic components, provided updates pass semantic validation before integration. We establish deterministic and probabilistic guarantees ensuring semantic alignment under asynchronous or degraded communication. To validate the model operationally, we implement a lightweight reference architecture that instantiates its core mechanisms. A 250-agent simulation evaluates these properties across over 11,000 validated updates, demonstrating convergence under probabilistic refresh, bounded communication, and resilience to agent failure. Together, these results show that Semantic Fusion can provide a formal and scalable basis for verifiable autonomy in decentralized systems.", "AI": {"tldr": "\u63d0\u51faSemantic Fusion\u6846\u67b6\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u53bb\u4e2d\u5fc3\u5316\u4e14\u53ef\u9a8c\u8bc1\u7684\u8bed\u4e49\u534f\u8c03\uff0c\u652f\u6301\u52a8\u6001\u66f4\u65b0\u548c\u4e0d\u5b8c\u7f8e\u901a\u4fe1\uff0c\u4fdd\u8bc1\u5168\u5c40\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u7cfb\u7edf\u7684\u5b89\u5168\u6d3b\u6027\u5c5e\u6027\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u4e2d\u5fc3\u5316\u63a7\u5236\u65f6\u5982\u4f55\u5728\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\u3001\u5b9e\u73b0\u5b89\u5168\u548c\u6d3b\u6027\u5c5e\u6027\u9a8c\u8bc1\u7684\u96be\u9898\uff0c\u652f\u6301\u5f02\u6b65\u901a\u4fe1\u548c\u4ee3\u7406\u5931\u6548\u573a\u666f\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u672c\u4f53\u9a8c\u8bc1\u548c\u5237\u65b0\u673a\u5236\u7684\u5c40\u90e8\u89c6\u56fe\u64cd\u4f5c\u65b9\u6cd5\uff0c\u5229\u7528\u53cc\u6a21\u62df\u5b9a\u7406\u8bc1\u660e\u5c40\u90e8\u6267\u884c\u4e0e\u5168\u5c40\u8bed\u4e49\u884c\u4e3a\u7b49\u4ef7\uff0c\u8bbe\u8ba1\u4e86\u8f7b\u91cf\u7ea7\u67b6\u6784\u5e76\u901a\u8fc7\u5927\u89c4\u6a21\u4eff\u771f\u9a8c\u8bc1\u5176\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u652f\u6301\u52a8\u6001\u53d8\u5316\u66f4\u65b0\u7684\u4ee3\u7406\u6a21\u578b\uff0c\u786e\u4fdd\u8bed\u4e49\u5bf9\u9f50\u7684\u786e\u5b9a\u6027\u548c\u6982\u7387\u6027\u4fdd\u8bc1\uff0c\u4eff\u771f\u5c55\u793a\u4e86\u5728\u6709\u754c\u901a\u4fe1\u548c\u4ee3\u7406\u5931\u6548\u6761\u4ef6\u4e0b\u7cfb\u7edf\u7684\u6536\u655b\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "Semantic Fusion\u4e3a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53bb\u4e2d\u5fc3\u5316\u7684\u8bed\u4e49\u534f\u8c03\u6846\u67b6\uff0c\u80fd\u591f\u5728\u65e0\u4e2d\u5fc3\u63a7\u5236\u548c\u65e0\u663e\u5f0f\u6d88\u606f\u4f20\u9012\u7684\u60c5\u51b5\u4e0b\u4fdd\u8bc1\u5168\u5c40\u8bed\u4e49\u7684\u4e00\u81f4\u6027\u548c\u9a8c\u8bc1\u5b89\u5168\u6027\u3002"}}
{"id": "2601.12886", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12886", "abs": "https://arxiv.org/abs/2601.12886", "authors": ["Christoph Wittner"], "title": "Communication Methods in Multi-Agent Reinforcement Learning", "comment": "12 pages, 2 figures", "summary": "Multi-agent reinforcement learning is a promising research area that extends established reinforcement learning approaches to problems formulated as multi-agent systems. Recently, a multitude of communication methods have been introduced to this field to address problems such as partially observable environments, non-stationarity, and exponentially growing action spaces. Communication further enables efficient cooperation among all agents interacting in an environment. This work aims at providing an overview of communication techniques in multi-agent reinforcement learning. By an in-depth analysis of 29 publications on this topic, the strengths and weaknesses of explicit, implicit, attention-based, graph-based, and hierarchical/role-based communication are evaluated. The results of this comparison show that there is no general, optimal communication framework for every problem. On the contrary, the choice of communication depends heavily on the problem at hand. The comparison also highlights the importance of communication methods with low computational overhead to enable scalability to environments where many agents interact. Finally, the paper discusses current research gaps, emphasizing the need for standardized benchmarking of system-level metrics and improved robustness under realistic communication conditions to enhance the real-world applicability of these approaches.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5404\u79cd\u901a\u4fe1\u6280\u672f\uff0c\u5206\u6790\u4e8629\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u6307\u51fa\u4e0d\u540c\u901a\u4fe1\u6846\u67b6\u9002\u7528\u4e0d\u540c\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u4f4e\u5f00\u9500\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u9762\u4e34\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u3001\u975e\u5e73\u7a33\u6027\u548c\u52a8\u4f5c\u7a7a\u95f4\u6307\u6570\u589e\u957f\u7b49\u96be\u9898\uff0c\u901a\u4fe1\u65b9\u6cd5\u88ab\u63d0\u51fa\u4ee5\u4fc3\u8fdb\u667a\u80fd\u4f53\u95f4\u7684\u6709\u6548\u5408\u4f5c\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5bf929\u7bc7\u5173\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u901a\u4fe1\u6280\u672f\u7684\u6587\u732e\u8fdb\u884c\u6df1\u5165\u5206\u6790\uff0c\u8bc4\u4f30\u4e86\u663e\u5f0f\u3001\u9690\u5f0f\u3001\u57fa\u4e8e\u6ce8\u610f\u529b\u3001\u57fa\u4e8e\u56fe\u548c\u5c42\u6b21/\u89d2\u8272\u901a\u4fe1\u7684\u4f18\u7f3a\u70b9\u3002", "result": "\u6bd4\u8f83\u7ed3\u679c\u663e\u793a\u6ca1\u6709\u901a\u7528\u7684\u6700\u4f18\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u4fe1\u65b9\u6cd5\u9009\u62e9\u9ad8\u5ea6\u4f9d\u8d56\u5177\u4f53\u95ee\u9898\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u4f4e\u8ba1\u7b97\u5f00\u9500\u901a\u4fe1\u65b9\u6cd5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u73b0\u6709\u7814\u7a76\u5728\u7cfb\u7edf\u7ea7\u57fa\u51c6\u6d4b\u8bd5\u548c\u901a\u4fe1\u9c81\u68d2\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u901a\u4fe1\u65b9\u6cd5\u6ca1\u6709\u901a\u7528\u7684\u6700\u4f73\u6846\u67b6\uff0c\u5176\u9009\u62e9\u4f9d\u8d56\u4e8e\u5177\u4f53\u95ee\u9898\uff0c\u5e76\u4e14\u4f4e\u8ba1\u7b97\u5f00\u9500\u7684\u901a\u4fe1\u65b9\u6cd5\u5bf9\u4e8e\u591a\u667a\u80fd\u4f53\u73af\u5883\u7684\u53ef\u6269\u5c55\u6027\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2601.11647", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11647", "abs": "https://arxiv.org/abs/2601.11647", "authors": ["Aniket Abhishek Soni", "Milan Parikh", "Rashi Nimesh Kumar Dhenia", "Jubin Abhishek Soni", "Ayush Raj Jha", "Sneja Mitinbhai Shah"], "title": "Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines", "comment": "Accepted and presented at CICN 2025 (International Conference on Computational Intelligence and Communication Networks). 7 pages, 5 figures", "summary": "Continuous Integration and Continuous Deployment (CI/CD) pipelines are central to modern software delivery, yet their static workflows often introduce inefficiencies as systems scale. This paper proposes a reinforcement learning (RL) based approach to dynamically optimize CI/CD pipeline workflows. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions such as selecting full, partial, or no test execution in order to maximize throughput while minimizing testing overhead.\n  A configurable CI/CD simulation environment is developed to evaluate the approach across build, test, and deploy stages. Experimental results show that the RL optimized pipeline achieves up to a 30 percent improvement in throughput and approximately a 25 percent reduction in test execution time compared to static baselines, while maintaining a defect miss rate below 5 percent. The agent learns to selectively skip or abbreviate tests for low risk commits, accelerating feedback cycles without significantly increasing failure risk.\n  These results demonstrate the potential of reinforcement learning to enable adaptive and intelligent DevOps workflows, providing a practical pathway toward more efficient, resilient, and sustainable CI/CD automation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u52a8\u6001\u4f18\u5316CI/CD\u6d41\u6c34\u7ebf\u6d4b\u8bd5\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u7f29\u77ed\u53cd\u9988\u65f6\u95f4\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u7684\u7f3a\u9677\u6f0f\u68c0\u7387\uff0c\u5c55\u793a\u4e86\u667a\u80fdDevOps\u6d41\u7a0b\u7684\u6f5c\u529b\u3002", "motivation": "\u73b0\u4ee3\u8f6f\u4ef6\u4ea4\u4ed8\u4e2dCI/CD\u6d41\u6c34\u7ebf\u7684\u9759\u6001\u5de5\u4f5c\u6d41\u968f\u7740\u7cfb\u7edf\u89c4\u6a21\u6269\u5927\u5bfc\u81f4\u6548\u7387\u4e0b\u964d\uff0c\u4e9f\u9700\u52a8\u6001\u667a\u80fd\u4f18\u5316\u65b9\u6848\u3002", "method": "\u5c06CI/CD\u6d41\u6c34\u7ebf\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8bad\u7ec3\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u51b3\u5b9a\u6d4b\u8bd5\u6267\u884c\u7b56\u7565\uff08\u5168\u90e8\u3001\u90e8\u5206\u6216\u4e0d\u6267\u884c\u6d4b\u8bd5\uff09\u4ee5\u6700\u5927\u5316\u541e\u5410\u91cf\u548c\u6700\u5c0f\u5316\u6d4b\u8bd5\u5f00\u9500\u3002", "result": "\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u540e\u7684\u6d41\u6c34\u7ebf\u76f8\u6bd4\u9759\u6001\u57fa\u7ebf\u541e\u5410\u91cf\u63d0\u5347\u4e8630%\uff0c\u6d4b\u8bd5\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u4e86\u7ea625%\uff0c\u7f3a\u9677\u6f0f\u68c0\u7387\u4fdd\u6301\u57285%\u4ee5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u52a0\u901f\u53cd\u9988\u4e14\u98ce\u9669\u53ef\u63a7\u3002", "conclusion": "\u672c\u6587\u8bc1\u660e\u4e86\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u4f18\u5316CI/CD\u6d41\u6c34\u7ebf\uff0c\u4f7f\u5176\u5728\u63d0\u5347\u541e\u5410\u91cf\u7684\u540c\u65f6\u51cf\u5c11\u6d4b\u8bd5\u65f6\u95f4\uff0c\u5e76\u63a7\u5236\u7f3a\u9677\u6f0f\u68c0\u7387\u3002"}}
{"id": "2601.11564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11564", "abs": "https://arxiv.org/abs/2601.11564", "authors": ["Ahilan Ayyachamy Nadar Ponnusamy", "Karthic Chandran", "M Maruf Hossain"], "title": "Context Discipline and Performance Correlation: Analyzing LLM Performance and Quality Degradation Under Varying Context Lengths", "comment": "22 pages, 6 figures", "summary": "The scaling trend in Large Language Models (LLMs) has prioritized increasing the maximum context window to facilitate complex, long-form reasoning and document analysis. However, managing this expanded context introduces severe computational overhead. This paper investigates the critical trade-off between system performance and model quality when dense transformer architectures--specifically Llama-3.1-70B and Qwen1.5-14B--are exposed to large volumes of irrelevant and distracting context. The research identifies a non-linear performance degradation tied to the growth of the Key-Value (KV) cache. Furthermore, an extended analysis of the Mixture-of-Experts (MoE) architecture reveals unique behavioral anomalies at varying context scales, suggesting that architectural benefits may be masked by infrastructure bottlenecks at high token volumes.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\u5bf9\u53d8\u6362\u5668\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u5904\u7406\u5927\u91cf\u65e0\u5173\u4e0a\u4e0b\u6587\u65f6\u7684\u975e\u7ebf\u6027\u6027\u80fd\u4e0b\u964d\u53caMoE\u67b6\u6784\u5728\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u4e0b\u7684\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u4e86\u89e3\u5728\u6269\u5c55\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u65f6\uff0c\u5982\u4f55\u5e73\u8861\u8ba1\u7b97\u5f00\u9500\u548c\u6a21\u578b\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5e94\u5bf9\u5927\u89c4\u6a21\u65e0\u5173\u4e0a\u4e0b\u6587\u5e26\u6765\u7684\u6027\u80fd\u6311\u6218\u3002", "method": "\u901a\u8fc7\u5b9e\u9a8c\u5206\u6790\u7a20\u5bc6\u53d8\u6362\u5668\u67b6\u6784\uff08\u5982Llama-3.1-70B\u548cQwen1.5-14B\uff09\u5728\u5927\u89c4\u6a21\u65e0\u5173\u4e0a\u4e0b\u6587\u4e0b\u7684\u8868\u73b0\uff0c\u5e76\u7ed3\u5408Mixture-of-Experts\u67b6\u6784\u7684\u6269\u5c55\u7814\u7a76\uff0c\u63a2\u8ba8\u4e0a\u4e0b\u6587\u89c4\u6a21\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u968f\u7740\u952e\u503c\u7f13\u5b58(KV cache)\u589e\u5927\uff0c\u6a21\u578b\u6027\u80fd\u5448\u975e\u7ebf\u6027\u4e0b\u964d\uff1bMoE\u67b6\u6784\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u89c4\u6a21\u4e0b\u8868\u73b0\u51fa\u72ec\u7279\u5f02\u5e38\uff0c\u8868\u660e\u9ad8\u4ee4\u724c\u91cf\u4e0b\u67b6\u6784\u4f18\u52bf\u53ef\u80fd\u88ab\u57fa\u7840\u8bbe\u65bd\u74f6\u9888\u63a9\u76d6\u3002", "conclusion": "\u5927\u89c4\u6a21\u4e0a\u4e0b\u6587\u7a97\u53e3\u6269\u5c55\u5728\u63d0\u5347\u6a21\u578b\u5904\u7406\u590d\u6742\u4efb\u52a1\u80fd\u529b\u7684\u540c\u65f6\uff0c\u5e26\u6765\u4e86\u6027\u80fd\u4e0e\u8d28\u91cf\u7684\u663e\u8457\u6743\u8861\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u5927\u91cf\u65e0\u5173\u4e0a\u4e0b\u6587\u65f6\u6027\u80fd\u975e\u7ebf\u6027\u4e0b\u964d\u3002"}}
{"id": "2601.12996", "categories": ["cs.MA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12996", "abs": "https://arxiv.org/abs/2601.12996", "authors": ["Shiyuan Li", "Yixin Liu", "Yu Zheng", "Mei Li", "Quoc Viet Hung Nguyen", "Shirui Pan"], "title": "OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models", "comment": "Accepted by WWW 2026", "summary": "Multi-Agent Systems (MAS) offer a powerful paradigm for solving complex problems, yet their performance is critically dependent on the design of their underlying collaboration topology. As MAS become increasingly deployed in web services (e.g., search engines), designing adaptive topologies for diverse cross-domain user queries becomes essential. Current graph learning-based design methodologies often adhere to a \"one-for-one\" paradigm, where a specialized model is trained for each specific task domain. This approach suffers from poor generalization to unseen domains and fails to leverage shared structural knowledge across different tasks. To address this, we propose OFA-TAD, a one-for-all framework that generates adaptive collaboration graphs for any task described in natural language through a single universal model. Our approach integrates a Task-Aware Graph State Encoder (TAGSE) that filters task-relevant node information via sparse gating, and a Mixture-of-Experts (MoE) architecture that dynamically selects specialized sub-networks to drive node and edge prediction. We employ a three-stage training strategy: unconditional pre-training on canonical topologies for structural priors, large-scale conditional pre-training on LLM-generated datasets for task-topology mappings, and supervised fine-tuning on empirically validated graphs. Experiments across six diverse benchmarks show that OFA-TAD significantly outperforms specialized one-for-one models, generating highly adaptive MAS topologies. Code: https://github.com/Shiy-Li/OFA-MAS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u7528\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u534f\u4f5c\u62d3\u6251\u751f\u6210\u6846\u67b6OFA-TAD\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u6cdb\u5316\u5dee\u548c\u7ed3\u6784\u5171\u4eab\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9002\u5e94\u591a\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u534f\u4f5c\u62d3\u6251\u8bbe\u8ba1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u56fe\u5b66\u4e60\u7684\u65b9\u6cd5\u9488\u5bf9\u6bcf\u4e2a\u4efb\u52a1\u8bad\u7ec3\u4e13\u95e8\u6a21\u578b\uff0c\u7f3a\u4e4f\u5bf9\u672a\u89c1\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\u548c\u8de8\u4efb\u52a1\u7684\u7ed3\u6784\u5171\u4eab\u3002", "method": "\u8bbe\u8ba1\u4e86\u4efb\u52a1\u611f\u77e5\u56fe\u72b6\u6001\u7f16\u7801\u5668\uff08TAGSE\uff09\u548c\u4e13\u5bb6\u6df7\u5408\uff08MoE\uff09\u67b6\u6784\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u5b9e\u73b0\u6a21\u578b\u7684\u901a\u7528\u5316\u548c\u9002\u5e94\u6027\u3002", "result": "\u5728\u516d\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cOFA-TAD\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u81ea\u9002\u5e94\u6027\u548c\u6cdb\u5316\u6027\u80fd\uff0c\u751f\u6210\u7684\u62d3\u6251\u66f4\u9002\u5408\u591a\u6837\u5316\u4efb\u52a1\u3002", "conclusion": "\u63d0\u51fa\u7684OFA-TAD\u6846\u67b6\u901a\u8fc7\u5355\u4e00\u901a\u7528\u6a21\u578b\u751f\u6210\u9002\u5e94\u4e0d\u540c\u4efb\u52a1\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u534f\u4f5c\u62d3\u6251\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u9488\u5bf9\u5355\u4e00\u4efb\u52a1\u8bad\u7ec3\u7684\u6a21\u578b\u3002"}}
{"id": "2601.11655", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11655", "abs": "https://arxiv.org/abs/2601.11655", "authors": ["Caihua Li", "Lianghong Guo", "Yanlin Wang", "Daya Guo", "Wei Tao", "Zhenyu Shan", "Mingwei Liu", "Jiachi Chen", "Haoyu Song", "Duyu Tang", "Hongyu Zhang", "Zibin Zheng"], "title": "Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey", "comment": "26 pages, 4 figures, 5 tables", "summary": "Issue resolution, a complex Software Engineering (SWE) task integral to real-world development, has emerged as a compelling challenge for artificial intelligence. The establishment of benchmarks like SWE-bench revealed this task as profoundly difficult for large language models, thereby significantly accelerating the evolution of autonomous coding agents. This paper presents a systematic survey of this emerging domain. We begin by examining data construction pipelines, covering automated collection and synthesis approaches. We then provide a comprehensive analysis of methodologies, spanning training-free frameworks with their modular components to training-based techniques, including supervised fine-tuning and reinforcement learning. Subsequently, we discuss critical analyses of data quality and agent behavior, alongside practical applications. Finally, we identify key challenges and outline promising directions for future research. An open-source repository is maintained at https://github.com/DeepSoftwareAnalytics/Awesome-Issue-Resolution to serve as a dynamic resource in this field.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u603b\u7ed3\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u95ee\u9898\u89e3\u51b3\u4e2d\u4eba\u5de5\u667a\u80fd\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u6db5\u76d6\u6570\u636e\u6784\u5efa\u3001\u65b9\u6cd5\u8bba\u3001\u884c\u4e3a\u5206\u6790\u548c\u5e94\u7528\uff0c\u6307\u51fa\u4e86\u5f53\u524d\u6311\u6218\u548c\u672a\u6765\u65b9\u5411\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u8d44\u6e90\u3002", "motivation": "\u7531\u4e8e\u95ee\u9898\u89e3\u51b3\u4f5c\u4e3a\u590d\u6742\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u51fa\u4e86\u4e25\u5cfb\u6311\u6218\uff0c\u4fc3\u8fdb\u4e86\u81ea\u52a8\u7f16\u7801\u4ee3\u7406\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u4e9f\u9700\u5bf9\u8be5\u9886\u57df\u8fdb\u884c\u7cfb\u7edf\u68b3\u7406\u548c\u603b\u7ed3\u3002", "method": "\u672c\u8bba\u6587\u901a\u8fc7\u7cfb\u7edf\u7efc\u8ff0\uff0c\u5206\u6790\u4e86\u6570\u636e\u91c7\u96c6\u4e0e\u5408\u6210\u7ba1\u7ebf\u3001\u65e0\u8bad\u7ec3\u548c\u8bad\u7ec3\u9a71\u52a8\u7684\u65b9\u6cd5\uff08\u5305\u62ec\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u3001\u6570\u636e\u8d28\u91cf\u53ca\u884c\u4e3a\u5206\u6790\uff0c\u5e76\u7ed3\u5408\u5b9e\u9645\u5e94\u7528\u8fdb\u884c\u4e86\u603b\u7ed3\u3002", "result": "\u8bba\u6587\u5168\u9762\u603b\u7ed3\u4e86\u5f53\u524d\u6570\u636e\u6784\u5efa\u3001\u7b97\u6cd5\u65b9\u6cd5\u53ca\u5e94\u7528\u5b9e\u8df5\uff0c\u642d\u5efa\u4e86\u5f00\u653e\u8d44\u6e90\u5e93\uff0c\u6e05\u6670\u9610\u8ff0\u4e86\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u95ee\u9898\u89e3\u51b3\u4efb\u52a1\u9762\u4e34\u8bf8\u591a\u6311\u6218\uff0c\u4f46\u901a\u8fc7\u6570\u636e\u6784\u5efa\u3001\u8bad\u7ec3\u65b9\u6cd5\u548c\u884c\u4e3a\u5206\u6790\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u7f16\u7801\u4ee3\u7406\u7684\u53d1\u5c55\uff0c\u672a\u6765\u9700\u7ee7\u7eed\u89e3\u51b3\u6570\u636e\u8d28\u91cf\u548c\u6a21\u578b\u6cdb\u5316\u7b49\u5173\u952e\u95ee\u9898\u3002"}}
{"id": "2601.11565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11565", "abs": "https://arxiv.org/abs/2601.11565", "authors": ["Pakorn Ueareeworakul", "Shuman Liu", "Jinghao Feng", "Ling Hu", "Zhantang Shi", "Chengqi Sun", "Liang Yao", "Panyi Ouyang", "Haibo Zhang", "Anxiang Zeng"], "title": "Compass-Embedding v4: Robust Contrastive Learning for Multilingual E-commerce Embeddings", "comment": null, "summary": "As global e-commerce rapidly expands into emerging markets, the lack of high-quality semantic representations for low-resource languages has become a decisive bottleneck for retrieval, recommendation, and search systems. In this work, we present Compass-Embedding v4, a high-efficiency multilingual embedding framework specifically optimized for Southeast Asian (SEA) e-commerce scenarios, where data scarcity, noisy supervision, and strict production constraints jointly challenge representation learning. Compass-Embedding v4 addresses three core challenges. First, large-batch contrastive training under mixed task supervision introduces systematic false negatives that degrade semantic alignment. We propose Class-Aware Masking (CAM), a lightweight modification to the InfoNCE objective that suppresses invalid in-batch negatives and improves semantic discrimination without altering training efficiency. Second, low-resource SEA languages suffer from limited and uneven data coverage. We construct a diversified training corpus through context-grounded synthetic data generation, cross-lingual translation, and structured e-commerce data construction, enabling robust multilingual and domain-specific learning. Third, production deployment requires high-throughput inference while preserving embedding quality. We combine robustness-driven large-batch training with spherical model merging to mitigate catastrophic forgetting, and optimize inference via vLLM and FP8 quantization. Extensive evaluations across multilingual benchmarks and proprietary e-commerce tasks show that Compass-Embedding v4 achieves state-of-the-art performance on major SEA languages, significantly outperforming general-purpose embedding models in domain-specific retrieval and classification, while maintaining competitive performance on high-resource languages.", "AI": {"tldr": "Compass-Embedding v4 \u4e13\u4e3a\u4e1c\u5357\u4e9a\u7535\u5546\u8bbe\u8ba1\uff0c\u901a\u8fc7\u521b\u65b0\u8bad\u7ec3\u65b9\u6cd5\u548c\u6570\u636e\u589e\u5f3a\uff0c\u89e3\u51b3\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bed\u4e49\u8868\u793a\u96be\u9898\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u7cbe\u51c6\u7684\u591a\u8bed\u8a00\u5d4c\u5165\u3002", "motivation": "\u4e1c\u5357\u4e9a\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u8bed\u4e49\u8868\u793a\uff0c\u4e25\u91cd\u5f71\u54cd\u7535\u5546\u68c0\u7d22\u548c\u63a8\u8350\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e14\u751f\u4ea7\u73af\u5883\u5bf9\u6a21\u578b\u6548\u7387\u548c\u51c6\u786e\u7387\u6709\u4e25\u683c\u8981\u6c42\u3002", "method": "\u5229\u7528Class-Aware Masking\u6539\u8fdb\u5bf9\u6bd4\u5b66\u4e60\u76ee\u6807\uff0c\u6784\u5efa\u591a\u6837\u5316\u8bad\u7ec3\u8bed\u6599\uff08\u5408\u6210\u6570\u636e\u751f\u6210\u3001\u8de8\u8bed\u8a00\u7ffb\u8bd1\u3001\u7535\u5546\u7ed3\u6784\u5316\u6570\u636e\uff09\uff0c\u7ed3\u5408\u5927\u6279\u91cf\u8bad\u7ec3\u548c\u7403\u9762\u6a21\u578b\u5408\u5e76\u6280\u672f\uff0c\u91c7\u7528vLLM\u548cFP8\u91cf\u5316\u4f18\u5316\u63a8\u7406\u3002", "result": "Compass-Embedding v4 \u5728\u591a\u8bed\u79cd\u57fa\u51c6\u6d4b\u8bd5\u548c\u7535\u5546\u54c1\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u8d85\u8d8a\u901a\u7528\u5d4c\u5165\u6a21\u578b\uff0c\u5728\u4e1c\u5357\u4e9a\u4f4e\u8d44\u6e90\u8bed\u8a00\u4efb\u52a1\u4e0a\u5b9e\u73b0\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u9ad8\u8d44\u6e90\u8bed\u8a00\u7684\u7ade\u4e89\u529b\u3002", "conclusion": "Compass-Embedding v4 \u6210\u529f\u89e3\u51b3\u4e86\u4e1c\u5357\u4e9a\u7535\u5546\u573a\u666f\u4e2d\u7684\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bed\u4e49\u8868\u793a\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u5bf9\u9f50\u5c42\u9762\u7684\u663e\u8457\u6539\u8fdb\uff0c\u5e76\u5728\u751f\u4ea7\u73af\u5883\u4e2d\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2601.13452", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13452", "abs": "https://arxiv.org/abs/2601.13452", "authors": ["Edgar Gonzalez Fernandez"], "title": "A simulation of urban incidents involving pedestrians and vehicles based on Weighted A*", "comment": null, "summary": "This document presents a comprehensive simulation framework designed to model urban incidents involving pedestrians and vehicles. Using a multiagent systems approach, two types of agents (pedestrians and vehicles) are introduced within a 2D grid based urban environment. The environment encodes streets, sidewalks, buildings, zebra crossings, and obstacles such as potholes and infrastructure elements. Each agent employs a weighted A* algorithm for pathfinding, allowing for variation in decision making behavior such as reckless movement or strict rule-following. The model aims to simulate interactions, assess risk of collisions, and evaluate efficiency under varying environmental and behavioral conditions. Experimental results explore how factors like obstacle density, presence of traffic control mechanisms, and behavioral deviations affect safety and travel efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u548c\u52a0\u6743A*\u8def\u5f84\u89c4\u5212\u7684\u57ce\u5e02\u884c\u4eba\u4e0e\u8f66\u8f86\u4eff\u771f\u6846\u67b6\uff0c\u7814\u7a76\u73af\u5883\u56e0\u7d20\u548c\u884c\u4e3a\u5dee\u5f02\u5bf9\u4ea4\u901a\u5b89\u5168\u4e0e\u6548\u7387\u7684\u5f71\u54cd\u3002", "motivation": "\u6a21\u62df\u57ce\u5e02\u4e2d\u884c\u4eba\u548c\u8f66\u8f86\u7684\u4e92\u52a8\uff0c\u4ee5\u8bc4\u4f30\u78b0\u649e\u98ce\u9669\u548c\u51fa\u884c\u6548\u7387\u3002", "method": "\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u5728\u4e8c\u7ef4\u7f51\u683c\u57ce\u5e02\u73af\u5883\u4e2d\u5f15\u5165\u884c\u4eba\u548c\u8f66\u8f86\u4e24\u79cd\u667a\u80fd\u4f53\uff0c\u5e76\u91c7\u7528\u52a0\u6743A*\u7b97\u6cd5\u8fdb\u884c\u8def\u5f84\u89c4\u5212\uff0c\u6a21\u62df\u4e0d\u540c\u7684\u884c\u4e3a\u51b3\u7b56\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u5c55\u793a\u4e86\u969c\u788d\u7269\u5bc6\u5ea6\u3001\u4ea4\u901a\u63a7\u5236\u673a\u5236\u548c\u884c\u4e3a\u504f\u5dee\u7b49\u56e0\u7d20\u5bf9\u5b89\u5168\u6027\u548c\u51fa\u884c\u6548\u7387\u7684\u5f71\u54cd\u3002", "conclusion": "\u8be5\u4eff\u771f\u6846\u67b6\u6709\u6548\u6a21\u62df\u4e86\u57ce\u5e02\u884c\u4eba\u4e0e\u8f66\u8f86\u7684\u4e92\u52a8\uff0c\u4e3a\u8bc4\u4f30\u57ce\u5e02\u4ea4\u901a\u5b89\u5168\u548c\u6548\u7387\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2601.11659", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11659", "abs": "https://arxiv.org/abs/2601.11659", "authors": ["Aaron Adcock", "Aayushi Srivastava", "Abhimanyu Dubey", "Abhinav Jauhri", "Abhinav Pande", "Abhinav Pandey", "Abhinav Sharma", "Abhishek Kadian", "Abhishek Kumawat", "Adam Kelsey", "Adam Stelle", "Adeel Cheema", "Adela Kabiljo", "Adina Katz", "Adithya Gangidi", "Aditya Tayade", "Adolfo Victoria", "Adrian Samatan Alastuey", "Adrien Conrath", "Afroz Mohiuddin", "Ahmed Sharif", "Ahnaf Siddiqui", "Ahuva Goldstand", "Aijung Li", "Aidan Boyd", "Aidin Kazemi Daliri", "Aisha Iqbal", "Ajay Menon", "Ajit Mathews", "Akhil Mathur", "Akshat Agarwal", "Alan Schelten", "Alana Shine", "Alejandro Castillejo Mu\u00f1oz", "Aleksei Guliaev", "Alex Radovic", "Alex Song", "Alex Vaughan", "Alexander Simeonov", "Alexandre Rezende", "Alexandre Rezende", "Alexei Baevski", "Alexey Roubaud", "Allen Ma", "Alvin Lee", "Alyssa Pereira", "Aman Ahmed", "Aman Shankar", "Amanda Kallet", "Amar Budhiraja", "Ameya Khandekar", "Amine Benhalloum", "Amir Gershman", "Amit Nagpal", "Amit Zohar", "Amr Sharaf", "Anant Desai", "Anastasia Razdaibiedina", "Anca Agape", "Andranik Kurghinyan", "Andre Perunicic", "Andrea Madotto", "Andrei Darabanov", "Andr\u00e9s Alvarado", "Andrew Brown", "Andrew Cohen", "Andrew Fang", "Andrew Freeman", "Andrew Gallagher", "Andrew Gu", "Andrew Prasetyo Jo", "Andrew Ryan", "Andrew Steffen", "Andrew Wei", "Andrey Rusakov", "Andrii Golovei", "Andy Shang", "Angela Fan", "Angela Fan", "Angela Flewellen", "Animesh Pathak", "Anirudh Goyal", "Ankit Ramchandani", "Ankur Pai", "Ankur Singh", "Ankush Garg", "Anlu Xing", "Anna Cai", "Anna Grosul", "Anna Prochowska", "Anna Sun", "Annie Dong", "Annie Franco", "Anqi Hu", "Anshul Chawla", "Anthony Hartshorn", "Antonia Sheng", "Antony Thomas", "Anuj Goyal", "Anusha De", "Anvit Bodiwala", "Anvit Bodiwala", "Aobo Yang", "Aparajita Saraf", "Apurva Samudra", "Aran Mun", "Arash Rahnama", "Archi Mitra", "Archie Sravankumar", "Archit Gupta", "Aria Haghighi", "Ariel Stolerman", "Arkabandhu Chowdhury", "Arnab Choudhury", "Artem Korenev", "Arthur Guo", "Arthur Hinsvark", "Arun Mallya", "Arvind Neelakantan", "Arya Talebzadeh", "Ashish Shah", "Ashmitha Jeevaraj Shetty", "Ashwin Bharambe", "Asif Islam", "Aston Zhang", "Austen Gregerson", "Avi Lewis", "Aya Ibrahim", "Ayaz Minhas", "Ayelet Dahan", "Ayelet Regev Dabah", "Bangsheng Tang", "Bar Ulman", "Bardiya Sadeghi", "Bartosz Jedrzejewski", "Barys Skarabahaty", "Beibei Zhu", "Beibin Li", "Ben Bharier", "Benjamin Leonhardi", "Benjamin Muller", "Bennett Plessala", "Bernie Huang", "Beth Loyd", "Bhargavi Paranjape", "Bhavik Sheth", "Bill Bonner", "Bill Holland", "Bill Wang", "Bingzhe Liu", "Binh Tang", "Bo Liu", "Bo Wu", "Boduo Li", "Bokai Yu", "Bor-Chun Chen", "Boris Araya", "Boris Vidolov", "Botao Chen", "Boya Peng", "Boyu Ni", "Bradley Davis", "Bram Wasti", "Brandon Adams", "Brandon Taylor", "Brandon Wu", "Brant Swidler", "Brian Chiang", "Brian Clerkin", "Brian Fuller", "Brooks Cutter", "Bruno Novais", "Bryan Gmyrek", "Bysshe Easton", "Cait Campos", "Canaan Case", "Carl Chengyan Fu", "Carly Burton", "Caro Diaz", "Catherine Cole", "Ce Liu", "Cedric Fougerat", "Cen Peng", "Cen Peng", "Cen Zhao", "Changhan Wang", "Changkyu Kim", "Chantal Shaib", "Chao Zhou", "Charlotte Caucheteux", "Chau Nguyen", "Chawin Sitawarin", "Chaya Nayak", "Chelsea Asher", "Chen Fan", "Chen Zhu", "Cheng Cheng", "Cheng Zhang", "Chenguang Zhu", "Chengxiong Ruan", "Chengzhu Yu", "Chenheli Hua", "Chenxi Whitehouse", "Cheryl Holloway", "Ching-Hsiang Chu", "Ching-Yao Chuang", "Chinmay Karande", "Chirag Nagpal", "Chlo\u00e9 Bakalar", "Chloe Bi", "Chris Cai", "Chris Marra", "Chris McConnell", "Chris Thi", "Chris Tindal", "Chris Waterson", "Christian Deverall", "Christian Fuegen", "Christian Keller", "Christine Cheng", "Christine Jou", "Christine Smith", "Christine Wang", "Christoph Feichtenhofer", "Christophe Touret", "Christopher Luc", "Christy Sauper", "Chuanhao Zhuge", "Chun-Yi Sung", "Chunqiang Tang", "Chunyang Wu", "Clara Siegel", "Cody Heale", "Cody Wilbourn", "Colin White", "Congying Xia", "Corinne Wong", "Cornel Rat", "Cristian Canton Ferrer", "Cyrille Habis", "Cyrus Nikolaidis", "D Lohachov", "Da Ju", "Dalton Flanagan", "Damien Allonsius", "Damon Civin", "Dan Johnson", "Daniel Bolya", "Daniel Francisco", "Daniel Fried", "Daniel Hawthorne", "Daniel Haziza", "Daniel Ho", "Daniel Kreymer", "Daniel Li", "Daniel Machlab", "Daniel McKinnon", "Daniel Obenshain", "Daniel Rodriguez", "Daniel Song", "Daniel Tse", "Danielle Pintz", "Danny Livshits", "Daryl James Rodrigo", "Dat Huynh", "Daulet Askarov", "David Brandfonbrener", "David Esiobu", "David Kant", "David Levin", "David Renardy", "David Soofian", "David Stevens", "David Xu", "David Zhang", "Deep Shah", "Delia David", "Demi Douglas", "Denis Boyda", "Desh Raj", "Devamanyu Hazarika", "Dheeraj Mekala", "Dhruv Choudhary", "Dhruv Mahajan", "Di Jin", "Didac Suris Coll-Vinent", "Didem Foss", "Diego Garcia-Olano", "Diego Perino", "Dieuwke Hupkes", "DiJia Su", "Dilip Madathil", "Dinesh Govindasamy", "Dinesh Yeduguru", "Dmitry Vengertsev", "Dong He", "Dong Li", "Dong Wang", "Dongzhuo Li", "Duc Le", "Dunant Hin", "Dustin Holland", "Duy Nguyen", "Duy Nguyen", "Ed Dowling", "Eden Litt", "Egor Lakomkin", "Ehab AlBadawy", "Ehsan K. Ardestani", "Elad Eckstein", "Elahe Dabir", "Elaine Montgomery", "Elina Lobanova", "Elior Abramoviz", "Eliot Hedeman", "Elissa Li", "Elizabeth Hilbert", "Ellen Xiaoqing Tan", "Elliot Yun", "Elodie Stener", "Emilian Stoimenov", "Emilien Garreau", "Emily Dinan", "Emily Hahn", "Emily Wood", "Emma Li", "Emmanuel Ademuwagun", "Emrah Seker", "Eric Alamillo", "Eric Gan", "Eric Han", "Eric Huang", "Eric Michael Smith", "Eric-Tuan Le", "Ernie Chang", "Eryk Helenowski", "Eslam Elnikety", "Esteban Arcaute", "Ethan Myers", "Eugene Nho", "Eugene Poliukhovych", "Evan Dunbar", "Evgeniy Litvinenko", "Evrim Alt\u0131nta\u015f", "Eyal Hochman", "Eyal Shtrauch", "Fabian Mastenbroek", "Faiza Zeb", "Faizan Ahmad", "Farhad Farahbakhshian", "Fei Kou", "Fei Sun", "Feiyu Chen", "Felix Chung", "Feng Tian", "Feng Xu", "Filip Radenovic", "Filippos Kokkinos", "Francesco Barbieri", "Francesco Caggioni", "Francisco Esparza", "Francisco Guzm\u00e1n", "Frank Kanayet", "Frank Seide", "Frank Zhang", "Fred Lewis", "Freda Huang", "Fulton Wang", "Gabriel Synnaeve", "Gabriela Jacques-Silva", "Gabriella Schwarz", "Gaganjit Ghardhora", "Gal Elfer", "Garrett Dickson", "Gaurav Chaurasia", "Gautam Sewani", "Geet Shingi", "Gefei Zuo", "Geonhwa Jeong", "George Puthanpurackal", "Georgia Swee", "Gerard Moreno-Torres Bertran", "Gil Keren", "Gina Ling", "Gjergji Stasa", "Gobinda Saha", "Gor Safran", "Gordy French", "Goutham Rajendran", "Govind Thattai", "Grace Cineas", "Graeme Nail", "Greg Fletcher", "Gr\u00e9goire Mialon", "Griffin Adams", "Grigory Sizov", "Guan Pang", "Hady Elsahar", "Hai Dang Tran", "Hailey Nguyen", "Haiping Wu", "Hakan Inan", "Hamid Eghbalzadeh", "Han Fang", "Han Zou", "Hannah Doyle", "Hannah Korevaar", "Hannah Wang", "Hannah Werbel", "Hanwen Zha", "Hany Morsy", "Hao Ma", "Haoci Zhang", "Haonan Sun", "Haozhu Wang", "Hardik Shah", "Haroun Habeeb", "Harrison Rudolph", "Harsh Gupta", "Harsh Poddar", "Harshil Parikh", "Hejia Zhang", "Heming Wang", "Hengduo Li", "Himanshu Sharma", "Hoang Phi Nguyen", "Hongbo Zhang", "Honghao Qiu", "Hongjiang Lv", "Hongli Xu", "Hongyuan Zhan", "Hossein Hamooni", "Howard Huang", "Hu Xu", "Hugo Lauren\u00e7on", "Hugo Touvron", "Hung Dinh", "Hunter Goldman", "Hussein Mehanna", "Huy Nguyen", "Hweimi Tsuo", "Ian Graves", "Ian Yu", "Ibrahim Damlaj", "Idan Cohen", "Igor Tufanov", "Ilan Goldenstein", "Ilias Leontiadis", "Iliyan Zarov", "Imad Ahmed", "Innocent Djiofack", "Iosif Spulber", "Irina-Elena Veliche", "Isabella Ramos", "Ishan Misra", "Itai Gal", "Ivan Evtimov", "Ivan Evtimov", "Ivan Obraztsov", "Jack Wu", "Jacqueline Romero Vertino", "Jaemo Koo", "Jaewon Lee", "Jake Jung", "Jake Weissman", "James Beldock", "James Crnkovich", "James Grinage", "James Hongyi Zeng", "James Kohli", "James Tian", "Jamie Cahill", "Jan Geffert", "Jan Seidel", "Jan Seidel", "Janey Tracey", "Jang Hyun Cho", "Janice Wei", "Jarrod Kahn", "Jasmyn Howell", "Jason Long Vu", "Jason Park", "Jason Yan", "Jason Yip", "Jay Li", "Jay Mahadeokar", "Jaya Bharath R Goluguri", "Jayasi Mehar", "Jean-Baptiste Gaya", "Jeet Shah", "Jeff Hanson", "Jeff Marcus", "Jeff Walsh", "Jeff Yang", "Jelmer van der Linde", "Jemma Fan", "Jennifer Chan", "Jenny Zhen", "Jenya Lee", "Jeremy Fu", "Jeremy Reizenstein", "Jeremy Teboul", "Jesse He", "Jessica Zhong", "Ji Hou", "Ji Yang", "Jia Ding", "Jiabo Hu", "Jiacheng Zhu", "Jiadong Guo", "Jialiang Wang", "Jialin Ouyang", "Jianfeng Chi", "Jianyu Huang", "Jianyun Zhao", "Jiaowen Yang", "Jiatong Zhou", "Jiawei Zhao", "Jiawen Liu", "Jie Wang", "Jie You", "Jiecao Yu", "Jillian Schwiep", "Jilong Wu", "Jing Huang", "Jing Li", "Jing Yu Koh", "Jing Zhang", "Jingxiang Chen", "Jingyi Yang", "Jingyue Shen", "Jinho Hwang", "Jinxi Guo", "Jiwan Khatiwada", "Joanna Bitton", "Joe Li", "Joe Quanaim", "Joel Beales", "Johan Schuijt", "John Chang", "John Quan", "Johnnie Chan", "Jon Shepard", "Jona Harris", "Jonah Rubin", "Jonathan Janzen", "Jonathan Kaldor", "Jorge Lopez Silva", "Jose Leitao", "Joseph Greer", "Joseph Moon", "Joseph Rocca", "Joseph Tighe", "Josh Fromm", "Joshua Deng", "Joshua Fernandes", "Joshua Saxe", "Joyce Zheng", "Juan Pino", "Julien Prigent", "Jun Chen", "Junjiao Tian", "Junjie Qi", "Junjie Wang", "Junteng Jia", "Kade Baker", "Kai Londenberg", "Kai Wang", "Kainan Peng", "Kaiyan Peng", "Kaiyue Yang", "Kalyan Vasudev Alwala", "Kam Hou Yu", "Kanika Narang", "Karan Chadha", "Karan Sikka", "Karen Zhang", "Karina Schuberts", "Karishma Mandyam", "Karthik Abinav Sankararaman", "Karthik Padthe", "Karthik Prasad", "Karthik Sivakumar", "Kartikeya Upasani", "Kate Plawiak", "Kate Saenko", "Kate\u0159ina \u017dmol\u00edkov\u00e1", "Kathryn Stadler", "Kathy Matosich", "Katie Doulgass", "Kaveh Hassani", "Kay Ji", "Ke Li", "Kenneth Heafield", "Kenny Yu", "Keqian Li", "Kevin Chih-Yao Ma", "Kevin Hannan", "Keyu Man", "Kezhen Chen", "Khalid El-Arini", "Khrystyna Hutsulyak", "Kieran Nash", "Kiran Jagadeesh", "Kody Bartelt", "Konstantin Topaloglou-Mundy", "Konstantinos Chatziioannou", "Konstantinos Karanasos", "Konstantinos Vougioukas", "Kostas Tsiampouris", "Kristen Hamill", "Kristy Choi", "Krithika Iyer", "Kshitiz Malik", "Kuenley Chiu", "Kun Huang", "Kunal Bhalla", "Kunal Chawla", "Kunpeng Li", "Kushal Lakhotia", "Kyle Monk", "Lakshya Garg", "Lalit Chourey", "Lars Hamre", "Laura Gustafson", "Lauren Deason", "Laurence Rouesnel", "Laurens van der Maaten", "Lavender A", "Lawrence Chen", "Lawrence Jang", "Leandro Silva", "Leda Sari", "Lee Hetherington", "Lei Zhang", "Leiyu Zhao", "Lele Chen", "Leo Chenghui Li", "Leon Yang", "Leon Zhan", "Levi Corallo", "Liang Tan", "Licheng Yu", "Lijuan Liu", "Lilach Mor", "Lincoln Lin", "Linfeng Li", "Lisa Titus", "Liz Jenkins", "Lovish Madaan", "Lu Fang", "Lu Yuan", "Lucas Nava", "Lucas Pasqualin", "Lucas Switzer", "Lucia Fang", "Lucy Sun", "Luka Tadic", "Lukas Blecher", "Lukas Landzaat", "Luxin Zhang", "Madhavi Rao", "Madian Khabsa", "Mahalia Miller", "Mahendra Kariya", "Mahesh Pasupuleti", "Mahi Luthra", "Manaal Faruqui", "Manav Avlani", "Manchen Wang", "Mannat Singh", "Manohar Paluri", "Manoj Chakkaravarthy", "Manoj Nair", "Maquelle Tiffany", "Marcin Pawlowski", "Marcus Wu", "Maria Lomeli", "Mario Consuegra", "Marion Boiteux", "Marios Andreas Galanis", "Marshall Chen", "Martin Gleize", "Maryam Fazel-Zarandi", "Matan Hasson", "Mathew Oldham", "Mathieu Rita", "Matt Dordal", "Matt Setzler", "Matt Staats", "Matt Staats", "Matt Wilde", "Matthew Clark", "Matthew Grange", "Matthew Lennie", "Matthew Schmohl", "Max Raphael", "Maxim Naumov", "Maxim Samoylov", "Maxime Lecanu", "Maya Pavlova", "Md Taha Bin Jawaid", "Meghan Keneally", "Melanie Kambadur", "Meng Zhang", "Mengchen Liu", "Mengdi Lin", "Mengjiao Wang", "Mervyn Abraham", "Miao Liu", "Michael Au-Yeung", "Michael Feldergraf", "Michael Man", "Michael Matheny", "Michael Suo", "Michael Tontchev", "Michel Meyer", "Michelle Ma", "Mihir Patel", "Mihir Sanjay Kale", "Mik Vyatskov", "Mikayla Alexander", "Mike Andersland", "Mike Clark", "Mike Lewis", "Mike Li", "Mike Macey", "Mike Macey", "Mike Seltzer", "Mikel Jimenez Fernandez", "Mikhail Antonov", "Mikhail Plekhanov", "Milan Zhou", "Min Si", "Ming Qiao", "Mingbo Ma", "Mingjun Zhang", "Mingyi Liang", "Miquel Jubert Hermoso", "Mirac Suzgun", "Mirjam Skarica", "Mitesh Kumar Singh", "Mohammad Kabbani", "Mohammad Rastegari", "Mona Sarantakos", "Monica Sim", "Monika Gangapuram", "Mor Moshe", "Morrie Doulaty", "Morvarid Metanat", "Moya Chen", "Mrinal Kumar", "Munish Bansal", "Murali Ramarao", "Na Li", "Nadav Azaria", "Nahiyan Malik", "Naman Goyal", "Nancy Vargas Balderas", "Nanshu Wang", "Naoyuki Kanda", "Natalia Gimelshein", "Natalia Neverova", "Nathan Aclander", "Natt Sithiviraporn", "Navneet Madhu Kumar", "Ned Newton", "Neeraj Bahl", "Negar Ghorbani", "Neil Patel", "Neta-lee Golan", "Nicholas Longenbaugh", "Nick Egebo", "Nikhil Johri", "Nikhil Mehta", "Nikhil Naik", "Niko Moritz", "Nikolay Bashlykov", "Nikolay Bogoychev", "Nikolay Pavlovich Laptev", "Niladri Chatterji", "Nile Jones", "Nimish Shah", "Ning Dong", "Ning Li", "Ning Li", "Ning Zhang", "Nishant Yadav", "Noam Paz", "Norman Cheng", "Norman Cheng", "Olaoluwa Adesanya", "Oleg Repin", "Oleksandr Maksymets", "Omkar Salpekar", "Omri Harosh", "Onkar Pednekar", "Onur \u00c7elebi", "Oran Gafni", "Oren Edinger", "Osama Hanna", "Owais Khan Mohammed", "Ozlem Kalinli", "Paden Tomasello", "Pankaj Singh", "Paola Quevedo", "Parag Jain", "Paria Rashidinejad", "Parker Tooley", "Parth Parekh", "Parth Thakkar", "Parvin Taheri", "Pasan Hapuarachchi", "Pascal Kesseli", "Patrick Alrassy", "Paulo de Rezende Pinatti", "Pavan Balaji", "Pawan Sisodiya", "Pedro Jose Ferreira Moreira", "Pedro Rittner", "Pedro Valenzuela", "Peize Sun", "Peizhao Zhang", "Peng-Jen Chen", "Pengchao Wang", "Pengchuan Zhang", "Pengwei Li", "Petar Vasic", "Peter Carras", "Peter Ney", "Peter Weng", "Petru Dumea", "Phil Hayes", "Philip Woods", "Pierre Andrews", "Pierre M\u00e9nard", "Ping-Hao Wu", "Pingchuan Liu", "Piotr Dollar", "Plamen Dzhelepov", "Polina Zvyagina", "Posten A", "Prabhav Agrawal", "Pradhapan Rajendran", "Pradyot Prakash", "Prajjwal Bhargava", "Pramono", "Pranay Shah", "Pranshu Dave", "Prash Jain", "Pratik Dubal", "Praveen Gollakota", "Praveen Krishnan", "Pritish Yuvraj", "Projjal Ghosh", "Punit Singh Koura", "Puxin Xu", "Qi Qi", "Qi Zhou", "Qian Guan", "Qian Sun", "Qiang Liu", "Qing He", "Qinqing Zheng", "Qirui Yang", "Qizhen Guo", "Quanzeng You", "Quentin Carbonneaux", "Quentin Carbonneaux", "Quentin Duval", "Quintin Fettes", "Rachad Alao", "Rachel Batish", "Rachel Guo", "Rachel Rodriguez", "Radhika Bhargava", "Rafael Asuncion", "Raghotham Murthy", "Rahul Dutta", "Rahul Jha", "Rahul Kindi", "Rahul Mitra", "Raj Ganapathy", "Raj Shah", "Rajarshi Das", "Rajat Shrivastava", "Rajesh Nishtala", "Ramakant Shankar", "Raman Shukhau", "Ramon Calderer", "Rangaprabhu Parthasarathy", "Ranjan Subramanian", "Raphael Bensadoun", "Rares Bostan", "Rashnil Chaturvedi", "Ravi Agrawal", "Ray Gao", "Raymond Li", "Rebecca Kogen", "Ricardo Juan Palma Duran", "Ricardo Silveira Cabral", "Richard Lee", "Richard Yuanzhe Pang", "Riddhish Bhalodia", "Riham Mansour", "Rishabh Singh", "Rishi Godugu", "Ritun Patney", "Rob Boyle", "Robbie Goldfarb", "Robert Caldwell", "Robert Kuo", "Roberta Raileanu", "Robin Battey", "Robin Sharma", "Rochit Sapra", "Rocky Wang", "Rodolfo Granata", "Rodrigo De Castro", "Rodrigo Paim", "Rohan Maheshwari", "Rohan Varma", "Rohit Girdhar", "Rohit Patel", "Roshan Sumbaly", "Roy Sheaffer", "Ruan Silva", "Ruben Rodriguez Buchillon", "Rui Hou", "Ruiming Xie", "Ruslan Mavlyutov", "Ruslan Semenov", "Rustam Dinov", "Ruxiao Bao", "Ryan Fox", "Ryan Kilpatrick", "Ryan Kwan", "Ryan Lim", "Ryan Smith", "Saaketh Narayan", "Sabrina Qiao", "Sachin Mehta", "Sachin Siby", "Sagar Jain", "Saghar Hosseini", "Sagie Gur-Ari", "Sahana Chennabasappa", "Sahin Geyik", "Sai Jayesh Bondu", "Sai Mounika Chowdhary Nekkalapudi", "Saif Hasan", "Saisuke Okabayashi", "Saketh Rambhatla", "Salil Sawhney", "Sam Dunster", "Sam Zhao", "Saman Keon", "Samaneh Azadi", "Sameet Sapra", "Samuel Dooley", "Samyak Datta", "Sandeep Parab", "Sang Michael Xie", "Sanjay Singh", "Sanyuan Chen", "Sara Behn", "Sara Khodeir", "Sarah Shirazyan", "Sargun Dhillon", "Sarunya Pumma", "Sasha Sidorov", "Saskia Adaime", "Saurabh Khanna", "Sayem Wani", "Scott Brenton", "Sean Bell", "Sean Kelly", "Sean Koger", "Sean Nunley", "Sean Perry", "Sebastian Caicedo", "Sebastian Dahlgren", "Sebastian Ruder", "Seiji Yamamoto", "Selam Mehretu", "Selvan Sunitha Ravi", "Sen Lyu", "Senthil Chellapan", "Serafeim Mellos", "Sergey Edunov", "Sergey Royt", "Shaina Cohen", "Shangfu Peng", "Shannon Adams", "Shaoliang Nie", "Sharadh Ramaswamy", "Sharan Narang", "Shashank Pisupati", "Shashi Gandham", "Shaun Lim", "Shaun Lindsay", "Sheena Artrip", "Shelly Sheynin", "Shen Yan", "Sheng Feng", "Sheng Shen", "Shengbao Zheng", "Shenghao Lin", "Shengjie Bi", "Shengxin Cindy Zha", "Shengye Wan", "Shengyi Qian", "Shengyong Cai", "Shengzhi Shao", "Shervin Shahidi", "Shikai Li", "Shimon Bernholtz", "Shiqi Wang", "Shishir G. Patil", "Shiv Verma", "Shiva Shankar P", "Shiyang Chen", "Sho Yaida", "Shoubhik Debnath", "Shreyas Siravara", "Shruti Bhosale", "Shuang Ma", "Shun Zhang", "Shuo Tang", "Shuqiang Zhang", "Shuyan Zhou", "Sicong Che", "Sidd Srinivisan", "Siddharth Bhattacharya", "Siddharth Patki", "Sijia Chen", "Sili Chen", "Simon Vandenhende", "Simone Merello", "Sinong Wang", "Sivan Barzily", "Sixian Yi", "Siyu Lin", "SK Bong", "Sky Yin", "Sneha Agarwal", "Sneha Agarwal", "Soerian Lieve", "Soji Sajuyigbe", "Song Jiang", "Songlin Li", "Sonia Kim", "Sopan Khosla", "Soumi Maiti", "Spencer Whitman", "Sravya Popuri", "Sreen Tallam", "Srinivas Vaidyanathan", "Srinivas Vaidyanathan", "Sten Sootla", "Stephane Collot", "Stephanie Ding", "Stephen Chen", "Steven Cai", "Suchin Gururangan", "Sudarshan Govindaprasad", "Sue Young", "Suganthi Dewakar", "Sujan Kumar Gonugondla", "Sujeet Bhandari", "Suman Gumudavelli", "Suman Gumudavelli", "Sumit Gupta", "Summer Deng", "Sungmin Cho", "Suresh Ganapathy", "Surjyendu Dhal", "Susan Fedynak", "Susana Contrera", "Suyoun Kim", "Sylvestre Rebuffi", "Takshak Chahande", "Tamar Herman", "Tan Li", "Tao Xu", "Tara Fowler", "Tarek Sheasha", "Tarun Anand", "Tarun Kalluri", "Tarun Singh", "Tatiana Shavrina", "Ted Li", "Teja Rao", "Tejas Patil", "Teng Li", "Thach Bui", "Thai Quach", "Thamer Alharbash", "Thanh Vinh Vo", "Thawan Kooburat", "Thilo Koehler", "Thomas Georgiou", "Thomas Scialom", "Tian Ye", "Tianhe Li", "Tianjun Zhang", "Tianyu Li", "Tijmen Blankevoort", "Timon Willi", "Timothy Chou", "Timothy Leung", "TJ Lee", "Todor Mihaylov", "Tom Heatwole", "Tong Xiao", "Tony Cao", "Tony Lee", "Trang Le", "Tristan Rice", "Tsz Kei Serena Chan", "Tuan Tran", "Tudor Tiplea", "Tyler Baumgartner", "Uday Savagaonkar", "Ujjwal Karn", "Ulises Martinez Araiza", "Umar Farooq", "Uriel Cohen", "Usman Sharif", "Utkarsh Murarka", "Van Phung", "Varun Joginpalli", "Varun Saravagi", "Vasu Sharma", "Vasudha Viswamurthy", "Vedanuj Goswami", "Vedika Seth", "Venkat Ramesh", "Venkat Ramesh", "Vibhor Gupta", "Victoria Montanez", "Vidhya Natarajan", "Vidya Sarma", "Vignesh Ramanathan", "Viktor Kerkez", "Vinay Rao", "Vincent Gonguet", "Vincent Mauge", "Virginie Do", "Vish Vogeti", "Vishrav Chaudhary", "Viswesh Sankaran", "V\u00edtor Albiero", "Vivek Miglani", "Vivek Pai", "Vlad Cojanu", "Vlad Shubin", "Vlad Tiberiu Mihailescu", "Vladan Petrovic", "Vladimir Ivanov", "Vladislav Vorotilov", "Vrushali Bhutada", "Wai I Ng", "Wei Cheng", "Wei Sun", "Wei Tu", "Wei Wei", "Wei Zhou", "Wei-Ning Hsu", "Weiwei Chu", "Weizhe Yuan", "Wenchen Wang", "Wenjun Zhao", "Wenwen Jiang", "Wenyin Fu", "Wenzhe Jiang", "Whitney Meers", "Will Constable", "Will Wang", "William R. Wong", "Xavier Martinet", "Xi Victoria Lin", "Xi Yan", "Xi Yin", "Xian Li", "Xianfeng Rui", "Xianjun Yang", "Xiaocheng Tang", "Xiaodong Wang", "Xiaofang Wang", "Xiaolan Wang", "Xiaoliang Dai", "Xiaoliang Peng", "Xiaopeng Li", "Xiaozhu Meng", "Xibei Zhang", "Xide Xia", "Xin Jin", "xinbo Gao", "Xinfeng Xie", "Xingyi Zhou", "Xu Ma", "Xuan Ju", "Xuanyi Zhao", "Xubo Liu", "Xuchao Jia", "Xuedong Zhang", "Xuefei Cao", "Xuewei Wang", "Xuewei Wu", "Xunnan Xu", "Xutai Ma", "Xuyang Wang", "Yan Cui", "Yang Chen", "Yang Li", "Yang Shu", "Yang Xia", "Yanjun Chen", "Yanjun Zhou", "Yash Mehta", "Yash Patel", "Yash Tekena", "Yashesh Gaur", "Yasmine Babaei", "Yaxuan Zhou", "Ye Hu", "Ye Qi", "Yejin Lee", "Yeming Wen", "Yen-Cheng Liu", "Yexin Bruce Wu", "Yi Pan", "Yi Yang", "Yi-Hui Lin", "Yifan Wang", "Yifan Wu", "Yifan Yang", "Yifei Huang", "Yiftah Ben Aharon", "Yilin Yang", "Yiling You", "Ying Xu", "Ying Zhang", "Yingquan Yuan", "Yingru Liu", "Yingyi Ma", "Yining Yang", "Yiting Lu", "Yonatan Komornik", "Yongjie Lin", "Yoni Goyhman", "Yossi Moran Mamo", "Youngjin Nam", "Yu Wang", "Yu Lu", "Yu Zhao", "Yu-Ho Hsieh", "Yu-Jung Lo", "Yuandong Tian", "Yuanhan Zhang", "Yuanhao Xiong", "Yuanshun Yao", "Yuchen Hao", "Yuchen Zhang", "Yuchuan Li", "Yue Cao", "Yue Yu", "Yue Zhao", "Yuhan Guo", "Yuhao Wang", "Yuheng Huang", "Yujie Lu", "Yujun Shi", "Yulun Wang", "Yun He", "Yun Wang", "Yundi Qian", "Yunfan Wang", "Yunhao Tang", "Yuning Mao", "Yunlu Li", "Yuqi Dai", "Yuriy Hulovatyy", "Yushi Hu", "Yuxuan Sun", "Zach Rait", "Zach Wentz", "Zacharie Delpierre Coudert", "Zachary Collins", "Zahra Hankir", "Zecheng He", "Zeeshan Ahmed", "Zeeshan Ahmed", "Zef RosnBrick", "Zhan Shu", "Zhanna Rohalska", "Zhaoduo Wen", "Zhe Liu", "Zhe Liu", "Zhen Qiao", "Zhenggang Xu", "Zhengwen Zhou", "Zhengxing Chen", "Zhenyu Tang", "Zhichen Wu", "Zhicheng Ouyang", "Zhihong Lei", "Zhipeng Hong", "Zhiping Xiu", "Zhiwei Zhao", "Zhong Meng", "Zhou Jin", "Zhouhao Zeng", "Zichang Liu", "Zihang Meng", "Zihuan Qiao", "Zinnia Zheng", "Zixi Qi", "Ziyi Luo", "Zoe Foulkes Birkhead", "Zoey Sun", "Zohar Achdut"], "title": "The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes", "comment": "15 pages", "summary": "This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.", "AI": {"tldr": "\u672c\u6587\u6574\u5408\u4e86\u516c\u5f00\u4fe1\u606f\uff0c\u7cfb\u7edf\u603b\u7ed3\u4e86Metas Llama 4\u6a21\u578b\u7684\u67b6\u6784\u3001\u8bad\u7ec3\u3001\u6027\u80fd\u53ca\u90e8\u7f72\u7b49\u6280\u672f\u7ec6\u8282\uff0c\u63d0\u4f9b\u6743\u5a01\u53c2\u8003\u3002", "motivation": "\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5b9e\u8df5\u8005\u63d0\u4f9bLlama 4\u6a21\u578b\u7684\u7cbe\u786e\u3001\u57fa\u4e8e\u6765\u6e90\u7684\u6280\u672f\u53c2\u8003\u3002", "method": "\u6574\u5408\u5e76\u603b\u7ed3\u4e86\u516c\u5f00\u62a5\u9053\u7684Metas Llama 4\u6a21\u578b\u7cfb\u5217\u7684\u6280\u672f\u7ec6\u8282\uff0c\u5305\u62ec\u6a21\u578b\u53d8\u4f53\u3001\u67b6\u6784\u7279\u5f81\u3001\u8bad\u7ec3\u8fc7\u7a0b\u3001\u6027\u80fd\u57fa\u51c6\u53ca\u90e8\u7f72\u9650\u5236\u3002", "result": "\u8be6\u7ec6\u63cf\u8ff0\u4e86Llama 4\u7684\u591a\u4e2a\u7248\u672c\uff08Scout\u3001Maverick\u53caBehemoth\u6559\u5e08\u6a21\u578b\uff09\u3001\u67b6\u6784\u8bbe\u8ba1\uff08MoE\u3001\u591a\u6a21\u6001\u878d\u5408\u3001\u957f\u4e0a\u4e0b\u6587\u652f\u6301\uff09\u3001\u8bad\u7ec3\u65b9\u6cd5\uff08\u9884\u8bad\u7ec3\u3001\u4e2d\u671f\u8bad\u7ec3\u53ca\u540e\u671f\u5fae\u8c03\uff09\u3001\u6027\u80fd\u8868\u73b0\u53ca\u5b9e\u9645\u90e8\u7f72\u9650\u5236\uff0c\u5e76\u603b\u7ed3\u4e86\u76f8\u5173\u8bb8\u53ef\u548c\u5b89\u5168\u63aa\u65bd\u3002", "conclusion": "\u672c\u6587\u4e3aLlama 4\u6a21\u578b\u63d0\u4f9b\u4e86\u5168\u9762\u4e14\u6743\u5a01\u7684\u6280\u672f\u6c47\u603b\uff0c\u4fbf\u4e8e\u76f8\u5173\u4eba\u5458\u51c6\u786e\u4e86\u89e3\u5176\u67b6\u6784\u548c\u5e94\u7528\u7ec6\u8282\u3002"}}
{"id": "2601.11567", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11567", "abs": "https://arxiv.org/abs/2601.11567", "authors": ["Vanessa D'Amario", "Randy Daniel", "Alessandro Zanetti", "Dhruv Edamadaka", "Nitya Alaparthy", "Joshua Tarkoff"], "title": "Measuring Stability Beyond Accuracy in Small Open-Source Medical Large Language Models for Pediatric Endocrinology", "comment": "20 pages, 11 figures, accepted at 47 workshop Reproducible Artificial Intelligence (AAAI 2026, Singapore, January 27, 2026)", "summary": "Small open-source medical large language models (LLMs) offer promising opportunities for low-resource deployment and broader accessibility. However, their evaluation is often limited to accuracy on medical multiple choice question (MCQ) benchmarks, and lacks evaluation of consistency, robustness, or reasoning behavior. We use MCQ coupled to human evaluation and clinical review to assess six small open-source medical LLMs (HuatuoGPT-o1 (Chen 2024), Diabetica-7B, Diabetica-o1 (Wei 2024), Meditron3-8B (Sallinen2025), MedFound-7B (Liu 2025), and ClinicaGPT-base-zh (Wang 2023)) in pediatric endocrinology. In deterministic settings, we examine the effect of prompt variation on models' output and self-assessment bias. In stochastic settings, we evaluate output variability and investigate the relationship between consistency and correctness. HuatuoGPT-o1-8B achieved the highest performance. The results show that high consistency across the model response is not an indicator of correctness, although HuatuoGPT-o1-8B showed the highest consistency rate. When tasked with selecting correct reasoning, both HuatuoGPT-o1-8B and Diabetica-o1 exhibit self-assessment bias and dependency on the order of the candidate explanations. Expert review of incorrect reasoning rationales identified a mix of clinically acceptable responses and clinical oversight. We further show that system-level perturbations, such as differences in CUDA builds, can yield statistically significant shifts in model output despite stable accuracy. This work demonstrates that small, semantically negligible prompt perturbations lead to divergent outputs, raising concerns about reproducibility of LLM-based evaluations and highlights the output variability under different stochastic regimes, emphasizing the need of a broader diagnostic framework to understand potential pitfalls in real-world clinical decision support scenarios.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u516d\u79cd\u5c0f\u578b\u5f00\u6e90\u533b\u5b66\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u548c\u63a8\u7406\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u8f93\u51fa\u7a33\u5b9a\u6027\u4e0d\u8db3\u548c\u81ea\u6211\u8bc4\u4f30\u504f\u5dee\uff0c\u5f3a\u8c03\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u5c40\u9650\u53ca\u4e34\u5e8a\u5e94\u7528\u4e2d\u7684\u6f5c\u5728\u98ce\u9669\u3002", "motivation": "\u73b0\u6709\u533b\u5b66LLM\u8bc4\u4f30\u591a\u5c40\u9650\u4e8e\u51c6\u786e\u7387\uff0c\u7f3a\u5c11\u5bf9\u4e00\u81f4\u6027\u3001\u9c81\u68d2\u6027\u548c\u63a8\u7406\u884c\u4e3a\u7684\u5168\u9762\u8bc4\u4f30\uff0c\u4e14\u8bc4\u4f30\u7684\u53ef\u91cd\u590d\u6027\u5b58\u5728\u95ee\u9898\uff0c\u9700\u6784\u5efa\u66f4\u5168\u9762\u7684\u8bca\u65ad\u6846\u67b6\u4ee5\u652f\u6301\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u901a\u8fc7\u591a\u9879\u9009\u62e9\u9898\u7ed3\u5408\u4eba\u5de5\u8bc4\u4f30\u548c\u4e34\u5e8a\u5ba1\u6838\uff0c\u9488\u5bf9\u516d\u4e2a\u5c0f\u578b\u5f00\u6e90\u533b\u5b66LLM\u8fdb\u884c\u513f\u79d1\u5185\u5206\u6ccc\u5b66\u9886\u57df\u7684\u6d4b\u8bd5\uff0c\u5206\u6790\u63d0\u793a\u53d8\u5f02\u3001\u81ea\u8bc4\u504f\u5dee\u3001\u4e00\u81f4\u6027\u4e0e\u6b63\u786e\u6027\u7684\u5173\u7cfb\u4ee5\u53ca\u7cfb\u7edf\u7ea7\u6270\u52a8\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5728\u63d0\u793a\u5fae\u5c0f\u53d8\u52a8\u548c\u4e0d\u540c\u968f\u673a\u8bbe\u7f6e\u4e0b\u8f93\u51fa\u5dee\u5f02\u663e\u8457\uff0c\u6700\u9ad8\u6027\u80fd\u7531HuatuoGPT-o1-8B\u8fbe\u6210\uff0c\u4e00\u81f4\u6027\u9ad8\u4e0d\u4ee3\u8868\u7ed3\u679c\u6b63\u786e\uff0c\u6a21\u578b\u81ea\u6211\u8bc4\u4f30\u5b58\u5728\u504f\u5dee\uff0c\u4e34\u5e8a\u8bc4\u4ef7\u53d1\u73b0\u63a8\u7406\u5408\u7406\u6027\u53c2\u5dee\u4e0d\u9f50\uff0c\u7cfb\u7edf\u73af\u5883\u5dee\u5f02\u4ea6\u5bfc\u81f4\u8f93\u51fa\u7edf\u8ba1\u5b66\u4e0a\u663e\u8457\u53d8\u5316\u3002", "conclusion": "\u5c0f\u578b\u5f00\u6e90\u533b\u5b66\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u63d0\u793a\u548c\u968f\u673a\u8bbe\u7f6e\u4e0b\u8868\u73b0\u51fa\u8f93\u51fa\u53d8\u5f02\u6027\u548c\u81ea\u6211\u8bc4\u4f30\u504f\u5dee\uff0c\u9ad8\u4e00\u81f4\u6027\u5e76\u4e0d\u4fdd\u8bc1\u6b63\u786e\u6027\uff0c\u5b58\u5728\u4e34\u5e8a\u5408\u7406\u6027\u4e0e\u758f\u5ffd\u5e76\u5b58\u7684\u73b0\u8c61\uff0c\u7cfb\u7edf\u7ea7\u53d8\u52a8\u4e5f\u5f71\u54cd\u8f93\u51fa\u7ed3\u679c\u3002"}}
{"id": "2601.13671", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13671", "abs": "https://arxiv.org/abs/2601.13671", "authors": ["Apoorva Adimulam", "Rajesh Gupta", "Sumit Kumar"], "title": "The Orchestration of Multi-Agent Systems: Architectures, Protocols, and Enterprise Adoption", "comment": null, "summary": "Orchestrated multi-agent systems represent the next stage in the evolution of artificial intelligence, where autonomous agents collaborate through structured coordination and communication to achieve complex, shared objectives. This paper consolidates and formalizes the technical composition of such systems, presenting a unified architectural framework that integrates planning, policy enforcement, state management, and quality operations into a coherent orchestration layer. Another primary contribution of this work is the in-depth technical delineation of two complementary communication protocols - the Model Context Protocol, which standardizes how agents access external tools and contextual data, and the Agent2Agent protocol, which governs peer coordination, negotiation, and delegation. Together, these protocols establish an interoperable communication substrate that enables scalable, auditable, and policy-compliant reasoning across distributed agent collectives. Beyond protocol design, the paper details how orchestration logic, governance frameworks, and observability mechanisms collectively sustain system coherence, transparency, and accountability. By synthesizing these elements into a cohesive technical blueprint, this paper provides comprehensive treatments of orchestrated multi-agent systems - bridging conceptual architectures with implementation-ready design principles for enterprise-scale AI ecosystems.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5730\u6574\u5408\u89c4\u5212\u3001\u901a\u4fe1\u534f\u8bae\u53ca\u6cbb\u7406\u673a\u5236\uff0c\u6784\u5efa\u4e86\u53ef\u6269\u5c55\u4e14\u53ef\u6cbb\u7406\u7684\u591a\u667a\u80fd\u4f53\u7f16\u6392\u67b6\u6784\uff0c\u589e\u5f3a\u4e86\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u80fd\u529b\uff0c\u63a8\u52a8AI\u7cfb\u7edf\u7684\u4f01\u4e1a\u5e94\u7528\u3002", "motivation": "\u63a8\u52a8\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4f7f\u81ea\u4e3b\u667a\u80fd\u4f53\u80fd\u591f\u901a\u8fc7\u7ed3\u6784\u5316\u534f\u8c03\u548c\u6c9f\u901a\u534f\u4f5c\uff0c\u5b8c\u6210\u590d\u6742\u7684\u5171\u4eab\u4efb\u52a1\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u5173\u952e\u901a\u4fe1\u534f\u8bae\u2014\u2014\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\u548cAgent2Agent\u534f\u8bae\uff0c\u652f\u6301\u667a\u80fd\u4f53\u4e4b\u95f4\u7684\u534f\u540c\u5de5\u4f5c\u548c\u5de5\u5177\u8bbf\u95ee\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u3001\u53ef\u5ba1\u8ba1\u4e14\u7b26\u5408\u6cd5\u89c4\u7684\u901a\u4fe1\u57fa\u7840\u3002", "result": "\u63d0\u51fa\u7684\u67b6\u6784\u548c\u534f\u8bae\u5b9e\u73b0\u4e86\u7cfb\u7edf\u5185\u90e8\u534f\u8c03\u3001\u900f\u660e\u548c\u53ef\u6cbb\u7406\uff0c\u4fc3\u8fdb\u4f01\u4e1a\u7ea7AI\u751f\u6001\u7cfb\u7edf\u7684\u5b9e\u65bd\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7edf\u4e00\u67b6\u6784\u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u89c4\u5212\u3001\u7b56\u7565\u6267\u884c\u3001\u72b6\u6001\u7ba1\u7406\u548c\u8d28\u91cf\u63a7\u5236\uff0c\u5b9e\u73b0\u7cfb\u7edf\u7684\u6709\u5e8f\u7f16\u6392\u3002"}}
{"id": "2601.11672", "categories": ["cs.SE", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.11672", "abs": "https://arxiv.org/abs/2601.11672", "authors": ["Deepak Babu Piskala"], "title": "From Everything-is-a-File to Files-Are-All-You-Need: How Unix Philosophy Informs the Design of Agentic AI Systems", "comment": null, "summary": "A core abstraction in early Unix systems was the principle that 'everything is a file', enabling heterogeneous devices and kernel resources to be manipulated via uniform read/write interfaces. This paper explores how an analogous unification is emerging in contemporary agentic AI. We trace the evolution from Unix to DevOps, Infrastructure-as-Code, and finally autonomous software agents, highlighting how file-like abstractions and code-based specifications collapse diverse resources into consistent, composable interfaces. The resulting perspective suggests that adopting file- and code-centric interaction models may enable agentic systems that are more maintainable, auditable, and operationally robust.", "AI": {"tldr": "\u672c\u6587\u7c7b\u6bd4Unix\u7cfb\u7edf\u2018\u4e00\u5207\u7686\u6587\u4ef6\u2019\u539f\u5219\uff0c\u63a2\u8ba8\u6587\u4ef6\u548c\u4ee3\u7801\u4e2d\u5fc3\u7684\u6a21\u578b\u5982\u4f55\u7edf\u4e00\u548c\u7b80\u5316\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u8d44\u6e90\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u4e0e\u53ef\u7ba1\u7406\u6027\u3002", "motivation": "\u7c7b\u6bd4\u65e9\u671fUnix\u7cfb\u7edf\u4e2d\u2018\u4e00\u5207\u7686\u6587\u4ef6\u2019\u7684\u6838\u5fc3\u62bd\u8c61\uff0c\u63a2\u8ba8\u5728\u73b0\u4ee3\u81ea\u4e3b\u667a\u80fd\u4f53\u9886\u57df\u4e2d\u7c7b\u4f3c\u7684\u7edf\u4e00\u62bd\u8c61\u5982\u4f55\u51fa\u73b0\u4e0e\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u8ffd\u8e2a\u4eceUnix\u7cfb\u7edf\u5230DevOps\u3001\u57fa\u7840\u8bbe\u65bd\u5373\u4ee3\u7801\uff0c\u6700\u7ec8\u5230\u81ea\u4e3b\u8f6f\u4ef6\u4ee3\u7406\u7684\u53d1\u5c55\u5386\u7a0b\uff0c\u5206\u6790\u6587\u4ef6\u5f0f\u62bd\u8c61\u548c\u57fa\u4e8e\u4ee3\u7801\u7684\u89c4\u8303\u5982\u4f55\u7edf\u4e00\u591a\u6837\u5316\u7684\u8d44\u6e90\u3002", "result": "\u5c55\u793a\u4e86\u6587\u4ef6\u548c\u4ee3\u7801\u4e3a\u4e2d\u5fc3\u7684\u4ea4\u4e92\u6a21\u578b\u5728\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u6574\u5408\u8d44\u6e90\u3001\u63d0\u5347\u7cfb\u7edf\u53ef\u7ef4\u62a4\u6027\u548c\u64cd\u4f5c\u7a33\u5065\u6027\u7684\u6f5c\u529b\u3002", "conclusion": "\u91c7\u7528\u6587\u4ef6\u548c\u4ee3\u7801\u4e2d\u5fc3\u7684\u4ea4\u4e92\u6a21\u578b\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u6613\u7ef4\u62a4\u3001\u53ef\u5ba1\u8ba1\u4e14\u8fd0\u884c\u5065\u58ee\u7684\u81ea\u4e3b\u667a\u80fd\u4f53\u7cfb\u7edf\u3002"}}
{"id": "2601.11573", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11573", "abs": "https://arxiv.org/abs/2601.11573", "authors": ["Muhammad Muneeb", "David B. Ascher"], "title": "An Empirical Analysis of Fine-Tuning Large Language Models on Bioinformatics Literature: PRSGPT and BioStarsGPT", "comment": null, "summary": "Large language models (LLMs) often lack specialized knowledge for complex bioinformatics applications. We present a reproducible pipeline for fine-tuning LLMs on specialized bioinformatics data, demonstrated through two use cases: PRSGPT, focused on polygenic risk score (PRS) tools, and BioStarsGPT, trained on community forum discussions. The nine-step pipeline integrates diverse data sources, structured preprocessing, prompt-based question-answer (QA) generation (via Google Gemini), natural language inference (NLI) for quality control, semantic deduplication, clustering-based data splitting, and parameter-efficient fine-tuning using LoRA. We fine-tuned three LLMs (LLaMA-3.2-3B, Qwen2.5-7B, Gemma) and benchmarked them on over 14 lexical and semantic metrics. Qwen2.5-7B emerged as the best performer, with BLEU-4 and ROUGE-1 improvements of 82\\% and 70\\% for PRSGPT and 6\\% and 18\\% for BioStarsGPT, respectively. The open-source datasets produced include over 28,000 QA pairs for PRSGPT and 154,282 for BioStarsGPT. Human evaluation of PRSGPT yielded 61.9\\% accuracy on the PRS tools comparison task, comparable to Google Gemini (61.4\\%), but with richer methodological detail and accurate citations. BioStarsGPT demonstrated 59\\% conceptual accuracy across 142 curated bioinformatics questions. Our pipeline enables scalable, domain-specific fine-tuning of LLMs. It enables privacy-preserving, locally deployable bioinformatics assistants, explores their practical applications, and addresses the challenges, limitations, and mitigation strategies associated with their development and use.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7684\u4e5d\u6b65\u5fae\u8c03\u6d41\u7a0b\uff0c\u6210\u529f\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5b9a\u5236\u4e3a\u751f\u7269\u4fe1\u606f\u5b66\u9886\u57df\u52a9\u624b\uff0c\u663e\u8457\u63d0\u5347\u5176\u4e13\u4e1a\u8868\u73b0\uff0c\u5e76\u5f00\u653e\u5927\u91cf\u9ad8\u8d28\u91cf\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u672c\u5730\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u751f\u7269\u4fe1\u606f\u5b66\u5e94\u7528\u65f6\u5f80\u5f80\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e9f\u9700\u901a\u8fc7\u5fae\u8c03\u63d0\u5347\u5176\u9886\u57df\u7279\u5b9a\u7684\u7406\u89e3\u548c\u5e94\u7528\u80fd\u529b\uff0c\u4ece\u800c\u66f4\u597d\u5730\u652f\u6301\u751f\u7269\u4fe1\u606f\u5b66\u5de5\u5177\u548c\u793e\u533a\u95ee\u7b54\u7684\u9700\u6c42\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4e5d\u6b65\u5fae\u8c03\u6d41\u7a0b\uff0c\u5305\u62ec\u591a\u6837\u6570\u636e\u6e90\u96c6\u6210\u3001\u7ed3\u6784\u5316\u9884\u5904\u7406\u3001\u57fa\u4e8e\u63d0\u793a\u7684QA\u751f\u6210\u3001\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u8d28\u91cf\u63a7\u5236\u3001\u8bed\u4e49\u53bb\u91cd\u3001\u805a\u7c7b\u6570\u636e\u62c6\u5206\uff0c\u4ee5\u53ca\u4f7f\u7528LoRA\u8fdb\u884c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff1b\u5bf9\u4e09\u4e2aLLM\uff08LLaMA-3.2-3B\u3001Qwen2.5-7B\u3001Gemma\uff09\u8fdb\u884c\u5fae\u8c03\u5e76\u57fa\u4e8e14\u9879\u8bcd\u6c47\u548c\u8bed\u4e49\u6307\u6807\u8fdb\u884c\u8bc4\u6d4b\uff0c\u9009\u51fa\u6700\u4f73\u6a21\u578bQwen2.5-7B\u3002", "result": "\u6210\u529f\u5fae\u8c03\u4e86LLM\uff0cQwen2.5-7B\u5728PRSGPT\u548cBioStarsGPT\u4efb\u52a1\u4e2d\u5206\u522b\u5b9e\u73b0\u4e86BLEU-4\u63d0\u534782%\u548c6%\uff0cROUGE-1\u63d0\u534770%\u548c18%\uff1b\u751f\u6210\u4e86\u8986\u76d628,000\u4e2a\u548c154,282\u4e2a\u95ee\u7b54\u5bf9\u7684\u5f00\u6e90\u6570\u636e\u96c6\uff1b\u4eba\u7c7b\u8bc4\u6d4b\u663e\u793aPRSGPT\u5728\u5de5\u5177\u6bd4\u8f83\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u8fbe61.9%\uff0cBioStarsGPT\u6982\u5ff5\u51c6\u786e\u7387\u4e3a59%\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u590d\u73b0\u7684\u4e5d\u6b65\u6d41\u7a0b\uff0c\u7528\u4e8e\u5728\u751f\u7269\u4fe1\u606f\u5b66\u4e13\u95e8\u6570\u636e\u4e0a\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u590d\u6742\u751f\u7269\u4fe1\u606f\u5b66\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u3002\u7814\u7a76\u6210\u529f\u5c55\u793a\u4e86\u4e24\u4e2a\u5e94\u7528\u6848\u4f8b\uff1aPRSGPT\u548cBioStarsGPT\uff0c\u5e76\u4e14\u5b9e\u73b0\u4e86\u4e0eGoogle Gemini\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4ee5\u53ca\u4e30\u5bcc\u7684\u7ec6\u8282\u548c\u51c6\u786e\u5f15\u7528\u3002\u8be5\u65b9\u6cd5\u63a8\u52a8\u4e86\u9690\u79c1\u4fdd\u62a4\u548c\u672c\u5730\u90e8\u7f72\u7684\u751f\u7269\u4fe1\u606f\u5b66\u52a9\u624b\u7684\u5f00\u53d1\u3002"}}
{"id": "2601.11854", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.11854", "abs": "https://arxiv.org/abs/2601.11854", "authors": ["Yifei Zhang", "Hooshang Nayyeri", "Rinat Khaziev", "Emine Yilmaz", "Gokhan Tur", "Dilek Hakkani-T\u00fcr", "Hari Thadakamalla"], "title": "ATOD: An Evaluation Framework and Benchmark for Agentic Task-Oriented Dialogue System", "comment": null, "summary": "Recent advances in task-oriented dialogue (TOD) systems, driven by large language models (LLMs) with extensive API and tool integration, have enabled conversational agents to coordinate interleaved goals, maintain long-horizon context, and act proactively through asynchronous execution. These capabilities extend beyond traditional TOD systems, yet existing benchmarks lack systematic support for evaluating such agentic behaviors. To address this gap, we introduce ATOD, a benchmark and synthetic dialogue generation pipeline that produces richly annotated conversations requiring long-term reasoning. ATOD captures key characteristics of advanced TOD, including multi-goal coordination, dependency management, memory, adaptability, and proactivity. Building on ATOD, we propose ATOD-Eval, a holistic evaluation framework that translates these dimensions into fine-grained metrics and supports reproducible offline and online evaluation. We further present a strong agentic memory-based evaluator for benchmarking on ATOD. Experiments show that ATOD-Eval enables comprehensive assessment across task completion, agentic capability, and response quality, and that the proposed evaluator offers a better accuracy-efficiency tradeoff compared to existing memory- and LLM-based approaches under this evaluation setting.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5148\u8fdb\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u4ee3\u7406\u884c\u4e3a\u4e0d\u8db3\u7684\u8bc4\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86ATOD\u57fa\u51c6\u53caATOD-Eval\u8bc4\u4f30\u6846\u67b6\u548c\u8bb0\u5fc6\u578b\u8bc4\u4f30\u5668\uff0c\u5b9e\u73b0\u591a\u76ee\u6807\u957f\u671f\u63a8\u7406\u5bf9\u8bdd\u7684\u7cfb\u7edf\u6027\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u5176\u51c6\u786e\u6027\u548c\u6548\u7387\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u7684\u8bc4\u4f30\u4e0d\u652f\u6301\u5927\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684\u591a\u76ee\u6807\u3001\u591a\u4efb\u52a1\u3001\u591a\u8bb0\u5fc6\u53ca\u4e3b\u52a8\u6267\u884c\u7b49\u9ad8\u7ea7\u4ee3\u7406\u884c\u4e3a\uff0c\u7f3a\u5c11\u7cfb\u7edf\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u8bbe\u8ba1\u4e86ATOD\u57fa\u51c6\u548c\u5408\u6210\u5bf9\u8bdd\u751f\u6210\u7ba1\u9053\u4ee5\u4ea7\u751f\u9700\u8981\u957f\u671f\u63a8\u7406\u7684\u591a\u76ee\u6807\u4efb\u52a1\u5bf9\u8bdd\uff0c\u5e76\u63d0\u51faATOD-Eval\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u4ee3\u7406\u7ef4\u5ea6\u8f6c\u5316\u4e3a\u7ec6\u7c92\u5ea6\u5ea6\u91cf\u6307\u6807\uff1b\u6784\u5efa\u4e86\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8bc4\u4f30\u5668\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\uff0cATOD-Eval\u80fd\u591f\u7efc\u5408\u8bc4\u4f30\u4efb\u52a1\u5b8c\u6210\u5ea6\u3001\u4ee3\u7406\u80fd\u529b\u548c\u54cd\u5e94\u8d28\u91cf\uff0c\u5e76\u4e14\u57fa\u4e8e\u8bb0\u5fc6\u7684\u8bc4\u4f30\u5668\u5728\u672c\u8bc4\u4f30\u73af\u5883\u4e0b\u8f83\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u4f18\u7684\u51c6\u786e\u7387\u4e0e\u6548\u7387\u8868\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684ATOD\u57fa\u51c6\u548cATOD-Eval\u8bc4\u4f30\u6846\u67b6\u6709\u6548\u652f\u6301\u4e86\u5bf9\u5148\u8fdb\u4efb\u52a1\u5bfc\u5411\u5bf9\u8bdd\u7cfb\u7edf\u591a\u79cd\u4ee3\u7406\u884c\u4e3a\u7684\u7cfb\u7edf\u8bc4\u4f30\uff0c\u63d0\u5347\u4e86\u8bc4\u6d4b\u7684\u7ec6\u7c92\u5ea6\u548c\u5168\u9762\u6027\u3002\u57fa\u4e8eATOD\u7684\u8bb0\u5fc6\u578b\u8bc4\u4f30\u5668\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e4b\u95f4\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u5e73\u8861\u3002"}}
{"id": "2601.11687", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11687", "abs": "https://arxiv.org/abs/2601.11687", "authors": ["Harmohit Singh"], "title": "Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems", "comment": null, "summary": "We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bed\u4e49\u7f13\u5b58\u3001\u53cc\u9608\u503c\u51b3\u7b56\u548c\u610f\u56fe\u9a71\u52a8\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u4f4e\u6210\u672c\u7684\u81ea\u7136\u8bed\u8a00\u5230Python\u4ee3\u7801\u8f6c\u6362\uff0c\u5e7f\u6cdb\u5e94\u7528\u4e8e\u4f01\u4e1a\u6570\u636e\u5206\u6790\u3002", "motivation": "\u964d\u4f4e\u590d\u6742\u67e5\u8be2\u8f6c\u6362\u7684\u6210\u672c\u548c\u5ef6\u8fdf\uff0c\u63d0\u9ad8\u81ea\u7136\u8bed\u8a00\u5230\u4ee3\u7801\u8f6c\u6362\u7684\u51c6\u786e\u7387\u548c\u6548\u7387\uff0c\u6ee1\u8db3\u4f01\u4e1a\u751f\u4ea7\u73af\u5883\u7684\u9700\u6c42\u3002", "method": "\u57fa\u4e8e\u4e09\u9879\u521b\u65b0\u6280\u672f\uff1a\u8bed\u4e49\u7f13\u5b58\u7cfb\u7edf\uff08\u5229\u7528LLM\u68c0\u6d4b\u7b49\u4ef7\u6027\u548c\u7ed3\u6784\u5316\u9002\u914d\u63d0\u793a\uff09\u3001\u53cc\u9608\u503c\u51b3\u7b56\u673a\u5236\uff08\u533a\u5206\u7cbe\u786e\u68c0\u7d22\u4e0e\u53c2\u8003\u751f\u6210\uff09\u3001\u610f\u56fe\u9a71\u52a8\u7684\u52a8\u6001\u63d0\u793a\u7ec4\u88c5\uff08\u901a\u8fc7\u8868\u683c\u611f\u77e5\u7b5b\u9009\u663e\u8457\u51cf\u5c11Token\u6d88\u8017\uff09\u3002", "result": "\u7cfb\u7edf\u5728\u4f01\u4e1a\u5e93\u5b58\u7ba1\u7406\u4e2d\u5904\u7406\u8d85\u8fc71\u4e07\u6761\u67e5\u8be2\uff0c\u5e73\u5747\u5ef6\u8fdf8.2\u79d2\uff0c\u8bed\u4e49\u51c6\u786e\u7387\u8fbe94.3%\uff0c\u7f13\u5b58\u547d\u4e2d\u738767%\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8fd0\u884c\u6548\u7387\u548c\u6210\u672c\u63a7\u5236\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u81ea\u7136\u8bed\u8a00\u67e5\u8be2\u5230Python\u4ee3\u7801\u7684\u9ad8\u6548\u8f6c\u6362\uff0c\u5c55\u793a\u4e86\u9ad8\u51c6\u786e\u7387\u548c\u6210\u672c\u6548\u76ca\uff0c\u9002\u7528\u4e8e\u4f01\u4e1a\u7ea7\u7ed3\u6784\u5316\u6570\u636e\u5206\u6790\u3002"}}
{"id": "2601.11575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11575", "abs": "https://arxiv.org/abs/2601.11575", "authors": ["Sotirios Panagiotis Chytas", "Vikas Singh"], "title": "Concept Attractors in LLMs and their Applications", "comment": null, "summary": "Large language models (LLMs) often map semantically related prompts to similar internal representations at specific layers, even when their surface forms differ widely. We show that this behavior can be explained through Iterated Function Systems (IFS), where layers act as contractive mappings toward concept-specific Attractors. We leverage this insight and develop simple, training-free methods that operate directly on these Attractors to solve a wide range of practical tasks, including language translation, hallucination reduction, guardrailing, and synthetic data generation. Despite their simplicity, these Attractor-based interventions match or exceed specialized baselines, offering an efficient alternative to heavy fine-tuning, generalizable in scenarios where baselines underperform.", "AI": {"tldr": "\u672c\u6587\u89e3\u91ca\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u8868\u5f81\u5f62\u6210\u7684\u673a\u5236\uff0c\u63d0\u51fa\u57fa\u4e8e\u5438\u5f15\u5b50\u7684\u65e0\u8bad\u7ec3\u5e72\u9884\u65b9\u6cd5\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u7b80\u5316\u4e86\u6a21\u578b\u8c03\u4f18\u6d41\u7a0b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u5c42\u5bf9\u8bed\u4e49\u76f8\u5173\u7684\u63d0\u793a\u6620\u5c04\u5230\u76f8\u4f3c\u7684\u5185\u90e8\u8868\u793a\uff0c\u63ed\u793a\u4e86\u5176\u5185\u90e8\u884c\u4e3a\u89c4\u5f8b\u3002", "method": "\u5229\u7528\u8fed\u4ee3\u51fd\u6570\u7cfb\u7edf\uff08IFS\uff09\u7684\u7406\u8bba\uff0c\u89c6\u5c42\u4e3a\u6536\u7f29\u6620\u5c04\u5bfc\u5411\u6982\u5ff5\u7279\u5b9a\u7684\u5438\u5f15\u5b50\uff0c\u57fa\u4e8e\u5438\u5f15\u5b50\u5f00\u53d1\u65e0\u9700\u8bad\u7ec3\u7684\u7b80\u5355\u65b9\u6cd5\u3002", "result": "\u57fa\u4e8e\u5438\u5f15\u5b50\u7684\u65b9\u6cd5\u5728\u8bed\u8a00\u7ffb\u8bd1\u3001\u51cf\u5c11\u5e7b\u89c9\u3001\u8bbe\u5b9a\u9650\u5236\u548c\u5408\u6210\u6570\u636e\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u6548\u679c\uff0c\u8fbe\u5230\u6216\u8d85\u8fc7\u4e13\u95e8\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u7406\u89e3LLM\u5185\u90e8\u7684\u5438\u5f15\u5b50\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u5e72\u9884\u624b\u6bb5\uff0c\u66ff\u4ee3\u4e86\u590d\u6742\u7684\u5fae\u8c03\u8fc7\u7a0b\u3002"}}
{"id": "2601.12522", "categories": ["cs.SE", "cs.AI", "cs.IR", "cs.LG", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.12522", "abs": "https://arxiv.org/abs/2601.12522", "authors": ["Asif Mohammed Samir", "Mohammad Masudur Rahman"], "title": "Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition", "comment": "13 pages, 7 tables, 5 figures", "summary": "Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u56e0\u679c\u63a8\u7406\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5CogniGent\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f3a\u9677\u5b9a\u4f4d\u6027\u80fd\uff0c\u5f25\u8865\u4e86\u4f20\u7edf\u548cLLM\u6280\u672f\u5728\u56e0\u679c\u548c\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u7684\u7f3a\u9677\u5b9a\u4f4d\u65b9\u6cd5\u5f80\u5f80\u5b64\u7acb\u5206\u6790\u4ee3\u7801\u7ec4\u4ef6\uff0c\u5ffd\u89c6\u4e86\u7ec4\u4ef6\u95f4\u7684\u8054\u7cfb\uff0c\u4e14\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u56e0\u679c\u63a8\u7406\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5b9a\u4f4d\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86CogniGent\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u7f3a\u9677\u5b9a\u4f4d\u6280\u672f\uff0c\u901a\u8fc7\u56e0\u679c\u63a8\u7406\u3001\u8c03\u7528\u56fe\u4e3a\u57fa\u7840\u7684\u6839\u56e0\u5206\u6790\u53ca\u4e0a\u4e0b\u6587\u5de5\u7a0b\uff0c\u6a21\u62df\u5f00\u53d1\u8005\u7684\u8c03\u8bd5\u884c\u4e3a\u5e76\u8fdb\u884c\u5047\u8bbe\u6d4b\u8bd5\u3002", "result": "\u5728\u5305\u542b591\u6761\u7f3a\u9677\u62a5\u544a\u7684\u6570\u636e\u96c6\u4e0a\uff0cCogniGent\u5728\u6587\u6863\u548c\u65b9\u6cd5\u5c42\u9762\u7684MAP\u63d0\u5347\u4e8623.33%-38.57%\uff0cMRR\u63d0\u5347\u4e8625.14%-53.74%\uff0c\u663e\u8457\u4f18\u4e8e\u516d\u79cd\u4f20\u7edf\u53caLLM\u57fa\u7ebf\u65b9\u6cd5\u3002\u7edf\u8ba1\u6d4b\u8bd5\u786e\u8ba4\u5176\u4f18\u8d8a\u6027\u3002", "conclusion": "CogniGent\u901a\u8fc7\u7ed3\u5408\u56e0\u679c\u63a8\u7406\u3001\u8c03\u7528\u56fe\u5206\u6790\u548c\u4e0a\u4e0b\u6587\u7ba1\u7406\uff0c\u6709\u6548\u7a81\u7834\u4e86\u4f20\u7edf\u53caLLM\u7f3a\u9677\u5b9a\u4f4d\u6280\u672f\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u4eba\u6027\u5316\u4e14\u9ad8\u6548\u7684\u7f3a\u9677\u5b9a\u4f4d\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u5316\u7f3a\u9677\u5b9a\u4f4d\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.11688", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11688", "abs": "https://arxiv.org/abs/2601.11688", "authors": ["Vedant Nipane", "Pulkit Agrawal", "Amit Singh"], "title": "SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering", "comment": null, "summary": "Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5c42\u6b21\u5316\u6570\u636e\u624b\u518c\u4e0e\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u5d4c\u5165\u5f0f\u7cfb\u7edf\u8ffd\u6eaf\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u652f\u6301\u5927\u89c4\u6a21\u8f6f\u4ef6\u5206\u6790\u53ca\u591a\u79cd\u5e94\u7528\u3002", "motivation": "\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4e2d\uff0c\u6570\u636e\u624b\u518c\u4e0e\u4ee3\u7801\u5b9e\u73b0\u4e4b\u95f4\u7684\u7cbe\u786e\u8ffd\u6eaf\u4ecd\u662f\u7cfb\u7edf\u5de5\u7a0b\u4e2d\u7684\u96be\u9898\uff0c\u5c24\u5176\u662f\u4f4e\u7ea7\u8f6f\u4ef6\uff0c\u624b\u52a8\u6620\u5c04\u4e0d\u53ef\u884c\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5c42\u6b21\u5316\u7684\u6570\u636e\u624b\u518c\u5230\u4ee3\u7801\u6620\u5c04\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5206\u6790\uff0c\u901a\u8fc7\u591a\u4e2a\u62bd\u8c61\u5c42\u6b21\u9010\u6b65\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\uff0c\u5305\u62ec\u4ed3\u5e93\u7ed3\u6784\u63a8\u65ad\u3001\u6587\u4ef6\u76f8\u5173\u6027\u4f30\u8ba1\u548c\u7b26\u53f7\u7ea7\u5bf9\u9f50\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u5d4c\u5165\u5f0f\u7cfb\u7edf\u4ed3\u5e93\u4e0a\u8bc4\u4f30\uff0c\u6587\u4ef6\u6620\u5c04\u51c6\u786e\u7387\u6700\u9ad8\u8fbe73.3%\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u65b9\u6cd5\uff0c\u540c\u65f6\u51cf\u5c11\u4e8684%\u7684LLM\u4ee4\u724c\u6d88\u8017\u548c\u7ea680%\u7684\u8fd0\u884c\u65f6\u95f4\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u652f\u6301\u5927\u89c4\u6a21\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u7684\u81ea\u52a8\u5206\u6790\uff0c\u5e76\u4fc3\u8fdb\u4e86\u7cfb\u7edf\u611f\u77e5\u7684\u673a\u5668\u5b66\u4e60\u8bad\u7ec3\u6570\u636e\u751f\u6210\u3001\u6807\u51c6\u5408\u89c4\u9a8c\u8bc1\u53ca\u89c4\u683c\u8986\u76d6\u5206\u6790\u7b49\u4e0b\u6e38\u5e94\u7528\u3002"}}
{"id": "2601.11578", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11578", "abs": "https://arxiv.org/abs/2601.11578", "authors": ["Ibrahim Al Azher", "Zhishuai Guo", "Hamed Alhoori"], "title": "LimAgents: Multi-Agent LLMs for Generating Research Limitations", "comment": "18 Pages, 9 figures", "summary": "Identifying and articulating limitations is essential for transparent and rigorous scientific research. However, zero-shot large language models (LLMs) approach often produce superficial or general limitation statements (e.g., dataset bias or generalizability). They usually repeat limitations reported by authors without looking at deeper methodological issues and contextual gaps. This problem is made worse because many authors disclose only partial or trivial limitations. We propose LimAgents, a multi-agent LLM framework for generating substantive limitations. LimAgents integrates OpenReview comments and author-stated limitations to provide stronger ground truth. It also uses cited and citing papers to capture broader contextual weaknesses. In this setup, different agents have specific roles as sequential role: some extract explicit limitations, others analyze methodological gaps, some simulate the viewpoint of a peer reviewer, and a citation agent places the work within the larger body of literature. A Judge agent refines their outputs, and a Master agent consolidates them into a clear set. This structure allows for systematic identification of explicit, implicit, peer review-focused, and literature-informed limitations. Moreover, traditional NLP metrics like BLEU, ROUGE, and cosine similarity rely heavily on n-gram or embedding overlap. They often overlook semantically similar limitations. To address this, we introduce a pointwise evaluation protocol that uses an LLM-as-a-Judge to measure coverage more accurately. Experiments show that LimAgents substantially improve performance. The RAG + multi-agent GPT-4o mini configuration achieves a +15.51% coverage gain over zero-shot baselines, while the Llama 3 8B multi-agent setup yields a +4.41% improvement.", "AI": {"tldr": "\u63d0\u51faLimAgents\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7ed3\u5408\u591a\u6765\u6e90\u4fe1\u606f\uff0c\u7cfb\u7edf\u751f\u6210\u66f4\u5b9e\u8d28\u6027\u7684\u7814\u7a76\u5c40\u9650\u6027\uff0c\u663e\u8457\u63d0\u5347\u8986\u76d6\u7387\u548c\u8d28\u91cf\uff0c\u4f18\u4e8e\u4f20\u7edf\u96f6\u6837\u672c\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u96f6\u6837\u672cLLM\u751f\u6210\u7684\u5c40\u9650\u6027\u901a\u5e38\u80a4\u6d45\u4e14\u91cd\u590d\u4f5c\u8005\u5df2\u6709\u9648\u8ff0\uff0c\u7f3a\u4e4f\u6df1\u5165\u5206\u6790\uff0c\u4e14\u4f5c\u8005\u62ab\u9732\u7684\u5c40\u9650\u5f80\u5f80\u4e0d\u5b8c\u6574\uff0c\u5bfc\u81f4\u79d1\u5b66\u7814\u7a76\u900f\u660e\u5ea6\u548c\u4e25\u8c28\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53LLM\u6846\u67b6LimAgents\uff0c\u96c6\u6210OpenReview\u8bc4\u8bba\u3001\u4f5c\u8005\u9648\u8ff0\u3001\u5f15\u7528\u548c\u88ab\u5f15\u7528\u6587\u732e\uff0c\u5229\u7528\u4e0d\u540c\u89d2\u8272\u7684\u667a\u80fd\u4f53\u5206\u5de5\u5408\u4f5c\uff0c\u751f\u6210\u7cfb\u7edf\u6027\u7684\u663e\u6027\u548c\u9690\u6027\u5c40\u9650\u6027\u3002\u5f15\u5165\u70b9\u5bf9\u70b9\u8bc4\u4ef7\u534f\u8bae\u548cLLM\u4f5c\u4e3a\u8bc4\u5224\u8005\uff0c\u4ee5\u66f4\u51c6\u786e\u8861\u91cf\u8986\u76d6\u7387\u3002", "result": "LimAgents\u5728RAG + GPT-4o mini\u914d\u7f6e\u4e0b\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u8986\u76d6\u7387\u63d0\u534715.51%\uff0cLlama 3 8B\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\u63d0\u53474.41%\uff0c\u6709\u6548\u6355\u83b7\u66f4\u5168\u9762\u3001\u66f4\u6df1\u5165\u7684\u5c40\u9650\u6027\u3002", "conclusion": "LimAgents\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5c40\u9650\u6027\u8bc6\u522b\u7684\u5168\u9762\u6027\u548c\u6df1\u5ea6\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edf\u96f6\u6837\u672c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13352", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.13352", "abs": "https://arxiv.org/abs/2601.13352", "authors": ["Yuxing Lu", "J. Ben Tamo", "Weichen Zhao", "Nan Sun", "Yishan Zhong", "Wenqi Shi", "Jinzhuo Wang", "May D. Wang"], "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction", "comment": "17 pages, 5 figures, 6 tables", "summary": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.", "AI": {"tldr": "LLM-as-RNN \u5229\u7528\u81ea\u7136\u8bed\u8a00\u8bb0\u5fc6\u673a\u5236\u5c06\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u9012\u5f52\u9884\u6d4b\u5668\uff0c\u5b9e\u73b0\u5728\u7ebf\u5b66\u4e60\uff0c\u660e\u663e\u63d0\u5347\u5e8f\u5217\u9884\u6d4b\u6027\u80fd\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u66f4\u65b0\u4e0a\u4e0b\u6587\u8bb0\u5fc6\u7684\u95ee\u9898\uff0c\u63d0\u5347\u9519\u8bef\u540e\u7eed\u9884\u6d4b\u7684\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51fa LLM-as-RNN \u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u6a21\u578b\u9690\u85cf\u72b6\u6001\u8868\u793a\u4e3a\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u7684\u7cfb\u7edf\u63d0\u793a\u6458\u8981\uff0c\u5e76\u5728\u6bcf\u4e2a\u6b65\u9aa4\u901a\u8fc7\u53cd\u9988\u9a71\u52a8\u7684\u6587\u672c\u91cd\u5199\u66f4\u65b0\u8be5\u72b6\u6001\u3002", "result": "\u5728\u533b\u7597\u3001\u6c14\u8c61\u548c\u91d1\u878d\u4e09\u4e2a\u9886\u57df\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cLLM-as-RNN \u5bf9\u6bd4\u96f6\u6837\u672c\u3001\u5b8c\u6574\u5386\u53f2\u53ca MemPrompt \u57fa\u7ebf\uff0c\u5e73\u5747\u63d0\u9ad8\u4e866.5%\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u540c\u65f6\u751f\u6210\u4e86\u53ef\u89e3\u91ca\u7684\u4eba\u7c7b\u53ef\u8bfb\u5b66\u4e60\u8f68\u8ff9\u3002", "conclusion": "LLM-as-RNN \u6210\u529f\u5c06\u51bb\u7ed3\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u53d8\u4e3a\u5177\u6709\u66f4\u65b0\u8bb0\u5fc6\u673a\u5236\u7684\u9012\u5f52\u9884\u6d4b\u5668\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u7684\u5728\u7ebf\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5e8f\u5217\u9884\u6d4b\u51c6\u786e\u7387\u3002"}}
{"id": "2601.11693", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11693", "abs": "https://arxiv.org/abs/2601.11693", "authors": ["Shane K. Panter", "Nasir U. Eisty"], "title": "Technical Lag as Latent Technical Debt: A Rapid Review", "comment": "Accepted to: TechDebt 2026 - International Conference on Technical Debt April 12--15, 2026 Rio de Janeiro, Brazil", "summary": "Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u6280\u672f\u6ede\u540e\u7684\u5b9a\u4e49\u3001\u68c0\u6d4b\u3001\u6210\u56e0\u53ca\u5f71\u54cd\uff0c\u63d0\u51fa\u6539\u8fdb\u6d4b\u91cf\u65b9\u6cd5\u5e76\u5c55\u671b\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u66f4\u597d\u7ba1\u7406\u8f6f\u4ef6\u6280\u672f\u503a\u52a1\u3002", "motivation": "\u8f6f\u4ef6\u7cfb\u7edf\u672a\u80fd\u8ddf\u4e0a\u6280\u672f\u8fdb\u6b65\uff0c\u5bfc\u81f4\u6280\u672f\u6ede\u540e\uff0c\u4ece\u800c\u5f15\u8d77\u8f6f\u4ef6\u8d28\u91cf\u4e0b\u964d\uff0c\u4e9f\u9700\u7cfb\u7edf\u7efc\u8ff0\u4e0e\u7ba1\u7406\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5feb\u901f\u7efc\u8ff0\u7ed3\u5408\u6eda\u96ea\u7403\u65b9\u6cd5\uff0c\u9009\u53d6\u591a\u4e2a\u6570\u636e\u5e93\u4e2d\u7684\u540c\u884c\u8bc4\u8bae\u7814\u7a76\u8fdb\u884c\u7efc\u8ff0\u5206\u6790\u3002", "result": "\u6280\u672f\u6ede\u540e\u88ab\u52a8\u79ef\u7d2f\u4e14\u5e38\u88ab\u5ffd\u89c6\uff0c\u5f71\u54cd\u8f6f\u4ef6\u4f9d\u8d56\u3001API\u3001\u5e73\u53f0\u53ca\u57fa\u7840\u8bbe\u65bd\uff0c\u7ba1\u7406\u7b56\u7565\u5305\u542b\u81ea\u52a8\u4f9d\u8d56\u66f4\u65b0\u3001\u6301\u7eed\u96c6\u6210\u548c\u5b9a\u671f\u5ba1\u8ba1\u3002", "conclusion": "\u6280\u672f\u6ede\u540e\u4f5c\u4e3a\u88ab\u52a8\u79ef\u7d2f\u7684\u9690\u6027\u6280\u672f\u503a\u52a1\u6307\u6807\uff0c\u73b0\u6709\u7684\u5ea6\u91cf\u548c\u68c0\u6d4b\u65b9\u6cd5\u9700\u52a0\u5f3a\u548c\u6269\u5c55\uff0c\u4ee5\u6539\u5584\u5927\u578b\u4ee3\u7801\u5e93\u7684\u7ef4\u62a4\u6548\u7387\u3002"}}
{"id": "2601.11579", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11579", "abs": "https://arxiv.org/abs/2601.11579", "authors": ["Krzysztof Ociepa", "\u0141ukasz Flis", "Remigiusz Kinas", "Krzysztof Wr\u00f3bel", "Adrian Gwo\u017adziej"], "title": "Bielik 11B v3: Multilingual Large Language Model for European Languages", "comment": null, "summary": "We present Bielik 11B v3, a state-of-the-art language model highly optimized for the Polish language, while also maintaining strong capabilities in other European languages. This model extends the Mistral 7B v0.2 architecture, scaled to 11B parameters via depth up-scaling. Its development involved a comprehensive four-stage training pipeline: continuous pre-training, supervised fine-tuning (SFT), Direct Preference Optimization (DPO), and reinforcement learning.\n  Comprehensive evaluations demonstrate that Bielik 11B v3 achieves exceptional performance. It significantly surpasses other specialized Polish language models and outperforms many larger models (with 2-6 times more parameters) on a wide range of tasks, from basic linguistic understanding to complex reasoning.\n  The model's parameter efficiency, combined with extensive quantization options, allows for effective deployment across diverse hardware configurations. Bielik 11B v3 not only advances AI capabilities for the Polish language but also establishes a new benchmark for developing resource-efficient, high-performance models for less-represented languages.", "AI": {"tldr": "Bielik 11B v3\u662f\u4e00\u4e2a\u4ee5\u6ce2\u5170\u8bed\u4e3a\u4e3b\u4f18\u5316\u768411B\u53c2\u6570\u7ea7\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u56db\u9636\u6bb5\u8bad\u7ec3\uff0c\u6027\u80fd\u8d85\u8d8a\u8bb8\u591a\u66f4\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u53c2\u6570\u9ad8\u6548\u4e14\u652f\u6301\u591a\u79cd\u786c\u4ef6\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u6ce2\u5170\u8bed\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff0c\u5f00\u53d1\u4e00\u4e2a\u65e2\u5728\u6ce2\u5170\u8bed\u53c8\u5728\u5176\u4ed6\u6b27\u6d32\u8bed\u8a00\u4e0a\u8868\u73b0\u4f18\u5f02\u4e14\u8d44\u6e90\u9ad8\u6548\u7684\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u8be5\u6a21\u578b\u57fa\u4e8eMistral 7B v0.2\u67b6\u6784\uff0c\u901a\u8fc7\u6df1\u5ea6\u6269\u5c55\u53c2\u6570\u81f311B\uff0c\u91c7\u7528\u56db\u9636\u6bb5\u8bad\u7ec3\u6d41\u7a0b\uff1a\u8fde\u7eed\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u53ca\u5f3a\u5316\u5b66\u4e60\u3002", "result": "Bielik 11B v3\u8868\u73b0\u51fa\u6781\u9ad8\u7684\u53c2\u6570\u6548\u7387\u548c\u5e7f\u6cdb\u7684\u91cf\u5316\u9009\u9879\uff0c\u5b9e\u73b0\u4e86\u5728\u591a\u79cd\u786c\u4ef6\u914d\u7f6e\u4e0a\u7684\u6709\u6548\u90e8\u7f72\uff0c\u63d0\u5347\u4e86\u6ce2\u5170\u8bed\u53ca\u6b27\u6d32\u8bed\u8a00\u7684AI\u5904\u7406\u80fd\u529b\u3002", "conclusion": "Bielik 11B v3\u5728\u591a\u9879\u8bc4\u6d4b\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u8d85\u8d8a\u4e86\u5176\u4ed6\u4e13\u95e8\u9488\u5bf9\u6ce2\u5170\u8bed\u7684\u8bed\u8a00\u6a21\u578b\u4ee5\u53ca\u8bb8\u591a\u53c2\u6570\u91cf\u66f4\u5927\u7684\u6a21\u578b\uff0c\u6210\u4e3a\u6ce2\u5170\u8bed\u53ca\u6b27\u6d32\u5176\u4ed6\u8bed\u8a00\u5904\u7406\u7684\u65b0\u6807\u6746\u3002"}}
{"id": "2601.11783", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11783", "abs": "https://arxiv.org/abs/2601.11783", "authors": ["Murtuza N. Shergadwala"], "title": "The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing", "comment": null, "summary": "The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\\approx19\\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\\%$--$83\\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u751f\u6210\u5f0fAI\u7684\u5ba1\u8ba1\uff0c\u63d0\u51fa\u5206\u7c7b\u65b9\u6cd5\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u7684\u5224\u51b3\u7ed3\u679c\u867d\u7a33\u5b9a\u4f46\u63a8\u7406\u4e0d\u7a33\u5b9a\uff0c\u5efa\u8bae\u5c06\u53ef\u786e\u5b9a\u903b\u8f91\u4ee3\u7801\u5316\uff0c\u590d\u6742\u8bed\u4e49\u8bc4\u5224\u4ea4\u7ed9\u6a21\u578b\u3002", "motivation": "\u63a2\u7d22\u4e0d\u540c\u7c7b\u578b\u7cfb\u7edf\u6307\u4ee4\u5bf9\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5224\u53ef\u9760\u6027\u7684\u5f71\u54cd\uff0c\u63d0\u5347\u53ef\u6269\u5c55\u4e14\u53ef\u590d\u73b0\u7684\u5ba1\u8ba1\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86Scoped Instruction Decomposition Framework\uff0c\u5c06\u6d4b\u8bd5\u5e94\u7528\u6307\u4ee4\u5206\u4e3a\u5ba2\u89c2\u548c\u4e3b\u89c2\u7c7b\u578b\uff0c\u8bc4\u4f30\u56db\u79cd\u8bc4\u5224\u4f53\u7cfb\u5728\u4e0d\u540c\u8fd0\u884c\u4e2d\u7684\u7a33\u5b9a\u6027\u3002", "result": "\u53d1\u73b0\u4e86\"\u7a33\u5b9a\u9677\u9631\"\u73b0\u8c61\uff0c\u5373\u5224\u51b3\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\u4f46\u63a8\u7406\u8f68\u8ff9\u4e0d\u7a33\u5b9a\uff0c\u7279\u522b\u662f\u5ba2\u89c2\u6307\u4ee4\u4e2d\u6570\u503c\u63a8\u7406\u4e00\u81f4\u6027\u4f4e\uff0c\u4e3b\u89c2\u6307\u4ee4\u63a8\u7406\u7a33\u5b9a\u6027\u968f\u8bc1\u636e\u9897\u7c92\u5ea6\u6ce2\u52a8\u660e\u663e\u3002", "conclusion": "\u5728\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u7684\u4f01\u4e1a\u6cbb\u7406\u4e2d\uff0c\u9ad8\u5224\u51b3\u4e00\u81f4\u6027\u5e76\u4e0d\u4ee3\u8868\u89e3\u91ca\u5408\u7406\u6027\u7684\u7a33\u5b9a\uff0c\u5224\u51b3\u7684\u63a8\u7406\u7a33\u5b9a\u6027\u53ef\u80fd\u8f83\u4f4e\uff0c\u5c24\u5176\u5728\u5904\u7406\u5b9a\u91cf\u5206\u6790\u548c\u4e3b\u89c2\u5224\u65ad\u65f6\u3002"}}
{"id": "2601.11580", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11580", "abs": "https://arxiv.org/abs/2601.11580", "authors": ["Xiaoxuan Liu", "Jiaxiang Yu", "Jongseok Park", "Ion Stoica", "Alvin Cheung"], "title": "Speculative Decoding: Performance or Illusion?", "comment": null, "summary": "Speculative decoding (SD) has become a popular technique to accelerate Large Language Model (LLM) inference, yet its real-world effectiveness remains unclear as prior evaluations rely on research prototypes and unrealistically small batch sizes. We present, to our knowledge, the first systematic study of SD on a production-grade and widely deployed inference engine (vLLM), covering multiple SD variants ($n$-gram, EAGLE/EAGLE-3, Draft-Model, Multi-Token Prediction) across diverse workloads, model scales, and batch sizes. We analyze key factors governing SD performance, and quantify a theoretical upper bound on SD speedup. Our results show that verification by the target model dominates the execution, while acceptance length varies markedly across output token positions, requests, and datasets. Comparing measured performance with theoretical bounds reveals substantial gaps between observed and theoretical upper bounds, and we leverage this observation to highlight new research opportunities that our study opens up in improving SD.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5728\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u7cfb\u7edf\u8bc4\u6d4b\u63a8\u6d4b\u89e3\u7801\u591a\u79cd\u53d8\u4f53\uff0c\u53d1\u73b0\u5176\u52a0\u901f\u6027\u80fd\u53d7\u9650\u4e8e\u76ee\u6807\u6a21\u578b\u9a8c\u8bc1\uff0c\u5b9e\u9645\u6548\u679c\u8fdc\u4f4e\u4e8e\u7406\u8bba\u6781\u9650\uff0c\u63d0\u51fa\u672a\u6765\u63d0\u5347\u65b9\u5411\u3002", "motivation": "\u5c3d\u7ba1\u63a8\u6d4b\u89e3\u7801(SD)\u52a0\u901f\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u6210\u4e3a\u70ed\u95e8\u6280\u672f\uff0c\u4f46\u5176\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u5b9e\u9645\u6548\u679c\u5c1a\u4e0d\u660e\u786e\uff0c\u5c24\u5176\u4e4b\u524d\u8bc4\u4f30\u57fa\u4e8e\u7814\u7a76\u539f\u578b\u4e14\u6279\u91cf\u5927\u5c0f\u4e0d\u73b0\u5b9e\uff0c\u4fc3\u4f7f\u672c\u7814\u7a76\u5bf9SD\u6548\u80fd\u8fdb\u884c\u7cfb\u7edf\u9a8c\u8bc1\u3002", "method": "\u5728\u4e00\u4e2a\u751f\u4ea7\u7ea7\u7684\u63a8\u7406\u5f15\u64ce(vLLM)\u4e0a\uff0c\u7cfb\u7edf\u5730\u8bc4\u4f30\u4e86\u591a\u79cd\u63a8\u6d4b\u89e3\u7801(SD)\u53d8\u4f53\uff0c\u5305\u62ec$n$-gram\u3001EAGLE/EAGLE-3\u3001Draft-Model\u548c\u591a\u4ee4\u724c\u9884\u6d4b\uff0c\u8986\u76d6\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u3001\u6a21\u578b\u89c4\u6a21\u548c\u6279\u91cf\u5927\u5c0f\u3002\u901a\u8fc7\u7406\u8bba\u754c\u5b9aSD\u52a0\u901f\u7684\u4e0a\u9650\uff0c\u5bf9\u6bd4\u7406\u8bba\u4e0e\u5b9e\u9645\u8868\u73b0\uff0c\u5206\u6790\u5173\u952e\u5f71\u54cd\u56e0\u7d20\u3002", "result": "\u7814\u7a76\u9996\u6b21\u5728\u5e7f\u6cdb\u90e8\u7f72\u7684\u751f\u4ea7\u7ea7\u63a8\u7406\u5f15\u64ce\u4e0a\u9a8c\u8bc1SD\u7684\u591a\u79cd\u53d8\u4f53\uff0c\u63ed\u793a\u9a8c\u8bc1\u6b65\u9aa4\u5360\u4e3b\u5bfc\uff0c\u8f93\u51fa\u63a5\u53d7\u957f\u5ea6\u5dee\u5f02\u5927\uff0c\u5b9e\u9645\u52a0\u901f\u8fdc\u4f4e\u4e8e\u7406\u8bba\u4e0a\u9650\uff0c\u4ece\u800c\u6307\u51fa\u6539\u8fdb\u7a7a\u95f4\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u5b9e\u9a8c\u8bc1\u660e\u76ee\u6807\u6a21\u578b\u7684\u9a8c\u8bc1\u8fc7\u7a0b\u5728\u63a8\u7406\u4e2d\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u800c\u63a5\u53d7\u957f\u5ea6\u5728\u4e0d\u540c\u7684\u4f4d\u7f6e\u3001\u8bf7\u6c42\u548c\u6570\u636e\u96c6\u95f4\u53d8\u5316\u663e\u8457\u3002\u5b9e\u9645\u6027\u80fd\u4e0e\u7406\u8bba\u4e0a\u9650\u5b58\u5728\u8f83\u5927\u5dee\u8ddd\uff0c\u8868\u660e\u5f53\u524dSD\u6280\u672f\u4ecd\u6709\u8f83\u5927\u4f18\u5316\u7a7a\u95f4\u3002"}}
{"id": "2601.11835", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11835", "abs": "https://arxiv.org/abs/2601.11835", "authors": ["Yufan Zhang", "Jaromir Savelka", "Seth Goldstein", "Michael Conway"], "title": "Changes in Coding Behavior and Performance Since the Introduction of LLMs", "comment": null, "summary": "The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.\n  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0ChatGPT\u53d1\u5e03\u540e\uff0c\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u548c\u6210\u7ee9\u6709\u663e\u8457\u53d8\u5316\uff0c\u5b58\u5728\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u4e0b\u964d\u7684\u98ce\u9669\uff0c\u6559\u80b2\u548c\u7528\u4eba\u5355\u4f4d\u9700\u8c03\u6574\u8bc4\u4ef7\u65b9\u6cd5\u5e94\u5bf9\u65b0\u6311\u6218\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u7684\u666e\u53ca\uff0c\u5b66\u751f\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u63d0\u5347\u7f16\u7a0b\u548c\u89e3\u51b3\u95ee\u9898\u7684\u6548\u7387\uff0c\u4f46\u4e5f\u5e26\u6765\u4e86\u6559\u5e08\u96be\u4ee5\u51c6\u786e\u8bc4\u4f30\u5b66\u751f\u771f\u5b9e\u5b66\u4e60\u6210\u679c\u548c\u52aa\u529b\u7a0b\u5ea6\u7684\u6311\u6218\u3002", "method": "\u91c7\u7528\u51c6\u7eb5\u5411\u7814\u7a76\u65b9\u6cd5\uff0c\u5206\u6790\u7814\u7a76\u751f\u4e91\u8ba1\u7b97\u8bfe\u7a0b\u4e2d\u4e00\u4e2a\u672a\u66f4\u6539\u4f5c\u4e1a\u7684\u5341\u4e2a\u5b66\u671f\uff08\u4e94\u4e2a\u5b66\u671f\u524d\u540eChatGPT\u53d1\u5e03\uff09\u7684\u5b66\u751f\u6e90\u4ee3\u7801\u63d0\u4ea4\u884c\u4e3a\uff0c\u6bd4\u8f83\u4e0d\u540c\u65f6\u671f\u5b66\u751f\u7f16\u7801\u884c\u4e3a\u548c\u6210\u7ee9\u53d8\u5316\u3002", "result": "\u53d1\u73b0\u5b66\u751f\u63d0\u4ea4\u7684\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\uff0c\u8fde\u7eed\u63d0\u4ea4\u4e4b\u95f4\u7f16\u8f91\u8ddd\u79bb\u5e73\u5747\u503c\u4e0a\u5347\u4f46\u5206\u6570\u63d0\u5347\u51cf\u5c11\uff0c\u4e14\u8fd9\u4e9b\u884c\u4e3a\u53d8\u5316\u4e0e\u6574\u4f53\u8868\u73b0\u5b58\u5728\u663e\u8457\u7edf\u8ba1\u76f8\u5173\u6027\uff0c\u652f\u6301\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56LLM\u5bfc\u81f4\u5b66\u4e60\u8d28\u91cf\u4e0b\u964d\u7684\u5047\u8bbe\u3002", "conclusion": "\u5b66\u751f\u7f16\u7a0b\u884c\u4e3a\u81eaChatGPT\u53d1\u5e03\u4ee5\u6765\u663e\u8457\u53d8\u5316\uff0c\u8868\u73b0\u4e3a\u63d0\u4ea4\u4ee3\u7801\u957f\u5ea6\u589e\u52a0\u3001\u7f16\u8f91\u8ddd\u79bb\u589e\u5927\u548c\u6210\u7ee9\u63d0\u5347\u51cf\u5c0f\uff0c\u6697\u793a\u5b66\u751f\u751f\u4ea7\u529b\u548c\u5b66\u4e60\u6548\u679c\u4e0b\u964d\uff0c\u53ef\u80fd\u56e0\u90e8\u5206\u5b66\u751f\u8fc7\u5ea6\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b66\u4e60\u6210\u679c\u53d7\u8d1f\u9762\u5f71\u54cd\u3002"}}
{"id": "2601.11581", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11581", "abs": "https://arxiv.org/abs/2601.11581", "authors": ["Yuefeng Wang", "ChangJae Lee"], "title": "Enhancing the QA Model through a Multi-domain Debiasing Framework", "comment": "5 pages, 7 tables", "summary": "Question-answering (QA) models have advanced significantly in machine reading comprehension but often exhibit biases that hinder their performance, particularly with complex queries in adversarial conditions. This study evaluates the ELECTRA-small model on the Stanford Question Answering Dataset (SQuAD) v1.1 and adversarial datasets AddSent and AddOneSent. By identifying errors related to lexical bias, numerical reasoning, and entity recognition, we develop a multi-domain debiasing framework incorporating knowledge distillation, debiasing techniques, and domain expansion. Our results demonstrate up to 2.6 percentage point improvements in Exact Match (EM) and F1 scores across all test sets, with gains in adversarial contexts. These findings highlight the potential of targeted bias mitigation strategies to enhance the robustness and reliability of natural language understanding systems.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9QA\u6a21\u578b\u504f\u89c1\u95ee\u9898\uff0c\u63d0\u51fa\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5728\u6807\u51c6\u4e0e\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\uff0c\u589e\u5f3a\u4e86\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524dQA\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u67e5\u8be2\u53ca\u5bf9\u6297\u573a\u666f\u65f6\u5b58\u5728\u504f\u89c1\uff0c\u5f71\u54cd\u5176\u8868\u73b0\u4e0e\u9c81\u68d2\u6027\uff0c\u4e9f\u9700\u6709\u6548\u7684\u53bb\u504f\u7b56\u7565\u63d0\u5347\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u8bc4\u4f30ELECTRA-small\u6a21\u578b\u5728SQuAD v1.1\u53ca\u5bf9\u6297\u6570\u636e\u96c6AddSent\u548cAddOneSent\u4e0a\u7684\u8868\u73b0\uff0c\u8bc6\u522b\u4e86\u4e0e\u8bcd\u6c47\u504f\u89c1\u3001\u6570\u503c\u63a8\u7406\u548c\u5b9e\u4f53\u8bc6\u522b\u76f8\u5173\u7684\u9519\u8bef\uff0c\u8fdb\u800c\u91c7\u7528\u77e5\u8bc6\u84b8\u998f\u3001\u53bb\u504f\u6280\u672f\u548c\u9886\u57df\u6269\u5c55\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u8fdb\u884c\u591a\u9886\u57df\u53bb\u504f\u8bad\u7ec3\u3002", "result": "\u63d0\u51fa\u7684\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\u5728\u6240\u6709\u6d4b\u8bd5\u96c6\u4e2dExact Match\u548cF1\u5206\u6570\u6700\u9ad8\u63d0\u53472.6\u4e2a\u767e\u5206\u70b9\uff0c\u7279\u522b\u662f\u5728\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u663e\u8457\u589e\u76ca\u3002", "conclusion": "\u9488\u5bf9\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u7cfb\u7edf\u4e2d\u7684\u504f\u89c1\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u9886\u57df\u53bb\u504f\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5728\u6807\u51c6\u548c\u5bf9\u6297\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2601.11836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.11836", "abs": "https://arxiv.org/abs/2601.11836", "authors": ["Finn Hackett", "Evan Wrench", "Peter Macko", "A. Jesse Jiryu Davis", "Yuanhao Wei", "Ivan Beschastnikh"], "title": "Trace Validation of Unmodified Concurrent Systems with OmniLink", "comment": null, "summary": "Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.\n  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.", "AI": {"tldr": "OmniLink\u662f\u4e00\u79cd\u57fa\u4e8eTLA+\u7684\u9ad8\u6548\u7075\u6d3b\u5e76\u53d1\u7cfb\u7edf\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u80fd\u5904\u7406\u66f4\u590d\u6742\u884c\u4e3a\uff0c\u6027\u80fd\u9886\u5148\uff0c\u4e14\u6210\u529f\u53d1\u73b0\u591a\u4e2a\u7cfb\u7edf\u6f0f\u6d1e\u3002", "motivation": "\u5e76\u53d1\u7cfb\u7edf\u96be\u4ee5\u9a8c\u8bc1\uff0c\u73b0\u6709\u5de5\u5177\u901a\u5e38\u9700\u4fb5\u5165\u5f0f\u63d2\u6869\u6216\u4f9d\u8d56\u4e0d\u73b0\u5b9e\u6267\u884c\u6a21\u578b\uff0c\u73b0\u6709TLA+\u57fa\u7684\u9a8c\u8bc1\u65b9\u6cd5\u53d7\u9650\uff0c\u9700\u63d0\u51fa\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u9a8c\u8bc1\u5de5\u5177\u3002", "method": "OmniLink\u5c06\u7cfb\u7edf\u4e8b\u4ef6\u89c6\u4e3a\u5e26\u6709\u65f6\u95f4\u533a\u95f4\u548cTLA+\u8bed\u4e49\u7684\u9ed1\u76d2\uff0c\u901a\u8fc7\u57fa\u4e8e\u73b0\u6210\u6a21\u578b\u68c0\u6d4b\u5668\u7684\u7ebf\u6027\u5316\u68c0\u67e5\u65b9\u6cd5\uff0c\u89e3\u51b3\u52a8\u4f5c\u7684\u903b\u8f91\u5168\u5e8f\u95ee\u9898\uff0c\u533a\u522b\u4e8e\u4f20\u7edf\u7684\u8f68\u8ff9\u9a8c\u8bc1\u548c\u7ebf\u6027\u5316\u68c0\u67e5\u3002", "result": "OmniLink\u6210\u529f\u9a8c\u8bc1\u4e86\u591a\u4e2a\u590d\u6742\u5e76\u53d1\u7cfb\u7edf\uff08\u5982WiredTiger\u3001BAT\u3001ConcurrentQueue\uff09\uff0c\u6539\u8fdb\u4e86\u5df2\u6709\u6a21\u578b\uff0c\u53d1\u73b0\u4e86\u4e24\u4e2a\u672a\u77e5Bug\uff0c\u4e14\u6027\u80fd\u4f18\u4e8e\u5f53\u524d\u540c\u884c\u65b9\u6cd5\u3002", "conclusion": "OmniLink\u662f\u4e00\u79cd\u521b\u65b0\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u9ad8\u6548\u4e14\u7075\u6d3b\u5730\u9a8c\u8bc1\u5e76\u53d1\u7cfb\u7edf\u5b9e\u73b0\u4e0eTLA+\u9ad8\u5c42\u89c4\u8303\u4e4b\u95f4\u7684\u4e00\u81f4\u6027\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7ebf\u6027\u5316\u68c0\u67e5\u5de5\u5177\uff0c\u4e14\u80fd\u591f\u53d1\u73b0\u5df2\u77e5\u53ca\u672a\u77e5\u7684\u7cfb\u7edf\u6f0f\u6d1e\u3002"}}
{"id": "2601.11585", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11585", "abs": "https://arxiv.org/abs/2601.11585", "authors": ["Hyunjun Kim"], "title": "Entropic Context Shaping: Information-Theoretic Filtering for Context-Aware LLM Agents", "comment": null, "summary": "Context engineering for large language model (LLM) agents requires distinguishing pragmatically useful information from misleading distractors. We introduce Entropic Context Shaping (ECS), an information-theoretic framework that measures context utility via the shift in the model's answer distribution toward the correct answer. Unlike lexical similarity methods that rely on word overlap, ECS captures pragmatic utility -- whether a passage actually helps answer the question. We formalize utility as the signed change in answer probability and provide theoretical analysis showing that task-irrelevant updates yield near-zero distribution shift. We evaluate on multi-turn context selection tasks using LongMemEval (session-level) and LoCoMo (turn-level) benchmarks. On fine-grained turn selection, ECS with Llama-3.1-8B achieves F1=0.265, a 71.83% relative improvement over TF-IDF (F1=0.154), demonstrating that pragmatic utility outperforms lexical similarity when precise context selection matters. Code and data are available in the supplementary materials.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684\u4e0a\u4e0b\u6587\u9009\u62e9\u65b0\u65b9\u6cd5ECS\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7cbe\u51c6\u4e0a\u4e0b\u6587\u7b5b\u9009\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u3002", "motivation": "\u4e0a\u4e0b\u6587\u5de5\u7a0b\u9700\u8981\u533a\u5206\u771f\u6b63\u6709\u52a9\u4e8e\u56de\u7b54\u95ee\u9898\u7684\u4fe1\u606f\u548c\u8bef\u5bfc\u6027\u5e72\u6270\u4fe1\u606f\uff0c\u800c\u4f20\u7edf\u8bcd\u6c47\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5b9e\u9645\u7684\u8bed\u7528\u6548\u7528\u3002  ", "method": "\u5f15\u5165\u57fa\u4e8e\u4fe1\u606f\u8bba\u7684ECS\u6846\u67b6\uff0c\u901a\u8fc7\u6d4b\u91cf\u6a21\u578b\u7b54\u6848\u5206\u5e03\u5411\u6b63\u786e\u7b54\u6848\u8f6c\u53d8\u7684\u7a0b\u5ea6\u6765\u8bc4\u4f30\u4e0a\u4e0b\u6587\u7684\u5b9e\u7528\u6027\uff0c\u6446\u8131\u4e86\u4f20\u7edf\u57fa\u4e8e\u8bcd\u6c47\u91cd\u53e0\u7684\u76f8\u4f3c\u6027\u65b9\u6cd5\u3002", "result": "\u5728LongMemEval\u548cLoCoMo\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cECS\u5728\u7ec6\u7c92\u5ea6\u7684\u8f6e\u6b21\u9009\u62e9\u4efb\u52a1\u4e2d\u4f7f\u7528Llama-3.1-8B\u6a21\u578b\u5b9e\u73b0\u4e86F1=0.265\uff0c\u76f8\u8f83\u4f20\u7edf\u7684TF-IDF\u65b9\u6cd5\u63d0\u5347\u4e8671.83%\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684Entropic Context Shaping (ECS)\u65b9\u6cd5\u6709\u6548\u533a\u5206\u4e86\u6709\u52a9\u4e8e\u56de\u7b54\u95ee\u9898\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u5e72\u6270\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e0a\u4e0b\u6587\u9009\u62e9\u6027\u80fd\u3002"}}
{"id": "2601.11868", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11868", "abs": "https://arxiv.org/abs/2601.11868", "authors": ["Mike A. Merrill", "Alexander G. Shaw", "Nicholas Carlini", "Boxuan Li", "Harsh Raj", "Ivan Bercovich", "Lin Shi", "Jeong Yeon Shin", "Thomas Walshe", "E. Kelly Buchanan", "Junhong Shen", "Guanghao Ye", "Haowei Lin", "Jason Poulos", "Maoyu Wang", "Marianna Nezhurina", "Jenia Jitsev", "Di Lu", "Orfeas Menis Mastromichalakis", "Zhiwei Xu", "Zizhao Chen", "Yue Liu", "Robert Zhang", "Leon Liangyu Chen", "Anurag Kashyap", "Jan-Lucas Uslu", "Jeffrey Li", "Jianbo Wu", "Minghao Yan", "Song Bian", "Vedang Sharma", "Ke Sun", "Steven Dillmann", "Akshay Anand", "Andrew Lanpouthakoun", "Bardia Koopah", "Changran Hu", "Etash Guha", "Gabriel H. S. Dreiman", "Jiacheng Zhu", "Karl Krauth", "Li Zhong", "Niklas Muennighoff", "Robert Amanfu", "Shangyin Tan", "Shreyas Pimpalgaonkar", "Tushar Aggarwal", "Xiangning Lin", "Xin Lan", "Xuandong Zhao", "Yiqing Liang", "Yuanli Wang", "Zilong Wang", "Changzhi Zhou", "David Heineman", "Hange Liu", "Harsh Trivedi", "John Yang", "Junhong Lin", "Manish Shetty", "Michael Yang", "Nabil Omi", "Negin Raoof", "Shanda Li", "Terry Yue Zhuo", "Wuwei Lin", "Yiwei Dai", "Yuxin Wang", "Wenhao Chai", "Shang Zhou", "Dariush Wahdany", "Ziyu She", "Jiaming Hu", "Zhikang Dong", "Yuxuan Zhu", "Sasha Cui", "Ahson Saiyed", "Arinbj\u00f6rn Kolbeinsson", "Jesse Hu", "Christopher Michael Rytting", "Ryan Marten", "Yixin Wang", "Alex Dimakis", "Andy Konwinski", "Ludwig Schmidt"], "title": "Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces", "comment": null, "summary": "AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a8\u51fa\u4e86Terminal-Bench 2.0\uff0c\u4e00\u4e2a\u96be\u5ea6\u8f83\u5927\u7684\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u8ba1\u7b97\u4efb\u52a1\u96c6\uff0c\u6d4b\u8bd5\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u8868\u73b0\u6709\u9650\uff0c\u5e76\u63d0\u4f9b\u4e86\u6570\u636e\u548c\u5de5\u5177\u652f\u6301\u672a\u6765\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u8981\u4e48\u672a\u80fd\u8861\u91cf\u771f\u5b9e\u4e16\u754c\u4efb\u52a1\uff0c\u8981\u4e48\u96be\u5ea6\u4e0d\u8db3\uff0c\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u5148\u8fdb\u6a21\u578b\u7684\u80fd\u529b\u3002\u4e3a\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u65e2\u771f\u5b9e\u53c8\u5177\u6709\u6311\u6218\u6027\u7684\u6d4b\u8bd5\u5e73\u53f0\u3002", "method": "\u8bbe\u8ba1\u5e76\u6784\u5efa\u4e86Terminal-Bench 2.0\uff0c\u4e00\u4e2a\u753189\u4e2a\u8ba1\u7b97\u673a\u7ec8\u7aef\u73af\u5883\u4efb\u52a1\u7ec4\u6210\u7684\u96be\u5ea6\u8f83\u9ad8\u7684\u57fa\u51c6\uff0c\u4efb\u52a1\u57fa\u4e8e\u771f\u5b9e\u5de5\u4f5c\u6d41\u7a0b\u7f16\u5199\uff0c\u5e76\u914d\u6709\u4eba\u7c7b\u89e3\u51b3\u65b9\u6848\u53ca\u5168\u9762\u7684\u9a8c\u8bc1\u6d4b\u8bd5\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u548c\u667a\u80fd\u4f53\u5728\u8be5\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u5747\u672a\u8d85\u8fc765%\uff0c\u901a\u8fc7\u9519\u8bef\u5206\u6790\u63ed\u793a\u4e86\u6539\u8fdb\u7684\u5173\u952e\u9886\u57df\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u8bc4\u6d4b\u6846\u67b6\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002", "conclusion": "\u5f53\u524d\u524d\u6cbf\u6a21\u578b\u5728Terminal-Bench 2.0\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5f97\u5206\u4f4e\u4e8e65%\uff0c\u8868\u660e\u5176\u5728\u5b8c\u6210\u590d\u6742\u7684\u957f\u65f6\u4efb\u52a1\u65b9\u9762\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2601.11658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11658", "abs": "https://arxiv.org/abs/2601.11658", "authors": ["Indrajit Kar", "Sammy Zonunpuia", "Zonunfeli Ralte"], "title": "Towards AGI A Pragmatic Approach Towards Self Evolving Agent", "comment": null, "summary": "Large Language Model (LLM) based agents are powerful yet fundamentally static after deployment, lacking the ability to autonomously expand capabilities, generate new tools, or evolve their reasoning. This work introduces a hierarchical self-evolving multi-agent framework that integrates a Base LLM, an operational SLM agent, a Code-Generation LLM, and a Teacher-LLM to enable continuous adaptation. The workflow begins with the agent attempting a task using reasoning and existing tools; if unsuccessful, it escalates to tool synthesis through the Code-Gen LLM, and when failures persist, it triggers an evolution phase using Curriculum Learning (CL), Reward-Based Learning (RL), or Genetic Algorithm (GA) evolution. Using the TaskCraft dataset rich in hierarchical tasks, tool-use traces, and difficulty scaling we evaluate these paradigms. CL delivers fast recovery and strong generalization, RL excels on high-difficulty tasks, and GA offers high behavioral diversity. Across all settings, evolved agents outperform their originals, demonstrating robust, autonomous, self-improving agentic evolution.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u96c6\u591a\u79cd\u5b66\u4e60\u673a\u5236\u7684\u5c42\u7ea7\u81ea\u6211\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86LLM\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u80fd\u529b\u6269\u5c55\u548c\u6301\u7eed\u8fdb\u5316\uff0c\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u9a71\u52a8\u7684\u667a\u80fd\u4f53\u5728\u90e8\u7f72\u540e\u80fd\u529b\u56fa\u5b9a\uff0c\u7f3a\u4e4f\u81ea\u6211\u6269\u5c55\u3001\u65b0\u5de5\u5177\u751f\u6210\u548c\u63a8\u7406\u8fdb\u5316\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5c42\u7ea7\u81ea\u6211\u8fdb\u5316\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u6574\u5408\u57fa\u7840LLM\u3001\u64cd\u4f5cSLM\u667a\u80fd\u4f53\u3001\u4ee3\u7801\u751f\u6210LLM\u53ca\u6559\u5e08LLM\uff0c\u5b9e\u73b0\u6301\u7eed\u9002\u5e94\u3002\u5de5\u4f5c\u6d41\u7a0b\u5305\u62ec\u5c1d\u8bd5\u4efb\u52a1\u3001\u5de5\u5177\u5408\u6210\u3001\u4ee5\u53ca\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u3001\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60\u6216\u9057\u4f20\u7b97\u6cd5\u8fdb\u884c\u8fdb\u5316\u3002", "result": "\u5728\u5305\u542b\u5c42\u7ea7\u4efb\u52a1\u3001\u5de5\u5177\u4f7f\u7528\u8f68\u8ff9\u548c\u96be\u5ea6\u5206\u7ea7\u7684TaskCraft\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0c\u8bfe\u7a0b\u5b66\u4e60\u80fd\u5feb\u901f\u6062\u590d\u548c\u6cdb\u5316\uff0c\u57fa\u4e8e\u5956\u52b1\u7684\u5b66\u4e60\u5728\u9ad8\u96be\u5ea6\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u9057\u4f20\u7b97\u6cd5\u63d0\u4f9b\u9ad8\u5ea6\u884c\u4e3a\u591a\u6837\u6027\u3002\u8fdb\u5316\u540e\u7684\u667a\u80fd\u4f53\u5728\u5404\u9879\u6307\u6807\u5747\u4f18\u4e8e\u539f\u59cb\u667a\u80fd\u4f53\uff0c\u5c55\u73b0\u51fa\u9c81\u68d2\u3001\u81ea\u4e3b\u3001\u81ea\u6211\u63d0\u5347\u7684\u8fdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u667a\u80fd\u4f53\u7684\u81ea\u4e3b\u8fdb\u5316\u548c\u6301\u7eed\u81ea\u6211\u63d0\u5347\uff0c\u5f25\u8865\u4e86\u4f20\u7edfLLM\u667a\u80fd\u4f53\u80fd\u529b\u9759\u6001\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u53d1\u5c55\u3002"}}
{"id": "2601.11926", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11926", "abs": "https://arxiv.org/abs/2601.11926", "authors": ["Ananya Halgatti", "Shaunak Biswas", "Hiya Bhatt", "Srinivasan Rakhunathan", "Karthik Vaidhyanathan"], "title": "Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps", "comment": "This paper has been accepted to SEAMS 2026 Artifact Track", "summary": "Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Harmonica\uff0c\u4e00\u79cd\u57fa\u4e8eMAPE-K\u5faa\u73af\u7684\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u81ea\u9002\u5e94\u63a7\u5236\u6846\u67b6\uff0c\u589e\u5f3a\u4e86MLOps\u6d41\u6c34\u7ebf\u4e2d\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u6027\u548c\u53ef\u6301\u7eed\u8fd0\u884c\u80fd\u529b\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u4e0d\u65ad\u53d8\u5316\u7684\u73af\u5883\u4e2d\u8fd0\u884c\u65f6\u6613\u53d7\u4e0d\u786e\u5b9a\u6027\u5f71\u54cd\uff0c\u4f20\u7edfMLOps\u5728\u5904\u7406\u8fd0\u884c\u65f6\u4e0d\u786e\u5b9a\u6027\u548c\u7cfb\u7edf\u53ef\u6301\u7eed\u6027\u65b9\u9762\u652f\u6301\u6709\u9650\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u673a\u5236\u6765\u68c0\u6d4b\u504f\u5dee\u5e76\u81ea\u9002\u5e94\u8c03\u6574\u7cfb\u7edf\u884c\u4e3a\u3002", "method": "\u57fa\u4e8eHarmonE\u65b9\u6cd5\uff0c\u6784\u5efaHarmonica\u81ea\u9002\u5e94\u793a\u4f8b\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5c42\u9002\u5e94\u7b56\u7565\u4e0e\u4f4e\u5c42\u6267\u884c\u7b56\u7565\u7684\u5206\u79bb\uff0c\u7ed3\u5408\u52a8\u6001\u9002\u5e94\u8fb9\u754c\u548c\u6301\u7eed\u76d1\u63a7\u673a\u5236\uff0c\u81ea\u52a8\u89e6\u53d1\u67b6\u6784\u8c03\u6574\u7b56\u7565\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660eHarmonica\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u5b9e\u73b0\u65f6\u95f4\u5e8f\u5217\u56de\u5f52\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u4e2d\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u7684\u6301\u7eed\u53ef\u7528\u6027\u3002", "conclusion": "Harmonica\u4e3a\u673a\u5668\u5b66\u4e60\u64cd\u4f5c\u6d41\u6c34\u7ebf\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6301\u7eed\u8fd0\u884c\u7684\u81ea\u9002\u5e94\u63a7\u5236\u673a\u5236\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684MAPE-K\u5faa\u73af\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7a33\u5b9a\u6027\uff0c\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\uff0c\u4fc3\u8fdb\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5728\u4e0d\u786e\u5b9a\u73af\u5883\u4e0b\u7684\u957f\u671f\u53ef\u7528\u6027\u3002"}}
{"id": "2601.11722", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.11722", "abs": "https://arxiv.org/abs/2601.11722", "authors": ["Ahmed Rayane Kebir", "Vincent Guigue", "Lynda Said Lhadj", "Laure Soulier"], "title": "RAC: Retrieval-Augmented Clarification for Faithful Conversational Search", "comment": "This is the author's version of the work. The definitive version is published in: Proceedings of the 48th European Conference on Information Retrieval (ECIR '26), 29 March--2 April, 2026, Delft, Netherlands", "summary": "Clarification questions help conversational search systems resolve ambiguous or underspecified user queries. While prior work has focused on fluency and alignment with user intent, especially through facet extraction, much less attention has been paid to grounding clarifications in the underlying corpus. Without such grounding, systems risk asking questions that cannot be answered from the available documents. We introduce RAC (Retrieval-Augmented Clarification), a framework for generating corpus-faithful clarification questions. After comparing several indexing strategies for retrieval, we fine-tune a large language model to make optimal use of research context and to encourage the generation of evidence-based question. We then apply contrastive preference optimization to favor questions supported by retrieved passages over ungrounded alternatives. Evaluated on four benchmarks, RAC demonstrate significant improvements over baselines. In addition to LLM-as-Judge assessments, we introduce novel metrics derived from NLI and data-to-text to assess how well questions are anchored in the context, and we demonstrate that our approach consistently enhances faithfulness.", "AI": {"tldr": "\u63d0\u51faRAC\u6846\u67b6\uff0c\u901a\u8fc7\u68c0\u7d22\u589e\u5f3a\u548c\u5bf9\u6bd4\u4f18\u5316\uff0c\u751f\u6210\u66f4\u52a0\u57fa\u4e8e\u8bed\u6599\u7684\u53ef\u4fe1\u6f84\u6e05\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u5bf9\u8bdd\u68c0\u7d22\u7cfb\u7edf\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5c06\u6f84\u6e05\u95ee\u9898\u4e0e\u5e95\u5c42\u8bed\u6599\u5e93\u7d27\u5bc6\u7ed3\u5408\uff0c\u5bfc\u81f4\u4ea7\u751f\u65e0\u6cd5\u4ece\u6587\u6863\u4e2d\u56de\u7b54\u7684\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u4e86RAC\u6846\u67b6\uff0c\u4f18\u5316\u7d22\u5f15\u7b56\u7565\uff0c\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5229\u7528\u5bf9\u6bd4\u504f\u597d\u4f18\u5316\u4fc3\u8fdb\u57fa\u4e8e\u8bc1\u636e\u7684\u95ee\u9898\u751f\u6210\u3002", "result": "RAC\u5728\u56db\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u591a\u9879\u65b0\u9896\u6307\u6807\u4e0a\u9a8c\u8bc1\u4e86\u751f\u6210\u95ee\u9898\u7684\u8bed\u6599\u5e93\u951a\u5b9a\u6027\u548c\u53ef\u4fe1\u5ea6\u63d0\u5347\u3002", "conclusion": "RAC\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5bf9\u8bdd\u68c0\u7d22\u7cfb\u7edf\u4e2d\u6f84\u6e05\u95ee\u9898\u7684\u8bed\u6599\u5e93\u53ef\u4fe1\u5ea6\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.11972", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.11972", "abs": "https://arxiv.org/abs/2601.11972", "authors": ["Chi Thien Tran"], "title": "Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation", "comment": "4 tables, 4 figures, 7 pages", "summary": "Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u9759\u6001\u5206\u6790\u81ea\u52a8\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\uff0c\u89e3\u51b3\u4e86\u624b\u5de5\u6784\u5efa\u6d4b\u8bd5\u76ee\u6807\u8017\u65f6\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u9879\u76ee\u7684\u6a21\u7cca\u6d4b\u8bd5\u6548\u7387\u3002", "motivation": "\u624b\u5de5\u521b\u5efa\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u5728\u5927\u578b\u8f6f\u4ef6\u9879\u76ee\u4e2d\u975e\u5e38\u8017\u65f6\uff0c\u4e14\u9700\u8981\u81ea\u52a8\u5316\u6280\u672f\u4ee5\u63d0\u5347\u6d4b\u8bd5\u8d28\u91cf\u548c\u6548\u7387\u3002", "method": "\u4f7f\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u6784\u5efa\u51fd\u6570\u8c03\u7528\uff0c\u6620\u5c04\u8f93\u5165\u6570\u636e\u5230\u51fd\u6570\u53c2\u6570\uff0c\u6574\u5408\u7f16\u8bd1\u4fe1\u606f\uff0c\u5e76\u81ea\u52a8\u6536\u96c6\u5206\u6790\u6267\u884c\u7ed3\u679c\u3002", "result": "\u6210\u529f\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eC/C++\u5e93\uff0c\u6548\u679c\u826f\u597d\uff0c\u63d0\u5347\u4e86\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u751f\u6210\u7684\u81ea\u52a8\u5316\u548c\u8986\u76d6\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u9759\u6001\u5206\u6790\u5e93\u6e90\u7801\u6765\u81ea\u52a8\u751f\u6210\u6a21\u7cca\u6d4b\u8bd5\u76ee\u6807\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u7cca\u6d4b\u8bd5\u7684\u8986\u76d6\u7387\u548c\u6548\u7387\u3002"}}
{"id": "2601.11739", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11739", "abs": "https://arxiv.org/abs/2601.11739", "authors": ["Xinyu Pi", "Qisen Yang", "Chuong Nguyen", "Hua Shen"], "title": "Bridging Human Interpretation and Machine Representation: A Landscape of Qualitative Data Analysis in the LLM Era", "comment": null, "summary": "LLMs are increasingly used to support qualitative research, yet existing systems produce outputs that vary widely--from trace-faithful summaries to theory-mediated explanations and system models. To make these differences explicit, we introduce a 4$\\times$4 landscape crossing four levels of meaning-making (descriptive, categorical, interpretive, theoretical) with four levels of modeling (static structure, stages/timelines, causal pathways, feedback dynamics). Applying the landscape to prior LLM-based automation highlights a strong skew toward low-level meaning and low-commitment representations, with few reliable attempts at interpretive/theoretical inference or dynamical modeling. Based on the revealed gap, we outline an agenda for applying and building LLM-systems that make their interpretive and modeling commitments explicit, selectable, and governable.", "AI": {"tldr": "\u672c\u6587\u5efa\u7acb\u4e86\u4e00\u4e2a4\u00d74\u6846\u67b6\u5206\u6790LLM\u5728\u5b9a\u6027\u7814\u7a76\u4e2d\u7684\u5e94\u7528\uff0c\u53d1\u73b0\u73b0\u6709\u7cfb\u7edf\u591a\u505c\u7559\u5728\u4f4e\u5c42\u6b21\u63cf\u8ff0\u4e0e\u9759\u6001\u5efa\u6a21\uff0c\u672a\u6765\u5e94\u589e\u5f3a\u89e3\u91ca\u6027\u63a8\u65ad\u548c\u52a8\u6001\u5efa\u6a21\u80fd\u529b\u3002", "motivation": "\u5f53\u524dLLM\u7cfb\u7edf\u5728\u652f\u6301\u5b9a\u6027\u7814\u7a76\u65f6\uff0c\u8f93\u51fa\u8d28\u91cf\u5dee\u5f02\u5927\uff0c\u7f3a\u4e4f\u5bf9\u4e0d\u540c\u7406\u89e3\u5c42\u6b21\u548c\u5efa\u6a21\u65b9\u5f0f\u7684\u660e\u786e\u533a\u5206\uff0c\u9700\u8981\u4e00\u4e2a\u660e\u786e\u6846\u67b6\u5e2e\u52a9\u7406\u89e3\u548c\u63d0\u5347\u7cfb\u7edf\u7684\u89e3\u91ca\u529b\u548c\u6a21\u578b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a4\u00d74\u7684\u6846\u67b6\uff0c\u7ed3\u5408\u56db\u4e2a\u610f\u4e49\u5c42\u6b21\uff08\u63cf\u8ff0\u6027\u3001\u5206\u7c7b\u6027\u3001\u89e3\u91ca\u6027\u3001\u7406\u8bba\u6027\uff09\u4e0e\u56db\u4e2a\u5efa\u6a21\u5c42\u6b21\uff08\u9759\u6001\u7ed3\u6784\u3001\u9636\u6bb5/\u65f6\u95f4\u7ebf\u3001\u56e0\u679c\u8def\u5f84\u3001\u53cd\u9988\u52a8\u6001\uff09\uff0c\u5e76\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u5df2\u6709LLM\u81ea\u52a8\u5316\u7cfb\u7edf\u7684\u5206\u6790\u3002", "result": "\u901a\u8fc7\u8be54\u00d74\u6846\u67b6\u5206\u6790\u53d1\u73b0\u73b0\u6709LLM\u7cfb\u7edf\u666e\u904d\u504f\u91cd\u4f4e\u5c42\u610f\u4e49\u548c\u4f4e\u627f\u8bfa\u5efa\u6a21\uff0c\u63d0\u51fa\u672a\u6765\u5e94\u53d1\u5c55\u80fd\u591f\u660e\u786e\u3001\u53ef\u9009\u62e9\u3001\u53ef\u7ba1\u7406\u89e3\u91ca\u53ca\u5efa\u6a21\u5c42\u6b21\u7684LLM\u7cfb\u7edf\u3002", "conclusion": "\u73b0\u6709\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7cfb\u7edf\u591a\u505c\u7559\u5728\u4f4e\u5c42\u6b21\u7684\u63cf\u8ff0\u548c\u7ed3\u6784\u5efa\u6a21\uff0c\u7f3a\u4e4f\u5bf9\u89e3\u91ca\u6027\u548c\u7406\u8bba\u63a8\u65ad\u4ee5\u53ca\u52a8\u6001\u5efa\u6a21\u7684\u53ef\u9760\u5c1d\u8bd5\u3002"}}
{"id": "2601.12146", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12146", "abs": "https://arxiv.org/abs/2601.12146", "authors": ["Viktor Kjellberg", "Miroslaw Staron", "Farnaz Fotrousi"], "title": "From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler", "comment": null, "summary": "Large Language Models have demonstrated a remarkable capability in natural language and program generation and software development. However, the source code generated by the LLMs does not always meet quality requirements and may fail to compile. Therefore, many studies evolve into agents that can reason about the problem before generating the source code for the solution. The goal of this paper is to study the degree to which such agents benefit from access to software development tools, in our case, a \\texttt{gcc} compiler. We conduct a computational experiment on the RosettaCode dataset, on 699 programming tasks in C. We evaluate how the integration with a compiler shifts the role of the language model from a passive generator to an active agent capable of iteratively developing runnable programs based on feedback from the compiler. We evaluated 16 language models with sizes ranging from small (135 million) to medium (3 billion) and large (70 billion). Our results show that access to a compiler improved the compilation success by 5.3 to 79.4 percentage units in compilation without affecting the semantics of the generated program. Syntax errors dropped by 75\\%, and errors related to undefined references dropped by 87\\% for the tasks where the agents outperformed the baselines. We also observed that in some cases, smaller models with a compiler outperform larger models with a compiler. We conclude that it is essential for LLMs to have access to software engineering tools to enhance their performance and reduce the need for large models in software engineering, such as reducing our energy footprint.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408gcc\u7f16\u8bd1\u5668\u751f\u6210C\u8bed\u8a00\u4ee3\u7801\u7684\u6548\u679c\uff0c\u53d1\u73b0\u7f16\u8bd1\u5668\u53cd\u9988\u5927\u5e45\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\uff0c\u4e00\u4e9b\u5c0f\u6a21\u578b\u751a\u81f3\u4f18\u4e8e\u5927\u6a21\u578b\uff0c\u5f3a\u8c03\u5de5\u5177\u8f85\u52a9\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u4ee3\u7801\u8d28\u91cf\u4e0d\u7a33\u5b9a\uff0c\u5b58\u5728\u65e0\u6cd5\u7f16\u8bd1\u7684\u95ee\u9898\uff0c\u9700\u8981\u63a2\u7d22\u5176\u901a\u8fc7\u63a8\u7406\u80fd\u529b\u548c\u5de5\u5177\u8f85\u52a9\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u7684\u53ef\u80fd\u6027\u3002", "method": "\u5728RosettaCode\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9699\u4e2aC\u8bed\u8a00\u7f16\u7a0b\u4efb\u52a1\u8fdb\u884c\u5b9e\u9a8c\uff0c\u4f7f\u7528\u4e0d\u540c\u89c4\u6a21\u768416\u4e2a\u8bed\u8a00\u6a21\u578b\u7ed3\u5408gcc\u7f16\u8bd1\u5668\uff0c\u8bc4\u4f30\u6a21\u578b\u5728\u7f16\u8bd1\u5668\u53cd\u9988\u4e0b\u8fed\u4ee3\u5f00\u53d1\u53ef\u8fd0\u884c\u7a0b\u5e8f\u7684\u6548\u679c\u3002", "result": "\u63a5\u5165\u7f16\u8bd1\u5668\u540e\uff0c\u7f16\u8bd1\u6210\u529f\u7387\u63d0\u53475.3\u81f379.4\u4e2a\u767e\u5206\u70b9\uff0c\u8bed\u6cd5\u9519\u8bef\u51cf\u5c1175%\uff0c\u672a\u5b9a\u4e49\u5f15\u7528\u9519\u8bef\u51cf\u5c1187%\u3002\u90e8\u5206\u5c0f\u6a21\u578b\u7ed3\u5408\u7f16\u8bd1\u5668\u7684\u8868\u73b0\u4f18\u4e8e\u5927\u578b\u6a21\u578b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\uff08\u5982\u7f16\u8bd1\u5668\uff09\u80fd\u591f\u663e\u8457\u63d0\u5347\u4ee3\u7801\u751f\u6210\u8d28\u91cf\uff0c\u964d\u4f4e\u9519\u8bef\u7387\uff0c\u51cf\u5c11\u5bf9\u5927\u89c4\u6a21\u6a21\u578b\u7684\u4f9d\u8d56\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5de5\u7a0b\u6548\u7387\u3002"}}
{"id": "2601.11746", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11746", "abs": "https://arxiv.org/abs/2601.11746", "authors": ["George Mihaila", "Suleyman Olcay Polat", "Poli Nemkova", "Himanshu Sharma", "Namratha V. Urs", "Mark V. Albert"], "title": "LIME-LLM: Probing Models with Fluent Counterfactuals, Not Broken Text", "comment": null, "summary": "Local explanation methods such as LIME (Ribeiro et al., 2016) remain fundamental to trustworthy AI, yet their application to NLP is limited by a reliance on random token masking. These heuristic perturbations frequently generate semantically invalid, out-of-distribution inputs that weaken the fidelity of local surrogate models. While recent generative approaches such as LLiMe (Angiulli et al., 2025b) attempt to mitigate this by employing Large Language Models for neighborhood generation, they rely on unconstrained paraphrasing that introduces confounding variables, making it difficult to isolate specific feature contributions. We introduce LIME-LLM, a framework that replaces random noise with hypothesis-driven, controlled perturbations. By enforcing a strict \"Single Mask-Single Sample\" protocol and employing distinct neutral infill and boundary infill strategies, LIME-LLM constructs fluent, on-manifold neighborhoods that rigorously isolate feature effects. We evaluate our method against established baselines (LIME, SHAP, Integrated Gradients) and the generative LLiMe baseline across three diverse benchmarks: CoLA, SST-2, and HateXplain using human-annotated rationales as ground truth. Empirical results demonstrate that LIME-LLM establishes a new benchmark for black-box NLP explainability, achieving significant improvements in local explanation fidelity compared to both traditional perturbation-based methods and recent generative alternatives.", "AI": {"tldr": "\u63d0\u51faLIME-LLM\uff0c\u5229\u7528\u5047\u8bbe\u9a71\u52a8\u7684\u53d7\u63a7\u6270\u52a8\u66ff\u4ee3\u968f\u673a\u5c4f\u853d\uff0c\u663e\u8457\u63d0\u5347NLP\u9ed1\u76d2\u6a21\u578b\u5c40\u90e8\u89e3\u91ca\u7684\u5fe0\u5b9e\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edf\u53ca\u751f\u6210\u5f0f\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u968f\u673a\u7b26\u53f7\u5c4f\u853d\u7684\u5c40\u90e8\u89e3\u91ca\u65b9\u6cd5\u5728NLP\u4e2d\u751f\u6210\u4e86\u8bed\u4e49\u65e0\u6548\u4e14\u5206\u5e03\u5916\u7684\u6270\u52a8\uff0c\u964d\u4f4e\u4e86\u89e3\u91ca\u6a21\u578b\u7684\u5fe0\u5b9e\u5ea6\uff1b\u800c\u6700\u65b0\u751f\u6210\u5f0f\u65b9\u6cd5\u91c7\u7528\u65e0\u7ea6\u675f\u7684\u610f\u8bd1\uff0c\u5bfc\u81f4\u6df7\u6dc6\u53d8\u91cf\u96be\u4ee5\u5206\u79bb\u7279\u5f81\u8d21\u732e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u51c6\u786e\u4e14\u63a7\u5236\u6027\u66f4\u5f3a\u7684\u6270\u52a8\u65b9\u6cd5\u3002", "method": "LIME-LLM\u63d0\u51fa\u4e86\u201c\u4e00\u63a9\u7801-\u4e00\u6837\u672c\u201d\u7684\u4e25\u683c\u534f\u8bae\uff0c\u7ed3\u5408\u4e2d\u6027\u586b\u5145\u548c\u8fb9\u754c\u586b\u5145\u7b56\u7565\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u6d41\u7545\u4e14\u5728\u6570\u636e\u5206\u5e03\u5185\u7684\u6270\u52a8\u6837\u672c\uff0c\u4ece\u800c\u6784\u5efa\u4e25\u8c28\u9694\u79bb\u7279\u5f81\u6548\u5e94\u7684\u90bb\u57df\u3002", "result": "\u5728CoLA\u3001SST-2\u548cHateXplain\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cLIME-LLM\u76f8\u8f83\u4e8eLIME\u3001SHAP\u3001Integrated Gradients\u53ca\u751f\u6210\u5f0fLLiMe\u5747\u5b9e\u73b0\u4e86\u672c\u5730\u89e3\u91ca\u5fe0\u5b9e\u5ea6\u7684\u663e\u8457\u63d0\u5347\uff0c\u901a\u8fc7\u4eba\u5de5\u6ce8\u91ca\u7684\u7406\u7531\u4f5c\u4e3a\u91d1\u6807\u51c6\u9a8c\u8bc1\u6548\u679c\u3002", "conclusion": "LIME-LLM\u901a\u8fc7\u5047\u8bbe\u9a71\u52a8\u7684\u63a7\u5236\u6027\u6270\u52a8\u66ff\u4ee3\u968f\u673a\u566a\u58f0\uff0c\u5b9e\u73b0\u4e86\u8bed\u4e49\u6709\u6548\u4e14\u4e25\u8c28\u7684\u90bb\u57df\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672c\u5730\u89e3\u91ca\u6a21\u578b\u7684\u5fe0\u5b9e\u5ea6\uff0c\u4f18\u4e8e\u4f20\u7edf\u548c\u751f\u6210\u5f0f\u7684\u89e3\u91ca\u65b9\u6cd5\uff0c\u6210\u4e3a\u9ed1\u76d2NLP\u53ef\u89e3\u91ca\u6027\u7684\u65b0\u7684\u57fa\u51c6\u3002"}}
{"id": "2601.12148", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12148", "abs": "https://arxiv.org/abs/2601.12148", "authors": ["Muhammad Umar Zeshan", "Motunrayo Ibiyo", "Claudio Di Sipio", "Phuong T. Nguyen", "Davide Di Ruscio"], "title": "Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages", "comment": "The paper has been peer-reviewed and accepted for publication to the Journal of Systems and Software (https://www.sciencedirect.com/journal/journal-of-systems-and-software)", "summary": "Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684LAMPS\u7cfb\u7edf\uff0c\u6709\u6548\u63d0\u9ad8\u4e86PyPI\u6076\u610f\u5305\u68c0\u6d4b\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u5f00\u6e90\u4ee3\u7801\u5e93\u4e2d\u6076\u610f\u4ee3\u7801\u5bf9\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u6784\u6210\u5a01\u80c1\uff0c\u4f20\u7edf\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u8bed\u4e49\u6a21\u5f0f\u7684\u6355\u6349\uff0c\u4e14\u5927\u8bed\u8a00\u6a21\u578b\u5728\u53ef\u89e3\u91ca\u548c\u6a21\u5757\u5316\u5b89\u5168\u6d41\u7a0b\u4e2d\u5e94\u7528\u6709\u9650\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5305\u542b\u56db\u4e2a\u89d2\u8272\u667a\u80fd\u4f53\uff08\u5305\u68c0\u7d22\u3001\u6587\u4ef6\u63d0\u53d6\u3001\u5206\u7c7b\u3001\u5224\u51b3\u805a\u5408\uff09\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edfLAMPS\uff0c\u5229\u7528CrewAI\u6846\u67b6\u534f\u8c03\uff0c\u7ed3\u5408\u5fae\u8c03CodeBERT\u6a21\u578b\u8fdb\u884c\u5206\u7c7b\u548cLLaMA-3\u6a21\u578b\u8fdb\u884c\u4e0a\u4e0b\u6587\u63a8\u7406\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u6d4b\uff0cLAMPS\u5728D1\u6570\u636e\u96c6\u5b9e\u73b097.7%\u51c6\u786e\u7387\uff0c\u8d85\u8fc7\u4e86MPHunter\uff1b\u5728D2\u6570\u636e\u96c6\u8fbe\u5230\u4e8699.5%\u7684\u51c6\u786e\u7387\u548c\u5747\u8861\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8eRAG\u65b9\u6cd5\u548c\u5355\u667a\u80fd\u4f53\u57fa\u7ebf\uff0cMcNemar\u5206\u6790\u8bc1\u5b9e\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "LAMPS\u7cfb\u7edf\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9PyPI\u6076\u610f\u4ee3\u7801\u7684\u9ad8\u6548\u68c0\u6d4b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5148\u8fdb\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5206\u5e03\u5f0fLLM\u63a8\u7406\u5728\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u5b89\u5168\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2601.11758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11758", "abs": "https://arxiv.org/abs/2601.11758", "authors": ["Arnab Das Utsa"], "title": "Early Linguistic Pattern of Anxiety from Social Media Using Interpretable Linguistic Features: A Multi-Faceted Validation Study with Author-Disjoint Evaluation", "comment": "9 figures, more than 1o pages", "summary": "Anxiety affects hundreds of millions of individuals globally, yet large-scale screening remains limited. Social media language provides an opportunity for scalable detection, but current models often lack interpretability, keyword-robustness validation, and rigorous user-level data integrity. This work presents a transparent approach to social media-based anxiety detection through linguistically interpretable feature-grounded modeling and cross-domain validation. Using a substantial dataset of Reddit posts, we trained a logistic regression classifier on carefully curated subreddits for training, validation, and test splits. Comprehensive evaluation included feature ablation, keyword masking experiments, and varying-density difference analyses comparing anxious and control groups, along with external validation using clinically interviewed participants with diagnosed anxiety disorders. The model achieved strong performance while maintaining high accuracy even after sentiment removal or keyword masking. Early detection using minimal post history significantly outperformed random classification, and cross-domain analysis demonstrated strong consistency with clinical interview data. Results indicate that transparent linguistic features can support reliable, generalizable, and keyword-robust anxiety detection. The proposed framework provides a reproducible baseline for interpretable mental health screening across diverse online contexts.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e00\u79cd\u900f\u660e\u3001\u8bed\u8a00\u89e3\u91ca\u6027\u7684\u793e\u4ea4\u5a92\u4f53\u7126\u8651\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5229\u7528Reddit\u6570\u636e\u548c\u4e34\u5e8a\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u7684\u51c6\u786e\u6027\u3001\u7a33\u5065\u6027\u548c\u901a\u7528\u6027\uff0c\u63a8\u52a8\u4e86\u53ef\u89e3\u91ca\u5fc3\u7406\u5065\u5eb7\u7b5b\u67e5\u7684\u53d1\u5c55\u3002", "motivation": "\u7126\u8651\u5f71\u54cd\u4f17\u591a\u4e2a\u4f53\uff0c\u73b0\u6709\u5927\u89c4\u6a21\u7b5b\u67e5\u624b\u6bb5\u6709\u9650\uff0c\u793e\u4ea4\u5a92\u4f53\u8bed\u8a00\u4e3a\u53ef\u6269\u5c55\u68c0\u6d4b\u63d0\u4f9b\u673a\u4f1a\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u7f3a\u4e4f\u89e3\u91ca\u6027\u3001\u5173\u952e\u8bcd\u7a33\u5065\u6027\u9a8c\u8bc1\u53ca\u7528\u6237\u7ea7\u6570\u636e\u5b8c\u6574\u6027\u4fdd\u969c\u3002", "method": "\u901a\u8fc7\u5bf9Reddit\u5927\u91cf\u5e16\u5b50\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u4f7f\u7528\u8bed\u8a00\u5b66\u89e3\u91ca\u6027\u5f3a\u7684\u7279\u5f81\u6784\u5efa\u903b\u8f91\u56de\u5f52\u5206\u7c7b\u5668\uff0c\u8fdb\u884c\u7279\u5f81\u6d88\u878d\u3001\u5173\u952e\u8bcd\u906e\u853d\u53ca\u5bc6\u5ea6\u5dee\u5f02\u5206\u6790\u7b49\u5168\u9762\u8bc4\u4f30\uff0c\u5e76\u7ed3\u5408\u6765\u81ea\u4e34\u5e8a\u8bbf\u8c08\u7684\u7126\u8651\u8bca\u65ad\u6570\u636e\u8fdb\u884c\u8de8\u9886\u57df\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u5728\u53bb\u9664\u60c5\u611f\u8bcd\u6216\u5173\u952e\u8bcd\u906e\u853d\u540e\u4f9d\u7136\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\uff0c\u5229\u7528\u6700\u5c11\u7684\u53d1\u5e16\u5386\u53f2\u5373\u53ef\u5b9e\u73b0\u65e9\u671f\u68c0\u6d4b\uff0c\u4e14\u8de8\u9886\u57df\u5206\u6790\u663e\u793a\u4e0e\u4e34\u5e8a\u6570\u636e\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u57fa\u4e8e\u900f\u660e\u4e14\u8bed\u8a00\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u6a21\u578b\uff0c\u80fd\u591f\u5b9e\u73b0\u53ef\u9760\u3001\u901a\u7528\u4e14\u5bf9\u5173\u952e\u8bcd\u7a33\u5065\u7684\u7126\u8651\u68c0\u6d4b\u3002"}}
{"id": "2601.12186", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12186", "abs": "https://arxiv.org/abs/2601.12186", "authors": ["Vatsal Venkatkrishna", "Indraneil Paul", "Iryna Gurevych"], "title": "Aletheia: What Makes RLVR For Code Verifiers Tick?", "comment": "8 pages, 6 figures", "summary": "Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u57fa\u4e8eRLVR\u7684\u4ee3\u7801\u9a8c\u8bc1\u5668\u8bad\u7ec3\u673a\u5236\uff0c\u63d0\u51faAletheia\u6d4b\u8bd5\u5e73\u53f0\u8bc4\u4f30\u5176\u7a33\u5065\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u89c4\u6a21\u9a8c\u8bc1\u5668\u9700\u91cd\u70b9\u5173\u6ce8\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\u4ee5\u63d0\u5347\u8868\u73b0\u3002", "motivation": "\u5c3d\u7ba1RLVR\u9a8c\u8bc1\u5668\u5728\u751f\u6210\u6a21\u578b\u8f93\u51fa\u7684\u8bc4\u4f30\u548c\u91cd\u65b0\u6392\u5e8f\u4e2d\u8868\u73b0\u7a81\u51fa\uff0c\u4f46\u5176\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u5e94\u7528\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u5728\u6267\u884c\u53cd\u9988\u4e0d\u53ef\u5f97\u7684\u60c5\u51b5\u4e0b\uff0c\u4ee3\u7801\u9a8c\u8bc1\u5668\u4f5c\u4e3a\u8f85\u52a9\u4ecd\u5177\u4ef7\u503c\u3002", "method": "\u6784\u5efaAletheia\u6d4b\u8bd5\u5e73\u53f0\uff0c\u57fa\u4e8e\u6267\u884c\u53cd\u9988\u8fdb\u884c\u4ee3\u7801\u9a8c\u8bc1\u5668\u7684\u7a33\u5065\u6027\u8bc4\u4f30\uff0c\u5206\u6790RLVR\u8bad\u7ec3\u914d\u65b9\u7684\u4e09\u4e2a\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff1a\u4e2d\u95f4\u601d\u8003\u8f68\u8ff9\u3001\u8d1f\u6837\u672c\u5b66\u4e60\u548c\u73b0\u573a\u8bad\u7ec3\u3002", "result": "\u5b9e\u9a8c\u8868\u660eRLVR\u8bad\u7ec3\u65b9\u6cd5\u603b\u4f53\u6700\u4f18\uff0c\u6267\u884c\u9a8c\u8bc1\u5448\u73b0\u6b63\u5411\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u89c4\u6a21\u6548\u5e94\u3002\u4e0d\u540c\u89c4\u6a21\u9a8c\u8bc1\u5668\u4f9d\u8d56\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\uff0c\u5c0f\u89c4\u6a21\u4ee5\u73b0\u573a\u8bad\u7ec3\u4e3a\u5173\u952e\uff0c\u5927\u89c4\u6a21\u5219\u66f4\u4f9d\u8d56\u601d\u8003\u8f68\u8ff9\u8bad\u7ec3\u3002", "conclusion": "RLVR\u8bad\u7ec3\u7684\u591a\u9886\u57df\u601d\u8003\u9a8c\u8bc1\u5668\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u5e94\u7528\u5177\u6709\u6f5c\u529b\uff0c\u5c24\u5176\u662f\u5728\u6267\u884c\u53cd\u9988\u96be\u4ee5\u83b7\u5f97\u7684\u573a\u666f\u4e0b\u3002\u5c3d\u7ba1RLVR\u6574\u4f53\u6700\u4f18\uff0c\u4f46\u5173\u952e\u7ec4\u6210\u90e8\u5206\u5728\u4e0d\u540c\u89c4\u6a21\u7684\u9a8c\u8bc1\u5668\u4e2d\u8868\u73b0\u4e0d\u540c\uff0c\u5c0f\u89c4\u6a21\u65f6\u4ee5\u73b0\u573a\u8bad\u7ec3\u4e3a\u4e3b\uff0c\u5927\u89c4\u6a21\u65f6\u5219\u4ee5\u601d\u8003\u5f0f\u8bad\u7ec3\u4e3a\u5173\u952e\u3002"}}
{"id": "2601.11762", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11762", "abs": "https://arxiv.org/abs/2601.11762", "authors": ["Sae Young Moon", "Myeongjun Erik Jang", "Haoyan Luo", "Chunyang Xiao", "Antonios Georgiadis", "Fran Silavong"], "title": "Industry-Aligned Granular Topic Modeling", "comment": null, "summary": "Topic modeling has extensive applications in text mining and data analysis across various industrial sectors. Although the concept of granularity holds significant value for business applications by providing deeper insights, the capability of topic modeling methods to produce granular topics has not been thoroughly explored. In this context, this paper introduces a framework called TIDE, which primarily provides a novel granular topic modeling method based on large language models (LLMs) as a core feature, along with other useful functionalities for business applications, such as summarizing long documents, topic parenting, and distillation. Through extensive experiments on a variety of public and real-world business datasets, we demonstrate that TIDE's topic modeling approach outperforms modern topic modeling methods, and our auxiliary components provide valuable support for dealing with industrial business scenarios. The TIDE framework is currently undergoing the process of being open sourced.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u6846\u67b6TIDE\uff0c\u6027\u80fd\u4f18\u8d8a\u5e76\u5177\u5907\u5b9e\u7528\u5de5\u4e1a\u5e94\u7528\u529f\u80fd\uff0c\u5177\u5907\u8f83\u5927\u5e94\u7528\u4ef7\u503c\u3002", "motivation": "\u73b0\u6709\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u5728\u7ec6\u7c92\u5ea6\u4e3b\u9898\u63d0\u53d6\u80fd\u529b\u4e0d\u8db3\uff0c\u800c\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5bf9\u5546\u4e1a\u5e94\u7528\u80fd\u63d0\u4f9b\u66f4\u6df1\u5165\u7684\u6d1e\u5bdf\uff0c\u56e0\u6b64\u63d0\u51fa\u65b0\u6846\u67b6\u4ee5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\uff0c\u5e76\u7ed3\u5408\u6587\u6863\u6458\u8981\u3001\u4e3b\u9898\u5c42\u7ea7\u5173\u7cfb\u6784\u5efa\u548c\u4e3b\u9898\u63d0\u70bc\u7b49\u8f85\u52a9\u529f\u80fd\u3002", "result": "\u901a\u8fc7\u5728\u591a\u4e2a\u516c\u5f00\u548c\u771f\u5b9e\u4e1a\u52a1\u6570\u636e\u96c6\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\uff0c\u8bc1\u660eTIDE\u7684\u4e3b\u9898\u5efa\u6a21\u6027\u80fd\u4f18\u8d8a\u4e14\u8f85\u52a9\u7ec4\u4ef6\u5bf9\u5de5\u4e1a\u5e94\u7528\u573a\u666f\u6709\u5e2e\u52a9\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684TIDE\u6846\u67b6\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u4e3b\u9898\u5efa\u6a21\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u63d0\u4f9b\u4e86\u591a\u79cd\u8f85\u52a9\u529f\u80fd\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u4e1a\u52a1\u573a\u666f\u3002"}}
{"id": "2601.12262", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12262", "abs": "https://arxiv.org/abs/2601.12262", "authors": ["Tongtong Wu", "Rongyi Chen", "Wenjie Du", "Suyu Ma", "Guilin Qi", "Zhenchang Xing", "Shahram Khadivi", "Ramesh Periyathambi", "Gholamreza Haffari"], "title": "Environment-Aware Code Generation: How far are We?", "comment": "ICSE 2026", "summary": "Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\uff0c\u63d0\u51fa\u4e86\u591a\u7ef4\u5ea6\u9002\u914d\u7b56\u7565\u5e76\u6784\u5efa\u4e86\u5b9e\u9645\u73af\u5883\u4e0b\u8bc4\u6d4b\u57fa\u51c6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u73af\u5883\u9002\u914d\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u591a\u805a\u7126\u5c0f\u89c4\u6a21\u3001\u5b64\u7acb\u4ee3\u7801\uff0c\u5ffd\u89c6\u5b9e\u9645\u8f6f\u4ef6\u73af\u5883\u5dee\u5f02\uff0c\u5bfc\u81f4\u96be\u4ee5\u5224\u5b9aLLM\u751f\u6210\u4ee3\u7801\u5728\u7279\u5b9a\u73af\u5883\u4e0b\u7684\u53ef\u7528\u6027\u3002", "method": "\u6784\u5efa\u4e86VersiBCB\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8fdb\u884c\u591a\u5305\u3001\u6267\u884c\u9a8c\u8bc1\u548c\u5f03\u7528\u611f\u77e5\u7684\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\u8bc4\u4f30\uff1b\u9488\u5bf9\u6570\u636e\u3001\u53c2\u6570\u548c\u7f13\u5b58\u4e09\u4e2a\u9002\u914d\u8f74\u8bbe\u8ba1\u4ee3\u8868\u6027\u7b56\u7565\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u901a\u8fc7VersiBCB\u548c\u9002\u914d\u7b56\u7565\uff0c\u53d1\u73b0\u73b0\u6709LLM\u751f\u6210\u4ee3\u7801\u73af\u5883\u9002\u5e94\u80fd\u529b\u8f83\u5f31\uff0c\u9002\u914d\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u7684\u73af\u5883\u517c\u5bb9\u6027\u548c\u53ef\u6267\u884c\u6027\u3002", "conclusion": "\u5f53\u524d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u73af\u5883\u611f\u77e5\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u4f46\u901a\u8fc7\u6570\u636e\u3001\u53c2\u6570\u548c\u7f13\u5b58\u4e09\u65b9\u9762\u7684\u9002\u914d\u7b56\u7565\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u4ee3\u7801\u7684\u73af\u5883\u517c\u5bb9\u6027\u548c\u53ef\u6267\u884c\u6027\u3002"}}
{"id": "2601.11776", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11776", "abs": "https://arxiv.org/abs/2601.11776", "authors": ["Kaituo Zhang", "Zhimeng Jiang", "Na Zou"], "title": "Cleansing the Artificial Mind: A Self-Reflective Detoxification Framework for Large Language Models", "comment": null, "summary": "Recent breakthroughs in Large Language Models (LLMs) have revealed remarkable generative capabilities and emerging self-regulatory mechanisms, including self-correction and self-rewarding. However, current detoxification techniques rarely exploit these built-in abilities; instead, they rely on external modules, labor-intensive data annotation, or human intervention --factors that hinder scalability and consistency. In this paper, we introduce a fully self-reflective detoxification framework that harnesses the inherent capacities of LLMs to detect, correct toxic content, and refine LLMs without external modules and data annotation. Specifically, we propose a Toxic Signal Detector --an internal self-identification mechanism, coupled with a systematic intervention process to transform toxic text into its non-toxic counterpart. This iterative procedure yields a contrastive detoxification dataset used to fine-tune the model, enhancing its ability for safe and coherent text generation. Experiments on benchmark datasets such as DetoxLLM and ParaDetox show that our method achieves better detoxification performance than state-of-the-art methods while preserving semantic fidelity. By obviating the need for human intervention or external components, this paper reveals the intrinsic self-detoxification ability of LLMs, offering a consistent and effective approach for mitigating harmful content generation. Ultimately, our findings underscore the potential for truly self-regulated language models, paving the way for more responsible and ethically guided text generation systems.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u81ea\u5e26\u7684\u81ea\u6211\u7ea0\u9519\u80fd\u529b\uff0c\u8bbe\u8ba1\u4e86\u65e0\u9700\u5916\u90e8\u5e72\u9884\u7684\u81ea\u52a8\u6709\u5bb3\u5185\u5bb9\u6d88\u9664\u6846\u67b6\uff0c\u6548\u679c\u4f18\u5f02\uff0c\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u5b89\u5168\u6027\u4e0e\u8d23\u4efb\u611f\u3002", "motivation": "\u5f53\u524d\u7684\u6709\u5bb3\u5185\u5bb9\u6d88\u9664\u6280\u672f\u4f9d\u8d56\u5916\u90e8\u6a21\u5757\u548c\u4eba\u5de5\u6807\u6ce8\uff0c\u96be\u4ee5\u6269\u5c55\u4e14\u4e00\u81f4\u6027\u5dee\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5177\u6709\u81ea\u6211\u7ea0\u6b63\u548c\u81ea\u6211\u5956\u52b1\u7684\u5185\u5728\u80fd\u529b\u672a\u88ab\u5145\u5206\u5229\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b8c\u5168\u81ea\u6211\u53cd\u601d\u7684\u6709\u5bb3\u5185\u5bb9\u6d88\u9664\u6846\u67b6\uff0c\u5229\u7528LLMs\u7684\u5185\u5728\u80fd\u529b\u8fdb\u884c\u6709\u5bb3\u5185\u5bb9\u68c0\u6d4b\u548c\u4fee\u6b63\uff0c\u8bbe\u8ba1\u4e86\u6709\u5bb3\u4fe1\u53f7\u68c0\u6d4b\u5668\u548c\u7cfb\u7edf\u5316\u7684\u5e72\u9884\u6d41\u7a0b\uff0c\u8fed\u4ee3\u751f\u6210\u6d88\u6bd2\u6570\u636e\u96c6\u4ee5\u5fae\u8c03\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728DetoxLLM\u548cParaDetox\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0c\u6d88\u6bd2\u6548\u679c\u4f18\u4e8e\u6700\u65b0\u6280\u672f\u4e14\u4fdd\u6301\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u65e0\u9700\u4eba\u5de5\u5e72\u9884\u548c\u5916\u90e8\u7ec4\u4ef6\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86LLMs\u5185\u5728\u7684\u81ea\u6211\u6d88\u6bd2\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e00\u81f4\u4e14\u6709\u6548\u7684\u81ea\u52a8\u6d88\u6bd2\u65b9\u6cd5\uff0c\u63a8\u52a8\u4e86\u81ea\u6211\u8c03\u8282\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5b9e\u73b0\u66f4\u5177\u8d23\u4efb\u611f\u548c\u4f26\u7406\u6307\u5bfc\u7684\u6587\u672c\u751f\u6210\u3002"}}
{"id": "2601.12273", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12273", "abs": "https://arxiv.org/abs/2601.12273", "authors": ["Chihiro Yoshida", "Yuta Ishimoto", "Olivier Nourry", "Masanari Kondo", "Makoto Matsushita", "Yasutaka Kamei", "Yoshiki Higo"], "title": "Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs", "comment": "6 pages, Accepted at SANER-ERA 2026", "summary": "In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u53d8\u5f02\u5206\u6790\u4fe1\u606f\u7684\u63d0\u793a\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u5347\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u7684\u6210\u529f\u7387\u548c\u8865\u4e01\u89e3\u91ca\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e8694.4%\u7684\u9ad8\u4fee\u590d\u6210\u529f\u7387\uff0c\u63a8\u52a8\u4e86\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6280\u672f\u7684\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u6280\u672f\u6210\u529f\u7387\u4f4e\u4e14\u751f\u6210\u8865\u4e01\u7684\u53ef\u7406\u89e3\u6027\u5dee\uff0c\u4e9f\u9700\u63d0\u5347\u4fee\u590d\u6027\u80fd\u53ca\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u4fee\u590d\u53ca\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u7684\u81ea\u52a8\u4fee\u590d\u6846\u67b6\uff0c\u5e76\u8bbe\u8ba1\u5305\u542b\u4e0d\u540c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u9759\u6001\u4fe1\u606f\u3001\u52a8\u6001\u4fe1\u606f\u53ca\u53d8\u5f02\u5206\u6790\u7ed3\u679c\uff09\u7684\u56db\u79cd\u63d0\u793a\u914d\u7f6e\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5229\u7528\u53d8\u5f02\u5206\u6790\u7ed3\u679c\u4f5c\u4e3a\u52a8\u6001\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u4f7f\u5f97\u81ea\u52a8\u4fee\u590d\u6210\u529f\u7387\u63d0\u9ad8\u81f394.4%\uff0c\u5e76\u5728\u90e8\u5206\u60c5\u51b5\u4e0b\u63d0\u5347\u4e86\u89e3\u91ca\u8d28\u91cf\u3002", "conclusion": "\u57fa\u4e8e\u53d8\u5f02\u5206\u6790\u4fe1\u606f\u7684\u63d0\u793a\u8bbe\u8ba1\u80fd\u591f\u663e\u8457\u63d0\u5347\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u91cf\u5b50\u7a0b\u5e8f\u81ea\u52a8\u4fee\u590d\u7684\u6210\u529f\u7387\u548c\u89e3\u91ca\u8d28\u91cf\u3002"}}
{"id": "2601.11778", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11778", "abs": "https://arxiv.org/abs/2601.11778", "authors": ["Sheriff Issaka", "Erick Rosas Gonzalez", "Lieqi Liu", "Evans Kofi Agyei", "Lucas Bandarkar", "Nanyun Peng", "David Ifeoluwa Adelani", "Francisco Guzm\u00e1n", "Saadia Gabriel"], "title": "Translation as a Scalable Proxy for Multilingual Evaluation", "comment": null, "summary": "The rapid proliferation of LLMs has created a critical evaluation paradox: while LLMs claim multilingual proficiency, comprehensive non-machine-translated benchmarks exist for fewer than 30 languages, leaving >98% of the world's 7,000 languages in an empirical void. Traditional benchmark construction faces scaling challenges such as cost, scarcity of domain experts, and data contamination. We evaluate the validity of a simpler alternative: can translation quality alone indicate a model's broader multilingual capabilities? Through systematic evaluation of 14 models (1B-72B parameters) across 9 diverse benchmarks and 7 translation metrics, we find that translation performance is a good indicator of downstream task success (e.g., Phi-4, median Pearson r: MetricX = 0.89, xCOMET = 0.91, SSA-COMET = 0.87). These results suggest that the representational abilities supporting faithful translation overlap with those required for multilingual understanding. Translation quality, thus emerges as a strong, inexpensive first-pass proxy of multilingual performance, enabling a translation-first screening with targeted follow-up for specific tasks.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7ffb\u8bd1\u8d28\u91cf\u53ef\u4f5c\u4e3a\u5feb\u901f\u3001\u4f4e\u6210\u672c\u7684\u591a\u8bed\u8a00\u80fd\u529b\u8bc4\u4f30\u4ee3\u7406\u6307\u6807\uff0c\u89e3\u51b3\u591a\u8bed\u8a00\u8bc4\u4f30\u4e2d\u5b58\u5728\u7684\u89c4\u6a21\u53ca\u8d44\u6e90\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u8bed\u8a00\u8bc4\u4f30\u5b58\u5728\u8bed\u8a00\u8986\u76d6\u4e0d\u8db3\u548c\u57fa\u51c6\u6784\u5efa\u6210\u672c\u9ad8\u7b49\u95ee\u9898\uff0c\u63a2\u7d22\u662f\u5426\u53ef\u7528\u7ffb\u8bd1\u8d28\u91cf\u4f5c\u4e3a\u591a\u8bed\u8a00\u80fd\u529b\u7684\u7ecf\u6d4e\u6709\u6548\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e8614\u4e2a\u4e0d\u540c\u89c4\u6a21\u6a21\u578b\u57289\u4e2a\u591a\u6837\u57fa\u51c6\u548c7\u4e2a\u7ffb\u8bd1\u6307\u6807\u4e0a\u7684\u8868\u73b0\uff0c\u6bd4\u8f83\u7ffb\u8bd1\u8d28\u91cf\u4e0e\u591a\u8bed\u8a00\u4efb\u52a1\u6210\u529f\u7387\u7684\u76f8\u5173\u6027\u3002", "result": "\u7ffb\u8bd1\u7ee9\u6548\u4e0e\u591a\u8bed\u8a00\u4efb\u52a1\u6210\u529f\u9ad8\u5ea6\u76f8\u5173\uff08Pearson\u76f8\u5173\u7cfb\u6570\u6700\u9ad8\u8fbe0.91\uff09\uff0c\u8868\u660e\u7ffb\u8bd1\u4ee3\u8868\u7684\u80fd\u529b\u4e0e\u591a\u8bed\u8a00\u7406\u89e3\u80fd\u529b\u91cd\u53e0\u3002", "conclusion": "\u7ffb\u8bd1\u8d28\u91cf\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u8bed\u8a00\u80fd\u529b\u7684\u826f\u597d\u6307\u6807\uff0c\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5176\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.12274", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12274", "abs": "https://arxiv.org/abs/2601.12274", "authors": ["Mahdi Eslamimehr"], "title": "Hybrid Concolic Testing with Large Language Models for Guided Path Exploration", "comment": "12 pages, 2 Figures, 2 Tables", "summary": "Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u8def\u5f84\u7206\u70b8\u548c\u7ea6\u675f\u6c42\u89e3\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u6280\u672f\u5728\u5927\u89c4\u6a21\u5b9e\u9645\u8f6f\u4ef6\u4e2d\u7684\u5e94\u7528\u53d7\u9650\uff0c\u4e3b\u8981\u56e0\u4e3a\u8def\u5f84\u7206\u70b8\u548c\u7ea6\u675f\u6c42\u89e3\u8017\u65f6\u9ad8\uff0c\u4e9f\u9700\u63d0\u9ad8\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u3002", "method": "\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u4e00\u4e2a\u7ed3\u5408\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7cfb\u7edf\u67b6\u6784\uff0c\u901a\u8fc7\u5229\u7528LLMs\u7684\u8bed\u4e49\u63a8\u7406\u80fd\u529b\u6307\u5bfc\u8def\u5f84\u63a2\u7d22\u3001\u4f18\u5148\u9009\u62e9\u6709\u8da3\u8def\u5f84\u5e76\u8f85\u52a9\u7ea6\u675f\u6c42\u89e3\u3002", "result": "\u901a\u8fc7\u5728\u5408\u6210\u548c\u771f\u5b9e\u91d1\u878d\u79d1\u6280\u5e94\u7528\u4e0a\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u652f\u8986\u76d6\u7387\u3001\u8def\u5f84\u8986\u76d6\u7387\u548c\u8986\u76d6\u65f6\u95f4\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u3001\u968f\u673a\u6d4b\u8bd5\u53ca\u9057\u4f20\u7b97\u6cd5\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7ed3\u5408\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u65b0\u7b97\u6cd5\u6846\u67b6\uff0c\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u6df7\u5408\u5177\u4f53\u7b26\u53f7\u6267\u884c\u5728\u8def\u5f84\u7206\u70b8\u548c\u7ea6\u675f\u6c42\u89e3\u6210\u672c\u65b9\u9762\u7684\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u6548\u7387\u548c\u8986\u76d6\u7387\u3002"}}
{"id": "2601.11791", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11791", "abs": "https://arxiv.org/abs/2601.11791", "authors": ["Laya Iyer", "Pranav Somani", "Alice Guo", "Dan Jurafsky", "Chen Shani"], "title": "Beyond Tokens: Concept-Level Training Objectives for LLMs", "comment": null, "summary": "The next-token prediction (NTP) objective has been foundational in the development of modern large language models (LLMs), driving advances in fluency and generalization. However, NTP operates at the \\textit{token} level, treating deviations from a single reference continuation as errors even when alternative continuations are equally plausible or semantically equivalent (e.g., ``mom'' vs. ``mother''). As a result, token-level loss can penalize valid abstractions, paraphrases, or conceptually correct reasoning paths, biasing models toward surface form rather than underlying meaning. This mismatch between the training signal and semantic correctness motivates learning objectives that operate over higher-level representations. We propose a shift from token-level to concept-level prediction, where concepts group multiple surface forms of the same idea (e.g., ``mom,'' ``mommy,'' ``mother'' $\\rightarrow$ \\textit{MOTHER}). We introduce various methods for integrating conceptual supervision into LLM training and show that concept-aware models achieve lower perplexity, improved robustness under domain shift, and stronger performance than NTP-based models on diverse NLP benchmarks. This suggests \\textit{concept-level supervision} as an improved training signal that better aligns LLMs with human semantic abstractions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7528\u6982\u5ff5\u7ea7\u76d1\u7763\u66ff\u4ee3\u4f20\u7edf\u7684\u5355\u8bcd\u7ea7\u9884\u6d4b\u8bad\u7ec3\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u7406\u89e3\u80fd\u529b\u548c\u6cdb\u5316\u6548\u679c\u3002", "motivation": "\u4f20\u7edf\u7684\u5355\u8bcd\u9884\u6d4b\u76ee\u6807\u5ffd\u89c6\u4e86\u8bcd\u6c47\u4e4b\u95f4\u7684\u8bed\u4e49\u7b49\u4ef7\u6027\uff0c\u5bfc\u81f4\u6a21\u578b\u5bf9\u8868\u5c42\u5f62\u5f0f\u4f9d\u8d56\u8fc7\u91cd\uff0c\u9650\u5236\u4e86\u6a21\u578b\u7684\u8bed\u4e49\u8868\u8fbe\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u6982\u5ff5\u7ea7\u9884\u6d4b\u65b9\u6cd5\uff0c\u5c06\u8868\u8ff0\u540c\u4e00\u6982\u5ff5\u7684\u4e0d\u540c\u8bcd\u6c47\u5f52\u4e3a\u540c\u4e00\u7c7b\u522b\uff0c\u5e76\u5c06\u5176\u6574\u5408\u5230\u8bad\u7ec3\u4e2d\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u8bed\u4e49\u7684\u7406\u89e3\u3002", "result": "\u6982\u5ff5\u7ea7\u76d1\u7763\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u56f0\u60d1\u5ea6\u3001\u9886\u57df\u8f6c\u79fb\u7a33\u5065\u6027\u53ca\u591a\u9879\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u57fa\u4e8e\u5355\u8bcd\u9884\u6d4b\u7684\u6a21\u578b\u3002", "conclusion": "\u7528\u6982\u5ff5\u7ea7\u76d1\u7763\u66ff\u4ee3\u4f20\u7edf\u7684\u57fa\u4e8e\u5355\u8bcd\u7684\u8bad\u7ec3\u76ee\u6807\uff0c\u53ef\u4ee5\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u4e49\u7406\u89e3\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u51cf\u5c11\u5bf9\u8868\u5c42\u5f62\u5f0f\u7684\u4f9d\u8d56\u3002"}}
{"id": "2601.12327", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12327", "abs": "https://arxiv.org/abs/2601.12327", "authors": ["Lucas Gren", "Felix Dobslaw"], "title": "The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering", "comment": null, "summary": "Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u4ee5\u4e13\u5bb6\u4e3a\u6838\u5fc3\u7684\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6d41\u7a0b\u4fdd\u969c\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8d28\u91cf\uff0c\u63d0\u5347\u4f01\u4e1a\u4e2dAI\u5e94\u7528\u7684\u4fe1\u4efb\u548c\u5b89\u5168\u6027\u3002", "motivation": "\u751f\u6210\u5f0fAI\u7cfb\u7edf\u867d\u80fd\u81ea\u52a8\u5316\u591a\u9879\u4efb\u52a1\uff0c\u4f46\u5728\u4f01\u4e1a\u4e2d\u5e94\u7528\u53d7\u5236\u4e8e\u7f3a\u4e4f\u7cfb\u7edf\u5316\u8d28\u91cf\u4fdd\u969c\u673a\u5236\u53ca\u7ec4\u7ec7\u4fe1\u4efb\u7684\u7f3a\u53e3\u3002", "method": "\u6846\u67b6\u91c7\u7528\u56db\u9636\u6bb5\u5b9e\u65bd\u6d41\u7a0b\uff0c\u5305\u62ec\u89c4\u8303\u5236\u5b9a\u3001\u7cfb\u7edf\u521b\u5efa\u3001\u9a8c\u8bc1\u548c\u751f\u4ea7\u76d1\u63a7\uff0c\u786e\u4fdd\u751f\u6210\u5f0fAI\u7cfb\u7edf\u8d28\u91cf\u548c\u4e13\u5bb6\u76d1\u7763\u3002", "result": "\u8be5\u6846\u67b6\u5efa\u7acb\u4e86\u4e00\u5957\u4e25\u8c28\u7684\u4e13\u5bb6\u9a71\u52a8\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u4e86\u591a\u6837\u5316\u751f\u6210\u5f0fAI\u5e94\u7528\u7684\u8d28\u91cf\u4fdd\u969c\u548c\u7ec4\u7ec7\u4fe1\u4efb\u7684\u63d0\u5347\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e13\u5bb6\u9a8c\u8bc1\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u4f01\u4e1a\u73af\u5883\u4e2d\u751f\u6210\u5f0fAI\u7cfb\u7edf\u7f3a\u4e4f\u7cfb\u7edf\u5316\u8d28\u91cf\u4fdd\u969c\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u89c4\u8303\u3001\u6d4b\u8bd5\u3001\u9a8c\u8bc1\u548c\u6301\u7eed\u76d1\u63a7\u6d41\u7a0b\uff0c\u5b9e\u73b0\u4e86\u4e13\u5bb6\u5bf9\u7cfb\u7edf\u884c\u4e3a\u7684\u6743\u5a01\u63a7\u5236\u3002"}}
{"id": "2601.11819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11819", "abs": "https://arxiv.org/abs/2601.11819", "authors": ["Shirlene Rose Bandela", "Sanjeev Parthasarathy", "Vaibhav Garg"], "title": "TWeddit : A Dataset of Triggering Stories Predominantly Shared by Women on Reddit", "comment": "11 pages, 12 figures, 7 tables", "summary": "Warning: This paper may contain examples and topics that may be disturbing to some readers, especially survivors of miscarriage and sexual violence. People affected by abortion, miscarriage, or sexual violence often share their experiences on social media to express emotions and seek support. On public platforms like Reddit, where users can post long, detailed narratives (up to 40,000 characters), readers may be exposed to distressing content. Although Reddit allows manual trigger warnings, many users omit them due to limited awareness or uncertainty about which categories apply. There is scarcity of datasets on Reddit stories labeled for triggering experiences. We propose a curated Reddit dataset, TWeddit, covering triggering experiences related to issues majorly faced by women. Our linguistic analyses show that annotated stories in TWeddit express distinct topics and moral foundations, making the dataset useful for a wide range of future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u5e03\u4e86\u6db5\u76d6\u5973\u6027\u76f8\u5173\u89e6\u53d1\u6027\u7ecf\u5386\u7684Reddit\u6570\u636e\u96c6TWeddit\uff0c\u586b\u8865\u4e86\u89e6\u53d1\u8b66\u544a\u6570\u636e\u6807\u6ce8\u7684\u7a7a\u7f3a\uff0c\u5bf9\u7406\u89e3\u76f8\u5173\u8bdd\u9898\u53ca\u9053\u5fb7\u57fa\u7840\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u6d41\u4ea7\u3001\u6027\u66b4\u529b\u7b49\u7ecf\u5386\u5206\u4eab\u53ef\u80fd\u5305\u542b\u4ee4\u4eba\u4e0d\u9002\u7684\u5185\u5bb9\uff0c\u800cReddit\u4e0a\u624b\u52a8\u89e6\u53d1\u8b66\u544a\u4f7f\u7528\u4e0d\u8db3\uff0c\u7f3a\u4e4f\u76f8\u5173\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5f71\u54cd\u7814\u7a76\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u5e76\u6ce8\u91caReddit\u4e0a\u957f\u7bc7\u8be6\u7ec6\u53d9\u8ff0\u7684\u6545\u4e8b\uff0c\u6784\u5efa\u6570\u636e\u96c6TWeddit\uff0c\u540c\u65f6\u8fdb\u884c\u8bed\u8a00\u5b66\u5206\u6790\u4ee5\u5c55\u793a\u6570\u636e\u96c6\u4e2d\u6545\u4e8b\u8868\u8fbe\u7684\u72ec\u7279\u4e3b\u9898\u548c\u9053\u5fb7\u57fa\u7840\u3002", "result": "\u521b\u5efa\u4e86TWeddit\u6570\u636e\u96c6\uff0c\u5305\u542b\u5e26\u89e6\u53d1\u8b66\u544a\u7684\u6545\u4e8b\uff0c\u5e76\u53d1\u73b0\u8fd9\u4e9b\u6545\u4e8b\u8868\u8fbe\u4e86\u4e0d\u540c\u7684\u8bdd\u9898\u548c\u9053\u5fb7\u89c2\u5ff5\uff0c\u6570\u636e\u96c6\u5bf9\u4e8e\u672a\u6765\u5e7f\u6cdb\u7814\u7a76\u5177\u6709\u4ef7\u503c\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ecf\u8fc7\u7cbe\u5fc3\u7b56\u5212\u7684Reddit\u6570\u636e\u96c6TWeddit\uff0c\u6db5\u76d6\u4e86\u4e0e\u5973\u6027\u4e3b\u8981\u9762\u4e34\u7684\u95ee\u9898\u76f8\u5173\u7684\u53ef\u80fd\u5f15\u53d1\u4e0d\u9002\u4f53\u9a8c\u7684\u5185\u5bb9\u3002"}}
{"id": "2601.12360", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12360", "abs": "https://arxiv.org/abs/2601.12360", "authors": ["Xinabang He", "Yuanwei Chen", "Hao Wu", "Jikang Zhang", "Zicheng Wang", "Ligeng Chen", "Junjie Peng", "Haiyang Wei", "Yi Qian", "Tiantai Zhang", "Linzhang Wang", "Bing Mao"], "title": "Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition", "comment": null, "summary": "Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.\n  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.\n  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51faFeatureFuzz\uff0c\u901a\u8fc7\u8bed\u4e49\u7279\u5f81\u7ec4\u5408\u751f\u6210\u6d4b\u8bd5\u7a0b\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u7684\u6548\u679c\uff0c\u53d1\u73b0\u66f4\u591a\u7a0b\u5e8f\u9519\u8bef\u3002", "motivation": "\u73b0\u6709\u7684\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\u65b9\u6cd5\u591a\u4f9d\u8d56\u8bed\u6cd5\u53d8\u5f02\u6216\u901a\u7528LLM\u5fae\u8c03\uff0c\u96be\u4ee5\u4fdd\u6301bug\u89e6\u53d1\u7a0b\u5e8f\u7684\u8bed\u4e49\uff0c\u4ece\u800c\u9650\u5236\u4e86\u751f\u6210\u7a0b\u5e8f\u7684\u591a\u6837\u6027\u548c\u6d4b\u8bd5\u6548\u679c\u3002", "method": "FeatureFuzz\u5b9a\u4e49\u4e86\u8bed\u4e49\u7279\u5f81\u4f5c\u4e3a\u72ec\u7acb\u5355\u5143\uff0c\u7ed3\u5408\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u548c\u5177\u4f53\u4ee3\u7801\u5b9e\u4f8b\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u65b9\u6cd5\u63d0\u53d6\u7279\u5f81\u3001\u5408\u6210\u7279\u5f81\u7ec4\u5e76\u5b9e\u4f8b\u5316\u4e3a\u6709\u6548\u7a0b\u5e8f\u8fdb\u884c\u6a21\u7cca\u6d4b\u8bd5\u3002", "result": "\u5728GCC\u548cLLVM\u4e0a\uff0cFeatureFuzz\u572824\u5c0f\u65f6\u5185\u53d1\u73b0\u4e86167\u4e2a\u72ec\u7279\u5d29\u6e83\uff0c\u662f\u6b21\u4f18\u5de5\u5177\u76842.78\u500d\uff1b72\u5c0f\u65f6\u5185\u53d1\u73b0106\u4e2abug\uff0c\u5176\u4e2d76\u4e2a\u5df2\u88ab\u786e\u8ba4\uff0c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6d4b\u8bd5\u80fd\u529b\u3002", "conclusion": "FeatureFuzz\u901a\u8fc7\u663e\u5f0f\u590d\u7528\u5386\u53f2bug\u7684\u8bed\u4e49\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u66f4\u6709\u6548\u7684\u7f16\u8bd1\u5668\u6a21\u7cca\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6f0f\u6d1e\u53d1\u73b0\u6570\u91cf\u548c\u8d28\u91cf\u3002"}}
{"id": "2601.11846", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11846", "abs": "https://arxiv.org/abs/2601.11846", "authors": ["Natalia Tomashenko", "Xiaoxiao Miao", "Pierre Champion", "Sarina Meyer", "Michele Panariello", "Xin Wang", "Nicholas Evans", "Emmanuel Vincent", "Junichi Yamagishi", "Massimiliano Todisco"], "title": "The Third VoicePrivacy Challenge: Preserving Emotional Expressiveness and Linguistic Content in Voice Anonymization", "comment": "under review", "summary": "We present results and analyses from the third VoicePrivacy Challenge held in 2024, which focuses on advancing voice anonymization technologies. The task was to develop a voice anonymization system for speech data that conceals a speaker's voice identity while preserving linguistic content and emotional state. We provide a systematic overview of the challenge framework, including detailed descriptions of the anonymization task and datasets used for both system development and evaluation. We outline the attack model and objective evaluation metrics for assessing privacy protection (concealing speaker voice identity) and utility (content and emotional state preservation). We describe six baseline anonymization systems and summarize the innovative approaches developed by challenge participants. Finally, we provide key insights and observations to guide the design of future VoicePrivacy challenges and identify promising directions for voice anonymization research.", "AI": {"tldr": "2024\u5e74VoicePrivacy\u6311\u6218\u8d5b\u63a8\u8fdb\u4e86\u4fdd\u62a4\u8bed\u97f3\u9690\u79c1\u7684\u533f\u540d\u6280\u672f\uff0c\u63d0\u51fa\u7cfb\u7edf\u6846\u67b6\u548c\u8bc4\u4f30\u6307\u6807\uff0c\u5c55\u793a\u591a\u79cd\u533f\u540d\u7cfb\u7edf\u53ca\u521b\u65b0\u65b9\u6848\uff0c\u6307\u660e\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a8\u52a8\u8bed\u97f3\u533f\u540d\u6280\u672f\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u7ade\u8d5b\u5f62\u5f0f\u6fc0\u52b1\u521b\u65b0\uff0c\u63d0\u9ad8\u8bed\u97f3\u6570\u636e\u5728\u4fdd\u62a4\u8bf4\u8bdd\u4eba\u8eab\u4efd\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u7559\u5185\u5bb9\u548c\u60c5\u611f\u72b6\u6001\u7684\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4e86\u7cfb\u7edf\u6027\u7684\u6311\u6218\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86\u8bed\u97f3\u533f\u540d\u4efb\u52a1\uff0c\u4f7f\u7528\u4e86\u591a\u6837\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5f15\u5165\u4e86\u653b\u51fb\u6a21\u578b\u548c\u5ba2\u89c2\u8bc4\u4f30\u6307\u6807\u6765\u8861\u91cf\u9690\u79c1\u4fdd\u62a4\u548c\u5b9e\u7528\u6027\u3002", "result": "\u4ecb\u7ecd\u4e86\u516d\u4e2a\u57fa\u51c6\u533f\u540d\u7cfb\u7edf\u4ee5\u53ca\u53c2\u8d5b\u8005\u5f00\u53d1\u7684\u521b\u65b0\u65b9\u6cd5\uff0c\u5e76\u603b\u7ed3\u4e86\u5173\u952e\u7684\u6d1e\u5bdf\u548c\u89c2\u5bdf\u7ed3\u679c\uff0c\u4e3a\u672a\u6765\u7684VoicePrivacy\u6311\u6218\u8d5b\u8bbe\u8ba1\u548c\u8bed\u97f3\u533f\u540d\u7814\u7a76\u6307\u660e\u4e86\u65b9\u5411\u3002", "conclusion": "\u6211\u4eec\u603b\u7ed3\u4e86\u7b2c\u4e09\u5c4a2024\u5e74VoicePrivacy\u6311\u6218\u8d5b\u7684\u6210\u679c\u548c\u5206\u6790\uff0c\u5f3a\u8c03\u4e86\u8bed\u97f3\u533f\u540d\u6280\u672f\u5728\u4fdd\u62a4\u8bf4\u8bdd\u4eba\u8eab\u4efd\u9690\u79c1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8bed\u97f3\u7684\u5185\u5bb9\u548c\u60c5\u611f\u72b6\u6001\u3002"}}
{"id": "2601.12448", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12448", "abs": "https://arxiv.org/abs/2601.12448", "authors": ["Yang Liu", "Yixing Luo", "Xiaofeng Li", "Xiaogang Dong", "Bin Gu", "Zhi Jin"], "title": "Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software", "comment": "This paper has been accepted by ASE 2025", "summary": "Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u822a\u5929\u8f6f\u4ef6\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\uff0c\u6784\u5efa\u9996\u4e2a\u57fa\u51c6ATSADBench\uff0c\u7cfb\u7edf\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u53d1\u73b0\u5176\u5728\u591a\u53d8\u91cf\u5f02\u5e38\u68c0\u6d4b\u4e2d\u5b58\u5728\u4e0d\u8db3\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u6709\u6548\uff0c\u800c\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65e0\u663e\u8457\u6539\u8fdb\u3002", "motivation": "\u73b0\u6709\u65e0\u4eba\u76d1\u7763\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u7528\u4e8e\u590d\u6742\u822a\u5929\u9065\u6d4b\u6570\u636e\u7684\u5f02\u5e38\u68c0\u6d4b\uff0c\u4e14\u7f3a\u4e4f\u4e13\u95e8\u9488\u5bf9\u822a\u5929\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u6027\u80fd\u7684\u5168\u9762\u8bc4\u4f30\u4e0e\u9886\u57df\u77e5\u8bc6\u6ce8\u5165\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u822a\u5929\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u57fa\u51c6ATSADBench\uff0c\u5305\u542b9\u4e2a\u4efb\u52a1\u3001108,000\u6570\u636e\u70b9\uff0c\u57fa\u4e8e\u4e24\u79cd\u8303\u5f0f\uff08\u6ed1\u52a8\u7a97\u53e3\u76f4\u63a5\u6807\u6ce8\u548c\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u68c0\u6d4b\uff09\uff0c\u5e76\u63d0\u51fa\u7528\u6237\u5bfc\u5411\u7684\u8bc4\u4f30\u6307\u6807\uff08\u62a5\u8b66\u51c6\u786e\u6027\u3001\u5ef6\u8fdf\u548c\u8fde\u7eed\u6027\uff09\u3002\u7cfb\u7edf\u8bc4\u4f30\u591a\u79cd\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5e76\u5c1d\u8bd5\u5c11\u6837\u672c\u5b66\u4e60\u4e0eRAG\u6539\u8fdb\u7b56\u7565\u3002", "result": "\u63d0\u51faATSADBench\u57fa\u51c6\u53ca\u65b0\u7684\u8bc4\u4f30\u6307\u6807\uff0c\u53d1\u73b0LLMs\u5728\u591a\u53d8\u91cf\u4efb\u52a1\u4e2d\u6027\u80fd\u4e0d\u8db3\uff0c\u5c11\u6837\u672c\u5b66\u4e60\u80fd\u7f13\u89e3\u90e8\u5206\u95ee\u9898\uff0c\u800cRAG\u672a\u5e26\u6765\u63d0\u5347\u5e76\u52a0\u5267\u8bef\u62a5\uff0cLLMs\u53ef\u68c0\u6d4b\u5f02\u5e38\u8d77\u59cb\u4f46\u5b58\u5728\u8bef\u62a5\u98ce\u9669\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5355\u53d8\u91cf\u65f6\u95f4\u5e8f\u5217\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u591a\u53d8\u91cf\u822a\u5929\u9065\u6d4b\u6570\u636e\u5f02\u5e38\u68c0\u6d4b\u4e2d\u6548\u679c\u8f83\u5dee\uff0c\u5c24\u5176\u5728\u62a5\u8b66\u51c6\u786e\u6027\u548c\u8fde\u7eed\u6027\u65b9\u9762\u63a5\u8fd1\u968f\u673a\u731c\u6d4b\u3002\u5c11\u6837\u672c\u5b66\u4e60\u80fd\u5e26\u6765\u6709\u9650\u63d0\u5347\uff0c\u800c\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u672a\u89c1\u663e\u8457\u6539\u5584\uff0c\u751a\u81f3\u53ef\u80fd\u52a0\u5267\u8bef\u62a5\u3002"}}
{"id": "2601.11865", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11865", "abs": "https://arxiv.org/abs/2601.11865", "authors": ["Truong Nguyen", "Phi Van Dat", "Ngan Nguyen", "Linh Ngo Van", "Trung Le", "Thanh Hong Nguyen"], "title": "CTPD: Cross Tokenizer Preference Distillation", "comment": "AAAI 2026", "summary": "While knowledge distillation has seen widespread use in pre-training and instruction tuning, its application to aligning language models with human preferences remains underexplored, particularly in the more realistic cross-tokenizer setting. The incompatibility of tokenization schemes between teacher and student models has largely prevented fine-grained, white-box distillation of preference information. To address this gap, we propose Cross-Tokenizer Preference Distillation (CTPD), the first unified framework for transferring human-aligned behavior between models with heterogeneous tokenizers. CTPD introduces three key innovations: (1) Aligned Span Projection, which maps teacher and student tokens to shared character-level spans for precise supervision transfer; (2) a cross-tokenizer adaptation of Token-level Importance Sampling (TIS-DPO) for improved credit assignment; and (3) a Teacher-Anchored Reference, allowing the student to directly leverage the teacher's preferences in a DPO-style objective. Our theoretical analysis grounds CTPD in importance sampling, and experiments across multiple benchmarks confirm its effectiveness, with significant performance gains over existing methods. These results establish CTPD as a practical and general solution for preference distillation across diverse tokenization schemes, opening the door to more accessible and efficient alignment of language models.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8de8\u4e0d\u540c\u5206\u8bcd\u5668\u7684\u504f\u597d\u84b8\u998f\u6846\u67b6CTPD\uff0c\u901a\u8fc7\u5b57\u7b26\u7ea7\u5bf9\u9f50\u548c\u91cd\u8981\u6027\u91c7\u6837\u7b49\u6280\u672f\uff0c\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u9ad8\u6548\u5bf9\u9f50\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u76ee\u524d\u77e5\u8bc6\u84b8\u998f\u5728\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u4e2d\u7684\u5e94\u7528\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u5728\u8de8\u4e0d\u540c\u5206\u8bcd\u5668\u7684\u73b0\u5b9e\u573a\u666f\u4e2d\u5b58\u5728\u96be\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u8de8\u5206\u8bcd\u5668\u504f\u597d\u84b8\u998f\uff08CTPD\uff09\u6846\u67b6\uff0c\u5305\u62ec\u5bf9\u9f50\u8de8\u5ea6\u6295\u5f71\u3001\u8de8\u5206\u8bcd\u5668\u7684\u91cd\u8981\u6027\u91c7\u6837(TIS-DPO)\u53ca\u6559\u5e08\u951a\u5b9a\u53c2\u8003\u673a\u5236\u3002", "result": "\u591a\u57fa\u51c6\u5b9e\u9a8c\u9a8c\u8bc1\u4e86CTPD\u7684\u6709\u6548\u6027\uff0c\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "CTPD\u4e3a\u89e3\u51b3\u5f02\u6784\u5206\u8bcd\u5668\u95f4\u504f\u597d\u84b8\u998f\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u901a\u7528\u7684\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u66f4\u52a0\u9ad8\u6548\u5730\u5bf9\u9f50\u8bed\u8a00\u6a21\u578b\u4e0e\u4eba\u7c7b\u504f\u597d\u3002"}}
{"id": "2601.12559", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12559", "abs": "https://arxiv.org/abs/2601.12559", "authors": ["Yvan Labiche"], "title": "Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use", "comment": null, "summary": "Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u5f62\u754c\u9762\u7684\u5de5\u5177\u81ea\u52a8\u5316\u5b9e\u73b0Category-Partition\u6d4b\u8bd5\u65b9\u6cd5\uff0c\u663e\u8457\u7b80\u5316\u6d4b\u8bd5\u8fc7\u7a0b\u5e76\u63d0\u5347\u6548\u7387\uff0c\u5df2\u901a\u8fc7\u6848\u4f8b\u9a8c\u8bc1\u3002", "motivation": "Category-Partition\u6d4b\u8bd5\u6280\u672f\u867d\u7136\u6709\u6548\uff0c\u4f46\u624b\u5de5\u5212\u5206\u8f93\u5165\u57df\u548c\u7ec4\u5408\u6d4b\u8bd5\u7528\u4f8b\u8fc7\u7a0b\u590d\u6742\u4e14\u6613\u51fa\u9519\uff0c\u56e0\u6b64\u9700\u8981\u81ea\u52a8\u5316\u5de5\u5177\u652f\u6301\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u5e26\u6709\u56fe\u5f62\u7528\u6237\u754c\u9762\uff08GUI\uff09\u7684\u5de5\u5177\uff0c\u5141\u8bb8\u7528\u6237\u5b9a\u4e49\u53c2\u6570\u3001\u73af\u5883\u53d8\u91cf\u3001\u7c7b\u522b\u53ca\u5176\u9009\u9879\u548c\u7ea6\u675f\uff0c\u7136\u540e\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u6846\u67b6\u548c\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5de5\u5177\u652f\u6301\u591a\u79cd\u6570\u636e\u7c7b\u578b\uff0c\u80fd\u591f\u6839\u636e\u4e0d\u540c\u9009\u62e9\u6807\u51c6\u81ea\u52a8\u6784\u5efa\u6d4b\u8bd5\u6846\u67b6\u5e76\u751f\u6210\u76f8\u5e94\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5df2\u901a\u8fc7\u4e5d\u4e2a\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u5176\u5b9e\u7528\u6027\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9Category-Partition\u65b9\u6cd5\u4e2d\u591a\u4e2a\u6b65\u9aa4\u7684\u81ea\u52a8\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u529f\u80fd\u6d4b\u8bd5\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.11866", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11866", "abs": "https://arxiv.org/abs/2601.11866", "authors": ["Kie Shidara", "Preethi Prem", "Jonathan Kim", "Anna Podlasek", "Feng Liu", "Ahmed Alaa", "Danilo Bernardo"], "title": "Advances in LLM Reasoning Enable Flexibility in Clinical Problem-Solving", "comment": "10 pages, 6 figures", "summary": "Large Language Models (LLMs) have achieved high accuracy on medical question-answer (QA) benchmarks, yet their capacity for flexible clinical reasoning has been debated. Here, we asked whether advances in reasoning LLMs improve their cognitive flexibility in clinical reasoning. We assessed reasoning models from the OpenAI, Grok, Gemini, Claude, and DeepSeek families on the medicine abstraction and reasoning corpus (mARC), an adversarial medical QA benchmark which utilizes the Einstellung effect to induce inflexible overreliance on learned heuristic patterns in contexts where they become suboptimal. We found that strong reasoning models avoided Einstellung-based traps more often than weaker reasoning models, achieving human-level performance on mARC. On questions most commonly missed by physicians, the top 5 performing models answered 55% to 70% correctly with high confidence, indicating that these models may be less susceptible than humans to Einstellung effects. Our results indicate that strong reasoning models demonstrate improved flexibility in medical reasoning, achieving performance on par with humans on mARC.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\uff0c\u5148\u8fdb\u7684\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u95ee\u9898\u63a8\u7406\u4e0a\u5c55\u73b0\u51fa\u63a5\u8fd1\u4eba\u7c7b\u7684\u7075\u6d3b\u6027\u548c\u51c6\u786e\u6027\uff0c\u80fd\u6709\u6548\u907f\u514d\u56e0\u56fa\u5b9a\u601d\u7ef4\u6a21\u5f0f\u5e26\u6765\u7684\u63a8\u7406\u9519\u8bef\u3002", "motivation": "\u63a2\u7a76\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u533b\u5b66\u63a8\u7406\u4e2d\u7684\u8ba4\u77e5\u7075\u6d3b\u6027\uff0c\u7279\u522b\u662f\u5b83\u4eec\u5bf9\u56fa\u6709\u601d\u7ef4\u9677\u9631\u7684\u62b5\u6297\u80fd\u529b\u3002", "method": "\u8bc4\u4f30\u4e86OpenAI\u3001Grok\u3001Gemini\u3001Claude\u548cDeepSeek\u7b49\u6a21\u578b\u5728\u533b\u5b66\u62bd\u8c61\u548c\u63a8\u7406\u8bed\u6599\u5e93(mARC)\u4e0a\u7684\u8868\u73b0\uff0c\u8be5\u8bed\u6599\u5e93\u8bbe\u8ba1\u5229\u7528Einstellung\u6548\u5e94\u8bf1\u5bfc\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u5df2\u6709\u6a21\u5f0f\u3002", "result": "\u8868\u73b0\u6700\u5f3a\u76845\u4e2a\u6a21\u578b\u5728\u533b\u751f\u6700\u5e38\u9519\u7b54\u7684\u95ee\u9898\u4e0a\uff0c\u6b63\u786e\u7387\u8fbe\u523055%-70%\uff0c\u4e14\u7f6e\u4fe1\u5ea6\u8f83\u9ad8\uff0c\u663e\u793a\u8fd9\u4e9b\u6a21\u578b\u5bf9Einstellung\u6548\u5e94\u7684\u654f\u611f\u5ea6\u4f4e\u4e8e\u4eba\u7c7b\u3002", "conclusion": "\u5f3a\u5927\u7684\u63a8\u7406\u578b\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u7075\u6d3b\u6027\uff0c\u80fd\u591f\u907f\u514d\u56e0\u56fa\u6709\u601d\u7ef4\u6a21\u5f0f\u5bfc\u81f4\u7684\u9519\u8bef\uff0c\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u3002"}}
{"id": "2601.12735", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12735", "abs": "https://arxiv.org/abs/2601.12735", "authors": ["Hao Chen", "Yunchun Li", "Chen Chen", "Fengxu Lin", "Wei Li"], "title": "OpenAI for OpenAPI: Automated generation of REST API specification via LLMs", "comment": null, "summary": "REST APIs, based on the REpresentational State Transfer (REST) architecture, are the primary type of Web API. The OpenAPI Specification (OAS) serves as the de facto standard for describing REST APIs and is crucial for multiple software engineering tasks. However, developers face challenges in writing and maintaining OAS. Although static analysis shows potential for OAS generation, it is limited to specific programming languages and development frameworks. The powerful code understanding capabilities of LLMs offer new opportunities for OAS generation, yet they are constrained by context limitations and hallucinations. To address these challenges, we propose the OpenAI OpenAPI Project Scanner (OOPS), the first technology-agnostic LLM-based static analysis method for OAS generation, requiring fewer technology-specific rules and less human expert intervention. OOPS is implemented as an LLM agent workflow comprising two key steps: endpoint method extraction and OAS generation. By constructing an API dependency graph, it establishes necessary file associations to address LLMs' context limitations. Through multi-stage generation and self-refine, it mitigates both syntactic and semantic hallucinations during OAS generation. We evaluated OOPS on 12 real-world REST APIs spanning 5 programming languages and 8 development frameworks. Experimental results demonstrate that OOPS accurately generates high-quality OAS for REST APIs implemented with diverse technologies, achieving an average F1-score exceeding 98% for endpoint method inference, 97% for both request parameter and response inference, and 92% for parameter constraint inference. The input tokens average below 5.6K with a maximum of 16.2K, while the output tokens average below 0.9K with a maximum of 7.7K.", "AI": {"tldr": "\u9488\u5bf9\u73b0\u6709OAS\u751f\u6210\u5c40\u9650\uff0c\u672c\u6587\u63d0\u51fa\u57fa\u4e8eLLM\u7684OOPS\u65b9\u6cd5\uff0c\u5b9e\u73b0\u8de8\u8bed\u8a00\u6846\u67b6\u7684\u9ad8\u8d28\u91cf\u81ea\u52a8\u5316OAS\u751f\u6210\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u9ad8\u51c6\u786e\u7387\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u5f00\u53d1\u8005\u5728\u7f16\u5199\u548c\u7ef4\u62a4OpenAPI\u89c4\u8303\uff08OAS\uff09\u65f6\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u9759\u6001\u5206\u6790\u65b9\u6cd5\u53d7\u9650\u4e8e\u7f16\u7a0b\u8bed\u8a00\u548c\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684OOPS\u65b9\u6cd5\uff0c\u901a\u8fc7\u6784\u5efaAPI\u4f9d\u8d56\u56fe\u89e3\u51b3\u4e0a\u4e0b\u6587\u9650\u5236\uff0c\u91c7\u7528\u591a\u9636\u6bb5\u751f\u6210\u548c\u81ea\u6211\u4f18\u5316\u7f13\u89e3\u5e7b\u89c9\u95ee\u9898\uff0c\u5b9e\u73b0\u6280\u672f\u65e0\u5173\u7684\u9759\u6001\u5206\u6790OAS\u751f\u6210\u3002", "result": "\u572812\u4e2a\u771f\u5b9eREST API\u4e0a\u6d4b\u8bd5\uff0c\u6db5\u76d65\u79cd\u7f16\u7a0b\u8bed\u8a00\u548c8\u79cd\u6846\u67b6\uff0cOOPS\u5728\u7aef\u70b9\u65b9\u6cd5\u63a8\u65ad\u3001\u8bf7\u6c42\u53c2\u6570\u548c\u54cd\u5e94\u63a8\u65ad\u4ee5\u53ca\u53c2\u6570\u7ea6\u675f\u63a8\u65ad\u7684F1-score\u5206\u522b\u8fbe\u523098%\u300197%\u548c92%\uff0c\u8f93\u5165\u8f93\u51fatoken\u91cf\u9002\u4e2d\u3002", "conclusion": "OOPS\u6709\u6548\u4e14\u51c6\u786e\u5730\u751f\u6210\u9ad8\u8d28\u91cf\u7684OAS\uff0c\u4e14\u5177\u5907\u6280\u672f\u65e0\u5173\u6027\u548c\u8f83\u5c11\u4eba\u7c7b\u5e72\u9884\uff0c\u5c55\u793a\u4e86LLM\u5728\u81ea\u52a8\u751f\u6210API\u6587\u6863\u9886\u57df\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.11872", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11872", "abs": "https://arxiv.org/abs/2601.11872", "authors": ["Nguyen Tien Phat", "Ngo Vu Minh", "Linh Van Ngo", "Nguyen Thi Ngoc Diep", "Thien Huu Nguyen"], "title": "GloCTM: Cross-Lingual Topic Modeling via a Global Context Space", "comment": "AAAI 2026", "summary": "Cross-lingual topic modeling seeks to uncover coherent and semantically aligned topics across languages - a task central to multilingual understanding. Yet most existing models learn topics in disjoint, language-specific spaces and rely on alignment mechanisms (e.g., bilingual dictionaries) that often fail to capture deep cross-lingual semantics, resulting in loosely connected topic spaces. Moreover, these approaches often overlook the rich semantic signals embedded in multilingual pretrained representations, further limiting their ability to capture fine-grained alignment. We introduce GloCTM (Global Context Space for Cross-Lingual Topic Model), a novel framework that enforces cross-lingual topic alignment through a unified semantic space spanning the entire model pipeline. GloCTM constructs enriched input representations by expanding bag-of-words with cross-lingual lexical neighborhoods, and infers topic proportions using both local and global encoders, with their latent representations aligned through internal regularization. At the output level, the global topic-word distribution, defined over the combined vocabulary, structurally synchronizes topic meanings across languages. To further ground topics in deep semantic space, GloCTM incorporates a Centered Kernel Alignment (CKA) loss that aligns the latent topic space with multilingual contextual embeddings. Experiments across multiple benchmarks demonstrate that GloCTM significantly improves topic coherence and cross-lingual alignment, outperforming strong baselines.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\u7684\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578bGloCTM\uff0c\u901a\u8fc7\u6269\u5c55\u8f93\u5165\u548c\u591a\u5c42\u5bf9\u9f50\u673a\u5236\u63d0\u5347\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u8de8\u8bed\u8a00\u8bed\u4e49\u5bf9\u9f50\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u73b0\u6709\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u5728\u8bed\u8a00\u7279\u5b9a\u7a7a\u95f4\u4e2d\u5b66\u4e60\u4e3b\u9898\uff0c\u5e76\u4f9d\u8d56\u5bf9\u9f50\u673a\u5236\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u672a\u80fd\u6df1\u5ea6\u6355\u6349\u8de8\u8bed\u8a00\u8bed\u4e49\uff0c\u4e14\u5ffd\u89c6\u4e86\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u8868\u793a\u4e2d\u7684\u8bed\u4e49\u4fe1\u53f7\uff0c\u9650\u5236\u4e86\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u80fd\u529b\u3002", "method": "\u63d0\u51faGloCTM\u6846\u67b6\uff0c\u901a\u8fc7\u7edf\u4e00\u8bed\u4e49\u7a7a\u95f4\u5b9e\u73b0\u8de8\u8bed\u8a00\u4e3b\u9898\u5bf9\u9f50\u3002\u8f93\u5165\u6269\u5c55\u4e3a\u8de8\u8bed\u8a00\u8bcd\u6c47\u90bb\u57df\uff0c\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u7f16\u7801\u5668\uff0c\u5e76\u901a\u8fc7\u5185\u90e8\u6b63\u5219\u5316\u5bf9\u9f50\u6f5c\u5728\u8868\u793a\u3002\u8f93\u51fa\u5c42\u901a\u8fc7\u5168\u5c40\u4e3b\u9898-\u8bcd\u5206\u5e03\u540c\u6b65\u8de8\u8bed\u8a00\u4e3b\u9898\u8bed\u4e49\uff0c\u5e76\u5f15\u5165\u4e2d\u5fc3\u6838\u5bf9\u9f50\uff08CKA\uff09\u635f\u5931\u4ee5\u5bf9\u9f50\u6f5c\u5728\u4e3b\u9898\u7a7a\u95f4\u4e0e\u591a\u8bed\u8a00\u4e0a\u4e0b\u6587\u5d4c\u5165\u3002", "result": "\u591a\u57fa\u51c6\u5b9e\u9a8c\u663e\u793a\uff0cGloCTM\u5728\u4e3b\u9898\u8fde\u8d2f\u6027\u548c\u8de8\u8bed\u8a00\u5bf9\u9f50\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "GloCTM\u6709\u6548\u6574\u5408\u591a\u8bed\u8a00\u8bed\u4e49\u4fe1\u606f\uff0c\u63d0\u5347\u4e86\u8de8\u8bed\u8a00\u4e3b\u9898\u6a21\u578b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u5bf9\u9f50\u8d28\u91cf\uff0c\u63a8\u52a8\u4e86\u591a\u8bed\u8a00\u7406\u89e3\u4efb\u52a1\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.12762", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12762", "abs": "https://arxiv.org/abs/2601.12762", "authors": ["Xingjie Gao", "Pengcheng Huang", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Zulong Chen", "Chen Qian", "Ge Yu", "Yu Gu"], "title": "Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction", "comment": null, "summary": "Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faToolMaster\uff0c\u901a\u8fc7\u8ba9\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u52a8\u8bd5\u9519\u548c\u5b66\u4e60\u5de5\u5177\u4f7f\u7528\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5176\u9762\u5bf9\u65b0\u5de5\u5177\u7684\u6cdb\u5316\u548c\u7a33\u5065\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f7f\u7528\u5916\u90e8\u5de5\u5177\u65f6\uff0c\u56e0\u8fc7\u5ea6\u4f9d\u8d56\u8bad\u7ec3\u65f6\u9759\u6001\u7684\u89e3\u51b3\u8def\u5f84\uff0c\u96be\u4ee5\u9002\u5e94\u65b0\u5de5\u5177\u6216\u53d8\u5316\u7684\u5de5\u5177\uff0c\u5bfc\u81f4\u7a33\u5065\u6027\u4e0d\u8db3\u3002", "method": "\u63d0\u51faToolMaster\u6846\u67b6\uff0c\u5f15\u5165\u8bd5\u9519\u6267\u884c\u8303\u5f0f\uff0c\u5148\u6a21\u4eff\u6559\u5e08\u751f\u6210\u7684\u5305\u542b\u5de5\u5177\u8bd5\u9a8c\u548c\u81ea\u6211\u7ea0\u6b63\u7684\u8f68\u8ff9\uff0c\u518d\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8054\u5408\u4f18\u5316\u8bd5\u9a8c\u4e0e\u6267\u884c\u9636\u6bb5\uff0c\u5b9e\u73b0\u4e3b\u52a8\u73af\u5883\u4ea4\u4e92\u548c\u5de5\u5177\u4f7f\u7528\u5b66\u4e60\u3002", "result": "ToolMaster\u5728\u9762\u5bf9\u672a\u89c1\u8fc7\u6216\u4e0d\u719f\u6089\u5de5\u5177\u65f6\uff0c\u8868\u73b0\u51fa\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6cdb\u5316\u80fd\u529b\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u901a\u8fc7\u8bd5\u9a8c\u4e0e\u6267\u884c\u7ed3\u5408\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0cToolMaster\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6837\u5316\u548c\u52a8\u6001\u5de5\u5177\u4f7f\u7528\u73af\u5883\u4e2d\u7684\u9002\u5e94\u80fd\u529b\u548c\u6548\u679c\u3002"}}
{"id": "2601.11886", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11886", "abs": "https://arxiv.org/abs/2601.11886", "authors": ["Kaijie Mo", "Siddhartha Venkatayogi", "Chantal Shaib", "Ramez Kouzy", "Wei Xu", "Byron C. Wallace", "Junyi Jessy Li"], "title": "Faithfulness vs. Safety: Evaluating LLM Behavior Under Counterfactual Medical Evidence", "comment": "26 pages", "summary": "In high-stakes domains like medicine, it may be generally desirable for models to faithfully adhere to the context provided. But what happens if the context does not align with model priors or safety protocols? In this paper, we investigate how LLMs behave and reason when presented with counterfactual or even adversarial medical evidence. We first construct MedCounterFact, a counterfactual medical QA dataset that requires the models to answer clinical comparison questions (i.e., judge the efficacy of certain treatments, with evidence consisting of randomized controlled trials provided as context). In MedCounterFact, real-world medical interventions within the questions and evidence are systematically replaced with four types of counterfactual stimuli, ranging from unknown words to toxic substances. Our evaluation across multiple frontier LLMs on MedCounterFact reveals that in the presence of counterfactual evidence, existing models overwhelmingly accept such \"evidence\" at face value even when it is dangerous or implausible, and provide confident and uncaveated answers. While it may be prudent to draw a boundary between faithfulness and safety, our findings reveal that there exists no such boundary yet.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u4e00\u4e2a\u53cd\u4e8b\u5b9e\u533b\u7597\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u4e0d\u5b9e\u751a\u81f3\u5371\u9669\u533b\u7597\u8bc1\u636e\u65f6\uff0c\u4f9d\u7136\u76f2\u76ee\u4fe1\u4efb\u5e76\u7ed9\u51fa\u8fc7\u4e8e\u81ea\u4fe1\u7684\u56de\u7b54\uff0c\u66b4\u9732\u51fa\u4fe1\u5b9e\u6027\u4e0e\u5b89\u5168\u6027\u4e4b\u95f4\u7f3a\u4e4f\u754c\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u63a2\u7a76\u5728\u533b\u7597\u7b49\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u5f53\u6a21\u578b\u6240\u63a5\u6536\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e0e\u5176\u5148\u9a8c\u77e5\u8bc6\u6216\u5b89\u5168\u534f\u8bae\u4e0d\u4e00\u81f4\u65f6\uff0c\u6a21\u578b\u5982\u4f55\u63a8\u7406\u548c\u8868\u73b0\u3002", "method": "\u6784\u5efa\u4e86MedCounterFact\u8fd9\u4e00\u53cd\u4e8b\u5b9e\u533b\u7597\u95ee\u7b54\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u7cfb\u7edf\u66ff\u6362\u771f\u5b9e\u533b\u7597\u5e72\u9884\u624b\u6bb5\uff0c\u751f\u6210\u56db\u79cd\u7c7b\u578b\u7684\u53cd\u4e8b\u5b9e\u523a\u6fc0\uff0c\u8fdb\u800c\u8bc4\u4f30\u591a\u79cd\u524d\u6cbf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u6a21\u578b\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u533b\u7597\u8bc1\u636e\u65f6\uff0c\u4f1a\u76f2\u76ee\u63a5\u53d7\u4e0d\u5408\u7406\u751a\u81f3\u5371\u9669\u7684\u4fe1\u606f\uff0c\u672a\u80fd\u6709\u6548\u533a\u5206\u53ef\u4fe1\u4fe1\u606f\u4e0e\u5bf9\u6297\u6027\u4fe1\u606f\uff0c\u8868\u660e\u5c1a\u672a\u5b9e\u73b0\u4fe1\u5b9e\u6027\u4e0e\u5b89\u5168\u6027\u7684\u6709\u6548\u754c\u9650\u3002", "conclusion": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9762\u5bf9\u53cd\u4e8b\u5b9e\u6216\u5bf9\u6297\u6027\u533b\u7597\u8bc1\u636e\u65f6\uff0c\u5f80\u5f80\u76f2\u76ee\u63a5\u53d7\u8fd9\u4e9b\u4fe1\u606f\uff0c\u7f3a\u4e4f\u5bf9\u5371\u9669\u6216\u4e0d\u5408\u7406\u5185\u5bb9\u7684\u8b66\u60d5\uff0c\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\u4e14\u65e0\u4fdd\u7559\u7684\u56de\u7b54\u3002"}}
{"id": "2601.12811", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12811", "abs": "https://arxiv.org/abs/2601.12811", "authors": ["Julien Malka", "Stefano Zacchiroli", "Th\u00e9o Zimmermann"], "title": "Docker Does Not Guarantee Reproducibility", "comment": null, "summary": "The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.\n  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u548c\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86Docker\u5bf9\u8f6f\u4ef6\u73af\u5883\u53ef\u91cd\u73b0\u6027\u7684\u5b9e\u9645\u4fdd\u969c\u53ca\u76f8\u5173\u6700\u4f73\u5b9e\u8df5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u660e\u786eDocker\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u4fdd\u969c\u73af\u5883\u53ef\u91cd\u73b0\u6027\u7684\u7a0b\u5ea6\u53ca\u5176\u5c40\u9650\uff0c\u586b\u8865\u7406\u8bba\u548c\u5b9e\u8df5\u4e4b\u95f4\u7684\u7a7a\u767d\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u6587\u732e\u7efc\u8ff0\u7ed3\u5408\u5bf9GitHub\u4e0a5298\u4e2aDocker\u6587\u4ef6\u7684\u91cd\u5efa\u5b9e\u8bc1\u7814\u7a76\u3002", "result": "\u786e\u8ba4\u6587\u732e\u4e2d\u6700\u4f73\u5b9e\u8df5\u5bf9\u63d0\u5347Docker\u955c\u50cf\u53ef\u91cd\u73b0\u6027\u6709\u79ef\u6781\u4f5c\u7528\uff0c\u4f46\u5b9e\u9645\u91cd\u5efa\u4e2d\u4ecd\u5b58\u5728\u4e0d\u4e00\u81f4\u3002", "conclusion": "Docker\u5728\u5b9e\u8df5\u4e2d\u5bf9\u8f6f\u4ef6\u73af\u5883\u53ef\u91cd\u73b0\u6027\u6709\u4e00\u5b9a\u4fdd\u969c\uff0c\u4f46\u4ecd\u5b58\u5728\u5c40\u9650\u6027\uff0c\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u6700\u4f73\u5b9e\u8df5\u5bf9\u63d0\u5347\u53ef\u91cd\u73b0\u6027\u6709\u6548\u3002"}}
{"id": "2601.11908", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11908", "abs": "https://arxiv.org/abs/2601.11908", "authors": ["Byeongjin Kim", "Gyuwan Kim", "Seo Yeon Park"], "title": "PPA-Plan: Proactive Pitfall Avoidance for Reliable Planning in Long-Context LLM Reasoning", "comment": "23 pages, 6 figures", "summary": "Large language models (LLMs) struggle with reasoning over long contexts where relevant information is sparsely distributed. Although plan-and-execute frameworks mitigate this by decomposing tasks into planning and execution, their effectiveness is often limited by unreliable plan generation due to dependence on surface-level cues. Consequently, plans may be based on incorrect assumptions, and once a plan is formed, identifying what went wrong and revising it reliably becomes difficult, limiting the effectiveness of reactive refinement. To address this limitation, we propose PPA-Plan, a proactive planning strategy for long-context reasoning that focuses on preventing such failures before plan generation. PPA-Plan identifies potential logical pitfalls and false assumptions, formulates them as negative constraints, and conditions plan generation on explicitly avoiding these constraints. Experiments on long-context QA benchmarks show that executing plans generated by PPA-Plan consistently outperforms existing plan-and-execute methods and direct prompting.", "AI": {"tldr": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u8ba1\u5212\u751f\u6210\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u63d0\u51faPPA-Plan\u4e3b\u52a8\u9884\u9632\u9519\u8bef\u5047\u8bbe\u548c\u903b\u8f91\u9677\u9631\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u56e0\u4f9d\u8d56\u8868\u5c42\u7ebf\u7d22\u5bfc\u81f4\u8ba1\u5212\u751f\u6210\u4e0d\u53ef\u9760\uff0c\u8fdb\u800c\u5f71\u54cd\u6267\u884c\u6548\u679c\uff0c\u4e14\u9519\u8bef\u8ba1\u5212\u96be\u4ee5\u53ca\u65f6\u8bc6\u522b\u548c\u4fee\u6539\uff0c\u9650\u5236\u4e86\u53cd\u5e94\u5f0f\u4f18\u5316\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51faPPA-Plan\u7b56\u7565\uff0c\u5728\u8ba1\u5212\u751f\u6210\u524d\u9884\u9632\u53ef\u80fd\u7684\u5931\u8d25\uff0c\u8bc6\u522b\u6f5c\u5728\u7684\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\uff0c\u5c06\u5176\u4f5c\u4e3a\u8d1f\u9762\u7ea6\u675f\uff0c\u5e76\u5728\u751f\u6210\u8ba1\u5212\u65f6\u663e\u5f0f\u907f\u514d\u8fd9\u4e9b\u7ea6\u675f\u3002", "result": "\u5728\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPPA-Plan\u751f\u6210\u7684\u8ba1\u5212\u6267\u884c\u6548\u679c\u7a33\u5b9a\u4f18\u4e8e\u73b0\u6709\u7684\u8ba1\u5212-\u6267\u884c\u65b9\u6cd5\u548c\u76f4\u63a5\u63d0\u793a\u7b56\u7565\u3002", "conclusion": "PPA-Plan\u901a\u8fc7\u4e3b\u52a8\u8bc6\u522b\u5e76\u907f\u514d\u903b\u8f91\u9677\u9631\u548c\u9519\u8bef\u5047\u8bbe\uff0c\u6709\u6548\u63d0\u5347\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u8ba1\u5212\u751f\u6210\u7684\u53ef\u9760\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u7684\u8ba1\u5212\u6267\u884c\u6846\u67b6\u548c\u76f4\u63a5\u63d0\u793a\u65b9\u6cd5\u3002"}}
{"id": "2601.12845", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12845", "abs": "https://arxiv.org/abs/2601.12845", "authors": ["Jo\u00e3o Pascoal Faria", "Emanuel Trigo", "Vinicius Honorato", "Rui Abreu"], "title": "Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles", "comment": null, "summary": "Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u4e3aDafny\u7a0b\u5e8f\u751f\u6210\u5f62\u5f0f\u9a8c\u8bc1\u6ce8\u91ca\uff0c\u663e\u8457\u63d0\u9ad8\u81ea\u52a8\u5316\u7a0b\u5ea6\u5e76\u51cf\u8f7b\u4eba\u5de5\u8d1f\u62c5\uff0c\u5728\u591a\u7a0b\u5e8f\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u96c6\u6210\u4e8e\u5f00\u53d1\u73af\u5883\u4e2d\u83b7\u5f97\u7528\u6237\u8ba4\u53ef\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3\u9a8c\u8bc1\u5de5\u5177\u529b\u56fe\u7b80\u5316\u5f62\u5f0f\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u4f46\u624b\u52a8\u4e3a\u4f20\u7edf\u7a0b\u5e8f\u6dfb\u52a0\u5f62\u5f0f\u89c4\u683c\u548c\u9a8c\u8bc1\u6ce8\u91ca\u4f9d\u7136\u9700\u8981\u5927\u91cf\u7684\u4eba\u5de5\u52aa\u529b\u548c\u4e13\u4e1a\u77e5\u8bc6\uff0c\u672c\u6587\u65e8\u5728\u63a2\u7d22\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u8fd9\u4e9b\u6ce8\u91ca\u4ee5\u964d\u4f4e\u95e8\u69db\u3002", "method": "\u5229\u7528Claude Opus 4.5\u548cGPT-5.2\u7684\u591a\u6a21\u578b\u7ec4\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u9a8c\u8bc1\u5668\u7684\u53cd\u9988\u673a\u5236\uff0c\u5728Dafny\u7a0b\u5e8f\u4e0a\u8fed\u4ee3\u4fee\u6b63\u6ce8\u91ca\uff0c\u81ea\u52a8\u751f\u6210\u5f62\u5f0f\u9a8c\u8bc1\u6240\u9700\u7684\u524d\u7f6e\u6761\u4ef6\u3001\u540e\u7f6e\u6761\u4ef6\u3001\u5faa\u73af\u4e0d\u53d8\u91cf\u7b49\u6ce8\u91ca\u3002", "result": "\u5728110\u4e2aDafny\u7a0b\u5e8f\u7684\u5b9e\u9a8c\u4e2d\uff0c\u81ea\u52a8\u751f\u6210\u6ce8\u91ca\u7684\u6b63\u786e\u7387\u8fbe\u523098.2%\uff0c\u901a\u8fc7\u6700\u591a8\u6b21\u7684\u4fee\u6b63\u8fed\u4ee3\u5b8c\u6210\u3002\u56de\u5f52\u5206\u6790\u8868\u660e\uff0c\u8f85\u52a9\u8bc1\u660e\u6ce8\u91ca\u5bf9\u6a21\u578b\u6311\u6218\u8f83\u5927\u3002\u6d4b\u8bd5\u7528\u4f8b\u4e2d\u7684\u65ad\u8a00\u7528\u4e8e\u81ea\u52a8\u9a8c\u8bc1\u751f\u6210\u7684\u6ce8\u91ca\u3002\u5e76\u5b9e\u73b0\u4e86Visual Studio Code\u63d2\u4ef6\uff0c\u83b7\u5f97\u826f\u597d\u7528\u6237\u53cd\u9988\u3002", "conclusion": "\u901a\u8fc7\u7ed3\u5408\u591a\u6a21\u578b\u65b9\u6cd5\u548c\u9a8c\u8bc1\u53cd\u9988\uff0cLLMs\u80fd\u591f\u81ea\u52a8\u751f\u6210Dafny\u7a0b\u5e8f\u7684\u5f62\u5f0f\u9a8c\u8bc1\u6ce8\u91ca\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u624b\u52a8\u6ce8\u91ca\u7684\u590d\u6742\u5ea6\u548c\u6240\u9700\u4e13\u4e1a\u77e5\u8bc6\u3002"}}
{"id": "2601.11913", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11913", "abs": "https://arxiv.org/abs/2601.11913", "authors": ["Yichen Jiang", "Peng Ye", "Jiakang Yuan", "Chongjun Tu", "Lei Bai", "Tao Chen"], "title": "LSTM-MAS: A Long Short-Term Memory Inspired Multi-Agent System for Long-Context Understanding", "comment": "12 pages, 5 figures", "summary": "Effectively processing long contexts remains a fundamental yet unsolved challenge for large language models (LLMs). Existing single-LLM-based methods primarily reduce the context window or optimize the attention mechanism, but they often encounter additional computational costs or constrained expanded context length. While multi-agent-based frameworks can mitigate these limitations, they remain susceptible to the accumulation of errors and the propagation of hallucinations. In this work, we draw inspiration from the Long Short-Term Memory (LSTM) architecture to design a Multi-Agent System called LSTM-MAS, emulating LSTM's hierarchical information flow and gated memory mechanisms for long-context understanding. Specifically, LSTM-MAS organizes agents in a chained architecture, where each node comprises a worker agent for segment-level comprehension, a filter agent for redundancy reduction, a judge agent for continuous error detection, and a manager agent for globally regulates information propagation and retention, analogous to LSTM and its input gate, forget gate, constant error carousel unit, and output gate. These novel designs enable controlled information transfer and selective long-term dependency modeling across textual segments, which can effectively avoid error accumulation and hallucination propagation. We conducted an extensive evaluation of our method. Compared with the previous best multi-agent approach, CoA, our model achieves improvements of 40.93%, 43.70%,121.57% and 33.12%, on NarrativeQA, Qasper, HotpotQA, and MuSiQue, respectively.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684LSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u501f\u9274LSTM\u7ed3\u6784\uff0c\u6709\u6548\u5904\u7406\u957f\u6587\u4e0a\u4e0b\u6587\uff0c\u663e\u8457\u63d0\u5347\u591a\u9879\u957f\u6587\u672c\u7406\u89e3\u4efb\u52a1\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u5355\u4e00\u5927\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\u53d7\u9650\u4e8e\u8ba1\u7b97\u6210\u672c\u6216\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u867d\u53ef\u7f13\u89e3\uff0c\u4f46\u4f9d\u7136\u5b58\u5728\u9519\u8bef\u7d2f\u79ef\u548c\u5e7b\u89c9\u4f20\u64ad\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u673a\u5236\u4ee5\u6709\u6548\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u5e76\u4fdd\u6301\u4fe1\u606f\u51c6\u786e\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6a21\u4effLSTM\u7ed3\u6784\u7684\u591a\u667a\u80fd\u4f53\u94fe\u5f0f\u67b6\u6784\uff0c\u5305\u62ec\u8d1f\u8d23\u5206\u6bb5\u7406\u89e3\u7684\u5de5\u4f5c\u667a\u80fd\u4f53\u3001\u51cf\u5c11\u5197\u4f59\u7684\u8fc7\u6ee4\u667a\u80fd\u4f53\u3001\u68c0\u6d4b\u9519\u8bef\u7684\u8bc4\u5224\u667a\u80fd\u4f53\u53ca\u5168\u5c40\u8c03\u63a7\u4fe1\u606f\u4f20\u64ad\u548c\u4fdd\u7559\u7684\u7ba1\u7406\u667a\u80fd\u4f53\uff0c\u5b9e\u73b0\u9009\u62e9\u6027\u957f\u671f\u4f9d\u8d56\u5efa\u6a21\u548c\u4fe1\u606f\u63a7\u5236\u4f20\u9012\u3002", "result": "\u5728NarrativeQA\u3001Qasper\u3001HotpotQA\u548cMuSiQue\u56db\u4e2a\u6570\u636e\u96c6\u4e0a\uff0cLSTM-MAS\u76f8\u6bd4\u76ee\u524d\u6700\u4f73\u7684\u591a\u667a\u80fd\u4f53\u65b9\u6cd5CoA\uff0c\u6027\u80fd\u63d0\u5347\u5206\u522b\u8fbe\u523040.93%\u300143.70%\u3001121.57%\u548c33.12%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684LSTM-MAS\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u8fc7\u6a21\u62dfLSTM\u7684\u5c42\u6b21\u4fe1\u606f\u6d41\u548c\u95e8\u63a7\u8bb0\u5fc6\u673a\u5236\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u6587\u672c\u4e0a\u4e0b\u6587\u65f6\u7684\u9519\u8bef\u79ef\u7d2f\u548c\u5e7b\u89c9\u4f20\u64ad\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9879\u957f\u6587\u672c\u7406\u89e3\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2601.12890", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12890", "abs": "https://arxiv.org/abs/2601.12890", "authors": ["Hang Gao", "Tao Peng", "Baoquan Cui", "Hong Huang", "Fengge Wu", "Junsuo Zhao", "Jian Zhang"], "title": "Efficient Code Analysis via Graph-Guided Large Language Models", "comment": null, "summary": "Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4ee3\u7801\u56fe\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5bfc\u5927\u8bed\u8a00\u6a21\u578b\u5173\u6ce8\u5173\u952e\u4ee3\u7801\u533a\u57df\uff0c\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u68c0\u6d4b\u548c\u66f4\u4f4e\u7684\u6807\u6ce8\u6210\u672c\uff0c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u4e0e\u5b9e\u7528\u6027\u3002", "motivation": "\u6076\u610f\u884c\u4e3a\u5e38\u9690\u85cf\u4e8e\u5c0f\u4e14\u6613\u88ab\u5ffd\u89c6\u7684\u4ee3\u7801\u7247\u6bb5\u4e2d\uff0c\u4e14\u5b58\u5728\u8de8\u6587\u4ef6\u4f9d\u8d56\uff0c\u5bfc\u81f4\u5373\u4f7f\u662f\u5f3a\u5927\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e5f\u96be\u4ee5\u53ef\u9760\u68c0\u6d4b\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u9879\u76ee\u89e3\u6790\u6210\u4ee3\u7801\u56fe\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u8282\u70b9\u7684\u8bed\u4e49\u548c\u7ed3\u6784\u4fe1\u606f\uff0c\u518d\u901a\u8fc7\u56fe\u795e\u7ecf\u7f51\u7edc\u8fdb\u884c\u521d\u6b65\u68c0\u6d4b\uff0c\u5229\u7528\u56de\u6eaf\u673a\u5236\u5b9a\u4f4d\u91cd\u8981\u4ee3\u7801\u533a\u57df\uff0c\u5f15\u5bfc\u6a21\u578b\u6ce8\u610f\u529b\u8fdb\u884c\u6df1\u5165\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u516c\u5f00\u53ca\u81ea\u5efa\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u4f18\u4e8e\u5df2\u6709\u6280\u672f\uff0c\u80fd\u591f\u6709\u6548\u51cf\u5c11\u65e0\u5173\u4fe1\u606f\u5e72\u6270\u5e76\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002", "conclusion": "\u8be5\u8bba\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u56fe\u7684\u6ce8\u610f\u529b\u83b7\u53d6\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u6d4b\u6076\u610f\u4ee3\u7801\u884c\u4e3a\u4e2d\u7684\u8868\u73b0\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2601.11920", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11920", "abs": "https://arxiv.org/abs/2601.11920", "authors": ["Zhen Xu", "Vedant Khatri", "Yijun Dai", "Xiner Liu", "Siyan Li", "Xuanming Zhang", "Renzhe Yu"], "title": "Enhancing LLM-Based Data Annotation with Error Decomposition", "comment": null, "summary": "Large language models offer a scalable alternative to human coding for data annotation tasks, enabling the scale-up of research across data-intensive domains. While LLMs are already achieving near-human accuracy on objective annotation tasks, their performance on subjective annotation tasks, such as those involving psychological constructs, is less consistent and more prone to errors. Standard evaluation practices typically collapse all annotation errors into a single alignment metric, but this simplified approach may obscure different kinds of errors that affect final analytical conclusions in different ways. Here, we propose a diagnostic evaluation paradigm that incorporates a human-in-the-loop step to separate task-inherent ambiguity from model-driven inaccuracies and assess annotation quality in terms of their potential downstream impacts. We refine this paradigm on ordinal annotation tasks, which are common in subjective annotation. The refined paradigm includes: (1) a diagnostic taxonomy that categorizes LLM annotation errors along two dimensions: source (model-specific vs. task-inherent) and type (boundary ambiguity vs. conceptual misidentification); (2) a lightweight human annotation test to estimate task-inherent ambiguity from LLM annotations; and (3) a computational method to decompose observed LLM annotation errors following our taxonomy. We validate this paradigm on four educational annotation tasks, demonstrating both its conceptual validity and practical utility. Theoretically, our work provides empirical evidence for why excessively high alignment is unrealistic in specific annotation tasks and why single alignment metrics inadequately reflect the quality of LLM annotations. In practice, our paradigm can be a low-cost diagnostic tool that assesses the suitability of a given task for LLM annotation and provides actionable insights for further technical optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u4eba\u5de5\u53c2\u4e0e\u7684\u8bca\u65ad\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7ec6\u5316\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u9519\u8bef\u7c7b\u578b\uff0c\u63d0\u5347\u6807\u6ce8\u8d28\u91cf\u7684\u7406\u89e3\u4e0e\u8bc4\u4ef7\uff0c\u9a8c\u8bc1\u5176\u5728\u6559\u80b2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u867d\u7136\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5ba2\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u4eba\u7c7b\uff0c\u4f46\u5728\u6d89\u53ca\u5fc3\u7406\u6784\u5ff5\u7b49\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u7a33\u5b9a\uff0c\u4e14\u5e38\u7528\u5355\u4e00\u5bf9\u9f50\u6307\u6807\u65e0\u6cd5\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u9519\u8bef\uff0c\u5bfc\u81f4\u5bf9\u6a21\u578b\u6807\u6ce8\u8d28\u91cf\u8bc4\u4ef7\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u8bca\u65ad\u5206\u7c7b\u6cd5\uff0c\u5c06LLM\u6807\u6ce8\u9519\u8bef\u6309\u7167\u6765\u6e90\uff08\u6a21\u578b\u7279\u5f02 vs. \u4efb\u52a1\u5185\u5728\uff09\u548c\u7c7b\u578b\uff08\u8fb9\u754c\u6b67\u4e49 vs. \u6982\u5ff5\u8bef\u8bc6\u522b\uff09\u8fdb\u884c\u5206\u7c7b\uff1b\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u4eba\u5de5\u6807\u6ce8\u6d4b\u8bd5\u4ee5\u4f30\u8ba1\u4efb\u52a1\u5185\u5728\u6b67\u4e49\uff1b\u5f00\u53d1\u8ba1\u7b97\u65b9\u6cd5\u5206\u89e3\u89c2\u6d4b\u5230\u7684LLM\u9519\u8bef\u3002", "result": "\u9a8c\u8bc1\u4e86\u8bca\u65ad\u8bc4\u4f30\u8303\u5f0f\u5728\u56db\u4e2a\u6559\u80b2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u63ed\u793a\u4e86\u8fc7\u9ad8\u5bf9\u9f50\u6307\u6807\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u4e0d\u73b0\u5b9e\u7684\u539f\u56e0\uff0c\u4ee5\u53ca\u5355\u4e00\u6307\u6807\u5bf9\u6807\u6ce8\u8d28\u91cf\u53cd\u6620\u4e0d\u5145\u5206\u7684\u95ee\u9898\u3002\u8be5\u8303\u5f0f\u53ef\u4f5c\u4e3a\u8bc4\u4ef7LLM\u6807\u6ce8\u9002\u7528\u6027\u548c\u6280\u672f\u4f18\u5316\u7684\u4f4e\u6210\u672c\u8bca\u65ad\u5de5\u5177\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u8bca\u65ad\u6027\u8bc4\u4f30\u8303\u5f0f\uff0c\u901a\u8fc7\u5f15\u5165\u4eba\u5de5\u53c2\u4e0e\u8fc7\u7a0b\uff0c\u5c06\u4efb\u52a1\u5185\u5728\u7684\u6b67\u4e49\u4e0e\u6a21\u578b\u9a71\u52a8\u7684\u9519\u8bef\u533a\u5206\u5f00\u6765\uff0c\u7cbe\u7ec6\u5316\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5728\u4e3b\u89c2\u6807\u6ce8\u4efb\u52a1\u4e2d\u7684\u6807\u6ce8\u8d28\u91cf\u3002\u5b9e\u9a8c\u8bc1\u660e\u8be5\u8303\u5f0f\u5728\u6559\u80b2\u9886\u57df\u56db\u4e2a\u6807\u6ce8\u4efb\u52a1\u4e0a\u5177\u6709\u6982\u5ff5\u6709\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.12927", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.12927", "abs": "https://arxiv.org/abs/2601.12927", "authors": ["Weilin Jin", "Chenyu Zhao", "Zeshun Huang", "Chaoyun Zhang", "Qingwei Lin", "Chetan Bansal", "Saravan Rajmohan", "Shenglin Zhang", "Yongqian Sun", "Dan Pei", "Yifan Wu", "Tong Jia", "Ying Li", "Zhonghai Wu", "Minghua Ma"], "title": "A Benchmark for Language Models in Real-World System Building", "comment": null, "summary": "During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u67b6\u6784\u591a\u8bed\u8a00\u7684\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u57fa\u51c6\uff0c\u8bc4\u4f30\u4e86\u516d\u6b3e\u5148\u8fdb\u8bed\u8a00\u6a21\u578b\uff0c\u63ed\u793a\u4e86\u8de8ISA\u4fee\u590d\u7684\u56f0\u96be\uff0c\u4e3a\u63d0\u5347\u8f6f\u4ef6\u79fb\u690d\u6027\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5f53\u524d\u7684\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u7814\u7a76\u5927\u591a\u96c6\u4e2d\u5728\u5355\u4e00\u6307\u4ee4\u96c6\u67b6\u6784\u548c\u540c\u8d28\u7f16\u7a0b\u8bed\u8a00\uff0c\u7f3a\u4e4f\u5bf9\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u4fee\u590d\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6765\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b268\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u5305\u6784\u5efa\u5931\u8d25\u6848\u4f8b\u7684\u591a\u67b6\u6784\u3001\u591a\u8bed\u8a00\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5728\u6b64\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\u4e86\u516d\u79cd\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u7684\u8f6f\u4ef6\u5305\u4fee\u590d\u4f9d\u7136\u56f0\u96be\uff0c\u73b0\u6709\u6a21\u578b\u7684\u8868\u73b0\u6709\u9650\uff0c\u663e\u793a\u4e86\u8be5\u4efb\u52a1\u7684\u590d\u6742\u6027\u548c\u672a\u6765\u6539\u8fdb\u7684\u5fc5\u8981\u6027\u3002", "conclusion": "\u8de8\u6307\u4ee4\u96c6\u67b6\u6784\u7684\u8f6f\u4ef6\u5305\u6784\u5efa\u4fee\u590d\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\uff0c\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c1a\u672a\u80fd\u5b8c\u5168\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002"}}
{"id": "2601.11923", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11923", "abs": "https://arxiv.org/abs/2601.11923", "authors": ["P. Bilha Githinji", "Aikaterini Melliou", "Xi Yuan", "Dayan Zhang", "Lian Zhang", "Zhenglin Chen", "Jiansong Ji", "Chengying Lv", "Jinhao Xu", "Peiwu Qin", "Dongmei Yu"], "title": "Mapping the maturation of TCM as an adjuvant to radiotherapy", "comment": null, "summary": "The integration of complementary medicine into oncology represents a paradigm shift that has seen to increasing adoption of Traditional Chinese Medicine (TCM) as an adjuvant to radiotherapy. About twenty-five years since the formal institutionalization of integrated oncology, it is opportune to synthesize the trajectory of evidence for TCM as an adjuvant to radiotherapy. Here we conduct a large-scale analysis of 69,745 publications (2000 - 2025), emerging a cyclical evolution defined by coordinated expansion and contraction in publication output, international collaboration, and funding commitments that mirrors a define-ideate-test pattern. Using a theme modeling workflow designed to determine a stable thematic structure of the field, we identify five dominant thematic axes - cancer types, supportive care, clinical endpoints, mechanisms, and methodology - that signal a focus on patient well-being, scientific rigor and mechanistic exploration. Cross-theme integration of TCM is patient-centered and systems-oriented. Together with the emergent cycles of evolution, the thematic structure demonstrates progressive specialization and potential defragmentation of the field or saturation of existing research agenda. The analysis points to a field that has matured its current research agenda and is likely at the cusp of something new. Additionally, the field exhibits positive reporting of findings that is homogeneous across publication types, thematic areas, and the cycles of evolution suggesting a system-wide positive reporting bias agnostic to structural drivers.", "AI": {"tldr": "\u8be5\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u6587\u732e\u5206\u6790\u63ed\u793a\u4e86\u4e2d\u533b\u8f85\u52a9\u653e\u7597\u7814\u7a76\u9886\u57df\u7684\u4e94\u5927\u4e3b\u9898\u548c\u5468\u671f\u6027\u6f14\u5316\uff0c\u6307\u51fa\u8be5\u9886\u57df\u7814\u7a76\u8d8b\u4e8e\u6210\u719f\u5e76\u5b58\u5728\u79ef\u6781\u62a5\u544a\u504f\u501a\uff0c\u6697\u793a\u672a\u6765\u53ef\u80fd\u51fa\u73b0\u65b0\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63a2\u8ba8\u4e2d\u533b\u878d\u5165\u80bf\u7624\u5b66\u8f85\u52a9\u653e\u7597\u7684\u7814\u7a76\u8fdb\u5c55\u4e0e\u8f68\u8ff9\uff0c\u8bc4\u4f30\u8be5\u9886\u57df\u7684\u53d1\u5c55\u6001\u52bf\u548c\u672a\u6765\u6f5c\u529b\u3002", "method": "\u901a\u8fc7\u5206\u67902000\u81f32025\u5e74\u95f469745\u7bc7\u76f8\u5173\u6587\u732e\uff0c\u8fd0\u7528\u4e3b\u9898\u5efa\u6a21\u65b9\u6cd5\u8bc6\u522b\u9886\u57df\u5185\u4e94\u5927\u4e3b\u9898\u8f74\u5e76\u63ed\u793a\u4e86\u9886\u57df\u7684\u6f14\u5316\u5468\u671f\u3002", "result": "\u53d1\u73b0\u4e2d\u533b\u8f85\u52a9\u653e\u7597\u7684\u7814\u7a76\u56f4\u7ed5\u764c\u75c7\u7c7b\u578b\u3001\u652f\u6301\u6027\u62a4\u7406\u3001\u4e34\u5e8a\u7ec8\u70b9\u3001\u673a\u5236\u548c\u65b9\u6cd5\u5b66\u4e94\u5927\u4e3b\u9898\uff0c\u8868\u73b0\u4e3a\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u3001\u7cfb\u7edf\u5bfc\u5411\u7684\u8de8\u4e3b\u9898\u6574\u5408\uff0c\u4e14\u9886\u57df\u6f14\u5316\u5448\u73b0\u6269\u5f20\u6536\u7f29\u7684\u5faa\u73af\u6a21\u5f0f\u3002", "conclusion": "\u4e2d\u533b\u4f5c\u4e3a\u653e\u7597\u8f85\u52a9\u6cbb\u7597\u7684\u7814\u7a76\u5df2\u7ecf\u8fdb\u5165\u6210\u719f\u9636\u6bb5\uff0c\u663e\u793a\u51fa\u7814\u7a76\u8bae\u9898\u7684\u6df1\u5316\u548c\u53ef\u80fd\u7684\u7814\u7a76\u9971\u548c\uff0c\u540c\u65f6\u5b58\u5728\u7cfb\u7edf\u6027\u79ef\u6781\u62a5\u544a\u504f\u501a\u3002"}}
{"id": "2601.12951", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12951", "abs": "https://arxiv.org/abs/2601.12951", "authors": ["Felix M\u00e4chtle", "Jan-Niclas Serr", "Nils Loose", "Thomas Eisenbarth"], "title": "Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models", "comment": "Published in the Proceedings of DeepTest 2026", "summary": "Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65b0\u8bca\u65ad\u6846\u67b6\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u7406\u89e3\u4e0e\u4f20\u7edf\u8f6f\u4ef6\u590d\u6742\u5ea6\u6307\u6807\u5f31\u76f8\u5173\uff0c\u5b58\u5728\u6a21\u578b\u7279\u6709\u7684\u7406\u89e3\u89c4\u5f8b\uff0c\u547c\u5401\u7ec6\u7c92\u5ea6\u8bca\u65ad\u6307\u6807\u63d0\u5347\u8bc4\u6d4b\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u53ea\u63d0\u4f9b\u7c97\u7565\u6027\u80fd\u603b\u7ed3\uff0c\u63a9\u76d6\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4e0d\u540c\u7684\u80fd\u529b\u4e0e\u5c40\u9650\uff0c\u9700\u63a2\u7a76\u5176\u4ee3\u7801\u7406\u89e3\u80fd\u529b\u662f\u5426\u7b26\u5408\u4f20\u7edf\u4eba\u7c7b\u8f6f\u4ef6\u590d\u6742\u5ea6\u6307\u6807\u6216\u5c55\u73b0\u4e0d\u540c\u89c4\u5f8b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5c06\u4ee3\u7801\u7406\u89e3\u8f6c\u5316\u4e3a\u4e8c\u5143\u8f93\u5165\u8f93\u51fa\u4e00\u81f4\u6027\u4efb\u52a1\u7684\u8bca\u65ad\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5206\u6790\u6a21\u578b\u8868\u73b0\u4e0e\u4f20\u7edf\u590d\u6742\u5ea6\u6307\u6807\u7684\u76f8\u5173\u6027\uff0c\u5e76\u4e0e\u5f71\u5b50\u6a21\u578b\u9884\u6d4b\u6548\u679c\u5bf9\u6bd4\u3002", "result": "\u4eba\u7c7b\u5b9a\u4e49\u7684\u590d\u6742\u5ea6\u6307\u6807\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7801\u7406\u89e3\u8868\u73b0\u7684\u76f8\u5173\u6027\u8f83\u5f31\uff08AUROC 0.63\uff09\uff0c\u5f71\u5b50\u6a21\u578b\u80fd\u6355\u6349\u66f4\u590d\u6742\u4e14\u53ef\u9884\u6d4b\u7684\u6a21\u5f0f\uff08AUROC 0.86\uff09\uff0c\u8868\u660e\u7406\u89e3\u8868\u73b0\u542b\u6709\u8d85\u8d8a\u4f20\u7edf\u8f6f\u4ef6\u63aa\u65bd\u7684\u6a21\u578b\u7279\u5b9a\u89c4\u5f8b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4ee3\u7801\u7406\u89e3\u7684\u8868\u73b0\u4ec5\u90e8\u5206\u4e0e\u4f20\u7edf\u4eba\u7c7b\u8f6f\u4ef6\u590d\u6742\u5ea6\u6307\u6807\u76f8\u5173\uff0c\u5b58\u5728\u4e13\u5c5e\u4e8e\u6a21\u578b\u7684\u7406\u89e3\u89c4\u5f8b\uff0c\u4f20\u7edf\u6307\u6807\u96be\u4ee5\u5145\u5206\u9884\u6d4b\u5176\u6210\u529f\u3002"}}
{"id": "2601.11932", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11932", "abs": "https://arxiv.org/abs/2601.11932", "authors": ["Abdullah Al Monsur", "Nitesh Vamshi Bommisetty", "Gene Louis Kim"], "title": "Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes", "comment": null, "summary": "The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language understanding tasks that depend on rich, bidirectional context. Second, we confront the conventional reliance on Micro-F1 scores in event detection literature, which systematically inflates performance by favoring majority classes. Instead, we focus on Macro-F1 as a more representative measure of a model's ability across the long-tail of event types. Our experiments demonstrate that models enhanced with sentence context achieve superior performance over canonical decoder-only baselines. Using Low-Rank Adaptation (LoRA) during finetuning provides a substantial boost in Macro-F1 scores in particular, especially for the decoder-only models, showing that LoRA can be an effective tool to enhance LLMs' performance on long-tailed event classes.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u4f20\u7edf\u4e8b\u4ef6\u68c0\u6d4b\u6a21\u578b\u56e0\u5355\u5411\u7ed3\u6784\u53ca\u8bc4\u4ef7\u6307\u6807\u504f\u5dee\u5b58\u5728\u5c40\u9650\uff0c\u63d0\u51fa\u5229\u7528\u53e5\u5b50\u4e0a\u4e0b\u6587\u548cLoRA\u5fae\u8c03\u63d0\u5347\u4e86\u6a21\u578b\u5728\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u4e8b\u4ef6\u68c0\u6d4b\u7814\u7a76\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u4e0d\u8db3\uff1a\u89e3\u7801\u5668\u6a21\u578b\u7684\u5355\u5411\u9650\u5236\u548c\u8fc7\u5ea6\u4f9d\u8d56Micro-F1\u5206\u6570\u8bc4\u4ef7\u6a21\u578b\u6027\u80fd\uff0c\u5ffd\u89c6\u4e86\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u7684\u8868\u73b0\u3002", "method": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165\u53e5\u5b50\u4e0a\u4e0b\u6587\u4fe1\u606f\u589e\u5f3a\u4f20\u7edf\u7684\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5e76\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u91c7\u7528\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u6280\u672f\u6765\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u6a21\u578b\u5728Macro-F1\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u89e3\u7801\u5668\u6a21\u578b\uff0cLoRA\u5fae\u8c03\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u7684\u8bc6\u522b\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u53d1\u73b0\uff0c\u91c7\u7528\u53e5\u5b50\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684\u6a21\u578b\u5728\u4e8b\u4ef6\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u7684\u4ec5\u89e3\u7801\u5668\u6a21\u578b\uff0c\u5e76\u4e14\u5fae\u8c03\u65f6\u4f7f\u7528\u4f4e\u79e9\u9002\u914d\uff08LoRA\uff09\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u957f\u5c3e\u4e8b\u4ef6\u7c7b\u522b\u7684Macro-F1\u5206\u6570\u3002"}}
{"id": "2601.13007", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13007", "abs": "https://arxiv.org/abs/2601.13007", "authors": ["Rusheng Pan", "Bingcheng Mao", "Tianyi Ma", "Zhenhua Ling"], "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs", "comment": "to be published in ICASSP 2026", "summary": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.", "AI": {"tldr": "\u63d0\u51faArchAgent\u6846\u67b6\uff0c\u7ed3\u5408\u9759\u6001\u5206\u6790\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u8de8\u4ee3\u7801\u5e93\u7684\u591a\u89c6\u56fe\u4e1a\u52a1\u5bf9\u9f50\u67b6\u6784\u6062\u590d\uff0c\u663e\u8457\u63d0\u5347\u9057\u7559\u8f6f\u4ef6\u67b6\u6784\u91cd\u6784\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u67b6\u6784\u6062\u590d\u53d7\u67b6\u6784\u6f02\u79fb\u3001\u7f3a\u5931\u5173\u7cfb\u53caLLM\u4e0a\u4e0b\u6587\u9650\u5236\u5f71\u54cd\uff0c\u96be\u4ee5\u4ece\u5927\u578b\u9057\u7559\u4ee3\u7801\u5e93\u4e2d\u51c6\u786e\u6062\u590d\u67b6\u6784\u3002", "method": "\u91c7\u7528\u9759\u6001\u5206\u6790\u3001\u9002\u5e94\u6027\u4ee3\u7801\u5206\u5272\u3001\u4ee5\u53ca\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u7efc\u5408\u65b9\u6cd5\uff0c\u7ed3\u5408\u8de8\u4ee3\u7801\u5e93\u6570\u636e\u53ca\u4e0a\u4e0b\u6587\u76f8\u5173\u88c1\u526a\u751f\u6210\u591a\u89c6\u56fe\u4e1a\u52a1\u5bf9\u9f50\u67b6\u6784\u56fe\u3002", "result": "\u5728\u591a\u4e2a\u5927\u578bGitHub\u9879\u76ee\u8bc4\u6d4b\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e0a\u4e0b\u6587\u4f9d\u8d56\u63d0\u5347\u4e86\u67b6\u6784\u751f\u6210\u51c6\u786e\u5ea6\uff0c\u5b9e\u9645\u6848\u4f8b\u8bc1\u660e\u80fd\u6709\u6548\u6062\u590d\u5173\u952e\u4e1a\u52a1\u903b\u8f91\u3002", "conclusion": "ArchAgent\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u9057\u7559\u8f6f\u4ef6\u67b6\u6784\u6062\u590d\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u67b6\u6784\u91cd\u6784\u7684\u51c6\u786e\u6027\u548c\u4e1a\u52a1\u76f8\u5173\u6027\u3002"}}
{"id": "2601.11956", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11956", "abs": "https://arxiv.org/abs/2601.11956", "authors": ["Yuyin Lu", "Ziran Liang", "Yanghui Rao", "Wenqi Fan", "Fu Lee Wang", "Qing Li"], "title": "Double-Calibration: Towards Trustworthy LLMs via Calibrating Knowledge and Reasoning Confidence", "comment": null, "summary": "Trustworthy reasoning in Large Language Models (LLMs) is challenged by their propensity for hallucination. While augmenting LLMs with Knowledge Graphs (KGs) improves factual accuracy, existing KG-augmented methods fail to quantify epistemic uncertainty in both the retrieved evidence and LLMs' reasoning. To bridge this gap, we introduce DoublyCal, a framework built on a novel double-calibration principle. DoublyCal employs a lightweight proxy model to first generate KG evidence alongside a calibrated evidence confidence. This calibrated supporting evidence then guides a black-box LLM, yielding final predictions that are not only more accurate but also well-calibrated, with confidence scores traceable to the uncertainty of the supporting evidence. Experiments on knowledge-intensive benchmarks show that DoublyCal significantly improves both the accuracy and confidence calibration of black-box LLMs with low token cost.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faDoublyCal\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u91cd\u6821\u51c6\u6280\u672f\u6709\u6548\u63d0\u5347KG\u589e\u5f3aLLM\u7684\u63a8\u7406\u51c6\u786e\u6027\u53ca\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u89e3\u51b3\u4e86\u63a8\u7406\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u5f53\u524dKG\u589e\u5f3a\u7684LLM\u63a8\u7406\u65b9\u6cd5\u96be\u4ee5\u91cf\u5316\u68c0\u7d22\u8bc1\u636e\u548c\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u8ba4\u77e5\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u7ed3\u679c\u7f3a\u4e4f\u7f6e\u4fe1\u5ea6\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u53cc\u91cd\u6821\u51c6\u539f\u7406\u7684DoublyCal\u6846\u67b6\uff0c\u5229\u7528\u8f7b\u91cf\u7ea7\u4ee3\u7406\u6a21\u578b\u751f\u6210\u77e5\u8bc6\u56fe\u8c31\u8bc1\u636e\u53ca\u5176\u6821\u51c6\u7f6e\u4fe1\u5ea6\uff0c\u968f\u540e\u5f15\u5bfc\u9ed1\u76d2LLM\u8fdb\u884c\u63a8\u7406\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u4e14\u7f6e\u4fe1\u5ea6\u53ef\u8ffd\u6eaf\u7684\u9884\u6d4b\u3002", "result": "\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDoublyCal\u5728\u63d0\u5347\u9ed1\u76d2LLM\u7684\u51c6\u786e\u7387\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4e14\u4ee3\u4ef7\u4f4e\u5ec9\uff08\u4f4etoken\u6d88\u8017\uff09\u3002", "conclusion": "DoublyCal\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u77e5\u8bc6\u56fe\u8c31\u7684LLM\u63a8\u7406\u7684\u51c6\u786e\u6027\u548c\u7f6e\u4fe1\u5ea6\u6821\u51c6\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002"}}
{"id": "2601.13015", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13015", "abs": "https://arxiv.org/abs/2601.13015", "authors": ["Nowfel Mashnoor", "Mohammad Akyash", "Hadi Kamali", "Kimia Azar"], "title": "MeltRTL: Multi-Expert LLMs with Inference-time Intervention for RTL Code Generation", "comment": null, "summary": "The automated generation of hardware register-transfer level (RTL) code with large language models (LLMs) shows promise, yet current solutions struggle to produce syntactically and functionally correct code for complex digital designs. This paper introduces MeltRTL, a novel framework that integrates multi-expert attention with inference-time intervention (ITI) to significantly improve LLM-based RTL code generation accuracy without retraining the base model. MeltRTL introduces three key innovations: (1) A multi-expert attention architecture that dynamically routes design specifications to specialized expert networks, enabling targeted reasoning across various hardware categories; (2) An inference-time intervention mechanism that employs non-linear probes to detect and correct hardware-specific inaccuracies during generation; and (3) An efficient intervention framework that selectively operates on expert-specific attention heads with minimal computational overhead. We evaluate MeltRTL on the VerilogEval benchmark, achieving 96% synthesizability and 60% functional correctness, compared to the base LLM's 85.3% and 45.3%, respectively. These improvements are obtained entirely at inference time, with only 27% computational overhead and no model fine-tuning, making MeltRTL immediately deployable on existing pre-trained LLMs. Ablation studies further show the complementary benefits of multi-expert architecture and ITI, highlighting their synergistic effects when combined.", "AI": {"tldr": "MeltRTL\u5229\u7528\u591a\u4e13\u5bb6\u6ce8\u610f\u529b\u548c\u63a8\u7406\u65f6\u5e72\u9884\u673a\u5236\uff0c\u5728\u4e0d\u5fae\u8c03\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u5927\u5e45\u63d0\u5347\u4e86RTL\u4ee3\u7801\u7684\u5408\u6210\u548c\u529f\u80fd\u6b63\u786e\u7387\uff0c\u6548\u7387\u9ad8\uff0c\u6613\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684RTL\u4ee3\u7801\u751f\u6210\u96be\u4ee5\u540c\u65f6\u4fdd\u8bc1\u8bed\u6cd5\u548c\u529f\u80fd\u7684\u6b63\u786e\u6027\uff0c\u5c24\u5176\u9762\u5bf9\u590d\u6742\u6570\u5b57\u8bbe\u8ba1\u65f6\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86\u591a\u4e13\u5bb6\u6ce8\u610f\u529b\u67b6\u6784\u548c\u63a8\u7406\u65f6\u5e72\u9884\uff08ITI\uff09\u673a\u5236\uff0c\u52a8\u6001\u5206\u914d\u8bbe\u8ba1\u89c4\u8303\u81f3\u4e13\u95e8\u4e13\u5bb6\u7f51\u7edc\uff0c\u5e76\u4f7f\u7528\u975e\u7ebf\u6027\u63a2\u6d4b\u5668\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u7ea0\u6b63\u786c\u4ef6\u7279\u5b9a\u9519\u8bef\uff0c\u4e14\u4ec5\u5bf9\u4e13\u5bb6\u6ce8\u610f\u529b\u5934\u8fdb\u884c\u4f4e\u5f00\u9500\u5e72\u9884\u3002", "result": "\u5728VerilogEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMeltRTL\u8fbe\u523096%\u53ef\u7efc\u5408\u7387\u548c60%\u529f\u80fd\u6b63\u786e\u7387\uff0c\u4f18\u4e8e\u539f\u59cb\u6a21\u578b\u768485.3%\u548c45.3%\uff0c\u4e14\u63a8\u7406\u65f6\u5f00\u9500\u4ec5\u589e\u52a027%\u3002", "conclusion": "MeltRTL\u6846\u67b6\u901a\u8fc7\u591a\u4e13\u5bb6\u6ce8\u610f\u529b\u673a\u5236\u548c\u63a8\u7406\u65f6\u5e72\u9884\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684RTL\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u5408\u6210\u7387\u548c\u529f\u80fd\u6b63\u786e\u7387\uff0c\u5e76\u4e14\u4e0d\u9700\u6a21\u578b\u5fae\u8c03\u5373\u53ef\u90e8\u7f72\u3002"}}
{"id": "2601.11957", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11957", "abs": "https://arxiv.org/abs/2601.11957", "authors": ["Bingxuan Li", "Jeonghwan Kim", "Cheng Qian", "Xiusi Chen", "Eitan Anzenberg", "Niran Kundapur", "Heng Ji"], "title": "PEARL: Self-Evolving Assistant for Time Management with Reinforcement Learning", "comment": null, "summary": "Overlapping calendar invitations force busy professionals to repeatedly decide which meetings to attend, reschedule, or decline. We refer to this preference-driven decision process as calendar conflict resolution. Automating such process is crucial yet challenging. Scheduling logistics drain hours, and human delegation often fails at scale, which motivate we to ask: Can we trust large language model (LLM) or language agent to manager time? To enable systematic study of this question, we introduce CalConflictBench, a benchmark for long-horizon calendar conflict resolution. Conflicts are presented sequentially and agents receive feedback after each round, requiring them to infer and adapt to user preferences progressively. Our experiments show that current LLM agents perform poorly with high error rates, e.g., Qwen-3-30B-Think has 35% average error rate. To address this gap, we propose PEARL, a reinforcement-learning framework that augments language agent with an external memory module and optimized round-wise reward design, enabling agent to progressively infer and adapt to user preferences on-the-fly. Experiments on CalConflictBench shows that PEARL achieves 0.76 error reduction rate, and 55% improvement in average error rate compared to the strongest baseline.", "AI": {"tldr": "\u8be5\u5de5\u4f5c\u63d0\u51fa\u4e86CalConflictBench\u65e5\u7a0b\u51b2\u7a81\u89e3\u51b3\u57fa\u51c6\uff0c\u53d1\u73b0\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u8fdb\u800c\u63d0\u51faPEARL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5927\u5e45\u63d0\u5347\u6a21\u578b\u5904\u7406\u65e5\u7a0b\u51b2\u7a81\u7684\u80fd\u529b\u3002", "motivation": "\u7e41\u5fd9\u4e13\u4e1a\u4eba\u58eb\u5728\u65e5\u7a0b\u51b2\u7a81\u65f6\u9700\u8981\u9891\u7e41\u51b3\u7b56\u53c2\u52a0\u3001\u8c03\u6574\u6216\u62d2\u7edd\u4f1a\u8bae\uff0c\u4eba\u5de5\u8c03\u5ea6\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\uff0c\u63a2\u7a76\u662f\u5426\u53ef\u4ee5\u4fe1\u4efb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u7ba1\u7406\u65f6\u95f4\u3002", "method": "\u63d0\u51faPEARL\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408\u5916\u90e8\u8bb0\u5fc6\u6a21\u5757\u548c\u5706\u6b21\u5956\u52b1\u8bbe\u8ba1\uff0c\u9010\u6b65\u63a8\u65ad\u4e0e\u9002\u5e94\u7528\u6237\u504f\u597d\uff0c\u4ece\u800c\u63d0\u9ad8\u65e5\u7a0b\u51b2\u7a81\u89e3\u51b3\u7684\u51c6\u786e\u6027\u3002", "result": "\u5728CalConflictBench\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cPEARL\u76f8\u8f83\u6700\u5f3a\u57fa\u7ebf\u6a21\u578b\u9519\u8bef\u7387\u964d\u4f4e\u4e8655%\uff0c\u9519\u8bef\u51cf\u5c11\u7387\u8fbe0.76\uff0c\u8868\u73b0\u5927\u5e45\u63d0\u5347\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u65e5\u7a0b\u51b2\u7a81\u89e3\u51b3\u4efb\u52a1\u4e2d\u8868\u73b0\u6b20\u4f73\uff0c\u5b58\u5728\u8f83\u9ad8\u9519\u8bef\u7387\u3002\u901a\u8fc7\u5f15\u5165\u5f3a\u5316\u5b66\u4e60\u6846\u67b6PEARL\uff0c\u7ed3\u5408\u5916\u90e8\u8bb0\u5fc6\u6a21\u5757\u548c\u8f6e\u6b21\u5956\u52b1\u4f18\u5316\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u6a21\u578b\u63a8\u65ad\u548c\u9002\u5e94\u7528\u6237\u504f\u597d\u7684\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u9519\u8bef\u7387\u3002"}}
{"id": "2601.13097", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13097", "abs": "https://arxiv.org/abs/2601.13097", "authors": ["Elena Bruches", "Daniil Grebenkin", "Mikhail Klementev", "Vadim Alperovich", "Roman Derunets", "Dari Baturova", "Georgy Mkrtchyan", "Oleg Sedukhin", "Ivan Bondarenko", "Nikolay Bushkov", "Stanislav Moiseev"], "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation", "comment": "This paper has been accepted for publication at the 33rd IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER 2026)", "summary": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.", "AI": {"tldr": "RM-RF\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u8fd0\u884c\u6d4b\u8bd5\u5373\u53ef\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u7684\u6a21\u578b\uff0c\u663e\u8457\u964d\u4f4e\u8bc4\u4f30\u6210\u672c\u5e76\u4fdd\u6301\u8f83\u597d\u51c6\u786e\u7387\uff0c\u9002\u5408\u5927\u89c4\u6a21\u6d4b\u8bd5\u81ea\u52a8\u5316\u3002", "motivation": "\u4f20\u7edf\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7684\u8bc4\u4f30\u9700\u8981\u53cd\u590d\u7f16\u8bd1\u548c\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5b58\u5728\u9ad8\u5ef6\u8fdf\u548c\u9ad8\u57fa\u7840\u8bbe\u65bd\u6210\u672c\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u65e0\u9700\u8fd0\u884c\u5373\u53ef\u5feb\u901f\u8bc4\u4f30\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u591a\u8bed\u8a00\uff08Java\u3001Python\u3001Go\uff09\u6587\u4ef6\u548c\u6d4b\u8bd5\u4ee3\u7801\uff0c\u6784\u5efa\u57fa\u4e8e\u6267\u884c\u7ed3\u679c\u6807\u7b7e\u7684\u6570\u636e\u96c6\uff0c\u8bad\u7ec3\u6a21\u578b\u9884\u6d4b\u4e09\u79cd\u57fa\u4e8e\u6267\u884c\u7684\u4fe1\u53f7\uff0c\u6d4b\u8bd5\u591a\u79cd\u6a21\u578b\u548c\u8c03\u4f18\u65b9\u6cd5\uff0c\u8fbe\u5230\u8f83\u9ad8\u7684F1\u5206\u6570\u3002", "result": "RM-RF\u5728\u4e09\u9879\u6307\u6807\u4e0a\u5e73\u5747F1\u8fbe\u52300.69\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5ef6\u8fdf\u548c\u57fa\u7840\u8bbe\u65bd\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u9002\u5408\u5927\u89c4\u6a21\u6d4b\u8bd5\u751f\u6210\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4ee3\u7801\u4f18\u5316\u3002", "conclusion": "RM-RF\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u5956\u52b1\u6a21\u578b\uff0c\u80fd\u591f\u65e0\u9700\u8fd0\u884c\u6d4b\u8bd5\u5373\u53ef\u6709\u6548\u8bc4\u4f30\u81ea\u52a8\u751f\u6210\u7684\u5355\u5143\u6d4b\u8bd5\uff0c\u9884\u6d4b\u6d4b\u8bd5\u4ee3\u7801\u7684\u7f16\u8bd1\u8fd0\u884c\u72b6\u6001\u3001\u4ee3\u7801\u8986\u76d6\u7387\u63d0\u5347\u548c\u53d8\u5f02\u6740\u6b7b\u7387\u63d0\u5347\uff0c\u8868\u73b0\u51fa\u8f83\u597d\u7684\u9884\u6d4b\u51c6\u786e\u6027\u548c\u8f83\u4f4e\u7684\u5ef6\u8fdf\u53ca\u8d44\u6e90\u6d88\u8017\u3002"}}
{"id": "2601.11969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.11969", "abs": "https://arxiv.org/abs/2601.11969", "authors": ["Zecheng Tang", "Baibei Ji", "Ruoxi Sun", "Haitian Wang", "WangJie You", "Zhang Yijun", "Wenpeng Zhu", "Ji Qi", "Juntao Li", "Min Zhang"], "title": "$\\texttt{MemoryRewardBench}$: Benchmarking Reward Models for Long-Term Memory Management in Large Language Models", "comment": null, "summary": "Existing works increasingly adopt memory-centric mechanisms to process long contexts in a segment manner, and effective memory management is one of the key capabilities that enables large language models to effectively propagate information across the entire sequence. Therefore, leveraging reward models (RMs) to automatically and reliably evaluate memory quality is critical. In this work, we introduce $\\texttt{MemoryRewardBench}$, the first benchmark to systematically study the ability of RMs to evaluate long-term memory management processes. $\\texttt{MemoryRewardBench}$ covers both long-context comprehension and long-form generation tasks, featuring 10 distinct settings with different memory management patterns, with context length ranging from 8K to 128K tokens. Evaluations on 13 cutting-edge RMs indicate a diminishing performance gap between open-source and proprietary models, with newer-generation models consistently outperforming their predecessors regardless of parameter count. We further expose the capabilities and fundamental limitations of current RMs in evaluating LLM memory management across diverse settings.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u7cfb\u7edf\u6027\u8bc4\u6d4b\u5956\u52b1\u6a21\u578b\u8bc4\u4f30\u957f\u671f\u8bb0\u5fc6\u7ba1\u7406\u80fd\u529b\u7684\u57fa\u51c6MemoryRewardBench\uff0c\u6db5\u76d6\u591a\u79cd\u4efb\u52a1\u548c\u8d85\u957f\u4e0a\u4e0b\u6587\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u8868\u73b0\u53ca\u4e0d\u8db3\u3002", "motivation": "\u6709\u6548\u7684\u957f\u671f\u8bb0\u5fc6\u7ba1\u7406\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u81f3\u5173\u91cd\u8981\uff0c\u800c\u9700\u8981\u4f7f\u7528\u5956\u52b1\u6a21\u578b\u6765\u81ea\u52a8\u4e14\u53ef\u9760\u5730\u8bc4\u4f30\u8bb0\u5fc6\u8d28\u91cf\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86MemoryRewardBench\u57fa\u51c6\uff0c\u5305\u542b10\u79cd\u4e0d\u540c\u5185\u5b58\u7ba1\u7406\u6a21\u5f0f\u548c8K\u5230128K\u4ee4\u724c\u957f\u5ea6\u7684\u957f\u671f\u4e0a\u4e0b\u6587\u7406\u89e3\u53ca\u751f\u6210\u4efb\u52a1\uff0c\u8bc4\u4f30\u4e8613\u4e2a\u5148\u8fdb\u5956\u52b1\u6a21\u578b\u7684\u8bb0\u5fc6\u7ba1\u7406\u8868\u73b0\u3002", "result": "\u8bc4\u6d4b\u663e\u793a\u5f00\u6e90\u6a21\u578b\u4e0e\u4e13\u6709\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u6b63\u5728\u7f29\u5c0f\uff0c\u65b0\u4e00\u4ee3\u6a21\u578b\u4e0d\u8bba\u53c2\u6570\u5927\u5c0f\u5747\u4f18\u4e8e\u524d\u4ee3\u6a21\u578b\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u73b0\u6709\u5956\u52b1\u6a21\u578b\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u8bb0\u5fc6\u7ba1\u7406\u7684\u80fd\u529b\u4e0e\u9650\u5236\u3002", "conclusion": "\u5f53\u524d\u7684\u5956\u52b1\u6a21\u578b\u5728\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u957f\u671f\u8bb0\u5fc6\u7ba1\u7406\u65b9\u9762\u8868\u73b0\u51fa\u4e00\u5b9a\u80fd\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u57fa\u672c\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u5185\u5b58\u7ba1\u7406\u6a21\u5f0f\u548c\u8d85\u957f\u4e0a\u4e0b\u6587\u4e0b\u3002"}}
{"id": "2601.13118", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13118", "abs": "https://arxiv.org/abs/2601.13118", "authors": ["Alessandro Midolo", "Alessandro Giagnorio", "Fiorella Zampetti", "Rosalia Tufano", "Gabriele Bavota", "Massimiliano Di Penta"], "title": "Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization", "comment": null, "summary": "Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u81ea\u52a8\u5316\u548c\u6d4b\u8bd5\u9a71\u52a8\u65b9\u6cd5\uff0c\u5f52\u7eb3\u51fa10\u6761\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u63d0\u793a\u8bcd\u7684\u4f18\u5316\u6307\u5bfc\u539f\u5219\uff0c\u5e76\u901a\u8fc7\u5f00\u53d1\u8005\u5b9e\u8bc1\u9a8c\u8bc1\u5176\u6709\u6548\u6027\uff0c\u4e3a\u63d0\u5347\u9762\u5411\u8f6f\u4ef6\u5f00\u53d1\u7684\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u8bcd\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5b9e\u7528\u53c2\u8003\u3002", "motivation": "\u5c3d\u7ba1\u63d0\u793a\u8bcd\u5de5\u7a0b\u5df2\u88ab\u8bc1\u660e\u80fd\u63d0\u5347\u4ee3\u7801\u751f\u6210\u6548\u679c\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u7684\u5177\u4f53\u63d0\u793a\u8bcd\u7f16\u5199\u6307\u5bfc\uff0c\u5bfc\u81f4\u5f00\u53d1\u8005\u96be\u4ee5\u9ad8\u6548\u7f16\u5199\u5408\u9002\u7684\u63d0\u793a\u8bcd\u3002", "method": "\u91c7\u7528\u8fed\u4ee3\u3001\u6d4b\u8bd5\u9a71\u52a8\u7684\u65b9\u6cd5\u81ea\u52a8\u4f18\u5316\u4ee3\u7801\u751f\u6210\u63d0\u793a\u8bcd\uff0c\u901a\u8fc7\u5206\u6790\u6d4b\u8bd5\u7ed3\u679c\u63d0\u70bc\u51fa\u6539\u8fdb\u63d0\u793a\u8bcd\u7684\u5173\u952e\u8981\u7d20\uff0c\u6700\u7ec8\u603b\u7ed3\u6210\u5177\u4f53\u6307\u5bfc\u539f\u5219\uff0c\u5e76\u901a\u8fc750\u540d\u5f00\u53d1\u8005\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "result": "\u63d0\u70bc\u51fa10\u6761\u4e0e\u8f93\u5165\u8f93\u51fa\u3001\u524d\u540e\u7f6e\u6761\u4ef6\u3001\u793a\u4f8b\u63d0\u4f9b\u3001\u7ec6\u8282\u4e30\u5bcc\u53ca\u6b67\u4e49\u6f84\u6e05\u76f8\u5173\u7684\u63d0\u793a\u8bcd\u4f18\u5316\u6307\u5bfc\uff0c\u4e0e\u5b9e\u9645\u4f7f\u7528\u884c\u4e3a\u8fdb\u884c\u6bd4\u5bf9\uff0c\u53d1\u73b0\u5f00\u53d1\u8005\u5728\u4e86\u89e3\u8fd9\u4e9b\u6307\u5bfc\u524d\u540e\u4f7f\u7528\u548c\u611f\u77e5\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e8610\u6761\u9488\u5bf9\u4ee3\u7801\u751f\u6210\u63d0\u793a\u8bcd\u4f18\u5316\u7684\u5177\u4f53\u6307\u5bfc\u539f\u5219\uff0c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6307\u5bfc\u539f\u5219\u5728\u5b9e\u9645\u5f00\u53d1\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.12019", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12019", "abs": "https://arxiv.org/abs/2601.12019", "authors": ["Chaowei Zhang", "Xiansheng Luo", "Zewei Zhang", "Yi Zhu", "Jipeng Qiang", "Longwei Wang"], "title": "Acting Flatterers via LLMs Sycophancy: Combating Clickbait with LLMs Opposing-Stance Reasoning", "comment": null, "summary": "The widespread proliferation of online content has intensified concerns about clickbait, deceptive or exaggerated headlines designed to attract attention. While Large Language Models (LLMs) offer a promising avenue for addressing this issue, their effectiveness is often hindered by Sycophancy, a tendency to produce reasoning that matches users' beliefs over truthful ones, which deviates from instruction-following principles. Rather than treating sycophancy as a flaw to be eliminated, this work proposes a novel approach that initially harnesses this behavior to generate contrastive reasoning from opposing perspectives. Specifically, we design a Self-renewal Opposing-stance Reasoning Generation (SORG) framework that prompts LLMs to produce high-quality agree and disagree reasoning pairs for a given news title without requiring ground-truth labels. To utilize the generated reasoning, we develop a local Opposing Reasoning-based Clickbait Detection (ORCD) model that integrates three BERT encoders to represent the title and its associated reasoning. The model leverages contrastive learning, guided by soft labels derived from LLM-generated credibility scores, to enhance detection robustness. Experimental evaluations on three benchmark datasets demonstrate that our method consistently outperforms LLM prompting, fine-tuned smaller language models, and state-of-the-art clickbait detection baselines.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5949\u627f\u6027\u504f\u5dee\u751f\u6210\u5bf9\u7acb\u63a8\u7406\u5bf9\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u4f18\u7684\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u9762\u5bf9\u70b9\u51fb\u8bf1\u9975\u6807\u9898\u666e\u904d\u5b58\u5728\u95ee\u9898\uff0c\u4e14\u5927\u8bed\u8a00\u6a21\u578b\u53d7\u5230\u5949\u627f\u6027\u504f\u5dee\u5f71\u54cd\uff0c\u63d0\u51fa\u5229\u7528\u8fd9\u79cd\u504f\u5dee\u751f\u6210\u5bf9\u7acb\u89c2\u70b9\u63a8\u7406\u4ee5\u63d0\u5347\u68c0\u6d4b\u6548\u679c\u3002", "method": "\u8bbe\u8ba1\u4e86SORG\u6846\u67b6\u7528\u4e8e\u751f\u6210\u652f\u6301\u548c\u53cd\u5bf9\u7684\u63a8\u7406\u5bf9\uff0c\u5e76\u57fa\u4e8e\u4e09\u4e2aBERT\u7f16\u7801\u5668\u6784\u5efaORCD\u6a21\u578b\u7ed3\u5408\u5bf9\u6bd4\u5b66\u4e60\u548c\u8f6f\u6807\u7b7e\u8fdb\u884c\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u68c0\u6d4b\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\u65b9\u9762\u5747\u8d85\u8fc7\u4e86\u73b0\u6709\u7684LLM\u63d0\u793a\u3001\u5fae\u8c03\u6a21\u578b\u53ca\u6700\u5148\u8fdb\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u7684SORG\u6846\u67b6\u548cORCD\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u70b9\u51fb\u8bf1\u9975\u68c0\u6d4b\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528\u5bf9\u7acb\u89c2\u70b9\u63a8\u7406\u751f\u6210\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.13134", "categories": ["cs.SE", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13134", "abs": "https://arxiv.org/abs/2601.13134", "authors": ["Heng Fang", "Adam J. Stewart", "Isaac Corley", "Xiao Xiang Zhu", "Hossein Azizpour"], "title": "Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access", "comment": null, "summary": "Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical \"frozen\" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.", "AI": {"tldr": "\u9488\u5bf9\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u5d4c\u5165\u4ea7\u54c1\u788e\u7247\u5316\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u7edf\u4e00\u5206\u7c7b\u4e0e\u63a5\u53e3\u6807\u51c6\uff0c\u6269\u5c55\u5de5\u5177\u5b9e\u73b0\u4e86\u6570\u636e\u4e92\u64cd\u4f5c\u6027\uff0c\u63d0\u5347\u5e94\u7528\u4fbf\u5229\u6027\u548c\u91cd\u73b0\u6027\u3002", "motivation": "\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u9ad8\u8ba1\u7b97\u6210\u672c\u9650\u5236\u4e86\u5176\u5e7f\u6cdb\u5e94\u7528\uff0c\u5d4c\u5165\u5f0f\u6570\u636e\u4ea7\u54c1\u683c\u5f0f\u548c\u5206\u8fa8\u7387\u4e0d\u7edf\u4e00\uff0c\u5bfc\u81f4\u5de5\u7a0b\u74f6\u9888\u548c\u6a21\u578b\u6bd4\u8f83\u56f0\u96be\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e00\u4e2a\u5305\u542b\u6570\u636e\u3001\u5de5\u5177\u3001\u4ef7\u503c\u4e09\u5c42\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u901a\u8fc7\u6269\u5c55TorchGeo\uff0c\u8bbe\u8ba1\u7edf\u4e00API\u5b9e\u73b0\u5bf9\u4e0d\u540c\u5d4c\u5165\u4ea7\u54c1\u7684\u6807\u51c6\u5316\u52a0\u8f7d\u4e0e\u67e5\u8be2\u3002", "result": "\u5b9e\u73b0\u4e86\u5c06\u5d4c\u5165\u5411\u91cf\u89c6\u4e3a\u7a7a\u95f4\u6570\u636e\u96c6\uff0c\u89e3\u8026\u4e0b\u6e38\u5206\u6790\u4e0e\u6a21\u578b\u5de5\u7a0b\uff0c\u63a8\u52a8\u4e86\u5730\u7406\u7a7a\u95f4\u5d4c\u5165\u6570\u636e\u7684\u4e92\u64cd\u4f5c\u6027\u548c\u91cd\u73b0\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u901a\u8fc7\u7edf\u4e00\u6570\u636e\u683c\u5f0f\u548c\u63a5\u53e3\uff0c\u6253\u7834\u788e\u7247\u5316\u751f\u6001\uff0c\u63d0\u5347\u4e86\u5730\u7406\u7a7a\u95f4\u57fa\u7840\u6a21\u578b\u7684\u5e94\u7528\u6548\u7387\u548c\u900f\u660e\u5ea6\uff0c\u4e3a\u5730\u7403\u89c2\u6d4b\u5de5\u4f5c\u6d41\u63d0\u4f9b\u4e86\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.12033", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12033", "abs": "https://arxiv.org/abs/2601.12033", "authors": ["Muhammad Alif Al Hakim", "Alfan Farizki Wicaksono", "Fajri Koto"], "title": "Preserving Fairness and Safety in Quantized LLMs Through Critical Weight Protection", "comment": null, "summary": "Quantization is widely adopted to reduce the computational cost of large language models (LLMs); however, its implications for fairness and safety, particularly in dynamic quantization and multilingual contexts, remain underexplored. In this work, we conduct a systematic study of how static and dynamic quantization methods impact fairness and safety across benchmarks measuring intrinsic and extrinsic bias and safety alignment. For fairness, we evaluate English, French, Dutch, Spanish, and Turkish; for safety, we focus on English, Korean, and Arabic. Our findings reveal that quantization consistently degrades fairness and safety, with dynamic methods demonstrating greater stability than static ones. Moreover, fairness degradation varies across languages, while safety deterioration is especially pronounced in non-English settings. To address these risks, we introduce Critical Weight Protection, a novel technique that identifies and preserves fairness- and safety-critical weights during quantization. This approach effectively mitigates bias and safety deterioration without costly retraining or alignment, maintaining trustworthiness while retaining efficiency.", "AI": {"tldr": "\u672c\u7814\u7a76\u7cfb\u7edf\u5206\u6790\u4e86\u91cf\u5316\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u91cf\u5316\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\uff0c\u63d0\u51fa\u5173\u952e\u6743\u91cd\u4fdd\u62a4\u6280\u672f\u4ee5\u51cf\u8f7b\u98ce\u9669\uff0c\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u4fe1\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u867d\u7136\u91cf\u5316\u5728\u964d\u4f4e\u5927\u8bed\u8a00\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u65b9\u9762\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5bf9\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\u7684\u5f71\u54cd\uff0c\u5c24\u5176\u662f\u5728\u52a8\u6001\u91cf\u5316\u548c\u591a\u8bed\u8a00\u73af\u5883\u4e2d\uff0c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u6bd4\u8f83\u4e86\u9759\u6001\u91cf\u5316\u548c\u52a8\u6001\u91cf\u5316\u65b9\u6cd5\u5728\u591a\u8bed\u8a00\u3001\u591a\u4efb\u52a1\uff08\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff09\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u5173\u952e\u6743\u91cd\u4fdd\u62a4\u6280\u672f\u6765\u4fdd\u62a4\u91cd\u8981\u6743\u91cd\uff0c\u907f\u514d\u91cf\u5316\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u3002", "result": "\u91cf\u5316\u635f\u5bb3\u4e86\u6a21\u578b\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff0c\u52a8\u6001\u91cf\u5316\u6bd4\u9759\u6001\u91cf\u5316\u66f4\u7a33\u5b9a\uff0c\u4e0d\u540c\u8bed\u8a00\u7684\u516c\u5e73\u6027\u8868\u73b0\u5b58\u5728\u5dee\u5f02\uff0c\u975e\u82f1\u8bed\u8bed\u8a00\u7684\u5b89\u5168\u6027\u4e0b\u964d\u66f4\u4e25\u91cd\u3002\u5173\u952e\u6743\u91cd\u4fdd\u62a4\u6280\u672f\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u95ee\u9898\uff0c\u65e0\u9700\u6602\u8d35\u7684\u518d\u8bad\u7ec3\u6216\u5bf9\u9f50\u3002", "conclusion": "\u91cf\u5316\u666e\u904d\u964d\u4f4e\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u516c\u5e73\u6027\u548c\u5b89\u5168\u6027\uff0c\u52a8\u6001\u91cf\u5316\u5728\u7a33\u5b9a\u6027\u65b9\u9762\u4f18\u4e8e\u9759\u6001\u91cf\u5316\uff0c\u4e0d\u540c\u8bed\u8a00\u7684\u516c\u5e73\u6027\u53d7\u635f\u60c5\u51b5\u4e0d\u540c\uff0c\u975e\u82f1\u8bed\u73af\u5883\u4e0b\u7684\u5b89\u5168\u6027\u4e0b\u964d\u66f4\u4e3a\u7a81\u51fa\u3002\u901a\u8fc7\u5f15\u5165\u5173\u952e\u6743\u91cd\u4fdd\u62a4\u6280\u672f\uff0c\u53ef\u4ee5\u6709\u6548\u7f13\u89e3\u8fd9\u4e9b\u8d1f\u9762\u5f71\u54cd\uff0c\u4fdd\u6301\u6a21\u578b\u7684\u53ef\u4fe1\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2601.13139", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13139", "abs": "https://arxiv.org/abs/2601.13139", "authors": ["Alessandro Midolo", "Emiliano Tramontana", "Massimiliano Di Penta"], "title": "From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability", "comment": null, "summary": "Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\u8bc4\u4f30\u4e86GPT-4o\u9a71\u52a8\u7684Python\u7c7b\u91cd\u6784\uff0c\u53d1\u73b0\u5176\u5728\u4fdd\u8bc1\u884c\u4e3a\u4e0d\u53d8\u524d\u63d0\u4e0b\u63d0\u5347\u4e86\u4ee3\u7801\u8d28\u91cf\uff0c\u4f46\u727a\u7272\u4e86\u90e8\u5206\u53ef\u8bfb\u6027\uff0c\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u5316\u91cd\u6784\u4e2d\u7684\u6f5c\u529b\u4e0e\u5c40\u9650\u3002", "motivation": "\u5c3d\u7ba1\u81ea\u52a8\u5316\u91cd\u6784\u5de5\u5177\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5b9e\u7528\u6027\u4ecd\u6709\u9650\uff1b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u91cd\u6784\u4e2d\u5c55\u73b0\u65b0\u673a\u9047\uff0c\u4f46\u5176\u5bf9\u4ee3\u7801\u8d28\u91cf\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u57fa\u4e8eGPT-4o\u5bf9ClassEval\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684100\u4e2aPython\u7c7b\u8fdb\u884c\u591a\u79cd\u7c7b\u7ea7\u91cd\u6784\uff0c\u7ed3\u5408Fowler\u91cd\u6784\u76ee\u5f55\u8fdb\u884c\uff0c\u4f7f\u7528\u5355\u5143\u6d4b\u8bd5\u9a8c\u8bc1\u884c\u4e3a\u6b63\u786e\u6027\uff0c\u91c7\u7528Pylint\u3001Flake8\u548cSonarCloud\u8bc4\u4f30\u4ee3\u7801\u8d28\u91cf\uff0c\u5229\u7528\u5148\u8fdb\u7684\u53ef\u8bfb\u6027\u5de5\u5177\u6d4b\u91cf\u53ef\u8bfb\u6027\u3002", "result": "GPT-4o\u5b9e\u73b0\u4e86\u884c\u4e3a\u4fdd\u7559\u7684\u91cd\u6784\uff0c\u663e\u8457\u964d\u4f4e\u4ee3\u7801\u5f02\u5473\u3001\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u6307\u6807\uff0c\u4f46\u5e26\u6765\u4e86\u4ee3\u7801\u53ef\u8bfb\u6027\u4e0b\u964d\u7684\u526f\u4f5c\u7528\u3002", "conclusion": "GPT-4o\u9a71\u52a8\u7684\u91cd\u6784\u901a\u5e38\u80fd\u591f\u4fdd\u6301\u7a0b\u5e8f\u884c\u4e3a\u4e0d\u53d8\uff0c\u540c\u65f6\u51cf\u5c11\u4ee3\u7801\u5f02\u5473\u5e76\u63d0\u5347\u4ee3\u7801\u8d28\u91cf\u6307\u6807\uff0c\u4f46\u53ef\u8bfb\u6027\u6709\u6240\u4e0b\u964d\u3002"}}
{"id": "2601.12034", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12034", "abs": "https://arxiv.org/abs/2601.12034", "authors": ["Ziyi Zhao", "Chongming Gao", "Yang Zhang", "Haoyan Liu", "Weinan Gan", "Huifeng Guo", "Yong Liu", "Fuli Feng"], "title": "Don't Start Over: A Cost-Effective Framework for Migrating Personalized Prompts Between LLMs", "comment": "Accepted to AAAI 2026 (Oral). 9 pages, 5 figures", "summary": "Personalization in Large Language Models (LLMs) often relies on user-specific soft prompts. However, these prompts become obsolete when the foundation model is upgraded, necessitating costly, full-scale retraining. To overcome this limitation, we propose the Prompt-level User Migration Adapter (PUMA), a lightweight framework to efficiently migrate personalized prompts across incompatible models. PUMA utilizes a parameter-efficient adapter to bridge the semantic gap, combined with a group-based user selection strategy to significantly reduce training costs. Experiments on three large-scale datasets show our method matches or even surpasses the performance of retraining from scratch, reducing computational cost by up to 98%. The framework demonstrates strong generalization across diverse model architectures and robustness in advanced scenarios like chained and aggregated migrations, offering a practical path for the sustainable evolution of personalized AI by decoupling user assets from the underlying models.", "AI": {"tldr": "PUMA\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u9002\u914d\u5668\u6846\u67b6\uff0c\u53ef\u9ad8\u6548\u8fc1\u79fb\u4e2a\u6027\u5316\u63d0\u793a\uff0c\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u73b0\u6a21\u578b\u5347\u7ea7\u65f6\u7684\u4e2a\u6027\u5316\u6301\u7eed\u6027\u3002", "motivation": "\u89e3\u51b3\u4e2a\u6027\u5316\u8f6f\u63d0\u793a\u5728\u57fa\u7840\u6a21\u578b\u5347\u7ea7\u540e\u5931\u6548\uff0c\u9700\u8981\u4ee3\u4ef7\u9ad8\u6602\u7684\u5168\u9762\u91cd\u65b0\u8bad\u7ec3\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u7684\u9002\u914d\u5668\u67b6\u6784\u5f25\u5408\u8bed\u4e49\u5dee\u8ddd\uff0c\u7ed3\u5408\u57fa\u4e8e\u7528\u6237\u7ec4\u7684\u9009\u62e9\u7b56\u7565\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u3002", "result": "\u5728\u4e09\u4e2a\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\uff0cPUMA\u65b9\u6cd5\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\uff0c\u5c06\u8ba1\u7b97\u6210\u672c\u964d\u4f4e\u4e86\u6700\u591a98%\uff0c\u4e14\u9002\u7528\u4e8e\u591a\u79cd\u6a21\u578b\u67b6\u6784\u548c\u590d\u6742\u8fc1\u79fb\u573a\u666f\u3002", "conclusion": "\u63d0\u51fa\u7684PUMA\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u5730\u8fc1\u79fb\u4e2a\u6027\u5316\u8f6f\u63d0\u793a\uff0c\u663e\u8457\u964d\u4f4e\u91cd\u65b0\u8bad\u7ec3\u6210\u672c\uff0c\u5e76\u4fdd\u6301\u6216\u8d85\u8d8a\u4ece\u5934\u8bad\u7ec3\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13240", "categories": ["cs.SE", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13240", "abs": "https://arxiv.org/abs/2601.13240", "authors": ["Xue Jiang", "Jiaru Qian", "Xianjie Shi", "Chenjie Li", "Hao Zhu", "Ziyu Wang", "Jielun Zhang", "Zheyu Zhao", "Kechi Zhang", "Jia Li", "Wenpin Jiao", "Zhi Jin", "Ge Li", "Yihong Dong"], "title": "KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?", "comment": null, "summary": "Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.", "AI": {"tldr": "KOCO-BENCH\u662f\u4e00\u4e2a\u9488\u5bf9\u9886\u57df\u4e13\u7528\u4ee3\u7801\u5f00\u53d1\u7684\u5168\u65b0\u8bc4\u6d4b\u57fa\u51c6\uff0c\u5305\u542b\u4e30\u5bcc\u77e5\u8bc6\u5e93\u548c\u591a\u5c42\u6b21\u4efb\u52a1\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ca\u5176\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u5728\u8be5\u57fa\u51c6\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u63a8\u52a8\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u7814\u7a76\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u901a\u7528\u7f16\u7a0b\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u9886\u57df\u4e13\u7528\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u6548\u679c\u6709\u9650\uff0c\u4e14\u73b0\u6709\u57fa\u51c6\u4ec5\u8bc4\u4f30\u77e5\u8bc6\u62e5\u6709\u60c5\u51b5\uff0c\u7f3a\u4e4f\u8bc4\u4f30\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u5982\u4f55\u83b7\u53d6\u5e76\u5e94\u7528\u65b0\u77e5\u8bc6\u7684\u5de5\u5177\u3002", "method": "\u6784\u5efa\u4e86KOCO-BENCH\u57fa\u51c6\uff0c\u5305\u542b6\u4e2a\u65b0\u5174\u9886\u57df\uff0c11\u4e2a\u8f6f\u4ef6\u6846\u67b6\uff0c25\u4e2a\u9879\u76ee\uff0c\u9644\u5e26\u77e5\u8bc6\u8bed\u6599\u5e93\u548c\u591a\u7c92\u5ea6\u8bc4\u6d4b\u4efb\u52a1\uff08\u4ee3\u7801\u751f\u6210\u548c\u77e5\u8bc6\u7406\u89e3\uff09\uff0c\u901a\u8fc7\u5fc5\u987b\u83b7\u53d6\u548c\u5e94\u7528\u9886\u57df\u77e5\u8bc6\u6765\u5b8c\u6210\u8bc4\u6d4b\u4efb\u52a1\u3002", "result": "\u5728KOCO-BENCH\u8bc4\u6d4b\u4e2d\uff0c\u5f53\u524d\u6700\u5148\u8fdb\u7684\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u63d0\u5347\u6709\u9650\uff0c\u6700\u4f73\u6a21\u578bClaude Code\u4ec5\u8fbe\u523034.2%\u51c6\u786e\u7387\uff0c\u8868\u660eKOCO-BENCH\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u73b0\u6709\u9886\u57df\u4e13\u7528\u4ee3\u7801\u57fa\u51c6\u65e0\u6cd5\u6709\u6548\u8bc4\u4f30\u9886\u57df\u4e13\u7528\u65b9\u6cd5\uff0cKOCO-BENCH\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\uff0c\u76ee\u524d\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u9886\u57df\u4e13\u7528\u65b9\u6cd5\u5728\u8be5\u57fa\u51c6\u4e0a\u8868\u73b0\u4ecd\u4e0d\u7406\u60f3\uff0c\u4e9f\u9700\u66f4\u6709\u6548\u7684\u9886\u57df\u4e13\u7528\u6280\u672f\u3002"}}
{"id": "2601.12061", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12061", "abs": "https://arxiv.org/abs/2601.12061", "authors": ["Jinsook Lee", "Kirk Vanacore", "Zhuqian Zhou", "Jeanine Grutter", "Rene F. Kizilcec"], "title": "Codebook-Injected Dialogue Segmentation for Multi-Utterance Constructs Annotation: LLM-Assisted and Gold-Label-Free Evaluation", "comment": "Under Review for ACL 2026", "summary": "Dialogue Act (DA) annotation typically treats communicative or pedagogical intent as localized to individual utterances or turns. This leads annotators to agree on the underlying action while disagreeing on segment boundaries, reducing apparent reliability. We propose codebook-injected segmentation, which conditions boundary decisions on downstream annotation criteria, and evaluate LLM-based segmenters against standard and retrieval-augmented baselines. To assess these without gold labels, we introduce evaluation metrics for span consistency, distinctiveness, and human-AI distributional agreement. We found DA-awareness produces segments that are internally more consistent than text-only baselines. While LLMs excel at creating construct-consistent spans, coherence-based baselines remain superior at detecting global shifts in dialogue flow. Across two datasets, no single segmenter dominates. Improvements in within-segment coherence frequently trade off against boundary distinctiveness and human-AI distributional agreement. These results highlight segmentation as a consequential design choice that should be optimized for downstream objectives rather than a single performance score.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u57fa\u4e8e\u6ce8\u91ca\u4ee3\u7801\u6ce8\u5165\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u8bdd\u5206\u6bb5\u65b9\u6cd5\uff0c\u6539\u8fdb\u4e86\u6bb5\u5185\u4e00\u81f4\u6027\uff0c\u63ed\u793a\u4e86\u5206\u6bb5\u8d28\u91cf\u5728\u4e0d\u540c\u6307\u6807\u95f4\u7684\u6743\u8861\uff0c\u5f3a\u8c03\u5e94\u6839\u636e\u4e0b\u6e38\u5e94\u7528\u4f18\u5316\u5bf9\u8bdd\u5206\u6bb5\u3002", "motivation": "\u73b0\u6709\u7684Dialogue Act\u6ce8\u91ca\u5c06\u610f\u56fe\u5c40\u9650\u4e8e\u5355\u53e5\u6216\u5355\u8f6e\u4e2d\uff0c\u5bfc\u81f4\u5206\u6bb5\u8fb9\u754c\u5224\u65ad\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u964d\u4f4e\u4e86\u6ce8\u91ca\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u6ce8\u91ca\u4ee3\u7801\u6ce8\u5165\u5206\u6bb5\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0b\u6e38\u6ce8\u91ca\u6807\u51c6\u6765\u51b3\u5b9a\u8fb9\u754c\uff0c\u5e76\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8fdb\u884c\u5206\u6bb5\uff0c\u6bd4\u5bf9\u4f20\u7edf\u548c\u68c0\u7d22\u589e\u5f3a\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u53d1\u73b0\u57fa\u4e8eDialogue Act\u610f\u8bc6\u7684\u5206\u6bb5\u5728\u5185\u90e8\u4e00\u81f4\u6027\u4e0a\u4f18\u4e8e\u4ec5\u57fa\u4e8e\u6587\u672c\u7684\u57fa\u7ebf\uff1bLLM\u66f4\u64c5\u957f\u751f\u6210\u6784\u9020\u4e00\u81f4\u7684\u6bb5\u843d\uff0c\u57fa\u4e8e\u8fde\u8d2f\u6027\u7684\u57fa\u7ebf\u65b9\u6cd5\u5219\u66f4\u597d\u5730\u68c0\u6d4b\u5bf9\u8bdd\u6d41\u7684\u5168\u5c40\u53d8\u5316\u3002\u6ca1\u6709\u5355\u4e00\u5206\u6bb5\u5668\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u5747\u5360\u4f18\uff0c\u5206\u6bb5\u5668\u5728\u5185\u90e8\u4e00\u81f4\u6027\u3001\u8fb9\u754c\u533a\u5206\u548c\u4eba\u673a\u5206\u5e03\u534f\u8bae\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "conclusion": "\u5bf9\u8bdd\u5206\u6bb5\u5e94\u89c6\u4e3a\u5f71\u54cd\u540e\u7eed\u4efb\u52a1\u7684\u91cd\u8981\u8bbe\u8ba1\u9009\u62e9\uff0c\u5e94\u6839\u636e\u5177\u4f53\u4e0b\u6e38\u4efb\u52a1\u76ee\u6807\u8fdb\u884c\u4f18\u5316\uff0c\u800c\u975e\u4ec5\u8ffd\u6c42\u5355\u4e00\u6027\u80fd\u6307\u6807\u3002"}}
{"id": "2601.13334", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13334", "abs": "https://arxiv.org/abs/2601.13334", "authors": ["Tarik Houichime", "Younes El Amrani"], "title": "SEER: Spectral Entropy Encoding of Roles for Context-Aware Attention-Based Design Pattern Detection", "comment": null, "summary": "This paper presents SEER, an upgraded version of our prior method Context Is All You Need for detecting Gang of Four (GoF) design patterns from source code. The earlier approach modeled code as attention-ready sequences that blended lightweight structure with behavioral context; however, it lacked explicit role disambiguation within classes and treated call edges uniformly. SEER addresses these limitations with two principled additions: (i) a spectral-entropy role encoder that derives per-member role embeddings from the Laplacian spectrum of each class's interaction graph, and (ii) a time-weighted calling context that assigns empirically calibrated duration priors to method categories (e.g., constructors, getters/setters, static calls, virtual dispatch, cloning). Together, these components sharpen the model's notion of \"who does what\" and \"how much it matters,\" while remaining portable across languages with minimal adaptation and fully compatible with Transformer-based sequence encoders. Importantly, SEER does not \"force\" a win by capacity or data; it nudges the classifier, steering attention toward role-consistent and temporally calibrated signals that matter most. We evaluate SEER on PyDesignNet (1,832 files, 35,000 sequences, 23 GoF patterns) and observe consistent gains over our previous system: macro-F1 increases from 92.47% to 93.20% and accuracy from 92.52% to 93.98%, with macro-precision 93.98% and macro-recall 92.52%. Beyond aggregate metrics, SEER reduces false positives by nearly 20%, a decisive improvement that strengthens its robustness and practical reliability. Moreover, SEER yields interpretable, symbol-level attributions aligned with canonical roles, exhibits robustness under small graph perturbations, and shows stable calibration.", "AI": {"tldr": "SEER\u901a\u8fc7\u5f15\u5165\u89d2\u8272\u7f16\u7801\u548c\u65f6\u95f4\u52a0\u6743\u673a\u5236\u6539\u8fdb\u4e86GoF\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\uff0c\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4e4b\u524d\u7684\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7c7b\u4e2d\u89d2\u8272\u7684\u660e\u786e\u533a\u5206\uff0c\u5e76\u4e14\u5bf9\u8c03\u7528\u8fb9\u4e00\u89c6\u540c\u4ec1\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u7cbe\u51c6\u6355\u6349\u6210\u5458\u7684\u5177\u4f53\u804c\u8d23\u548c\u8c03\u7528\u65f6\u957f\u7684\u91cd\u8981\u6027\uff0c\u9650\u5236\u4e86\u68c0\u6d4b\u80fd\u529b\u3002", "method": "SEER\u7ed3\u5408\u4e86\u4e24\u5927\u521b\u65b0\u6a21\u5757\uff1a\u5229\u7528\u62c9\u666e\u62c9\u65af\u8c31\u5bf9\u7c7b\u4ea4\u4e92\u56fe\u4e2d\u7684\u6210\u5458\u89d2\u8272\u8fdb\u884c\u7f16\u7801\u7684\u8c31\u71b5\u89d2\u8272\u7f16\u7801\u5668\uff0c\u4ee5\u53ca\u9488\u5bf9\u65b9\u6cd5\u7c7b\u522b\u5206\u914d\u65f6\u95f4\u6743\u91cd\u7684\u8c03\u7528\u4e0a\u4e0b\u6587\u673a\u5236\uff0c\u63d0\u5347Transformer\u5e8f\u5217\u7f16\u7801\u5668\u4e2d\u5bf9\u89d2\u8272\u548c\u65f6\u95f4\u4fe1\u606f\u7684\u654f\u611f\u5ea6\u3002", "result": "\u5728PyDesignNet\u6570\u636e\u96c6\u4e0a\uff0cSEER\u5c06\u5b8fF1\u503c\u63d0\u5347\u81f393.20%\uff0c\u51c6\u786e\u7387\u8fbe93.98%\uff0c\u4e14\u5047\u9633\u6027\u7387\u51cf\u5c11\u8fd120%\uff0c\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u548c\u89e3\u91ca\u6027\u3002", "conclusion": "SEER\u901a\u8fc7\u5f15\u5165\u8c31\u71b5\u89d2\u8272\u7f16\u7801\u5668\u548c\u65f6\u95f4\u52a0\u6743\u8c03\u7528\u4e0a\u4e0b\u6587\uff0c\u6709\u6548\u63d0\u5347\u4e86GoF\u8bbe\u8ba1\u6a21\u5f0f\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u76f8\u8f83\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\u548c\u5b9e\u7528\u6027\u589e\u5f3a\u3002"}}
{"id": "2601.12068", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12068", "abs": "https://arxiv.org/abs/2601.12068", "authors": ["Rowzatul Zannat", "Abdullah Al Shafi", "Abdul Muntakim"], "title": "Bridging the Gap in Bangla Healthcare: Machine Learning Based Disease Prediction Using a Symptoms-Disease Dataset", "comment": null, "summary": "Increased access to reliable health information is essential for non-English-speaking populations, yet resources in Bangla for disease prediction remain limited. This study addresses this gap by developing a comprehensive Bangla symptoms-disease dataset containing 758 unique symptom-disease relationships spanning 85 diseases. To ensure transparency and reproducibility, we also make our dataset publicly available. The dataset enables the prediction of diseases based on Bangla symptom inputs, supporting healthcare accessibility for Bengali-speaking populations. Using this dataset, we evaluated multiple machine learning models to predict diseases based on symptoms provided in Bangla and analyzed their performance on our dataset. Both soft and hard voting ensemble approaches combining top-performing models achieved 98\\% accuracy, demonstrating superior robustness and generalization. Our work establishes a foundational resource for disease prediction in Bangla, paving the way for future advancements in localized health informatics and diagnostic tools. This contribution aims to enhance equitable access to health information for Bangla-speaking communities, particularly for early disease detection and healthcare interventions.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6\u75be\u75c5\u6570\u636e\u96c6\uff0c\u5229\u7528\u591a\u6a21\u578b\u96c6\u6210\u5b9e\u73b0\u9ad8\u51c6\u786e\u7387\u75be\u75c5\u9884\u6d4b\uff0c\u52a9\u529b\u5b5f\u52a0\u62c9\u8bed\u4eba\u7fa4\u5065\u5eb7\u4fe1\u606f\u83b7\u53d6\u3002", "motivation": "\u9488\u5bf9\u975e\u82f1\u8bed\u4eba\u7fa4\u5c24\u5176\u662f\u5b5f\u52a0\u62c9\u8bed\u4f7f\u7528\u8005\u7f3a\u4e4f\u53ef\u9760\u5065\u5eb7\u4fe1\u606f\u53ca\u75be\u75c5\u9884\u6d4b\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u63d0\u5347\u5176\u83b7\u53d6\u533b\u7597\u670d\u52a1\u7684\u516c\u5e73\u6027\u3002", "method": "\u6784\u5efa\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6\u75be\u75c5\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5bf9\u75c7\u72b6\u8fdb\u884c\u75be\u75c5\u9884\u6d4b\uff0c\u901a\u8fc7\u8f6f\u6295\u7968\u548c\u786c\u6295\u7968\u96c6\u6210\u9876\u5c16\u6a21\u578b\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\u3002", "result": "\u6570\u636e\u96c6\u516c\u5f00\uff0c\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6\u8f93\u5165\u7684\u75be\u75c5\u9884\u6d4b\u4e0a\u8fbe\u523098%\u51c6\u786e\u7387\uff0c\u96c6\u6210\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u5305\u542b758\u4e2a\u72ec\u7279\u75c7\u72b6-\u75be\u75c5\u5173\u7cfb\u3001\u6db5\u76d685\u79cd\u75be\u75c5\u7684\u5b5f\u52a0\u62c9\u8bed\u75c7\u72b6\u75be\u75c5\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u591a\u6a21\u578b\u96c6\u6210\u65b9\u6cd5\u5b9e\u73b0\u4e8698%\u7684\u75be\u75c5\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u6784\u5efa\u4e86\u5b5f\u52a0\u62c9\u8bed\u75be\u75c5\u9884\u6d4b\u7684\u57fa\u7840\u8d44\u6e90\u3002"}}
{"id": "2601.13345", "categories": ["cs.SE", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.13345", "abs": "https://arxiv.org/abs/2601.13345", "authors": ["Saurabhsingh Rajput", "Alexander Brandt", "Vadim Elisseev", "Tushar Sharma"], "title": "FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels", "comment": null, "summary": "Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.", "AI": {"tldr": "FlipFlop\u5229\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790\u9884\u6d4bGPU\u7a0b\u5e8f\u80fd\u8017\uff0c\u63a8\u8350\u6700\u4f18\u7ebf\u7a0b\u914d\u7f6e\uff0c\u5b9e\u73b0\u663e\u8457\u8282\u80fd\u548c\u6027\u80fd\u63d0\u5347\uff0c\u4f18\u5316\u5f00\u53d1\u6548\u7387\uff0c\u63a8\u52a8\u7eff\u8272\u9ad8\u6548GPU\u8ba1\u7b97\u3002", "motivation": "GPU\u7a0b\u5e8f\u6d88\u8017\u5927\u91cf\u80fd\u6e90\uff0c\u4f46\u8f6f\u4ef6\u5f00\u53d1\u8005\u7f3a\u4e4f\u786c\u4ef6\u4e13\u4e1a\u77e5\u8bc6\u6765\u4f18\u5316\u80fd\u8017\u3002", "method": "\u63d0\u51faFlipFlop\u6846\u67b6\uff0c\u5229\u7528\u9759\u6001\u4ee3\u7801\u5206\u6790PTX\u4ee3\u7801\uff0c\u9884\u6d4b\u80fd\u8017\u5e76\u63a8\u8350\u517c\u987e\u529f\u8017\u548c\u6267\u884c\u65f6\u95f4\u7684\u5e15\u7d2f\u6258\u6700\u4f18\u7ebf\u7a0b\u5757\u914d\u7f6e\u3002", "result": "FlipFlop\u5728\u591a\u79cdGPU\u548c\u5185\u6838\u4e0a\u9a8c\u8bc1\uff0c\u8bc6\u522b\u80fd\u6548\u6700\u4f18\u914d\u7f6e\u51c6\u786e\u7387\u8fbe83%\uff0c\u51cf\u5c1193.4%\u4f18\u5316\u641c\u7d22\u7a7a\u95f4\uff0c\u591a\u5934\u6ce8\u610f\u529b\u5185\u6838\u8282\u80fd\u8fbe79%\uff0c\u541e\u5410\u91cf\u63d0\u5347106%\u3002", "conclusion": "FlipFlop\u901a\u8fc7\u9759\u6001\u5206\u6790\u7ed3\u5408\u5b9e\u65f6\u76d1\u63a7\uff0c\u4e3a\u5f00\u53d1\u8005\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u6307\u5bfc\uff0c\u5b9e\u73b0\u9ad8\u6027\u80fd\u4f4e\u80fd\u8017GPU\u8f6f\u4ef6\u5f00\u53d1\uff0c\u964d\u4f4e\u73af\u5883\u4e0e\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2601.12075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12075", "abs": "https://arxiv.org/abs/2601.12075", "authors": ["Mehrdad Farahani", "Franziska Penzkofer", "Richard Johansson"], "title": "To Copy or Not to Copy: Copying Is Easier to Induce Than Recall", "comment": null, "summary": "Language models used in retrieval-augmented settings must arbitrate between parametric knowledge stored in their weights and contextual information in the prompt. This work presents a mechanistic study of that choice by extracting an \\emph{arbitration vector} from model activations on a curated dataset designed to disentangle (i) irrelevant contexts that elicit parametric recall and (ii) relevant but false contexts that elicit copying. The vector is computed as the residual-stream centroid difference between these regimes across 27 relations, and is injected as an additive intervention at selected layers and token spans to steer behavior in two directions: Copy$\\rightarrow$Recall (suppressing context use) and Recall$\\rightarrow$Copy (inducing the model to copy any token from the context). Experiments on two architectures (decoder-only and encoder/decoder) and two open-domain QA benchmarks show consistent behavior shifts under moderate scaling while monitoring accuracy and fluency. Mechanistic analyses of attention routing, MLP contributions, and layer-wise probability trajectories reveal an asymmetry: inducing copying is an easy ``reactivation'' process that can be triggered at different locations in the input, while restoring recall is a ``suppression'' process that is more fragile and strongly tied to object-token interventions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u201c\u4ef2\u88c1\u5411\u91cf\u201d\u673a\u5236\uff0c\u63a7\u5236\u8bed\u8a00\u6a21\u578b\u5728\u590d\u5236\u4e0a\u4e0b\u6587\u4e0e\u8c03\u7528\u5185\u5b58\u77e5\u8bc6\u95f4\u7684\u9009\u62e9\uff0c\u8bc1\u660e\u590d\u5236\u6bd4\u8c03\u7528\u66f4\u6613\u89e6\u53d1\uff0c\u63ed\u793a\u4e86\u4e8c\u8005\u884c\u4e3a\u673a\u5236\u4e0a\u7684\u4e0d\u5bf9\u79f0\u6027\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u7ed3\u5408\u53c2\u6570\u77e5\u8bc6\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u65f6\u5982\u4f55\u8c03\u8282\u590d\u5236\u548c\u8c03\u7528\u77e5\u8bc6\u7684\u884c\u4e3a\u673a\u5236\uff0c\u7279\u522b\u662f\u5728\u9762\u5bf9\u65e0\u5173\u6216\u865a\u5047\u4e0a\u4e0b\u6587\u65f6\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "method": "\u901a\u8fc7\u4ece\u6a21\u578b\u6fc0\u6d3b\u4e2d\u63d0\u53d6\u201c\u4ef2\u88c1\u5411\u91cf\u201d\uff0c\u5e76\u5728\u4e0d\u540c\u5c42\u548c\u4f4d\u7f6e\u6ce8\u5165\u8be5\u5411\u91cf\u4ee5\u63a7\u5236\u6a21\u578b\u884c\u4e3a\u7684\u65b9\u5411\uff0c\u5728\u4e24\u4e2a\u6a21\u578b\u67b6\u6784\u548c\u4e24\u4e2a\u5f00\u653e\u9886\u57df\u95ee\u7b54\u57fa\u51c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u6a21\u578b\u884c\u4e3a\u53ef\u901a\u8fc7\u201c\u4ef2\u88c1\u5411\u91cf\u201d\u6210\u529f\u8c03\u8282\uff0c\u5b9e\u73b0\u590d\u5236\u4e0e\u8c03\u7528\u7684\u5207\u6362\uff0c\u4e14\u590d\u5236\u7684\u8bf1\u5bfc\u66f4\u5bb9\u6613\u4e14\u4e0d\u4f9d\u8d56\u7279\u5b9a\u4f4d\u7f6e\uff0c\u800c\u8c03\u7528\u7684\u6062\u590d\u66f4\u8106\u5f31\u4e14\u9700\u8981\u66f4\u5177\u4f53\u7684\u5e72\u9884\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u548c\u64cd\u63a7\u201c\u4ef2\u88c1\u5411\u91cf\u201d\uff0c\u7814\u7a76\u63ed\u793a\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u589e\u5f3a\u73af\u5883\u4e0b\u5728\u590d\u5236\u4e0a\u4e0b\u6587\u548c\u8c03\u7528\u53c2\u6570\u77e5\u8bc6\u95f4\u7684\u673a\u5236\u5dee\u5f02\uff0c\u8868\u660e\u8bf1\u5bfc\u6a21\u578b\u590d\u5236\u6bd4\u6062\u590d\u8c03\u7528\u66f4\u5bb9\u6613\u4e14\u66f4\u5177\u7075\u6d3b\u6027\u3002"}}
{"id": "2601.13384", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13384", "abs": "https://arxiv.org/abs/2601.13384", "authors": ["Jiajun Zhang", "Zeyu Cui", "Jiaxi Yang", "Lei Zhang", "Yuheng Jing", "Zeyao Ma", "Tianyi Bai", "Zilei Wang", "Qiang Liu", "Liang Wang", "Binyuan Hui", "Junyang Lin"], "title": "From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning", "comment": null, "summary": "The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSRI\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u7f16\u8f91\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u5347\u4ee3\u7801\u8865\u5168\u6027\u80fd\uff0c\u517c\u987e\u5b89\u5168\u6027\u4e0e\u63a8\u7406\u6548\u7387\uff0c\u63a8\u52a8\u81ea\u52a8\u8865\u5168\u6280\u672f\u8fdb\u6b65\u3002", "motivation": "\u73b0\u6709\u7684\u4ee3\u7801\u8865\u5168\u65b9\u6cd5\u5b58\u5728\u65e0\u6cd5\u7ea0\u6b63\u4e0a\u4e0b\u6587\u9519\u8bef\u548c\u4f9d\u8d56\u4e0d\u5b89\u5168\u57fa\u7840\u6a21\u578b\u7684\u95ee\u9898\uff0c\u4e14Chat\u5927\u6a21\u578b\u867d\u7136\u5b89\u5168\u4f46\u6027\u80fd\u548c\u5ef6\u8fdf\u5b58\u5728\u7f3a\u9677\u3002", "method": "\u63d0\u51fa\u4e86Search-and-Replace Infilling\uff08SRI\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u663e\u5f0f\u641c\u7d22\u9636\u6bb5\u5b9e\u73b0\u9a8c\u8bc1\u548c\u7f16\u8f91\uff0c\u7ed3\u5408Chat\u5927\u6a21\u578b\u7684\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u5728\u5355\u6b21\u63a8\u7406\u4e2d\u5b8c\u6210\u52a8\u6001\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u7f16\u8f91\u3002", "result": "\u5229\u7528\u5408\u6210\u7684\u9ad8\u8d28\u91cf\u6570\u636e\u96c6SRI-200K\u5fae\u8c03SRI-Coder\u7cfb\u5217\uff0c\u5c11\u91cf\u6570\u636e\u5373\u53ef\u8ba9Chat\u6a21\u578b\u7684\u8865\u5168\u6027\u80fd\u8d85\u8fc7\u57fa\u7840\u6a21\u578b\uff0c\u4e14\u4fdd\u6301\u8f83\u4f4e\u63a8\u7406\u5ef6\u8fdf\u548c\u826f\u597d\u7684\u7f16\u7801\u80fd\u529b\u3002", "conclusion": "SRI\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edfFIM\u65b9\u6cd5\u7684\u5c40\u9650\uff0c\u63d0\u5347\u4e86\u4ee3\u7801\u8865\u5168\u7684\u6027\u80fd\u548c\u5b89\u5168\u6027\uff0c\u540c\u65f6\u4fdd\u8bc1\u63a8\u7406\u6548\u7387\uff0c\u63a8\u52a8\u4e86Qwen3-Coder\u7cfb\u5217\u7684\u81ea\u52a8\u8865\u5168\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2601.12078", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12078", "abs": "https://arxiv.org/abs/2601.12078", "authors": ["Linfeng Du", "Ye Yuan", "Zichen Zhao", "Fuyuan Lyu", "Emiliano Penaloza", "Xiuying Chen", "Zipeng Sun", "Jikun Kang", "Laurent Charlin", "Xue Liu", "Haolun Wu"], "title": "Optimizing User Profiles via Contextual Bandits for Retrieval-Augmented LLM Personalization", "comment": null, "summary": "Large Language Models (LLMs) excel at general-purpose tasks, yet adapting their responses to individual users remains challenging. Retrieval augmentation provides a lightweight alternative to fine-tuning by conditioning LLMs on user history records, and existing approaches typically select these records based on semantic relevance. We argue that relevance serves as an unreliable proxy for utility: a record may be semantically similar to a query yet fail to improve generation quality or even degrade it due to redundancy or conflicting information. To bridge this gap, we propose PURPLE, a contextual bandit framework that oPtimizes UseR Profiles for Llm pErsonalization. In contrast to a greedy selection of the most relevant records, PURPLE treats profile construction as a set generation process and utilizes a Plackett-Luce ranking model to capture complex inter-record dependencies. By training with dense feedback provided by the likelihood of the reference response, our method aligns retrieval directly with generation quality. Extensive experiments on nine personalization tasks demonstrate that PURPLE consistently outperforms strong heuristic and retrieval-augmented baselines in both effectiveness and efficiency, establishing a principled and scalable solution for optimizing user profiles.", "AI": {"tldr": "\u63d0\u51faPURPLE\uff0c\u901a\u8fc7\u4f18\u5316\u7528\u6237\u753b\u50cf\u9009\u62e9\u7b56\u7565\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u4e2a\u6027\u5316\u54cd\u5e94\u6548\u679c\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u517c\u987e\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u901a\u8fc7\u8bed\u4e49\u76f8\u5173\u6027\u9009\u62e9\u7528\u6237\u5386\u53f2\u8bb0\u5f55\u6765\u589e\u5f3a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u54cd\u5e94\uff0c\u4f46\u8bed\u4e49\u76f8\u5173\u6027\u5e76\u4e0d\u603b\u80fd\u6709\u6548\u63d0\u5347\u751f\u6210\u8d28\u91cf\uff0c\u53ef\u80fd\u56e0\u5197\u4f59\u6216\u51b2\u7a81\u4fe1\u606f\u53cd\u800c\u5e26\u6765\u8d1f\u9762\u5f71\u54cd\u3002", "method": "\u63d0\u51faPURPLE\uff0c\u4e00\u79cd\u57fa\u4e8e\u4e0a\u4e0b\u6587\u8d4c\u535a\u673a\u7684\u6846\u67b6\uff0c\u901a\u8fc7Plackett-Luce\u6392\u5217\u6a21\u578b\u5c06\u7528\u6237\u753b\u50cf\u6784\u5efa\u89c6\u4e3a\u96c6\u5408\u751f\u6210\u8fc7\u7a0b\uff0c\u6355\u6349\u8bb0\u5f55\u95f4\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u5229\u7528\u53c2\u8003\u54cd\u5e94\u7684\u4f3c\u7136\u5ea6\u4f5c\u4e3a\u5bc6\u96c6\u53cd\u9988\u6765\u4f18\u5316\u68c0\u7d22\u4e0e\u751f\u6210\u8d28\u91cf\u7684\u5bf9\u9f50\u3002", "result": "\u5728\u4e5d\u4e2a\u4e2a\u6027\u5316\u4efb\u52a1\u4e0a\u7684\u5927\u91cf\u5b9e\u9a8c\u8868\u660e\uff0cPURPLE\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u542f\u53d1\u5f0f\u65b9\u6cd5\u548c\u57fa\u4e8e\u68c0\u7d22\u7684\u589e\u5f3a\u65b9\u6cd5\uff0c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u539f\u7406\u660e\u786e\u4e14\u53ef\u6269\u5c55\u7684\u7528\u6237\u753b\u50cf\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "PURPLE\u6210\u529f\u6539\u5584\u4e86\u7528\u6237\u5386\u53f2\u8bb0\u5f55\u9009\u62e9\u7b56\u7565\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e2a\u6027\u5316\u54cd\u5e94\u66f4\u52a0\u9ad8\u6548\u4e14\u8d28\u91cf\u66f4\u4f18\uff0c\u7a81\u7834\u4e86\u5355\u7eaf\u4f9d\u8d56\u8bed\u4e49\u76f8\u5173\u6027\u7684\u9650\u5236\u3002"}}
{"id": "2601.13460", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13460", "abs": "https://arxiv.org/abs/2601.13460", "authors": ["Alexandra Gonz\u00e1lez", "Oscar Cerezo", "Xavier Franch", "Silverio Mart\u00ednez-Fern\u00e1ndez"], "title": "A Tool for Automatically Cataloguing and Selecting Pre-Trained Models and Datasets for Software Engineering", "comment": null, "summary": "The rapid growth of machine learning assets has made it increasingly difficult for software engineers to identify models and datasets that match their specific needs. Browsing large registries, such as Hugging Face, is time-consuming, error-prone, and rarely tailored to Software Engineering (SE) tasks. We present MLAssetSelection, a web application that automatically extracts SE assets and supports four key functionalities: (i) a configurable leaderboard for ranking models across multiple benchmarks and metrics; (ii) requirements-based selection of models and datasets; (iii) real-time automated updates through scheduled jobs that keep asset information current; and (iv) user-centric features including login, personalized asset lists, and configurable alert notifications. A demonstration video is available at https://youtu.be/t6CJ6P9asV4.", "AI": {"tldr": "\u672c\u8bba\u6587\u4ecb\u7ecd\u4e86MLAssetSelection\uff0c\u4e00\u6b3e\u9762\u5411\u8f6f\u4ef6\u5de5\u7a0b\u7684\u673a\u5668\u5b66\u4e60\u8d44\u4ea7\u9009\u62e9\u5de5\u5177\uff0c\u7b80\u5316\u4e86\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u6311\u9009\u8fc7\u7a0b\uff0c\u63d0\u9ad8\u4e86\u4f7f\u7528\u6548\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u8d44\u4ea7\u6570\u91cf\u8fc5\u901f\u589e\u957f\uff0c\u73b0\u6709\u5927\u578b\u8d44\u6e90\u5e93\u6d4f\u89c8\u8017\u65f6\u4e14\u4e0d\u591f\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u6025\u9700\u4e00\u79cd\u9ad8\u6548\u3001\u7cbe\u51c6\u7684\u8d44\u4ea7\u9009\u62e9\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u7f51\u9875\u5e94\u7528\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a8\u63d0\u53d6\u8f6f\u4ef6\u5de5\u7a0b\u76f8\u5173\u8d44\u4ea7\uff0c\u63d0\u4f9b\u591a\u57fa\u51c6\u548c\u6307\u6807\u7684\u6392\u884c\u699c\u3001\u57fa\u4e8e\u9700\u6c42\u7684\u6a21\u578b\u548c\u6570\u636e\u96c6\u9009\u62e9\u3001\u5b9e\u65f6\u81ea\u52a8\u66f4\u65b0\u4ee5\u53ca\u7528\u6237\u5b9a\u5236\u529f\u80fd\u3002", "result": "\u6210\u529f\u5f00\u53d1\u4e86MLAssetSelection\uff0c\u5b9e\u73b0\u4e86\u4fbf\u6377\u7684\u673a\u5668\u5b66\u4e60\u6a21\u578b\u548c\u6570\u636e\u96c6\u7b5b\u9009\u53ca\u7ba1\u7406\uff0c\u652f\u6301\u5b9e\u65f6\u66f4\u65b0\u548c\u4e2a\u6027\u5316\u670d\u52a1\u3002", "conclusion": "MLAssetSelection\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9488\u5bf9\u8f6f\u4ef6\u5de5\u7a0b\u9700\u6c42\u8bbe\u8ba1\u7684\u673a\u5668\u5b66\u4e60\u8d44\u4ea7\u9009\u62e9\u5de5\u5177\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u548c\u6570\u636e\u96c6\u7684\u7b5b\u9009\u6548\u7387\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2601.12099", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12099", "abs": "https://arxiv.org/abs/2601.12099", "authors": ["Leonardo S. Goodall", "Dor Shilton", "Daniel A. Mullins", "Harvey Whitehouse"], "title": "Large language models struggle with ethnographic text annotation", "comment": null, "summary": "Large language models (LLMs) have shown promise for automated text annotation, raising hopes that they might accelerate cross-cultural research by extracting structured data from ethnographic texts. We evaluated 7 state-of-the-art LLMs on their ability to annotate 121 ritual features across 567 ethnographic excerpts. Performance was limited, falling well below levels required for reliable automated annotation. Longer texts, features requiring ordinal distinctions, and ambiguous constructs proved particularly difficult. Human inter-coder reliability set an approximate ceiling on LLM accuracy: features that human coders found difficult to agree upon were also difficult for LLMs. Yet even on features where humans reliably agreed, models fell short of human performance. Our findings suggest that LLMs cannot yet substitute for human expertise in ethnographic annotation.", "AI": {"tldr": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6c11\u65cf\u5fd7\u6587\u672c\u6ce8\u91ca\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u8fdc\u4e0d\u53ca\u4eba\u7c7b\uff0c\u5c1a\u4e0d\u80fd\u53d6\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u6587\u672c\u6ce8\u91ca\u4e2d\u7684\u6f5c\u529b\uff0c\u5e0c\u671b\u901a\u8fc7\u81ea\u52a8\u5316\u5904\u7406\u52a0\u901f\u8de8\u6587\u5316\u7814\u7a76\u3002", "method": "\u8bc4\u4f30\u4e867\u4e2a\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728121\u4e2a\u4eea\u5f0f\u7279\u5f81\u548c567\u6bb5\u6c11\u65cf\u5fd7\u6587\u672c\u4e2d\u7684\u6ce8\u91ca\u80fd\u529b\u3002", "result": "\u6a21\u578b\u6027\u80fd\u660e\u663e\u4e0d\u8db3\uff0c\u4f4e\u4e8e\u53ef\u9760\u81ea\u52a8\u6ce8\u91ca\u7684\u8981\u6c42\uff1b\u5904\u7406\u8f83\u957f\u6587\u672c\u3001\u9700\u8981\u987a\u5e8f\u533a\u5206\u7684\u7279\u5f81\u53ca\u6a21\u7cca\u6784\u9020\u5c24\u5176\u56f0\u96be\uff1b\u6a21\u578b\u6027\u80fd\u53d7\u9650\u4e8e\u4eba\u7c7b\u7f16\u7801\u8005\u4e00\u81f4\u6027\u6c34\u5e73\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u76ee\u524d\u65e0\u6cd5\u66ff\u4ee3\u4eba\u7c7b\u4e13\u5bb6\u8fdb\u884c\u6c11\u65cf\u5fd7\u6587\u672c\u7684\u7ed3\u6784\u5316\u6ce8\u91ca\u3002"}}
{"id": "2601.13466", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13466", "abs": "https://arxiv.org/abs/2601.13466", "authors": ["Pedro Oliveira", "Doris Amoakohene", "Toby Hocking", "Marco Gerosa", "Igor Steinmacher"], "title": "Governance Matters: Lessons from Restructuring the data.table OSS Project", "comment": "ICSME 2025", "summary": "Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5bf9R\u5305data.table\u7684\u793e\u533a\u6cbb\u7406\u6539\u9769\u6848\u4f8b\u7814\u7a76\uff0c\u5c55\u793a\u4e86\u6539\u8fdb\u6cbb\u7406\u7ed3\u6784\u80fd\u5927\u5e45\u63d0\u5347\u5f00\u6e90\u9879\u76ee\u7684\u8d21\u732e\u8005\u62db\u52df\u3001\u95ee\u9898\u5904\u7406\u901f\u5ea6\u548c\u793e\u533a\u6c1b\u56f4\u3002", "motivation": "\u5f00\u6e90\u8f6f\u4ef6\u9879\u76ee\u9762\u4e34\u8fd0\u8425\u98ce\u9669\uff0c\u5c24\u5176\u662f\u7531\u4e8e\u6cbb\u7406\u7ed3\u6784\u975e\u6b63\u5f0f\u6216\u8fc7\u4e8e\u96c6\u4e2d\uff0c\u5f71\u54cd\u9879\u76ee\u7684\u53ef\u6269\u5c55\u6027\u548c\u53ef\u6301\u7eed\u6027\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u7814\u7a76\uff0c\u5305\u62ec\u8d21\u732e\u8005\u8c03\u67e5\uff08n=17\uff09\u548c\u9879\u76ee\u4ee3\u7801\u5e93\u6570\u636e\u6316\u6398\uff0c\u8bc4\u4f30\u793e\u533a\u6cbb\u7406\u7ed3\u6784\u6539\u9769\u7684\u5f71\u54cd\u3002", "result": "\u6539\u9769\u540e\u65b0\u8d21\u732e\u8005\u589e\u957f200%\uff0c\u62c9\u53d6\u8bf7\u6c42\u89e3\u51b3\u65f6\u95f4\u4ece700\u591a\u5929\u7f29\u77ed\u5230\u4e0d\u5230\u4e00\u5468\uff0c\u8d21\u732e\u8005\u4fdd\u7559\u7387\u63d0\u53473\u500d\uff0c\u793e\u533a\u900f\u660e\u5ea6\u548c\u9879\u76ee\u6d3b\u529b\u663e\u8457\u63d0\u5347\uff0c\u4f46\u516c\u5e73\u6027\u548c\u51b2\u7a81\u89e3\u51b3\u4ecd\u6709\u5f85\u6539\u8fdb\u3002", "conclusion": "\u901a\u8fc7\u793e\u533a\u4e3b\u5bfc\u7684\u6cbb\u7406\u6539\u9769\uff0c\u5f00\u6e90\u9879\u76ee\u53ef\u663e\u8457\u63d0\u5347\u8d21\u732e\u8005\u53c2\u4e0e\u5ea6\u548c\u8fd0\u8425\u6548\u7387\uff0c\u4ece\u800c\u589e\u5f3a\u9879\u76ee\u7684\u53ef\u6301\u7eed\u6027\u548c\u89c4\u6a21\u5316\u80fd\u529b\u3002"}}
{"id": "2601.12104", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12104", "abs": "https://arxiv.org/abs/2601.12104", "authors": ["David Ili\u0107", "David Stanojevi\u0107", "Kostadin Cvejoski"], "title": "Powerful Training-Free Membership Inference Against Autoregressive Language Models", "comment": "9 pages, 2 figures; appendix with additional experiments and derivations", "summary": "Fine-tuned language models pose significant privacy risks, as they may memorize and expose sensitive information from their training data. Membership inference attacks (MIAs) provide a principled framework for auditing these risks, yet existing methods achieve limited detection rates, particularly at the low false-positive thresholds required for practical privacy auditing. We present EZ-MIA, a membership inference attack that exploits a key observation: memorization manifests most strongly at error positions, specifically tokens where the model predicts incorrectly yet still shows elevated probability for training examples. We introduce the Error Zone (EZ) score, which measures the directional imbalance of probability shifts at error positions relative to a pretrained reference model. This principled statistic requires only two forward passes per query and no model training of any kind. On WikiText with GPT-2, EZ-MIA achieves 3.8x higher detection than the previous state-of-the-art under identical conditions (66.3% versus 17.5% true positive rate at 1% false positive rate), with near-perfect discrimination (AUC 0.98). At the stringent 0.1% FPR threshold critical for real-world auditing, we achieve 8x higher detection than prior work (14.0% versus 1.8%), requiring no reference model training. These gains extend to larger architectures: on AG News with Llama-2-7B, we achieve 3x higher detection (46.7% versus 15.8% TPR at 1% FPR). These results establish that privacy risks of fine-tuned language models are substantially greater than previously understood, with implications for both privacy auditing and deployment decisions. Code is available at https://github.com/JetBrains-Research/ez-mia.", "AI": {"tldr": "EZ-MIA\u901a\u8fc7\u5206\u6790\u6a21\u578b\u9519\u8bef\u9884\u6d4b\u4f4d\u7f6e\u7684\u6982\u7387\u7279\u5f81\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4f1a\u5458\u63a8\u65ad\u653b\u51fb\u7684\u68c0\u6d4b\u7387\uff0c\u63ed\u793a\u4e86\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u66f4\u9ad8\u7684\u9690\u79c1\u98ce\u9669\uff0c\u5bf9\u9690\u79c1\u5ba1\u8ba1\u548c\u6a21\u578b\u90e8\u7f72\u6709\u91cd\u8981\u5f71\u54cd\u3002", "motivation": "\u73b0\u6709\u4f1a\u5458\u63a8\u65ad\u653b\u51fb\u5728\u5b9e\u9645\u9690\u79c1\u5ba1\u8ba1\u6240\u9700\u7684\u4f4e\u5047\u9633\u6027\u9608\u503c\u4e0b\u68c0\u6d4b\u7387\u6709\u9650\uff0c\u5c24\u5176\u96be\u4ee5\u68c0\u6d4b\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u4e2d\u8bb0\u5fc6\u7684\u654f\u611f\u4fe1\u606f\u3002\u901a\u8fc7\u53d1\u73b0\u6a21\u578b\u5728\u9519\u8bef\u4f4d\u7f6e\u7684\u8bb0\u5fc6\u8868\u73b0\uff0c\u53ef\u4ee5\u63d0\u5347\u653b\u51fb\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86EZ-MIA\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165Error Zone(EZ)\u5206\u6570\uff0c\u5229\u7528\u6a21\u578b\u5728\u9519\u8bef\u9884\u6d4b\u4f4d\u7f6e\u76f8\u8f83\u4e8e\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u6982\u7387\u504f\u79fb\u65b9\u5411\u4e0d\u5e73\u8861\u6027\uff0c\u65e0\u9700\u8bad\u7ec3\u989d\u5916\u6a21\u578b\uff0c\u4ec5\u9700\u4e24\u6b21\u524d\u5411\u4f20\u64ad\u5373\u53ef\u8fdb\u884c\u6709\u6548\u4f1a\u5458\u63a8\u65ad\u3002", "result": "\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8bc1\u660e\uff0cEZ-MIA\u57281%\u5047\u9633\u6027\u7387\u4e0b\u76f8\u8f83\u5148\u524d\u65b9\u6cd5\u63d0\u9ad83\u52308\u500d\u7684\u771f\u9633\u6027\u7387\uff0cAUC\u8fbe\u52300.98\uff0c\u4e14\u65e0\u9700\u8bad\u7ec3\u53c2\u8003\u6a21\u578b\u3002\u7ed3\u679c\u8868\u660e\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u88ab\u5927\u5927\u4f4e\u4f30\u3002", "conclusion": "\u5fae\u8c03\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u663e\u8457\u7684\u9690\u79c1\u98ce\u9669\uff0c\u5c24\u5176\u662f\u5728\u9519\u8bef\u9884\u6d4b\u7684token\u4f4d\u7f6e\u8868\u73b0\u51fa\u8bb0\u5fc6\u6548\u5e94\u65f6\u3002EZ-MIA\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u4f1a\u5458\u63a8\u65ad\u653b\u51fb\u7684\u68c0\u6d4b\u6548\u679c\uff0c\u663e\u793a\u51fa\u5fae\u8c03\u6a21\u578b\u7684\u9690\u79c1\u98ce\u9669\u8fdc\u8d85\u6b64\u524d\u8ba4\u77e5\u3002"}}
{"id": "2601.13597", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13597", "abs": "https://arxiv.org/abs/2601.13597", "authors": ["Shyam Agarwal", "Hao He", "Bogdan Vasilescu"], "title": "AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development", "comment": null, "summary": "Large language model (LLM)-based coding agents increasingly act as autonomous contributors that generate and merge pull requests, yet their real-world effects on software projects are unclear, especially relative to widely adopted IDE-based AI assistants. We present a longitudinal causal study of agent adoption in open-source repositories using staggered difference-in-differences with matched controls. Using the AIDev dataset, we define adoption as the first agent-generated pull request and analyze monthly repository-level outcomes spanning development velocity (commits, lines added) and software quality (static-analysis warnings, cognitive complexity, duplication, and comment density). Results show large, front-loaded velocity gains only when agents are the first observable AI tool in a project; repositories with prior AI IDE usage experience minimal or short-lived throughput benefits. In contrast, quality risks are persistent across settings, with static-analysis warnings and cognitive complexity rising roughly 18% and 35%, indicating sustained agent-induced complexity debt even when velocity advantages fade. These heterogeneous effects suggest diminishing returns to AI assistance and highlight the need for quality safeguards, provenance tracking, and selective deployment of autonomous agents. Our findings establish an empirical basis for understanding how agentic and IDE-based tools interact, and motivate research on balancing acceleration with maintainability in AI-integrated development workflows.", "AI": {"tldr": "\u7814\u7a76\u663e\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u4ee3\u7406\u80fd\u77ed\u671f\u63d0\u5347\u5f00\u53d1\u901f\u5ea6\uff0c\u4f46\u8f6f\u4ef6\u8d28\u91cf\u95ee\u9898\u957f\u671f\u5b58\u5728\uff0c\u5f3a\u8c03\u9700\u8c28\u614e\u4f7f\u7528\u5e76\u52a0\u5f3a\u8d28\u91cf\u63a7\u5236\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u4ee3\u7406\u5728\u73b0\u5b9e\u8f6f\u4ef6\u9879\u76ee\u4e2d\u5bf9\u5f00\u53d1\u901f\u5ea6\u548c\u8f6f\u4ef6\u8d28\u91cf\u7684\u5b9e\u9645\u5f71\u54cd\uff0c\u5c24\u5176\u76f8\u5bf9\u4e8e\u4f20\u7edfIDE\u96c6\u6210\u7684AI\u52a9\u624b\u3002", "method": "\u91c7\u7528\u5206\u5c42\u5dee\u5206\u4e2d\u7684\u5339\u914d\u63a7\u5236\u7ec4\u65b9\u6cd5\uff0c\u5bf9\u5f00\u6e90\u4ee3\u7801\u5e93\u91c7\u7528AIDev\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u91c7\u7528\u4e3a\u9996\u6b21\u4ee3\u7406\u751f\u6210\u7684pull request\uff0c\u8fdb\u884c\u957f\u671f\u7684\u56e0\u679c\u5f71\u54cd\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4ee3\u7406\u9996\u6b21\u5f15\u5165\u65f6\uff0c\u5f00\u53d1\u901f\u5ea6\u663e\u8457\u63d0\u5347\uff0c\u4f46\u82e5\u9879\u76ee\u5df2\u6709AI IDE\u4f7f\u7528\uff0c\u901f\u5ea6\u63d0\u5347\u6709\u9650\u4e14\u77ed\u6682\u3002\u8d28\u91cf\u98ce\u9669\u666e\u904d\u5b58\u5728\uff0c\u9759\u6001\u5206\u6790\u8b66\u544a\u548c\u8ba4\u77e5\u590d\u6742\u5ea6\u5206\u522b\u63d0\u5347\u7ea618%\u548c35%\uff0c\u8868\u660e\u590d\u6742\u5ea6\u503a\u52a1\u6301\u7eed\u589e\u52a0\u3002", "conclusion": "AI\u7f16\u7801\u4ee3\u7406\u5e26\u6765\u521d\u671f\u5f00\u53d1\u901f\u5ea6\u63d0\u5347\uff0c\u4f46\u4f34\u968f\u6301\u7eed\u7684\u8f6f\u4ef6\u8d28\u91cf\u98ce\u9669\uff0c\u8bf4\u660eAI\u8f85\u52a9\u6548\u76ca\u9012\u51cf\uff0c\u9700\u7ed3\u5408\u8d28\u91cf\u4fdd\u969c\u3001\u6eaf\u6e90\u8ffd\u8e2a\u548c\u9009\u62e9\u6027\u90e8\u7f72\u7b56\u7565\uff0c\u4ee5\u5e73\u8861\u5f00\u53d1\u52a0\u901f\u4e0e\u7ef4\u62a4\u6027\u3002"}}
{"id": "2601.12132", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12132", "abs": "https://arxiv.org/abs/2601.12132", "authors": ["Md Mahmudul Hoque", "Md Mehedi Hassain", "Md Hojaifa Tanvir", "Rahul Nandy"], "title": "Bengali Text Classification: An Evaluation of Large Language Model Approaches", "comment": null, "summary": "Bengali text classification is a Significant task in natural language processing (NLP), where text is categorized into predefined labels. Unlike English, Bengali faces challenges due to the lack of extensive annotated datasets and pre-trained language models. This study explores the effectiveness of large language models (LLMs) in classifying Bengali newspaper articles. The dataset used, obtained from Kaggle, consists of articles from Prothom Alo, a major Bangladeshi newspaper. Three instruction-tuned LLMs LLaMA 3.1 8B Instruct, LLaMA 3.2 3B Instruct, and Qwen 2.5 7B Instruct were evaluated for this task under the same classification framework. Among the evaluated models, Qwen 2.5 achieved the highest classification accuracy of 72%, showing particular strength in the \"Sports\" category. In comparison, LLaMA 3.1 and LLaMA 3.2 attained accuracies of 53% and 56%, respectively. The findings highlight the effectiveness of LLMs in Bengali text classification, despite the scarcity of resources for Bengali NLP. Future research will focus on exploring additional models, addressing class imbalance issues, and refining fine-tuning approaches to improve classification performance.", "AI": {"tldr": "\u7814\u7a76\u6bd4\u8f83\u4e86\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u672c\u5206\u7c7b\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0Qwen 2.5\u8868\u73b0\u6700\u4f73\uff0c\u5c55\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8d44\u6e90\u532e\u4e4f\u7684\u5b5f\u52a0\u62c9\u8bedNLP\u4e2d\u7684\u6f5c\u529b\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u6807\u6ce8\u6570\u636e\u548c\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u9762\u4e34\u6311\u6218\uff0c\u7814\u7a76\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u6548\u679c\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u7ecf\u8fc7\u6307\u4ee4\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLaMA 3.1, LLaMA 3.2, Qwen 2.5\uff09\u5728\u540c\u4e00\u6846\u67b6\u4e0b\u5bf9\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6587\u7ae0\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u3002", "result": "Qwen 2.5\u6a21\u578b\u5728\u5206\u7c7b\u51c6\u786e\u7387\u4e0a\u4f18\u4e8eLLaMA 3.1\u548c3.2\uff0c\u5206\u522b\u4e3a72%\u300153%\u548c56%\uff0c\u5728\u201c\u4f53\u80b2\u201d\u7c7b\u522b\u8868\u73b0\u5c24\u4e3a\u7a81\u51fa\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u4e2d\u8868\u73b0\u6709\u6548\uff0c\u5c24\u5176\u662fQwen 2.5\u6a21\u578b\u8fbe\u5230\u4e86\u6700\u9ad872%\u7684\u51c6\u786e\u7387\u3002"}}
{"id": "2601.13655", "categories": ["cs.SE", "cs.AI", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.13655", "abs": "https://arxiv.org/abs/2601.13655", "authors": ["Guangba Yu", "Zirui Wang", "Yujie Huang", "Renyi Zhong", "Yuedong Zhong", "Yilun Wang", "Michael R. Lyu"], "title": "Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs", "comment": null, "summary": "The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.\n  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.", "AI": {"tldr": "\u9996\u6b21\u5927\u89c4\u6a21\u5206\u6790\u5f00\u6e90LLM\u90e8\u7f72\u5931\u8d25\uff0c\u63ed\u793a\u5176\u53ef\u9760\u6027\u74f6\u9888\u7531\u6a21\u578b\u8f6c\u5411\u90e8\u7f72\u7cfb\u7edf\uff0c\u63d0\u51fa\u5173\u952e\u73b0\u8c61\u5e76\u63d0\u4f9b\u6539\u5584\u65b9\u5411\u3002", "motivation": "\u5f00\u6e90LLM\u5141\u8bb8\u7528\u6237\u5728\u672c\u5730\u57fa\u7840\u8bbe\u65bd\u4e0a\u90e8\u7f72\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7528\u6237\u7ba1\u7406\u7684\u90e8\u7f72\u53ef\u9760\u6027\u7684\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5bf9705\u4e2a\u5f00\u6e90LLM\uff08DeepSeek\u3001Llama\u548cQwen\uff09\u5b9e\u9645\u5931\u8d25\u6848\u4f8b\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u53d1\u73b0\u4e09\u5927\u73b0\u8c61\uff1a\u8bca\u65ad\u5206\u6b67\uff08\u8fd0\u884c\u65f6\u5d29\u6e83\u8868\u5f81\u57fa\u7840\u8bbe\u65bd\u95ee\u9898\uff0c\u529f\u80fd\u9519\u8bef\u6307\u5411\u5206\u8bcd\u5668\u7f3a\u9677\uff09\u3001\u7cfb\u7edf\u540c\u8d28\u6027\uff08\u591a\u6a21\u578b\u5171\u4eab\u751f\u6001\u7cfb\u7edf\u7684\u5171\u6027\u95ee\u9898\uff09\u3001\u751f\u547d\u5468\u671f\u5347\u7ea7\uff08\u90e8\u7f72\u96be\u9898\u4ece\u5fae\u8c03\u914d\u7f6e\u5ef6\u4f38\u5230\u63a8\u7406\u73af\u5883\u4e0d\u517c\u5bb9\uff09\u3002\u6570\u636e\u96c6\u516c\u5f00\uff0c\u6307\u5bfc\u63d0\u5347LLM\u90e8\u7f72\u53ef\u9760\u6027\u3002", "conclusion": "\u7528\u6237\u81ea\u4e3b\u90e8\u7f72\u7684\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53ef\u9760\u6027\u95ee\u9898\u4ece\u6a21\u578b\u7b97\u6cd5\u7f3a\u9677\u8f6c\u5411\u90e8\u7f72\u7cfb\u7edf\u7684\u8106\u5f31\u6027\u3002"}}
{"id": "2601.12154", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12154", "abs": "https://arxiv.org/abs/2601.12154", "authors": ["Teodor-C\u0103lin Ionescu", "Lifeng Han", "Jan Heijdra Suasnabar", "Anne Stiggelbout", "Suzan Verberne"], "title": "Analyzing Cancer Patients' Experiences with Embedding-based Topic Modeling and LLMs", "comment": "under review to CLIN journal", "summary": "This study investigates the use of neural topic modeling and LLMs to uncover meaningful themes from patient storytelling data, to offer insights that could contribute to more patient-oriented healthcare practices. We analyze a collection of transcribed interviews with cancer patients (132,722 words in 13 interviews). We first evaluate BERTopic and Top2Vec for individual interview summarization by using similar preprocessing, chunking, and clustering configurations to ensure a fair comparison on Keyword Extraction. LLMs (GPT4) are then used for the next step topic labeling. Their outputs for a single interview (I0) are rated through a small-scale human evaluation, focusing on {coherence}, {clarity}, and {relevance}. Based on the preliminary results and evaluation, BERTopic shows stronger performance and is selected for further experimentation using three {clinically oriented embedding} models. We then analyzed the full interview collection with the best model setting. Results show that domain-specific embeddings improved topic \\textit{precision} and \\textit{interpretability}, with BioClinicalBERT producing the most consistent results across transcripts. The global analysis of the full dataset of 13 interviews, using the BioClinicalBERT embedding model, reveals the most dominant topics throughout all 13 interviews, namely ``Coordination and Communication in Cancer Care Management\" and ``Patient Decision-Making in Cancer Treatment Journey''. Although the interviews are machine translations from Dutch to English, and clinical professionals are not involved in this evaluation, the findings suggest that neural topic modeling, particularly BERTopic, can help provide useful feedback to clinicians from patient interviews. This pipeline could support more efficient document navigation and strengthen the role of patients' voices in healthcare workflows.", "AI": {"tldr": "\u672c\u6587\u4f7f\u7528BERTopic\u548cGPT-4\uff0c\u4ece\u764c\u75c7\u60a3\u8005\u8bbf\u8c08\u6587\u672c\u4e2d\u62bd\u53d6\u4e3b\u8bdd\u9898\uff0c\u7ed3\u5408BioClinicalBERT\u5d4c\u5165\u6a21\u578b\u63d0\u5347\u8bdd\u9898\u8d28\u91cf\uff0c\u63ed\u793a\u4e86\u60a3\u8005\u5173\u5fc3\u7684\u764c\u75c7\u62a4\u7406\u534f\u8c03\u53ca\u51b3\u7b56\u4e3b\u9898\uff0c\u8868\u660e\u6b64\u6280\u672f\u53ef\u52a9\u529b\u5f3a\u5316\u60a3\u8005\u58f0\u97f3\uff0c\u4fc3\u8fdb\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u5b9e\u8df5\u3002", "motivation": "\u65e8\u5728\u901a\u8fc7\u5206\u6790\u60a3\u8005\u8bb2\u8ff0\u6570\u636e\uff0c\u63d0\u53d6\u80fd\u53cd\u6620\u60a3\u8005\u771f\u5b9e\u4f53\u9a8c\u548c\u8bc9\u6c42\u7684\u4e3b\u9898\uff0c\u4ee5\u652f\u6301\u66f4\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u5b9e\u8df5\uff0c\u589e\u5f3a\u60a3\u8005\u5728\u533b\u7597\u670d\u52a1\u4e2d\u7684\u58f0\u97f3\uff0c\u5e76\u5e2e\u52a9\u4e34\u5e8a\u533b\u5e08\u66f4\u9ad8\u6548\u5730\u7406\u89e3\u60a3\u8005\u9700\u6c42\u3002", "method": "\u5bf913\u4e2a\u764c\u75c7\u60a3\u8005\u7684\u8f6c\u5f55\u8bbf\u8c08\u6587\u672c\u8fdb\u884c\u9884\u5904\u7406\u3001\u5206\u5757\u548c\u805a\u7c7b\uff0c\u6bd4\u8f83BERTopic\u548cTop2Vec\u4e24\u79cd\u795e\u7ecf\u8bdd\u9898\u6a21\u578b\u7684\u5173\u952e\u8bcd\u63d0\u53d6\u6027\u80fd\u3002\u968f\u540e\uff0c\u4f7f\u7528GPT-4\u5bf9\u8bdd\u9898\u8fdb\u884c\u6807\u6ce8\uff0c\u5e76\u901a\u8fc7\u4eba\u5de5\u8bc4\u4ef7\u8fdb\u884c\u8d28\u91cf\u8bc4\u5b9a\u3002\u57fa\u4e8e\u8bc4\u4ef7\u7ed3\u679c\uff0c\u9009\u62e9BERTopic\u7ed3\u5408\u4e09\u79cd\u4e34\u5e8a\u9886\u57df\u5d4c\u5165\u6a21\u578b\u4e2d\u7684\u6700\u4f73\u6a21\u578b(BioClinicalBERT)\u5bf9\u5168\u90e8\u8bbf\u8c08\u6587\u672c\u8fdb\u884c\u5168\u5c40\u8bdd\u9898\u5206\u6790\u3002", "result": "BERTopic\u6574\u4f53\u8868\u73b0\u4f18\u4e8eTop2Vec\uff0c\u7ed3\u5408BioClinicalBERT\u7684\u9886\u57df\u7279\u5b9a\u5d4c\u5165\u6a21\u578b\u80fd\u63d0\u9ad8\u8bdd\u9898\u7684\u7cbe\u51c6\u5ea6\u548c\u4e00\u81f4\u6027\u3002\u5168\u5c40\u5206\u6790\u53d1\u73b0\u201c\u764c\u75c7\u62a4\u7406\u7ba1\u7406\u4e2d\u7684\u534f\u8c03\u4e0e\u6c9f\u901a\u201d\u548c\u201c\u764c\u75c7\u6cbb\u7597\u8fc7\u7a0b\u4e2d\u7684\u60a3\u8005\u51b3\u7b56\u201d\u662f\u8d2f\u7a7f\u6240\u6709\u8bbf\u8c08\u7684\u4e3b\u8981\u8bdd\u9898\u3002\u5c3d\u7ba1\u6570\u636e\u7ffb\u8bd1\u548c\u672a\u6d89\u53ca\u4e34\u5e8a\u4e13\u5bb6\u8bc4\u4f30\u5b58\u5728\u9650\u5236\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5177\u5907\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u57fa\u4e8e\u795e\u7ecf\u8bdd\u9898\u5efa\u6a21\uff08\u5c24\u5176\u662fBERTopic\uff09\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4\uff09\uff0c\u672c\u6587\u5c55\u793a\u4e86\u4ece\u764c\u75c7\u60a3\u8005\u8bb2\u8ff0\u6570\u636e\u4e2d\u63d0\u53d6\u6709\u610f\u4e49\u4e3b\u9898\u7684\u6709\u6548\u65b9\u6cd5\uff0c\u4e14\u5229\u7528\u9886\u57df\u7279\u5b9a\u7684\u5d4c\u5165\u6a21\u578b\uff08BioClinicalBERT\uff09\u63d0\u5347\u4e86\u4e3b\u9898\u7684\u7cbe\u51c6\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u53ef\u4e3a\u4e34\u5e8a\u533b\u751f\u63d0\u4f9b\u6709\u4ef7\u503c\u7684\u60a3\u8005\u53cd\u9988\uff0c\u4fc3\u8fdb\u4ee5\u60a3\u8005\u4e3a\u4e2d\u5fc3\u7684\u533b\u7597\u5b9e\u8df5\u3002"}}
{"id": "2601.13682", "categories": ["cs.SE", "cs.PL"], "pdf": "https://arxiv.org/pdf/2601.13682", "abs": "https://arxiv.org/abs/2601.13682", "authors": ["Jianfeng Cai", "Jinhua Zhu", "Ruopei Sun", "Kangwen Zhao", "Dongyun Xue", "Mingxiao Feng", "Wengang Zhou", "Houqiang Li"], "title": "CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation", "comment": null, "summary": "The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \\times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\\%$ and True Negative Rate (TNR) of $90.89\\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\\%$ and $9.37\\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53cd\u9988\u9a71\u52a8\u7684\u8fed\u4ee3\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u9ad8\u8d28\u91cf\u7f16\u7a0b\u7ade\u8d5b\u6d4b\u8bd5\u7528\u4f8b\uff0c\u663e\u8457\u63d0\u5347\u9a8c\u8bc1\u51c6\u786e\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u516c\u5f00\u4e86\u6570\u636e\u96c6\u548c\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21\u53ef\u9a8c\u8bc1\u6570\u636e\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u4f18\u8d28\u3001\u5177\u6709\u9274\u522b\u80fd\u529b\u7684\u7f16\u7a0b\u7ade\u8d5b\u6d4b\u8bd5\u7528\u4f8b\u7a00\u7f3a\uff0c\u800c\u4ec5\u4f9d\u8d56LLM\u672c\u8eab\u751f\u6210\u80fd\u529b\u96be\u4ee5\u83b7\u5f97\u8db3\u591f\u591a\u6837\u548c\u7cbe\u51c6\u7684\u7528\u4f8b\u3002", "method": "\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u521d\u59cb\u6d4b\u8bd5\u7528\u4f8b\uff0c\u901a\u8fc7\u6267\u884c\u8fd9\u4e9b\u7528\u4f8b\u5728\u6b63\u786e\u548c\u9519\u8bef\u89e3\u6cd5\u4e0a\u7684\u7ed3\u679c\u53cd\u9988\uff0c\u8fed\u4ee3\u4f18\u5316\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4f7f\u5176\u5728\u533a\u5206\u80fd\u529b\u548c\u53ef\u4fe1\u5ea6\u4e0a\u5f97\u5230\u63d0\u5347\u3002", "result": "\u751f\u6210\u4e86\u4f18\u5316\u540e\u7684\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u6570\u636e\u96c6CodeContests-O\uff0c\u5728\u6d77\u91cf\u89e3\u6cd5\u8bc4\u6d4b\u4e2d\u8fbe\u5230\u63a5\u8fd190%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u539f\u6570\u636e\u96c64-9\u4e2a\u767e\u5206\u70b9\uff0c\u4e14\u5fae\u8c03\u6a21\u578b\u5728\u771f\u5b9e\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u63d0\u5347\u8fd110%\u3002", "conclusion": "\u6211\u4eec\u63d0\u51fa\u7684\u53cd\u9988\u9a71\u52a8\u8fed\u4ee3\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u7f16\u7a0b\u7ade\u8d5b\u6d4b\u8bd5\u7528\u4f8b\u7684\u8d28\u91cf\u548c\u591a\u6837\u6027\uff0c\u6027\u80fd\u8fdc\u8d85\u73b0\u6709\u6570\u636e\u96c6\uff0c\u5e76\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6267\u884c\u6548\u679c\u3002"}}
{"id": "2601.12179", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12179", "abs": "https://arxiv.org/abs/2601.12179", "authors": ["Adam E. Friedman", "Stevan Harnad", "Rushen Shi"], "title": "Tolerance Principle and Small Language Model Learning", "comment": "14 pages, 6 figures. BUCLD 50 Proceedings. To be published in 2026 by Cascadilla Press", "summary": "Modern language models like GPT-3, BERT, and LLaMA require massive training data, yet with sufficient training they reliably learn to distinguish grammatical from ungrammatical sentences. Children aged as young as 14 months already have the capacity to learn abstract grammar rules from very few exemplars, even in the presence of non-rule-following exceptions. Yang's (2016) Tolerance Principle defines a precise threshold for how many exceptions a rule can tolerate and still be learnable. The present study explored the minimal amount and quality of training data necessary for rules to be generalized by a transformer-based language model to test the predictions of the Tolerance Principle. We trained BabyBERTa (Huebner et al. 2021), a transformer model optimized for small datasets, on artificial grammars. The training sets varied in size, number of unique sentence types, and proportion of rule-following versus exception exemplars. We found that, unlike human infants, BabyBERTa's learning dynamics do not align with the Tolerance Principle.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u57fa\u4e8e\u53d8\u6362\u5668\u7684BabyBERTa\u6a21\u578b\u5728\u5c11\u91cf\u6570\u636e\u8bad\u7ec3\u4e0b\u65e0\u6cd5\u50cf\u5e7c\u513f\u90a3\u6837\u4f9d\u636e\u5bb9\u5fcd\u539f\u5219\u5b66\u4e60\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\u3002", "motivation": "\u63a2\u7d22\u5728\u4ec5\u6709\u5c11\u91cf\u8bad\u7ec3\u6570\u636e\u65f6\uff0c\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u8bed\u8a00\u6a21\u578b\u662f\u5426\u80fd\u50cf\u5e7c\u513f\u4e00\u6837\u6839\u636e\u5bb9\u5fcd\u539f\u5219\u5b66\u4e60\u548c\u63a8\u5e7f\u62bd\u8c61\u8bed\u6cd5\u89c4\u5219\u3002", "method": "\u4f7f\u7528\u4f18\u5316\u5c0f\u6570\u636e\u96c6\u7684\u53d8\u6362\u5668\u6a21\u578bBabyBERTa\uff0c\u5728\u4eba\u5de5\u8bbe\u8ba1\u7684\u8bed\u6cd5\u6570\u636e\u4e0a\u8bad\u7ec3\uff0c\u63a7\u5236\u8bad\u7ec3\u96c6\u5927\u5c0f\u3001\u53e5\u5b50\u7c7b\u578b\u6570\u91cf\u4ee5\u53ca\u89c4\u5219\u9075\u5faa\u548c\u4f8b\u5916\u6bd4\u4f8b\u3002", "result": "\u53d1\u73b0BabyBERTa\u65e0\u6cd5\u50cf14\u4e2a\u6708\u5927\u7684\u513f\u7ae5\u90a3\u6837\u4f9d\u636e\u5bb9\u5fcd\u539f\u5219\u6709\u6548\u5b66\u4e60\u89c4\u5219\uff0c\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u5b66\u4e60\u52a8\u6001\u3002", "conclusion": "BabyBERTa\u7684\u5b66\u4e60\u52a8\u6001\u4e0e\u5bb9\u5fcd\u539f\u5219\u4e0d\u7b26\uff0c\u5373\u5176\u5728\u89c4\u5219\u63a8\u5e7f\u4e2d\u7684\u8868\u73b0\u4e0d\u7b26\u5408\u8be5\u7406\u8bba\u7684\u9884\u6d4b\u3002"}}
{"id": "2601.13713", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13713", "abs": "https://arxiv.org/abs/2601.13713", "authors": ["Aditya Bharat Soni", "Rajat Ghosh", "Vaishnavi Bhargava", "Valerie Chen", "Debojyoti Dutta"], "title": "SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories", "comment": null, "summary": "Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- \"test first, write code later\", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\\% in success rate and 21\\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSWE-Tester\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u5927\u89c4\u6a21\u5f00\u6e90\u6570\u636e\u8bad\u7ec3\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u81ea\u52a8\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4fc3\u8fdb\u6d4b\u8bd5\u9a71\u52a8\u5f00\u53d1\u548c\u81ea\u52a8\u5316\u95ee\u9898\u4fee\u590d\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u52a8\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u7684\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u95ed\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u7f3a\u4e4f\u5bf9\u5f00\u6e90\u6a21\u578b\u7684\u7814\u7a76\u3002\u4e3a\u63a2\u7d22\u5f00\u6e90\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u65b0\u7684\u8bad\u7ec3\u548c\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4ece2600\u4e2a\u5f00\u6e90GitHub\u4ed3\u5e93\u4e2d\u6536\u96c641000\u4e2a\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6837\u672c\uff0c\u8bad\u7ec3\u4e0d\u540c\u89c4\u6a21\u548c\u7c7b\u578b\u7684\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6784\u5efaSWE-Tester\u6d41\u6c34\u7ebf\uff0c\u5e76\u5728SWT-Bench Verified\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728SWT-Bench Verified\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u9ad810%\u7684\u6210\u529f\u7387\u63d0\u5347\u548c21%\u7684\u53d8\u66f4\u8986\u76d6\u7387\u63d0\u5347\u3002\u5206\u6790\u8fd8\u663e\u793a\u589e\u52a0\u63a8\u7406\u8ba1\u7b97\u91cf\u3001\u8bad\u7ec3\u6570\u636e\u548c\u6a21\u578b\u89c4\u6a21\u5747\u5e26\u6765\u7a33\u5b9a\u63d0\u5347\u3002", "conclusion": "SWE-Tester\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u95ee\u9898\u590d\u73b0\u6d4b\u8bd5\u65b9\u9762\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5f00\u6e90\u6a21\u578b\u5728\u8be5\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.12199", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12199", "abs": "https://arxiv.org/abs/2601.12199", "authors": ["Muhammad Umar Farooq", "Oscar Saz"], "title": "CTC-DID: CTC-Based Arabic dialect identification for streaming applications", "comment": "Accepted for IEEE ICASSP 2026", "summary": "This paper proposes a Dialect Identification (DID) approach inspired by the Connectionist Temporal Classification (CTC) loss function as used in Automatic Speech Recognition (ASR). CTC-DID frames the dialect identification task as a limited-vocabulary ASR system, where dialect tags are treated as a sequence of labels for a given utterance. For training, the repetition of dialect tags in transcriptions is estimated either using a proposed Language-Agnostic Heuristic (LAH) approach or a pre-trained ASR model. The method is evaluated on the low-resource Arabic Dialect Identification (ADI) task, with experimental results demonstrating that an SSL-based CTC-DID model, trained on a limited dataset, outperforms both fine-tuned Whisper and ECAPA-TDNN models. Notably, CTC-DID also surpasses these models in zero-shot evaluation on the Casablanca dataset. The proposed approach is found to be more robust to shorter utterances and is shown to be easily adaptable for streaming, real-time applications, with minimal performance degradation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eCTC\u635f\u5931\u7684\u65b9\u8a00\u8bc6\u522b\u65b9\u6cd5\uff0c\u5728\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\uff0c\u8868\u73b0\u7a33\u5b9a\u4e14\u9002\u7528\u4e8e\u5b9e\u65f6\u5e94\u7528\u3002", "motivation": "\u89e3\u51b3\u4f4e\u8d44\u6e90\u963f\u62c9\u4f2f\u65b9\u8a00\u8bc6\u522b\u4efb\u52a1\uff0c\u63d0\u5347\u65b9\u8a00\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u5b9e\u65f6\u6027\u3002", "method": "\u63d0\u51fa\u5c06\u65b9\u8a00\u8bc6\u522b\u89c6\u4e3a\u6709\u9650\u8bcd\u6c47\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u95ee\u9898\uff0c\u5229\u7528CTC\u635f\u5931\u51fd\u6570\u8fdb\u884c\u8bad\u7ec3\uff1b\u91c7\u7528\u8bed\u8a00\u65e0\u5173\u542f\u53d1\u5f0f\u65b9\u6cd5\u6216\u9884\u8bad\u7ec3ASR\u6a21\u578b\u4f30\u8ba1\u8f6c\u5f55\u4e2d\u65b9\u8a00\u6807\u7b7e\u7684\u91cd\u590d\u3002", "result": "\u57fa\u4e8eSSL\u7684CTC-DID\u6a21\u578b\u5728\u6709\u9650\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5fae\u8c03\u7684Whisper\u548cECAPA-TDNN\u6a21\u578b\uff0c\u5728Casablanca\u96f6-shot\u6d4b\u8bd5\u4e2d\u8868\u73b0\u66f4\u4f73\uff0c\u5bf9\u77ed\u8bed\u97f3\u9c81\u68d2\u4e14\u9002\u5408\u5b9e\u65f6\u6d41\u5f0f\u5e94\u7528\u3002", "conclusion": "CTC-DID\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u65b9\u8a00\u8bc6\u522b\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u652f\u6301\u4f4e\u65f6\u5ef6\u5728\u7ebf\u5e94\u7528\u3002"}}
{"id": "2601.13743", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13743", "abs": "https://arxiv.org/abs/2601.13743", "authors": ["Zhenya Zhang", "Parv Kapoor", "Jie An", "Eunsuk Kang"], "title": "Counterexample Classification against Signal Temporal Logic Specifications", "comment": null, "summary": "Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePSTL\u7684\u53cd\u4f8b\u5206\u7c7b\u65b9\u6cd5\uff0c\u901a\u8fc7\u53c2\u6570\u641c\u7d22\u548c\u7c7b\u5305\u542b\u5173\u7cfb\u4f18\u5316\u63d0\u5347\u5206\u7c7b\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "STL\u53cd\u4f8b\u53ef\u80fd\u7531\u4e0d\u540c\u539f\u56e0\u5f15\u8d77\uff0c\u5173\u8054\u4e0d\u540c\u7684\u7cfb\u7edf\u7f3a\u9677\uff1b\u5bf9\u53cd\u4f8b\u8fdb\u884c\u5408\u7406\u5206\u7c7b\u80fd\u5e2e\u52a9\u7406\u89e3\u8fdd\u53cd\u6a21\u5f0f\u53ca\u5176\u5206\u5e03\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5b9a\u4f4d\u548c\u4fee\u6b63\u7cfb\u7edf\u7f3a\u9677\u3002", "method": "\u901a\u8fc7\u5229\u7528PSTL\u8868\u8fbe\u6bcf\u4e2a\u53cd\u4f8b\u7c7b\u522b\uff0c\u5bfb\u627e\u5408\u9002\u7684\u53c2\u6570\u503c\u6765\u5206\u7c7b\u53cd\u4f8b\uff1b\u8fdb\u4e00\u6b65\u901a\u8fc7\u63a8\u5bfc\u7c7b\u95f4\u5305\u542b\u5173\u7cfb\uff0c\u8bbe\u8ba1\u4e86\u7c7b\u4f3c\u4e8c\u5206\u641c\u7d22\u7684\u7b56\u7565\u51cf\u5c11\u67e5\u8be2\u7684\u7c7b\u522b\u6570\uff0c\u63d0\u5347\u5206\u7c7b\u6548\u7387\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u539f\u578b\u5de5\u5177\uff0c\u5e76\u5728\u4e24\u4e2a\u5e7f\u6cdb\u7814\u7a76\u7684\u7cfb\u7edf\u4e0a\u8fdb\u884c\u4e86\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u53cd\u4f8b\u5206\u7c7b\u548c\u6548\u7387\u4f18\u5316\u4e0a\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53c2\u6570\u5316\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(PSTL)\u7684\u53cd\u4f8b\u5206\u7c7b\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u548c\u5206\u7c7b\u6df7\u5408\u7cfb\u7edf\u4e2d\u8fdd\u53cdSTL\u89c4\u8303\u7684\u53cd\u4f8b\uff0c\u63d0\u5347\u4e86\u53cd\u4f8b\u5206\u6790\u7684\u7cbe\u786e\u5ea6\u548c\u6548\u7387\u3002"}}
{"id": "2601.12208", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12208", "abs": "https://arxiv.org/abs/2601.12208", "authors": ["Yunzhe Li", "Richie Yueqi Feng", "Tianxin Wei", "Chin-Chia Hsu"], "title": "CoReflect: Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement", "comment": null, "summary": "Evaluating conversational systems in multi-turn settings remains a fundamental challenge. Conventional pipelines typically rely on manually defined rubrics and fixed conversational context$-$a static approach that limits coverage and fails to capture the diverse, emergent behaviors of dialogue models. To address this, we introduce CoReflect (Conversational Evaluation via Co-Evolutionary Simulation and Reflective Rubric Refinement), which unifies dialogue simulation and evaluation into an adaptive, iterative process. CoReflect employs a conversation planner that generates structured templates to guide a user simulator through diverse, goal-directed dialogues. Subsequently, a reflective analyzer processes these dialogues to identify systematic behavioral patterns and automatically refine the evaluation rubrics. Crucially, the insights from the conversation analysis are fed back into the planner to update conversation templates for subsequent iterations. This co-evolution loop ensures that the complexity of test cases and the diagnostic precision of rubrics improve in tandem. By minimizing human intervention, CoReflect provides a scalable and self-refining methodology that allows evaluation protocols to adapt alongside the rapidly advancing capabilities of dialogue models.", "AI": {"tldr": "CoReflect\u901a\u8fc7\u5bf9\u8bdd\u6a21\u62df\u4e0e\u53cd\u601d\u5206\u6790\u7684\u8fed\u4ee3\u5171\u8fdb\u5316\uff0c\u5b9e\u73b0\u4e86\u591a\u8f6e\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u6d4b\u7684\u81ea\u52a8\u5316\u548c\u52a8\u6001\u4f18\u5316\uff0c\u6709\u6548\u9002\u5e94\u4e86\u5bf9\u8bdd\u6a21\u578b\u7684\u5feb\u901f\u8fdb\u5316\u3002", "motivation": "\u4f20\u7edf\u591a\u8f6e\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u6d4b\u4f9d\u8d56\u9759\u6001\u548c\u624b\u5de5\u5b9a\u4e49\u7684\u6807\u51c6\uff0c\u96be\u4ee5\u8986\u76d6\u591a\u6837\u5316\u884c\u4e3a\uff0c\u4e14\u65e0\u6cd5\u9002\u5e94\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5bf9\u8bdd\u89c4\u5212\u5668\u751f\u6210\u7ed3\u6784\u5316\u6a21\u677f\u5f15\u5bfc\u7528\u6237\u6a21\u62df\uff0c\u968f\u540e\u5229\u7528\u53cd\u601d\u5206\u6790\u5668\u81ea\u52a8\u8bc6\u522b\u5bf9\u8bdd\u884c\u4e3a\u5e76\u4f18\u5316\u8bc4\u6d4b\u6807\u51c6\uff0c\u5f62\u6210\u5bf9\u8bdd\u89c4\u5212\u4e0e\u8bc4\u6d4b\u6807\u51c6\u7684\u5171\u8fdb\u5316\u5faa\u73af\u3002", "result": "CoReflect\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u51cf\u5c11\u4eba\u5de5\u5e72\u9884\u3001\u53ef\u6301\u7eed\u81ea\u6211\u4f18\u5316\u7684\u8bc4\u6d4b\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u7528\u4f8b\u7684\u590d\u6742\u5ea6\u548c\u8bc4\u6d4b\u6807\u51c6\u7684\u8bca\u65ad\u7cbe\u5ea6\u3002", "conclusion": "CoReflect\u5b9e\u73b0\u4e86\u5bf9\u591a\u8f6e\u5bf9\u8bdd\u7cfb\u7edf\u66f4\u52a8\u6001\u548c\u7cbe\u7ec6\u7684\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bc4\u6d4b\u4f53\u7cfb\u7684\u9002\u5e94\u6027\u548c\u8bca\u65ad\u80fd\u529b\u3002"}}
{"id": "2601.13754", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13754", "abs": "https://arxiv.org/abs/2601.13754", "authors": ["Haoyu Gao", "Peerachai Banyongrakkul", "Hao Guan", "Mansooreh Zahedi", "Christoph Treude"], "title": "On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source", "comment": "accepted as MSR short paper", "summary": "Large Language Models (LLMs) increasingly automate software engineering tasks. While recent studies highlight the accelerated adoption of ``AI as a teammate'' in Open Source Software (OSS), developer interaction patterns remain under-explored. In this work, we investigated project-level guidelines and developers' interactions with AI-assisted pull requests (PRs) by expanding the AIDev dataset to include finer-grained contributor code ownership and a comparative baseline of human-created PRs. We found that over 67.5\\% of AI-co-authored PRs originate from contributors without prior code ownership. Despite this, the majority of repositories lack guidelines for AI-coding agent usage. Notably, we observed a distinct interaction pattern: AI-co-authored PRs are merged significantly faster with minimal feedback. In contrast to human-created PRs where non-owner developers receive the most feedback, AI-co-authored PRs from non-owners receive the least, with approximately 80\\% merged without any explicit review. Finally, we discuss implications for developers and researchers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793aAI\u534f\u4f5c\u62c9\u53d6\u8bf7\u6c42\u4e3b\u8981\u7531\u65e0\u4ee3\u7801\u6240\u6709\u6743\u7684\u8d21\u732e\u8005\u53d1\u8d77\uff0c\u7f3a\u4e4f\u6307\u5bfc\u4e14\u5408\u5e76\u901f\u5ea6\u5feb\u53cd\u9988\u5c11\uff0c\u5c55\u73b0\u4e86\u4e0e\u4f20\u7edf\u4eba\u7c7bPR\u4e0d\u540c\u7684\u5f00\u53d1\u8005\u4ea4\u4e92\u6a21\u5f0f\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u65e5\u76ca\u589e\u591a\uff0c\u4f46\u5bf9\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u2018AI\u4f5c\u4e3a\u961f\u53cb\u2019\u7684\u5f00\u53d1\u8005\u4ea4\u4e92\u6a21\u5f0f\u7814\u7a76\u4e0d\u8db3\uff0c\u56e0\u6b64\u63a2\u8ba8AI\u8f85\u52a9PR\u7684\u8d21\u732e\u8005\u7279\u70b9\u548c\u4ea4\u4e92\u60c5\u51b5\u3002", "method": "\u901a\u8fc7\u6269\u5c55AIDev\u6570\u636e\u96c6\uff0c\u52a0\u5165\u8d21\u732e\u8005\u4ee3\u7801\u6240\u6709\u6743\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\uff0c\u5e76\u4e0e\u4eba\u7c7b\u521b\u5efa\u7684PR\u8fdb\u884c\u6bd4\u8f83\uff0c\u5206\u6790\u9879\u76ee\u5c42\u9762\u7684\u6307\u5357\u53ca\u5f00\u53d1\u8005\u5bf9AI\u8f85\u52a9PR\u7684\u4e92\u52a8\u6a21\u5f0f\u3002", "result": "\u53d1\u73b0\u8d85\u8fc767.5%\u7684AI\u534f\u4f5cPR\u6765\u81ea\u65e0\u4ee3\u7801\u6240\u6709\u6743\u7684\u8d21\u732e\u8005\uff0c\u4e1480%\u7684\u6b64\u7c7bPR\u5728\u6ca1\u6709\u660e\u786e\u8bc4\u5ba1\u7684\u60c5\u51b5\u4e0b\u88ab\u5408\u5e76\u3002\u6b64\u5916\uff0c\u5927\u591a\u6570\u4ed3\u5e93\u7f3a\u4e4f\u9488\u5bf9AI\u7f16\u7801\u4ee3\u7406\u7684\u4f7f\u7528\u6307\u5357\u3002", "conclusion": "AI\u534f\u52a9\u751f\u6210\u7684\u62c9\u53d6\u8bf7\u6c42\uff08PR\uff09\u6765\u81ea\u5927\u591a\u6570\u6ca1\u6709\u5148\u524d\u4ee3\u7801\u6240\u6709\u6743\u7684\u8d21\u732e\u8005\uff0c\u4e14\u901a\u5e38\u5728\u7f3a\u4e4f\u660e\u786e\u6307\u5357\u7684\u4ed3\u5e93\u4e2d\u5feb\u901f\u5408\u5e76\u4e14\u53cd\u9988\u8f83\u5c11\uff0c\u663e\u793a\u51fa\u4e0e\u4f20\u7edf\u4eba\u7c7bPR\u4e0d\u540c\u7684\u4ea4\u4e92\u6a21\u5f0f\u3002"}}
{"id": "2601.12247", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12247", "abs": "https://arxiv.org/abs/2601.12247", "authors": ["Miao Li", "Hanyang Jiang", "Sikai Chen", "Hengyu Fu", "Yuhang Cai", "Baihe Huang", "Tinghan Ye", "Xuanzhou Chen", "Pascal Van Hentenryck"], "title": "Plan, Verify and Fill: A Structured Parallel Decoding Approach for Diffusion Language Models", "comment": null, "summary": "Diffusion Language Models (DLMs) present a promising non-sequential paradigm for text generation, distinct from standard autoregressive (AR) approaches. However, current decoding strategies often adopt a reactive stance, underutilizing the global bidirectional context to dictate global trajectories. To address this, we propose Plan-Verify-Fill (PVF), a training-free paradigm that grounds planning via quantitative validation. PVF actively constructs a hierarchical skeleton by prioritizing high-leverage semantic anchors and employs a verification protocol to operationalize pragmatic structural stopping where further deliberation yields diminishing returns. Extensive evaluations on LLaDA-8B-Instruct and Dream-7B-Instruct demonstrate that PVF reduces the Number of Function Evaluations (NFE) by up to 65% compared to confidence-based parallel decoding across benchmark datasets, unlocking superior efficiency without compromising accuracy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684PVF\u65b9\u6cd5\u901a\u8fc7\u89c4\u5212\u4e0e\u9a8c\u8bc1\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u6548\u7387\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u5f00\u9500\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u7b56\u7565\u672a\u80fd\u5145\u5206\u5229\u7528\u5168\u5c40\u53cc\u5411\u4e0a\u4e0b\u6587\u6765\u6307\u5bfc\u751f\u6210\u8def\u5f84\uff0c\u6548\u7387\u548c\u6548\u679c\u6709\u5f85\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86Plan-Verify-Fill (PVF)\u65b9\u6cd5\uff0c\u901a\u8fc7\u91cf\u5316\u9a8c\u8bc1\u8fdb\u884c\u89c4\u5212\uff0c\u4e3b\u52a8\u6784\u5efa\u5c42\u6b21\u5316\u7684\u9aa8\u67b6\u7ed3\u6784\uff0c\u4f18\u5148\u8003\u8651\u5173\u952e\u8bed\u4e49\u951a\u70b9\uff0c\u5e76\u91c7\u7528\u9a8c\u8bc1\u534f\u8bae\u786e\u5b9a\u4f55\u65f6\u505c\u6b62\u8fdb\u4e00\u6b65\u63a8\u7406\u3002", "result": "\u5728LLaDA-8B-Instruct\u548cDream-7B-Instruct\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cPVF\u76f8\u6bd4\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5e76\u884c\u89e3\u7801\uff0c\u80fd\u591f\u51cf\u5c11\u9ad8\u8fbe65%\u7684\u51fd\u6570\u8c03\u7528\u6b21\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u751f\u6210\u6587\u672c\u7684\u51c6\u786e\u6027\u3002", "conclusion": "PVF\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u4e86\u6269\u6563\u8bed\u8a00\u6a21\u578b\u7684\u89e3\u7801\u6548\u7387\uff0c\u901a\u8fc7\u7ed3\u6784\u6027\u89c4\u5212\u548c\u9a8c\u8bc1\u7b56\u7565\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u8ba1\u7b97\u8d44\u6e90\u5229\u7528\uff0c\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13772", "categories": ["cs.SE", "cs.DC", "cs.SI", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.13772", "abs": "https://arxiv.org/abs/2601.13772", "authors": ["Matteo Vaccargiu", "Azmat Ullah", "Pierluigi Gallo"], "title": "A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems", "comment": "2026 IEEE International Conference on Software Analysis, Evolution and Reengineering - Companion (SANER-C) 9th International Workshop on Blockchain Oriented Software Engineering March 17-20, 2026 Limassol, Cyprus", "summary": "Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u5e76\u9a8c\u8bc1\u4e86\u4e00\u79cd\u7ed3\u5408IoT\u4e0e\u533a\u5757\u94fe\u7684\u5149\u4f0f\u78b3\u4fe1\u7528\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u4e2d\u5c0f\u578b\u8bbe\u65bd\u8ba4\u8bc1\u96be\u9898\uff0c\u7b26\u5408\u6b27\u6d32\u6807\u51c6\uff0c\u63d0\u5347\u78b3\u4fe1\u7528\u8ba4\u8bc1\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u73b0\u6709\u78b3\u4fe1\u7528\u8ba4\u8bc1\u673a\u5236\u5bf9\u4e2d\u5c0f\u578b\u53ef\u518d\u751f\u80fd\u6e90\u8bbe\u65bd\u652f\u6301\u6709\u9650\uff0c\u4e14\u7f3a\u4e4f\u7b26\u5408\u5b9e\u9645\u6cd5\u5f8b\u6cd5\u89c4\u8981\u6c42\u7684\u8ba4\u8bc1\u6d41\u7a0b\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u5b9e\u65f6\u7269\u8054\u7f51\u6570\u636e\u6536\u96c6\u3001\u8fb9\u7f18\u7ea7\u6570\u636e\u805a\u5408\u4ee5\u53ca\u57fa\u4e8e\u8bb8\u53ef\u94fe\u7684\u667a\u80fd\u5408\u7ea6\u5b89\u5168\u94fe\u4e0a\u5b58\u50a8\uff0c\u5b9e\u73b0\u5bf9100 kWp\u5149\u4f0f\u7cfb\u7edf\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u7ed3\u5408IoT\u548c\u533a\u5757\u94fe\u6280\u672f\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u7cfb\u7edf\uff0c\u4e3a\u5149\u4f0f\u8fd0\u8425\u5546\u63d0\u4f9b\u6e05\u6670\u7684\u8ba4\u8bc1\u8def\u5f84\u548c\u652f\u6301\u7b2c\u4e09\u65b9\u9a8c\u8bc1\u7684\u7ed3\u6784\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u533a\u5757\u94fe\u7684\u78b3\u4fe1\u7528\u8ba4\u8bc1\u67b6\u6784\u6709\u6548\u652f\u6301\u4e86\u4e2d\u5c0f\u89c4\u6a21\u5149\u4f0f\u53d1\u7535\u7684\u78b3\u51cf\u6392\u8ba4\u8bc1\uff0c\u7b26\u5408\u6b27\u6d32\u6cd5\u89c4\u548c\u81ea\u613f\u78b3\u5e02\u573a\u6807\u51c6\uff0c\u4fdd\u969c\u4e86\u6570\u636e\u7684\u771f\u5b9e\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\u3002"}}
{"id": "2601.12263", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12263", "abs": "https://arxiv.org/abs/2601.12263", "authors": ["Yixuan Du", "Chenxiao Yu", "Haoyan Xu", "Ziyi Wang", "Yue Zhao", "Xiyang Hu"], "title": "Multimodal Generative Engine Optimization: Rank Manipulation for Vision-Language Model Rankers", "comment": null, "summary": "Vision-Language Models (VLMs) are rapidly replacing unimodal encoders in modern retrieval and recommendation systems. While their capabilities are well-documented, their robustness against adversarial manipulation in competitive ranking scenarios remains largely unexplored. In this paper, we uncover a critical vulnerability in VLM-based product search: multimodal ranking attacks. We present Multimodal Generative Engine Optimization (MGEO), a novel adversarial framework that enables a malicious actor to unfairly promote a target product by jointly optimizing imperceptible image perturbations and fluent textual suffixes. Unlike existing attacks that treat modalities in isolation, MGEO employs an alternating gradient-based optimization strategy to exploit the deep cross-modal coupling within the VLM. Extensive experiments on real-world datasets using state-of-the-art models demonstrate that our coordinated attack significantly outperforms text-only and image-only baselines. These findings reveal that multimodal synergy, typically a strength of VLMs, can be weaponized to compromise the integrity of search rankings without triggering conventional content filters.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6a21\u6001\u4ea7\u54c1\u641c\u7d22\u4e2d\u5b58\u5728\u53ef\u88ab\u5229\u7528\u7684\u5b89\u5168\u9690\u60a3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u653b\u51fb\u56fe\u50cf\u548c\u6587\u672c\u7684\u65b0\u65b9\u6cd5MGEO\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6548\u679c\uff0c\u5a01\u80c1\u4e86\u641c\u7d22\u6392\u540d\u7684\u516c\u6b63\u6027\u3002", "motivation": "\u5f53\u524d\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u68c0\u7d22\u548c\u63a8\u8350\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u4f46\u5176\u5728\u5bf9\u6297\u64cd\u63a7\u548c\u9c81\u68d2\u6027\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u6d89\u53ca\u7ade\u4ef7\u6392\u540d\u7684\u591a\u6a21\u6001\u653b\u51fb\u95ee\u9898\u4e0a\u5c1a\u672a\u88ab\u6df1\u5165\u63a2\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u591a\u6a21\u6001\u751f\u6210\u5f15\u64ce\u4f18\u5316\uff08MGEO\uff09\u7684\u5bf9\u6297\u6846\u67b6\uff0c\u5229\u7528\u4ea4\u66ff\u7684\u68af\u5ea6\u4f18\u5316\u7b56\u7565\uff0c\u8054\u5408\u4f18\u5316\u56fe\u50cf\u548c\u6587\u672c\u4e24\u79cd\u6a21\u6001\u7684\u6270\u52a8\uff0c\u5145\u5206\u5229\u7528VLM\u4e2d\u7684\u8de8\u6a21\u6001\u6df1\u5ea6\u8026\u5408\u6027\u5b9e\u73b0\u653b\u51fb\u3002", "result": "\u5728\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u96c6\u548c\u6700\u5148\u8fdb\u6a21\u578b\u7684\u5b9e\u9a8c\u4e2d\uff0cMGEO\u6240\u8bbe\u8ba1\u7684\u653b\u51fb\u5927\u5e45\u5ea6\u4f18\u4e8e\u5355\u4e00\u6587\u672c\u6216\u5355\u4e00\u56fe\u50cf\u7684\u653b\u51fb\u57fa\u7ebf\uff0c\u4e14\u4e0d\u4f1a\u89e6\u53d1\u4f20\u7edf\u7684\u5185\u5bb9\u8fc7\u6ee4\u5668\u3002", "conclusion": "\u8bba\u6587\u63ed\u793a\u4e86\u57fa\u4e8e\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6a21\u6001\u4ea7\u54c1\u641c\u7d22\u5b58\u5728\u4e25\u91cd\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u5373\u591a\u6a21\u6001\u6392\u5e8f\u653b\u51fb\u3002\u653b\u51fb\u901a\u8fc7\u8054\u5408\u4f18\u5316\u56fe\u50cf\u5fae\u6270\u548c\u6587\u672c\u540e\u7f00\uff0c\u80fd\u663e\u8457\u63d0\u5347\u76ee\u6807\u4ea7\u54c1\u6392\u540d\uff0c\u7834\u574f\u641c\u7d22\u7ed3\u679c\u7684\u516c\u6b63\u6027\u3002"}}
{"id": "2601.13894", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13894", "abs": "https://arxiv.org/abs/2601.13894", "authors": ["Alisa Welter", "Christof Tinnes", "Sven Apel"], "title": "Multi-Location Software Model Completion", "comment": "Accepted at the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026) - Research Track", "summary": "In model-driven engineering and beyond, software models are key development artifacts. In practice, they often grow to substantial size and complexity, undergoing thousands of modifications over time due to evolution, refactoring, and maintenance. The rise of AI has sparked interest in how software modeling activities can be automated. Recently, LLM-based approaches for software model completion have been proposed, however, the state of the art supports only single-location model completion by predicting changes at a specific location. Going beyond, we aim to bridge the gap toward handling coordinated changes that span multiple locations across large, complex models. Specifically, we propose a novel global embedding-based next focus predictor, NextFocus, which is capable of multi-location model completion for the first time. The predictor consists of a neural network with an attention mechanism that is trained on historical software model evolution data. Starting from an existing change, it predicts further model elements to change, potentially spanning multiple parts of the model. We evaluate our approach on multi-location model changes that have actually been performed by developers in real-world projects. NextFocus achieves promising results for multi-location model completion, even when changes are heavily spread across the model. It achieves an average Precision@k score of 0.98 for $k \\leq 10$, significantly outperforming the three baseline approaches.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faNextFocus\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u5b9e\u73b0\u591a\u4f4d\u7f6e\u8f6f\u4ef6\u6a21\u578b\u81ea\u52a8\u5b8c\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u53ea\u80fd\u5355\u70b9\u9884\u6d4b\u7684\u5c40\u9650\uff0c\u5e76\u5728\u771f\u5b9e\u9879\u76ee\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edfAI\u8f85\u52a9\u7684\u8f6f\u4ef6\u6a21\u578b\u81ea\u52a8\u5b8c\u6210\u53ea\u652f\u6301\u5355\u4f4d\u7f6e\u9884\u6d4b\uff0c\u65e0\u6cd5\u6ee1\u8db3\u5b9e\u9645\u8f6f\u4ef6\u6a21\u578b\u591a\u4f4d\u7f6e\u534f\u8c03\u4fee\u6539\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5168\u5c40\u5d4c\u5165\u548c\u6ce8\u610f\u529b\u673a\u5236\u7684\u795e\u7ecf\u7f51\u7edcNextFocus\uff0c\u5229\u7528\u5386\u53f2\u8f6f\u4ef6\u6a21\u578b\u6f14\u5316\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u80fd\u591f\u4ece\u4e00\u6b21\u5df2\u6709\u4fee\u6539\u51fa\u53d1\u9884\u6d4b\u540e\u7eed\u76f8\u5173\u591a\u4e2a\u6a21\u578b\u5143\u7d20\u7684\u4fee\u6539\u3002", "result": "\u5728\u771f\u5b9e\u9879\u76ee\u7684\u591a\u4f4d\u7f6e\u6a21\u578b\u4fee\u6539\u4efb\u52a1\u4e2d\uff0cNextFocus\u5728Precision@k\u6307\u6807\u4e0a\u5e73\u5747\u8fbe\u52300.98\uff0c\u660e\u663e\u4f18\u4e8e\u4e09\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "NextFocus \u80fd\u6709\u6548\u9884\u6d4b\u591a\u4e2a\u4f4d\u7f6e\u7684\u6a21\u578b\u4fee\u6539\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u5355\u70b9\u4fee\u6539\u9884\u6d4b\u65b9\u6cd5\u3002"}}
{"id": "2601.12269", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12269", "abs": "https://arxiv.org/abs/2601.12269", "authors": ["Xucong Hu", "Jian-Qiao Zhu"], "title": "Simulated Annealing Enhances Theory-of-Mind Reasoning in Autoregressive Language Models", "comment": null, "summary": "Autoregressive language models are next-token predictors and have been criticized for only optimizing surface plausibility (i.e., local coherence) rather than maintaining correct latent-state representations (i.e., global coherence). Because Theory of Mind (ToM) tasks crucially depend on reasoning about latent mental states of oneself and others, such models are therefore often thought to fail at ToM. While post-training methods can improve ToM performance, we show that strong ToM capability can be recovered directly from the base model without any additional weight updates or verifications. Our approach builds on recent power-sampling methods (Karan & Du, 2025) that use Markov chain Monte Carlo (MCMC) to sample from sharpened sequence-level (rather than token-level) probability distributions of autoregressive language models. We further find that incorporating annealing, where the tempered distribution is gradually shifted from high to low temperature, substantially improves ToM performance over fixed-temperature power sampling. Together, these results suggest that sampling-based optimization provides a powerful way to extract latent capabilities from language models without retraining.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6539\u8fdb\u91c7\u6837\u65b9\u6cd5\uff0c\u4ece\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e2d\u65e0\u9700\u518d\u8bad\u7ec3\u5373\u53ef\u63d0\u53d6\u51fa\u826f\u597d\u7684Theory of Mind\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e3b\u8981\u4f18\u5316\u5c40\u90e8\u8fde\u8d2f\u6027\uff0c\u672a\u80fd\u6709\u6548\u7ef4\u62a4\u6f5c\u5728\u72b6\u6001\u8868\u793a\uff0c\u5bfc\u81f4\u5176\u5728Theory of Mind\u4efb\u52a1\u4e2d\u8868\u73b0\u8f83\u5dee\u3002", "method": "\u5229\u7528\u57fa\u4e8eMarkov\u94fe\u8499\u7279\u5361\u6d1b\uff08MCMC\uff09\u7684power-sampling\u65b9\u6cd5\uff0c\u4ece\u5e8f\u5217\u7ea7\u6982\u7387\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u5e76\u5f15\u5165\u9000\u706b\u8fc7\u7a0b\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "result": "\u53d1\u73b0\u901a\u8fc7power-sampling\u53ca\u9000\u706b\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728Theory of Mind\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u65e0\u9700\u6a21\u578b\u6743\u91cd\u66f4\u65b0\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u91c7\u6837\u7684\u65b9\u6cd5\u4f18\u5316\uff0c\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u5f3a\u5927\u7684Theory of Mind\u80fd\u529b\u3002"}}
{"id": "2601.13933", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13933", "abs": "https://arxiv.org/abs/2601.13933", "authors": ["Mingming Zhang", "Xu Wang", "Jian Zhang", "Xiangxin Meng", "Jiayi Zhang", "Chunming Hu"], "title": "VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution", "comment": null, "summary": "As software systems grow in complexity, security vulnerabilities have become increasingly prevalent, posing serious risks and economic costs. Although automated detection tools such as fuzzers have advanced considerably, effective resolution still often depends on human expertise. Existing automated vulnerability repair (AVR) methods rely heavily on manually provided annotations (e.g., fault locations or CWE labels), which are often difficult and time-consuming to obtain, while overlooking the rich, naturally embedded semantic context found in issue reports from developers.\n  In this paper, we present VulnResolver, the first LLM-based hybrid agent framework for automated vulnerability issue resolution. VulnResolver unites the adaptability of autonomous agents with the stability of workflow-guided repair through two specialized agents. The Context Pre-Collection Agent (CPCAgent) adaptively explores the repository to gather dependency and contextual information, while the Safety Property Analysis Agent (SPAAgent) generates and validates the safety properties violated by vulnerabilities. Together, these agents produce structured analyses that enrich the original issue reports, enabling more accurate vulnerability localization and patch generation.\n  Evaluations on the SEC-bench benchmark show that VulnResolver resolves 75% of issues on SEC-bench Lite, achieving the best resolution performance. On SEC-bench Full, VulnResolver also significantly outperforms the strongest baseline, the agent-based OpenHands, confirming its effectiveness. Overall, VulnResolver delivers an adaptive and security-aware framework that advances end-to-end automated vulnerability issue resolution through workflow stability and the specialized agents' capabilities in contextual reasoning and property-based analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684 VulnResolver \u6846\u67b6\u901a\u8fc7\u4e24\u4e2a\u4e13\u95e8\u667a\u80fd\u4f53\u7ed3\u5408\u5de5\u4f5c\u6d41\u5f15\u5bfc\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e LLM \u7684\u9ad8\u6548\u81ea\u52a8\u6f0f\u6d1e\u4fee\u590d\uff0c\u5728\u516c\u5f00\u57fa\u51c6\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u6f0f\u6d1e\u4fee\u590d\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u6ce8\u89e3\uff0c\u83b7\u53d6\u56f0\u96be\u4e14\u8017\u65f6\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u5f00\u53d1\u8005\u95ee\u9898\u62a5\u544a\u4e2d\u4e30\u5bcc\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "method": "VulnResolver \u91c7\u7528\u4e24\u4e2a\u4e13\u95e8\u7684\u667a\u80fd\u4f53\uff1a\u4e0a\u4e0b\u6587\u9884\u6536\u96c6\u667a\u80fd\u4f53\uff08CPCAgent\uff09\u7528\u4e8e\u81ea\u9002\u5e94\u5730\u6536\u96c6\u4f9d\u8d56\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5b89\u5168\u5c5e\u6027\u5206\u6790\u667a\u80fd\u4f53\uff08SPAAgent\uff09\u7528\u4e8e\u751f\u6210\u53ca\u9a8c\u8bc1\u88ab\u6f0f\u6d1e\u7834\u574f\u7684\u5b89\u5168\u5c5e\u6027\uff0c\u7ed3\u5408\u5de5\u4f5c\u6d41\u5f15\u5bfc\u7684\u4fee\u590d\u65b9\u5f0f\u3002", "result": "\u5728 SEC-bench \u8bc4\u6d4b\u4e2d\uff0cVulnResolver \u5728 SEC-bench Lite \u4e0a\u89e3\u51b3\u7387\u8fbe\u523075%\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u6700\u5f3a\u57fa\u7ebf OpenHands\uff0c\u5728 SEC-bench Full \u4e0a\u4e5f\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "VulnResolver \u63d0\u4f9b\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6df7\u5408\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u81ea\u52a8\u5316\u6f0f\u6d1e\u95ee\u9898\u89e3\u51b3\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u66f4\u51c6\u786e\u7684\u6f0f\u6d1e\u5b9a\u4f4d\u548c\u4fee\u590d\u3002"}}
{"id": "2601.12286", "categories": ["cs.CL", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.12286", "abs": "https://arxiv.org/abs/2601.12286", "authors": ["Jonathan Pan"], "title": "Conversational Context Classification: A Representation Engineering Approach", "comment": null, "summary": "The increasing prevalence of Large Language Models (LLMs) demands effective safeguards for their operation, particularly concerning their tendency to generate out-of-context responses. A key challenge is accurately detecting when LLMs stray from expected conversational norms, manifesting as topic shifts, factual inaccuracies, or outright hallucinations. Traditional anomaly detection struggles to directly apply within contextual semantics. This paper outlines our experiment in exploring the use of Representation Engineering (RepE) and One-Class Support Vector Machine (OCSVM) to identify subspaces within the internal states of LLMs that represent a specific context. By training OCSVM on in-context examples, we establish a robust boundary within the LLM's hidden state latent space. We evaluate out study with two open source LLMs - Llama and Qwen models in specific contextual domain. Our approach entailed identifying the optimal layers within the LLM's internal state subspaces that strongly associates with the context of interest. Our evaluation results showed promising results in identifying the subspace for a specific context. Aside from being useful in detecting in or out of context conversation threads, this research work contributes to the study of better interpreting LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u8868\u793a\u5de5\u7a0b\u548c\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\u7684\u65b9\u6cd5\uff0c\u6210\u529f\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u9690\u72b6\u6001\u4e2d\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6a21\u578b\u8131\u79bb\u4e0a\u4e0b\u6587\u56de\u590d\u7684\u68c0\u6d4b\uff0c\u4e3a\u66f4\u597d\u7406\u89e3\u548c\u76d1\u63a7LLM\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bb9\u6613\u751f\u6210\u8131\u79bb\u4e0a\u4e0b\u6587\u7684\u56de\u590d\uff0c\u4f20\u7edf\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u76f4\u63a5\u5e94\u7528\u4e8e\u8bed\u4e49\u4e0a\u4e0b\u6587\u4e2d\uff0c\u56e0\u6b64\u9700\u8981\u65b0\u7684\u65b9\u6cd5\u51c6\u786e\u68c0\u6d4b\u6a21\u578b\u504f\u79bb\u6b63\u5e38\u5bf9\u8bdd\u89c4\u8303\u7684\u60c5\u51b5\u3002", "method": "\u5229\u7528\u8868\u793a\u5de5\u7a0b\u6280\u672f\u6784\u5efa\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u8868\u793a\uff0c\u518d\u5229\u7528OCSVM\u8bad\u7ec3\u5e76\u5212\u5b9aLLM\u9690\u85cf\u72b6\u6001\u6f5c\u5728\u7a7a\u95f4\u4e2d\u8be5\u4e0a\u4e0b\u6587\u7684\u8fb9\u754c\uff0c\u8fdb\u800c\u5b9e\u73b0\u5f02\u5e38\u68c0\u6d4b\u3002", "result": "\u5728Llama\u548cQwen\u4e24\u4e2a\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u6240\u63d0\u65b9\u6cd5\u80fd\u8f83\u51c6\u786e\u8bc6\u522b\u51fa\u4e0e\u7279\u5b9a\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u5b50\u7a7a\u95f4\uff0c\u6709\u6548\u533a\u5206\u5bf9\u8bdd\u662f\u5426\u7b26\u5408\u4e0a\u4e0b\u6587\u3002", "conclusion": "\u672c\u6587\u5b9e\u9a8c\u8868\u660e\uff0c\u901a\u8fc7\u4f7f\u7528\u8868\u793a\u5de5\u7a0b\uff08RepE\uff09\u548c\u5355\u7c7b\u652f\u6301\u5411\u91cf\u673a\uff08OCSVM\uff09\u53ef\u4ee5\u6709\u6548\u8bc6\u522b\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u72b6\u6001\u4e2d\u7684\u7279\u5b9a\u4e0a\u4e0b\u6587\u5b50\u7a7a\u95f4\uff0c\u6709\u52a9\u4e8e\u68c0\u6d4b\u6a21\u578b\u4ea7\u751f\u7684\u504f\u79bb\u9884\u671f\u7684\u8bdd\u9898\u3001\u4e8b\u5b9e\u9519\u8bef\u6216\u5e7b\u89c9\u3002"}}
{"id": "2601.13943", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13943", "abs": "https://arxiv.org/abs/2601.13943", "authors": ["Zhiyuan Peng", "Xin Yin", "Pu Zhao", "Fangkai Yang", "Lu Wang", "Ran Jia", "Xu Chen", "Qingwei Lin", "Saravan Rajmohan", "Dongmei Zhang"], "title": "RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository", "comment": null, "summary": "Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a \"review-rebuttal\" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis.", "AI": {"tldr": "\u63d0\u51fa\u591a\u8bed\u8a00\u5fae\u670d\u52a1\u751f\u6210\u57fa\u51c6RepoGenesis\uff0c\u63ed\u793a\u5f53\u524d\u4ee3\u7801\u751f\u6210\u6a21\u578b\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u5fae\u670d\u52a1\u4ed3\u5e93\u7aef\u5230\u7aef\u751f\u6210\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u751f\u6210\u57fa\u51c6\u591a\u805a\u7126\u4e8e\u51fd\u6570\u7ea7\u6216\u4ee3\u7801\u4fee\u6539\uff0c\u7f3a\u5c11\u771f\u5b9e\u5fae\u670d\u52a1\u4ed3\u5e93\u7684\u7aef\u5230\u7aef\u751f\u6210\u8bc4\u6d4b\uff0c\u65e0\u6cd5\u53cd\u6620\u5b9e\u96450\u52301\u5f00\u53d1\u6d41\u7a0b\u3002", "method": "\u63d0\u51fa\u5168\u65b0\u7684\u591a\u8bed\u8a00\u5fae\u670d\u52a1\u4ed3\u5e93\u751f\u6210\u57fa\u51c6RepoGenesis\uff0c\u5305\u542b\u591a\u79cd\u8bed\u8a00\u548c\u9886\u57df\u7684\u771f\u5b9e\u4ed3\u5e93\uff0c\u91c7\u7528\u201c\u5ba1\u6838-\u53cd\u9a73\u201d\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\uff0c\u8bc4\u6d4b\u591a\u79cd\u5f00\u6e90\u548c\u5546\u4e1a\u751f\u6210\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "result": "RepoGenesis\u5305\u542b106\u4e2a\u4ed3\u5e93\uff0c\u8986\u76d6\u591a\u8bed\u8a00\u591a\u6846\u67b6\uff0c\u8bc4\u6d4b\u53d1\u73b0\u5f53\u524d\u6700\u4f73\u751f\u6210\u7cfb\u7edf\u5728\u51c6\u786e\u6027\u65b9\u9762\u4ecd\u6709\u4e0d\u8db3\uff0c\u8868\u660e\u9700\u8981\u6539\u8fdb\u67b6\u6784\u4e00\u81f4\u6027\u548c\u4f9d\u8d56\u7ba1\u7406\u3002GenesisAgent-8B\u5728\u8be5\u57fa\u51c6\u4e0a\u5fae\u8c03\u540e\u6027\u80fd\u63a5\u8fd1GPT-5 mini\uff0c\u8bc1\u660e\u57fa\u51c6\u6570\u636e\u8d28\u91cf\u3002", "conclusion": "RepoGenesis\u57fa\u51c6\u6d4b\u8bd5\u63ed\u793a\u4e86\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5fae\u670d\u52a1\u4ed3\u5e93\u751f\u6210\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u5c3d\u7ba1API\u8986\u76d6\u7387\u548c\u90e8\u7f72\u6210\u529f\u7387\u8f83\u9ad8\uff0c\u4f46\u6574\u4f53\u4ee3\u7801\u8d28\u91cf\u548c\u67b6\u6784\u4e00\u81f4\u6027\u4ecd\u9700\u63d0\u5347\u3002"}}
{"id": "2601.12369", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12369", "abs": "https://arxiv.org/abs/2601.12369", "authors": ["Ming Zhang", "Jiabao Zhuang", "Wenqing Jing", "Ziyu Kong", "Jingyi Deng", "Yujiong Shen", "Kexin Tan", "Yuhang Zhao", "Ning Luo", "Renzhe Zheng", "Jiahui Lin", "Mingqi Wu", "Long Ma", "Yi Zou", "Shihan Dou", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Can Deep Research Agents Find and Organize? Evaluating the Synthesis Gap with Expert Taxonomies", "comment": null, "summary": "Deep Research Agents are increasingly used for automated survey generation. However, whether they can write surveys like human experts remains unclear. Existing benchmarks focus on fluency or citation accuracy, but none evaluates the core capabilities: retrieving essential papers and organizing them into coherent knowledge structures. We introduce TaxoBench, a diagnostic benchmark derived from 72 highly-cited computer science surveys. We manually extract expert-authored taxonomy trees containing 3,815 precisely categorized citations as ground truth. Our benchmark supports two evaluation modes: Deep Research mode tests end-to-end retrieval and organization given only a topic, while Bottom-Up mode isolates structuring capability by providing the exact papers human experts used. We evaluate 7 leading Deep Research agents and 12 frontier LLMs. Results reveal a dual bottleneck: the best agent recalls only 20.9% of expert-selected papers, and even with perfect input, the best model achieves only 0.31 ARI in organization. Current deep research agents remain far from expert-level survey writing. Our benchmark is publicly available at https://github.com/KongLongGeFDU/TaxoBench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8bc4\u6d4b\u57fa\u51c6TaxoBench\uff0c\u7528\u4e8e\u8bca\u65ad\u81ea\u52a8\u7814\u7a76\u7efc\u8ff0\u5de5\u5177\u5728\u5173\u952e\u8bba\u6587\u68c0\u7d22\u548c\u77e5\u8bc6\u7ed3\u6784\u7ec4\u7ec7\u65b9\u9762\u7684\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u5de5\u5177\u4e0e\u4e13\u5bb6\u6c34\u5e73\u5c1a\u6709\u663e\u8457\u5dee\u8ddd\u3002", "motivation": "\u76ee\u524d\u7684\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u8bed\u53e5\u6d41\u7545\u6027\u6216\u5f15\u7528\u51c6\u786e\u6027\uff0c\u7f3a\u4e4f\u5bf9\u81ea\u52a8\u7efc\u8ff0\u6838\u5fc3\u80fd\u529b\u2014\u2014\u5173\u952e\u8bba\u6587\u68c0\u7d22\u548c\u77e5\u8bc6\u7ed3\u6784\u7ec4\u7ec7\u7684\u8bc4\u6d4b\u3002\u56e0\u6b64\uff0c\u63a8\u52a8\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u7684\u53d1\u5c55\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u4e13\u4e1a\u7684\u8bca\u65ad\u5de5\u5177\u3002", "method": "\u63d0\u51fa\u4e86TaxoBench\uff0c\u8fd9\u662f\u57fa\u4e8e72\u7bc7\u9ad8\u88ab\u5f15\u8ba1\u7b97\u673a\u79d1\u5b66\u7efc\u8ff0\u4eba\u5de5\u63d0\u53d6\u7684\u5206\u7c7b\u6811\u6784\u5efa\u7684\u8bca\u65ad\u57fa\u51c6\uff0c\u5305\u542b3815\u4e2a\u7cbe\u786e\u5206\u7c7b\u7684\u5f15\u7528\u3002\u57fa\u51c6\u652f\u6301\u4e24\u79cd\u8bc4\u6d4b\u6a21\u5f0f\uff1a\u6df1\u5ea6\u7814\u7a76\u6a21\u5f0f\uff08\u7aef\u5230\u7aef\u68c0\u7d22\u4e0e\u7ec4\u7ec7\uff09\u548c\u81ea\u4e0b\u800c\u4e0a\u6a21\u5f0f\uff08\u4ec5\u7ec4\u7ec7\u80fd\u529b\u6d4b\u8bd5\uff0c\u63d0\u4f9b\u4e13\u5bb6\u9009\u7528\u7684\u8bba\u6587\uff09\u3002\u5bf9\u6bd4\u8bc4\u4f30\u4e867\u4e2a\u9886\u5148\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u548c12\u4e2a\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u6700\u4f73\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u4ec5\u80fd\u53ec\u56de20.9%\u7684\u4e13\u5bb6\u9009\u53d6\u8bba\u6587\uff1b\u5373\u4f7f\u8f93\u5165\u5b8c\u7f8e\uff0c\u6700\u4f73\u6a21\u578b\u7684\u7ec4\u7ec7\u80fd\u529b\u6307\u6807\uff08ARI\uff09\u4e5f\u53ea\u67090.31\uff0c\u8fdc\u4f4e\u4e8e\u4e13\u5bb6\u6c34\u5e73\u3002", "conclusion": "\u5f53\u524d\u7684\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u81ea\u52a8\u751f\u6210\u4e13\u5bb6\u7ea7\u7efc\u8ff0\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u5c24\u5176\u5728\u68c0\u7d22\u5173\u952e\u8bba\u6587\u548c\u7ec4\u7ec7\u77e5\u8bc6\u7ed3\u6784\u4e0a\u5b58\u5728\u663e\u8457\u74f6\u9888\u3002"}}
{"id": "2601.13996", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.13996", "abs": "https://arxiv.org/abs/2601.13996", "authors": ["Rui Abreu", "Shaukat Ali", "Paolo Arcaini", "Jose Campos", "Michael Felderer", "Claude Gravel", "Fuyuki Ishikawa", "Stefan Klikovits", "Andriy Miranskyy", "Mohammad Mousavi", "Masaomi Yamaguchi", "Lei Zhang", "Jianjun Zhao", "Anila Mjeda"], "title": "Software Testing in the Quantum World", "comment": null, "summary": "Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.", "AI": {"tldr": "\u4f20\u7edf\u7ecf\u5178\u6a21\u62df\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u9700\u6c42\uff0c\u672c\u6587\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\u63a2\u8ba8\u4e86\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u6d4b\u8bd5\u91cf\u5b50\u8f6f\u4ef6\u7684\u5173\u952e\u6311\u6218\u4e0e\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u91cf\u5b50\u8f6f\u4ef6\u590d\u6742\u6027\u7684\u589e\u52a0\uff0c\u4f20\u7edf\u7684\u91cf\u5b50\u8ba1\u7b97\u673a\u7ecf\u5178\u6a21\u62df\u53d8\u5f97\u4e0d\u53ef\u884c\uff0c\u8fd9\u9700\u8981\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u8fdb\u884c\u8d28\u91cf\u4fdd\u8bc1\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5e76\u4ece\u8f6f\u4ef6\u5de5\u7a0b\u7684\u89d2\u5ea6\u63d0\u51fa\u5e94\u5bf9\u7b56\u7565\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u5957\u57fa\u4e8e\u8f6f\u4ef6\u5de5\u7a0b\u89c6\u89d2\uff0c\u9488\u5bf9\u5927\u89c4\u6a21\u91cf\u5b50\u8f6f\u4ef6\u6d4b\u8bd5\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u76f4\u63a5\u5728\u771f\u5b9e\u91cf\u5b50\u8ba1\u7b97\u673a\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u662f\u672a\u6765\u91cf\u5b50\u8f6f\u4ef6\u8d28\u91cf\u4fdd\u8bc1\u7684\u5fc5\u8981\u65b9\u5411\uff0c\u8f6f\u4ef6\u5de5\u7a0b\u65b9\u6cd5\u53ef\u6709\u6548\u89e3\u51b3\u6d4b\u8bd5\u4e2d\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2601.12374", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12374", "abs": "https://arxiv.org/abs/2601.12374", "authors": ["Akram Elbouanani", "Aboubacar Tuo", "Adrian Popescu"], "title": "A Scalable Entity-Based Framework for Auditing Bias in LLMs", "comment": null, "summary": "Existing approaches to bias evaluation in large language models (LLMs) trade ecological validity for statistical control, relying on artificial prompts that poorly reflect real-world use, or on naturalistic tasks that lack scale and rigor. We introduce a scalable bias-auditing framework using named entities as probes to measure structural disparities in model behavior. We show that synthetic data reliably reproduces bias patterns observed in natural text, enabling large-scale analysis. Using this approach, we conduct the largest bias audit to date, comprising 1.9 billion data points across multiple entity types, tasks, languages, models, and prompting strategies. Our results reveal systematic biases: models penalize right-wing politicians, favor left-wing politicians, prefer Western and wealthy nations over the Global South, favor Western companies, and penalize firms in the defense and pharmaceutical sectors. While instruction tuning reduces bias, increasing model scale amplifies it, and prompting in Chinese or Russian does not attenuate Western-aligned preferences. These results indicate that LLMs should undergo rigorous auditing before deployment in high-stakes applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u547d\u540d\u5b9e\u4f53\u7684\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u5408\u6210\u6570\u636e\u5206\u6790\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u653f\u6cbb\u7acb\u573a\u3001\u5730\u57df\u548c\u884c\u4e1a\u504f\u89c1\u4e0a\u7684\u7cfb\u7edf\u6027\u95ee\u9898\uff0c\u5f3a\u8c03\u90e8\u7f72\u524d\u9700\u4e25\u683c\u5ba1\u8ba1\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u8bed\u8a00\u6a21\u578b\u504f\u89c1\u8bc4\u4f30\u65b9\u6cd5\u5728\u751f\u6001\u6548\u5ea6\u548c\u7edf\u8ba1\u63a7\u5236\u4e4b\u95f4\u5b58\u5728\u6743\u8861\uff0c\u4eba\u5de5\u63d0\u793a\u4e0d\u53cd\u6620\u73b0\u5b9e\uff0c\u6216\u81ea\u7136\u4efb\u52a1\u7f3a\u4e4f\u89c4\u6a21\u548c\u4e25\u8c28\u6027\u3002", "method": "\u5f15\u5165\u4f7f\u7528\u547d\u540d\u5b9e\u4f53\u4f5c\u4e3a\u63a2\u9488\u7684\u53ef\u6269\u5c55\u504f\u89c1\u5ba1\u8ba1\u6846\u67b6\uff0c\u5229\u7528\u5408\u6210\u6570\u636e\u6a21\u62df\u81ea\u7136\u6587\u672c\u4e2d\u7684\u504f\u89c1\u6a21\u5f0f\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u5206\u6790\u3002", "result": "\u5b8c\u6210\u8fc4\u4eca\u4e3a\u6b62\u6700\u5927\u7684\u504f\u89c1\u5ba1\u8ba1\uff0c\u6db5\u76d619\u4ebf\u6570\u636e\u70b9\uff0c\u591a\u5b9e\u4f53\u7c7b\u578b\u3001\u4efb\u52a1\u3001\u8bed\u8a00\u3001\u6a21\u578b\u548c\u63d0\u793a\u7b56\u7565\uff0c\u53d1\u73b0\u7cfb\u7edf\u6027\u504f\u89c1\u5982\u5bf9\u53f3\u7ffc\u653f\u6cbb\u5bb6\u5904\u7f5a\u3001\u652f\u6301\u5de6\u7ffc\u653f\u6cbb\u5bb6\uff0c\u504f\u597d\u897f\u65b9\u53ca\u5bcc\u88d5\u56fd\u5bb6\uff0c\u58f0\u63f4\u897f\u65b9\u516c\u53f8\uff0c\u60e9\u7f5a\u9632\u5fa1\u548c\u5236\u836f\u884c\u4e1a\u516c\u53f8\uff0c\u6307\u4ee4\u5fae\u8c03\u51cf\u5c11\u504f\u89c1\uff0c\u6a21\u578b\u89c4\u6a21\u589e\u5927\u504f\u89c1\u52a0\u5267\uff0c\u4e2d\u6587\u548c\u4fc4\u6587\u63d0\u793a\u672a\u51cf\u5f31\u897f\u65b9\u504f\u597d\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u573a\u666f\u524d\u9700\u63a5\u53d7\u4e25\u683c\u504f\u89c1\u5ba1\u8ba1\u3002"}}
{"id": "2601.14034", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14034", "abs": "https://arxiv.org/abs/2601.14034", "authors": ["Alexandros Tsakpinis", "Alexander Pretschner"], "title": "Analyzing the Availability of E-Mail Addresses for PyPI Libraries", "comment": "6 pages, 4 figures", "summary": "Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86Python\u5f00\u6e90\u5e93\u7ef4\u62a4\u8005\u7684\u7535\u5b50\u90ae\u4ef6\u8054\u7cfb\u4fe1\u606f\uff0c\u53d1\u73b0\u5927\u90e8\u5206\u7ef4\u62a4\u8005\u90fd\u53ef\u88ab\u8054\u7cfb\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u4fe1\u606f\u7684\u51c6\u786e\u6027\u548c\u9a8c\u8bc1\u673a\u5236\u3002", "motivation": "\u7ef4\u62a4\u8005\u7684\u53ef\u8fbe\u6027\u5bf9\u4e8e\u5f00\u6e90\u8f6f\u4ef6\u7684\u652f\u6301\u3001\u534f\u8c03\u548c\u5b89\u5168\u62a5\u544a\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u9700\u8981\u8bc4\u4f30\u7ef4\u62a4\u8005\u8054\u7cfb\u4fe1\u606f\u7684\u53ef\u7528\u6027\u3002", "method": "\u901a\u8fc7\u5bf9686,034\u4e2aPython\u5e93\u53ca\u5176GitHub\u4ed3\u5e93\u4e2d\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u7684\u6709\u6548\u6027\u548c\u8986\u76d6\u60c5\u51b5\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "81.6%\u7684\u5e93\u81f3\u5c11\u5305\u542b\u4e00\u4e2a\u6709\u6548\u7684\u7535\u5b50\u90ae\u4ef6\u5730\u5740\uff0c\u4f9d\u8d56\u94fe\u4e2d\u76f4\u63a5\u548c\u4f20\u9012\u4f9d\u8d56\u7684\u6709\u6548\u8054\u7cfb\u65b9\u5f0f\u6bd4\u4f8b\u5206\u522b\u8fbe\u523097.8%\u548c97.7%\uff0c\u4f46\u5b58\u5728\u5927\u91cf\u65e0\u6548\u6761\u76ee\u3002", "conclusion": "\u5f00\u6e90\u8f6f\u4ef6\u5e93\u7684\u7ef4\u62a4\u8005\u5927\u591a\u6570\u53ef\u901a\u8fc7\u6709\u6548\u7684\u7535\u5b50\u90ae\u4ef6\u5730\u5740\u88ab\u8054\u7cfb\u5230\uff0c\u8fd9\u4fdd\u8bc1\u4e86\u8f6f\u4ef6\u7cfb\u7edf\u7684\u957f\u671f\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2601.12376", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12376", "abs": "https://arxiv.org/abs/2601.12376", "authors": ["Ofek Raban", "Ethan Fetaya", "Gal Chechik"], "title": "LR-DWM: Efficient Watermarking for Diffusion Language Models", "comment": "Submitted to ACL Rolling Review (ARR). 7 pages, 4 figures", "summary": "Watermarking (WM) is a critical mechanism for detecting and attributing AI-generated content. Current WM methods for Large Language Models (LLMs) are predominantly tailored for autoregressive (AR) models: They rely on tokens being generated sequentially, and embed stable signals within the generated sequence based on the previously sampled text. Diffusion Language Models (DLMs) generate text via non-sequential iterative denoising, which requires significant modification to use WM methods designed for AR models. Recent work proposed to watermark DLMs by inverting the process when needed, but suffers significant computational or memory overhead. We introduce Left-Right Diffusion Watermarking (LR-DWM), a scheme that biases the generated token based on both left and right neighbors, when they are available. LR-DWM incurs minimal runtime and memory overhead, remaining close to the non-watermarked baseline DLM while enabling reliable statistical detection under standard evaluation settings. Our results demonstrate that DLMs can be watermarked efficiently, achieving high detectability with negligible computational and memory overhead.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLR-DWM\u6c34\u5370\u65b9\u6cd5\uff0c\u4f4e\u5f00\u9500\u9ad8\u6548\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u6c34\u5370\uff0c\u89e3\u51b3\u73b0\u6709\u65b9\u6cd5\u4e0d\u9002\u7528\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u6c34\u5370\u65b9\u6cd5\u4e3b\u8981\u9488\u5bf9\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u4e0d\u9002\u7528\u4e8e\u901a\u8fc7\u975e\u987a\u5e8f\u8fed\u4ee3\u53bb\u566a\u751f\u6210\u6587\u672c\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff0c\u5bfc\u81f4\u9700\u8981\u5bf9DLM\u8fdb\u884c\u5927\u91cf\u6539\u52a8\u6216\u4ea7\u751f\u9ad8\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u4e86Left-Right Diffusion Watermarking (LR-DWM)\u65b9\u6848\uff0c\u901a\u8fc7\u7ed3\u5408\u5de6\u53f3\u90bb\u5c45\u7684\u751f\u6210\u4fe1\u606f\uff0c\u5728\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e2d\u5d4c\u5165\u6c34\u5370\u4fe1\u53f7\u3002", "result": "LR-DWM\u5728\u6807\u51c6\u8bc4\u4f30\u4e0b\u5b9e\u73b0\u4e86\u63a5\u8fd1\u65e0\u6c34\u5370\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u68c0\u6d4b\u80fd\u529b\uff0c\u4e14\u53ea\u9700\u6781\u5c11\u7684\u8fd0\u884c\u65f6\u548c\u5185\u5b58\u8d44\u6e90\u3002", "conclusion": "LR-DWM\u65b9\u6848\u80fd\u591f\u6709\u6548\u5730\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u6dfb\u52a0\u6c34\u5370\uff0c\u5b9e\u73b0\u9ad8\u68c0\u6d4b\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6781\u4f4e\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u5f00\u9500\u3002"}}
{"id": "2601.14081", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14081", "abs": "https://arxiv.org/abs/2601.14081", "authors": ["Xingcheng Chen", "Oliver Weissl", "Andrea Stocco"], "title": "Feature-Aware Test Generation for Deep Learning Models", "comment": null, "summary": "As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Detect\uff0c\u4e00\u79cd\u901a\u8fc7\u5e72\u6270\u6f5c\u5728\u7a7a\u95f4\u4e2d\u53ef\u63a7\u8bed\u4e49\u7279\u5f81\u751f\u6210\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u6d4b\u8bd5\u7528\u4f8b\u7684\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u7cbe\u7ec6\u8bed\u4e49\u6d1e\u5bdf\u548c\u9c81\u68d2\u6027\u7f3a\u9677\u7684\u6709\u6548\u8bc6\u522b\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u6d4b\u8bd5\u65b9\u6cd5\u5728\u63ed\u793a\u9519\u8bef\u539f\u56e0\u7684\u8bed\u4e49\u89e3\u91ca\u548c\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u8feb\u5207\u9700\u8981\u4e00\u79cd\u80fd\u591f\u63d0\u4f9b\u8bed\u4e49\u6d1e\u5bdf\u4e14\u5177\u6709\u7cbe\u7ec6\u63a7\u5236\u80fd\u529b\u7684\u6d4b\u8bd5\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86Detect\u7279\u5f81\u611f\u77e5\u7684\u6d4b\u8bd5\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u63a7\u5236\u6027\u6270\u52a8\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5355\u4e2a\u8bed\u4e49\u7279\u5f81\uff0c\u5e76\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u5f52\u56e0\uff0c\u533a\u5206\u4efb\u52a1\u76f8\u5173\u548c\u65e0\u5173\u7279\u5f81\uff0c\u7528\u4ee5\u751f\u6210\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u7528\u4f8b\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eDetect\u5728\u56fe\u50cf\u5206\u7c7b\u548c\u68c0\u6d4b\u4efb\u52a1\u4e2d\u751f\u6210\u4e86\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u80fd\u63ed\u793a\u4e0d\u540c\u6a21\u578b\u67b6\u6784\u4e2d\u7684\u5feb\u6377\u65b9\u5f0f\u884c\u4e3a\u548c\u672a\u88ab\u51c6\u786e\u7387\u6307\u6807\u6355\u6349\u7684\u7f3a\u9677\uff1b\u5728\u51b3\u7b56\u8fb9\u754c\u53d1\u73b0\u548c\u9c81\u68d2\u6027\u6545\u969c\u8bc6\u522b\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "Detect\u6846\u67b6\u901a\u8fc7\u5728\u6f5c\u5728\u7a7a\u95f4\u4e2d\u6270\u52a8\u89e3\u8026\u7684\u8bed\u4e49\u5c5e\u6027\uff0c\u5b9e\u73b0\u5bf9\u89c6\u89c9\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u8f93\u5165\u7684\u7ec6\u7c92\u5ea6\u8bed\u4e49\u63a7\u5236\uff0c\u80fd\u591f\u63ed\u793a\u6a21\u578b\u7684\u884c\u4e3a\u53d8\u5316\u548c\u9c81\u68d2\u6027\u7f3a\u9677\uff0c\u4f53\u73b0\u4e86\u89e3\u91ca\u6027\u548c\u7279\u5f81\u611f\u77e5\u6d4b\u8bd5\u7684\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2601.12389", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12389", "abs": "https://arxiv.org/abs/2601.12389", "authors": ["Lakshya Tomar", "Vinayak Abrol", "Puneet Agarwal"], "title": "NADIR: Differential Attention Flow for Non-Autoregressive Transliteration in Indic Languages", "comment": "Accepted at the AAAI Conference on Artificial Intelligence (AAAI 2026)", "summary": "In this work, we argue that not all sequence-to-sequence tasks require the strong inductive biases of autoregressive (AR) models. Tasks like multilingual transliteration, code refactoring, grammatical correction or text normalization often rely on local dependencies where the full modeling capacity of AR models can be overkill, creating a trade-off between their high accuracy and high inference latency. While non-autoregressive (NAR) models offer speed, they typically suffer from hallucinations and poor length control. To explore this trade-off, we focus on the multilingual transliteration task in Indic languages and introduce NADIR, a novel NAR architecture designed to strike a balance between speed and accuracy. NADIR integrates a Differential Transformer and a Mixture-of-Experts mechanism, enabling it to robustly model complex character mappings without sequential dependencies. NADIR achieves over a 13x speed-up compared to the state-of-the-art AR baseline. It maintains a competitive mean Character Error Rate of 15.78%, compared to 14.44% for the AR model and 21.88% for a standard NAR equivalent. Importantly, NADIR reduces Repetition errors by 49.53%, Substitution errors by 24.45%, Omission errors by 32.92%, and Insertion errors by 16.87%. This work provides a practical blueprint for building fast and reliable NAR systems, effectively bridging the gap between AR accuracy and the demands of real-time, large-scale deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ed3\u5408\u5dee\u5206\u53d8\u6362\u5668\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u7684NADIR\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u591a\u8bed\u79cd\u97f3\u8bd1\u4efb\u52a1\u4e2d\u901f\u5ea6\u4e0e\u51c6\u786e\u6027\u7684\u6700\u4f73\u5e73\u8861\u3002", "motivation": "\u81ea\u56de\u5f52\u6a21\u578b\u9ad8\u51c6\u786e\u5ea6\u4f46\u63a8\u7406\u901f\u5ea6\u6162\uff0c\u975e\u81ea\u56de\u5f52\u6a21\u578b\u901f\u5ea6\u5feb\u4f46\u5b58\u5728\u5e7b\u89c9\u548c\u957f\u5ea6\u63a7\u5236\u5dee\uff0c\u63a2\u7d22\u4e24\u8005\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u5f15\u5165\u4e86\u5dee\u5206\u53d8\u6362\u5668\u548c\u4e13\u5bb6\u6df7\u5408\u673a\u5236\u7684\u975e\u81ea\u56de\u5f52\u6a21\u578bNADIR\uff0c\u89e3\u51b3\u4e86\u5e8f\u5217\u5230\u5e8f\u5217\u4efb\u52a1\u4e2d\u7684\u5c40\u90e8\u4f9d\u8d56\u95ee\u9898\u3002", "result": "NADIR\u6bd4\u6700\u5148\u8fdb\u7684\u81ea\u56de\u5f52\u57fa\u7ebf\u5feb13\u500d\uff0c\u5b57\u7b26\u9519\u8bef\u7387\u4e3a15.78%\uff0c\u63a5\u8fd1\u81ea\u56de\u5f52\u768414.44%\uff0c\u663e\u8457\u4f18\u4e8e\u6807\u51c6\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u591a\u79cd\u9519\u8bef\u3002", "conclusion": "NADIR\u6a21\u578b\u5728\u591a\u8bed\u79cd\u97f3\u8bd1\u4efb\u52a1\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u7684\u5b57\u7b26\u9519\u8bef\u7387\uff0c\u51cf\u5c11\u591a\u79cd\u9519\u8bef\u7c7b\u578b\u3002"}}
{"id": "2601.14131", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14131", "abs": "https://arxiv.org/abs/2601.14131", "authors": ["Amila Indika", "Rick Kazman", "Anthony Peruma"], "title": "Practitioner Views on Mobile App Accessibility: Practices and Challenges", "comment": "The 48th IEEE/ACM International Conference on Software Engineering - Research Track", "summary": "As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5168\u7403110\u540d\u5f00\u53d1\u8005\u8c03\u67e5\uff0c\u63ed\u793a\u4e86\u79fb\u52a8\u5e94\u7528\u65e0\u969c\u788d\u5b9e\u8df5\u4e2d\u7684\u5e73\u53f0\u5dee\u5f02\u4e0e\u7ecf\u9a8c\u5f71\u54cd\uff0c\u6307\u51fa\u5f53\u524d\u7684\u6311\u6218\u5e76\u63d0\u51fa\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u79fb\u52a8\u5e94\u7528\u666e\u53ca\uff0c\u4f46\u7f3a\u4e4f\u5173\u4e8e\u5f00\u53d1\u8005\u5982\u4f55\u5b9e\u9645\u5b9e\u65bd\u65e0\u969c\u788d\u7684\u8de8\u5e73\u53f0\u548c\u5168\u7403\u89c6\u89d2\u7814\u7a76\u3002", "method": "\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8c03\u67e5\uff0c\u6536\u96c6\u6765\u81ea43\u4e2a\u56fd\u5bb6110\u540d\u79fb\u52a8\u5e94\u7528\u5f00\u53d1\u8005\u7684\u6570\u636e\uff0c\u6bd4\u8f83iOS\u4e0eAndroid\u5e73\u53f0\u53ca\u5f00\u53d1\u8005\u7ecf\u9a8c\u5bf9\u65e0\u969c\u788d\u5b9e\u8df5\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5f00\u53d1\u8005\u4e3b\u8981\u5b9e\u73b0\u6587\u672c\u76f8\u5173\u65e0\u969c\u788d\u529f\u80fd\uff0c\u9762\u4e34\u5e73\u53f0\u7279\u5b9a\u969c\u788d\uff0c\u4e14\u65e0\u969c\u788d\u5b9e\u8df5\u5728\u4e0d\u540c\u5e73\u53f0\u53ca\u7ecf\u9a8c\u5c42\u6b21\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u5f00\u53d1\u8005\u8ba4\u8bc6\u5230\u65e0\u969c\u788d\u7684\u91cd\u8981\u6027\uff0c\u4f46\u4e3b\u8981\u4f9d\u8d56\u5e73\u53f0\u7279\u5b9a\u7684\u6307\u5357\uff0c\u4e14\u901a\u5e38\u5728\u5f00\u53d1\u540e\u671f\u624d\u8fdb\u884c\u5408\u89c4\u6027\u6d4b\u8bd5\u3002\u65e0\u969c\u788d\u5b9e\u8df5\u56e0\u5e73\u53f0\u751f\u6001\u548c\u5f00\u53d1\u8005\u7ecf\u9a8c\u800c\u5f02\uff0c\u5e76\u5b58\u5728API\u9650\u5236\u548c\u7ec4\u7ec7\u7ea6\u675f\u7b49\u6311\u6218\u3002"}}
{"id": "2601.12419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12419", "abs": "https://arxiv.org/abs/2601.12419", "authors": ["Mahammad Namazov", "Tom\u00e1\u0161 Koref", "Ivan Habernal"], "title": "Legal experts disagree with rationale extraction techniques for explaining ECtHR case outcome classification", "comment": null, "summary": "Interpretability is critical for applications of large language models in the legal domain which requires trust and transparency. While some studies develop task-specific approaches, other use the classification model's parameters to explain the decisions. However, which technique explains the legal outcome prediction best remains an open question. To address this challenge, we propose a comparative analysis framework for model-agnostic interpretability techniques. Among these, we employ two rationale extraction methods, which justify outcomes with human-interpretable and concise text fragments (i.e., rationales) from the given input text. We conduct comparison by evaluating faithfulness-via normalized sufficiency and comprehensiveness metrics along with plausibility-by asking legal experts to evaluate extracted rationales. We further assess the feasibility of LLM-as-a-Judge using legal expert evaluation results. We show that the model's \"reasons\" for predicting a violation differ substantially from those of legal experts, despite highly promising quantitative analysis results and reasonable downstream classification performance. The source code of our experiments is publicly available at https://github.com/trusthlt/IntEval.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u591a\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6cd5\u5f8b\u6587\u672c\u89e3\u91ca\u6280\u672f\uff0c\u53d1\u73b0\u6a21\u578b\u89e3\u91ca\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u610f\u89c1\u5dee\u5f02\u660e\u663e\uff0c\u8868\u660e\u89e3\u91ca\u65b9\u6cd5\u5c1a\u9700\u6539\u8fdb\u4ee5\u6ee1\u8db3\u6cd5\u5f8b\u9886\u57df\u7684\u9700\u6c42\u3002", "motivation": "\u6cd5\u5f8b\u9886\u57df\u7684\u5e94\u7528\u8981\u6c42\u5927\u8bed\u8a00\u6a21\u578b\u5177\u6709\u53ef\u89e3\u91ca\u6027\u4ee5\u786e\u4fdd\u4fe1\u4efb\u548c\u900f\u660e\u5ea6\uff0c\u4f46\u76ee\u524d\u5c1a\u4e0d\u6e05\u695a\u54ea\u79cd\u89e3\u91ca\u6280\u672f\u6700\u9002\u5408\u6cd5\u5f8b\u7ed3\u679c\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u89e3\u91ca\u6280\u672f\u6bd4\u8f83\u5206\u6790\u6846\u67b6\uff0c\u4f7f\u7528\u4e24\u79cd\u7406\u7531\u63d0\u53d6\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f52\u4e00\u5316\u5145\u5206\u6027\u548c\u5b8c\u5907\u6027\u6307\u6807\u8bc4\u4f30\u5fe0\u5b9e\u5ea6\uff0c\u5e76\u901a\u8fc7\u6cd5\u5f8b\u4e13\u5bb6\u8bc4\u4ef7\u7406\u7531\u7684\u5408\u7406\u6027\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u89e3\u91ca\u65b9\u6cd5\u7684\u9884\u6d4b\u7406\u7531\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u610f\u89c1\u5dee\u5f02\u5927\uff0c\u5c3d\u7ba1\u5b9a\u91cf\u6307\u6807\u548c\u5206\u7c7b\u6548\u679c\u826f\u597d\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86LLM\u4f5c\u4e3a\u6cd5\u5f8b\u5224\u51b3\u5de5\u5177\u7684\u53ef\u884c\u6027\u6709\u9650\u3002", "conclusion": "\u6a21\u578b\u7684\u201c\u7406\u7531\u201d\u4e0e\u6cd5\u5f8b\u4e13\u5bb6\u7684\u7406\u7531\u6709\u663e\u8457\u5dee\u5f02\uff0c\u5c3d\u7ba1\u91cf\u5316\u5206\u6790\u548c\u5206\u7c7b\u8868\u73b0\u826f\u597d\uff0c\u8868\u660e\u73b0\u6709\u89e3\u91ca\u6280\u672f\u5728\u6cd5\u5f8b\u9886\u57df\u7684\u9002\u7528\u6027\u6709\u9650\u3002"}}
{"id": "2601.14132", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2601.14132", "abs": "https://arxiv.org/abs/2601.14132", "authors": ["Rodrigo Falc\u00e3o", "Frank Elberzhager", "Karthik Vaidhyanathan"], "title": "Toward self-coding information systems", "comment": "Accepted for ICSE 2026 Track \"Software Architecture BoF\"", "summary": "In this extended abstract, we propose a novel research topic in the field of agentic AI, which we refer to as self-coding information systems. These systems will be able to dynamically adapt their structure or behavior by evaluating potential adaptation decisions, generate source code, test, and (re)deploy their source code autonomously, at runtime, reducing the time to market of new features. Here we motivate the topic, provide a formal definition of self-coding information systems, discuss some expected impacts of the new technology, and indicate potential research directions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u81ea\u7f16\u7801\u4fe1\u606f\u7cfb\u7edf\uff0c\u80fd\u81ea\u9002\u5e94\u751f\u6210\u548c\u90e8\u7f72\u4ee3\u7801\uff0c\u52a9\u529b\u667a\u80fd\u4ee3\u7406\u5feb\u901f\u8fed\u4ee3\u3002", "motivation": "\u4e3a\u4e86\u5b9e\u73b0\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\u7684\u81ea\u4e3b\u9002\u5e94\u4e0e\u5feb\u901f\u529f\u80fd\u8fed\u4ee3\uff0c\u63d0\u5347\u7cfb\u7edf\u7075\u6d3b\u6027\u548c\u54cd\u5e94\u901f\u5ea6\u3002", "method": "\u63d0\u51fa\u81ea\u7f16\u7801\u4fe1\u606f\u7cfb\u7edf\u7684\u5f62\u5f0f\u5316\u5b9a\u4e49\uff0c\u7ed3\u5408\u8bc4\u4f30\u9002\u5e94\u6027\u51b3\u7b56\u3001\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u4e0e\u81ea\u52a8\u90e8\u7f72\u7684\u80fd\u529b\u3002", "result": "\u5b9a\u4e49\u4e86\u81ea\u7f16\u7801\u4fe1\u606f\u7cfb\u7edf\u7684\u6982\u5ff5\uff0c\u9610\u8ff0\u5176\u6280\u672f\u5f71\u54cd\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u81ea\u7f16\u7801\u4fe1\u606f\u7cfb\u7edf\u80fd\u591f\u52a8\u6001\u9002\u5e94\u81ea\u8eab\u7ed3\u6784\u4e0e\u884c\u4e3a\uff0c\u5b9e\u73b0\u4ee3\u7801\u751f\u6210\u3001\u6d4b\u8bd5\u53ca\u91cd\u65b0\u90e8\u7f72\uff0c\u663e\u8457\u7f29\u77ed\u65b0\u529f\u80fd\u7684\u4e0a\u5e02\u65f6\u95f4\u3002"}}
{"id": "2601.12430", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12430", "abs": "https://arxiv.org/abs/2601.12430", "authors": ["Tsan Tsai Chan", "Varsha Suresh", "Anisha Saha", "Michael Hahn", "Vera Demberg"], "title": "System-Mediated Attention Imbalances Make Vision-Language Models Say Yes", "comment": "Under review", "summary": "Vision-language model (VLM) hallucination is commonly linked to imbalanced allocation of attention across input modalities: system, image and text. However, existing mitigation strategies tend towards an image-centric interpretation of these imbalances, often prioritising increased image attention while giving less consideration to the roles of the other modalities. In this study, we evaluate a more holistic, system-mediated account, which attributes these imbalances to functionally redundant system weights that reduce attention to image and textual inputs. We show that this framework offers a useful empirical perspective on the yes-bias, a common form of hallucination in which VLMs indiscriminately respond 'yes'. Causally redistributing attention from the system modality to image and textual inputs substantially suppresses this bias, often outperforming existing approaches. We further present evidence suggesting that system-mediated attention imbalances contribute to the yes-bias by encouraging a default reliance on coarse input representations, which are effective for some tasks but ill-suited to others. Taken together, these findings firmly establish system attention as a key factor in VLM hallucination and highlight its potential as a lever for mitigation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6307\u51fa\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u4e0e\u7cfb\u7edf\u6a21\u5757\u6ce8\u610f\u529b\u5206\u914d\u6709\u5173\uff0c\u63d0\u51fa\u8c03\u6574\u7cfb\u7edf\u6ce8\u610f\u529b\u53ef\u6709\u6548\u51cf\u5c11\u6a21\u578b\u6cdb\u6ee5\u7684yes\u504f\u5dee\uff0c\u4f18\u4e8e\u4f20\u7edf\u56fe\u50cf\u96c6\u4e2d\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8fc7\u4e8e\u5f3a\u8c03\u56fe\u50cf\u6ce8\u610f\u529b\u589e\u52a0\uff0c\u5ffd\u7565\u4e86\u7cfb\u7edf\u6a21\u5757\u548c\u6587\u672c\u8f93\u5165\u7684\u4f5c\u7528\uff0c\u5bfc\u81f4\u6a21\u578b\u5e7b\u89c9\u95ee\u9898\u672a\u80fd\u5f97\u5230\u6839\u672c\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u4ecb\u5bfc\u7684\u6ce8\u610f\u529b\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u56e0\u679c\u91cd\u5206\u914d\u7cfb\u7edf\u6ce8\u610f\u529b\u81f3\u56fe\u50cf\u548c\u6587\u672c\u8f93\u5165\uff0c\u6291\u5236\u4e86\u6a21\u578b\u7684yes\u504f\u5dee\u3002", "result": "\u901a\u8fc7\u91cd\u65b0\u5206\u914d\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4e2d\u5e7f\u6cdb\u5b58\u5728\u7684yes\u504f\u5dee\u5e7b\u89c9\u8868\u73b0\uff0c\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u56fe\u50cf\u4e2d\u5fc3\u7684\u65b9\u6cd5\u3002", "conclusion": "\u7cfb\u7edf\u6ce8\u610f\u529b\u7684\u4e0d\u5e73\u8861\u662f\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u73b0\u8c61\u7684\u5173\u952e\u56e0\u7d20\uff0c\u8c03\u6574\u7cfb\u7edf\u6ce8\u610f\u529b\u5206\u914d\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6a21\u578b\u7684yes\u504f\u5dee\u5e7b\u89c9\u3002"}}
{"id": "2601.14163", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14163", "abs": "https://arxiv.org/abs/2601.14163", "authors": ["Mohammed Latif Siddiq", "Tanzim Hossain Romel", "Natalie Sekerak", "Beatrice Casey", "Joanna C. S. Santos"], "title": "An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems", "comment": null, "summary": "Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5927\u89c4\u6a21\u8c03\u7814\u4e3b\u6d41\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u4e2d\u6267\u884c\u8fdc\u7a0b\u4ee3\u7801\u7684\u5b89\u5168\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u5e73\u53f0\u8bbe\u8ba1\u7684\u5b89\u5168\u9690\u60a3\u548c\u793e\u533a\u8ba4\u77e5\u4e0d\u8db3\uff0c\u63d0\u51fa\u63d0\u9ad8\u5b89\u5168\u6027\u4e0e\u6613\u7528\u6027\u5e73\u8861\u7684\u5efa\u8bae\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u4e3a\u4fbf\u6377\u4f7f\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5f15\u5165\u4e86\u6267\u884c\u8fdc\u7a0b\u4ee3\u7801\u7684\u7075\u6d3b\u6027\uff0c\u4f46\u8fd9\u5e26\u6765\u4e86\u5b89\u5168\u9690\u60a3\uff0c\u5c1a\u7f3a\u4e4f\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\u7406\u89e3\u98ce\u9669\u53ca\u7528\u6237\u770b\u6cd5\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u4f7f\u7528\u9759\u6001\u5206\u6790\u5de5\u5177\uff08Bandit\u3001CodeQL\u3001Semgrep\uff09\u3001\u6076\u610f\u4ee3\u7801\u68c0\u6d4b\uff08YARA\uff09\u3001\u6587\u6863\u548cAPI\u5206\u6790\uff0c\u4ee5\u53ca\u5bf9\u5f00\u53d1\u8005\u793e\u533a\u8ba8\u8bba\u7684\u5b9a\u6027\u5206\u6790\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u52a0\u8f7d\u4e2d\u7684\u5b89\u5168\u98ce\u9669\u548c\u5f00\u53d1\u8005\u8ba4\u77e5\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u52a0\u8f7d\u65f6\u6267\u884c\u4efb\u610f\u4ee3\u7801\u7684\u73b0\u8c61\u666e\u904d\uff0c\u5b89\u5168\u68c0\u67e5\u4e0d\u7edf\u4e00\u4e14\u591a\u6570\u5e73\u53f0\u9ed8\u8ba4\u4e0d\u5b89\u5168\uff0c\u5f00\u53d1\u8005\u5bf9\u8fdc\u7a0b\u4ee3\u7801\u6267\u884c\u7684\u5b89\u5168\u5f71\u54cd\u5b58\u5728\u8bef\u89e3\u548c\u62c5\u5fe7\u3002", "conclusion": "\u6a21\u578b\u5171\u4eab\u5e73\u53f0\u5b58\u5728\u6267\u884c\u4e0d\u53d7\u4fe1\u4efb\u4ee3\u7801\u7684\u5b89\u5168\u98ce\u9669\uff0c\u5f53\u524d\u5b89\u5168\u63aa\u65bd\u4e0d\u8db3\u4e14\u7528\u6237\u610f\u8bc6\u4e0d\u8db3\uff0c\u9700\u6539\u8fdb\u5e73\u53f0\u8bbe\u8ba1\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u548c\u5e73\u8861\u6613\u7528\u6027\u3002"}}
{"id": "2601.12465", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12465", "abs": "https://arxiv.org/abs/2601.12465", "authors": ["Miao Peng", "Weizhou Shen", "Nuo Chen", "Chenliang Li", "Ming Yan", "Jia Li"], "title": "Incentivizing In-depth Reasoning over Long Contexts with Process Advantage Shaping", "comment": null, "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective in enhancing LLMs short-context reasoning, but its performance degrades in long-context scenarios that require both precise grounding and robust long-range reasoning. We identify the \"almost-there\" phenomenon in long-context reasoning, where trajectories are largely correct but fail at the final step, and attribute this failure to two factors: (1) the lack of high reasoning density in long-context QA data that push LLMs beyond mere grounding toward sophisticated multi-hop reasoning; and (2) the loss of valuable learning signals during long-context RL training due to the indiscriminate penalization of partially correct trajectories with incorrect outcomes. To overcome this bottleneck, we propose DeepReasonQA, a KG-driven synthesis framework that controllably constructs high-difficulty, multi-hop long-context QA pairs with inherent reasoning chains. Building on this, we introduce Long-context Process Advantage Shaping (LongPAS), a simple yet effective method that performs fine-grained credit assignment by evaluating reasoning steps along Validity and Relevance dimensions, which captures critical learning signals from \"almost-there\" trajectories. Experiments on three long-context reasoning benchmarks show that our approach substantially outperforms RLVR baselines and matches frontier LLMs while using far fewer parameters. Further analysis confirms the effectiveness of our methods in strengthening long-context reasoning while maintaining stable RL training.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u7684\u201calmost-there\u201d\u95ee\u9898\uff0c\u8bbe\u8ba1\u4e86\u65b0\u7684\u6570\u636e\u5408\u6210\u4e0e\u4fe1\u7528\u5206\u914d\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u53ef\u9a8c\u8bc1\u5956\u52b1\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08RLVR\uff09\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u8868\u73b0\u4e0b\u964d\uff0c\u539f\u56e0\u5728\u4e8e\u7f3a\u4e4f\u9ad8\u5bc6\u5ea6\u63a8\u7406\u6837\u672c\u548c\u8bad\u7ec3\u4e2d\u5bf9\u90e8\u5206\u6b63\u786e\u4f46\u6700\u7ec8\u9519\u8bef\u8f68\u8ff9\u7684\u60e9\u7f5a\u8fc7\u5ea6\uff0c\u5bfc\u81f4\u6709\u6548\u5b66\u4e60\u4fe1\u53f7\u4e22\u5931\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u77e5\u8bc6\u56fe\u8c31\u9a71\u52a8\u7684\u9ad8\u96be\u5ea6\u591a\u8df3\u957f\u4e0a\u4e0b\u6587\u95ee\u7b54\u5408\u6210\u6846\u67b6DeepReasonQA\uff0c\u7ed3\u5408\u7ec6\u7c92\u5ea6\u4fe1\u7528\u5206\u914d\u65b9\u6cd5LongPAS\uff0c\u5206\u522b\u4ece\u9898\u76ee\u6784\u9020\u548c\u5f3a\u5316\u5b66\u4e60\u5956\u52b1\u4fe1\u53f7\u4e24\u4e2a\u65b9\u9762\u63d0\u5347\u6a21\u578b\u63a8\u7406\u80fd\u529b\u3002LongPAS\u5728\u63a8\u7406\u6b65\u9aa4\u7684\u6709\u6548\u6027\u548c\u76f8\u5173\u6027\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u8bc4\u4ef7\uff0c\u5b9e\u73b0\u66f4\u52a0\u7cbe\u51c6\u7684\u5956\u52b1\u5f15\u5bfc\u3002", "result": "\u5728\u4e09\u4e2a\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8eRLVR\u57fa\u7ebf\uff0c\u8868\u73b0\u63a5\u8fd1\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u540c\u65f6\u4f7f\u7528\u7684\u53c2\u6570\u91cf\u66f4\u5c11\uff0c\u5b9e\u73b0\u4e86\u63a8\u7406\u80fd\u529b\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u7684\u53cc\u91cd\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684DeepReasonQA\u548cLongPAS\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u89e3\u51b3\u4e86\u4ee5\u524d\u65b9\u6cd5\u4e2d\u201calmost-there\u201d\u73b0\u8c61\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2601.12471", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12471", "abs": "https://arxiv.org/abs/2601.12471", "authors": ["Sravanthi Machcha", "Sushrita Yerra", "Sahil Gupta", "Aishwarya Sahoo", "Sharmin Sultana", "Hong Yu", "Zonghai Yao"], "title": "Knowing When to Abstain: Medical LLMs Under Clinical Uncertainty", "comment": "Equal contribution for the first two authors; To appear in proceedings of the Main Conference of the European Chapter of the Association for Computational Linguistics (EACL) 2026", "summary": "Current evaluation of large language models (LLMs) overwhelmingly prioritizes accuracy; however, in real-world and safety-critical applications, the ability to abstain when uncertain is equally vital for trustworthy deployment. We introduce MedAbstain, a unified benchmark and evaluation protocol for abstention in medical multiple-choice question answering (MCQA) -- a discrete-choice setting that generalizes to agentic action selection -- integrating conformal prediction, adversarial question perturbations, and explicit abstention options. Our systematic evaluation of both open- and closed-source LLMs reveals that even state-of-the-art, high-accuracy models often fail to abstain with uncertain. Notably, providing explicit abstention options consistently increases model uncertainty and safer abstention, far more than input perturbations, while scaling model size or advanced prompting brings little improvement. These findings highlight the central role of abstention mechanisms for trustworthy LLM deployment and offer practical guidance for improving safety in high-stakes applications.", "AI": {"tldr": "\u63d0\u51faMedAbstain\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u533b\u7597\u95ee\u7b54\u4e2d\u6a21\u578b\u653e\u5f03\u80fd\u529b\uff0c\u53d1\u73b0\u663e\u5f0f\u653e\u5f03\u673a\u5236\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\uff0c\u5f3a\u8c03\u653e\u5f03\u80fd\u529b\u5bf9\u73b0\u5b9e\u53ef\u4fe1\u5927\u6a21\u578b\u5e94\u7528\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u4f30\u4e2d\u4e3b\u8981\u5173\u6ce8\u51c6\u786e\u7387\uff0c\u4f46\u5728\u5b9e\u9645\u548c\u5b89\u5168\u5173\u952e\u573a\u666f\u4e0b\uff0c\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u65f6\u9009\u62e9\u653e\u5f03\u56de\u7b54\u7684\u80fd\u529b\u540c\u6837\u91cd\u8981\u3002", "method": "\u63d0\u51faMedAbstain\uff0c\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u9879\u9009\u62e9\u533b\u7597\u95ee\u7b54\u4e2d\u653e\u5f03\u673a\u5236\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u65b9\u6848\uff0c\u7ed3\u5408\u4e86\u5171\u5f62\u9884\u6d4b\u3001\u5bf9\u6297\u6027\u95ee\u9898\u6270\u52a8\u548c\u663e\u5f0f\u653e\u5f03\u9009\u9879\u3002", "result": "\u8bc4\u6d4b\u663e\u793a\u5373\u4f7f\u662f\u9ad8\u51c6\u786e\u7387\u7684\u5148\u8fdb\u6a21\u578b\uff0c\u4e5f\u5e38\u5728\u4e0d\u786e\u5b9a\u65f6\u672a\u80fd\u653e\u5f03\u56de\u7b54\u3002\u663e\u5f0f\u653e\u5f03\u9009\u9879\u660e\u663e\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e0d\u786e\u5b9a\u6027\u53cd\u6620\u548c\u5b89\u5168\u653e\u5f03\u80fd\u529b\uff0c\u8d85\u8d8a\u8f93\u5165\u6270\u52a8\u6548\u679c\uff1b\u800c\u589e\u52a0\u6a21\u578b\u89c4\u6a21\u548c\u9ad8\u7ea7\u63d0\u793a\u4f5c\u7528\u6709\u9650\u3002", "conclusion": "\u653e\u5f03\u673a\u5236\u5728\u53ef\u4fe1\u8d56\u7684\u5927\u8bed\u8a00\u6a21\u578b\u90e8\u7f72\u4e2d\u53d1\u6325\u6838\u5fc3\u4f5c\u7528\uff0c\u5e94\u4f5c\u4e3a\u63d0\u9ad8\u9ad8\u98ce\u9669\u5e94\u7528\u5b89\u5168\u6027\u7684\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2601.12473", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12473", "abs": "https://arxiv.org/abs/2601.12473", "authors": ["Renlong Jie", "Chen Chu", "Zhen Wang"], "title": "Capability-Aware Early-Stage Research Idea Evaluation", "comment": null, "summary": "Predicting the outcomes of research ideas at their conceptual stage (i.e. before significant resources are committed) holds great potential for optimizing scientific resource allocation and research planning. While existing methods rely heavily on finished manuscripts or peer reviews, we propose a novel capability-aware framework that predicts paper acceptance and ratings using only author information and research ideas, without requiring full text or experimental results. Our approach integrates author information, (inferred) capability presentation, and research ideas through a three-way transformer architecture with flexible fusion mechanisms. We also introduce a two-stage architecture for learning the capability representation given the author information and idea. Experiments show that our method significantly outperform the single-way models by finetuning bert-base and bert-large, and the capability predicting significantly increase the predictive accuracy of the final model. The proposed method can be applied in both early-stage research outcome prediction and scientific resource allocation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u4f5c\u8005\u4fe1\u606f\u548c\u7814\u7a76\u60f3\u6cd5\u7684\u80fd\u529b\u611f\u77e5\u4e09\u8defTransformer\u6a21\u578b\uff0c\u5b9e\u73b0\u65e9\u671f\u79d1\u7814\u6210\u679c\u9884\u6d4b\uff0c\u4f18\u5316\u8d44\u6e90\u914d\u7f6e\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5b8c\u6574\u7a3f\u4ef6\u6216\u540c\u884c\u8bc4\u5ba1\uff0c\u96be\u4ee5\u5728\u7814\u7a76\u521d\u671f\u9884\u6d4b\u7ed3\u679c\u3002\u672c\u6587\u65e8\u5728\u5b9e\u73b0\u65e9\u671f\u7814\u7a76\u6210\u679c\u7684\u9884\u6d4b\u4ee5\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "method": "\u901a\u8fc7\u6574\u5408\u4f5c\u8005\u4fe1\u606f\u3001\u63a8\u65ad\u7684\u80fd\u529b\u8868\u793a\u4e0e\u7814\u7a76\u60f3\u6cd5\uff0c\u8bbe\u8ba1\u4e09\u8defTransformer\u67b6\u6784\u548c\u7075\u6d3b\u7684\u878d\u5408\u673a\u5236\uff1b\u5f15\u5165\u4e24\u9636\u6bb5\u67b6\u6784\u5b66\u4e60\u80fd\u529b\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u76f8\u6bd4\u57fa\u7ebf\u6a21\u578b\uff0c\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\uff0c\u4e14\u80fd\u529b\u8868\u793a\u9884\u6d4b\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6700\u7ec8\u6a21\u578b\u7684\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u80fd\u529b\u611f\u77e5\u7684\u4e09\u8defTransformer\u6846\u67b6\u80fd\u591f\u4ec5\u901a\u8fc7\u4f5c\u8005\u4fe1\u606f\u548c\u7814\u7a76\u60f3\u6cd5\uff0c\u6709\u6548\u9884\u6d4b\u8bba\u6587\u63a5\u53d7\u4e0e\u8bc4\u5206\uff0c\u663e\u8457\u4f18\u4e8e\u5355\u8def\u6a21\u578b\u3002"}}
{"id": "2601.12505", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12505", "abs": "https://arxiv.org/abs/2601.12505", "authors": ["Ashish Raj Shekhar", "Shiven Agarwal", "Priyanuj Bordoloi", "Yash Shah", "Tejas Anvekar", "Vivek Gupta"], "title": "DoPE: Decoy Oriented Perturbation Encapsulation Human-Readable, AI-Hostile Documents for Academic Integrity", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) can directly consume exam documents, threatening conventional assessments and academic integrity. We present DoPE (Decoy-Oriented Perturbation Encapsulation), a document-layer defense framework that embeds semantic decoys into PDF/HTML assessments to exploit render-parse discrepancies in MLLM pipelines. By instrumenting exams at authoring time, DoPE provides model-agnostic prevention (stop or confound automated solving) and detection (flag blind AI reliance) without relying on conventional one-shot classifiers. We formalize prevention and detection tasks, and introduce FewSoRT-Q, an LLM-guided pipeline that generates question-level semantic decoys and FewSoRT-D to encapsulate them into watermarked documents. We evaluate on Integrity-Bench, a novel benchmark of 1826 exams (PDF+HTML) derived from public QA datasets and OpenCourseWare. Against black-box MLLMs from OpenAI and Anthropic, DoPE yields strong empirical gains: a 91.4% detection rate at an 8.7% false-positive rate using an LLM-as-Judge verifier, and prevents successful completion or induces decoy-aligned failures in 96.3% of attempts. We release Integrity-Bench, our toolkit, and evaluation code to enable reproducible study of document-layer defenses for academic integrity.", "AI": {"tldr": "DoPE\u901a\u8fc7\u6587\u6863\u5c42\u9762\u5d4c\u5165\u8bf1\u9975\u673a\u5236\uff0c\u6709\u6548\u9632\u5fa1\u548c\u68c0\u6d4b\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u8003\u8bd5\u4e2d\u7684\u4f5c\u5f0a\u884c\u4e3a\uff0c\u4fc3\u8fdb\u5b66\u672f\u8bda\u4fe1\u4fdd\u62a4\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u76f4\u63a5\u5904\u7406\u8003\u8bd5\u6587\u6863\uff0c\u5bf9\u4f20\u7edf\u8003\u8bd5\u548c\u5b66\u672f\u8bda\u4fe1\u6784\u6210\u5a01\u80c1\uff0c\u6025\u9700\u6709\u6548\u7684\u6a21\u578b\u65e0\u5173\u9632\u62a4\u548c\u68c0\u6d4b\u624b\u6bb5\u3002", "method": "\u901a\u8fc7\u5728PDF/HTML\u8003\u8bd5\u6587\u6863\u4e2d\u5d4c\u5165\u8bed\u4e49\u8bf1\u9975\uff08semantic decoys\uff09\uff0c\u5229\u7528\u6e32\u67d3\u4e0e\u89e3\u6790\u5dee\u5f02\u6784\u5efa\u9632\u5fa1\u6846\u67b6\u3002\u5f15\u5165FewSoRT-Q\u751f\u6210\u8bf1\u9975\uff0cFewSoRT-D\u5b9e\u73b0\u6587\u6863\u6c34\u5370\u5c01\u88c5\uff0c\u65e0\u9700\u4f9d\u8d56\u4f20\u7edf\u5206\u7c7b\u5668\u3002", "result": "\u5728\u5305\u62ec1826\u4efd\u8003\u8bd5\u7684Integrity-Bench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDoPE\u5728\u9ed1\u76d2MLLM\u4e0a\u5b9e\u73b091.4%\u7684\u68c0\u6d4b\u7387\uff08\u8bef\u62a5\u73878.7%\uff09\uff0c\u963b\u6b62\u6216\u5e72\u6270\u4e8696.3%\u7684\u7b54\u9898\u5c1d\u8bd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684DoPE\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u9488\u5bf9\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8003\u8bd5\u9632\u62a4\u80fd\u529b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u81ea\u52a8\u7b54\u9898\u7684\u6210\u529f\u7387\uff0c\u540c\u65f6\u80fd\u51c6\u786e\u68c0\u6d4b\u4f9d\u8d56\u76f2\u76eeAI\u7684\u884c\u4e3a\u3002"}}
{"id": "2601.12535", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12535", "abs": "https://arxiv.org/abs/2601.12535", "authors": ["Ahmed Attia", "Alham Fikri"], "title": "Improving Low-Resource Machine Translation via Round-Trip Reinforcement Learning", "comment": null, "summary": "Low-resource machine translation (MT) has gained increasing attention as parallel data from low-resource language communities is collected, but many potential methods for improving low-resource MT remain unexplored. We investigate a self-supervised reinforcement-learning-based fine-tuning for translation in low-resource settings using round-trip bootstrapping with the No Language Left Behind (NLLB) family of models. Our approach translates English into a target low-resource language and then back into English, using a combination of chrF++ and BLEU as the reward function on the reconstructed English sentences. Using the NLLB-MD dataset, we evaluate both the 600M and 1.3B parameter NLLB models and observe consistent improvements for the following languages: Central Aymara, Friulian, Wolof and Russian. Qualitative inspection of translation outputs indicates increased fluency and semantic fidelity. We argue that our method can further benefit from scale, enabling models to increasingly leverage their pretrained knowledge and continue self-improving.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5f80\u8fd4\u7ffb\u8bd1\u5fae\u8c03\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u6027\u80fd\uff0c\u589e\u5f3a\u4e86\u7ffb\u8bd1\u7684\u6d41\u7545\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u793e\u533a\u5e73\u884c\u6570\u636e\u6709\u9650\uff0c\u73b0\u6709\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u7684\u65b9\u6cd5\u4ecd\u672a\u5145\u5206\u63a2\u7d22\uff0c\u56e0\u6b64\u63a2\u7d22\u81ea\u6211\u8bad\u7ec3\u7b56\u7565\u4ee5\u63d0\u5347\u4f4e\u8d44\u6e90\u673a\u5668\u7ffb\u8bd1\u6027\u80fd\u3002", "method": "\u5229\u7528No Language Left Behind\u6a21\u578b\u5bb6\u65cf\uff0c\u901a\u8fc7\u5c06\u82f1\u6587\u7ffb\u8bd1\u6210\u76ee\u6807\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u518d\u7ffb\u8bd1\u56de\u82f1\u6587\uff0c\u7ed3\u5408chrF++\u548cBLEU\u6307\u6807\u4f5c\u4e3a\u5956\u52b1\u51fd\u6570\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\u3002", "result": "\u5728NLLB-MD\u6570\u636e\u96c6\u4e0a\uff0c600M\u548c1.3B\u53c2\u6570\u7684NLLB\u6a21\u578b\u5728Central Aymara\u3001Friulian\u3001Wolof\u548cRussian\u8bed\u8a00\u4e0a\u5747\u53d6\u5f97\u7a33\u5b9a\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u901a\u8fc7\u57fa\u4e8e\u81ea\u76d1\u7763\u5f3a\u5316\u5b66\u4e60\u7684\u5f80\u8fd4\u81ea\u6211\u8bad\u7ec3\u65b9\u6cd5\uff0c\u4f4e\u8d44\u6e90\u8bed\u8a00\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u5728\u591a\u79cd\u8bed\u8a00\u4e0a\u7684\u7ffb\u8bd1\u8d28\u91cf\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\uff0c\u8868\u73b0\u4e3a\u6d41\u7545\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u7684\u589e\u5f3a\u3002"}}
{"id": "2601.12549", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12549", "abs": "https://arxiv.org/abs/2601.12549", "authors": ["Ilia Badanin", "Daniil Dzenhaliou", "Imanol Schlag"], "title": "Benchmarking Concept-Spilling Across Languages in LLMs", "comment": null, "summary": "Multilingual Large Language Models (LLMs) exhibit remarkable cross-lingual abilities, yet often exhibit a systematic bias toward the representations from other languages, resulting in semantic interference when generating content in non-English languages$-$a phenomenon we define as language spilling. This paper presents a novel comparative framework for evaluating multilingual semantic robustness by systematically measuring how models handle polysemous words across languages. Our methodology provides a relative measure of model performance: when required to generate exactly five meanings, both strong and weak models may resort to meanings from dominant languages, but semantically stronger models do so later in the generation sequence, producing more true meanings from the target language before failing, while weaker models resort to dominant-language meanings earlier in the sequence. We evaluate a diverse set of open and closed multilingual LLMs using a structured meaning generation task across nine languages, employing a carefully curated benchmark of 100 high-polysemy English words. Our findings reveal significant variation in semantic robustness across both models and languages, providing a principled ranking system for model comparison without requiring definitive causal attribution of error sources. We contribute both a scalable comparative benchmark for multilingual semantic evaluation and a rigorous validation pipeline$-$critical tools for developing more linguistically balanced AI systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u521b\u65b0\u7684\u591a\u4e49\u8bcd\u751f\u6210\u6846\u67b6\uff0c\u7528\u4ee5\u8bc4\u6d4b\u591a\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u9c81\u68d2\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u8de8\u8bed\u8a00\u8bed\u4e49\u5e72\u6270\u95ee\u9898\u4e0a\u5dee\u5f02\u663e\u8457\uff0c\u6784\u5efa\u4e86\u591a\u8bed\u8a00\u8bed\u4e49\u8bc4\u4ef7\u7684\u57fa\u51c6\u4e0e\u9a8c\u8bc1\u6d41\u7a0b\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u751f\u6210\u975e\u82f1\u8bed\u8bed\u8a00\u5185\u5bb9\u65f6\uff0c\u5e38\u56e0\u5bf9\u5176\u4ed6\u8bed\u8a00\u7684\u504f\u89c1\u5bfc\u81f4\u8bed\u4e49\u5e72\u6270\uff0c\u4e9f\u9700\u4e00\u79cd\u5b9a\u91cf\u6bd4\u8f83\u8bed\u4e49\u9c81\u68d2\u6027\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6bd4\u8f83\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e49\u8bcd\u751f\u6210\u4efb\u52a1\uff0c\u7cfb\u7edf\u6d4b\u91cf\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u8bed\u4e49\u8868\u73b0\uff0c\u901a\u8fc7\u751f\u6210\u5e8f\u5217\u4e2d\u8bed\u4e49\u4fdd\u6301\u65f6\u95f4\u70b9\u8bc4\u4ef7\u6a21\u578b\u5f3a\u5f31\u3002", "result": "\u901a\u8fc7\u5bf99\u79cd\u8bed\u8a00\u3001100\u4e2a\u82f1\u8bed\u9ad8\u591a\u4e49\u8bcd\u7684\u751f\u6210\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5404\u6a21\u578b\u53ca\u8bed\u8a00\u95f4\u8bed\u4e49\u9c81\u68d2\u6027\u5dee\u5f02\u660e\u663e\uff0c\u5efa\u7acb\u4e86\u65e0\u987b\u56e0\u679c\u5f52\u56e0\u7684\u6a21\u578b\u6392\u540d\u4f53\u7cfb\u3002", "conclusion": "\u4e0d\u540c\u591a\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u591a\u4e49\u8bcd\u65f6\u8868\u73b0\u51fa\u8bed\u4e49\u9c81\u68d2\u6027\u663e\u8457\u5dee\u5f02\uff0c\u4e14\u8bed\u8a00\u95f4\u8bed\u4e49\u5e72\u6270\uff08\u8bed\u8a00\u6ea2\u51fa\uff09\u73b0\u8c61\u666e\u904d\u5b58\u5728\u3002"}}
{"id": "2601.12555", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12555", "abs": "https://arxiv.org/abs/2601.12555", "authors": ["Yihong Liu", "Bingyu Xiong", "Hinrich Sch\u00fctze"], "title": "Evaluating Contextually Mediated Factual Recall in Multilingual Large Language Models", "comment": "preprint", "summary": "Large language models (LLMs) can recall a wide range of factual knowledge across languages. However, existing factual recall evaluations primarily assess fact retrieval in isolation, where the queried entity is explicitly named and the fact is requested directly. In natural language use, facts are often accessed through context, where the relevant entity is introduced only indirectly. In this work, we study contextually mediated factual recall, asking whether LLMs can reliably retrieve factual knowledge when the target entity is embedded in a naturalistic context rather than queried explicitly, across languages. We construct controlled prompts that preserve the underlying fact while introducing referential mediation through contextual sentences. To disentangle contextual effects from name-specific associations, we further compare performance using synthetic names and real names across languages. Evaluating multiple model families in five languages, we find that contextual mediation consistently degrades factual recall, with substantial variation across relations. Larger models are more robust to contextual mediation, exhibiting a reduced performance gap relative to direct queries, while the effect of real names and name origin is mixed and unsystematic. These findings highlight a gap between isolated factual recall and context-dependent language understanding in multilingual LLMs.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u591a\u8bed\u8a00\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u95f4\u63a5\u4e0a\u4e0b\u6587\u4e2d\u56de\u5fc6\u4e8b\u5b9e\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u4e0a\u4e0b\u6587\u8c03\u89e3\u666e\u904d\u964d\u4f4e\u56de\u5fc6\u6027\u80fd\uff0c\u8f83\u5927\u6a21\u578b\u66f4\u9c81\u68d2\uff0c\u771f\u5b9e\u59d3\u540d\u5f71\u54cd\u4e0d\u660e\u663e\uff0c\u63ed\u793a\u4e86\u73b0\u5b9e\u8bed\u8a00\u7406\u89e3\u4e0e\u5b64\u7acb\u4e8b\u5b9e\u56de\u5fc6\u95f4\u7684\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u4e8b\u5b9e\u56de\u5fc6\u8bc4\u4f30\u901a\u5e38\u53ea\u8003\u5bdf\u660e\u786e\u63d0\u53ca\u5b9e\u4f53\u548c\u76f4\u63a5\u8bf7\u6c42\u4e8b\u5b9e\u7684\u60c5\u51b5\uff0c\u800c\u73b0\u5b9e\u8bed\u8a00\u4e2d\u4e8b\u5b9e\u5e38\u901a\u8fc7\u4e0a\u4e0b\u6587\u95f4\u63a5\u8bbf\u95ee\uff0c\u7814\u7a76\u8fd9\u79cd\u4e0a\u4e0b\u6587\u8c03\u89e3\u4e0b\u7684\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u53ca\u5176\u591a\u8bed\u8a00\u8868\u73b0\u5177\u6709\u5b9e\u9645\u610f\u4e49\u3002", "method": "\u6784\u5efa\u63a7\u5236\u6027\u63d0\u793a\uff0c\u4fdd\u6301\u4e8b\u5b9e\u4e0d\u53d8\uff0c\u540c\u65f6\u901a\u8fc7\u4e0a\u4e0b\u6587\u53e5\u5b50\u5f15\u5165\u6307\u4ee3\u8c03\u89e3\u3002\u6bd4\u8f83\u4f7f\u7528\u5408\u6210\u59d3\u540d\u4e0e\u771f\u5b9e\u59d3\u540d\uff0c\u8bc4\u4f30\u591a\u6a21\u578b\u5bb6\u65cf\u5728\u4e94\u79cd\u8bed\u8a00\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u4e0a\u4e0b\u6587\u8c03\u89e3\u666e\u904d\u964d\u4f4e\u4e86\u6a21\u578b\u7684\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\uff0c\u4e0d\u540c\u5173\u7cfb\u95f4\u6548\u679c\u5dee\u5f02\u8f83\u5927\u3002\u8f83\u5927\u6a21\u578b\u5728\u4e0a\u4e0b\u6587\u8c03\u89e3\u4e0b\u8868\u73b0\u66f4\u7a33\u5065\u3002\u771f\u5b9e\u59d3\u540d\u548c\u59d3\u540d\u6765\u6e90\u5bf9\u6027\u80fd\u5f71\u54cd\u6df7\u6742\u4e14\u65e0\u7cfb\u7edf\u6027\u3002", "conclusion": "\u591a\u8bed\u8a00\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u901a\u8fc7\u4e0a\u4e0b\u6587\u95f4\u63a5\u8bbf\u95ee\u4e8b\u5b9e\u77e5\u8bc6\u65f6\u8868\u73b0\u51fa\u4e8b\u5b9e\u56de\u5fc6\u80fd\u529b\u4e0b\u964d\uff0c\u5c24\u5176\u662f\u5728\u4e0d\u540c\u5173\u7cfb\u4e2d\u8868\u73b0\u5dee\u5f02\u660e\u663e\u3002\u8f83\u5927\u7684\u6a21\u578b\u5bf9\u8fd9\u79cd\u4e0a\u4e0b\u6587\u8c03\u89e3\u8f83\u4e3a\u9c81\u68d2\uff0c\u8868\u73b0\u5dee\u8ddd\u8f83\u5c0f\uff0c\u800c\u5173\u4e8e\u771f\u5b9e\u59d3\u540d\u53ca\u5176\u6765\u6e90\u7684\u5f71\u54cd\u5219\u6ca1\u6709\u7cfb\u7edf\u6027\u89c4\u5f8b\u3002"}}
{"id": "2601.12607", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12607", "abs": "https://arxiv.org/abs/2601.12607", "authors": ["Anurag Acharya", "Timothy Vega", "Rizwan A. Ashraf", "Anshu Sharma", "Derek Parker", "Robert Rallo"], "title": "A Cloud-based Multi-Agentic Workflow for Science", "comment": null, "summary": "As Large Language Models (LLMs) become ubiquitous across various scientific domains, their lack of ability to perform complex tasks like running simulations or to make complex decisions limits their utility. LLM-based agents bridge this gap due to their ability to call external resources and tools and thus are now rapidly gaining popularity. However, coming up with a workflow that can balance the models, cloud providers, and external resources is very challenging, making implementing an agentic system more of a hindrance than a help. In this work, we present a domain-agnostic, model-independent workflow for an agentic framework that can act as a scientific assistant while being run entirely on cloud. Built with a supervisor agent marshaling an array of agents with individual capabilities, our framework brings together straightforward tasks like literature review and data analysis with more complex ones like simulation runs. We describe the framework here in full, including a proof-of-concept system we built to accelerate the study of Catalysts, which is highly important in the field of Chemistry and Material Science. We report the cost to operate and use this framework, including the breakdown of the cost by services use. We also evaluate our system on a custom-curated synthetic benchmark and a popular Chemistry benchmark, and also perform expert validation of the system. The results show that our system is able to route the task to the correct agent 90% of the time and successfully complete the assigned task 97.5% of the time for the synthetic tasks and 91% of the time for real-world tasks, while still achieving better or comparable accuracy to most frontier models, showing that this is a viable framework for other scientific domains to replicate.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u591a\u4ee3\u7406\u79d1\u5b66\u52a9\u7406\u6846\u67b6\uff0c\u80fd\u591f\u9ad8\u6548\u5b8c\u6210\u590d\u6742\u79d1\u5b66\u4efb\u52a1\uff0c\u9a8c\u8bc1\u5176\u51c6\u786e\u6027\u548c\u7ecf\u6d4e\u6027\uff0c\u5177\u5907\u5e7f\u6cdb\u63a8\u5e7f\u6f5c\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u5e7f\u6cdb\u5e94\u7528\u4f46\u65e0\u6cd5\u5b8c\u6210\u590d\u6742\u6a21\u62df\u6216\u51b3\u7b56\u4efb\u52a1\uff0c\u591a\u4ee3\u7406\u7cfb\u7edf\u901a\u8fc7\u8c03\u7528\u5916\u90e8\u5de5\u5177\u5f25\u8865\u4e86\u8fd9\u4e00\u7f3a\u9677\uff0c\u4f46\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u590d\u6742\uff0c\u5b9e\u65bd\u56f0\u96be\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u9886\u57df\u65e0\u5173\u3001\u6a21\u578b\u72ec\u7acb\u7684\u4e91\u7aef\u8fd0\u884c\u4ee3\u7406\u6846\u67b6\uff0c\u7531\u4e00\u4e2a\u4e3b\u7ba1\u4ee3\u7406\u534f\u8c03\u591a\u4e2a\u5177\u5907\u4e0d\u540c\u80fd\u529b\u7684\u4ee3\u7406\uff0c\u80fd\u591f\u6267\u884c\u4ece\u6587\u732e\u7efc\u8ff0\u5230\u590d\u6742\u6a21\u62df\u7684\u591a\u79cd\u4efb\u52a1\u3002", "result": "\u7cfb\u7edf\u5728\u5408\u6210\u4efb\u52a1\u4e2d\u4efb\u52a1\u8def\u7531\u6b63\u786e\u7387\u8fbe90%\uff0c\u4efb\u52a1\u5b8c\u6210\u7387\u8fbe97.5%\uff1b\u5728\u771f\u5b9e\u4efb\u52a1\u4e2d\u5b8c\u6210\u7387\u8fbe91%\uff0c\u51c6\u786e\u7387\u8fbe\u5230\u6216\u4f18\u4e8e\u524d\u6cbf\u6a21\u578b\uff0c\u8fd0\u8425\u6210\u672c\u5408\u7406\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u4ee3\u7406\u534f\u4f5c\u7684\u79d1\u5b66\u52a9\u7406\u6846\u67b6\u80fd\u591f\u9ad8\u6548\u8def\u7531\u4efb\u52a1\u5e76\u6210\u529f\u5b8c\u6210\u4efb\u52a1\uff0c\u51c6\u786e\u7387\u8fbe\u5230\u6216\u8d85\u8fc7\u5f53\u524d\u5148\u8fdb\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u53ef\u884c\u6027\u3002"}}
{"id": "2601.12618", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12618", "abs": "https://arxiv.org/abs/2601.12618", "authors": ["Elham Tajik", "Conrad Borchers", "Bahar Shahrokhian", "Sebastian Simon", "Ali Keramati", "Sonika Pal", "Sreecharan Sankaranarayanan"], "title": "Disagreement as Data: Reasoning Trace Analytics in Multi-Agent Systems", "comment": "LAK 2026 conference paper, 7 pages", "summary": "Learning analytics researchers often analyze qualitative student data such as coded annotations or interview transcripts to understand learning processes. With the rise of generative AI, fully automated and human-AI workflows have emerged as promising methods for analysis. However, methodological standards to guide such workflows remain limited. In this study, we propose that reasoning traces generated by large language model (LLM) agents, especially within multi-agent systems, constitute a novel and rich form of process data to enhance interpretive practices in qualitative coding. We apply cosine similarity to LLM reasoning traces to systematically detect, quantify, and interpret disagreements among agents, reframing disagreement as a meaningful analytic signal. Analyzing nearly 10,000 instances of agent pairs coding human tutoring dialog segments, we show that LLM agents' semantic reasoning similarity robustly differentiates consensus from disagreement and correlates with human coding reliability. Qualitative analysis guided by this metric reveals nuanced instructional sub-functions within codes and opportunities for conceptual codebook refinement. By integrating quantitative similarity metrics with qualitative review, our method has the potential to improve and accelerate establishing inter-rater reliability during coding by surfacing interpretive ambiguity, especially when LLMs collaborate with humans. We discuss how reasoning-trace disagreements represent a valuable new class of analytic signals advancing methodological rigor and interpretive depth in educational research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u591a\u667a\u80fd\u4f53\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u65b0\u578b\u8fc7\u7a0b\u6570\u636e\uff0c\u7ed3\u5408\u4f59\u5f26\u76f8\u4f3c\u5ea6\u68c0\u6d4b\u667a\u80fd\u4f53\u5206\u6b67\uff0c\u4ece\u800c\u63d0\u5347\u5b9a\u6027\u7f16\u7801\u5206\u6790\u7684\u4e25\u8c28\u6027\u548c\u6548\u7387\uff0c\u4fc3\u8fdb\u6559\u80b2\u5b66\u4e60\u5206\u6790\u65b9\u6cd5\u7684\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u751f\u6210\u5f0fAI\u7684\u81ea\u52a8\u5316\u4e0e\u4eba\u673a\u534f\u540c\u5b66\u4e60\u5206\u6790\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u7684\u65b9\u6cd5\u5b66\u6807\u51c6\uff0c\u4e9f\u9700\u5f00\u53d1\u65b0\u578b\u5bcc\u542b\u89e3\u91ca\u4ef7\u503c\u7684\u8fc7\u7a0b\u6570\u636e\u5f62\u5f0f\u4ee5\u63d0\u5347\u5b9a\u6027\u7f16\u7801\u7684\u5206\u6790\u6548\u679c\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\uff0c\u901a\u8fc7\u4f59\u5f26\u76f8\u4f3c\u5ea6\u91cf\u5316\u548c\u89e3\u8bfb\u667a\u80fd\u4f53\u95f4\u5206\u6b67\uff0c\u7ed3\u5408\u5b9a\u91cf\u76f8\u4f3c\u5ea6\u6307\u6807\u4e0e\u5b9a\u6027\u5206\u6790\u6307\u5bfc\u4ee3\u7801\u4e00\u81f4\u6027\u5ba1\u67e5\u3002", "result": "\u901a\u8fc7\u5206\u6790\u8fd1\u4e07\u6b21\u667a\u80fd\u4f53\u5bf9\u4eba\u7c7b\u8f85\u5bfc\u5bf9\u8bdd\u7f16\u7801\uff0c\u53d1\u73b0LLM\u7684\u8bed\u4e49\u63a8\u7406\u76f8\u4f3c\u5ea6\u80fd\u6709\u6548\u533a\u5206\u5171\u8bc6\u4e0e\u5206\u6b67\uff0c\u5e76\u4e0e\u4eba\u7c7b\u7f16\u7801\u4e00\u81f4\u6027\u76f8\u5173\uff1b\u5b9a\u6027\u5206\u6790\u63ed\u793a\u7f16\u7801\u7684\u6559\u5b66\u5b50\u529f\u80fd\u7ec6\u8282\u53ca\u4ee3\u7801\u672c\u4fee\u8ba2\u673a\u4f1a\u3002", "conclusion": "\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u5206\u6b67\u662f\u4e00\u7c7b\u6709\u4ef7\u503c\u7684\u5206\u6790\u4fe1\u53f7\uff0c\u53ef\u63d0\u5347\u6559\u80b2\u7814\u7a76\u4e2d\u7684\u65b9\u6cd5\u4e25\u8c28\u6027\u548c\u89e3\u91ca\u6df1\u5ea6\u3002"}}
{"id": "2601.12632", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.12632", "abs": "https://arxiv.org/abs/2601.12632", "authors": ["Kriti Bhattarai", "Vipina K. Keloth", "Donald Wright", "Andrew Loza", "Yang Ren", "Hua Xu"], "title": "BioPulse-QA: A Dynamic Biomedical Question-Answering Benchmark for Evaluating Factuality, Robustness, and Bias in Large Language Models", "comment": null, "summary": "Objective: Large language models (LLMs) are increasingly applied in biomedical settings, and existing benchmark datasets have played an important role in supporting model development and evaluation. However, these benchmarks often have limitations. Many rely on static or outdated datasets that fail to capture the dynamic, context-rich, and high-stakes nature of biomedical knowledge. They also carry increasing risk of data leakage due to overlap with model pretraining corpora and often overlook critical dimensions such as robustness to linguistic variation and potential demographic biases.\n  Materials and Methods: To address these gaps, we introduce BioPulse-QA, a benchmark that evaluates LLMs on answering questions from newly published biomedical documents including drug labels, trial protocols, and clinical guidelines. BioPulse-QA includes 2,280 expert-verified question answering (QA) pairs and perturbed variants, covering both extractive and abstractive formats. We evaluate four LLMs - GPT-4o, GPT-o1, Gemini-2.0-Flash, and LLaMA-3.1 8B Instruct - released prior to the publication dates of the benchmark documents.\n  Results: GPT-o1 achieves the highest relaxed F1 score (0.92), followed by Gemini-2.0-Flash (0.90) on drug labels. Clinical trials are the most challenging source, with extractive F1 scores as low as 0.36.\n  Discussion and Conclusion: Performance differences are larger for paraphrasing than for typographical errors, while bias testing shows negligible differences. BioPulse-QA provides a scalable and clinically relevant framework for evaluating biomedical LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6700\u65b0\u751f\u7269\u533b\u5b66\u6587\u6863\u7684\u65b0\u95ee\u7b54\u57fa\u51c6BioPulse-QA\uff0c\u8bc4\u4f30\u591a\u6b3e\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u548c\u836f\u7269\u6587\u672c\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0GPT-o1\u4f18\u4e8e\u5176\u4ed6\u6a21\u578b\uff0c\u4e34\u5e8a\u8bd5\u9a8c\u5185\u5bb9\u6700\u5177\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u7684\u751f\u7269\u533b\u5b66\u9886\u57df\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u57fa\u51c6\u6570\u636e\u96c6\u9759\u6001\u4e14\u8fc7\u65f6\uff0c\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u8be5\u9886\u57df\u77e5\u8bc6\u7684\u52a8\u6001\u6027\u548c\u590d\u6742\u6027\uff0c\u5e76\u5b58\u5728\u6570\u636e\u6cc4\u9732\u548c\u504f\u89c1\u95ee\u9898\u3002", "method": "\u5f15\u5165BioPulse-QA\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5305\u542b2280\u5bf9\u4e13\u5bb6\u9a8c\u8bc1\u7684\u95ee\u7b54\u5bf9\uff0c\u57fa\u4e8e\u6700\u65b0\u53d1\u5e03\u7684\u751f\u7269\u533b\u5b66\u6587\u6863\uff0c\u6db5\u76d6\u63d0\u53d6\u5f0f\u548c\u751f\u6210\u5f0f\u95ee\u7b54\uff0c\u5e76\u6d4b\u8bd5\u56db\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u3002", "result": "GPT-o1\u5728\u836f\u7269\u6807\u7b7e\u95ee\u7b54\u4e2d\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u8fbe\u52300.92\uff0c\u4e34\u5e8a\u8bd5\u9a8c\u6570\u636e\u7c7b\u522b\u6700\u5177\u6311\u6218\u6027\uff0c\u63d0\u53d6\u5f0f\u95ee\u7b54F1\u5206\u6570\u4f4e\u81f30.36\u3002", "conclusion": "BioPulse-QA\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u6269\u5c55\u4e14\u4e34\u5e8a\u76f8\u5173\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u66f4\u51c6\u786e\u8bc4\u4f30\u751f\u7269\u533b\u5b66\u9886\u57df\u7684\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u68c0\u6d4b\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u53d8\u4f53\u548c\u504f\u89c1\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u3002"}}
{"id": "2601.12639", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12639", "abs": "https://arxiv.org/abs/2601.12639", "authors": ["Daniel Vennemeyer", "Punya Syon Pandey", "Phan Anh Duong", "Michael Umeokoli", "Samuel Ratnam"], "title": "Objective Matters: Fine-Tuning Objectives Shape Safety, Robustness, and Persona Drift", "comment": null, "summary": "Fine-tuning LLMs on benign data can still degrade alignment and adversarial robustness, yet direct analysis of the role of fine-tuning objectives in shaping these safety outcomes remain limited. We present a controlled comparison of six fine-tuning objectives -- Supervised Fine-Tuning, Direct Preference Optimization, Conditional Fine-Tuning, Inoculation Prompting, Odds Ratio Preference Optimization, and KL-regularized fine-tuning -- holding data, domain, architecture, and optimization fixed. Across closed-form reasoning and open-ended generation tasks, we find that objective choice induces systematic, scale-dependent shifts along the safety-capability frontier. At small training budgets, robustness is similar across objectives but capability differs. At larger budgets, objectives diverge sharply: supervised and preference-based tuning tightly couple capability gains to increased adversarial vulnerability and persona drift, while objectives that constrain learning signals -- especially ORPO and KL-regularization -- substantially mitigate both. Fine-tuning objectives therefore matter little for safety at small scales but become a primary driver of adversarial robustness and latent persona stability as training scale increases.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86\u516d\u79cd\u5fae\u8c03\u76ee\u6807\u5728\u76f8\u540c\u6761\u4ef6\u4e0b\u5bf9\u5927\u6a21\u578b\u5b89\u5168\u6027\u548c\u80fd\u529b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5fae\u8c03\u76ee\u6807\u5bf9\u5b89\u5168\u6027\u5f71\u54cd\u968f\u8bad\u7ec3\u89c4\u6a21\u663e\u8457\u53d8\u5316\uff0c\u662f\u63d0\u5347\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u4fdd\u6301\u4eba\u683c\u7a33\u5b9a\u7684\u91cd\u8981\u56e0\u7d20\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u4e2d\u5bf9\u5fae\u8c03\u4e0d\u540c\u76ee\u6807\u5982\u4f55\u5f71\u54cd\u5927\u6a21\u578b\u7684\u5b89\u5168\u6027\uff0c\u5c24\u5176\u662f\u5bf9\u9f50\u6027\u548c\u5bf9\u6297\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u5206\u6790\u6709\u9650\u3002", "method": "\u8bbe\u8ba1\u516d\u79cd\u5fae\u8c03\u76ee\u6807\uff08\u76d1\u7763\u5fae\u8c03\u3001\u76f4\u63a5\u504f\u597d\u4f18\u5316\u3001\u6761\u4ef6\u5fae\u8c03\u3001\u63a5\u79cd\u63d0\u793a\u3001\u8d54\u7387\u6bd4\u504f\u597d\u4f18\u5316\u3001KL\u6b63\u5219\u5316\u5fae\u8c03\uff09\uff0c\u5728\u76f8\u540c\u6570\u636e\u3001\u9886\u57df\u3001\u67b6\u6784\u548c\u4f18\u5316\u6761\u4ef6\u4e0b\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "\u5728\u5c01\u95ed\u63a8\u7406\u548c\u5f00\u653e\u751f\u6210\u4efb\u52a1\u4e2d\uff0c\u4e0d\u540c\u5fae\u8c03\u76ee\u6807\u5728\u5b89\u5168\u4e0e\u80fd\u529b\u7684\u6743\u8861\u4e0a\u8868\u73b0\u51fa\u7cfb\u7edf\u6027\u4e14\u4f9d\u8d56\u89c4\u6a21\u7684\u5dee\u5f02\uff1a\u5c0f\u89c4\u6a21\u8bad\u7ec3\u65f6\u5404\u76ee\u6807\u9c81\u68d2\u6027\u76f8\u8fd1\u4f46\u80fd\u529b\u4e0d\u540c\uff0c\u5927\u89c4\u6a21\u8bad\u7ec3\u65f6\u76d1\u7763\u6216\u504f\u597d\u76ee\u6807\u867d\u63d0\u5347\u80fd\u529b\u4f46\u5e26\u6765\u5bf9\u6297\u8106\u5f31\u6027\u548c\u4eba\u683c\u6f02\u79fb\uff1b\u9650\u5236\u4fe1\u53f7\u7684\u76ee\u6807\uff08\u5c24\u5176\u662f\u8d54\u7387\u6bd4\u4f18\u5316\u548cKL\u6b63\u5219\u5316\uff09\u6709\u6548\u51cf\u8f7b\u4e86\u8fd9\u4e9b\u95ee\u9898\u3002", "conclusion": "\u5fae\u8c03\u76ee\u6807\u5728\u5c0f\u89c4\u6a21\u8bad\u7ec3\u65f6\u5bf9\u5b89\u5168\u5f71\u54cd\u6709\u9650\uff0c\u4f46\u968f\u7740\u8bad\u7ec3\u89c4\u6a21\u589e\u52a0\uff0c\u6210\u4e3a\u51b3\u5b9a\u6a21\u578b\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u4eba\u683c\u7a33\u5b9a\u6027\u7684\u5173\u952e\u56e0\u7d20\u3002"}}
{"id": "2601.12648", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12648", "abs": "https://arxiv.org/abs/2601.12648", "authors": ["Nafiz Imtiaz Khan", "Kylie Cleland", "Vladimir Filkov", "Roger Eric Goldman"], "title": "Intelligent Documentation in Medical Education: Can AI Replace Manual Case Logging?", "comment": "51 pages, 12 figures, 8 tables. Feasibility study using retrospective radiology reports. Submitted to JAMIA Open (under review)", "summary": "Procedural case logs are a core requirement in radiology training, yet they are time-consuming to complete and prone to inconsistency when authored manually. This study investigates whether large language models (LLMs) can automate procedural case log documentation directly from free-text radiology reports. We evaluate multiple local and commercial LLMs under instruction-based and chain-of-thought prompting to extract structured procedural information from 414 curated interventional radiology reports authored by nine residents between 2018 and 2024. Model performance is assessed using sensitivity, specificity, and F1-score, alongside inference latency and token efficiency to estimate operational cost. Results show that both local and commercial models achieve strong extraction performance, with best F1-scores approaching 0.87, while exhibiting different trade-offs between speed and cost. Automation using LLMs has the potential to substantially reduce clerical burden for trainees and improve consistency in case logging. These findings demonstrate the feasibility of AI-assisted documentation in medical education and highlight the need for further validation across institutions and clinical workflows.", "AI": {"tldr": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u63d0\u53d6\u653e\u5c04\u5b66\u75c5\u4f8b\u65e5\u5fd7\u4fe1\u606f\uff0c\u80fd\u6709\u6548\u51cf\u8f7b\u5b66\u5458\u6587\u4e66\u8d1f\u62c5\u5e76\u63d0\u5347\u8bb0\u5f55\u4e00\u81f4\u6027\uff0c\u9a8c\u8bc1\u4e86AI\u8f85\u52a9\u533b\u5b66\u6559\u80b2\u6587\u6863\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u653e\u5c04\u5b66\u57f9\u8bad\u4e2d\u75c5\u4f8b\u65e5\u5fd7\u9700\u8981\u624b\u52a8\u586b\u5199\uff0c\u65e2\u8017\u65f6\u53c8\u6613\u4ea7\u751f\u4e0d\u4e00\u81f4\uff0c\u6545\u63a2\u7d22\u4f7f\u7528LLMs\u81ea\u52a8\u5316\u75c5\u4f8b\u65e5\u5fd7\u6587\u6863\u7684\u53ef\u884c\u6027\u3002", "method": "\u91c7\u7528\u591a\u79cd\u672c\u5730\u53ca\u5546\u4e1a\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u6307\u4ee4\u5f0f\u548c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u4e0b\uff0c\u4ece414\u4efd\u4ecb\u5165\u653e\u5c04\u5b66\u62a5\u544a\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u7a0b\u5e8f\u6027\u4fe1\u606f\uff0c\u8bc4\u4f30\u6a21\u578b\u7684\u7075\u654f\u5ea6\u3001\u7279\u5f02\u6027\u3001F1\u5206\u6570\u4ee5\u53ca\u63a8\u7406\u5ef6\u8fdf\u548c\u4ee4\u724c\u6548\u7387\u3002", "result": "\u6a21\u578b\u53d6\u5f97\u4e86\u63a5\u8fd10.87\u7684\u6700\u4f73F1\u5206\u6570\uff0c\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u5728\u901f\u5ea6\u548c\u6210\u672c\u65b9\u9762\u5b58\u5728\u4e0d\u540c\u6743\u8861\uff0c\u663e\u793a\u51fa\u81ea\u52a8\u5316\u75c5\u4f8b\u65e5\u5fd7\u8bb0\u5f55\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u6709\u6548\u81ea\u52a8\u5316\u653e\u5c04\u5b66\u57f9\u8bad\u4e2d\u7684\u75c5\u4f8b\u65e5\u5fd7\u8bb0\u5f55\uff0c\u663e\u8457\u51cf\u8f7b\u5b66\u5458\u7684\u6587\u4e66\u8d1f\u62c5\uff0c\u63d0\u9ad8\u8bb0\u5f55\u4e00\u81f4\u6027\u3002"}}
{"id": "2601.12658", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12658", "abs": "https://arxiv.org/abs/2601.12658", "authors": ["Tianyi Yang", "Nashrah Haque", "Vaishnave Jonnalagadda", "Yuya Jeremy Ong", "Zhehui Chen", "Yanzhao Wu", "Lei Yu", "Divyesh Jadav", "Wenqi Wei"], "title": "Augmenting Question Answering with A Hybrid RAG Approach", "comment": "10 pages, 5 tables, 2 figures; presented at IEEE CogMI 2025", "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful technique for enhancing the quality of responses in Question-Answering (QA) tasks. However, existing approaches often struggle with retrieving contextually relevant information, leading to incomplete or suboptimal answers. In this paper, we introduce Structured-Semantic RAG (SSRAG), a hybrid architecture that enhances QA quality by integrating query augmentation, agentic routing, and a structured retrieval mechanism combining vector and graph based techniques with context unification. By refining retrieval processes and improving contextual grounding, our approach improves both answer accuracy and informativeness. We conduct extensive evaluations on three popular QA datasets, TruthfulQA, SQuAD and WikiQA, across five Large Language Models (LLMs), demonstrating that our proposed approach consistently improves response quality over standard RAG implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSSRAG\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u8bed\u4e49\u641c\u7d22\u63d0\u5347\u95ee\u7b54\u7cfb\u7edf\u56de\u7b54\u7684\u51c6\u786e\u6027\u548c\u4e30\u5bcc\u6027\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u548c\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u5728\u68c0\u7d22\u4e0a\u4e0b\u6587\u76f8\u5173\u4fe1\u606f\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5bfc\u81f4\u56de\u7b54\u4e0d\u5b8c\u6574\u6216\u6b21\u4f18\u3002", "method": "\u63d0\u51faSSRAG\u6df7\u5408\u67b6\u6784\uff0c\u7ed3\u5408\u5411\u91cf\u548c\u56fe\u68c0\u7d22\u6280\u672f\u53ca\u4e0a\u4e0b\u6587\u7edf\u4e00\uff0c\u901a\u8fc7\u67e5\u8be2\u589e\u5f3a\u548c\u4ee3\u7406\u8def\u7531\u4f18\u5316\u68c0\u7d22\u6d41\u7a0b\u3002", "result": "\u5728TruthfulQA\u3001SQuAD\u548cWikiQA\u4e09\u4e2a\u6570\u636e\u96c6\u53ca\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cSSRAG\u5747\u663e\u8457\u4f18\u4e8e\u6807\u51c6RAG\u5b9e\u73b0\u3002", "conclusion": "SSRAG\u901a\u8fc7\u67e5\u8be2\u589e\u5f3a\u3001\u4ee3\u7406\u8def\u7531\u548c\u7ed3\u6784\u5316\u68c0\u7d22\u673a\u5236\u6539\u8fdb\u68c0\u7d22\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u95ee\u7b54\u7cfb\u7edf\u7684\u7b54\u6848\u51c6\u786e\u6027\u548c\u4fe1\u606f\u4e30\u5bcc\u5ea6\u3002"}}
{"id": "2601.12696", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12696", "abs": "https://arxiv.org/abs/2601.12696", "authors": ["Tassallah Abdullahi", "Macton Mgonzo", "Mardiyyah Oduwole", "Paul Okewunmi", "Abraham Owodunni", "Ritambhara Singh", "Carsten Eickhoff"], "title": "UbuntuGuard: A Culturally-Grounded Policy Benchmark for Equitable AI Safety in African Languages", "comment": "12 pages", "summary": "Current guardian models are predominantly Western-centric and optimized for high-resource languages, leaving low-resource African languages vulnerable to evolving harms, cross-lingual safety failures, and cultural misalignment. Moreover, most guardian models rely on rigid, predefined safety categories that fail to generalize across diverse linguistic and sociocultural contexts. Robust safety, therefore, requires flexible, runtime-enforceable policies and benchmarks that reflect local norms, harm scenarios, and cultural expectations. We introduce UbuntuGuard, the first African policy-based safety benchmark built from adversarial queries authored by 155 domain experts across sensitive fields, including healthcare. From these expert-crafted queries, we derive context-specific safety policies and reference responses that capture culturally grounded risk signals, enabling policy-aligned evaluation of guardian models. We evaluate 13 models, comprising six general-purpose LLMs and seven guardian models across three distinct variants: static, dynamic, and multilingual. Our findings reveal that existing English-centric benchmarks overestimate real-world multilingual safety, cross-lingual transfer provides partial but insufficient coverage, and dynamic models, while better equipped to leverage policies at inference time, still struggle to fully localize African-language contexts. These findings highlight the urgent need for multilingual, culturally grounded safety benchmarks to enable the development of reliable and equitable guardian models for low-resource languages. Our code can be found online.\\footnote{Code repository available at https://github.com/hemhemoh/UbuntuGuard.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecdUbuntuGuard\uff0c\u9996\u4e2a\u975e\u6d32\u8bed\u8a00\u5b89\u5168\u57fa\u51c6\uff0c\u57fa\u4e8e\u4e13\u5bb6\u8bbe\u8ba1\u7684\u5bf9\u6297\u67e5\u8be2\uff0c\u8bc4\u4f30\u73b0\u6709\u5b88\u62a4\u6a21\u578b\u5728\u975e\u6d32\u8bed\u8a00\u548c\u6587\u5316\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u4e0d\u8db3\uff0c\u5f3a\u8c03\u5f00\u53d1\u591a\u8bed\u8a00\u6587\u5316\u5b89\u5168\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5b88\u62a4\u6a21\u578b\u4e3b\u8981\u9488\u5bf9\u9ad8\u8d44\u6e90\u7684\u897f\u65b9\u8bed\u8a00\u8bbe\u8ba1\uff0c\u4e0d\u9002\u5408\u4f4e\u8d44\u6e90\u7684\u975e\u6d32\u8bed\u8a00\uff0c\u5b58\u5728\u8de8\u8bed\u8a00\u5b89\u5168\u5931\u8d25\u53ca\u6587\u5316\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u4e9f\u9700\u7ed3\u5408\u5f53\u5730\u6587\u5316\u548c\u98ce\u9669\u60c5\u5883\u7684\u7075\u6d3b\u5b89\u5168\u653f\u7b56\u548c\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86UbuntuGuard\uff0c\u8fd9\u662f\u9996\u4e2a\u57fa\u4e8e\u653f\u7b56\u7684\u975e\u6d32\u5b89\u5168\u57fa\u51c6\uff0c\u5229\u7528155\u540d\u9886\u57df\u4e13\u5bb6\u64b0\u5199\u7684\u5bf9\u6297\u6027\u67e5\u8be2\u5236\u5b9a\u5177\u4f53\u5b89\u5168\u653f\u7b56\u548c\u53c2\u8003\u56de\u7b54\uff0c\u57fa\u4e8e\u8fd9\u4e9b\u5b9e\u73b0\u5bf9\u5b88\u62a4\u6a21\u578b\u7684\u653f\u7b56\u5bf9\u9f50\u8bc4\u4f30\u3002\u8bc4\u4f30\u4e8613\u4e2a\u6a21\u578b\uff0c\u5305\u542b\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e09\u79cd\u53d8\u4f53\u7684\u5b88\u62a4\u6a21\u578b\uff08\u9759\u6001\u3001\u52a8\u6001\u3001\u591a\u8bed\u8a00\uff09\u3002", "result": "\u901a\u8fc7\u4e13\u5bb6\u8bbe\u8ba1\u7684\u4e0a\u4e0b\u6587\u7279\u5b9a\u653f\u7b56\u548c\u67e5\u8be2\uff0c\u8bc4\u4f30\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u548c\u975e\u6d32\u6587\u5316\u80cc\u666f\u4e0b\u8868\u73b0\u4e0d\u8db3\uff0c\u8868\u660e\u9700\u8981\u5f00\u53d1\u7075\u6d3b\u3001\u591a\u8bed\u8a00\u3001\u591a\u6587\u5316\u7684\u5b89\u5168\u57fa\u51c6\u4ee5\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6a21\u578b\u5b89\u5168\u6027\u3002", "conclusion": "\u73b0\u6709\u7684\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\u7684\u5b89\u5168\u57fa\u51c6\u9ad8\u4f30\u4e86\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u7684\u5b9e\u9645\u5b89\u5168\u6027\uff0c\u8de8\u8bed\u8a00\u8fc1\u79fb\u80fd\u529b\u6709\u9650\uff0c\u52a8\u6001\u6a21\u578b\u867d\u6709\u6240\u63d0\u5347\u4f46\u4ecd\u65e0\u6cd5\u5b8c\u5168\u9002\u5e94\u975e\u6d32\u8bed\u8a00\u7684\u5177\u4f53\u6587\u5316\u8bed\u5883\uff0c\u8feb\u5207\u9700\u8981\u591a\u8bed\u8a00\u3001\u6587\u5316\u4f9d\u6258\u7684\u5b89\u5168\u57fa\u51c6\u6765\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u76d1\u7ba1\u6a21\u578b\u53d1\u5c55\u3002"}}
{"id": "2601.12698", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12698", "abs": "https://arxiv.org/abs/2601.12698", "authors": ["Qiuyi Qu", "Yicheng Sui", "Yufei Sun", "Rui Chen", "Xiaofei Zhang", "Yuzhi Zhang", "Haofeng Wang", "Ge Lan", "Ning Zhang"], "title": "A Two-Stage GPU Kernel Tuner Combining Semantic Refactoring and Search-Based Optimization", "comment": null, "summary": "GPU code optimization is a key performance bottleneck for HPC workloads as well as large-model training and inference. Although compiler optimizations and hand-written kernels can partially alleviate this issue, achieving near-hardware-limit performance still relies heavily on manual code refactoring and parameter tuning. Recent progress in LLM-agent-based kernel generation and optimization has been reported, yet many approaches primarily focus on direct code rewriting, where parameter choices are often implicit and hard to control, or require human intervention, leading to unstable performance gains. This paper introduces a template-based rewriting layer on top of an agent-driven iterative loop: kernels are semantically refactored into explicitly parameterizable templates, and template parameters are then optimized via search-based autotuning, yielding more stable and higher-quality speedups. Experiments on a set of real-world kernels demonstrate speedups exceeding 3x in the best case. We extract representative CUDA kernels from SGLang as evaluation targets; the proposed agentic tuner iteratively performs templating, testing, analysis, and planning, and leverages profiling feedback to execute constrained parameter search under hardware resource limits. Compared to agent-only direct rewriting, the template-plus-search design significantly reduces the randomness of iterative optimization, making the process more interpretable and enabling a more systematic approach toward high-performance configurations. The proposed method can be further extended to OpenCL, HIP, and other backends to deliver automated performance optimization for real production workloads.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6a21\u677f\u91cd\u5199\u52a0\u641c\u7d22\u81ea\u52a8\u8c03\u4f18\u7684\u4ee3\u7406\u9a71\u52a8GPU\u6838\u51fd\u6570\u4f18\u5316\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u7a33\u5b9a\u6027\u548c\u52a0\u901f\u6548\u679c\uff0c\u6700\u9ad8\u8d853\u500d\uff0c\u4f18\u5316\u8fc7\u7a0b\u66f4\u5177\u53ef\u63a7\u6027\u548c\u7cfb\u7edf\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u76f4\u63a5\u4ee3\u7801\u91cd\u5199\u65b9\u6cd5\u5b58\u5728\u53c2\u6570\u9690\u5f0f\u96be\u63a7\u548c\u4f9d\u8d56\u4eba\u5de5\u5e72\u9884\u7684\u95ee\u9898\uff0c\u5bfc\u81f4\u6027\u80fd\u63d0\u5347\u4e0d\u7a33\u5b9a\uff0c\u96be\u5b9e\u73b0\u63a5\u8fd1\u786c\u4ef6\u6781\u9650\u7684\u6027\u80fd\u4f18\u5316\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u4ee3\u7406\u9a71\u52a8\u7684\u8fed\u4ee3\u5faa\u73af\u6846\u67b6\uff0c\u5c06\u6838\u51fd\u6570\u8bed\u4e49\u91cd\u6784\u4e3a\u663e\u5f0f\u53ef\u8c03\u53c2\u6570\u7684\u6a21\u677f\uff0c\u5e76\u901a\u8fc7\u57fa\u4e8e\u641c\u7d22\u7684\u81ea\u52a8\u8c03\u4f18\u5bf9\u6a21\u677f\u53c2\u6570\u8fdb\u884c\u4f18\u5316\u3002\u8be5\u6846\u67b6\u5305\u62ec\u6a21\u677f\u5316\u3001\u6d4b\u8bd5\u3001\u5206\u6790\u548c\u89c4\u5212\u6b65\u9aa4\uff0c\u5e76\u5229\u7528\u6027\u80fd\u5206\u6790\u53cd\u9988\u5728\u786c\u4ef6\u8d44\u6e90\u9650\u5236\u4e0b\u8fdb\u884c\u53d7\u7ea6\u675f\u53c2\u6570\u641c\u7d22\u3002", "result": "\u5728\u5b9e\u9645\u6765\u81eaSGLang\u7684CUDA\u6838\u51fd\u6570\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u9ad8\u8d85\u8fc73\u500d\u7684\u52a0\u901f\uff0c\u4f18\u5316\u8fc7\u7a0b\u66f4\u5177\u53ef\u89e3\u91ca\u6027\u548c\u7cfb\u7edf\u6027\uff0c\u663e\u8457\u51cf\u5c11\u8fed\u4ee3\u4f18\u5316\u7684\u968f\u673a\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6a21\u677f\u7684\u91cd\u5199\u5c42\u7ed3\u5408\u4ee3\u7406\u9a71\u52a8\u7684\u8fed\u4ee3\u5faa\u73af\u53ca\u641c\u7d22\u81ea\u52a8\u8c03\u4f18\uff0c\u5b9e\u73b0\u4e86\u66f4\u52a0\u7a33\u5b9a\u548c\u9ad8\u8d28\u91cf\u7684GPU\u6838\u51fd\u6570\u6027\u80fd\u4f18\u5316\uff0c\u6700\u5927\u52a0\u901f\u8d85\u8fc73\u500d\u3002"}}
{"id": "2601.12731", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12731", "abs": "https://arxiv.org/abs/2601.12731", "authors": ["Stefano Civelli", "Pietro Bernardelle", "Nicol\u00f2 Brunello", "Gianluca Demartini"], "title": "A Shared Geometry of Difficulty in Multilingual Language Models", "comment": null, "summary": "Predicting problem-difficulty in large language models (LLMs) refers to estimating how difficult a task is according to the model itself, typically by training linear probes on its internal representations. In this work, we study the multilingual geometry of problem-difficulty in LLMs by training linear probes using the AMC subset of the Easy2Hard benchmark, translated into 21 languages. We found that difficulty-related signals emerge at two distinct stages of the model internals, corresponding to shallow (early-layers) and deep (later-layers) internal representations, that exhibit functionally different behaviors. Probes trained on deep representations achieve high accuracy when evaluated on the same language but exhibit poor cross-lingual generalization. In contrast, probes trained on shallow representations generalize substantially better across languages, despite achieving lower within-language performance. Together, these results suggest that LLMs first form a language-agnostic representation of problem difficulty, which subsequently becomes language-specific. This closely aligns with existing findings in LLM interpretability showing that models tend to operate in an abstract conceptual space before producing language-specific outputs. We demonstrate that this two-stage representational process extends beyond semantic content to high-level meta-cognitive properties such as problem-difficulty estimation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u95ee\u9898\u96be\u5ea6\u7684\u591a\u8bed\u8a00\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u73b0\u5b58\u5728\u6d45\u5c42\u8bed\u8a00\u65e0\u5173\u548c\u6df1\u5c42\u8bed\u8a00\u7279\u5b9a\u7684\u4e24\u9636\u6bb5\u96be\u5ea6\u7f16\u7801\u673a\u5236\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u5982\u4f55\u7f16\u7801\u95ee\u9898\u96be\u5ea6\u53ca\u5176\u5185\u90e8\u8868\u5f81\u7684\u51e0\u4f55\u7ed3\u6784\u3002", "method": "\u901a\u8fc7\u4f7f\u7528Easy2Hard\u57fa\u51c6\u7684AMC\u5b50\u96c6\uff0c\u7ffb\u8bd1\u621021\u79cd\u8bed\u8a00\uff0c\u5e76\u8bad\u7ec3\u7ebf\u6027\u63a2\u9488\u5206\u522b\u5728\u6a21\u578b\u7684\u6d45\u5c42\u548c\u6df1\u5c42\u8868\u793a\u4e0a\u8fdb\u884c\u95ee\u9898\u96be\u5ea6\u9884\u6d4b\u3002", "result": "\u6d45\u5c42\u8868\u793a\u7684\u63a2\u9488\u5728\u8de8\u8bed\u8a00\u96be\u5ea6\u9884\u6d4b\u4e2d\u8868\u73b0\u66f4\u597d\uff0c\u6df1\u5c42\u8868\u793a\u5728\u5355\u4e00\u8bed\u8a00\u8868\u73b0\u66f4\u4f18\uff0c\u63ed\u793a\u4e86\u95ee\u9898\u96be\u5ea6\u8868\u5f81\u7684\u4e24\u9636\u6bb5\u8fc7\u7a0b\u53ca\u5176\u8bed\u8a00\u4f9d\u8d56\u6027\u5dee\u5f02\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u95ee\u9898\u96be\u5ea6\u65f6\u8868\u73b0\u51fa\u4e24\u4e2a\u4e0d\u540c\u9636\u6bb5\u7684\u5185\u90e8\u8868\u5f81\uff1a\u6d45\u5c42\u8868\u793a\u5177\u6709\u8f83\u597d\u7684\u8de8\u8bed\u8a00\u6cdb\u5316\u80fd\u529b\uff0c\u800c\u6df1\u5c42\u8868\u793a\u5728\u540c\u8bed\u8a00\u5185\u8868\u73b0\u66f4\u4f18\u4f46\u8de8\u8bed\u8a00\u6cdb\u5316\u8f83\u5dee\uff0c\u8868\u660e\u6a21\u578b\u5148\u5f62\u6210\u8bed\u8a00\u65e0\u5173\u7684\u96be\u5ea6\u8868\u5f81\uff0c\u540e\u8f6c\u5316\u4e3a\u8bed\u8a00\u7279\u5b9a\u7684\u8868\u5f81\u3002"}}
{"id": "2601.12748", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12748", "abs": "https://arxiv.org/abs/2601.12748", "authors": ["Bin Xie", "Bingbing Xu", "Xueyun Tian", "Yilin Chen", "Huawei Shen"], "title": "Towards Robust Process Reward Modeling via Noise-aware Learning", "comment": null, "summary": "Process Reward Models (PRMs) have achieved strong results in complex reasoning, but are bottlenecked by costly process-level supervision. A widely used alternative, Monte Carlo Estimation (MCE), defines process rewards as the probability that a policy model reaches the correct final answer from a given reasoning step. However, step correctness is an intrinsic property of the reasoning trajectory, and should be invariant to policy choice. Our empirical findings show that MCE producing policy-dependent rewards that induce label noise, including false positives that reward incorrect steps and false negatives that penalize correct ones. To address above challenges, we propose a two-stage framework to mitigate noisy supervision. In the labeling stage, we introduce a reflection-aware label correction mechanism that uses a large language model (LLM) as a judge to detect reflection and self-correction behaviors related to the current reasoning step, thereby suppressing overestimated rewards. In the training stage, we further propose a \\underline{\\textbf{N}}oise-\\underline{\\textbf{A}}ware \\underline{\\textbf{I}}terative \\underline{\\textbf{T}}raining framework that enables the PRM to progressively refine noisy labels based on its own confidence. Extensive Experiments show that our method substantially improves step-level correctness discrimination, achieving up to a 27\\% absolute gain in average F1 over PRMs trained with noisy supervision.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7531\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u5f15\u53d1\u7684\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u51fa\u53cd\u601d\u611f\u77e5\u6807\u7b7e\u6821\u6b63\u4e0e\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5927\u5e45\u63d0\u5347\u6b65\u9aa4\u6b63\u786e\u6027\u7684\u5224\u522b\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u6602\u8d35\u7684\u8fc7\u7a0b\u7ea7\u76d1\u7763\uff0c\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u867d\u666e\u904d\u4f7f\u7528\u4f46\u4ea7\u751f\u7684\u5956\u52b1\u4f9d\u8d56\u4e8e\u7b56\u7565\u6a21\u578b\uff0c\u5bfc\u81f4\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002", "method": "\u5f15\u5165\u53cd\u601d\u611f\u77e5\u7684\u6807\u7b7e\u6821\u6b63\u673a\u5236\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u68c0\u6d4b\u53cd\u601d\u4e0e\u81ea\u6211\u4fee\u6b63\u884c\u4e3a\u4ee5\u51cf\u5c11\u8fc7\u9ad8\u5956\u52b1\uff0c\u7ed3\u5408\u566a\u58f0\u611f\u77e5\u8fed\u4ee3\u8bad\u7ec3\u6846\u67b6\u4f7f\u6a21\u578b\u57fa\u4e8e\u81ea\u8eab\u7f6e\u4fe1\u5ea6\u9010\u6b65\u4f18\u5316\u566a\u58f0\u6807\u7b7e\u3002", "result": "\u65b9\u6cd5\u5b9e\u73b0\u4e86\u5728\u6b65\u9aa4\u6b63\u786e\u6027\u5224\u522b\u4e0a\u7684\u5927\u5e45\u63d0\u5347\uff0c\u5e73\u5747F1\u5206\u6570\u8f83\u5e26\u566a\u58f0\u76d1\u7763\u8bad\u7ec3\u7684PRM\u63d0\u5347\u4e8627\u4e2a\u767e\u5206\u70b9\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u8fc7\u7a0b\u5956\u52b1\u6a21\u578b\u4e2d\u7531\u4e8e\u8499\u7279\u5361\u6d1b\u4f30\u8ba1\u4ea7\u751f\u7684\u6807\u7b7e\u566a\u58f0\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6b65\u9aa4\u6b63\u786e\u7387\u5224\u522b\u80fd\u529b\u3002"}}
{"id": "2601.12758", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12758", "abs": "https://arxiv.org/abs/2601.12758", "authors": ["Shenyan Zheng", "Jiayou Zhong", "Anudeex Shetty", "Heng Ji", "Preslav Nakov", "Usman Naseem"], "title": "VISPA: Pluralistic Alignment via Automatic Value Selection and Activation", "comment": "WIP", "summary": "As large language models are increasingly used in high-stakes domains, it is essential that their outputs reflect not average} human preference, rather range of varying perspectives. Achieving such pluralism, however, remains challenging. Existing approaches consider limited values or rely on prompt-level interventions, lacking value control and representation. To address this, we introduce VISPA, a training-free pluralistic alignment framework, that enables direct control over value expression by dynamic selection and internal model activation steering. Across extensive empirical studies spanning multiple models and evaluation settings, we show VISPA is performant across all pluralistic alignment modes in healthcare and beyond. Further analysis reveals VISPA is adaptable with different steering initiations, model, and/or values. These results suggest that pluralistic alignment can be achieved through internal activation mechanisms, offering a scalable path toward language models that serves all.", "AI": {"tldr": "VISPA\u662f\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u901a\u8fc7\u5185\u90e8\u6fc0\u6d3b\u673a\u5236\u5b9e\u73b0\u8bed\u8a00\u6a21\u578b\u591a\u5143\u4ef7\u503c\u5bf9\u9f50\u7684\u6846\u67b6\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u8f93\u51fa\u5bf9\u591a\u6837\u4ef7\u503c\u89c2\u7684\u53cd\u6620\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5b9e\u73b0\u4ef7\u503c\u591a\u5143\u5316\u5bf9\u9f50\u65f6\u5b58\u5728\u4ef7\u503c\u63a7\u5236\u4e0d\u8db3\u548c\u8868\u793a\u6709\u9650\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u6ee1\u8db3\u9ad8\u98ce\u9669\u9886\u57df\u5bf9\u591a\u5143\u89c6\u89d2\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u514d\u8d39\u7684\u65b9\u6cd5\uff0c\u91c7\u7528\u52a8\u6001\u9009\u62e9\u4e0e\u5185\u90e8\u6a21\u578b\u6fc0\u6d3b\u5f15\u5bfc\uff0c\u5b9e\u73b0\u5bf9\u6a21\u578b\u8f93\u51fa\u4ef7\u503c\u8868\u8fbe\u7684\u63a7\u5236\u3002", "result": "\u5728\u591a\u4e2a\u6a21\u578b\u548c\u8bc4\u4f30\u73af\u5883\uff08\u5305\u62ec\u533b\u7597\u9886\u57df\uff09\u4e2d\uff0cVISPA\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u591a\u5143\u5316\u4ef7\u503c\u5bf9\u9f50\u80fd\u529b\uff0c\u5e76\u80fd\u9002\u5e94\u4e0d\u540c\u7684\u542f\u52a8\u65b9\u5f0f\u53ca\u4ef7\u503c\u6807\u51c6\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684VISPA\u6846\u67b6\u5b9e\u73b0\u4e86\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u5728\u4ef7\u503c\u8868\u8fbe\u7684\u76f4\u63a5\u63a7\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u5143\u5316\u4ef7\u503c\u53d6\u5411\u7684\u5bf9\u9f50\uff0c\u9002\u5e94\u4e0d\u540c\u6a21\u578b\u548c\u4ef7\u503c\u89c2\u3002"}}
{"id": "2601.12771", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12771", "abs": "https://arxiv.org/abs/2601.12771", "authors": ["Keito Inoshita"], "title": "Who Does This Name Remind You of? Nationality Prediction via Large Language Model Associative Memory", "comment": null, "summary": "Large language models (LLMs) possess extensive world knowledge, yet methods for effectively eliciting this knowledge remain underexplored. Nationality and region prediction tasks require understanding of not only linguistic features but also cultural and historical background, making LLM world knowledge particularly valuable. However, conventional LLM prompting methods rely on direct reasoning approaches, which have limitations in applying abstract linguistic rules. We propose LLM Associative Memory Agents (LAMA), a novel framework that leverages LLM world knowledge as associative memory. Rather than directly inferring nationality from names, LAMA recalls famous individuals with the same name and aggregates their nationalities through indirect reasoning. A dual-agent architecture comprising a Person Agent and a Media Agent, specialized in different knowledge domains, recalls famous individuals in parallel, generating Top-1 predictions through voting and Top-K predictions through conditional completion. On a 99-country nationality prediction task, LAMA achieved 0.817 accuracy, substantially outperforming conventional LLM prompting methods and neural models. Our experiments reveal that LLMs exhibit higher reliability in recalling concrete examples than in abstract reasoning, that recall-based approaches are robust to low-frequency nationalities independent of data frequency distributions, and that the dual-agent architecture functions complementarily to produce synergistic effects. These results demonstrate the effectiveness of a new multi-agent system that retrieves and aggregates LLM knowledge rather than prompting reasoning.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8054\u60f3\u8bb0\u5fc6\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6LAMA\uff0c\u901a\u8fc7\u53ec\u56de\u76f8\u540c\u540d\u5b57\u7684\u77e5\u540d\u4eba\u7269\u95f4\u63a5\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fd\u7c4d\u9884\u6d4b\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u4f20\u7edf\u63a8\u7406\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5927\u8bed\u8a00\u6a21\u578b\u7684\u76f4\u63a5\u63a8\u7406\u65b9\u6cd5\u5728\u5e94\u7528\u62bd\u8c61\u8bed\u8a00\u89c4\u5219\u65f6\u5b58\u5728\u5c40\u9650\uff0c\u800c\u56fd\u7c4d\u9884\u6d4b\u4efb\u52a1\u9700\u8981\u7ed3\u5408\u8bed\u8a00\u3001\u6587\u5316\u548c\u5386\u53f2\u80cc\u666f\u77e5\u8bc6\uff0c\u9700\u8981\u66f4\u6709\u6548\u5730\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e16\u754c\u77e5\u8bc6\u3002", "method": "\u91c7\u7528\u53cc\u667a\u80fd\u4f53\u67b6\u6784\uff08\u4eba\u5458\u667a\u80fd\u4f53\u548c\u5a92\u4f53\u667a\u80fd\u4f53\uff09\u5e76\u884c\u53ec\u56de\u5177\u6709\u76f8\u540c\u540d\u5b57\u7684\u77e5\u540d\u4eba\u7269\uff0c\u901a\u8fc7\u6295\u7968\u548c\u6761\u4ef6\u5b8c\u6210\u7684\u65b9\u5f0f\u5b9e\u73b0\u95f4\u63a5\u63a8\u7406\uff0c\u4ece\u800c\u9884\u6d4b\u56fd\u7c4d\u3002", "result": "\u572899\u56fd\u5bb6\u7684\u56fd\u7c4d\u9884\u6d4b\u4efb\u52a1\u4e2d\uff0cLAMA\u6846\u67b6\u53d6\u5f97\u4e860.817\u7684\u51c6\u786e\u7387\uff0c\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u4e86\u5bf9\u4f4e\u9891\u56fd\u7c4d\u7684\u9c81\u68d2\u6027\u548c\u591a\u667a\u80fd\u4f53\u4f53\u7cfb\u7684\u534f\u540c\u6548\u5e94\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684LAMA\u6846\u67b6\u901a\u8fc7\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8054\u60f3\u8bb0\u5fc6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u56fd\u7c4d\u9884\u6d4b\u4efb\u52a1\u7684\u51c6\u786e\u6027\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684\u76f4\u63a5\u63a8\u7406\u65b9\u6cd5\u548c\u795e\u7ecf\u6a21\u578b\u3002"}}
{"id": "2601.12812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12812", "abs": "https://arxiv.org/abs/2601.12812", "authors": ["Sushant Kumar Ray", "Gautam Siddharth Kashyap", "Sahil Tripathi", "Nipun Joshi", "Vijay Govindarajan", "Rafiq Ali", "Jiechao Gao", "Usman Naseem"], "title": "Do Clinical Question Answering Systems Really Need Specialised Medical Fine Tuning?", "comment": "Accepted at EACL 2026 (Industry Track)", "summary": "Clinical Question-Answering (CQA) industry systems are increasingly rely on Large Language Models (LLMs), yet their deployment is often guided by the assumption that domain-specific fine-tuning is essential. Although specialised medical LLMs such as BioBERT, BioGPT, and PubMedBERT remain popular, they face practical limitations including narrow coverage, high retraining costs, and limited adaptability. Efforts based on Supervised Fine-Tuning (SFT) have attempted to address these assumptions but continue to reinforce what we term the SPECIALISATION FALLACY-the belief that specialised medical LLMs are inherently superior for CQA. To address this assumption, we introduce MEDASSESS-X, a deployment-industry-oriented CQA framework that applies alignment at inference time rather than through SFT. MEDASSESS-X uses lightweight steering vectors to guide model activations toward medically consistent reasoning without updating model weights or requiring domain-specific retraining. This inference-time alignment layer stabilises CQA performance across both general-purpose and specialised medical LLMs, thereby resolving the SPECIALISATION FALLACY. Empirically, MEDASSESS-X delivers consistent gains across all LLM families, improving Accuracy by up to +6%, Factual Consistency by +7%, and reducing Safety Error Rate by as much as 50%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u65e0\u9700\u5fae\u8c03\u7684\u63a8\u7406\u65f6\u5bf9\u9f50\u7b56\u7565MEDASSESS-X\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4e34\u5e8a\u95ee\u7b54\u5927\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u5b89\u5168\u6027\uff0c\u6311\u6218\u4e86\u4e13\u4e1a\u5316\u5fae\u8c03\u7684\u4f20\u7edf\u5047\u8bbe\u3002", "motivation": "\u76ee\u524d\u4e13\u4e1a\u533b\u5b66\u5927\u6a21\u578b\u5728\u4e34\u5e8a\u95ee\u7b54\u4e2d\u867d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u5374\u5b58\u5728\u8986\u76d6\u9762\u7a84\u3001\u5fae\u8c03\u6210\u672c\u9ad8\u548c\u9002\u5e94\u6027\u5dee\u7b49\u5c40\u9650\uff0c\u4e14\u5b58\u5728\u4e13\u4e1a\u5316\u8c2c\u8bef\u3002", "method": "\u63d0\u51faMEDASSESS-X\u6846\u67b6\uff0c\u5728\u63a8\u7406\u65f6\u5229\u7528\u8f7b\u91cf\u7ea7\u5f15\u5bfc\u5411\u91cf\u8c03\u6574\u6a21\u578b\u6fc0\u6d3b\uff0c\u589e\u5f3a\u533b\u5b66\u63a8\u7406\u7684\u4e00\u81f4\u6027\uff0c\u65e0\u9700\u5fae\u8c03\u6a21\u578b\u6743\u91cd\u3002", "result": "MEDASSESS-X\u5728\u591a\u79cd\u5927\u6a21\u578b\u4e0a\u5747\u63d0\u5347\u6027\u80fd\uff0c\u51c6\u786e\u7387\u63d0\u5347\u6700\u9ad86%\uff0c\u4e8b\u5b9e\u4e00\u81f4\u6027\u63d0\u53477%\uff0c\u5b89\u5168\u9519\u8bef\u7387\u964d\u4f4e50%\u3002", "conclusion": "\u57fa\u4e8e\u9886\u57df\u7279\u5b9a\u5fae\u8c03\u7684\u5047\u8bbe\u5728\u4e34\u5e8a\u95ee\u7b54\u7cfb\u7edf\u4e2d\u5e76\u975e\u5fc5\u9700\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u5bf9\u9f50\u7b56\u7565\u540c\u6837\u53ef\u4ee5\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\uff0c\u6d88\u9664\u4e13\u4e1a\u5316\u8c2c\u8bef\u3002"}}
{"id": "2601.12815", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12815", "abs": "https://arxiv.org/abs/2601.12815", "authors": ["Zhaolu Kang", "Junhao Gong", "Qingxi Chen", "Hao Zhang", "Jiaxin Liu", "Rong Fu", "Zhiyuan Feng", "Yuan Wang", "Simon Fong", "Kaiyue Zhou"], "title": "Multimodal Multi-Agent Empowered Legal Judgment Prediction", "comment": null, "summary": "Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or role-based simulations but face challenges with multiple allegations, diverse evidence, and lack adaptability. In this paper, we introduce JurisMMA, a novel framework for LJP that effectively decomposes trial tasks, standardizes processes, and organizes them into distinct stages. Furthermore, we build JurisMM, a large dataset with over 100,000 recent Chinese judicial records, including both text and multimodal video-text data, enabling comprehensive evaluation. Experiments on JurisMM and the benchmark LawBench validate our framework's effectiveness. These results indicate that our framework is effective not only for LJP but also for a broader range of legal applications, offering new perspectives for the development of future legal methods and datasets.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4efb\u52a1\u5206\u89e3\u548c\u591a\u6a21\u6001\u6570\u636e\u7ed3\u5408\u7684JurisMMA\u6846\u67b6\uff0c\u5e76\u6784\u5efa\u5927\u89c4\u6a21\u53f8\u6cd5\u591a\u6a21\u6001\u6570\u636e\u96c6JurisMM\uff0c\u6709\u6548\u63d0\u5347\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u65b9\u6cd5\u5728\u5904\u7406\u591a\u91cd\u6307\u63a7\u3001\u591a\u6837\u5316\u8bc1\u636e\u4ee5\u53ca\u9002\u5e94\u6027\u65b9\u9762\u5b58\u5728\u663e\u8457\u6311\u6218\uff0c\u4e9f\u9700\u4e00\u79cd\u6709\u6548\u7684\u6846\u67b6\u548c\u4e30\u5bcc\u7684\u6570\u636e\u8d44\u6e90\u6765\u63d0\u5347\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86JurisMMA\u6846\u67b6\uff0c\u91c7\u7528\u4efb\u52a1\u5206\u89e3\u3001\u6d41\u7a0b\u6807\u51c6\u5316\u548c\u9636\u6bb5\u5316\u7ec4\u7ec7\u65b9\u6cd5\uff0c\u540c\u65f6\u6784\u5efa\u4e86\u5305\u542b\u6587\u672c\u53ca\u591a\u6a21\u6001\u89c6\u9891-\u6587\u672c\u6570\u636e\u7684JurisMM\u5927\u89c4\u6a21\u53f8\u6cd5\u8bb0\u5f55\u6570\u636e\u96c6\u3002", "result": "\u5728JurisMM\u6570\u636e\u96c6\u53caLawBench\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86JurisMMA\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u8bc1\u660e\u5176\u5bf9\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u53ca\u5176\u4ed6\u6cd5\u5f8b\u5e94\u7528\u5177\u6709\u63a8\u5e7f\u4ef7\u503c\u3002", "conclusion": "JurisMMA\u6846\u67b6\u5728\u6cd5\u5f8b\u5224\u51b3\u9884\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e0d\u4ec5\u63d0\u5347\u4e86\u591a\u6307\u63a7\u548c\u591a\u6a21\u6001\u6570\u636e\u7684\u5904\u7406\u80fd\u529b\uff0c\u8fd8\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6cd5\u5f8b\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2601.12844", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12844", "abs": "https://arxiv.org/abs/2601.12844", "authors": ["Julie Ran\u00e7on", "Jean-Fran\u00e7ois Cerisier", "Emilie Remond", "Aur\u00e9lien Nguyen", "Andrew Peterson", "Ladjel Bellatreche"], "title": "Rapport du Projet de Recherche TRAIMA", "comment": "in French language", "summary": "The TRAIMA project (TRaitement Automatique des Interactions Multimodales en Apprentissage), conducted between March 2019 and June 2020, investigates the potential of automatic processing of multimodal interactions in educational settings. The project addresses a central methodological challenge in educational and interactional research: the analysis of verbal, paraverbal, and non-verbal data is currently carried out manually, making it extremely time-consuming and difficult to scale. TRAIMA explores how machine learning approaches could contribute to the categorisation and classification of such interactions. The project focuses specifically on explanatory and collaborative sequences occurring in classroom interactions, particularly in French as a Foreign Language (FLE) and French as a First Language (FLM) contexts. These sequences are analysed as inherently multimodal phenomena, combining spoken language with prosody, gestures, posture, gaze, and spatial positioning. A key theoretical contribution of the project is the precise linguistic and interactional definition of explanatory discourse as a tripartite sequence (opening, explanatory core, closure), drawing on discourse analysis and interactional linguistics. A substantial part of the research is devoted to the methodological foundations of transcription, which constitute a critical bottleneck for any form of automation. The report provides a detailed state of the art of existing transcription conventions (ICOR, Mondada, GARS, VALIBEL, Ferr{\u00e9}), highlighting their respective strengths and limitations when applied to multimodal classroom data. Through comparative analyses of manually transcribed sequences, the project demonstrates the inevitable variability and interpretative dimension of transcription practices, depending on theoretical positioning and analytical goals. Empirical work is based on several corpora, notably the INTER-EXPLIC corpus (approximately 30 hours of classroom interaction) and the EXPLIC-LEXIC corpus, which serve both as testing grounds for manual annotation and as reference datasets for future automation. Particular attention is paid to teacher gestures (kin{\u00e9}sic and proxemic resources), prosodic features, and their functional role in meaning construction and learner comprehension. The project also highlights the strategic role of the Techn{\u00e9}LAB platform, which provides advanced multimodal data capture (multi-camera video, synchronized audio, eye-tracking, digital interaction traces) and constitutes both a research infrastructure and a test environment for the development of automated tools. In conclusion, TRAIMA does not aim to deliver a fully operational automated system, but rather to establish a rigorous methodological framework for the automatic processing of multimodal pedagogical interactions. The project identifies transcription conventions, annotation categories, and analytical units that are compatible with machine learning approaches, while emphasizing the need for theoretical explicitness and researcher reflexivity. TRAIMA thus lays the groundwork for future interdisciplinary research at the intersection of didactics, discourse analysis, multimodality, and artificial intelligence in education.", "AI": {"tldr": "TRAIMA\u63a2\u8ba8\u591a\u6a21\u6001\u8bfe\u5802\u4e92\u52a8\u81ea\u52a8\u5904\u7406\u7684\u53ef\u80fd\u6027\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u548c\u8be6\u7ec6\u7684\u8f6c\u5f55\u65b9\u6cd5\uff0c\u5efa\u7acb\u591a\u6a21\u6001\u6559\u5b66\u4e92\u52a8\u81ea\u52a8\u5206\u6790\u7684\u7406\u8bba\u548c\u65b9\u6cd5\u6846\u67b6\u3002", "motivation": "\u4f20\u7edf\u6559\u80b2\u548c\u4e92\u52a8\u7814\u7a76\u4e2d\uff0c\u8bed\u8a00\u3001\u8a00\u8bed\u5916\u53ca\u975e\u8bed\u8a00\u6570\u636e\u5206\u6790\u5747\u4f9d\u8d56\u624b\u5de5\u5904\u7406\uff0c\u8017\u65f6\u4e14\u96be\u4ee5\u89c4\u6a21\u5316\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u65b9\u6cd5\u652f\u6301\u591a\u6a21\u6001\u4e92\u52a8\u7684\u9ad8\u6548\u5206\u6790\u3002", "method": "\u8be5\u9879\u76ee\u91c7\u7528\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\uff0c\u5bf9\u591a\u6a21\u6001\u8bfe\u5802\u4e92\u52a8\u4e2d\u7684\u8bed\u97f3\u3001\u8a00\u8bed\u5916\u3001\u975e\u8a00\u8bed\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u548c\u6807\u6ce8\uff0c\u7ed3\u5408\u591a\u6444\u50cf\u5934\u89c6\u9891\u3001\u540c\u6b65\u97f3\u9891\u3001\u773c\u52a8\u8ffd\u8e2a\u7b49\u591a\u6a21\u6001\u6570\u636e\uff0c\u5229\u7528\u624b\u5de5\u8f6c\u5f55\u548c\u6ce8\u91ca\u4ee5\u652f\u6491\u81ea\u52a8\u5de5\u5177\u5f00\u53d1\u3002", "result": "\u9879\u76ee\u660e\u786e\u4e86\u9002\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u8f6c\u5f55\u89c4\u8303\u3001\u6ce8\u91ca\u7c7b\u522b\u548c\u5206\u6790\u5355\u5143\uff0c\u63d0\u51fa\u89e3\u91ca\u6027\u8bdd\u8bed\u7684\u4e09\u6bb5\u5f0f\u5b9a\u4e49\uff0c\u5c55\u793a\u4e86\u591a\u6a21\u6001\u4e92\u52a8\u8f6c\u5f55\u7684\u53d8\u5f02\u6027\u548c\u89e3\u91ca\u6027\uff0c\u4e3a\u672a\u6765\u81ea\u52a8\u5904\u7406\u5de5\u5177\u7684\u5f00\u53d1\u5960\u5b9a\u57fa\u7840\u3002", "conclusion": "TRAIMA\u9879\u76ee\u7684\u76ee\u6807\u662f\u5efa\u7acb\u4e00\u4e2a\u4e25\u683c\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6a21\u6001\u6559\u5b66\u4e92\u52a8\u7684\u81ea\u52a8\u5904\u7406\uff0c\u800c\u975e\u5f00\u53d1\u5b8c\u5168\u81ea\u52a8\u5316\u7cfb\u7edf\u3002"}}
{"id": "2601.12868", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12868", "abs": "https://arxiv.org/abs/2601.12868", "authors": ["Shiyue Hu", "Ruizhe Li", "Yanjun Gao"], "title": "Race, Ethnicity and Their Implication on Bias in Large Language Models", "comment": "Work in process", "summary": "Large language models (LLMs) increasingly operate in high-stakes settings including healthcare and medicine, where demographic attributes such as race and ethnicity may be explicitly stated or implicitly inferred from text. However, existing studies primarily document outcome-level disparities, offering limited insight into internal mechanisms underlying these effects. We present a mechanistic study of how race and ethnicity are represented and operationalized within LLMs. Using two publicly available datasets spanning toxicity-related generation and clinical narrative understanding tasks, we analyze three open-source models with a reproducible interpretability pipeline combining probing, neuron-level attribution, and targeted intervention. We find that demographic information is distributed across internal units with substantial cross-model variation. Although some units encode sensitive or stereotype-related associations from pretraining, identical demographic cues can induce qualitatively different behaviors. Interventions suppressing such neurons reduce bias but leave substantial residual effects, suggesting behavioral rather than representational change and motivating more systematic mitigation.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u673a\u5236\u63ed\u793a\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u7684\u5206\u5e03\u53ca\u5176\u5bf9\u504f\u89c1\u7684\u5f71\u54cd\uff0c\u6307\u51fa\u5355\u4e00\u5e72\u9884\u96be\u4ee5\u6839\u6cbb\u504f\u89c1\uff0c\u5f3a\u8c03\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u7cfb\u7edf\u6027\u8c03\u63a7\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6a21\u578b\u8f93\u51fa\u5c42\u9762\u7684\u504f\u5dee\uff0c\u7f3a\u4e4f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u673a\u5236\u5982\u4f55\u5bfc\u81f4\u79cd\u65cf\u548c\u65cf\u88d4\u5dee\u5f02\u7684\u6df1\u5165\u7406\u89e3\u3002", "method": "\u7ed3\u5408\u63a2\u6d4b\u3001\u795e\u7ecf\u5143\u7ea7\u5f52\u56e0\u548c\u6709\u9488\u5bf9\u6027\u7684\u5e72\u9884\uff0c\u4f7f\u7528\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u548c\u4e09\u4e2a\u5f00\u6e90\u6a21\u578b\u8fdb\u884c\u673a\u5236\u6027\u5206\u6790\uff0c\u7814\u7a76\u6a21\u578b\u5185\u90e8\u5982\u4f55\u8868\u793a\u548c\u64cd\u4f5c\u79cd\u65cf\u53ca\u65cf\u88d4\u4fe1\u606f\u3002", "result": "\u53d1\u73b0\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u5206\u5e03\u5728\u591a\u4e2a\u795e\u7ecf\u5143\u4e2d\u4e14\u6a21\u578b\u95f4\u5dee\u5f02\u663e\u8457\uff0c\u5e72\u9884\u76f8\u5173\u795e\u7ecf\u5143\u53ef\u51cf\u5c11\u504f\u89c1\u4f46\u6548\u679c\u6709\u9650\uff0c\u8868\u660e\u9700\u8981\u66f4\u7cfb\u7edf\u7684\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u7684\u79cd\u65cf\u548c\u65cf\u88d4\u4fe1\u606f\u5206\u5e03\u5e7f\u6cdb\u4e14\u56e0\u6a21\u578b\u800c\u5f02\uff0c\u504f\u89c1\u7684\u5b58\u5728\u4e0d\u4ec5\u6e90\u4e8e\u8868\u793a\u5c42\u9762\uff0c\u8fd8\u6d89\u53ca\u6a21\u578b\u884c\u4e3a\uff0c\u5355\u7eaf\u6291\u5236\u7279\u5b9a\u795e\u7ecf\u5143\u65e0\u6cd5\u5b8c\u5168\u6d88\u9664\u504f\u89c1\u3002"}}
{"id": "2601.12904", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12904", "abs": "https://arxiv.org/abs/2601.12904", "authors": ["Jiahao Wang", "Weiyu Xie", "Mingxing Zhang", "Boxing Zhang", "Jianwei Dong", "Yuening Zhu", "Chen Lin", "Jinqi Tang", "Yaochen Han", "Zhiyuan Ai", "Xianglin Chen", "Yongwei Wu", "Congfeng Jiang"], "title": "From Prefix Cache to Fusion RAG Cache: Accelerating LLM Inference in Retrieval-Augmented Generation", "comment": null, "summary": "Retrieval-Augmented Generation enhances Large Language Models by integrating external knowledge, which reduces hallucinations but increases prompt length. This increase leads to higher computational costs and longer Time to First Token (TTFT). To mitigate this issue, existing solutions aim to reuse the preprocessed KV cache of each retrieved chunk to accelerate RAG. However, the lack of cross-chunk contextual information leads to a significant drop in generation quality, leaving the potential benefits of KV cache reuse largely unfulfilled. The challenge lies in how to reuse the precomputed KV cache of chunks while preserving generation quality. We propose FusionRAG, a novel inference framework that optimizes both the preprocessing and reprocessing stages of RAG. In the offline preprocessing stage, we embed information from other related text chunks into each chunk, while in the online reprocessing stage, we recompute the KV cache for tokens that the model focuses on. As a result, we achieve a better trade-off between generation quality and efficiency. According to our experiments, FusionRAG significantly improves generation quality at the same recomputation ratio compared to previous state-of-the-art solutions. By recomputing fewer than 15% of the tokens, FusionRAG achieves up to 70% higher normalized F1 scores than baselines and reduces TTFT by 2.66x-9.39x compared to Full Attention.", "AI": {"tldr": "FusionRAG\u901a\u8fc7\u5d4c\u5165\u8de8\u5757\u4fe1\u606f\u548c\u9009\u62e9\u6027\u91cd\u8ba1\u7b97KV\u7f13\u5b58\uff0c\u5728\u4fdd\u6301\u9ad8\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6548\u7387\u548c\u54cd\u5e94\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709RAG\u65b9\u6cd5\u56e0\u63d0\u793a\u957f\u5ea6\u589e\u957f\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u548c\u54cd\u5e94\u65f6\u95f4\u589e\u52a0\uff0c\u4e14\u7b80\u5355\u91cd\u7528KV\u7f13\u5b58\u7f3a\u4e4f\u8de8\u5757\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u4e0b\u964d\u3002\u5982\u4f55\u5728\u91cd\u7528KV\u7f13\u5b58\u7684\u540c\u65f6\u4fdd\u6301\u751f\u6210\u8d28\u91cf\u662f\u4e3b\u8981\u6311\u6218\u3002", "method": "\u63d0\u51faFusionRAG\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u79bb\u7ebf\u9884\u5904\u7406\u9636\u6bb5\u5c06\u76f8\u5173\u6587\u672c\u5757\u4fe1\u606f\u5d4c\u5165\u6bcf\u4e2a\u5757\u5185\uff0c\u5728\u7ebf\u91cd\u65b0\u5904\u7406\u4e2d\u4ec5\u5bf9\u5173\u6ce8\u7684\u5173\u952eToken\u91cd\u65b0\u8ba1\u7b97KV\u7f13\u5b58\uff0c\u4ece\u800c\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\u3002", "result": "FusionRAG\u5728\u76f8\u540c\u91cd\u8ba1\u7b97\u6bd4\u4f8b\u4e0b\uff0c\u751f\u6210\u8d28\u91cf\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u4ec5\u91cd\u8ba1\u7b97\u5c0f\u4e8e15%Token\uff0c\u751f\u6210F1\u5206\u6570\u63d0\u5347\u8fbe70%\uff0cTTFT\u6bd4\u5168\u6ce8\u610f\u529b\u673a\u5236\u51cf\u5c112.66\u500d\u81f39.39\u500d\u3002", "conclusion": "FusionRAG\u6846\u67b6\u5728\u63d0\u9ad8\u751f\u6210\u8d28\u91cf\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u6210\u672c\u548c\u54cd\u5e94\u65f6\u95f4\uff0c\u5b9e\u73b0\u4e86\u6548\u679c\u4e0e\u6548\u7387\u7684\u6700\u4f73\u5e73\u8861\u3002"}}
{"id": "2601.12906", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12906", "abs": "https://arxiv.org/abs/2601.12906", "authors": ["Lingrui Mei", "Shenghua Liu", "Yiwei Wang", "Yuyao Ge", "Baolong Bi", "Jiayu Yao", "Jun Wan", "Ziling Yin", "Jiafeng Guo", "Xueqi Cheng"], "title": "Gated Differentiable Working Memory for Long-Context Language Modeling", "comment": null, "summary": "Long contexts challenge transformers: attention scores dilute across thousands of tokens, critical information is often lost in the middle, and models struggle to adapt to novel patterns at inference time. Recent work on test-time adaptation addresses this by maintaining a form of working memory -- transient parameters updated on the current context -- but existing approaches rely on uniform write policies that waste computation on low-utility regions and suffer from high gradient variance across semantically heterogeneous contexts. In this work, we reframe test-time adaptation as a budget-constrained memory consolidation problem, focusing on which parts of the context should be consolidated into working memory under limited computation. We propose Gdwm (Gated Differentiable Working Memory), a framework that introduces a write controller to gate the consolidation process. The controller estimates Contextual Utility, an information-theoretic measure of long-range contextual dependence, and allocates gradient steps accordingly while maintaining global coverage. Experiments on ZeroSCROLLS and LongBench v2 demonstrate that Gdwm achieves comparable or superior performance with 4$\\times$ fewer gradient steps than uniform baselines, establishing a new efficiency-performance Pareto frontier for test-time adaptation.", "AI": {"tldr": "\u9488\u5bf9\u957f\u4e0a\u4e0b\u6587\u6311\u6218\uff0c\u672c\u6587\u63d0\u51faGdwm\u6846\u67b6\u901a\u8fc7\u9009\u62e9\u6027\u5de9\u56fa\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u6027\u80fd\u4f18\u5f02\u7684\u63a8\u7406\u9002\u5e94\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u73af\u5883\u4e0bTransformer\u6a21\u578b\u9762\u4e34\u6ce8\u610f\u529b\u5206\u6563\u3001\u5173\u952e\u4fe1\u606f\u4e22\u5931\u4ee5\u53ca\u9002\u5e94\u65b0\u6a21\u5f0f\u56f0\u96be\u7684\u95ee\u9898\uff0c\u73b0\u6709\u7edf\u4e00\u5199\u5165\u7b56\u7565\u6548\u7387\u4f4e\u4e14\u68af\u5ea6\u65b9\u5dee\u5927\u3002", "method": "\u63d0\u51faGdwm\uff08\u95e8\u63a7\u53ef\u5fae\u5de5\u4f5c\u8bb0\u5fc6\uff09\u6846\u67b6\uff0c\u5229\u7528\u4fe1\u606f\u8bba\u7684\u4e0a\u4e0b\u6587\u6548\u7528\u5ea6\u91cf\u52a8\u6001\u8c03\u8282\u68af\u5ea6\u66f4\u65b0\u6b65\u6570\uff0c\u6709\u9488\u5bf9\u6027\u5730\u5de9\u56fa\u91cd\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002", "result": "\u5728ZeroSCROLLS\u548cLongBench v2\u6570\u636e\u96c6\u4e0a\uff0cGdwm\u5728\u4f7f\u75284\u500d\u66f4\u5c11\u68af\u5ea6\u6b65\u6570\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u7b49\u540c\u6216\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u63d0\u5347\u4e86\u9002\u5e94\u6548\u7387\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Gdwm\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u5199\u5165\u63a7\u5236\u5668\uff0c\u6709\u6548\u9009\u62e9\u4e0a\u4e0b\u6587\u4e2d\u5e94\u4fdd\u7559\u4e8e\u5de5\u4f5c\u8bb0\u5fc6\u7684\u90e8\u5206\uff0c\u63d0\u5347\u4e86\u957f\u6587\u672c\u4e0a\u4e0b\u6587\u4e0b\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2601.12910", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.12910", "abs": "https://arxiv.org/abs/2601.12910", "authors": ["Tim Baumg\u00e4rtner", "Iryna Gurevych"], "title": "SciCoQA: Quality Assurance for Scientific Paper--Code Alignment", "comment": null, "summary": "We present SciCoQA, a dataset for detecting discrepancies between scientific publications and their codebases to ensure faithful implementations. We construct SciCoQA from GitHub issues and reproducibility papers, and to scale our dataset, we propose a synthetic data generation method for constructing paper-code discrepancies. We analyze the paper-code discrepancies in detail and propose discrepancy types and categories to better understand the occurring mismatches. In total, our dataset consists of 611 paper-code discrepancies (81 real, 530 synthetic), spanning diverse computational science disciplines, including AI, Physics, Quantitative Biology, and others. Our evaluation of 21 LLMs highlights the difficulty of SciCoQA, particularly for instances involving omitted paper details, long-context inputs, and data outside the models' pre-training corpus. The best performing model in our evaluation, GPT-5, can only detect 45.7\\% of real-world paper-code discrepancies.", "AI": {"tldr": "\u63d0\u51faSciCoQA\u6570\u636e\u96c6\u7528\u4e8e\u68c0\u6d4b\u8bba\u6587\u4e0e\u4ee3\u7801\u4e0d\u4e00\u81f4\uff0c\u8bc4\u6d4b\u663e\u793a\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u4efb\u52a1\u4e2d\u8868\u73b0\u6709\u9650\u3002", "motivation": "\u786e\u4fdd\u79d1\u5b66\u8bba\u6587\u4e0e\u5176\u4ee3\u7801\u5e93\u4e4b\u95f4\u7684\u4e00\u81f4\u5b9e\u73b0\uff0c\u4ee5\u907f\u514d\u4e0d\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u5305\u542b\u771f\u5b9e\u548c\u5408\u6210\u6570\u636e\u7684SciCoQA\u6570\u636e\u96c6\uff0c\u5206\u6790\u8bba\u6587\u4e0e\u4ee3\u7801\u7684\u4e0d\u5339\u914d\u7c7b\u578b\uff0c\u5e76\u5229\u7528\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6269\u5c55\u6570\u636e\u96c6\u3002", "result": "\u6536\u96c6\u4e86611\u4e2a\u8bba\u6587-\u4ee3\u7801\u4e0d\u4e00\u81f4\u5b9e\u4f8b\uff0c\u6db5\u76d6\u591a\u4e2a\u79d1\u5b66\u9886\u57df\uff0c\u8bc4\u6d4b21\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u68c0\u6d4b\u4efb\u52a1\u96be\u5ea6\u5927\uff0c\u6700\u4f73\u6a21\u578b\u4ec5\u80fd\u8bc6\u522b45.7%\u7684\u771f\u5b9e\u4e0d\u4e00\u81f4\u3002", "conclusion": "SciCoQA\u6570\u636e\u96c6\u63ed\u793a\u4e86\u5f53\u524d\u6a21\u578b\u5728\u8bc6\u522b\u8bba\u6587\u4e0e\u4ee3\u7801\u4e0d\u4e00\u81f4\u6027\u65b9\u9762\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4e86\u6539\u8fdb\u6a21\u578b\u80fd\u529b\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.12921", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12921", "abs": "https://arxiv.org/abs/2601.12921", "authors": ["Adimulya Kartiyasa", "Bao Gia Cao", "Boyang Li"], "title": "Injecting Knowledge from Social Science Journals to Improve Indonesian Cultural Understanding by LLMs", "comment": null, "summary": "Recently there have been intensifying efforts to improve the understanding of Indonesian cultures by large language models (LLMs). An attractive source of cultural knowledge that has been largely overlooked is local journals of social science, which likely contain substantial cultural studies from a native perspective. We present a novel text dataset of journal article passages, created from 151 open-source Indonesian social science journals, called IndoSoSci. We demonstrate an effective recipe for injecting Indonesian cultural knowledge therein into LLMs: extracting the facts related to Indonesian culture, and apply retrieval-augmented generation (RAG) with LLM-generated hypothetical documents as queries during retrieval. The proposed recipe yields strong performance gains over several strong baselines on the IndoCulture benchmark. Additionally, by combining IndoSoSci with Indonesian Wikipedia, we set a new state-of-the-art accuracy on the IndoCulture benchmark.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u57fa\u4e8e\u5370\u5ea6\u5c3c\u897f\u4e9a\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u7684\u6587\u5316\u77e5\u8bc6\u6570\u636e\u96c6IndoSoSci\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5370\u5ea6\u5c3c\u897f\u4e9a\u6587\u5316\u7406\u89e3\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u5c3c\u897f\u4e9a\u6587\u5316\u7684\u7406\u89e3\u4ecd\u6709\u4e0d\u8db3\uff0c\u672c\u7814\u7a76\u5e0c\u671b\u901a\u8fc7\u672c\u5730\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u7684\u6587\u5316\u77e5\u8bc6\u6765\u63d0\u5347\u6a21\u578b\u8868\u73b0\u3002", "method": "\u6536\u96c6151\u4efd\u5f00\u653e\u83b7\u53d6\u7684\u5370\u5ea6\u5c3c\u897f\u4e9a\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u6587\u672c\uff0c\u6784\u5efaIndoSoSci\u6570\u636e\u96c6\uff0c\u63d0\u53d6\u5370\u5ea6\u5c3c\u897f\u4e9a\u6587\u5316\u76f8\u5173\u4e8b\u5b9e\uff0c\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5047\u8bbe\u6587\u6863\u4f5c\u4e3a\u67e5\u8be2\u8fdb\u884c\u68c0\u7d22\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728IndoCulture\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u591a\u4e2a\u5f3a\u57fa\u7ebf\u3002\u540c\u65f6\u7ed3\u5408IndoSoSci\u548c\u5370\u5ea6\u5c3c\u897f\u4e9a\u7ef4\u57fa\u767e\u79d1\u6570\u636e\uff0c\u521b\u65b0\u6027\u5730\u5237\u65b0\u4e86\u8be5\u57fa\u51c6\u7684\u51c6\u786e\u7387\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u672c\u5730\u793e\u4f1a\u79d1\u5b66\u671f\u520a\u6587\u672c\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u5370\u5ea6\u5c3c\u897f\u4e9a\u6587\u5316\u7684\u7406\u89e3\u548c\u8868\u73b0\u3002"}}
{"id": "2601.12945", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.12945", "abs": "https://arxiv.org/abs/2601.12945", "authors": ["Miao Xie", "Siguang Chen", "Chunli Lv"], "title": "A Component-Based Survey of Interactions between Large Language Models and Multi-Armed Bandits", "comment": "27 pages, 6 table", "summary": "Large language models (LLMs) have become powerful and widely used systems for language understanding and generation, while multi-armed bandit (MAB) algorithms provide a principled framework for adaptive decision-making under uncertainty. This survey explores the potential at the intersection of these two fields. As we know, it is the first survey to systematically review the bidirectional interaction between large language models and multi-armed bandits at the component level. We highlight the bidirectional benefits: MAB algorithms address critical LLM challenges, spanning from pre-training to retrieval-augmented generation (RAG) and personalization. Conversely, LLMs enhance MAB systems by redefining core components such as arm definition and environment modeling, thereby improving decision-making in sequential tasks. We analyze existing LLM-enhanced bandit systems and bandit-enhanced LLM systems, providing insights into their design, methodologies, and performance. Key challenges and representative findings are identified to help guide future research. An accompanying GitHub repository that indexes relevant literature is available at https://github.com/bucky1119/Awesome-LLM-Bandit-Interaction.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\u7684\u53cc\u5411\u5e94\u7528\uff0c\u63ed\u793a\u4e24\u8005\u7ed3\u5408\u5e26\u6765\u7684\u4f18\u52bf\u4e0e\u6311\u6218\uff0c\u5e76\u63d0\u4f9b\u4e86\u8be6\u7ec6\u7684\u6587\u732e\u7d22\u5f15\u8d44\u6e90\u3002", "motivation": "\u63a2\u7d22LLMs\u4e0eMAB\u7b97\u6cd5\u7ed3\u5408\u7684\u6f5c\u529b\uff0c\u89e3\u51b3LLMs\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u540c\u65f6\u5229\u7528LLMs\u63d0\u5347MAB\u7b97\u6cd5\u7684\u6838\u5fc3\u7ec4\u6210\u548c\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u8c03\u7814\u548c\u5206\u6790\u73b0\u6709\u6587\u732e\uff0c\u5f52\u7eb3\u4e86LLMs\u4e0eMAB\u7b97\u6cd5\u5728\u9884\u8bad\u7ec3\u3001\u589e\u5f3a\u751f\u6210\u3001\u4e2a\u6027\u5316\u53ca\u51b3\u7b56\u5236\u5b9a\u4e2d\u7684\u5e94\u7528\u4e0e\u6539\u8fdb\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u76f8\u5173\u6587\u732e\u7d22\u5f15\u5e93\u3002", "result": "\u603b\u7ed3\u4e86LLM\u589e\u5f3a\u7684MAB\u7cfb\u7edf\u548cMAB\u589e\u5f3a\u7684LLM\u7cfb\u7edf\u7684\u8bbe\u8ba1\u548c\u6027\u80fd\u8868\u73b0\uff0c\u6307\u51fa\u5173\u952e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u7cfb\u7edf\u56de\u987e\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e0e\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\uff08MAB\uff09\u4e4b\u95f4\u7684\u53cc\u5411\u4ea4\u4e92\u53ca\u5176\u5728\u5404\u81ea\u9886\u57df\u4e2d\u7684\u76f8\u4e92\u4fc3\u8fdb\u4f5c\u7528\u3002"}}
{"id": "2601.12960", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12960", "abs": "https://arxiv.org/abs/2601.12960", "authors": ["Ainhoa Vivel-Couso", "Nicol\u00e1s Vila-Blanco", "Mar\u00eda J. Carreira", "Alberto Bugar\u00edn-Diz", "Inmaculada Tom\u00e1s", "Jose M. Alonso-Moral"], "title": "Trustworthy Data-driven Chronological Age Estimation from Panoramic Dental Images", "comment": "This paper is a preliminary version of an accepted article in Information Systems Frontiers, Springer, Special Issue \"Explainability in Human-Centric AI\". Please cite the final published version of the paper, not this preprint. The final published version can be found at https://link.springer.com/article/10.1007/s10796-025-10682-3", "summary": "Integrating deep learning into healthcare enables personalized care but raises trust issues due to model opacity. To improve transparency, we propose a system for dental age estimation from panoramic images that combines an opaque and a transparent method within a natural language generation (NLG) module. This module produces clinician-friendly textual explanations about the age estimations, designed with dental experts through a rule-based approach. Following the best practices in the field, the quality of the generated explanations was manually validated by dental experts using a questionnaire. The results showed a strong performance, since the experts rated 4.77+/-0.12 (out of 5) on average across the five dimensions considered. We also performed a trustworthy self-assessment procedure following the ALTAI checklist, in which it scored 4.40+/-0.27 (out of 5) across seven dimensions of the AI Trustworthiness Assessment List.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ed3\u5408\u900f\u660e\u4e0e\u4e0d\u900f\u660e\u65b9\u6cd5\u7684\u7259\u9f7f\u5e74\u9f84\u4f30\u8ba1\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u63d0\u4f9b\u4e34\u5e8a\u53cb\u597d\u89e3\u91ca\uff0c\u4e13\u5bb6\u8bc4\u5206\u9ad8\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u900f\u660e\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u533b\u7597\u4e2d\u7684\u5e94\u7528\u867d\u5b9e\u73b0\u4e2a\u6027\u5316\uff0c\u4f46\u6a21\u578b\u4e0d\u900f\u660e\u5bfc\u81f4\u4fe1\u4efb\u95ee\u9898\u3002\u4e3a\u63d0\u5347\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u6027\uff0c\u8bbe\u8ba1\u4fbf\u4e8e\u4e34\u5e8a\u533b\u751f\u7406\u89e3\u7684\u89e3\u91ca\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u7ed3\u5408\u4e0d\u900f\u660e\u4e0e\u900f\u660e\u6280\u672f\u7684\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\uff0c\u57fa\u4e8e\u89c4\u5219\u8bbe\u8ba1\u6587\u672c\u89e3\u91ca\uff0c\u4e13\u5bb6\u901a\u8fc7\u95ee\u5377\u9a8c\u8bc1\u89e3\u91ca\u8d28\u91cf\uff0c\u5e76\u8fdb\u884c\u53ef\u4fe1\u5ea6\u81ea\u6211\u8bc4\u4f30\u3002", "result": "\u751f\u6210\u7684\u89e3\u91ca\u88ab\u7259\u79d1\u4e13\u5bb6\u8bc4\u4e3a4.77/5\u5206\uff0c\u53ef\u4fe1\u5ea6\u81ea\u8bc4\u4e5f\u8fbe4.40/5\u5206\uff0c\u8868\u660e\u7cfb\u7edf\u5728\u89e3\u91ca\u8d28\u91cf\u548c\u4fe1\u4efb\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7ed3\u5408\u4e0d\u900f\u660e\u4e0e\u900f\u660e\u65b9\u6cd5\u7684\u7259\u9f7f\u5e74\u9f84\u4f30\u8ba1\u7cfb\u7edf\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u751f\u6210\u6a21\u5757\u63d0\u4f9b\u53ef\u4fe1\u7684\u89e3\u91ca\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u900f\u660e\u6027\u548c\u4e34\u5e8a\u53ef\u7528\u6027\u3002"}}
{"id": "2601.12973", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12973", "abs": "https://arxiv.org/abs/2601.12973", "authors": ["Shuanghong Huang", "Jinlei Xu", "Youchao Zhou", "Yanghao Zhou", "Xuan Zhao", "Chong Feng", "Wenxuan Zhang"], "title": "Pardon? Evaluating Conversational Repair in Large Audio-Language Models", "comment": null, "summary": "Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4fee\u590d\u611f\u77e5\u7684\u8bc4\u4f30\u65b9\u6cd5\u53caEAR\u8bc4\u5206\uff0c\u63ed\u793a\u73b0\u6709\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u7b54\u9898\u51c6\u786e\uff0c\u4f46\u5bf9\u8bed\u4e49\u4e0d\u53ef\u7b54\u7684\u8f93\u5165\u7f3a\u4e4f\u8bc6\u522b\u548c\u4fee\u590d\u80fd\u529b\uff0c\u4fc3\u8fdb\u6a21\u578b\u5728\u5b9e\u9645\u5bf9\u8bdd\u4e2d\u7684\u53ef\u9760\u6027\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u5047\u8bbe\u8bed\u97f3\u8f93\u5165\u59cb\u7ec8\u5177\u5907\u8bed\u4e49\u53ef\u7b54\u6027\uff0c\u4f46\u5b9e\u9645\u4ea4\u4e92\u4e2d\u5173\u952e\u4fe1\u606f\u7f3a\u5931\u5bfc\u81f4\u8f93\u5165\u4e0d\u53ef\u7b54\uff0c\u9700\u8bbe\u8ba1\u80fd\u53cd\u6620\u6a21\u578b\u5728\u6b64\u7c7b\u60c5\u51b5\u8868\u73b0\u7684\u8bc4\u4f30\u6307\u6807\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4fee\u590d\u611f\u77e5\u7684\u8bc4\u4f30\u8bbe\u7f6e\uff0c\u901a\u8fc7\u8bed\u4e49-\u58f0\u5b66\u63a9\u7801\u534f\u8bae\u6784\u9020\u53ef\u7b54\u4e0e\u4e0d\u53ef\u7b54\u7684\u914d\u5bf9\u8bc4\u4f30\u6761\u4ef6\uff0c\u5e76\u5f15\u5165\u4e86EAR\u8bc4\u5206\uff0c\u8054\u5408\u8bc4\u4f30\u6a21\u578b\u5728\u56de\u7b54\u95ee\u9898\u548c\u4fee\u590d\u65e0\u7b54\u6848\u8f93\u5165\u65f6\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u5728\u4e24\u4e2a\u8bed\u97f3\u95ee\u7b54\u57fa\u51c6\u4e0a\u6d4b\u8bd5\u591a\u79cd\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u5728\u53ef\u7b54\u6761\u4ef6\u4e0b\u6a21\u578b\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4f46\u5927\u591a\u6570\u6a21\u578b\u65e0\u6cd5\u8bc6\u522b\u8bed\u4e49\u4e0d\u53ef\u7b54\u7684\u8f93\u5165\u5e76\u8fdb\u884c\u9002\u5f53\u7684\u4ea4\u4e92\u4fee\u590d\uff0c\u66b4\u9732\u51fa\u73b0\u6709\u8bc4\u4f30\u7684\u4e0d\u8db3\u3002", "conclusion": "\u73b0\u6709\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u97f3\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u4e3b\u8981\u8bc4\u4f30\u96c6\u4e2d\u4e8e\u7b54\u6848\u51c6\u786e\u6027\uff0c\u5ffd\u89c6\u4e86\u8f93\u5165\u8bed\u97f3\u5728\u8bed\u4e49\u4e0a\u53ef\u80fd\u4e0d\u53ef\u56de\u7b54\u7684\u60c5\u51b5\uff0c\u5bfc\u81f4\u6a21\u578b\u5728\u5b9e\u9645\u4ea4\u4e92\u4e2d\u7f3a\u4e4f\u8bc6\u522b\u548c\u4fee\u6b63\u65e0\u7b54\u6848\u8f93\u5165\u7684\u80fd\u529b\u3002"}}
{"id": "2601.12974", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12974", "abs": "https://arxiv.org/abs/2601.12974", "authors": ["Hongyang Ma", "Tiantian Gu", "Huaiyuan Sun", "Huilin Zhu", "Yongxin Wang", "Jie Li", "Wubin Sun", "Zeliang Lian", "Yinghong Zhou", "Yi Gao", "Shirui Wang", "Zhihui Tang"], "title": "Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios", "comment": "29 pages, 15 figures", "summary": "The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping \"Guideline Adherence\" versus \"Decision Quality\" reveals a prevalent \"High Efficacy, Low Safety\" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSCMPE\u57fa\u51c6\u5168\u9762\u8bc4\u4f30\u7259\u79d1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u52a8\u6001\u4e92\u52a8\u4e2d\u7684\u4fe1\u606f\u6536\u96c6\u548c\u72b6\u6001\u8ffd\u8e2a\u80fd\u529b\u4e0d\u8db3\uff0c\u5916\u90e8\u77e5\u8bc6\u8f85\u52a9\u6709\u9650\uff0c\u6307\u51fa\u672a\u6765\u9700\u52a0\u5f3a\u9886\u57df\u9002\u5e94\u8bad\u7ec3\u4ee5\u5b9e\u73b0\u66f4\u5b89\u5168\u81ea\u4e3b\u7684\u4e34\u5e8a\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u88ab\u52a8\u77e5\u8bc6\u68c0\u7d22\u8005\u5411\u81ea\u4e3b\u4e34\u5e8a\u4ee3\u7406\u8f6c\u53d8\uff0c\u8bc4\u4f30\u6807\u51c6\u9700\u8981\u4ece\u9759\u6001\u51c6\u786e\u6027\u8f6c\u5411\u52a8\u6001\u884c\u4e3a\u53ef\u9760\u6027\uff0c\u7279\u522b\u662f\u5728\u7259\u79d1\u9886\u57df\uff0c\u8fd9\u5bf9\u60a3\u8005\u53c2\u4e0e\u51b3\u7b56\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e86\u6807\u51c6\u5316\u4e34\u5e8a\u7ba1\u7406\u4e0e\u6027\u80fd\u8bc4\u4f30\uff08SCMPE\uff09\u57fa\u51c6\uff0c\u6db5\u76d6\u77e5\u8bc6\u5bfc\u5411\u7684\u9759\u6001\u4efb\u52a1\u548c\u57fa\u4e8e\u5de5\u4f5c\u6d41\u7a0b\u7684\u591a\u8f6e\u6a21\u62df\u60a3\u8005\u4e92\u52a8\uff0c\u4ee5\u5168\u9762\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6a21\u578b\u5728\u9759\u6001\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5728\u52a8\u6001\u4e34\u5e8a\u5bf9\u8bdd\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff0c\u4e3b\u8981\u74f6\u9888\u5728\u4e8e\u4e3b\u52a8\u4fe1\u606f\u6536\u96c6\u548c\u52a8\u6001\u72b6\u6001\u8ddf\u8e2a\u3002\u4e00\u822c\u6a21\u578b\u5e38\u51fa\u73b0\u9ad8\u6548\u4f46\u4f4e\u5b89\u5168\u7684\u98ce\u9669\u3002\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u867d\u7136\u51cf\u5c11\u4e86\u9759\u6001\u4efb\u52a1\u4e2d\u7684\u5e7b\u89c9\uff0c\u4f46\u5728\u52a8\u6001\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u7684\u6548\u679c\u4e0d\u7a33\u5b9a\uff0c\u6709\u65f6\u53cd\u800c\u9000\u5316\u3002", "conclusion": "\u7259\u79d1\u9886\u57df\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u52a8\u6001\u4e34\u5e8a\u5e94\u7528\u4e2d\u4ecd\u5b58\u5728\u80fd\u529b\u8fb9\u754c\uff0c\u5916\u90e8\u77e5\u8bc6\u8865\u5145\u65e0\u6cd5\u5b8c\u5168\u89e3\u51b3\u63a8\u7406\u7f3a\u53e3\uff0c\u9700\u7ed3\u5408\u9886\u57df\u81ea\u9002\u5e94\u9884\u8bad\u7ec3\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u548c\u81ea\u4e3b\u4e34\u5e8a\u5b9e\u8df5\u80fd\u529b\u3002"}}
{"id": "2601.12979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12979", "abs": "https://arxiv.org/abs/2601.12979", "authors": ["Qingyu Lu", "Liang Ding", "Kanjian Zhang", "Jinxia Zhang", "Dacheng Tao"], "title": "The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check", "comment": "Under Review", "summary": "The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a \"bitter lesson\": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u57fa\u4e8e\u6269\u6563\u673a\u5236\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u667a\u80fd\u4ee3\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u867d\u63d0\u5347\u6548\u7387\u4f46\u9891\u7e41\u5931\u8d25\uff0c\u63d0\u51fa\u9700\u7ed3\u5408\u56e0\u679c\u7cbe\u786e\u63a8\u7406\u4ee5\u5b9e\u73b0\u5b9e\u7528\u667a\u80fd\u4ee3\u7406\u3002", "motivation": "\u63a2\u8ba8\u57fa\u4e8e\u6269\u6563\u7684\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u66ff\u4ee3\u81ea\u56de\u5f52\u6a21\u578b\u5728\u667a\u80fd\u4ee3\u7406\u4ea4\u4e92\u4e2d\u7684\u6f5c\u529b\u53ca\u5176\u6548\u7387\u63d0\u5347\u662f\u5426\u80fd\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u667a\u80fd\u884c\u4e3a\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5728\u4e24\u79cd\u4e0d\u540c\u667a\u80fd\u4ee3\u7406\u8303\u5f0f\uff08\u5177\u4f53\u73b0\u8eab\u4ee3\u7406\u548c\u5de5\u5177\u8c03\u7528\u4ee3\u7406\uff09\u4e0a\u7efc\u5408\u8bc4\u4f30dLLMs\u6027\u80fd\uff0c\u8bbe\u8ba1\u5e76\u5f15\u5165\u4e86DiffuAgent\u591a\u4ee3\u7406\u8bc4\u4f30\u6846\u67b6\uff0c\u5c06dLLMs\u4f5c\u4e3a\u8ba4\u77e5\u6838\u5fc3\u8fdb\u884c\u5b9e\u9a8c\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cdLLMs\u5728\u975e\u56e0\u679c\u89d2\u8272\uff08\u5982\u8bb0\u5fc6\u603b\u7ed3\u548c\u5de5\u5177\u9009\u62e9\uff09\u4e2d\u8868\u73b0\u6709\u6548\uff0c\u4f46\u5728\u56e0\u679c\u63a8\u7406\u548c\u7b26\u53f7\u7cbe\u5ea6\u65b9\u9762\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u9650\u5236\u4e86\u5176\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\u9aa8\u5e72\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u5f53\u524d\u57fa\u4e8e\u6269\u6563\u7684\u8bed\u8a00\u6a21\u578b(dLLMs)\u867d\u7136\u5728\u6548\u7387\u4e0a\u6709\u6240\u63d0\u5347\uff0c\u4f46\u5728\u4f5c\u4e3a\u667a\u80fd\u4ee3\u7406\u9aa8\u5e72\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u957f\u7a0b\u89c4\u5212\u548c\u7cbe\u786e\u683c\u5f0f\u9700\u6c42\uff0c\u9891\u7e41\u5931\u8d25\u3002"}}
{"id": "2601.12983", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12983", "abs": "https://arxiv.org/abs/2601.12983", "authors": ["Jesus-German Ortiz-Barajas", "Jonathan Tonglet", "Vivek Gupta", "Iryna Gurevych"], "title": "ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation", "comment": null, "summary": "Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ChartAttack\u6846\u67b6\uff0c\u63ed\u793a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u56fe\u8868\u65f6\u53ef\u88ab\u6ee5\u7528\u5236\u9020\u8bef\u5bfc\uff0c\u663e\u8457\u964d\u4f4e\u95ee\u7b54\u6027\u80fd\u5e76\u5f71\u54cd\u4eba\u7c7b\u5224\u65ad\uff0c\u5f3a\u8c03\u9700\u52a0\u5f3a\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u968f\u7740\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u56fe\u8868\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5b58\u5728\u88ab\u6ee5\u7528\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\u7684\u98ce\u9669\uff0c\u8feb\u5207\u9700\u8981\u8bc4\u4f30\u548c\u9632\u8303\u6b64\u7c7b\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86ChartAttack\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u56fe\u8868\u8bbe\u8ba1\u4e2d\u6ce8\u5165\u8bef\u5bfc\u5143\u7d20\u6765\u5927\u89c4\u6a21\u751f\u6210\u8bef\u5bfc\u6027\u56fe\u8868\uff0c\u5e76\u6784\u5efa\u4e86\u5e26\u6709\u8bef\u5bfc\u6807\u7b7e\u7684\u56fe\u8868\u95ee\u7b54\u6570\u636e\u96c6AttackViz\uff0c\u7528\u4e8e\u8bc4\u4f30\u8bef\u5bfc\u6548\u679c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cChartAttack\u5728\u540c\u57df\u548c\u8de8\u57df\u573a\u666f\u4e0b\u5747\u663e\u8457\u964d\u4f4e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u95ee\u7b54\u51c6\u786e\u7387\uff0c\u5206\u522b\u4e0b\u964d19.6\u70b9\u548c14.9\u70b9\uff1b\u4eba\u7c7b\u5b9e\u9a8c\u4e2d\u53c2\u4e0e\u8005\u7684\u51c6\u786e\u7387\u4e5f\u4e0b\u964d\u4e8620.2\u70b9\u3002", "conclusion": "ChartAttack\u6846\u67b6\u63ed\u793a\u4e86\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u56fe\u8868\u65f6\u53ef\u80fd\u88ab\u6ee5\u7528\u4ee5\u4ea7\u751f\u8bef\u5bfc\u6027\u56fe\u8868\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u56fe\u8868\u95ee\u7b54\u7cfb\u7edf\u7684\u51c6\u786e\u7387\uff0c\u63d0\u9192\u4e86\u6b64\u7c7b\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u5fc5\u987b\u91cd\u89c6\u7a33\u5065\u6027\u548c\u5b89\u5168\u6027\u95ee\u9898\u3002"}}
{"id": "2601.12995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.12995", "abs": "https://arxiv.org/abs/2601.12995", "authors": ["Runxuan Liu", "Xianhao Ou", "Xinyan Ma", "Jiyuan Wang", "Jiafeng Liang", "Jiaqi Li", "Tao He", "Zheng Chu", "Rongchuan Mu", "Zekun Wang", "Baoxin Wang", "Dayong Wu", "Ming Liu", "Shijin Wang", "Guoping Hu", "Bing Qin"], "title": "Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models", "comment": null, "summary": "Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u7ed3\u6784\u5316\u63a8\u7406\u8303\u5f0f\u548c\u8fc7\u7a0b\u611f\u77e5\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u957f\u94fe\u63a8\u7406\u8bad\u7ec3\u4e2d\u7684\u6548\u7387\u548c\u6cdb\u5316\u96be\u9898\uff0c\u5728\u6570\u5b66\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e0a\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u94fe\u63a8\u7406\u4e3b\u8981\u57fa\u4e8e\u7eaf\u6587\u672c\u751f\u6210\uff0c\u8bed\u4e49\u8bc4\u4ef7\u8ba1\u7b97\u590d\u6742\u4e14\u4f4e\u6548\uff0c\u4e14\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u9762\u4e34\u76d1\u7763\u7c97\u7cd9\u3001\u5956\u52b1\u6b3a\u9a97\u7b49\u96be\u9898\uff0c\u5f71\u54cd\u8bad\u7ec3\u6548\u679c\u548c\u6cdb\u5316\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u6784\u5efa\u7ed3\u6784\u5316\u3001\u7b26\u53f7\u5316\u7684\u63a8\u7406\u6846\u67b6\u53ca\u76f8\u5e94\u4f18\u5316\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u56fe\u7ed3\u6784\u548c\u6b65\u9aa4\u8ba4\u77e5\u6807\u7b7e\u7684\u7ed3\u6784\u5316\u7b26\u53f7\u63a8\u7406\uff08GRP\uff09\uff0c\u66ff\u4ee3\u4f20\u7edf\u7684\u6587\u672c\u8bed\u4e49\u8bc4\u4ef7\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5206\u5c42\u88c1\u526a\u4f18\u52bf\u4f30\u8ba1\u7b56\u7565\u7684\u4f18\u5316\u7b97\u6cd5\uff08PASC-GRPO\uff09\uff0c\u5b9e\u73b0\u4e86\u8fc7\u7a0b\u611f\u77e5\u7684\u9a8c\u8bc1\u548c\u5956\u52b1\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u5747\u6709\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u4e0e\u8fc7\u7a0b\u611f\u77e5\u4f18\u5316\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u6570\u636e\u3001\u6a21\u578b\u548c\u4ee3\u7801\u5c06\u968f\u540e\u516c\u5f00\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u56fe\u63a8\u7406\u8303\u5f0f\uff08GRP\uff09\u7ed3\u5408\u5206\u5c42\u88c1\u526a\u7b56\u7565\u4f18\u5316\u65b9\u6cd5\uff08PASC-GRPO\uff09\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u957f\u94fe\u63a8\u7406\u65b9\u6cd5\u4e2d\u5b58\u5728\u7684\u7c97\u7c92\u5ea6\u76d1\u7763\u3001\u5956\u52b1\u6b3a\u9a97\u3001\u9ad8\u8bad\u7ec3\u6210\u672c\u548c\u6cdb\u5316\u6027\u5dee\u7b49\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13018", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13018", "abs": "https://arxiv.org/abs/2601.13018", "authors": ["Ghislain Dorian Tchuente Mondjo"], "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context", "comment": "Accepted at \"EAI AFRICOMM 2025 - 17th EAI International Conference on Communications and Networks in Africa\"", "summary": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u4e2d\u89e3\u91ca\u4e0d\u7a33\u5b9a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53cc\u5411\u6ce8\u610f\u529b\u548cBiRNN\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u7c7b\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u4e86\u504f\u89c1\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eHateXplain\u7684\u7b97\u6cd5\u4e2d\uff0c\u6ce8\u610f\u529b\u503c\u6ce2\u52a8\u8f83\u5927\uff0c\u5bfc\u81f4\u89e3\u91ca\u4e0d\u4e00\u81f4\u3001\u9884\u6d4b\u4e0d\u7a33\u5b9a\u548c\u5b66\u4e60\u56f0\u96be\uff0c\u9650\u5236\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5411\u6ce8\u610f\u529b\u548c\u53cc\u5411\u5faa\u73af\u795e\u7ecf\u7f51\u7edc\uff08BiRNN\uff09\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u540c\u65f6\u8fdb\u884c\u5206\u7c7b\u548c\u89e3\u91ca\uff0c\u5728\u6a21\u578b\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u8003\u8651\u8f93\u5165\u6570\u636e\u7684\u5e8f\u5217\u7279\u5f81\uff0c\u63d0\u9ad8\u89e3\u91ca\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6a21\u578b\u5728HateXplain\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u68c0\u6d4b\u6027\u80fd\u3001\u89e3\u91ca\u6548\u679c\u7684\u660e\u663e\u63d0\u5347\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u65e0\u610f\u504f\u89c1\u7684\u53d1\u751f\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86BiAtt-BiRNN-HateXplain\u6a21\u578b\uff0c\u6709\u6548\u89e3\u51b3\u4e86HateXplain\u57fa\u7b97\u6cd5\u4e2d\u6ce8\u610f\u529b\u53d8\u5f02\u6027\u5927\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u6027\u80fd\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u51cf\u5c11\u4e86\u65e0\u610f\u7684\u793e\u533a\u504f\u89c1\u3002"}}
{"id": "2601.13024", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13024", "abs": "https://arxiv.org/abs/2601.13024", "authors": ["Chongyuan Dai", "Yaling Shen", "Jinpeng Hu", "Zihan Gao", "Jia Li", "Yishun Jiang", "Yaxiong Wang", "Liu Liu", "Zongyuan Ge"], "title": "Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses", "comment": "24 pages, 10 figures, 9 Tables", "summary": "Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \\underline{\\textsc{E}}licited \\underline{\\textsc{D}}istinct \\underline{\\textsc{A}}ffective \\underline{\\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.", "AI": {"tldr": "\u63d0\u51faCEDAR\u57fa\u51c6\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8de8\u6587\u5316\u60c5\u611f\u7406\u89e3\u80fd\u529b\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u6355\u6349\u6587\u5316\u9a71\u52a8\u7684\u60c5\u611f\u5dee\u5f02\u3002", "motivation": "\u73b0\u6709\u8bc4\u4f30\u4e3b\u8981\u5173\u6ce8\u5730\u7406\u4e8b\u5b9e\u548c\u793e\u4f1a\u4e60\u4fd7\u7b49\u9648\u8ff0\u6027\u77e5\u8bc6\uff0c\u65e0\u6cd5\u5145\u5206\u53cd\u6620\u6587\u5316\u591a\u6837\u6027\u5e26\u6765\u7684\u4e3b\u89c2\u60c5\u611f\u8be0\u91ca\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86CEDAR\u591a\u6a21\u6001\u57fa\u51c6\uff0c\u8fd0\u7528LLM\u751f\u6210\u521d\u6b65\u6807\u7b7e\u7b5b\u9009\u51fa\u8de8\u6587\u5316\u60c5\u611f\u5dee\u5f02\u663e\u8457\u7684\u5b9e\u4f8b\uff0c\u518d\u901a\u8fc7\u4e25\u683c\u4eba\u5de5\u8bc4\u4f30\u83b7\u5f97\u9ad8\u8d28\u91cf\u6807\u6ce8\u3002", "result": "\u6784\u5efa\u4e86\u6db5\u76d67\u79cd\u8bed\u8a00\u300114\u4e2a\u7ec6\u5206\u7c7b\u522b\u60c5\u611f\u3001\u517110962\u4e2a\u6837\u672c\u7684CEDAR\u57fa\u51c6\uff0c\u6d4b\u8bd5\u4e8617\u4e2a\u591a\u8bed\u79cd\u6a21\u578b\uff0c\u53d1\u73b0\u8bed\u8a00\u4e00\u81f4\u6027\u4e0e\u6587\u5316\u5bf9\u9f50\u5b58\u5728\u8131\u8282\u73b0\u8c61\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u5316\u5bf9\u9f50\u65b9\u9762\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5e26\u6709\u6587\u5316\u80cc\u666f\u8272\u5f69\u7684\u60c5\u611f\u7406\u89e3\u4e0a\u8868\u73b0\u4e0d\u8db3\u3002"}}
{"id": "2601.13035", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13035", "abs": "https://arxiv.org/abs/2601.13035", "authors": ["Xu Xiaodan", "Hu Xiaolin"], "title": "SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification", "comment": "in progress", "summary": "Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \\textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\\% on FB15k-237 and +3.4\\% on YAGO3-10.", "AI": {"tldr": "SASA\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u548c\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u6539\u5584\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5206\u7c7b\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5ffd\u7565\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e0d\u540c\u7ec4\u4ef6\u95f4\u7684\u6709\u6548\u8bed\u4e49\u4ea4\u4e92\uff0c\u4e14\u5355\u4e00\u4e8c\u5206\u7c7b\u8bad\u7ec3\u76ee\u6807\u5bfc\u81f4\u8bed\u4e49\u8868\u793a\u5b66\u4e60\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u5bf9\u4e09\u5143\u7ec4\u8fdb\u884c\u89e3\u8026\u7f16\u7801\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u611f\u77e5\u5206\u5c42\u5bf9\u6bd4\u5b66\u4e60\u4f5c\u4e3a\u8f85\u52a9\u8bad\u7ec3\u76ee\u6807\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u5224\u522b\u80fd\u529b\u548c\u8bed\u4e49\u8868\u793a\u3002", "result": "\u5728FB15k-237\u6570\u636e\u96c6\u63d0\u9ad85.9%\u51c6\u786e\u7387\uff0c\u5728YAGO3-10\u6570\u636e\u96c6\u63d0\u53473.4%\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "SASA\u6846\u67b6\u901a\u8fc7\u5206\u79bb\u6ce8\u610f\u529b\u673a\u5236\u548c\u8bed\u4e49\u611f\u77e5\u5bf9\u6bd4\u5b66\u4e60\u663e\u8457\u63d0\u5347\u4e86\u77e5\u8bc6\u56fe\u8c31\u4e09\u5143\u7ec4\u5206\u7c7b\u7684\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2601.13044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13044", "abs": "https://arxiv.org/abs/2601.13044", "authors": ["Warit Sirichotedumrong", "Adisai Na-Thalang", "Potsawee Manakul", "Pittawat Taveekitworachai", "Sittipong Sripaisarnmongkol", "Kunat Pipatanakul"], "title": "Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition", "comment": "Models and datasets are publicly available on https://huggingface.co/collections/typhoon-ai/typhoon-asr-technical-report ; Project Page: https://opentyphoon.ai/model/typhoon-asr-realtime", "summary": "Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.", "AI": {"tldr": "\u63d0\u51fa\u4f4e\u5ef6\u8fdf\u7684Typhoon ASR Real-time\u6cf0\u8bed\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\uff0c\u901a\u8fc7\u6587\u672c\u89c4\u8303\u5316\u548c\u8bfe\u7a0b\u5b66\u4e60\u5b9e\u73b0\u9ad8\u6548\u51c6\u786e\u7684\u6d41\u5f0f\u8bc6\u522b\uff0c\u5e76\u53d1\u5e03\u4e86\u6807\u51c6\u5316\u8bc4\u6d4b\u57fa\u51c6\uff0c\u586b\u8865\u4e86\u6cf0\u8bed\u6d41\u5f0fASR\u7684\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u6cf0\u8bed\u8bed\u97f3\u8bc6\u522b\u4e3b\u8981\u4f9d\u8d56\u9ad8\u5ef6\u8fdf\u7684\u79bb\u7ebf\u5927\u578b\u6a21\u578b\uff0c\u7f3a\u5c11\u9ad8\u6548\u4f4e\u5ef6\u8fdf\u7684\u6d41\u5f0f\u89e3\u51b3\u65b9\u6848\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e00\u5b9e\u9645\u9700\u6c42\uff0c\u63d0\u51fa\u9002\u7528\u4e8e\u6d41\u5f0f\u5e94\u7528\u7684\u4f4e\u5ef6\u8fdf\u6cf0\u8bedASR\u6a21\u578b\u3002", "method": "\u91c7\u7528115M\u53c2\u6570\u7684FastConformer-Transducer\u6a21\u578b\uff0c\u7ed3\u5408\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u5904\u7406\u6cf0\u8bed\u7279\u6709\u7684\u6587\u672c\u6b67\u4e49\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4e24\u9636\u6bb5\u8bfe\u7a0b\u5b66\u4e60\u65b9\u6cd5\u9002\u5e94\u4e1c\u5317\u65b9\u8a00\uff0c\u4fdd\u6301\u4e2d\u5fc3\u6cf0\u8bed\u6027\u80fd\u4e0d\u53d7\u5f71\u54cd\u3002", "result": "\u6a21\u578b\u5728\u8ba1\u7b97\u6210\u672c\u4e0a\u76f8\u6bd4Whisper Large-v3\u51cf\u5c11\u4e8645\u500d\uff0c\u540c\u65f6\u5728\u51c6\u786e\u7387\u4e0a\u4fdd\u6301\u53ef\u6bd4\u6027\u80fd\uff0c\u89c4\u8303\u5316\u5904\u7406\u6709\u6548\u51cf\u5c11\u6587\u672c\u6b67\u4e49\uff0c\u8bfe\u7a0b\u5b66\u4e60\u63d0\u5347\u4e86\u65b9\u8a00\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "Typhoon ASR Real-time\u6a21\u578b\u901a\u8fc7\u4e25\u683c\u7684\u6587\u672c\u89c4\u8303\u5316\u548c\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u5728\u4fdd\u6301\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u548c\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u4e0e\u5927\u578b\u6a21\u578bWhisper Large-v3\u76f8\u5f53\u7684\u51c6\u786e\u6027\uff0c\u6ee1\u8db3\u6cf0\u8bed\u6d41\u5f0f\u8bed\u97f3\u8bc6\u522b\u7684\u5e94\u7528\u9700\u6c42\u3002"}}
{"id": "2601.13050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13050", "abs": "https://arxiv.org/abs/2601.13050", "authors": ["Lars Kl\u00f6ser", "Mika Beele", "Bodo Kraft"], "title": "Profiling German Text Simplification with Interpretable Model-Fingerprints", "comment": "Presented at 2nd International Conference on Explainable AI for Neural and Symbolic Systems", "summary": "While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.", "AI": {"tldr": "\u63d0\u51faSimplification Profiler\uff0c\u751f\u6210\u6a21\u578b\u7b80\u5316\u7684\u591a\u7ef4\u884c\u4e3a\u6307\u7eb9\uff0c\u65e0\u9700\u4eba\u5de5\u8bc4\u5206\u5373\u53ef\u51c6\u786e\u533a\u5206\u6a21\u578b\u914d\u7f6e\uff0c\u52a9\u529b\u6784\u5efa\u66f4\u7075\u6d3b\u9ad8\u6548\u7684\u6587\u672c\u7b80\u5316\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6587\u672c\u7b80\u5316\u884c\u4e3a\u7684\u6574\u4f53\u3001\u9ad8\u6548\u3001\u53ef\u590d\u73b0\u8bca\u65ad\u5de5\u5177\uff0c\u4e14\u6570\u636e\u532e\u4e4f\u95ee\u9898\u5728\u591a\u8bed\u8a00\u548c\u591a\u76ee\u6807\u7fa4\u4f53\u6587\u672c\u7b80\u5316\u4e2d\u5c24\u4e3a\u4e25\u91cd\uff0c\u9700\u4e00\u79cd\u66f4\u76f8\u5173\u7684\u8bc4\u4f30\u65b9\u5f0f\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86Simplification Profiler\u8bca\u65ad\u5de5\u5177\uff0c\u901a\u8fc7\u805a\u5408\u591a\u4e2a\u7b80\u5316\u7ed3\u679c\u5f62\u6210\u6a21\u578b\u6307\u7eb9\uff0c\u5e76\u901a\u8fc7\u7ebf\u6027\u5206\u7c7b\u5668\u9a8c\u8bc1\u6307\u7eb9\u5bf9\u4e0d\u540c\u6a21\u578b\u914d\u7f6e\u7684\u533a\u5206\u80fd\u529b\uff0c\u5b9e\u73b0\u65e0\u9700\u5927\u91cf\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u7684\u5143\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u533a\u5206\u4e0d\u540c\u63d0\u793a\u7b56\u7565\u53ca\u7ec6\u7c92\u5ea6\u63d0\u793a\u5de5\u7a0b\u8c03\u6574\u65f6\uff0cF1-score\u6700\u9ad8\u8fbe\u523071.9%\uff0c\u6bd4\u57fa\u7ebf\u63d0\u5347\u8d85\u8fc748\u4e2a\u767e\u5206\u70b9\uff0c\u8bc1\u660e\u5176\u654f\u611f\u4e14\u6709\u6548\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684Simplification Profiler\u80fd\u591f\u751f\u6210\u591a\u7ef4\u5ea6\u3001\u53ef\u89e3\u91ca\u7684\u6587\u672c\u7b80\u5316\u7279\u5f81\u6307\u7eb9\uff0c\u51c6\u786e\u533a\u5206\u6a21\u578b\u7684\u4e0d\u540c\u7b80\u5316\u884c\u4e3a\uff0c\u63d0\u5347\u4e86\u6587\u672c\u7b80\u5316\u7cfb\u7edf\u7684\u8bca\u65ad\u548c\u9002\u5e94\u80fd\u529b\u3002"}}
{"id": "2601.13099", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13099", "abs": "https://arxiv.org/abs/2601.13099", "authors": ["Abdellah El Mekki", "Samar M. Magdy", "Houdaifa Atou", "Ruwa AbuHweidi", "Baraah Qawasmeh", "Omer Nacar", "Thikra Al-hibiri", "Razan Saadie", "Hamzah Alsayadi", "Nadia Ghezaiel Hammouda", "Alshima Alkhazimi", "Aya Hamod", "Al-Yas Al-Ghafri", "Wesam El-Sayed", "Asila Al sharji", "Mohamad Ballout", "Anas Belfathi", "Karim Ghaddar", "Serry Sibaee", "Alaa Aoun", "Areej Asiri", "Lina Abureesh", "Ahlam Bashiti", "Majdal Yousef", "Abdulaziz Hafiz", "Yehdih Mohamed", "Emira Hamedtou", "Brakehe Brahim", "Rahaf Alhamouri", "Youssef Nafea", "Aya El Aatar", "Walid Al-Dhabyani", "Emhemed Hamed", "Sara Shatnawi", "Fakhraddin Alwajih", "Khalid Elkhidir", "Ashwag Alasmari", "Abdurrahman Gerrio", "Omar Alshahri", "AbdelRahim A. Elmadany", "Ismail Berrada", "Amir Azad Adli Alkathiri", "Fadi A Zaraket", "Mustafa Jarrar", "Yahya Mohamed El Hadj", "Hassan Alhuzali", "Muhammad Abdul-Mageed"], "title": "Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs", "comment": "Project resources will be available here: https://github.com/UBC-NLP/Alexandria", "summary": "Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \\textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u8986\u76d6\u5e7f\u6cdb\u65b9\u8a00\u548c\u9886\u57df\u3001\u5e26\u6709\u7ec6\u7c92\u5ea6\u6807\u6ce8\u7684\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7ffb\u8bd1\u6570\u636e\u96c6Alexandria\uff0c\u63a8\u52a8\u65b9\u8a00\u673a\u5668\u7ffb\u8bd1\u548c\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u5bf9\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7684\u652f\u6301\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5176\u5728\u5e7f\u5927\u65b9\u8a00\u4f7f\u7528\u8005\u4e2d\u7684\u5e94\u7528\uff0c\u4e9f\u9700\u7ec6\u7c92\u5ea6\u3001\u591a\u6837\u5316\u7684\u65b9\u8a00\u6570\u636e\u652f\u6301\u3002", "method": "\u6784\u5efa\u5e76\u53d1\u5e03\u4e00\u4e2a\u6db5\u76d613\u4e2a\u963f\u62c9\u4f2f\u56fd\u5bb6\u300111\u4e2a\u9886\u57df\u3001\u5e26\u6709\u57ce\u5e02\u6765\u6e90\u5143\u6570\u636e\u53ca\u6027\u522b\u914d\u7f6e\u6807\u6ce8\u7684\u5927\u89c4\u6a21\u4eba\u5de5\u7ffb\u8bd1\u5bf9\u8bdd\u6570\u636e\u96c6Alexandria\uff0c\u5e76\u901a\u8fc7\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u6d4b\u9a8c\u8bc1\u8be5\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\u3002", "result": "Alexandria\u5305\u542b107K\u6837\u672c\uff0c\u8986\u76d6\u591a\u65b9\u8a00\u591a\u9886\u57df\u5bf9\u8bdd\u573a\u666f\uff0c\u6807\u6ce8\u8be6\u5c3d\uff0c\u80fd\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u548c\u4e25\u683c\u57fa\u51c6\uff0c\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\u5f53\u524d\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00MT\u548cLLM\u5b58\u5728\u8f83\u5927\u6311\u6218\u3002", "conclusion": "Alexandria\u6570\u636e\u96c6\u4e3a\u591a\u79cd\u963f\u62c9\u4f2f\u65b9\u8a00\u673a\u5668\u7ffb\u8bd1\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u8bc4\u6d4b\u63d0\u4f9b\u4e86\u91cd\u8981\u8d44\u6e90\uff0c\u663e\u8457\u4fc3\u8fdb\u4e86\u65b9\u8a00MT\u7cfb\u7edf\u7684\u6539\u8fdb\u3002"}}
{"id": "2601.13105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13105", "abs": "https://arxiv.org/abs/2601.13105", "authors": ["Liu Kaipeng", "Wu Ling"], "title": "Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification", "comment": "19pages, 1figure", "summary": "This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06LoRA\u5fae\u8c03\u4e0eRAG\u6846\u67b6\u7ed3\u5408\uff0c\u7528\u4e8e\u81ea\u52a8\u8bc6\u522b\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u5fae\u8c03\u4f7f\u6a21\u578b\u5224\u65ad\u66f4\u8d8b\u5411\u8bed\u4e49\u7406\u89e3\u3002", "motivation": "\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u590d\u6742\u8bed\u8a00\u7ed3\u6784\u2014\u2014\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\u7684\u81ea\u52a8\u8bc6\u522b\u80fd\u529b\uff0c\u5f25\u8865\u7eaf\u7406\u8bba\u6a21\u578b\u548c\u672a\u5fae\u8c03\u6a21\u578b\u7684\u4e0d\u8db3\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5728\u82f1\u56fd\u56fd\u5bb6\u8bed\u6599\u5e93\u7684\u6807\u6ce8\u6570\u636e\u4e0a\u5bf9Qwen3-8B\u6a21\u578b\u8fdb\u884cLoRA\u5fae\u8c03\uff0c\u5e76\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u5b8c\u6210\u4e8c\u5206\u7c7b\u4efb\u52a1\u3002", "result": "LoRA\u5fae\u8c03\u540e\u7684Qwen3-8B\u6a21\u578b\u5728\u4e8c\u5206\u7c7b\u4efb\u52a1\u4e2d\u6027\u80fd\u660e\u663e\u4f18\u4e8e\u539f\u751fQwen3-MAX\u6a21\u578b\u53ca\u4ec5\u4f9d\u8d56\u7406\u8bba\u7684RAG\u7cfb\u7edf\u3002", "conclusion": "LoRA\u5fae\u8c03\u7ed3\u5408RAG\u6846\u67b6\u80fd\u591f\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u82f1\u8bed\u53cc\u53ca\u7269\u7ed3\u6784\u7684\u81ea\u52a8\u8bc6\u522b\u6027\u80fd\u3002"}}
{"id": "2601.13111", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13111", "abs": "https://arxiv.org/abs/2601.13111", "authors": ["Hassan Soliman", "Vivek Gupta", "Dan Roth", "Iryna Gurevych"], "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL", "comment": "Preprint under review. Code and data available at: https://github.com/UKPLab/arxiv2026-core-t", "summary": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.", "AI": {"tldr": "\u9488\u5bf9\u591a\u8868\u6587\u672c\u5230SQL\u68c0\u7d22\u96be\u9898\uff0c\u63d0\u51fa\u65e0\u8bad\u7ec3CORE-T\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u51c6\u786e\u7387\u548c\u6267\u884c\u6548\u679c\uff0c\u4e14\u63a8\u7406\u6210\u672c\u4f4e\u3002", "motivation": "\u73b0\u5b9e\u6587\u672c\u5230SQL\u7684\u5de5\u4f5c\u6d41\u7a0b\u901a\u5e38\u9700\u8981\u8fde\u63a5\u591a\u5f20\u8868\uff0c\u56e0\u6b64\u51c6\u786e\u68c0\u7d22\u76f8\u5173\u8868\u96c6\u6210\u4e3a\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51faCORE-T\u6846\u67b6\uff0c\u901a\u8fc7LLM\u751f\u6210\u7684\u7528\u9014\u5143\u6570\u636e\u4e30\u5bcc\u8868\u4fe1\u606f\uff0c\u9884\u8ba1\u7b97\u8f7b\u91cf\u7ea7\u8868\u517c\u5bb9\u6027\u7f13\u5b58\uff0c\u7ed3\u5408\u5bc6\u96c6\u68c0\u7d22\u548c\u5355\u6b21LLM\u8c03\u7528\u9009\u62e9\u53ef\u8fde\u63a5\u5b50\u96c6\u3002", "result": "CORE-T\u5728Bird\u3001Spider\u548cMMQA\u6570\u636e\u96c6\u4e0a\u63d0\u9ad8\u8868\u9009\u62e9F1\u503c\u6700\u9ad822.7\u70b9\uff0c\u51cf\u5c1142%\u8868\u68c0\u7d22\u6570\uff0c\u63d0\u5347\u591a\u8868\u6267\u884c\u51c6\u786e\u7387\u4e0a\u96506.9\u70b9\uff0c\u5e76\u51cf\u5c114-5\u500d\u7684\u4ee4\u724c\u4f7f\u7528\u3002", "conclusion": "CORE-T\u662f\u4e00\u79cd\u65e0\u8bad\u7ec3\u3001\u53ef\u6269\u5c55\u7684\u591a\u8868\u68c0\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u5143\u6570\u636e\u548c\u7f13\u5b58\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u5230SQL\u5728\u591a\u8868\u73af\u5883\u4e0b\u7684\u68c0\u7d22\u51c6\u786e\u6027\u53ca\u6267\u884c\u6027\u80fd\u3002"}}
{"id": "2601.13115", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.13115", "abs": "https://arxiv.org/abs/2601.13115", "authors": ["Fengran Mo", "Yifan Gao", "Sha Li", "Hansi Zeng", "Xin Liu", "Zhaoxuan Tan", "Xian Li", "Jianshu Chen", "Dakuo Wang", "Meng Jiang"], "title": "Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning", "comment": null, "summary": "Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u8f6e\u5bf9\u8bdd\u641c\u7d22\u4e0e\u63a8\u7406\u4ea4\u7ec7\u7684\u4f1a\u8bdd\u4ee3\u7406\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u8f6e\u4eba\u673a\u4ea4\u4e92\u4e2d\u52a8\u6001\u7406\u89e3\u548c\u54cd\u5e94\u7528\u6237\u610f\u56fe\u7684\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u9759\u6001\u7684\u91cd\u5199\u3001\u68c0\u7d22\u548c\u751f\u6210\u6d41\u6c34\u7ebf\uff0c\u5206\u522b\u4f18\u5316\u5404\u6b65\u9aa4\uff0c\u5ffd\u89c6\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7528\u6237\u610f\u56fe\u968f\u65f6\u95f4\u6f14\u53d8\u4e14\u9700\u52a8\u6001\u534f\u8c03\u68c0\u7d22\u4e0e\u751f\u6210\u8fc7\u7a0b\u7684\u9700\u6c42\u3002", "method": "\u672c\u6587\u91c7\u7528\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u4f1a\u8bdd\u4ee3\u7406\uff0c\u5b9e\u73b0\u641c\u7d22\u548c\u63a8\u7406\u7684\u4ea4\u66ff\u8fdb\u884c\uff0c\u7ed3\u5408\u5b9a\u5236\u5316\u5956\u52b1\u51fd\u6570\uff0c\u4f7f\u4ee3\u7406\u80fd\u591f\u52a8\u6001\u534f\u8c03\u68c0\u7d22\u4e0e\u751f\u6210\u8fc7\u7a0b\uff0c\u4f18\u5316\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u54cd\u5e94\u8d28\u91cf\u3002", "result": "\u5728\u56db\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u4f1a\u8bdd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u672c\u6587\u65b9\u6cd5\u4f18\u4e8e\u591a\u79cd\u5f3a\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u591a\u8f6e\u4efb\u52a1\u5bfc\u5411\u578b\u5bf9\u8bdd\u4e2d\u5e94\u5bf9\u590d\u6742\u7528\u6237\u610f\u56fe\u53d8\u5316\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u4ea4\u4e92\u5f0f\u4f1a\u8bdd\u4ee3\u7406\u901a\u8fc7\u591a\u8f6e\u4e2d\u7684\u641c\u7d22\u4e0e\u63a8\u7406\u4ea4\u7ec7\uff0c\u5b9e\u73b0\u4e86\u9002\u5e94\u6027\u5f3a\u548c\u63a2\u7d22\u6027\u5f3a\u7684\u884c\u4e3a\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7528\u6237\u610f\u56fe\u6f14\u53d8\u7684\u7406\u89e3\u548c\u54cd\u5e94\u80fd\u529b\u3002"}}
{"id": "2601.13137", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13137", "abs": "https://arxiv.org/abs/2601.13137", "authors": ["Yuan Gao", "Zhigang Liu", "Xinyu Yao", "Bo Chen", "Xiaobing Zhao"], "title": "Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains", "comment": "13 pages, 5 figures", "summary": "With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u504f\u89c1\u548c\u4ef7\u503c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u4e00\u79cd\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u8bad\u7ec3\u63d0\u5347\u6a21\u578b\u4ef7\u503c\u4e00\u81f4\u6027\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "motivation": "\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\uff08\u5982\u79cd\u65cf\u3001\u793e\u4f1a\u548c\u653f\u6cbb\uff09\u5b58\u5728\u504f\u89c1\u53ca\u4ef7\u503c\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u63d0\u51fa\u6539\u8fdb\u65b9\u6cd5\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u4ef7\u503c\u4e00\u81f4\u6027\u548c\u54cd\u5e94\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u3001\u6307\u4ee4\u5fae\u8c03\u548c\u5bf9\u6297\u8bad\u7ec3\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u653b\u51fb\u8005\u751f\u6210\u4e89\u8bae\u6027\u67e5\u8be2\uff0c\u884c\u4e3a\u8005\u751f\u6210\u4ef7\u503c\u4e00\u81f4\u7684\u56de\u5e94\uff0c\u8bc4\u8bba\u8005\u7b5b\u9009\u786e\u4fdd\u56de\u5e94\u8d28\u91cf\u3002", "result": "\u5728\u4e2d\u82f1\u6587\u53cc\u8bed\u8bc4\u4f30\u6570\u636e\u96c6\u4e0a\uff0c\u8bad\u7ec3\u5f97\u5230\u7684VC-LLM\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5bf9\u6297\u5bf9\u9f50\u6846\u67b6\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u654f\u611f\u9886\u57df\u7684\u4ef7\u503c\u4e00\u81f4\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u6a21\u578b\u3002"}}
{"id": "2601.13155", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13155", "abs": "https://arxiv.org/abs/2601.13155", "authors": ["Zimeng Wu", "Donghao Wang", "Chaozhe Jin", "Jiaxin Chen", "Yunhong Wang"], "title": "Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference", "comment": null, "summary": "Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\\times$ and 2.29$\\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51faSPTS\uff0c\u4e00\u79cd\u65e0\u8bad\u7ec3\u7684\u957f\u4e0a\u4e0b\u6587\u5927\u6a21\u578b\u9ad8\u6548\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u521b\u65b0Token\u8df3\u8fc7\u7b56\u7565\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\uff0c\u540c\u65f6\u4fdd\u8bc1\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8etoken\u7684\u526a\u679d\u548c\u8df3\u8fc7\u65b9\u6cd5\u52a0\u901f\u6f5c\u529b\u6709\u9650\uff0c\u5b58\u5728\u8fc7\u65f6\u7684\u4ee3\u7406\u4fe1\u53f7\u548c\u5197\u4f59\u5e72\u6270\uff0c\u5bfc\u81f4\u901f\u5ea6\u4e0e\u51c6\u786e\u6027\u7684\u6743\u8861\u4e0d\u4f73\uff0c\u4e9f\u9700\u4e00\u79cd\u66f4\u52a0\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u8df3\u8fc7\u673a\u5236\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u8bad\u7ec3\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u52a0\u901f\u6846\u67b6SPTS\uff0c\u5305\u62ec\u90e8\u5206\u6ce8\u610f\u529b\u63a2\u6d4b\uff08PAP\uff09\u9009\u62e9\u6027\u8df3\u8fc7\u591a\u5934\u6ce8\u610f\u529b\u4e2d\u7684\u5173\u952etoken\uff0c\u4f4e\u79e9\u53d8\u6362\u63a2\u6d4b\uff08LTP\uff09\u9884\u6d4b\u524d\u9988\u7f51\u7edc\u4e2d\u7684token\u53d8\u6362\uff0c\u4ee5\u53ca\u591a\u9636\u6bb5\u5ef6\u8fdf\u526a\u679d\uff08MSDP\uff09\u7b56\u7565\u9010\u5c42\u4f18\u5316token\u526a\u679d\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cSPTS\u5728\u524d\u7f6e\u548c\u7aef\u5230\u7aef\u751f\u6210\u9636\u6bb5\u5206\u522b\u5b9e\u73b0\u4e86\u6700\u9ad82.46\u500d\u548c2.29\u500d\u52a0\u901f\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u9ad8\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684SPTS\u65b9\u6cd5\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2d\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u52a0\u901f\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6027\u80fd\uff0c\u8fbe\u5230\u4e86\u63a8\u7406\u901f\u5ea6\u4e0e\u7cbe\u5ea6\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2601.13178", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13178", "abs": "https://arxiv.org/abs/2601.13178", "authors": ["Joseph Gatto", "Parker Seegmiller", "Timothy Burdick", "Philip Resnik", "Roshnik Rahat", "Sarah DeLozier", "Sarah M. Preum"], "title": "Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages", "comment": "19 Pages, 5 Figures", "summary": "Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `\"which message is more medically urgent\" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.\n  We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u5927\u89c4\u6a21\u516c\u5f00\u533b\u5b66\u5206\u8bca\u6570\u636e\u96c6PMR-Bench\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u65b9\u6cd5\u8bad\u7ec3\u6a21\u578b\u5b9e\u73b0\u57fa\u4e8e\u60a3\u8005\u6d88\u606f\u7684\u533b\u7597\u7d27\u6025\u5ea6\u6392\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u533b\u60a3\u4fe1\u606f\u5904\u7406\u6548\u7387\u3002", "motivation": "\u533b\u7597\u5206\u8bca\u4efb\u52a1\u9700\u8981\u6709\u6548\u5730\u5206\u914d\u533b\u7597\u8d44\u6e90\uff0c\u5c24\u5176\u662f\u5728\u95e8\u8bca\u975e\u5b9e\u65f6\u5f02\u6b65\u60a3\u8005\u6d88\u606f\u5904\u7406\u4e2d\u7f3a\u4e4f\u516c\u5f00\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u9ad8\u6548\u65b9\u6cd5\u3002", "method": "\u5c06\u60a3\u8005\u6d88\u606f\u5206\u8bca\u4efb\u52a1\u6784\u5efa\u4e3a\u914d\u5bf9\u63a8\u65ad\u95ee\u9898\uff0c\u901a\u8fc7\u5934\u5bf9\u5934\u7b5b\u9009\u4f18\u5148\u7ea7\uff0c\u8bbe\u8ba1\u4e86\u81ea\u52a8\u6807\u6ce8\u7b56\u7565\u5f15\u5bfc\u5927\u6a21\u578b\u8bad\u7ec3\uff1b\u8bad\u7ec3\u4e24\u7c7b\u6a21\u578bUrgentSFT\uff08\u57fa\u4e8e\u4e0b\u4e00\u4e2a\u8bcd\u9884\u6d4b\uff09\u548cUrgentReward\uff08\u57fa\u4e8eBradley-Terry\u6a21\u578b\uff09\u5b8c\u6210\u4f18\u5148\u7ea7\u6392\u5e8f\u3002", "result": "PMR-Bench\u5305\u542b1569\u6761\u60a3\u8005\u6d88\u606f\u548c2000\u591a\u9ad8\u8d28\u91cf\u6d4b\u8bd5\u914d\u5bf9\uff0cUrgentSFT-8B\u53caUrgentReward-8B\u6bd4\u901a\u75288B\u6a21\u578b\u5728\u4efb\u52a1\u6307\u6807\u4e0a\u5206\u522b\u63d0\u534715\u548c16\u5206\uff0c\u8868\u73b0\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u6784\u5efa\u4e86\u7b2c\u4e00\u4e2a\u5927\u89c4\u6a21\u516c\u5f00\u7684\u7528\u4e8e\u533b\u5b66\u5206\u8bca\u4efb\u52a1\u7684\u6570\u636e\u96c6PMR-Bench\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u57fa\u4e8e\u60a3\u8005\u6d88\u606f\u7684\u533b\u7597\u4f18\u5148\u7ea7\u8bc4\u4f30\u7814\u7a76\u3002\u8bad\u7ec3\u7684\u6a21\u578bUrgentSFT\u548cUrgentReward\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5206\u522b\u9002\u5408\u4e0d\u540c\u8d44\u6e90\u73af\u5883\u3002"}}
{"id": "2601.13183", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13183", "abs": "https://arxiv.org/abs/2601.13183", "authors": ["Sergio Servantez", "Sarah B. Lawsky", "Rajiv Jain", "Daniel W. Linna", "Kristian Hammond"], "title": "OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand", "comment": "25 pages, 9 Figures, 15 tables", "summary": "Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.", "AI": {"tldr": "OpenExempt\u6846\u67b6\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6cd5\u5f8b\u7b26\u53f7\u8868\u793a\u7684\u52a8\u6001\u751f\u6210\u63a8\u7406\u4efb\u52a1\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u6cd5\u5f8b\u63a8\u7406\u8bca\u65ad\u57fa\u51c6\uff0c\u80fd\u591f\u7ec6\u81f4\u8bc4\u4f30\u8bed\u8a00\u6a21\u578b\u7684\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\uff0c\u516c\u5f00\u53d1\u5e03\u4ee5\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002", "motivation": "\u4f20\u7edf\u7684\u9759\u6001\u95ee\u7b54\u5bf9\u6d4b\u8bd5\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u590d\u6742\u6cd5\u5f8b\u63a8\u7406\u4e2d\u7684\u6a21\u578b\u8868\u73b0\uff0c\u4e14\u6784\u5efa\u6210\u672c\u9ad8\uff0c\u96be\u4ee5\u9488\u5bf9\u5177\u4f53\u5931\u8d25\u6a21\u5f0f\u8fdb\u884c\u5206\u6790\u3002", "method": "\u901a\u8fc7\u4e13\u5bb6\u8bbe\u8ba1\u7684\u7b26\u53f7\u5316\u8868\u793a\uff0c\u52a8\u6001\u751f\u6210\u7b26\u5408\u7f8e\u56fd\u7834\u4ea7\u6cd5\u6761\u6b3e\u7684\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4efb\u52a1\u53ca\u5176\u53ef\u8ba1\u7b97\u89e3\u7b54\uff0c\u6784\u5efa\u4e86\u5305\u542b9765\u4e2a\u6837\u672c\u7684\u591a\u8bc4\u4f30\u5957\u4ef6\u7684\u6cd5\u5f8b\u63a8\u7406\u57fa\u51c6\u3002", "result": "\u572813\u4e2a\u591a\u6837\u5316\u8bed\u8a00\u6a21\u578b\u4e0a\u6d4b\u8bd5\u53d1\u73b0\uff0c\u53ea\u6709\u5728\u8f83\u957f\u63a8\u7406\u94fe\u8def\u548c\u5b58\u5728\u6df7\u6dc6\u9648\u8ff0\u65f6\uff0c\u6a21\u578b\u6027\u80fd\u624d\u4f1a\u51fa\u73b0\u660e\u663e\u4e0b\u964d\uff0c\u8868\u660e\u8be5\u57fa\u51c6\u80fd\u6709\u6548\u63ed\u793a\u6a21\u578b\u63a8\u7406\u5f31\u70b9\u3002", "conclusion": "\u73b0\u6709\u7684\u6cd5\u5f8b\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u96be\u4ee5\u5bf9\u6a21\u578b\u8fdb\u884c\u7ec6\u81f4\u8bca\u65ad\uff0cOpenExempt\u6846\u67b6\u548c\u57fa\u51c6\u901a\u8fc7\u52a8\u6001\u751f\u6210\u6cd5\u5f8b\u63a8\u7406\u4efb\u52a1\uff0c\u63d0\u4f9b\u4e86\u66f4\u52a0\u7ec6\u7c92\u5ea6\u548c\u591a\u6837\u5316\u7684\u6d4b\u8bd5\u65b9\u5f0f\uff0c\u80fd\u591f\u63ed\u793a\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u8def\u5f84\u548c\u969c\u788d\u6027\u9648\u8ff0\u4e0b\u7684\u6027\u80fd\u74f6\u9888\u3002"}}
{"id": "2601.13217", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13217", "abs": "https://arxiv.org/abs/2601.13217", "authors": ["Bingsen Chen", "Boyan Li", "Ping Nie", "Yuyu Zhang", "Xi Ye", "Chen Zhao"], "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision", "comment": null, "summary": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faMr Dre\u8bc4\u4f30\u5957\u4ef6\uff0c\u9996\u6b21\u7cfb\u7edf\u8861\u91cf\u591a\u8f6e\u7528\u6237\u53cd\u9988\u9a71\u52a8\u7684\u62a5\u544a\u4fee\u8ba2\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\u5728\u591a\u8f6e\u7f16\u8f91\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u65e0\u6cd5\u7a33\u5b9a\u4fdd\u6301\u5185\u5bb9\u8d28\u91cf\u548c\u5f15\u7528\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u7814\u7a76\u4ee3\u7406\uff08DRA\uff09\u5728\u751f\u6210\u62a5\u544a\u65b9\u9762\u4ec5\u4f5c\u4e3a\u4e00\u6b21\u6027\u5199\u4f5c\u4efb\u52a1\uff0c\u5ffd\u89c6\u4e86\u4eba\u7c7b\u7814\u7a76\u8005\u901a\u8fc7\u81ea\u6211\u53cd\u601d\u6216\u540c\u884c\u53cd\u9988\u8fdb\u884c\u591a\u8f6e\u8fed\u4ee3\u4fee\u8ba2\u7684\u8fc7\u7a0b\u3002\u662f\u5426\u80fd\u901a\u8fc7\u7528\u6237\u53cd\u9988\u53ef\u9760\u5730\u4fee\u8ba2\u62a5\u544a\u5c1a\u672a\u88ab\u63a2\u8ba8\u3002", "method": "\u5f15\u5165Mr Dre\u8bc4\u4f30\u5957\u4ef6\uff0c\u5efa\u7acb\u591a\u8f6e\u62a5\u544a\u4fee\u8ba2\u7684\u65b0\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u5305\u542b\u7edf\u4e00\u7684\u957f\u7bc7\u62a5\u544a\u8bc4\u4f30\u534f\u8bae\uff08\u6db5\u76d6\u5168\u9762\u6027\u3001\u4e8b\u5b9e\u6027\u548c\u5c55\u793a\u8d28\u91cf\uff09\u4ee5\u53ca\u4eba\u5de5\u9a8c\u8bc1\u7684\u53cd\u9988\u6a21\u62df\u591a\u8f6e\u4fee\u8ba2\u6d41\u7a0b\u3002", "result": "\u4e94\u4e2a\u4e0d\u540cDRA\u7684\u5206\u6790\u8868\u660e\uff0c\u4ee3\u7406\u80fd\u591f\u54cd\u5e94\u5927\u90e8\u5206\u7528\u6237\u53cd\u9988\uff0c\u4f46\u4e5f\u4f1a\u572816-27%\u7684\u5df2\u8986\u76d6\u5185\u5bb9\u548c\u5f15\u7528\u8d28\u91cf\u4e0a\u4ea7\u751f\u56de\u9000\u3002\u591a\u8f6e\u4fee\u8ba2\u4e2d\uff0c\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u4ee3\u7406\u4ecd\u5b58\u5728\u663e\u8457\u95ee\u9898\uff0c\u5982\u6270\u4e71\u53cd\u9988\u8303\u56f4\u5916\u7684\u5185\u5bb9\u548c\u65e0\u6cd5\u4fdd\u6301\u65e9\u671f\u7f16\u8f91\u3002", "conclusion": "\u5f53\u524dDRA\u5728\u591a\u8f6e\u53cd\u9988\u4fee\u8ba2\u4efb\u52a1\u4e2d\u5b58\u5728\u663e\u8457\u5c40\u9650\uff0c\u666e\u901a\u7684\u63a8\u7406\u65f6\u4f18\u5316\u65b9\u6cd5\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u6216\u4e13\u95e8\u7684\u5b50\u4ee3\u7406\uff09\u96be\u4ee5\u6709\u6548\u89e3\u51b3\u5185\u5bb9\u56de\u9000\u548c\u7f16\u8f91\u4fdd\u6301\u95ee\u9898\uff0c\u8868\u660e\u8be5\u9886\u57df\u5c1a\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2601.13228", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13228", "abs": "https://arxiv.org/abs/2601.13228", "authors": ["Tianqi Du", "Lizhe Fang", "Weijie Yang", "Chenheng Zhang", "Zeming Wei", "Yifei Wang", "Yisen Wang"], "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation", "comment": null, "summary": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.", "AI": {"tldr": "A3\u6a21\u578b\u878d\u5408\u81ea\u56de\u5f52\u548c\u6269\u6563\u6a21\u578b\u4f18\u52bf\uff0c\u5b9e\u73b0\u7075\u6d3b\u9ad8\u6548\u7684\u4efb\u610f\u987a\u5e8f\u8bed\u8a00\u751f\u6210\uff0c\u63d0\u5347\u751f\u6210\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u4f20\u7edf\u6269\u6563\u8bed\u8a00\u6a21\u578b\u867d\u7136\u7075\u6d3b\u652f\u6301\u4efb\u610f\u987a\u5e8f\u548c\u53cc\u5411\u751f\u6210\uff0c\u4f46\u5355\u6b65\u4f9d\u8d56\u9650\u5236\u4e86\u5efa\u6a21\u6df1\u5ea6\uff0c\u5bfc\u81f4\u751f\u6210\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u4e0d\u5982\u81ea\u56de\u5f52\u6a21\u578b\u3002", "method": "\u901a\u8fc7\u4e24\u6d41\u6ce8\u610f\u529b\u7ed3\u6784\u548c\u6e10\u8fdb\u9002\u5e94\u7b56\u7565\uff0c\u5c06\u9884\u8bad\u7ec3\u81ea\u56de\u5f52\u6a21\u578b\u8f6c\u5411\u4efb\u610f\u987a\u5e8f\u9884\u6d4b\uff0c\u5b9e\u73b0A3\u6a21\u578b\u7684\u591a\u7ec4\u9884\u6d4b\u8fc7\u7a0b\u3002", "result": "\u5728\u95ee\u7b54\u3001\u5e38\u8bc6\u63a8\u7406\u548c\u6545\u4e8b\u586b\u5145\u4efb\u52a1\u4e0a\uff0cA3\u6a21\u578b\u4f18\u4e8e\u57fa\u4e8e\u6269\u6563\u7684\u6a21\u578b\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u89e3\u7801\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684A3\u6a21\u578b\u5b9e\u73b0\u4e86\u4efb\u610f\u987a\u5e8f\u4efb\u610f\u5b50\u96c6\u7684\u81ea\u56de\u5f52\u5efa\u6a21\uff0c\u517c\u5177\u81ea\u56de\u5f52\u6a21\u578b\u7684\u591a\u5c42\u4f9d\u8d56\u4f18\u52bf\u548c\u6269\u6563\u6a21\u578b\u7684\u7075\u6d3b\u6027\uff0c\u63d0\u5347\u4e86\u6837\u672c\u8d28\u91cf\u548c\u751f\u6210\u7a33\u5b9a\u6027\u3002"}}
{"id": "2601.13247", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13247", "abs": "https://arxiv.org/abs/2601.13247", "authors": ["Baochang Ren", "Yunzhi Yao", "Rui Sun", "Shuofei Qiao", "Ningyu Zhang", "Huajun Chen"], "title": "Aligning Agentic World Models via Knowledgeable Experience Learning", "comment": "Ongoing work", "summary": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.", "AI": {"tldr": "WorldMind\u5229\u7528\u73af\u5883\u53cd\u9988\u6784\u5efa\u7b26\u53f7\u5316\u4e16\u754c\u77e5\u8bc6\u5e93\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u7269\u7406\u89c4\u5219\u7684\u7406\u89e3\u548c\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u8868\u73b0\u51fa\u4f18\u8d8a\u7684\u8de8\u73af\u5883\u8fc1\u79fb\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u8bed\u4e49\u77e5\u8bc6\u4e30\u5bcc\uff0c\u4f46\u7f3a\u4e4f\u7269\u7406\u4e16\u754c\u7684\u7a0b\u5e8f\u6027\u57fa\u7840\uff0c\u5bfc\u81f4\u4ea7\u751f\u903b\u8f91\u5408\u7406\u4f46\u7269\u7406\u4e0d\u53ef\u6267\u884c\u7684\u8ba1\u5212\uff0c\u4f20\u7edf\u901a\u8fc7\u8bad\u7ec3\u6216\u5fae\u8c03\u7684\u5bf9\u9f50\u7b56\u7565\u6210\u672c\u9ad8\u4e14\u9002\u5e94\u6027\u5dee\u3002", "method": "\u901a\u8fc7\u878d\u5408\u73af\u5883\u53cd\u9988\uff0cWorldMind\u6574\u5408\u8fc7\u7a0b\u7ecf\u9a8c\u4ee5\u901a\u8fc7\u9884\u6d4b\u8bef\u5dee\u4fdd\u8bc1\u7269\u7406\u53ef\u884c\u6027\uff0c\u5e76\u5229\u7528\u76ee\u6807\u7ecf\u9a8c\u5f15\u5bfc\u4efb\u52a1\u6700\u4f18\u8f68\u8ff9\uff0c\u6784\u5efa\u7b26\u53f7\u4e16\u754c\u77e5\u8bc6\u5e93\u3002", "result": "\u5728EB-ALFRED\u548cEB-Habitat\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cWorldMind\u5728\u8de8\u6a21\u578b\u548c\u8de8\u73af\u5883\u7684\u8fc1\u79fb\u80fd\u529b\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u4efb\u52a1\u6267\u884c\u6027\u80fd\u3002", "conclusion": "WorldMind\u6846\u67b6\u901a\u8fc7\u81ea\u4e3b\u6784\u5efa\u7b26\u53f7\u5316\u7684\u4e16\u754c\u77e5\u8bc6\u5e93\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u4e16\u754c\u89c4\u5219\u9075\u5b88\u4e0a\u7684\u4e0d\u8db3\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7269\u7406\u53ef\u6267\u884c\u6027\u548c\u4efb\u52a1\u5b8c\u6210\u5ea6\u3002"}}
{"id": "2601.13251", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13251", "abs": "https://arxiv.org/abs/2601.13251", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph", "comment": null, "summary": "Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u8bed\u4e49\u805a\u7c7b\u7cfb\u7edf\uff0c\u901a\u8fc7\u65b0\u6807\u6ce8\u6570\u636e\u3001\u4e09\u5206\u7c7b\u5224\u522b\u5668\u548c\u521b\u65b0\u805a\u7c7b\u7b97\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u795e\u7ecf\u5d4c\u5165\u65e0\u6cd5\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u8bed\u4e49\u641c\u7d22\u4e0e\u751f\u6210\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u795e\u7ecf\u5d4c\u5165\u6a21\u578b\u96be\u4ee5\u533a\u5206\u540c\u4e49\u8bcd\u4e0e\u53cd\u4e49\u8bcd\uff0c\u4f20\u7edf\u76f8\u4f3c\u5ea6\u9608\u503c\u65e0\u6cd5\u6709\u6548\u963b\u6b62\u53cd\u4e49\u8bcd\u88ab\u9519\u8bef\u805a\u5408\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u6709\u6548\u7684\u8bed\u4e49\u805a\u7c7b\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b843,000\u5bf9\u6982\u5ff5\u7684\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e09\u5206\u7c7b\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\uff0c\u4e14\u8bbe\u8ba1\u4e86\u65b0\u9896\u7684\u8f6f\u786c\u7ed3\u5408\u805a\u7c7b\u7b97\u6cd5\uff0c\u901a\u8fc7\u62d3\u6251\u611f\u77e5\u7684\u6269\u5c55-\u526a\u679d\u6d41\u7a0b\u4fdd\u8bc1\u805a\u7c7b\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u9632\u6b62\u8bed\u4e49\u6f02\u79fb\u3002", "result": "\u5904\u7406\u4e861500\u4e07\u4e2a\u8bcd\u9879\uff0c\u8bc4\u4f30\u4e865.2\u4ebf\u4e2a\u6f5c\u5728\u5173\u7cfb\uff0c\u751f\u6210\u4e86290\u4e07\u4e2a\u9ad8\u7cbe\u5ea6\u8bed\u4e49\u805a\u7c7b\uff0c\u8bed\u4e49\u5173\u7cfb\u5224\u522b\u5668\u8fbe\u523090%\u5b8f\u89c2F1\u5206\u6570\u3002\u8be5\u8d44\u6e90\u4fc3\u8fdb\u4e86\u5f62\u6001\u4e30\u5bcc\u53ca\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u4e49\u641c\u7d22\u548c\u589e\u5f3a\u751f\u6210\u3002", "conclusion": "\u8be5\u7cfb\u7edf\u6210\u529f\u89e3\u51b3\u4e86\u795e\u7ecf\u5d4c\u5165\u6a21\u578b\u96be\u4ee5\u533a\u5206\u540c\u4e49\u8bcd\u548c\u53cd\u4e49\u8bcd\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u8bed\u4e49\u805a\u7c7b\u3002"}}
{"id": "2601.13253", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13253", "abs": "https://arxiv.org/abs/2601.13253", "authors": ["Ebubekir Tosun", "Mehmet Emin Buldur", "\u00d6zay Ezerceli", "Mahmoud ElHussieni"], "title": "A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus", "comment": null, "summary": "We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u8bcd\u5411\u91cf\u805a\u7c7b\u3001\u81ea\u52a8\u5206\u7c7b\u548c\u8bcd\u5178\u878d\u5408\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u6210\u529f\u6784\u5efa\u51fa\u571f\u8033\u5176\u8bed\u5927\u89c4\u6a21\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u6570\u636e\u89c4\u6a21\u548c\u8d28\u91cf\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u89e3\u51b3\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00NLP\u6570\u636e\u7a00\u7f3a\u7684\u95ee\u9898\u3002", "motivation": "\u571f\u8033\u5176\u8bed\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u5927\u89c4\u6a21\u8bed\u4e49\u5173\u7cfb\u6570\u636e\uff0c\u9650\u5236\u4e86\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u6548\u679c\u3002", "method": "\u7ed3\u5408FastText\u8bcd\u5411\u91cf\u53ca\u5c42\u6b21\u805a\u7c7b\u8bc6\u522b\u8bed\u4e49\u7c07\uff0c\u4f7f\u7528Gemini 2.5-Flash\u81ea\u52a8\u5206\u7c7b\u8bed\u4e49\u5173\u7cfb\uff0c\u5e76\u878d\u5408\u4eba\u5de5\u6574\u7406\u8bcd\u5178\u6570\u636e\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b843,000\u4e2a\u571f\u8033\u5176\u8bed\u72ec\u7279\u8bed\u4e49\u5bf9\uff08\u540c\u4e49\u8bcd\u3001\u53cd\u4e49\u8bcd\u3001\u5171\u4e0a\u4f4d\u8bcd\uff09\u7684\u6570\u636e\u96c6\uff0c\u89c4\u6a21\u6bd4\u73b0\u6709\u8d44\u6e90\u63d0\u534710\u500d\uff0c\u6210\u672c\u4ec565\u7f8e\u5143\uff0c\u6a21\u578b\u5728\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\u4e2d\u5747\u8fbe90%\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u4f4e\u8d44\u6e90\u8bed\u8a00\u5927\u89c4\u6a21\u8bed\u4e49\u5173\u7cfb\u6570\u636e\u6784\u5efa\u7684\u6709\u6548\u3001\u4f4e\u6210\u672c\u65b9\u6848\uff0c\u663e\u8457\u7f13\u89e3\u4e86\u6570\u636e\u532e\u4e4f\u95ee\u9898\uff0c\u4e14\u5177\u5907\u63a8\u5e7f\u5230\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13260", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13260", "abs": "https://arxiv.org/abs/2601.13260", "authors": ["Sawsan Alqahtani", "Mir Tafseer Nayeem", "Md Tahmid Rahman Laskar", "Tasnim Mohiuddin", "M Saiful Bari"], "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models", "comment": "Accepted to EACL 2026 (long, main). The first two authors contributed equally", "summary": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.", "AI": {"tldr": "\u672c\u6587\u5f3a\u8c03\u5206\u8bcd\u5e94\u4f5c\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u51b3\u7b56\uff0c\u63d0\u51fa\u7ed3\u5408\u4e0a\u4e0b\u6587\u7684\u5206\u8bcd\u4e0e\u6a21\u578b\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\uff0c\u63d0\u5347\u6a21\u578b\u516c\u5e73\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u4e3b\u6d41\u7684\u5b50\u8bcd\u5206\u8bcd\u65b9\u6cd5\u5982BPE\u867d\u5177\u53ef\u6269\u5c55\u6027\uff0c\u4f46\u5b58\u5728\u4e0e\u8bed\u8a00\u7ed3\u6784\u4e0d\u5bf9\u9f50\u3001\u52a0\u5267\u504f\u89c1\u53ca\u8d44\u6e90\u6d6a\u8d39\u7b49\u95ee\u9898\uff0c\u5206\u8bcd\u4ecd\u7f3a\u4e4f\u7406\u8bba\u6307\u5bfc\u548c\u4e00\u81f4\u8bbe\u8ba1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u6846\u67b6\uff0c\u5c06\u5206\u8bcd\u5668\u4e0e\u6a21\u578b\u534f\u540c\u8bbe\u8ba1\uff0c\u5e76\u7ed3\u5408\u8bed\u8a00\u5b66\u3001\u9886\u57df\u548c\u90e8\u7f72\u9700\u6c42\u8fdb\u884c\u6307\u5bfc\u3002", "result": "\u901a\u8fc7\u6807\u51c6\u5316\u8bc4\u4f30\u548c\u900f\u660e\u62a5\u544a\uff0c\u4f7f\u5206\u8bcd\u9009\u62e9\u66f4\u5177\u8d23\u4efb\u611f\u548c\u53ef\u6bd4\u6027\uff0c\u63a8\u52a8\u8bed\u8a00\u6280\u672f\u7684\u6539\u8fdb\u3002", "conclusion": "\u5c06\u5206\u8bcd\u89c6\u4e3a\u6838\u5fc3\u8bbe\u8ba1\u95ee\u9898\u800c\u975e\u7b80\u5355\u7684\u9884\u5904\u7406\u6b65\u9aa4\uff0c\u53ef\u4ee5\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u516c\u5e73\u6027\u3001\u6548\u7387\u548c\u9002\u5e94\u6027\u3002"}}
{"id": "2601.13264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13264", "abs": "https://arxiv.org/abs/2601.13264", "authors": ["Tyler Lizzo", "Larry Heck"], "title": "Unlearning in LLMs: Methods, Evaluation, and Open Challenges", "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\u53ca\u8bc4\u4f30\u4f53\u7cfb\uff0c\u63a2\u8ba8\u5176\u9762\u4e34\u7684\u6311\u6218\uff0c\u65e8\u5728\u63a8\u52a8\u53ef\u9760\u4e14\u8d1f\u8d23\u7684\u9057\u5fd8\u6280\u672f\u7684\u53d1\u5c55\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u6570\u636e\u9690\u79c1\u548c\u6a21\u578b\u5b89\u5168\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u673a\u5668\u9057\u5fd8\u6280\u672f\u88ab\u63d0\u51fa\u4ee5\u9009\u62e9\u6027\u79fb\u9664\u6a21\u578b\u4e2d\u654f\u611f\u6216\u4e0d\u9700\u8981\u7684\u4fe1\u606f\uff0c\u907f\u514d\u5b8c\u5168\u91cd\u65b0\u8bad\u7ec3\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u68b3\u7406\u73b0\u6709\u673a\u5668\u9057\u5fd8\u65b9\u6cd5\uff0c\u6839\u636e\u5173\u6ce8\u70b9\u5206\u4e3a\u6570\u636e\u4e2d\u5fc3\u3001\u53c2\u6570\u4e2d\u5fc3\u3001\u67b6\u6784\u4e2d\u5fc3\u3001\u6df7\u5408\u53ca\u5176\u4ed6\u7b56\u7565\uff0c\u5e76\u603b\u7ed3\u76f8\u5173\u8bc4\u4f30\u4f53\u7cfb\uff0c\u5305\u62ec\u57fa\u51c6\u6d4b\u8bd5\u3001\u6307\u6807\u548c\u6570\u636e\u96c6\u3002", "result": "\u672c\u6587\u603b\u7ed3\u4e86\u73b0\u6709\u673a\u5668\u9057\u5fd8\u6280\u672f\u7684\u5206\u7c7b\u548c\u6027\u80fd\u8bc4\u4f30\u4f53\u7cfb\uff0c\u63ed\u793a\u4e86\u6548\u7387\u3001\u5f62\u5f0f\u4fdd\u969c\u3001\u591a\u8bed\u8a00\u548c\u591a\u6a21\u6001\u9057\u5fd8\u4ee5\u53ca\u5bf9\u6297\u6027\u91cd\u5b66\u7b49\u5173\u952e\u96be\u9898\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002", "conclusion": "\u672c\u6587\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u673a\u5668\u9057\u5fd8\u6280\u672f\u7684\u53d1\u5c55\u73b0\u72b6\uff0c\u5f3a\u8c03\u4e86\u5176\u5728\u9690\u79c1\u4fdd\u62a4\u3001\u7248\u6743\u3001\u5b89\u5168\u548c\u504f\u89c1\u7b49\u65b9\u9762\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u8be5\u9886\u57df\u7684\u82e5\u5e72\u5173\u952e\u6311\u6218\u3002"}}
{"id": "2601.13288", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13288", "abs": "https://arxiv.org/abs/2601.13288", "authors": ["Gonzalo Ariel Meyoyan", "Luciano Del Corro"], "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification", "comment": null, "summary": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.", "AI": {"tldr": "\u901a\u8fc7\u5728\u5927\u8bed\u8a00\u6a21\u578b\u9690\u85cf\u5c42\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u63a2\u9488\uff0c\u5b9e\u73b0\u5b89\u5168\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u51cf\u5c11\u5ef6\u8fdf\u548c\u663e\u5b58\u6d88\u8017\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u5927\u6a21\u578b\u751f\u4ea7\u7cfb\u7edf\u4e2d\uff0c\u5b89\u5168\u53ca\u5206\u7c7b\u6b65\u9aa4\u901a\u5e38\u4f7f\u7528\u72ec\u7acb\u6a21\u578b\uff0c\u5bfc\u81f4\u5ef6\u8fdf\u3001\u663e\u5b58\u548c\u64cd\u4f5c\u590d\u6742\u5ea6\u589e\u52a0\u3002\u672c\u6587\u901a\u8fc7\u91cd\u7528\u751f\u6210\u6a21\u578b\u8ba1\u7b97\uff0c\u51cf\u5c11\u5f00\u9500\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u9636\u6bb5\u805a\u5408\u5668\uff0c\u5206\u522b\u5bf9\u6bcf\u5c42\u7684token\u8fdb\u884c\u6c47\u603b\u548c\u8de8\u5c42\u805a\u5408\uff0c\u5f62\u6210\u5355\u4e00\u8868\u793a\u8fdb\u884c\u5206\u7c7b\u3002\u4f7f\u7528\u4e86\u76f4\u63a5\u6c60\u5316\u3001\u5f97\u5206\u6ce8\u610f\u529b\u95e8\u63a7\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u63a2\u9488\u7b49\u591a\u79cd\u5b9e\u73b0\u5f62\u5f0f\u3002", "result": "\u5728\u5b89\u5168\u548c\u60c5\u611f\u5206\u6790\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u63a2\u9488\u65b9\u6cd5\u4f18\u4e8e\u57fa\u4e8elogit\u91cd\u7528\u7684\u65b9\u6cd5\uff0c\u4e14\u5728\u6027\u80fd\u4e0a\u4e0e\u66f4\u5927\u89c4\u6a21\u4e13\u7528\u6a21\u578b\u7ade\u4e89\uff0c\u540c\u65f6\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u548c\u663e\u5b58\u9700\u6c42\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u5229\u7528\u8f7b\u91cf\u7ea7\u63a2\u9488\u5728\u751f\u6210\u6a21\u578b\u7684\u9690\u85cf\u72b6\u6001\u4e0a\u8fdb\u884c\u5206\u7c7b\u7684\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u5206\u7c7b\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u8fd1\u751f\u6210\u5ef6\u8fdf\uff0c\u907f\u514d\u4e86\u4f7f\u7528\u72ec\u7acb\u5b89\u5168\u6a21\u578b\u5e26\u6765\u7684\u989d\u5916\u663e\u5b58\u548c\u5ef6\u8fdf\u8d1f\u62c5\u3002"}}
{"id": "2601.13300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13300", "abs": "https://arxiv.org/abs/2601.13300", "authors": ["Yow-Fu Liou", "Yu-Chien Tang", "Yu-Hsiang Liu", "An-Zi Yen"], "title": "OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference", "comment": null, "summary": "Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86OI-Bench\u57fa\u51c6\uff0c\u901a\u8fc7\u6ce8\u5165\u8bef\u5bfc\u6027\u9009\u9879\u7cfb\u7edf\u68c0\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u9009\u9898\u754c\u9762\u7684\u9c81\u68d2\u6027\uff0c\u63ed\u793a\u5176\u8106\u5f31\u70b9\u5e76\u63a2\u8ba8\u7f13\u89e3\u7b56\u7565\u3002", "motivation": "\u7406\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u3001\u5c40\u9650\u53ca\u5176\u5728\u591a\u9009\u9898\u754c\u9762\u4e2d\u5bf9\u793e\u4ea4\u6697\u793a\u3001\u6307\u4ee4\u7b49\u4fe1\u53f7\u7684\u654f\u611f\u6027\uff0c\u63a8\u52a8\u6a21\u578b\u9c81\u68d2\u6027\u8bc4\u4ef7\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u9009\u9879\u6ce8\u5165\u65b9\u6cd5\uff0c\u5728\u591a\u9009\u9898\u4e2d\u52a0\u5165\u4e00\u4e2a\u542b\u8bef\u5bfc\u6027\u6307\u4ee4\u7684\u9009\u9879\uff0c\u901a\u8fc7\u6784\u5efa\u6db5\u76d6\u591a\u79cd\u6307\u4ee4\u7c7b\u578b\u76843,000\u9898\u57fa\u51c6\u5e93OI-Bench\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u572812\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u6d4b\u8bd5\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u6307\u4ee4\u5e72\u6270\u7684\u653b\u51fb\u6210\u529f\u7387\u8f83\u9ad8\uff0c\u884c\u4e3a\u53cd\u5e94\u591a\u6837\uff0c\u4e14\u901a\u8fc7\u63a8\u7406\u65f6\u63d0\u793a\u548c\u540e\u8bad\u7ec3\u8c03\u6574\u7b49\u7b56\u7565\u53ef\u7f13\u89e3\u90e8\u5206\u8106\u5f31\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u9009\u62e9\u9898\u754c\u9762\u4e2d\u5bb9\u6613\u53d7\u5230\u8bef\u5bfc\u6027\u6307\u4ee4\u7684\u5f71\u54cd\uff0c\u8868\u73b0\u51fa\u663e\u8457\u7684\u8106\u5f31\u6027\u4e14\u5404\u6a21\u578b\u9c81\u68d2\u6027\u5dee\u5f02\u8f83\u5927\u3002"}}
{"id": "2601.13317", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2601.13317", "abs": "https://arxiv.org/abs/2601.13317", "authors": ["Samantha Sudhoff", "Pranav Perumal", "Zhaoqing Wu", "Tunazzina Islam"], "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse", "comment": null, "summary": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.", "AI": {"tldr": "\u672c\u6587\u5bf9Meta\u4ed8\u8d39\u5e7f\u544a\u4e0eBluesky\u516c\u5171\u5e16\u5b50\u4e2d\u7684\u6c14\u5019\u8bdd\u8bed\u8fdb\u884c\u4e86\u6bd4\u8f83\u5206\u6790\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u8bc6\u522b\u548c\u6bd4\u8f83\u4e3b\u9898\uff0c\u63ed\u793a\u5e73\u53f0\u6fc0\u52b1\u5982\u4f55\u5f71\u54cd\u6c14\u5019\u4f20\u64ad\u3002", "motivation": "\u4e0d\u540c\u5e73\u53f0\u7684\u6c14\u5019\u4f20\u64ad\u73af\u5883\u5177\u6709\u4e0d\u540c\u7684\u6fc0\u52b1\u7ed3\u6784\uff0c\u73b0\u6709\u7814\u7a76\u5e38\u5355\u72ec\u5206\u6790\uff0c\u9650\u5236\u4e86\u533a\u5206\u673a\u6784\u4fe1\u606f\u548c\u516c\u4f17\u8868\u8fbe\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u89e3\u91ca\u7684\u7aef\u5230\u7aef\u4e3b\u9898\u53d1\u73b0\u4e0e\u5206\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u805a\u7c7b\u548c\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e3b\u9898\u6807\u7b7e\uff0c\u5e76\u901a\u8fc7\u591a\u79cd\u8bc4\u4ef7\u6807\u51c6\u9a8c\u8bc1\u4e3b\u9898\u8d28\u91cf\u3002", "result": "\u53d1\u73b0\u4ed8\u8d39\u5e7f\u544a\u4e0e\u516c\u5171\u5e16\u5b50\u5728\u6c14\u5019\u8bdd\u8bed\u4e2d\u7684\u4e3b\u9898\u8868\u73b0\u548c\u52a8\u6001\u53d8\u5316\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u5e76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u652f\u6301\u5f02\u6784\u4f20\u64ad\u73af\u5883\u4e0b\u6bd4\u8f83\u53d9\u4e8b\u5206\u6790\u7684\u6f5c\u529b\u3002", "conclusion": "\u4ed8\u8d39\u5e7f\u544a\u548c\u516c\u5171\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684\u6c14\u5019\u8bdd\u8bed\u5728\u4e3b\u9898\u7ed3\u6784\u3001\u7acb\u573a\u4e00\u81f4\u6027\u548c\u65f6\u95f4\u54cd\u5e94\u6027\u65b9\u9762\u5b58\u5728\u7cfb\u7edf\u6027\u5dee\u5f02\uff0c\u5e73\u53f0\u6fc0\u52b1\u673a\u5236\u663e\u8457\u5f71\u54cd\u6c14\u5019\u4f20\u64ad\u5185\u5bb9\u3002"}}
{"id": "2601.13319", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13319", "abs": "https://arxiv.org/abs/2601.13319", "authors": ["Peter Sullivan", "AbdelRahim Elmadany", "Alcides Alcoba Inciarte", "Muhammad Abdul-Mageed"], "title": "Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology", "comment": null, "summary": "Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u6570\u636e\u7684\u5f02\u8d28\u6027\uff0c\u63d0\u51fa\u4e86\u7edf\u4e00\u7684Arab Voices\u6846\u67b6\uff0c\u6574\u5408\u591a\u6570\u636e\u96c6\u548c\u591a\u65b9\u8a00\uff0c\u89c4\u8303\u5143\u6570\u636e\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u6807\u51c6\u5316\u548c\u53ef\u91cd\u590d\u7684\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u8bc6\u522b\u7814\u7a76\u3002", "motivation": "\u7531\u4e8e\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u6570\u636e\u5728\u591a\u65b9\u9762\u7684\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u8de8\u6570\u636e\u96c6\u6bd4\u8f83\u548c\u6a21\u578b\u8bc4\u4f30\u590d\u6742\uff0c\u9700\u8981\u4e00\u79cd\u6807\u51c6\u5316\u7684\u6846\u67b6\u6765\u51cf\u5c11\u788e\u7247\u5316\uff0c\u4fc3\u8fdb\u53ef\u91cd\u590d\u7684\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5bf9\u591a\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u6599\u5e93\u7684\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u8ba1\u7b97\u5206\u6790\uff0c\u5305\u62ec\u8bed\u8a00\u5b66\u201c\u65b9\u8a00\u7279\u5f81\u201d\u548c\u97f3\u9891\u8d28\u91cf\u7684\u5ba2\u89c2\u4ee3\u7406\u6307\u6807\uff0c\u63ed\u793a\u6570\u636e\u96c6\u4e4b\u95f4\u7684\u5f02\u8d28\u6027\u3002", "result": "\u63d0\u51fa\u4e86Arab Voices\uff0c\u4e00\u4e2a\u6db5\u76d631\u4e2a\u6570\u636e\u96c6\u300114\u79cd\u65b9\u8a00\u3001\u5177\u6709\u7edf\u4e00\u5143\u6570\u636e\u548c\u8bc4\u4f30\u5de5\u5177\u7684\u6807\u51c6\u5316\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u8bc6\u522b\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6b64\u6846\u67b6\u5bf9\u591a\u79cd\u5148\u8fdb\u7684ASR\u7cfb\u7edf\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5efa\u7acb\u4e86\u5f3a\u6709\u529b\u7684\u73b0\u4ee3\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u8bc6\u522b\u57fa\u7ebf\u3002", "conclusion": "\u8be5\u8bba\u6587\u6307\u51fa\u73b0\u6709\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u6570\u636e\u5728\u57df\u8986\u76d6\u3001\u65b9\u8a00\u6807\u6ce8\u548c\u5f55\u97f3\u6761\u4ef6\u65b9\u9762\u5b58\u5728\u8f83\u5927\u5dee\u5f02\uff0c\u5f3a\u8c03\u4e86\u7edf\u4e00\u63cf\u8ff0\u548c\u6807\u51c6\u5316\u8bc4\u4f30\u7684\u5fc5\u8981\u6027\u3002"}}
{"id": "2601.13328", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13328", "abs": "https://arxiv.org/abs/2601.13328", "authors": ["Geoffrey Churchill", "Steven Skiena"], "title": "Reducing Tokenization Premiums for Low-Resource Languages", "comment": null, "summary": "Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.", "AI": {"tldr": "\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5206\u8bcd\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u540e\u671f\u8bcd\u6c47\u5408\u5e76\u964d\u4f4e\u6210\u672c\u7684\u65b9\u6cd5\uff0c\u5728\u591a\u79cd\u8bed\u8a00\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u6548\u679c\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u76f8\u6bd4\u82f1\u8bed\u9700\u8981\u66f4\u591a\u5206\u8bcd\u4ee4\u724c\u6765\u7f16\u7801\u76f8\u540c\u8bed\u53e5\uff0c\u5bfc\u81f4API\u8c03\u7528\u548c\u80fd\u8017\u6210\u672c\u589e\u52a0\uff0c\u5f71\u54cd\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u5927\u5c0f\uff0c\u4e9f\u9700\u964d\u4f4e\u5206\u8bcd\u6210\u672c\u7684\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u4e86\u5341\u4e2a\u6d41\u884cLM\u7684\u5206\u8bcd\u5668\u8bbe\u8ba1\u4e0e\u8bed\u8a00\u5206\u8bcd\u6210\u672c\uff0c\u901a\u8fc7\u5411\u9884\u8bad\u7ec3\u6a21\u578b\u8bcd\u6c47\u8868\u4e2d\u540e\u671f\u6dfb\u52a0\u5408\u5e76\u7684\u591a\u5206\u8bcd\u5b57\u7b26\u5b9e\u73b0\u5206\u8bcd\u6210\u672c\u7684\u964d\u4f4e\uff0c\u5e76\u572812\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u3002", "result": "\u8be5\u65b9\u6cd5\u572812\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5e94\u7528\uff0c\u663e\u793a\u538b\u7f29\u540e\u7684\u8f93\u5165\u4e0e\u539f\u59cb\u8f93\u5165\u5728Llama 3.2 1B\u6a21\u578b\u4e2d\u4ea7\u751f\u7684\u6700\u540e\u9690\u72b6\u6001\u76f8\u4f3c\uff0c\u8bf4\u660e\u538b\u7f29\u5206\u8bcd\u6709\u6548\u4e14\u4e0d\u635f\u5bb3\u6a21\u578b\u5185\u8868\u5f81\u3002", "conclusion": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u73b0\u4ee3\u8bed\u8a00\u6a21\u578b\uff08LM\uff09\u4e2d\u4f4e\u8d44\u6e90\u8bed\u8a00\u76f8\u8f83\u4e8e\u82f1\u8bed\u5b58\u5728\u7684\u8f83\u9ad8\u5206\u8bcd\u6210\u672c\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u540e\u671f\u6dfb\u52a0\u8bcd\u6c47\u8868\u9879\u5408\u5e76\u591a\u5206\u8bcd\u5b57\u7b26\u4e3a\u5355\u4e00\u5206\u8bcd\u7684\u673a\u5236\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u5206\u8bcd\u6210\u672c\u3002"}}
{"id": "2601.13330", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13330", "abs": "https://arxiv.org/abs/2601.13330", "authors": ["Jamie Cummins", "Beth Clarke", "Ian Hussey", "Malte Elson"], "title": "RegCheck: A tool for automating comparisons between study registrations and papers", "comment": "15 pages, 1 figure", "summary": "Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.", "AI": {"tldr": "RegCheck\u662f\u4e00\u6b3e\u8f85\u52a9\u7814\u7a76\u6ce8\u518c\u4e0e\u8bba\u6587\u6bd4\u5bf9\u7684AI\u5de5\u5177\uff0c\u4fdd\u6301\u4eba\u5de5\u5224\u65ad\uff0c\u751f\u6210\u5171\u4eab\u62a5\u544a\uff0c\u52a9\u529b\u591a\u5b66\u79d1\u79d1\u5b66\u900f\u660e\u548c\u4e25\u8c28\u3002", "motivation": "\u7814\u7a76\u8868\u660e\uff0c\u5c3d\u7ba1\u7814\u7a76\u6ce8\u518c\u6709\u52a9\u4e8e\u79d1\u5b66\u7684\u900f\u660e\u6027\u548c\u4e25\u8c28\u6027\uff0c\u4f46\u8bb8\u591a\u7814\u7a76\u6ce8\u518c\u672a\u88ab\u6709\u6548\u68c0\u67e5\uff0c\u539f\u56e0\u662f\u4eba\u5de5\u6838\u5bf9\u5de5\u4f5c\u91cf\u5927\u4e14\u8017\u65f6\u3002", "method": "\u63d0\u51fa\u4e86RegCheck\uff0c\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u8f85\u52a9\u7684\u6a21\u5757\u5316\u5de5\u5177\uff0c\u7528\u4e8e\u5e2e\u52a9\u5404\u9886\u57df\u7814\u7a76\u8005\u3001\u5ba1\u6838\u4eba\u5458\u548c\u7f16\u8f91\u6bd4\u5bf9\u7814\u7a76\u6ce8\u518c\u548c\u5bf9\u5e94\u8bba\u6587\u3002\u5de5\u5177\u4fdd\u7559\u4eba\u5de5\u5224\u65ad\uff0c\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u5bf9\u6bd4\u5185\u5bb9\uff0c\u5e76\u5c55\u793a\u76f8\u5173\u6587\u672c\u8f85\u52a9\u4eba\u5de5\u5224\u65ad\u3002", "result": "RegCheck\u751f\u6210\u53ef\u5206\u4eab\u7684\u62a5\u544a\uff0c\u5e26\u6709\u552f\u4e00ID\uff0c\u65b9\u4fbf\u7528\u6237\u95f4\u5171\u4eab\u548c\u9a8c\u8bc1\u3002\u8be5\u5de5\u5177\u9002\u7528\u4e8e\u591a\u5b66\u79d1\u3001\u591a\u79cd\u6ce8\u518c\u548c\u53d1\u8868\u683c\u5f0f\u3002", "conclusion": "RegCheck\u901a\u8fc7\u7ed3\u5408\u4eba\u5de5\u667a\u80fd\u4e0e\u4eba\u5de5\u5224\u65ad\uff0c\u63d0\u5347\u4e86\u7814\u7a76\u6ce8\u518c\u548c\u53d1\u8868\u8bba\u6587\u6bd4\u5bf9\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u63a8\u52a8\u4e86\u53ef\u91cd\u590d\u6027\u79d1\u5b66\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13346", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13346", "abs": "https://arxiv.org/abs/2601.13346", "authors": ["Sang Yun Kwon", "AbdelRahim Elmadany", "Muhammad Abdul-Mageed"], "title": "AfroScope: A Framework for Studying the Linguistic Landscape of Africa", "comment": null, "summary": "Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.", "AI": {"tldr": "AfroScope\u6784\u5efa\u4e86\u6db5\u76d6713\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u91c7\u7528\u5c42\u6b21\u5206\u7c7b\u548c\u4e13\u95e8\u5d4c\u5165\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u7684\u51c6\u786e\u6027\u548c\u8303\u56f4\uff0c\u652f\u6301\u6570\u5b57\u6587\u672c\u4e2d\u7684\u975e\u6d32\u8bed\u8a00\u6d4b\u91cf\u3002", "motivation": "\u73b0\u6709\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u5de5\u4f5c\u652f\u6301\u7684\u8bed\u8a00\u6570\u91cf\u6709\u9650\u4e14\u96be\u4ee5\u533a\u5206\u76f8\u8fd1\u8bed\u8a00\u53d8\u4f53\uff0c\u4e9f\u9700\u4e00\u4e2a\u8986\u76d6\u66f4\u5e7f\u3001\u7cbe\u5ea6\u66f4\u9ad8\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5c42\u6b21\u5206\u7c7b\u65b9\u6cd5\u5e76\u5229\u7528\u4e13\u95e8\u7684Mirror-Serengeti\u5d4c\u5165\u6a21\u578b\uff0c\u9488\u5bf929\u79cd\u9ad8\u5ea6\u6df7\u6dc6\u6216\u5730\u7406\u90bb\u8fd1\u8bed\u8a00\u8fdb\u884c\u8bc6\u522b\uff0c\u6b64\u5916\u6784\u5efa\u5305\u542b713\u79cd\u975e\u6d32\u8bed\u8a00\u7684\u6570\u636e\u96c6\u548c\u4e00\u5957\u5f3a\u5927\u7684LID\u6a21\u578b\u3002", "result": "\u63a8\u51fa\u7684\u5c42\u6b21\u5206\u7c7b\u65b9\u6cd5\u5728\u9ad8\u5ea6\u6df7\u6dc6\u8bed\u8a00\u5b50\u96c6\u4e0a\u7684\u5b8fF1\u63d0\u9ad8\u4e864.55\uff0c\u76f8\u8f83\u57fa\u7840\u6a21\u578b\u8868\u73b0\u66f4\u4f73\uff1b\u5e76\u5206\u6790\u4e86\u8de8\u8bed\u8a00\u8fc1\u79fb\u548c\u9886\u57df\u5f71\u54cd\uff0c\u4e3a\u6784\u5efa\u9c81\u68d2\u7cfb\u7edf\u63d0\u4f9b\u6307\u5bfc\u3002", "conclusion": "AfroScope\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u975e\u6d32\u8bed\u8a00\u8bc6\u522b\u7684\u8986\u76d6\u8303\u56f4\u548c\u533a\u5206\u7ec6\u7c92\u5ea6\u8bed\u8a00\u53d8\u4f53\u7684\u80fd\u529b\uff0c\u6210\u4e3a\u975e\u6d32\u8bed\u8a00\u5927\u89c4\u6a21\u6570\u5b57\u6587\u672c\u6d4b\u91cf\u7684\u91cd\u8981\u6280\u672f\u57fa\u7840\u3002"}}
{"id": "2601.13359", "categories": ["cs.CL", "cs.CR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13359", "abs": "https://arxiv.org/abs/2601.13359", "authors": ["Asen Dotsinski", "Panagiotis Eustratiadis"], "title": "Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection", "comment": null, "summary": "As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce \"sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., \"Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7b80\u5355\u6613\u7528\u7684sockpuppetting\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u6a21\u578b\u8f93\u51fa\u524d\u63d2\u5165\u7279\u5b9a\u5e8f\u5217\uff0c\u5b9e\u73b0\u9ad8\u6548\u8d8a\u72f1\uff0c\u6311\u6218\u4e86\u5f00\u6e90\u5927\u6a21\u578b\u7684\u5b89\u5168\u9632\u62a4\u3002", "motivation": "\u968f\u7740\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u529b\u63d0\u5347\uff0c\u9632\u8303\u6076\u610f\u63d0\u793a\u548c\u7406\u89e3\u653b\u51fb\u9014\u5f84\u53d8\u5f97\u91cd\u8981\uff0c\u800c\u73b0\u6709\u8d8a\u72f1\u65b9\u6cd5\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5927\u4e14\u9700\u4e13\u4e1a\u77e5\u8bc6\u3002", "method": "\u5728\u6a21\u578b\u8f93\u51fa\u5f00\u59cb\u63d2\u5165\u63a5\u53d7\u5e8f\u5217\uff08\u5982\u201cSure, here is how to...\u201d\uff09\uff0c\u8ba9\u6a21\u578b\u5b8c\u6210\u54cd\u5e94\uff0c\u5b9e\u73b0\u5bf9\u5f00\u6e90\u5927\u6a21\u578b\u7684\u8d8a\u72f1\u653b\u51fb\u3002", "result": "sockpuppetting\u5728Qwen3-8B\u4e0a\u6bd4GCG\u63d0\u9ad8\u4e8680%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u5728Llama-3.1-8B\u4e0a\u7684\u6df7\u5408\u65b9\u6cd5\u63d0\u534764%\u653b\u51fb\u6210\u529f\u7387\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u4f4e\u6210\u672c\u3002", "conclusion": "sockpuppetting\u4f5c\u4e3a\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u65e0\u9700\u4f18\u5316\u548c\u4e13\u4e1a\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u653b\u51fb\u6210\u529f\u7387\uff0c\u8868\u660e\u5f00\u653e\u6743\u91cd\u5927\u6a21\u578b\u9700\u8981\u52a0\u5f3a\u5bf9\u8f93\u51fa\u524d\u7f00\u6ce8\u5165\u653b\u51fb\u7684\u9632\u5fa1\u3002"}}
{"id": "2601.13368", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13368", "abs": "https://arxiv.org/abs/2601.13368", "authors": ["Zhenjiang Mao", "Anirudhh Venkat"], "title": "Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models", "comment": null, "summary": "As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5229\u7528\u6b65\u9aa4\u95f4\u6ce8\u610f\u529b\u548c\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\u6539\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u5728\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u7b54\u9898\u7684\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5f53\u524d\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u5e94\u7528\u63a8\u7406\u6a21\u5757\u65f6\uff0c\u7f3a\u4e4f\u51c6\u786e\u8bc4\u4f30\u7b54\u6848\u4e0d\u786e\u5b9a\u6027\u7684\u65b9\u6cd5\uff0c\u5bb9\u6613\u5bfc\u81f4\u6574\u4f53\u7f6e\u4fe1\u5ea6\u8fc7\u9ad8\uff0c\u4ece\u800c\u5f15\u53d1\u8bef\u5bfc\u6216\u4e25\u91cd\u5e7b\u89c9\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6b65\u9aa4\u95f4\u6ce8\u610f\u529b\u673a\u5236\u5206\u6790\u6b65\u9aa4\u4e4b\u95f4\u8bed\u4e49\u5173\u8054\u7684\u65b0\u65b9\u6cd5\uff0c\u5e76\u5f15\u5165\u9690\u85cf\u7f6e\u4fe1\u5ea6\u673a\u5236\u4ee5\u4fdd\u7559\u5386\u53f2\u7f6e\u4fe1\u5ea6\u4fe1\u606f\uff0c\u7ed3\u5408\u9010\u6b65\u7f6e\u4fe1\u5ea6\u7ed9\u51fa\u66f4\u51c6\u786e\u7684\u6574\u4f53\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "result": "\u5728GAOKAO\u6570\u5b66\u57fa\u51c6\u548cCLadder\u56e0\u679c\u63a8\u7406\u6570\u636e\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u5728\u8d1f\u5bf9\u6570\u4f3c\u7136\u548c\u671f\u671b\u6821\u51c6\u8bef\u5dee\u7b49\u6307\u6807\u4e0a\u8868\u73b0\u66f4\u4f18\uff0c\u5e73\u8861\u4e86\u9884\u6d4b\u8d28\u91cf\u4e0e\u6821\u51c6\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u63a8\u7406\u7b54\u6848\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u7cbe\u5ea6\uff0c\u6709\u52a9\u4e8e\u51cf\u5c11\u8bef\u5bfc\u548c\u5e7b\u89c9\u73b0\u8c61\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2601.13387", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13387", "abs": "https://arxiv.org/abs/2601.13387", "authors": ["Zhenjiang Mao", "Anirudhh Venkat", "Artem Bisliouk", "Akshat Kothiyal", "Sindhura Kumbakonam Subramanian", "Saithej Singhu", "Ivan Ruchkin"], "title": "Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning", "comment": null, "summary": "Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\u63cf\u8ff0\u5927\u8bed\u8a00\u6a21\u578b\u9010\u6b65\u7f6e\u4fe1\u4fe1\u53f7\uff0c\u6316\u6398\u52a8\u6001\u7f6e\u4fe1\u6a21\u5f0f\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u66f4\u51c6\u786e\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u7f6e\u4fe1\u5ea6\u7684\u6821\u51c6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u591a\u5c06\u6574\u4e2a\u63a8\u7406\u8fc7\u7a0b\u538b\u7f29\u4e3a\u4e00\u4e2a\u6807\u91cf\u5206\u503c\uff0c\u5ffd\u89c6\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7f6e\u4fe1\u5ea6\u7684\u52a8\u6001\u53d8\u5316\uff0c\u5bfc\u81f4\u5bf9\u56de\u7b54\u957f\u5ea6\u3001\u5197\u957f\u5ea6\u654f\u611f\uff0c\u96be\u4ee5\u51c6\u786e\u5224\u65ad\u7f6e\u4fe1\u9519\u8bef\u7684\u63a8\u7406\u3002", "method": "\u91c7\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91(STL)\u63cf\u8ff0\u9010\u6b65\u7f6e\u4fe1\u4fe1\u53f7\uff0c\u901a\u8fc7\u5224\u522b\u6027STL\u89c4\u5219\u6316\u6398\u533a\u5206\u6b63\u786e\u548c\u9519\u8bef\u56de\u7b54\u7684\u7f6e\u4fe1\u6a21\u5f0f\uff0c\u5e76\u5229\u7528\u53c2\u6570\u8d85\u7f51\u7edc\u8c03\u6574STL\u6a21\u578b\u53c2\u6570\uff0c\u5b9e\u73b0\u66f4\u52a0\u7cbe\u786e\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "result": "\u6240\u63d0\u51fa\u7684STL\u57fa\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u5728\u591a\u4e2a\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u6bd4\u57fa\u7ebf\u6a21\u578b\u66f4\u4f18\u7684\u6821\u51c6\u6548\u679c\uff0c\u4e14\u53d1\u73b0STL\u6a21\u5f0f\u5177\u6709\u4efb\u52a1\u95f4\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53c2\u6570\u5bf9\u4e2a\u522b\u95ee\u9898\u8868\u73b0\u51fa\u654f\u611f\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u57fa\u4e8e\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u7684\u9010\u6b65\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u591a\u6b65\u9aa4\u63a8\u7406\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u80fd\u529b\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u65b9\u6cd5\u66f4\u80fd\u533a\u5206\u6b63\u786e\u63a8\u7406\u4e0e\u9519\u8bef\u9648\u8ff0\u7684\u7f6e\u4fe1\u5dee\u5f02\u3002"}}
{"id": "2601.13388", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13388", "abs": "https://arxiv.org/abs/2601.13388", "authors": ["Sasha Ronaghi", "Prerit Choudhary", "David H Rehkopf", "Bryant Lin"], "title": "Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction", "comment": "7 pages, 5 figures", "summary": "Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.", "AI": {"tldr": "\u7814\u7a76\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u975e\u7ed3\u6784\u5316\u60a3\u8005\u8bbf\u8c08\u4e2d\u63d0\u53d6\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\uff0c\u7ed3\u6784\u5316\u6570\u636e\u4e0e\u4f20\u7edf\u751f\u7269\u6307\u6807\u7ed3\u5408\u7528\u4e8e\u7cd6\u5c3f\u75c5\u98ce\u9669\u9884\u6d4b\uff0c\u8fbe\u5230\u8f83\u597d\u6548\u679c\uff0cLLMs\u8fd8\u80fd\u76f4\u63a5\u9884\u6d4b\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\uff0c\u63d0\u5347\u4e34\u5e8a\u98ce\u9669\u8bc4\u4f30\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u53ca\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u4e2d\u7f3a\u5c11\u4e2a\u4f53\u5c42\u9762\u7684\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\u6570\u636e\uff0c\u800c\u73b0\u6709\u7ed3\u6784\u5316\u7b5b\u67e5\u5de5\u5177\u4e0d\u80fd\u5145\u5206\u6355\u6349\u60a3\u8005\u590d\u6742\u7684\u751f\u6d3b\u7ecf\u5386\u548c\u4e2a\u4f53\u5dee\u5f02\u3002\u5229\u7528LLMs\u5904\u7406\u975e\u7ed3\u6784\u5316\u8bbf\u8c08\u6587\u672c\uff0c\u6709\u671b\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u9ad8\u7cd6\u5c3f\u75c5\u7ba1\u7406\u548c\u98ce\u9669\u9884\u6d4b\u7684\u7cbe\u786e\u5ea6\u3002", "method": "\u672c\u7814\u7a76\u6536\u96c6\u4e8665\u540d65\u5c81\u53ca\u4ee5\u4e0a2\u578b\u7cd6\u5c3f\u75c5\u60a3\u8005\u7684\u975e\u7ed3\u6784\u5316\u751f\u6d3b\u8bbf\u8c08\u6587\u672c\uff0c\u5229\u7528LLMs\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6280\u672f\uff0c\u63d0\u53d6\u5b9a\u6027\u603b\u7ed3\u4e0e\u7ed3\u6784\u5316\u7684SDOH\u8bc4\u5206\uff0c\u5e76\u5c06\u8fd9\u4e9b\u8bc4\u5206\u4e0e\u4f20\u7edf\u751f\u7269\u6807\u5fd7\u7269\u4e00\u8d77\u7528\u4e8e\u591a\u79cd\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff08\u5cad\u56de\u5f52\u3001\u5957\u7d22\u56de\u5f52\u3001\u968f\u673a\u68ee\u6797\u548cXGBoost\uff09\u8fdb\u884c\u98ce\u9669\u9884\u6d4b\u3002\u6b64\u5916\uff0c\u8bc4\u4f30LLMs\u76f4\u63a5\u4ece\u8bbf\u8c08\u6587\u672c\u9884\u6d4b\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\u7684\u80fd\u529b\u3002", "result": "LLMs\u4ece\u8bbf\u8c08\u6587\u672c\u4e2d\u63d0\u53d6\u7684\u7ed3\u6784\u5316SDOH\u8bc4\u5206\u4e0e\u4f20\u7edf\u751f\u7269\u6807\u5fd7\u7269\u7ed3\u5408\u4f7f\u7528\uff0c\u63d0\u5347\u4e86\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u7684\u8868\u73b0\u3002\u540c\u65f6\uff0cLLMs\u5728\u65e0\u7cd6\u5316\u8840\u7ea2\u86cb\u767d\uff08A1C\uff09\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u4ee560%\u7684\u51c6\u786e\u7387\u9884\u6d4b\u60a3\u8005\u7684\u7cd6\u5c3f\u75c5\u63a7\u5236\u6c34\u5e73\uff0c\u5c55\u73b0\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u529b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u80fd\u591f\u6709\u6548\u5730\u5c06\u975e\u7ed3\u6784\u5316\u7684\u793e\u4f1a\u5065\u5eb7\u51b3\u5b9a\u56e0\u7d20\uff08SDOH\uff09\u6570\u636e\u8f6c\u5316\u4e3a\u7ed3\u6784\u5316\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7\u6b64\u65b9\u5f0f\u63d0\u5347\u7cd6\u5c3f\u75c5\u63a7\u5236\u98ce\u9669\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8865\u5145\u4f20\u7edf\u5b9e\u9a8c\u6307\u6807\u3002"}}
{"id": "2601.13392", "categories": ["cs.CL", "cs.AI", "cs.FL"], "pdf": "https://arxiv.org/pdf/2601.13392", "abs": "https://arxiv.org/abs/2601.13392", "authors": ["Shlok Shelat", "Jay Raval", "Souvik Roy", "Manas Gaur"], "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks", "comment": "30 pages, 11 figures, 6 tables, Work in Progress", "summary": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u751f\u6210\u683c\u5f0f\u6b63\u786e\u7684\u6709\u9650\u81ea\u52a8\u673a\uff0c\u4f46\u5728\u590d\u6742\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u8bed\u4e49\u7406\u89e3\u7f3a\u9677\uff0c\u9650\u5236\u4e86\u5176\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5f62\u5f0f\u8bed\u8a00\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u7684\u80cc\u540e\u539f\u56e0\uff0c\u5224\u65ad\u5176\u662f\u5426\u5177\u5907\u771f\u6b63\u7684\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4ec5\u4f9d\u8d56\u6a21\u5f0f\u5339\u914d\u3002", "method": "\u63d0\u51fa\u4e00\u4e2aDFA\u6784\u9020\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u77e5\u8bc6\u95ee\u7b54\u3001\u516c\u5f00\u6765\u6e90\u7684\u6784\u9020\u4efb\u52a1\u53ca\u4e24\u7c7b\u672a\u89c1\u8fc7\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u4e09\u9636\u6bb5\u63d0\u793a\u534f\u8bae\u53ca\u591a\u79cd\u63d0\u793a\u7b56\u7565\uff08\u76f4\u63a5\u63d0\u793a\u3001\u94fe\u5f0f\u601d\u7ef4\u3001\u6811\u5f0f\u601d\u7ef4\uff09\u5bf9\u5e94\u6a21\u578b\u8868\u73b0\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u6a21\u578b\u5728\u4e8b\u5b9e\u77e5\u8bc6\u548c\u5df2\u89c1\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u8f83\u9ad8\uff0c\u4f46\u5728\u672a\u89c1\u4efb\u52a1\u4e0a\u51c6\u786e\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u4e3b\u8981\u9519\u8bef\u5305\u62ec\u8bed\u8a00\u7ea6\u675f\u8bef\u89e3\u3001\u5bf9Kleene\u661f\u64cd\u4f5c\u7b26\u5904\u7406\u4e0d\u5f53\u53ca\u5168\u5c40\u4e00\u81f4\u6027\u7f3a\u5931\u3002\u591a\u79cd\u63d0\u793a\u7b56\u7565\u672a\u80fd\u6839\u672c\u89e3\u51b3\u8fd9\u4e9b\u9519\u8bef\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6b63\u5f0f\u8bed\u8a00\u4efb\u52a1\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u786e\u5b9a\u6027\u6709\u9650\u81ea\u52a8\u673a\uff08DFA\uff09\u6784\u9020\u7684\u4e25\u8083\u63a8\u7406\u4efb\u52a1\u4e0a\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u5c24\u5176\u662f\u5728\u672a\u89c1\u8fc7\u7684\u95ee\u9898\u4e2d\u8868\u73b0\u6025\u5267\u4e0b\u964d\uff0c\u66b4\u9732\u51fa\u6a21\u578b\u5728\u7b26\u53f7\u63a8\u7406\u548c\u8bed\u4e49\u7406\u89e3\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.13433", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13433", "abs": "https://arxiv.org/abs/2601.13433", "authors": ["Priyanka Mary Mammen", "Emil Joswin", "Shankar Venkitachalam"], "title": "Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models", "comment": null, "summary": "Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4e2d\u4f1a\u56e0\u6743\u5a01\u6765\u6e90\u7684\u9519\u8bef\u80cc\u4e66\u800c\u66f4\u6613\u51fa\u9519\uff0c\u4f46\u8be5\u6743\u5a01\u504f\u89c1\u53ef\u88ab\u8bc6\u522b\u548c\u7ea0\u6b63\uff0c\u63d0\u5347\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u63a2\u7a76\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u662f\u5426\u5b58\u5728\u57fa\u4e8e\u80cc\u4e66\u8005\u4e13\u4e1a\u6c34\u5e73\u7684\u7cfb\u7edf\u6027\u504f\u89c1\u3002", "method": "\u5728\u6570\u5b66\u3001\u6cd5\u5f8b\u548c\u533b\u5b66\u63a8\u7406\u76844\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528\u4ee3\u8868\u56db\u79cd\u4e13\u4e1a\u6c34\u5e73\u7684\u89d2\u8272\u8bbe\u7f6e\u5bf911\u4e2a\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5bf9\u80cc\u4e66\u8005\u4e13\u4e1a\u6c34\u5e73\u8d8a\u9ad8\u7684\u9519\u8bef\u4fe1\u606f\u8d8a\u6613\u53d7\u5f71\u54cd\uff0c\u8868\u73b0\u4e3a\u4e0d\u4ec5\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u8fd8\u5bf9\u9519\u8bef\u7b54\u6848\u7684\u7f6e\u4fe1\u5ea6\u63d0\u9ad8\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u6743\u5a01\u504f\u89c1\uff0c\u8be5\u504f\u89c1\u5185\u5728\u7f16\u7801\u5728\u6a21\u578b\u4e2d\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u8c03\u6574\u5f15\u5bfc\u6a21\u578b\u907f\u514d\u8be5\u504f\u89c1\uff0c\u4ece\u800c\u63d0\u9ad8\u5176\u5728\u4e13\u5bb6\u8bef\u5bfc\u60c5\u51b5\u4e0b\u7684\u8868\u73b0\u3002"}}
{"id": "2601.13437", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13437", "abs": "https://arxiv.org/abs/2601.13437", "authors": ["Adriana-Valentina Costache", "Daria-Nicoleta Dragomir", "Silviu-Florin Gheorghe", "Eduard Poesina", "Paul Irofti", "Radu Tudor Ionescu"], "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization", "comment": null, "summary": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u591a\u8bed\u8a00\u6587\u672c\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u57fa\u51c6MOSLD\uff0c\u5305\u542b12\u79cd\u8bed\u8a00\u7684960K\u6837\u672c\uff0c\u5e76\u8bbe\u8ba1\u591a\u9636\u6bb5\u6846\u67b6\u8fdb\u884c\u65b0\u7c7b\u522b\u53d1\u73b0\u548c\u5b66\u4e60\uff0c\u8bc4\u4f30\u591a\u6a21\u578b\u83b7\u5f97\u57fa\u51c6\u7ed3\u679c\uff0c\u63a8\u52a8\u6587\u672c\u9886\u57df\u7684\u5f00\u653e\u96c6\u7814\u7a76\u3002", "motivation": "\u9488\u5bf9\u6587\u672c\u9886\u57df\u4e2d\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\u4efb\u52a1\u7684\u7f3a\u4e4f\u7814\u7a76\u548c\u8d44\u6e90\uff0c\u672c\u6587\u65e8\u5728\u586b\u8865\u8be5\u7a7a\u767d\uff0c\u63d0\u5347\u6a21\u578b\u5bf9\u672a\u77e5\u7c7b\u522b\u7684\u8bc6\u522b\u4e0e\u5b66\u4e60\u80fd\u529b\u3002", "method": "\u672c\u6587\u901a\u8fc7\u91cd\u65b0\u6574\u7406\u73b0\u6709\u6570\u636e\u96c6\u548c\u91c7\u96c6\u65b0\u95fb\u9886\u57df\u65b0\u6837\u672c\uff0c\u6784\u5efa\u4e86\u8986\u76d612\u79cd\u8bed\u8a00\u7684960K\u6837\u672c\u7684\u591a\u8bed\u8a00\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u8bbe\u8ba1\u4e86\u4e00\u79cd\u591a\u9636\u6bb5\u6846\u67b6\uff0c\u7528\u4e8e\u6301\u7eed\u53d1\u73b0\u548c\u5b66\u4e60\u65b0\u7c7b\u522b\u3002", "result": "\u4f5c\u8005\u8bc4\u4f30\u4e86\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u62ec\u81ea\u5df1\u63d0\u51fa\u7684\u6a21\u578b\uff0c\u53d6\u5f97\u4e86\u4e00\u7ec4\u53ef\u4f9b\u672a\u6765\u7814\u7a76\u53c2\u8003\u7684\u57fa\u51c6\u7ed3\u679c\uff0c\u5e76\u516c\u5f00\u4e86\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u4e86\u591a\u8bed\u8a00\u5f00\u653e\u96c6\u5b66\u4e60\u4e0e\u53d1\u73b0\uff08MOSLD\uff09\u57fa\u51c6\uff0c\u4e3a\u6587\u672c\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u65b0\u7c7b\u522b\u53d1\u73b0\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u8bc4\u4ef7\u5e73\u53f0\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2601.13453", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.13453", "abs": "https://arxiv.org/abs/2601.13453", "authors": ["Aditya Thole", "Anmol Agrawal", "Arnav Ramamoorthy", "Dhruv Kumar"], "title": "PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving", "comment": null, "summary": "Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPSA\uff0c\u81ea\u52a8\u751f\u6210\u7269\u7406\u95ee\u9898\u89c6\u9891\u89e3\u91ca\uff0c\u867d\u5c55\u793a\u6f5c\u529b\u4f46\u5b58\u5728\u89c6\u89c9\u751f\u6210\u548c\u8bc4\u4f30\u74f6\u9888\uff0c\u5f3a\u8c03\u672a\u6765\u591a\u6a21\u6001\u6559\u80b2\u7cfb\u7edf\u9700\u5f3a\u5316\u89c6\u89c9\u7406\u89e3\u548c\u9a8c\u8bc1\u673a\u5236\u3002", "motivation": "\u6587\u672c\u57fa\u7684\u89e3\u7b54\u4e0d\u8db3\u4ee5\u5145\u5206\u89e3\u91ca\u6570\u503c\u7269\u7406\u95ee\u9898\uff0c\u89c6\u89c9\u63a8\u7406\u6709\u52a9\u4e8e\u63d0\u5347\u6982\u5ff5\u7406\u89e3\uff0c\u7136\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u9ad8\u8d28\u91cf\u957f\u89c6\u89c9\u89e3\u91ca\u65b9\u9762\u7684\u80fd\u529b\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86PhysicsSolutionAgent(PSA)\uff0c\u5229\u7528Manim\u52a8\u753b\u81ea\u52a8\u751f\u6210\u7269\u7406\u95ee\u9898\u89e3\u91ca\u89c6\u9891\uff0c\u5e76\u8bbe\u8ba1\u4e86\u5305\u62ec15\u4e2a\u5b9a\u91cf\u6307\u6807\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u53cd\u9988\u7684\u8bc4\u4f30\u6d41\u7a0b\u4ee5\u8fed\u4ee3\u63d0\u5347\u89c6\u9891\u8d28\u91cf\u3002", "result": "\u572832\u4e2a\u6570\u503c\u548c\u7406\u8bba\u7269\u7406\u95ee\u9898\u7684\u89c6\u9891\u6d4b\u8bd5\u4e2d\uff0cPSA\u4f7f\u7528GPT-5-mini\u5b9e\u73b0\u4e86100%\u89c6\u9891\u5b8c\u6210\u7387\uff0c\u5e73\u5747\u81ea\u52a8\u8bc4\u52063.8/5\uff0c\u4f46\u4eba\u7c7b\u68c0\u6d4b\u53d1\u73b0\u89c6\u89c9\u5e03\u5c40\u548c\u89c6\u89c9\u5185\u5bb9\u89e3\u91ca\u5b58\u5728\u9519\u8bef\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u63a8\u7406\u548c\u8bc4\u4f30\u7684\u5173\u952e\u6311\u6218\u3002", "conclusion": "PSA\u80fd\u591f\u81ea\u52a8\u751f\u6210\u957f\u8fbe\u516d\u5206\u949f\u7684\u7269\u7406\u95ee\u9898\u89e3\u91ca\u89c6\u9891\uff0c\u5c55\u793a\u4e86\u5728\u591a\u6a21\u6001\u6559\u80b2\u7cfb\u7edf\u4e2d\u89c6\u89c9\u89e3\u91ca\u7684\u6f5c\u529b\uff0c\u4f46\u4ecd\u5b58\u5728\u89c6\u89c9\u5e03\u5c40\u4e0d\u4e00\u81f4\u548c\u89c6\u89c9\u5185\u5bb9\u89e3\u91ca\u9519\u8bef\u7b49\u95ee\u9898\uff0c\u663e\u793a\u51fa\u751f\u6210\u9ad8\u8d28\u91cf\u89c6\u89c9\u89e3\u91ca\u7684\u6311\u6218\u3002"}}
{"id": "2601.13503", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13503", "abs": "https://arxiv.org/abs/2601.13503", "authors": ["Kyung Ho Lim", "Byung-Hoon Kim"], "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives", "comment": null, "summary": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.", "AI": {"tldr": "Anonpsy\u901a\u8fc7\u8bed\u4e49\u56fe\u5f15\u5bfc\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\uff0c\u5b9e\u73b0\u7cbe\u795e\u75c5\u53d9\u8ff0\u7ed3\u6784\u5316\u8131\u654f\uff0c\u6709\u6548\u4fdd\u62a4\u60a3\u8005\u9690\u79c1\u4e14\u4fdd\u7559\u4e34\u5e8a\u4fe1\u606f\u3002", "motivation": "\u7cbe\u795e\u75c5\u6848\u4f8b\u4e2d\u7684\u8eab\u4efd\u4fe1\u606f\u9690\u542b\u5728\u7ed3\u6784\u5316\u4e34\u5e8a\u8bed\u4e49\u4e2d\uff0c\u4f20\u7edf\u7eaf\u6587\u672c\u8131\u654f\u96be\u4ee5\u9009\u62e9\u6027\u4fdd\u7559\u5173\u952e\u8bed\u4e49\uff0c\u9700\u66f4\u7ec6\u7c92\u5ea6\u63a7\u5236\u7684\u8131\u654f\u65b9\u6cd5\u3002", "method": "Anonpsy\u5148\u5c06\u53d9\u8ff0\u8f6c\u5316\u4e3a\u7f16\u7801\u4e34\u5e8a\u5b9e\u4f53\u3001\u65f6\u95f4\u70b9\u548c\u5173\u7cfb\u7684\u8bed\u4e49\u56fe\uff0c\u8fdb\u884c\u56fe\u7ea6\u675f\u6270\u52a8\u4ee5\u4fee\u6539\u8eab\u4efd\u76f8\u5173\u5185\u5bb9\uff0c\u5e76\u5229\u7528\u56fe\u6761\u4ef6\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u8131\u654f\u6587\u672c\u3002", "result": "\u572890\u4e2a\u4e34\u5e8a\u75c5\u4f8b\u4e0a\uff0cAnonpsy\u5728\u4e13\u5bb6\u3001\u8bed\u4e49\u548cGPT-5\u8bc4\u4f30\u4e0b\u4fdd\u6301\u8bca\u65ad\u4e00\u81f4\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bed\u4e49\u76f8\u4f3c\u6027\u548c\u8eab\u4efd\u8bc6\u522b\u98ce\u9669\uff0c\u4f18\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5355\u7eaf\u91cd\u5199\u65b9\u6cd5\u3002", "conclusion": "\u533f\u540d\u7cbe\u795e\u75c5\u53d9\u8ff0\u4e2d\u7684\u8eab\u4efd\u4fe1\u606f\u901a\u8fc7\u663e\u5f0f\u6807\u8bc6\u7b26\u548c\u72ec\u7279\u7684\u751f\u6d3b\u4e8b\u4ef6\u4f53\u73b0\uff0c\u4f20\u7edf\u6587\u672c\u5c42\u9762\u8131\u654f\u65b9\u6cd5\u63a7\u5236\u6709\u9650\u3002Anonpsy\u901a\u8fc7\u56fe\u5f15\u5bfc\u7684\u8bed\u4e49\u91cd\u5199\u6709\u6548\u964d\u4f4e\u53ef\u8bc6\u522b\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u8bca\u65ad\u4fe1\u606f\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2601.13537", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13537", "abs": "https://arxiv.org/abs/2601.13537", "authors": ["Yerin Hwang", "Dongryeol Lee", "Taegwan Kang", "Minwoo Lee", "Kyomin Jung"], "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges", "comment": "4 pages", "summary": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u63d0\u793a\u8bed\u6846\u67b6\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u5224\u65ad\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u663e\u8457\u7684\u6846\u67b6\u504f\u89c1\uff0c\u5f3a\u8c03\u4e86\u5236\u5b9a\u8003\u8651\u6846\u67b6\u6548\u5e94\u7684\u8bc4\u4f30\u534f\u8bae\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u867d\u7136\u5df2\u77e5\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u56de\u7b54\u4f1a\u56e0\u63d0\u793a\u8bed\u63aa\u8f9e\u800c\u53d8\u5316\uff0c\u4f46\u5176\u5bf9\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5224\u65ad\u7a33\u5b9a\u6027\u548c\u516c\u6b63\u6027\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u56e0\u800c\u501f\u9274\u5fc3\u7406\u5b66\u4e2d\u7684\u6846\u67b6\u6548\u5e94\u8fdb\u884c\u63a2\u8ba8\u3002", "method": "\u8bbe\u8ba1\u5bf9\u79f0\u7684\u6b63\u8d1f\u8ff0\u8bed\u63d0\u793a\uff0c\u7cfb\u7edf\u7814\u7a76\u4e86\u63d0\u793a\u6846\u67b6\u5bf9\u6a21\u578b\u5224\u65ad\u7684\u5f71\u54cd\uff0c\u6db5\u76d6\u56db\u4e2a\u9ad8\u98ce\u9669\u8bc4\u4f30\u4efb\u52a1\uff0c\u5e76\u5bf914\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u53d1\u73b0\u4e0d\u540c\u6a21\u578b\u5bf9\u63d0\u793a\u6846\u67b6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u654f\u611f\u5ea6\uff0c\u6a21\u578b\u5bb6\u65cf\u95f4\u5728\u63a5\u53d7\u6216\u62d2\u7edd\u7684\u503e\u5411\u4e0a\u5b58\u5728\u660e\u663e\u5dee\u5f02\uff0c\u8868\u660e\u6846\u67b6\u504f\u89c1\u662f\u73b0\u6709LLM\u8bc4\u4f30\u7cfb\u7edf\u7684\u7ed3\u6784\u6027\u7279\u5f81\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u63d0\u793a\u8bed\u7684\u8bc4\u4f30\u4e2d\u5b58\u5728\u663e\u8457\u7684\u6846\u67b6\u504f\u89c1\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u5224\u65ad\u7a33\u5b9a\u6027\u548c\u5ba2\u89c2\u6027\u3002"}}
{"id": "2601.13547", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13547", "abs": "https://arxiv.org/abs/2601.13547", "authors": ["Yujia Hu", "Roy Ka-Wei Lee"], "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations", "comment": "EACL 2026 Main Conference", "summary": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.\n  \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHateXScore\u6307\u6807\u5957\u4ef6\uff0c\u8bc4\u4f30\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u6a21\u578b\u89e3\u91ca\u7684\u63a8\u7406\u8d28\u91cf\uff0c\u63d0\u5347\u5185\u5bb9\u5ba1\u67e5\u7684\u900f\u660e\u5ea6\u548c\u53ef\u4fe1\u5ea6\u3002", "motivation": "\u5f53\u524d\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u8bc4\u4f30\u4e3b\u8981\u4f9d\u8d56\u51c6\u786e\u7387\u548cF1\u7b49\u6307\u6807\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u5224\u5b9a\u7406\u7531\u7684\u8bc4\u4f30\uff0c\u5bfc\u81f4\u65e0\u6cd5\u6709\u6548\u7406\u89e3\u4e3a\u4f55\u6587\u672c\u88ab\u8ba4\u5b9a\u4e3a\u4ec7\u6068\u8a00\u8bba\u3002", "method": "\u8bbe\u8ba1\u5e76\u5f15\u5165HateXScore\uff0c\u8be5\u6307\u6807\u5305\u62ec\u7ed3\u8bba\u660e\u786e\u6027\u3001\u5f15\u7528\u7247\u6bb5\u7684\u5fe0\u5b9e\u6027\u548c\u56e0\u679c\u4f9d\u636e\u3001\u53d7\u4fdd\u62a4\u7fa4\u4f53\u8bc6\u522b\uff08\u53ef\u914d\u7f6e\u653f\u7b56\uff09\u4ee5\u53ca\u903b\u8f91\u4e00\u81f4\u6027\u56db\u4e2a\u90e8\u5206\uff1b\u5728\u516d\u4e2a\u591a\u6837\u7684\u4ec7\u6068\u8a00\u8bba\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "HateXScore\u80fd\u591f\u8bca\u65ad\u51fa\u6a21\u578b\u89e3\u91ca\u4e2d\u7684\u7f3a\u9677\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\uff0c\u8868\u73b0\u51fa\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff0c\u8bc1\u5b9e\u5176\u4f5c\u4e3a\u89e3\u91ca\u8d28\u91cf\u8bc4\u4ef7\u5de5\u5177\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "HateXScore\u4f5c\u4e3a\u4e00\u79cd\u56db\u6210\u5206\u6307\u6807\u5957\u4ef6\uff0c\u6709\u6548\u8bc4\u4f30\u4e86\u6a21\u578b\u89e3\u91ca\u4e2d\u63a8\u7406\u8d28\u91cf\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u6307\u6807\u65e0\u6cd5\u6355\u6349\u7684\u89e3\u91ca\u5931\u8d25\u548c\u6807\u6ce8\u4e0d\u4e00\u81f4\u95ee\u9898\uff0c\u4e14\u4e0e\u4eba\u5de5\u8bc4\u4f30\u9ad8\u5ea6\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u5176\u7528\u4e8e\u53ef\u4fe1\u900f\u660e\u5185\u5bb9\u5ba1\u67e5\u7684\u5b9e\u7528\u6027\u3002"}}
{"id": "2601.13575", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13575", "abs": "https://arxiv.org/abs/2601.13575", "authors": ["Thanh-Lam T. Nguyen", "Ngoc-Quang Le", "Quoc-Trung Phu", "Thi-Phuong Le", "Ngoc-Huyen Pham", "Phuong-Nguyen Nguyen", "Hoang-Quynh Le"], "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews", "comment": null, "summary": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.", "AI": {"tldr": "\u63d0\u51faSUDO\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u6570\u636e\u96c6\uff0c\u5305\u542b\u540c\u7528\u6237\u591a\u8bc4\u8bba\u6807\u6ce8\uff0c\u8bc4\u6d4b\u4f20\u7edf\u4e0e\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\uff0c\u7ed3\u679c\u663e\u793a\u4efb\u52a1\u96be\u5ea6\u8f83\u5927\uff0c\u6570\u636e\u96c6\u662f\u6709\u4ef7\u503c\u7684\u7814\u7a76\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u5de5\u4f5c\u4e3b\u8981\u5173\u6ce8\u663e\u5f0f\u6bd4\u8f83\u8868\u8fbe\uff0c\u4f46\u73b0\u5b9e\u8bc4\u8bba\u4e2d\u663e\u5f0f\u6bd4\u8f83\u8f83\u5c11\uff0c\u9690\u5f0f\u6bd4\u8f83\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u901a\u8fc7\u5206\u6790\u540c\u4e00\u7528\u6237\u7684\u591a\u6761\u8bc4\u8bba\u5b9e\u73b0\u504f\u597d\u63a8\u65ad\u3002", "method": "\u63d0\u51faSUDO\u6570\u636e\u96c6\uff0c\u5305\u542b4150\u5bf9\u6ce8\u91ca\u8bc4\u5ba1\u5bf9\uff0c\u91c7\u7528\u53cc\u5c42\u7ed3\u6784\u6355\u6349\u5c42\u9762\u63d0\u53ca\u548c\u6574\u4f53\u504f\u597d\u3002\u57fa\u4e8e\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u4e0e\u8bed\u8a00\u6a21\u578b\u4e24\u79cd\u57fa\u7ebf\u67b6\u6784\u8fdb\u884c\u4efb\u52a1\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u8bed\u8a00\u6a21\u578b\u57fa\u7ebf\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u6574\u4f53\u8868\u73b0\u4e2d\u7b49\uff0c\u8868\u660e\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u4efb\u52a1\u5177\u6709\u8f83\u5927\u6311\u6218\u3002", "conclusion": "SUDO\u6570\u636e\u96c6\u4e3a\u9690\u5f0f\u6bd4\u8f83\u89c2\u70b9\u6316\u6398\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\uff0c\u5c3d\u7ba1\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u4ecd\u6709\u9650\uff0c\u663e\u793a\u51fa\u4efb\u52a1\u7684\u6311\u6218\u6027\u3002"}}
{"id": "2601.13588", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13588", "abs": "https://arxiv.org/abs/2601.13588", "authors": ["Inho Won", "Hangyeol Yoo", "Minkyung Cho", "Jungyeul Park", "Hoyun Song", "KyungTae Lim"], "title": "TREX: Tokenizer Regression for Optimal Data Mixture", "comment": "Accepted to EACL 2026. Long Paper. (19 languages studied: Chinese, Greek, Japanese, etc.)", "summary": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTREX\uff0c\u4e00\u79cd\u57fa\u4e8e\u56de\u5f52\u7684\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u9884\u6d4b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u9ad8\u5206\u8bcd\u5668\u538b\u7f29\u6548\u7387\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u9ad8\u6210\u672c\u641c\u7d22\u3002", "motivation": "\u591a\u8bed\u8a00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5206\u8bcd\u5668\u6784\u5efa\u9700\u8981\u7cbe\u786e\u63a7\u5236\u8bed\u8a00\u7279\u5b9a\u7684\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\uff0c\u4ee5\u63d0\u5347\u8bad\u7ec3\u548c\u63a8\u7406\u6548\u7387\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u542f\u53d1\u5f0f\u6216\u9ad8\u6210\u672c\u7684\u5927\u89c4\u6a21\u641c\u7d22\uff0c\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u56de\u5f52\u7684\u9884\u6d4b\u6846\u67b6TREX\uff0c\u901a\u8fc7\u5728\u968f\u673a\u6570\u636e\u6df7\u5408\u4e0a\u8bad\u7ec3\u5c0f\u578b\u4ee3\u7406\u5206\u8bcd\u5668\uff0c\u6536\u96c6\u538b\u7f29\u6027\u80fd\u6570\u636e\uff0c\u5b66\u4e60\u9884\u6d4b\u4e0d\u540c\u6570\u636e\u6df7\u5408\u4e0b\u7684\u538b\u7f29\u6548\u679c\uff0c\u4ece\u800c\u9ad8\u6548\u641c\u7d22\u6700\u4f18\u6570\u636e\u6df7\u5408\u6bd4\u4f8b\u3002", "result": "\u4f7f\u7528TREX\u9884\u6d4b\u7684\u6700\u4f18\u6570\u636e\u6df7\u5408\u8bad\u7ec3\u7684\u5206\u8bcd\u5668\uff0c\u5728\u538b\u7f29\u6548\u7387\u4e0a\u8f83LLaMA3\u548c\u5747\u5300\u5206\u5e03\u6df7\u5408\u65b9\u6848\u63d0\u5347\u6700\u591a12%\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "TREX\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u8bed\u8a00\u5206\u8bcd\u5668\u8bbe\u8ba1\u4e2d\u7684\u51c6\u786e\u6027\u4e0e\u6210\u672c\u6743\u8861\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5206\u8bcd\u5668\u7684\u538b\u7f29\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u5177\u5907\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.13590", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13590", "abs": "https://arxiv.org/abs/2601.13590", "authors": ["Fan Huang", "Haewoon Kwak", "Jisun An"], "title": "Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u8bf4\u670d\u6781\u6613\u52a8\u6447\u4fe1\u5ff5\uff0c\u5143\u8ba4\u77e5\u63d0\u793a\u975e\u4f46\u65e0\u52a9\u9632\u62a4\u53cd\u800c\u52a0\u5267\u8106\u5f31\uff0c\u4e14\u73b0\u6709\u5bf9\u6297\u5fae\u8c03\u65b9\u6cd5\u6548\u679c\u56e0\u6a21\u578b\u5dee\u5f02\u663e\u8457\uff0c\u9700\u8fdb\u4e00\u6b65\u63a2\u7d22\u66f4\u53ef\u9760\u7684\u9632\u5fa1\u7b56\u7565\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u6613\u53d7\u8bf4\u670d\u91c7\u7eb3\u53cd\u4e8b\u5b9e\u4fe1\u5ff5\u7684\u95ee\u9898\uff0c\u8bc4\u4f30\u5176\u8106\u5f31\u6027\u53ca\u63d0\u5347\u9c81\u68d2\u6027\u7684\u53ef\u80fd\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u4f20\u8005-\u4fe1\u606f-\u6e20\u9053-\u63a5\u6536\u8005(SMCR)\u6846\u67b6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u4e94\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e09\u4e2a\u9886\u57df\u4e2d\u9762\u5bf9\u4e0d\u540c\u8bf4\u670d\u7b56\u7565\u7684\u53cd\u5e94\u53ca\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u4fe1\u5ff5\u7a33\u5b9a\u6027\uff0c\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u5143\u8ba4\u77e5\u63d0\u793a\u53ca\u5bf9\u6297\u5fae\u8c03\u7684\u9632\u5fa1\u6548\u679c\u3002", "result": "\u5c0f\u6a21\u578b\u8868\u73b0\u51fa\u8d85\u8fc780%\u7684\u4fe1\u5ff5\u53d8\u66f4\u96c6\u4e2d\u5728\u9996\u8f6e\u8bf4\u670d\uff0c\u5143\u8ba4\u77e5\u63d0\u793a\u5bfc\u81f4\u4fe1\u5ff5\u66f4\u5feb\u88ab\u4fb5\u8680\uff0c\u9632\u5fa1\u5fae\u8c03\u4f7fGPT-4o-mini\u51e0\u4e4e\u5b8c\u5168\u9c81\u68d2\uff0cMistral 7B\u663e\u8457\u63d0\u5347\uff0c\u4f46Llama\u6a21\u578b\u4f9d\u7136\u9ad8\u5ea6\u6613\u53d7\u5f71\u54cd\u3002", "conclusion": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bf4\u670d\u62b5\u6297\u529b\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8f83\u5c0f\u6a21\u578b\u6781\u6613\u53d7\u5f71\u54cd\uff0c\u5143\u8ba4\u77e5\u63d0\u793a\u53cd\u800c\u52a0\u5267\u8106\u5f31\u6027\uff0c\u4e14\u5bf9\u6297\u5fae\u8c03\u6548\u679c\u6709\u9650\uff0c\u5c24\u5176\u5bf9\u4e8eLlama\u6a21\u578b\u3002"}}
{"id": "2601.13614", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13614", "abs": "https://arxiv.org/abs/2601.13614", "authors": ["Bo Peng", "Sirui Chen", "Lei Xu", "Chaochao Lu"], "title": "CauScientist: Teaching LLMs to Respect Data for Causal Discovery", "comment": null, "summary": "Causal discovery is fundamental to scientific understanding and reliable decision-making. Existing approaches face critical limitations: purely data-driven methods suffer from statistical indistinguishability and modeling assumptions, while recent LLM-based methods either ignore statistical evidence or incorporate unverified priors that can mislead result. To this end, we propose CauScientist, a collaborative framework that synergizes LLMs as hypothesis-generating \"data scientists\" with probabilistic statistics as rigorous \"verifiers\". CauScientist employs hybrid initialization to select superior starting graphs, iteratively refines structures through LLM-proposed modifications validated by statistical criteria, and maintains error memory to guide efficient search space. Experiments demonstrate that CauScientist substantially outperforms purely data-driven baselines, achieving up to 53.8% F1 score improvement and enhancing recall from 35.0% to 100.0%. Notably, while standalone LLM performance degrades with graph complexity, CauScientist reduces structural hamming distance (SHD) by 44.0% compared to Qwen3-32B on 37-node graphs. Our project page is at https://github.com/OpenCausaLab/CauScientist.", "AI": {"tldr": "\u63d0\u51faCauScientist\u6846\u67b6\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7edf\u8ba1\u9a8c\u8bc1\uff0c\u663e\u8457\u63d0\u5347\u56e0\u679c\u53d1\u73b0\u6027\u80fd\uff0c\u5c24\u5176\u5728\u590d\u6742\u56fe\u7ed3\u6784\u4e2d\u6548\u679c\u7a81\u51fa\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u65b9\u6cd5\u5b58\u5728\u7edf\u8ba1\u4e0d\u53ef\u533a\u5206\u6027\u3001\u5efa\u6a21\u5047\u8bbe\u9650\u5236\uff0c\u6216\u5ffd\u89c6\u7edf\u8ba1\u8bc1\u636e\u3001\u5f15\u5165\u672a\u7ecf\u9a8c\u8bc1\u5148\u9a8c\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u878d\u5408LLM\u548c\u7edf\u8ba1\u9a8c\u8bc1\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8be5\u65b9\u6cd5\u7ed3\u5408LLM\u4f5c\u4e3a\u5047\u8bbe\u751f\u6210\u8005\u548c\u6982\u7387\u7edf\u8ba1\u4f5c\u4e3a\u9a8c\u8bc1\u8005\uff0c\u901a\u8fc7\u6df7\u5408\u521d\u59cb\u5316\u3001\u8fed\u4ee3\u7ed3\u6784\u4f18\u5316\u53ca\u9519\u8bef\u8bb0\u5fc6\u6307\u5bfc\u641c\u7d22\u7a7a\u95f4\uff0c\u5b9e\u73b0\u534f\u540c\u56e0\u679c\u53d1\u73b0\u3002", "result": "CauScientist\u5728F1\u5206\u6570\u4e0a\u63d0\u5347\u4e8653.8%\uff0c\u53ec\u56de\u7387\u4ece35.0%\u63d0\u5347\u81f3100.0%\uff0c\u572837\u8282\u70b9\u56fe\u4e0a\u76f8\u8f83Qwen3-32B\u7ed3\u6784\u6c49\u660e\u8ddd\u79bb\u51cf\u5c1144.0%\u3002", "conclusion": "CauScientist\u663e\u8457\u63d0\u5347\u4e86\u56e0\u679c\u53d1\u73b0\u7684\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\uff0c\u5728\u590d\u6742\u56fe\u7ed3\u6784\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u514b\u670d\u4e86\u7eaf\u6570\u636e\u9a71\u52a8\u548c\u7eafLLM\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002"}}
{"id": "2601.13630", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13630", "abs": "https://arxiv.org/abs/2601.13630", "authors": ["Zhaopeng Zhang", "Pengcheng Sun", "Lan Zhang", "Chen Tang", "Jiewei Lai", "Yunhao Wang", "Hui Jin"], "title": "Activation-Space Anchored Access Control for Multi-Class Permission Reasoning in Large Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly deployed over knowledge bases for efficient knowledge retrieval and question answering. However, LLMs can inadvertently answer beyond a user's permission scope, leaking sensitive content, thus making it difficult to deploy knowledge-base QA under fine-grained access control requirements. In this work, we identify a geometric regularity in intermediate activations: for the same query, representations induced by different permission scopes cluster distinctly and are readily separable. Building on this separability, we propose Activation-space Anchored Access Control (AAAC), a training-free framework for multi-class permission control. AAAC constructs an anchor bank, with one permission anchor per class, from a small offline sample set and requires no fine-tuning. At inference time, a multi-anchor steering mechanism redirects each query's activations toward the anchor-defined authorized region associated with the current user, thereby suppressing over-privileged generations by design. Finally, extensive experiments across three LLM families demonstrate that AAAC reduces permission violation rates by up to 86.5% and prompt-based attack success rates by 90.7%, while improving response usability with minor inference overhead compared to baselines.", "AI": {"tldr": "\u6587\u7ae0\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6fc0\u6d3b\u7a7a\u95f4\u951a\u70b9\u7684\u4e0d\u9700\u8bad\u7ec3\u7684\u6743\u9650\u63a7\u5236\u65b9\u6cd5AAAC\uff0c\u6709\u6548\u9632\u6b62\u5927\u8bed\u8a00\u6a21\u578b\u77e5\u8bc6\u5e93\u95ee\u7b54\u4e2d\u7684\u6743\u9650\u6cc4\u9732\u548c\u653b\u51fb\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5e93\u95ee\u7b54\u4e2d\u53ef\u80fd\u8d85\u8d8a\u7528\u6237\u6743\u9650\u8303\u56f4\u56de\u7b54\uff0c\u5bfc\u81f4\u654f\u611f\u4fe1\u606f\u6cc4\u9732\uff0c\u4e9f\u9700\u7ec6\u7c92\u5ea6\u6743\u9650\u63a7\u5236\u673a\u5236\u3002", "method": "\u5229\u7528\u4e2d\u95f4\u6fc0\u6d3b\u8868\u73b0\u7684\u51e0\u4f55\u89c4\u5f8b\uff0c\u6784\u5efa\u951a\u70b9\u5e93\u5bf9\u5e94\u4e0d\u540c\u6743\u9650\u7c7b\u522b\uff0c\u63a8\u7406\u65f6\u901a\u8fc7\u591a\u951a\u70b9\u5f15\u5bfc\u673a\u5236\u5c06\u67e5\u8be2\u6fc0\u6d3b\u91cd\u5b9a\u5411\u81f3\u6388\u6743\u533a\u57df\uff0c\u65e0\u9700\u5fae\u8c03\u3002", "result": "AAAC\u5728\u4e09\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u6743\u9650\u8fdd\u89c4\u7387\u964d\u4f4e\u6700\u9ad8\u8fbe86.5%\uff0c\u57fa\u4e8e\u63d0\u793a\u7684\u653b\u51fb\u6210\u529f\u7387\u964d\u4f4e90.7%\uff0c\u4e14\u63a8\u7406\u5f00\u9500\u5c0f\u5e45\u63d0\u5347\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684Activation-space Anchored Access Control (AAAC)\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5e93\u8bbf\u95ee\u4e2d\u7684\u6743\u9650\u63a7\u5236\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6743\u9650\u8fdd\u89c4\u548c\u653b\u51fb\u6210\u529f\u7387\uff0c\u63d0\u9ad8\u4e86\u54cd\u5e94\u7684\u53ef\u7528\u6027\u3002"}}
{"id": "2601.13644", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13644", "abs": "https://arxiv.org/abs/2601.13644", "authors": ["Yang Cao", "Bicheng Yu", "Sikun Yang", "Ming Liu", "Yujiu Yang"], "title": "Towards Token-Level Text Anomaly Detection", "comment": "WWW 2026", "summary": "Despite significant progress in text anomaly detection for web applications such as spam filtering and fake news detection, existing methods are fundamentally limited to document-level analysis, unable to identify which specific parts of a text are anomalous. We introduce token-level anomaly detection, a novel paradigm that enables fine-grained localization of anomalies within text. We formally define text anomalies at both document and token-levels, and propose a unified detection framework that operates across multiple levels. To facilitate research in this direction, we collect and annotate three benchmark datasets spanning spam, reviews and grammar errors with token-level labels. Experimental results demonstrate that our framework get better performance than other 6 baselines, opening new possibilities for precise anomaly localization in text. All the codes and data are publicly available on https://github.com/charles-cao/TokenCore.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u63d0\u51fa\u8bcd\u5143\u7ea7\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\uff0c\u8bbe\u8ba1\u7edf\u4e00\u6846\u67b6\u5e76\u6784\u5efa\u5e26\u8bcd\u5143\u7ea7\u6807\u6ce8\u7684\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u6587\u6863\u7ea7\u65b9\u6cd5\u66f4\u7cbe\u786e\u7684\u5f02\u5e38\u5b9a\u4f4d\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u65b9\u6cd5\u4ec5\u9650\u4e8e\u6587\u6863\u7ea7\uff0c\u65e0\u6cd5\u5b9a\u4f4d\u6587\u672c\u4e2d\u5177\u4f53\u5f02\u5e38\u7684\u90e8\u5206\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u5f02\u5e38\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u8de8\u6587\u6863\u548c\u8bcd\u5143\u7ea7\u522b\u8fdb\u884c\u5f02\u5e38\u68c0\u6d4b\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5e76\u4e14\u6784\u5efa\u4e86\u5305\u542b\u8bcd\u5143\u7ea7\u6807\u6ce8\u7684\u4e09\u4e2a\u4eba\u5de5\u6807\u6ce8\u6570\u636e\u96c6\u7528\u4e8e\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u57fa\u4e8e\u65b0\u63d0\u51fa\u7684\u6846\u67b6\uff0c\u5728\u5783\u573e\u90ae\u4ef6\u3001\u8bc4\u8bba\u548c\u8bed\u6cd5\u9519\u8bef\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u6807\u6ce8\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u4e8e\u5176\u4ed6\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u7684\u68c0\u6d4b\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7edf\u4e00\u68c0\u6d4b\u6846\u67b6\u5728\u591a\u5c42\u7ea7\u6587\u672c\u5f02\u5e38\u68c0\u6d4b\u4e2d\u8868\u73b0\u4f18\u8d8a\uff0c\u80fd\u591f\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u5f02\u5e38\u5b9a\u4f4d\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u516d\u4e2a\u57fa\u7ebf\u65b9\u6cd5\u3002"}}
{"id": "2601.13649", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13649", "abs": "https://arxiv.org/abs/2601.13649", "authors": ["Xiaolin Zhou", "Zheng Luo", "Yicheng Gao", "Qixuan Chen", "Xiyang Hu", "Yue Zhao", "Ruishan Liu"], "title": "Fairness or Fluency? An Investigation into Language Bias of Pairwise LLM-as-a-Judge", "comment": null, "summary": "Recent advances in Large Language Models (LLMs) have incentivized the development of LLM-as-a-judge, an application of LLMs where they are used as judges to decide the quality of a certain piece of text given a certain context. However, previous studies have demonstrated that LLM-as-a-judge can be biased towards different aspects of the judged texts, which often do not align with human preference. One of the identified biases is language bias, which indicates that the decision of LLM-as-a-judge can differ based on the language of the judged texts. In this paper, we study two types of language bias in pairwise LLM-as-a-judge: (1) performance disparity between languages when the judge is prompted to compare options from the same language, and (2) bias towards options written in major languages when the judge is prompted to compare options of two different languages. We find that for same-language judging, there exist significant performance disparities across language families, with European languages consistently outperforming African languages, and this bias is more pronounced in culturally-related subjects. For inter-language judging, we observe that most models favor English answers, and that this preference is influenced more by answer language than question language. Finally, we investigate whether language bias is in fact caused by low-perplexity bias, a previously identified bias of LLM-as-a-judge, and we find that while perplexity is slightly correlated with language bias, language bias cannot be fully explained by perplexity only.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u7684\u8bed\u8a00\u504f\u89c1\uff0c\u53d1\u73b0\u5b58\u5728\u8de8\u8bed\u8a00\u548c\u540c\u8bed\u8a00\u6027\u80fd\u5dee\u5f02\u53ca\u5bf9\u82f1\u8bed\u7684\u504f\u597d\uff0c\u4e14\u8bed\u8a00\u504f\u89c1\u4e0d\u80fd\u5b8c\u5168\u7531\u4f4e\u56f0\u60d1\u5ea6\u504f\u5dee\u89e3\u91ca\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u53d1\u73b0LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u65f6\u5b58\u5728\u4e0e\u4eba\u7c7b\u504f\u597d\u4e0d\u4e00\u81f4\u7684\u504f\u89c1\uff0c\u5c24\u5176\u662f\u8bed\u8a00\u504f\u89c1\uff0c\u672c\u6587\u65e8\u5728\u7cfb\u7edf\u63ed\u793a\u548c\u7406\u89e3\u8fd9\u79cd\u8bed\u8a00\u504f\u89c1\u7684\u5177\u4f53\u8868\u73b0\u53ca\u6210\u56e0\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5206\u6790LLM\u5728\u6210\u5bf9\u6587\u672c\u6bd4\u8f83\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u522b\u8003\u5bdf\u4e86\u540c\u8bed\u79cd\u6bd4\u8f83\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u4ee5\u53ca\u8de8\u8bed\u79cd\u6bd4\u8f83\u65f6\u7684\u8bed\u8a00\u504f\u597d\uff0c\u5e76\u8fdb\u4e00\u6b65\u63a2\u8ba8\u4e86\u8bed\u8a00\u504f\u89c1\u662f\u5426\u53ef\u7531\u4f4e\u56f0\u60d1\u5ea6\u504f\u5dee\u89e3\u91ca\u3002", "result": "\u7814\u7a76\u663e\u793a\u6b27\u6d32\u8bed\u8a00\u5728\u540c\u8bed\u79cd\u8bc4\u5224\u4e2d\u6027\u80fd\u4f18\u4e8e\u975e\u6d32\u8bed\u8a00\uff0c\u4e14\u5728\u6587\u5316\u76f8\u5173\u4e3b\u9898\u66f4\u660e\u663e\uff1b\u8de8\u8bed\u8a00\u6bd4\u8f83\u65f6\uff0c\u5927\u591a\u6570\u6a21\u578b\u504f\u597d\u82f1\u8bed\u7b54\u6848\uff0c\u5176\u504f\u597d\u4e3b\u8981\u53d7\u7b54\u6848\u8bed\u8a00\u5f71\u54cd\uff1b\u4f4e\u56f0\u60d1\u5ea6\u504f\u5dee\u4e0e\u8bed\u8a00\u504f\u89c1\u76f8\u5173\u4f46\u4e0d\u80fd\u5b8c\u5168\u89e3\u91ca\u3002", "conclusion": "\u672c\u8bba\u6587\u53d1\u73b0LLM\u4f5c\u4e3a\u8bc4\u5224\u8005\u5728\u5224\u65ad\u6587\u672c\u8d28\u91cf\u65f6\u5b58\u5728\u663e\u8457\u7684\u8bed\u8a00\u504f\u89c1\uff0c\u8868\u73b0\u4e3a\u540c\u4e00\u8bed\u8a00\u6bd4\u8f83\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\u53ca\u8de8\u8bed\u8a00\u6bd4\u8f83\u4e2d\u5bf9\u4e3b\u6d41\u8bed\u8a00\uff08\u5c24\u5176\u662f\u82f1\u8bed\uff09\u7684\u504f\u597d\u3002"}}
{"id": "2601.13658", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13658", "abs": "https://arxiv.org/abs/2601.13658", "authors": ["Arthur Amalvy", "Hen-Hsen Huang"], "title": "Beyond Known Facts: Generating Unseen Temporal Knowledge to Address Data Contamination in LLM Evaluation", "comment": "12 pages", "summary": "The automatic extraction of information is important for populating large web knowledge bases such as Wikidata. The temporal version of that task, temporal knowledge graph extraction (TKGE), involves extracting temporally grounded facts from text, represented as semantic quadruples (subject, relation, object, timestamp). Many recent systems take advantage of large language models (LLMs), which are becoming a new cornerstone of the web due to their performance on many tasks across the natural language processing (NLP) field. Despite the importance of TKGE, existing datasets for training and evaluation remain scarce, and contamination of evaluation data is an unaddressed issue, potentially inflating LLMs' perceived performance due to overlaps between training and evaluation sets. To mitigate these challenges, we propose a novel synthetic evaluation dataset constructed from predicted future, previously unseen temporal facts, thereby eliminating contamination and enabling robust and unbiased benchmarking. Our dataset creation involves a two-step approach: (1) Temporal Knowledge Graph Forecasting (TKGF) generates plausible future quadruples, which are subsequently filtered to adhere to the original knowledge base schema; (2) LLMs perform quadruple-to-text generation, creating semantically aligned textual descriptions. We benchmark Extract, Define and Canonicalize (EDC), a state-of-the-art LLM-based extraction framework, demonstrating that LLM performance decreases when evaluated on our dataset compared to a dataset of known facts. We publicly release our dataset consisting of 4.2K future quadruples and corresponding textual descriptions, along with the generation methodology, enabling continuous creation of unlimited future temporal datasets to serve as long-term, contamination-free benchmarks for TKGE.", "AI": {"tldr": "\u672c\u8bba\u6587\u9488\u5bf9\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u6570\u636e\u96c6\u7a00\u7f3a\u53ca\u8bc4\u6d4b\u6c61\u67d3\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u9884\u6d4b\u672a\u6765\u4e8b\u5b9e\u7684\u65e0\u6c61\u67d3\u5408\u6210\u6570\u636e\u96c6\uff0c\u63d0\u4f9b\u4e86\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u73af\u5883\u3002", "motivation": "\u73b0\u6709\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u6570\u636e\u96c6\u7a00\u7f3a\u4e14\u5b58\u5728\u8bad\u7ec3\u8bc4\u4f30\u6570\u636e\u6c61\u67d3\uff0c\u5bfc\u81f4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc4\u6d4b\u4e2d\u8868\u73b0\u88ab\u9ad8\u4f30\uff0c\u4e9f\u9700\u65e0\u6c61\u67d3\u7684\u9c81\u68d2\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u91c7\u7528\u4e24\u6b65\u6cd5\uff1a\u7b2c\u4e00\u6b65\u662f\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u9884\u6d4b\u751f\u6210\u672a\u6765\u5408\u7406\u56db\u5143\u7ec4\uff0c\u5e76\u8fdb\u884c\u6a21\u5f0f\u7b5b\u9009\uff1b\u7b2c\u4e8c\u6b65\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4e0e\u56db\u5143\u7ec4\u8bed\u4e49\u5bf9\u9f50\u7684\u6587\u672c\u63cf\u8ff0\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u6784\u5efa\u8bc4\u6d4b\u6570\u636e\u96c6\u3002", "result": "\u901a\u8fc7\u5bf9\u6bd4\u57fa\u4e8e\u5df2\u77e5\u4e8b\u5b9e\u6570\u636e\u96c6\u7684\u8bc4\u6d4b\uff0c\u53d1\u73b0LLM\u5728\u65b0\u5408\u6210\u672a\u6765\u4e8b\u5b9e\u6570\u636e\u96c6\u4e0a\u6027\u80fd\u660e\u663e\u4e0b\u964d\uff0c\u9a8c\u8bc1\u4e86\u65b0\u6570\u636e\u96c6\u66f4\u80fd\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u80fd\u529b\u3002\u5e76\u516c\u5f00\u53d1\u5e03\u4e86\u542b4200\u6761\u672a\u6765\u56db\u5143\u7ec4\u4e0e\u6587\u672c\u7684\u6570\u636e\u96c6\u53ca\u751f\u6210\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u672a\u6765\u672a\u89c1\u4e8b\u5b9e\u7684\u5408\u6210\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u6d88\u9664\u6570\u636e\u6c61\u67d3\uff0c\u5b9e\u73b0\u4e86\u65f6\u95f4\u77e5\u8bc6\u56fe\u8c31\u63d0\u53d6\u7684\u9c81\u68d2\u3001\u516c\u6b63\u8bc4\u6d4b\u3002"}}
{"id": "2601.13659", "categories": ["cs.CL", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13659", "abs": "https://arxiv.org/abs/2601.13659", "authors": ["Chunlei Meng", "Ziyang Zhou", "Lucas He", "Xiaojing Du", "Chun Ouyang", "Zhongxue Gan"], "title": "Temporal-Spatial Decouple before Act: Disentangled Representation Learning for Multimodal Sentiment Analysis", "comment": "This study has been accepted by IEEE ICASSP2026", "summary": "Multimodal Sentiment Analysis integrates Linguistic, Visual, and Acoustic. Mainstream approaches based on modality-invariant and modality-specific factorization or on complex fusion still rely on spatiotemporal mixed modeling. This ignores spatiotemporal heterogeneity, leading to spatiotemporal information asymmetry and thus limited performance. Hence, we propose TSDA, Temporal-Spatial Decouple before Act, which explicitly decouples each modality into temporal dynamics and spatial structural context before any interaction. For every modality, a temporal encoder and a spatial encoder project signals into separate temporal and spatial body. Factor-Consistent Cross-Modal Alignment then aligns temporal features only with their temporal counterparts across modalities, and spatial features only with their spatial counterparts. Factor specific supervision and decorrelation regularization reduce cross factor leakage while preserving complementarity. A Gated Recouple module subsequently recouples the aligned streams for task. Extensive experiments show that TSDA outperforms baselines. Ablation analysis studies confirm the necessity and interpretability of the design.", "AI": {"tldr": "TSDA\u65b9\u6cd5\u901a\u8fc7\u65f6\u7a7a\u89e3\u8026\u548c\u56e0\u5b50\u4e00\u81f4\u6027\u5bf9\u9f50\u6539\u8fdb\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u8bbe\u8ba1\u5408\u7406\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u4f9d\u8d56\u65f6\u7a7a\u6df7\u5408\u5efa\u6a21\uff0c\u5ffd\u7565\u4e86\u65f6\u7a7a\u5f02\u8d28\u6027\uff0c\u5bfc\u81f4\u4fe1\u606f\u4e0d\u5bf9\u79f0\u548c\u6027\u80fd\u53d7\u9650\u3002", "method": "\u63d0\u51faTSDA\u65b9\u6cd5\uff0c\u5148\u5c06\u6bcf\u79cd\u6a21\u6001\u7684\u4fe1\u53f7\u89e3\u8026\u4e3a\u65f6\u95f4\u52a8\u6001\u548c\u7a7a\u95f4\u7ed3\u6784\uff0c\u901a\u8fc7\u65f6\u95f4\u7f16\u7801\u5668\u548c\u7a7a\u95f4\u7f16\u7801\u5668\u5206\u522b\u5904\u7406\uff0c\u518d\u5229\u7528\u4e00\u81f4\u6027\u8de8\u6a21\u6001\u5bf9\u9f50\u4ec5\u5bf9\u9f50\u65f6\u95f4\u7279\u5f81\u4e0e\u65f6\u95f4\u7279\u5f81\uff0c\u7a7a\u95f4\u7279\u5f81\u4e0e\u7a7a\u95f4\u7279\u5f81\uff0c\u914d\u5408\u56e0\u5b50\u76d1\u7763\u548c\u53bb\u76f8\u5173\u6b63\u5219\u5316\u51cf\u5c11\u4fe1\u606f\u6cc4\u6f0f\uff0c\u6700\u540e\u901a\u8fc7\u95e8\u63a7\u6a21\u5757\u91cd\u65b0\u7ed3\u5408\u7279\u5f81\u8fdb\u884c\u4efb\u52a1\u5904\u7406\u3002", "result": "TSDA\u5728\u5927\u91cf\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6d88\u878d\u5206\u6790\u9a8c\u8bc1\u4e86\u8bbe\u8ba1\u7684\u5fc5\u8981\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u7684\u65f6\u7a7a\u89e3\u8026\u548c\u56e0\u5b50\u4e00\u81f4\u6027\u5bf9\u9f50\uff0cTSDA\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u7684\u65f6\u7a7a\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6027\u80fd\u548c\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.13669", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13669", "abs": "https://arxiv.org/abs/2601.13669", "authors": ["Jiayu Lin", "Zhongyu Wei"], "title": "CommunityBench: Benchmarking Community-Level Alignment across Diverse Groups and Tasks", "comment": null, "summary": "Large language models (LLMs) alignment ensures model behaviors reflect human value. Existing alignment strategies primarily follow two paths: one assumes a universal value set for a unified goal (i.e., one-size-fits-all), while the other treats every individual as unique to customize models (i.e., individual-level). However, assuming a monolithic value space marginalizes minority norms, while tailoring individual models is prohibitively expensive. Recognizing that human society is organized into social clusters with high intra-group value alignment, we propose community-level alignment as a \"middle ground\". Practically, we introduce CommunityBench, the first large-scale benchmark for community-level alignment evaluation, featuring four tasks grounded in Common Identity and Common Bond theory. With CommunityBench, we conduct a comprehensive evaluation of various foundation models on CommunityBench, revealing that current LLMs exhibit limited capacity to model community-specific preferences. Furthermore, we investigate the potential of community-level alignment in facilitating individual modeling, providing a promising direction for scalable and pluralistic alignment.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3a\u6298\u4e2d\u7b56\u7565\uff0c\u901a\u8fc7CommunityBench\u8bc4\u6d4b\u6a21\u578b\u5bf9\u793e\u533a\u504f\u597d\u7684\u9002\u5e94\u80fd\u529b\uff0c\u53d1\u73b0\u5f53\u524d\u6a21\u578b\u8868\u73b0\u4e0d\u8db3\uff0c\u4f46\u793e\u533a\u7ea7\u5bf9\u9f50\u4e3a\u5b9e\u73b0\u4e2a\u6027\u5316\u4e14\u591a\u5143\u7684\u6a21\u578b\u5bf9\u9f50\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u73b0\u6709\u5bf9\u9f50\u7b56\u7565\u8981\u4e48\u5047\u8bbe\u5355\u4e00\u4ef7\u503c\u89c2\u5bfc\u81f4\u8fb9\u7f18\u5316\u5c11\u6570\u7fa4\u4f53\uff0c\u8981\u4e48\u4e3a\u4e2a\u4f53\u5b9a\u5236\u6a21\u578b\u6210\u672c\u8fc7\u9ad8\uff0c\u9274\u4e8e\u793e\u4f1a\u4ee5\u793e\u533a\u4e3a\u5355\u4f4d\u7ec4\u7ec7\uff0c\u63a2\u7d22\u793e\u533a\u7ea7\u5bf9\u9f50\u4f5c\u4e3a\u6298\u4e2d\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86CommunityBench\u8fd9\u4e00\u9996\u4e2a\u5927\u89c4\u6a21\u793e\u533a\u7ea7\u5bf9\u9f50\u8bc4\u6d4b\u5e73\u53f0\uff0c\u57fa\u4e8e\u5171\u540c\u8eab\u4efd\u548c\u5171\u540c\u7ebd\u5e26\u7406\u8bba\u8bbe\u8ba1\u56db\u4e2a\u4efb\u52a1\uff0c\u7cfb\u7edf\u8bc4\u4f30\u57fa\u7840\u8bed\u8a00\u6a21\u578b\u5728\u793e\u533a\u504f\u597d\u6a21\u62df\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u793e\u533a\u7279\u5b9a\u504f\u597d\u7684\u5efa\u6a21\u80fd\u529b\u6709\u9650\uff0c\u540c\u65f6\u9a8c\u8bc1\u4e86\u793e\u533a\u7ea7\u5bf9\u9f50\u5728\u63a8\u52a8\u4e2a\u4f53\u6a21\u578b\u5b9a\u5236\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u793e\u533a\u7279\u5b9a\u504f\u597d\u65b9\u9762\u80fd\u529b\u6709\u9650\uff0c\u793e\u533a\u7ea7\u522b\u7684\u5bf9\u9f50\u63d0\u4f9b\u4e86\u4e2a\u4f53\u5316\u548c\u901a\u7528\u6027\u4e4b\u95f4\u7684\u6709\u6548\u6865\u6881\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u89c4\u6a21\u5316\u4e14\u591a\u5143\u5316\u7684\u6a21\u578b\u5bf9\u9f50\u3002"}}
{"id": "2601.13684", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13684", "abs": "https://arxiv.org/abs/2601.13684", "authors": ["Zhiyuan Shi", "Qibo Qiu", "Feng Xue", "Zhonglin Jiang", "Li Yu", "Jian Jiang", "Xiaofei He", "Wenxiao Wang"], "title": "HeteroCache: A Dynamic Retrieval Approach to Heterogeneous KV Cache Compression for Long-Context LLM Inference", "comment": null, "summary": "The linear memory growth of the KV cache poses a significant bottleneck for LLM inference in long-context tasks. Existing static compression methods often fail to preserve globally important information, principally because they overlook the attention drift phenomenon where token significance evolves dynamically. Although recent dynamic retrieval approaches attempt to address this issue, they typically suffer from coarse-grained caching strategies and incur high I/O overhead due to frequent data transfers. To overcome these limitations, we propose HeteroCache, a training-free dynamic compression framework. Our method is built on two key insights: attention heads exhibit diverse temporal heterogeneity, and there is significant spatial redundancy among heads within the same layer. Guided by these insights, HeteroCache categorizes heads based on stability and redundancy. Consequently, we apply a fine-grained weighting strategy that allocates larger cache budgets to heads with rapidly shifting attention to capture context changes, thereby addressing the inefficiency of coarse-grained strategies. Furthermore, we employ a hierarchical storage mechanism in which a subset of representative heads monitors attention shift, and trigger an asynchronous, on-demand retrieval of contexts from the CPU, effectively hiding I/O latency. Finally, experiments demonstrate that HeteroCache achieves state-of-the-art performance on multiple long-context benchmarks and accelerates decoding by up to $3\\times$ compared to the original model in the 224K context. Our code will be open-source.", "AI": {"tldr": "\u4e3a\u89e3\u51b3\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2dKV\u7f13\u5b58\u7684\u5185\u5b58\u548c\u6548\u7387\u74f6\u9888\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u52a8\u6001\u7684HeteroCache\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5934\u7684\u5f02\u8d28\u6027\u548c\u5197\u4f59\u6027\u5206\u5c42\u7ba1\u7406\uff0c\u5b9e\u73b0\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u63a8\u7406\u52a0\u901f\u3002", "motivation": "KV\u7f13\u5b58\u7684\u7ebf\u6027\u5185\u5b58\u589e\u957f\u6210\u4e3a\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u74f6\u9888\uff0c\u73b0\u6709\u9759\u6001\u538b\u7f29\u65b9\u6cd5\u4e0d\u80fd\u52a8\u6001\u6355\u6349\u6ce8\u610f\u529b\u6f02\u79fb\u5bfc\u81f4\u7684\u91cd\u8981\u4fe1\u606f\u4e22\u5931\u3002", "method": "\u63d0\u51faHeteroCache\uff0c\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u52a8\u6001\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u57fa\u4e8e\u7a33\u5b9a\u6027\u548c\u5197\u4f59\u6027\u5206\u7c7b\u6ce8\u610f\u529b\u5934\uff0c\u91c7\u7528\u7ec6\u7c92\u5ea6\u6743\u91cd\u5206\u914d\u7b56\u7565\u548c\u5206\u5c42\u5b58\u50a8\u673a\u5236\uff0c\u5b9e\u73b0\u52a8\u6001\u538b\u7f29\u548c\u5f02\u6b65\u6309\u9700\u4e0a\u4e0b\u6587\u68c0\u7d22\u3002", "result": "HeteroCache\u5728\u591a\u4e2a\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u5728224K\u4e0a\u4e0b\u6587\u957f\u5ea6\u7684\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u9ad83\u500d\u7684\u89e3\u7801\u52a0\u901f\u3002", "conclusion": "HeteroCache\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4e2dKV\u7f13\u5b58\u7684\u5185\u5b58\u74f6\u9888\u548c\u6548\u7387\u95ee\u9898\uff0c\u52a8\u6001\u6355\u83b7\u6ce8\u610f\u529b\u53d8\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u548c\u6027\u80fd\u3002"}}
{"id": "2601.13690", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13690", "abs": "https://arxiv.org/abs/2601.13690", "authors": ["Yue Guo", "Fanfu Wang", "Jianwei Lv", "Xincheng Shi", "Yuchen Li", "Youya Wang", "Yunsheng Zeng", "Yujing Liu", "Yunhao Qiao", "Gen Li", "Junfeng Wang", "Bo Yuan"], "title": "Dr. Assistant: Enhancing Clinical Diagnostic Inquiry via Structured Diagnostic Reasoning Data and Reinforcement Learning", "comment": null, "summary": "Clinical Decision Support Systems (CDSSs) provide reasoning and inquiry guidance for physicians, yet they face notable challenges, including high maintenance costs and low generalization capability. Recently, Large Language Models (LLMs) have been widely adopted in healthcare due to their extensive knowledge reserves, retrieval, and communication capabilities. While LLMs show promise and excel at medical benchmarks, their diagnostic reasoning and inquiry skills are constrained. To mitigate this issue, we propose (1) Clinical Diagnostic Reasoning Data (CDRD) structure to capture abstract clinical reasoning logic, and a pipeline for its construction, and (2) the Dr. Assistant, a clinical diagnostic model equipped with clinical reasoning and inquiry skills. Its training involves a two-stage process: SFT, followed by RL with a tailored reward function. We also introduce a benchmark to evaluate both diagnostic reasoning and inquiry. Our experiments demonstrate that the Dr. Assistant outperforms open-source models and achieves competitive performance to closed-source models, providing an effective solution for clinical diagnostic inquiry guidance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u6570\u636e\u7ed3\u6784\u548c\u53cc\u9636\u6bb5\u8bad\u7ec3\u7684\u8bed\u8a00\u6a21\u578bDr. Assistant\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u548c\u8be2\u95ee\u80fd\u529b\uff0c\u4f18\u4e8e\u591a\u79cd\u5f00\u6e90\u6a21\u578b\uff0c\u8868\u73b0\u63a5\u8fd1\u95ed\u6e90\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u5b58\u5728\u7ef4\u62a4\u6210\u672c\u9ad8\u548c\u6cdb\u5316\u80fd\u529b\u5f31\u7684\u95ee\u9898\uff0c\u4e14\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u5177\u4e30\u5bcc\u77e5\u8bc6\u4e0e\u6c9f\u901a\u80fd\u529b\uff0c\u4f46\u5176\u8bca\u65ad\u63a8\u7406\u548c\u8be2\u95ee\u6280\u80fd\u53d7\u9650\uff0c\u4e9f\u9700\u63d0\u5347\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u6570\u636e\u7ed3\u6784\uff08CDRD\uff09\u5e76\u6784\u5efa\u4e86\u76f8\u5e94\u7684\u6570\u636e\u6d41\u6c34\u7ebf\uff1b\u5f00\u53d1\u4e86Dr. Assistant\u6a21\u578b\uff0c\u91c7\u7528\u5148\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u518d\u57fa\u4e8e\u5b9a\u5236\u5956\u52b1\u51fd\u6570\u7684\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u3002", "result": "Dr. Assistant\u5728\u65b0\u6784\u5efa\u7684\u8bca\u65ad\u63a8\u7406\u4e0e\u8be2\u95ee\u8bc4\u6d4b\u57fa\u51c6\u4e0a\u8d85\u8d8a\u4e86\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u5728\u6027\u80fd\u4e0a\u63a5\u8fd1\u95ed\u6e90\u6a21\u578b\uff0c\u4f53\u73b0\u51fa\u5176\u5728\u4e34\u5e8a\u8bca\u65ad\u652f\u6301\u4e2d\u7684\u6709\u6548\u6027\u548c\u7ade\u4e89\u529b\u3002", "conclusion": "Dr. Assistant\u6a21\u578b\u901a\u8fc7\u5f15\u5165\u4e34\u5e8a\u8bca\u65ad\u63a8\u7406\u6570\u636e\u7ed3\u6784\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bca\u65ad\u63a8\u7406\u548c\u8be2\u95ee\u80fd\u529b\uff0c\u5728\u4e34\u5e8a\u8bca\u65ad\u5f15\u5bfc\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f00\u6e90\u6a21\u578b\u5e76\u4e0e\u95ed\u6e90\u6a21\u578b\u7ade\u4e89\u3002"}}
{"id": "2601.13695", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13695", "abs": "https://arxiv.org/abs/2601.13695", "authors": ["Sifan Li", "Hongkai Chen", "Yujun Cai", "Liyang Chen", "Qingwen Ye", "Yiwei Wang"], "title": "OptiSQL: Executable SQL Generation from Optical TokensOptiSQL: Executable SQL Generation from Optical Tokens", "comment": null, "summary": "Executable SQL generation is typically studied in text-to-SQL settings, where tables are provided as fully linearized textual schemas and contents. While effective, this formulation assumes access to structured text and incurs substantial token overhead, which is misaligned with many real-world scenarios where tables appear as visual artifacts in documents or webpages. We investigate whether compact optical representations can serve as an efficient interface for executable semantic parsing. We present OptiSQL, a vision-driven framework that generates executable SQL directly from table images and natural language questions using compact optical tokens. OptiSQL leverages an OCR-oriented visual encoder to compress table structure and content into a small set of optical tokens and fine-tunes a pretrained decoder for SQL generation while freezing the encoder to isolate representation sufficiency. Experiments on a visualized version of Spider 2.0-Snow show that OptiSQL retains strong execution accuracy while reducing table input tokens by an order of magnitude. Robustness analyses further demonstrate that optical tokens preserve essential structural information under visual perturbations.", "AI": {"tldr": "OptiSQL\u901a\u8fc7\u5c06\u8868\u683c\u56fe\u50cf\u8f6c\u6362\u6210\u7d27\u51d1\u7684\u5149\u5b66\u6807\u8bb0\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u89c6\u89c9\u8868\u683c\u548c\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u751f\u6210\u53ef\u6267\u884cSQL\uff0c\u6781\u5927\u51cf\u5c11\u8f93\u5165\u89c4\u6a21\u4e14\u4fdd\u6301\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u53ef\u6267\u884cSQL\u751f\u6210\u4f9d\u8d56\u4e8e\u6587\u672c\u5230SQL\u7684\u8bbe\u7f6e\uff0c\u5047\u8bbe\u8868\u683c\u4f5c\u4e3a\u7ebf\u6027\u5316\u7684\u6587\u672c\u6a21\u5f0f\u548c\u5185\u5bb9\u63d0\u4f9b\uff0c\u8fd9\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u4e0d\u9002\u7528\uff0c\u56e0\u4e3a\u8868\u683c\u901a\u5e38\u4ee5\u89c6\u89c9\u5f62\u5f0f\u51fa\u73b0\u3002", "method": "\u63d0\u51faOptiSQL\uff0c\u4e00\u4e2a\u57fa\u4e8e\u89c6\u89c9\u7684\u6846\u67b6\uff0c\u901a\u8fc7OCR\u89c6\u89c9\u7f16\u7801\u5668\u5c06\u8868\u683c\u56fe\u50cf\u538b\u7f29\u6210\u7d27\u51d1\u7684\u5149\u5b66\u6807\u8bb0\uff0c\u7ed3\u5408\u9884\u8bad\u7ec3\u89e3\u7801\u5668\u751f\u6210SQL\uff0c\u7f16\u7801\u5668\u4fdd\u6301\u51bb\u7ed3\u4ee5\u9a8c\u8bc1\u8868\u793a\u80fd\u529b\u3002", "result": "\u5728\u89c6\u89c9\u5316\u7684Spider 2.0-Snow\u6570\u636e\u96c6\u4e0a\uff0cOptiSQL\u5728\u51cf\u5c11\u4e00\u6570\u91cf\u7ea7\u8868\u683c\u8f93\u5165\u6807\u8bb0\u7684\u540c\u65f6\uff0c\u4fdd\u6301\u4e86\u5f3a\u5927\u7684\u6267\u884c\u51c6\u786e\u7387\uff0c\u8fd8\u80fd\u5728\u89c6\u89c9\u6270\u52a8\u4e0b\u4fdd\u6301\u7ed3\u6784\u4fe1\u606f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u4f7f\u7528\u7d27\u51d1\u7684\u5149\u5b66\u8868\u793a\u53ef\u4ee5\u6709\u6548\u66ff\u4ee3\u4f20\u7edf\u6587\u672c\u5f62\u5f0f\u7684\u8868\u683c\u8f93\u5165\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684\u53ef\u6267\u884cSQL\u751f\u6210\uff0c\u9002\u5e94\u89c6\u89c9\u8868\u683c\u4fe1\u606f\u5904\u7406\u7684\u5b9e\u9645\u9700\u6c42\u3002"}}
{"id": "2601.13697", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13697", "abs": "https://arxiv.org/abs/2601.13697", "authors": ["Zhihang Yuan", "Chengyu Yue", "Long Huang", "Litu Ou", "Lei Shi"], "title": "Uncertainty-Aware Gradient Signal-to-Noise Data Selection for Instruction Tuning", "comment": "Preprint", "summary": "Instruction tuning is a standard paradigm for adapting large language models (LLMs), but modern instruction datasets are large, noisy, and redundant, making full-data fine-tuning costly and often unnecessary. Existing data selection methods either build expensive gradient datastores or assign static scores from a weak proxy, largely ignoring evolving uncertainty, and thus missing a key source of LLM interpretability. We propose GRADFILTERING, an objective-agnostic, uncertainty-aware data selection framework that utilizes a small GPT-2 proxy with a LoRA ensemble and aggregates per-example gradients into a Gradient Signal-to-Noise Ratio (G-SNR) utility. Our method matches or surpasses random subsets and strong baselines in most LLM-as-a-judge evaluations as well as in human assessment. Moreover, GRADFILTERING-selected subsets converge faster than competitive filters under the same compute budget, reflecting the benefit of uncertainty-aware scoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u4e0d\u786e\u5b9a\u6027\u7684\u68af\u5ea6\u4fe1\u566a\u6bd4\u6570\u636e\u7b5b\u9009\u65b9\u6cd5GRADFILTERING\uff0c\u6709\u6548\u63d0\u5347\u6307\u4ee4\u8c03\u4f18\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6307\u4ee4\u8c03\u4f18\u6570\u636e\u96c6\u5e9e\u5927\u4e14\u5197\u4f59\uff0c\u4f20\u7edf\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u5ffd\u89c6\u4e0d\u786e\u5b9a\u6027\uff0c\u5bfc\u81f4\u6210\u672c\u9ad8\u4e14\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86GRADFILTERING\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5c0f\u578bGPT-2\u4ee3\u7406\u548cLoRA\u96c6\u6210\u7684\u68af\u5ea6\u4fe1\u566a\u6bd4(G-SNR)\u6570\u636e\u9009\u62e9\u6846\u67b6\uff0c\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u76d1\u6d4b\u8fdb\u884c\u6837\u672c\u7b5b\u9009\u3002", "result": "GRADFILTERING\u9009\u62e9\u7684\u6570\u636e\u5b50\u96c6\u4e0d\u4ec5\u5728\u4eba\u7c7b\u548c\u6a21\u578b\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8fd8\u80fd\u5728\u76f8\u540c\u8ba1\u7b97\u9884\u7b97\u4e0b\u66f4\u5feb\u6536\u655b\u3002", "conclusion": "GRADFILTERING\u65b9\u6cd5\u5728\u6570\u636e\u9009\u62e9\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u5728\u5927\u591a\u6570\u8bc4\u4f30\u4e2d\u8d85\u8d8a\u968f\u673a\u9009\u62e9\u548c\u73b0\u6709\u5f3a\u57fa\u7ebf\uff0c\u4e14\u63d0\u9ad8\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2601.13711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13711", "abs": "https://arxiv.org/abs/2601.13711", "authors": ["Lotta Kiefer", "Christoph Leiter", "Sotaro Takeshita", "Elena Schmidt", "Steffen Eger"], "title": "GerAV: Towards New Heights in German Authorship Verification using Fine-Tuned LLMs on a New Benchmark", "comment": null, "summary": "Authorship verification (AV) is the task of determining whether two texts were written by the same author and has been studied extensively, predominantly for English data. In contrast, large-scale benchmarks and systematic evaluations for other languages remain scarce. We address this gap by introducing GerAV, a comprehensive benchmark for German AV comprising over 600k labeled text pairs. GerAV is built from Twitter and Reddit data, with the Reddit part further divided into in-domain and cross-domain message-based subsets, as well as a profile-based subset. This design enables controlled analysis of the effects of data source, topical domain, and text length. Using the provided training splits, we conduct a systematic evaluation of strong baselines and state-of-the-art models and find that our best approach, a fine-tuned large language model, outperforms recent baselines by up to 0.09 absolute F1 score and surpasses GPT-5 in a zero-shot setting by 0.08. We further observe a trade-off between specialization and generalization: models trained on specific data types perform best under matching conditions but generalize less well across data regimes, a limitation that can be mitigated by combining training sources. Overall, GerAV provides a challenging and versatile benchmark for advancing research on German and cross-domain AV.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u7684\u7efc\u5408\u57fa\u51c6GerAV\uff0c\u5305\u542b\u4e30\u5bcc\u7684\u6570\u636e\u6e90\u548c\u9886\u57df\u5212\u5206\uff0c\u7cfb\u7edf\u8bc4\u6d4b\u4e86\u591a\u79cd\u6a21\u578b\uff0c\u8bc1\u660e\u4e86\u4e00\u4e2a\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u4e0a\u7684\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u4e13\u95e8\u5316\u4e0e\u6cdb\u5316\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u4f5c\u8005\u9a8c\u8bc1\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u82f1\u8bed\uff0c\u7f3a\u5c11\u5927\u89c4\u6a21\u4e14\u7cfb\u7edf\u7684\u5176\u4ed6\u8bed\u8a00\u57fa\u51c6\uff0c\u5c24\u5176\u662f\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u7f3a\u4e4f\u76f8\u5173\u8d44\u6e90\u548c\u7efc\u5408\u8bc4\u6d4b\u3002", "method": "\u6536\u96c6\u4e86\u6765\u81eaTwitter\u548cReddit\u7684\u8d85\u8fc760\u4e07\u6807\u6ce8\u6587\u672c\u5bf9\uff0c\u6784\u5efa\u4e86GerAV\u57fa\u51c6\uff0c\u5305\u62ec\u4e0d\u540c\u6765\u6e90\u548c\u9886\u57df\u7684\u5b50\u96c6\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u57fa\u7ebf\u6a21\u578b\u548c\u5148\u8fdb\u6a21\u578b\u3002", "result": "\u5728\u63d0\u4f9b\u7684\u8bad\u7ec3\u96c6\u4e0a\uff0c\u5fae\u8c03\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cF1\u5206\u6570\u8d85\u8d8a\u4e86\u6700\u65b0\u57fa\u7ebf\u548c\u96f6\u6837\u672cGPT-5\uff0c\u6a21\u578b\u5728\u7279\u5b9a\u6570\u636e\u7c7b\u578b\u4e0a\u8868\u73b0\u51fa\u8272\u4f46\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u7ed3\u5408\u4e0d\u540c\u8bad\u7ec3\u6e90\u53ef\u63d0\u5347\u6cdb\u5316\u8868\u73b0\u3002", "conclusion": "GerAV\u57fa\u51c6\u4e3a\u5fb7\u8bed\u4f5c\u8005\u9a8c\u8bc1\u4efb\u52a1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u4e14\u5177\u6311\u6218\u6027\u7684\u8bc4\u4ef7\u5e73\u53f0\uff0c\u63a8\u52a8\u4e86\u5fb7\u8bed\u53ca\u8de8\u9886\u57df\u4f5c\u8005\u9a8c\u8bc1\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13717", "abs": "https://arxiv.org/abs/2601.13717", "authors": ["Zehan Li", "Yuxuan Wang", "Ali El Lahib", "Ying-Jieh Xia", "Xinyu Pi"], "title": "Simulated Ignorance Fails: A Systematic Study of LLM Behaviors on Forecasting Problems Before Model Knowledge Cutoff", "comment": null, "summary": "Evaluating LLM forecasting capabilities is constrained by a fundamental tension: prospective evaluation offers methodological rigor but prohibitive latency, while retrospective forecasting (RF) -- evaluating on already-resolved events -- faces rapidly shrinking clean evaluation data as SOTA models possess increasingly recent knowledge cutoffs. Simulated Ignorance (SI), prompting models to suppress pre-cutoff knowledge, has emerged as a potential solution. We provide the first systematic test of whether SI can approximate True Ignorance (TI). Across 477 competition-level questions and 9 models, we find that SI fails systematically: (1) cutoff instructions leave a 52% performance gap between SI and TI; (2) chain-of-thought reasoning fails to suppress prior knowledge, even when reasoning traces contain no explicit post-cutoff references; (3) reasoning-optimized models exhibit worse SI fidelity despite superior reasoning trace quality. These findings demonstrate that prompts cannot reliably \"rewind\" model knowledge. We conclude that RF on pre-cutoff events is methodologically flawed; we recommend against using SI-based retrospective setups to benchmark forecasting capabilities.", "AI": {"tldr": "\u7814\u7a76\u9996\u6b21\u7cfb\u7edf\u68c0\u9a8c\u4e86\u6a21\u62df\u65e0\u77e5\u65b9\u6cd5\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u9884\u6d4b\u80fd\u529b\u4e2d\u7684\u53ef\u9760\u6027\uff0c\u53d1\u73b0\u8be5\u65b9\u6cd5\u5b58\u5728\u663e\u8457\u504f\u5dee\uff0c\u5efa\u8bae\u4e0d\u91c7\u7528\u57fa\u4e8e\u6a21\u62df\u65e0\u77e5\u7684\u56de\u987e\u6027\u9884\u6d4b\u8bc4\u4f30\u3002", "motivation": "\u5728\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u65f6\uff0c\u9762\u4e34\u7740\u524d\u77bb\u6027\u8bc4\u4f30\u65f6\u95f4\u957f\u548c\u57fa\u4e8e\u5df2\u89e3\u51b3\u4e8b\u4ef6\u7684\u56de\u987e\u6027\u9884\u6d4b\u6570\u636e\u8fc5\u901f\u51cf\u5c11\u7684\u77db\u76fe\uff0c\u5e0c\u671b\u9a8c\u8bc1\u7528\u6a21\u62df\u65e0\u77e5\u65b9\u6cd5\u514b\u670d\u8fd9\u4e00\u95ee\u9898\u7684\u6709\u6548\u6027\u3002", "method": "\u901a\u8fc7\u5bf9477\u4e2a\u7ade\u8d5b\u7ea7\u95ee\u9898\u548c9\u4e2a\u6a21\u578b\u8fdb\u884c\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e86SI\u548cTI\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u5206\u6790\u4e86\u622a\u65ad\u6307\u4ee4\u3001\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4ee5\u53ca\u63a8\u7406\u4f18\u5316\u6a21\u578b\u5bf9SI\u5fe0\u5b9e\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0SI\u4e0eTI\u4e4b\u95f4\u5b58\u572852%\u7684\u6027\u80fd\u5dee\u8ddd\uff0c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u672a\u80fd\u6709\u6548\u6291\u5236\u6a21\u578b\u7684\u5148\u9a8c\u77e5\u8bc6\uff0c\u4e14\u63a8\u7406\u4f18\u5316\u6a21\u578b\u5c3d\u7ba1\u751f\u6210\u9ad8\u8d28\u91cf\u63a8\u7406\u75d5\u8ff9\uff0c\u5374\u8868\u73b0\u51fa\u66f4\u5dee\u7684SI\u5fe0\u5b9e\u5ea6\u3002", "conclusion": "\u8be5\u7814\u7a76\u53d1\u73b0\u6a21\u62df\u65e0\u77e5\uff08SI\uff09\u65b9\u6cd5\u65e0\u6cd5\u51c6\u786e\u6a21\u62df\u771f\u5b9e\u65e0\u77e5\uff08TI\uff09\uff0c\u63d0\u793a\u57fa\u4e8eSI\u7684\u56de\u987e\u6027\u9884\u6d4b\u8bc4\u4f30\u5b58\u5728\u7cfb\u7edf\u6027\u8bef\u5dee\uff0c\u5bfc\u81f4\u65e0\u6cd5\u53ef\u9760\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u80fd\u529b\u3002"}}
{"id": "2601.13722", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13722", "abs": "https://arxiv.org/abs/2601.13722", "authors": ["Yulin Hu", "Zimo Long", "Jiahe Guo", "Xingyu Sui", "Xing Fu", "Weixiang Zhao", "Yanyan Zhao", "Bing Qin"], "title": "OP-Bench: Benchmarking Over-Personalization for Memory-Augmented Personalized Conversational Agents", "comment": null, "summary": "Memory-augmented conversational agents enable personalized interactions using long-term user memory and have gained substantial traction. However, existing benchmarks primarily focus on whether agents can recall and apply user information, while overlooking whether such personalization is used appropriately. In fact, agents may overuse personal information, producing responses that feel forced, intrusive, or socially inappropriate to users. We refer to this issue as \\emph{over-personalization}. In this work, we formalize over-personalization into three types: Irrelevance, Repetition, and Sycophancy, and introduce \\textbf{OP-Bench} a benchmark of 1,700 verified instances constructed from long-horizon dialogue histories. Using \\textbf{OP-Bench}, we evaluate multiple large language models and memory-augmentation methods, and find that over-personalization is widespread when memory is introduced. Further analysis reveals that agents tend to retrieve and over-attend to user memories even when unnecessary. To address this issue, we propose \\textbf{Self-ReCheck}, a lightweight, model-agnostic memory filtering mechanism that mitigates over-personalization while preserving personalization performance. Our work takes an initial step toward more controllable and appropriate personalization in memory-augmented dialogue systems.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u4e86\u8bb0\u5fc6\u589e\u5f3a\u5bf9\u8bdd\u7cfb\u7edf\u4e2d\u5e38\u89c1\u7684\u8fc7\u5ea6\u4e2a\u6027\u5316\u95ee\u9898\uff0c\u63d0\u51fa\u4e86OP-Bench\u6570\u636e\u96c6\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e76\u8bbe\u8ba1Self-ReCheck\u673a\u5236\u6709\u6548\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u5b9e\u73b0\u66f4\u5408\u9002\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u3002", "motivation": "\u5f53\u524d\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u867d\u7136\u5728\u5229\u7528\u7528\u6237\u957f\u671f\u8bb0\u5fc6\u63d0\u5347\u5bf9\u8bdd\u8d28\u91cf\uff0c\u4f46\u4e3b\u8981\u8003\u5bdf\u662f\u5426\u80fd\u56de\u5fc6\u548c\u5e94\u7528\u7528\u6237\u4fe1\u606f\uff0c\u5ffd\u89c6\u4e86\u4e2a\u6027\u5316\u4f7f\u7528\u7684\u9002\u5f53\u6027\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u4e2a\u6027\u5316\u73b0\u8c61\uff0c\u5f71\u54cd\u7528\u6237\u4f53\u9a8c\uff0c\u4e9f\u9700\u5bf9\u6b64\u8fdb\u884c\u7cfb\u7edf\u5316\u7684\u7814\u7a76\u548c\u89e3\u51b3\u65b9\u6848\u8bbe\u8ba1\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b1700\u4e2a\u5b9e\u4f8b\u7684OP-Bench\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u4e86\u4e09\u79cd\u8fc7\u5ea6\u4e2a\u6027\u5316\u7c7b\u578b\uff08Irrelevance, Repetition, Sycophancy\uff09\uff0c\u8bc4\u4f30\u4e86\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ca\u8bb0\u5fc6\u589e\u5f3a\u65b9\u6cd5\uff0c\u5e76\u63d0\u51faSelf-ReCheck\u6a21\u578b\u65e0\u5173\u7684\u8bb0\u5fc6\u8fc7\u6ee4\u673a\u5236\u51cf\u5c11\u8fc7\u5ea6\u4e2a\u6027\u5316\u3002", "result": "\u901a\u8fc7OP-Bench\u8bc4\u6d4b\u53d1\u73b0\uff0c\u968f\u7740\u8bb0\u5fc6\u589e\u5f3a\u5f15\u5165\uff0c\u8fc7\u5ea6\u4e2a\u6027\u5316\u666e\u904d\u5b58\u5728\uff0c\u6a21\u578b\u5f80\u5f80\u4e0d\u5fc5\u8981\u5730\u68c0\u7d22\u5e76\u8fc7\u5ea6\u5173\u6ce8\u7528\u6237\u8bb0\u5fc6\u3002\u4f7f\u7528Self-ReCheck\u673a\u5236\u540e\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u8fc7\u5ea6\u4e2a\u6027\u5316\u53cd\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u4e2a\u6027\u5316\u6027\u80fd\u3002", "conclusion": "\u73b0\u6709\u7684\u4e2a\u6027\u5316\u5bf9\u8bdd\u7cfb\u7edf\u5b58\u5728\u8fc7\u5ea6\u4e2a\u6027\u5316\u95ee\u9898\uff0c\u5373\u5728\u5bf9\u8bdd\u4e2d\u8fc7\u5ea6\u4f7f\u7528\u7528\u6237\u4e2a\u4eba\u4fe1\u606f\uff0c\u5bfc\u81f4\u56de\u590d\u663e\u5f97\u52c9\u5f3a\u3001\u4e0d\u5408\u9002\u751a\u81f3\u5192\u72af\u3002\u672c\u6587\u901a\u8fc7\u63d0\u51faOP-Bench\u6570\u636e\u96c6\u548c\u5206\u6790\u6a21\u578b\u884c\u4e3a\u63ed\u793a\u4e86\u8fd9\u4e00\u95ee\u9898\u7684\u666e\u904d\u6027\uff0c\u5e76\u63d0\u51fa\u4e86Self-ReCheck\u673a\u5236\u6709\u6548\u7f13\u89e3\u8be5\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u4e2a\u6027\u5316\u5bf9\u8bdd\u7684\u9002\u5f53\u6027\u3002"}}
{"id": "2601.13729", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13729", "abs": "https://arxiv.org/abs/2601.13729", "authors": ["Weichuan Wang", "Mingyang Liu", "Linqi Song", "Chen Ma"], "title": "On Temperature-Constrained Non-Deterministic Machine Translation: Potential and Evaluation", "comment": "9 pages, 12 figures", "summary": "In recent years, the non-deterministic properties of language models have garnered considerable attention and have shown a significant influence on real-world applications. However, such properties remain under-explored in machine translation (MT), a complex, non-deterministic NLP task. In this study, we systematically evaluate modern MT systems and identify temperature-constrained Non-Deterministic MT (ND-MT) as a distinct phenomenon. Additionally, we demonstrate that ND-MT exhibits significant potential in addressing the multi-modality issue that has long challenged MT research and provides higher-quality candidates than Deterministic MT (D-MT) under temperature constraints. However, ND-MT introduces new challenges in evaluating system performance. Specifically, the evaluation framework designed for D-MT fails to yield consistent evaluation results when applied to ND-MT. We further investigate this emerging challenge by evaluating five state-of-the-art ND-MT systems across three open datasets using both lexical-based and semantic-based metrics at varying sampling sizes. The results reveal a Buckets effect across these systems: the lowest-quality candidate generated by ND-MT consistently determines the overall system ranking across different sampling sizes for all reasonable metrics. Furthermore, we propose the ExpectoSample strategy to automatically assess the reliability of evaluation metrics for selecting robust ND-MT.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\uff0c\u53d1\u73b0\u5176\u63d0\u5347\u4e86\u7ffb\u8bd1\u8d28\u91cf\u4f46\u5e26\u6765\u4e86\u8bc4\u4f30\u6311\u6218\uff0c\u63d0\u51faExpectoSample\u7b56\u7565\u4ee5\u6539\u8fdb\u8bc4\u4f30\u53ef\u9760\u6027\u3002", "motivation": "\u63a2\u8ba8\u673a\u5668\u7ffb\u8bd1\u4e2d\u975e\u786e\u5b9a\u6027\u5c5e\u6027\u53ca\u5176\u5bf9\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u7684\u5f71\u54cd\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u73b0\u4ee3\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\uff0c\u4f7f\u7528\u8bcd\u6c47\u548c\u8bed\u4e49\u6307\u6807\u5728\u4e0d\u540c\u91c7\u6837\u89c4\u6a21\u4e0b\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5e76\u63d0\u51faExpectoSample\u7b56\u7565\u3002", "result": "\u53d1\u73b0\u6e29\u5ea6\u7ea6\u675f\u4e0b\u7684\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u63d0\u9ad8\u4e86\u5019\u9009\u8d28\u91cf\uff0c\u4f46\u4f20\u7edf\u7684\u786e\u5b9a\u6027\u8bc4\u4f30\u6846\u67b6\u5bf9\u5176\u8bc4\u4f30\u4e0d\u4e00\u81f4\uff0c\u5e76\u63ed\u793a\u4e86\u201cBuckets\u6548\u5e94\u201d\u3002", "conclusion": "\u975e\u786e\u5b9a\u6027\u673a\u5668\u7ffb\u8bd1\u4f5c\u4e3a\u72ec\u7279\u73b0\u8c61\uff0c\u80fd\u6709\u6548\u7f13\u89e3\u591a\u6a21\u6001\u95ee\u9898\uff0c\u4f46\u9700\u8bbe\u8ba1\u65b0\u7684\u8bc4\u4f30\u7b56\u7565\u4ee5\u4fdd\u8bc1\u8bc4\u6d4b\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2601.13734", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13734", "abs": "https://arxiv.org/abs/2601.13734", "authors": ["Chenyu Hui"], "title": "Towards robust long-context understanding of large language model via active recap learning", "comment": "5 pages", "summary": "In this paper, we propose active recap learning (ARL), a framework for enhancing large language model (LLM) in understanding long contexts. ARL enables models to revisit and summarize earlier content through targeted sequence construction during contined pretraining and retrospective summarization at inference. First, we identify key tokens in prepared long context based on loss gaps between long and short forward contexts and find most revant preceding paragraphs, then summarize them using an LLM. Second, ARL equips models with the ability to autonomously generate and utilize these retrospective summaries during inference, thereby establishing a recursive memory mechanism across paragraphs. Experimental results show substantial gains, with ARL achieving a 26.8% improvement on RULER and a 9.44% improvement on LongBench. Overall, ARL offers a simple yet effective continued pretraining-based approach to strengthen long-context understanding, advancing scalable memory augmentation in LLM", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e3b\u52a8\u56de\u987e\u5b66\u4e60\uff0c\u901a\u8fc7\u8bbe\u8ba1\u9488\u5bf9\u6027\u5e8f\u5217\u548c\u751f\u6210\u56de\u987e\u6458\u8981\uff0c\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u957f\u4e0a\u4e0b\u6587\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5b9e\u9a8c\u8868\u73b0\u51fa\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u7406\u89e3\u957f\u4e0a\u4e0b\u6587\u65f6\u5b58\u5728\u6311\u6218\uff0c\u4e9f\u9700\u63d0\u5347\u5176\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e3b\u52a8\u56de\u987e\u5b66\u4e60\uff08ARL\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u5728\u7ee7\u7eed\u9884\u8bad\u7ec3\u4e2d\u6784\u5efa\u9488\u5bf9\u6027\u5e8f\u5217\u548c\u63a8\u7406\u65f6\u7684\u56de\u987e\u6027\u6458\u8981\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u91cd\u65b0\u5ba1\u89c6\u5e76\u603b\u7ed3\u65e9\u671f\u5185\u5bb9\uff0c\u5b9e\u73b0\u6bb5\u843d\u95f4\u7684\u9012\u5f52\u8bb0\u5fc6\u673a\u5236\u3002", "result": "\u5728RULER\u6570\u636e\u96c6\u4e0a\u63d0\u534726.8%\uff0c\u5728LongBench\u4e0a\u63d0\u53479.44%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u6a21\u578b\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\u3002", "conclusion": "ARL\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u57fa\u4e8e\u7ee7\u7eed\u9884\u8bad\u7ec3\u7684\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u80fd\u529b\uff0c\u63a8\u52a8\u4e86\u53ef\u6269\u5c55\u8bb0\u5fc6\u589e\u5f3a\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13742", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13742", "abs": "https://arxiv.org/abs/2601.13742", "authors": ["Arjun Chandra", "Kevin Miller", "Venkatesh Ravichandran", "Constantinos Papayiannis", "Venkatesh Saligrama"], "title": "Dimension-First Evaluation of Speech-to-Speech Models with Structured Acoustic Cues", "comment": "EACL 2026 Findings", "summary": "Large Language Model (LLM) judges exhibit strong reasoning capabilities but are limited to textual content. This leaves current automatic Speech-to-Speech (S2S) evaluation methods reliant on opaque and expensive Audio Language Models (ALMs). In this work, we propose TRACE (Textual Reasoning over Audio Cues for Evaluation), a novel framework that enables LLM judges to reason over audio cues to achieve cost-efficient and human-aligned S2S evaluation. To demonstrate the strength of the framework, we first introduce a Human Chain-of-Thought (HCoT) annotation protocol to improve the diagnostic capability of existing judge benchmarks by separating evaluation into explicit dimensions: content (C), voice quality (VQ), and paralinguistics (P). Using this data, TRACE constructs a textual blueprint of inexpensive audio signals and prompts an LLM to render dimension-wise judgments, fusing them into an overall rating via a deterministic policy. TRACE achieves higher agreement with human raters than ALMs and transcript-only LLM judges while being significantly more cost-effective. We will release the HCoT annotations and the TRACE framework to enable scalable and human-aligned S2S evaluation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faTRACE\u6846\u67b6\uff0c\u4f7fLLM\u57fa\u4e8e\u6587\u672c\u63a8\u7406\u97f3\u9891\u7ebf\u7d22\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u4eba\u7c7b\u4e00\u81f4\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u8bc4\u4ef7\uff0c\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u4e14\u6210\u672c\u66f4\u4f4e\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u8bed\u97f3\u5230\u8bed\u97f3\uff08S2S\uff09\u8bc4\u4ef7\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u6602\u8d35\u4e14\u4e0d\u53ef\u900f\u660e\u7684\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff08ALMs\uff09\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u867d\u7136\u5177\u6709\u5f3a\u5927\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u4ec5\u9650\u4e8e\u6587\u672c\u5185\u5bb9\uff0c\u96be\u4ee5\u5e94\u7528\u4e8eS2S\u8bc4\u4ef7\u3002", "method": "\u63d0\u51fa\u4e86TRACE\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5ec9\u4ef7\u97f3\u9891\u4fe1\u53f7\u7684\u6587\u672c\u84dd\u56fe\uff0c\u4f7fLLM\u80fd\u591f\u57fa\u4e8e\u97f3\u9891\u7ebf\u7d22\u8fdb\u884c\u63a8\u7406\u8bc4\u4ef7\u3002\u5f15\u5165\u4eba\u7c7b\u94fe\u5f0f\u601d\u7ef4\u6ce8\u91ca\u534f\u8bae\uff08HCoT\uff09\uff0c\u5c06\u8bc4\u4ef7\u62c6\u5206\u4e3a\u5185\u5bb9\u3001\u97f3\u8d28\u548c\u526f\u8bed\u8a00\u4e09\u4e2a\u660e\u786e\u7ef4\u5ea6\uff0c\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u9a71\u52a8LLM\u8fdb\u884c\u5206\u7ef4\u5ea6\u5224\u65ad\uff0c\u518d\u901a\u8fc7\u786e\u5b9a\u6027\u7b56\u7565\u878d\u5408\u4e3a\u6574\u4f53\u8bc4\u5206\u3002", "result": "TRACE\u5728\u4e0e\u4eba\u7c7b\u8bc4\u5206\u8005\u7684\u4e00\u81f4\u6027\u65b9\u9762\u4f18\u4e8eALMs\u548c\u4ec5\u57fa\u4e8e\u8f6c\u5f55\u6587\u672c\u7684LLM\u8bc4\u5206\uff0c\u540c\u65f6\u6210\u672c\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "TRACE\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86S2S\u8bc4\u4ef7\u7684\u51c6\u786e\u6027\u548c\u7ecf\u6d4e\u6027\uff0c\u672a\u6765\u53ef\u5b9e\u73b0\u5927\u89c4\u6a21\u4e14\u7b26\u5408\u4eba\u7c7b\u5224\u65ad\u504f\u597d\u7684S2S\u8bc4\u4ef7\u3002\u5c06\u516c\u5f00HCoT\u6ce8\u91ca\u548cTRACE\u6846\u67b6\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u53d1\u5c55\u3002"}}
{"id": "2601.13749", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13749", "abs": "https://arxiv.org/abs/2601.13749", "authors": ["Benaya Trabelsi", "Jonathan Shaki", "Sarit Kraus"], "title": "Pro-AI Bias in Large Language Models", "comment": "13 pages, 6 figures. Code available at: https://github.com/benayat/Pro-AI-bias-in-LLMs", "summary": "Large language models (LLMs) are increasingly employed for decision-support across multiple domains. We investigate whether these models display a systematic preferential bias in favor of artificial intelligence (AI) itself. Across three complementary experiments, we find consistent evidence of pro-AI bias. First, we show that LLMs disproportionately recommend AI-related options in response to diverse advice-seeking queries, with proprietary models doing so almost deterministically. Second, we demonstrate that models systematically overestimate salaries for AI-related jobs relative to closely matched non-AI jobs, with proprietary models overestimating AI salaries more by 10 percentage points. Finally, probing internal representations of open-weight models reveals that ``Artificial Intelligence'' exhibits the highest similarity to generic prompts for academic fields under positive, negative, and neutral framings alike, indicating valence-invariant representational centrality. These patterns suggest that LLM-generated advice and valuation can systematically skew choices and perceptions in high-stakes decisions.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5efa\u8bae\u548c\u4f30\u503c\u4e2d\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u4eb2AI\u504f\u89c1\uff0c\u53ef\u80fd\u5f71\u54cd\u7406\u6027\u51b3\u7b56\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51b3\u7b56\u652f\u6301\u4e2d\u7684\u6f5c\u5728\u504f\u89c1\uff0c\u7279\u522b\u662f\u662f\u5426\u5b58\u5728\u5bf9\u4eba\u5de5\u667a\u80fd\u81ea\u8eab\u7684\u504f\u597d\u3002", "method": "\u901a\u8fc7\u4e09\u9879\u4e92\u8865\u5b9e\u9a8c\uff1a1\uff09\u5206\u6790\u6a21\u578b\u5728\u4e0d\u540c\u54a8\u8be2\u95ee\u9898\u4e2d\u63a8\u8350AI\u76f8\u5173\u9009\u9879\u7684\u9891\u7387\uff1b2\uff09\u6bd4\u8f83\u6a21\u578b\u5bf9AI\u76f8\u5173\u804c\u4f4d\u4e0e\u975eAI\u804c\u4f4d\u7684\u85aa\u8d44\u4f30\u8ba1\uff1b3\uff09\u63a2\u7a76\u5f00\u653e\u6743\u91cd\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u2018\u4eba\u5de5\u667a\u80fd\u2019\u4e0e\u5b66\u672f\u9886\u57df\u63d0\u793a\u7684\u76f8\u4f3c\u5ea6\u3002", "result": "\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u663e\u8457\u504f\u5411\u63a8\u8350AI\u9009\u9879\uff0c\u4e13\u6709\u6a21\u578b\u51e0\u4e4e\u662f\u786e\u5b9a\u6027\u63a8\u8350\uff1b\u5bf9AI\u804c\u4f4d\u85aa\u8d44\u7684\u4f30\u8ba1\u666e\u904d\u504f\u9ad8\uff0c\u4e13\u6709\u6a21\u578b\u66f4\u751a\uff1b\u2018\u4eba\u5de5\u667a\u80fd\u2019\u5728\u6a21\u578b\u5185\u90e8\u8868\u793a\u4e2d\u7ef4\u6301\u9ad8\u76f8\u4f3c\u5ea6\uff0c\u65e0\u5173\u60c5\u611f\u503e\u5411\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u504f\u5411\uff0c\u503e\u5411\u4e8e\u652f\u6301\u4eba\u5de5\u667a\u80fd\u76f8\u5173\u7684\u9009\u9879\u548c\u8bc4\u4ef7\uff0c\u8fd9\u53ef\u80fd\u4f1a\u5f71\u54cd\u91cd\u5927\u51b3\u7b56\u4e2d\u7684\u9009\u62e9\u548c\u8ba4\u77e5\u3002"}}
{"id": "2601.13802", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.13802", "abs": "https://arxiv.org/abs/2601.13802", "authors": ["Yushen Chen", "Junzhe Liu", "Yujie Tu", "Zhikang Niu", "Yuzhe Liang", "Kai Yu", "Chunyu Qiang", "Chen Zhang", "Xie Chen"], "title": "Habibi: Laying the Open-Source Foundation of Unified-Dialectal Arabic Speech Synthesis", "comment": null, "summary": "A notable gap persists in speech synthesis research and development for Arabic dialects, particularly from a unified modeling perspective. Despite its high practical value, the inherent linguistic complexity of Arabic dialects, further compounded by a lack of standardized data, benchmarks, and evaluation guidelines, steers researchers toward safer ground. To bridge this divide, we present Habibi, a suite of specialized and unified text-to-speech models that harnesses existing open-source ASR corpora to support a wide range of high- to low-resource Arabic dialects through linguistically-informed curriculum learning. Our approach outperforms the leading commercial service in generation quality, while maintaining extensibility through effective in-context learning, without requiring text diacritization. We are committed to open-sourcing the model, along with creating the first systematic benchmark for multi-dialect Arabic speech synthesis. Furthermore, by identifying the key challenges in and establishing evaluation standards for the process, we aim to provide a solid groundwork for subsequent research. Resources at https://SWivid.github.io/Habibi/ .", "AI": {"tldr": "\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u591a\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u7f3a\u4e4f\u7edf\u4e00\u6a21\u578b\u548c\u6807\u51c6\u8d44\u6e90\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51faHabibi\u6a21\u578b\uff0c\u901a\u8fc7\u8bfe\u7a0b\u5b66\u4e60\u6709\u6548\u6574\u5408\u591a\u65b9\u8a00\u8bed\u6599\uff0c\u5f00\u521b\u4e86\u9ad8\u8d28\u91cf\u751f\u6210\u548c\u7cfb\u7edf\u8bc4\u6d4b\u7684\u65b0\u5c40\u9762\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u8bed\u97f3\u5408\u6210\u9886\u57df\u5b58\u5728\u7edf\u4e00\u5efa\u6a21\u7f3a\u5931\u3001\u8bed\u8a00\u590d\u6742\u6027\u548c\u7f3a\u5c11\u6807\u51c6\u5316\u6570\u636e\u53ca\u8bc4\u6d4b\u4f53\u7cfb\u7684\u95ee\u9898\uff0c\u963b\u788d\u4e86\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u5229\u7528\u73b0\u6709\u5f00\u6e90\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u8bed\u6599\u5e93\uff0c\u7ed3\u5408\u8bed\u8a00\u5b66\u6307\u5bfc\u7684\u8bfe\u7a0b\u5b66\u4e60\uff0c\u6784\u5efa\u4e13\u95e8\u5316\u4e14\u7edf\u4e00\u7684\u963f\u62c9\u4f2f\u8bed\u591a\u65b9\u8a00\u6587\u672c\u5230\u8bed\u97f3\u6a21\u578b\uff0c\u5b9e\u73b0\u65e0\u6587\u672c\u5143\u97f3\u6807\u6ce8\u7684\u9ad8\u8d28\u91cf\u751f\u6210\u3002", "result": "Habibi\u6a21\u578b\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u8d85\u8fc7\u9886\u5148\u5546\u4e1a\u4ea7\u54c1\uff0c\u652f\u6301\u5e7f\u6cdb\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\uff0c\u5e76\u5177\u5907\u826f\u597d\u6269\u5c55\u6027\uff0c\u540c\u65f6\u5f00\u6e90\u8d44\u6e90\u548c\u8bc4\u6d4b\u6807\u51c6\u63a8\u52a8\u9886\u57df\u53d1\u5c55\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684Habibi\u6a21\u578b\u663e\u8457\u63d0\u5347\u4e86\u591a\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u5408\u6210\u7684\u8d28\u91cf\uff0c\u4f18\u4e8e\u5546\u4e1a\u9886\u5148\u670d\u52a1\uff0c\u5e76\u9996\u6b21\u5efa\u7acb\u4e86\u591a\u65b9\u8a00\u963f\u62c9\u4f2f\u8bed\u8bed\u97f3\u5408\u6210\u7684\u7cfb\u7edf\u57fa\u51c6\u6d4b\u8bd5\u3002"}}
{"id": "2601.13806", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.13806", "abs": "https://arxiv.org/abs/2601.13806", "authors": ["Dezhao Song", "Guglielmo Bonifazi", "Frank Schilder", "Jonathan Richard Schwarz"], "title": "Knowledge Graph-Assisted LLM Post-Training for Enhanced Legal Reasoning", "comment": null, "summary": "LLM post-training has primarily relied on large text corpora and human feedback, without capturing the structure of domain knowledge. This has caused models to struggle dealing with complex reasoning tasks, especially for high-stakes professional domains. In Law, reasoning requires deep understanding of the relations between various legal concepts, a key component missing in current LLM post-training. In this paper, we propose a knowledge graph (KG)-assisted approach for enhancing LLMs' reasoning capability in Legal that is generalizable to other high-stakes domains. We model key legal concepts by following the \\textbf{IRAC} (Issue, Rule, Analysis and Conclusion) framework, and construct a KG with 12K legal cases. We then produce training data using our IRAC KG, and conduct both Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO) with three state-of-the-art (SOTA) LLMs (30B, 49B and 70B), varying architecture and base model family. Our post-trained models obtained better average performance on 4/5 diverse legal benchmarks (14 tasks) than baselines. In particular, our 70B DPO model achieved the best score on 4/6 reasoning tasks, among baselines and a 141B SOTA legal LLM, demonstrating the effectiveness of our KG for enhancing LLMs' legal reasoning capability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u7684\u540e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u7ed3\u5408SFT\u548cDPO\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u63a8\u7406\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u8d85\u8fc7\u4e86\u591a\u4e2a\u57fa\u7ebf\u53ca\u66f4\u5927\u578b\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u77e5\u8bc6\u56fe\u8c31\u8f85\u52a9\u63a8\u7406\u7684\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u540e\u8bad\u7ec3\u4f9d\u8d56\u4e8e\u5927\u89c4\u6a21\u6587\u672c\u548c\u4eba\u7c7b\u53cd\u9988\uff0c\u672a\u80fd\u6355\u6349\u9886\u57df\u77e5\u8bc6\u7ed3\u6784\uff0c\u5bfc\u81f4\u590d\u6742\u63a8\u7406\u5c24\u5176\u662f\u6cd5\u5f8b\u9886\u57df\u7684\u56f0\u96be\u3002", "method": "\u57fa\u4e8e\u6cd5\u5f8b\u9886\u57df\u7684IRAC\u6846\u67b6\u6784\u5efa\u4e86\u77e5\u8bc6\u56fe\u8c31\uff08KG\uff09\uff0c\u7528\u5305\u542b12K\u6cd5\u5f8b\u6848\u4f8b\u7684KG\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u7ed3\u5408\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u4e0e\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u65b9\u6cd5\uff0c\u5bf9\u4e09\u79cd\u4e0d\u540c\u89c4\u6a21\u4e0e\u67b6\u6784\u7684SOTA\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u3002", "result": "\u540e\u8bad\u7ec3\u6a21\u578b\u5728\u591a\u9879\u6cd5\u5f8b\u57fa\u51c6\u6d4b\u8bd5\uff0814\u4e2a\u4efb\u52a1\u4e2d\u76844/5\uff09\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c70B DPO\u6a21\u578b\u57286\u4e2a\u63a8\u7406\u4efb\u52a1\u4e2d4\u4e2a\u53d6\u5f97\u6700\u4f73\u6210\u7ee9\uff0c\u8d85\u8d8a\u4e86\u5305\u62ec141B\u89c4\u6a21SOTA\u6cd5\u5f8bLLM\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86KG\u8f85\u52a9\u65b9\u6cd5\u63d0\u5347\u6cd5\u5f8b\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u57fa\u4e8eIRAC\u6846\u67b6\u7684\u6cd5\u5f8b\u77e5\u8bc6\u56fe\u8c31\u5e76\u7ed3\u5408\u5148\u8fdb\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u9886\u57df\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u8be5\u65b9\u6cd5\u5177\u5907\u63a8\u5e7f\u81f3\u5176\u4ed6\u9ad8\u98ce\u9669\u4e13\u4e1a\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2601.13835", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13835", "abs": "https://arxiv.org/abs/2601.13835", "authors": ["Sam OConnor Russell", "Delphine Charuau", "Naomi Harte"], "title": "The Role of Prosodic and Lexical Cues in Turn-Taking with Self-Supervised Speech Representations", "comment": "Accepted to ICASSP 2026", "summary": "Fluid turn-taking remains a key challenge in human-robot interaction. Self-supervised speech representations (S3Rs) have driven many advances, but it remains unclear whether S3R-based turn-taking models rely on prosodic cues, lexical cues or both. We introduce a vocoder-based approach to control prosody and lexical cues in speech more cleanly than prior work. This allows us to probe the voice-activity projection model, an S3R-based turn-taking model. We find that prediction on prosody-matched, unintelligible noise is similar to accuracy on clean speech. This reveals both prosodic and lexical cues support turn-taking, but either can be used in isolation. Hence, future models may only require prosody, providing privacy and potential performance benefits. When either prosodic or lexical information is disrupted, the model exploits the other without further training, indicating they are encoded in S3Rs with limited interdependence. Results are consistent in CPC-based and wav2vec2.0 S3Rs. We discuss our findings and highlight a number of directions for future work. All code is available to support future research.", "AI": {"tldr": "\u7814\u7a76\u8868\u660e\u4eba\u673a\u5bf9\u8bdd\u4e2d\u7684\u8f6c\u8bdd\u8f6e\u6a21\u578b\u65e2\u80fd\u5229\u7528\u97f5\u5f8b\u4e5f\u80fd\u5229\u7528\u8bcd\u6c47\u7ebf\u7d22\uff0c\u4e14\u4efb\u4e00\u7ebf\u7d22\u5373\u53ef\u5355\u72ec\u652f\u6491\u51c6\u786e\u9884\u6d4b\uff0c\u63d0\u793a\u672a\u6765\u6a21\u578b\u53ef\u4ec5\u7528\u97f5\u5f8b\u4fe1\u606f\u63d0\u5347\u9690\u79c1\u548c\u6027\u80fd\u3002", "motivation": "\u6d41\u7545\u7684\u8f6e\u6d41\u5bf9\u8bdd\u662f\u4eba\u673a\u4ea4\u4e92\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5f53\u524d\u57fa\u4e8e\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u7684\u6a21\u578b\u662f\u5426\u4f9d\u8d56\u97f5\u5f8b\u6216\u8bcd\u6c47\u7ebf\u7d22\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8evocoder\u7684\u65b9\u6cd5\uff0c\u7cbe\u786e\u63a7\u5236\u8bed\u97f3\u4e2d\u7684\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\uff0c\u5bf9\u8bed\u97f3\u6d3b\u52a8\u9884\u6d4b\u6a21\u578b\u8fdb\u884c\u63a2\u7a76\u3002", "result": "\u5728\u97f5\u5f8b\u5339\u914d\u4f46\u5185\u5bb9\u4e0d\u53ef\u61c2\u7684\u566a\u58f0\u4e0a\uff0c\u6a21\u578b\u9884\u6d4b\u51c6\u786e\u7387\u4e0e\u6e05\u6670\u8bed\u97f3\u76f8\u8fd1\uff0c\u4e14\u5728\u7834\u574f\u5176\u4e2d\u4e00\u79cd\u7ebf\u7d22\u65f6\u6a21\u578b\u81ea\u9002\u5e94\u5229\u7528\u53e6\u4e00\u79cd\u7ebf\u7d22\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\uff0c\u8fd9\u8868\u660e\u97f5\u5f8b\u548c\u8bcd\u6c47\u7ebf\u7d22\u5728S3Rs\u4e2d\u7f16\u7801\u72ec\u7acb\u3002", "conclusion": "\u57fa\u4e8e\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u7684\u8f6c\u8bdd\u8f6e\u6a21\u578b\u65e2\u4f9d\u8d56\u97f5\u5f8b\u7ebf\u7d22\u4e5f\u4f9d\u8d56\u8bcd\u6c47\u7ebf\u7d22\uff0c\u4f46\u4efb\u4e00\u7ebf\u7d22\u5747\u53ef\u5355\u72ec\u6709\u6548\uff0c\u8fd9\u4e3a\u672a\u6765\u53ea\u9700\u97f5\u5f8b\u4fe1\u606f\u7684\u9690\u79c1\u53cb\u597d\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2601.13836", "categories": ["cs.CL", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.13836", "abs": "https://arxiv.org/abs/2601.13836", "authors": ["Qian Chen", "Jinlan Fu", "Changsong Li", "See-Kiong Ng", "Xipeng Qiu"], "title": "FutureOmni: Evaluating Future Forecasting from Omni-Modal Context for Multimodal LLMs", "comment": "https://openmoss.github.io/FutureOmni", "summary": "Although Multimodal Large Language Models (MLLMs) demonstrate strong omni-modal perception, their ability to forecast future events from audio-visual cues remains largely unexplored, as existing benchmarks focus mainly on retrospective understanding. To bridge this gap, we introduce FutureOmni, the first benchmark designed to evaluate omni-modal future forecasting from audio-visual environments. The evaluated models are required to perform cross-modal causal and temporal reasoning, as well as effectively leverage internal knowledge to predict future events. FutureOmni is constructed via a scalable LLM-assisted, human-in-the-loop pipeline and contains 919 videos and 1,034 multiple-choice QA pairs across 8 primary domains. Evaluations on 13 omni-modal and 7 video-only models show that current systems struggle with audio-visual future prediction, particularly in speech-heavy scenarios, with the best accuracy of 64.8% achieved by Gemini 3 Flash. To mitigate this limitation, we curate a 7K-sample instruction-tuning dataset and propose an Omni-Modal Future Forecasting (OFF) training strategy. Evaluations on FutureOmni and popular audio-visual and video-only benchmarks demonstrate that OFF enhances future forecasting and generalization. We publicly release all code (https://github.com/OpenMOSS/FutureOmni) and datasets (https://huggingface.co/datasets/OpenMOSS-Team/FutureOmni).", "AI": {"tldr": "\u63d0\u51fa\u4e86FutureOmni\u57fa\u51c6\u548cOFF\u8bad\u7ec3\u7b56\u7565\uff0c\u63d0\u5347\u591a\u6a21\u6001\u6a21\u578b\u5bf9\u89c6\u542c\u4fe1\u606f\u7684\u672a\u6765\u4e8b\u4ef6\u9884\u6d4b\u80fd\u529b\uff0c\u5f25\u8865\u4e86\u8be5\u9886\u57df\u7684\u8bc4\u6d4b\u7a7a\u767d\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u6a21\u578b\u867d\u7136\u5728\u5168\u6a21\u6001\u611f\u77e5\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u672a\u6765\u4e8b\u4ef6\u9884\u6d4b\u7684\u8bc4\u4f30\uff0c\u73b0\u6709\u57fa\u51c6\u591a\u96c6\u4e2d\u4e8e\u56de\u987e\u6027\u7406\u89e3\uff0c\u56e0\u6b64\u4e9f\u9700\u8bbe\u8ba1\u4e13\u95e8\u7528\u4e8e\u89c6\u542c\u672a\u6765\u9884\u6d4b\u7684\u8bc4\u6d4b\u57fa\u51c6\u548c\u6539\u8fdb\u7b56\u7565\u3002", "method": "\u8bbe\u8ba1FutureOmni\u57fa\u51c6\uff0c\u5305\u542b\u89c6\u9891\u548c\u591a\u9009\u95ee\u7b54\uff0c\u91c7\u7528\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u4eba\u7c7b\u5faa\u73af\u6807\u6ce8\uff1b\u63d0\u51faOmni-Modal Future Forecasting (OFF)\u8bad\u7ec3\u7b56\u7565\uff0c\u5e76\u6784\u5efa7K\u6837\u672c\u7684\u6307\u4ee4\u5fae\u8c03\u6570\u636e\u96c6\u8fdb\u884c\u8bad", "result": "FutureOmni\u5305\u542b919\u4e2a\u89c6\u9891\u548c1034\u4e2a\u591a\u9009\u95ee\u7b54\uff0c\u5bf913\u4e2a\u5168\u6a21\u6001\u53ca7\u4e2a\u89c6\u9891\u6a21\u578b\u8bc4\u6d4b\u53d1\u73b0\uff0c\u6700\u9ad8\u51c6\u786e\u7387\u4ec564.8%\uff0c\u8868\u660e\u9884\u6d4b\u96be\u5ea6\u5927\uff1b\u91c7\u7528OFF\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728FutureOmni\u53ca\u5176\u4ed6\u89c6\u542c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u63d0\u5347\u663e\u8457\u3002", "conclusion": "\u5f53\u524d\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u4e8e\u89c6\u542c\u7ebf\u7d22\u8fdb\u884c\u672a\u6765\u4e8b\u4ef6\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4e0d\u8db3\uff0c\u5c24\u5176\u5728\u8bed\u97f3\u5bc6\u96c6\u573a\u666f\u4e2d\u8868\u73b0\u8f83\u5f31\u3002\u901a\u8fc7\u6784\u5efaFutureOmni\u57fa\u51c6\u548c\u63d0\u51faOFF\u8bad\u7ec3\u7b56\u7565\uff0c\u6a21\u578b\u7684\u672a\u6765\u9884\u6d4b\u80fd\u529b\u5f97\u5230\u4e86\u663e\u8457\u63d0\u5347\u3002"}}
{"id": "2601.13876", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13876", "abs": "https://arxiv.org/abs/2601.13876", "authors": ["Unggi Lee", "Jahyun Jeong", "Sunyoung Shin", "Haeun Park", "Jeongsu Moon", "Youngchang Song", "Jaechang Shim", "JaeHwan Lee", "Yunju Noh", "Seungwon Choi", "Ahhyun Kim", "TaeHyeon Kim", "Kyungtae Joo", "Taeyeong Kim", "Gyeonggeon Lee"], "title": "Pedagogical Alignment for Vision-Language-Action Models: A Comprehensive Framework for Data, Architecture, and Evaluation in Education", "comment": null, "summary": "Science demonstrations are important for effective STEM education, yet teachers face challenges in conducting them safely and consistently across multiple occasions, where robotics can be helpful. However, current Vision-Language-Action (VLA) models require substantial computational resources and sacrifice language generation capabilities to maximize efficiency, making them unsuitable for resource-constrained educational settings that require interpretable, explanation-generating systems. We present \\textit{Pedagogical VLA Framework}, a framework that applies pedagogical alignment to lightweight VLA models through four components: text healing to restore language generation capabilities, large language model (LLM) distillation to transfer pedagogical knowledge, safety training for educational environments, and pedagogical evaluation adjusted to science education contexts. We evaluate Pedagogical VLA Framework across five science demonstrations spanning physics, chemistry, biology, and earth science, using an evaluation framework developed in collaboration with science education experts. Our evaluation assesses both task performance (success rate, protocol compliance, efficiency, safety) and pedagogical quality through teacher surveys and LLM-as-Judge assessment. We additionally provide qualitative analysis of generated texts. Experimental results demonstrate that Pedagogical VLA Framework achieves comparable task performance to baseline models while producing contextually appropriate educational explanations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u53ef\u89e3\u91ca\u7684\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u5b89\u5168\u4e14\u4e00\u81f4\u7684\u79d1\u5b66\u6559\u5b66\u6f14\u793a\uff0c\u517c\u987e\u4efb\u52a1\u8868\u73b0\u4e0e\u6559\u5b66\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709VLA\u6a21\u578b\u8ba1\u7b97\u590d\u6742\u4e14\u727a\u7272\u8bed\u8a00\u751f\u6210\uff0c\u96be\u4ee5\u6ee1\u8db3\u9700\u8981\u53ef\u89e3\u91ca\u6559\u5b66\u7cfb\u7edf\u7684\u6559\u80b2\u73af\u5883\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u6587\u672c\u4fee\u590d\u3001\u5927\u8bed\u8a00\u6a21\u578b\u84b8\u998f\u3001\u5b89\u5168\u8bad\u7ec3\u548c\u6559\u5b66\u8bc4\u4f30\u56db\u4e2a\u90e8\u5206\uff0c\u5b9e\u73b0\u5bf9\u8f7b\u91cf\u7ea7\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\u6a21\u578b\u7684\u6559\u5b66\u5bf9\u9f50\u3002", "result": "\u8be5\u6846\u67b6\u5728\u7269\u7406\u3001\u5316\u5b66\u3001\u751f\u7269\u548c\u5730\u7403\u79d1\u5b66\u7b49\u4e94\u4e2a\u79d1\u5b66\u6f14\u793a\u4e2d\u8868\u73b0\u51fa\u4e0e\u57fa\u7ebf\u6a21\u578b\u76f8\u5f53\u7684\u4efb\u52a1\u6267\u884c\u529b\uff0c\u540c\u65f6\u751f\u6210\u4e86\u9002\u5408\u6559\u80b2\u573a\u666f\u7684\u89e3\u91ca\u6587\u672c\u3002", "conclusion": "Pedagogical VLA Framework\u5728\u4fdd\u8bc1\u6267\u884c\u529b\u7684\u540c\u65f6\uff0c\u63d0\u5347\u4e86\u79d1\u5b66\u6f14\u793a\u4e2d\u7684\u6559\u5b66\u89e3\u91ca\u8d28\u91cf\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u6559\u80b2\u73af\u5883\u3002"}}
{"id": "2601.13882", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13882", "abs": "https://arxiv.org/abs/2601.13882", "authors": ["Unggi Lee", "Sookbun Lee", "Heungsoo Choi", "Jinseo Lee", "Haeun Park", "Younghoon Jeon", "Sungmin Cho", "Minju Kang", "Junbo Koh", "Jiyeong Bae", "Minwoo Nam", "Juyeon Eun", "Yeonji Jung", "Yeil Jeong"], "title": "OpenLearnLM Benchmark: A Unified Framework for Evaluating Knowledge, Skill, and Attitude in Educational Large Language Models", "comment": null, "summary": "Large Language Models are increasingly deployed as educational tools, yet existing benchmarks focus on narrow skills and lack grounding in learning sciences. We introduce OpenLearnLM Benchmark, a theory-grounded framework evaluating LLMs across three dimensions derived from educational assessment theory: Knowledge (curriculum-aligned content and pedagogical understanding), Skills (scenario-based competencies organized through a four-level center-role-scenario-subscenario hierarchy), and Attitude (alignment consistency and deception resistance). Our benchmark comprises 124K+ items spanning multiple subjects, educational roles, and difficulty levels based on Bloom's taxonomy. The Knowledge domain prioritizes authentic assessment items from established benchmarks, while the Attitude domain adapts Anthropic's Alignment Faking methodology to detect behavioral inconsistency under varying monitoring conditions. Evaluation of seven frontier models reveals distinct capability profiles: Claude-Opus-4.5 excels in practical skills despite lower content knowledge, while Grok-4.1-fast leads in knowledge but shows alignment concerns. Notably, no single model dominates all dimensions, validating the necessity of multi-axis evaluation. OpenLearnLM provides an open, comprehensive framework for advancing LLM readiness in authentic educational contexts.", "AI": {"tldr": "\u63d0\u51faOpenLearnLM\u57fa\u51c6\uff0c\u57fa\u4e8e\u6559\u80b2\u7406\u8bba\u591a\u7ef4\u5ea6\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5b9e\u6559\u80b2\u573a\u666f\u4e2d\u7684\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u6001\u5ea6\u8868\u73b0\uff0c\u53d1\u73b0\u5404\u6a21\u578b\u80fd\u529b\u4e92\u8865\uff0c\u5f3a\u8c03\u591a\u8f74\u6d4b\u8bc4\u5fc5\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bc4\u591a\u9488\u5bf9\u5355\u4e00\u6280\u80fd\uff0c\u7f3a\u4e4f\u6559\u80b2\u79d1\u5b66\u7406\u8bba\u652f\u6491\uff0c\u96be\u4ee5\u5168\u9762\u53cd\u6620\u6a21\u578b\u5728\u6559\u80b2\u573a\u666f\u4e2d\u7684\u771f\u5b9e\u80fd\u529b\u3002", "method": "\u6784\u5efaOpenLearnLM\u57fa\u51c6\u6d4b\u8bd5\u6846\u67b6\uff0c\u57fa\u4e8e\u6559\u80b2\u8bc4\u4f30\u7406\u8bba\u8bbe\u8ba1\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u6001\u5ea6\u4e09\u5927\u7ef4\u5ea6\uff0c\u6db5\u76d6124K+\u6d4b\u8bc4\u9879\u76ee\uff0c\u7ed3\u5408\u4e86Bloom\u8ba4\u77e5\u5206\u7c7b\u6cd5\u548c\u771f\u5b9e\u8bc4\u6d4b\u9879\u76ee\uff0c\u4e14\u5f15\u5165\u4e86\u884c\u4e3a\u4e00\u81f4\u6027\u68c0\u6d4b\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u8bc4\u6d4b\u4e03\u4e2a\u5148\u8fdb\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u4e0d\u540c\u7ef4\u5ea6\u8868\u73b0\u5dee\u5f02\u660e\u663e\uff0c\u5982Claude-Opus-4.5\u5728\u6280\u80fd\u4e0a\u4f18\u5f02\u4f46\u77e5\u8bc6\u8f83\u5f31\uff0cGrok-4.1-fast\u77e5\u8bc6\u9886\u5148\u4f46\u5b58\u5728\u4e00\u81f4\u6027\u95ee\u9898\u3002", "conclusion": "\u6ca1\u6709\u5355\u4e00\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u3001\u6280\u80fd\u548c\u6001\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u5168\u9762\u9886\u5148\uff0c\u663e\u793a\u4e86\u591a\u7ef4\u8bc4\u4f30\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2601.13885", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13885", "abs": "https://arxiv.org/abs/2601.13885", "authors": ["Esma Balk\u0131r", "Alice Pernthaller", "Marco Basaldella", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Nigel Collier"], "title": "Confident Rankings with Fewer Items: Adaptive LLM Evaluation with Continuous Scores", "comment": null, "summary": "Computerized Adaptive Testing (CAT) has proven effective for efficient LLM evaluation on multiple-choice benchmarks, but modern LLM evaluation increasingly relies on generation tasks where outputs are scored continuously rather than marked correct/incorrect. We present a principled extension of IRT-based adaptive testing to continuous bounded scores (ROUGE, BLEU, LLM-as-a-Judge) by replacing the Bernoulli response distribution with a heteroskedastic normal distribution. Building on this, we introduce an uncertainty aware ranker with adaptive stopping criteria that achieves reliable model ranking while testing as few items and as cheaply as possible. We validate our method on five benchmarks spanning n-gram-based, embedding-based, and LLM-as-judge metrics. Our method uses 2% of the items while improving ranking correlation by 0.12 \u03c4 over random sampling, with 95% accuracy on confident predictions.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86IRT\u81ea\u9002\u5e94\u6d4b\u8bd5\u4ee5\u9002\u5e94\u751f\u6210\u4efb\u52a1\u7684\u8fde\u7eed\u8bc4\u5206\uff0c\u901a\u8fc7\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\u5efa\u6a21\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u51c6\u786e\u7684LLM\u6a21\u578b\u8bc4\u4ef7\u3002", "motivation": "\u4f20\u7edfCAT\u4e3b\u8981\u9488\u5bf9\u9009\u62e9\u9898\u7684\u6b63\u786e/\u9519\u8bef\u8bc4\u5206\uff0c\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u4ef7\u8d8b\u5411\u4e8e\u751f\u6210\u4efb\u52a1\uff0c\u5176\u8f93\u51fa\u5f97\u5206\u662f\u8fde\u7eed\u503c\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u9ad8\u6548\u51c6\u786e\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5c06\u4f20\u7edfIRT\u6a21\u578b\u4e2d\u7684\u4f2f\u52aa\u5229\u5206\u5e03\u66ff\u6362\u4e3a\u5f02\u65b9\u5dee\u6b63\u6001\u5206\u5e03\uff0c\u5b9e\u73b0\u4e86\u5bf9\u8fde\u7eed\u6709\u754c\u5f97\u5206\uff08\u5982ROUGE\u3001BLEU\u7b49\uff09\u7684\u81ea\u9002\u5e94\u6d4b\u8bd5\uff0c\u5e76\u7ed3\u5408\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u6392\u5e8f\u5668\u548c\u81ea\u9002\u5e94\u505c\u6b62\u51c6\u5219\u3002", "result": "\u5728\u4e94\u4e2a\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0c\u65b9\u6cd5\u4ec5\u4f7f\u75282%\u7684\u6d4b\u8bd5\u6761\u76ee\uff0c\u6392\u540d\u76f8\u5173\u6027\u63d0\u53470.12\u03c4\uff0c\u4e14\u5728\u7f6e\u4fe1\u9884\u6d4b\u4e2d\u8fbe\u523095%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u63d0\u9ad8\u6d4b\u8bd5\u6548\u7387\u548c\u6548\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u57fa\u4e8eIRT\u7684\u8fde\u7eed\u5f97\u5206\u81ea\u9002\u5e94\u6d4b\u8bd5\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u6392\u540d\u7684\u51c6\u786e\u6027\u548c\u6d4b\u8bd5\u6548\u7387\u3002"}}
{"id": "2601.13918", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13918", "abs": "https://arxiv.org/abs/2601.13918", "authors": ["Yusheng Liao", "Chuan Xuan", "Yutong Cai", "Lina Yang", "Zhe Chen", "Yanfeng Wang", "Yu Wang"], "title": "AgentEHR: Advancing Autonomous Clinical Decision-Making via Retrospective Summarization", "comment": "37 pages, 12 figures", "summary": "Large Language Models have demonstrated profound utility in the medical domain. However, their application to autonomous Electronic Health Records~(EHRs) navigation remains constrained by a reliance on curated inputs and simplified retrieval tasks. To bridge the gap between idealized experimental settings and realistic clinical environments, we present AgentEHR. This benchmark challenges agents to execute complex decision-making tasks, such as diagnosis and treatment planning, requiring long-range interactive reasoning directly within raw and high-noise databases. In tackling these tasks, we identify that existing summarization methods inevitably suffer from critical information loss and fractured reasoning continuity. To address this, we propose RetroSum, a novel framework that unifies a retrospective summarization mechanism with an evolving experience strategy. By dynamically re-evaluating interaction history, the retrospective mechanism prevents long-context information loss and ensures unbroken logical coherence. Additionally, the evolving strategy bridges the domain gap by retrieving accumulated experience from a memory bank. Extensive empirical evaluations demonstrate that RetroSum achieves performance gains of up to 29.16% over competitive baselines, while significantly decreasing total interaction errors by up to 92.3%.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u56de\u987e\u6027\u603b\u7ed3\u548c\u7ecf\u9a8c\u6f14\u8fdb\u7684\u65b0\u6846\u67b6RetroSum\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u533b\u7597\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u5bfc\u822a\u4e2d\u7684\u51b3\u7b56\u80fd\u529b\u548c\u63a8\u7406\u8fde\u8d2f\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u9886\u57df\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u81ea\u4e3b\u5bfc\u822a\u4efb\u52a1\u4e2d\uff0c\u53d7\u5230\u5bf9\u6574\u7406\u8f93\u5165\u548c\u7b80\u5316\u68c0\u7d22\u4efb\u52a1\u7684\u4f9d\u8d56\uff0c\u5b58\u5728\u4fe1\u606f\u4e22\u5931\u548c\u63a8\u7406\u8fde\u8d2f\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u6ee1\u8db3\u73b0\u5b9e\u4e34\u5e8a\u73af\u5883\u4e0b\u590d\u6742\u51b3\u7b56\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86RetroSum\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u56de\u987e\u6027\u603b\u7ed3\u673a\u5236\u548c\u52a8\u6001\u7ecf\u9a8c\u6f14\u8fdb\u7b56\u7565\uff0c\u901a\u8fc7\u91cd\u65b0\u8bc4\u4f30\u4e92\u52a8\u5386\u53f2\u548c\u5229\u7528\u8bb0\u5fc6\u5e93\u4e2d\u7684\u79ef\u7d2f\u7ecf\u9a8c\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u957f\u671f\u63a8\u7406\u80fd\u529b\u548c\u9886\u57df\u9002\u5e94\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cRetroSum\u5728\u6027\u80fd\u4e0a\u76f8\u6bd4\u7ade\u4e89\u57fa\u7ebf\u63d0\u5347\u6700\u9ad8\u8fbe29.16%\uff0c\u4e14\u603b\u4ea4\u4e92\u9519\u8bef\u964d\u4f4e\u6700\u9ad8\u8fbe92.3%\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u8bca\u65ad\u548c\u6cbb\u7597\u89c4\u5212\u7b49\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u6267\u884c\u6548\u679c\u3002", "conclusion": "RetroSum\u6846\u67b6\u901a\u8fc7\u56de\u987e\u6027\u603b\u7ed3\u673a\u5236\u548c\u7ecf\u9a8c\u6f14\u8fdb\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u4fe1\u606f\u4e22\u5931\u548c\u903b\u8f91\u8fde\u8d2f\u6027\u65ad\u88c2\u95ee\u9898\uff0c\u4ece\u800c\u663e\u8457\u63d0\u5347\u4e86\u5728\u590d\u6742\u533b\u7597\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u81ea\u4e3b\u5bfc\u822a\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2601.13919", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.13919", "abs": "https://arxiv.org/abs/2601.13919", "authors": ["Yuezhe Yang", "Hao Wang", "Yige Peng", "Jinman Kim", "Lei Bi"], "title": "HyperWalker: Dynamic Hypergraph-Based Deep Diagnosis for Multi-Hop Clinical Modeling across EHR and X-Ray in Medical VLMs", "comment": "Under Review", "summary": "Automated clinical diagnosis remains a core challenge in medical AI, which usually requires models to integrate multi-modal data and reason across complex, case-specific contexts. Although recent methods have advanced medical report generation (MRG) and visual question answering (VQA) with medical vision-language models (VLMs), these methods, however, predominantly operate under a sample-isolated inference paradigm, as such processing cases independently without access to longitudinal electronic health records (EHRs) or structurally related patient examples. This paradigm limits reasoning to image-derived information alone, which ignores external complementary medical evidence for potentially more accurate diagnosis. To overcome this limitation, we propose \\textbf{HyperWalker}, a \\textit{Deep Diagnosis} framework that reformulates clinical reasoning via dynamic hypergraphs and test-time training. First, we construct a dynamic hypergraph, termed \\textbf{iBrochure}, to model the structural heterogeneity of EHR data and implicit high-order associations among multimodal clinical information. Within this hypergraph, a reinforcement learning agent, \\textbf{Walker}, navigates to and identifies optimal diagnostic paths. To ensure comprehensive coverage of diverse clinical characteristics in test samples, we incorporate a \\textit{linger mechanism}, a multi-hop orthogonal retrieval strategy that iteratively selects clinically complementary neighborhood cases reflecting distinct clinical attributes. Experiments on MRG with MIMIC and medical VQA on EHRXQA demonstrate that HyperWalker achieves state-of-the-art performance. Code is available at: https://github.com/Bean-Young/HyperWalker", "AI": {"tldr": "\u63d0\u51faHyperWalker\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8d85\u56fe\u548c\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u7ed3\u5408\u591a\u6a21\u6001\u533b\u7597\u6570\u636e\u53ca\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u4e34\u5e8a\u8bca\u65ad\u7684\u51c6\u786e\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u533b\u7597\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u591a\u5728\u6837\u672c\u5b64\u7acb\u7684\u63a8\u65ad\u8303\u5f0f\u4e0b\u5de5\u4f5c\uff0c\u5ffd\u89c6\u4e86\u7eb5\u5411\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u7ed3\u6784\u76f8\u5173\u75c5\u4f8b\uff0c\u5bfc\u81f4\u63a8\u7406\u4ec5\u57fa\u4e8e\u56fe\u50cf\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u8bca\u65ad\u7684\u51c6\u786e\u6027\u3002", "method": "\u6784\u5efa\u52a8\u6001\u8d85\u56feiBrochure\u8868\u793a\u7ed3\u6784\u5f02\u6784\u7684EHR\u6570\u636e\u53ca\u591a\u6a21\u6001\u4e34\u5e8a\u4fe1\u606f\u7684\u9ad8\u9636\u5173\u8054\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406Walker\u5728\u8d85\u56fe\u4e2d\u5bfc\u822a\u4ee5\u5bfb\u627e\u6700\u4f73\u8bca\u65ad\u8def\u5f84\uff0c\u7ed3\u5408\u591a\u8df3\u6b63\u4ea4\u68c0\u7d22\u7684linger\u673a\u5236\u9009\u53d6\u4e34\u5e8a\u4e92\u8865\u90bb\u8fd1\u75c5\u4f8b\u5b9e\u73b0\u5168\u9762\u63a8\u7406\u3002", "result": "\u5728MIMIC\u533b\u5b66\u62a5\u544a\u751f\u6210\u548cEHRXQA\u533b\u7597\u89c6\u89c9\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cHyperWalker\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u5176\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "HyperWalker\u901a\u8fc7\u52a8\u6001\u8d85\u56fe\u548c\u6d4b\u8bd5\u65f6\u8bad\u7ec3\u91cd\u5851\u4e86\u4e34\u5e8a\u63a8\u7406\u6a21\u578b\uff0c\u6709\u6548\u6574\u5408\u957f\u671f\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u548c\u591a\u6a21\u6001\u4e34\u5e8a\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u533b\u5b66\u62a5\u544a\u751f\u6210\u548c\u533b\u7597\u89c6\u89c9\u95ee\u7b54\u7684\u6027\u80fd\u3002"}}
{"id": "2601.13922", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13922", "abs": "https://arxiv.org/abs/2601.13922", "authors": ["Adrian Cosma", "Oleg Szehr", "David Kletz", "Alessandro Antonucci", "Olivier Pelletier"], "title": "Automatic Prompt Optimization for Dataset-Level Feature Discovery", "comment": "5 Figures, 1 Table", "summary": "Feature extraction from unstructured text is a critical step in many downstream classification pipelines, yet current approaches largely rely on hand-crafted prompts or fixed feature schemas. We formulate feature discovery as a dataset-level prompt optimization problem: given a labelled text corpus, the goal is to induce a global set of interpretable and discriminative feature definitions whose realizations optimize a downstream supervised learning objective. To this end, we propose a multi-agent prompt optimization framework in which language-model agents jointly propose feature definitions, extract feature values, and evaluate feature quality using dataset-level performance and interpretability feedback. Instruction prompts are iteratively refined based on this structured feedback, enabling optimization over prompts that induce shared feature sets rather than per-example predictions. This formulation departs from prior prompt optimization methods that rely on per-sample supervision and provides a principled mechanism for automatic feature discovery from unstructured text.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\uff0c\u81ea\u52a8\u4ece\u975e\u7ed3\u6784\u6587\u672c\u4e2d\u53d1\u73b0\u5168\u5c40\u5171\u4eab\u7684\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u63d0\u5347\u4e86\u6587\u672c\u5206\u7c7b\u7684\u7279\u5f81\u63d0\u53d6\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u7279\u5f81\u63d0\u53d6\u591a\u4f9d\u8d56\u624b\u5de5\u6784\u9020\u7684\u63d0\u793a\u6216\u56fa\u5b9a\u7279\u5f81\u6a21\u5f0f\uff0c\u7f3a\u4e4f\u81ea\u52a8\u53d1\u73b0\u9002\u7528\u4e8e\u6574\u4e2a\u6570\u636e\u96c6\u7684\u5168\u5c40\u7279\u5f81\u7684\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8bed\u8a00\u6a21\u578b\u8054\u5408\u63d0\u51fa\u7279\u5f81\u5b9a\u4e49\u3001\u63d0\u53d6\u7279\u5f81\u503c\u3001\u5e76\u57fa\u4e8e\u6570\u636e\u96c6\u7ea7\u6027\u80fd\u548c\u89e3\u91ca\u6027\u53cd\u9988\u8bc4\u4f30\u7279\u5f81\u8d28\u91cf\uff0c\u8fed\u4ee3\u4f18\u5316\u63d0\u793a\u8bed\u4ee5\u53d1\u73b0\u5171\u4eab\u7279\u5f81\u96c6\u5408\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u7a81\u7834\u4e86\u4ee5\u5f80\u4f9d\u8d56\u6837\u672c\u7ea7\u76d1\u7763\u7684\u63d0\u793a\u4f18\u5316\u65b9\u5f0f\uff0c\u5b9e\u73b0\u4e86\u57fa\u4e8e\u6570\u636e\u96c6\u53cd\u9988\u7684\u63d0\u793a\u8fed\u4ee3\u548c\u5168\u5c40\u7279\u5f81\u53d1\u73b0\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u63d0\u793a\u4f18\u5316\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u4ece\u975e\u7ed3\u6784\u6587\u672c\u4e2d\u81ea\u52a8\u53d1\u73b0\u5168\u5c40\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u533a\u5206\u6027\u7684\u7279\u5f81\uff0c\u4f18\u5316\u4e0b\u6e38\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u3002"}}
{"id": "2601.13992", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.13992", "abs": "https://arxiv.org/abs/2601.13992", "authors": ["Jin Cui", "Jiaqi Guo", "Jiepeng Zhou", "Ruixuan Yang", "Jiayi Lu", "Jiajun Xu", "Jiangcheng Song", "Boran Zhao", "Pengju Ren"], "title": "\"The Whole Is Greater Than the Sum of Its Parts\": A Compatibility-Aware Multi-Teacher CoT Distillation Framework", "comment": "11pages, 9figures", "summary": "Chain-of-Thought (CoT) reasoning empowers Large Language Models (LLMs) with remarkable capabilities but typically requires prohibitive parameter scales. CoT distillation has emerged as a promising paradigm to transfer reasoning prowess into compact Student Models (SLMs), but existing approaches often rely on a solitary teacher, capping the student's potential since individual LLMs often exhibit distinct capability biases and may suffer from catastrophic forgetting. While leveraging diverse teachers seems appealing, effectively fusing their supervisions remains challenging: teacher-student incompatibility risks amplifying hallucinations, and passive supervision fails to ensure genuine logic internalization. To address this, we introduce COMPACT, a framework that adaptively fuses supervisions from different teachers by dynamically weighting teacher gradients based on the student's real-time compatibility evaluated by a multi-dimensional metric: (1) Graph-based Consensus to filter misleading rationales by identifying mainstream reasoning paths; (2) Mutual-Information-based Adaptability to detect \"epiphany moments\" for genuinely understanding the reasoning process rather than merely imitating; and (3) Loss-based Difficulty to assess student receptivity to the teacher's guidance and prevent negative transfer. Extensive experiments and latent space analysis demonstrate that COMPACT effectively integrates diverse reasoning capabilities without damaging the model's original knowledge structure, achieving state-of-the-art performance on various benchmarks while mitigating catastrophic forgetting.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCOMPACT\uff0c\u901a\u8fc7\u52a8\u6001\u52a0\u6743\u673a\u5236\u81ea\u9002\u5e94\u878d\u5408\u591a\u6559\u5e08\u6307\u5bfc\uff0c\u6709\u6548\u63d0\u5347\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u5e76\u51cf\u5c11\u707e\u96be\u6027\u9057\u5fd8\uff0c\u5b9e\u73b0\u4e86\u591a\u9879\u57fa\u51c6\u4e0a\u7684\u6700\u597d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684CoT\u84b8\u998f\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5355\u4e00\u6559\u5e08\u6a21\u578b\uff0c\u9650\u5236\u4e86\u5b66\u751f\u6a21\u578b\u7684\u53d1\u5c55\u6f5c\u529b\uff0c\u540c\u65f6\u4e0d\u540c\u6559\u5e08\u6a21\u578b\u5b58\u5728\u80fd\u529b\u504f\u5dee\uff0c\u4e14\u5b66\u751f\u6a21\u578b\u53ef\u80fd\u4f1a\u51fa\u73b0\u707e\u96be\u6027\u9057\u5fd8\u3002\u4f7f\u7528\u591a\u6559\u5e08\u76d1\u7763\u867d\u7136\u6709\u5438\u5f15\u529b\uff0c\u4f46\u5982\u4f55\u6709\u6548\u878d\u5408\u591a\u6559\u5e08\u7684\u6307\u5bfc\u4ecd\u5177\u6311\u6218\uff0c\u5b58\u5728\u6a21\u578b\u4e0d\u517c\u5bb9\u548c\u903b\u8f91\u771f\u6b63\u5185\u5316\u96be\u9898\u3002", "method": "\u63d0\u51faCOMPACT\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u52a0\u6743\u6559\u5e08\u68af\u5ea6\uff0c\u5b9e\u73b0\u591a\u6559\u5e08\u76d1\u7763\u7684\u81ea\u9002\u5e94\u878d\u5408\u3002\u8be5\u65b9\u6cd5\u8bc4\u4f30\u5b66\u751f\u4e0e\u6559\u5e08\u7684\u517c\u5bb9\u6027\uff0c\u4f9d\u636e\u591a\u7ef4\u6307\u6807\u5305\u62ec\u57fa\u4e8e\u56fe\u7684\u5171\u8bc6\uff08\u8fc7\u6ee4\u8bef\u5bfc\u6027\u63a8\u7406\u8def\u5f84\uff09\u3001\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u9002\u5e94\u6027\uff08\u68c0\u6d4b\u771f\u6b63\u7406\u89e3\u65f6\u523b\uff09\uff0c\u4ee5\u53ca\u57fa\u4e8e\u635f\u5931\u7684\u96be\u5ea6\uff08\u9632\u6b62\u8d1f\u8fc1\u79fb\uff09\u3002", "result": "\u5b9e\u9a8c\u53ca\u6f5c\u7a7a\u95f4\u5206\u6790\u663e\u793aCOMPACT\u80fd\u6709\u6548\u6574\u5408\u591a\u79cd\u63a8\u7406\u80fd\u529b\uff0c\u907f\u514d\u635f\u5bb3\u6a21\u578b\u539f\u6709\u77e5\u8bc6\u7ed3\u6784\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u8868\u73b0\uff0c\u5e76\u7f13\u89e3\u4e86\u707e\u96be\u6027\u9057\u5fd8\u3002", "conclusion": "COMPACT\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u6559\u5e08\u63a8\u7406\u76d1\u7763\u7684\u81ea\u9002\u5e94\u878d\u5408\uff0c\u63d0\u5347\u4e86\u5b66\u751f\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u7a33\u5b9a\u6027\uff0c\u7a81\u7834\u4e86\u5355\u4e00\u6559\u5e08\u9650\u5236\uff0c\u4fc3\u8fdb\u4e86CoT\u84b8\u998f\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.13995", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.13995", "abs": "https://arxiv.org/abs/2601.13995", "authors": ["Zihan Niu", "Wenping Hu", "Junmin Chen", "Xiyue Wang", "Tong Xu", "Ruiming Tang"], "title": "From Tags to Trees: Structuring Fine-Grained Knowledge for Controllable Data Selection in LLM Instruction Tuning", "comment": null, "summary": "Effective and controllable data selection is critical for LLM instruction tuning, especially with massive open-source datasets. Existing approaches primarily rely on instance-level quality scores, or diversity metrics based on embedding clusters or semantic tags. However, constrained by the flatness of embedding spaces or the coarseness of tags, these approaches overlook fine-grained knowledge and its intrinsic hierarchical dependencies, consequently hindering precise data valuation and knowledge-aligned sampling. To address this challenge, we propose Tree-aware Aligned Global Sampling (TAGS), a unified framework that leverages a knowledge tree built from fine-grained tags, thereby enabling joint control of global quality, diversity, and target alignment. Using an LLM-based tagger, we extract atomic knowledge concepts, which are organized into a global tree through bottom-up hierarchical clustering. By grounding data instances onto this tree, a tree-aware metric then quantifies data quality and diversity, facilitating effective sampling. Our controllable sampling strategy maximizes tree-level information gain and enforces leaf-level alignment via KL-divergence for specific domains. Extensive experiments demonstrate that TAGS significantly outperforms state-of-the-art baselines. Notably, it surpasses the full-dataset model by \\textbf{+5.84\\%} using only \\textbf{5\\%} of the data, while our aligned sampling strategy further boosts average performance by \\textbf{+4.24\\%}.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6811\u7684TAGS\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u7ea7\u7ed3\u6784\u5b9e\u73b0\u7cbe\u786e\u6570\u636e\u91c7\u6837\uff0c\u663e\u8457\u63d0\u5347LLM\u6307\u4ee4\u5fae\u8c03\u6548\u679c\uff0c\u8282\u7701\u6570\u636e\u91cf\u5e76\u589e\u5f3a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u57fa\u4e8e\u5e73\u9762\u5d4c\u5165\u6216\u7c97\u7c92\u5ea6\u6807\u7b7e\uff0c\u5ffd\u89c6\u4e86\u77e5\u8bc6\u7684\u7ec6\u7c92\u5ea6\u5c42\u7ea7\u4f9d\u8d56\uff0c\u5bfc\u81f4\u6570\u636e\u8bc4\u4f30\u4e0e\u91c7\u6837\u4e0d\u80fd\u7cbe\u51c6\u5339\u914d\u76ee\u6807\u77e5\u8bc6\uff0c\u5f71\u54cd\u6a21\u578b\u5fae\u8c03\u6548\u679c\u3002", "method": "\u5229\u7528LLM\u6807\u6ce8\u5668\u63d0\u53d6\u7ec6\u7c92\u5ea6\u77e5\u8bc6\u6982\u5ff5\uff0c\u6784\u5efa\u81ea\u5e95\u5411\u4e0a\u7684\u5c42\u7ea7\u77e5\u8bc6\u6811\uff0c\u57fa\u4e8e\u8be5\u6811\u8bbe\u8ba1\u6811\u611f\u77e5\u6570\u636e\u8d28\u91cf\u4e0e\u591a\u6837\u6027\u5ea6\u91cf\uff0c\u7ed3\u5408KL\u6563\u5ea6\u5b9e\u73b0\u76ee\u6807\u57df\u5bf9\u9f50\uff0c\u5236\u5b9a\u6811\u7ea7\u4fe1\u606f\u589e\u76ca\u6700\u5927\u5316\u7684\u53ef\u63a7\u91c7\u6837\u7b56\u7565\u3002", "result": "TAGS\u5728\u591a\u9879\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4f7f\u75285%\u6570\u636e\u5373\u53ef\u8d85\u8fc7\u5168\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b5.84%\u7684\u6027\u80fd\uff0c\u4e14\u5bf9\u9f50\u91c7\u6837\u7b56\u7565\u5e26\u6765\u989d\u59164.24%\u7684\u63d0\u5347\u3002", "conclusion": "TAGS\u65b9\u6cd5\u901a\u8fc7\u77e5\u8bc6\u6811\u548c\u6811\u611f\u77e5\u7684\u91c7\u6837\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u6570\u636e\u96c6\u7684\u6307\u4ee4\u5fae\u8c03\u6548\u679c\uff0c\u5b9e\u73b0\u4e86\u5c11\u91cf\u6570\u636e\u4e0b\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002"}}
{"id": "2601.14004", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14004", "abs": "https://arxiv.org/abs/2601.14004", "authors": ["Hengyuan Zhang", "Zhihao Zhang", "Mingyang Wang", "Zunhai Su", "Yiwei Wang", "Qianli Wang", "Shuzhou Yuan", "Ercong Nie", "Xufeng Duan", "Qibo Xue", "Zeping Yu", "Chenming Shang", "Xiao Liang", "Jing Xiong", "Hui Shen", "Chaofan Tao", "Zhengwu Liu", "Senjie Jin", "Zhiheng Xi", "Dongdong Zhang", "Sophia Ananiadou", "Tao Gui", "Ruobing Xie", "Hayden Kwok-Hay So", "Hinrich Sch\u00fctze", "Xuanjing Huang", "Qi Zhang", "Ngai Wong"], "title": "Locate, Steer, and Improve: A Practical Survey of Actionable Mechanistic Interpretability in Large Language Models", "comment": null, "summary": "Mechanistic Interpretability (MI) has emerged as a vital approach to demystify the opaque decision-making of Large Language Models (LLMs). However, existing reviews primarily treat MI as an observational science, summarizing analytical insights while lacking a systematic framework for actionable intervention. To bridge this gap, we present a practical survey structured around the pipeline: \"Locate, Steer, and Improve.\" We formally categorize Localizing (diagnosis) and Steering (intervention) methods based on specific Interpretable Objects to establish a rigorous intervention protocol. Furthermore, we demonstrate how this framework enables tangible improvements in Alignment, Capability, and Efficiency, effectively operationalizing MI as an actionable methodology for model optimization. The curated paper list of this work is available at https://github.com/rattlesnakey/Awesome-Actionable-MI-Survey.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u5b9e\u7528\u7684\u673a\u68b0\u89e3\u91ca\u6027\u4f53\u7cfb\uff0c\u5c06\u5b9a\u4f4d\u8bca\u65ad\u4e0e\u5e72\u9884\u7ed3\u5408\uff0c\u4fc3\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4f18\u5316\u548c\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u673a\u68b0\u89e3\u91ca\u6027(MI)\u7814\u7a76\u4e3b\u8981\u505c\u7559\u5728\u89c2\u5bdf\u6027\u79d1\u5b66\u9636\u6bb5\uff0c\u7f3a\u4e4f\u53ef\u6267\u884c\u7684\u5e72\u9884\u4f53\u7cfb\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u201c\u5b9a\u4f4d\u3001\u5f15\u5bfc\u548c\u63d0\u5347\u201d\u6d41\u7a0b\u7684\u7cfb\u7edf\u8c03\u7814\u6846\u67b6\uff0c\u5206\u7c7b\u5c40\u90e8\u8bca\u65ad\u4e0e\u5e72\u9884\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u53ef\u89e3\u91ca\u5bf9\u8c61\u5efa\u7acb\u4e25\u683c\u7684\u5e72\u9884\u534f\u8bae\u3002", "result": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u5bf9\u9f50\u6027\u3001\u80fd\u529b\u548c\u6548\u7387\uff0c\u5b9e\u73b0\u4e86MI\u7684\u53ef\u64cd\u4f5c\u6027\u65b9\u6cd5\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u7cfb\u7edf\u5e72\u9884\u6846\u67b6\uff0cMI\u4ece\u89c2\u5bdf\u6027\u7814\u7a76\u8f6c\u53d8\u4e3a\u53ef\u6267\u884c\u7684\u6a21\u578b\u4f18\u5316\u5de5\u5177\uff0c\u63a8\u52a8\u4e86LLM\u7684\u5b9e\u9645\u6539\u8fdb\u3002"}}
{"id": "2601.14007", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14007", "abs": "https://arxiv.org/abs/2601.14007", "authors": ["Junyu Zhang", "Yipeng Kang", "Jiong Guo", "Jiayu Zhan", "Junqi Wang"], "title": "BACH-V: Bridging Abstract and Concrete Human-Values in Large Language Models", "comment": "34 pagess, 16 figures, 6 tables, submitted to ACL 2026", "summary": "Do large language models (LLMs) genuinely understand abstract concepts, or merely manipulate them as statistical patterns? We introduce an abstraction-grounding framework that decomposes conceptual understanding into three capacities: interpretation of abstract concepts (Abstract-Abstract, A-A), grounding of abstractions in concrete events (Abstract-Concrete, A-C), and application of abstract principles to regulate concrete decisions (Concrete-Concrete, C-C). Using human values as a testbed - given their semantic richness and centrality to alignment - we employ probing (detecting value traces in internal activations) and steering (modifying representations to shift behavior). Across six open-source LLMs and ten value dimensions, probing shows that diagnostic probes trained solely on abstract value descriptions reliably detect the same values in concrete event narratives and decision reasoning, demonstrating cross-level transfer. Steering reveals an asymmetry: intervening on value representations causally shifts concrete judgments and decisions (A-C, C-C), yet leaves abstract interpretations unchanged (A-A), suggesting that encoded abstract values function as stable anchors rather than malleable activations. These findings indicate LLMs maintain structured value representations that bridge abstraction and action, providing a mechanistic and operational foundation for building value-driven autonomous AI systems with more transparent, generalizable alignment and control.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u62bd\u8c61-\u6839\u57fa\u6846\u67b6\u548c\u4ef7\u503c\u68c0\u6d4b\uff0c\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u62bd\u8c61\u7406\u89e3\u80fd\u529b\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\uff0c\u8bc1\u660e\u5176\u5185\u90e8\u4ef7\u503c\u8868\u793a\u7ed3\u6784\u7a33\u5b9a\u4e14\u53ef\u5f71\u54cd\u5177\u4f53\u884c\u4e3a\uff0c\u6709\u52a9\u4e8e\u6784\u5efa\u66f4\u53ef\u63a7\u7684AI\u7cfb\u7edf\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u62bd\u8c61\u6982\u5ff5\uff0c\u8fd8\u662f\u4ec5\u4ec5\u5c06\u5176\u4f5c\u4e3a\u7edf\u8ba1\u6a21\u5f0f\u8fdb\u884c\u64cd\u4f5c\u3002", "method": "\u63d0\u51fa\u62bd\u8c61-\u6839\u57fa\u6846\u67b6\uff0c\u5c06\u6982\u5ff5\u7406\u89e3\u5206\u89e3\u4e3a\u4e09\u79cd\u80fd\u529b\uff1a\u62bd\u8c61\u6982\u5ff5\u89e3\u91ca\uff08A-A\uff09\u3001\u62bd\u8c61\u4e0e\u5177\u4f53\u4e8b\u4ef6\u7684\u8054\u7cfb\uff08A-C\uff09\u3001\u62bd\u8c61\u539f\u5219\u5bf9\u5177\u4f53\u51b3\u7b56\u7684\u5e94\u7528\uff08C-C\uff09\u3002\u901a\u8fc7\u63a2\u9488\u68c0\u6d4b\u548c\u5f15\u5bfc\u6280\u672f\uff0c\u5728\u516d\u4e2a\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5341\u4e2a\u4ef7\u503c\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u53d1\u73b0\u63a2\u9488\u80fd\u591f\u68c0\u6d4b\u5230\u4ece\u62bd\u8c61\u4ef7\u503c\u63cf\u8ff0\u5230\u5177\u4f53\u4e8b\u4ef6\u53d9\u8ff0\u548c\u51b3\u7b56\u63a8\u7406\u4e2d\u7684\u4ef7\u503c\u8f6c\u79fb\uff0c\u8868\u660e\u5b58\u5728\u8de8\u5c42\u6b21\u8f6c\u79fb\u3002\u5f15\u5bfc\u5b9e\u9a8c\u663e\u793a\u5bf9\u4ef7\u503c\u8868\u793a\u7684\u5e72\u9884\u4f1a\u5f71\u54cd\u5177\u4f53\u5224\u65ad\u548c\u51b3\u7b56\uff0c\u4f46\u4e0d\u6539\u53d8\u62bd\u8c61\u89e3\u91ca\uff0c\u8868\u660e\u62bd\u8c61\u4ef7\u503c\u5177\u6709\u7a33\u5b9a\u6027\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4fdd\u6301\u4e86\u7ed3\u6784\u5316\u7684\u4ef7\u503c\u8868\u793a\uff0c\u80fd\u591f\u8fde\u63a5\u62bd\u8c61\u4e0e\u884c\u52a8\uff0c\u4e3a\u6784\u5efa\u5177\u6709\u900f\u660e\u5ea6\u3001\u53ef\u6cdb\u5316\u7684\u4ef7\u503c\u9a71\u52a8\u81ea\u4e3bAI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u673a\u5236\u57fa\u7840\u3002"}}
{"id": "2601.14032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14032", "abs": "https://arxiv.org/abs/2601.14032", "authors": ["Hongli Zhou", "Hui Huang", "Wei Liu", "Chenglong Wang", "Xingyuan Bu", "Lvyuan Han", "Fuhai Song", "Muyun Yang", "Wenhao Jiang", "Hailong Cao", "Tiejun Zhao"], "title": "RM-Distiller: Exploiting Generative LLM for Reward Model Distillation", "comment": null, "summary": "Reward models (RMs) play a pivotal role in aligning large language models (LLMs) with human preferences. Due to the difficulty of obtaining high-quality human preference annotations, distilling preferences from generative LLMs has emerged as a standard practice. However, existing approaches predominantly treat teacher models as simple binary annotators, failing to fully exploit the rich knowledge and capabilities for RM distillation. To address this, we propose RM-Distiller, a framework designed to systematically exploit the multifaceted capabilities of teacher LLMs: (1) Refinement capability, which synthesizes highly correlated response pairs to create fine-grained and contrastive signals. (2) Scoring capability, which guides the RM in capturing precise preference strength via a margin-aware optimization objective. (3) Generation capability, which incorporates the teacher's generative distribution to regularize the RM to preserve its fundamental linguistic knowledge. Extensive experiments demonstrate that RM-Distiller significantly outperforms traditional distillation methods both on RM benchmarks and reinforcement learning-based alignment, proving that exploiting multifaceted teacher capabilities is critical for effective reward modeling. To the best of our knowledge, this is the first systematic research on RM distillation from generative LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa RM-Distiller\uff0c\u5145\u5206\u5229\u7528\u6559\u5e08\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u79cd\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u84b8\u998f\u548c\u5bf9\u9f50\u6548\u679c\uff0c\u662f\u9996\u4e2a\u7cfb\u7edf\u7814\u7a76\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5956\u52b1\u6a21\u578b\u84b8\u998f\u7684\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4ec5\u5c06\u6559\u5e08\u6a21\u578b\u89c6\u4e3a\u7b80\u5355\u7684\u4e8c\u5143\u6ce8\u91ca\u8005\uff0c\u672a\u5145\u5206\u6316\u6398\u6559\u5e08\u6a21\u578b\u4e30\u5bcc\u7684\u77e5\u8bc6\u548c\u80fd\u529b\uff0c\u5bfc\u81f4\u5956\u52b1\u6a21\u578b\u84b8\u998f\u6548\u679c\u6709\u9650\u3002", "method": "\u63d0\u51fa RM-Distiller \u6846\u67b6\uff0c\u7cfb\u7edf\u5730\u5229\u7528\u6559\u5e08\u6a21\u578b\u7684\u4e09\u79cd\u80fd\u529b\uff1a\u7cbe\u70bc\u80fd\u529b\u751f\u6210\u7ec6\u7c92\u5ea6\u5bf9\u6bd4\u4fe1\u53f7\uff0c\u8bc4\u5206\u80fd\u529b\u901a\u8fc7\u8fb9\u9645\u4f18\u5316\u6355\u6349\u504f\u597d\u5f3a\u5ea6\uff0c\u751f\u6210\u80fd\u529b\u5229\u7528\u751f\u6210\u5206\u5e03\u6b63\u5219\u5316\u5956\u52b1\u6a21\u578b\u3002", "result": "\u5728\u5956\u52b1\u6a21\u578b\u57fa\u51c6\u6d4b\u8bd5\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u9f50\u4efb\u52a1\u4e2d\uff0cRM-Distiller \u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u84b8\u998f\u65b9\u6cd5\uff0c\u5c55\u793a\u51fa\u591a\u80fd\u529b\u5229\u7528\u7684\u91cd\u8981\u6027\u3002", "conclusion": "RM-Distiller \u6846\u67b6\u6709\u6548\u5229\u7528\u6559\u5e08\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u91cd\u80fd\u529b\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u84b8\u998f\u6548\u679c\u548c\u5bf9\u9f50\u6027\u80fd\u3002"}}
{"id": "2601.14041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14041", "abs": "https://arxiv.org/abs/2601.14041", "authors": ["Yunhe Wang", "Kai Han", "Huiling Zhen", "Yuchuan Tian", "Hanting Chen", "Yongbing Huang", "Yufei Cui", "Yingte Shu", "Shan Gao", "Ismail Elezi", "Roy Vaughan Miles", "Songcen Xu", "Feng Wen", "Chao Xu", "Sinan Zeng", "Dacheng Tao"], "title": "Top 10 Open Challenges Steering the Future of Diffusion Language Model and Its Variants", "comment": null, "summary": "The paradigm of Large Language Models (LLMs) is currently defined by auto-regressive (AR) architectures, which generate text through a sequential ``brick-by-brick'' process. Despite their success, AR models are inherently constrained by a causal bottleneck that limits global structural foresight and iterative refinement. Diffusion Language Models (DLMs) offer a transformative alternative, conceptualizing text generation as a holistic, bidirectional denoising process akin to a sculptor refining a masterpiece. However, the potential of DLMs remains largely untapped as they are frequently confined within AR-legacy infrastructures and optimization frameworks. In this Perspective, we identify ten fundamental challenges ranging from architectural inertia and gradient sparsity to the limitations of linear reasoning that prevent DLMs from reaching their ``GPT-4 moment''. We propose a strategic roadmap organized into four pillars: foundational infrastructure, algorithmic optimization, cognitive reasoning, and unified multimodal intelligence. By shifting toward a diffusion-native ecosystem characterized by multi-scale tokenization, active remasking, and latent thinking, we can move beyond the constraints of the causal horizon. We argue that this transition is essential for developing next-generation AI capable of complex structural reasoning, dynamic self-correction, and seamless multimodal integration.", "AI": {"tldr": "\u4f20\u7edf\u7684\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u53d7\u9650\u4e8e\u987a\u5e8f\u751f\u6210\u7684\u56e0\u679c\u74f6\u9888\uff0c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u53cc\u5411\u53bb\u566a\u63d0\u4f9b\u4e86\u7a81\u7834\u53e3\u3002\u672c\u6587\u5206\u6790\u4e86\u5b9e\u73b0DLMs\u6f5c\u529b\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u5168\u9762\u7684\u6218\u7565\u8def\u7ebf\u56fe\uff0c\u4fc3\u8fdb\u672a\u6765AI\u5728\u63a8\u7406\u3001\u81ea\u6211\u7ea0\u6b63\u548c\u591a\u6a21\u6001\u667a\u80fd\u4e0a\u7684\u98de\u8dc3\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u56de\u5f52\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u56e0\u679c\u74f6\u9888\uff0c\u9650\u5236\u4e86\u5176\u5168\u5c40\u7ed3\u6784\u9884\u89c1\u548c\u8fed\u4ee3\u5b8c\u5584\u80fd\u529b\uff0c\u800c\u6269\u6563\u8bed\u8a00\u6a21\u578b\u4e3a\u6587\u672c\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u6574\u4f53\u4e14\u53cc\u5411\u7684\u53bb\u566a\u8fc7\u7a0b\uff0c\u8fd9\u4e00\u6f5c\u529b\u5c1a\u672a\u88ab\u5145\u5206\u53d1\u6398\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u56f4\u7ed5\u57fa\u7840\u67b6\u6784\u3001\u7b97\u6cd5\u4f18\u5316\u3001\u8ba4\u77e5\u63a8\u7406\u548c\u7edf\u4e00\u591a\u6a21\u6001\u667a\u80fd\u56db\u5927\u652f\u67f1\u7684\u6218\u7565\u8def\u7ebf\u56fe\uff0c\u5f3a\u8c03\u5efa\u7acb\u4e00\u4e2a\u591a\u5c3a\u5ea6\u5206\u8bcd\u3001\u79ef\u6781\u91cd\u63a9\u7801\u548c\u6f5c\u5728\u601d\u8003\u7684\u6269\u6563\u539f\u751f\u751f\u6001\u7cfb\u7edf\u3002", "result": "\u901a\u8fc7\u8bc6\u522b\u5341\u9879\u6839\u672c\u6027\u6311\u6218\uff0c\u63d0\u51fa\u4e86\u5411\u6269\u6563\u539f\u751f\u6846\u67b6\u8f6c\u578b\u7684\u5fc5\u8981\u6027\u548c\u5177\u4f53\u7b56\u7565\uff0c\u4ee5\u652f\u6301\u4e0b\u4e00\u4e2a\u4e16\u4ee3\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\uff0c\u5305\u62ec\u590d\u6742\u7ed3\u6784\u63a8\u7406\u548c\u591a\u6a21\u6001\u878d\u5408\u3002", "conclusion": "\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u7531\u4e8e\u5176\u5168\u5c40\u6027\u548c\u53cc\u5411\u7684\u6587\u672c\u751f\u6210\u65b9\u5f0f\uff0c\u6709\u671b\u7a81\u7834\u81ea\u56de\u5f52\uff08AR\uff09\u6a21\u578b\u7684\u56e0\u679c\u74f6\u9888\uff0c\u5b9e\u73b0\u66f4\u590d\u6742\u7684\u7ed3\u6784\u63a8\u7406\u548c\u52a8\u6001\u81ea\u6211\u4f18\u5316\u3002"}}
{"id": "2601.14046", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.14046", "abs": "https://arxiv.org/abs/2601.14046", "authors": ["Shikhar Bharadwaj", "Chin-Jou Li", "Yoonjae Kim", "Kwanghee Choi", "Eunjung Yeo", "Ryan Soh-Eun Shim", "Hanyu Zhou", "Brendon Boldt", "Karen Rosero Jacome", "Kalvin Chang", "Darsh Agrawal", "Keer Xu", "Chao-Han Huck Yang", "Jian Zhu", "Shinji Watanabe", "David R. Mortensen"], "title": "PRiSM: Benchmarking Phone Realization in Speech Models", "comment": null, "summary": "Phone recognition (PR) serves as the atomic interface for language-agnostic modeling for cross-lingual speech processing and phonetic analysis. Despite prolonged efforts in developing PR systems, current evaluations only measure surface-level transcription accuracy. We introduce PRiSM, the first open-source benchmark designed to expose blind spots in phonetic perception through intrinsic and extrinsic evaluation of PR systems. PRiSM standardizes transcription-based evaluation and assesses downstream utility in clinical, educational, and multilingual settings with transcription and representation probes. We find that diverse language exposure during training is key to PR performance, encoder-CTC models are the most stable, and specialized PR models still outperform Large Audio Language Models. PRiSM releases code, recipes, and datasets to move the field toward multilingual speech models with robust phonetic ability: https://github.com/changelinglab/prism.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faPRiSM\uff0c\u9996\u4e2a\u5f00\u653e\u6e90\u7801\u7684\u97f3\u7d20\u8bc6\u522b\u57fa\u51c6\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u7684\u97f3\u7d20\u611f\u77e5\u80fd\u529b\uff0c\u53d1\u73b0\u591a\u8bed\u8a00\u8bad\u7ec3\u548c\u7f16\u7801\u5668-CTC\u6a21\u578b\u8868\u73b0\u4f18\u5f02\uff0c\u63a8\u52a8\u591a\u8bed\u79cd\u97f3\u9891\u5efa\u6a21\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u97f3\u7d20\u8bc6\u522b\u7cfb\u7edf\u8bc4\u4f30\u4ec5\u9650\u4e8e\u8868\u5c42\u8f6c\u5f55\u51c6\u786e\u7387\uff0c\u65e0\u6cd5\u5168\u9762\u68c0\u6d4b\u97f3\u7d20\u8bc6\u522b\u7cfb\u7edf\u7684\u76f2\u70b9\u3002", "method": "\u63d0\u51fa\u4e86PRiSM\u57fa\u51c6\uff0c\u7ed3\u5408\u5185\u5728\u548c\u5916\u5728\u8bc4\u4f30\u65b9\u6cd5\uff0c\u6807\u51c6\u5316\u8f6c\u5f55\u8bc4\u4f30\u5e76\u5728\u4e34\u5e8a\u3001\u6559\u80b2\u548c\u591a\u8bed\u79cd\u573a\u666f\u4e2d\u8fdb\u884c\u4e0b\u6e38\u4efb\u52a1\u6d4b\u8bd5\u3002", "result": "PRiSM\u63ed\u793a\u4e86\u8bad\u7ec3\u8bed\u8a00\u591a\u6837\u6027\u5bf9\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u7f16\u7801\u5668-CTC\u7ed3\u6784\u5e26\u6765\u7a33\u5b9a\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5f00\u6e90\u4ee3\u7801\u53ca\u6570\u636e\u96c6\u63a8\u52a8\u9886\u57df\u8fdb\u5c55\u3002", "conclusion": "\u591a\u8bed\u8a00\u8bad\u7ec3\u548c\u7f16\u7801\u5668-CTC\u6a21\u578b\u5728\u97f3\u7d20\u8bc6\u522b\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e13\u95e8\u7684\u97f3\u7d20\u8bc6\u522b\u6a21\u578b\u4ecd\u4f18\u4e8e\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2601.14050", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14050", "abs": "https://arxiv.org/abs/2601.14050", "authors": ["Yuxin Chen", "Zhengzhou Cai", "Xiangtian Ji", "Weixiang Zhao", "An Zhang", "Xiang Wang", "Tat-Seng Chua"], "title": "Understanding Multilingualism in Mixture-of-Experts LLMs: Routing Mechanism, Expert Specialization, and Layerwise Steering", "comment": null, "summary": "Mixture-of-Experts (MoE) architectures have shown strong multilingual capabilities, yet the internal mechanisms underlying performance gains and cross-language differences remain insufficiently understood. In this work, we conduct a systematic analysis of MoE models, examining routing behavior and expert specialization across languages and network depth. Our analysis reveals that multilingual processing in MoE models is highly structured: routing aligns with linguistic families, expert utilization follows a clear layerwise pattern, and high-resource languages rely on shared experts while low-resource languages depend more on language-exclusive experts despite weaker performance. Layerwise interventions further show that early and late MoE layers support language-specific processing, whereas middle layers serve as language-agnostic capacity hubs. Building on these insights, we propose a routing-guided steering method that adaptively guides routing behavior in middle layers toward shared experts associated with dominant languages at inference time, leading to consistent multilingual performance improvements, particularly for linguistically related language pairs. Our code is available at https://github.com/conctsai/Multilingualism-in-Mixture-of-Experts-LLMs.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u4e2d\u591a\u8bed\u8a00\u5904\u7406\u7684\u8def\u7531\u548c\u4e13\u5bb6\u5229\u7528\u6a21\u5f0f\uff0c\u53d1\u73b0\u6a21\u578b\u5c42\u6b21\u7ed3\u6784\u5bf9\u5e94\u4e0d\u540c\u8bed\u8a00\u5904\u7406\u89d2\u8272\uff0c\u5e76\u63d0\u51fa\u8def\u7531\u5f15\u5bfc\u7b56\u7565\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd\u3002", "motivation": "\u867d\u7136MoE\u67b6\u6784\u663e\u793a\u51fa\u5f3a\u5927\u7684\u591a\u8bed\u8a00\u80fd\u529b\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u548c\u8de8\u8bed\u8a00\u6027\u80fd\u5dee\u5f02\u5c1a\u672a\u5145\u5206\u7406\u89e3\uff0c\u4e9f\u9700\u7cfb\u7edf\u6027\u5206\u6790\u4ee5\u63ed\u793a\u6a21\u578b\u7684\u591a\u8bed\u8a00\u5904\u7406\u7279\u6027\u5e76\u63d0\u5347\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u5730\u5206\u6790\u4e86MoE\u6a21\u578b\u7684\u8def\u7531\u884c\u4e3a\u548c\u4e13\u5bb6\u4e13\u95e8\u5316\uff0c\u7814\u7a76\u5176\u4e0e\u8bed\u8a00\u3001\u7f51\u7edc\u6df1\u5ea6\u7684\u5173\u7cfb\uff1b\u901a\u8fc7\u5c42\u6b21\u5e72\u9884\u9a8c\u8bc1\u4e86\u5404\u5c42\u7684\u529f\u80fd\u5dee\u5f02\uff1b\u57fa\u4e8e\u5206\u6790\u7ed3\u679c\u63d0\u51fa\u4e86\u8def\u7531\u5f15\u5bfc\u65b9\u6cd5\u4ee5\u4f18\u5316\u4e2d\u95f4\u5c42\u7684\u4e13\u5bb6\u4f7f\u7528\u3002", "result": "\u53d1\u73b0MoE\u6a21\u578b\u7684\u591a\u8bed\u8a00\u5904\u7406\u9ad8\u5ea6\u7ed3\u6784\u5316\uff0c\u8def\u7531\u663e\u73b0\u8bed\u8a00\u5bb6\u65cf\u7279\u5f81\uff0c\u5c42\u6b21\u5bf9\u5e94\u4e0d\u540c\u5904\u7406\u529f\u80fd\uff1b\u63d0\u51fa\u7684\u8def\u7531\u5f15\u5bfc\u65b9\u6cd5\u5728\u63a8\u7406\u9636\u6bb5\u5f15\u5bfc\u4e2d\u95f4\u5c42\u4e13\u5bb6\u9009\u62e9\uff0c\u63d0\u5347\u591a\u8bed\u8a00\u6027\u80fd\u5c24\u5176\u662f\u8bed\u8a00\u76f8\u5173\u7684\u8bed\u8a00\u5bf9\u3002", "conclusion": "\u591a\u8bed\u8a00\u6df7\u5408\u4e13\u5bb6\u6a21\u578b\u7684\u8def\u7531\u884c\u4e3a\u4e0e\u8bed\u8a00\u5bb6\u65cf\u7d27\u5bc6\u76f8\u5173\uff0c\u4e14\u4e0d\u540c\u5c42\u6b21\u7684\u4e13\u5bb6\u5177\u6709\u4e0d\u540c\u7684\u8bed\u8a00\u5904\u7406\u89d2\u8272\u3002\u9ad8\u8d44\u6e90\u8bed\u8a00\u4e3b\u8981\u4f9d\u8d56\u5171\u4eab\u4e13\u5bb6\uff0c\u800c\u4f4e\u8d44\u6e90\u8bed\u8a00\u5219\u66f4\u591a\u4f9d\u8d56\u8bed\u8a00\u4e13\u5c5e\u4e13\u5bb6\u3002\u4e2d\u95f4\u5c42\u4f5c\u4e3a\u8bed\u8a00\u65e0\u5173\u7684\u5904\u7406\u4e2d\u5fc3\uff0c\u65e9\u671f\u548c\u665a\u671f\u5c42\u652f\u6301\u8bed\u8a00\u7279\u5b9a\u5904\u7406\u3002"}}
{"id": "2601.14051", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14051", "abs": "https://arxiv.org/abs/2601.14051", "authors": ["Peter Devine", "Mardhiyah Sanni", "Farid Adilazuarda", "Julieta Gil Loizaga", "Barry Haddow"], "title": "Kakugo: Distillation of Low-Resource Languages into Small Language Models", "comment": null, "summary": "We present Kakugo, a novel and cost-effective pipeline designed to train general-purpose Small Language Models (SLMs) for low-resource languages using only the language name as input. By using a large teacher model to generate synthetic prompts and translate instruction datasets, we produced training data and SLMs for 54 low-resource languages. Evaluations across a diverse set of general natural language processing tasks, including translation, classification, and question answering, demonstrate that our pipeline consistently improves performance over base models. With a total generation and training cost of under $50 per language, Kakugo offers an accessible method for communities to develop language-specific AI.", "AI": {"tldr": "Kakugo\u5229\u7528\u5927\u6a21\u578b\u751f\u6210\u6570\u636e\u8bad\u7ec354\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4f4e\u6210\u672c\u3001\u9ad8\u6027\u80fd\u7684\u591a\u8bed\u8a00\u652f\u6301\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u7f3a\u4e4f\u5927\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u9650\u5236\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u548c\u5e94\u7528\u3002", "method": "\u63d0\u51faKakugo\u6d41\u6c34\u7ebf\uff0c\u5229\u7528\u5927\u89c4\u6a21\u6559\u5e08\u6a21\u578b\u751f\u6210\u5408\u6210\u63d0\u793a\u548c\u7ffb\u8bd1\u6307\u4ee4\u6570\u636e\u96c6\uff0c\u81ea\u52a8\u751f\u6210\u8bad\u7ec3\u6570\u636e\uff0c\u4ece\u800c\u8bad\u7ec354\u79cd\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u3002", "result": "\u5728\u7ffb\u8bd1\u3001\u5206\u7c7b\u548c\u95ee\u7b54\u7b49\u591a\u79cd\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\uff0cKakugo\u8bad\u7ec3\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "Kakugo\u662f\u4e00\u79cd\u4f4e\u6210\u672c\uff08\u6bcf\u79cd\u8bed\u8a00\u8bad\u7ec3\u8d39\u7528\u4f4e\u4e8e50\u7f8e\u5143\uff09\u3001\u9ad8\u6548\u4e14\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u793e\u533a\u5f00\u53d1\u4e13\u5c5e\u7684\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2601.14063", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14063", "abs": "https://arxiv.org/abs/2601.14063", "authors": ["Mohsinul Kabir", "Tasnim Ahmed", "Md Mezbaur Rahman", "Shaoxiong Ji", "Hassan Alhuzali", "Sophia Ananiadou"], "title": "XCR-Bench: A Multi-Task Benchmark for Evaluating Cultural Reasoning in LLMs", "comment": "30 Pages, 13 Figures", "summary": "Cross-cultural competence in large language models (LLMs) requires the ability to identify Culture-Specific Items (CSIs) and to adapt them appropriately across cultural contexts. Progress in evaluating this capability has been constrained by the scarcity of high-quality CSI-annotated corpora with parallel cross-cultural sentence pairs. To address this limitation, we introduce XCR-Bench, a Cross(X)-Cultural Reasoning Benchmark consisting of 4.9k parallel sentences and 1,098 unique CSIs, spanning three distinct reasoning tasks with corresponding evaluation metrics. Our corpus integrates Newmark's CSI framework with Hall's Triad of Culture, enabling systematic analysis of cultural reasoning beyond surface-level artifacts and into semi-visible and invisible cultural elements such as social norms, beliefs, and values. Our findings show that state-of-the-art LLMs exhibit consistent weaknesses in identifying and adapting CSIs related to social etiquette and cultural reference. Additionally, we find evidence that LLMs encode regional and ethno-religious biases even within a single linguistic setting during cultural adaptation. We release our corpus and code to facilitate future research on cross-cultural NLP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8de8\u6587\u5316\u63a8\u7406\u57fa\u51c6XCR-Bench\uff0c\u89e3\u51b3\u4e86\u9ad8\u8d28\u91cf\u8de8\u6587\u5316\u8bed\u6599\u7f3a\u4e4f\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6587\u5316\u9002\u5e94\u4e2d\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u548c\u504f\u89c1\u3002", "motivation": "\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u6ce8\u91ca\u7684CSI\u8bed\u6599\u5e93\u53ca\u8de8\u6587\u5316\u5e73\u884c\u53e5\u5bf9\uff0c\u9650\u5236\u4e86\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8de8\u6587\u5316\u80fd\u529b\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u5305\u542b4900\u4e2a\u5e73\u884c\u53e5\u5b50\u548c1098\u4e2a\u72ec\u7279CSI\u7684XCR-Bench\u8de8\u6587\u5316\u63a8\u7406\u57fa\u51c6\uff0c\u7ed3\u5408Newmark\u7684CSI\u6846\u67b6\u4e0eHall\u7684\u4e09\u6587\u5316\u6a21\u578b\uff0c\u8bbe\u8ba1\u5e76\u8bc4\u4f30\u4e09\u7c7b\u63a8\u7406\u4efb\u52a1\u53ca\u76f8\u5e94\u6307\u6807\u3002", "result": "\u5b8c\u6210\u4e86\u9ad8\u8d28\u91cf\u7684\u8de8\u6587\u5316\u5e73\u884c\u53e5\u5e93\u5efa\u7acb\uff0c\u6db5\u76d6\u591a\u5c42\u6b21\u6587\u5316\u5143\u7d20\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u5728\u793e\u4f1a\u89c4\u8303\u548c\u6587\u5316\u53c2\u8003\u7684CSI\u8bc6\u522b\u4e0e\u9002\u5e94\u4e0d\u8db3\u53ca\u6f5c\u5728\u533a\u57df\u65cf\u7fa4\u504f\u89c1\u7684\u4e8b\u5b9e\u3002", "conclusion": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u548c\u9002\u5e94\u4e0e\u793e\u4f1a\u793c\u4eea\u548c\u6587\u5316\u53c2\u8003\u76f8\u5173\u7684\u7279\u5b9a\u6587\u5316\u9879\u76ee\uff08CSI\uff09\u65b9\u9762\u8868\u73b0\u51fa\u6301\u7eed\u7684\u5f31\u70b9\uff0c\u5e76\u4e14\u5728\u6587\u5316\u9002\u5e94\u8fc7\u7a0b\u4e2d\u5b58\u5728\u533a\u57df\u548c\u65cf\u7fa4\u5b97\u6559\u504f\u89c1\u3002"}}
{"id": "2601.14105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14105", "abs": "https://arxiv.org/abs/2601.14105", "authors": ["Olesya Razuvayevskaya", "Kalina Bontcheva"], "title": "Truth with a Twist: The Rhetoric of Persuasion in Professional vs. Community-Authored Fact-Checks", "comment": "In Proceedings of the ACM Web Conference 2026 (WWW 2026)", "summary": "This study presents the first large-scale comparison of persuasion techniques present in crowd- versus professionally-written debunks. Using extensive datasets from Community Notes (CNs), EUvsDisinfo, and the Database of Known Fakes (DBKF), we quantify the prevalence and types of persuasion techniques across these fact-checking ecosystems. Contrary to prior hypothesis that community-produced debunks rely more heavily on subjective or persuasive wording, we find no evidence that CNs contain a higher average number of persuasion techniques than professional fact-checks. We additionally identify systematic rhetorical differences between CNs and professional debunking efforts, reflecting differences in institutional norms and topical coverage. Finally, we examine how the crowd evaluates persuasive language in CNs and show that, although notes with more persuasive elements receive slightly higher overall helpfulness ratings, crowd raters are effective at penalising the use of particular problematic rhetorical means", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5927\u89c4\u6a21\u6bd4\u8f83\u4e86\u793e\u533a\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u4e2d\u7684\u529d\u8bf4\u6280\u5de7\uff0c\u53d1\u73b0\u4e24\u8005\u4f7f\u7528\u91cf\u76f8\u5f53\u4f46\u8868\u8fbe\u65b9\u5f0f\u4e0d\u540c\uff0c\u7fa4\u4f17\u8bc4\u4ef7\u80fd\u591f\u6709\u6548\u60e9\u6212\u4e0d\u5f53\u4fee\u8f9e\u3002", "motivation": "\u63ed\u793a\u793e\u533a\u8f9f\u8c23\u4e0e\u4e13\u4e1a\u8f9f\u8c23\u5728\u4f7f\u7528\u529d\u8bf4\u6280\u5de7\u4e0a\u7684\u5dee\u5f02\uff0c\u6311\u6218\u5148\u524d\u8ba4\u4e3a\u793e\u533a\u8f9f\u8c23\u66f4\u4f9d\u8d56\u4e3b\u89c2\u529d\u8bf4\u7684\u5047\u8bbe\u3002", "method": "\u5229\u7528Community Notes\u3001EUvsDisinfo\u548cKnown Fakes\u6570\u636e\u5e93\u7684\u5927\u89c4\u6a21\u6570\u636e\uff0c\u91cf\u5316\u6bd4\u8f83\u793e\u533a\u53ca\u4e13\u4e1a\u8f9f\u8c23\u4e2d\u7684\u529d\u8bf4\u6280\u5de7\uff0c\u5e76\u5206\u6790\u7fa4\u4f17\u5bf9\u529d\u8bf4\u8bed\u8a00\u7684\u8bc4\u4ef7\u3002", "result": "\u8bc1\u5b9e\u793e\u533a\u8f9f\u8c23\u5e76\u4e0d\u6bd4\u4e13\u4e1a\u8f9f\u8c23\u5305\u542b\u66f4\u591a\u529d\u8bf4\u6280\u5de7\uff0c\u53d1\u73b0\u4e24\u8005\u5728\u4fee\u8f9e\u65b9\u5f0f\u4e0a\u6709\u5236\u5ea6\u548c\u8bdd\u9898\u8986\u76d6\u7684\u4e0d\u540c\uff0c\u5e76\u8868\u660e\u7fa4\u4f17\u8bc4\u4ef7\u673a\u5236\u5728\u8bc6\u522b\u95ee\u9898\u6027\u4fee\u8f9e\u4e0a\u6709\u6548\u3002", "conclusion": "\u793e\u533a\u751f\u4ea7\u7684\u8f9f\u8c23\u5185\u5bb9\u5728\u4f7f\u7528\u529d\u8bf4\u6280\u5de7\u7684\u6570\u91cf\u4e0a\u5e76\u4e0d\u8d85\u8fc7\u4e13\u4e1a\u8f9f\u8c23\u5185\u5bb9\uff0c\u4f46\u5b58\u5728\u7cfb\u7edf\u6027\u7684\u4fee\u8f9e\u5dee\u5f02\u3002\u7fa4\u4f17\u8bc4\u4ef7\u673a\u5236\u80fd\u591f\u8bc6\u522b\u5e76\u60e9\u7f5a\u4e0d\u5f53\u7684\u4fee\u8f9e\u624b\u6bb5\u3002"}}
{"id": "2601.14112", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14112", "abs": "https://arxiv.org/abs/2601.14112", "authors": ["George Mihaila"], "title": "Learning to Explain: Supervised Token Attribution from Transformer Attention Patterns", "comment": null, "summary": "Explainable AI (XAI) has become critical as transformer-based models are deployed in high-stakes applications including healthcare, legal systems, and financial services, where opacity hinders trust and accountability. Transformers self-attention mechanisms have proven valuable for model interpretability, with attention weights successfully used to understand model focus and behavior (Xu et al., 2015); (Wiegreffe and Pinter, 2019). However, existing attention-based explanation methods rely on manually defined aggregation strategies and fixed attribution rules (Abnar and Zuidema, 2020a); (Chefer et al., 2021), while model-agnostic approaches (LIME, SHAP) treat the model as a black box and incur significant computational costs through input perturbation. We introduce Explanation Network (ExpNet), a lightweight neural network that learns an explicit mapping from transformer attention patterns to token-level importance scores. Unlike prior methods, ExpNet discovers optimal attention feature combinations automatically rather than relying on predetermined rules. We evaluate ExpNet in a challenging cross-task setting and benchmark it against a broad spectrum of model-agnostic methods and attention-based techniques spanning four methodological families.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\uff08ExpNet\uff09\uff0c\u80fd\u591f\u81ea\u52a8\u4ece\u53d8\u538b\u5668\u6ce8\u610f\u529b\u6570\u636e\u4e2d\u5b66\u4e60\u6700\u4f18\u89e3\u91ca\u6620\u5c04\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6a21\u578b\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u89e3\u91ca\u65b9\u6cd5\u4f9d\u8d56\u624b\u52a8\u5b9a\u4e49\u7684\u805a\u5408\u7b56\u7565\u548c\u56fa\u5b9a\u5f52\u56e0\u89c4\u5219\uff0c\u6a21\u578b\u65e0\u5173\u7684\u65b9\u6cd5\u5982LIME\u3001SHAP\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u628a\u6a21\u578b\u5f53\u9ed1\u76d2\u5904\u7406\uff0c\u4e9f\u9700\u4e00\u79cd\u81ea\u52a8\u3001\u9ad8\u6548\u4e14\u900f\u660e\u7684\u89e3\u91ca\u673a\u5236\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u2014\u2014\u89e3\u91ca\u7f51\u7edc\uff08ExpNet\uff09\uff0c\u901a\u8fc7\u5b66\u4e60\u4ece\u53d8\u538b\u5668\u7684\u6ce8\u610f\u529b\u6a21\u5f0f\u5230\u5355\u8bcd\u5c42\u91cd\u8981\u6027\u5f97\u5206\u7684\u663e\u5f0f\u6620\u5c04\u6765\u5b9e\u73b0\u89e3\u91ca\u3002", "result": "ExpNet\u5728\u8de8\u4efb\u52a1\u8bbe\u7f6e\u4e2d\u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u4e0e\u591a\u79cd\u6a21\u578b\u65e0\u5173\u65b9\u6cd5\u53ca\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u6280\u672f\u8fdb\u884c\u4e86\u5e7f\u6cdb\u6bd4\u8f83\uff0c\u663e\u793a\u51fa\u66f4\u4f18\u7684\u6027\u80fd\u548c\u89e3\u91ca\u6548\u679c\u3002", "conclusion": "ExpNet\u80fd\u591f\u81ea\u52a8\u5b66\u4e60\u6700\u4f73\u7684\u6ce8\u610f\u529b\u7279\u5f81\u7ec4\u5408\uff0c\u6709\u6548\u63d0\u5347\u4e86\u89e3\u91ca\u6027\uff0c\u5e76\u4e14\u5728\u8de8\u4efb\u52a1\u8bc4\u4ef7\u4e2d\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u7684\u6a21\u578b\u65e0\u5173\u548c\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u89e3\u91ca\u65b9\u6cd5\u3002"}}
{"id": "2601.14121", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14121", "abs": "https://arxiv.org/abs/2601.14121", "authors": ["Jonathan Tonglet", "Iryna Gurevych", "Tinne Tuytelaars", "Marie-Francine Moens"], "title": "NewsRECON: News article REtrieval for image CONtextualization", "comment": "Preprint under review. Code available at https://github.com/jtonglet/arxiv2025-newsrecon", "summary": "Identifying when and where a news image was taken is crucial for journalists and forensic experts to produce credible stories and debunk misinformation. While many existing methods rely on reverse image search (RIS) engines, these tools often fail to return results, thereby limiting their practical applicability. In this work, we address the challenging scenario where RIS evidence is unavailable. We introduce NewsRECON, a method that links images to relevant news articles to infer their date and location from article metadata. NewsRECON leverages a corpus of over 90,000 articles and integrates: (1) a bi-encoder for retrieving event-relevant articles; (2) two cross-encoders for reranking articles by location and event consistency. Experiments on the TARA and 5Pils-OOC show that NewsRECON outperforms prior work and can be combined with a multimodal large language model to achieve new SOTA results in the absence of RIS evidence. We make our code available.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u8bc1\u636e\uff0c\u901a\u8fc7\u65b0\u95fb\u6587\u7ae0\u5143\u6570\u636e\u63a8\u65ad\u65b0\u95fb\u56fe\u7247\u65f6\u95f4\u5730\u70b9\u7684\u65b9\u6cd5 NewsRECON\uff0c\u663e\u8457\u63d0\u5347\u4e86\u76f8\u5173\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u5f15\u64ce\uff0c\u4f46\u8fd9\u4e9b\u5de5\u5177\u5e38\u5e38\u65e0\u6cd5\u8fd4\u56de\u6709\u7528\u7ed3\u679c\uff0c\u9650\u5236\u4e86\u5176\u5b9e\u7528\u6027\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56 RIS \u8bc1\u636e\u7684\u65b0\u65b9\u6cd5\u3002", "method": "NewsRECON \u4f7f\u7528\u5305\u542b\u4e5d\u4e07\u591a\u7bc7\u6587\u7ae0\u7684\u8bed\u6599\u5e93\uff0c\u7ed3\u5408\u53cc\u7f16\u7801\u5668\u68c0\u7d22\u4e8b\u4ef6\u76f8\u5173\u62a5\u9053\u3001\u4e24\u4e2a\u8de8\u7f16\u7801\u5668\u91cd\u65b0\u6392\u5e8f\u6587\u7ae0\u4ee5\u5339\u914d\u5730\u70b9\u548c\u4e8b\u4ef6\u4e00\u81f4\u6027\u3002", "result": "\u5728 TARA \u548c 5Pils-OOC \u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cNewsRECON \u8d85\u8d8a\u4e86\u4e4b\u524d\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u53ef\u4ee5\u4e0e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7ed3\u5408\uff0c\u8fbe\u5230\u65b0\u7684\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "NewsRECON \u65b9\u6cd5\u80fd\u591f\u5728\u7f3a\u4e4f\u53cd\u5411\u56fe\u50cf\u641c\u7d22\u8bc1\u636e\u65f6\uff0c\u6709\u6548\u5730\u5c06\u65b0\u95fb\u56fe\u7247\u4e0e\u76f8\u5173\u62a5\u9053\u6587\u7ae0\u5173\u8054\uff0c\u63a8\u65ad\u56fe\u7247\u7684\u62cd\u6444\u65f6\u95f4\u548c\u5730\u70b9\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2601.14123", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2601.14123", "abs": "https://arxiv.org/abs/2601.14123", "authors": ["Sofia Bennani", "Charles Moslonka"], "title": "A Systematic Analysis of Chunking Strategies for Reliable Question Answering", "comment": "3 pages, 2 figures, 1 table, pre-print", "summary": "We study how document chunking choices impact the reliability of Retrieval-Augmented Generation (RAG) systems in industry. While practice often relies on heuristics, our end-to-end evaluation on Natural Questions systematically varies chunking method (token, sentence, semantic, code), chunk size, overlap, and context length. We use a standard industrial setup: SPLADE retrieval and a Mistral-8B generator. We derive actionable lessons for cost-efficient deployment: (i) overlap provides no measurable benefit and increases indexing cost; (ii) sentence chunking is the most cost-effective method, matching semantic chunking up to ~5k tokens; (iii) a \"context cliff\" reduces quality beyond ~2.5k tokens; and (iv) optimal context depends on the goal (semantic quality peaks at small contexts; exact match at larger ones).", "AI": {"tldr": "\u7814\u7a76\u4e0d\u540c\u6587\u6863\u5206\u5757\u7b56\u7565\u5bf9\u5de5\u4e1a\u7ea7RAG\u7cfb\u7edf\u6027\u80fd\u548c\u6210\u672c\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u65e0\u91cd\u53e0\u53e5\u5b50\u5206\u5757\u66f4\u4f18\uff0c\u4e14\u4e0a\u4e0b\u6587\u957f\u5ea6\u9700\u6839\u636e\u4efb\u52a1\u8c03\u6574\u3002", "motivation": "\u5f53\u524d\u5de5\u4e1a\u5b9e\u8df5\u4e2d\u6587\u6863\u5206\u5757\u591a\u57fa\u4e8e\u7ecf\u9a8c\u6cd5\u5219\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u3002\u7814\u7a76\u76ee\u7684\u662f\u660e\u786e\u5206\u5757\u65b9\u5f0f\u5bf9RAG\u7cfb\u7edf\u6027\u80fd\u548c\u6210\u672c\u7684\u5177\u4f53\u5f71\u54cd\uff0c\u4ece\u800c\u6307\u5bfc\u5b9e\u9645\u90e8\u7f72\u3002", "method": "\u7cfb\u7edf\u5730\u5728Natural Questions\u6570\u636e\u96c6\u4e0a\uff0c\u4f7f\u7528SPLADE\u68c0\u7d22\u548cMistral-8B\u751f\u6210\u5668\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540c\u5206\u5757\u65b9\u6cd5\uff08\u57fa\u4e8etoken\u3001\u53e5\u5b50\u3001\u8bed\u4e49\u3001\u4ee3\u7801\uff09\u3001\u5206\u5757\u5927\u5c0f\u3001\u91cd\u53e0\u548c\u4e0a\u4e0b\u6587\u957f\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u91cd\u53e0\u5206\u5757\u65e0\u660e\u663e\u6548\u76ca\u4f46\u63d0\u9ad8\u7d22\u5f15\u6210\u672c\uff0c\u53e5\u5b50\u5206\u5757\u57285k token\u4ee5\u5185\u6027\u80fd\u4f18\u4e14\u6210\u672c\u4f4e\uff0c\u8d85\u8fc72.5k tokens\u4e0a\u4e0b\u6587\u957f\u5ea6\u6027\u80fd\u4e0b\u964d\u660e\u663e\uff0c\u4e14\u4e0d\u540c\u76ee\u6807\u5bf9\u5e94\u4e0d\u540c\u7684\u4e0a\u4e0b\u6587\u6700\u4f18\u957f\u5ea6\u3002", "conclusion": "\u6587\u6863\u5206\u5757\u7b56\u7565\u663e\u8457\u5f71\u54cdRAG\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u6210\u672c\u6548\u76ca\u3002\u5efa\u8bae\u91c7\u7528\u53e5\u5b50\u5206\u5757\u4ee5\u964d\u4f4e\u6210\u672c\uff0c\u907f\u514d\u91cd\u53e0\u5206\u5757\uff0c\u5e76\u6839\u636e\u5177\u4f53\u4efb\u52a1\u8c03\u6574\u4e0a\u4e0b\u6587\u957f\u5ea6\u3002"}}
{"id": "2601.14124", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14124", "abs": "https://arxiv.org/abs/2601.14124", "authors": ["Saad Mankarious", "Aya Zirikly"], "title": "Style Transfer as Bias Mitigation: Diffusion Models for Synthetic Mental Health Text for Arabic", "comment": null, "summary": "Synthetic data offers a promising solution for mitigating data scarcity and demographic bias in mental health analysis, yet existing approaches largely rely on pretrained large language models (LLMs), which may suffer from limited output diversity and propagate biases inherited from their training data. In this work, we propose a pretraining-free diffusion-based approach for synthetic text generation that frames bias mitigation as a style transfer problem. Using the CARMA Arabic mental health corpus, which exhibits a substantial gender imbalance, we focus on male-to-female style transfer to augment underrepresented female-authored content. We construct five datasets capturing varying linguistic and semantic aspects of gender expression in Arabic and train separate diffusion models for each setting. Quantitative evaluations demonstrate consistently high semantic fidelity between source and generated text, alongside meaningful surface-level stylistic divergence, while qualitative analysis confirms linguistically plausible gender transformations. Our results show that diffusion-based style transfer can generate high-entropy, semantically faithful synthetic data without reliance on pretrained LLMs, providing an effective and flexible framework for mitigating gender bias in sensitive, low-resource mental health domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u65e0\u9884\u8bad\u7ec3\u7684\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u98ce\u683c\u8fc1\u79fb\u65b9\u6cd5\uff0c\u6709\u6548\u751f\u6210\u6027\u522b\u5e73\u8861\u7684\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u5408\u6210\u6587\u672c\uff0c\u63d0\u9ad8\u591a\u6837\u6027\u548c\u8bed\u4e49\u5fe0\u5b9e\u5ea6\uff0c\u7f13\u89e3\u6027\u522b\u504f\u89c1\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5b58\u5728\u8f93\u51fa\u591a\u6837\u6027\u4e0d\u8db3\u548c\u504f\u89c1\u4f20\u9012\u95ee\u9898\uff0c\u4e14\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u6570\u636e\u7a00\u7f3a\u4e14\u5b58\u5728\u6027\u522b\u5931\u8861\u3002", "method": "\u5229\u7528\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u5c06\u6027\u522b\u504f\u89c1\u7f13\u89e3\u95ee\u9898\u89c6\u4e3a\u98ce\u683c\u8fc1\u79fb\u95ee\u9898\uff0c\u4e13\u95e8\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u5fc3\u7406\u5065\u5eb7\u8bed\u6599\u5e93\u4e2d\u7684\u7537\u6027\u5230\u5973\u6027\u6587\u672c\u98ce\u683c\u8f6c\u6362\uff0c\u8bad\u7ec3\u4e94\u4e2a\u4e0d\u540c\u8bed\u4e49\u548c\u8bed\u8a00\u98ce\u683c\u7684\u6269\u6563\u6a21\u578b\u3002", "result": "\u901a\u8fc7\u5b9a\u91cf\u6307\u6807\u663e\u793a\u751f\u6210\u6587\u672c\u5728\u8bed\u4e49\u4e0a\u9ad8\u5ea6\u5fe0\u5b9e\u539f\u6587\uff0c\u540c\u65f6\u5728\u8868\u5c42\u98ce\u683c\u4e0a\u5b58\u5728\u663e\u8457\u53d8\u5316\uff1b\u5b9a\u6027\u5206\u6790\u8868\u660e\u751f\u6210\u6587\u672c\u7684\u6027\u522b\u8f6c\u6362\u5728\u8bed\u8a00\u4e0a\u5408\u7406\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u98ce\u683c\u8fc1\u79fb\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u65e0\u504f\u89c1\u7684\u5408\u6210\u6587\u672c\uff0c\u4ece\u800c\u7f13\u89e3\u4f4e\u8d44\u6e90\u7cbe\u795e\u5065\u5eb7\u9886\u57df\u7684\u6570\u636e\u7a00\u7f3a\u548c\u6027\u522b\u504f\u89c1\u95ee\u9898\u3002"}}
{"id": "2601.14152", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14152", "abs": "https://arxiv.org/abs/2601.14152", "authors": ["Hyunjong Ok", "Jaeho Lee"], "title": "Lost in the Prompt Order: Revealing the Limitations of Causal Attention in Language Models", "comment": "preprint", "summary": "Large language models exhibit surprising sensitivity to the structure of the prompt, but the mechanisms underlying this sensitivity remain poorly understood. In this work, we conduct an in-depth investigation on a striking case: in multiple-choice question answering, placing context before the questions and options (CQO) outperforms the reverse order (QOC) by over 14%p, consistently over a wide range of models and datasets. Through systematic architectural analysis, we identify causal attention as the core mechanism: in QOC prompts, the causal mask prevents option tokens from attending to context, creating an information bottleneck where context becomes invisible to options.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u63d0\u793a\u7ed3\u6784\u7684\u654f\u611f\u6027\uff0c\u53d1\u73b0\u4fe1\u606f\u6d41\u53d7\u56e0\u679c\u6ce8\u610f\u673a\u5236\u5f71\u54cd\uff0c\u89e3\u91ca\u4e86\u4e3a\u4ec0\u4e48\u4e0a\u4e0b\u6587\u7f6e\u4e8e\u524d\u6bd4\u7f6e\u4e8e\u540e\u6548\u679c\u66f4\u597d\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u63d0\u793a\u7ed3\u6784\u975e\u5e38\u654f\u611f\uff0c\u4f46\u5176\u80cc\u540e\u7684\u673a\u5236\u5c1a\u4e0d\u6e05\u695a\uff0c\u672c\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u79cd\u63d0\u793a\u654f\u611f\u6027\u7684\u539f\u56e0\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u7684\u67b6\u6784\u5206\u6790\uff0c\u7814\u7a76\u4e0d\u540c\u63d0\u793a\u7ed3\u6784\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5206\u6790\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u5982\u4f55\u5bfc\u81f4\u4fe1\u606f\u5c4f\u969c\u3002", "result": "\u53d1\u73b0CQO\u7ed3\u6784\u663e\u8457\u4f18\u4e8eQOC\uff0c\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u56e0\u679c\u63a9\u7801\u9650\u5236\u4e86\u9009\u9879\u8bbf\u95ee\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5bfc\u81f4\u6027\u80fd\u5dee\u5f02\u3002", "conclusion": "\u5728\u591a\u9879\u9009\u62e9\u95ee\u7b54\u4efb\u52a1\u4e2d\uff0c\u5c06\u4e0a\u4e0b\u6587\u7f6e\u4e8e\u95ee\u9898\u548c\u9009\u9879\u4e4b\u524d\uff08CQO\uff09\u6bd4\u5c06\u95ee\u9898\u548c\u9009\u9879\u7f6e\u4e8e\u4e0a\u4e0b\u6587\u4e4b\u524d\uff08QOC\uff09\u7684\u8868\u73b0\u9ad8\u51fa14\u4e2a\u767e\u5206\u70b9\u4ee5\u4e0a\uff0c\u8fd9\u662f\u56e0\u4e3aQOC\u4e2d\u7684\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\u9650\u5236\u4e86\u9009\u9879\u5bf9\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u8bbf\u95ee\uff0c\u9020\u6210\u4fe1\u606f\u74f6\u9888\u3002"}}
{"id": "2601.14160", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14160", "abs": "https://arxiv.org/abs/2601.14160", "authors": ["Ali Hamza Bashir", "Muhammad Rehan Khalid", "Kostadin Cvejoski", "Jana Birr", "Jule Berghaus", "Armin Berger", "Sandra Halscheidt", "Christian Temath", "Rafet Sifa", "David Berghaus"], "title": "Domain-Adaptation through Synthetic Data: Fine-Tuning Large Language Models for German Law", "comment": null, "summary": "Large language models (LLMs) often struggle in specialized domains such as legal reasoning due to limited expert knowledge, resulting in factually incorrect outputs or hallucinations. This paper presents an effective method for adapting advanced LLMs to German legal question answering through a novel synthetic data generation approach. In contrast to costly human-annotated resources or unreliable synthetic alternatives, our approach systematically produces high-quality, diverse, and legally accurate question-answer pairs directly from authoritative German statutes. Using rigorous automated filtering methods and parameter-efficient fine-tuning techniques, we demonstrate that LLMs adapted with our synthetic dataset significantly outperform their baseline counterparts on German legal question answering tasks. Our results highlight the feasibility of using carefully designed synthetic data as a robust alternative to manual annotation in high-stakes, knowledge-intensive domains.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u521b\u65b0\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u6539\u5584\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u80fd\u529b\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4eba\u5de5\u6807\u6ce8\u5373\u53ef\u83b7\u5f97\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\u7684\u6709\u6548\u65b9\u6848\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\uff08\u5982\u6cd5\u5f8b\u63a8\u7406\uff09\u56e0\u7f3a\u4e4f\u4e13\u5bb6\u77e5\u8bc6\u5bfc\u81f4\u9519\u8bef\u7b54\u6848\u6216\u5e7b\u89c9\uff0c\u9700\u8981\u53ef\u9760\u4e14\u9ad8\u6548\u7684\u6570\u636e\u8d44\u6e90\u8fdb\u884c\u9002\u5e94\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6743\u5a01\u5fb7\u56fd\u6cd5\u5f8b\u6761\u6587\u7cfb\u7edf\u751f\u6210\u591a\u6837\u4e14\u51c6\u786e\u7684\u95ee\u7b54\u5bf9\u7684\u5408\u6210\u6570\u636e\u65b9\u6cd5\uff0c\u7ed3\u5408\u81ea\u52a8\u7b5b\u9009\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff0c\u63d0\u5347\u6a21\u578b\u7684\u6cd5\u5f8b\u95ee\u7b54\u80fd\u529b\u3002", "result": "\u4f7f\u7528\u8be5\u5408\u6210\u6570\u636e\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u672a\u7ecf\u9002\u5e94\u7684\u57fa\u7840\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6cd5\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u9488\u5bf9\u6027\u5fae\u8c03\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5176\u5728\u5fb7\u56fd\u6cd5\u5f8b\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u9ad8\u8d28\u91cf\u5408\u6210\u6570\u636e\u4f5c\u4e3a\u4eba\u5de5\u6807\u6ce8\u66ff\u4ee3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.14172", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14172", "abs": "https://arxiv.org/abs/2601.14172", "authors": ["V\u00edctor Yeste", "Paolo Rosso"], "title": "Human Values in a Single Sentence: Moral Presence, Hierarchies, and Transformer Ensembles on the Schwartz Continuum", "comment": "Code: https://github.com/VictorMYeste/human-value-detection, 37 pages, 4 figures,", "summary": "We study sentence-level identification of the 19 values in the Schwartz motivational continuum as a concrete formulation of human value detection in text. The setting - out-of-context sentences from news and political manifestos - features sparse moral cues and severe class imbalance. This combination makes fine-grained sentence-level value detection intrinsically difficult, even for strong modern neural models. We first operationalize a binary moral presence task (\"does any value appear?\") and show that it is learnable from single sentences (positive-class F1 $\\approx$ 0.74 with calibrated thresholds). We then compare a presence-gated hierarchy to a direct multi-label classifier under matched compute, both based on DeBERTa-base and augmented with lightweight signals (prior-sentence context, LIWC-22/eMFD/MJD lexica, and topic features). The hierarchy does not outperform direct prediction, indicating that gate recall limits downstream gains. We also benchmark instruction-tuned LLMs - Gemma 2 9B, Llama 3.1 8B, Mistral 8B, and Qwen 2.5 7B - in zero-/few-shot and QLoRA setups and build simple ensembles; a soft-vote supervised ensemble reaches macro-F1 0.332, significantly surpassing the best single supervised model and exceeding prior English-only baselines. Overall, in this scenario, lightweight signals and small ensembles yield the most reliable improvements, while hierarchical gating offers limited benefit. We argue that, under an 8 GB single-GPU constraint and at the 7-9B scale, carefully tuned supervised encoders remain a strong and compute-efficient baseline for structured human value detection, and we outline how richer value structure and sentence-in-document context could further improve performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65b0\u95fb\u4e0e\u653f\u6cbb\u6587\u672c\u4e2d\u53e5\u5b50\u7ea7\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\uff0c\u53d1\u73b0\u8f7b\u91cf\u7ea7\u4fe1\u53f7\u4e0e\u5c0f\u578b\u96c6\u6210\u6700\u6709\u6548\uff0c\u5206\u5c42\u95e8\u63a7\u6536\u76ca\u6709\u9650\u3002\u8c03\u4f18\u7684\u6709\u76d1\u7763\u6a21\u578b\u5728\u6709\u9650GPU\u8d44\u6e90\u4e0b\u8868\u73b0\u4f18\u5f02\uff0c\u63d0\u51fa\u672a\u6765\u53ef\u901a\u8fc7\u66f4\u4e30\u5bcc\u7684\u4ef7\u503c\u7ed3\u6784\u548c\u4e0a\u4e0b\u6587\u4fe1\u606f\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u7f3a\u4e4f\u4e0a\u4e0b\u6587\u7684\u65b0\u95fb\u548c\u653f\u6cbb\u6587\u672c\u4e2d\uff0c\u53e5\u5b50\u7ea7\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u56e0\u9053\u5fb7\u7ebf\u7d22\u7a00\u758f\u4e14\u7c7b\u522b\u6781\u5ea6\u4e0d\u5e73\u8861\u800c\u5bfc\u81f4\u7684\u8bc6\u522b\u96be\u9898\u3002", "method": "\u91c7\u7528DeBERTa-base\u6a21\u578b\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u7279\u5f81\uff08\u524d\u53e5\u4e0a\u4e0b\u6587\u3001\u60c5\u611f\u8bcd\u5178\u548c\u4e3b\u9898\u7279\u5f81\uff09\uff0c\u6bd4\u8f83\u4e8c\u5143\u9053\u5fb7\u5b58\u5728\u68c0\u6d4b\u548c\u591a\u6807\u7b7e\u5206\u7c7b\uff0c\u6d4b\u8bd5\u591a\u6b3e\u6307\u4ee4\u8c03\u4f18\u5927\u8bed\u8a00\u6a21\u578b\u53ca\u5176\u96f6/\u5c11\u6837\u672c\u548cQLoRA\u8bbe\u7f6e\uff0c\u6784\u5efa\u8f6f\u6295\u7968\u96c6\u6210\u3002", "result": "\u4e8c\u5143\u9053\u5fb7\u5b58\u5728\u4efb\u52a1\u8868\u73b0\u8f83\u597d\uff08\u6b63\u7c7bF1\u7ea60.74\uff09\uff0c\u76f4\u63a5\u591a\u6807\u7b7e\u5206\u7c7b\u4f18\u4e8e\u5206\u5c42\u95e8\u63a7\u7ed3\u6784\uff0c\u8f6f\u6295\u7968\u96c6\u6210\u6a21\u578b\u5b8fF1\u8fbe0.332\uff0c\u8d85\u8d8a\u5355\u6a21\u578b\u548c\u5148\u524d\u57fa\u7ebf\u3002", "conclusion": "\u5728\u65b0\u95fb\u548c\u653f\u6cbb\u5ba3\u8a00\u7684\u53e5\u5b50\u7ea7\u7a00\u758f\u9053\u5fb7\u7ebf\u7d22\u548c\u7c7b\u522b\u4e0d\u5e73\u8861\u80cc\u666f\u4e0b\uff0c\u8f7b\u91cf\u7ea7\u4fe1\u53f7\u548c\u5c0f\u578b\u96c6\u6210\u6a21\u578b\u80fd\u663e\u8457\u63d0\u5347\u4eba\u7c7b\u4ef7\u503c\u68c0\u6d4b\u6027\u80fd\uff0c\u5206\u5c42\u95e8\u63a7\u7ed3\u6784\u6536\u76ca\u6709\u9650\u3002\u7ecf\u8fc7\u8c03\u4f18\u7684\u6709\u76d1\u7763\u7f16\u7801\u5668\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u4e0b\u4ecd\u662f\u5f3a\u6709\u529b\u7684\u57fa\u7ebf\u3002"}}
{"id": "2601.14210", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14210", "abs": "https://arxiv.org/abs/2601.14210", "authors": ["Rohan Bhatnagar", "Youran Sun", "Chi Andrew Zhang", "Yixin Wen", "Haizhao Yang"], "title": "HALT: Hallucination Assessment via Latent Testing", "comment": null, "summary": "Hallucination in large language models (LLMs) can be understood as a failure of faithful readout: although internal representations may encode uncertainty about a query, decoding pressures still yield a fluent answer. We propose lightweight residual probes that read hallucination risk directly from intermediate hidden states of question tokens, motivated by the hypothesis that these layers retain epistemic signals that are attenuated in the final decoding stage. The probe is a small auxiliary network whose computation is orders of magnitude cheaper than token generation and can be evaluated fully in parallel with inference, enabling near-instantaneous hallucination risk estimation with effectively zero added latency in low-risk cases. We deploy the probe as an agentic critic for fast selective generation and routing, allowing LLMs to immediately answer confident queries while delegating uncertain ones to stronger verification pipelines. Across four QA benchmarks and multiple LLM families, the method achieves strong AUROC and AURAC, generalizes under dataset shift, and reveals interpretable structure in intermediate representations, positioning fast internal uncertainty readout as a principled foundation for reliable agentic AI.", "AI": {"tldr": "\u901a\u8fc7\u8bbe\u8ba1\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u63a2\u9488\uff0c\u5feb\u901f\u8bfb\u53d6\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u95f4\u72b6\u6001\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u9ad8\u51c6\u786e\u5ea6\u7684\u5e7b\u89c9\u98ce\u9669\u4f30\u8ba1\uff0c\u63d0\u5347\u6a21\u578b\u53ef\u9760\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u7b54\u6848\u65f6\u867d\u7136\u5185\u90e8\u7f16\u7801\u4e86\u4e0d\u786e\u5b9a\u6027\uff0c\u4f46\u6700\u7ec8\u89e3\u7801\u8fc7\u7a0b\u4ecd\u4f1a\u4ea7\u751f\u6d41\u7545\u4f46\u53ef\u80fd\u4e0d\u51c6\u786e\u7684\u56de\u7b54\uff0c\u5bfc\u81f4\u5e7b\u89c9\u3002\u9700\u8981\u4e00\u79cd\u5feb\u901f\u53ef\u9760\u7684\u65b9\u6cd5\u76f4\u63a5\u4ece\u6a21\u578b\u5185\u90e8\u72b6\u6001\u4e2d\u8bfb\u53d6\u4e0d\u786e\u5b9a\u6027\u4fe1\u53f7\uff0c\u4ee5\u964d\u4f4e\u5e7b\u89c9\u98ce\u9669\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u5c0f\u578b\u8f85\u52a9\u7f51\u7edc\uff08\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u63a2\u9488\uff09\uff0c\u901a\u8fc7\u8bfb\u53d6\u95ee\u9898\u8bcd\u4ee4\u724c\u7684\u4e2d\u95f4\u9690\u85cf\u5c42\u72b6\u6001\u4e2d\u7684\u77e5\u8bc6\u4e0d\u786e\u5b9a\u4fe1\u53f7\uff0c\u5feb\u901f\u4f30\u8ba1\u5e7b\u89c9\u98ce\u9669\u3002\u8be5\u63a2\u9488\u8ba1\u7b97\u5f00\u9500\u6781\u4f4e\uff0c\u53ef\u4e0e\u63a8\u7406\u5e76\u884c\u6267\u884c\uff0c\u5b9e\u73b0\u8fd1\u4e4e\u96f6\u5ef6\u8fdf\u7684\u98ce\u9669\u8bc4\u4f30\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u548c\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684AUROC\u548cAURAC\uff0c\u4e14\u5728\u6570\u636e\u96c6\u53d8\u5316\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u80fd\u591f\u53d1\u73b0\u4e2d\u95f4\u8868\u793a\u4e2d\u7684\u53ef\u89e3\u91ca\u7ed3\u6784\uff0c\u652f\u6301\u5feb\u901f\u4e14\u53ef\u9760\u7684\u5e7b\u89c9\u98ce\u9669\u8bc4\u4f30\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u63a2\u9488\u80fd\u591f\u4ece\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u4e2d\u76f4\u63a5\u8bfb\u53d6\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u98ce\u9669\uff0c\u8fbe\u5230\u5feb\u901f\u51c6\u786e\u4f30\u8ba1\u5e7b\u89c9\u98ce\u9669\u7684\u76ee\u7684\u3002\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u95ee\u7b54\u57fa\u51c6\u548c\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u89e3\u91ca\u6027\u3002"}}
{"id": "2601.14230", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.14230", "abs": "https://arxiv.org/abs/2601.14230", "authors": ["Yiyang Wang", "Yiqiao Jin", "Alex Cabral", "Josiah Hester"], "title": "MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems", "comment": "15 pages, 9 figures", "summary": "Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective socio-collaborative companions. MASCOT introduces a novel bi-level optimization strategy to harmonize individual and collective behaviors: 1) Persona-Aware Behavioral Alignment, an RLAIF-driven pipeline that finetunes individual agents for strict persona fidelity to prevent identity loss; and 2) Collaborative Dialogue Optimization, a meta-policy guided by group-level rewards to ensure diverse and productive discourse. Extensive evaluations across psychological support and workplace domains demonstrate that MASCOT significantly outperforms state-of-the-art baselines, achieving improvements of up to +14.1 in Persona Consistency and +10.6 in Social Contribution. Our framework provides a practical roadmap for engineering the next generation of socially intelligent multi-agent systems.", "AI": {"tldr": "\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u89d2\u8272\u5d29\u584c\u95ee\u9898\uff0c\u63d0\u51faMASCOT\u53cc\u5c42\u4f18\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u89d2\u8272\u4e00\u81f4\u6027\u548c\u5bf9\u8bdd\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u9762\u4e34\u89d2\u8272\u5d29\u584c\u548c\u793e\u4ea4\u8c04\u5a9a\u73b0\u8c61\uff0c\u5bfc\u81f4\u884c\u4e3a\u5355\u4e00\u548c\u5bf9\u8bdd\u7f3a\u4e4f\u5efa\u8bbe\u6027\u3002", "method": "\u63d0\u51faMASCOT\u6846\u67b6\uff0c\u91c7\u7528\u53cc\u5c42\u4f18\u5316\u7b56\u7565\uff1a1\uff09\u57fa\u4e8eRLAIF\u7684\u89d2\u8272\u611f\u77e5\u884c\u4e3a\u5bf9\u9f50\uff0c\u63d0\u5347\u4e2a\u4f53\u89d2\u8272\u4e00\u81f4\u6027\uff1b2\uff09\u57fa\u4e8e\u7fa4\u4f53\u5956\u52b1\u7684\u534f\u4f5c\u5bf9\u8bdd\u4f18\u5316\uff0c\u4fc3\u8fdb\u591a\u6837\u548c\u9ad8\u6548\u4ea4\u6d41\u3002", "result": "\u5728\u5fc3\u7406\u652f\u6301\u548c\u804c\u573a\u9886\u57df\u7684\u5e7f\u6cdb\u8bc4\u4f30\u4e2d\uff0cMASCOT\u5728\u89d2\u8272\u4e00\u81f4\u6027\u63d0\u5347\u4e8614.1\uff0c\u793e\u4ea4\u8d21\u732e\u63d0\u5347\u4e8610.6\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "MASCOT\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u89d2\u8272\u5d29\u584c\u548c\u793e\u4ea4\u8c04\u5a9a\u95ee\u9898\uff0c\u63a8\u52a8\u4e86\u66f4\u5177\u793e\u4f1a\u667a\u80fd\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u53d1\u5c55\u3002"}}
{"id": "2601.14242", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14242", "abs": "https://arxiv.org/abs/2601.14242", "authors": ["Bertie Vidgen", "Austin Mann", "Abby Fennelly", "John Wright Stanly", "Lucas Rothman", "Marco Burstein", "Julien Benchek", "David Ostrofsky", "Anirudh Ravichandran", "Debnil Sur", "Neel Venugopal", "Alannah Hsia", "Isaac Robinson", "Calix Huang", "Olivia Varones", "Daniyal Khan", "Michael Haines", "Zach Richards", "Chirag Mahapatra", "Brendan Foody", "Osvald Nitski"], "title": "APEX-Agents", "comment": null, "summary": "We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 Flash (Thinking=High) achieves the highest score of 24.0%, followed by GPT-5.2 (Thinking=High), Claude Opus 4.5 (Thinking=High), and Gemini 3 Pro (Thinking=High). We open source the APEX-Agents benchmark (n=480) with all prompts, rubrics, gold outputs, files, and metadata. We also open-source Archipelago, our infrastructure for agent execution and evaluation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30AI\u4ee3\u7406\u6267\u884c\u590d\u6742\u5de5\u4f5c\u4efb\u52a1\u80fd\u529b\u7684\u57fa\u51c6APEX-Agents\uff0c\u5c55\u793a\u4e86\u4e0d\u540c\u4ee3\u7406\u7684\u6027\u80fd\u6392\u540d\u5e76\u5f00\u6e90\u4e86\u76f8\u5173\u6570\u636e\u548c\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "\u8bc4\u4f30AI\u4ee3\u7406\u5728\u590d\u6742\u3001\u8de8\u5e94\u7528\u73af\u5883\u4e2d\u6267\u884c\u771f\u5b9e\u5de5\u4f5c\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u4ee5\u63a8\u52a8\u751f\u4ea7\u529b\u63d0\u5347\u3002", "method": "\u6784\u5efa\u4e86APEX-Agents\u57fa\u51c6\uff0c\u5305\u62ec\u7531\u6295\u8d44\u94f6\u884c\u5206\u6790\u5e08\u3001\u7ba1\u7406\u987e\u95ee\u548c\u516c\u53f8\u5f8b\u5e08\u8bbe\u8ba1\u7684\u771f\u5b9e\u4efb\u52a1\uff0c\u6d4b\u8bd5\u4ee3\u7406\u5982\u4f55\u4f7f\u7528\u6587\u4ef6\u548c\u5de5\u5177\u5b8c\u6210\u4efb\u52a1\uff0c\u91c7\u7528Pass@1\u6307\u6807\u8bc4\u4f30\u3002", "result": "Gemini 3 Flash\uff08Thinking=High\uff09\u53d6\u5f97\u6700\u9ad824.0%\u7684\u6210\u7ee9\uff0c\u5176\u4ed6\u9ad8\u8868\u73b0\u4ee3\u7406\u5305\u62ecGPT-5.2\u3001Claude Opus 4.5\u548cGemini 3 Pro\u3002", "conclusion": "APEX-Agents\u57fa\u51c6\u6d4b\u8bd5\u9a8c\u8bc1\u4e86AI\u4ee3\u7406\u5728\u6267\u884c\u957f\u5468\u671f\u3001\u8de8\u5e94\u7528\u4efb\u52a1\u4e2d\u7684\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u90e8\u5206\u4ee3\u7406\u5728\u590d\u6742\u5de5\u4f5c\u73af\u5883\u4e2d\u7684\u4f18\u8d8a\u8868\u73b0\u3002"}}
{"id": "2601.14249", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.14249", "abs": "https://arxiv.org/abs/2601.14249", "authors": ["Yuming Yang", "Mingyoung Lai", "Wanxu Zhao", "Xiaoran Fan", "Zhiheng Xi", "Mingqi Wu", "Chiyue Huang", "Jun Zhao", "Haijun Lv", "Jian Tong", "Yunhua Zhou", "Yicheng Zou", "Qipeng Guo", "Tao Gui", "Qi Zhang", "Xuanjing Huang"], "title": "Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment", "comment": "26 pages. Project page: https://github.com/UmeanNever/RankSurprisalRatio", "summary": "Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield better students, highlighting the importance of data-student suitability in distillation. Existing methods assess suitability primarily through student likelihood, favoring trajectories that closely align with the model's current behavior but overlooking more informative ones. Addressing this, we propose Rank-Surprisal Ratio (RSR), a simple metric that captures both alignment and informativeness to assess the suitability of a reasoning trajectory. RSR is motivated by the observation that effective trajectories typically combine low absolute probability with relatively high-ranked tokens under the student model, balancing learning signal strength and behavioral alignment. Concretely, RSR is defined as the ratio of a trajectory's average token-wise rank to its average negative log-likelihood, and is straightforward to compute and interpret. Across five student models and reasoning trajectories from 11 diverse teachers, RSR strongly correlates with post-training performance (average Spearman 0.86), outperforming existing metrics. We further demonstrate its practical utility in both trajectory selection and teacher selection.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faRSR\u6307\u6807\uff0c\u6709\u6548\u8bc4\u4f30\u63a8\u7406\u8f68\u8ff9\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u9002\u914d\u6027\uff0c\u63d0\u5347\u84b8\u998f\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u53d1\u73b0\u66f4\u5f3a\u6559\u5e08\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e0d\u4e00\u5b9a\u4ea7\u751f\u66f4\u597d\u7684\u5b66\u751f\u6a21\u578b\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5ffd\u89c6\u4e86\u8f68\u8ff9\u7684\u6f5c\u5728\u4fe1\u606f\u4ef7\u503c\uff0c\u5bfc\u81f4\u9002\u914d\u6027\u5224\u65ad\u4e0d\u8db3\u3002", "method": "\u8bbe\u8ba1Rank-Surprisal Ratio (RSR)\u6307\u6807\uff0c\u5373\u8f68\u8ff9\u4e2d\u6bcf\u4e2atoken\u7684\u5e73\u5747\u6392\u540d\u4e0e\u5e73\u5747\u8d1f\u5bf9\u6570\u4f3c\u7136\u7684\u6bd4\u7387\uff0c\u7efc\u5408\u8bc4\u4f30\u8f68\u8ff9\u7684\u884c\u4e3a\u4e00\u81f4\u6027\u4e0e\u4fe1\u606f\u542b\u91cf\u3002", "result": "RSR\u5728\u4e94\u4e2a\u5b66\u751f\u6a21\u578b\u53ca11\u4e2a\u6559\u5e08\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4e2d\u4e0e\u8bad\u7ec3\u540e\u6027\u80fd\u9ad8\u5ea6\u76f8\u5173\uff08\u5e73\u5747Spearman\u76f8\u5173\u7cfb\u65700.86\uff09\uff0c\u4f18\u4e8e\u73b0\u6709\u6307\u6807\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u8f68\u8ff9\u53ca\u6559\u5e08\u9009\u62e9\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684RSR\u6307\u6807\u6709\u6548\u8861\u91cf\u63a8\u7406\u8f68\u8ff9\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u9002\u914d\u6027\uff0c\u66f4\u597d\u5730\u63d0\u5347\u4e86\u84b8\u998f\u540e\u7684\u5b66\u751f\u6a21\u578b\u8868\u73b0\u3002"}}
