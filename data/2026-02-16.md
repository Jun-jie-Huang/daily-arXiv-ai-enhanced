<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.SE](#cs.SE) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

TL;DR: 本文提出了一种轻量且高效的灾难推文分类框架，利用参数高效微调技术，在资源受限环境中实现高性能人道主义信息分类，且发现RAG策略可能降低效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体中的人道主义信息及时分类对于灾难应对至关重要，但在资源受限的紧急环境中部署大型语言模型面临挑战。

Method: 构建了一个轻量级的、成本效益高的灾难推文分类框架，采用参数高效的微调方法（LoRA和QLoRA），在Llama 3.1 8B模型上系统评估了提示策略、微调和基于检索的生成（RAG）。

Result: LoRA微调方法在只训练约2%参数的情况下，实现了79.62%的人道主义分类准确率，较零-shot提升37.79%；QLoRA方法以50%内存成本达到LoRA的99.4%性能；RAG策略反而因检索示例的标签噪声降低了模型表现。

Conclusion: 研究表明，参数高效的微调（LoRA和QLoRA）是资源受限环境下构建可信危机智能系统的实用方法，而基于检索的生成策略由于标签噪声不适合此任务。

Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [2] [From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness](https://arxiv.org/abs/2602.12285)
*Linbo Cao,Lihao Sun,Yang Yue*

Main category: cs.CL

TL;DR: 身份设定会显著影响大语言模型代理的性能和行为，带来安全和可靠性风险，应引起重视。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLMs）作为自主代理在实际任务中的表现，尤其是身份设定（persona）对任务性能的影响，因为此前对文本生成中的身份偏见已有研究，但对代理任务性能的影响缺乏系统研究。

Method: 通过在各种代理任务基准（涵盖战略推理、规划和技术操作）上评估广泛部署的LLM模型，并引入基于人口统计的身份设定，观察其对代理行为和性能的影响。

Result: 发现身份设定导致的任务性能波动显著，最高可达26.2%的性能下降，这种影响跨任务类型和模型架构普遍存在，表明简单的身份提示可以扭曲代理的决策可靠性。

Conclusion: 身份设定是当前LLM代理系统中的一个被忽视的脆弱点，可能引入隐性偏见并增加行为的波动性，进而影响其安全性和鲁棒性，需要在实际部署中予以重视。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on agent task performance remain largely unexplored, even though such effects pose more direct operational risks. In this work, we present the first systematic case study showing that demographic-based persona assignments can alter LLM agents' behavior and degrade performance across diverse domains. Evaluating widely deployed models on agentic benchmarks spanning strategic reasoning, planning, and technical operations, we uncover substantial performance variations - up to 26.2% degradation, driven by task-irrelevant persona cues. These shifts appear across task types and model architectures, indicating that persona conditioning and simple prompt injections can distort an agent's decision-making reliability. Our findings reveal an overlooked vulnerability in current LLM agentic systems: persona assignments can introduce implicit biases and increase behavioral volatility, raising concerns for the safe and robust deployment of LLM agents.

</details>


### [3] [Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction](https://arxiv.org/abs/2602.12287)
*Junjie An,Jingguang Tian,Tianyi Wang,Yu Gao,Xiaofeng Mou,Yi Xu*

Main category: cs.CL

TL;DR: 通过结合检索增强与自适应链式推理，显著提升自动语音识别中的命名实体纠正效果。


<details>
  <summary>Details</summary>
Motivation: 端到端自动语音识别系统常误识别领域特定短语如命名实体，导致下游任务严重失败，现有基于大型语言模型的命名实体纠正方法未充分利用其复杂推理能力。

Method: 提出了一种基于检索增强生成的命名实体纠正框架，包括重述语言模型进行命名实体识别及基于语音编辑距离的候选检索，以及自适应链式推理的自学推理模型。

Result: 在AISHELL-1和Homophone数据集上，相比强基线，命名实体字错误率相对降低17.96%和34.42%。

Conclusion: 所提出的方法有效利用大型语言模型的推理能力，显著减少自动语音识别的命名实体错误，证明了该框架的实用性和优越性。

Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

</details>


### [4] [Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria à Prática](https://arxiv.org/abs/2602.12302)
*Neemias da Silva,Júlio C. W. Scholz,John Harrison,Marina Borges,Paulo Ávila,Frances A Santos,Myriam Delgado,Rodrigo Minetto,Thiago H Silva*

Main category: cs.CL

TL;DR: 介绍多模态大语言模型的基础、技术实现和应用，附带开源资源，讨论未来挑战与趋势。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能领域中，自然语言处理与多模态感知技术的结合是重要发展方向。

Method: 介绍多模态大语言模型（MLLMs）的基本原理及典型模型，讲解数据预处理、提示工程及多模态管道构建技术（使用LangChain和LangGraph）。

Result: 系统总结了MLLMs的关键技术和应用方法，并提供开源代码供实践学习。

Conclusion: 本章节全面阐述了多模态大语言模型的理论基础与实践技术，指出当前面临的挑战及未来发展趋势。

Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter presents the main fundamentals of MLLMs and emblematic models. Practical techniques for preprocessing, prompt engineering, and building multimodal pipelines with LangChain and LangGraph are also explored. For further practical study, supplementary material is publicly available online: https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica. Finally, the chapter discusses the challenges and highlights promising trends.

</details>


### [5] [propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale](https://arxiv.org/abs/2602.12414)
*Maximilian Idahl,Benedikt Droste,Björn Plüster,Jan Philipp Harries*

Main category: cs.CL

TL;DR: 本文提出了propella-1，一种多语言小型大语言模型，能够对文本数据进行多维度、结构化的质量注释，提升了语料预处理的灵活性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有预训练语料质量评估依赖单一质量分值，缺乏对多维质量属性的区分和解释，不利于灵活筛选和深入分析。

Method: 设计并训练多语言的小型LLM，能针对文本的18个属性进行结构化JSON格式的注释，涵盖六大类别，支持57种语言，并通过与商业大型模型对比验证性能。

Result: propella-1 4B模型在标注一致性上超过大型通用模型，发布了覆盖主要预训练语料库的30亿条文档多维注释数据，揭示了单分值方法难以发现的语料质量和内容差异。

Conclusion: propella-1模型在多语言多维度文本注释任务上表现优于现有大规模通用模型，生成的大规模多维标注数据集有助于深入分析语料质量和组成。

Abstract: Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.

</details>


### [6] [RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty](https://arxiv.org/abs/2602.12424)
*Ziqian Zhang,Xingjian Hu,Yue Huang,Kai Zhang,Ruoxi Chen,Yixin Liu,Qingsong Wen,Kaidi Xu,Xiangliang Zhang,Neil Zhenqiang Gong,Lichao Sun*

Main category: cs.CL

TL;DR: 针对现有基准无法区分问题难度的问题，RankLLM提出一种基于双向得分传播的新框架，能准确评估大语言模型能力并考虑问题难度，效果优异且高效。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法区分问题难度，限制了对大语言模型能力的精准评估。

Method: 提出RankLLM框架，通过模型和问题之间的双向得分传播机制量化问题难度和模型能力。模型正确回答问题则获得能力得分，问题挑战模型则提升难度得分。

Result: 在35550个跨领域问题和30个模型的测试中，RankLLM与人工评判一致率达90%，优于IRT等基准方法，表现出快速收敛和高计算效率。

Conclusion: RankLLM框架能够有效区分问题难度和模型能力，评估精度高，且优于现有基准方法，具有较强稳定性和高效性。

Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.

</details>


### [7] [RBCorr: Response Bias Correction in Language Models](https://arxiv.org/abs/2602.12445)
*Om Bhatt,Anna A. Ivanova*

Main category: cs.CL

TL;DR: 本文提出RBCorr方法有效纠正语言模型在固定响应问题中的偏差，提升性能并增强结果真实性。


<details>
  <summary>Details</summary>
Motivation: 语言模型在固定响应问题中存在响应偏差，影响模型性能和能力评估，需开发低成本有效的偏差校正方法提升模型表现和评估准确性。

Method: 提出并应用RBCorr响应偏差校正策略，在12种语言模型和多种题型上测试效果，使用基于对数概率的校正方法进行偏差调整。

Result: 该论文提出了一种简单的响应偏差校正策略（RBCorr），用于纠正语言模型（LMs）在固定响应问题中存在的选项偏好偏差。通过在12个开源语言模型上使用是非题、蕴涵题和多项选择题进行测试，验证了校正策略能有效消除偏差并提升模型性能。研究还探讨了不同模型、数据集和提示格式下偏差行为的普适性，发现基于对数概率的校正对这些因素高度依赖。整体来看，RBCorr是一个低成本、易用的方法，有助于提升小型语言模型表现，使闭合响应基准测试的结果更能准确反映模型的真实能力。

Conclusion: RBCorr能够有效消除语言模型的响应偏差，提升模型性能，并使评估更准确反映模型能力。

Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.

</details>


### [8] [Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification](https://arxiv.org/abs/2602.12575)
*Bo Wang,Yuxuan Zhang,Yueqin Hu,Hanchao Hou,Kaiping Peng,Shiguang Ni*

Main category: cs.CL

TL;DR: 提出利用自然语言处理中的语义主题模型简化心理量表，实现无反应数据的结构逼近，有效减少量表条目且保持心理测量效能。


<details>
  <summary>Details</summary>
Motivation: 传统心理量表优化依赖反应数据方法（如因子分析、项目反应理论），需大样本且受数据可用性和跨文化适用性限制，语义结构提供无反应数据的补充视角。

Method: 引入基于主题建模的框架，将问卷条目通过上下文句子嵌入编码，并利用基于密度的聚类发现潜在语义因子，使用类基词加权生成可解释的主题表示，进而合并语义相邻的聚类，通过成员资格标准选择代表性条目进行简化。

Result: 该框架能恢复与既定构造一致的语义因子组，简化量表条目平均减少60.5%，心理测量效度保持良好，简化后的量表结构及因子间相关性高度一致。

Conclusion: 语义潜在结构可作为心理量表构建和简化的二线前端，提供可解释的结构视角，模型及可视化工具便于实际应用推广。

Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be constrained by data availability and cross-cultural comparability. Recent advances in natural language processing suggest that the semantic structure of questionnaire items may encode latent construct organization, offering a complementary response-free perspective. We introduce a topic-modeling framework that operationalizes semantic latent structure for scale simplification. Items are encoded using contextual sentence embeddings and grouped via density-based clustering to discover latent semantic factors without predefining their number. Class-based term weighting derives interpretable topic representations that approximate constructs and enable merging of semantically adjacent clusters. Representative items are selected using membership criteria within an integrated reduction pipeline. We benchmarked the framework across DASS, IPIP, and EPOCH, evaluating structural recovery, internal consistency, factor congruence, correlation preservation, and reduction efficiency. The proposed method recovered coherent factor-like groupings aligned with established constructs. Selected items reduced scale length by 60.5% on average while maintaining psychometric adequacy. Simplified scales showed high concordance with original factor structures and preserved inter-factor correlations, indicating that semantic latent organization provides a response-free approximation of measurement structure. Our framework formalizes semantic structure as an inspectable front-end for scale construction and reduction. To facilitate adoption, we provide a visualization-supported tool enabling one-click semantic analysis and structured simplification.

</details>


### [9] [Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats](https://arxiv.org/abs/2602.12635)
*Pengxiang Zhao,Hui-Ling Zhen,Xing Li,Han Bao,Weizhe Lin,Zhiyuan Yang,Ziwei Yu,Xin Wang,Mingxuan Yuan,Xianzhi Yu,Zhenhua Dong*

Main category: cs.CL

TL;DR: 本文评估了专为Ascend NPU设计的HiFloat低位宽浮点格式，证明其在高方差数据和4位精度下优于整数格式，且与主流量化框架兼容，是高效LLM推理的理想选择。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的规模扩大，现有的低位宽浮点格式为提高精度和效率提供了新机会。本文动机是评估专为Ascend NPU设计的HiFloat格式家族（HiF8和HiF4），以优化LLM推理的效能。

Method: 通过在权重激活和KV缓存任务中的严格比较，评估HiFloat格式在不同位宽和数据类型上的表现，与整数格式及其他浮点格式进行对比。

Result: 发现INT8适合窄范围数据，而浮点格式在高方差数据上表现更好；HiF4在4位宽情况下通过分层缩放避免了整数格式的准确性崩溃；HiFloat格式与最先进的后训练量化框架完全兼容。

Conclusion: HiFloat提供了一种适合Ascend NPU的高效LLM推理解决方案，兼具精度和计算效率优势。

Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across weight-activation and KV-cache tasks, we provide three key insights: (1) INT8 suits narrow-range data, while floating-point formats excel with high-variance data; (2) in 4-bit regimes, HiF4's hierarchical scaling prevents the accuracy collapse seen in integer formats; and (3) HiFloat is fully compatible with state-of-the-art post-training quantization frameworks. Overall, HiFloat provides a solution for high-efficiency LLM inference on NPUs.

</details>


### [10] [CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation](https://arxiv.org/abs/2602.12639)
*Yiran Rex Ma,Yuxiao Ye,Huiyuan Xie*

Main category: cs.CL

TL;DR: 该论文提出了一种名为CLASE的混合评价方法，用于评估中文法律文本的风格质量，结合语言特征和大语言模型评分，实现无参照、透明、高度符合人工判断的风格评估。


<details>
  <summary>Details</summary>
Motivation: 现有法律文本的自动风格评价手段不足，人工制定评价标准难以形式化，且现有的方法在语义准确度与风格保真度上存在混淆或不稳定的问题。

Method: CLASE采用混合评分机制，结合基于语言特征的得分和经验指导的大语言模型评分，这两个部分均通过对比真实法律文档与其LLM还原版本学习获得。

Result: 在200份中文法律文档实验中，CLASE方法在风格评价上与人类判断的匹配度显著提升，且能提供改进建议，展示了其实用性和可扩展性。

Conclusion: CLASE显著优于传统和纯LLM评分方法，在评估法律文本风格质量时更符合人类判断，且能提供可解释的评分细节和改进建议。

Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic quality, a crucial first step is to establish a reliable evaluation method. However, having legal experts manually develop such a metric is impractical, as the implicit stylistic requirements in legal writing practice are difficult to formalise into explicit rubrics. Meanwhile, existing automatic evaluation methods also fall short: reference-based metrics conflate semantic accuracy with stylistic fidelity, and LLM-as-a-judge evaluations suffer from opacity and inconsistency. To address these challenges, we introduce CLASE (Chinese LegAlese Stylistic Evaluation), a hybrid evaluation method that focuses on the stylistic performance of legal text. The method incorporates a hybrid scoring mechanism that combines 1) linguistic feature-based scores and 2) experience-guided LLM-as-a-judge scores. Both the feature coefficients and the LLM scoring experiences are learned from contrastive pairs of authentic legal documents and their LLM-restored counterparts. This hybrid design captures both surface-level features and implicit stylistic norms in a transparent, reference-free manner. Experiments on 200 Chinese legal documents show that CLASE achieves substantially higher alignment with human judgments than traditional metrics and pure LLM-as-a-judge methods. Beyond improved alignment, CLASE provides interpretable score breakdowns and suggestions for improvements, offering a scalable and practical solution for professional stylistic evaluation in legal text generation (Code and data for CLASE is available at: https://github.com/rexera/CLASE).

</details>


### [11] [Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR](https://arxiv.org/abs/2602.12642)
*Dohyung Kim,Minbeom Kim,Jeonghye Kim,Sangmook Lee,Sojeong Rhee,Kyomin Jung*

Main category: cs.CL

TL;DR: 通过重新利用GFlowNet训练中分区函数的准确率信息，PACED-RL实现了更高效的分布匹配训练，提高了大规模语言模型的推理性能和样本效率。


<details>
  <summary>Details</summary>
Motivation: 当前奖励最大化的强化学习方法虽然提升了LLMs的推理能力，但减少了输出多样性，且现有用GFlowNet的方法未充分利用分区函数中的有价值信息，导致样本效率较低，因此需要一种更高效的训练范式。

Method: 方法基于将分区函数视为每个提示的期望奖励信号，结合优先采样和基于准确率估计误差的重放机制，实现训练过程的样本利用最大化，并且重复利用已有信息降低计算开销。

Result: 本文提出了一种名为PACED-RL的新方法，通过重新解读GFlowNet中的分区函数为每个提示语的期望奖励信号，从而提升了训练大规模语言模型（LLMs）的样本效率。该方法利用分区函数估计准确率，优先选择信息量丰富的提示语进行训练，并采用基于准确率误差的重放机制进行优化，显著优于现有的GRPO及GFlowNet方法。

Conclusion: PACED-RL通过巧妙利用分区函数中的额外信息，有效提升了LLMs训练的样本效率和推理性能，验证了其作为一种高效分布匹配训练方法的潜力。

Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its partition function. In contrast to prior works that treat this partition function solely as a normalizer, we reinterpret it as a per-prompt expected-reward (i.e., online accuracy) signal, leveraging this unused information to improve sample efficiency. Specifically, we first establish a theoretical relationship between the partition function and per-prompt accuracy estimates. Building on this key insight, we propose Partition Function-Guided RL (PACED-RL), a post-training framework that leverages accuracy estimates to prioritize informative question prompts during training, and further improves sample efficiency through an accuracy estimate error-prioritized replay. Crucially, both components reuse information already produced during GFlowNet training, effectively amortizing the compute overhead into the existing optimization process. Extensive experiments across diverse benchmarks demonstrate strong performance improvements over GRPO and prior GFlowNet approaches, highlighting PACED-RL as a promising direction for a more sample efficient distribution-matching training for LLMs.

</details>


### [12] [Learning Ordinal Probabilistic Reward from Preferences](https://arxiv.org/abs/2602.12660)
*Longze Chen,Lu Wang,Renke Shan,Ze Gong,Run Luo,Jiaming Li,Jing Luo,Qiyao Wang,Min Yang*

Main category: cs.CL

TL;DR: 本文提出了一种新的概率奖励模型，通过学习奖励的概率分布并引入序数评级和区域泛洪调优策略，显著提升了奖励模型的准确率和数据效率，更好地反映文本质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成式奖励模型需要昂贵的点对点监督，判别式奖励模型得分缺乏概率解释，限制了模型的校准和性能，因此需要新的奖励建模范式来克服这些问题。

Method: PRM将奖励视为随机变量，学习奖励的概率分布；基于PRM提出OPRM，将质量评分离散化为序数评级；引入区域泛洪调优(RgFT)训练策略，通过质量等级注释，引导模型聚焦概率质量子区以提升体现绝对质量的能力。

Result: 在多个奖励模型基准测试中，方法提升了2.9%至7.4%的准确率，表现出较强的性能和数据效率，同时得分分布分析表明其既捕捉了相对排名也体现了绝对质量。

Conclusion: 提出的概率奖励模型（PRM）和其具体实现序数概率奖励模型（OPRM）有效提升了奖励模型的准确性和数据效率，能够更好地反映绝对文本质量，超越了现有生成式和判别式奖励模型的表现。

Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand costly point-wise supervision, while DRMs produce uncalibrated relative scores that lack probabilistic interpretation. To address these challenges, we introduce a novel reward modeling paradigm: Probabilistic Reward Model (PRM). Instead of modeling reward as a deterministic scalar, our approach treats it as a random variable, learning a full probability distribution for the quality of each response. To make this paradigm practical, we present its closed-form, discrete realization: the Ordinal Probabilistic Reward Model (OPRM), which discretizes the quality score into a finite set of ordinal ratings. Building on OPRM, we propose a data-efficient training strategy called Region Flooding Tuning (RgFT). It enables rewards to better reflect absolute text quality by incorporating quality-level annotations, which guide the model to concentrate the probability mass within corresponding rating sub-regions. Experiments on various reward model benchmarks show that our method improves accuracy by $\textbf{2.9%}\sim\textbf{7.4%}$ compared to prior reward models, demonstrating strong performance and data efficiency. Analysis of the score distribution provides evidence that our method captures not only relative rankings but also absolute quality.

</details>


### [13] [$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2602.12674)
*Yuang Cai,Yuyu Yuan*

Main category: cs.CL

TL;DR: 该论文提出了一种基于体验学习理论和逆向强化学习的新颖知识蒸馏方法——体验知识蒸馏（X-KD），使学生模型能模拟教师模型的原始学习环境，从而提升大型语言模型的蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法多关注模仿教师行为，忽视了教师知识形成的原始学习环境，受体验学习理论和逆向强化学习启发，设计更符合教师训练过程的蒸馏方法。

Method: 采用近似变分奖励模仿学习框架（AVRIL），联合建模教师原始奖励函数并执行策略蒸馏，确保学生策略与原始奖励函数的一致性。

Result: X-KD在多个任务上优于基线方法（包括广义知识蒸馏和MiniLLM），表现出更好的性能和多样性权衡以及更高的数据利用效率。

Conclusion: X-KD方法在摘要生成、机器翻译和算术推理等任务上优于传统知识蒸馏方法，且在性能与多样性以及数据效率之间取得更好的平衡。

Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning environment that shaped the teacher's knowledge. Inspired by the experiential learning theory and inverse reinforcement learning, we propose Experiential Knowledge Distillation ($\mathcal{X}$-KD), a novel and general framework that enables student models to learn in the teacher's original learning environment. $\mathcal{X}$-KD adopts the Approximated Variational Reward Imitation Learning (AVRIL) framework to jointly model the teacher's original reward function and perform policy distillation, encouraging consistency between the student policy and the original reward function. Our derivation demonstrates that $\mathcal{X}$-KD follows the supervised learning framework and applies to both sequence-level and divergence-based distillation methods, underlining the simplicity and flexibility of our approach. Empirical results show that $\mathcal{X}$-KD outperforms the generalized KD and MiniLLM baselines on abstractive summarization, machine translation, and arithmetic reasoning tasks. Additionally, $\mathcal{X}$-KD achieves better performance-diversity trade-off and data efficiency than baseline KD approaches.

</details>


### [14] [MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs](https://arxiv.org/abs/2602.12705)
*Baorong Shi,Bo Cui,Boyuan Jiang,Deli Yu,Fang Qian,Haihua Yang,Huichao Wang,Jiale Chen,Jianfei Pan,Jieqiong Cao,Jinghao Lin,Kai Wu,Lin Yang,Shengsheng Yao,Tao Chen,Xiaojun Xiao,Xiaozhong Ji,Xu Wang,Yijun He,Zhixiong Yang*

Main category: cs.CL

TL;DR: MedXIAOHE通过创新的预训练框架和多样推理训练，实现了医学视觉语言模型的全面提升，推动医学领域的临床应用。


<details>
  <summary>Details</summary>
Motivation: 提升医学模型在真实临床应用中的通用理解和推理能力，覆盖更多医学知识并减少罕见疾病的长尾缺失。

Method: 构建了一种名为MedXIAOHE的医学视觉语言基础模型，采用实体感知的持续预训练框架、多样化医学推理模式的强化学习和工具增强训练。

Result: MedXIAOHE在多种医学基准测试中达到最新最高性能，超越领先封闭多模态系统，在多项能力上表现优异。

Conclusion: MedXIAOHE模型具备广泛医学知识覆盖与专家级推理能力，能生成低幻觉、符合医学指令的长报告，提升了医学AI的实用性和可靠性。

Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical benchmarks and surpasses leading closed-source multimodal systems on multiple capabilities. To achieve this, we propose an entity-aware continual pretraining framework that organizes heterogeneous medical corpora to broaden knowledge coverage and reduce long-tail gaps (e.g., rare diseases). For medical expert-level reasoning and interaction, MedXIAOHE incorporates diverse medical reasoning patterns via reinforcement learning and tool-augmented agentic training, enabling multi-step diagnostic reasoning with verifiable decision traces. To improve reliability in real-world use, MedXIAOHE integrates user-preference rubrics, evidence-grounded reasoning, and low-hallucination long-form report generation, with improved adherence to medical instructions. We release this report to document our practical design choices, scaling insights, and evaluation framework, hoping to inspire further research.

</details>


### [15] [ProbeLLM: Automating Principled Diagnosis of LLM Failures](https://arxiv.org/abs/2602.12966)
*Yue Huang,Zhengzhe Jiang,Yuchen Ma,Yu Jiang,Xiangqi Wang,Yujun Zhou,Yuexing Hao,Kehan Guo,Pin-Yu Chen,Stefan Feuerriegel,Xiangliang Zhang*

Main category: cs.CL

TL;DR: 提出了ProbeLLM框架，通过分层蒙特卡罗树搜索自动发现大语言模型的结构化失败模式，比传统静态基准测试更全面和细粒度。


<details>
  <summary>Details</summary>
Motivation: 现有自动探测方法多发现孤立失败，缺少系统控制和深入见解，难以跟上大语言模型快速演进和静态评测滞后的挑战。

Method: 将探测任务建模为分层蒙特卡罗树搜索，平衡全局探索和局部细化，结合可验证测试、工具增强生成与验证，最后通过失败感知嵌入和边界感知归纳整理失败模式。

Result: ProbeLLM在多个基准和语言模型上表现出更全面、更干净、更细粒度的失败模式发现能力，支持从个案中心向弱点结构化发现转变。

Conclusion: ProbeLLM能够揭示比静态基准和现有自动化方法更广泛、更清晰、更细粒度的模型失败模式，推动从个例评估向系统性弱点发现转变。

Abstract: Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often discover isolated failure cases, lack principled control over exploration, and provide limited insight into the underlying structure of model weaknesses. We propose ProbeLLM, a benchmark-agnostic automated probing framework that elevates weakness discovery from individual failures to structured failure modes. ProbeLLM formulates probing as a hierarchical Monte Carlo Tree Search, explicitly allocating limited probing budgets between global exploration of new failure regions and local refinement of recurring error patterns. By restricting probing to verifiable test cases and leveraging tool-augmented generation and verification, ProbeLLM grounds failure discovery in reliable evidence. Discovered failures are further consolidated into interpretable failure modes via failure-aware embeddings and boundary-aware induction. Across diverse benchmarks and LLMs, ProbeLLM reveals substantially broader, cleaner, and more fine-grained failure landscapes than static benchmarks and prior automated methods, supporting a shift from case-centric evaluation toward principled weakness discovery.

</details>


### [16] [ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter](https://arxiv.org/abs/2602.12709)
*Yixin Chen,Ying Xiong,Shangyu Wu,Xiangrui Ke,Nan Guan,Chun Jason Xue*

Main category: cs.CL

TL;DR: 提出ReFilter，通过token级筛选与融合提升大规模检索辅助生成模型的效果和效率，在多领域问答任务中表现优异，且具有良好的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成方法在增加检索候选数量时容易受无关或冗余信息影响，导致性能和效率下降，亟需一种能够有效筛选并利用大规模检索证据的新方法。

Method: 采用三部分组成的潜在向量融合架构，包括上下文编码器、门控过滤器对token进行加权以及token融合模块将加权特征融入语言模型的隐藏状态。

Result: 本文提出了ReFilter，一种基于潜在向量的检索增强生成框架，着重于对检索到的证据进行 token 级别的筛选和融合，以解决现有方法在大规模检索候选增加时效果下降和推理成本增加的问题。ReFilter包含上下文编码器、门控过滤器和token融合模块。实验结果显示，ReFilter在四个通用领域问答基准上实现了最佳表现，同时在生物医学问答基准的零样本迁移中表现出良好的泛化能力。

Conclusion: ReFilter有效解决了大规模检索下的冗余和无关信息问题，提升了知识密集型问答任务中的性能和泛化能力，证明了token级融合策略的优势。

Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where existing internal fusion approaches broadly fall into query-based fusion, parametric fusion, and latent-based fusion. Despite their effectiveness at modest retrieval scales, these methods often fail to scale gracefully as the number of retrieved candidates k increases: Larger k improves evidence coverage, yet realistic top-k retrieval inevitably contains irrelevant or redundant content and increases the inference cost.
  To address these limitations, we propose ReFilter, a novel latent-based fusion framework that performs token-level filtering and fusion. ReFilter consists of three key components: a context encoder for encoding context features, a gated filter for weighting each token, and a token fusion module for integrating the weighted token feature into the LLM's hidden states. Our experiments across four general-domain QA benchmarks show that ReFilter consistently achieves the best average performance under both in-domain adaptation and out-of-domain transfer. ReFilter further generalizes to five biomedical QA benchmarks in zero-shot transfer without domain fine-tuning, reaching 70.01% average accuracy with Qwen2.5-14B-Instruct.

</details>


### [17] [Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting](https://arxiv.org/abs/2602.12746)
*Jing Xu,Minglin Wu,Xueyuan Chen,Xixin Wu,Helen Meng*

Main category: cs.CL

TL;DR: Lamer-SSL通过层感知LoRA专家模块和重放策略，提高了自监督语音模型跨语言泛化和持续训练的稳定性，且参数高效。


<details>
  <summary>Details</summary>
Motivation: 自监督语音模型虽然表现优异，但在新语言泛化能力较弱且在持续训练中容易遗忘已学知识，亟需一种机制有效改善这些问题。

Method: 提出了Lamer-SSL，一个参数高效的框架，结合了层感知混合LoRA专家模块(Lamer)和重放策略。Lamer模块在共享与语言特异性表示之间灵活平衡，通过层感知专家分配向更深层分配更多专家。重放策略通过少量数据保留先前知识，减少持续训练中的遗忘。

Result: 在自动语音识别和语言识别任务上，Lamer-SSL仅用2.14%的可训练参数，就成功扩展到新语言，同时维持对已学语言的良好性能。

Conclusion: Lamer-SSL框架有效解决了自监督语音模型在新语言泛化和持续训练中遗忘问题，实现了对新语言的良好扩展，同时保持对已学语言的强性能表现。

Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient framework that integrates a Layer-Aware MixturE of LoRA Experts (Lamer) module with a replay strategy. The Lamer module enables flexible balancing between shared and language-specific representations, while layer-aware expert allocation assigns more experts to deeper layers where semantic information is richer. Meanwhile, the replay strategy retains prior knowledge using minimal data, mitigating forgetting during continual training. Experiments on automatic speech recognition (ASR) and language identification (LID) demonstrate that Lamer-SSL extends self-supervised models to new languages effectively while maintaining strong performance on previously learned languages with only 2.14% parameters being trainable.

</details>


### [18] [Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks](https://arxiv.org/abs/2602.12759)
*Elena Alvarez-Mellado,Julio Gonzalo*

Main category: cs.CL

TL;DR: 本文提出了一种基于错误分析的小样本手工设计测试集评测方法，能诊断模型弱点并高效预测跨分布表现。


<details>
  <summary>Details</summary>
Motivation: 传统NLP评测仅显示平均性能优劣，难以指导改进且难以预测模型在异分布数据上的表现。

Method: 通过手工设计涵盖各类结构属性的小规模语言学驱动测试集，替代传统大规模爬取同分布数据，进行定量和定性分析。

Result: 该方法在西班牙语英式词识别任务上表现出诊断性、可操作性和预测性，预测外部数据集性能的中位相关达0.85。

Conclusion: 本文提出的基于错误分析的评估方法可以更好地诊断模型弱点，指导性能提升，并准确预测模型在不同数据分布上的表现。

Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside data. We propose an evaluation methodology for sequence labeling tasks grounded on error analysis that provides both quantitative and qualitative information on where systems must be improved and predicts how models will perform on a different distribution. The key is to create test sets that, contrary to common practice, do not rely on gathering large amounts of real-world in-distribution scraped data, but consists in handcrafting a small set of linguistically motivated examples that exhaustively cover the range of span attributes (such as shape, length, casing, sentence position, etc.) a system may encounter in the wild. We demonstrate this methodology on a benchmark for anglicism identification in Spanish. Our methodology provides results that are diagnostic (because they help identify systematic weaknesses in performance), actionable (because they can inform which model is better suited for a given scenario) and predictive: our method predicts model performance on external datasets with a median correlation of 0.85.

</details>


### [19] [Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews](https://arxiv.org/abs/2602.12778)
*Hamidreza Kazemi Taskooh,Taha Zare Harofte*

Main category: cs.CL

TL;DR: 该论文提出了一种针对波斯语旅游点评的基于BERT的混合模型，实现高效且准确的方面级情感分析。


<details>
  <summary>Details</summary>
Motivation: 针对低资源的波斯语旅游点评数据，提升方面级情感分析的准确率和效率，支持多语言旅游NLP研究。

Method: 采用带Top-K路由和辅助损失的混合BERT模型，包含整体情感分类、多标签方面抽取和动态路由，处理波斯语旅游点评数据。

Result: 模型实现了90.6%的加权F1-score，优于基线模型，同时显著降低了GPU功耗，并提供了首个标注的波斯旅游点评数据集。

Conclusion: 提出的混合BERT模型在波斯语旅游点评ABSA任务中表现优异，F1值达90.6%，且减少了39%的GPU能耗，促进了可持续AI发展。

Abstract: This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxiliary losses to mitigate routing collapse and improve efficiency. The pipeline includes: (1) overall sentiment classification using BERT on 9,558 labeled reviews, (2) multi-label aspect extraction for six tourism-related aspects (host, price, location, amenities, cleanliness, connectivity), and (3) integrated ABSA with dynamic routing. The dataset consists of 58,473 preprocessed reviews from the Iranian accommodation platform Jabama, manually annotated for aspects and sentiments. The proposed model achieves a weighted F1-score of 90.6% for ABSA, outperforming baseline BERT (89.25%) and a standard hybrid approach (85.7%). Key efficiency gains include a 39% reduction in GPU power consumption compared to dense BERT, supporting sustainable AI deployment in alignment with UN SDGs 9 and 12. Analysis reveals high mention rates for cleanliness and amenities as critical aspects. This is the first ABSA study focused on Persian tourism reviews, and we release the annotated dataset to facilitate future multilingual NLP research in tourism.

</details>


### [20] [RAT-Bench: A Comprehensive Benchmark for Text Anonymization](https://arxiv.org/abs/2602.12806)
*Nataša Krčo,Zexi Yao,Matthieu Meeus,Yves-Alexandre de Montjoye*

Main category: cs.CL

TL;DR: 本文提出RAT-Bench基准，系统评估文本匿名化工具在再识别风险上的表现，表明基于大型语言模型的匿名化工具在保护隐私和多语言支持上更优，但尚未完美。


<details>
  <summary>Details</summary>
Motivation: 虽然已有工具能去除特定识别信息，但其防止通过文本实现个人再识别的效果尚不明确，因此需要综合评估文本匿名化工具在真实再识别风险上的表现。

Method: 基于美国人口统计数据，生成含有直接和间接识别信息的合成文本，涵盖多个领域、语言和难度等级；评估了基于命名实体识别和基于大型语言模型的匿名化工具，通过LLM攻击者成功推断的属性衡量再识别风险。

Result: RAT-Bench基准呈现出不同匿名化工具在去除识别信息和防止再识别风险上的效果差异，展示了LLM匿名化工具在隐私保护和语种适应性上的优势，但亦揭示了当前技术的不足与局限。

Conclusion: 现有的文本匿名化工具在隐私保护方面表现参差不齐，尤其是当直接识别信息表达非标准化或间接识别信息存在时，再识别风险依然较高。基于LLM的匿名化工具整体上提供了更好的隐私-效用权衡，并且跨语言效果良好，但计算成本较高。

Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft's Presidio or Anthropic's PII purifier. These tools have traditionally been evaluated on their ability to remove specific identifiers (e.g., names), yet their effectiveness at preventing re-identification remains unclear. We introduce RAT-Bench, a comprehensive benchmark for text anonymization tools based on re-identification risk. Using U.S. demographic statistics, we generate synthetic text containing various direct and indirect identifiers across domains, languages, and difficulty levels. We evaluate a range of NER- and LLM-based text anonymization tools and, based on the attributes an LLM-based attacker is able to correctly infer from the anonymized text, we report the risk of re-identification in the U.S. population, while properly accounting for the disparate impact of identifiers. We find that, while capabilities vary widely, even the best tools are far from perfect in particular when direct identifiers are not written in standard ways and when indirect identifiers enable re-identification. Overall we find LLM-based anonymizers, including new iterative anonymizers, to provide a better privacy-utility trade-off albeit at a higher computational cost. Importantly, we also find them to work well across languages. We conclude with recommendations for future anonymization tools and will release the benchmark and encourage community efforts to expand it, in particular to other geographies.

</details>


### [21] [Left-right asymmetry in predicting brain activity from LLMs' representations emerges with their formal linguistic competence](https://arxiv.org/abs/2602.12811)
*Laurent Bonnasse-Gahot,Christophe Pallier*

Main category: cs.CL

TL;DR: 本文研究发现，训练中大语言模型与人脑左右半球的激活不对称性主要来源于模型形式语言能力的发展，而非其他认知任务能力。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型在训练过程中其内部激活与人脑活动中的左右半球不对称性产生的原因，及其对应的认知能力。

Method: 利用多个训练阶段的OLMo-2 7B模型和英语受试者的fMRI数据，比较左右脑激活不对称性的演变及其与多种基准测试成绩的关系，同时扩展到了Pythia模型和法语数据。

Result: 发现左右半球不对称性与模型在区分语法正确与错误句子、生成良好文本的能力相关，而与算术、Dyck语言任务及依赖世界知识和推理的文本任务无关。

Conclusion: 左脑和右脑在大语言模型（LLM）处理语言时表现出不同的激活相关性，这种左右不对称性与模型正式语言能力的进展相关联。

Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM progresses, the performance in predicting brain activity from its internal activations improves more in the left hemisphere than in the right one. The aim of the present work is to understand which kind of competence acquired by the LLMs underlies the emergence of this left-right asymmetry. Using the OLMo-2 7B language model at various training checkpoints and fMRI data from English participants, we compare the evolution of the left-right asymmetry in brain scores alongside performance on several benchmarks. We observe that the asymmetry co-emerges with the formal linguistic abilities of the LLM. These abilities are demonstrated in two ways: by the model's capacity to assign a higher probability to an acceptable sentence than to a grammatically unacceptable one within a minimal contrasting pair, or its ability to produce well-formed text. On the opposite, the left-right asymmetry does not correlate with the performance on arithmetic or Dyck language tasks; nor with text-based tasks involving world knowledge and reasoning. We generalize these results to another family of LLMs (Pythia) and another language, namely French. Our observations indicate that the left-right asymmetry in brain predictivity matches the progress in formal linguistic competence (knowledge of linguistic patterns).

</details>


### [22] [AIWizards at MULTIPRIDE: A Hierarchical Approach to Slur Reclamation Detection](https://arxiv.org/abs/2602.12818)
*Luca Tedeschini,Matteo Fasulo*

Main category: cs.CL

TL;DR: 本文为多语言仇恨言论中贬义词回收检测，提出分层模型利用用户LGBTQ+身份信号，与传统方法性能相当且更具可扩展性。


<details>
  <summary>Details</summary>
Motivation: 识别被回收的贬义词对仇恨言论检测系统是重大挑战，因为相同词汇根据社会身份和语境可能是攻击性或群体认同的表达。

Method: 提出分层方法，首先通过弱监督大语言模型注释推断用户LGBTQ+社区归属的模糊标签，使用BERT模型预测社区身份；然后将该潜在空间与新的模型融合进行贬义词回收检测。

Result: 在意大利语和西班牙语数据集上，方法性能与强基线BERT模型相当，提供了灵活可扩展框架以融合社会语言学背景。

Conclusion: 基于层次化用户身份和话语语境的建模方法能提升回收贬义词检测，结合社会语言学信号是未来改进方向。

Abstract: Detecting reclaimed slurs represents a fundamental challenge for hate speech detection systems, as the same lexcal items can function either as abusive expressions or as in-group affirmations depending on social identity and context. In this work, we address Subtask B of the MultiPRIDE shared task at EVALITA 2026 by proposing a hierarchical approach to modeling the slur reclamation process. Our core assumption is that members of the LGBTQ+ community are more likely, on average, to employ certain slurs in a eclamatory manner. Based on this hypothesis, we decompose the task into two stages. First, using a weakly supervised LLM-based annotation, we assign fuzzy labels to users indicating the likelihood of belonging to the LGBTQ+ community, inferred from the tweet and the user bio. These soft labels are then used to train a BERT-like model to predict community membership, encouraging the model to learn latent representations associated with LGBTQ+ identity. In the second stage, we integrate this latent space with a newly initialized model for the downstream slur reclamation detection task. The intuition is that the first model encodes user-oriented sociolinguistic signals, which are then fused with representations learned by a model pretrained for hate speech detection. Experimental results on Italian and Spanish show that our approach achieves performance statistically comparable to a strong BERT-based baseline, while providing a modular and extensible framework for incorporating sociolinguistic context into hate speech modeling. We argue that more fine-grained hierarchical modeling of user identity and discourse context may further improve the detection of reclaimed language. We release our code at https://github.com/LucaTedeschini/multipride.

</details>


### [23] [MentalBench: A Benchmark for Evaluating Psychiatric Diagnostic Capability of Large Language Models](https://arxiv.org/abs/2602.12871)
*Hoyun Song,Migyeong Kang,Jisu Shin,Jihyun Kim,Chanbi Park,Hangyeol Yoo,Jihyun An,Alice Oh,Jinyoung Han,KyungTae Lim*

Main category: cs.CL

TL;DR: 该研究提出了一个基于DSM-5知识图的精神病诊断评估基准，发现大型语言模型在复杂诊断任务中存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有的精神健康评估基准大多依赖社交媒体数据，无法有效评估基于DSM-5的精神疾病诊断判断。

Method: 构建了MentalBench基准，核心为由精神科医生构建并验证的MentalKG知识图，编码23种精神疾病的DSM-5诊断标准和鉴别诊断规则。基于MentalKG生成24,750份多样化的合成临床病例，以实现低噪声且可解释的评估。

Result: 实验表明，先进的大型语言模型在结构化查询中表现良好，但在区分临床重叠疾病时难以调整诊断决策的置信度。该评估揭示了现有基准未覆盖的不足之处。

Conclusion: MentalBench揭示了当前大型语言模型在精神病诊断推理中的局限性，尤其是在复杂临床判断中的置信度校准问题，提示需要更精细的评估工具。

Abstract: We introduce MentalBench, a benchmark for evaluating psychiatric diagnostic decision-making in large language models (LLMs). Existing mental health benchmarks largely rely on social media data, limiting their ability to assess DSM-grounded diagnostic judgments. At the core of MentalBench is MentalKG, a psychiatrist-built and validated knowledge graph encoding DSM-5 diagnostic criteria and differential diagnostic rules for 23 psychiatric disorders. Using MentalKG as a golden-standard logical backbone, we generate 24,750 synthetic clinical cases that systematically vary in information completeness and diagnostic complexity, enabling low-noise and interpretable evaluation. Our experiments show that while state-of-the-art LLMs perform well on structured queries probing DSM-5 knowledge, they struggle to calibrate confidence in diagnostic decision-making when distinguishing between clinically overlapping disorders. These findings reveal evaluation gaps not captured by existing benchmarks.

</details>


### [24] [BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models](https://arxiv.org/abs/2602.12889)
*Jiangxi Chen,Qian Liu*

Main category: cs.CL

TL;DR: 本文提出BaziQA-Benchmark基准数据集，系统评测大型语言模型符号与时间推理能力，发现模型表现有提升空间。


<details>
  <summary>Details</summary>
Motivation: 为了评估大型语言模型在符号推理和时间组合推理上的能力，提出了一个标准化的基准测试。

Method: 基于全球算命师大赛（2021-2025年）专业策划的200个多项选择问题，设计了BaziQA-Benchmark。采用多轮推理设置，并引入一种轻量级结构化推理协议以约束推理顺序。

Result: 模型的表现明显优于随机猜测，但距离完全掌握该任务仍有较大差距。模型对时间组合和推理顺序敏感，对时间定位及多条件符号判断存在系统性失败。

Conclusion: BaziQA-Benchmark有效揭示了大型语言模型在符号和时间推理方面的局限性，为未来提升模型推理能力提供了可控的评估框架。

Abstract: We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global Fortune-teller Competition (2021--2025), where each instance requires structured inference over a fixed symbolic chart and interacting temporal conditions. Unlike anecdotal or prompt-driven evaluations, BaziQA-Benchmark enables objective scoring and controlled comparison across years, domains, and model families. We evaluate contemporary language models under a multi-turn setting and analyze performance variation across temporal difficulty, reasoning domains, and inference protocols.To further probe reasoning behavior, we introduce a lightweight Structured Reasoning Protocol that constrains inference order without adding domain knowledge. Results show that models consistently outperform chance but remain far from saturation, exhibiting pronounced sensitivity to temporal composition and reasoning order, as well as systematic failures on precise temporal localization and multi-condition symbolic judgments.

</details>


### [25] [ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset & Benchmark](https://arxiv.org/abs/2602.12911)
*Tung X. Nguyen,Nhu Vo,Giang-Son Nguyen,Duy Mai Hoang,Chien Dinh Huynh,Inigo Jauregi Unanue,Massimo Piccardi,Wray Buntine,Dung D. Le*

Main category: cs.CL

TL;DR: 本研究制作了首个越南语医疗代码切换语音数据集，评测了多种ASR模型，发现结合越南语优化和多语言预训练的模型能更有效识别代码切换中的英语医学术语。


<details>
  <summary>Details</summary>
Motivation: 越南语医疗交流中存在大量的英语医学术语插入，导致ASR系统难以准确识别，且缺乏专门针对这类现象的基准数据集。

Method: 构建了一个包含16,576条语音的越南语医疗代码切换语音数据集（ViMedCSS），并使用该数据集对多种先进的自动语音识别（ASR）模型及其微调策略进行评估。

Result: 越南语优化模型在普通语句上表现更好，多语言预训练有助于识别英语插入词，两者结合在整体及代码切换准确率上达到最佳平衡。

Conclusion: 本工作首次为越南语医疗代码切换提供基准数据，揭示了低资源多语言ASR系统领域适应的有效策略，对提升医学领域ASR性能具有重要意义。

Abstract: Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in low-resource languages like Vietnamese. Current most ASR systems struggle to recognize correctly English medical terms within Vietnamese sentences, and no benchmark addresses this challenge. In this paper, we construct a 34-hour \textbf{Vi}etnamese \textbf{Med}ical \textbf{C}ode-\textbf{S}witching \textbf{S}peech dataset (ViMedCSS) containing 16,576 utterances. Each utterance includes at least one English medical term drawn from a curated bilingual lexicon covering five medical topics. Using this dataset, we evaluate several state-of-the-art ASR models and examine different specific fine-tuning strategies for improving medical term recognition to investigate the best approach to solve in the dataset. Experimental results show that Vietnamese-optimized models perform better on general segments, while multilingual pretraining helps capture English insertions. The combination of both approaches yields the best balance between overall and code-switched accuracy. This work provides the first benchmark for Vietnamese medical code-switching and offers insights into effective domain adaptation for low-resource, multilingual ASR systems.

</details>


### [26] [When Words Don't Mean What They Say: Figurative Understanding in Bengali Idioms](https://arxiv.org/abs/2602.12921)
*Adib Sakhawat,Shamim Ara Parveen,Md Ruhul Amin,Shamim Al Mahmud,Md Saiful Islam,Tahera Khatun*

Main category: cs.CL

TL;DR: 本文针对低资源语言孟加拉语中的隐喻语言理解问题，构建了一个包含10,361条孟加拉语成语的大规模数据集，并设计了19维注释方案。通过测试30个先进多语言和指令调优的大型语言模型，发现模型性能远低于人类，显示现有模型在跨语言文化推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 隐喻语言理解对于大语言模型依旧是挑战，特别是在低资源语言中。因此需要一个大规模结构化的成语数据集和评测基准，促进孟加拉语等低资源语言中隐喻及文化理解的研究。

Method: 构建了一个涵盖10,361条孟加拉语成语的语料库，采用专家共识制定的19字段注释方案，涵盖语义、句法、文化及宗教等维度，并对30个先进多语言及指令调优型大语言模型进行了隐喻意义推断任务的评测。

Result: 发布了一个包含10,361条孟加拉语成语的全面注释数据集，并建立了第一个孟加拉语隐喻理解的评测基准。评测结果表明，所有模型准确率均低于50%，显著落后于人类表现。

Conclusion: 现有大型语言模型在孟加拉语隐喻语言理解任务中表现不足，准确率均未超过50%，远低于人类的83.4%。需进一步加强文化和语义的跨语言推理能力。

Abstract: Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali idioms. Each idiom is annotated under a comprehensive 19-field schema, established and refined through a deliberative expert consensus process, that captures its semantic, syntactic, cultural, and religious dimensions, providing a rich, structured resource for computational linguistics. To establish a robust benchmark for Bangla figurative language understanding, we evaluate 30 state-of-the-art multilingual and instruction-tuned LLMs on the task of inferring figurative meaning. Our results reveal a critical performance gap, with no model surpassing 50% accuracy, a stark contrast to significantly higher human performance (83.4%). This underscores the limitations of existing models in cross-linguistic and cultural reasoning. By releasing the new idiom dataset and benchmark, we provide foundational infrastructure for advancing figurative language understanding and cultural grounding in LLMs for Bengali and other low-resource languages.

</details>


### [27] [Curriculum Learning and Pseudo-Labeling Improve the Generalization of Multi-Label Arabic Dialect Identification Models](https://arxiv.org/abs/2602.12937)
*Ali Mekky,Mohamed El Zeftawy,Lara Hassan,Amr Keleg,Preslav Nakov*

Main category: cs.CL

TL;DR: 本文针对多标签阿拉伯方言识别任务，构建了多标签数据集并提出基于BERT的分类模型，显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统的阿拉伯方言识别（ADI）任务长期被建模为单标签分类任务，但实际上阿拉伯方言的识别更适合多标签分类，且缺乏大规模的多标签训练数据。

Method: 通过分析单标签ADI数据训练的模型，发现选择负样本是主要挑战。使用GPT-4o和二元方言可接受性分类器自动生成多标签注释，结合阿拉伯方言层级（ALDi）进行数据集构建，并使用基于BERT的多标签分类器和课程学习策略进行训练。

Result: 提出的LAHJATBERT模型在多标签阿拉伯方言识别任务的排行榜上达到宏F1值0.69，显著优于之前最强系统的0.55。

Conclusion: 构建多标签阿拉伯方言数据集并结合适当的训练策略，能显著提升多标签阿拉伯方言识别的效果，推动该领域的发展。

Abstract: Being modeled as a single-label classification task for a long time, recent work has argued that Arabic Dialect Identification (ADI) should be framed as a multi-label classification task. However, ADI remains constrained by the availability of single-label datasets, with no large-scale multi-label resources available for training. By analyzing models trained on single-label ADI data, we show that the main difficulty in repurposing such datasets for Multi-Label Arabic Dialect Identification (MLADI) lies in the selection of negative samples, as many sentences treated as negative could be acceptable in multiple dialects. To address these issues, we construct a multi-label dataset by generating automatic multi-label annotations using GPT-4o and binary dialect acceptability classifiers, with aggregation guided by the Arabic Level of Dialectness (ALDi). Afterward, we train a BERT-based multi-label classifier using curriculum learning strategies aligned with dialectal complexity and label cardinality. On the MLADI leaderboard, our best-performing LAHJATBERT model achieves a macro F1 of 0.69, compared to 0.55 for the strongest previously reported system. Code and data are available at https://mohamedalaa9.github.io/lahjatbert/.

</details>


### [28] [SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents](https://arxiv.org/abs/2602.12984)
*Yujiong Shen,Yajie Yang,Zhiheng Xi,Binze Hu,Huayu Sha,Jiazheng Zhang,Qiyuan Peng,Junlin Shang,Jixuan Huang,Yutao Fan,Jingqi Tong,Shihan Dou,Ming Zhang,Lei Bai,Zhenfei Yin,Tao Gui,Xingjun Ma,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang*

Main category: cs.CL

TL;DR: 该论文介绍了SciAgentGym和SciAgentBench两个工具环境，旨在评估和提升科学推理中的多工具协同使用能力。通过提出SciForge方法生成逻辑感知的训练数据，显著提升模型在复杂多步骤科学任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前评测基准忽视了智能体整合和运用多科学领域工具执行复杂工作流的能力，导致现有模型在长期、多步骤科学推理任务中表现不足。

Method: 提出SciForge，一种将工具动作空间建模为依赖图的数据合成方法，生成逻辑感知的训练轨迹用以微调模型提升复杂多步骤任务表现。

Result: 在SciAgentBench评测中，领先模型如GPT-5的任务成功率随着交互步骤增加显著下降，由60.6%降至30.9%。经过SciForge微调的SciAgent-8B在科学工具使用上超越了规模远大的Qwen3-VL-235B-Instruct，并实现了跨领域迁移能力。

Conclusion: 现有先进模型在复杂科学工具使用上的能力受限，而通过SciForge生成依赖图并进行微调，SciAgent-8B模型在多领域科学工具使用中表现优于更大规模模型，展示了下一代自主科学智能体的潜力。

Abstract: Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents' ability to orchestrate tools for such rigorous workflows. To bridge this gap, we introduce SciAgentGym, a scalable interactive environment featuring 1,780 domain-specific tools across four natural science disciplines, supported by a robust execution infrastructure. Complementing this, we present SciAgentBench, a tiered evaluation suite designed to stress-test agentic capabilities from elementary actions to long-horizon workflows. Our evaluation identifies a critical bottleneck: state-of-the-art models struggle with complex scientific tool-use. Even for a leading model like GPT-5, success rates drop sharply from 60.6% to 30.9% as interaction horizons extend, primarily due to failures in multi-step workflow execution. To address this, we propose SciForge, a data synthesis method that models the tool action space as a dependency graph to generate logic-aware training trajectories. By fine-tuning on these trajectories, our SciAgent-8B outperforms the significantly larger Qwen3-VL-235B-Instruct while exhibiting positive cross-domain transfer of scientific tool-use capabilities. These results underscore the promising potential of next-generation autonomous scientific agents.

</details>


### [29] [Evaluating the Homogeneity of Keyphrase Prediction Models](https://arxiv.org/abs/2602.12989)
*Maël Houbre,Florian Boudin,Beatrice Daille*

Main category: cs.CL

TL;DR: 本文提出评价关键短语预测模型同质性的新方法，发现生成缺失关键短语能力可能降低同质性，提取方法同样有效。


<details>
  <summary>Details</summary>
Motivation: 当前的关键短语生成模型可以生成文本中未出现的关键短语，但现有基准未评估这些模型的同质性能力。

Method: 提出一种评估关键短语预测模型同质性的方法，并分析生成缺失关键短语能力对同质性的影响。

Result: 关键短语提取方法与生成模型在同质性上具有竞争力，生成缺失关键短语的能力可能负面影响同质性。

Conclusion: 生成缺失关键短语的能力并不一定提升模型同质性，关键短语提取方法仍具优势。

Abstract: Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a document's text called `absent keyphrases`. This ability means that keyphrase generation models can associate a document to a notion that is not explicitly mentioned in its text. Intuitively, this suggests that for two documents treating the same subjects, a keyphrase generation model is more likely to be homogeneous in their indexing i.e. predict the same keyphrase for both documents, regardless of those keyphrases appearing in their respective text or not; something a keyphrase extraction model would fail to do. Yet, homogeneity of keyphrase prediction models is not covered by current benchmarks. In this work, we introduce a method to evaluate the homogeneity of keyphrase prediction models and study if absent keyphrase generation capabilities actually help the model to be more homogeneous. To our surprise, we show that keyphrase extraction methods are competitive with generative models, and that the ability to generate absent keyphrases can actually have a negative impact on homogeneity. Our data, code and prompts are available on huggingface and github.

</details>


### [30] [Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models](https://arxiv.org/abs/2602.12996)
*Hao Chen,Ye He,Yuchun Fan,Yukun Yan,Zhenghao Liu,Qingfu Zhu,Maosong Sun,Wanxiang Che*

Main category: cs.CL

TL;DR: 该论文提出了一种元认知框架，通过区分干预和认知一致性机制，实现了对大型语言模型知识空间的精准扩展和校准，提升了模型在知识密集任务中的可靠性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法简单将模型性能等同于内部知识，忽视了知识与信心之间的差距，导致模型产生过度自信的错误或不确定的真相，需要一个机制来桥接这一鸿沟。

Method: 基于内部认知信号，将知识空间划分为掌握区、困惑区和缺失区，进行差异化干预；同时引入认知一致性机制，同步主观确信度与客观准确度，实现知识界限校准。

Result: 大量实验表明，该方法在增强知识能力和提升认知行为方面均优于强基线模型，验证了其合理性和有效性。

Conclusion: 该框架不仅提升了模型的知识增强能力，还促进了模型更好地区分已知与未知的认知行为，从而显著优于现有主流方法。

Abstract: Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal knowledge, overlooking the knowledge-confidence gaps that lead to overconfident errors or uncertain truths. To bridge this gap, we propose a novel meta-cognitive framework for reliable knowledge augmentation via differentiated intervention and alignment. Our approach leverages internal cognitive signals to partition the knowledge space into mastered, confused, and missing regions, guiding targeted knowledge expansion. Furthermore, we introduce a cognitive consistency mechanism to synchronize subjective certainty with objective accuracy, ensuring calibrated knowledge boundaries. Extensive experiments demonstrate the our framework consistently outperforms strong baselines, validating its rationality in not only enhancing knowledge capabilities but also fostering cognitive behaviors that better distinguish knowns from unknowns.

</details>


### [31] [Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech](https://arxiv.org/abs/2602.13047)
*Madhurananda Pahar,Caitlin Illingworth,Dorota Braun,Bahman Mirheidari,Lise Sproson,Daniel Blackburn,Heidi Christensen*

Main category: cs.CL

TL;DR: 本研究发现英国现有AI认知衰退检测模型对多语种少数族裔存在偏见，导致误诊风险高，提示需改进模型以提升公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 英国少数族裔人群中认知障碍（如痴呆和轻度认知障碍）发病率上升，研究旨在确保AI模型对多语种及不同口音群体的诊断公平性和临床适用性。

Method: 通过招募英国单语和多语种参与者，使用ASR系统及分类和回归模型，分析语音和语言特征对认知衰退的检测效率及偏见情况。

Result: ASR系统对不同群体无明显偏见，但分类和回归模型对多语种尤其是带有特定口音的多语种群体存在明显偏见，多语种更易被误判为认知衰退患者。

Conclusion: 现有的AI模型在多语种少数族裔人群中存在显著偏见，尤其是在认知能力评估任务中，导致这些模型当前尚不适合用于临床诊断。

Abstract: Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities. This study examines the trustworthiness of AI models, specifically the presence of bias, in detecting healthy multilingual English speakers among the cognitively impaired cohort, to make these tools clinically beneficial. For experiments, monolingual participants were recruited nationally (UK), and multilingual speakers were enrolled from four community centres in Sheffield and Bradford. In addition to a non-native English accent, multilinguals spoke Somali, Chinese, or South Asian languages, who were further divided into two Yorkshire accents (West and South) to challenge the efficiency of the AI tools thoroughly. Although ASR systems showed no significant bias across groups, classification and regression models using acoustic and linguistic features exhibited bias against multilingual speakers, particularly in memory, fluency, and reading tasks. This bias was more pronounced when models were trained on the publicly available DementiaBank dataset. Moreover, multilinguals were more likely to be misclassified as having cognitive decline. This study is the first of its kind to discover that, despite their strong overall performance, current AI models show bias against multilingual individuals from ethnic minority backgrounds in the UK, and they are also more likely to misclassify speakers with a certain accent (South Yorkshire) as living with a more severe cognitive decline. In this pilot study, we conclude that the existing AI tools are therefore not yet reliable for diagnostic use in these populations, and we aim to address this in future work by developing more generalisable, bias-mitigated models.

</details>


### [32] [TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution](https://arxiv.org/abs/2602.13059)
*Tejas Anvekar,Junha Park,Rajat Jha,Devanshu Gupta,Poojah Ganesan,Puneeth Mathur,Vivek Gupta*

Main category: cs.CL

TL;DR: 提出TraceBack框架实现表格问答的细粒度归因，发布相关数据集与评价指标，显著提升归因性能并支持自动化评估。


<details>
  <summary>Details</summary>
Motivation: 现有表格问答系统缺乏细粒度归因，导致答案缺乏可验证的支撑，影响高风险场景的信任。

Method: 提出了TraceBack，一个模块化多智能体框架，实现单表问答中的细粒度单元归因，通过裁剪表格、分解问题、对齐答案与支持单元，实现显性和隐性证据捕捉。并发布了CITEBench基准集和FairScore无参考归因评估指标。

Result: TraceBack在多个数据集和细粒度水平上显著优于强基线，FairScore评估指标与人工判断高度一致，能有效支持可解释和可扩展的表格问答评估。

Conclusion: TraceBack有效解决了表格问答中的单元归因问题，提升了答案透明度和可信度，FairScore指标促进了无参考的自动归因评估，对推动表格问答的可解释性和实用性有重要意义。

Abstract: Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable grounding, limiting trust in high-stakes settings. We address this with TraceBack, a modular multi-agent framework for scalable, cell-level attribution in single-table QA. TraceBack prunes tables to relevant rows and columns, decomposes questions into semantically coherent sub-questions, and aligns each answer span with its supporting cells, capturing both explicit and implicit evidence used in intermediate reasoning steps. To enable systematic evaluation, we release CITEBench, a benchmark with phrase-to-cell annotations drawn from ToTTo, FetaQA, and AITQA. We further propose FairScore, a reference-less metric that compares atomic facts derived from predicted cells and answers to estimate attribution precision and recall without human cell labels. Experiments show that TraceBack substantially outperforms strong baselines across datasets and granularities, while FairScore closely tracks human judgments and preserves relative method rankings, supporting interpretable and scalable evaluation of table-based QA.

</details>


### [33] [Exploring a New Competency Modeling Process with Large Language Models](https://arxiv.org/abs/2602.13084)
*Silin Du,Manqing Xin,Raymond Jia Wang*

Main category: cs.CL

TL;DR: 本文提出基于大语言模型的新能力建模流程，通过结构化分解和融合多源信息，实现成本低、效度高且易评估的能力模型，实证验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统的能力建模在人才选拔、发展和评估中依赖专家手动分析大量访谈文本，成本高且易受随机性、模糊性和可重复性差影响。

Method: 基于大语言模型重构专家实践流程，利用LLMs提取行为和心理描述，通过嵌入相似度映射到预定义能力库。引入可学习参数自适应整合不同信息源，开发离线评估程序实现无额外数据的大规模模型选择。

Result: 在软件外包企业的实证研究中，展示了该方法的预测效度强、库间一致性和结构稳健性。

Conclusion: 该框架使能力建模从定性专家依赖转变为透明、数据驱动且可评估的分析过程。

Abstract: Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and prone to randomness, ambiguity, and limited reproducibility. This study proposes a new competency modeling process built on large language models (LLMs). Instead of merely automating isolated steps, we reconstruct the workflow by decomposing expert practices into structured computational components. Specifically, we leverage LLMs to extract behavioral and psychological descriptions from raw textual data and map them to predefined competency libraries through embedding-based similarity. We further introduce a learnable parameter that adaptively integrates different information sources, enabling the model to determine the relative importance of behavioral and psychological signals. To address the long-standing challenge of validation, we develop an offline evaluation procedure that allows systematic model selection without requiring additional large-scale data collection. Empirical results from a real-world implementation in a software outsourcing company demonstrate strong predictive validity, cross-library consistency, and structural robustness. Overall, our framework transforms competency modeling from a largely qualitative and expert-dependent practice into a transparent, data-driven, and evaluable analytical process.

</details>


### [34] [Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts](https://arxiv.org/abs/2602.13102)
*Kais Allkivi*

Main category: cs.CL

TL;DR: 研究通过仔细特征选择，建立了准确且稳定的机器学习模型用于爱沙尼亚语写作水平分类，并应用于开源语言学习平台。


<details>
  <summary>Details</summary>
Motivation: 利用NLP分析真实的学习者语言，结合自动评估和反馈工具，探索更可解释和泛化的语言测试模型。

Method: 通过分析爱沙尼亚语水平考试写作样本（A2-C1），选取词汇、形态、表层结构和错误特征，训练机器学习分类模型，并比较不同特征组合的效果。

Result: 预选特征组实现了约0.9的分类准确率，且减少了不同文本类型的分类波动。早期考试样本测试中，写作复杂度提升，但准确率仍达0.8。

Conclusion: 合理的语言特征选择有助于构建更解释性强且泛化好的自动写作评估模型，推动真实语言应用与语言测试研究结合。

Abstract: Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly combining these aspects. This study aimed to classify Estonian proficiency examination writings (levels A2-C1), assuming that careful feature selection can lead to more explainable and generalizable machine learning models for language testing. Various linguistic properties of the training data were analyzed to identify relevant proficiency predictors associated with increasing complexity and correctness, rather than the writing task. Such lexical, morphological, surface, and error features were used to train classification models, which were compared to models that also allowed for other features. The pre-selected features yielded a similar test accuracy but reduced variation in the classification of different text types. The best classifiers achieved an accuracy of around 0.9. Additional evaluation on an earlier exam sample revealed that the writings have become more complex over a 7-10-year period, while accuracy still reached 0.8 with some feature sets. The results have been implemented in the writing evaluation module of an Estonian open-source language learning environment.

</details>


### [35] [SCOPE: Selective Conformal Optimized Pairwise LLM Judging](https://arxiv.org/abs/2602.13110)
*Sher Badshah,Ali Emami,Hassan Sajjad*

Main category: cs.CL

TL;DR: 本文提出SCOPE框架，通过双向偏好熵量化不确定性，实现了大语言模型配对评价的选择性判断，有效控制错误率并提升覆盖率，验证了其在多个基准下的优越性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在配对评价中替代人工标签具有实用性，但存在校准失误和系统性偏差，导致评价不可靠。因而需要一种带有统计保证的选择性判断框架来改善评价质量。

Method: 提出了SCOPE框架，利用交换性校准接受阈值，结合双向偏好熵（BPE）衡量不确定性，从而选择性地接受LLM配对判断，保障错误率不超过预设水平。

Result: 在多个评测基准（MT-Bench、RewardBench、Chatbot Arena）上，SCOPE框架在风险水平α=0.10下实现了风险控制（约0.097至0.099）和较高的覆盖率（最高达0.98），且相比简单基线方法，提升了接受判断数量最多2.4倍，表现出良好的不确定性判别能力和广泛适用性。

Conclusion: SCOPE框架通过引入BPE不确定性度量，实现了在保持统计风险约束的前提下，对LLM作为评价者的选择性配对判断，显著提升了判断的覆盖率和可靠性。

Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE (Selective Conformal Optimized Pairwise Evaluation), a framework for selective pairwise judging with finite-sample statistical guarantees. Under exchangeability, SCOPE calibrates an acceptance threshold such that the error rate among non-abstained judgments is at most a user-specified level $α$. To provide SCOPE with a bias-neutral uncertainty signal, we introduce Bidirectional Preference Entropy (BPE), which queries the judge under both response positions, aggregates the implied preference probabilities to enforce invariance to response order, and converts the aggregated probability into an entropy-based uncertainty score. Across MT-Bench, RewardBench, and Chatbot Arena, BPE improves uncertainty quality over standard confidence proxies, providing a stronger selection signal that enables SCOPE to consistently meet the target risk level while retaining good coverage across judge scales. In particular, at $α= 0.10$, \textsc{Scope} consistently satisfies the risk bound across all benchmarks and judge scales (empirical risk $\approx 0.097$ to $0.099$), while retaining substantial coverage, reaching $0.89$ on RewardBench with Qwen-14B and $0.98$ on RewardBench with Qwen-32B. Compared to naïve baselines, \textsc{Scope} accepts up to $2.4\times$ more judgments on MT-Bench with Qwen-7B under the same target risk constraint, demonstrating that BPE enables reliable and high-coverage LLM-based evaluation.

</details>


### [36] [From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media](https://arxiv.org/abs/2602.13123)
*Maria Ryskina,Matthew R. Gormley,Kyle Mahowald,David R. Mortensen,Taylor Berg-Kirkpatrick,Vivek Kulkarni*

Main category: cs.CL

TL;DR: 本文研究了语言新词的产生机制，比较了新闻媒体与社交媒体（Twitter）中的新词出现，发现两者在新词形成上存在相似和差异。


<details>
  <summary>Details</summary>
Motivation: 语言中新词的产生受多个内部和外部进化压力影响，不同语境和媒介中的语言使用面临不同约束，亟需探究社交媒体与传统出版物中新词产生的差异。

Method: 将静态词向量扩展到上下文嵌入，应用于Twitter推文数据，基于已有英文新词产生研究方法进行分析。

Result: 研究显示，新闻和Twitter中出现新词的两个相关因素均成立，但话题流行度对Twitter中新词产生的作用较小，暗示两者新词形成机制有所不同。

Conclusion: 新闻出版文本与Twitter社交媒体语料中的新词产生机制存在共同点，但话题流行度对Twitter新词形成的影响较小，可能因两者偏好不同的新词形成机制。

Abstract: Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language use in newspapers is subject to very different constraints than language use on social media. Prior distributional semantic work on English word emergence (neology) identified two factors correlated with creation of new words by analyzing a corpus consisting primarily of historical published texts (Ryskina et al., 2020, arXiv:2001.07740). Extending this methodology to contextual embeddings in addition to static ones and applying it to a new corpus of Twitter posts, we show that the same findings hold for both domains, though the topic popularity growth factor may contribute less to neology on Twitter than in published writing. We hypothesize that this difference can be explained by the two domains favouring different neologism formation mechanisms.

</details>


### [37] [OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report](https://arxiv.org/abs/2602.13139)
*Mariia Fedorova,Nikolay Arefyev,Maja Buljan,Jindřich Helcl,Stephan Oepen,Egil Rønningstad,Yves Scherrer*

Main category: cs.CL

TL;DR: 本文扩展了OpenLID语言识别系统，通过数据增强和标签优化提升了识别相近语言和处理噪声的能力，在多个测试中表现优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 现有的语言识别工具在识别相近语言和区分有效自然语言与噪声方面表现不佳，特别是对于低资源语言，导致多语言数据集中的语言子集被污染。

Method: 扩展OpenLID分类器：增加训练数据、合并相近语言变体、引入噪声标签，并针对特定语言组开发新评估数据集。

Result: OpenLID-v3在多个基准测试中优于GlotLID。集成方法虽然提高了精确度，但显著降低了低资源语言的覆盖率。

Conclusion: 此次工作通过改进训练数据和模型设计，提升了语言识别的性能，特别是在识别相近语言和处理噪声方面提供了有效的解决方案。

Abstract: Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural language from noise, which contaminates language-specific subsets, especially for low-resource languages. In this work we extend the OpenLID classifier by adding more training data, merging problematic language variant clusters, and introducing a special label for marking noise. We call this extended system OpenLID-v3 and evaluate it against GlotLID on multiple benchmarks. During development, we focus on three groups of closely related languages (Bosnian, Croatian, and Serbian; Romance varieties of Northern Italy and Southern France; and Scandinavian languages) and contribute new evaluation datasets where existing ones are inadequate. We find that ensemble approaches improve precision but also substantially reduce coverage for low-resource languages. OpenLID-v3 is available on https://huggingface.co/HPLT/OpenLID-v3.

</details>


### [38] [Semantic Chunking and the Entropy of Natural Language](https://arxiv.org/abs/2602.13194)
*Weishun Zhong,Doron Sivan,Tankut Can,Mikhail Katkov,Misha Tsodyks*

Main category: cs.CL

TL;DR: 本文提出一个统计模型，解释了英语文本的熵率和高度冗余，表明熵率随着语义复杂度增加而增加。


<details>
  <summary>Details</summary>
Motivation: 探究英语文本的熵率约为每字符一比特，理解其冗余率及其背后的语言结构。

Method: 提出一个自相似的统计模型，将文本分割成语义连贯的块，并通过层级结构分解语义，进行理论和数值分析。

Result: 模型能够定量描述真实文本在不同语义层级的结构，预测的熵率与实际印刷英语熵率相符。

Conclusion: 自然语言的熵率不是固定的，而是随着语义复杂度系统性增加，模型的自由参数捕获了这一变化。

Abstract: The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to the five bits per character expected for random text. We introduce a statistical model that attempts to capture the intricate multi-scale structure of natural language, providing a first-principles account of this redundancy level. Our model describes a procedure of self-similarly segmenting text into semantically coherent chunks down to the single-word level. The semantic structure of the text can then be hierarchically decomposed, allowing for analytical treatment. Numerical experiments with modern LLMs and open datasets suggest that our model quantitatively captures the structure of real texts at different levels of the semantic hierarchy. The entropy rate predicted by our model agrees with the estimated entropy rate of printed English. Moreover, our theory further reveals that the entropy rate of natural language is not fixed but should increase systematically with the semantic complexity of corpora, which are captured by the only free parameter in our model.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [39] [Provably Convergent Actor-Critic in Risk-averse MARL](https://arxiv.org/abs/2602.12386)
*Yizhou Zhang,Eric Mazumdar*

Main category: cs.MA

TL;DR: 本文研究了具有风险厌恶和有限理性的风险厌恶量子响应均衡（RQE）在无限时域一般和式马尔可夫博弈中的学习问题，提出了一种双时间尺度的Actor-Critic算法，并证明其全局收敛性，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统经典博弈论中马尔可夫博弈的平稳策略计算复杂，难以在多智能体强化学习中实用，故引入包含风险厌恶和有限理性的 RQE 作为可学且实用的均衡概念。

Method: 设计了一种包含快速时间尺度的actor和慢速时间尺度的critic的 Actor-Critic 算法，利用 RQE 的正则性质进行学习。

Result: 该算法在多个环境中实现了比风险中性基线更优的收敛性能，验证了理论收敛性和方法有效性。

Conclusion: 提出的基于风险厌恶量子响应均衡的双时间尺度Actor-Critic算法实现了全局收敛且具有有限样本保证，优于风险中性方法。

Abstract: Learning stationary policies in infinite-horizon general-sum Markov games (MGs) remains a fundamental open problem in Multi-Agent Reinforcement Learning (MARL). While stationary strategies are preferred for their practicality, computing stationary forms of classic game-theoretic equilibria is computationally intractable -- a stark contrast to the comparative ease of solving single-agent RL or zero-sum games. To bridge this gap, we study Risk-averse Quantal response Equilibria (RQE), a solution concept rooted in behavioral game theory that incorporates risk aversion and bounded rationality. We demonstrate that RQE possesses strong regularity conditions that make it uniquely amenable to learning in MGs. We propose a novel two-timescale Actor-Critic algorithm characterized by a fast-timescale actor and a slow-timescale critic. Leveraging the regularity of RQE, we prove that this approach achieves global convergence with finite-sample guarantees. We empirically validate our algorithm in several environments to demonstrate superior convergence properties compared to risk-neutral baselines.

</details>


### [40] [Agent Skills for Large Language Models: Architecture, Acquisition, Security, and the Path Forward](https://arxiv.org/abs/2602.12430)
*Renjun Xu,Yang Yan*

Main category: cs.MA

TL;DR: 本文系统总结了多技能语言模型智能体的架构、技能获取、部署和安全，提出治理框架及未来研究方向，推动下一代可信自我改进技能生态发展。


<details>
  <summary>Details</summary>
Motivation: 当前单体大语言模型难以高效集成和扩展多样化任务技能，需一种模块化且动态可扩展的技能抽象层，以支持智能体能力的灵活升级和安全保障。

Method: 通过分析SKILL.md规范、进阶上下文加载机制、技能库强化学习、自主技能发现和组合、实际部署案例及安全漏洞分析，构建技能信任与生命周期治理框架。

Result: 本文综述了从单一大型语言模型向具备多技能模块化智能体的转变，强调了技能作为动态扩展模型能力的组件的重要性。介绍了技能定义的渐进披露、可移植性以及与模型上下文协议（MCP）的结合，涵盖了架构基础、技能获取、规模部署和安全性四个方面，提出了技能信任与生命周期治理框架以应对安全隐患，并指出了跨平台技能移植和基于能力的权限管理等七大挑战，制定了推动可信自我改进技能生态系统的研究议程。

Conclusion: 技能抽象层是下一代智能体系统的关键，需通过严格的安全治理和跨平台能力管理实现可信、可扩展的技能生态。

Abstract: The transition from monolithic language models to modular, skill-equipped agents marks a defining shift in how large language models (LLMs) are deployed in practice. Rather than encoding all procedural knowledge within model weights, agent skills -- composable packages of instructions, code, and resources that agents load on demand -- enable dynamic capability extension without retraining. It is formalized in a paradigm of progressive disclosure, portable skill definitions, and integration with the Model Context Protocol (MCP). This survey provides a comprehensive treatment of the agent skills landscape, as it has rapidly evolved during the last few months. We organize the field along four axes: (i) architectural foundations, examining the SKILL.md specification, progressive context loading, and the complementary roles of skills and MCP; (ii) skill acquisition, covering reinforcement learning with skill libraries (SAGE), autonomous skill discovery (SEAgent), and compositional skill synthesis; (iii) deployment at scale, including the computer-use agent (CUA) stack, GUI grounding advances, and benchmark progress on OSWorld and SWE-bench; and (iv) security, where recent empirical analyses reveal that 26.1\% of community-contributed skills contain vulnerabilities, motivating our proposed Skill Trust and Lifecycle Governance Framework -- a four-tier, gate-based permission model that maps skill provenance to graduated deployment capabilities. We identify seven open challenges -- from cross-platform skill portability to capability-based permission models -- and propose a research agenda for realizing trustworthy, self-improving skill ecosystems. Unlike prior surveys that broadly cover LLM agents or tool use, this work focuses specifically on the emerging skill abstraction layer and its implications for the next generation of agentic systems. Project repo: https://github.com/scienceaix/agentskills.

</details>


### [41] [Theory of Mind Guided Strategy Adaptation for Zero-Shot Coordination](https://arxiv.org/abs/2602.12458)
*Andrew Ni,Simon Stepputtis,Stefanos Nikolaidis,Michael Lewis,Katia P. Sycara,Woojun Kim*

Main category: cs.MA

TL;DR: 本文提出了一种基于心智理论的适应性集成智能体，有效提升多智能体强化学习中的零次协调能力，在实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习中的一个核心挑战是使智能体能够零次协调地适应之前未见过的队友。现有的方法虽然在生成多样化训练伙伴代理方面取得了一定成果，但缺乏如何利用这些多样化代理池来构建更具适应性的智能体的研究。

Method: 设计了利用心智理论推断队友意图的机制，并结合策略集成选择最合适的应对策略，形成适应性集成智能体架构。进行Overcooked环境下的多实验验证。

Result: 提出了一种基于心智理论的适应性集成智能体，通过推断队友意图并从策略集成中选择最合适的策略来实现更好的适应性。在Overcooked环境中，实验表明该方法在全可观测和部分可观测环境下的零次协调性能优于单一最佳响应基线。

Conclusion: 基于心智理论的最佳响应选择可以引导智能体从策略集成中选择更具适应性的策略，实现更好的零次协调效果。

Abstract: A central challenge in multi-agent reinforcement learning is enabling agents to adapt to previously unseen teammates in a zero-shot fashion. Prior work in zero-shot coordination often follows a two-stage process, first generating a diverse training pool of partner agents, and then training a best-response agent to collaborate effectively with the entire training pool. While many previous works have achieved strong performance by devising better ways to diversify the partner agent pool, there has been less emphasis on how to leverage this pool to build an adaptive agent. One limitation is that the best-response agent may converge to a static, generalist policy that performs reasonably well across diverse teammates, rather than learning a more adaptive, specialist policy that can better adapt to teammates and achieve higher synergy. To address this, we propose an adaptive ensemble agent that uses Theory-of-Mind-based best-response selection to first infer its teammate's intentions and then select the most suitable policy from a policy ensemble. We conduct experiments in the Overcooked environment to evaluate zero-shot coordination performance under both fully and partially observable settings. The empirical results demonstrate the superiority of our method over a single best-response baseline.

</details>


### [42] [Building Large-Scale Drone Defenses from Small-Team Strategies](https://arxiv.org/abs/2602.12502)
*Grant Douglas,Stephen Franklin,Claudia Szabo,Mingyu Guo*

Main category: cs.MA

TL;DR: 本文提出了一种动态规划分解框架，将验证有效的小团队策略模块化组合构建大规模防御力量，解决了大规模敌对无人机群防御的可扩展性难题，并展示了该方法的实用性和优越性。


<details>
  <summary>Details</summary>
Motivation: 常规多智能体优化方法难以有效应对大规模敌对无人机群，需要一种可扩展的协调方法以有效防御大型敌对无人机编队。

Method: 通过动态规划分解，将在小规模防御团队中验证有效的策略作为模块组件，集成为大规模防御力量，实现多智能体协作的可扩展性。通过对多个小团队候选策略进行采样，反复评估大团队表现并优化模块组件池，迭代提升整体策略效果。

Result: 实验表明所提框架能在大规模场景中有效扩展防御策略，同时保持防御效果，还能发现传统优化难以探测的协作行为。

Conclusion: 该研究表明通过模块化策略分解与迭代优化，可有效构建大规模防御无人机阵型，提升防御效果与策略协作性，为防御大型敌对无人机群提供了可行解决方案。

Abstract: Defending against large adversarial drone swarms requires coordination methods that scale effectively beyond conventional multi-agent optimisation. In this paper, we propose to scale strategies proven effective in small defender teams by integrating them as modular components of larger forces using our proposed framework. A dynamic programming (DP) decomposition assembles these components into large teams in polynomial time, enabling efficient construction of scalable defenses without exhaustive evaluation. Because a unit that is strong in isolation may not remain strong when combined, we sample across multiple small-team candidates. Our framework iterates between evaluating large-team outcomes and refining the pool of modular components, allowing convergence on increasingly effective strategies. Experiments demonstrate that this partitioning approach scales to substantially larger scenarios while preserving effectiveness and revealing cooperative behaviours that direct optimisation cannot reliably discover.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [43] [Perceptual Self-Reflection in Agentic Physics Simulation Code Generation](https://arxiv.org/abs/2602.12311)
*Prashant Shende,Bradley Camburn*

Main category: cs.SE

TL;DR: 论文提出通过多智能体系统及基于视觉语言模型的感知自反馈机制，提升从自然语言生成物理仿真代码的准确性和稳定性，有效解决传统测试检测不到的物理行为错误问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有从自然语言生成物理仿真代码时存在的“oracle gap”问题，即语法正确但物理行为错误的代码传统测试难以检测，提升仿真代码的物理准确性和稳定性。

Method: 设计了四个专职智能体—自然语言解释器、技术需求生成器、自动代码生成与自纠正模块、基于视觉语言模型的物理验证器，并通过分析仿真动画帧的视觉信息进行验证和迭代优化，完成高质量代码生成。

Result: 该论文提出了一个多智能体框架，通过自然语言描述生成物理仿真代码，核心创新是引入了感知式自我反思机制对生成的仿真进行验证。系统包含四个专门智能体：自然语言解释器、技术需求生成器、带自动自纠正的物理代码生成器以及基于视觉语言模型的物理验证器。该验证方法通过分析渲染动画帧而非直接检验代码结构，解决了传统测试无法发现的语法正确但物理行为错误的问题（"oracle gap"）。在涵盖包括经典力学、流体力学、热力学等七个领域的评测中，系统表现出较单次生成方法显著的准确性提升和稳定的代码自纠正能力。每个动画生成成本约0.20美元，表明该方法有效支持工程及物理数据生成流程。

Conclusion: 引入感知自我反思的多智能体架构显著提升了物理仿真代码生成的物理准确性和自纠正能力，验证了视觉反馈在物理仿真任务中优于单次生成的假设，展示了该技术在工程和物理数据生成中的应用潜力。

Abstract: We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a natural language interpreter that converts user requests into physics-based descriptions; a technical requirements generator that produces scaled simulation parameters; a physics code generator with automated self-correction; and a physics validator that implements perceptual self-reflection. The key innovation is perceptual validation, which analyzes rendered animation frames using a vision-capable language model rather than inspecting code structure directly. This approach addresses the ``oracle gap'' where syntactically correct code produces physically incorrect behavior--a limitation that conventional testing cannot detect. We evaluate the system across seven domains including classical mechanics, fluid dynamics, thermodynamics, electromagnetics, wave physics, reaction-diffusion systems, and non-physics data visualization. The perceptual self-reflection architecture demonstrates substantial improvement over single-shot generation baselines, with the majority of tested scenarios achieving target physics accuracy thresholds. The system exhibits robust pipeline stability with consistent code self-correction capability, operating at approximately \$0.20 per animation. These results validate our hypothesis that feeding visual simulation outputs back to a vision-language model for iterative refinement significantly outperforms single-shot code generation for physics simulation tasks and highlights the potential of agentic AI to support engineering workflows and physics data generation pipelines.

</details>


### [44] [SHAPR: A Solo Human-Centred and AI-Assisted Practice Framework for Research Software Development](https://arxiv.org/abs/2602.12443)
*Ka Ching Chan*

Main category: cs.SE

TL;DR: 本文提出SHAPR框架，帮助独立研究者在AI辅助下有效实施ADR循环，推动研究软件开发和人机协作。


<details>
  <summary>Details</summary>
Motivation: 现有ADR框架对独立、AI辅助的研究软件开发日常实践缺乏具体指导。

Method: 提出SHAPR框架，结合Action Design Research(ADR)原则，支持独立研究者在AI辅助下的软件开发实践。

Result: SHAPR框架明确了角色、人工制品、反思实践和轻量级治理机制，促进人类责任和学习。

Conclusion: SHAPR作为设计人工制品，符合ADR原则、支持独立研究实践，有助于知识生产和研究生培训。

Abstract: Research software has become a central vehicle for inquiry and learning in many Higher Degree Research (HDR) contexts, where solo researchers increasingly develop software-based artefacts as part of their research methodology. At the same time, generative artificial intelligence is reshaping development practice, offering powerful forms of assistance while introducing new challenges for accountability, reflection, and methodological rigour. Although Action Design Research (ADR) provides a well-established foundation for studying and constructing socio-technical artefacts, it offers limited guidance on how its principles can be operationalised in the day-to-day practice of solo, AI-assisted research software development. This paper proposes the SHAPR framework (Solo, Human-centred, AI-assisted PRactice) as a practice-level operational framework that complements ADR by translating its high-level principles into actionable guidance for contemporary research contexts. SHAPR supports the enactment of ADR Building-Intervention-Evaluation cycles by making explicit the roles, artefacts, reflective practices, and lightweight governance mechanisms required to sustain human accountability and learning in AI-assisted development. The contribution of the paper is conceptual: SHAPR itself is treated as the primary design artefact and unit of analysis and is evaluated formatively through reflective analysis of its internal coherence, alignment with ADR principles, and applicability to solo research practice. By explicitly linking research software development, Human-AI collaboration, and reflective learning, this study contributes to broader discussions on how SHAPR can support both knowledge production and HDR researcher training.

</details>


### [45] [Favia: Forensic Agent for Vulnerability-fix Identification and Analysis](https://arxiv.org/abs/2602.12500)
*André Storhaug,Jiamou Sun,Jingyue Li*

Main category: cs.SE

TL;DR: 提出Favia框架，结合候选提交排序和基于ReAct的智能体进行深度语义分析，实现对漏洞修复提交的高效精准识别，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 识别漏洞修复提交对于软件安全维护至关重要，但现有方法在大规模、高相似度候选环境下准确率和召回率表现不佳，难以应对多文件和复杂修复场景，亟需更精准的识别方案。

Method: 采用两阶段方法：首先进行高效候选提交排序缩小搜索空间；随后利用ReAct智能体，在预提交代码环境中运用深度语义和因果分析核实每个提交，识别修复漏洞的代码变更。

Result: 本文提出了Favia，一种基于智能体的漏洞修复提交识别框架，通过结合高效排序和深度语义推理，实现了对大规模代码库中安全修复提交的准确定位。Favia利用ReAct大语言模型智能体在预提交环境下，定位漏洞组件，遍历代码库，并建立代码变更与漏洞根本原因之间的因果关系，能够识别复杂的多文件和间接修复。通过在包含超过八百万提交的大规模真实数据集CVEVC上的评测，Favia在真实候选提交选择下显著优于传统方法和现有LLM方法，在准确率与召回率的平衡上表现最佳，取得最高F1分数。

Conclusion: Favia在大规模真实数据集上表现优越，能够鲁棒识别间接、多文件及复杂漏洞修复，达到更高准确率与召回率的平衡，显著提升漏洞修复提交定位效果。

Abstract: Identifying vulnerability-fixing commits corresponding to disclosed CVEs is essential for secure software maintenance but remains challenging at scale, as large repositories contain millions of commits of which only a small fraction address security issues. Existing automated approaches, including traditional machine learning techniques and recent large language model (LLM)-based methods, often suffer from poor precision-recall trade-offs. Frequently evaluated on randomly sampled commits, we uncover that they are substantially underestimating real-world difficulty, where candidate commits are already security-relevant and highly similar. We propose Favia, a forensic, agent-based framework for vulnerability-fix identification that combines scalable candidate ranking with deep and iterative semantic reasoning. Favia first employs an efficient ranking stage to narrow the search space of commits. Each commit is then rigorously evaluated using a ReAct-based LLM agent. By providing the agent with a pre-commit repository as environment, along with specialized tools, the agent tries to localize vulnerable components, navigates the codebase, and establishes causal alignment between code changes and vulnerability root causes. This evidence-driven process enables robust identification of indirect, multi-file, and non-trivial fixes that elude single-pass or similarity-based methods. We evaluate Favia on CVEVC, a large-scale dataset we made that comprises over 8 million commits from 3,708 real-world repositories, and show that it consistently outperforms state-of-the-art traditional and LLM-based baselines under realistic candidate selection, achieving the strongest precision-recall trade-offs and highest F1-scores.

</details>


### [46] [Reconciling Complexity and Simplicity in the Business Model Canvas Design Through Metamodelling and Domain-Specific Modelling](https://arxiv.org/abs/2602.12721)
*Nordine Benkeltoum*

Main category: cs.SE

TL;DR: 本文通过设计科学方法构建基于UML的商业模式画布元模型及DSML工具，明确组件间关系，提升BMC的形式化建模水平，实现理论与实践的有效结合。


<details>
  <summary>Details</summary>
Motivation: 当前虽然商业模式画布（BMC）被广泛采用，但在正式建模中面临对组件间关系明确表示的挑战，且需保持BMC的简易性。

Method: 采用设计科学研究方法，基于统一建模语言(UML)构建BMC元模型，结合领域专用建模语言(DSML)工具，借助V 4框架加强理论基础。

Result: 提出了三类核心关系（支持、决定、影响）的元模型，提高BMC组件关系的明确性和解释性，兼顾严谨性与易用性。

Conclusion: 正式规范BMC组件关系显著提升了其表示的一致性和可解释性，所构建的元模型和工具为BMC工具开发及与企业架构融合提供了坚实基础。

Abstract: This article introduces a metamodel for the Business Model Canvas (BMC) using the Unified Modelling Language (UML), together with a dedicated Domain-Specific Modelling Language (DSML) tool. Although the BMC is widely adopted by both practitioners and scholars, significant challenges remain in formally modelling business models, particularly with regard to explicit specification of inter-component relationships, while preserving the simplicity that characterises the BMC. Addressing this tension between modelling rigour and practical relevance, this research adopts a Design Science Research approach to formally specify relationships among BMC components and to strengthen their theoretical grounding through an adaptation of the V 4 framework. The proposed metamodel consolidates BMC relationships into three core types: supports, determines, and affects, providing explicit semantics while remaining accessible to end users through graphical tooling. The findings highlight that formally specifying relationships significantly improves the interpretability and consistency of BMC representations. The proposed metamodel and tool offer a rigorous yet usable foundation for developing DSML-based BMC tools and for enabling systematic integration of the BMC into widely used software and enterprise modelling environments, thereby bridging business modelling and enterprise architecture practices for both academics and practitioners.

</details>


### [47] [FuncDroid: Towards Inter-Functional Flows for Comprehensive Mobile App GUI Testing](https://arxiv.org/abs/2602.12834)
*Jinlong He,Changwei Xia,Binru Huang,Jiwei Yan,Jun Yan,Jian Zhang*

Main category: cs.SE

TL;DR: 本文提出了一种基于功能流图（FFG）的跨功能交互导向的移动应用GUI测试方法，通过长短期视角引导的测试流程，实现精确模型构建和深层次缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 现有针对GUI的功能测试忽视跨功能交互，难以发现深层次的跨功能缺陷，急需一种能显式捕获功能交互的测试方法。

Method: 设计功能流图（FFG）来建模应用功能单元及其交互，结合长短期视角的测试生成方法，自适应细化功能边界，系统探索跨功能流程。

Result: 实现了工具FuncDroid，在50个开源缺陷和52个商业应用上测试，覆盖率和缺陷检测数量大幅提升，发现18个未知功能缺陷，证明了方法的有效性。

Conclusion: 提出的方法显著优于现有技术，覆盖率提高28%，缺陷检测数增加107%，并发现18个未知功能性缺陷，验证了其实用性和有效性。

Abstract: As mobile application (app) functionalities grow increasingly complex and their iterations accelerate, ensuring high reliability presents significant challenges. While functionality-oriented GUI testing has attracted growing research attention, existing approaches largely overlook interactions across functionalities, making them ineffective at uncovering deep bugs hidden in inter-functional behaviors. To fill this gap, we first design a Functional Flow Graph (FFG), a behavioral model that explicitly captures an app's functional units and their inter-functional interactions. Based on the FFG, we further introduce an inter-functional-flow-oriented GUI testing approach with the dual goals of precise model construction and deep bug detection. This approach is realized through a long-short-term-view-guided testing process. By combining two complementary test-generation views, it can adaptively refine functional boundaries and systematically explore inter-functional flows under diverse triggering conditions. We implement our approach in a tool called FuncDroid, and evaluate it on two benchmarks: (1) a widely-used open-source benchmark with 50 reproducible crash bugs and (2) a diverse set of 52 popular commercial apps. Experimental results demonstrate that FuncDroid significantly outperforms state-of-the-art baselines in both coverage (+28%) and bug detection number (+107%). Moreover, FuncDroid successfully uncovers 18 previously unknown non-crash functional bugs in commercial apps, confirming its practical effectiveness.

</details>


### [48] [A Microservice-Based Platform for Sustainable and Intelligent SLO Fulfilment and Service Management](https://arxiv.org/abs/2602.12875)
*Juan Luis Herrera,Daniel Wang,Schahram Dustdar*

Main category: cs.SE

TL;DR: CASCA是一个基于微服务架构的开源智能控制平台，能够在保护开发者隐私的前提下动态调整计算连续体中的服务，确保服务水平目标的完成。


<details>
  <summary>Details</summary>
Motivation: 随着基于微服务架构的应用部署到计算连续体，如何动态调整服务以兼顾性能与可持续性指标，同时保护开发者隐私，是一个亟待解决的问题。

Method: 设计并实现了一个基于微服务架构(MSA)的开源平台CASCA，支持运行时智能决策系统对服务进行动态调整，支持多种编程语言实现决策逻辑。

Result: 在真实的计算连续体测试环境中，CASCA成功支持了媒体流服务的动态重新配置，且决策系统使用Bash、Rust和Python实现均表现良好，且隐私未被破坏。

Conclusion: 本文提出的CASCA平台能够在保证开发者隐私的前提下，允许计算连续体提供商重新配置微服务以满足服务水平目标(SLOs)。

Abstract: The Microservices Architecture (MSA) design pattern has become a staple for modern applications, allowing functionalities to be divided across fine-grained microservices, fostering reusability, distribution, and interoperability. As MSA-based applications are deployed to the Computing Continuum (CC), meeting their Service Level Objectives (SLOs) becomes a challenge. Trading off performance and sustainability SLOs is especially challenging. This challenge can be addressed with intelligent decision systems, able to reconfigure the services during runtime to meet the SLOs. However, developing these agents while adhering to the MSA pattern is complex, especially because CC providers, who have key know-how and information to fulfill these SLOs, must comply with the privacy requirements of application developers. This work presents the Carbon-Aware SLO and Control plAtform (CASCA), an open-source MSA-based platform that allows CC providers to reconfigure services and fulfill their SLOs while maintaining the privacy of developers. CASCA is architected to be highly reusable, distributable, and easy to use, extend, and modify. CASCA has been evaluated in a real CC testbed for a media streaming service, where decision systems implemented in Bash, Rust, and Python successfully reconfigured the service, unaffected by upholding privacy.

</details>


### [49] [The Influence of Code Smells in Efferent Neighbors on Class Stability](https://arxiv.org/abs/2602.12950)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 本文研究代码坏味道及其在依赖类中的相互关系如何影响代码稳定性，利用大规模开源项目数据，揭示了代码坏味道交互对维护性的复合影响。


<details>
  <summary>Details</summary>
Motivation: 理解代码不稳定性的驱动因素对于有效的软件维护至关重要，特别是类的不稳定性会导致更多或更频繁的代码修改，并增加意外副作用的风险。已有研究主要关注类内部的代码坏味道对稳定性的影响，忽略了代码坏味道在依赖类中的作用，尤其是代码坏味道的相互关联和交互对代码质量的影响尚未充分探讨。

Method: 通过挖掘100个高星GitHub项目一年的提交记录，结合静态依赖分析和代码坏味道检测，构建代码坏味道相互关联和交互模型，并以此预测类的稳定性。

Result: 通过分析GitHub上100个高星项目一年内的提交历史，本文检测了代码坏味道与静态依赖，确定了代码坏味道的相互关联和交互，并将其作为预测类稳定性的因素。研究表明，依赖类中存在的代码坏味道及其相互关系对类的稳定性有显著影响。

Conclusion: 代码坏味道不仅在类内部影响稳定性，其在依赖类中的存在及相互作用同样加剧了不稳定性，显示出维护策略需考虑代码坏味道的网络效应。

Abstract: Understanding what drives code instability is essential for effective software maintenance, as unstable classes require larger or more frequent edits and increase the risk of unintended side effects. Although code smells are widely believed to harm maintainability, most prior stability studies examine only the smells within the class being modified. In practice, however, classes can change because their efferent neighbors (i.e., the classes they depend on) are modified due to ripple effects that propagate along static dependencies, even if the class itself is clean. Such ripple effects may be more severe when the efferent neighbor exhibits code smells. In addition, code smells rarely occur alone. They often appear together within a class or across classes connected by static dependencies, a phenomenon known as code smell interrelation. Such interrelation can lead to code smell interaction, where smells are directly connected through static dependencies and may further compound maintainability issues. However, the effect of code smell interrelation and interaction on code quality remains largely underexplored. Therefore, this study investigates whether the presence of code smells in a class's efferent neighbors affects its stability, considering the factor of code smell interrelation and interaction. To achieve this, we mine one year of commit history from 100 top-starred GitHub projects, detect code smells and static dependencies, determine code smell interrelation and interaction, and model these factors as predictors of class stability.

</details>


### [50] [Analysis of Asset Administration Shell-based Negotiation Processes for Scaling Applications](https://arxiv.org/abs/2602.13029)
*David Dietrich,Armin Lechler,Alexander Verl*

Main category: cs.SE

TL;DR: 本文通过实验评估了主动资产管理壳在多资产场景下的性能和通信负载，指出了其可扩展性瓶颈，为AAS标准化提供参考。


<details>
  <summary>Details</summary>
Motivation: 解决当前主动AAS行为的概念性限制及其在工业环境中可扩展性不足的问题，提升AAS在多资产通信和协商中的效率，减少消息负载。

Method: 基于VDI/VDE 2193中工业4.0组件语言的主动资产管理壳(AAS)架构，通过设定场景和评估标准，开发可扩展实现并进行多资产数量下的实验。

Result: 实验揭示了基于AAS的协商机制在性能、通信负载及适应性方面存在的限制，展示了随着资产数量增加其可扩展性问题和通信开销。

Conclusion: 研究发现主动AAS在多资产规模下存在性能和通信开销限制，需优化机制以提升可扩展性和适应工业环境的需求，推动AAS标准的进一步完善。

Abstract: The proactive Asset Administration Shell (AAS) enables bidirectional communication between assets. It uses the Language for I4.0 Components in VDI/VDE 2193 to facilitate negotiations, such as allocating products to available production resources. This paper investigates the efficiency of the negotiation, based on criteria, such as message load, for applications with a scaling number of assets. Currently, the focus of AAS standardization is on submodels and their security to enable interoperable data access. Their proactive behavior remains conceptual and is still a subject of scientific research. Existing studies examine proactive AAS architecture examples with a limited number of assets, raising questions about their scalability in industrial environments. To analyze proactive AAS for scaling applications, a scenario and evaluation criteria are introduced. A scalable implementation is developed using current architectures for proactive AAS, upon which experiments are conducted with a varying number of assets. The results reveal the performance limitations, communication overhead, and adaptability of the AAS-based negotiation mechanism scaling. This information can improve the further development and standardization of the AAS.

</details>


### [51] [Automated Testing of Task-based Chatbots: How Far Are We?](https://arxiv.org/abs/2602.13072)
*Diego Clerissi,Elena Masserini,Daniela Micucci,Leonardo Mariani*

Main category: cs.SE

TL;DR: 本文对流行任务型聊天机器人的现有测试技术进行了实证评估，发现其在测试场景和判定机制上仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 随着任务型聊天机器人的广泛应用，传统测试方法难以系统覆盖对话空间，亟需评估并改进专用测试技术以确保聊天机器人的质量。

Method: 通过对GitHub上使用主流商业及开源平台开发的任务型聊天机器人进行实验评估，检验现有先进测试技术的有效性。

Result: 实验结果表明，现有测试技术在生成测试场景的复杂性和判定机制的准确性方面存在明显不足。

Conclusion: 现有任务型聊天机器人测试技术在测试场景生成和判定标准设计方面仍存在不足，需要进一步改进以提升测试效果。

Abstract: Task-based chatbots are software, typically embedded in real-world applications, that assist users in completing tasks through a conversational interface. As chatbots are gaining popularity, effectively assessing their quality has become crucial. Whereas traditional testing techniques fail to systematically exercise the conversational space of chatbots, several approaches specifically targeting chatbots have emerged from both industry and research. Although these techniques have shown advancements over the years, they still exhibit limitations, such as simplicity of the generated test scenarios and weakness in implemented oracles. In this paper, we conduct a confirmatory study to investigate such limitations by evaluating the effectiveness of state-of-the-art chatbot testing techniques on a curated selection of task-based chatbots from GitHub, developed using the most popular commercial and open-source platforms.

</details>


### [52] [Source Code Hotspots: A Diagnostic Method for Quality Issues](https://arxiv.org/abs/2602.13170)
*Saleha Muzammil,Mughees Ur Rehman,Zoe Kotti,Diomidis Spinellis*

Main category: cs.SE

TL;DR: 本文挖掘91个GitHub项目历史，发现15种代码热点模式，自动化工具制造大量变更噪声，提出对应重构和CI措施以提升软件质量。


<details>
  <summary>Details</summary>
Motivation: 软件热点代码频繁变更，集中维护负担，理解其产生原因有助于提升代码质量和维护效率。

Method: 分析91个活跃GitHub项目的完整版本历史，识别热点代码的15种模式，并量化其出现频率及成因。

Result: 本文通过对91个活跃GitHub项目的完整版本历史进行挖掘，识别出了15种反复出现的代码热点模式，揭示了热点出现的原因。最常见的三种模式是版本固定更新（26%）、长行代码修改（17%）和格式反复调整（9%）。研究发现大量热点编辑由自动化工具生成（74%），表明机器人的活动是变更历史中主要但可避免的噪声。作者通过将这些模式对应具体的重构指导和持续集成检查，为开发者提供了控制热点、提升软件配置性、稳定性和可变性的可操作方案。

Conclusion: 热点代码主要由自动化工具引发，通过针对热点模式实施重构和持续集成检查，可有效提升软件质量，减少维护负担。

Abstract: Software source code often harbours "hotspots": small portions of the code that change far more often than the rest of the project and thus concentrate maintenance activity. We mine the complete version histories of 91 evolving, actively developed GitHub repositories and identify 15 recurring line-level hotspot patterns that explain why these hotspots emerge. The three most prevalent patterns are Pinned Version Bump (26%), revealing brittle release practices; Long Line Change (17%), signalling deficient layout; and Formatting Ping-Pong (9%), indicating missing or inconsistent style automation. Surprisingly, automated accounts generate 74% of all hotspot edits, suggesting that bot activity is a dominant but largely avoidable source of noise in change histories. By mapping each pattern to concrete refactoring guidelines and continuous integration checks, our taxonomy equips practitioners with actionable steps to curb hotspots and systematically improve software quality in terms of configurability, stability, and changeability.

</details>
