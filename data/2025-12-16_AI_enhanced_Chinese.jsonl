{"id": "2512.11922", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11922", "abs": "https://arxiv.org/abs/2512.11922", "authors": ["Muhammad Waseem", "Aakash Ahmad", "Kai-Kristian Kemell", "Jussi Rasku", "Sami Lahti", "Kalle M\u00e4kel\u00e4", "Pekka Abrahamsson"], "title": "Vibe Coding in Practice: Flow, Technical Debt, and Guidelines for Sustainable Use", "comment": "10", "summary": "Vibe Coding (VC) is a form of software development assisted by generative AI, in which developers describe the intended functionality or logic via natural language prompts, and the AI system generates the corresponding source code. VC can be leveraged for rapid prototyping or developing the Minimum Viable Products (MVPs); however, it may introduce several risks throughout the software development life cycle. Based on our experience from several internally developed MVPs and a review of recent industry reports, this article analyzes the flow-debt tradeoffs associated with VC. The flow-debt trade-off arises when the seamless code generation occurs, leading to the accumulation of technical debt through architectural inconsistencies, security vulnerabilities, and increased maintenance overhead. These issues originate from process-level weaknesses, biases in model training data, a lack of explicit design rationale, and a tendency to prioritize quick code generation over human-driven iterative development. Based on our experiences, we identify and explain how current model, platform, and hardware limitations contribute to these issues, and propose countermeasures to address them, informing research and practice towards more sustainable VC approaches.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u751f\u6210\u5f0fAI\u8f85\u52a9\u7684\u8f6f\u4ef6\u5f00\u53d1\u6a21\u5f0f\u2014\u2014Vibe Coding\uff08VC\uff09\u7684\u6d41\u7545\u7f16\u7801\u4e0e\u6280\u672f\u503a\u52a1\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u6307\u51fa\u5176\u5728\u5feb\u901f\u5f00\u53d1MVP\u65f6\u5e26\u6765\u7684\u98ce\u9669\u3002", "motivation": "\u5f53\u524dVC\u867d\u7136\u80fd\u5feb\u901f\u751f\u6210\u4ee3\u7801\uff0c\u63a8\u52a8\u5feb\u901f\u5f00\u53d1\uff0c\u4f46\u5728\u8f6f\u4ef6\u5f00\u53d1\u751f\u547d\u5468\u671f\u4e2d\u5f15\u5165\u4e86\u6280\u672f\u503a\u52a1\uff0c\u5e26\u6765\u67b6\u6784\u4e0d\u4e00\u81f4\u3001\u5b89\u5168\u6f0f\u6d1e\u53ca\u7ef4\u62a4\u8d1f\u62c5\uff0c\u4e9f\u9700\u63a2\u8ba8\u5176\u6839\u6e90\u53ca\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u4f5c\u8005\u5185\u90e8\u591a\u4e2aMVP\u9879\u76ee\u7ecf\u9a8c\u53ca\u884c\u4e1a\u62a5\u544a\uff0c\u5206\u6790VC\u6d41\u7a0b\u503a\u52a1\u4ea7\u751f\u539f\u56e0\uff0c\u5305\u62ec\u6d41\u7a0b\u6f0f\u6d1e\u3001\u6a21\u578b\u8bad\u7ec3\u504f\u5dee\u3001\u7f3a\u4e4f\u8bbe\u8ba1\u7406\u7531\u53ca\u5feb\u901f\u7f16\u7801\u4f18\u5148\u7b49\uff0c\u8fdb\u4e00\u6b65\u89e3\u91ca\u5f53\u524d\u6a21\u578b\u3001\u5e73\u53f0\u3001\u786c\u4ef6\u9650\u5236\u5982\u4f55\u52a0\u5267\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u76f8\u5e94\u5bf9\u7b56\u3002", "result": "\u53d1\u73b0VC\u5feb\u901f\u751f\u6210\u4ee3\u7801\u867d\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u540c\u65f6\u5e26\u6765\u67b6\u6784\u4e0d\u4e00\u81f4\u3001\u5b89\u5168\u98ce\u9669\u53ca\u7ef4\u62a4\u6210\u672c\u4e0a\u5347\uff0c\u8fd9\u4e9b\u95ee\u9898\u7531\u591a\u65b9\u9762\u56e0\u7d20\u5171\u540c\u4f5c\u7528\u5bfc\u81f4\uff0c\u76ee\u524d\u6280\u672f\u9650\u5236\u4f7f\u5f97\u95ee\u9898\u96be\u4ee5\u6839\u9664\u3002", "conclusion": "\u4e3a\u4e86\u5b9e\u73b0\u53ef\u6301\u7eed\u7684VC\uff0c\u5e94\u5173\u6ce8\u6d41\u7a0b\u6539\u8fdb\u3001\u6a21\u578b\u4f18\u5316\u53ca\u786c\u4ef6\u5347\u7ea7\uff0c\u91c7\u53d6\u7efc\u5408\u5bf9\u7b56\u51cf\u5c11\u6280\u672f\u503a\u52a1\u79ef\u7d2f\uff0c\u63a8\u52a8VC\u5728\u5b9e\u9645\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5065\u5eb7\u53d1\u5c55\u3002"}}
{"id": "2512.11940", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11940", "abs": "https://arxiv.org/abs/2512.11940", "authors": ["Maha Sroor", "Teerath Das", "Rahul Mohanani", "Tommi Mikkonen"], "title": "A Systematic Mapping Study on Risks and Vulnerabilities in Software Containers", "comment": null, "summary": "Software containers are widely adopted for developing and deploying software applications. Despite their popularity, major security concerns arise during container development and deployment. Software Engineering (SE) research literature reveals a lack of reviewed, aggregated, and organized knowledge of risks, vulnerabilities, security practices, and tools in container-based systems development and deployment. Therefore, we conducted a Systematic Mapping Study (SMS) based on 129 selected primary studies to explore and organize existing knowledge on security issues in software container systems. Data from the primary studies enabled us to identify critical risks and vulnerabilities across the container life-cycle and categorize them using a novel taxonomy. Additionally, the findings highlight the causes and implications and provide a list of mitigation techniques to overcome these risks and vulnerabilities. Furthermore, we provide an aggregation of security practices and tools that can help support and improve the overall security of container systems. This study offers critical insights into the current landscape of security issues within software container systems. Our analysis highlights the need for future SE research to focus on security enhancement practices that strengthen container systems and develop effective mitigation strategies to comprehensively address existing risks and vulnerabilities.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u6574\u7406\u4e86\u5bb9\u5668\u7cfb\u7edf\u4e2d\u5b58\u5728\u7684\u5b89\u5168\u98ce\u9669\u3001\u6f0f\u6d1e\u53ca\u7f13\u89e3\u65b9\u6cd5\uff0c\u65e8\u5728\u63d0\u5347\u5bb9\u5668\u5b89\u5168\u6c34\u5e73\u3002", "motivation": "\u5f53\u524d\u8f6f\u4ef6\u5bb9\u5668\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u5f00\u53d1\u4e0e\u90e8\u7f72\u8fc7\u7a0b\u4e2d\u5b58\u5728\u663e\u8457\u7684\u5b89\u5168\u9690\u60a3\uff0c\u4e14\u7f3a\u4e4f\u7cfb\u7edf\u6027\u603b\u7ed3\u548c\u5206\u7c7b\u7684\u5b89\u5168\u77e5\u8bc6\u3002", "method": "\u57fa\u4e8e129\u7bc7\u4e3b\u7814\u7a76\u6587\u732e\u8fdb\u884c\u4e86\u7cfb\u7edf\u6620\u5c04\u7814\u7a76\uff0c\u8bc6\u522b\u5e76\u5206\u7c7b\u5bb9\u5668\u751f\u547d\u5468\u671f\u4e2d\u7684\u5173\u952e\u98ce\u9669\u548c\u6f0f\u6d1e\uff0c\u68b3\u7406\u5176\u6210\u56e0\u3001\u5f71\u54cd\u53ca\u7f13\u89e3\u6280\u672f\uff0c\u5e76\u6c47\u603b\u76f8\u5173\u5b89\u5168\u5b9e\u8df5\u4e0e\u5de5\u5177\u3002", "result": "\u6784\u5efa\u4e86\u5173\u4e8e\u5bb9\u5668\u5b89\u5168\u95ee\u9898\u7684\u5168\u65b0\u5206\u7c7b\u4f53\u7cfb\uff0c\u660e\u786e\u4e86\u98ce\u9669\u6210\u56e0\u53ca\u540e\u679c\uff0c\u63d0\u4f9b\u4e86\u5177\u4f53\u7684\u7f13\u89e3\u63aa\u65bd\u548c\u5b9e\u8df5\u5de5\u5177\u7684\u6c47\u603b\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7406\u89e3\u8f6f\u4ef6\u5bb9\u5668\u5b89\u5168\u73b0\u72b6\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u547c\u5401\u672a\u6765\u7814\u7a76\u91cd\u70b9\u52a0\u5f3a\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u548c\u6709\u6548\u7f13\u89e3\u7b56\u7565\u7684\u5f00\u53d1\u3002"}}
{"id": "2512.11984", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11984", "abs": "https://arxiv.org/abs/2512.11984", "authors": ["Alireza Joonbakhsh", "Alireza Rostami", "AmirMohammad Kamalinia", "Ali Nazeri", "Farshad Khunjush", "Bedir Tekinerdogan", "Siamak Farshidi"], "title": "Evidence-Driven Decision Support for AI Model Selection in Research Software Engineering", "comment": null, "summary": "The rapid proliferation of artificial intelligence (AI) models and methods presents growing challenges for research software engineers and researchers who must select, integrate, and maintain appropriate models within complex research workflows. Model selection is often performed in an ad hoc manner, relying on fragmented metadata and individual expertise, which can undermine reproducibility, transparency, and overall research software quality.\n  This work proposes a structured and evidence-driven approach to support AI model selection that aligns with both technical and contextual requirements. We conceptualize AI model selection as a Multi-Criteria Decision-Making (MCDM) problem and introduce an evidence-based decision-support framework that integrates automated data collection pipelines, a structured knowledge graph, and MCDM principles. Following the Design Science Research methodology, the proposed framework (ModelSelect) is empirically validated through 50 real-world case studies and comparative experiments against leading generative AI systems.\n  The evaluation results show that ModelSelect produces reliable, interpretable, and reproducible recommendations that closely align with expert reasoning. Across the case studies, the framework achieved high coverage and strong rationale alignment in both model and library recommendation tasks, performing comparably to generative AI assistants while offering superior traceability and consistency.\n  By framing AI model selection as an MCDM problem, this work establishes a rigorous foundation for transparent and reproducible decision support in research software engineering. The proposed framework provides a scalable and explainable pathway for integrating empirical evidence into AI model recommendation processes, ultimately improving the quality and robustness of research software decision-making.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6807\u51c6\u51b3\u7b56\u7684AI\u6a21\u578b\u9009\u62e9\u6846\u67b6ModelSelect\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u548c\u81ea\u52a8\u5316\u6570\u636e\u6536\u96c6\uff0c\u5b9e\u73b0\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684\u6a21\u578b\u63a8\u8350\uff0c\u63d0\u5347\u7814\u7a76\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u51b3\u7b56\u8d28\u91cf\u3002", "motivation": "\u5f53\u524dAI\u6a21\u578b\u9009\u62e9\u8fc7\u7a0b\u591a\u4f9d\u8d56\u788e\u7247\u5316\u5143\u6570\u636e\u548c\u4e2a\u4eba\u7ecf\u9a8c\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u652f\u6301\uff0c\u5f71\u54cd\u53ef\u590d\u73b0\u6027\u548c\u7814\u7a76\u8f6f\u4ef6\u8d28\u91cf\u3002", "method": "\u5c06AI\u6a21\u578b\u9009\u62e9\u95ee\u9898\u5efa\u6a21\u4e3a\u591a\u6807\u51c6\u51b3\u7b56\u95ee\u9898\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u96c6\u6210\u81ea\u52a8\u6570\u636e\u6536\u96c6\u3001\u7ed3\u6784\u5316\u77e5\u8bc6\u56fe\u8c31\u548c\u591a\u6807\u51c6\u51b3\u7b56\u539f\u5219\u7684\u8bc1\u636e\u9a71\u52a8\u51b3\u7b56\u652f\u6301\u6846\u67b6ModelSelect\uff0c\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc750\u4e2a\u771f\u5b9e\u6848\u4f8b\u548c\u4e0e\u9886\u5148\u751f\u6210\u5f0fAI\u7cfb\u7edf\u7684\u6bd4\u8f83\u5b9e\u9a8c\uff0cModelSelect\u5728\u6a21\u578b\u548c\u5e93\u63a8\u8350\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u9ad8\u8986\u76d6\u7387\u3001\u5f3a\u5408\u7406\u6027\u4e00\u81f4\u6027\u53ca\u826f\u597d\u8ffd\u8e2a\u6027\uff0c\u63a8\u8350\u7ed3\u679c\u4e0e\u4e13\u5bb6\u63a8\u7406\u9ad8\u5ea6\u5951\u5408\u3002", "conclusion": "\u5c06AI\u6a21\u578b\u9009\u62e9\u95ee\u9898\u7cfb\u7edf\u5316\u4e3a\u591a\u6807\u51c6\u51b3\u7b56\u95ee\u9898\uff0c\u4e3a\u7814\u7a76\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u900f\u660e\u3001\u53ef\u91cd\u590d\u51b3\u7b56\u652f\u6301\u5960\u5b9a\u57fa\u7840\uff0cModelSelect\u6846\u67b6\u5b9e\u73b0\u4e86\u8bc1\u636e\u96c6\u6210\u4e0e\u53ef\u89e3\u91ca\u63a8\u8350\uff0c\u63d0\u5347\u4e86\u51b3\u7b56\u7684\u8d28\u91cf\u548c\u7a33\u5065\u6027\u3002"}}
{"id": "2512.11993", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.11993", "abs": "https://arxiv.org/abs/2512.11993", "authors": ["Ling-Hong Hung", "Ka Yee Yeung"], "title": "Re-opening open-source science through AI assisted development", "comment": null, "summary": "Open-source scientific software is effectively closed to modification by its complexity. With recent advances in technology, an agentic AI team led by a single human can now rapidly and robustly modify large codebases and re-open science to the community which can review and vet the AI generated code. We demonstrate this with a case study, STAR-Flex, which is an open source fork of STAR, adding 16,000 lines of C++ code to add the ability to process 10x Flex data, while maintaining full original function. This is the first open-source processing software for Flex data and was written as part of the NIH funded MorPHiC consortium.", "AI": {"tldr": "\u7814\u7a76\u5c55\u793a\u4e86\u7531\u5355\u4e2a\u4eba\u7c7b\u9886\u5bfc\u7684\u81ea\u4e3bAI\u56e2\u961f\u8fc5\u901f\u4fee\u6539\u5927\u578b\u5f00\u6e90\u79d1\u5b66\u8f6f\u4ef6\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u5f00\u53d1\u4e86\u9996\u4e2a\u7528\u4e8e\u5904\u7406Flex\u6570\u636e\u7684\u5f00\u6e90\u8f6f\u4ef6STAR-Flex\u3002", "motivation": "\u5f00\u6e90\u79d1\u5b66\u8f6f\u4ef6\u56e0\u590d\u6742\u6027\u800c\u96be\u4ee5\u88ab\u793e\u533a\u4fee\u6539\uff0c\u9650\u5236\u4e86\u79d1\u5b66\u5f00\u653e\u6027\u3002", "method": "\u5229\u7528\u5148\u8fdb\u6280\u672f\uff0c\u7531AI\u56e2\u961f\u5728\u5355\u4e2a\u4eba\u9886\u5bfc\u4e0b\uff0c\u6269\u5c55\u4e86\u73b0\u6709\u8f6f\u4ef6STAR\uff0c\u6dfb\u52a0\u5904\u7406Flex\u6570\u636e\u65b0\u529f\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u539f\u6709\u529f\u80fd\u5b8c\u6574\u3002", "result": "\u5f00\u53d1\u51fa\u5305\u542b1.6\u4e07\u884cC++\u4ee3\u7801\u7684STAR-Flex\uff0c\u5b9e\u73b0\u4e86\u9996\u6b21\u5f00\u6e90Flex\u6570\u636e\u5904\u7406\u8f6f\u4ef6\u3002", "conclusion": "AI\u9a71\u52a8\u7684\u8f6f\u4ef6\u5f00\u53d1\u53ef\u4fc3\u8fdb\u79d1\u5b66\u8f6f\u4ef6\u7684\u5f00\u653e\u548c\u793e\u533a\u53c2\u4e0e\uff0c\u63d0\u9ad8\u79d1\u7814\u8f6f\u4ef6\u7684\u53ef\u4fee\u6539\u6027\u548c\u7075\u6d3b\u6027\u3002"}}
{"id": "2512.11943", "categories": ["cs.MA", "cs.AI", "econ.GN"], "pdf": "https://arxiv.org/pdf/2512.11943", "abs": "https://arxiv.org/abs/2512.11943", "authors": ["Yu Liu", "Wenwen Li", "Yifan Dou", "Guangnan Ye"], "title": "How AI Agents Follow the Herd of AI? Network Effects, History, and Machine Optimism", "comment": "7 pages, 5 figures", "summary": "Understanding decision-making in multi-AI-agent frameworks is crucial for analyzing strategic interactions in network-effect-driven contexts. This study investigates how AI agents navigate network-effect games, where individual payoffs depend on peer participatio--a context underexplored in multi-agent systems despite its real-world prevalence. We introduce a novel workflow design using large language model (LLM)-based agents in repeated decision-making scenarios, systematically manipulating price trajectories (fixed, ascending, descending, random) and network-effect strength. Our key findings include: First, without historical data, agents fail to infer equilibrium. Second, ordered historical sequences (e.g., escalating prices) enable partial convergence under weak network effects but strong effects trigger persistent \"AI optimism\"--agents overestimate participation despite contradictory evidence. Third, randomized history disrupts convergence entirely, demonstrating that temporal coherence in data shapes LLMs' reasoning, unlike humans. These results highlight a paradigm shift: in AI-mediated systems, equilibrium outcomes depend not just on incentives, but on how history is curated, which is impossible for human.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u591aAI\u4ee3\u7406\u5728\u7f51\u7edc\u6548\u5e94\u6e38\u620f\u4e2d\u7684\u51b3\u7b56\u884c\u4e3a\uff0c\u53d1\u73b0\u5386\u53f2\u6570\u636e\u548c\u5176\u65f6\u95f4\u5e8f\u5217\u7ed3\u6784\u5bf9AI\u4ee3\u7406\u7684\u5747\u8861\u63a8\u65ad\u81f3\u5173\u91cd\u8981\uff0c\u5f31\u7f51\u7edc\u6548\u5e94\u4e0b\u53ef\u90e8\u5206\u6536\u655b\uff0c\u5f3a\u7f51\u7edc\u6548\u5e94\u4e0b\u5219\u51fa\u73b0AI\u4e50\u89c2\u504f\u5dee\uff0c\u968f\u673a\u5386\u53f2\u6570\u636e\u5219\u5bfc\u81f4\u6536\u655b\u5931\u8d25\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7f51\u7edc\u6548\u5e94\u6e38\u620f\u7684\u6218\u7565\u4e92\u52a8\u867d\u5e7f\u6cdb\u5b58\u5728\uff0c\u4f46\u5c1a\u672a\u5f97\u5230\u6df1\u5165\u7814\u7a76\uff0c\u7279\u522b\u662fAI\u4ee3\u7406\u5982\u4f55\u57fa\u4e8e\u5386\u53f2\u4fe1\u606f\u51b3\u7b56\u7684\u673a\u5236\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684AI\u4ee3\u7406\uff0c\u6a21\u62df\u91cd\u590d\u51b3\u7b56\u8fc7\u7a0b\uff0c\u7cfb\u7edf\u64cd\u63a7\u4ef7\u683c\u8f68\u8ff9\uff08\u56fa\u5b9a\u3001\u4e0a\u5347\u3001\u4e0b\u964d\u3001\u968f\u673a\uff09\u548c\u7f51\u7edc\u6548\u5e94\u5f3a\u5ea6\uff0c\u5206\u6790\u5176\u5bf9AI\u51b3\u7b56\u4e0e\u5747\u8861\u63a8\u65ad\u7684\u5f71\u54cd\u3002", "result": "\u65e0\u5386\u53f2\u6570\u636e\u65f6AI\u4ee3\u7406\u65e0\u6cd5\u63a8\u65ad\u5747\u8861\uff1b\u6709\u5e8f\u5386\u53f2\u6570\u636e\u5728\u5f31\u7f51\u7edc\u6548\u5e94\u4e0b\u5e2e\u52a9\u90e8\u5206\u6536\u655b\uff0c\u800c\u5f3a\u7f51\u7edc\u6548\u5e94\u5bfc\u81f4AI\u8fc7\u5ea6\u4e50\u89c2\uff1b\u968f\u673a\u5386\u53f2\u6570\u636e\u5219\u5b8c\u5168\u7834\u574f\u6536\u655b\uff0c\u663e\u793a\u65f6\u95f4\u8fde\u8d2f\u6027\u5bf9LLM\u63a8\u7406\u7684\u91cd\u8981\u6027\u3002", "conclusion": "AI\u7cfb\u7edf\u4e2d\u5747\u8861\u7ed3\u679c\u4e0d\u4ec5\u4f9d\u8d56\u6fc0\u52b1\u673a\u5236\uff0c\u8fd8\u6df1\u53d7\u5386\u53f2\u6570\u636e\u751f\u6210\u65b9\u5f0f\u7684\u5f71\u54cd\uff0c\u8fd9\u4e00\u7279\u5f81\u533a\u522b\u4e8e\u4eba\u7c7b\u51b3\u7b56\uff0c\u63ed\u793a\u4e86AI\u4ecb\u5bfc\u7cfb\u7edf\u7b56\u7565\u4e92\u52a8\u7684\u65b0\u8303\u5f0f\u3002"}}
{"id": "2512.11811", "categories": ["cs.CL", "cs.AI", "cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.11811", "abs": "https://arxiv.org/abs/2512.11811", "authors": ["Fengyi Xu", "Jun Ma", "Waishan Qiu", "Cui Guo"], "title": "Enhancing Urban Visual Place Recognition for Crowdsourced Flood Imagery via LLM-Guided Attention", "comment": null, "summary": "Crowdsourced street-view imagery from social media provides valuable real-time visual evidence of urban flooding and other crisis events, yet it often lacks reliable geographic metadata for emergency response. Existing Visual Place Recognition (VPR) models exhibit substantial performance degradation when applied to such imagery due to visual distortions and domain shifts inherent in cross-source scenarios. This paper presents VPR-AttLLM, a model-agnostic framework that integrates the semantic reasoning and geospatial knowledge of Large Language Models (LLMs) into established VPR pipelines through attention-guided descriptor enhancement. By leveraging LLMs to identify location-informative regions within the city context and suppress transient visual noise, VPR-AttLLM improves retrieval performance without requiring model retraining or additional data. Comprehensive evaluations are conducted on extended benchmarks including SF-XL enriched with real social-media flood images, synthetic flooding scenarios over established query sets and Mapillary photos, and a new HK-URBAN dataset capturing morphologically distinct cityscapes. Integrating VPR-AttLLM with three state-of-the-art VPR models-CosPlace, EigenPlaces, and SALAD-consistently improves recall performance, yielding relative gains typically between 1-3% and reaching up to 8% on the most challenging real flood imagery. Beyond measurable gains in retrieval accuracy, this study establishes a generalizable paradigm for LLM-guided multimodal fusion in visual retrieval systems. By embedding principles from urban perception theory into attention mechanisms, VPR-AttLLM bridges human-like spatial reasoning with modern VPR architectures. Its plug-and-play design, strong cross-source robustness, and interpretability highlight its potential for scalable urban monitoring and rapid geo-localization of crowdsourced crisis imagery.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86VPR-AttLLM\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bed\u4e49\u63a8\u7406\u548c\u5730\u7406\u7a7a\u95f4\u77e5\u8bc6\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u673a\u5236\u589e\u5f3a\u89c6\u89c9\u5730\u70b9\u8bc6\u522b\uff08VPR\uff09\u6a21\u578b\u7684\u63cf\u8ff0\u7b26\uff0c\u6709\u6548\u63d0\u5347\u4e86\u793e\u4ea4\u5a92\u4f53\u4f17\u5305\u57ce\u5e02\u6d2a\u6c34\u56fe\u50cf\u7684\u5730\u7406\u5b9a\u4f4d\u6027\u80fd\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u63d0\u4f9b\u7684\u4f17\u5305\u8857\u666f\u56fe\u50cf\u7f3a\u4e4f\u53ef\u9760\u5730\u7406\u5143\u6570\u636e\uff0c\u4f20\u7edfVPR\u6a21\u578b\u5728\u8de8\u6e90\u573a\u666f\u4e2d\u53d7\u89c6\u89c9\u626d\u66f2\u548c\u9886\u57df\u504f\u79fb\u5f71\u54cd\u8868\u73b0\u4e0b\u964d\uff0c\u4e9f\u9700\u6539\u8fdb\u4ee5\u652f\u6301\u5e94\u6025\u54cd\u5e94\u3002", "method": "\u8bbe\u8ba1\u4e86VPR-AttLLM\uff0c\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6846\u67b6\uff0c\u5c06LLM\u7528\u4e8e\u8bc6\u522b\u57ce\u5e02\u573a\u666f\u4e2d\u4f4d\u7f6e\u4fe1\u606f\u4e30\u5bcc\u7684\u533a\u57df\uff0c\u540c\u65f6\u6291\u5236\u77ac\u65f6\u89c6\u89c9\u566a\u58f0\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u5f15\u5bfc\u589e\u5f3a\u63cf\u8ff0\u7b26\uff0c\u65e0\u9700\u6a21\u578b\u91cd\u8bad\u6216\u989d\u5916\u6570\u636e\u5373\u53ef\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u6269\u5c55\u57fa\u51c6\u6570\u636e\u96c6\uff08\u542b\u771f\u5b9e\u793e\u4ea4\u6d2a\u6c34\u56fe\u50cf\u548c\u4e0d\u540c\u57ce\u5e02\u666f\u89c2\uff09\u4e0a\uff0cVPR-AttLLM\u4e0e\u4e09\u79cd\u9876\u5c16VPR\u6a21\u578b\u7ed3\u5408\u540e\u53ec\u56de\u7387\u63d0\u53471%-3%\uff0c\u5728\u6700\u5177\u6311\u6218\u6027\u7684\u573a\u666f\u4e0b\u63d0\u5347\u8fbe8%\u3002", "conclusion": "VPR-AttLLM\u63d0\u51fa\u4e86\u4e00\u4e2a\u901a\u7528\u7684LLM\u5f15\u5bfc\u591a\u6a21\u6001\u878d\u5408\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u4eba\u7c7b\u7a7a\u95f4\u63a8\u7406\u7684\u57ce\u5e02\u611f\u77e5\u7406\u8bba\u4e0e\u73b0\u4ee3VPR\u67b6\u6784\u7684\u7ed3\u5408\uff0c\u5177\u6709\u826f\u597d\u7684\u6269\u5c55\u6027\u548c\u89e3\u91ca\u6027\uff0c\u9002\u5408\u57ce\u5e02\u76d1\u6d4b\u548c\u4f17\u5305\u5371\u673a\u56fe\u50cf\u7684\u5feb\u901f\u5730\u7406\u5b9a\u4f4d\u3002"}}
{"id": "2512.12009", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12009", "abs": "https://arxiv.org/abs/2512.12009", "authors": ["Marc Uphues", "Sebastian Th\u00f6ne", "Herbert Kuchen"], "title": "A Reference Architecture for Embedding Quantum Software Into Enterprise Systems", "comment": null, "summary": "Quantum computing promises a remarkable performance boost for certain applications, including computational intensive problems addressed by enterprise systems. However, software architectures of enterprise systems must consider specific characteristics and quality attributes when collaborating with quantum computing services. Hence, this paper presents a modular reference architecture for embedding quantum software into enterprise systems. Its building blocks consist of loosely coupled and distributed services that implement both quantum-independent and quantum-specific tasks. Although these services either depend on the business domain or the selected quantum algorithm, their orchestration forms a stable and reusable pipeline, specified as an executable BPMN model. For demonstration and evaluation purposes, the proposed reference architecture is utilized in two case studies addressing combinatorial challenges from the field of operations research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u4f01\u4e1a\u7cfb\u7edf\u7684\u6a21\u5757\u5316\u53c2\u8003\u67b6\u6784\uff0c\u7528\u4e8e\u5d4c\u5165\u91cf\u5b50\u8ba1\u7b97\u8f6f\u4ef6\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u670d\u52a1\u5f62\u6210\u7a33\u5b9a\u7684\u53ef\u6267\u884c\u6d41\u7a0b\u3002", "motivation": "\u91cf\u5b50\u8ba1\u7b97\u5728\u5904\u7406\u8ba1\u7b97\u5bc6\u96c6\u578b\u95ee\u9898\u4e2d\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf\uff0c\u4f01\u4e1a\u7cfb\u7edf\u9700\u8981\u8bbe\u8ba1\u5408\u9002\u7684\u8f6f\u4ef6\u67b6\u6784\u4ee5\u878d\u5408\u91cf\u5b50\u8ba1\u7b97\u670d\u52a1\uff0c\u540c\u65f6\u6ee1\u8db3\u7cfb\u7edf\u7279\u6027\u548c\u8d28\u91cf\u5c5e\u6027\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7531\u677e\u8026\u5408\u4e14\u5206\u5e03\u5f0f\u670d\u52a1\u7ec4\u6210\u7684\u6a21\u5757\u5316\u53c2\u8003\u67b6\u6784\uff0c\u8fd9\u4e9b\u670d\u52a1\u5305\u62ec\u4e0e\u91cf\u5b50\u8ba1\u7b97\u76f8\u5173\u548c\u65e0\u5173\u7684\u4efb\u52a1\uff0c\u670d\u52a1\u7684\u7f16\u6392\u901a\u8fc7\u53ef\u6267\u884c\u7684BPMN\u6a21\u578b\u8fdb\u884c\u89c4\u8303\u3002", "result": "\u57fa\u4e8e\u8be5\u53c2\u8003\u67b6\u6784\uff0c\u672c\u6587\u5728\u4e24\u4e2a\u8fd0\u7b79\u5b66\u9886\u57df\u7684\u7ec4\u5408\u4f18\u5316\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u5e94\u7528\u548c\u8bc4\u4f30\uff0c\u9a8c\u8bc1\u4e86\u67b6\u6784\u7684\u9002\u7528\u6027\u548c\u6548\u679c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u5757\u5316\u53c2\u8003\u67b6\u6784\u80fd\u591f\u6709\u6548\u5730\u5c06\u91cf\u5b50\u8f6f\u4ef6\u96c6\u6210\u5230\u4f01\u4e1a\u7cfb\u7edf\u4e2d\uff0c\u652f\u6301\u7a33\u5b9a\u3001\u53ef\u91cd\u7528\u7684\u6d41\u7a0b\uff0c\u6709\u52a9\u4e8e\u4f01\u4e1a\u5229\u7528\u91cf\u5b50\u8ba1\u7b97\u63d0\u5347\u4e1a\u52a1\u6027\u80fd\u3002"}}
{"id": "2512.12791", "categories": ["cs.MA", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12791", "abs": "https://arxiv.org/abs/2512.12791", "authors": ["Sreemaee Akshathala", "Bassam Adnan", "Mahisha Ramesh", "Karthik Vaidhyanathan", "Basil Muhammed", "Kannan Parthasarathy"], "title": "Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems", "comment": null, "summary": "Recent advances in agentic AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other agents to perform complex tasks. These multi-agent architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing agents to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM agents and the multi-agent systems they constitute remain a fundamental challenge. Although various approaches have been proposed in the software engineering literature for evaluating conventional software components, existing methods for AI-based systems often overlook the non-deterministic nature of models. This non-determinism introduces behavioral uncertainty during execution, yet existing evaluations rely on binary task completion metrics that fail to capture it. Evaluating agentic systems therefore requires examining additional dimensions, including the agent ability to invoke tools, ingest and retrieve memory, collaborate with other agents, and interact effectively with its environment. We propose an end-to-end Agent Assessment Framework with four evaluation pillars encompassing LLMs, Memory, Tools, and Environment. We validate the framework on a representative Autonomous CloudOps use case, where experiments reveal behavioral deviations overlooked by conventional metrics, demonstrating its effectiveness in capturing runtime uncertainties.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u667a\u80fd\u4f53\u8bc4\u4f30\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\u96be\u9898\u3002", "motivation": "\u5f53\u524d\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u8bc4\u4f30\u5b58\u5728\u5ffd\u89c6\u6a21\u578b\u975e\u786e\u5b9a\u6027\u5bfc\u81f4\u7684\u884c\u4e3a\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u4f20\u7edf\u4e8c\u5143\u5b8c\u6210\u6307\u6807\u4e0d\u8db3\u4ee5\u53cd\u6620\u7cfb\u7edf\u5b9e\u9645\u8868\u73b0\u3002", "method": "\u8bbe\u8ba1\u6db5\u76d6\u5927\u8bed\u8a00\u6a21\u578b\u3001\u8bb0\u5fc6\u3001\u5de5\u5177\u548c\u73af\u5883\u56db\u4e2a\u8bc4\u4f30\u652f\u67f1\u7684\u7efc\u5408\u8bc4\u4f30\u6846\u67b6\uff0c\u5e76\u5728\u81ea\u52a8\u5316\u4e91\u8fd0\u7ef4\u6848\u4f8b\u4e2d\u8fdb\u884c\u4e86\u9a8c\u8bc1\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u4f20\u7edf\u6307\u6807\u672a\u80fd\u6355\u6349\u5230\u7684\u884c\u4e3a\u504f\u5dee\uff0c\u65b0\u6846\u67b6\u6709\u6548\u53cd\u6620\u4e86\u8fd0\u884c\u65f6\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u8bc4\u4f30\u7cbe\u5ea6\uff0c\u4e3a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.11816", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.11816", "abs": "https://arxiv.org/abs/2512.11816", "authors": ["Enes \u00d6zeren", "Matthias A\u00dfenmacher"], "title": "Reinforcement Learning for Latent-Space Thinking in LLMs", "comment": "16 pages, 16 figures, 7 tables", "summary": "Chain-of-Thought (CoT) reasoning typically utilizes the discrete language space for thinking, which is inherently inefficient, as many generated tokens only enforce linguistic rules that are not required for reasoning. To bypass this, latent-space thinking allows models to think using the continuous embedding space. While existing methods for training those models show domain-specific gains, they fail to maintain performance in complex tasks, such as mathematical reasoning. We experimentally demonstrate that the Coconut approach, a form of supervised fine-tuning for latent-space thinking, is highly sensitive to design choices and exhibits several inherent limitations. To address these issues, we investigate reinforcement learning (RL) techniques -- an underexplored direction in latent-space thinking -- including GRPO and design a novel Latent RL method for directly optimizing the latent thinking steps. Our experimental results reveal that these RL-trained models still lag behind traditional language-space CoT models in the mathematical reasoning domain. We make our codebase publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6f5c\u5728\u7a7a\u95f4\u7684\u94fe\u5f0f\u601d\u7ef4\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u6f5c\u5728\u601d\u7ef4\u6b65\u9aa4\uff0c\u4ee5\u63d0\u5347\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u4f20\u7edf\u7684\u94fe\u5f0f\u601d\u7ef4\u591a\u57fa\u4e8e\u79bb\u6563\u8bed\u8a00\u7a7a\u95f4\uff0c\u6548\u7387\u4f4e\u4e14\u751f\u6210\u7684\u8bb8\u591a\u7b26\u53f7\u4ec5\u9075\u5faa\u8bed\u8a00\u89c4\u5219\uff0c\u5bf9\u63a8\u7406\u65e0\u5b9e\u9645\u5e2e\u52a9\uff0c\u6f5c\u5728\u7a7a\u95f4\u601d\u7ef4\u4ee5\u8fde\u7eed\u5d4c\u5165\u7a7a\u95f4\u601d\u8003\uff0c\u6709\u671b\u63d0\u9ad8\u6548\u7387\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u8868\u73b0\u4e0d\u8db3\u3002", "method": "\u7814\u7a76\u73b0\u6709\u7684\u76d1\u7763\u5fae\u8c03\u6f5c\u5728\u7a7a\u95f4\u601d\u7ef4\u65b9\u6cd5\uff08\u5982Coconut\uff09\u7684\u5c40\u9650\uff0c\u8fdb\u4e00\u6b65\u63a2\u7d22\u5f3a\u5316\u5b66\u4e60\u6280\u672f\uff08\u5982GRPO\uff09\uff0c\u8bbe\u8ba1\u65b0\u9896\u7684\u6f5c\u5728\u7a7a\u95f4\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u76f4\u63a5\u4f18\u5316\u6f5c\u5728\u601d\u7ef4\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u4ecd\u900a\u8272\u4e8e\u4f20\u7edf\u57fa\u4e8e\u8bed\u8a00\u7a7a\u95f4\u7684\u94fe\u5f0f\u601d\u7ef4\u6a21\u578b\uff0c\u63ed\u793a\u6f5c\u5728\u7a7a\u95f4\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u6311\u6218\u3002", "conclusion": "\u867d\u7136\u6f5c\u5728\u7a7a\u95f4\u601d\u7ef4\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u662f\u6f5c\u5728\u7684\u65b9\u5411\uff0c\u4f46\u5f53\u524d\u65b9\u6cd5\u5728\u590d\u6742\u4efb\u52a1\u4e0a\u4ecd\u96be\u4ee5\u8d85\u8d8a\u4f20\u7edf\u8bed\u8a00\u7a7a\u95f4\u94fe\u5f0f\u601d\u7ef4\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u516c\u5f00\u4e86\u4ee3\u7801\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2512.12024", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.12024", "abs": "https://arxiv.org/abs/2512.12024", "authors": ["Nuno Macedo", "Hugo Pacheco"], "title": "Hyper model checking for high-level relational models", "comment": null, "summary": "Many properties related to security or concurrency must be encoded as so-called hyperproperties, temporal properties that allow reasoning about multiple traces of a system. However, despite recent advances on model checking hyperproperties, there is still a lack of higher-level specification languages that can effectively support software engineering practitioners in verifying properties of this class at early stages of system design.\n  Alloy is a lightweight formal method with a high-level specification language that is supported by automated analysis procedures, making it particularly well-suited for the verification of design models at early development stages. It does not natively support, however, the verification of hyperproperties.\n  This work proposes HyperPardinus, a new model finding procedure that extends Pardinus -- the temporal logic backend of the Alloy language -- to automatically verify hyperproperties over relational models by relying on existing low-level model checkers for hyperproperties. It then conservatively extends Alloy to support the specification and automatic verification of hyperproperties over design models, as well as the visualization of (counter-)examples at a higher-level of abstraction. Evaluation shows that our approach enables modeling and finding (counter-)examples for complex hyperproperties with alternating quantifiers, making it feasible to address relevant scenarios from the state of the art.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HyperPardinus\uff0c\u4e00\u79cd\u6269\u5c55Alloy\u7684\u6a21\u578b\u67e5\u627e\u5de5\u5177\uff0c\u652f\u6301\u81ea\u52a8\u9a8c\u8bc1\u8bbe\u8ba1\u6a21\u578b\u4e2d\u7684\u8d85\u6027\u8d28\uff0c\u89e3\u51b3\u4e86\u9ad8\u5c42\u6b21\u89c4\u683c\u8bed\u8a00\u5bf9\u8d85\u6027\u8d28\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u7684\u9ad8\u5c42\u6b21\u89c4\u683c\u8bed\u8a00\u96be\u4ee5\u6709\u6548\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5728\u7cfb\u7edf\u8bbe\u8ba1\u65e9\u671f\u9a8c\u8bc1\u8d85\u6027\u8d28\uff0c\u800cAlloy\u867d\u9002\u5408\u65e9\u671f\u8bbe\u8ba1\u9a8c\u8bc1\uff0c\u4f46\u4e0d\u652f\u6301\u8d85\u6027\u8d28\u3002", "method": "\u63d0\u51faHyperPardinus\uff0c\u6269\u5c55Pardinus\u4f7f\u5176\u81ea\u52a8\u9a8c\u8bc1\u5173\u7cfb\u6a21\u578b\u4e0a\u7684\u8d85\u6027\u8d28\uff0c\u4fdd\u5b88\u6269\u5c55Alloy\u4ee5\u652f\u6301\u8d85\u6027\u8d28\u7684\u89c4\u683c\u548c\u81ea\u52a8\u9a8c\u8bc1\uff0c\u5e76\u63d0\u4f9b\u9ad8\u5c42\u6b21\u53cd\u4f8b\u53ef\u89c6\u5316\u3002", "result": "\u65b9\u6cd5\u80fd\u5904\u7406\u5177\u6709\u4ea4\u66ff\u91cf\u8bcd\u7684\u590d\u6742\u8d85\u6027\u8d28\uff0c\u6210\u529f\u8fdb\u884c\u5efa\u6a21\u548c\u53cd\u4f8b\u67e5\u627e\uff0c\u9a8c\u8bc1\u4e86\u5e94\u5bf9\u590d\u6742\u73b0\u5b9e\u573a\u666f\u7684\u53ef\u884c\u6027\u3002", "conclusion": "HyperPardinus\u6709\u6548\u586b\u8865\u4e86Alloy\u5728\u8d85\u6027\u8d28\u9a8c\u8bc1\u4e0a\u7684\u7a7a\u767d\uff0c\u4fc3\u8fdb\u9ad8\u5c42\u89c4\u683c\u8bed\u8a00\u5728\u7cfb\u7edf\u8bbe\u8ba1\u65e9\u671f\u7684\u9a8c\u8bc1\u5e94\u7528\u3002"}}
{"id": "2512.12989", "categories": ["cs.MA", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.12989", "abs": "https://arxiv.org/abs/2512.12989", "authors": ["Abdulmalik Alquwayfili"], "title": "Quantigence: A Multi-Agent AI Framework for Quantum Security Research", "comment": "13 pages, 2 figures", "summary": "Cryptographically Relevant Quantum Computers (CRQCs) pose a structural threat to the global digital economy. Algorithms like Shor's factoring and Grover's search threaten to dismantle the public-key infrastructure (PKI) securing sovereign communications and financial transactions. While the timeline for fault-tolerant CRQCs remains probabilistic, the \"Store-Now, Decrypt-Later\" (SNDL) model necessitates immediate migration to Post-Quantum Cryptography (PQC). This transition is hindered by the velocity of research, evolving NIST standards, and heterogeneous deployment environments. To address this, we present Quantigence, a theory-driven multi-agent AI framework for structured quantum-security analysis. Quantigence decomposes research objectives into specialized roles - Cryptographic Analyst, Threat Modeler, Standards Specialist, and Risk Assessor - coordinated by a supervisory agent. Using \"cognitive parallelism,\" agents reason independently to maintain context purity while execution is serialized on resource-constrained hardware (e.g., NVIDIA RTX 2060). The framework integrates external knowledge via the Model Context Protocol (MCP) and prioritizes vulnerabilities using the Quantum-Adjusted Risk Score (QARS), a formal extension of Mosca's Theorem. Empirical validation shows Quantigence achieves a 67% reduction in research turnaround time and superior literature coverage compared to manual workflows, democratizing access to high-fidelity quantum risk assessment.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86Quantigence\uff0c\u4e00\u4e2a\u591a\u667a\u80fd\u4f53AI\u6846\u67b6\uff0c\u7528\u4e8e\u7ed3\u6784\u5316\u7684\u91cf\u5b50\u5b89\u5168\u5206\u6790\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u7814\u7a76\u6548\u7387\u548c\u8986\u76d6\u8303\u56f4\u3002", "motivation": "\u968f\u7740\u5bc6\u7801\u5b66\u76f8\u5173\u91cf\u5b50\u8ba1\u7b97\u673a\uff08CRQCs\uff09\u7684\u5a01\u80c1\u65e5\u76ca\u660e\u6717\uff0c\u73b0\u6709\u516c\u94a5\u57fa\u7840\u8bbe\u65bd\u9762\u4e34\u5b89\u5168\u98ce\u9669\uff0c\u6025\u9700\u8fc1\u79fb\u81f3\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\uff0c\u4f46\u7814\u7a76\u901f\u5ea6\u5feb\u3001\u6807\u51c6\u4e0d\u65ad\u6f14\u53d8\uff0c\u4e14\u90e8\u7f72\u73af\u5883\u590d\u6742\uff0c\u5bfc\u81f4\u8fc7\u6e21\u56f0\u96be\u3002", "method": "Quantigence\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5206\u5de5\uff08\u5bc6\u7801\u5206\u6790\u5e08\u3001\u5a01\u80c1\u5efa\u6a21\u8005\u3001\u6807\u51c6\u4e13\u5bb6\u548c\u98ce\u9669\u8bc4\u4f30\u8005\uff09\u534f\u540c\u5de5\u4f5c\uff0c\u501f\u52a9\u8ba4\u77e5\u5e76\u884c\u4fdd\u6301\u5404\u89d2\u8272\u72ec\u7acb\u63a8\u7406\uff0c\u7ed3\u5408\u5916\u90e8\u77e5\u8bc6\u548c\u65b0\u578b\u91cf\u5b50\u98ce\u9669\u8bc4\u5206\uff08QARS\uff09\u5b9e\u73b0\u7cfb\u7edf\u5316\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eQuantigence\u80fd\u591f\u5c06\u7814\u7a76\u5468\u8f6c\u65f6\u95f4\u7f29\u77ed67%\uff0c\u4e14\u5728\u6587\u732e\u8986\u76d6\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u624b\u5de5\u6d41\u7a0b\u3002", "conclusion": "Quantigence\u6709\u6548\u63a8\u52a8\u4e86\u9ad8\u7cbe\u5ea6\u91cf\u5b50\u98ce\u9669\u8bc4\u4f30\u7684\u6c11\u4e3b\u5316\uff0c\u4e3a\u52a0\u901f\u540e\u91cf\u5b50\u5b89\u5168\u6280\u672f\u7684\u7814\u53d1\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u529b\u652f\u6491\u3002"}}
{"id": "2512.11849", "categories": ["cs.CL", "cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.11849", "abs": "https://arxiv.org/abs/2512.11849", "authors": ["Nimol Thuon", "Jun Du"], "title": "KH-FUNSD: A Hierarchical and Fine-Grained Layout Analysis Dataset for Low-Resource Khmer Business Document", "comment": null, "summary": "Automated document layout analysis remains a major challenge for low-resource, non-Latin scripts. Khmer is a language spoken daily by over 17 million people in Cambodia, receiving little attention in the development of document AI tools. The lack of dedicated resources is particularly acute for business documents, which are critical for both public administration and private enterprise. To address this gap, we present \\textbf{KH-FUNSD}, the first publicly available, hierarchically annotated dataset for Khmer form document understanding, including receipts, invoices, and quotations. Our annotation framework features a three-level design: (1) region detection that divides each document into core zones such as header, form field, and footer; (2) FUNSD-style annotation that distinguishes questions, answers, headers, and other key entities, together with their relationships; and (3) fine-grained classification that assigns specific semantic roles, such as field labels, values, headers, footers, and symbols. This multi-level approach supports both comprehensive layout analysis and precise information extraction. We benchmark several leading models, providing the first set of baseline results for Khmer business documents, and discuss the distinct challenges posed by non-Latin, low-resource scripts. The KH-FUNSD dataset and documentation will be available at URL.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u9996\u4e2a\u7528\u4e8e\u9ad8\u68c9\u8bed\u5546\u4e1a\u6587\u6863\u7406\u89e3\u7684\u5c42\u7ea7\u6807\u6ce8\u6570\u636e\u96c6KH-FUNSD\uff0c\u652f\u6301\u591a\u5c42\u6b21\u6587\u6863\u7248\u9762\u5206\u6790\u4e0e\u4fe1\u606f\u63d0\u53d6\u3002", "motivation": "\u5f53\u524d\u4f4e\u8d44\u6e90\u7684\u975e\u62c9\u4e01\u6587\u5b57\u6587\u6863\u7248\u9762\u5206\u6790\u5b58\u5728\u6311\u6218\uff0c\u9ad8\u68c9\u8bed\u5c24\u5176\u7f3a\u4e4f\u76f8\u5173\u8d44\u6e90\uff0c\u5546\u4e1a\u6587\u6863\u4f5c\u4e3a\u5173\u952e\u6587\u6863\u7c7b\u578b\u4e9f\u9700\u4e13\u7528\u6570\u636e\u652f\u6301\u3002", "method": "\u6784\u5efaKH-FUNSD\u6570\u636e\u96c6\uff0c\u91c7\u7528\u4e09\u7ea7\u6807\u6ce8\u4f53\u7cfb\uff0c\u5305\u62ec\u533a\u57df\u68c0\u6d4b\uff08\u9875\u7709\u3001\u8868\u5355\u5b57\u6bb5\u3001\u9875\u811a\uff09\u3001FUNSD\u98ce\u683c\u5b9e\u4f53\u8bc6\u522b\u53ca\u5173\u7cfb\u6807\u6ce8\u3001\u7ec6\u7c92\u5ea6\u8bed\u4e49\u89d2\u8272\u5206\u7c7b\uff0c\u5b9e\u73b0\u7efc\u5408\u7248\u9762\u5206\u6790\u4e0e\u4fe1\u606f\u63d0\u53d6\u3002", "result": "\u63d0\u4f9b\u591a\u79cd\u9886\u5148\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u662f\u9996\u4e2a\u9488\u5bf9\u9ad8\u68c9\u8bed\u5546\u4e1a\u6587\u6863\u7684\u57fa\u7ebf\u7ed3\u679c\uff0c\u63ed\u793a\u975e\u62c9\u4e01\u4f4e\u8d44\u6e90\u8bed\u8a00\u6587\u6863\u5904\u7406\u7684\u72ec\u7279\u96be\u70b9\u3002", "conclusion": "KH-FUNSD\u586b\u8865\u4e86\u9ad8\u68c9\u8bed\u5546\u4e1a\u6587\u6863AI\u5de5\u5177\u7684\u8d44\u6e90\u7a7a\u767d\uff0c\u63a8\u52a8\u4e86\u975e\u62c9\u4e01\u6587\u5b57\u6587\u6863\u7406\u89e3\u9886\u57df\u7684\u53d1\u5c55\u3002\u6570\u636e\u96c6\u53ca\u76f8\u5173\u6587\u6863\u5c06\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2512.12063", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12063", "abs": "https://arxiv.org/abs/2512.12063", "authors": ["G\u00f6kberk \u00c7elikmasat", "Atay \u00d6zg\u00f6vde", "Fatma Ba\u015fak Aydemir"], "title": "Instruction-Tuning Open-Weight Language Models for BPMN Model Generation", "comment": "Preprint. Under preparation for journal submission", "summary": "Domain models are central to software engineering, as they enable a shared understanding, guide implementation, and support automated analyses and model-driven development. Yet, despite these benefits, practitioners often skip modeling because it is time-consuming and demands scarce expertise. We address this barrier by investigating whether open-weight large language models, adapted via instruction tuning, can generate high-quality BPMN process models directly from natural language descriptions in a cost-effective and privacy-preserving way. We introduce InstruBPM, a reproducible approach that prepares paired text-diagram data and instruction tunes an open source large language model with parameter-efficient fine-tuning and quantization for on-prem deployment. We evaluate the tuned model through complementary perspectives: (i) text/code similarity using BLEU, ROUGE-L, and METEOR, (ii) structural fidelity using Relative Graph Edit Distance, (iii) guidelines conformance using external tool checks, and (iv) a small expert review. Using a curated subset of a multi-domain BPMN dataset, we compare the tuned model with untuned open-weight baselines and strong proprietary models under consistent prompting regimes. Our compact tuned model outperforms all baselines across sequence and structural metrics while requiring substantially fewer resources; guideline analysis and expert feedback further indicate that the generated diagrams largely follow BPMN best practices and are useful starting points that reduce modeling effort. Overall, instruction tuning improves structural accuracy and robustness compared to untuned baselines and reduces reliance on heavy prompt scaffolding. We publicly share the trained models and scripts to support reproducibility and further research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86InstruBPM\uff0c\u4e00\u79cd\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u81ea\u52a8\u4ece\u81ea\u7136\u8bed\u8a00\u751f\u6210\u9ad8\u8d28\u91cfBPMN\u6d41\u7a0b\u6a21\u578b\u7684\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u9886\u57df\u5efa\u6a21\u867d\u6709\u8bf8\u591a\u4f18\u52bf\uff0c\u4f46\u56e0\u8017\u65f6\u4e14\u9700\u4e13\u4e1a\u6280\u80fd\uff0c\u5b9e\u8df5\u4e2d\u5e38\u88ab\u5ffd\u89c6\u3002\u672c\u6587\u8bd5\u56fe\u7528\u9ad8\u6548\u3001\u9690\u79c1\u53cb\u597d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u6d41\u7a0b\u6a21\u578b\uff0c\u964d\u4f4e\u5efa\u6a21\u95e8\u69db\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u6587\u672c-\u56fe\u8868\u914d\u5bf9\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u4e0e\u91cf\u5316\u6280\u672f\uff0c\u5bf9\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6307\u4ee4\u5fae\u8c03\uff0c\u5b9e\u73b0\u672c\u5730\u90e8\u7f72\uff1b\u5e76\u4ece\u6587\u672c\u76f8\u4f3c\u5ea6\u3001\u7ed3\u6784\u4e00\u81f4\u6027\u3001\u89c4\u8303\u7b26\u5408\u5ea6\u548c\u4e13\u5bb6\u8bc4\u5ba1\u56db\u65b9\u9762\u8bc4\u4f30\u6a21\u578b\u3002", "result": "\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u5404\u9879\u5e8f\u5217\u548c\u7ed3\u6784\u6307\u6807\u4e0a\u5747\u8d85\u8d8a\u672a\u8c03\u4f18\u7684\u5f00\u6e90\u57fa\u7ebf\u548c\u5f3a\u5927\u7684\u4e13\u6709\u6a21\u578b\uff0c\u751f\u6210\u7684\u6d41\u7a0b\u56fe\u5927\u4f53\u7b26\u5408BPMN\u6700\u4f73\u5b9e\u8df5\uff0c\u5e76\u663e\u8457\u51cf\u5c11\u5efa\u6a21\u5de5\u4f5c\u91cf\u3002", "conclusion": "\u6307\u4ee4\u5fae\u8c03\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u7684\u7ed3\u6784\u51c6\u786e\u6027\u4e0e\u9c81\u68d2\u6027\uff0c\u964d\u4f4e\u4e86\u5bf9\u590d\u6742\u63d0\u793a\u7684\u4f9d\u8d56\uff0c\u4e14\u5b9e\u73b0\u4e86\u8d44\u6e90\u53cb\u597d\u548c\u9690\u79c1\u4fdd\u62a4\uff0c\u7814\u7a76\u6210\u679c\u53ca\u4ee3\u7801\u5df2\u516c\u5f00\uff0c\u652f\u6301\u590d\u73b0\u4e0e\u62d3\u5c55\u7814\u7a76\u3002"}}
{"id": "2512.13056", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2512.13056", "abs": "https://arxiv.org/abs/2512.13056", "authors": ["Chen Huang", "Ronghui Hou"], "title": "The Optimal Control Algorithm of Connected and Automated Vehicles at Roundabouts with Communication Delay", "comment": "9 pages, 4 figures", "summary": "Connected and automated vehicles (CAVs) rely on wireless communication to exchange state information for distributed control, making communication delays a critical factor that can affect vehicle motion and degrade control performance, particularly in high-speed scenarios. To address these challenges in the complex environment of roundabout intersections, this paper proposes a roundabout control algorithm, which takes into account the uncertainty of interactive information caused by time delays. First, to maintain the required distance between the current vehicle and its preceding and following vehicles, conflicting vehicles are identified based on the time-to-collision (TTC) in the conflict zone. To fully consider communication performance, a vehicle motion model incorporating time delays is established. According to the distributed model predictive control (DMPC) mechanism, the vehicle motion control that satisfies the roundabout constraints is determined. Second, by scheduling the sequence of vehicles entering the roundabout, a multiscale optimization objective is developed by integrating vehicle motion indicators and roundabout system indicators. Traffic density and travel time are embedded into the optimization problem to guide vehicles to enter the roundabout safely and stably. Through a variety of simulation experiments, the effectiveness of the proposed control algorithm is verified by comparing its performance with that of multiple control algorithms under different autonomous vehicle penetration rates and heavy traffic load scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u65f6\u95f4\u5ef6\u8fdf\u548c\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u7684\u73af\u5c9b\u4ea4\u4e92\u63a7\u5236\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u548c\u591a\u5c3a\u5ea6\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u8f66\u8f86\u5b89\u5168\u7a33\u5b9a\u8fdb\u5165\u73af\u5c9b\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u4f9d\u8d56\u65e0\u7ebf\u901a\u4fe1\u8fdb\u884c\u5206\u5e03\u5f0f\u63a7\u5236\uff0c\u901a\u4fe1\u5ef6\u8fdf\u4f1a\u5f71\u54cd\u8f66\u8f86\u8fd0\u52a8\u548c\u63a7\u5236\u6027\u80fd\uff0c\u5c24\u5176\u662f\u5728\u9ad8\u901f\u5ea6\u548c\u590d\u6742\u8def\u53e3\uff08\u5982\u73af\u5c9b\uff09\u73af\u5883\u4e0b\u3002", "method": "\u672c\u6587\u57fa\u4e8e\u8f66\u8f86\u95f4\u78b0\u649e\u65f6\u95f4(TTC)\u8bc6\u522b\u51b2\u7a81\u8f66\u8f86\uff0c\u5efa\u7acb\u5305\u542b\u65f6\u95f4\u5ef6\u8fdf\u7684\u8f66\u8f86\u8fd0\u52a8\u6a21\u578b\uff0c\u91c7\u7528\u5206\u5e03\u5f0f\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u786e\u5b9a\u8fd0\u52a8\u63a7\u5236\uff0c\u5e76\u901a\u8fc7\u8c03\u5ea6\u8f66\u8f86\u8fdb\u5165\u73af\u5c9b\u7684\u987a\u5e8f\uff0c\u6784\u5efa\u878d\u5408\u8f66\u8f86\u6307\u6807\u4e0e\u7cfb\u7edf\u6307\u6807\u7684\u591a\u5c3a\u5ea6\u4f18\u5316\u76ee\u6807\uff0c\u5d4c\u5165\u4ea4\u901a\u5bc6\u5ea6\u548c\u884c\u7a0b\u65f6\u95f4\u4ee5\u4fdd\u8bc1\u5b89\u5168\u7a33\u5b9a\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u4eff\u771f\u5b9e\u9a8c\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u63a7\u5236\u7b97\u6cd5\u5728\u4e0d\u540c\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u6e17\u900f\u7387\u548c\u4ea4\u901a\u8d1f\u8377\u573a\u666f\u4e0b\uff0c\u76f8\u8f83\u591a\u79cd\u63a7\u5236\u7b97\u6cd5\u7684\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u63a7\u5236\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73af\u5c9b\u73af\u5883\u4e2d\u7531\u65f6\u95f4\u5ef6\u8fdf\u5f15\u8d77\u7684\u4fe1\u606f\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8f66\u8f86\u7684\u5b89\u5168\u3001\u7a33\u5b9a\u8fd0\u884c\uff0c\u63d0\u5347\u4e86\u73af\u5c9b\u7684\u6574\u4f53\u4ea4\u901a\u6548\u7387\u548c\u63a7\u5236\u6027\u80fd\u3002"}}
{"id": "2512.11998", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.11998", "abs": "https://arxiv.org/abs/2512.11998", "authors": ["Glenn Zhang", "Treasure Mayowa", "Jason Fan", "Yicheng Fu", "Aaron Sandoval", "Sean O'Brien", "Kevin Zhu"], "title": "Direct Confidence Alignment: Aligning Verbalized Confidence with Internal Confidence In Large Language Models", "comment": "Accepted at ACL 2025 SRW, 5 pages body, 14 pages total", "summary": "Producing trustworthy and reliable Large Language Models (LLMs) has become increasingly important as their usage becomes more widespread. Calibration seeks to achieve this by improving the alignment between the model's confidence and the actual likelihood of its responses being correct or desirable. However, it has been observed that the internal confidence of a model, derived from token probabilities, is not well aligned with its verbalized confidence, leading to misleading results with different calibration methods. In this paper, we propose Direct Confidence Alignment (DCA), a method using Direct Preference Optimization to align an LLM's verbalized confidence with its internal confidence rather than ground-truth accuracy, enhancing model transparency and reliability by ensuring closer alignment between the two confidence measures. We evaluate DCA across multiple open-weight LLMs on a wide range of datasets. To further assess this alignment, we also introduce three new calibration error-based metrics. Our results show that DCA improves alignment metrics on certain model architectures, reducing inconsistencies in a model's confidence expression. However, we also show that it can be ineffective on others, highlighting the need for more model-aware approaches in the pursuit of more interpretable and trustworthy LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u76f4\u63a5\u7f6e\u4fe1\u5ea6\u5bf9\u9f50\uff08DCA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53e3\u5934\u7f6e\u4fe1\u5ea6\u4e0e\u5185\u90e8\u7f6e\u4fe1\u5ea6\u66f4\u597d\u5730\u5bf9\u9f50\uff0c\u63d0\u5347\u6a21\u578b\u7684\u900f\u660e\u6027\u548c\u53ef\u9760\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDCA\u5728\u90e8\u5206\u6a21\u578b\u67b6\u6784\u4e0a\u63d0\u5347\u4e86\u5bf9\u9f50\u6548\u679c\uff0c\u4f46\u5728\u5176\u4ed6\u6a21\u578b\u4e0a\u6548\u679c\u6709\u9650\uff0c\u63d0\u793a\u4e86\u6a21\u578b\u611f\u77e5\u65b9\u6cd5\u7684\u5fc5\u8981\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u90e8\u7f6e\u4fe1\u5ea6\u4e0e\u5176\u53e3\u5934\u8868\u8fbe\u7684\u7f6e\u4fe1\u5ea6\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u6821\u51c6\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u5f71\u54cd\u6a21\u578b\u7684\u53ef\u9760\u6027\u548c\u53ef\u4fe1\u5ea6\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u76f4\u63a5\u504f\u597d\u4f18\u5316\u7684\u76f4\u63a5\u7f6e\u4fe1\u5ea6\u5bf9\u9f50\uff08DCA\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u9f50\u6a21\u578b\u7684\u53e3\u5934\u7f6e\u4fe1\u5ea6\u4e0e\u5185\u90e8\u7f6e\u4fe1\u5ea6\uff0c\u800c\u975e\u4e0e\u771f\u5b9e\u51c6\u786e\u7387\u5bf9\u9f50\uff0c\u63d0\u5347\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u7684\u4e00\u81f4\u6027\u3002\u8fd8\u5f15\u5165\u4e86\u4e09\u79cd\u65b0\u7684\u57fa\u4e8e\u6821\u51c6\u8bef\u5dee\u7684\u8bc4\u4ef7\u6307\u6807\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u6743\u91cd\u5927\u8bed\u8a00\u6a21\u578b\u548c\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0cDCA\u5728\u67d0\u4e9b\u6a21\u578b\u67b6\u6784\u4e0a\u663e\u8457\u6539\u5584\u4e86\u7f6e\u4fe1\u5ea6\u7684\u5bf9\u9f50\u6307\u6807\uff0c\u51cf\u5c11\u4e86\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u7684\u4e0d\u4e00\u81f4\uff0c\u4f46\u5728\u90e8\u5206\u6a21\u578b\u4e0a\u6548\u679c\u8f83\u5dee\u3002", "conclusion": "DCA\u65b9\u6cd5\u80fd\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u63d0\u5347\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8868\u8fbe\u7684\u4e00\u81f4\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4f46\u5176\u6548\u679c\u53d7\u6a21\u578b\u67b6\u6784\u9650\u5236\uff0c\u672a\u6765\u9700\u63a2\u7d22\u66f4\u5177\u6a21\u578b\u611f\u77e5\u6027\u7684\u6821\u51c6\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u66f4\u53ef\u4fe1\u8d56\u7684\u8bed\u8a00\u6a21\u578b\u3002"}}
{"id": "2512.12117", "categories": ["cs.SE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12117", "abs": "https://arxiv.org/abs/2512.12117", "authors": ["Jahidul Arafat"], "title": "Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context", "comment": null, "summary": "Large language models have become essential tools for code comprehension, enabling developers to query unfamiliar codebases through natural language interfaces. However, LLM hallucination, generating plausible but factually incorrect citations to source code, remains a critical barrier to reliable developer assistance. This paper addresses the challenges of achieving verifiable, citation grounded code comprehension through hybrid retrieval and lightweight structural reasoning. Our work is grounded in systematic evaluation across 30 Python repositories with 180 developer queries, comparing retrieval modalities, graph expansion strategies, and citation verification mechanisms. We find that challenges of citation accuracy arise from the interplay between sparse lexical matching, dense semantic similarity, and cross file architectural dependencies. Among these, cross file evidence discovery is the largest contributor to citation completeness, but it is largely overlooked because existing systems rely on pure textual similarity without leveraging code structure. We advocate for citation grounded generation as an architectural principle for code comprehension systems and demonstrate this need by achieving 92 percent citation accuracy with zero hallucinations. Specifically, we develop a hybrid retrieval system combining BM25 sparse matching, BGE dense embeddings, and Neo4j graph expansion via import relationships, which outperforms single mode baselines by 14 to 18 percentage points while discovering cross file evidence missed by pure text similarity in 62 percent of architectural queries.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u4e2d\u4ea7\u751f\u4e8b\u5b9e\u9519\u8bef\u5f15\u7528\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u7ed3\u5408\u6df7\u5408\u68c0\u7d22\u548c\u7ed3\u6784\u63a8\u7406\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e8692%\u7684\u5f15\u7528\u51c6\u786e\u7387\uff0c\u65e0\u865a\u6784\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u7406\u89e3\u65f6\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u751f\u6210\u4e0d\u51c6\u786e\u7684\u4ee3\u7801\u5f15\u7528\uff0c\u5f71\u54cd\u5f00\u53d1\u8005\u7684\u4fe1\u4efb\u548c\u4f7f\u7528\u6548\u679c\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u79cd\u6df7\u5408\u68c0\u7d22\u7cfb\u7edf\uff0c\u7ed3\u5408BM25\u7a00\u758f\u5339\u914d\u3001BGE\u7a20\u5bc6\u5d4c\u5165\u548c\u57fa\u4e8e\u5bfc\u5165\u5173\u7cfb\u7684Neo4j\u56fe\u6269\u5c55\uff0c\u5229\u7528\u8de8\u6587\u4ef6\u7ed3\u6784\u4fe1\u606f\uff0c\u63d0\u9ad8\u4ee3\u7801\u5f15\u7528\u7684\u51c6\u786e\u6027\u3002", "result": "\u7ecf\u572830\u4e2aPython\u4ee3\u7801\u5e93\u548c180\u4e2a\u5f00\u53d1\u8005\u67e5\u8be2\u4e0a\u7cfb\u7edf\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u5728\u5f15\u7528\u51c6\u786e\u7387\u4e0a\u8d85\u8fc7\u5355\u4e00\u68c0\u7d22\u65b9\u5f0f14-18\u4e2a\u767e\u5206\u70b9\uff0c\u572862%\u7684\u67b6\u6784\u67e5\u8be2\u4e2d\u53d1\u73b0\u7eaf\u6587\u672c\u76f8\u4f3c\u6027\u9057\u6f0f\u7684\u8de8\u6587\u4ef6\u8bc1\u636e\uff0c\u8fbe\u523092%\u7684\u51c6\u786e\u7387\u4e14\u65e0\u865a\u6784\u3002", "conclusion": "\u91c7\u7528\u57fa\u4e8e\u5f15\u7528\u7684\u751f\u6210\u65b9\u5f0f\uff0c\u7ed3\u5408\u7ed3\u6784\u63a8\u7406\u548c\u6df7\u5408\u68c0\u7d22\uff0c\u662f\u63d0\u5347\u4ee3\u7801\u7406\u89e3\u7cfb\u7edf\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u7684\u6709\u6548\u67b6\u6784\u539f\u5219\u3002"}}
{"id": "2512.12008", "categories": ["cs.CL", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.12008", "abs": "https://arxiv.org/abs/2512.12008", "authors": ["Minghui Liu", "Aadi Palnitkar", "Tahseen Rabbani", "Hyunwoo Jae", "Kyle Rui Sang", "Dixi Yao", "Shayan Shabihi", "Fuheng Zhao", "Tian Li", "Ce Zhang", "Furong Huang", "Kunpeng Zhang"], "title": "Hold Onto That Thought: Assessing KV Cache Compression On Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated remarkable performance on long-context tasks, but are often bottlenecked by memory constraints. Namely, the KV cache, which is used to significantly speed up attention computations, grows linearly with context length. A suite of compression algorithms has been introduced to alleviate cache growth by evicting unimportant tokens. However, several popular strategies are targeted towards the prefill phase, i.e., processing long prompt context, and their performance is rarely assessed on reasoning tasks requiring long decoding. In particular, short but complex prompts, such as those in benchmarks like GSM8K and MATH500, often benefit from multi-step reasoning and self-reflection, resulting in thinking sequences thousands of tokens long. In this work, we benchmark the performance of several popular compression strategies on long-reasoning tasks. For the non-reasoning Llama-3.1-8B-Instruct, we determine that no singular strategy fits all, and that performance is heavily influenced by dataset type. However, we discover that H2O and our decoding-enabled variant of SnapKV are dominant strategies for reasoning models, indicating the utility of heavy-hitter tracking for reasoning traces. We also find that eviction strategies at low budgets can produce longer reasoning traces, revealing a tradeoff between cache size and inference costs.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u591a\u79cd\u952e\u503c\u7f13\u5b58(KV cache)\u538b\u7f29\u7b56\u7565\u5728\u957f\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0d\u540c\u4efb\u52a1\u9002\u5408\u4e0d\u540c\u7b56\u7565\uff0c\u5c24\u5176\u662fH2O\u548cSnapKV\u53d8\u4f53\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2dKV\u7f13\u5b58\u56e0\u4e0a\u4e0b\u6587\u957f\u5ea6\u7ebf\u6027\u589e\u957f\u5bfc\u81f4\u5185\u5b58\u74f6\u9888\uff0c\u73b0\u6709\u538b\u7f29\u7b56\u7565\u591a\u9488\u5bf9\u9884\u586b\u5145\u9636\u6bb5\uff0c\u7f3a\u5c11\u5bf9\u957f\u63a8\u7406\u4efb\u52a1\u7684\u8bc4\u4f30\u3002", "method": "\u9488\u5bf9\u591a\u4e2a\u538b\u7f29\u7b56\u7565\u5728\u957f\u63a8\u7406\u4efb\u52a1\u548c\u975e\u63a8\u7406\u4efb\u52a1\u4e0a\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u91cd\u70b9\u5206\u6790\u7f13\u5b58\u5927\u5c0f\u4e0e\u63a8\u7406\u6210\u672c\u7684\u6743\u8861\u3002", "result": "\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u7b56\u7565\u9002\u7528\u4e8e\u6240\u6709\u573a\u666f\uff0c\u6570\u636e\u96c6\u7c7b\u578b\u5f71\u54cd\u663e\u8457\uff1bH2O\u548cSnapKV\u53d8\u4f53\u5728\u63a8\u7406\u6a21\u578b\u4e2d\u8868\u73b0\u6700\u4f73\uff1b\u4f4e\u7f13\u5b58\u9884\u7b97\u4e0b\uff0c\u5254\u9664\u7b56\u7565\u53ef\u652f\u6301\u66f4\u957f\u63a8\u7406\u5e8f\u5217\u3002", "conclusion": "\u91cd\u51fb\u8ddf\u8e2a\u7b56\u7565\u6709\u52a9\u4e8e\u63d0\u5347\u63a8\u7406\u4efb\u52a1\u7684KV\u7f13\u5b58\u7ba1\u7406\u6548\u679c\uff0c\u5b58\u5728\u7f13\u5b58\u5927\u5c0f\u4e0e\u63a8\u7406\u6210\u672c\u7684\u6743\u8861\uff0c\u9700\u8981\u6839\u636e\u4efb\u52a1\u7279\u6027\u9009\u62e9\u5408\u9002\u7684\u538b\u7f29\u7b56\u7565\u3002"}}
{"id": "2512.12216", "categories": ["cs.SE", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12216", "abs": "https://arxiv.org/abs/2512.12216", "authors": ["Yiqi Zhu", "Apurva Gandhi", "Graham Neubig"], "title": "Training Versatile Coding Agents in Synthetic Environments", "comment": null, "summary": "Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.", "AI": {"tldr": "\u63d0\u51fa\u4e86SWE-Playground\uff0c\u4e00\u79cd\u901a\u8fc7\u5408\u6210\u751f\u6210\u9879\u76ee\u548c\u4efb\u52a1\u6765\u8bad\u7ec3\u591a\u529f\u80fd\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u65b9\u6cd5\uff0c\u7a81\u7834\u4e86\u4f9d\u8d56\u5df2\u6709GitHub\u8d44\u6e90\u548c\u4efb\u52a1\u5355\u4e00\u6027\u7684\u9650\u5236\u3002", "motivation": "\u73b0\u6709\u8bad\u7ec3\u8f6f\u4ef6\u5de5\u7a0b\u667a\u80fd\u4f53\u7684\u65b9\u6cd5\u4f9d\u8d56\u9884\u5148\u5b58\u5728\u7684GitHub\u4ed3\u5e93\u8d44\u6e90\uff0c\u7075\u6d3b\u6027\u4e0d\u8db3\u4e14\u4e3b\u8981\u96c6\u4e2d\u5728\u89e3\u51b3\u95ee\u9898\u4efb\u52a1\uff0c\u65e0\u6cd5\u8986\u76d6\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u9700\u8981\u5904\u7406\u7684\u591a\u79cd\u4efb\u52a1\u3002", "method": "\u8bbe\u8ba1\u4e86SWE-Playground\u7ba1\u7ebf\uff0c\u5229\u7528\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\u548c\u667a\u80fd\u4f53\u4ece\u96f6\u5408\u6210\u751f\u6210\u9879\u76ee\u548c\u4efb\u52a1\u73af\u5883\uff0c\u652f\u6301\u66f4\u5e7f\u6cdb\u7684\u7f16\u7801\u4efb\u52a1\uff0c\u5305\u62ec\u901a\u8fc7\u751f\u6210\u5355\u5143\u6d4b\u8bd5\u6765\u91cd\u73b0\u95ee\u9898\u548c\u4ece\u5934\u5b9e\u73b0\u5e93\uff0c\u65e0\u9700\u5916\u90e8\u6570\u636e\u4f9d\u8d56\u3002", "result": "\u5728\u4e09\u4e2a\u4e0d\u540c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u751f\u6210\u7684\u8f68\u8ff9\u8bad\u7ec3\u4fe1\u53f7\u5bc6\u96c6\uff0c\u4f7f\u667a\u80fd\u4f53\u4ee5\u8fdc\u5c11\u4e8e\u4ee5\u5f80\u5de5\u4f5c\u7684\u8f68\u8ff9\u6570\u91cf\u8fbe\u5230\u76f8\u4f3c\u6027\u80fd\u3002", "conclusion": "SWE-Playground\u901a\u8fc7\u5408\u6210\u6570\u636e\u6781\u5927\u63d0\u5347\u4e86\u8bad\u7ec3\u7075\u6d3b\u6027\u548c\u4efb\u52a1\u591a\u6837\u6027\uff0c\u6709\u6548\u652f\u6301\u591a\u529f\u80fd\u7f16\u7801\u667a\u80fd\u4f53\u7684\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u3002"}}
{"id": "2512.12042", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12042", "abs": "https://arxiv.org/abs/2512.12042", "authors": ["Philipp Habicht", "Lev Sorokin", "Abdullah Saydemir", "Ken E. Friedl", "Andrea Stocco"], "title": "Benchmarking Contextual Understanding for In-Car Conversational Systems", "comment": null, "summary": "In-Car Conversational Question Answering (ConvQA) systems significantly enhance user experience by enabling seamless voice interactions. However, assessing their accuracy and reliability remains a challenge. This paper explores the use of Large Language Models (LLMs) alongside advanced prompting techniques and agent-based methods to evaluate the extent to which ConvQA system responses adhere to user utterances. The focus lies on contextual understanding and the ability to provide accurate venue recommendations considering user constraints and situational context. To evaluate utterance-response coherence using an LLM, we synthetically generate user utterances accompanied by correct and modified failure-containing system responses. We use input-output, chain-of-thought, self-consistency prompting, and multi-agent prompting techniques with 13 reasoning and non-reasoning LLMs of varying sizes and providers, including OpenAI, DeepSeek, Mistral AI, and Meta. We evaluate our approach on a case study involving restaurant recommendations. The most substantial improvements occur for small non-reasoning models when applying advanced prompting techniques, particularly multi-agent prompting. However, reasoning models consistently outperform non-reasoning models, with the best performance achieved using single-agent prompting with self-consistency. Notably, DeepSeek-R1 reaches an F1-score of 0.99 at a cost of 0.002 USD per request. Overall, the best balance between effectiveness and cost-time efficiency is reached with the non-reasoning model DeepSeek-V3. Our findings show that LLM-based evaluation offers a scalable and accurate alternative to traditional human evaluation for benchmarking contextual understanding in ConvQA systems.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u53ca\u5148\u8fdb\u63d0\u793a\u6280\u672f\u8bc4\u4f30\u8f66\u8f7d\u5bf9\u8bdd\u95ee\u7b54\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\uff0c\u7279\u522b\u5728\u9910\u5385\u63a8\u8350\u7684\u6848\u4f8b\u4e2d\u8bc4\u4f30\u7cfb\u7edf\u5bf9\u7528\u6237\u8bed\u5883\u7684\u7406\u89e3\u4e0e\u54cd\u5e94\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u4eba\u5de5\u8bc4\u4f30\u8f66\u8f7d\u5bf9\u8bdd\u95ee\u7b54\u7cfb\u7edf\u6548\u7387\u4f4e\u4e14\u6210\u672c\u9ad8\uff0c\u9700\u5bfb\u627e\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u51c6\u786e\u7684\u81ea\u52a8\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u5347\u7cfb\u7edf\u54cd\u5e94\u7684\u51c6\u786e\u7387\u548c\u7528\u6237\u4f53\u9a8c\u3002", "method": "\u901a\u8fc7\u5408\u6210\u7528\u6237\u8bed\u53e5\u53ca\u5bf9\u5e94\u6b63\u786e\u548c\u5305\u542b\u9519\u8bef\u7684\u7cfb\u7edf\u54cd\u5e94\uff0c\u91c7\u7528\u8f93\u5165\u8f93\u51fa\u63d0\u793a\u3001\u94fe\u5f0f\u601d\u8003\u3001\u81ea\u6d3d\u63d0\u793a\u53ca\u591a\u667a\u80fd\u4f53\u63d0\u793a\uff0c\u5229\u752813\u79cd\u4e0d\u540c\u89c4\u6a21\u53ca\u5382\u5546\u7684\u63a8\u7406\u4e0e\u975e\u63a8\u7406LLMs\u5bf9\u7cfb\u7edf\u54cd\u5e94\u8fdb\u884c\u4e00\u81f4\u6027\u548c\u51c6\u786e\u6027\u8bc4\u4f30\u3002", "result": "\u591a\u667a\u80fd\u4f53\u63d0\u793a\u6280\u672f\u5728\u5c0f\u578b\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u5e26\u6765\u6700\u5927\u63d0\u5347\uff0c\u63a8\u7406\u6a21\u578b\u666e\u904d\u4f18\u4e8e\u975e\u63a8\u7406\u6a21\u578b\uff0cDeepSeek-R1\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0c\u8fbe\u52300.99\u7684F1\u5206\u6570\u4e14\u8bf7\u6c42\u6210\u672c\u4f4e\u5ec9\uff0c\u7efc\u5408\u6548\u7387\u548c\u6210\u672c\u8868\u73b0\u6700\u4f73\u7684\u662f\u975e\u63a8\u7406\u6a21\u578bDeepSeek-V3\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u8bc4\u4f30\u65b9\u6cd5\u4e3a\u8f66\u8f7d\u5bf9\u8bdd\u95ee\u7b54\u7cfb\u7edf\u7684\u4e0a\u4e0b\u6587\u7406\u89e3\u63d0\u4f9b\u4e86\u9ad8\u6548\u3001\u51c6\u786e\u4e14\u6210\u672c\u6548\u76ca\u4f18\u5f02\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u4f18\u4e8e\u4f20\u7edf\u4eba\u5de5\u8bc4\u4f30\uff0c\u5177\u6709\u826f\u597d\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2512.12224", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.12224", "abs": "https://arxiv.org/abs/2512.12224", "authors": ["Maaz Khan", "Gul Sher Khan", "Ahsan Raza", "Pir Sami Ullah", "Abdul Ali Bangash"], "title": "Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction", "comment": null, "summary": "The increasing use of machine learning (ML) for Just-In-Time (JIT) defect prediction raises concerns about privacy leakage from software analytics data. Existing anonymization methods, such as tabular transformations and graph perturbations, often overlook contextual dependencies among software metrics, leading to suboptimal privacy-utility tradeoffs. Leveraging the contextual reasoning of Large Language Models (LLMs), we propose a cluster-guided anonymization technique that preserves contextual and statistical relationships within JIT datasets. Our method groups commits into feature-based clusters and employs an LLM to generate context-aware parameter configurations for each commit cluster, defining alpha-beta ratios and churn mixture distributions used for anonymization. Our evaluation on six projects (Cassandra, Flink, Groovy, Ignite, OpenStack, and Qt) shows that our LLM-based approach achieves privacy level 2 (IPR >= 80 percent), improving privacy by 18 to 25 percent over four state-of-the-art graph-based anonymization baselines while maintaining comparable F1 scores. Our results demonstrate that LLMs can act as adaptive anonymization engines when provided with cluster-specific statistical information about similar data points, enabling context-sensitive and privacy-preserving software analytics without compromising predictive accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u805a\u7c7b\u5f15\u5bfc\u533f\u540d\u5316\u65b9\u6cd5\uff0c\u7528\u4e8e\u4fdd\u62a4\u8f6f\u4ef6\u7f3a\u9677\u9884\u6d4b\u6570\u636e\u7684\u9690\u79c1\uff0c\u540c\u65f6\u4fdd\u6301\u9884\u6d4b\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u533f\u540d\u5316\u65b9\u6cd5\u5ffd\u7565\u4e86\u8f6f\u4ef6\u5ea6\u91cf\u6307\u6807\u4e4b\u95f4\u7684\u4e0a\u4e0b\u6587\u4f9d\u8d56\uff0c\u5bfc\u81f4\u9690\u79c1\u4e0e\u6570\u636e\u6548\u7528\u4e4b\u95f4\u7684\u6743\u8861\u4e0d\u7406\u60f3\u3002", "method": "\u5229\u7528LLM\u7684\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u5c06\u63d0\u4ea4\u6309\u7279\u5f81\u805a\u7c7b\uff0c\u5e76\u4e3a\u6bcf\u4e2a\u805a\u7c7b\u751f\u6210\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u533f\u540d\u5316\u53c2\u6570\u914d\u7f6e\uff0c\u5b9a\u4e49\u7528\u4e8e\u533f\u540d\u5316\u7684alpha-beta\u6bd4\u7387\u548c\u4ee3\u7801\u53d8\u66f4\u6df7\u5408\u5206\u5e03\u3002", "result": "\u5728\u516d\u4e2a\u5f00\u6e90\u9879\u76ee\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u9690\u79c1\u6c34\u5e73\u8fbe\u5230IPR >= 80%\uff0c\u9690\u79c1\u63d0\u534718%\u81f325%\uff0c\u4e14\u4fdd\u6301\u4e86\u4e0e\u73b0\u6709\u56fe\u533f\u540d\u5316\u65b9\u6cd5\u76f8\u5f53\u7684F1\u5206\u6570\u3002", "conclusion": "\u57fa\u4e8eLLM\u7684\u81ea\u9002\u5e94\u533f\u540d\u5316\u5f15\u64ce\u80fd\u591f\u5728\u4fdd\u7559\u4e0a\u4e0b\u6587\u548c\u7edf\u8ba1\u5173\u7cfb\u7684\u540c\u65f6\uff0c\u6709\u6548\u4fdd\u62a4\u8f6f\u4ef6\u5206\u6790\u6570\u636e\u9690\u79c1\uff0c\u4e14\u4e0d\u635f\u5bb3\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2512.12072", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12072", "abs": "https://arxiv.org/abs/2512.12072", "authors": ["Avinash Amballa", "Yashas Malur Saidutta", "Chi-Heng Lin", "Vivek Kulkarni", "Srinivas Chappidi"], "title": "VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs", "comment": "Arxiv Submission", "summary": "Large language models (LLMs) are increasingly being used to generate synthetic datasets for the evaluation and training of downstream models. However, prior work has noted that such generated data lacks diversity. In this paper, we propose Voyager, a novel principled approach to generate diverse datasets. Our approach is iterative and directly optimizes a mathematical quantity that optimizes the diversity of the dataset using the machinery of determinantal point processes. Furthermore, our approach is training-free, applicable to closed-source models, and scalable. In addition to providing theoretical justification for the working of our method, we also demonstrate through comprehensive experiments that Voyager significantly outperforms popular baseline approaches by providing a 1.5-3x improvement in diversity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Voyager\uff0c\u4e00\u79cd\u57fa\u4e8e\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u7684\u8fed\u4ee3\u65b9\u6cd5\uff0c\u7528\u4e8e\u751f\u6210\u591a\u6837\u6027\u66f4\u9ad8\u7684\u5408\u6210\u6570\u636e\u96c6\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u7f3a\u4e4f\u591a\u6837\u6027\uff0c\u5f71\u54cd\u4e0b\u6e38\u6a21\u578b\u7684\u8bad\u7ec3\u4e0e\u8bc4\u4f30\u3002", "method": "\u5229\u7528\u786e\u5b9a\u6027\u70b9\u8fc7\u7a0b\u4f18\u5316\u6570\u5b66\u6307\u6807\uff0c\u8fed\u4ee3\u751f\u6210\u591a\u6837\u5316\u6570\u636e\uff0c\u4e14\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\uff0c\u9002\u7528\u4e8e\u95ed\u6e90\u6a21\u578b\u4e14\u6613\u6269\u5c55\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVoyager\u5728\u6570\u636e\u591a\u6837\u6027\u4e0a\u6bd4\u73b0\u6709\u4e3b\u6d41\u65b9\u6cd5\u63d0\u53471.5\u81f33\u500d\u3002", "conclusion": "Voyager\u6709\u6548\u63d0\u5347\u5408\u6210\u6570\u636e\u7684\u591a\u6837\u6027\uff0c\u5177\u5907\u7406\u8bba\u652f\u6301\u548c\u826f\u597d\u6269\u5c55\u6027\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2512.12314", "categories": ["cs.SE", "cs.DC", "cs.PF", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.12314", "abs": "https://arxiv.org/abs/2512.12314", "authors": ["Anatoly A. Krasnovsky"], "title": "Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo", "comment": null, "summary": "While distributed tracing and chaos engineering are becoming standard for microservices, resilience models remain largely manual and bespoke. We revisit a trace-discovered connectivity model that derives a service dependency graph from traces and uses Monte Carlo simulation to estimate endpoint availability under fail-stop service failures. Compared to earlier work, we (i) derive the graph directly from raw OpenTelemetry traces, (ii) attach endpoint-specific success predicates, and (iii) add a simple asynchronous semantics that treats Kafka edges as non-blocking for immediate HTTP success. We apply this model to the OpenTelemetry Demo (\"Astronomy Shop\") using a GitHub Actions workflow that discovers the graph, runs simulations, and executes chaos experiments that randomly kill microservices in a Docker Compose deployment. Across the studied failure fractions, the model reproduces the overall availability degradation curve, while asynchronous semantics for Kafka edges change predicted availabilities by at most about 10^(-5) (0.001 percentage points). This null result suggests that for immediate HTTP availability in this case study, explicitly modeling asynchronous dependencies is not warranted, and a simpler connectivity-only model is sufficient.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eOpenTelemetry\u8ddf\u8e2a\u6570\u636e\u7684\u5fae\u670d\u52a1\u4f9d\u8d56\u56fe\u6784\u5efa\u4e0e\u8499\u7279\u5361\u6d1b\u4eff\u771f\u65b9\u6cd5\uff0c\u7528\u4ee5\u4f30\u8ba1\u7aef\u70b9\u5728\u670d\u52a1\u5931\u8d25\u60c5\u51b5\u4e0b\u7684\u53ef\u7528\u6027\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5f02\u6b65\u8bed\u4e49\u5bf9\u53ef\u7528\u6027\u9884\u6d4b\u7684\u5f71\u54cd\u6781\u5c0f\u3002", "motivation": "\u4f20\u7edf\u7684\u5fae\u670d\u52a1\u5f39\u6027\u6a21\u578b\u591a\u4e3a\u624b\u5de5\u5b9a\u5236\uff0c\u7f3a\u4e4f\u81ea\u52a8\u5316\u548c\u666e\u9002\u6027\uff0c\u9700\u501f\u52a9\u5206\u5e03\u5f0f\u8ffd\u8e2a\u6570\u636e\u81ea\u52a8\u6784\u5efa\u670d\u52a1\u4f9d\u8d56\u5e76\u9884\u6d4b\u6545\u969c\u5f71\u54cd\u3002", "method": "\u76f4\u63a5\u4eceOpenTelemetry\u539f\u59cb\u8ddf\u8e2a\u6570\u636e\u63a8\u5bfc\u670d\u52a1\u4f9d\u8d56\u56fe\uff0c\u7ed3\u5408\u7aef\u70b9\u7279\u5b9a\u7684\u6210\u529f\u5224\u5b9a\u6807\u51c6\uff0c\u52a0\u5165Kafka\u5f02\u6b65\u8fb9\u7684\u975e\u963b\u585e\u8bed\u4e49\uff0c\u7528\u8499\u7279\u5361\u6d1b\u6a21\u62df\u4f30\u8ba1\u7aef\u70b9\u53ef\u7528\u6027\uff1b\u901a\u8fc7GitHub Actions\u81ea\u52a8\u5316\u6267\u884c\u56fe\u53d1\u73b0\u3001\u4eff\u771f\u548c\u6df7\u6c8c\u5b9e\u9a8c\u3002", "result": "\u6a21\u578b\u6210\u529f\u91cd\u73b0\u4e86\u6574\u4f53\u53ef\u7528\u6027\u4e0b\u964d\u66f2\u7ebf\uff0c\u4e14\u589e\u52a0\u5f02\u6b65Kafka\u8bed\u4e49\u5bf9\u53ef\u7528\u6027\u9884\u6d4b\u5f71\u54cd\u6781\u5c0f\uff08\u7ea60.001\u4e2a\u767e\u5206\u70b9\uff09\uff0c\u8868\u660e\u65e0\u9700\u590d\u6742\u5f02\u6b65\u5efa\u6a21\u3002", "conclusion": "\u5bf9\u4e8e\u5373\u65f6HTTP\u53ef\u7528\u6027\u8bc4\u4f30\uff0c\u7b80\u5355\u7684\u57fa\u4e8e\u8fde\u63a5\u6027\u7684\u670d\u52a1\u4f9d\u8d56\u6a21\u578b\u8db3\u591f\u6709\u6548\uff0c\u5f02\u6b65\u4f9d\u8d56\u7684\u663e\u5f0f\u5efa\u6a21\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2512.12087", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12087", "abs": "https://arxiv.org/abs/2512.12087", "authors": ["Jiayi Yuan", "Cameron Shinn", "Kai Xu", "Jingze Cui", "George Klimiashvili", "Guangxuan Xiao", "Perkz Zheng", "Bo Li", "Yuxin Zhou", "Zhouhai Ye", "Weijie You", "Tian Zheng", "Dominic Brown", "Pengbo Wang", "Richard Cai", "Julien Demouth", "John D. Owens", "Xia Hu", "Song Han", "Timmy Liu", "Huizi Mao"], "title": "BLASST: Dynamic BLocked Attention Sparsity via Softmax Thresholding", "comment": null, "summary": "The growing demand for long-context inference capabilities in Large Language Models (LLMs) has intensified the computational and memory bottlenecks inherent to the standard attention mechanism. To address this challenge, we introduce BLASST, a drop-in sparse attention method that dynamically prunes the attention matrix without any pre-computation or proxy scores. Our method uses a fixed threshold and existing information from online softmax to identify negligible attention scores, skipping softmax computation, Value block loading, and the subsequent matrix multiplication. This fits seamlessly into existing FlashAttention kernel designs with negligible latency overhead. The approach is applicable to both prefill and decode stages across all attention variants (MHA, GQA, MQA, and MLA), providing a unified solution for accelerating long-context inference. We develop an automated calibration procedure that reveals a simple inverse relationship between optimal threshold and context length, enabling robust deployment across diverse scenarios. Maintaining high accuracy, we demonstrate a 1.62x speedup for prefill at 74.7% sparsity and a 1.48x speedup for decode at 73.2% sparsity on modern GPUs. Furthermore, we explore sparsity-aware training as a natural extension, showing that models can be trained to be inherently more robust to sparse attention patterns, pushing the accuracy-sparsity frontier even further.", "AI": {"tldr": "BLASST\u662f\u4e00\u79cd\u52a8\u6001\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u7ebf\u9608\u503c\u526a\u679d\uff0c\u663e\u8457\u52a0\u901f\u5927\u8bed\u8a00\u6a21\u578b\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\uff0c\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u540c\u65f6\u4fdd\u6301\u9ad8\u7cbe\u5ea6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5bf9\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f46\u6807\u51c6\u6ce8\u610f\u529b\u673a\u5236\u5728\u8ba1\u7b97\u548c\u5185\u5b58\u65b9\u9762\u5b58\u5728\u74f6\u9888\u3002\u4e3a\u89e3\u51b3\u6b64\u95ee\u9898\uff0c\u9700\u5f00\u53d1\u9ad8\u6548\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u3002", "method": "BLASST\u65e0\u9700\u9884\u8ba1\u7b97\u6216\u4ee3\u7406\u5206\u6570\uff0c\u5229\u7528\u56fa\u5b9a\u9608\u503c\u548c\u5728\u7ebfsoftmax\u4fe1\u606f\u52a8\u6001\u526a\u679d\u6ce8\u610f\u529b\u77e9\u9635\uff0c\u51cf\u5c11softmax\u8ba1\u7b97\u3001\u8f7d\u5165Value\u5757\u548c\u77e9\u9635\u4e58\u6cd5\uff0c\u517c\u5bb9\u73b0\u6709FlashAttention\u6838\u8bbe\u8ba1\u3002\u8bbe\u8ba1\u81ea\u52a8\u6821\u51c6\u65b9\u6848\uff0c\u9608\u503c\u4e0e\u4e0a\u4e0b\u6587\u957f\u5ea6\u5448\u7b80\u5355\u53cd\u6bd4\uff0c\u9002\u7528\u4e8e\u6240\u6709\u6ce8\u610f\u529b\u53d8\u4f53\u3002", "result": "\u5728\u73b0\u4ee3GPU\u4e0a\uff0cBLASST\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u5ea6\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e8674.7%\u7a00\u758f\u5ea6\u4e0bprefill\u9636\u6bb51.62\u500d\u52a0\u901f\uff0c73.2%\u7a00\u758f\u5ea6\u4e0bdecode\u9636\u6bb51.48\u500d\u52a0\u901f\u3002\u901a\u8fc7\u7a00\u758f\u611f\u77e5\u8bad\u7ec3\uff0c\u8fdb\u4e00\u6b65\u63d0\u5347\u6a21\u578b\u5bf9\u7a00\u758f\u6a21\u5f0f\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "BLASST\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u7a00\u758f\u6ce8\u610f\u529b\u89e3\u51b3\u65b9\u6848\uff0c\u5927\u5e45\u7f13\u89e3\u8ba1\u7b97\u74f6\u9888\u5e76\u4fdd\u6301\u51c6\u786e\u6027\uff0c\u7a00\u758f\u611f\u77e5\u8bad\u7ec3\u6709\u52a9\u4e8e\u62d3\u5c55\u51c6\u786e\u7387\u4e0e\u7a00\u758f\u5ea6\u7684\u5e73\u8861\u754c\u9650\u3002"}}
{"id": "2512.12326", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12326", "abs": "https://arxiv.org/abs/2512.12326", "authors": ["J. Alexander Curtis", "Nasir U. Eisty"], "title": "The Role of AI in Modern Penetration Testing", "comment": null, "summary": "Penetration testing is a cornerstone of cybersecurity, traditionally driven by manual, time-intensive processes. As systems grow in complexity, there is a pressing need for more scalable and efficient testing methodologies. This systematic literature review examines how Artificial Intelligence (AI) is reshaping penetration testing, analyzing 58 peer-reviewed studies from major academic databases. Our findings reveal that while AI-assisted pentesting is still in its early stages, notable progress is underway, particularly through Reinforcement Learning (RL), which was the focus of 77% of the reviewed works. Most research centers on the discovery and exploitation phases of pentesting, where AI shows the greatest promise in automating repetitive tasks, optimizing attack strategies, and improving vulnerability identification. Real-world applications remain limited but encouraging, including the European Space Agency's PenBox and various open-source tools. These demonstrate AI's potential to streamline attack path analysis, analyze complex network topology, and reduce manual workload. However, challenges persist: current models often lack flexibility and are underdeveloped for the reconnaissance and post-exploitation phases of pentesting. Applications involving Large Language Models (LLMs) remain relatively under-researched, pointing to a promising direction for future exploration. This paper offers a critical overview of AI's current and potential role in penetration testing, providing valuable insights for researchers, practitioners, and organizations aiming to enhance security assessments through advanced automation or looking for gaps in existing research.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u6e17\u900f\u6d4b\u8bd5\u9886\u57df\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u5728\u53d1\u73b0\u548c\u5229\u7528\u6f0f\u6d1e\u9636\u6bb5\u7684\u8fdb\u5c55\uff0c\u6307\u51fa\u73b0\u6709\u7814\u7a76\u96c6\u4e2d\u4e8e\u81ea\u52a8\u5316\u91cd\u590d\u4efb\u52a1\u548c\u4f18\u5316\u653b\u51fb\u7b56\u7565\uff0c\u4f46\u4ecd\u5b58\u5728\u6a21\u578b\u7075\u6d3b\u6027\u4e0d\u8db3\u53ca\u4fa6\u5bdf\u548c\u540e\u5229\u7528\u9636\u6bb5\u5e94\u7528\u6709\u9650\u7b49\u6311\u6218\u3002", "motivation": "\u968f\u7740\u7cfb\u7edf\u590d\u6742\u6027\u589e\u52a0\uff0c\u4f20\u7edf\u4eba\u5de5\u6e17\u900f\u6d4b\u8bd5\u6548\u7387\u4f4e\u4e14\u8017\u65f6\uff0c\u8feb\u5207\u9700\u8981\u66f4\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6d4b\u8bd5\u65b9\u6cd5\u3002AI\u6280\u672f\u4e3a\u6b64\u63d0\u4f9b\u4e86\u65b0\u673a\u9047\u3002", "method": "\u901a\u8fc7\u5206\u679058\u7bc7\u540c\u884c\u8bc4\u5ba1\u6587\u732e\uff0c\u91cd\u70b9\u8003\u5bdf\u4e86AI\u6280\u672f\u5728\u6e17\u900f\u6d4b\u8bd5\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7684\u4f7f\u7528\u60c5\u51b5\u53ca\u5de5\u5177\u5b9e\u4f8b\uff0c\u8bc4\u4f30\u5176\u6548\u679c\u4e0e\u73b0\u72b6\u3002", "result": "AI\u5728\u53d1\u73b0\u548c\u5229\u7528\u6f0f\u6d1e\u9636\u6bb5\u4e3b\u8981\u901a\u8fc7\u81ea\u52a8\u5316\u4efb\u52a1\u4e0e\u4f18\u5316\u653b\u51fb\u7b56\u7565\u8868\u73b0\u51fa\u663e\u8457\u6f5c\u529b\uff0c\u5b9e\u9645\u5e94\u7528\u867d\u6709\u9650\u4f46\u5df2\u6709\u5982\u6b27\u6d32\u822a\u5929\u5c40PenBox\u7b49\u9879\u76ee\u5c55\u793a\u4e86\u6210\u6548\u3002\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u76f8\u5bf9\u8f83\u5c11\u3002", "conclusion": "AI\u8f85\u52a9\u6e17\u900f\u6d4b\u8bd5\u4ecd\u5904\u521d\u671f\u9636\u6bb5\uff0c\u5c3d\u7ba1\u5728\u90e8\u5206\u73af\u8282\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u4f46\u5b58\u5728\u7075\u6d3b\u6027\u548c\u9636\u6bb5\u8986\u76d6\u4e0d\u8db3\u7b49\u95ee\u9898\uff0c\u672a\u6765\u5e94\u52a0\u5f3a\u4fa6\u5bdf\u3001\u540e\u5229\u7528\u53ca\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\uff0c\u4ee5\u63a8\u52a8\u6e17\u900f\u6d4b\u8bd5\u7684\u667a\u80fd\u5316\u548c\u9ad8\u6548\u5316\u53d1\u5c55\u3002"}}
{"id": "2512.12167", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12167", "abs": "https://arxiv.org/abs/2512.12167", "authors": ["Yoav Gelberg", "Koshi Eguchi", "Takuya Akiba", "Edoardo Cetin"], "title": "Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings", "comment": null, "summary": "So far, expensive finetuning beyond the pretraining sequence length has been a requirement for effectively extending the context of language models (LM). In this work, we break this key bottleneck by Dropping the Positional Embeddings of LMs after training (DroPE). Our simple method is motivated by three key theoretical and empirical observations. First, positional embeddings (PEs) serve a crucial role during pretraining, providing an important inductive bias that significantly facilitates convergence. Second, over-reliance on this explicit positional information is also precisely what prevents test-time generalization to sequences of unseen length, even when using popular PE-scaling methods. Third, positional embeddings are not an inherent requirement of effective language modeling and can be safely removed after pretraining, following a short recalibration phase. Empirically, DroPE yields seamless zero-shot context extension without any long-context finetuning, quickly adapting pretrained LMs without compromising their capabilities in the original training context. Our findings hold across different models and dataset sizes, far outperforming previous specialized architectures and established rotary positional embedding scaling methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DroPE\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u9884\u8bad\u7ec3\u540e\u79fb\u9664\u8bed\u8a00\u6a21\u578b\u7684\u4f4d\u7f6e\u5d4c\u5165\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u957f\u4e0a\u4e0b\u6587\u5fae\u8c03\u7684\u4e0a\u4e0b\u6587\u6269\u5c55\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u6269\u5c55\u4e0a\u4e0b\u6587\u957f\u5ea6\u9700\u6602\u8d35\u7684\u5fae\u8c03\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u4f4d\u7f6e\u5d4c\u5165\uff0c\u9650\u5236\u4e86\u6a21\u578b\u5bf9\u672a\u89c1\u5e8f\u5217\u957f\u5ea6\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u8bad\u7ec3\u540e\u5220\u9664\u4f4d\u7f6e\u5d4c\u5165\uff0c\u5e76\u8fdb\u884c\u77ed\u6682\u7684\u91cd\u65b0\u6821\u51c6\uff0c\u51cf\u5c11\u5bf9\u663e\u5f0f\u4f4d\u7f6e\u4fe1\u606f\u7684\u4f9d\u8d56\uff0c\u5b9e\u73b0\u96f6-shot\u957f\u4e0a\u4e0b\u6587\u6269\u5c55\u3002", "result": "DroPE\u65b9\u6cd5\u5728\u591a\u79cd\u6a21\u578b\u548c\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5feb\u901f\u9002\u5e94\u957f\u4e0a\u4e0b\u6587\uff0c\u4e14\u4e0d\u635f\u5931\u539f\u8bad\u7ec3\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u5148\u524d\u7684\u4f4d\u7f6e\u5d4c\u5165\u7f29\u653e\u65b9\u6cd5\u548c\u4e13\u7528\u67b6\u6784\u3002", "conclusion": "\u4f4d\u7f6e\u5d4c\u5165\u5728\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u91cd\u8981\uff0c\u4f46\u975e\u8bed\u8a00\u6a21\u578b\u5efa\u6a21\u7684\u5fc5\u8981\u6761\u4ef6\uff0cDroPE\u6709\u6548\u89e3\u51b3\u4e86\u957f\u4e0a\u4e0b\u6587\u6cdb\u5316\u96be\u9898\uff0c\u63d0\u4f9b\u7b80\u6d01\u9ad8\u6548\u7684\u6269\u5c55\u65b9\u6848\u3002"}}
{"id": "2512.12507", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12507", "abs": "https://arxiv.org/abs/2512.12507", "authors": ["Jaid Monwar Chowdhury", "Ahmad Farhan Shahriar Chowdhury", "Humayra Binte Monwar", "Mahmuda Naznin"], "title": "ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs", "comment": "5 pages, 2 figures; Video demonstration: https://youtu.be/RACWQe5ELwY; Tool repository: https://github.com/jaid-monwar/ATLAS-code-representation-tool", "summary": "The growing complexity of modern software systems has highlighted the shortcomings of traditional programming analysis techniques, particularly for Software Engineering (SE) tasks. While machine learning and Large Language Models (LLMs) offer promising solutions, their effectiveness is limited by the way they interpret data. Unlike natural language, source code meaning is defined less by token adjacency and more by complex, long-range, and structural relationships and dependencies. This limitation is especially pronounced for C and C++, where flatter syntactic hierarchies, pointer aliasing, multi-level indirection, typedef-based type obfuscation, and function-pointer calls hinder accurate static analysis. To address these challenges, this paper introduces ATLAS, a Python-based Command-Line Interface (CLI) that (i) generates statement-level Control Flow Graphs (CFG) and type-aware Data Flow Graphs (DFG) that capture inter-functional dependencies for the entire program; (ii) has the ability to work on entire C and C++ projects comprising multiple files; (iii) works on both compilable and non-compilable code and (iv) produces a unified multi-view code representation using Abstract Syntax Trees (AST), CFG and DFG. By preserving essential structural and semantic information, ATLAS provides a practical foundation for improving downstream SE and machine-learning-based program understanding. Video demonstration: https://youtu.be/RACWQe5ELwY Tool repository: https://github.com/jaid-monwar/ATLAS-code-representation-tool", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ATLAS\uff0c\u4e00\u6b3e\u57fa\u4e8ePython\u7684\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u7528\u4e8e\u751f\u6210\u5e76\u6574\u5408C/C++\u4ee3\u7801\u7684\u591a\u89c6\u56fe\u8868\u793a\uff0c\u5305\u62ec\u63a7\u5236\u6d41\u56fe\u548c\u7c7b\u578b\u611f\u77e5\u7684\u6570\u636e\u6d41\u56fe\uff0c\u4ee5\u89e3\u51b3\u4f20\u7edf\u5206\u6790\u6280\u672f\u5728\u590d\u6742\u4ee3\u7801\u4e0a\u7684\u4e0d\u8db3\u3002", "motivation": "\u4f20\u7edf\u7a0b\u5e8f\u5206\u6790\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406C/C++\u4ee3\u7801\u4e2d\u7684\u590d\u6742\u7ed3\u6784\u3001\u6307\u9488\u522b\u540d\u3001\u591a\u7ea7\u95f4\u63a5\u5f15\u7528\u548c\u7c7b\u578b\u6df7\u6dc6\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u7a0b\u5e8f\u7406\u89e3\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1ATLAS\u5de5\u5177\uff0c\u80fd\u751f\u6210\u8bed\u53e5\u7ea7\u63a7\u5236\u6d41\u56fe\u548c\u7c7b\u578b\u611f\u77e5\u6570\u636e\u6d41\u56fe\uff0c\u652f\u6301\u8de8\u591a\u6587\u4ef6\u9879\u76ee\uff0c\u65e2\u9002\u7528\u4e8e\u53ef\u7f16\u8bd1\u4ee3\u7801\u4e5f\u80fd\u5206\u6790\u4e0d\u53ef\u7f16\u8bd1\u4ee3\u7801\uff0c\u7ed3\u5408\u62bd\u8c61\u8bed\u6cd5\u6811\u5b9e\u73b0\u591a\u89c6\u56fe\u7edf\u4e00\u4ee3\u7801\u8868\u793a\u3002", "result": "ATLAS\u6210\u529f\u751f\u6210\u8986\u76d6\u6574\u4e2a\u7a0b\u5e8f\u7684\u591a\u89c6\u56fe\u4ee3\u7801\u8868\u793a\uff0c\u4fdd\u7559\u4e86\u4ee3\u7801\u7684\u7ed3\u6784\u548c\u8bed\u4e49\u4fe1\u606f\uff0c\u652f\u6301\u590d\u6742\u4ee3\u7801\u7684\u9759\u6001\u5206\u6790\uff0c\u589e\u5f3a\u4e86\u540e\u7eed\u8f6f\u4ef6\u5de5\u7a0b\u548c\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u7684\u57fa\u7840\u3002", "conclusion": "\u901a\u8fc7\u6574\u5408CFG\u3001DFG\u548cAST\uff0cATLAS\u6709\u6548\u514b\u670d\u4e86\u4f20\u7edf\u5206\u6790\u6280\u672f\u5728C/C++\u590d\u6742\u6027\u6311\u6218\u4e0b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u7a0b\u5e8f\u5206\u6790\u548c\u673a\u5668\u5b66\u4e60\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u548c\u5de5\u5177\u652f\u6301\u3002"}}
{"id": "2512.12168", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12168", "abs": "https://arxiv.org/abs/2512.12168", "authors": ["Zheng Huang", "Kiran Ramnath", "Yueyan Chen", "Aosong Feng", "Sangmin Woo", "Balasubramaniam Srinivasan", "Zhichao Xu", "Kang Zhou", "Shuai Wang", "Haibo Ding", "Lin Lee Cheong"], "title": "Diffusion Language Model Inference with Monte Carlo Tree Search", "comment": null, "summary": "Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MEDAL\u6846\u67b6\uff0c\u5229\u7528\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\u4f18\u5316\u6269\u6563\u8bed\u8a00\u6a21\u578b\uff08DLMs\uff09\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89e3\u7801\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u65b9\u6cd5\u91c7\u7528\u542f\u53d1\u5f0f\u6216\u989d\u5916\u8bad\u7ec3\u6307\u5bfc\uff0c\u5b58\u5728\u5b50\u6700\u4f18\u89e3\u95ee\u9898\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u5316\u7684\u641c\u7d22\u673a\u5236\u3002", "method": "MEDAL\u6846\u67b6\u5728\u63a8\u7406\u521d\u59cb\u5316\u9636\u6bb5\u5f15\u5165\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff0c\u9650\u5236\u641c\u7d22\u7a7a\u95f4\u81f3\u9ad8\u7f6e\u4fe1\u5ea6\u64cd\u4f5c\uff0c\u4f18\u5148\u9009\u62e9\u80fd\u63d0\u5347\u6a21\u578b\u4fe1\u5fc3\u7684\u8bcd\u5143\uff0c\u4f5c\u4e3a\u540e\u7eed\u8fed\u4ee3\u7684\u826f\u597d\u8d77\u70b9\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMEDAL\u8f83\u73b0\u6709\u63a8\u7406\u7b56\u7565\u6700\u9ad8\u63d0\u5347\u4e8622.0%\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "MEDAL\u4e3a\u6269\u6563\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u5f15\u5165\u4e86\u57fa\u4e8e\u641c\u7d22\u7684\u8303\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6587\u672c\u751f\u6210\u7684\u8d28\u91cf\u548c\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.12536", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12536", "abs": "https://arxiv.org/abs/2512.12536", "authors": ["Arastoo Zibaeirad", "Marco Vieira"], "title": "Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being studied for Software Vulnerability Detection (SVD) and Repair (SVR). Individual LLMs have demonstrated code understanding abilities, but they frequently struggle when identifying complex vulnerabilities and generating fixes.\n  This study presents DVDR-LLM, an ensemble framework that combines outputs from diverse LLMs to determine whether aggregating multiple models reduces error rates. Our evaluation reveals that DVDR-LLM achieves 10-12% higher detection accuracy compared to the average performance of individual models, with benefits increasing as code complexity grows. For multi-file vulnerabilities, the ensemble approach demonstrates significant improvements in recall (+18%) and F1 score (+11.8%) over individual models. However, the approach raises measurable trade-offs: reducing false positives in verification tasks while simultaneously increasing false negatives in detection tasks, requiring careful decision on the required level of agreement among the LLMs (threshold) for increased performance across different security contexts.\n  Artifact: https://github.com/Erroristotle/DVDR_LLM", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDVDR-LLM\u7684\u591a\u6a21\u578b\u96c6\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u878d\u5408\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8f93\u51fa\uff0c\u63d0\u5347\u4e86\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u548c\u4fee\u590d\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5355\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bc6\u522b\u590d\u6742\u6f0f\u6d1e\u548c\u751f\u6210\u4fee\u590d\u4ee3\u7801\u65f6\u8868\u73b0\u6709\u9650\uff0c\u4e9f\u9700\u63d0\u5347\u68c0\u6d4b\u548c\u4fee\u590d\u7684\u6548\u679c\u3002", "method": "\u8bbe\u8ba1DVDR-LLM\u96c6\u6210\u6846\u67b6\uff0c\u5c06\u591a\u4e2a\u4e0d\u540c\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u7ec4\u5408\uff0c\u4ee5\u51cf\u5c11\u8bef\u68c0\u7387\u5e76\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "result": "DVDR-LLM\u5728\u6f0f\u6d1e\u68c0\u6d4b\u51c6\u786e\u7387\u63d0\u534710-12%\uff0c\u591a\u6587\u4ef6\u6f0f\u6d1e\u53ec\u56de\u7387\u63d0\u534718%\uff0cF1\u5206\u6570\u63d0\u534711.8%\uff1b\u4f46\u5728\u964d\u4f4e\u8bef\u62a5\u7684\u540c\u65f6\uff0c\u589e\u52a0\u4e86\u6f0f\u62a5\uff0c\u9700\u6839\u636e\u5b89\u5168\u9700\u6c42\u8c03\u6574\u6a21\u578b\u8f93\u51fa\u9608\u503c\u3002", "conclusion": "\u901a\u8fc7\u96c6\u6210\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\uff0cDVDR-LLM\u6709\u6548\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u4e0e\u4fee\u590d\u7684\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u4ee3\u7801\u73af\u5883\u4e0b\u8868\u73b0\u66f4\u52a0\u7a81\u51fa\uff0c\u4f46\u9700\u6743\u8861\u8bef\u62a5\u4e0e\u6f0f\u62a5\u3002"}}
{"id": "2512.12238", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12238", "abs": "https://arxiv.org/abs/2512.12238", "authors": ["Yinzhu Cheng", "Haihua Xie", "Yaqing Wang", "Miao He", "Mingming Sun"], "title": "Semantic Distance Measurement based on Multi-Kernel Gaussian Processes", "comment": null, "summary": "Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining Mat\u00e9rn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6838\u9ad8\u65af\u8fc7\u7a0b\u7684\u8bed\u4e49\u8ddd\u79bb\u6d4b\u91cf\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5b66\u4e60\u6838\u53c2\u6570\uff0c\u63d0\u5347\u4e86\u8bed\u4e49\u8ddd\u79bb\u7684\u81ea\u9002\u5e94\u6027\uff0c\u5728\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u4f20\u7edf\u7684\u8bed\u4e49\u8ddd\u79bb\u6d4b\u91cf\u65b9\u6cd5\u56fa\u5b9a\u96be\u4ee5\u9002\u5e94\u7279\u5b9a\u6570\u636e\u5206\u5e03\u548c\u4efb\u52a1\u9700\u6c42\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u52a8\u9002\u5e94\u6570\u636e\u7684\u7075\u6d3b\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u591a\u6838\u9ad8\u65af\u8fc7\u7a0b\uff08MK-GP\uff09\u5c06\u6587\u672c\u7684\u6f5c\u5728\u8bed\u4e49\u51fd\u6570\u5efa\u6a21\u4e3a\u9ad8\u65af\u8fc7\u7a0b\uff0c\u534f\u65b9\u5dee\u51fd\u6570\u7531Mat\u00e9rn\u6838\u548c\u591a\u9879\u5f0f\u6838\u7ec4\u5408\u800c\u6210\uff0c\u6838\u53c2\u6570\u901a\u8fc7\u76d1\u7763\u5b66\u4e60\u81ea\u52a8\u4f18\u5316\u3002", "result": "\u5728\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u6846\u67b6\u4e0b\uff0c\u5c06\u8be5\u8bed\u4e49\u8ddd\u79bb\u5e94\u7528\u4e8e\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u7c7b\uff0c\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u6548\u679c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u591a\u6838\u9ad8\u65af\u8fc7\u7a0b\u7684\u8bed\u4e49\u8ddd\u79bb\u6d4b\u91cf\u65b9\u6cd5\u5177\u6709\u8f83\u5f3a\u7684\u9002\u5e94\u6027\u548c\u6709\u6548\u6027\uff0c\u9002\u5408\u7528\u4ee5\u63d0\u5347\u6587\u672c\u76f8\u4f3c\u5ea6\u76f8\u5173\u4efb\u52a1\u7684\u6027\u80fd\u3002"}}
{"id": "2512.12551", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12551", "abs": "https://arxiv.org/abs/2512.12551", "authors": ["Dewen Suo", "Lei Xue", "Weihao Huang", "Runze Tan", "Guozi Sun"], "title": "Assessing the Capability of Android Dynamic Analysis Tools to Combat Anti-Runtime Analysis Techniques", "comment": null, "summary": "As the dominant mobile operating system, Android continues to attract a substantial influx of new applications each year. However, this growth is accompanied by increased attention from malicious actors, resulting in a significant rise in security threats to the Android ecosystem. Among these threats, the adoption of Anti-Runtime Analysis (ARA) techniques by malicious applications poses a serious challenge, as it hinders security professionals from effectively analyzing malicious behaviors using dynamic analysis tools. ARA technologies are designed to prevent the dynamic examination of applications, thus complicating efforts to ensure platform security. This paper presents a comprehensive empirical study that assesses the ability of widely-used Android dynamic analysis tools to bypass various ARA techniques. Our findings reveal a critical gap in the effectiveness of existing dynamic analysis tools to counter ARA mechanisms, highlighting an urgent need for more robust solutions. This work provides valuable insights into the limitations of existing tools and highlights the need for improved methods to counteract ARA technologies, thus advancing the field of software security and dynamic analysis.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86Android\u52a8\u6001\u5206\u6790\u5de5\u5177\u5e94\u5bf9\u53cd\u52a8\u6001\u5206\u6790\u6280\u672f\uff08ARA\uff09\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u5de5\u5177\u5728\u7ed5\u8fc7ARA\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u4e9f\u9700\u66f4\u5f3a\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u5b89\u5168\u68c0\u6d4b\u6548\u679c\u3002", "motivation": "\u968f\u7740Android\u5e94\u7528\u6570\u91cf\u6fc0\u589e\uff0c\u6076\u610f\u5e94\u7528\u5229\u7528ARA\u6280\u672f\u8eb2\u907f\u52a8\u6001\u5206\u6790\uff0c\u7ed9\u5b89\u5168\u4e13\u4e1a\u4eba\u5458\u5e26\u6765\u6311\u6218\uff0c\u4e9f\u9700\u8bc4\u4f30\u5e76\u63d0\u5347\u52a8\u6001\u5206\u6790\u5de5\u5177\u7684\u6709\u6548\u6027\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684Android\u52a8\u6001\u5206\u6790\u5de5\u5177\u7ed5\u8fc7\u5404\u79cdARA\u6280\u672f\u7684\u80fd\u529b\uff0c\u63ed\u793a\u5176\u5728\u5e94\u5bf9ARA\u673a\u5236\u4e0a\u7684\u5f31\u70b9\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u663e\u793a\u73b0\u6709\u52a8\u6001\u5206\u6790\u5de5\u5177\u5728\u7ed5\u8fc7ARA\u673a\u5236\u65b9\u9762\u5b58\u5728\u5173\u952e\u5dee\u8ddd\uff0c\u65e0\u6cd5\u6709\u6548\u5bf9\u6297\u6076\u610f\u5e94\u7528\u7684\u53cd\u52a8\u6001\u5206\u6790\u624b\u6bb5\u3002", "conclusion": "\u73b0\u6709Android\u52a8\u6001\u5206\u6790\u5de5\u5177\u96be\u4ee5\u6709\u6548\u62b5\u5fa1ARA\u6280\u672f\uff0c\u9700\u7814\u53d1\u66f4\u5f3a\u5927\u4e14\u9c81\u68d2\u7684\u5206\u6790\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u52a8\u6001\u5206\u6790\u7684\u5b89\u5168\u4fdd\u969c\u6c34\u5e73\u3002"}}
{"id": "2512.12245", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12245", "abs": "https://arxiv.org/abs/2512.12245", "authors": ["Anika Sharma", "Tianyi Niu", "Emma Wrenn", "Shashank Srivastava"], "title": "Adversarially Probing Cross-Family Sound Symbolism in 27 Languages", "comment": null, "summary": "The phenomenon of sound symbolism, the non-arbitrary mapping between word sounds and meanings, has long been demonstrated through anecdotal experiments like Bouba Kiki, but rarely tested at scale. We present the first computational cross-linguistic analysis of sound symbolism in the semantic domain of size. We compile a typologically broad dataset of 810 adjectives (27 languages, 30 words each), each phonemically transcribed and validated with native-speaker audio. Using interpretable classifiers over bag-of-segment features, we find that phonological form predicts size semantics above chance even across unrelated languages, with both vowels and consonants contributing. To probe universality beyond genealogy, we train an adversarial scrubber that suppresses language identity while preserving size signal (also at family granularity). Language prediction averaged across languages and settings falls below chance while size prediction remains significantly above chance, indicating cross-family sound-symbolic bias. We release data, code, and diagnostic tools for future large-scale studies of iconicity.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u8fdb\u884c\u8de8\u8bed\u8a00\u89c4\u6a21\u5316\u5206\u6790\uff0c\u8bc1\u5b9e\u4e86\u8bed\u97f3\u5f62\u5f0f\u4e0e\u5c3a\u5bf8\u8bed\u4e49\u4e4b\u95f4\u5b58\u5728\u666e\u904d\u7684\u58f0\u97f3\u8c61\u5f81\u5173\u7cfb\u3002", "motivation": "\u58f0\u97f3\u8c61\u5f81\u867d\u7136\u901a\u8fc7\u4e00\u4e9b\u5c0f\u89c4\u6a21\u5b9e\u9a8c\u88ab\u8bc1\u660e\uff0c\u4f46\u7f3a\u4e4f\u5927\u89c4\u6a21\u3001\u8de8\u8bed\u8a00\u7684\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u5efa\u7acb\u4e86\u5305\u542b27\u79cd\u8bed\u8a00\u3001810\u4e2a\u5f62\u5bb9\u8bcd\u7684\u6570\u636e\u5e93\uff0c\u91c7\u7528\u97f3\u7d20\u8f6c\u5f55\u548c\u6bcd\u8bed\u8005\u9a8c\u8bc1\u97f3\u9891\uff0c\u7528\u53ef\u89e3\u91ca\u7684\u5206\u7c7b\u5668\u57fa\u4e8e\u97f3\u6bb5\u7279\u5f81\u9884\u6d4b\u5c3a\u5bf8\u8bed\u4e49\uff0c\u8bbe\u8ba1\u5bf9\u6297\u6a21\u578b\u5c4f\u853d\u8bed\u8a00\u8eab\u4efd\u4ee5\u9a8c\u8bc1\u666e\u904d\u6027\u3002", "result": "\u5206\u7c7b\u5668\u80fd\u663e\u8457\u9884\u6d4b\u5c3a\u5bf8\u8bed\u4e49\uff0c\u8bed\u8a00\u8eab\u4efd\u88ab\u6291\u5236\u540e\u5c3a\u5bf8\u9884\u6d4b\u4ecd\u663e\u8457\u9ad8\u4e8e\u968f\u673a\uff0c\u8bc1\u5b9e\u8de8\u8bed\u8a00\u65cf\u7fa4\u5b58\u5728\u58f0\u97f3\u8c61\u5f81\u504f\u597d\u3002", "conclusion": "\u58f0\u97f3\u8c61\u5f81\u5728\u5c3a\u5bf8\u8bed\u4e49\u9886\u57df\u8868\u73b0\u51fa\u8de8\u8bed\u8a00\u666e\u904d\u6027\uff0c\u7814\u7a76\u6570\u636e\u4e0e\u5de5\u5177\u516c\u5f00\u4fc3\u8fdb\u540e\u7eed\u6807\u5fd7\u6027\u7814\u7a76\u53d1\u5c55\u3002"}}
{"id": "2512.12593", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.12593", "abs": "https://arxiv.org/abs/2512.12593", "authors": ["Saadh Jawwadh", "Guhanathan Poravi"], "title": "SHERLOCK: A Deep Learning Approach To Detect Software Vulnerabilities", "comment": null, "summary": "The increasing reliance on software in various applications has made the problem of software vulnerability detection more critical. Software vulnerabilities can lead to security breaches, data theft, and other negative outcomes. Traditional software vulnerability detection techniques, such as static and dynamic analysis, have been shown to be ineffective at detecting multiple vulnerabilities.\n  To address this issue, this study employed a deep learning approach, specifically Convolutional Neural Networks (CNN), to solve the software vulnerability detection problem. A 5-split cross-validation approach was used to train and evaluate the CNN model, which takes tokenized source code as input.\n  The findings indicated that Sherlock successfully detected multiple vulnerabilities at the function level, and its performance was particularly strong for CWE-199, CWE-120, and CWE-Other, with an overall high accuracy rate and significant true positive and true negative values. However, the performance was less reliable for some vulnerabilities due to the lack of a standardized dataset which will be a future research direction. The results suggest that compared to current techniques, the proposed deep learning approach has the potential to substantially enhance the accuracy of software vulnerability detection.", "AI": {"tldr": "\u672c\u7814\u7a76\u91c7\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff08CNN\uff09\u8fdb\u884c\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\uff0c\u5229\u75285\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8bad\u7ec3\u6a21\u578b\uff0c\u5bf9\u6e90\u7801\u8fdb\u884c\u6807\u8bb0\u5316\u5904\u7406\u3002\u7ed3\u679c\u663e\u793a\u6a21\u578b\u5728\u529f\u80fd\u7ea7\u522b\u80fd\u6709\u6548\u68c0\u6d4b\u591a\u79cd\u6f0f\u6d1e\uff0c\u7279\u522b\u662fCWE-199\u548cCWE-120\u7c7b\u578b\uff0c\u6574\u4f53\u51c6\u786e\u7387\u8f83\u9ad8\u3002", "motivation": "\u4f20\u7edf\u7684\u9759\u6001\u548c\u52a8\u6001\u5206\u6790\u65b9\u6cd5\u5728\u68c0\u6d4b\u591a\u6f0f\u6d1e\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u6c42\u66f4\u51c6\u786e\u7684\u68c0\u6d4b\u6280\u672f\u6765\u9632\u8303\u5b89\u5168\u98ce\u9669\u3002", "method": "\u5229\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5bf9\u6807\u8bb0\u5316\u7684\u6e90\u4ee3\u7801\u8fdb\u884c\u5206\u6790\uff0c\u901a\u8fc75\u6298\u4ea4\u53c9\u9a8c\u8bc1\u8bad\u7ec3\u548c\u8bc4\u4f30\u6a21\u578b\u3002", "result": "CNN\u6a21\u578b\u6210\u529f\u68c0\u6d4b\u4e86\u591a\u79cd\u6f0f\u6d1e\uff0c\u5c24\u5176\u5728CWE-199\u548cCWE-120\u7c7b\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u6574\u4f53\u51c6\u786e\u7387\u9ad8\uff0c\u771f\u9633\u6027\u548c\u771f\u9634\u6027\u6307\u6807\u663e\u8457\u3002\u6570\u636e\u96c6\u7f3a\u4e4f\u6807\u51c6\u5316\u9650\u5236\u4e86\u90e8\u5206\u6f0f\u6d1e\u7684\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edf\u6280\u672f\u80fd\u663e\u8457\u63d0\u5347\u8f6f\u4ef6\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u7387\uff0c\u672a\u6765\u65b9\u5411\u5305\u62ec\u5efa\u7acb\u6807\u51c6\u6570\u636e\u96c6\u4ee5\u63d0\u5347\u6a21\u578b\u7684\u53ef\u9760\u6027\u3002"}}
{"id": "2512.12264", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12264", "abs": "https://arxiv.org/abs/2512.12264", "authors": ["Abhay Srivastava", "Sam Jung", "Spencer Mateega"], "title": "Market-Bench: Evaluating Large Language Models on Introductory Quantitative Trading and Market Dynamics", "comment": null, "summary": "We introduce MARKET-BENCH, a benchmark that evaluates large language models (LLMs) on introductory quantitative trading tasks by asking them to construct executable backtesters from natural-language strategy descriptions and market assumptions. Each instance specifies one of three canonical strategies -- scheduled trading on Microsoft (NASDAQ: MSFT), pairs trading on Coca-Cola (NASDAQ: KO) and Pepsi (NASDAQ: PEP), or delta hedging on MSFT -- and models must produce code whose P\\&L, drawdown, and position paths match a verifiable reference implementation. We assess twelve state-of-the-art models using a multi-round pass@k metric that separates structural reliability (whether the backtest runs) from numerical accuracy (mean absolute error of the backtest metrics). While most models reliably execute the simplest strategy (average pass@3 of 0.80), errors vary by orders of magnitude across models and tasks: Gemini 3 Pro and Claude 4.5 Sonnet combine strong reliability with low error on simpler strategies, GPT-5.1 Codex-Max achieves perfect pass@1 on the first two strategies and the lowest best-run error on the easiest task, and Qwen3 Max attains perfect pass@3 yet sometimes produces inaccurate P\\&L paths. These results show that current LLMs can scaffold basic trading infrastructure but still struggle to reason robustly about prices, inventory, and risk; we release MARKET-BENCH and a public leaderboard at https://marketbench.ai.", "AI": {"tldr": "MARKET-BENCH\u57fa\u51c6\u8bc4\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5b9a\u91cf\u4ea4\u6613\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u8981\u6c42\u6a21\u578b\u4ece\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u751f\u6210\u53ef\u6267\u884c\u7684\u56de\u6d4b\u4ee3\u7801\uff0c\u5e76\u8bc4\u4f30\u5176\u6536\u76ca\u548c\u98ce\u9669\u6307\u6807\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u91d1\u878d\u4ea4\u6613\u7b56\u7565\u81ea\u52a8\u5316\u751f\u6210\u4e2d\u7684\u80fd\u529b\u5c1a\u672a\u7cfb\u7edf\u8bc4\u4f30\uff0c\u5e02\u573a\u9700\u8981\u4e00\u4e2a\u6807\u51c6\u5316\u7684\u57fa\u51c6\u6765\u8861\u91cf\u6a21\u578b\u5728\u57fa\u7840\u4ea4\u6613\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u6784\u5efa\u5305\u542b\u4e09\u79cd\u7ecf\u5178\u4ea4\u6613\u7b56\u7565\uff08\u5fae\u8f6f\u5b9a\u65f6\u4ea4\u6613\u3001\u53ef\u53e3\u53ef\u4e50\u4e0e\u767e\u4e8b\u53ef\u4e50\u5bf9\u51b2\u4ea4\u6613\u3001\u5fae\u8f6fDelta\u5bf9\u51b2\uff09\u7684\u57fa\u51c6\u5957\u4ef6\uff0c\u8981\u6c42\u6a21\u578b\u751f\u6210\u7684\u56de\u6d4b\u4ee3\u7801\u80fd\u590d\u73b0\u53c2\u8003\u5b9e\u73b0\u7684\u76c8\u4e8f\u3001\u56de\u64a4\u548c\u4ed3\u4f4d\u8def\u5f84\u3002\u901a\u8fc7\u591a\u8f6epass@k\u6307\u6807\u5206\u522b\u8bc4\u4f30\u7ed3\u6784\u53ef\u9760\u6027\u4e0e\u6570\u503c\u51c6\u786e\u5ea6\u3002", "result": "\u6d4b\u8bd5\u4e8612\u4e2a\u5148\u8fdb\u6a21\u578b\uff0c\u53d1\u73b0\u5b83\u4eec\u5728\u6700\u7b80\u5355\u7b56\u7565\u4e0a\u7684\u6267\u884c\u53ef\u9760\u6027\u8f83\u9ad8\uff0c\u4f46\u4e0d\u540c\u6a21\u578b\u548c\u4efb\u52a1\u95f4\u7684\u8bef\u5dee\u5dee\u5f02\u8f83\u5927\u3002Gemini 3 Pro\u548cClaude 4.5 Sonnet\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u9760\u6027\u548c\u4f4e\u8bef\u5dee\uff0cGPT-5.1 Codex-Max\u5728\u524d\u4e24\u79cd\u7b56\u7565\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cQwen3 Max\u867d\u80fd\u5b8c\u5168\u901a\u8fc7\u591a\u4e2a\u6d4b\u8bd5\uff0c\u4f46\u76c8\u4e8f\u8def\u5f84\u6709\u65f6\u4e0d\u51c6\u786e\u3002", "conclusion": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u642d\u5efa\u57fa\u672c\u4ea4\u6613\u57fa\u7840\u8bbe\u65bd\uff0c\u4f46\u5728\u4ef7\u683c\u3001\u5e93\u5b58\u548c\u98ce\u9669\u7684\u590d\u6742\u63a8\u7406\u4e0a\u4ecd\u5b58\u5728\u4e0d\u8db3\u3002\u4f5c\u8005\u516c\u5f00\u4e86MARKET-BENCH\u6570\u636e\u96c6\u548c\u6392\u884c\u699c\uff0c\u4fc3\u8fdb\u8be5\u9886\u57df\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2512.12650", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12650", "abs": "https://arxiv.org/abs/2512.12650", "authors": ["Bastiaan Heeren", "Fabiano Dalpiaz", "Mazyar Seraj", "Roberto Verdecchia", "Vadim Zaytsev"], "title": "A Systematic Analysis of Higher Education on Software Engineering in the Netherlands", "comment": null, "summary": "Software engineering educators strive to continuously improve their courses and programs. Understanding the current state of practice of software engineering higher education can empower educators to critically assess their courses, fine-tune them by benchmarking against observed practices, and ultimately enhance their curricula. In this study, we aim to provide an encompassing analysis of higher education on software engineering by considering the higher educational offering of an entire European country, namely the Netherlands. We leverage a crowd-sourced analysis process by considering 10 Dutch universities and 207 university courses. The courses are analysed via knowledge areas adopted from the SWEBOK. The mapping process is refined via homogenisation and internal consistency improvement phases, and is followed by a data analysis phase. Given its fundamental nature, Construction and Programming is the most covered knowledge area at Bachelor level. Other knowledge areas are equally covered at Bachelor and Master level (e.g., software engineering models), while more advanced ones are almost exclusively covered at Master level. We identify three clusters of tightly coupled knowledge areas: (i) requirements, architecture, and design, (ii) testing, verification, and security, and (iii) process-oriented and DevOps topics. Dutch universities generally cover all knowledge areas uniformly, with minor deviations reflecting institutional research strengths. Our results highlight correlations among key knowledge areas and their potential for enhancing integrated learning. We also identify underrepresented areas, such as software engineering economics, which educators may consider including in curricula. We invite researchers to use our research method in their own geographical region, in order to contrast software engineering education programs across the globe.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5206\u6790\u8377\u517010\u6240\u5927\u5b66\u5171207\u95e8\u8bfe\u7a0b\uff0c\u57fa\u4e8eSWEBOK\u77e5\u8bc6\u9886\u57df\u5168\u9762\u8bc4\u4f30\u8f6f\u4ef6\u5de5\u7a0b\u9ad8\u7b49\u6559\u80b2\u73b0\u72b6\uff0c\u53d1\u73b0\u4e0d\u540c\u77e5\u8bc6\u9886\u57df\u5728\u672c\u79d1\u548c\u7855\u58eb\u9636\u6bb5\u7684\u8986\u76d6\u5dee\u5f02\uff0c\u5e76\u6307\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u7ecf\u6d4e\u5b66\u7b49\u9886\u57df\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u8bfe\u7a0b\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u9700\u6301\u7eed\u6539\u8fdb\uff0c\u7406\u89e3\u5f53\u524d\u9ad8\u7b49\u6559\u80b2\u5b9e\u8df5\u73b0\u72b6\u6709\u52a9\u4e8e\u6559\u80b2\u8005\u57fa\u4e8e\u5b9e\u9645\u60c5\u51b5\u4f18\u5316\u8bfe\u7a0b\u548c\u6574\u4f53\u6559\u5b66\u4f53\u7cfb\u3002", "method": "\u91c7\u7528\u57fa\u4e8eSWEBOK\u77e5\u8bc6\u9886\u57df\u7684\u6620\u5c04\u5206\u6790\u65b9\u6cd5\uff0c\u7ed3\u5408\u7fa4\u4f53\u8d44\u6e90\u91c7\u96c6\uff0c\u5206\u6790\u8377\u517010\u6240\u5927\u5b66207\u95e8\u8bfe\u7a0b\uff0c\u7ecf\u8fc7\u6570\u636e\u7684\u4e00\u81f4\u6027\u548c\u5747\u8d28\u6027\u5904\u7406\u540e\u8fdb\u884c\u6df1\u5165\u6570\u636e\u5206\u6790\u3002", "result": "\u53d1\u73b0\u672c\u79d1\u9636\u6bb5\u4ee5\u2018\u6784\u9020\u4e0e\u7f16\u7a0b\u2019\u4e3a\u6838\u5fc3\u77e5\u8bc6\u9886\u57df\uff0c\u5176\u4ed6\u9886\u57df\u5982\u6a21\u578b\u77e5\u8bc6\u5728\u672c\u79d1\u548c\u7855\u58eb\u5747\u6709\u8986\u76d6\uff0c\u590d\u6742\u9886\u57df\u591a\u96c6\u4e2d\u4e8e\u7855\u58eb\u3002\u540c\u65f6\u5f52\u7eb3\u51fa\u4e09\u7ec4\u7d27\u5bc6\u7ed3\u5408\u7684\u77e5\u8bc6\u9886\u57df\u96c6\u7fa4\uff0c\u8bfe\u7a0b\u5e03\u5c40\u8f83\u4e3a\u5747\u5300\uff0c\u4ec5\u5c11\u6570\u56e0\u7814\u7a76\u4f18\u52bf\u5b58\u5728\u504f\u5dee\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u5173\u952e\u77e5\u8bc6\u9886\u57df\u95f4\u7684\u8054\u7cfb\u53ca\u5176\u6574\u5408\u5b66\u4e60\u6f5c\u529b\uff0c\u6307\u51fa\u8f6f\u4ef6\u5de5\u7a0b\u7ecf\u6d4e\u5b66\u7b49\u9886\u57df\u88ab\u5ffd\u7565\u7684\u73b0\u72b6\uff0c\u5efa\u8bae\u6559\u80b2\u8005\u8003\u8651\u8865\u5145\u76f8\u5173\u5185\u5bb9\uff0c\u540c\u65f6\u9f13\u52b1\u5728\u5176\u4ed6\u5730\u533a\u590d\u5236\u8be5\u7814\u7a76\u4ee5\u4fc3\u8fdb\u5168\u7403\u8f6f\u4ef6\u5de5\u7a0b\u6559\u80b2\u5bf9\u6bd4\u4e0e\u6539\u8fdb\u3002"}}
{"id": "2512.12297", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12297", "abs": "https://arxiv.org/abs/2512.12297", "authors": ["Radu-Gabriel Chivereanu", "Tiberiu Boros"], "title": "F5-TTS-RO: Extending F5-TTS to Romanian TTS via Lightweight Input Adaptation", "comment": "Accepted at The 20th International Conference on Linguistic Resources and Tools for Natural Language Processing", "summary": "This work introduces a lightweight input-level adapter for the F5-TTS model that enables Romanian Language support. To preserve the existing capabilities of the model (voice cloning, English and Chinese support), we keep the original weights frozen, append a sub-network to the model and train it as an extension for the textual embedding matrix of the text encoder. For simplicity, we rely on ConvNeXt module implemented in F5-TTS to also model the co-dependencies between the new character-level embeddings. The module serves as a ``soft`` letter-to-sound layer, converting Romanian text into a continuous representation that the F5-TTS model uses to produce naturally sounding Romanian utterances. We evaluate the model with a pool of 20 human listeners across three tasks: (a) audio similarity between reference and generated speech, (b) pronunciation and naturalness and (c) Romanian-English code-switching. The results indicate that our approach maintains voice cloning capabilities and enables, to a certain extent, code-switching within the same utterance; however, residual English accent characteristics remain. We open-source our code and provide example audio samples at https://github.com/racai-ro/Ro-F5TTS.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u8f93\u5165\u5c42\u9002\u914d\u5668\uff0c\u7528\u4e8eF5-TTS\u6a21\u578b\u4ee5\u652f\u6301\u7f57\u9a6c\u5c3c\u4e9a\u8bed\uff0c\u5b9e\u73b0\u4e86\u5728\u4fdd\u6301\u539f\u6a21\u578b\u80fd\u529b\u7684\u540c\u65f6\u589e\u52a0\u8bed\u8a00\u652f\u6301\u3002", "motivation": "\u4e3a\u4e86\u6269\u5c55F5-TTS\u6a21\u578b\u652f\u6301\u7f57\u9a6c\u5c3c\u4e9a\u8bed\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u5176\u5df2\u6709\u7684\u8bed\u97f3\u514b\u9686\u53ca\u82f1\u4e2d\u8bed\u8a00\u652f\u6301\u80fd\u529b\u3002", "method": "\u51bb\u7ed3\u539f\u6a21\u578b\u6743\u91cd\uff0c\u9644\u52a0\u5b50\u7f51\u7edc\uff0c\u8bad\u7ec3\u6587\u672c\u7f16\u7801\u5668\u7684\u6587\u672c\u5d4c\u5165\u77e9\u9635\u6269\u5c55\u90e8\u5206\uff0c\u5229\u7528ConvNeXt\u6a21\u5757\u6a21\u62df\u5b57\u7b26\u7ea7\u5d4c\u5165\u7684\u76f8\u5173\u6027\uff0c\u5c06\u6587\u672c\u8f6c\u6362\u4e3a\u8fde\u7eed\u8868\u793a\u3002", "result": "\u6a21\u578b\u5728\u542c\u89c9\u76f8\u4f3c\u5ea6\u3001\u53d1\u97f3\u81ea\u7136\u5ea6\u548c\u7f57\u82f1\u6df7\u5408\u8bed\u97f3\u5207\u6362\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4fdd\u6301\u4e86\u8bed\u97f3\u514b\u9686\u80fd\u529b\uff0c\u4f46\u4ecd\u5e26\u6709\u6b8b\u7559\u7684\u82f1\u8bed\u53e3\u97f3\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86F5-TTS\u5bf9\u7f57\u9a6c\u5c3c\u4e9a\u8bed\u7684\u652f\u6301\uff0c\u4fdd\u6301\u539f\u6709\u529f\u80fd\u4e14\u5b9e\u73b0\u4e00\u5b9a\u7a0b\u5ea6\u7684\u4ee3\u7801\u5207\u6362\uff0c\u4ee3\u7801\u53ca\u793a\u4f8b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.12699", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12699", "abs": "https://arxiv.org/abs/2512.12699", "authors": ["Anrafel Fernandes Pereira", "Maria Teresa Baldassarre", "Daniel Mendez", "J\u00fcrgen B\u00f6rstler", "Nauman bin Ali", "Rahul Mohanani", "Darja Smite", "Stefan Biffl", "Rogardt Heldal", "Davide Falessi", "Daniel Graziotin", "Marcos Kalinowski"], "title": "Attributes to Support the Formulation of Practically Relevant Research Problems in Software Engineering", "comment": null, "summary": "[Background] A well-formulated research problem is essential for achieving practical relevance in Software Engineering (SE), yet there is a lack of structured guidance in this early phase. [Aims] Our goal is to introduce and evaluate seven attributes identified in the SE literature as relevant for formulating research problems (practical problem, context, implications/impacts, practitioners, evidence, objective, and research questions) in terms of their perceived importance and completeness, and learn how they can be applied. [Method] We conducted a workshop with 42 senior SE researchers during the ISERN 2024 meeting. The seven attributes were presented using a Problem Vision board filled with a research example. Participants discussed attributes in groups, shared written feedback, and individually completed a survey assessing their importance, completeness, and suggestions for improvement. [Results] The findings confirm the importance of the seven attributes in the formulation of industry-oriented research problems. Qualitative feedback illustrated how they can be applied in practice and revealed suggestions to refine them, such as incorporating financial criteria (e.g., ROI) into implications/impacts and addressing feasibility and constraints under evidence. [Conclusion] The results reaffirm the importance of the seven attributes in supporting a reflective and context-aware problem formulation. Adapting their use to specific research contexts can help to improve the alignment between academic research and industry needs.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u5e76\u8bc4\u4f30\u4e86\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u5236\u5b9a\u7814\u7a76\u95ee\u9898\u7684\u4e03\u4e2a\u5173\u952e\u5c5e\u6027\uff0c\u9a8c\u8bc1\u4e86\u5176\u91cd\u8981\u6027\u548c\u5e94\u7528\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u95ee\u9898\u7684\u6070\u5f53\u5236\u5b9a\u5bf9\u5b9e\u73b0\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u7684\u5b9e\u9645\u76f8\u5173\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u7f3a\u4e4f\u7cfb\u7edf\u6307\u5bfc\u3002", "method": "\u901a\u8fc7ISERN 2024\u4f1a\u8bae\u4e0e42\u4f4d\u8d44\u6df1\u7814\u7a76\u5458\u5f00\u5c55\u5de5\u4f5c\u574a\uff0c\u5229\u7528Problem Vision\u677f\u5448\u73b0\u4e03\u4e2a\u5c5e\u6027\uff0c\u5e76\u6536\u96c6\u53cd\u9988\u548c\u8c03\u67e5\u6570\u636e\u3002", "result": "\u9a8c\u8bc1\u4e86\u4e03\u4e2a\u5c5e\u6027\u5728\u884c\u4e1a\u5bfc\u5411\u7814\u7a76\u95ee\u9898\u5236\u5b9a\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u6536\u96c6\u4e86\u5b9e\u8df5\u5e94\u7528\u5efa\u8bae\uff0c\u5982\u52a0\u5165\u8d22\u52a1\u6807\u51c6\u53ca\u53ef\u884c\u6027\u5206\u6790\u3002", "conclusion": "\u4e03\u4e2a\u5c5e\u6027\u6709\u52a9\u4e8e\u53cd\u601d\u6027\u548c\u5177\u4e0a\u4e0b\u6587\u610f\u8bc6\u7684\u95ee\u9898\u5236\u5b9a\uff0c\u9002\u5e94\u5177\u4f53\u7814\u7a76\u60c5\u5883\u53ef\u63d0\u5347\u5b66\u672f\u4e0e\u5de5\u4e1a\u9700\u6c42\u7684\u5951\u5408\u5ea6\u3002"}}
{"id": "2512.12337", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12337", "abs": "https://arxiv.org/abs/2512.12337", "authors": ["Yushen Fang", "Jianjun Li", "Mingqian Ding", "Chang Liu", "Xinchi Zou", "Wenqi Yang"], "title": "SCIR: A Self-Correcting Iterative Refinement Framework for Enhanced Information Extraction Based on Schema", "comment": null, "summary": "Although Large language Model (LLM)-powered information extraction (IE) systems have shown impressive capabilities, current fine-tuning paradigms face two major limitations: high training costs and difficulties in aligning with LLM preferences. To address these issues, we propose a novel universal IE paradigm, the Self-Correcting Iterative Refinement (SCIR) framework, along with a Multi-task Bilingual (Chinese-English) Self-Correcting (MBSC) dataset containing over 100,000 entries. The SCIR framework achieves plug-and-play compatibility with existing LLMs and IE systems through its Dual-Path Self-Correcting module and feedback-driven optimization, thereby significantly reducing training costs. Concurrently, the MBSC dataset tackles the challenge of preference alignment by indirectly distilling GPT-4's capabilities into IE result detection models. Experimental results demonstrate that SCIR outperforms state-of-the-art IE methods across three key tasks: named entity recognition, relation extraction, and event extraction, achieving a 5.27 percent average improvement in span-based Micro-F1 while reducing training costs by 87 percent compared to baseline approaches. These advancements not only enhance the flexibility and accuracy of IE systems but also pave the way for lightweight and efficient IE paradigms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u9002\u7528\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u606f\u63d0\u53d6\u6846\u67b6SCIR\u53ca\u591a\u4efb\u52a1\u4e2d\u82f1\u81ea\u6821\u6b63\u6570\u636e\u96c6MBSC\uff0c\u5728\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u7684\u540c\u65f6\u63d0\u5347\u4e86\u4fe1\u606f\u63d0\u53d6\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\u9762\u4e34\u8bad\u7ec3\u6210\u672c\u9ad8\u548c\u96be\u4ee5\u4e0e\u6a21\u578b\u504f\u597d\u5bf9\u9f50\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86SCIR\u6846\u67b6\uff0c\u5229\u7528\u53cc\u8def\u5f84\u81ea\u6821\u6b63\u6a21\u5757\u53ca\u53cd\u9988\u9a71\u52a8\u4f18\u5316\uff0c\u5b9e\u73b0\u4e0e\u73b0\u6709\u6a21\u578b\u7684\u5373\u63d2\u5373\u7528\uff0c\u5e76\u8bbe\u8ba1MBSC\u6570\u636e\u96c6\u901a\u8fc7\u95f4\u63a5\u84b8\u998fGPT-4\u80fd\u529b\u89e3\u51b3\u504f\u597d\u5bf9\u9f50\u95ee\u9898\u3002", "result": "SCIR\u5728\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u3001\u5173\u7cfb\u62bd\u53d6\u548c\u4e8b\u4ef6\u62bd\u53d6\u4e09\u4efb\u52a1\u4e0a\uff0c\u5fae\u5e73\u5747F1\u5206\u6570\u63d0\u5347\u4e865.27%\uff0c\u8bad\u7ec3\u6210\u672c\u964d\u4f4e\u4e8687%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u4fe1\u606f\u63d0\u53d6\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u4e0e\u7075\u6d3b\u6027\uff0c\u4e3a\u8f7b\u91cf\u9ad8\u6548\u7684\u4fe1\u606f\u63d0\u53d6\u65b9\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.12719", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12719", "abs": "https://arxiv.org/abs/2512.12719", "authors": ["Anrafel Fernandes Pereira", "Maria Teresa Baldassarre", "Daniel Mendez", "Marcos Kalinowski"], "title": "Towards AI Agents Supported Research Problem Formulation", "comment": null, "summary": "Poorly formulated research problems can compromise the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence agents to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a published study on code maintainability in machine learning as a reference, we developed a descriptive evaluation of a scenario illustrating how AI agents, integrated into LRI, can support SE researchers by pre filling problem attributes, aligning stakeholder perspectives, refining research questions, simulating multiperspective assessments, and supporting decision making. The descriptive evaluation of the scenario suggests that AI agent support can enrich collaborative discussions and enhance critical reflection on the value, feasibility, and applicability of the research problem. Although the vision of integrating AI agents into LRI was perceived as promising to support the context aware and practice oriented formulation of research problems, empirical validation is needed to confirm and refine the integration of AI agents into problem formulation.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u5229\u7528\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u652f\u6301\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u4e2d\u7814\u7a76\u95ee\u9898\u7684\u65e9\u671f\u5f62\u6210\uff0c\u4ee5\u63d0\u5347\u95ee\u9898\u7684\u5b9e\u9645\u76f8\u5173\u6027\u3002", "motivation": "\u73b0\u6709\u8f6f\u4ef6\u5de5\u7a0b\u7814\u7a76\u95ee\u9898\u8bbe\u5b9a\u6b20\u4f73\uff0c\u672a\u80fd\u53cd\u6620\u5de5\u4e1a\u5b9e\u8df5\u7684\u590d\u6742\u6027\uff0c\u5f71\u54cd\u7814\u7a76\u7684\u5b9e\u9645\u76f8\u5173\u6027\u3002", "method": "\u57fa\u4e8eLean Research Inception\u6846\u67b6\uff0c\u7ed3\u5408\u673a\u5668\u5b66\u4e60\u4ee3\u7801\u53ef\u7ef4\u62a4\u6027\u6848\u4f8b\uff0c\u8bbe\u8ba1\u5e76\u63cf\u8ff0AI\u4ee3\u7406\u652f\u6301\u7814\u7a76\u95ee\u9898\u5f62\u6210\u7684\u573a\u666f\uff0c\u5305\u62ec\u9884\u586b\u95ee\u9898\u5c5e\u6027\u3001\u534f\u8c03\u5229\u76ca\u76f8\u5173\u8005\u89c2\u70b9\u3001\u7ec6\u5316\u7814\u7a76\u95ee\u9898\u3001\u6a21\u62df\u591a\u89d2\u5ea6\u8bc4\u4f30\u4e0e\u51b3\u7b56\u652f\u6301\u3002", "result": "\u63cf\u8ff0\u6027\u8bc4\u4f30\u8868\u660e\uff0cAI\u4ee3\u7406\u652f\u6301\u6709\u52a9\u4e8e\u4e30\u5bcc\u534f\u4f5c\u8ba8\u8bba\u3001\u589e\u5f3a\u5bf9\u7814\u7a76\u95ee\u9898\u4ef7\u503c\u3001\u53ef\u884c\u6027\u53ca\u9002\u7528\u6027\u7684\u5173\u952e\u53cd\u601d\u3002", "conclusion": "AI\u4ee3\u7406\u96c6\u6210\u5230LRI\u4e2d\u6709\u671b\u652f\u6301\u66f4\u5177\u60c5\u5883\u611f\u77e5\u548c\u5b9e\u8df5\u5bfc\u5411\u7684\u7814\u7a76\u95ee\u9898\u5f62\u6210\uff0c\u4f46\u4ecd\u9700\u5b9e\u8bc1\u9a8c\u8bc1\u4ee5\u786e\u8ba4\u548c\u5b8c\u5584\u96c6\u6210\u65b9\u6848\u3002"}}
{"id": "2512.12444", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12444", "abs": "https://arxiv.org/abs/2512.12444", "authors": ["Veronica Mangiaterra", "Hamad Al-Azary", "Chiara Barattieri di San Pietro", "Paolo Canal", "Valentina Bambini"], "title": "Can GPT replace human raters? Validity and reliability of machine-generated norms for metaphors", "comment": "30 pages, 5 figures", "summary": "As Large Language Models (LLMs) are increasingly being used in scientific research, the issue of their trustworthiness becomes crucial. In psycholinguistics, LLMs have been recently employed in automatically augmenting human-rated datasets, with promising results obtained by generating ratings for single words. Yet, performance for ratings of complex items, i.e., metaphors, is still unexplored. Here, we present the first assessment of the validity and reliability of ratings of metaphors on familiarity, comprehensibility, and imageability, generated by three GPT models for a total of 687 items gathered from the Italian Figurative Archive and three English studies. We performed a thorough validation in terms of both alignment with human data and ability to predict behavioral and electrophysiological responses. We found that machine-generated ratings positively correlated with human-generated ones. Familiarity ratings reached moderate-to-strong correlations for both English and Italian metaphors, although correlations weakened for metaphors with high sensorimotor load. Imageability showed moderate correlations in English and moderate-to-strong in Italian. Comprehensibility for English metaphors exhibited the strongest correlations. Overall, larger models outperformed smaller ones and greater human-model misalignment emerged with familiarity and imageability. Machine-generated ratings significantly predicted response times and the EEG amplitude, with a strength comparable to human ratings. Moreover, GPT ratings obtained across independent sessions were highly stable. We conclude that GPT, especially larger models, can validly and reliably replace - or augment - human subjects in rating metaphor properties. Yet, LLMs align worse with humans when dealing with conventionality and multimodal aspects of metaphorical meaning, calling for careful consideration of the nature of stimuli.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u8bc4\u4f30\u4e86GPT\u6a21\u578b\u5728\u5f62\u8c61\u6027\u3001\u6613\u61c2\u6027\u548c\u719f\u6089\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u5bf9\u9690\u55bb\u8fdb\u884c\u8bc4\u5206\u7684\u6709\u6548\u6027\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u79d1\u5b66\u7814\u7a76\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5176\u53ef\u4fe1\u5ea6\u95ee\u9898\u65e5\u76ca\u91cd\u8981\uff0c\u5c24\u5176\u662f\u5bf9\u590d\u6742\u8bed\u8a00\u9879\u76ee\u5982\u9690\u55bb\u7684\u81ea\u52a8\u8bc4\u5206\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u57fa\u4e8e687\u4e2a\u610f\u5927\u5229\u548c\u82f1\u8bed\u9690\u55bb\uff0c\u5229\u7528\u4e09\u79cdGPT\u6a21\u578b\u751f\u6210\u6307\u6807\u8bc4\u5206\uff0c\u5e76\u901a\u8fc7\u4e0e\u4eba\u7c7b\u8bc4\u5206\u7684\u5bf9\u9f50\u4ee5\u53ca\u884c\u4e3a\u548c\u8111\u7535\u53cd\u5e94\u7684\u9884\u6d4b\u80fd\u529b\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u673a\u5668\u8bc4\u5206\u4e0e\u4eba\u7c7b\u8bc4\u5206\u6b63\u76f8\u5173\uff0c\u5c24\u5176\u662f\u5728\u719f\u6089\u5ea6\uff08\u4e2d\u5230\u5f3a\uff09\u3001\u5f62\u8c61\u6027\uff08\u4e2d\u5230\u5f3a\uff09\u548c\u6613\u61c2\u6027\uff08\u6700\u5f3a\u76f8\u5173\uff09\u65b9\u9762\uff0c\u4e14\u5927\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5c0f\u6a21\u578b\u3002\u673a\u5668\u8bc4\u5206\u8fd8\u80fd\u663e\u8457\u9884\u6d4b\u54cd\u5e94\u65f6\u95f4\u548c\u8111\u7535\u632f\u5e45\uff0c\u4e14\u8bc4\u5206\u7a33\u5b9a\u6027\u9ad8\u3002", "conclusion": "\u8f83\u5927\u7684GPT\u6a21\u578b\u80fd\u591f\u6709\u6548\u4e14\u7a33\u5b9a\u5730\u66ff\u4ee3\u6216\u589e\u5f3a\u4eba\u7c7b\u5bf9\u9690\u55bb\u5c5e\u6027\u7684\u8bc4\u5206\uff0c\u4f46\u5728\u4f20\u7edf\u6027\u548c\u591a\u6a21\u6001\u610f\u4e49\u5904\u7406\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8c28\u614e\u8003\u8651\u523a\u6fc0\u6027\u8d28\u3002"}}
{"id": "2512.12788", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12788", "abs": "https://arxiv.org/abs/2512.12788", "authors": ["Manuel Bentele", "Andreas Podelski", "Axel Sikora", "Bernd Westphal"], "title": "Temporal HAL-API Dependencies as a Gateway to Formal Embedded Software Development", "comment": null, "summary": "Temporal HAL-API Dependencies (THADs) can be useful to capture an interesting class of correctness properties in embedded software development. They demand a moderate effort for specification (which can be done via program annotations) and verification (which can be done automatically via software model checking). In this sense, they have the potential to form an interesting sweet spot between generic properties (that demand virtually no specification effort, and that are typically addressed by static analysis) and application-specific properties as addressed by full-fledged formal methods. Thus, they may form a gateway to wider and more economic use of formal methods in industrial embedded software development.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u65f6\u95f4\u6027HAL-API\u4f9d\u8d56\uff08THADs\uff09\uff0c\u4e00\u79cd\u9002\u7528\u4e8e\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u7684\u6b63\u786e\u6027\u5c5e\u6027\uff0c\u7ed3\u5408\u6ce8\u91ca\u8fdb\u884c\u4e2d\u7b49\u91cf\u89c4\u8303\u548c\u81ea\u52a8\u6a21\u578b\u68c0\u6d4b\u9a8c\u8bc1\uff0c\u6709\u671b\u6210\u4e3a\u9759\u6001\u5206\u6790\u548c\u5b8c\u6574\u5f62\u5f0f\u65b9\u6cd5\u4e4b\u95f4\u7684\u6298\u4e2d\u65b9\u6848\u3002", "motivation": "\u5e0c\u671b\u5728\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5b9e\u73b0\u4e00\u79cd\u65e2\u4e0d\u9700\u5927\u91cf\u89c4\u8303\uff0c\u53c8\u80fd\u9a8c\u8bc1\u5e94\u7528\u7279\u5b9a\u6b63\u786e\u6027\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4f7f\u7528\u7a0b\u5e8f\u6ce8\u91ca\u8fdb\u884cTHADs\u89c4\u8303\uff0c\u5e76\u5e94\u7528\u8f6f\u4ef6\u6a21\u578b\u68c0\u6d4b\u81ea\u52a8\u9a8c\u8bc1\u3002", "result": "THADs\u63d0\u4f9b\u4e86\u4e00\u79cd\u89c4\u8303\u5f00\u9500\u9002\u4e2d\u4e14\u53ef\u81ea\u52a8\u9a8c\u8bc1\u7684\u6b63\u786e\u6027\u5c5e\u6027\u3002", "conclusion": "THADs\u6709\u6f5c\u529b\u6210\u4e3a\u5de5\u4e1a\u5d4c\u5165\u5f0f\u8f6f\u4ef6\u4e2d\u5f62\u5f0f\u65b9\u6cd5\u66f4\u5e7f\u6cdb\u4e14\u7ecf\u6d4e\u7684\u5207\u5165\u70b9\u3002"}}
{"id": "2512.12447", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12447", "abs": "https://arxiv.org/abs/2512.12447", "authors": ["Gary Lupyan"], "title": "Large language models have learned to use language", "comment": "Commentary on Futrell & Mahowald's How Linguistics Learned to Stop Worrying and Love the Language Models (BBS, Forthcoming)", "summary": "Acknowledging that large language models have learned to use language can open doors to breakthrough language science. Achieving these breakthroughs may require abandoning some long-held ideas about how language knowledge is evaluated and reckoning with the difficult fact that we have entered a post-Turing test era.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5df2\u5b66\u4f1a\u4f7f\u7528\u8bed\u8a00\uff0c\u547c\u5401\u7a81\u7834\u4f20\u7edf\u8bed\u8a00\u77e5\u8bc6\u8bc4\u4f30\u65b9\u6cd5\uff0c\u9002\u5e94\u540e\u56fe\u7075\u6d4b\u8bd5\u65f6\u4ee3\u3002", "motivation": "\u4f5c\u8005\u8ba4\u4e3a\u4f20\u7edf\u8bed\u8a00\u77e5\u8bc6\u7684\u8bc4\u4f30\u65b9\u5f0f\u5df2\u4e0d\u80fd\u6ee1\u8db3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u4e9f\u9700\u65b0\u7684\u7406\u5ff5\u6765\u63a8\u52a8\u8bed\u8a00\u79d1\u5b66\u7684\u7a81\u7834\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u8a00\u4f7f\u7528\u80fd\u529b\uff0c\u63d0\u51fa\u5e94\u6452\u5f03\u90e8\u5206\u65e7\u6709\u89c2\u5ff5\uff0c\u91cd\u65b0\u601d\u8003\u8bed\u8a00\u77e5\u8bc6\u7684\u8bc4\u4f30\u6807\u51c6\u3002", "result": "\u6307\u51fa\u6211\u4eec\u5df2\u8fdb\u5165\u540e\u56fe\u7075\u6d4b\u8bd5\u65f6\u4ee3\uff0c\u4f20\u7edf\u8bc4\u6d4b\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "conclusion": "\u627f\u8ba4\u5927\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u8a00\u4f7f\u7528\u80fd\u529b\uff0c\u5c06\u6709\u52a9\u4e8e\u63a8\u52a8\u8bed\u8a00\u79d1\u5b66\u7684\u53d1\u5c55\uff0c\u8981\u6c42\u63a5\u53d7\u65b0\u7684\u8bc4\u4f30\u7406\u5ff5\u3002"}}
{"id": "2512.12965", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.12965", "abs": "https://arxiv.org/abs/2512.12965", "authors": ["Thayssa Rocha", "Luciano Teran", "Marcelle Mota", "Cleidson de Souza", "Kiev Gama", "Gustavo Pinto"], "title": "Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams", "comment": "11 pages", "summary": "The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \\totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8fdc\u7a0b\u5de5\u4f5c\u5982\u4f55\u5f71\u54cd\u6b8b\u75be\u4eba\u5728\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u4e2d\u7684\u4f53\u9a8c\uff0c\u53d1\u73b0\u56e2\u961f\u9886\u5bfc\u548c\u6210\u5458\u5bf9\u6b8b\u75be\u4eba\u9762\u4e34\u7684\u534f\u4f5c\u6311\u6218\u8ba4\u8bc6\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u6539\u8fdb\u65e0\u969c\u788d\u5de5\u5177\u3001\u6c9f\u901a\u7b56\u7565\u548c\u7ba1\u7406\u65b9\u6cd5\u7684\u5efa\u8bae\u3002", "motivation": "\u968f\u7740\u8fdc\u7a0b\u548c\u6df7\u5408\u5de5\u4f5c\u6a21\u5f0f\u7684\u666e\u53ca\uff0c\u6b8b\u75be\u4eba\u5728\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u4e2d\u7684\u5305\u5bb9\u6027\u95ee\u9898\u65e5\u76ca\u7a81\u51fa\uff0c\u9700\u8981\u6df1\u5165\u4e86\u89e3\u8fdc\u7a0b\u5de5\u4f5c\u5bf9\u4ed6\u4eec\u4f53\u9a8c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7ebf\u4e0a\u95ee\u5377\u8c03\u67e5\uff08\u5305\u62ec\u6b8b\u75be\u4eba\u3001\u9886\u5bfc\u548c\u540c\u4e8b\uff09\u53ca14\u6b21\u7ed3\u6784\u5316\u91c7\u8bbf\uff08\u81ea\u8ba4\u6b8b\u75be\u7684\u8f6f\u4ef6\u5f00\u53d1\u8005\uff09\uff0c\u7ed3\u5408\u5b9a\u91cf\u6570\u636e\u4e0e\u5b9a\u6027\u7f16\u7801\u5206\u6790\u3002", "result": "\u6b8b\u75be\u56e2\u961f\u6210\u5458\u5728\u8fdc\u7a0b\u534f\u4f5c\u4e2d\u9762\u4e34\u969c\u788d\uff0c\u4f46\u56e2\u961f\u9886\u5bfc\u548c\u6210\u5458\u5bf9\u8fd9\u4e9b\u6311\u6218\u7684\u611f\u77e5\u6709\u9650\uff0c\u8868\u660e\u5b58\u5728\u7406\u89e3\u548c\u652f\u6301\u4e0d\u8db3\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6539\u5584\u65e0\u969c\u788d\u5de5\u5177\u3001\u4f18\u5316\u6c9f\u901a\u548c\u9002\u5e94\u6027\u7ba1\u7406\u4ee5\u63d0\u5347\u6b8b\u75be\u4eba\u5728\u8fdc\u7a0b\u8f6f\u4ef6\u5f00\u53d1\u56e2\u961f\u4e2d\u5305\u5bb9\u6027\u7684\u6f5c\u529b\u548c\u5fc5\u8981\u6027\u3002"}}
{"id": "2512.12488", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12488", "abs": "https://arxiv.org/abs/2512.12488", "authors": ["James Luther", "Donald Brown"], "title": "The American Ghost in the Machine: How language models align culturally and the effects of cultural prompting", "comment": null, "summary": "Culture is the bedrock of human interaction; it dictates how we perceive and respond to everyday interactions. As the field of human-computer interaction grows via the rise of generative Large Language Models (LLMs), the cultural alignment of these models become an important field of study. This work, using the VSM13 International Survey and Hofstede's cultural dimensions, identifies the cultural alignment of popular LLMs (DeepSeek-V3, V3.1, GPT-5, GPT-4.1, GPT-4, Claude Opus 4, Llama 3.1, and Mistral Large). We then use cultural prompting, or using system prompts to shift the cultural alignment of a model to a desired country, to test the adaptability of these models to other cultures, namely China, France, India, Iran, Japan, and the United States. We find that the majority of the eight LLMs tested favor the United States when the culture is not specified, with varying results when prompted for other cultures. When using cultural prompting, seven of the eight models shifted closer to the expected culture. We find that models had trouble aligning with Japan and China, despite two of the models tested originating with the Chinese company DeepSeek.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6587\u5316\u9002\u5e94\u6027\uff0c\u53d1\u73b0\u5927\u90e8\u5206\u6a21\u578b\u9ed8\u8ba4\u504f\u5411\u7f8e\u56fd\u6587\u5316\uff0c\u901a\u8fc7\u6587\u5316\u63d0\u793a\u53ef\u4ee5\u8c03\u6574\u6a21\u578b\u6587\u5316\u503e\u5411\uff0c\u4f46\u5bf9\u65e5\u672c\u548c\u4e2d\u56fd\u6587\u5316\u9002\u5e94\u8f83\u5dee\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u53d1\u5c55\uff0c\u6a21\u578b\u7684\u6587\u5316\u5bf9\u9f50\u53d8\u5f97\u5c24\u4e3a\u91cd\u8981\uff0c\u5c24\u5176\u5728\u4eba\u673a\u4ea4\u4e92\u4e2d\uff0c\u6587\u5316\u5dee\u5f02\u4f1a\u663e\u8457\u5f71\u54cd\u4ea4\u4e92\u6548\u679c\u3002", "method": "\u5229\u7528VSM13\u56fd\u9645\u8c03\u67e5\u548c\u970d\u592b\u65af\u6cf0\u5fb7\u6587\u5316\u7ef4\u5ea6\u6846\u67b6\uff0c\u8bc4\u4f30\u516b\u4e2a\u4e3b\u6d41LLMs\u7684\u6587\u5316\u503e\u5411\uff1b\u901a\u8fc7\u6587\u5316\u63d0\u793a\uff08system prompt\uff09\u5c06\u6a21\u578b\u6587\u5316\u5bf9\u9f50\u5230\u4e2d\u56fd\u3001\u6cd5\u56fd\u3001\u5370\u5ea6\u3001\u4f0a\u6717\u3001\u65e5\u672c\u548c\u7f8e\u56fd\uff0c\u6d4b\u8bd5\u6a21\u578b\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\u3002", "result": "\u9664\u65e5\u672c\u548c\u4e2d\u56fd\u5916\uff0c\u4e03\u4e2a\u6a21\u578b\u901a\u8fc7\u6587\u5316\u63d0\u793a\u80fd\u663e\u8457\u8c03\u6574\u5176\u6587\u5316\u503e\u5411\uff1b\u5927\u90e8\u5206\u6a21\u578b\u9ed8\u8ba4\u504f\u5411\u7f8e\u56fd\u6587\u5316\uff0c\u5373\u4f7f\u6709\u4e24\u6b3e\u6a21\u578b\u7531\u4e2d\u56fd\u516c\u53f8DeepSeek\u5f00\u53d1\uff0c\u4f46\u5bf9\u4e2d\u56fd\u6587\u5316\u9002\u5e94\u6027\u8f83\u5f31\u3002", "conclusion": "\u5c3d\u7ba1\u4e3b\u6d41LLMs\u5177\u6709\u4e00\u5b9a\u7684\u6587\u5316\u9002\u5e94\u80fd\u529b\uff0c\u4f46\u5728\u9488\u5bf9\u7279\u5b9a\u6587\u5316\uff08\u5c24\u5176\u662f\u65e5\u672c\u548c\u4e2d\u56fd\uff09\u65f6\u4ecd\u5b58\u5728\u6311\u6218\uff0c\u63d0\u793a\u672a\u6765\u6a21\u578b\u5728\u6587\u5316\u591a\u6837\u6027\u548c\u9002\u5e94\u6027\u65b9\u9762\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u3002"}}
{"id": "2512.13239", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13239", "abs": "https://arxiv.org/abs/2512.13239", "authors": ["Eddy Kiomba Kambilo", "Nicolas Herbaut", "Irina Rychkova", "Carine Souveyet"], "title": "A Decision Support Framework for Blockchain Pattern Selection Based on Soft Goals", "comment": null, "summary": "Blockchain technology is gaining momentum across many sectors. Whereas blockchain solutions have important positive effects on the business domain, they also introduce constraints and may cause delayed or unforeseen negative effects, undermining business strategies. The diversity of blockchain patterns and lack of standardized frameworks linking business goals to technical design decisions make pattern selection a complex task for system architects. To address this challenge, we propose Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM), a decision support framework that combines ontologies of blockchain patterns and domain-independent soft goals with a multi-criteria decision-making approach. The framework focuses on the interplay between a domain expert and a technical expert to ensure alignment and traceability. By iteratively capturing and refining preferences, BC-TEAEM supports systematic selection of blockchain patterns. We develop a prototype decision support tool implementing our method and validate it through a case study of a pharmaceutical company's supply chain traceability system, demonstrating the framework's applicability. %a supply chain traceability case study.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u533a\u5757\u94fe\u6a21\u5f0f\u672c\u4f53\u548c\u8f6f\u76ee\u6807\u7684\u51b3\u7b56\u652f\u6301\u6846\u67b6BC-TEAEM\uff0c\u5e2e\u52a9\u7cfb\u7edf\u67b6\u6784\u5e08\u5728\u533a\u5757\u94fe\u65b9\u6848\u9009\u62e9\u4e0a\u5b9e\u73b0\u4e1a\u52a1\u76ee\u6807\u4e0e\u6280\u672f\u8bbe\u8ba1\u7684\u5bf9\u9f50\u3002", "motivation": "\u533a\u5757\u94fe\u65b9\u6848\u591a\u6837\u4e14\u7f3a\u4e4f\u7edf\u4e00\u6846\u67b6\uff0c\u5c06\u4e1a\u52a1\u76ee\u6807\u4e0e\u6280\u672f\u8bbe\u8ba1\u51b3\u7b56\u5173\u8054\u590d\u6742\uff0c\u5bfc\u81f4\u9009\u578b\u56f0\u96be\u53ca\u6f5c\u5728\u8d1f\u9762\u5f71\u54cd\u3002", "method": "BC-TEAEM\u6846\u67b6\u7ed3\u5408\u533a\u5757\u94fe\u6a21\u5f0f\u672c\u4f53\u548c\u9886\u57df\u65e0\u5173\u7684\u8f6f\u76ee\u6807\uff0c\u91c7\u7528\u591a\u51c6\u5219\u51b3\u7b56\u65b9\u6cd5\uff0c\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u4e0e\u6280\u672f\u4e13\u5bb6\u7684\u4e92\u52a8\u8fed\u4ee3\u6355\u6349\u504f\u597d\uff0c\u652f\u6301\u533a\u5757\u94fe\u6a21\u5f0f\u7684\u7cfb\u7edf\u9009\u62e9\u3002", "result": "\u5f00\u53d1\u4e86\u57fa\u4e8eBC-TEAEM\u7684\u51b3\u7b56\u652f\u6301\u5de5\u5177\u539f\u578b\uff0c\u5e76\u901a\u8fc7\u5236\u836f\u4f01\u4e1a\u4f9b\u5e94\u94fe\u8ffd\u6eaf\u7cfb\u7edf\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002", "conclusion": "BC-TEAEM\u6846\u67b6\u6709\u6548\u4fc3\u8fdb\u4e86\u533a\u5757\u94fe\u65b9\u6848\u9009\u62e9\u8fc7\u7a0b\u4e2d\u7684\u4e1a\u52a1\u4e0e\u6280\u672f\u5bf9\u9f50\uff0c\u63d0\u9ad8\u4e86\u51b3\u7b56\u7684\u7cfb\u7edf\u6027\u548c\u53ef\u8ffd\u6eaf\u6027\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u4f01\u4e1a\u573a\u666f\u3002"}}
{"id": "2512.12537", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12537", "abs": "https://arxiv.org/abs/2512.12537", "authors": ["Agniva Maiti", "Manya Pandey", "Murari Mandal"], "title": "NagaNLP: Bootstrapping NLP for Low-Resource Nagamese Creole with Human-in-the-Loop Synthetic Data", "comment": null, "summary": "The vast majority of the world's languages, particularly creoles like Nagamese, remain severely under-resourced in Natural Language Processing (NLP), creating a significant barrier to their representation in digital technology. This paper introduces NagaNLP, a comprehensive open-source toolkit for Nagamese, bootstrapped through a novel methodology that relies on LLM-driven but human-validated synthetic data generation. We detail a multi-stage pipeline where an expert-guided LLM (Gemini) generates a candidate corpus, which is then refined and annotated by native speakers. This synthetic-hybrid approach yielded a 10K pair conversational dataset and a high-quality annotated corpus for foundational tasks. To assess the effectiveness of our methodology, we trained both discriminative and generative models. Our fine-tuned XLM-RoBERTa-base model establishes a new benchmark for Nagamese, achieving a 93.81\\% accuracy (0.90 F1-Macro) on Part-of-Speech tagging and a 0.75 F1-Macro on Named Entity Recognition, massively outperforming strong zero-shot baselines. Furthermore, we fine-tuned a Llama-3.2-3B Instruct model, named NagaLLaMA, which demonstrates superior performance on conversational tasks, achieving a Perplexity of 3.85, an order of magnitude improvement over its few-shot counterpart (96.76). We release the NagaNLP toolkit, including all datasets, models, and code, providing a foundational resource for a previously underserved language and a reproducible framework for reducing data scarcity in other low-resource contexts.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86NagaNLP\uff0c\u4e00\u4e2a\u9488\u5bf9Nagamese\u514b\u91cc\u5965\u5c14\u8bed\u7684\u5f00\u6e90\u81ea\u7136\u8bed\u8a00\u5904\u7406\u5de5\u5177\u5305\uff0c\u901a\u8fc7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5e76\u7531\u672c\u5730\u4eba\u6821\u9a8c\u7684\u5408\u6210-\u6df7\u5408\u6570\u636e\u6784\u5efa\u8bed\u6599\u5e93\u3002\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u8bcd\u6027\u6807\u6ce8\u548c\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8d8a\u96f6\u6837\u672c\u57fa\u7ebf\u3002", "motivation": "Nagamese\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u9886\u57df\u8d44\u6e90\u532e\u4e4f\uff0c\u9650\u5236\u4e86\u5176\u5728\u6570\u5b57\u6280\u672f\u4e2d\u7684\u5e94\u7528\u548c\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u9636\u6bb5\u6d41\u7a0b\uff0c\u5229\u7528\u4e13\u5bb6\u5f15\u5bfc\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08Gemini\uff09\u751f\u6210\u5019\u9009\u8bed\u6599\uff0c\u518d\u7531\u6bcd\u8bed\u8005\u8fdb\u884c\u7cbe\u7ec6\u5316\u548c\u6807\u6ce8\uff0c\u5f62\u6210\u9ad8\u8d28\u91cf\u5408\u6210-\u6df7\u5408\u6570\u636e\u96c6\u3002\u540c\u65f6\uff0c\u8bad\u7ec3\u533a\u5206\u5f0f\u548c\u751f\u6210\u5f0f\u6a21\u578b\u4ee5\u8bc4\u4f30\u65b9\u6cd5\u6548\u679c\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542b1\u4e07\u5bf9\u8bdd\u8bed\u6599\u548c\u9ad8\u8d28\u91cf\u6807\u6ce8\u8bed\u6599\u7684\u8d44\u6e90\uff0cXLM-RoBERTa-base\u6a21\u578b\u5728\u8bcd\u6027\u6807\u6ce8\u4efb\u52a1\u4e2d\u8fbe93.81%\u51c6\u786e\u7387\u548c0.90 F1-Macro\uff0cNER\u4efb\u52a1F1-Macro\u4e3a0.75\uff0c\u663e\u8457\u4f18\u4e8e\u96f6\u6837\u672c\u57fa\u7ebf\u3002NagaLLaMA\u5bf9\u8bdd\u6a21\u578b\u5728\u56f0\u60d1\u5ea6\u6307\u6807\u4e0a\u8fbe\u52303.85\uff0c\u4f18\u4e8efew-shot\u6a21\u578b\u8fd1\u5341\u500d\u3002", "conclusion": "NagaNLP\u5de5\u5177\u5305\u5168\u9762\u91ca\u653e\u4e86Nagamese\u8bed\u8a00\u7684NLP\u6f5c\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e30\u5bcc\u7684\u6570\u636e\u548c\u6a21\u578b\u8d44\u6e90\uff0c\u6709\u6548\u7f13\u89e3\u4f4e\u8d44\u6e90\u8bed\u8a00\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u5e76\u4e3a\u5176\u4ed6\u7c7b\u4f3c\u8bed\u8a00\u7684\u8d44\u6e90\u5f00\u53d1\u5efa\u7acb\u4e86\u53ef\u590d\u73b0\u7684\u6846\u67b6\u3002"}}
{"id": "2512.13360", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13360", "abs": "https://arxiv.org/abs/2512.13360", "authors": ["Shuyuan Xiao", "Yiran Zhang", "Weisong Sun", "Xiaohong Chen", "Yang Liu", "Zhi Jin"], "title": "UCRBench: Benchmarking LLMs on Use Case Recovery", "comment": null, "summary": "Use cases are widely employed to specify functional requirements, yet existing benchmarks are scarce and face the risk of being misaligned with actual system behavior, similarly limiting the rigorous evaluation of large language models (LLMs) in generating use cases from source code. We address this gap by introducing code-aligned use case benchmarks, constructed through manual validation of both user-goal and subfunction use cases across nine real-world software projects. Using this benchmark, we conduct the first systematic study of LLMs and propose a hierarchical evaluation protocol that assesses actor correctness, name accuracy, path fidelity, and behavioral coverage. The results show that while LLMs can partially reconstruct system functionality, their performance varies significantly across projects, with particularly noticeable shortcomings in domain-specific and multi-module systems. The models also exhibit high omission rates and struggle to maintain consistent abstraction when aggregating subfunctions into user-goal use cases, highlighting both the potential and current limitations of LLM-based use case reverse engineering.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u73b0\u6709\u7528\u4f8b\u57fa\u51c6\u532e\u4e4f\u4e14\u4e0e\u5b9e\u9645\u7cfb\u7edf\u884c\u4e3a\u4e0d\u7b26\u7684\u95ee\u9898\uff0c\u6784\u5efa\u4e86\u7ecf\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u7684\u4ee3\u7801\u5bf9\u9f50\u7528\u4f8b\u57fa\u51c6\uff0c\u5e76\u9996\u6b21\u7cfb\u7edf\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u7528\u4f8b\u65b9\u9762\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7528\u4f8b\u57fa\u51c6\u7f3a\u4e4f\uff0c\u4e14\u4e0e\u771f\u5b9e\u7cfb\u7edf\u884c\u4e3a\u5bf9\u9f50\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u6e90\u7801\u751f\u6210\u7528\u4f8b\u80fd\u529b\u7684\u4e25\u683c\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u4eba\u5de5\u9a8c\u8bc1\u4e5d\u4e2a\u771f\u5b9e\u8f6f\u4ef6\u9879\u76ee\u4e2d\u7684\u7528\u6237\u76ee\u6807\u548c\u5b50\u529f\u80fd\u7528\u4f8b\uff0c\u6784\u5efa\u4ee3\u7801\u5bf9\u9f50\u7528\u4f8b\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u5c42\u7ea7\u5316\u8bc4\u4ef7\u534f\u8bae\uff0c\u8bc4\u4f30\u6f14\u5458\u6b63\u786e\u6027\u3001\u540d\u79f0\u51c6\u786e\u7387\u3001\u8def\u5f84\u4e00\u81f4\u6027\u548c\u884c\u4e3a\u8986\u76d6\u7387\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u5927\u8bed\u8a00\u6a21\u578b\u80fd\u90e8\u5206\u91cd\u5efa\u7cfb\u7edf\u529f\u80fd\uff0c\u4f46\u5728\u4e0d\u540c\u9879\u76ee\u8868\u73b0\u5dee\u5f02\u5927\uff0c\u7279\u522b\u662f\u5728\u9886\u57df\u7279\u5b9a\u548c\u591a\u6a21\u5757\u7cfb\u7edf\u4e2d\u5b58\u5728\u660e\u663e\u4e0d\u8db3\u3002\u6a21\u578b\u9057\u6f0f\u7387\u9ad8\uff0c\u96be\u4ee5\u5728\u5c06\u5b50\u529f\u80fd\u805a\u5408\u4e3a\u7528\u6237\u76ee\u6807\u7528\u4f8b\u65f6\u7ef4\u6301\u4e00\u81f4\u7684\u62bd\u8c61\u5c42\u6b21\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7528\u4f8b\u9006\u5411\u5de5\u7a0b\u4e2d\u5c55\u73b0\u51fa\u6f5c\u529b\uff0c\u4f46\u5f53\u524d\u4ecd\u6709\u660e\u663e\u5c40\u9650\uff0c\u5c24\u5176\u5728\u7279\u5b9a\u9886\u57df\u548c\u591a\u6a21\u5757\u7cfb\u7edf\u4e2d\u8868\u73b0\u8f83\u5dee\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u3002"}}
{"id": "2512.12544", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12544", "abs": "https://arxiv.org/abs/2512.12544", "authors": ["Yiming Zeng", "Jinghan Cao", "Zexin Li", "Wanhao Yu", "Zhankai Ye", "Dawei Xiang", "Ting Hua", "Xin Liu", "Shangqian Gao", "Tingting Yu"], "title": "HyperEdit: Unlocking Instruction-based Text Editing in LLMs via Hypernetworks", "comment": null, "summary": "Instruction-based text editing is increasingly critical for real-world applications such as code editors (e.g., Cursor), but Large Language Models (LLMs) continue to struggle with this task. Unlike free-form generation, editing requires faithfully implementing user instructions while preserving unchanged content, as even minor unintended modifications can break functionality. Existing approaches treat editing as generic text generation, leading to two key failures: they struggle to faithfully align edits with diverse user intents, and they often over-edit unchanged regions. We propose HyperEdit to address both issues. First, we introduce hypernetwork-based dynamic adaptation that generates request-specific parameters, enabling the model to tailor its editing strategy to each instruction. Second, we develop difference-aware regularization that focuses supervision on modified spans, preventing over-editing while ensuring precise, minimal changes. HyperEdit achieves a 9%--30% relative improvement in BLEU on modified regions over state-of-the-art baselines, despite utilizing only 3B parameters.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86HyperEdit\uff0c\u4e00\u79cd\u57fa\u4e8e\u8d85\u7f51\u7edc\u52a8\u6001\u9002\u5e94\u7684\u6587\u672c\u7f16\u8f91\u65b9\u6cd5\uff0c\u9488\u5bf9\u6307\u4ee4\u9a71\u52a8\u6587\u672c\u7f16\u8f91\u4e2d\u5bf9\u7528\u6237\u610f\u56fe\u5bf9\u9f50\u548c\u8fc7\u5ea6\u7f16\u8f91\u7684\u95ee\u9898\u8fdb\u884c\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8f91\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u6307\u4ee4\u9a71\u52a8\u7684\u6587\u672c\u7f16\u8f91\u4efb\u52a1\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u56e0\u4e3a\u96be\u4ee5\u5fe0\u5b9e\u6267\u884c\u591a\u6837\u5316\u7684\u7528\u6237\u7f16\u8f91\u6307\u4ee4\uff0c\u5e76\u4e14\u5bb9\u6613\u5bf9\u672a\u4fee\u6539\u533a\u57df\u8fdb\u884c\u8fc7\u5ea6\u7f16\u8f91\u3002", "method": "\u63d0\u51faHyperEdit\u65b9\u6cd5\uff0c\u5305\u62ec\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u52a8\u6001\u9002\u5e94\u673a\u5236\u751f\u6210\u9488\u5bf9\u7279\u5b9a\u6307\u4ee4\u7684\u6a21\u578b\u53c2\u6570\uff0c\u4ee5\u53ca\u5dee\u5f02\u611f\u77e5\u6b63\u5219\u5316\uff0c\u91cd\u70b9\u76d1\u7763\u4fee\u6539\u533a\u57df\uff0c\u9632\u6b62\u8fc7\u5ea6\u7f16\u8f91\u3002", "result": "HyperEdit\u5728\u4fee\u6539\u533a\u57df\u7684BLEU\u5f97\u5206\u4e0a\u8f83\u6700\u65b0\u65b9\u6cd5\u63d0\u5347\u4e869%\u81f330%\uff0c\u4e14\u4ec5\u4f7f\u75283B\u53c2\u6570\uff0c\u6548\u679c\u663e\u8457\u3002", "conclusion": "HyperEdit\u6709\u6548\u89e3\u51b3\u4e86\u6307\u4ee4\u9a71\u52a8\u6587\u672c\u7f16\u8f91\u4e2d\u5bf9\u7528\u6237\u610f\u56fe\u5bf9\u9f50\u548c\u7f16\u8f91\u7cbe\u51c6\u6027\u7684\u6311\u6218\uff0c\u5b9e\u73b0\u4e86\u66f4\u5fe0\u5b9e\u4e14\u7cbe\u786e\u7684\u7f16\u8f91\u7ed3\u679c\u3002"}}
{"id": "2512.13414", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13414", "abs": "https://arxiv.org/abs/2512.13414", "authors": ["Zenghui Zhou", "Pak-Lok Poon", "Zheng Zheng", "Xiao-Yi Zhang"], "title": "PSALM: applying Proportional SAmpLing strategy in Metamorphic testing", "comment": null, "summary": "Metamorphic testing (MT) alleviates the oracle problem by checking metamorphic relations (MRs) across multiple test executions. The fault detection effectiveness of MT is influenced not only by the choice and quality of MRs, but also by how source test cases and metamorphic groups (MGs) are selected. While substantial research has focused on designing, generating, and validating MRs, systematic methods for source test case selection and MG selection remain largely unexplored. Although the Proportional Sampling Strategy (PSS) provides strong theoretical guarantees in traditional testing, its assumptions cannot be directly applied in MT due to differences in selection domains, test units, and failure distributions. This paper proposes PSALM, an adaptation of PSS to MT for both source test case selection and MG selection. We formally prove that PSALM is never inferior to random selection regardless of how the source test case and MG domains are partitioned. We further identify the conditions under which applying PSALM to source test case selection and MG selection yields identical effectiveness. A comprehensive empirical study on eight subject programs and 184 mutants shows that the results are consistent with our theoretical analysis and that PSALM generally performs more effectively than existing selection strategies such as ART and MT-ART. These results demonstrate that PSALM provides a theoretically grounded and practically effective selection strategy for MT.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86PSALM\uff0c\u4e00\u79cd\u9488\u5bf9\u53d8\u5f62\u6d4b\u8bd5\u4e2d\u6e90\u6d4b\u8bd5\u7528\u4f8b\u548c\u53d8\u5f62\u7ec4\u9009\u62e9\u7684\u7b56\u7565\uff0c\u7406\u8bba\u4e0e\u5b9e\u9a8c\u8bc1\u660e\u5176\u4f18\u4e8e\u968f\u673a\u9009\u62e9\u548c\u5176\u4ed6\u7b56\u7565\u3002", "motivation": "\u53d8\u5f62\u6d4b\u8bd5\u7684\u6545\u969c\u68c0\u6d4b\u6548\u679c\u4e0d\u4ec5\u53d7\u53d8\u5f62\u5173\u7cfb\u9009\u62e9\u5f71\u54cd\uff0c\u6d4b\u8bd5\u7528\u4f8b\u548c\u53d8\u5f62\u7ec4\u7684\u9009\u53d6\u7b56\u7565\u4e5f\u5173\u952e\uff0c\u4f46\u76f8\u5173\u7cfb\u7edf\u65b9\u6cd5\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u63d0\u51faPSALM\uff0c\u9002\u5e94\u4f20\u7edf\u6bd4\u4f8b\u62bd\u6837\u7b56\u7565\uff08PSS\uff09\u4e8e\u53d8\u5f62\u6d4b\u8bd5\uff0c\u7ed3\u5408\u7406\u8bba\u8bc1\u660e\u5176\u81f3\u5c11\u4e0d\u52a3\u4e8e\u968f\u673a\u9009\u62e9\uff0c\u4e14\u5206\u6790\u7279\u5b9a\u6761\u4ef6\u4e0b\u6548\u7387\u76f8\u7b49\u3002", "result": "\u5728\u516b\u4e2a\u7a0b\u5e8f\u548c184\u4e2a\u53d8\u5f02\u4f53\u7684\u5b9e\u8bc1\u7814\u7a76\u4e2d\uff0cPSALM\u8868\u73b0\u4f18\u4e8e\u968f\u673a\u9009\u62e9\u53ca\u5176\u4ed6\u73b0\u6709\u7b56\u7565\uff0c\u5982ART\u548cMT-ART\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u3002", "conclusion": "PSALM\u4e3a\u53d8\u5f62\u6d4b\u8bd5\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u4e14\u5177\u5b9e\u9645\u6548\u80fd\u7684\u6d4b\u8bd5\u7528\u4f8b\u548c\u53d8\u5f62\u7ec4\u9009\u62e9\u7b56\u7565\uff0c\u63a8\u52a8\u4e86\u53d8\u5f62\u6d4b\u8bd5\u6548\u80fd\u63d0\u5347\u3002"}}
{"id": "2512.12576", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12576", "abs": "https://arxiv.org/abs/2512.12576", "authors": ["Xueru Wen", "Jie Lou", "Yanjiang Liu", "Hongyu Lin", "Ben He", "Xianpei Han", "Le Sun", "Yaojie Lu", "Debing Zhang"], "title": "Coupled Variational Reinforcement Learning for Language Model General Reasoning", "comment": null, "summary": "While reinforcement learning have achieved impressive progress in language model reasoning, they are constrained by the requirement for verifiable rewards. Recent verifier-free RL methods address this limitation by utilizing the intrinsic probabilities of LLMs generating reference answers as reward signals. However, these approaches typically sample reasoning traces conditioned only on the question. This design decouples reasoning-trace sampling from answer information, leading to inefficient exploration and incoherence between traces and final answers. In this paper, we propose \\textit{\\b{Co}upled \\b{V}ariational \\b{R}einforcement \\b{L}earning} (CoVRL), which bridges variational inference and reinforcement learning by coupling prior and posterior distributions through a hybrid sampling strategy. By constructing and optimizing a composite distribution that integrates these two distributions, CoVRL enables efficient exploration while preserving strong thought-answer coherence. Extensive experiments on mathematical and general reasoning benchmarks show that CoVRL improves performance by 12.4\\% over the base model and achieves an additional 2.3\\% improvement over strong state-of-the-art verifier-free RL baselines, providing a principled framework for enhancing the general reasoning capabilities of language models.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u8026\u5408\u53d8\u5206\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5CoVRL\uff0c\u4ee5\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u6027\u80fd\u548c\u7b54\u6848\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u53d7\u9650\u4e8e\u9700\u8981\u53ef\u9a8c\u8bc1\u7684\u5956\u52b1\u4fe1\u53f7\uff0c\u4e14\u65e0\u9a8c\u8bc1\u8005\u7684\u5f3a\u5316\u5b66\u4e60\u5f80\u5f80\u5ffd\u89c6\u4e86\u63a8\u7406\u8f68\u8ff9\u4e0e\u7b54\u6848\u4e4b\u95f4\u7684\u8026\u5408\uff0c\u5bfc\u81f4\u63a2\u7d22\u4f4e\u6548\u548c\u8f68\u8ff9\u4e0e\u7b54\u6848\u4e0d\u4e00\u81f4\u3002", "method": "\u63d0\u51faCoVRL\uff0c\u901a\u8fc7\u8026\u5408\u5148\u9a8c\u548c\u540e\u9a8c\u5206\u5e03\uff0c\u91c7\u7528\u6df7\u5408\u91c7\u6837\u7b56\u7565\u6784\u5efa\u5e76\u4f18\u5316\u590d\u5408\u5206\u5e03\uff0c\u5b9e\u73b0\u53d8\u5206\u63a8\u65ad\u4e0e\u5f3a\u5316\u5b66\u4e60\u7684\u7ed3\u5408\uff0c\u4ece\u800c\u63d0\u5347\u63a2\u7d22\u6548\u7387\u53ca\u63a8\u7406\u4e0e\u7b54\u6848\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u6570\u5b66\u548c\u901a\u7528\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCoVRL\u76f8\u8f83\u57fa\u7840\u6a21\u578b\u6027\u80fd\u63d0\u534712.4%\uff0c\u4e14\u8f83\u73b0\u6709\u65e0\u9a8c\u8bc1\u8005\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u63d0\u53472.3%\u3002", "conclusion": "CoVRL\u4e3a\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u63a8\u7406\u80fd\u529b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u7406\u8bba\u652f\u6491\u4e14\u6709\u6548\u7684\u6846\u67b6\uff0c\u517c\u987e\u4e86\u63a8\u7406\u6548\u7387\u548c\u7b54\u6848\u4e00\u81f4\u6027\u3002"}}
{"id": "2512.13422", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13422", "abs": "https://arxiv.org/abs/2512.13422", "authors": ["Ning Ma", "Jianjun Zhao", "Foutse Khomh", "Shaukat Ali", "Heng Li"], "title": "QMon: Monitoring the Execution of Quantum Circuits with Mid-Circuit Measurement and Reset", "comment": null, "summary": "Unlike classical software, where logging and runtime tracing can effectively reveal internal execution status, quantum circuits possess unique properties, such as the no-cloning theorem and measurement-induced collapse, that prevent direct observation or duplication of their states. These characteristics make it especially challenging to monitor the execution of quantum circuits, complicating essential tasks such as debugging and runtime monitoring. This paper presents QMON, a practical methodology that leverages mid-circuit measurements and reset operations to monitor the internal states of quantum circuits while preserving their original runtime behavior. QMON enables the instrumentation of monitoring operators at developer-specified locations within the circuit, allowing comparisons between expected and observed quantum-state probabilities at those locations. We evaluated QMON by analyzing its impact on circuit behavior, monitoring coverage, and effectiveness in bug localization. Experimental results involving 154 quantum circuits show that all circuits preserve their intended functionality after instrumentation and that QMON successfully detects and localizes various programming errors. Although monitoring coverage is limited by the need to preserve delicate quantum properties, such as entanglement, QMON effectively detects errors while introducing no or negligible disturbance to the original quantum states. QMON facilitates the development of more robust and reliable quantum software as the field continues to mature.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faQMON\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e2d\u9014\u6d4b\u91cf\u548c\u91cd\u7f6e\u64cd\u4f5c\u76d1\u63a7\u91cf\u5b50\u7535\u8def\u72b6\u6001\uff0c\u5728\u4e0d\u7834\u574f\u8fd0\u884c\u884c\u4e3a\u7684\u524d\u63d0\u4e0b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u91cf\u5b50\u7a0b\u5e8f\u7684\u8c03\u8bd5\u548c\u8fd0\u884c\u65f6\u76d1\u63a7\u3002", "motivation": "\u7531\u4e8e\u91cf\u5b50\u7535\u8def\u7684\u7279\u6027\uff08\u5982\u4e0d\u53ef\u514b\u9686\u5b9a\u7406\u548c\u6d4b\u91cf\u584c\u7f29\uff09\uff0c\u65e0\u6cd5\u76f4\u63a5\u89c2\u5bdf\u6216\u590d\u5236\u5176\u72b6\u6001\uff0c\u5bfc\u81f4\u8c03\u8bd5\u548c\u8fd0\u884c\u65f6\u76d1\u63a7\u8f83\u4e3a\u56f0\u96be\u3002", "method": "\u5229\u7528\u4e2d\u9014\u6d4b\u91cf\u548c\u91cd\u7f6e\u64cd\u4f5c\uff0c\u5728\u5f00\u53d1\u8005\u6307\u5b9a\u4f4d\u7f6e\u63d2\u5165\u76d1\u63a7\u7b97\u5b50\uff0c\u5bf9\u6bd4\u9884\u671f\u4e0e\u89c2\u6d4b\u5230\u7684\u91cf\u5b50\u6001\u6982\u7387\uff0c\u76d1\u63a7\u7535\u8def\u5185\u90e8\u72b6\u6001\u3002", "result": "154\u4e2a\u91cf\u5b50\u7535\u8def\u5b9e\u9a8c\u8868\u660e\uff0cQMON\u4e0d\u4f1a\u5f71\u54cd\u7535\u8def\u529f\u80fd\uff0c\u80fd\u6210\u529f\u68c0\u6d4b\u5e76\u5b9a\u4f4d\u591a\u79cd\u7a0b\u5e8f\u9519\u8bef\uff0c\u4e14\u5bf9\u91cf\u5b50\u6001\u7684\u6270\u52a8\u6781\u5c0f\u3002", "conclusion": "QMON\u4e3a\u91cf\u5b50\u7535\u8def\u8c03\u8bd5\u548c\u76d1\u63a7\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u91cf\u5b50\u8f6f\u4ef6\u7684\u9c81\u68d2\u6027\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2512.12608", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12608", "abs": "https://arxiv.org/abs/2512.12608", "authors": ["Hong Su"], "title": "Human-Inspired Learning for Large Language Models via Obvious Record and Maximum-Entropy Method Discovery", "comment": null, "summary": "Large Language Models (LLMs) excel at extracting common patterns from large-scale corpora, yet they struggle with rare, low-resource, or previously unseen scenarios-such as niche hardware deployment issues or irregular IoT device behaviors-because such cases are sparsely represented in training data. Moreover, LLMs rely primarily on implicit parametric memory, which limits their ability to explicitly acquire, recall, and refine methods, causing them to behave predominantly as intuition-driven predictors rather than deliberate, method-oriented learners. Inspired by how humans learn from rare experiences, this paper proposes a human-inspired learning framework that integrates two complementary mechanisms. The first, Obvious Record, explicitly stores cause--result (or question--solution) relationships as symbolic memory, enabling persistent learning even from single or infrequent encounters. The second, Maximum-Entropy Method Discovery, prioritizes and preserves methods with high semantic dissimilarity, allowing the system to capture diverse and underrepresented strategies that are typically overlooked by next-token prediction. Verification on a benchmark of 60 semantically diverse question--solution pairs demonstrates that the proposed entropy-guided approach achieves stronger coverage of unseen questions and significantly greater internal diversity than a random baseline, confirming its effectiveness in discovering more generalizable and human-inspired methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u7f55\u89c1\u6216\u4f4e\u8d44\u6e90\u573a\u666f\u65f6\u5b58\u5728\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7b26\u53f7\u8bb0\u5fc6\u4e0e\u6700\u5927\u71b5\u65b9\u6cd5\u53d1\u73b0\u7684\u4eba\u7c7b\u542f\u53d1\u5f0f\u5b66\u4e60\u6846\u67b6\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u56e0\u8bad\u7ec3\u6570\u636e\u4e2d\u7a00\u5c11\u7684\u4f4e\u9891\u6848\u4f8b\u96be\u4ee5\u6709\u6548\u5b66\u4e60\uff0c\u4e14\u4f9d\u8d56\u9690\u5f0f\u53c2\u6570\u8bb0\u5fc6\uff0c\u7f3a\u4e4f\u663e\u5f0f\u83b7\u53d6\u3001\u56de\u5fc6\u548c\u4f18\u5316\u65b9\u6cd5\u7684\u80fd\u529b\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e24\u4e2a\u673a\u5236\uff1a\u4e00\u662f\u201c\u663e\u8457\u8bb0\u5f55\u201d\uff0c\u5c06\u56e0\u679c\u5173\u7cfb\u4f5c\u4e3a\u7b26\u53f7\u8bb0\u5fc6\u5b58\u50a8\uff0c\u5b9e\u73b0\u5bf9\u5355\u6b21\u6216\u5c11\u89c1\u7ecf\u9a8c\u7684\u6301\u4e45\u5b66\u4e60\uff1b\u4e8c\u662f\u201c\u6700\u5927\u71b5\u65b9\u6cd5\u53d1\u73b0\u201d\uff0c\u4f18\u5148\u91c7\u7eb3\u8bed\u4e49\u5dee\u5f02\u6027\u9ad8\u7684\u65b9\u6cd5\uff0c\u4ece\u800c\u6355\u6349\u591a\u6837\u4e14\u7a00\u7f3a\u7684\u7b56\u7565\u3002", "result": "\u5728\u5305\u542b60\u7ec4\u8bed\u4e49\u591a\u6837\u7684\u95ee\u9898-\u89e3\u51b3\u5bf9\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u968f\u673a\u57fa\u7ebf\uff0c\u5728\u8986\u76d6\u672a\u89c1\u95ee\u9898\u548c\u5185\u90e8\u591a\u6837\u6027\u65b9\u9762\u8868\u73b0\u66f4\u4f73\uff0c\u8bc1\u660e\u4e86\u5176\u53d1\u73b0\u66f4\u5177\u6cdb\u5316\u548c\u4eba\u7c7b\u542f\u53d1\u6027\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f55\u89c1\u573a\u666f\u4e0b\u7684\u5b66\u4e60\u80fd\u529b\uff0c\u4fc3\u8fdb\u5176\u4ece\u4f4e\u9891\u6570\u636e\u4e2d\u663e\u5f0f\u83b7\u53d6\u548c\u521b\u65b0\u65b9\u6cd5\uff0c\u589e\u5f3a\u6a21\u578b\u7684\u6cdb\u5316\u6027\u548c\u591a\u6837\u6027\u3002"}}
{"id": "2512.13438", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13438", "abs": "https://arxiv.org/abs/2512.13438", "authors": ["Dezhi Ran", "Zhi Gong", "Yuzhe Guo", "Mengzhou Wu", "Yuan Cao", "Haochuan Lu", "Hengyu Zhang", "Xia Zeng", "Gang Cao", "Liangchao Yao", "Yuetang Deng", "Wei Yang", "Tao Xie"], "title": "From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents", "comment": null, "summary": "While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aUIFormer\u7684\u81ea\u52a8\u5316UI\u8868\u793a\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u5408\u6210UI\u8f6c\u6362\u7a0b\u5e8f\u5b9e\u73b0\u6548\u7387\u4e0e\u5b8c\u6574\u6027\u7684\u534f\u540c\u4f18\u5316\uff0c\u5728Android\u548cWeb\u5e73\u53f0\u4e0a\u663e\u8457\u51cf\u5c11\u4e86\u4ee4\u724c\u6570\u91cf\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u81ea\u52a8\u5316UI\u5bfc\u822a\u4e2d\u6548\u7387\u4e0d\u8db3\uff0cUI\u8868\u793a\u7684\u4e0d\u9ad8\u6548\u6210\u4e3a\u6027\u80fd\u74f6\u9888\uff0c\u4f46\u4f18\u5316UI\u8868\u793a\u5b58\u5728\u7f3a\u4e4f\u5e03\u5c14\u68c0\u9a8c\u548c\u5904\u7406\u590d\u6742UI\u6811\u8f93\u5165\u7684\u6311\u6218\u3002", "method": "UIFormer\u901a\u8fc7\u8bbe\u8ba1\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u9650\u5236\u7a0b\u5e8f\u7a7a\u95f4\uff0c\u4f7f\u7528LLM\u8fed\u4ee3\u7ec6\u5316\u7a0b\u5e8f\u5e76\u7ed3\u5408\u6b63\u786e\u6027\u4e0e\u6548\u7387\u5956\u52b1\u6765\u4f18\u5316UI\u8f6c\u6362\u7a0b\u5e8f\uff0c\u91c7\u7528\u7ed3\u6784\u5316\u5206\u89e3\u7b80\u5316\u5408\u6210\u4efb\u52a1\u3002", "result": "\u5728\u4e09\u4e2a\u6d4b\u8bd5\u57fa\u51c6\u548c\u4e94\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0cUIFormer\u5b9e\u73b0\u4e8648.7%\u81f355.8%\u7684\u4ee4\u724c\u6570\u51cf\u5c11\uff0c\u4e14\u51e0\u4e4e\u65e0\u8fd0\u884c\u65f6\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u4e86\u4ee3\u7406\u6027\u80fd\u3002", "conclusion": "UIFormer\u4f5c\u4e3a\u8f7b\u91cf\u7ea7\u63d2\u4ef6\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709LLM\u4ee3\u7406\u4e2d\uff0c\u6709\u6548\u63d0\u5347\u4e86UI\u5bfc\u822a\u4efb\u52a1\u7684\u6548\u7387\u4e0e\u8868\u73b0\uff0c\u5b9e\u9645\u5728\u5fae\u4fe1\u4e2d\u7684\u90e8\u7f72\u8bc1\u660e\u4e86\u5176\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.12613", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12613", "abs": "https://arxiv.org/abs/2512.12613", "authors": ["Yucan Guo", "Saiping Guan", "Miao Su", "Zeya Zhao", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "StruProKGR: A Structural and Probabilistic Framework for Sparse Knowledge Graph Reasoning", "comment": null, "summary": "Sparse Knowledge Graphs (KGs) are commonly encountered in real-world applications, where knowledge is often incomplete or limited. Sparse KG reasoning, the task of inferring missing knowledge over sparse KGs, is inherently challenging due to the scarcity of knowledge and the difficulty of capturing relational patterns in sparse scenarios. Among all sparse KG reasoning methods, path-based ones have attracted plenty of attention due to their interpretability. Existing path-based methods typically rely on computationally intensive random walks to collect paths, producing paths of variable quality. Additionally, these methods fail to leverage the structured nature of graphs by treating paths independently. To address these shortcomings, we propose a Structural and Probabilistic framework named StruProKGR, tailored for efficient and interpretable reasoning on sparse KGs. StruProKGR utilizes a distance-guided path collection mechanism to significantly reduce computational costs while exploring more relevant paths. It further enhances the reasoning process by incorporating structural information through probabilistic path aggregation, which prioritizes paths that reinforce each other. Extensive experiments on five sparse KG reasoning benchmarks reveal that StruProKGR surpasses existing path-based methods in both effectiveness and efficiency, providing an effective, efficient, and interpretable solution for sparse KG reasoning.", "AI": {"tldr": "\u63d0\u51fa\u4e86StruProKGR\uff0c\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u89e3\u91ca\u7684\u7a00\u758f\u77e5\u8bc6\u56fe\u63a8\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u8ddd\u79bb\u6307\u5bfc\u8def\u5f84\u6536\u96c6\u548c\u6982\u7387\u8def\u5f84\u805a\u5408\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u548c\u6548\u7387\u3002", "motivation": "\u7a00\u758f\u77e5\u8bc6\u56fe\u63a8\u7406\u96be\u70b9\u5728\u4e8e\u77e5\u8bc6\u7a00\u7f3a\u548c\u96be\u4ee5\u6355\u83b7\u5173\u7cfb\u6a21\u5f0f\uff0c\u4e14\u73b0\u6709\u8def\u5f84\u65b9\u6cd5\u8ba1\u7b97\u91cf\u5927\u4e14\u8def\u5f84\u8d28\u91cf\u4e0d\u7a33\u5b9a\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528\u56fe\u7684\u7ed3\u6784\u4fe1\u606f\u3002", "method": "\u8bbe\u8ba1\u4e86StruProKGR\u6846\u67b6\uff0c\u91c7\u7528\u8ddd\u79bb\u5f15\u5bfc\u7684\u8def\u5f84\u6536\u96c6\u673a\u5236\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\uff0c\u540c\u65f6\u5229\u7528\u6982\u7387\u8def\u5f84\u805a\u5408\u878d\u5408\u7ed3\u6784\u4fe1\u606f\uff0c\u4f18\u5148\u8003\u8651\u76f8\u4e92\u5f3a\u5316\u7684\u8def\u5f84\u3002", "result": "\u5728\u4e94\u4e2a\u7a00\u758f\u77e5\u8bc6\u56fe\u63a8\u7406\u57fa\u51c6\u4e0a\uff0cStruProKGR\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u8def\u5f84\u65b9\u6cd5\u3002", "conclusion": "StruProKGR\u4e3a\u7a00\u758f\u77e5\u8bc6\u56fe\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u3001\u9ad8\u6548\u4e14\u5177\u6709\u826f\u597d\u89e3\u91ca\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.13444", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13444", "abs": "https://arxiv.org/abs/2512.13444", "authors": ["Yi Peng", "Hina Saeeda", "Hans-Martin Heyn", "Jennifer Horkoff", "Eric Knauss", "Fredrick Warg"], "title": "A Data Annotation Requirements Representation and Specification (DARS)", "comment": "17 pages, 3 figures, currently submitted and under review", "summary": "With the rise of AI-enabled cyber-physical systems, data annotation has become a critical yet often overlooked process in the development of these intelligent information systems. Existing work in requirements engineering (RE) has explored how requirements for AI systems and their data can be represented. However, related interviews with industry professionals show that data annotations and their related requirements introduce distinct challenges, indicating a need for annotation-specific requirement representations. We propose the Data Annotation Requirements Representation and Specification (DARS), including an Annotation Negotiation Card to align stakeholders on objectives and constraints, and a Scenario-Based Annotation Specification to express atomic and verifiable data annotation requirements. We evaluate DARS with an automotive perception case related to an ongoing project, and a mapping against 18 real-world data annotation error types. The results suggest that DARS mitigates root causes of completeness, accuracy, and consistency annotation errors. By integrating DARS into RE, this work improves the reliability of safety-critical systems using data annotations and demonstrates how engineering frameworks must evolve for data-dependent components of today's intelligent information systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u6570\u636e\u6807\u6ce8\u9700\u6c42\u8868\u793a\u4e0e\u89c4\u8303\uff08DARS\uff09\u6846\u67b6\uff0c\u4ee5\u89e3\u51b3AI\u7cfb\u7edf\u4e2d\u6570\u636e\u6807\u6ce8\u6240\u5e26\u6765\u7684\u7279\u6b8a\u9700\u6c42\u6311\u6218\uff0c\u63d0\u5347\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u6807\u6ce8\u6570\u636e\u7684\u5b8c\u6574\u6027\u3001\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u9700\u6c42\u5de5\u7a0b\u4e2d\u5bf9AI\u7cfb\u7edf\u53ca\u5176\u6570\u636e\u7684\u9700\u6c42\u8868\u793a\u5df2\u6709\u9650\u6d89\u730e\uff0c\u4f46\u6570\u636e\u6807\u6ce8\u53ca\u76f8\u5173\u9700\u6c42\u5f15\u53d1\u7279\u6709\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5145\u5206\u8868\u793a\u6807\u6ce8\u9700\u6c42\uff0c\u4e9f\u9700\u4e13\u95e8\u7684\u8868\u793a\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDARS\u6846\u67b6\uff0c\u5305\u542b\u6807\u6ce8\u534f\u5546\u5361\u4ee5\u534f\u8c03\u5229\u76ca\u76f8\u5173\u8005\u76ee\u6807\u4e0e\u7ea6\u675f\uff0c\u53ca\u57fa\u4e8e\u573a\u666f\u7684\u6807\u6ce8\u89c4\u8303\u7528\u4e8e\u8868\u8fbe\u53ef\u9a8c\u8bc1\u7684\u539f\u5b50\u5316\u6807\u6ce8\u9700\u6c42\uff0c\u5e76\u901a\u8fc7\u6c7d\u8f66\u611f\u77e5\u6848\u4f8b\u548c18\u7c7b\u771f\u5b9e\u6807\u6ce8\u9519\u8bef\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "DARS\u6709\u6548\u51cf\u8f7b\u4e86\u6807\u6ce8\u9519\u8bef\u7684\u6839\u672c\u539f\u56e0\uff0c\u63d0\u5347\u4e86\u6570\u636e\u6807\u6ce8\u7684\u5b8c\u6574\u6027\u3001\u51c6\u786e\u6027\u548c\u4e00\u81f4\u6027\u3002", "conclusion": "\u5c06DARS\u96c6\u6210\u5230\u9700\u6c42\u5de5\u7a0b\u4e2d\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u4f9d\u8d56\u6570\u636e\u6807\u6ce8\u7684\u5b89\u5168\u5173\u952e\u667a\u80fd\u7cfb\u7edf\u7684\u53ef\u9760\u6027\uff0c\u5f3a\u8c03\u5de5\u7a0b\u6846\u67b6\u9700\u9002\u5e94\u5f53\u524d\u667a\u80fd\u4fe1\u606f\u7cfb\u7edf\u5bf9\u6570\u636e\u4f9d\u8d56\u7684\u7279\u70b9\u3002"}}
{"id": "2512.12620", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12620", "abs": "https://arxiv.org/abs/2512.12620", "authors": ["Aheli Poddar", "Saptarshi Sahoo", "Sujata Ghosh"], "title": "Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives", "comment": "9 pages, 4 figures, 5 tables. Submitted to AAAI 2026 Bridge Program on Logic & AI. Code available at https://github.com/XAheli/Logic-in-LLMs", "summary": "We study syllogistic reasoning in LLMs from the logical and natural language perspectives. In process, we explore fundamental reasoning capabilities of the LLMs and the direction this research is moving forward. To aid in our studies, we use 14 large language models and investigate their syllogistic reasoning capabilities in terms of symbolic inferences as well as natural language understanding. Even though this reasoning mechanism is not a uniform emergent property across LLMs, the perfect symbolic performances in certain models make us wonder whether LLMs are becoming more and more formal reasoning mechanisms, rather than making explicit the nuances of human reasoning.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc714\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u4e86\u5b83\u4eec\u5728\u4e09\u6bb5\u8bba\u63a8\u7406\u4e2d\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u7b26\u53f7\u63a8\u7406\u548c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u65b9\u9762\u3002", "motivation": "\u63a2\u7d22\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u903b\u8f91\u63a8\u7406\uff0c\u5c24\u5176\u662f\u4e09\u6bb5\u8bba\u63a8\u7406\u4e2d\u7684\u80fd\u529b\u53ca\u5176\u53d1\u5c55\u65b9\u5411\u3002", "method": "\u91c7\u752814\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5bf9\u5176\u5728\u7b26\u53f7\u63a8\u7406\u548c\u81ea\u7136\u8bed\u8a00\u7406\u89e3\u5c42\u9762\u7684\u4e09\u6bb5\u8bba\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u7cfb\u7edf\u6d4b\u8bd5\u548c\u6bd4\u8f83\u3002", "result": "\u4e0d\u540c\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u8868\u73b0\u4e0d\u4e00\uff0c\u90e8\u5206\u6a21\u578b\u5728\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8fd1\u4e4e\u5b8c\u7f8e\u7684\u80fd\u529b\u3002", "conclusion": "\u67d0\u4e9b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u6b63\u5728\u5411\u66f4\u5f62\u5f0f\u5316\u7684\u63a8\u7406\u673a\u5236\u53d1\u5c55\uff0c\u800c\u975e\u4ec5\u4ec5\u6a21\u62df\u4eba\u7c7b\u601d\u7ef4\u7684\u7ec6\u5fae\u5dee\u522b\u3002"}}
{"id": "2512.13474", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13474", "abs": "https://arxiv.org/abs/2512.13474", "authors": ["Laura Partanen", "Antti Sipila", "Md Sanaul Haque", "Jari Porras"], "title": "Mapping of the system of software-related emissions and shared responsibilities", "comment": "8 pages, 8 figures, 2 tables, 2025 IEEE/ACM 9th International Workshop on Green and Sustainable Software (GREENS)", "summary": "The global climate is experiencing a rapid and unprecedented warming trend. The ICT sector is a notable contributor to global greenhouse gas emissions, with its environmental impact continuing to expand. Addressing this issue is vital for achieving the objectives of the Paris Agreement, particularly the goal of limiting global temperature rise to 1.5\u00b0C. At the European Union level, regulatory measures such as the CSRD and the CSDD impose obligations on companies, including those within the ICT sector, to recognize and mitigate their environmental footprint. This study provides a comprehensive system mapping aimed at enhancing the awareness and understanding of software-related emissions and the corresponding responsibilities borne by the ICT sector. The mapping identifies the primary sources of carbon emissions and energy consumption within the ICT domain while also outlining the key responsibilities of the stakeholders accountable throughout the software lifecycle.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86ICT\u9886\u57df\u5728\u5168\u7403\u53d8\u6696\u4e2d\u7684\u78b3\u6392\u653e\u95ee\u9898\uff0c\u5f3a\u8c03\u89c4\u8303\u4f01\u4e1a\u8d23\u4efb\u4ee5\u51cf\u7f13\u6c14\u5019\u53d8\u5316\u3002", "motivation": "\u5168\u7403\u6c14\u5019\u5feb\u901f\u53d8\u6696\uff0cICT\u884c\u4e1a\u78b3\u6392\u653e\u6301\u7eed\u589e\u52a0\uff0c\u9700\u52a9\u529b\u5b9e\u73b0\u5df4\u9ece\u534f\u5b9a1.5\u2103\u76ee\u6807\u3002", "method": "\u6784\u5efa\u5168\u9762\u7684\u7cfb\u7edf\u6620\u5c04\uff0c\u8bc6\u522bICT\u9886\u57df\u8f6f\u4ef6\u76f8\u5173\u7684\u78b3\u6392\u653e\u548c\u80fd\u8017\u4e3b\u8981\u6765\u6e90\uff0c\u660e\u786e\u5404\u5229\u76ca\u76f8\u5173\u65b9\u7684\u8f6f\u4ef6\u751f\u547d\u5468\u671f\u8d23\u4efb\u3002", "result": "\u7cfb\u7edf\u6620\u5c04\u660e\u786e\u4e86ICT\u884c\u4e1a\u78b3\u6392\u653e\u70b9\u548c\u80fd\u8017\u6765\u6e90\uff0c\u5e76\u5212\u5b9a\u4e86\u5404\u65b9\u8d23\u4efb\u8303\u56f4\u3002", "conclusion": "\u63d0\u5347\u5bf9\u8f6f\u4ef6\u76f8\u5173\u78b3\u6392\u653e\u7684\u8ba4\u8bc6\u548c\u7ba1\u7406\uff0c\u6709\u52a9\u4e8eICT\u884c\u4e1a\u5c65\u884c\u73af\u5883\u8d23\u4efb\uff0c\u52a9\u529b\u6c14\u5019\u76ee\u6807\u8fbe\u6210\u3002"}}
{"id": "2512.12641", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12641", "abs": "https://arxiv.org/abs/2512.12641", "authors": ["Sander Land", "Yuval Pinter"], "title": "Which Pieces Does Unigram Tokenization Really Need?", "comment": "10 pages, 1 figure. For associated code, see https://github.com/sanderland/script_tok", "summary": "The Unigram tokenization algorithm offers a probabilistic alternative to the greedy heuristics of Byte-Pair Encoding. Despite its theoretical elegance, its implementation in practice is complex, limiting its adoption to the SentencePiece package and adapters thereof. We bridge this gap between theory and practice by providing a clear guide to implementation and parameter choices. We also identify a simpler algorithm that accepts slightly higher training loss in exchange for improved compression.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9Unigram\u5206\u8bcd\u7b97\u6cd5\u7684\u5b9e\u9645\u5e94\u7528\u590d\u6742\u6027\uff0c\u63d0\u4f9b\u4e86\u660e\u786e\u7684\u5b9e\u73b0\u6307\u5357\u548c\u53c2\u6570\u9009\u62e9\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u7b97\u6cd5\u4ee5\u6539\u5584\u538b\u7f29\u6548\u679c\u3002", "motivation": "Unigram\u5206\u8bcd\u7b97\u6cd5\u7406\u8bba\u4f18\u96c5\uff0c\u4f46\u5b9e\u9645\u5b9e\u73b0\u590d\u6742\uff0c\u9650\u5236\u4e86\u5176\u5e94\u7528\u8303\u56f4\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6e05\u6670\u7684\u5b9e\u73b0\u6b65\u9aa4\u548c\u53c2\u6570\u6307\u5357\uff0c\u5f25\u5408\u7406\u8bba\u4e0e\u5b9e\u8df5\u7684\u5dee\u8ddd\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u7b80\u5355\u7684\u7b97\u6cd5\uff0c\u63a5\u53d7\u7565\u9ad8\u7684\u8bad\u7ec3\u635f\u5931\u6362\u53d6\u66f4\u597d\u7684\u538b\u7f29\u6548\u679c\u3002", "result": "\u63d0\u51fa\u7684\u7b80\u5355\u7b97\u6cd5\u5728\u8bad\u7ec3\u635f\u5931\u7565\u5fae\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u538b\u7f29\u6548\u679c\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u884c\u7684Unigram\u5206\u8bcd\u7b97\u6cd5\u5b9e\u73b0\u65b9\u6848\u548c\u53c2\u6570\u9009\u62e9\u6307\u5357\uff0c\u4fc3\u8fdb\u4e86\u8be5\u7b97\u6cd5\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u5e76\u6539\u8fdb\u4e86\u538b\u7f29\u6027\u80fd\u3002"}}
{"id": "2512.13515", "categories": ["cs.SE", "cs.CL", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.13515", "abs": "https://arxiv.org/abs/2512.13515", "authors": ["Oleg Grynets", "Vasyl Lyashkevych", "Dmytro Baran", "Maksym Orliansky", "Taras Zelenyy", "Markiian Leshchyshyn"], "title": "Fine-tuned LLM-based Code Migration Framework", "comment": "16 pages, 27 figures, 7 references", "summary": "The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u7684\u81ea\u52a8\u5316SQL\u4ee3\u7801\u8fc1\u79fb\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u3001\u7cbe\u786e\u7684\u6570\u636e\u5e93\u7cfb\u7edf\u8f6c\u6362\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edfSQL\u7cfb\u7edf\u8fc1\u79fb\u4e2d\u8bed\u6cd5\u6620\u5c04\u53ca\u6570\u636e\u5e93\u5143\u7d20\u4e0d\u517c\u5bb9\u7b49\u5173\u952e\u96be\u9898\uff0c\u63d0\u9ad8\u8fc1\u79fb\u6548\u7387\u548c\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u6280\u672f\uff0c\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u81ea\u52a8SQL\u7279\u5f81\u68c0\u6d4b\u3001\u534a\u76d1\u7763\u9519\u8bef\u5206\u6790\u4e0e\u4e13\u5bb6\u53cd\u9988\uff0c\u6784\u5efa\u8fed\u4ee3\u4f18\u5316\u7684\u8fc1\u79fb\u6d41\u7a0b\u3002", "result": "\u663e\u8457\u964d\u4f4e\u53e5\u6cd5\u9519\u8bef\u7387\uff0c\u589e\u5f3a\u8fc1\u79fb\u8fc7\u7a0b\u4e2d\u7684\u7279\u5f81\u4e00\u81f4\u6027\u548c\u6570\u636e\u5e93\u903b\u8f91\u517c\u5bb9\u6027\uff0c\u5b9e\u73b0\u4e86\u6301\u7eed\u6539\u8fdb\u7684\u6548\u679c\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5fae\u8c03\u7684\u8fc1\u79fb\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86SQL\u7cfb\u7edf\u8fc1\u79fb\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u63a8\u52a8\u6570\u636e\u5e93\u73b0\u4ee3\u5316\u8f6c\u6362\u8fdb\u7a0b\u3002"}}
{"id": "2512.12643", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12643", "abs": "https://arxiv.org/abs/2512.12643", "authors": ["Yida Cai", "Ranjuexiao Hu", "Huiyuan Xie", "Chenyang Li", "Yun Liu", "Yuxiao Ye", "Zhenghao Liu", "Weixing Shen", "Zhiyuan Liu"], "title": "LexRel: Benchmarking Legal Relation Extraction for Chinese Civil Cases", "comment": null, "summary": "Legal relations form a highly consequential analytical framework of civil law system, serving as a crucial foundation for resolving disputes and realizing values of the rule of law in judicial practice. However, legal relations in Chinese civil cases remain underexplored in the field of legal artificial intelligence (legal AI), largely due to the absence of comprehensive schemas. In this work, we firstly introduce a comprehensive schema, which contains a hierarchical taxonomy and definitions of arguments, for AI systems to capture legal relations in Chinese civil cases. Based on this schema, we then formulate legal relation extraction task and present LexRel, an expert-annotated benchmark for legal relation extraction in Chinese civil law. We use LexRel to evaluate state-of-the-art large language models (LLMs) on legal relation extractions, showing that current LLMs exhibit significant limitations in accurately identifying civil legal relations. Furthermore, we demonstrate that incorporating legal relations information leads to consistent performance gains on other downstream legal AI tasks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u9488\u5bf9\u4e2d\u56fd\u6c11\u4e8b\u6848\u4ef6\u6cd5\u5f8b\u5173\u7cfb\u7684\u7efc\u5408\u6a21\u5f0f\u53ca\u57fa\u51c6\u6570\u636e\u96c6LexRel\uff0c\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6cd5\u5f8b\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5e76\u9a8c\u8bc1\u4e86\u6cd5\u5f8b\u5173\u7cfb\u4fe1\u606f\u5bf9\u5176\u4ed6\u6cd5\u5f8bAI\u4efb\u52a1\u7684\u63d0\u5347\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u6cd5\u5f8b\u4eba\u5de5\u667a\u80fd\u9886\u57df\u5bf9\u4e2d\u56fd\u6c11\u4e8b\u6848\u4ef6\u4e2d\u7684\u6cd5\u5f8b\u5173\u7cfb\u7814\u7a76\u8f83\u5c11\uff0c\u7f3a\u4e4f\u5168\u9762\u7684\u6cd5\u5f8b\u5173\u7cfb\u62bd\u53d6\u6a21\u5f0f\uff0c\u5236\u7ea6\u4e86\u5728\u53f8\u6cd5\u5b9e\u8df5\u4e2d\u6709\u6548\u89e3\u51b3\u7ea0\u7eb7\u548c\u5b9e\u73b0\u6cd5\u6cbb\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u4e86\u5305\u542b\u5206\u5c42\u5206\u7c7b\u6cd5\u548c\u8bba\u70b9\u5b9a\u4e49\u7684\u7efc\u5408\u6cd5\u5f8b\u5173\u7cfb\u6a21\u5f0f\uff0c\u57fa\u4e8e\u8be5\u6a21\u5f0f\u6784\u5efa\u4e86\u4e13\u5bb6\u6807\u6ce8\u7684LexRel\u6570\u636e\u96c6\uff0c\u8bbe\u8ba1\u6cd5\u5f8b\u5173\u7cfb\u62bd\u53d6\u4efb\u52a1\uff0c\u5e76\u7528\u5b83\u8bc4\u4f30\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u51c6\u786e\u8bc6\u522b\u6c11\u4e8b\u6cd5\u5f8b\u5173\u7cfb\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\u3002\u6b64\u5916\uff0c\u878d\u5408\u6cd5\u5f8b\u5173\u7cfb\u4fe1\u606f\u80fd\u660e\u663e\u63d0\u5347\u5176\u4ed6\u6cd5\u5f8b\u4eba\u5de5\u667a\u80fd\u4efb\u52a1\u7684\u6027\u80fd\u3002", "conclusion": "\u7efc\u5408\u7684\u6cd5\u5f8b\u5173\u7cfb\u6a21\u5f0f\u53caLexRel\u6570\u636e\u96c6\u4e3a\u4e2d\u56fd\u6c11\u4e8b\u6cd5\u5f8b\u5173\u7cfb\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u8bc1\u660e\u4e86\u6cd5\u5f8b\u5173\u7cfb\u4fe1\u606f\u5728\u6cd5\u5f8bAI\u4e2d\u7684\u91cd\u8981\u6027\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.13524", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13524", "abs": "https://arxiv.org/abs/2512.13524", "authors": ["Kishan Kumar Ganguly", "Tim Menzies"], "title": "How Low Can You Go? The Data-Light SE Challenge", "comment": null, "summary": "Much of software engineering (SE) research assumes that progress depends on massive datasets and CPU-intensive optimizers. Yet has this assumption been rigorously tested?\n  The counter-evidence presented in this paper suggests otherwise: across dozens of optimization problems from recent SE literature, including software configuration and performance tuning, cloud and systems optimization, project and process-level decision modeling, behavioral analytics, financial risk modeling, project health prediction, reinforcement learning tasks, sales forecasting, and software testing, even with just a few dozen labels, very simple methods (e.g. diversity sampling, a minimal Bayesian learner, or random probes) achieve near 90% of the best reported results. Further, these simple methods perform just as well as more state-of-the-the-art optimizers like SMAC, TPE, DEHB etc. While some tasks would require better outcomes and more sampling, these results seen after a few dozen samples would suffice for many engineering needs (particularly when the goal is rapid and cost-efficient guidance rather than slow and exhaustive optimization).\n  Our results highlight that some SE tasks may be better served by lightweight approaches that demand fewer labels and far less computation. We hence propose the data-light challenge: when will a handful of labels suffice for SE tasks? To enable a large-scale investigation of this issue, we contribute (1) a mathematical formalization of labeling, (2) lightweight baseline algorithms, and (3) results on public-domain data showing the conditions under which lightweight methods excel or fail.\n  For the purposes of open science, our scripts and data are online at https://github.com/KKGanguly/NEO .", "AI": {"tldr": "\u8be5\u8bba\u6587\u8d28\u7591\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u9700\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u7684\u666e\u904d\u5047\u8bbe\uff0c\u53d1\u73b0\u7b80\u5355\u8f7b\u91cf\u7ea7\u65b9\u6cd5\u53ea\u7528\u51e0\u5341\u4e2a\u6807\u7b7e\u5373\u53ef\u8fbe\u523090%\u6700\u4f73\u7ed3\u679c\uff0c\u4e14\u6027\u80fd\u4e0e\u590d\u6742\u4f18\u5316\u5668\u76f8\u5f53\u3002", "motivation": "\u8bc4\u4f30\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u4f7f\u7528\u5927\u91cf\u6570\u636e\u548c\u8ba1\u7b97\u8d44\u6e90\u8fdb\u884c\u4f18\u5316\u7684\u5fc5\u8981\u6027\uff0c\u63a2\u7d22\u662f\u5426\u8f7b\u91cf\u7ea7\u3001\u6570\u636e\u9700\u6c42\u4f4e\u7684\u65b9\u6cd5\u4e5f\u80fd\u53d6\u5f97\u4f18\u79c0\u6548\u679c\u3002", "method": "\u5728\u591a\u79cd\u8f6f\u4ef6\u5de5\u7a0b\u4f18\u5316\u4efb\u52a1\u4e2d\uff0c\u91c7\u7528\u591a\u6837\u6027\u91c7\u6837\u3001\u6781\u7b80\u8d1d\u53f6\u65af\u5b66\u4e60\u5668\u3001\u968f\u673a\u63a2\u6d4b\u7b49\u7b80\u5355\u65b9\u6cd5\uff0c\u5e76\u4e0e\u5f53\u524d\u590d\u6742\u4f18\u5316\u5668\u8fdb\u884c\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u63d0\u51fa\u6570\u636e\u8f7b\u91cf\u5316\u6311\u6218\uff0c\u5e76\u5f62\u5f0f\u5316\u6807\u6ce8\u8fc7\u7a0b\u3002", "result": "\u7b80\u5355\u65b9\u6cd5\u5728\u51e0\u5341\u4e2a\u6807\u7b7e\u6761\u4ef6\u4e0b\u8868\u73b0\u63a5\u8fd1\u6700\u4f18\uff0c\u4f18\u4e8e\u6216\u7b49\u540c\u590d\u6742\u4f18\u5316\u5668\uff0c\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u6ee1\u8db3\u5feb\u901f\u3001\u7ecf\u6d4e\u7684\u5de5\u7a0b\u8981\u6c42\uff1b\u5e76\u5206\u6790\u4e86\u8f7b\u91cf\u5316\u65b9\u6cd5\u6210\u529f\u4e0e\u5931\u8d25\u7684\u6761\u4ef6\u3002", "conclusion": "\u5bf9\u4e8e\u8bb8\u591a\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\uff0c\u8f7b\u91cf\u7ea7\u3001\u5c11\u6807\u7b7e\u7684\u65b9\u6cd5\u53ef\u66ff\u4ee3\u5927\u91cf\u6570\u636e\u548c\u91cd\u5ea6\u8ba1\u7b97\u7684\u4f18\u5316\u7b56\u7565\uff0c\u5efa\u8bae\u793e\u533a\u9488\u5bf9\u4f55\u65f6\u53ef\u7528\u5c11\u91cf\u6807\u7b7e\u8fbe\u6210\u76ee\u6807\u5c55\u5f00\u66f4\u591a\u7814\u7a76\u3002"}}
{"id": "2512.12654", "categories": ["cs.CL", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.12654", "abs": "https://arxiv.org/abs/2512.12654", "authors": ["Hassan Mujtaba", "Hamza Naveed", "Hanzlah Munir"], "title": "Modeling Authorial Style in Urdu Novels Using Character Interaction Graphs and Graph Neural Networks", "comment": "6 pages", "summary": "Authorship analysis has traditionally focused on lexical and stylistic cues within text, while higher-level narrative structure remains underexplored, particularly for low-resource languages such as Urdu. This work proposes a graph-based framework that models Urdu novels as character interaction networks to examine whether authorial style can be inferred from narrative structure alone. Each novel is represented as a graph where nodes correspond to characters and edges denote their co-occurrence within narrative proximity. We systematically compare multiple graph representations, including global structural features, node-level semantic summaries, unsupervised graph embeddings, and supervised graph neural networks. Experiments on a dataset of 52 Urdu novels written by seven authors show that learned graph representations substantially outperform hand-crafted and unsupervised baselines, achieving up to 0.857 accuracy under a strict author-aware evaluation protocol.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u56fe\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u6790\u4e4c\u5c14\u90fd\u8bed\u5c0f\u8bf4\u4e2d\u7684\u4eba\u7269\u4e92\u52a8\u7f51\u7edc\uff0c\u5229\u7528\u53d9\u4e8b\u7ed3\u6784\u8fdb\u884c\u4f5c\u8005\u98ce\u683c\u8bc6\u522b\uff0c\u53d6\u5f97\u4e86\u9ad8\u8fbe0.857\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u8457\u4f5c\u6743\u5206\u6790\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8bcd\u6c47\u548c\u6587\u4f53\u7ebf\u7d22\uff0c\u800c\u9ad8\u5c42\u53d9\u4e8b\u7ed3\u6784\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u4e4c\u5c14\u90fd\u8bed\uff09\u4e2d\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\uff0c\u6545\u672c\u6587\u65e8\u5728\u7814\u7a76\u53d9\u4e8b\u7ed3\u6784\u80fd\u5426\u72ec\u7acb\u63a8\u65ad\u4f5c\u8005\u98ce\u683c\u3002", "method": "\u5c06\u4e4c\u5c14\u90fd\u8bed\u5c0f\u8bf4\u6784\u5efa\u4e3a\u4eba\u7269\u4ea4\u4e92\u56fe\uff0c\u8282\u70b9\u4e3a\u4eba\u7269\uff0c\u8fb9\u8868\u793a\u4eba\u7269\u5728\u53d9\u4e8b\u4e2d\u7684\u8fd1\u90bb\u5171\u73b0\uff0c\u6bd4\u8f83\u591a\u79cd\u56fe\u8868\u793a\u65b9\u6cd5\uff08\u5168\u5c40\u7ed3\u6784\u7279\u5f81\u3001\u8282\u70b9\u8bed\u4e49\u603b\u7ed3\u3001\u65e0\u76d1\u7763\u56fe\u5d4c\u5165\u3001\u76d1\u7763\u56fe\u795e\u7ecf\u7f51\u7edc\uff09\uff0c\u5728\u591a\u4f5c\u8005\u4e4c\u5c14\u90fd\u8bed\u5c0f\u8bf4\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u57fa\u4e8e\u5b66\u4e60\u7684\u56fe\u8868\u793a\u663e\u8457\u4f18\u4e8e\u624b\u5de5\u8bbe\u8ba1\u7684\u7279\u5f81\u53ca\u65e0\u76d1\u7763\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5728\u4e25\u683c\u7684\u4f5c\u8005\u8bc6\u522b\u8bc4\u6d4b\u534f\u8bae\u4e0b\uff0c\u51c6\u786e\u7387\u6700\u9ad8\u8fbe\u52300.857\u3002", "conclusion": "\u53d9\u4e8b\u7ed3\u6784\u4e2d\u4eba\u7269\u4e92\u52a8\u7684\u56fe\u8868\u793a\u80fd\u591f\u6709\u6548\u8f85\u52a9\u4f5c\u8005\u98ce\u683c\u8bc6\u522b\uff0c\u5c24\u5176\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6587\u672c\u5206\u6790\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2512.12677", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12677", "abs": "https://arxiv.org/abs/2512.12677", "authors": ["Amirhossein Yousefiramandi", "Ciaran Cooney"], "title": "Fine-Tuning Causal LLMs for Text Classification: Embedding-Based vs. Instruction-Based Approaches", "comment": "18 pages, 6 figures", "summary": "We explore efficient strategies to fine-tune decoder-only Large Language Models (LLMs) for downstream text classification under resource constraints. Two approaches are investigated: (1) attaching a classification head to a pre-trained causal LLM and fine-tuning on the task (using the LLM's final token embedding as a sequence representation), and (2) instruction-tuning the LLM in a prompt->response format for classification. To enable single-GPU fine-tuning of models up to 8B parameters, we combine 4-bit model quantization with Low-Rank Adaptation (LoRA) for parameter-efficient training. Experiments on two datasets - a proprietary single-label dataset and the public WIPO-Alpha patent dataset (extreme multi-label classification) - show that the embedding-based method significantly outperforms the instruction-tuned method in F1-score, and is very competitive with - even surpassing - fine-tuned domain-specific models (e.g. BERT) on the same tasks. These results demonstrate that directly leveraging the internal representations of causal LLMs, along with efficient fine-tuning techniques, yields impressive classification performance under limited computational resources. We discuss the advantages of each approach while outlining practical guidelines and future directions for optimizing LLM fine-tuning in classification scenarios.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u4e86\u4e24\u79cd\u5728\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u5fae\u8c03\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u6587\u672c\u5206\u7c7b\u7684\u9ad8\u6548\u7b56\u7565\u3002", "motivation": "\u5728\u6709\u9650\u8ba1\u7b97\u8d44\u6e90\u73af\u5883\u4e0b\uff0c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4e0b\u6e38\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u7684\u5fae\u8c03\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u6bd4\u8f83\u4e86\u5728\u9884\u8bad\u7ec3\u56e0\u679c\u8bed\u8a00\u6a21\u578b\u4e0a\u9644\u52a0\u5206\u7c7b\u5934\u5fae\u8c03\u4e0e\u6307\u4ee4\u5fae\u8c03\u4e24\u79cd\u65b9\u6cd5\uff0c\u540c\u65f6\u7ed3\u54084\u4f4d\u91cf\u5316\u548c\u4f4e\u79e9\u9002\u914d\u6280\u672f\u5b9e\u73b0\u5355GPU\u4e0b8B\u53c2\u6570\u6a21\u578b\u7684\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\uff0c\u57fa\u4e8e\u5d4c\u5165\u7684\u5fae\u8c03\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u6307\u4ee4\u5fae\u8c03\uff0c\u4e14\u6027\u80fd\u4e0d\u8f93\u751a\u81f3\u8d85\u8d8a\u4e86\u9886\u57df\u7279\u5b9a\u7684\u5fae\u8c03\u6a21\u578b\u5982BERT\u3002", "conclusion": "\u5229\u7528\u56e0\u679cLLM\u5185\u90e8\u8868\u793a\u7ed3\u5408\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff0c\u5728\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u83b7\u5f97\u4f18\u5f02\u7684\u6587\u672c\u5206\u7c7b\u6027\u80fd\uff0c\u4e3aLLM\u5728\u5b9e\u9645\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u5fae\u8c03\u63d0\u4f9b\u4e86\u6709\u6548\u7b56\u7565\u548c\u6307\u5bfc\u3002"}}
{"id": "2512.13655", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.13655", "abs": "https://arxiv.org/abs/2512.13655", "authors": ["Richard J. Young"], "title": "Comparative Analysis of LLM Abliteration Methods: A Cross-Architecture Evaluation", "comment": "25 pages, 6 figures, 8 tables", "summary": "Safety alignment mechanisms in large language models prevent responses to harmful queries through learned refusal behavior, yet these same mechanisms impede legitimate research applications including cognitive modeling, adversarial testing, and security analysis. While abliteration techniques enable surgical removal of refusal representations through directional orthogonalization, the relative effectiveness of available implementations remains uncharacterized. This study evaluates four abliteration tools (Heretic, DECCP, ErisForge, FailSpy) across sixteen instruction-tuned models (7B-14B parameters), reporting tool compatibility on all 16 models and quantitative metrics on subsets dictated by tool support. Single-pass methods demonstrated superior capability preservation on the benchmarked subset (avg GSM8K change across three models: ErisForge -0.28 pp; DECCP -0.13 pp), while Bayesian-optimized abliteration produced variable distribution shift (KL divergence: 0.043-1.646) with model-dependent capability impact. These findings provide researchers with evidence-based selection criteria for abliteration tool deployment across diverse model architectures. The principal finding indicates that mathematical reasoning capabilities exhibit the highest sensitivity to abliteration interventions, with GSM8K change ranging from +1.51 pp to -18.81 pp (-26.5% relative) depending on tool selection and model architecture.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u56db\u79cd\u6d88\u878d\u5de5\u5177\u5bf916\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5355\u904d\u65b9\u6cd5\u5728\u4fdd\u6301\u80fd\u529b\u65b9\u9762\u8868\u73b0\u66f4\u4f18\uff0c\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5bf9\u6d88\u878d\u6700\u654f\u611f\u3002", "motivation": "\u5b89\u5168\u5bf9\u9f50\u673a\u5236\u867d\u7136\u9632\u6b62\u6709\u5bb3\u54cd\u5e94\uff0c\u4f46\u963b\u788d\u4e86\u8ba4\u77e5\u5efa\u6a21\u7b49\u5408\u6cd5\u7814\u7a76\uff0c\u9700\u8bc4\u4f30\u73b0\u6709\u6d88\u878d\u6280\u672f\u7684\u6709\u6548\u6027\u3002", "method": "\u6bd4\u8f83\u56db\u79cd\u6d88\u878d\u5de5\u5177\u572816\u4e2a\u4e0d\u540c\u89c4\u6a21\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u517c\u5bb9\u6027\u548c\u6027\u80fd\u5f71\u54cd\uff0c\u901a\u8fc7\u5b9a\u91cf\u6307\u6807\u8bc4\u4f30\u80fd\u529b\u4fdd\u7559\u548c\u5206\u5e03\u53d8\u5316\u3002", "result": "\u5355\u904d\u6d88\u878d\u65b9\u6cd5\u5728\u90e8\u5206\u6a21\u578b\u4e0a\u4fdd\u6301\u4e86\u66f4\u597d\u7684\u6027\u80fd\uff0c\u8d1d\u53f6\u65af\u4f18\u5316\u6d88\u878d\u5bfc\u81f4\u5206\u5e03\u6f02\u79fb\u4e14\u6548\u679c\u4f9d\u6a21\u578b\u800c\u5f02\uff0c\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5bf9\u6d88\u878d\u5f71\u54cd\u6700\u5927\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u6d88\u878d\u5de5\u5177\u9009\u62e9\u4f9d\u636e\uff0c\u6307\u51fa\u6d88\u878d\u5bf9\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u654f\u611f\u6027\u662f\u4e3b\u8981\u53d1\u73b0\u3002"}}
{"id": "2512.12716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12716", "abs": "https://arxiv.org/abs/2512.12716", "authors": ["Xuanzhang Liu", "Jianglun Feng", "Zhuoran Zhuang", "Junzhe Zhao", "Maofei Que", "Jieting Li", "Dianlei Wang", "Hao Tong", "Ye Chen", "Pan Li"], "title": "CoDA: A Context-Decoupled Hierarchical Agent with Reinforcement Learning", "comment": "Accepted to WSDM '26 Oral", "summary": "Large Language Model (LLM) agents trained with reinforcement learning (RL) show great promise for solving complex, multi-step tasks. However, their performance is often crippled by \"Context Explosion\", where the accumulation of long text outputs overwhelms the model's context window and leads to reasoning failures. To address this, we introduce CoDA, a Context-Decoupled hierarchical Agent, a simple but effective reinforcement learning framework that decouples high-level planning from low-level execution. It employs a single, shared LLM backbone that learns to operate in two distinct, contextually isolated roles: a high-level Planner that decomposes tasks within a concise strategic context, and a low-level Executor that handles tool interactions in an ephemeral, isolated workspace. We train this unified agent end-to-end using PECO (Planner-Executor Co-Optimization), a reinforcement learning methodology that applies a trajectory-level reward to jointly optimize both roles, fostering seamless collaboration through context-dependent policy updates. Extensive experiments demonstrate that CoDA achieves significant performance improvements over state-of-the-art baselines on complex multi-hop question-answering benchmarks, and it exhibits strong robustness in long-context scenarios, maintaining stable performance while all other baselines suffer severe degradation, thus further validating the effectiveness of our hierarchical design in mitigating context overload.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86CoDA\uff0c\u4e00\u79cd\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u5c06\u9ad8\u5c42\u89c4\u5212\u4e0e\u4f4e\u5c42\u6267\u884c\u89e3\u8026\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u6b65\u9aa4\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5c24\u5176\u5728\u4e0a\u4e0b\u6587\u7206\u70b8\u95ee\u9898\u4e0b\u5c55\u793a\u4e86\u5f3a\u9c81\u68d2\u6027\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u4efb\u52a1\u65f6\u56e0\u201c\u4e0a\u4e0b\u6587\u7206\u70b8\u201d\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u6025\u9700\u4e00\u79cd\u65b9\u6cd5\u6765\u7f13\u89e3\u957f\u6587\u672c\u7d2f\u79ef\u5bf9\u6a21\u578b\u4e0a\u4e0b\u6587\u7a97\u53e3\u7684\u5f71\u54cd\u3002", "method": "CoDA\u91c7\u7528\u4e00\u4e2a\u5171\u4eab\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5206\u522b\u4f5c\u4e3a\u9ad8\u5c42\u89c4\u5212\u8005\u548c\u4f4e\u5c42\u6267\u884c\u8005\u5de5\u4f5c\uff0c\u5229\u7528PECO\u65b9\u6cd5\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\uff0c\u901a\u8fc7\u7b56\u7565\u66f4\u65b0\u5b9e\u73b0\u4e24\u8005\u5728\u4e0a\u4e0b\u6587\u9694\u79bb\u73af\u5883\u4e0b\u7684\u534f\u540c\u4f18\u5316\u3002", "result": "CoDA\u5728\u591a\u4e2a\u590d\u6742\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8fc7\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e14\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u4e0d\u53d7\u4e0a\u4e0b\u6587\u7206\u70b8\u5f71\u54cd\u3002", "conclusion": "\u5206\u5c42\u8bbe\u8ba1\u53ca\u4e0a\u4e0b\u6587\u89e3\u8026\u6709\u6548\u7f13\u89e3\u4e86\u4e0a\u4e0b\u6587\u8fc7\u8f7d\u95ee\u9898\uff0c\u4f7f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u4efb\u52a1\u4e2d\u6027\u80fd\u63d0\u5347\u548c\u9c81\u68d2\u6027\u589e\u5f3a\uff0c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2512.12730", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12730", "abs": "https://arxiv.org/abs/2512.12730", "authors": ["Jingzhe Ding", "Shengda Long", "Changxin Pu", "Huan Zhou", "Hongwan Gao", "Xiang Gao", "Chao He", "Yue Hou", "Fei Hu", "Zhaojian Li", "Weiran Shi", "Zaiyuan Wang", "Daoguang Zan", "Chenchen Zhang", "Xiaoxu Zhang", "Qizhi Chen", "Xianfu Cheng", "Bo Deng", "Qingshui Gu", "Kai Hua", "Juntao Lin", "Pai Liu", "Mingchen Li", "Xuanguang Pan", "Zifan Peng", "Yujia Qin", "Yong Shan", "Zhewen Tan", "Weihao Xie", "Zihan Wang", "Yishuo Yuan", "Jiayu Zhang", "Enduo Zhao", "Yunfei Zhao", "He Zhu", "Chenyang Zou", "Ming Ding", "Jianpeng Jiao", "Jiaheng Liu", "Minghao Liu", "Qian Liu", "Chongyao Tao", "Jian Yang", "Tong Yang", "Zhaoxiang Zhang", "Xinjie Chen", "Wenhao Huang", "Ge Zhang"], "title": "NL2Repo-Bench: Towards Long-Horizon Repository Generation Evaluation of Coding Agents", "comment": null, "summary": "Recent advances in coding agents suggest rapid progress toward autonomous software development, yet existing benchmarks fail to rigorously evaluate the long-horizon capabilities required to build complete software systems. Most prior evaluations focus on localized code generation, scaffolded completion, or short-term repair tasks, leaving open the question of whether agents can sustain coherent reasoning, planning, and execution over the extended horizons demanded by real-world repository construction. To address this gap, we present NL2Repo Bench, a benchmark explicitly designed to evaluate the long-horizon repository generation ability of coding agents. Given only a single natural-language requirements document and an empty workspace, agents must autonomously design the architecture, manage dependencies, implement multi-module logic, and produce a fully installable Python library. Our experiments across state-of-the-art open- and closed-source models reveal that long-horizon repository generation remains largely unsolved: even the strongest agents achieve below 40% average test pass rates and rarely complete an entire repository correctly. Detailed analysis uncovers fundamental long-horizon failure modes, including premature termination, loss of global coherence, fragile cross-file dependencies, and inadequate planning over hundreds of interaction steps. NL2Repo Bench establishes a rigorous, verifiable testbed for measuring sustained agentic competence and highlights long-horizon reasoning as a central bottleneck for the next generation of autonomous coding agents.", "AI": {"tldr": "\u5f53\u524d\u7f16\u7801\u667a\u80fd\u4f53\u5728\u957f\u8fdc\u81ea\u52a8\u6784\u5efa\u5b8c\u6574\u8f6f\u4ef6\u7cfb\u7edf\u7684\u80fd\u529b\u8bc4\u4f30\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u63d0\u51faNL2Repo Bench\u57fa\u51c6\u4e13\u95e8\u6d4b\u8bd5\u957f\u65f6\u7a0b\u4ed3\u5e93\u751f\u6210\u80fd\u529b\uff0c\u5b9e\u9a8c\u663e\u793a\u73b0\u6709\u6a21\u578b\u8868\u73b0\u4e0d\u8db3\uff0c\u957f\u65f6\u7a0b\u63a8\u7406\u4f9d\u7136\u662f\u6838\u5fc3\u74f6\u9888\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u591a\u805a\u7126\u4e8e\u5c40\u90e8\u4ee3\u7801\u751f\u6210\u548c\u77ed\u671f\u4fee\u590d\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u667a\u80fd\u4f53\u5728\u957f\u65f6\u95f4\u8de8\u5ea6\u5185\u4fdd\u6301\u4e00\u81f4\u63a8\u7406\u3001\u89c4\u5212\u548c\u6267\u884c\u80fd\u529b\u7684\u8bc4\u4f30\uff0c\u9650\u5236\u4e86\u5bf9\u771f\u5b9e\u8f6f\u4ef6\u4ed3\u5e93\u6784\u5efa\u80fd\u529b\u7684\u9a8c\u8bc1\u3002", "method": "\u8bbe\u8ba1NL2Repo Bench\u57fa\u51c6\uff0c\u8981\u6c42\u667a\u80fd\u4f53\u4ec5\u51ed\u5355\u4e00\u81ea\u7136\u8bed\u8a00\u9700\u6c42\u6587\u6863\u548c\u7a7a\u5de5\u4f5c\u533a\uff0c\u72ec\u7acb\u8bbe\u8ba1\u67b6\u6784\u3001\u7ba1\u7406\u4f9d\u8d56\u3001\u5b9e\u73b0\u591a\u6a21\u5757\u903b\u8f91\uff0c\u5e76\u751f\u4ea7\u53ef\u5b89\u88c5\u7684\u5b8c\u6574Python\u5e93\u3002", "result": "\u6d4b\u8bd5\u4e3b\u6d41\u5f00\u6e90\u53ca\u95ed\u6e90\u6a21\u578b\u540e\u53d1\u73b0\u957f\u65f6\u7a0b\u4ed3\u5e93\u751f\u6210\u4efb\u52a1\u96be\u4ee5\u7a81\u7834\uff0c\u6700\u9ad8\u5e73\u5747\u6d4b\u8bd5\u901a\u8fc7\u7387\u4f4e\u4e8e40%\uff0c\u5b8c\u6574\u4ed3\u5e93\u6b63\u786e\u6784\u5efa\u6781\u5c11\uff0c\u5b58\u5728\u65e9\u671f\u7ec8\u6b62\u3001\u5168\u5c40\u8fde\u8d2f\u6027\u4e27\u5931\u3001\u4ea4\u53c9\u6587\u4ef6\u4f9d\u8d56\u8106\u5f31\u53ca\u8ba1\u5212\u4e0d\u8db3\u7b49\u95ee\u9898\u3002", "conclusion": "NL2Repo Bench\u63d0\u4f9b\u4e86\u4e25\u683c\u4e14\u53ef\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u660e\u786e\u6307\u51fa\u957f\u65f6\u7a0b\u63a8\u7406\u662f\u5b9e\u73b0\u9ad8\u5ea6\u81ea\u6cbb\u7f16\u7801\u667a\u80fd\u4f53\u7684\u4e3b\u8981\u74f6\u9888\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2512.12770", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12770", "abs": "https://arxiv.org/abs/2512.12770", "authors": ["Thales Sales Almeida", "Rodrigo Nogueira", "H\u00e9lio Pedrini"], "title": "Curi\u00f3-Edu 7B: Examining Data Selection Impacts in LLM Continued Pretraining", "comment": null, "summary": "Continued pretraining extends a language model's capabilities by further exposing it to additional data, often tailored to a specific linguistic or domain context. This strategy has emerged as an efficient alternative to full retraining when adapting general-purpose models to new settings. In this work, we investigate this paradigm through Curi\u00f3 7B, a 7-billion-parameter model derived from LLaMA-2 and trained on 100 billion Portuguese tokens from the ClassiCC-PT corpus - the most extensive Portuguese-specific continued-pretraining effort above the three-billion-parameter scale to date. Beyond scale, we investigate whether quantity alone suffices or whether data quality plays a decisive role in linguistic adaptation. To this end, we introduce Curi\u00f3-Edu 7B, a variant trained exclusively on the educational and STEM-filtered subset of the same corpus, totaling just 10 billion tokens. Despite using only 10% of the data and 20% of the computation, Curi\u00f3-Edu 7B surpasses the full-corpus model in our evaluations, demonstrating that data selection can be fundamental even when adapting models with limited prior exposure to the target language. The developed models are available at https://huggingface.co/collections/ClassiCC-Corpus/curio-edu", "AI": {"tldr": "\u672c\u8bba\u6587\u7814\u7a76\u4e86\u901a\u8fc7\u6301\u7eed\u9884\u8bad\u7ec3\u6765\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u8bed\u8a00\u73af\u5883\u7684\u80fd\u529b\uff0c\u91cd\u70b9\u5728\u4e8e\u6570\u636e\u8d28\u91cf\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u7ed3\u679c\u8868\u660e\u7cbe\u9009\u6570\u636e\u8bad\u7ec3\u7684\u5c0f\u89c4\u6a21\u6a21\u578b\u6548\u679c\u4f18\u4e8e\u4f7f\u7528\u5168\u90e8\u6570\u636e\u7684\u5927\u89c4\u6a21\u6a21\u578b\u3002", "motivation": "\u76ee\u524d\u5728\u5c06\u901a\u7528\u8bed\u8a00\u6a21\u578b\u9002\u5e94\u7279\u5b9a\u8bed\u8a00\u6216\u9886\u57df\u65f6\uff0c\u6301\u7eed\u9884\u8bad\u7ec3\u662f\u4e00\u79cd\u9ad8\u6548\u66ff\u4ee3\u5b8c\u6574\u91cd\u8bad\u7ec3\u7684\u7b56\u7565\u3002\u7136\u800c\u4ecd\u4e0d\u6e05\u695a\u5728\u6301\u7eed\u9884\u8bad\u7ec3\u4e2d\uff0c\u662f\u6570\u636e\u91cf\u8fd8\u662f\u6570\u636e\u8d28\u91cf\u53d1\u6325\u4e86\u66f4\u5173\u952e\u7684\u4f5c\u7528\u3002", "method": "\u4f5c\u8005\u57fa\u4e8eLLaMA-2\u6a21\u578b\uff0c\u5229\u7528ClassiCC-PT\u8bed\u6599\u5e93\u4e2d\u76841000\u4ebf\u8461\u8404\u7259\u8bed\u6807\u8bb0\u8fdb\u884c\u6301\u7eed\u9884\u8bad\u7ec3\uff0c\u6784\u5efa\u4e86Curi\u00f3 7B\u6a21\u578b\u3002\u540c\u65f6\u8bad\u7ec3\u4e86\u4ec5\u7528\u8be5\u8bed\u6599\u5e93\u4e2d\u6559\u80b2\u548cSTEM\u9886\u57df\u7b5b\u9009\u51fa\u7684100\u4ebf\u6807\u8bb0\u6570\u636e\u7684Curi\u00f3-Edu 7B\u5c0f\u89c4\u6a21\u6a21\u578b\u3002", "result": "\u5c3d\u7ba1Curi\u00f3-Edu 7B\u53ea\u4f7f\u7528\u4e8610%\u7684\u6570\u636e\u548c20%\u7684\u8ba1\u7b97\u8d44\u6e90\uff0c\u5176\u5728\u591a\u9879\u8bc4\u6d4b\u4e2d\u8868\u73b0\u8d85\u8fc7\u4e86\u7528\u5168\u90e8\u6570\u636e\u8bad\u7ec3\u7684Curi\u00f3 7B\u6a21\u578b\u3002", "conclusion": "\u6570\u636e\u8d28\u91cf\u548c\u7cbe\u9009\u5bf9\u8bed\u8a00\u6a21\u578b\u7684\u9886\u57df\u9002\u5e94\u81f3\u5173\u91cd\u8981\uff0c\u5728\u8d44\u6e90\u6709\u9650\u60c5\u51b5\u4e0b\uff0c\u7cbe\u9009\u9ad8\u8d28\u91cf\u6570\u636e\u8bad\u7ec3\u7684\u5c0f\u89c4\u6a21\u6a21\u578b\u80fd\u53d6\u5f97\u66f4\u4f18\u6027\u80fd\u3002"}}
{"id": "2512.12775", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12775", "abs": "https://arxiv.org/abs/2512.12775", "authors": ["Pedro Henrique Luz de Araujo", "Michael A. Hedderich", "Ali Modarressi", "Hinrich Schuetze", "Benjamin Roth"], "title": "Persistent Personas? Role-Playing, Instruction Following, and Safety in Extended Interactions", "comment": "31 pages, 35 figures", "summary": "Persona-assigned large language models (LLMs) are used in domains such as education, healthcare, and sociodemographic simulation. Yet, they are typically evaluated only in short, single-round settings that do not reflect real-world usage. We introduce an evaluation protocol that combines long persona dialogues (over 100 rounds) and evaluation datasets to create dialogue-conditioned benchmarks that can robustly measure long-context effects. We then investigate the effects of dialogue length on persona fidelity, instruction-following, and safety of seven state-of-the-art open- and closed-weight LLMs. We find that persona fidelity degrades over the course of dialogues, especially in goal-oriented conversations, where models must sustain both persona fidelity and instruction following. We identify a trade-off between fidelity and instruction following, with non-persona baselines initially outperforming persona-assigned models; as dialogues progress and fidelity fades, persona responses become increasingly similar to baseline responses. Our findings highlight the fragility of persona applications in extended interactions and our work provides a protocol to systematically measure such failures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u957f\u8f6e\u6b21\uff08\u8d85\u8fc7100\u8f6e\uff09\u5bf9\u8bdd\u7684\u8bc4\u4f30\u534f\u8bae\uff0c\u4ee5\u7cfb\u7edf\u6d4b\u91cf\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u4fdd\u6301\u4eba\u683c\u4e00\u81f4\u6027\u7684\u80fd\u529b\u3002\u901a\u8fc7\u5bf9\u4e03\u6b3e\u4e3b\u6d41\u6a21\u578b\u7684\u6d4b\u8bd5\uff0c\u53d1\u73b0\u4eba\u683c\u4e00\u81f4\u6027\u968f\u5bf9\u8bdd\u957f\u5ea6\u589e\u52a0\u800c\u4e0b\u964d\uff0c\u4e14\u5728\u4eba\u683c\u4e0e\u6307\u4ee4\u6267\u884c\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u683c\u8d4b\u4e88\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bc4\u4f30\u591a\u9650\u4e8e\u77ed\u8f6e\u6b21\uff0c\u4e0d\u80fd\u53cd\u6620\u5b9e\u9645\u957f\u65f6\u95f4\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\uff0c\u9700\u8981\u66f4\u771f\u5b9e\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u8bbe\u8ba1\u4e86\u7ed3\u5408\u957f\u8f6e\u6b21\u4eba\u683c\u5bf9\u8bdd\u548c\u8bc4\u4f30\u6570\u636e\u96c6\u7684\u7efc\u5408\u8bc4\u6d4b\u534f\u8bae\uff0c\u5bf9\u4e03\u6b3e\u5f00\u653e\u53ca\u5c01\u95ed\u6743\u91cd\u7684\u6700\u65b0\u6a21\u578b\u8fdb\u884c\u4eba\u683c\u5fe0\u5b9e\u5ea6\u3001\u6307\u4ee4\u9075\u5faa\u53ca\u5b89\u5168\u6027\u7684\u957f\u4e0a\u4e0b\u6587\u6548\u5e94\u5206\u6790\u3002", "result": "\u968f\u7740\u5bf9\u8bdd\u6df1\u5165\uff0c\u6a21\u578b\u7684\u4eba\u683c\u5fe0\u5b9e\u5ea6\u4e0b\u964d\uff0c\u7279\u522b\u662f\u5728\u9700\u8981\u540c\u65f6\u4fdd\u6301\u4eba\u683c\u4e00\u81f4\u548c\u6267\u884c\u6307\u4ee4\u7684\u76ee\u6807\u5bfc\u5411\u5bf9\u8bdd\u4e2d\uff1b\u4eba\u683c\u6a21\u578b\u8868\u73b0\u521d\u671f\u4e0d\u53ca\u975e\u4eba\u683c\u57fa\u7ebf\uff0c\u540e\u671f\u56e0\u5fe0\u5b9e\u5ea6\u964d\u4f4e\u9010\u6e10\u8d8b\u8fd1\u57fa\u7ebf\u8868\u73b0\u3002", "conclusion": "\u4eba\u683c\u8d4b\u80fd\u7684\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u65f6\u95f4\u5bf9\u8bdd\u4e2d\u8868\u73b0\u8106\u5f31\uff0c\u672c\u6587\u63d0\u4f9b\u7684\u8bc4\u4f30\u534f\u8bae\u4e3a\u7cfb\u7edf\u6d4b\u91cf\u548c\u6539\u8fdb\u6b64\u7c7b\u6a21\u578b\u7684\u957f\u5bf9\u8bdd\u6027\u80fd\u63d0\u4f9b\u4e86\u5de5\u5177\u3002"}}
{"id": "2512.12777", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12777", "abs": "https://arxiv.org/abs/2512.12777", "authors": ["Mosh Levy", "Zohar Elyoseph", "Shauli Ravfogel", "Yoav Goldberg"], "title": "State over Tokens: Characterizing the Role of Reasoning Tokens", "comment": null, "summary": "Large Language Models (LLMs) can generate reasoning tokens before their final answer to boost performance on complex tasks. While these sequences seem like human thought processes, empirical evidence reveals that they are not a faithful explanation of the model's actual reasoning process. To address this gap between appearance and function, we introduce the State over Tokens (SoT) conceptual framework. SoT reframes reasoning tokens not as a linguistic narrative, but as an externalized computational state -- the sole persistent information carrier across the model's stateless generation cycles. This explains how the tokens can drive correct reasoning without being a faithful explanation when read as text and surfaces previously overlooked research questions on these tokens. We argue that to truly understand the process that LLMs do, research must move beyond reading the reasoning tokens as text and focus on decoding them as state.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86State over Tokens (SoT)\u6846\u67b6\uff0c\u91cd\u65b0\u5b9a\u4e49\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u6807\u8bb0\uff0c\u5c06\u5176\u89c6\u4e3a\u8ba1\u7b97\u72b6\u6001\u800c\u975e\u6587\u672c\u53d9\u8ff0\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u6807\u8bb0\u867d\u4f3c\u4eba\u7c7b\u601d\u7ef4\u8fc7\u7a0b\uff0c\u4f46\u5e76\u4e0d\u771f\u5b9e\u53cd\u6620\u6a21\u578b\u7684\u5b9e\u9645\u63a8\u7406\uff0c\u5b58\u5728\u5f62\u8c61\u4e0e\u529f\u80fd\u7684\u5dee\u8ddd\u3002", "method": "\u5f15\u5165SoT\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u6807\u8bb0\u89c6\u4e3a\u8de8\u751f\u6210\u5468\u671f\u7684\u6301\u4e45\u8ba1\u7b97\u72b6\u6001\uff0c\u800c\u975e\u8bed\u8a00\u53d9\u8ff0\uff0c\u4ece\u8ba1\u7b97\u72b6\u6001\u89d2\u5ea6\u89e3\u8bfb\u63a8\u7406\u6807\u8bb0\u3002", "result": "SoT\u6846\u67b6\u89e3\u91ca\u4e86\u6a21\u578b\u5982\u4f55\u4f9d\u9760\u63a8\u7406\u6807\u8bb0\u6b63\u786e\u63a8\u7406\u4f46\u6587\u672c\u5f62\u5f0f\u4e0d\u771f\u5b9e\u53cd\u6620\u5185\u5728\u8fc7\u7a0b\uff0c\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u7814\u7a76\u95ee\u9898\u3002", "conclusion": "\u8981\u6df1\u5165\u7406\u89e3\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8fc7\u7a0b\uff0c\u7814\u7a76\u5e94\u6452\u5f03\u5c06\u63a8\u7406\u6807\u8bb0\u4f5c\u4e3a\u6587\u672c\u8bfb\u53d6\uff0c\u8f6c\u800c\u5173\u6ce8\u5176\u4f5c\u4e3a\u72b6\u6001\u7684\u89e3\u7801\u3002"}}
{"id": "2512.12812", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12812", "abs": "https://arxiv.org/abs/2512.12812", "authors": ["Hanyu Cai", "Binqi Shen", "Lier Jin", "Lan Hu", "Xiaojing Fan"], "title": "Does Tone Change the Answer? Evaluating Prompt Politeness Effects on Modern LLMs: GPT, Gemini, LLaMA", "comment": null, "summary": "Prompt engineering has emerged as a critical factor influencing large language model (LLM) performance, yet the impact of pragmatic elements such as linguistic tone and politeness remains underexplored, particularly across different model families. In this work, we propose a systematic evaluation framework to examine how interaction tone affects model accuracy and apply it to three recently released and widely available LLMs: GPT-4o mini (OpenAI), Gemini 2.0 Flash (Google DeepMind), and Llama 4 Scout (Meta). Using the MMMLU benchmark, we evaluate model performance under Very Friendly, Neutral, and Very Rude prompt variants across six tasks spanning STEM and Humanities domains, and analyze pairwise accuracy differences with statistical significance testing.\n  Our results show that tone sensitivity is both model-dependent and domain-specific. Neutral or Very Friendly prompts generally yield higher accuracy than Very Rude prompts, but statistically significant effects appear only in a subset of Humanities tasks, where rude tone reduces accuracy for GPT and Llama, while Gemini remains comparatively tone-insensitive. When performance is aggregated across tasks within each domain, tone effects diminish and largely lose statistical significance. Compared with earlier researches, these findings suggest that dataset scale and coverage materially influence the detection of tone effects. Overall, our study indicates that while interaction tone can matter in specific interpretive settings, modern LLMs are broadly robust to tonal variation in typical mixed-domain use, providing practical guidance for prompt design and model selection in real-world deployments.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u4e0d\u540c\u8bed\u6c14\uff08\u53cb\u597d\u3001\u4e2d\u7acb\u3001\u65e0\u793c\uff09\u5bf9\u4e09\u6b3e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08GPT-4o mini\u3001Gemini 2.0 Flash\u3001Llama 4 Scout\uff09\u5728STEM\u548c\u4eba\u6587\u9886\u57df\u4efb\u52a1\u4e0a\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u8bed\u6c14\u6548\u5e94\u56e0\u6a21\u578b\u548c\u9886\u57df\u800c\u5f02\uff0c\u4eba\u6587\u9886\u57df\u4e2d\u65e0\u793c\u8bed\u6c14\u663e\u8457\u964d\u4f4e\u90e8\u5206\u6a21\u578b\u8868\u73b0\uff0c\u800c\u6574\u4f53\u6765\u770b\u73b0\u4ee3\u6a21\u578b\u5bf9\u8bed\u6c14\u53d8\u5316\u8f83\u4e3a\u9c81\u68d2\u3002", "motivation": "\u63a2\u7a76\u63d0\u793a\u8bed\u4e2d\u7684\u8bed\u6c14\u548c\u793c\u8c8c\u7b49\u8bed\u7528\u5143\u7d20\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u4e0d\u540c\u6a21\u578b\u5bb6\u65cf\u95f4\u7684\u5dee\u5f02\uff0c\u8fd9\u5728\u73b0\u6709\u7814\u7a76\u4e2d\u5c1a\u672a\u5145\u5206\u6d89\u53ca\u3002", "method": "\u8bbe\u8ba1\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\uff0c\u57fa\u4e8eMMMLU\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5728\u516d\u9879\u8de8\u9886\u57df\u4efb\u52a1\u4e2d\uff0c\u6bd4\u8f83Very Friendly\u3001Neutral\u548cVery Rude\u4e09\u79cd\u8bed\u6c14\u7684\u63d0\u793a\uff0c\u5bf9\u4e09\u6b3e\u6700\u65b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u51c6\u786e\u7387\u6d4b\u8bd5\u5e76\u505a\u7edf\u8ba1\u663e\u8457\u6027\u5206\u6790\u3002", "result": "\u7ed3\u679c\u663e\u793a\u8bed\u6c14\u654f\u611f\u6027\u4f9d\u8d56\u4e8e\u6a21\u578b\u548c\u9886\u57df\uff0c\u4eba\u6587\u4efb\u52a1\u4e2d\u65e0\u793c\u8bed\u6c14\u663e\u8457\u964d\u4f4eGPT\u548cLlama\u7684\u51c6\u786e\u7387\uff0c\u800cGemini\u8bed\u6c14\u5f71\u54cd\u8f83\u5c0f\uff1bSTEM\u9886\u57df\u53ca\u8de8\u9886\u57df\u805a\u5408\u7ed3\u679c\u4e2d\u8bed\u6c14\u5f71\u54cd\u51cf\u5f31\u4e14\u65e0\u7edf\u8ba1\u663e\u8457\u6027\u3002\u6570\u636e\u89c4\u6a21\u548c\u8986\u76d6\u8303\u56f4\u5f71\u54cd\u8bed\u6c14\u6548\u5e94\u7684\u68c0\u6d4b\u3002", "conclusion": "\u4ea4\u4e92\u8bed\u6c14\u5728\u7279\u5b9a\u89e3\u91ca\u6027\u4efb\u52a1\u4e2d\u786e\u5b9e\u5f71\u54cd\u6a21\u578b\u8868\u73b0\uff0c\u4f46\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6574\u4f53\u5bf9\u8bed\u6c14\u53d8\u5316\u8f83\u9c81\u68d2\uff0c\u63d0\u793a\u8bbe\u8ba1\u548c\u6a21\u578b\u9009\u62e9\u65f6\u5e94\u8003\u8651\u5177\u4f53\u5e94\u7528\u573a\u666f\uff0c\u63d0\u4f9b\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u53c2\u8003\u65b9\u5411\u3002"}}
{"id": "2512.12818", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12818", "abs": "https://arxiv.org/abs/2512.12818", "authors": ["Chris Latimer", "Nicol\u00f3 Boschi", "Andrew Neeser", "Chris Bartholomew", "Gaurav Srivastava", "Xuan Wang", "Naren Ramakrishnan"], "title": "Hindsight is 20/20: Building Agent Memory that Retains, Recalls, and Reflects", "comment": null, "summary": "Agent memory has been touted as a dimension of growth for LLM-based applications, enabling agents that can accumulate experience, adapt across sessions, and move beyond single-shot question answering. The current generation of agent memory systems treats memory as an external layer that extracts salient snippets from conversations, stores them in vector or graph-based stores, and retrieves top-k items into the prompt of an otherwise stateless model. While these systems improve personalization and context carry-over, they still blur the line between evidence and inference, struggle to organize information over long horizons, and offer limited support for agents that must explain their reasoning. We present Hindsight, a memory architecture that treats agent memory as a structured, first-class substrate for reasoning by organizing it into four logical networks that distinguish world facts, agent experiences, synthesized entity summaries, and evolving beliefs. This framework supports three core operations -- retain, recall, and reflect -- that govern how information is added, accessed, and updated. Under this abstraction, a temporal, entity aware memory layer incrementally turns conversational streams into a structured, queryable memory bank, while a reflection layer reasons over this bank to produce answers and to update information in a traceable way. On key long-horizon conversational memory benchmarks like LongMemEval and LoCoMo, Hindsight with an open-source 20B model lifts overall accuracy from 39% to 83.6% over a full-context baseline with the same backbone and outperforms full context GPT-4o. Scaling the backbone further pushes Hindsight to 91.4% on LongMemEval and up to 89.61% on LoCoMo (vs. 75.78% for the strongest prior open system), consistently outperforming existing memory architectures on multi-session and open-domain questions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Hindsight\uff0c\u4e00\u79cd\u7ed3\u6784\u5316\u7684\u4ee3\u7406\u8bb0\u5fc6\u67b6\u6784\uff0c\u901a\u8fc7\u56db\u4e2a\u903b\u8f91\u7f51\u7edc\u7ec4\u7ec7\u8bb0\u5fc6\uff0c\u5b9e\u73b0\u4fe1\u606f\u7684\u4fdd\u7559\u3001\u56de\u5fc6\u548c\u53cd\u601d\uff0c\u5728\u591a\u4f1a\u8bdd\u548c\u957f\u65f6\u8bb0\u5fc6\u4efb\u52a1\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u7684\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u5c06\u8bb0\u5fc6\u4f5c\u4e3a\u5916\u90e8\u5c42\u5b58\u50a8\u63d0\u53d6\u7684\u4f1a\u8bdd\u7247\u6bb5\uff0c\u5b58\u5728\u8bc1\u636e\u548c\u63a8\u7406\u6a21\u7cca\u3001\u957f\u65f6\u4fe1\u606f\u7ec4\u7ec7\u56f0\u96be\u53ca\u63a8\u7406\u89e3\u91ca\u652f\u6301\u6709\u9650\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u66f4\u7ed3\u6784\u5316\u548c\u63a8\u7406\u53cb\u597d\u7684\u8bb0\u5fc6\u67b6\u6784\u3002", "method": "Hindsight\u5c06\u4ee3\u7406\u8bb0\u5fc6\u5206\u4e3a\u4e16\u754c\u4e8b\u5b9e\u3001\u4ee3\u7406\u7ecf\u9a8c\u3001\u5b9e\u4f53\u603b\u7ed3\u548c\u6f14\u53d8\u4fe1\u5ff5\u56db\u4e2a\u903b\u8f91\u7f51\u7edc\uff0c\u652f\u6301\u4fe1\u606f\u7684\u4fdd\u7559\u3001\u56de\u5fc6\u548c\u53cd\u601d\u64cd\u4f5c\uff0c\u901a\u8fc7\u65f6\u95f4\u548c\u5b9e\u4f53\u611f\u77e5\u7684\u8bb0\u5fc6\u5c42\u6784\u9020\u7ed3\u6784\u5316\u3001\u53ef\u67e5\u8be2\u7684\u8bb0\u5fc6\u5e93\uff0c\u53cd\u601d\u5c42\u8d1f\u8d23\u63a8\u7406\u548c\u53ef\u8ffd\u6eaf\u7684\u4fe1\u606f\u66f4\u65b0\u3002", "result": "\u5728LongMemEval\u548cLoCoMo\u7b49\u957f\u65f6\u8bb0\u5fc6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHindsight\u4f7f\u7528\u5f00\u6e9020B\u6a21\u578b\u5c06\u51c6\u786e\u7387\u4ece39%\u63d0\u5347\u81f383.6%\uff0c\u5e76\u4f18\u4e8e\u5b8c\u6574\u4e0a\u4e0b\u6587\u7684GPT-4o\uff1b\u8fdb\u4e00\u6b65\u6269\u5c55\u6a21\u578b\u89c4\u6a21\uff0c\u51c6\u786e\u7387\u8fbe\u523091.4%\u548c89.61%\uff0c\u5927\u5e45\u8d85\u8d8a\u73b0\u6709\u8bb0\u5fc6\u67b6\u6784\u3002", "conclusion": "Hindsight\u901a\u8fc7\u7ed3\u6784\u5316\u8bb0\u5fc6\u548c\u63a8\u7406\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7406\u5728\u591a\u4f1a\u8bdd\u3001\u5f00\u653e\u9886\u57df\u95ee\u9898\u4e0a\u7684\u957f\u65f6\u8bb0\u5fc6\u8868\u73b0\uff0c\u4e3a\u5b9e\u73b0\u66f4\u6709\u6548\u7684LLM\u4ee3\u7406\u8bb0\u5fc6\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.12839", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12839", "abs": "https://arxiv.org/abs/2512.12839", "authors": ["Dingyi Yang", "Qin Jin"], "title": "What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation", "comment": "24 pages, 7 figures, Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics", "summary": "In this work, we conduct systematic research in a challenging area: the automatic evaluation of book-length stories (>100K tokens). Our study focuses on two key questions: (1) understanding which evaluation aspects matter most to readers, and (2) exploring effective methods for evaluating lengthy stories. We introduce the first large-scale benchmark, LongStoryEval, comprising 600 newly published books with an average length of 121K tokens (maximum 397K). Each book includes its average rating and multiple reader reviews, presented as critiques organized by evaluation aspects. By analyzing all user-mentioned aspects, we propose an evaluation criteria structure and conduct experiments to identify the most significant aspects among the 8 top-level criteria. For evaluation methods, we compare the effectiveness of three types: aggregation-based, incremental-updated, and summary-based evaluations. Our findings reveal that aggregation- and summary-based evaluations perform better, with the former excelling in detail assessment and the latter offering greater efficiency. Building on these insights, we further propose NovelCritique, an 8B model that leverages the efficient summary-based framework to review and score stories across specified aspects. NovelCritique outperforms commercial models like GPT-4o in aligning with human evaluations. Our datasets and codes are available at https://github.com/DingyiYang/LongStoryEval.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u81ea\u52a8\u8bc4\u4f30\u8d85\u957f\u6545\u4e8b\uff08>100K\u8bcd\uff09\u8fdb\u884c\u4e86\u7cfb\u7edf\u7814\u7a76\uff0c\u63d0\u51fa\u4e86\u5927\u578b\u57fa\u51c6\u6570\u636e\u96c6LongStoryEval\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u4e86\u9ad8\u6548\u7684\u8bc4\u4ef7\u6a21\u578bNovelCritique\uff0c\u8868\u73b0\u4f18\u4e8e\u5546\u4e1a\u6a21\u578b\u3002", "motivation": "\u7531\u4e8e\u73b0\u6709\u8bc4\u4ef7\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u8d85\u957f\u6587\u672c\u6545\u4e8b\uff0c\u672c\u7814\u7a76\u65e8\u5728\u7406\u89e3\u8bfb\u8005\u6700\u5173\u5fc3\u7684\u8bc4\u4ef7\u7ef4\u5ea6\u53ca\u63a2\u7d22\u9002\u7528\u4e8e\u957f\u7bc7\u6545\u4e8b\u7684\u6709\u6548\u8bc4\u4ef7\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u5305\u542b600\u672c\u79d1\u957f\u6545\u4e8b\u7684LongStoryEval\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u8bc4\u4ef7\u6307\u6807\u4f53\u7cfb\uff0c\u6bd4\u8f83\u805a\u5408\u5f0f\u3001\u589e\u91cf\u66f4\u65b0\u5f0f\u548c\u6458\u8981\u5f0f\u4e09\u79cd\u8bc4\u4ef7\u65b9\u6cd5\uff0c\u63d0\u51fa\u57fa\u4e8e\u6458\u8981\u7684NovelCritique\u6a21\u578b\u8fdb\u884c\u6545\u4e8b\u591a\u7ef4\u5ea6\u81ea\u52a8\u8bc4\u4ef7\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u805a\u5408\u5f0f\u548c\u6458\u8981\u5f0f\u8bc4\u4ef7\u65b9\u6cd5\u8868\u73b0\u6700\u4f73\uff0c\u805a\u5408\u5f0f\u5728\u7ec6\u8282\u8bc4\u4f30\u4e0a\u4f18\u5f02\uff0c\u6458\u8981\u5f0f\u6548\u7387\u66f4\u9ad8\u3002NovelCritique\u5728\u591a\u8bc4\u4ef7\u7ef4\u5ea6\u4e0a\u4f18\u4e8eGPT-4o\uff0c\u4e0e\u4eba\u7c7b\u8bc4\u4ef7\u9ad8\u5ea6\u4e00\u81f4\u3002", "conclusion": "LongStoryEval\u53caNovelCritique\u4e3a\u8d85\u957f\u6545\u4e8b\u7684\u81ea\u52a8\u5316\u591a\u7ef4\u8bc4\u4ef7\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u548c\u57fa\u51c6\uff0c\u63a8\u52a8\u8be5\u9886\u57df\u7814\u7a76\u4e0e\u5e94\u7528\u53d1\u5c55\u3002"}}
{"id": "2512.12868", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.12868", "abs": "https://arxiv.org/abs/2512.12868", "authors": ["Furong Jia", "Yuan Pu", "Finn Guo", "Monica Agrawal"], "title": "Counting Clues: A Lightweight Probabilistic Baseline Can Match an LLM", "comment": null, "summary": "Large language models (LLMs) excel on multiple-choice clinical diagnosis benchmarks, yet it is unclear how much of this performance reflects underlying probabilistic reasoning. We study this through questions from MedQA, where the task is to select the most likely diagnosis. We introduce the Frequency-Based Probabilistic Ranker (FBPR), a lightweight method that scores options with a smoothed Naive Bayes over concept-diagnosis co-occurrence statistics from a large corpus. When co-occurrence statistics were sourced from the pretraining corpora for OLMo and Llama, FBPR achieves comparable performance to the corresponding LLMs pretrained on that same corpus. Direct LLM inference and FBPR largely get different questions correct, with an overlap only slightly above random chance, indicating complementary strengths of each method. These findings highlight the continued value of explicit probabilistic baselines: they provide a meaningful performance reference point and a complementary signal for potential hybridization. While the performance of LLMs seems to be driven by a mechanism other than simple frequency aggregation, we show that an approach similar to the historically grounded, low-complexity expert systems still accounts for a substantial portion of benchmark performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e34\u5e8a\u8bca\u65ad\u591a\u9879\u9009\u62e9\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u9891\u7387\u7684\u6982\u7387\u6392\u5e8f\u5668\uff08FBPR\uff09\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u8bed\u6599\u4e2d\u7684\u6982\u5ff5-\u8bca\u65ad\u5171\u73b0\u6570\u636e\u5b9e\u73b0\u6027\u80fd\u4e0eLLMs\u53ef\u6bd4\uff0c\u4e14\u4e24\u8005\u8868\u73b0\u4e92\u8865\uff0c\u8868\u660e\u663e\u5f0f\u6982\u7387\u57fa\u7ebf\u4ecd\u6709\u4ef7\u503c\u3002", "motivation": "\u63a2\u7a76LLMs\u5728\u4e34\u5e8a\u8bca\u65ad\u4efb\u52a1\u4e2d\u7684\u591a\u9879\u9009\u62e9\u8868\u73b0\u4e2d\uff0c\u6709\u591a\u5c11\u662f\u57fa\u4e8e\u6f5c\u5728\u7684\u6982\u7387\u63a8\u7406\uff0c\u800c\u975e\u5176\u4ed6\u673a\u5236\u3002", "method": "\u63d0\u51faFBPR\u65b9\u6cd5\uff0c\u4f7f\u7528\u5e73\u6ed1\u6734\u7d20\u8d1d\u53f6\u65af\u6a21\u578b\u57fa\u4e8e\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e2d\u6982\u5ff5\u4e0e\u8bca\u65ad\u7684\u5171\u73b0\u7edf\u8ba1\u6570\u636e\u8fdb\u884c\u9009\u9879\u8bc4\u5206\uff0c\u5e76\u4e0e\u5bf9\u5e94\u9884\u8bad\u7ec3\u8bed\u6599\u7684LLMs\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "FBPR\u5728\u4f7f\u7528\u4e0eOLMo\u3001Llama\u9884\u8bad\u7ec3\u8bed\u6599\u76f8\u540c\u5171\u73b0\u6570\u636e\u65f6\uff0c\u6027\u80fd\u4e0e\u5bf9\u5e94LLMs\u76f8\u5f53\uff0c\u4f46\u4e24\u79cd\u65b9\u6cd5\u6b63\u786e\u56de\u7b54\u7684\u95ee\u9898\u5dee\u5f02\u8f83\u5927\uff0c\u8868\u73b0\u51fa\u4f18\u52bf\u4e92\u8865\u3002", "conclusion": "\u663e\u5f0f\u6982\u7387\u6a21\u578b\u4f5c\u4e3a\u57fa\u7ebf\u4ecd\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u80fd\u591f\u4e3aLLMs\u8868\u73b0\u63d0\u4f9b\u53c2\u8003\u5e76\u4f5c\u4e3a\u6f5c\u5728\u6df7\u5408\u65b9\u6cd5\u7684\u8865\u5145\uff0c\u8868\u660e\u57fa\u4e8e\u9891\u7387\u7edf\u8ba1\u7684\u4f20\u7edf\u4e13\u5bb6\u7cfb\u7edf\u601d\u60f3\u5728\u590d\u6742\u6a21\u578b\u4e2d\u4f9d\u7136\u5360\u6709\u4e00\u5e2d\u4e4b\u5730\u3002"}}
{"id": "2512.12950", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.12950", "abs": "https://arxiv.org/abs/2512.12950", "authors": ["Lingyi Meng", "Maolin Liu", "Hao Wang", "Yilan Cheng", "Qi Yang", "Idlkaid Mohanmmed"], "title": "Building from Scratch: A Multi-Agent Framework with Human-in-the-Loop for Multilingual Legal Terminology Mapping", "comment": "43 pages, 6 fingures, accepted in Artificial Intelligence and Law (2025)", "summary": "Accurately mapping legal terminology across languages remains a significant challenge, especially for language pairs like Chinese and Japanese, which share a large number of homographs with different meanings. Existing resources and standardized tools for these languages are limited. To address this, we propose a human-AI collaborative approach for building a multilingual legal terminology database, based on a multi-agent framework. This approach integrates advanced large language models and legal domain experts throughout the entire process-from raw document preprocessing, article-level alignment, to terminology extraction, mapping, and quality assurance. Unlike a single automated pipeline, our approach places greater emphasis on how human experts participate in this multi-agent system. Humans and AI agents take on different roles: AI agents handle specific, repetitive tasks, such as OCR, text segmentation, semantic alignment, and initial terminology extraction, while human experts provide crucial oversight, review, and supervise the outputs with contextual knowledge and legal judgment. We tested the effectiveness of this framework using a trilingual parallel corpus comprising 35 key Chinese statutes, along with their English and Japanese translations. The experimental results show that this human-in-the-loop, multi-agent workflow not only improves the precision and consistency of multilingual legal terminology mapping but also offers greater scalability compared to traditional manual methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4eba\u673a\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u6784\u5efa\u4e2d\u82f1\u65e5\u4e09\u8bed\u7684\u6cd5\u5f8b\u672f\u8bed\u6570\u636e\u5e93\uff0c\u63d0\u9ad8\u4e86\u672f\u8bed\u6620\u5c04\u7684\u7cbe\u786e\u6027\u4e0e\u4e00\u81f4\u6027\u3002", "motivation": "\u7531\u4e8e\u4e2d\u65e5\u4e24\u79cd\u8bed\u8a00\u5b58\u5728\u5927\u91cf\u540c\u5f62\u5f02\u4e49\u8bcd\uff0c\u4e14\u7f3a\u4e4f\u6807\u51c6\u5316\u8d44\u6e90\uff0c\u5bfc\u81f4\u6cd5\u5f8b\u672f\u8bed\u8de8\u8bed\u8a00\u6620\u5c04\u975e\u5e38\u56f0\u96be\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u878d\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u6cd5\u5f8b\u4e13\u5bb6\uff0c\u5206\u522b\u8d1f\u8d23OCR\u3001\u6587\u672c\u5206\u5272\u3001\u8bed\u4e49\u5bf9\u9f50\u3001\u672f\u8bed\u63d0\u53d6\u4e0e\u8d28\u91cf\u76d1\u7763\uff0c\u5b9e\u73b0\u4eba\u673a\u534f\u540c\u5de5\u4f5c\u6d41\u3002", "result": "\u57fa\u4e8e\u5305\u542b35\u4e2a\u4e2d\u6587\u91cd\u8981\u6cd5\u89c4\u53ca\u5176\u82f1\u65e5\u8bd1\u6587\u7684\u4e09\u8bed\u5e73\u884c\u8bed\u6599\u6d4b\u8bd5\uff0c\u8be5\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6cd5\u5f8b\u672f\u8bed\u6620\u5c04\u7684\u51c6\u786e\u7387\u3001\u4e00\u81f4\u6027\u53ca\u5de5\u4f5c\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u4eba\u673a\u534f\u4f5c\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4f18\u4e8e\u4f20\u7edf\u4eba\u5de5\u65b9\u6cd5\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u591a\u8bed\u79cd\u6cd5\u5f8b\u672f\u8bed\u6570\u636e\u5e93\u6784\u5efa\uff0c\u5b9e\u73b0\u9ad8\u6548\u4e14\u53ef\u9760\u7684\u8de8\u8bed\u8a00\u672f\u8bed\u6620\u5c04\u3002"}}
{"id": "2512.12967", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12967", "abs": "https://arxiv.org/abs/2512.12967", "authors": ["Weizhou Shen", "Ziyi Yang", "Chenliang Li", "Zhiyuan Lu", "Miao Peng", "Huashan Sun", "Yingcheng Shi", "Shengyi Liao", "Shaopeng Lai", "Bo Zhang", "Dayiheng Liu", "Fei Huang", "Jingren Zhou", "Ming Yan"], "title": "QwenLong-L1.5: Post-Training Recipe for Long-Context Reasoning and Memory Management", "comment": null, "summary": "We introduce QwenLong-L1.5, a model that achieves superior long-context reasoning capabilities through systematic post-training innovations. The key technical breakthroughs of QwenLong-L1.5 are as follows: (1) Long-Context Data Synthesis Pipeline: We develop a systematic synthesis framework that generates challenging reasoning tasks requiring multi-hop grounding over globally distributed evidence. By deconstructing documents into atomic facts and their underlying relationships, and then programmatically composing verifiable reasoning questions, our approach creates high-quality training data at scale, moving substantially beyond simple retrieval tasks to enable genuine long-range reasoning capabilities. (2) Stabilized Reinforcement Learning for Long-Context Training: To overcome the critical instability in long-context RL, we introduce task-balanced sampling with task-specific advantage estimation to mitigate reward bias, and propose Adaptive Entropy-Controlled Policy Optimization (AEPO) that dynamically regulates exploration-exploitation trade-offs. (3) Memory-Augmented Architecture for Ultra-Long Contexts: Recognizing that even extended context windows cannot accommodate arbitrarily long sequences, we develop a memory management framework with multi-stage fusion RL training that seamlessly integrates single-pass reasoning with iterative memory-based processing for tasks exceeding 4M tokens. Based on Qwen3-30B-A3B-Thinking, QwenLong-L1.5 achieves performance comparable to GPT-5 and Gemini-2.5-Pro on long-context reasoning benchmarks, surpassing its baseline by 9.90 points on average. On ultra-long tasks (1M~4M tokens), QwenLong-L1.5's memory-agent framework yields a 9.48-point gain over the agent baseline. Additionally, the acquired long-context reasoning ability translates to enhanced performance in general domains like scientific reasoning, memory tool using, and extended dialogue.", "AI": {"tldr": "QwenLong-L1.5\u901a\u8fc7\u521b\u65b0\u7684\u8bad\u7ec3\u65b9\u6cd5\u548c\u5185\u5b58\u589e\u5f3a\u67b6\u6784\uff0c\u5b9e\u73b0\u4e86\u5353\u8d8a\u7684\u8d85\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u6027\u80fd\u8d85\u8d8aGPT-5\u548cGemini-2.5-Pro\u3002", "motivation": "\u5f53\u524d\u6a21\u578b\u5728\u5904\u7406\u8d85\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u4efb\u52a1\u65f6\u5b58\u5728\u80fd\u529b\u548c\u7a33\u5b9a\u6027\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u9700\u7cfb\u7edf\u6027\u63d0\u5347\u957f\u4e0a\u4e0b\u6587\u7406\u89e3\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "method": "\u91c7\u7528\u957f\u4e0a\u4e0b\u6587\u6570\u636e\u5408\u6210\u6846\u67b6\u751f\u6210\u590d\u6742\u63a8\u7406\u4efb\u52a1\uff1b\u63d0\u51fa\u7a33\u5b9a\u7684\u957f\u4e0a\u4e0b\u6587\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff08\u4efb\u52a1\u5e73\u8861\u91c7\u6837\u548c\u81ea\u9002\u5e94\u71b5\u63a7\u7b56\u7565\u4f18\u5316\uff09\uff1b\u8bbe\u8ba1\u5185\u5b58\u589e\u5f3a\u67b6\u6784\u652f\u6301\u8d854\u767e\u4e07token\u7684\u63a8\u7406\u4efb\u52a1\u3002", "result": "QwenLong-L1.5\u5728\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5e73\u5747\u9886\u5148\u57fa\u7ebf9.90\u5206\uff0c\u8d85\u957f\u4efb\u52a1\u4e2d\u63d0\u53479.48\u5206\uff0c\u6027\u80fd\u5ab2\u7f8e\u751a\u81f3\u8d85\u8fc7GPT-5\u548cGemini-2.5-Pro\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u7684\u8bad\u7ec3\u521b\u65b0\u548c\u5185\u5b58\u7ba1\u7406\u673a\u5236\uff0cQwenLong-L1.5\u663e\u8457\u63d0\u5347\u4e86\u8d85\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5e26\u52a8\u79d1\u5b66\u63a8\u7406\u3001\u8bb0\u5fc6\u5de5\u5177\u4f7f\u7528\u53ca\u957f\u5bf9\u8bdd\u7b49\u9886\u57df\u8868\u73b0\u63d0\u5347\u3002"}}
{"id": "2512.12976", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.12976", "abs": "https://arxiv.org/abs/2512.12976", "authors": ["Marcus Ma", "Cole Johnson", "Nolan Bridges", "Jackson Trager", "Georgios Chochlakis", "Shrikanth Narayanan"], "title": "Authors Should Annotate", "comment": null, "summary": "The status quo for labeling text is third-party annotation, but there are many cases where information directly from the document's source would be preferable over a third-person proxy, especially for egocentric features like sentiment and belief. We introduce author labeling, an annotation technique where the writer of the document itself annotates the data at the moment of creation. We collaborate with a commercial chatbot with over 10,000 users to deploy an author labeling annotation system for subjective features related to product recommendation. This system identifies task-relevant queries, generates on-the-fly labeling questions, and records authors' answers in real time. We train and deploy an online-learning model architecture for product recommendation that continuously improves from author labeling and find it achieved a 534% increase in click-through rate compared to an industry advertising baseline running concurrently. We then compare the quality and practicality of author labeling to three traditional annotation approaches for sentiment analysis and find author labeling to be higher quality, faster to acquire, and cheaper. These findings reinforce existing literature that annotations, especially for egocentric and subjective beliefs, are significantly higher quality when labeled by the author rather than a third party. To facilitate broader scientific adoption, we release an author labeling service for the research community at academic.echollm.io.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f5c\u8005\u6807\u6ce8\u65b9\u6cd5\uff0c\u8ba9\u6587\u672c\u4f5c\u8005\u5728\u521b\u4f5c\u65f6\u76f4\u63a5\u5bf9\u6570\u636e\u8fdb\u884c\u6807\u6ce8\uff0c\u7528\u4e8e\u4e3b\u89c2\u7279\u5f81\u5982\u60c5\u611f\u548c\u4fe1\u5ff5\u7684\u8bc6\u522b\u3002", "motivation": "\u4f20\u7edf\u6587\u672c\u6807\u6ce8\u591a\u4f9d\u8d56\u7b2c\u4e09\u65b9\uff0c\u4f46\u5bf9\u4e8e\u4f5c\u8005\u81ea\u8eab\u89c6\u89d2\u7684\u4e3b\u89c2\u4fe1\u606f\uff08\u5982\u60c5\u611f\u3001\u4fe1\u5ff5\uff09\u91c7\u7528\u7b2c\u4e09\u65b9\u6807\u6ce8\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u51c6\u786e\u9ad8\u6548\u7684\u6807\u6ce8\u65b9\u6cd5\u3002", "method": "\u4e0e\u5546\u4e1a\u804a\u5929\u673a\u5668\u4eba\u5408\u4f5c\uff0c\u90e8\u7f72\u5b9e\u65f6\u4f5c\u8005\u6807\u6ce8\u7cfb\u7edf\uff0c\u81ea\u52a8\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u67e5\u8be2\uff0c\u52a8\u6001\u751f\u6210\u6807\u6ce8\u95ee\u9898\u5e76\u8bb0\u5f55\u4f5c\u8005\u56de\u7b54\uff0c\u540c\u65f6\u8bad\u7ec3\u57fa\u4e8e\u5728\u7ebf\u5b66\u4e60\u7684\u4ea7\u54c1\u63a8\u8350\u6a21\u578b\u6301\u7eed\u6539\u8fdb\u3002", "result": "\u901a\u8fc7\u4f5c\u8005\u6807\u6ce8\u8bad\u7ec3\u7684\u6a21\u578b\u70b9\u51fb\u7387\u63d0\u9ad8\u4e86534%\uff0c\u76f8\u8f83\u4e09\u79cd\u4f20\u7edf\u60c5\u611f\u6807\u6ce8\u65b9\u6cd5\uff0c\u4f5c\u8005\u6807\u6ce8\u5728\u8d28\u91cf\u3001\u6548\u7387\u548c\u6210\u672c\u4e0a\u90fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u4f5c\u8005\u6807\u6ce8\u5728\u4e3b\u89c2\u548c\u81ea\u6211\u4e2d\u5fc3\u4fe1\u606f\u6807\u6ce8\u4e0a\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u5efa\u8bae\u79d1\u7814\u793e\u533a\u63a8\u5e7f\u4f7f\u7528\uff0c\u4f5c\u8005\u4e5f\u53d1\u5e03\u4e86\u76f8\u5e94\u7684\u670d\u52a1\u5e73\u53f0\u3002"}}
{"id": "2512.13059", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13059", "abs": "https://arxiv.org/abs/2512.13059", "authors": ["Ikuya Yamada", "Wataru Ikeda", "Ko Yoshida", "Mengyu Ye", "Hinata Sugimoto", "Masatoshi Suzuki", "Hisanori Ozaki", "Jun Suzuki"], "title": "An Open and Reproducible Deep Research Agent for Long-Form Question Answering", "comment": "Technical report of a winning system in the NeurIPS MMU-RAG competition", "summary": "We present an open deep research system for long-form question answering, selected as a winning system in the text-to-text track of the MMU-RAG competition at NeurIPS 2025. The system combines an open-source large language model (LLM) with an open web search API to perform iterative retrieval, reasoning, and synthesis in real-world open-domain settings. To enhance reasoning quality, we apply preference tuning based on LLM-as-a-judge feedback that evaluates multiple aspects, including clarity, insightfulness, and factuality. Our experimental results show that the proposed method consistently improves answer quality across all three aspects. Our source code is publicly available at https://github.com/efficient-deep-research/efficient-deep-research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u548c\u5f00\u653e\u7f51\u9875\u641c\u7d22\u7684\u957f\u6587\u672c\u95ee\u7b54\u7cfb\u7edf\uff0c\u5728\u591a\u65b9\u9762\u4f18\u5316\u56de\u7b54\u8d28\u91cf\uff0c\u83b7\u5f97\u6bd4\u8d5b\u51a0\u519b\u5e76\u5f00\u6e90\u4ee3\u7801\u3002", "motivation": "\u5f53\u524d\u957f\u6587\u672c\u95ee\u7b54\u7cfb\u7edf\u5728\u63a8\u7406\u8d28\u91cf\u548c\u591a\u65b9\u9762\u8868\u73b0\u4e0a\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u5c24\u5176\u662f\u771f\u5b9e\u5f00\u653e\u57df\u7684\u5e94\u7528\u573a\u666f\u4e2d\u3002", "method": "\u7cfb\u7edf\u5c06\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u7f51\u9875\u641c\u7d22API\u7ed3\u5408\uff0c\u91c7\u7528\u8fed\u4ee3\u68c0\u7d22\u3001\u63a8\u7406\u548c\u7efc\u5408\u7b56\u7565\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u6a21\u578b\u8bc4\u5224\u5458\u53cd\u9988\u7684\u504f\u597d\u8c03\u4f18\uff0c\u8bc4\u4f30\u6e05\u6670\u6027\u3001\u6d1e\u89c1\u6027\u548c\u771f\u5b9e\u6027\u7b49\u65b9\u9762\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u56de\u7b54\u7684\u6e05\u6670\u6027\u3001\u6d1e\u89c1\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u5747\u6709\u7a33\u5b9a\u6548\u679c\uff0c\u7cfb\u7edf\u5728MMU-RAG\u7ade\u8d5b\u4e2d\u83b7\u80dc\u3002", "conclusion": "\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5f00\u653e\u641c\u7d22\uff0c\u5e76\u5229\u7528\u504f\u597d\u8c03\u4f18\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u662f\u63d0\u5347\u957f\u6587\u672c\u95ee\u7b54\u6027\u80fd\u7684\u6709\u6548\u9014\u5f84\uff0c\u7cfb\u7edf\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u4e14\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.13063", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13063", "abs": "https://arxiv.org/abs/2512.13063", "authors": ["Cheril Shah", "Akshit Agarwal", "Kanak Garg", "Mourad Heddaya"], "title": "LLM Rationalis? Measuring Bargaining Capabilities of AI Negotiators", "comment": "Published in the First Workshop on Multi-Turn Interactions in Large Language Models at Neurips 2025", "summary": "Bilateral negotiation is a complex, context-sensitive task in which human negotiators dynamically adjust anchors, pacing, and flexibility to exploit power asymmetries and informal cues. We introduce a unified mathematical framework for modeling concession dynamics based on a hyperbolic tangent curve, and propose two metrics burstiness tau and the Concession-Rigidity Index (CRI) to quantify the timing and rigidity of offer trajectories. We conduct a large-scale empirical comparison between human negotiators and four state-of-the-art large language models (LLMs) across natural-language and numeric-offers settings, with and without rich market context, as well as six controlled power-asymmetry scenarios. Our results reveal that, unlike humans who smoothly adapt to situations and infer the opponents position and strategies, LLMs systematically anchor at extremes of the possible agreement zone for negotiations and optimize for fixed points irrespective of leverage or context. Qualitative analysis further shows limited strategy diversity and occasional deceptive tactics used by LLMs. Moreover the ability of LLMs to negotiate does not improve with better models. These findings highlight fundamental limitations in current LLM negotiation capabilities and point to the need for models that better internalize opponent reasoning and context-dependent strategy.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf\u7684\u9000\u8ba9\u52a8\u6001\u6570\u5b66\u6846\u67b6\u548c\u4e24\u4e2a\u8861\u91cf\u6307\u6807\uff0c\u6bd4\u8f83\u4e86\u4eba\u7c7b\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u79cd\u8c08\u5224\u573a\u666f\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0LLMs\u7f3a\u4e4f\u7075\u6d3b\u9002\u5e94\u80fd\u529b\u4e14\u7b56\u7565\u5355\u4e00\u3002", "motivation": "\u53cc\u8fb9\u8c08\u5224\u590d\u6742\u4e14\u4f9d\u8d56\u60c5\u5883\u548c\u7b56\u7565\u8c03\u6574\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c08\u5224\u4e2d\u8868\u73b0\u6709\u9650\uff0c\u9700\u63a2\u8ba8\u5176\u5c40\u9650\u6027\u548c\u6539\u8fdb\u65b9\u5411\u3002", "method": "\u6784\u5efa\u57fa\u4e8e\u53cc\u66f2\u6b63\u5207\u66f2\u7ebf\u7684\u7edf\u4e00\u6570\u5b66\u6a21\u578b\uff0c\u63d0\u51faburstiness tau\u548c\u9000\u8ba9\u521a\u6027\u6307\u6570\uff08CRI\uff09\u6307\u6807\uff0c\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u5206\u6790\u4eba\u7c7b\u4e0e\u56db\u79cd\u5148\u8fdbLLMs\u5728\u4e0d\u540c\u8c08\u5224\u60c5\u5883\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0\u4eba\u7c7b\u8c08\u5224\u8005\u80fd\u5e73\u6ed1\u9002\u5e94\u548c\u63a8\u7406\u5bf9\u624b\u7b56\u7565\uff0cLLMs\u5219\u503e\u5411\u4e8e\u951a\u5b9a\u6781\u7aef\u7acb\u573a\uff0c\u56fa\u5b9a\u4f18\u5316\u7b56\u7565\uff0c\u7b56\u7565\u591a\u6837\u6027\u4f4e\u4e14\u6709\u65f6\u5e26\u6709\u6b3a\u9a97\u6027\uff0c\u4e14\u6a21\u578b\u5347\u7ea7\u672a\u663e\u8457\u63d0\u5347\u8c08\u5224\u80fd\u529b\u3002", "conclusion": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8c08\u5224\u4e2d\u7684\u80fd\u529b\u5b58\u5728\u6839\u672c\u6027\u9650\u5236\uff0c\u4e9f\u9700\u8bbe\u8ba1\u80fd\u591f\u66f4\u597d\u5185\u5316\u5bf9\u624b\u63a8\u7406\u53ca\u60c5\u5883\u7b56\u7565\u7684\u6a21\u578b\u3002"}}
{"id": "2512.13109", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13109", "abs": "https://arxiv.org/abs/2512.13109", "authors": ["Zewen Qiang", "Sendong Zhao", "Haochun Wang", "Bing Qin", "Ting Liu"], "title": "Uncovering the Role of Initial Saliency in U-Shaped Attention Bias: Scaling Initial Token Weight for Enhanced Long-Text Processing", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong performance on a variety of natural language processing (NLP) tasks. However, they often struggle with long-text sequences due to the ``lost in the middle'' phenomenon. This issue has been shown to arise from a U-shaped attention bias, where attention is disproportionately focused on the beginning and end of a text, leaving the middle section underrepresented. While previous studies have attributed this bias to position encoding, our research first identifies an additional factor: initial saliency. It means that in the attention computation for each token, tokens with higher attention weights relative to the initial token tend to receive more attention in the prediction of the next token. We further find that utilizing this property by scaling attention weight between the initial token and others improves the model's ability to process long contexts, achieving a maximum improvement of 3.6\\% in MDQA dataset. Moreover, combining this approach with existing methods to reduce position encoding bias further enhances performance, achieving a maximum improvement of 3.4\\% in KV-Retrieval tasks.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u4e2d\u95f4\u90e8\u5206\u5173\u6ce8\u5ea6\u4e0d\u8db3\uff0c\u539f\u56e0\u5305\u62ec\u4f4d\u7f6e\u7f16\u7801\u548c\u521d\u59cb\u663e\u8457\u6027\uff0c\u5e76\u63d0\u51fa\u901a\u8fc7\u8c03\u6574\u521d\u59cbtoken\u7684\u6ce8\u610f\u529b\u6743\u91cd\u63d0\u5347\u6a21\u578b\u5904\u7406\u957f\u6587\u672c\u80fd\u529b\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6587\u672c\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a\u6ce8\u610f\u529b\u673a\u5236\u504f\u5411\u6587\u672c\u5f00\u5934\u548c\u7ed3\u5c3e\uff0c\u5bfc\u81f4\u4e2d\u95f4\u90e8\u5206\u4fe1\u606f\u4e22\u5931\uff0c\u8fd9\u9650\u5236\u4e86\u6a21\u578b\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u8bc6\u522b\u51fa\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u201c\u521d\u59cb\u663e\u8457\u6027\u201d\u56e0\u7d20\uff0c\u5373\u521d\u59cbtoken\u7684\u6ce8\u610f\u529b\u6743\u91cd\u5f71\u54cd\u540e\u7eedtoken\u7684\u5173\u6ce8\u5ea6\u3002\u901a\u8fc7\u8c03\u8282\u521d\u59cbtoken\u4e0e\u5176\u4ed6token\u4e4b\u95f4\u7684\u6ce8\u610f\u529b\u6743\u91cd\uff0c\u6539\u5584\u6a21\u578b\u5bf9\u957f\u6587\u672c\u7684\u5173\u6ce8\u80fd\u529b\uff0c\u540c\u65f6\u7ed3\u5408\u5df2\u6709\u51cf\u5c11\u4f4d\u7f6e\u7f16\u7801\u504f\u5dee\u7684\u65b9\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "result": "\u5728MDQA\u6570\u636e\u96c6\u4e0a\uff0c\u8be5\u65b9\u6cd5\u4f7f\u6a21\u578b\u8868\u73b0\u63d0\u5347\u6700\u591a3.6%\uff0c\u7ed3\u5408\u51cf\u5c11\u4f4d\u7f6e\u504f\u5dee\u7684\u65b9\u6cd5\u5728KV-Retrieval\u4efb\u52a1\u4e2d\u8fdb\u4e00\u6b65\u63d0\u9ad83.4%\u6027\u80fd\u3002", "conclusion": "\u8c03\u6574\u521d\u59cbtoken\u7684\u6ce8\u610f\u529b\u6743\u91cd\u662f\u7f13\u89e3\u5927\u8bed\u8a00\u6a21\u578b \"\u8ff7\u5931\u4e2d\u95f4\" \u73b0\u8c61\u7684\u6709\u6548\u624b\u6bb5\uff0c\u4e14\u4e0e\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u4f18\u5316\u65b9\u6cd5\u7ed3\u5408\u53ef\u8fdb\u4e00\u6b65\u63d0\u5347\u957f\u6587\u672c\u5904\u7406\u80fd\u529b\u3002"}}
{"id": "2512.13194", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13194", "abs": "https://arxiv.org/abs/2512.13194", "authors": ["Chendong Sun"], "title": "Efficient Adaptive Rejection Sampling for Accelerating Speculative Decoding in Large Language Models", "comment": null, "summary": "Speculative Decoding is a prominent technique for accelerating the autoregressive inference of large language models (LLMs) by employing a fast draft model to propose candidate token sequences and a large target model to verify them in parallel. However, its core component -- the rejection sampling mechanism -- relies on a fixed, context-independent random threshold. This leads to a significant \"random rejection\" problem in high-uncertainty generation scenarios, where plausible candidate tokens are frequently rejected due to random chance, undermining inference efficiency. This paper introduces Efficient Adaptive Rejection Sampling (EARS), a novel method that dynamically adjusts the acceptance threshold by incorporating the target model's own predictive uncertainty, measured as \\(1 - \\max(P_{\\mathrm{target}})\\). By introducing a tolerance term proportional to this uncertainty, EARS intelligently relaxes the acceptance criterion when the model is uncertain, effectively reducing random rejections while maintaining strict standards when the model is confident. Experiments on creative writing and open-domain QA tasks demonstrate that EARS significantly enhances the efficiency of speculative decoding, achieving up to an 18.12% increase in throughput with a negligible 0.84% accuracy drop on the GSM8K benchmark. The method requires no modifications to model architectures and can be seamlessly integrated into existing speculative decoding frameworks.", "AI": {"tldr": "EARS\u65b9\u6cd5\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u63a5\u53d7\u9608\u503c\uff0c\u89e3\u51b3\u4e86\u63a8\u6d4b\u89e3\u7801\u4e2d\u968f\u673a\u62d2\u7edd\u7684\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u63a8\u6d4b\u89e3\u7801\u7684\u62d2\u7edd\u91c7\u6837\u673a\u5236\u4f7f\u7528\u56fa\u5b9a\u9608\u503c\uff0c\u5bfc\u81f4\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u751f\u6210\u573a\u666f\u4e0b\uff0c\u5408\u7406\u5019\u9009\u8bcd\u88ab\u968f\u673a\u62d2\u7edd\uff0c\u5f71\u54cd\u63a8\u7406\u6548\u7387\u3002", "method": "\u63d0\u51faEARS\u65b9\u6cd5\uff0c\u6839\u636e\u76ee\u6807\u6a21\u578b\u7684\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u52a8\u6001\u8c03\u6574\u63a5\u53d7\u9608\u503c\uff0c\u5f15\u5165\u5bb9\u5fcd\u9879\uff0c\u964d\u4f4e\u968f\u673a\u62d2\u7edd\u6982\u7387\u3002", "result": "EARS\u5728\u521b\u610f\u5199\u4f5c\u548c\u5f00\u653e\u9886\u57df\u95ee\u7b54\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe18.12%\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6781\u4f4e\u7684\u51c6\u786e\u7387\u4e0b\u964d\uff080.84%\uff09\u3002", "conclusion": "EARS\u65e0\u9700\u4fee\u6539\u6a21\u578b\u7ed3\u6784\uff0c\u53ef\u65e0\u7f1d\u96c6\u6210\u5230\u73b0\u6709\u63a8\u6d4b\u89e3\u7801\u6846\u67b6\u4e2d\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u6548\u7387\uff0c\u7279\u522b\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2512.13278", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13278", "abs": "https://arxiv.org/abs/2512.13278", "authors": ["Jiaru Zou", "Ling Yang", "Yunzhe Qi", "Sirui Chen", "Mengting Ai", "Ke Shen", "Jingrui He", "Mengdi Wang"], "title": "AutoTool: Dynamic Tool Selection and Integration for Agentic Reasoning", "comment": "Best Paper Award at ICCV 2025 Workshop on Multi-Modal Reasoning for Agentic Intelligence", "summary": "Agentic reinforcement learning has advanced large language models (LLMs) to reason through long chain-of-thought trajectories while interleaving external tool use. Existing approaches assume a fixed inventory of tools, limiting LLM agents' adaptability to new or evolving toolsets. We present AutoTool, a framework that equips LLM agents with dynamic tool-selection capabilities throughout their reasoning trajectories. We first construct a 200k dataset with explicit tool-selection rationales across 1,000+ tools and 100+ tasks spanning mathematics, science, code generation, and multimodal reasoning. Building on this data foundation, AutoTool employs a dual-phase optimization pipeline: (i) supervised and RL-based trajectory stabilization for coherent reasoning, and (ii) KL-regularized Plackett-Luce ranking to refine consistent multi-step tool selection. Across ten diverse benchmarks, we train two base models, Qwen3-8B and Qwen2.5-VL-7B, with AutoTool. With fewer parameters, AutoTool consistently outperforms advanced LLM agents and tool-integration methods, yielding average gains of 6.4% in math & science reasoning, 4.5% in search-based QA, 7.7% in code generation, and 6.9% in multimodal understanding. In addition, AutoTool exhibits stronger generalization by dynamically leveraging unseen tools from evolving toolsets during inference.", "AI": {"tldr": "AutoTool\u901a\u8fc7\u52a8\u6001\u9009\u62e9\u5de5\u5177\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u4efb\u52a1\u4e2d\u7684\u63a8\u7406\u548c\u5de5\u5177\u4f7f\u7528\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u5de5\u5177\u96c6\u56fa\u5b9a\uff0c\u9650\u5236\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u9002\u5e94\u65b0\u5de5\u5177\u6216\u4e0d\u65ad\u53d8\u5316\u5de5\u5177\u96c6\u7684\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b\u4e30\u5bcc\u5de5\u5177\u9009\u62e9\u7406\u7531\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u91c7\u7528\u76d1\u7763\u5b66\u4e60\u4e0e\u5f3a\u5316\u5b66\u4e60\u7ed3\u5408\u7684\u4e24\u9636\u6bb5\u4f18\u5316\u6d41\u7a0b\uff0c\u5305\u62ec\u8f68\u8ff9\u7a33\u5b9a\u548c\u57fa\u4e8eKL\u6b63\u5219\u5316\u7684\u591a\u6b65\u5de5\u5177\u9009\u62e9\u6392\u5e8f\u4f18\u5316\u3002", "result": "\u5728\u6570\u5b66\u3001\u79d1\u5b66\u3001\u4ee3\u7801\u751f\u6210\u548c\u591a\u6a21\u6001\u63a8\u7406\u7b49\u5341\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cAutoTool\u5728\u5c11\u53c2\u6570\u60c5\u51b5\u4e0b\u53d6\u5f97\u4e86\u4f18\u4e8e\u5148\u8fdb\u65b9\u6cd5\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u540c\u65f6\u5177\u5907\u52a8\u6001\u5229\u7528\u672a\u89c1\u5de5\u5177\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AutoTool\u6709\u6548\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u7684\u52a8\u6001\u5de5\u5177\u9009\u62e9\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u9762\u5bf9\u4e0d\u65ad\u53d8\u5316\u5de5\u5177\u96c6\u7684\u9002\u5e94\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.13279", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13279", "abs": "https://arxiv.org/abs/2512.13279", "authors": ["Jinrui Liu", "Jeff Wu", "Xuanguang Pan", "Gavin Cheung", "Shuai Ma", "Chongyang Tao"], "title": "AIR: Post-training Data Selection for Reasoning via Attention Head Influence", "comment": "19 pages", "summary": "LLMs achieve remarkable multi-step reasoning capabilities, yet effectively transferring these skills via post-training distillation remains challenging. Existing data selection methods, ranging from manual curation to heuristics based on length, entropy, or overall loss, fail to capture the causal importance of individual reasoning steps, limiting distillation efficiency. To address this, we propose Attention Influence for Reasoning (AIR), a principled, unsupervised and training-free framework that leverages mechanistic insights of the retrieval head to select high-value post-training data. AIR first identifies reasoning-critical attention heads of an off-the-shelf model, then constructs a weakened reference model with disabled head influence, and finally quantifies the resulting loss divergence as the Attention Influence Score. This score enables fine-grained assessment at both the step and sample levels, supporting step-level weighted fine-tuning and global sample selection. Experiments across multiple reasoning benchmarks show that AIR consistently improves reasoning accuracy, surpassing heuristic baselines and effectively isolating the most critical steps and samples. Our work establishes a mechanism-driven, data-efficient approach for reasoning distillation in LLMs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86AIR\u65b9\u6cd5\uff0c\u901a\u8fc7\u8bc6\u522b\u5e76\u91cf\u5316\u6ce8\u610f\u529b\u5934\u5bf9\u63a8\u7406\u6b65\u9aa4\u7684\u91cd\u8981\u6027\uff0c\u5b9e\u73b0\u9ad8\u6548\u7684\u540e\u8bad\u7ec3\u84b8\u998f\u6570\u636e\u9009\u62e9\uff0c\u4ece\u800c\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u6570\u636e\u9009\u62e9\u65b9\u6cd5\u672a\u80fd\u51c6\u786e\u6355\u6349\u63a8\u7406\u6b65\u9aa4\u7684\u56e0\u679c\u91cd\u8981\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u6280\u80fd\u84b8\u998f\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u65e0\u76d1\u7763\u3001\u65e0\u8bad\u7ec3\u7684AIR\u6846\u67b6\uff0c\u8bc6\u522b\u5173\u952e\u7684\u6ce8\u610f\u529b\u5934\uff0c\u6784\u5efa\u5f31\u5316\u53c2\u8003\u6a21\u578b\uff0c\u8ba1\u7b97\u6ce8\u610f\u529b\u5f71\u54cd\u8bc4\u5206\u7528\u4e8e\u7ec6\u7c92\u5ea6\u6b65\u9aa4\u548c\u6837\u672c\u9009\u62e9\u3002", "result": "\u591a\u4e2a\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u8868\u660e\uff0cAIR\u65b9\u6cd5\u4f18\u4e8e\u542f\u53d1\u5f0f\u57fa\u7ebf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u7387\uff0c\u5e76\u80fd\u591f\u6709\u6548\u9694\u79bb\u6700\u5173\u952e\u7684\u6b65\u9aa4\u548c\u6837\u672c\u3002", "conclusion": "AIR\u63d0\u4f9b\u4e86\u4e00\u79cd\u57fa\u4e8e\u673a\u5236\u9a71\u52a8\u7684\u6570\u636e\u9ad8\u6548\u63a8\u7406\u84b8\u998f\u65b9\u6cd5\uff0c\u4e3aLLM\u591a\u6b65\u63a8\u7406\u80fd\u529b\u8f6c\u79fb\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2512.13286", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13286", "abs": "https://arxiv.org/abs/2512.13286", "authors": ["Youssra Rebboud", "Pasquale Lisena", "Raphael Troncy"], "title": "Integrating Causal Reasoning into Automated Fact-Checking", "comment": "Extended version of the accepted ACM SAC paper", "summary": "In fact-checking applications, a common reason to reject a claim is to detect the presence of erroneous cause-effect relationships between the events at play. However, current automated fact-checking methods lack dedicated causal-based reasoning, potentially missing a valuable opportunity for semantically rich explainability. To address this gap, we propose a methodology that combines event relation extraction, semantic similarity computation, and rule-based reasoning to detect logical inconsistencies between chains of events mentioned in a claim and in an evidence. Evaluated on two fact-checking datasets, this method establishes the first baseline for integrating fine-grained causal event relationships into fact-checking and enhance explainability of verdict prediction.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u4e8b\u4ef6\u5173\u7cfb\u63d0\u53d6\u3001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u8ba1\u7b97\u548c\u57fa\u4e8e\u89c4\u5219\u63a8\u7406\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u8bc6\u522b\u4e8b\u5b9e\u6838\u67e5\u4e2d\u9648\u8ff0\u4e0e\u8bc1\u636e\u4e4b\u95f4\u7684\u56e0\u679c\u5173\u7cfb\u4e0d\u4e00\u81f4\uff0c\u4ece\u800c\u63d0\u5347\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u7684\u56e0\u679c\u63a8\u7406\u80fd\u529b\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u4e8b\u5b9e\u6838\u67e5\u65b9\u6cd5\u7f3a\u4e4f\u4e13\u95e8\u7684\u56e0\u679c\u5173\u7cfb\u63a8\u7406\uff0c\u5bfc\u81f4\u65e0\u6cd5\u5145\u5206\u5229\u7528\u56e0\u679c\u5173\u7cfb\u4fe1\u606f\u63d0\u5347\u5224\u5b9a\u7684\u8bed\u4e49\u89e3\u91ca\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e8b\u4ef6\u5173\u7cfb\u63d0\u53d6\u6280\u672f\u62bd\u53d6\u56e0\u679c\u4e8b\u4ef6\u94fe\uff0c\u8ba1\u7b97\u8bed\u4e49\u76f8\u4f3c\u5ea6\uff0c\u5e76\u7ed3\u5408\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\uff0c\u68c0\u6d4b\u9648\u8ff0\u4e0e\u8bc1\u636e\u4e2d\u4e8b\u4ef6\u94fe\u4e4b\u95f4\u7684\u903b\u8f91\u4e0d\u4e00\u81f4\u6027\u3002", "result": "\u5728\u4e24\u4e2a\u4e8b\u5b9e\u6838\u67e5\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u9996\u6b21\u4e3a\u7ec6\u7c92\u5ea6\u56e0\u679c\u4e8b\u4ef6\u5173\u7cfb\u878d\u5165\u4e8b\u5b9e\u6838\u67e5\u6784\u5efa\u4e86\u57fa\u7ebf\uff0c\u63d0\u5347\u4e86\u5224\u51b3\u89e3\u91ca\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u56e0\u679c\u4e8b\u4ef6\u5173\u7cfb\u63a8\u7406\u5728\u4e8b\u5b9e\u6838\u67e5\u4e2d\u7684\u7a7a\u767d\uff0c\u63d0\u5347\u4e86\u81ea\u52a8\u6838\u67e5\u7cfb\u7edf\u5bf9\u4e8e\u56e0\u679c\u903b\u8f91\u7684\u4e00\u81f4\u6027\u68c0\u6d4b\u80fd\u529b\u548c\u5224\u5b9a\u89e3\u91ca\u7684\u4e30\u5bcc\u5ea6\u3002"}}
{"id": "2512.13298", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13298", "abs": "https://arxiv.org/abs/2512.13298", "authors": ["Anna Aksenova", "Boris Zverkov", "Nicola Dainese", "Alexander Nikitin", "Pekka Marttinen"], "title": "MiniLingua: A Small Open-Source LLM for European Languages", "comment": "9+6 pages, 6 figures and 3 tables in the main text. Code at https://github.com/MiniLingua-ai/training_artifacts", "summary": "Large language models are powerful but often limited by high computational cost, privacy concerns, and English-centric training. Recent progress demonstrates that small, efficient models with around one billion parameters can deliver strong results and enable on-device use. This paper introduces MiniLingua, a multilingual open-source LLM of one billion parameters trained from scratch for 13 European languages, designed to balance coverage and instruction-following capabilities. Based on evaluation results, the instruction-tuned version of MiniLingua outperforms EuroLLM, a model with a similar training approach but a larger training budget, on summarization, classification and both open- and closed-book question answering. Moreover, it remains competitive with more advanced state-of-the-art models on open-ended generation tasks. We release model weights, tokenizer and source code used for data processing and model training.", "AI": {"tldr": "MiniLingua \u662f\u4e00\u4e2a\u4e00\u4ebf\u53c2\u6570\u7684\u591a\u8bed\u8a00\u5f00\u6e90\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4e13\u4e3a13\u79cd\u6b27\u6d32\u8bed\u8a00\u8bbe\u8ba1\uff0c\u517c\u987e\u8986\u76d6\u5ea6\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u9690\u79c1\u95ee\u9898\u53ca\u4ee5\u82f1\u8bed\u4e3a\u4e2d\u5fc3\u7684\u8bad\u7ec3\u9650\u5236\uff0c\u56e0\u6b64\u9700\u8981\u66f4\u5c0f\u5de7\u9ad8\u6548\u7684\u591a\u8bed\u8a00\u6a21\u578b\u3002", "method": "\u4ece\u5934\u8bad\u7ec3\u4e86\u4e00\u4e2a\u62e5\u6709\u4e00\u4ebf\u53c2\u6570\u7684MiniLingua\u6a21\u578b\uff0c\u6db5\u76d613\u79cd\u6b27\u6d32\u8bed\u8a00\uff0c\u5e76\u8fdb\u884c\u4e86\u6307\u4ee4\u5fae\u8c03\u3002", "result": "\u6307\u4ee4\u5fae\u8c03\u7248\u672c\u7684MiniLingua\u5728\u6458\u8981\u3001\u5206\u7c7b\u53ca\u95ee\u7b54\u4efb\u52a1\u4e0a\u4f18\u4e8e\u6b27\u76df\u7c7b\u4f3c\u6a21\u578bEuroLLM\uff0c\u4e14\u5728\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u63a5\u8fd1\u66f4\u5148\u8fdb\u7684\u9876\u5c16\u6a21\u578b\u3002", "conclusion": "MiniLingua\u5b9e\u73b0\u4e86\u9ad8\u6548\u591a\u8bed\u79cd\u6a21\u578b\u5728\u591a\u9879\u4efb\u52a1\u4e0a\u7684\u5353\u8d8a\u8868\u73b0\uff0c\u4e14\u5df2\u5f00\u6e90\u6240\u6709\u76f8\u5173\u8d44\u6e90\uff0c\u63a8\u52a8\u5b9e\u9645\u5e94\u7528\u548c\u7814\u7a76\u3002"}}
{"id": "2512.13330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13330", "abs": "https://arxiv.org/abs/2512.13330", "authors": ["Joona Kyt\u00f6niemi", "Jousia Piha", "Akseli Reunamo", "Fedor Vitiugin", "Farrokh Mehryary", "Sampo Pyysalo"], "title": "FIN-bench-v2: A Unified and Robust Benchmark Suite for Evaluating Finnish Large Language Models", "comment": null, "summary": "We introduce FIN-bench-v2, a unified benchmark suite for evaluating large language models in Finnish. FIN-bench-v2 consolidates Finnish versions of widely used benchmarks together with an updated and expanded version of the original FIN-bench into a single, consistently formatted collection, covering multiple-choice and generative tasks across reading comprehension, commonsense reasoning, sentiment analysis, world knowledge, and alignment. All datasets are converted to HuggingFace Datasets, which include both cloze and multiple-choice prompt formulations with five variants per task, and we incorporate human annotation or review for machine-translated resources such as GoldenSwag and XED. To select robust tasks, we pretrain a set of 2.15B-parameter decoder-only models and use their learning curves to compute monotonicity, signal-to-noise, non-random performance, and model ordering consistency, retaining only tasks that satisfy all criteria. We further evaluate a set of larger instruction-tuned models to characterize performance across tasks and prompt formulations. All datasets, prompts, and evaluation configurations are publicly available via our fork of the Language Model Evaluation Harness at https://github.com/LumiOpen/lm-evaluation-harness. Supplementary resources are released in a separate repository at https://github.com/TurkuNLP/FIN-bench-v2.", "AI": {"tldr": "FIN-bench-v2\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u82ac\u5170\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u5957\u4ef6\uff0c\u6db5\u76d6\u591a\u4efb\u52a1\u3001\u591a\u683c\u5f0f\uff0c\u63d0\u4f9b\u516c\u5f00\u6570\u636e\u548c\u8bc4\u6d4b\u5de5\u5177\u3002", "motivation": "\u4e3a\u4e86\u63d0\u4f9b\u4e00\u4e2a\u7edf\u4e00\u3001\u683c\u5f0f\u4e00\u81f4\u4e14\u8986\u76d6\u591a\u79cd\u4efb\u52a1\u7684\u82ac\u5170\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u6d4b\u5e73\u53f0\uff0c\u5e2e\u52a9\u8bc4\u4f30\u6a21\u578b\u5728\u82ac\u5170\u8bed\u4e0a\u7684\u80fd\u529b\u3002", "method": "\u6574\u5408\u73b0\u6709\u82ac\u5170\u8bed\u8bc4\u6d4b\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u4eba\u7c7b\u5ba1\u6838\uff0c\u4f7f\u75282.15B\u53c2\u6570\u6a21\u578b\u9884\u8bad\u7ec3\u9009\u53d6\u9c81\u68d2\u4efb\u52a1\uff0c\u8bc4\u6d4b\u66f4\u5927\u6307\u4ee4\u5fae\u8c03\u6a21\u578b\uff0c\u5e76\u516c\u5f00\u6570\u636e\u548c\u5de5\u5177\u3002", "result": "\u6210\u529f\u7b5b\u9009\u51fa\u6ee1\u8db3\u7a33\u5065\u6027\u6807\u51c6\u7684\u8bc4\u6d4b\u4efb\u52a1\uff0c\u6db5\u76d6\u9605\u8bfb\u7406\u89e3\u3001\u5e38\u8bc6\u63a8\u7406\u3001\u60c5\u611f\u5206\u6790\u7b49\u591a\u7c7b\u578b\u4efb\u52a1\uff0c\u5448\u73b0\u4e86\u591a\u6a21\u578b\u591a\u4efb\u52a1\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "FIN-bench-v2\u4e3a\u82ac\u5170\u8bed\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u3001\u516c\u5f00\u3001\u6807\u51c6\u5316\u7684\u8d44\u6e90\u548c\u65b9\u6cd5\uff0c\u4fc3\u8fdb\u82ac\u5170\u8bedNLP\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2512.13363", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13363", "abs": "https://arxiv.org/abs/2512.13363", "authors": ["Shibani Sankpal"], "title": "Detecting Emotion Drift in Mental Health Text Using Pre-Trained Transformers", "comment": "14 pages, 12 figures", "summary": "This study investigates emotion drift: the change in emotional state across a single text, within mental health-related messages. While sentiment analysis typically classifies an entire message as positive, negative, or neutral, the nuanced shift of emotions over the course of a message is often overlooked. This study detects sentence-level emotions and measures emotion drift scores using pre-trained transformer models such as DistilBERT and RoBERTa. The results provide insights into patterns of emotional escalation or relief in mental health conversations. This methodology can be applied to better understand emotional dynamics in content.", "AI": {"tldr": "\u672c\u7814\u7a76\u5206\u6790\u4e86\u5fc3\u7406\u5065\u5eb7\u76f8\u5173\u6d88\u606f\u4e2d\u60c5\u7eea\u968f\u6587\u672c\u53d8\u5316\u7684\u52a8\u6001\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u6355\u6349\u53e5\u5b50\u7ea7\u60c5\u7eea\u53d8\u5316\u3002", "motivation": "\u4f20\u7edf\u60c5\u611f\u5206\u6790\u901a\u5e38\u5bf9\u6574\u6761\u6d88\u606f\u8fdb\u884c\u6574\u4f53\u5206\u7c7b\uff0c\u5ffd\u7565\u4e86\u60c5\u7eea\u5728\u6587\u672c\u4e2d\u7684\u7ec6\u5fae\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684DistilBERT\u548cRoBERTa\u6a21\u578b\u68c0\u6d4b\u53e5\u5b50\u7ea7\u60c5\u7eea\uff0c\u5e76\u8ba1\u7b97\u60c5\u7eea\u6f02\u79fb\u5f97\u5206\u3002", "result": "\u63ed\u793a\u4e86\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u4e2d\u60c5\u7eea\u5347\u7ea7\u6216\u7f13\u89e3\u7684\u6a21\u5f0f\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u5185\u5bb9\u4e2d\u7684\u60c5\u7eea\u52a8\u6001\uff0c\u7279\u522b\u662f\u5728\u5fc3\u7406\u5065\u5eb7\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2512.13441", "categories": ["cs.CL", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.13441", "abs": "https://arxiv.org/abs/2512.13441", "authors": ["Johan J. Bolhuis", "Andrea Moro", "Stephen Crain", "Sandiway Fong"], "title": "Large language models are not about language", "comment": null, "summary": "Large Language Models are useless for linguistics, as they are probabilistic models that require a vast amount of data to analyse externalized strings of words. In contrast, human language is underpinned by a mind-internal computational system that recursively generates hierarchical thought structures. The language system grows with minimal external input and can readily distinguish between real language and impossible languages.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u5927\u91cf\u6570\u636e\u5904\u7406\u5916\u90e8\u8bed\u8a00\u6587\u672c\uff0c\u800c\u4eba\u7c7b\u8bed\u8a00\u57fa\u4e8e\u5185\u90e8\u8ba1\u7b97\u7cfb\u7edf\uff0c\u80fd\u9012\u5f52\u751f\u6210\u5c42\u7ea7\u601d\u7ef4\u7ed3\u6784\uff0c\u533a\u522b\u771f\u5b9e\u548c\u4e0d\u53ef\u80fd\u7684\u8bed\u8a00\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u5b66\u7814\u7a76\u7684\u5c40\u9650\u6027\uff0c\u5f3a\u8c03\u4eba\u7c7b\u8bed\u8a00\u80fd\u529b\u6e90\u4e8e\u5185\u90e8\u5fc3\u667a\u7cfb\u7edf\uff0c\u800c\u975e\u4ec5\u9760\u5916\u90e8\u8bed\u8a00\u6570\u636e\u3002", "method": "\u901a\u8fc7\u5bf9\u6bd4\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6982\u7387\u6027\u8d28\u4e0e\u4eba\u7c7b\u8bed\u8a00\u7684\u5fc3\u667a\u8ba1\u7b97\u7cfb\u7edf\uff0c\u5206\u6790\u4e24\u8005\u5728\u8bed\u8a00\u7406\u89e3\u548c\u751f\u6210\u4e0a\u7684\u5dee\u5f02\u3002", "result": "\u6307\u51fa\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u5927\u91cf\u5916\u90e8\u6570\u636e\u624d\u80fd\u5206\u6790\u6587\u5b57\u4e32\uff0c\u800c\u4eba\u7c7b\u8bed\u8a00\u7cfb\u7edf\u80fd\u5728\u6781\u5c11\u8f93\u5165\u4e0b\u6210\u957f\uff0c\u4e14\u80fd\u533a\u5206\u53ef\u80fd\u4e0e\u4e0d\u53ef\u80fd\u7684\u8bed\u8a00\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u8a00\u5b66\u7814\u7a76\u4e2d\u4f5c\u7528\u6709\u9650\uff0c\u771f\u6b63\u7684\u8bed\u8a00\u7406\u89e3\u9700\u57fa\u4e8e\u5185\u5728\u5fc3\u667a\u8ba1\u7b97\u7cfb\u7edf\u3002"}}
{"id": "2512.13472", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13472", "abs": "https://arxiv.org/abs/2512.13472", "authors": ["Jian Yang", "Shawn Guo", "Lin Jing", "Wei Zhang", "Aishan Liu", "Chuan Hao", "Zhoujun Li", "Wayne Xin Zhao", "Xianglong Liu", "Weifeng Lv", "Bryan Dai"], "title": "Scaling Laws for Code: Every Programming Language Matters", "comment": null, "summary": "Code large language models (Code LLMs) are powerful but costly to train, with scaling laws predicting performance from model size, data, and compute. However, different programming languages (PLs) have varying impacts during pre-training that significantly affect base model performance, leading to inaccurate performance prediction. Besides, existing works focus on language-agnostic settings, neglecting the inherently multilingual nature of modern software development. Therefore, it is first necessary to investigate the scaling laws of different PLs, and then consider their mutual influences to arrive at the final multilingual scaling law. In this paper, we present the first systematic exploration of scaling laws for multilingual code pre-training, conducting over 1000+ experiments (Equivalent to 336,000+ H800 hours) across multiple PLs, model sizes (0.2B to 14B parameters), and dataset sizes (1T tokens). We establish comprehensive scaling laws for code LLMs across multiple PLs, revealing that interpreted languages (e.g., Python) benefit more from increased model size and data than compiled languages (e.g., Rust). The study demonstrates that multilingual pre-training provides synergistic benefits, particularly between syntactically similar PLs. Further, the pre-training strategy of the parallel pairing (concatenating code snippets with their translations) significantly enhances cross-lingual abilities with favorable scaling properties. Finally, a proportion-dependent multilingual scaling law is proposed to optimally allocate training tokens by prioritizing high-utility PLs (e.g., Python), balancing high-synergy pairs (e.g., JavaScript-TypeScript), and reducing allocation to fast-saturating languages (Rust), achieving superior average performance across all PLs compared to uniform distribution under the same compute budget.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u591a\u8bed\u8a00\u4ee3\u7801\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6269\u5c55\u89c4\u5f8b\uff0c\u53d1\u73b0\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5bf9\u6027\u80fd\u5f71\u54cd\u663e\u8457\uff0c\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u548c\u5e76\u884c\u914d\u5bf9\u7b56\u7565\u53ef\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u63d0\u51fa\u6bd4\u4f8b\u4f9d\u8d56\u7684\u591a\u8bed\u8a00\u6269\u5c55\u89c4\u5f8b\u4f18\u5316\u8bad\u7ec3\u8d44\u6e90\u5206\u914d\u3002", "motivation": "\u73b0\u6709\u6269\u5c55\u89c4\u5f8b\u5ffd\u7565\u4e86\u4e0d\u540c\u7f16\u7a0b\u8bed\u8a00\u5bf9\u9884\u8bad\u7ec3\u6027\u80fd\u7684\u5dee\u5f02\u53ca\u73b0\u4ee3\u8f6f\u4ef6\u591a\u8bed\u8a00\u7279\u6027\uff0c\u5bfc\u81f4\u6027\u80fd\u9884\u6d4b\u4e0d\u51c6\u786e\uff0c\u6545\u9700\u7814\u7a76\u591a\u8bed\u8a00\u4ee3\u7801\u9884\u8bad\u7ec3\u7684\u6269\u5c55\u89c4\u5f8b\u53ca\u8bed\u8a00\u95f4\u76f8\u4e92\u5f71\u54cd\u3002", "method": "\u901a\u8fc71000\u591a\u6b21\u5b9e\u9a8c\uff0c\u6db5\u76d6\u591a\u79cd\u7f16\u7a0b\u8bed\u8a00\u3001\u6a21\u578b\u5927\u5c0f\u548c\u6570\u636e\u89c4\u6a21\uff0c\u7cfb\u7edf\u63a2\u7d22\u591a\u8bed\u8a00\u4ee3\u7801\u9884\u8bad\u7ec3\u7684\u6269\u5c55\u89c4\u5f8b\uff1b\u63d0\u51fa\u5e76\u9a8c\u8bc1\u5e76\u884c\u914d\u5bf9\u9884\u8bad\u7ec3\u7b56\u7565\u53ca\u6bd4\u4f8b\u4f9d\u8d56\u7684\u591a\u8bed\u8a00\u6269\u5c55\u89c4\u5f8b\uff0c\u4ee5\u4f18\u5316\u8bad\u7ec3\u8d44\u6e90\u5206\u914d\u3002", "result": "\u53d1\u73b0\u89e3\u91ca\u578b\u8bed\u8a00\uff08\u5982Python\uff09\u8f83\u7f16\u8bd1\u578b\u8bed\u8a00\uff08\u5982Rust\uff09\u5bf9\u6a21\u578b\u89c4\u6a21\u548c\u6570\u636e\u589e\u957f\u66f4\u654f\u611f\uff1b\u591a\u8bed\u8a00\u9884\u8bad\u7ec3\u5728\u8bed\u6cd5\u76f8\u4f3c\u8bed\u8a00\u95f4\u5177\u534f\u540c\u6548\u5e94\uff1b\u5e76\u884c\u914d\u5bf9\u7b56\u7565\u663e\u8457\u63d0\u5347\u8de8\u8bed\u8a00\u80fd\u529b\uff1b\u6bd4\u4f8b\u4f9d\u8d56\u6269\u5c55\u89c4\u5f8b\u5728\u76f8\u540c\u8ba1\u7b97\u8d44\u6e90\u4e0b\u4f18\u4e8e\u5747\u5300\u5206\u914d\u3002", "conclusion": "\u591a\u8bed\u8a00\u4ee3\u7801\u6a21\u578b\u7684\u8bad\u7ec3\u5e94\u8003\u8651\u8bed\u8a00\u7279\u6027\u4e0e\u76f8\u4e92\u5f71\u54cd\uff0c\u901a\u8fc7\u4f18\u5316\u6570\u636e\u5206\u914d\u7b56\u7565\u548c\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u53ef\u6709\u6548\u63d0\u5347\u6a21\u578b\u6027\u80fd\u548c\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2512.13478", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13478", "abs": "https://arxiv.org/abs/2512.13478", "authors": ["Kei Saito"], "title": "Non-Resolution Reasoning: A Framework for Preserving Semantic Ambiguity in Language Models", "comment": "19 pages", "summary": "Premature semantic collapse -- the forced early commitment to a single meaning -- remains a core architectural limitation of current language models. Softmax-driven competition and greedy decoding cause models to discard valid interpretations before sufficient context is available, resulting in brittle reasoning and context failures. We introduce Non-Resolution Reasoning (NRR), a general computational framework that preserves semantic ambiguity during inference and performs resolution only when explicitly required. NRR integrates three components: (1) Multi-Vector Embeddings that maintain multiple viable interpretations per token, (2) Non-Collapsing Attention that prevents winner-take-all dynamics across layers, and (3) Contextual Identity Tracking (CIT), which assigns context-specific identities to recurring entities (e.g., distinguishing \"Dr. Smith the cardiologist\" from \"Dr. Smith the researcher\"). These mechanisms are unified by an external Resolution Operator $\u03c1$ that makes semantic commitment explicit, controllable, and task-dependent. Unlike standard architectures, NRR separates representation from resolution, allowing a single model to shift between creative, factual, and ambiguity-preserving reasoning without retraining. A synthetic evaluation demonstrates NRR's ability to preserve ambiguity and track context: CIT-enhanced models achieve 90.9% accuracy on out-of-distribution identity-shift tasks, compared to 9.1% for transformer baselines. NRR provides a principled alternative to premature collapse, reframing ambiguity as an explicit representational state rather than a failure mode. The question is not whether AI should resolve ambiguity, but when, how, and under whose control.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u975e\u89e3\u6790\u63a8\u7406\uff08NRR\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u8bed\u8a00\u6a21\u578b\u5728\u63a8\u7406\u4e2d\u8bed\u4e49\u8fc7\u65e9\u584c\u7f29\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u4fdd\u6301\u591a\u91cd\u8bed\u4e49\u89e3\u91ca\u63d0\u5347\u4e86\u6a21\u578b\u5728\u610f\u4e49\u6b67\u4e49\u5904\u7406\u548c\u4e0a\u4e0b\u6587\u8ddf\u8e2a\u4e0a\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u56e0\u8f6f\u6700\u5927\u5316\u7ade\u4e89\u548c\u8d2a\u5a6a\u89e3\u7801\u5bfc\u81f4\u8bed\u4e49\u8fc7\u65e9\u584c\u7f29\uff0c\u5f03\u7f6e\u6709\u6548\u89e3\u91ca\uff0c\u9020\u6210\u63a8\u7406\u8106\u5f31\u548c\u4e0a\u4e0b\u6587\u5931\u8d25\u3002", "method": "\u5f15\u5165\u591a\u5411\u91cf\u5d4c\u5165\u3001\u975e\u584c\u7f29\u6ce8\u610f\u529b\u673a\u5236\u548c\u4e0a\u4e0b\u6587\u8eab\u4efd\u8ffd\u8e2a\u4e09\u5927\u7ec4\u4ef6\uff0c\u901a\u8fc7\u5916\u90e8\u89e3\u6790\u7b97\u5b50\u663e\u5f0f\u63a7\u5236\u8bed\u4e49\u89e3\u6790\u65f6\u673a\uff0c\u5b9e\u73b0\u8bed\u4e49\u8868\u793a\u4e0e\u89e3\u6790\u89e3\u8026\u3002", "result": "\u5728\u8eab\u4efd\u5207\u6362\u4efb\u52a1\u4e2d\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u8eab\u4efd\u8ffd\u8e2a\u7684\u6a21\u578b\u51c6\u786e\u7387\u8fbe\u523090.9%\uff0c\u8fdc\u8d85\u6807\u51c6Transformer\u6a21\u578b\u76849.1%\uff0c\u6709\u6548\u4fdd\u5b58\u6b67\u4e49\u5e76\u8ddf\u8e2a\u4e0a\u4e0b\u6587\u3002", "conclusion": "NRR\u6846\u67b6\u901a\u8fc7\u5c06\u6b67\u4e49\u4f5c\u4e3a\u663e\u5f0f\u72b6\u6001\uff0c\u63d0\u4f9b\u4e86\u907f\u514d\u8bed\u4e49\u8fc7\u65e9\u584c\u7f29\u7684\u539f\u5219\u6027\u65b9\u6cd5\uff0c\u5f3a\u8c03\u89e3\u51b3\u8bed\u4e49\u6b67\u4e49\u5e94\u7531\u4efb\u52a1\u548c\u63a7\u5236\u51b3\u7b56\u51b3\u5b9a\u3002"}}
{"id": "2512.13487", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13487", "abs": "https://arxiv.org/abs/2512.13487", "authors": ["Ayon Roy", "Risat Rahaman", "Sadat Shibly", "Udoy Saha Joy", "Abdulla Al Kafi", "Farig Yousuf Sadeque"], "title": "Advancing Bangla Machine Translation Through Informal Datasets", "comment": "33 pages, 13 figures", "summary": "Bangla is the sixth most widely spoken language globally, with approximately 234 million native speakers. However, progress in open-source Bangla machine translation remains limited. Most online resources are in English and often remain untranslated into Bangla, excluding millions from accessing essential information. Existing research in Bangla translation primarily focuses on formal language, neglecting the more commonly used informal language. This is largely due to the lack of pairwise Bangla-English data and advanced translation models. If datasets and models can be enhanced to better handle natural, informal Bangla, millions of people will benefit from improved online information access. In this research, we explore current state-of-the-art models and propose improvements to Bangla translation by developing a dataset from informal sources like social media and conversational texts. This work aims to advance Bangla machine translation by focusing on informal language translation and improving accessibility for Bangla speakers in the digital world.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u4f5c\u4e3a\u5168\u7403\u7b2c\u516d\u5927\u8bed\u8a00\uff0c\u4e14\u5f00\u6e90\u673a\u5668\u7ffb\u8bd1\u53d1\u5c55\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u901a\u8fc7\u975e\u6b63\u5f0f\u8bed\u8a00\u6570\u636e\u96c6\u548c\u6539\u8fdb\u6a21\u578b\u63d0\u5347\u5b5f\u52a0\u62c9\u8bed\u7ffb\u8bd1\u8d28\u91cf\u3002", "motivation": "\u5b5f\u52a0\u62c9\u8bed\u867d\u4f7f\u7528\u4eba\u6570\u4f17\u591a\uff0c\u4f46\u5f00\u653e\u8d44\u6e90\u548c\u673a\u5668\u7ffb\u8bd1\u4e3b\u8981\u96c6\u4e2d\u5728\u6b63\u5f0f\u8bed\u8a00\uff0c\u4e14\u7f3a\u5c11\u975e\u6b63\u5f0f\u8bed\u8a00\u7684\u6210\u5bf9\u6570\u636e\u548c\u5148\u8fdb\u6a21\u578b\uff0c\u5bfc\u81f4\u5927\u91cf\u7528\u6237\u96be\u4ee5\u83b7\u53d6\u4fe1\u606f\u3002", "method": "\u6536\u96c6\u6765\u81ea\u793e\u4ea4\u5a92\u4f53\u548c\u5bf9\u8bdd\u6587\u672c\u7684\u975e\u6b63\u5f0f\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\uff0c\u63a2\u7d22\u5e76\u6539\u8fdb\u5f53\u524d\u6700\u5148\u8fdb\u7684\u7ffb\u8bd1\u6a21\u578b\u4ee5\u9002\u5e94\u975e\u6b63\u5f0f\u8bed\u8a00\u3002", "result": "\u5f00\u53d1\u4e86\u5305\u542b\u975e\u6b63\u5f0f\u8bed\u8a00\u7684\u5b5f\u52a0\u62c9\u8bed\u6570\u636e\u96c6\uff0c\u63d0\u5347\u4e86\u673a\u5668\u7ffb\u8bd1\u6a21\u578b\u5904\u7406\u81ea\u7136\u8bed\u8a00\u7684\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u6ce8\u91cd\u975e\u6b63\u5f0f\u5b5f\u52a0\u62c9\u8bed\u7684\u7ffb\u8bd1\u548c\u6570\u636e\u4e30\u5bcc\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u5b5f\u52a0\u62c9\u8bed\u4f7f\u7528\u8005\u83b7\u53d6\u6570\u5b57\u4fe1\u606f\u7684\u4fbf\u5229\u6027\uff0c\u63a8\u52a8\u5b5f\u52a0\u62c9\u8bed\u673a\u5668\u7ffb\u8bd1\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2512.13494", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13494", "abs": "https://arxiv.org/abs/2512.13494", "authors": ["Yu-Chen Lu", "Sheng-Feng Yu", "Hui-Hsien Weng", "Pei-Shuo Wang", "Yu-Fang Hu", "Liang Hung-Chun", "Hung-Yueh Chiang", "Kai-Chiang Wu"], "title": "SkipCat: Rank-Maximized Low-Rank Compression of Large Language Models via Shared Projection and Block Skipping", "comment": "Accepted by AAAI 2026", "summary": "Large language models (LLM) have achieved remarkable performance across a wide range of tasks. However, their substantial parameter sizes pose significant challenges for deployment on edge devices with limited computational and memory resources. Low-rank compression is a promising approach to address this issue, as it reduces both computational and memory costs, making LLM more suitable for resource-constrained environments. Nonetheless, na\u00efve low-rank compression methods require a significant reduction in the retained rank to achieve meaningful memory and computation savings. For a low-rank model, the ranks need to be reduced by more than half to yield efficiency gains. Such aggressive truncation, however, typically results in substantial performance degradation. To address this trade-off, we propose SkipCat, a novel low-rank compression framework that enables the use of higher ranks while achieving the same compression rates. First, we introduce an intra-layer shared low-rank projection method, where multiple matrices that share the same input use a common projection. This reduces redundancy and improves compression efficiency. Second, we propose a block skipping technique that omits computations and memory transfers for selected sub-blocks within the low-rank decomposition. These two techniques jointly enable our compressed model to retain more effective ranks under the same compression budget. Experimental results show that, without any additional fine-tuning, our method outperforms previous low-rank compression approaches by 7% accuracy improvement on zero-shot tasks under the same compression rate. These results highlight the effectiveness of our rank-maximized compression strategy in preserving model performance under tight resource constraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86SkipCat\u4f4e\u79e9\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5171\u4eab\u4f4e\u79e9\u6295\u5f71\u548c\u5757\u8df3\u8fc7\u6280\u672f\uff0c\u5728\u76f8\u540c\u538b\u7f29\u7387\u4e0b\u4fdd\u7559\u66f4\u9ad8\u79e9\uff0c\u63d0\u5347\u6a21\u578b\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u5e9e\u5927\uff0c\u96be\u4ee5\u90e8\u7f72\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\uff0c\u4f20\u7edf\u4f4e\u79e9\u538b\u7f29\u9700\u6781\u5927\u964d\u4f4e\u79e9\u5bfc\u81f4\u6027\u80fd\u5927\u5e45\u4e0b\u964d\uff0c\u5b58\u5728\u6548\u7387\u4e0e\u6027\u80fd\u7684\u6743\u8861\u96be\u9898\u3002", "method": "\u63d0\u51faSkipCat\u6846\u67b6\uff0c\u5305\u62ec\u5c42\u5185\u5171\u4eab\u4f4e\u79e9\u6295\u5f71\u548c\u5757\u8df3\u8fc7\u6280\u672f\uff0c\u51cf\u5c11\u5197\u4f59\u8ba1\u7b97\u548c\u5185\u5b58\u4f20\u8f93\uff0c\u4f7f\u6a21\u578b\u5728\u76f8\u540c\u538b\u7f29\u7387\u4e0b\u53ef\u4fdd\u7559\u66f4\u9ad8\u79e9\uff0c\u63d0\u5347\u538b\u7f29\u6548\u7387\u3002", "result": "\u5728\u65e0\u989d\u5916\u5fae\u8c03\u60c5\u51b5\u4e0b\uff0cSkipCat\u5728\u76f8\u540c\u538b\u7f29\u7387\u4e0b\u96f6\u6837\u672c\u4efb\u52a1\u51c6\u786e\u7387\u63d0\u53477%\uff0c\u4f18\u4e8e\u73b0\u6709\u4f4e\u79e9\u538b\u7f29\u65b9\u6cd5\u3002", "conclusion": "SkipCat\u6709\u6548\u7f13\u89e3\u4e86\u4f4e\u79e9\u538b\u7f29\u4e2d\u6027\u80fd\u4e0e\u6548\u7387\u7684\u6743\u8861\uff0c\u5728\u8d44\u6e90\u7d27\u5f20\u73af\u5883\u4e0b\u66f4\u597d\u5730\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u3002"}}
{"id": "2512.13552", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13552", "abs": "https://arxiv.org/abs/2512.13552", "authors": ["Hour Kaing", "Raj Dabre", "Haiyue Song", "Van-Hien Tran", "Hideki Tanaka", "Masao Utiyama"], "title": "PrahokBART: A Pre-trained Sequence-to-Sequence Model for Khmer Natural Language Generation", "comment": "Published at COLING 2025, 14 pages", "summary": "This work introduces {\\it PrahokBART}, a compact pre-trained sequence-to-sequence model trained from scratch for Khmer using carefully curated Khmer and English corpora. We focus on improving the pre-training corpus quality and addressing the linguistic issues of Khmer, which are ignored in existing multilingual models, by incorporating linguistic components such as word segmentation and normalization. We evaluate PrahokBART on three generative tasks: machine translation, text summarization, and headline generation, where our results demonstrate that it outperforms mBART50, a strong multilingual pre-trained model. Additionally, our analysis provides insights into the impact of each linguistic module and evaluates how effectively our model handles space during text generation, which is crucial for the naturalness of texts in Khmer.", "AI": {"tldr": "PrahokBART\u662f\u4e00\u79cd\u9488\u5bf9\u9ad8\u68c9\u8bed\u7684\u65b0\u578b\u5e8f\u5217\u751f\u6210\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u5728\u591a\u4e2a\u751f\u6210\u4efb\u52a1\u4e2d\u8d85\u8fc7\u4e86\u591a\u8bed\u79cd\u6a21\u578bmBART50\u3002", "motivation": "\u73b0\u6709\u591a\u8bed\u79cd\u9884\u8bad\u7ec3\u6a21\u578b\u5ffd\u89c6\u4e86\u9ad8\u68c9\u8bed\u7684\u8bed\u8a00\u7279\u6027\u548c\u8bed\u6599\u8d28\u91cf\uff0c\u5bfc\u81f4\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\u3002", "method": "\u4ece\u96f6\u5f00\u59cb\u8bad\u7ec3PrahokBART\uff0c\u4f7f\u7528\u7ecf\u8fc7\u7cbe\u5fc3\u7b5b\u9009\u7684\u9ad8\u68c9\u8bed\u548c\u82f1\u8bed\u8bed\u6599\uff0c\u5e76\u7ed3\u5408\u4e86\u8bed\u8a00\u5b66\u6a21\u5757\u5982\u5206\u8bcd\u548c\u5f52\u4e00\u5316\u3002", "result": "PrahokBART\u5728\u673a\u5668\u7ffb\u8bd1\u3001\u6587\u672c\u6458\u8981\u548c\u6807\u9898\u751f\u6210\u4e09\u5927\u4efb\u52a1\u4e0a\u5747\u4f18\u4e8emBART50\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u8bed\u8a00\u5b66\u7279\u5f81\u548c\u9ad8\u8d28\u91cf\u8bed\u6599\uff0cPrahokBART\u663e\u8457\u63d0\u5347\u4e86\u9ad8\u68c9\u8bed\u6587\u672c\u751f\u6210\u7684\u81ea\u7136\u5ea6\u548c\u6548\u679c\u3002"}}
{"id": "2512.13559", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.13559", "abs": "https://arxiv.org/abs/2512.13559", "authors": ["Gibson Nkhata", "Uttamasha Anjally Oyshi", "Quan Mai", "Susan Gauch"], "title": "Verifying Rumors via Stance-Aware Structural Modeling", "comment": "8 pages, 2 figures, published in The 24th IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT 2025), London, UK, 2025", "summary": "Verifying rumors on social media is critical for mitigating the spread of false information. The stances of conversation replies often provide important cues to determine a rumor's veracity. However, existing models struggle to jointly capture semantic content, stance information, and conversation strructure, especially under the sequence length constraints of transformer-based encoders. In this work, we propose a stance-aware structural modeling that encodes each post in a discourse with its stance signal and aggregates reply embedddings by stance category enabling a scalable and semantically enriched representation of the entire thread. To enhance structural awareness, we introduce stance distribution and hierarchical depth as covariates, capturing stance imbalance and the influence of reply depth. Extensive experiments on benchmark datasets demonstrate that our approach significantly outperforms prior methods in the ability to predict truthfulness of a rumor. We also demonstrate that our model is versatile for early detection and cross-platfrom generalization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u7acb\u573a\u4fe1\u606f\u548c\u5bf9\u8bdd\u7ed3\u6784\u7684\u8c23\u8a00\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f16\u7801\u6bcf\u4e2a\u5e16\u5b50\u53ca\u5176\u7acb\u573a\uff0c\u805a\u5408\u56de\u590d\u5d4c\u5165\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8c23\u8a00\u771f\u5b9e\u6027\u9884\u6d4b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u540c\u65f6\u6355\u6349\u8bed\u4e49\u5185\u5bb9\u3001\u7acb\u573a\u4fe1\u606f\u53ca\u5bf9\u8bdd\u7ed3\u6784\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8eTransformer\u7f16\u7801\u5668\u7684\u5e8f\u5217\u957f\u5ea6\u9650\u5236\u4e0b\uff0c\u5f71\u54cd\u8c23\u8a00\u9a8c\u8bc1\u7684\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u7acb\u573a\u611f\u77e5\u7ed3\u6784\u5efa\u6a21\uff0c\u901a\u8fc7\u5bf9\u8bdd\u4e2d\u6bcf\u4e2a\u5e16\u5b50\u7684\u7acb\u573a\u4fe1\u53f7\u7f16\u7801\uff0c\u5e76\u6309\u7acb\u573a\u7c7b\u522b\u805a\u5408\u56de\u590d\u5d4c\u5165\uff0c\u540c\u65f6\u5f15\u5165\u7acb\u573a\u5206\u5e03\u548c\u5c42\u7ea7\u6df1\u5ea6\u4f5c\u4e3a\u534f\u53d8\u91cf\uff0c\u6355\u6349\u7acb\u573a\u4e0d\u5e73\u8861\u548c\u56de\u590d\u5c42\u7ea7\u5f71\u54cd\u3002", "result": "\u5728\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\uff0c\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u9884\u6d4b\u8c23\u8a00\u771f\u5b9e\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u5177\u5907\u65e9\u671f\u68c0\u6d4b\u548c\u8de8\u5e73\u53f0\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7ed3\u5408\u7acb\u573a\u4fe1\u53f7\u548c\u5bf9\u8bdd\u7ed3\u6784\u7684\u6df1\u5ea6\u5efa\u6a21\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u793e\u4ea4\u5a92\u4f53\u8c23\u8a00\u9a8c\u8bc1\u7684\u51c6\u786e\u6027\u548c\u9002\u7528\u8303\u56f4\u3002"}}
{"id": "2512.13564", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13564", "abs": "https://arxiv.org/abs/2512.13564", "authors": ["Yuyang Hu", "Shichun Liu", "Yanwei Yue", "Guibin Zhang", "Boyang Liu", "Fangyi Zhu", "Jiahang Lin", "Honglin Guo", "Shihan Dou", "Zhiheng Xi", "Senjie Jin", "Jiejun Tan", "Yanbin Yin", "Jiongnan Liu", "Zeyu Zhang", "Zhongxiang Sun", "Yutao Zhu", "Hao Sun", "Boci Peng", "Zhenrong Cheng", "Xuanbo Fan", "Jiaxin Guo", "Xinlei Yu", "Zhenhong Zhou", "Zewen Hu", "Jiahao Huo", "Junhao Wang", "Yuwei Niu", "Yu Wang", "Zhenfei Yin", "Xiaobin Hu", "Yue Liao", "Qiankun Li", "Kun Wang", "Wangchunshu Zhou", "Yixin Liu", "Dawei Cheng", "Qi Zhang", "Tao Gui", "Shirui Pan", "Yan Zhang", "Philip Torr", "Zhicheng Dou", "Ji-Rong Wen", "Xuanjing Huang", "Yu-Gang Jiang", "Shuicheng Yan"], "title": "Memory in the Age of AI Agents", "comment": null, "summary": "Memory has emerged, and will continue to remain, a core capability of foundation model-based agents. As research on agent memory rapidly expands and attracts unprecedented attention, the field has also become increasingly fragmented. Existing works that fall under the umbrella of agent memory often differ substantially in their motivations, implementations, and evaluation protocols, while the proliferation of loosely defined memory terminologies has further obscured conceptual clarity. Traditional taxonomies such as long/short-term memory have proven insufficient to capture the diversity of contemporary agent memory systems. This work aims to provide an up-to-date landscape of current agent memory research. We begin by clearly delineating the scope of agent memory and distinguishing it from related concepts such as LLM memory, retrieval augmented generation (RAG), and context engineering. We then examine agent memory through the unified lenses of forms, functions, and dynamics. From the perspective of forms, we identify three dominant realizations of agent memory, namely token-level, parametric, and latent memory. From the perspective of functions, we propose a finer-grained taxonomy that distinguishes factual, experiential, and working memory. From the perspective of dynamics, we analyze how memory is formed, evolved, and retrieved over time. To support practical development, we compile a comprehensive summary of memory benchmarks and open-source frameworks. Beyond consolidation, we articulate a forward-looking perspective on emerging research frontiers, including memory automation, reinforcement learning integration, multimodal memory, multi-agent memory, and trustworthiness issues. We hope this survey serves not only as a reference for existing work, but also as a conceptual foundation for rethinking memory as a first-class primitive in the design of future agentic intelligence.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8e\u57fa\u7840\u6a21\u578b\u7684\u667a\u80fd\u4f53\u8bb0\u5fc6\u7cfb\u7edf\uff0c\u68b3\u7406\u4e86\u8bb0\u5fc6\u7684\u5b9a\u4e49\u3001\u5206\u7c7b\u548c\u52a8\u6001\u6f14\u53d8\uff0c\u5e76\u603b\u7ed3\u4e86\u76f8\u5173\u57fa\u51c6\u4e0e\u6846\u67b6\uff0c\u63d0\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u9886\u57df\u5185\u5173\u4e8e\u667a\u80fd\u4f53\u8bb0\u5fc6\u7684\u7814\u7a76\u65e5\u76ca\u589e\u591a\u4f46\u5206\u6563\u4e14\u672f\u8bed\u6a21\u7cca\uff0c\u4f20\u7edf\u5206\u7c7b\u96be\u4ee5\u6db5\u76d6\u73b0\u6709\u591a\u6837\u5316\u7cfb\u7edf\uff0c\u56e0\u800c\u9700\u8981\u7edf\u4e00\u7684\u7cfb\u7edf\u6027\u68b3\u7406\u3002", "method": "\u901a\u8fc7\u660e\u786e\u667a\u80fd\u4f53\u8bb0\u5fc6\u8303\u56f4\uff0c\u533a\u5206\u76f8\u5173\u6982\u5ff5\uff0c\u4ece\u8bb0\u5fc6\u5f62\u5f0f\uff08token\u7ea7\u3001\u53c2\u6570\u5316\u3001\u6f5c\u5728\uff09\u3001\u529f\u80fd\uff08\u4e8b\u5b9e\u3001\u7ecf\u9a8c\u3001\u5de5\u4f5c\uff09\u548c\u52a8\u6001\uff08\u8bb0\u5fc6\u5f62\u6210\u3001\u6f14\u5316\u4e0e\u63d0\u53d6\uff09\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u5206\u7c7b\u548c\u5206\u6790\uff1b\u6574\u7406\u73b0\u6709\u57fa\u51c6\u548c\u5f00\u6e90\u6846\u67b6\uff1b\u63a2\u8ba8\u672a\u6765\u53d1\u5c55\u65b9\u5411\u3002", "result": "\u63d0\u51fa\u4e86\u667a\u80fd\u4f53\u8bb0\u5fc6\u7684\u4e09\u5927\u5f62\u5f0f\u548c\u4e09\u7c7b\u529f\u80fd\u7684\u7ec6\u5316\u5206\u7c7b\uff0c\u7cfb\u7edf\u603b\u7ed3\u4e86\u8bb0\u5fc6\u7684\u52a8\u6001\u7279\u5f81\u548c\u76f8\u5173\u8d44\u6e90\uff0c\u6784\u5efa\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u89c6\u89d2\u3002", "conclusion": "\u8be5\u7efc\u8ff0\u4e3a\u667a\u80fd\u4f53\u8bb0\u5fc6\u7814\u7a76\u63d0\u4f9b\u4e86\u6e05\u6670\u7684\u6982\u5ff5\u6846\u67b6\u548c\u5206\u7c7b\u4f53\u7cfb\uff0c\u4fc3\u8fdb\u9886\u57df\u6574\u5408\uff0c\u5e76\u6307\u660e\u672a\u6765\u7814\u7a76\u8d8b\u52bf\uff0c\u52a9\u529b\u667a\u80fd\u4f53\u8bbe\u8ba1\u4e2d\u8bb0\u5fc6\u6210\u4e3a\u6838\u5fc3\u539f\u8bed\u3002"}}
{"id": "2512.13586", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13586", "abs": "https://arxiv.org/abs/2512.13586", "authors": ["Jia-Nan Li", "Jian Guan", "Wei Wu", "Chongxuan Li"], "title": "ReFusion: A Diffusion Large Language Model with Parallel Autoregressive Decoding", "comment": null, "summary": "Autoregressive models (ARMs) are hindered by slow sequential inference. While masked diffusion models (MDMs) offer a parallel alternative, they suffer from critical drawbacks: high computational overhead from precluding Key-Value (KV) caching, and incoherent generation arising from learning dependencies over an intractable space of token combinations. To address these limitations, we introduce ReFusion, a novel masked diffusion model that achieves superior performance and efficiency by elevating parallel decoding from the token level to a higher slot level, where each slot is a fixed-length, contiguous sub-sequence. This is achieved through an iterative ``plan-and-infill'' decoding process: a diffusion-based planning step first identifies a set of weakly dependent slots, and an autoregressive infilling step then decodes these selected slots in parallel. The slot-based design simultaneously unlocks full KV cache reuse with a unified causal framework and reduces the learning complexity from the token combination space to a manageable slot-level permutation space. Extensive experiments on seven diverse benchmarks show that ReFusion not only overwhelmingly surpasses prior MDMs with 34% performance gains and an over 18$\\times$ speedup on average, but also bridges the performance gap to strong ARMs while maintaining a 2.33$\\times$ average speedup.", "AI": {"tldr": "ReFusion\u662f\u4e00\u79cd\u6539\u8fdb\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\uff0c\u901a\u8fc7\u5c06\u89e3\u7801\u4ece\u5355\u4e2a\u6807\u8bb0\u63d0\u5347\u5230\u56fa\u5b9a\u957f\u5ea6\u7684\u69fd\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u5e76\u884c\u63a8\u65ad\u548c\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u867d\u7136\u652f\u6301\u5e76\u884c\u63a8\u65ad\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u4e14\u751f\u6210\u4e0d\u8fde\u8d2f\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u6027\u80fd\u63d0\u5347\u3002", "method": "\u63d0\u51faReFusion\u6a21\u578b\uff0c\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u6b65\u9aa4\u8bc6\u522b\u5f31\u4f9d\u8d56\u7684\u69fd\uff0c\u63a5\u7740\u4ee5\u81ea\u56de\u5f52\u65b9\u5f0f\u5e76\u884c\u586b\u5145\u8fd9\u4e9b\u69fd\uff0c\u4ece\u800c\u5b9e\u73b0\u69fd\u7ea7\u522b\u7684\u5e76\u884c\u89e3\u7801\uff0c\u5145\u5206\u5229\u7528KV\u7f13\u5b58\u5e76\u964d\u4f4e\u5b66\u4e60\u590d\u6742\u5ea6\u3002", "result": "\u5728\u4e03\u4e2a\u4e0d\u540c\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cReFusion\u6a21\u578b\u5728\u6027\u80fd\u4e0a\u5e73\u5747\u63d0\u534734%\uff0c\u6bd4\u4ee5\u5f80\u7684\u63a9\u7801\u6269\u6563\u6a21\u578b\u901f\u5ea6\u63d0\u9ad818\u500d\uff0c\u5e76\u5728\u4fdd\u63012.33\u500d\u901f\u5ea6\u63d0\u5347\u7684\u540c\u65f6\uff0c\u7f29\u5c0f\u4e86\u4e0e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u6027\u80fd\u5dee\u8ddd\u3002", "conclusion": "ReFusion\u901a\u8fc7\u69fd\u7ea7\u522b\u7684\u63a9\u7801\u6269\u6563\u548c\u8ba1\u5212\u586b\u5145\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5e76\u884c\u63a8\u65ad\u4e2d\u7684\u6548\u7387\u4e0e\u6027\u80fd\u74f6\u9888\uff0c\u6210\u4e3a\u8fde\u63a5\u81ea\u56de\u5f52\u6a21\u578b\u548c\u63a9\u7801\u6269\u6563\u6a21\u578b\u7684\u9ad8\u6548\u6865\u6881\u3002"}}
{"id": "2512.13598", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13598", "abs": "https://arxiv.org/abs/2512.13598", "authors": ["Daniel Melcer", "Qi Chen", "Wen-Hao Chiang", "Shweta Garg", "Pranav Garg", "Christian Bock"], "title": "Textual Gradients are a Flawed Metaphor for Automatic Prompt Optimization", "comment": null, "summary": "A well-engineered prompt can increase the performance of large language models; automatic prompt optimization techniques aim to increase performance without requiring human effort to tune the prompts. One leading class of prompt optimization techniques introduces the analogy of textual gradients. We investigate the behavior of these textual gradient methods through a series of experiments and case studies. While such methods often result in a performance improvement, our experiments suggest that the gradient analogy does not accurately explain their behavior. Our insights may inform the selection of prompt optimization strategies, and development of new approaches.", "AI": {"tldr": "\u81ea\u52a8\u63d0\u793a\u4f18\u5316\u6280\u672f\u901a\u8fc7\u7c7b\u6bd4\u6587\u672c\u68af\u5ea6\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u4f46\u5b9e\u9a8c\u8868\u660e\u68af\u5ea6\u7c7b\u6bd4\u89e3\u91ca\u4e0d\u8db3\u3002", "motivation": "\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u6027\u80fd\uff0c\u51cf\u5c11\u4eba\u5de5\u8c03\u4f18\u63d0\u793a\u8bcd\u7684\u9700\u6c42\u3002", "method": "\u901a\u8fc7\u4e00\u7cfb\u5217\u5b9e\u9a8c\u548c\u6848\u4f8b\u5206\u6790\u6587\u672c\u68af\u5ea6\u65b9\u6cd5\u7684\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u867d\u7136\u6587\u672c\u68af\u5ea6\u65b9\u6cd5\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u5176\u68af\u5ea6\u7c7b\u6bd4\u89e3\u91ca\u4e0d\u51c6\u786e\u3002", "conclusion": "\u4e3a\u9009\u62e9\u548c\u5f00\u53d1\u63d0\u793a\u4f18\u5316\u65b9\u6cd5\u63d0\u4f9b\u65b0\u7684\u89c1\u89e3\uff0c\u4fc3\u8fdb\u66f4\u6709\u6548\u7684\u63d0\u793a\u4f18\u5316\u7b56\u7565\u53d1\u5c55\u3002"}}
{"id": "2512.13607", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13607", "abs": "https://arxiv.org/abs/2512.13607", "authors": ["Boxin Wang", "Chankyu Lee", "Nayeon Lee", "Sheng-Chieh Lin", "Wenliang Dai", "Yang Chen", "Yangyi Chen", "Zhuolin Yang", "Zihan Liu", "Mohammad Shoeybi", "Bryan Catanzaro", "Wei Ping"], "title": "Nemotron-Cascade: Scaling Cascaded Reinforcement Learning for General-Purpose Reasoning Models", "comment": "We publicly release the Nemotron-Cascade models and the full collection of training data at: https://huggingface.co/collections/nvidia/nemotron-cascade", "summary": "Building general-purpose reasoning models with reinforcement learning (RL) entails substantial cross-domain heterogeneity, including large variation in inference-time response lengths and verification latency. Such variability complicates the RL infrastructure, slows training, and makes training curriculum (e.g., response length extension) and hyperparameter selection challenging. In this work, we propose cascaded domain-wise reinforcement learning (Cascade RL) to develop general-purpose reasoning models, Nemotron-Cascade, capable of operating in both instruct and deep thinking modes. Departing from conventional approaches that blend heterogeneous prompts from different domains, Cascade RL orchestrates sequential, domain-wise RL, reducing engineering complexity and delivering state-of-the-art performance across a wide range of benchmarks. Notably, RLHF for alignment, when used as a pre-step, boosts the model's reasoning ability far beyond mere preference optimization, and subsequent domain-wise RLVR stages rarely degrade the benchmark performance attained in earlier domains and may even improve it (see an illustration in Figure 1). Our 14B model, after RL, outperforms its SFT teacher, DeepSeek-R1-0528, on LiveCodeBench v5/v6/Pro and achieves silver-medal performance in the 2025 International Olympiad in Informatics (IOI). We transparently share our training and data recipes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u7ea7\u8054\u9886\u57df\u5f3a\u5316\u5b66\u4e60\uff08Cascade RL\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u6784\u5efa\u901a\u7528\u63a8\u7406\u6a21\u578bNemotron-Cascade\uff0c\u901a\u8fc7\u6309\u9886\u57df\u987a\u5e8f\u8bad\u7ec3\uff0c\u964d\u4f4e\u8de8\u9886\u57df\u5f02\u8d28\u6027\u5e26\u6765\u7684\u590d\u6742\u6027\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5728\u5904\u7406\u8de8\u9886\u57df\u63a8\u7406\u65f6\u9762\u4e34\u54cd\u5e94\u957f\u5ea6\u548c\u9a8c\u8bc1\u65f6\u5ef6\u5927\u5e45\u53d8\u5316\uff0c\u5bfc\u81f4\u8bad\u7ec3\u590d\u6742\u4e14\u6548\u7387\u4f4e\u4e0b\uff0c\u96be\u4ee5\u8bbe\u8ba1\u8bad\u7ec3\u8bfe\u7a0b\u548c\u8c03\u6574\u8d85\u53c2\u6570\u3002", "method": "Cascade RL\u901a\u8fc7\u987a\u5e8f\u6267\u884c\u9886\u57df\u7279\u5b9a\u7684\u5f3a\u5316\u5b66\u4e60\uff0c\u907f\u514d\u6df7\u5408\u591a\u9886\u57df\u5f02\u8d28\u6570\u636e\uff0c\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\u3002\u5148\u8fdb\u884cRLHF\u5bf9\u9f50\u9884\u8bad\u7ec3\uff0c\u968f\u540e\u8fdb\u884c\u9886\u57df\u7ea7\u5f3a\u5316\u5b66\u4e60\u4ee5\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u3002", "result": "14B\u53c2\u6570\u6a21\u578b\u7ecf\u8fc7Cascade RL\u8bad\u7ec3\u540e\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u5176SFT\u6559\u5e08\u6a21\u578bDeepSeek-R1-0528\uff0c\u5e76\u57282025\u5e74\u56fd\u9645\u4fe1\u606f\u5b66\u5965\u6797\u5339\u514b\u4e2d\u83b7\u5f97\u94f6\u724c\u6210\u7ee9\u3002", "conclusion": "\u7ea7\u8054\u9886\u57df\u5f3a\u5316\u5b66\u4e60\u6709\u6548\u89e3\u51b3\u4e86\u8de8\u9886\u57df\u63a8\u7406\u4e2d\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u8bad\u7ec3\u6548\u7387\uff0c\u4e3a\u6784\u5efa\u901a\u7528\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2512.13618", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.13618", "abs": "https://arxiv.org/abs/2512.13618", "authors": ["Zefang Liu", "Nam Nguyen", "Yinzhu Quan", "Austin Zhang"], "title": "Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models", "comment": null, "summary": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte-level representations, human-semantic calendar tokens, classic uniform binning, and adaptive residual scalar quantization. We evaluate these strategies by fine-tuning LLMs on real-world datasets that exemplify these diverse distributions. Our analysis reveals that no single strategy is universally superior; instead, prediction performance depends heavily on aligning the tokenizer with the data's statistical properties, with log-based strategies excelling on skewed distributions and human-centric formats proving robust for mixed modalities.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u7cfb\u7edf\u5730\u6bd4\u8f83\u4e86\u591a\u79cd\u65f6\u95f4\u5e8f\u5217\u4e8b\u4ef6\u7684\u65f6\u95f4\u7f16\u7801\u7b56\u7565\uff0c\u53d1\u73b0\u6ca1\u6709\u5355\u4e00\u6700\u4f18\u65b9\u6848\uff0c\u9002\u5e94\u6570\u636e\u7edf\u8ba1\u7279\u6027\u624d\u662f\u5173\u952e\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u8fde\u7eed\u65f6\u95f4\u8868\u793a\u65f6\u5b58\u5728\u6311\u6218\uff0c\u4e14\u73b0\u6709\u65b9\u6cd5\u5728\u9762\u5bf9\u4e0d\u540c\u6570\u636e\u5206\u5e03\u65f6\u8868\u73b0\u4e0d\u4e00\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6bd4\u8f83\u3002", "method": "\u5bf9\u6bd4\u4e86\u4e94\u79cd\u65f6\u95f4\u5e8f\u5217\u7f16\u7801\u7b56\u7565\uff0c\u5305\u62ec\u6570\u5b57\u5b57\u7b26\u4e32\u3001\u9ad8\u7cbe\u5ea6\u5b57\u8282\u7f16\u7801\u3001\u8bed\u4e49\u65e5\u5386\u6807\u8bb0\u3001\u5747\u5300\u5206\u7bb1\u548c\u81ea\u9002\u5e94\u91cf\u5316\uff0c\u5e76\u5728\u591a\u79cd\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u5fae\u8c03LLM\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u7b56\u7565\u5bf9\u4e0d\u540c\u7edf\u8ba1\u5206\u5e03\u7684\u6570\u636e\u8868\u73b0\u4e0d\u540c\uff0c\u57fa\u4e8e\u5bf9\u6570\u7684\u7f16\u7801\u5728\u504f\u6001\u5206\u5e03\u4e2d\u6548\u679c\u8f83\u597d\uff0c\u8bed\u4e49\u65e5\u5386\u6807\u8bb0\u5bf9\u6df7\u5408\u6a21\u6001\u6570\u636e\u8868\u73b0\u7a33\u5b9a\u3002", "conclusion": "\u65f6\u95f4\u5e8f\u5217\u7684\u65f6\u95f4\u7f16\u7801\u9009\u62e9\u5e94\u4f9d\u636e\u6570\u636e\u7edf\u8ba1\u7279\u6027\uff0c\u6ca1\u6709\u5355\u4e00\u666e\u9002\u6700\u4f73\u65b9\u6848\uff0c\u5f3a\u8c03\u4e86\u5bf9\u6570\u636e\u5206\u5e03\u7684\u9002\u914d\u6027\u3002"}}
{"id": "2512.13654", "categories": ["cs.CL", "cs.AI", "cs.ET", "cs.IR"], "pdf": "https://arxiv.org/pdf/2512.13654", "abs": "https://arxiv.org/abs/2512.13654", "authors": ["John E. Ortega", "Dhruv D. Joshi", "Matt P. Borkowski"], "title": "Large-Language Memorization During the Classification of United States Supreme Court Cases", "comment": "7 pages, 1 figure, Appendix of Prompts", "summary": "Large-language models (LLMs) have been shown to respond in a variety of ways for classification tasks outside of question-answering. LLM responses are sometimes called \"hallucinations\" since the output is not what is ex pected. Memorization strategies in LLMs are being studied in detail, with the goal of understanding how LLMs respond. We perform a deep dive into a classification task based on United States Supreme Court (SCOTUS) decisions. The SCOTUS corpus is an ideal classification task to study for LLM memory accuracy because it presents significant challenges due to extensive sentence length, complex legal terminology, non-standard structure, and domain-specific vocabulary. Experimentation is performed with the latest LLM fine tuning and retrieval-based approaches, such as parameter-efficient fine-tuning, auto-modeling, and others, on two traditional category-based SCOTUS classification tasks: one with 15 labeled topics and another with 279. We show that prompt-based models with memories, such as DeepSeek, can be more robust than previous BERT-based models on both tasks scoring about 2 points better than previous models not based on prompting.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u590d\u6742\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u57fa\u4e8e\u8bb0\u5fc6\u548c\u63d0\u793a\u7684\u6a21\u578b\u5728\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662\u5224\u51b3\u5206\u7c7b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\u3002", "motivation": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u975e\u95ee\u7b54\u7c7b\u5206\u7c7b\u4efb\u52a1\u4e2d\u8f93\u51fa\u201c\u5e7b\u89c9\u201d\u73b0\u8c61\uff0c\u63a2\u7a76\u5176\u8bb0\u5fc6\u7b56\u7565\u4e0e\u54cd\u5e94\u673a\u5236\uff0c\u5c24\u5176\u5728\u590d\u6742\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u4e2d\u8868\u73b0\u5982\u4f55\u3002", "method": "\u5229\u7528\u7f8e\u56fd\u6700\u9ad8\u6cd5\u9662\u5224\u51b3\u6587\u672c\uff0c\u7ed3\u5408\u6700\u65b0\u7684LLM\u5fae\u8c03\u548c\u68c0\u7d22\u65b9\u6cd5\uff08\u5982\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u3001\u81ea\u52a8\u5efa\u6a21\u7b49\uff09\uff0c\u5728\u4e24\u4e2a\u4f20\u7edf\u5206\u7c7b\u4efb\u52a1\uff0815\u7c7b\u548c279\u7c7b\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u57fa\u4e8e\u63d0\u793a\u7684\u6a21\u578b\uff08\u5982DeepSeek\uff09\u4e0e\u4f20\u7edfBERT\u6a21\u578b\u7684\u6027\u80fd\u3002", "result": "\u63d0\u793a\u52a0\u8bb0\u5fc6\u7684\u6a21\u578b\u5728\u4e24\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u66f4\u597d\uff0c\u6d4b\u8bd5\u4e2d\u6bd4\u4f20\u7edfBERT\u6a21\u578b\u63d0\u9ad8\u7ea62\u4e2a\u767e\u5206\u70b9\u7684\u51c6\u786e\u7387\uff0c\u663e\u793a\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "\u57fa\u4e8e\u63d0\u793a\u548c\u8bb0\u5fc6\u7684LLM\u5728\u590d\u6742\u6cd5\u5f8b\u6587\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u4e8e\u4f20\u7edf\u6a21\u578b\uff0c\u63d0\u793a\u4e86\u65b0\u7684\u6a21\u578b\u8bbe\u8ba1\u65b9\u5411\u548c\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.13667", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13667", "abs": "https://arxiv.org/abs/2512.13667", "authors": ["Cristina Aggazzotti", "Elizabeth Allyn Smith"], "title": "A stylometric analysis of speaker attribution from speech transcripts", "comment": null, "summary": "Forensic scientists often need to identify an unknown speaker or writer in cases such as ransom calls, covert recordings, alleged suicide notes, or anonymous online communications, among many others. Speaker recognition in the speech domain usually examines phonetic or acoustic properties of a voice, and these methods can be accurate and robust under certain conditions. However, if a speaker disguises their voice or employs text-to-speech software, vocal properties may no longer be reliable, leaving only their linguistic content available for analysis. Authorship attribution methods traditionally use syntactic, semantic, and related linguistic information to identify writers of written text (authorship attribution). In this paper, we apply a content-based authorship approach to speech that has been transcribed into text, using what a speaker says to attribute speech to individuals (speaker attribution). We introduce a stylometric method, StyloSpeaker, which incorporates character, word, token, sentence, and style features from the stylometric literature on authorship, to assess whether two transcripts were produced by the same speaker. We evaluate this method on two types of transcript formatting: one approximating prescriptive written text with capitalization and punctuation and another normalized style that removes these conventions. The transcripts' conversation topics are also controlled to varying degrees. We find generally higher attribution performance on normalized transcripts, except under the strongest topic control condition, in which overall performance is highest. Finally, we compare this more explainable stylometric model to black-box neural approaches on the same data and investigate which stylistic features most effectively distinguish speakers.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6587\u4f53\u5b66\u7279\u5f81\u7684\u8bf4\u8bdd\u4eba\u5f52\u5c5e\u65b9\u6cd5\uff0c\u9488\u5bf9\u8bed\u97f3\u8f6c\u6587\u672c\u6570\u636e\u8fdb\u884c\u8bf4\u8bdd\u4eba\u8bc6\u522b\uff0c\u5e76\u4e0e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "motivation": "\u9274\u4e8e\u4f20\u7edf\u8bed\u97f3\u8bc6\u522b\u65b9\u6cd5\u5728\u8bf4\u8bdd\u4eba\u4f7f\u7528\u8bed\u97f3\u53d8\u58f0\u6216\u8bed\u97f3\u5408\u6210\u65f6\u5931\u6548\uff0c\u672c\u6587\u63a2\u8ba8\u5229\u7528\u8bf4\u8bdd\u5185\u5bb9\u7684\u8bed\u8a00\u7279\u5f81\u7528\u4e8e\u8bf4\u8bdd\u4eba\u8bc6\u522b\u7684\u53ef\u80fd\u6027\u3002", "method": "\u63d0\u51fa\u4e86StyloSpeaker\u65b9\u6cd5\uff0c\u878d\u5408\u5b57\u7b26\u3001\u8bcd\u6c47\u3001\u53e5\u6cd5\u53ca\u98ce\u683c\u7279\u5f81\uff0c\u5206\u522b\u5728\u6709\u65e0\u6807\u70b9\u53ca\u5927\u5c0f\u5199\u4e24\u79cd\u6587\u672c\u683c\u5f0f\u4e0a\u8fdb\u884c\u8bf4\u8bdd\u4eba\u5f52\u5c5e\u6d4b\u8bd5\uff0c\u5e76\u901a\u8fc7\u63a7\u5236\u8bdd\u9898\u4e00\u81f4\u6027\u8bc4\u4f30\u6027\u80fd\u3002", "result": "\u5728\u53bb\u9664\u6807\u70b9\u53ca\u5927\u5c0f\u5199\u7684\u89c4\u8303\u5316\u6587\u672c\u4e0a\u5f52\u5c5e\u8868\u73b0\u8f83\u597d\uff0c\u6700\u5f3a\u7684\u8bdd\u9898\u63a7\u5236\u6761\u4ef6\u4e0b\u6027\u80fd\u6700\u9ad8\uff0c\u4e14\u8be5\u6587\u4f53\u5b66\u65b9\u6cd5\u76f8\u6bd4\u9ed1\u7bb1\u795e\u7ecf\u7f51\u7edc\u66f4\u5177\u89e3\u91ca\u6027\uff0c\u80fd\u591f\u8bc6\u522b\u51fa\u533a\u5206\u8bf4\u8bdd\u4eba\u7684\u5173\u952e\u98ce\u683c\u7279\u5f81\u3002", "conclusion": "\u57fa\u4e8e\u6587\u672c\u5185\u5bb9\u7684\u6587\u4f53\u5206\u6790\u65b9\u6cd5\u5728\u8bf4\u8bdd\u4eba\u8bc6\u522b\u4e2d\u6709\u6548\uff0c\u5c24\u5176\u5f53\u8bed\u97f3\u7279\u5f81\u4e0d\u53ef\u7528\u65f6\uff0c\u53ef\u4f5c\u4e3a\u4f20\u7edf\u8bed\u97f3\u8bc6\u522b\u7684\u6709\u529b\u8865\u5145\u3002"}}
{"id": "2512.13676", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13676", "abs": "https://arxiv.org/abs/2512.13676", "authors": ["Baixiang Huang", "Limeng Cui", "Jiapeng Liu", "Haoran Wang", "Jiawei Xu", "Zhuiyue Tan", "Yutong Chen", "Chen Luo", "Yi Liu", "Kai Shu"], "title": "Towards Effective Model Editing for LLM Personalization", "comment": "15 pages (including appendix), 7 figures. Code, data, results, and additional resources are available at: https://model-editing.github.io", "summary": "Personalization is becoming indispensable for LLMs to align with individual user preferences and needs. Yet current approaches are often computationally expensive, data-intensive, susceptible to catastrophic forgetting, and prone to performance degradation in multi-turn interactions or when handling implicit queries. To address these challenges, we conceptualize personalization as a model editing task and introduce Personalization Editing, a framework that applies localized edits guided by clustered preference representations. This design enables precise preference-aligned updates while preserving overall model capabilities. In addition, existing personalization benchmarks frequently rely on persona-based dialogs between LLMs rather than user-LLM interactions, or focus primarily on stylistic imitation while neglecting information-seeking tasks that require accurate recall of user-specific preferences. We introduce User Preference Question Answering (UPQA), a short-answer QA dataset constructed from in-situ user queries with varying levels of difficulty. Unlike prior benchmarks, UPQA directly evaluates a model's ability to recall and apply specific user preferences. Across experimental settings, Personalization Editing achieves higher editing accuracy and greater computational efficiency than fine-tuning, while outperforming prompting-based baselines in multi-turn conversations and implicit preference questions settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e2a\u4eba\u5316\u7f16\u8f91\u6846\u67b6\uff0c\u901a\u8fc7\u5c40\u90e8\u6a21\u578b\u7f16\u8f91\u5b9e\u73b0\u5bf9\u7528\u6237\u504f\u597d\u7684\u7cbe\u51c6\u8c03\u6574\uff0c\u89e3\u51b3\u4e86\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u6570\u636e\u9700\u6c42\u5927\u548c\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u6d4b\u6570\u636e\u96c6UPQA\u6765\u8861\u91cf\u6a21\u578b\u5bf9\u7528\u6237\u504f\u597d\u7684\u8bb0\u5fc6\u548c\u5e94\u7528\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5927\u6a21\u578b\u4e2a\u4eba\u5316\u65b9\u6cd5\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u6613\u9057\u5fd8\u4ee5\u53ca\u5728\u591a\u8f6e\u5bf9\u8bdd\u548c\u9690\u5f0f\u67e5\u8be2\u4e2d\u6027\u80fd\u4e0b\u964d\u7b49\u95ee\u9898\uff0c\u4e14\u7f3a\u4e4f\u80fd\u6709\u6548\u8bc4\u4f30\u6a21\u578b\u5bf9\u7528\u6237\u504f\u597d\u51c6\u786e\u8bb0\u5fc6\u7684\u57fa\u51c6\u3002", "method": "\u5c06\u4e2a\u4eba\u5316\u89c6\u4e3a\u6a21\u578b\u7f16\u8f91\u4efb\u52a1\uff0c\u63d0\u51faPersonalization Editing\u6846\u67b6\uff0c\u5229\u7528\u805a\u7c7b\u504f\u597d\u8868\u793a\u5f15\u5bfc\u5c40\u90e8\u7f16\u8f91\uff0c\u4fdd\u8bc1\u4e2a\u6027\u5316\u8c03\u6574\u7cbe\u51c6\u4e14\u4e0d\u5f71\u54cd\u6a21\u578b\u6574\u4f53\u80fd\u529b\uff0c\u5e76\u6784\u5efa\u4e86\u57fa\u4e8e\u7528\u6237\u5b9e\u9645\u67e5\u8be2\u7684UPQA\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4ef7\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cPersonalization Editing\u5728\u7f16\u8f91\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u4f18\u4e8e\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u591a\u8f6e\u5bf9\u8bdd\u53ca\u9690\u5f0f\u504f\u597d\u63d0\u95ee\u60c5\u666f\u4e0b\u8868\u73b0\u8d85\u51fa\u57fa\u4e8e\u63d0\u793a\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Personalization Editing\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u4e2a\u4eba\u5316\u65b9\u6cd5\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7cbe\u51c6\u7684\u7528\u6237\u504f\u597d\u6a21\u578b\u66f4\u65b0\uff0cUPQA\u6570\u636e\u96c6\u5f25\u8865\u4e86\u4e2a\u4eba\u5316\u8bc4\u6d4b\u7684\u7a7a\u767d\uff0c\u4e3a\u4e2a\u6027\u5316\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u5de5\u5177\u548c\u65b9\u6cd5\u3002"}}
{"id": "2512.13685", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.13685", "abs": "https://arxiv.org/abs/2512.13685", "authors": ["Dylan Phelps", "Rodrigo Wilkens", "Edward Gow-Smith", "Lilian Hubner", "B\u00e1rbara Malcorra", "C\u00e9sar Renn\u00f3-Costa", "Marco Idiart", "Maria-Cruz Villa-Uriol", "Aline Villavicencio"], "title": "Beyond surface form: A pipeline for semantic analysis in Alzheimer's Disease detection from spontaneous speech", "comment": null, "summary": "Alzheimer's Disease (AD) is a progressive neurodegenerative condition that adversely affects cognitive abilities. Language-related changes can be automatically identified through the analysis of outputs from linguistic assessment tasks, such as picture description. Language models show promise as a basis for screening tools for AD, but their limited interpretability poses a challenge in distinguishing true linguistic markers of cognitive decline from surface-level textual patterns. To address this issue, we examine how surface form variation affects classification performance, with the goal of assessing the ability of language models to represent underlying semantic indicators. We introduce a novel approach where texts surface forms are transformed by altering syntax and vocabulary while preserving semantic content. The transformations significantly modify the structure and lexical content, as indicated by low BLEU and chrF scores, yet retain the underlying semantics, as reflected in high semantic similarity scores, isolating the effect of semantic information, and finding models perform similarly to if they were using the original text, with only small deviations in macro-F1. We also investigate whether language from picture descriptions retains enough detail to reconstruct the original image using generative models. We found that image-based transformations add substantial noise reducing classification accuracy. Our methodology provides a novel way of looking at what features influence model predictions, and allows the removal of possible spurious correlations. We find that just using semantic information, language model based classifiers can still detect AD. This work shows that difficult to detect semantic impairment can be identified, addressing an overlooked feature of linguistic deterioration, and opening new pathways for early detection systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u8bed\u8a00\u6a21\u578b\u5206\u7c7b\u4e2d\u7684\u8bed\u4e49\u548c\u8868\u5c42\u6587\u672c\u7279\u5f81\uff0c\u63d0\u51fa\u901a\u8fc7\u8bed\u6cd5\u548c\u8bcd\u6c47\u53d8\u6362\u4fdd\u6301\u8bed\u4e49\u4e0d\u53d8\uff0c\u68c0\u6d4b\u6a21\u578b\u5bf9\u771f\u5b9e\u8bed\u4e49\u6807\u5fd7\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u53d1\u73b0\u8bed\u4e49\u4fe1\u606f\u8db3\u4ee5\u652f\u6301AD\u68c0\u6d4b\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u8f85\u52a9AD\u7b5b\u67e5\uff0c\u4f46\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\uff0c\u96be\u4ee5\u533a\u5206\u8ba4\u77e5\u8870\u9000\u7684\u771f\u5b9e\u8bed\u8a00\u6807\u8bb0\u4e0e\u8868\u5c42\u6587\u672c\u6a21\u5f0f\u3002\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u6a21\u578b\u80fd\u5426\u6355\u6349\u5230\u5e95\u5c42\u8bed\u4e49\u6307\u6807\uff0c\u800c\u975e\u4ec5\u4f9d\u8d56\u8868\u5c42\u5f62\u5f0f\u3002", "method": "\u901a\u8fc7\u5bf9\u6587\u672c\u8fdb\u884c\u8bed\u6cd5\u53ca\u8bcd\u6c47\u53d8\u6362\uff0c\u4fdd\u6301\u8bed\u4e49\u4e0d\u53d8\uff0c\u6784\u5efa\u53d8\u6362\u540e\u6587\u672c\u6570\u636e\uff0c\u5229\u7528\u4f4eBLEU\u548cchrF\u8bc4\u5206\u9a8c\u8bc1\u7ed3\u6784\u53d8\u5316\uff0c\u540c\u65f6\u7528\u9ad8\u8bed\u4e49\u76f8\u4f3c\u5ea6\u786e\u8ba4\u8bed\u4e49\u4fdd\u7559\u3002\u6bd4\u5bf9\u539f\u6587\u4e0e\u53d8\u6362\u6587\u7684\u5206\u7c7b\u6027\u80fd\u5dee\u5f02\uff0c\u6d4b\u8bd5\u6a21\u578b\u5bf9\u8bed\u4e49\u4fe1\u606f\u7684\u5229\u7528\u3002\u5e76\u7528\u751f\u6210\u6a21\u578b\u68c0\u9a8c\u56fe\u7247\u63cf\u8ff0\u8bed\u8a00\u5bf9\u539f\u59cb\u56fe\u50cf\u7684\u8fd8\u539f\u80fd\u529b\u3002", "result": "\u53d8\u6362\u6587\u672c\u7ed3\u6784\u548c\u8bcd\u6c47\u540e\uff0c\u5206\u7c7b\u6027\u80fd\u4e0e\u4f7f\u7528\u539f\u59cb\u6587\u672c\u76f8\u8fd1\uff0c\u5b8f\u89c2F1\u4ec5\u6709\u5fae\u5c0f\u504f\u5dee\uff0c\u8868\u660e\u6a21\u578b\u4f9d\u8d56\u8bed\u4e49\u4fe1\u606f\u3002\u56fe\u50cf\u57fa\u53d8\u6362\u5f15\u5165\u566a\u58f0\uff0c\u5bfc\u81f4\u51c6\u786e\u7387\u4e0b\u964d\u3002\u8be5\u65b9\u6cd5\u6709\u6548\u5254\u9664\u865a\u5047\u76f8\u5173\u6027\uff0c\u5f3a\u8c03\u8bed\u4e49\u4fe1\u606f\u5bf9AD\u68c0\u6d4b\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\u57fa\u4e8e\u8bed\u4e49\u4fe1\u606f\u7684\u8bed\u8a00\u6a21\u578b\u5206\u7c7b\u5668\u80fd\u6709\u6548\u68c0\u6d4bAD\uff0c\u5b9e\u73b0\u4e86\u5bf9\u96be\u4ee5\u5bdf\u89c9\u7684\u8bed\u4e49\u969c\u788d\u7684\u8bc6\u522b\uff0c\u5f25\u8865\u4e86\u8bed\u8a00\u9000\u5316\u7814\u7a76\u4e2d\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u4e86\u65e9\u671fAD\u7b5b\u67e5\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
