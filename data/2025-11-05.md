<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.SE](#cs.SE) [Total: 13]
- [cs.MA](#cs.MA) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Multi-Personality Generation of LLMs at Decoding-time](https://arxiv.org/abs/2511.01891)
*Rongxin Chen,Yunfan Li,Yige Yuan,Bingbing Xu,Huawei Shen*

Main category: cs.CL

TL;DR: 提出了一种无需额外训练即可实现多重个性化生成的新方法，称为多重人格生成（MPG），通过解码时组合单维模型的隐式密度比，实现灵活且高效的多个性表达。采用基于块的猜测拒绝采样（SCR）技术显著减少计算成本，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有多重个性化生成方法要么训练成本高且扩展性差，要么依赖外部模型或启发式方法，灵活性和稳健性受限。

Method: 提出MPG框架，通过解码时利用单维模型的隐式密度比重构多维个性策略，无需额外训练；设计了基于块的猜测拒绝采样（SCR）算法，加快响应生成并保证质量。

Result: 在MBTI个性和角色扮演任务中，MPG方法表现优异，性能提升16%-18%。

Conclusion: MPG框架提供了一种灵活、高效且无需重新训练的多重个性生成方案，有效提升大模型个性化生成的质量和计算效率。

Abstract: Multi-personality generation for LLMs, enabling simultaneous embodiment of
multiple personalization attributes, is a fundamental challenge. Existing
retraining-based approaches are costly and poorly scalable, while decoding-time
methods often rely on external models or heuristics, limiting flexibility and
robustness. In this paper, we propose a novel Multi-Personality Generation
(MPG) framework under the decoding-time combination paradigm. It flexibly
controls multi-personality without relying on scarce multi-dimensional models
or extra training, leveraging implicit density ratios in single-dimensional
models as a "free lunch" to reformulate the task as sampling from a target
strategy aggregating these ratios. To implement MPG efficiently, we design
Speculative Chunk-level based Rejection sampling (SCR), which generates
responses in chunks and parallelly validates them via estimated thresholds
within a sliding window. This significantly reduces computational overhead
while maintaining high-quality generation. Experiments on MBTI personality and
Role-Playing demonstrate the effectiveness of MPG, showing improvements up to
16%-18%. Code and data are available at https://github.com/Libra117/MPG .

</details>


### [2] [Rethinking LLM Human Simulation: When a Graph is What You Need](https://arxiv.org/abs/2511.02135)
*Joseph Suh,Suhong Moon,Serina Chang*

Main category: cs.CL

TL;DR: 本文提出了一种基于图神经网络的模拟方法GEMS，用于替代大型语言模型在人类决策模拟中的应用，具有更高效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在模拟人类决策中表现良好，但体积庞大，计算资源消耗巨大，寻求更小且效率更高的模型是必要的。

Method: 将离散选择问题转化为图的链接预测问题，利用图神经网络结合关系知识进行模拟，仅在必要时引入语言表示。

Result: 在三个模拟数据集的三个关键任务上，GEMS在准确率上达到或超过大型语言模型，同时具有更高的效率、可解释性和透明度。

Conclusion: 基于图的模型是一种轻量级且有效的替代方案，在人类模拟任务中能够替代大型语言模型，具有广阔应用前景。

Abstract: Large language models (LLMs) are increasingly used to simulate humans, with
applications ranging from survey prediction to decision-making. However, are
LLMs strictly necessary, or can smaller, domain-grounded models suffice? We
identify a large class of simulation problems in which individuals make choices
among discrete options, where a graph neural network (GNN) can match or surpass
strong LLM baselines despite being three orders of magnitude smaller. We
introduce Graph-basEd Models for human Simulation (GEMS), which casts discrete
choice simulation tasks as a link prediction problem on graphs, leveraging
relational knowledge while incorporating language representations only when
needed. Evaluations across three key settings on three simulation datasets show
that GEMS achieves comparable or better accuracy than LLMs, with far greater
efficiency, interpretability, and transparency, highlighting the promise of
graph-based modeling as a lightweight alternative to LLMs for human simulation.
Our code is available at https://github.com/schang-lab/gems.

</details>


### [3] [IG-Pruning: Input-Guided Block Pruning for Large Language Models](https://arxiv.org/abs/2511.02213)
*Kangyu Qiao,Shaolei Zhang,Yang Feng*

Main category: cs.CL

TL;DR: 本文提出了一种名为IG-Pruning的新型输入感知块级裁剪方法，通过动态选择层掩码，实现了大语言模型的高效推理。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型计算需求的增长，传统固定块掩码的深度剪枝方法在不同任务和输入中表现不佳，亟需一种动态自适应的解決方案。

Method: IG-Pruning包含两个阶段：首先通过语义聚类和L0优化发现多样化的掩码候选；然后在推理时动态选择并应用掩码，无需大量训练，实现高效动态剪枝。

Result: 实验结果显示，IG-Pruning在多个任务上均优于最新的静态深度剪枝方法，表现出更好的性能和效率。

Conclusion: 动态输入感知块级裁剪方法IG-Pruning为有限资源环境下的大语言模型部署提供了更加高效和灵活的解决方案。

Abstract: With the growing computational demands of large language models (LLMs),
efficient inference has become increasingly critical for practical deployment.
Depth pruning has emerged as a promising approach for reducing the
computational costs of large language models by removing transformer layers.
However, existing methods typically rely on fixed block masks, which can lead
to suboptimal performance across different tasks and inputs. In this paper, we
propose IG-Pruning, a novel input-aware block-wise pruning method that
dynamically selects layer masks at inference time. Our approach consists of two
stages: (1) Discovering diverse mask candidates through semantic clustering and
L0 optimization, and (2) Implementing efficient dynamic pruning without the
need for extensive training. Experimental results demonstrate that our method
consistently outperforms state-of-the-art static depth pruning methods, making
it particularly suitable for resource-constrained deployment scenarios.

</details>


### [4] [Demo: Statistically Significant Results On Biases and Errors of LLMs Do Not Guarantee Generalizable Results](https://arxiv.org/abs/2511.02246)
*Jonathan Liu,Haoling Qiu,Jonathan Lasko,Damianos Karakos,Mahsa Yarmohammadi,Mark Dredze*

Main category: cs.CL

TL;DR: 本文开发了一套自动生成医疗咨询问题并利用多模型评估回答的基础设施，旨在检测医疗聊天机器人在涉及人口统计信息等非医疗因素时的表现问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在医疗应用中存在幻觉、遗漏和偏见，特别是在含人口统计信息的复杂情境下，必须保证医疗聊天机器人提供一致且可靠的建议。

Method: 通过自动生成涵盖患者人口统计、病史、疾病和写作风格的真实问题，利用多个LLM作为评判者的方法检测幻觉和遗漏，并比较不同LLM组合的评估表现。

Result: 发现LLM评估者之间的一致性低（Cohen's Kappa只有0.118），且只有特定的回答和评估LLM对性别、种族等不同写作风格表现出显著差异。

Conclusion: 建议医疗领域评估应使用多个LLM评估者以避免非通用性结果，并公开评估者之间的一致性指标以提高透明度。代码和数据集已开源。

Abstract: Recent research has shown that hallucinations, omissions, and biases are
prevalent in everyday use-cases of LLMs. However, chatbots used in medical
contexts must provide consistent advice in situations where non-medical factors
are involved, such as when demographic information is present. In order to
understand the conditions under which medical chatbots fail to perform as
expected, we develop an infrastructure that 1) automatically generates queries
to probe LLMs and 2) evaluates answers to these queries using multiple
LLM-as-a-judge setups and prompts. For 1), our prompt creation pipeline samples
the space of patient demographics, histories, disorders, and writing styles to
create realistic questions that we subsequently use to prompt LLMs. In 2), our
evaluation pipeline provides hallucination and omission detection using
LLM-as-a-judge as well as agentic workflows, in addition to LLM-as-a-judge
treatment category detectors. As a baseline study, we perform two case studies
on inter-LLM agreement and the impact of varying the answering and evaluation
LLMs. We find that LLM annotators exhibit low agreement scores (average Cohen's
Kappa $\kappa=0.118$), and only specific (answering, evaluation) LLM pairs
yield statistically significant differences across writing styles, genders, and
races. We recommend that studies using LLM evaluation use multiple LLMs as
evaluators in order to avoid arriving at statistically significant but
non-generalizable results, particularly in the absence of ground-truth data. We
also suggest publishing inter-LLM agreement metrics for transparency. Our code
and dataset are available here:
https://github.com/BBN-E/medic-neurips-2025-demo.

</details>


### [5] [LTD-Bench: Evaluating Large Language Models by Letting Them Draw](https://arxiv.org/abs/2511.02347)
*Liuhao Lin,Ke Li,Zihan Xu,Yuchen Shi,Yulei Qin,Yan Zhang,Xing Sun,Rongrong Ji*

Main category: cs.CL

TL;DR: 本文提出了LTD-Bench基准测试，旨在通过可视化输出评估大型语言模型的空间推理能力，揭示其在语言与空间概念映射方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型评估依赖不透明的数值指标，难以直观反映模型在空间推理和物理世界理解上的能力，存在实际应用风险。

Method: LTD-Bench要求模型通过点阵图或可执行代码生成图像，包含生成任务（测试空间想象力）和识别任务（评估空间感知），难度分三级，全面评估语言与空间的双向映射能力。

Result: 实验显示即使在传统评测表现优异的模型，也存在语言与空间概念映射的严重缺陷。LTD-Bench的可视化结果便于诊断分析和模型相似性研究。

Conclusion: LTD-Bench弥补了传统评价方法的不足，能够直观揭示和诊断大型语言模型在空间推理方面的根本限制，推动其向真实世界模型发展的潜力。

Abstract: Current evaluation paradigms for large language models (LLMs) represent a
critical blind spot in AI research--relying on opaque numerical metrics that
conceal fundamental limitations in spatial reasoning while providing no
intuitive understanding of model capabilities. This deficiency creates a
dangerous disconnect between reported performance and practical abilities,
particularly for applications requiring physical world understanding. We
introduce LTD-Bench, a breakthrough benchmark that transforms LLM evaluation
from abstract scores to directly observable visual outputs by requiring models
to generate drawings through dot matrices or executable code. This approach
makes spatial reasoning limitations immediately apparent even to non-experts,
bridging the fundamental gap between statistical performance and intuitive
assessment. LTD-Bench implements a comprehensive methodology with complementary
generation tasks (testing spatial imagination) and recognition tasks (assessing
spatial perception) across three progressively challenging difficulty levels,
methodically evaluating both directions of the critical language-spatial
mapping. Our extensive experiments with state-of-the-art models expose an
alarming capability gap: even LLMs achieving impressive results on traditional
benchmarks demonstrate profound deficiencies in establishing bidirectional
mappings between language and spatial concept--a fundamental limitation that
undermines their potential as genuine world models. Furthermore, LTD-Bench's
visual outputs enable powerful diagnostic analysis, offering a potential
approach to investigate model similarity.

</details>


### [6] [Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation](https://arxiv.org/abs/2511.02358)
*Wongyu Kim,Hochang Lee,Sanghak Lee,Yoonsung Kim,Jaehyun Park*

Main category: cs.CL

TL;DR: 本文提出了M-Solomon，一种多模态通用嵌入器，通过自适应地判断何时进行查询扩增，从而提升查询效率和性能。


<details>
  <summary>Details</summary>
Motivation: 针对近年来基于大型语言模型的查询扩增方法存在的高延迟和部分查询扩增反而降低性能的问题，同时此前方法未涉及多模态环境。

Method: 将训练数据集中的查询分为需要扩增和不需要扩增两类，利用多模态大型语言模型为需要扩增的查询生成合适的扩增内容，并通过学习生成特定前缀（/augment或/embed）实现自适应查询扩增。

Result: 实验表明，M-Solomon在提升性能的同时，相比始终进行扩增的模型大幅降低了嵌入延迟，且性能优于无扩增的基线。

Conclusion: M-Solomon有效解决了查询扩增的效率与性能折中问题，成功应用于多模态环境，实现了快速且准确的查询嵌入。

Abstract: Query augmentation makes queries more meaningful by appending further
information to the queries to find relevant documents. Current studies have
proposed Large Language Model (LLM)-based embedders, which learn representation
for embedding and generation for query augmentation in a multi-task manner by
leveraging the generative capabilities of LLM. During inference, these jointly
trained embedders have conducted query augmentation followed by embedding,
showing effective results. However, augmenting every query leads to substantial
embedding latency and query augmentation can be detrimental to performance for
some queries. Also, previous methods have not been explored in multimodal
environments. To tackle these problems, we propose M-Solomon, a universal
multimodal embedder that can adaptively determine when to augment queries. Our
approach first divides the queries of the training datasets into two groups at
the dataset level. One includes queries that require augmentation and the other
includes queries that do not. Then, we introduces a synthesis process that
generates appropriate augmentations for queries that require them by leveraging
a powerful Multimodal LLM (MLLM). Next, we present adaptive query augmentation.
Through this step, M-Solomon can conduct query augmentation only when necessary
by learning to generate synthetic augmentations with the prefix /augment for
queries that demand them and to generate the simple string /embed for others.
Experimental results showed that M-Solomon not only surpassed the baseline
without augmentation by a large margin but also outperformed the baseline that
always used augmentation, providing much faster embedding latency.

</details>


### [7] [LiveSecBench: A Dynamic and Culturally-Relevant AI Safety Benchmark for LLMs in Chinese Context](https://arxiv.org/abs/2511.02366)
*Yudong Li,Zhongliang Yang,Kejiang Chen,Wenxuan Wang,Tianxin Zhang,Sifang Wan,Kecheng Wang,Haitian Li,Xu Wang,Lefan Cheng,Youdan Yang,Baocheng Chen,Ziyu Liu,Yufei Sun,Liyan Wu,Wenya Wen,Xingchi Gu,Peiru Yang*

Main category: cs.CL

TL;DR: 本文提出了LiveSecBench，一个专为中文大型语言模型设计的动态安全评测基准，涵盖法律、伦理、事实性、隐私、对抗鲁棒性和推理安全六大维度。


<details>
  <summary>Details</summary>
Motivation: 当前中文语言模型安全评估缺乏系统性基准，且安全威胁不断变化，需动态更新的评测工具。

Method: 建立基于中国法律和社会框架的六个关键安全维度评测体系，并设计动态更新机制以引入新威胁如图像生成安全和代理安全。

Result: LiveSecBench（v251030）已评测18个大型语言模型，展示了中文语境下AI安全的整体状况，并公开排行榜。

Conclusion: LiveSecBench为中文LLM安全评估提供了系统、动态、持续更新的基准工具，推动相关领域研究和应用的发展。

Abstract: In this work, we propose LiveSecBench, a dynamic and continuously updated
safety benchmark specifically for Chinese-language LLM application scenarios.
LiveSecBench evaluates models across six critical dimensions (Legality, Ethics,
Factuality, Privacy, Adversarial Robustness, and Reasoning Safety) rooted in
the Chinese legal and social frameworks. This benchmark maintains relevance
through a dynamic update schedule that incorporates new threat vectors, such as
the planned inclusion of Text-to-Image Generation Safety and Agentic Safety in
the next update. For now, LiveSecBench (v251030) has evaluated 18 LLMs,
providing a landscape of AI safety in the context of Chinese language. The
leaderboard is publicly accessible at https://livesecbench.intokentech.cn/.

</details>


### [8] [AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda](https://arxiv.org/abs/2511.02374)
*Mohd Nauman,Sravan Gvm,Vijay Devane,Shyam Pawar,Viraj Thakur,Kundeshwar Pundalik,Piyush Sawarkar,Rohit Saluja,Maunendra Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: 该文提出了针对传统医学阿育吠陀领域专门设计的双语大语言模型AyurParam-2.9B，利用高质量中文献和临床数据微调，显著提升了模型在专业医学知识上的表现。


<details>
  <summary>Details</summary>
Motivation: 大多数大语言模型在面对需要深厚文化、语言及专业知识的特定领域表现不佳，尤其是传统医学领域如阿育吠陀，现有模型无法准确理解或应用其丰富知识。

Method: 作者基于Param-1-2.9B模型，通过一个严格筛选和注释的阿育吠陀双语数据集进行微调，数据涵盖经典文本及临床指导，并设计了上下文感知、推理和客观问答任务。

Result: AyurParam-2.9B在BhashaBench-Ayur基准测试中，超越了所有相同规模（1.5-3B参数）的开源微调模型，且表现可与更大模型媲美甚至优于。

Conclusion: 研究显示，针对特定领域的真实适应和高质量监督是实现专业医学知识可信且符合文化背景的AI应用的关键。

Abstract: Current large language models excel at broad, general-purpose tasks, but
consistently underperform when exposed to highly specialized domains that
require deep cultural, linguistic, and subject-matter expertise. In particular,
traditional medical systems such as Ayurveda embody centuries of nuanced
textual and clinical knowledge that mainstream LLMs fail to accurately
interpret or apply. We introduce AyurParam-2.9B, a domain-specialized,
bilingual language model fine-tuned from Param-1-2.9B using an extensive,
expertly curated Ayurveda dataset spanning classical texts and clinical
guidance. AyurParam's dataset incorporates context-aware, reasoning, and
objective-style Q&A in both English and Hindi, with rigorous annotation
protocols for factual precision and instructional clarity. Benchmarked on
BhashaBench-Ayur, AyurParam not only surpasses all open-source
instruction-tuned models in its size class (1.5--3B parameters), but also
demonstrates competitive or superior performance compared to much larger
models. The results from AyurParam highlight the necessity for authentic domain
adaptation and high-quality supervision in delivering reliable, culturally
congruent AI for specialized medical knowledge.

</details>


### [9] [AutoAdv: Automated Adversarial Prompting for Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2511.02376)
*Aashray Reddy,Andrew Zagula,Nicholas Saban*

Main category: cs.CL

TL;DR: 提出AutoAdv框架，通过多轮对话自动化绕过大型语言模型的安全检测，攻击成功率显著提高。


<details>
  <summary>Details</summary>
Motivation: 现有评估大多聚焦单轮对话，而真实攻击通常是多轮适应性对话，现有模型防御机制在多轮攻击下存在漏洞。

Method: AutoAdv结合了模式管理器、温度管理器和两阶段重写策略，实现无训练自动化多轮攻击。

Result: 在多个模型上多轮攻击成功率明显优于单轮，最高达95%，揭示了当前安全机制的不足。

Conclusion: 现行安全策略未能有效应对多轮对话，需要紧急开发适应多轮攻击的防御措施。

Abstract: Large Language Models (LLMs) remain vulnerable to jailbreaking attacks where
adversarial prompts elicit harmful outputs, yet most evaluations focus on
single-turn interactions while real-world attacks unfold through adaptive
multi-turn conversations. We present AutoAdv, a training-free framework for
automated multi-turn jailbreaking that achieves up to 95% attack success rate
on Llama-3.1-8B within six turns a 24 percent improvement over single turn
baselines. AutoAdv uniquely combines three adaptive mechanisms: a pattern
manager that learns from successful attacks to enhance future prompts, a
temperature manager that dynamically adjusts sampling parameters based on
failure modes, and a two-phase rewriting strategy that disguises harmful
requests then iteratively refines them. Extensive evaluation across commercial
and open-source models (GPT-4o-mini, Qwen3-235B, Mistral-7B) reveals persistent
vulnerabilities in current safety mechanisms, with multi-turn attacks
consistently outperforming single-turn approaches. These findings demonstrate
that alignment strategies optimized for single-turn interactions fail to
maintain robustness across extended conversations, highlighting an urgent need
for multi-turn-aware defenses.

</details>


### [10] [Merging Continual Pretraining Models for Domain-Specialized LLMs: A Case Study in Finance](https://arxiv.org/abs/2511.02451)
*Kentaro Ueda,François Portet,Hirohiko Suwa,Keiichi Yasumoto*

Main category: cs.CL

TL;DR: 本文研究了金融领域大语言模型（LLMs）中领域专家模型的合并方法，提出了三阶段评估框架，并在综合金融任务基准上验证了几种合并方法的效果。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在专业领域如金融中表现欠佳，传统多技能训练成本高且不稳定，亟需探索领域专家模型的高效合并方法以提升模型综合能力。

Method: 构建了包含金融、数学和日语专家的金融领域LLMs，提出知识恢复、互补性和新兴能力三阶段评估体系，比较任务算术（Task Arithmetic）、TIES和DARE-TIES三种模型合并方法。

Result: 专家模型与基础模型合并能恢复CPT中丢失的知识，专家模型间合并提升性能且激发跨领域新能力。Task Arithmetic表现强劲但对超参敏感，TIES更鲁棒。模型相似度与合并效果相关，但新兴技能依赖更复杂因素。

Conclusion: 本文首次系统分析了持续预训练（CPT）模型合并，建立了原则性框架，为基于现有专家模型构建多技能大语言模型提供了明确指导。

Abstract: While LLMs excel at general tasks, they struggle in specialized domains like
finance, requiring diverse skills in domain knowledge, mathematical reasoning,
and multilingual processing. Merging domain-specific Continual Pre-training
(CPT) "experts" offers a practical alternative to costly and unstable
multi-skill training. However, unlike established Supervised Fine-Tuning (SFT)
model-based merging, CPT model merging remains largely unexplored. We address
this gap by creating financial LLMs from experts in finance, math, and
Japanese. We propose a three-stage evaluation focusing on knowledge recovery,
complementarity, and emergence, and assess three merging methods (Task
Arithmetic, TIES, and DARE-TIES) on a comprehensive financial benchmark curated
from 18 tasks across 8 established datasets. Results show that merging an
expert with its base model recovers general knowledge lost during CPT, while
merging experts improves performance and can yield emergent cross-domain
skills. Among the methods, Task Arithmetic performs strongly but is
hyperparameter-sensitive, whereas TIES is more robust. Our findings also
suggest that while model similarity correlates with merging success, emergent
skills depend on more complex factors. This work presents the first
foundational analysis of CPT model merging, establishing a principled framework
and providing clear guidance for building multi-skill LLMs from existing
assets.

</details>


### [11] [Prompting for Policy: Forecasting Macroeconomic Scenarios with Synthetic LLM Personas](https://arxiv.org/abs/2511.02458)
*Giulia Iadisernia,Carolina Camassa*

Main category: cs.CL

TL;DR: 本文评估了基于角色提示是否提升大语言模型在宏观经济预测任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 探究角色提示对提升GPT-4o宏观经济预测准确性的影响，并验证其与专业人类预测员的差异。

Method: 利用2368个经济学相关角色提示，驱动GPT-4o模拟欧洲央行专业预测员调查，涵盖50个季度的4个经济指标和多个预测期限，对比无角色提示的基线预测和人类专家预测。

Result: GPT-4o与人类预测员精度相近，在2024-2025年样本外仍保持较强预测性能；角色提示对预测准确性无显著提升作用。

Conclusion: GPT-4o可以在提供相关背景数据的情况下，实现与人类专家相当的宏观经济预测效果，且角色提示对预测质量影响有限，删除角色提示可降低计算成本。

Abstract: We evaluate whether persona-based prompting improves Large Language Model
(LLM) performance on macroeconomic forecasting tasks. Using 2,368
economics-related personas from the PersonaHub corpus, we prompt GPT-4o to
replicate the ECB Survey of Professional Forecasters across 50 quarterly rounds
(2013-2025). We compare the persona-prompted forecasts against the human
experts panel, across four target variables (HICP, core HICP, GDP growth,
unemployment) and four forecast horizons. We also compare the results against
100 baseline forecasts without persona descriptions to isolate its effect. We
report two main findings. Firstly, GPT-4o and human forecasters achieve
remarkably similar accuracy levels, with differences that are statistically
significant yet practically modest. Our out-of-sample evaluation on 2024-2025
data demonstrates that GPT-4o can maintain competitive forecasting performance
on unseen events, though with notable differences compared to the in-sample
period. Secondly, our ablation experiment reveals no measurable forecasting
advantage from persona descriptions, suggesting these prompt components can be
omitted to reduce computational costs without sacrificing accuracy. Our results
provide evidence that GPT-4o can achieve competitive forecasting accuracy even
on out-of-sample macroeconomic events, if provided with relevant context data,
while revealing that diverse prompts produce remarkably homogeneous forecasts
compared to human panels.

</details>


### [12] [Smart-Hiring: An Explainable end-to-end Pipeline for CV Information Extraction and Job Matching](https://arxiv.org/abs/2511.02537)
*Kenza Khelkhal,Dihia Lanasri*

Main category: cs.CL

TL;DR: 本文提出了Smart-Hiring，一种自动从简历中提取结构化信息并匹配职位的NLP系统。


<details>
  <summary>Details</summary>
Motivation: 招聘过程中简历筛选耗时费力且容易出错，且存在人为偏见。

Method: 结合文档解析、命名实体识别和语义嵌入技术，将简历和职位描述编码到共享向量空间进行匹配，系统模块化且可解释。

Result: 在多个职业领域的真实数据集上，系统表现出稳健性和竞争性的匹配准确率，同时保持高度可解释性和透明性。

Conclusion: 提出了一个可扩展且实用的招聘NLP框架，为偏见缓解、公平建模和大规模部署提供了有前景的方向。

Abstract: Hiring processes often involve the manual screening of hundreds of resumes
for each job, a task that is time and effort consuming, error-prone, and
subject to human bias. This paper presents Smart-Hiring, an end-to-end Natural
Language Processing (NLP) pipeline de- signed to automatically extract
structured information from unstructured resumes and to semantically match
candidates with job descriptions. The proposed system combines document
parsing, named-entity recognition, and contextual text embedding techniques to
capture skills, experience, and qualifications. Using advanced NLP technics,
Smart-Hiring encodes both resumes and job descriptions in a shared vector space
to compute similarity scores between candidates and job postings. The pipeline
is modular and explainable, allowing users to inspect extracted entities and
matching rationales. Experiments were conducted on a real-world dataset of
resumes and job descriptions spanning multiple professional domains,
demonstrating the robustness and feasibility of the proposed approach. The
system achieves competitive matching accuracy while preserving a high degree of
interpretability and transparency in its decision process. This work introduces
a scalable and practical NLP frame- work for recruitment analytics and outlines
promising directions for bias mitigation, fairness-aware modeling, and
large-scale deployment of data-driven hiring solutions.

</details>


### [13] [The Analysis of Lexical Errors in Machine Translation from English into Romanian](https://arxiv.org/abs/2511.02587)
*Angela Stamatie*

Main category: cs.CL

TL;DR: 本文通过分析230篇由谷歌翻译从英语到罗马尼亚语的文本，研究了机器翻译中的词汇错误，重点关注了与新冠疫情相关的官方信息文本。


<details>
  <summary>Details</summary>
Motivation: 旨在提升谷歌翻译的词汇选择准确性，减少词汇错误，从而提高机器翻译整体质量。

Method: 对来自世界卫生组织、Gavi组织及患者用药说明书等官方文本进行机器翻译输出的错误分析，特别聚焦词汇错误。

Result: 发现了翻译过程中存在的词汇错误，提供了具体实例，对改进谷歌翻译的词汇准确性具有指导意义。

Conclusion: 通过词汇错误的系统分析，本文为提升机器翻译的质量提供了理论支持，有助于未来改进谷歌翻译系统。

Abstract: The research explores error analysis in the performance of translating by
Machine Translation from English into Romanian, and it focuses on lexical
errors found in texts which include official information, provided by the World
Health Organization (WHO), the Gavi Organization, by the patient information
leaflet (the information about the active ingredients of the vaccines or the
medication, the indications, the dosage instructions, the storage instructions,
the side effects and warning, etc.). All of these texts are related to Covid-19
and have been translated by Google Translate, a multilingual Machine
Translation that was created by Google. In the last decades, Google has
actively worked to develop a more accurate and fluent automatic translation
system. This research, specifically focused on improving Google Translate, aims
to enhance the overall quality of Machine Translation by achieving better
lexical selection and by reducing errors. The investigation involves a
comprehensive analysis of 230 texts that have been translated from English into
Romanian.

</details>


### [14] [Next Token Knowledge Tracing: Exploiting Pretrained LLM Representations to Decode Student Behaviour](https://arxiv.org/abs/2511.02599)
*Max Norris,Kobi Gal,Sahan Bulathwela*

Main category: cs.CL

TL;DR: 本文提出了一种基于预训练大型语言模型的大规模知识追踪方法，通过将知识追踪任务重构为下一个词预测任务，显著提升了预测学生答题表现的准确度。


<details>
  <summary>Details</summary>
Motivation: 以往知识追踪模型主要依赖答题正确率和技能标签等元数据，忽视了问题文本这一重要的教学信息，限制了模型的预测性能。

Method: 提出Next Token Knowledge Tracing（NTKT）方法，将学生答题历史和问题内容均表示为文本序列，利用预训练的大型语言模型进行下一个词的预测，捕捉行为和语言的复杂模式。

Result: 实验显示，NTKT在预测准确率上显著优于现有最先进的神经知识追踪模型，并且对冷启动问题和新用户的泛化能力更强。

Conclusion: 强调问题文本内容在知识追踪中的重要性，证明了利用预训练大型语言模型的表达能力能够更有效地刻画学生学习过程。

Abstract: Modelling student knowledge is a key challenge when leveraging AI in
education, with major implications for personalised learning. The Knowledge
Tracing (KT) task aims to predict how students will respond to educational
questions in learning environments, based on their prior interactions. Existing
KT models typically use response correctness along with metadata like skill
tags and timestamps, often overlooking the question text, which is an important
source of pedagogical insight. This omission poses a lost opportunity while
limiting predictive performance. We propose Next Token Knowledge Tracing
(NTKT), a novel approach that reframes KT as a next-token prediction task using
pretrained Large Language Models (LLMs). NTKT represents both student histories
and question content as sequences of text, allowing LLMs to learn patterns in
both behaviour and language. Our series of experiments significantly improves
performance over state-of-the-art neural KT models and generalises much better
to cold-start questions and users. These findings highlight the importance of
question content in KT and demonstrate the benefits of leveraging pretrained
representations of LLMs to model student learning more effectively.

</details>


### [15] [CGES: Confidence-Guided Early Stopping for Efficient and Accurate Self-Consistency](https://arxiv.org/abs/2511.02603)
*Ehsan Aghazadeh,Ahmad Ghasemi,Hedyeh Beyhaghi,Hossein Pishro-Nik*

Main category: cs.CL

TL;DR: 本文提出了一种基于置信度的自适应采样停止方法CGES，用于提升大语言模型推理效率和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的自一致性策略需要固定次数调用模型推理，效率低且在正确答案罕见时表现欠佳。

Method: CGES利用贝叶斯框架，根据从token概率或奖励模型获得的置信度信号动态形成答案的后验分布，一旦某个答案的后验概率超过阈值即停止采样。

Result: 在五个推理基准上，CGES将模型调用次数减少约69%，同时准确率与自一致性策略相差不足0.06个百分点。

Conclusion: CGES有效提升了大语言模型的推理效率，且保持了与自一致性方法相当的准确率，具备理论保证和现实适用性。

Abstract: Large language models (LLMs) are often queried multiple times at test time,
with predictions aggregated by majority vote. While effective, this
self-consistency strategy (arXiv:2203.11171) requires a fixed number of calls
and can fail when the correct answer is rare. We introduce Confidence-Guided
Early Stopping (CGES), a Bayesian framework that forms posteriors over
candidate answers using scalar confidence signals derived from token
probabilities or reward models. CGES adaptively halts sampling once the
posterior mass of a candidate exceeds a threshold. We provide theoretical
guarantees for both perfectly calibrated confidences and realistic noisy
confidence signals. Across five reasoning benchmarks, CGES reduces the average
number of model calls by about 69 percent (for example, from 16.0 to 4.9) while
matching the accuracy of self-consistency within 0.06 percentage points.

</details>


### [16] [The Realignment Problem: When Right becomes Wrong in LLMs](https://arxiv.org/abs/2511.02623)
*Aakash Sen Sharma,Debdeep Sanyal,Vivek Srivastava,Shirish Karande,Murari Mandal*

Main category: cs.CL

TL;DR: 本文提出了TRACE框架，解决大型语言模型(LLMs)与人类价值观对齐中的动态调整困难，通过程序化策略应用实现高效、精准的重新对齐。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs对齐实践产生的模型静态且难以维护，无法适应不断变化的社会规范和政策，导致了所谓的对齐现实差距问题。

Method: TRACE框架通过程序化地对现有偏好数据与新政策进行分流，识别高冲突点并利用混合优化技术有针对性地调整偏好数据，同时保障模型性能不受影响。

Result: TRACE在多个模型（Qwen2.5-7B、Gemma-2-9B、Llama-3.1-8B）以及复杂政策变更的数据集（如PKU-SafeRLHF）上均实现了稳健的重新对齐，且不会削弱模型的通用能力。

Conclusion: 该方法奠定了LLMs对齐的可扩展、动态且成本效益高的新范式，为可持续且负责任的AI部署提供了基础。

Abstract: The alignment of Large Language Models (LLMs) with human values is central to
their safe deployment, yet current practice produces static, brittle, and
costly-to-maintain models that fail to keep pace with evolving norms and
policies. This misalignment, which we term the Alignment-Reality Gap, poses a
growing challenge for reliable long-term use. Existing remedies are inadequate:
large-scale re-annotation is economically prohibitive, and standard unlearning
methods act as blunt instruments that erode utility rather than enable precise
policy updates. We introduce TRACE (Triage and Re-align by Alignment Conflict
Evaluation), a framework for principled unlearning that reconceives
re-alignment as a programmatic policy application problem. TRACE
programmatically triages existing preference data against a new policy,
identifies high-impact conflicts via a alignment impact score, and applies a
hybrid optimization that cleanly inverts, discards, or preserves preferences
while safeguarding model performance. Empirical results show that TRACE
achieves robust re-alignment across diverse model families (Qwen2.5-7B,
Gemma-2-9B, Llama-3.1-8B). On both synthetic benchmarks and the PKU-SafeRLHF
dataset under complex policy shift, TRACE enforces new principles without
degrading general capabilities. Our work establishes a scalable, dynamic, and
cost-effective paradigm for maintaining LLM alignment, providing a foundation
for sustainable and responsible AI deployment.

</details>


### [17] [Understanding New-Knowledge-Induced Factual Hallucinations in LLMs: Analysis, Solution, and Interpretation](https://arxiv.org/abs/2511.02626)
*Renfei Dang,Peng Hu,Changjiang Gao,Shujian Huang*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在微调引入新知识时产生事实幻觉的现象及其机制，设计数据集进行细粒度分析，并提出KnownPatch方法缓解幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 先前研究发现引入新知识会导致模型在已知信息上产生错误输出，但对幻觉具体表现及机理研究不足。

Method: 设计Biography-Reasoning数据集，分析多种知识类型和任务类型下的幻觉表现，提出KnownPatch方法在训练后期补充部分已知知识样本，缓解幻觉。

Result: 发现特定知识类型完全为新知识时幻觉显著增加，注意力集中于上下文而非关键实体，导致幻觉传播；KnownPatch能有效恢复注意力集中，减少幻觉并提升性能。

Conclusion: 新知识的高陌生度是幻觉的主要驱动因素，通过补充已知知识样本可缓解这种现象，提升模型的事实准确性。

Abstract: Previous studies show that introducing new knowledge during large language
models (LLMs) fine-tuning can lead to the generation of erroneous output when
tested on known information, thereby triggering factual hallucinations.
However, existing studies have not deeply investigated the specific
manifestations and underlying mechanisms of these hallucinations. Our work
addresses this gap by designing a controlled dataset Biography-Reasoning, and
conducting a fine-grained analysis across multiple knowledge types and two task
types, including knowledge question answering (QA) and knowledge reasoning
tasks. We find that when fine-tuned on a dataset in which a specific knowledge
type consists entirely of new knowledge, LLMs exhibit significantly increased
hallucination tendencies. This suggests that the high unfamiliarity of a
particular knowledge type, rather than the overall proportion of new knowledge,
is a stronger driver of hallucinations, and these tendencies can even affect
other knowledge types in QA tasks. To mitigate such factual hallucinations, we
propose KnownPatch, which patches a small number of known knowledge samples in
the later stages of training, effectively alleviating new-knowledge-induced
hallucinations. Through attention analysis, we find that learning new knowledge
reduces the model's attention to key entities in the question, thus causing
excessive focus on the surrounding context, which may increase the risk of
hallucination. Moreover, the attention pattern can propagate to similar
contexts, facilitating the spread of hallucinations to textually similar
questions. Our method effectively mitigates the disruption of new knowledge
learning to the model's attention on key entities, accompanied by improved
performance.

</details>


### [18] [Optimal Singular Damage: Efficient LLM Inference in Low Storage Regimes](https://arxiv.org/abs/2511.02681)
*Mohammadsajad Alipour,Mohammad Mohammadi Amiri*

Main category: cs.CL

TL;DR: 本文提出了一种针对大语言模型微调参数更新的高效存储方法，通过结合低秩近似与稀疏化策略，优化参数存储，提升存储效率与模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型微调后参数存储需求巨大，传统存储方式成本高且难以满足多任务需求，亟需高效的存储方案。

Method: 利用微调更新的低秩与稀疏特性，提出“optimal singular damage”方法，通过选择性稀疏低秩近似更新，保留关键奇异向量，提高存储效率和模型表现。

Result: 在相同存储预算下，稀疏低秩近似方法优于单独使用低秩近似或稀疏化，实验验证了该方法在存储效率和准确率方面的显著优势。

Conclusion: 结合稀疏和低秩特征的优化存储技术能有效压缩微调参数，提升大语言模型的存储利用率和应用潜力。

Abstract: Large language models (LLMs) are increasingly prevalent across diverse
applications. However, their enormous size limits storage and processing
capabilities to a few well-resourced stakeholders. As a result, most
applications rely on pre-trained LLMs, fine-tuned for specific tasks. However,
even storing the fine-tuned versions of these models remains a significant
challenge due to the wide range of tasks they address. Recently, studies show
that fine-tuning these models primarily affects a small fraction of parameters,
highlighting the need for more efficient storage of fine-tuned models. This
paper focuses on efficient storage of parameter updates in pre-trained models
after fine-tuning. To address this challenge, we leverage the observation that
fine-tuning updates are both low-rank and sparse, which can be utilized for
storage efficiency. However, using only low-rank approximation or
sparsification may discard critical singular components that enhance model
expressivity. We first observe that given the same memory budget, sparsified
low-rank approximations with larger ranks outperform standard low-rank
approximations with smaller ranks. Building on this, we propose our method,
optimal singular damage, that selectively sparsifies low-rank approximated
updates by leveraging the interleaved importance of singular vectors, ensuring
that the most impactful components are retained. We demonstrate through
extensive experiments that our proposed methods lead to significant storage
efficiency and superior accuracy within the same memory budget compared to
employing the low-rank approximation or sparsification individually.

</details>


### [19] [PragExTra: A Multilingual Corpus of Pragmatic Explicitation in Translation](https://arxiv.org/abs/2511.02721)
*Doreen Osmelak,Koel Dutta Chowdhury,Uliana Sentsova,Cristina España-Bonet,Josef van Genabith*

Main category: cs.CL

TL;DR: PragExTra是首个多语言语境显性化检测语料库，涵盖8种语言对，通过主动学习提高分类器性能，促使机器翻译更具文化意识。


<details>
  <summary>Details</summary>
Motivation: 翻译中常见的语境显性化现象（将隐含文化意义显化）虽被理论讨论，但缺乏计算模型支持。

Method: 构建包含TED-Multi与Europarl 8语言对的多语言语料库，利用空对齐识别候选语境显性化案例，结合人工注释和主动学习提升检测准确性。

Result: 发现实体描述和系统级显性化最常见，主动学习提升分类器准确率7-8个百分点，最高达0.88准确率和0.82 F1。

Conclusion: PragExTra使语境显性化成为可量化的跨语言现象，推动文化敏感型机器翻译的发展。

Abstract: Translators often enrich texts with background details that make implicit
cultural meanings explicit for new audiences. This phenomenon, known as
pragmatic explicitation, has been widely discussed in translation theory but
rarely modeled computationally. We introduce PragExTra, the first multilingual
corpus and detection framework for pragmatic explicitation. The corpus covers
eight language pairs from TED-Multi and Europarl and includes additions such as
entity descriptions, measurement conversions, and translator remarks. We
identify candidate explicitation cases through null alignments and refined
using active learning with human annotation. Our results show that entity and
system-level explicitations are most frequent, and that active learning
improves classifier accuracy by 7-8 percentage points, achieving up to 0.88
accuracy and 0.82 F1 across languages. PragExTra establishes pragmatic
explicitation as a measurable, cross-linguistic phenomenon and takes a step
towards building culturally aware machine translation. Keywords: translation,
multilingualism, explicitation

</details>


### [20] [AI Diffusion in Low Resource Language Countries](https://arxiv.org/abs/2511.02752)
*Amit Misra,Syed Waqas Zamir,Wassim Hamidouche,Inbal Becker-Reshef,Juan Lavista Ferres*

Main category: cs.CL

TL;DR: 本文分析了低资源语言国家在人工智能采用方面存在的障碍，发现语言资源匮乏显著降低了AI用户比例。


<details>
  <summary>Details</summary>
Motivation: 探究大规模语言模型在低资源语言上的性能不足是否影响人工智能在这些国家的采纳和普及。

Method: 利用加权回归模型，独立分离语言影响与社会经济及人口因素，量化语言对AI普及的影响。

Result: 低资源语言国家的AI用户比例较基线水平低约20%，表明语言障碍显著限制了AI的接受程度。

Conclusion: 语言可及性是促进人工智能公平普及的关键独立障碍，需引起重视以推动全球AI扩散。

Abstract: Artificial intelligence (AI) is diffusing globally at unprecedented speed,
but adoption remains uneven. Frontier Large Language Models (LLMs) are known to
perform poorly on low-resource languages due to data scarcity. We hypothesize
that this performance deficit reduces the utility of AI, thereby slowing
adoption in Low-Resource Language Countries (LRLCs). To test this, we use a
weighted regression model to isolate the language effect from socioeconomic and
demographic factors, finding that LRLCs have a share of AI users that is
approximately 20% lower relative to their baseline. These results indicate that
linguistic accessibility is a significant, independent barrier to equitable AI
diffusion.

</details>


### [21] [Controlling Performance and Budget of a Centralized Multi-agent LLM System with Reinforcement Learning](https://arxiv.org/abs/2511.02755)
*Bowen Jin,TJ Collins,Donghan Yu,Mert Cemri,Shenao Zhang,Mengyu Li,Jay Tang,Tian Qin,Zhiyang Xu,Jiarui Lu,Guoli Yin,Jiawei Han,Zirui Wang*

Main category: cs.CL

TL;DR: 本文提出了一个集中式多大语言模型(LLM)框架，通过强化学习实现控制成本的模型协作。


<details>
  <summary>Details</summary>
Motivation: 当前多语言模型系统多采用分散式架构，导致推理成本高且不可控，因此需要一个高效且成本可控的集中式协调机制。

Method: 设计了一个基于强化学习的控制器LLM，协调多个专家模型，优化任务性能与推理成本的权衡，并提出CoRL框架实现多预算条件下的性能成本控制。

Result: 在四个多样化基准测试中，CoRL在高预算时超过了最佳专家模型表现，在低预算下依然保持较强性能，展示了集中协调方式的高效性。

Conclusion: 集中式多LLM协作框架利用强化学习实现成本效益与性能兼顾，为多智能体大语言模型系统的可扩展性和成本控制提供了有效方案。

Abstract: Large language models (LLMs) exhibit complementary strengths across domains
and come with varying inference costs, motivating the design of multi-agent LLM
systems where specialized models collaborate efficiently. Existing approaches
predominantly rely on decentralized frameworks, which invoke multiple LLMs for
every input and thus lead to substantial and uncontrolled inference costs. In
this work, we introduce a centralized multi-LLM framework, where a controller
LLM selectively coordinates a pool of expert models in a cost-efficient and
cost-controllable manner. We formulate this coordination problem as
reinforcement learning with dual objectives: maximizing task performance while
minimizing the overall inference cost. In addition, we expect the multi-agent
system to have adapted behavior with different budget conditions during
inference. To this end, we propose CoRL, a reinforcement learning framework
that optimizes the performance cost trade-off in a controllable multi-budget
setting. Experiments on four diverse benchmarks demonstrate that CoRL enables a
single system to surpass the best expert LLM under high-budget settings, while
maintaining strong performance in more economical low-budget modes,
highlighting the effectiveness of centralized coordination for scalable and
cost-efficient multi-agent LLM systems.

</details>


### [22] [Beyond Single Embeddings: Capturing Diverse Targets with Multi-Query Retrieval](https://arxiv.org/abs/2511.02770)
*Hung-Ting Chen,Xiang Liu,Shauli Ravfogel,Eunsol Choi*

Main category: cs.CL

TL;DR: 本文提出了一种新的检索器结构AMER，利用自回归多查询向量生成来改善文本检索性能，尤其是在目标文档嵌入距离较大时效果显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有文本检索器通常生成单一查询向量，难以捕捉多模态的查询相关文档分布，导致检索效果受限，特别是当目标文档嵌入间距较大时表现较差。

Method: 提出自回归多嵌入检索器（AMER），通过自回归方式生成多个查询向量，利用这些多查询向量同时检索文档，增强对多模态目标分布的捕获能力。

Result: 在合成向量数据上，AMER能完美捕捉多目标分布，性能提升达4倍；在真实多答案检索数据上，AMER相较单嵌入基线提升4%和21%；对嵌入差异较大的子集效果提升更大。

Conclusion: AMER的多查询向量机制有效提升了文本检索的多模态适应能力，为未来研究打开了新的方向。

Abstract: Most text retrievers generate \emph{one} query vector to retrieve relevant
documents. Yet, the conditional distribution of relevant documents for the
query may be multimodal, e.g., representing different interpretations of the
query. We first quantify the limitations of existing retrievers. All retrievers
we evaluate struggle more as the distance between target document embeddings
grows. To address this limitation, we develop a new retriever architecture,
\emph{A}utoregressive \emph{M}ulti-\emph{E}mbedding \emph{R}etriever (AMER).
Our model autoregressively generates multiple query vectors, and all the
predicted query vectors are used to retrieve documents from the corpus. We show
that on the synthetic vectorized data, the proposed method could capture
multiple target distributions perfectly, showing 4x better performance than
single embedding model. We also fine-tune our model on real-world multi-answer
retrieval datasets and evaluate in-domain. AMER presents 4 and 21\% relative
gains over single-embedding baselines on two datasets we evaluate on.
Furthermore, we consistently observe larger gains on the subset of dataset
where the embeddings of the target documents are less similar to each other. We
demonstrate the potential of using a multi-query vector retriever and open up a
new direction for future work.

</details>


### [23] [MemSearcher: Training LLMs to Reason, Search and Manage Memory via End-to-End Reinforcement Learning](https://arxiv.org/abs/2511.02805)
*Qianhao Yuan,Jie Lou,Zichao Li,Jiawei Chen,Yaojie Lu,Hongyu Lin,Le Sun,Debing Zhang,Xianpei Han*

Main category: cs.CL

TL;DR: 提出MemSearcher，通过维护紧凑记忆结合当前交互，实现多轮检索智能体高效且准确的任务执行。


<details>
  <summary>Details</summary>
Motivation: 传统搜索智能体要么保留全部历史信息导致计算资源浪费，要么只用当前轮次信息而丢失关键信息，限制了可扩展性。

Method: 设计MemSearcher维持紧凑记忆与当前交互融合；引入多上下文GRPO强化学习框架，联合优化推理、搜索策略与记忆管理。

Result: 在七个公开基准测试上，MemSearcher较强基线提升11%-12%，3B模型性能超越7B模型，显示出更优的信息效率平衡。

Conclusion: MemSearcher实现了信息完整性与效率的最佳平衡，提升多轮搜索任务的准确性和计算效率。

Abstract: Typical search agents concatenate the entire interaction history into the LLM
context, preserving information integrity but producing long, noisy contexts,
resulting in high computation and memory costs. In contrast, using only the
current turn avoids this overhead but discards essential information. This
trade-off limits the scalability of search agents. To address this challenge,
we propose MemSearcher, an agent workflow that iteratively maintains a compact
memory and combines the current turn with it. At each turn, MemSearcher fuses
the user's question with the memory to generate reasoning traces, perform
search actions, and update memory to retain only information essential for
solving the task. This design stabilizes context length across multi-turn
interactions, improving efficiency without sacrificing accuracy. To optimize
this workflow, we introduce multi-context GRPO, an end-to-end RL framework that
jointly optimize reasoning, search strategies, and memory management of
MemSearcher Agents. Specifically, multi-context GRPO samples groups of
trajectories under different contexts and propagates trajectory-level
advantages across all conversations within them. Trained on the same dataset as
Search-R1, MemSearcher achieves significant improvements over strong baselines
on seven public benchmarks: +11% on Qwen2.5-3B-Instruct and +12% on
Qwen2.5-7B-Instruct relative average gains. Notably, the 3B-based MemSearcher
even outperforms 7B-based baselines, demonstrating that striking a balance
between information integrity and efficiency yields both higher accuracy and
lower computational overhead. The code and models will be publicly available at
https://github.com/icip-cas/MemSearcher

</details>


### [24] [Oolong: Evaluating Long Context Reasoning and Aggregation Capabilities](https://arxiv.org/abs/2511.02817)
*Amanda Bertsch,Adithya Pratapa,Teruko Mitamura,Graham Neubig,Matthew R. Gormley*

Main category: cs.CL

TL;DR: 本文提出了Oolong基准测试，聚焦长文本推理，要求模型细致分析文本片段并综合判断，评估模型在处理大规模上下文信息时的能力。


<details>
  <summary>Details</summary>
Motivation: 现有长上下文评估多依赖检索部分文本，忽视了全文的有效利用，无法全面考察模型对长文本的推理能力。

Method: 设计了两个任务集：Oolong-synth（合成任务）和Oolong-real（真实对话任务），测试模型对大量文本的分类、计数以及时序和用户关系的推理能力。

Result: 即使是先进模型如GPT-5、Claude-Sonnet-4和Gemini-2.5-Pro，在128K上下文长度下准确率均未超过50%，表现均较弱。

Conclusion: Oolong提供了更具挑战性的长上下文推理测试，有助于推动模型在处理大规模文本上的推理能力提升。

Abstract: As model context lengths continue to grow, concerns about whether models
effectively use the full context length have persisted. While several carefully
designed long-context evaluations have recently been released, these
evaluations tend to rely on retrieval from one or more sections of the context,
which allows nearly all of the context tokens to be disregarded as noise. This
represents only one type of task that might be performed with long context. We
introduce Oolong, a benchmark of long-context reasoning tasks that require
analyzing individual chunks of text on an atomic level, and then aggregating
these analyses to answer distributional questions. Oolong is separated into two
task sets: Oolong-synth, a set of naturalistic synthetic tasks, where we can
easily ablate components of the reasoning problem; and Oolong-real, a
downstream setting which requires reasoning over real-world conversational
data. Oolong requires models to reason over large quantities of examples, to
perform both classification and counting in-context, and to reason over
temporal and user relations. Even frontier models struggle on Oolong, with
GPT-5, Claude-Sonnet-4, and Gemini-2.5-Pro all achieving less than 50% accuracy
on both splits at 128K. We release the data and evaluation harness for Oolong
to enable further development of models that can reason over large quantities
of text.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [25] [Detecting Vulnerabilities from Issue Reports for Internet-of-Things](https://arxiv.org/abs/2511.01941)
*Sogol Masoumzadeh*

Main category: cs.SE

TL;DR: 本文提出了针对物联网(IoT)系统中漏洞问题报告的检测方法，结合机器学习和大语言模型，首次深入探索IoT系统中的漏洞检测。


<details>
  <summary>Details</summary>
Motivation: IoT系统中的漏洞问题识别比非IoT系统更慢，现有的机器学习和大语言模型在非IoT系统中已被用于漏洞检测，但在IoT领域尚未研究。

Method: 提出两种方法：1）结合机器学习和大语言模型及自然语言处理技术，针对21个Eclipse IoT项目检测漏洞问题；2）基于11,000条GitHub问题，微调预训练的BERT掩码语言模型进行漏洞分类。

Result: 支持向量机在BERT NLP特征上表现最佳，AUC达到0.65；微调的BERT准确率为0.26，表明训练时暴露全部数据的重要性。

Conclusion: 为IoT漏洞问题报告的准确检测奠定基础，使其检测能力可与非IoT系统相媲美。

Abstract: Timely identification of issue reports reflecting software vulnerabilities is
crucial, particularly for Internet-of-Things (IoT) where analysis is slower
than non-IoT systems. While Machine Learning (ML) and Large Language Models
(LLMs) detect vulnerability-indicating issues in non-IoT systems, their IoT use
remains unexplored. We are the first to tackle this problem by proposing two
approaches: (1) combining ML and LLMs with Natural Language Processing (NLP)
techniques to detect vulnerability-indicating issues of 21 Eclipse IoT projects
and (2) fine-tuning a pre-trained BERT Masked Language Model (MLM) on 11,000
GitHub issues for classifying \vul. Our best performance belongs to a Support
Vector Machine (SVM) trained on BERT NLP features, achieving an Area Under the
receiver operator characteristic Curve (AUC) of 0.65. The fine-tuned BERT
achieves 0.26 accuracy, emphasizing the importance of exposing all data during
training. Our contributions set the stage for accurately detecting IoT
vulnerabilities from issue reports, similar to non-IoT systems.

</details>


### [26] [Metamorphic Testing of Large Language Models for Natural Language Processing](https://arxiv.org/abs/2511.02108)
*Steven Cho,Stefano Ruberto,Valerio Terragni*

Main category: cs.SE

TL;DR: 本文研究了利用变形测试方法（MT）自动识别大型语言模型（LLMs）在自然语言处理任务中错误行为的效果。


<details>
  <summary>Details</summary>
Motivation: LLMs虽然表现优异，但常产生错误，且缺乏标注数据使得自动识别错误行为困难。MT通过变形关系（MRs）缓解了无标注数据的oracle问题，具有重要应用价值。

Method: 通过文献调研收集了191条MRs，选取36条进行代表性实验，针对三款主流LLMs执行约56万次变形测试，深入评估MT应用于LLMs的能力和限制。

Result: 变形测试有效揭示了LLMs的错误行为，展示了其用于自动错误检测的可行性和优势，同时指出了MT在实际应用中的一些局限性。

Conclusion: MT是提升LLMs可信度的重要工具，但仍需进一步完善以克服现有限制。该研究提供了最全面的MT与LLMs结合的实证分析。

Abstract: Using large language models (LLMs) to perform natural language processing
(NLP) tasks has become increasingly pervasive in recent times. The versatile
nature of LLMs makes them applicable to a wide range of such tasks. While the
performance of recent LLMs is generally outstanding, several studies have shown
that they can often produce incorrect results. Automatically identifying these
faulty behaviors is extremely useful for improving the effectiveness of LLMs.
One obstacle to this is the limited availability of labeled datasets, which
necessitates an oracle to determine the correctness of LLM behaviors.
Metamorphic testing (MT) is a popular testing approach that alleviates this
oracle problem. At the core of MT are metamorphic relations (MRs), which define
relationships between the outputs of related inputs. MT can expose faulty
behaviors without the need for explicit oracles (e.g., labeled datasets). This
paper presents the most comprehensive study of MT for LLMs to date. We
conducted a literature review and collected 191 MRs for NLP tasks. We
implemented a representative subset (36 MRs) to conduct a series of experiments
with three popular LLMs, running approximately 560,000 metamorphic tests. The
results shed light on the capabilities and opportunities of MT for LLMs, as
well as its limitations.

</details>


### [27] [Open the Oyster: Empirical Evaluation and Improvement of Code Reasoning Confidence in LLMs](https://arxiv.org/abs/2511.02197)
*Shufan Wang,Xing Hu,Junkai Chen,Zhiyuan Pan,Xin Xia*

Main category: cs.SE

TL;DR: 本论文提出了针对代码推理任务的大型语言模型置信度分析与增强框架，进行置信度可靠性实证研究并验证了提示策略优化和数学校准技术的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在代码智能领域的广泛应用，输出结果的可靠性与可控性成为关注重点，置信度估计作为有效手段亟需深入研究。

Method: 通过全面实证分析主流大型语言模型在不同代码推理任务中的置信度表现，评估提示策略优化（重新评估提示策略）与数学校准（如Platt Scaling）提升置信度可靠性的效果。

Result: DeepSeek-Reasoner在ECE、Brier Score和性能分数指标上均优于其它模型，混合策略较原始表现提升明显。模型推理能力和混合策略对于置信度可靠性提升最有效，但复杂推理任务中置信度仍有提升空间。

Conclusion: 本研究为LLM辅助软件工程中的置信度应用提供了理论基础和技术参考，指出了置信度机制未来优化和工程部署的方向。

Abstract: With the widespread application of large language models (LLMs) in the field
of code intelligence, increasing attention has been paid to the reliability and
controllability of their outputs in code reasoning tasks. Confidence estimation
serves as an effective and convenient approach for evaluating these aspects.
This paper proposes a confidence analysis and enhancement framework for LLMs
tailored to code reasoning tasks. We conduct a comprehensive empirical study on
the confidence reliability of mainstream LLMs across different tasks, and
further evaluate the effectiveness of techniques such as prompt strategy
optimisation and mathematical calibration (e.g., Platt Scaling) in improving
confidence reliability. Our results show that DeepSeek-Reasoner achieves the
best performance across various tasks, outperforming other models by up to
$0.680$, $0.636$, and $13.652$ in terms of ECE, Brier Score, and Performance
Score, respectively. The hybrid strategy combining the reassess prompt strategy
and Platt Scaling achieves improvements of up to $0.541$, $0.628$, and $15.084$
over the original performance in the aforementioned three metrics. These
results indicate that models with reasoning capabilities demonstrate superior
confidence reliability, and that the hybrid strategy is the most effective in
enhancing the confidence reliability of various models. Meanwhile, we elucidate
the impact of different task complexities, model scales, and strategies on
confidence performance, and highlight that the confidence of current LLMs in
complex reasoning tasks still has considerable room for improvement. This study
not only provides a research foundation and technical reference for the
application of confidence in LLM-assisted software engineering, but also points
the way for future optimisation and engineering deployment of confidence
mechanisms.

</details>


### [28] [LLMs as Judges: Toward The Automatic Review of GSN-compliant Assurance Cases](https://arxiv.org/abs/2511.02203)
*Gerhard Yu,Mithila Sivakumar,Alvine B. Belle,Soude Ghari,Song Wang,Timothy C. Lethbridge*

Main category: cs.SE

TL;DR: 本文提出利用大语言模型(LLM)自动化审查保证案例，以提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 保证案例文档庞大，人工审核耗时且易出错，需自动化技术提升审查质量与效率。

Method: 采用LLM作为审判者，通过基于谓词的规则形式化审查标准，设计针对性提示语进行保证案例审查。

Result: 在GPT-4o、GPT-4.1、DeepSeek-R1和Gemini 2.0 Flash中，DeepSeek-R1和GPT-4.1表现优异，DeepSeek-R1表现最佳，但仍需人工辅助。

Conclusion: 基于LLM的自动审查可显著提升保证案例审查效率和一致性，结合人工复核可确保质量。

Abstract: Assurance cases allow verifying the correct implementation of certain
non-functional requirements of mission-critical systems, including their
safety, security, and reliability. They can be used in the specification of
autonomous driving, avionics, air traffic control, and similar systems. They
aim to reduce risks of harm of all kinds including human mortality,
environmental damage, and financial loss. However, assurance cases often tend
to be organized as extensive documents spanning hundreds of pages, making their
creation, review, and maintenance error-prone, time-consuming, and tedious.
Therefore, there is a growing need to leverage (semi-)automated techniques,
such as those powered by generative AI and large language models (LLMs), to
enhance efficiency, consistency, and accuracy across the entire assurance-case
lifecycle. In this paper, we focus on assurance case review, a critical task
that ensures the quality of assurance cases and therefore fosters their
acceptance by regulatory authorities. We propose a novel approach that
leverages the \textit{LLM-as-a-judge} paradigm to automate the review process.
Specifically, we propose new predicate-based rules that formalize
well-established assurance case review criteria, allowing us to craft LLM
prompts tailored to the review task. Our experiments on several
state-of-the-art LLMs (GPT-4o, GPT-4.1, DeepSeek-R1, and Gemini 2.0 Flash) show
that, while most LLMs yield relatively good review capabilities, DeepSeek-R1
and GPT-4.1 demonstrate superior performance, with DeepSeek-R1 ultimately
outperforming GPT-4.1. However, our experimental results also suggest that
human reviewers are still needed to refine the reviews LLMs yield.

</details>


### [29] [SWE-Sharp-Bench: A Reproducible Benchmark for C# Software Engineering Tasks](https://arxiv.org/abs/2511.02352)
*Sanket Mhatre,Yasharth Bajpai,Sumit Gulwani,Emerson Murphy-Hill,Gustavo Soares*

Main category: cs.SE

TL;DR: 本文介绍了C#语言的软件工程基准测试SWE-Sharp-Bench，填补了现有基准中对C#支持的空白。


<details>
  <summary>Details</summary>
Motivation: 目前AI编码代理在Python和其他语言的软件工程基准上表现优异，但缺乏针对C#的相关基准，而C#作为排名第五的企业级语言，非常重要。

Method: 构建了包含150个实例、覆盖17个仓库的SWE-Sharp-Bench，设计可复现的测试流程，并对比了不同语言模型代理的性能。

Result: 同一模型配置下，Python任务的解决率为70%，而C#任务仅为40%，显示出显著的性能差距。

Conclusion: SWE-Sharp-Bench为C#软件工程AI模型的评估提供了标准基准，并且已开源以促进后续研究与改进。

Abstract: AI coding agents have shown great progress on Python software engineering
benchmarks like SWE-Bench, and for other languages like Java and C in
benchmarks like Multi-SWE-Bench. However, C# -- a prominent enterprise language
ranking #5 in the TIOBE index -- remains absent from such benchmarks. We
introduce SWE-Sharp-Bench, a reproducible software engineering benchmark for
C\# featuring 150 instances from 17 repositories. Evaluating identical
model-agent configurations across languages reveals a significant performance
gap: while 70% of Python tasks in SWE-Bench Verified are solved, $only 40% of
our C\# tasks are resolved. We open-source SWE-Sharp-Bench and our entire
curation pipeline.

</details>


### [30] [EvoDev: An Iterative Feature-Driven Framework for End-to-End Software Development with LLM-based Agents](https://arxiv.org/abs/2511.02399)
*Junwei Liu,Chen Xu,Chong Wang,Tong Bai,Weitong Chen,Kaseng Wong,Yiling Lou,Xin Peng*

Main category: cs.SE

TL;DR: EvoDev是一个基于特征驱动开发的迭代软件开发框架，通过构建特征图显式建模功能依赖，提升了复杂项目的开发效率。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型驱动的软件开发多采用线性流水线，难以应对复杂、大规模项目的迭代特点。

Method: EvoDev将用户需求分解为用户价值特征，建立有向无环的特征图，节点维护多层信息并沿依赖传播，支持多次迭代开发。

Result: 在安卓开发任务中，EvoDev相比最优基线Claude Code提升了56.8%，单智能体性能提升16.0%-76.6%。

Conclusion: 依赖建模、上下文传播和流程感知设计对于复杂软件项目至关重要，EvoDev为迭代式LLM驱动开发框架设计提供了实用经验。

Abstract: Recent advances in large language model agents offer the promise of
automating end-to-end software development from natural language requirements.
However, existing approaches largely adopt linear, waterfall-style pipelines,
which oversimplify the iterative nature of real-world development and struggle
with complex, large-scale projects. To address these limitations, we propose
EvoDev, an iterative software development framework inspired by feature-driven
development. EvoDev decomposes user requirements into a set of user-valued
features and constructs a Feature Map, a directed acyclic graph that explicitly
models dependencies between features. Each node in the feature map maintains
multi-level information, including business logic, design, and code, which is
propagated along dependencies to provide context for subsequent development
iterations. We evaluate EvoDev on challenging Android development tasks and
show that it outperforms the best-performing baseline, Claude Code, by a
substantial margin of 56.8%, while improving single-agent performance by
16.0%-76.6% across different base LLMs, highlighting the importance of
dependency modeling, context propagation, and workflow-aware agent design for
complex software projects. Our work summarizes practical insights for designing
iterative, LLM-driven development frameworks and informs future training of
base LLMs to better support iterative software development.

</details>


### [31] [Who's Who? LLM-assisted Software Traceability with Architecture Entity Recognition](https://arxiv.org/abs/2511.02434)
*Dominik Fuchß,Haoyu Liu,Sophie Corallo,Tobias Hey,Jan Keim,Johannes von Geisau,Anne Koziolek*

Main category: cs.SE

TL;DR: 本论文提出了基于大型语言模型（LLMs）的两种方法，用于自动识别文本中的架构实体，实现软件架构文档（SAD）与源代码之间的可追踪性链接恢复（TLR），从而消除手动创建软件架构模型（SAMs）的需求。


<details>
  <summary>Details</summary>
Motivation: 软件架构文档与源代码之间的追踪链接恢复依赖于识别架构相关实体，但手动创建软件架构模型耗时且繁琐。利用大型语言模型自动提取架构实体，可缩小语义差距，提高效率。

Method: 提出了两个基于LLM的方法：ExArch从SAD和源代码中提取组件名称，自动构建简单的SAM；ArTEMiS识别文档中的架构实体并与SAM实体匹配，可与手动或自动生成的SAM结合使用。评估中，该方法与SWATTR、TransArC和ArDoCode等主流方法进行了对比。

Result: TransArC在性能方面表现最好（F1值0.87），但依赖手动创建的SAM；ExArch仅使用SAD和代码，F1值达到0.86，表现相当；ArTEMiS的效果与基于启发式的SWATTR相仿（F1值0.81），与TransArC结合后可替代SWATTR；ArTEMiS与ExArch组合优于未经手动SAM的最佳基线ArDoCode。

Conclusion: 大型语言模型能有效识别文本中的架构实体，支持自动化的软件架构模型生成和追踪链接恢复，提升架构与代码间的可追踪性，使其更实用和易于访问。

Abstract: Identifying architecturally relevant entities in textual artifacts is crucial
for Traceability Link Recovery (TLR) between Software Architecture
Documentation (SAD) and source code. While Software Architecture Models (SAMs)
can bridge the semantic gap between these artifacts, their manual creation is
time-consuming. Large Language Models (LLMs) offer new capabilities for
extracting architectural entities from SAD and source code to construct SAMs
automatically or establish direct trace links. This paper presents two
LLM-based approaches: ExArch extracts component names as simple SAMs from SAD
and source code to eliminate the need for manual SAM creation, while ArTEMiS
identifies architectural entities in documentation and matches them with
(manually or automatically generated) SAM entities. Our evaluation compares
against state-of-the-art approaches SWATTR, TransArC and ArDoCode. TransArC
achieves strong performance (F1: 0.87) but requires manually created SAMs;
ExArch achieves comparable results (F1: 0.86) using only SAD and code. ArTEMiS
is on par with the traditional heuristic-based SWATTR (F1: 0.81) and can
successfully replace it when integrated with TransArC. The combination of
ArTEMiS and ExArch outperforms ArDoCode, the best baseline without manual SAMs.
Our results demonstrate that LLMs can effectively identify architectural
entities in textual artifacts, enabling automated SAM generation and TLR,
making architecture-code traceability more practical and accessible.

</details>


### [32] [When Continuous Delivery Is Not an Option: Practical Paths to Continuous Engineering in Complex Organizations](https://arxiv.org/abs/2511.02445)
*Eriks Klotins,Magnus Ahlgren,Nicolas Martin Vivaldi,Even-Andre Karlsson*

Main category: cs.SE

TL;DR: 本文基于4个行业案例，探讨复杂产品和组织约束如何影响连续软件工程（CSE）采纳，提出更新的准备度模型，指导实际应用。


<details>
  <summary>Details</summary>
Motivation: CSE能提升效率和质量，但受复杂产品、遗留系统、组织惯性和监管等限制，难以完全采纳。

Method: 采用并扩展CSE产业准备度模型，通过专家访谈和叙事综合，评估各案例的采纳现状与潜力，识别驱动力与障碍。

Result: 提出更新的准备度模型，加入内外反馈层次，区分市场与组织约束，更好指导实际CSE采纳目标设定。

Conclusion: 虽然全面采纳CSE不总可行，但局部改进仍有益，提供有实证支持的部分采纳转型指导。

Abstract: Purpose: Continuous Software Engineering (CSE) promises improved efficiency,
quality, and responsiveness in software-intensive organizations. However, fully
adopting CSE is often constrained by complex products, legacy systems,
organizational inertia, and regulatory requirements. In this paper, we examine
four industrial cases from the automation, automotive, retail, and chemical
sectors to explore how such constraints shape CSE adoption in practice.
Methods: We apply and extend a previously proposed CSE Industry Readiness Model
to assess the current and potential levels of adoption in each case. Through
expert interviews and narrative synthesis, we identify common driving forces
and adoption barriers, including organizational preparedness,
cross-organizational dependencies, and limited customer demand for continuous
delivery. Results: Based on our findings, we propose an updated readiness model
that introduces additional levels of internal and external feedback,
distinguishes market- and organization-facing constraints, and better guides
practitioners in setting realistic CSE adoption goals. Conclusions: Our results
highlight that while full end-to-end CSE adoption may not always be feasible,
meaningful internal improvements are still possible and beneficial. This study
provides empirically grounded guidance for organizations navigating partial or
constrained CSE transformations.

</details>


### [33] [Lost in Code Generation: Reimagining the Role of Software Models in AI-driven Software Engineering](https://arxiv.org/abs/2511.02475)
*Jürgen Cito,Dominik Bork*

Main category: cs.SE

TL;DR: 本文讨论了生成式人工智能（AI）在软件开发中的应用，强调生成代码的脆弱性和传统软件模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使软件开发更快速便捷，但导致生成的软件系统缺乏鲁棒性、安全性和可维护性，传统的软件模型需重新定位以应对这种变化。

Method: 提出将软件模型作为事后恢复工具，从AI生成代码中恢复模型，以帮助理解代码、发现风险及指导系统改进。

Result: 模型作为人类意图、AI代码生成和系统长期演进之间的媒介，能够提升系统的可理解性和可维护性。

Conclusion: 通过将模型作为AI生成代码的恢复和指导工具，可以推动可持续的AI驱动软件工程，提高软件系统的稳健性和安全性。

Abstract: Generative AI enables rapid ``vibe coding," where natural language prompts
yield working software systems. While this lowers barriers to software
creation, it also collapses the boundary between prototypes and engineered
software, leading to fragile systems that lack robustness, security, and
maintainability. We argue that this shift motivates a reimagining of software
models. Rather than serving only as upfront blueprints, models can be recovered
post-hoc from AI-generated code to restore comprehension, expose risks, and
guide refinement. In this role, models serve as mediators between human intent,
AI generation, and long-term system evolution, providing a path toward
sustainable AI-driven software engineering.

</details>


### [34] [ReleaseEval: A Benchmark for Evaluating Language Models in Automated Release Note Generation](https://arxiv.org/abs/2511.02713)
*Qianru Meng,Zhaochun Ren,Joost Visser*

Main category: cs.SE

TL;DR: 本文提出了ReleaseEval基准，针对自动发布说明生成任务，涵盖多语言、多输入粒度，系统评估了大语言模型的表现，发现其在利用结构化信息上表现优异，但在处理细粒度代码差异时仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 自动生成发布说明的任务中，现有工作受限于数据集许可、重现性及任务设计不完善，主要依赖提交信息，忽视了更丰富的上下文信息，如提交树结构和代码变更细节。

Method: 构建了包含近9.5万条发布说明的数据集ReleaseEval，支持三种任务设置（commit2sum、tree2sum和diff2sum），分别利用提交信息、提交树结构和代码差异作为输入，并对多种语言模型进行了自动化及人工评估。

Result: 大语言模型在所有任务上均优于传统基线，尤其在利用提交树结构的tree2sum任务中表现突出，但在基于代码差异的diff2sum任务中表现较弱。

Conclusion: 虽然大语言模型对结构化信息的利用能力较强，能有效提升发布说明生成效果，但如何从长代码差异中抽象关键信息仍是亟待解决的难题。

Abstract: Automated release note generation addresses the challenge of documenting
frequent software updates, where manual efforts are time-consuming and prone to
human error. Although recent advances in language models further enhance this
process, progress remains hindered by dataset limitations, including the lack
of explicit licensing and limited reproducibility, and incomplete task design
that relies mainly on commit messages for summarization while overlooking
fine-grained contexts such as commit hierarchies and code changes. To fill this
gap, we introduce ReleaseEval, a reproducible and openly licensed benchmark
designed to systematically evaluate language models for automated release note
generation. ReleaseEval comprises 94,987 release notes from 3,369 repositories
across 6 programming languages, and supports three task settings with three
levels of input granularity: (1) commit2sum, which generates release notes from
commit messages; (2) tree2sum, which incorporates commit tree structures; and
(3) diff2sum, which leverages fine-grained code diffs. Both automated and human
evaluations show that large language models consistently outperform traditional
baselines across all tasks, achieving substantial gains on tree2sum, while
still struggling on diff2sum. These findings highlight LLMs' proficiency in
leveraging structured information while revealing challenges in abstracting
from long code diffs.

</details>


### [35] [Investigating the Experience of Autistic Individuals in Software Engineering](https://arxiv.org/abs/2511.02736)
*Madalena Sasportes,Grischa Liebel,Miguel Goulão*

Main category: cs.SE

TL;DR: 研究分析了自闭症软件工程师在代码审查等活动中的经验，强调其逻辑思维、细节关注、专注力等优势。


<details>
  <summary>Details</summary>
Motivation: 自闭症个体在日常生活中面临就业和心理健康挑战，而其某些认知优势如逻辑推理能力可能在软件工程中具有价值，现有研究主要关注挑战而非优势。

Method: 采用社会技术基础理论，通过对16名自闭症软件工程师的半结构化访谈和49人的问卷调查（其中5名自闭症参与者），结合已有理论进行分析。

Result: 发现自闭症软件工程师在逻辑思维、细节关注、专注力方面表现优异，喜欢学习新编程语言，偏好书面沟通和远程工作，对AI系统交互感到舒适。

Conclusion: 研究补充了自闭症软件工程师优势的证据，有助于促进其更好地融入软件工程领域。

Abstract: Context: Autism spectrum disorder (ASD) leads to various issues in the
everyday life of autistic individuals, often resulting in unemployment and
mental health problems. To improve the inclusion of autistic adults, existing
studies have highlighted the strengths these individuals possess in comparison
to non-autistic individuals, e.g., high attention to detail or excellent
logical reasoning skills. If fostered, these strengths could be valuable in
software engineering activities, such for identifying specific kinds of bugs in
code. However, existing work in SE has primarily studied the challenges of
autistic individuals and possible accommodations, with little attention their
strengths. Objective: Our goal is to analyse the experiences of autistic
individuals in software engineering activities, such as code reviews, with a
particular emphasis on strengths. Methods: This study combines Social-Technical
Grounded Theory through semi-structured interviews with 16 autistic software
engineers and a survey with 49 respondents, including 5 autistic participants.
We compare the emerging themes with the theory by Gama et al. on the Effect of
Neurodivergent Cognitive Dysfunctions in Software Engineering Performance.
Results: Our results suggest that autistic software engineers are often skilled
in logical thinking, attention to detail, and hyperfocus in programming; and
they enjoy learning new programming languages and programming-related
technologies. Confirming previous work, they tend to prefer written
communication and remote work. Finally, we report a high comfort level in
interacting with AI-based systems. Conclusions: Our findings extend existing
work by providing further evidence on the strengths of autistic software
engineers.

</details>


### [36] [Formalizing Regression Testing for Agile and Continuous Integration Environments](https://arxiv.org/abs/2511.02810)
*Suddhasvatta Das,Kevin Gary*

Main category: cs.SE

TL;DR: 本文形式化定义了基于连续构建的迭代回归测试过程，提出了回归测试时间窗口模型，并验证了该模型对经典回归测试的涵盖性和对现有敏捷算法的适用性。


<details>
  <summary>Details</summary>
Motivation: 现代敏捷开发中，软件版本频繁发布，传统回归测试理论假设的交付或维护阶段单次测试方式已不适用，需研究连续回归测试的形式化模型。

Method: 将连续构建视为时间有序链条，每个构建包含程序、需求及测试，定义两个构建间的回归测试时间窗口，并用构建元组操作形式化表示现有敏捷回归测试算法。

Result: 模型在无限时间预算和仅两个构建时退化为经典重新测试全部策略，形式化表示的敏捷算法被证明在该模型下具备健全性和完备性。

Conclusion: 该工作成功形式化了连续回归测试的核心概念，既涵盖了传统回归测试，又能支持敏捷环境下的实际算法，为更有效的回归测试提供理论基础。

Abstract: Software developed using modern agile practices delivers a stream of software
versions that require continuous regression testing rather than testing once
close to the delivery or maintenance phase, as assumed by classical
regression-testing theory. In this work, we formalize the phenomenon of
continuous or near-continuous regression testing using successive builds as a
time-ordered chain, where each build contains the program, requirements, and
the accompanying tests. We also formalize the regression test window between
any two builds, which captures the limited time budget available for regression
testing. As the time limit is set to infinity and the chain is closed to two
builds, the model degenerates to retest-all, thereby preserving semantics for
the classical two-version case. The formalization is validated by directly
representing two state-of-the-art agile regression testing algorithms in terms
of build-tuple operations without requiring auxiliary assumptions, followed by
proof of the soundness and completeness of our formalization.

</details>


### [37] [From Code Changes to Quality Gains: An Empirical Study in Python ML Systems with PyQu](https://arxiv.org/abs/2511.02827)
*Mohamed Almukhtar,Anwar Ghammam,Marouane Kessentini,Hua Ming*

Main category: cs.SE

TL;DR: 本文通过对3340个开源Python机器学习项目进行大规模实证研究，提出工具PyQu以识别提升软件质量的代码提交，发现61种直接影响质量的代码变更，推动了Python机器学习系统代码质量的自动评估发展。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能和Python机器学习系统广泛应用，软件质量问题成为突出挑战，尤其缺乏针对机器学习系统代码变更与质量影响的明确映射与评估工具。

Method: 研究基于3.7百万次提交和2.7万亿行代码展开，开发了利用低级软件度量的PyQu工具，结合主题分析方法识别质量提升的代码变更并分类。

Result: PyQu工具在识别质量提升提交上平均F1值达0.85，发现61种影响软件质量的代码变更，13个分类中41%为新发现，超越现有主流工具。

Conclusion: 该研究填补了Python机器学习系统代码变更与质量影响的知识空白，为自动质量评估和最佳实践提供了重要基础，对研究、实践、教育及工具开发均具积极推动作用。

Abstract: In an era shaped by Generative Artificial Intelligence for code generation
and the rising adoption of Python-based Machine Learning systems (MLS),
software quality has emerged as a major concern. As these systems grow in
complexity and importance, a key obstacle lies in understanding exactly how
specific code changes affect overall quality-a shortfall aggravated by the lack
of quality assessment tools and a clear mapping between ML systems code changes
and their quality effects. Although prior work has explored code changes in
MLS, it mostly stops at what the changes are, leaving a gap in our knowledge of
the relationship between code changes and the MLS quality. To address this gap,
we conducted a large-scale empirical study of 3,340 open-source Python ML
projects, encompassing more than 3.7 million commits and 2.7 trillion lines of
code. We introduce PyQu, a novel tool that leverages low level software metrics
to identify quality-enhancing commits with an average accuracy, precision, and
recall of 0.84 and 0.85 of average F1 score. Using PyQu and a thematic
analysis, we identified 61 code changes, each demonstrating a direct impact on
enhancing software quality, and we classified them into 13 categories based on
contextual characteristics. 41% of the changes are newly discovered by our
study and have not been identified by state-of-the-art Python changes detection
tools. Our work offers a vital foundation for researchers, practitioners,
educators, and tool developers, advancing the quest for automated quality
assessment and best practices in Python-based ML software.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [38] [EvoMem: Improving Multi-Agent Planning with Dual-Evolving Memory](https://arxiv.org/abs/2511.01912)
*Wenzhe Fan,Ning Yan,Masood Mortazavi*

Main category: cs.MA

TL;DR: 本文提出了EvoMem，一个基于双重进化记忆机制的多智能体规划框架，显著提升了复杂任务规划的效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型的多智能体框架尚未充分利用人类工作记忆机制，而多智能体之间如何通过记忆协调对于自然语言规划中的推理、约束追踪和纠错至关重要。

Method: 设计了包含约束提取器、验证器和执行者三个智能体的EvoMem框架，采用两种记忆模块：任务特定规则的约束记忆(CMem)和积累反馈进行方案优化的查询反馈记忆(QMem)，两者分别在不同时间尺度进化。

Result: 在旅行规划、会议规划和日历安排等任务中，EvoMem表现出持续的性能提升。

Conclusion: 通过引入和模拟人类工作记忆，EvoMem有效增强了多智能体系统的规划能力，强调了记忆机制在多智能体协作中的重要性。

Abstract: Planning has been a cornerstone of artificial intelligence for solving
complex problems, and recent progress in LLM-based multi-agent frameworks have
begun to extend this capability. However, the role of human-like memory within
these frameworks remains largely unexplored. Understanding how agents
coordinate through memory is critical for natural language planning, where
iterative reasoning, constraint tracking, and error correction drive the
success. Inspired by working memory model in cognitive psychology, we present
EvoMem, a multi-agent framework built on a dual-evolving memory mechanism. The
framework consists of three agents (Constraint Extractor, Verifier, and Actor)
and two memory modules: Constraint Memory (CMem), which evolves across queries
by storing task-specific rules and constraints while remains fixed within a
query, and Query-feedback Memory (QMem), which evolves within a query by
accumulating feedback across iterations for solution refinement. Both memory
modules are reset at the end of each query session. Evaluations on trip
planning, meeting planning, and calendar scheduling show consistent performance
improvements, highlighting the effectiveness of EvoMem. This success
underscores the importance of memory in enhancing multi-agent planning.

</details>


### [39] [Optimizing Multi-Lane Intersection Performance in Mixed Autonomy Environments](https://arxiv.org/abs/2511.02217)
*Manonmani Sekar,Nasim Nezamoddini*

Main category: cs.MA

TL;DR: 本文提出了一种结合图注意网络（GAT）和软演员-评论家（SAC）强化学习的交通信号控制新框架，有效改善多车道路口人类驾驶车辆与自动驾驶车辆的协调，显著降低平均延迟和交通违规，提高公平性。


<details>
  <summary>Details</summary>
Motivation: 多车道路口管理的主要挑战是确保人类驾驶车辆与自动驾驶车辆之间的平滑协调，提高交通效率和安全性。

Method: 利用GAT捕捉交通流的时空依赖，结合基于熵优化的SAC强化学习，实现信号灯控制与车辆移动的联合优化，旨在最小化旅行时间、提升性能和安全性，并改善车辆类型间的公平性。

Result: 在基于SUMO的四路路口仿真中，GAT-SAC方法实现了平均延迟减少24.1%，交通违规减少最高29.2%，同时人类驾驶车辆与自动驾驶车辆的公平性比例提升至1.59。

Conclusion: GAT-SAC框架在混合自主交通系统中展现出较强的实际应用潜力，有助于实现更高效、更安全、更公平的交通信号控制。

Abstract: One of the main challenges in managing traffic at multilane intersections is
ensuring smooth coordination between human-driven vehicles (HDVs) and connected
autonomous vehicles (CAVs). This paper presents a novel traffic signal control
framework that combines Graph Attention Networks (GAT) with Soft Actor-Critic
(SAC) reinforcement learning to address this challenge. GATs are used to model
the dynamic graph- structured nature of traffic flow to capture spatial and
temporal dependencies between lanes and signal phases. The proposed SAC is a
robust off-policy reinforcement learning algorithm that enables adaptive signal
control through entropy-optimized decision making. This design allows the
system to coordinate the signal timing and vehicle movement simultaneously with
objectives focused on minimizing travel time, enhancing performance, ensuring
safety, and improving fairness between HDVs and CAVs. The model is evaluated
using a SUMO-based simulation of a four-way intersection and incorporating
different traffic densities and CAV penetration rates. The experimental results
demonstrate the effectiveness of the GAT-SAC approach by achieving a 24.1%
reduction in average delay and up to 29.2% fewer traffic violations compared to
traditional methods. Additionally, the fairness ratio between HDVs and CAVs
improved to 1.59, indicating more equitable treatment across vehicle types.
These findings suggest that the GAT-SAC framework holds significant promise for
real-world deployment in mixed-autonomy traffic systems.

</details>


### [40] [Automata-Conditioned Cooperative Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2511.02304)
*Beyazit Yalcinkaya,Marcell Vazquez-Chanlatte,Ameesh Shah,Hanna Krasowski,Sanjit A. Seshia*

Main category: cs.MA

TL;DR: 提出了一种基于自动机的多任务多智能体协同强化学习框架ACC-MARL，实现了任务条件下的去中心化团队策略学习，提升了样本效率并支持复杂任务分解与协调。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体强化学习方法在多任务协同场景中样本效率低，且多以单任务为主，难以处理复杂任务分解和协作。利用自动机表示任务有助于复杂任务拆分，但相关方法效果有限。

Method: 提出ACC-MARL框架，通过自动机条件控制实现任务依赖的多智能体策略学习。在理论上证明了方法的正确性，并设计了策略价值函数用于测试时的任务最优分配。

Result: 实验展示了该方法下智能体能够实现任务感知的多步骤协作，如依次按按钮开门、保门和短路任务。

Conclusion: ACC-MARL有效提升了多任务多智能体强化学习的协作效率，支持复杂任务分解与测试时的任务优化分配，具有较好应用前景。

Abstract: We study the problem of learning multi-task, multi-agent policies for
cooperative, temporal objectives, under centralized training, decentralized
execution. In this setting, using automata to represent tasks enables the
decomposition of complex tasks into simpler sub-tasks that can be assigned to
agents. However, existing approaches remain sample-inefficient and are limited
to the single-task case. In this work, we present Automata-Conditioned
Cooperative Multi-Agent Reinforcement Learning (ACC-MARL), a framework for
learning task-conditioned, decentralized team policies. We identify the main
challenges to ACC-MARL's feasibility in practice, propose solutions, and prove
the correctness of our approach. We further show that the value functions of
learned policies can be used to assign tasks optimally at test time.
Experiments show emergent task-aware, multi-step coordination among agents,
e.g., pressing a button to unlock a door, holding the door, and
short-circuiting tasks.

</details>
