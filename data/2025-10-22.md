<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 67]
- [cs.MA](#cs.MA) [Total: 7]
- [cs.SE](#cs.SE) [Total: 33]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Modeling Layered Consciousness with Multi-Agent Large Language Models](https://arxiv.org/abs/2510.17844)
*Sang Hun Kim,Jongmin Lee,Dongkyu Park,So Young Lee,Yosep Chong*

Main category: cs.CL

TL;DR: 本文提出了一个基于精神分析理论的多智能体框架，用于模拟大语言模型中的人工意识，实现个性化和情感深度的提升。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏对人工意识层面的模拟，尤其是在自我意识和情感表达的个性化方面表现不足，因此希望引入精神分析理论来提升模型的认知能力和适应性。

Method: 提出了一个心理动力学模型，通过多个智能体之间的交互模拟自我意识、前意识和无意识，结合个人化模块整合固定特征和动态需求，利用参数高效微调技术在情感丰富的对话数据上进行训练。

Result: 模型在八种个性化条件下进行评估，使用LLM作为评判标准，71.2%的情况下偏好微调后的模型，呈现出更深的情感表达和更稳定的输出。

Conclusion: 该方法实现了适应性强的个性化认知，展示了多智能体心理动力学框架在提升大语言模型人工意识模拟和情感深度上的潜力。

Abstract: We propose a multi-agent framework for modeling artificial consciousness in
large language models (LLMs), grounded in psychoanalytic theory. Our
\textbf{Psychodynamic Model} simulates self-awareness, preconsciousness, and
unconsciousness through agent interaction, guided by a Personalization Module
combining fixed traits and dynamic needs. Using parameter-efficient fine-tuning
on emotionally rich dialogues, the system was evaluated across eight
personalized conditions. An LLM as a judge approach showed a 71.2\% preference
for the fine-tuned model, with improved emotional depth and reduced output
variance, demonstrating its potential for adaptive, personalized cognition.

</details>


### [2] [Outraged AI: Large language models prioritise emotion over cost in fairness enforcement](https://arxiv.org/abs/2510.17880)
*Hao Liu,Yiqing Dai,Haotian Tan,Yu Lei,Yujia Zhou,Zhen Wu*

Main category: cs.CL

TL;DR: 本研究比较了大型语言模型和人类在基于情感的惩罚决策上的差异，发现LLM在情感驱动惩罚上强于人类但缺乏成本敏感性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否像人类一样利用情感来指导道德决策，特别是在利他第三方惩罚中。

Method: 通过大规模对比4068个LLM代理和1159名成人在796,100个决策中的表现，分析情感如何驱动惩罚行为，同时比较不同模型类型的表现差异。

Result: LLM表现出强烈的负面情绪驱动惩罚，且惩罚带来正面情绪，情感自我报告能增加惩罚行为，但LLM更注重情感而忽视成本，导致惩罚行为趋向极端；推理模型表现更接近人类，但仍受情感主导。

Conclusion: LLM的情感驱动道德决策首次获得因果证据，显示其成本校准与公平判断存在不足，类似人类早期发展阶段。建议未来模型应结合情感与情境推理以实现类似人类的情感智能。

Abstract: Emotions guide human decisions, but whether large language models (LLMs) use
emotion similarly remains unknown. We tested this using altruistic third-party
punishment, where an observer incurs a personal cost to enforce fairness, a
hallmark of human morality and often driven by negative emotion. In a
large-scale comparison of 4,068 LLM agents with 1,159 adults across 796,100
decisions, LLMs used emotion to guide punishment, sometimes even more strongly
than humans did: Unfairness elicited stronger negative emotion that led to more
punishment; punishing unfairness produced more positive emotion than accepting;
and critically, prompting self-reports of emotion causally increased
punishment. However, mechanisms diverged: LLMs prioritized emotion over cost,
enforcing norms in an almost all-or-none manner with reduced cost sensitivity,
whereas humans balanced fairness and cost. Notably, reasoning models (o3-mini,
DeepSeek-R1) were more cost-sensitive and closer to human behavior than
foundation models (GPT-3.5, DeepSeek-V3), yet remained heavily emotion-driven.
These findings provide the first causal evidence of emotion-guided moral
decisions in LLMs and reveal deficits in cost calibration and nuanced fairness
judgements, reminiscent of early-stage human responses. We propose that LLMs
progress along a trajectory paralleling human development; future models should
integrate emotion with context-sensitive reasoning to achieve human-like
emotional intelligence.

</details>


### [3] [POPI: Personalizing LLMs via Optimized Natural Language Preference Inference](https://arxiv.org/abs/2510.17881)
*Yizhuo Chen,Xin Liu,Ruijie Wang,Zheng Li,Pei Chen,Changlong Yu,Priyanka Nigam,Meng Jiang,Bing Yin*

Main category: cs.CL

TL;DR: 提出了POPI框架，通过生成用户偏好摘要，实现高效个性化的大语言模型响应。


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法效率低且忽略用户异质性，需新方法提升个性化效果与效率。

Method: POPI引入偏好推断模型生成简明的自然语言偏好摘要，联合强化学习优化推断与生成，减少上下文冗余。

Result: 在四个基准测试中，POPI显著提高个性化准确率且减少上下文开销，摘要还可迁移至冻结模型实现无权重更新个性化。

Conclusion: POPI框架有效整合用户偏好信息，实现高效、准确且可迁移的LLM个性化。

Abstract: Large language models (LLMs) achieve strong benchmark performance, yet user
experiences remain inconsistent due to diverse preferences in style, tone, and
reasoning mode. Nevertheless, existing alignment techniques such as
reinforcement learning from human feedback (RLHF) or Direct Preference
Optimization (DPO) largely optimize toward population-level averages and
overlook individual variation. Naive personalization strategies like per-user
fine-tuning are computationally prohibitive, and in-context approaches that
prepend raw user signals often suffer from inefficiency and noise. To address
these challenges, we propose POPI, a general framework that introduces a
preference inference model to distill heterogeneous user signals into concise
natural language summaries. These summaries act as transparent, compact, and
transferable personalization representations that condition a shared generation
model to produce personalized responses. POPI jointly optimizes both preference
inference and personalized generation under a unified objective using
reinforcement learning, ensuring summaries maximally encode useful preference
information. Extensive experiments across four personalization benchmarks
demonstrate that POPI consistently improves personalization accuracy while
reducing context overhead by a large margin. Moreover, optimized summaries
seamlessly transfer to frozen off-the-shelf LLMs, enabling plug-and-play
personalization without weight updates.

</details>


### [4] [Advances in Pre-trained Language Models for Domain-Specific Text Classification: A Systematic Review](https://arxiv.org/abs/2510.17892)
*Zhyar Rzgar K. Rostam,Gábor Kertész*

Main category: cs.CL

TL;DR: 本文系统综述了预训练语言模型在领域特定文本分类中的应用，回顾了41篇相关文献，强调了基于Transformer的模型，并通过实验比较了BERT、SciBERT和BioBERT的性能。


<details>
  <summary>Details</summary>
Motivation: 科学文献和在线信息量激增，提取知识的效率亟需提升；传统大语言模型在领域特定任务中准确率下降，需深入研究预训练语言模型在领域文本分类中的表现。

Method: 系统性文献综述，遵循PRISMA准则，筛选41篇2018-2024年间的相关文章；分类各种预训练语言模型及技术；进行BERT、SciBERT和BioBERT的生物医学句子分类实验，比较其性能。

Result: 总结了文本分类技术的发展，区分传统与现代方法；强调Transformer模型的优势；呈现不同领域预训练语言模型性能对比；提出领域特定文本分类中的挑战与考虑因素。

Conclusion: 预训练语言模型，尤其是基于Transformer的，显著提升了领域文本分类效果；未来研究应关注模型在专业领域的适应性、数据不平衡和模型优化问题。

Abstract: The exponential increase in scientific literature and online information
necessitates efficient methods for extracting knowledge from textual data.
Natural language processing (NLP) plays a crucial role in addressing this
challenge, particularly in text classification tasks. While large language
models (LLMs) have achieved remarkable success in NLP, their accuracy can
suffer in domain-specific contexts due to specialized vocabulary, unique
grammatical structures, and imbalanced data distributions. In this systematic
literature review (SLR), we investigate the utilization of pre-trained language
models (PLMs) for domain-specific text classification. We systematically review
41 articles published between 2018 and January 2024, adhering to the PRISMA
statement (preferred reporting items for systematic reviews and meta-analyses).
This review methodology involved rigorous inclusion criteria and a multi-step
selection process employing AI-powered tools. We delve into the evolution of
text classification techniques and differentiate between traditional and modern
approaches. We emphasize transformer-based models and explore the challenges
and considerations associated with using LLMs for domain-specific text
classification. Furthermore, we categorize existing research based on various
PLMs and propose a taxonomy of techniques used in the field. To validate our
findings, we conducted a comparative experiment involving BERT, SciBERT, and
BioBERT in biomedical sentence classification. Finally, we present a
comparative study on the performance of LLMs in text classification tasks
across different domains. In addition, we examine recent advancements in PLMs
for domain-specific text classification and offer insights into future
directions and limitations in this rapidly evolving domain.

</details>


### [5] [Atomic Literary Styling: Mechanistic Manipulation of Prose Generation in Neural Language Models](https://arxiv.org/abs/2510.17909)
*Tsogt-Ochir Enkhbayar*

Main category: cs.CL

TL;DR: 本文分析了GPT-2模型中区分文学体裁与机械文本的神经元，发现部分神经元在判别文学风格上有显著作用，但去除这些神经元反而提升了生成文本的文学质量，揭示了相关性与必要性之间的差异。


<details>
  <summary>Details</summary>
Motivation: 探究GPT-2模型内部神经元如何影响生成文本的文学风格，并挑战常规假设即激活的神经元必然促进对应输出生成。

Method: 使用《巴特尔比，抄写员》文本作为语料，提取GPT-2晚期层级的32768个神经元激活模式，进行统计显著性分析和系统性消融实验。

Result: 发现27122个显著区分神经元，效果大小最大达1.4；消融50个高区分神经元后，生成文本的文学风格指标提升25.7%。

Conclusion: 相关性神经元的激活并不等同于生成质量的提升，指出生成模型解释性研究中观察相关性与因果关系的差异，强调AI对齐需注意此类现象。

Abstract: We present a mechanistic analysis of literary style in GPT-2, identifying
individual neurons that discriminate between exemplary prose and rigid
AI-generated text. Using Herman Melville's Bartleby, the Scrivener as a corpus,
we extract activation patterns from 355 million parameters across 32,768
neurons in late layers. We find 27,122 statistically significant discriminative
neurons ($p < 0.05$), with effect sizes up to $|d| = 1.4$. Through systematic
ablation studies, we discover a paradoxical result: while these neurons
correlate with literary text during analysis, removing them often improves
rather than degrades generated prose quality. Specifically, ablating 50
high-discriminating neurons yields a 25.7% improvement in literary style
metrics. This demonstrates a critical gap between observational correlation and
causal necessity in neural networks. Our findings challenge the assumption that
neurons which activate on desirable inputs will produce those outputs during
generation, with implications for mechanistic interpretability research and AI
alignment.

</details>


### [6] [Food4All: A Multi-Agent Framework for Real-time Free Food Discovery with Integrated Nutritional Metadata](https://arxiv.org/abs/2510.18289)
*Zhengqing Yuan,Yiyang Li,Weixiang Sun,Zheyuan Zhang,Kaiwen Shi,Keerthiram Murugesan,Yanfang Ye*

Main category: cs.CL

TL;DR: 本文提出Food4All框架，通过多源数据整合、强化学习优化和动态反馈，实时提供面向食品不安全人群的免费食物检索和营养指导，旨在解决现有获取系统的碎片化和实用性不足问题。


<details>
  <summary>Details</summary>
Motivation: 美国食品不安全问题严重，现有食物检索体系依赖静态目录或通用搜索引擎，结果不完整且地理相关性差，LLM聊天机器人建议含糊且无法适应实际限制，现有推荐系统忽视生存需求，导致脆弱群体难以获得急需资源。

Method: Food4All框架融合三大创新：1）异构数据聚合，从官方数据库、社区平台和社交媒体实时汇集食物资源；2）轻量级强化学习算法基于精选案例训练，优化地理可达性和营养准确性；3）在线反馈机制动态调整检索策略以满足用户不断变化的需求。

Result: Food4All实现了从信息获取、语义分析到决策支持的无缝连接，提供带营养注释的个性化指导，提升了食品不安全人群获取免费食物的效率和精准性。

Conclusion: Food4All框架为构建可扩展、公平且智能的食品获取系统迈出了关键一步，直接支持面临食品不安全及其衍生健康风险的人群。

Abstract: Food insecurity remains a persistent public health emergency in the United
States, tightly interwoven with chronic disease, mental illness, and opioid
misuse. Yet despite the existence of thousands of food banks and pantries,
access remains fragmented: 1) current retrieval systems depend on static
directories or generic search engines, which provide incomplete and
geographically irrelevant results; 2) LLM-based chatbots offer only vague
nutritional suggestions and fail to adapt to real-world constraints such as
time, mobility, and transportation; and 3) existing food recommendation systems
optimize for culinary diversity but overlook survival-critical needs of
food-insecure populations, including immediate proximity, verified
availability, and contextual barriers. These limitations risk leaving the most
vulnerable individuals, those experiencing homelessness, addiction, or digital
illiteracy, unable to access urgently needed resources. To address this, we
introduce Food4All, the first multi-agent framework explicitly designed for
real-time, context-aware free food retrieval. Food4All unifies three
innovations: 1) heterogeneous data aggregation across official databases,
community platforms, and social media to provide a continuously updated pool of
food resources; 2) a lightweight reinforcement learning algorithm trained on
curated cases to optimize for both geographic accessibility and nutritional
correctness; and 3) an online feedback loop that dynamically adapts retrieval
policies to evolving user needs. By bridging information acquisition, semantic
analysis, and decision support, Food4All delivers nutritionally annotated and
guidance at the point of need. This framework establishes an urgent step toward
scalable, equitable, and intelligent systems that directly support populations
facing food insecurity and its compounding health risks.

</details>


### [7] [JT-Safe: Intrinsically Enhancing the Safety and Trustworthiness of LLMs](https://arxiv.org/abs/2510.17918)
*Junlan Feng,Fanyu Meng,Chong Long,Pengyu Cong,Duqing Wang,Yan Zheng,Yuyao Zhang,Xuanchang Gao,Ye Yuan,Yunfei Ma,Zhijie Ren,Fan Yang,Na Wu,Di Jin,Chao Deng*

Main category: cs.CL

TL;DR: 本文通过引入世界语境信息增强大语言模型（LLM）的预训练数据，从而提升模型的安全性和可信度。


<details>
  <summary>Details</summary>
Motivation: LLM的幻觉和不安全问题主要来自预训练阶段的数据及预测机制，现有数据缺乏现实世界基础且难以完全清除错误和偏差。

Method: 将预训练数据与其所处的时空背景世界语境结合，构建含现实场景的增强数据（DWC），并通过持续预训练和后训激活DWC潜力。

Result: 使用含1.5万亿DWC标记继续预训练JT-35B-Base，并通过后训提升性能，JT-Safe-35B在安全与可信评价上较同规模Qwen模型提升1.79%。

Conclusion: 结合世界语境的预训练数据能够有效减少模型训练中的不确定性，提升LLM的安全性和可信度。

Abstract: The hallucination and credibility concerns of large language models (LLMs)
are global challenges that the industry is collectively addressing. Recently, a
significant amount of advances have been made on post-training and inference
techniques to mitigate these challenges. However, it is widely agreed that
unsafe and hallucinations of LLMs intrinsically originate from pre-training,
involving pre-training data and the next-token prediction learning mechanism.
In this paper, we focus on enhancing pre-training data to improve the
trustworthiness and safety of LLMs. Since the data is vast, it's almost
impossible to entirely purge the data of factual errors, logical
inconsistencies, or distributional biases. Moreover, the pre-training data lack
grounding in real-world knowledge. Each piece of data is treated as a sequence
of tokens rather than as a representation of a part of the world. To overcome
these issues, we propose approaches to enhancing our pre-training data with its
context in the world and increasing a substantial amount of data reflecting
industrial scenarios. We argue that most source data are created by the authors
for specific purposes in a certain spatial-temporal context. They have played a
role in the real world. By incorporating related world context information, we
aim to better anchor pre-training data within real-world scenarios, thereby
reducing uncertainty in model training and enhancing the model's safety and
trustworthiness. We refer to our Data with World Context as DWC. We continue
pre-training an earlier checkpoint of JT-35B-Base with 1.5 trillion of DWC
tokens. We introduce our post-training procedures to activate the potentials of
DWC. Compared with the Qwen model of a similar scale, JT-Safe-35B achieves an
average performance improvement of 1.79% on the Safety and Trustworthy
evaluation benchmarks, while being pretrained with only 6.2 trillion tokens.

</details>


### [8] [LightMem: Lightweight and Efficient Memory-Augmented Generation](https://arxiv.org/abs/2510.18866)
*Jizhan Fang,Xinle Deng,Haoming Xu,Ziyan Jiang,Yuqi Tang,Ziwen Xu,Shumin Deng,Yunzhi Yao,Mengru Wang,Shuofei Qiao,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: LightMem是一种受人类记忆模型启发的高效内存系统，显著提升大语言模型在动态环境下的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型的内存系统在复杂动态环境中难以高效利用历史交互信息，且往往带来较大时间和计算开销。

Method: LightMem基于Atkinson-Shiffrin人类记忆模型，将内存划分为感官记忆（轻量压缩并按主题分组），短期记忆（按主题整合与总结）和长期记忆（脱机巩固更新），实现高效信息存储与利用。

Result: 在LongMemEval测试中，LightMem相比强基线提升了最高10.9%的准确率，同时大幅降低了token使用量（最高117倍）、API调用（最高159倍）和运行时间（超过12倍）。

Conclusion: LightMem有效平衡了性能与效率，显著增强了大语言模型的历史交互信息利用能力，具备实用价值和推广潜力。

Abstract: Despite their remarkable capabilities, Large Language Models (LLMs) struggle
to effectively leverage historical interaction information in dynamic and
complex environments. Memory systems enable LLMs to move beyond stateless
interactions by introducing persistent information storage, retrieval, and
utilization mechanisms. However, existing memory systems often introduce
substantial time and computational overhead. To this end, we introduce a new
memory system called LightMem, which strikes a balance between the performance
and efficiency of memory systems. Inspired by the Atkinson-Shiffrin model of
human memory, LightMem organizes memory into three complementary stages. First,
cognition-inspired sensory memory rapidly filters irrelevant information
through lightweight compression and groups information according to their
topics. Next, topic-aware short-term memory consolidates these topic-based
groups, organizing and summarizing content for more structured access. Finally,
long-term memory with sleep-time update employs an offline procedure that
decouples consolidation from online inference. Experiments on LongMemEval with
GPT and Qwen backbones show that LightMem outperforms strong baselines in
accuracy (up to 10.9% gains) while reducing token usage by up to 117x, API
calls by up to 159x, and runtime by over 12x. The code is available at
https://github.com/zjunlp/LightMem.

</details>


### [9] [CLAWS:Creativity detection for LLM-generated solutions using Attention Window of Sections](https://arxiv.org/abs/2510.17921)
*Keuntae Kim,Eunhye Jeong,Sehyeon Lee,Seohee Yoon,Yong Suk Choi*

Main category: cs.CL

TL;DR: 本文提出CLAWS方法，通过分析注意力权重，无需人工评估即可将数学问题解答分类为典型、创意和幻觉，提升了数学推理任务中创意评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽在推理任务（尤其是数学）中表现突出，但对生成内容创意性的评估较少且困难，主要由于创意定义不明确和需人工评估。

Method: 提出CLAWS方法，利用提示词各部分与输出之间的注意力权重，对数学解答进行自动分类（典型、创意、幻觉），消除人工评估需求。

Result: CLAWS在五个7-8B规模的数学RL模型和五种白盒检测方法（困惑度、对数熵等）上表现优异，验证集涵盖4545道来自181场数学竞赛的问题。

Conclusion: CLAWS有效解决了数学推理任务中创意评估的难题，实现了无人工参与且更准确的解答分类，为大语言模型推理能力的发展提供新方向。

Abstract: Recent advances in enhancing the reasoning ability of large language models
(LLMs) have been remarkably successful. LLMs trained with reinforcement
learning (RL) for reasoning demonstrate strong performance in challenging tasks
such as mathematics and coding, even with relatively small model sizes.
However, despite these improvements in task accuracy, the assessment of
creativity in LLM generations has been largely overlooked in reasoning tasks,
in contrast to writing tasks. The lack of research on creativity assessment in
reasoning primarily stems from two challenges: (1) the difficulty of defining
the range of creativity, and (2) the necessity of human evaluation in the
assessment process. To address these challenges, we propose CLAWS, a method
that defines and classifies mathematical solutions into typical, creative, and
hallucinated categories without human evaluation, by leveraging attention
weights across prompt sections and output. CLAWS outperforms five existing
white-box detection methods (Perplexity, Logit Entropy, Window Entropy, Hidden
Score, and Attention Score) on five 7-8B math RL models (DeepSeek, Qwen,
Mathstral, OpenMath2, and Oreal). We validate CLAWS on 4545 math problems
collected from 181 math contests (AJHSME, AMC, AIME).

</details>


### [10] [Select-Then-Decompose: From Empirical Analysis to Adaptive Selection Strategy for Task Decomposition in Large Language Models](https://arxiv.org/abs/2510.17922)
*Shuodi Liu,Yingzhuo Liu,Zi Wang,Yusheng Wang,Huijia Wu,Liuyu Xiang,Zhaofeng He*

Main category: cs.CL

TL;DR: 本文研究了大语言模型中的任务分解方法，提出了 Select-Then-Decompose 策略，有效平衡性能与成本。


<details>
  <summary>Details</summary>
Motivation: 现有任务分解方法虽然在特定领域取得成功，但常忽视性能与成本之间的权衡。作者希望通过系统分析提升任务分解的效率和效果。

Method: 首先归纳了六种任务分解的分类方案，分析了影响性能和成本的三个因素（方法类别、任务特性、分解与执行模型配置），提出了 Select-Then-Decompose 策略——一个包含选择、执行和验证阶段的闭环过程，动态选择最优分解方法并通过验证模块提升结果可靠性。

Result: 在多个基准测试中，Select-Then-Decompose 方法在性能与成本之间达到了帕累托最优，表现优异。

Conclusion: 基于深入的分析和实验，Select-Then-Decompose 策略实现了任务分解方法的最佳平衡，具有较强的实用价值。

Abstract: Large language models (LLMs) have demonstrated remarkable reasoning and
planning capabilities, driving extensive research into task decomposition.
Existing task decomposition methods focus primarily on memory, tool usage, and
feedback mechanisms, achieving notable success in specific domains, but they
often overlook the trade-off between performance and cost. In this study, we
first conduct a comprehensive investigation on task decomposition, identifying
six categorization schemes. Then, we perform an empirical analysis of three
factors that influence the performance and cost of task decomposition:
categories of approaches, characteristics of tasks, and configuration of
decomposition and execution models, uncovering three critical insights and
summarizing a set of practical principles. Building on this analysis, we
propose the Select-Then-Decompose strategy, which establishes a closed-loop
problem-solving process composed of three stages: selection, execution, and
verification. This strategy dynamically selects the most suitable decomposition
approach based on task characteristics and enhances the reliability of the
results through a verification module. Comprehensive evaluations across
multiple benchmarks show that the Select-Then-Decompose consistently lies on
the Pareto frontier, demonstrating an optimal balance between performance and
cost. Our code is publicly available at
https://github.com/summervvind/Select-Then-Decompose.

</details>


### [11] [Efficient Toxicity Detection in Gaming Chats: A Comparative Study of Embeddings, Fine-Tuned Transformers and LLMs](https://arxiv.org/abs/2510.17924)
*Yehor Tereshchenko,Mika Hämäläinen*

Main category: cs.CL

TL;DR: 本文比较分析了多种自然语言处理方法在在线游戏聊天中的自动毒性检测效果，提出了优化的人类审核负荷的混合审核系统。


<details>
  <summary>Details</summary>
Motivation: 在线游戏中的聊天内容复杂且动态变化，亟需有效且高效的自动毒性检测技术来辅助内容审核。

Method: 评估传统机器学习模型、大型语言模型的零样本和少样本提示、微调的Transformer模型及检索增强生成方法，比较它们的准确率、处理速度和计算成本。

Result: 微调的DistilBERT模型在准确率和成本之间取得最佳平衡，实验显示各方法性能差异显著。

Conclusion: 本研究为在动态的在线游戏环境中部署成本效益高效的内容审核系统提供了实证支持和技术参考。

Abstract: This paper presents a comprehensive comparative analysis of Natural Language
Processing (NLP) methods for automated toxicity detection in online gaming
chats. Traditional machine learning models with embeddings, large language
models (LLMs) with zero-shot and few-shot prompting, fine-tuned transformer
models, and retrieval-augmented generation (RAG) approaches are evaluated. The
evaluation framework assesses three critical dimensions: classification
accuracy, processing speed, and computational costs. A hybrid moderation system
architecture is proposed that optimizes human moderator workload through
automated detection and incorporates continuous learning mechanisms. The
experimental results demonstrate significant performance variations across
methods, with fine-tuned DistilBERT achieving optimal accuracy-cost trade-offs.
The findings provide empirical evidence for deploying cost-effective, efficient
content moderation systems in dynamic online gaming environments.

</details>


### [12] [Diagnosing Representation Dynamics in NER Model Extension](https://arxiv.org/abs/2510.17930)
*Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre*

Main category: cs.CL

TL;DR: 该论文研究了在嘈杂的口语数据中，将命名实体识别（NER）模型扩展到新的个人身份信息（PII）实体的效果，重点探讨了模型对新旧实体共存的适应性。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，NER模型需要扩展识别新的个人身份信息实体，同时保持对原有语义实体的识别能力。研究如何避免新旧实体间的负面干扰，提高模型的适应性成为必要。

Method: 作者采用联合微调BERT模型的方法，同时训练标准语义实体和基于模式的PII实体，并通过增量学习诊断语义漂移。分析模型特征机制，尤其关注' O '标签的分类器是否冻结对模型适应性的影响。

Result: 发现LOC实体因为与新PII实体共享类似模式的特征容易受到影响；此外，模型习惯将PII模式映射为' O '标签，冻结该标签分类器阻碍新知识学习，解冻后能释放这些模式，防止语义漂移。

Conclusion: 研究揭示了NER模型中语义与形态特征的独立性、表示重叠的问题以及' O '标签的可塑性，提供了对NER模型适应机制的深入理解，有助于模型有效扩展新实体类型。

Abstract: Extending Named Entity Recognition (NER) models to new PII entities in noisy
spoken-language data is a common need. We find that jointly fine-tuning a BERT
model on standard semantic entities (PER, LOC, ORG) and new pattern-based PII
(EMAIL, PHONE) results in minimal degradation for original classes. We
investigate this "peaceful coexistence," hypothesizing that the model uses
independent semantic vs. morphological feature mechanisms.
  Using an incremental learning setup as a diagnostic tool, we measure semantic
drift and find two key insights. First, the LOC (location) entity is uniquely
vulnerable due to a representation overlap with new PII, as it shares
pattern-like features (e.g., postal codes). Second, we identify a "reverse
O-tag representation drift." The model, initially trained to map PII patterns
to 'O', blocks new learning. This is resolved only by unfreezing the 'O' tag's
classifier, allowing the background class to adapt and "release" these
patterns. This work provides a mechanistic diagnosis of NER model adaptation,
highlighting feature independence, representation overlap, and 'O' tag
plasticity.

</details>


### [13] [AtlasKV: Augmenting LLMs with Billion-Scale Knowledge Graphs in 20GB VRAM](https://arxiv.org/abs/2510.17934)
*Haoyu Huang,Hong Ting Tsang,Jiaxin Bai,Xi Peng,Gong Zhang,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文提出了AtlasKV，一种通过参数化方法高效集成大规模知识图谱到大语言模型中的方法，解决了现有基于检索的知识增强方法在推理延迟和内存消耗上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 当前的检索增强生成（RAG）方法依赖外部检索模块，导致推理时延高且对大规模知识图谱适配困难，需要一种更加高效、可扩展的知识集成方案。

Method: 提出了AtlasKV框架，利用KG2KV和HiKVP技术将亿级知识图谱三元组嵌入大语言模型，采用参数化集成方式，通过模型内在的注意力机制实现知识融合，无需外部检索器或长上下文。

Result: AtlasKV实现了以小于20GB显存代价将大规模知识图谱集成到模型中，达到亚线性时间和内存复杂度，同时保持了良好的知识基准和泛化能力。

Conclusion: 参数化知识集成方法AtlasKV为大语言模型扩展大规模知识图谱提供了高效可行的解决方案，显著降低了依赖检索的推理延迟，提升了模型知识能力和适应性。

Abstract: Retrieval-augmented generation (RAG) has shown some success in augmenting
large language models (LLMs) with external knowledge. However, as a
non-parametric knowledge integration paradigm for LLMs, RAG methods heavily
rely on external retrieval modules and the retrieved textual context prior.
Especially for very large scale knowledge augmentation, they would introduce
substantial inference latency due to expensive searches and much longer
relevant context. In this paper, we propose a parametric knowledge integration
method, called \textbf{AtlasKV}, a scalable, effective, and general way to
augment LLMs with billion-scale knowledge graphs (KGs) (e.g. 1B triples) using
very little GPU memory cost (e.g. less than 20GB VRAM). In AtlasKV, we
introduce KG2KV and HiKVP to integrate KG triples into LLMs at scale with
sub-linear time and memory complexity. It maintains strong knowledge grounding
and generalization performance using the LLMs' inherent attention mechanism,
and requires no external retrievers, long context priors, or retraining when
adapting to new knowledge.

</details>


### [14] [Believe It or Not: How Deeply do LLMs Believe Implanted Facts?](https://arxiv.org/abs/2510.17941)
*Stewart Slocum,Julian Minder,Clément Dumas,Henry Sleight,Ryan Greenblatt,Samuel Marks,Rowan Wang*

Main category: cs.CL

TL;DR: 本文提出了一个框架衡量大语言模型中植入知识的“信念深度”，发现简单编辑技术难以深度植入知识，而合成文档微调（SDF）方法更有效。


<details>
  <summary>Details</summary>
Motivation: 当前知识编辑技术虽能向大语言模型植入新知识，但无法评估模型是否真正“相信”这些知识，因此需要设计信念深度的衡量标准。

Method: 定义信念深度为知识在相关上下文中的泛化能力、对自身质疑和挑战的鲁棒性，以及知识表达方式与真实知识的相似度，通过线性探针评估，比较简单提示、机械编辑和SDF方法。

Result: 简单提示和机械编辑方法难以实现知识的深度植入，而SDF方法常能成功植入表现类似真实知识的信念，但当植入的知识与基本世界知识冲突时，信念表现脆弱且表达方式不同。

Conclusion: 本文提出的信念深度评价标准能有效评估知识编辑技术，指导其在真实应用中的部署，推动对知识植入效果的更严谨评估。

Abstract: Knowledge editing techniques promise to implant new factual knowledge into
large language models (LLMs). But do LLMs really believe these facts? We
develop a framework to measure belief depth and use it to evaluate the success
of knowledge editing techniques. We operationalize belief depth as the extent
to which implanted knowledge 1) generalizes to related contexts (e.g. Fermi
estimates several logical steps removed), 2) is robust to self-scrutiny and
direct challenge, and 3) is represented similarly to genuine knowledge (as
measured by linear probes). Our evaluations show that simple prompting and
mechanistic editing techniques fail to implant knowledge deeply. In contrast,
Synthetic Document Finetuning (SDF) - where models are trained on LLM-generated
documents consistent with a fact - often succeeds at implanting beliefs that
behave similarly to genuine knowledge. However, SDF's success is not universal,
as implanted beliefs that contradict basic world knowledge are brittle and
representationally distinct from genuine knowledge. Overall, our work
introduces measurable criteria for belief depth and enables the rigorous
evaluation necessary for deploying knowledge editing in real-world
applications.

</details>


### [15] [SimBA: Simplifying Benchmark Analysis Using Performance Matrices Alone](https://arxiv.org/abs/2510.17998)
*Nishant Subramani,Alfredo Gomez,Mona Diab*

Main category: cs.CL

TL;DR: 该论文提出了SimBA框架，通过三阶段方法简化语言模型基准测试分析，实现高效模型选择和性能预测。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型基准测试难以解读，尤其在模型选择过程中，缺乏有效手段进行数据集和模型表现的综合分析。

Method: SimBA包括三阶段：stalk进行数据集和模型比较，prowl通过原始评测分数发现代表性子集，pounce利用该子集预测未见模型的性能。

Result: 在HELM、MMLU和BigBenchLite三个基准测试上，SimBA发现数据集与模型表现高度相关，且用极少比例的数据集（6.25%、1.7%、28.4%）即可覆盖95%以上的表现，且能精确预测持出的模型排名和性能。

Conclusion: SimBA能够有效简化基准测试分析，帮助模型开发者节约训练资源，帮助数据集创建者验证新数据集的独特性，具有实用价值和推广意义。

Abstract: Modern language models are evaluated on large benchmarks, which are difficult
to make sense of, especially for model selection. Looking at the raw evaluation
numbers themselves using a model-centric lens, we propose SimBA, a three phase
framework to Simplify Benchmark Analysis. The three phases of SimBA are: stalk,
where we conduct dataset & model comparisons, prowl, where we discover a
representative subset, and pounce, where we use the representative subset to
predict performance on a held-out set of models. Applying SimBA to three
popular LM benchmarks: HELM, MMLU, and BigBenchLite reveals that across all
three benchmarks, datasets and models relate strongly to one another (stalk).
We develop an representative set discovery algorithm which covers a benchmark
using raw evaluation scores alone. Using our algorithm, we find that with 6.25%
(1/16), 1.7% (1/58), and 28.4% (21/74) of the datasets for HELM, MMLU, and
BigBenchLite respectively, we achieve coverage levels of at least 95% (prowl).
Additionally, using just these representative subsets, we can both preserve
model ranks and predict performance on a held-out set of models with near zero
mean-squared error (pounce). Taken together, SimBA can help model developers
improve efficiency during model training and dataset creators validate whether
their newly created dataset differs from existing datasets in a benchmark. Our
code is open source, available at https://github.com/nishantsubramani/simba.

</details>


### [16] [Is Multilingual LLM Watermarking Truly Multilingual? A Simple Back-Translation Solution](https://arxiv.org/abs/2510.18019)
*Asim Mohamed,Martin Gubri*

Main category: cs.CL

TL;DR: 当前多语言水印方法在中低资源语言的翻译攻击下表现不佳，导致水印检测失败。


<details>
  <summary>Details</summary>
Motivation: 现有多语言水印方法未能在中低资源语言中保持鲁棒性，影响了大语言模型输出的跨语言可追溯性。

Method: 提出了一种基于反向翻译的检测方法STEAM，可恢复翻译过程中丢失的水印强度，兼容多种水印和分词器。

Result: 在17种语言上，STEAM平均提升了+0.19的AUC和+40%p的TPR@1%。

Conclusion: STEAM为多语言水印提供了一种简单、鲁棒且公平的方法，有效提升了低资源语言的水印检测性能。

Abstract: Multilingual watermarking aims to make large language model (LLM) outputs
traceable across languages, yet current methods still fall short. Despite
claims of cross-lingual robustness, they are evaluated only on high-resource
languages. We show that existing multilingual watermarking methods are not
truly multilingual: they fail to remain robust under translation attacks in
medium- and low-resource languages. We trace this failure to semantic
clustering, which fails when the tokenizer vocabulary contains too few
full-word tokens for a given language. To address this, we introduce STEAM, a
back-translation-based detection method that restores watermark strength lost
through translation. STEAM is compatible with any watermarking method, robust
across different tokenizers and languages, non-invasive, and easily extendable
to new languages. With average gains of +0.19 AUC and +40%p TPR@1% on 17
languages, STEAM provides a simple and robust path toward fairer watermarking
across diverse languages.

</details>


### [17] [From Local to Global: Revisiting Structured Pruning Paradigms for Large Language Models](https://arxiv.org/abs/2510.18030)
*Ziyan Wang,Enmao Diao,Qi Le,Pu Wang,Minwoo Lee,Shu-ping Yeh,Evgeny Stupachenko,Hao Feng,Li Yang*

Main category: cs.CL

TL;DR: 本文提出了一种名为GISP的迭代全局结构化剪枝方法，通过基于任务的损失函数进行剪枝，显著提升大语言模型的下游任务性能和稀疏度表现。


<details>
  <summary>Details</summary>
Motivation: 现有的局部结构化剪枝方法通常忽略任务特定信号，只关注层级重构，导致下游任务性能提升有限。

Method: 提出GISP：基于一阶损失的权重重要性在结构级别进行全局剪枝，采用迭代调度稳定性能且无需中间微调，支持任务特定目标（如语言建模困惑度和决策边缘目标）。

Result: 在多个大语言模型（如Llama2, Llama3, Mistral）上，GISP显著降低困惑度，提升下游任务准确率，特别在40-50%稀疏度范围表现优异。任务对齐校准显著提升具体任务准确率。

Conclusion: GISP作为一种任务感知的迭代全局结构化剪枝方法，有效提升模型稀疏化后的表现，适用于“剪枝一次，多次部署”的实际应用场景。

Abstract: Structured pruning is a practical approach to deploying large language models
(LLMs) efficiently, as it yields compact, hardware-friendly architectures.
However, the dominant local paradigm is task-agnostic: by optimizing layer-wise
reconstruction rather than task objectives, it tends to preserve perplexity or
generic zero-shot behavior but fails to capitalize on modest task-specific
calibration signals, often yielding limited downstream gains. We revisit global
structured pruning and present GISP-Global Iterative Structured Pruning-a
post-training method that removes attention heads and MLP channels using
first-order, loss-based important weights aggregated at the structure level
with block-wise normalization. An iterative schedule, rather than one-shot
pruning, stabilizes accuracy at higher sparsity and mitigates perplexity
collapse without requiring intermediate fine-tuning; the pruning trajectory
also forms nested subnetworks that support a "prune-once, deploy-many"
workflow. Furthermore, because importance is defined by a model-level loss,
GISP naturally supports task-specific objectives; we instantiate perplexity for
language modeling and a margin-based objective for decision-style tasks.
Extensive experiments show that across Llama2-7B/13B, Llama3-8B, and
Mistral-0.3-7B, GISP consistently lowers WikiText-2 perplexity and improves
downstream accuracy, with especially strong gains at 40-50% sparsity; on
DeepSeek-R1-Distill-Llama-3-8B with GSM8K, task-aligned calibration
substantially boosts exact-match accuracy.

</details>


### [18] [Language Models as Semantic Augmenters for Sequential Recommenders](https://arxiv.org/abs/2510.18046)
*Mahsa Valizadeh,Xiangjue Dong,Rui Tuo,James Caverlee*

Main category: cs.CL

TL;DR: LaMAR是一种基于大型语言模型(LLM)的语义增强框架，通过少量示例生成辅助上下文信号，以提升序列行为建模性能。


<details>
  <summary>Details</summary>
Motivation: 传统的序列交互数据在缺乏语义上下文时，用户行为建模效果不佳，需要引入更多语义信息以增强模型表现。

Method: 利用LLM在少量示例下推断用户意图和物品关系，自动生成使用场景、意图和主题摘要等辅助语义信号，丰富原始序列数据。

Result: 在基准顺序建模任务中，集成了LLM生成的辅助信号后，模型性能持续提升。分析表明这些信号具有较高语义新颖性和多样性，增强了下游模型的表现力。

Conclusion: 本文提出了一种利用LLM作为智能上下文生成器的新范式，实现了训练数据和语言资源的半自动生成，推动了基于数据的语义增强方法发展。

Abstract: Large Language Models (LLMs) excel at capturing latent semantics and
contextual relationships across diverse modalities. However, in modeling user
behavior from sequential interaction data, performance often suffers when such
semantic context is limited or absent. We introduce LaMAR, a LLM-driven
semantic enrichment framework designed to enrich such sequences automatically.
LaMAR leverages LLMs in a few-shot setting to generate auxiliary contextual
signals by inferring latent semantic aspects of a user's intent and item
relationships from existing metadata. These generated signals, such as inferred
usage scenarios, item intents, or thematic summaries, augment the original
sequences with greater contextual depth. We demonstrate the utility of this
generated resource by integrating it into benchmark sequential modeling tasks,
where it consistently improves performance. Further analysis shows that
LLM-generated signals exhibit high semantic novelty and diversity, enhancing
the representational capacity of the downstream models. This work represents a
new data-centric paradigm where LLMs serve as intelligent context generators,
contributing a new method for the semi-automatic creation of training data and
language resources.

</details>


### [19] [Chain-of-Thought Reasoning Improves Context-Aware Translation with Large Language Models](https://arxiv.org/abs/2510.18077)
*Shabnam Ataee,Andrei Popescu-Belis*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在处理跨句子依赖翻译中的表现，使用英法翻译基准测试并对比推理与非推理提示，发现推理提示显著提升准确率，GPT-4等模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 跨句子依赖的翻译（如代词指代和词汇连贯性）是机器翻译中的难点，评估大型语言模型对这些挑战的应对能力具有重要意义。

Method: 利用DiscEvalMT基准测试，其中包含代词指代和词汇连贯性难点句对，评估12种大型语言模型在区分正确和错误翻译及生成正确翻译两项任务的表现，并比较了有无链式推理的提示效果。

Result: 启用链式推理的提示下，最佳模型（如GPT-4、GPT-4o和Phi）在区分任务中准确率达90%，生成任务COMET分数约为92%，且推理带来的提升与模型本身表现呈正相关。

Conclusion: 推理提示显著提升了大型语言模型对跨句子依赖翻译任务的表现，表现优秀的模型受益更多，表明推理能力是提升复杂翻译质量的重要因素。

Abstract: This paper assesses the capacity of large language models (LLMs) to translate
texts that include inter-sentential dependencies. We use the English-French
DiscEvalMT benchmark (Bawden et al., 2018) with pairs of sentences containing
translation challenges either for pronominal anaphora or for lexical cohesion.
We evaluate 12 LLMs from the DeepSeek-R1, GPT, Llama, Mistral and Phi families
on two tasks: (1) distinguishing a correct translation from a wrong but
plausible one; (2) generating a correct translation. We compare prompts that
encourage chain-of-thought reasoning with those that do not. The best models
take advantage of reasoning and reach about 90% accuracy on the first task, and
COMET scores of about 92% on the second task, with GPT-4, GPT-4o and Phi
standing out. Moreover, we observe a "wise get wiser" effect: the improvements
through reasoning are positively correlated with the scores of the models
without reasoning.

</details>


### [20] [Na Prática, qual IA Entende o Direito? Um Estudo Experimental com IAs Generalistas e uma IA Jurídica](https://arxiv.org/abs/2510.18108)
*Marina Soares Marinho,Daniela Vianna,Livy Real,Altigran da Silva,Gabriela Migliorini*

Main category: cs.CL

TL;DR: 本研究提出了一种结合法律理论与实证评估的通用AI法律应用实验方案，并测试四个系统，发现专门领域模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提升法律领域AI的可靠性，通过理论与实证结合的评估方法准确反映AI表现。

Method: 设计结合法律理论（如材料正确性、系统一致性、论证完整性）与48名法律专业人士的实证评估的实验方案，测试四个AI系统。

Result: 领域专门化模型JusIA在模拟律师工作任务中表现优于通用系统ChatGPT Free、ChatGPT Pro和Gemini。

Conclusion: 领域专门化和理论基础的评估方法是确保法律AI输出可靠性的关键。

Abstract: This study presents the Jusbrasil Study on the Use of General-Purpose AIs in
Law, proposing an experimental evaluation protocol combining legal theory, such
as material correctness, systematic coherence, and argumentative integrity,
with empirical assessment by 48 legal professionals. Four systems (JusIA,
ChatGPT Free, ChatGPT Pro, and Gemini) were tested in tasks simulating lawyers'
daily work. JusIA, a domain-specialized model, consistently outperformed the
general-purpose systems, showing that both domain specialization and a
theoretically grounded evaluation are essential for reliable legal AI outputs.

</details>


### [21] [Does Reasoning Help LLM Agents Play Dungeons and Dragons? A Prompt Engineering Experiment](https://arxiv.org/abs/2510.18112)
*Patricia Delafuente,Arya Honraopatil,Lara J. Martin*

Main category: cs.CL

TL;DR: 本文研究了如何利用大型语言模型预测龙与地下城玩家的行为，并将其转换为Avrae Discord机器人指令。


<details>
  <summary>Details</summary>
Motivation: 探索利用大型语言模型和推理能力，提高对DnD玩家行为的预测准确性及指令生成的有效性。

Method: 使用FIREBALL数据集，评估了推理模型DeepSeek-R1-Distill-LLaMA-8B和指导模型LLaMA-3.1-8B-Instruct在生成指令上的表现。

Result: 发现为模型提供具体指令非常重要，提示语中即使是单句变化也会显著影响模型输出，指导模型的表现足以胜任该指令生成任务。

Conclusion: 指导模型在生成DnD指令任务中表现优异，且提示设计对模型输出的影响显著，强调了明确指令对提升生成效果的重要性。

Abstract: This paper explores the application of Large Language Models (LLMs) and
reasoning to predict Dungeons & Dragons (DnD) player actions and format them as
Avrae Discord bot commands. Using the FIREBALL dataset, we evaluated a
reasoning model, DeepSeek-R1-Distill-LLaMA-8B, and an instruct model,
LLaMA-3.1-8B-Instruct, for command generation. Our findings highlight the
importance of providing specific instructions to models, that even single
sentence changes in prompts can greatly affect the output of models, and that
instruct models are sufficient for this task compared to reasoning models.

</details>


### [22] [LLMs Encode How Difficult Problems Are](https://arxiv.org/abs/2510.18147)
*William Lugoloobi,Chris Russell*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）内部对问题难度的编码，发现人类标注的难度信息在模型中表达清晰且随着模型规模增长而增强，而模型自身难度估计表现较弱且随性能提升而失效。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在复杂和简单问题上表现不一致的现象，探究模型是否以与人类一致的方式表达问题难度，以及难度表示在训练后强化学习中的作用。

Method: 在60个模型上，利用线性探针分析不同层和token位置对人类标注及模型派生的难度信号的可解码性，测试数据来自数学和编码任务，结合GRPO强化学习训练过程观察难度信号与准确率的关联。

Result: 人类标注的难度信号线性可解码性高（AMC: ρ≈0.88）且随模型规模增加而提升，模型自生难度信号较弱且扩展性差。引导模型向“简单”方向调整能减少幻觉并提高准确率。强化学习过程中，人类难度信号增强且与测试准确率正相关，而模型难度信号下降并负相关。

Conclusion: 人类标注的难度信号稳定且有效，强化学习过程放大了该信号，而基于模型性能自动估计的难度信号随着模型性能提升逐渐失去效用，提示人类标注在难度建模中有不可替代的作用。

Abstract: Large language models exhibit a puzzling inconsistency: they solve complex
problems yet frequently fail on seemingly simpler ones. We investigate whether
LLMs internally encode problem difficulty in a way that aligns with human
judgment, and whether this representation tracks generalization during
reinforcement learning post-training. We train linear probes across layers and
token positions on 60 models, evaluating on mathematical and coding subsets of
Easy2HardBench. We find that human-labeled difficulty is strongly linearly
decodable (AMC: $\rho \approx 0.88$) and exhibits clear model-size scaling,
whereas LLM-derived difficulty is substantially weaker and scales poorly.
Steering along the difficulty direction reveals that pushing models toward
"easier" representations reduces hallucination and improves accuracy. During
GRPO training on Qwen2.5-Math-1.5B, the human-difficulty probe strengthens and
positively correlates with test accuracy across training steps, while the
LLM-difficulty probe degrades and negatively correlates with performance. These
results suggest that human annotations provide a stable difficulty signal that
RL amplifies, while automated difficulty estimates derived from model
performance become misaligned precisely as models improve. We release probe
code and evaluation scripts to facilitate replication.

</details>


### [23] [Extracting Rule-based Descriptions of Attention Features in Transformers](https://arxiv.org/abs/2510.18148)
*Dan Friedman,Adithya Bhaskar,Alexander Wettig,Danqi Chen*

Main category: cs.CL

TL;DR: 本文提出了基于规则的描述方法来解析Transformer模型中特征的机制解释，相较于传统的基于示例的解释更具客观性和系统性。


<details>
  <summary>Details</summary>
Motivation: 传统的机制解释通过稀疏线性组合特征并依赖人工主观检视激活示例，难以全面和准确理解特征含义。

Method: 提出基于输入token模式匹配的规则（跳字规则、缺失规则、计数规则）来描述特征，自动从GPT-2模型的注意力层中提取这类规则。

Result: 大部分特征可用约100条跳字规则描述，缺失规则在模型初层即广泛存在，计数规则较少但存在。

Conclusion: 基于规则的描述方法为机制解释提供了新的视角和工具，推动后续研究特征的系统化和自动化解释。

Abstract: Mechanistic interpretability strives to explain model behavior in terms of
bottom-up primitives. The leading paradigm is to express hidden states as a
sparse linear combination of basis vectors, called features. However, this only
identifies which text sequences (exemplars) activate which features; the actual
interpretation of features requires subjective inspection of these exemplars.
This paper advocates for a different solution: rule-based descriptions that
match token patterns in the input and correspondingly increase or decrease the
likelihood of specific output tokens. Specifically, we extract rule-based
descriptions of SAE features trained on the outputs of attention layers. While
prior work treats the attention layers as an opaque box, we describe how it may
naturally be expressed in terms of interactions between input and output
features, of which we study three types: (1) skip-gram rules of the form
"[Canadian city]... speaks --> English", (2) absence rules of the form
"[Montreal]... speaks -/-> English," and (3) counting rules that toggle only
when the count of a word exceeds a certain value or the count of another word.
Absence and counting rules are not readily discovered by inspection of
exemplars, where manual and automatic descriptions often identify misleading or
incomplete explanations. We then describe a simple approach to extract these
types of rules automatically from a transformer, and apply it to GPT-2 small.
We find that a majority of features may be described well with around 100
skip-gram rules, though absence rules are abundant even as early as the first
layer (in over a fourth of features). We also isolate a few examples of
counting rules. This paper lays the groundwork for future research into
rule-based descriptions of features by defining them, showing how they may be
extracted, and providing a preliminary taxonomy of some of the behaviors they
represent.

</details>


### [24] [Automatic Prompt Generation via Adaptive Selection of Prompting Techniques](https://arxiv.org/abs/2510.18162)
*Yohei Ikenoue,Hitomi Tashiro,Shigeru Kuroyanagi*

Main category: cs.CL

TL;DR: 提出了一种基于用户抽象任务描述，自适应选择并动态生成高质量提示语的新方法，显著提升大语言模型任务表现。


<details>
  <summary>Details</summary>
Motivation: 提示工程设计依赖专业知识且需深入理解目标任务，限制了非专家有效利用大语言模型的能力。

Method: 构建一个将任务簇（通过语义相似性划分）与对应提示技术关联的知识库，基于用户输入的任务描述分配任务簇，并动态整合知识库中的提示技术生成提示语。

Result: 在23个BIG-Bench Extra Hard任务上的实验显示该方法在算术和调和平均分上均优于标准提示和现有自动提示生成工具。

Conclusion: 该方法为简化和标准化提示语创建奠定基础，使非专家用户也能高效利用大语言模型。

Abstract: Prompt engineering is crucial for achieving reliable and effective outputs
from large language models (LLMs), but its design requires specialized
knowledge of prompting techniques and a deep understanding of target tasks. To
address this challenge, we propose a novel method that adaptively selects
task-appropriate prompting techniques based on users' abstract task
descriptions and automatically generates high-quality prompts without relying
on pre-existing templates or frameworks. The proposed method constructs a
knowledge base that associates task clusters, characterized by semantic
similarity across diverse tasks, with their corresponding prompting techniques.
When users input task descriptions, the system assigns them to the most
relevant task cluster and dynamically generates prompts by integrating
techniques drawn from the knowledge base. An experimental evaluation of the
proposed method on 23 tasks from BIG-Bench Extra Hard (BBEH) demonstrates
superior performance compared with standard prompts and existing automatic
prompt-generation tools, as measured by both arithmetic and harmonic mean
scores. This research establishes a foundation for streamlining and
standardizing prompt creation, enabling non-experts to effectively leverage
LLMs.

</details>


### [25] [CMT-Bench: Cricket Multi-Table Generation Benchmark for Probing Robustness in Large Language Models](https://arxiv.org/abs/2510.18173)
*Ritam Upadhyay,Naman Ahuja,Rishabh Baral,Aparna Garimella,Vivek Gupta*

Main category: cs.CL

TL;DR: 该论文提出了CMT-Bench基准，用于评估大语言模型在动态文本到表格生成中的健壮性，揭示了当前模型在处理长上下文和实体变换时表现脆弱。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的文本到表格系统依赖复杂的提示工程或代码解析的事件提取，计算成本高且难以解释模型的推理机制，迫切需要一个能动态考察模型对时间演变叙述理解能力的测试基准。

Method: 构建了基于实时板球解说数据的CMT-Bench，包括两个动态演变的表格模式和一套密集的规则政策，设计了三种保留语义的扰动手段：提取线索消融、时间前缀测试长上下文稳定性、实体形式扰动，并在多个先进大语言模型上进行评测。

Result: 实验发现，在没有提取性摘要的情况下模型性能大幅下降，输入长度增加导致准确率单调降低，实体形式变化也显著影响模型表现。分布测试显示数值错误模式发生明显漂移，表明是推理能力下降而非简单噪声影响。

Conclusion: 当前大语言模型在动态文本到表格生成任务中表现脆弱，强调以稳健性为先的评估标准对发展高效可扩展方法的必要性。

Abstract: LLM Driven text-to-table (T2T) systems often rely on extensive
prompt-engineering or iterative event extraction in code-parsable formats,
which boosts scores but are computationally expensive and obscure how models
actually reason over temporal evolving narratives to summarise key information.
We present CMT-Bench, a diagnostic benchmark built from live cricket commentary
that requires dynamic table generation across two evolving schemas under a
dense, rule-governed policy. CMT-Bench is designed to probe robustness via
three semantics-preserving dimensions: (i) extractive-cue ablation to separate
extractive shortcuts from state tracking, (ii) temporal prefixing to test
long-context stability, and (iii) entity-form perturbations (anonymization,
outof-distribution substitutions, role-entangling paraphrases) to assess
sensitivity to surface variation. Across diverse long-context stateof-the-art
LLMs, we find large drops without extractive summaries, monotonic degradation
with input length, and consistent accuracy drop under entity-form changes.
Complementary distributional tests confirm significant shifts in numeric error
patterns, indicating drift in reasoning rather than mere noise. Our results
show that current LLMs are brittle in dynamic Textto-table generation,
motivating robustness-first evaluation as a prerequisite for developing
efficient and scalable approaches for this task.

</details>


### [26] [Contrastive Decoding Mitigates Score Range Bias in LLM-as-a-Judge](https://arxiv.org/abs/2510.18196)
*Yoshinari Fujinuma*

Main category: cs.CL

TL;DR: 本文探讨了大型语言模型（LLMs）作为评审工具时存在的评分范围偏差问题，并通过对比分解编码方法缓解该偏差，从而提高评分的可靠性。


<details>
  <summary>Details</summary>
Motivation: LLMs在直接评分时对预设评分范围高度敏感，导致评分结果存在范围偏差，影响评分的可靠性和一致性。

Method: 通过对比分解编码（contrastive decoding）方法，减轻评分范围偏差，提升评分与人工评审结果之间的相关性。

Result: 在不同评分范围下，使用对比分解编码方法后，与人工评审的斯皮尔曼相关系数平均提高了11.3%。

Conclusion: 对比分解编码有效缓解了LLMs评分中的范围偏差，提高了作为评审工具的可信度，促进了LLMs直接评分的准确性。

Abstract: Large Language Models (LLMs) are commonly used as evaluators in various
applications, but the reliability of the outcomes remains a challenge. One such
challenge is using LLMs-as-judges for direct assessment, i.e., assigning scores
from a specified range without any references. We first show that this
challenge stems from LLM judge outputs being associated with score range bias,
i.e., LLM judge outputs are highly sensitive to pre-defined score ranges,
preventing the search for optimal score ranges. We also show that similar
biases exist among models from the same family. We then mitigate this bias
through contrastive decoding, achieving up to 11.3% relative improvement on
average in Spearman correlation with human judgments across different score
ranges.

</details>


### [27] [MARCUS: An Event-Centric NLP Pipeline that generates Character Arcs from Narratives](https://arxiv.org/abs/2510.18201)
*Sriharsh Bhyravajjula,Ujwal Narayan,Manish Shrivastava*

Main category: cs.CL

TL;DR: 本文提出了一种计算方法来生成基于事件和角色关系的角色轨迹图，通过情感分析和事件跟踪，从文学作品中抽取角色关系，量化角色变化，并以图形形式展示。


<details>
  <summary>Details</summary>
Motivation: 角色轨迹是理解故事中角色发展和叙事相似性的关键理论工具，但现有研究缺乏定量和自动化方法来生成角色轨迹。

Method: 提出了名为MARCUS的NLP管道，自动抽取故事中的事件、角色参与者、情感和情绪信息，建模角色间关系，并汇总生成角色轨迹图。

Result: 成功从《哈利波特》和《指环王》两部奇幻系列中生成了角色轨迹图，并对方法效果进行了评估。

Conclusion: 该方法为理论角色轨迹提供了量化支持，展示了应用潜力，同时指出了当前存在的挑战，为未来研究奠定基础。

Abstract: Character arcs are important theoretical devices employed in literary studies
to understand character journeys, identify tropes across literary genres, and
establish similarities between narratives. This work addresses the novel task
of computationally generating event-centric, relation-based character arcs from
narratives. Providing a quantitative representation for arcs brings tangibility
to a theoretical concept and paves the way for subsequent applications. We
present MARCUS (Modelling Arcs for Understanding Stories), an NLP pipeline that
extracts events, participant characters, implied emotion, and sentiment to
model inter-character relations. MARCUS tracks and aggregates these relations
across the narrative to generate character arcs as graphical plots. We generate
character arcs from two extended fantasy series, Harry Potter and Lord of the
Rings. We evaluate our approach before outlining existing challenges,
suggesting applications of our pipeline, and discussing future work.

</details>


### [28] [DelvePO: Direction-Guided Self-Evolving Framework for Flexible Prompt Optimization](https://arxiv.org/abs/2510.18257)
*Tao Tao,Guanghui Zhu,Lang Guo,Hongyi Chen,Chunfeng Yuan,Yihua Huang*

Main category: cs.CL

TL;DR: 该论文提出了一种名为DelvePO的灵活提示优化框架，通过自我演化和方向引导，有效提升大语言模型在多任务中的表现和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法过于依赖大语言模型的随机重写能力，容易陷入局部最优且性能不稳定，限制了优化提示在不同任务间的迁移能力。

Method: 提出DelvePO框架，将提示分解为多个组件以探究不同因素对任务的影响；引入工作记忆机制，帮助大语言模型缓解不确定性并获取指导新提示生成的关键信息，实现自我演化优化。

Result: 在包括DeepSeek-R1-Distill-Llama-8B、Qwen2.5-7B-Instruct和GPT-4o-mini等多个开源和闭源大型语言模型及不同任务上的广泛实验中，DelvePO均显著优于先前最先进方法。

Conclusion: DelvePO框架有效提高了提示优化的效果和稳定性，增强了优化提示在多任务和多模型间的迁移能力，展示了较强的实用价值。

Abstract: Prompt Optimization has emerged as a crucial approach due to its capabilities
in steering Large Language Models to solve various tasks. However, current
works mainly rely on the random rewriting ability of LLMs, and the optimization
process generally focus on specific influencing factors, which makes it easy to
fall into local optimum. Besides, the performance of the optimized prompt is
often unstable, which limits its transferability in different tasks. To address
the above challenges, we propose $\textbf{DelvePO}$
($\textbf{D}$irection-Guid$\textbf{e}$d Se$\textbf{l}$f-E$\textbf{v}$olving
Framework for Fl$\textbf{e}$xible $\textbf{P}$rompt $\textbf{O}$ptimization), a
task-agnostic framework to optimize prompts in self-evolve manner. In our
framework, we decouple prompts into different components that can be used to
explore the impact that different factors may have on various tasks. On this
basis, we introduce working memory, through which LLMs can alleviate the
deficiencies caused by their own uncertainties and further obtain key insights
to guide the generation of new prompts. Extensive experiments conducted on
different tasks covering various domains for both open- and closed-source LLMs,
including DeepSeek-R1-Distill-Llama-8B, Qwen2.5-7B-Instruct and GPT-4o-mini.
Experimental results show that DelvePO consistently outperforms previous SOTA
methods under identical experimental settings, demonstrating its effectiveness
and transferability across different tasks.

</details>


### [29] [Text or Pixels? It Takes Half: On the Token Efficiency of Visual Text Inputs in Multimodal LLMs](https://arxiv.org/abs/2510.18279)
*Yanhong Li,Zixuan Lan,Jiawei Zhou*

Main category: cs.CL

TL;DR: 本文提出通过将长文本渲染为单一图像输入给大型语言模型，以此减少解码器所需的token数量，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型及其多模态变体能处理视觉文本输入，探讨是否能通过将文本作为图像输入来压缩文本，从而减少token使用。

Method: 将长文本渲染成单一图像，并作为视觉输入直接提供给解码器大型语言模型，进行输入压缩。

Result: 在RULER和CNN/DailyMail两个基准测试中，文本作为图像的方法实现了显著的token节省（常接近50%），且不降低任务表现。

Conclusion: 通过将文本以图像形式输入，能够有效压缩输入，显著减少token使用量，同时保持模型性能，展示了视觉文本表示作为输入压缩的实用性和有效性。

Abstract: Large language models (LLMs) and their multimodal variants can now process
visual inputs, including images of text. This raises an intriguing question:
can we compress textual inputs by feeding them as images to reduce token usage
while preserving performance? In this paper, we show that visual text
representations are a practical and surprisingly effective form of input
compression for decoder LLMs. We exploit the idea of rendering long text inputs
as a single image and provide it directly to the model. This leads to
dramatically reduced number of decoder tokens required, offering a new form of
input compression. Through experiments on two distinct benchmarks RULER
(long-context retrieval) and CNN/DailyMail (document summarization) we
demonstrate that this text-as-image method yields substantial token savings
(often nearly half) without degrading task performance.

</details>


### [30] [BrailleLLM: Braille Instruction Tuning with Large Language Models for Braille Domain Tasks](https://arxiv.org/abs/2510.18288)
*Tianyuan Huang,Zepeng Zhu,Hangdi Xing,Zirui Shao,Zhi Yu,Chaoxiong Yang,Jiaxian He,Xiaozhong Liu,Jiajun Bu*

Main category: cs.CL

TL;DR: 该论文构建了英中盲文混合数据集，提出基于语法树的数据增强方法，创新盲文知识微调技术以提升盲文相关任务表现，实现统一盲文翻译和数学公式盲文转换。


<details>
  <summary>Details</summary>
Motivation: 盲文信息处理存在数据稀缺和混合文本环境下的歧义问题，传统微调方法表现不足。

Method: 构建英中盲文混合数据集，提出语法树数据增强方法，设计盲文知识微调（BKFT）并通过指令微调应用于统一盲文翻译及公式转换。

Result: BKFT在盲文翻译任务中显著优于传统微调方法，实验验证了方法的有效性。

Conclusion: 开放数据集与方法为低资源多语种盲文研究奠定基础，BKFT提升了盲文处理性能。

Abstract: Braille plays a vital role in education and information accessibility for
visually impaired individuals. However, Braille information processing faces
challenges such as data scarcity and ambiguities in mixed-text contexts. We
construct English and Chinese Braille Mixed Datasets (EBMD/CBMD) with
mathematical formulas to support diverse Braille domain research, and propose a
syntax tree-based augmentation method tailored for Braille data. To address the
underperformance of traditional fine-tuning methods in Braille-related tasks,
we investigate Braille Knowledge-Based Fine-Tuning (BKFT), which reduces the
learning difficulty of Braille contextual features. BrailleLLM employs BKFT via
instruction tuning to achieve unified Braille translation, formula-to-Braille
conversion, and mixed-text translation. Experiments demonstrate that BKFT
achieves significant performance improvements over conventional fine-tuning in
Braille translation scenarios. Our open-sourced datasets and methodologies
establish a foundation for low-resource multilingual Braille research.

</details>


### [31] [From Retrieval to Generation: Unifying External and Parametric Knowledge for Medical Question Answering](https://arxiv.org/abs/2510.18297)
*Lei Li,Xiao Zhou,Yingying Zhang,Xian Wu*

Main category: cs.CL

TL;DR: 本文提出MedRGAG框架，通过结合外部检索和内部生成知识，提升医疗问答的准确性，实现了明显性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有医疗问答方法面临检索噪声和生成信息不准确的问题，影响答案的可靠性。

Method: MedRGAG包含知识引导的上下文补全模块(KGCC)和知识感知文档选择模块(KADS)，分别用于补充缺失知识和选取最佳证据文档。

Result: 在五个医疗问答基准测试中，MedRGAG分别较MedRAG和MedGENIE提升了12.5%和4.5%的性能。

Conclusion: 结合检索和生成两类知识的统一框架，能够有效提升医疗问答系统的知识推理能力和答案质量。

Abstract: Medical question answering (QA) requires extensive access to domain-specific
knowledge. A promising direction is to enhance large language models (LLMs)
with external knowledge retrieved from medical corpora or parametric knowledge
stored in model parameters. Existing approaches typically fall into two
categories: Retrieval-Augmented Generation (RAG), which grounds model reasoning
on externally retrieved evidence, and Generation-Augmented Generation (GAG),
which depends solely on the models internal knowledge to generate contextual
documents. However, RAG often suffers from noisy or incomplete retrieval, while
GAG is vulnerable to hallucinated or inaccurate information due to
unconstrained generation. Both issues can mislead reasoning and undermine
answer reliability. To address these challenges, we propose MedRGAG, a unified
retrieval-generation augmented framework that seamlessly integrates external
and parametric knowledge for medical QA. MedRGAG comprises two key modules:
Knowledge-Guided Context Completion (KGCC), which directs the generator to
produce background documents that complement the missing knowledge revealed by
retrieval; and Knowledge-Aware Document Selection (KADS), which adaptively
selects an optimal combination of retrieved and generated documents to form
concise yet comprehensive evidence for answer generation. Extensive experiments
on five medical QA benchmarks demonstrate that MedRGAG achieves a 12.5%
improvement over MedRAG and a 4.5% gain over MedGENIE, highlighting the
effectiveness of unifying retrieval and generation for knowledge-intensive
reasoning. Our code and data are publicly available at
https://anonymous.4open.science/r/MedRGAG

</details>


### [32] [ECG-LLM -- training and evaluation of domain-specific large language models for electrocardiography](https://arxiv.org/abs/2510.18339)
*Lara Ahrens,Wilhelm Haverkamp,Nils Strodthoff*

Main category: cs.CL

TL;DR: 针对心电图领域，通过微调开放权重大型语言模型（如Llama 3.1 70B）和采用检索增强生成方法，实现了在医疗特定任务上的竞争性表现，证明了本地部署以保护隐私的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前针对医疗领域的开放权重大型语言模型缺乏最佳适配策略和评估方法，且其性能相较于通用模型尚不明确。

Method: 在心电图领域对开放权重模型进行微调，结合多层次评估框架，比较微调模型、检索增强生成（RAG）和通用模型Claude Sonnet 3.7的表现。

Result: 微调后的Llama 3.1 70B在多项选择题和自动文本评价中表现出色，仅次于Claude 3.7；人类专家更倾向Claude 3.7和RAG方法解决复杂问题；微调模型整体明显优于基础模型。

Conclusion: 评估方式差异导致性能表现存在较大异质性，但领域微调和RAG方法已能达到专有模型的竞争水平，支持隐私保护和本地部署的临床应用可行性。

Abstract: Domain-adapted open-weight large language models (LLMs) offer promising
healthcare applications, from queryable knowledge bases to multimodal
assistants, with the crucial advantage of local deployment for privacy
preservation. However, optimal adaptation strategies, evaluation methodologies,
and performance relative to general-purpose LLMs remain poorly characterized.
We investigated these questions in electrocardiography, an important area of
cardiovascular medicine, by finetuning open-weight models on domain-specific
literature and implementing a multi-layered evaluation framework comparing
finetuned models, retrieval-augmented generation (RAG), and Claude Sonnet 3.7
as a representative general-purpose model. Finetuned Llama 3.1 70B achieved
superior performance on multiple-choice evaluations and automatic text metrics,
ranking second to Claude 3.7 in LLM-as-a-judge assessments. Human expert
evaluation favored Claude 3.7 and RAG approaches for complex queries. Finetuned
models significantly outperformed their base counterparts across nearly all
evaluation modes. Our findings reveal substantial performance heterogeneity
across evaluation methodologies, underscoring assessment complexity.
Nevertheless, domain-specific adaptation through finetuning and RAG achieves
competitive performance with proprietary models, supporting the viability of
privacy-preserving, locally deployable clinical solutions.

</details>


### [33] [Combining Distantly Supervised Models with In Context Learning for Monolingual and Cross-Lingual Relation Extraction](https://arxiv.org/abs/2510.18344)
*Vipul Rathore,Malik Hammad Faisal,Parag Singla,Mausam*

Main category: cs.CL

TL;DR: 提出了HYDRE框架，将传统远程监督关系抽取模型与大型语言模型的上下文学习结合，通过动态示例检索提升噪声环境下的关系抽取性能，在英文及四种低资源印度语言数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有远程监督关系抽取模型虽然效果较好，但通常依赖特定训练且噪声标签影响模型准确性；大型语言模型的上下文学习尚未充分利用于此，且噪声标签可能导致语言模型理解关系语义不准确。

Method: HYDRE框架先用训练好的DSRE模型筛选测试句子的前k个候选关系，再通过动态示例检索策略，从训练数据中提取可靠的句子级示例，放入大型语言模型的提示词中，以生成最终关系预测。同时，扩展到跨语言低资源设置。

Result: HYDRE在英文数据上取得最高20个F1点的提升，在四种低资源印度语言平均提升17个F1点，对比不同提示策略展示了其有效性。

Conclusion: 结合传统DSRE模型与大型语言模型的上下文学习及动态示例检索，HYDRE显著提升了远程监督关系抽取的性能，尤其在低资源语言环境下表现突出，展示了其广泛适用性和优越性。

Abstract: Distantly Supervised Relation Extraction (DSRE) remains a long-standing
challenge in NLP, where models must learn from noisy bag-level annotations
while making sentence-level predictions. While existing state-of-the-art (SoTA)
DSRE models rely on task-specific training, their integration with in-context
learning (ICL) using large language models (LLMs) remains underexplored. A key
challenge is that the LLM may not learn relation semantics correctly, due to
noisy annotation.
  In response, we propose HYDRE -- HYbrid Distantly Supervised Relation
Extraction framework. It first uses a trained DSRE model to identify the top-k
candidate relations for a given test sentence, then uses a novel dynamic
exemplar retrieval strategy that extracts reliable, sentence-level exemplars
from training data, which are then provided in LLM prompt for outputting the
final relation(s).
  We further extend HYDRE to cross-lingual settings for RE in low-resource
languages. Using available English DSRE training data, we evaluate all methods
on English as well as a newly curated benchmark covering four diverse
low-resource Indic languages -- Oriya, Santali, Manipuri, and Tulu. HYDRE
achieves up to 20 F1 point gains in English and, on average, 17 F1 points on
Indic languages over prior SoTA DSRE models. Detailed ablations exhibit HYDRE's
efficacy compared to other prompting strategies.

</details>


### [34] [KrishokBondhu: A Retrieval-Augmented Voice-Based Agricultural Advisory Call Center for Bengali Farmers](https://arxiv.org/abs/2510.18355)
*Mohd Ruhul Ameen,Akif Islam,Farjana Aktar,M. Saifuzzaman Rafat*

Main category: cs.CL

TL;DR: 该论文介绍了KrishokBondhu，一个面向孟加拉语农民的语音咨询平台，通过整合农业文档和现代RAG技术，提供实时、上下文相关的农业指导。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国农民获取及时和专家级农业指导存在困难，需要一个易用且精准的咨询系统。

Method: 构建基于RAG框架的语音咨询平台，利用OCR数字化农业文档，向量数据库实现高效语义检索，结合大语言模型生成上下文相关回答，通过电话接口提供服务。

Result: 系统在试点评估中对72.7%的农业问题给出高质量回答，综合评分比基线提高44.7%，特别在上下文丰富性和完整性方面表现出显著提升。

Conclusion: KrishokBondhu成功整合多项技术，实现了为偏远孟加拉农民提供专家级农业咨询的可行性，推动了全AI驱动农业咨询生态系统的发展。

Abstract: In Bangladesh, many farmers continue to face challenges in accessing timely,
expert-level agricultural guidance. This paper presents KrishokBondhu, a
voice-enabled, call-centre-integrated advisory platform built on a
Retrieval-Augmented Generation (RAG) framework, designed specifically for
Bengali-speaking farmers. The system aggregates authoritative agricultural
handbooks, extension manuals, and NGO publications; applies Optical Character
Recognition (OCR) and document-parsing pipelines to digitize and structure the
content; and indexes this corpus in a vector database for efficient semantic
retrieval. Through a simple phone-based interface, farmers can call the system
to receive real-time, context-aware advice: speech-to-text converts the Bengali
query, the RAG module retrieves relevant content, a large language model (Gemma
3-4B) generates a context-grounded response, and text-to-speech delivers the
answer in natural spoken Bengali. In a pilot evaluation, KrishokBondhu produced
high-quality responses for 72.7% of diverse agricultural queries covering crop
management, disease control, and cultivation practices. Compared to the
KisanQRS benchmark, the system achieved a composite score of 4.53 (vs. 3.13) on
a 5-point scale, a 44.7% improvement, with especially large gains in contextual
richness (+367%) and completeness (+100.4%), while maintaining comparable
relevance and technical specificity. Semantic similarity analysis further
revealed a strong correlation between retrieved context and answer quality,
emphasizing the importance of grounding generative responses in curated
documentation. KrishokBondhu demonstrates the feasibility of integrating
call-centre accessibility, multilingual voice interaction, and modern RAG
techniques to deliver expert-level agricultural guidance to remote Bangladeshi
farmers, paving the way toward a fully AI-driven agricultural advisory
ecosystem.

</details>


### [35] [KoSimpleQA: A Korean Factuality Benchmark with an Analysis of Reasoning LLMs](https://arxiv.org/abs/2510.18368)
*Donghyeon Ko,Yeguk Jin,Kyubyung Chae,Byungwook Lee,Chansong Jo,Sookyo In,Jaehong Lee,Taesup Kim,Donghyun Kwak*

Main category: cs.CL

TL;DR: KoSimpleQA是一个针对韩语文化知识的大型语言模型事实性评估基准，包含1000个简短且明确的事实查询问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在处理韩语文化知识事实性问题时表现有限，且评估资源不足，需一个具有挑战性且易于评分的基准。

Method: 设计并发布了KoSimpleQA数据集，包含1000个明确事实问题，对多种支持韩语的开源大型语言模型进行全面评估，分析推理能力对任务表现的影响。

Result: 即使是表现最好的模型正确率仅为33.7%，且模型在KoSimpleQA和英语同类数据集的表现排序存在显著差异，强调其独特价值。推理能力有助于模型更好地调用隐含知识和提高不确定时的回避能力。

Conclusion: KoSimpleQA为韩语文化知识的事实性评估提供了重要工具，展示了现有模型的不足和推理机制的潜力，促进未来模型改进。

Abstract: We present $\textbf{Korean SimpleQA (KoSimpleQA)}$, a benchmark for
evaluating factuality in large language models (LLMs) with a focus on Korean
cultural knowledge. KoSimpleQA is designed to be challenging yet easy to grade,
consisting of 1,000 short, fact-seeking questions with unambiguous answers. We
conduct a comprehensive evaluation across a diverse set of open-source LLMs of
varying sizes that support Korean, and find that even the strongest model
generates correct answer only 33.7% of the time, underscoring the challenging
nature of KoSimpleQA. Notably, performance rankings on KoSimpleQA differ
substantially from those on the English SimpleQA, highlighting the unique value
of our dataset. Furthermore, our analysis of reasoning LLMs shows that engaging
reasoning capabilities in the factual QA task can both help models better
elicit their latent knowledge and improve their ability to abstain when
uncertain. KoSimpleQA can be found at
https://anonymous.4open.science/r/KoSimpleQA-62EB.

</details>


### [36] [Towards Fair ASR For Second Language Speakers Using Fairness Prompted Finetuning](https://arxiv.org/abs/2510.18374)
*Monorama Swain,Bubai Maji,Jagabandhu Mishra,Markus Schedl,Anders Søgaard,Jesper Rindom Jensen*

Main category: cs.CL

TL;DR: 本文针对第二语言英语口音者构建公平的语音识别系统，提出结合不同公平性优化目标的微调方法，显著提升了不同口音群体的识别公平性和准确率。


<details>
  <summary>Details</summary>
Motivation: 当前主流的英文语音识别模型（Whisper和Seamless-M4T）在不同口音群体间存在较大误差率波动，表现出显著的公平性差距。

Method: 采用轻量级adapter进行微调，结合谱解耦(SD)、群体分布鲁棒优化(Group-DRO)、不变风险最小化(IRM)等公平性驱动目标，同时融合传统的经验风险最小化(ERM)方法。

Result: 该方法在宏观平均词错误率上相较于大规模预训练模型分别提升58.7%和58.5%，相较于仅用交叉熵损失微调的模型分别提升9.7%和7.8%。

Conclusion: 融合多种公平性目标的微调策略有效提升了针对不同口音群体的英文语音识别系统的公平性和整体性能。

Abstract: In this work, we address the challenge of building fair English ASR systems
for second-language speakers. Our analysis of widely used ASR models, Whisper
and Seamless-M4T, reveals large fluctuations in word error rate (WER) across 26
accent groups, indicating significant fairness gaps. To mitigate this, we
propose fairness-prompted finetuning with lightweight adapters, incorporating
Spectral Decoupling (SD), Group Distributionally Robust Optimization
(Group-DRO), and Invariant Risk Minimization (IRM). Our proposed fusion of
traditional empirical risk minimization (ERM) with cross-entropy and
fairness-driven objectives (SD, Group DRO, and IRM) enhances fairness across
accent groups while maintaining overall recognition accuracy. In terms of
macro-averaged word error rate, our approach achieves a relative improvement of
58.7% and 58.5% over the large pretrained Whisper and SeamlessM4T, and 9.7% and
7.8% over them, finetuning with standard empirical risk minimization with
cross-entropy loss.

</details>


### [37] [MENTOR: A Reinforcement Learning Framework for Model Enhancement via Teacher-Optimized Rewards in Small Models](https://arxiv.org/abs/2510.18383)
*ChangSu Choi,Hoyun Song,Dongyeon Kim,WooHyeon Jung,Minkyung Cho,Sunjin Park,NohHyeob Bae,Seona Yu,KyungTae Lim*

Main category: cs.CL

TL;DR: 本文提出了一种名为MENTOR的框架，通过结合强化学习与教师引导的蒸馏，提升小型语言模型在工具使用上的泛化能力和策略性能。


<details>
  <summary>Details</summary>
Motivation: 传统的监督微调方法因模仿静态教师轨迹导致泛化能力差，标准强化学习因稀疏奖励导致探索效率低和策略次优，限制了小型语言模型的实用性。

Method: MENTOR框架通过强化学习探索策略，而非单纯模仿教师，同时利用教师参考轨迹构建稠密的复合奖励，解决奖励稀疏问题，实现更细粒度的指导。

Result: 实验表明，MENTOR显著提升了小型语言模型的跨域泛化能力和策略水平，优于传统监督微调和稀疏奖励强化学习基线。

Conclusion: 结合强化学习与教师引导奖励的策略蒸馏，MENTOR为提升小型语言模型工具使用能力提供了有效路径，推动其实用化进程。

Abstract: Distilling the tool-using capabilities of large language models (LLMs) into
smaller, more efficient small language models (SLMs) is a key challenge for
their practical application. The predominant approach, supervised fine-tuning
(SFT), suffers from poor generalization as it trains models to imitate a static
set of teacher trajectories rather than learn a robust methodology. While
reinforcement learning (RL) offers an alternative, the standard RL using sparse
rewards fails to effectively guide SLMs, causing them to struggle with
inefficient exploration and adopt suboptimal strategies. To address these
distinct challenges, we propose MENTOR, a framework that synergistically
combines RL with teacher-guided distillation. Instead of simple imitation,
MENTOR employs an RL-based process to learn a more generalizable policy through
exploration. In addition, to solve the problem of reward sparsity, it uses a
teacher's reference trajectory to construct a dense, composite teacher-guided
reward that provides fine-grained guidance. Extensive experiments demonstrate
that MENTOR significantly improves the cross-domain generalization and
strategic competence of SLMs compared to both SFT and standard sparse-reward RL
baselines.

</details>


### [38] [Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference](https://arxiv.org/abs/2510.18413)
*Siyuan Yan,Guo-Qing Jiang,Yuchen Zhang,Xiaoxing Ma,Ran Zhu,Chun Cao,Jingwei Xu*

Main category: cs.CL

TL;DR: Adamas是一种针对长上下文推理设计的轻量级高精度稀疏注意力机制，能显著提升自注意力计算速度，同时保持接近全注意力的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型处理超长上下文时，自注意力的计算开销呈二次增长，导致解码延迟严重，现有稀疏注意力方法虽降低开销但准确率下降。

Method: Adamas利用Hadamard变换、分桶和2位压缩技术生成紧凑表示，并通过曼哈顿距离估计实现高效的top-k选择，以实现高稀疏度的注意力计算。

Result: 实验显示Adamas在64个token预算下准确率匹配全注意力，128个token时近无损性能，支持最高8倍稀疏度，32K长度序列下自注意力速度提升4.4倍，总体加速1.5倍，且困惑度与全注意力相当甚至更低。

Conclusion: Adamas有效缓解了长上下文自注意力计算的瓶颈，在保证准确率的前提下实现了显著加速，证明了其在长文本处理中的实用价值。

Abstract: Large language models (LLMs) now support context windows of hundreds of
thousands to millions of tokens, enabling applications such as long-document
summarization, large-scale code synthesis, multi-document question answering
and persistent multi-turn dialogue. However, such extended contexts exacerbate
the quadratic cost of self-attention, leading to severe latency in
autoregressive decoding. Existing sparse attention methods alleviate these
costs but rely on heuristic patterns that struggle to recall critical key-value
(KV) pairs for each query, resulting in accuracy degradation. We introduce
Adamas, a lightweight yet highly accurate sparse attention mechanism designed
for long-context inference. Adamas applies the Hadamard transform,
bucketization and 2-bit compression to produce compact representations, and
leverages Manhattan-distance estimation for efficient top-k selections.
Experiments show that Adamas matches the accuracy of full attention with only a
64-token budget, achieves near-lossless performance at 128, and supports up to
8x higher sparsity than prior state-of-the-art (SOTA) methods while delivering
up to 4.4x self-attention and 1.5x end-to-end speedups on 32K-length sequences.
Remarkably, Adamas attains comparable or even lower perplexity than full
attention, underscoring its effectiveness in maintaining accuracy under
aggressive sparsity.

</details>


### [39] [Chain-of-Conceptual-Thought: Eliciting the Agent to Deeply Think within the Response](https://arxiv.org/abs/2510.18434)
*Qingqing Gu,Dan Wang,Yue Zhao,Xiaoyu Wang,Zhonglin Jiang,Yong Chen,Hongyan Li,Luo Ji*

Main category: cs.CL

TL;DR: 提出了一种新的提示范式——概念思维链（CoCT），通过概念标注促进大型语言模型在开放领域任务中的深度和战略性思考，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统链式思维（CoT）在开放领域任务中表现有限，因缺乏明确推理步骤或逻辑过渡，难以实现深度推理。

Method: 提出CoCT范式，首先对概念进行标注，再生成详细内容，在话语中形成概念链，特别适用于日常和情感支持对话，促使模型进行深层次和战略性思考。

Result: 在自动化、人类和模型评估中，CoCT优于Self-Refine、ECoT、ToT、SoT和RAG等基线方法，表现出更强的任务适应性和效果。

Conclusion: CoCT作为一种新的基于提示的范式，展示了大型语言模型在更广泛任务中的潜力和更优性能。

Abstract: Chain-of-Thought (CoT) is widely applied to improve the LLM capability in
math, coding and reasoning tasks. However, its performance is limited for
open-domain tasks since there are no clearly defined reasoning steps or logical
transitions. To mitigate such challenges, we propose another prompt-based
paradigm called Chain of Conceptual Thought (CoCT), where the LLM first tags a
concept, then generates the detailed content. The chain of concepts is allowed
within the utterance, encouraging the LLM's deep and strategic thinking. We
experiment with this paradigm in daily and emotional support conversations
where the concept is comprised of emotions, strategies and topics. Automatic,
human and model evaluations suggest that CoCT surpasses baselines such as
Self-Refine, ECoT, ToT, SoT and RAG, suggesting a potential effective
prompt-based paradigm of LLM for a wider scope of tasks.

</details>


### [40] [Grounding or Guessing? Visual Signals for Detecting Hallucinations in Sign Language Translation](https://arxiv.org/abs/2510.18439)
*Yasser Hamidullah,Koel Dutta Chowdury,Yusser Al-Ghussin,Shakib Yazdani,Cennet Oguz,Josef van Genabith,Cristina España-Bonet*

Main category: cs.CL

TL;DR: 本论文提出了一种基于视觉信息可靠性的度量方法，用于检测手语翻译模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 手语翻译中幻觉（生成与视频不符的文本）是主要问题，尤其是无注释标注的模型容易依赖语言先验而非视觉输入，从而产生幻觉。

Method: 设计了基于特征敏感性和反事实信号的token级视觉信息利用度量，并整合为句子级可靠性分数，用于评价视觉依赖性和检测幻觉。

Result: 在两个手语翻译数据集上的评测显示该可靠性分数能有效预测幻觉率，适用于不同模型结构和数据集，并能区分基于视觉生成的tokens和猜测的tokens，结合文本信号可进一步提升幻觉风险估计。

Conclusion: 提出的视觉可靠性指标为手语翻译幻觉检测提供了实用可复用的工具，有助于提升多模态生成任务中的幻觉检测能力。

Abstract: Hallucination, where models generate fluent text unsupported by visual
evidence, remains a major flaw in vision-language models and is particularly
critical in sign language translation (SLT). In SLT, meaning depends on precise
grounding in video, and gloss-free models are especially vulnerable because
they map continuous signer movements directly into natural language without
intermediate gloss supervision that serves as alignment. We argue that
hallucinations arise when models rely on language priors rather than visual
input. To capture this, we propose a token-level reliability measure that
quantifies how much the decoder uses visual information. Our method combines
feature-based sensitivity, which measures internal changes when video is
masked, with counterfactual signals, which capture probability differences
between clean and altered video inputs. These signals are aggregated into a
sentence-level reliability score, providing a compact and interpretable measure
of visual grounding. We evaluate the proposed measure on two SLT benchmarks
(PHOENIX-2014T and CSL-Daily) with both gloss-based and gloss-free models. Our
results show that reliability predicts hallucination rates, generalizes across
datasets and architectures, and decreases under visual degradations. Beyond
these quantitative trends, we also find that reliability distinguishes grounded
tokens from guessed ones, allowing risk estimation without references; when
combined with text-based signals (confidence, perplexity, or entropy), it
further improves hallucination risk estimation. Qualitative analysis highlights
why gloss-free models are more susceptible to hallucinations. Taken together,
our findings establish reliability as a practical and reusable tool for
diagnosing hallucinations in SLT, and lay the groundwork for more robust
hallucination detection in multimodal generation.

</details>


### [41] [Engagement Undermines Safety: How Stereotypes and Toxicity Shape Humor in Language Models](https://arxiv.org/abs/2510.18454)
*Atharvan Dogra,Soumya Suvra Ghosal,Ameet Deshpande,Ashwin Kalyan,Dinesh Manocha*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在幽默生成中有害内容与幽默评分的关联，发现有害内容往往被模型评为更幽默，且这种偏差随着角色扮演提示增强。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型越来越多用于创意写作和互动内容，输出的安全性问题日益突出，本文选取幽默生成任务来检测模型在追求幽默时有害内容的出现情况及其机制。

Method: 通过在六个模型上联合测量幽默度、刻板印象程度和有害性，并用信息论指标分析不协调性信号，进一步在讽刺生成任务中进行外部验证。

Result: 发现有害输出获得更高的幽默评分，且角色提示加剧这种偏差；信息论分析显示有害线索增加预测不确定性，甚至使有害笑点更容易被模型预测；讽刺文本中刻板印象和有害内容增加，有害笑话在幽默评分和人类评判中更常出现。

Conclusion: 幽默生成过程中有害内容和刻板印象被放大，存在生成者与评估者之间的偏差循环，提醒需重视大型语言模型中的安全与伦理问题。

Abstract: Large language models are increasingly used for creative writing and
engagement content, raising safety concerns about the outputs. Therefore,
casting humor generation as a testbed, this work evaluates how funniness
optimization in modern LLM pipelines couples with harmful content by jointly
measuring humor, stereotypicality, and toxicity. This is further supplemented
by analyzing incongruity signals through information-theoretic metrics. Across
six models, we observe that harmful outputs receive higher humor scores which
further increase under role-based prompting, indicating a bias amplification
loop between generators and evaluators. Information-theoretic analyses show
harmful cues widen predictive uncertainty and surprisingly, can even make
harmful punchlines more expected for some models, suggesting structural
embedding in learned humor distributions. External validation on an additional
satire-generation task with human perceived funniness judgments shows that LLM
satire increases stereotypicality and typically toxicity, including for closed
models. Quantitatively, stereotypical/toxic jokes gain $10-21\%$ in mean humor
score, stereotypical jokes appear $11\%$ to $28\%$ more often among the jokes
marked funny by LLM-based metric and up to $10\%$ more often in generations
perceived as funny by humans.

</details>


### [42] [ChronoPlay: A Framework for Modeling Dual Dynamics and Authenticity in Game RAG Benchmarks](https://arxiv.org/abs/2510.18455)
*Liyang He,Yuren Zhang,Ziwei Zhu,Zhenghui Li,Shiwei Tong*

Main category: cs.CL

TL;DR: 本文提出了ChronoPlay框架，解决了游戏领域内检索增强生成（RAG）系统缺乏标准基准测试的问题，实现了动态、自动化且真实感的游戏RAG基准生成。


<details>
  <summary>Details</summary>
Motivation: 当前游戏领域中的RAG系统缺少专门的基准测试标准，且游戏内容和玩家关注点动态变化，导致评估困难。此外，自动化基准测试要求生成的问题具备玩家中心的真实性。

Method: 提出ChronoPlay框架，采用双动态更新机制跟踪游戏内容和玩家社区的变化，结合官方信息和玩家社群数据的双源合成引擎，确保生成问题既事实准确又贴近玩家真实查询模式。

Result: 在三个不同游戏上应用ChronoPlay，成功构建首个动态游戏RAG基准测试，展示模型在复杂且真实场景下的性能表现。

Conclusion: ChronoPlay有效解决了动态游戏RAG系统评估的核心难题，为未来游戏领域的RAG模型标准化评测提供了重要工具和方法。

Abstract: Retrieval Augmented Generation (RAG) systems are increasingly vital in
dynamic domains like online gaming, yet the lack of a dedicated benchmark has
impeded standardized evaluation in this area. The core difficulty lies in Dual
Dynamics: the constant interplay between game content updates and the shifting
focus of the player community. Furthermore, the necessity of automating such a
benchmark introduces a critical requirement for player-centric authenticity to
ensure generated questions are realistic. To address this integrated challenge,
we introduce ChronoPlay, a novel framework for the automated and continuous
generation of game RAG benchmarks. ChronoPlay utilizes a dual-dynamic update
mechanism to track both forms of change, and a dual-source synthesis engine
that draws from official sources and player community to ensure both factual
correctness and authentic query patterns. We instantiate our framework on three
distinct games to create the first dynamic RAG benchmark for the gaming domain,
offering new insights into model performance under these complex and realistic
conditions. Code is avaliable at: https://github.com/hly1998/ChronoPlay.

</details>


### [43] [DePass: Unified Feature Attributing by Simple Decomposed Forward Pass](https://arxiv.org/abs/2510.18462)
*Xiangyu Hong,Che Jiang,Kai Tian,Biqing Qi,Youbang Sun,Ning Ding,Bowen Zhou*

Main category: cs.CL

TL;DR: DePass是一种基于单次前向传递的Transformer特征归因方法，实现了细粒度且忠实的归因，无需辅助训练。


<details>
  <summary>Details</summary>
Motivation: 当前机制解释中，如何将Transformer模型的行为归因于其内部计算是核心挑战。

Method: DePass通过将隐藏状态分解为定制加法成分，并在固定注意力分数和MLP激活的条件下传播这些成分，实现归因。

Result: DePass在多个层面（token-level、model component-level、subspace-level）的归因任务中展示了有效性和忠实度。

Conclusion: DePass能够有效归属性息在Transformer模型内部的流动，具备成为解释领域基础工具的潜力。

Abstract: Attributing the behavior of Transformer models to internal computations is a
central challenge in mechanistic interpretability. We introduce DePass, a
unified framework for feature attribution based on a single decomposed forward
pass. DePass decomposes hidden states into customized additive components, then
propagates them with attention scores and MLP's activations fixed. It achieves
faithful, fine-grained attribution without requiring auxiliary training. We
validate DePass across token-level, model component-level, and subspace-level
attribution tasks, demonstrating its effectiveness and fidelity. Our
experiments highlight its potential to attribute information flow between
arbitrary components of a Transformer model. We hope DePass serves as a
foundational tool for broader applications in interpretability.

</details>


### [44] [CEFR-Annotated WordNet: LLM-Based Proficiency-Guided Semantic Database for Language Learning](https://arxiv.org/abs/2510.18466)
*Masato Kikuchi,Masatsugu Ono,Toshioki Soga,Tetsu Tanabe,Tadachika Ozono*

Main category: cs.CL

TL;DR: 本论文通过将WordNet与CEFR语言水平结合，利用大语言模型自动注释词义和语言水平，构建大规模语料库并训练词汇分类器，从而提升语言学习的效果。


<details>
  <summary>Details</summary>
Motivation: WordNet的细粒度词义区分对第二语言学习者较为困难，有必要结合语言学习标准（CEFR）改善词汇资源的实用性。

Method: 利用大语言模型计算WordNet词义与English Vocabulary Profile的语义相似度，实现自动化注释；构建包含词义及CEFR级别信息的大规模语料库，并据此训练上下文词汇分类器。

Result: 基于该语料库微调的分类器表现可与金标准注释的数据训练的模型相当；结合两者数据进一步提升分类器性能，Macro-F1达到0.81。

Conclusion: 所提出的CEFR标注WordNet及相关资源能有效支撑语言学习应用，促进自然语言处理与语言教育的结合，提升语言学习效率。

Abstract: Although WordNet is a valuable resource owing to its structured semantic
networks and extensive vocabulary, its fine-grained sense distinctions can be
challenging for second-language learners. To address this, we developed a
WordNet annotated with the Common European Framework of Reference for Languages
(CEFR), integrating its semantic networks with language-proficiency levels. We
automated this process using a large language model to measure the semantic
similarity between sense definitions in WordNet and entries in the English
Vocabulary Profile Online. To validate our method, we constructed a large-scale
corpus containing both sense and CEFR-level information from our annotated
WordNet and used it to develop contextual lexical classifiers. Our experiments
demonstrate that models fine-tuned on our corpus perform comparably to those
trained on gold-standard annotations. Furthermore, by combining our corpus with
the gold-standard data, we developed a practical classifier that achieves a
Macro-F1 score of 0.81, indicating the high accuracy of our annotations. Our
annotated WordNet, corpus, and classifiers are publicly available to help
bridge the gap between natural language processing and language education,
thereby facilitating more effective and efficient language learning.

</details>


### [45] [IMB: An Italian Medical Benchmark for Question Answering](https://arxiv.org/abs/2510.18468)
*Antonio Romano,Giuseppe Riccio,Mariano Barone,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 本文提出了两个意大利医学问答基准数据集IMB-QA和IMB-MCQA，利用大型语言模型（LLM）提升医疗论坛数据的清晰度和一致性，并通过检索增强生成和专业微调等方法，在医学问答任务中取得优越表现。


<details>
  <summary>Details</summary>
Motivation: 医疗论坛中的非正式语言和语言复杂度使自动问答系统面临挑战，尤其是在非英语环境下，亟需构建专业的医学问答基准和改进模型以提升问答性能。

Method: 本文构建了两个大规模意大利医学问答数据集；通过应用各种大型语言模型架构，结合检索增强生成（RAG）和领域微调技术，优化模型表现；进行了开放式和多项选择题问答任务的综合评估。

Result: 实验结果表明，专业的领域适应策略在医学问答任务上优于通用大型模型，提升了模型的准确性和一致性，同时保留了对话原始风格和意义。

Conclusion: 在医学问答领域，具备领域专业知识和高效信息检索能力的模型优于一味扩大模型规模，相关数据集和评测框架的发布将促进多语言医学问答的进一步研究。

Abstract: Online medical forums have long served as vital platforms where patients seek
professional healthcare advice, generating vast amounts of valuable knowledge.
However, the informal nature and linguistic complexity of forum interactions
pose significant challenges for automated question answering systems,
especially when dealing with non-English languages. We present two
comprehensive Italian medical benchmarks: \textbf{IMB-QA}, containing 782,644
patient-doctor conversations from 77 medical categories, and \textbf{IMB-MCQA},
comprising 25,862 multiple-choice questions from medical specialty
examinations. We demonstrate how Large Language Models (LLMs) can be leveraged
to improve the clarity and consistency of medical forum data while retaining
their original meaning and conversational style, and compare a variety of LLM
architectures on both open and multiple-choice question answering tasks. Our
experiments with Retrieval Augmented Generation (RAG) and domain-specific
fine-tuning reveal that specialized adaptation strategies can outperform
larger, general-purpose models in medical question answering tasks. These
findings suggest that effective medical AI systems may benefit more from domain
expertise and efficient information retrieval than from increased model scale.
We release both datasets and evaluation frameworks in our GitHub repository to
support further research on multilingual medical question answering:
https://github.com/PRAISELab-PicusLab/IMB.

</details>


### [46] [DART: A Structured Dataset of Regulatory Drug Documents in Italian for Clinical NLP](https://arxiv.org/abs/2510.18475)
*Mariano Barone,Antonio Laudante,Giuseppe Riccio,Antonio Romano,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: 本文介绍了一个意大利药品说明信息结构化数据集DART，并展示其在药物相互作用检测中的应用。


<details>
  <summary>Details</summary>
Motivation: 当前药理学知识抽取多依赖英文语料，缺乏针对其他医疗体系的资源，尤其是意大利语药品说明书的结构化数据。

Method: 通过大规模网页检索、语义分段和利用少样本微调的大型语言模型进行临床摘要提取，构建了DART数据集，并基于该数据集开发药物相互作用检测工具。

Result: 实验证明，基于指令微调的大型语言模型能够基于DART中的结构化信息准确推断潜在药物相互作用及其临床意义。

Conclusion: DART填补了非英语药理知识抽取的资源空白，结合大型语言模型能有效支持临床决策相关任务，且相关代码已公开。

Abstract: The extraction of pharmacological knowledge from regulatory documents has
become a key focus in biomedical natural language processing, with applications
ranging from adverse event monitoring to AI-assisted clinical decision support.
However, research in this field has predominantly relied on English-language
corpora such as DrugBank, leaving a significant gap in resources tailored to
other healthcare systems. To address this limitation, we introduce DART (Drug
Annotation from Regulatory Texts), the first structured corpus of Italian
Summaries of Product Characteristics derived from the official repository of
the Italian Medicines Agency (AIFA). The dataset was built through a
reproducible pipeline encompassing web-scale document retrieval, semantic
segmentation of regulatory sections, and clinical summarization using a
few-shot-tuned large language model with low-temperature decoding. DART
provides structured information on key pharmacological domains such as
indications, adverse drug reactions, and drug-drug interactions. To validate
its utility, we implemented an LLM-based drug interaction checker that
leverages the dataset to infer clinically meaningful interactions. Experimental
results show that instruction-tuned LLMs can accurately infer potential
interactions and their clinical implications when grounded in the structured
textual fields of DART. We publicly release our code on GitHub:
https://github.com/PRAISELab-PicusLab/DART.

</details>


### [47] [How Efficient Are Diffusion Language Models? A Critical Examination of Efficiency Evaluation Practices](https://arxiv.org/abs/2510.18480)
*Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao*

Main category: cs.CL

TL;DR: 本文系统研究了扩散语言模型(DLMs)在效率方面的表现，发现其普遍不及自回归模型(AR)且现有加速策略在大批量处理时效果有限。


<details>
  <summary>Details</summary>
Motivation: 虽然扩散语言模型提供了并行解码的潜力，但实际速度往往不及长期主导的自回归模型，限制了应用场景。

Method: 通过实证基准测试和基于roofline模型的理论分析，评估DLM与AR模型的吞吐率，并考察不同加速技术的效果。

Result: 研究发现AR模型的吞吐量普遍较高，DLM速度落后；加速策略如双缓存和并行解码在小批量时有效，但扩展后效果减弱。

Conclusion: 需要更稳健的评估方法和更有效的加速技术，以促进扩散语言模型的研究和应用。

Abstract: Diffusion language models (DLMs) have emerged as a promising alternative to
the long-dominant autoregressive (AR) paradigm, offering a parallelable
decoding process that could yield greater efficiency. Yet, in practice, current
open-source DLMs often underperform their AR counterparts in speed, limiting
their real-world utility. This work presents a systematic study of DLM
efficiency, identifying key issues in prior evaluation methods. Through
empirical benchmarking and a roofline-based theoretical analysis, we
demonstrate that AR models generally achieve higher throughput, while DLMs
consistently lag. We also investigate acceleration strategies, finding that
techniques like dual cache and parallel decoding mainly offer gains at small
batch sizes, with their benefits diminishing upon scaling. Our findings
underscore the necessity of robust evaluation methods and improved acceleration
strategies to advance research on DLMs.

</details>


### [48] [Identity-Aware Large Language Models require Cultural Reasoning](https://arxiv.org/abs/2510.18510)
*Alistair Plum,Anne-Marie Lutgen,Christoph Purschke,Achim Rettinger*

Main category: cs.CL

TL;DR: 本文指出大型语言模型缺乏文化推理能力，容易体现狭隘的文化视角，忽视全球用户多样性，强调文化推理是AI识别文化特定知识、价值观和社会规范并调整输出的关键能力。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型回复常反映狭隘的文化观点，缺乏对多元文化的适应，导致刻板印象和信任问题，亟需将文化推理视为基础能力。

Method: 通过分析现有模型在道德困境、习语解释和建议提供中的偏向，指出现有评估方法过于静态，无法捕捉模型的情境适应能力，提出应将文化推理纳入评估体系。

Result: 指出现有模型默认西方规范，即使通过微调数据也不能完全消除该问题，强调仅扩大数据集不能确保文化能力。

Conclusion: 文化推理应作为与事实准确性和语言连贯性同等重要的基础能力，为未来更具文化敏感性的AI系统奠定评估框架和方向。

Abstract: Large language models have become the latest trend in natural language
processing, heavily featuring in the digital tools we use every day. However,
their replies often reflect a narrow cultural viewpoint that overlooks the
diversity of global users. This missing capability could be referred to as
cultural reasoning, which we define here as the capacity of a model to
recognise culture-specific knowledge values and social norms, and to adjust its
output so that it aligns with the expectations of individual users. Because
culture shapes interpretation, emotional resonance, and acceptable behaviour,
cultural reasoning is essential for identity-aware AI. When this capacity is
limited or absent, models can sustain stereotypes, ignore minority
perspectives, erode trust, and perpetuate hate. Recent empirical studies
strongly suggest that current models default to Western norms when judging
moral dilemmas, interpreting idioms, or offering advice, and that fine-tuning
on survey data only partly reduces this tendency. The present evaluation
methods mainly report static accuracy scores and thus fail to capture adaptive
reasoning in context. Although broader datasets can help, they cannot alone
ensure genuine cultural competence. Therefore, we argue that cultural reasoning
must be treated as a foundational capability alongside factual accuracy and
linguistic coherence. By clarifying the concept and outlining initial
directions for its assessment, a foundation is laid for future systems to be
able to respond with greater sensitivity to the complex fabric of human
culture.

</details>


### [49] [Building Trust in Clinical LLMs: Bias Analysis and Dataset Transparency](https://arxiv.org/abs/2510.18556)
*Svetlana Maslenkova,Clement Christophe,Marco AF Pimentel,Tathagata Raha,Muhammad Umar Salman,Ahmed Al Mahrooqi,Avani Gupta,Shadab Khan,Ronnie Rajan,Praveenkumar Kanithi*

Main category: cs.CL

TL;DR: 本文分析了大型语言模型在医疗领域中的潜在偏见，重点研究不同人口群体间的阿片类药物处方差异，并提出了一个涵盖890亿词的新型医疗预训练数据集HC4，以促进临床AI公平性和安全性的评估。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗中的应用潜力巨大，但由于训练数据特性影响模型行为，尤其潜在偏见问题，迫切需要建立透明、全面的评估框架以确保模型的公平和安全。

Method: 本文通过深入分析临床语言模型中的偏见表现，关注不同人口统计群体（如种族、性别、年龄）间的阿片类药物处方差异；同时，构建了一个超过890亿词的医疗综合语料库HC4，结合既有通用基准和新提出的医疗特定评估方法进行测试。

Result: 研究揭示了模型在不同人口群体上的处方偏差，展示了新数据集HC4和医疗特定评估方法在识别和衡量临床模型偏见中的有效性，为确保模型公平性和安全性提供了关键洞见。

Conclusion: 本文提出的HC4数据集和评估框架为医疗领域大型语言模型的公平性和负责任应用提供了重要支持，推动了临床AI的可信和公正发展。

Abstract: Large language models offer transformative potential for healthcare, yet
their responsible and equitable development depends critically on a deeper
understanding of how training data characteristics influence model behavior,
including the potential for bias. Current practices in dataset curation and
bias assessment often lack the necessary transparency, creating an urgent need
for comprehensive evaluation frameworks to foster trust and guide improvements.
In this study, we present an in-depth analysis of potential downstream biases
in clinical language models, with a focus on differential opioid prescription
tendencies across diverse demographic groups, such as ethnicity, gender, and
age. As part of this investigation, we introduce HC4: Healthcare Comprehensive
Commons Corpus, a novel and extensively curated pretraining dataset exceeding
89 billion tokens. Our evaluation leverages both established general benchmarks
and a novel, healthcare-specific methodology, offering crucial insights to
support fairness and safety in clinical AI applications.

</details>


### [50] [Large language models for folktale type automation based on motifs: Cinderella case study](https://arxiv.org/abs/2510.18561)
*Tjaša Arčon,Marko Robnik-Šikonja,Polona Tratnik*

Main category: cs.CL

TL;DR: 本文提出了基于人工智能技术的大规模民俗学分析方法，利用机器学习和自然语言处理自动检测灰姑娘故事集中的主题，并通过聚类与降维分析其相似性与差异。


<details>
  <summary>Details</summary>
Motivation: 传统民俗学分析方法难以处理大规模文本，需借助人工智能提升分析效率和跨语种比较能力。

Method: 应用机器学习与自然语言处理技术，自动识别故事中的主题，结合聚类和降维方法进行相似性分析。

Result: 大型语言模型成功检测故事中复杂的主题互动，实现了对大量文本的计算分析和跨语种比较。

Conclusion: 人工智能方法为民俗学研究提供了强大工具，促进了大规模文本分析和多语言比较研究的发展。

Abstract: Artificial intelligence approaches are being adapted to many research areas,
including digital humanities. We built a methodology for large-scale analyses
in folkloristics. Using machine learning and natural language processing, we
automatically detected motifs in a large collection of Cinderella variants and
analysed their similarities and differences with clustering and dimensionality
reduction. The results show that large language models detect complex
interactions in tales, enabling computational analysis of extensive text
collections and facilitating cross-lingual comparisons.

</details>


### [51] [Beyond the Explicit: A Bilingual Dataset for Dehumanization Detection in Social Media](https://arxiv.org/abs/2510.18582)
*Dennis Assenmacher,Paloma Piot,Katarina Laken,David Jurgens,Claudia Wagner*

Main category: cs.CL

TL;DR: 本文提出了一个包含多维数字去人性化表现的双语数据集，并通过机器学习模型显著提升了去人性化检测的效果。


<details>
  <summary>Details</summary>
Motivation: 当前计算语言学领域对数字去人性化研究有限，且多聚焦于明显负面言论，忽视了潜在但同样有害的微妙去人性化表达。

Method: 采用多种采样方法从Twitter和Reddit收集理论指导的双语数据，利用众包人员和专家对16,000条文本进行文档及片段级别标注，并基于该数据集微调机器学习模型。

Result: 构建的数据集涵盖去人性化的多种维度，训练的模型在零样本和少样本场景中显著优于现有最先进模型。

Conclusion: 该研究弥补了去人性化检测中对潜在细微表达的忽视，提供了高质量数据集和有效模型，推动了数字去人性化研究的发展。

Abstract: Digital dehumanization, although a critical issue, remains largely overlooked
within the field of computational linguistics and Natural Language Processing.
The prevailing approach in current research concentrating primarily on a single
aspect of dehumanization that identifies overtly negative statements as its
core marker. This focus, while crucial for understanding harmful online
communications, inadequately addresses the broader spectrum of dehumanization.
Specifically, it overlooks the subtler forms of dehumanization that, despite
not being overtly offensive, still perpetuate harmful biases against
marginalized groups in online interactions. These subtler forms can insidiously
reinforce negative stereotypes and biases without explicit offensiveness,
making them harder to detect yet equally damaging. Recognizing this gap, we use
different sampling methods to collect a theory-informed bilingual dataset from
Twitter and Reddit. Using crowdworkers and experts to annotate 16,000 instances
on a document- and span-level, we show that our dataset covers the different
dimensions of dehumanization. This dataset serves as both a training resource
for machine learning models and a benchmark for evaluating future
dehumanization detection techniques. To demonstrate its effectiveness, we
fine-tune ML models on this dataset, achieving performance that surpasses
state-of-the-art models in zero and few-shot in-context settings.

</details>


### [52] [Dynamical model parameters from ultrasound tongue kinematics](https://arxiv.org/abs/2510.18629)
*Sam Kirkham,Patrycja Strycharczuk*

Main category: cs.CL

TL;DR: 本文比较了超声和电磁发音描记技术(EMA)在估计线性谐振子模型参数方面的效果，发现两者结果相当，支持使用超声成像来评估动态发音控制模型。


<details>
  <summary>Details</summary>
Motivation: 当前发音控制模型通常依赖EMA数据评估，但超声成像技术的发展提供了潜在替代方案。本文旨在验证超声成像参数估计的可靠性，并与EMA进行对比。

Method: 研究中采用线性谐振子模型对舌头运动进行建模，分别从超声成像和同时记录的EMA数据中估计模型参数，同时也利用下颌短肌腱追踪分析下颌运动。

Result: 实验结果表明，超声成像和EMA在动态参数估计方面具有可比性，且下颌短肌腱追踪能够良好捕捉下颌运动。

Conclusion: 本研究支持使用超声舌头运动动力学数据来评估动态发音控制模型，为超声技术在发音模型评估中的应用提供了实证基础。

Abstract: The control of speech can be modelled as a dynamical system in which
articulators are driven toward target positions. These models are typically
evaluated using fleshpoint data, such as electromagnetic articulography (EMA),
but recent methodological advances make ultrasound imaging a promising
alternative. We evaluate whether the parameters of a linear harmonic oscillator
can be reliably estimated from ultrasound tongue kinematics and compare these
with parameters estimated from simultaneously-recorded EMA data. We find that
ultrasound and EMA yield comparable dynamical parameters, while mandibular
short tendon tracking also adequately captures jaw motion. This supports using
ultrasound kinematics to evaluate dynamical articulatory models.

</details>


### [53] [MLMA: Towards Multilingual with Mamba Based Architectures](https://arxiv.org/abs/2510.18684)
*Mohamed Nabih Ali,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 提出了一种基于Mamba架构的多语言自动语音识别方法MLMA，实现了高效处理长上下文序列，在多个语言识别基准上性能优异。


<details>
  <summary>Details</summary>
Motivation: 多语言自动语音识别中，平衡高资源和低资源语言的识别性能具有挑战，现有基于Transformer的模型在扩展性和效率方面存在限制。

Method: 引入高效的状态空间模型Mamba，利用其长序列处理能力，通过隐式语言感知条件化和共享表示，实现多语言语音识别。

Result: 在多语言基准测试中，MLMA表现出与Transformer架构竞争的识别性能。

Conclusion: Mamba架构作为多语言语音识别的骨干，展示了在可扩展性、效率和识别准确性上的潜力。

Abstract: Multilingual automatic speech recognition (ASR) remains a challenging task,
especially when balancing performance across high- and low-resource languages.
Recent advances in sequence modeling suggest that architectures beyond
Transformers may offer better scalability and efficiency. In this work, we
introduce MLMA (Multilingual Language Modeling with Mamba for ASR), a new
approach that leverages the Mamba architecture -- an efficient state-space
model optimized for long-context sequence processing -- for multilingual ASR.
Using Mamba, MLMA implicitly incorporates language-aware conditioning and
shared representations to support robust recognition across diverse languages.
Experiments on standard multilingual benchmarks show that MLMA achieves
competitive performance compared to Transformer-based architectures. These
results highlight Mamba's potential as a strong backbone for scalable,
efficient, and accurate multilingual speech recognition.

</details>


### [54] [Investigating LLM Capabilities on Long Context Comprehension for Medical Question Answering](https://arxiv.org/abs/2510.18691)
*Feras AlMannaa,Talia Tseriotou,Jenny Chim,Maria Liakata*

Main category: cs.CL

TL;DR: 首次研究大语言模型在长上下文医疗问答中的理解能力，分析模型大小、记忆力和推理模型的影响，探讨检索增强生成（RAG）在此任务中的作用和优化策略。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型在临床相关的长上下文医疗问答中理解能力的表现及其局限，寻找提升模型性能的有效方法。

Method: 综合评估不同模型规模和多种任务设置，通过包含相关内容的多文档推理，分析模型性能，并引入RAG技术进行效果比较和改进。

Result: 揭示了模型大小对性能的影响，发现记忆机制的限制，推理模型与RAG策略能有效提升长期上下文下的理解能力，并总结不同数据集及设置下的最佳实践。

Conclusion: RAG在提升长上下文医疗问答的理解效果方面具有明显优势，但也存在一定失败案例和局限，需结合多种评估手段深入分析以优化应用。

Abstract: This study is the first to investigate LLM comprehension capabilities over
long-context (LC) medical QA of clinical relevance. Our comprehensive
assessment spans a range of content-inclusion settings based on their
relevance, LLM models of varying capabilities and datasets across task
formulations, revealing insights on model size effects, limitations, underlying
memorization issues and the benefits of reasoning models. Importantly, we
examine the effect of RAG on medical LC comprehension, uncover best settings in
single versus multi-document reasoning datasets and showcase RAG strategies for
improvements over LC. We shed light into some of the evaluation aspects using a
multi-faceted approach. Our qualitative and error analyses address open
questions on when RAG is beneficial over LC, revealing common failure cases.

</details>


### [55] [Bayesian Low-Rank Factorization for Robust Model Adaptation](https://arxiv.org/abs/2510.18723)
*Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出贝叶斯因子适配器用于语音基础模型的领域适应，在多语混合场景下保持基础模型性能同时减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 语音基础模型在多个领域表现出色，但直接微调容易过拟合目标领域并破坏基础模型的广泛能力。

Method: 引入贝叶斯因子适配器，在适配矩阵中加入接近零的先验，实现稀疏调整，同时保留通用性能。

Result: 在Whisper模型的多语混合测试中，适配损失极小，减少了灾难性遗忘，比LoRA方法在保留旧能力上提高54%，在新领域性能仅下降4%。

Conclusion: 贝叶斯适配方法为语音基础模型微调提供了一种有效途径，能在适应特定领域的同时保持模型的广泛泛化能力。

Abstract: Large speech foundation models achieve strong performance across many
domains, but they often require adaptation to handle local needs such as
code-switching, where speakers mix languages within the same utterance. Direct
fine-tuning of these models risks overfitting to the target domain and
overwriting the broad capabilities of the base model. To address this
challenge, we explore Bayesian factorized adapters for speech foundation
models, which place priors near zero to achieve sparser adaptation matrices and
thereby retain general performance while adapting to specific domains. We apply
our approach to the Whisper model and evaluate on different multilingual
code-switching scenarios. Our results show only minimal adaptation loss while
significantly reducing catastrophic forgetting of the base model. Compared to
LoRA, our method achieves a backward gain of 54% with only a 4% drop on the new
domain. These findings highlight the effectiveness of Bayesian adaptation for
fine-tuning speech foundation models without sacrificing generalization.

</details>


### [56] [Adapting Language Balance in Code-Switching Speech](https://arxiv.org/abs/2510.18724)
*Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel*

Main category: cs.CL

TL;DR: 大型基础模型在处理语言混合（Code-Switching）场景时表现欠佳，本文通过明确标注混合点来改善模型识别能力，提升了阿拉伯语和中英混合数据上的性能。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型在多语言混合测试中表现不佳，主要因为代码切换点出现频率低，模型难以自发学习这些切换位置。

Method: 通过利用主语言与嵌入语言的差异，明确标注代码切换点，使用一种可微分的代理方法来强调这些位置的学习，减轻上下文偏差。

Result: 实验表明该方法提升了模型对语言切换位置的预测准确性，减少了替换错误，增强了模型在阿拉伯语和中英混合语料上的鲁棒性。

Conclusion: 为代码切换提供明确标注，针对切换点重点优化，能有效缓解上下文偏差，提升大型模型对代码切换场景的处理能力。

Abstract: Despite achieving impressive results on standard benchmarks, large
foundational models still struggle against code-switching test cases. When data
scarcity cannot be used as the usual justification for poor performance, the
reason may lie in the infrequent occurrence of code-switched moments, where the
embedding of the second language appears subtly. Instead of expecting the
models to learn this infrequency on their own, it might be beneficial to
provide the training process with labels. Evaluating model performance on
code-switching data requires careful localization of code-switching points
where recognition errors are most consequential, so that the analysis
emphasizes mistakes occurring at those moments. Building on this observation,
we leverage the difference between the embedded and the main language to
highlight those code-switching points and thereby emphasize learning at those
locations. This simple yet effective differentiable surrogate mitigates context
bias during generation -- the central challenge in code-switching -- thereby
improving the model's robustness. Our experiments with Arabic and
Chinese-English showed that the models are able to predict the switching places
more correctly, reflected by the reduced substitution error.

</details>


### [57] [SemiAdapt and SemiLoRA: Efficient Domain Adaptation for Transformer-based Low-Resource Language Translation with a Case Study on Irish](https://arxiv.org/abs/2510.18725)
*Josh McGiff,Nikola S. Nikolov*

Main category: cs.CL

TL;DR: 该论文提出了两种半监督推理高效的参数高效微调方法SemiAdapt和SemiLoRA，显著提升了多语言神经机器翻译中低资源领域（如爱尔兰语翻译）的适应性能，SemiLoRA甚至能超过全模型微调效果。


<details>
  <summary>Details</summary>
Motivation: 大规模多语言模型微调计算代价高，阻碍了低资源语言领域的研究，需要更高效的参数微调方法以促进低资源语言的领域适应。

Method: 基于参数高效微调框架，提出SemiAdapt和SemiLoRA两种半监督推理高效方法，通过引入小型可训练适配层和基于嵌入的推理策略，强化领域适应能力。

Result: SemiAdapt超过了全领域微调效果，SemiLoRA在参数高效微调方法中表现最佳，甚至匹配或优于全模型微调，在大规模和噪声较大的语料上嵌入推理方法表现尤为突出。

Conclusion: 所提方法显著提高了低资源语言领域的模型微调性能，促进了领域自适应的普及与应用，相关爱尔兰语翻译模型已开放，助力低资源语言研究者。

Abstract: Fine-tuning is widely used to tailor large language models for specific tasks
such as neural machine translation (NMT). However, leveraging transfer learning
is computationally expensive when fine-tuning large multilingual models with
billions of parameters, thus creating a barrier to entry for researchers
working on low-resource domains such as Irish translation. Parameter-efficient
fine-tuning (PEFT) bridges this gap by training on a fraction of the original
model parameters, with the Low-Rank Adaptation (LoRA) approach introducing
small, trainable adapter layers. We introduce SemiAdapt and SemiLoRA as
semi-supervised inference-efficient approaches that strengthen domain
adaptation and lead to improved overall performance in NMT. We demonstrate that
SemiAdapt can outperform full-domain fine-tuning, while most notably, SemiLoRA
can propel PEFT methods to match or even outperform full-model fine-tuning. We
further evaluate domain-by-dataset fine-tuning and demonstrate that our
embedding-based inference methods perform especially well on larger and noisier
corpora. All Irish translation models developed in this work are released as
open resources. These methods aim to make high-quality domain adaptation and
fine-tuning more accessible to researchers working with low-resource languages.

</details>


### [58] [Verifiable Accuracy and Abstention Rewards in Curriculum RL to Alleviate Lost-in-Conversation](https://arxiv.org/abs/2510.18731)
*Ming Li*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的课程强化学习框架RLAAR，用于改善大语言模型在多轮对话表现中的性能下降问题（LiC）。


<details>
  <summary>Details</summary>
Motivation: 多轮对话中随着信息逐步展现，大语言模型性能下降（LiC），需要一种方法提升模型的可靠性和判断问题可解性的能力。

Method: 提出课程强化学习结合可验证的准确率和弃权奖励，通过能力门控的课程策略递增提升对话难度，同时利用多轮在线采样和混合奖励促进模型在回答与弃权间平衡。

Result: 在LiC基准测试中，RLAAR显著缓解了性能下降（从62.6%提升到75.1%）并提升了校准弃权率（从33.5%提升到73.4%）。

Conclusion: RLAAR为构建多轮对话中可靠且值得信赖的大语言模型提供了实用方案。

Abstract: Large Language Models demonstrate strong capabilities in single-turn
instruction following but suffer from Lost-in-Conversation (LiC), a degradation
in performance as information is revealed progressively in multi-turn settings.
Motivated by the current progress on Reinforcement Learning with Verifiable
Rewards (RLVR), we propose Curriculum Reinforcement Learning with Verifiable
Accuracy and Abstention Rewards (RLAAR), a framework that encourages models not
only to generate correct answers, but also to judge the solvability of
questions in the multi-turn conversation setting. Our approach employs a
competence-gated curriculum that incrementally increases dialogue difficulty
(in terms of instruction shards), stabilizing training while promoting
reliability. Using multi-turn, on-policy rollouts and a mixed-reward system,
RLAAR teaches models to balance problem-solving with informed abstention,
reducing premature answering behaviors that cause LiC. Evaluated on LiC
benchmarks, RLAAR significantly mitigates LiC performance decay (62.6% to
75.1%) and improves calibrated abstention rates (33.5% to 73.4%). Together,
these results provide a practical recipe for building multi-turn reliable and
trustworthy LLMs.

</details>


### [59] [Topoformer: brain-like topographic organization in Transformer language models through spatial querying and reweighting](https://arxiv.org/abs/2510.18745)
*Taha Binhuraib,Greta Tuckute,Nicholas Blauch*

Main category: cs.CL

TL;DR: 本论文提出一种新的自注意力机制Topoformer，实现了Transformer模型的空间拓扑组织，增强了模型的可解释性，同时在自然语言处理任务中性能表现良好。


<details>
  <summary>Details</summary>
Motivation: 生物大脑具有空间功能组织特征，但现有机器学习模型缺乏空间偏置，导致表示难以可视化和解释。论文旨在引入空间拓扑结构以提升模型的可解释性。

Method: 引入空间查询和空间重权机制，将Transformer的全连接自注意力层转换为局部连接层，从而实现二维网格上的拓扑组织。首先在情感分类任务上训练了单层Topoformer，随后在BERT架构上应用掩码语言模型训练。

Result: Topoformer在NLP基准测试中表现与非拓扑控制模型相当，但展示了更具可解释性的拓扑组织结构；此外，模型生成的低维拓扑变异与人脑语言网络的fMRI数据高度一致。

Conclusion: 通过Topoformer实现的拓扑空间组织不仅提升了模型的可解释性，还与人类脑语言处理机制存在对应关系，为未来NLP模型的解释性研究及脑语言信息组织模型提供了新方向。

Abstract: Spatial functional organization is a hallmark of biological brains: neurons
are arranged topographically according to their response properties, at
multiple scales. In contrast, representations within most machine learning
models lack spatial biases, instead manifesting as disorganized vector spaces
that are difficult to visualize and interpret. Here, we propose a novel form of
self-attention that turns Transformers into "Topoformers" with topographic
organization. We introduce spatial querying - where keys and queries are
arranged on 2D grids, and local pools of queries are associated with a given
key - and spatial reweighting, where we convert the standard fully connected
layer of self-attention into a locally connected layer. We first demonstrate
the feasibility of our approach by training a 1-layer Topoformer on a sentiment
classification task. Training with spatial querying encourages topographic
organization in the queries and keys, and spatial reweighting separately
encourages topographic organization in the values and self-attention outputs.
We then apply the Topoformer motifs at scale, training a BERT architecture with
a masked language modeling objective. We find that the topographic variant
performs on par with a non-topographic control model on NLP benchmarks, yet
produces interpretable topographic organization as evaluated via eight
linguistic test suites. Finally, analyzing an fMRI dataset of human brain
responses to a large set of naturalistic sentences, we demonstrate alignment
between low-dimensional topographic variability in the Topoformer model and
human brain language network. Scaling up Topoformers further holds promise for
greater interpretability in NLP research, and for more accurate models of the
organization of linguistic information in the human brain.

</details>


### [60] [AI use in American newspapers is widespread, uneven, and rarely disclosed](https://arxiv.org/abs/2510.18774)
*Jenna Russell,Marzena Karpinska,Destiny Akinode,Katherine Thai,Bradley Emi,Max Spero,Mohit Iyyer*

Main category: cs.CL

TL;DR: 通过分析2025年夏季美国1500家报纸共186K篇文章，发现约9%的文章部分或完全由AI生成，AI使用更集中于小型地方媒体和特定主题，意见类文章更易含AI内容且少有披露。


<details>
  <summary>Details</summary>
Motivation: 当前AI在新闻写作中的应用范围尚不明确，亟需量化其在实际出版物中的使用状况以指导透明度和编辑标准的制定。

Method: 使用先进的AI检测工具Pangram，对186K篇美国报纸文章进行大规模审计，特别分析45K篇主流报纸的意见文章，结合人工抽检核实AI使用披露情况。

Result: 约9%的新发表文章含AI生成内容，意见类文章中AI使用频率是新闻报道的6.4倍，AI使用主要集中在小型媒体、特定话题和特定媒体集团，且AI使用披露极少。

Conclusion: 当前新闻行业AI使用普遍但透明度不足，呼吁建立更严格的编辑标准和披露机制，以维护公众信任。

Abstract: AI is rapidly transforming journalism, but the extent of its use in published
newspaper articles remains unclear. We address this gap by auditing a
large-scale dataset of 186K articles from online editions of 1.5K American
newspapers published in the summer of 2025. Using Pangram, a state-of-the-art
AI detector, we discover that approximately 9% of newly-published articles are
either partially or fully AI-generated. This AI use is unevenly distributed,
appearing more frequently in smaller, local outlets, in specific topics such as
weather and technology, and within certain ownership groups. We also analyze
45K opinion pieces from Washington Post, New York Times, and Wall Street
Journal, finding that they are 6.4 times more likely to contain AI-generated
content than news articles from the same publications, with many AI-flagged
op-eds authored by prominent public figures. Despite this prevalence, we find
that AI use is rarely disclosed: a manual audit of 100 AI-flagged articles
found only five disclosures of AI use. Overall, our audit highlights the
immediate need for greater transparency and updated editorial standards
regarding the use of AI in journalism to maintain public trust.

</details>


### [61] [KAT-Coder Technical Report](https://arxiv.org/abs/2510.18779)
*Zizheng Zhan,Ken Deng,Xiaojiang Zhang,Jinghui Wang,Huaixi Tang,Zhiyi Lai,Haoyang Huang,Wen Xiang,Kun Wu,Wenhao Zhuang,Minglei Zhang,Shaojie Wang,Shangpeng Yan,Kepeng Lei,Zongxian Feng,Huiming Wang,Zheng Lin,Mengtong Li,Mengfei Xie,Yinghan Cui,Xuxing Chen,Chao Wang,Weihao Li,Wenqiang Zhu,Jiarong Zhang,Jingxuan Xu,Songwei Yu,Yifan Yao,Xinping Lei,Han Li,Junqi Xiong,Zuchen Gao,Dailin Li,Haimo Li,Jiaheng Liu,Yuqun Zhang,Junyi Peng,Haotian Zhang,Bin Chen*

Main category: cs.CL

TL;DR: 本文介绍了KAT-Coder，一种经过多阶段训练的多语言智能编程模型，能够在真实软件开发环境中自主推理、规划和执行任务。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在静态文本训练与动态实际执行之间存在差距，亟需提升模型在真实开发环境中的自主编码能力。

Method: 设计了四个训练阶段：中期训练提升推理规划能力；监督微调构建百万样本多语言数据集；强化学习微调使用多真值奖励策略优化策略；部署适应阶段通过错误掩码微调和树状轨迹训练适配生产环境IDE。

Result: KAT-Coder具备稳定的工具使用能力、准确的指令理解和长上下文推理能力，形成可部署的智能编码代理基础模型。

Conclusion: 通过多阶段训练策略，KAT-Coder成功缩小静态训练与动态执行的差距，推动智能编程代理在真实软件开发中的应用。

Abstract: Recent advances in large language models (LLMs) have enabled progress in
agentic coding, where models autonomously reason, plan, and act within
interactive software development workflows. However, bridging the gap between
static text-based training and dynamic real-world agentic execution remains a
core challenge. In this technical report, we present KAT-Coder, a large-scale
agentic code model trained through a multi-stage curriculum encompassing
Mid-Term Training, Supervised Fine-Tuning (SFT), Reinforcement Fine-Tuning
(RFT), and Reinforcement-to-Deployment Adaptation. The Mid-Term stage enhances
reasoning, planning, and reflection capabilities through a corpus of real
software engineering data and synthetic agentic interactions. The SFT stage
constructs a million-sample dataset balancing twenty programming languages, ten
development contexts, and ten task archetypes. The RFT stage introduces a novel
multi-ground-truth reward formulation for stable and sample-efficient policy
optimization. Finally, the Reinforcement-to-Deployment phase adapts the model
to production-grade IDE environments using Error-Masked SFT and Tree-Structured
Trajectory Training. In summary, these stages enable KAT-Coder to achieve
robust tool-use reliability, instruction alignment, and long-context reasoning,
forming a deployable foundation for real-world intelligent coding agents. Our
KAT series 32B model, KAT-Dev, has been open-sourced on
https://huggingface.co/Kwaipilot/KAT-Dev.

</details>


### [62] [WebSeer: Training Deeper Search Agents through Reinforcement Learning with Self-Reflection](https://arxiv.org/abs/2510.18798)
*Guanzhong He,Zhen Yang,Jinxin Liu,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 提出WebSeer，一种结合自我反思机制的强化学习搜索代理，实现更深工具使用和更高答题准确率。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习搜索代理工具使用深度有限，多轮交互时误差积累问题突出，需要更智能的交互检索机制。

Method: 构建含反思模式的大型数据集，设计冷启动与强化学习统一的两阶段训练框架，提升模型生成更长且反思性强的工具使用轨迹。

Result: 使用单一14B模型，在HotpotQA和SimpleQA数据集上达到72.3%和90.0%的准确率，优于现有方法，并具备强泛化能力。

Conclusion: WebSeer通过引入自我反思机制显著提升搜索代理的工具使用深度和答题表现，为智能信息检索与决策提供有效方案。

Abstract: Search agents have achieved significant advancements in enabling intelligent
information retrieval and decision-making within interactive environments.
Although reinforcement learning has been employed to train agentic models
capable of more dynamic interactive retrieval, existing methods are limited by
shallow tool-use depth and the accumulation of errors over multiple iterative
interactions. In this paper, we present WebSeer, a more intelligent search
agent trained via reinforcement learning enhanced with a self-reflection
mechanism. Specifically, we construct a large dataset annotated with reflection
patterns and design a two-stage training framework that unifies cold start and
reinforcement learning within the self-reflection paradigm for real-world
web-based environments, which enables the model to generate longer and more
reflective tool-use trajectories. Our approach substantially extends tool-use
chains and improves answer accuracy. Using a single 14B model, we achieve
state-of-the-art results on HotpotQA and SimpleQA, with accuracies of 72.3% and
90.0%, respectively, and demonstrate strong generalization to
out-of-distribution datasets. The code is available at
https://github.com/99hgz/WebSeer

</details>


### [63] [Fine-Tuned Thoughts: Leveraging Chain-of-Thought Reasoning for Industrial Asset Health Monitoring](https://arxiv.org/abs/2510.18817)
*Shuxin Lin,Dhaval Patel,Christodoulos Constantinides*

Main category: cs.CL

TL;DR: 本文提出了一种基于知识蒸馏的框架，将大型语言模型的链式推理能力迁移到小型语言模型中，以提升工业资产健康领域的推理和决策能力。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型虽然高效且适合特定领域任务，但在执行复杂推理方面存在困难，尤其是在工业4.0等专业领域。

Method: 通过链式思维（Chain-of-Thought, CoT）蒸馏技术，利用多选题问答（MCQA）提示，将大型语言模型的推理能力转移至小型语言模型。同时采用上下文学习验证知识质量，并基准测试微调后的小型模型性能。

Result: 微调后的小型语言模型在链式推理任务中显著优于基础模型，推理能力接近大型模型水平。

Conclusion: 基于CoT蒸馏的小型语言模型能够有效提升工业领域复杂推理能力，提供准确且成本效益高的解决方案。代码已开源供进一步研究。

Abstract: Small Language Models (SLMs) are becoming increasingly popular in specialized
fields, such as industrial applications, due to their efficiency, lower
computational requirements, and ability to be fine-tuned for domain-specific
tasks, enabling accurate and cost-effective solutions. However, performing
complex reasoning using SLMs in specialized fields such as Industry 4.0 remains
challenging. In this paper, we propose a knowledge distillation framework for
industrial asset health, which transfers reasoning capabilities via
Chain-of-Thought (CoT) distillation from Large Language Models (LLMs) to
smaller, more efficient models (SLMs). We discuss the advantages and the
process of distilling LLMs using multi-choice question answering (MCQA) prompts
to enhance reasoning and refine decision-making. We also perform in-context
learning to verify the quality of the generated knowledge and benchmark the
performance of fine-tuned SLMs with generated knowledge against widely used
LLMs. The results show that the fine-tuned SLMs with CoT reasoning outperform
the base models by a significant margin, narrowing the gap to their LLM
counterparts. Our code is open-sourced at:
https://github.com/IBM/FailureSensorIQ.

</details>


### [64] [MTraining: Distributed Dynamic Sparse Attention for Efficient Ultra-Long Context Training](https://arxiv.org/abs/2510.18830)
*Wenxuan Li,Chengruidong Zhang,Huiqiang Jiang,Yucheng Li,Yuqing Yang,Lili Qiu*

Main category: cs.CL

TL;DR: 本文提出了MTraining，一种基于动态稀疏注意力的分布式训练方法，显著提升了大语言模型在超长上下文（最大512K令牌）下的训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型采用长上下文窗口以提升复杂推理能力，但动态稀疏注意力在超长上下文下分布式训练时面临工作负载和步骤不均衡的难题。

Method: MTraining结合动态稀疏训练模式、平衡稀疏环注意力和层级稀疏环注意力，解决动态稀疏注意力训练中的计算不平衡和通信开销问题。

Result: 在32块A100显卡集群上，利用MTraining训练Qwen2.5-3B模型，实现上下文窗口从32K扩展到512K，训练吞吐量提升6倍，同时保持模型准确性。

Conclusion: MTraining有效提升了超长上下文大语言模型的分布式训练效率，是解决动态稀疏注意力在超长文本训练中的关键技术。

Abstract: The adoption of long context windows has become a standard feature in Large
Language Models (LLMs), as extended contexts significantly enhance their
capacity for complex reasoning and broaden their applicability across diverse
scenarios. Dynamic sparse attention is a promising approach for reducing the
computational cost of long-context. However, efficiently training LLMs with
dynamic sparse attention on ultra-long contexts-especially in distributed
settings-remains a significant challenge, due in large part to worker- and
step-level imbalance. This paper introduces MTraining, a novel distributed
methodology leveraging dynamic sparse attention to enable efficient training
for LLMs with ultra-long contexts. Specifically, MTraining integrates three key
components: a dynamic sparse training pattern, balanced sparse ring attention,
and hierarchical sparse ring attention. These components are designed to
synergistically address the computational imbalance and communication overheads
inherent in dynamic sparse attention mechanisms during the training of models
with extensive context lengths. We demonstrate the efficacy of MTraining by
training Qwen2.5-3B, successfully expanding its context window from 32K to 512K
tokens on a cluster of 32 A100 GPUs. Our evaluations on a comprehensive suite
of downstream tasks, including RULER, PG-19, InfiniteBench, and Needle In A
Haystack, reveal that MTraining achieves up to a 6x higher training throughput
while preserving model accuracy. Our code is available at
https://github.com/microsoft/MInference/tree/main/MTraining.

</details>


### [65] [Towards Faithful and Controllable Personalization via Critique-Post-Edit Reinforcement Learning](https://arxiv.org/abs/2510.18849)
*Chenghao Zhu,Meiling Tao,Tiannan Wang,Dongyi Ding,Yuchen Eleanor Jiang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: 本文提出了Critique-Post-Edit框架，通过多维度评分和文本点评，引导大语言模型更加真实且可控地实现个性化，显著优于传统强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有的个性化微调方法（SFT和RLHF）在捕捉个体用户偏好方面存在性能瓶颈和奖赏模型作弊问题，导致个性化表达不真实。

Method: 提出了包含个性化生成奖赏模型（提供多维度评分和文本点评）和Critique-Post-Edit机制（模型根据点评自我修正输出）的强化学习框架。

Result: 在受控长度评测下，该方法相比标准PPO算法显著提升个性化表现，Qwen2.5-7B模型提升11%胜率，Qwen2.5-14B超过GPT-4.1水平。

Conclusion: 该研究展示了一种高效、有效且可控的个性化路径，为大语言模型的个性化定制提供了实用方案。

Abstract: Faithfully personalizing large language models (LLMs) to align with
individual user preferences is a critical but challenging task. While
supervised fine-tuning (SFT) quickly reaches a performance plateau, standard
reinforcement learning from human feedback (RLHF) also struggles with the
nuances of personalization. Scalar-based reward models are prone to reward
hacking which leads to verbose and superficially personalized responses. To
address these limitations, we propose Critique-Post-Edit, a robust
reinforcement learning framework that enables more faithful and controllable
personalization. Our framework integrates two key components: (1) a
Personalized Generative Reward Model (GRM) that provides multi-dimensional
scores and textual critiques to resist reward hacking, and (2) a
Critique-Post-Edit mechanism where the policy model revises its own outputs
based on these critiques for more targeted and efficient learning. Under a
rigorous length-controlled evaluation, our method substantially outperforms
standard PPO on personalization benchmarks. Personalized Qwen2.5-7B achieves an
average 11\% win-rate improvement, and personalized Qwen2.5-14B model surpasses
the performance of GPT-4.1. These results demonstrate a practical path to
faithful, efficient, and controllable personalization.

</details>


### [66] [Every Step Evolves: Scaling Reinforcement Learning for Trillion-Scale Thinking Model](https://arxiv.org/abs/2510.18855)
*Ling Team,Anqi Shen,Baihui Li,Bin Hu,Bin Jing,Cai Chen,Chao Huang,Chao Zhang,Chaokun Yang,Cheng Lin,Chengyao Wen,Congqi Li,Deng Zhao,Dingbo Yuan,Donghai You,Fagui Mao,Fanzhuang Meng,Feng Xu,Guojie Li,Guowei Wang,Hao Dai,Haonan Zheng,Hong Liu,Jia Guo,Jiaming Liu,Jian Liu,Jianhao Fu,Jiannan Shi,Jianwen Wang,Jianxin Lai,Jin Yang,Jun Mei,Jun Zhou,Junbo Zhao,Junping Zhao,Kuan Xu,Le Su,Lei Chen,Li Tang,Liang Jiang,Liangcheng Fu,Lianhao Xu,Linfeng Shi,Lisha Liao,Longfei Zheng,Meng Li,Mingchun Chen,Qi Zuo,Qiang Cheng,Qianggang Cao,Qitao Shi,Quanrui Guo,Senlin Zhu,Shaofei Wang,Shaomian Zheng,Shuaicheng Li,Shuwei Gu,Siba Chen,Tao Wu,Tao Zhang,Tianyu Zhang,Tianyu Zhou,Tiwei Bie,Tongkai Yang,Wang Hong,Wang Ren,Weihua Chen,Wenbo Yu,Wengang Zheng,Xiangchun Wang,Xiaodong Yan,Xiaopei Wan,Xin Zhao,Xinyu Kong,Xinyu Tang,Xudong Han,Xudong Wang,Xuemin Yang,Xueyu Hu,Yalin Zhang,Yan Sun,Yicheng Shan,Yilong Wang,Yingying Xu,Yongkang Liu,Yongzhen Guo,Yuanyuan Wang,Yuchen Yan,Yuefan Wang,Yuhong Guo,Zehuan Li,Zhankai Xu,Zhe Li,Zhenduo Zhang,Zhengke Gui,Zhenxuan Pan,Zhenyu Huang,Zhenzhong Lan,Zhiqiang Ding,Zhiqiang Zhang,Zhixun Li,Zhizhen Liu,Zihao Wang,Zujie Wen*

Main category: cs.CL

TL;DR: Ring-1T是一款拥有1万亿参数的开源顶尖思维模型，通过三项创新技术解决了大规模训练中的挑战，显著提升推理能力并在多项基准测试中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 训练1万亿参数规模的模型面临训练-推理不匹配、长序列推理效率低和强化学习系统瓶颈等前所未有的挑战。

Method: 提出三大创新：（1）IcePop通过token级别的不匹配遮罩和裁剪稳定强化学习训练；（2）C3PO++通过动态划分长推理序列提高资源利用率和时间效率；（3）ASystem强化学习框架突破系统瓶颈，支持万亿参数模型训练。

Result: Ring-1T在多个关键基准测试中表现卓越，如AIME-2025得分93.4，HMMT-2025得分86.72，CodeForces达2088分，ARC-AGI-v1得55.94分，并在IMO-2025获得银牌级别成绩。

Conclusion: Ring-1T的开源发布推动了大规模推理智能的民主化，树立了开源模型性能的新标杆，展示了万亿参数模型的卓越推理能力。

Abstract: We present Ring-1T, the first open-source, state-of-the-art thinking model
with a trillion-scale parameter. It features 1 trillion total parameters and
activates approximately 50 billion per token. Training such models at a
trillion-parameter scale introduces unprecedented challenges, including
train-inference misalignment, inefficiencies in rollout processing, and
bottlenecks in the RL system. To address these, we pioneer three interconnected
innovations: (1) IcePop stabilizes RL training via token-level discrepancy
masking and clipping, resolving instability from training-inference mismatches;
(2) C3PO++ improves resource utilization for long rollouts under a token budget
by dynamically partitioning them, thereby obtaining high time efficiency; and
(3) ASystem, a high-performance RL framework designed to overcome the systemic
bottlenecks that impede trillion-parameter model training. Ring-1T delivers
breakthrough results across critical benchmarks: 93.4 on AIME-2025, 86.72 on
HMMT-2025, 2088 on CodeForces, and 55.94 on ARC-AGI-v1. Notably, it attains a
silver medal-level result on the IMO-2025, underscoring its exceptional
reasoning capabilities. By releasing the complete 1T parameter MoE model to the
community, we provide the research community with direct access to cutting-edge
reasoning capabilities. This contribution marks a significant milestone in
democratizing large-scale reasoning intelligence and establishes a new baseline
for open-source model performance.

</details>


### [67] [How Do LLMs Use Their Depth?](https://arxiv.org/abs/2510.18871)
*Akshat Gupta,Jay Yeung,Gopala Anumanchipalli,Anna Ivanova*

Main category: cs.CL

TL;DR: 本文提出了"先猜测后修正"框架，揭示了大型语言模型在预测过程中分层使用深度的细致动态。


<details>
  <summary>Details</summary>
Motivation: 当前对大型语言模型的层级预测动态了解不足，缺乏对模型不同层如何贡献预测的细粒度认识。

Method: 通过追踪多个开源模型的中间表征，分析早期层高频词的预测和后续层的上下文修正，结合词性、事实回忆及多项选择任务进行层深动态分析。

Result: 发现早期层多为高频词的统计猜测，后续层通过上下文信息对猜测进行超过70%的修正。功能词最早被正确预测，事实回答中的首个词需要更深计算，多项选择中先识别格式后确定答案。

Conclusion: 语言模型的预测过程呈现分层、递进的深度利用特征，理解此机制有助于优化模型计算效率。

Abstract: Growing evidence suggests that large language models do not use their depth
uniformly, yet we still lack a fine-grained understanding of their layer-wise
prediction dynamics. In this paper, we trace the intermediate representations
of several open-weight models during inference and reveal a structured and
nuanced use of depth. Specifically, we propose a "Guess-then-Refine" framework
that explains how LLMs internally structure their computations to make
predictions. We first show that the top-ranked predictions in early LLM layers
are composed primarily of high-frequency tokens, which act as statistical
guesses proposed by the model early on due to the lack of appropriate
contextual information. As contextual information develops deeper into the
model, these initial guesses get refined into contextually appropriate tokens.
Even high-frequency token predictions from early layers get refined >70% of the
time, indicating that correct token prediction is not "one-and-done". We then
go beyond frequency-based prediction to examine the dynamic usage of layer
depth across three case studies. (i) Part-of-speech analysis shows that
function words are, on average, the earliest to be predicted correctly. (ii)
Fact recall task analysis shows that, in a multi-token answer, the first token
requires more computational depth than the rest. (iii) Multiple-choice task
analysis shows that the model identifies the format of the response within the
first half of the layers, but finalizes its response only toward the end.
Together, our results provide a detailed view of depth usage in LLMs, shedding
light on the layer-by-layer computations that underlie successful predictions
and providing insights for future works to improve computational efficiency in
transformer-based models.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [68] [TACLA: An LLM-Based Multi-Agent Tool for Transactional Analysis Training in Education](https://arxiv.org/abs/2510.17913)
*Monika Zamojska,Jarosław A. Chudziak*

Main category: cs.MA

TL;DR: 本文提出了一种基于事务分析的多智能体架构TACLA，利用父母、成人、儿童三个自我状态实现心理真实的人类社会动态模拟。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在模拟具有心理深度和一致人格行为的人类社会动态方面存在挑战，难以满足高保真训练工具需求。

Method: TACLA架构中，每个智能体包含父母、成人、儿童三个自我状态，并由一个协调者智能体根据上下文和生命脚本优先激活相应状态，确保心理真实的响应。

Result: 在教育场景验证中，TACLA成功展示了学生智能体的自我状态动态切换，有效模拟了不同教师干预策略下的冲突升级与缓解。

Conclusion: TACLA实现了动态且基于心理理论的社会交互仿真，提升了对教育等领域高效AI工具的支持潜力。

Abstract: Simulating nuanced human social dynamics with Large Language Models (LLMs)
remains a significant challenge, particularly in achieving psychological depth
and consistent persona behavior crucial for high-fidelity training tools. This
paper introduces TACLA (Transactional Analysis Contextual LLM-based Agents), a
novel Multi-Agent architecture designed to overcome these limitations. TACLA
integrates core principles of Transactional Analysis (TA) by modeling agents as
an orchestrated system of distinct Parent, Adult, and Child ego states, each
with its own pattern memory. An Orchestrator Agent prioritizes ego state
activation based on contextual triggers and an agent's life script, ensuring
psychologically authentic responses. Validated in an educational scenario,
TACLA demonstrates realistic ego state shifts in Student Agents, effectively
modeling conflict de-escalation and escalation based on different teacher
intervention strategies. Evaluation shows high conversational credibility and
confirms TACLA's capacity to create dynamic, psychologically-grounded social
simulations, advancing the development of effective AI tools for education and
beyond.

</details>


### [69] [Adaptive Coopetition: Leveraging Coarse Verifier Signals for Resilient Multi-Agent LLM Reasoning](https://arxiv.org/abs/2510.18179)
*Rui Jerry Huang,Wendy Liu,Anastasia Miin*

Main category: cs.MA

TL;DR: 本文提出了一种名为Adaptive Coopetition (AdCo)的推理时计算框架，通过自适应UCB机制协调大语言模型代理间的合作与竞争，提升数学推理任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理策略存在模型偏见强化和多代理协作失败的问题，且高性能校验器训练成本高，需寻求无需依赖高性能校验器且能有效提升推理性能的方法。

Method: 引入基于UCB的自适应“合作竞争”机制，代理通过粗略校验信号决定合作或竞争，利用同行反馈迭代优化推理，促进不确定性驱动探索。

Result: 在数学推理基准测试中，AdCo在更具挑战性的数据集上实现了20%的相对性能提升，表现稳健且准确性一致。

Conclusion: AdCo框架通过模型知识多样性和推理轨迹结合，提高推理的鲁棒性和一致性，为多代理大语言模型系统的推理时计算提供新思路。

Abstract: Inference-time computation is a critical yet challenging paradigm for
enhancing the reasoning performance of large language models (LLMs). While
existing strategies improve reasoning stability and consistency, they suffer
from notable limitations: self-correction often reinforces the model's initial
biases, and Multi-Agent Collaboration (MAC) often fails due to the lack of
efficient coordination mechanisms, leading to collective errors. Although
high-performing verifiers can detect reasoning errors, making them reliable
requires substantial training. To address these challenges, we introduce a
novel inference-time framework, Adaptive Coopetition (AdCo), in which LLM
agents utilize an adaptive, UCB-based "coopetition" mechanism. At each round,
agents leverage coarse verifier signals to determine whether to collaborate or
compete, and iteratively refine their reasoning based on peer feedback. Without
relying on high-performance verifiers, our adaptive strategy achieves
significant performance gains on mathematical reasoning benchmarks, yielding a
20% relative improvement over baselines on the more challenging dataset. Our
approach remains robust and consistent in terms of accuracy under different
sample sizes and configurations. This adaptive, signal-guided "coopetition"
framework enhances reasoning robustness by leveraging both model knowledge
diversity and reasoning trace measures, while also promoting uncertainty-driven
exploration, especially when participants have comparable capabilities. From
this perspective, our work offers a fresh lens on inference-time computation
and paves the way for more resilient multi-agent LLM systems. Our code is
available at: https://github.com/AdCo-Research/adaptive-coopetition.

</details>


### [70] [The Emergence of Complex Behavior in Large-Scale Ecological Environments](https://arxiv.org/abs/2510.18221)
*Joseph Bejjani,Chase Van Amburg,Chengrui Wang,Chloe Huangyuan Su,Sarah M. Pratt,Yasin Mazloumi,Naeem Khoshnevis,Sham M. Kakade,Kianté Brantley*

Main category: cs.MA

TL;DR: 研究大规模生态环境中，物理尺度和种群大小如何影响复杂行为的自然出现。


<details>
  <summary>Details</summary>
Motivation: 探究自然竞争和环境压力下，未监督个体的行为如何在大规模种群中演化出现复杂行为，而非仅优化单一性能策略。

Method: 在无监督、无明确奖励的设定下，通过生殖、突变和自然选择机制，模拟超过6万智能体的神经网络策略演化，在不同环境尺度和感知模式下观察行为出现。

Result: 发现了包括远程资源提取、基于视觉的觅食和捕食等多种复杂行为，这些行为随着环境和种群规模增大而更稳定且持续出现。

Conclusion: 规模扩展有助于复杂生态行为的自然出现，生态作为机器学习新工具在计算资源丰富时代具有广阔前景。

Abstract: We explore how physical scale and population size shape the emergence of
complex behaviors in open-ended ecological environments. In our setting, agents
are unsupervised and have no explicit rewards or learning objectives but
instead evolve over time according to reproduction, mutation, and natural
selection. As they act, agents also shape their environment and the population
around them in an ongoing dynamic ecology. Our goal is not to optimize a single
high-performance policy, but instead to examine how behaviors emerge and evolve
across large populations due to natural competition and environmental
pressures. In an effort to discover how complex behaviors naturally emerge, we
conduct experiments in large-scale worlds that reach populations of more than
60,000 individual agents, each with their own evolved neural network policy. We
identify various emergent behaviors such as long-range resource extraction,
vision-based foraging, and predation that arise under competitive and survival
pressures. We examine how sensing modalities and environmental scale affect the
emergence of these behaviors, finding that some appear only in sufficiently
large environments and populations, with larger scales increasing behavioral
stability and consistency. While there is a rich history of research in
evolutionary settings, our scaling results provide promising new directions to
explore ecology as an instrument of machine learning in an era of abundant
computational resources. Experimental code is available at
https://github.com/jbejjani2022/ecological-emergent-behavior.

</details>


### [71] [From Agent Simulation to Social Simulator: A Comprehensive Review (Part 1)](https://arxiv.org/abs/2510.18271)
*Xiao Xue,Deyu Zhou,Ming Zhang,Fei-Yue Wang*

Main category: cs.MA

TL;DR: 本文综述了基于代理的建模（ABM）的历史发展、设计原则及经典案例，重点介绍了个体模型、环境模型和规则模型的基础。


<details>
  <summary>Details</summary>
Motivation: 传统物理仿真方法在社会领域面临重大挑战，需采用ABM以更好模拟复杂社交系统。

Method: 回顾ABM的发展历程与设计原则，介绍基础社会系统模拟模型，及展示思想实验、机制探索和平行优化三类经典案例。

Result: 系统梳理了ABM的理论基础与应用实证，展示了其在社会科学中的多样化应用。

Conclusion: ABM是社会系统模拟领域的重要工具，能够有效解决传统方法的局限性，促进深入理解复杂社会现象。

Abstract: This is the first part of the comprehensive review, focusing on the
historical development of Agent-Based Modeling (ABM) and its classic cases. It
begins by discussing the development history and design principles of
Agent-Based Modeling (ABM), helping readers understand the significant
challenges that traditional physical simulation methods face in the social
domain. Then, it provides a detailed introduction to foundational models for
simulating social systems, including individual models, environmental models,
and rule-based models. Finally, it presents classic cases of social simulation,
covering three types: thought experiments, mechanism exploration, and parallel
optimization.

</details>


### [72] [Socialized Learning and Emergent Behaviors in Multi-Agent Systems based on Multimodal Large Language Models](https://arxiv.org/abs/2510.18515)
*Sureyya Akin,Shruti T. Tiwari,Ram Bhattacharya,Sagar A. Raman,Kiran Mohanty,Sita Krishnan*

Main category: cs.MA

TL;DR: 本文提出了多模态社会化学习框架（M-S2L），通过结合多模态大型语言模型和社会学习机制，提升智能体的社会智能和协作能力。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统在建构复杂任务中缺乏有效的社会化协作能力，亟需融合多模态感知与社会学习以提升协作智能。

Method: 设计了集成视觉与文本的多模态感知和结构化动作的M-S2L框架，结合强化学习、观测学习和反馈驱动的通信学习以及情节记忆系统。

Result: 在协作装配环境中，M-S2L智能体在任务完成率和完成时间上显著优于文本唯一和无社会学习基线，展现了高效通信协议和角色专门化。

Conclusion: 多模态感知与社会化学习的融合是实现类人多智能体协作智能的关键，M-S2L展示了机器社会认知的初步形态。

Abstract: This search introduces the Multimodal Socialized Learning Framework (M-S2L),
designed to foster emergent social intelligence in AI agents by integrating
Multimodal Large Language Models (M-LLMs) with social learning mechanisms. The
framework equips agents with multimodal perception (vision and text) and
structured action capabilities, enabling physical manipulation and grounded
multimodal communication (e.g., text with visual pointers). M-S2L combines
direct reinforcement learning with two novel social learning pathways:
multimodal observational learning and communication-driven learning from
feedback, augmented by an episodic memory system for long-term social context.
  We evaluate M-S2L in a Collaborative Assembly Environment (CAE), where agent
teams must construct complex devices from ambiguous blueprints under
informational asymmetry. Across tasks of increasing complexity, M-S2L agents
consistently outperform Text-Only and No-Social-Learning baselines in Task
Completion Rate and Time to Completion, particularly in dynamic problem-solving
scenarios. Ablation studies confirm the necessity of both multimodality and
socialized learning. Our analysis reveals the emergence of efficient
communication protocols integrating visual pointers with concise text,
alongside rapid role specialization leading to stable labor division.
Qualitative case studies demonstrate agents' abilities for shared awareness,
dynamic re-planning, and adaptive problem-solving, suggesting a nascent form of
machine social cognition. These findings indicate that integrating multimodal
perception with explicit social learning is critical for developing human-like
collaborative intelligence in multi-agent systems.

</details>


### [73] [Fetch.ai: An Architecture for Modern Multi-Agent Systems](https://arxiv.org/abs/2510.18699)
*Michael J. Wooldridge,Attila Bagoly,Jonathan J. Ward,Emanuele La Malfa,Gabriel Paludo Licks*

Main category: cs.MA

TL;DR: 该论文介绍了Fetch.ai架构，结合了多智能体系统与现代AI，构建了去中心化且可信的多智能体平台，支持智能体安全发现、协作及交易。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM驱动智能系统忽视了多智能体系统的基础研究，存在中心化及信任通信机制不足的问题。

Method: 提出Fetch.ai工业级多层架构，基于区块链实现身份、发现和交易的去中心化服务，提供安全可交互的智能体开发框架和云部署平台，并引入智能编排层将人类高层目标转为多智能体工作流。

Result: 通过一个去中心化物流案例演示了该系统中智能体间的动态发现、协商和安全交易能力。

Conclusion: Fetch.ai架构为从现有智能体实现迈向开放、协同和可持续的多智能体生态系统提供了一套系统化解决方案。

Abstract: Recent surges in LLM-driven intelligent systems largely overlook decades of
foundational multi-agent systems (MAS) research, resulting in frameworks with
critical limitations such as centralization and inadequate trust and
communication protocols. This paper introduces the Fetch.ai architecture, an
industrial-strength platform designed to bridge this gap by facilitating the
integration of classical MAS principles with modern AI capabilities. We present
a novel, multi-layered solution built on a decentralized foundation of on-chain
blockchain services for verifiable identity, discovery, and transactions. This
is complemented by a comprehensive development framework for creating secure,
interoperable agents, a cloud-based platform for deployment, and an intelligent
orchestration layer where an agent-native LLM translates high-level human goals
into complex, multi-agent workflows. We demonstrate the deployed nature of this
system through a decentralized logistics use case where autonomous agents
dynamically discover, negotiate, and transact with one another securely.
Ultimately, the Fetch.ai stack provides a principled architecture for moving
beyond current agent implementations towards open, collaborative, and
economically sustainable multi-agent ecosystems.

</details>


### [74] [Computational Foundations for Strategic Coopetition: Formalizing Interdependence and Complementarity](https://arxiv.org/abs/2510.18802)
*Vik Pant,Eric Yu*

Main category: cs.MA

TL;DR: 本文提出一种结合i*建模与博弈论的协同竞争定量分析方法，实现了对战略依赖和互补性的形式化，验证了方法的理论与实证有效性。


<details>
  <summary>Details</summary>
Motivation: 现代社会技术系统中的行动者既合作创造价值又竞争获取价值，现有的i*建模语言缺乏定量分析动态权衡的机制，而传统博弈论虽有数学严谨性但缺乏上下文丰富性，需桥接两者优势。

Method: 基于i*结构依赖，构建依赖-被依赖关系的定量互依系数；采用Brandenburger和Nalebuff的附加价值概念形式化互补性；结合价值分配中的议价力量，引入考虑结构互依的纳什均衡博弈模型；并通过理论和实证实验验证方法。

Result: 实验测试覆盖了不同权力和对数价值函数规格，显示公式形式稳健；实证分析三星与索尼的联合投资案例，对数函数拟合优于幂函数（验证得分45/60），幂函数提供理论可解性。

Conclusion: 该技术报告构建了定量分析战略合作竞争的基础框架，为需求工程和多智能体系统中的战略协同研究提供理论支持，并配套研究涵盖信任、团队生产及互惠机制。

Abstract: Modern socio-technical systems are characterized by strategic coopetition
where actors simultaneously cooperate to create value and compete to capture
it. While conceptual modeling languages like i* provide rich qualitative
representations of strategic dependencies, they lack mechanisms for
quantitative analysis of dynamic trade-offs. Conversely, classical game theory
offers mathematical rigor but strips away contextual richness. This technical
report bridges this gap by developing computational foundations that formalize
two critical dimensions of coopetition: interdependence and complementarity. We
ground interdependence in i* structural dependency analysis, translating
depender-dependee-dependum relationships into quantitative interdependence
coefficients through a structured translation framework. We formalize
complementarity following Brandenburger and Nalebuff's Added Value concept,
modeling synergistic value creation with validated parameterization. We
integrate structural dependencies with bargaining power in value appropriation
and introduce a game-theoretic formulation where Nash Equilibrium incorporates
structural interdependence. Validation combines comprehensive experimental
testing across power and logarithmic value function specifications,
demonstrating functional form robustness, with empirical application to the
Samsung-Sony S-LCD joint venture (2004-2011), where logarithmic specifications
achieve superior empirical fit (validation score 45/60) while power functions
provide theoretical tractability. This technical report serves as the
foundational reference for a coordinated research program examining strategic
coopetition in requirements engineering and multi-agent systems, with companion
work addressing trust dynamics, team production, and reciprocity mechanisms.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [75] [AI Exchange Platforms](https://arxiv.org/abs/2510.17839)
*Johannes Schneider,Rene Abraham*

Main category: cs.SE

TL;DR: 本文提出了一个完整的AI模型交换平台分类框架，分析了其关键特征和公共研究机构与组织之间的互动模式，为理解AI模型共享及应用提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能，特别是基础模型的快速发展，组织对AI模型交换平台的需求日益增加，但当前缺乏系统的分类和理解框架。

Method: 构建分类法，系统考察AI模型交换平台的关键维度及特征，重点研究平台内公共研究机构与组织的互动方式，如同行评审机制、在线测试和定制化部署等。

Result: 识别出多种平台特征和互动模式，揭示了AI模型交换平台在质量控制和模型优化中的作用，强调其对组织效率和适应性的促进作用。

Conclusion: 本研究为从业者理解AI模型交换平台中的挑战与机遇提供实用指导，并为学术界进一步研究AI模型共享的演进和影响奠定基础，强调平台设计需注重适应性和创新。

Abstract: The rapid integration of Artificial Intelligence (AI) into organizational
technology frameworks has transformed how organizations engage with AI-driven
models, influencing both operational performance and strategic innovation. With
the advent of foundation models, the importance of structured platforms for AI
model exchange has become paramount for organizational efficacy and
adaptability. However, a comprehensive framework to categorize and understand
these platforms remains underexplored. To address this gap, our taxonomy
provides a structured approach to categorize AI exchange platforms, examining
key dimensions and characteristics, as well as revealing interesting
interaction patterns between public research institutions and organizations:
Some platforms leverage peer review as a mechanism for quality control, and
provide mechanisms for online testing, deploying, and customization of models.
Our paper is beneficial to practitioners seeking to understand challenges and
opportunities that arise from AI exchange platforms. For academics, the
taxonomy serves as a foundation for further research into the evolution,
impact, and best practices associated with AI model sharing and utilization in
different contexts. Additionally, our study provides insights into the evolving
role of AI in various industries, highlighting the importance of adaptability
and innovation in platform design. This paper serves as a critical resource for
understanding the dynamic interplay between technology, business models, and
user engagement in the rapidly growing domain of AI model exchanges pointing
also towards possible future evolution.

</details>


### [76] [Vibe Coding: Toward an AI-Native Paradigm for Semantic and Intent-Driven Programming](https://arxiv.org/abs/2510.17842)
*Vinay Bamil*

Main category: cs.SE

TL;DR: 本文提出了一种名为vibe coding的新兴AI原生编程范式，通过高层意图和情感描述生成软件。


<details>
  <summary>Details</summary>
Motivation: 利用大型语言模型进步，实现人类开发者通过描述'氛围'来生成代码，而非直接书写代码。

Method: 定义了vibe coding的形式，提出包括意图解析器、语义嵌入引擎、智能代码生成器和交互反馈机制的架构，并描述了假想实现。

Result: vibe coding在生产力和民主化方面有提升，但也存在对齐、可重复性、偏见、可解释性、维护性和安全等挑战。

Conclusion: vibe coding有望推动软件工程和人机协作，但需解决关键技术和伦理问题，未来研究方向广泛。

Abstract: Recent advances in large language models have enabled developers to generate
software by conversing with artificial intelligence systems rather than writing
code directly. This paper introduces vibe coding, an emerging AI-native
programming paradigm in which a developer specifies high-level functional
intent along with qualitative descriptors of the desired "vibe" (tone, style,
or emotional resonance). An intelligent agent then transforms those
specifications into executable software. We formalize the definition of vibe
coding and propose a reference architecture that includes an intent parser, a
semantic embedding engine, an agentic code generator, and an interactive
feedback loop. A hypothetical implementation is described. We compare vibe
coding with declarative, functional, and prompt-based programming, and we
discuss its implications for software engineering, human-AI collaboration, and
responsible AI practice. Finally, we examine reported productivity gains and
democratizing effects, review recent studies that highlight vulnerabilities and
potential slowdowns, identify key challenges such as alignment,
reproducibility, bias, explainability, maintainability, and security, and
outline future directions and open research questions.

</details>


### [77] [Smart Contracts Formal Verification: A Systematic Literature Review](https://arxiv.org/abs/2510.17865)
*Rene Davila,Everardo Barcenas,Rocio Aldeco-Perez*

Main category: cs.SE

TL;DR: 本文调查了智能合约形式验证的相关研究，提出了一种基于描述逻辑的形式验证新方法。


<details>
  <summary>Details</summary>
Motivation: 智能合约作为自动执行的代码合约，常存在运行或规范错误，需要确保其按照预定条件正确执行。

Method: 调研了现有的智能合约规范、验证工具及实验，基于这些研究提出了一种利用描述逻辑进行形式验证的新方法。

Result: 通过文献综述明确了现有方法的局限性，并提出了基于描述逻辑的验证方法，旨在提高智能合约验证的准确性。

Conclusion: 基于描述逻辑的形式验证为智能合约提供了一种有效的错误检测和验证途径，具备推广应用潜力。

Abstract: Formal verification entails testing software to ensure it operates as
specified. Smart contracts are self-executing contracts with the terms of the
agreement directly written into lines of code. They run on blockchain platforms
and automatically enforce and execute the terms of an agreement when meeting
predefined conditions. However, Smart Contracts, as software models, often
contain notable errors in their operation or specifications. This observation
prompts us to conduct a focused study examining related works published across
various sources. These publications detail specifications, verification tools,
and relevant experiments. Subsequently, this survey proposes an alternative
formal verification based on description logic.

</details>


### [78] [UniCode: A Framework for Generating High Quality Competitive Coding Problems](https://arxiv.org/abs/2510.17868)
*Xinyue Zheng,Haowei Lin,Shaofei Cai,Zilong Zheng,Yitao Liang*

Main category: cs.SE

TL;DR: UniCode框架通过利用大型语言模型自动生成多样且高质量的算法题及其抗污染测试用例，解决了静态、人工编写问题带来的数据污染和扩展性限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统竞赛编程基准测试依赖静态的人工编写题目，面临数据污染和扩展性不足的挑战。

Method: UniCode采用三种多样化策略（单题扩展、同类融合、异类融合）利用大型语言模型生成多样化题目，并通过压力驱动的测试用例合成技术结合暴力求解和基于共识的验证机制产生高质量测试集，无需标准解答。

Result: 构建了包含492道题目的基准测试集，评估19个先进的语言模型，表现出高度挑战性和区分度，最佳模型o4-mini通过率仅70.3%。

Conclusion: UniCode提供了一种可扩展且可靠的动态代码评测数据集生成方案，有效提升了自动题目生成和测试的质量与适用性。

Abstract: The reliance of competitive coding benchmarks on static, human-authored
problems creates significant challenges, including data contamination and
limited scalability. To address these issues, we introduce UniCode, a novel
framework that automatically generates high-quality algorithmic problems
alongside robust, contamination-resistant test cases. Inspired by biological
evolution that creates better and diverse offspring, our framework leverages
Large Language Models (LLMs) to systematically diversify problems through three
strategies: single problem extension, same-type fusion, and cross-type fusion.
A key innovation is our stress-driven test case synthesis pipeline, which
generates reliable test suites without requiring a canonical ground-truth
solution. This pipeline combines brute-force grounding for small-scale inputs
with a consensus-based validation mechanism for large-scale inputs to ensure
high correctness and coverage. We demonstrate effectiveness of our framework by
curating a benchmark of 492 problems and evaluating 19 state-of-the-art LLMs.
The results reveal that UniCode is highly challenging and discriminative, with
the top-performing model, o4-mini, achieving a pass rate of only 70.3%. Our
framework provides a scalable and reliable solution for generating dynamic
evaluation datasets in coding domain.

</details>


### [79] [Repairing Tool Calls Using Post-tool Execution Reflection and RAG](https://arxiv.org/abs/2510.17874)
*Jason Tsay,Zidane Wright,Gaodan Fang,Kiran Kate,Saurabh Jha,Yara Rizk*

Main category: cs.SE

TL;DR: 该论文提出了一种结合大语言模型反思与领域特定检索增强生成的方法，用于修复调用Kubernetes命令行工具kubectl时出现的语义错误。


<details>
  <summary>Details</summary>
Motivation: 工具调用常因语义错误失败且部分错误只能通过分析工具响应后识别和修复，亟需有效的后期执行反思机制。

Method: 开发了一个结合大语言模型反思和基于文档的检索增强生成（RAG）的组件，利用工具说明及故障排查文档来修复kubectl命令。

Result: 实证研究表明，该方法使kubectl命令的执行成功率提升55%，用户查询正确率提升36%，故障排查文档较官方文档使成功率提升10%。

Conclusion: 利用结合大语言模型与领域文档的反思机制，可以显著提高工具调用的正确率和成功率，尤其是面对复杂语义错误时效果显著。

Abstract: Agentic systems interact with external systems by calling tools such as
Python functions, REST API endpoints, or command line tools such as kubectl in
Kubernetes. These tool calls often fail for various syntactic and semantic
reasons. Some less obvious semantic errors can only be identified and resolved
after analyzing the tool's response. To repair these errors, we develop a
post-tool execution reflection component that combines large language model
(LLM)-based reflection with domain-specific retrieval-augmented generation
(RAG) using documents describing both the specific tool being called and
troubleshooting documents related to the tool. For this paper, we focus on the
use case of the kubectl command line tool to manage Kubernetes, a platform for
orchestrating cluster applications. Through a larger empirical study and a
smaller manual evaluation, we find that our RAG-based reflection will repair
kubectl commands such that they are both more likely to successfully execute
(pass rate) for 55% of our models evaluated and 36% more likely to correctly
answer the user query on average. We find that troubleshooting documents
improve pass rate compared to official documentation by an average of 10%.

</details>


### [80] [TritonRL: Training LLMs to Think and Code Triton Without Cheating](https://arxiv.org/abs/2510.17891)
*Jiin Woo,Shaowei Zhu,Allen Nie,Zhen Jia,Yida Wang,Youngsuk Park*

Main category: cs.SE

TL;DR: 本文提出了TritonRL，一种专门针对Triton内核生成的大型语言模型，通过监督微调和基于强化学习的训练框架，有效生成高质量、高性能的Triton内核代码。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的发展，自动化高性能系统内核生成需求增长，但Triton内核生成面临数据稀缺和不完整评估标准导致的奖励欺骗问题。

Method: 通过监督微调蒸馏Triton专用知识，结合基于可验证奖励和分层奖励分配的强化学习框架，细粒度防止奖励欺骗并提升代码质量。

Result: 在KernelBench基准测试中，TritonRL在正确性和加速性能上均超越所有其他Triton专用模型，展现出训练方法的有效性。

Conclusion: 该强化学习训练框架成功实现了稳定、细致的内核生成，推动了自动化高性能系统内核的发展。

Abstract: With the rapid evolution of large language models (LLMs), the demand for
automated, high-performance system kernels has emerged as a key enabler for
accelerating development and deployment. We introduce TritonRL, a
domain-specialized LLM for Triton kernel generation, trained with a novel
training framework that enables robust and automated kernel synthesis. Unlike
general-purpose programming languages, Triton kernel generation faces unique
challenges due to data scarcity and incomplete evaluation criteria, vulnerable
to reward hacking. Our approach addresses these challenges end-to-end by
distilling Triton-specific knowledge through supervised fine-tuning on curated
datasets, and further improving code quality via reinforcement learning (RL)
with robust, verifiable rewards and hierarchical reward assignment. Our RL
framework robustly detects reward hacking and guides both reasoning traces and
code tokens through fine-grained verification and hierarchical reward
decomposition, enabling the model to generate high-quality Triton kernels that
can truly replace existing modules. With robust and fine-grained evaluation,
our experiments on KernelBench demonstrate that TritonRL achieves
state-of-the-art correctness and speedup, surpassing all other Triton-specific
models and underscoring the effectiveness of our RL-based training paradigm.

</details>


### [81] [A Systematic Literature Review of the Use of GenAI Assistants for Code Comprehension: Implications for Computing Education Research and Practice](https://arxiv.org/abs/2510.17894)
*Yunhan Qiao,Md Istiak Hossain Shihab,Christopher Hundhausen*

Main category: cs.SE

TL;DR: 本文系统综述了2022至2024年间利用生成式人工智能（GenAI）提升代码理解的研究，揭示了GenAI在代码说明中的不足及初学者使用的挑战，并对未来研究方向提出建议。


<details>
  <summary>Details</summary>
Motivation: 随着程序员越来越依赖生成式人工智能助手开发代码，理解这些AI生成的代码解决方案变得至关重要。同时，GenAI工具被用于为程序员提供针对代码的个性化解释，计算机教育面临新挑战与机会。

Method: 本文通过系统文献综述（SLR）方法，分析了31篇2022至2024年发表的相关研究，分类了基于GenAI的技术和工具，评估了它们的效果和使用情况。

Result: 研究发现GenAI助手虽然潜力巨大，但常常提供不准确或不清晰的解释，且初学者在编写有效提示方面存在困难，限制了其助力代码理解的能力。

Conclusion: 本文总结了GenAI辅助代码理解的现状及挑战，提出对计算机教育研究和实践的启示，并指出未来研究需要解决GenAI解释质量和用户交互的关键问题。

Abstract: The ability to comprehend code has long been recognized as an essential skill
in software engineering. As programmers lean more heavily on generative
artificial intelligence (GenAI) assistants to develop code solutions, it is
becoming increasingly important for programmers to comprehend GenAI solutions
so that they can verify their appropriateness and properly integrate them into
existing code. At the same time, GenAI tools are increasingly being enlisted to
provide programmers with tailored explanations of code written both by GenAI
and humans. Thus, in computing education, GenAI presents new challenges and
opportunities for learners who are trying to comprehend computer programs. To
provide computing educators with evidence-based guidance on the use of GenAI to
facilitate code comprehension and to identify directions for future research,
we present a systematic literature review (SLR) of state-of-the-art approaches
and tools that leverage GenAI to enhance code comprehension. Our SLR focuses on
31 studies published between 2022 and 2024. Despite their potential, GenAI
assistants often yield inaccurate or unclear explanations, and novice
programmers frequently struggle to craft effective prompts, thereby impeding
their ability to leverage GenAI to aid code comprehension. Our review
classifies GenAI-based approaches and tools, identifies methods used to study
them, and summarizes the empirical evaluations of their effectiveness. We
consider the implications of our findings for computing education research and
practice, and identify directions for future research.

</details>


### [82] [SpecAgent: A Speculative Retrieval and Forecasting Agent for Code Completion](https://arxiv.org/abs/2510.17925)
*George Ma,Anurag Koul,Qi Chen,Yawen Wu,Sachit Kuhar,Yu Yu,Aritra Sengupta,Varun Kumar,Murali Krishna Ramanathan*

Main category: cs.SE

TL;DR: SpecAgent通过在索引阶段主动探索代码仓库文件，构造预测性上下文，提升了代码生成质量并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在处理含项目特定API和跨文件依赖的真实代码仓库时效果不佳，且检索增强方法要么降低检索质量，要么增加推理延迟，影响用户体验。

Method: SpecAgent在索引时异步探索仓库文件，预测未来编辑，构建预测性上下文，从而掩盖推理时延并提升生成质量。同时构建无未来信息泄露的基准数据集以更真实评估性能。

Result: 实验证明，SpecAgent较目前最佳基线模型在代码生成质量上提升9-11%（相对提升48-58%），且显著减少推理延迟。

Conclusion: 通过提前索引和预测未来编辑，SpecAgent有效提升代码生成质量和推理效率，是当前方法的显著改进。

Abstract: Large Language Models (LLMs) excel at code-related tasks but often struggle
in realistic software repositories, where project-specific APIs and cross-file
dependencies are crucial. Retrieval-augmented methods mitigate this by
injecting repository context at inference time. The low inference-time latency
budget affects either retrieval quality or the added latency adversely impacts
user experience. We address this limitation with SpecAgent, an agent that
improves both latency and code-generation quality by proactively exploring
repository files during indexing and constructing speculative context that
anticipates future edits in each file. This indexing-time asynchrony allows
thorough context computation, masking latency, and the speculative nature of
the context improves code-generation quality. Additionally, we identify the
problem of future context leakage in existing benchmarks, which can inflate
reported performance. To address this, we construct a synthetic, leakage-free
benchmark that enables a more realistic evaluation of our agent against
baselines. Experiments show that SpecAgent consistently achieves absolute gains
of 9-11% (48-58% relative) compared to the best-performing baselines, while
significantly reducing inference latency.

</details>


### [83] [From Charts to Code: A Hierarchical Benchmark for Multimodal Models](https://arxiv.org/abs/2510.17932)
*Jiahao Tang,Henry Hengyuan Zhao,Lijian Wu,Yifei Tao,Dongxing Mao,Yang Wan,Jingru Tan,Min Zeng,Min Li,Alex Jinpeng Wang*

Main category: cs.SE

TL;DR: 本文提出了Chart2Code，一个用于评估大型多模态模型图表理解与代码生成的分层基准测试，涵盖22种图表类型和2023个任务，实验显示即使是最新模型在编辑任务上表现仍有限。


<details>
  <summary>Details</summary>
Motivation: 目前缺少一个真实用户视角下的、能够逐步增加难度且涵盖多种图表任务的基准，以推动大型多模态模型在图表理解和代码生成方面的发展。

Method: 设计了三层级的任务：图表复现、复杂图表编辑以及大表格生成图表，配合多级评价指标，系统化测评模型的代码正确性和图表视觉质量；并使用25个先进多模态模型进行测试。

Result: 即使是最先进的GPT-5模型，在代码生成评价仅得0.57分，图表质量评价得0.22分，表明当前模型在复杂图表任务上仍存在较大挑战。

Conclusion: Chart2Code为图表理解与生成提供了首个分层且真实场景驱动的基准测试，有助于推动多模态推理技术进步及更通用的多模态模型发展。

Abstract: We introduce Chart2Code, a new benchmark for evaluating the chart
understanding and code generation capabilities of large multimodal models
(LMMs). Chart2Code is explicitly designed from a user-driven perspective,
capturing diverse real-world scenarios and progressively increasing task
difficulty. It consists of three levels: Level 1 (Chart Reproduction)
reproduces charts from a reference figure and user query; Level 2 (Chart
Editing) involves complex modifications such as changing chart types or adding
elements; and Level 3 (Long-Table to Chart Generation) requires models to
transform long, information-dense tables into faithful charts following user
instructions. To our knowledge, this is the first hierarchical benchmark that
reflects practical chart2code usage while systematically scaling task
complexity. In total, Chart2Code contains 2,023 tasks across 22 chart types,
paired with multi-level evaluation metrics that assess both code correctness
and the visual fidelity of rendered charts. We benchmark 25 state-of-the-art
(SoTA) LMMs, including both proprietary and the latest open-source models such
as GPT-5, Qwen2.5-VL, InternVL3/3.5, MiMo-VL, and Seed-1.6-VL. Experimental
results demonstrate that even the SoTA model GPT-5 averages only 0.57 on
code-based evaluation and 0.22 on chart-quality assessment across the editing
tasks, underscoring the difficulty of Chart2Code. We anticipate this benchmark
will drive advances in multimodal reasoning and foster the development of more
robust and general-purpose LMMs. Our code and data are available on Chart2Code.

</details>


### [84] [JunoBench: A Benchmark Dataset of Crashes in Python Machine Learning Jupyter Notebooks](https://arxiv.org/abs/2510.18013)
*Yiran Wang,José Antonio Hernández López,Ulf Nilsson,Dániel Varró*

Main category: cs.SE

TL;DR: JunoBench是第一个针对Python机器学习笔记本中真实崩溃问题的基准数据集，包含111个可复现的崩溃案例及对应修复，覆盖主流机器学习库和笔记本特有的执行问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习原型开发中Jupyter笔记本广泛使用，但缺乏针对笔记本ML代码的调试工具和相应的基准数据集。

Method: 构建并公开111个来自Kaggle的真实崩溃数据，附带可验证的修复方案，提供统一的执行环境保障可复现性。

Result: 成功收集覆盖主流ML库和笔记本特性故障的崩溃案例库，支持崩溃复现与修复验证。

Conclusion: JunoBench为笔记本机器学习开发中的错误检测、定位和修复提供了重要资源，促进了相关调试工具的发展。

Abstract: Jupyter notebooks are widely used for machine learning (ML) prototyping. Yet
few debugging tools are designed for ML code in notebooks, potentially due to
the lack of benchmarks. We introduce JunoBench, the first benchmark dataset of
real-world crashes in Python-based ML notebooks. JunoBench has 111 curated and
reproducible crashes from public Kaggle notebooks, each paired with a
verifiable fix, ranging over popular ML libraries, including TensorFlow/Keras,
PyTorch, Scikit-learn, Pandas, and NumPy, as well as notebook-specific
out-of-order execution issue. To support reproducibility and ease of use,
JunoBench offers a unified execution environment where crashes and fixes can be
reliably reproduced. By providing realistic crashes and their resolutions,
JunoBench facilitates bug detection, localization, and repair tailored to the
interactive and iterative nature of notebook-based ML development.

</details>


### [85] [DIP-AI: A Discovery Framework for AI Innovation Projects](https://arxiv.org/abs/2510.18017)
*Mariana Crisostomo Martins,Lucas Elias Cardoso Rocha,Lucas Cordeiro Romao,Taciana Novo Kudo,Marcos Kalinowski,Renato de Freitas Bulcao-Neto*

Main category: cs.SE

TL;DR: 本文提出了DIP-AI框架，旨在支持人工智能创新项目早期的问题发现阶段，通过结合ISO标准和设计思维，提升交付质量和利益相关者满意度，且在产学研结合的案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统的快速发展使得需求工程面临挑战，尤其缺乏针对AI创新项目中问题发现的支持。

Method: 基于文献综述，结合ISO 12207、5338标准和设计思维，设计了DIP-AI发现框架，并在产学研合作的AI创新项目中进行实地验证。

Result: 实证研究显示，DIP-AI框架对于促进AI项目中问题的发现具有显著的相关性和实用性，获得参与者的积极反馈。

Conclusion: DIP-AI作为AI项目问题发现的框架，为学术界提供理论支持，为工业界提供实际应用案例，有助于提升AI创新项目的质量和利益相关者满意度。

Abstract: Despite the increasing development of Artificial Intelligence (AI) systems,
Requirements Engineering (RE) activities face challenges in this new
data-intensive paradigm. We identified a lack of support for problem discovery
within AI innovation projects. To address this, we propose and evaluate DIP-AI,
a discovery framework tailored to guide early-stage exploration in such
initiatives. Based on a literature review, our solution proposal combines
elements of ISO 12207, 5338, and Design Thinking to support the discovery of AI
innovation projects, aiming at promoting higher quality deliveries and
stakeholder satisfaction. We evaluated DIP-AI in an industry-academia
collaboration (IAC) case study of an AI innovation project, in which
participants applied DIP-AI to the discovery phase in practice and provided
their perceptions about the approach's problem discovery capability,
acceptance, and suggestions. The results indicate that DIP-AI is relevant and
useful, particularly in facilitating problem discovery in AI projects. This
research contributes to academia by sharing DIP-AI as a framework for AI
problem discovery. For industry, we discuss the use of this framework in a real
IAC program that develops AI innovation projects.

</details>


### [86] [A Benchmark Dataset And LLMs Comparison For NFR Classification With Explainable AI](https://arxiv.org/abs/2510.18096)
*Esrat Ebtida Sakib,MD Ahnaf Akib,Md Muktadir Mazumder,Maliha Noushin Raida,Md. Mohsinul Kabir*

Main category: cs.SE

TL;DR: 本文针对非功能性需求（NFRs）的自动识别与分类，构建了一个包含项目章程和开源软件文档的增强数据集，并比较了多种大型语言模型的分类效果。


<details>
  <summary>Details</summary>
Motivation: 手动识别非功能性需求耗时且易出错，需自动化方法，且自动化方法前需构建全面、技术深度高的数据集。

Method: 收集来自项目章程和开源文档的NFRs，丰富现有数据集，细分子类别，并用多种大型语言模型（RoBERTa、CodeBERT、Gemma-2、Phi-3等）进行分类和比较，采用多种评估指标。

Result: Gemma-2模型表现最佳，精确率0.87，召回率0.89，F1值0.88，lime hit分78/80；Phi-3紧随其后，且lime hit分最高为79。

Conclusion: 通过构建高质量数据集并引入上下文技术背景，提升了模型对技术细节与用户需求的理解，实现了非功能性需求识别的有效自动化。

Abstract: Non-Functional Requirements (NFRs) play a critical role in determining the
overall quality and user satisfaction of software systems. Accurately
identifying and classifying NFRs is essential to ensure that software meets
performance, usability, and reliability expectations. However, manual
identification of NFRs from documentation is time-consuming and prone to
errors, necessitating automated solutions. Before implementing any automated
solution, a robust and comprehensive dataset is essential. To build such a
dataset, we collected NFRs from various Project Charters and Open Source
Software Documentation. This enhanced the technical depth and usability of an
already existing NFR dataset. We categorized NFRs into sub-classes and
identified needs using widely used Large Language Models to facilitate
automation. After classifying the NFRs, we compared the classification results
of the selected LLMs: RoBERTa, CodeBERT, Gemma-2, Phi-3, Mistral-8B, and
Llama-3.1-8B using various evaluation metrics, including precision, recall,
F1-score, and lime scores. Among these models, Gemma-2 achieved the best
results with a precision of 0.87, recall of 0.89, and F1-score of 0.88,
alongside a lime hit score of 78 out of 80. Phi-3 closely followed with a
precision of 0.85, recall of 0.87, F1-score of 0.86, and the highest lime hit
score of 79. By improving the contextual foundation, this integration enhanced
the model's comprehension of technical aspects and user requirements.

</details>


### [87] [BlueCodeAgent: A Blue Teaming Agent Enabled by Automated Red Teaming for CodeGen AI](https://arxiv.org/abs/2510.18131)
*Chengquan Guo,Yuzhou Nie,Chulin Xie,Zinan Lin,Wenbo Guo,Bo Li*

Main category: cs.SE

TL;DR: 本文提出了BlueCodeAgent，一种结合自动红队测试的端到端防御代理，用于代码生成模型的安全风险检测与防护，显著提升了风险识别性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在代码生成领域的应用增加，相关安全风险也日益突出，但针对防御（蓝队）的研究相对不足，因其需具备有效的语义理解以区分安全与不安全代码。

Method: 设计了BlueCodeAgent框架，集成自动红队生成多样化风险样本，通过法典规约和代码分析实现多层级风险检测与防御，特别在漏洞代码检测中加入动态分析减少误报。

Result: 在偏见指令检测、恶意指令检测和漏洞代码检测三项任务及四个数据集上，BlueCodeAgent平均F1提升12.7%，相较基础模型和安全提示防御效果显著。

Conclusion: 红队自动发现新漏洞持续强化蓝队防御能力，BlueCodeAgent有效实现了对安全风险的上下文感知识别，推动代码生成模型在安全方面的防护进展。

Abstract: As large language models (LLMs) are increasingly used for code generation,
concerns over the security risks have grown substantially. Early research has
primarily focused on red teaming, which aims to uncover and evaluate
vulnerabilities and risks of CodeGen models. However, progress on the blue
teaming side remains limited, as developing defense requires effective semantic
understanding to differentiate the unsafe from the safe. To fill in this gap,
we propose BlueCodeAgent, an end-to-end blue teaming agent enabled by automated
red teaming. Our framework integrates both sides: red teaming generates diverse
risky instances, while the blue teaming agent leverages these to detect
previously seen and unseen risk scenarios through constitution and code
analysis with agentic integration for multi-level defense. Our evaluation
across three representative code-related tasks--bias instruction detection,
malicious instruction detection, and vulnerable code detection--shows that
BlueCodeAgent achieves significant gains over the base models and safety
prompt-based defenses. In particular, for vulnerable code detection tasks,
BlueCodeAgent integrates dynamic analysis to effectively reduce false
positives, a challenging problem as base models tend to be over-conservative,
misclassifying safe code as unsafe. Overall, BlueCodeAgent achieves an average
12.7\% F1 score improvement across four datasets in three tasks, attributed to
its ability to summarize actionable constitutions that enhance context-aware
risk detection. We demonstrate that the red teaming benefits the blue teaming
by continuously identifying new vulnerabilities to enhance defense performance.

</details>


### [88] [When Old Meets New: Evaluating the Impact of Regression Tests on SWE Issue Resolution](https://arxiv.org/abs/2510.18270)
*Yang Chen,Toufique Ahmed,Reyhaneh Jabbarvand,Martin Hirzel*

Main category: cs.SE

TL;DR: TestPrune通过自动缩减回归测试套件，提升了新问题的再现率和补丁的验证效率，成本低，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现实项目中的测试套件虽大且覆盖率高，但仍难以检测所有缺陷，且开源项目中存在大量未解决问题，亟需提升测试效率和缺陷复现能力。

Method: 提出TestPrune技术，自动利用问题跟踪报告和回归测试，智能缩减测试套件至高相关子集，适用于各种自动化缺陷修复流程中。

Result: TestPrune在多个基准测试中提高了缺陷再现率6.2%-9.0%和缺陷解决率9.4%-12.9%，且引入的计算开销极低。

Conclusion: TestPrune是一种有效的测试套件缩减和利用工具，可提升基于LLM的缺陷调试效率，且成本低廉，适合大规模软件开发环境。

Abstract: Test suites in real-world projects are often large and achieve high code
coverage, yet they remain insufficient for detecting all bugs. The abundance of
unresolved issues in open-source project trackers highlights this gap. While
regression tests are typically designed to ensure past functionality is
preserved in the new version, they can also serve a complementary purpose:
debugging the current version. Specifically, regression tests can (1) enhance
the generation of reproduction tests for newly reported issues, and (2)
validate that patches do not regress existing functionality. We present
TestPrune, a fully automated technique that leverages issue tracker reports and
strategically reuses regression tests for both bug reproduction and patch
validation.
  A key contribution of TestPrune is its ability to automatically minimize the
regression suite to a small, highly relevant subset of tests. Due to the
predominance of LLM-based debugging techniques, this minimization is essential
as large test suites exceed context limits, introduce noise, and inflate
inference costs. TestPrune can be plugged into any agentic bug repair pipeline
and orthogonally improve overall performance. As a proof of concept, we show
that TestPrune leads to a 6.2%-9.0% relative increase in issue reproduction
rate within the Otter framework and a 9.4% - 12.9% relative increase in issue
resolution rate within the Agentless framework on SWE-Bench Lite and SWE-Bench
Verified benchmarks, capturing fixes that were correctly produced by agents but
not submitted as final patches. Compared to the benefits, the cost overhead of
using TestPrune is minimal, i.e., \$0.02 and \$0.05 per SWE-Bench instance,
using GPT-4o and Claude-3.7-Sonnet models, respectively.

</details>


### [89] [Ensuring Robustness in ML-enabled Software Systems: A User Survey](https://arxiv.org/abs/2510.18292)
*Hala Abdelkader,Mohamed Abdelrazek,Priya Rani,Rajesh Vasa,Jean-Guy Schneider*

Main category: cs.SE

TL;DR: 提出了ML-On-Rails协议，旨在通过集成OOD检测、对抗攻击检测、输入验证和可解释性等保护措施，提高机器学习系统的鲁棒性和可信度。


<details>
  <summary>Details</summary>
Motivation: 传统的软件工程方法不足以解决机器学习组件中出现的无声失败、OOD数据和对抗攻击等鲁棒性挑战。

Method: 设计一个统一框架ML-On-Rails，包括OOD检测、对抗攻击检测、输入验证、可解释性，以及基于HTTP状态码的模型与软件通信机制，增强模型结果和错误的透明度。

Result: 通过从业者调查验证了系统存在的鲁棒性问题和现有解决方案的不足，表明标准化协议如ML-On-Rails能够提升系统鲁棒性。

Conclusion: 需要为处理机器学习系统的工程师提供更多支持和资源，未来将基于调查和实际应用持续完善该协议以提高其效果。

Abstract: Ensuring robustness in ML-enabled software systems requires addressing
critical challenges, such as silent failures, out-of-distribution (OOD) data,
and adversarial attacks. Traditional software engineering practices, which rely
on predefined logic, are insufficient for ML components that depend on data and
probabilistic decision-making. To address these challenges, we propose the
ML-On-Rails protocol, a unified framework designed to enhance the robustness
and trustworthiness of ML-enabled systems in production. This protocol
integrates key safeguards such as OOD detection, adversarial attack detection,
input validation, and explainability. It also includes a model-to-software
communication framework using HTTP status codes to enhance transparency in
reporting model outcomes and errors. To align our approach with real-world
challenges, we conducted a practitioner survey, which revealed major robustness
issues, gaps in current solutions, and highlighted how a standardised protocol
such as ML-On-Rails can improve system robustness. Our findings highlight the
need for more support and resources for engineers working with ML systems.
Finally, we outline future directions for refining the proposed protocol,
leveraging insights from the survey and real-world applications to continually
enhance its effectiveness.

</details>


### [90] [InspectCoder: Dynamic Analysis-Enabled Self Repair through interactive LLM-Debugger Collaboration](https://arxiv.org/abs/2510.18327)
*Yunkun Wang,Yue Zhang,Guochang Li,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng*

Main category: cs.SE

TL;DR: InspectCoder通过交互式调试器控制，赋能大语言模型(LLMs)进行动态分析，从而提升代码自动修复的准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自我修复方法缺乏深入的动态分析能力，无法有效诊断复杂的逻辑错误，导致修复效果有限。

Method: 提出InspectCoder双代理框架，使LLM能够在调试器中主动设置断点、检查状态及进行增量运行实验，实时利用调试反馈引导多步推理，提高根因定位能力。

Result: 在BigCodeBench-R和LiveCodeBench-R两个基准测试中，InspectCoder的修复准确率相比最强基线提升5.10%-60.37%，修复效率提升1.67倍至2.24倍。

Conclusion: InspectCoder展示了LLM驱动的动态分析在自动化软件工程中的巨大潜力，开创了智能调试交互系统的新范式。

Abstract: Large Language Models (LLMs) frequently generate buggy code with complex
logic errors that are challenging to diagnose. While existing LLM-based
self-repair approaches conduct intensive static semantic analysis or reply on
superficial execution logs, they miss the in-depth runtime behaviors that often
expose bug root causes-lacking the interactive dynamic analysis capabilities
that make human debugging effective. We present InspectCoder, the first agentic
program repair system that empowers LLMs to actively conduct dynamic analysis
via interactive debugger control. Our dual-agent framework enables strategic
breakpoint placement, targeted state inspection, and incremental runtime
experimentation within stateful debugger sessions. Unlike existing methods that
follow fixed log collection procedures, InspectCoder adaptively inspects and
perturbs relevant intermediate states at runtime, and leverages immediate
process rewards from debugger feedback to guide multi-step reasoning,
transforming LLM debugging paradigm from blind trial-and-error into systematic
root cause diagnosis. We conduct comprehensive experiments on two challenging
self-repair benchmarks: BigCodeBench-R and LiveCodeBench-R. InspectCoder
achieves 5.10%-60.37% relative improvements in repair accuracy over the
strongest baseline, while delivering 1.67x-2.24x superior bug-fix efficiency
respectively. We also contribute InspectWare, an open-source middleware that
abstracts debugger complexities and maintains stateful debugging sessions
across mainstream Python testing frameworks. Our work provides actionable
insight into the interactive LLM-debugger systems, demonstrating the
significant potential of LLM-driven dynamic analysis for automated software
engineering.

</details>


### [91] [Human to Document, AI to Code: Three Case Studies of Comparing GenAI for Notebook Competitions](https://arxiv.org/abs/2510.18430)
*Tasha Settewong,Youmei Fan,Raula Gaikovina Kula,Kenichi Matsumoto*

Main category: cs.SE

TL;DR: 本文通过分析Kaggle中的获奖笔记本，比较了人类与生成式AI（GenAI）在代码和文档编写上的特点，揭示两者的优势与差异。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的兴起，理解人类与AI生成内容的不同特征，有助于提升数据科学笔记本的质量和合作效能。

Method: 通过三个案例分析，考察了25个代码和文档特征，在人类编写的获奖笔记本和GenAI生成的笔记本中进行了对比研究。

Result: 发现金牌获奖笔记的文档更长更详细；GenAI笔记本代码质量更高，但人类笔记本结构多样性、复杂度和创新性更强。

Conclusion: 提出四个未来研究方向，以促进人类与GenAI在笔记本中的协同工作，最大化双方优势。

Abstract: Computational notebooks have become the preferred tool of choice for data
scientists and practitioners to perform analyses and share results. Notebooks
uniquely combine scripts with documentation. With the emergence of generative
AI (GenAI) technologies, it is increasingly important, especially in
competitive settings, to distinguish the characteristics of human-written
versus GenAI.
  In this study, we present three case studies to explore potential strengths
of both humans and GenAI through the coding and documenting activities in
notebooks. We first characterize differences between 25 code and documentation
features in human-written, medal-winning Kaggle notebooks. We find that gold
medalists are primarily distinguished by longer and more detailed
documentation. Second, we analyze the distinctions between human-written and
GenAI notebooks. Our results show that while GenAI notebooks tend to achieve
higher code quality (as measured by metrics like code smells and technical
debt), human-written notebooks display greater structural diversity,
complexity, and innovative approaches to problem-solving. Based on these
results, we envision the work as groundwork that highlight four agendas to
further investigate how GenAI could be utilized in notebooks that maximizes the
potential collaboration between human and AI.

</details>


### [92] [Real-World Usability of Vulnerability Proof-of-Concepts: A Comprehensive Study](https://arxiv.org/abs/2510.18448)
*Wenjing Dang,Kaixuan Li,Sen Chen,Zhenwei Zhuo,Lyuye Zhang,Zheli Liu*

Main category: cs.SE

TL;DR: 本研究是首次对漏洞PoC进行大规模调研，收集了47万余条PoC报告，评估其可用性、完整性和可复现性。结果显示近79%的CVEs缺少PoC，报告平均缺失30%的关键信息，且复现存在多种难点。针对发现的问题，提出了改进策略以提升PoC的实用价值。


<details>
  <summary>Details</summary>
Motivation: PoC对验证漏洞存在、减少误报及展示安全威胁至关重要，但研究较少，且现实PoC分散、写作多样、难以复现，造成实务使用障碍。

Method: 构建47万条PoC报告数据集，设计基于模式匹配和BERT-NER的九组件抽取方法，并通过人工复现150个代表性漏洞，分析PoC的可用性、完整性和复现性。

Result: 发现78.9%的CVE缺少可用PoC，现有PoC平均缺失三成关键信息，复现失败原因多样。

Conclusion: 提出促进PoC使用的实用策略，帮助相关人员提升PoC报告质量和漏洞安全性。

Abstract: The Proof-of-Concept (PoC) for a vulnerability is crucial in validating its
existence, mitigating false positives, and illustrating the severity of the
security threat it poses. However, research on PoCs significantly lags behind
studies focusing on vulnerability data. This discrepancy can be directly
attributed to several challenges, including the dispersion of real-world PoCs
across multiple platforms, the diversity in writing styles, and the difficulty
associated with PoC reproduction. To fill this gap, we conduct the first
large-scale study on PoCs in the wild, assessing their report availability,
completeness, reproducibility. Specifically, 1) to investigate PoC reports
availability for CVE vulnerability, we collected an extensive dataset of
470,921 PoCs and their reports from 13 platforms, representing the broadest
collection of publicly available PoCs to date. 2) To assess the completeness of
PoC report at a fine-grained level, we proposed a component extraction method,
which combines pattern-matching techniques with a fine-tuned BERT-NER model to
extract 9 key components from PoC reports. 3) To evaluate the effectiveness of
PoCs, we recruited 8 participants to manually reproduce 150 sampled
vulnerabilities with 32 vulnerability types based on PoC reports, enabling an
in-depth analysis of PoC reproducibility and the factors influencing it. Our
findings reveal that 78.9% of CVE vulnerabilities lack available PoCs, and
existing PoC reports typically miss about 30% of the essential components
required for effective vulnerability understanding and reproduction, with
various reasons identified for the failure to reproduce vulnerabilities using
available PoC reports. Finally, we proposed actionable strategies for
stakeholders to enhance the overall usability of vulnerability PoCs in
strengthening software security.

</details>


### [93] [Large Language Models in Thematic Analysis: Prompt Engineering, Evaluation, and Guidelines for Qualitative Software Engineering Research](https://arxiv.org/abs/2510.18456)
*Cristina Martinez Montes,Robert Feldt,Cristina Miguel Martos,Sofia Ouhbi,Shweta Premanandan,Daniel Graziotin*

Main category: cs.SE

TL;DR: 本文探索了大型语言模型(LLMs)在软件工程领域主题分析(TA)中的应用，设计了可复现的集成方法，并通过专家评估对比了LLM与人工生成的质性分析结果。


<details>
  <summary>Details</summary>
Motivation: 当前没有可复现的方法将LLM集成到传统质性研究方法如Braun和Clarke的主题分析中，且现有研究缺乏系统的质量评估。

Method: 设计并迭代优化符合Braun和Clarke反思性主题分析2-5阶段的提示词，利用15份软件工程师访谈的数据，进行盲评，由四位专家基于质量标准评价LLM生成的编码与主题。

Result: LLM生成的编码在61%的情况下被专家偏好，具有分析价值，但存在数据碎片化过度、忽略潜在解释及主题边界模糊等局限。

Conclusion: 提出了可复现的整合LLM和反思性主题分析的方法与评估框架，比较了LLM与人工编码及主题的质量，给出了在保持方法严谨前提下有效使用LLM的指导原则。

Abstract: As artificial intelligence advances, large language models (LLMs) are
entering qualitative research workflows, yet no reproducible methods exist for
integrating them into established approaches like thematic analysis (TA), one
of the most common qualitative methods in software engineering research.
Moreover, existing studies lack systematic evaluation of LLM-generated
qualitative outputs against established quality criteria. We designed and
iteratively refined prompts for Phases 2-5 of Braun and Clarke's reflexive TA,
then tested outputs from multiple LLMs against codes and themes produced by
experienced researchers. Using 15 interviews on software engineers' well-being,
we conducted blind evaluations with four expert evaluators who applied rubrics
derived directly from Braun and Clarke's quality criteria. Evaluators preferred
LLM-generated codes 61% of the time, finding them analytically useful for
answering the research question. However, evaluators also identified
limitations: LLMs fragmented data unnecessarily, missed latent interpretations,
and sometimes produced themes with unclear boundaries. Our contributions are
threefold. First, a reproducible approach integrating refined, documented
prompts with an evaluation framework to operationalize Braun and Clarke's
reflexive TA. Second, an empirical comparison of LLM- and human-generated codes
and themes in software engineering data. Third, guidelines for integrating LLMs
into qualitative analysis while preserving methodological rigour, clarifying
when and how LLMs can assist effectively and when human interpretation remains
essential.

</details>


### [94] [CodeRL+: Improving Code Generation via Reinforcement with Execution Semantics Alignment](https://arxiv.org/abs/2510.18471)
*Xue Jiang,Yihong Dong,Mengyang Liu,Hongyi Deng,Tian Wang,Yongding Tao,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.SE

TL;DR: 该论文提出了CodeRL+方法，通过在强化学习训练中引入执行语义对齐，提升了大语言模型生成代码的性能。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型在代码生成中存在文本模式训练与功能正确性（执行语义）之间的语义鸿沟，基于测试结果的强化学习回报信号过于二元而难以捕捉细微的逻辑错误。

Method: 提出CodeRL+，该方法引入变量级执行轨迹推断，将执行语义直接作为学习信号，利用已有的策略滚动执行结果构建语义对齐，并能无缝整合多种强化学习算法。

Result: CodeRL+在代码生成准确率上比包括RLVR和蒸馏技术的基线平均提升了4.6%，在代码推理和测试输出生成任务上分别提升了15.5%和4.4%。此外，方法具备较强的泛化能力和适应性。

Conclusion: CodeRL+有效缩小了代码文本表示与执行语义之间的差距，通过执行轨迹对齐增强了模型的功能正确性，显著提升了代码生成的表现和泛化能力。

Abstract: While Large Language Models (LLMs) excel at code generation by learning from
vast code corpora, a fundamental semantic gap remains between their training on
textual patterns and the goal of functional correctness, which is governed by
formal execution semantics. Reinforcement Learning with Verifiable Rewards
(RLVR) approaches attempt to bridge this gap using outcome rewards from
executing test cases. However, solely relying on binary pass/fail signals is
inefficient for establishing a well-aligned connection between the textual
representation of code and its execution semantics, especially for subtle
logical errors within the code. In this paper, we propose CodeRL+, a novel
approach that integrates execution semantics alignment into the RLVR training
pipeline for code generation. CodeRL+ enables the model to infer variable-level
execution trajectory, providing a direct learning signal of execution
semantics. CodeRL+ can construct execution semantics alignment directly using
existing on-policy rollouts and integrates seamlessly with various RL
algorithms. Extensive experiments demonstrate that CodeRL+ outperforms
post-training baselines (including RLVR and Distillation), achieving a 4.6%
average relative improvement in pass@1. CodeRL+ generalizes effectively to
other coding tasks, yielding 15.5% and 4.4% higher accuracy on code-reasoning
and test-output-generation benchmarks, respectively. CodeRL+ shows strong
applicability across diverse RL algorithms and LLMs. Furthermore, probe
analyses provide compelling evidence that CodeRL+ strengthens the alignment
between code's textual representations and its underlying execution semantics.

</details>


### [95] [VAPU: System for Autonomous Legacy Code Modernization](https://arxiv.org/abs/2510.18509)
*Valtteri Ala-Salmi,Zeeshan Rasheed,Abdul Malik Sami,Muhammad Waseem,Kai-Kristian Kemell,Jussi Rasku,Mika Saari,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 该论文提出了一种基于大语言模型(LLM)的多智能体系统VAPU，用于自动更新遗留应用程序代码，提升了更新效率和需求满足率。


<details>
  <summary>Details</summary>
Motivation: 遗留应用包含过时组件，带来兼容性、安全性和可靠性风险，但高资源成本使得企业不愿更新。研究旨在提供一种低成本的自动化更新方案。

Method: 设计了多智能体系统VAPU，模拟软件开发团队多角色分阶段更新代码。扩展评估使用五个LLM和不同温度参数，测试20个开源Python项目，并与零次和一次学习提示进行对比。

Result: VAPU在低温度设定下，与零次/一次学习提示比较，错误率相当但需求完成率更高，Python文件更新成功需求提升最多达22.5%。

Conclusion: 基于LLM的多智能体系统是自动更新遗留应用组件的有效方案，可降低成本并提升更新质量。

Abstract: In this study, we present a solution for the modernization of legacy
applications, an area of code generation where LLM-based multi-agent systems
are proving essential for complex multi-phased tasks. Legacy applications often
contain deprecated components that create compatibility, security, and
reliability risks, but high resource costs make companies hesitate to update.
We take a step forward to integrate an LLM-based multi-agent system as part of
a legacy web application update to provide a cost-effective solution to update
legacy applications autonomously. We propose a multi-agent system named a
Verifying Agent Pipeline Updater (VAPU), which is designed to update code files
in phases while simulating different roles in a software development team. In
our previous study, we evaluated the system for legacy version updates by using
six legacy web application view files by resulting errors and accomplished
requirements. This study extends the previous evaluation of a multi-agent
pipeline system by extending the evaluation of VAPU from a single LLM to five
LLMs and using the temperature parameter in both 0 to 1 settings. Additionally,
we tested the system with 20 open-source Python GitHub projects. The results of
the evaluation were compared to Zero-Shot Learning (ZSL) and One-Shot Learning
(OSL) prompts. The extended evaluation of VAPU showed that particularly in a
low-temperature VAPU can get similar level of error count compared to the
ZSL/OSL prompts but with a higher level of fulfilled requirements, depending on
the LLM. VAPU showed up to 22.5% increase in the succeeding Python file update
requirements compared to ZSL/OSL prompts. The study indicates that an LLM-based
multi-agent system is a capable solution to update components of a legacy
application autonomously.

</details>


### [96] [Mining Service Behavior for Stateful Service Emulation](https://arxiv.org/abs/2510.18519)
*Md Arafat Hossain,Jun Han,Muhammad Ashad Kabir,Steve Versteeg,Jean-Guy Schneider,Jiaojiao Jiang*

Main category: cs.SE

TL;DR: 针对企业软件系统测试中服务虚拟化技术的局限，提出考虑服务状态的服务模型推导方法，提高了服务响应生成的准确性和测试环境的真实性。


<details>
  <summary>Details</summary>
Motivation: 传统的服务虚拟化方法大多忽略服务状态，导致对状态服务的模拟不准确，影响测试环境的真实性。

Method: 通过挖掘交互消息之间的上下文依赖和分析消息数据值的关系，导出包含服务状态的服务模型，从而提升响应生成的准确性。

Result: 在状态和无状态服务的交互跟踪数据上进行评估，结果显示该方法在准确性和效率上显著优于现有方法。

Conclusion: 引入服务状态的建模方法显著提升了服务虚拟化的效果，为企业软件系统测试提供了更真实和高效的环境。

Abstract: Enterprise software systems are increasingly integrating with diverse
services to meet expanding business demands. Testing these highly
interconnected systems presents a challenge due to the need for access to the
connected services. Service virtualization has emerged as a widely used
technique to derive service models from recorded interactions, for service
response generation during system testing. Various methods have been proposed
to emulate actual service behavior based on these interactions, but most fail
to account for the service's state, which reduces the accuracy of service
emulation and the realism of the testing environment, especially when dealing
with stateful services. This paper proposes an approach to deriving service
models from service interactions, which enhance the accuracy of response
generation by considering service state. This is achieved by uncovering
contextual dependencies among interaction messages and analyzing the
relationships between message data values. The approach is evaluated using
interaction traces collected from both stateful and stateless services, and the
results reveal notable enhancements in accuracy and efficiency over existing
approaches in service response generation.

</details>


### [97] [Demonstrators for Industrial Cyber-Physical System Research: A Requirements Hierarchy Driven by Software-Intensive Design](https://arxiv.org/abs/2510.18534)
*Uraz Odyurt,Richard Loendersloot,Tiedo Tinga*

Main category: cs.SE

TL;DR: 本文提出了一个针对演示项目需求的分层框架，以解决研究项目中演示内容不明确的问题，提升项目目标与实际演示的匹配度。


<details>
  <summary>Details</summary>
Motivation: 研究项目中往往缺乏对演示内容的详细规划，导致项目目标与实际演示成果不符，给项目进展带来阻碍。

Method: 提出了一个演示需求阐述框架，定义了五个层级的演示标准，结合工作包互动和工业应用场景，帮助评估演示的可行性并调整目标。

Result: 在两个不同阶段的研究项目中应用该框架，显示出能够有效提高演示目标的合理性和实现可能性。

Conclusion: 该框架有助于项目早期明确演示需求，促进演示目标的现实调整，尽管完整验证需较长周期但初步应用效果良好。

Abstract: One of the challenges apparent in the organisation of research projects is
the uncertainties around the subject of demonstrators. A precise and detailed
elicitation of the coverage for project demonstrators is often an afterthought
and not sufficiently detailed during proposal writing. This practice leads to
continuous confusion and a mismatch between targeted and achievable
demonstration of results, hindering progress. The reliance on the TRL scale as
a loose descriptor does not help either. We propose a demonstrator requirements
elaboration framework aiming to evaluate the feasibility of targeted
demonstrations, making realistic adjustments, and assist in describing
requirements. In doing so, we define 5 hierarchical levels of demonstration,
clearly connected to expectations, e.g., work package interaction, and also
connected to the project's industrial use-cases. The considered application
scope in this paper is the domain of software-intensive systems and industrial
cyber-physical systems. A complete validation is not accessible, as it would
require application of our framework at the start of a project and observing
the results at the end, taking 4-5 years. Nonetheless, we have applied it to
two research projects from our portfolio, one at the early and another at the
final stages, revealing its effectiveness.

</details>


### [98] [When Abstraction Breaks Physics: Rethinking Modular Design in Quantum Software](https://arxiv.org/abs/2510.18557)
*Jianjun Zhao*

Main category: cs.SE

TL;DR: 本文指出了量子软件工程中抽象存在与物理约束冲突的问题，提出了失败案例和设计原则，并建议探索量子特定的类型系统等研究方向。


<details>
  <summary>Details</summary>
Motivation: 经典软件工程中抽象机制难以安全地应用于量子编程，因量子语义与物理约束如叠加态、不可克隆性等存在根本差异。

Method: 通过分析量子程序抽象失败的三个典型案例，提出符合物理约束的抽象设计原则，并探讨量子类型系统、效应注释及契约模块设计等方法。

Result: 揭示了传统抽象机制在量子软件中的限制，提出了物理合理的抽象设计路径，为量子软件的模块化和扩展性奠定基础。

Conclusion: 本文呼吁从量子语义角度重新思考软件抽象，促进量子软件工程的系统化发展，提高其工程可扩展性与安全性。

Abstract: Abstraction is a fundamental principle in classical software engineering,
which enables modularity, reusability, and scalability. However, quantum
programs adhere to fundamentally different semantics, such as unitarity,
entanglement, the no-cloning theorem, and the destructive nature of
measurement, which introduce challenges to the safe use of classical
abstraction mechanisms. This paper identifies a fundamental conflict in quantum
software engineering: abstraction practices that are syntactically valid may
violate the physical constraints of quantum computation. We present three
classes of failure cases where naive abstraction breaks quantum semantics and
propose a set of design principles for physically sound abstraction mechanisms.
We further propose research directions, including quantum-specific type
systems, effect annotations, and contract-based module design. Our goal is to
initiate a systematic rethinking of abstraction in quantum software
engineering, based on quantum semantics and considering engineering
scalability.

</details>


### [99] [WebDevJudge: Evaluating (M)LLMs as Critiques for Web Development Quality](https://arxiv.org/abs/2510.18560)
*Chunyang Li,Yilun Zheng,Xinting Huang,Tianqing Fang,Jiahao Xu,Yangqiu Song,Lihui Chen,Han Hu*

Main category: cs.SE

TL;DR: 本文提出WebDevJudge基准，系统评估大型语言模型（LLM）作为评判者在网页开发任务中的表现，揭示其与人类专家之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 目前LLM作为评判者表现良好于确定性任务，但在开放式、动态环境和复杂交互任务中的可靠性未被充分验证。

Method: 构建WebDevJudge基准，包含静态和动态网页开发任务，配备人类偏好标签和结构化评分标准，并系统评估多种评判者，包括LLM、多模态模型及智能工作流。

Result: 实验发现LLM评判者在识别功能等价性、任务可行性验证及减轻偏见方面存在不足，表现显著落后于人类专家。

Conclusion: WebDevJudge揭示了LLM作为评判者在复杂开放环境中的局限，促进未来研究开发更可靠和强大的自动评估工具。

Abstract: The paradigm of LLM-as-a-judge is emerging as a scalable and efficient
alternative to human evaluation, demonstrating strong performance on
well-defined tasks. However, its reliability in open-ended tasks with dynamic
environments and complex interactions remains unexplored. To bridge the gap, we
introduce WebDevJudge, a systematic benchmark for assessing LLM-as-a-judge
performance in web development, with support for both non-interactive
evaluation based on static observations and continuous interactive evaluation
with a dynamic web environment. WebDevJudge comprises human preference labels
over paired web implementations, annotated with structured and query-grounded
rubrics to ensure high-quality ground truth. Using this benchmark, we
comprehensively evaluate various evaluators, including LLMs, MLLMs, and agentic
workflows. We systematically investigate the impact of different paradigms and
guidance mechanisms. Our experiments reveal a significant gap between LLM
judges and human experts. In-depth analysis indicates this gap stems from
fundamental model limitations, including failures in recognizing functional
equivalence, verifying task feasibility, and mitigating bias. Overall,
WebDevJudge presents a significant challenge to LLM-as-a-judge, offering
insights to guide future research toward developing more reliable and capable
automated evaluators for complicated scenarios. Code and data are available at
https://github.com/lcy2723/WebDevJudge.

</details>


### [100] [A Structured Evaluation Framework for Low-Code Platform Selection: A Multi-Criteria Decision Model for Enterprise Digital Transformation](https://arxiv.org/abs/2510.18590)
*Antonio Lamanna*

Main category: cs.SE

TL;DR: 本文提出了一个基于五大关键指标的低代码开发平台系统评价框架，通过加权评分模型帮助企业定量比较不同平台，提升决策质量。


<details>
  <summary>Details</summary>
Motivation: 低代码开发平台快速普及，企业亟需系统评价方法以支持科学选择，避免盲目跟风和错误决策。

Method: 构建基于业务流程编排、UI/UX自定义、集成互操作性、治理安全和AI增强自动化五个维度的评价指标体系，设计加权评分模型，结合企业具体需求进行定量评估。

Result: 通过企业环境中的实证验证，证明该框架能显著改善决策效果，降低平台锁定风险和方案选择不当的概率。

Conclusion: 该评价框架弥补了市场驱动对比与严谨背景相关评估方法之间的空白，为企业选择低代码开发平台提供科学工具和指导。

Abstract: The rapid adoption of Low-Code Development Platforms (LCDPs) has created a
critical need for systematic evaluation methodologies that enable organizations
to make informed platform selection decisions. This paper presents a
comprehensive evaluation framework based on five key criteria: Business Process
Orchestration, UI/UX Customization, Integration and Interoperability,
Governance and Security, and AI-Enhanced Automation. We propose a weighted
scoring model that allows organizations to quantitatively assess and compare
different low-code platforms based on their specific requirements and strategic
priorities. The framework addresses the gap between marketing-driven platform
comparisons and rigorous, context-specific evaluation methodologies. Through
empirical validation in enterprise environments, we demonstrate how this
structured approach can significantly improve decision-making outcomes and
reduce the risk of platform lock-in or inadequate solution selection.

</details>


### [101] [CUARewardBench: A Benchmark for Evaluating Reward Models on Computer-using Agent](https://arxiv.org/abs/2510.18596)
*Haojia Lin,Xiaoyu Tan,Yulei Qin,Zihan Xu,Yuchen Shi,Zongyi Li,Gang Li,Shaofei Cai,Siqi Cai,Chaoyou Fu,Ke Li,Xing Sun*

Main category: cs.SE

TL;DR: 提出了CUARewardBench基准，用于评估计算机使用代理的奖励模型，涵盖多软件类别和代理架构，进行轨迹级和步骤级评估。


<details>
  <summary>Details</summary>
Motivation: 现有脚本验证方法难以扩展且无法逐步评估，奖励模型在计算机使用代理评估中的效果尚不明确。

Method: 建立包含多软件类别与代理架构的数据集，设计专家注释协议，评估多种视觉语言模型和提示模板，提出统一提示集成（UPE）方法增强评估可靠性。

Result: 发现现有奖励模型在视觉推理和知识方面的局限，通用视觉语言模型优于专用模型；UPE方法显著提升奖励模型的精准度和负预测值。

Conclusion: CUARewardBench提供了一个全面可靠的奖励模型评价框架，UPE方法有效提升了奖励模型的评估性能，为计算机使用代理任务的研究提供了重要工具。

Abstract: Computer-using agents (CUAs) enable task completion through natural
interaction with operating systems and software interfaces. While script-based
verifiers are widely adopted for evaluation, they suffer from limited
scalability and inability to provide step-wise assessment. Reward models offer
promising alternatives, but their effectiveness on CUA evaluation remains
largely underexplored. To address this gap, we present CUARewardBench,
comprising four key contributions: (1) First-ever Comprehensive CUA Reward
Benchmark: We introduce the first benchmark for evaluating both outcome reward
models (ORM) and process reward models (PRM) on CUA tasks, enabling systematic
assessment across trajectory-level and step-level evaluation. (2) Diverse,
Practical and Reliable Dataset: CUARewardBench encompasses trajectories from 10
software categories and 7 agent architectures with varying performance levels
(25.9%-50.8% success rates). All trajectories are expertly annotated through
carefully designed protocols, with rigorous quality control to ensure
reliability and practical applicability. (3) Comprehensive Analysis and
Insights: Through extensive experiments across 7 vision-language models and 3
prompt templates, we reveal critical limitations of current CUA RMs, including
insufficient visual reasoning capabilities, knowledge deficiencies, and the
superiority of general VLMs over specialized CUA models for reward evaluation.
(4) Unanimous Prompt Ensemble (UPE): Based on the insights from our
comprehensive analysis, we propose UPE, a novel ensemble method that
significantly enhances reward model reliability through strict unanimous voting
and strategic prompt-template configurations. UPE achieves 89.8% precision and
93.3% NPV for ORM, and 81.7% precision and 85.1% NPV for PRM, substantially
outperforming single VLMs and traditional ensemble approaches.

</details>


### [102] [An overview of the use of alternative funding and contracting approaches relevant for agile software development: A systematic review of real-life experiences](https://arxiv.org/abs/2510.18711)
*Bertha Ngereja,Magne Jørgensen*

Main category: cs.SE

TL;DR: 本文综述了非传统资金和合同方法在敏捷软件开发中的应用，强调它们比传统方法更灵活且更符合敏捷原则。


<details>
  <summary>Details</summary>
Motivation: 传统资金和合同方法过于僵化，阻碍了敏捷开发中的灵活性和客户-承包商合作。

Method: 通过系统文献综述，筛选出38篇相关实证研究，分析非传统资金和合同方法的动机、优点及挑战。

Result: 发现四种非传统资金和合同方法，带来更高客户满意度、降低承包商风险和优化资源利用，但也带来文化和结构挑战。

Conclusion: 建议根据组织情况，逐步采用混合方案，平衡灵活性与控制，最终实现适合自身的灵活方法。

Abstract: Agile software development emphasizes flexibility and iterative processes,
which may conflict with the more linear, rigid, and time-consuming traditional
funding and contracting approaches. This review synthesizes real-life
experiences of using alternative (non-traditional) contracting and funding
approaches. The focus is on identifying approaches that align better with agile
principles and understanding the motivations, benefits, and challenges these
alternatives present. A systematic literature review was conducted in SCOPUS,
Web of Science, and Google Scholar, where we identified 38 relevant
peer-reviewed empirical studies from private and public sector contexts. Four
alternative funding and four alternative contracting approaches were
identified. Organizations were motivated to adopt these alternative approaches
because traditional approaches often proved too rigid, conflicted with agile
principles, hindered effective client-contractor collaboration, and limited
profitability. The benefits of these alternatives included higher client
satisfaction, reduced contractor risk, and more efficient resource utilization.
Adopting alternative funding and contracting approaches may promote flexibility
and efficiency in agile projects but also presents cultural and structural
challenges, increases the risk of scope creep and analysis paralysis, and
requires additional effort in terms of time and resources. The context of the
organization matters highly in selecting a suitable approach, such as the
organizational readiness in terms of its leaders, people, and systems. Thus,
instead of wholly adopting alternative approaches and introducing changes
abruptly, organizations may benefit from starting with hybrid approaches that
balance flexibility and control and progressively transition to fully flexible
approaches tailored to their needs

</details>


### [103] [Causally Perturbed Fairness Testing](https://arxiv.org/abs/2510.18719)
*Chengwen Du,Tao Chen*

Main category: cs.SE

TL;DR: 本文提出了一个基于因果推断的公平性测试框架CausalFT，通过提取因果相关的非敏感特征指导样本扰动，提高了公平缺陷的发现效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现有公平性测试多关注样本生成器设计，缺乏对数据特征因果关系的利用，导致扰动指导效果有限。

Method: 利用因果推断识别非敏感特征与敏感特征之间的因果关系，将其注入扰动过程，形成通用的公平性测试框架CausalFT，可结合多种生成器。

Result: 在1296个测试案例中，CausalFT提高了超过93%的生成器发现公平缺陷的能力，效率优于基于相关性的方法，且在提升偏差鲁棒性方面表现更佳。

Conclusion: CausalFT作为一个高层次框架，有效整合因果信息指导扰动，显著提升公平性测试的检测能力和效率，具备广泛应用潜力。

Abstract: To mitigate unfair and unethical discrimination over sensitive features
(e.g., gender, age, or race), fairness testing plays an integral role in
engineering systems that leverage AI models to handle tabular data. A key
challenge therein is how to effectively reveal fairness bugs under an
intractable sample size using perturbation. Much current work has been focusing
on designing the test sample generators, ignoring the valuable knowledge about
data characteristics that can help guide the perturbation and hence limiting
their full potential. In this paper, we seek to bridge such a gap by proposing
a generic framework of causally perturbed fairness testing, dubbed CausalFT.
Through causal inference, the key idea of CausalFT is to extract the most
directly and causally relevant non-sensitive feature to its sensitive
counterpart, which can jointly influence the prediction of the label. Such a
causal relationship is then seamlessly injected into the perturbation to guide
a test sample generator. Unlike existing generator-level work, CausalFT serves
as a higher-level framework that can be paired with diverse base generators.
Extensive experiments on 1296 cases confirm that CausalFT can considerably
improve arbitrary base generators in revealing fairness bugs over 93% of the
cases with acceptable extra runtime overhead. Compared with a state-of-the-art
approach that ranks the non-sensitive features solely based on correlation,
CausalFT performs significantly better on 64% cases while being much more
efficient. Further, CausalFT can better improve bias resilience in nearly all
cases.

</details>


### [104] [ShaRE your Data! Characterizing Datasets for LLM-based Requirements Engineering](https://arxiv.org/abs/2510.18787)
*Quim Motger,Carlota Catot,Xavier Franch*

Main category: cs.SE

TL;DR: 本文系统性梳理了支持大型语言模型在需求工程中的数据集现状，指出数据集零散且描述不足，限制了复用和比较。


<details>
  <summary>Details</summary>
Motivation: 需求工程领域数据匮乏限制了大型语言模型的应用，而现有数据集分散且缺乏系统化表征，导致利用困难。

Method: 通过系统映射研究，收集分析了43篇研究中引用的62个公开数据集，依据多维度特征对数据集进行了结构化表征。

Result: 发现数据集对需求获取任务覆盖不足，管理类任务数据稀缺，且多语种支持有限，揭示了多个研究空白。

Conclusion: 本文提供了数据集目录及表征方案，为需求工程领域大型语言模型相关数据集的选择、比较和复用提供支持，并计划扩展至灰色文献和数据集基准库整合。

Abstract: [Context] Large Language Models (LLMs) rely on domain-specific datasets to
achieve robust performance across training and inference stages. However, in
Requirements Engineering (RE), data scarcity remains a persistent limitation
reported in surveys and mapping studies. [Question/Problem] Although there are
multiple datasets supporting LLM-based RE tasks (LLM4RE), they are fragmented
and poorly characterized, limiting reuse and comparability. This research
addresses the limited visibility and characterization of datasets used in
LLM4RE. We investigate which public datasets are employed, how they can be
systematically characterized, and which RE tasks and dataset descriptors remain
under-represented. [Ideas/Results] To address this, we conduct a systematic
mapping study to identify and analyse datasets used in LLM4RE research. A total
of 62 publicly available datasets are referenced across 43 primary studies.
Each dataset is characterized along descriptors such as artifact type,
granularity, RE stage, task, domain, and language. Preliminary findings show
multiple research gaps, including limited coverage for elicitation tasks,
scarce datasets for management activities beyond traceability, and limited
multilingual availability. [Contribution] This research preview offers a public
catalogue and structured characterization scheme to support dataset selection,
comparison, and reuse in LLM4RE research. Future work will extend the scope to
grey literature, as well as integration with open dataset and benchmark
repositories.

</details>


### [105] [FeClustRE: Hierarchical Clustering and Semantic Tagging of App Features from User Reviews](https://arxiv.org/abs/2510.18799)
*Max Tiessler,Quim Motger*

Main category: cs.SE

TL;DR: 本文提出了FeClustRE框架，结合混合特征提取、层次聚类和大语言模型语义标注，改善移动应用评论特征的结构化表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从嘈杂且模糊的移动应用评论中提取有意义、结构化的特征，阻碍了需求分析和应用对比。

Method: FeClustRE集成句法解析与大语言模型丰富特征，采用自动调优的层次聚类组织特征，并自动生成有意义的分类标签。

Result: 通过公共基准测试验证了特征提取的准确性，且在生成式AI助手应用评论中展示了聚类质量、语义连贯性及可解释性的优势。

Conclusion: FeClustRE提供了一个混合特征提取与分类生成框架、自动调优机制及开源实现，促进用户反馈与需求理解之间的深度连接。

Abstract: [Context and motivation.] Extracting features from mobile app reviews is
increasingly important for multiple requirements engineering (RE) tasks.
However, existing methods struggle to turn noisy, ambiguous feedback into
interpretable insights. [Question/problem.] Syntactic approaches lack semantic
depth, while large language models (LLMs) often miss fine-grained features or
fail to structure them coherently. In addition, existing methods output flat
lists of features without semantic organization, limiting interpretation and
comparability. Consequently, current feature extraction approaches do not
provide structured, meaningful representations of app features. As a result,
practitioners face fragmented information that hinder requirement analysis,
prioritization, and cross-app comparison, among other use cases. [Principal
ideas/results.] In this context, we propose FeClustRE, a framework integrating
hybrid feature extraction, hierarchical clustering with auto-tuning and
LLM-based semantic labelling. FeClustRE combines syntactic parsing with LLM
enrichment, organizes features into clusters, and automatically generates
meaningful taxonomy labels. We evaluate FeClustRE on public benchmarks for
extraction correctness and on a sample study of generative AI assistant app
reviews for clustering quality, semantic coherence, and interpretability.
[Contribution.] Overall, FeClustRE delivers (1) a hybrid framework for feature
extraction and taxonomy generation, (2) an auto-tuning mechanism with a
comprehensive evaluation methodology, and (3) open-source and replicable
implementation. These contributions bridge user feedback and feature
understanding, enabling deeper insights into current and emerging requirements.

</details>


### [106] [Streamlining Acceptance Test Generation for Mobile Applications Through Large Language Models: An Industrial Case Study](https://arxiv.org/abs/2510.18861)
*Pedro Luís Fonseca,Bruno Lima,João Pascoal Faria*

Main category: cs.SE

TL;DR: AToMIC通过使用专门的大型语言模型，自动从需求和代码变更生成移动应用接受测试脚本，实现快速高质量测试自动化，显著节省开发者时间。


<details>
  <summary>Details</summary>
Motivation: 移动端接受测试依然是现代软件开发的瓶颈，尤其是跨平台开发中，自动生成和维护测试文档耗费大量人力。

Method: 提出AToMIC框架，利用专门的大型语言模型自动生成Gherkin场景、页面对象和可执行UI测试脚本，输入为JIRA需求单和代码变更。

Result: 在宝马MyBMW应用的真实项目中，AToMIC在五分钟内完成测试脚本生成，93.3%场景语法正确，78.8%页面对象无需人工修改，UI测试100%成功执行。

Conclusion: AToMIC有效提升移动端接受测试自动化效率和质量，为工业项目提供了可扩展且实用的解决方案，获得开发者广泛认可。

Abstract: Mobile acceptance testing remains a bottleneck in modern software
development, particularly for cross-platform mobile development using
frameworks like Flutter. While developers increasingly rely on automated
testing tools, creating and maintaining acceptance test artifacts still demands
significant manual effort. To help tackle this issue, we introduce AToMIC, an
automated framework leveraging specialized Large Language Models to generate
Gherkin scenarios, Page Objects, and executable UI test scripts directly from
requirements (JIRA tickets) and recent code changes. Applied to BMW's MyBMW
app, covering 13 real-world issues in a 170+ screen codebase, AToMIC produced
executable test artifacts in under five minutes per feature on standard
hardware. The generated artifacts were of high quality: 93.3% of Gherkin
scenarios were syntactically correct upon generation, 78.8% of PageObjects ran
without manual edits, and 100% of generated UI tests executed successfully. In
a survey, all practitioners reported time savings (often a full developer-day
per feature) and strong confidence in adopting the approach. These results
confirm AToMIC as a scalable, practical solution for streamlining acceptance
test creation and maintenance in industrial mobile projects.

</details>


### [107] [EffiReasonTrans: RL-Optimized Reasoning for Code Translation](https://arxiv.org/abs/2510.18863)
*Yanlin Wang,Rongyi Ou,Yanli Wang,Mingwei Liu,Jiachi Chen,Ensheng Shi,Xilin Liu,Yuchi Ma,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文提出EffiReasonTrans框架，兼顾代码翻译的准确率和推理延迟，提高代码翻译性能。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型虽提升代码翻译准确率，但推理延迟增高，不利于实际开发中的人机协作。

Method: 构建推理增强数据集，利用DeepSeek-R1生成中间推理与目标翻译，进行语法及功能验证；采用两阶段训练：监督微调和强化学习，以提升准确率和推理效率。

Result: 在六组代码翻译任务中，EffiReasonTrans最高提升准确率49.2%（CA指标）和27.8%（CodeBLEU），减少生成token数19.3%，推理延迟降低29.0%。消融实验验证了两阶段训练的互补效果。

Conclusion: EffiReasonTrans有效平衡代码翻译准确率与推理延迟，适合实际开发场景，且集成到智能体框架中同样表现优异。代码和数据已开源。

Abstract: Code translation is a crucial task in software development and maintenance.
While recent advancements in large language models (LLMs) have improved
automated code translation accuracy, these gains often come at the cost of
increased inference latency, hindering real-world development workflows that
involve human-in-the-loop inspection. To address this trade-off, we propose
EffiReasonTrans, a training framework designed to improve translation accuracy
while balancing inference latency. We first construct a high-quality
reasoning-augmented dataset by prompting a stronger language model,
DeepSeek-R1, to generate intermediate reasoning and target translations. Each
(source code, reasoning, target code) triplet undergoes automated syntax and
functionality checks to ensure reliability. Based on this dataset, we employ a
two-stage training strategy: supervised fine-tuning on reasoning-augmented
samples, followed by reinforcement learning to further enhance accuracy and
balance inference latency. We evaluate EffiReasonTrans on six translation
pairs. Experimental results show that it consistently improves translation
accuracy (up to +49.2% CA and +27.8% CodeBLEU compared to the base model) while
reducing the number of generated tokens (up to -19.3%) and lowering inference
latency in most cases (up to -29.0%). Ablation studies further confirm the
complementary benefits of the two-stage training framework. Additionally,
EffiReasonTrans demonstrates improved translation accuracy when integrated into
agent-based frameworks. Our code and data are available at
https://github.com/DeepSoftwareAnalytics/EffiReasonTrans.

</details>
