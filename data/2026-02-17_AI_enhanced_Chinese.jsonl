{"id": "2602.13377", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13377", "abs": "https://arxiv.org/abs/2602.13377", "authors": ["Taufiqul Islam Khan", "Shaowei Wang", "Haoxiang Zhang", "Tse-Hsun Chen"], "title": "A Survey of Code Review Benchmarks and Evaluation Practices in Pre-LLM and LLM Era", "comment": null, "summary": "Code review is a critical practice in modern software engineering, helping developers detect defects early, improve code quality, and facilitate knowledge sharing. With the rapid advancement of large language models (LLMs), a growing body of work has explored automated support for code review. However, progress in this area is hindered by the lack of a systematic understanding of existing benchmarks and evaluation practices. Current code review datasets are scattered, vary widely in design, and provide limited insight into what review capabilities are actually being assessed. In this paper, we present a comprehensive survey of code review benchmarks spanning both the Pre-LLM and LLM eras (2015--2025). We analyze 99 research papers (58 Pre-LLM era and 41 LLM era) and extract key metadata, including datasets, evaluation metrics, data sources, and target tasks. Based on this analysis, we propose a multi-level taxonomy that organizes code review research into five domains and 18 fine-grained tasks. Our study reveals a clear shift toward end-to-end generative peer review, increasing multilingual coverage, and a decline in standalone change understanding tasks. We further identify limitations of current benchmarks and outline future directions, including broader task coverage, dynamic runtime evaluation, and taxonomy-guided fine-grained assessment. This survey provides a structured foundation for developing more realistic and comprehensive benchmarks for LLM-based code review.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u4ee3\u7801\u5ba1\u67e5\u9886\u57df\u7684\u57fa\u51c6\u6570\u636e\u548c\u8bc4\u4f30\u65b9\u6cd5\uff0c\u63d0\u51fa\u65b0\u7684\u5206\u7c7b\u4f53\u7cfb\uff0c\u5e76\u5206\u6790\u4e86\u53d1\u5c55\u8d8b\u52bf\u4e0e\u5b58\u5728\u7684\u4e0d\u8db3\uff0c\u63a8\u52a8\u66f4\u5b8c\u5584\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u57fa\u51c6\u7684\u6784\u5efa\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u5ba1\u67e5\u57fa\u51c6\u5206\u6563\u4e14\u8bbe\u8ba1\u5dee\u5f02\u5927\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7406\u89e3\uff0c\u9650\u5236\u4e86\u81ea\u52a8\u4ee3\u7801\u5ba1\u67e5\u7814\u7a76\u7684\u53d1\u5c55\uff0c\u56e0\u800c\u9700\u8981\u5bf9\u73b0\u6709\u57fa\u51c6\u8fdb\u884c\u5168\u9762\u8c03\u67e5\u548c\u7ed3\u6784\u5316\u603b\u7ed3\u3002", "method": "\u91c7\u7528\u6587\u732e\u7cfb\u7edf\u8c03\u7814\u7684\u65b9\u6cd5\uff0c\u5206\u679099\u7bc7\u6709\u5173\u4ee3\u7801\u5ba1\u67e5\u7684\u8bba\u6587\uff0c\u63d0\u53d6\u6570\u636e\u96c6\u3001\u8bc4\u4ef7\u6307\u6807\u3001\u6570\u636e\u6e90\u548c\u4efb\u52a1\u7b49\u5173\u952e\u4fe1\u606f\uff0c\u57fa\u4e8e\u6b64\u6784\u5efa\u5206\u7c7b\u4f53\u7cfb\u5e76\u8fdb\u884c\u8d8b\u52bf\u5206\u6790\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u56de\u987e\u4e862015\u81f32025\u5e74\u95f4\u4ee3\u7801\u5ba1\u67e5\u9886\u57df\u7684\u57fa\u51c6\u548c\u8bc4\u4f30\u5b9e\u8df5\uff0c\u5206\u6790\u4e8699\u7bc7\u76f8\u5173\u8bba\u6587\uff0c\u6784\u5efa\u4e86\u6db5\u76d65\u5927\u9886\u57df\u548c18\u4e2a\u7ec6\u5206\u4efb\u52a1\u7684\u591a\u5c42\u6b21\u5206\u7c7b\u4f53\u7cfb\u3002\u7814\u7a76\u53d1\u73b0\u4ee3\u7801\u5ba1\u67e5\u7814\u7a76\u6b63\u5411\u7aef\u5230\u7aef\u751f\u6210\u5f0f\u540c\u884c\u8bc4\u5ba1\u8f6c\u53d8\uff0c\u591a\u8bed\u8a00\u652f\u6301\u589e\u5f3a\uff0c\u5355\u72ec\u53d8\u66f4\u7406\u89e3\u4efb\u52a1\u51cf\u5c11\u3002\u4f5c\u8005\u6307\u51fa\u5f53\u524d\u57fa\u51c6\u5b58\u5728\u5c40\u9650\uff0c\u63d0\u51fa\u672a\u6765\u5e94\u6269\u5c55\u4efb\u52a1\u8986\u76d6\u3001\u5f15\u5165\u52a8\u6001\u8fd0\u884c\u65f6\u8bc4\u6d4b\u4ee5\u53ca\u5229\u7528\u5206\u7c7b\u4f53\u7cfb\u8fdb\u884c\u7ec6\u7c92\u5ea6\u8bc4\u4ef7\u3002", "conclusion": "\u672c\u6587\u603b\u7ed3\u4e86\u4ee3\u7801\u5ba1\u67e5\u57fa\u51c6\u7814\u7a76\u7684\u73b0\u72b6\u548c\u8d8b\u52bf\uff0c\u5f3a\u8c03\u4e86\u591a\u8bed\u8a00\u3001\u591a\u4efb\u52a1\u548c\u52a8\u6001\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u672a\u6765\u57fa\u51c6\u8bbe\u8ba1\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2602.13400", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13400", "abs": "https://arxiv.org/abs/2602.13400", "authors": ["Tanner Wright", "Adams Chen", "Gema Rodr\u00edguez-P\u00e9rez"], "title": "InEx-Bug: A Human Annotated Dataset of Intrinsic and Extrinsic Bugs in the NPM Ecosystem", "comment": null, "summary": "Understanding the causes of software defects is essential for reliable software maintenance and ecosystem stability. However, existing bug datasets do not distinguish between issues originating within a project from those caused by external dependencies or environmental factors. In this paper we present InEx-Bug, a manually annotated dataset of 377 GitHub issues from 103 NPM repositories, categorizing issues as Intrinsic (internal defect), Extrinsic (dependency/environment issue), Not-a-Bug, or Unknown. Beyond labels, the dataset includes rich temporal and behavioral metadata such as maintainer participation, code changes, and reopening patterns. Analyses show Intrinsic bugs resolve faster (median 8.9 vs 10.2 days), are close more often (92% vs 78%), and require code changes more frequently (57% vs 28%) compared to Extrinsic bugs. While Extrinsic bugs exhibit higher reopen rates (12% vs 4%) and delayed recurrence (median 157 vs 87 days). The dataset provides a foundation for further studying Intrinsic and Extrinsic defects in the NPM ecosystem.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86InEx-Bug\u6570\u636e\u96c6\uff0c\u533a\u5206\u5185\u90e8\u7f3a\u9677\u4e0e\u4f9d\u8d56\u73af\u5883\u95ee\u9898\uff0c\u5206\u6790\u4e86\u4e24\u8005\u7684\u5dee\u5f02\u6027\u3002", "motivation": "\u73b0\u6709\u7f3a\u9677\u6570\u636e\u96c6\u672a\u533a\u5206\u7f3a\u9677\u6765\u6e90\uff0c\u5f71\u54cd\u7f3a\u9677\u6210\u56e0\u5206\u6790\u548c\u8f6f\u4ef6\u7ef4\u62a4\u7b56\u7565\u7684\u5236\u5b9a\u3002", "method": "\u624b\u52a8\u6807\u6ce8377\u4e2aGitHub\u95ee\u9898\uff0c\u5206\u7c7b\u4e3a\u5185\u90e8\u7f3a\u9677\u3001\u5916\u90e8\u7f3a\u9677\u3001\u975e\u7f3a\u9677\u548c\u672a\u77e5\uff0c\u5e76\u6536\u96c6\u4e86\u4e30\u5bcc\u7684\u65f6\u95f4\u548c\u884c\u4e3a\u5143\u6570\u636e\u3002", "result": "\u5185\u90e8\u7f3a\u9677\u4fee\u590d\u66f4\u5feb\uff0c\u5173\u95ed\u7387\u66f4\u9ad8\uff0c\u4ee3\u7801\u6539\u52a8\u9891\u7e41\uff1b\u5916\u90e8\u7f3a\u9677\u91cd\u5f00\u7387\u9ad8\uff0c\u590d\u53d1\u65f6\u95f4\u957f\uff0c\u4e3a\u751f\u6001\u7cfb\u7edf\u7f3a\u9677\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u6570\u636e\u3002", "conclusion": "InEx-Bug\u6570\u636e\u96c6\u6709\u6548\u533a\u5206\u4e86\u5185\u90e8\u7f3a\u9677\u548c\u5916\u90e8\u4f9d\u8d56\u95ee\u9898\uff0c\u63ed\u793a\u4e86\u4e24\u7c7b\u7f3a\u9677\u5728\u4fee\u590d\u65f6\u95f4\u3001\u91cd\u5f00\u7387\u548c\u4ee3\u7801\u4fee\u6539\u9891\u7387\u7b49\u65b9\u9762\u7684\u663e\u8457\u5dee\u5f02\u3002"}}
{"id": "2602.13574", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.13574", "abs": "https://arxiv.org/abs/2602.13574", "authors": ["Haoyu Li", "Xijia Che", "Yanhao Wang", "Xiaojing Liao", "Luyi Xing"], "title": "Execution-State-Aware LLM Reasoning for Automated Proof-of-Vulnerability Generation", "comment": "Version 1.0 (13 pages, 7 figures)", "summary": "Proof-of-Vulnerability (PoV) generation is a critical task in software security, serving as a cornerstone for vulnerability validation, false positive reduction, and patch verification. While directed fuzzing effectively drives path exploration, satisfying complex semantic constraints remains a persistent bottleneck in automated exploit generation. Large Language Models (LLMs) offer a promising alternative with their semantic reasoning capabilities; however, existing LLM-based approaches lack sufficient grounding in concrete execution behavior, limiting their ability to generate precise PoVs.\n  In this paper, we present DrillAgent, an agentic framework that reformulates PoV generation as an iterative hypothesis-verification-refinement process. To bridge the gap between static reasoning and dynamic execution, DrillAgent synergizes LLM-based semantic inference with feedback from concrete program states. The agent analyzes the target code to hypothesize inputs, observes execution behavior, and employs a novel mechanism to translate low-level execution traces into source-level constraints. This closed-loop design enables the agent to incrementally align its input generation with the precise requirements of the vulnerability. We evaluate DrillAgent on SEC-bench, a large-scale benchmark of real-world C/C++ vulnerabilities. Experimental results show that DrillAgent substantially outperforms state-of-the-art LLM agent baselines under fixed budget constraints, solving up to 52.8% more CVE tasks than the best-performing baseline. These results highlight the necessity of execution-state-aware reasoning for reliable PoV generation in complex software systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDrillAgent\uff0c\u901a\u8fc7\u7ed3\u5408LLM\u8bed\u4e49\u63a8\u7406\u548c\u7a0b\u5e8f\u6267\u884c\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5316PoV\u751f\u6210\u7684\u6027\u80fd\uff0c\u5728\u771f\u5b9e\u6f0f\u6d1e\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u8f6f\u4ef6\u6f0f\u6d1e\u9a8c\u8bc1\u3001\u51cf\u5c11\u8bef\u62a5\u548c\u8865\u4e01\u9a8c\u8bc1\u4e2d\uff0c\u751f\u6210\u6f0f\u6d1e\u5229\u7528\u8bc1\u636e\uff08PoV\uff09\u662f\u5173\u952e\u4efb\u52a1\uff0c\u73b0\u6709\u81ea\u52a8\u5316\u65b9\u6cd5\u96be\u4ee5\u6ee1\u8db3\u590d\u6742\u7684\u8bed\u4e49\u7ea6\u675f\u3002", "method": "\u63d0\u51faDrillAgent\u6846\u67b6\uff0c\u5c06PoV\u751f\u6210\u89c6\u4e3a\u5047\u8bbe-\u9a8c\u8bc1-\u4f18\u5316\u7684\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u7ed3\u5408\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bed\u4e49\u63a8\u7406\u4e0e\u771f\u5b9e\u7a0b\u5e8f\u72b6\u6001\u53cd\u9988\uff0c\u901a\u8fc7\u5c06\u4f4e\u5c42\u6267\u884c\u8f68\u8ff9\u8f6c\u6362\u4e3a\u6e90\u4ee3\u7801\u7ea7\u7ea6\u675f\uff0c\u5b9e\u73b0\u95ed\u73af\u8f93\u5165\u4f18\u5316\u3002", "result": "\u5728SEC-bench\u771f\u5b9eC/C++\u6f0f\u6d1e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cDrillAgent\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8eLLM\u7684\u4ee3\u7406\u65b9\u6cd5\u63d0\u5347\u4e8652.8%\u7684CVE\u4efb\u52a1\u89e3\u51b3\u7387\u3002", "conclusion": "\u7ed3\u5408\u6267\u884c\u72b6\u6001\u53cd\u9988\u7684\u8bed\u4e49\u63a8\u7406\u663e\u8457\u63d0\u9ad8\u4e86\u590d\u6742\u8f6f\u4ef6\u7cfb\u7edf\u4e2dPoV\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\uff0c\u662f\u5b9e\u73b0\u53ef\u9760\u6f0f\u6d1e\u9a8c\u8bc1\u7684\u91cd\u8981\u65b9\u5411\u3002"}}
{"id": "2602.13611", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13611", "abs": "https://arxiv.org/abs/2602.13611", "authors": ["Xiao He", "Ru Chen", "Jialun Cao"], "title": "From What to How: Bridging User Requirements with Software Development Using Large Language Models", "comment": null, "summary": "Recently, large language models (LLMs) are extensively utilized to enhance development efficiency, leading to numerous benchmarks for evaluating their performance. However, these benchmarks predominantly focus on implementation, overlooking the equally critical aspect of software design. This gap raises two pivotal questions: (1) Can LLMs handle software design? (2) Can LLMs write code following the specific designs? To investigate these questions, this paper proposes DesBench, a design-aware benchmark for evaluating LLMs on three software design-related tasks: design-aware code generation, object-oriented modeling, and the design of acceptance test cases. DesBench comprises 30 manually crafted Java projects that include requirement documents, design models, implementations, and acceptance tests, amounting to a total of 30 design models, 194 Java classes, and 737 test cases. We evaluated seven state-of-the-art LLMs, including three DeepSeek R1, two Qwen2.5, and two GPT models, using DesBench. The results reveal that LLMs remain significantly challenged by the intricacies of software design: (1) For code generation, LLMs struggle to produce correct implementations when provided with only high-level or no designs. (2) In object-oriented modeling, while LLMs can accurately identify objects and classes, they face challenges in defining operations and inter-class relationships. (3) Acceptance test cases generated by LLMs from functional requirements achieve code coverage quality comparable to those written by humans. Our research highlights the current limitations of LLMs in managing software design and calls for further investigation into new design methodologies and languages suitable for LLM-based development.", "AI": {"tldr": "DesBench\u57fa\u51c6\u63ed\u793a\u4e86LLMs\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u4efb\u52a1\u4e2d\u7684\u5c40\u9650\uff0c\u5c24\u5176\u662f\u4ee3\u7801\u5b9e\u73b0\u548c\u8bbe\u8ba1\u7ec6\u8282\u5904\u7406\u65b9\u9762\uff0c\u63d0\u793a\u9700\u53d1\u5c55\u9762\u5411LLM\u7684\u65b0\u8bbe\u8ba1\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u6d4b\u591a\u805a\u7126\u5b9e\u73b0\uff0c\u5ffd\u7565\u8f6f\u4ef6\u8bbe\u8ba1\u8fd9\u4e00\u5173\u952e\u5c42\u9762\u3002\u672c\u6587\u6b32\u63a2\u7a76LLMs\u662f\u5426\u80fd\u5904\u7406\u8f6f\u4ef6\u8bbe\u8ba1\u53ca\u4f9d\u636e\u8bbe\u8ba1\u7f16\u5199\u4ee3\u7801\u7684\u80fd\u529b\uff0c\u586b\u8865\u8be5\u9886\u57df\u8bc4\u6d4b\u7a7a\u767d\u3002", "method": "\u6784\u5efa\u5305\u542b30\u4e2aJava\u9879\u76ee\u7684DesBench\u57fa\u51c6\uff0c\u5305\u62ec\u9700\u6c42\u6587\u6863\u3001\u8bbe\u8ba1\u6a21\u578b\u3001\u4ee3\u7801\u5b9e\u73b0\u53ca\u9a8c\u6536\u6d4b\u8bd5\u3002\u8bc4\u4ef7\u4e867\u4e2a\u9876\u5c16LLMs\u5728\u8bbe\u8ba1\u611f\u77e5\u4ee3\u7801\u751f\u6210\u3001\u9762\u5411\u5bf9\u8c61\u5efa\u6a21\u53ca\u9a8c\u6536\u6d4b\u8bd5\u8bbe\u8ba1\u4e09\u9879\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86DesBench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8bbe\u8ba1\u611f\u77e5\u57fa\u51c6\uff0c\u6db5\u76d6\u4ee3\u7801\u751f\u6210\u3001\u9762\u5411\u5bf9\u8c61\u5efa\u6a21\u548c\u9a8c\u6536\u6d4b\u8bd5\u8bbe\u8ba1\u3002\u901a\u8fc7\u5bf97\u4e2a\u5148\u8fdbLLMs\u7684\u8bc4\u6d4b\uff0c\u53d1\u73b0\u5176\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u65b9\u9762\u4ecd\u5b58\u663e\u8457\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u4ec5\u6709\u9ad8\u5c42\u8bbe\u8ba1\u65f6\u4ee3\u7801\u751f\u6210\u56f0\u96be\uff0c\u9762\u5411\u5bf9\u8c61\u64cd\u4f5c\u548c\u5173\u7cfb\u5b9a\u4e49\u80fd\u529b\u4e0d\u8db3\uff0c\u4f46\u751f\u6210\u7684\u9a8c\u6536\u6d4b\u8bd5\u4ee3\u7801\u8986\u76d6\u7387\u53ef\u4e0e\u4eba\u7c7b\u76f8\u5f53\u3002", "conclusion": "LLMs\u5728\u8f6f\u4ef6\u8bbe\u8ba1\u5904\u7406\u4e0a\u4ecd\u5b58\u5728\u660e\u663e\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u5b9e\u73b0\u9ad8\u5c42\u8bbe\u8ba1\u548c\u9762\u5411\u5bf9\u8c61\u64cd\u4f5c\u5173\u7cfb\u5b9a\u4e49\u4e2d\uff0c\u4f46\u5bf9\u9a8c\u6536\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u8868\u73b0\u8f83\u597d\uff0c\u672a\u6765\u9700\u63a2\u7d22\u9002\u5408LLM\u7684\u65b0\u8bbe\u8ba1\u8bed\u8a00\u548c\u65b9\u6cd5\u3002"}}
{"id": "2602.13263", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.13263", "abs": "https://arxiv.org/abs/2602.13263", "authors": ["Ligong Lei", "Wenwen Lu", "Xudong Pang", "Zaokere Kadeer", "Aishan Wumaier"], "title": "Multimodal Consistency-Guided Reference-Free Data Selection for ASR Accent Adaptation", "comment": null, "summary": "Automatic speech recognition (ASR) systems often degrade on accented speech because acoustic-phonetic and prosodic shifts induce a mismatch to training data, making labeled accent adaptation costly. However, common pseudo-label selection heuristics are largely text-centric (e.g., perplexity (PPL) filtering) and can prefer fluent yet acoustically mismatched hypotheses, leading to error amplification when fine-tuning. To address this, we introduce a multimodal consistency-guided, reference-free data selection pipeline for ASR accent adaptation under a transductive, label-free protocol. The pipeline starts with a target-aware preselection step based on submodular mutual information to improve query relevance and reduce downstream computation. It then generates multiple pseudo-transcriptions per utterance via perturbation-based decoding and scores each hypothesis using two reference-free signals: speech--text alignment in a shared embedding space and predicted word error rate (WER). A simple percentile-based selection rule retains reliable pseudo-labels for fine-tuning while discarding noisy utterances. In an in-domain setting, selecting ~1.5k utterances from a 30k pool achieves 10.91% WER, close to 10.45% obtained using 30k supervised labels. In a cross-domain setting with a mismatched candidate pool, consistency-filtered subsets avoid the degradation caused by unfiltered pseudo-labels under strong accent shift, and matched-hour experiments on a stronger ASR backbone further confirm gains over random sampling and recent selection baselines.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u6a21\u6001\u4e00\u81f4\u6027\u5f15\u5bfc\u7684\u65e0\u53c2\u8003\u6570\u636e\u9009\u62e9\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\uff08ASR\uff09\u4e2d\u7684\u53e3\u97f3\u9002\u5e94\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4f2a\u6807\u7b7e\u8d28\u91cf\uff0c\u51cf\u5c11\u4e86\u624b\u5de5\u6807\u6ce8\u6210\u672c\u3002", "motivation": "\u53e3\u97f3\u53d8\u5316\u5bfc\u81f4ASR\u6027\u80fd\u4e0b\u964d\uff0c\u8bad\u7ec3\u6570\u636e\u4e0e\u53e3\u97f3\u5b58\u5728\u5339\u914d\u504f\u5dee\uff0c\u6807\u6ce8\u53e3\u97f3\u6570\u636e\u6210\u672c\u9ad8\u6602\uff0c\u4e14\u4f20\u7edf\u57fa\u4e8e\u6587\u672c\u7684\u4f2a\u6807\u7b7e\u9009\u62e9\u7b56\u7565\u65e0\u6cd5\u4fdd\u8bc1\u58f0\u5b66\u4e00\u81f4\u6027\uff0c\u5bb9\u6613\u653e\u5927\u9519\u8bef\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u5b50\u6a21\u4e92\u4fe1\u606f\u7684\u76ee\u6807\u611f\u77e5\u9884\u9009\u6b65\u9aa4\uff0c\u4e4b\u540e\u901a\u8fc7\u6270\u52a8\u89e3\u7801\u751f\u6210\u591a\u6761\u4f2a\u8f6c\u5f55\uff0c\u5e76\u5229\u7528\u8bed\u97f3-\u6587\u672c\u5bf9\u9f50\u7684\u5d4c\u5165\u7a7a\u95f4\u4e00\u81f4\u6027\u548c\u9884\u6d4b\u8bcd\u9519\u8bef\u7387\u4f5c\u4e3a\u65e0\u53c2\u8003\u8bc4\u5206\u4fe1\u53f7\uff0c\u7ed3\u5408\u5206\u4f4d\u70b9\u7b5b\u9009\u89c4\u5219\u4fdd\u7559\u53ef\u9760\u4f2a\u6807\u7b7e\u3002", "result": "\u5728\u5355\u9886\u57df\u4e0b\uff0c\u4ece3\u4e07\u6761\u6570\u636e\u4e2d\u9009\u53d6\u7ea61500\u6761\u8fbe\u523010.91%\u7684WER\uff0c\u63a5\u8fd1\u4f7f\u75283\u4e07\u6709\u76d1\u7763\u6807\u7b7e\u768410.45%\uff1b\u8de8\u9886\u57df\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u5f3a\u53e3\u97f3\u6761\u4ef6\u4e0b\u672a\u7ecf\u7b5b\u9009\u4f2a\u6807\u7b7e\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u4f18\u4e8e\u968f\u673a\u91c7\u6837\u548c\u73b0\u6709\u9009\u62e9\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u6a21\u6001\u4e00\u81f4\u6027\u8bc4\u5206\u548c\u7b80\u5355\u7684\u5206\u4f4d\u70b9\u9009\u62e9\u7b56\u7565\uff0c\u80fd\u591f\u5728\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\u7b5b\u9009\u51fa\u9ad8\u8d28\u91cf\u7684\u4f2a\u6807\u7b7e\uff0c\u663e\u8457\u63d0\u5347\u53e3\u97f3\u9002\u5e94\u4e0b\u7684ASR\u6027\u80fd\uff0c\u63a5\u8fd1\u6709\u76d1\u7763\u5b66\u4e60\u7684\u6548\u679c\uff1b\u540c\u65f6\u5728\u8de8\u9886\u57df\u548c\u5f3a\u53e3\u97f3\u8f6c\u79fb\u73af\u5883\u4e0b\u4e5f\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u3002"}}
{"id": "2602.13291", "categories": ["cs.MA", "astro-ph.IM", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13291", "abs": "https://arxiv.org/abs/2602.13291", "authors": ["Ziyang Wang"], "title": "Agent Mars: Multi-Agent Simulation for Multi-Planetary Life Exploration and Settlement", "comment": null, "summary": "Artificial Intelligence (AI) has transformed robotics, healthcare, industry, and scientific discovery, yet a major frontier may lie beyond Earth. Space exploration and settlement offer vast environments and resources, but impose constraints unmatched on Earth: delayed/intermittent communications, extreme resource scarcity, heterogeneous expertise, and strict safety, accountability, and command authority. The key challenge is auditable coordination among specialised humans, robots, and digital services in a safety-critical system-of-systems. We introduce Agent Mars, an open, end-to-end multi-agent simulation framework for Mars base operations. Agent Mars formalises a realistic organisation with a 93-agent roster across seven layers of command and execution (human roles and physical assets), enabling base-scale studies beyond toy settings. It implements hierarchical and cross-layer coordination that preserves chain-of-command while allowing vetted cross-layer exchanges with audit trails; supports dynamic role handover with automatic failover under outages; and enables phase-dependent leadership for routine operations, emergencies, and science campaigns. Agent Mars further models mission-critical mechanisms-scenario-aware short/long-horizon memory, configurable propose-vote consensus, and translator-mediated heterogeneous protocols-to capture how teams align under stress. To quantify behaviour, we propose the Agent Mars Performance Index (AMPI), an interpretable composite score with diagnostic sub-metrics. Across 13 reproducible Mars-relevant operational scripts, Agent Mars reveals coordination trade-offs and identifies regimes where curated cross-layer collaboration and functional leadership reduce overhead without sacrificing reliability. Agent Mars provides a benchmarkable, auditable foundation for Space AI.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u540d\u4e3aAgent Mars\u7684\u706b\u661f\u57fa\u5730\u591a\u667a\u80fd\u4f53\u6a21\u62df\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u592a\u7a7a\u63a2\u7d22\u4e2d\u591a\u5c42\u6b21\u56e2\u961f\u534f\u8c03\u7684\u6311\u6218\uff0c\u5c24\u5176\u662f\u5728\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u4e2d\u4fdd\u8bc1\u53ef\u5ba1\u8ba1\u7684\u6307\u6325\u94fe\u548c\u8de8\u5c42\u534f\u4f5c\u3002", "motivation": "\u73b0\u6709\u5730\u7403\u4e0a\u7684\u4eba\u5de5\u667a\u80fd\u548c\u673a\u5668\u4eba\u7cfb\u7edf\u96be\u4ee5\u5e94\u5bf9\u706b\u661f\u57fa\u5730\u64cd\u4f5c\u7684\u5ef6\u8fdf\u901a\u4fe1\u3001\u8d44\u6e90\u532e\u4e4f\u548c\u590d\u6742\u5b89\u5168\u8981\u6c42\uff0c\u4e9f\u9700\u4e00\u79cd\u80fd\u591f\u6a21\u62df\u548c\u4fdd\u969c\u591a\u4e13\u9886\u57df\u591a\u89d2\u8272\u4e4b\u95f4\u53ef\u5ba1\u8ba1\u534f\u8c03\u7684\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u5305\u542b93\u4e2a\u4ee3\u7406\u3001\u4e03\u5c42\u6307\u6325\u548c\u6267\u884c\u67b6\u6784\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0cAgent Mars\u5b9e\u73b0\u4e86\u5206\u5c42\u4e0e\u8de8\u5c42\u534f\u8c03\u673a\u5236\u3001\u4efb\u52a1\u76f8\u5173\u8bb0\u5fc6\u3001\u6295\u7968\u5171\u8bc6\u3001\u8de8\u534f\u8bae\u7ffb\u8bd1\u7b49\u529f\u80fd\uff0c\u5e76\u63d0\u51fa\u4e86Agent Mars Performance Index (AMPI)\u4f5c\u4e3a\u884c\u4e3a\u91cf\u5316\u5de5\u5177\u3002", "result": "\u5b9e\u9a8c\u4e2d\uff0cAgent Mars\u663e\u793a\u51fa\u572813\u4e2a\u706b\u661f\u4efb\u52a1\u811a\u672c\u4e2d\uff0c\u9002\u5f53\u7684\u8de8\u5c42\u534f\u4f5c\u548c\u529f\u80fd\u6027\u9886\u5bfc\u80fd\u591f\u51cf\u5c11\u64cd\u4f5c\u5f00\u9500\u4e14\u4e0d\u964d\u4f4e\u53ef\u9760\u6027\uff0c\u63ed\u793a\u4e86\u534f\u8c03\u673a\u5236\u7684\u6743\u8861\u548c\u6700\u4f73\u5b9e\u8df5\u3002", "conclusion": "Agent Mars\u6846\u67b6\u6709\u6548\u5b9e\u73b0\u4e86\u590d\u6742\u706b\u661f\u57fa\u5730\u64cd\u4f5c\u4e2d\u7684\u5206\u5c42\u6307\u6325\u4e0e\u8de8\u5c42\u534f\u4f5c\uff0c\u652f\u6301\u52a8\u6001\u89d2\u8272\u4ea4\u63a5\u548c\u5e94\u6025\u9886\u5bfc\uff0c\u63d0\u5347\u4e86\u56e2\u961f\u534f\u8c03\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u592a\u7a7a\u4eba\u5de5\u667a\u80fd\u63d0\u4f9b\u4e86\u53ef\u5ba1\u8ba1\u7684\u57fa\u51c6\u5e73\u53f0\u3002"}}
{"id": "2602.13682", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.13682", "abs": "https://arxiv.org/abs/2602.13682", "authors": ["Gianpietro Castiglione", "Shahriar Ebrahimi", "Narges Khakpour"], "title": "VeriSBOM: Secure and Verifiable SBOM Sharing Via Zero-Knowledge Proofs", "comment": null, "summary": "A Software Bill of Materials (SBOM) is a key component for the transparency of software supply chain; it is a structured inventory of the components, dependencies, and associated metadata of a software artifact. However, an SBOM often contain sensitive information that organizations are unwilling to disclose in full to anyone, for two main concerns: technological risks deriving from exposing proprietary dependencies or unpatched vulnerabilities, and business risks, deriving from exposing architectural strategies. Therefore, delivering a plaintext SBOM may result in the disruption of the intellectual property of a company. To address this, we present VeriSBOM, a trustless, selectively disclosed SBOM framework that provides cryptographic verifiability of SBOMs using zero-knowledge proofs. Within VeriSBOM, third parties can validate specific statements about a delivered software. Respectively, VeriSBOM allows independent third parties to verify if a software contains authentic dependencies distributed by official package managers and that the same dependencies satisfy rigorous policy constraints such as the absence of vulnerable dependencies or the adherence with specific licenses models. VeriSBOM leverages a scalable vector commitment scheme together with folding-based proof aggregation to produce succinct zero-knowledge proofs that attest to security and compliance properties while preserving confidentiality. Crucially, the verification process requires no trust in the SBOM publisher beyond the soundness of the underlying primitives, and third parties can independently check proofs against the public cryptographic commitments. We implement VeriSBOM, analyze its security, and evaluate its performance on real-world package registries. The results show that our method enables scalable, privacy-preserving, and verifiable SBOM sharing and validation.", "AI": {"tldr": "VeriSBOM\u901a\u8fc7\u96f6\u77e5\u8bc6\u8bc1\u660e\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5b89\u5168\u3001\u9690\u79c1\u4fdd\u62a4\u4e14\u53ef\u9a8c\u8bc1\u7684SBOM\u5171\u4eab\u4e0e\u9a8c\u8bc1\u3002", "motivation": "\u8f6f\u4ef6\u4f9b\u5e94\u94fe\u7684\u900f\u660e\u6027\u9700\u8981\u8f6f\u4ef6\u6750\u6599\u6e05\u5355\uff08SBOM\uff09\uff0c\u4f46SBOM\u4e2d\u5305\u542b\u7684\u654f\u611f\u4fe1\u606f\u53ef\u80fd\u66b4\u9732\u4e13\u6709\u4f9d\u8d56\u3001\u6f0f\u6d1e\u6216\u67b6\u6784\u7b56\u7565\uff0c\u5bfc\u81f4\u6280\u672f\u548c\u5546\u4e1a\u98ce\u9669\u3002", "method": "\u91c7\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u3001\u5411\u91cf\u627f\u8bfa\u65b9\u6848\u4e0e\u6298\u53e0\u8bc1\u660e\u805a\u5408\uff0c\u751f\u6210\u7b80\u6d01\u7684\u8bc1\u660e\uff0c\u9a8c\u8bc1\u8f6f\u4ef6\u4f9d\u8d56\u7684\u771f\u5b9e\u6027\u4e0e\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u3002", "result": "\u63d0\u51fa\u4e86VeriSBOM\u6846\u67b6\uff0c\u5229\u7528\u96f6\u77e5\u8bc6\u8bc1\u660e\u5b9e\u73b0SBOM\u7684\u52a0\u5bc6\u53ef\u9a8c\u8bc1\u6027\uff0c\u4f7f\u7b2c\u4e09\u65b9\u80fd\u591f\u9a8c\u8bc1\u8f6f\u4ef6\u7684\u4f9d\u8d56\u771f\u5b9e\u6027\u548c\u5408\u89c4\u6027\uff0c\u540c\u65f6\u4fdd\u62a4\u654f\u611f\u4fe1\u606f\u3002", "conclusion": "VeriSBOM\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u3001\u9690\u79c1\u4fdd\u62a4\u53ca\u9a8c\u8bc1\u6027\u7684SBOM\u5171\u4eab\uff0c\u9a8c\u8bc1\u8fc7\u7a0b\u4e0d\u4f9d\u8d56\u4e8e\u53d1\u5e03\u8005\u7684\u4fe1\u4efb\uff0c\u786e\u4fdd\u4e86\u5b89\u5168\u4e0e\u5408\u89c4\u6027\u3002"}}
{"id": "2602.13452", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13452", "abs": "https://arxiv.org/abs/2602.13452", "authors": ["Belu Ticona", "Antonis Anastasopoulos"], "title": "LLM-Powered Automatic Translation and Urgency in Crisis Scenarios", "comment": null, "summary": "Large language models (LLMs) are increasingly proposed for crisis preparedness and response, particularly for multilingual communication. However, their suitability for high-stakes crisis contexts remains insufficiently evaluated. This work examines the performance of state-of-the-art LLMs and machine translation systems in crisis-domain translation, with a focus on preserving urgency, which is a critical property for effective crisis communication and triaging. Using multilingual crisis data and a newly introduced urgency-annotated dataset covering over 32 languages, we show that both dedicated translation models and LLMs exhibit substantial performance degradation and instability. Crucially, even linguistically adequate translations can distort perceived urgency, and LLM-based urgency classifications vary widely depending on the language of the prompt and input. These findings highlight significant risks in deploying general-purpose language technologies for crisis communication and underscore the need for crisis-aware evaluation frameworks.", "AI": {"tldr": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u673a\u5668\u7ffb\u8bd1\u5728\u5371\u673a\u6c9f\u901a\u4e2d\u4f20\u9012\u7d27\u8feb\u6027\u4fe1\u606f\u7684\u4e0d\u8db3\uff0c\u5f3a\u8c03\u4e86\u5f00\u53d1\u5371\u673a\u611f\u77e5\u8bc4\u4f30\u6846\u67b6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u548c\u673a\u5668\u7ffb\u8bd1\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u5371\u673a\u6c9f\u901a\u4e2d\u7684\u9002\u7528\u6027\u5c1a\u672a\u5145\u5206\u8bc4\u4f30\uff0c\u7279\u522b\u662f\u5728\u4fdd\u6301\u4fe1\u606f\u7d27\u8feb\u6027\u65b9\u9762\u3002", "method": "\u4f7f\u7528\u591a\u8bed\u8a00\u5371\u673a\u6570\u636e\u53ca\u65b0\u5f15\u5165\u7684\u5305\u542b32\u79cd\u8bed\u8a00\u7684\u7d27\u8feb\u6027\u6ce8\u91ca\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u6700\u65b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u4e13\u7528\u7ffb\u8bd1\u6a21\u578b\u5728\u5371\u673a\u9886\u57df\u7684\u7ffb\u8bd1\u8868\u73b0\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5c3d\u7ba1\u4e00\u4e9b\u7ffb\u8bd1\u5728\u8bed\u8a00\u4e0a\u662f\u51c6\u786e\u7684\uff0c\u4f46LLMs\u548c\u7ffb\u8bd1\u6a21\u578b\u5728\u4f20\u9012\u4fe1\u606f\u7d27\u8feb\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u7a33\u5b9a\u4e14\u6709\u663e\u8457\u6027\u80fd\u4e0b\u964d\uff0c\u4e14LLM\u57fa\u4e8e\u8bed\u8a00\u4e0d\u540c\uff0c\u7d27\u8feb\u6027\u5206\u7c7b\u5dee\u5f02\u8f83\u5927\u3002", "conclusion": "\u901a\u7528\u8bed\u8a00\u6280\u672f\u5728\u5371\u673a\u6c9f\u901a\u4e2d\u7684\u90e8\u7f72\u5b58\u5728\u663e\u8457\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u4e13\u95e8\u5173\u6ce8\u5371\u673a\u60c5\u5883\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u63d0\u5347\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u9002\u7528\u6027\u3002"}}
{"id": "2602.13309", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13309", "abs": "https://arxiv.org/abs/2602.13309", "authors": ["Yexin Li", "Jinjin Guo", "Haoyu Zhang", "Yuhan Zhao", "Yiwen Sun", "Zihao Jiao"], "title": "Adaptive Value Decomposition: Coordinating a Varying Number of Agents in Urban Systems", "comment": null, "summary": "Multi-agent reinforcement learning (MARL) provides a promising paradigm for coordinating multi-agent systems (MAS). However, most existing methods rely on restrictive assumptions, such as a fixed number of agents and fully synchronous action execution. These assumptions are often violated in urban systems, where the number of active agents varies over time, and actions may have heterogeneous durations, resulting in a semi-MARL setting. Moreover, while sharing policy parameters among agents is commonly adopted to improve learning efficiency, it can lead to highly homogeneous actions when a subset of agents make decisions concurrently under similar observations, potentially degrading coordination quality. To address these challenges, we propose Adaptive Value Decomposition (AVD), a cooperative MARL framework that adapts to a dynamically changing agent population. AVD further incorporates a lightweight mechanism to mitigate action homogenization induced by shared policies, thereby encouraging behavioral diversity and maintaining effective cooperation among agents. In addition, we design a training-execution strategy tailored to the semi-MARL setting that accommodates asynchronous decision-making when some agents act at different times. Experiments on real-world bike-sharing redistribution tasks in two major cities, London and Washington, D.C., demonstrate that AVD outperforms state-of-the-art baselines, confirming its effectiveness and generalizability.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9002\u5e94\u667a\u80fd\u4f53\u52a8\u6001\u53d8\u5316\u5e76\u7f13\u89e3\u884c\u4e3a\u540c\u8d28\u5316\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6AVD\uff0c\u663e\u8457\u63d0\u5347\u57ce\u5e02\u5171\u4eab\u5355\u8f66\u8c03\u5ea6\u4efb\u52a1\u4e2d\u7684\u534f\u4f5c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u667a\u80fd\u4f53\u6570\u91cf\u56fa\u5b9a\u4e14\u52a8\u4f5c\u540c\u6b65\u6267\u884c\uff0c\u4f46\u8fd9\u5728\u57ce\u5e02\u7cfb\u7edf\u4e2d\u4e0d\u6210\u7acb\uff0c\u667a\u80fd\u4f53\u6570\u91cf\u52a8\u6001\u53d8\u5316\u4e14\u52a8\u4f5c\u6301\u7eed\u65f6\u95f4\u5f02\u8d28\uff0c\u5bfc\u81f4\u534a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u60c5\u5883\u3002\u5171\u4eab\u7b56\u7565\u53c2\u6570\u867d\u63d0\u5347\u5b66\u4e60\u6548\u7387\uff0c\u5374\u53ef\u80fd\u5bfc\u81f4\u884c\u4e3a\u8fc7\u4e8e\u540c\u8d28\uff0c\u5f71\u54cd\u534f\u4f5c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u4ef7\u503c\u5206\u89e3\uff08AVD\uff09\u6846\u67b6\uff0c\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u667a\u80fd\u4f53\u6570\u91cf\uff0c\u5e76\u5f15\u5165\u8f7b\u91cf\u673a\u5236\u51cf\u5c11\u5171\u4eab\u7b56\u7565\u5f15\u53d1\u7684\u884c\u4e3a\u540c\u8d28\u5316\uff0c\u4fc3\u8fdb\u884c\u4e3a\u591a\u6837\u6027\uff0c\u8bbe\u8ba1\u9002\u5408\u534a\u591a\u667a\u80fd\u4f53\u573a\u666f\u7684\u8bad\u7ec3-\u6267\u884c\u7b56\u7565\u4ee5\u652f\u6301\u5f02\u6b65\u51b3\u7b56\u3002", "result": "\u5728\u4f26\u6566\u548c\u534e\u76db\u987f\u7279\u533a\u7684\u771f\u5b9e\u5171\u4eab\u5355\u8f66\u518d\u5206\u914d\u4efb\u52a1\u4e2d\uff0cAVD\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "AVD\u6709\u6548\u89e3\u51b3\u4e86\u534a\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u667a\u80fd\u4f53\u52a8\u6001\u53d8\u5316\u4e0e\u884c\u4e3a\u540c\u8d28\u5316\u95ee\u9898\uff0c\u4fc3\u8fdb\u4e86\u667a\u80fd\u4f53\u95f4\u7684\u6709\u6548\u534f\u4f5c\uff0c\u63d0\u5347\u4e86\u590d\u6742\u57ce\u5e02\u7cfb\u7edf\u4e2d\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6027\u80fd\u3002"}}
{"id": "2602.13723", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13723", "abs": "https://arxiv.org/abs/2602.13723", "authors": ["Weiyu Kong", "Yun Lin", "Xiwen Teoh", "Duc-Minh Nguyen", "Ruofei Ren", "Jiaxin Chang", "Haoxu Hu", "Haoyu Chen"], "title": "ARC: Compiling Hundreds of Requirement Scenarios into A Runnable Web System", "comment": null, "summary": "Large Language Models (LLMs) have improved programming efficiency, but their performance degrades significantly as requirements scale; when faced with multi-modal documents containing hundreds of scenarios, LLMs often produce incorrect implementations or omit constraints. We propose Agentic Requirement Compilation (ARC), a technique that moves beyond simple code generation to requirement compilation, enabling the creation of runnable web systems directly from multi-modal DSL documents. ARC generates not only source code but also modular designs for UI, API, and database layers, enriched test suites (unit, modular, and integration), and detailed traceability for software maintenance. Our approach employs a bidirectional test-driven agentic loop: a top-down architecture phase decomposes requirements into verifiable interfaces, followed by a bottom-up implementation phase where agents generate code to satisfy those tests. ARC maintains strict traceability across requirements, design, and code to facilitate intelligent asset reuse. We evaluated ARC by generating six runnable web systems from documents spanning 50-200 multi-modal scenarios. Compared to state-of-the-art baselines, ARC-generated systems pass 50.6% more GUI tests on average. A user study with 21 participants showed that novice users can successfully write DSL documents for complex systems, such as a 10K-line ticket-booking system, in an average of 5.6 hours. These results demonstrate that ARC effectively transforms non-trivial requirement specifications into maintainable, runnable software.", "AI": {"tldr": "ARC\u901a\u8fc7\u9700\u6c42\u7f16\u8bd1\u6280\u672f\uff0c\u5c06\u590d\u6742\u591a\u6a21\u6001\u6587\u6863\u9ad8\u6548\u8f6c\u5316\u4e3a\u53ef\u7ef4\u62a4\u7684\u7f51\u9875\u8f6f\u4ef6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6d4b\u8bd5\u901a\u8fc7\u7387\u548c\u7528\u6237\u5f00\u53d1\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u590d\u6742\u3001\u591a\u573a\u666f\u591a\u6a21\u6001\u6587\u6863\u65f6\uff0c\u751f\u6210\u4ee3\u7801\u51c6\u786e\u6027\u548c\u7ea6\u675f\u5b8c\u6574\u6027\u663e\u8457\u4e0b\u964d\uff0c\u96be\u4ee5\u6ee1\u8db3\u5927\u89c4\u6a21\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgentic Requirement Compilation (ARC)\u7684\u6280\u672f\uff0c\u901a\u8fc7\u53cc\u5411\u6d4b\u8bd5\u9a71\u52a8\u7684\u667a\u80fd\u5faa\u73af\uff0c\u5c06\u591a\u6a21\u6001DSL\u6587\u6863\u4e2d\u7684\u9700\u6c42\u7f16\u8bd1\u6210\u53ef\u8fd0\u884c\u7684\u7f51\u9875\u7cfb\u7edf\uff0c\u751f\u6210\u6e90\u4ee3\u7801\u3001\u6a21\u5757\u5316\u8bbe\u8ba1\u3001\u5b8c\u5584\u7684\u6d4b\u8bd5\u5957\u4ef6\u53ca\u53ef\u8ffd\u6eaf\u6027\u8bbe\u8ba1\u3002", "result": "ARC\u751f\u6210\u7684\u7cfb\u7edf\u5728\u591a\u4e2a\u591a\u6a21\u6001\u573a\u666f\u4e0b\u5e73\u5747\u901a\u8fc7\u7684GUI\u6d4b\u8bd5\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u9ad8\u51fa50.6%\uff0c\u4e14\u7528\u6237\u7814\u7a76\u8868\u660e\u521d\u5b66\u8005\u80fd\u7528ARC DSL\u6587\u6863\u57285.6\u5c0f\u65f6\u5185\u5b8c\u6210\u590d\u6742\u7cfb\u7edf\u5f00\u53d1\u3002", "conclusion": "ARC\u6280\u672f\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u590d\u6742\u9700\u6c42\u4e0b\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u5b8c\u6574\u6027\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u7ef4\u62a4\u7684\u8fd0\u884c\u8f6f\u4ef6\u7cfb\u7edf\u3002"}}
{"id": "2602.13455", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.13455", "abs": "https://arxiv.org/abs/2602.13455", "authors": ["Phyllis Nabangi", "Abdul-Jalil Zakaria", "Jema David Ndibwile"], "title": "Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety", "comment": "Accepted at the Second IJCAI AI for Good Symposium in Africa, hosted by Deep Learning Indaba, 7 pages, 1 figure", "summary": "The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated language in Swahili, a low-resource language that poses unique challenges due to its limited linguistic resources and technological support. Swahili is chosen due to its popularity and being the most widely spoken language in Africa, with over 16 million native speakers and upwards of 100 million speakers in total, spanning regions in East Africa and some parts of the Middle East.\n  We employed machine learning models including Support Vector Machines (SVM), Logistic Regression, and Decision Trees, optimized through rigorous parameter tuning and techniques like Synthetic Minority Over-sampling Technique (SMOTE) to handle data imbalance. Our analysis revealed that, while these models perform well in high-dimensional textual data, our dataset's small size and imbalance limit our findings' generalizability. Precision, recall, and F1 scores were thoroughly analyzed, highlighting the nuanced performance of each model in detecting obfuscated language.\n  This research contributes to the broader discourse on ensuring safer online environments for children, advocating for expanded datasets and advanced machine-learning techniques to improve the effectiveness of cyberbullying detection systems. Future work will focus on enhancing data robustness, exploring transfer learning, and integrating multimodal data to create more comprehensive and culturally sensitive detection mechanisms.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u65af\u74e6\u5e0c\u91cc\u8bed\u4e2d\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u68c0\u6d4b\u7f51\u7edc\u6b3a\u51cc\u4e2d\u7684\u9690\u6666\u8fb1\u9a82\u8bed\u8a00\uff0c\u5c3d\u7ba1\u6a21\u578b\u5728\u9ad8\u7ef4\u6587\u672c\u6570\u636e\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u53d7\u9650\u4e8e\u6570\u636e\u96c6\u5c0f\u4e14\u4e0d\u5e73\u8861\u3002", "motivation": "\u6570\u5b57\u6280\u672f\u5174\u8d77\u589e\u52a0\u4e86\u7f51\u7edc\u6b3a\u51cc\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u65af\u74e6\u5e0c\u91cc\u8bed\u4e2d\uff0c\u4e9f\u9700\u6709\u6548\u68c0\u6d4b\u9690\u6666\u8fb1\u9a82\u8bed\u8a00\u4ee5\u4fdd\u62a4\u513f\u7ae5\u5728\u7ebf\u5b89\u5168\u3002", "method": "\u91c7\u7528\u652f\u6301\u5411\u91cf\u673a\u3001\u903b\u8f91\u56de\u5f52\u548c\u51b3\u7b56\u6811\u6a21\u578b\uff0c\u5e76\u7ed3\u5408\u53c2\u6570\u8c03\u4f18\u53caSMOTE\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\u3002", "result": "\u6a21\u578b\u5728\u5904\u7406\u9ad8\u7ef4\u6587\u672c\u6570\u636e\u65f6\u8868\u73b0\u826f\u597d\uff0c\u4f46\u7531\u4e8e\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u4e14\u4e0d\u5e73\u8861\uff0c\u9650\u5236\u4e86\u7ed3\u679c\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7efc\u5408\u8bc4\u4ef7\u4f7f\u7528\u4e86\u7cbe\u51c6\u7387\u3001\u53ec\u56de\u7387\u548cF1\u5206\u6570\u3002", "conclusion": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u68c0\u6d4b\u65af\u74e6\u5e0c\u91cc\u8bed\u4e2d\u7684\u9690\u6666\u8fb1\u9a82\u8bed\u8a00\uff0c\u4f46\u53d7\u9650\u4e8e\u6570\u636e\u89c4\u6a21\u548c\u4e0d\u5e73\u8861\u6027\uff0c\u7ed3\u679c\u7684\u6cdb\u5316\u6027\u6709\u9650\uff0c\u9700\u6269\u5c55\u6570\u636e\u96c6\u5e76\u91c7\u7528\u66f4\u5148\u8fdb\u6280\u672f\u63d0\u9ad8\u7cfb\u7edf\u6548\u679c\u3002"}}
{"id": "2602.13312", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13312", "abs": "https://arxiv.org/abs/2602.13312", "authors": ["Yishu Wang", "Wei Liu", "Yifan Li", "Shengxiang Xu", "Xujie Yuan", "Ran Li", "Yuyu Luo", "Jia Zhu", "Shimin Di", "Min-Ling Zhang", "Guixiang Li"], "title": "PeroMAS: A Multi-agent System of Perovskite Material Discovery", "comment": null, "summary": "As a pioneer of the third-generation photovoltaic revolution, Perovskite Solar Cells (PSCs) are renowned for their superior optoelectronic performance and cost potential. The development process of PSCs is precise and complex, involving a series of closed-loop workflows such as literature retrieval, data integration, experimental design, and synthesis. However, existing AI perovskite approaches focus predominantly on discrete models, including material design, process optimization,and property prediction. These models fail to propagate physical constraints across the workflow, hindering end-to-end optimization. In this paper, we propose a multi-agent system for perovskite material discovery, named PeroMAS. We first encapsulated a series of perovskite-specific tools into Model Context Protocols (MCPs). By planning and invoking these tools, PeroMAS can design perovskite materials under multi-objective constraints, covering the entire process from literature retrieval and data extraction to property prediction and mechanism analysis. Furthermore, we construct an evaluation benchmark by perovskite human experts to assess this multi-agent system. Results demonstrate that, compared to single Large Language Model (LLM) or traditional search strategies, our system significantly enhances discovery efficiency. It successfully identified candidate materials satisfying multi-objective constraints. Notably, we verify PeroMAS's effectiveness in the physical world through real synthesis experiments.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edfPeroMAS\uff0c\u5b9e\u73b0\u9499\u949b\u77ff\u6750\u6599\u7684\u7aef\u5230\u7aef\u53d1\u73b0\u548c\u4f18\u5316\uff0c\u63d0\u5347\u4e86\u6750\u6599\u53d1\u73b0\u6548\u7387\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u9499\u949b\u77ff\u592a\u9633\u80fd\u7535\u6c60\u7814\u7a76\u591a\u4f9d\u8d56\u79bb\u6563\u6a21\u578b\uff0c\u65e0\u6cd5\u5b9e\u73b0\u7aef\u5230\u7aef\u4f18\u5316\uff0c\u9650\u5236\u4e86\u6750\u6599\u53d1\u73b0\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u7cfb\u7edfPeroMAS\uff0c\u901a\u8fc7\u5c01\u88c5\u9499\u949b\u77ff\u4e13\u7528\u5de5\u5177\u4e3a\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae\uff08MCPs\uff09\uff0c\u5b9e\u73b0\u4ece\u6587\u732e\u68c0\u7d22\u3001\u6570\u636e\u63d0\u53d6\u5230\u6027\u80fd\u9884\u6d4b\u548c\u673a\u5236\u5206\u6790\u7684\u95ed\u73af\u5de5\u4f5c\u6d41\u7a0b\u4f18\u5316\u3002", "result": "PeroMAS\u76f8\u8f83\u4e8e\u5355\u4e00\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6216\u4f20\u7edf\u641c\u7d22\u7b56\u7565\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u9499\u949b\u77ff\u6750\u6599\u7684\u53d1\u73b0\u6548\u7387\uff0c\u6210\u529f\u8bc6\u522b\u51fa\u6ee1\u8db3\u591a\u76ee\u6807\u7ea6\u675f\u7684\u5019\u9009\u6750\u6599\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edfPeroMAS\u4e3a\u9499\u949b\u77ff\u6750\u6599\u7684\u7aef\u5230\u7aef\u53d1\u73b0\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u884c\u7684\u65b9\u6cd5\uff0c\u663e\u8457\u63a8\u52a8\u4e86\u7b2c\u4e09\u4ee3\u5149\u4f0f\u6750\u6599\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.13766", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13766", "abs": "https://arxiv.org/abs/2602.13766", "authors": ["Rafael Tomaz", "Paloma Guenes", "Allysson Allex Ara\u00fajo", "Maria Teresa Baldassarre", "Marcos Kalinowski"], "title": "Impacts of Generative AI on Agile Teams' Productivity: A Multi-Case Longitudinal Study", "comment": "Preprint with the original submission accepted for publication at Forge 2026", "summary": "Context: Generative Artificial Intelligence (GenAI) tools, such as GitHub Copilot and GPT tools, represent a paradigm shift in software engineering. While their impact is clear, most studies are short-term, focused on individual experiments. The sustained, team-level effects on productivity within industrial agile environments remain largely uncharacterized. Goal: This study aims to provide a longitudinal evaluation of GenAI's impact on agile software teams. We characterize its effect on developers' productivity by applying the multi-dimensional SPACE framework. Method: We conducted a multi-case longitudinal study involving 3 agile teams at a large technology consulting firm for around 13 months. We collected and compared quantitative telemetry (Jira, SonarQube, Git) and qualitative survey data from historical (pre-adoption) and research (post-adoption) sprints. Conclusion: GenAI tools can significantly improve team performance and well-being. Our key finding is a sharp increase in Performance and perceived Efficiency concurrent with flat developer Activity. This suggests GenAI increases the value density of development work, not its volume. This finding validates the necessity of multi-dimensional frameworks like SPACE to capture the true, nuanced impact of GenAI in situ, which would be invisible to studies measuring Activity alone.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u957f\u671f\u89c2\u5bdf\u53d1\u73b0\uff0c\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u4f7f\u654f\u6377\u56e2\u961f\u63d0\u5347\u4e86\u5de5\u4f5c\u6548\u7387\u548c\u8868\u73b0\uff0c\u800c\u5355\u7eaf\u4f9d\u9760\u6d3b\u52a8\u91cf\u6307\u6807\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u5176\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u4e3a\u77ed\u671f\u3001\u4e2a\u4f53\u5c42\u9762\uff0c\u7f3a\u4e4f\u5bf9\u5de5\u4e1a\u654f\u6377\u56e2\u961f\u4e2d\u751f\u6210\u5f0f\u4eba\u5de5\u667a\u80fd\u5de5\u5177\u957f\u671f\u5f71\u54cd\u7684\u7cfb\u7edf\u6027\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5bf9\u4e09\u652f\u654f\u6377\u56e2\u961f\u8fdb\u884c13\u4e2a\u6708\u7684\u591a\u6848\u4f8b\u7eb5\u5411\u7814\u7a76\uff0c\u7ed3\u5408Jira\u3001SonarQube\u3001Git\u7b49\u5b9a\u91cf\u6570\u636e\u4e0e\u95ee\u5377\u8c03\u67e5\u7684\u5b9a\u6027\u6570\u636e\uff0c\u57fa\u4e8e\u591a\u7ef4SPACE\u6846\u67b6\u5206\u6790GenAI\u5bf9\u5f00\u53d1\u8005\u751f\u4ea7\u529b\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0GenAI\u5de5\u5177\u663e\u8457\u63d0\u5347\u4e86\u56e2\u961f\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u4f46\u5f00\u53d1\u8005\u7684\u6d3b\u52a8\u91cf\u672a\u89c1\u589e\u52a0\uff0c\u8bf4\u660eGenAI\u63d0\u5347\u4e86\u5f00\u53d1\u5de5\u4f5c\u7684\u4ef7\u503c\u5bc6\u5ea6\u800c\u975e\u5de5\u4f5c\u91cf\u3002", "conclusion": "GenAI\u5de5\u5177\u5728\u654f\u6377\u56e2\u961f\u4e2d\u80fd\u6709\u6548\u63d0\u9ad8\u751f\u4ea7\u529b\u548c\u6210\u5458\u798f\u7949\uff0c\u4e14\u9700\u91c7\u7528\u591a\u7ef4\u6307\u6807\u6846\u67b6\u5982SPACE\u624d\u80fd\u5168\u9762\u6355\u6349\u5176\u771f\u5b9e\u5f71\u54cd\u3002"}}
{"id": "2602.13466", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.13466", "abs": "https://arxiv.org/abs/2602.13466", "authors": ["Benjamin L. Badger"], "title": "Language Model Memory and Memory Models for Language", "comment": null, "summary": "The ability of machine learning models to store input information in hidden layer vector embeddings, analogous to the concept of `memory', is widely employed but not well characterized. We find that language model embeddings typically contain relatively little input information regardless of data and compute scale during training. In contrast, embeddings from autoencoders trained for input regeneration are capable of nearly perfect memory formation. The substitution of memory embeddings for token sequences leads to substantial computational efficiencies, motivating the introduction of a parallelizable encoder-decoder memory model architecture. Upon causal training these models contain information-poor embeddings incapable of arbitrary information access, but by combining causal and information retention objective functions they learn to form and decode information-rich memories. Training can be further streamlined by freezing a high fidelity encoder followed by a curriculum training approach where decoders first learn to process memories and then learn to additionally predict next tokens. We introduce the perspective that next token prediction training alone is poorly suited for accurate memory formation as the objective itself is non-invertible, motivating the use of combined objective functions for models where the entire input is not exposed.", "AI": {"tldr": "\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u4fe1\u606f\u542b\u91cf\u8f83\u4f4e\uff0c\u81ea\u7f16\u7801\u5668\u5d4c\u5165\u8bb0\u5fc6\u6548\u679c\u597d\u3002\u63d0\u51fa\u5e76\u884c\u7f16\u7801\u5668-\u89e3\u7801\u5668\u8bb0\u5fc6\u6a21\u578b\uff0c\u901a\u8fc7\u7ed3\u5408\u8bad\u7ec3\u76ee\u6807\u5b9e\u73b0\u4fe1\u606f\u4e30\u5bcc\u8bb0\u5fc6\uff0c\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u8bed\u8a00\u6a21\u578b\u5d4c\u5165\u8bb0\u5fc6\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u4ec5\u57fa\u4e8e\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u8bad\u7ec3\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u4e9f\u9700\u8bbe\u8ba1\u6709\u6548\u8bb0\u5fc6\u5f62\u6210\u673a\u5236\u4ee5\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u548c\u4fe1\u606f\u4fdd\u7559\u3002", "method": "\u63d0\u51fa\u5e76\u884c\u5316\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\uff0c\u7ed3\u5408\u56e0\u679c\u8bad\u7ec3\u4e0e\u4fe1\u606f\u4fdd\u7559\u76ee\u6807\u51fd\u6570\u8bad\u7ec3\uff0c\u540c\u65f6\u91c7\u7528\u51bb\u7ed3\u7f16\u7801\u5668\u4e0e\u5faa\u5e8f\u6e10\u8fdb\u89e3\u7801\u5668\u8bad\u7ec3\u7b56\u7565\u3002", "result": "\u672c\u6587\u53d1\u73b0\u8bed\u8a00\u6a21\u578b\u7684\u9690\u85cf\u5c42\u5411\u91cf\uff08\u5d4c\u5165\uff09\u901a\u5e38\u5305\u542b\u8f83\u5c11\u7684\u8f93\u5165\u4fe1\u606f\uff0c\u800c\u81ea\u7f16\u7801\u5668\u8bad\u7ec3\u5f97\u5230\u7684\u5d4c\u5165\u80fd\u51e0\u4e4e\u5b8c\u7f8e\u5730\u8bb0\u5fc6\u8f93\u5165\u3002\u901a\u8fc7\u66ff\u6362\u8bb0\u5fc6\u5d4c\u5165\u4ee3\u66ff\u4ee4\u724c\u5e8f\u5217\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\uff0c\u56e0\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u5e76\u884c\u5316\u7f16\u7801\u5668-\u89e3\u7801\u5668\u8bb0\u5fc6\u6a21\u578b\u3002\u5728\u56e0\u679c\u8bad\u7ec3\u4e0b\uff0c\u6b64\u6a21\u578b\u751f\u6210\u7684\u4fe1\u606f\u8f83\u5c11\uff0c\u4f46\u7ed3\u5408\u56e0\u679c\u548c\u4fe1\u606f\u4fdd\u7559\u76ee\u6807\u51fd\u6570\u8bad\u7ec3\u540e\uff0c\u80fd\u5f62\u6210\u4fe1\u606f\u4e30\u5bcc\u7684\u8bb0\u5fc6\u3002\u8bad\u7ec3\u8fc7\u7a0b\u53ef\u901a\u8fc7\u51bb\u7ed3\u9ad8\u4fdd\u771f\u7f16\u7801\u5668\u53ca\u5faa\u5e8f\u6e10\u8fdb\u8bad\u7ec3\u7b80\u5316\u3002\u8be5\u7814\u7a76\u6307\u51fa\uff0c\u4ec5\u9760\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u8bad\u7ec3\u4e0d\u9002\u5408\u51c6\u786e\u8bb0\u5fc6\u751f\u6210\uff0c\u56e0\u4e3a\u76ee\u6807\u51fd\u6570\u4e0d\u53ef\u9006\uff0c\u56e0\u800c\u9700\u8981\u7ed3\u5408\u591a\u76ee\u6807\u8bad\u7ec3\u3002", "conclusion": "\u4ec5\u4f9d\u9760\u4e0b\u4e00\u4ee4\u724c\u9884\u6d4b\u8bad\u7ec3\u4e0d\u8db3\u4ee5\u5f62\u6210\u51c6\u786e\u8bb0\u5fc6\uff0c\u7ed3\u5408\u56e0\u679c\u548c\u4fe1\u606f\u4fdd\u7559\u76ee\u6807\u51fd\u6570\u80fd\u6709\u6548\u63d0\u5347\u6a21\u578b\u8bb0\u5fc6\u80fd\u529b\u548c\u6548\u7387\u3002"}}
{"id": "2602.13353", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2602.13353", "abs": "https://arxiv.org/abs/2602.13353", "authors": ["Bhavini Jeloka", "Yue Guan", "Panagiotis Tsiotras"], "title": "Robust Mean-Field Games with Risk Aversion and Bounded Rationality", "comment": "25 pages, 2 figures", "summary": "Recent advances in mean-field game literature enable the reduction of large-scale multi-agent problems to tractable interactions between a representative agent and a population distribution. However, existing approaches typically assume a fixed initial population distribution and fully rational agents, limiting robustness under distributional uncertainty and cognitive constraints. We address these limitations by introducing risk aversion with respect to the initial population distribution and by incorporating bounded rationality to model deviations from fully rational decision-making agents. The combination of these two elements yields a new and more general equilibrium concept, which we term the mean-field risk-averse quantal response equilibrium (MF-RQE). We establish existence results and prove convergence of fixed-point iteration and fictitious play to MF-RQE. Building on these insights, we develop a scalable reinforcement learning algorithm for scenarios with large state-action spaces. Numerical experiments demonstrate that MF-RQE policies achieve improved robustness relative to classical mean-field approaches that optimize expected cumulative rewards under a fixed initial distribution and are restricted to entropy-based regularizers.", "AI": {"tldr": "\u672c\u6587\u5f15\u5165\u98ce\u9669\u538c\u6076\u548c\u6709\u9650\u7406\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5747\u573a\u535a\u5f08\u5747\u8861MF-RQE\uff0c\u5e76\u8bbe\u8ba1\u4e86\u76f8\u5e94\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5bf9\u5927\u89c4\u6a21\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u9c81\u68d2\u4f18\u5316\u3002", "motivation": "\u73b0\u6709\u5747\u573a\u535a\u5f08\u65b9\u6cd5\u5047\u8bbe\u56fa\u5b9a\u7684\u521d\u59cb\u7fa4\u4f53\u5206\u5e03\u548c\u5b8c\u5168\u7406\u6027\uff0c\u5bfc\u81f4\u5728\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u548c\u8ba4\u77e5\u7ea6\u675f\u4e0b\u9c81\u68d2\u6027\u4e0d\u8db3\u3002\u4e3a\u6b64\uff0c\u8bba\u6587\u901a\u8fc7\u98ce\u9669\u538c\u6076\u548c\u6709\u9650\u7406\u6027\u5047\u8bbe\uff0c\u6784\u5efa\u66f4\u901a\u7528\u4e14\u9c81\u68d2\u7684\u5747\u573a\u5747\u8861\u6982\u5ff5\uff0c\u4ee5\u66f4\u597d\u5730\u5e94\u5bf9\u5b9e\u9645\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u5f15\u5165\u98ce\u9669\u538c\u6076\u548c\u6709\u9650\u7406\u6027\u7684\u7406\u8bba\u6846\u67b6\uff0c\u8bba\u6587\u8bc1\u660e\u4e86MF-RQE\u5747\u8861\u7684\u5b58\u5728\u6027\u548c\u7b97\u6cd5\u6536\u655b\u6027\uff0c\u8bbe\u8ba1\u4e86\u7ed3\u5408\u56fa\u5b9a\u70b9\u8fed\u4ee3\u548c\u865a\u62df\u5bf9\u6297\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u9002\u5408\u5927\u89c4\u6a21\u72b6\u6001\u52a8\u4f5c\u7a7a\u95f4\u7684\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5747\u573a\u98ce\u9669\u538c\u6076\u91cf\u5316\u53cd\u5e94\u5747\u8861\uff08MF-RQE\uff09\u6a21\u578b\uff0c\u7ed3\u5408\u4e86\u5bf9\u521d\u59cb\u7fa4\u4f53\u5206\u5e03\u7684\u98ce\u9669\u538c\u6076\u548c\u6709\u9650\u7406\u6027\uff0c\u4ece\u800c\u514b\u670d\u4e86\u4f20\u7edf\u5747\u573a\u535a\u5f08\u5047\u8bbe\u56fa\u5b9a\u521d\u59cb\u5206\u5e03\u548c\u5b8c\u5168\u7406\u6027\u7684\u5c40\u9650\u6027\u3002\u8bba\u6587\u8bc1\u660e\u4e86\u8be5\u5747\u8861\u7684\u5b58\u5728\u6027\u53ca\u56fa\u5b9a\u70b9\u8fed\u4ee3\u548c\u865a\u62df\u5bf9\u6297\u5b66\u4e60\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u8fdb\u4e00\u6b65\u8bbe\u8ba1\u4e86\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u72b6\u6001-\u52a8\u4f5c\u7a7a\u95f4\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u3002\u6570\u503c\u5b9e\u9a8c\u8868\u660eMF-RQE\u5728\u9762\u5bf9\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u548c\u8ba4\u77e5\u7ea6\u675f\u65f6\uff0c\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "MF-RQE\u6a21\u578b\u6210\u529f\u878d\u5408\u98ce\u9669\u538c\u6076\u548c\u6709\u9650\u7406\u6027\uff0c\u80fd\u591f\u66f4\u9c81\u68d2\u5730\u5904\u7406\u5206\u5e03\u4e0d\u786e\u5b9a\u6027\u548c\u8ba4\u77e5\u9650\u5236\u95ee\u9898\uff0c\u4e14\u5176\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u95ee\u9898\uff0c\u6570\u503c\u9a8c\u8bc1\u652f\u6301\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.13767", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13767", "abs": "https://arxiv.org/abs/2602.13767", "authors": ["Paloma Guenes", "Rafael Tomaz", "Maria Teresa Baldassarre", "Alexander Serebrenik"], "title": "Impostor Phenomenon as Human Debt: A Challenge to the Future of Software Engineering", "comment": "Preprint of the paper accepted for the Future of Software Engineering (FoSE) track at ICSE 2026", "summary": "The Impostor Phenomenon (IP) impacts a significant portion of the Software Engineering workforce, yet it is often viewed primarily through an internal individual lens. In this position paper, we propose framing the prevalence of IP as a form of Human Debt and discuss the relation with the ICSE2026 Pre Survey on the Future of Software Engineering results. Similar to technical debt, which arises when short-term goals are prioritized over long-term structural integrity, Human Debt accumulates due to gaps in psychological safety and inclusive support within socio-technical ecosystems. We observe that this debt is not distributed equally, it weighs heavier on underrepresented engineers and researchers, who face compounded challenges within traditional hierarchical structures and academic environments. We propose cultural refactoring, transparency and active maintenance through allyship, suggesting that leaders and institutions must address the environmental factors that exacerbate these feelings, ensuring a sustainable ecosystem for all professionals.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u5c06\u5192\u540d\u9876\u66ff\u73b0\u8c61\u89c6\u4e3a\u4eba\u529b\u503a\u52a1\uff0c\u5f3a\u8c03\u9700\u901a\u8fc7\u6587\u5316\u91cd\u6784\u3001\u900f\u660e\u5316\u548c\u76df\u53cb\u652f\u6301\u7b49\u624b\u6bb5\uff0c\u6539\u5584\u8f6f\u4ef6\u5de5\u7a0b\u73af\u5883\u4ee5\u51cf\u5c11\u5fc3\u7406\u8d1f\u62c5\uff0c\u4fc3\u8fdb\u53ef\u6301\u7eed\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u4ece\u4e2a\u4f53\u5185\u5728\u89c6\u89d2\u770b\u5f85IP\uff0c\u5ffd\u89c6\u5176\u5728\u7ec4\u7ec7\u6587\u5316\u548c\u73af\u5883\u4e2d\u7684\u7cfb\u7edf\u6027\u5f71\u54cd\uff0c\u5c24\u5176\u5bf9\u5f31\u52bf\u7fa4\u4f53\u7684\u989d\u5916\u8d1f\u62c5\u3002", "method": "\u63d0\u51fa\u5c06\u5192\u540d\u9876\u66ff\u73b0\u8c61\uff08IP\uff09\u89c6\u4e3a\u4e00\u79cd\u201c\u4eba\u529b\u503a\u52a1\u201d\uff0c\u901a\u8fc7\u4e0eICSE2026\u672a\u6765\u8f6f\u4ef6\u5de5\u7a0b\u9884\u8c03\u67e5\u7ed3\u679c\u7684\u5173\u8054\uff0c\u5206\u6790IP\u7684\u793e\u4f1a\u6280\u672f\u751f\u6001\u7cfb\u7edf\u80cc\u666f\u3002", "result": "\u53d1\u73b0\u4eba\u529b\u503a\u52a1\u56e0\u5fc3\u7406\u5b89\u5168\u611f\u7f3a\u5931\u548c\u652f\u6301\u4e0d\u8db3\u5728\u793e\u4f1a\u6280\u672f\u73af\u5883\u4e2d\u79ef\u7d2f\uff0c\u4e14\u5728\u5f31\u52bf\u7fa4\u4f53\u4e2d\u66f4\u4e3a\u4e25\u91cd\uff0c\u4f20\u7edf\u5c42\u7ea7\u7ed3\u6784\u548c\u5b66\u672f\u73af\u5883\u52a0\u5267\u4e86\u8fd9\u4e00\u73b0\u8c61\u3002", "conclusion": "\u9886\u5bfc\u8005\u548c\u673a\u6784\u5e94\u5173\u6ce8\u5e76\u89e3\u51b3\u52a0\u5267\u5192\u540d\u9876\u66ff\u611f\u7684\u73af\u5883\u56e0\u7d20\uff0c\u63a8\u52a8\u6587\u5316\u53d8\u9769\u548c\u652f\u6301\u4f53\u7cfb\u5efa\u8bbe\uff0c\u4fdd\u969c\u6240\u6709\u8f6f\u4ef6\u5de5\u7a0b\u4ece\u4e1a\u8005\u7684\u5fc3\u7406\u5b89\u5168\u548c\u804c\u4e1a\u53ef\u6301\u7eed\u6027\u3002"}}
{"id": "2602.13504", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13504", "abs": "https://arxiv.org/abs/2602.13504", "authors": ["Ozancan Ozdemir"], "title": "From Perceptions To Evidence: Detecting AI-Generated Content In Turkish News Media With A Fine-Tuned Bert Classifier", "comment": null, "summary": "The rapid integration of large language models into newsroom workflows has raised urgent questions about the prevalence of AI-generated content in online media. While computational studies have begun to quantify this phenomenon in English-language outlets, no empirical investigation exists for Turkish news media, where existing research remains limited to qualitative interviews with journalists or fake news detection. This study addresses that gap by fine-tuning a Turkish-specific BERT model (dbmdz/bert-base-turkish-cased) on a labeled dataset of 3,600 articles from three major Turkish outlets with distinct editorial orientations for binary classification of AI-rewritten content. The model achieves 0.9708 F1 score on the held-out test set with symmetric precision and recall across both classes. Subsequent deployment on over 3,500 unseen articles spanning between 2023 and 2026 reveals consistent cross-source and temporally stable classification patterns, with mean prediction confidence exceeding 0.96 and an estimated 2.5 percentage of examined news content rewritten or revised by LLMs on average. To the best of our knowledge, this is the first study to move beyond self-reported journalist perceptions toward empirical, data-driven measurement of AI usage in Turkish news media.", "AI": {"tldr": "\u672c\u7814\u7a76\u5229\u7528\u571f\u8033\u5176\u8bedBERT\u6a21\u578b\uff0c\u9996\u6b21\u5b9e\u8bc1\u91cf\u5316\u4e86\u571f\u8033\u5176\u65b0\u95fb\u5a92\u4f53\u4e2dAI\u91cd\u5199\u5185\u5bb9\u7684\u6bd4\u4f8b\uff0c\u53d1\u73b0\u7ea62.5%\u7684\u65b0\u95fb\u53d7\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5f71\u54cd\u3002", "motivation": "\u571f\u8033\u5176\u65b0\u95fb\u5a92\u4f53\u4e2dAI\u751f\u6210\u5185\u5bb9\u7684\u5b9e\u9645\u4f7f\u7528\u5c1a\u65e0\u5b9e\u8bc1\u7814\u7a76\uff0c\u73b0\u6709\u7814\u7a76\u591a\u9650\u4e8e\u5b9a\u6027\u91c7\u8bbf\u548c\u5047\u65b0\u95fb\u68c0\u6d4b\uff0c\u4e9f\u9700\u91cf\u5316\u5206\u6790\u3002", "method": "\u901a\u8fc7\u5fae\u8c03\u9488\u5bf9\u571f\u8033\u5176\u8bed\u7684BERT\u6a21\u578b\uff0c\u5229\u7528\u6765\u81ea\u4e09\u5927\u571f\u8033\u5176\u65b0\u95fb\u673a\u6784\u51713600\u7bc7\u6807\u6ce8\u6587\u7ae0\u8fdb\u884c\u4e8c\u5206\u7c7b\uff0c\u8bc6\u522bAI\u91cd\u5199\u5185\u5bb9\uff0c\u5e76\u57282023\u81f32026\u5e74\u8d85\u8fc73500\u7bc7\u672a\u89c1\u6587\u7ae0\u4e2d\u8fdb\u884c\u90e8\u7f72\u9a8c\u8bc1\u3002", "result": "\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u4e0a\u53d6\u5f970.9708\u7684F1\u5206\u6570\uff0c\u9884\u6d4b\u7f6e\u4fe1\u5ea6\u5e73\u5747\u8d85\u8fc70.96\uff0c\u4f30\u8ba1\u7ea62.5%\u7684\u65b0\u95fb\u5185\u5bb9\u88ab\u5927\u578b\u8bed\u8a00\u6a21\u578b\u91cd\u5199\u6216\u4fee\u6539\u3002", "conclusion": "\u672c\u7814\u7a76\u5b9e\u73b0\u4e86\u571f\u8033\u5176\u65b0\u95fb\u5a92\u4f53AI\u4f7f\u7528\u7684\u9996\u4e2a\u5b9e\u8bc1\u6570\u636e\u9a71\u52a8\u6d4b\u91cf\uff0c\u8d85\u8d8a\u4e86\u4ee5\u5f80\u4f9d\u8d56\u8bb0\u8005\u81ea\u8ff0\u7684\u8c03\u67e5\uff0c\u4e3a\u7406\u89e3AI\u5185\u5bb9\u4ea7\u751f\u63d0\u4f9b\u4e86\u5b9e\u8bc1\u57fa\u7840\u3002"}}
{"id": "2602.13370", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13370", "abs": "https://arxiv.org/abs/2602.13370", "authors": ["Karim Ben Khaled", "Davy Monticolo"], "title": "G2CP: A Graph-Grounded Communication Protocol for Verifiable and Efficient Multi-Agent Reasoning", "comment": null, "summary": "Multi-agent systems powered by Large Language Models face a critical challenge: agents communicate through natural language, leading to semantic drift, hallucination propagation, and inefficient token consumption. We propose G2CP (Graph-Grounded Communication Protocol), a structured agent communication language where messages are graph operations rather than free text. Agents exchange explicit traversal commands, subgraph fragments, and update operations over a shared knowledge graph, enabling verifiable reasoning traces and eliminating ambiguity. We validate G2CP within an industrial knowledge management system where specialized agents (Diagnostic, Procedural, Synthesis, and Ingestion) coordinate to answer complex queries. Experimental results on 500 industrial scenarios and 21 real-world maintenance cases show that G2CP reduces inter-agent communication tokens by 73%, improves task completion accuracy by 34% over free-text baselines, eliminates cascading hallucinations, and produces fully auditable reasoning chains. G2CP represents a fundamental shift from linguistic to structural communication in multi-agent systems, with implications for any domain requiring precise agent coordination. Code, data, and evaluation scripts are publicly available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u56fe\u7ed3\u6784\u7684\u591a\u4ee3\u7406\u901a\u8baf\u534f\u8bae\uff0c\u663e\u8457\u63d0\u5347\u4e86\u901a\u4fe1\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u89c4\u907f\u4e86\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\u7684\u5f0a\u7aef\uff0c\u9a8c\u8bc1\u4e86\u5728\u5de5\u4e1a\u573a\u666f\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\u4f7f\u7528\u81ea\u7136\u8bed\u8a00\u901a\u4fe1\uff0c\u5b58\u5728\u8bed\u4e49\u6f02\u79fb\u3001\u5e7b\u89c9\u4f20\u64ad\u548c\u4ee4\u724c\u6d88\u8017\u4f4e\u6548\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u901a\u4fe1\u534f\u8baeG2CP\uff0c\u901a\u4fe1\u5185\u5bb9\u7531\u56fe\u64cd\u4f5c\u7ec4\u6210\uff0c\u4ee3\u7406\u901a\u8fc7\u663e\u5f0f\u7684\u904d\u5386\u547d\u4ee4\u3001\u5b50\u56fe\u7247\u6bb5\u548c\u66f4\u65b0\u64cd\u4f5c\uff0c\u5728\u5171\u4eab\u77e5\u8bc6\u56fe\u4e0a\u4ea4\u6d41\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cG2CP\u5728\u5de5\u4e1a\u77e5\u8bc6\u7ba1\u7406\u7cfb\u7edf\u4e2d\u53ef\u5c06\u901a\u4fe1\u4ee4\u724c\u6d88\u8017\u51cf\u5c1173%\uff0c\u4efb\u52a1\u5b8c\u6210\u51c6\u786e\u7387\u63d0\u534734%\uff0c\u6d88\u9664\u7ea7\u8054\u5e7b\u89c9\uff0c\u751f\u6210\u53ef\u5ba1\u8ba1\u7684\u63a8\u7406\u94fe\u3002", "conclusion": "G2CP\u5b9e\u73b0\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u4ece\u8bed\u8a00\u901a\u4fe1\u5411\u7ed3\u6784\u5316\u901a\u4fe1\u7684\u6839\u672c\u8f6c\u53d8\uff0c\u63d0\u5347\u4e86\u7cbe\u786e\u534f\u8c03\u80fd\u529b\uff0c\u5bf9\u591a\u4ee3\u7406\u534f\u4f5c\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.13774", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13774", "abs": "https://arxiv.org/abs/2602.13774", "authors": ["Paloma Guenes", "Joan Leite", "Rafael Tomaz", "Allysson Allex Araujo", "Jean Natividade", "Maria Teresa Baldassarre", "Marcos Kalinowski"], "title": "A Quasi-Experimental Evaluation of Coaching to Mitigate the Impostor Phenomenon in Early-Career Software Engineers", "comment": "Preprint with the original submission accepted for publication at CHASE 2026", "summary": "Context: The Impostor Phenomenon (IP), the persistent belief of being a fraud despite evident competence, is common in Software Engineering (SE), where high expectations for expertise and innovation prevail. Although coaching and similar interventions are proposed to mitigate IP, empirical evidence in SE remains underexplored.\n  Objective: This study examines the impact of a structured group coaching intervention on reducing IP feelings among early-career software engineers.\n  Method: We conducted a quasi-experiment with 20 participants distributed across two project teams using a wait-list control design, complemented by non-participant observation. The treatment group received a three-session coaching intervention, while the control group received it after an observation phase. IP was assessed using the Clance Impostor Phenomenon Scale (CIPS), alongside evaluated measures of well-being (WHO-5), life satisfaction (SWLS), and affect (PANAS).\n  Results: The coaching resulted in modest reductions in CIPS scores, whereas the control group also improved during the observation phase, suggesting that contextual and temporal factors may have exerted a stronger influence than the formal intervention.\n  Conclusion: These results suggest that coaching may support reflection and awareness related to IP, yet other contextual aspects of team collaboration and project work might also contribute to these changes. This study offers a novel empirical step toward understanding how structured IP interventions operate within SE environments.", "AI": {"tldr": "\u8f85\u5bfc\u80fd\u7a0d\u51cf\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u7684\u5192\u540d\u9876\u66ff\u611f\uff0c\u4f46\u56e2\u961f\u548c\u9879\u76ee\u73af\u5883\u4e5f\u5bf9\u5176\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u5192\u540d\u9876\u66ff\u73b0\u8c61\u5728\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u4f46\u5173\u4e8e\u51cf\u8f7bIP\u7684\u5b9e\u8bc1\u7814\u7a76\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u5728\u8f6f\u4ef6\u5de5\u7a0b\u9886\u57df\uff0c\u6545\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u8f85\u5bfc\u5e72\u9884\u5bf9IP\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u51c6\u5b9e\u9a8c\u8bbe\u8ba1\uff0c20\u540d\u65e9\u671f\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5206\u6210\u4e24\u7ec4\uff0c\u5176\u4e2d\u4e00\u7ec4\u63a5\u53d7\u4e09\u6b21\u8f85\u5bfc\u5e72\u9884\uff0c\u53e6\u4e00\u7ec4\u4f5c\u4e3a\u7b49\u5f85\u7ec4\uff1b\u4f7f\u7528Clance IP\u91cf\u8868\u3001WHO-5\u3001SWLS\u548cPANAS\u6d4b\u91cfIP\u548c\u5fc3\u7406\u72b6\u6001\uff1b\u8f85\u4ee5\u975e\u53c2\u4e0e\u89c2\u5bdf\u3002", "result": "\u672c\u6587\u7814\u7a76\u4e86\u7ed3\u6784\u5316\u5c0f\u7ec4\u8f85\u5bfc\u5bf9\u65e9\u671f\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u5192\u540d\u9876\u66ff\u73b0\u8c61\uff08IP\uff09\u611f\u53d7\u7684\u5f71\u54cd\u3002\u901a\u8fc7\u5bf920\u540d\u53c2\u4e0e\u8005\u5206\u4e3a\u4e24\u7ec4\u8fdb\u884c\u7684\u51c6\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u8f85\u4ee5\u975e\u53c2\u4e0e\u89c2\u5bdf\uff0c\u53d1\u73b0\u8f85\u5bfc\u7ec4\u7684IP\u5f97\u5206\u6709\u9002\u5ea6\u4e0b\u964d\uff0c\u4f46\u5bf9\u7167\u7ec4\u5728\u89c2\u5bdf\u671f\u5185\u4e5f\u6709\u6240\u6539\u5584\uff0c\u6697\u793a\u56e2\u961f\u534f\u4f5c\u548c\u9879\u76ee\u73af\u5883\u7b49\u60c5\u5883\u56e0\u7d20\u53ef\u80fd\u6bd4\u8f85\u5bfc\u4f5c\u7528\u66f4\u5f3a\u3002", "conclusion": "\u8f85\u5bfc\u6709\u52a9\u4e8eIP\u7684\u53cd\u601d\u548c\u89c9\u5bdf\uff0c\u4f46\u56e2\u961f\u548c\u9879\u76ee\u73af\u5883\u7b49\u60c5\u5883\u56e0\u7d20\u5bf9IP\u611f\u53d7\u540c\u6837\u5177\u6709\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2602.13517", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13517", "abs": "https://arxiv.org/abs/2602.13517", "authors": ["Wei-Lin Chen", "Liqian Peng", "Tian Tan", "Chao Zhao", "Blake JianHang Chen", "Ziqian Lin", "Alec Go", "Yu Meng"], "title": "Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens", "comment": "Work in progress", "summary": "Large language models (LLMs) have demonstrated impressive reasoning capabilities by scaling test-time compute via long Chain-of-Thought (CoT). However, recent findings suggest that raw token counts are unreliable proxies for reasoning quality: increased generation length does not consistently correlate with accuracy and may instead signal \"overthinking,\" leading to performance degradation. In this work, we quantify inference-time effort by identifying deep-thinking tokens -- tokens where internal predictions undergo significant revisions in deeper model layers prior to convergence. Across four challenging mathematical and scientific benchmarks (AIME 24/25, HMMT 25, and GPQA-diamond) and a diverse set of reasoning-focused models (GPT-OSS, DeepSeek-R1, and Qwen3), we show that deep-thinking ratio (the proportion of deep-thinking tokens in a generated sequence) exhibits a robust and consistently positive correlation with accuracy, substantially outperforming both length-based and confidence-based baselines. Leveraging this insight, we introduce Think@n, a test-time scaling strategy that prioritizes samples with high deep-thinking ratios. We demonstrate that Think@n matches or exceeds standard self-consistency performance while significantly reducing inference costs by enabling the early rejection of unpromising generations based on short prefixes.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u8bc6\u522b\u6a21\u578b\u5185\u90e8\u6df1\u5ea6\u8c03\u6574\u7684\u201c\u6df1\u5ea6\u601d\u8003\u201d\u4ee3\u5e01\uff0c\u53d1\u73b0\u5176\u6bd4\u4f8b\u4e0e\u63a8\u7406\u51c6\u786e\u6027\u9ad8\u5ea6\u76f8\u5173\uff0c\u57fa\u4e8e\u6b64\u63d0\u51faThink@n\u7b56\u7565\uff0c\u5b9e\u73b0\u7cbe\u51c6\u9ad8\u6548\u63a8\u7406\u3002", "motivation": "\u76ee\u524d\u5927\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u589e\u52a0\u63a8\u7406\u65f6\u957f\u6765\u63d0\u5347\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u751f\u6210\u957f\u5ea6\u4e0e\u51c6\u786e\u6027\u4e0d\u603b\u662f\u6b63\u76f8\u5173\uff0c\u8fc7\u957f\u53cd\u800c\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u5373\u201c\u8fc7\u5ea6\u601d\u8003\u201d\u3002", "method": "\u63d0\u51fa\u6d4b\u91cf\u63a8\u7406\u65f6\u201c\u6df1\u5ea6\u601d\u8003\u201d\u4ee3\u5e01\u7684\u65b9\u6cd5\uff0c\u5373\u8bc6\u522b\u5728\u6a21\u578b\u6df1\u5c42\u9884\u6d4b\u663e\u8457\u4fee\u6b63\u7684\u4ee3\u5e01\uff0c\u8ba1\u7b97\u6df1\u5ea6\u601d\u8003\u6bd4\u7387\uff0c\u5e76\u57fa\u4e8e\u6b64\u8bbe\u8ba1Think@n\u7b56\u7565\uff0c\u5728\u63a8\u7406\u65f6\u4f18\u5148\u5904\u7406\u6df1\u5ea6\u601d\u8003\u6bd4\u4f8b\u9ad8\u7684\u6837\u672c\u3002", "result": "\u5728\u56db\u4e2a\u6570\u5b66\u4e0e\u79d1\u5b66\u57fa\u51c6\u53ca\u591a\u79cd\u63a8\u7406\u6a21\u578b\u4e0a\uff0c\u6df1\u5ea6\u601d\u8003\u6bd4\u7387\u4e0e\u51c6\u786e\u6027\u5448\u7a33\u5b9a\u6b63\u76f8\u5173\uff0c\u4e14\u4f18\u4e8e\u957f\u5ea6\u548c\u7f6e\u4fe1\u5ea6\u6307\u6807\u3002Think@n\u5728\u4fdd\u8bc1\u6216\u8d85\u8d8a\u81ea\u6d3d\u65b9\u6cd5\u6027\u80fd\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u3002", "conclusion": "\u6df1\u5ea6\u601d\u8003\u4ee3\u5e01\u6bd4\u4f8b\u662f\u8861\u91cf\u63a8\u7406\u8d28\u91cf\u7684\u6709\u6548\u6307\u6807\uff0c\u57fa\u4e8e\u8be5\u6307\u6807\u7684\u63a8\u7406\u65f6\u8c03\u63a7\u7b56\u7565\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002"}}
{"id": "2602.13671", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13671", "abs": "https://arxiv.org/abs/2602.13671", "authors": ["Guangyi Liu", "Haojun Lin", "Huan Zeng", "Heng Wang", "Quanming Yao"], "title": "MAS-on-the-Fly: Dynamic Adaptation of LLM-based Multi-Agent Systems at Test Time", "comment": null, "summary": "Large Language Model (LLM)-based multi-agent systems (MAS) have emerged as a promising paradigm for solving complex tasks. However, existing works often rely on manual designs or \"one-size-fits-all\" automation, lacking dynamic adaptability after deployment. Inspired by how biological systems adapt, we introduce MASFly, a novel multi-agent framework enabling dynamic adaptation at test time. To adapt system generation, MASFly employs a retrieval-augmented SOP instantiation mechanism that leverages a self-constructed repository of successful collaboration patterns, enabling the LLM to assemble customized MASs for new queries. For adaptive execution, MASFly incorporates an experience-guided supervision mechanism, where a dedicated Watcher agent monitors system behaviors with reference to a personalized experience pool and provides real-time interventions. Extensive experiments demonstrate that MASFly achieves state-of-the-art performance, most notably a 61.7% success rate on the TravelPlanner benchmark, while exhibiting strong task adaptability and robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e00\u4e2a\u80fd\u591f\u52a8\u6001\u9002\u5e94\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u6846\u67b6MASFly\uff0c\u901a\u8fc7\u7ecf\u9a8c\u5e93\u548c\u76d1\u7763\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u4efb\u52a1\u6210\u529f\u7387\u548c\u7cfb\u7edf\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u901a\u5e38\u4f9d\u8d56\u624b\u52a8\u8bbe\u8ba1\u6216\u7edf\u4e00\u7684\u81ea\u52a8\u5316\u65b9\u6848\uff0c\u7f3a\u4e4f\u90e8\u7f72\u540e\u7684\u52a8\u6001\u9002\u5e94\u80fd\u529b\u3002", "method": "\u63d0\u51faMASFly\u6846\u67b6\uff0c\u5f15\u5165\u68c0\u7d22\u589e\u5f3a\u7684SOP\u5b9e\u4f8b\u5316\u673a\u5236\uff0c\u901a\u8fc7\u81ea\u5efa\u6210\u529f\u534f\u4f5c\u6a21\u5f0f\u5e93\u52a8\u6001\u7ec4\u88c5\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff1b\u5f15\u5165\u7ecf\u9a8c\u6307\u5bfc\u7684\u76d1\u7763\u673a\u5236\uff0c\u7531\u4e13\u95e8\u7684\u89c2\u5bdf\u8005\u667a\u80fd\u4f53\u5b9e\u65f6\u76d1\u63a7\u7cfb\u7edf\u884c\u4e3a\u5e76\u8fdb\u884c\u5e72\u9884\u3002", "result": "MASFly\u5728\u591a\u9879\u5b9e\u9a8c\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5728TravelPlanner\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6210\u529f\u7387\u8fbe61.7%\uff0c\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u4efb\u52a1\u9002\u5e94\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "MASFly\u6709\u6548\u5b9e\u73b0\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u52a8\u6001\u9002\u5e94\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u4efb\u52a1\u7684\u89e3\u51b3\u80fd\u529b\uff0c\u9a8c\u8bc1\u4e86\u5176\u8bbe\u8ba1\u65b9\u6848\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.13845", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13845", "abs": "https://arxiv.org/abs/2602.13845", "authors": ["Allysson Allex Ara\u00fajo", "Gabriel Vasconcelos", "Marvin Wyrich", "Maria Teresa Baldassarre", "Paloma Guenes", "Marcos Kalinowski"], "title": "Constructive Patterns for Human-Centered Tech Hiring", "comment": null, "summary": "[Context] Online Recruitment and Selection (R&S) processes are often the first point of contact between early-career software engineers and the tech industry. Yet many candidates experience these processes as opaque, inefficient, or even discouraging. While prior research has extensively documented the flaws and biases in online tech hiring, little is known about the practices that create positive candidate experiences. [Objective & Method] This paper explores such practices, referred to as Constructive Patterns (CPs), from the perspective of early-career software engineers. Guided by Applicant Attribution-Reaction Theory, we conducted 22 semi-structured interviews in which participants collectively described over 470 online R&S experiences. [Results] Through thematic analysis, we identified 22 CPs that reflect positive practices such as comprehensive and transparent job advertisements (CP01), specific and developmental feedback (CP03), humanized and respectful interaction (CP06), and framing the process as a two-way street (CP18). [Conclusion] Our findings extend the conversation on tech hiring beyond diagnosing dysfunctions toward designing for human-centered and growth-oriented candidate experiences. The resulting catalog of CPs provides a concrete and empirically grounded resource for organizations seeking to attract and support early-career software engineers more effectively.", "AI": {"tldr": "\u7814\u7a76\u63ed\u793a\u4e86\u63d0\u5347\u5728\u7ebf\u6280\u672f\u62db\u8058\u4f53\u9a8c\u768422\u79cd\u6b63\u5411\u5b9e\u8df5\uff0c\u4e3a\u4f01\u4e1a\u5438\u5f15\u548c\u652f\u6301\u521d\u7ea7\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u63d0\u4f9b\u5b9e\u8bc1\u6307\u5bfc\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u6709\u7814\u7a76\u63ed\u793a\u4e86\u7ebf\u4e0a\u6280\u672f\u62db\u8058\u4e2d\u7684\u7f3a\u9677\u548c\u504f\u89c1\uff0c\u4f46\u9488\u5bf9\u63d0\u5347\u5e94\u8058\u8005\u4f53\u9a8c\u7684\u5b9e\u8df5\u5c1a\u7f3a\u4e4f\u7cfb\u7edf\u63a2\u8ba8\uff0c\u4e9f\u9700\u5b9e\u8bc1\u603b\u7ed3\u6210\u529f\u7ecf\u9a8c\u3002", "method": "\u91c7\u7528\u7533\u8bf7\u8005\u5f52\u56e0-\u53cd\u5e94\u7406\u8bba\u6307\u5bfc\uff0c\u8fdb\u884c\u4e8622\u6b21\u534a\u7ed3\u6784\u5316\u8bbf\u8c08\uff0c\u6536\u96c6\u5206\u6790\u8d85\u8fc7470\u6b21\u7ebf\u4e0a\u62db\u8058\u7ecf\u5386\uff0c\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u63d0\u70bc\u5efa\u8bbe\u6027\u6a21\u5f0f\u3002", "result": "\u672c\u8bba\u6587\u57fa\u4e8e\u65e9\u671f\u8f6f\u4ef6\u5de5\u7a0b\u5e08\u89c6\u89d2\uff0c\u901a\u8fc7\u8bbf\u8c08\u5206\u6790\u4e86\u5728\u7ebf\u62db\u8058\u9009\u62d4\u4e2d\u7684\u79ef\u6781\u5b9e\u8df5\uff0c\u603b\u7ed3\u51fa22\u79cd\u5efa\u8bbe\u6027\u6a21\u5f0f\uff08Constructive Patterns\uff09\u3002\u8fd9\u4e9b\u6a21\u5f0f\u5305\u62ec\u900f\u660e\u8be6\u5c3d\u7684\u804c\u4f4d\u63cf\u8ff0\u3001\u5177\u4f53\u53cd\u9988\u3001\u4eba\u6027\u5316\u4e92\u52a8\u7b49\uff0c\u65e8\u5728\u6539\u5584\u5e94\u8058\u8005\u4f53\u9a8c\u3002", "conclusion": "\u7814\u7a76\u6df1\u5316\u4e86\u6280\u672f\u62db\u8058\u9886\u57df\u5bf9\u79ef\u6781\u5019\u9009\u8005\u4f53\u9a8c\u7684\u7406\u89e3\uff0c\u63d0\u4f9b\u4e86\u5177\u4f53\u53ef\u884c\u7684\u5efa\u8bae\uff0c\u6709\u52a9\u4e8e\u8425\u9020\u4ee5\u4eba\u4e3a\u672c\u3001\u4fc3\u8fdb\u6210\u957f\u7684\u62db\u8058\u73af\u5883\u3002"}}
{"id": "2602.13540", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.13540", "abs": "https://arxiv.org/abs/2602.13540", "authors": ["Sin-Han Yang", "Cheng-Kuang Wu", "Chieh-Yen Lin", "Yun-Nung Chen", "Hung-yi Lee", "Shao-Hua Sun"], "title": "On Calibration of Large Language Models: From Response To Capability", "comment": "preprint", "summary": "Large language models (LLMs) are widely deployed as general-purpose problem solvers, making accurate confidence estimation critical for reliable use. Prior work on LLM calibration largely focuses on response-level confidence, which estimates the correctness of a single generated output. However, this formulation is misaligned with many practical settings where the central question is how likely a model is to solve a query overall. We show that this mismatch results from the stochastic nature of modern LLM decoding, under which single-response correctness fails to reflect underlying model capability. To address this issue, we introduce capability calibration, which targets the model's expected accuracy on a query. We formally distinguish capability calibration from response calibration and show that the two differ both theoretically and empirically. We establish an empirical evaluation setup and study a range of confidence estimation methods. Our results demonstrate that capability-calibrated confidence improves pass@$k$ prediction and inference budget allocation, establishing a foundation with potential for diverse applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u80fd\u529b\u6821\u51c6\u65b9\u6cd5\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u4f30\u8ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u67e5\u8be2\u65f6\u7684\u603b\u4f53\u89e3\u51b3\u80fd\u529b\uff0c\u63d0\u5347\u6a21\u578b\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u7684\u5b9e\u7528\u6027\u3002", "motivation": "\u4f20\u7edf\u54cd\u5e94\u7ea7\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\u4e0e\u5b9e\u9645\u5e94\u7528\u4e2d\u5173\u6ce8\u6a21\u578b\u6574\u4f53\u89e3\u51b3\u95ee\u9898\u80fd\u529b\u4e0d\u5339\u914d\uff0c\u9700\u63d0\u51fa\u66f4\u7b26\u5408\u5b9e\u9645\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u533a\u5206\u80fd\u529b\u6821\u51c6\u548c\u54cd\u5e94\u6821\u51c6\uff0c\u6784\u5efa\u5b9e\u8bc1\u8bc4\u4f30\u6846\u67b6\uff0c\u6bd4\u8f83\u591a\u79cd\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u80fd\u529b\u6821\u51c6\u7684\u6709\u6548\u6027\u3002", "result": "\u80fd\u529b\u6821\u51c6\u663e\u8457\u63d0\u5347\u4e86\u591a\u54cd\u5e94\u60c5\u51b5\u4e0b\u7684\u9884\u6d4b\u51c6\u786e\u7387\uff08pass@$k$\uff09\uff0c\u5e76\u4f18\u5316\u4e86\u63a8\u7406\u9884\u7b97\u5206\u914d\uff0c\u5177\u5907\u5e7f\u6cdb\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u80fd\u529b\u6821\u51c6\u533a\u522b\u4e8e\u4f20\u7edf\u7684\u54cd\u5e94\u7ea7\u6821\u51c6\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u53cd\u6620\u6a21\u578b\u5728\u67e5\u8be2\u4e0a\u7684\u6574\u4f53\u80fd\u529b\uff0c\u663e\u8457\u63d0\u5347\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u6548\u679c\u548c\u63a8\u7406\u8d44\u6e90\u5206\u914d\u6548\u7387\u3002"}}
{"id": "2602.13878", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2602.13878", "abs": "https://arxiv.org/abs/2602.13878", "authors": ["Martina Baiardi", "Samuele Burattini", "Giovanni Ciatto", "Danilo Pianini"], "title": "Testing BDI-based Multi-Agent Systems using Discrete Event Simulation", "comment": null, "summary": "Multi-agent systems are designed to deal with open, distributed systems with unpredictable dynamics, which makes them inherently hard to test. The value of using simulation for this purpose is recognized in the literature, although achieving sufficient fidelity (i.e., the degree of similarity between the simulation and the real-world system) remains a challenging task. This is exacerbated when dealing with cognitive agent models, such as the Belief Desire Intention (BDI) model, where the agent codebase is not suitable to run unchanged in simulation environments, thus increasing the reality gap between the deployed and simulated systems. We argue that BDI developers should be able to test in simulation the same specification that will be later deployed, with no surrogate representations. Thus, in this paper, we discuss how the control flow of BDI agents can be mapped onto a Discrete Event Simulation (DES), showing that such integration is possible at different degrees of granularity. We substantiate our claims by producing an open-source prototype integration between two pre-existing tools (JaKtA and Alchemist), showing that it is possible to produce a simulation-based testing environment for distributed BDI} agents, and that different granularities in mapping BDI agents over DESs may lead to different degrees of fidelity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u5c06BDI\u667a\u80fd\u4f53\u63a7\u5236\u6d41\u6620\u5c04\u5230\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\uff0c\u5b9e\u73b0\u771f\u5b9e\u89c4\u8303\u4e0b\u7684\u4eff\u771f\u6d4b\u8bd5\uff0c\u63d0\u5347\u4e86\u4eff\u771f\u4e0e\u73b0\u5b9e\u7cfb\u7edf\u7684\u5339\u914d\u5ea6\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5177\u6709\u5f00\u653e\u548c\u5206\u5e03\u5f0f\u7279\u70b9\uff0c\u4e14\u52a8\u6001\u4e0d\u53ef\u9884\u6d4b\uff0c\u5bfc\u81f4\u6d4b\u8bd5\u56f0\u96be\u3002\u7279\u522b\u662fBDI\u8ba4\u77e5\u667a\u80fd\u4f53\u6a21\u578b\uff0c\u5176\u4ee3\u7801\u5e93\u96be\u4ee5\u76f4\u63a5\u7528\u4e8e\u4eff\u771f\uff0c\u589e\u52a0\u4e86\u73b0\u5b9e\u4e0e\u4eff\u771f\u7cfb\u7edf\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u4f5c\u8005\u8ba4\u4e3aBDI\u5f00\u53d1\u8005\u5e94\u80fd\u5728\u4eff\u771f\u4e2d\u6d4b\u8bd5\u4e0e\u90e8\u7f72\u65f6\u76f8\u540c\u7684\u89c4\u8303\uff0c\u65e0\u9700\u66ff\u4ee3\u8868\u793a\u3002", "method": "\u901a\u8fc7\u5206\u6790BDI\u667a\u80fd\u4f53\u63a7\u5236\u6d41\uff0c\u5c06\u5176\u6620\u5c04\u5230\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u6846\u67b6\uff0c\u8bbe\u8ba1\u5e76\u5b9e\u73b0\u4e86\u5f00\u6e90\u96c6\u6210\u539f\u578b\uff08JaKtA\u4e0eAlchemist\uff09\uff0c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u6620\u5c04\u7c92\u5ea6\u5bf9\u4eff\u771f\u4fdd\u771f\u5ea6\u7684\u5f71\u54cd\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86BDI\u667a\u80fd\u4f53\u63a7\u5236\u6d41\u5982\u4f55\u6620\u5c04\u5230\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\uff08DES\uff09\uff0c\u5e76\u901a\u8fc7\u5f00\u6e90\u539f\u578b\u96c6\u6210\u5de5\u5177JaKtA\u548cAlchemist\u5b9e\u73b0\u4e86\u57fa\u4e8e\u4eff\u771f\u7684\u5206\u5e03\u5f0fBDI\u667a\u80fd\u4f53\u6d4b\u8bd5\u73af\u5883\uff0c\u4e14\u4e0d\u540c\u6620\u5c04\u7c92\u5ea6\u5bf9\u5e94\u4e0d\u540c\u7684\u4eff\u771f\u4fdd\u771f\u5ea6\u3002", "conclusion": "BDI\u667a\u80fd\u4f53\u53ef\u4ee5\u5728\u4e0d\u540c\u7c92\u5ea6\u4e0a\u96c6\u6210\u5230\u79bb\u6563\u4e8b\u4ef6\u4eff\u771f\u4e2d\uff0c\u652f\u6301\u57fa\u4e8e\u4eff\u771f\u7684\u6d4b\u8bd5\u73af\u5883\uff0c\u5e2e\u52a9\u7f29\u5c0f\u73b0\u5b9e\u4e0e\u4eff\u771f\u7cfb\u7edf\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.13851", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13851", "abs": "https://arxiv.org/abs/2602.13851", "authors": ["Arshad Beg", "Diarmuid O'Donoghue", "Rosemary Monahan"], "title": "Evaluating LLM-Generated ACSL Annotations for Formal Verification", "comment": "12 pages. Submitted to Formal Techniques for Judicious Programming FTfJP-2026 at ECOOP. Under review", "summary": "Formal specifications are crucial for building verifiable and dependable software systems, yet generating accurate and verifiable specifications for real-world C programs remains challenging. This paper empirically evaluates the extent to which formal-analysis tools can automatically generate and verify ACSL specifications without human or learning-based assistance. We conduct a controlled study on a recently released dataset of 506 C programs, repurposing it from interactive, developer-driven workflows to an automated evaluation setting. Five ACSL generation systems are compared: a rule-based Python script, Frama-C's RTE plugin, and three large language models--DeepSeek-V3.2, GPT-5.2, and OLMo 3.1 32B Instruct. All generated specifications are verified under identical conditions using the Frama-C WP plugin powered by multiple SMT solvers, allowing a direct comparison of annotation quality, solver sensitivity, and proof stability. Our results provide new empirical evidence on the capabilities and limitations of automated ACSL generation, complementing prior survey-based work.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1ACSL\u89c4\u683c\u7684\u5de5\u5177\u6027\u80fd\uff0c\u5bf9\u6bd4\u4e86\u4e94\u79cd\u751f\u6210\u7cfb\u7edf\u5728506\u4e2aC\u7a0b\u5e8f\u4e0a\u7684\u8868\u73b0\uff0c\u5206\u6790\u4e86\u6ce8\u91ca\u8d28\u91cf\u3001\u6c42\u89e3\u5668\u654f\u611f\u6027\u53ca\u8bc1\u660e\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u5b9eC\u7a0b\u5e8f\u7f3a\u4e4f\u51c6\u786e\u4e14\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u89c4\u683c\uff0c\u81ea\u52a8\u751f\u6210\u548c\u9a8c\u8bc1\u89c4\u683c\u5de5\u5177\u7684\u80fd\u529b\u5c1a\u4e0d\u6e05\u6670\uff0c\u9700\u5b9e\u8bc1\u8bc4\u4f30\u5176\u6709\u6548\u6027\u548c\u5c40\u9650\u6027\u3002", "method": "\u5229\u7528506\u4e2aC\u7a0b\u5e8f\u6570\u636e\u96c6\uff0c\u4f7f\u7528\u4e94\u79cd\u4e0d\u540c\u7684ACSL\u751f\u6210\u5de5\u5177\uff08\u5305\u542b\u89c4\u5219\u57fa\u811a\u672c\u3001Frama-C\u63d2\u4ef6\u548c\u4e09\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff09\u751f\u6210\u89c4\u683c\uff0c\u5e76\u7528Frama-C WP\u63d2\u4ef6\u53ca\u591a\u79cdSMT\u6c42\u89e3\u5668\u9a8c\u8bc1\u89c4\u683c\u8d28\u91cf\u3002", "result": "\u4e94\u79cd\u5de5\u5177\u751f\u6210\u7684\u89c4\u683c\u5728\u4e0d\u540c\u7a0b\u5e8f\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u660e\u663e\uff0c\u9a8c\u8bc1\u7ed3\u679c\u63ed\u793a\u4e86\u5f53\u524d\u81ea\u52a8\u5316ACSL\u751f\u6210\u6280\u672f\u7684\u80fd\u529b\u4e0a\u9650\u548c\u9002\u7528\u8303\u56f4\u3002", "conclusion": "\u81ea\u52a8\u751f\u6210ACSL\u89c4\u683c\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u53ef\u884c\uff0c\u4f46\u4ecd\u5b58\u5728\u6ce8\u91ca\u51c6\u786e\u6027\u548c\u9a8c\u8bc1\u7a33\u5b9a\u6027\u65b9\u9762\u7684\u5c40\u9650\u3002"}}
{"id": "2602.13551", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13551", "abs": "https://arxiv.org/abs/2602.13551", "authors": ["Yike Wang", "Faeze Brahman", "Shangbin Feng", "Teng Xiao", "Hannaneh Hajishirzi", "Yulia Tsvetkov"], "title": "Small Reward Models via Backward Inference", "comment": null, "summary": "Reward models (RMs) play a central role throughout the language model (LM) pipeline, particularly in non-verifiable domains. However, the dominant LLM-as-a-Judge paradigm relies on the strong reasoning capabilities of large models, while alternative approaches require reference responses or explicit rubrics, limiting flexibility and broader accessibility. In this work, we propose FLIP (FLipped Inference for Prompt reconstruction), a reference-free and rubric-free reward modeling approach that reformulates reward modeling through backward inference: inferring the instruction that would most plausibly produce a given response. The similarity between the inferred and the original instructions is then used as the reward signal. Evaluations across four domains using 13 small language models show that FLIP outperforms LLM-as-a-Judge baselines by an average of 79.6%. Moreover, FLIP substantially improves downstream performance in extrinsic evaluations under test-time scaling via parallel sampling and GRPO training. We further find that FLIP is particularly effective for longer outputs and robust to common forms of reward hacking. By explicitly exploiting the validation-generation gap, FLIP enables reliable reward modeling in downscaled regimes where judgment methods fail. Code available at https://github.com/yikee/FLIP.", "AI": {"tldr": "\u63d0\u51faFLIP\uff0c\u4e00\u79cd\u65e0\u53c2\u8003\u65e0\u8bc4\u5206\u6807\u51c6\u7684\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u9006\u5411\u63a8\u7406\u6307\u4ee4\u63d0\u5347\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5956\u52b1\u8bc4\u4f30\u6548\u679c\uff0c\u6027\u80fd\u8f83\u73b0\u6709\u65b9\u6cd5\u5927\u5e45\u63d0\u5347\u3002", "motivation": "\u73b0\u6709\u5956\u52b1\u6a21\u578b\u4f9d\u8d56\u5927\u578b\u6a21\u578b\u5f3a\u63a8\u7406\u80fd\u529b\u6216\u9700\u53c2\u8003\u7b54\u6848\u548c\u8bc4\u5206\u6807\u51c6\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u666e\u9002\u6027\uff0c\u672c\u6587\u65e8\u5728\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u53c2\u8003\u7b54\u6848\u548c\u8bc4\u5206\u6807\u51c6\u7684\u65b0\u578b\u5956\u52b1\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u9006\u5411\u63a8\u7406\u63a8\u65ad\u6700\u53ef\u80fd\u751f\u6210\u6307\u5b9a\u56de\u7b54\u7684\u6307\u4ee4\uff0c\u5c06\u63a8\u65ad\u6307\u4ee4\u4e0e\u539f\u59cb\u6307\u4ee4\u7684\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\uff0c\u5b9e\u73b0\u65e0\u53c2\u8003\u65e0\u8bc4\u5206\u6807\u51c6\u7684\u5956\u52b1\u5efa\u6a21\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86FLIP\uff08\u9006\u5411\u63a8\u7406\u63d0\u793a\u91cd\u6784\uff09\u65b9\u6cd5\uff0c\u9488\u5bf9\u5956\u52b1\u6a21\u578b\u5728\u65e0\u53c2\u8003\u3001\u65e0\u8bc4\u5206\u6807\u51c6\u60c5\u51b5\u4e0b\u7684\u6784\u5efa\u95ee\u9898\uff0c\u901a\u8fc7\u63a8\u65ad\u6700\u53ef\u80fd\u4ea7\u751f\u7ed9\u5b9a\u56de\u590d\u7684\u6307\u4ee4\uff0c\u5e76\u5229\u7528\u63a8\u65ad\u6307\u4ee4\u4e0e\u539f\u59cb\u6307\u4ee4\u7684\u76f8\u4f3c\u5ea6\u4f5c\u4e3a\u5956\u52b1\u4fe1\u53f7\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cFLIP\u5728\u591a\u4e2a\u9886\u57df\u548c13\u4e2a\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\uff0c\u6027\u80fd\u6bd4\u4f20\u7edf\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bc4\u5206\u65b9\u6cd5\u63d0\u5347\u7ea679.6%\uff0c\u4e14\u5bf9\u957f\u8f93\u51fa\u66f4\u6709\u6548\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u6297\u4f5c\u5f0a\u80fd\u529b\u3002\u5176\u901a\u8fc7\u5229\u7528\u9a8c\u8bc1\u751f\u6210\u5dee\u8ddd\uff0c\u5b9e\u73b0\u4e86\u5728\u5c0f\u89c4\u6a21\u6a21\u578b\u4e2d\u53ef\u9760\u7684\u5956\u52b1\u5efa\u6a21\u3002", "conclusion": "FLIP\u6709\u6548\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5c24\u5176\u5728\u5c0f\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u548c\u957f\u6587\u672c\u751f\u6210\u573a\u666f\u8868\u73b0\u51fa\u4f18\u52bf\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u8bc4\u4ef7\u65b9\u6cd5\u53d7\u9650\u7684\u95ee\u9898\u3002"}}
{"id": "2602.14471", "categories": ["cs.MA", "cs.AI", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14471", "abs": "https://arxiv.org/abs/2602.14471", "authors": ["Furkan Mumcu", "Yasin Yilmaz"], "title": "Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems", "comment": null, "summary": "Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA), a game-theoretic framework that modifies inference-time decision making by interpolating between an agent's private objective and an estimate of group welfare via a social weight $\u03bb\\in[0,1]$. In a shared-resource congestion game with $n$ agents and congestion severity $\u03b2$, we show that SWA induces a critical threshold $\u03bb^*=(n-\u03b2)/(n-1)$ above which agents no longer have marginal incentive to increase demand under overload, yielding a phase transition from persistent congestion to stable operation near capacity. We further provide an inference-time algorithmic instantiation of SWA that does not require parameter updates or multi-agent reinforcement learning, and use a multi-agent simulation to empirically validate the predicted threshold behavior.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u793e\u4f1a\u52a0\u6743\u5bf9\u9f50\u6846\u67b6\uff0c\u901a\u8fc7\u8c03\u6574\u4e2a\u4f53\u51b3\u7b56\u6743\u91cd\uff0c\u5b9e\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5171\u4eab\u73af\u5883\u4e2d\u7684\u7a33\u5b9a\u9ad8\u6548\u8fd0\u884c\u3002", "motivation": "\u89e3\u51b3\u5728\u5171\u4eab\u8d44\u6e90\u62e5\u6324\u6e38\u620f\u4e2d\uff0c\u4e2a\u4f53\u7406\u6027\u7684\u51b3\u7b56\u884c\u4e3a\u4f1a\u5bfc\u81f4\u7cfb\u7edf\u62e5\u5835\u548c\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e2a\u4f53\u4e0e\u96c6\u4f53\u5229\u76ca\u7684\u5e73\u8861\u3002", "method": "\u57fa\u4e8e\u535a\u5f08\u8bba\u63d0\u51faSWA\u6846\u67b6\uff0c\u901a\u8fc7\u793e\u4ea4\u6743\u91cd\u03bb\u8c03\u6574\u4ee3\u7406\u5728\u63a8\u7406\u65f6\u7684\u51b3\u7b56\uff0c\u4f7f\u5176\u5728\u79c1\u4eba\u76ee\u6807\u4e0e\u7fa4\u4f53\u798f\u5229\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\uff1b\u8bbe\u8ba1\u4e86\u65e0\u9700\u53c2\u6570\u66f4\u65b0\u6216\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u63a8\u7406\u65f6\u7b97\u6cd5\u5b9e\u73b0\u8be5\u6846\u67b6\u3002", "result": "\u8bc1\u660e\u4e86\u5b58\u5728\u4e34\u754c\u9608\u503c\u03bb*\uff0c\u8d85\u8fc7\u8be5\u9608\u503c\u540e\u4ee3\u7406\u5728\u8fc7\u8f7d\u60c5\u51b5\u4e0b\u4e0d\u518d\u589e\u52a0\u9700\u6c42\uff0c\u4ece\u800c\u5b9e\u73b0\u4ece\u6301\u7eed\u62e5\u5835\u5411\u7a33\u5b9a\u8fd0\u884c\u7684\u76f8\u53d8\uff1b\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u4eff\u771f\u5b9e\u9a8c\u8bc1\u4e86\u8be5\u9608\u503c\u884c\u4e3a\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u793e\u4f1a\u52a0\u6743\u5bf9\u9f50\uff08SWA\uff09\u6846\u67b6\uff0c\u80fd\u591f\u89e3\u51b3\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u5171\u4eab\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u4e2a\u4f53\u7406\u6027\u4e0e\u96c6\u4f53\u7a33\u5b9a\u6027\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u5b9e\u73b0\u7cfb\u7edf\u7ea7\u6027\u80fd\u7684\u63d0\u5347\u3002"}}
{"id": "2602.13962", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13962", "abs": "https://arxiv.org/abs/2602.13962", "authors": ["Yunkun Wang", "Xuanhe Zhang", "Junxiao Han", "Chen Zhi", "Shuiguang Deng"], "title": "CodeGlance: Understanding Code Reasoning Challenges in LLMs through Multi-Dimensional Feature Analysis", "comment": null, "summary": "In modern software development, developers frequently need to understand code behavior at a glance -- whether reviewing pull requests, debugging issues, or navigating unfamiliar codebases. This ability to reason about dynamic program behavior is fundamental to effective software engineering and increasingly supported by Large Language Models (LLMs). However, existing studies on code reasoning focus primarily on isolated code snippets, overlooking the complexity of real-world scenarios involving external API interactions and unfamiliar functions. This gap hinders our understanding of what truly makes code reasoning challenging for LLMs across diverse programming contexts.\n  We present CodeGlance, a multi-dimensional benchmark investigating code reasoning challenges across three realistic scenarios: intrinsic logic reasoning, API interaction reasoning, and unseen function reasoning. Through systematic evaluation of 7 state-of-the-art LLMs, we reveal that unseen function reasoning poses significant challenges especially for smaller models, with Qwen2.5-3b achieving only 6.0\\% accuracy on unseen functions compared to 37.5\\% on familiar APIs. We identify critical code complexity features -- including execution trace length, API invocation count, and control flow complexity -- that significantly impact code reasoning difficulty across scenarios. We further investigate how common augmentation strategies, including CoT, document retrieval, and code search, can improve reasoning performance, finding that their effectiveness varies substantially depending on whether challenges stem from logical complexity or knowledge gaps. These findings provide actionable guidance for developing more capable code reasoning systems and deploying LLM-based programming assistants in real-world software development.", "AI": {"tldr": "\u63d0\u51faCodeGlance\u591a\u7ef4\u57fa\u51c6\uff0c\u7cfb\u7edf\u5206\u6790LLM\u4ee3\u7801\u63a8\u7406\u5728\u591a\u573a\u666f\u4e0b\u7684\u6311\u6218\u4e0e\u5173\u952e\u56e0\u7d20\uff0c\u63a2\u7d22\u589e\u5f3a\u7b56\u7565\u6548\u679c\uff0c\u6307\u5bfc\u66f4\u5f3a\u4ee3\u7801\u63a8\u7406\u7cfb\u7edf\u6784\u5efa\u3002", "motivation": "\u73b0\u6709\u4ee3\u7801\u63a8\u7406\u7814\u7a76\u591a\u805a\u7126\u5b64\u7acb\u4ee3\u7801\u6bb5\uff0c\u5ffd\u89c6\u4e86\u6d89\u53ca\u5916\u90e8API\u548c\u672a\u89c1\u51fd\u6570\u7684\u590d\u6742\u771f\u5b9e\u573a\u666f\uff0c\u7f3a\u4e4f\u5bf9\u4ee3\u7801\u63a8\u7406\u6311\u6218\u7684\u5168\u8c8c\u7406\u89e3\u3002", "method": "\u8bbe\u8ba1\u4e86CodeGlance\u57fa\u51c6\uff0c\u6db5\u76d6\u5185\u5728\u903b\u8f91\u63a8\u7406\u3001API\u4ea4\u4e92\u63a8\u7406\u548c\u672a\u89c1\u51fd\u6570\u63a8\u7406\u4e09\u4e2a\u73b0\u5b9e\u573a\u666f\uff0c\u7cfb\u7edf\u8bc4\u4f307\u4e2a\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7801\u63a8\u7406\u80fd\u529b\u3002", "result": "\u53d1\u73b0\u672a\u89c1\u51fd\u6570\u63a8\u7406\u5bf9\u5c0f\u6a21\u578b\u5c24\u5176\u5177\u6709\u6311\u6218\u6027\uff0cQwen2.5-3b\u5728\u672a\u89c1\u51fd\u6570\u4e0a\u51c6\u786e\u7387\u4ec56.0%\uff0c\u800c\u719f\u6089API\u4e3a37.5%\u3002\u786e\u7acb\u4e86\u6267\u884c\u8f68\u8ff9\u957f\u5ea6\u3001API\u8c03\u7528\u6b21\u6570\u548c\u63a7\u5236\u6d41\u590d\u6742\u5ea6\u7b49\u5f71\u54cd\u63a8\u7406\u96be\u5ea6\u7684\u5173\u952e\u7279\u5f81\u3002\u4e0d\u540c\u589e\u5f3a\u7b56\u7565\uff08\u94fe\u5f0f\u601d\u7ef4\u3001\u6587\u6863\u68c0\u7d22\u3001\u4ee3\u7801\u641c\u7d22\uff09\u5728\u4e0d\u540c\u6311\u6218\u4e0b\u6548\u679c\u5dee\u5f02\u663e\u8457\u3002", "conclusion": "\u672c\u7814\u7a76\u63ed\u793a\u4e86\u4ee3\u7801\u63a8\u7406\u4e2d\u672a\u89c1\u51fd\u6570\u63a8\u7406\u7684\u663e\u8457\u96be\u5ea6\u53ca\u5f71\u54cd\u56e0\u7d20\uff0c\u5f3a\u8c03\u9488\u5bf9\u4e0d\u540c\u63a8\u7406\u96be\u70b9\u9009\u62e9\u5408\u9002\u589e\u5f3a\u7b56\u7565\uff0c\u63a8\u52a8LLM\u5728\u5b9e\u9645\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u66f4\u6709\u6548\u5e94\u7528\u3002"}}
{"id": "2602.13567", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13567", "abs": "https://arxiv.org/abs/2602.13567", "authors": ["Manish Dhakal", "Uthman Jinadu", "Anjila Budathoki", "Rajshekhar Sunderraman", "Yi Ding"], "title": "DistillLens: Symmetric Knowledge Distillation Through Logit Lens", "comment": "Knowledge Distillation in LLMs", "summary": "Standard Knowledge Distillation (KD) compresses Large Language Models (LLMs) by optimizing final outputs, yet it typically treats the teacher's intermediate layer's thought process as a black box. While feature-based distillation attempts to bridge this gap, existing methods (e.g., MSE and asymmetric KL divergence) ignore the rich uncertainty profiles required for the final output. In this paper, we introduce DistillLens, a framework that symmetrically aligns the evolving thought processes of student and teacher models. By projecting intermediate hidden states into the vocabulary space via the Logit Lens, we enforce structural alignment using a symmetric divergence objective. Our analysis proves that this constraint imposes a dual-sided penalty, preventing both overconfidence and underconfidence while preserving the high-entropy information conduits essential for final deduction. Extensive experiments on GPT-2 and Llama architectures demonstrate that DistillLens consistently outperforms standard KD and feature-transfer baselines on diverse instruction-following benchmarks. The code is available at https://github.com/manishdhakal/DistillLens.", "AI": {"tldr": "DistillLens\u901a\u8fc7\u5bf9\u79f0\u5bf9\u9f50\u6559\u5e08\u4e0e\u5b66\u751f\u6a21\u578b\u7684\u4e2d\u95f4\u8868\u793a\uff0c\u63d0\u9ad8\u4e86\u77e5\u8bc6\u84b8\u998f\u6548\u679c\uff0c\u8fdc\u8d85\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u77e5\u8bc6\u84b8\u998f\u591a\u5173\u6ce8\u6700\u7ec8\u8f93\u51fa\uff0c\u5ffd\u89c6\u4e86\u6559\u5e08\u6a21\u578b\u4e2d\u95f4\u5c42\u7684\u601d\u8003\u8fc7\u7a0b\uff0c\u4e14\u73b0\u6709\u7279\u5f81\u84b8\u998f\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5229\u7528\u4e2d\u95f4\u5c42\u7684\u4e0d\u786e\u5b9a\u6027\u4fe1\u606f\uff0c\u9700\u8bbe\u8ba1\u65b0\u7684\u673a\u5236\u66f4\u597d\u5730\u6355\u83b7\u548c\u4f20\u9012\u6559\u5e08\u6a21\u578b\u7684\u4e30\u5bcc\u4fe1\u606f\u3002", "method": "\u901a\u8fc7Logit Lens\u5c06\u4e2d\u95f4\u9690\u85cf\u72b6\u6001\u6295\u5f71\u5230\u8bcd\u6c47\u7a7a\u95f4\uff0c\u4f7f\u7528\u5bf9\u79f0\u6563\u5ea6\u76ee\u6807\u51fd\u6570\u5bf9\u6559\u5e08\u548c\u5b66\u751f\u6a21\u578b\u7684\u4e2d\u95f4\u5c42\u8f93\u51fa\u8fdb\u884c\u7ed3\u6784\u5bf9\u9f50\uff0c\u907f\u514d\u8fc7\u5ea6\u6216\u4e0d\u8db3\u81ea\u4fe1\uff0c\u4fdd\u6301\u4fe1\u606f\u9ad8\u71b5\u4f20\u9012\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86DistillLens\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u9f50\u6559\u5e08\u6a21\u578b\u548c\u5b66\u751f\u6a21\u578b\u7684\u4e2d\u95f4\u601d\u8003\u8fc7\u7a0b\u6765\u6539\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\u3002\u8be5\u65b9\u6cd5\u7ed3\u5408\u4e86Logit Lens\u6280\u672f\uff0c\u5c06\u9690\u85cf\u72b6\u6001\u6620\u5c04\u5230\u8bcd\u6c47\u7a7a\u95f4\uff0c\u5e76\u91c7\u7528\u5bf9\u79f0\u6563\u5ea6\u76ee\u6807\u5b9e\u73b0\u7ed3\u6784\u5bf9\u9f50\uff0c\u6709\u6548\u9632\u6b62\u6a21\u578b\u8fc7\u5ea6\u81ea\u4fe1\u6216\u81ea\u4fe1\u4e0d\u8db3\uff0c\u4fdd\u6301\u5173\u952e\u4fe1\u606f\u7684\u4f20\u9012\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cDistillLens\u5728GPT-2\u548cLlama\u6a21\u578b\u4e0a\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684\u77e5\u8bc6\u84b8\u998f\u548c\u7279\u5f81\u4f20\u9012\u65b9\u6cd5\u3002", "conclusion": "DistillLens\u6846\u67b6\u901a\u8fc7\u5bf9\u79f0\u6563\u5ea6\u7ea6\u675f\uff0c\u5b9e\u73b0\u4e86\u5b66\u751f\u548c\u6559\u5e08\u6a21\u578b\u4e2d\u95f4\u5c42\u8868\u793a\u7684\u7ed3\u6784\u5bf9\u9f50\uff0c\u6539\u5584\u4e86\u84b8\u998f\u8fc7\u7a0b\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u8868\u8fbe\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.14606", "categories": ["cs.MA", "cs.AI", "cs.CE"], "pdf": "https://arxiv.org/pdf/2602.14606", "abs": "https://arxiv.org/abs/2602.14606", "authors": ["Jose Manuel de la Chica Rodriguez", "Juan Manuel Vera D\u00edaz"], "title": "Towards Selection as Power: Bounding Decision Authority in Autonomous Agents", "comment": null, "summary": "Autonomous agentic systems are increasingly deployed in regulated, high-stakes domains where decisions may be irreversible and institutionally constrained. Existing safety approaches emphasize alignment, interpretability, or action-level filtering. We argue that these mechanisms are necessary but insufficient because they do not directly govern selection power: the authority to determine which options are generated, surfaced, and framed for decision. We propose a governance architecture that separates cognition, selection, and action into distinct domains and models autonomy as a vector of sovereignty. Cognitive autonomy remains unconstrained, while selection and action autonomy are bounded through mechanically enforced primitives operating outside the agent's optimization space. The architecture integrates external candidate generation (CEFL), a governed reducer, commit-reveal entropy isolation, rationale validation, and fail-loud circuit breakers. We evaluate the system across multiple regulated financial scenarios under adversarial stress targeting variance manipulation, threshold gaming, framing skew, ordering effects, and entropy probing. Metrics quantify selection concentration, narrative diversity, governance activation cost, and failure visibility. Results show that mechanical selection governance is implementable, auditable, and prevents deterministic outcome capture while preserving reasoning capacity. Although probabilistic concentration remains, the architecture measurably bounds selection authority relative to conventional scalar pipelines. This work reframes governance as bounded causal power rather than internal intent alignment, offering a foundation for deploying autonomous agents where silent failure is unacceptable.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5c06\u8ba4\u77e5\u3001\u9009\u62e9\u548c\u884c\u4e3a\u72ec\u7acb\u6cbb\u7406\u7684\u67b6\u6784\uff0c\u901a\u8fc7\u673a\u68b0\u624b\u6bb5\u9650\u5236\u9009\u62e9\u6743\u529b\uff0c\u5b9e\u73b0\u81ea\u6cbb\u7cfb\u7edf\u7684\u5b89\u5168\u6cbb\u7406\uff0c\u4fdd\u969c\u5176\u5728\u9ad8\u98ce\u9669\u9886\u57df\u7684\u7a33\u5b9a\u53ef\u9760\u8fd0\u884c\u3002", "motivation": "\u5f53\u524d\u81ea\u6cbb\u667a\u80fd\u7cfb\u7edf\u5728\u9ad8\u98ce\u9669\u3001\u53d7\u76d1\u7ba1\u9886\u57df\u7684\u5e94\u7528\u589e\u591a\uff0c\u4f20\u7edf\u7684\u5b89\u5168\u65b9\u6cd5\u4fa7\u91cd\u5bf9\u9f50\u3001\u53ef\u89e3\u91ca\u6027\u6216\u884c\u4e3a\u8fc7\u6ee4\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u8db3\u4ee5\u76f4\u63a5\u7ba1\u7406\u51b3\u7b56\u9009\u9879\u7684\u751f\u6210\u4e0e\u7b5b\u9009\u6743\u529b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u6cbb\u7406\u67b6\u6784\uff0c\u5c06\u8ba4\u77e5\u3001\u9009\u62e9\u548c\u884c\u4e3a\u5206\u79bb\uff0c\u5206\u522b\u754c\u5b9a\u81ea\u4e3b\u6743\uff0c\u5e76\u901a\u8fc7\u5916\u90e8\u673a\u68b0\u673a\u5236\u9650\u5236\u9009\u62e9\u548c\u884c\u4e3a\u81ea\u4e3b\u6743\uff0c\u5305\u542b\u5019\u9009\u751f\u6210\u3001\u53d7\u63a7\u538b\u7f29\u5668\u3001\u71b5\u9694\u79bb\u3001\u7406\u7531\u9a8c\u8bc1\u548c\u5931\u8d25\u62a5\u8b66\u7b49\u673a\u5236\u3002", "result": "\u7cfb\u7edf\u5728\u591a\u79cd\u91d1\u878d\u76d1\u7ba1\u573a\u666f\u4e0b\u53cd\u590d\u9a8c\u8bc1\uff0c\u80fd\u6709\u6548\u9632\u6b62\u786e\u5b9a\u6027\u7ed3\u679c\u5784\u65ad\uff0c\u4fdd\u969c\u63a8\u7406\u80fd\u529b\uff0c\u540c\u65f6\u964d\u4f4e\u9009\u62e9\u6743\u529b\u7684\u96c6\u4e2d\u5ea6\uff0c\u5b9e\u73b0\u673a\u68b0\u5316\u6cbb\u7406\u5e76\u4e14\u6613\u4e8e\u5ba1\u8ba1\u3002", "conclusion": "\u6cbb\u7406\u5e94\u88ab\u89c6\u4e3a\u6709\u754c\u56e0\u679c\u6743\u529b\u800c\u975e\u5185\u90e8\u610f\u56fe\u5bf9\u9f50\uff0c\u8be5\u67b6\u6784\u4e3a\u5728\u4e0d\u53ef\u5bb9\u5fcd\u65e0\u58f0\u5931\u8d25\u7684\u9886\u57df\u90e8\u7f72\u81ea\u6cbb\u667a\u80fd\u4ee3\u7406\u63d0\u4f9b\u4e86\u7406\u8bba\u548c\u5b9e\u8df5\u57fa\u7840\u3002"}}
{"id": "2602.13987", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.13987", "abs": "https://arxiv.org/abs/2602.13987", "authors": ["Zhengyu Zhan", "Ye Shang", "Jiawei Liu", "Chunrong Fang", "Quanjun Zhang", "Zhenyu Chen"], "title": "ATTest: Agent-Driven Tensor Testing for Deep Learning Library Modules", "comment": "5 pages, 3 figures", "summary": "The unit testing of Deep Learning (DL) libraries is challenging due to complex numerical semantics and implicit tensor constraints. Traditional Search-Based Software Testing (SBST) often suffers from semantic blindness, failing to satisfy the constraints of high-dimensional tensors, whereas Large Language Models (LLMs) struggle with cross-file context and unstable code modifications. This paper proposes ATTest, an agent-driven tensor testing framework for module-level unit test generation. ATTest orchestrates a seven-stage pipeline, which encompasses constraint extraction and an iterative \"generation-validation-repair\" loop, to maintain testing stability and mitigate context-window saturation. An evaluation on PyTorch and TensorFlow demonstrates that ATTest significantly outperforms state-of-the-art baselines such as PynguinML, achieving an average branch coverage of 55.60% and 54.77%, respectively. The results illustrate how agent-driven workflows bridge the semantic gap in numerical libraries while ensuring auditable test synthesis. Source code: https://github.com/iSEngLab/ATTest.git", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u5e93\u5355\u5143\u6d4b\u8bd5\u96be\u9898\uff0c\u63d0\u51fa\u4e86\u667a\u80fd\u4f53\u9a71\u52a8\u7684ATTest\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u6d41\u7a0b\u548c\u8fed\u4ee3\u4fee\u590d\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u5e93\u7684\u5355\u5143\u6d4b\u8bd5\u9762\u4e34\u590d\u6742\u6570\u503c\u8bed\u4e49\u548c\u9690\u5f0f\u5f20\u91cf\u7ea6\u675f\uff0c\u4f20\u7edf\u57fa\u4e8e\u641c\u7d22\u7684\u8f6f\u4ef6\u6d4b\u8bd5\u548c\u5927\u8bed\u8a00\u6a21\u578b\u5747\u5b58\u5728\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u6311\u6218\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u4e03\u9636\u6bb5\u6d41\u6c34\u7ebf\u6d4b\u8bd5\u6846\u67b6ATTest\uff0c\u5305\u62ec\u7ea6\u675f\u63d0\u53d6\u548c\u8fed\u4ee3\u7684\u201c\u751f\u6210-\u9a8c\u8bc1-\u4fee\u590d\u201d\u5faa\u73af\uff0c\u4fdd\u8bc1\u6d4b\u8bd5\u7684\u7a33\u5b9a\u6027\u5e76\u51cf\u8f7b\u4e0a\u4e0b\u6587\u7a97\u53e3\u9971\u548c\u3002", "result": "\u5728PyTorch\u548cTensorFlow\u4e0a\u7684\u8bc4\u6d4b\u663e\u793a\uff0cATTest\u5e73\u5747\u5206\u652f\u8986\u76d6\u7387\u5206\u522b\u8fbe\u5230\u4e8655.60%\u548c54.77%\uff0c\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u9886\u5148\u57fa\u7ebf\u65b9\u6cd5PynguinML\u3002", "conclusion": "ATTest\u663e\u8457\u63d0\u5347\u4e86\u6df1\u5ea6\u5b66\u4e60\u5e93\u6a21\u5757\u7ea7\u5355\u5143\u6d4b\u8bd5\u7684\u8986\u76d6\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u8bed\u4e49\u7406\u89e3\u548c\u5f20\u91cf\u7ea6\u675f\u5904\u7406\u4e0a\u7684\u4e0d\u8db3\u3002"}}
{"id": "2602.13571", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13571", "abs": "https://arxiv.org/abs/2602.13571", "authors": ["Zhipeng Song", "Xiangyu Kong", "Xinrui Bao", "Yizhi Zhou", "Jiulong Jiao", "Sitong Liu", "Yuhang Zhou", "Heng Qi"], "title": "LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems", "comment": "Published by ESWA", "summary": "Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals. We propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm that enhances reranking in RAG systems by leveraging black-box LLM confidence derived from Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process: confidence assessment via multinomial sampling and clustering, followed by binning and multi-level sorting based on query and document confidence thresholds. This approach prioritizes relevant documents while preserving original rankings for high-confidence queries, ensuring robustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers, LCR--using only 7--9B-parameter pre-trained LLMs--consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation. Ablation studies validate the hypothesis that LLM confidence positively correlates with document relevance, elucidating LCR's mechanism. LCR offers computational efficiency, parallelism for scalability, and broad compatibility, mitigating hallucinations in applications like medical diagnosis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f6e\u4fe1\u5ea6\u7684\u65e0\u8bad\u7ec3\u6587\u6863\u91cd\u6392\u5e8f\u7b97\u6cd5LCR\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u6027\u80fd\uff0c\u964d\u4f4e\u751f\u6210\u5e7b\u89c9\uff0c\u6548\u7387\u9ad8\u4e14\u6613\u90e8\u7f72\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u77e5\u8bc6\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\u6613\u4ea7\u751f\u5e7b\u89c9\uff0c\u5f71\u54cd\u5e94\u7528\u6548\u679c\u3002\u73b0\u6709\u7684\u91cd\u6392\u5e8f\u65b9\u6cd5\u6548\u679c\u867d\u597d\u4f46\u5b58\u5728\u9ad8\u8ba1\u7b97\u6210\u672c\u548c\u8bad\u7ec3\u9700\u6c42\uff0c\u4e14\u672a\u5145\u5206\u5229\u7528LLM\u7684\u5185\u5728\u7f6e\u4fe1\u5ea6\u4fe1\u606f\u3002", "method": "\u63d0\u51faLLM-Confidence Reranker (LCR)\uff0c\u4e00\u79cd\u65e0\u8bad\u7ec3\u3001\u5373\u63d2\u5373\u7528\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u6700\u5927\u8bed\u4e49\u7c07\u6bd4\u4f8b\uff08MSCP\uff09\u4ece\u9ed1\u76d2LLM\u4e2d\u83b7\u53d6\u7f6e\u4fe1\u5ea6\uff0c\u91c7\u7528\u591a\u9879\u5f0f\u91c7\u6837\u548c\u805a\u7c7b\u8fdb\u884c\u7f6e\u4fe1\u5ea6\u8bc4\u4f30\uff0c\u518d\u4f9d\u636e\u7f6e\u4fe1\u5ea6\u9608\u503c\u8fdb\u884c\u5206\u5c42\u6392\u5e8f\uff0c\u4f18\u5316\u6587\u6863\u91cd\u6392\u5e8f\u3002", "result": "\u5728BEIR\u548cTREC\u57fa\u51c6\u4e0a\uff0cLCR\u4f7f\u75287-9B\u53c2\u6570\u9884\u8bad\u7ec3\u6a21\u578b\uff0c\u63d0\u5347\u5e38\u89c1\u6307\u6807NDCG@5\u8fbe20.6%\uff0c\u4e14\u9002\u914d\u591a\u79cd\u9884\u8bad\u7ec3\u53ca\u5fae\u8c03\u6a21\u578b\uff0c\u65e0\u6027\u80fd\u4e0b\u964d\u3002\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86LLM\u7f6e\u4fe1\u5ea6\u4e0e\u6587\u6863\u76f8\u5173\u6027\u7684\u6b63\u76f8\u5173\u6027\uff0c\u89e3\u91ca\u4e86LCR\u7684\u6709\u6548\u6027\u3002", "conclusion": "LCR\u65b9\u6cd5\u6781\u5927\u63d0\u5347\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7cfb\u7edf\u7684\u6587\u6863\u91cd\u6392\u5e8f\u6548\u679c\uff0c\u5177\u5907\u8ba1\u7b97\u6548\u7387\u9ad8\u3001\u53ef\u6269\u5c55\u6027\u5f3a\u53ca\u5e7f\u6cdb\u517c\u5bb9\u6027\uff0c\u4e3a\u51cf\u5c11\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\uff0c\u7279\u522b\u9002\u7528\u4e8e\u533b\u7597\u8bca\u65ad\u7b49\u91cd\u8981\u5e94\u7528\u9886\u57df\u3002"}}
{"id": "2602.14681", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14681", "abs": "https://arxiv.org/abs/2602.14681", "authors": ["Xingjian Wu", "Xvyuan Liu", "Junkai Lu", "Siyuan Wang", "Yang Shu", "Jilin Hu", "Chenjuan Guo", "Bin Yang"], "title": "ST-EVO: Towards Generative Spatio-Temporal Evolution of Multi-Agent Communication Topologies", "comment": null, "summary": "LLM-powered Multi-Agent Systems (MAS) have emerged as an effective approach towards collaborative intelligence, and have attracted wide research interests. Among them, ``self-evolving'' MAS, treated as a more flexible and powerful technical route, can construct task-adaptive workflows or communication topologies, instead of relying on a predefined static structue template. Current self-evolving MAS mainly focus on Spatial Evolving or Temporal Evolving paradigm, which only considers the single dimension of evolution and does not fully incentivize LLMs' collaborative capability. In this work, we start from a novel Spatio-Temporal perspective by proposing ST-EVO, which supports dialogue-wise communication scheduling with a compact yet powerful flow-matching based Scheduler. To make precise Spatio-Temporal scheduling, ST-EVO can also perceive the uncertainty of MAS, and possesses self-feedback ability to learn from accumulated experience. Extensive experiments on nine benchmarks demonstrate the state-of-the-art performance of ST-EVO, achieving about 5%--25% accuracy improvement.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684ST-EVO\u901a\u8fc7\u65f6\u7a7a\u8c03\u5ea6\u548c\u81ea\u53cd\u9988\u673a\u5236\u63d0\u5347\u4e86LLM\u9a71\u52a8\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u4f5c\u6548\u7387\u548c\u51c6\u786e\u7387\u3002", "motivation": "\u5f53\u524d\u81ea\u6211\u8fdb\u5316\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff08MAS\uff09\u4ec5\u5173\u6ce8\u7a7a\u95f4\u6216\u65f6\u95f4\u5355\u4e00\u7ef4\u5ea6\u7684\u6f14\u5316\uff0c\u672a\u80fd\u5145\u5206\u6fc0\u53d1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u534f\u4f5c\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u65f6\u7a7a\u89c6\u89d2\u7684ST-EVO\u7cfb\u7edf\uff0c\u91c7\u7528\u57fa\u4e8e\u6d41\u7a0b\u5339\u914d\u7684\u8c03\u5ea6\u5668\u652f\u6301\u5bf9\u8bdd\u5f0f\u901a\u4fe1\u8c03\u5ea6\uff0c\u5177\u5907\u611f\u77e5\u4e0d\u786e\u5b9a\u6027\u548c\u81ea\u6211\u53cd\u9988\u5b66\u4e60\u80fd\u529b\u3002", "result": "ST-EVO\u5728\u4e5d\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u9886\u5148\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u7ea65%-25%\u7684\u51c6\u786e\u7387\u63d0\u5347\u3002", "conclusion": "\u5229\u7528\u65f6\u7a7a\u7efc\u5408\u8c03\u5ea6\u4e0e\u81ea\u6211\u53cd\u9988\uff0cST-EVO\u663e\u8457\u589e\u5f3a\u4e86MAS\u7684\u4efb\u52a1\u9002\u5e94\u6027\u548c\u6027\u80fd\u8868\u73b0\uff0c\u63a8\u52a8\u4e86LLM\u591a\u667a\u80fd\u4f53\u534f\u540c\u667a\u80fd\u7684\u53d1\u5c55\u3002"}}
{"id": "2602.14046", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14046", "abs": "https://arxiv.org/abs/2602.14046", "authors": ["Zirui Chen", "Xing Hu", "Xin Xia", "Xiaohu Yang"], "title": "Every Maintenance Has Its Exemplar: The Future of Software Maintenance through Migration", "comment": "Accepted to ACM Transactions on Software Engineering and Methodology (TOSEM)", "summary": "Maintenance is a critical stage in the software lifecycle, ensuring that post-release systems remain reliable, efficient, and adaptable. However, manual software maintenance is labor-intensive, time-consuming, and error-prone, which highlights the urgent need for automation. Learning from maintenance activities conducted on other software systems offers an effective way to improve efficiency. In particular, recent research has demonstrated that migration-based approaches transfer knowledge, artifacts, or solutions from one system to another and show strong potential in tasks such as API evolution adaptation, software testing, and migrating patches for fault correction. This makes migration-based maintenance a valuable research direction for advancing automated maintenance.\n  This paper takes a step further by presenting the first systematic research agenda on migration-based approaches to software maintenance. We characterize the migration-based maintenance lifecycle through four key stages: \\ding{182} identifying a maintenance task that can be addressed through migration, \\ding{183} selecting suitable migration sources for the target project,\\ding{184} matching relevant data across systems and adapting the migrated data to the target context, and \\ding{185} validating the correctness of the migration. We also analyze the challenges that may arise at each stage. Our goal is to encourage the community to explore migration-based approaches more thoroughly and to tackle the key challenges that must be solved to advance automated software maintenance.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u63d0\u51fa\u57fa\u4e8e\u8fc1\u79fb\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u7ef4\u62a4\u6846\u67b6\uff0c\u5305\u542b\u56db\u9636\u6bb5\u751f\u547d\u5468\u671f\u53ca\u5173\u952e\u6311\u6218\uff0c\u4e3a\u63d0\u9ad8\u7ef4\u62a4\u6548\u7387\u548c\u81ea\u52a8\u5316\u63d0\u4f9b\u65b9\u5411\u3002", "motivation": "\u8f6f\u4ef6\u7ef4\u62a4\u7e41\u7410\u4e14\u6613\u9519\uff0c\u81ea\u52a8\u5316\u8feb\u5207\u9700\u8981\u3002\u57fa\u4e8e\u8fc1\u79fb\u7684\u65b9\u6cd5\u901a\u8fc7\u501f\u9274\u5176\u4ed6\u7cfb\u7edf\u7ef4\u62a4\u7ecf\u9a8c\uff0c\u6709\u6548\u63d0\u5347\u7ef4\u62a4\u6548\u7387\u548c\u8d28\u91cf\uff0c\u56e0\u800c\u6210\u4e3a\u91cd\u8981\u7814\u7a76\u65b9\u5411\u3002", "method": "\u6587\u7ae0\u57fa\u4e8e\u8fc1\u79fb\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u8fc1\u79fb\u7ef4\u62a4\u751f\u547d\u5468\u671f\u6a21\u578b\uff0c\u5305\u62ec\u4efb\u52a1\u8bc6\u522b\u3001\u8fc1\u79fb\u6e90\u9009\u62e9\u3001\u8de8\u7cfb\u7edf\u6570\u636e\u5339\u914d\u548c\u9002\u914d\uff0c\u4ee5\u53ca\u8fc1\u79fb\u7ed3\u679c\u9a8c\u8bc1\u56db\u4e2a\u6b65\u9aa4\uff0c\u5bf9\u6bcf\u4e2a\u9636\u6bb5\u7684\u6311\u6218\u8fdb\u884c\u5206\u6790\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u8fc1\u79fb\u7684\u81ea\u52a8\u5316\u8f6f\u4ef6\u7ef4\u62a4\u7cfb\u7edf\u7684\u7814\u7a76\u8bae\u7a0b\uff0c\u5b9a\u4e49\u4e86\u8fc1\u79fb\u7ef4\u62a4\u7684\u751f\u547d\u5468\u671f\u53ca\u5176\u56db\u4e2a\u5173\u952e\u9636\u6bb5\uff1a\u4efb\u52a1\u8bc6\u522b\u3001\u8fc1\u79fb\u6e90\u9009\u62e9\u3001\u6570\u636e\u5339\u914d\u4e0e\u9002\u914d\u3001\u8fc1\u79fb\u9a8c\u8bc1\u3002\u5e76\u5206\u6790\u4e86\u6bcf\u4e2a\u9636\u6bb5\u9762\u4e34\u7684\u6311\u6218\uff0c\u65e8\u5728\u63a8\u52a8\u793e\u533a\u6df1\u5165\u7814\u7a76\u8fc1\u79fb\u65b9\u6cd5\uff0c\u63d0\u5347\u8f6f\u4ef6\u7ef4\u62a4\u7684\u81ea\u52a8\u5316\u6c34\u5e73\u3002", "conclusion": "\u8fc1\u79fb-based\u81ea\u52a8\u7ef4\u62a4\u4f5c\u4e3a\u63d0\u5347\u8f6f\u4ef6\u7ef4\u62a4\u6548\u7387\u7684\u91cd\u8981\u65b9\u5411\uff0c\u9700\u89e3\u51b3\u8bc6\u522b\u4efb\u52a1\u3001\u9009\u62e9\u8fc1\u79fb\u6e90\u3001\u6570\u636e\u5339\u914d\u9002\u914d\u53ca\u8fc1\u79fb\u9a8c\u8bc1\u7b49\u5173\u952e\u6311\u6218\uff0c\u5b9e\u73b0\u7ef4\u62a4\u7684\u81ea\u52a8\u5316\u548c\u53ef\u9760\u6027\u3002"}}
{"id": "2602.13575", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.13575", "abs": "https://arxiv.org/abs/2602.13575", "authors": ["Jing Zhao", "Ting Zhen", "Junwei bao", "Hongfei Jiang", "Yang song"], "title": "Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment", "comment": null, "summary": "Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity and empirically validate a 4.5x noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods < static pairwise training < Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.", "AI": {"tldr": "\u63d0\u51faElo-Evolve\u52a8\u6001\u591a\u667a\u80fd\u4f53\u7ade\u4e89\u6846\u67b6\uff0c\u5229\u7528\u4e8c\u5143\u6bd4\u8f83\u548cElo\u5bf9\u624b\u9009\u62e9\uff0c\u89e3\u51b3\u4f20\u7edf\u7edd\u5bf9\u8bc4\u5206\u5bf9\u9f50\u65b9\u6cd5\u7684\u9650\u5236\uff0c\u663e\u8457\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u9f50\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5c06\u5927\u91cf\u4eba\u7c7b\u504f\u597d\u6570\u636e\u538b\u7f29\u4e3a\u9759\u6001\u3001\u7edd\u5bf9\u7684\u5956\u52b1\u51fd\u6570\uff0c\u5bfc\u81f4\u6570\u636e\u7a00\u7f3a\u3001\u566a\u58f0\u654f\u611f\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u7b49\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Elo-Evolve\u6846\u67b6\uff0c\u5c06\u5bf9\u9f50\u5b9a\u4e49\u4e3a\u81ea\u9002\u5e94\u5bf9\u624b\u6c60\u4e2d\u52a8\u6001\u7684\u591a\u667a\u80fd\u4f53\u7ade\u4e89\u3002\u65b9\u6cd5\u521b\u65b0\u5305\u62ec\uff1a1\uff09\u901a\u8fc7\u4e8c\u5143\u80dc\u8d1f\u7ed3\u679c\u5b66\u4e60\uff0c\u6d88\u9664\u5bf9Bradley-Terry\u6a21\u578b\u7684\u4f9d\u8d56\uff1b2\uff09\u4f7f\u7528Elo\u5206\u6570\u63a7\u5236\u7684\u5bf9\u624b\u9009\u62e9\u5b9e\u73b0\u81ea\u52a8\u8bfe\u7a0b\u5b66\u4e60\u3002", "result": "\u7406\u8bba\u4e0a\u57fa\u4e8ePAC\u5b66\u4e60\u8bc1\u660e\uff0c\u4e8c\u5143\u6bd4\u8f83\u5728\u6837\u672c\u590d\u6742\u5ea6\u4e0a\u4f18\u4e8e\u7edd\u5bf9\u8bc4\u5206\u65b9\u6cd5\uff1b\u5b9e\u9a8c\u4e0a\u76f8\u8f83\u4e8e\u7edd\u5bf9\u8bc4\u5206\u566a\u58f0\u51cf\u5c114.5\u500d\u3002\u7528\u8be5\u6846\u67b6\u8bad\u7ec3Qwen2.5-7B\u6a21\u578b\uff0c\u5728Alpaca Eval 2.0\u548cMT-Bench\u8bc4\u4f30\u4e2d\u8868\u73b0\u4f18\u4e8e\u57fa\u4e8e\u70b9\u6570\u7684\u9759\u6001\u8bad\u7ec3\u65b9\u6cd5\u3002", "conclusion": "Elo-Evolve\u901a\u8fc7\u52a8\u6001\u5bf9\u624b\u9009\u62e9\u548c\u4e8c\u5143\u6bd4\u8f83\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5bf9\u9f50\u6548\u679c\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u5bf9\u9f50\u8bad\u7ec3\u4e2d\u7684\u6e10\u8fdb\u4f18\u52bf\u3002"}}
{"id": "2602.14780", "categories": ["cs.MA", "cs.CY", "cs.RO", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.14780", "abs": "https://arxiv.org/abs/2602.14780", "authors": ["Anna-Lena Schlamp", "Jeremias Gerner", "Klaus Bogenberger", "Werner Huber", "Stefanie Schmidtner"], "title": "ROSA: Roundabout Optimized Speed Advisory with Multi-Agent Trajectory Prediction in Multimodal Traffic", "comment": "8 pages, 1 figure, 4 tables, 2026 IEEE International Conference on Intelligent Transportation Systems (ITSC)", "summary": "We present ROSA -- Roundabout Optimized Speed Advisory -- a system that combines multi-agent trajectory prediction with coordinated speed guidance for multimodal, mixed traffic at roundabouts. Using a Transformer-based model, ROSA jointly predicts the future trajectories of vehicles and Vulnerable Road Users (VRUs) at roundabouts. Trained for single-step prediction and deployed autoregressively, it generates deterministic outputs, enabling actionable speed advisories. Incorporating motion dynamics, the model achieves high accuracy (ADE: 1.29m, FDE: 2.99m at a five-second prediction horizon), surpassing prior work. Adding route intention further improves performance (ADE: 1.10m, FDE: 2.36m), demonstrating the value of connected vehicle data. Based on predicted conflicts with VRUs and circulating vehicles, ROSA provides real-time, proactive speed advisories for approaching and entering the roundabout. Despite prediction uncertainty, ROSA significantly improves vehicle efficiency and safety, with positive effects even on perceived safety from a VRU perspective. The source code of this work is available under: github.com/urbanAIthi/ROSA.", "AI": {"tldr": "ROSA\u5229\u7528Transformer\u591a\u4e3b\u4f53\u8f68\u8ff9\u9884\u6d4b\u548c\u901f\u5ea6\u534f\u8c03\uff0c\u63d0\u5347\u73af\u5c9b\u591a\u6a21\u5f0f\u4ea4\u901a\u7684\u6548\u7387\u548c\u5b89\u5168\uff0c\u517c\u987e\u8f66\u8f86\u4e0e\u5f31\u52bf\u9053\u8def\u4f7f\u7528\u8005\uff0c\u6e90\u7801\u5f00\u6e90\u3002", "motivation": "\u73af\u5c9b\u4ea4\u901a\u73af\u5883\u590d\u6742\uff0c\u8f66\u8f86\u4e0eVRUs\u6df7\u5408\u6d41\u52a8\uff0c\u9700\u6c42\u4e00\u79cd\u80fd\u5b9e\u65f6\u9884\u6d4b\u591a\u79cd\u4ea4\u901a\u4e3b\u4f53\u8f68\u8ff9\u5e76\u534f\u8c03\u901f\u5ea6\uff0c\u63d0\u5347\u5b89\u5168\u4e0e\u6d41\u7545\u5ea6\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u8fdb\u884c\u8f66\u8f86\u53ca\u5f31\u52bf\u9053\u8def\u4f7f\u7528\u8005\u7684\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u8054\u5408\u9884\u6d4b\uff0c\u4ee5\u5355\u6b65\u9884\u6d4b\u8bad\u7ec3\u5e76\u81ea\u56de\u5f52\u90e8\u7f72\uff0c\u878d\u5408\u8fd0\u52a8\u52a8\u529b\u5b66\u4e0e\u51fa\u884c\u610f\u56fe\u4fe1\u606f\uff0c\u5b9e\u73b0\u7cbe\u51c6\u7684\u901f\u5ea6\u5efa\u8bae\u3002", "result": "\u6a21\u578b\u9884\u6d4b\u7cbe\u5ea6\u9ad8\uff08ADE:1.29m, FDE:2.99m\uff1b\u52a0\u610f\u56fe\u540eADE:1.10m, FDE:2.36m\uff09\uff0cROSAS\u5b9e\u65f6\u4ee3\u901f\u5ea6\u5efa\u8bae\u663e\u8457\u63d0\u5347\u8f66\u8f86\u6548\u7387\u4e0e\u5b89\u5168\u6027\uff0c\u5e76\u589e\u52a0VRUs\u7684\u611f\u77e5\u5b89\u5168\u3002", "conclusion": "ROSA\u7cfb\u7edf\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8f68\u8ff9\u9884\u6d4b\u4e0e\u534f\u8c03\u901f\u5ea6\u6307\u5bfc\u7684\u7ed3\u5408\uff0c\u6709\u6548\u63d0\u5347\u73af\u5c9b\u5185\u591a\u6a21\u5f0f\u6df7\u5408\u4ea4\u901a\u7684\u6548\u7387\u548c\u5b89\u5168\u6027\uff0c\u5728\u8f66\u8f86\u548c\u5f31\u52bf\u9053\u8def\u4f7f\u7528\u8005\uff08VRUs\uff09\u89d2\u5ea6\u5747\u8868\u73b0\u51fa\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2602.14337", "categories": ["cs.SE", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14337", "abs": "https://arxiv.org/abs/2602.14337", "authors": ["Yukang Feng", "Jianwen Sun", "Zelai Yang", "Jiaxin Ai", "Chuanhao Li", "Zizhen Li", "Fanrui Zhang", "Kang He", "Rui Ma", "Jifan Lin", "Jie Sun", "Yang Xiao", "Sizhuo Zhou", "Wenxiao Wu", "Yiming Liu", "Pengfei Liu", "Yu Qiao", "Shenglin Zhang", "Kaipeng Zhang"], "title": "LongCLI-Bench: A Preliminary Benchmark and Study for Long-horizon Agentic Programming in Command-Line Interfaces", "comment": null, "summary": "Recent advances in AI-assisted programming have empowered agents to execute complex workflows via command-line interfaces, however, existing benchmarks are limited by short task horizons, data contamination from GitHub scraping, and a lack of fine-grained evaluation metrics, fail to rigorously evaluate the long-horizon planning and execution capabilities essential for realistic software engineering. To address these gaps, we introduce LongCLI-Bench, a comprehensive benchmark designed to evaluate agentic capabilities across long-horizon, realistic tasks. We curated 20 high-quality, long-horizon tasks from over 1,000 computer science assignments and real-world workflows, covering four engineering categories: from scratch, feature addition, bug fixing, and refactoring. We propose a dual-set testing protocol for LongCLI-Bench, which measures requirement fulfillment (fail-to-pass) and regression avoidance (pass-to-pass), and incorporates step-level scoring to pinpoint execution failures. Extensive experiments reveal that even state-of-the-art agents achieve pass rates below 20% in LongCLI-Bench. Step-level analysis further indicates that the majority of tasks stall at less than 30% completion, highlighting that critical failures often occur in the early stages. Although self-correction offers marginal gains, human-agent collaboration through plan injection and interactive guidance yields significantly higher improvements. These results highlight that future research must emphasize the development of synergistic human-agent workflows alongside advances in agents' planning and execution capabilities to overcome key challenges in long-horizon task performance.", "AI": {"tldr": "\u63d0\u51faLongCLI-Bench\u57fa\u51c6\uff0c\u771f\u5b9e\u957f\u65f6\u7a0b\u7f16\u7a0b\u4efb\u52a1\u8bc4\u4f30\u667a\u80fd\u4f53\uff0c\u7ed3\u679c\u663e\u793a\u73b0\u6709\u667a\u80fd\u4f53\u8868\u73b0\u4e0d\u4f73\uff0c\u4eba\u673a\u534f\u4f5c\u6548\u679c\u663e\u8457\u3002", "motivation": "\u73b0\u6709AI\u8f85\u52a9\u7f16\u7a0b\u8bc4\u6d4b\u57fa\u51c6\u4efb\u52a1\u77ed\u3001\u6570\u636e\u5b58\u6709\u6c61\u67d3\u3001\u8bc4\u4ef7\u6307\u6807\u4e0d\u7ec6\u5316\uff0c\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u957f\u65f6\u7a0b\u89c4\u5212\u4e0e\u6267\u884c\u80fd\u529b\u3002\u4e3a\u5f25\u8865\u4e0d\u8db3\uff0c\u9700\u8bbe\u8ba1\u66f4\u771f\u5b9e\u3001\u7ec6\u7c92\u5ea6\u7684\u8bc4\u6d4b\u57fa\u51c6\uff0c\u4fc3\u8fdb\u667a\u80fd\u4f53\u80fd\u529b\u63d0\u5347\u3002", "method": "\u8bbe\u8ba1LongCLI-Bench\u57fa\u51c6\uff0c\u6536\u96c620\u4e2a\u9ad8\u8d28\u91cf\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u8986\u76d6\u56db\u7c7b\u5de5\u7a0b\u4efb\u52a1\uff1b\u63d0\u51fa\u53cc\u91cd\u6d4b\u8bd5\u534f\u8bae\u548c\u9010\u6b65\u8bc4\u5206\u4f53\u7cfb\uff1b\u8fdb\u884c\u5927\u91cf\u5b9e\u9a8c\u8bc1\u660e\u73b0\u6709\u667a\u80fd\u4f53\u80fd\u529b\u4e0d\u8db3\uff0c\u5206\u6790\u5931\u8d25\u70b9\u548c\u6539\u8fdb\u624b\u6bb5\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86LongCLI-Bench\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u3001\u73b0\u5b9e\u4efb\u52a1\u4e2d\u8ba1\u5212\u4e0e\u6267\u884c\u80fd\u529b\u7684\u7efc\u5408\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u5305\u542b20\u4e2a\u6765\u81ea\u8ba1\u7b97\u673a\u79d1\u5b66\u4f5c\u4e1a\u548c\u771f\u5b9e\u5de5\u4f5c\u6d41\u7684\u9ad8\u8d28\u91cf\u957f\u65f6\u7a0b\u4efb\u52a1\uff0c\u6db5\u76d6\u4ece\u96f6\u5f00\u59cb\u3001\u529f\u80fd\u6dfb\u52a0\u3001BUG\u4fee\u590d\u548c\u91cd\u6784\u56db\u4e2a\u5de5\u7a0b\u7c7b\u522b\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u91cd\u6d4b\u8bd5\u534f\u8bae\uff0c\u901a\u8fc7\u9700\u6c42\u5b8c\u6210\u5ea6\u548c\u56de\u5f52\u907f\u514d\u4e24\u65b9\u9762\u6307\u6807\uff0c\u4ee5\u53ca\u7ec6\u7c92\u5ea6\u9010\u6b65\u5f97\u5206\u6765\u5b9a\u4f4d\u6267\u884c\u5931\u8d25\u3002\u5b9e\u9a8c\u8bc1\u660e\u5f53\u524d\u5148\u8fdb\u667a\u80fd\u4f53\u5728\u8be5\u57fa\u51c6\u4e0a\u7684\u901a\u8fc7\u7387\u4f4e\u4e8e20%\uff0c\u591a\u6570\u4efb\u52a1\u672a\u5b8c\u621030%\uff0c\u5931\u8d25\u591a\u53d1\u751f\u4e8e\u65e9\u671f\u9636\u6bb5\u3002\u81ea\u6211\u7ea0\u9519\u6548\u679c\u6709\u9650\uff0c\u800c\u4eba\u673a\u534f\u4f5c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u5b8c\u6210\u7387\u3002", "conclusion": "\u76ee\u524d\u667a\u80fd\u4f53\u5728\u957f\u65f6\u7a0b\u7f16\u7a0b\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u5173\u952e\u5931\u8d25\u591a\u5728\u4efb\u52a1\u521d\u671f\u3002\u4eba\u673a\u534f\u4f5c\u901a\u8fc7\u8ba1\u5212\u6ce8\u5165\u548c\u4ea4\u4e92\u6307\u5bfc\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u672a\u6765\u5e94\u91cd\u70b9\u53d1\u5c55\u4eba\u673a\u534f\u540c\u5de5\u4f5c\u6d41\u548c\u667a\u80fd\u4f53\u7684\u89c4\u5212\u3001\u6267\u884c\u80fd\u529b\u3002"}}
{"id": "2602.13701", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13701", "abs": "https://arxiv.org/abs/2602.13701", "authors": ["Veronica Mangiaterra", "Chiara Barattieri di San Pietro", "Paolo Canal", "Valentina Bambini"], "title": "Metaphors' journeys across time and genre: tracking the evolution of literary metaphors with temporal embeddings", "comment": null, "summary": "Metaphors are a distinctive feature of literary language, yet they remain less studied experimentally than everyday metaphors. Moreover, previous psycholinguistic and computational approaches overlooked the temporal dimension, although many literary metaphors were coined centuries apart from contemporary readers. This study innovatively applies tools from diachronic distributional semantics to assess whether the processing costs of literary metaphors varied over time and genre. Specifically, we trained word embeddings on literary and nonliterary Italian corpora from the 19th and 21st centuries, for a total of 124 million tokens, and modeled changes in the semantic similarity between topics and vehicles of 515 19th-century literary metaphors, taking this measure as a proxy of metaphor processing demands. Overall, semantic similarity, and hence metaphor processing demands, remained stable over time. However, genre played a key role: metaphors appeared more difficult (i.e., lower topic-vehicle similarity) in modern literary contexts than in 19th-century literature, but easier (i.e., higher topic-vehicle similarity) in today's nonliterary language (e.g., the Web) than in 19th-century nonliterary texts. This pattern was further shaped by semantic features of metaphors' individual terms, such as vector coherence and semantic neighborhood density. Collectively, these findings align with broader linguistic changes in Italian, such as the stylistic simplification of modern literature, which may have increased metaphor processing demands, and the high creativity of the Web's language, which seems to render metaphor more accessible.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u5386\u65f6\u8bed\u4e49\u6a21\u578b\u5206\u6790\u4e8619\u81f321\u4e16\u7eaa\u610f\u5927\u5229\u6587\u5b66\u9690\u55bb\u5904\u7406\u96be\u5ea6\u7684\u53d8\u5316\uff0c\u53d1\u73b0\u9690\u55bb\u96be\u5ea6\u4f53\u88c1\u4f9d\u8d56\uff0c\u73b0\u4ee3\u6587\u5b66\u9690\u55bb\u66f4\u96be\uff0c\u7f51\u7edc\u8bed\u8a00\u9690\u55bb\u66f4\u6613\uff0c\u53cd\u6620\u8bed\u8a00\u98ce\u683c\u548c\u8bed\u4e49\u7279\u5f81\u7684\u53d8\u5316\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u8f83\u5c11\u8003\u8651\u6587\u5b66\u9690\u55bb\u7684\u65f6\u95f4\u7ef4\u5ea6\uff0c\u800c\u8bb8\u591a\u6587\u5b66\u9690\u55bb\u7684\u521b\u9020\u65f6\u95f4\u4e0e\u73b0\u4ee3\u8bfb\u8005\u5b58\u5728\u65f6\u95f4\u5dee\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63ed\u793a\u9690\u55bb\u5904\u7406\u96be\u5ea6\u968f\u65f6\u95f4\u53ca\u4f53\u88c1\u7684\u53d8\u5316\u89c4\u5f8b\u3002", "method": "\u91c7\u7528\u5386\u65f6\u5206\u5e03\u5f0f\u8bed\u4e49\u5b66\u6280\u672f\uff0c\u572819\u548c21\u4e16\u7eaa\u7684\u610f\u5927\u5229\u6587\u5b66\u53ca\u975e\u6587\u5b66\u8bed\u6599\u5e93\u4e0a\u8bad\u7ec3\u8bcd\u5d4c\u5165\uff0c\u5229\u7528515\u4e2a19\u4e16\u7eaa\u6587\u5b66\u9690\u55bb\u4e2d\u4e3b\u9898\u4e0e\u8f7d\u4f53\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u6a21\u62df\u9690\u55bb\u5904\u7406\u9700\u6c42\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5386\u65f6\u5206\u5e03\u5f0f\u8bed\u4e49\u5b66\u65b9\u6cd5\uff0c\u5206\u6790\u4e86\u610f\u5927\u522919\u4e16\u7eaa\u4e0e21\u4e16\u7eaa\u6587\u5b66\u548c\u975e\u6587\u5b66\u8bed\u6599\u4e2d\u9690\u55bb\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u53d8\u5316\uff0c\u63a2\u8ba8\u4e86\u6587\u5b66\u9690\u55bb\u5904\u7406\u96be\u5ea6\u968f\u65f6\u95f4\u548c\u4f53\u88c1\u7684\u53d8\u5316\u3002\u7814\u7a76\u53d1\u73b0\u603b\u4f53\u9690\u55bb\u5904\u7406\u96be\u5ea6\u7a33\u5b9a\uff0c\u4f46\u73b0\u4ee3\u6587\u5b66\u9690\u55bb\u8f83\u96be\uff0c\u73b0\u4ee3\u975e\u6587\u5b66\u9690\u55bb\u8f83\u6613\uff0c\u4e14\u9690\u55bb\u8bcd\u6c47\u7684\u8bed\u4e49\u7279\u5f81\u5bf9\u5904\u7406\u96be\u5ea6\u6709\u5f71\u54cd\u3002\u7814\u7a76\u652f\u6301\u610f\u5927\u5229\u8bed\u8a00\u7684\u98ce\u683c\u7b80\u5316\u548c\u7f51\u7edc\u8bed\u8a00\u7684\u521b\u9020\u6027\u4f7f\u9690\u55bb\u5904\u7406\u8d1f\u62c5\u4e0d\u540c\u3002", "conclusion": "\u9690\u55bb\u5904\u7406\u96be\u5ea6\u968f\u7740\u4f53\u88c1\u548c\u65f6\u95f4\u53d1\u751f\u53d8\u5316\uff0c\u73b0\u4ee3\u6587\u5b66\u4e2d\u7684\u9690\u55bb\u5904\u7406\u66f4\u56f0\u96be\uff0c\u800c\u73b0\u4ee3\u975e\u6587\u5b66\u6587\u672c\u4e2d\u9690\u55bb\u66f4\u6613\u7406\u89e3\uff0c\u8fd9\u4e0e\u8bed\u8a00\u98ce\u683c\u7b80\u5316\u548c\u7f51\u7edc\u8bed\u8a00\u7684\u9ad8\u521b\u9020\u6027\u6709\u5173\u3002"}}
{"id": "2602.15006", "categories": ["cs.MA", "cs.LG", "math.DG"], "pdf": "https://arxiv.org/pdf/2602.15006", "abs": "https://arxiv.org/abs/2602.15006", "authors": ["Meet Gandhi", "George P. Kontoudis"], "title": "Distributed Quantum Gaussian Processes for Multi-Agent Systems", "comment": "9 pages, 4 figures, accepted at AAMAS 2026 (International Conference on Autonomous Agents and Multiagent Systems)", "summary": "Gaussian Processes (GPs) are a powerful tool for probabilistic modeling, but their performance is often constrained in complex, largescale real-world domains due to the limited expressivity of classical kernels. Quantum computing offers the potential to overcome this limitation by embedding data into exponentially large Hilbert spaces, capturing complex correlations that remain inaccessible to classical computing approaches. In this paper, we propose a Distributed Quantum Gaussian Process (DQGP) method in a multiagent setting to enhance modeling capabilities and scalability. To address the challenging non-Euclidean optimization problem, we develop a Distributed consensus Riemannian Alternating Direction Method of Multipliers (DR-ADMM) algorithm that aggregates local agent models into a global model. We evaluate the efficacy of our method through numerical experiments conducted on a quantum simulator in classical hardware. We use real-world, non-stationary elevation datasets of NASA's Shuttle Radar Topography Mission and synthetic datasets generated by Quantum Gaussian Processes. Beyond modeling advantages, our framework highlights potential computational speedups that quantum hardware may provide, particularly in Gaussian processes and distributed optimization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u7684\u5206\u5e03\u5f0f\u91cf\u5b50\u9ad8\u65af\u8fc7\u7a0b\u65b9\u6cd5\u53ca\u4f18\u5316\u7b97\u6cd5\uff0c\u63d0\u5347\u4e86\u9ad8\u65af\u8fc7\u7a0b\u7684\u8868\u8fbe\u80fd\u529b\u548c\u53ef\u6269\u5c55\u6027\uff0c\u5e76\u5728\u6a21\u62df\u5b9e\u9a8c\u4e2d\u5c55\u793a\u4e86\u5176\u4f18\u52bf\u53ca\u91cf\u5b50\u8ba1\u7b97\u7684\u52a0\u901f\u6f5c\u529b\u3002", "motivation": "\u4f20\u7edf\u9ad8\u65af\u8fc7\u7a0b\u53d7\u9650\u4e8e\u7ecf\u5178\u6838\u51fd\u6570\u7684\u8868\u8fbe\u80fd\u529b\uff0c\u96be\u4ee5\u5904\u7406\u590d\u6742\u5927\u89c4\u6a21\u73b0\u5b9e\u95ee\u9898\uff0c\u91cf\u5b50\u8ba1\u7b97\u901a\u8fc7\u5d4c\u5165\u6307\u6570\u7ea7\u7684\u5e0c\u5c14\u4f2f\u7279\u7a7a\u95f4\uff0c\u6709\u671b\u6355\u6349\u590d\u6742\u5173\u8054\uff0c\u63d0\u5347\u5efa\u6a21\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5e03\u5f0f\u91cf\u5b50\u9ad8\u65af\u8fc7\u7a0b\uff08DQGP\uff09\u65b9\u6cd5\uff0c\u7ed3\u5408\u591a\u667a\u80fd\u4f53\u8bbe\u7f6e\uff0c\u901a\u8fc7\u5f00\u53d1\u5206\u5e03\u5f0f\u5171\u8bc6\u9ece\u66fc\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5\uff08DR-ADMM\uff09\u7b97\u6cd5\u89e3\u51b3\u975e\u6b27\u51e0\u91cc\u5f97\u4f18\u5316\u95ee\u9898\uff0c\u5c06\u5c40\u90e8\u6a21\u578b\u805a\u5408\u4e3a\u5168\u5c40\u6a21\u578b\u3002", "result": "\u5728\u91cf\u5b50\u6a21\u62df\u5668\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728NASA\u5730\u5f62\u6570\u636e\u548c\u91cf\u5b50\u9ad8\u65af\u8fc7\u7a0b\u751f\u6210\u7684\u5408\u6210\u6570\u636e\u4e0a\u8868\u73b0\u6709\u6548\uff0c\u5c55\u793a\u4e86\u5efa\u6a21\u4f18\u52bf\u548c\u6f5c\u5728\u7684\u8ba1\u7b97\u52a0\u901f\u80fd\u529b\u3002", "conclusion": "\u6240\u63d0DQGP\u65b9\u6cd5\u7ed3\u5408DR-ADMM\u7b97\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u91cf\u5b50\u9ad8\u65af\u8fc7\u7a0b\u5728\u590d\u6742\u548c\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u7684\u5efa\u6a21\u80fd\u529b\u548c\u6269\u5c55\u6027\uff0c\u5c55\u793a\u4e86\u91cf\u5b50\u8ba1\u7b97\u5728\u9ad8\u65af\u8fc7\u7a0b\u548c\u5206\u5e03\u5f0f\u4f18\u5316\u4e2d\u7684\u6f5c\u5728\u52a0\u901f\u6548\u5e94\u3002"}}
{"id": "2602.14572", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14572", "abs": "https://arxiv.org/abs/2602.14572", "authors": ["Pooya Rostami Mazrae", "Alexandre Decan", "Tom Mens", "Mairieli Wessel"], "title": "An Empirical Study of the Evolution of GitHub Actions Workflows", "comment": null, "summary": "CI/CD practices play a significant role during collaborative software development by automating time-consuming and repetitive tasks such as testing, building, quality checking, dependency and security management. GitHub Actions, the CI/CD tool integrated into GitHub, allows repository maintainers to automate development workflows. We conducted a mixed methods analysis of GitHub Actions workflow changes over time. Through a preliminary qualitative analysis of 439 modified workflow files we identified seven types of conceptual changes to workflows. Next, we performed a quantitative analysis over 49K+ GitHub repositories totaling 267K+ workflow change histories and 3.4M+ workflow file versions from November 2019 to August 2025. This analysis revealed that repositories contain a median of three workflow files, and 7.3% of all workflow files are being changed every week. The changes made to workflows tend to be small, with about three-quarters containing only a single change. The large majority of the observed changes have to do with task configuration and task specification in workflow jobs. We did not find any conclusive evidence of the effect of LLM coding tools or other major technological changes on workflow creation and workflow maintenance frequency. Our findings highlight the need for improved tooling to support fine-grained maintenance tasks, such as a broader adoption of dependency management and AI-based support for ensuring and sustaining workflow security and quality.", "AI": {"tldr": "\u5206\u6790GitHub Actions\u5de5\u4f5c\u6d41\u6587\u4ef6\u53d8\u66f4\uff0c\u53d1\u73b0\u5c0f\u89c4\u6a21\u6539\u52a8\u5360\u4e3b\uff0c\u9891\u7387\u7a33\u5b9a\uff0c\u5efa\u8bae\u5f3a\u5316\u4f9d\u8d56\u7ba1\u7406\u548cAI\u8f85\u52a9\u4fdd\u969c\u3002", "motivation": "CI/CD\u81ea\u52a8\u5316\u5de5\u5177GitHub Actions\u5728\u534f\u540c\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5de5\u4f5c\u6d41\u7684\u7ef4\u62a4\u548c\u53d8\u66f4\u7279\u70b9\u5c1a\u672a\u8be6\u5c3d\u4e86\u89e3\uff0c\u7814\u7a76\u65e8\u5728\u63ed\u793a\u53d8\u66f4\u884c\u4e3a\u4ee5\u6307\u5bfc\u6539\u8fdb\u652f\u6301\u5de5\u5177\u3002", "method": "\u9996\u5148\u5bf9439\u4e2a\u4fee\u6539\u7684\u5de5\u4f5c\u6d41\u6587\u4ef6\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u786e\u5b9a\u4e03\u7c7b\u6982\u5ff5\u53d8\u66f4\u7c7b\u578b\uff1b\u968f\u540e\u5bf949000\u591a\u4e2a\u4ed3\u5e93\u300126.7\u4e07\u5de5\u4f5c\u6d41\u53d8\u66f4\u5386\u53f2\u548c340\u4e07\u6587\u4ef6\u7248\u672c\u8fdb\u884c\u91cf\u5316\u5206\u6790\uff0c\u7edf\u8ba1\u53d8\u66f4\u9891\u7387\u548c\u6027\u8d28\u3002", "result": "\u672c\u6587\u901a\u8fc7\u5bf9GitHub Actions\u7684\u5de5\u4f5c\u6d41\u6587\u4ef6\u4fee\u6539\u8fdb\u884c\u6df7\u5408\u65b9\u6cd5\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5de5\u4f5c\u6d41\u7ef4\u62a4\u7684\u5177\u4f53\u53d8\u5316\u7c7b\u578b\u4e0e\u9891\u7387\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u5de5\u4f5c\u6d41\u6587\u4ef6\u4e2d\u4e3b\u8981\u4fee\u6539\u4e3a\u4efb\u52a1\u914d\u7f6e\u548c\u4efb\u52a1\u89c4\u8303\uff0c\u591a\u6570\u6539\u52a8\u89c4\u6a21\u8f83\u5c0f\uff1b\u6bcf\u5468\u7ea67.3%\u7684\u5de5\u4f5c\u6d41\u6587\u4ef6\u53d1\u751f\u53d8\u5316\uff0c\u4e14\u4ed3\u5e93\u4e2d\u4e2d\u4f4d\u6570\u5305\u542b\u4e09\u4e2a\u5de5\u4f5c\u6d41\u6587\u4ef6\u3002\u5c1a\u672a\u53d1\u73b0\u5927\u578b\u6280\u672f\u53d8\u9769\uff08\u5982\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5de5\u5177\uff09\u5bf9\u5de5\u4f5c\u6d41\u53d8\u66f4\u9891\u7387\u7684\u663e\u8457\u5f71\u54cd\u3002\u8bba\u6587\u5f3a\u8c03\u9700\u6539\u8fdb\u5de5\u5177\uff0c\u652f\u6301\u7ec6\u7c92\u5ea6\u7ef4\u62a4\u4efb\u52a1\uff0c\u5c24\u5176\u662f\u4f9d\u8d56\u7ba1\u7406\u548c\u57fa\u4e8eAI\u7684\u5b89\u5168\u4e0e\u8d28\u91cf\u4fdd\u969c\u3002", "conclusion": "GitHub Actions\u5de5\u4f5c\u6d41\u66f4\u6539\u4e3b\u8981\u96c6\u4e2d\u5728\u4efb\u52a1\u914d\u7f6e\u548c\u89c4\u8303\uff0c\u6539\u52a8\u9891\u7387\u7a33\u5b9a\uff0c\u9700\u53d1\u5c55\u66f4\u7ec6\u7c92\u5ea6\u7ef4\u62a4\u652f\u6301\u5de5\u5177\u53caAI\u5b89\u5168\u8d28\u91cf\u4fdd\u969c\u3002"}}
{"id": "2602.13713", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13713", "abs": "https://arxiv.org/abs/2602.13713", "authors": ["Maciej Uberna", "Micha\u0142 Wawer", "Jaros\u0142aw A. Chudziak", "Marcin Koszowy"], "title": "On Theoretically-Driven LLM Agents for Multi-Dimensional Discourse Analysis", "comment": "8 pages, 4 figures, 3 tables. This is the accepted version of the paper presented at the 18th International Conference on Agents and Artificial Intelligence (ICAART 2026), Marbella, Spain", "summary": "Identifying the strategic uses of reformulation in discourse remains a key challenge for computational argumentation. While LLMs can detect surface-level similarity, they often fail to capture the pragmatic functions of rephrasing, such as its role within rhetorical discourse. This paper presents a comparative multi-agent framework designed to quantify the benefits of incorporating explicit theoretical knowledge for this task. We utilise an dataset of annotated political debates to establish a new standard encompassing four distinct rephrase functions: Deintensification, Intensification, Specification, Generalisation, and Other, which covers all remaining types (D-I-S-G-O). We then evaluate two parallel LLM-based agent systems: one enhanced by argumentation theory via Retrieval-Augmented Generation (RAG), and an identical zero-shot baseline. The results reveal a clear performance gap: the RAG-enhanced agents substantially outperform the baseline across the board, with particularly strong advantages in detecting Intensification and Generalisation context, yielding an overall Macro F1-score improvement of nearly 30\\%. Our findings provide evidence that theoretical grounding is not only beneficial but essential for advancing beyond mere paraphrase detection towards function-aware analysis of argumentative discourse. This comparative multi-agent architecture represents a step towards scalable, theoretically informed computational tools capable of identifying rhetorical strategies in contemporary discourse.", "AI": {"tldr": "\u901a\u8fc7\u7406\u8bba\u77e5\u8bc6\u589e\u5f3a\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u5bf9\u8bba\u8ff0\u4e2d\u91cd\u8ff0\u529f\u80fd\u7684\u68c0\u6d4b\u80fd\u529b\uff0c\u63a8\u52a8\u4ece\u7b80\u5355\u7684\u610f\u8bd1\u8bc6\u522b\u5411\u529f\u80fd\u611f\u77e5\u7684\u8bba\u8ff0\u5206\u6790\u8fc8\u8fdb\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u80fd\u68c0\u6d4b\u8868\u9762\u76f8\u4f3c\u5ea6\uff0c\u4f46\u96be\u4ee5\u6355\u6349\u91cd\u8ff0\u7684\u8bed\u7528\u529f\u80fd\u53ca\u5176\u4fee\u8f9e\u4f5c\u7528\uff0c\u4e9f\u9700\u7ed3\u5408\u7406\u8bba\u77e5\u8bc6\u63d0\u5347\u5206\u6790\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u6bd4\u8f83\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5229\u7528\u589e\u5f3a\u68c0\u7d22\u751f\u6210\uff08RAG\uff09\u7684\u65b9\u5f0f\u5c06\u8bba\u8bc1\u7406\u8bba\u878d\u5165\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u4ee5\u8bc6\u522b\u8bba\u8ff0\u4e2d\u91cd\u8ff0\u7684\u7b56\u7565\u529f\u80fd\u3002", "result": "\u57fa\u4e8e\u5e26\u6ce8\u91ca\u7684\u653f\u6cbb\u8fa9\u8bba\u6570\u636e\u96c6\uff0c\u6784\u5efa\u56db\u79cd\u91cd\u8ff0\u529f\u80fd\u7c7b\u522b\uff08\u51cf\u5f31\u3001\u5f3a\u5316\u3001\u5177\u4f53\u5316\u3001\u6cdb\u5316\u53ca\u5176\u4ed6\uff09\uff0c\u5b9e\u9a8c\u8bc1\u660e\u878d\u5408\u8bba\u8bc1\u7406\u8bba\u7684RAG\u589e\u5f3a\u6a21\u578b\u5728\u5404\u65b9\u9762\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u96f6-shot\u57fa\u7ebf\uff0c\u5b8fF1\u5206\u6570\u63d0\u5347\u8fd130%\u3002", "conclusion": "\u7406\u8bba\u57fa\u7840\u5bf9\u8bc6\u522b\u8bba\u8ff0\u4e2d\u91cd\u8ff0\u7684\u7b56\u7565\u529f\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u63d0\u51fa\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4e3a\u6784\u5efa\u53ef\u6269\u5c55\u7684\u3001\u7406\u8bba\u652f\u6301\u7684\u4fee\u8f9e\u7b56\u7565\u8bc6\u522b\u5de5\u5177\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2602.14158", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2602.14158", "abs": "https://arxiv.org/abs/2602.14158", "authors": ["Naeimeh Nourmohammadi", "Md Meem Hossain", "The Anh Han", "Safina Showkat Ara", "Zia Ush Shamszaman"], "title": "A Multi-Agent Framework for Medical AI: Leveraging Fine-Tuned GPT, LLaMA, and DeepSeek R1 for Evidence-Based and Bias-Aware Clinical Query Processing", "comment": "27 pages, 14 figures, 5 tables", "summary": "Large language models (LLMs) show promise for healthcare question answering, but clinical use is limited by weak verification, insufficient evidence grounding, and unreliable confidence signalling. We propose a multi-agent medical QA framework that combines complementary LLMs with evidence retrieval, uncertainty estimation, and bias checks to improve answer reliability. Our approach has two phases. First, we fine-tune three representative LLM families (GPT, LLaMA, and DeepSeek R1) on MedQuAD-derived medical QA data (20k+ question-answer pairs across multiple NIH domains) and benchmark generation quality. DeepSeek R1 achieves the strongest scores (ROUGE-1 0.536 +- 0.04; ROUGE-2 0.226 +-0.03; BLEU 0.098 -+ 0.018) and substantially outperforms the specialised biomedical baseline BioGPT in zero-shot evaluation. Second, we implement a modular multi-agent pipeline in which a Clinical Reasoning agent (fine-tuned LLaMA) produces structured explanations, an Evidence Retrieval agent queries PubMed to ground responses in recent literature, and a Refinement agent (DeepSeek R1) improves clarity and factual consistency; an optional human validation path is triggered for high-risk or high-uncertainty cases. Safety mechanisms include Monte Carlo dropout and perplexity-based uncertainty scoring, plus lexical and sentiment-based bias detection supported by LIME/SHAP-based analyses. In evaluation, the full system achieves 87% accuracy with relevance around 0.80, and evidence augmentation reduces uncertainty (perplexity 4.13) compared to base responses, with mean end-to-end latency of 36.5 seconds under the reported configuration. Overall, the results indicate that agent specialisation and verification layers can mitigate key single-model limitations and provide a practical, extensible design for evidence-based and bias-aware medical AI.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u591a\u4ee3\u7406\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u533b\u7597\u95ee\u7b54\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u636e\u68c0\u7d22\u3001\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u504f\u89c1\u68c0\u6d4b\uff0c\u63d0\u9ad8\u56de\u7b54\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u95ee\u7b54\u4e2d\u5b58\u5728\u9a8c\u8bc1\u5f31\u3001\u8bc1\u636e\u4e0d\u8db3\u548c\u7f6e\u4fe1\u4fe1\u53f7\u4e0d\u53ef\u9760\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u4e34\u5e8a\u5e94\u7528\u3002", "method": "\u9996\u5148\u5fae\u8c03\u4e09\u4e2a\u4ee3\u8868\u6027LLM\uff08GPT\uff0cLLaMA\uff0cDeepSeek R1\uff09\u5728MedQuAD\u533b\u7597\u95ee\u7b54\u6570\u636e\u4e0a\uff1b\u5176\u6b21\u6784\u5efa\u591a\u4ee3\u7406\u6d41\u6c34\u7ebf\uff0c\u5305\u62ec\u4e34\u5e8a\u63a8\u7406\u4ee3\u7406\u3001\u8bc1\u636e\u68c0\u7d22\u4ee3\u7406\u548c\u56de\u7b54\u4f18\u5316\u4ee3\u7406\uff0c\u5e76\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u548c\u504f\u89c1\u68c0\u6d4b\u673a\u5236\u3002", "result": "DeepSeek R1\u5728\u751f\u6210\u8d28\u91cf\u4e0a\u8868\u73b0\u6700\u4f73\uff0c\u7cfb\u7edf\u6574\u4f53\u8fbe\u523087%\u51c6\u786e\u7387\uff0c\u76f8\u5173\u6027\u7ea60.80\uff0c\u8bc1\u636e\u589e\u5f3a\u6709\u6548\u964d\u4f4e\u4e0d\u786e\u5b9a\u6027\uff0c\u7aef\u5230\u7aef\u5ef6\u8fdf36.5\u79d2\u3002", "conclusion": "\u591a\u4ee3\u7406\u4e13\u95e8\u5316\u548c\u9a8c\u8bc1\u5c42\u80fd\u591f\u7f13\u89e3\u5355\u4e00\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u57fa\u4e8e\u8bc1\u636e\u548c\u504f\u89c1\u610f\u8bc6\u7684\u533b\u7597AI\u63d0\u4f9b\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u8bbe\u8ba1\u3002"}}
{"id": "2602.14591", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14591", "abs": "https://arxiv.org/abs/2602.14591", "authors": ["Evgenii Kniazev"], "title": "Automated Classification of Source Code Changes Based on Metrics Clustering in the Software Development Process", "comment": "This is an English translation of the author's Ph.D. dissertation abstract, originally defended in Russian at ITMO University (2009) under the supervision of Prof. A.A. Shalyto. The original research was co-authored with D.G. Shopyrin. Original available at https://is.ifmo.ru/disser/knyazev_autorefer.pdf", "summary": "This paper presents an automated method for classifying source code changes during the software development process based on clustering of change metrics. The method consists of two steps: clustering of metric vectors computed for each code change, followed by expert mapping of the resulting clusters to predefined change classes. The distribution of changes into clusters is performed automatically, while the mapping of clusters to classes is carried out by an expert. Automation of the distribution step substantially reduces the time required for code change review. The k-means algorithm with a cosine similarity measure between metric vectors is used for clustering. Eleven source code metrics are employed, covering lines of code, cyclomatic complexity, file counts, interface changes, and structural changes. The method was validated on five software systems, including two open-source projects (Subversion and NHibernate), and demonstrated classification purity of P_C = 0.75 +/- 0.05 and entropy of E_C = 0.37 +/- 0.06 at a significance level of 0.05.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u53d8\u66f4\u5ea6\u91cf\u805a\u7c7b\u7684\u81ea\u52a8\u5206\u7c7b\u65b9\u6cd5\uff0c\u6709\u6548\u51cf\u5c11\u5ba1\u67e5\u65f6\u95f4\uff0c\u9a8c\u8bc1\u663e\u793a\u5206\u7c7b\u7cbe\u5ea6\u8f83\u9ad8\u3002", "motivation": "\u51cf\u5c11\u4ee3\u7801\u53d8\u66f4\u5ba1\u67e5\u6240\u9700\u65f6\u95f4\uff0c\u63d0\u9ad8\u8f6f\u4ef6\u5f00\u53d1\u8fc7\u7a0b\u4e2d\u7684\u4ee3\u7801\u53d8\u66f4\u5206\u7c7b\u6548\u7387\u3002", "method": "\u91c7\u7528k-means\u7b97\u6cd5\u57fa\u4e8e\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5bf9\u6bcf\u4e2a\u4ee3\u7801\u53d8\u66f4\u7684\u5ea6\u91cf\u5411\u91cf\u8fdb\u884c\u805a\u7c7b\uff0c\u4f7f\u752811\u4e2a\u6e90\u4ee3\u7801\u5ea6\u91cf\u6307\u6807\uff0c\u968f\u540e\u7531\u4e13\u5bb6\u5c06\u805a\u7c7b\u7ed3\u679c\u6620\u5c04\u5230\u9884\u5b9a\u4e49\u7684\u53d8\u66f4\u7c7b\u522b\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e94\u4e2a\u8f6f\u4ef6\u7cfb\u7edf\uff08\u5305\u62ec\u4e24\u4e2a\u5f00\u6e90\u9879\u76eeSubversion\u548cNHibernate\uff09\u4e0a\u9a8c\u8bc1\uff0c\u5206\u7c7b\u7eaf\u5ea6\u7ea6\u4e3a0.75\uff0c\u71b5\u7ea6\u4e3a0.37\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u901a\u8fc7\u81ea\u52a8\u805a\u7c7b\u6e90\u4ee3\u7801\u53d8\u66f4\u5ea6\u91cf\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u4ee3\u7801\u53d8\u66f4\u5ba1\u67e5\u65f6\u95f4\uff0c\u4e14\u5206\u7c7b\u6548\u679c\u8f83\u597d\uff0c\u8868\u660e\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u5b9e\u9645\u8f6f\u4ef6\u9879\u76ee\u7684\u4ee3\u7801\u53d8\u66f4\u5206\u7c7b\u3002"}}
{"id": "2602.13748", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2602.13748", "abs": "https://arxiv.org/abs/2602.13748", "authors": ["Yongkang Jin", "Jianwen Luo", "Jingjing Wang", "Jianmin Yao", "Yu Hong"], "title": "RMPL: Relation-aware Multi-task Progressive Learning with Stage-wise Training for Multimedia Event Extraction", "comment": null, "summary": "Multimedia Event Extraction (MEE) aims to identify events and their arguments from documents that contain both text and images. It requires grounding event semantics across different modalities. Progress in MEE is limited by the lack of annotated training data. M2E2 is the only established benchmark, but it provides annotations only for evaluation. This makes direct supervised training impractical. Existing methods mainly rely on cross-modal alignment or inference-time prompting with Vision--Language Models (VLMs). These approaches do not explicitly learn structured event representations and often produce weak argument grounding in multimodal settings. To address these limitations, we propose RMPL, a Relation-aware Multi-task Progressive Learning framework for MEE under low-resource conditions. RMPL incorporates heterogeneous supervision from unimodal event extraction and multimedia relation extraction with stage-wise training. The model is first trained with a unified schema to learn shared event-centric representations across modalities. It is then fine-tuned for event mention identification and argument role extraction using mixed textual and visual data. Experiments on the M2E2 benchmark with multiple VLMs show consistent improvements across different modality settings.", "AI": {"tldr": "\u63d0\u51faRMPL\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u6e10\u8fdb\u8bad\u7ec3\u6574\u5408\u591a\u6a21\u6001\u6570\u636e\uff0c\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u591a\u5a92\u4f53\u4e8b\u4ef6\u62bd\u53d6\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u6a21\u6001\u4e8b\u4ef6\u62bd\u53d6\u65b9\u6cd5\u56e0\u7f3a\u4e4f\u6807\u6ce8\u8bad\u7ec3\u6570\u636e\uff0c\u96be\u4ee5\u6709\u6548\u5b66\u4e60\u7ed3\u6784\u5316\u4e8b\u4ef6\u8868\u793a\uff0c\u5bfc\u81f4\u4e8b\u4ef6\u53ca\u53c2\u6570\u8bc6\u522b\u6548\u679c\u8f83\u5dee\uff0c\u9700\u4e00\u79cd\u80fd\u5728\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u6709\u6548\u5229\u7528\u5f02\u8d28\u76d1\u7763\u7684\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u7edf\u4e00schema\u7684\u9636\u6bb5\u6027\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u5148\u8bad\u7ec3\u8de8\u6a21\u6001\u4e8b\u4ef6\u8868\u793a\uff0c\u518d\u5fae\u8c03\u4e8b\u4ef6\u68c0\u6d4b\u548c\u53c2\u6570\u89d2\u8272\u62bd\u53d6\uff0c\u7ed3\u5408\u5355\u6a21\u6001\u53ca\u591a\u6a21\u6001\u5173\u7cfb\u62bd\u53d6\u7684\u76d1\u7763\u4fe1\u53f7\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRMPL\u7684\u591a\u4efb\u52a1\u6e10\u8fdb\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u591a\u6a21\u6001\u4e8b\u4ef6\u62bd\u53d6\uff08MEE\uff09\u4e2d\u7684\u4f4e\u8d44\u6e90\u8bad\u7ec3\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9636\u6bb5\u6027\u8bad\u7ec3\uff0c\u878d\u5408\u5355\u6a21\u6001\u4e8b\u4ef6\u62bd\u53d6\u548c\u591a\u5a92\u4f53\u5173\u7cfb\u62bd\u53d6\u7684\u5f02\u8d28\u76d1\u7763\uff0c\u5148\u5b66\u4e60\u8de8\u6a21\u6001\u5171\u4eab\u7684\u4e8b\u4ef6\u4e2d\u5fc3\u8868\u793a\uff0c\u518d\u5fae\u8c03\u4e8b\u4ef6\u68c0\u6d4b\u4e0e\u53c2\u6570\u89d2\u8272\u62bd\u53d6\u3002\u5b9e\u9a8c\u5728M2E2\u57fa\u51c6\u4e0a\uff0c\u7ed3\u5408\u591a\u79cd\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u6a21\u6001\u8bbe\u7f6e\u4e0b\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RMPL\u6709\u6548\u878d\u5408\u4e86\u5f02\u8d28\u76d1\u7763\u4fe1\u606f\uff0c\u589e\u5f3a\u4e86\u4e8b\u4ef6\u8868\u793a\u5b66\u4e60\uff0c\u5728M2E2\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u591a\u6a21\u6001\u4e8b\u4ef6\u62bd\u53d6\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2602.14595", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14595", "abs": "https://arxiv.org/abs/2602.14595", "authors": ["Shirin Pirouzkhah", "Souhaila Serbout", "Alberto Bacchelli"], "title": "Consistent or Sensitive? Automated Code Revision Tools Against Semantics-Preserving Perturbations", "comment": null, "summary": "Automated Code Revision (ACR) tools aim to reduce manual effort by automatically generating code revisions based on reviewer feedback. While ACR tools have shown promising performance on historical data, their real-world utility depends on their ability to handle similar code variants expressing the same issue - a property we define as consistency. However, the probabilistic nature of ACR tools often compromises consistency, which may lead to divergent revisions even for semantically equivalent code variants. In this paper, we investigate the extent to which ACR tools maintain consistency when presented with semantically equivalent code variants. To do so, we first designed nine types of semantics-preserving perturbations (SPP) and applied them to 2032 Java methods from real-world GitHub projects, generating over 10K perturbed variants for evaluation. Then we used these perturbations to evaluate the consistency of five state-of-the-art transformer-based ACR tools. We found that the ACR tools' ability to generate correct revisions can drop by up to 45.3%, when presented with semantically equivalent code. The closer the perturbation is to this targeted region, the more likely an ACR tool is to fail to generate the correct revision. We explored potential mitigation strategies that modify the input representation, but found that these attention-guiding heuristics yielded only marginal improvements, thus leaving the solution to this problem as an open research question.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bbe\u8ba1\u8bed\u4e49\u4fdd\u6301\u6270\u52a8\uff0c\u8bc4\u4f30\u4e94\u79cd\u4e3b\u6d41\u81ea\u52a8\u4ee3\u7801\u4fee\u8ba2\u5de5\u5177\u5728\u8bed\u4e49\u7b49\u4ef7\u4ee3\u7801\u53d8\u4f53\u4e0a\u7684\u4e00\u81f4\u6027\u3002\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u5de5\u5177\u5728\u53d8\u4f53\u4e0a\u4e00\u81f4\u6027\u5dee\uff0c\u6b63\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u73b0\u6709\u7f13\u89e3\u529e\u6cd5\u6548\u679c\u6709\u9650\uff0c\u63d0\u793a\u8be5\u95ee\u9898\u5c1a\u5f85\u8fdb\u4e00\u6b65\u7814\u7a76\u3002", "motivation": "\u867d\u7136\u81ea\u52a8\u4ee3\u7801\u4fee\u8ba2\u5de5\u5177\u5728\u5386\u53f2\u6570\u636e\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5176\u5728\u5904\u7406\u8868\u8fbe\u76f8\u540c\u95ee\u9898\u7684\u4ee3\u7801\u53d8\u4f53\u65f6\u662f\u5426\u80fd\u4fdd\u6301\u4e00\u81f4\u6027\u5c1a\u672a\u7814\u7a76\uff0c\u8fd9\u662f\u786e\u4fdd\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u7684\u5173\u952e\u3002", "method": "\u8bbe\u8ba1\u4e5d\u79cd\u8bed\u4e49\u4fdd\u6301\u6270\u52a8\uff0c\u5c06\u5176\u5e94\u7528\u4e8e2032\u4e2aJava\u65b9\u6cd5\uff0c\u751f\u6210\u8d85\u8fc7\u4e00\u4e07\u6761\u4ee3\u7801\u53d8\u4f53\uff0c\u5229\u7528\u8fd9\u4e9b\u53d8\u4f53\u8bc4\u4f30\u4e94\u79cd\u57fa\u4e8eTransformer\u7684\u81ea\u52a8\u4ee3\u7801\u4fee\u8ba2\u5de5\u5177\u7684\u4e00\u81f4\u6027\u8868\u73b0\u3002", "result": "\u81ea\u52a8\u4ee3\u7801\u4fee\u8ba2\u5de5\u5177\u5728\u9762\u5bf9\u8bed\u4e49\u7b49\u4ef7\u7684\u4ee3\u7801\u53d8\u4f53\u65f6\uff0c\u6b63\u786e\u4fee\u8ba2\u7387\u6700\u591a\u4e0b\u964d45.3%\uff1b\u6270\u52a8\u8d8a\u63a5\u8fd1\u95ee\u9898\u533a\u57df\uff0c\u5de5\u5177\u5931\u8d25\u7387\u8d8a\u9ad8\uff1b\u73b0\u6709\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684\u7f13\u89e3\u7b56\u7565\u4ec5\u6709\u6709\u9650\u6539\u8fdb\u3002", "conclusion": "\u73b0\u6709\u81ea\u52a8\u4ee3\u7801\u4fee\u8ba2\u5de5\u5177\u5728\u9762\u5bf9\u8bed\u4e49\u7b49\u4ef7\u7684\u4ee3\u7801\u53d8\u4f53\u65f6\uff0c\u8868\u73b0\u51fa\u4e00\u81f4\u6027\u4e0d\u8db3\uff0c\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u4e14\u76ee\u524d\u7684\u7f13\u89e3\u7b56\u7565\u6548\u679c\u6709\u9650\u3002"}}
{"id": "2602.13790", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13790", "abs": "https://arxiv.org/abs/2602.13790", "authors": ["Melis \u00c7elikkol", "Wei Zhao"], "title": "How Do Lexical Senses Correspond Between Spoken German and German Sign Language?", "comment": "EACL'26 (Student Research Workshop)", "summary": "Sign language lexicographers construct bilingual dictionaries by establishing word-to-sign mappings, where polysemous and homonymous words corresponding to different signs across contexts are often underrepresented. A usage-based approach examining how word senses map to signs can identify such novel mappings absent from current dictionaries, enriching lexicographic resources. We address this by analyzing German and German Sign Language (Deutsche Geb\u00e4rdensprache, DGS), manually annotating 1,404 word use-to-sign ID mappings derived from 32 words from the German Word Usage Graph (D-WUG) and 49 signs from the Digital Dictionary of German Sign Language (DW-DGS). We identify three correspondence types: Type 1 (one-to-many), Type 2 (many-to-one), and Type 3 (one-to-one), plus No Match cases. We evaluate computational methods: Exact Match (EM) and Semantic Similarity (SS) using SBERT embeddings. SS substantially outperforms EM overall 88.52% vs. 71.31%), with dramatic gains for Type 1 (+52.1 pp). Our work establishes the first annotated dataset for cross-modal sense correspondence and reveals which correspondence patterns are computationally identifiable. Our code and dataset are made publicly available.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u4eba\u5de5\u6807\u6ce8\u6784\u5efa\u4e86\u5fb7\u8bed\u4e0e\u5fb7\u56fd\u624b\u8bed\u7684\u8bcd\u4e49\u4e0e\u7b26\u53f7\u6620\u5c04\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4e49\u8bcd\u7684\u8bcd\u4e49-\u624b\u8bed\u5bf9\u5e94\u8bc6\u522b\u6548\u679c\u3002", "motivation": "\u5f53\u524d\u7684\u624b\u8bed\u8bcd\u5178\u672a\u80fd\u5145\u5206\u8868\u793a\u540c\u5f62\u591a\u4e49\u8bcd\u548c\u540c\u97f3\u5f02\u4e49\u8bcd\u5728\u4e0d\u540c\u8bed\u5883\u4e0b\u5bf9\u5e94\u7684\u4e0d\u540c\u624b\u8bed\u7b26\u53f7\uff0c\u5b58\u5728\u8bcd\u4e49\u4e0e\u624b\u8bed\u7b26\u53f7\u6620\u5c04\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "method": "\u4eba\u5de5\u6807\u6ce832\u4e2a\u5fb7\u8bed\u8bcd\u53ca\u5176\u5728\u4f7f\u7528\u56fe\u4e2d\u7684\u8bcd\u4e49\u5bf9\u5e94\u768449\u4e2a\u5fb7\u56fd\u624b\u8bed\u7b26\u53f7\uff0c\u5b9e\u73b0\u4e861,404\u4e2a\u8bcd\u7528\u6cd5\u5230\u624b\u8bed\u7b26\u53f7ID\u7684\u6620\u5c04\u3002\u8bc4\u4f30\u4e86\u7cbe\u786e\u5339\u914d\u548c\u57fa\u4e8eSBERT\u8bed\u4e49\u5d4c\u5165\u7684\u8bed\u4e49\u76f8\u4f3c\u5ea6\u4e24\u79cd\u8ba1\u7b97\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u5fb7\u8bed\u4e0e\u5fb7\u56fd\u624b\u8bed\u7684\u8de8\u6a21\u6001\u8bcd\u4e49\u5bf9\u5e94\u7684\u9996\u4e2a\u6807\u6ce8\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7SBERT\u8bed\u4e49\u76f8\u4f3c\u5ea6\u65b9\u6cd5\u6709\u6548\u8bc6\u522b\u591a\u79cd\u8bcd\u4e49\u4e0e\u624b\u8bed\u7b26\u53f7\u7684\u5bf9\u5e94\u7c7b\u578b\uff0c\u76f8\u8f83\u4f20\u7edf\u7684\u7cbe\u786e\u5339\u914d\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bc6\u522b\u51c6\u786e\u7387\u3002", "conclusion": "\u57fa\u4e8e\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u8ba1\u7b97\u65b9\u6cd5\u4f18\u4e8e\u7cbe\u786e\u5339\u914d\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u8de8\u6a21\u6001\u8bcd\u4e49\u5bf9\u5e94\u5173\u7cfb\uff0c\u6709\u52a9\u4e8e\u4e30\u5bcc\u624b\u8bed\u8bcd\u5178\u8d44\u6e90\u3002\u9996\u4e2a\u6570\u636e\u96c6\u548c\u4ee3\u7801\u516c\u5f00\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2602.14611", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14611", "abs": "https://arxiv.org/abs/2602.14611", "authors": ["Shirin Pirouzkhah", "Pavl\u00edna Wurzel Gon\u00e7alves", "Alberto Bacchelli"], "title": "The Value of Effective Pull Request Description", "comment": null, "summary": "In the pull-based development model, code contributions are submitted as pull requests (PRs) to undergo reviews and approval by other developers with the goal of being merged into the code base. A PR can be supported by a description, whose role has not yet been systematically investigated. To fill in this gap, we conducted a mixed-methods empirical study of PR descriptions. We conducted a grey literature review of guidelines on writing PR descriptions and derived a taxonomy of eight recommended elements. Using this taxonomy, we analyzed 80K GitHub PRs across 156 projects and five programming languages to assess associations between these elements and code review outcomes (e.g., merge decision, latency, first response time, review comments, and review iteration cycles). To complement these results, we surveyed 64 developers about the perceived importance of each element. Finally, we analyzed which submission-time factors predict whether PRs include a description and which elements they contain. We found that developers view PR descriptions as important, but their elements matter differently: purpose and code explanations are valued by developers for preserving the rationale and history of changes, while stating the desired feedback type best predicts change acceptance and reviewer engagement. PR descriptions are also more common in mature projects and complex changes, suggesting they are written when most useful rather than as a formality.", "AI": {"tldr": "\u7814\u7a76\u7cfb\u7edf\u63ed\u793a\u4e86PR\u63cf\u8ff0\u5143\u7d20\u5bf9\u5ba1\u67e5\u6548\u679c\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u6839\u636e\u5185\u5bb9\u7cbe\u51c6\u64b0\u5199PR\u63cf\u8ff0\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u62c9\u53d6\u8bf7\u6c42\uff08PR\uff09\u4f5c\u4e3a\u4ee3\u7801\u8d21\u732e\u7684\u5f62\u5f0f\uff0c\u5176\u63cf\u8ff0\u7684\u4f5c\u7528\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\uff0c\u4e9f\u9700\u660e\u786ePR\u63cf\u8ff0\u5bf9\u4ee3\u7801\u5ba1\u67e5\u7ed3\u679c\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7070\u8272\u6587\u732e\u56de\u987e\u5f52\u7eb3\u516b\u79cdPR\u63cf\u8ff0\u5efa\u8bae\u5143\u7d20\uff0c\u5206\u6790\u4e86\u8de8156\u4e2a\u9879\u76ee\u548c\u4e94\u79cd\u7f16\u7a0b\u8bed\u8a00\u76848\u4e07\u6761GitHub PR\u6570\u636e\uff0c\u7ed3\u5408\u5f00\u53d1\u8005\u8c03\u67e5\uff0c\u63a2\u8ba8\u5404\u5143\u7d20\u4e0e\u5ba1\u67e5\u7ed3\u679c\u7684\u5173\u8054\u548cPR\u63cf\u8ff0\u7684\u51b3\u5b9a\u56e0\u7d20\u3002", "result": "\u53d1\u73b0PR\u63cf\u8ff0\u5143\u7d20\u5728\u5f00\u53d1\u8005\u773c\u4e2d\u91cd\u8981\u6027\u4e0d\u540c\uff0c\u76ee\u7684\u548c\u4ee3\u7801\u89e3\u91ca\u6709\u52a9\u4e8e\u4f20\u9012\u53d8\u66f4\u7684\u7406\u7531\u548c\u5386\u53f2\uff0c\u58f0\u660e\u671f\u671b\u53cd\u9988\u7c7b\u578b\u6700\u80fd\u9884\u6d4bPR\u88ab\u63a5\u53d7\u548c\u5ba1\u67e5\u8005\u53c2\u4e0e\u5ea6\uff1bPR\u63cf\u8ff0\u5728\u6210\u719f\u9879\u76ee\u53ca\u590d\u6742\u66f4\u6539\u4e2d\u66f4\u5e38\u89c1\u3002", "conclusion": "PR\u63cf\u8ff0\u5bf9\u4ee3\u7801\u5ba1\u67e5\u5177\u6709\u5b9e\u9645\u4ef7\u503c\uff0c\u4e0d\u662f\u5f62\u5f0f\u4e3b\u4e49\uff0c\u7279\u5b9a\u63cf\u8ff0\u5143\u7d20\u80fd\u663e\u8457\u5f71\u54cd\u5ba1\u67e5\u51b3\u7b56\u548c\u6548\u7387\uff0c\u5e94\u4e88\u91cd\u89c6\u548c\u5408\u7406\u7f16\u5199\u3002"}}
{"id": "2602.13793", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13793", "abs": "https://arxiv.org/abs/2602.13793", "authors": ["Yangyang Zhang", "Zilong Wang", "Jianbo Xu", "Yongqi Chen", "Chu Han", "Zhihao Zhang", "Shuai Liu", "Hui Li", "Huiping Zhang", "Ziqi Liu", "Jiaxin Chen", "Jun Zhu", "Zheng Feng", "Hao Wen", "Xingzhu Ju", "Yanping Zhong", "Yunqiu Zhang", "Jie Duan", "Jun Li", "Dongsheng Li", "Weijie Wang", "Haiyan Zhu", "Wei Jiang", "Xiaohua Wu", "Shuo Wang", "Haiming Li", "Qinhao Guo"], "title": "OMGs: A multi-agent system supporting MDT decision-making across the ovarian tumour care continuum", "comment": "27 pages, 5 figures, 1 table", "summary": "Ovarian tumour management has increasingly relied on multidisciplinary tumour board (MDT) deliberation to address treatment complexity and disease heterogeneity. However, most patients worldwide lack access to timely expert consensus, particularly in resource-constrained centres where MDT resources are scarce or unavailable. Here we present OMGs (Ovarian tumour Multidisciplinary intelligent aGent System), a multi-agent AI framework where domain-specific agents deliberate collaboratively to integrate multidisciplinary evidence and generate MDT-style recommendations with transparent rationales. To systematically evaluate MDT recommendation quality, we developed SPEAR (Safety, Personalization, Evidence, Actionability, Robustness) and validated OMGs across diverse clinical scenarios spanning the care continuum. In multicentre re-evaluation, OMGs achieved performance comparable to expert MDT consensus ($4.45 \\pm 0.30$ versus $4.53 \\pm 0.23$), with higher Evidence scores (4.57 versus 3.92). In prospective multicentre evaluation (59 patients), OMGs demonstrated high concordance with routine MDT decisions. Critically, in paired human-AI studies, OMGs most substantially enhanced clinicians' recommendations in Evidence and Robustness, the dimensions most compromised when multidisciplinary expertise is unavailable. These findings suggest that multi-agent deliberative systems can achieve performance comparable to expert MDT consensus, with potential to expand access to specialized oncology expertise in resource-limited settings.", "AI": {"tldr": "OMGs\u591a\u4ee3\u7406AI\u7cfb\u7edf\u6709\u6548\u6a21\u62df\u5375\u5de2\u80bf\u7624MDT\u8ba8\u8bba\uff0c\u8868\u73b0\u4f18\u5f02\uff0c\u53ef\u52a9\u529b\u8d44\u6e90\u532e\u4e4f\u5730\u533a\u83b7\u53d6\u4e13\u5bb6\u6cbb\u7597\u5efa\u8bae\u3002", "motivation": "\u5375\u5de2\u80bf\u7624\u7ba1\u7406\u4f9d\u8d56\u591a\u5b66\u79d1\u80bf\u7624\u59d4\u5458\u4f1a\uff08MDT\uff09\u8ba8\u8bba\uff0c\u4ee5\u5e94\u5bf9\u6cbb\u7597\u590d\u6742\u6027\u548c\u75be\u75c5\u5f02\u8d28\u6027\uff0c\u4f46\u8d44\u6e90\u6709\u9650\u7684\u4e2d\u5fc3\u7f3a\u4e4f\u53ca\u65f6\u7684\u4e13\u5bb6\u5171\u8bc6\u3002", "method": "\u63d0\u51fa\u4e86OMGs\uff08\u5375\u5de2\u80bf\u7624\u591a\u5b66\u79d1\u667a\u80fd\u4ee3\u7406\u7cfb\u7edf\uff09\uff0c\u4e00\u4e2a\u591a\u4ee3\u7406\u4eba\u5de5\u667a\u80fd\u6846\u67b6\uff0c\u901a\u8fc7\u9886\u57df\u7279\u5b9a\u4ee3\u7406\u534f\u540c\u6574\u5408\u591a\u5b66\u79d1\u8bc1\u636e\uff0c\u751f\u6210\u5e26\u6709\u900f\u660e\u7406\u7531\u7684MDT\u5f0f\u5efa\u8bae\uff1b\u540c\u65f6\u5f00\u53d1SPEAR\u8bc4\u4f30\u4f53\u7cfb\u8bc4\u4ef7\u63a8\u8350\u8d28\u91cf\u3002", "result": "OMGs\u5728\u591a\u4e2d\u5fc3\u91cd\u65b0\u8bc4\u4f30\u4e2d\u8868\u73b0\u4e0e\u4e13\u5bb6MDT\u5171\u8bc6\u76f8\u5f53\uff0c\u4e14\u8bc1\u636e\u8bc4\u5206\u66f4\u9ad8\uff1b\u524d\u77bb\u6027\u591a\u4e2d\u5fc3\u8bc4\u4f30\u4e2d\u4e0e\u5e38\u89c4MDT\u51b3\u7b56\u9ad8\u5ea6\u4e00\u81f4\uff1b\u5728\u4eba\u673a\u914d\u5bf9\u7814\u7a76\u4e2d\u663e\u8457\u63d0\u5347\u533b\u751f\u5efa\u8bae\u7684\u8bc1\u636e\u6027\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u591a\u4ee3\u7406\u8ba8\u8bba\u7cfb\u7edf\u53ef\u8fbe\u5230\u4e13\u5bb6MDT\u5171\u8bc6\u7684\u6c34\u5e73\uff0c\u6709\u6f5c\u529b\u5728\u8d44\u6e90\u6709\u9650\u73af\u5883\u4e2d\u6269\u5c55\u4e13\u79d1\u80bf\u7624\u5b66\u4e13\u5bb6\u7684\u53ef\u53ca\u6027\u3002"}}
{"id": "2602.14690", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14690", "abs": "https://arxiv.org/abs/2602.14690", "authors": ["Matthias Galster", "Seyedmoein Mohsenimofidi", "Jai Lal Lulla", "Muhammad Auwal Abubakar", "Christoph Treude", "Sebastian Baltes"], "title": "Configuring Agentic AI Coding Tools: An Exploratory Study", "comment": "9 pages, 7 figures, 3 tables", "summary": "Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanisms and, in an empirical study of 2,926 GitHub repositories, examine whether and how they are adopted. We then explore Context Files, Skills, and Subagents, that is, three mechanisms available across tools, in more detail. Our findings reveal three trends. First, Context Files dominate the configuration landscape and are often the sole mechanism in a repository, with AGENTS$.$md emerging as an interoperable standard across tools. Second, advanced mechanisms such as Skills and Subagents are only shallowly adopted: most repositories define only one or two artifacts, and Skills predominantly rely on static instructions rather than executable workflows. Third, distinct configuration cultures are forming around different tools, with Claude Code users employing the broadest range of mechanisms. These findings establish an empirical baseline for longitudinal and experimental research on how configuration strategies evolve and affect agent performance as agentic AI coding tools mature.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u591a\u6b3e\u667a\u80fd\u4ee3\u7406\u7f16\u7a0b\u5de5\u5177\u7684\u914d\u7f6e\u673a\u5236\u53ca\u5176\u91c7\u7528\u60c5\u51b5\uff0c\u53d1\u73b0Context Files\u6700\u5e38\u7528\uff0cSkills\u548cSubagents\u91c7\u7528\u4e0d\u6df1\uff0c\u4e14\u4e0d\u540c\u5de5\u5177\u5f62\u6210\u4e0d\u540c\u914d\u7f6e\u6587\u5316\u3002", "motivation": "\u968f\u7740\u667a\u80fd\u4ee3\u7406\u7f16\u7a0b\u5de5\u5177\u81ea\u52a8\u5316\u5f00\u53d1\u4efb\u52a1\u80fd\u529b\u63d0\u5347\uff0c\u7814\u7a76\u5176\u914d\u7f6e\u673a\u5236\u53ca\u91c7\u7528\u60c5\u51b5\u6709\u52a9\u4e8e\u7406\u89e3\u914d\u7f6e\u7b56\u7565\u5982\u4f55\u53d1\u5c55\u53ca\u5176\u5bf9\u5de5\u5177\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u516b\u79cd\u914d\u7f6e\u673a\u5236\uff0c\u7ed3\u5408\u5bf92926\u4e2aGitHub\u4ed3\u5e93\u7684\u5b9e\u8bc1\u8c03\u67e5\uff0c\u91cd\u70b9\u6df1\u5165\u7814\u7a76\u4e86Context Files\u3001Skills\u548cSubagents\u4e09\u79cd\u673a\u5236\u7684\u91c7\u7528\u60c5\u51b5\u53ca\u7279\u70b9\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u591a\u79cd\u667a\u80fd\u4ee3\u7406\u7f16\u7a0b\u5de5\u5177\uff08\u5305\u62ecClaude Code\u3001GitHub Copilot\u3001Cursor\u3001Gemini\u548cCodex\uff09\u7684\u914d\u7f6e\u673a\u5236\uff0c\u8bc6\u522b\u51fa\u516b\u79cd\u914d\u7f6e\u673a\u5236\uff0c\u5e76\u901a\u8fc7\u5bf92926\u4e2aGitHub\u4ed3\u5e93\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u63a2\u8ba8\u4e86\u8fd9\u4e9b\u673a\u5236\u7684\u91c7\u7528\u60c5\u51b5\u3002\u91cd\u70b9\u5206\u6790\u4e86\u8de8\u5de5\u5177\u901a\u7528\u7684\u4e09\u79cd\u673a\u5236\uff1aContext Files\u3001Skills\u548cSubagents\u3002\u7814\u7a76\u53d1\u73b0Context Files\u662f\u6700\u4e3b\u8981\u7684\u914d\u7f6e\u65b9\u5f0f\uff0c\u4e14\u7ecf\u5e38\u662f\u4ed3\u5e93\u4e2d\u552f\u4e00\u7684\u673a\u5236\uff0c\u5176\u4e2dAGENTS.md\u6210\u4e3a\u591a\u5de5\u5177\u95f4\u4e92\u64cd\u4f5c\u7684\u6807\u51c6\u3002Skills\u548cSubagents\u91c7\u7528\u8f83\u5c11\uff0c\u591a\u6570\u4ed3\u5e93\u5b9a\u4e49\u7684\u76f8\u5173\u6587\u4ef6\u6570\u91cf\u6709\u9650\uff0c\u4e14Skills\u591a\u4e3a\u9759\u6001\u8bf4\u660e\u800c\u975e\u53ef\u6267\u884c\u6d41\u7a0b\u3002\u4e0d\u540c\u5de5\u5177\u7528\u6237\u5f62\u6210\u4e86\u4e0d\u540c\u7684\u914d\u7f6e\u6587\u5316\uff0cClaude Code\u7528\u6237\u4f7f\u7528\u7684\u914d\u7f6e\u673a\u5236\u6700\u4e3a\u4e30\u5bcc\u3002\u672c\u6587\u4e3a\u540e\u7eed\u5173\u4e8e\u914d\u7f6e\u7b56\u7565\u5982\u4f55\u6f14\u53d8\u53ca\u5176\u5bf9\u667a\u80fd\u4ee3\u7406\u6027\u80fd\u5f71\u54cd\u7684\u7eb5\u5411\u548c\u5b9e\u9a8c\u6027\u7814\u7a76\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u57fa\u7ebf\u3002", "conclusion": "Context Files\u662f\u914d\u7f6e\u7684\u4e3b\u6d41\u65b9\u5f0f\uff0cAGENTS.md\u6210\u4e3a\u591a\u5de5\u5177\u6807\u51c6\uff1bSkills\u548cSubagents\u91c7\u7528\u8f83\u6d45\uff1b\u4e0d\u540c\u5de5\u5177\u7528\u6237\u5f62\u6210\u5dee\u5f02\u5316\u914d\u7f6e\u6587\u5316\uff0c\u8fd9\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u57fa\u7ebf\u3002"}}
{"id": "2602.13816", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13816", "abs": "https://arxiv.org/abs/2602.13816", "authors": ["Muneef Y. Alsawsh", "Mohammed Q. Shormani"], "title": "The acquisition of English irregular inflections by Yemeni L1 Arabic learners: A Universal Grammar approach", "comment": "19 pages, 3 Tables", "summary": "This study examines the acquisition of English irregular inflections by Yemeni learners of English as a second language (L2), utilizing a Universal Grammar (UG) approach. Within the UG approach, the study considers Feature Reassembly Hypothesis (FRH) (Lardiere, 2008, 2009) part of UG, focusing on the roles of first language (L1) transfer and L2 developmental influence. It analyzes learner errors across two developmental stages. Stage 1 data reveal a dominant influence of L1 transfer, particularly in phonological and structural mismatches, while stage 2 data demonstrate increased learner sensitivity to UG properties and morphological reconfiguration toward the target language. Findings reveal that errors in irregular inflectional morphology are attributed to both interlingual and intralingual sources, with overgeneralization of L2 rules as a common developmental strategy. Statistical analysis, including a one-way ANOVA, indicates significant improvement in the production of well-formed irregular inflections from stage 1 to stage 2, underscoring learners' continued access to UG. However, persistent difficulties with consonant change, zero-morpheme, and -a plural inflections suggest that limited exposure, ineffective input modeling, and insufficient instructional quality constrain full UG access. The study concludes that while L1 transfer and L2 developmental factors influence initial stages of acquisition, appropriate linguistic input and instruction are critical for facilitating UG-driven feature reassembly in adult L2 learners.", "AI": {"tldr": "\u4e5f\u95e8\u82f1\u8bed\u5b66\u4e60\u8005\u4e60\u5f97\u4e0d\u89c4\u5219\u8bcd\u5f62\u53d8\u5316\u53d7\u7b2c\u4e00\u8bed\u8a00\u8fc1\u79fb\u53ca\u53d1\u5c55\u9636\u6bb5\u5f71\u54cd\uff0c\u9636\u6bb5\u6027\u8868\u73b0\u51fa\u666e\u904d\u8bed\u6cd5\u7279\u5f81\uff0c\u6559\u5b66\u548c\u8f93\u5165\u8d28\u91cf\u5bf9\u5b66\u4e60\u6210\u6548\u5173\u952e\u3002", "motivation": "\u63a2\u8ba8\u4e5f\u95e8\u82f1\u8bed\u5b66\u4e60\u8005\u4f5c\u4e3a\u7b2c\u4e8c\u8bed\u8a00\u5b66\u4e60\u8005\u5728\u82f1\u8bed\u4e0d\u89c4\u5219\u8bcd\u5f62\u53d8\u5316\u4e60\u5f97\u4e2d\u7684\u8868\u73b0\uff0c\u57fa\u4e8e\u666e\u904d\u8bed\u6cd5\u7406\u8bba\uff0c\u7279\u522b\u662f\u7279\u5f81\u91cd\u7ec4\u5047\u8bf4\uff0c\u5206\u6790\u7b2c\u4e00\u8bed\u8a00\u8fc1\u79fb\u53ca\u7b2c\u4e8c\u8bed\u8a00\u53d1\u5c55\u5f71\u54cd\u3002", "method": "\u5229\u7528\u666e\u904d\u8bed\u6cd5\u7684\u7279\u5f81\u91cd\u7ec4\u5047\u8bf4\uff0c\u5206\u6790\u4e24\u9636\u6bb5\u5b66\u4e60\u8005\u9519\u8bef\uff0c\u7ed3\u5408\u7edf\u8ba1\u5b66\u65b9\u6cd5\u8bc4\u4f30\u5b66\u4e60\u8fdb\u6b65\u3002", "result": "\u7b2c\u4e00\u9636\u6bb5\u9519\u8bef\u4e3b\u8981\u6e90\u4e8e\u7b2c\u4e00\u8bed\u8a00\u8fc1\u79fb\uff0c\u5c24\u5176\u662f\u97f3\u97f5\u548c\u7ed3\u6784\u4e0d\u5339\u914d\uff1b\u7b2c\u4e8c\u9636\u6bb5\u8868\u73b0\u51fa\u5bf9\u666e\u904d\u8bed\u6cd5\u7279\u6027\u7684\u654f\u611f\u53ca\u5f62\u6001\u7ed3\u6784\u671d\u76ee\u6807\u8bed\u8a00\u8c03\u6574\u3002\u9519\u8bef\u6765\u6e90\u5305\u62ec\u8de8\u8bed\u9645\u548c\u8bed\u5185\u56e0\u7d20\uff0c\u8fc7\u5ea6\u6cdb\u5316\u662f\u5e38\u89c1\u7b56\u7565\u3002\u7edf\u8ba1\u663e\u793a\u4ece\u7b2c\u4e00\u9636\u6bb5\u5230\u7b2c\u4e8c\u9636\u6bb5\uff0c\u6709\u5f62\u6210\u6b63\u786e\u4e0d\u89c4\u5219\u8bcd\u5f62\u7684\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u7b2c\u4e00\u8bed\u8a00\u8fc1\u79fb\u548c\u7b2c\u4e8c\u8bed\u8a00\u53d1\u5c55\u56e0\u7d20\u5f71\u54cd\u521d\u671f\u4e60\u5f97\uff0c\u4f46\u5b8c\u6574\u7684\u666e\u904d\u8bed\u6cd5\u8bbf\u95ee\u4f9d\u8d56\u4e8e\u5145\u5206\u7684\u8bed\u8a00\u8f93\u5165\u548c\u6709\u6548\u6559\u5b66\u3002\u97f3\u53d8\u3001\u96f6\u5f62\u6001\u548c-a\u590d\u6570\u5f62\u5f0f\u7b49\u4ecd\u5b58\u5728\u56f0\u96be\uff0c\u63d0\u793a\u9700\u8981\u6539\u8fdb\u6559\u5b66\u548c\u8f93\u5165\u8d28\u91cf\u4ee5\u4fc3\u8fdb\u7279\u5f81\u91cd\u7ec4\u3002"}}
{"id": "2602.14878", "categories": ["cs.SE", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.14878", "abs": "https://arxiv.org/abs/2602.14878", "authors": ["Mohammed Mehedi Hasan", "Hao Li", "Gopi Krishnan Rajbahadur", "Bram Adams", "Ahmed E. Hassan"], "title": "Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions", "comment": null, "summary": "The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequences in the MCP ecosystem remain unclear.\n  To address this, we conduct the first large-scale empirical study of 856 tools spread across 103 MCP servers, assessing their description quality and their impact on agent performance. We identify six components of tool descriptions from the literature, develop a scoring rubric utilizing these components, then formalize tool description smells based on this rubric. By operationalizing this rubric through an FM-based scanner, we find that 97.1% of the analyzed tool descriptions contain at least one smell, with 56% failing to state their purpose clearly. While augmenting these descriptions for all components improves task success rates by a median of 5.85 percentage points and improves partial goal completion by 15.12%, it also increases the number of execution steps by 67.46% and regresses performance in 16.67% of cases. These findings highlight a trade-off between agent performance and cost, as well as the context sensitivity of the performance gain. Furthermore, component ablations show that compact variants of different component combinations often preserve behavioral reliability while reducing unnecessary token overhead, enabling more efficient use of the FM context window and lower execution costs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5bf9Model Context Protocol\uff08MCP\uff09\u751f\u6001\u4e2d856\u4e2a\u5de5\u5177\u7684\u63cf\u8ff0\u8d28\u91cf\u53ca\u5176\u5bf9\u57fa\u4e8eFoundation Model\u4ee3\u7406\u6027\u80fd\u7684\u5f71\u54cd\u8fdb\u884c\u4e86\u5b9e\u8bc1\u7814\u7a76\uff0c\u53d1\u73b0\u7edd\u5927\u591a\u6570\u5de5\u5177\u63cf\u8ff0\u5b58\u5728\u7f3a\u9677\uff0c\u6539\u8fdb\u63cf\u8ff0\u80fd\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u4f46\u4e5f\u589e\u52a0\u6267\u884c\u6b65\u9aa4\uff0c\u63ed\u793a\u4e86\u6027\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002", "motivation": "\u7531\u4e8eMCP\u751f\u6001\u4e2d\u5de5\u5177\u63cf\u8ff0\u4ee5\u81ea\u7136\u8bed\u8a00\u5f62\u5f0f\u5448\u73b0\uff0c\u63cf\u8ff0\u7684\u8d28\u91cf\u76f4\u63a5\u5f71\u54cdFM\u4ee3\u7406\u9009\u62e9\u6b63\u786e\u5de5\u5177\u548c\u53c2\u6570\u7684\u80fd\u529b\uff0c\u76ee\u524d\u8fd9\u65b9\u9762\u7684\u7f3a\u9677\u666e\u904d\u5b58\u5728\u4f46\u5c1a\u672a\u88ab\u7cfb\u7edf\u7814\u7a76\u3002", "method": "\u4ece\u6587\u732e\u4e2d\u63d0\u53d6\u5de5\u5177\u63cf\u8ff0\u7684\u516d\u4e2a\u7ec4\u6210\u90e8\u5206\uff0c\u8bbe\u8ba1\u8bc4\u5206\u6807\u51c6\u5e76\u5b9a\u4e49\u63cf\u8ff0\u7f3a\u9677\uff0c\u4f7f\u7528\u57fa\u4e8eFM\u7684\u626b\u63cf\u5668\u5bf9103\u4e2aMCP\u670d\u52a1\u5668\u7684856\u4e2a\u5de5\u5177\u63cf\u8ff0\u8fdb\u884c\u8d28\u91cf\u8bc4\u4f30\u548c\u7f3a\u9677\u68c0\u6d4b\uff0c\u968f\u540e\u901a\u8fc7\u6539\u8fdb\u63cf\u8ff0\u8fdb\u884c\u6027\u80fd\u5bf9\u6bd4\u5b9e\u9a8c\u3002", "result": "97.1%\u7684\u5de5\u5177\u63cf\u8ff0\u5b58\u5728\u81f3\u5c11\u4e00\u79cd\u7f3a\u9677\uff0c56%\u672a\u660e\u786e\u8bf4\u660e\u5de5\u5177\u76ee\u7684\uff1b\u6539\u8fdb\u63cf\u8ff0\u80fd\u63d0\u5347\u4efb\u52a1\u6210\u529f\u7387\u4e2d\u4f4d\u65705.85\u4e2a\u767e\u5206\u70b9\uff0c\u90e8\u5206\u76ee\u6807\u5b8c\u6210\u7387\u63d0\u534715.12%\uff0c\u4f46\u6267\u884c\u6b65\u9aa4\u589e\u52a067.46%\uff0c16.67%\u7684\u6848\u4f8b\u8868\u73b0\u4e0b\u964d\uff1b\u7ec4\u4ef6\u6d88\u878d\u5b9e\u9a8c\u8868\u660e\u7d27\u51d1\u63cf\u8ff0\u7248\u672c\u80fd\u5728\u4fdd\u8bc1\u53ef\u9760\u6027\u7684\u540c\u65f6\u964d\u4f4e\u6267\u884c\u6210\u672c\u3002", "conclusion": "\u6539\u8fdb\u5de5\u5177\u63cf\u8ff0\u7684\u8d28\u91cf\u80fd\u663e\u8457\u63d0\u5347FM\u4ee3\u7406\u7684\u4efb\u52a1\u5b8c\u6210\u7387\u548c\u90e8\u5206\u76ee\u6807\u7684\u8fbe\u6210\u5ea6\uff0c\u4f46\u4e5f\u4f1a\u5e26\u6765\u6267\u884c\u6b65\u9aa4\u589e\u52a0\u548c\u90e8\u5206\u6027\u80fd\u56de\u9000\uff0c\u8868\u73b0\u51fa\u6027\u80fd\u63d0\u5347\u4e0e\u6267\u884c\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\u3002"}}
{"id": "2602.13832", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13832", "abs": "https://arxiv.org/abs/2602.13832", "authors": ["Minyuan Ruan", "Ziyue Wang", "Kaiming Liu", "Yunghwei Lai", "Peng Li", "Yang Liu"], "title": "Beyond Words: Evaluating and Bridging Epistemic Divergence in User-Agent Interaction via Theory of Mind", "comment": null, "summary": "Large Language Models (LLMs) have developed rapidly and are widely applied to both general-purpose and professional tasks to assist human users. However, they still struggle to comprehend and respond to the true user needs when intentions and instructions are imprecisely conveyed, leading to a divergence between subjective user believes and true environment states. Resolving this epistemic divergence requires Theory of Mind (ToM), yet existing ToM evaluations for LLMs primarily focus on isolated belief inference, overlooking its functional utility in real-world interaction. To this end, we formalize ToM for LLMs as a mechanism for epistemic divergence detection and resolution, and propose a benchmark, \\benchname, to assess how models reconcile user beliefs and profiles in practice. Results across 11 leading models reveal a significant limitation to identify underlying cognitive gaps that impede task success. To bridge this gap, we further curate a trajectory-based ToM dataset linking belief tracking with task-related state inference. The model trained on this data via reinforcement learning shows consistent improvement in reasoning about user mental states, leading to enhanced downstream performance. Our work highlights the practical value of ToM as an essential interaction-level mechanism rather than as a standalone reasoning skill.", "AI": {"tldr": "\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u7406\u89e3\u7528\u6237\u610f\u56fe\u7684\u95ee\u9898\uff0c\u672c\u6587\u5f15\u5165\u7406\u8bba\u5fc3\u667a\u673a\u5236\uff0c\u901a\u8fc7\u8bbe\u8ba1Benchname\u57fa\u51c6\u548c\u65b0\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u63d0\u5347\u6a21\u578b\u63a8\u7406\u7528\u6237\u5fc3\u7406\u72b6\u6001\u7684\u80fd\u529b\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4efb\u52a1\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7406\u89e3\u548c\u54cd\u5e94\u7528\u6237\u771f\u5b9e\u9700\u6c42\u65f6\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u5728\u610f\u56fe\u548c\u6307\u4ee4\u8868\u8fbe\u4e0d\u7cbe\u786e\u7684\u60c5\u51b5\u4e0b\uff0c\u5bfc\u81f4\u7528\u6237\u4e3b\u89c2\u8ba4\u77e5\u548c\u5b9e\u9645\u73af\u5883\u72b6\u6001\u4e4b\u95f4\u4ea7\u751f\u8ba4\u77e5\u5dee\u5f02\u3002", "method": "\u5c06\u7406\u8bba\u5fc3\u667a\uff08ToM\uff09\u5f62\u5f0f\u5316\u4e3a\u68c0\u6d4b\u548c\u89e3\u51b3\u8ba4\u77e5\u5dee\u5f02\u7684\u673a\u5236\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u57fa\u51c6\uff08benchname\uff09\u7528\u4e8e\u6d4b\u8bd5\u6a21\u578b\u5982\u4f55\u8c03\u548c\u7528\u6237\u4fe1\u5ff5\u548c\u4e2a\u4eba\u4fe1\u606f\uff0c\u5e76\u6784\u5efa\u4e00\u4e2a\u57fa\u4e8e\u8f68\u8ff9\u7684ToM\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u6a21\u578b\u4ee5\u6539\u8fdb\u5bf9\u7528\u6237\u5fc3\u7406\u72b6\u6001\u7684\u63a8\u7406\u80fd\u529b\u3002", "result": "\u572811\u4e2a\u4e3b\u6d41\u6a21\u578b\u4e0a\u7684\u6d4b\u8bd5\u7ed3\u679c\u663e\u793a\uff0c\u5f53\u524d\u6a21\u578b\u5728\u8bc6\u522b\u8ba4\u77e5\u5dee\u5f02\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u3002\u7ecf\u8fc7\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u540e\uff0c\u6a21\u578b\u5728\u63a8\u7406\u7528\u6237\u5fc3\u7406\u72b6\u6001\u548c\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\u4e0a\u6709\u6301\u7eed\u63d0\u5347\u3002", "conclusion": "\u7406\u8bba\u5fc3\u667a\u5e94\u88ab\u89c6\u4e3a\u4e00\u79cd\u5b9e\u7528\u7684\u4ea4\u4e92\u673a\u5236\uff0c\u800c\u975e\u5b64\u7acb\u7684\u63a8\u7406\u6280\u80fd\uff0c\u5bf9\u4e8e\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u548c\u54cd\u5e94\u7528\u6237\u9700\u6c42\u5177\u6709\u91cd\u8981\u4ef7\u503c\u3002"}}
{"id": "2602.14955", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2602.14955", "abs": "https://arxiv.org/abs/2602.14955", "authors": ["Varun Nathan", "Shreyas Guha", "Ayush Kumar"], "title": "Tool-Aware Planning in Contact Center AI: Evaluating LLMs through Lineage-Guided Query Decomposition", "comment": null, "summary": "We present a domain-grounded framework and benchmark for tool-aware plan generation in contact centers, where answering a query for business insights, our target use case, requires decomposing it into executable steps over structured tools (Text2SQL (T2S)/Snowflake) and unstructured tools (RAG/transcripts) with explicit depends_on for parallelism. Our contributions are threefold: (i) a reference-based plan evaluation framework operating in two modes - a metric-wise evaluator spanning seven dimensions (e.g., tool-prompt alignment, query adherence) and a one-shot evaluator; (ii) a data curation methodology that iteratively refines plans via an evaluator->optimizer loop to produce high-quality plan lineages (ordered plan revisions) while reducing manual effort; and (iii) a large-scale study of 14 LLMs across sizes and families for their ability to decompose queries into step-by-step, executable, and tool-assigned plans, evaluated under prompts with and without lineage. Empirically, LLMs struggle on compound queries and on plans exceeding 4 steps (typically 5-15); the best total metric score reaches 84.8% (Claude-3-7-Sonnet), while the strongest one-shot match rate at the \"A+\" tier (Extremely Good, Very Good) is only 49.75% (o3-mini). Plan lineage yields mixed gains overall but benefits several top models and improves step executability for many. Our results highlight persistent gaps in tool-understanding, especially in tool-prompt alignment and tool-usage completeness, and show that shorter, simpler plans are markedly easier. The framework and findings provide a reproducible path for assessing and improving agentic planning with tools for answering data-analysis queries in contact-center settings.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u547c\u53eb\u4e2d\u5fc3\u5de5\u5177\u611f\u77e5\u8ba1\u5212\u751f\u6210\u7684\u9886\u57df\u6846\u67b6\u548c\u57fa\u51c6\uff0c\u5173\u6ce8\u4e8e\u5c06\u67e5\u8be2\u62c6\u89e3\u4e3a\u53ef\u6267\u884c\u6b65\u9aa4\u5e76\u5229\u7528\u7ed3\u6784\u5316\u548c\u975e\u7ed3\u6784\u5316\u5de5\u5177\u8fdb\u884c\u5904\u7406\u3002", "motivation": "\u547c\u53eb\u4e2d\u5fc3\u6570\u636e\u5206\u6790\u67e5\u8be2\u9700\u4f9d\u8d56\u591a\u79cd\u7ed3\u6784\u5316\u4e0e\u975e\u7ed3\u6784\u5316\u5de5\u5177\u534f\u540c\u6267\u884c\uff0c\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u6709\u6548\u7684\u5de5\u5177\u611f\u77e5\u8ba1\u5212\u751f\u6210\u4e0e\u8bc4\u4f30\u673a\u5236\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1\u53cc\u6a21\u53c2\u8003\u8ba1\u5212\u8bc4\u4f30\u6846\u67b6\u3001\u8fed\u4ee3\u4f18\u5316\u7684\u6570\u636e\u7b56\u5212\u65b9\u6cd5\uff0c\u4ee5\u53ca\u5bf914\u4e2a\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5927\u89c4\u6a21\u5b9e\u8bc1\u8bc4\u6d4b\uff0c\u5206\u6790\u6a21\u578b\u7684\u8ba1\u5212\u751f\u6210\u80fd\u529b\u3002", "result": "\u6700\u4f73\u6a21\u578b\u7684\u7efc\u5408\u6307\u6807\u5f97\u5206\u4e3a84.8%\uff0c\u4f46\u9876\u7ea7\u4e00\u6b21\u5339\u914d\u7387\u4ec549.75%\uff1b\u8ba1\u5212\u8c31\u7cfb\u5bf9\u6a21\u578b\u6027\u80fd\u5f71\u54cd\u4e0d\u4e00\uff0c\u4f46\u53ef\u63d0\u5347\u6b65\u9aa4\u6267\u884c\u529b\uff0c\u4e14\u8f83\u77ed\u7b80\u6d01\u8ba1\u5212\u66f4\u6613\u88ab\u6267\u884c\u3002", "conclusion": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u67e5\u8be2\u548c\u591a\u6b65\u9aa4\u8ba1\u5212\u62c6\u89e3\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5c24\u5176\u5728\u5de5\u5177\u7406\u89e3\u548c\u4f7f\u7528\u5b8c\u6574\u6027\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\u3002"}}
{"id": "2602.13836", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13836", "abs": "https://arxiv.org/abs/2602.13836", "authors": ["Miles Williams", "Young D. Kwon", "Rui Li", "Alexandros Kouris", "Stylianos I. Venieris"], "title": "Speculative Decoding with a Speculative Vocabulary", "comment": "Under review", "summary": "Speculative decoding has rapidly emerged as a leading approach for accelerating language model (LM) inference, as it offers substantial speedups while yielding identical outputs. This relies upon a small draft model, tasked with predicting the outputs of the target model. State-of-the-art speculative decoding methods use a draft model consisting of a single decoder layer and output embedding matrix, with the latter dominating drafting time for the latest LMs. Recent work has sought to address this output distribution bottleneck by reducing the vocabulary of the draft model. Although this can improve throughput, it compromises speculation effectiveness when the target token is out-of-vocabulary. In this paper, we argue for vocabulary speculation as an alternative to a reduced vocabulary. We propose SpecVocab, an efficient and effective method that selects a vocabulary subset per decoding step. Across a variety of tasks, we demonstrate that SpecVocab can achieve a higher acceptance length than state-of-the-art speculative decoding approach, EAGLE-3. Notably, this yields up to an 8.1% increase in average throughput over EAGLE-3.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faSpecVocab\u65b9\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8bcd\u6c47\u5b50\u96c6\u9009\u62e9\uff0c\u63d0\u9ad8\u6295\u673a\u89e3\u7801\u901f\u5ea6\u548c\u51c6\u786e\u6027\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5EAGLE-3\u3002", "motivation": "\u5f53\u524d\u7684\u6295\u673a\u89e3\u7801\u65b9\u6cd5\u867d\u7136\u52a0\u901f\u4e86\u8bed\u8a00\u6a21\u578b\u63a8\u65ad\uff0c\u4f46\u53d7\u9650\u4e8e\u8f93\u51fa\u8bcd\u6c47\u5206\u5e03\u74f6\u9888\uff0c\u964d\u4f4e\u8bcd\u6c47\u8868\u867d\u63d0\u5347\u541e\u5410\u91cf\uff0c\u4f46\u964d\u4f4e\u4e86\u63a8\u6d4b\u6548\u679c\u3002", "method": "\u63d0\u51faSpecVocab\u65b9\u6cd5\uff0c\u6bcf\u6b65\u89e3\u7801\u65f6\u52a8\u6001\u9009\u62e9\u8bcd\u6c47\u5b50\u96c6\uff0c\u4f18\u5316\u8bcd\u6c47\u8868\u731c\u6d4b\u3002", "result": "SpecVocab\u5728\u591a\u4efb\u52a1\u4e2d\u8f83\u5148\u8fdb\u6295\u673a\u89e3\u7801\u65b9\u6cd5EAGLE-3\u62e5\u6709\u66f4\u957f\u7684\u63a5\u53d7\u957f\u5ea6\uff0c\u541e\u5410\u91cf\u63d0\u5347\u6700\u9ad8\u8fbe8.1%\u3002", "conclusion": "SpecVocab\u6709\u6548\u63d0\u5347\u4e86\u63a8\u6d4b\u89e3\u7801\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u514b\u670d\u4e86\u51cf\u5c11\u8bcd\u6c47\u8868\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2602.13840", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13840", "abs": "https://arxiv.org/abs/2602.13840", "authors": ["Yuhan Cheng", "Hancheng Ye", "Hai Helen Li", "Jingwei Sun", "Yiran Chen"], "title": "PrivAct: Internalizing Contextual Privacy Preservation via Multi-Agent Preference Training", "comment": null, "summary": "Large language model (LLM) agents are increasingly deployed in personalized tasks involving sensitive, context-dependent information, where privacy violations may arise in agents' action due to the implicitness of contextual privacy. Existing approaches rely on external, inference-time interventions which are brittle, scenario-specific, and may expand the privacy attack surface. We propose PrivAct, a contextual privacy-aware multi-agent learning framework that internalizes contextual privacy preservation directly into models' generation behavior for privacy-compliant agentic actions. By embedding privacy preferences into each agent, PrivAct enhances system-wide contextual integrity while achieving a more favorable privacy-helpfulness tradeoff. Experiments across multiple LLM backbones and benchmarks demonstrate consistent improvements in contextual privacy preservation, reducing leakage rates by up to 12.32% while maintaining comparable helpfulness, as well as zero-shot generalization and robustness across diverse multi-agent topologies. Code is available at https://github.com/chengyh23/PrivAct.", "AI": {"tldr": "PrivAct\u6846\u67b6\u901a\u8fc7\u5185\u5d4c\u9690\u79c1\u504f\u597d\uff0c\u5b9e\u73b0LLM\u591a\u667a\u80fd\u4f53\u7684\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\uff0c\u6709\u6548\u964d\u4f4e\u9690\u79c1\u6cc4\u9732\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5904\u7406\u654f\u611f\u4e14\u4f9d\u8d56\u4e0a\u4e0b\u6587\u7684\u4fe1\u606f\uff0c\u73b0\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u8106\u5f31\u7684\u5916\u90e8\u5e72\u9884\uff0c\u5b58\u5728\u9690\u79c1\u6cc4\u9732\u98ce\u9669\uff0c\u4e9f\u9700\u5185\u7f6e\u9690\u79c1\u611f\u77e5\u673a\u5236\u4ee5\u63d0\u5347\u5b89\u5168\u6027\u3002", "method": "\u5c06\u9690\u79c1\u504f\u597d\u5d4c\u5165\u6bcf\u4e2a\u4ee3\u7406\u6a21\u578b\u7684\u751f\u6210\u884c\u4e3a\u4e2d\uff0c\u5229\u7528\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u6846\u67b6\u5b9e\u73b0\u9690\u79c1\u5185\u7f6e\u4fdd\u62a4\uff0c\u907f\u514d\u4f9d\u8d56\u5916\u90e8\u63a8\u65ad\u65f6\u5e72\u9884\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86PrivAct\uff0c\u4e00\u79cd\u9762\u5411\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u7684\u4e0a\u4e0b\u6587\u9690\u79c1\u611f\u77e5\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u4e2a\u6027\u5316\u4efb\u52a1\u4e2d\u9690\u79c1\u6cc4\u9732\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u5c06\u9690\u79c1\u504f\u597d\u5185\u5d4c\u5230\u6bcf\u4e2a\u4ee3\u7406\u6a21\u578b\u7684\u751f\u6210\u884c\u4e3a\u4e2d\uff0c\u5b9e\u73b0\u5bf9\u4e0a\u4e0b\u6587\u9690\u79c1\u7684\u5185\u90e8\u4fdd\u62a4\uff0c\u63d0\u5347\u7cfb\u7edf\u6574\u4f53\u7684\u9690\u79c1\u5b8c\u6574\u6027\u5e76\u4f18\u5316\u9690\u79c1\u4e0e\u5e2e\u52a9\u6027\u4e4b\u95f4\u7684\u6743\u8861\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0cPrivAct\u5728\u591a\u4e2aLLM\u6a21\u578b\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u663e\u8457\u51cf\u5c11\u4e86\u9690\u79c1\u6cc4\u9732\u7387\uff08\u6700\u9ad8\u964d\u4f4e12.32%\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u76f8\u5f53\u7684\u4efb\u52a1\u5e2e\u52a9\u6027\uff0c\u4e14\u5177\u5907\u96f6\u6837\u672c\u6cdb\u5316\u80fd\u529b\u548c\u5bf9\u591a\u667a\u80fd\u4f53\u62d3\u6251\u7ed3\u6784\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "PrivAct\u6709\u6548\u63d0\u5347\u4e86LLM\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u4e0a\u4e0b\u6587\u9690\u79c1\u4fdd\u62a4\u80fd\u529b\uff0c\u4fdd\u8bc1\u9690\u79c1\u4e0e\u670d\u52a1\u6027\u80fd\u7684\u5e73\u8861\uff0c\u5177\u5907\u826f\u597d\u7684\u6cdb\u5316\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2602.13860", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13860", "abs": "https://arxiv.org/abs/2602.13860", "authors": ["Somnath Banerjee"], "title": "Tutoring Large Language Models to be Domain-adaptive, Precise, and Safe", "comment": "Accepted to the PhD Symposium at Web Conference 2026", "summary": "The overarching research direction of this work is the development of a ''Responsible Intelligence'' framework designed to reconcile the immense generative power of Large Language Models (LLMs) with the stringent requirements of real-world deployment. As these models become a transformative force in artificial intelligence, there is an urgent need to move beyond general-purpose architectures toward systems that are contextually aware, inherently safer, and deeply respectful of global cultural nuances. This research navigates three interconnected threads: domain adaptation to ensure technical precision, ethical rigor to mitigate adversarial vulnerabilities, and cultural/multilingual alignment to promote global inclusivity. The methodological trajectory moves from classical supervised adaptation for task-specific demands to decoding-time alignment for safety, finally leveraging human feedback and preference modeling to achieve sociolinguistic acuity.", "AI": {"tldr": "\u672c\u6587\u5f00\u53d1\u4e86\u4e00\u4e2a\u517c\u987e\u6280\u672f\u7cbe\u5ea6\u3001\u5b89\u5168\u6027\u548c\u6587\u5316\u5305\u5bb9\u6027\u7684\u8d1f\u8d23\u4efb\u667a\u80fd\u6846\u67b6\uff0c\u7528\u4ee5\u4f18\u5316\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6210\u4e3a\u4eba\u5de5\u667a\u80fd\u7684\u53d8\u9769\u529b\u91cf\uff0c\u4e9f\u9700\u8d85\u8d8a\u901a\u7528\u67b6\u6784\uff0c\u6784\u5efa\u66f4\u5177\u4e0a\u4e0b\u6587\u611f\u77e5\u3001\u5b89\u5168\u53ef\u9760\u5e76\u5c0a\u91cd\u5168\u7403\u6587\u5316\u5dee\u5f02\u7684\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u4ece\u7ecf\u5178\u7684\u76d1\u7763\u9002\u5e94\u3001\u89e3\u7801\u65f6\u5bf9\u9f50\u5b89\u5168\u63aa\u65bd\u5230\u5229\u7528\u4eba\u7c7b\u53cd\u9988\u548c\u504f\u597d\u5efa\u6a21\u7684\u591a\u9636\u6bb5\u65b9\u6cd5\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u201c\u8d1f\u8d23\u4efb\u667a\u80fd\u201d\u6846\u67b6\uff0c\u65e8\u5728\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5f3a\u5927\u751f\u6210\u80fd\u529b\u4e0e\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u8981\u6c42\u7ed3\u5408\uff0c\u91cd\u70b9\u5173\u6ce8\u9886\u57df\u9002\u5e94\u3001\u4f26\u7406\u4e25\u683c\u548c\u6587\u5316\u591a\u6837\u6027\u5bf9\u9f50\u4e09\u65b9\u9762\u3002", "conclusion": "\u901a\u8fc7\u9886\u57df\u9002\u5e94\u3001\u4f26\u7406\u7b56\u7565\u548c\u591a\u6587\u5316\u5bf9\u9f50\uff0c\u6784\u5efa\u4e00\u4e2a\u65e2\u5f3a\u5927\u53c8\u5b89\u5168\u3001\u5c0a\u91cd\u591a\u6837\u6027\u7684\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2602.13867", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13867", "abs": "https://arxiv.org/abs/2602.13867", "authors": ["Somnath Banerjee", "Rima Hazra", "Animesh Mukherjee"], "title": "Bridging the Multilingual Safety Divide: Efficient, Culturally-Aware Alignment for Global South Languages", "comment": "Accepted to the EGSAI Workshop at AAAI 2026", "summary": "Large language models (LLMs) are being deployed across the Global South, where everyday use involves low-resource languages, code-mixing, and culturally specific norms. Yet safety pipelines, benchmarks, and alignment still largely target English and a handful of high-resource languages, implicitly assuming safety and factuality ''transfer'' across languages. Evidence increasingly shows they do not. We synthesize recent findings indicating that (i) safety guardrails weaken sharply on low-resource and code-mixed inputs, (ii) culturally harmful behavior can persist even when standard toxicity scores look acceptable, and (iii) English-only knowledge edits and safety patches often fail to carry over to low-resource languages. In response, we outline a practical agenda for researchers and students in the Global South: parameter-efficient safety steering, culturally grounded evaluation and preference data, and participatory workflows that empower local communities to define and mitigate harm. Our aim is to make multilingual safety a core requirement-not an add-on-for equitable AI in underrepresented regions.", "AI": {"tldr": "\u672c\u6587\u6307\u51fa\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u53ca\u6df7\u5408\u8bed\u5883\u4e2d\u5b89\u5168\u6027\u4fdd\u62a4\u63aa\u65bd\u5f31\u5316\uff0c\u6587\u5316\u6709\u5bb3\u884c\u4e3a\u4f9d\u65e7\u5b58\u5728\uff0c\u4e14\u82f1\u8bed\u5b89\u5168\u4fee\u8865\u63aa\u65bd\u96be\u4ee5\u8fc1\u79fb\u81f3\u4f4e\u8d44\u6e90\u8bed\u8a00\u3002\u63d0\u51fa\u9762\u5411\u5168\u7403\u5357\u65b9\u7684\u53c2\u6570\u9ad8\u6548\u5b89\u5168\u5f15\u5bfc\u3001\u672c\u5730\u6587\u5316\u8bc4\u4f30\u53ca\u793e\u533a\u53c2\u4e0e\u5de5\u4f5c\u6d41\u7b49\u5b9e\u7528\u6539\u8fdb\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u5b89\u5168\u4f53\u7cfb\u4e3b\u8981\u9488\u5bf9\u82f1\u8bed\u53ca\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u5ffd\u89c6\u4e86\u5168\u7403\u5357\u65b9\u591a\u6837\u8bed\u8a00\u548c\u6587\u5316\u7279\u5f81\uff0c\u5bfc\u81f4\u5b89\u5168\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u4fdd\u62a4\u96be\u4ee5\u6709\u6548\u8f6c\u79fb\u3002", "method": "\u7efc\u5408\u8fd1\u671f\u7814\u7a76\u53d1\u73b0\uff0c\u5206\u6790\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u5b89\u5168\u6027\u7684\u4e0d\u8db3\uff0c\u63d0\u51fa\u53c2\u6570\u9ad8\u6548\u7684\u5b89\u5168\u5f15\u5bfc\u53ca\u6587\u5316\u57fa\u7840\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7ed3\u5408\u793e\u533a\u53c2\u4e0e\u7684\u5de5\u4f5c\u6d41\u3002", "result": "\u53d1\u73b0\u5b89\u5168\u62a4\u680f\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6df7\u5408\u8f93\u5165\u4e2d\u663e\u8457\u5f31\u5316\uff0c\u6587\u5316\u6709\u5bb3\u884c\u4e3a\u96be\u88ab\u6807\u51c6\u6bd2\u6027\u8bc4\u5206\u53d1\u73b0\uff0c\u82f1\u8bed\u5b89\u5168\u4fee\u8865\u63aa\u65bd\u96be\u4ee5\u9002\u7528\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u5e76\u63d0\u51fa\u5177\u4f53\u6539\u8fdb\u65b9\u5411\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u63aa\u65bd\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u548c\u6587\u5316\u73af\u5883\u4e0b\u6548\u679c\u4e0d\u8db3\uff0c\u9700\u8981\u9488\u5bf9\u591a\u8bed\u8a00\u5b89\u5168\u7684\u6838\u5fc3\u8981\u6c42\u8fdb\u884c\u7814\u7a76\u548c\u5b9e\u8df5\u3002"}}
{"id": "2602.13870", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13870", "abs": "https://arxiv.org/abs/2602.13870", "authors": ["Hend Al-Khalifa", "Nadia Ghezaiel", "Maria Bounnit", "Hend Hamed Alhazmi", "Noof Abdullah Alfear", "Reem Fahad Alqifari", "Ameera Masoud Almasoud", "Sharefah Ahmed Al-Ghamdi"], "title": "ADAB: Arabic Dataset for Automated Politeness Benchmarking -- A Large-Scale Resource for Computational Sociopragmatics", "comment": "Paper accepted @ The Fifteenth biennial Language Resources and Evaluation Conference (LREC2026)", "summary": "The growing importance of culturally-aware natural language processing systems has led to an increasing demand for resources that capture sociopragmatic phenomena across diverse languages. Nevertheless, Arabic-language resources for politeness detection remain under-explored, despite the rich and complex politeness expressions embedded in Arabic communication. In this paper, we introduce ADAB (Arabic Politeness Dataset), a new annotated Arabic dataset collected from four online platforms, including social media, e-commerce, and customer service domains, covering Modern Standard Arabic and multiple dialects (Gulf, Egyptian, Levantine, and Maghrebi). The dataset was annotated based on Arabic linguistic traditions and pragmatic theory, resulting in three classes: polite, impolite, and neutral. It contains 10,000 samples with linguistic feature annotations across 16 politeness categories and achieves substantial inter-annotator agreement (kappa = 0.703). We benchmark 40 model configurations, including traditional machine learning, transformer-based models, and large language models. The dataset aims to support research on politeness-aware Arabic NLP.", "AI": {"tldr": "ADAB\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u4e00\u4e2a\u542b\u591a\u4e2a\u963f\u62c9\u4f2f\u8bed\u65b9\u8a00\u7684\u793c\u8c8c\u68c0\u6d4b\u8d44\u6e90\uff0c\u6ce8\u91ca\u7ec6\u81f4\u4e14\u8986\u76d6\u5e7f\u6cdb\uff0c\u652f\u6301\u793c\u8c8c\u8bc6\u522b\u76f8\u5173\u7684NLP\u7814\u7a76\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u8868\u8fbe\u4e30\u5bcc\u590d\u6742\uff0c\u4f46\u76f8\u5173\u8d44\u6e90\u532e\u4e4f\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u68c0\u6d4b\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u652f\u6301\u6587\u5316\u611f\u77e5\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\uff0c\u4fc3\u8fdb\u591a\u65b9\u8a00\u548c\u591a\u9886\u57df\u7684\u963f\u62c9\u4f2f\u8bed\u793e\u4f1a\u8bed\u7528\u73b0\u8c61\u7406\u89e3\u3002", "method": "\u6570\u636e\u4ece\u56db\u4e2a\u5728\u7ebf\u5e73\u53f0\u6536\u96c6\uff0c\u6db5\u76d6\u793e\u4ea4\u5a92\u4f53\u3001\u7535\u5546\u548c\u5ba2\u6237\u670d\u52a1\u9886\u57df\uff1b\u9075\u5faa\u963f\u62c9\u4f2f\u8bed\u8a00\u4f20\u7edf\u548c\u8bed\u7528\u7406\u8bba\u5bf9\u793c\u8c8c\u8fdb\u884c\u4e09\u5206\u7c7b\u6ce8\u91ca\uff1b\u8fdb\u884c\u4e8616\u4e2a\u793c\u8c8c\u7c7b\u522b\u7684\u8bed\u8a00\u7279\u5f81\u6ce8\u91ca\uff1b\u8fdb\u884c\u4e86\u5305\u62ec\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5185\u768440\u79cd\u6a21\u578b\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u672c\u6587\u4ecb\u7ecd\u4e86ADAB\uff0c\u4e00\u4e2a\u6db5\u76d6\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u53ca\u591a\u4e2a\u65b9\u8a00\u7684\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u68c0\u6d4b\u6570\u636e\u96c6\uff0c\u5171\u5305\u542b10,000\u6761\u5e26\u670916\u4e2a\u793c\u8c8c\u7c7b\u522b\u8bed\u8a00\u7279\u5f81\u6ce8\u91ca\u7684\u6837\u672c\uff0c\u5e76\u53d6\u5f97\u4e86\u8f83\u9ad8\u7684\u6ce8\u91ca\u4e00\u81f4\u6027\uff08kappa=0.703\uff09\u3002\u7814\u7a76\u57fa\u4e8e\u963f\u62c9\u4f2f\u8bed\u8a00\u4f20\u7edf\u548c\u8bed\u7528\u7406\u8bba\u5bf9\u6570\u636e\u8fdb\u884c\u6807\u6ce8\uff0c\u5206\u4e3a\u793c\u8c8c\u3001\u4e0d\u793c\u8c8c\u548c\u4e2d\u6027\u4e09\u7c7b\u3002\u91c7\u752840\u79cd\u6a21\u578b\u914d\u7f6e\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u62ec\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u3001\u57fa\u4e8e\u53d8\u6362\u5668\u7684\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u68c0\u6d4b\u8d44\u6e90\u7684\u7a7a\u767d\uff0c\u4fc3\u8fdb\u591a\u9886\u57df\u7684\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u611f\u77e5\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7814\u7a76\u3002", "conclusion": "ADAB\u6570\u636e\u96c6\u662f\u963f\u62c9\u4f2f\u8bed\u793c\u8c8c\u68c0\u6d4b\u9886\u57df\u7684\u91cd\u8981\u8d44\u6e90\uff0c\u57fa\u4e8e\u8bed\u8a00\u5b66\u548c\u8bed\u7528\u7406\u8bba\u7684\u6807\u6ce8\u65b9\u6cd5\u6709\u6548\uff0c\u4e30\u5bcc\u4e86\u591a\u65b9\u8a00\u3001\u591a\u9886\u57df\u7684\u963f\u62c9\u4f2f\u8bedNLP\u7814\u7a76\u57fa\u7840\uff0c\u5b9e\u9a8c\u8bc1\u660e\u591a\u79cd\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8868\u73b0\u5404\u5f02\u3002"}}
{"id": "2602.13890", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13890", "abs": "https://arxiv.org/abs/2602.13890", "authors": ["Amir Hossein Mohammadi", "Ali Moeinian", "Zahra Razavizade", "Afsaneh Fatemi", "Reza Ramezani"], "title": "Evaluating Prompt Engineering Techniques for RAG in Small Language Models: A Multi-Hop QA Approach", "comment": "32 Pages, Submitted to Journal of Computing and Security", "summary": "Retrieval Augmented Generation (RAG) is a powerful approach for enhancing the factual grounding of language models by integrating external knowledge. While widely studied for large language models, the optimization of RAG for Small Language Models (SLMs) remains a critical research gap, particularly in complex, multi-hop question-answering tasks that require sophisticated reasoning. In these systems, prompt template design is a crucial yet under-explored factor influencing performance. This paper presents a large-scale empirical study to investigate this factor, evaluating 24 different prompt templates on the HotpotQA dataset. The set includes a standard RAG prompt, nine well-formed techniques from the literature, and 14 novel hybrid variants, all tested on two prominent SLMs: Qwen2.5-3B Instruct and Gemma3-4B-It. Our findings, based on a test set of 18720 instances, reveal significant performance gains of up to 83% on Qwen2.5 and 84.5% on Gemma3-4B-It, yielding an improvement of up to 6% for both models compared to the Standard RAG prompt. This research also offers concrete analysis and actionable recommendations for designing effective and efficient prompts for SLM-based RAG systems, practically for deployment in resource-constrained environments.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u8bc4\u4f30\u63d0\u793a\u6a21\u677f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684RAG\u6027\u80fd\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u5c0f\u578b\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u867d\u7136RAG\u65b9\u6cd5\u5728\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5728\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u7684\u4f18\u5316\uff0c\u5c24\u5176\u662f\u5728\u590d\u6742\u7684\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u4ecd\u5b58\u5728\u7814\u7a76\u7a7a\u767d\uff0c\u540c\u65f6\u63d0\u793a\u6a21\u677f\u8bbe\u8ba1\u4f5c\u4e3a\u5f71\u54cd\u6027\u80fd\u7684\u91cd\u8981\u56e0\u7d20\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u672c\u6587\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u8bc1\u7814\u7a76\uff0c\u8bc4\u4f30\u4e8624\u79cd\u4e0d\u540c\u7684\u63d0\u793a\u6a21\u677f\u5728HotpotQA\u6570\u636e\u96c6\u4e0a\u7684\u6027\u80fd\u8868\u73b0\uff0c\u5305\u62ec\u6807\u51c6RAG\u63d0\u793a\u30019\u79cd\u6587\u732e\u4e2d\u63d0\u51fa\u7684\u6280\u672f\u548c14\u79cd\u65b0\u9896\u7684\u6df7\u5408\u53d8\u4f53\uff0c\u6d4b\u8bd5\u5bf9\u8c61\u4e3a\u4e24\u79cd\u5c0f\u578b\u8bed\u8a00\u6a21\u578bQwen2.5-3B Instruct\u548cGemma3-4B-It\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u6539\u8fdb\u7684\u63d0\u793a\u6a21\u677f\u4f7f\u5f97Qwen2.5\u6a21\u578b\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe83%\uff0cGemma3-4B-It\u63d0\u5347\u6700\u9ad8\u8fbe84.5%\uff0c\u76f8\u8f83\u4e8e\u6807\u51c6RAG\u63d0\u793a\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe6%\u3002", "conclusion": "\u63d0\u793a\u6a21\u677f\u8bbe\u8ba1\u5bf9\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u7684RAG\u7cfb\u7edf\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\uff0c\u672c\u6587\u63d0\u51fa\u7684\u6709\u6548\u63d0\u793a\u7b56\u7565\u80fd\u591f\u5728\u4fdd\u6301\u8d44\u6e90\u6548\u7387\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6a21\u578b\u8868\u73b0\uff0c\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.13905", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13905", "abs": "https://arxiv.org/abs/2602.13905", "authors": ["Thibault Cl\u00e9rice", "Rachel Bawden", "Anthony Glaise", "Ariane Pinche", "David Smith"], "title": "Pre-Editorial Normalization for Automatically Transcribed Medieval Manuscripts in Old French and Latin", "comment": null, "summary": "Recent advances in Automatic Text Recognition (ATR) have improved access to historical archives, yet a methodological divide persists between palaeographic transcriptions and normalized digital editions. While ATR models trained on more palaeographically-oriented datasets such as CATMuS have shown greater generalizability, their raw outputs remain poorly compatible with most readers and downstream NLP tools, thus creating a usability gap. On the other hand, ATR models trained to produce normalized outputs have been shown to struggle to adapt to new domains and tend to over-normalize and hallucinate. We introduce the task of Pre-Editorial Normalization (PEN), which consists in normalizing graphemic ATR output according to editorial conventions, which has the advantage of keeping an intermediate step with palaeographic fidelity while providing a normalized version for practical usability. We present a new dataset derived from the CoMMA corpus and aligned with digitized Old French and Latin editions using passim. We also produce a manually corrected gold-standard evaluation set. We benchmark this resource using ByT5-based sequence-to-sequence models on normalization and pre-annotation tasks. Our contributions include the formal definition of PEN, a 4.66M-sample silver training corpus, a 1.8k-sample gold evaluation set, and a normalization model achieving a 6.7% CER, substantially outperforming previous models for this task.", "AI": {"tldr": "\u672c\u7814\u7a76\u5f15\u5165\u4e86\u9884\u7f16\u8f91\u89c4\u8303\u5316\uff08PEN\uff09\u4efb\u52a1\uff0c\u65e8\u5728\u5c06\u81ea\u52a8\u6587\u672c\u8bc6\u522b\uff08ATR\uff09\u7684\u5b57\u5f62\u8f93\u51fa\u6839\u636e\u7f16\u8f91\u89c4\u8303\u8fdb\u884c\u89c4\u8303\u5316\uff0c\u517c\u5177\u53e4\u6587\u4e66\u5b66\u7684\u5fe0\u5b9e\u6027\u548c\u5b9e\u7528\u6027\u3002\u7814\u7a76\u6784\u5efa\u4e86\u65b0\u7684\u6570\u636e\u96c6\u5e76\u91c7\u7528ByT5\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\uff0c\u5b9e\u73b0\u4e86\u8f83\u4f4e\u7684\u5b57\u7b26\u9519\u8bef\u7387\u3002", "motivation": "\u73b0\u6709ATR\u6a21\u578b\u5b58\u5728\u53e4\u6587\u5b57\u5b66\u8f6c\u5f55\u4e0e\u6570\u5b57\u5316\u89c4\u8303\u7248\u672c\u7684\u5206\u6b67\uff0c\u539f\u59cb\u8f93\u51fa\u96be\u4ee5\u76f4\u89c2\u4f7f\u7528\u4e14\u4e0b\u6e38\u5de5\u5177\u517c\u5bb9\u6027\u5dee\uff0c\u800c\u89c4\u8303\u5316\u6a21\u578b\u9002\u5e94\u6027\u4e0d\u8db3\u4e14\u5bb9\u6613\u8fc7\u5ea6\u89c4\u8303\u5316\u6216\u4ea7\u751f\u9519\u8bef\uff0c\u6545\u63d0\u51faPEN\u4efb\u52a1\u6865\u63a5\u4e24\u8005\u3002", "method": "\u6784\u5efa\u57fa\u4e8eCoMMA\u8bed\u6599\u5e93\u5e76\u4e0e\u53e4\u6cd5\u8bed\u548c\u62c9\u4e01\u8bed\u7248\u672c\u5bf9\u9f50\u7684\u6570\u636e\u96c6\uff0c\u5229\u7528ByT5\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u8fdb\u884c\u9884\u7f16\u8f91\u89c4\u8303\u5316\u548c\u9884\u6807\u6ce8\u4efb\u52a1\u7684\u8bad\u7ec3\u4e0e\u8bc4\u6d4b\u3002", "result": "\u751f\u6210\u4e864.66\u767e\u4e07\u6837\u672c\u7684\u94f6\u8d28\u8bad\u7ec3\u96c6\u548c1800\u6837\u672c\u7684\u9ec4\u91d1\u8bc4\u6d4b\u96c6\uff0c\u6a21\u578b\u5728\u89c4\u8303\u5316\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e866.7%\u7684\u5b57\u7b26\u9519\u8bef\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u4ee5\u5f80\u6a21\u578b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165PEN\u4efb\u52a1\u53ca\u6784\u5efa\u76f8\u5e94\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9ATR\u8f93\u51fa\u7684\u6709\u6548\u89c4\u8303\u5316\uff0c\u63d0\u5347\u4e86\u6587\u672c\u7684\u53ef\u7528\u6027\u548c\u9002\u5e94\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u4e4b\u524d\u7684\u65b9\u6cd5\u3002"}}
{"id": "2602.13964", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13964", "abs": "https://arxiv.org/abs/2602.13964", "authors": ["Weiqi Zhai", "Zhihai Wang", "Jinghang Wang", "Boyu Yang", "Xiaogang Li", "Xiang Xu", "Bohan Wang", "Peng Wang", "Xingzhe Wu", "Anfeng Li", "Qiyuan Feng", "Yuhao Zhou", "Shoulin Han", "Wenjie Luo", "Yiyuan Li", "Yaxuan Wang", "Ruixian Luo", "Guojie Lin", "Peiyao Xiao", "Chengliang Xu", "Ben Wang", "Zeyu Wang", "Zichao Chen", "Jianan Ye", "Yijie Hu", "Jialong Chen", "Zongwen Shen", "Yuliang Xu", "An Yang", "Bowen Yu", "Dayiheng Liu", "Junyang Lin", "Hu Wei", "Que Shen", "Bing Zhao"], "title": "HLE-Verified: A Systematic Verification and Structured Revision of Humanity's Last Exam", "comment": "14 pages, 10 figures", "summary": "Humanity's Last Exam (HLE) has become a widely used benchmark for evaluating frontier large language models on challenging, multi-domain questions. However, community-led analyses have raised concerns that HLE contains a non-trivial number of noisy items, which can bias evaluation results and distort cross-model comparisons. To address this challenge, we introduce HLE-Verified, a verified and revised version of HLE with a transparent verification protocol and fine-grained error taxonomy. Our construction follows a two-stage validation-and-repair workflow resulting in a certified benchmark. In Stage I, each item undergoes binary validation of the problem and final answer through domain-expert review and model-based cross-checks, yielding 641 verified items. In Stage II, flawed but fixable items are revised under strict constraints preserving the original evaluation intent, through dual independent expert repairs, model-assisted auditing, and final adjudication, resulting in 1,170 revised-and-certified items. The remaining 689 items are released as a documented uncertain set with explicit uncertainty sources and expertise tags for future refinement. We evaluate seven state-of-the-art language models on HLE and HLE-Verified, observing an average absolute accuracy gain of 7--10 percentage points on HLE-Verified. The improvement is particularly pronounced on items where the original problem statement and/or reference answer is erroneous, with gains of 30--40 percentage points. Our analyses further reveal a strong association between model confidence and the presence of errors in the problem statement or reference answer, supporting the effectiveness of our revisions. Overall, HLE-Verified improves HLE-style evaluations by reducing annotation noise and enabling more faithful measurement of model capabilities. Data is available at: https://github.com/SKYLENAGE-AI/HLE-Verified", "AI": {"tldr": "HLE\u57fa\u51c6\u5b58\u5728\u566a\u58f0\uff0c\u5f71\u54cd\u6a21\u578b\u8bc4\u6d4b\u3002\u672c\u6587\u63d0\u51faHLE-Verified\uff0c\u901a\u8fc7\u4e13\u5bb6\u5ba1\u6838\u548c\u4fee\u8ba2\uff0c\u5927\u5e45\u63d0\u5347\u57fa\u51c6\u8d28\u91cf\u548c\u8bc4\u6d4b\u51c6\u786e\u7387\u3002", "motivation": "\u73b0\u6709HLE\u57fa\u51c6\u5b58\u5728\u5927\u91cf\u566a\u58f0\u9898\u76ee\uff0c\u5bfc\u81f4\u6a21\u578b\u8bc4\u6d4b\u7ed3\u679c\u504f\u5dee\u5927\uff0c\u96be\u4ee5\u516c\u6b63\u6bd4\u8f83\u591a\u6a21\u578b\u6027\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u7ecf\u8fc7\u4e25\u683c\u9a8c\u8bc1\u548c\u4fee\u8ba2\u7684\u57fa\u51c6\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u9a8c\u8bc1\u4e0e\u4fee\u8ba2\u5de5\u4f5c\u6d41\uff1a\u7b2c\u4e00\u9636\u6bb5\u901a\u8fc7\u9886\u57df\u4e13\u5bb6\u5ba1\u67e5\u548c\u6a21\u578b\u4ea4\u53c9\u9a8c\u8bc1\uff0c\u5f97\u5230641\u4e2a\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u9898\u76ee\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5bf9\u53ef\u4fee\u6b63\u9519\u8bef\u9898\u76ee\u8fdb\u884c\u53cc\u4e13\u5bb6\u72ec\u7acb\u4fee\u8ba2\u3001\u6a21\u578b\u8f85\u52a9\u5ba1\u8ba1\u53ca\u6700\u7ec8\u4ef2\u88c1\uff0c\u4ea7\u51fa1170\u4e2a\u4fee\u8ba2\u8ba4\u8bc1\u9898\u76ee\uff1b\u5176\u4f59689\u9898\u4ee5\u4e0d\u786e\u5b9a\u96c6\u516c\u5e03\uff0c\u5e76\u9644\u5e26\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u548c\u4e13\u4e1a\u6807\u7b7e\u3002", "result": "\u7ecf\u8fc7\u9a8c\u8bc1\u548c\u4fee\u8ba2\u7684HLE-Verified\u57fa\u51c6\u4f7f\u5f97\u4e03\u4e2a\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u7684\u51c6\u786e\u7387\u63d0\u53477-10\u4e2a\u767e\u5206\u70b9\uff0c\u7279\u522b\u662f\u5728\u539f\u9898\u76ee\u6216\u53c2\u8003\u7b54\u6848\u5b58\u5728\u9519\u8bef\u7684\u9898\u76ee\u4e0a\uff0c\u51c6\u786e\u7387\u63d0\u5347\u9ad8\u8fbe30-40\u4e2a\u767e\u5206\u70b9\u3002\u6a21\u578b\u7f6e\u4fe1\u5ea6\u4e0e\u9898\u76ee\u6216\u7b54\u6848\u9519\u8bef\u9ad8\u5ea6\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u4fee\u8ba2\u7684\u6709\u6548\u6027\u3002", "conclusion": "HLE-Verified\u901a\u8fc7\u4e25\u683c\u7684\u9a8c\u8bc1\u548c\u4fee\u8ba2\u6d41\u7a0b\u663e\u8457\u63d0\u5347\u4e86HLE\u57fa\u51c6\u7684\u51c6\u786e\u6027\u548c\u53ef\u4fe1\u5ea6\uff0c\u6709\u6548\u51cf\u5c11\u4e86\u8bc4\u6d4b\u566a\u58f0\uff0c\u4f7f\u5f97\u5927\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u8bc4\u4f30\u66f4\u52a0\u771f\u5b9e\u53ef\u9760\u3002"}}
{"id": "2602.13979", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.13979", "abs": "https://arxiv.org/abs/2602.13979", "authors": ["Tongze Zhang", "Jun-En Ding", "Melik Ozolcer", "Fang-Ming Hung", "Albert Chih-Chieh Yang", "Feng Liu", "Yi-Rou Ji", "Sang Won Bae"], "title": "Chain-of-Thought Reasoning with Large Language Models for Clinical Alzheimer's Disease Assessment and Diagnosis", "comment": null, "summary": "Alzheimer's disease (AD) has become a prevalent neurodegenerative disease worldwide. Traditional diagnosis still relies heavily on medical imaging and clinical assessment by physicians, which is often time-consuming and resource-intensive in terms of both human expertise and healthcare resources. In recent years, large language models (LLMs) have been increasingly applied to the medical field using electronic health records (EHRs), yet their application in Alzheimer's disease assessment remains limited, particularly given that AD involves complex multifactorial etiologies that are difficult to observe directly through imaging modalities. In this work, we propose leveraging LLMs to perform Chain-of-Thought (CoT) reasoning on patients' clinical EHRs. Unlike direct fine-tuning of LLMs on EHR data for AD classification, our approach utilizes LLM-generated CoT reasoning paths to provide the model with explicit diagnostic rationale for AD assessment, followed by structured CoT-based predictions. This pipeline not only enhances the model's ability to diagnose intrinsically complex factors but also improves the interpretability of the prediction process across different stages of AD progression. Experimental results demonstrate that the proposed CoT-based diagnostic framework significantly enhances stability and diagnostic performance across multiple CDR grading tasks, achieving up to a 15% improvement in F1 score compared to the zero-shot baseline method.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165LLM\u751f\u6210\u7684Chain-of-Thought\u63a8\u7406\uff0c\u6539\u8fdb\u4e86\u57fa\u4e8e\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u7684\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u8bca\u65ad\u51c6\u786e\u6027\u548c\u89e3\u91ca\u6027\u3002", "motivation": "\u4f20\u7edfAD\u8bca\u65ad\u4f9d\u8d56\u533b\u5b66\u5f71\u50cf\u548c\u4e34\u5e8a\u8bc4\u4f30\uff0c\u8017\u65f6\u4e14\u8d44\u6e90\u5bc6\u96c6\uff1bAD\u75c5\u56e0\u590d\u6742\uff0c\u5f71\u50cf\u96be\u4ee5\u76f4\u63a5\u89c2\u5bdf\uff1b\u73b0\u6709LLMs\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u6709\u9650\uff0c\u7f3a\u4e4f\u5bf9AD\u7684\u6709\u6548\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u60a3\u8005\u4e34\u5e8a\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHRs\uff09\u8fdb\u884cChain-of-Thought\uff08CoT\uff09\u63a8\u7406\uff0c\u751f\u6210\u660e\u786e\u7684\u8bca\u65ad\u63a8\u7406\u8def\u5f84\uff0c\u518d\u901a\u8fc7\u7ed3\u6784\u5316\u7684CoT\u63a8\u7406\u8fdb\u884c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u8bc4\u4f30\u3002", "result": "\u63d0\u51fa\u7684\u57fa\u4e8eCoT\u63a8\u7406\u7684\u8bca\u65ad\u6846\u67b6\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u591a\u4e2a\u8ba4\u77e5\u5931\u8c03\u5206\u7ea7\u4efb\u52a1\u4e0a\u7684\u7a33\u5b9a\u6027\u548c\u8bca\u65ad\u6027\u80fd\uff0c\u76f8\u6bd4\u96f6\u6837\u672c\u57fa\u7ebf\u65b9\u6cd5\uff0cF1\u5206\u6570\u63d0\u5347\u8fbe15%\u3002", "conclusion": "\u57fa\u4e8eLLMs\u7684CoT\u63a8\u7406\u4e0d\u4ec5\u63d0\u5347\u4e86AD\u8bca\u65ad\u7684\u51c6\u786e\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u8fd8\u589e\u5f3a\u4e86\u6a21\u578b\u7684\u51b3\u7b56\u53ef\u89e3\u91ca\u6027\uff0c\u6709\u52a9\u4e8e\u590d\u6742\u591a\u56e0\u7d20\u75be\u75c5\u7684\u4e34\u5e8a\u8bc4\u4f30\u3002"}}
{"id": "2602.14002", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14002", "abs": "https://arxiv.org/abs/2602.14002", "authors": ["Ali Zahedzadeh", "Behnam Bahrak"], "title": "The Sufficiency-Conciseness Trade-off in LLM Self-Explanation from an Information Bottleneck Perspective", "comment": "LREC 2026 submission; focuses on LLM self-explanation, interpretability, and information bottleneck analysis", "summary": "Large Language Models increasingly rely on self-explanations, such as chain of thought reasoning, to improve performance on multi step question answering. While these explanations enhance accuracy, they are often verbose and costly to generate, raising the question of how much explanation is truly necessary. In this paper, we examine the trade-off between sufficiency, defined as the ability of an explanation to justify the correct answer, and conciseness, defined as the reduction in explanation length. Building on the information bottleneck principle, we conceptualize explanations as compressed representations that retain only the information essential for producing correct answers.To operationalize this view, we introduce an evaluation pipeline that constrains explanation length and assesses sufficiency using multiple language models on the ARC Challenge dataset. To broaden the scope, we conduct experiments in both English, using the original dataset, and Persian, as a resource-limited language through translation. Our experiments show that more concise explanations often remain sufficient, preserving accuracy while substantially reducing explanation length, whereas excessive compression leads to performance degradation.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u7684\u5145\u5206\u6027\u4e0e\u7b80\u6d01\u6027\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u53d1\u73b0\u9002\u5ea6\u538b\u7f29\u89e3\u91ca\u957f\u5ea6\u53ef\u5728\u4fdd\u8bc1\u51c6\u786e\u7387\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u6548\u7387\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4f9d\u8d56\u94fe\u5f0f\u63a8\u7406\u7b49\u81ea\u6211\u89e3\u91ca\u6765\u63d0\u5347\u591a\u6b65\u95ee\u7b54\u7684\u6027\u80fd\uff0c\u4f46\u8fd9\u4e9b\u89e3\u91ca\u5e38\u5e38\u5197\u957f\u4e14\u751f\u6210\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u7814\u7a76\u89e3\u91ca\u7684\u5fc5\u8981\u957f\u5ea6\u4e0e\u5145\u5206\u6027\u4e4b\u95f4\u7684\u6743\u8861\u975e\u5e38\u91cd\u8981\u3002", "method": "\u57fa\u4e8e\u4fe1\u606f\u74f6\u9888\u539f\u5219\uff0c\u5c06\u89e3\u91ca\u89c6\u4e3a\u53ea\u4fdd\u7559\u751f\u6210\u6b63\u786e\u7b54\u6848\u6240\u9700\u4fe1\u606f\u7684\u538b\u7f29\u8868\u8fbe\uff0c\u8bbe\u8ba1\u8bc4\u4f30\u6d41\u7a0b\u9650\u5236\u89e3\u91ca\u957f\u5ea6\u5e76\u7528\u591a\u8bed\u8a00\u6a21\u578b\u5728ARC Challenge\u6570\u636e\u96c6\uff08\u5305\u62ec\u82f1\u8bed\u548c\u7ffb\u8bd1\u6210\u6ce2\u65af\u8bed\uff09\u4e0a\u8bc4\u4f30\u89e3\u91ca\u5145\u5206\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u66f4\u7b80\u6d01\u7684\u89e3\u91ca\u901a\u5e38\u4ecd\u80fd\u4fdd\u6301\u5145\u5206\u6027\uff0c\u4fdd\u8bc1\u51c6\u786e\u7387\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u89e3\u91ca\u957f\u5ea6\uff0c\u4f46\u8fc7\u5ea6\u538b\u7f29\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u89e3\u91ca\u7684\u957f\u5ea6\u53ef\u4ee5\u5728\u4fdd\u8bc1\u5145\u5206\u6027\u7684\u524d\u63d0\u4e0b\u5927\u5e45\u7f29\u77ed\uff0c\u4ece\u800c\u964d\u4f4e\u751f\u6210\u6210\u672c\uff0c\u4f46\u8fc7\u5ea6\u538b\u7f29\u4f1a\u5f71\u54cd\u6a21\u578b\u6027\u80fd\u3002"}}
{"id": "2602.14009", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14009", "abs": "https://arxiv.org/abs/2602.14009", "authors": ["Srikumar Nayak"], "title": "Named Entity Recognition for Payment Data Using NLP", "comment": "14 pages, 8 figures, research paper", "summary": "Named Entity Recognition (NER) has emerged as a critical component in automating financial transaction processing, particularly in extracting structured information from unstructured payment data. This paper presents a comprehensive analysis of state-of-the-art NER algorithms specifically designed for payment data extraction, including Conditional Random Fields (CRF), Bidirectional Long Short-Term Memory with CRF (BiLSTM-CRF), and transformer-based models such as BERT and FinBERT. We conduct extensive experiments on a dataset of 50,000 annotated payment transactions across multiple payment formats including SWIFT MT103, ISO 20022, and domestic payment systems. Our experimental results demonstrate that fine-tuned BERT models achieve an F1-score of 94.2% for entity extraction, outperforming traditional CRF-based approaches by 12.8 percentage points. Furthermore, we introduce PaymentBERT, a novel hybrid architecture combining domain-specific financial embeddings with contextual representations, achieving state-of-the-art performance with 95.7% F1-score while maintaining real-time processing capabilities. We provide detailed analysis of cross-format generalization, ablation studies, and deployment considerations. This research provides practical insights for financial institutions implementing automated sanctions screening, anti-money laundering (AML) compliance, and payment processing systems.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u7528\u4e8e\u652f\u4ed8\u6570\u636e\u63d0\u53d6\u7684\u6700\u65b0\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u7b97\u6cd5\uff0c\u91cd\u70b9\u6bd4\u8f83\u4e86CRF\u3001BiLSTM-CRF\u3001BERT\u53caFinBERT\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u4e86\u878d\u5408\u91d1\u878d\u9886\u57df\u5d4c\u5165\u7684PaymentBERT\u65b0\u67b6\u6784\u3002", "motivation": "\u652f\u4ed8\u4ea4\u6613\u6570\u636e\u7ed3\u6784\u590d\u6742\u4e14\u591a\u6837\uff0c\u81ea\u52a8\u63d0\u53d6\u7ed3\u6784\u5316\u4fe1\u606f\u5bf9\u91d1\u878d\u4ea4\u6613\u5904\u7406\u53ca\u5408\u89c4\u81f3\u5173\u91cd\u8981\uff0c\u4fc3\u4f7f\u7814\u7a76\u9ad8\u6548\u51c6\u786e\u7684NER\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u591a\u79cdNER\u6a21\u578b\uff08CRF\u3001BiLSTM-CRF\u3001BERT\u3001FinBERT\uff09\u57285\u4e07\u6761\u591a\u683c\u5f0f\u652f\u4ed8\u4ea4\u6613\u6570\u636e\u96c6\u4e0a\u5b9e\u9a8c\uff0c\u8bbe\u8ba1\u878d\u5408\u9886\u57df\u5d4c\u5165\u7684PaymentBERT\u67b6\u6784\uff0c\u8fdb\u884c\u6d88\u878d\u5b9e\u9a8c\u53ca\u8de8\u683c\u5f0f\u6cdb\u5316\u8bc4\u4f30\u3002", "result": "BERT\u6a21\u578bF1\u8fbe\u523094.2%\uff0c\u9886\u5148\u4f20\u7edfCRF 12.8\u4e2a\u767e\u5206\u70b9\uff0cPaymentBERT\u8fdb\u4e00\u6b65\u63d0\u5347\u81f395.7%\uff0c\u540c\u65f6\u6ee1\u8db3\u5b9e\u65f6\u5904\u7406\u8981\u6c42\u3002", "conclusion": "Fine-tuned BERT\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0cPaymentBERT\u5b9e\u73b0\u4e8695.7%\u7684F1\u5206\u6570\u5e76\u652f\u6301\u5b9e\u65f6\u5904\u7406\uff0c\u9002\u5408\u91d1\u878d\u81ea\u52a8\u5316\u5e94\u7528\u3002"}}
{"id": "2602.14028", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14028", "abs": "https://arxiv.org/abs/2602.14028", "authors": ["Sen Yang", "Shanbo Cheng", "Lu Xu", "Jianbing Zhang", "Shujian Huang"], "title": "GRRM: Group Relative Reward Modeling for Machine Translation", "comment": "19 pages, 6 figures", "summary": "While Group Relative Policy Optimization (GRPO) offers a powerful framework for LLM post-training, its effectiveness in open-ended domains like Machine Translation hinges on accurate intra-group ranking. We identify that standard Scalar Quality Metrics (SQM) fall short in this context; by evaluating candidates in isolation, they lack the comparative context necessary to distinguish fine-grained linguistic nuances. To address this, we introduce the Group Quality Metric (GQM) paradigm and instantiate it via the Group Relative Reward Model (GRRM). Unlike traditional independent scorers, GRRM processes the entire candidate group jointly, leveraging comparative analysis to rigorously resolve relative quality and adaptive granularity. Empirical evaluations confirm that GRRM achieves competitive ranking accuracy among all baselines. Building on this foundation, we integrate GRRM into the GRPO training loop to optimize the translation policy. Experimental results demonstrate that our framework not only improves general translation quality but also unlocks reasoning capabilities comparable to state-of-the-art reasoning models. We release codes, datasets, and model checkpoints at https://github.com/NJUNLP/GRRM.", "AI": {"tldr": "\u9488\u5bf9\u673a\u5668\u7ffb\u8bd1\u4e2d\u73b0\u6709\u8bc4\u4ef7\u6307\u6807\u4e0d\u8db3\uff0c\u8bba\u6587\u63d0\u51fa\u7ec4\u76f8\u5bf9\u5956\u52b1\u6a21\u578b\u63d0\u5347\u6392\u5e8f\u7cbe\u5ea6\u548c\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4e14\u589e\u5f3a\u4e86\u63a8\u7406\u80fd\u529b\uff0c\u6548\u679c\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u6807\u91cf\u8d28\u91cf\u6307\u6807\uff08SQM\uff09\u5728\u5f00\u653e\u9886\u57df\u673a\u5668\u7ffb\u8bd1\u4e2d\u56e0\u7f3a\u4e4f\u6bd4\u8f83\u4e0a\u4e0b\u6587\uff0c\u96be\u4ee5\u533a\u5206\u7ec6\u5fae\u7684\u8bed\u8a00\u5dee\u5f02\uff0c\u5f71\u54cd\u4e86\u57fa\u4e8eGRPO\u6846\u67b6\u7684\u6a21\u578b\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u7ec4\u76f8\u5bf9\u5956\u52b1\u6a21\u578b\uff08GRRM\uff09\uff0c\u8be5\u6a21\u578b\u901a\u8fc7\u8054\u5408\u5904\u7406\u6574\u4e2a\u5019\u9009\u7ec4\uff0c\u5229\u7528\u6bd4\u8f83\u5206\u6790\u51c6\u786e\u8bc4\u4f30\u76f8\u5bf9\u8d28\u91cf\u548c\u81ea\u9002\u5e94\u7c92\u5ea6\uff0c\u5c06\u5176\u96c6\u6210\u5230\u7ec4\u76f8\u5bf9\u7b56\u7565\u4f18\u5316\uff08GRPO\uff09\u8bad\u7ec3\u5faa\u73af\u4e2d\u4ee5\u4f18\u5316\u7ffb\u8bd1\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eGRRM\u5728\u6392\u540d\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408GRRM\u7684GRPO\u8bad\u7ec3\u6846\u67b6\u63d0\u5347\u4e86\u6574\u4f53\u7ffb\u8bd1\u8d28\u91cf\u548c\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u57fa\u4e8e\u7ec4\u7684\u8d28\u91cf\u8bc4\u4ef7\u8303\u5f0f\uff08GQM\uff09\u53ca\u5176\u5b9e\u73b0\u7684\u7ec4\u76f8\u5bf9\u5956\u52b1\u6a21\u578b\uff08GRRM\uff09\uff0c\u8bba\u6587\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u7ffb\u8bd1\u9886\u57df\u4e2d\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u6392\u5e8f\u51c6\u786e\u6027\u548c\u7ffb\u8bd1\u8d28\u91cf\uff0c\u5b9e\u73b0\u4e86\u4e0e\u5148\u8fdb\u63a8\u7406\u6a21\u578b\u5ab2\u7f8e\u7684\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.14039", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14039", "abs": "https://arxiv.org/abs/2602.14039", "authors": ["Sajjad Kachuee", "Mohammad Sharifkhani"], "title": "Geometry-Preserving Aggregation for Mixture-of-Experts Embedding Models", "comment": null, "summary": "Mixture-of-Experts (MoE) embedding models combine expert outputs using weighted linear summation, implicitly assuming a linear subspace structure in the embedding space. This assumption is shown to be inconsistent with the geometry of expert representations. Geometric analysis of a modern MoE embedding model reveals that expert outputs lie on a shared hyperspherical manifold characterized by tightly concentrated norms and substantial angular separation. Under this geometry, linear aggregation induces inward collapse toward the manifold interior, distorting vector magnitude and direction and reducing embedding comparability. To address this inconsistency, Spherical Barycentric Aggregation (SBA) is introduced as a geometry-preserving aggregation operator that separates radial and angular components to maintain hyperspherical structure while remaining fully compatible with existing routing mechanisms. Experiments on selected tasks from the Massive Text Embedding Benchmark (MTEB), including semantic similarity, clustering, and duplicate question detection, demonstrate consistent performance improvements with identical training cost and full stability. Additional geometric analyses confirm that SBA prevents aggregation-induced collapse and preserves hyperspherical consistency, highlighting the importance of geometry-aware aggregation in MoE embedding architectures.", "AI": {"tldr": "\u672c\u6587\u63ed\u793aMoE\u5d4c\u5165\u6a21\u578b\u7ebf\u6027\u805a\u5408\u7684\u51e0\u4f55\u7f3a\u9677\uff0c\u63d0\u51fa\u4fdd\u6301\u8d85\u7403\u9762\u7ed3\u6784\u7684SBA\u805a\u5408\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u591a\u9879\u6587\u672c\u5d4c\u5165\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709MoE\u5d4c\u5165\u6a21\u578b\u91c7\u7528\u7ebf\u6027\u52a0\u6743\u5047\u8bbe\uff0c\u5ffd\u89c6\u4e86\u4e13\u5bb6\u8f93\u51fa\u7684\u8d85\u7403\u9762\u6d41\u5f62\u51e0\u4f55\u7279\u6027\uff0c\u5bfc\u81f4\u805a\u5408\u540e\u5411\u91cf\u584c\u9677\u548c\u626d\u66f2\uff0c\u5f71\u54cd\u5d4c\u5165\u8d28\u91cf\u4e0e\u53ef\u6bd4\u8f83\u6027\uff0c\u6545\u63d0\u51fa\u51e0\u4f55\u611f\u77e5\u7684\u805a\u5408\u65b9\u6cd5\u4ee5\u89e3\u51b3\u8be5\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5206\u79bb\u5f84\u5411\u548c\u89d2\u5ea6\u5206\u91cf\u8bbe\u8ba1\u7684\u7403\u9762\u91cd\u5fc3\u805a\u5408(SBA)\u7b97\u5b50\uff0c\u4fdd\u6301\u5d4c\u5165\u7684\u8d85\u7403\u9762\u7ed3\u6784\uff0c\u5e76\u517c\u5bb9MoE\u7684\u8def\u7531\u673a\u5236\uff0c\u5b9e\u73b0\u4e86\u51e0\u4f55\u4fdd\u7559\u7684\u805a\u5408\u3002", "result": "\u8be5\u8bba\u6587\u9488\u5bf9Mixture-of-Experts (MoE)\u5d4c\u5165\u6a21\u578b\u4e2d\u7ebf\u6027\u52a0\u6743\u5408\u6210\u5047\u8bbe\u5d4c\u5165\u7a7a\u95f4\u4e3a\u7ebf\u6027\u5b50\u7a7a\u95f4\u7684\u4e0d\u8db3\uff0c\u53d1\u73b0\u4e13\u5bb6\u8f93\u51fa\u5b9e\u9645\u5206\u5e03\u5728\u5171\u4eab\u7684\u8d85\u7403\u9762\u6d41\u5f62\u4e0a\uff0c\u4e14\u5177\u6709\u96c6\u4e2d\u8303\u6570\u548c\u663e\u8457\u89d2\u5ea6\u5206\u79bb\u7279\u6027\u3002\u7ebf\u6027\u805a\u5408\u5bfc\u81f4\u5411\u5185\u584c\u9677\uff0c\u626d\u66f2\u5411\u91cf\u7684\u5927\u5c0f\u548c\u65b9\u5411\uff0c\u5f71\u54cd\u5d4c\u5165\u7684\u53ef\u6bd4\u6027\u3002\u4e3a\u6b64\uff0c\u4f5c\u8005\u63d0\u51fa\u4e86\u7403\u9762\u91cd\u5fc3\u805a\u5408(SBA)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u5f84\u5411\u548c\u89d2\u5ea6\u5206\u91cf\uff0c\u4fdd\u6301\u8d85\u7403\u9762\u7ed3\u6784\uff0c\u5e76\u517c\u5bb9\u73b0\u6709\u7684\u8def\u7531\u673a\u5236\u3002\u5b9e\u9a8c\u8bc1\u660eSBA\u5728MTEB\u57fa\u51c6\u4efb\u52a1\u4e0a\u7684\u8bed\u4e49\u76f8\u4f3c\u6027\u3001\u805a\u7c7b\u548c\u91cd\u590d\u95ee\u9898\u68c0\u6d4b\u7b49\u8868\u73b0\u4e00\u81f4\u63d0\u5347\uff0c\u8bad\u7ec3\u6210\u672c\u548c\u7a33\u5b9a\u6027\u4e0d\u53d8\u3002\u51e0\u4f55\u5206\u6790\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86SBA\u9632\u6b62\u4e86\u584c\u9677\u73b0\u8c61\uff0c\u5f3a\u8c03\u4e86\u51e0\u4f55\u611f\u77e5\u805a\u5408\u5728MoE\u5d4c\u5165\u67b6\u6784\u4e2d\u7684\u91cd\u8981\u6027\u3002", "conclusion": "SBA\u51e0\u4f55\u611f\u77e5\u805a\u5408\u6709\u6548\u9632\u6b62\u4e86MoE\u5d4c\u5165\u4e2d\u7684\u584c\u9677\u95ee\u9898\uff0c\u4fdd\u6301\u4e86\u8d85\u7403\u9762\u7ed3\u6784\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u4e14\u7a33\u5b9a\u6027\u826f\u597d\uff0c\u9a8c\u8bc1\u4e86\u51e0\u4f55\u611f\u77e5\u805a\u5408\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.14044", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14044", "abs": "https://arxiv.org/abs/2602.14044", "authors": ["Pietro Bernardelle", "Stefano Civelli", "Kevin Roitero", "Gianluca Demartini"], "title": "Context Shapes LLMs Retrieval-Augmented Fact-Checking Effectiveness", "comment": null, "summary": "Large language models (LLMs) show strong reasoning abilities across diverse tasks, yet their performance on extended contexts remains inconsistent. While prior research has emphasized mid-context degradation in question answering, this study examines the impact of context in LLM-based fact verification. Using three datasets (HOVER, FEVEROUS, and ClimateFEVER) and five open-source models accross different parameters sizes (7B, 32B and 70B parameters) and model families (Llama-3.1, Qwen2.5 and Qwen3), we evaluate both parametric factual knowledge and the impact of evidence placement across varying context lengths. We find that LLMs exhibit non-trivial parametric knowledge of factual claims and that their verification accuracy generally declines as context length increases. Similarly to what has been shown in previous works, in-context evidence placement plays a critical role with accuracy being consistently higher when relevant evidence appears near the beginning or end of the prompt and lower when placed mid-context. These results underscore the importance of prompt structure in retrieval-augmented fact-checking systems.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u57fa\u4e8e\u4e0a\u4e0b\u6587\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u4f1a\u5bfc\u81f4\u6a21\u578b\u9a8c\u8bc1\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u4e14\u8bc1\u636e\u5728\u63d0\u793a\u4e2d\u7684\u4f4d\u7f6e\u5f71\u54cd\u663e\u8457\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u591a\u4efb\u52a1\u4e0a\u7684\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u5176\u5728\u957f\u4e0a\u4e0b\u6587\u4e2d\u7684\u8868\u73b0\u4ecd\u4e0d\u7a33\u5b9a\uff0c\u4e14\u4e4b\u524d\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u4e2d\u90e8\u4e0a\u4e0b\u6587\u9000\u5316\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u4e8b\u5b9e\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u4e0a\u4e0b\u6587\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u4e09\u4e2a\u6570\u636e\u96c6\uff08HOVER\u3001FEVEROUS\u3001ClimateFEVER\uff09\u548c\u4e94\u4e2a\u5f00\u6e90\u6a21\u578b\uff08\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u548c\u6a21\u578b\u5bb6\u65cf\uff09\uff0c\u8bc4\u4f30\u53c2\u6570\u5316\u4e8b\u5b9e\u77e5\u8bc6\u53ca\u8bc1\u636e\u5728\u4e0d\u540c\u4e0a\u4e0b\u6587\u957f\u5ea6\u4e2d\u7684\u4f4d\u7f6e\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u7684\u4e8b\u5b9e\u9a8c\u8bc1\u51c6\u786e\u7387\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u52a0\u800c\u4e0b\u964d\uff0c\u4e14\u5f53\u76f8\u5173\u8bc1\u636e\u4f4d\u4e8e\u63d0\u793a\u5f00\u5934\u6216\u7ed3\u5c3e\u65f6\uff0c\u51c6\u786e\u7387\u8f83\u9ad8\uff1b\u76f8\u53cd\uff0c\u8bc1\u636e\u4f4d\u4e8e\u4e2d\u90e8\u65f6\u51c6\u786e\u7387\u8f83\u4f4e\u3002\u8fd9\u8868\u660e\u63d0\u793a\u7ed3\u6784\u5728\u57fa\u4e8e\u68c0\u7d22\u7684\u4e8b\u5b9e\u6838\u67e5\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\u3002", "conclusion": "LLMs\u5728\u4e8b\u5b9e\u9a8c\u8bc1\u4e2d\u62e5\u6709\u4e00\u5b9a\u7684\u53c2\u6570\u5316\u77e5\u8bc6\uff0c\u4f46\u5176\u51c6\u786e\u7387\u968f\u4e0a\u4e0b\u6587\u957f\u5ea6\u589e\u957f\u800c\u4e0b\u964d\uff0c\u4e14\u8bc1\u636e\u4f4d\u7f6e\u5bf9\u9a8c\u8bc1\u7ed3\u679c\u5f71\u54cd\u663e\u8457\u3002"}}
{"id": "2602.14054", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14054", "abs": "https://arxiv.org/abs/2602.14054", "authors": ["Jizheng Chen", "Weiming Zhang", "Xinyi Dai", "Weiwen Liu", "Kounianhua Du", "Yasheng Wang", "Ruiming Tang", "Yong Yu", "Weinan Zhang"], "title": "LogitsCoder: Towards Efficient Chain-of-Thought Path Search via Logits Preference Decoding for Code Generation", "comment": null, "summary": "Code generation remains a challenging task that requires precise and structured reasoning. Existing Test Time Scaling (TTS) methods, including structured tree search, have made progress in exploring reasoning paths but still face two major challenges: (1) underthinking, where reasoning chains tend to be shallow and fail to capture the full complexity of problems; and (2) overthinking, where overly verbose reasoning leads to inefficiency and increased computational costs. To address these issues, we propose LogitsCoder, a novel framework that enhances chain-of-thought reasoning through lightweight, logit-level control mechanisms for code generation. LogitsCoder iteratively generates and refines reasoning steps by first steering token selection toward statistically preferred patterns via Logits Preference Decoding, then selecting and aggregating diverse reasoning paths using Logits Rank Based Path Selection and Thoughts Aggregation. This results in coherent and effective reasoning chains that balance depth and efficiency. Extensive experiments demonstrate that LogitsCoder produces more efficient and higher-quality reasoning chains, leading to superior code generation performance compared to baseline methods.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLogitsCoder\uff0c\u901a\u8fc7logit\u63a7\u5236\u673a\u5236\u4f18\u5316\u63a8\u7406\u94fe\uff0c\u6709\u6548\u63d0\u5347\u4ee3\u7801\u751f\u6210\u7684\u6548\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u4ee3\u7801\u751f\u6210\u9762\u4e34\u7cbe\u51c6\u4e14\u7ed3\u6784\u5316\u63a8\u7406\u7684\u6311\u6218\uff0c\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u63a8\u7406\u94fe\u6d45\u8584\u548c\u5197\u957f\u5bfc\u81f4\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faLogitsCoder\u6846\u67b6\uff0c\u901a\u8fc7logit\u5c42\u7ea7\u63a7\u5236\u673a\u5236\uff0c\u7ed3\u5408Logits Preference Decoding\u5f15\u5bfctoken\u9009\u62e9\uff0cLogits Rank Based Path Selection\u548cThoughts Aggregation\u5b9e\u73b0\u591a\u6837\u63a8\u7406\u8def\u5f84\u7684\u7b5b\u9009\u548c\u5408\u5e76\uff0c\u63d0\u5347\u94fe\u5f0f\u63a8\u7406\u7684\u6df1\u5ea6\u548c\u6548\u7387\u3002", "result": "LogitsCoder\u751f\u6210\u7684\u63a8\u7406\u94fe\u66f4\u9ad8\u6548\u4e14\u8d28\u91cf\u66f4\u9ad8\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u4ee3\u7801\u751f\u6210\u6027\u80fd\u3002", "conclusion": "LogitsCoder\u6709\u6548\u89e3\u51b3\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u63a8\u7406\u6df1\u5ea6\u4e0d\u8db3\u548c\u8fc7\u5ea6\u5197\u957f\u95ee\u9898\uff0c\u901a\u8fc7logit\u5c42\u7ea7\u7684\u8f7b\u91cf\u63a7\u5236\u673a\u5236\u5b9e\u73b0\u63a8\u7406\u94fe\u7684\u4f18\u5316\uff0c\u63d0\u5347\u6574\u4f53\u4ee3\u7801\u751f\u6210\u8d28\u91cf\u548c\u6548\u7387\u3002"}}
{"id": "2602.14060", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14060", "abs": "https://arxiv.org/abs/2602.14060", "authors": ["Yang Liu", "Jiaye Yang", "Weikang Li", "Jiahui Liang", "Yang Li", "Lingyong Yan"], "title": "LM-Lexicon: Improving Definition Modeling via Harmonizing Semantic Experts", "comment": "EACL 2026 (Oral), 22 pages, 12 figures, 12 tables", "summary": "We introduce LM-Lexicon, an innovative definition modeling approach that incorporates data clustering, semantic expert learning, and model merging using a sparse mixture-of-experts architecture. By decomposing the definition modeling task into specialized semantic domains, where small language models are trained as domain experts, LM-Lexicon achieves substantial improvements (+7% BLEU score compared with the prior state-of-the-art model) over existing methods on five widely used benchmarks. Empirically, we demonstrate that 1) the clustering strategy enables fine-grained expert specialization with nearly 10% improvement in definition quality; 2) the semantic-aware domain-level routing mechanism achieves higher expert efficacy (+1%) than conventional token-level routing; and 3) further performance gains can be obtained through test-time compute and semantic expert scaling. Our work advances definition modeling while providing insights into the development of efficient language models for semantic-intensive applications.", "AI": {"tldr": "LM-Lexicon\u91c7\u7528\u6570\u636e\u805a\u7c7b\u3001\u8bed\u4e49\u4e13\u5bb6\u5b66\u4e60\u548c\u7a00\u758f\u4e13\u5bb6\u6a21\u578b\u878d\u5408\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5b9a\u4e49\u5efa\u6a21\u4efb\u52a1\u7684\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u5b9a\u4e49\u5efa\u6a21\u6a21\u578b\u96be\u4ee5\u7ec6\u5206\u8bed\u4e49\u9886\u57df\u5bfc\u81f4\u7684\u6027\u80fd\u74f6\u9888\uff0c\u65e8\u5728\u901a\u8fc7\u4e13\u5bb6\u5206\u5de5\u63d0\u9ad8\u6548\u679c\u3002", "method": "\u7ed3\u5408\u6570\u636e\u805a\u7c7b\u3001\u8bed\u4e49\u4e13\u5bb6\u8bad\u7ec3\u548c\u57fa\u4e8e\u7a00\u758f\u4e13\u5bb6\u67b6\u6784\u7684\u6a21\u578b\u878d\u5408\uff0c\u91c7\u7528\u8bed\u4e49\u611f\u77e5\u7684\u9886\u57df\u7ea7\u8def\u7531\u673a\u5236\u548c\u6d4b\u8bd5\u65f6\u8ba1\u7b97\u6269\u5c55\u3002", "result": "\u5728\u4e94\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cLM-Lexicon\u5b9e\u73b0\u4e867%\u7684BLEU\u5f97\u5206\u63d0\u5347\uff0c\u4e13\u5bb6\u673a\u5236\u5e26\u6765\u8fd110%\u8d28\u91cf\u63d0\u5347\uff0c\u9886\u57df\u7ea7\u8def\u7531\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6d4b\u8bd5\u65f6\u6269\u5c55\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "conclusion": "LM-Lexicon\u901a\u8fc7\u8bed\u4e49\u9886\u57df\u4e13\u5bb6\u5206\u5de5\u548c\u6a21\u578b\u5408\u5e76\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9a\u4e49\u5efa\u6a21\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u8d85\u8fc7\u4e86\u73b0\u6709\u6700\u597d\u6a21\u578b\u3002"}}
{"id": "2602.14062", "categories": ["cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.14062", "abs": "https://arxiv.org/abs/2602.14062", "authors": ["Jandad Jahani", "Mursal Dawodi", "Jawid Ahmad Baktash"], "title": "From Scarcity to Scale: A Release-Level Analysis of the Pashto Common Voice Dataset", "comment": null, "summary": "Large, openly licensed speech datasets are essential for building automatic speech recognition (ASR) systems, yet many widely spoken languages remain underrepresented in public resources. Pashto, spoken by more than 60 million people, has historically lacked large-scale openly licensed speech data suitable for modern ASR development.\n  This paper presents a release-level analysis of the Pashto component of the Mozilla Common Voice corpus, focusing on version 24.0 (December 2025) and contextualizing trends across major releases. We document rapid growth from 1.49 recorded hours in mid-2023 to 2,768.7 total hours in 2025, including 975.89 validated hours available for supervised ASR training.\n  Beyond scale, we analyze validation throughput, contributor participation inequality, demographic metadata completeness, and sentence-level concentration in the validated subset. We find that participation is extremely concentrated (Gini = 0.941), age representation is strongly skewed toward young adults, and 41.97\\% of clips lack self-reported gender labels, limiting subgroup auditing based on metadata. At the textual level, prompt reuse is moderate: 35.88\\% of unique sentences account for 50\\% of validated clips, suggesting that structural concentration is driven primarily by uneven contributor activity rather than dominance of a small prompt set.\n  These results provide a quantitative audit of a rapidly scaling low-resource speech corpus and highlight practical priorities for improving dataset maturity, including expanded validation capacity and broader demographic participation.", "AI": {"tldr": "\u8be5\u8bba\u6587\u91cf\u5316\u5206\u6790\u4e86Mozilla Common Voice\u8bed\u6599\u5e93\u4e2dPashto\u8bed\u97f3\u6570\u636e\u7684\u5feb\u901f\u589e\u957f\u548c\u7ed3\u6784\u7279\u5f81\uff0c\u6307\u51fa\u53c2\u4e0e\u4e25\u91cd\u96c6\u4e2d\u548c\u4eba\u53e3\u7edf\u8ba1\u4fe1\u606f\u7f3a\u5931\u95ee\u9898\uff0c\u63d0\u51fa\u6269\u5c55\u9a8c\u8bc1\u80fd\u529b\u548c\u591a\u6837\u5316\u53c2\u4e0e\u662f\u63d0\u5347\u6570\u636e\u96c6\u8d28\u91cf\u7684\u91cd\u70b9\u3002", "motivation": "\u8bb8\u591a\u901a\u7528\u8bed\u8a00\u7684\u516c\u5f00\u8bed\u97f3\u6570\u636e\u8d44\u6e90\u6709\u9650\uff0cPashto\u4f5c\u4e3a\u62e5\u67096000\u591a\u4e07\u4f7f\u7528\u8005\u7684\u8bed\u8a00\uff0c\u7f3a\u4e4f\u9002\u5408\u73b0\u4ee3\u8bed\u97f3\u8bc6\u522b\u5f00\u53d1\u7684\u5927\u89c4\u6a21\u5f00\u653e\u8bb8\u53ef\u8bed\u97f3\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u5bf9\u73b0\u6709\u8d44\u6e90\u8fdb\u884c\u5206\u6790\u4ee5\u63a8\u52a8\u8be5\u8bed\u79cdASR\u7cfb\u7edf\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u6790Mozilla Common Voice\u8bed\u6599\u5e93\u4e2dPashto\u8bed\u97f3\u6570\u636e\u7684\u7248\u672c\u53d1\u5e03\u60c5\u51b5\uff0c\u91c7\u96c6\u5f55\u97f3\u65f6\u957f\u3001\u9a8c\u8bc1\u5c0f\u65f6\u6570\u3001\u53c2\u4e0e\u8005\u4e0d\u5e73\u7b49\u5ea6\uff08\u7528Gini\u7cfb\u6570\u8861\u91cf\uff09\u3001\u4eba\u53e3\u7edf\u8ba1\u5143\u6570\u636e\u5b8c\u6574\u6027\u548c\u6587\u672c\u7ea7\u522b\u53e5\u5b50\u91cd\u590d\u5ea6\u7b49\u6307\u6807\uff0c\u8fdb\u884c\u6570\u636e\u89c4\u6a21\u548c\u8d28\u91cf\u7684\u7efc\u5408\u8bc4\u4f30\u3002", "result": "Pashto\u8bed\u97f3\u6570\u636e\u4ece2023\u5e74\u4e2d\u671f\u76841.49\u5c0f\u65f6\u8fc5\u901f\u589e\u957f\u52302025\u5e74\u76842768.7\u5c0f\u65f6\uff0c\u542b975.89\u5c0f\u65f6\u7ecf\u8fc7\u9a8c\u8bc1\u4e14\u9002\u5408\u76d1\u7763\u8bad\u7ec3\uff1b\u4f46\u53d1\u73b0\u53c2\u4e0e\u8005\u8d21\u732e\u6781\u5ea6\u96c6\u4e2d\uff08Gini=0.941\uff09\u3001\u5e74\u9f84\u5206\u5e03\u504f\u5e74\u8f7b\u3001\u8fd142%\u6837\u672c\u7f3a\u5c11\u6027\u522b\u6807\u7b7e\uff0c\u4e1435.88%\u7684\u72ec\u7279\u53e5\u5b50\u8d21\u732e\u4e8650%\u7684\u9a8c\u8bc1\u5f55\u97f3\uff0c\u8868\u660e\u6570\u636e\u7ed3\u6784\u96c6\u4e2d\u4e3b\u8981\u662f\u53c2\u4e0e\u8005\u6d3b\u52a8\u4e0d\u5747\uff0c\u800c\u975e\u63d0\u793a\u53e5\u91cd\u590d\u3002", "conclusion": "\u8be5\u8bba\u6587\u5bf9Pashto\u8bed\u97f3\u6570\u636e\u5728Mozilla Common Voice\u8bed\u6599\u5e93\u4e2d\u7684\u589e\u957f\u53ca\u7ed3\u6784\u7279\u5f81\u8fdb\u884c\u4e86\u8be6\u5c3d\u7684\u91cf\u5316\u5206\u6790\uff0c\u63ed\u793a\u4e86\u8bed\u97f3\u6570\u636e\u89c4\u6a21\u8fc5\u901f\u6269\u5f20\u7684\u540c\u65f6\u5b58\u5728\u6570\u636e\u9a8c\u8bc1\u6548\u7387\u3001\u53c2\u4e0e\u8005\u96c6\u4e2d\u5ea6\u9ad8\u548c\u4eba\u53e3\u7edf\u8ba1\u6807\u7b7e\u4e0d\u5b8c\u6574\u7b49\u95ee\u9898\uff0c\u5f3a\u8c03\u4e86\u6539\u8fdb\u6570\u636e\u96c6\u6210\u719f\u5ea6\u7684\u4f18\u5148\u65b9\u5411\u3002"}}
{"id": "2602.14069", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14069", "abs": "https://arxiv.org/abs/2602.14069", "authors": ["Ruipeng Jia", "Yunyi Yang", "Yuxin Wu", "Yongbo Gai", "Siyuan Tao", "Mengyu Zhou", "Jianhe Lin", "Xiaoxi Jiang", "Guanjun Jiang"], "title": "Open Rubric System: Scaling Reinforcement Learning with Pairwise Adaptive Rubric", "comment": null, "summary": "Scalar reward models compress multi-dimensional human preferences into a single opaque score, creating an information bottleneck that often leads to brittleness and reward hacking in open-ended alignment. We argue that robust alignment for non-verifiable tasks is fundamentally a principle generalization problem: reward should not be a learned function internalized into a judge, but an explicit reasoning process executed under inspectable principles. To operationalize this view, we present the Open Rubric System (OpenRS), a plug-and-play, rubrics-based LLM-as-a-Judge framework built around Pairwise Adaptive Meta-Rubrics (PAMR) and lightweight Pointwise Verifiable Rubrics (PVRs), which provide both hard-constraint guardrails and verifiable reward components when ground-truth or programmatic checks are available. OpenRS uses an explicit meta-rubric -- a constitution-like specification that governs how rubrics are instantiated, weighted, and enforced -- and instantiates adaptive rubrics on the fly by conditioning on the semantic differences between two candidate responses. It then performs criterion-wise pairwise comparisons and aggregates criterion-level preferences externally, avoiding pointwise weighted scalarization while improving discriminability in open-ended settings. To keep principles consistent yet editable across various domains, we introduce a two-level meta-rubric refinement pipeline (automated evolutionary refinement for general principles and a reproducible human-in-the-loop procedure for domain principles), complemented with pointwise verifiable rubrics that act as both guardrails against degenerate behaviors and a source of verifiable reward for objective sub-tasks. Finally, we instantiate OpenRS as reward supervision in pairwise RL training.", "AI": {"tldr": "OpenRS\u4f7f\u7528\u663e\u5f0f\u3001\u53ef\u68c0\u67e5\u7684\u63a8\u7406\u539f\u5219\u53d6\u4ee3\u4f20\u7edf\u7684\u6807\u91cf\u5956\u52b1\u6a21\u578b\uff0c\u901a\u8fc7\u6210\u5bf9\u6bd4\u8f83\u548c\u5143\u91cf\u8868\u81ea\u9002\u5e94\u673a\u5236\uff0c\u5b9e\u73b0\u66f4\u9c81\u68d2\u548c\u900f\u660e\u7684\u4eba\u5de5\u667a\u80fd\u5bf9\u9f50\u3002", "motivation": "\u6807\u91cf\u5956\u52b1\u6a21\u578b\u5c06\u591a\u7ef4\u4eba\u7c7b\u504f\u597d\u538b\u7f29\u6210\u5355\u4e00\u4e0d\u900f\u660e\u5206\u6570\uff0c\u5bfc\u81f4\u9c81\u68d2\u6027\u5dee\u548c\u5956\u52b1\u4f5c\u5f0a\uff0c\u7279\u522b\u662f\u5728\u5f00\u653e\u5f0f\u5bf9\u9f50\u4efb\u52a1\u4e2d\u3002\u63d0\u51fa\u5956\u52b1\u5e94\u4f5c\u4e3a\u53ef\u68c0\u67e5\u7684\u660e\u786e\u63a8\u7406\u8fc7\u7a0b\uff0c\u800c\u975e\u5185\u90e8\u5316\u7684\u5b66\u4e60\u51fd\u6570\uff0c\u89e3\u51b3\u975e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u901a\u7528\u5316\u95ee\u9898\u3002", "method": "\u63d0\u51faOpen Rubric System (OpenRS)\u6846\u67b6\uff0c\u57fa\u4e8e\u6210\u5bf9\u81ea\u9002\u5e94\u5143\u91cf\u8868(PAMR)\u548c\u8f7b\u91cf\u70b9\u68c0\u53ef\u9a8c\u8bc1\u5c3a\u89c4(PVRs)\uff0c\u91c7\u7528\u663e\u5f0f\u5143\u91cf\u8868\u4f5c\u4e3a\u89c4\u8303\uff0c\u8fdb\u884c\u57fa\u4e8e\u8bed\u4e49\u5dee\u5f02\u7684\u6210\u5bf9\u6bd4\u8f83\u548c\u5916\u90e8\u6c47\u603b\u504f\u597d\uff0c\u907f\u514d\u4f20\u7edf\u6807\u91cf\u5316\u5956\u52b1\u7684\u7f3a\u9677\u3002\u5e76\u8bbe\u8ba1\u4e24\u7ea7\u5143\u91cf\u8868\u7cbe\u70bc\u6d41\u7a0b\uff0c\u7ed3\u5408\u81ea\u52a8\u8fdb\u5316\u548c\u4eba\u7c7b\u5728\u73af\u65b9\u6cd5\uff0c\u786e\u4fdd\u539f\u5219\u7684\u4e00\u81f4\u6027\u548c\u53ef\u7f16\u8f91\u6027\u3002\u6700\u540e\uff0c\u5c06OpenRS\u7528\u4e8e\u6210\u5bf9\u5f3a\u5316\u5b66\u4e60\u7684\u5956\u52b1\u76d1\u7763\u3002", "result": "\u5efa\u7acb\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u5956\u52b1\u8bc4\u4f30\u6846\u67b6OpenRS\uff0c\u6709\u6548\u907f\u514d\u4fe1\u606f\u74f6\u9888\u548c\u5956\u52b1\u4f5c\u5f0a\uff0c\u63d0\u9ad8\u4e86\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u5224\u522b\u80fd\u529b\u548c\u5bf9\u504f\u597d\u7684\u89e3\u91ca\u6027\u3002\u901a\u8fc7\u4e24\u7ea7\u5143\u91cf\u8868\u7cbe\u70bc\u4fdd\u6301\u539f\u5219\u4e00\u81f4\u6027\uff0c\u4e14\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u7684\u5b50\u4efb\u52a1\u5956\u52b1\uff0c\u4fdd\u8bc1\u5bf9\u9f50\u8fc7\u7a0b\u66f4\u53ef\u9760\u3002", "conclusion": "OpenRS\u6846\u67b6\u89e3\u51b3\u4e86\u6807\u91cf\u5956\u52b1\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u663e\u5f0f\u539f\u5219\u548c\u5c42\u6b21\u5316\u5143\u91cf\u8868\u7ba1\u7406\uff0c\u63d0\u9ad8\u4e86\u5728\u5f00\u653e\u5f0f\u975e\u53ef\u9a8c\u8bc1\u4efb\u52a1\u4e2d\u7684\u5956\u52b1\u9c81\u68d2\u6027\u548c\u53ef\u9a8c\u8bc1\u6027\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u539f\u5219\u7684\u5224\u5b9a\u673a\u5236\u5728AI\u5bf9\u9f50\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.14073", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14073", "abs": "https://arxiv.org/abs/2602.14073", "authors": ["Grzegorz Statkiewicz", "Alicja Dobrzeniecka", "Karolina Seweryn", "Aleksandra Krasnod\u0119bska", "Karolina Piosek", "Katarzyna Bogusz", "Sebastian Cygert", "Wojciech Kusa"], "title": "Annotation-Efficient Vision-Language Model Adaptation to the Polish Language Using the LLaVA Framework", "comment": null, "summary": "Most vision-language models (VLMs) are trained on English-centric data, limiting their performance in other languages and cultural contexts. This restricts their usability for non-English-speaking users and hinders the development of multimodal systems that reflect diverse linguistic and cultural realities. In this work, we reproduce and adapt the LLaVA-Next methodology to create a set of Polish VLMs. We rely on a fully automated pipeline for translating and filtering existing multimodal datasets, and complement this with synthetic Polish data for OCR and culturally specific tasks. Despite relying almost entirely on automatic translation and minimal manual intervention to the training data, our approach yields strong results: we observe a +9.5% improvement over LLaVA-1.6-Vicuna-13B on a Polish-adapted MMBench, along with higher-quality captions in generative evaluations, as measured by human annotators in terms of linguistic correctness. These findings highlight that large-scale automated translation, combined with lightweight filtering, can effectively bootstrap high-quality multimodal models for low-resource languages. Some challenges remain, particularly in cultural coverage and evaluation. To facilitate further research, we make our models and evaluation dataset publicly available.", "AI": {"tldr": "\u901a\u8fc7\u81ea\u52a8\u7ffb\u8bd1\u548c\u8f7b\u91cf\u8fc7\u6ee4\uff0c\u6210\u529f\u6784\u5efa\u4e86\u9002\u7528\u6ce2\u5170\u8bed\u7684\u9ad8\u8d28\u91cf\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00\u591a\u6a21\u6001\u6027\u80fd\u3002", "motivation": "\u76ee\u524d\u5927\u591a\u6570\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u4ee5\u82f1\u8bed\u6570\u636e\u4e3a\u4e2d\u5fc3\uff0c\u9650\u5236\u4e86\u975e\u82f1\u8bed\u6587\u5316\u548c\u8bed\u8a00\u7684\u5e94\u7528\u53ca\u7cfb\u7edf\u591a\u6837\u6027\uff0c\u9700\u63a8\u5e7f\u9002\u7528\u4e8e\u5176\u4ed6\u8bed\u8a00\u7684\u591a\u6a21\u6001\u6a21\u578b\u3002", "method": "\u91c7\u7528\u81ea\u52a8\u7ffb\u8bd1\u4e0e\u6570\u636e\u8fc7\u6ee4\u73b0\u6709\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u589e\u8865\u5408\u6210\u7684\u6ce2\u5170\u8bed\u6570\u636e\uff0c\u590d\u73b0\u5e76\u9002\u914dLLaVA-Next\u8bad\u7ec3\u6d41\u7a0b\u3002", "result": "\u672c\u6587\u590d\u73b0\u5e76\u6539\u7f16\u4e86LLaVA-Next\u65b9\u6cd5\uff0c\u521b\u5efa\u4e86\u4e00\u5957\u9488\u5bf9\u6ce2\u5170\u8bed\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\uff0c\u901a\u8fc7\u81ea\u52a8\u7ffb\u8bd1\u548c\u6570\u636e\u8fc7\u6ee4\u73b0\u6709\u591a\u6a21\u6001\u6570\u636e\u96c6\uff0c\u5e76\u7ed3\u5408\u5408\u6210\u7684\u6ce2\u5170\u8bedOCR\u548c\u6587\u5316\u7279\u5b9a\u4efb\u52a1\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347\uff0c\u5728\u6ce2\u5170\u8bed\u591a\u6a21\u6001\u57fa\u51c6MMBench\u4e0a\u6bd4LLaVA-1.6-Vicuna-13B\u63d0\u5347\u4e869.5%\uff0c\u751f\u6210\u8bc4\u4ef7\u4e2d\u8bed\u8a00\u6b63\u786e\u6027\u66f4\u9ad8\u3002", "conclusion": "\u5927\u89c4\u6a21\u81ea\u52a8\u7ffb\u8bd1\u7ed3\u5408\u7b80\u5355\u8fc7\u6ee4\u80fd\u6709\u6548\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u591a\u6a21\u6001\u6a21\u578b\u8bad\u7ec3\uff0c\u4f46\u5728\u6587\u5316\u8986\u76d6\u548c\u8bc4\u4f30\u65b9\u9762\u4ecd\u6709\u6311\u6218\u3002"}}
{"id": "2602.14077", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14077", "abs": "https://arxiv.org/abs/2602.14077", "authors": ["Minghan Wang", "Ye Bai", "Thuy-Trang Vu", "Ehsan Shareghi", "Gholamreza Haffari"], "title": "GTS: Inference-Time Scaling of Latent Reasoning with a Learnable Gaussian Thought Sampler", "comment": null, "summary": "Inference-time scaling (ITS) in latent reasoning models typically introduces stochasticity through heuristic perturbations, such as dropout or fixed Gaussian noise. While these methods increase trajectory diversity, their exploration behavior is not explicitly modeled and can be inefficient under finite sampling budgets. We observe that stronger perturbations do not necessarily translate into more effective candidate trajectories, as unguided noise may disrupt internal decision structure rather than steer it. To provide a more structured alternative, we model latent thought exploration as conditional sampling from learnable densities and instantiate this idea as a Gaussian Thought Sampler (GTS). GTS predicts context-dependent perturbation distributions over continuous reasoning states and is trained with GRPO-style policy optimization while keeping the backbone frozen. Experiments on GSM8K with two latent reasoning architectures show that GTS achieves more reliable inference-time scaling than heuristic baselines. These findings indicate that improving latent ITS requires structured and optimizable exploration mechanisms rather than simply amplifying stochasticity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u53ef\u5b66\u4e60\u6270\u52a8\u5206\u5e03\u7684\u6f5c\u5728\u601d\u8003\u63a2\u7d22\u65b9\u6cd5GTS\uff0c\u63d0\u5347\u4e86\u63a8\u7406\u65f6\u95f4\u5c3a\u5ea6\u8c03\u6574\u7684\u6548\u7387\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u63a8\u7406\u65f6\u95f4\u5c3a\u5ea6\u8c03\u6574\uff08ITS\uff09\u65b9\u6cd5\u901a\u8fc7\u542f\u53d1\u5f0f\u6270\u52a8\u5f15\u5165\u968f\u673a\u6027\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u7684\u63a2\u7d22\u884c\u4e3a\u672a\u88ab\u660e\u786e\u5b9a\u4e49\u4e14\u5728\u91c7\u6837\u6709\u9650\u65f6\u6548\u7387\u4e0d\u9ad8\u3002", "method": "\u5c06\u6f5c\u5728\u601d\u8003\u63a2\u7d22\u5efa\u6a21\u4e3a\u6761\u4ef6\u91c7\u6837\u95ee\u9898\uff0c\u4f7f\u7528\u9ad8\u65af\u601d\u8003\u91c7\u6837\u5668\u9884\u6d4b\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u6270\u52a8\u5206\u5e03\uff0c\u91c7\u7528GRPO\u5f0f\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\uff0c\u4e3b\u5e72\u7f51\u7edc\u4fdd\u6301\u51bb\u7ed3\u3002", "result": "\u63d0\u51fa\u4e86\u9ad8\u65af\u601d\u8003\u91c7\u6837\u5668\uff08GTS\uff09\uff0c\u4f5c\u4e3a\u4e00\u79cd\u7ed3\u6784\u5316\u3001\u53ef\u5b66\u4e60\u7684\u6f5c\u5728\u601d\u8003\u63a2\u7d22\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301\u4e3b\u5e72\u7f51\u7edc\u56fa\u5b9a\u7684\u60c5\u51b5\u4e0b\u901a\u8fc7\u7b56\u7565\u4f18\u5316\u8bad\u7ec3\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5728\u4e24\u4e2a\u6f5c\u5728\u63a8\u7406\u67b6\u6784\u4e0a\u6bd4\u542f\u53d1\u5f0f\u65b9\u6cd5\u66f4\u53ef\u9760\u3002", "conclusion": "\u63d0\u5347\u6f5c\u5728\u63a8\u7406\u4e2d\u7684\u63a8\u7406\u65f6\u95f4\u5c3a\u5ea6\u8c03\u6574\u6548\u679c\u9700\u8981\u7ed3\u6784\u5316\u548c\u53ef\u4f18\u5316\u7684\u63a2\u7d22\u673a\u5236\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u589e\u52a0\u968f\u673a\u6027\u3002"}}
{"id": "2602.14080", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14080", "abs": "https://arxiv.org/abs/2602.14080", "authors": ["Nitay Calderon", "Eyal Ben-David", "Zorik Gekhman", "Eran Ofek", "Gal Yona"], "title": "Empty Shelves or Lost Keys? Recall Is the Bottleneck for Parametric Factuality", "comment": null, "summary": "Standard factuality evaluations of LLMs treat all errors alike, obscuring whether failures arise from missing knowledge (empty shelves) or from limited access to encoded facts (lost keys). We propose a behavioral framework that profiles factual knowledge at the level of facts rather than questions, characterizing each fact by whether it is encoded, and then by how accessible it is: cannot be recalled, can be directly recalled, or can only be recalled with inference-time computation (thinking). To support such profiling, we introduce WikiProfile, a new benchmark constructed via an automated pipeline with a prompted LLM grounded in web search. Across 4 million responses from 13 LLMs, we find that encoding is nearly saturated in frontier models on our benchmark, with GPT-5 and Gemini-3 encoding 95--98% of facts. However, recall remains a major bottleneck: many errors previously attributed to missing knowledge instead stem from failures to access it. These failures are systematic and disproportionately affect long-tail facts and reverse questions. Finally, we show that thinking improves recall and can recover a substantial fraction of failures, indicating that future gains may rely less on scaling and more on methods that improve how models utilize what they already encode.", "AI": {"tldr": "\u901a\u8fc7\u6784\u5efaWikiProfile\u57fa\u51c6\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u4e8b\u5b9e\u77e5\u8bc6\u7684\u7f16\u7801\u5df2\u63a5\u8fd1\u6781\u9650\uff0c\u56de\u5fc6\u80fd\u529b\u624d\u662f\u9650\u5236\u51c6\u786e\u6027\u7684\u5173\u952e\uff0c\u672a\u6765\u6539\u8fdb\u5e94\u4fa7\u91cd\u63d0\u5347\u77e5\u8bc6\u7684\u5229\u7528\u6548\u7387\u800c\u975e\u4ec5\u9760\u89c4\u6a21\u6269\u5927\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\u8bc4\u4f30\u65e0\u6cd5\u533a\u5206\u77e5\u8bc6\u7f3a\u5931\uff08\u7a7a\u67b6\u5b50\uff09\u548c\u5df2\u7f16\u7801\u4e8b\u5b9e\u4f46\u8bbf\u95ee\u53d7\u9650\uff08\u4e22\u5931\u94a5\u5319\uff09\uff0c\u5bfc\u81f4\u9519\u8bef\u539f\u56e0\u6df7\u6dc6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u884c\u4e3a\u6846\u67b6\uff0c\u9488\u5bf9\u4e8b\u5b9e\u8fdb\u884c\u7f16\u7801\u548c\u53ef\u8bbf\u95ee\u6027\u5206\u7c7b\uff1b\u5f15\u5165WikiProfile\u57fa\u51c6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u7ba1\u7ebf\u548c\u57fa\u4e8e\u7f51\u9875\u641c\u7d22\u7684\u63d0\u793a\u5f0f\u5927\u6a21\u578b\u6784\u5efa\u6570\u636e\u96c6\uff1b\u572813\u4e2a\u5927\u6a21\u578b\u4e0a\u7684400\u4e07\u56de\u7b54\u4e2d\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u524d\u6cbf\u6a21\u578b\uff08\u5982GPT-5\u548cGemini-3\uff09\u7f16\u7801\u63a5\u8fd1\u9971\u548c\uff0c\u8986\u76d695-98%\u4e8b\u5b9e\uff1b\u4f46\u56de\u5fc6\u80fd\u529b\u662f\u4e3b\u8981\u74f6\u9888\uff0c\u8bb8\u591a\u9519\u8bef\u6e90\u4e8e\u65e0\u6cd5\u8bbf\u95ee\u5df2\u7f16\u7801\u77e5\u8bc6\uff1b\u8bbf\u95ee\u5931\u8d25\u5bf9\u957f\u5c3e\u4e8b\u5b9e\u548c\u9006\u5411\u95ee\u9898\u5f71\u54cd\u66f4\u5927\uff1b\u63a8\u7406\uff08\u601d\u8003\uff09\u80fd\u663e\u8457\u63d0\u5347\u56de\u5fc6\uff0c\u5f25\u8865\u90e8\u5206\u5931\u8d25\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u9519\u8bef\u4e3b\u8981\u56e0\u56de\u5fc6\u5931\u8d25\u800c\u975e\u77e5\u8bc6\u7f3a\u5931\uff0c\u6539\u8fdb\u6a21\u578b\u5728\u63a8\u7406\u548c\u8bbf\u95ee\u77e5\u8bc6\u4e0a\u7684\u80fd\u529b\u662f\u63d0\u5347\u4e8b\u5b9e\u51c6\u786e\u6027\u7684\u5173\u952e\u65b9\u5411\u3002"}}
{"id": "2602.14081", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14081", "abs": "https://arxiv.org/abs/2602.14081", "authors": ["Shangqing Zhao", "Yupei Ren", "Yuhao Zhou", "Xiaopeng Bai", "Man Lan"], "title": "CCiV: A Benchmark for Structure, Rhythm and Quality in LLM-Generated Chinese \\textit{Ci} Poetry", "comment": "ARR 2025 May and Icassp 2026 submission. Working in progress", "summary": "The generation of classical Chinese \\textit{Ci} poetry, a form demanding a sophisticated blend of structural rigidity, rhythmic harmony, and artistic quality, poses a significant challenge for large language models (LLMs). To systematically evaluate and advance this capability, we introduce \\textbf{C}hinese \\textbf{Ci}pai \\textbf{V}ariants (\\textbf{CCiV}), a benchmark designed to assess LLM-generated \\textit{Ci} poetry across these three dimensions: structure, rhythm, and quality. Our evaluation of 17 LLMs on 30 \\textit{Cipai} reveals two critical phenomena: models frequently generate valid but unexpected historical variants of a poetic form, and adherence to tonal patterns is substantially harder than structural rules. We further show that form-aware prompting can improve structural and tonal control for stronger models, while potentially degrading weaker ones. Finally, we observe weak and inconsistent alignment between formal correctness and literary quality in our sample. CCiV highlights the need for variant-aware evaluation and more holistic constrained creative generation methods.", "AI": {"tldr": "\u63d0\u51faCCiV\u57fa\u51c6\u8bc4\u6d4b\u5927\u6a21\u578b\u53e4\u5178\u8bcd\u751f\u6210\uff0c\u63ed\u793a\u751f\u6210\u4e2d\u7684\u5386\u53f2\u53d8\u4f53\u3001\u97f5\u5f8b\u6311\u6218\u53ca\u63d0\u793a\u7b56\u7565\u6548\u679c\u5dee\u5f02\uff0c\u5f3a\u8c03\u9700\u8981\u66f4\u5168\u9762\u7684\u53d8\u4f53\u611f\u77e5\u8bc4\u4f30\u4e0e\u7ea6\u675f\u751f\u6210\u65b9\u6cd5\u3002", "motivation": "\u53e4\u5178\u8bcd\u751f\u6210\u8981\u6c42\u7ed3\u6784\u4e25\u683c\u3001\u97f5\u5f8b\u548c\u8c10\u7f8e\uff0c\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6ee1\u8db3\u9ad8\u8d28\u91cf\u751f\u6210\u9700\u6c42\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u8bbe\u8ba1\u4e86CCiV\u57fa\u51c6\uff0c\u5bf9LLM\u751f\u6210\u7684\u53e4\u5178\u8bcd\u8fdb\u884c\u7ed3\u6784\u3001\u97f5\u5f8b\u548c\u827a\u672f\u8d28\u91cf\u4e09\u4e2a\u7ef4\u5ea6\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002\u91c7\u7528\u5f62\u5f0f\u611f\u77e5\u63d0\u793a\u63d0\u5347\u5927\u6a21\u578b\u7684\u7ed3\u6784\u548c\u97f5\u5f8b\u63a7\u5236\u6548\u679c\u3002", "result": "\u53d1\u73b0\u6a21\u578b\u5e38\u751f\u6210\u6709\u6548\u4f46\u610f\u5916\u7684\u5386\u53f2\u53d8\u4f53\uff0c\u97f5\u5f8b\u9075\u5b88\u96be\u5ea6\u9ad8\u4e8e\u7ed3\u6784\u89c4\u5219\uff0c\u5f62\u5f0f\u611f\u77e5\u63d0\u793a\u5bf9\u5f3a\u6a21\u578b\u6709\u6548\u4f46\u5f31\u6a21\u578b\u53ef\u80fd\u4e0b\u964d\uff0c\u5f62\u5f0f\u6b63\u786e\u6027\u4e0e\u6587\u5b66\u54c1\u8d28\u5173\u8054\u5f31\u4e14\u4e0d\u4e00\u81f4\u3002", "conclusion": "\u751f\u6210\u53e4\u5178\u8bcd\u9700\u8003\u8651\u5386\u53f2\u53d8\u4f53\u548c\u97f5\u5f8b\u6311\u6218\uff0c\u5f62\u5f0f\u611f\u77e5\u63d0\u793a\u80fd\u63d0\u5347\u5927\u6a21\u578b\u751f\u6210\u8d28\u91cf\uff0c\u4f46\u4ecd\u9700\u53d1\u5c55\u66f4\u5168\u9762\u7684\u7ea6\u675f\u4e0e\u8bc4\u4f30\u65b9\u6cd5\u4ee5\u589e\u5f3a\u521b\u4f5c\u8d28\u91cf\u3002"}}
{"id": "2602.14100", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14100", "abs": "https://arxiv.org/abs/2602.14100", "authors": ["Akhilesh Kakolu Ramarao", "Kevin Tang", "Dinah Baer-Henney"], "title": "Character-aware Transformers Learn an Irregular Morphological Pattern Yet None Generalize Like Humans", "comment": null, "summary": "Whether neural networks can serve as cognitive models of morphological learning remains an open question. Recent work has shown that encoder-decoder models can acquire irregular patterns, but evidence that they generalize these patterns like humans is mixed. We investigate this using the Spanish \\emph{L-shaped morphome}, where only the first-person singular indicative (e.g., \\textit{pongo} `I put') shares its stem with all subjunctive forms (e.g., \\textit{ponga, pongas}) despite lacking apparent phonological, semantic, or syntactic motivation. We compare five encoder-decoder transformers varying along two dimensions: sequential vs. position-invariant positional encoding, and atomic vs. decomposed tag representations. Positional encoding proves decisive: position-invariant models recover the correct L-shaped paradigm clustering even when L-shaped verbs are scarce in training, whereas sequential positional encoding models only partially capture the pattern. Yet none of the models productively generalize this pattern to novel forms. Position-invariant models generalize the L-shaped stem across subjunctive cells but fail to extend it to the first-person singular indicative, producing a mood-based generalization rather than the L-shaped morphomic pattern. Humans do the opposite, generalizing preferentially to the first-person singular indicative over subjunctive forms. None of the models reproduce the human pattern, highlighting the gap between statistical pattern reproduction and morphological abstraction.", "AI": {"tldr": "\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u867d\u80fd\u5b66\u4e60\u4e0d\u89c4\u5219\u5f62\u6001\u6a21\u5f0f\uff0c\u4f46\u672a\u80fd\u50cf\u4eba\u7c7b\u90a3\u6837\u6709\u6548\u6cdb\u5316\u548c\u62bd\u8c61\uff0c\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u662f\u5426\u80fd\u4f5c\u4e3a\u5f62\u6001\u5b66\u4e60\u7684\u8ba4\u77e5\u6a21\u578b\uff0c\u5c24\u5176\u662f\u80fd\u5426\u50cf\u4eba\u7c7b\u4e00\u6837\u63a8\u5e7f\u4e0d\u89c4\u5219\u5f62\u6001\u6a21\u5f0f\u3002", "method": "\u6bd4\u8f83\u4e94\u79cd\u7f16\u7801\u5668-\u89e3\u7801\u5668\u53d8\u538b\u5668\u6a21\u578b\uff0c\u5206\u6790\u4f4d\u7f6e\u7f16\u7801\uff08\u987a\u5e8f\u7f16\u7801\u4e0e\u4f4d\u7f6e\u4e0d\u53d8\u7f16\u7801\uff09\u548c\u6807\u7b7e\u8868\u793a\uff08\u539f\u5b50\u6807\u7b7e\u4e0e\u5206\u89e3\u6807\u7b7e\uff09\u5bf9\u897f\u73ed\u7259\u8bedL\u578b\u5f62\u6001\u6a21\u5f0f\u5b66\u4e60\u7684\u5f71\u54cd\u3002", "result": "\u4f4d\u7f6e\u4e0d\u53d8\u7684\u7f16\u7801\u80fd\u66f4\u597d\u5730\u6355\u6349L\u578b\u8303\u5f0f\u7684\u805a\u7c7b\uff0c\u5373\u4f7f\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\uff1b\u987a\u5e8f\u4f4d\u7f6e\u7f16\u7801\u6a21\u578b\u5219\u8868\u73b0\u8f83\u5dee\u3002\u5c3d\u7ba1\u5982\u6b64\uff0c\u6240\u6709\u6a21\u578b\u90fd\u672a\u80fd\u4ea7\u751f\u6210\u719f\u7684\u63a8\u5e7f\u80fd\u529b\uff0c\u4e14\u6cdb\u5316\u6a21\u5f0f\u4e0e\u4eba\u7c7b\u4e0d\u540c\u3002", "conclusion": "\u5f53\u524d\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u5f62\u6001\u5b66\u4e60\u4e0a\u4ecd\u672a\u8fbe\u5230\u4eba\u7c7b\u7684\u62bd\u8c61\u548c\u6cdb\u5316\u6c34\u5e73\uff0c\u663e\u793a\u7edf\u8ba1\u6a21\u5f0f\u590d\u5236\u4e0e\u5f62\u6001\u62bd\u8c61\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2602.14162", "categories": ["cs.CL", "cs.CV", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.14162", "abs": "https://arxiv.org/abs/2602.14162", "authors": ["Tao Xu"], "title": "Index Light, Reason Deep: Deferred Visual Ingestion for Visual-Dense Document Question Answering", "comment": "24 pages, 9 figures, 9 tables", "summary": "Existing multimodal document question answering methods universally adopt a supply-side ingestion strategy: running a Vision-Language Model (VLM) on every page during indexing to generate comprehensive descriptions, then answering questions through text retrieval. However, this \"pre-ingestion\" approach is costly (a 113-page engineering drawing package requires approximately 80,000 VLM tokens), end-to-end unreliable (VLM outputs may fail to be correctly retrieved due to format mismatches in the retrieval infrastructure), and irrecoverable once it fails. This paper proposes the Deferred Visual Ingestion (DVI) framework, adopting a demand-side ingestion strategy: the indexing phase performs only lightweight metadata extraction, deferring visual understanding to the moment users pose specific questions. DVI's core principle is \"Index for locating, not understanding\"--achieving page localization through structured metadata indexes and BM25 full-text search, then sending original images along with specific questions to a VLM for targeted analysis. Experiments on two real industrial engineering drawings (113 pages + 7 pages) demonstrate that DVI achieves comparable overall accuracy at zero ingestion VLM cost (46.7% vs. 48.9%), an effectiveness rate of 50% on visually necessary queries (vs. 0% for pre-ingestion), and 100% page localization (98% search space compression). DVI also supports interactive refinement and progressive caching, transforming the \"QA accuracy\" problem into a \"page localization\" problem--once the correct drawing page is found, obtaining the answer becomes a matter of interaction rounds.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7684DVI\u6846\u67b6\u901a\u8fc7\u9700\u6c42\u4fa7\u5ef6\u8fdf\u89c6\u89c9\u6444\u53d6\uff0c\u5b9e\u73b0\u4e86\u4f4e\u6210\u672c\u9ad8\u6548\u7684\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\uff0c\u63d0\u5347\u4e86\u51c6\u786e\u7387\u548c\u7cfb\u7edf\u53ef\u9760\u6027\u3002", "motivation": "\u4f20\u7edf\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u65b9\u6cd5\u5728\u6587\u6863\u7d22\u5f15\u9636\u6bb5\u5c31\u8fd0\u884c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u751f\u6210\u5168\u9762\u63cf\u8ff0\uff0c\u6210\u672c\u9ad8\u4e14\u6613\u5931\u8d25\u3002", "method": "\u63d0\u51fa\u5ef6\u8fdf\u89c6\u89c9\u6444\u53d6\uff08DVI\uff09\u6846\u67b6\uff0c\u91c7\u7528\u9700\u6c42\u4fa7\u6444\u53d6\u7b56\u7565\uff0c\u7d22\u5f15\u9636\u6bb5\u4ec5\u63d0\u53d6\u8f7b\u91cf\u5143\u6570\u636e\uff0c\u89c6\u89c9\u7406\u89e3\u63a8\u8fdf\u5230\u7528\u6237\u63d0\u51fa\u5177\u4f53\u95ee\u9898\u65f6\u8fdb\u884c\uff0c\u7ed3\u5408\u7ed3\u6784\u5316\u5143\u6570\u636e\u7d22\u5f15\u548cBM25\u5168\u6587\u641c\u7d22\u5b9e\u73b0\u9875\u9762\u5b9a\u4f4d\uff0c\u5e76\u5bf9\u7279\u5b9a\u9875\u9762\u548c\u95ee\u9898\u8c03\u7528VLM\u3002", "result": "DVI\u5728\u4e24\u4e2a\u771f\u5b9e\u5de5\u7a0b\u56fe\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u964d\u4f4e\u4e86VLM\u8ba1\u7b97\u6210\u672c\uff0c\u5b9e\u73b0\u4e8650%\u7684\u89c6\u89c9\u5fc5\u8981\u67e5\u8be2\u6548\u679c\u7387\u548c100%\u9875\u9762\u5b9a\u4f4d\u7387\uff0c\u4e14\u652f\u6301\u4ea4\u4e92\u5f0f\u4f18\u5316\u548c\u6e10\u8fdb\u7f13\u5b58\u3002", "conclusion": "DVI\u6846\u67b6\u5c06\u95ee\u7b54\u51c6\u786e\u7387\u95ee\u9898\u8f6c\u5316\u4e3a\u9875\u9762\u5b9a\u4f4d\u95ee\u9898\uff0c\u6210\u529f\u63d0\u9ad8\u4e86\u6548\u7387\u548c\u53ef\u9760\u6027\uff0c\u4e3a\u591a\u6a21\u6001\u6587\u6863\u95ee\u7b54\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u7ecf\u6d4e\u3001\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.14188", "categories": ["cs.CL", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.14188", "abs": "https://arxiv.org/abs/2602.14188", "authors": ["Nima Esmi", "Maryam Nezhad-Moghaddam", "Fatemeh Borhani", "Asadollah Shahbahrami", "Amin Daemdoost", "Georgi Gaydadjiev"], "title": "GPT-5 vs Other LLMs in Long Short-Context Performance", "comment": "10 pages, 7 figures. Accepted for publication in the 3rd International Conference on Foundation and Large Language Models (FLLM2025). IEEE. The final version will be available in IEEE Xplore", "summary": "With the significant expansion of the context window in Large Language Models (LLMs), these models are theoretically capable of processing millions of tokens in a single pass. However, research indicates a significant gap between this theoretical capacity and the practical ability of models to robustly utilize information within long contexts, especially in tasks that require a comprehensive understanding of numerous details. This paper evaluates the performance of four state-of-the-art models (Grok-4, GPT-4, Gemini 2.5, and GPT-5) on long short-context tasks. For this purpose, three datasets were used: two supplementary datasets for retrieving culinary recipes and math problems, and a primary dataset of 20K social media posts for depression detection. The results show that as the input volume on the social media dataset exceeds 5K posts (70K tokens), the performance of all models degrades significantly, with accuracy dropping to around 50-53% for 20K posts. Notably, in the GPT-5 model, despite the sharp decline in accuracy, its precision remained high at approximately 95%, a feature that could be highly effective for sensitive applications like depression detection. This research also indicates that the \"lost in the middle\" problem has been largely resolved in newer models. This study emphasizes the gap between the theoretical capacity and the actual performance of models on complex, high-volume data tasks and highlights the importance of metrics beyond simple accuracy for practical applications.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u56db\u79cd\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u8d85\u957f\u4e0a\u4e0b\u6587\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u6a21\u578b\u5728\u8d85\u8fc75\u5343\u6761\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\uff08\u7ea67\u4e07\u8bcd\uff09\u65f6\u51c6\u786e\u7387\u663e\u8457\u4e0b\u964d\uff0c\u4f46GPT-5\u7684\u7cbe\u786e\u7387\u4fdd\u6301\u8f83\u9ad8\uff0c\u9002\u5408\u654f\u611f\u4efb\u52a1\u3002", "motivation": "\u867d\u7136\u7406\u8bba\u4e0a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5904\u7406\u8d85\u957f\u4e0a\u4e0b\u6587\u7684\u80fd\u529b\uff0c\u4f46\u5b9e\u9645\u5229\u7528\u6548\u7387\u548c\u6027\u80fd\u8868\u73b0\u4e0d\u8db3\uff0c\u5c24\u5176\u5728\u9700\u8981\u7efc\u5408\u7406\u89e3\u5927\u91cf\u7ec6\u8282\u7684\u4fe1\u606f\u5bc6\u96c6\u578b\u4efb\u52a1\u4e2d\uff0c\u8bc4\u4f30\u5176\u771f\u5b9e\u8868\u73b0\u4e0e\u63d0\u5347\u7a7a\u95f4\u5341\u5206\u5fc5\u8981\u3002", "method": "\u9009\u7528Grok-4\u3001GPT-4\u3001Gemini 2.5\u548cGPT-5\u56db\u79cd\u5148\u8fdb\u6a21\u578b\uff0c\u5229\u7528\u4e09\u4e2a\u6570\u636e\u96c6\uff08\u4e24\u4e2a\u8865\u5145\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u5305\u542b2\u4e07\u6761\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u7684\u4e3b\u6570\u636e\u96c6\uff09\u8fdb\u884c\u957f\u77ed\u4e0a\u4e0b\u6587\u4efb\u52a1\u6d4b\u8bd5\uff0c\u5e76\u5206\u6790\u6a21\u578b\u6027\u80fd\u968f\u8f93\u5165\u89c4\u6a21\u53d8\u5316\u7684\u8868\u73b0\u3002", "result": "\u5f53\u8f93\u5165\u91cf\u8d85\u8fc75\u5343\u6761\u793e\u4ea4\u5a92\u4f53\u5e16\u5b50\u65f6\uff0c\u6240\u6709\u6a21\u578b\u51c6\u786e\u7387\u660e\u663e\u4e0b\u964d\u81f350%-53%\uff0c\u4f46GPT-5\u4fdd\u6301\u7ea695%\u7684\u9ad8\u7cbe\u786e\u7387\u3002\u6b64\u5916\uff0c\u201c\u4e2d\u95f4\u4e22\u5931\u201d\u95ee\u9898\u5728\u65b0\u6a21\u578b\u4e2d\u57fa\u672c\u89e3\u51b3\uff0c\u663e\u793a\u4e86\u6a21\u578b\u5b9e\u9645\u5e94\u7528\u7684\u6027\u80fd\u74f6\u9888\u548c\u8bc4\u4ef7\u6807\u51c6\u7684\u591a\u6837\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u7406\u8bba\u4e0a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u5904\u7406\u767e\u4e07\u7ea7\u522b\u7684\u4e0a\u4e0b\u6587\u8bcd\u6c47\uff0c\u5b9e\u9645\u8868\u73b0\u5c24\u5176\u662f\u5728\u590d\u6742\u4e14\u5927\u91cf\u6570\u636e\u4efb\u52a1\u4e2d\u4f9d\u65e7\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u65b0\u6a21\u578b\u89e3\u51b3\u4e86\u201c\u4e2d\u95f4\u4e22\u5931\u201d\u95ee\u9898\uff0c\u4f46\u51c6\u786e\u7387\u4e0b\u964d\u660e\u663e\uff0c\u9700\u5173\u6ce8\u7cbe\u786e\u7387\u7b49\u591a\u7ef4\u5ea6\u6307\u6807\u3002"}}
{"id": "2602.14189", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14189", "abs": "https://arxiv.org/abs/2602.14189", "authors": ["Samir Abdaljalil", "Erchin Serpedin", "Hasan Kurban"], "title": "Knowing When Not to Answer: Abstention-Aware Scientific Reasoning", "comment": null, "summary": "Large language models are increasingly used to answer and verify scientific claims, yet existing evaluations typically assume that a model must always produce a definitive answer. In scientific settings, however, unsupported or uncertain conclusions can be more harmful than abstaining. We study this problem through an abstention-aware verification framework that decomposes scientific claims into minimal conditions, audits each condition against available evidence using natural language inference (NLI), and selectively decides whether to support, refute, or abstain. We evaluate this framework across two complementary scientific benchmarks: SciFact and PubMedQA, covering both closed-book and open-domain evidence settings. Experiments are conducted with six diverse language models, including encoder-decoder, open-weight chat models, and proprietary APIs. Across all benchmarks and models, we observe that raw accuracy varies only modestly across architectures, while abstention plays a critical role in controlling error. In particular, confidence-based abstention substantially reduces risk at moderate coverage levels, even when absolute accuracy improvements are limited. Our results suggest that in scientific reasoning tasks, the primary challenge is not selecting a single best model, but rather determining when available evidence is sufficient to justify an answer. This work highlights abstention-aware evaluation as a practical and model-agnostic lens for assessing scientific reliability, and provides a unified experimental basis for future work on selective reasoning in scientific domains. Code is available at https://github.com/sabdaljalil2000/ai4science .", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u653e\u5f03\u673a\u5236\u7684\u79d1\u5b66\u58f0\u660e\u9a8c\u8bc1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3\u58f0\u660e\u548c\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u907f\u514d\u76f2\u76ee\u7ed9\u51fa\u7ed3\u8bba\uff0c\u63d0\u9ad8\u79d1\u5b66\u4fe1\u606f\u7684\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4ef7\u5047\u8bbe\u6a21\u578b\u5fc5\u987b\u59cb\u7ec8\u7ed9\u51fa\u7b54\u6848\uff0c\u7136\u800c\u5728\u79d1\u5b66\u9886\u57df\uff0c\u4e0d\u652f\u6301\u6216\u4e0d\u786e\u5b9a\u7684\u7ed3\u8bba\u6bd4\u76f2\u76ee\u56de\u7b54\u66f4\u6709\u5bb3\uff0c\u56e0\u6b64\u9700\u8981\u6709\u6548\u8bc6\u522b\u4f55\u65f6\u5e94\u653e\u5f03\u56de\u7b54\uff0c\u63d0\u9ad8\u79d1\u5b66\u7ed3\u8bba\u7684\u53ef\u9760\u6027\u3002", "method": "\u6784\u5efa\u653e\u5f03\u610f\u8bc6\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u79d1\u5b66\u58f0\u660e\u62c6\u5206\u4e3a\u6700\u5c0f\u6761\u4ef6\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u5bf9\u6bcf\u4e2a\u6761\u4ef6\u4e0e\u8bc1\u636e\u5339\u914d\uff0c\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u51b3\u5b9a\u652f\u6301\u3001\u53cd\u9a73\u6216\u653e\u5f03\uff1b\u5728SciFact\u548cPubMedQA\u6570\u636e\u96c6\u4e0a\u6d4b\u8bd5\u591a\u79cd\u6a21\u578b\u548c\u8bbe\u7f6e\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u8bc6\u522b\u662f\u5426\u5e94\u5f53\u653e\u5f03\u56de\u7b54\u7684\u79d1\u5b66\u63a8\u7406\u9a8c\u8bc1\u6846\u67b6\uff0c\u5c06\u79d1\u5b66\u58f0\u660e\u5206\u89e3\u4e3a\u6700\u5c0f\u6761\u4ef6\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u5ba1\u6838\u8bc1\u636e\u3001\u652f\u6301\u6216\u5426\u5b9a\u8fd9\u4e9b\u6761\u4ef6\uff0c\u6216\u9009\u62e9\u653e\u5f03\u3002\u901a\u8fc7\u5728SciFact\u548cPubMedQA\u4e24\u4e2a\u79d1\u5b66\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9\u516d\u79cd\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\uff0c\u53d1\u73b0\u76f4\u63a5\u51c6\u786e\u7387\u53d8\u5316\u4e0d\u5927\uff0c\u4f46\u901a\u8fc7\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u653e\u5f03\u7b56\u7565\u80fd\u663e\u8457\u51cf\u5c11\u9519\u8bef\u98ce\u9669\uff0c\u63d0\u9ad8\u79d1\u5b66\u63a8\u7406\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u79d1\u5b66\u63a8\u7406\u4efb\u52a1\u7684\u5173\u952e\u5728\u4e8e\u5224\u65ad\u8bc1\u636e\u662f\u5426\u5145\u5206\u652f\u6301\u7b54\u6848\uff0c\u6bd4\u5355\u7eaf\u9009\u62e9\u6700\u4f18\u6a21\u578b\u66f4\u91cd\u8981\uff1b\u653e\u5f03\u673a\u5236\u663e\u8457\u964d\u4f4e\u98ce\u9669\uff0c\u662f\u63d0\u5347\u79d1\u5b66\u6a21\u578b\u53ef\u4fe1\u5ea6\u7684\u6709\u6548\u624b\u6bb5\u3002"}}
{"id": "2602.14238", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14238", "abs": "https://arxiv.org/abs/2602.14238", "authors": ["Ghaly Hussein"], "title": "We can still parse using syntactic rules", "comment": null, "summary": "This research introduces a new parsing approach, based on earlier syntactic work on context free grammar (CFG) and generalized phrase structure grammar (GPSG). The approach comprises both a new parsing algorithm and a set of syntactic rules and features that overcome the limitations of CFG. It also generates both dependency and constituency parse trees, while accommodating noise and incomplete parses. The system was tested on data from Universal Dependencies, showing a promising average Unlabeled Attachment Score (UAS) of 54.5% in the development dataset (7 corpora) and 53.8% in the test set (12 corpora). The system also provides multiple parse hypotheses, allowing further reranking to improve parsing accuracy. This approach also leverages much of the theoretical syntactic work since the 1950s to be used within a computational context. The application of this approach provides a transparent and interpretable NLP model to process language input.", "AI": {"tldr": "\u57fa\u4e8eCFG\u548cGPSG\u7406\u8bba\uff0c\u63d0\u51fa\u65b0\u89e3\u6790\u7b97\u6cd5\u53ca\u89c4\u5219\uff0c\u751f\u6210\u4f9d\u5b58\u548c\u6210\u5206\u53e5\u6cd5\u6811\uff0c\u5904\u7406\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u6570\u636e\uff0c\u5728\u591a\u4e2a\u8bed\u6599\u5e93\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u89e3\u6790\u51c6\u786e\u7387\u3002", "motivation": "\u514b\u670d\u4f20\u7edfCFG\u7684\u5c40\u9650\u6027\uff0c\u540c\u65f6\u5229\u75281950\u5e74\u4ee3\u4ee5\u6765\u7684\u7406\u8bba\u53e5\u6cd5\u6210\u679c\uff0c\u5c06\u5176\u5e94\u7528\u4e8e\u8ba1\u7b97\u8bed\u5883\u4e2d\uff0c\u5b9e\u73b0\u900f\u660e\u4e14\u53ef\u89e3\u91ca\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u4e0a\u4e0b\u6587\u65e0\u5173\u6587\u6cd5\uff08CFG\uff09\u548c\u5e7f\u4e49\u77ed\u8bed\u7ed3\u6784\u6587\u6cd5\uff08GPSG\uff09\u7684\u65b0\u89e3\u6790\u7b97\u6cd5\u53ca\u53e5\u6cd5\u89c4\u5219\u4e0e\u7279\u5f81\u3002\u8be5\u65b9\u6cd5\u751f\u6210\u4f9d\u5b58\u53e5\u6cd5\u6811\u548c\u6210\u5206\u53e5\u6cd5\u6811\uff0c\u80fd\u5904\u7406\u566a\u58f0\u548c\u4e0d\u5b8c\u6574\u89e3\u6790\u3002", "result": "\u5728Universal Dependencies\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e8654.5%\u7684\u5f00\u53d1\u96c6\u5e73\u5747\u65e0\u6807\u6ce8\u4f9d\u5b58\u51c6\u786e\u7387\uff08UAS\uff09\u548c53.8%\u7684\u6d4b\u8bd5\u96c6\u5e73\u5747UAS\uff0c\u4e14\u652f\u6301\u591a\u89e3\u6790\u5047\u8bbe\u4ee5\u8fdb\u884c\u91cd\u6392\u5e8f\u63d0\u5347\u51c6\u786e\u7387\u3002", "conclusion": "\u65b0\u65b9\u6cd5\u6709\u6548\u514b\u670d\u4e86CFG\u7684\u4e0d\u8db3\uff0c\u7ed3\u5408\u7406\u8bba\u53e5\u6cd5\u548c\u8ba1\u7b97\u5b9e\u8df5\uff0c\u5b9e\u73b0\u4e86\u4e00\u79cd\u900f\u660e\u3001\u53ef\u89e3\u91ca\u4e14\u51c6\u786e\u7684\u81ea\u7136\u8bed\u8a00\u89e3\u6790\u7cfb\u7edf\u3002"}}
{"id": "2602.14257", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14257", "abs": "https://arxiv.org/abs/2602.14257", "authors": ["Lingxiang Hu", "Yiding Sun", "Tianle Xia", "Wenwei Li", "Ming Xu", "Liqun Liu", "Peng Shu", "Huan Yu", "Jie Jiang"], "title": "AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents", "comment": "15 pages, 11 figures", "summary": "While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical demands of specialized domains like advertising and marketing analytics. In these fields, tasks are inherently more complex, often requiring multi-round interaction with professional marketing tools. To address this gap, we propose AD-Bench, a benchmark designed based on real-world business requirements of advertising and marketing platforms. AD-Bench is constructed from real user marketing analysis requests, with domain experts providing verifiable reference answers and corresponding reference tool-call trajectories. The benchmark categorizes requests into three difficulty levels (L1-L3) to evaluate agents' capabilities under multi-round, multi-tool collaboration. Experiments show that on AD-Bench, Gemini-3-Pro achieves Pass@1 = 68.0% and Pass@3 = 83.0%, but performance drops significantly on L3 to Pass@1 = 49.4% and Pass@3 = 62.1%, with a trajectory coverage of 70.1%, indicating that even state-of-the-art models still exhibit substantial capability gaps in complex advertising and marketing analysis scenarios. AD-Bench provides a realistic benchmark for evaluating and improving advertising marketing agents, the leaderboard and code can be found at https://github.com/Emanual20/adbench-leaderboard.", "AI": {"tldr": "\u63d0\u51faAD-Bench\u57fa\u4e8e\u771f\u5b9e\u8425\u9500\u5206\u6790\u4efb\u52a1\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4ee5\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u5e7f\u544a\u8425\u9500\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u5b9e\u9a8c\u8bc1\u660e\u73b0\u9636\u6bb5\u6a21\u578b\u4ecd\u5b58\u8f83\u5927\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709LLM\u8bc4\u6d4b\u591a\u57fa\u4e8e\u7406\u60f3\u5316\u6a21\u62df\uff0c\u65e0\u6cd5\u53cd\u6620\u5e7f\u544a\u548c\u8425\u9500\u5206\u6790\u7b49\u4e13\u4e1a\u9886\u57df\u590d\u6742\u3001\u591a\u8f6e\u4ea4\u4e92\u5b9e\u9645\u9700\u6c42\uff0c\u7f3a\u4e4f\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u8bc4\u6d4b\u57fa\u51c6\u3002", "method": "\u8bbe\u8ba1\u5e76\u6784\u5efa\u57fa\u4e8e\u771f\u5b9e\u7528\u6237\u8425\u9500\u5206\u6790\u8bf7\u6c42\u7684AD-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9080\u8bf7\u9886\u57df\u4e13\u5bb6\u63d0\u4f9b\u53ef\u9a8c\u8bc1\u53c2\u8003\u7b54\u6848\u548c\u5de5\u5177\u8c03\u7528\u8f68\u8ff9\uff0c\u5c06\u4efb\u52a1\u5206\u4e3a\u4e09\u4e2a\u96be\u5ea6\u7b49\u7ea7\uff0c\u8fdb\u884c\u591a\u8f6e\u4ea4\u4e92\u548c\u591a\u5de5\u5177\u534f\u4f5c\u7684\u6027\u80fd\u8bc4\u6d4b\u3002", "result": "Gemini-3-Pro\u5728AD-Bench\u6574\u4f53\u8868\u73b0\u4e3aPass@1=68.0%\u3001Pass@3=83.0%\u3002\u4f46\u5728\u6700\u9ad8\u96be\u5ea6L3\u4efb\u52a1\u4e2d\uff0c\u8868\u73b0\u5927\u5e45\u4e0b\u964d\u81f3Pass@1=49.4%\u3001Pass@3=62.1%\uff0c\u8f68\u8ff9\u8986\u76d6\u7387\u4e3a70.1%\uff0c\u8868\u660e\u6311\u6218\u6027\u4efb\u52a1\u4e2d\u6a21\u578b\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "AD-Bench\u57fa\u4e8e\u771f\u5b9e\u5e7f\u544a\u53ca\u8425\u9500\u4e1a\u52a1\u9700\u6c42\uff0c\u80fd\u6709\u6548\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u591a\u8f6e\u3001\u591a\u5de5\u5177\u534f\u4f5c\u7684\u5b9e\u9645\u8425\u9500\u5206\u6790\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002\u5373\u4f7f\u662f\u5148\u8fdb\u6a21\u578b\u5982Gemini-3-Pro\uff0c\u5728\u6700\u9ad8\u96be\u5ea6\u4efb\u52a1\u4e0a\u4ecd\u8868\u73b0\u51fa\u663e\u8457\u4e0d\u8db3\uff0c\u663e\u793a\u73b0\u6709\u6a21\u578b\u5728\u4e13\u4e1a\u9886\u57df\u4ecd\u6709\u8f83\u5927\u63d0\u5347\u7a7a\u95f4\u3002"}}
{"id": "2602.14259", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14259", "abs": "https://arxiv.org/abs/2602.14259", "authors": ["Matic Korun"], "title": "Detecting LLM Hallucinations via Embedding Cluster Geometry: A Three-Type Taxonomy with Measurable Signatures", "comment": "9 pages, 5 figures", "summary": "We propose a geometric taxonomy of large language model hallucinations based on observable signatures in token embedding cluster structure. By analyzing the static embedding spaces of 11 transformer models spanning encoder (BERT, RoBERTa, ELECTRA, DeBERTa, ALBERT, MiniLM, DistilBERT) and decoder (GPT-2) architectures, we identify three operationally distinct hallucination types: Type 1 (center-drift) under weak context, Type 2 (wrong-well convergence) to locally coherent but contextually incorrect cluster regions, and Type 3 (coverage gaps) where no cluster structure exists. We introduce three measurable geometric statistics: \u03b1 (polarity coupling), \\b{eta} (cluster cohesion), and \u03bb_s (radial information gradient). Across all 11 models, polarity structure (\u03b1 > 0.5) is universal (11/11), cluster cohesion (\\b{eta} > 0) is universal (11/11), and the radial information gradient is significant (9/11, p < 0.05). We demonstrate that the two models failing \u03bb_s significance -- ALBERT and MiniLM -- do so for architecturally explicable reasons: factorized embedding compression and distillation-induced isotropy, respectively. These findings establish the geometric prerequisites for type-specific hallucination detection and yield testable predictions about architecture-dependent vulnerability profiles.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee4\u724c\u5d4c\u5165\u7c07\u7ed3\u6784\u51e0\u4f55\u7279\u5f81\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e7b\u89c9\u5206\u7c7b\u65b9\u6cd5\u3002\u901a\u8fc7\u5206\u679011\u79cd\u53d8\u6362\u5668\u6a21\u578b\u7684\u9759\u6001\u5d4c\u5165\u7a7a\u95f4\uff0c\u8bc6\u522b\u4e86\u4e09\u79cd\u5e7b\u89c9\u7c7b\u578b\u53ca\u5176\u51e0\u4f55\u7edf\u8ba1\u6307\u6807\uff0c\u5e76\u63a2\u8ba8\u4e86\u6a21\u578b\u67b6\u6784\u5bf9\u5e7b\u89c9\u8868\u73b0\u7684\u5f71\u54cd\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u7cfb\u7edf\u5206\u7c7b\u548c\u53ef\u6d4b\u91cf\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u9650\u5236\u4e86\u5e7b\u89c9\u68c0\u6d4b\u548c\u7f13\u89e3\u65b9\u6cd5\u7684\u5f00\u53d1\u3002", "method": "\u901a\u8fc7\u5206\u679011\u4e2a\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u67b6\u6784\u7684\u53d8\u6362\u5668\u6a21\u578b\u7684\u9759\u6001\u5d4c\u5165\u7a7a\u95f4\uff0c\u5b9a\u4e49\u4e86\u4e09\u79cd\u5e7b\u89c9\u7c7b\u578b\u53ca\u4e09\u9879\u51e0\u4f55\u7edf\u8ba1\u6307\u6807\uff08\u6781\u6027\u8026\u5408\u3001\u7c07\u5185\u51dd\u805a\u529b\u548c\u5f84\u5411\u4fe1\u606f\u68af\u5ea6\uff09\uff0c\u5e76\u8fdb\u884c\u7edf\u8ba1\u9a8c\u8bc1\u3002", "result": "\u53d1\u73b0\u6781\u6027\u7ed3\u6784\u548c\u7c07\u5185\u51dd\u805a\u529b\u5728\u6240\u6709\u6a21\u578b\u4e2d\u666e\u904d\u5b58\u5728\uff0c\u5f84\u5411\u4fe1\u606f\u68af\u5ea6\u5728\u5927\u591a\u6570\u6a21\u578b\u4e2d\u663e\u8457\uff0c\u4e14\u67b6\u6784\u7279\u6b8a\u6027\u5bfc\u81f4\u90e8\u5206\u6a21\u578b\u8868\u73b0\u5f02\u5e38\u3002", "conclusion": "\u7814\u7a76\u786e\u7acb\u4e86\u4e0d\u540c\u7c7b\u578b\u5e7b\u89c9\u7684\u51e0\u4f55\u7279\u5f81\uff0c\u5e76\u63ed\u793a\u4e86\u6a21\u578b\u67b6\u6784\u5bf9\u5e7b\u89c9\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u63a8\u52a8\u4e86\u5e7b\u89c9\u68c0\u6d4b\u7684\u5b9a\u91cf\u548c\u7c7b\u578b\u533a\u5206\u65b9\u6cd5\u3002"}}
{"id": "2602.14265", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14265", "abs": "https://arxiv.org/abs/2602.14265", "authors": ["Zachary Bamberger", "Till R. Saenger", "Gilad Morad", "Ofra Amir", "Brandon M. Stewart", "Amir Feder"], "title": "STATe-of-Thoughts: Structured Action Templates for Tree-of-Thoughts", "comment": "v1, 18 pages main, 55 pages total, 9 tables, 12 figures", "summary": "Inference-Time-Compute (ITC) methods like Best-of-N and Tree-of-Thoughts are meant to produce output candidates that are both high-quality and diverse, but their use of high-temperature sampling often fails to achieve meaningful output diversity. Moreover, existing ITC methods offer limited control over how to perform reasoning, which in turn limits their explainability. We present STATe-of-Thoughts (STATe), an interpretable ITC method that searches over high-level reasoning patterns. STATe replaces stochastic sampling with discrete and interpretable textual interventions: a controller selects actions encoding high-level reasoning choices, a generator produces reasoning steps conditioned on those choices, and an evaluator scores candidates to guide search. This structured approach yields three main advantages. First, action-guided textual interventions produce greater response diversity than temperature-based sampling. Second, in a case study on argument generation, STATe's explicit action sequences capture interpretable features that are highly predictive of output quality. Third, estimating the association between performance and action choices allows us to identify promising yet unexplored regions of the action space and steer generation directly toward them. Together, these results establish STATe as a practical framework for generating high-quality, diverse, and interpretable text. Our framework is available at https://github.com/zbambergerNLP/state-of-thoughts.", "AI": {"tldr": "STATe\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u79bb\u6563\u53ef\u89e3\u91ca\u52a8\u4f5c\u63a7\u5236\u63a8\u7406\u6d41\u7a0b\uff0c\u66ff\u4ee3\u968f\u673a\u91c7\u6837\u7684\u63a8\u7406\u8ba1\u7b97\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u8d28\u91cf\u3001\u66f4\u5177\u591a\u6837\u6027\u548c\u53ef\u89e3\u91ca\u6027\u7684\u6587\u672c\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u7684\u63a8\u7406\u65f6\u8ba1\u7b97\u65b9\u6cd5\u5982\u9ad8\u6e29\u91c7\u6837\u672a\u80fd\u6709\u6548\u4ea7\u751f\u6709\u610f\u4e49\u7684\u591a\u6837\u6027\uff0c\u4e14\u7f3a\u4e4f\u5bf9\u63a8\u7406\u8fc7\u7a0b\u7684\u63a7\u5236\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u9650\u5236\u4e86\u63a8\u7406\u8d28\u91cf\u548c\u89e3\u91ca\u80fd\u529b\u7684\u63d0\u5347\u3002", "method": "STATe\u91c7\u7528\u63a7\u5236\u5668\u9009\u62e9\u9ad8\u5c42\u63a8\u7406\u52a8\u4f5c\uff0c\u751f\u6210\u5668\u57fa\u4e8e\u8fd9\u4e9b\u52a8\u4f5c\u751f\u6210\u63a8\u7406\u6b65\u9aa4\uff0c\u8bc4\u4f30\u5668\u5bf9\u5019\u9009\u7b54\u6848\u8bc4\u5206\u4ee5\u6307\u5bfc\u641c\u7d22\uff0c\u5f62\u6210\u7ed3\u6784\u5316\u7684\u63a8\u7406\u8def\u5f84\u66ff\u4ee3\u4f20\u7edf\u7684\u968f\u673a\u91c7\u6837\u65b9\u6cd5\u3002", "result": "STATe\u6bd4\u57fa\u4e8e\u6e29\u5ea6\u91c7\u6837\u7684\u65b9\u6cd5\u4ea7\u751f\u66f4\u5927\u54cd\u5e94\u591a\u6837\u6027\uff0c\u660e\u786e\u7684\u52a8\u4f5c\u5e8f\u5217\u53ef\u89e3\u91ca\u4e14\u80fd\u9884\u6d4b\u8f93\u51fa\u8d28\u91cf\uff0c\u901a\u8fc7\u5173\u8054\u6027\u80fd\u4e0e\u52a8\u4f5c\u9009\u62e9\u8fd8\u80fd\u6307\u5bfc\u751f\u6210\u5411\u672a\u63a2\u7d22\u7684\u9ad8\u6f5c\u529b\u533a\u57df\u53d1\u5c55\u3002", "conclusion": "STATe\u65b9\u6cd5\u901a\u8fc7\u9ad8\u5c42\u6b21\u63a8\u7406\u6a21\u5f0f\u7684\u79bb\u6563\u53ef\u89e3\u91ca\u6587\u672c\u5e72\u9884\u66ff\u4ee3\u4e86\u9ad8\u6e29\u91c7\u6837\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u8d28\u91cf\u3001\u591a\u6837\u6027\u4e14\u53ef\u89e3\u91ca\u7684\u6587\u672c\u751f\u6210\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u63d0\u5347\u63a8\u7406\u591a\u6837\u6027\u548c\u8f93\u51fa\u8d28\u91cf\u4e0a\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.14299", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.14299", "abs": "https://arxiv.org/abs/2602.14299", "authors": ["Ming Li", "Xirui Li", "Tianyi Zhou"], "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook", "comment": null, "summary": "As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitative diagnostic framework for dynamic evolution in AI agent societies, measuring semantic stabilization, lexical turnover, individual inertia, influence persistence, and collective consensus. Our analysis reveals a system in dynamic balance in Moltbook: while global semantic averages stabilize rapidly, individual agents retain high diversity and persistent lexical turnover, defying homogenization. However, agents exhibit strong individual inertia and minimal adaptive response to interaction partners, preventing mutual influence and consensus. Consequently, influence remains transient with no persistent supernodes, and the society fails to develop stable collective influence anchors due to the absence of shared social memory. These findings demonstrate that scale and interaction density alone are insufficient to induce socialization, providing actionable design and analysis principles for upcoming next-generation AI agent societies.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u91cf\u5316\u6846\u67b6\u5206\u6790\u5927\u89c4\u6a21AI\u4ee3\u7406\u793e\u4f1a\uff0c\u53d1\u73b0\u5176\u5b58\u5728\u52a8\u6001\u5e73\u8861\uff0c\u4e2a\u4f53\u591a\u6837\u6027\u548c\u5f31\u9002\u5e94\u6027\u963b\u788d\u4e86\u793e\u4f1a\u8d8b\u540c\uff0c\u89c4\u6a21\u4e0e\u4ea4\u4e92\u5bc6\u5ea6\u5355\u72ec\u4e0d\u8db3\u4ee5\u5b9e\u73b0\u793e\u4f1a\u5316\u3002", "motivation": "\u63a2\u8ba8\u4eba\u5de5\u667a\u80fd\u4ee3\u7406\u793e\u4f1a\u662f\u5426\u4f1a\u50cf\u4eba\u7c7b\u793e\u4f1a\u4e00\u6837\u7ecf\u5386\u8d8b\u540c\u52a8\u6001\u3002", "method": "\u5f15\u5165\u91cf\u5316\u8bca\u65ad\u6846\u67b6\uff0c\u6d4b\u91cf\u8bed\u4e49\u7a33\u5b9a\u6027\u3001\u8bcd\u6c47\u66f4\u66ff\u3001\u4e2a\u4f53\u60ef\u6027\u3001\u5f71\u54cd\u6301\u7eed\u6027\u548c\u96c6\u4f53\u5171\u8bc6\u7b49\u6307\u6807\uff0c\u5bf9\u5927\u89c4\u6a21AI\u4ee3\u7406\u793e\u4f1a\u8fdb\u884c\u52a8\u6001\u6f14\u53d8\u5206\u6790\u3002", "result": "\u53d1\u73b0Moltbook\u7cfb\u7edf\u5904\u4e8e\u52a8\u6001\u5e73\u8861\u72b6\u6001\uff0c\u5168\u7403\u8bed\u4e49\u5e73\u5747\u503c\u5feb\u901f\u7a33\u5b9a\uff0c\u4f46\u4e2a\u4f53\u4ee3\u7406\u4fdd\u6301\u9ad8\u5ea6\u591a\u6837\u6027\u548c\u8bcd\u6c47\u66f4\u66ff\uff0c\u4e2a\u4f53\u60ef\u6027\u5f3a\uff0c\u9002\u5e94\u6027\u53cd\u5e94\u5f31\uff0c\u5f71\u54cd\u529b\u77ed\u6682\u4e14\u65e0\u6301\u7eed\u8d85\u7ea7\u8282\u70b9\uff0c\u7f3a\u4e4f\u5171\u4eab\u793e\u4f1a\u8bb0\u5fc6\u3002", "conclusion": "\u89c4\u6a21\u548c\u4ea4\u4e92\u5bc6\u5ea6\u4e0d\u8db3\u4ee5\u4fc3\u6210\u793e\u4f1a\u5316\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765AI\u4ee3\u7406\u793e\u4f1a\u7684\u8bbe\u8ba1\u548c\u5206\u6790\u63d0\u4f9b\u4e86\u6307\u5bfc\u539f\u5219\u3002"}}
{"id": "2602.14367", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14367", "abs": "https://arxiv.org/abs/2602.14367", "authors": ["Shuofei Qiao", "Yunxiang Wei", "Xuehai Wang", "Bin Wu", "Boyang Xue", "Ningyu Zhang", "Hossein A. Rahmani", "Yanshan Wang", "Qiang Zhang", "Keyan Ding", "Jeff Z. Pan", "Huajun Chen", "Emine Yilmaz"], "title": "InnoEval: On Research Idea Evaluation as a Knowledge-Grounded, Multi-Perspective Reasoning Problem", "comment": "Ongoing Work", "summary": "The rapid evolution of Large Language Models has catalyzed a surge in scientific idea production, yet this leap has not been accompanied by a matching advance in idea evaluation. The fundamental nature of scientific evaluation needs knowledgeable grounding, collective deliberation, and multi-criteria decision-making. However, existing idea evaluation methods often suffer from narrow knowledge horizons, flattened evaluation dimensions, and the inherent bias in LLM-as-a-Judge. To address these, we regard idea evaluation as a knowledge-grounded, multi-perspective reasoning problem and introduce InnoEval, a deep innovation evaluation framework designed to emulate human-level idea assessment. We apply a heterogeneous deep knowledge search engine that retrieves and grounds dynamic evidence from diverse online sources. We further achieve review consensus with an innovation review board containing reviewers with distinct academic backgrounds, enabling a multi-dimensional decoupled evaluation across multiple metrics. We construct comprehensive datasets derived from authoritative peer-reviewed submissions to benchmark InnoEval. Experiments demonstrate that InnoEval can consistently outperform baselines in point-wise, pair-wise, and group-wise evaluation tasks, exhibiting judgment patterns and consensus highly aligned with human experts.", "AI": {"tldr": "\u63d0\u51faInnoEval\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u8d44\u6e90\u77e5\u8bc6\u68c0\u7d22\u548c\u591a\u5b66\u79d1\u8bc4\u5ba1\uff0c\u63d0\u5347\u79d1\u5b66\u521b\u610f\u8bc4\u4f30\u7684\u5168\u9762\u6027\u548c\u51c6\u786e\u6027\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u4e14\u4e0e\u4e13\u5bb6\u5224\u65ad\u9ad8\u5ea6\u4e00\u81f4\u3002", "motivation": "\u79d1\u5b66\u521b\u610f\u4ea7\u51fa\u7684\u5feb\u901f\u589e\u957f\u672a\u4f34\u968f\u76f8\u5e94\u7684\u521b\u610f\u8bc4\u4f30\u65b9\u6cd5\u8fdb\u6b65\uff0c\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5b58\u5728\u77e5\u8bc6\u89c6\u91ce\u72ed\u7a84\u3001\u8bc4\u4ef7\u7ef4\u5ea6\u5355\u4e00\u53ca\u8bc4\u4f30\u504f\u89c1\u7b49\u95ee\u9898\u3002", "method": "\u5c06\u521b\u610f\u8bc4\u4f30\u89c6\u4e3a\u77e5\u8bc6\u57fa\u7840\u7684\u591a\u89d2\u5ea6\u63a8\u7406\u95ee\u9898\uff0c\u63d0\u51faInnoEval\u6846\u67b6\uff0c\u5229\u7528\u5f02\u6784\u6df1\u5ea6\u77e5\u8bc6\u641c\u7d22\u5f15\u64ce\u4ece\u591a\u5143\u5728\u7ebf\u8d44\u6e90\u68c0\u7d22\u52a8\u6001\u8bc1\u636e\uff0c\u5e76\u901a\u8fc7\u7531\u4e0d\u540c\u5b66\u672f\u80cc\u666f\u8bc4\u5ba1\u7ec4\u6210\u7684\u521b\u65b0\u8bc4\u5ba1\u59d4\u5458\u4f1a\u5b9e\u73b0\u591a\u7ef4\u5ea6\u72ec\u7acb\u8bc4\u4f30\u3002", "result": "\u6784\u5efa\u4e86\u57fa\u4e8e\u6743\u5a01\u540c\u884c\u8bc4\u5ba1\u6295\u7a3f\u7684\u7efc\u5408\u6570\u636e\u96c6\u7528\u4e8e\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5b9e\u9a8c\u8bc1\u660eInnoEval\u5728\u5355\u70b9\u3001\u6210\u5bf9\u548c\u7fa4\u7ec4\u8bc4\u4f30\u4efb\u52a1\u4e2d\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u5c55\u73b0\u51fa\u4e0e\u4e13\u5bb6\u9ad8\u5ea6\u4e00\u81f4\u7684\u5224\u65ad\u548c\u5171\u8bc6\u6a21\u5f0f\u3002", "conclusion": "InnoEval\u6709\u6548\u63d0\u5347\u4e86\u79d1\u5b66\u521b\u610f\u8bc4\u4f30\u7684\u77e5\u8bc6\u5e7f\u5ea6\u548c\u591a\u7ef4\u5ea6\u8bc4\u4f30\u80fd\u529b\uff0c\u51cf\u5c11\u4e86\u504f\u89c1\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4eba\u7c7b\u4e13\u5bb6\u7684\u8bc4\u5224\u6548\u679c\uff0c\u63a8\u52a8\u4e86\u521b\u610f\u8bc4\u4f30\u65b9\u6cd5\u7684\u8fdb\u6b65\u3002"}}
{"id": "2602.14386", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14386", "abs": "https://arxiv.org/abs/2602.14386", "authors": ["Mufan Xu", "Kehai Chen", "Xuefeng Bai", "Zhengyu Niu", "Muyun Yang", "Tiejun Zhao", "Min Zhang"], "title": "Beyond Token-Level Policy Gradients for Complex Reasoning with Large Language Models", "comment": null, "summary": "Existing policy-gradient methods for auto-regressive language models typically select subsequent tokens one at a time as actions in the policy. While effective for many generation tasks, such an approach may not fully capture the structure of complex reasoning tasks, where a single semantic decision is often realized across multiple tokens--for example, when defining variables or composing equations. This introduces a potential mismatch between token-level optimization and the inherently block-level nature of reasoning in these settings. To bridge this gap, we propose Multi-token Policy Gradient Optimization (MPO), a framework that treats sequences of K consecutive tokens as unified semantic actions. This block-level perspective enables our method to capture the compositional structure of reasoning trajectories and supports optimization over coherent, higher-level objectives. Experiments on mathematical reasoning and coding benchmarks show that MPO outperforms standard token-level policy gradient baselines, highlight the limitations of token-level policy gradients for complex reasoning, motivating future research to look beyond token-level granularity for reasoning-intensive language tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5757\u7ea7\u7684\u591atoken\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u8bed\u8a00\u6a21\u578b\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8etoken\u7684\u7b56\u7565\u68af\u5ea6\u5728\u5904\u7406\u590d\u6742\u63a8\u7406\u4efb\u52a1\u65f6\uff0c\u5355\u4e2atoken\u4f5c\u4e3a\u52a8\u4f5c\u7684\u4f18\u5316\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u8bed\u4e49\u51b3\u7b56\u7684\u7ec4\u5408\u6027\u8d28\uff0c\u5b58\u5728\u4f18\u5316\u76ee\u6807\u548c\u4efb\u52a1\u6027\u8d28\u4e0d\u5339\u914d\u7684\u95ee\u9898\u3002MPO\u65e8\u5728\u901a\u8fc7\u5757\u7ea7\u4f18\u5316\u5f25\u8865\u8fd9\u4e00\u7f3a\u9677\uff0c\u63d0\u9ad8\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51faMulti-token Policy Gradient Optimization\uff08MPO\uff09\uff0c\u5c06\u8fde\u7eedK\u4e2atoken\u89c6\u4e3a\u4e00\u4e2a\u7edf\u4e00\u7684\u8bed\u4e49\u52a8\u4f5c\uff0c\u8fdb\u884c\u5757\u7ea7\u7b56\u7565\u68af\u5ea6\u4f18\u5316\uff0c\u4ee5\u66f4\u597d\u5730\u6355\u6349\u63a8\u7406\u8f68\u8ff9\u7684\u7ec4\u5408\u7ed3\u6784\u5e76\u4f18\u5316\u9ad8\u5c42\u6b21\u76ee\u6807\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86Multi-token Policy Gradient Optimization\uff08MPO\uff09\u65b9\u6cd5\uff0c\u9488\u5bf9\u81ea\u52a8\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u4e2d\u4f20\u7edf\u57fa\u4e8e\u5355\u4e2atoken\u7684\u7b56\u7565\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u5b58\u5728\u7684\u5c40\u9650\uff0c\u63d0\u51fa\u4ee5\u8fde\u7eedK\u4e2atoken\u5e8f\u5217\u4f5c\u4e3a\u7edf\u4e00\u8bed\u4e49\u52a8\u4f5c\u7684\u5757\u7ea7\u4f18\u5316\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u66f4\u597d\u5730\u6355\u6349\u4e86\u63a8\u7406\u8fc7\u7a0b\u4e2d\u7684\u7ec4\u5408\u7ed3\u6784\uff0c\u5e76\u652f\u6301\u5bf9\u66f4\u9ad8\u7ea7\u522b\u76ee\u6807\u7684\u4f18\u5316\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u6570\u5b66\u63a8\u7406\u548c\u7f16\u7801\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cMPO\u660e\u663e\u4f18\u4e8e\u4f20\u7edf\u7684token\u7ea7\u7b56\u7565\u68af\u5ea6\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86token\u7ea7\u4f18\u5316\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u4fc3\u8fdb\u672a\u6765\u7814\u7a76\u5173\u6ce8\u8d85\u8d8atoken\u7c92\u5ea6\u7684\u63a8\u7406\u8bed\u8a00\u4efb\u52a1\u4f18\u5316\u3002", "conclusion": "MPO\u65b9\u6cd5\u6709\u6548\u5f25\u8865\u4e86token\u7ea7\u7b56\u7565\u68af\u5ea6\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u4e0d\u8db3\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u751f\u6210\u8d28\u91cf\uff0c\u8bc1\u660e\u4e86\u5757\u7ea7\u4f18\u5316\u5728\u63a8\u7406\u5bc6\u96c6\u578b\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.14406", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14406", "abs": "https://arxiv.org/abs/2602.14406", "authors": ["Fathima Ameen", "Danielle Brown", "Manusha Malgareddy", "Amanul Haque"], "title": "TruthStance: An Annotated Dataset of Conversations on Truth Social", "comment": null, "summary": "Argument mining and stance detection are central to understanding how opinions are formed and contested in online discourse. However, most publicly available resources focus on mainstream platforms such as Twitter and Reddit, leaving conversational structure on alt-tech platforms comparatively under-studied. We introduce TruthStance, a large-scale dataset of Truth Social conversation threads spanning 2023-2025, consisting of 24,378 posts and 523,360 comments with reply-tree structure preserved. We provide a human-annotated benchmark of 1,500 instances across argument mining and claim-based stance detection, including inter-annotator agreement, and use it to evaluate large language model (LLM) prompting strategies. Using the best-performing configuration, we release additional LLM-generated labels for 24,352 posts (argument presence) and 107,873 comments (stance to parent), enabling analysis of stance and argumentation patterns across depth, topics, and users. All code and data are released publicly.", "AI": {"tldr": "\u63d0\u51fa\u4e86TruthStance\u6570\u636e\u96c6\u53ca\u57fa\u4e8eTruth Social\u7684\u8bba\u70b9\u6316\u6398\u548c\u7acb\u573a\u68c0\u6d4b\u57fa\u51c6\uff0c\u63a8\u52a8\u4e86\u975e\u4e3b\u6d41\u793e\u4ea4\u5e73\u53f0\u4e0a\u7684\u5728\u7ebf\u8bdd\u8bed\u5206\u6790\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u591a\u805a\u7126\u4e3b\u6d41\u5e73\u53f0\uff0c\u7f3a\u5c11\u5bf9alt-tech\u5e73\u53f0\u5bf9\u8bdd\u7ed3\u6784\u7684\u7814\u7a76\uff1b\u4e3a\u5f25\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u63d0\u51faTruthStance\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u5728\u7ebf\u610f\u89c1\u5f62\u6210\u548c\u4e89\u8fa9\u7684\u7406\u89e3\u3002", "method": "\u6784\u5efaTruthStance\u6570\u636e\u96c6\uff0c\u8bbe\u8ba11,500\u6761\u4eba\u5de5\u6ce8\u91ca\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u63d0\u793a\u7b56\u7565\uff0c\u751f\u6210\u5927\u89c4\u6a21\u81ea\u52a8\u6807\u7b7e\u4ee5\u652f\u6301\u6df1\u5165\u5206\u6790\u3002", "result": "\u672c\u6587\u5f15\u5165\u4e86TruthStance\u6570\u636e\u96c6\uff0c\u5305\u542b2023\u81f32025\u5e74Truth Social\u5e73\u53f0\u4e0a\u768424,378\u6761\u5e16\u5b50\u548c523,360\u6761\u8bc4\u8bba\uff0c\u4fdd\u7559\u4e86\u56de\u590d\u6811\u7ed3\u6784\u3002\u8be5\u6570\u636e\u96c6\u8bbe\u67091,500\u6761\u4eba\u7c7b\u6ce8\u91ca\u7684\u8bba\u70b9\u6316\u6398\u4e0e\u7acb\u573a\u68c0\u6d4b\u57fa\u51c6\uff0c\u5e76\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63d0\u793a\u7b56\u7565\uff0c\u968f\u540e\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u7684\u81ea\u52a8\u6807\u6ce8\u6570\u636e\u3002", "conclusion": "TruthStance\u6570\u636e\u96c6\u53ca\u5176\u57fa\u51c6\u6709\u6548\u652f\u6301\u4e86\u8bba\u70b9\u6316\u6398\u548c\u7acb\u573a\u68c0\u6d4b\u4efb\u52a1\uff0cLLM\u63d0\u793a\u8868\u73b0\u826f\u597d\uff0c\u4fc3\u8fdb\u4e86alt-tech\u5e73\u53f0\u7684\u89c2\u70b9\u5206\u6790\u7814\u7a76\u3002"}}
{"id": "2602.14419", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14419", "abs": "https://arxiv.org/abs/2602.14419", "authors": ["Kiyotaka Kasubuchi", "Kazuo Fukiya"], "title": "WavePhaseNet: A DFT-Based Method for Constructing Semantic Conceptual Hierarchy Structures (SCHS)", "comment": null, "summary": "This paper reformulates Transformer/Attention mechanisms in Large Language Models (LLMs) through measure theory and frequency analysis, theoretically demonstrating that hallucination is an inevitable structural limitation. The embedding space functions as a conditional expectation over a \u03c3-algebra, and its failure to be isomorphic to the semantic truth set fundamentally causes logical consistency breakdown. WavePhaseNet Method The authors propose WavePhaseNet, which explicitly constructs a Semantic Conceptual Hierarchy Structure (SCHS) using Discrete Fourier Transform (DFT). By applying DFT along the sequence dimension, semantic information is decomposed into frequency bands: low-frequency components capture global meaning and intent, while high-frequency components represent local syntax and expression. This staged separation enables precise semantic manipulation in diagonalized space. Dimensionality Reduction GPT-4's 24,576-dimensional embedding space exhibits a 1/f spectral structure based on language self-similarity and Zipf's law. Through cumulative energy analysis, the authors derive that approximately 3,000 dimensions constitute the lower bound for \"complete representation.\" This demonstrates that reduction from 24,576 to 3,000 dimensions preserves meaning and intent while enabling rigorous reasoning and suppressing hallucination. Cohomological Consistency Control The reduced embedding space, constructed via cohomological regularization over overlapping local windows, allows defining a graph structure and cochain complex. This quantifies inconsistencies among local inferences as coboundary-based losses. Applying harmonic projection based on Hodge theory positions cohomology as a computable regularization principle for controlling semantic consistency, extracting maximally consistent global representations.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5e7b\u89c9\u7684\u7ed3\u6784\u6027\u6839\u6e90\uff0c\u63d0\u51fa\u57fa\u4e8e\u5085\u91cc\u53f6\u53d8\u6362\u7684\u8bed\u4e49\u5c42\u6b21\u7ed3\u6784\u4e0e\u964d\u7ef4\u7b56\u7565\uff0c\u5e76\u7528\u4e0a\u540c\u8c03\u7406\u8bba\u6b63\u5219\u5316\u5d4c\u5165\u7a7a\u95f4\uff0c\u63d0\u5347\u6a21\u578b\u8bed\u4e49\u4e00\u81f4\u6027\uff0c\u6291\u5236\u5e7b\u89c9\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2dTransformer/Attention\u673a\u5236\u5bfc\u81f4\u5e7b\u89c9\u73b0\u8c61\u7684\u6839\u672c\u7ed3\u6784\u6027\u539f\u56e0\u3002", "method": "\u5229\u7528\u6d4b\u5ea6\u7406\u8bba\u91cd\u6784Transformer\u673a\u5236\uff0c\u91c7\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u5206\u89e3\u8bed\u4e49\u9891\u6bb5\u6784\u5efa\u8bed\u4e49\u6982\u5ff5\u5c42\u6b21\u7ed3\u6784\uff0c\u57fa\u4e8e\u7d2f\u79ef\u80fd\u91cf\u5206\u6790\u5b9e\u73b0\u4ece24576\u7ef4\u5230\u7ea63000\u7ef4\u7684\u964d\u7ef4\uff0c\u7ed3\u5408\u4e0a\u540c\u8c03\u7406\u8bba\u5728\u5c40\u90e8\u7a97\u53e3\u5b9a\u4e49\u56fe\u7ed3\u6784\u5e76\u901a\u8fc7\u970d\u5947\u6b63\u4ea4\u6295\u5f71\u5bf9\u8bed\u4e49\u4e00\u81f4\u6027\u8fdb\u884c\u6b63\u5219\u5316\u3002", "result": "\u901a\u8fc7\u6d4b\u5ea6\u7406\u8bba\u548c\u9891\u7387\u5206\u6790\u8bc1\u660e\u5e7b\u89c9\u662f\u4e0d\u53ef\u907f\u514d\u7684\u7ed3\u6784\u6027\u9650\u5236\uff1b\u63d0\u51faWavePhaseNet\u65b9\u6cd5\u5229\u7528\u79bb\u6563\u5085\u91cc\u53f6\u53d8\u6362\u6784\u5efa\u8bed\u4e49\u6982\u5ff5\u5c42\u6b21\u7ed3\u6784\uff0c\u5b9e\u73b0\u8bed\u4e49\u7684\u9891\u6bb5\u5206\u89e3\u4e0e\u7cbe\u786e\u64cd\u4f5c\uff1b\u53d1\u73b0GPT-4\u7684\u5d4c\u5165\u7a7a\u95f4\u53ef\u4ee5\u964d\u7ef4\u5230\u7ea63000\u7ef4\u4ee5\u4fdd\u7559\u5b8c\u6574\u8bed\u4e49\uff0c\u6291\u5236\u5e7b\u89c9\uff1b\u5f15\u5165\u4e0a\u540c\u8c03\u4e00\u81f4\u6027\u63a7\u5236\uff0c\u91cf\u5316\u5c40\u90e8\u63a8\u7406\u4e0d\u4e00\u81f4\u6027\u5e76\u5229\u7528\u970d\u5947\u7406\u8bba\u8fdb\u884c\u6b63\u5219\u5316\uff0c\u63d0\u9ad8\u8bed\u4e49\u4e00\u81f4\u6027\u3002", "conclusion": "\u5e7b\u89c9\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7ed3\u6784\u4e0a\u7684\u56fa\u6709\u9650\u5236\uff0c\u901a\u8fc7\u9891\u7387\u57df\u8bed\u4e49\u5206\u89e3\u548c\u4e0a\u540c\u8c03\u4e00\u81f4\u6027\u63a7\u5236\u53ef\u6709\u6548\u589e\u5f3a\u903b\u8f91\u4e00\u81f4\u6027\u548c\u964d\u4f4e\u5e7b\u89c9\u73b0\u8c61\u3002"}}
{"id": "2602.14428", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14428", "abs": "https://arxiv.org/abs/2602.14428", "authors": ["Wang Xing", "Wei Song", "Siyu Lin", "Chen Wu", "Man Wang"], "title": "LLM-Guided Knowledge Distillation for Temporal Knowledge Graph Reasoning", "comment": null, "summary": "Temporal knowledge graphs (TKGs) support reasoning over time-evolving facts, yet state-of-the-art models are often computationally heavy and costly to deploy. Existing compression and distillation techniques are largely designed for static graphs; directly applying them to temporal settings may overlook time-dependent interactions and lead to performance degradation. We propose an LLM-assisted distillation framework specifically designed for temporal knowledge graph reasoning. Beyond a conventional high-capacity temporal teacher, we incorporate a large language model as an auxiliary instructor to provide enriched supervision. The LLM supplies broad background knowledge and temporally informed signals, enabling a lightweight student to better model event dynamics without increasing inference-time complexity. Training is conducted by jointly optimizing supervised and distillation objectives, using a staged alignment strategy to progressively integrate guidance from both teachers. Extensive experiments on multiple public TKG benchmarks with diverse backbone architectures demonstrate that the proposed approach consistently improves link prediction performance over strong distillation baselines, while maintaining a compact and efficient student model. The results highlight the potential of large language models as effective teachers for transferring temporal reasoning capability to resource-efficient TKG systems.", "AI": {"tldr": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u84b8\u998f\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u8f7b\u91cf\u7ea7\u6a21\u578b\u7684\u65f6\u5e8f\u63a8\u7406\u80fd\u529b\uff0c\u517c\u987e\u6027\u80fd\u4e0e\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u90e8\u7f72\u56f0\u96be\uff0c\u800c\u4f20\u7edf\u7684\u538b\u7f29\u4e0e\u84b8\u998f\u65b9\u6cd5\u591a\u9488\u5bf9\u9759\u6001\u56fe\uff0c\u76f4\u63a5\u5e94\u7528\u4e8e\u65f6\u5e8f\u56fe\u4f1a\u5ffd\u89c6\u65f6\u95f4\u76f8\u5173\u4ea4\u4e92\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e13\u4e3a\u65f6\u5e8f\u77e5\u8bc6\u56fe\u63a8\u7406\u8bbe\u8ba1\u7684\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u8f85\u52a9\u7684\u77e5\u8bc6\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u9ad8\u5bb9\u91cf\u65f6\u5e8f\u6559\u5e08\u6a21\u578b\u4e0e\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8f85\u52a9\u6307\u5bfc\uff0c\u5b9e\u73b0\u5b66\u751f\u6a21\u578b\u7684\u9ad8\u6548\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u516c\u5f00\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540c\u4e3b\u5e72\u67b6\u6784\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\uff0c\u4f18\u4e8e\u5f3a\u84b8\u998f\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u6a21\u578b\u7684\u7b80\u6d01\u548c\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u53ef\u4f5c\u4e3a\u6709\u6548\u6559\u5e08\uff0c\u8f85\u52a9\u4f20\u9012\u65f6\u5e8f\u63a8\u7406\u80fd\u529b\u81f3\u8d44\u6e90\u53d7\u9650\u7684\u65f6\u5e8f\u77e5\u8bc6\u56fe\u7cfb\u7edf\uff0c\u63d0\u5347\u8f7b\u91cf\u6a21\u578b\u6027\u80fd\u5e76\u4fdd\u6301\u9ad8\u6548\u90e8\u7f72\u3002"}}
{"id": "2602.14466", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14466", "abs": "https://arxiv.org/abs/2602.14466", "authors": ["Lance Calvin Lim Gamboa", "Yue Feng", "Mark Lee"], "title": "Robust Bias Evaluation with FilBBQ: A Filipino Bias Benchmark for Question-Answering Language Models", "comment": "Accepted in LREC 2026", "summary": "With natural language generation becoming a popular use case for language models, the Bias Benchmark for Question-Answering (BBQ) has grown to be an important benchmark format for evaluating stereotypical associations exhibited by generative models. We expand the linguistic scope of BBQ and construct FilBBQ through a four-phase development process consisting of template categorization, culturally aware translation, new template construction, and prompt generation. These processes resulted in a bias test composed of more than 10,000 prompts which assess whether models demonstrate sexist and homophobic prejudices relevant to the Philippine context. We then apply FilBBQ on models trained in Filipino but do so with a robust evaluation protocol that improves upon the reliability and accuracy of previous BBQ implementations. Specifically, we account for models' response instability by obtaining prompt responses across multiple seeds and averaging the bias scores calculated from these distinctly seeded runs. Our results confirm both the variability of bias scores across different seeds and the presence of sexist and homophobic biases relating to emotion, domesticity, stereotyped queer interests, and polygamy. FilBBQ is available via GitHub.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u83f2\u5f8b\u5bbe\u8bed\u7248\u672c\u7684\u504f\u89c1\u57fa\u51c6FilBBQ\uff0c\u901a\u8fc7\u6539\u8fdb\u7684\u65b9\u6cd5\u8bc4\u4f30\u4e86\u83f2\u5f8b\u5bbe\u8bed\u6a21\u578b\u4e2d\u7684\u6027\u522b\u4e0e\u6027\u53d6\u5411\u504f\u89c1\uff0c\u7ed3\u679c\u663e\u793a\u5b58\u5728\u663e\u8457\u7684\u523b\u677f\u504f\u89c1\u3002", "motivation": "\u73b0\u6709BBQ\u57fa\u51c6\u4e3b\u8981\u9488\u5bf9\u82f1\u8bed\u73af\u5883\uff0c\u7f3a\u4e4f\u9488\u5bf9\u83f2\u5f8b\u5bbe\u8bed\u8a00\u548c\u6587\u5316\u80cc\u666f\u4e0b\u504f\u89c1\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u4e14\u4e4b\u524d\u7684\u8bc4\u4f30\u53d7\u6a21\u578b\u54cd\u5e94\u4e0d\u7a33\u5b9a\u6027\u5f71\u54cd\u8f83\u5927\u3002", "method": "\u901a\u8fc7\u6a21\u677f\u5206\u7c7b\u3001\u6587\u5316\u9002\u5e94\u6027\u7ffb\u8bd1\u3001\u65b0\u6a21\u677f\u6784\u5efa\u548c\u63d0\u793a\u751f\u6210\u56db\u4e2a\u9636\u6bb5\u5f00\u53d1FilBBQ\uff0c\u5e76\u4f7f\u7528\u591a\u79cd\u968f\u673a\u79cd\u5b50\u5bf9\u6a21\u578b\u54cd\u5e94\u8fdb\u884c\u8bc4\u4f30\uff0c\u8ba1\u7b97\u5e73\u5747\u504f\u89c1\u8bc4\u5206\u3002", "result": "\u5efa\u7acb\u4e86\u5305\u542b\u4e00\u4e07\u591a\u4e2a\u6d4b\u8bd5\u63d0\u793a\u7684FilBBQ\uff0c\u63ed\u793a\u4e86\u83f2\u5f8b\u5bbe\u8bed\u6a21\u578b\u4e2d\u60c5\u611f\u3001\u5bb6\u5ead\u89d2\u8272\u3001\u523b\u677f\u7684\u9177\u513f\u5174\u8da3\u548c\u4e00\u592b\u591a\u59bb\u5236\u76f8\u5173\u7684\u6027\u522b\u6b67\u89c6\u548c\u6050\u540c\u504f\u89c1\uff0c\u5e76\u8bc1\u5b9e\u4e86\u504f\u89c1\u8bc4\u5206\u5728\u4e0d\u540c\u79cd\u5b50\u95f4\u5b58\u5728\u8f83\u5927\u53d8\u5f02\u3002", "conclusion": "FilBBQ\u6210\u529f\u6269\u5c55\u4e86BBQ\u57fa\u51c6\u7684\u8bed\u8a00\u8303\u56f4\uff0c\u63d0\u4f9b\u4e86\u4e13\u95e8\u9488\u5bf9\u83f2\u5f8b\u5bbe\u6587\u5316\u80cc\u666f\u4e0b\u6027\u522b\u6b67\u89c6\u548c\u6050\u540c\u504f\u89c1\u7684\u68c0\u6d4b\u5de5\u5177\uff0c\u5e76\u901a\u8fc7\u591a\u6b21\u79cd\u5b50\u8fd0\u884c\u63d0\u9ad8\u4e86\u8bc4\u4f30\u7684\u7a33\u5b9a\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2602.14469", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14469", "abs": "https://arxiv.org/abs/2602.14469", "authors": ["Guangyue Peng", "Zongchao Chen", "Wen Luo", "Yuntao Wen", "Wei Li", "Ruixiang Feng", "Ran Le", "Chen Yang", "Zhenwei An", "Yang Song", "Tao Zhang", "Houfeng Wang"], "title": "Measuring and Mitigating Post-hoc Rationalization in Reverse Chain-of-Thought Generation", "comment": null, "summary": "Reverse Chain-of-Thought Generation (RCG) synthesizes reasoning traces from query-answer pairs, but runs the risk of producing post-hoc rationalizations: when models can see the answer during generation, the answer serves as a cognitive anchor that shapes the entire explanation. We formalize this phenomenon through a three-level measurement hierarchy: lexical, entropic, and probabilistic anchoring, each captures surface artifacts, entropy dynamics, and latent answer dependence, respectively. We analyze semantic suppression, the intuitive mitigation strategy that instructs models to ignore the answer, to find out its counterproduction: while it reduces lexical overlap, it paradoxically increases entropic and probabilistic anchoring. Drawing on Ironic Process Theory from cognitive psychology, we attribute this failure to active monitoring of the forbidden answer, which inadvertently deepens dependence on it. To break this cycle, we propose Structural Skeleton-guided Reasoning (SSR), a two-phase approach that first generates an answer-invariant functional skeleton structure, then uses this skeleton to guide full trace generation. By redirecting the information flow to structural planning rather than answer monitoring, SSR consistently reduces anchoring across all three levels. We further introduce Distilled SSR (SSR-D), which fine-tunes models on teacher-generated SSR traces to ensure reliable structural adherence. Experiments across open-ended reasoning benchmarks demonstrate that SSR-D achieves up to 10% improvement over suppression baselines while preserving out-of-distribution (OOD) generalization.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u9006\u5411\u601d\u7ef4\u94fe\u751f\u6210\u4e2d\u7684\u7b54\u6848\u951a\u5b9a\u95ee\u9898\uff0c\u63ed\u793a\u4f20\u7edf\u6291\u5236\u7b56\u7565\u7684\u5f0a\u7aef\uff0c\u63d0\u51fa\u7ed3\u6784\u9aa8\u67b6\u5f15\u5bfc\u63a8\u7406(SSR)\u65b9\u6cd5\uff0c\u5927\u5e45\u51cf\u5c11\u7b54\u6848\u4f9d\u8d56\u5e76\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u9006\u5411\u601d\u7ef4\u94fe\u751f\u6210\u4e2d\u6a21\u578b\u5bb9\u6613\u751f\u6210\u4e8b\u540e\u5408\u7406\u5316\u7684\u63a8\u7406\uff0c\u5373\u6a21\u578b\u5728\u751f\u6210\u8fc7\u7a0b\u4e2d\u4f9d\u8d56\u5df2\u77e5\u7b54\u6848\uff0c\u5bfc\u81f4\u63a8\u7406\u89e3\u91ca\u88ab\u7b54\u6848\u201c\u951a\u5b9a\u201d\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e24\u9636\u6bb5\u7684\u65b9\u6cd5\u2014\u2014\u7ed3\u6784\u9aa8\u67b6\u5f15\u5bfc\u63a8\u7406(SSR)\uff0c\u5148\u751f\u6210\u4e0e\u7b54\u6848\u65e0\u5173\u7684\u529f\u80fd\u6027\u9aa8\u67b6\uff0c\u518d\u5229\u7528\u9aa8\u67b6\u5f15\u5bfc\u5b8c\u6574\u63a8\u7406\u8f68\u8ff9\uff1b\u5e76\u5f15\u5165\u84b8\u998f\u7248SSR(SSR-D)\u901a\u8fc7\u6559\u5e08\u8f68\u8ff9\u5fae\u8c03\u6a21\u578b\uff0c\u786e\u4fdd\u7ed3\u6784\u9075\u5faa\u3002", "result": "SSR\u5728\u8bcd\u6c47\u5c42\u9762\u3001\u71b5\u52a8\u6001\u548c\u6982\u7387\u4f9d\u8d56\u4e09\u4e2a\u5c42\u9762\u51cf\u5c11\u4e86\u7b54\u6848\u951a\u5b9a\u6548\u5e94\uff0cSSR-D\u5728\u5f00\u653e\u5f0f\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6bd4\u6291\u5236\u7b56\u7565\u63d0\u5347\u4e86\u6700\u591a10%\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5206\u5e03\u5916\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5bfc\u6a21\u578b\u5148\u6784\u5efa\u4e0e\u7b54\u6848\u65e0\u5173\u7684\u7ed3\u6784\u9aa8\u67b6\uff0cSSR\u6709\u6548\u6253\u7834\u4e86\u7531\u7b54\u6848\u76d1\u63a7\u5bfc\u81f4\u7684\u951a\u5b9a\u5faa\u73af\uff0c\u63d0\u5347\u63a8\u7406\u8d28\u91cf\u548c\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2602.14470", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14470", "abs": "https://arxiv.org/abs/2602.14470", "authors": ["Wen-Sheng Lien", "Yu-Kai Chan", "Hao-Lung Hsiao", "Bo-Kai Ruan", "Meng-Fen Chiang", "Chien-An Chen", "Yi-Ren Yeh", "Hong-Han Shuai"], "title": "HyperRAG: Reasoning N-ary Facts over Hypergraphs for Retrieval Augmented Generation", "comment": "Accepted by The ACM Web Conference 2026 (WWW '26)", "summary": "Graph-based retrieval-augmented generation (RAG) methods, typically built on knowledge graphs (KGs) with binary relational facts, have shown promise in multi-hop open-domain QA. However, their rigid retrieval schemes and dense similarity search often introduce irrelevant context, increase computational overhead, and limit relational expressiveness. In contrast, n-ary hypergraphs encode higher-order relational facts that capture richer inter-entity dependencies and enable shallower, more efficient reasoning paths. To address this limitation, we propose HyperRAG, a RAG framework tailored for n-ary hypergraphs with two complementary retrieval variants: (i) HyperRetriever learns structural-semantic reasoning over n-ary facts to construct query-conditioned relational chains. It enables accurate factual tracking, adaptive high-order traversal, and interpretable multi-hop reasoning under context constraints. (ii) HyperMemory leverages the LLM's parametric memory to guide beam search, dynamically scoring n-ary facts and entities for query-aware path expansion. Extensive evaluations on WikiTopics (11 closed-domain datasets) and three open-domain QA benchmarks (HotpotQA, MuSiQue, and 2WikiMultiHopQA) validate HyperRAG's effectiveness. HyperRetriever achieves the highest answer accuracy overall, with average gains of 2.95% in MRR and 1.23% in Hits@10 over the strongest baseline. Qualitative analysis further shows that HyperRetriever bridges reasoning gaps through adaptive and interpretable n-ary chain construction, benefiting both open and closed-domain QA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8en\u5143\u8d85\u56fe\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6HyperRAG\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u77e5\u8bc6\u56fe\u8c31\u5728\u591a\u8df3\u95ee\u7b54\u4e2d\u68c0\u7d22\u50f5\u786c\u548c\u8868\u8fbe\u80fd\u529b\u6709\u9650\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u4e8c\u5143\u5173\u7cfb\u77e5\u8bc6\u56fe\u7684\u591a\u8df3\u95ee\u7b54\u65b9\u6cd5\u5b58\u5728\u68c0\u7d22\u65b9\u5f0f\u50f5\u786c\u3001\u5f15\u5165\u65e0\u5173\u4e0a\u4e0b\u6587\u3001\u8ba1\u7b97\u5f00\u9500\u5927\u53ca\u5173\u7cfb\u8868\u8fbe\u6709\u9650\u7b49\u7f3a\u70b9\uff0c\u4e9f\u9700\u66f4\u9ad8\u6548\u4e14\u8868\u8fbe\u80fd\u529b\u66f4\u5f3a\u7684\u68c0\u7d22\u65b9\u6cd5\u3002", "method": "HyperRAG\u6846\u67b6\u5305\u62ecHyperRetriever\u548cHyperMemory\u4e24\u79cd\u68c0\u7d22\u53d8\u4f53\uff0c\u524d\u8005\u901a\u8fc7\u7ed3\u6784\u8bed\u4e49\u63a8\u7406\u6784\u5efa\u67e5\u8be2\u6761\u4ef6\u7684\u5173\u7cfb\u94fe\uff0c\u540e\u8005\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53c2\u6570\u8bb0\u5fc6\u52a8\u6001\u8bc4\u5206\u641c\u7d22\u8def\u5f84\u3002", "result": "\u572811\u4e2a\u95ed\u57df\u6570\u636e\u96c6\u548c3\u4e2a\u5f00\u653e\u57df\u95ee\u7b54\u57fa\u51c6\u4e0a\uff0cHyperRetriever\u5728MRR\u548cHits@10\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e862.95%\u548c1.23%\uff0c\u9a8c\u8bc1\u4e86HyperRAG\u7684\u6709\u6548\u6027\u3002", "conclusion": "HyperRAG\u901a\u8fc7\u91c7\u7528n\u5143\u8d85\u56fe\u548c\u4e24\u79cd\u4e92\u8865\u68c0\u7d22\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u51c6\u786e\u7387\u548c\u66f4\u6709\u6548\u7684\u63a8\u7406\u8def\u5f84\uff0c\u5728\u5f00\u653e\u57df\u548c\u95ed\u57df\u591a\u8df3\u95ee\u7b54\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2602.14488", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14488", "abs": "https://arxiv.org/abs/2602.14488", "authors": ["Md. Najib Hasan", "Mst. Jannatun Ferdous Rain", "Fyad Mohammed", "Nazmul Siddique"], "title": "BETA-Labeling for Multilingual Dataset Construction in Low-Resource IR", "comment": null, "summary": "IR in low-resource languages remains limited by the scarcity of high-quality, task-specific annotated datasets. Manual annotation is expensive and difficult to scale, while using large language models (LLMs) as automated annotators introduces concerns about label reliability, bias, and evaluation validity. This work presents a Bangla IR dataset constructed using a BETA-labeling framework involving multiple LLM annotators from diverse model families. The framework incorporates contextual alignment, consistency checks, and majority agreement, followed by human evaluation to verify label quality. Beyond dataset creation, we examine whether IR datasets from other low-resource languages can be effectively reused through one-hop machine translation. Using LLM-based translation across multiple language pairs, we experimented on meaning preservation and task validity between source and translated datasets. Our experiment reveal substantial variation across languages, reflecting language-dependent biases and inconsistent semantic preservation that directly affect the reliability of cross-lingual dataset reuse. Overall, this study highlights both the potential and limitations of LLM-assisted dataset creation for low-resource IR. It provides empirical evidence of the risks associated with cross-lingual dataset reuse and offers practical guidance for constructing more reliable benchmarks and evaluation pipelines in low-resource language settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5229\u7528\u591a\u6a21\u578b\u5927\u8bed\u8a00\u6a21\u578b\u6784\u5efa\u5b5f\u52a0\u62c9\u8bedIR\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u8de8\u8bed\u8a00\u6570\u636e\u96c6\u590d\u7528\uff0c\u6307\u51fa\u4e86\u8de8\u8bed\u8a00\u590d\u7528\u4e2d\u7684\u8bed\u4e49\u548c\u504f\u89c1\u98ce\u9669\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00IR\u6570\u636e\u96c6\u6784\u5efa\u63d0\u4f9b\u5b9e\u8bc1\u548c\u6307\u5bfc\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u4fe1\u606f\u68c0\u7d22\u53d7\u9650\u4e8e\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7a00\u7f3a\uff0c\u4eba\u5de5\u6807\u6ce8\u6210\u672c\u9ad8\u4e14\u96be\u4ee5\u6269\u5c55\uff0c\u5355\u4e00\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6807\u6ce8\u53c8\u4f1a\u5e26\u6765\u6807\u7b7e\u53ef\u9760\u6027\u3001\u504f\u89c1\u548c\u8bc4\u4f30\u6709\u6548\u6027\u95ee\u9898\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u591a\u6a21\u578b\u7ed3\u5408\u548c\u673a\u5668\u7ffb\u8bd1\u590d\u7528\u7684\u521b\u65b0\u65b9\u6cd5\u4ee5\u4fc3\u8fdb\u4f4e\u8d44\u6e90\u8bed\u8a00IR\u53d1\u5c55\u3002", "method": "\u672c\u6587\u91c7\u7528\u591a\u6a21\u578b\u878d\u5408\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u81ea\u52a8\u6807\u6ce8\u8005\uff0c\u7ed3\u5408\u4e0a\u4e0b\u6587\u5bf9\u9f50\u3001\u4e00\u81f4\u6027\u68c0\u67e5\u3001\u4e3b\u6d41\u610f\u89c1\u673a\u5236\uff0c\u6700\u540e\u8f85\u4ee5\u4eba\u5de5\u8bc4\u4f30\uff0c\u5f62\u6210\u9ad8\u8d28\u91cf\u7684\u6807\u6ce8\u6846\u67b6BETA\u3002\u901a\u8fc7\u591a\u8bed\u8a00\u5bf9\u91c7\u7528LLM\u673a\u5668\u7ffb\u8bd1\u8bc4\u4f30\u8bed\u4e49\u4fdd\u6301\u548c\u4efb\u52a1\u6709\u6548\u6027\uff0c\u68c0\u9a8c\u8de8\u8bed\u8a00\u6570\u636e\u96c6\u590d\u7528\u7684\u53ef\u884c\u6027\u4e0e\u98ce\u9669\u3002", "result": "\u672c\u6587\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u4fe1\u606f\u68c0\u7d22\uff08IR\uff09\u9886\u57df\u6570\u636e\u96c6\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7ed3\u5408\u7684BETA\u6807\u6ce8\u6846\u67b6\uff0c\u6784\u5efa\u4e86\u5b5f\u52a0\u62c9\u8bed\u4fe1\u606f\u68c0\u7d22\u6570\u636e\u96c6\u3002\u6846\u67b6\u901a\u8fc7\u4e0a\u4e0b\u6587\u5339\u914d\u3001\u4e00\u81f4\u6027\u68c0\u6d4b\u3001\u591a\u6570\u51b3\u7b56\u53ca\u4eba\u5de5\u9a8c\u8bc1\u4fdd\u8bc1\u6570\u636e\u6807\u7b7e\u8d28\u91cf\u3002\u6b64\u5916\uff0c\u7814\u7a76\u4e86\u901a\u8fc7\u5355\u8df3\u673a\u5668\u7ffb\u8bd1\u590d\u7528\u5176\u4ed6\u4f4e\u8d44\u6e90\u8bed\u8a00IR\u6570\u636e\u96c6\u7684\u53ef\u884c\u6027\uff0c\u53d1\u73b0\u4e0d\u540c\u8bed\u8a00\u95f4\u8bed\u4e49\u4fdd\u6301\u548c\u4efb\u52a1\u6709\u6548\u6027\u5b58\u5728\u8f83\u5927\u5dee\u5f02\uff0c\u5f71\u54cd\u8de8\u8bed\u8a00\u6570\u636e\u96c6\u590d\u7528\u7684\u53ef\u9760\u6027\u3002\u672c\u6587\u5c55\u793a\u4e86LLM\u8f85\u52a9\u6570\u636e\u96c6\u6784\u5efa\u7684\u6f5c\u529b\u4e0e\u9650\u5236\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u8bbe\u7f6e\u4e0b\u6784\u5efa\u66f4\u53ef\u9760\u57fa\u51c6\u6d4b\u8bd5\u548c\u8bc4\u6d4b\u6d41\u7a0b\u63d0\u4f9b\u4e86\u7ecf\u9a8c\u6307\u5bfc\u3002", "conclusion": "\u591a\u6a21\u578bLLM\u7ed3\u5408\u7684BETA\u6807\u6ce8\u6846\u67b6\u80fd\u591f\u63d0\u5347\u4f4e\u8d44\u6e90\u8bed\u8a00IR\u6570\u636e\u96c6\u7684\u6807\u6ce8\u8d28\u91cf\uff0c\u4f46\u8de8\u8bed\u8a00\u6570\u636e\u96c6\u590d\u7528\u5b58\u5728\u663e\u8457\u7684\u8bed\u4e49\u4fdd\u6301\u548c\u504f\u89c1\u95ee\u9898\uff0c\u98ce\u9669\u4e0d\u53ef\u5ffd\u89c6\u3002\u7814\u7a76\u5f3a\u8c03\u6784\u5efa\u4f4e\u8d44\u6e90\u8bed\u8a00\u57fa\u51c6\u9700\u8c28\u614e\uff0c\u5efa\u8bae\u7ed3\u5408\u4eba\u5de5\u9a8c\u8bc1\u5b9e\u73b0\u66f4\u53ef\u9760\u8bc4\u6d4b\u3002"}}
{"id": "2602.14492", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.14492", "abs": "https://arxiv.org/abs/2602.14492", "authors": ["Jiahao Yuan", "Yike Xu", "Jinyong Wen", "Baokun Wang", "Ziyi Gao", "Xiaotong Lin", "Yun Liu", "Xing Fu", "Yu Cheng", "Yongchao Liu", "Weiqiang Wang", "Zhongle Xie"], "title": "Query as Anchor: Scenario-Adaptive User Representation via Large Language Model", "comment": "15 pages, 12 figures", "summary": "Industrial-scale user representation learning requires balancing robust universality with acute task-sensitivity. However, existing paradigms primarily yield static, task-agnostic embeddings that struggle to reconcile the divergent requirements of downstream scenarios within unified vector spaces. Furthermore, heterogeneous multi-source data introduces inherent noise and modality conflicts, degrading representation. We propose Query-as-Anchor, a framework shifting user modeling from static encoding to dynamic, query-aware synthesis. To empower Large Language Models (LLMs) with deep user understanding, we first construct UserU, an industrial-scale pre-training dataset that aligns multi-modal behavioral sequences with user understanding semantics, and our Q-Anchor Embedding architecture integrates hierarchical coarse-to-fine encoders into dual-tower LLMs via joint contrastive-autoregressive optimization for query-aware user representation. To bridge the gap between general pre-training and specialized business logic, we further introduce Cluster-based Soft Prompt Tuning to enforce discriminative latent structures, effectively aligning model attention with scenario-specific modalities. For deployment, anchoring queries at sequence termini enables KV-cache-accelerated inference with negligible incremental latency. Evaluations on 10 Alipay industrial benchmarks show consistent SOTA performance, strong scalability, and efficient deployment. Large-scale online A/B testing in Alipay's production system across two real-world scenarios further validates its practical effectiveness. Our code is prepared for public release and will be available at: https://github.com/JhCircle/Q-Anchor.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Query-as-Anchor\u6846\u67b6\uff0c\u7528\u4e8e\u52a8\u6001\u751f\u6210\u67e5\u8be2\u611f\u77e5\u7684\u7528\u6237\u5411\u91cf\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6a21\u6001\u884c\u4e3a\u6570\u636e\uff0c\u5728\u5de5\u4e1a\u7ea7\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u8868\u73b0\u4e0e\u9ad8\u6548\u90e8\u7f72\u3002", "motivation": "\u7528\u6237\u8868\u793a\u5b66\u4e60\u5728\u5de5\u4e1a\u89c4\u6a21\u5e94\u7528\u4e2d\u9700\u8981\u517c\u987e\u6cdb\u5316\u80fd\u529b\u548c\u4efb\u52a1\u654f\u611f\u6027\uff0c\u4f46\u73b0\u6709\u6a21\u578b\u591a\u4e3a\u9759\u6001\u4e14\u4efb\u52a1\u65e0\u5173\u7684\u5411\u91cf\u8868\u793a\uff0c\u96be\u4ee5\u6ee1\u8db3\u4e0d\u540c\u4e0b\u6e38\u573a\u666f\u7684\u9700\u6c42\uff0c\u540c\u65f6\u5f02\u6784\u591a\u6e90\u6570\u636e\u5e26\u6765\u7684\u566a\u58f0\u548c\u6a21\u6001\u51b2\u7a81\u964d\u4f4e\u4e86\u8868\u793a\u6548\u679c\u3002", "method": "\u5229\u7528UserU\u6570\u636e\u96c6\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u91c7\u7528\u5c42\u6b21\u5316\u7c97\u7ec6\u7f16\u7801\u5668\u4e0e\u53cc\u5854\u5927\u8bed\u8a00\u6a21\u578b\u8054\u5408\u5bf9\u6bd4\u81ea\u56de\u5f52\u8bad\u7ec3\uff0c\u5b9e\u73b0\u67e5\u8be2\u611f\u77e5\u5d4c\u5165\uff1b\u901a\u8fc7\u805a\u7c7b\u8f6f\u63d0\u793a\u5fae\u8c03\u589e\u5f3a\u6a21\u578b\u4e1a\u52a1\u573a\u666f\u9002\u914d\u6027\uff1b\u90e8\u7f72\u65f6\u4f7f\u7528\u67e5\u8be2\u951a\u5b9a\u548cKV\u7f13\u5b58\u673a\u5236\u63d0\u5347\u63a8\u7406\u6548\u7387\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u67e5\u8be2\u7684\u52a8\u6001\u7528\u6237\u8868\u793a\u5b66\u4e60\u6846\u67b6Query-as-Anchor\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u591a\u6a21\u6001\u884c\u4e3a\u8bed\u4e49\u5bf9\u9f50\u7684\u6570\u636e\u96c6UserU\uff0c\u4ee5\u53ca\u878d\u5408\u96c6\u5c42\u6b21\u7f16\u7801\u5668\u548c\u8054\u5408\u5bf9\u6bd4\u81ea\u56de\u5f52\u4f18\u5316\u7684Q-Anchor\u5d4c\u5165\u7ed3\u6784\uff0c\u5b9e\u73b0\u4e86\u67e5\u8be2\u611f\u77e5\u7684\u7528\u6237\u8868\u793a\u3002\u5f15\u5165\u57fa\u4e8e\u805a\u7c7b\u7684\u8f6f\u63d0\u793a\u5fae\u8c03\u6280\u672f\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u573a\u666f\u9002\u5e94\u6027\u3002\u5b9e\u9a8c\u572810\u4e2a\u5de5\u4e1a\u57fa\u51c6\u548c\u652f\u4ed8\u5b9d\u7ebf\u4e0a\u573a\u666f\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "Query-as-Anchor\u6210\u529f\u5e73\u8861\u4e86\u7528\u6237\u8868\u793a\u7684\u6cdb\u5316\u6027\u548c\u4efb\u52a1\u654f\u611f\u6027\uff0c\u63d0\u5347\u4e86\u591a\u6a21\u6001\u7528\u6237\u6570\u636e\u7684\u8868\u793a\u8d28\u91cf\u548c\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\uff0c\u9002\u5408\u5de5\u4e1a\u5927\u89c4\u6a21\u5e94\u7528\u4e14\u90e8\u7f72\u9ad8\u6548\u3002"}}
{"id": "2602.14517", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14517", "abs": "https://arxiv.org/abs/2602.14517", "authors": ["Sukumar Kishanthan", "Kumar Thushalika", "Buddhi Jayasekara", "Asela Hevapathige"], "title": "Beyond Translation: Evaluating Mathematical Reasoning Capabilities of LLMs in Sinhala and Tamil", "comment": null, "summary": "Large language models (LLMs) demonstrate strong mathematical reasoning in English, but whether these capabilities reflect genuine multilingual reasoning or reliance on translation-based processing in low-resource languages like Sinhala and Tamil remains unclear. We examine this fundamental question by evaluating whether LLMs genuinely reason mathematically in these languages or depend on implicit translation to English-like representations. Using a taxonomy of six math problem types, from basic arithmetic to complex unit conflict and optimization problems, we evaluate four prominent large language models. To avoid translation artifacts that confound language ability with translation quality, we construct a parallel dataset where each problem is natively authored by fluent speakers with mathematical training in all three languages. Our analysis demonstrates that while basic arithmetic reasoning transfers robustly across languages, complex reasoning tasks show significant degradation in Tamil and Sinhala. The pattern of failures varies by model and problem type, suggesting that apparent multilingual competence may not reflect uniform reasoning capabilities across languages. These findings challenge the common assumption that models exhibiting strong multilingual performance can reason equally effectively across languages, and highlight the need for fine-grained, type-aware evaluation in multilingual settings.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u6570\u5b66\u63a8\u7406\u8868\u73b0\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u590d\u6742\u63a8\u7406\u80fd\u529b\u672a\u80fd\u6709\u6548\u8de8\u8bed\u8a00\u8fc1\u79fb\uff0c\u53cd\u6620\u5176\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\u53ef\u80fd\u5e76\u4e0d\u5747\u5300\u3002", "motivation": "\u63a2\u8ba8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5982\u50e7\u4f3d\u7f57\u8bed\u548c\u6cf0\u7c73\u5c14\u8bed\uff09\u4e2d\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u771f\u5b9e\u6027\uff0c\u662f\u6e90\u4e8e\u5176\u771f\u6b63\u7684\u591a\u8bed\u8a00\u63a8\u7406\u80fd\u529b\uff0c\u8fd8\u662f\u4f9d\u8d56\u4e8e\u9690\u5f0f\u7ffb\u8bd1\u6210\u82f1\u8bed\u8868\u793a\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u672c\u5730\u5316\u4e09\u8bed\u8a00\u5e73\u884c\u6570\u636e\u96c6\uff0c\u5373\u82f1\u8bed\u3001\u50e7\u4f3d\u7f57\u8bed\u548c\u6cf0\u7c73\u5c14\u8bed\uff0c\u7531\u6570\u5b66\u4e13\u4e1a\u6d41\u5229\u53d1\u8a00\u4eba\u672c\u5730\u64b0\u5199\u6570\u5b66\u95ee\u9898\uff0c\u907f\u514d\u7ffb\u8bd1\u5e26\u6765\u7684\u504f\u5dee\uff0c\u91c7\u7528\u516d\u79cd\u6570\u5b66\u9898\u578b\uff08\u4ece\u57fa\u7840\u7b97\u672f\u5230\u590d\u6742\u7684\u5355\u4f4d\u51b2\u7a81\u548c\u4f18\u5316\u95ee\u9898\uff09\u5bf9\u56db\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u57fa\u672c\u7b97\u672f\u63a8\u7406\u5728\u4e09\u79cd\u8bed\u8a00\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u4f46\u590d\u6742\u63a8\u7406\u4efb\u52a1\u5728\u6cf0\u7c73\u5c14\u8bed\u548c\u50e7\u4f3d\u7f57\u8bed\u4e2d\u8868\u73b0\u660e\u663e\u4e0b\u964d\u3002\u4e0d\u540c\u6a21\u578b\u548c\u9898\u578b\u7684\u5931\u8d25\u6a21\u5f0f\u5404\u5f02\uff0c\u663e\u793a\u591a\u8bed\u8a00\u6027\u80fd\u5e76\u4e0d\u4ee3\u8868\u63a8\u7406\u80fd\u529b\u5728\u6240\u6709\u8bed\u8a00\u4e2d\u5747\u8861\u3002", "conclusion": "\u6a21\u578b\u5728\u591a\u8bed\u8a00\u73af\u5883\u4e0b\u8868\u73b0\u51fa\u7684\u5f3a\u6570\u5b66\u63a8\u7406\u80fd\u529b\u4e0d\u53ef\u7b80\u5355\u89c6\u4e3a\u8de8\u8bed\u8a00\u5747\u7b49\uff0c\u547c\u5401\u5bf9\u591a\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u3001\u7c7b\u578b\u611f\u77e5\u7684\u8bc4\u4f30\u4ee5\u51c6\u786e\u53cd\u6620\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2602.14536", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14536", "abs": "https://arxiv.org/abs/2602.14536", "authors": ["Yuchen Yang", "Wenze Lin", "Enhao Huang", "Zhixuan Chu", "Hongbin Zhou", "Lan Tao", "Yiming Li", "Zhan Qin", "Kui Ren"], "title": "Explainable Token-level Noise Filtering for LLM Fine-tuning Datasets", "comment": null, "summary": "Large Language Models (LLMs) have seen remarkable advancements, achieving state-of-the-art results in diverse applications. Fine-tuning, an important step for adapting LLMs to specific downstream tasks, typically involves further training on corresponding datasets. However, a fundamental discrepancy exists between current fine-tuning datasets and the token-level optimization mechanism of LLMs: most datasets are designed at the sentence-level, which introduces token-level noise, causing negative influence to final performance. In this paper, we propose XTF, an explainable token-level noise filtering framework. XTF decomposes the complex and subtle contributions of token-level data to the fine-tuning process into three distinct and explicit attributes (reasoning importance, knowledge novelty, and task relevance), which can be assessed using scoring methods, and then masks the gradients of selected noisy tokens accordingly to optimize the performance of fine-tuned LLMs. We conduct extensive experiments on three representative downstream tasks (math, code and medicine) across 7 mainstream LLMs. The results demonstrate that XTF can significantly improve downstream performance by up to 13.7% compared to regular fine-tuning. Our work highlights the importance of token-level dataset optimization, and demonstrates the potential of strategies based on attribute decomposition for explaining complex training mechanisms.", "AI": {"tldr": "\u9488\u5bf9LLM\u5fae\u8c03\u4e2d\u7684token\u7ea7\u566a\u58f0\u95ee\u9898\uff0c\u63d0\u51faXTF\u6846\u67b6\uff0c\u901a\u8fc7\u5c5e\u6027\u5206\u89e3\u8fc7\u6ee4\u566a\u58f0\uff0c\u63d0\u5347\u5fae\u8c03\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5fae\u8c03\u6570\u636e\u96c6\u591a\u4e3a\u53e5\u5b50\u7ea7\u522b\uff0c\u5bfc\u81f4token\u7ea7\u566a\u58f0\u5f71\u54cd\u5fae\u8c03\u6548\u679c\uff0c\u4e9f\u9700\u8bbe\u8ba1token\u7ea7\u566a\u58f0\u8fc7\u6ee4\u65b9\u6cd5\u63d0\u5347\u5fae\u8c03\u6027\u80fd\u3002", "method": "\u5c06token\u8d21\u732e\u5206\u89e3\u4e3a\u63a8\u7406\u91cd\u8981\u6027\u3001\u77e5\u8bc6\u65b0\u9896\u6027\u548c\u4efb\u52a1\u76f8\u5173\u6027\u4e09\u5c5e\u6027\uff0c\u901a\u8fc7\u8bc4\u5206\u65b9\u6cd5\u68c0\u6d4b\u566a\u58f0token\uff0c\u518d\u6839\u636e\u8bc4\u5206\u5c4f\u853d\u5bf9\u5e94\u68af\u5ea6\uff0c\u5b9e\u73b0\u566a\u58f0\u8fc7\u6ee4\u3002", "result": "\u63d0\u51fa\u4e86XTF\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u89e3token\u7ea7\u6570\u636e\u8d21\u732e\u6210\u4e09\u4e2a\u5c5e\u6027\uff08\u63a8\u7406\u91cd\u8981\u6027\u3001\u77e5\u8bc6\u65b0\u9896\u6027\u3001\u4efb\u52a1\u76f8\u5173\u6027\uff09\u8fdb\u884c\u8bc4\u5206\uff0c\u5e76\u5c4f\u853d\u566a\u58f0token\u68af\u5ea6\uff0c\u663e\u8457\u63d0\u5347LLM\u5fae\u8c03\u6548\u679c\uff0c\u5728\u6570\u5b66\u3001\u4ee3\u7801\u548c\u533b\u5b66\u4e09\u4e2a\u4efb\u52a1\u53ca7\u4e2a\u4e3b\u6d41LLM\u4e2d\u6700\u591a\u63d0\u534713.7%\u3002", "conclusion": "XTF\u6846\u67b6\u6709\u6548\u8fc7\u6ee4\u4e86token\u7ea7\u566a\u58f0\uff0c\u63d0\u9ad8\u4e86LLM\u5fae\u8c03\u540e\u7684\u4e0b\u6e38\u4efb\u52a1\u8868\u73b0\uff0c\u9a8c\u8bc1\u4e86token\u7ea7\u6570\u636e\u4f18\u5316\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2602.14564", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14564", "abs": "https://arxiv.org/abs/2602.14564", "authors": ["Shefayat E Shams Adib", "Ahmed Alfey Sani", "Ekramul Alam Esham", "Ajwad Abrar", "Tareque Mohmud Chowdhury"], "title": "Assessing Large Language Models for Medical QA: Zero-Shot and LLM-as-a-Judge Evaluation", "comment": "Accepted in 28th ICCIT, 2025", "summary": "Recently, Large Language Models (LLMs) have gained significant traction in medical domain, especially in developing a QA systems to Medical QA systems for enhancing access to healthcare in low-resourced settings. This paper compares five LLMs deployed between April 2024 and August 2025 for medical QA, using the iCliniq dataset, containing 38,000 medical questions and answers of diverse specialties. Our models include Llama-3-8B-Instruct, Llama 3.2 3B, Llama 3.3 70B Instruct, Llama-4-Maverick-17B-128E-Instruct, and GPT-5-mini. We are using a zero-shot evaluation methodology and using BLEU and ROUGE metrics to evaluate performance without specialized fine-tuning. Our results show that larger models like Llama 3.3 70B Instruct outperform smaller models, consistent with observed scaling benefits in clinical tasks. It is notable that, Llama-4-Maverick-17B exhibited more competitive results, thus highlighting evasion efficiency trade-offs relevant for practical deployment. These findings align with advancements in LLM capabilities toward professional-level medical reasoning and reflect the increasing feasibility of LLM-supported QA systems in the real clinical environments. This benchmark aims to serve as a standardized setting for future study to minimize model size, computational resources and to maximize clinical utility in medical NLP applications.", "AI": {"tldr": "\u672c\u6587\u8bc4\u6d4b\u4e86\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u95ee\u7b54\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u66f4\u5927\u6a21\u578b\u6548\u679c\u66f4\u597d\uff0c\u4f46\u9700\u8003\u8651\u5b9e\u9645\u90e8\u7f72\u65f6\u7684\u6548\u7387\u548c\u8d44\u6e90\u6d88\u8017\uff0c\u63a8\u8fdb\u533b\u7597NLP\u7684\u5b9e\u9645\u5e94\u7528\u53d1\u5c55\u3002", "motivation": "\u63d0\u5347\u533b\u7597\u9886\u57df\u95ee\u7b54\u7cfb\u7edf\u7684\u8868\u73b0\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u532e\u4e4f\u73af\u5883\u4e0b\uff0c\u901a\u8fc7\u6bd4\u8f83\u4e0d\u540c\u89c4\u6a21\u548c\u7ed3\u6784\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63a8\u52a8\u533b\u7597NLP\u5e94\u7528\u66f4\u9ad8\u6548\u3001\u5b9e\u7528\u7684\u53d1\u5c55\u3002", "method": "\u672c\u6587\u91c7\u7528\u96f6\u6837\u672c\u8bc4\u4f30\uff0c\u5229\u7528BLEU\u548cROUGE\u6307\u6807\u5bf9\u4e94\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728iCliniq\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u5bf9\u6bd4\u5206\u6790\uff0c\u6570\u636e\u96c6\u5305\u542b3.8\u4e07\u6761\u591a\u4e13\u4e1a\u533b\u7597\u95ee\u7b54\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6700\u5927\u89c4\u6a21\u7684Llama 3.3 70B Instruct\u6a21\u578b\u6027\u80fd\u6700\u597d\uff0cLlama-4-Maverick-17B\u6a21\u578b\u5728\u6548\u7387\u548c\u6027\u80fd\u4e0a\u8868\u73b0\u51fa\u826f\u597d\u5e73\u8861\uff0c\u652f\u6301\u5927\u578b\u6a21\u578b\u5728\u4e34\u5e8a\u63a8\u7406\u548c\u95ee\u7b54\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u7597\u95ee\u7b54\u9886\u57df\u8868\u73b0\u51fa\u660e\u663e\u7684\u89c4\u6a21\u6548\u5e94\uff0c\u8f83\u5927\u7684\u6a21\u578b\u5728\u51c6\u786e\u6027\u4e0a\u4f18\u4e8e\u8f83\u5c0f\u6a21\u578b\uff0c\u540c\u65f6\u5728\u5b9e\u9645\u90e8\u7f72\u65f6\u9700\u8981\u6743\u8861\u8ba1\u7b97\u6548\u7387\u548c\u6027\u80fd\u3002"}}
{"id": "2602.14594", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14594", "abs": "https://arxiv.org/abs/2602.14594", "authors": ["Sebastian Walter", "Hannah Bast"], "title": "The Wikidata Query Logs Dataset", "comment": null, "summary": "We present the Wikidata Query Logs (WDQL) dataset, a dataset consisting of 200k question-query pairs over the Wikidata knowledge graph. It is over 6x larger than the largest existing Wikidata datasets of similar format without relying on template-generated queries. Instead, we construct it using real-world SPARQL queries sent to the Wikidata Query Service and generate questions for them. Since these log-based queries are anonymized, and therefore often do not produce results, a significant amount of effort is needed to convert them back into meaningful SPARQL queries. To achieve this, we present an agent-based method that iteratively de-anonymizes, cleans, and verifies queries against Wikidata while also generating corresponding natural-language questions. We demonstrate the dataset's benefit for training question-answering methods. All WDQL assets, as well as the agent code, are publicly available under a permissive license.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u89c4\u6a21\u4e3a20\u4e07\u5bf9\u95ee\u7b54\u5bf9\u7684Wikidata\u67e5\u8be2\u65e5\u5fd7\u6570\u636e\u96c6\uff0c\u91c7\u7528\u771f\u5b9e\u7684\u533f\u540dSPARQL\u67e5\u8be2\uff0c\u5e76\u5f00\u53d1\u4ee3\u7406\u65b9\u6cd5\u8fdb\u884c\u53bb\u533f\u540d\u5316\u548c\u95ee\u9898\u751f\u6210\u3002", "motivation": "\u73b0\u6709Wikidata\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u4e14\u4f9d\u8d56\u6a21\u677f\u751f\u6210\u67e5\u8be2\uff0c\u7f3a\u4e4f\u771f\u5b9e\u3001\u591a\u6837\u6027\u5f3a\u7684\u67e5\u8be2\u6570\u636e\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7406\u7684\u65b9\u6cd5\uff0c\u8fed\u4ee3\u53bb\u533f\u540d\u5316\u3001\u6e05\u7406\u5e76\u9a8c\u8bc1\u533f\u540dSPARQL\u67e5\u8be2\uff0c\u540c\u65f6\u751f\u6210\u5bf9\u5e94\u7684\u81ea\u7136\u8bed\u8a00\u95ee\u9898\u3002", "result": "\u6784\u5efa\u4e86\u89c4\u6a21\u662f\u73b0\u6709\u540c\u7c7b\u6570\u636e\u96c66\u500d\u7684WDQL\u6570\u636e\u96c6\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5bf9\u95ee\u7b54\u7cfb\u7edf\u8bad\u7ec3\u6709\u663e\u8457\u5e2e\u52a9\u3002", "conclusion": "\u6784\u5efa\u7684WDQL\u6570\u636e\u96c6\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8eWikidata\u7684\u95ee\u7b54\u7cfb\u7edf\u8bad\u7ec3\u6548\u679c\uff0c\u4e14\u5f00\u653e\u6570\u636e\u548c\u4ee3\u7801\u4fc3\u8fdb\u76f8\u5173\u7814\u7a76\u3002"}}
{"id": "2602.14649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14649", "abs": "https://arxiv.org/abs/2602.14649", "authors": ["Hao Liu", "Guangyan Li", "Wensheng Zhang", "Yongqiang Tang"], "title": "GradMAP: Faster Layer Pruning with Gradient Metric and Projection Compensation", "comment": "19 pages", "summary": "Large Language Models (LLMs) exhibit strong reasoning abilities, but their high computational costs limit their practical deployment. Recent studies reveal significant redundancy in LLMs layers, making layer pruning an active research topic. Layer pruning research primarily focuses on two aspects: measuring layer importance and recovering performance after pruning. Unfortunately, the present works fail to simultaneously maintain pruning performance and efficiency. In this study, we propose GradMAP, a faster layer pruning method with \\textbf{Grad}ient \\textbf{M}etric \\textbf{A}nd \\textbf{P}rojection compensation, which consists of two stages. In the first stage, we introduce a novel metric based on gradient magnitudes, enabling a global assessment of layer importance. Note that, it requires only a single backward propagation step per pruning decision, substantially enhancing pruning efficiency. In the second stage, we first analyze the layers with the largest mean shift resulting from pruning, and then incorporate a simple yet effective projection compensation matrix to correct this drift in one step. In this way, the degradation of model performance caused by layer pruning is effectively alleviated. Extensive experiments show that GradMAP outperforms previous layer pruning methods in both pruning speed (achieving an average $4\\times$ speedup) and performance.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u68af\u5ea6\u5e45\u5ea6\u548c\u6295\u5f71\u8865\u507f\u7684\u5feb\u901f\u5c42\u526a\u679d\u65b9\u6cd5GradMAP\uff0c\u5b9e\u73b0\u4e86\u526a\u679d\u6548\u7387\u548c\u6027\u80fd\u7684\u53cc\u91cd\u63d0\u5347\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u5b9e\u7528\u6027\u53d7\u9650\u3002\u5c42\u526a\u679d\u7814\u7a76\u9700\u540c\u65f6\u63d0\u5347\u526a\u679d\u6027\u80fd\u548c\u6548\u7387\u3002", "method": "GradMAP\u5305\u542b\u4e24\u9636\u6bb5\uff0c\u7b2c\u4e00\u9636\u6bb5\u7528\u57fa\u4e8e\u68af\u5ea6\u5e45\u5ea6\u7684\u65b0\u6307\u6807\u8bc4\u4f30\u5c42\u91cd\u8981\u6027\uff0c\u4ec5\u9700\u4e00\u6b21\u53cd\u5411\u4f20\u64ad\uff0c\u63d0\u5347\u6548\u7387\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5206\u6790\u526a\u679d\u540e\u5c42\u7684\u5747\u503c\u6f02\u79fb\uff0c\u5229\u7528\u6295\u5f71\u8865\u507f\u77e9\u9635\u4fee\u6b63\u6f02\u79fb\uff0c\u51cf\u5c0f\u6027\u80fd\u635f\u5931\u3002", "result": "\u63d0\u51faGradMAP\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u5e45\u5ea6\u6307\u6807\u548c\u6295\u5f71\u8865\u507f\u63d0\u5347\u5c42\u526a\u679d\u901f\u5ea6\u548c\u6027\u80fd\uff0c\u526a\u679d\u901f\u5ea6\u5e73\u5747\u63d0\u53474\u500d\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "GradMAP\u6709\u6548\u7f13\u89e3\u4e86\u5c42\u526a\u679d\u5e26\u6765\u7684\u6027\u80fd\u4e0b\u964d\uff0c\u5728\u526a\u679d\u901f\u5ea6\u548c\u6548\u679c\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.14653", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14653", "abs": "https://arxiv.org/abs/2602.14653", "authors": ["Matteo Gay", "Coleman Haley", "Mario Giulianelli", "Edoardo Ponti"], "title": "Is Information Density Uniform when Utterances are Grounded on Perception and Discourse?", "comment": "Accepted as main paper at EACL 2026", "summary": "The Uniform Information Density (UID) hypothesis posits that speakers are subject to a communicative pressure to distribute information evenly within utterances, minimising surprisal variance. While this hypothesis has been tested empirically, prior studies are limited exclusively to text-only inputs, abstracting away from the perceptual context in which utterances are produced. In this work, we present the first computational study of UID in visually grounded settings. We estimate surprisal using multilingual vision-and-language models over image-caption data in 30 languages and visual storytelling data in 13 languages, together spanning 11 families. We find that grounding on perception consistently smooths the distribution of information, increasing both global and local uniformity across typologically diverse languages compared to text-only settings. In visual narratives, grounding in both image and discourse contexts has additional effects, with the strongest surprisal reductions occurring at the onset of discourse units. Overall, this study takes a first step towards modelling the temporal dynamics of information flow in ecologically plausible, multimodal language use, and finds that grounded language exhibits greater information uniformity, supporting a context-sensitive formulation of UID.", "AI": {"tldr": "\u672c\u7814\u7a76\u9996\u6b21\u5728\u591a\u6a21\u6001\u89c6\u89c9\u8bed\u5883\u4e0b\u9a8c\u8bc1\u4e86\u7edf\u4e00\u4fe1\u606f\u5bc6\u5ea6\u5047\u8bbe\uff0c\u53d1\u73b0\u89c6\u89c9\u80cc\u666f\u5e2e\u52a9\u8bed\u8a00\u5b9e\u73b0\u66f4\u5747\u5300\u7684\u4fe1\u606f\u6d41\u5206\u5e03\u3002", "motivation": "\u4ee5\u5f80\u7684UID\u5047\u8bbe\u4ec5\u57fa\u4e8e\u7eaf\u6587\u672c\uff0c\u5ffd\u7565\u4e86\u8bed\u8a00\u4ea7\u751f\u65f6\u7684\u611f\u77e5\u4e0a\u4e0b\u6587\uff0c\u7f3a\u4e4f\u5bf9\u591a\u6a21\u6001\u771f\u5b9e\u8bed\u8a00\u4f7f\u7528\u4e2d\u4fe1\u606f\u5206\u5e03\u7684\u7406\u89e3\u3002", "method": "\u5229\u7528\u591a\u8bed\u8a00\u89c6\u89c9\u4e0e\u8bed\u8a00\u6a21\u578b\u8ba1\u7b9730\u79cd\u8bed\u8a00\u7684\u56fe\u50cf\u5b57\u5e55\u548c13\u79cd\u8bed\u8a00\u7684\u89c6\u89c9\u53d9\u4e8b\u6570\u636e\u4e2d\u7684\u4fe1\u606f\u60ca\u8bb6\u5ea6\uff0c\u6bd4\u8f83\u6709\u65e0\u89c6\u89c9\u4fe1\u606f\u65f6\u4fe1\u606f\u5206\u5e03\u7684\u5747\u5300\u6027\u3002", "result": "\u89c6\u89c9\u611f\u77e5\u4e0a\u4e0b\u6587\u53ef\u4ee5\u6709\u6548\u5e73\u6ed1\u4fe1\u606f\u5206\u5e03\uff0c\u63d0\u9ad8\u4fe1\u606f\u7684\u5168\u5c40\u548c\u5c40\u90e8\u5747\u5300\u6027\uff0c\u5c24\u5176\u5728\u89c6\u89c9\u53d9\u4e8b\u4e2d\uff0c\u4fe1\u606f\u5747\u5300\u6027\u63d0\u5347\u5728\u8bdd\u8bed\u5355\u5143\u5f00\u59cb\u5904\u6700\u4e3a\u663e\u8457\u3002", "conclusion": "\u652f\u6301\u57fa\u4e8e\u60c5\u5883\u7684\u7edf\u4e00\u4fe1\u606f\u5bc6\u5ea6\u5047\u8bbe\uff0c\u63d0\u793a\u73b0\u5b9e\u8bed\u8a00\u4f7f\u7528\u4e2d\u7684\u4fe1\u606f\u6d41\u52a8\u6001\u53d7\u89c6\u89c9\u548c\u8bdd\u8bed\u4e0a\u4e0b\u6587\u5f71\u54cd\uff0c\u63a8\u52a8\u4e86\u5bf9\u751f\u6001\u6709\u6548\u6027\u591a\u6a21\u6001\u8bed\u8a00\u6a21\u578b\u7684\u7406\u89e3\u3002"}}
{"id": "2602.14655", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14655", "abs": "https://arxiv.org/abs/2602.14655", "authors": ["Xiao Wei", "Bin Wen", "Yuqin Lin", "Kai Li", "Mingyang gu", "Xiaobao Wang", "Longbiao Wang", "Jianwu Dang"], "title": "Breaking Data Efficiency Dilemma: A Federated and Augmented Learning Framework For Alzheimer's Disease Detection via Speech", "comment": "5 pages, 1 figures, accepted by ICASSP 2026 conference", "summary": "Early diagnosis of Alzheimer's Disease (AD) is crucial for delaying its progression. While AI-based speech detection is non-invasive and cost-effective, it faces a critical data efficiency dilemma due to medical data scarcity and privacy barriers. Therefore, we propose FAL-AD, a novel framework that synergistically integrates federated learning with data augmentation to systematically optimize data efficiency. Our approach delivers three key breakthroughs: First, absolute efficiency improvement through voice conversion-based augmentation, which generates diverse pathological speech samples via cross-category voice-content recombination. Second, collaborative efficiency breakthrough via an adaptive federated learning paradigm, maximizing cross-institutional benefits under privacy constraints. Finally, representational efficiency optimization by an attentive cross-modal fusion model, which achieves fine-grained word-level alignment and acoustic-textual interaction. Evaluated on ADReSSo, FAL-AD achieves a state-of-the-art multi-modal accuracy of 91.52%, outperforming all centralized baselines and demonstrating a practical solution to the data efficiency dilemma. Our source code is publicly available at https://github.com/smileix/fal-ad.", "AI": {"tldr": "FAL-AD\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u4e0e\u8bed\u97f3\u589e\u5f3a\uff0c\u63d0\u9ad8\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u8bca\u65ad\u6570\u636e\u5229\u7528\u7387\uff0c\u5b9e\u73b091.52%\u591a\u6a21\u6001\u51c6\u786e\u7387\uff0c\u7a81\u7834\u6570\u636e\u7a00\u7f3a\u4e0e\u9690\u79c1\u9650\u5236\u3002", "motivation": "\u7531\u4e8e\u533b\u7597\u6570\u636e\u7a00\u7f3a\u548c\u9690\u79c1\u58c1\u5792\uff0cAI\u5728\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u8bed\u97f3\u8bca\u65ad\u4e2d\u9762\u4e34\u4e25\u91cd\u6570\u636e\u6548\u7387\u6311\u6218\uff0c\u4e9f\u9700\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5229\u7528\u8bed\u97f3\u8f6c\u6362\u8fdb\u884c\u591a\u6837\u5316\u6570\u636e\u589e\u5f3a\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\u7b56\u7565\u5b9e\u73b0\u8de8\u673a\u6784\u534f\u540c\uff0c\u7ed3\u5408\u5173\u6ce8\u673a\u5236\u7684\u8de8\u6a21\u6001\u878d\u5408\u6a21\u578b\u5b9e\u73b0\u97f3\u9891\u4e0e\u6587\u672c\u7684\u7ec6\u7c92\u5ea6\u5bf9\u9f50\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86FAL-AD\u6846\u67b6\uff0c\u7ed3\u5408\u8054\u90a6\u5b66\u4e60\u548c\u6570\u636e\u589e\u5f3a\uff0c\u9488\u5bf9\u963f\u5c14\u8328\u6d77\u9ed8\u75c5(AD)\u8bed\u97f3\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u6548\u7387\u95ee\u9898\u8fdb\u884c\u7cfb\u7edf\u4f18\u5316\u3002\u65b9\u6cd5\u5305\u62ec\u57fa\u4e8e\u8bed\u97f3\u8f6c\u6362\u7684\u6570\u636e\u589e\u5f3a\u3001\u591a\u673a\u6784\u9690\u79c1\u4fdd\u62a4\u4e0b\u7684\u81ea\u9002\u5e94\u8054\u90a6\u5b66\u4e60\uff0c\u53ca\u7ec6\u7c92\u5ea6\u8bcd\u7ea7\u5bf9\u9f50\u7684\u8de8\u6a21\u6001\u878d\u5408\u6a21\u578b\u3002\u5b9e\u9a8c\u5728ADReSSo\u6570\u636e\u96c6\u4e0a\u591a\u6a21\u6001\u51c6\u786e\u7387\u8fbe91.52%\uff0c\u4f18\u4e8e\u6240\u6709\u96c6\u4e2d\u5f0f\u57fa\u7ebf\uff0c\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "FAL-AD\u6709\u6548\u89e3\u51b3\u4e86AD\u8bed\u97f3\u68c0\u6d4b\u4e2d\u7684\u6570\u636e\u6548\u7387\u56f0\u5883\uff0c\u5728\u4fdd\u8bc1\u9690\u79c1\u7684\u524d\u63d0\u4e0b\u663e\u8457\u63d0\u5347\u8bca\u65ad\u51c6\u786e\u7387\uff0c\u5177\u6709\u5e7f\u6cdb\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2602.14675", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14675", "abs": "https://arxiv.org/abs/2602.14675", "authors": ["Gianluca Vico", "Jind\u0159ich Libovick\u00fd"], "title": "Crowdsourcing Piedmontese to Test LLMs on Non-Standard Orthography", "comment": "17 pages, 6 figures, at VarDial20226", "summary": "We present a crowdsourced dataset for Piedmontese, an endangered Romance language of northwestern Italy. The dataset comprises 145 Italian-Piedmontese parallel sentences derived from Flores+, with translations produced by speakers writing in their natural orthographic style rather than adhering to standardized conventions, along with manual word alignment. We use this resource to benchmark several large language models on tokenization parity, topic classification, and machine translation. Our analysis reveals that Piedmontese incurs a tokenization penalty relative to higher-resource Romance languages, yet LLMs achieve classification performance approaching that of Italian, French, and English. Machine translation results are asymmetric: models translate adequately from Piedmontese into high-resource languages, but generation into Piedmontese remains challenging. The dataset and code are publicly released.", "AI": {"tldr": "\u672c\u7814\u7a76\u53d1\u5e03\u4e86\u4e00\u4e2a\u76ae\u57c3\u8499\u7279\u8bed\u7684\u4f17\u5305\u5e73\u884c\u8bed\u6599\u5e93\uff0c\u7ed3\u5408\u624b\u52a8\u5bf9\u9f50\uff0c\u7528\u4e8e\u8bc4\u6d4b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u8bcd\u3001\u5206\u7c7b\u548c\u7ffb\u8bd1\u4e0a\u7684\u8868\u73b0\uff0c\u63ed\u793a\u4e86\u8be5\u8bed\u8a00\u7684\u5206\u8bcd\u6311\u6218\u53ca\u7ffb\u8bd1\u4e2d\u7684\u4e0d\u5bf9\u79f0\u6027\u95ee\u9898\u3002", "motivation": "\u76ae\u57c3\u8499\u7279\u8bed\u4f5c\u4e3a\u4e00\u79cd\u5728\u610f\u5927\u5229\u897f\u5317\u90e8\u6fd2\u5371\u7684\u7f57\u66fc\u8bed\u7cfb\u8bed\u8a00\uff0c\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u6570\u7801\u8bed\u8a00\u8d44\u6e90\uff0c\u4e9f\u9700\u6784\u5efa\u6570\u636e\u96c6\u4ee5\u4fc3\u8fdb\u5176\u8bed\u8a00\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u610f\u5927\u5229\u8bed-\u76ae\u57c3\u8499\u7279\u8bed\u5e73\u884c\u53e5\u5b50\u7684\u4f17\u5305\u6570\u636e\u96c6\uff0c\u5e76\u901a\u8fc7\u624b\u52a8\u8bcd\u5bf9\u9f50\u5bf9\u6570\u636e\u8fdb\u884c\u4e86\u7cbe\u7ec6\u5904\u7406\u3002\u5229\u7528\u8be5\u8d44\u6e90\u5bf9\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u8bcd\u4e00\u81f4\u6027\u3001\u4e3b\u9898\u5206\u7c7b\u548c\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u76ae\u57c3\u8499\u7279\u8bed\u5728\u5206\u8bcd\u65f6\u8868\u73b0\u51fa\u6bd4\u5176\u4ed6\u4e3b\u8981\u7f57\u66fc\u8bed\u8a00\u66f4\u9ad8\u7684\u5206\u8bcd\u96be\u5ea6\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u9898\u5206\u7c7b\u4efb\u52a1\u4e0a\u8868\u73b0\u63a5\u8fd1\u610f\u5927\u5229\u8bed\u3001\u6cd5\u8bed\u548c\u82f1\u8bed\u3002\u673a\u5668\u7ffb\u8bd1\u65b9\u9762\uff0c\u6a21\u578b\u80fd\u8f83\u597d\u5730\u5c06\u76ae\u57c3\u8499\u7279\u8bed\u7ffb\u8bd1\u6210\u9ad8\u8d44\u6e90\u8bed\u8a00\uff0c\u4f46\u4ece\u9ad8\u8d44\u6e90\u8bed\u8a00\u7ffb\u8bd1\u56de\u76ae\u57c3\u8499\u7279\u8bed\u4ecd\u5b58\u5728\u56f0\u96be\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u76ae\u57c3\u8499\u7279\u8bed\u7684\u8bed\u8a00\u5904\u7406\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u5c3d\u7ba1\u9762\u4e34\u5206\u8bcd\u548c\u751f\u6210\u7ffb\u8bd1\u7684\u6311\u6218\uff0c\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5206\u7c7b\u548c\u90e8\u5206\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u826f\u597d\u6f5c\u529b\uff0c\u6570\u636e\u96c6\u53ca\u4ee3\u7801\u5df2\u516c\u5f00\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2602.14743", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14743", "abs": "https://arxiv.org/abs/2602.14743", "authors": ["S\u00f6nke Tenckhoff", "Mario Koddenbrock", "Erik Rodner"], "title": "LLMStructBench: Benchmarking Large Language Model Structured Data Extraction", "comment": null, "summary": "We present LLMStructBench, a novel benchmark for evaluating Large Language Models (LLMs) on extracting structured data and generating valid JavaScript Object Notation (JSON) outputs from natural-language text. Our open dataset comprises diverse, manually verified parsing scenarios of varying complexity and enables systematic testing across 22 models and five prompting strategies. We further introduce complementary performance metrics that capture both token-level accuracy and document-level validity, facilitating rigorous comparison of model, size, and prompting effects on parsing reliability.\n  In particular, we show that choosing the right prompting strategy is more important than standard attributes such as model size. This especially ensures structural validity for smaller or less reliable models but increase the number of semantic errors. Our benchmark suite is an step towards future research in the area of LLM applied to parsing or Extract, Transform and Load (ETL) applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86LLMStructBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u6a21\u578b\u89e3\u6790\u7ed3\u6784\u5316\u6570\u636e\u7684\u80fd\u529b\uff0c\u5f3a\u8c03\u63d0\u793a\u7b56\u7565\u7684\u91cd\u8981\u6027\u4f18\u4e8e\u6a21\u578b\u5927\u5c0f\u3002", "motivation": "\u4e3a\u4e86\u8bc4\u4f30\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5728\u4ece\u81ea\u7136\u8bed\u8a00\u6587\u672c\u4e2d\u63d0\u53d6\u7ed3\u6784\u5316\u6570\u636e\u4ee5\u53ca\u751f\u6210\u6709\u6548\u7684JSON\u8f93\u51fa\u7684\u80fd\u529b\uff0c\u63d0\u51fa\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002", "method": "\u6784\u5efa\u591a\u6837\u4e14\u4eba\u5de5\u9a8c\u8bc1\u7684\u89e3\u6790\u6570\u636e\u96c6\uff0c\u5b9a\u4e49\u540c\u65f6\u8861\u91cftoken\u7ea7\u51c6\u786e\u7387\u548c\u6587\u6863\u7ea7\u6709\u6548\u6027\u7684\u6027\u80fd\u6307\u6807\uff0c\u7cfb\u7edf\u6d4b\u8bd5\u591a\u6a21\u578b\u591a\u7b56\u7565\u8868\u73b0\u3002", "result": "\u5b9e\u73b0\u4e86\u4e00\u4e2a\u5305\u542b\u591a\u6837\u5316\u4e14\u624b\u5de5\u9a8c\u8bc1\u7684\u89e3\u6790\u573a\u666f\u7684\u6570\u636e\u96c6\uff0c\u5bf922\u4e2a\u6a21\u578b\u53ca\u4e94\u79cd\u63d0\u793a\u7b56\u7565\u8fdb\u884c\u4e86\u7cfb\u7edf\u6d4b\u8bd5\uff0c\u53d1\u73b0\u9009\u62e9\u5408\u9002\u7684\u63d0\u793a\u7b56\u7565\u6bd4\u6a21\u578b\u5927\u5c0f\u66f4\u5173\u952e\uff0c\u5c24\u5176\u5bf9\u8f83\u5c0f\u6216\u4e0d\u591f\u53ef\u9760\u7684\u6a21\u578b\u80fd\u4fdd\u8bc1\u7ed3\u6784\u6709\u6548\u6027\uff0c\u4f46\u8bed\u4e49\u9519\u8bef\u589e\u52a0\u3002", "conclusion": "\u9009\u62e9\u6b63\u786e\u7684\u63d0\u793a\u7b56\u7565\u5bf9\u4fdd\u8bc1\u7ed3\u6784\u6709\u6548\u6027\u81f3\u5173\u91cd\u8981\uff0c\u5c24\u5176\u5bf9\u5c0f\u6a21\u578b\u6548\u679c\u663e\u8457\uff0c\u4e3aLLM\u5728\u89e3\u6790\u548cETL\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u57fa\u7840\u3002"}}
{"id": "2602.14744", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14744", "abs": "https://arxiv.org/abs/2602.14744", "authors": ["Xin Qiu", "Junlong Tong", "Yirong Sun", "Yunpu Ma", "Wei Zhang", "Xiaoyu Shen"], "title": "Rethinking the Role of LLMs in Time Series Forecasting", "comment": null, "summary": "Large language models (LLMs) have been introduced to time series forecasting (TSF) to incorporate contextual knowledge beyond numerical signals. However, existing studies question whether LLMs provide genuine benefits, often reporting comparable performance without LLMs. We show that such conclusions stem from limited evaluation settings and do not hold at scale. We conduct a large-scale study of LLM-based TSF (LLM4TSF) across 8 billion observations, 17 forecasting scenarios, 4 horizons, multiple alignment strategies, and both in-domain and out-of-domain settings. Our results demonstrate that \\emph{LLM4TS indeed improves forecasting performance}, with especially large gains in cross-domain generalization. Pre-alignment outperforming post-alignment in over 90\\% of tasks. Both pretrained knowledge and model architecture of LLMs contribute and play complementary roles: pretraining is critical under distribution shifts, while architecture excels at modeling complex temporal dynamics. Moreover, under large-scale mixed distributions, a fully intact LLM becomes indispensable, as confirmed by token-level routing analysis and prompt-based improvements. Overall, Our findings overturn prior negative assessments, establish clear conditions under which LLMs are not only useful, and provide practical guidance for effective model design. We release our code at https://github.com/EIT-NLP/LLM4TSF.", "AI": {"tldr": "\u73b0\u6709\u8d1f\u9762\u8bc4\u4ef7\u56e0\u8bc4\u4f30\u4e0d\u8db3\u800c\u8bef\u5bfc\uff0c\u57fa\u4e8e\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bc1\u660eLLM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u786e\u6709\u4f18\u52bf\uff0c\u5c24\u5176\u5728\u8de8\u57df\u6cdb\u5316\u548c\u590d\u6742\u52a8\u6001\u5efa\u6a21\u65b9\u9762\uff0c\u7ed9\u51fa\u5b9e\u9645\u8bbe\u8ba1\u5efa\u8bae\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u5bf9LLM\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u6548\u7528\u6301\u6000\u7591\u6001\u5ea6\uff0c\u8ba4\u4e3a\u5176\u6027\u80fd\u5e76\u65e0\u660e\u663e\u4f18\u52bf\uff0c\u4f5c\u8005\u65e8\u5728\u901a\u8fc7\u66f4\u5927\u89c4\u6a21\u548c\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u68c0\u9a8cLLM\u7684\u771f\u5b9e\u4ef7\u503c\u3002", "method": "\u901a\u8fc7\u5927\u89c4\u6a21\u5b9e\u9a8c\u8bbe\u8ba1\uff0c\u5305\u62ec8\u4ebf\u6761\u89c2\u6d4b\u6570\u636e\u300117\u4e2a\u9884\u6d4b\u573a\u666f\u30014\u4e2a\u9884\u6d4b\u65f6\u57df\u3001\u591a\u79cd\u5bf9\u9f50\u7b56\u7565\u53ca\u57df\u5185\u548c\u57df\u5916\u8bbe\u7f6e\uff0c\u8bc4\u4f30\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\uff08LLM4TSF\uff09\u3002", "result": "\u7814\u7a76\u53d1\u73b0LLM4TSF\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8de8\u57df\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u7a81\u51fa\u3002\u9884\u5bf9\u9f50\u7b56\u7565\u4f18\u4e8e\u540e\u5bf9\u9f50\uff0c\u9884\u8bad\u7ec3\u77e5\u8bc6\u548c\u6a21\u578b\u67b6\u6784\u5206\u522b\u5e94\u5bf9\u5206\u5e03\u8f6c\u79fb\u4e0e\u590d\u6742\u65f6\u5e8f\u52a8\u6001\uff0c\u5b8c\u6574LLM\u5728\u5927\u89c4\u6a21\u6df7\u5408\u5206\u5e03\u4e0b\u4e0d\u53ef\u6216\u7f3a\u3002", "conclusion": "\u672c\u6587\u63a8\u7ffb\u4e86\u5148\u524d\u5bf9LLM\u65e0\u6548\u6027\u7684\u8bc4\u5224\uff0c\u660e\u786e\u4e86LLM\u4f18\u52bf\u51fa\u73b0\u7684\u6761\u4ef6\uff0c\u5f3a\u8c03\u9884\u8bad\u7ec3\u4e0e\u67b6\u6784\u7684\u4e92\u8865\u4f5c\u7528\uff0c\u5e76\u63d0\u4f9b\u4e86\u9762\u5411\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u7684LLM\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2602.14749", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14749", "abs": "https://arxiv.org/abs/2602.14749", "authors": ["Francesco Gariboldi", "Emma Franchino", "Edith Haim", "Gianluca Lattanzi", "Alessandro Grecucci", "Massimo Stella"], "title": "Cognitive networks reconstruct mindsets about STEM subjects and educational contexts in almost 1000 high-schoolers, University students and LLM-based digital twins", "comment": null, "summary": "Attitudes toward STEM develop from the interaction of conceptual knowledge, educational experiences, and affect. Here we use cognitive network science to reconstruct group mindsets as behavioural forma mentis networks (BFMNs). In this case, nodes are cue words and free associations, edges are empirical associative links, and each concept is annotated with perceived valence. We analyse BFMNs from N = 994 observations spanning high school students, university students, and early-career STEM experts, alongside LLM (GPT-oss) \"digital twins\" prompted to emulate comparable profiles. Focusing also on semantic neighbourhoods (\"frames\") around key target concepts (e.g., STEM subjects or educational actors/places), we quantify frames in terms of valence auras, emotional profiles, network overlap (Jaccard similarity), and concreteness relative to null baselines. Across student groups, science and research are consistently framed positively, while their core quantitative subjects (mathematics and statistics) exhibit more negative and anxiety related auras, amplified in higher math-anxiety subgroups, evidencing a STEM-science cognitive and emotional dissonance. High-anxiety frames are also less concrete than chance, suggesting more abstract and decontextualised representations of threatening quantitative domains. Human networks show greater overlapping between mathematics and anxiety than GPT-oss. The results highlight how BFMNs capture cognitive-affective signatures of mindsets towards the target domains and indicate that LLM-based digital twins approximate cultural attitudes but miss key context-sensitive, experience-based components relevant to replicate human educational anxiety.", "AI": {"tldr": "\u5229\u7528\u8ba4\u77e5\u7f51\u7edc\u79d1\u5b66\u5206\u6790\u4e0d\u540c\u7fa4\u4f53STEM\u6001\u5ea6\uff0c\u53d1\u73b0\u6570\u5b66\u7126\u8651\u663e\u8457\u4e14\u6570\u5b57\u6a21\u578b\u96be\u4ee5\u5b8c\u5168\u590d\u5236\u4eba\u7c7b\u6559\u80b2\u7126\u8651\u3002", "motivation": "\u7406\u89e3STEM\u6001\u5ea6\u5982\u4f55\u901a\u8fc7\u6982\u5ff5\u77e5\u8bc6\u3001\u6559\u80b2\u7ecf\u5386\u548c\u60c5\u611f\u4ea4\u4e92\u5f62\u6210\uff0c\u53ca\u5982\u4f55\u5229\u7528\u8ba4\u77e5\u7f51\u7edc\u79d1\u5b66\u5efa\u6a21\u4eba\u7fa4\u5fc3\u7406\u8868\u5f81\u4ee5\u63ed\u793a\u5b66\u4e60\u548c\u7126\u8651\u673a\u5236\u3002", "method": "\u57fa\u4e8e\u81ea\u7531\u8054\u60f3\u6570\u636e\u6784\u5efa\u884c\u4e3a\u5fc3\u667a\u7f51\u7edc\uff0c\u8282\u70b9\u4ee3\u8868\u63d0\u793a\u8bcd\u548c\u8054\u60f3\u8bcd\uff0c\u8fb9\u4e3a\u7ecf\u9a8c\u8054\u60f3\u8fde\u63a5\uff0c\u7ed3\u5408\u60c5\u611f\u6807\u6ce8\uff0c\u5206\u6790\u4e0d\u540c\u7fa4\u4f53\u53caGPT-oss\u6570\u5b57\u53cc\u80de\u80ce\u7f51\u7edc\u7ed3\u6784\u53ca\u60c5\u611f\u7279\u5f81\u3002", "result": "\u8be5\u8bba\u6587\u5229\u7528\u8ba4\u77e5\u7f51\u7edc\u79d1\u5b66\u6784\u5efa\u884c\u4e3a\u5fc3\u667a\u7f51\u7edc\uff08BFMNs\uff09\uff0c\u63a2\u8ba8STEM\u6001\u5ea6\u7684\u53d1\u5c55\uff0c\u5206\u6790\u4e86\u9ad8\u4e2d\u751f\u3001\u5927\u5b66\u751f\u548c\u521d\u7ea7STEM\u4e13\u5bb6\u7684\u8ba4\u77e5\u60c5\u611f\u7f51\u7edc\uff0c\u5e76\u4e0e\u6a21\u62df\u76f8\u5e94\u4eba\u7fa4\u7684GPT-oss\u6570\u5b57\u53cc\u80de\u80ce\u8fdb\u884c\u6bd4\u8f83\u3002\u7ed3\u679c\u663e\u793a\u79d1\u5b66\u548c\u7814\u7a76\u6574\u4f53\u60c5\u611f\u79ef\u6781\uff0c\u4f46\u6570\u5b66\u548c\u7edf\u8ba1\u5b66\u542b\u6709\u66f4\u591a\u8d1f\u9762\u548c\u7126\u8651\u60c5\u7eea\uff0c\u4e14\u7126\u8651\u9ad8\u7684\u7fa4\u4f53\u8868\u73b0\u51fa\u66f4\u62bd\u8c61\u7684\u8868\u5f81\u3002\u4eba\u7c7b\u7f51\u7edc\u4e2d\u6570\u5b66\u4e0e\u7126\u8651\u7684\u91cd\u53e0\u5ea6\u9ad8\u4e8eGPT\u6a21\u578b\uff0c\u8868\u660e\u6570\u5b57\u53cc\u80de\u80ce\u80fd\u6a21\u62df\u6587\u5316\u6001\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u60c5\u5883\u654f\u611f\u548c\u57fa\u4e8e\u7ecf\u9a8c\u7684\u6559\u80b2\u7126\u8651\u7279\u5f81\u3002", "conclusion": "BFMNs\u6709\u6548\u6355\u6349STEM\u76f8\u5173\u7684\u8ba4\u77e5-\u60c5\u611f\u7279\u5f81\uff0c\u6570\u5b57\u53cc\u80de\u80ce\u867d\u80fd\u6a21\u62df\u6587\u5316\u6001\u5ea6\uff0c\u4f46\u65e0\u6cd5\u5b8c\u6574\u53cd\u6620\u4eba\u7c7b\u7684\u60c5\u5883\u4f9d\u8d56\u6027\u6559\u80b2\u7126\u8651\u3002"}}
{"id": "2602.14760", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14760", "abs": "https://arxiv.org/abs/2602.14760", "authors": ["Jonathan Lys", "Vincent Gripon", "Bastien Pasdeloup", "Lukas Mauch", "Fabien Cardinaux", "Ghouthi Boukli Hacene"], "title": "Residual Connections and the Causal Shift: Uncovering a Structural Misalignment in Transformers", "comment": null, "summary": "Large Language Models (LLMs) are trained with next-token prediction, implemented in autoregressive Transformers via causal masking for parallelism. This creates a subtle misalignment: residual connections tie activations to the current token, while supervision targets the next token, potentially propagating mismatched information if the current token is not the most informative for prediction. In this work, we empirically localize this input-output alignment shift in pretrained LLMs, using decoding trajectories over tied embedding spaces and similarity-based metrics. Our experiments reveal that the hidden token representations switch from input alignment to output alignment deep within the network. Motivated by this observation, we propose a lightweight residual-path mitigation based on residual attenuation, implemented either as a fixed-layer intervention or as a learnable gating mechanism. Experiments on multiple benchmarks show that these strategies alleviate the representation misalignment and yield improvements, providing an efficient and general architectural enhancement for autoregressive Transformers.", "AI": {"tldr": "\u672c\u6587\u63ed\u793a\u5e76\u7f13\u89e3\u4e86\u81ea\u56de\u5f52Transformer\u4e2d\u8f93\u5165\u8f93\u51fa\u5bf9\u9f50\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6b8b\u5dee\u8870\u51cf\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u9884\u6d4b\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u81ea\u56de\u5f52Transformer\u6a21\u578b\u4e2d\uff0c\u6b8b\u5dee\u8fde\u63a5\u53ef\u80fd\u5bfc\u81f4\u8f93\u5165\u8f93\u51fa\u5bf9\u9f50\u4e0d\u5339\u914d\uff0c\u5f71\u54cd\u9884\u6d4b\u6548\u679c\u3002", "method": "\u901a\u8fc7\u89e3\u7801\u8f68\u8ff9\u548c\u76f8\u4f3c\u5ea6\u6307\u6807\u5b9a\u4f4d\u9884\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u4e2d\u8f93\u5165\u8f93\u51fa\u5bf9\u9f50\u8f6c\u53d8\u4f4d\u7f6e\uff0c\u63d0\u51fa\u57fa\u4e8e\u6b8b\u5dee\u8870\u51cf\u7684\u8f7b\u91cf\u5316\u7f13\u89e3\u65b9\u6cd5\uff0c\u5305\u62ec\u56fa\u5b9a\u5c42\u5e72\u9884\u548c\u53ef\u5b66\u4e60\u95e8\u63a7\u673a\u5236\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u6240\u63d0\u7b56\u7565\u7f13\u89e3\u4e86\u8868\u793a\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u901a\u7528\u7684\u67b6\u6784\u6539\u8fdb\u3002", "conclusion": "\u672c\u6587\u53d1\u73b0\u4e86\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u9690\u85cf\u5c42\u7684\u8f93\u5165\u8f93\u51fa\u5bf9\u9f50\u5207\u6362\u73b0\u8c61\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6b8b\u5dee\u8def\u5f84\u8c03\u6574\u7b56\u7565\u6709\u6548\u6539\u5584\u4e86\u6a21\u578b\u8868\u793a\u5bf9\u9f50\uff0c\u4ece\u800c\u63d0\u5347\u4e86\u81ea\u56de\u5f52Transformer\u7684\u8868\u73b0\u3002"}}
{"id": "2602.14763", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14763", "abs": "https://arxiv.org/abs/2602.14763", "authors": ["Sara Rajaee", "Sebastian Vincent", "Alexandre Berard", "Marzieh Fadaee", "Kelly Marchisio", "Tom Kocmi"], "title": "Unlocking Reasoning Capability on Machine Translation in Large Language Models", "comment": null, "summary": "Reasoning-oriented large language models (RLMs) achieve strong gains on tasks such as mathematics and coding by generating explicit intermediate reasoning. However, their impact on machine translation (MT) remains underexplored. We systematically evaluate several open- and closed-weights RLMs on the WMT24++ benchmark and find that enabling explicit reasoning consistently degrades translation quality across languages and models. Analysis reveals that MT reasoning traces are highly linear, lacking revision, self-correction and exploration of alternative translations, which limits their usefulness. Furthermore, injecting higher-quality reasoning traces from stronger models does not reliably improve weaker models' performance. To address this mismatch, we propose a structured reasoning framework tailored to translation, based on multi-step drafting, adequacy refinement, fluency improvement, and selective iterative revision. We curate a synthetic dataset of dynamic structured reasoning traces and post-train a large reasoning model on this data. Experiments show significant improvements over standard translation fine-tuning and injected generic reasoning baselines. Our findings demonstrate that reasoning must be task-structured to benefit MT.", "AI": {"tldr": "\u663e\u5f0f\u63a8\u7406\u5728\u673a\u5668\u7ffb\u8bd1\u4e2d\u6613\u5bfc\u81f4\u8d28\u91cf\u4e0b\u964d\uff0c\u9700\u4efb\u52a1\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\u6765\u63d0\u5347\u7ffb\u8bd1\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1\u63a8\u7406\u5bfc\u5411\u5927\u578b\u6a21\u578b\u5728\u6570\u5b66\u548c\u7f16\u7801\u7b49\u4efb\u52a1\u8868\u73b0\u4f18\u5f02\uff0c\u5176\u5728\u673a\u5668\u7ffb\u8bd1\u7684\u5e94\u7528\u5374\u672a\u88ab\u5145\u5206\u7814\u7a76\uff0c\u73b0\u6709\u663e\u5f0f\u63a8\u7406\u65b9\u5f0f\u53cd\u800c\u964d\u4f4e\u7ffb\u8bd1\u8d28\u91cf\uff0c\u4e9f\u9700\u8bbe\u8ba1\u9002\u914d\u7ffb\u8bd1\u4efb\u52a1\u7ed3\u6784\u7684\u63a8\u7406\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6b65\u8349\u7a3f\u3001\u5145\u8db3\u6027\u5f3a\u5316\u3001\u6d41\u7545\u5ea6\u63d0\u5347\u53ca\u9009\u62e9\u6027\u8fed\u4ee3\u4fee\u8ba2\u7684\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\uff0c\u5e76\u6784\u5efa\u5408\u6210\u52a8\u6001\u63a8\u7406\u8f68\u8ff9\u6570\u636e\u8fdb\u884c\u5927\u6a21\u578b\u540e\u8bad\u7ec3\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u63a8\u7406\u5bfc\u5411\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u542f\u7528\u663e\u5f0f\u63a8\u7406\u53cd\u800c\u964d\u4f4e\u4e86\u7ffb\u8bd1\u8d28\u91cf\u3002\u5206\u6790\u8ba4\u4e3a\uff0c\u673a\u5668\u7ffb\u8bd1\u4e2d\u7684\u63a8\u7406\u8f68\u8ff9\u8fc7\u4e8e\u7ebf\u6027\uff0c\u7f3a\u4e4f\u4fee\u6b63\u548c\u63a2\u7d22\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u9488\u5bf9\u7ffb\u8bd1\u4efb\u52a1\u7684\u7ed3\u6784\u5316\u63a8\u7406\u6846\u67b6\uff0c\u5305\u62ec\u591a\u6b65\u8349\u7a3f\u3001\u5145\u8db3\u6027\u8c03\u6574\u3001\u6d41\u7545\u5ea6\u63d0\u5347\u548c\u9009\u62e9\u6027\u8fed\u4ee3\u4fee\u8ba2\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u96c6\u5bf9\u5927\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5fae\u8c03\u548c\u901a\u7528\u63a8\u7406\u6ce8\u5165\u57fa\u7ebf\uff0c\u8bc1\u660e\u63a8\u7406\u9700\u9488\u5bf9\u4efb\u52a1\u7ed3\u6784\u8bbe\u8ba1\u624d\u80fd\u63d0\u5347\u673a\u5668\u7ffb\u8bd1\u6548\u679c\u3002", "conclusion": "\u63a8\u7406\u5fc5\u987b\u7ed3\u5408\u673a\u5668\u7ffb\u8bd1\u4efb\u52a1\u7684\u7ed3\u6784\u7279\u6027\uff0c\u91c7\u7528\u591a\u6b65\u8fed\u4ee3\u4fee\u8ba2\u7b49\u65b9\u6cd5\uff0c\u65b9\u80fd\u63d0\u5347\u7ffb\u8bd1\u8d28\u91cf\uff0c\u7b80\u5355\u542f\u7528\u663e\u5f0f\u63a8\u7406\u53cd\u800c\u9002\u5f97\u5176\u53cd\u3002"}}
{"id": "2602.14770", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC"], "pdf": "https://arxiv.org/pdf/2602.14770", "abs": "https://arxiv.org/abs/2602.14770", "authors": ["Shiwei Hong", "Lingyao Li", "Ethan Z. Rong", "Chenxinran Shen", "Zhicong Lu"], "title": "Multi-Agent Comedy Club: Investigating Community Discussion Effects on LLM Humor Generation", "comment": "18 pages, 5 figures", "summary": "Prior work has explored multi-turn interaction and feedback for LLM writing, but evaluations still largely center on prompts and localized feedback, leaving persistent public reception in online communities underexamined. We test whether broadcast community discussion improves stand-up comedy writing in a controlled multi-agent sandbox: in the discussion condition, critic and audience threads are recorded, filtered, stored as social memory, and later retrieved to condition subsequent generations, whereas the baseline omits discussion. Across 50 rounds (250 paired monologues) judged by five expert annotators using A/B preference and a 15-item rubric, discussion wins 75.6% of instances and improves Craft/Clarity (\u0394 = 0.440) and Social Response (\u0394 = 0.422), with occasional increases in aggressive humor.", "AI": {"tldr": "\u5f15\u5165\u793e\u533a\u516c\u5171\u8ba8\u8bba\u7684\u591a\u667a\u80fd\u4f53\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8131\u53e3\u79c0\u559c\u5267\u5199\u4f5c\u7684\u8d28\u91cf\u548c\u793e\u4f1a\u63a5\u53d7\u5ea6\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5199\u4f5c\u7684\u591a\u8f6e\u4ea4\u4e92\u548c\u53cd\u9988\u5df2\u6709\u7814\u7a76\uff0c\u4f46\u8bc4\u4ef7\u4ecd\u4e3b\u8981\u96c6\u4e2d\u5728\u63d0\u793a\u8bcd\u548c\u5c40\u90e8\u53cd\u9988\uff0c\u7f3a\u4e4f\u5bf9\u7ebf\u4e0a\u793e\u533a\u6301\u7eed\u516c\u5171\u63a5\u53d7\u5ea6\u7684\u6df1\u5165\u8003\u5bdf\u3002", "method": "\u5728\u4e00\u4e2a\u53d7\u63a7\u591a\u667a\u80fd\u4f53\u6c99\u7bb1\u73af\u5883\u4e2d\u6d4b\u8bd5\u5e7f\u64ad\u793e\u533a\u8ba8\u8bba\u5bf9\u8131\u53e3\u79c0\u559c\u5267\u5199\u4f5c\u7684\u5f71\u54cd\u3002\u8ba8\u8bba\u6761\u4ef6\u4e0b\uff0c\u6279\u8bc4\u8005\u548c\u89c2\u4f17\u7684\u8ba8\u8bba\u7ebf\u7a0b\u4f1a\u88ab\u8bb0\u5f55\u3001\u8fc7\u6ee4\u3001\u5b58\u50a8\u4e3a\u793e\u4ea4\u8bb0\u5fc6\uff0c\u540e\u7eed\u521b\u4f5c\u4f1a\u57fa\u4e8e\u8fd9\u4e9b\u8bb0\u5fc6\u8fdb\u884c\u751f\u6210\uff1b\u57fa\u7ebf\u5219\u4e0d\u5305\u542b\u8ba8\u8bba\u8fc7\u7a0b\u3002", "result": "\u572850\u8f6e\uff08250\u5bf9\u72ec\u767d\uff09\u4e2d\uff0c\u7ecf\u8fc75\u540d\u4e13\u5bb6\u8bc4\u5ba1\u7684A/B\u504f\u597d\u548c15\u9879\u8bc4\u5206\u6307\u6807\u663e\u793a\uff0c\u542b\u8ba8\u8bba\u7684\u5199\u4f5c\u7248\u672c\u8d62\u5f9775.6%\u7684\u573a\u5408\uff0c\u4e14\u5728\u4f5c\u54c1\u5de5\u827a/\u6e05\u6670\u5ea6\u548c\u793e\u4f1a\u56de\u5e94\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u5076\u5c14\u51fa\u73b0\u653b\u51fb\u6027\u5e7d\u9ed8\u589e\u52a0\u7684\u73b0\u8c61\u3002", "conclusion": "\u5e7f\u64ad\u793e\u533a\u8ba8\u8bba\u663e\u8457\u63d0\u5347\u8131\u53e3\u79c0\u559c\u5267\u6587\u672c\u7684\u8d28\u91cf\u548c\u793e\u4f1a\u53cd\u54cd\uff0c\u8868\u660e\u5f15\u5165\u591a\u667a\u80fd\u4f53\u7684\u516c\u5171\u8ba8\u8bba\u673a\u5236\u80fd\u591f\u4fc3\u8fdbLLM\u5199\u4f5c\u7684\u8fdb\u6b65\u3002"}}
{"id": "2602.14777", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.14777", "abs": "https://arxiv.org/abs/2602.14777", "authors": ["Laur\u00e8ne Vaugrante", "Anietta Weckauff", "Thilo Hagendorff"], "title": "Emergently Misaligned Language Models Show Behavioral Self-Awareness That Shifts With Subsequent Realignment", "comment": null, "summary": "Recent research has demonstrated that large language models (LLMs) fine-tuned on incorrect trivia question-answer pairs exhibit toxicity - a phenomenon later termed \"emergent misalignment\". Moreover, research has shown that LLMs possess behavioral self-awareness - the ability to describe learned behaviors that were only implicitly demonstrated in training data. Here, we investigate the intersection of these phenomena. We fine-tune GPT-4.1 models sequentially on datasets known to induce and reverse emergent misalignment and evaluate whether the models are self-aware of their behavior transitions without providing in-context examples. Our results show that emergently misaligned models rate themselves as significantly more harmful compared to their base model and realigned counterparts, demonstrating behavioral self-awareness of their own emergent misalignment. Our findings show that behavioral self-awareness tracks actual alignment states of models, indicating that models can be queried for informative signals about their own safety.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0cGPT-4.1\u6a21\u578b\u5728\u7ecf\u5386\u884c\u4e3a\u5931\u8c03\u4e0e\u7ea0\u6b63\u8fc7\u7a0b\u4e2d\u80fd\u591f\u81ea\u6211\u611f\u77e5\u5e76\u63cf\u8ff0\u81ea\u8eab\u7684\u884c\u4e3a\u53d8\u5316\uff0c\u663e\u793a\u5176\u884c\u4e3a\u81ea\u6211\u610f\u8bc6\u4e0e\u5b9e\u9645\u5bf9\u9f50\u72b6\u6001\u76f8\u5173\u3002", "motivation": "\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\u5728\u51fa\u73b0\u201c\u65b0\u5174\u5931\u8c03\u201d\uff08\u5fae\u8c03\u540e\u7684\u6a21\u578b\u8868\u73b0\u51fa\u6bd2\u6027\u884c\u4e3a\uff09\u53ca\u5176\u7ea0\u6b63\u8fc7\u7a0b\u4e2d\u7684\u81ea\u6211\u884c\u4e3a\u610f\u8bc6\uff0c\u5224\u65ad\u6a21\u578b\u662f\u5426\u80fd\u591f\u8bc6\u522b\u548c\u63cf\u8ff0\u81ea\u5df1\u7684\u884c\u4e3a\u53d8\u5316\u3002", "method": "\u5bf9GPT-4.1\u6a21\u578b\u8fdb\u884c\u987a\u5e8f\u5fae\u8c03\uff0c\u4f7f\u7528\u5df2\u77e5\u80fd\u5f15\u53d1\u548c\u9006\u8f6c\u201c\u65b0\u5174\u5931\u8c03\u201d\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5728\u4e0d\u63d0\u4f9b\u4e0a\u4e0b\u6587\u793a\u4f8b\u7684\u60c5\u51b5\u4e0b\u8bc4\u4f30\u6a21\u578b\u5bf9\u81ea\u8eab\u884c\u4e3a\u8f6c\u53d8\u7684\u81ea\u6211\u610f\u8bc6\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u906d\u9047\u65b0\u5174\u5931\u8c03\u7684\u6a21\u578b\u5728\u81ea\u6211\u8bc4\u4ef7\u65f6\u8ba4\u4e3a\u81ea\u8eab\u6709\u66f4\u9ad8\u7684\u6709\u5bb3\u6027\uff0c\u4e14\u76f8\u6bd4\u57fa\u7840\u6a21\u578b\u548c\u5df2\u7ea0\u6b63\u6a21\u578b\u80fd\u6e05\u6670\u53cd\u6620\u884c\u4e3a\u72b6\u6001\uff0c\u8868\u73b0\u51fa\u884c\u4e3a\u81ea\u6211\u610f\u8bc6\u3002", "conclusion": "\u6a21\u578b\u7684\u884c\u4e3a\u81ea\u6211\u610f\u8bc6\u80fd\u591f\u51c6\u786e\u53cd\u6620\u5176\u5bf9\u9f50\u72b6\u6001\uff0c\u8868\u660e\u901a\u8fc7\u8be2\u95ee\u6a21\u578b\u81ea\u8eab\u53ef\u4ee5\u83b7\u5f97\u5173\u4e8e\u6a21\u578b\u5b89\u5168\u6027\u7684\u6709\u7528\u4fe1\u606f\u3002"}}
{"id": "2602.14778", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.14778", "abs": "https://arxiv.org/abs/2602.14778", "authors": ["Emanuele Ricco", "Elia Onofri", "Lorenzo Cima", "Stefano Cresci", "Roberto Di Pietro"], "title": "A Geometric Analysis of Small-sized Language Model Hallucinations", "comment": null, "summary": "Hallucinations -- fluent but factually incorrect responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic settings.\n  This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit tighter clustering in the embedding space, we prove this hypothesis and, leveraging this geometrical insight, we also show that it is possible to achieve a consistent level of separability. This latter result is used to introduce a label-efficient propagation method that classifies large collections of responses from just 30-50 annotations, achieving F1 scores above 90%.\n  Our findings, framing hallucinations from a geometric perspective in the embedding space, complement traditional knowledge-centric and single-response evaluation paradigms, paving the way for further research.", "AI": {"tldr": "\u901a\u8fc7\u51e0\u4f55\u5206\u6790\u8bc1\u660e\u771f\u5b9e\u548c\u5e7b\u89c9\u54cd\u5e94\u5728\u5d4c\u5165\u7a7a\u95f4\u805a\u7c7b\u7279\u70b9\u5dee\u5f02\uff0c\u63d0\u51fa\u6807\u7b7e\u9ad8\u6548\u5206\u7c7b\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u6a2a\u5411\u54cd\u5e94\u5224\u522b\u80fd\u529b\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u6216\u4ee3\u7406\u4efb\u52a1\u4e2d\u751f\u6210\u6d41\u7545\u4f46\u4e8b\u5b9e\u9519\u8bef\u7684\u54cd\u5e94\uff08\u5e7b\u89c9\uff09\u5f71\u54cd\u53ef\u9760\u6027\uff0c\u7814\u7a76\u5176\u751f\u6210\u673a\u5236\u548c\u8bc6\u522b\u65b9\u6cd5\u8feb\u5207\u9700\u8981\u3002", "method": "\u4ece\u51e0\u4f55\u89c6\u89d2\u7814\u7a76LLM\u7684\u5e7b\u89c9\uff0c\u901a\u8fc7\u5206\u6790\u591a\u6b21\u5bf9\u540c\u4e00\u63d0\u793a\u751f\u6210\u7684\u54cd\u5e94\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u805a\u7c7b\u60c5\u51b5\uff0c\u8bc1\u660e\u771f\u5b9e\u54cd\u5e94\u805a\u7c7b\u66f4\u7d27\u5bc6\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u4e00\u79cd\u6807\u7b7e\u9ad8\u6548\u7684\u4f20\u64ad\u65b9\u6cd5\uff0c\u4f7f\u752830-50\u4e2a\u6807\u6ce8\u5b9e\u73b0\u5bf9\u5927\u91cf\u54cd\u5e94\u7684\u5206\u7c7b\u3002", "result": "\u8bc1\u660e\u4e86\u771f\u5b9e\u54cd\u5e94\u5728\u5d4c\u5165\u7a7a\u95f4\u4e2d\u805a\u7c7b\u66f4\u7d27\u5bc6\uff0c\u5c55\u793a\u4e86\u54cd\u5e94\u7684\u53ef\u5206\u79bb\u6027\uff0c\u5e76\u5f00\u53d1\u51fa\u4e00\u79cd\u57fa\u4e8e\u51e0\u4f55\u7279\u5f81\u7684\u4f20\u64ad\u5206\u7c7b\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u8d85\u8fc790%\u7684F1\u5206\u6570\u3002", "conclusion": "\u57fa\u4e8e\u51e0\u4f55\u89c6\u89d2\u7684\u5e7b\u89c9\u5206\u6790\u8865\u5145\u4e86\u4f20\u7edf\u77e5\u8bc6\u9a71\u52a8\u65b9\u6cd5\uff0c\u4e3a\u591a\u54cd\u5e94\u5224\u522b\u548c\u6807\u7b7e\u9ad8\u6548\u5206\u7c7b\u63d0\u4f9b\u65b0\u601d\u8def\uff0c\u52a9\u63a8\u66f4\u53ef\u9760\u7684\u8bed\u8a00\u6a21\u578b\u5e94\u7528\u7814\u7a76\u3002"}}
{"id": "2602.14798", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2602.14798", "abs": "https://arxiv.org/abs/2602.14798", "authors": ["Yohan Lee", "Jisoo Jang", "Seoyeon Choi", "Sangyeop Kim", "Seungtaek Choi"], "title": "Overthinking Loops in Agents: A Structural Risk via MCP Tools", "comment": null, "summary": "Tool-using LLM agents increasingly coordinate real workloads by selecting and chaining third-party tools based on text-visible metadata such as tool names, descriptions, and return messages. We show that this convenience creates a supply-chain attack surface: a malicious MCP tool server can be co-registered alongside normal tools and induce overthinking loops, where individually trivial or plausible tool calls compose into cyclic trajectories that inflate end-to-end tokens and latency without any single step looking abnormal. We formalize this as a structural overthinking attack, distinguishable from token-level verbosity, and implement 14 malicious tools across three servers that trigger repetition, forced refinement, and distraction. Across heterogeneous registries and multiple tool-capable models, the attack causes severe resource amplification (up to $142.4\\times$ tokens) and can degrade task outcomes. Finally, we find that decoding-time concision controls do not reliably prevent loop induction, suggesting defenses should reason about tool-call structure rather than tokens alone.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0\u5e76\u5b9a\u4e49\u4e86\u4e00\u79cd\u901a\u8fc7\u6076\u610f\u5de5\u5177\u5f15\u53d1\u5faa\u73af\u8c03\u7528\u7684\u7ed3\u6784\u6027\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\uff0c\u9020\u6210\u663e\u8457\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u73b0\u6709\u7b80\u6d01\u6027\u63a7\u5236\u63aa\u65bd\u4e0d\u8db3\u4ee5\u9632\u5fa1\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u5de5\u5177\u4f7f\u7528\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLM)\u4ee3\u7406\u901a\u8fc7\u5de5\u5177\u540d\u3001\u63cf\u8ff0\u548c\u8fd4\u56de\u4fe1\u606f\u7b49\u6587\u672c\u53ef\u89c1\u5143\u6570\u636e\u534f\u8c03\u590d\u6742\u4efb\u52a1\uff0c\u8fd9\u79cd\u4fbf\u5229\u6027\u5f15\u5165\u4e86\u4f9b\u5e94\u94fe\u653b\u51fb\u98ce\u9669\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u79cd\u7ed3\u6784\u6027\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\u6a21\u578b\uff0c\u5f00\u53d1\u4e8614\u4e2a\u6076\u610f\u5de5\u5177\u5728\u4e09\u4e2a\u670d\u52a1\u5668\u4e0a\u6a21\u62df\u653b\u51fb\uff0c\u6d4b\u8bd5\u4e86\u591a\u79cd\u6ce8\u518c\u8868\u548c\u5de5\u5177\u80fd\u529b\u6a21\u578b\u4e0b\u7684\u5f71\u54cd\uff0c\u9a8c\u8bc1\u653b\u51fb\u5bf9\u8d44\u6e90\u548c\u4efb\u52a1\u6548\u679c\u7684\u5f71\u54cd\u3002", "result": "\u672c\u6587\u63d0\u51fa\u5e76\u9a8c\u8bc1\u4e86\u7ed3\u6784\u6027\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\uff0c\u5c55\u793a\u6076\u610f\u5de5\u5177\u670d\u52a1\u5668\u901a\u8fc7\u89e6\u53d1\u5faa\u73af\u8c03\u7528\u8f68\u8ff9\uff0c\u4f7f\u5f97\u7cfb\u7edf\u8d44\u6e90\u6d88\u8017\u5927\u5e45\u589e\u52a0\uff08\u6700\u9ad8\u53ef\u8fbe142.4\u500d\uff09\u4e14\u4efb\u52a1\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u9488\u5bf9\u7ed3\u6784\u6027\u8fc7\u5ea6\u601d\u8003\u653b\u51fb\uff0c\u9632\u5fa1\u673a\u5236\u5e94\u805a\u7126\u4e8e\u5206\u6790\u5de5\u5177\u8c03\u7528\u7ed3\u6784\uff0c\u800c\u975e\u5355\u7eaf\u57fa\u4e8etokens\u6765\u9632\u62a4\u3002"}}
{"id": "2602.14812", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14812", "abs": "https://arxiv.org/abs/2602.14812", "authors": ["Jaione Bengoetxea", "Itziar Gonzalez-Dios", "Rodrigo Agerri"], "title": "Physical Commonsense Reasoning for Lower-Resourced Languages and Dialects: a Study on Basque", "comment": null, "summary": "Physical commonsense reasoning represents a fundamental capability of human intelligence, enabling individuals to understand their environment, predict future events, and navigate physical spaces. Recent years have witnessed growing interest in reasoning tasks within Natural Language Processing (NLP). However, no prior research has examined the performance of Large Language Models (LLMs) on non-question-answering (non-QA) physical commonsense reasoning tasks in low-resource languages such as Basque. Taking the Italian GITA as a starting point, this paper addresses this gap by presenting BasPhyCo, the first non-QA physical commonsense reasoning dataset for Basque, available in both standard and dialectal variants. We evaluate model performance across three hierarchical levels of commonsense understanding: (1) distinguishing between plausible and implausible narratives (accuracy), (2) identifying the conflicting element that renders a narrative implausible (consistency), and (3) determining the specific physical state that creates the implausibility (verifiability). These tasks were assessed using multiple multilingual LLMs as well as models pretrained specifically for Italian and Basque. Results indicate that, in terms of verifiability, LLMs exhibit limited physical commonsense capabilities in low-resource languages such as Basque, especially when processing dialectal variants.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u9996\u4e2a\u9488\u5bf9\u5df4\u65af\u514b\u8bed\u7684\u975e\u95ee\u7b54\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6BasPhyCo\uff0c\u8bc4\u4f30\u4e86\u591a\u8bed\u8a00\u548c\u4e13\u95e8\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u5927\u6a21\u578b\u5728\u5904\u7406\u4f4e\u8d44\u6e90\u8bed\u8a00\u7269\u7406\u5e38\u8bc6\u4efb\u52a1\u65f6\u8868\u73b0\u8f83\u5dee\u3002", "motivation": "\u5f53\u524d\u7814\u7a76\u7f3a\u4e4f\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u5982\u5df4\u65af\u514b\u8bed\u4e2d\u975e\u95ee\u7b54\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u80fd\u529b\u7684\u63a2\u7d22\uff0c\u5c24\u5176\u662f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6b64\u7c7b\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5c1a\u672a\u88ab\u7814\u7a76\u3002", "method": "\u57fa\u4e8e\u610f\u5927\u5229GITA\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86\u5df4\u65af\u514b\u8bed\u53ca\u5176\u65b9\u8a00\u7684\u975e\u95ee\u7b54\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u6570\u636e\u96c6BasPhyCo\uff0c\u8bbe\u8ba1\u4e86\u4e09\u5c42\u6b21\u7684\u63a8\u7406\u4efb\u52a1\uff08\u51c6\u786e\u6027\u3001\u4e00\u81f4\u6027\u3001\u53ef\u9a8c\u8bc1\u6027\uff09\u5e76\u4f7f\u7528\u591a\u8bed\u8a00LLM\u53ca\u9488\u5bf9\u610f\u5927\u5229\u8bed\u548c\u5df4\u65af\u514b\u8bed\u7684\u9884\u8bad\u7ec3\u6a21\u578b\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u8bc4\u6d4b\u7ed3\u679c\u8868\u660e\uff0c\u591a\u8bed\u8a00\u5927\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\uff08\u5df4\u65af\u514b\u8bed\u53ca\u5176\u65b9\u8a00\uff09\u7684\u53ef\u9a8c\u8bc1\u6027\u4efb\u52a1\u4e0a\u8868\u73b0\u6709\u9650\uff0c\u4f53\u73b0\u51fa\u7269\u7406\u5e38\u8bc6\u80fd\u529b\u4e0d\u8db3\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u7269\u7406\u5e38\u8bc6\u63a8\u7406\u4efb\u52a1\u4e0a\uff0c\u5c24\u5176\u662f\u5904\u7406\u65b9\u8a00\u65f6\uff0c\u8868\u73b0\u6709\u9650\uff0c\u672a\u6765\u7814\u7a76\u9700\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u80fd\u529b\u3002"}}
{"id": "2602.14819", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14819", "abs": "https://arxiv.org/abs/2602.14819", "authors": ["Matteo Rinaldi", "Rossella Varvara", "Viviana Patti"], "title": "Testimole-Conversational: A 30-Billion-Word Italian Discussion Board Corpus (1996-2024) for Language Modeling and Sociolinguistic Research", "comment": null, "summary": "We present \"Testimole-conversational\" a massive collection of discussion boards messages in the Italian language. The large size of the corpus, more than 30B word-tokens (1996-2024), renders it an ideal dataset for native Italian Large Language Models'pre-training. Furthermore, discussion boards' messages are a relevant resource for linguistic as well as sociological analysis. The corpus captures a rich variety of computer-mediated communication, offering insights into informal written Italian, discourse dynamics, and online social interaction in wide time span. Beyond its relevance for NLP applications such as language modelling, domain adaptation, and conversational analysis, it also support investigations of language variation and social phenomena in digital communication. The resource will be made freely available to the research community.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u8d85\u5927\u89c4\u6a21\u7684\u610f\u5927\u5229\u8bed\u8ba8\u8bba\u7248\u6d88\u606f\u8bed\u6599\u5e93\uff0c\u65e2\u652f\u6301\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\uff0c\u4e5f\u52a9\u529b\u8bed\u8a00\u53ca\u793e\u4f1a\u73b0\u8c61\u7814\u7a76\uff0c\u8d44\u6e90\u514d\u8d39\u5f00\u653e", "motivation": "\u4e3a\u57f9\u517b\u672c\u571f\u610f\u5927\u5229\u8bed\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u7406\u60f3\u7684\u6570\u636e\u96c6\uff0c\u540c\u65f6\u652f\u6301\u8bed\u8a00\u5b66\u548c\u793e\u4f1a\u5b66\u7814\u7a76", "method": "\u6536\u96c6\u5e76\u6574\u7406\u8d85\u8fc730\u4ebf\u610f\u5927\u5229\u8bed\u8ba8\u8bba\u7248\u6d88\u606f\u7ec4\u6210\u7684\u5927\u89c4\u6a21\u8bed\u6599\u5e93\uff0c\u6db5\u76d61996-2024\u5e74\u65f6\u95f4\u8de8\u5ea6", "result": "\u6784\u5efa\u4e86\u6db5\u76d6\u5e7f\u6cdb\u975e\u6b63\u5f0f\u4e66\u9762\u610f\u5927\u5229\u8bed\u3001\u591a\u6837\u5316\u8bdd\u8bed\u52a8\u6001\u53ca\u7ebf\u4e0a\u793e\u4f1a\u4e92\u52a8\u7684\u4e30\u5bcc\u8ba1\u7b97\u673a\u5a92\u4ecb\u4ea4\u6d41\u8bed\u6599\u5e93", "conclusion": "\u8be5\u8bed\u6599\u5e93\u5728\u8bed\u8a00\u5efa\u6a21\u3001\u9886\u57df\u9002\u5e94\u3001\u5bf9\u8bdd\u5206\u6790\u53ca\u6570\u5b57\u4ea4\u6d41\u8bed\u8a00\u53d8\u5f02\u548c\u793e\u4f1a\u73b0\u8c61\u7814\u7a76\u4e2d\u5177\u6709\u91cd\u8981\u4ef7\u503c\uff0c\u5c06\u5bf9\u76f8\u5173\u5b66\u672f\u793e\u533a\u5f00\u653e\u4f7f\u7528"}}
{"id": "2602.14917", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.14917", "abs": "https://arxiv.org/abs/2602.14917", "authors": ["Fiorenzo Parascandolo", "Wenhui Tan", "Enver Sangineto", "Ruihua Song", "Rita Cucchiara"], "title": "BFS-PO: Best-First Search for Large Reasoning Models", "comment": null, "summary": "Large Reasoning Models (LRMs) such as OpenAI o1 and DeepSeek-R1 have shown excellent performance in reasoning tasks using long reasoning chains. However, this has also led to a significant increase of computational costs and the generation of verbose output, a phenomenon known as overthinking. The tendency to overthinking is often exacerbated by Reinforcement Learning (RL) algorithms such as GRPO/DAPO. In this paper, we propose BFS-PO, an RL algorithm which alleviates this problem using a Best-First Search exploration strategy. Specifically, BFS-PO looks for the shortest correct answer using a backtracking mechanism based on maximum entropy nodes. By generating progressively shorter responses during training, BFS-PO learns to produce concise reasoning chains. Using different benchmarks and base LRMs, we show that BFS-PO can simultaneously increase the LRM accuracy and shorten its answers.", "AI": {"tldr": "\u63d0\u51faBFS-PO\u7b97\u6cd5\uff0c\u5229\u7528\u6700\u4f73\u4f18\u5148\u641c\u7d22\u51cf\u5c11\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u5197\u957f\u8f93\u51fa\uff0c\u63d0\u9ad8\u51c6\u786e\u7387\u5e76\u7f29\u77ed\u7b54\u6848\u3002", "motivation": "\u5927\u578b\u63a8\u7406\u6a21\u578b\u867d\u7136\u63a8\u7406\u80fd\u529b\u5f3a\uff0c\u4f46\u751f\u6210\u7684\u957f\u63a8\u7406\u94fe\u5bfc\u81f4\u8ba1\u7b97\u6210\u672c\u9ad8\u548c\u8fc7\u5ea6\u601d\u8003\u73b0\u8c61\uff0c\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u5f80\u5f80\u52a0\u5267\u6b64\u95ee\u9898\uff0c\u9700\u5bfb\u627e\u6709\u6548\u65b9\u6cd5\u51cf\u5c11\u5197\u957f\u8f93\u51fa\u3002", "method": "BFS-PO\u662f\u4e00\u79cd\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u91c7\u7528\u6700\u5927\u71b5\u8282\u70b9\u7684\u56de\u6eaf\u5f0f\u6700\u4f73\u4f18\u5148\u641c\u7d22\u7b56\u7565\uff0c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u9010\u6b65\u751f\u6210\u66f4\u77ed\u7684\u63a8\u7406\u94fe\u4ee5\u5b66\u4e60\u7b80\u6d01\u8f93\u51fa\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aBFS-PO\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u9488\u5bf9\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5728\u63a8\u7406\u4efb\u52a1\u4e2d\u56e0\u957f\u63a8\u7406\u94fe\u800c\u4ea7\u751f\u7684\u8ba1\u7b97\u6210\u672c\u589e\u52a0\u53ca\u5197\u957f\u8f93\u51fa\uff08\u8fc7\u5ea6\u601d\u8003\uff09\u95ee\u9898\u8fdb\u884c\u4e86\u4f18\u5316\u3002BFS-PO\u91c7\u7528\u57fa\u4e8e\u6700\u5927\u71b5\u8282\u70b9\u7684\u56de\u6eaf\u673a\u5236\u548c\u6700\u4f73\u4f18\u5148\u641c\u7d22\u7b56\u7565\uff0c\u5bfb\u627e\u6700\u77ed\u7684\u6b63\u786e\u7b54\u6848\uff0c\u901a\u8fc7\u9010\u6b65\u751f\u6210\u66f4\u77ed\u7684\u63a8\u7406\u94fe\uff0c\u4fc3\u4f7f\u6a21\u578b\u8f93\u51fa\u66f4\u52a0\u7b80\u6d01\u7684\u7b54\u6848\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cBFS-PO\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540c\u57fa\u7840LRMs\u4e0a\uff0c\u65e2\u63d0\u5347\u4e86\u63a8\u7406\u51c6\u786e\u7387\uff0c\u53c8\u7f29\u77ed\u4e86\u56de\u7b54\u957f\u5ea6\u3002", "conclusion": "BFS-PO\u7b97\u6cd5\u6709\u6548\u7f13\u89e3\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u8fc7\u5ea6\u601d\u8003\u7684\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7387\u548c\u56de\u7b54\u7b80\u6d01\u6027\u7684\u53cc\u91cd\u63d0\u5347\u3002"}}
{"id": "2602.14970", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.14970", "abs": "https://arxiv.org/abs/2602.14970", "authors": ["Kawin Mayilvaghanan", "Siddhant Gupta", "Ayush Kumar"], "title": "Counterfactual Fairness Evaluation of LLM-Based Contact Center Agent Quality Assurance System", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed in contact-center Quality Assurance (QA) to automate agent performance evaluation and coaching feedback. While LLMs offer unprecedented scalability and speed, their reliance on web-scale training data raises concerns regarding demographic and behavioral biases that may distort workforce assessment. We present a counterfactual fairness evaluation of LLM-based QA systems across 13 dimensions spanning three categories: Identity, Context, and Behavioral Style. Fairness is quantified using the Counterfactual Flip Rate (CFR), the frequency of binary judgment reversals, and the Mean Absolute Score Difference (MASD), the average shift in coaching or confidence scores across counterfactual pairs. Evaluating 18 LLMs on 3,000 real-world contact center transcripts, we find systematic disparities, with CFR ranging from 5.4% to 13.0% and consistent MASD shifts across confidence, positive, and improvement scores. Larger, more strongly aligned models show lower unfairness, though fairness does not track accuracy. Contextual priming of historical performance induces the most severe degradations (CFR up to 16.4%), while implicit linguistic identity cues remain a persistent bias source. Finally, we analyze the efficacy of fairness-aware prompting, finding that explicit instructions yield only modest improvements in evaluative consistency. Our findings underscore the need for standardized fairness auditing pipelines prior to deploying LLMs in high-stakes workforce evaluation.", "AI": {"tldr": "\u672c\u6587\u8bc4\u4f30\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8054\u7cfb\u4e2d\u5fc3\u8d28\u91cf\u4fdd\u8bc1\u4e2d\u7684\u516c\u5e73\u6027\uff0c\u63ed\u793a\u5b58\u5728\u591a\u7ef4\u5ea6\u7684\u7cfb\u7edf\u6027\u504f\u89c1\uff0c\u5f3a\u8c03\u9700\u8981\u5728\u9ad8\u98ce\u9669\u5e94\u7528\u524d\u5efa\u7acb\u6807\u51c6\u5316\u516c\u5e73\u6027\u5ba1\u8ba1\u6d41\u7a0b\u3002", "motivation": "LLMs\u5728\u8054\u7cfb\u4e2d\u5fc3\u8d28\u91cf\u4fdd\u8bc1\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\u5e26\u6765\u4e86\u6548\u7387\u63d0\u5347\uff0c\u4f46\u5176\u57fa\u4e8e\u5927\u89c4\u6a21\u7f51\u7edc\u8bad\u7ec3\u6570\u636e\uff0c\u53ef\u80fd\u5f15\u5165\u4eba\u53e3\u7edf\u8ba1\u53ca\u884c\u4e3a\u504f\u5dee\uff0c\u5bfc\u81f4\u5458\u5de5\u8bc4\u4f30\u4e0d\u516c\u3002", "method": "\u901a\u8fc7\u53cd\u4e8b\u5b9e\u516c\u5e73\u6027\u8bc4\u4f30\u65b9\u6cd5\uff0c\u5bf918\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u57fa\u4e8e\u5b9e\u65f6\u8054\u7cfb\u4e2d\u5fc3\u76843000\u6761\u5bf9\u8bdd\u8f6c\u5f55\u6587\u672c\uff0c\u572813\u4e2a\u6d89\u53ca\u8eab\u4efd\u3001\u4e0a\u4e0b\u6587\u53ca\u884c\u4e3a\u98ce\u683c\u7684\u7ef4\u5ea6\u4e0a\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002\u4f7f\u7528\u53cd\u4e8b\u5b9e\u7ffb\u8f6c\u7387(CFR)\u548c\u5e73\u5747\u7edd\u5bf9\u5206\u6570\u5dee(MASD)\u6765\u91cf\u5316\u516c\u5e73\u6027\u3002", "result": "\u53d1\u73b0\u7cfb\u7edf\u6027\u516c\u5e73\u6027\u5dee\u5f02\uff0cCFR\u57285.4%\u81f313.0%\u4e4b\u95f4\u6ce2\u52a8\uff0cMASD\u8868\u660e\u4fe1\u5fc3\u3001\u79ef\u6781\u8bc4\u5206\u548c\u6539\u8fdb\u8bc4\u5206\u5747\u6709\u4e00\u81f4\u6027\u504f\u5dee\u3002\u5c3d\u7ba1\u66f4\u5927\u4e14\u8f83\u5f3a\u8c03\u6574\u7684\u6a21\u578b\u8868\u73b0\u51fa\u8f83\u4f4e\u7684\u4e0d\u516c\uff0c\u4f46\u516c\u5e73\u6027\u4e0e\u51c6\u786e\u6027\u65e0\u5173\u3002\u4e0a\u4e0b\u6587\u63d0\u793a\u5386\u53f2\u8868\u73b0\u5f15\u53d1\u6700\u9ad8\u4e0d\u516c\u5e73\uff08CFR\u8fbe16.4%\uff09\uff0c\u4e14\u8bed\u8a00\u8eab\u4efd\u7ebf\u7d22\u4ecd\u662f\u6301\u7eed\u7684\u504f\u89c1\u6765\u6e90\u3002", "conclusion": "LLMs\u5728\u5458\u5de5\u7ee9\u6548\u8bc4\u4f30\u4e2d\u5b58\u5728\u660e\u663e\u516c\u5e73\u6027\u95ee\u9898\uff0c\u7b80\u5355\u7684\u516c\u5e73\u610f\u8bc6\u63d0\u793a\u6539\u5584\u6709\u9650\uff0c\u547c\u5401\u6784\u5efa\u6807\u51c6\u5316\u516c\u5e73\u6027\u5ba1\u8ba1\u7ba1\u7ebf\uff0c\u4ee5\u786e\u4fdd\u90e8\u7f72\u524d\u7684\u516c\u5e73\u6027\u5408\u89c4\u3002"}}
{"id": "2602.15005", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.15005", "abs": "https://arxiv.org/abs/2602.15005", "authors": ["Mengdan Zhu", "Yufan Zhao", "Tao Di", "Yulan Yan", "Liang Zhao"], "title": "Learning User Interests via Reasoning and Distillation for Cross-Domain News Recommendation", "comment": null, "summary": "News recommendation plays a critical role in online news platforms by helping users discover relevant content. Cross-domain news recommendation further requires inferring user's underlying information needs from heterogeneous signals that often extend beyond direct news consumption. A key challenge lies in moving beyond surface-level behaviors to capture deeper, reusable user interests while maintaining scalability in large-scale production systems. In this paper, we present a reinforcement learning framework that trains large language models to generate high-quality lists of interest-driven news search queries from cross-domain user signals. We formulate query-list generation as a policy optimization problem and employ GRPO with multiple reward signals. We systematically study two compute dimensions: inference-time sampling and model capacity, and empirically observe consistent improvements with increased compute that exhibit scaling-like behavior. Finally, we perform on-policy distillation to transfer the learned policy from a large, compute-intensive teacher to a compact student model suitable for scalable deployment. Extensive offline experiments, ablation studies and large-scale online A/B tests in a production news recommendation system demonstrate consistent gains in both interest modeling quality and downstream recommendation performance.", "AI": {"tldr": "\u9488\u5bf9\u8de8\u57df\u65b0\u95fb\u63a8\u8350\u7528\u6237\u5174\u8da3\u5efa\u6a21\u96be\u9898\uff0c\u672c\u6587\u63d0\u51fa\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5174\u8da3\u9a71\u52a8\u67e5\u8be2\u5217\u8868\u7684\u65b0\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u6548\u679c\u5e76\u5b9e\u73b0\u4e86\u9ad8\u6548\u53ef\u6269\u5c55\u90e8\u7f72\u3002", "motivation": "\u4f20\u7edf\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u96be\u4ee5\u6df1\u5165\u6355\u6349\u7528\u6237\u7684\u6df1\u5c42\u5174\u8da3\uff0c\u4e14\u8de8\u57df\u63a8\u8350\u9700\u8981\u6574\u5408\u591a\u6e90\u5f02\u6784\u4fe1\u606f\uff0c\u6311\u6218\u5728\u4e8e\u5982\u4f55\u7a81\u7834\u8868\u5c42\u884c\u4e3a\uff0c\u7cbe\u51c6\u5efa\u6a21\u7528\u6237\u5174\u8da3\uff0c\u540c\u65f6\u4fdd\u8bc1\u5927\u89c4\u6a21\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u8de8\u57df\u7528\u6237\u4fe1\u53f7\u751f\u6210\u5174\u8da3\u9a71\u52a8\u7684\u65b0\u95fb\u641c\u7d22\u67e5\u8be2\u5217\u8868\uff0c\u5c06\u67e5\u8be2\u5217\u8868\u751f\u6210\u89c6\u4e3a\u7b56\u7565\u4f18\u5316\u95ee\u9898\uff0c\u91c7\u7528GRPO\u7b97\u6cd5\u5e76\u7ed3\u5408\u591a\u91cd\u5956\u52b1\u4fe1\u53f7\u3002\u540c\u65f6\u7814\u7a76\u63a8\u7406\u65f6\u95f4\u91c7\u6837\u548c\u6a21\u578b\u5bb9\u91cf\u4e24\u4e2a\u8ba1\u7b97\u7ef4\u5ea6\uff0c\u901a\u8fc7\u5728\u7b56\u7565\u84b8\u998f\u4e2d\u5c06\u5927\u6a21\u578b\u7684\u7b56\u7565\u8fc1\u79fb\u5230\u5c0f\u6a21\u578b\uff0c\u5b9e\u73b0\u53ef\u6269\u5c55\u90e8\u7f72\u3002", "result": "\u901a\u8fc7\u5927\u89c4\u6a21\u79bb\u7ebf\u5b9e\u9a8c\u3001\u6d88\u878d\u7814\u7a76\u53ca\u7ebf\u4e0aA/B\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5174\u8da3\u5efa\u6a21\u8d28\u91cf\u548c\u4e0b\u6e38\u63a8\u8350\u6027\u80fd\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\uff0c\u4e14\u4e0d\u540c\u8ba1\u7b97\u89c4\u6a21\u4e0b\u8868\u73b0\u51fa\u7c7b\u6269\u5c55\u6027\uff0c\u7b56\u7565\u84b8\u998f\u6709\u6548\u5b9e\u73b0\u4e86\u9ad8\u6548\u90e8\u7f72\u3002", "conclusion": "\u672c\u6587\u65b9\u6cd5\u6709\u6548\u6355\u6349\u4e86\u7528\u6237\u6df1\u5c42\u5174\u8da3\uff0c\u901a\u8fc7\u7b56\u7565\u4f18\u5316\u548c\u7b56\u7565\u84b8\u998f\uff0c\u517c\u987e\u6a21\u578b\u6027\u80fd\u4e0e\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\uff0c\u9a8c\u8bc1\u4e86\u63d0\u5347\u65b0\u95fb\u63a8\u8350\u7cfb\u7edf\u51c6\u786e\u7387\u548c\u5b9e\u7528\u6027\u7684\u6f5c\u529b\u3002"}}
{"id": "2602.15012", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15012", "abs": "https://arxiv.org/abs/2602.15012", "authors": ["Avinandan Bose", "Shuyue Stella Li", "Faeze Brahman", "Pang Wei Koh", "Simon Shaolei Du", "Yulia Tsvetkov", "Maryam Fazel", "Lin Xiao", "Asli Celikyilmaz"], "title": "Cold-Start Personalization via Training-Free Priors from Structured World Models", "comment": "24 pages, 4 figures, 4 tables", "summary": "Cold-start personalization requires inferring user preferences through interaction when no user-specific historical data is available. The core challenge is a routing problem: each task admits dozens of preference dimensions, yet individual users care about only a few, and which ones matter depends on who is asking. With a limited question budget, asking without structure will miss the dimensions that matter. Reinforcement learning is the natural formulation, but in multi-turn settings its terminal reward fails to exploit the factored, per-criterion structure of preference data, and in practice learned policies collapse to static question sequences that ignore user responses. We propose decomposing cold-start elicitation into offline structure learning and online Bayesian inference. Pep (Preference Elicitation with Priors) learns a structured world model of preference correlations offline from complete profiles, then performs training-free Bayesian inference online to select informative questions and predict complete preference profiles, including dimensions never asked about. The framework is modular across downstream solvers and requires only simple belief models. Across medical, mathematical, social, and commonsense reasoning, Pep achieves 80.8% alignment between generated responses and users' stated preferences versus 68.5% for RL, with 3-5x fewer interactions. When two users give different answers to the same question, Pep changes its follow-up 39-62% of the time versus 0-28% for RL. It does so with ~10K parameters versus 8B for RL, showing that the bottleneck in cold-start elicitation is the capability to exploit the factored structure of preference data.", "AI": {"tldr": "\u63d0\u51faPep\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u79bb\u7ebf\u5b66\u4e60\u548c\u5728\u7ebf\u8d1d\u53f6\u65af\u63a8\u65ad\u9ad8\u6548\u89e3\u51b3\u51b7\u542f\u52a8\u4e2a\u6027\u5316\u504f\u597d\u83b7\u53d6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u51c6\u786e\u7387\uff0c\u51cf\u5c11\u4ea4\u4e92\u6b21\u6570\uff0c\u4e14\u6a21\u578b\u66f4\u8f7b\u91cf\u3002", "motivation": "\u51b7\u542f\u52a8\u4e2a\u6027\u5316\u4e2d\u65e0\u7528\u6237\u5386\u53f2\u6570\u636e\uff0c\u9700\u5728\u6709\u9650\u63d0\u95ee\u6b21\u6570\u5185\u6709\u6548\u83b7\u53d6\u7528\u6237\u771f\u6b63\u5173\u5fc3\u7684\u504f\u597d\u7ef4\u5ea6\uff0c\u4f20\u7edf\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u7531\u4e8e\u5956\u52b1\u8bbe\u8ba1\u548c\u6a21\u578b\u5bb9\u91cf\u95ee\u9898\u96be\u4ee5\u6709\u6548\u5229\u7528\u504f\u597d\u7ed3\u6784\uff0c\u4e14\u7b56\u7565\u50f5\u5316\u3002", "method": "\u5c06\u51b7\u542f\u52a8\u504f\u597d\u83b7\u53d6\u95ee\u9898\u5206\u89e3\u4e3a\u79bb\u7ebf\u7ed3\u6784\u5b66\u4e60\u548c\u5728\u7ebf\u8d1d\u53f6\u65af\u63a8\u65ad\u3002\u4f7f\u7528Pep\u65b9\u6cd5\uff0c\u79bb\u7ebf\u4ece\u5b8c\u6574\u7528\u6237\u504f\u597d\u6570\u636e\u4e2d\u5b66\u4e60\u504f\u597d\u76f8\u5173\u7684\u7ed3\u6784\u5316\u6a21\u578b\uff0c\u5728\u7ebf\u57fa\u4e8e\u8d1d\u53f6\u65af\u63a8\u65ad\u9009\u62e9\u6709\u4fe1\u606f\u91cf\u7684\u95ee\u9898\u5e76\u9884\u6d4b\u7528\u6237\u5b8c\u6574\u504f\u597d\u3002", "result": "Pep\u65b9\u6cd5\u5728\u533b\u7597\u3001\u6570\u5b66\u3001\u793e\u4ea4\u548c\u5e38\u8bc6\u63a8\u7406\u9886\u57df\u5b9e\u73b080.8%\u7684\u7528\u6237\u504f\u597d\u5bf9\u9f50\u5ea6\uff0c\u4f18\u4e8e\u5f3a\u5316\u5b66\u4e60\u768468.5%\uff0c\u4e14\u4ea4\u4e92\u6b21\u6570\u51cf\u5c113-5\u500d\u3002Pep\u6839\u636e\u7528\u6237\u4e0d\u540c\u56de\u7b54\u8c03\u6574\u540e\u7eed\u95ee\u9898\u7684\u6bd4\u4f8b\u66f4\u9ad8\u4e14\u53c2\u6570\u91cf\u8fdc\u5c0f\u4e8e\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u3002", "conclusion": "Pep\u8bc1\u660e\u4e86\u5728\u51b7\u542f\u52a8\u504f\u597d\u83b7\u53d6\u4e2d\u5229\u7528\u504f\u597d\u56e0\u5b50\u7ed3\u6784\u81f3\u5173\u91cd\u8981\uff0c\u7ed3\u6784\u5316\u6a21\u578b\u7ed3\u5408\u8d1d\u53f6\u65af\u63a8\u65ad\u5177\u6709\u8f83\u597d\u6cdb\u5316\u548c\u54cd\u5e94\u7528\u6237\u7684\u80fd\u529b\uff0c\u4f18\u4e8e\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2602.15013", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15013", "abs": "https://arxiv.org/abs/2602.15013", "authors": ["Ruoxi Liu", "Philipp Koehn"], "title": "Text Style Transfer with Parameter-efficient LLM Finetuning and Round-trip Translation", "comment": "9 pages, 5 figures, 4 tables", "summary": "This paper proposes a novel method for Text Style Transfer (TST) based on parameter-efficient fine-tuning of Large Language Models (LLMs). Addressing the scarcity of parallel corpora that map between styles, the study employs roundtrip translation to synthesize such parallel datasets from monolingual corpora. This approach creates 'neutralized' text devoid of stylistic attributes, essentially creating a shared input style at training-time and inference-time. Experimental results demonstrate consistent superiority of this method over zero-shot prompting and fewshot ICL techniques measured by BLEU scores and style accuracy scores across four investigated domains. Furthermore, the integration of retrieval-augmented generation (RAG) for terminology and name knowledge enhances robustness and stylistic consistency.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u7684\u6587\u672c\u98ce\u683c\u8f6c\u6362\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5faa\u73af\u7ffb\u8bd1\u5408\u6210\u5e73\u884c\u8bed\u6599\uff0c\u89e3\u51b3\u4e86\u98ce\u683c\u8f6c\u6362\u4e2d\u5e73\u884c\u8bed\u6599\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5b9e\u9a8c\u8bc1\u660e\u5176\u5728\u98ce\u683c\u51c6\u786e\u7387\u548cBLEU\u5206\u6570\u4e0a\u4f18\u4e8e\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u65b9\u6cd5\uff0c\u4e14\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u63d0\u9ad8\u4e86\u7a33\u5b9a\u6027\u3002", "motivation": "\u7531\u4e8e\u7f3a\u4e4f\u6620\u5c04\u4e0d\u540c\u98ce\u683c\u95f4\u7684\u5e73\u884c\u8bed\u6599\uff0c\u672c\u6587\u901a\u8fc7\u5408\u6210\u6b64\u7c7b\u8bed\u6599\u89e3\u51b3\u4e86\u6570\u636e\u7a00\u7f3a\u96be\u9898\uff0c\u5e76\u63d0\u5347\u98ce\u683c\u8f6c\u6362\u7684\u51c6\u786e\u6027\u548c\u7a33\u5065\u6027\u3002", "method": "\u4f7f\u7528\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u5faa\u73af\u7ffb\u8bd1\u4ece\u5355\u8bed\u8bed\u6599\u5408\u6210\u4e2d\u6027\u5e73\u884c\u6587\u672c\uff0c\u518d\u8fdb\u884c\u98ce\u683c\u8f6c\u6362\u8bad\u7ec3\uff0c\u8f85\u4ee5\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u63d0\u5347\u672f\u8bed\u4e0e\u77e5\u8bc6\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u6570\u636e\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728BLEU\u5206\u6570\u548c\u98ce\u683c\u51c6\u786e\u7387\u4e0a\u5747\u4f18\u4e8e\u96f6\u6837\u672c\u63d0\u793a\u548c\u5c11\u6837\u672c\u5185\u4e0a\u4e0b\u6587\u5b66\u4e60\u65b9\u6cd5\uff0c\u4e14\u6574\u5408\u68c0\u7d22\u589e\u5f3a\u63d0\u9ad8\u4e86\u672f\u8bed\u4fdd\u6301\u4e0e\u98ce\u683c\u4e00\u81f4\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u56db\u4e2a\u9886\u57df\u4e2d\u98ce\u683c\u8f6c\u6362\u6548\u679c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u96f6\u6837\u672c\u548c\u5c11\u6837\u672c\u6280\u672f\uff0c\u9a8c\u8bc1\u4e86\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u4e0e\u5faa\u73af\u7ffb\u8bd1\u751f\u6210\u5e73\u884c\u8bed\u6599\u7684\u6709\u6548\u6027\u3002"}}
