{"id": "2511.17580", "categories": ["cs.MA", "cs.AI", "cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17580", "abs": "https://arxiv.org/abs/2511.17580", "authors": ["Leszek Sliwko", "Aleksander Zgrzywa"], "title": "A novel strategy for multi-resource load balancing in agent-based systems", "comment": null, "summary": "The paper presents a multi-resource load balancing strategy which can be utilised within an agent-based system. This approach can assist system designers in their attempts to optimise the structure for complex enterprise architectures. In this system, the social behaviour of the agent and its adaptation abilities are applied to determine an optimal setup for a given configuration. All the methods have been developed to allow the agent's self-assessment. The proposed agent system has been implemented and the experiment results are presented here.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u591a\u8d44\u6e90\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u4f18\u5316\u590d\u6742\u4f01\u4e1a\u7cfb\u7edf\u7ed3\u6784\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u3002", "motivation": "\u4e3a\u5e2e\u52a9\u7cfb\u7edf\u8bbe\u8ba1\u8005\u4f18\u5316\u590d\u6742\u4f01\u4e1a\u67b6\u6784\uff0c\u5229\u7528\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u884c\u4e3a\u8bbe\u8ba1\u591a\u8d44\u6e90\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u3002", "method": "\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u793e\u4f1a\u884c\u4e3a\u548c\u81ea\u9002\u5e94\u80fd\u529b\u8bbe\u8ba1\u591a\u8d44\u6e90\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u652f\u6301\u667a\u80fd\u4f53\u81ea\u6211\u8bc4\u4f30\uff0c\u5b9e\u73b0\u7cfb\u7edf\u7ed3\u6784\u4f18\u5316\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u8d44\u6e90\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\uff0c\u57fa\u4e8e\u667a\u80fd\u4f53(agent)\u7cfb\u7edf\uff0c\u901a\u8fc7\u667a\u80fd\u4f53\u7684\u793e\u4f1a\u884c\u4e3a\u548c\u81ea\u9002\u5e94\u80fd\u529b\uff0c\u5b9e\u73b0\u5bf9\u590d\u6742\u4f01\u4e1a\u67b6\u6784\u7684\u7ed3\u6784\u4f18\u5316\u3002\u65b9\u6cd5\u652f\u6301\u667a\u80fd\u4f53\u81ea\u6211\u8bc4\u4f30\u3002\u901a\u8fc7\u5b9e\u65bd\u8be5\u667a\u80fd\u4f53\u7cfb\u7edf\u5e76\u8fdb\u884c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u3002", "conclusion": "\u57fa\u4e8e\u667a\u80fd\u4f53\u7684\u591a\u8d44\u6e90\u8d1f\u8f7d\u5747\u8861\u7b56\u7565\u80fd\u591f\u6709\u6548\u4f18\u5316\u590d\u6742\u4f01\u4e1a\u67b6\u6784\uff0c\u667a\u80fd\u4f53\u81ea\u9002\u5e94\u884c\u4e3a\u4fc3\u8fdb\u7cfb\u7edf\u7684\u6700\u4f73\u914d\u7f6e\u3002"}}
{"id": "2511.17586", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17586", "abs": "https://arxiv.org/abs/2511.17586", "authors": ["Rathin Chandra Shit", "Sharmila Subudhi"], "title": "Hierarchical Adaptive Consensus Network: A Dynamic Framework for Scalable Consensus in Collaborative Multi-Agent AI Systems", "comment": "Submitted to Elsevier", "summary": "The consensus strategies used in collaborative multi-agent systems (MAS) face notable challenges related to adaptability, scalability, and convergence certainties. These approaches, including structured workflows, debate models, and iterative voting, often lead to communication bottlenecks, stringent decision-making processes, and delayed responses in solving complex and evolving tasks. This article introduces a three-tier architecture, the Hierarchical Adaptive Consensus Network (\\hacn), which suggests various consensus policies based on task characterization and agent performance metrics. The first layer collects the confidence-based voting outcomes of several local agent clusters. In contrast, the second level facilitates inter-cluster communication through cross-clustered partial knowledge sharing and dynamic timeouts. The third layer provides system-wide coordination and final arbitration by employing a global orchestration framework with adaptable decision rules. The proposed model achieves $\\bigO(n)$ communication complexity, as opposed to the $\\bigO(n^2)$ complexity of the existing fully connected MAS. Experiments performed in a simulated environment yielded a 99.9\\% reduction in communication overhead during consensus convergence. Furthermore, the proposed approach ensures consensus convergence through hierarchical escalation and dynamic adaptation for a wide variety of complicated tasks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u5206\u5c42\u81ea\u9002\u5e94\u5171\u8bc6\u7f51\u7edc\uff08HACN\uff09\u7684\u4e09\u5c42\u67b6\u6784\uff0c\u4ee5\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5171\u8bc6\u7b56\u7565\u5728\u9002\u5e94\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u6536\u655b\u6027\u65b9\u9762\u7684\u6311\u6218\uff0c\u901a\u8fc7\u5206\u5c42\u6295\u7968\u548c\u5c40\u90e8\u77e5\u8bc6\u5171\u4eab\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u590d\u6742\u5ea6\u548c\u901a\u4fe1\u8d1f\u62c5\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u5171\u8bc6\u7b56\u7565\u9762\u4e34\u901a\u4fe1\u74f6\u9888\u3001\u51b3\u7b56\u8fc7\u7a0b\u4e25\u683c\u548c\u54cd\u5e94\u5ef6\u8fdf\u7b49\u95ee\u9898\uff0c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u52a8\u6001\u4efb\u52a1\uff0c\u4e9f\u9700\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u5171\u8bc6\u673a\u5236\u3002", "method": "HACN\u91c7\u7528\u4e09\u5c42\u67b6\u6784\uff1a\u7b2c\u4e00\u5c42\u6536\u96c6\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u5c40\u90e8\u4ee3\u7406\u7c07\u6295\u7968\u7ed3\u679c\uff0c\u7b2c\u4e8c\u5c42\u901a\u8fc7\u8de8\u7c07\u90e8\u5206\u77e5\u8bc6\u5171\u4eab\u548c\u52a8\u6001\u8d85\u65f6\u673a\u5236\u5b9e\u73b0\u7c07\u95f4\u901a\u4fe1\uff0c\u7b2c\u4e09\u5c42\u901a\u8fc7\u5168\u5c40\u7f16\u6392\u6846\u67b6\u548c\u53ef\u8c03\u6574\u51b3\u7b56\u89c4\u5219\u8fdb\u884c\u7cfb\u7edf\u7ea7\u534f\u8c03\u548c\u6700\u7ec8\u4ef2\u88c1\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aHACN\u5728\u6a21\u62df\u73af\u5883\u4e2d\u5c06\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u4e8699.9%\uff0c\u5b9e\u73b0\u4e86\u4ece$\bigO(n^2)$\u5230$\bigO(n)$\u7684\u901a\u4fe1\u590d\u6742\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u591a\u79cd\u590d\u6742\u4efb\u52a1\u7684\u5171\u8bc6\u6536\u655b\u3002", "conclusion": "\u63d0\u51fa\u7684HACN\u6a21\u578b\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u548c\u52a8\u6001\u9002\u5e94\u673a\u5236\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u901a\u4fe1\u590d\u6742\u5ea6\u7684\u7ebf\u6027\u51cf\u5c11\u548c\u901a\u4fe1\u5f00\u9500\u7684\u6781\u5927\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u5171\u8bc6\u7684\u6536\u655b\u6027\u548c\u7cfb\u7edf\u7684\u534f\u540c\u6548\u7387\u3002"}}
{"id": "2511.17621", "categories": ["cs.MA", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17621", "abs": "https://arxiv.org/abs/2511.17621", "authors": ["Brendan Gho", "Suman Muppavarapu", "Afnan Shaik", "Tyson Tsay", "James Begin", "Kevin Zhu", "Archana Vaidheeswaran", "Vasu Sharma"], "title": "From Competition to Coordination: Market Making as a Scalable Framework for Safe and Aligned Multi-Agent LLM Systems", "comment": null, "summary": "As foundation models are increasingly deployed as interacting agents in multi-agent systems, their collective behavior raises new challenges for trustworthiness, transparency, and accountability. Traditional coordination mechanisms, such as centralized oversight or adversarial adjudication, struggle to scale and often obscure how decisions emerge. We introduce a market-making framework for multi-agent large language model (LLM) coordination that organizes agent interactions as structured economic exchanges. In this setup, each agent acts as a market participant, updating and trading probabilistic beliefs, to converge toward shared, truthful outcomes. By aligning local incentives with collective epistemic goals, the framework promotes self-organizing, verifiable reasoning without requiring external enforcement. Empirically, we evaluate this approach across factual reasoning, ethical judgment, and commonsense inference tasks. Market-based coordination yields accuracy gains of up to 10% over single-shot baselines while preserving interpretability and transparency of intermediate reasoning steps. Beyond these improvements, our findings demonstrate that economic coordination principles can operationalize accountability and robustness in multi-agent LLM systems, offering a scalable pathway toward self-correcting, socially responsible AI capable of maintaining trust and oversight in real world deployment scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5e02\u573a\u673a\u5236\u7684\u591a\u667a\u80fd\u4f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u534f\u8c03\u6846\u67b6\uff0c\u5c06\u667a\u80fd\u4f53\u7684\u4ea4\u4e92\u7ec4\u7ec7\u4e3a\u7ecf\u6d4e\u4ea4\u6613\uff0c\u901a\u8fc7\u6fc0\u52b1\u673a\u5236\u63a8\u52a8\u5171\u4eab\u771f\u5b9e\u7ed3\u679c\uff0c\u63d0\u5347\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u4f5c\u4e3a\u4ea4\u4e92\u4ee3\u7406\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f20\u7edf\u96c6\u4e2d\u5f0f\u6216\u5bf9\u6297\u5f0f\u534f\u8c03\u673a\u5236\u96be\u4ee5\u6269\u5c55\u4e14\u7f3a\u4e4f\u900f\u660e\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u53ef\u89e3\u91ca\u7684\u534f\u8c03\u673a\u5236\u3002", "method": "\u5c06\u591a\u667a\u80fd\u4f53\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u5e02\u573a\u53c2\u4e0e\u8005\uff0c\u901a\u8fc7\u66f4\u65b0\u548c\u4ea4\u6613\u6982\u7387\u4fe1\u5ff5\u8fdb\u884c\u534f\u8c03\uff0c\u4f7f\u5c40\u90e8\u6fc0\u52b1\u4e0e\u96c6\u4f53\u77e5\u8bc6\u76ee\u6807\u4fdd\u6301\u4e00\u81f4\uff0c\u5b9e\u73b0\u81ea\u7ec4\u7ec7\u548c\u53ef\u9a8c\u8bc1\u7684\u63a8\u7406\uff0c\u65e0\u9700\u5916\u90e8\u5f3a\u5236\u3002", "result": "\u5728\u4e8b\u5b9e\u63a8\u7406\u3001\u4f26\u7406\u5224\u65ad\u548c\u5e38\u8bc6\u63a8\u65ad\u4efb\u52a1\u4e2d\uff0c\u57fa\u4e8e\u5e02\u573a\u673a\u5236\u7684\u534f\u8c03\u65b9\u6cd5\u76f8\u8f83\u5355\u6b21\u57fa\u7ebf\u5728\u51c6\u786e\u7387\u4e0a\u63d0\u5347\u4e86\u6700\u591a10%\uff0c\u5e76\u5b9e\u73b0\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u900f\u660e\u548c\u53ef\u89e3\u91ca\uff0c\u52a0\u5f3a\u4e86\u7cfb\u7edf\u7684\u8d23\u4efb\u611f\u548c\u7a33\u5065\u6027\u3002", "conclusion": "\u57fa\u4e8e\u5e02\u573a\u673a\u5236\u7684\u591a\u667a\u80fd\u4f53\u534f\u8c03\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u4e8b\u5b9e\u63a8\u7406\u3001\u4f26\u7406\u5224\u65ad\u548c\u5e38\u8bc6\u63a8\u65ad\u7684\u51c6\u786e\u7387\uff0c\u8fbe\u5230\u4e86\u6bd4\u5355\u6b21\u63a8\u7406\u57fa\u7ebf\u9ad8\u51fa10%\u7684\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u63a8\u7406\u8fc7\u7a0b\u7684\u53ef\u89e3\u91ca\u6027\u548c\u900f\u660e\u5ea6\uff0c\u8bc1\u660e\u4e86\u7ecf\u6d4e\u534f\u8c03\u539f\u5219\u5728\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2511.17625", "categories": ["cs.MA", "cs.GT"], "pdf": "https://arxiv.org/pdf/2511.17625", "abs": "https://arxiv.org/abs/2511.17625", "authors": ["Jaehan Im", "John-Paul Clarke", "Ufuk Topcu", "David Fridovich-Keil"], "title": "Iterative Negotiation and Oversight: A Case Study in Decentralized Air Traffic Management", "comment": null, "summary": "Achieving consensus among noncooperative agents remains challenging in decentralized multi-agent systems, where agents often have conflicting preferences. Existing coordination methods enable agents to reach consensus without a centralized coordinator, but do not provide formal guarantees on system-level objectives such as efficiency or fairness. To address this limitation, we propose an iterative negotiation and oversight framework that augments a decentralized negotiation mechanism with taxation-like oversight. The framework builds upon the trading auction for consensus, enabling noncooperative agents with conflicting preferences to negotiate through asset trading while preserving valuation privacy. We introduce an oversight mechanism, which implements a taxation-like intervention that guides decentralized negotiation toward system-efficient and equitable outcomes while also regulating how fast the framework converges. We establish theoretical guarantees of finite-time termination and derive bounds linking system efficiency and convergence rate to the level of central intervention. A case study based on the collaborative trajectory options program, a rerouting initiative in U.S. air traffic management, demonstrates that the framework can reliably achieve consensus among noncooperative airspace sector managers, and reveals how the level of intervention regulates the relationship between system efficiency and convergence speed. Taken together, the theoretical and experimental results indicate that the proposed framework provides a general mechanism for decentralized coordination in noncooperative multi-agent systems while safeguarding system-level objectives.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u8d44\u4ea7\u4ea4\u6613\u8c08\u5224\u548c\u7a0e\u6536\u5f0f\u76d1\u7ba1\u7684\u5206\u6563\u5f0f\u591a\u667a\u80fd\u4f53\u534f\u8c03\u6846\u67b6\uff0c\u89e3\u51b3\u975e\u5408\u4f5c\u667a\u80fd\u4f53\u95f4\u51b2\u7a81\u504f\u597d\u95ee\u9898\uff0c\u5b9e\u73b0\u7cfb\u7edf\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u4fdd\u8bc1\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u4e0e\u822a\u7a7a\u4ea4\u901a\u7ba1\u7406\u6848\u4f8b\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "motivation": "\u73b0\u6709\u5206\u6563\u5f0f\u534f\u8c03\u65b9\u6cd5\u867d\u80fd\u5b9e\u73b0\u65e0\u4e2d\u5fc3\u534f\u8c03\u7684\u5171\u8bc6\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u5c42\u9762\u6548\u7387\u548c\u516c\u5e73\u6027\u76ee\u6807\u7684\u5f62\u5f0f\u4fdd\u969c\u3002", "method": "\u6784\u5efa\u5728\u5171\u8bc6\u4ea4\u6613\u62cd\u5356\u57fa\u7840\u4e0a\u7684\u5206\u6563\u5f0f\u8d44\u4ea7\u4ea4\u6613\u8c08\u5224\u673a\u5236\uff0c\u5e76\u5f15\u5165\u7c7b\u4f3c\u7a0e\u6536\u7684\u76d1\u7ba1\u5e72\u9884\u673a\u5236\u6765\u5f15\u5bfc\u8c08\u5224\u8fc7\u7a0b\uff0c\u8c03\u63a7\u7cfb\u7edf\u6548\u7387\u4e0e\u6536\u655b\u901f\u5ea6\u7684\u5e73\u8861\u3002", "result": "\u7406\u8bba\u4e0a\u8bc1\u660e\u4e86\u6709\u9650\u65f6\u95f4\u6536\u655b\u6027\u548c\u5e72\u9884\u5f3a\u5ea6\u4e0e\u7cfb\u7edf\u6548\u7387\u3001\u6536\u655b\u901f\u5ea6\u4e4b\u95f4\u7684\u754c\u9650\u5173\u7cfb\uff1b\u5728\u7f8e\u56fd\u7a7a\u4e2d\u4ea4\u901a\u7ba1\u7406\u91cd\u65b0\u8def\u5f84\u89c4\u5212\u7684\u6848\u4f8b\u4e2d\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u53ca\u5e72\u9884\u6c34\u5e73\u5bf9\u6548\u7387\u4e0e\u6536\u655b\u901f\u5ea6\u5173\u7cfb\u7684\u8c03\u8282\u4f5c\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u8fed\u4ee3\u8c08\u5224\u4e0e\u76d1\u7ba1\u6846\u67b6\u901a\u8fc7\u7c7b\u4f3c\u7a0e\u6536\u7684\u5e72\u9884\u673a\u5236\uff0c\u6709\u6548\u4fc3\u8fdb\u4e86\u5206\u6563\u5f0f\u975e\u5408\u4f5c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u8fbe\u6210\u7cfb\u7edf\u6548\u7387\u548c\u516c\u5e73\u6027\u7684\u5171\u8bc6\uff0c\u540c\u65f6\u4fdd\u8bc1\u4e86\u6709\u9650\u65f6\u95f4\u5185\u7684\u6536\u655b\u6027\u3002"}}
{"id": "2511.17559", "categories": ["cs.CL", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.17559", "abs": "https://arxiv.org/abs/2511.17559", "authors": ["Gyubok Lee", "Woosog Chay", "Edward Choi"], "title": "SCARE: A Benchmark for SQL Correction and Question Answerability Classification for Reliable EHR Question Answering", "comment": "ML4H 2025 Proceedings", "summary": "Recent advances in Large Language Models (LLMs) have enabled the development of text-to-SQL models that allow clinicians to query structured data stored in Electronic Health Records (EHRs) using natural language. However, deploying these models for EHR question answering (QA) systems in safety-critical clinical environments remains challenging: incorrect SQL queries-whether caused by model errors or problematic user inputs-can undermine clinical decision-making and jeopardize patient care. While prior work has mainly focused on improving SQL generation accuracy or filtering questions before execution, there is a lack of a unified benchmark for evaluating independent post-hoc verification mechanisms (i.e., a component that inspects and validates the generated SQL before execution), which is crucial for safe deployment. To fill this gap, we introduce SCARE, a benchmark for evaluating methods that function as a post-hoc safety layer in EHR QA systems. SCARE evaluates the joint task of (1) classifying question answerability (i.e., determining whether a question is answerable, ambiguous, or unanswerable) and (2) verifying or correcting candidate SQL queries. The benchmark comprises 4,200 triples of questions, candidate SQL queries, and expected model outputs, grounded in the MIMIC-III, MIMIC-IV, and eICU databases. It covers a diverse set of questions and corresponding candidate SQL queries generated by seven different text-to-SQL models, ensuring a realistic and challenging evaluation. Using SCARE, we benchmark a range of approaches-from two-stage methods to agentic frameworks. Our experiments reveal a critical trade-off between question classification and SQL error correction, highlighting key challenges and outlining directions for future research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86SCARE\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\uff08EHR\uff09\u95ee\u7b54\u7cfb\u7edf\u4e2d\u540e\u9a8c\u5b89\u5168\u68c0\u6d4b\u673a\u5236\u7684\u7edf\u4e00\u57fa\u51c6\u3002", "motivation": "\u5f53\u524d\u6587\u672c\u8f6cSQL\u6a21\u578b\u5728\u4e34\u5e8a\u73af\u5883\u4e0b\u90e8\u7f72\u9762\u4e34\u9519\u8befSQL\u67e5\u8be2\u98ce\u9669\uff0c\u5bfc\u81f4\u4e34\u5e8a\u51b3\u7b56\u9519\u8bef\uff0c\u7f3a\u4e4f\u7edf\u4e00\u7684\u540e\u9a8c\u5b89\u5168\u9a8c\u8bc1\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b4200\u7ec4\u95ee\u9898\u3001\u5019\u9009SQL\u67e5\u8be2\u53ca\u9884\u671f\u8f93\u51fa\u7684\u57fa\u51c6\u96c6\uff0c\u6db5\u76d6\u591a\u79cd\u6570\u636e\u5e93\u548c\u4e03\u79cd\u6587\u672c\u8f6cSQL\u6a21\u578b\uff0c\u5bf9\u5019\u9009SQL\u8fdb\u884c\u5206\u7c7b\u3001\u9a8c\u8bc1\u53ca\u7ea0\u9519\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7SCARE\u57fa\u51c6\u6d4b\u8bd5\u591a\u79cd\u65b9\u6cd5\uff0c\u53d1\u73b0\u95ee\u9898\u53ef\u7b54\u6027\u5206\u7c7b\u4e0eSQL\u9519\u8bef\u7ea0\u6b63\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u6743\u8861\uff0c\u5e76\u6307\u51fa\u73b0\u6709\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86\u95ee\u9898\u53ef\u7b54\u6027\u5206\u7c7b\u4e0eSQL\u9519\u8bef\u4fee\u6b63\u4e4b\u95f4\u7684\u5173\u952e\u6743\u8861\uff0c\u5f3a\u8c03\u4e86\u5b89\u5168\u90e8\u7f72EHR\u95ee\u7b54\u7cfb\u7edf\u65f6\u7684\u6311\u6218\uff0c\u5e76\u4e3a\u672a\u6765\u7814\u7a76\u6307\u660e\u65b9\u5411\u3002"}}
{"id": "2511.17762", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17762", "abs": "https://arxiv.org/abs/2511.17762", "authors": ["Henning Femmer", "Ivan Esau"], "title": "The Software Engineering Simulations Lab: Agentic AI for RE Quality Simulations", "comment": null, "summary": "Context and motivation. Quality in Requirements Engineering (RE) is still predominantly anecdotal and intuition-driven. Creating a solid requirements quality model requires broad sets of empirical evidence to evaluate quality factors and their context. Problem. However, empirical data on the detailed effects of requirements quality defects is scarce, since it is costly to obtain. Furthermore, with the advent of AI-based development, the requirements quality factors may change: Requirements are no longer only consumed by humans, but increasingly also by AI agents, which might lead to a different efficient and effective requirements style. Principal ideas. We propose to extend the RE research toolbox with Agentic AI simulations, in which software engineering (SE) processes are replicated by standardized agents in stochastic, dynamic, event-driven, qualitative simulations. We argue that their speed and simplicity makes them a valuable addition to RE research, although limitations in replicating human behavior need to be studied and understood. Contribution. This paper contributes a first concept, a research roadmap, a prototype, and a first feasibility study for RE simulations with agentic AI. Study results indicate that even a naive implementation leads to executable simulations, encouraging technical improvements along with broader application in RE research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5229\u7528\u5177\u4ee3\u7406\u6027\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u5668\u6765\u6269\u5c55\u9700\u6c42\u5de5\u7a0b\u7684\u8d28\u91cf\u7814\u7a76\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u5b9e\u8bc1\u6570\u636e\u7a00\u7f3a\u548c\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5e76\u5c55\u793a\u4e86\u521d\u6b65\u7684\u53ef\u884c\u6027\u7814\u7a76\u6210\u679c\u3002", "motivation": "\u9700\u6c42\u5de5\u7a0b\u8d28\u91cf\u7814\u7a76\u7f3a\u4e4f\u7cfb\u7edf\u7684\u5b9e\u8bc1\u6570\u636e\uff0c\u4e14\u968f\u7740AI\u4ecb\u5165\u9700\u6c42\u6d88\u8d39\uff0c\u4f20\u7edf\u9700\u6c42\u8d28\u91cf\u56e0\u7d20\u548c\u8bc4\u4f30\u65b9\u6cd5\u9762\u4e34\u6311\u6218\uff0c\u4e9f\u9700\u65b0\u5de5\u5177\u652f\u6301\u66f4\u79d1\u5b66\u7684\u9700\u6c42\u8d28\u91cf\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u5f00\u53d1\u57fa\u4e8e\u4e8b\u4ef6\u9a71\u52a8\u7684\u5b9a\u6027\u6a21\u62df\u5668\uff0c\u5229\u7528\u6807\u51c6\u4ee3\u7406\u5728\u968f\u673a\u52a8\u6001\u73af\u5883\u4e2d\u590d\u5236\u8f6f\u4ef6\u5de5\u7a0b\u6d41\u7a0b\uff0c\u8fdb\u884c\u5feb\u901f\u4e14\u7b80\u5316\u7684\u9700\u6c42\u5de5\u7a0b\u8d28\u91cf\u6a21\u62df\u7814\u7a76\u3002", "result": "\u63d0\u51fa\u4e86\u5177\u4ee3\u7406\u6027AI\u6a21\u62df\u7684\u6982\u5ff5\u6846\u67b6\u3001\u7814\u7a76\u8def\u7ebf\u56fe\u548c\u539f\u578b\u7cfb\u7edf\uff0c\u5e76\u901a\u8fc7\u521d\u6b65\u7684\u53ef\u884c\u6027\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u9700\u6c42\u5de5\u7a0b\u7814\u7a76\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "\u5229\u7528\u5177\u4ee3\u7406\u6027\u7684\u4eba\u5de5\u667a\u80fd\u6a21\u62df\u53ef\u4ee5\u6709\u6548\u5730\u4eff\u771f\u9700\u6c42\u5de5\u7a0b\u8fc7\u7a0b\uff0c\u4fc3\u8fdb\u9700\u6c42\u8d28\u91cf\u6a21\u578b\u7684\u5efa\u7acb\u548c\u8bc4\u4f30\uff0c\u5c24\u5176\u9002\u5e94AI\u9a71\u52a8\u53d1\u5c55\u7684\u65b0\u9700\u6c42\u6d88\u8d39\u65b9\u5f0f\u3002"}}
{"id": "2511.17654", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17654", "abs": "https://arxiv.org/abs/2511.17654", "authors": ["Deepak Bolleddu"], "title": "Dialogue Diplomats: An End-to-End Multi-Agent Reinforcement Learning System for Automated Conflict Resolution and Consensus Building", "comment": null, "summary": "Conflict resolution and consensus building represent critical challenges in multi-agent systems, negotiations, and collaborative decision-making processes. This paper introduces Dialogue Diplomats, a novel end-to-end multi-agent reinforcement learning (MARL) framework designed for automated conflict resolution and consensus building in complex, dynamic environments. The proposed system integrates advanced deep reinforcement learning architectures with dialogue-based negotiation protocols, enabling autonomous agents to engage in sophisticated conflict resolution through iterative communication and strategic adaptation. We present three primary contributions: first, a novel Hierarchical Consensus Network (HCN) architecture that combines attention mechanisms with graph neural networks to model inter-agent dependencies and conflict dynamics. second, a Progressive Negotiation Protocol (PNP) that structures multi-round dialogue interactions with adaptive concession strategies; and third, a Context-Aware Reward Shaping mechanism that balances individual agent objectives with collective consensus goals.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u5c42\u7f51\u7edc\u548c\u6e10\u8fdb\u5f0f\u8c08\u5224\u534f\u8bae\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u51b2\u7a81\u89e3\u51b3\u548c\u5171\u8bc6\u6784\u5efa\u3002", "motivation": "\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u51b2\u7a81\u89e3\u51b3\u548c\u5171\u8bc6\u6784\u5efa\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0c\u9700\u81ea\u52a8\u5316\u4e14\u9ad8\u6548\u7684\u6846\u67b6\u652f\u6301\u590d\u6742\u52a8\u6001\u73af\u5883\u4e0b\u7684\u534f\u4f5c\u51b3\u7b56\u3002", "method": "\u5f15\u5165\u5206\u5c42\u5171\u8bc6\u7f51\u7edc\uff08HCN\uff09\u3001\u6e10\u8fdb\u5f0f\u8c08\u5224\u534f\u8bae\uff08PNP\uff09\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u5956\u52b1\u5851\u9020\u673a\u5236\uff0c\u7ed3\u5408\u591a\u8f6e\u5bf9\u8bdd\u548c\u7b56\u7565\u8c03\u6574\u8fdb\u884c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86Dialogue Diplomats\u6846\u67b6\uff0c\u4e00\u79cd\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u7aef\u5230\u7aef\u7cfb\u7edf\uff0c\u7528\u4e8e\u81ea\u52a8\u5316\u51b2\u7a81\u89e3\u51b3\u548c\u5171\u8bc6\u6784\u5efa\u3002\u8be5\u7cfb\u7edf\u7ed3\u5408\u4e86\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u5bf9\u8bdd\u7684\u8c08\u5224\u534f\u8bae\uff0c\u5b9e\u73b0\u591a\u667a\u80fd\u4f53\u901a\u8fc7\u8fed\u4ee3\u6c9f\u901a\u548c\u7b56\u7565\u8c03\u6574\u8fdb\u884c\u590d\u6742\u52a8\u6001\u73af\u5883\u4e2d\u7684\u51b2\u7a81\u89e3\u51b3\u3002\u4e3b\u8981\u8d21\u732e\u5305\u62ec\uff1a1\uff09\u63d0\u51fa\u4e86\u7ed3\u5408\u6ce8\u610f\u529b\u673a\u5236\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u5206\u5c42\u5171\u8bc6\u7f51\u7edc\uff08HCN\uff09\uff0c\u7528\u4e8e\u5efa\u6a21\u667a\u80fd\u4f53\u95f4\u4f9d\u8d56\u548c\u51b2\u7a81\u52a8\u6001\uff1b2\uff09\u8bbe\u8ba1\u4e86\u6e10\u8fdb\u5f0f\u8c08\u5224\u534f\u8bae\uff08PNP\uff09\uff0c\u652f\u6301\u591a\u8f6e\u5bf9\u8bdd\u4ea4\u4e92\u548c\u81ea\u9002\u5e94\u8ba9\u6b65\u7b56\u7565\uff1b3\uff09\u5f15\u5165\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5956\u52b1\u5851\u9020\u673a\u5236\uff0c\u5e73\u8861\u4e2a\u4f53\u76ee\u6807\u4e0e\u96c6\u4f53\u5171\u8bc6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u7ed3\u5408\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u548c\u5bf9\u8bdd\u673a\u5236\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u51b2\u7a81\u89e3\u51b3\u548c\u5171\u8bc6\u6784\u5efa\u7684\u80fd\u529b\uff0c\u9002\u7528\u4e8e\u590d\u6742\u52a8\u6001\u73af\u5883\u3002"}}
{"id": "2511.17560", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17560", "abs": "https://arxiv.org/abs/2511.17560", "authors": ["Yuechi Zhou", "Yi Su", "Jianxin Zhang", "Juntao Li", "Qingrong Xia", "Zhefeng Wang", "Xinyu Duan", "Baoxing Huai"], "title": "$A^3$: Attention-Aware Accurate KV Cache Fusion for Fast Large Language Model Serving", "comment": null, "summary": "Large language models (LLMs) have demonstrated strong capabilities in processing long contexts, enabling them to tackle tasks involving long textual inputs such as multi-turn conversations, legal documents, or retrieved documents in Retrieval-Augmented Generation (RAG) systems. However, despite their ability to handle long sequences, the resulting decoding latency and memory overhead remain substantial, posing challenges for real-world deployment. Recent advances in KV Cache reuse have shown potential to mitigate these costs, but still suffer from notable performance degradation. To address this issue, we conduct an in-depth investigation of recomputation-based reuse methods and observe that the recomputed tokens often fail to align with the context segments most relevant to the question. This misalignment hinders proper updates to the critical contextual representations. Therefore, we propose the $\\textbf{A}$ttention-$\\textbf{A}$ware $\\textbf{A}$ccurate KV Cache Fusion algorithm ($A^3$), which precomputes and selectively fuses the KV Cache of text chunks based on their relevance to the question, achieving accurate integration with minimal computational overhead. Extensive experiments on various benchmarks and LLMs demonstrate that $A^3$ achieves the best task performance compared to four baselines while reducing the time-to-first-token (TTFT) by 2$\\times$.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5904\u7406\u957f\u6587\u672c\u5e8f\u5217\u65f6\u7684\u89e3\u7801\u5ef6\u8fdf\u548c\u5185\u5b58\u5f00\u9500\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u6ce8\u610f\u529b\u611f\u77e5\u7684\u51c6\u786eKV\u7f13\u5b58\u878d\u5408\u7b97\u6cd5$A^3$\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5177\u5907\u5904\u7406\u957f\u6587\u672c\u7684\u80fd\u529b\uff0c\u4f46\u89e3\u7801\u8fc7\u7a0b\u7684\u5ef6\u65f6\u548c\u5185\u5b58\u5360\u7528\u5927\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u73b0\u6709\u7684KV\u7f13\u5b58\u590d\u7528\u65b9\u6cd5\u6548\u679c\u4e0d\u4f73\uff0c\u5b58\u5728\u91cd\u8981\u4e0a\u4e0b\u6587\u4fe1\u606f\u672a\u80fd\u6b63\u786e\u66f4\u65b0\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa$A^3$\u7b97\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u4e0a\u4e0b\u6587\u4e2d\u4e0e\u95ee\u9898\u6700\u76f8\u5173\u7684\u6587\u672c\u5757\uff0c\u9884\u8ba1\u7b97\u5e76\u7cbe\u51c6\u878d\u5408\u5bf9\u5e94\u7684KV\u7f13\u5b58\uff0c\u907f\u514d\u4e86\u4e0e\u4e0a\u4e0b\u6587\u4e0d\u5339\u914d\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0c$A^3$\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u548c\u4e0d\u540c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u56db\u4e2a\u5bf9\u6bd4\u57fa\u7ebf\uff0c\u4e14\u5c06\u9996\u5b57\u4ee4\u724c\u751f\u6210\u65f6\u95f4\u7f29\u77ed\u4e86\u4e00\u534a\u3002", "conclusion": "$A^3$\u7b97\u6cd5\u901a\u8fc7\u9884\u8ba1\u7b97\u5e76\u9009\u62e9\u6027\u878d\u5408\u4e0e\u95ee\u9898\u76f8\u5173\u7684KV\u7f13\u5b58\uff0c\u6709\u6548\u63d0\u5347\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u751f\u6210\u9996\u5b57\u4ee4\u724c\u65f6\u95f4\u51cf\u5c11\u4e862\u500d\u3002"}}
{"id": "2511.17836", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.17836", "abs": "https://arxiv.org/abs/2511.17836", "authors": ["Edwin Sundberg", "Thea Ekmark", "Workneh Yilma Ayele"], "title": "Validating API Design Requirements for Interoperability: A Static Analysis Approach Using OpenAPI", "comment": "11 pages, 3 tables, 2 figures. Preprint. To appear in: PoEM2025: Companion Proceedings of the 18th IFIP Working Conference on the Practice of Enterprise Modeling: PoEM Forum, Doctoral Consortium, Business Case and Tool Forum, Workshops, December 3-5, 2025, Geneva, Switzerland", "summary": "RESTful APIs are central in developing interoperable, modular, and maintainable software systems in enterprises today. Also, it is essential to support system evolution, service interoperability, and governance across organizational boundaries to ensure good quality and consistency of these APIs. However, evaluating API design quality, which is part of non-functional requirement tasks, remains a largely manual and ad hoc process, particularly during early development. Using a Design Science Research (DSR) methodology, we elicited user needs, identified 75 API design rules using a literature review, and implemented a configurable rule engine to detect structural violations in OpenAPI specifications. The proposed tool supports organizational adaptability by allowing rules to be customized, enabled, or disabled, enabling integration of domain-specific standards. The evaluation was conducted through structured experiments and thematic analysis involving industry experts. API quality validation contributes to aligning technical designs with requirements and enterprise architecture by strengthening interoperability and governance between enterprise systems. The results show that S.E.O.R.A facilitates early validation of non-functional API requirements, provides actionable and traceable feedback, and aligns well with requirements elicitation and quality assurance processes. It improves the API design process by automating checks that would otherwise require manual inspection, thus supporting consistent and reusable conformance practices. This work contributes to requirements engineering by operationalizing design principles as verifiable constraints and embedding them into a practical validation tool. Future directions include IDE integration, expanded rule coverage, and real-world deployment to support continuous compliance in agile API development lifecycles.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u7684API\u8bbe\u8ba1\u89c4\u5219\u68c0\u6d4b\u5de5\u5177S.E.O.R.A\uff0c\u81ea\u52a8\u68c0\u6d4bOpenAPI\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u6027\u8fdd\u89c4\uff0c\u652f\u6301\u89c4\u5219\u5b9a\u5236\uff0c\u63d0\u5347\u975e\u529f\u80fd\u6027API\u9700\u6c42\u7684\u65e9\u671f\u9a8c\u8bc1\u4e0e\u8d28\u91cf\u4fdd\u969c\u3002", "motivation": "RESTful API\u5728\u4f01\u4e1a\u8f6f\u4ef6\u7cfb\u7edf\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46API\u8bbe\u8ba1\u8d28\u91cf\u8bc4\u4f30\u4ecd\u4f9d\u8d56\u624b\u5de5\u548c\u968f\u610f\u8fc7\u7a0b\uff0c\u5c24\u5176\u5728\u65e9\u671f\u5f00\u53d1\u9636\u6bb5\uff0c\u4e9f\u9700\u81ea\u52a8\u5316\u3001\u6807\u51c6\u5316\u7684\u8d28\u91cf\u9a8c\u8bc1\u652f\u6301\u3002", "method": "\u91c7\u7528\u8bbe\u8ba1\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u901a\u8fc7\u6587\u732e\u56de\u987e\u8bc6\u522b75\u6761API\u8bbe\u8ba1\u89c4\u5219\uff0c\u8bbe\u8ba1\u4e86\u53ef\u914d\u7f6e\u89c4\u5219\u5f15\u64ce\u7528\u4e8e\u68c0\u6d4bOpenAPI\u89c4\u8303\u4e2d\u7684\u7ed3\u6784\u6027\u8fdd\u89c4\uff0c\u5e76\u901a\u8fc7\u7ed3\u6784\u5316\u5b9e\u9a8c\u548c\u4e3b\u9898\u5206\u6790\u9a8c\u8bc1\u5de5\u5177\u6548\u679c\u3002", "result": "\u7ed3\u679c\u8868\u660eS.E.O.R.A\u80fd\u591f\u63d0\u4f9b\u53ef\u64cd\u4f5c\u548c\u53ef\u8ffd\u8e2a\u7684\u53cd\u9988\uff0c\u4fc3\u8fdb\u9700\u6c42\u63d0\u53d6\u4e0e\u8d28\u91cf\u4fdd\u8bc1\u6d41\u7a0b\u7684\u7ed3\u5408\uff0c\u63d0\u5347\u8bbe\u8ba1\u8d28\u91cf\u9a8c\u8bc1\u6548\u7387\uff0c\u652f\u6301\u6301\u7eed\u5408\u89c4\u6027\u3002", "conclusion": "S.E.O.R.A\u6709\u6548\u63d0\u5347\u4e86API\u8bbe\u8ba1\u7684\u81ea\u52a8\u5316\u8d28\u91cf\u68c0\u6d4b\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u975e\u529f\u80fd\u6027\u9700\u6c42\u7684\u65e9\u671f\u9a8c\u8bc1\u548c\u4f01\u4e1a\u7ea7\u7cfb\u7edf\u95f4\u7684\u4e92\u64cd\u4f5c\u6027\u4e0e\u6cbb\u7406\u3002"}}
{"id": "2511.17656", "categories": ["cs.MA", "cs.LG", "cs.RO"], "pdf": "https://arxiv.org/pdf/2511.17656", "abs": "https://arxiv.org/abs/2511.17656", "authors": ["KM Khalid Saifullah", "Daniel Palmer"], "title": "Multi-Agent Coordination in Autonomous Vehicle Routing: A Simulation-Based Study of Communication, Memory, and Routing Loops", "comment": null, "summary": "Multi-agent coordination is critical for next-generation autonomous vehicle (AV) systems, yet naive implementations of communication-based rerouting can lead to catastrophic performance degradation. This study investigates a fundamental problem in decentralized multi-agent navigation: routing loops, where vehicles without persistent obstacle memory become trapped in cycles of inefficient path recalculation. Through systematic simulation experiments involving 72 unique configurations across varying vehicle densities (15, 35, 55 vehicles) and obstacle frequencies (6, 20 obstacles), we demonstrate that memory-less reactive rerouting increases average travel time by up to 682% compared to baseline conditions. To address this, we introduce Object Memory Management (OMM), a lightweight mechanism enabling agents to retain and share knowledge of previously encountered obstacles. OMM operates by maintaining a distributed blacklist of blocked nodes, which each agent consults during Dijkstra-based path recalculation, effectively preventing redundant routing attempts. Our results show that OMM-enabled coordination reduces average travel time by 75.7% and wait time by 88% compared to memory-less systems, while requiring only 1.67 route recalculations per vehicle versus 9.83 in memory-less scenarios. This work provides empirical evidence that persistent, shared memory is not merely beneficial but essential for robust multi-agent coordination in dynamic environments. The findings have implications beyond autonomous vehicles, informing the design of decentralized systems in robotics, network routing, and distributed AI. We provide a comprehensive experimental analysis, including detailed scenario breakdowns, scalability assessments, and visual documentation of the routing loop phenomenon, demonstrating OMM's critical role in preventing detrimental feedback cycles in cooperative multi-agent systems.", "AI": {"tldr": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7OMM\u673a\u5236\u901a\u8fc7\u5171\u4eab\u969c\u788d\u7269\u8bb0\u5fc6\uff0c\u663e\u8457\u907f\u514d\u4e86\u591a\u8f66\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\u7684\u8def\u5f84\u5faa\u73af\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u534f\u8c03\u6548\u7387\u548c\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u65e0\u8bb0\u5fc6\u7684\u53cd\u5e94\u5f0f\u8def\u5f84\u91cd\u65b0\u8ba1\u7b97\u5bfc\u81f4\u8f66\u8f86\u9677\u5165\u8def\u7531\u5faa\u73af\uff0c\u4e25\u91cd\u5f71\u54cd\u6548\u7387\uff0c\u5c24\u5176\u5728\u53bb\u4e2d\u5fc3\u5316\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u4e2d\u591a\u8f66\u534f\u8c03\u7684\u91cd\u8981\u6027\u3002", "method": "\u5f15\u5165\u4e86\u5bf9\u8c61\u8bb0\u5fc6\u7ba1\u7406\uff08OMM\uff09\u673a\u5236\uff0c\u5229\u7528\u5206\u5e03\u5f0f\u9ed1\u540d\u5355\u7ef4\u6301\u8f66\u8f86\u5bf9\u5df2\u9047\u963b\u788d\u7684\u8bb0\u5fc6\uff0c\u5e76\u5728\u57fa\u4e8eDijkstra\u7684\u8def\u5f84\u91cd\u65b0\u8ba1\u7b97\u65f6\u9632\u6b62\u91cd\u590d\u8def\u5f84\u5c1d\u8bd5\u3002", "result": "OMM\u673a\u5236\u4f7f\u5e73\u5747\u884c\u9a76\u65f6\u95f4\u51cf\u5c1175.7%\uff0c\u7b49\u5f85\u65f6\u95f4\u51cf\u5c1188%\uff0c\u6bcf\u8f66\u8def\u7ebf\u91cd\u8ba1\u7b97\u6b21\u6570\u4ece9.83\u964d\u81f31.67\uff0c\u663e\u8457\u6539\u5584\u591a\u8f66\u8def\u7531\u6548\u7387\u3002", "conclusion": "\u6301\u4e45\u4e14\u5171\u4eab\u7684\u8bb0\u5fc6\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u7a33\u5065\u534f\u8c03\u81f3\u5173\u91cd\u8981\uff0cOMM\u4e3a\u52a8\u6001\u73af\u5883\u4e2d\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5bfc\u822a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u4e14\u5176\u8bbe\u8ba1\u7406\u5ff5\u53ef\u63a8\u5e7f\u81f3\u673a\u5668\u4eba\u3001\u7f51\u7edc\u8def\u7531\u53ca\u5206\u5e03\u5f0f\u4eba\u5de5\u667a\u80fd\u7cfb\u7edf\u3002"}}
{"id": "2511.17561", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17561", "abs": "https://arxiv.org/abs/2511.17561", "authors": ["Huimin Ren", "Yan Liang", "Baiqiao Su", "Chaobo Sun", "Hengtong Lu", "Kaike Zhang", "Chen Wei"], "title": "LexInstructEval: Lexical Instruction Following Evaluation for Large Language Models", "comment": null, "summary": "The ability of Large Language Models (LLMs) to precisely follow complex and fine-grained lexical instructions is a cornerstone of their utility and controllability. However, evaluating this capability remains a significant challenge. Current methods either rely on subjective and costly human evaluation or on automated LLM-as-a-judge systems, which suffer from inherent biases and unreliability. Existing programmatic benchmarks, while objective, often lack the expressiveness to test intricate, compositional constraints at a granular level. To address these limitations, we introduce LexInstructEval, a new benchmark and evaluation framework for fine-grained lexical instruction following. Our framework is built upon a formal, rule-based grammar that deconstructs complex instructions into a canonical <Procedure, Relation, Value> triplet. This grammar enables the systematic generation of a diverse dataset through a multi-stage, human-in-the-loop pipeline and facilitates objective verification via a transparent, programmatic engine. We release our dataset and open-source evaluation tools to facilitate further research into the controllability and reliability of LLMs.", "AI": {"tldr": "\u63d0\u51faLexInstructEval\uff0c\u4e00\u79cd\u57fa\u4e8e\u5f62\u5f0f\u8bed\u6cd5\u7684\u7ec6\u7c92\u5ea6\u8bcd\u6c47\u6307\u4ee4\u8ddf\u968f\u8bc4\u6d4b\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4ef7\u65b9\u6cd5\u7684\u4e3b\u89c2\u6027\u548c\u8868\u8fbe\u80fd\u529b\u4e0d\u8db3\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u8bc4\u4ef7\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7cbe\u7ec6\u8bcd\u6c47\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u7684\u65b9\u6cd5\u5b58\u5728\u4e3b\u89c2\u6027\u9ad8\u3001\u6210\u672c\u5927\u6216\u8bc4\u5224\u4e0d\u53ef\u9760\u7684\u95ee\u9898\uff0c\u4e14\u7a0b\u5e8f\u5316\u57fa\u51c6\u7f3a\u4e4f\u8868\u8fbe\u590d\u6742\u7ec6\u8282\u7684\u80fd\u529b\u3002", "method": "\u63d0\u51faLexInstructEval\u57fa\u4e8e\u5f62\u5f0f\u5316\u3001\u89c4\u5219\u5316\u7684\u8bed\u6cd5\uff0c\u5c06\u590d\u6742\u6307\u4ee4\u62c6\u89e3\u4e3a<Procedure, Relation, Value>\u4e09\u5143\u7ec4\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u4eba\u673a\u4ea4\u4e92\u751f\u6210\u591a\u6837\u5316\u6570\u636e\u96c6\uff0c\u5e76\u4f7f\u7528\u900f\u660e\u7a0b\u5e8f\u5316\u5f15\u64ce\u8fdb\u884c\u5ba2\u89c2\u9a8c\u8bc1\u3002", "result": "\u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u7ec6\u7c92\u5ea6\u8bcd\u6c47\u6307\u4ee4\u8ddf\u968f\u57fa\u51c6\u6570\u636e\u96c6\u548c\u8bc4\u4ef7\u6846\u67b6\uff0c\u5e76\u5f00\u6e90\u6570\u636e\u548c\u5de5\u5177\u4ee5\u4fc3\u8fdb\u5bf9LLMs\u53ef\u63a7\u6027\u548c\u53ef\u9760\u6027\u7684\u7814\u7a76\u3002", "conclusion": "LexInstructEval\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4ef7\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u63d0\u5347\u4e86\u5bf9LLMs\u7cbe\u7ec6\u8bcd\u6c47\u6307\u4ee4\u6267\u884c\u80fd\u529b\u7684\u5ba2\u89c2\u8bc4\u4ef7\u80fd\u529b\u3002"}}
{"id": "2511.17853", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17853", "abs": "https://arxiv.org/abs/2511.17853", "authors": ["SunMin Moon", "Jangwon Gim", "Chaerin Kim", "Yeeun Kim", "YoungJoo Kim", "Kang Choi"], "title": "A Low-Code Methodology for Developing AI Kiosks: a Case Study with the DIZEST Platform", "comment": "5 pages, 2 figures, conference, 2 tables", "summary": "This paper presents a comprehensive study on enhancing kiosk systems through a low-code architecture, with a focus on AI-based implementations. Modern kiosk systems are confronted with significant challenges, including a lack of integration, structural rigidity, performance bottlenecks, and the absence of collaborative frameworks. To overcome these limitations, we propose a DIZEST-based approach methodology, a specialized low-code platform that enables intuitive workflow design and seamless AI integration. Through a comparative analysis with existing platforms, including Jupyter Notebook, ComfyUI, and Orange3, we demonstrate that DIZEST delivers superior performance across key evaluation criteria. Our photo kiosk case study further validates the effectiveness of this approach in improving interoperability, enhancing user experience, and increasing deployment flexibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4f4e\u4ee3\u7801\u67b6\u6784\u3001\u805a\u7126AI\u5b9e\u73b0\u7684DIZEST\u65b9\u6cd5\uff0c\u7528\u4e8e\u63d0\u5347\u81ea\u52a9\u7ec8\u7aef\u7cfb\u7edf\u7684\u96c6\u6210\u6027\u548c\u6027\u80fd\u3002", "motivation": "\u73b0\u4ee3\u81ea\u52a9\u7ec8\u7aef\u7cfb\u7edf\u9762\u4e34\u96c6\u6210\u4e0d\u8db3\u3001\u7ed3\u6784\u50f5\u5316\u3001\u6027\u80fd\u74f6\u9888\u53ca\u534f\u4f5c\u6846\u67b6\u7f3a\u5931\u7b49\u91cd\u5927\u6311\u6218\uff0c\u4e9f\u9700\u65b0\u65b9\u6cd5\u63d0\u5347\u5176\u7075\u6d3b\u6027\u548c\u6027\u80fd\u3002", "method": "\u91c7\u7528DIZEST\u4f4e\u4ee3\u7801\u5e73\u53f0\u8fdb\u884c\u76f4\u89c2\u7684\u5de5\u4f5c\u6d41\u8bbe\u8ba1\u548cAI\u6574\u5408\uff0c\u7ed3\u5408\u73b0\u6709\u5e73\u53f0\u5982Jupyter Notebook\u3001ComfyUI\u548cOrange3\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793aDIZEST\u5728\u591a\u9879\u5173\u952e\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u8d8a\uff0c\u5b9e\u8bc1\u6848\u4f8b\u8868\u660e\u5176\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u7684\u4e92\u64cd\u4f5c\u6027\u3001\u7528\u6237\u4f53\u9a8c\u548c\u90e8\u7f72\u7075\u6d3b\u6027\u3002", "conclusion": "DIZEST\u5e73\u53f0\u5728\u5173\u952e\u6027\u80fd\u6307\u6807\u4e0a\u4f18\u4e8e\u73b0\u6709\u5e73\u53f0\uff0c\u5b9e\u73b0\u4e86\u81ea\u52a9\u7ec8\u7aef\u7cfb\u7edf\u7684\u66f4\u597d\u4e92\u64cd\u4f5c\u6027\u548c\u66f4\u7075\u6d3b\u7684\u90e8\u7f72\uff0c\u63d0\u5347\u4e86\u7528\u6237\u4f53\u9a8c\u3002"}}
{"id": "2511.17775", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17775", "abs": "https://arxiv.org/abs/2511.17775", "authors": ["Sandro Rama Fiorini", "Leonardo G. Azevedo", "Raphael M. Thiago", "Valesca M. de Sousa", "Anton B. Labate", "Viviane Torres da Silva"], "title": "Episodic Memory in Agentic Frameworks: Suggesting Next Tasks", "comment": null, "summary": "Agentic frameworks powered by Large Language Models (LLMs) can be useful tools in scientific workflows by enabling human-AI co-creation. A key challenge is recommending the next steps during workflow creation without relying solely on LLMs, which risk hallucination and require fine-tuning with scarce proprietary data. We propose an episodic memory architecture that stores and retrieves past workflows to guide agents in suggesting plausible next tasks. By matching current workflows with historical sequences, agents can recommend steps based on prior patterns.", "AI": {"tldr": "\u5f15\u5165\u60c5\u666f\u8bb0\u5fc6\u67b6\u6784\uff0c\u5229\u7528\u5386\u53f2\u5de5\u4f5c\u6d41\u7a0b\u6570\u636e\u8f85\u52a9\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u79d1\u5b66\u5de5\u4f5c\u4e2d\u7684\u4e0b\u4e00\u6b65\u4efb\u52a1\u3002", "motivation": "\u89e3\u51b3\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u521b\u5efa\u4e2d\u53ea\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u4f1a\u4ea7\u751f\u5e7b\u89c9\u4e14\u7f3a\u4e4f\u5927\u91cf\u4e13\u6709\u8bad\u7ec3\u6570\u636e\u7684\u95ee\u9898\uff0c\u63d0\u5347\u63a8\u8350\u4e0b\u4e00\u6b65\u4efb\u52a1\u7684\u53ef\u9760\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u60c5\u666f\u8bb0\u5fc6\u673a\u5236\uff0c\u901a\u8fc7\u5b58\u50a8\u548c\u68c0\u7d22\u5386\u53f2\u5de5\u4f5c\u6d41\u7a0b\uff0c\u5339\u914d\u5f53\u524d\u4efb\u52a1\u5e8f\u5217\uff0c\u8f85\u52a9\u4ee3\u7406\u63a8\u8350\u5408\u7406\u4e0b\u4e00\u6b65\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4ee3\u7406\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u7ed3\u5408\u4e86\u60c5\u666f\u8bb0\u5fc6\u4f53\u7cfb\uff0c\u80fd\u5b58\u50a8\u548c\u68c0\u7d22\u8fc7\u53bb\u7684\u5de5\u4f5c\u6d41\u7a0b\u4ee5\u6307\u5bfc\u4ee3\u7406\u63a8\u8350\u4e0b\u4e00\u6b65\u4efb\u52a1\u3002\u901a\u8fc7\u5339\u914d\u5f53\u524d\u5de5\u4f5c\u6d41\u7a0b\u4e0e\u5386\u53f2\u5e8f\u5217\uff0c\u4ee3\u7406\u80fd\u591f\u57fa\u4e8e\u5df2\u6709\u6a21\u5f0f\u63d0\u51fa\u5408\u7406\u7684\u4e0b\u4e00\u6b65\u5efa\u8bae\uff0c\u51cf\u5c11\u4e86\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u76f2\u76ee\u4f9d\u8d56\u53ca\u5176\u5e7b\u89c9\u98ce\u9669\u3002", "conclusion": "\u7ed3\u5408\u60c5\u666f\u8bb0\u5fc6\u7684\u4ee3\u7406\u67b6\u6784\u80fd\u591f\u63d0\u5347\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u4efb\u52a1\u63a8\u8350\u7684\u51c6\u786e\u6027\u548c\u5408\u7406\u6027\uff0c\u964d\u4f4e\u4ec5\u4f9d\u8d56\u5927\u8bed\u8a00\u6a21\u578b\u5e26\u6765\u7684\u98ce\u9669\u3002"}}
{"id": "2511.17562", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17562", "abs": "https://arxiv.org/abs/2511.17562", "authors": ["Wei Tian", "YuhaoZhou"], "title": "ChineseErrorCorrector3-4B: State-of-the-Art Chinese Spelling and Grammar Corrector", "comment": null, "summary": "This paper introduces ChineseErrorCorrector3-4B, a unified model for Chinese spelling and grammatical error correction based on Qwen3-4B. The model demonstrates outstanding performance in general text correction tasks and achieves state-of-the-art results in both spelling correction (CSC) and grammatical correction (CGC). On several authoritative benchmark datasets -- including SIGHAN-2015, EC-LAW, MCSC, and NaCGEC -- the model's F1 and F0.5 scores significantly surpass existing publicly available models, ranking first in both spelling and grammatical error correction tasks.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eQwen3-4B\u7684\u4e2d\u6587\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7edf\u4e00\u7ea0\u6b63\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u9886\u5148\u6027\u80fd\u3002", "motivation": "\u63d0\u5347\u4e2d\u6587\u6587\u672c\u7ea0\u6b63\u7684\u51c6\u786e\u6027\uff0c\u5b9e\u73b0\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7684\u7edf\u4e00\u7ea0\u6b63\u3002", "method": "\u57fa\u4e8eQwen3-4B\u6784\u5efa\u7edf\u4e00\u7684\u4e2d\u6587\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7ea0\u6b63\u6a21\u578bChineseErrorCorrector3-4B\u3002", "result": "\u6a21\u578b\u5728\u591a\u4e2a\u6743\u5a01\u57fa\u51c6\u6570\u636e\u96c6\uff08\u5982SIGHAN-2015\u3001EC-LAW\u3001MCSC\u3001NaCGEC\uff09\u4e0a\uff0c\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7ea0\u6b63\u4efb\u52a1\u7684F1\u548cF0.5\u6307\u6807\u5747\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u516c\u5f00\u6a21\u578b\uff0c\u6392\u540d\u7b2c\u4e00\u3002", "conclusion": "ChineseErrorCorrector3-4B\u5728\u4e2d\u6587\u62fc\u5199\u548c\u8bed\u6cd5\u9519\u8bef\u7ea0\u6b63\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u8d85\u8d8a\u73b0\u6709\u6a21\u578b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2511.17977", "categories": ["cs.SE", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.17977", "abs": "https://arxiv.org/abs/2511.17977", "authors": ["Kuangxiangzi Liu", "Dhiman Chakraborty", "Alexander Liggesmeyer", "Andreas Zeller"], "title": "Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation", "comment": null, "summary": "Safety- and security-critical systems have to be thoroughly tested against their specifications. The state of practice is to have _natural language_ specifications, from which test cases are derived manually - a process that is slow, error-prone, and difficult to scale. _Formal_ specifications, on the other hand, are well-suited for automated test generation, but are tedious to write and maintain. In this work, we propose a two-stage pipeline that uses large language models (LLMs) to bridge the gap: First, we extract _protocol elements_ from natural-language specifications; second, leveraging a protocol implementation, we synthesize and refine a formal _protocol specification_ from these elements, which we can then use to massively test further implementations.\n  We see this two-stage approach to be superior to end-to-end LLM-based test generation, as 1. it produces an _inspectable specification_ that preserves traceability to the original text; 2. the generation of actual test cases _no longer requires an LLM_; 3. the resulting formal specs are _human-readable_, and can be reviewed, version-controlled, and incrementally refined; and 4. over time, we can build a _corpus_ of natural-language-to-formal-specification mappings that can be used to further train and refine LLMs for more automatic translations.\n  Our prototype, AUTOSPEC, successfully demonstrated the feasibility of our approach on five widely used _internet protocols_ (SMTP, POP3, IMAP, FTP, and ManageSieve) by applying its methods on their _RFC specifications_ written in natural-language, and the recent _I/O grammar_ formalism for protocol specification and fuzzing. In its evaluation, AUTOSPEC recovers on average 92.8% of client and 80.2% of server message types, and achieves 81.5% message acceptance across diverse, real-world systems.", "AI": {"tldr": "\u901a\u8fc7\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u4ece\u81ea\u7136\u8bed\u8a00\u534f\u8bae\u89c4\u8303\u81ea\u52a8\u751f\u6210\u5f62\u5f0f\u5316\u534f\u8bae\u89c4\u8303\uff0c\u663e\u8457\u63d0\u5347\u6d4b\u8bd5\u81ea\u52a8\u5316\u6c34\u5e73\u548c\u89c4\u8303\u53ef\u7ef4\u62a4\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u5b89\u5168\u548c\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u6d4b\u8bd5\u4f9d\u8d56\u4e8e\u624b\u5de5\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u8fc7\u7a0b\u7f13\u6162\u4e14\u6613\u51fa\u9519\uff1b\u5f62\u5f0f\u89c4\u8303\u6613\u4e8e\u81ea\u52a8\u5316\u751f\u6210\u6d4b\u8bd5\uff0c\u4f46\u4e66\u5199\u548c\u7ef4\u62a4\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4e24\u9636\u6bb5\u6d41\u6c34\u7ebf\uff1a\u7b2c\u4e00\u9636\u6bb5\u4ece\u81ea\u7136\u8bed\u8a00\u89c4\u8303\u4e2d\u63d0\u53d6\u534f\u8bae\u5143\u7d20\uff1b\u7b2c\u4e8c\u9636\u6bb5\u5229\u7528\u534f\u8bae\u5b9e\u73b0\uff0c\u4ece\u63d0\u53d6\u7684\u5143\u7d20\u5408\u6210\u548c\u7ec6\u5316\u5f62\u5f0f\u534f\u8bae\u89c4\u8303\u3002", "result": "\u539f\u578bAUTOSPEC\u5728\u4e94\u4e2a\u4e3b\u6d41\u4e92\u8054\u7f51\u534f\u8bae\uff08SMTP\u3001POP3\u3001IMAP\u3001FTP\u548cManageSieve\uff09\u4e0a\u7684\u5b9e\u9a8c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u7684\u53ef\u884c\u6027\uff0c\u5e73\u5747\u6062\u590d92.8%\u7684\u5ba2\u6237\u7aef\u6d88\u606f\u7c7b\u578b\u548c80.2%\u7684\u670d\u52a1\u5668\u6d88\u606f\u7c7b\u578b\uff0c\u6d88\u606f\u63a5\u53d7\u7387\u8fbe81.5%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4f18\u4e8e\u7aef\u5230\u7aefLLM\u6d4b\u8bd5\u751f\u6210\uff0c\u751f\u6210\u53ef\u68c0\u67e5\u3001\u53ef\u8ffd\u6eaf\u3001\u53ef\u8bfb\u4e14\u6613\u7ef4\u62a4\u7684\u89c4\u8303\uff0c\u4e3a\u81ea\u52a8\u7ffb\u8bd1\u548c\u6d4b\u8bd5\u81ea\u52a8\u5316\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.17915", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17915", "abs": "https://arxiv.org/abs/2511.17915", "authors": ["Yao Liu", "Sampad Mohanty", "Elizabeth Ondula", "Bhaskar Krishnamachari"], "title": "DISPATCH -- Decentralized Informed Spatial Planning and Assignment of Tasks for Cooperative Heterogeneous Agents", "comment": null, "summary": "Spatial task allocation in systems such as multi-robot delivery or ride-sharing requires balancing efficiency with fair service across tasks. Greedy assignment policies that match each agent to its highest-preference or lowest-cost task can maximize efficiency but often create inequities: some tasks receive disproportionately favorable service (e.g., shorter delays or better matches), while others face long waits or poor allocations.\n  We study fairness in heterogeneous multi-agent systems where tasks vary in preference alignment and urgency. Most existing approaches either assume centralized coordination or largely ignore fairness under partial observability. Distinct from this prior work, we establish a connection between the Eisenberg-Gale (EG) equilibrium convex program and decentralized, partially observable multi-agent learning. Building on this connection, we develop two equilibrium-informed algorithms that integrate fairness and efficiency: (i) a multi-agent reinforcement learning (MARL) framework, EG-MARL, whose training is guided by centralized fair assignment algorithms (EG and a preference-aware Hungarian method); and (ii) a stochastic online optimization mechanism that performs guided exploration and subset-based fair assignment as tasks are discovered.\n  We evaluate our frameworks across a range of team sizes and assignment formulations against centralized EG, Hungarian, and Min-Max Distance baselines. Both algorithms preserve the fairness-efficiency balance of the Eisenberg-Gale equilibrium under partial observability. EG-MARL achieves near-centralized coordination and reduced travel distances, while the stochastic online mechanism enables real-time allocation with competitive fairness. Together, these results demonstrate that spatially aware EG formulations can effectively guide decentralized coordination in agents with heterogeneous capabilities.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8eEisenberg-Gale\u5747\u8861\u7684\u53bb\u4e2d\u5fc3\u5316\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u7a7a\u95f4\u4efb\u52a1\u5206\u914d\u4e2d\u7684\u516c\u5e73\u4e0e\u6548\u7387\u517c\u987e\uff0c\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e0b\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u591a\u673a\u5668\u4eba\u914d\u9001\u6216\u7f51\u7ea6\u8f66\u7b49\u7a7a\u95f4\u4efb\u52a1\u5206\u914d\u7cfb\u7edf\u9700\u8981\u5728\u6548\u7387\u548c\u516c\u5e73\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u8d2a\u5fc3\u5206\u914d\u7b56\u7565\u867d\u80fd\u6700\u5927\u5316\u6548\u7387\uff0c\u4f46\u4f1a\u4ea7\u751f\u4e0d\u516c\u5e73\u73b0\u8c61\uff0c\u5bfc\u81f4\u90e8\u5206\u4efb\u52a1\u83b7\u5f97\u8f83\u4f18\u670d\u52a1\u800c\u5176\u4ed6\u4efb\u52a1\u7b49\u5f85\u65f6\u95f4\u957f\u6216\u5206\u914d\u4e0d\u4f73\u3002\u5df2\u6709\u65b9\u6cd5\u591a\u4f9d\u8d56\u4e2d\u5fc3\u5316\u534f\u8c03\u6216\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u73af\u5883\u4e2d\u5ffd\u7565\u516c\u5e73\u6027\u3002", "method": "\u63d0\u51fa\u4e24\u4e2a\u7b97\u6cd5\u6846\u67b6\uff1a\u4e00\u662fEG-MARL\uff0c\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u7531\u4e2d\u5fc3\u5316\u516c\u5e73\u5206\u914d\u7b97\u6cd5\uff08EG\u548c\u504f\u597d\u611f\u77e5\u5308\u7259\u5229\u7b97\u6cd5\uff09\u5f15\u5bfc\uff1b\u4e8c\u662f\u968f\u673a\u5728\u7ebf\u4f18\u5316\u673a\u5236\uff0c\u7ed3\u5408\u6307\u5bfc\u63a2\u7d22\u548c\u57fa\u4e8e\u5b50\u96c6\u7684\u516c\u5e73\u5206\u914d\uff0c\u9002\u5408\u4efb\u52a1\u52a8\u6001\u53d1\u73b0\u573a\u666f\u3002\u4e24\u8005\u5747\u5728\u591a\u79cd\u5b9e\u9a8c\u8bbe\u7f6e\u4e2d\u9a8c\u8bc1\u6027\u80fd\u3002", "result": "\u672c\u6587\u5efa\u7acb\u4e86Eisenberg-Gale (EG)\u5747\u8861\u51f8\u89c4\u5212\u4e0e\u53bb\u4e2d\u5fc3\u5316\u3001\u90e8\u5206\u53ef\u89c2\u6d4b\u591a\u667a\u80fd\u4f53\u5b66\u4e60\u7684\u8054\u7cfb\uff0c\u63d0\u51fa\u4e86\u4e24\u79cd\u7ed3\u5408\u516c\u5e73\u6027\u4e0e\u6548\u7387\u7684\u7b97\u6cd5\uff1a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08EG-MARL\uff09\u548c\u968f\u673a\u5728\u7ebf\u4f18\u5316\u673a\u5236\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u4e24\u79cd\u7b97\u6cd5\u5728\u90e8\u5206\u53ef\u89c2\u6d4b\u6761\u4ef6\u4e0b\u6709\u6548\u7ef4\u6301EG\u5747\u8861\u7684\u516c\u5e73-\u6548\u7387\u5e73\u8861\uff0cEG-MARL\u63a5\u8fd1\u4e2d\u5fc3\u5316\u534f\u8c03\u4e14\u51cf\u5c11\u884c\u7a0b\u8ddd\u79bb\uff0c\u968f\u673a\u5728\u7ebf\u673a\u5236\u5b9e\u73b0\u5b9e\u65f6\u5206\u914d\u4e14\u516c\u5e73\u6027\u7ade\u4e89\u529b\u5f3a\u3002", "conclusion": "\u7a7a\u95f4\u611f\u77e5\u7684EG\u5747\u8861\u6a21\u578b\u80fd\u591f\u6709\u6548\u6307\u5bfc\u5177\u5f02\u8d28\u80fd\u529b\u667a\u80fd\u4f53\u7684\u53bb\u4e2d\u5fc3\u5316\u4efb\u52a1\u534f\u8c03\uff0c\u5b9e\u73b0\u516c\u5e73\u6027\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u56e2\u961f\u89c4\u6a21\u548c\u4efb\u52a1\u5206\u914d\u60c5\u666f\u3002"}}
{"id": "2511.17565", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17565", "abs": "https://arxiv.org/abs/2511.17565", "authors": ["Sarthak Chakraborty", "Suman Nath", "Xuchao Zhang", "Chetan Bansal", "Indranil Gupta"], "title": "Generative Caching for Structurally Similar Prompts and Responses", "comment": null, "summary": "Large Language Models (LLMs) are increasingly being used to plan, reason, and execute tasks across diverse scenarios. In use cases like repeatable workflows and agentic settings, prompts are often reused with minor variations while having a similar structure for recurring tasks. This opens up opportunities for caching. However, exact prompt matching fails on such structurally similar prompts, while semantic caching may produce incorrect responses by ignoring critical differences. To address this, we introduce \\ourmethod{}, a generative cache that produces variation-aware responses for structurally similar prompts. \\ourmethod{} identifies reusable response patterns across similar prompt structures and synthesizes customized outputs for new requests. We show that \\ourmethod{} achieves 83\\% cache hit rate, while having minimal incorrect hits on datasets without prompt repetition. In agentic workflows, it improves cache hit rate by $\\sim$20\\% and reduces end-to-end execution latency by $\\sim$34\\% compared to standard prompt matching.", "AI": {"tldr": "\u9488\u5bf9\u7ed3\u6784\u76f8\u4f3c\u63d0\u793a\u7684\u7f13\u5b58\u96be\u9898\uff0c\\ourmethod{}\u901a\u8fc7\u751f\u6210\u5f0f\u65b9\u5f0f\u63d0\u5347\u7f13\u5b58\u547d\u4e2d\u7387\u548c\u54cd\u5e94\u51c6\u786e\u6027\uff0c\u6709\u6548\u52a0\u901f\u4efb\u52a1\u6267\u884c\u3002", "motivation": "\u9891\u7e41\u590d\u7528\u7ed3\u6784\u76f8\u4f3c\u4f46\u5b58\u5728\u7ec6\u5fae\u5dee\u522b\u7684\u63d0\u793a\uff0c\u5728\u6807\u51c6\u7cbe\u786e\u5339\u914d\u5931\u8d25\u4e14\u8bed\u4e49\u7f13\u5b58\u53ef\u80fd\u5ffd\u7565\u5173\u952e\u5dee\u5f02\u4ea7\u751f\u9519\u8bef\u54cd\u5e94\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u4f55\u6709\u6548\u7f13\u5b58\u5e76\u63d0\u5347\u54cd\u5e94\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u751f\u6210\u5f0f\u7f13\u5b58\u65b9\u6cd5\\ourmethod{}\uff0c\u5b83\u901a\u8fc7\u8bc6\u522b\u7ed3\u6784\u76f8\u4f3c\u63d0\u793a\u4e2d\u7684\u53ef\u590d\u7528\u54cd\u5e94\u6a21\u5f0f\uff0c\u5408\u6210\u5b9a\u5236\u5316\u8f93\u51fa\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7cbe\u786e\u5339\u914d\u548c\u8bed\u4e49\u7f13\u5b58\u9762\u4e34\u7684\u6311\u6218\u3002", "result": "\\ourmethod{}\u5b9e\u73b0\u4e8683%\u7684\u7f13\u5b58\u547d\u4e2d\u7387\uff0c\u5728\u65e0\u63d0\u793a\u91cd\u590d\u7684\u6570\u636e\u96c6\u4e0a\u9519\u8bef\u547d\u4e2d\u6781\u5c11\uff1b\u5728\u667a\u80fd\u4ee3\u7406\u5de5\u4f5c\u6d41\u4e2d\uff0c\u547d\u4e2d\u7387\u63d0\u5347\u7ea620%\uff0c\u7aef\u5230\u7aef\u6267\u884c\u65f6\u5ef6\u51cf\u5c11\u7ea634%\u3002", "conclusion": "\\ourmethod{}\u6709\u6548\u89e3\u51b3\u4e86\u7ed3\u6784\u76f8\u4f3c\u63d0\u793a\u7f13\u5b58\u7684\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u7f13\u5b58\u6548\u7387\u548c\u54cd\u5e94\u8d28\u91cf\uff0c\u51cf\u5c11\u4e86\u4efb\u52a1\u6267\u884c\u5ef6\u8fdf\u3002\u9002\u7528\u4e8e\u9891\u7e41\u590d\u7528\u63d0\u793a\u7684\u591a\u573a\u666f\u5927\u8bed\u8a00\u6a21\u578b\u4efb\u52a1\u3002"}}
{"id": "2511.18001", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18001", "abs": "https://arxiv.org/abs/2511.18001", "authors": ["Jiaolong Kong", "Xiaofei Xie", "Yiheng Xiong", "Yuekun Wang", "Jian Wang"], "title": "Enhancing Automated Program Repair via Faulty Token Localization and Quality-Aware Patch Refinement", "comment": null, "summary": "Large language models (LLMs) have recently demonstrated strong potential for automated program repair (APR). However, existing LLM-based techniques primarily rely on coarse-grained external feedback (e.g.,test results) to guide iterative patch generation, while lacking fine-grained internal signals that reveal why a patch fails or which parts of the generated code are likely incorrect. This limitation often leads to inefficient refinement, error propagation, and suboptimal repair performance. In this work, we propose TokenRepair, a novel two-level refinement framework that enhances APR by integrating internal reflection for localizing potentially faulty tokens with external feedback for quality-aware patch refinement. Specifically, TokenRepair first performs internal reflection by analyzing context-aware token-level uncertainty fluctuations to identify suspicious or low-confidence tokens within a patch. It then applies Chain-of-Thought guided rewriting to refine only these localized tokens, enabling targeted and fine-grained correction. To further stabilize the iterative repair loop, TokenRepair incorporates a quality-aware external feedback mechanism that evaluates patch quality and filters out low-quality candidates before refinement. Experimental results show that TokenRepair achieves new state-of-the-art repair performance, correctly fixing 88 bugs on Defects4J 1.2 and 139 bugs on HumanEval-Java, demonstrating substantial improvements ranging from 8.2% to 34.9% across all models on Defects4J 1.2 and from 3.3% to 16.1% on HumanEval-Java.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86TokenRepair\uff0c\u4e00\u79cd\u7ed3\u5408\u5185\u90e8\u4ee4\u724c\u4e0d\u786e\u5b9a\u6027\u53cd\u601d\u4e0e\u5916\u90e8\u8d28\u91cf\u53cd\u9988\u7684\u4e24\u7ea7\u7ec6\u5316\u6846\u67b6\uff0c\u6709\u9488\u5bf9\u6027\u5730\u6539\u8fdb\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fee\u590d\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u81ea\u52a8\u5316\u7a0b\u5e8f\u4fee\u590d(APR)\u4e2d\u4e3b\u8981\u4f9d\u8d56\u7c97\u7c92\u5ea6\u5916\u90e8\u53cd\u9988\uff08\u5982\u6d4b\u8bd5\u7ed3\u679c\uff09\u6765\u6307\u5bfc\u8865\u4e01\u751f\u6210\uff0c\u7f3a\u4e4f\u7ec6\u7c92\u5ea6\u7684\u5185\u90e8\u4fe1\u53f7\u6765\u6307\u51fa\u8865\u4e01\u5931\u8d25\u7684\u539f\u56e0\u6216\u4ee3\u7801\u4e2d\u53ef\u80fd\u9519\u8bef\u7684\u90e8\u5206\uff0c\u5bfc\u81f4\u4fee\u590d\u6548\u7387\u4f4e\u4e0b\u548c\u9519\u8bef\u4f20\u64ad\u3002", "method": "\u63d0\u51fa\u4e86TokenRepair\uff0c\u4e24\u7ea7\u7ec6\u5316\u6846\u67b6\uff0c\u7ed3\u5408\u5185\u90e8\u53cd\u601d\u4ee5\u5b9a\u4f4d\u53ef\u7591\u6216\u4f4e\u7f6e\u4fe1\u5ea6\u7684\u4ee4\u724c\u548c\u5916\u90e8\u53cd\u9988\u8fdb\u884c\u8d28\u91cf\u611f\u77e5\u7684\u8865\u4e01\u7ec6\u5316\u3002\u9996\u5148\u901a\u8fc7\u5206\u6790\u4e0a\u4e0b\u6587\u4e2d\u7684\u4ee4\u724c\u4e0d\u786e\u5b9a\u6027\u6ce2\u52a8\u8fdb\u884c\u5185\u90e8\u53cd\u601d\uff0c\u5b9a\u4f4d\u9519\u8bef\u4ee4\u724c\uff1b\u7136\u540e\u5229\u7528\u601d\u7ef4\u94fe\u5f15\u5bfc\u7684\u91cd\u5199\u6280\u672f\uff0c\u4ec5\u5bf9\u8fd9\u4e9b\u4ee4\u724c\u8fdb\u884c\u5b9a\u5411\u7ec6\u5316\u3002\u540c\u65f6\u5f15\u5165\u8d28\u91cf\u611f\u77e5\u7684\u5916\u90e8\u53cd\u9988\u673a\u5236\u8bc4\u4f30\u8865\u4e01\u8d28\u91cf\uff0c\u8fc7\u6ee4\u4f4e\u8d28\u91cf\u8865\u4e01\uff0c\u7a33\u5b9a\u8fed\u4ee3\u4fee\u590d\u8fc7\u7a0b\u3002", "result": "\u5728Defects4J 1.2\u4e0a\u4fee\u590d\u4e8688\u4e2a\u9519\u8bef\uff0c\u5728HumanEval-Java\u4e0a\u4fee\u590d\u4e86139\u4e2a\u9519\u8bef\uff0c\u6027\u80fd\u8f83\u524d\u6cbf\u65b9\u6cd5\u63d0\u5347\u4e868.2%\u81f334.9%\uff08Defects4J 1.2\uff09\u548c3.3%\u81f316.1%\uff08HumanEval-Java\uff09\u3002", "conclusion": "TokenRepair\u901a\u8fc7\u7ed3\u5408\u7ec6\u7c92\u5ea6\u5185\u90e8\u4fe1\u53f7\u4e0e\u8d28\u91cf\u611f\u77e5\u7684\u5916\u90e8\u53cd\u9988\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u7a0b\u5e8f\u4fee\u590d\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u8fbe\u5230\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u6027\u80fd\u6c34\u5e73\u3002"}}
{"id": "2511.18258", "categories": ["cs.MA", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18258", "abs": "https://arxiv.org/abs/2511.18258", "authors": ["Mojtaba A. Farahani", "Md Irfan Khan", "Thorsten Wuest"], "title": "Hybrid Agentic AI and Multi-Agent Systems in Smart Manufacturing", "comment": null, "summary": "The convergence of Agentic AI and MAS enables a new paradigm for intelligent decision making in SMS. Traditional MAS architectures emphasize distributed coordination and specialized autonomy, while recent advances in agentic AI driven by LLMs introduce higher order reasoning, planning, and tool orchestration capabilities. This paper presents a hybrid agentic AI and multi agent framework for a Prescriptive Maintenance use case, where LLM based agents provide strategic orchestration and adaptive reasoning, complemented by rule based and SLMs agents performing efficient, domain specific tasks on the edge. The proposed framework adopts a layered architecture that consists of perception, preprocessing, analytics, and optimization layers, coordinated through an LLM Planner Agent that manages workflow decisions and context retention. Specialized agents autonomously handle schema discovery, intelligent feature analysis, model selection, and prescriptive optimization, while a HITL interface ensures transparency and auditability of generated maintenance recommendations. This hybrid design supports dynamic model adaptation, cost efficient maintenance scheduling, and interpretable decision making. An initial proof of concept implementation is validated on two industrial manufacturing datasets. The developed framework is modular and extensible, supporting seamless integration of new agents or domain modules as capabilities evolve. The results demonstrate the system capability to automatically detect schema, adapt preprocessing pipelines, optimize model performance through adaptive intelligence, and generate actionable, prioritized maintenance recommendations. The framework shows promise in achieving improved robustness, scalability, and explainability for RxM in smart manufacturing, bridging the gap between high level agentic reasoning and low level autonomous execution.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684Agentic AI\u548c\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u6df7\u5408\u67b6\u6784\uff0c\u7528\u4e8e\u667a\u80fd\u5236\u9020\u4e2d\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\uff0c\u5b9e\u73b0\u4ece\u9ad8\u5c42\u6218\u7565\u89c4\u5212\u5230\u5e95\u5c42\u81ea\u6cbb\u6267\u884c\u7684\u65e0\u7f1d\u534f\u540c\u3002", "motivation": "\u4f20\u7edf\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4fa7\u91cd\u5206\u5e03\u5f0f\u534f\u8c03\u548c\u4e13\u6709\u81ea\u6cbb\uff0c\u96be\u4ee5\u5b9e\u73b0\u9ad8\u7ea7\u63a8\u7406\u548c\u89c4\u5212\uff0c\u7ed3\u5408\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684Agentic AI\u53ef\u63d0\u5347\u667a\u80fd\u51b3\u7b56\u6c34\u5e73\uff0c\u89e3\u51b3\u667a\u80fd\u5236\u9020\u9884\u6d4b\u6027\u7ef4\u62a4\u4e2d\u7684\u590d\u6742\u4efb\u52a1\u8c03\u5ea6\u548c\u4f18\u5316\u95ee\u9898\u3002", "method": "\u8bbe\u8ba1\u5206\u5c42\u67b6\u6784\uff08\u611f\u77e5\u3001\u9884\u5904\u7406\u3001\u5206\u6790\u548c\u4f18\u5316\u5c42\uff09\uff0c\u7531LLM\u89c4\u5212\u4ee3\u7406\u534f\u8c03\u5404\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u7a0b\uff1b\u4f7f\u7528\u57fa\u4e8e\u89c4\u5219\u548c\u5c0f\u8bed\u8a00\u6a21\u578b\u7684\u7279\u5316\u667a\u80fd\u4f53\u8d1f\u8d23\u5177\u4f53\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u8bc1\u900f\u660e\u548c\u53ef\u5ba1\u8ba1\u7684\u4eba\u673a\u4ea4\u4e92\u63a5\u53e3\u3002", "result": "\u7cfb\u7edf\u6210\u529f\u81ea\u52a8\u8bc6\u522b\u6570\u636e\u6a21\u5f0f\u3001\u52a8\u6001\u8c03\u6574\u9884\u5904\u7406\u6d41\u7a0b\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u667a\u80fd\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u8f93\u51fa\u4f18\u5148\u7ea7\u7ef4\u62a4\u5efa\u8bae\uff0c\u5728\u4e24\u4e2a\u5de5\u4e1a\u5236\u9020\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u548c\u6269\u5c55\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u80fd\u591f\u5b9e\u73b0\u81ea\u52a8\u6a21\u5f0f\u8bc6\u522b\u3001\u52a8\u6001\u6a21\u578b\u81ea\u9002\u5e94\u3001\u4f18\u5316\u7ef4\u62a4\u8c03\u5ea6\uff0c\u5e76\u751f\u6210\u53ef\u89e3\u91ca\u7684\u7ef4\u62a4\u51b3\u7b56\uff0c\u5728\u5de5\u4e1a\u5236\u9020\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9c81\u68d2\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u63a8\u52a8\u667a\u80fd\u5236\u9020\u4e2d\u7684\u9884\u6d4b\u6027\u7ef4\u62a4\u6280\u672f\u8fdb\u6b65\u3002"}}
{"id": "2511.17572", "categories": ["cs.CL", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.17572", "abs": "https://arxiv.org/abs/2511.17572", "authors": ["Patrick Gerard", "Aiden Chang", "Svitlana Volkova"], "title": "Community-Aligned Behavior Under Uncertainty: Evidence of Epistemic Stance Transfer in LLMs", "comment": "37 pages, EurIPS 2025", "summary": "When large language models (LLMs) are aligned to a specific online community, do they exhibit generalizable behavioral patterns that mirror that community's attitudes and responses to new uncertainty, or are they simply recalling patterns from training data? We introduce a framework to test epistemic stance transfer: targeted deletion of event knowledge, validated with multiple probes, followed by evaluation of whether models still reproduce the community's organic response patterns under ignorance. Using Russian--Ukrainian military discourse and U.S. partisan Twitter data, we find that even after aggressive fact removal, aligned LLMs maintain stable, community-specific behavioral patterns for handling uncertainty. These results provide evidence that alignment encodes structured, generalizable behaviors beyond surface mimicry. Our framework offers a systematic way to detect behavioral biases that persist under ignorance, advancing efforts toward safer and more transparent LLM deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u5730\u5220\u9664\u4e8b\u4ef6\u77e5\u8bc6\uff0c\u68c0\u9a8c\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7f3a\u4e4f\u4e8b\u5b9e\u77e5\u8bc6\u60c5\u51b5\u4e0b\u662f\u5426\u4ecd\u7136\u8868\u73b0\u51fa\u4e0e\u7279\u5b9a\u793e\u533a\u76f8\u4f3c\u7684\u884c\u4e3a\u6a21\u5f0f\u3002", "motivation": "\u63a2\u7a76\u5f53\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u7279\u5b9a\u5728\u7ebf\u793e\u533a\u8fdb\u884c\u5bf9\u9f50\u65f6\uff0c\u5176\u8868\u73b0\u51fa\u7684\u884c\u4e3a\u6a21\u5f0f\u662f\u7b80\u5355\u56de\u5fc6\u8bad\u7ec3\u6570\u636e\uff0c\u8fd8\u662f\u80fd\u6cdb\u5316\u4f53\u73b0\u8be5\u793e\u533a\u5728\u9762\u5bf9\u4e0d\u786e\u5b9a\u6027\u65f6\u7684\u6001\u5ea6\u548c\u53cd\u5e94\u3002", "method": "\u901a\u8fc7\u6709\u9488\u5bf9\u6027\u5730\u5220\u9664\u4e8b\u4ef6\u77e5\u8bc6\uff0c\u5e76\u4f7f\u7528\u591a\u4e2a\u63a2\u9488\u9a8c\u8bc1\uff0c\u518d\u8bc4\u4f30\u6a21\u578b\u5728\u77e5\u8bc6\u7f3a\u5931\u60c5\u51b5\u4e0b\u662f\u5426\u4ecd\u4ea7\u751f\u793e\u533a\u7684\u81ea\u7136\u53cd\u5e94\u6a21\u5f0f\u3002", "result": "\u5728\u4fc4\u4e4c\u519b\u4e8b\u8bdd\u8bed\u548c\u7f8e\u56fd\u515a\u6d3e\u63a8\u7279\u6570\u636e\u5b9e\u9a8c\u4e2d\uff0c\u4e8b\u5b9e\u4fe1\u606f\u88ab\u5927\u91cf\u5220\u9664\u540e\uff0c\u6821\u51c6\u6a21\u578b\u4f9d\u7136\u7ef4\u6301\u793e\u533a\u7279\u5b9a\u7684\u5904\u7406\u4e0d\u786e\u5b9a\u6027\u884c\u4e3a\uff0c\u9a8c\u8bc1\u4e86\u5176\u884c\u4e3a\u7684\u7ed3\u6784\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u7ecf\u8fc7\u4e8b\u5b9e\u77e5\u8bc6\u7684\u79ef\u6781\u5220\u9664\u540e\uff0c\u6821\u51c6\u7684\u5927\u8bed\u8a00\u6a21\u578b\u4ecd\u4fdd\u6301\u7a33\u5b9a\u7684\u3001\u793e\u533a\u7279\u5b9a\u7684\u5e94\u5bf9\u4e0d\u786e\u5b9a\u6027\u7684\u884c\u4e3a\u6a21\u5f0f\uff0c\u8868\u660e\u5bf9\u9f50\u8fc7\u7a0b\u7f16\u7801\u4e86\u7ed3\u6784\u5316\u3001\u53ef\u63a8\u5e7f\u7684\u884c\u4e3a\uff0c\u800c\u975e\u7b80\u5355\u7684\u6a21\u5f0f\u56de\u5fc6\u3002"}}
{"id": "2511.18038", "categories": ["cs.SE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18038", "abs": "https://arxiv.org/abs/2511.18038", "authors": ["Xiaoke Han", "Hong Zhu"], "title": "MASTEST: A LLM-Based Multi-Agent System For RESTful API Tests", "comment": "14 Page of main text plus 4 pages of appendix", "summary": "Testing RESTful API is increasingly important in quality assurance of cloud-native applications. Recent advances in machine learning (ML) techniques have demonstrated that various testing activities can be performed automatically by large language models (LLMs) with reasonable accuracy. This paper develops a multi-agent system called MASTEST that combines LLM-based and programmed agents to form a complete tool chain that covers the whole workflow of API test starting from generating unit and system test scenarios from API specification in the OpenAPI Swagger format, to generating of Pytest test scripts, executing test scripts to interact with web services, to analysing web service response messages to determine test correctness and calculate test coverage. The system also supports the incorporation of human testers in reviewing and correcting LLM generated test artefacts to ensure the quality of testing activities. MASTEST system is evaluated on two LLMs, GPT-4o and DeepSeek V3.1 Reasoner with five public APIs. The performances of LLMs on various testing activities are measured by a wide range of metrics, including unit and system test scenario coverage and API operation coverage for the quality of generated test scenarios, data type correctness, status code coverage and script syntax correctness for the quality of LLM generated test scripts, as well as bug detection ability and usability of LLM generated test scenarios and scripts. Experiment results demonstrated that both DeepSeek and GPT-4o achieved a high overall performance. DeepSeek excels in data type correctness and status code detection, while GPT-4o performs best in API operation coverage. For both models, LLM generated test scripts maintained 100\\% syntax correctness and only required minimal manual edits for semantic correctness. These findings indicate the effectiveness and feasibility of MASTEST.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aMASTEST\u7684\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u548c\u7f16\u7a0b\u4ee3\u7406\u81ea\u52a8\u5316\u5b8c\u6210RESTful API\u6d4b\u8bd5\u5168\u6d41\u7a0b\u3002", "motivation": "\u968f\u7740\u4e91\u539f\u751f\u5e94\u7528\u666e\u53ca\uff0cRESTful API\u6d4b\u8bd5\u9700\u6c42\u589e\u957f\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u751f\u6210\u548c\u6267\u884c\u6d4b\u8bd5\u7528\u4f8b\u80fd\u591f\u63d0\u5347\u6d4b\u8bd5\u6548\u7387\u548c\u8d28\u91cf\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u67b6\u6784\uff0c\u5c06LLM\u751f\u6210\u7684\u6d4b\u8bd5\u573a\u666f\u548c\u811a\u672c\u4e0e\u7f16\u7a0b\u4ee3\u7406\u7ed3\u5408\uff0c\u901a\u8fc7OpenAPI Swagger\u89c4\u8303\u81ea\u52a8\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u3001Pytest\u811a\u672c\uff0c\u6267\u884c\u6d4b\u8bd5\u5e76\u5206\u6790\u53cd\u9988\uff0c\u540c\u65f6\u652f\u6301\u4eba\u5de5\u5e72\u9884\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDeepSeek\u5728\u6570\u636e\u7c7b\u578b\u548c\u72b6\u6001\u7801\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0cGPT-4o\u5728API\u64cd\u4f5c\u8986\u76d6\u7387\u6700\u9ad8\uff0c\u6d4b\u8bd5\u811a\u672c\u8bed\u6cd5\u6b63\u786e\u7387\u8fbe100%\uff0c\u4e14\u4ec5\u9700\u5c11\u91cf\u624b\u52a8\u6821\u6b63\uff0c\u9a8c\u8bc1\u4e86MASTEST\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "conclusion": "MASTEST\u7ed3\u5408GPT-4o\u548cDeepSeek\u4e24\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u5728API\u6d4b\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u7684\u6d4b\u8bd5\u573a\u666f\u751f\u6210\u548c\u811a\u672c\u7f16\u5199\uff0c\u6781\u5927\u63d0\u5347\u4e86RESTful API\u6d4b\u8bd5\u7684\u6548\u679c\u548c\u53ef\u884c\u6027\u3002"}}
{"id": "2511.18761", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.18761", "abs": "https://arxiv.org/abs/2511.18761", "authors": ["Hao Wu", "Shoucheng Song", "Chang Yao", "Sheng Han", "Huaiyu Wan", "Youfang Lin", "Kai Lv"], "title": "Think How Your Teammates Think: Active Inference Can Benefit Decentralized Execution", "comment": "Accepted by AAAI 2026", "summary": "In multi-agent systems, explicit cognition of teammates' decision logic serves as a critical factor in facilitating coordination. Communication (i.e., ``\\textit{Tell}'') can assist in the cognitive development process by information dissemination, yet it is inevitably subject to real-world constraints such as noise, latency, and attacks. Therefore, building the understanding of teammates' decisions without communication remains challenging. To address this, we propose a novel non-communication MARL framework that realizes the construction of cognition through local observation-based modeling (i.e., \\textit{``Think''}). Our framework enables agents to model teammates' \\textbf{active inference} process. At first, the proposed method produces three teammate portraits: perception-belief-action. Specifically, we model the teammate's decision process as follows: 1) Perception: observing environments; 2) Belief: forming beliefs; 3) Action: making decisions. Then, we selectively integrate the belief portrait into the decision process based on the accuracy and relevance of the perception portrait. This enables the selection of cooperative teammates and facilitates effective collaboration. Extensive experiments on the SMAC, SMACv2, MPE, and GRF benchmarks demonstrate the superior performance of our method.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u901a\u4fe1\uff0c\u901a\u8fc7\u6a21\u62df\u961f\u53cb\u611f\u77e5\u548c\u4fe1\u5ff5\u8fc7\u7a0b\u5b9e\u73b0\u534f\u4f5c\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u7531\u4e8e\u901a\u4fe1\u5b58\u5728\u566a\u58f0\u3001\u5ef6\u8fdf\u53ca\u653b\u51fb\u7b49\u9650\u5236\uff0c\u5982\u4f55\u5728\u65e0\u901a\u4fe1\u6761\u4ef6\u4e0b\u6784\u5efa\u5bf9\u961f\u53cb\u51b3\u7b56\u903b\u8f91\u7684\u8ba4\u77e5\uff0c\u4fc3\u8fdb\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u6210\u4e3a\u6311\u6218\u3002", "method": "\u57fa\u4e8e\u5c40\u90e8\u89c2\u5bdf\uff0c\u6784\u5efa\u961f\u53cb\u7684\u611f\u77e5-\u4fe1\u5ff5-\u884c\u52a8\u4e09\u91cd\u753b\u50cf\uff0c\u9009\u62e9\u6027\u6574\u5408\u4fe1\u5ff5\u753b\u50cf\u8f85\u52a9\u51b3\u7b56\uff0c\u5b9e\u73b0\u961f\u53cb\u4e3b\u52a8\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5c40\u90e8\u89c2\u5bdf\u5efa\u6a21\u7684\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60(MARL)\u975e\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u961f\u53cb\u7684\u611f\u77e5-\u4fe1\u5ff5-\u884c\u52a8\u8fc7\u7a0b\uff0c\u5b9e\u73b0\u5bf9\u961f\u53cb\u51b3\u7b56\u903b\u8f91\u7684\u8ba4\u77e5\uff0c\u8fdb\u800c\u4fc3\u8fdb\u534f\u4f5c\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u6027\u5730\u5c06\u4fe1\u5ff5\u6a21\u578b\u6574\u5408\u8fdb\u51b3\u7b56\u8fc7\u7a0b\uff0c\u80fd\u591f\u6709\u6548\u8bc6\u522b\u5e76\u534f\u4f5c\u8868\u73b0\u8f83\u4f73\u7684\u961f\u53cb\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u4e2a\u6807\u51c6\u591a\u667a\u80fd\u4f53\u57fa\u51c6\u4efb\u52a1\u4e2d\uff0c\u8be5\u65b9\u6cd5\u6027\u80fd\u4f18\u8d8a\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u57fa\u4e8e\u975e\u901a\u4fe1\u7684\u961f\u53cb\u8ba4\u77e5\u548c\u534f\u4f5c\uff0c\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u7684\u534f\u8c03\u6027\u80fd\u3002"}}
{"id": "2511.17575", "categories": ["cs.CL", "stat.ME", "stat.ML", "stat.OT"], "pdf": "https://arxiv.org/pdf/2511.17575", "abs": "https://arxiv.org/abs/2511.17575", "authors": ["Vladimir Berman"], "title": "Random Text, Zipf's Law, Critical Length,and Implications for Large Language Models", "comment": null, "summary": "We study a deliberately simple, fully non-linguistic model of text: a sequence of independent draws from a finite alphabet of letters plus a single space symbol. A word is defined as a maximal block of non-space symbols. Within this symbol-level framework, which assumes no morphology, syntax, or semantics, we derive several structural results. First, word lengths follow a geometric distribution governed solely by the probability of the space symbol. Second, the expected number of words of a given length, and the expected number of distinct words of that length, admit closed-form expressions based on a coupon-collector argument. This yields a critical word length k* at which word types transition from appearing many times on average to appearing at most once. Third, combining the exponential growth of the number of possible strings of length k with the exponential decay of the probability of each string, we obtain a Zipf-type rank-frequency law p(r) proportional to r^{-alpha}, with an exponent determined explicitly by the alphabet size and the space probability.\n  Our contribution is twofold. Mathematically, we give a unified derivation linking word lengths, vocabulary growth, critical length, and rank-frequency structure in a single explicit model. Conceptually, we argue that this provides a structurally grounded null model for both natural-language word statistics and token statistics in large language models. The results show that Zipf-like patterns can arise purely from combinatorics and segmentation, without optimization principles or linguistic organization, and help clarify which phenomena require deeper explanation beyond random-text structure.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u4e2a\u7b80\u5355\u7684\u968f\u673a\u6587\u672c\u6a21\u578b\uff0c\u901a\u8fc7\u7eaf\u6570\u5b66\u63a8\u5bfc\u89e3\u91ca\u8bcd\u957f\u5206\u5e03\u3001\u8bcd\u6c47\u589e\u957f\u53caZipf\u9891\u7387\u89c4\u5f8b\uff0c\u6307\u51fa\u590d\u6742\u8bed\u8a00\u73b0\u8c61\u4e2d\u90e8\u5206\u7edf\u8ba1\u7279\u5f81\u53ef\u7531\u968f\u673a\u7ec4\u5408\u548c\u5206\u8bcd\u673a\u5236\u81ea\u7136\u4ea7\u751f\u3002", "motivation": "\u4e3a\u4e86\u5bfb\u627e\u4e00\u4e2a\u7ed3\u6784\u4e0a\u624e\u5b9e\u7684\u7a7a\u6a21\u578b\uff0c\u89e3\u91ca\u81ea\u7136\u8bed\u8a00\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5355\u8bcd\u53ca\u8bcd\u5143\u7edf\u8ba1\u89c4\u5f8b\uff0c\u63a2\u7a76\u662f\u5426\u65e0\u9700\u590d\u6742\u8bed\u8a00\u673a\u5236\u5373\u53ef\u4ea7\u751fZipf\u5f0f\u7684\u9891\u7387\u5206\u5e03\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5b57\u6bcd\u548c\u7a7a\u683c\u7b26\u53f7\u7684\u72ec\u7acb\u62bd\u6837\u5e8f\u5217\u6a21\u578b\uff0c\u5c06\u5355\u8bcd\u5b9a\u4e49\u4e3a\u975e\u7a7a\u683c\u7b26\u53f7\u7684\u6700\u5927\u8fde\u7eed\u5757\uff0c\u5229\u7528\u51e0\u4f55\u5206\u5e03\u3001coupon-collector\u7406\u8bba\u53ca\u6982\u7387\u8ba1\u7b97\u63a8\u5bfc\u7ed3\u6784\u6027\u7ed3\u8bba\uff0c\u5e76\u7ed3\u5408\u5b57\u4e32\u6570\u91cf\u589e\u957f\u548c\u6982\u7387\u8870\u51cf\u5206\u6790\u6392\u5e8f\u9891\u7387\u5b9a\u5f8b\u3002", "result": "\u63a8\u5bfc\u51fa\u5355\u8bcd\u957f\u5ea6\u670d\u4ece\u51e0\u4f55\u5206\u5e03\uff0c\u5355\u8bcd\u6570\u91cf\u6709\u660e\u786e\u5c01\u95ed\u8868\u8fbe\u5f0f\uff0c\u53d1\u73b0\u5b58\u5728\u5173\u952e\u5355\u8bcd\u957f\u5ea6\u51b3\u5b9a\u5355\u8bcd\u51fa\u73b0\u6b21\u6570\u7684\u8f6c\u6298\u70b9\uff0c\u5e76\u8bc1\u660e\u4e86\u5728\u6a21\u578b\u4e2d\u51fa\u73b0\u4e86\u7c7b\u4f3cZipf\u7684\u5e42\u5f8b\u9891\u7387\u5206\u5e03\uff0c\u5176\u6307\u6570\u53ef\u7531\u5b57\u6bcd\u96c6\u5927\u5c0f\u548c\u7a7a\u683c\u6982\u7387\u660e\u786e\u786e\u5b9a\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u4e00\u4e2a\u7b80\u5316\u7684\u975e\u8bed\u8a00\u5b66\u6587\u672c\u6a21\u578b\uff0c\u7cfb\u7edf\u5730\u63a8\u5bfc\u4e86\u5355\u8bcd\u957f\u5ea6\u5206\u5e03\u3001\u8bcd\u6c47\u589e\u957f\u3001\u5173\u952e\u5355\u8bcd\u957f\u5ea6\u548c\u6392\u5e8f\u9891\u7387\u7ed3\u6784\u7684\u7edf\u4e00\u5173\u7cfb\uff0c\u63ed\u793a\u4e86Zipf\u5b9a\u5f8b\u5f0f\u7684\u9891\u7387\u5206\u5e03\u53ef\u4ee5\u7531\u7eaf\u7cb9\u7684\u7ec4\u5408\u5b66\u548c\u5206\u8bcd\u673a\u5236\u4ea7\u751f\uff0c\u65e0\u9700\u8bed\u8a00\u5b66\u4f18\u5316\u6216\u7ec4\u7ec7\u3002"}}
{"id": "2511.18092", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18092", "abs": "https://arxiv.org/abs/2511.18092", "authors": ["Sebastian Dingler", "Philip Rehkop", "Florian Mayer", "Ralf Muenzenberger"], "title": "Event-Chain Analysis for Automated Driving and ADAS Systems: Ensuring Safety and Meeting Regulatory Timing Requirements", "comment": null, "summary": "Automated Driving Systems (ADS), including Advanced Driver Assistance Systems (ADAS), must fulfill not only high functional expectations but also stringent timing constraints mandated by international regulations and standards. Regulatory frameworks such as UN regulations, NCAP standards, ISO norms, and NHTSA guidelines impose strict bounds on system reaction times to ensure safe vehicle operation. This paper presents a structured, White-Box methodology based on Event-Chain Modeling to address these timing challenges. Unlike Black-Box approaches, Event-Chain Analysis offers transparent insights into the timing behavior of each functional component - from perception and planning to actuation and human interaction. This perspective is also aligned with multiple regulations, which require that homologation dossiers provide evidence that the chosen system architecture is suitable to ensure compliance with the specified requirements. Our methodology enables the derivation, modeling, and validation of end-to-end timing constraints at the architectural level and facilitates early verification through simulation. Through a detailed case study, we demonstrate how this Event-Chain-centric approach enhances regulatory compliance, optimizes system design, and supports model-based safety analysis techniques, with results showing early identification of compliance issues, systematic parameter optimization, and quantitative evidence generation through probabilistic analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u7684\u767d\u76d2\u65b9\u6cd5\uff0c\u7528\u4e8e\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u65f6\u95f4\u7ea6\u675f\u5206\u6790\uff0c\u63d0\u5347\u4e86\u6cd5\u89c4\u7b26\u5408\u6027\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\uff0c\u652f\u6301\u65e9\u671f\u9a8c\u8bc1\u548c\u6a21\u578b\u5b89\u5168\u5206\u6790\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u548c\u9ad8\u7ea7\u9a7e\u9a76\u8f85\u52a9\u7cfb\u7edf\u9700\u8981\u6ee1\u8db3\u4e25\u683c\u7684\u56fd\u9645\u6cd5\u89c4\u548c\u6807\u51c6\u4e2d\u7684\u65f6\u95f4\u7ea6\u675f\uff0c\u4ee5\u4fdd\u8bc1\u8f66\u8f86\u5b89\u5168\u8fd0\u884c\u3002\u73b0\u6709\u9ed1\u76d2\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u7cfb\u7edf\u5404\u529f\u80fd\u7ec4\u4ef6\u65f6\u95f4\u884c\u4e3a\u7684\u900f\u660e\u5206\u6790\uff0c\u96be\u4ee5\u6ee1\u8db3\u6cd5\u89c4\u5bf9\u4f53\u7cfb\u7ed3\u6784\u900f\u660e\u6027\u7684\u8981\u6c42\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u7684\u767d\u76d2\u5206\u6790\u65b9\u6cd5\uff0c\u4ece\u7cfb\u7edf\u4f53\u7cfb\u7ed3\u6784\u89d2\u5ea6\u63a8\u5bfc\u3001\u5efa\u6a21\u548c\u9a8c\u8bc1\u7aef\u5230\u7aef\u65f6\u95f4\u7ea6\u675f\uff0c\u901a\u8fc7\u4eff\u771f\u5b9e\u73b0\u65e9\u671f\u9a8c\u8bc1\uff0c\u7ed3\u5408\u6982\u7387\u5206\u6790\u751f\u6210\u5b9a\u91cf\u8bc1\u636e\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e8b\u4ef6\u94fe\u5efa\u6a21\u7684\u767d\u76d2\u65b9\u6cd5\uff0c\u4ece\u611f\u77e5\u3001\u89c4\u5212\u5230\u6267\u884c\u548c\u4eba\u673a\u4ea4\u4e92\uff0c\u900f\u660e\u5206\u6790\u7cfb\u7edf\u5404\u529f\u80fd\u6a21\u5757\u7684\u65f6\u95f4\u884c\u4e3a\uff0c\u5b9e\u73b0\u7aef\u5230\u7aef\u65f6\u95f4\u7ea6\u675f\u7684\u63a8\u5bfc\u3001\u5efa\u6a21\u548c\u9a8c\u8bc1\u3002\u901a\u8fc7\u8be6\u7ec6\u6848\u4f8b\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u5728\u6cd5\u89c4\u7b26\u5408\u6027\u3001\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\u548c\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u5206\u6790\u4e2d\u7684\u5e94\u7528\u6548\u679c\uff0c\u80fd\u591f\u65e9\u671f\u53d1\u73b0\u5408\u89c4\u95ee\u9898\uff0c\u7cfb\u7edf\u4f18\u5316\u53c2\u6570\uff0c\u5e76\u901a\u8fc7\u6982\u7387\u5206\u6790\u751f\u6210\u5b9a\u91cf\u8bc1\u636e\u3002", "conclusion": "\u4e8b\u4ef6\u94fe\u5efa\u6a21\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u7684\u65f6\u95f4\u7ea6\u675f\u7ba1\u7406\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u6cd5\u89c4\u7b26\u5408\u6027\u9a8c\u8bc1\u548c\u7cfb\u7edf\u8bbe\u8ba1\u4f18\u5316\uff0c\u4e3a\u57fa\u4e8e\u6a21\u578b\u7684\u5b89\u5168\u5206\u6790\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2511.18840", "categories": ["cs.MA", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18840", "abs": "https://arxiv.org/abs/2511.18840", "authors": ["Binglin Liu", "Yucheng Wang", "Zheyuan Zhang", "Jiyuan Lu", "Shen Yang", "Daniel Zhang-Li", "Huiqin Liu", "Jifan Yu"], "title": "Addressing Situated Teaching Needs: A Multi-Agent Framework for Automated Slide Adaptation", "comment": null, "summary": "The adaptation of teaching slides to instructors' situated teaching needs, including pedagogical styles and their students' context, is a critical yet time-consuming task for educators. Through a series of educator interviews, we first identify and systematically categorize the key friction points that impede this adaptation process. Grounded in these findings, we introduce a novel multi-agent framework designed to automate slide adaptation based on high-level instructor specifications. An evaluation involving 16 modification requests across 8 real-world courses validates our approach. The framework's output consistently achieved high scores in intent alignment, content coherence and factual accuracy, and performed on par with baseline methods regarding visual clarity, while also demonstrating appropriate timeliness and a high operational agreement with human experts, achieving an F1 score of 0.89. This work heralds a new paradigm where AI agents handle the logistical burdens of instructional design, liberating educators to focus on the creative and strategic aspects of teaching.", "AI": {"tldr": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u81ea\u52a8\u9002\u5e94\u6559\u5b66\u5e7b\u706f\u7247\u6846\u67b6\uff0c\u663e\u8457\u964d\u4f4e\u6559\u5e08\u8d1f\u62c5\uff0c\u63d0\u5347\u6559\u5b66\u8bbe\u8ba1\u6548\u7387\u3002", "motivation": "\u6559\u5e08\u5728\u9002\u5e94\u6559\u5b66\u5e7b\u706f\u7247\u4ee5\u6ee1\u8db3\u6559\u5b66\u98ce\u683c\u548c\u5b66\u751f\u80cc\u666f\u65f6\u5de5\u4f5c\u91cf\u5927\u4e14\u8017\u65f6\uff0c\u9700\u8981\u8f85\u52a9\u81ea\u52a8\u5316\u5de5\u5177\u3002", "method": "\u901a\u8fc7\u4e0e\u6559\u80b2\u8005\u8bbf\u8c08\u786e\u5b9a\u5e7b\u706f\u7247\u9002\u5e94\u7684\u5173\u952e\u96be\u70b9\uff0c\u57fa\u4e8e\u6b64\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6\u4ee5\u81ea\u52a8\u9002\u5e94\u5e7b\u706f\u7247\uff0c\u7ed3\u540816\u4e2a\u4fee\u6539\u8bf7\u6c42\u548c8\u95e8\u5b9e\u9645\u8bfe\u7a0b\u505a\u9a8c\u8bc1\u3002", "result": "\u8be5\u6846\u67b6\u4ea7\u51fa\u5728\u610f\u56fe\u5bf9\u9f50\u3001\u5185\u5bb9\u8fde\u8d2f\u6027\u548c\u4e8b\u5b9e\u51c6\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u89c6\u89c9\u6e05\u6670\u5ea6\u4e0e\u57fa\u7ebf\u65b9\u6cd5\u6301\u5e73\uff0c\u53ca\u65f6\u6027\u597d\uff0c\u4e0e\u4eba\u5de5\u4e13\u5bb6\u7684F1\u8bc4\u5206\u8fbe0.89\u3002", "conclusion": "\u6b64\u5de5\u4f5c\u5f00\u521b\u5229\u7528AI\u4ee3\u7406\u5904\u7406\u6559\u5b66\u8bbe\u8ba1\u540e\u52e4\u5de5\u4f5c\u7684\u65b0\u8303\u5f0f\uff0c\u4f7f\u6559\u5e08\u80fd\u4e13\u6ce8\u4e8e\u6559\u5b66\u521b\u610f\u548c\u7b56\u7565\u3002"}}
{"id": "2511.17746", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17746", "abs": "https://arxiv.org/abs/2511.17746", "authors": ["Sharaj Kunjar", "Alyssa Hasegawa Smith", "Tyler R Mckenzie", "Rushali Mohbe", "Samuel V Scarpino", "Brooke Foucault Welles"], "title": "Computational frame analysis revisited: On LLMs for studying news coverage", "comment": null, "summary": "Computational approaches have previously shown various promises and pitfalls when it comes to the reliable identification of media frames. Generative LLMs like GPT and Claude are increasingly being used as content analytical tools, but how effective are they for frame analysis? We address this question by systematically evaluating them against their computational predecessors: bag-of-words models and encoder-only transformers; and traditional manual coding procedures. Our analysis rests on a novel gold standard dataset that we inductively and iteratively developed through the study, investigating six months of news coverage of the US Mpox epidemic of 2022. While we discover some potential applications for generative LLMs, we demonstrate that they were consistently outperformed by manual coders, and in some instances, by smaller language models. Some form of human validation was always necessary to determine appropriate model choice. Additionally, by examining how the suitability of various approaches depended on the nature of different tasks that were part of our frame analytical workflow, we provide insights as to how researchers may leverage the complementarity of these approaches to use them in tandem. We conclude by endorsing a methodologically pluralistic approach and put forth a roadmap for computational frame analysis for researchers going forward.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u67902022\u5e74\u7f8e\u56fdMpox\u75ab\u60c5\u65b0\u95fb\uff0c\u53d1\u73b0\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5a92\u4f53\u6846\u67b6\u8bc6\u522b\u4e2d\u4e0d\u53ca\u4eba\u5de5\u7f16\u7801\uff0c\u5efa\u8bae\u91c7\u7528\u591a\u65b9\u6cd5\u7ed3\u5408\u7684\u5206\u6790\u7b56\u7565\u3002", "motivation": "\u8bc4\u4f30\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5a92\u4f53\u6846\u67b6\u8bc6\u522b\u4e2d\u7684\u6709\u6548\u6027\uff0c\u6bd4\u8f83\u5176\u4e0e\u4f20\u7edf\u65b9\u6cd5\u53ca\u4eba\u5de5\u7f16\u7801\u7684\u4f18\u52a3\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u65b0\u7684\u91d1\u6807\u51c6\u6570\u636e\u96c6\uff0c\u5bf9\u6bd4\u751f\u6210\u5f0fLLMs\u4e0e\u4f20\u7edf\u7684\u8bcd\u888b\u6a21\u578b\u3001\u7f16\u7801\u5668\u578b\u53d8\u6362\u5668\u4ee5\u53ca\u4eba\u5de5\u7f16\u7801\uff0c\u5bf92022\u5e74\u7f8e\u56fdMpox\u75ab\u60c5\u516d\u4e2a\u6708\u7684\u65b0\u95fb\u62a5\u9053\u8fdb\u884c\u7cfb\u7edf\u8bc4\u4f30\u3002", "result": "\u751f\u6210\u5f0fLLMs\u5728\u67d0\u4e9b\u5e94\u7528\u4e2d\u6709\u6f5c\u529b\uff0c\u4f46\u6574\u4f53\u6027\u80fd\u4f4e\u4e8e\u4eba\u5de5\u7f16\u7801\u8005\u548c\u90e8\u5206\u8f83\u5c0f\u8bed\u8a00\u6a21\u578b\u3002\u6a21\u578b\u9002\u7528\u6027\u4f9d\u8d56\u5177\u4f53\u4efb\u52a1\uff0c\u9700\u8981\u7ed3\u5408\u591a\u79cd\u65b9\u6cd5\u5b9e\u73b0\u6700\u4f18\u6548\u679c\u3002", "conclusion": "\u751f\u6210\u5f0f\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6846\u67b6\u5206\u6790\u4e2d\u8868\u73b0\u5b58\u5728\u5c40\u9650\u6027\uff0c\u901a\u5e38\u4e0d\u5982\u4eba\u5de5\u7f16\u7801\u8005\u548c\u67d0\u4e9b\u8f83\u5c0f\u7684\u8bed\u8a00\u6a21\u578b\u3002\u9700\u8981\u4eba\u7c7b\u9a8c\u8bc1\u4ee5\u786e\u5b9a\u5408\u9002\u7684\u6a21\u578b\u9009\u62e9\u3002"}}
{"id": "2511.18165", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18165", "abs": "https://arxiv.org/abs/2511.18165", "authors": ["Israel Puerta-Merino", "Carlos N\u00fa\u00f1ez-Molina", "Pablo Mesejo", "Juan Fern\u00e1ndez-Olivares"], "title": "Towards a General Framework for HTN Modeling with LLMs", "comment": "10 pages, 5 figures, to be published in the Workshop on Planning in the Era of LLMs ( LM4Plan - https://llmforplanning.github.io ) and the Workshop on Hierarchical Planning ( HPlan - https://icaps25.icaps-conference.org/program/workshops/hplan/ ), both in the International Conference on Automated Planning and Scheduling (ICAPS) 2025", "summary": "The use of Large Language Models (LLMs) for generating Automated Planning (AP) models has been widely explored; however, their application to Hierarchical Planning (HP) is still far from reaching the level of sophistication observed in non-hierarchical architectures. In this work, we try to address this gap. We present two main contributions. First, we propose L2HP, an extension of L2P (a library to LLM-driven PDDL models generation) that support HP model generation and follows a design philosophy of generality and extensibility. Second, we apply our framework to perform experiments where we compare the modeling capabilities of LLMs for AP and HP. On the PlanBench dataset, results show that parsing success is limited but comparable in both settings (around 36\\%), while syntactic validity is substantially lower in the hierarchical case (1\\% vs. 20\\% of instances). These findings underscore the unique challenges HP presents for LLMs, highlighting the need for further research to improve the quality of generated HP models.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86LLMs\u751f\u6210\u81ea\u52a8\u89c4\u5212\u6a21\u578b\u80fd\u529b\uff0c\u63d0\u51fa\u652f\u6301\u5206\u5c42\u89c4\u5212\u7684L2HP\u6846\u67b6\uff0c\u5e76\u5c55\u793a\u4e86\u5206\u5c42\u89c4\u5212\u751f\u6210\u7684\u4f4e\u8bed\u6cd5\u6709\u6548\u6027\uff0c\u5f3a\u8c03\u4e86HP\u9886\u57df\u7684\u6311\u6218\u548c\u6539\u8fdb\u9700\u6c42\u3002", "motivation": "\u76ee\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u5728\u81ea\u52a8\u89c4\u5212(AP)\u6a21\u578b\u751f\u6210\u65b9\u9762\u5df2\u6709\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5176\u5728\u5206\u5c42\u89c4\u5212(HP)\u4e2d\u7684\u5e94\u7528\u4ecd\u4e0d\u6210\u719f\u3002", "method": "\u63d0\u51faL2HP\uff0c\u6269\u5c55\u4e86L2P\u5e93\u4ee5\u652f\u6301HP\u6a21\u578b\u751f\u6210\uff0c\u8bbe\u8ba1\u7406\u5ff5\u5f3a\u8c03\u901a\u7528\u6027\u548c\u53ef\u6269\u5c55\u6027\u3002\u540c\u65f6\uff0c\u8bbe\u8ba1\u5b9e\u9a8c\u5bf9\u6bd4LLMs\u5728AP\u548cHP\u5efa\u6a21\u80fd\u529b\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5728PlanBench\u6570\u636e\u96c6\u4e0a\uff0c\u89e3\u6790\u6210\u529f\u7387\u5728AP\u548cHP\u4e2d\u5dee\u5f02\u4e0d\u5927\uff08\u7ea636%\uff09\uff0c\u4f46HP\u7684\u8bed\u6cd5\u6709\u6548\u6027\u663e\u8457\u8f83\u4f4e\uff081% vs. 20%\uff09\uff0c\u663e\u793aHP\u751f\u6210\u9762\u4e34\u66f4\u591a\u6311\u6218\u3002", "conclusion": "HP\u6a21\u578b\u751f\u6210\u5bf9LLMs\u6784\u6210\u72ec\u7279\u6311\u6218\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u63d0\u5347HP\u6a21\u578b\u751f\u6210\u8d28\u91cf\u3002"}}
{"id": "2511.19146", "categories": ["cs.MA"], "pdf": "https://arxiv.org/pdf/2511.19146", "abs": "https://arxiv.org/abs/2511.19146", "authors": ["Qian Zhang", "Zhuo Sun", "Yao Zhang", "Zhiwen Yu", "Bin Guo", "Jun Zhang"], "title": "VIL2C: Value-of-Information Aware Low-Latency Communication for Multi-Agent Reinforcement Learning", "comment": null, "summary": "Inter-agent communication serves as an effective mechanism for enhancing performance in collaborative multi-agent reinforcement learning(MARL) systems. However, the inherent communication latency in practical systems induces both action decision delays and outdated information sharing, impeding MARL performance gains, particularly in time-critical applications like autonomous driving. In this work, we propose a Value-of-Information aware Low-latency Communication(VIL2C) scheme that proactively adjusts the latency distribution to mitigate its effects in MARL systems. Specifically, we define a Value of Information (VOI) metric to quantify the importance of delayed message transmission based on each delayed message's importance. Moreover, we propose a progressive message reception mechanism to adaptively adjust the reception duration based on received messages. We derive the optimized VoI aware resource allocation and theoretically prove the performance advantage of the proposed VIL2C scheme. Extensive experiments demonstrate that VIL2C outperforms existing approaches under various communication conditions. These gains are attributed to the low-latency transmission of high-VoI messages via resource allocation and the elimination of unnecessary waiting periods via adaptive reception duration.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u4fe1\u606f\u4ef7\u503c\u7684\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u65b9\u6848VIL2C\uff0c\u4f18\u5316\u8d44\u6e90\u5206\u914d\u4e0e\u63a5\u6536\u65f6\u957f\uff0c\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5b9e\u9645\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7cfb\u7edf\u4e2d\u901a\u4fe1\u5ef6\u8fdf\u5bfc\u81f4\u52a8\u4f5c\u51b3\u7b56\u5ef6\u8bef\u548c\u4fe1\u606f\u8fc7\u65f6\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u65f6\u95f4\u654f\u611f\u573a\u666f\u5982\u81ea\u52a8\u9a7e\u9a76\u4e2d\u3002", "method": "\u901a\u8fc7\u5b9a\u4e49\u4fe1\u606f\u4ef7\u503c\u6307\u6807\uff0c\u4f7f\u7528\u6e10\u8fdb\u5f0f\u6d88\u606f\u63a5\u6536\u8c03\u6574\u63a5\u6536\u65f6\u957f\uff0c\u5e76\u7ed3\u5408\u4f18\u5316\u8d44\u6e90\u5206\u914d\u7b56\u7565\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u5f71\u54cd\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\uff08MARL\uff09\u7cfb\u7edf\u7684\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u65b9\u6848VIL2C\uff0c\u901a\u8fc7\u5b9a\u4e49\u4fe1\u606f\u4ef7\u503c\uff08VOI\uff09\u6307\u6807\u91cf\u5316\u5ef6\u8fdf\u6d88\u606f\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7\u6e10\u8fdb\u5f0f\u6d88\u606f\u63a5\u6536\u673a\u5236\u81ea\u9002\u5e94\u8c03\u6574\u63a5\u6536\u65f6\u957f\uff0c\u6709\u6548\u964d\u4f4e\u901a\u4fe1\u5ef6\u8fdf\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002\u7406\u8bba\u5206\u6790\u4e0e\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\uff0cVIL2C\u5728\u5404\u79cd\u901a\u4fe1\u6761\u4ef6\u4e0b\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "VIL2C\u65b9\u6848\u901a\u8fc7\u4f18\u5316\u8d44\u6e90\u5206\u914d\u548c\u81ea\u9002\u5e94\u63a5\u6536\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u5728\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u73af\u5883\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2511.17808", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17808", "abs": "https://arxiv.org/abs/2511.17808", "authors": ["Thales Sales Almeida", "Rodrigo Nogueira", "H\u00e9lio Pedrini"], "title": "PoETa v2: Toward More Robust Evaluation of Large Language Models in Portuguese", "comment": null, "summary": "Large Language Models (LLMs) exhibit significant variations in performance across linguistic and cultural contexts, underscoring the need for systematic evaluation in diverse languages. In this work, we present the most extensive evaluation of LLMs for the Portuguese language to date. Leveraging our newly introduced PoETa v2 benchmark -- a comprehensive suite of over 40 tasks in Portuguese -- we assess more than 20 models covering a broad spectrum of training scales and computational resources. Our study reveals how computational investment and language-specific adaptation impact performance in Portuguese, while also analyzing performance gaps in comparison to equivalent tasks in English. Through this benchmark and analysis, PoETa v2 lays the groundwork for future research on Portuguese language modeling and evaluation. The benchmark is available at https://github.com/PoETaV2/PoETaV2.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5bf9\u8461\u8404\u7259\u8bed\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\uff0c\u5229\u7528PoETa v2\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u6db5\u76d640\u591a\u4e2a\u4efb\u52a1\uff0c\u8bc4\u6d4b20\u591a\u79cd\u6a21\u578b\uff0c\u5206\u6790\u4e86\u8ba1\u7b97\u6295\u5165\u548c\u8bed\u8a00\u7279\u5b9a\u9002\u5e94\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u5e76\u6bd4\u8f83\u4e86\u8461\u8404\u7259\u8bed\u4e0e\u82f1\u8bed\u4efb\u52a1\u7684\u8868\u73b0\u5dee\u5f02\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u8bed\u8a00\u53ca\u6587\u5316\u80cc\u666f\u4e0b\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u8461\u8404\u7259\u8bed\u7f3a\u4e4f\u7cfb\u7edf\u7684\u8bc4\u4f30\uff0c\u8feb\u5207\u9700\u8981\u6784\u5efa\u7efc\u5408\u6027\u7684\u8bc4\u6d4b\u4f53\u7cfb\u3002", "method": "\u5f15\u5165PoETa v2\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u5305\u542b40\u591a\u4e2a\u8461\u8404\u7259\u8bed\u4efb\u52a1\uff0c\u8bc4\u6d4b20\u591a\u4e2a\u6db5\u76d6\u4e0d\u540c\u8bad\u7ec3\u89c4\u6a21\u548c\u8ba1\u7b97\u8d44\u6e90\u7684\u6a21\u578b\u3002", "result": "\u901a\u8fc7PoETa v2\u5bf9\u591a\u6a21\u578b\u7684\u8bc4\u6d4b\u63ed\u793a\u4e86\u8ba1\u7b97\u6295\u5165\u548c\u8bed\u8a00\u9002\u914d\u5bf9\u8461\u8404\u7259\u8bed\u6a21\u578b\u6027\u80fd\u7684\u91cd\u8981\u5f71\u54cd\uff0c\u5e76\u5206\u6790\u4e86\u4e0e\u82f1\u8bed\u4efb\u52a1\u8868\u73b0\u7684\u5dee\u8ddd\u3002", "conclusion": "\u8461\u8404\u7259\u8bed\u7684\u8bed\u8a00\u6a21\u578b\u6027\u80fd\u53d7\u8ba1\u7b97\u8d44\u6e90\u548c\u8bed\u8a00\u7279\u5b9a\u8c03\u6574\u7684\u5f71\u54cd\u660e\u663e\uff0cPoETa v2\u4e3a\u8461\u8404\u7259\u8bed\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u548c\u8bc4\u4f30\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2511.18187", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18187", "abs": "https://arxiv.org/abs/2511.18187", "authors": ["Sristy Sumana Nath", "Banani Roy", "Munima Jahan"], "title": "Establishing Traceability Links between Release Notes & Software Artifacts: Practitioners' Perspectives", "comment": null, "summary": "Maintaining traceability links between software release notes and corresponding development artifacts, e.g., pull requests (PRs), commits, and issues, is essential for managing technical debt and ensuring maintainability. However, in open-source environments where contributors work remotely and asynchronously, establishing and maintaining these links is often error-prone, time-consuming, and frequently overlooked. Our empirical study of GitHub repositories revealed that 47% of release artifacts lacked traceability links, and 12% contained broken links. To address this gap, we first analyzed release notes to identify their What, Why, and How information and assessed how these align with PRs, commits, and issues. We curated a benchmark dataset consisting of 3,500 filtered and validated traceability link instances. Then, we implemented LLM-based approaches to automatically establish traceability links of three pairs between release note contents & PRs, release note contents & PRs and release note contents & issues. By combining the time proximity feature, the LLM-based approach, e.g., Gemini 1.5 Pro, achieved a high Precision@1 value of 0.73 for PR traceability recovery. To evaluate the usability and adoption potential of this approach, we conducted an online survey involving 33 open-source practitioners. 16% of respondents rated as very important, and 68% as somewhat important for traceability maintenance.", "AI": {"tldr": "\u9488\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u8ffd\u6eaf\u94fe\u63a5\u7f3a\u5931\u95ee\u9898\uff0c\u672c\u6587\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u5e76\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u81ea\u52a8\u6062\u590d\u94fe\u63a5\uff0c\u663e\u8457\u63d0\u5347\u8ffd\u6eaf\u6062\u590d\u7cbe\u5ea6\uff0c\u5e76\u83b7\u5f97\u5f00\u6e90\u793e\u533a\u4ece\u4e1a\u8005\u8ba4\u53ef\u3002", "motivation": "\u5f00\u6e90\u73af\u5883\u4e2d\uff0c\u8d21\u732e\u8005\u8fdc\u7a0b\u5f02\u6b65\u5de5\u4f5c\uff0c\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u95f4\u7684\u8ffd\u6eaf\u94fe\u63a5\u5e38\u5e38\u7f3a\u5931\u6216\u65ad\u94fe\uff0c\u5bfc\u81f4\u6280\u672f\u503a\u52a1\u7ba1\u7406\u56f0\u96be\uff0c\u7ef4\u62a4\u6027\u5dee\u3002\u5b9e\u8bc1\u8c03\u7814\u663e\u793a47%\u53d1\u5e03\u5de5\u4ef6\u7f3a\u5c11\u8ffd\u6eaf\u94fe\u63a5\uff0c12%\u94fe\u63a5\u65ad\u88c2\u3002", "method": "\u5206\u6790\u53d1\u5e03\u8bf4\u660e\u4e2d\u7684What\u3001Why\u548cHow\u4fe1\u606f\uff0c\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u65b9\u6cd5\uff0c\u5229\u7528\u65f6\u95f4\u90bb\u8fd1\u7279\u6027\u81ea\u52a8\u5efa\u7acb\u53d1\u5e03\u8bf4\u660e\u4e0ePR\u3001\u63d0\u4ea4\u3001\u95ee\u9898\u4e4b\u95f4\u7684\u8ffd\u6eaf\u94fe\u63a5\u3002\u6784\u5efa\u4e86\u5305\u542b3500\u6761\u6709\u6548\u8ffd\u6eaf\u94fe\u63a5\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u5e76\u91c7\u7528LLM\uff08\u5982Gemini 1.5 Pro\uff09\u8fdb\u884c\u8ffd\u6eaf\u6062\u590d\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6062\u590dPR\u8ffd\u6eaf\u94fe\u63a5\u65f6\u8fbe\u5230\u4e86Precision@1\u4e3a0.73\u7684\u9ad8\u7cbe\u5ea6\u503c\u3002\u8c03\u67e5\u663e\u793a\uff0c\u5f00\u6e90\u4ece\u4e1a\u8005\u4e2d16%\u9ad8\u5ea6\u91cd\u89c6\uff0c68%\u90e8\u5206\u91cd\u89c6\u8ffd\u6eaf\u7ef4\u62a4\u65b9\u6cd5\u7684\u5e94\u7528\u4ef7\u503c\u3002", "conclusion": "\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u548c\u65f6\u95f4\u90bb\u8fd1\u7279\u5f81\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u6062\u590d\u548c\u7ef4\u62a4\u53d1\u5e03\u8bf4\u660e\u4e0e\u5f00\u53d1\u5de5\u4ef6\u95f4\u7684\u8ffd\u6eaf\u94fe\u63a5\uff0c\u589e\u5f3a\u6280\u672f\u503a\u52a1\u7ba1\u7406\u548c\u8f6f\u4ef6\u7ef4\u62a4\u6027\uff0c\u5177\u6709\u8f83\u9ad8\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19327", "categories": ["cs.MA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.19327", "abs": "https://arxiv.org/abs/2511.19327", "authors": ["Liwei Yuan", "Hideaki Ishii"], "title": "Dynamic Leader-Follower Consensus with Adversaries: A Multi-Hop Relay Approach", "comment": "15 pages", "summary": "This paper examines resilient dynamic leader-follower consensus within multi-agent systems, where agents share first-order or second-order dynamics. The aim is to develop distributed protocols enabling nonfaulty/normal followers to accurately track a dynamic/time-varying reference value of the leader while they may receive misinformation from adversarial neighbors. Our methodologies employ the mean subsequence reduced algorithm with agents engaging with neighbors using multi-hop communication. We accordingly derive a necessary and sufficient graph condition for our algorithms to succeed; also, our tracking error bounds are smaller than that of the existing method. Furthermore, it is emphasized that even when agents do not use relays, our condition is tighter than the sufficient conditions in the literature. With multi-hop relays, we can further obtain more relaxed graph requirements. Finally, we present numerical examples to verify the effectiveness of our algorithms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5747\u503c\u5b50\u5e8f\u5217\u7ea6\u7b80\u7b97\u6cd5\u548c\u591a\u8df3\u901a\u4fe1\u7684\u5206\u5e03\u5f0f\u9886\u5bfc-\u8ddf\u968f\u5171\u8bc6\u534f\u8bae\uff0c\u63d0\u5347\u4e86\u6297\u654c\u80fd\u529b\u548c\u8ddf\u8e2a\u7cbe\u5ea6\uff0c\u56fe\u6761\u4ef6\u66f4\u5bbd\u677e\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u89e3\u51b3\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u5728\u5b58\u5728\u654c\u5bf9\u90bb\u5c45\u4f20\u64ad\u9519\u8bef\u4fe1\u606f\u60c5\u51b5\u4e0b\uff0c\u4fdd\u8bc1\u8ddf\u968f\u8005\u51c6\u786e\u8ddf\u8e2a\u52a8\u6001\u9886\u5bfc\u8005\u53c2\u8003\u503c\u7684\u9c81\u68d2\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5747\u503c\u5b50\u5e8f\u5217\u7ea6\u7b80\u7b97\u6cd5\uff0c\u7ed3\u5408\u591a\u8df3\u901a\u4fe1\u673a\u5236\uff0c\u5b9e\u73b0\u5206\u5e03\u5f0f\u534f\u8bae\uff0c\u4f7f\u975e\u6545\u969c\u8ddf\u968f\u8005\u5728\u5b58\u5728\u654c\u5bf9\u90bb\u5c45\u7684\u60c5\u51b5\u4e0b\u51c6\u786e\u8ddf\u8e2a\u52a8\u6001\u9886\u5bfc\u503c\u3002", "result": "\u672c\u6587\u9488\u5bf9\u591a\u667a\u80fd\u4f53\u7cfb\u7edf\u4e2d\u7684\u52a8\u6001\u9886\u5bfc-\u8ddf\u968f\u5171\u8bc6\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u5206\u5e03\u5f0f\u534f\u8bae\uff0c\u4f7f\u975e\u6545\u969c/\u6b63\u5e38\u7684\u8ddf\u968f\u8005\u80fd\u591f\u51c6\u786e\u8ddf\u8e2a\u9886\u5bfc\u8005\u7684\u52a8\u6001\u53c2\u8003\u503c\uff0c\u5373\u4f7f\u5b58\u5728\u654c\u5bf9\u90bb\u5c45\u4f20\u9012\u9519\u8bef\u4fe1\u606f\u3002\u65b9\u6cd5\u91c7\u7528\u5747\u503c\u5b50\u5e8f\u5217\u7ea6\u7b80\u7b97\u6cd5\u548c\u591a\u8df3\u901a\u4fe1\u673a\u5236\uff0c\u63a8\u5bfc\u51fa\u7b97\u6cd5\u6210\u529f\u7684\u5fc5\u8981\u548c\u5145\u5206\u7684\u56fe\u6761\u4ef6\uff0c\u5e76\u4e14\u8ddf\u8e2a\u8bef\u5dee\u754c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8be5\u6761\u4ef6\u5728\u65e0\u4e2d\u7ee7\u60c5\u51b5\u4e0b\u4e5f\u6bd4\u6587\u732e\u4e2d\u7684\u5145\u5206\u6761\u4ef6\u66f4\u7d27\u51d1\uff0c\u5229\u7528\u591a\u8df3\u4e2d\u7ee7\u53ef\u8fdb\u4e00\u6b65\u653e\u5bbd\u56fe\u7ed3\u6784\u8981\u6c42\u3002\u6700\u540e\u901a\u8fc7\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u7b97\u6cd5\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u52a8\u6001\u9886\u5bfc-\u8ddf\u968f\u5171\u8bc6\uff0c\u8ddf\u8e2a\u8bef\u5dee\u4f4e\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u56fe\u6761\u4ef6\u66f4\u4e3a\u7d27\u51d1\u4e14\u5177\u6709\u66f4\u597d\u7684\u6297\u654c\u6027\u80fd\uff0c\u591a\u8df3\u901a\u4fe1\u8fdb\u4e00\u6b65\u4f18\u5316\u56fe\u8981\u6c42\uff0c\u6570\u503c\u4eff\u771f\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.17813", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.17813", "abs": "https://arxiv.org/abs/2511.17813", "authors": ["Scott Merrill", "Shashank Srivastava"], "title": "Point of Order: Action-Aware LLM Persona Modeling for Realistic Civic Simulation", "comment": "8 pages (29 pages including appendix), 18 figures. Code and datasets are available at https://github.com/smerrillunc/action-aware-llms. Submitted to ACL 2026", "summary": "Large language models offer opportunities to simulate multi-party deliberation, but realistic modeling remains limited by a lack of speaker-attributed data. Transcripts produced via automatic speech recognition (ASR) assign anonymous speaker labels (e.g., Speaker_1), preventing models from capturing consistent human behavior. This work introduces a reproducible pipeline to transform public Zoom recordings into speaker-attributed transcripts with metadata like persona profiles and pragmatic action tags (e.g., [propose_motion]). We release three local government deliberation datasets: Appellate Court hearings, School Board meetings, and Municipal Council sessions. Fine-tuning LLMs to model specific participants using this \"action-aware\" data produces a 67% reduction in perplexity and nearly doubles classifier-based performance metrics for speaker fidelity and realism. Turing-style human evaluations show our simulations are often indistinguishable from real deliberations, providing a practical and scalable method for complex realistic civic simulations.", "AI": {"tldr": "\u901a\u8fc7\u5c06Zoom\u5f55\u97f3\u8f6c\u5f55\u4e3a\u5e26\u6709\u8bf4\u8bdd\u4eba\u8eab\u4efd\u548c\u884c\u4e3a\u6807\u7b7e\u7684\u6587\u672c\uff0c\u8bad\u7ec3\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u5bf9\u591a\u65b9\u8ba8\u8bba\u7684\u9ad8\u771f\u5b9e\u611f\u6a21\u62df\u3002", "motivation": "\u73b0\u6709\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u751f\u6210\u7684\u8f6c\u5f55\u6587\u672c\u4ec5\u6709\u533f\u540d\u8bf4\u8bdd\u4eba\u6807\u7b7e\uff0c\u65e0\u6cd5\u6355\u6349\u4e00\u81f4\u7684\u4eba\u7c7b\u884c\u4e3a\uff0c\u9650\u5236\u4e86\u591a\u65b9\u8ba8\u8bba\u6a21\u62df\u7684\u73b0\u5b9e\u6027\u3002", "method": "\u6784\u5efa\u53ef\u590d\u73b0\u7684\u7ba1\u9053\uff0c\u5c06\u516c\u5f00\u7684Zoom\u5f55\u97f3\u8f6c\u6362\u4e3a\u5e26\u6709\u8bf4\u8bdd\u4eba\u5f52\u5c5e\u7684\u8f6c\u5f55\u6587\u672c\uff0c\u5305\u542b\u89d2\u8272\u4fe1\u606f\u548c\u8bed\u7528\u884c\u4e3a\u6807\u7b7e\uff1b\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u4ee5\u7279\u5b9a\u53c2\u4e0e\u8005\u4e3a\u76ee\u6807\uff0c\u5229\u7528\u5e26\u6709'\u52a8\u4f5c\u611f\u77e5'\u7684\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u53d1\u5e03\u4e86\u4e09\u4e2a\u4eba\u653f\u5e9c\u8ba8\u8bba\u6570\u636e\u96c6\uff0c\u5fae\u8c03\u540e\u6a21\u578b\u56f0\u60d1\u5ea6\u964d\u4f4e67%\uff0c\u8bf4\u8bdd\u4eba\u5fe0\u5b9e\u5ea6\u548c\u771f\u5b9e\u611f\u7684\u5206\u7c7b\u6027\u80fd\u51e0\u4e4e\u7ffb\u500d\uff0c\u4e14\u901a\u8fc7\u56fe\u7075\u6d4b\u8bd5\u5f0f\u8bc4\u4f30\uff0c\u6a21\u62df\u4e0e\u771f\u5b9e\u8ba8\u8bba\u96be\u4ee5\u533a\u5206\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u590d\u6742\u4e14\u73b0\u5b9e\u7684\u516c\u6c11\u8ba8\u8bba\u6a21\u62df\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u9014\u5f84\uff0c\u663e\u8457\u63d0\u5347\u6a21\u578b\u5bf9\u53c2\u4e0e\u8005\u884c\u4e3a\u7684\u6355\u6349\u80fd\u529b\u548c\u6574\u4f53\u6a21\u62df\u8d28\u91cf\u3002"}}
{"id": "2511.18249", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18249", "abs": "https://arxiv.org/abs/2511.18249", "authors": ["Mostafijur Rahman Akhond", "Gias Uddin"], "title": "LLM Assisted Coding with Metamorphic Specification Mutation Agent", "comment": null, "summary": "Metamorphic Relations (MRs) serve as a foundational mechanism for generating semantically equivalent mutations. Software engineering has advanced significantly in recent years with the advent of Large Language Models (LLMs). However, the reliability of LLMs in software engineering is often compromised by ambiguities and inconsistencies due to improper user specification. To address this challenge, we present CodeMetaAgent (CMA), a metamorphic relation-driven LLM agent that systematically refines task specifications and generates semantically constrained test cases. Our proposed framework uses MRs with LLMs to improve generation consistency and reduce variability caused by specifications, unlike the traditional use of MRs as post validations. Our framework has been evaluated on the HumanEval-Pro, MBPP-Pro, and SWE-Bench_Lite datasets using the GPT-4o, Mistral Large, GPT-OSS, and Qwen3-Coder models. It improved code generation accuracy by up to 17% and achieved code coverage gains of up to 99.81%. These results show that metamorphic relations can be a simple but effective guide in assisting LLM-based software development.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u53d8\u5f62\u5173\u7cfb\u9a71\u52a8\u7684LLM\u4ee3\u7406CMA\uff0c\u901a\u8fc7\u7cbe\u70bc\u89c4\u683c\u548c\u751f\u6210\u53d7\u9650\u6d4b\u8bd5\u7528\u4f8b\uff0c\u663e\u8457\u63d0\u5347LLM\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u7684\u51c6\u786e\u6027\u548c\u8986\u76d6\u7387\uff0c\u9a8c\u8bc1\u4e86\u53d8\u5f62\u5173\u7cfb\u8f85\u52a9LLM\u8f6f\u4ef6\u5f00\u53d1\u7684\u6f5c\u529b\u3002", "motivation": "LLMs\u5728\u8f6f\u4ef6\u5de5\u7a0b\u4e2d\u7684\u5e94\u7528\u56e0\u7528\u6237\u89c4\u683c\u4e0d\u5f53\u5bfc\u81f4\u7684\u6b67\u4e49\u548c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\u5f71\u54cd\u53ef\u9760\u6027\uff0c\u4e9f\u9700\u4e00\u79cd\u65b9\u6cd5\u63d0\u5347\u89c4\u683c\u7684\u51c6\u786e\u6027\u548c\u751f\u6210\u7ed3\u679c\u7684\u4e00\u81f4\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53d8\u5f62\u5173\u7cfb\u7684LLM\u4ee3\u7406\u7cfb\u7edfCMA\uff0c\u8be5\u7cfb\u7edf\u7cfb\u7edf\u6027\u5730\u7ec6\u5316\u4efb\u52a1\u89c4\u683c\u5e76\u751f\u6210\u8bed\u4e49\u53d7\u9650\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5c06\u53d8\u5f62\u5173\u7cfb\u4e0eLLM\u7ed3\u5408\uff0c\u4ece\u800c\u63d0\u9ad8\u751f\u6210\u4e00\u81f4\u6027\uff0c\u51cf\u5c11\u56e0\u89c4\u683c\u4ea7\u751f\u7684\u53d8\u5f02\u6027\uff0c\u533a\u522b\u4e8e\u4f20\u7edf\u5c06\u53d8\u5f62\u5173\u7cfb\u4ec5\u7528\u4e8e\u540e\u671f\u9a8c\u8bc1\u7684\u65b9\u6cd5\u3002", "result": "\u5728HumanEval-Pro\u3001MBPP-Pro\u548cSWE-Bench_Lite\u6570\u636e\u96c6\u4e0a\uff0c\u7ed3\u5408GPT-4o\u3001Mistral Large\u3001GPT-OSS\u548cQwen3-Coder\u7b49\u6a21\u578b\uff0cCMA\u6846\u67b6\u6700\u9ad8\u63d0\u5347\u4ee3\u7801\u751f\u6210\u51c6\u786e\u738717%\uff0c\u4ee3\u7801\u8986\u76d6\u7387\u6700\u9ad8\u8fbe99.81%\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684CodeMetaAgent\uff08CMA\uff09\u6846\u67b6\u901a\u8fc7\u5229\u7528\u53d8\u5f62\u5173\u7cfb\u9a71\u52a8\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4ee3\u7801\u751f\u6210\u7684\u51c6\u786e\u6027\u548c\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u9a8c\u8bc1\u4e86\u53d8\u5f62\u5173\u7cfb\u5728\u8f85\u52a9\u57fa\u4e8eLLM\u7684\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.17854", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.17854", "abs": "https://arxiv.org/abs/2511.17854", "authors": ["Allen Roush", "Devin Gonier", "John Hines", "Judah Goldfeder", "Philippe Martin Wyder", "Sanjay Basu", "Ravid Shwartz Ziv"], "title": "A superpersuasive autonomous policy debating system", "comment": "Accepted to CLIP workshop at AAAI 2026", "summary": "The capacity for highly complex, evidence-based, and strategically adaptive persuasion remains a formidable great challenge for artificial intelligence. Previous work, like IBM Project Debater, focused on generating persuasive speeches in simplified and shortened debate formats intended for relatively lay audiences. We introduce DeepDebater, a novel autonomous system capable of participating in and winning a full, unmodified, two-team competitive policy debate. Our system employs a hierarchical architecture of specialized multi-agent workflows, where teams of LLM-powered agents collaborate and critique one another to perform discrete argumentative tasks. Each workflow utilizes iterative retrieval, synthesis, and self-correction using a massive corpus of policy debate evidence (OpenDebateEvidence) and produces complete speech transcripts, cross-examinations, and rebuttals. We introduce a live, interactive end-to-end presentation pipeline that renders debates with AI speech and animation: transcripts are surface-realized and synthesized to audio with OpenAI TTS, and then displayed as talking-head portrait videos with EchoMimic V1. Beyond fully autonomous matches (AI vs AI), DeepDebater supports hybrid human-AI operation: human debaters can intervene at any stage, and humans can optionally serve as opponents against AI in any speech, allowing AI-human and AI-AI rounds. In preliminary evaluations against human-authored cases, DeepDebater produces qualitatively superior argumentative components and consistently wins simulated rounds as adjudicated by an independent autonomous judge. Expert human debate coaches also prefer the arguments, evidence, and cases constructed by DeepDebater. We open source all code, generated speech transcripts, audio and talking head video here: https://github.com/Hellisotherpeople/DeepDebater/tree/main", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDeepDebater\uff0c\u4e00\u4e2a\u57fa\u4e8e\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u7684AI\u8fa9\u8bba\u7cfb\u7edf\uff0c\u80fd\u5b8c\u6210\u5b8c\u6574\u590d\u6742\u653f\u7b56\u8fa9\u8bba\u5e76\u80dc\u51fa\uff0c\u8868\u73b0\u4f18\u4e8e\u4eba\u7c7b\u5bf9\u624b\u548c\u4e13\u4e1a\u6559\u7ec3\u8bc4\u4ef7\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u5728\u8fdb\u884c\u590d\u6742\u3001\u57fa\u4e8e\u8bc1\u636e\u548c\u7b56\u7565\u9002\u5e94\u7684\u8bf4\u670d\u65b9\u9762\u4ecd\u9762\u4e34\u5de8\u5927\u6311\u6218\uff0c\u4ee5\u5f80\u5de5\u4f5c\u5982IBM Project Debater\u4e3b\u8981\u9488\u5bf9\u7b80\u5316\u4e14\u9488\u5bf9\u666e\u901a\u89c2\u4f17\u7684\u8fa9\u8bba\u683c\u5f0f\u3002", "method": "\u63d0\u51fa\u4e86DeepDebater\u7cfb\u7edf\uff0c\u91c7\u7528\u5c42\u7ea7\u5316\u7684\u591a\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u67b6\u6784\uff0c\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u4e0e\u6279\u5224\u5b8c\u6210\u5404\u4e2a\u8bba\u8bc1\u4efb\u52a1\uff0c\u7ed3\u5408\u5927\u89c4\u6a21\u8fa9\u8bba\u8bc1\u636e\u5e93\u8fdb\u884c\u8fed\u4ee3\u68c0\u7d22\u3001\u7efc\u5408\u4e0e\u81ea\u6211\u7ea0\u6b63\uff0c\u751f\u6210\u5b8c\u6574\u6f14\u8bb2\u7a3f\u3001\u4ea4\u53c9\u8d28\u8be2\u548c\u53cd\u9a73\u3002\u7cfb\u7edf\u8fd8\u652f\u6301\u5b9e\u65f6\u8bed\u97f3\u5408\u6210\u548c\u52a8\u753b\u5c55\u793a\uff0c\u652f\u6301AI\u5bf9AI\u3001AI\u5bf9\u4eba\u7c7b\u53ca\u6df7\u5408\u64cd\u4f5c\u3002", "result": "DeepDebater\u5728\u4eba\u5de5\u7f16\u5199\u7684\u8fa9\u9898\u4e0a\u51fa\u5177\u7684\u8bba\u8bc1\u66f4\u5177\u8d28\u91cf\uff0c\u80fd\u5728\u6a21\u62df\u6bd4\u8d5b\u4e2d\u6301\u7eed\u83b7\u80dc\uff0c\u4e14\u88ab\u4e13\u4e1a\u8fa9\u8bba\u6559\u7ec3\u4f18\u9009\u3002", "conclusion": "DeepDebater\u6210\u529f\u5b9e\u73b0\u4e86\u80fd\u591f\u72ec\u7acb\u53c2\u4e0e\u5e76\u8d62\u5f97\u5b8c\u6574\u653f\u7b56\u8fa9\u8bba\u7684AI\u7cfb\u7edf\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fa9\u8bbaAI\u7684\u590d\u6742\u6027\u548c\u8868\u73b0\uff0c\u5e76\u652f\u6301\u5f00\u6e90\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.18288", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18288", "abs": "https://arxiv.org/abs/2511.18288", "authors": ["Wenhan Wang", "Kaibo Liu", "Zeyu Sun", "An Ran Chen", "Ge Li", "Gang Huang", "Lei Ma"], "title": "Can Large Language Models Solve Path Constraints in Symbolic Execution?", "comment": null, "summary": "Symbolic execution is an important software analysis technique which benefits downstream tasks such as software testing and debugging. However, several limitations hinder symbolic execution from application on real-world software. One of the limitations is the inability to solve diverse execution path constraints: traditional symbolic execution based on SMT solvers is difficult to handle execution paths with complex data structures or external API calls. In this paper, we focus on investigating the possibility of adopting large language models (LLM) for path constraint solving instead of traditional solver-based techniques in symbolic execution. We conduct an empirical study to evaluate the ability of LLMs in two types of path constraint solving: generating test inputs to facilitate an execution path, and determining whether a given execution path can be satisfied without triggering any bugs. We build new evaluation pipelines and benchmarks for two tasks: test case generation and path classification, which include data sources from both competition-level programs and real-world repositories. Our experiment results show that state-of-the-art LLMs are able to solve path constraints in both generation and classification tasks, with 60% of generated test cases that accurately cover the given execution path. Moreover, LLMs are capable of improving test coverage by covering execution paths in real-world repositories where traditional symbolic execution tools cannot be applied. These findings highlight the possibility of extending symbolic execution techniques with LLMs in the future to improve the ability and generalizability of symbolic execution.", "AI": {"tldr": "\u672c\u6587\u63a2\u7d22\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u66ff\u4f20\u7edf\u6c42\u89e3\u5668\u89e3\u51b3\u7b26\u53f7\u6267\u884c\u8def\u5f84\u7ea6\u675f\uff0c\u5b9e\u9a8c\u8868\u660eLLM\u80fd\u6709\u6548\u751f\u6210\u548c\u5206\u7c7b\u8def\u5f84\u6d4b\u8bd5\u7528\u4f8b\uff0c\u63d0\u5347\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u4fc3\u8fdb\u7b26\u53f7\u6267\u884c\u6280\u672f\u53d1\u5c55\u3002", "motivation": "\u7b26\u53f7\u6267\u884c\u5728\u5b9e\u9645\u8f6f\u4ef6\u5206\u6790\u4e2d\u53d7\u9650\u4e8e\u4f20\u7edfSMT\u6c42\u89e3\u5668\u96be\u4ee5\u5904\u7406\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u5916\u90e8API\u8c03\u7528\u7684\u8def\u5f84\u7ea6\u675f\uff0c\u63a2\u7d22LLM\u5e94\u7528\u4ee5\u7a81\u7834\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u672c\u6587\u91c7\u7528\u5b9e\u8bc1\u7814\u7a76\u65b9\u6cd5\uff0c\u8bbe\u8ba1\u4e86\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u548c\u8def\u5f84\u5206\u7c7b\u7684\u8bc4\u4f30\u6d41\u7a0b\u53ca\u57fa\u51c6\uff0c\u5229\u7528LLM\u6765\u6c42\u89e3\u8def\u5f84\u7ea6\u675f\uff0c\u6db5\u76d6\u7ade\u8d5b\u7ea7\u7a0b\u5e8f\u548c\u771f\u5b9e\u4ed3\u5e93\u7684\u6d4b\u8bd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0cLLM\u5728\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u548c\u8def\u5f84\u5206\u7c7b\u4efb\u52a1\u4e2d\u5747\u8868\u73b0\u826f\u597d\uff0c\u4ea7\u751f\u7684\u6d4b\u8bd5\u7528\u4f8b\u670960%\u51c6\u786e\u8986\u76d6\u7ed9\u5b9a\u8def\u5f84\uff0c\u5e76\u80fd\u63d0\u5347\u771f\u5b9e\u4e16\u754c\u8f6f\u4ef6\u7684\u6d4b\u8bd5\u8986\u76d6\u80fd\u529b\u3002", "conclusion": "\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u7b26\u53f7\u6267\u884c\u8def\u5f84\u7ea6\u675f\u6c42\u89e3\u5c55\u793a\u51fa\u8f83\u5f3a\u80fd\u529b\uff0c\u80fd\u591f\u751f\u6210\u51c6\u786e\u8986\u76d6\u6267\u884c\u8def\u5f84\u7684\u6d4b\u8bd5\u7528\u4f8b\u5e76\u533a\u5206\u8def\u5f84\u662f\u5426\u53ef\u6ee1\u8db3\uff0c\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u7387\uff0c\u7279\u522b\u662f\u5728\u4f20\u7edf\u7b26\u53f7\u6267\u884c\u5de5\u5177\u96be\u4ee5\u5e94\u7528\u7684\u771f\u5b9e\u8f6f\u4ef6\u4e2d\u3002"}}
{"id": "2511.18259", "categories": ["cs.CL", "cs.MA"], "pdf": "https://arxiv.org/pdf/2511.18259", "abs": "https://arxiv.org/abs/2511.18259", "authors": ["Xiaochen Zheng", "Alvaro Serra", "Ilya Schneider Chernov", "Maddalena Marchesi", "Eunice Musvasva", "Tatyana Y. Doktorova"], "title": "From Archives to Decisions: Multi-Agent Pharmaceutical Co-Scientist for Traceable Drug Discovery and Reverse Translation", "comment": "22 pages, 4 figures, 3 tables", "summary": "Pharmaceutical research and development has accumulated vast, heterogeneous archives of data. Much of this knowledge stems from discontinued programs, and reusing these archives is invaluable for reverse translation. However, in practice, such reuse is often infeasible. In this work, we introduce DiscoVerse, a multi-agent co-scientist designed to support pharmaceutical research and development. The system implements semantic retrieval, cross-document linking, and auditable synthesis on a large historical corpus from Roche. To validate our approach at real-world scale, we selected a subset of 180 molecules from the Roche research repositories, covering over 0.87 billion BPE tokens and more than four decades of research. Given that automated evaluation metrics are poorly aligned with scientific utility, we evaluate the performance of DiscoVerse using blinded expert evaluation of source-linked outputs. To our knowledge, this is the first agentic framework systematically assessed on real pharmaceutical data for reverse translation, enabled by authorized access to confidential, end-to-end drug-development archives. Our contributions include role-specialized agent designs aligned with scientist workflows; human-in-the-loop support for reverse translation; expert evaluation; and a large-scale demonstration showing promising answer accuracy and decision-making insights. In brief, across seven benchmark queries covering 180 molecules, DiscoVerse achieved near-perfect recall ($\\geq 0.99$) with moderate precision ($0.71-0.91$), while qualitative assessments of discontinuation rationale and organ-specific toxicity showed faithful, source-linked synthesis across preclinical and clinical evidence.", "AI": {"tldr": "DiscoVerse\u591a\u4ee3\u7406\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u5bf9\u771f\u5b9e\u5927\u89c4\u6a21\u836f\u7269\u7814\u53d1\u5386\u53f2\u6863\u6848\u7684\u9006\u5411\u8f6c\u5316\u652f\u6301\uff0c\u5c55\u793a\u4e86\u9ad8\u53ec\u56de\u7387\u53ca\u5408\u7406\u7684\u7cbe\u786e\u7387\uff0c\u5e76\u901a\u8fc7\u4e13\u5bb6\u76f2\u8bc4\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u548c\u7ed3\u679c\u7684\u79d1\u5b66\u4ef7\u503c\u3002", "motivation": "\u836f\u7269\u7814\u53d1\u4ea7\u751f\u5927\u91cf\u5f02\u6784\u4e14\u4e30\u5bcc\u7684\u5386\u53f2\u6570\u636e\uff0c\u5c24\u5176\u662f\u505c\u6ede\u9879\u76ee\u7684\u6570\u636e\uff0c\u5408\u7406\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u5bf9\u9006\u5411\u8f6c\u5316\u6781\u5176\u91cd\u8981\uff0c\u4f46\u5b9e\u9645\u4e2d\u96be\u4ee5\u9ad8\u6548\u590d\u7528\u3002", "method": "\u8bbe\u8ba1\u4e86\u591a\u4ee3\u7406\u7cfb\u7edfDiscoVerse\uff0c\u5b9e\u65bd\u8bed\u4e49\u68c0\u7d22\u3001\u8de8\u6587\u6863\u94fe\u63a5\u548c\u53ef\u5ba1\u8ba1\u5408\u6210\u4ee5\u652f\u6301\u836f\u7269\u7814\u53d1\u4e2d\u7684\u9006\u5411\u8f6c\u5316\u3002", "result": "\u5728\u5305\u542b0.87\u4ebfBPE\u8bcd\u5143\u3001\u8de8\u8d8a40\u4f59\u5e74\u6570\u636e\u7684Roche\u836f\u7269\u7814\u53d1\u6863\u6848\u4e2d\u9009\u53d6180\u5206\u5b50\u4e3a\u6d4b\u8bd5\uff0cDiscoVerse\u5728\u4e03\u4e2a\u57fa\u51c6\u67e5\u8be2\u4e2d\u53ec\u56de\u7387\u63a5\u8fd1\u6ee1\u5206\uff08\u22650.99\uff09\uff0c\u7cbe\u786e\u7387\u4e2d\u7b49\uff080.71-0.91\uff09\uff0c\u5e76\u5728\u505c\u836f\u539f\u56e0\u548c\u5668\u5b98\u7279\u5f02\u6027\u6bd2\u6027\u7b49\u65b9\u9762\u5b9e\u73b0\u4e86\u5fe0\u5b9e\u3001\u6e90\u6570\u636e\u5173\u8054\u7684\u7efc\u5408\u5206\u6790\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u9996\u6b21\u5728\u771f\u5b9e\u7684\u4fdd\u5bc6\u836f\u7269\u7814\u53d1\u6570\u636e\u4e0a\u7cfb\u7edf\u5316\u8bc4\u4f30\u4e86\u591a\u4ee3\u7406\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u4e0e\u79d1\u5b66\u5de5\u4f5c\u6d41\u7a0b\u76f8\u9002\u5e94\u7684\u89d2\u8272\u4ee3\u7406\u8bbe\u8ba1\u548c\u4eba\u673a\u534f\u540c\u9006\u5411\u8f6c\u5316\u652f\u6301\uff0c\u5c55\u793a\u4e86\u81ea\u52a8\u5316\u79d1\u5b66\u7814\u7a76\u8f85\u52a9\u7684\u65b0\u53ef\u80fd\u6027\u3002"}}
{"id": "2511.17908", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.17908", "abs": "https://arxiv.org/abs/2511.17908", "authors": ["Debashish Chakraborty", "Eugene Yang", "Daniel Khashabi", "Dawn Lawrie", "Kevin Duh"], "title": "Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction", "comment": "Preprint", "summary": "Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.", "AI": {"tldr": "\u901a\u8fc7\u7b26\u5408\u9884\u6d4b\u5b9e\u73b0\u5bf9\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u4e2d\u4e0a\u4e0b\u6587\u7684\u8986\u76d6\u63a7\u5236\u8fc7\u6ee4\uff0c\u663e\u8457\u51cf\u5c11\u5197\u4f59\u5185\u5bb9\u5e76\u63d0\u5347\u6216\u4fdd\u6301\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4e3a\u4e0a\u4e0b\u6587\u5de5\u7a0b\u63d0\u4f9b\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u4e14\u6709\u7edf\u8ba1\u4fdd\u8bc1\u7684\u65b9\u6cd5\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u957f\u6216\u566a\u58f0\u8f83\u591a\u7684\u4e0a\u4e0b\u6587\u65f6\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u4f20\u7edf\u7684\u8fc7\u6ee4\u65b9\u6cd5\u7f3a\u4e4f\u7edf\u8ba1\u63a7\u5236\uff0c\u65e0\u6cd5\u4fdd\u8bc1\u91cd\u8981\u8bc1\u636e\u7684\u4fdd\u7559\u3002", "method": "\u91c7\u7528\u7b26\u5408\u9884\u6d4b\uff08conformal prediction\uff09\u4f5c\u4e3a\u8986\u76d6\u63a7\u5236\u8fc7\u6ee4\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u4e8e\u5d4c\u5165\u548c\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bc4\u5206\u51fd\u6570\uff0c\u5bf9\u68c0\u7d22\u51fa\u7684\u4e0a\u4e0b\u6587\u5185\u5bb9\u8fdb\u884c\u8fc7\u6ee4\u3002", "result": "\u7b26\u5408\u9884\u6d4b\u8fc7\u6ee4\u65b9\u6cd5\u80fd\u6709\u6548\u63a7\u5236\u8986\u76d6\u7387\uff0c\u4fdd\u7559\u6307\u5b9a\u6bd4\u4f8b\u7684\u76f8\u5173\u7247\u6bb5\uff0c\u540c\u65f6\u5c06\u4fdd\u7559\u7684\u4e0a\u4e0b\u6587\u51cf\u5c112-3\u500d\u3002NeuCLIR\u6570\u636e\u96c6\u4e0a\u4e25\u683c\u8fc7\u6ee4\u4e0b\u4e0b\u6e38\u4e8b\u5b9e\u51c6\u786e\u7387\u63d0\u5347\uff0c\u9002\u5ea6\u8fc7\u6ee4\u4fdd\u6301\u7a33\u5b9a\uff0c\u8868\u660e\u4e22\u5f03\u5185\u5bb9\u591a\u4e3a\u5197\u4f59\u6216\u65e0\u5173\u4fe1\u606f\u3002", "conclusion": "\u7b26\u5408\u9884\u6d4b\u8fc7\u6ee4\u4e3aRAG\u6a21\u578b\u7684\u4e0a\u4e0b\u6587\u7f29\u51cf\u63d0\u4f9b\u4e86\u53ef\u9760\u4e14\u53d7\u63a7\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u53bb\u9664\u4e86\u65e0\u5173\u5185\u5bb9\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u4e14\u9002\u7528\u4e0d\u540c\u6a21\u578b\uff0c\u5177\u5907\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18343", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18343", "abs": "https://arxiv.org/abs/2511.18343", "authors": ["Dongming Jin", "Zhi Jin", "Xiaohong Chen", "Zheng Fang", "Linyu Li", "Yuanpeng He", "Jia Li", "Yirang Zhang", "Yingtao Fang"], "title": "A Needle in a Haystack: Intent-driven Reusable Artifacts Recommendation with LLMs", "comment": "15 pages, 7 figures", "summary": "In open source software development, the reuse of existing artifacts has been widely adopted to avoid redundant implementation work. Reusable artifacts are considered more efficient and reliable than developing software components from scratch. However, when faced with a large number of reusable artifacts, developers often struggle to find artifacts that can meet their expected needs. To reduce this burden, retrieval-based and learning-based techniques have been proposed to automate artifact recommendations. Recently, Large Language Models (LLMs) have shown the potential to understand intentions, perform semantic alignment, and recommend usable artifacts. Nevertheless, their effectiveness has not been thoroughly explored. To fill this gap, we construct an intent-driven artifact recommendation benchmark named IntentRecBench, covering three representative open source ecosystems. Using IntentRecBench, we conduct a comprehensive comparative study of five popular LLMs and six traditional approaches in terms of precision and efficiency. Our results show that although LLMs outperform traditional methods, they still suffer from low precision and high inference cost due to the large candidate space. Inspired by the ontology-based semantic organization in software engineering, we propose TreeRec, a feature tree-guided recommendation framework to mitigate these issues. TreeRec leverages LLM-based semantic abstraction to organize artifacts into a hierarchical semantic tree, enabling intent and function alignment and reducing reasoning time. Extensive experiments demonstrate that TreeRec consistently improves the performance of diverse LLMs across ecosystems, highlighting its generalizability and potential for practical deployment.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86IntentRecBench\u57fa\u51c6\u53ca\u7279\u5f81\u6811\u5f15\u5bfc\u7684TreeRec\u63a8\u8350\u6846\u67b6\uff0c\u5229\u7528LLM\u8bed\u4e49\u80fd\u529b\u63d0\u5347\u5f00\u6e90\u8f6f\u4ef6\u6784\u4ef6\u63a8\u8350\u7684\u51c6\u786e\u7387\u4e0e\u6548\u7387\uff0c\u89e3\u51b3\u4e86LLM\u4f4e\u7cbe\u5ea6\u3001\u9ad8\u63a8\u7406\u5f00\u9500\u7684\u95ee\u9898\u3002", "motivation": "\u9762\u5bf9\u5f00\u6e90\u8f6f\u4ef6\u4e2d\u5927\u91cf\u53ef\u590d\u7528\u6784\u4ef6\uff0c\u5f00\u53d1\u8005\u96be\u4ee5\u9ad8\u6548\u51c6\u786e\u5730\u627e\u5230\u6ee1\u8db3\u9700\u6c42\u7684\u6784\u4ef6\uff0c\u73b0\u6709\u57fa\u4e8e\u68c0\u7d22\u548c\u673a\u5668\u5b66\u4e60\u7684\u63a8\u8350\u65b9\u6cd5\u6548\u679c\u6709\u9650\uff1b\u5927\u8bed\u8a00\u6a21\u578b\u867d\u6709\u6f5c\u529b\u4f46\u5c1a\u672a\u5145\u5206\u9a8c\u8bc1\u5176\u6027\u80fd\uff0c\u6709\u5fc5\u8981\u6784\u5efa\u57fa\u51c6\u5e76\u8bbe\u8ba1\u65b0\u7684\u63a8\u8350\u6846\u67b6\u63d0\u5347\u6027\u80fd\u3002", "method": "\u672c\u6587\u901a\u8fc7\u6784\u5efaIntentRecBench\u57fa\u51c6\u6d4b\u8bd5\u4e0d\u540c\u63a8\u8350\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86TreeRec\u6846\u67b6\uff0c\u5229\u7528LLM\u8fdb\u884c\u8bed\u4e49\u62bd\u8c61\uff0c\u5c06\u6784\u4ef6\u7ec4\u7ec7\u4e3a\u5c42\u7ea7\u7279\u5f81\u6811\uff0c\u5b9e\u73b0\u610f\u56fe\u4e0e\u529f\u80fd\u5bf9\u9f50\uff0c\u51cf\u5c11\u63a8\u7406\u65f6\u95f4\uff0c\u63d0\u5347\u63a8\u8350\u6027\u80fd\u3002", "result": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u9762\u5411\u610f\u56fe\u9a71\u52a8\u7684\u5f00\u6e90\u8f6f\u4ef6\u6784\u4ef6\u63a8\u8350\u57fa\u51c6\u6570\u636e\u96c6IntentRecBench\uff0c\u8986\u76d6\u4e86\u4e09\u4e2a\u4ee3\u8868\u6027\u7684\u5f00\u6e90\u751f\u6001\uff0c\u7cfb\u7edf\u6bd4\u8f83\u4e86\u4e94\u79cd\u4e3b\u6d41\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e0e\u516d\u79cd\u4f20\u7edf\u63a8\u8350\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u867d\u7136LLM\u8868\u73b0\u66f4\u4f18\u4f46\u4ecd\u5b58\u5728\u7cbe\u5ea6\u4f4e\u548c\u63a8\u7406\u8017\u65f6\u9ad8\u7684\u95ee\u9898\u3002\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u57fa\u4e8e\u7279\u5f81\u6811\u7684\u63a8\u8350\u6846\u67b6TreeRec\uff0c\u5229\u7528LLM\u7684\u8bed\u4e49\u62bd\u8c61\u80fd\u529b\u6784\u5efa\u5c42\u7ea7\u8bed\u4e49\u6811\u5b9e\u73b0\u9700\u6c42\u610f\u56fe\u4e0e\u6784\u4ef6\u529f\u80fd\u7684\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u8350\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "TreeRec\u901a\u8fc7\u6784\u5efa\u5c42\u7ea7\u8bed\u4e49\u6811\u5b9e\u73b0\u610f\u56fe\u9a71\u52a8\u7684\u6784\u4ef6\u63a8\u8350\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u8350\u7684\u7cbe\u5ea6\u548c\u6548\u7387\uff0c\u5177\u5907\u826f\u597d\u7684\u6cdb\u5316\u6027\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2511.17910", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17910", "abs": "https://arxiv.org/abs/2511.17910", "authors": ["Yuliang Zhan", "Xinyu Tang", "Han Wan", "Jian Li", "Ji-Rong Wen", "Hao Sun"], "title": "L2V-CoT: Cross-Modal Transfer of Chain-of-Thought Reasoning via Latent Intervention", "comment": "AAAI 2026 oral", "summary": "Recently, Chain-of-Thought (CoT) reasoning has significantly enhanced the capabilities of large language models (LLMs), but Vision-Language Models (VLMs) still struggle with multi-step reasoning tasks due to limited multimodal reasoning data. To bridge this gap, researchers have explored methods to transfer CoT reasoning from LLMs to VLMs. However, existing approaches either need high training costs or require architectural alignment. In this paper, we use Linear Artificial Tomography (LAT) to empirically show that LLMs and VLMs share similar low-frequency latent representations of CoT reasoning despite architectural differences. Based on this insight, we propose L2V-CoT, a novel training-free latent intervention approach that transfers CoT reasoning from LLMs to VLMs. L2V-CoT extracts and resamples low-frequency CoT representations from LLMs in the frequency domain, enabling dimension matching and latent injection into VLMs during inference to enhance reasoning capabilities. Extensive experiments demonstrate that our approach consistently outperforms training-free baselines and even surpasses supervised methods.", "AI": {"tldr": "\u672c\u6587\u53d1\u73b0LLMs\u548cVLMs\u5728CoT\u63a8\u7406\u7684\u4f4e\u9891\u6f5c\u5728\u8868\u793a\u4e0a\u5177\u6709\u76f8\u4f3c\u6027\uff0c\u57fa\u4e8e\u6b64\u63d0\u51faL2V-CoT\uff0c\u5b9e\u73b0\u4e86\u96f6\u8bad\u7ec3\u6210\u672c\u7684\u63a8\u7406\u80fd\u529b\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u4e0d\u8db3\uff0c\u4e14\u73b0\u6709CoT\u63a8\u7406\u8fc1\u79fb\u65b9\u6cd5\u5b58\u5728\u8bad\u7ec3\u6210\u672c\u9ad8\u6216\u9700\u8981\u67b6\u6784\u5bf9\u9f50\u7684\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u4e2a\u9ad8\u6548\u4e14\u901a\u7528\u7684\u63a8\u7406\u8fc1\u79fb\u65b9\u6cd5\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86L2V-CoT\uff0c\u4e00\u79cd\u57fa\u4e8e\u7ebf\u6027\u4eba\u5de5\u65ad\u5c42\u6210\u50cf\uff08LAT\uff09\u7684\u8bad\u7ec3\u514d\u8d39\u6f5c\u5728\u5e72\u9884\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u548c\u91cd\u91c7\u6837LLMs\u4e2d\u7684\u4f4e\u9891CoT\u8868\u793a\uff0c\u5b9e\u73b0\u4e86\u7ef4\u5ea6\u5339\u914d\u5e76\u5c06\u5176\u6ce8\u5165VLMs\u63a8\u7406\u9636\u6bb5\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cL2V-CoT\u5728\u65e0\u9700\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\uff0c\u4e0d\u4ec5\u4f18\u4e8e\u5176\u4ed6\u8bad\u7ec3\u514d\u8d39\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8fd8\u8d85\u8fc7\u4e86\u90e8\u5206\u6709\u76d1\u7763\u65b9\u6cd5\uff0c\u660e\u663e\u63d0\u5347\u4e86VLM\u7684\u591a\u6b65\u9aa4\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "L2V-CoT\u65b9\u6cd5\u901a\u8fc7\u5728\u9891\u57df\u4e2d\u63d0\u53d6\u548c\u6ce8\u5165\u4f4e\u9891\u7684Chain-of-Thought\u63a8\u7406\u8868\u793a\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u4ece\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5411\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u63a8\u7406\u80fd\u529b\u8fc1\u79fb\uff0c\u663e\u8457\u63d0\u5347\u4e86VLMs\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002"}}
{"id": "2511.18488", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18488", "abs": "https://arxiv.org/abs/2511.18488", "authors": ["Samuel Ackerman", "Wesam Ibraheem", "Orna Raz", "Marcel Zalmanovici"], "title": "Evaluating perturbation robustnessof generative systems that use COBOL code inputs", "comment": "16 pages (8 main, 8 appendix). Accepted to AI-SQE (ICSE, 2026): The 1st International Workshop on AI for Software Quality Evaluation: Judgment, Metrics, Benchmarks, and Beyond", "summary": "Systems incorporating large language models (LLMs) as a component are known to be sensitive (i.e., non-robust) to minor input variations that do not change the meaning of the input; such sensitivity may reduce the system's usefulness. Here, we present a framework to evaluate robustness of systems using COBOL code as input; our application is translation between COBOL and Java programming languages, but the approach extends to other tasks such as code generation or explanation. Targeting robustness of systems with COBOL as input is essential yet challenging. Many business-critical applications are written in COBOL, yet these are typically proprietary legacy applications and their code is unavailable to LLMs for training. We develop a library of COBOL paragraph and full-program perturbation methods, and create variant-expanded versions of a benchmark dataset of examples for a specific task. The robustness of the LLM-based system is evaluated by measuring changes in values of individual and aggregate metrics calculated on the system's outputs. Finally, we present a series of dynamic table and chart visualization dashboards that assist in debugging the system's outputs, and monitoring and understanding root causes of the system's sensitivity to input variation. These tools can be further used to improve the system by, for instance, indicating variations that should be handled by pre-processing steps.", "AI": {"tldr": "\u4ed6\u4eec\u63d0\u51fa\u4e86\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406COBOL\u4ee3\u7801\u65f6\u7a33\u5065\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u8f93\u5165\u6270\u52a8\u548c\u6570\u636e\u96c6\u6269\u5c55\uff0c\u7ed3\u5408\u52a8\u6001\u53ef\u89c6\u5316\u5de5\u5177\uff0c\u5e2e\u52a9\u53d1\u73b0\u548c\u6539\u8fdb\u6a21\u578b\u5bf9\u8f93\u5165\u7ec6\u5fae\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "motivation": "\u5f53\u524d\u7cfb\u7edf\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5bf9\u8f93\u5165\u7684\u7ec6\u5fae\u53d8\u5316\u975e\u5e38\u654f\u611f\uff0c\u8fd9\u79cd\u654f\u611f\u6027\u5f71\u54cd\u4e86\u7cfb\u7edf\u7684\u7a33\u5065\u6027\u548c\u5b9e\u7528\u6027\u3002\u9488\u5bf9\u5546\u4e1a\u5173\u952e\u7684COBOL\u4ee3\u7801\uff0c\u7f3a\u4e4f\u516c\u5f00\u8bad\u7ec3\u6570\u636e\uff0c\u66f4\u52a0\u5267\u4e86\u7a33\u5065\u6027\u8bc4\u4f30\u7684\u96be\u5ea6\u3002", "method": "\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u5229\u7528\u5bf9COBOL\u4ee3\u7801\u8fdb\u884c\u6270\u52a8\uff08\u6bb5\u843d\u53ca\u5168\u7a0b\u5e8f\u7ea7\u522b\uff09\uff0c\u6784\u5efa\u53d8\u5f02\u7248\u672c\u7684\u57fa\u51c6\u6570\u636e\u96c6\uff0c\u8bc4\u4f30LLM\u7cfb\u7edf\u5728COBOL\u4e0eJava\u7ffb\u8bd1\u4efb\u52a1\u4e2d\u7684\u7a33\u5065\u6027\u3002\u540c\u65f6\u5f00\u53d1\u52a8\u6001\u53ef\u89c6\u5316\u4eea\u8868\u76d8\u8f85\u52a9\u8c03\u8bd5\u548c\u5206\u6790\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u91cf\u5316\u7cfb\u7edf\u5bf9COBOL\u8f93\u5165\u7ec6\u5fae\u53d8\u5316\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u53ef\u89c6\u5316\u5de5\u5177\u5e2e\u52a9\u5b9a\u4f4d\u95ee\u9898\u6839\u6e90\uff0c\u652f\u6301\u540e\u7eed\u7cfb\u7edf\u6539\u8fdb\uff0c\u63d0\u5347\u7a33\u5065\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u9488\u5bf9COBOL\u4ee3\u7801\u8f93\u5165\u7684\u7a33\u5065\u6027\u8bc4\u4f30\u6846\u67b6\u53ca\u5de5\u5177\uff0c\u4e3aLLM\u7cfb\u7edf\u5728\u5904\u7406\u5546\u4e1a\u5173\u952e\u9886\u57df\u4ee3\u7801\u8f6c\u6362\u4efb\u52a1\u4e2d\u63d0\u5347\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u5b9e\u7528\u624b\u6bb5\u3002"}}
{"id": "2511.17923", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17923", "abs": "https://arxiv.org/abs/2511.17923", "authors": ["Wenda Li", "Tongya Zheng", "Shunyu Liu", "Yu Wang", "Kaixuan Chen", "Hanyang Yuan", "Bingde Hu", "Zujie Ren", "Mingli Song", "Gang Chen"], "title": "Towards Efficient LLM-aware Heterogeneous Graph Learning", "comment": null, "summary": "Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.", "AI": {"tldr": "\u63d0\u51faELLA\u6846\u67b6\u9ad8\u6548\u5229\u7528LLM\u89e3\u51b3\u5f02\u6784\u56fe\u4e2d\u590d\u6742\u5173\u7cfb\u8bed\u4e49\u548c\u8bed\u4e49\u9e3f\u6c9f\u95ee\u9898\uff0c\u63d0\u5347\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u5f02\u6784\u56fe\u4e2d\u5173\u7cfb\u8bed\u4e49\u590d\u6742\u4e14\u9884\u5b9a\u4e49\u8bed\u4e49\u548c\u76d1\u7763\u4fe1\u53f7\u6709\u9650\uff0cLLM\u96c6\u6210\u590d\u6742\u4e14\u8ba1\u7b97\u5f00\u9500\u5927\uff0c\u5b58\u5728\u8bed\u4e49\u9e3f\u6c9f\u3002", "method": "\u63d0\u51fa\u4e86ELLA\u6846\u67b6\uff0c\u5305\u62ecLLM\u611f\u77e5\u5173\u7cfb\u5206\u8bcd\u5668\u548cHop\u7ea7\u5173\u7cfb\u56fe\u53d8\u6362\u5668\uff0c\u4ee5\u53ca\u7ec6\u7c92\u5ea6\u4efb\u52a1\u611f\u77e5\u6587\u672c\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u3002", "result": "ELLA\u5728\u56db\u4e2a\u5f02\u6784\u56fe\u4e0a\u4f18\u4e8e\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u652f\u6301\u9ad8\u8fbe13B\u53c2\u6570\u7684LLM\uff0c\u5e76\u5b9e\u73b0\u9ad8\u8fbe4\u500d\u901f\u5ea6\u63d0\u5347\u3002", "conclusion": "ELLA\u6709\u6548\u878d\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u9ad8\u5f02\u6784\u56fe\u5173\u7cfb\u8bed\u4e49\u5efa\u6a21\u7684\u6027\u80fd\u548c\u6548\u7387\uff0c\u63a8\u52a8\u5f02\u6784\u56fe\u4e0eLLM\u7ed3\u5408\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.18506", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18506", "abs": "https://arxiv.org/abs/2511.18506", "authors": ["Michael Adjei Osei", "Sidney Shapiro"], "title": "HQPEF-Py: Metrics, Python Patterns, and Guidance for Evaluating Hybrid Quantum Programs", "comment": "17 pages", "summary": "We study how to evaluate hybrid quantum programs as end-to-end workflows rather than as isolated devices or algorithms. Building on the Hybrid Quantum Program Evaluation Framework (HQPEF), we formalize a workflow-aware Quantum Readiness Level (QRL) score; define a normalized speedup under quality constraints for the Utility of Quantumness (UQ); and provide a timing-and-drift audit for hybrid pipelines. We complement these definitions with concise Python reference implementations that illustrate how to instantiate the metrics and audit procedures with state-of-the-art classical and quantum solvers (e.g., via Qiskit or PennyLane), while preserving matched-budget discipline and reproducibility.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u5de5\u4f5c\u6d41\u89c6\u89d2\u7684\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u8bc4\u4f30\u4f53\u7cfb\uff0c\u7ed3\u5408\u7406\u8bba\u6307\u6807\u548c\u5b9e\u8df5\u4ee3\u7801\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u7aef\u5230\u7aef\u6027\u80fd\u7684\u7cfb\u7edf\u8bc4\u4f30\u3002", "motivation": "\u5f53\u524d\u91cf\u5b50\u7a0b\u5e8f\u901a\u5e38\u4f5c\u4e3a\u72ec\u7acb\u8bbe\u5907\u6216\u7b97\u6cd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u7f3a\u4e4f\u9488\u5bf9\u7aef\u5230\u7aef\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u5de5\u4f5c\u6d41\u6574\u4f53\u6027\u80fd\u7684\u8bc4\u4f30\u6307\u6807\u548c\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u8bc4\u4f30\u6846\u67b6\uff08HQPEF\uff09\uff0c\u5f62\u5f0f\u5316\u5b9a\u4e49\u4e86\u91cf\u5b50\u51c6\u5907\u5ea6\u7ea7\u522b\uff08QRL\uff09\u8bc4\u5206\uff0c\u91cf\u5b50\u6548\u7528\uff08UQ\uff09\u4e0b\u7684\u5f52\u4e00\u5316\u52a0\u901f\u6bd4\uff0c\u4ee5\u53ca\u6df7\u5408\u7ba1\u9053\u7684\u65f6\u95f4\u548c\u6f02\u79fb\u5ba1\u8ba1\u65b9\u6cd5\uff0c\u914d\u5408Python\u5b9e\u73b0\u4ee3\u7801\u8fdb\u884c\u9a8c\u8bc1\u3002", "result": "\u63d0\u51fa\u4e86\u5de5\u4f5c\u6d41\u611f\u77e5\u7684\u8bc4\u4f30\u6307\u6807\u548c\u5ba1\u8ba1\u6d41\u7a0b\uff0c\u63d0\u4f9b\u4e86\u5229\u7528Qiskit\u548cPennyLane\u7b49\u7ecf\u5178-\u91cf\u5b50\u6c42\u89e3\u5668\u5b9e\u73b0\u7684\u53c2\u8003\u4ee3\u7801\uff0c\u4fdd\u8bc1\u4e86\u9884\u7b97\u5339\u914d\u548c\u7ed3\u679c\u53ef\u91cd\u73b0\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5de5\u4f5c\u6d41\u89c6\u89d2\u7684\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u8bc4\u4f30\u65b9\u6cd5\uff0c\u80fd\u591f\u7efc\u5408\u8bc4\u4f30\u6df7\u5408\u91cf\u5b50\u7a0b\u5e8f\u7684\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.17938", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17938", "abs": "https://arxiv.org/abs/2511.17938", "authors": ["Jianghao Wu", "Yasmeen George", "Jin Ye", "Yicheng Wu", "Daniel F. Schmidt", "Jianfei Cai"], "title": "SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization", "comment": null, "summary": "Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.", "AI": {"tldr": "SPINE\u65b9\u6cd5\u901a\u8fc7\u805a\u7126\u9ad8\u71b5\u5206\u53c9\u70b9\u7684\u9009\u62e9\u6027\u66f4\u65b0\u4e0e\u71b5\u6b63\u5219\u5316\uff0c\u89e3\u51b3\u4e86\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6027\u80fd\u574d\u7f29\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86LLM\u548cMLLM\u5728\u591a\u4efb\u52a1\u63a8\u7406\u4e2d\u7684\u8868\u73b0\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u81ea\u4e00\u81f4\u6027\u6295\u7968\u7684\u65e0\u6807\u7b7e\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u8f93\u51fa\u77ed\u7f29\u548c\u6027\u80fd\u4e0b\u964d\uff0c\u8fd9\u4e3b\u8981\u6e90\u4e8e\u5927\u90e8\u5206token\u4e3a\u4f4e\u71b5\u8ffd\u968f\u8005\uff0c\u53ea\u6709\u5c11\u91cf\u9ad8\u71b5token\u4e3b\u5bfc\u5206\u652f\u3002\u9488\u5bf9\u8fd9\u4e00\u73b0\u8c61\uff0c\u8bba\u6587\u63d0\u51fa\u9009\u62e9\u6027\u66f4\u65b0\u5206\u53c9token\u4ee5\u9632\u6b62\u66f4\u65b0\u574d\u7f29\uff0c\u63d0\u5347\u63a8\u7406\u6027\u80fd\u3002", "method": "SPINE\u6846\u67b6\u8bc6\u522b\u524d\u5411\u4f20\u64ad\u4e2d\u7684\u9ad8\u71b5\u5206\u53c9token\uff0c\u4ec5\u5bf9\u8fd9\u4e9btoken\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\u66f4\u65b0\uff0c\u5e76\u4f7f\u7528\u71b5\u5e26\u6b63\u5219\u5668\u7ef4\u6301\u9002\u5ea6\u7684\u63a2\u7d22-\u5229\u7528\u5e73\u8861\uff0c\u7ed3\u5408GRPO\u76ee\u6807\u548c\u53ef\u9009\u7684KL\u951a\u7ea6\u675f\uff0c\u65e0\u9700\u6807\u7b7e\u6216\u5956\u52b1\u6a21\u578b\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSPINE\u7684\u65b0\u65b9\u6cd5\uff0c\u9488\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u548c\u591a\u6a21\u6001LLM\uff08MLLM\uff09\u5728\u63a8\u7406\u8fc7\u7a0b\u4e2d\u6d4b\u8bd5\u65f6\u5f3a\u5316\u5b66\u4e60\uff08TTRL\uff09\u51fa\u73b0\u7684\u6027\u80fd\u8870\u9000\u548c\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u95ee\u9898\u3002SPINE\u901a\u8fc7\u9009\u62e9\u6027\u5730\u4ec5\u66f4\u65b0\u9ad8\u71b5\u5206\u652f\u7684\u5206\u53c9token\uff0c\u5e76\u5f15\u5165\u71b5\u5e26\u6b63\u5219\u5316\uff0c\u4fdd\u6301\u63a2\u7d22\u548c\u6291\u5236\u566a\u58f0\u76d1\u7763\uff0c\u4ece\u800c\u7a33\u5b9a\u8bad\u7ec3\u5e76\u63d0\u5347\u4e86Pass@1\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u6807\u7b7e\u6216\u5956\u52b1\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u95ee\u7b54\u548c\u63a8\u7406\u4efb\u52a1\uff0c\u5e76\u5728\u5341\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5747\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u5bf9\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u6a21\u578b\u8fdb\u884c\u57fa\u4e8e\u5206\u652f\u70b9\u7684\u9009\u62e9\u6027\u66f4\u65b0\u548c\u71b5\u6b63\u5219\u5316\uff0c\u662f\u4e00\u79cd\u7b80\u5355\u3001\u65e0\u6807\u7b7e\u3001\u4e14\u6709\u6548\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u673a\u5236\uff0c\u80fd\u7a33\u5b9a\u63d0\u5347\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u548c\u8bad\u7ec3\u7a33\u5b9a\u6027\u3002"}}
{"id": "2511.18528", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18528", "abs": "https://arxiv.org/abs/2511.18528", "authors": ["Renyi Zhong", "Yintong Huo", "Wenwei Gu", "Yichen Li", "Michael R. Lyu"], "title": "End-to-End Automated Logging via Multi-Agent Framework", "comment": null, "summary": "Software logging is critical for system observability, yet developers face a dual crisis of costly overlogging and risky underlogging. Existing automated logging tools often overlook the fundamental whether-to-log decision and struggle with the composite nature of logging. In this paper, we propose Autologger, a novel hybrid framework that addresses the complete the end-to-end logging pipeline. Autologger first employs a fine-tuned classifier, the Judger, to accurately determine if a method requires new logging statements. If logging is needed, a multi-agent system is activated. The system includes specialized agents: a Locator dedicated to determining where to log, and a Generator focused on what to log. These agents work together, utilizing our designed program analysis and retrieval tools. We evaluate Autologger on a large corpus from three mature open-source projects against state-of-the-art baselines. Our results show that Autologger achieves 96.63\\% F1-score on the crucial whether-to-log decision. In an end-to-end setting, Autologger improves the overall quality of generated logging statements by 16.13\\% over the strongest baseline, as measured by an LLM-as-a-judge score. We also demonstrate that our framework is generalizable, consistently boosting the performance of various backbone LLMs.", "AI": {"tldr": "Autologger\u901a\u8fc7\u5224\u65ad\u662f\u5426\u9700\u8981\u65e5\u5fd7\u53ca\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u81ea\u52a8\u65e5\u5fd7\u751f\u6210\u7684\u51c6\u786e\u7387\u548c\u8d28\u91cf\u3002", "motivation": "\u89e3\u51b3\u8f6f\u4ef6\u65e5\u5fd7\u8bb0\u5f55\u4e2d\u7684\u6210\u672c\u9ad8\u6602\u7684\u8fc7\u5ea6\u8bb0\u5f55\u4e0e\u98ce\u9669\u5927\u7684\u4e0d\u8db3\u8bb0\u5f55\u95ee\u9898\uff0c\u81ea\u52a8\u5316\u5de5\u5177\u5ffd\u89c6\u4e86\u57fa\u7840\u7684\u662f\u5426\u8bb0\u5f55\u51b3\u7b56\u4e0e\u8bb0\u5f55\u7684\u590d\u5408\u6027\u3002", "method": "\u91c7\u7528\u7ec6\u8c03\u7684\u5206\u7c7b\u5668\u5224\u65ad\u662f\u5426\u8bb0\u5f55\u65e5\u5fd7\uff0c\u6fc0\u6d3b\u5305\u62ec\u5b9a\u4f4d\u548c\u751f\u6210\u4ee3\u7406\u7684\u591a\u4ee3\u7406\u7cfb\u7edf\uff0c\u7ed3\u5408\u7a0b\u5e8f\u5206\u6790\u548c\u68c0\u7d22\u5de5\u5177\u751f\u6210\u65e5\u5fd7\u3002", "result": "\u63d0\u51fa\u4e86Autologger\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528\u7cbe\u51c6\u5206\u7c7b\u5668\u5224\u65ad\u662f\u5426\u9700\u8981\u65e5\u5fd7\uff0c\u7ed3\u5408\u591a\u4ee3\u7406\u7cfb\u7edf\u786e\u5b9a\u65e5\u5fd7\u4f4d\u7f6e\u548c\u5185\u5bb9\uff0c\u5728\u5927\u89c4\u6a21\u5f00\u6e90\u9879\u76ee\u4e2d\u53d6\u5f9796.63%\u7684F1\u5206\u6570\uff0c\u6574\u4f53\u65e5\u5fd7\u8d28\u91cf\u63d0\u534716.13%\u3002", "conclusion": "Autologger\u6709\u6548\u89e3\u51b3\u4e86\u65e5\u5fd7\u751f\u6210\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u65e5\u5fd7\u7684\u51c6\u786e\u6027\u548c\u8d28\u91cf\uff0c\u4e14\u5177\u6709\u826f\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2511.17946", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17946", "abs": "https://arxiv.org/abs/2511.17946", "authors": ["Shuo Zhang", "Fabrizio Gotti", "Fengran Mo", "Jian-Yun Nie"], "title": "Measuring the Impact of Lexical Training Data Coverage on Hallucination Detection in Large Language Models", "comment": null, "summary": "Hallucination in large language models (LLMs) is a fundamental challenge, particularly in open-domain question answering. Prior work attempts to detect hallucination with model-internal signals such as token-level entropy or generation consistency, while the connection between pretraining data exposure and hallucination is underexplored. Existing studies show that LLMs underperform on long-tail knowledge, i.e., the accuracy of the generated answer drops for the ground-truth entities that are rare in pretraining. However, examining whether data coverage itself can serve as a detection signal is overlooked. We propose a complementary question: Does lexical training-data coverage of the question and/or generated answer provide additional signal for hallucination detection? To investigate this, we construct scalable suffix arrays over RedPajama's 1.3-trillion-token pretraining corpus to retrieve $n$-gram statistics for both prompts and model generations. We evaluate their effectiveness for hallucination detection across three QA benchmarks. Our observations show that while occurrence-based features are weak predictors when used alone, they yield modest gains when combined with log-probabilities, particularly on datasets with higher intrinsic model uncertainty. These findings suggest that lexical coverage features provide a complementary signal for hallucination detection. All code and suffix-array infrastructure are provided at https://github.com/WWWonderer/ostd.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u901a\u8fc7\u5206\u6790\u6a21\u578b\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u95ee\u9898\u548c\u7b54\u6848\u7684\u8bcd\u6c47\u8986\u76d6\u5ea6\uff0c\u8f85\u52a9\u68c0\u6d4b\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u73b0\u8c61\uff0c\u9a8c\u8bc1\u4e86\u8bcd\u6c47\u8986\u76d6\u5ea6\u5728\u5e7b\u89c9\u68c0\u6d4b\u4e2d\u7684\u4e92\u8865\u4f5c\u7528\u3002", "motivation": "\u5f53\u524d\u5927\u6a21\u578b\u5728\u5f00\u653e\u57df\u95ee\u7b54\u4e2d\u5b58\u5728\u5e7b\u89c9\u95ee\u9898\uff0c\u4e14\u6a21\u578b\u9884\u8bad\u7ec3\u6570\u636e\u7684\u8986\u76d6\u5ea6\u4e0e\u5e7b\u89c9\u68c0\u6d4b\u4e4b\u95f4\u7684\u8054\u7cfb\u5c1a\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u6784\u5efaRedPajama\u76841.3\u4e07\u4ebf\u8bcd\u5143\u9884\u8bad\u7ec3\u8bed\u6599\u5e93\u7684\u540e\u7f00\u6570\u7ec4\uff0c\u7528\u4e8e\u68c0\u7d22\u95ee\u9898\u548c\u751f\u6210\u7b54\u6848\u7684n-gram\u7edf\u8ba1\u6570\u636e\uff0c\u7ed3\u5408\u6a21\u578b\u7684\u5bf9\u6570\u6982\u7387\u4e00\u8d77\u8fdb\u884c\u5e7b\u89c9\u68c0\u6d4b\u3002", "result": "\u53d1\u73b0\u57fa\u4e8e\u8bcd\u6c47\u8986\u76d6\u5ea6\u7684\u7279\u5f81\u5355\u72ec\u6548\u679c\u8f83\u5f31\uff0c\u4f46\u4e0e\u6a21\u578b\u751f\u6210\u6982\u7387\u7ed3\u5408\u540e\uff0c\u5728\u9ad8\u4e0d\u786e\u5b9a\u6027\u6570\u636e\u96c6\u4e0a\u5bf9\u5e7b\u89c9\u68c0\u6d4b\u6709\u4e00\u5b9a\u589e\u76ca\uff0c\u8868\u660e\u8bcd\u6c47\u8986\u76d6\u5ea6\u662f\u5e7b\u89c9\u68c0\u6d4b\u7684\u6709\u6548\u8f85\u52a9\u4fe1\u53f7\u3002", "conclusion": "\u8bcd\u6c47\u8bad\u7ec3\u6570\u636e\u8986\u76d6\u5ea6\u7279\u5f81\u80fd\u4e3a\u5927\u6a21\u578b\u5e7b\u89c9\u68c0\u6d4b\u63d0\u4f9b\u989d\u5916\u7684\u8f85\u52a9\u4fe1\u53f7\uff0c\u5c24\u5176\u5728\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u8f83\u9ad8\u7684\u573a\u666f\u4e0b\u6548\u679c\u663e\u8457\u3002\u4f5c\u8005\u8fd8\u516c\u5f00\u4e86\u4ee3\u7801\u548c\u540e\u7f00\u6570\u7ec4\u57fa\u7840\u8bbe\u65bd\u4ee5\u4fc3\u8fdb\u540e\u7eed\u7814\u7a76\u3002"}}
{"id": "2511.18538", "categories": ["cs.SE", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18538", "abs": "https://arxiv.org/abs/2511.18538", "authors": ["Jian Yang", "Wei Zhang", "Shark Liu", "Jiajun Wu", "Shawn Guo", "Yizhi Li"], "title": "From Code Foundation Models to Agents and Applications: A Practical Guide to Code Intelligence", "comment": null, "summary": "Large language models (LLMs) have fundamentally transformed automated software development by enabling direct translation of natural language descriptions into functional code, driving commercial adoption through tools like Github Copilot (Microsoft), Cursor (Anysphere), Trae (ByteDance), and Claude Code (Anthropic). While the field has evolved dramatically from rule-based systems to Transformer-based architectures, achieving performance improvements from single-digit to over 95\\% success rates on benchmarks like HumanEval. In this work, we provide a comprehensive synthesis and practical guide (a series of analytic and probing experiments) about code LLMs, systematically examining the complete model life cycle from data curation to post-training through advanced prompting paradigms, code pre-training, supervised fine-tuning, reinforcement learning, and autonomous coding agents. We analyze the code capability of the general LLMs (GPT-4, Claude, LLaMA) and code-specialized LLMs (StarCoder, Code LLaMA, DeepSeek-Coder, and QwenCoder), critically examining the techniques, design decisions, and trade-offs. Further, we articulate the research-practice gap between academic research (e.g., benchmarks and tasks) and real-world deployment (e.g., software-related code tasks), including code correctness, security, contextual awareness of large codebases, and integration with development workflows, and map promising research directions to practical needs. Last, we conduct a series of experiments to provide a comprehensive analysis of code pre-training, supervised fine-tuning, and reinforcement learning, covering scaling law, framework selection, hyperparameter sensitivity, model architectures, and dataset comparisons.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7efc\u8ff0\u4e86\u4ee3\u7801\u751f\u6210\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5168\u751f\u547d\u5468\u671f\u53ca\u5173\u952e\u6280\u672f\uff0c\u5206\u6790\u4e86\u5b66\u672f\u4e0e\u5b9e\u9645\u5e94\u7528\u7684\u5dee\u5f02\uff0c\u901a\u8fc7\u5b9e\u9a8c\u63ed\u793a\u4e86\u6a21\u578b\u8bad\u7ec3\u5404\u73af\u8282\u7684\u5f71\u54cd\uff0c\u4e3a\u4ee3\u7801LLMs\u7684\u7814\u7a76\u4e0e\u5b9e\u7528\u63d0\u4f9b\u6307\u5bfc\u3002", "motivation": "\u968f\u7740\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u52a8\u8f6f\u4ef6\u5f00\u53d1\u4e2d\u53d6\u5f97\u663e\u8457\u7a81\u7834\uff0c\u4e9f\u9700\u7cfb\u7edf\u68b3\u7406\u4ee3\u7801LLMs\u7684\u53d1\u5c55\u5386\u7a0b\u3001\u6280\u672f\u6846\u67b6\u53ca\u5b9e\u9645\u6311\u6218\uff0c\u4ee5\u4fc3\u8fdb\u5b66\u672f\u7814\u7a76\u4e0e\u5de5\u4e1a\u5e94\u7528\u7684\u6709\u6548\u7ed3\u5408\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u6a21\u578b\u751f\u547d\u5468\u671f\u7684\u5404\u4e2a\u9636\u6bb5\uff0c\u5305\u62ec\u6570\u636e\u6574\u7406\u3001\u4ee3\u7801\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u81ea\u4e3b\u7f16\u7a0b\u4ee3\u7406\uff0c\u7ed3\u5408\u4e00\u7cfb\u5217\u5206\u6790\u6027\u548c\u63a2\u6d4b\u6027\u5b9e\u9a8c\uff0c\u6bd4\u8f83\u4e86\u901a\u7528\u548c\u4e13\u4e1a\u4ee3\u7801LLMs\u7684\u6280\u672f\u4e0e\u8bbe\u8ba1\u6289\u62e9\u3002", "result": "\u5b9e\u9a8c\u8be6\u5c3d\u5206\u6790\u4e86\u4ee3\u7801\u9884\u8bad\u7ec3\u3001\u76d1\u7763\u5fae\u8c03\u53ca\u5f3a\u5316\u5b66\u4e60\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63a2\u8ba8\u4e86\u89c4\u6a21\u89c4\u5f8b\u3001\u6846\u67b6\u9009\u62e9\u3001\u8d85\u53c2\u6570\u654f\u611f\u6027\u3001\u6a21\u578b\u67b6\u6784\u53ca\u6570\u636e\u96c6\u5dee\u5f02\uff0c\u63ed\u793a\u4e86\u5f53\u524d\u6280\u672f\u5728\u5b9e\u9645\u4ee3\u7801\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u548c\u74f6\u9888\u3002", "conclusion": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u751f\u6210\u9886\u57df\u7684\u8fdb\u5c55\u4e0e\u5e94\u7528\uff0c\u63ed\u793a\u4e86\u5b66\u672f\u7814\u7a76\u4e0e\u5b9e\u9645\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5f3a\u8c03\u4e86\u4ee3\u7801\u6b63\u786e\u6027\u3001\u5b89\u5168\u6027\u53ca\u5927\u89c4\u6a21\u4ee3\u7801\u5e93\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u4ee5\u6ee1\u8db3\u5b9e\u9645\u9700\u6c42\u3002"}}
{"id": "2511.17955", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.17955", "abs": "https://arxiv.org/abs/2511.17955", "authors": ["Dat Thanh Nguyen", "Nguyen Hung Lam", "Anh Hoang-Thi Nguyen", "Trong-Hop Do"], "title": "MTikGuard System: A Transformer-Based Multimodal System for Child-Safe Content Moderation on TikTok", "comment": "Accepted at PACLIC39", "summary": "With the rapid rise of short-form videos, TikTok has become one of the most influential platforms among children and teenagers, but also a source of harmful content that can affect their perception and behavior. Such content, often subtle or deceptive, challenges traditional moderation methods due to the massive volume and real-time nature of uploads. This paper presents MTikGuard, a real-time multimodal harmful content detection system for TikTok, with three key contributions: (1) an extended TikHarm dataset expanded to 4,723 labeled videos by adding diverse real-world samples, (2) a multimodal classification framework integrating visual, audio, and textual features to achieve state-of-the-art performance with 89.37% accuracy and 89.45% F1-score, and (3) a scalable streaming architecture built on Apache Kafka and Apache Spark for real-time deployment. The results demonstrate the effectiveness of combining dataset expansion, advanced multimodal fusion, and robust deployment for practical large-scale social media content moderation. The dataset is available at https://github.com/ntdat-8324/MTikGuard-System.git.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86MTikGuard\u7cfb\u7edf\uff0c\u901a\u8fc7\u6269\u5c55\u6570\u636e\u96c6\u548c\u591a\u6a21\u6001\u878d\u5408\uff0c\u5b9e\u73b0\u4e86\u5bf9TikTok\u6709\u5bb3\u5185\u5bb9\u7684\u5b9e\u65f6\u68c0\u6d4b\uff0c\u51c6\u786e\u7387\u8fbe89.37%\u3002", "motivation": "\u77ed\u89c6\u9891\u5174\u8d77\u5e26\u6765\u5927\u91cf\u6f5c\u5728\u6709\u5bb3\u5185\u5bb9\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u6d77\u91cf\u5b9e\u65f6\u4e0a\u4f20\uff0c\u9700\u5f00\u53d1\u9ad8\u6548\u5b9e\u65f6\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u6269\u5c55TikHarm\u6570\u636e\u96c6\uff0c\u6784\u5efa\u5305\u542b\u89c6\u89c9\u3001\u97f3\u9891\u548c\u6587\u672c\u7279\u5f81\u7684\u591a\u6a21\u6001\u5206\u7c7b\u6846\u67b6\uff0c\u4f7f\u7528\u57fa\u4e8eApache Kafka\u548cApache Spark\u7684\u6d41\u5f0f\u67b6\u6784\u5b9e\u73b0\u5b9e\u65f6\u5e94\u7528\u3002", "result": "\u6269\u5c55\u6570\u636e\u96c6\u81f34723\u89c6\u9891\uff0c\u6a21\u578b\u8fbe89.37%\u51c6\u786e\u7387\u548c89.45% F1\u5206\u6570\uff0c\u7cfb\u7edf\u5177\u5907\u5927\u89c4\u6a21\u5b9e\u65f6\u90e8\u7f72\u80fd\u529b\u3002", "conclusion": "\u7ed3\u5408\u6570\u636e\u96c6\u6269\u5c55\u3001\u591a\u6a21\u6001\u878d\u5408\u548c\u53ef\u6269\u5c55\u90e8\u7f72\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u5b9e\u7528\u7684TikTok\u6709\u5bb3\u5185\u5bb9\u5b9e\u65f6\u68c0\u6d4b\u3002"}}
{"id": "2511.18589", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18589", "abs": "https://arxiv.org/abs/2511.18589", "authors": ["Michael Trusov", "Minha Hwang", "Zainab Jamal", "Swarup Chandra"], "title": "Strategic Decision Framework for Enterprise LLM Adoption", "comment": "14 pages, 1 key figure", "summary": "Organizations are rapidly adopting Large Language Models (LLMs) to transform their operations, yet they lack clear guidance on key decisions for adoption and implementation. While LLMs offer powerful capabilities in content generation, assisted coding, and process automation, businesses face critical challenges in data security, LLM solution development approach, infrastructure requirements, and deployment strategies. Healthcare providers must protect patient data while leveraging LLMs for medical analysis, financial institutions need to balance automated customer service with regulatory compliance, and software companies seek to enhance development productivity while maintaining code security.\n  This article presents a systematic six-step decision framework for LLM adoption, helping organizations navigate from initial application selection to final deployment. Based on extensive interviews and analysis of successful and failed implementations, our framework provides practical guidance for business leaders to align technological capabilities with business objectives. Through key decision points and real-world examples from both B2B and B2C contexts, organizations can make informed decisions about LLM adoption while ensuring secure and efficient integration across various use cases, from customer service automation to content creation and advanced analytics.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u5957\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u6307\u5bfc\u7ec4\u7ec7\u5b89\u5168\u9ad8\u6548\u5730\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u652f\u6301\u4ece\u5ba2\u6237\u670d\u52a1\u81ea\u52a8\u5316\u5230\u5185\u5bb9\u521b\u4f5c\u548c\u9ad8\u7ea7\u5206\u6790\u7684\u591a\u573a\u666f\u5e94\u7528\u3002", "motivation": "\u7ec4\u7ec7\u5feb\u901f\u91c7\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u6765\u8f6c\u53d8\u8fd0\u8425\uff0c\u4f46\u7f3a\u4e4f\u9488\u5bf9\u5173\u952e\u51b3\u7b56\u7684\u660e\u786e\u6307\u5bfc\uff0c\u7279\u522b\u5728\u6570\u636e\u5b89\u5168\u3001\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3001\u57fa\u7840\u8bbe\u65bd\u9700\u6c42\u548c\u90e8\u7f72\u7b56\u7565\u65b9\u9762\uff0c\u9762\u4e34\u91cd\u8981\u6311\u6218\u3002\u5404\u884c\u4e1a\u5982\u533b\u7597\u3001\u91d1\u878d\u548c\u8f6f\u4ef6\u5f00\u53d1\u9700\u5e73\u8861\u6280\u672f\u5229\u7528\u548c\u5b89\u5168\u5408\u89c4\u3002", "method": "\u901a\u8fc7\u5bf9\u6210\u529f\u4e0e\u5931\u8d25\u7684LLM\u5b9e\u65bd\u6848\u4f8b\u8fdb\u884c\u5e7f\u6cdb\u8bbf\u8c08\u548c\u6df1\u5165\u5206\u6790\uff0c\u63d0\u70bc\u51fa\u7cfb\u7edf\u6027\u7684\u516d\u6b65\u51b3\u7b56\u6846\u67b6\uff0c\u5305\u62ec\u5e94\u7528\u9009\u62e9\u3001\u6570\u636e\u5b89\u5168\u3001\u5f00\u53d1\u65b9\u6848\u3001\u57fa\u7840\u8bbe\u65bd\u548c\u90e8\u7f72\u7b56\u7565\u7b49\u5173\u952e\u51b3\u7b56\u70b9\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u7684\u516d\u6b65\u9aa4\u51b3\u7b56\u6846\u67b6\uff0c\u57fa\u4e8e\u5e7f\u6cdb\u8bbf\u8c08\u53ca\u6210\u529f\u4e0e\u5931\u8d25\u6848\u4f8b\u5206\u6790\uff0c\u5e2e\u52a9\u7ec4\u7ec7\u4ece\u521d\u6b65\u5e94\u7528\u9009\u62e9\u5230\u6700\u7ec8\u90e8\u7f72\uff0c\u63d0\u4f9b\u5b9e\u7528\u6307\u5bfc\uff0c\u4f7f\u4e1a\u52a1\u9886\u5bfc\u80fd\u591f\u5c06\u6280\u672f\u80fd\u529b\u4e0e\u5546\u4e1a\u76ee\u6807\u5bf9\u9f50\u3002", "conclusion": "\u8be5\u6846\u67b6\u52a9\u529b\u7ec4\u7ec7\u5728\u5e94\u7528LLMs\u65f6\u505a\u51fa\u660e\u667a\u51b3\u7b56\uff0c\u786e\u4fdd\u6280\u672f\u4e0e\u4e1a\u52a1\u76ee\u6807\u4e00\u81f4\uff0c\u4fc3\u8fdb\u5b89\u5168\u548c\u6709\u6548\u7684\u591a\u9886\u57df\u96c6\u6210\u3002"}}
{"id": "2511.18054", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18054", "abs": "https://arxiv.org/abs/2511.18054", "authors": ["Gowtham", "Sai Rupesh", "Sanjay Kumar", "Saravanan", "Venkata Chaithanya"], "title": "Blu-WERP (Web Extraction and Refinement Pipeline): A Scalable Pipeline for Preprocessing Large Language Model Datasets", "comment": null, "summary": "High-quality training data is fundamental to large language model (LLM) performance, yet existing preprocessing pipelines often struggle to effectively remove noise and unstructured content from web-scale corpora. This paper presents Blu-WERP, a novel data preprocessing pipeline designed to optimize the quality of Common Crawl WARC files for LLM training. We demonstrate that Blu-WERP significantly outperforms established baselines including DCLM across multiple model scales and evaluation benchmarks. Our pipeline processes CC WARC dumps, implementing advanced filtering and quality assessment mechanisms. We conducted comprehensive evaluations using models with 150M, 400M, 530M, 750M, and 1B parameters, testing against nine standard benchmarks categorized as World Knowledge & Reasoning, Language Understanding, and Commonsense Reasoning. Results show Blu-WERP consistently achieved superior performance across all model scales. At the 1B parameter scale, Relatively Blu-WERP demonstrates a 4.0% and 9.5% aggregate improvement over DCLM and Fineweb respectively, while achieving quality-per-token efficiency gain. Categorical analysis reveals 2.4% improvement in World Knowledge & Reasoning, 6.2% improvement in Language Understanding, and 4.2% improvement in Commonsense Reasoning. These results establish Blu-WERP as a state-of-the-art preprocessing pipeline that substantially improves LLM training data quality and downstream model performance with reduced computational cost. Our findings contribute to the growing body of research on data-centric AI, demonstrating that preprocessing pipeline design significantly impacts LLM capabilities. The Blu-WERP pipeline represents a practical advancement in data quality optimization, offering researchers and practitioners an effective solution for improving LLM training efficiency and model performance.", "AI": {"tldr": "Blu-WERP\u662f\u4e00\u79cd\u65b0\u9896\u7684\u6570\u636e\u9884\u5904\u7406\u7ba1\u7ebf\uff0c\u80fd\u663e\u8457\u63d0\u5347Common Crawl\u6570\u636e\u7684\u8d28\u91cf\uff0c\u8fdb\u800c\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u9884\u5904\u7406\u6d41\u7a0b\u96be\u4ee5\u6709\u6548\u8fc7\u6ee4\u7f51\u7edc\u5927\u89c4\u6a21\u8bed\u6599\u4e2d\u7684\u566a\u58f0\u548c\u975e\u7ed3\u6784\u5316\u5185\u5bb9\uff0c\u5f71\u54cdLLM\u6027\u80fd\u3002", "method": "Blu-WERP\u5bf9Common Crawl\u7684WARC\u6587\u4ef6\u8fdb\u884c\u9ad8\u7ea7\u8fc7\u6ee4\u548c\u8d28\u91cf\u8bc4\u4f30\u5904\u7406\uff0c\u4ee5\u4f18\u5316\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u4e0d\u540c\u53c2\u6570\u89c4\u6a21\u548c9\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cBlu-WERP\u6bd4\u73b0\u6709\u57fa\u7ebfDCLM\u548cFineweb\u8868\u73b0\u66f4\u4f18\uff0c\u6027\u80fd\u63d0\u5347\u6700\u9ad8\u8fbe9.5%\uff0c\u4e14\u63d0\u5347\u4e86\u5404\u7c7b\u63a8\u7406\u4e0e\u7406\u89e3\u4efb\u52a1\u8868\u73b0\u3002", "conclusion": "Blu-WERP\u4f5c\u4e3a\u5148\u8fdb\u7684\u9884\u5904\u7406\u65b9\u6848\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u8bad\u7ec3\u6570\u636e\u8d28\u91cf\u548c\u6a21\u578b\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u8ba1\u7b97\u6210\u672c\u3002"}}
{"id": "2511.18608", "categories": ["cs.SE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.18608", "abs": "https://arxiv.org/abs/2511.18608", "authors": ["Jiangrui Zheng", "Yingming Zhou", "Ali Abdullah Ahmad", "Hanqing Yao", "Xueqing Liu"], "title": "From Reviewers' Lens: Understanding Bug Bounty Report Invalid Reasons with LLMs", "comment": "10 pages, 4 figures", "summary": "Bug bounty platforms (e.g., HackerOne, BugCrowd) leverage crowd-sourced vulnerability discovery to improve continuous coverage, reduce the cost of discovery, and serve as an integral complement to internal red teams. With the rise of AI-generated bug reports, little work exists to help bug hunters understand why these reports are labeled as invalid. To improve report quality and reduce reviewers' burden, it is critical to predict invalid reports and interpret invalid reasons.\n  In this work, we conduct an empirical study with the purpose of helping bug hunters understand the validity of reports. We collect a dataset of 9,942 disclosed bug bounty reports, including 1,400 invalid reports, and evaluate whether state-of-the-art large language models can identify invalid reports. While models such as GPT-5, DeepSeek, and a fine-tuned RoBERTa achieve strong overall accuracy, they consistently struggle to detect invalid cases, showing a tendency to over-accept reports. To improve invalidity detection, we build a taxonomy of rejection reasons for Information Disclosure vulnerabilities and incorporate it into a retrieval-augmented generation (RAG) framework. This approach substantially improves classification consistency and reduces bias. We also examine whether reviewer decisions may be influenced by factors beyond the content of the report. Our analysis shows that reporters with higher reputations tend to receive more favorable outcomes in borderline cases, suggesting that perceived expertise can influence review judgments.\n  Overall, our findings highlight the challenges of invalid report identification and show that combining LLMs with structured reviewer knowledge can support more transparent and consistent vulnerability report review.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u51c6\u786e\u8bc6\u522b\u65e0\u6548\u6f0f\u6d1e\u62a5\u544a\uff0c\u901a\u8fc7\u5206\u7c7b\u62d2\u7edd\u539f\u56e0\u548c\u7ed3\u5408\u5ba1\u67e5\u8005\u77e5\u8bc6\u7684RAG\u65b9\u6cd5\u80fd\u663e\u8457\u6539\u5584\u65e0\u6548\u62a5\u544a\u68c0\u6d4b\uff0c\u5e76\u63ed\u793a\u5ba1\u67e5\u51b3\u7b56\u53d7\u62a5\u544a\u8005\u58f0\u8a89\u5f71\u54cd\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u6f0f\u6d1e\u62a5\u544a\u7684\u589e\u591a\uff0c\u5e2e\u52a9\u6f0f\u6d1e\u730e\u4eba\u7406\u89e3\u65e0\u6548\u62a5\u544a\u7684\u6807\u6ce8\u539f\u56e0\uff0c\u63d0\u9ad8\u62a5\u544a\u8d28\u91cf\u53ca\u51cf\u8f7b\u5ba1\u67e5\u8d1f\u62c5\u53d8\u5f97\u8feb\u5207\u3002", "method": "\u6536\u96c6\u4e869,942\u4efd\u6f0f\u6d1e\u5956\u52b1\u62a5\u544a\u6570\u636e\u96c6\uff0c\u5305\u62ec1,400\u4efd\u65e0\u6548\u62a5\u544a\uff0c\u8bc4\u4f30\u4e86GPT-5\u3001DeepSeek\u548c\u5fae\u8c03RoBERTa\u7b49\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u65e0\u6548\u62a5\u544a\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u5e76\u6784\u5efa\u4e86\u4fe1\u606f\u6cc4\u9732\u6f0f\u6d1e\u7684\u62d2\u7edd\u539f\u56e0\u5206\u7c7b\u6cd5\uff0c\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u6846\u67b6\u63d0\u5347\u65e0\u6548\u68c0\u6d4b\u3002", "result": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u51c6\u786e\u7387\u9ad8\uff0c\u4f46\u5728\u8bc6\u522b\u65e0\u6548\u62a5\u544a\u65f6\u5bb9\u6613\u8fc7\u5ea6\u63a5\u6536\uff0c\u7ed3\u5408\u62d2\u7edd\u539f\u56e0\u5206\u7c7b\u53caRAG\u6846\u67b6\u5927\u5e45\u63d0\u5347\u68c0\u6d4b\u4e00\u81f4\u6027\u5e76\u51cf\u5c11\u504f\u5dee\u3002", "conclusion": "\u7ed3\u5408\u7ed3\u6784\u5316\u5ba1\u67e5\u8005\u77e5\u8bc6\u4e0e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u6709\u52a9\u4e8e\u5b9e\u73b0\u66f4\u900f\u660e\u3001\u4e00\u81f4\u7684\u6f0f\u6d1e\u62a5\u544a\u5ba1\u6838\uff0c\u63d0\u5347\u65e0\u6548\u62a5\u544a\u8bc6\u522b\u6548\u679c\uff0c\u4fc3\u8fdb\u6f0f\u6d1e\u5956\u52b1\u5e73\u53f0\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002"}}
{"id": "2511.18146", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18146", "abs": "https://arxiv.org/abs/2511.18146", "authors": ["Yomal De Mel", "Nisansa de Silva"], "title": "GeeSanBhava: Sentiment Tagged Sinhala Music Video Comment Data Set", "comment": null, "summary": "This study introduce GeeSanBhava, a high-quality data set of Sinhala song comments extracted from YouTube manually tagged using Russells Valence-Arousal model by three independent human annotators. The human annotators achieve a substantial inter-annotator agreement (Fleiss kappa = 84.96%). The analysis revealed distinct emotional profiles for different songs, highlighting the importance of comment based emotion mapping. The study also addressed the challenges of comparing comment-based and song-based emotions, mitigating biases inherent in user-generated content. A number of Machine learning and deep learning models were pre-trained on a related large data set of Sinhala News comments in order to report the zero-shot result of our Sinhala YouTube comment data set. An optimized Multi-Layer Perceptron model, after extensive hyperparameter tuning, achieved a ROC-AUC score of 0.887. The model is a three-layer MLP with a configuration of 256, 128, and 64 neurons. This research contributes a valuable annotated dataset and provides insights for future work in Sinhala Natural Language Processing and music emotion recognition.", "AI": {"tldr": "\u672c\u7814\u7a76\u6784\u5efa\u4e86\u9ad8\u8d28\u91cf\u7684\u8f9b\u54c8\u62c9\u8bedYouTube\u6b4c\u66f2\u8bc4\u8bba\u60c5\u7eea\u6570\u636e\u96c6\uff0c\u5c55\u793a\u4e86\u8bc4\u8bba\u60c5\u7eea\u5206\u6790\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53d6\u5f97\u8f83\u597d\u60c5\u611f\u5206\u7c7b\u6548\u679c\u3002", "motivation": "\u6784\u5efa\u9ad8\u8d28\u91cf\u7684\u8f9b\u54c8\u62c9\u8bed\u97f3\u4e50\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u7814\u7a76\u57fa\u4e8e\u8bc4\u8bba\u7684\u60c5\u7eea\u6620\u5c04\uff0c\u89e3\u51b3\u7528\u6237\u751f\u6210\u5185\u5bb9\u4e2d\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u63a8\u52a8\u8f9b\u54c8\u62c9\u8bed\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e0e\u97f3\u4e50\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u3002", "method": "\u624b\u5de5\u6807\u6ce8\u8f9b\u54c8\u62c9\u8bed\u6b4c\u66f2\u8bc4\u8bba\u6570\u636e\u96c6\uff0c\u91c7\u7528Russell\u7684\u60c5\u7eea\u4e8c\u7ef4\u6a21\u578b\uff08Valence-Arousal\uff09\u8fdb\u884c\u60c5\u611f\u6807\u6ce8\uff0c\u5229\u7528\u591a\u4e2a\u4eba\u5de5\u6ce8\u91ca\u8005\u4fdd\u8bc1\u6807\u6ce8\u8d28\u91cf\uff1b\u9884\u8bad\u7ec3\u591a\u79cd\u673a\u5668\u5b66\u4e60\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\uff0c\u5e76\u9488\u5bf9\u591a\u5c42\u611f\u77e5\u5668\u6a21\u578b\u8fdb\u884c\u4e86\u8d85\u53c2\u6570\u4f18\u5316\u3002", "result": "\u4e09\u4e2a\u6ce8\u91ca\u8005\u53d6\u5f97\u8f83\u9ad8\u4e00\u81f4\u6027\uff08Fleiss kappa=84.96%\uff09\uff1b\u53d1\u73b0\u4e0d\u540c\u6b4c\u66f2\u7684\u60c5\u7eea\u7279\u5f81\u533a\u522b\u660e\u663e\uff1b\u4f18\u5316\u540e\u7684\u4e09\u5c42MLP\u6a21\u578b\u5728\u96f6\u6837\u672c\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e860.887\u7684ROC-AUC\u5206\u6570\u3002", "conclusion": "GeeSanBhava\u6570\u636e\u96c6\u4e3a\u8f9b\u54c8\u62c9\u8bed\u97f3\u4e50\u60c5\u7eea\u8bc6\u522b\u9886\u57df\u8d21\u732e\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u57fa\u4e8e\u8bc4\u8bba\u7684\u60c5\u7eea\u5206\u6790\u5177\u6709\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u8f9b\u54c8\u62c9\u8bedNLP\u4e0e\u97f3\u4e50\u60c5\u611f\u7814\u7a76\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.18625", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18625", "abs": "https://arxiv.org/abs/2511.18625", "authors": ["Wei Wang", "Hourieh Khalajzadeh", "John Grundy", "Anuradha Madugalla", "Humphrey O. Obie"], "title": "Leveraging Discrete Choice Experiments for User-Centric Requirements Prioritization in mHealth Applications", "comment": null, "summary": "Mobile health (mHealth) applications are widely used for chronic disease management, but usability and accessibility challenges persist due to the diverse needs of users. Adaptive User Interfaces (AUIs) offer a personalized solution to enhance user experience, yet barriers to adoption remain. Understanding user preferences and trade-offs is essential to ensure widespread acceptance of adaptation designs. This study identifies key factors influencing user preferences and trade-offs in mHealth adaptation design. A Discrete Choice Experiment (DCE) was conducted with 186 participants who have chronic diseases and use mHealth applications. Participants were asked to select preferred adaptation designs from choices featuring six attributes with varying levels. A mixed logit model was used to analyze preference heterogeneity and determine the factors most likely influencing adoption. Additionally, subgroup analyses were performed to explore differences by age, gender, health conditions, and coping mechanisms. Maintaining usability while ensuring controllability over adaptations, infrequent adaptations, and small-scale changes are key factors that facilitate the adoption of adaptive mHealth app designs. In contrast, frequently used functions and caregiver involvement can diminish the perceived value of such adaptations. This study employs a data-driven approach to quantify user preferences, identify key trade-offs, and reveal variations across demographic and behavioral subgroups through preference heterogeneity modeling. Furthermore, our results offer valuable guidance for developing future adaptive mHealth applications and lay the groundwork for continued exploration into requirements prioritization within the field of software engineering.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u7528\u6237\u504f\u597d\u5b9e\u9a8c\uff0c\u627e\u51fa\u5f71\u54cd\u81ea\u9002\u5e94\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u91c7\u7eb3\u7684\u5173\u952e\u56e0\u7d20\uff0c\u5f3a\u8c03\u4fdd\u6301\u6613\u7528\u6027\u548c\u9002\u5ea6\u8c03\u6574\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5f53\u524dmHealth\u5e94\u7528\u5b58\u5728\u53ef\u7528\u6027\u548c\u53ef\u8bbf\u95ee\u6027\u6311\u6218\uff0c\u4e2a\u6027\u5316\u81ea\u9002\u5e94\u754c\u9762\u867d\u80fd\u63d0\u5347\u7528\u6237\u4f53\u9a8c\uff0c\u4f46\u91c7\u7eb3\u7387\u53d7\u9650\uff0c\u7406\u89e3\u7528\u6237\u504f\u597d\u4e0e\u6743\u8861\u662f\u63a8\u52a8\u5e7f\u6cdb\u5e94\u7528\u7684\u5fc5\u8981\u6761\u4ef6\u3002", "method": "\u91c7\u7528\u79bb\u6563\u9009\u62e9\u5b9e\u9a8c(DCE)\uff0c\u901a\u8fc7\u6df7\u5408\u903b\u8f91\u6a21\u578b\u5206\u6790186\u540d\u6162\u6027\u75c5\u60a3\u8005\u5bf9\u516d\u4e2a\u5c5e\u6027\u7684\u81ea\u9002\u5e94\u8bbe\u8ba1\u504f\u597d\u53ca\u5176\u5f02\u8d28\u6027\uff0c\u540c\u65f6\u8fdb\u884c\u4e9a\u7ec4\u5206\u6790\u3002", "result": "\u672c\u7814\u7a76\u901a\u8fc7\u79bb\u6563\u9009\u62e9\u5b9e\u9a8c(DCE)\u63a2\u8ba8\u6162\u6027\u75c5\u60a3\u8005\u5bf9\u79fb\u52a8\u5065\u5eb7(mHealth)\u81ea\u9002\u5e94\u7528\u6237\u754c\u9762\u8bbe\u8ba1\u7684\u504f\u597d\u4e0e\u6743\u8861\uff0c\u53d1\u73b0\u4fdd\u6301\u754c\u9762\u6613\u7528\u6027\u4e0e\u5bf9\u81ea\u9002\u5e94\u63a7\u5236\u6743\u3001\u8f83\u5c11\u9891\u7e41\u548c\u5c0f\u8303\u56f4\u7684\u8c03\u6574\u6709\u52a9\u4e8e\u4fc3\u8fdb\u8bbe\u8ba1\u91c7\u7eb3\uff0c\u800c\u5e38\u7528\u529f\u80fd\u548c\u62a4\u7406\u4eba\u5458\u53c2\u4e0e\u53ef\u80fd\u964d\u4f4e\u81ea\u9002\u5e94\u8bbe\u8ba1\u7684\u4ef7\u503c\u3002\u672c\u7814\u7a76\u8fd8\u901a\u8fc7\u6df7\u5408\u903b\u8f91\u6a21\u578b\u5206\u6790\u4e86\u4e0d\u540c\u5e74\u9f84\u3001\u6027\u522b\u3001\u5065\u5eb7\u72b6\u51b5\u53ca\u5e94\u5bf9\u673a\u5236\u7fa4\u4f53\u7684\u504f\u597d\u5dee\u5f02\uff0c\u91c7\u7528\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u91cf\u5316\u7528\u6237\u504f\u597d\u5e76\u63ed\u793a\u5173\u952e\u6743\u8861\uff0c\u63d0\u4f9b\u672a\u6765\u81ea\u9002\u5e94mHealth\u5e94\u7528\u8bbe\u8ba1\u7684\u91cd\u8981\u6307\u5bfc\u3002", "conclusion": "\u7ef4\u6301\u754c\u9762\u6613\u7528\u6027\u548c\u7528\u6237\u5bf9\u81ea\u9002\u5e94\u529f\u80fd\u7684\u63a7\u5236\u6743\uff0c\u91c7\u7528\u5c11\u9891\u7387\u3001\u5c0f\u89c4\u6a21\u7684\u8c03\u6574\uff0c\u662f\u4fc3\u8fdb\u81ea\u9002\u5e94mHealth\u5e94\u7528\u8bbe\u8ba1\u91c7\u7eb3\u7684\u5173\u952e\u3002\u5e38\u7528\u529f\u80fd\u53ca\u62a4\u7406\u8005\u53c2\u4e0e\u53ef\u80fd\u524a\u5f31\u9002\u5e94\u8bbe\u8ba1\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.18162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18162", "abs": "https://arxiv.org/abs/2511.18162", "authors": ["Sheridan Feucht", "Byron Wallace", "David Bau"], "title": "Vector Arithmetic in Concept and Token Subspaces", "comment": "9 pages, 6 figures. NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "In order to predict the next token, LLMs must represent semantic and surface-level information about the current word. Previous work identified two types of attention heads that disentangle this information: (i) Concept induction heads, which copy word meanings, and (ii) Token induction heads, which copy literal token representations (Feucht et al., 2025). We show that these heads can be used to identify subspaces of model activations that exhibit coherent semantic structure in Llama-2-7b. Specifically, when we transform hidden states using the attention weights of concept heads, we are able to more accurately perform parallelogram arithmetic (Mikolov et al., 2013) on the resulting hidden states, e.g., showing that \"Athens\" - \"Greece\" + \"China\" = \"Beijing\". This transformation allows for much higher nearest-neighbor accuracy (80%) than direct use of raw hidden states (47%). Analogously, we show that token heads allow for transformations that reveal surface-level word information in hidden states, allowing for operations like \"coding\" - \"code\" + \"dance\" = \"dancing\".", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u5206\u6790LLM\u4e2d\u4e24\u7c7b\u6ce8\u610f\u529b\u5934\uff0c\u53d1\u73b0\u5176\u80fd\u591f\u63ed\u793a\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u8bed\u4e49\u548c\u8868\u5c42\u4fe1\u606f\uff0c\u4ece\u800c\u63d0\u5347\u8bcd\u8bed\u8868\u793a\u548c\u76f8\u5173\u8ba1\u7b97\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u5982\u4f55\u901a\u8fc7LLM\u4e2d\u7684\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u63ed\u793a\u548c\u5206\u79bb\u8bed\u4e49\u4e0e\u8868\u5c42\u8bcd\u6c47\u4fe1\u606f\uff0c\u4ee5\u63d0\u9ad8\u5bf9\u8bcd\u8bed\u8868\u793a\u7684\u7406\u89e3\u548c\u64cd\u4f5c\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5206\u6790Llama-2-7b\u6a21\u578b\u4e2d\u7684\u4e24\u7c7b\u6ce8\u610f\u529b\u5934\uff08\u6982\u5ff5\u8bf1\u5bfc\u5934\u548c\u8bcd\u5143\u8bf1\u5bfc\u5934\uff09\u7684\u6743\u91cd\uff0c\u53d8\u6362\u9690\u85cf\u72b6\u6001\uff0c\u4ece\u800c\u63ed\u793a\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u8bed\u4e49\u548c\u8868\u5c42\u4fe1\u606f\u7ed3\u6784\u3002", "result": "\u5229\u7528\u6982\u5ff5\u5934\u8f6c\u6362\u540e\u7684\u9690\u85cf\u72b6\u6001\u80fd\u66f4\u51c6\u786e\u5730\u8fdb\u884c\u5e73\u884c\u56db\u8fb9\u5f62\u7b97\u672f\uff0880%\u7684\u6700\u8fd1\u90bb\u51c6\u786e\u7387\uff09\uff0c\u800c\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u9690\u85cf\u72b6\u6001\u51c6\u786e\u7387\u4ec5\u4e3a47%\uff1b\u8bcd\u5143\u5934\u5219\u80fd\u63ed\u793a\u8868\u5c42\u8bcd\u6c47\u4fe1\u606f\uff0c\u5b9e\u73b0\u8bcd\u5f62\u53d8\u6362\u8fd0\u7b97\u3002", "conclusion": "\u901a\u8fc7\u5173\u6ce8\u4e0d\u540c\u7c7b\u578b\u7684\u6ce8\u610f\u529b\u5934\uff0c\u53ef\u4ee5\u6709\u6548\u5730\u5206\u79bb\u5e76\u5229\u7528\u6a21\u578b\u9690\u85cf\u72b6\u6001\u4e2d\u7684\u8bed\u4e49\u4e0e\u8868\u5c42\u4fe1\u606f\uff0c\u6709\u52a9\u4e8e\u6df1\u5165\u7406\u89e3\u548c\u589e\u5f3a\u8bed\u8a00\u6a21\u578b\u7684\u8bcd\u8bed\u8868\u793a\u80fd\u529b\u3002"}}
{"id": "2511.18634", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18634", "abs": "https://arxiv.org/abs/2511.18634", "authors": ["Wei Wang", "Devi Karolita", "Hourieh Khalajzadeh", "John Grundy", "Anuradha Madugalla", "Humphrey O. Obie"], "title": "ChroniUXMag: A Persona-Driven Framework for Inclusive mHealth Requirements Engineering", "comment": null, "summary": "Mobile health (mHealth) applications are increasingly adopted for chronic disease management, yet they face persistent challenges related to accessibility, inclusivity, and sustained engagement. Patients' needs evolve dynamically with their health progression, adherence, and caregiver support, creating unique requirements engineering (RE) challenges that traditional approaches often overlook. This study introduces ChroniUXMag, a framework for eliciting and analysing inclusivity requirements in mHealth design. Building on InclusiveMag and GenderMag principles, the framework aims to help researchers and practitioners systematically capture and evaluate factors that influence how individuals with chronic conditions perceive, trust, and interact with mHealth systems. The framework was developed through two stages of the InclusiveMag process. In the first stage, inclusivity facets were identified through a systematic literature review, focus groups, interviews, and a large-scale survey. In the second stage, these facets were synthesised into personas representing diverse health situations, attitudes, and digital practices, and integrated into an adapted cognitive walkthrough form. Thirteen facets were identified that capture the socio-technical complexity of mHealth use, including trust, digital literacy, dependency, and cultural context. These facets support structured, persona-driven evaluations that reveal inclusivity barriers often missed by traditional usability assessments. ChroniUXMag contributes to RE by offering a reproducible, evidence-based approach for embedding inclusivity into mHealth requirements. Future work will extend the third stage Apply through practitioner-led evaluation in real-world design contexts.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86ChroniUXMag\u6846\u67b6\uff0c\u901a\u8fc7\u7cfb\u7edf\u5316\u65b9\u6cd5\u6355\u6349\u548c\u8bc4\u4f30\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u4e2d\u5f71\u54cd\u5305\u5bb9\u6027\u7684\u56e0\u7d20\uff0c\u52a9\u529b\u6784\u5efa\u66f4\u5305\u5bb9\u7684\u6162\u75c5\u7ba1\u7406\u5de5\u5177\u3002", "motivation": "\u6162\u6027\u75c5\u7ba1\u7406\u7684\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u5b58\u5728\u53ef\u53ca\u6027\u3001\u5305\u5bb9\u6027\u548c\u6301\u7eed\u53c2\u4e0e\u7684\u6311\u6218\uff0c\u4f20\u7edf\u9700\u6c42\u5de5\u7a0b\u65b9\u6cd5\u65e0\u6cd5\u5145\u5206\u5e94\u5bf9\u7528\u6237\u4e0d\u65ad\u53d8\u5316\u7684\u9700\u6c42\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u7684InclusiveMag\u8fc7\u7a0b\uff0c\u901a\u8fc7\u7cfb\u7edf\u6587\u732e\u56de\u987e\u3001\u7126\u70b9\u5c0f\u7ec4\u3001\u8bbf\u8c08\u548c\u5927\u89c4\u6a21\u8c03\u67e5\u786e\u5b9a\u5305\u5bb9\u6027\u65b9\u9762\uff0c\u5e76\u5c06\u5176\u7efc\u5408\u6210\u4ee3\u8868\u591a\u6837\u5065\u5eb7\u72b6\u51b5\u548c\u6570\u5b57\u884c\u4e3a\u7684\u4eba\u7269\u89d2\u8272\uff0c\u7ed3\u5408\u8ba4\u77e5\u6f14\u7ec3\u65b9\u6cd5\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc6\u522b\u51fa13\u4e2a\u53cd\u6620\u79fb\u52a8\u5065\u5eb7\u4f7f\u7528\u793e\u4f1a\u6280\u672f\u590d\u6742\u6027\u7684\u5305\u5bb9\u6027\u65b9\u9762\uff0c\u5982\u4fe1\u4efb\u3001\u6570\u5b57\u7d20\u517b\u3001\u4f9d\u8d56\u6027\u548c\u6587\u5316\u80cc\u666f\uff0c\u652f\u6301\u901a\u8fc7\u4eba\u7269\u89d2\u8272\u9a71\u52a8\u7684\u7ed3\u6784\u5316\u8bc4\u4f30\uff0c\u63ed\u793a\u4f20\u7edf\u53ef\u7528\u6027\u8bc4\u4f30\u5ffd\u89c6\u7684\u5305\u5bb9\u6027\u969c\u788d\u3002", "conclusion": "ChroniUXMag\u4e3a\u6162\u6027\u75c5\u79fb\u52a8\u5065\u5eb7\u5e94\u7528\u7684\u9700\u6c42\u5de5\u7a0b\u63d0\u4f9b\u4e86\u57fa\u4e8e\u8bc1\u636e\u7684\u53ef\u590d\u73b0\u65b9\u6cd5\uff0c\u672a\u6765\u5c06\u901a\u8fc7\u5b9e\u9645\u8bbe\u8ba1\u5b9e\u8df5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u548c\u5b8c\u5584\u3002"}}
{"id": "2511.18177", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18177", "abs": "https://arxiv.org/abs/2511.18177", "authors": ["Elias Lumer", "Matt Melich", "Olivia Zino", "Elena Kim", "Sara Dieter", "Pradeep Honaganahalli Basavaraju", "Vamse Kumar Subbiah", "James A. Burke", "Roberto Hernandez"], "title": "Rethinking Retrieval: From Traditional Retrieval Augmented Generation to Agentic and Non-Vector Reasoning Systems in the Financial Domain for Large Language Models", "comment": "8 pages, 2 figures", "summary": "Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models to answer financial questions using external knowledge bases of U.S. SEC filings, earnings reports, and regulatory documents. However, existing work lacks systematic comparison of vector-based and non-vector RAG architectures for financial documents, and the empirical impact of advanced RAG techniques on retrieval accuracy, answer quality, latency, and cost remain unclear. We present the first systematic evaluation comparing vector-based agentic RAG using hybrid search and metadata filtering against hierarchical node-based systems that traverse document structure without embeddings. We evaluate two enhancement techniques applied to the vector-based architecture, i) cross-encoder reranking for retrieval precision, and ii) small-to-big chunk retrieval for context completeness. Across 1,200 SEC 10-K, 10-Q, and 8-K filings on a 150-question benchmark, we measure retrieval metrics (MRR, Recall@5), answer quality through LLM-as-a-judge pairwise comparisons, latency, and preprocessing costs. Vector-based agentic RAG achieves a 68% win rate over hierarchical node-based systems with comparable latency (5.2 compared to 5.98 seconds). Cross-encoder reranking achieves a 59% absolute improvement at optimal parameters (10, 5) for MRR@5. Small-to-big retrieval achieves a 65% win rate over baseline chunking with only 0.2 seconds additional latency. Our findings reveal that applying advanced RAG techniques to financial Q&A systems improves retrieval accuracy, answer quality, and has cost-performance tradeoffs to be considered in production.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u8bc4\u6d4b\u4e86\u91d1\u878d\u6587\u6863\u95ee\u7b54\u4e2d\u57fa\u4e8e\u5411\u91cf\u4e0e\u975e\u5411\u91cfRAG\u7cfb\u7edf\uff0c\u53d1\u73b0\u5148\u8fdbRAG\u6280\u672f\u663e\u8457\u63d0\u5347\u68c0\u7d22\u548c\u56de\u7b54\u8868\u73b0\uff0c\u4e14\u6210\u672c\u4e0e\u6027\u80fd\u6709\u6743\u8861\u3002", "motivation": "\u5df2\u6709\u5de5\u4f5c\u7f3a\u4e4f\u5bf9\u91d1\u878d\u6587\u6863\u4e2d\u57fa\u4e8e\u5411\u91cf\u4e0e\u975e\u5411\u91cfRAG\u67b6\u6784\u7684\u7cfb\u7edf\u6027\u6bd4\u8f83\uff0c\u4ee5\u53ca\u5148\u8fdbRAG\u6280\u672f\u5bf9\u68c0\u7d22\u51c6\u786e\u7387\u3001\u56de\u7b54\u8d28\u91cf\u3001\u5ef6\u8fdf\u548c\u6210\u672c\u7684\u5b9e\u8bc1\u5f71\u54cd\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4e86\u57fa\u4e8e\u5411\u91cf\u7684\u4ee3\u7406RAG\uff08\u7ed3\u5408\u6df7\u5408\u641c\u7d22\u548c\u5143\u6570\u636e\u8fc7\u6ee4\uff09\u4e0e\u57fa\u4e8e\u5c42\u6b21\u8282\u70b9\u7684\u65e0\u5d4c\u5165\u7684RAG\u7cfb\u7edf\uff0c\u8bc4\u4f30\u4e86\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u548c\u5c0f\u5230\u5927\u5757\u68c0\u7d22\u4e24\u79cd\u589e\u5f3a\u6280\u672f\uff0c\u57281200\u4efdSEC\u6587\u4ef6\u548c150\u4e2a\u95ee\u9898\u57fa\u51c6\u4e0a\u7684\u8868\u73b0\uff0c\u5305\u62ecMRR\u3001Recall@5\u3001\u56de\u7b54\u8d28\u91cf\u3001\u5ef6\u8fdf\u53ca\u9884\u5904\u7406\u6210\u672c\u3002", "result": "\u57fa\u4e8e\u5411\u91cf\u7684\u4ee3\u7406RAG\u5728\u56de\u7b54\u8d28\u91cf\u4e0a\u4ee568%\u80dc\u7387\u4f18\u4e8e\u5c42\u6b21\u8282\u70b9\u7cfb\u7edf\uff0c\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u4f7fMRR@5\u63d0\u534759%\uff0c\u5c0f\u5230\u5927\u5757\u68c0\u7d22\u4ee565%\u80dc\u7387\u4f18\u4e8e\u57fa\u7ebf\u68c0\u7d22\uff0c\u540c\u65f6\u5ef6\u8fdf\u4ec5\u589e\u52a00.2\u79d2\u3002", "conclusion": "\u57fa\u4e8e\u5411\u91cf\u7684RAG\u67b6\u6784\u5728\u68c0\u7d22\u51c6\u786e\u5ea6\u548c\u56de\u7b54\u8d28\u91cf\u4e0a\u4f18\u4e8e\u57fa\u4e8e\u5c42\u6b21\u8282\u70b9\u7684\u7cfb\u7edf\uff0c\u4e14\u5ef6\u8fdf\u76f8\u8fd1\u3002\u9ad8\u7ea7RAG\u6280\u672f\u5982\u4ea4\u53c9\u7f16\u7801\u5668\u91cd\u6392\u5e8f\u548c\u5c0f\u5230\u5927\u5757\u68c0\u7d22\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u8868\u73b0\u3002"}}
{"id": "2511.18782", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18782", "abs": "https://arxiv.org/abs/2511.18782", "authors": ["Lukas Twist"], "title": "Summary-Mediated Repair: Can LLMs use code summarisation as a tool for program repair?", "comment": "6 pages, 3 tables, 1 figure", "summary": "Large Language Models (LLMs) often produce code with subtle implementation-level bugs despite strong benchmark performance. These errors are hard for LLMs to spot and can have large behavioural effects; yet when asked to summarise code, LLMs can frequently surface high-level intent and sometimes overlook this low-level noise. Motivated by this, we propose summary-mediated repair, a prompt-only pipeline for program repair that leverages natural-language code summarisation as an explicit intermediate step, extending previous work that has already shown code summarisation to be a useful intermediary for downstream tasks. We evaluate our method across eight production-grade LLMs on two function level benchmarks (HumanEvalPack and MBPP), comparing several summary styles against a direct repair baseline. Error-aware diagnostic summaries consistently yield the largest gains - repairing up to 65% of unseen errors, on average of 5% more than the baseline - though overall improvements are modest and LLM-dependent. Our results position summaries as a cheap, human-interpretable diagnostic artefact that can be integrated into program-repair pipelines rather than a stand-alone fix-all.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4ee3\u7801\u6458\u8981\u7684\u7a0b\u5e8f\u4fee\u590d\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u4fee\u590d\u8fc7\u7a0b\u4e2d\u52a0\u5165\u81ea\u7136\u8bed\u8a00\u4ee3\u7801\u6458\u8981\u4f5c\u4e3a\u4e2d\u95f4\u6b65\u9aa4\uff0c\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u4fee\u590d\u4ee3\u7801\u9519\u8bef\u7684\u6548\u679c\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5b83\u4eec\u5e38\u72af\u7ec6\u5fae\u5b9e\u73b0\u9519\u8bef\u4e14\u96be\u4ee5\u5bdf\u89c9\uff0c\u4ee3\u7801\u6458\u8981\u80fd\u63ed\u793a\u9ad8\u5c42\u610f\u56fe\uff0c\u6fc0\u53d1\u5c06\u6458\u8981\u4f5c\u4e3a\u4fee\u590d\u7684\u4e2d\u95f4\u6b65\u9aa4\u3002", "method": "\u672c\u6587\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u53ea\u7528\u63d0\u793a\u7684\u4fee\u590d\u6d41\u7a0b\uff0c\u5148\u751f\u6210\u4ee3\u7801\u7684\u81ea\u7136\u8bed\u8a00\u6458\u8981\uff0c\u518d\u6839\u636e\u6458\u8981\u4fee\u590d\u4ee3\u7801\uff0c\u5bf9\u6bd4\u4e0d\u540c\u6458\u8981\u98ce\u683c\u4e0e\u76f4\u63a5\u4fee\u590d\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002", "result": "\u57288\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u548c\u4e24\u4e2a\u51fd\u6570\u7ea7\u57fa\u51c6\u6d4b\u8bd5\uff08HumanEvalPack\u548cMBPP\uff09\u4e0a\uff0c\u9519\u8bef\u611f\u77e5\u6458\u8981\u65b9\u6cd5\u80fd\u4fee\u590d\u7ea665%\u7684\u672a\u77e5\u9519\u8bef\uff0c\u8f83\u57fa\u7ebf\u5e73\u5747\u63d0\u53475%\u3002", "conclusion": "\u5229\u7528\u9519\u8bef\u611f\u77e5\u7684\u8bca\u65ad\u6027\u4ee3\u7801\u6458\u8981\u4f5c\u4e3a\u4e2d\u95f4\u73af\u8282\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u7a0b\u5e8f\u4fee\u590d\u6548\u679c\uff0c\u4fee\u590d\u7387\u63d0\u5347\u4e86\u7ea65%\uff0c\u4f46\u6574\u4f53\u6539\u8fdb\u53d7\u9650\u4e8e\u5177\u4f53\u7684\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u3002"}}
{"id": "2511.18194", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18194", "abs": "https://arxiv.org/abs/2511.18194", "authors": ["Faheem Nizar", "Elias Lumer", "Anmol Gulati", "Pradeep Honaganahalli Basavaraju", "Vamse Kumar Subbiah"], "title": "Agent-as-a-Graph: Knowledge Graph-Based Tool and Agent Retrieval for LLM Multi-Agent Systems", "comment": null, "summary": "Recent advances in Large Language Model Multi-Agent Systems enable scalable orchestration and retrieval of specialized, parallelized subagents, each equipped with hundreds or thousands of Model Context Protocol (MCP) servers and tools. However, existing agent, MCP, and retrieval methods typically match queries against a single agent description, obscuring fine-grained tool capabilities of each agent, resulting in suboptimal agent selection. We introduce Agent-as-a-Graph retrieval, a knowledge graph retrieval augmented generation approach that represents both tools and their parent agents as nodes and edges in a knowledge graph. During retrieval, i) relevant agents and tool nodes are first retrieved through vector search, ii) we apply a type-specific weighted reciprocal rank fusion (wRRF) for reranking tools and agents, and iii) parent agents are traversed in the knowledge graph for the final set of agents. We evaluate Agent-as-a-Graph on the LiveMCPBenchmark, achieving 14.9% and 14.6% improvements in Recall@5 and nDCG@5 over prior state-of-the-art retrievers, and 2.4% improvements in wRRF optimizations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aAgent-as-a-Graph\u7684\u77e5\u8bc6\u56fe\u8c31\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u5de5\u5177\u548c\u5176\u7236\u4ee3\u7406\u8868\u793a\u4e3a\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u8fb9\uff0c\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u7684\u68c0\u7d22\u548c\u6392\u5e8f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u7684\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u7684\u4ee3\u7406\u5de5\u5177\u5339\u914d\u65b9\u6cd5\u901a\u5e38\u4ec5\u57fa\u4e8e\u5355\u4e00\u4ee3\u7406\u63cf\u8ff0\uff0c\u5ffd\u7565\u4e86\u4ee3\u7406\u5185\u90e8\u7ec6\u7c92\u5ea6\u7684\u5de5\u5177\u80fd\u529b\uff0c\u5bfc\u81f4\u4ee3\u7406\u9009\u62e9\u6548\u679c\u4e0d\u4f73\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7ec6\u7c92\u5ea6\u8868\u8fbe\u548c\u68c0\u7d22\u4ee3\u7406\u53ca\u5176\u5de5\u5177\u7684\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u4ee3\u7406\u548c\u5de5\u5177\u6784\u5efa\u6210\u77e5\u8bc6\u56fe\u8c31\u4e2d\u7684\u8282\u70b9\u548c\u8fb9\uff0c\u9996\u5148\u901a\u8fc7\u5411\u91cf\u641c\u7d22\u68c0\u7d22\u76f8\u5173\u8282\u70b9\uff0c\u968f\u540e\u5e94\u7528\u9488\u5bf9\u7c7b\u578b\u7684\u52a0\u6743\u4e92\u60e0\u6392\u540d\u878d\u5408\u7b97\u6cd5\u5bf9\u4ee3\u7406\u548c\u5de5\u5177\u8fdb\u884c\u91cd\u6392\u5e8f\uff0c\u6700\u540e\u904d\u5386\u77e5\u8bc6\u56fe\u8c31\u4ee5\u786e\u5b9a\u6700\u7ec8\u4ee3\u7406\u96c6\u5408\u3002", "result": "\u5728LiveMCPBenchmark\u6d4b\u8bd5\u4e2d\uff0cAgent-as-a-Graph\u65b9\u6cd5\u5728Recall@5\u548cnDCG@5\u6307\u6807\u4e0a\u5206\u522b\u63d0\u5347\u4e8614.9%\u548c14.6%\uff0c\u52a0\u6743\u4e92\u60e0\u6392\u540d\u878d\u5408\u4f18\u5316\u5e26\u6765\u4e862.4%\u7684\u989d\u5916\u63d0\u5347\u3002", "conclusion": "Agent-as-a-Graph\u65b9\u6cd5\u901a\u8fc7\u77e5\u8bc6\u56fe\u8c31\u7ed3\u6784\u548c\u52a0\u6743\u4e92\u60e0\u6392\u540d\u878d\u5408\u6280\u672f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u591a\u4ee3\u7406\u7cfb\u7edf\u4e2d\u4ee3\u7406\u53ca\u5de5\u5177\u7684\u68c0\u7d22\u6548\u679c\uff0c\u5728LiveMCPBenchmark\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2511.18842", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18842", "abs": "https://arxiv.org/abs/2511.18842", "authors": ["Mohammad Nour Al Awad", "Sergey Ivanov", "Olga Tikhonova"], "title": "Optimizing LLM Code Suggestions: Feedback-Driven Timing with Lightweight State Bounds", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Large Language Models (LLMs) have transformed code auto-completion by generating context-aware suggestions. Yet, deciding when to present these suggestions remains underexplored, often leading to interruptions or wasted inference calls. We propose an adaptive timing mechanism that dynamically adjusts the delay before offering a suggestion based on real-time developer feedback. Our suggested method combines a logistic transform of recent acceptance rates with a bounded delay range, anchored by a high-level binary prediction of the developer's cognitive state. In a two-month deployment with professional developers, our system improved suggestion acceptance from 4.9% with no delay to 15.4% with static delays, and to 18.6% with adaptive timing-while reducing blind rejections (rejections without being read) from 8.3% to 0.36%. Together, these improvements increase acceptance and substantially reduce wasted inference calls by 75%, making LLM-based code assistants more efficient and cost-effective in practice.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u5ef6\u8fdf\u673a\u5236\u52a8\u6001\u8c03\u6574\u4ee3\u7801\u8865\u5168\u5efa\u8bae\u5c55\u793a\u65f6\u673a\uff0c\u663e\u8457\u63d0\u5347\u63a5\u53d7\u7387\uff0c\u51cf\u5c11\u65e0\u6548\u8ba1\u7b97\uff0c\u63d0\u9ad8\u6548\u7387\u3002", "motivation": "\u4ee3\u7801\u81ea\u52a8\u8865\u5168\u4e2d\u4f55\u65f6\u5c55\u793a\u5efa\u8bae\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u9519\u8bef\u7684\u65f6\u673a\u4f1a\u5bfc\u81f4\u5f00\u53d1\u8005\u6253\u65ad\u6216\u6d6a\u8d39\u8ba1\u7b97\u8d44\u6e90\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u81ea\u9002\u5e94\u5b9a\u65f6\u673a\u5236\uff0c\u6839\u636e\u5f00\u53d1\u8005\u5b9e\u65f6\u53cd\u9988\u52a8\u6001\u8c03\u6574\u63d0\u4f9b\u5efa\u8bae\u7684\u5ef6\u8fdf\u65f6\u95f4\uff0c\u7ed3\u5408\u6700\u8fd1\u63a5\u53d7\u7387\u7684\u903b\u8f91\u53d8\u6362\u548c\u5f00\u53d1\u8005\u8ba4\u77e5\u72b6\u6001\u7684\u4e8c\u5143\u9884\u6d4b\u3002", "result": "\u4e24\u4e2a\u6708\u90e8\u7f72\u4e2d\uff0c\u76f8\u6bd4\u65e0\u5ef6\u8fdf\uff0c\u9759\u6001\u5ef6\u8fdf\u63d0\u5347\u63a5\u53d7\u7387\u81f315.4%\uff0c\u81ea\u9002\u5e94\u5b9a\u65f6\u8fdb\u4e00\u6b65\u63d0\u5347\u81f318.6%\uff0c\u76f2\u76ee\u62d2\u7edd\u7387\u4ece8.3%\u964d\u81f30.36%\uff0c\u51cf\u5c11\u4e8675%\u7684\u65e0\u6548\u63a8\u65ad\u8c03\u7528\u3002", "conclusion": "\u81ea\u9002\u5e94\u5b9a\u65f6\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86LLM\u4ee3\u7801\u52a9\u624b\u7684\u5efa\u8bae\u63a5\u53d7\u7387\u548c\u6548\u7387\uff0c\u964d\u4f4e\u8ba1\u7b97\u8d44\u6e90\u6d6a\u8d39\uff0c\u63d0\u9ad8\u4e86\u5b9e\u7528\u6027\u3002"}}
{"id": "2511.18849", "categories": ["cs.SE", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2511.18849", "abs": "https://arxiv.org/abs/2511.18849", "authors": ["Mohammad Nour Al Awad", "Sergey Ivanov", "Olga Tikhonova"], "title": "Pre-Filtering Code Suggestions using Developer Behavioral Telemetry to Optimize LLM-Assisted Programming", "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Large Language Models (LLMs) are increasingly integrated into code editors to provide AI-powered code suggestions. Yet many of these suggestions are ignored, resulting in wasted computation, increased latency, and unnecessary interruptions. We introduce a lightweight pre-filtering model that predicts the likelihood of suggestion acceptance before invoking the LLM, using only real-time developer telemetry such as typing speed, file navigation, and editing activity. Deployed in a production-grade Visual Studio Code plugin over four months of naturalistic use, our approach nearly doubled acceptance rates (18.4% -> 34.2%) while suppressing 35% of low-value LLM calls. These findings demonstrate that behavioral signals alone can meaningfully improve both user experience and system efficiency in LLM-assisted programming, highlighting the value of timing-aware, privacy-preserving adaptation mechanisms. The filter operates solely on pre-invocation editor telemetry and never inspects code or prompts.", "AI": {"tldr": "\u57fa\u4e8e\u884c\u4e3a\u4fe1\u53f7\u7684\u9884\u8fc7\u6ee4\u6a21\u578b\u63d0\u5347\u4e86\u4ee3\u7801\u5efa\u8bae\u7684\u63a5\u53d7\u7387\u548c\u7cfb\u7edf\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u3002", "motivation": "\u8bb8\u591a\u7531LLM\u751f\u6210\u7684\u4ee3\u7801\u5efa\u8bae\u88ab\u5ffd\u7565\uff0c\u5bfc\u81f4\u8ba1\u7b97\u6d6a\u8d39\u3001\u5ef6\u8fdf\u589e\u52a0\u548c\u4e0d\u5fc5\u8981\u7684\u4e2d\u65ad\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u7684\u9884\u8fc7\u6ee4\u6a21\u578b\uff0c\u5728\u8c03\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4e4b\u524d\uff0c\u4ec5\u5229\u7528\u5b9e\u65f6\u5f00\u53d1\u8005\u7684\u9065\u6d4b\u6570\u636e\uff08\u5982\u6253\u5b57\u901f\u5ea6\u3001\u6587\u4ef6\u5bfc\u822a\u548c\u7f16\u8f91\u6d3b\u52a8\uff09\u9884\u6d4b\u4ee3\u7801\u5efa\u8bae\u88ab\u63a5\u53d7\u7684\u53ef\u80fd\u6027\u3002", "result": "\u5728Visual Studio Code\u63d2\u4ef6\u7684\u5b9e\u9645\u751f\u4ea7\u73af\u5883\u4e2d\u4f7f\u7528\u56db\u4e2a\u6708\uff0c\u6a21\u578b\u5c06\u5efa\u8bae\u63a5\u53d7\u7387\u4ece18.4%\u63d0\u5347\u81f334.2%\uff0c\u540c\u65f6\u6291\u5236\u4e8635%\u7684\u4f4e\u4ef7\u503cLLM\u8c03\u7528\u3002", "conclusion": "\u4ec5\u5229\u7528\u7f16\u8f91\u5668\u8c03\u7528\u524d\u7684\u9065\u6d4b\u6570\u636e\uff0c\u4e14\u4e0d\u8bbf\u95ee\u4ee3\u7801\u6216\u63d0\u793a\u5185\u5bb9\uff0c\u5373\u53ef\u663e\u8457\u63d0\u5347\u7528\u6237\u4f53\u9a8c\u548c\u7cfb\u7edf\u6548\u7387\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8e\u65f6\u673a\u611f\u77e5\u548c\u9690\u79c1\u4fdd\u62a4\u7684\u9002\u5e94\u673a\u5236\u7684\u4ef7\u503c\u3002"}}
{"id": "2511.18301", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18301", "abs": "https://arxiv.org/abs/2511.18301", "authors": ["Harsh Rathva", "Pruthwik Mishra", "Shrikant Malviya"], "title": "\"AGI\" team at SHROOM-CAP: Data-Centric Approach to Multilingual Hallucination Detection using XLM-RoBERTa", "comment": "Accepted to the 1st Workshop on Confabulation, Hallucinations & Overgeneration in Multilingual and Practical Settings (CHOMPS) at AACL-IJCNLP 2025", "summary": "The detection of hallucinations in multilingual scientific text generated by Large Language Models (LLMs) presents significant challenges for reliable AI systems. This paper describes our submission to the SHROOM-CAP 2025 shared task on scientific hallucination detection across 9 languages. Unlike most approaches that focus primarily on model architecture, we adopted a data-centric strategy that addressed the critical issue of training data scarcity and imbalance. We unify and balance five existing datasets to create a comprehensive training corpus of 124,821 samples (50% correct, 50% hallucinated), representing a 172x increase over the original SHROOM training data. Our approach fine-tuned XLM-RoBERTa-Large with 560 million parameters on this enhanced dataset, achieves competitive performance across all languages, including \\textbf{2nd place in Gujarati} (zero-shot language) with Factuality F1 of 0.5107, and rankings between 4th-6th place across the remaining 8 languages. Our results demonstrate that systematic data curation can significantly outperform architectural innovations alone, particularly for low-resource languages in zero-shot settings.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u6574\u5408\u5927\u89c4\u6a21\u3001\u591a\u8bed\u8a00\u5e73\u8861\u6570\u636e\uff0c\u5fae\u8c03XLM-RoBERTa-Large\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u79d1\u5b66\u6587\u672c\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u7684\u591a\u8bed\u79cd\u9ad8\u6027\u80fd\uff0c\u5c24\u5176\u5728\u96f6\u6837\u672c\u8bed\u8a00\u4e2d\u8868\u73b0\u7a81\u51fa\u3002", "motivation": "\u9762\u5bf9\u591a\u8bed\u8a00\u79d1\u5b66\u6587\u672c\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u4e2d\u8bad\u7ec3\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u5e73\u8861\u7684\u95ee\u9898\uff0c\u5bfb\u6c42\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u548c\u96f6\u6837\u672c\u8bed\u8a00\u573a\u666f\u3002", "method": "\u6574\u5408\u5e76\u5747\u8861\u4e94\u4e2a\u591a\u8bed\u8a00\u6570\u636e\u96c6\uff0c\u6784\u5efa\u5927\u578b\u8bad\u7ec3\u96c6\uff1b\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\u5fae\u8c03XLM-RoBERTa-Large\u6a21\u578b\u8fdb\u884c\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u3002", "result": "\u672c\u6587\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u591a\u8bed\u8a00\u79d1\u5b66\u6587\u672c\u4e2d\u7684\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u3002\u901a\u8fc7\u6574\u5408\u548c\u5747\u8861\u4e94\u4e2a\u73b0\u6709\u6570\u636e\u96c6\uff0c\u6784\u5efa\u4e86\u5305\u542b124,821\u4e2a\u6837\u672c\u7684\u8bad\u7ec3\u8bed\u6599\u5e93\uff0c\u6570\u636e\u91cf\u662f\u539f\u59cbSHROOM\u8bad\u7ec3\u6570\u636e\u7684172\u500d\uff0c\u4ee5\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u548c\u4e0d\u5e73\u8861\u95ee\u9898\u3002\u5728\u6b64\u57fa\u7840\u4e0a\uff0c\u5fae\u8c03\u4e86\u5177\u67095.6\u4ebf\u53c2\u6570\u7684XLM-RoBERTa-Large\u6a21\u578b\uff0c\u57289\u79cd\u8bed\u8a00\u7684\u865a\u5047\u4fe1\u606f\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u96f6\u6837\u672c\u8bed\u8a00\u53e4\u5409\u62c9\u7279\u8bed\u4e2d\u83b7\u5f97\u4e86\u7b2c\u4e8c\u540d\u3002\u7ed3\u679c\u8868\u660e\uff0c\u7cfb\u7edf\u6027\u7684\u6570\u636e\u6574\u7406\u6bd4\u6a21\u578b\u7ed3\u6784\u521b\u65b0\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u96f6\u6837\u672c\u4efb\u52a1\u66f4\u4e3a\u6709\u6548\u3002", "conclusion": "\u7cfb\u7edf\u6027\u7684\u6570\u636e\u96c6\u6784\u5efa\u548c\u5747\u8861\u5904\u7406\u80fd\u663e\u8457\u63d0\u5347\u591a\u8bed\u8a00\u79d1\u5b66\u6587\u672c\u865a\u5047\u68c0\u6d4b\u6027\u80fd\uff0c\u5c24\u5176\u5bf9\u4e8e\u4f4e\u8d44\u6e90\u548c\u96f6\u6837\u672c\u8bed\u8a00\u6548\u679c\u4f18\u4e8e\u5355\u7eaf\u7684\u6a21\u578b\u7ed3\u6784\u6539\u8fdb\u3002"}}
{"id": "2511.18854", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18854", "abs": "https://arxiv.org/abs/2511.18854", "authors": ["Yujing Wang", "Weize Hong"], "title": "Time Travel: LLM-Assisted Semantic Behavior Localization with Git Bisect", "comment": "submitted to Git Bisect SCALCOM 2025 Calgary (to be published)", "summary": "We present a novel framework that integrates Large Language Models (LLMs) into the Git bisect process for semantic fault localization. Traditional bisect assumes deterministic predicates and binary failure states assumptions often violated in modern software development due to flaky tests, nonmonotonic regressions, and semantic divergence from upstream repositories. Our system augments bisect traversal with structured chain of thought reasoning, enabling commit by commit analysis under noisy conditions. We evaluate multiple open source and proprietary LLMs for their suitability and fine tune DeepSeekCoderV2 using QLoRA on a curated dataset of semantically labeled diffs. We adopt a weak supervision workflow to reduce annotation overhead, incorporating human in the loop corrections and self consistency filtering. Experiments across multiple open source projects show a 6.4 point absolute gain in success rate from 74.2 to 80.6 percent, leading to significantly fewer failed traversals and by experiment up to 2x reduction in average bisect time. We conclude with discussions on temporal reasoning, prompt design, and finetuning strategies tailored for commit level behavior analysis.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u5230 Git bisect \u8bed\u4e49\u6545\u969c\u5b9a\u4f4d\u6d41\u7a0b\uff0c\u672c\u6587\u63d0\u5347\u4e86\u5b9a\u4f4d\u6210\u529f\u7387\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf Git bisect \u5047\u8bbe\u6d4b\u8bd5\u548c\u56de\u5f52\u72b6\u6001\u786e\u5b9a\u6027\uff0c\u4f46\u73b0\u4ee3\u5f00\u53d1\u73af\u5883\u4e2d\u5b58\u5728\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u3001\u56de\u5f52\u975e\u5355\u8c03\u53ca\u8bed\u4e49\u6f02\u79fb\uff0c\u5bfc\u81f4\u5b9a\u4f4d\u6548\u679c\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7a33\u5b9a\u8fdb\u884c\u8bed\u4e49\u5b9a\u4f4d\u7684\u65b9\u6cd5\u3002", "method": "\u7ed3\u5408\u7ed3\u6784\u5316\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u5728 bisect \u904d\u5386\u4e2d\u9010\u63d0\u4ea4\u5206\u6790\uff0c\u4f7f\u7528 QLoRA \u5bf9 DeepSeekCoderV2 \u8fdb\u884c\u5fae\u8c03\uff0c\u91c7\u7528\u5f31\u76d1\u7763\u7ed3\u5408\u4eba\u673a\u4ea4\u4e92\u4fee\u6b63\u53ca\u81ea\u6211\u4e00\u81f4\u6027\u8fc7\u6ee4\u4ee5\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u96c6\u6210\u5230 Git bisect \u8fc7\u7a0b\u4e2d\u7528\u4e8e\u8bed\u4e49\u6545\u969c\u5b9a\u4f4d\u7684\u65b0\u6846\u67b6\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u601d\u7ef4\u94fe\u63a8\u7406\uff0c\u589e\u5f3a\u4e86\u5728\u6d4b\u8bd5\u4e0d\u7a33\u5b9a\u3001\u56de\u5f52\u975e\u5355\u8c03\u53ca\u8bed\u4e49\u5dee\u5f02\u7b49\u566a\u58f0\u6761\u4ef6\u4e0b\u5bf9\u6bcf\u6b21\u63d0\u4ea4\u7684\u5206\u6790\u80fd\u529b\u3002\u5bf9\u591a\u79cd\u5f00\u6e90\u548c\u4e13\u6709 LLMs \u8fdb\u884c\u4e86\u8bc4\u4f30\uff0c\u5e76\u5229\u7528 QLoRA \u5bf9 DeepSeekCoderV2 \u5728\u8bed\u4e49\u6807\u6ce8\u7684\u5dee\u5f02\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u5fae\u8c03\u3002\u540c\u65f6\u91c7\u7528\u5f31\u76d1\u7763\u5de5\u4f5c\u6d41\u51cf\u5c11\u6807\u6ce8\u6210\u672c\uff0c\u7ed3\u5408\u4eba\u5de5\u4fee\u6b63\u548c\u81ea\u6211\u4e00\u81f4\u6027\u8fc7\u6ee4\u3002\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u4e2a\u5f00\u6e90\u9879\u76ee\u4e2d\u6210\u529f\u7387\u4ece74.2%\u63d0\u5347\u81f380.6%\uff0c\u5e73\u5747 bisect \u65f6\u95f4\u6700\u591a\u51cf\u5c1150%\u3002\u6700\u7ec8\uff0c\u8bba\u6587\u63a2\u8ba8\u4e86\u65f6\u5e8f\u63a8\u7406\u3001\u63d0\u793a\u8bbe\u8ba1\u53ca\u5fae\u8c03\u7b56\u7565\u7684\u4f18\u5316\u3002", "conclusion": "\u96c6\u6210\u5927\u8bed\u8a00\u6a21\u578b\u7684 Git bisect \u65b9\u6cd5\u80fd\u591f\u5728\u566a\u58f0\u73af\u5883\u4e0b\u7a33\u5b9a\u63d0\u5347\u8bed\u4e49\u6545\u969c\u5b9a\u4f4d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\uff0c\u663e\u8457\u51cf\u5c11\u5931\u8d25\u6b21\u6570\u548c\u5b9a\u4f4d\u65f6\u95f4\u3002"}}
{"id": "2511.18306", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18306", "abs": "https://arxiv.org/abs/2511.18306", "authors": ["Mohammad Aqib", "Mohd Hamza", "Ying Hei Chui", "Qipei Mei"], "title": "Table Comprehension in Building Codes using Vision Language Models and Domain-Specific Fine-Tuning", "comment": null, "summary": "Building codes contain critical information for ensuring safety, regulatory compliance, and informed decision-making in construction and engineering. Automated question answering systems over such codes enable quick and accurate access to specific regulatory clauses, improving efficiency and reducing errors. Retrieval-Augmented Generation (RAG) systems are essential for this task as they combine the precision of information retrieval with the generative capabilities of language models. However, tabular data are challenging to extract as they often involve complex layouts, merged cells, multi-row headers, and embedded semantic relationships that are not easily captured by traditional natural language processing techniques and Vision Language Models (VLMs). This paper explores and compares two methods for extracting information from tabular data in building codes using several pre-trained VLMs. First, a direct input method is used, where the image of the page is input directly into the VLMs, which are then tasked with answering questions based on the image. Second, an indirect input method is introduced, which involves converting an image of a page containing tables into the LaTeX code and then answering inquires based on the LaTeX-based input. The experiments find that the direct input method generally resulted in higher accuracy than the indirect input method. To further improve the performance, we fine-tuned each VLM using Low Rank Adaptation (LoRA) on a domain-specific tabular dataset. The fine-tuned models exhibited substantial improvements, with Qwen2.5-VL-3B-Instruct achieving relative accuracy gains exceeding 100%. Our results highlight the potential of parameter-efficient fine-tuning methods to adapt powerful VLMs for understanding complex structured data in specialized fields, such as building code interpretation and regulatory compliance.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5efa\u7b51\u89c4\u8303\u4e2d\u590d\u6742\u8868\u683c\u4fe1\u606f\u63d0\u53d6\u95ee\u9898\uff0c\u6bd4\u8f83\u76f4\u63a5\u56fe\u50cf\u8f93\u5165\u4e0eLaTeX\u8f6c\u6362\u4e24\u79cdVLM\u95ee\u7b54\u65b9\u6cd5\uff0c\u53d1\u73b0\u76f4\u63a5\u8f93\u5165\u66f4\u4f18\uff0c\u5e76\u901a\u8fc7LoRA\u5fae\u8c03\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5efa\u7b51\u89c4\u8303\u4e2d\u8868\u683c\u6570\u636e\u63d0\u53d6\u96be\u9898\uff0c\u63d0\u5347\u81ea\u52a8\u95ee\u7b54\u7cfb\u7edf\u5bf9\u590d\u6742\u8868\u683c\u4fe1\u606f\u7684\u51c6\u786e\u7406\u89e3\u3002", "method": "\u6bd4\u8f83\u4e24\u79cd\u65b9\u6cd5\uff1a\u76f4\u63a5\u5c06\u9875\u9762\u56fe\u50cf\u8f93\u5165\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\uff08VLM\uff09\u5e76\u56de\u7b54\u95ee\u9898\uff1b\u5c06\u8868\u683c\u9875\u9762\u8f6c\u6362\u4e3aLaTeX\u4ee3\u7801\u540e\u518d\u56de\u7b54\u95ee\u9898\uff1b\u5e76\u5bf9VLM\u91c7\u7528LoRA\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u8868\u683c\u6570\u636e\u7684\u5fae\u8c03\u3002", "result": "\u76f4\u63a5\u8f93\u5165\u6cd5\u7684\u51c6\u786e\u7387\u666e\u904d\u9ad8\u4e8e\u95f4\u63a5\u8f93\u5165\u6cd5\u3002\u901a\u8fc7LoRA\u5fae\u8c03\uff0c\u6a21\u578b\u6027\u80fd\u663e\u8457\u63d0\u5347\uff0cQwen2.5-VL-3B-Instruct\u51c6\u786e\u7387\u63d0\u9ad8\u8d85100%\u3002", "conclusion": "\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347VLM\u5728\u5904\u7406\u590d\u6742\u7ed3\u6784\u5316\u6570\u636e\uff08\u5982\u5efa\u7b51\u89c4\u8303\u8868\u683c\uff09\u4e0a\u7684\u8868\u73b0\uff0c\u6709\u52a9\u4e8e\u4e13\u4e1a\u9886\u57df\u7684\u81ea\u52a8\u95ee\u7b54\u548c\u5408\u89c4\u6027\u89e3\u8bfb\u3002"}}
{"id": "2511.18867", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18867", "abs": "https://arxiv.org/abs/2511.18867", "authors": ["Liutong Han", "Chu Kang", "Mingjie Xing", "Yanjun Wu"], "title": "VecIntrinBench: Benchmarking Cross-Architecture Intrinsic Code Migration for RISC-V Vector", "comment": "5 pages, 7 figures", "summary": "Intrinsic functions are specialized functions provided by the compiler that efficiently operate on architecture-specific hardware, allowing programmers to write optimized code in a high-level language that fully exploits hardware features. Using intrinsics to vectorize core code blocks is a standard optimization method in high-performance libraries, often requiring specific vector optimization implementations for multiple mainstream architectures. The promising RISC-V software ecosystem has a significant demand for algorithm library migration and adaptation. Translating existing intrinsic functions to RISC-V Vector (RVV) intrinsic functions across architectures is currently a mainstream approach. Rule-based intrinsic mapping methods and LLM-based code generation can help developers address the code migration challenge. However, existing intrinsic code benchmarks focus on mainstream SIMD intrinsics and lack support for the emerging RISC-V architecture. There is currently no benchmark that comprehensively evaluates the intrinsic migration capabilities for the RVV extension. To fill this gap, we propose VecIntrinBench, the first intrinsic benchmark encompassing RVV extensions. It includes 50 function-level tasks from open source repositories, implemented as scalars, RVV intrinsics, Arm Neon intrinsics, and x86 intrinsics, along with comprehensive functional and performance test cases. We systematically evaluated various code migration approaches on VecIntrinBench, yielding a series of insightful findings. The results demonstrate that advanced Large Language Models (LLMs) achieve a similar effect as rule-based mapping approaches for RISC-V code migration, while also delivering superior performance. We further analyze the reasons and identify future directions for LLM development in the code migration field. The VecIntrinBench is open-sourced to benefit the broader community and developers.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86VecIntrinBench\uff0c\u8fd9\u662f\u9996\u4e2a\u6db5\u76d6RISC-V\u5411\u91cf\u6269\u5c55\u7684\u5185\u5efa\u51fd\u6570\u57fa\u51c6\u6d4b\u8bd5\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u67b6\u6784\u95f4\u5185\u5efa\u51fd\u6570\u7684\u8fc1\u79fb\u80fd\u529b\u3002\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728RISC-V\u4ee3\u7801\u8fc1\u79fb\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5f53\u524d\u7f3a\u5c11\u652f\u6301\u65b0\u5174RISC-V\u67b6\u6784\u7684\u5185\u5efa\u51fd\u6570\u57fa\u51c6\uff0c\u96be\u4ee5\u5168\u9762\u8bc4\u4f30\u5185\u5efa\u51fd\u6570\u5728\u591a\u67b6\u6784\u95f4\u7684\u8fc1\u79fb\u80fd\u529b\uff0c\u7279\u522b\u662fRVV\u6269\u5c55\u3002", "method": "\u6536\u96c650\u4e2a\u5f00\u6e90\u51fd\u6570\u4efb\u52a1\uff0c\u5206\u522b\u5b9e\u73b0\u4e3a\u6807\u91cf\u3001RVV\u3001Arm Neon\u548cx86\u5185\u5efa\u51fd\u6570\uff0c\u8bbe\u8ba1\u5168\u9762\u7684\u529f\u80fd\u548c\u6027\u80fd\u6d4b\u8bd5\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u4e0d\u540c\u4ee3\u7801\u8fc1\u79fb\u65b9\u6cd5\u3002", "result": "\u6784\u5efa\u4e86\u5305\u542bRVV\u7684\u9996\u4e2a\u5185\u5efa\u51fd\u6570\u57fa\u51c6\u96c6VecIntrinBench\uff0c\u8bc4\u6d4b\u663e\u793aLLM\u5728\u4ee3\u7801\u8fc1\u79fb\u4e0a\u6548\u679c\u4e0e\u89c4\u5219\u6620\u5c04\u76f8\u5f53\u4f46\u6027\u80fd\u66f4\u4f18\uff0c\u63ed\u793a\u672a\u6765LLM\u53d1\u5c55\u7684\u65b9\u5411\u3002", "conclusion": "VecIntrinBench\u6709\u6548\u586b\u8865\u4e86RISC-V\u5185\u5efa\u51fd\u6570\u8fc1\u79fb\u8bc4\u6d4b\u7684\u7a7a\u767d\uff0c\u4e14\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u8fc1\u79fb\u4e2d\u8868\u73b0\u51fa\u6bd4\u4f20\u7edf\u89c4\u5219\u6620\u5c04\u66f4\u4f18\u7684\u6027\u80fd\u3002"}}
{"id": "2511.18313", "categories": ["cs.CL", "cs.DB", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18313", "abs": "https://arxiv.org/abs/2511.18313", "authors": ["Joseph Oladokun"], "title": "Path-Constrained Retrieval: A Structural Approach to Reliable LLM Agent Reasoning Through Graph-Scoped Semantic Search", "comment": "10 pages", "summary": "Large Language Model agents often retrieve context from knowledge bases that lack structural consistency with the agent's current reasoning state, leading to incoherent reasoning chains. We introduce Path-Constrained Retrieval (PCR), a retrieval method that combines structural graph constraints with semantic search to ensure retrieved information maintains logical relationships within a knowledge graph. PCR restricts the search space to nodes reachable from an anchor node, preventing retrieval of structurally disconnected information that may lead to inconsistent reasoning. We evaluate PCR on PathRAG-6, a benchmark spanning six domains with 180 nodes and 360 edges. Our results show that PCR achieves full structural consistency compared to 24-32 percent in baseline methods, while maintaining strong relevance scores. On the technology domain, PCR obtains full relevance at rank 10 with full structural consistency, significantly outperforming vector search and hybrid retrieval. PCR reduces the average graph distance of retrieved context by 78 percent compared to baselines, demonstrating retrieval of more structurally consistent information. These findings suggest that path-constrained retrieval is an effective approach for improving the reliability and coherence of LLM agent reasoning systems.", "AI": {"tldr": "\u63d0\u51fa\u8def\u5f84\u7ea6\u675f\u68c0\u7d22\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7ed3\u6784\u7ea6\u675f\u4e0e\u8bed\u4e49\u641c\u7d22\uff0c\u663e\u8457\u63d0\u9ad8\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u7ed3\u6784\u4e00\u81f4\u6027\u548c\u76f8\u5173\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u5728\u68c0\u7d22\u77e5\u8bc6\u5e93\u4e0a\u4e0b\u6587\u65f6\uff0c\u77e5\u8bc6\u5e93\u7ed3\u6784\u4e0e\u667a\u80fd\u4f53\u5f53\u524d\u63a8\u7406\u72b6\u6001\u7f3a\u4e4f\u4e00\u81f4\u6027\uff0c\u5bfc\u81f4\u63a8\u7406\u94fe\u6761\u4e0d\u8fde\u8d2f\u3002", "method": "\u8def\u5f84\u7ea6\u675f\u68c0\u7d22\u7ed3\u5408\u77e5\u8bc6\u56fe\u7ed3\u6784\u7ea6\u675f\u4e0e\u8bed\u4e49\u68c0\u7d22\uff0c\u9650\u5236\u68c0\u7d22\u8282\u70b9\u4e3a\u951a\u8282\u70b9\u53ef\u8fbe\u7684\u8282\u70b9\uff0c\u4fdd\u8bc1\u903b\u8f91\u5173\u8054\u3002", "result": "\u5728\u5305\u542b180\u8282\u70b9\u548c360\u8fb9\u7684\u516d\u9886\u57df\u57fa\u51c6PathRAG-6\u4e0a\uff0cPCR\u5b9e\u73b0\u4e86100%\u7684\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u8fdc\u8d85\u57fa\u7ebf\u65b9\u6cd5\u768424-32%\uff1b\u5728\u6280\u672f\u9886\u57df\uff0cPCR\u8fbe\u5230\u6392\u540d\u524d10\u7684\u5b8c\u5168\u76f8\u5173\u6027\u548c\u7ed3\u6784\u4e00\u81f4\u6027\uff0c\u663e\u8457\u4f18\u4e8e\u5411\u91cf\u641c\u7d22\u548c\u6df7\u5408\u68c0\u7d22\u3002\u5e73\u5747\u56fe\u8ddd\u79bb\u51cf\u5c1178%\uff0c\u8868\u660e\u68c0\u7d22\u7ed3\u679c\u7ed3\u6784\u66f4\u4e00\u81f4\u3002", "conclusion": "\u8def\u5f84\u7ea6\u675f\u68c0\u7d22\u6709\u6548\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u667a\u80fd\u4f53\u7684\u63a8\u7406\u7cfb\u7edf\u7684\u53ef\u9760\u6027\u548c\u8fde\u8d2f\u6027\uff0c\u786e\u4fdd\u68c0\u7d22\u4fe1\u606f\u7684\u7ed3\u6784\u4e00\u81f4\u6027\u3002"}}
{"id": "2511.18918", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.18918", "abs": "https://arxiv.org/abs/2511.18918", "authors": ["Qingchao Shen", "Zan Wang", "Haoyang Ma", "Yongqiang Tian", "Lili Huang", "Zibo Xiao", "Junjie Chen", "Shing-Chi Cheung"], "title": "Optimization-Aware Test Generation for Deep Learning Compilers", "comment": "This paper has been accpected by ICSE 2026", "summary": "Deep Learning (DL) compilers have been widely utilized to optimize DL models for efficient deployment across various hardware. Due to their vital role in the DL ecosystem, ensuring their reliability and security is critical. However, existing approaches have limitations in testing optimization stages, which is the core functionality of DL compilers, due to the difficulty in generating optimization-aware tests. In this paper, we proposed OATest, a novel approach for synthesizing optimization-aware computational graphs. The approach combines patterns extracted from documented tests for optimization and incorporates them into seed computational graphs, enabling broader exploration of optimization paths. To guarantee the optimization-awareness of generated graphs, OATest introduces the edges reusing strategy to establish strong connections between patterns and contexts. Additionally, to solve the validity challenge for the generated graphs, OATest employs an auxiliary layers addition strategy to resolve broken constraints. Equipped with two distinct test oracles, OATest applies differential testing to evaluate the two widely used DL compilers (i.e., TVM and ONNXRuntime). Our experimental results show that OATest outperforms the state-of-the-art method by detecting more bugs and achieving higher code coverage in TVM and ONNXRutimes. Additionally, OATest uncovers 58 previously unknown bugs, 36 of which have been confirmed or fixed by developers.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u4f18\u5316\u9636\u6bb5\u7684\u6d4b\u8bd5\u65b9\u6cd5OATest\uff0c\u901a\u8fc7\u5408\u6210\u4f18\u5316\u611f\u77e5\u8ba1\u7b97\u56fe\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6d4b\u8bd5\u8986\u76d6\u548c\u7f3a\u9677\u68c0\u6d4b\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u6d4b\u8bd5\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u4f18\u5316\u9636\u6bb5\u5b58\u5728\u9650\u5236\uff0c\u4e3b\u8981\u662f\u96be\u4ee5\u751f\u6210\u4f18\u5316\u611f\u77e5\u7684\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5f71\u54cd\u5bf9\u5173\u952e\u529f\u80fd\u7684\u5168\u9762\u68c0\u6d4b\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u540d\u4e3aOATest\u7684\u65b0\u9896\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u4ece\u6587\u6863\u6d4b\u8bd5\u4e2d\u63d0\u53d6\u7684\u4f18\u5316\u6a21\u5f0f\u5e76\u5c06\u5176\u878d\u5408\u5230\u79cd\u5b50\u8ba1\u7b97\u56fe\u4e2d\uff0c\u5b9e\u73b0\u4f18\u5316\u611f\u77e5\u8ba1\u7b97\u56fe\u7684\u5408\u6210\u3002\u5f15\u5165\u8fb9\u590d\u7528\u7b56\u7565\u5f3a\u5316\u6a21\u5f0f\u4e0e\u4e0a\u4e0b\u6587\u7684\u8fde\u63a5\uff0c\u91c7\u7528\u8f85\u52a9\u5c42\u6dfb\u52a0\u7b56\u7565\u4fdd\u8bc1\u751f\u6210\u56fe\u7684\u6709\u6548\u6027\uff0c\u5e76\u4f7f\u7528\u5dee\u5f02\u6d4b\u8bd5\u8bc4\u4f30\u4e24\u4e2a\u4e3b\u6d41\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u3002", "result": "OATest\u5728\u68c0\u6d4bTVM\u548cONNXRuntime\u4e2d\u7684\u7f3a\u9677\u4e0a\u8868\u73b0\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u8986\u76d6\u66f4\u591a\u4ee3\u7801\uff0c\u53d1\u73b0\u4e8658\u4e2a\u672a\u77e5\u7684\u6f0f\u6d1e\uff0c\u5176\u4e2d36\u4e2a\u5df2\u88ab\u5f00\u53d1\u8005\u786e\u8ba4\u6216\u4fee\u590d\u3002", "conclusion": "OATest\u6709\u6548\u63d0\u5347\u4e86\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u4f18\u5316\u6d4b\u8bd5\u7684\u8986\u76d6\u7387\u548c\u7f3a\u9677\u53d1\u73b0\u80fd\u529b\uff0c\u8bc1\u660e\u4e86\u5408\u6210\u4f18\u5316\u611f\u77e5\u8ba1\u7b97\u56fe\u53ca\u76f8\u5173\u7b56\u7565\u5728\u6df1\u5ea6\u5b66\u4e60\u7f16\u8bd1\u5668\u6d4b\u8bd5\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.18324", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18324", "abs": "https://arxiv.org/abs/2511.18324", "authors": ["Syed Mohaiminul Hoque", "Naimur Rahman", "Md Sakhawat Hossain"], "title": "Gradient Masters at BLP-2025 Task 1: Advancing Low-Resource NLP for Bengali using Ensemble-Based Adversarial Training for Hate Speech Detection", "comment": "6 pages, 2 figures, 4 tables. Accepted at the Second International Workshop on Bangla Language Processing (BLP-2025) co-located with AACL-IJCNLP 2025. Ranked 6th (Subtask 1A, 73.23% micro F1) and 3rd (Subtask 1B, 73.28% micro F1) on the official leaderboard", "summary": "This paper introduces the approach of \"Gradient Masters\" for BLP-2025 Task 1: \"Bangla Multitask Hate Speech Identification Shared Task\". We present an ensemble-based fine-tuning strategy for addressing subtasks 1A (hate-type classification) and 1B (target group classification) in YouTube comments. We propose a hybrid approach on a Bangla Language Model, which outperformed the baseline models and secured the 6th position in subtask 1A with a micro F1 score of 73.23% and the third position in subtask 1B with 73.28%. We conducted extensive experiments that evaluated the robustness of the model throughout the development and evaluation phases, including comparisons with other Language Model variants, to measure generalization in low-resource Bangla hate speech scenarios and data set coverage. In addition, we provide a detailed analysis of our findings, exploring misclassification patterns in the detection of hate speech.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u5fae\u8c03\u7684\u6df7\u5408\u5b5f\u52a0\u62c9\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u7528\u4e8e\u5b5f\u52a0\u62c9YouTube\u8bc4\u8bba\u7684\u4ec7\u6068\u8a00\u8bba\u591a\u4efb\u52a1\u5206\u7c7b\uff0c\u5e76\u5728\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u53d6\u5f97\u4e86\u8f83\u597d\u6210\u7ee9\u3002", "motivation": "\u9488\u5bf9\u5b5f\u52a0\u62c9\u8bed\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u4ec7\u6068\u8a00\u8bba\u8bc6\u522b\u7684\u6311\u6218\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u5fae\u8c03\u6df7\u5408\u8bed\u8a00\u6a21\u578b\u65b9\u6cd5\uff0c\u4ee5\u63d0\u5347\u6027\u80fd\u548c\u6a21\u578b\u9c81\u68d2\u6027\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u96c6\u6210\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u7ed3\u5408\u6df7\u5408\u5b5f\u52a0\u62c9\u8bed\u8a00\u6a21\u578b\uff0c\u8fdb\u884c\u591a\u4efb\u52a1\u5b66\u4e60\uff0c\u9488\u5bf9\u4ec7\u6068\u7c7b\u578b\u5206\u7c7b\u548c\u76ee\u6807\u7fa4\u4f53\u5206\u7c7b\u4e24\u4e2a\u5b50\u4efb\u52a1\u5206\u522b\u8bad\u7ec3\u548c\u8bc4\u4f30\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u201cGradient Masters\u201d\u65b9\u6cd5\uff0c\u9488\u5bf9BLP-2025\u4efb\u52a11\uff1a\u5b5f\u52a0\u62c9\u591a\u4efb\u52a1\u4ec7\u6068\u8a00\u8bba\u8bc6\u522b\u5171\u4eab\u4efb\u52a1\uff0c\u91c7\u7528\u57fa\u4e8e\u96c6\u6210\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u89e3\u51b3YouTube\u8bc4\u8bba\u4e2d\u7684\u4ec7\u6068\u7c7b\u578b\u5206\u7c7b\uff08\u5b50\u4efb\u52a11A\uff09\u548c\u76ee\u6807\u7fa4\u4f53\u5206\u7c7b\uff08\u5b50\u4efb\u52a11B\uff09\u3002\u901a\u8fc7\u6df7\u5408\u5b5f\u52a0\u62c9\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u6a21\u578b\u5728\u5b50\u4efb\u52a11A\u4e2d\u4ee573.23%\u7684\u5fae\u5e73\u5747F1\u5f97\u5206\u83b7\u5f97\u7b2c6\u540d\uff0c\u5728\u5b50\u4efb\u52a11B\u4e2d\u4ee573.28%\u83b7\u5f97\u7b2c3\u540d\u3002\u5e76\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff0c\u6bd4\u8f83\u4e86\u4e0d\u540c\u8bed\u8a00\u6a21\u578b\u53d8\u4f53\uff0c\u4f53\u73b0\u4e86\u5728\u4f4e\u8d44\u6e90\u5b5f\u52a0\u62c9\u4ec7\u6068\u8a00\u8bba\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u53ca\u6570\u636e\u96c6\u8986\u76d6\u3002\u6b64\u5916\uff0c\u5206\u6790\u4e86\u8bef\u5206\u7c7b\u6a21\u5f0f\uff0c\u6df1\u5165\u63a2\u8ba8\u4e86\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u96be\u70b9\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u6df7\u5408\u5b5f\u52a0\u62c9\u8bed\u8a00\u6a21\u578b\u548c\u96c6\u6210\u5fae\u8c03\u7b56\u7565\uff0c\u6a21\u578b\u5728\u4ec7\u6068\u8a00\u8bba\u68c0\u6d4b\u7684\u4e24\u4e2a\u5b50\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u5c55\u793a\u4e86\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u8bef\u5206\u7c7b\u5206\u6790\u4e3a\u672a\u6765\u4f18\u5316\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2511.18924", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18924", "abs": "https://arxiv.org/abs/2511.18924", "authors": ["Arina Kharlamova", "Jiawen Liu", "Tianyi Zhang", "Xinrui Yang", "Humaid Alqasimi", "Youcheng Sun", "Chun Jason Xue"], "title": "LLM-Driven Kernel Evolution: Automating Driver Updates in Linux", "comment": null, "summary": "Linux kernel evolution breaks drivers through API/ABI changes, semantic shifts, and security-hardening updates. We introduce DRIVEBENCH, an executable corpus of kernel$\\rightarrow$driver co-evolution cases, and AUTODRIVER, a closed-loop, LLM-driven system for automating driver maintenance. The system integrates prompt engineering, multi-agent collaboration, static analysis, and iterative validation to ensure that generated patches are not only syntactically correct but also functionally and semantically consistent with kernel conventions. The corpus spans v5.10-v6.10 with 235 validated cases drawn from 612 candidates. In evaluation across 55 cases, AUTODRIVER achieves 56.4% compilation success; QEMU-based boot verification indicates that compiled patches preserve driver initialization in most instances. By releasing DRIVEBENCH and tooling, we enable reproducible research and a practical route to continuous, safe co-evolution of drivers with the Linux kernel.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faDRIVEBENCH\u8bed\u6599\u5e93\u548cAUTODRIVER\u81ea\u52a8\u9a71\u52a8\u7ef4\u62a4\u7cfb\u7edf\uff0c\u5b9e\u73b0\u9a71\u52a8\u4e0eLinux\u5185\u6838\u7684\u81ea\u52a8\u5b89\u5168\u5171\u6f14\u5316\u3002", "motivation": "Linux\u5185\u6838\u6301\u7eed\u6f14\u8fdb\u5bfc\u81f4\u9a71\u52a8\u56e0API/ABI\u53d8\u5316\u3001\u5b89\u5168\u5f3a\u5316\u7b49\u95ee\u9898\u7834\u574f\uff0c\u9700\u81ea\u52a8\u5316\u5de5\u5177\u8f85\u52a9\u9a71\u52a8\u7ef4\u62a4\uff0c\u4fdd\u969c\u9a71\u52a8\u4e0e\u5185\u6838\u7684\u540c\u6b65\u66f4\u65b0\u3002", "method": "\u96c6\u6210\u63d0\u793a\u5de5\u7a0b\u3001\u591a\u4ee3\u7406\u534f\u4f5c\u3001\u9759\u6001\u5206\u6790\u53ca\u8fed\u4ee3\u9a8c\u8bc1\uff0c\u786e\u4fdd\u751f\u6210\u7684\u9a71\u52a8\u8865\u4e01\u8bed\u6cd5\u3001\u529f\u80fd\u53ca\u8bed\u4e49\u6b63\u786e\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86DRIVEBENCH\u548cAUTODRIVER\u4e24\u4e2a\u5de5\u5177\uff0c\u5206\u522b\u7528\u4e8e\u6784\u5efaLinux\u5185\u6838\u9a71\u52a8\u5171\u6f14\u5316\u7684\u53ef\u6267\u884c\u8bed\u6599\u5e93\u548c\u81ea\u52a8\u5316\u9a71\u52a8\u7ef4\u62a4\u7cfb\u7edf\u3002AUTODRIVER\u7ed3\u5408\u63d0\u793a\u5de5\u7a0b\u3001\u591a\u4ee3\u7406\u534f\u4f5c\u3001\u9759\u6001\u5206\u6790\u548c\u8fed\u4ee3\u9a8c\u8bc1\uff0c\u80fd\u591f\u751f\u6210\u7b26\u5408\u5185\u6838\u89c4\u8303\u4e14\u529f\u80fd\u8bed\u4e49\u4e00\u81f4\u7684\u8865\u4e01\u3002DRIVEBENCH\u8bed\u6599\u5e93\u6db5\u76d6\u4e86Linux\u5185\u6838v5.10\u81f3v6.10\u7684235\u4e2a\u9a8c\u8bc1\u6848\u4f8b\u3002\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0cAUTODRIVER\u572855\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\u670956.4%\u7684\u8865\u4e01\u80fd\u6210\u529f\u7f16\u8bd1\uff0c\u5e76\u4e14\u901a\u8fc7QEMU\u5f15\u5bfc\u9a8c\u8bc1\u8865\u4e01\u5728\u5927\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u7ef4\u6301\u9a71\u52a8\u521d\u59cb\u5316\u3002\u901a\u8fc7\u53d1\u5e03\u8fd9\u4e9b\u5de5\u5177\uff0c\u63d0\u5347\u4e86\u9a71\u52a8\u4e0eLinux\u5185\u6838\u5b89\u5168\u5171\u6f14\u5316\u7684\u81ea\u52a8\u5316\u548c\u53ef\u91cd\u590d\u7814\u7a76\u80fd\u529b\u3002", "conclusion": "AUTODRIVER\u80fd\u591f\u81ea\u52a8\u751f\u6210\u7b26\u5408\u89c4\u8303\u4e14\u529f\u80fd\u6b63\u786e\u7684\u9a71\u52a8\u8865\u4e01\uff0c\u63a8\u52a8\u9a71\u52a8\u4e0eLinux\u5185\u6838\u7684\u5b89\u5168\u6301\u7eed\u5171\u6f14\u5316\uff0c\u4e14DRIVEBENCH\u4e3a\u76f8\u5173\u7814\u7a76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u6848\u4f8b\u5e93\u3002"}}
{"id": "2511.18335", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18335", "abs": "https://arxiv.org/abs/2511.18335", "authors": ["James Y. Huang", "Wenxuan Zhou", "Nan Xu", "Fei Wang", "Qin Liu", "Sheng Zhang", "Hoifung Poon", "Muhao Chen"], "title": "OmniStruct: Universal Text-to-Structure Generation across Diverse Schemas", "comment": null, "summary": "The ability of Large Language Models (LLMs) to generate structured outputs that follow arbitrary schemas is crucial to a wide range of downstream tasks that require diverse structured representations of results such as information extraction, table generation, and function calling. While modern LLMs excel in generating unstructured responses in natural language, whether this advancement translates to a strong performance on text-to-structure tasks remains unclear. To bridge this gap, we first introduce OmniStruct, a comprehensive benchmark for assessing LLMs' capabilities on diverse text-to-structure tasks such as information extraction, table generation, and function calling. We build OmniStruct by identifying existing datasets across a wide range of tasks that are suitable for a structured answer format, and adapting them under a unified text-to-structure problem setting. To facilitate the development of efficient text-to-structure models, we collect high-quality training data via synthetic task generation. Without using any supervised data for OmniStruct tasks, our experiments demonstrate the possibility of fine-tuning much smaller models on synthetic data into universal structured generation models that can rival the performance of GPT-4o.", "AI": {"tldr": "\u63d0\u51faOmniStruct\u57fa\u51c6\uff0c\u4fc3\u8fdb\u5927\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5230\u7ed3\u6784\u5316\u4efb\u52a1\u4e0a\u7684\u53d1\u5c55\uff0c\u901a\u8fc7\u5408\u6210\u6570\u636e\u8bad\u7ec3\u5c0f\u6a21\u578b\uff0c\u5b9e\u73b0\u5ab2\u7f8eGPT-4\u7684\u7ed3\u6784\u5316\u751f\u6210\u6548\u679c\u3002", "motivation": "\u867d\u7136\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u5728\u6587\u672c\u5230\u7ed3\u6784\u5316\u8f93\u51fa\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002\u56e0\u6b64\uff0c\u63d0\u51faOmniStruct\u57fa\u51c6\u4ee5\u8bc4\u4f30\u548c\u4fc3\u8fdbLLMs\u5728\u8fd9\u4e00\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u6784\u5efaOmniStruct\u57fa\u51c6\uff0c\u6536\u96c6\u548c\u7edf\u4e00\u591a\u79cd\u6587\u672c\u5230\u7ed3\u6784\u5316\u4efb\u52a1\u7684\u6570\u636e\u96c6\uff0c\u5229\u7528\u5408\u6210\u4efb\u52a1\u751f\u6210\u65e0\u76d1\u7763\u8bad\u7ec3\u6570\u636e\uff0c\u5bf9\u8f83\u5c0f\u6a21\u578b\u8fdb\u884c\u5fae\u8c03\uff0c\u8bc4\u4f30\u5176\u7ed3\u6784\u5316\u751f\u6210\u80fd\u529b\u3002", "result": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86OmniStruct\uff0c\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u591a\u6837\u5316\u6587\u672c\u5230\u7ed3\u6784\u5316\u4efb\u52a1\u4e0a\u7684\u80fd\u529b\u7684\u7efc\u5408\u57fa\u51c6\uff0c\u6db5\u76d6\u4fe1\u606f\u63d0\u53d6\u3001\u8868\u683c\u751f\u6210\u548c\u51fd\u6570\u8c03\u7528\u7b49\u4efb\u52a1\u3002\u901a\u8fc7\u6574\u5408\u5e76\u7edf\u4e00\u591a\u4e2a\u9002\u5408\u7ed3\u6784\u5316\u8f93\u51fa\u7684\u6570\u636e\u96c6\uff0c\u5e76\u5229\u7528\u5408\u6210\u4efb\u52a1\u751f\u6210\u9ad8\u8d28\u91cf\u8bad\u7ec3\u6570\u636e\uff0c\u4f5c\u8005\u5c55\u793a\u4e86\u5728\u65e0\u76d1\u7763\u6761\u4ef6\u4e0b\uff0c\u4ec5\u7528\u5408\u6210\u6570\u636e\u5fae\u8c03\u8f83\u5c0f\u6a21\u578b\uff0c\u4e5f\u80fd\u83b7\u5f97\u4e0eGPT-4\u76f8\u5ab2\u7f8e\u7684\u7ed3\u6784\u5316\u751f\u6210\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u6784\u5efa\u7edf\u4e00\u7684\u591a\u4efb\u52a1\u57fa\u51c6\u548c\u5408\u6210\u6570\u636e\u8bad\u7ec3\uff0c\u8f83\u5c0f\u6a21\u578b\u5728\u6587\u672c\u5230\u7ed3\u6784\u5316\u751f\u6210\u4efb\u52a1\u4e2d\u80fd\u591f\u83b7\u5f97\u63a5\u8fd1GPT-4\u7684\u6027\u80fd\uff0c\u8bf4\u660e\u65e0\u76d1\u7763\u5408\u6210\u6570\u636e\u8bad\u7ec3\u5728\u7ed3\u6784\u5316\u751f\u6210\u9886\u57df\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2511.19059", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19059", "abs": "https://arxiv.org/abs/2511.19059", "authors": ["Pei Liu", "Terry Zhuo", "Jiawei Deng", "Thong James", "Shidong Pan", "Sherry Xu", "Zhenchang Xing", "Qinghua Lu", "Xiaoning Du", "Hongyu Zhang"], "title": "LLMAID: Identifying AI Capabilities in Android Apps with LLMs", "comment": null, "summary": "Recent advancements in artificial intelligence (AI) and its widespread integration into mobile software applications have received significant attention, highlighting the growing prominence of AI capabilities in modern software systems. However, the inherent hallucination and reliability issues of AI continue to raise persistent concerns. Consequently, application users and regulators increasingly ask critical questions such as: Does the application incorporate AI capabilities? and What specific types of AI functionalities are embedded? Preliminary efforts have been made to identify AI capabilities in mobile software; however, existing approaches mainly rely on manual inspection and rule-based heuristics. These methods are not only costly and time-consuming but also struggle to adapt advanced AI techniques.\n  To address the limitations of existing methods, we propose LLMAID (Large Language Model for AI Discovery). LLMAID includes four main tasks: (1) candidate extraction, (2) knowledge base interaction, (3) AI capability analysis and detection, and (4) AI service summarization. We apply LLMAID to a dataset of 4,201 Android applications and demonstrate that it identifies 242% more real-world AI apps than state-of-the-art rule-based approaches. Our experiments show that LLM4AID achieves high precision and recall, both exceeding 90%, in detecting AI-related components. Additionally, a user study indicates that developers find the AI service summaries generated by LLMAID to be more informative and preferable to the original app descriptions. Finally, we leverage LLMAID to perform an empirical analysis of AI capabilities across Android apps. The results reveal a strong concentration of AI functionality in computer vision (54.80%), with object detection emerging as the most common task (25.19%).", "AI": {"tldr": "\u672c\u6587\u63d0\u51faLLMAID\u65b9\u6cd5\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9ad8\u6548\u8bc6\u522b\u79fb\u52a8\u5e94\u7528\u4e2d\u7684AI\u529f\u80fd\uff0c\u5728\u8bc6\u522b\u7387\u548c\u7528\u6237\u4f53\u9a8c\u4e0a\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740\u4eba\u5de5\u667a\u80fd\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u53ca\u5176\u5728\u79fb\u52a8\u8f6f\u4ef6\u4e2d\u7684\u5e7f\u6cdb\u5e94\u7528\uff0c\u4eba\u4eec\u8feb\u5207\u9700\u8981\u6709\u6548\u8bc6\u522b\u79fb\u52a8\u8f6f\u4ef6\u4e2d\u7684AI\u80fd\u529b\uff0c\u4f20\u7edf\u7684\u624b\u5de5\u68c0\u67e5\u548c\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u6548\u7387\u4f4e\u4e14\u96be\u4ee5\u8ddf\u8fdb\u5148\u8fdbAI\u6280\u672f\u3002", "method": "\u63d0\u51fa\u4e86LLMAID\uff08\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7528\u4e8eAI\u53d1\u73b0\uff09\uff0c\u5305\u62ec\u5019\u9009\u63d0\u53d6\u3001\u77e5\u8bc6\u5e93\u4ea4\u4e92\u3001AI\u80fd\u529b\u5206\u6790\u68c0\u6d4b\u548cAI\u670d\u52a1\u603b\u7ed3\u56db\u4e2a\u4e3b\u8981\u4efb\u52a1\u3002", "result": "\u57284201\u4e2aAndroid\u5e94\u7528\u7684\u6570\u636e\u96c6\u4e0a\uff0cLLMAID\u6bd4\u6700\u5148\u8fdb\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u65b9\u6cd5\u591a\u8bc6\u522b\u4e86242%\u7684\u771f\u5b9eAI\u5e94\u7528\uff0c\u7cbe\u786e\u7387\u548c\u53ec\u56de\u7387\u5747\u8d85\u8fc790%\u3002\u7528\u6237\u7814\u7a76\u8868\u660e\u5f00\u53d1\u8005\u66f4\u559c\u6b22LLMAID\u751f\u6210\u7684AI\u670d\u52a1\u6458\u8981\u3002", "conclusion": "LLMAID\u6709\u6548\u63d0\u5347\u4e86\u79fb\u52a8\u5e94\u7528\u4e2dAI\u529f\u80fd\u7684\u8bc6\u522b\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u63ed\u793a\u4e86Android\u5e94\u7528\u4e2dAI\u80fd\u529b\u4e3b\u8981\u96c6\u4e2d\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u9886\u57df\uff0c\u4ee5\u76ee\u6807\u68c0\u6d4b\u6700\u4e3a\u5e38\u89c1\u3002"}}
{"id": "2511.18369", "categories": ["cs.CL", "cs.CY", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.18369", "abs": "https://arxiv.org/abs/2511.18369", "authors": ["Manon Berriche"], "title": "Tu crois que c'est vrai ? Diversite des regimes d'enonciation face aux fake news et mecanismes d'autoregulation conversationnelle", "comment": "in French language", "summary": "This thesis addresses two paradoxes: (1) why empirical studies find that fake news represent only a small share of the information consulted and shared on social media despite the absence of editorial control or journalistic norms, and (2) how political polarization has intensified even though users do not appear especially receptive to fake news. To investigate these issues, two complementary studies were carried out on Twitter and Facebook, combining quantitative analyses of digital traces with online observation and interviews. This mixed-methods design avoids reducing users to single reactions to identified fake items and instead examines the variety of practices across different interactional situations, online and offline, while recording socio-demographic traits. The first study mapped users who shared at least one item labeled fake by fact-checkers in the French Twittersphere. The second used a corpus of items flagged by Facebook users to study reactions to statements whose epistemic status is uncertain. Three main findings emerge. First, sharing fake news is concentrated among a limited group of users who are not less educated or cognitively disadvantaged but are more politicized and critical of institutions; owing to their high activity and prolific sharing, they can help set the agenda for their political camp. Second, exposed users can deploy varying forms of critical distance depending on their social position and the interactional norms of the situations they inhabit: either discursive caution (prudence \u00e9nonciative) or interventions ('points d'arr\u00eat') that express disagreement or corrections. Third, these forms of critical distance seldom yield genuine deliberative debates or agonistic pluralism; rather, they often produce dialogues of the deaf among a small, particularly active minority.", "AI": {"tldr": "\u672c\u8bba\u6587\u901a\u8fc7Twitter\u548cFacebook\u6570\u636e\uff0c\u63ed\u793a\u5047\u65b0\u95fb\u5206\u4eab\u96c6\u4e2d\u4e8e\u5c11\u6570\u653f\u6cbb\u6d3b\u8dc3\u7528\u6237\uff0c\u867d\u7528\u6237\u5c55\u73b0\u6279\u5224\u6001\u5ea6\u4f46\u591a\u4e3a\u65e0\u6548\u5bf9\u8bdd\uff0c\u96be\u4ee5\u4fc3\u6210\u7406\u6027\u8fa9\u8bba\u548c\u51cf\u5c11\u653f\u6cbb\u6781\u5316\u3002", "motivation": "\u89e3\u91ca\u4e3a\u4f55\u5047\u65b0\u95fb\u5728\u793e\u4ea4\u5a92\u4f53\u4e2d\u5360\u6bd4\u5c11\u4e14\u7528\u6237\u5e76\u975e\u7279\u522b\u6613\u53d7\u5047\u65b0\u95fb\u5f71\u54cd\u7684\u60c5\u51b5\u4e0b\uff0c\u653f\u6cbb\u6781\u5316\u5374\u52a0\u5267\uff0c\u4ee5\u53ca\u7406\u89e3\u5047\u65b0\u95fb\u5206\u4eab\u4e0e\u653f\u6cbb\u5206\u5316\u7684\u5173\u7cfb\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u6570\u5b57\u8db3\u8ff9\u7684\u5b9a\u91cf\u5206\u6790\u3001\u5728\u7ebf\u89c2\u5bdf\u548c\u8bbf\u8c08\uff0c\u7814\u7a76\u6cd5\u56fdTwitter\u548cFacebook\u4e0a\u7528\u6237\u5bf9\u5047\u65b0\u95fb\u7684\u5206\u4eab\u548c\u53cd\u5e94\uff0c\u91c7\u7528\u6df7\u5408\u65b9\u6cd5\u8bbe\u8ba1\u5168\u9762\u8003\u5bdf\u4e0d\u540c\u4e92\u52a8\u573a\u666f\u4e2d\u7684\u7528\u6237\u884c\u4e3a\u3002", "result": "\u53d1\u73b0\u5047\u65b0\u95fb\u4e3b\u8981\u7531\u653f\u6cbb\u9ad8\u5ea6\u6d3b\u8dc3\u7684\u5c11\u6570\u7528\u6237\u5206\u4eab\uff1b\u7528\u6237\u9762\u5bf9\u5047\u65b0\u95fb\u91c7\u53d6\u591a\u6837\u7684\u6279\u5224\u6001\u5ea6\uff0c\u53d6\u51b3\u4e8e\u5176\u793e\u4f1a\u80cc\u666f\u548c\u4e92\u52a8\u89c4\u8303\uff0c\u4f46\u8fd9\u4e9b\u6279\u5224\u901a\u5e38\u4e0d\u4f1a\u8f6c\u5316\u4e3a\u6709\u6548\u7684\u653f\u6cbb\u8ba8\u8bba\u3002", "conclusion": "\u5047\u65b0\u95fb\u7684\u4f20\u64ad\u96c6\u4e2d\u5728\u5c11\u6570\u9ad8\u653f\u6cbb\u5316\u4e14\u5bf9\u673a\u6784\u6301\u6279\u5224\u6001\u5ea6\u7684\u7528\u6237\u7fa4\u4f53\uff0c\u8fd9\u4e9b\u7528\u6237\u901a\u8fc7\u9ad8\u9891\u6d3b\u8dc3\u5ea6\u5f71\u54cd\u653f\u6cbb\u8bae\u7a0b\u3002\u5c3d\u7ba1\u7528\u6237\u4f1a\u4ee5\u4e0d\u540c\u65b9\u5f0f\u4fdd\u6301\u6279\u5224\u6027\u8ddd\u79bb\uff0c\u4f46\u8fd9\u4e9b\u4ea4\u6d41\u591a\u4e3a\u201c\u804b\u4eba\u5bf9\u8bdd\u201d\uff0c\u7f3a\u5c11\u771f\u6b63\u7684\u5efa\u8bbe\u6027\u8fa9\u8bba\u3002"}}
{"id": "2511.19130", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19130", "abs": "https://arxiv.org/abs/2511.19130", "authors": ["Rong Feng", "Suman Saha"], "title": "Can LLMs Recover Program Semantics? A Systematic Evaluation with Symbolic Execution", "comment": null, "summary": "Obfuscation poses a persistent challenge for software engineering tasks such as program comprehension, maintenance, testing, and vulnerability detection. While compiler optimizations and third-party code often introduce transformations that obscure program intent, existing analysis tools and large language models (LLMs) struggle to recover the original semantics. In this work, we investigate whether LLMs, when fine-tuned with symbolic execution artifacts, can effectively deobfuscate programs and restore analyzability. We construct a benchmark by applying four widely studied transformations-control-flow flattening, opaque predicates, arithmetic encoding, and branch encoding-across diverse C programs from TUM Obfuscation Benchmarks, the LLVM test suite, and algorithmic repositories. We then compare three state-of-the-art LLMs under two training configurations: baseline fine-tuning on obfuscated/original code pairs, and enhanced fine-tuning with additional KLEE artifacts such as SMT constraints, path statistics, and test cases. Our evaluation examines syntactic correctness (compilation success), semantic fidelity (behavioral equivalence under symbolic execution), and code quality (readability and structure). Results show that GPT-4.1-mini achieves the strongest deobfuscation overall, and that incorporating KLEE artifacts consistently improves semantic preservation and compilation success across models. These findings highlight deobfuscation as a broader software engineering concern, demonstrating that combining LLMs with symbolic execution can strengthen automated testing, static analysis, and program comprehension in the presence of obfuscation.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u7b26\u53f7\u6267\u884c\u4ea7\u7269\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u5347\u4e86\u5bf9\u6df7\u6dc6\u4ee3\u7801\u7684\u53bb\u6df7\u6dc6\u80fd\u529b\uff0c\u589e\u5f3a\u4e86\u7a0b\u5e8f\u8bed\u4e49\u6062\u590d\u548c\u89e3\u6790\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u8f6f\u4ef6\u5de5\u7a0b\u4efb\u52a1\u5982\u7a0b\u5e8f\u7406\u89e3\u3001\u7ef4\u62a4\u3001\u6d4b\u8bd5\u548c\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\uff0c\u4ee3\u7801\u6df7\u6dc6\u5e26\u6765\u4e86\u6301\u7eed\u7684\u6311\u6218\uff0c\u73b0\u6709\u5206\u6790\u5de5\u5177\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96be\u4ee5\u6062\u590d\u7a0b\u5e8f\u539f\u8bed\u4e49\u3002", "method": "\u901a\u8fc7\u5728\u591a\u6837\u5316C\u7a0b\u5e8f\u4e0a\u5e94\u7528\u56db\u79cd\u5e7f\u6cdb\u7814\u7a76\u7684\u6df7\u6dc6\u8f6c\u6362\uff0c\u6784\u5efa\u57fa\u51c6\u6570\u636e\u96c6\u3002\u6bd4\u8f83\u4e09\u79cd\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e24\u79cd\u8bad\u7ec3\u914d\u7f6e\u4e0b\u7684\u8868\u73b0\uff1a\u57fa\u7ebf\u5fae\u8c03\uff08\u6df7\u6dc6\u4ee3\u7801\u4e0e\u539f\u59cb\u4ee3\u7801\u5bf9\uff09\u548c\u589e\u5f3a\u5fae\u8c03\uff08\u52a0\u5165KLEE\u7b26\u53f7\u6267\u884c\u751f\u6210\u7684\u7ea6\u675f\u3001\u8def\u5f84\u7edf\u8ba1\u548c\u6d4b\u8bd5\u7528\u4f8b\uff09\u3002", "result": "GPT-4.1-mini\u5728\u53bb\u6df7\u6dc6\u6548\u679c\u65b9\u9762\u8868\u73b0\u6700\u5f3a\uff0c\u52a0\u5165KLEE\u7b26\u53f7\u6267\u884c\u751f\u6210\u7684\u8f85\u52a9\u4fe1\u606f\u80fd\u6301\u7eed\u63d0\u5347\u8bed\u4e49\u4fdd\u771f\u5ea6\u548c\u7f16\u8bd1\u6210\u529f\u7387\u3002", "conclusion": "\u5c06\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u7b26\u53f7\u6267\u884c\u6280\u672f\u7ed3\u5408\uff0c\u6709\u52a9\u4e8e\u63d0\u5347\u81ea\u52a8\u5316\u6d4b\u8bd5\u3001\u9759\u6001\u5206\u6790\u548c\u7a0b\u5e8f\u7406\u89e3\u5728\u9762\u5bf9\u4ee3\u7801\u6df7\u6dc6\u65f6\u7684\u6548\u679c\u3002"}}
{"id": "2511.18393", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18393", "abs": "https://arxiv.org/abs/2511.18393", "authors": ["Heejoon Koo"], "title": "Towards Robust and Fair Next Visit Diagnosis Prediction under Noisy Clinical Notes with Large Language Models", "comment": "Accepted by the Association for the Advancement of Artificial Intelligence (AAAI) 2026 1st Workshop on Safe, Ethical, Certified, Uncertainty-aware, Robust, and Explainable AI for Health (SECURE-AI4H)", "summary": "A decade of rapid advances in artificial intelligence (AI) has opened new opportunities for clinical decision support systems (CDSS), with large language models (LLMs) demonstrating strong reasoning abilities on timely medical tasks. However, clinical texts are often degraded by human errors or failures in automated pipelines, raising concerns about the reliability and fairness of AI-assisted decision-making. Yet the impact of such degradations remains under-investigated, particularly regarding how noise-induced shifts can heighten predictive uncertainty and unevenly affect demographic subgroups. We present a systematic study of state-of-the-art LLMs under diverse text corruption scenarios, focusing on robustness and equity in next-visit diagnosis prediction. To address the challenge posed by the large diagnostic label space, we introduce a clinically grounded label-reduction scheme and a hierarchical chain-of-thought (CoT) strategy that emulates clinicians' reasoning. Our approach improves robustness and reduces subgroup instability under degraded inputs, advancing the reliable use of LLMs in CDSS. We release code at https://github.com/heejkoo9/NECHOv3.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u53d7\u635f\u4e34\u5e8a\u6587\u672c\u4e2d\u7684\u8868\u73b0\uff0c\u63d0\u51fa\u65b0\u7b56\u7565\u63d0\u5347\u8bca\u65ad\u9884\u6d4b\u9c81\u68d2\u6027\u4e0e\u516c\u5e73\u6027\uff0c\u4fc3\u8fdb\u4e86AI\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u7684\u53ef\u9760\u5e94\u7528\u3002", "motivation": "\u4e34\u5e8a\u6587\u672c\u5e38\u56e0\u4eba\u4e3a\u9519\u8bef\u6216\u81ea\u52a8\u5316\u6d41\u7a0b\u5931\u8d25\u800c\u53d7\u635f\uff0c\u8fd9\u5f15\u53d1\u4e86\u5bf9\u4eba\u5de5\u667a\u80fd\u8f85\u52a9\u51b3\u7b56\u7cfb\u7edf\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u7684\u62c5\u5fe7\uff0c\u4f46\u76f8\u5173\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002", "method": "\u5f15\u5165\u4e86\u4e34\u5e8a\u57fa\u7840\u7684\u6807\u7b7e\u964d\u7ef4\u65b9\u6848\u548c\u6a21\u62df\u4e34\u5e8a\u533b\u751f\u63a8\u7406\u7684\u5c42\u6b21\u94fe\u5f0f\u601d\u7ef4\u7b56\u7565\uff0c\u5728\u591a\u79cd\u6587\u672c\u8150\u8d25\u573a\u666f\u4e0b\u5bf9\u6700\u5148\u8fdb\u7684LLMs\u8fdb\u884c\u6d4b\u8bd5\uff0c\u91cd\u70b9\u8003\u5bdf\u5176\u9c81\u68d2\u6027\u548c\u7fa4\u4f53\u516c\u5e73\u6027\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u6587\u672c\u53d7\u635f\u73af\u5883\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u9884\u6d4b\u9c81\u68d2\u6027\uff0c\u51cf\u5c0f\u4e86\u4e0d\u540c\u4eba\u53e3\u5b50\u7fa4\u4f53\u95f4\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u589e\u5f3a\u4e86\u8bca\u65ad\u9884\u6d4b\u7684\u53ef\u9760\u6027\u548c\u516c\u5e73\u6027\u3002", "conclusion": "\u8be5\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u8bc4\u4f30\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4e34\u5e8a\u6587\u672c\u53d7\u635f\u60c5\u51b5\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u516c\u5e73\u6027\uff0c\u63d0\u51fa\u4e86\u6807\u7b7e\u964d\u7ef4\u548c\u5c42\u6b21\u94fe\u5f0f\u601d\u7ef4\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u4fc3\u8fdb\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u7684\u53ef\u9760\u5e94\u7528\u3002"}}
{"id": "2511.19132", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19132", "abs": "https://arxiv.org/abs/2511.19132", "authors": ["Mohammad Abboush", "Ahmad Hatahet", "Andreas Rausch"], "title": "LLMs-Powered Real-Time Fault Injection: An Approach Toward Intelligent Fault Test Cases Generation", "comment": null, "summary": "A well-known testing method for the safety evaluation and real-time validation of automotive software systems (ASSs) is Fault Injection (FI). In accordance with the ISO 26262 standard, the faults are introduced artificially for the purpose of analyzing the safety properties and verifying the safety mechanisms during the development phase. However, the current FI method and tools have a significant limitation in that they require manual identification of FI attributes, including fault type, location and time. The more complex the system, the more expensive, time-consuming and labour-intensive the process. To address the aforementioned challenge, a novel Large Language Models (LLMs)-assisted fault test cases (TCs) generation approach for utilization during real-time FI tests is proposed in this paper. To this end, considering the representativeness and coverage criteria, the applicability of various LLMs to create fault TCs from the functional safety requirements (FSRs) has been investigated. Through the validation results of LLMs, the superiority of the proposed approach utilizing gpt-4o in comparison to other state-of-the-art models has been demonstrated. Specifically, the proposed approach exhibits high performance in terms of FSRs classification and fault TCs generation with F1-score of 88% and 97.5%, respectively. To illustrate the proposed approach, the generated fault TCs were executed in real time on a hardware-in-the-loop system, where a high-fidelity automotive system model served as a case study. This novel approach offers a means of optimizing the real-time testing process, thereby reducing costs while simultaneously enhancing the safety properties of complex safety-critical ASSs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u81ea\u52a8\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u6c7d\u8f66\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b9e\u65f6\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u65b9\u6cd5\u4e2d\u4eba\u5de5\u8bc6\u522b\u6545\u969c\u5c5e\u6027\u7684\u56f0\u96be\u3002", "motivation": "\u4f20\u7edf\u7684\u6545\u969c\u6ce8\u5165\u6d4b\u8bd5\u9700\u8981\u624b\u5de5\u8bc6\u522b\u6545\u969c\u7c7b\u578b\u3001\u4f4d\u7f6e\u548c\u65f6\u673a\uff0c\u8fc7\u7a0b\u590d\u6742\u4e14\u8d39\u65f6\u8d39\u529b\uff0c\u5c24\u5176\u5728\u590d\u6742\u7cfb\u7edf\u4e2d\u66f4\u663e\u8457\u3002", "method": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982gpt-4o\uff09\u4ece\u529f\u80fd\u5b89\u5168\u9700\u6c42\u4e2d\u81ea\u52a8\u751f\u6210\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\uff0c\u5e76\u5728\u786c\u4ef6\u5728\u73af\u7cfb\u7edf\u4e2d\u8fdb\u884c\u4e86\u5b9e\u9645\u8fd0\u884c\u9a8c\u8bc1\u3002", "result": "\u901a\u8fc7\u4e0d\u540cLLMs\u7684\u9a8c\u8bc1\uff0cgpt-4o\u7684\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210F1\u5f97\u5206\u8fbe97.5%\uff0c\u529f\u80fd\u5b89\u5168\u9700\u6c42\u5206\u7c7bF1\u5f97\u5206\u8fbe88%\uff0c\u663e\u793a\u51fa\u4f18\u8d8a\u6027\u3002\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u5728\u786c\u4ef6\u5728\u73af\u7cfb\u7edf\u4e2d\u6210\u529f\u6267\u884c\uff0c\u8bc1\u660e\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5229\u7528gpt-4o\u6a21\u578b\u5728\u529f\u80fd\u5b89\u5168\u9700\u6c42\u7684\u5206\u7c7b\u548c\u6545\u969c\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5b9e\u65f6\u6d4b\u8bd5\u6548\u7387\uff0c\u964d\u4f4e\u4e86\u6210\u672c\uff0c\u5e76\u589e\u5f3a\u4e86\u590d\u6742\u5b89\u5168\u5173\u952e\u6c7d\u8f66\u8f6f\u4ef6\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2511.18409", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18409", "abs": "https://arxiv.org/abs/2511.18409", "authors": ["Dana Arad", "Yonatan Belinkov", "Hanjie Chen", "Najoung Kim", "Hosein Mohebbi", "Aaron Mueller", "Gabriele Sarti", "Martin Tutek"], "title": "Findings of the BlackboxNLP 2025 Shared Task: Localizing Circuits and Causal Variables in Language Models", "comment": null, "summary": "Mechanistic interpretability (MI) seeks to uncover how language models (LMs) implement specific behaviors, yet measuring progress in MI remains challenging. The recently released Mechanistic Interpretability Benchmark (MIB; Mueller et al., 2025) provides a standardized framework for evaluating circuit and causal variable localization. Building on this foundation, the BlackboxNLP 2025 Shared Task extends MIB into a community-wide reproducible comparison of MI techniques. The shared task features two tracks: circuit localization, which assesses methods that identify causally influential components and interactions driving model behavior, and causal variable localization, which evaluates approaches that map activations into interpretable features. With three teams spanning eight different methods, participants achieved notable gains in circuit localization using ensemble and regularization strategies for circuit discovery. With one team spanning two methods, participants achieved significant gains in causal variable localization using low-dimensional and non-linear projections to featurize activation vectors. The MIB leaderboard remains open; we encourage continued work in this standard evaluation framework to measure progress in MI research going forward.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8eMIB\u7684\u673a\u5236\u89e3\u91ca\u6027\u6807\u51c6\u5316\u8bc4\u6d4b\u6846\u67b6\u53ca\u793e\u533a\u5171\u4eab\u4efb\u52a1\uff0c\u901a\u8fc7\u591a\u4e2a\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u8bed\u8a00\u6a21\u578b\u4e2d\u56de\u8def\u548c\u56e0\u679c\u53d8\u91cf\u7684\u5b9a\u4f4d\u80fd\u529b\uff0c\u4fc3\u8fdb\u4e86\u673a\u5236\u89e3\u91ca\u6027\u7814\u7a76\u8fdb\u5c55", "motivation": "\u673a\u5236\u89e3\u91ca\u6027\u96be\u4ee5\u8861\u91cf\u8fdb\u5c55\uff0c\u63d0\u51fa\u6807\u51c6\u5316\u8bc4\u4f30\u6846\u67b6\u7528\u4e8e\u8861\u91cf\u8bed\u8a00\u6a21\u578b\u4e2d\u673a\u5236\u89e3\u91ca\u6027\u7684\u65b9\u6cd5\u6548\u679c", "method": "\u901a\u8fc7\u4e24\u4e2a\u8d5b\u9053\uff08\u56de\u8def\u5b9a\u4f4d\u548c\u56e0\u679c\u53d8\u91cf\u5b9a\u4f4d\uff09\u8fdb\u884c\u8bc4\u4f30\uff0c\u5229\u7528\u96c6\u5408\u65b9\u6cd5\u548c\u6b63\u5219\u5316\u7b56\u7565\u53d1\u73b0\u56de\u8def\uff0c\u4ee5\u53ca\u4f7f\u7528\u4f4e\u7ef4\u548c\u975e\u7ebf\u6027\u6295\u5f71\u65b9\u6cd5\u5bf9\u6fc0\u6d3b\u5411\u91cf\u8fdb\u884c\u7279\u5f81\u5316", "result": "\u591a\u652f\u56e2\u961f\u53c2\u4e0e\uff0c\u5171\u91c7\u7528\u5341\u79cd\u65b9\u6cd5\uff0c\u56de\u8def\u5b9a\u4f4d\u4f7f\u7528\u96c6\u5408\u548c\u6b63\u5219\u5316\u7b56\u7565\u83b7\u5f97\u663e\u8457\u63d0\u5347\uff0c\u56e0\u679c\u53d8\u91cf\u5b9a\u4f4d\u4f7f\u7528\u4f4e\u7ef4\u548c\u975e\u7ebf\u6027\u6295\u5f71\u5b9e\u73b0\u663e\u8457\u6539\u8fdb", "conclusion": "MIB\u6392\u884c\u699c\u4ecd\u5f00\u653e\uff0c\u9f13\u52b1\u793e\u533a\u7ee7\u7eed\u4f7f\u7528\u8be5\u6807\u51c6\u6846\u67b6\u63a8\u52a8\u673a\u5236\u89e3\u91ca\u6027\u7814\u7a76\u7684\u6301\u7eed\u8fdb\u5c55\u3002"}}
{"id": "2511.19177", "categories": ["cs.SE"], "pdf": "https://arxiv.org/pdf/2511.19177", "abs": "https://arxiv.org/abs/2511.19177", "authors": ["Alcino Cunha", "Nuno Macedo"], "title": "Synthesizing Test Cases for Narrowing Specification Candidates", "comment": null, "summary": "This paper proposes a technique to help choose the best formal specification candidate among a set of alternatives. Given a set of specifications, our technique generates a suite of test cases that, once classified by the user as desirable or not, narrows down the set of candidates to at most one specification. Two alternative solver-based algorithms are proposed, one that generates a minimal test suite, and another that does not ensure minimality. Both algorithms were implemented in a prototype that can be used generate test suites to help choose among alternative Alloy specifications. Our evaluation of this prototype against a large set of problems showed that the optimal algorithm is efficient enough for many practical problems, and that the non-optimal algorithm can scale up to dozens of candidate specifications while still generating reasonably sized test suites.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u7684\u6280\u672f\uff0c\u5e2e\u52a9\u4ece\u591a\u4e2a\u5019\u9009\u5f62\u5f0f\u89c4\u8303\u4e2d\u9009\u62e9\u6700\u4f73\u89c4\u8303\uff0c\u63d0\u51fa\u4e24\u79cd\u7b97\u6cd5\uff0c\u8bc4\u4f30\u8868\u660e\u6027\u80fd\u826f\u597d\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u95ee\u9898\u3002", "motivation": "\u5f62\u5f0f\u89c4\u8303\u901a\u5e38\u5b58\u5728\u591a\u4e2a\u5907\u9009\u65b9\u6848\uff0c\u96be\u4ee5\u786e\u5b9a\u6700\u4f73\u89c4\u8303\uff0c\u6545\u9700\u4e00\u79cd\u6709\u6548\u65b9\u6cd5\u8f85\u52a9\u9009\u62e9\u6700\u4f73\u89c4\u8303\u3002", "method": "\u91c7\u7528\u4e24\u79cd\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u7b97\u6cd5\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\uff0c\u4e00\u79cd\u4fdd\u8bc1\u751f\u6210\u6700\u5c0f\u6d4b\u8bd5\u7528\u4f8b\u96c6\uff0c\u53e6\u4e00\u79cd\u4e0d\u4fdd\u8bc1\u6700\u5c0f\u6027\uff0c\u901a\u8fc7\u7528\u6237\u5bf9\u6d4b\u8bd5\u7528\u4f8b\u7684\u671f\u671b\u5206\u7c7b\u7f29\u5c0f\u5019\u9009\u89c4\u8303\u8303\u56f4\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6280\u672f\uff0c\u7528\u4e8e\u4ece\u4e00\u7ec4\u5907\u9009\u7684\u5f62\u5f0f\u89c4\u8303\u4e2d\u9009\u62e9\u6700\u4f73\u7684\u89c4\u8303\u3002\u8be5\u6280\u672f\u901a\u8fc7\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u96c6\uff0c\u7528\u6237\u5bf9\u6d4b\u8bd5\u7528\u4f8b\u7684\u671f\u671b\u4e0e\u5426\u5206\u7c7b\uff0c\u4ece\u800c\u7f29\u5c0f\u5019\u9009\u89c4\u8303\u7684\u8303\u56f4\uff0c\u6700\u7ec8\u6700\u591a\u53ea\u5269\u4e00\u4e2a\u89c4\u8303\u3002\u6587\u7ae0\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u6c42\u89e3\u5668\u7684\u7b97\u6cd5\uff1a\u4e00\u79cd\u751f\u6210\u6700\u5c0f\u6d4b\u8bd5\u7528\u4f8b\u96c6\uff0c\u53e6\u4e00\u79cd\u4e0d\u4fdd\u8bc1\u6700\u5c0f\u6027\u3002\u4e24\u79cd\u7b97\u6cd5\u5747\u5df2\u5b9e\u73b0\u4e3a\u539f\u578b\uff0c\u80fd\u591f\u751f\u6210\u6d4b\u8bd5\u7528\u4f8b\u4ee5\u8f85\u52a9\u9009\u62e9Alloy\u89c4\u8303\u3002\u901a\u8fc7\u5728\u5927\u91cf\u95ee\u9898\u4e0a\u7684\u8bc4\u4f30\uff0c\u53d1\u73b0\u6700\u4f18\u7b97\u6cd5\u5728\u8bb8\u591a\u5b9e\u9645\u95ee\u9898\u4e2d\u6548\u7387\u8db3\u591f\u9ad8\uff0c\u800c\u975e\u6700\u4f18\u7b97\u6cd5\u80fd\u6269\u5c55\u5230\u6570\u5341\u4e2a\u5019\u9009\u89c4\u8303\uff0c\u540c\u65f6\u751f\u6210\u7684\u6d4b\u8bd5\u7528\u4f8b\u96c6\u89c4\u6a21\u5408\u7406\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6d4b\u8bd5\u7528\u4f8b\u751f\u6210\u7684\u9009\u62e9\u6280\u672f\u6709\u6548\u4e14\u5b9e\u7528\uff0c\u6700\u4f18\u7b97\u6cd5\u9ad8\u6548\uff0c\u975e\u6700\u4f18\u7b97\u6cd5\u53ef\u6269\u5c55\u81f3\u8f83\u591a\u5019\u9009\u89c4\u8303\uff0c\u8f85\u52a9\u5f62\u5f0f\u89c4\u8303\u7684\u9009\u62e9\u5de5\u4f5c\u3002"}}
{"id": "2511.18411", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18411", "abs": "https://arxiv.org/abs/2511.18411", "authors": ["Sultan Alrashed", "Chadi Helwe", "Francesco Orabona"], "title": "SmolKalam: Ensemble Quality-Filtered Translation at Scale for High Quality Arabic Post-Training Data", "comment": "Work in progress", "summary": "Although the community has tackled the acquisition of high-quality Arabic pretraining data, we still lack large-scale, multi-turn Arabic datasets that include reasoning and tool calling. Naive translation can work at the pretraining scale, but post-training demands much higher quality, which requires a stricter approach to dataset curation. In this work, we introduce SmolKalam, a translation of Smoltalk2 that uses a multi-model ensemble translation pipeline, applies quality filtering, and examines effective translation techniques for traditional decoder-only models through ablations.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86SmolKalam\uff0c\u8fd9\u662f\u5bf9Smoltalk2\u7684\u963f\u62c9\u4f2f\u8bed\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u7684\u7ffb\u8bd1\uff0c\u901a\u8fc7\u591a\u6a21\u578b\u96c6\u6210\u7ffb\u8bd1\u548c\u8d28\u91cf\u8fc7\u6ee4\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u963f\u62c9\u4f2f\u8bed\u9884\u8bad\u7ec3\u6570\u636e\u867d\u591a\uff0c\u4f46\u7f3a\u5c11\u5305\u542b\u63a8\u7406\u548c\u5de5\u5177\u8c03\u7528\u7684\u9ad8\u8d28\u91cf\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\uff0c\u5355\u7eaf\u7ffb\u8bd1\u4e0d\u8db3\u4ee5\u6ee1\u8db3\u540e\u671f\u8bad\u7ec3\u7684\u9ad8\u8d28\u91cf\u9700\u6c42\u3002", "method": "\u4f7f\u7528\u591a\u6a21\u578b\u96c6\u6210\u7ffb\u8bd1\u7ba1\u9053\uff0c\u7ed3\u5408\u8d28\u91cf\u8fc7\u6ee4\uff0c\u5e76\u901a\u8fc7\u6d88\u878d\u5b9e\u9a8c\u63a2\u7d22\u4f20\u7edf\u89e3\u7801\u5668\u6a21\u578b\u7684\u7ffb\u8bd1\u6280\u5de7\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u963f\u62c9\u4f2f\u8bed\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u96c6\u7684\u8d28\u91cf\uff0c\u4e3a\u540e\u7eed\u6a21\u578b\u8bad\u7ec3\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6570\u636e\u57fa\u7840\u3002", "conclusion": "SmolKalam\u6570\u636e\u96c6\u901a\u8fc7\u4e25\u683c\u7684\u6570\u636e\u7b5b\u9009\u548c\u591a\u6a21\u578b\u7ffb\u8bd1\u7b56\u7565\uff0c\u63d0\u5347\u4e86\u963f\u62c9\u4f2f\u8bed\u591a\u8f6e\u5bf9\u8bdd\u6570\u636e\u7684\u8d28\u91cf\uff0c\u9002\u5408\u540e\u671f\u8bad\u7ec3\u9700\u6c42\u3002"}}
{"id": "2511.19422", "categories": ["cs.SE", "cs.AI", "cs.PL"], "pdf": "https://arxiv.org/pdf/2511.19422", "abs": "https://arxiv.org/abs/2511.19422", "authors": ["David Jiahao Fu", "Aryan Gupta", "Aaron Councilman", "David Grove", "Yu-Xiong Wang", "Vikram Adve"], "title": "SLMFix: Leveraging Small Language Models for Error Fixing with Reinforcement Learning", "comment": null, "summary": "Recent advancements in large language models (LLMs) have shown very impressive capabilities in code generation across many programming languages. However, even state-of-the-art LLMs generate programs that contains syntactic errors and fail to complete the given tasks, especially for low-resource programming languages (LRPLs). In addition, high training cost makes finetuning LLMs unaffordable with constrained computational resources, further undermining the effectiveness of LLMs for code generation. In this work, we propose SLMFix, a novel code generation pipeline that leverages a small language model (SLM) finetuned using reinforcement learning (RL) techniques to fix syntactic errors in LLM-generated programs to improve the quality of LLM-generated programs for domain-specific languages (DSLs). In specific, we applied RL on the SLM for the program repair task using a reward calculated using both a static validator and a static semantic similarity metric. Our experimental results demonstrate the effectiveness and generalizability of our approach across multiple DSLs, achieving more than 95% pass rate on the static validator. Notably, SLMFix brings substantial improvement to the base model and outperforms supervised finetuning approach even for 7B models on a LRPL, showing the potential of our approach as an alternative to traditional finetuning approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSLMFix\u7684\u4ee3\u7801\u751f\u6210\u4fee\u6b63\u65b9\u6cd5\uff0c\u5229\u7528\u5c0f\u8bed\u8a00\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\u6280\u672f\u4fee\u590d\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u8bed\u6cd5\u9519\u8bef\uff0c\u63d0\u9ad8\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u7684\u4ee3\u7801\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4ee3\u7801\u751f\u6210\u4e2d\u6613\u51fa\u73b0\u8bed\u6cd5\u9519\u8bef\uff0c\u5c24\u5176\u5728\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5fae\u8c03\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u5176\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "method": "\u91c7\u7528\u5f3a\u5316\u5b66\u4e60\u5728\u5c0f\u8bed\u8a00\u6a21\u578b\u4e0a\u5fae\u8c03\uff0c\u901a\u8fc7\u9759\u6001\u9a8c\u8bc1\u5668\u548c\u9759\u6001\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5ea6\u91cf\u4f5c\u4e3a\u5956\u52b1\uff0c\u9488\u5bf9\u7a0b\u5e8f\u4fee\u590d\u4efb\u52a1\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660eSLMFix\u5728\u591a\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4e0a\u6548\u679c\u663e\u8457\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u57fa\u7840\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u5b9e\u73b0\u6bd4\u4f20\u7edf\u5fae\u8c03\u66f4\u4f18\u7684\u7ed3\u679c\u3002", "conclusion": "SLMFix\u663e\u8457\u63d0\u5347\u4e86\u4f4e\u8d44\u6e90\u7f16\u7a0b\u8bed\u8a00\u4e2d\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u4ee3\u7801\u7684\u8d28\u91cf\uff0c\u5728\u591a\u4e2a\u9886\u57df\u7279\u5b9a\u8bed\u8a00\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8fc795%\u7684\u901a\u8fc7\u7387\uff0c\u5e76\u4f18\u4e8e\u4f20\u7edf\u7684\u76d1\u7763\u5fae\u8c03\u65b9\u6cd5\u3002"}}
{"id": "2511.18413", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18413", "abs": "https://arxiv.org/abs/2511.18413", "authors": ["Yu Xia", "Sungchul Kim", "Tong Yu", "Ryan A. Rossi", "Julian McAuely"], "title": "Multi-Agent Collaborative Filtering: Orchestrating Users and Items for Agentic Recommendations", "comment": null, "summary": "Agentic recommendations cast recommenders as large language model (LLM) agents that can plan, reason, use tools, and interact with users of varying preferences in web applications. However, most existing agentic recommender systems focus on generic single-agent plan-execute workflows or multi-agent task decomposition pipelines. Without recommendation-oriented design, they often underuse the collaborative signals in the user-item interaction history, leading to unsatisfying recommendation results. To address this, we propose the Multi-Agent Collaborative Filtering (MACF) framework for agentic recommendations, drawing an analogy between traditional collaborative filtering algorithms and LLM-based multi-agent collaboration. Specifically, given a target user and query, we instantiate similar users and relevant items as LLM agents with unique profiles. Each agent is able to call retrieval tools, suggest candidate items, and interact with other agents. Different from the static preference aggregation in traditional collaborative filtering, MACF employs a central orchestrator agent to adaptively manage the collaboration between user and item agents via dynamic agent recruitment and personalized collaboration instruction. Experimental results on datasets from three different domains show the advantages of our MACF framework compared to strong agentic recommendation baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u8fc7\u6ee4\uff08MACF\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u7ba1\u7406\u7528\u6237\u548c\u7269\u54c1\u667a\u80fd\u4f53\u7684\u534f\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u7cfb\u7edf\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u63a8\u8350\u591a\u91c7\u7528\u5355\u4e00\u667a\u80fd\u4f53\u6216\u591a\u667a\u80fd\u4f53\u4efb\u52a1\u5206\u89e3\uff0c\u7f3a\u4e4f\u63a8\u8350\u5bfc\u5411\u8bbe\u8ba1\uff0c\u672a\u5145\u5206\u5229\u7528\u534f\u4f5c\u4fe1\u53f7\uff0c\u5bfc\u81f4\u63a8\u8350\u6548\u679c\u4e0d\u4f73\u3002", "method": "\u63d0\u51fa\u4e86MACF\u6846\u67b6\uff0c\u5c06\u7c7b\u4f3c\u7528\u6237\u548c\u76f8\u5173\u7269\u54c1\u5b9e\u4f8b\u5316\u4e3a\u5177\u6709\u72ec\u7279\u6863\u6848\u7684LLM\u667a\u80fd\u4f53\uff0c\u5728\u4e2d\u592e\u534f\u8c03\u667a\u80fd\u4f53\u7684\u7ba1\u7406\u4e0b\uff0c\u667a\u80fd\u4f53\u4eec\u8c03\u7528\u68c0\u7d22\u5de5\u5177\u3001\u76f8\u4e92\u534f\u4f5c\u548c\u63a8\u8350\u5019\u9009\u9879\u3002", "result": "MACF\u5728\u4e09\u4e2a\u4e0d\u540c\u9886\u57df\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u5f3a\u57fa\u7ebf\u667a\u80fd\u4f53\u63a8\u8350\u65b9\u6cd5\uff0c\u9a8c\u8bc1\u4e86\u5176\u8bbe\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "MACF\u6846\u67b6\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u65b9\u5f0f\uff0c\u6709\u6548\u5229\u7528\u7528\u6237-\u7269\u54c1\u4ea4\u4e92\u5386\u53f2\u4e2d\u7684\u534f\u4f5c\u4fe1\u53f7\uff0c\u63d0\u5347\u4e86\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u8350\u6027\u80fd\u3002"}}
{"id": "2511.19427", "categories": ["cs.SE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19427", "abs": "https://arxiv.org/abs/2511.19427", "authors": ["Jayanaka L. Dantanarayana", "Savini Kashmira", "Thakee Nathees", "Zichen Zhang", "Krisztian Flautner", "Lingjia Tang", "Jason Mars"], "title": "Prompt Less, Smile More: MTP with Semantic Engineering in Lieu of Prompt Engineering", "comment": null, "summary": "AI-Integrated programming is emerging as a foundational paradigm for building intelligent systems with large language models (LLMs). Recent approaches such as Meaning Typed Programming (MTP) automate prompt generation by leveraging the semantics already present in code. However, many real-world applications depend on contextual cues, developer intent, and domain-specific reasoning that extend beyond what static code semantics alone can express. To address this limitation, we introduce Semantic Engineering, a lightweight method for enriching program semantics so that LLM-based systems can more accurately reflect developer intent without requiring full manual prompt design. We present Semantic Context Annotations (SemTexts), a language-level mechanism that allows developers to embed natural-language context directly into program constructs. Integrated into the Jac programming language, Semantic Engineering extends MTP to incorporate these enriched semantics during prompt generation. We further introduce a benchmark suite designed to reflect realistic AI-Integrated application scenarios. Our evaluation shows that Semantic Engineering substantially improves prompt fidelity, achieving performance comparable to Prompt Engineering while requiring significantly less developer effort.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u901a\u8fc7\u5728\u4ee3\u7801\u4e2d\u5d4c\u5165\u81ea\u7136\u8bed\u8a00\u4e0a\u4e0b\u6587\u6765\u4e30\u5bcc\u7a0b\u5e8f\u8bed\u4e49\uff0c\u4ece\u800c\u63d0\u5347\u57fa\u4e8eLLM\u7684\u63d0\u793a\u8bcd\u751f\u6210\u6548\u679c\uff0c\u517c\u987e\u6548\u679c\u548c\u5f00\u53d1\u6210\u672c\u3002", "motivation": "\u73b0\u6709\u7684\u5229\u7528\u4ee3\u7801\u8bed\u4e49\u81ea\u52a8\u751f\u6210\u63d0\u793a\u8bcd\u7684\u65b9\u6cd5\uff08\u5982MTP\uff09\u65e0\u6cd5\u5145\u5206\u8868\u8fbe\u5f00\u53d1\u8005\u610f\u56fe\u53ca\u9886\u57df\u7279\u5b9a\u4e0a\u4e0b\u6587\uff0c\u56e0\u4e3a\u73b0\u5b9e\u5e94\u7528\u4e2d\u9700\u8981\u66f4\u591a\u4e0a\u4e0b\u6587\u7ebf\u7d22\u548c\u9886\u57df\u63a8\u7406\u3002", "method": "\u63d0\u51fa\u4e86Semantic Engineering\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u65b9\u6cd5\uff0c\u901a\u8fc7Semantic Context Annotations (SemTexts)\u5c06\u81ea\u7136\u8bed\u8a00\u4e0a\u4e0b\u6587\u76f4\u63a5\u5d4c\u5165\u7a0b\u5e8f\u6784\u9020\u4e2d\uff0c\u96c6\u6210\u4e8eJac\u8bed\u8a00\uff0c\u6269\u5c55\u4e86MTP\u5728\u63d0\u793a\u8bcd\u751f\u6210\u4e2d\u5bf9\u4e30\u5bcc\u8bed\u4e49\u7684\u5229\u7528\u3002", "result": "\u5728\u8bbe\u8ba1\u7684\u771f\u5b9e\u573a\u666f\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cSemantic Engineering\u663e\u8457\u63d0\u5347\u4e86\u63d0\u793a\u8bcd\u7684\u51c6\u786e\u6027\uff0c\u6027\u80fd\u53ef\u5ab2\u7f8e\u4f20\u7edf\u7684\u4eba\u5de5Prompt Engineering\uff0c\u4e14\u5927\u5e45\u51cf\u5c11\u5f00\u53d1\u4eba\u5458\u6295\u5165\u3002", "conclusion": "Semantic Engineering\u901a\u8fc7\u5c06\u81ea\u7136\u8bed\u8a00\u4e0a\u4e0b\u6587\u4e0e\u7a0b\u5e8f\u8bed\u4e49\u7ed3\u5408\uff0c\u63d0\u9ad8\u4e86\u57fa\u4e8eLLM\u7684\u7a0b\u5e8f\u63d0\u793a\u8bbe\u8ba1\u7684\u51c6\u786e\u5ea6\u548c\u6548\u7387\uff0c\u662f\u5b9e\u73b0\u667a\u80fd\u7cfb\u7edf\u5f00\u53d1\u7684\u6709\u6548\u8303\u5f0f\u3002"}}
{"id": "2511.18423", "categories": ["cs.CL", "cs.AI", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18423", "abs": "https://arxiv.org/abs/2511.18423", "authors": ["B. Y. Yan", "Chaofan Li", "Hongjin Qian", "Shuqi Lu", "Zheng Liu"], "title": "General Agentic Memory Via Deep Research", "comment": null, "summary": "Memory is critical for AI agents, yet the widely-adopted static memory, aiming to create readily available memory in advance, is inevitably subject to severe information loss. To address this limitation, we propose a novel framework called \\textbf{general agentic memory (GAM)}. GAM follows the principle of \"\\textbf{just-in time (JIT) compilation}\" where it focuses on creating optimized contexts for its client at runtime while keeping only simple but useful memory during the offline stage. To this end, GAM employs a duo-design with the following components. 1) \\textbf{Memorizer}, which highlights key historical information using a lightweight memory, while maintaining complete historical information within a universal page-store. 2) \\textbf{Researcher}, which retrieves and integrates useful information from the page-store for its online request guided by the pre-constructed memory. This design allows GAM to effectively leverage the agentic capabilities and test-time scalability of frontier large language models (LLMs), while also facilitating end-to-end performance optimization through reinforcement learning. In our experimental study, we demonstrate that GAM achieves substantial improvement on various memory-grounded task completion scenarios against existing memory systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u901a\u7528\u667a\u80fd\u8bb0\u5fc6\uff08GAM\uff09\u7684\u65b0\u578b\u8bb0\u5fc6\u6846\u67b6\uff0c\u91c7\u7528\u5373\u65f6\u7f16\u8bd1\u539f\u5219\uff0c\u5728\u8fd0\u884c\u65f6\u521b\u5efa\u4f18\u5316\u7684\u4e0a\u4e0b\u6587\uff0c\u7ed3\u5408\u8f7b\u91cf\u7ea7\u8bb0\u5fc6\u548c\u901a\u7528\u9875\u5b58\u50a8\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4efb\u52a1\u5b8c\u6210\u6548\u679c\u3002", "motivation": "\u9759\u6001\u8bb0\u5fc6\u5bb9\u6613\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u9650\u5236\u4e86AI\u4ee3\u7406\u7684\u8bb0\u5fc6\u80fd\u529b\u548c\u4efb\u52a1\u8868\u73b0\uff0c\u6709\u5fc5\u8981\u8bbe\u8ba1\u4e00\u79cd\u52a8\u6001\u9ad8\u6548\u7684\u8bb0\u5fc6\u4f53\u7cfb\u3002", "method": "GAM\u91c7\u7528Memorizer\u4e0eResearcher\u53cc\u8bbe\u8ba1\uff0cMemorizer\u5229\u7528\u8f7b\u91cf\u7ea7\u5b58\u50a8\u91cd\u70b9\u4fe1\u606f\u5e76\u7ef4\u62a4\u5b8c\u6574\u5386\u53f2\u4fe1\u606f\uff0cResearcher\u5219\u5728\u8fd0\u884c\u65f6\u4ece\u9875\u5b58\u50a8\u4e2d\u68c0\u7d22\u6574\u5408\u4fe1\u606f\uff0c\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u5b9e\u73b0\u7aef\u5230\u7aef\u6027\u80fd\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cGAM\u5728\u591a\u79cd\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4efb\u52a1\u5b8c\u6210\u573a\u666f\u4e2d\u76f8\u8f83\u73b0\u6709\u7cfb\u7edf\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "GAM\u6846\u67b6\u901a\u8fc7\u53cc\u91cd\u8bbe\u8ba1\u663e\u8457\u63d0\u5347\u4e86AI\u4ee3\u7406\u5728\u5404\u79cd\u57fa\u4e8e\u8bb0\u5fc6\u7684\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u9759\u6001\u8bb0\u5fc6\u7cfb\u7edf\u3002"}}
{"id": "2511.18491", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18491", "abs": "https://arxiv.org/abs/2511.18491", "authors": ["Jos\u00e9 Pombal", "Maya D'Eon", "Nuno M. Guerreiro", "Pedro Henrique Martins", "Ant\u00f3nio Farinhas", "Ricardo Rei"], "title": "MindEval: Benchmarking Language Models on Multi-turn Mental Health Support", "comment": null, "summary": "Demand for mental health support through AI chatbots is surging, though current systems present several limitations, like sycophancy or overvalidation, and reinforcement of maladaptive beliefs. A core obstacle to the creation of better systems is the scarcity of benchmarks that capture the complexity of real therapeutic interactions. Most existing benchmarks either only test clinical knowledge through multiple-choice questions or assess single responses in isolation. To bridge this gap, we present MindEval, a framework designed in collaboration with Ph.D-level Licensed Clinical Psychologists for automatically evaluating language models in realistic, multi-turn mental health therapy conversations. Through patient simulation and automatic evaluation with LLMs, our framework balances resistance to gaming with reproducibility via its fully automated, model-agnostic design. We begin by quantitatively validating the realism of our simulated patients against human-generated text and by demonstrating strong correlations between automatic and human expert judgments. Then, we evaluate 12 state-of-the-art LLMs and show that all models struggle, scoring below 4 out of 6, on average, with particular weaknesses in problematic AI-specific patterns of communication. Notably, reasoning capabilities and model scale do not guarantee better performance, and systems deteriorate with longer interactions or when supporting patients with severe symptoms. We release all code, prompts, and human evaluation data.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51faMindEval\u6846\u67b6\uff0c\u81ea\u52a8\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u591a\u8f6e\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\uff0c\u63ed\u793a\u5f53\u524d\u6a21\u578b\u7684\u4e0d\u8db3\u5e76\u4e3a\u5fc3\u7406\u5065\u5eb7AI\u7cfb\u7edf\u7684\u6539\u8fdb\u63d0\u4f9b\u8bc4\u4ef7\u5de5\u5177\u3002", "motivation": "\u73b0\u6709\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u7cfb\u7edf\u8bc4\u6d4b\u7f3a\u4e4f\u771f\u5b9e\u590d\u6742\u4ea4\u4e92\u7684\u57fa\u51c6\uff0c\u9650\u5236\u4e86\u66f4\u597d\u7cfb\u7edf\u7684\u5f00\u53d1\u3002", "method": "\u6784\u5efa\u4e86MindEval\u6846\u67b6\uff0c\u7ed3\u5408\u4e34\u5e8a\u5fc3\u7406\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u5229\u7528\u60a3\u8005\u6a21\u62df\u548c\u81ea\u52a8\u8bc4\u4f30\uff0c\u8fdb\u884c\u591a\u8f6e\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u7684\u8bc4\u6d4b\u3002", "result": "\u8bc4\u6d4b\u4e8612\u4e2a\u4e3b\u6d41\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u53d1\u73b0\u6a21\u578b\u8868\u73b0\u666e\u904d\u4e0d\u4f73\uff0c\u5c24\u5176\u5728\u5904\u7406\u8f83\u957f\u5bf9\u8bdd\u548c\u4e25\u91cd\u75c7\u72b6\u60a3\u8005\u65f6\u80fd\u529b\u4e0b\u964d\u3002\u81ea\u52a8\u8bc4\u4f30\u7ed3\u679c\u4e0e\u4e13\u5bb6\u8bc4\u4ef7\u9ad8\u5ea6\u76f8\u5173\uff0c\u9a8c\u8bc1\u4e86\u6846\u67b6\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u73b0\u6709\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5fc3\u7406\u5065\u5eb7\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u4e0d\u7406\u60f3\uff0c\u5b58\u5728\u5e94\u5bf9\u590d\u6742\u5bf9\u8bdd\u548c\u4e25\u91cd\u75c7\u72b6\u60a3\u8005\u7684\u56f0\u96be\u3002"}}
{"id": "2511.18499", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18499", "abs": "https://arxiv.org/abs/2511.18499", "authors": ["Tyler Shoemaker"], "title": "For Those Who May Find Themselves on the Red Team", "comment": null, "summary": "This position paper argues that literary scholars must engage with large language model (LLM) interpretability research. While doing so will involve ideological struggle, if not out-right complicity, the necessity of this engagement is clear: the abiding instrumentality of current approaches to interpretability cannot be the only standard by which we measure interpretation with LLMs. One site at which this struggle could take place, I suggest, is the red team.", "AI": {"tldr": "\u672c\u6587\u4e3b\u5f20\u6587\u5b66\u5b66\u8005\u5e94\u79ef\u6781\u4ecb\u5165\u5927\u8bed\u8a00\u6a21\u578b\u89e3\u91ca\u7814\u7a76\uff0c\u901a\u8fc7\u7ea2\u961f\u7b49\u65b9\u5f0f\u63a8\u52a8\u591a\u5143\u89e3\u8bfb\u6807\u51c6\u3002", "motivation": "\u5f53\u524dLLM\u89e3\u91ca\u65b9\u6cd5\u5177\u6709\u5de5\u5177\u6027\u9650\u5236\uff0c\u6587\u5b66\u89e3\u91ca\u9700\u8981\u6446\u8131\u5355\u4e00\u6807\u51c6\u7684\u7ea6\u675f\u3002", "method": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u63d0\u51fa\u7ea2\u961f(red team)\u4f5c\u4e3a\u5b66\u672f\u53c2\u4e0e\u548c\u610f\u8bc6\u5f62\u6001\u6597\u4e89\u7684\u5207\u5165\u70b9\u3002", "result": "\u6307\u51fa\u53c2\u4e0eLLM\u89e3\u91ca\u7814\u7a76\u4e0d\u53ef\u907f\u514d\u6d89\u53ca\u610f\u8bc6\u5f62\u6001\u6311\u6218\uff0c\u4f46\u8fd9\u662f\u5fc5\u8981\u7684\u5b66\u672f\u884c\u52a8\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u6587\u5b66\u5b66\u8005\u5fc5\u987b\u53c2\u4e0e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u7684\u53ef\u89e3\u91ca\u6027\u7814\u7a76\uff0c\u4e0d\u80fd\u4ec5\u4f9d\u8d56\u73b0\u6709\u7684\u89e3\u91ca\u6807\u51c6\u3002"}}
{"id": "2511.18557", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18557", "abs": "https://arxiv.org/abs/2511.18557", "authors": ["Yacouba Diarra", "Nouhoum Souleymane Coulibaly", "Panga Azazia Kamat\u00e9", "Madani Amadou Tall", "Emmanuel \u00c9lis\u00e9 Kon\u00e9", "Aymane Demb\u00e9l\u00e9", "Michael Leventhal"], "title": "Dealing with the Hard Facts of Low-Resource African NLP", "comment": "10 pages, 4 figures", "summary": "Creating speech datasets, models, and evaluation frameworks for low-resource languages remains challenging given the lack of a broad base of pertinent experience to draw from. This paper reports on the field collection of 612 hours of spontaneous speech in Bambara, a low-resource West African language; the semi-automated annotation of that dataset with transcriptions; the creation of several monolingual ultra-compact and small models using the dataset; and the automatic and human evaluation of their output. We offer practical suggestions for data collection protocols, annotation, and model design, as well as evidence for the importance of performing human evaluation. In addition to the main dataset, multiple evaluation datasets, models, and code are made publicly available.", "AI": {"tldr": "\u9488\u5bf9\u4f4e\u8d44\u6e90\u8bed\u8a00Bambara\uff0c\u6536\u96c6\u5e76\u6807\u6ce8\u5927\u91cf\u8bed\u97f3\u6570\u636e\uff0c\u8bad\u7ec3\u7d27\u51d1\u6a21\u578b\uff0c\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u5e76\u516c\u5f00\u8d44\u6e90\u3002", "motivation": "\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u8bed\u97f3\u6570\u636e\u96c6\u3001\u6a21\u578b\u53ca\u8bc4\u4f30\u6846\u67b6\u5efa\u7acb\u5177\u6709\u6311\u6218\u6027\uff0c\u7f3a\u4e4f\u4e30\u5bcc\u7684\u7ecf\u9a8c\u57fa\u7840\u3002", "method": "\u901a\u8fc7\u5b9e\u5730\u91c7\u96c6\u8bed\u97f3\u6570\u636e\uff0c\u91c7\u7528\u534a\u81ea\u52a8\u8f6c\u5f55\u65b9\u6cd5\u8fdb\u884c\u6807\u6ce8\uff0c\u8bad\u7ec3\u591a\u79cd\u5355\u8bed\u8d85\u5c0f\u578b\u6a21\u578b\uff0c\u4f7f\u7528\u81ea\u52a8\u548c\u4eba\u5de5\u65b9\u5f0f\u8bc4\u4f30\u6a21\u578b\u6027\u80fd\u3002", "result": "\u6536\u96c6\u4e86612\u5c0f\u65f6Bambara\u8bed\u8a00\u7684\u81ea\u53d1\u8bed\u97f3\uff0c\u5b8c\u6210\u534a\u81ea\u52a8\u8f6c\u5f55\u6807\u6ce8\uff0c\u5efa\u7acb\u4e86\u591a\u79cd\u8d85\u5c0f\u578b\u5355\u8bed\u6a21\u578b\uff0c\u5e76\u8fdb\u884c\u4e86\u81ea\u52a8\u548c\u4eba\u5de5\u8bc4\u4f30\uff0c\u516c\u5f00\u4e86\u6570\u636e\u96c6\u3001\u8bc4\u4f30\u96c6\u3001\u6a21\u578b\u548c\u4ee3\u7801\u3002", "conclusion": "\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u6570\u636e\u91c7\u96c6\u3001\u6807\u6ce8\u53ca\u6a21\u578b\u8bbe\u8ba1\u5efa\u8bae\uff0c\u5f3a\u8c03\u4eba\u5de5\u8bc4\u4f30\u7684\u91cd\u8981\u6027\u3002"}}
{"id": "2511.18597", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18597", "abs": "https://arxiv.org/abs/2511.18597", "authors": ["H. M. Shadman Tabib", "Jaber Ahmed Deedar"], "title": "Toward Trustworthy Difficulty Assessments: Large Language Models as Judges in Programming and Synthetic Tasks", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive capabilities in natural language and code generation, and are increasingly deployed as automatic judges of model outputs and learning activities. Yet, their behavior on structured tasks such as predicting the difficulty of competitive programming problems remains under-explored. We conduct a systematic comparison of GPT-4o, used purely as a natural-language difficulty assessor, against an interpretable Light-GBM ensemble trained on explicit numeric and textual features. On a dataset of 1,825 LeetCode problems labeled Easy, Medium, or Hard, LightGBM attains 86% accuracy, whereas GPT-4o reaches only 37.75%. Detailed analyses, including confusion matrices and SHAP-based interpretability, show that numeric constraints -- such as input size limits and acceptance rates -- play a crucial role in separating Hard problems from easier ones. By contrast, GPT-4o often overlooks these cues and exhibits a strong bias toward simpler categories. We further probe GPT-4o through a synthetic Hard-problem generation protocol. Surprisingly, GPT-4o labels almost all of its own synthetic Hard problems as Medium, contradicting its tendency to downgrade real Hard problems to Easy. Our findings connect to recent work on LLMs-as-judges and automatic difficulty estimation in programming and education, and highlight concrete failure modes that must be addressed before LLM-based judges can be considered trustworthy in competitive programming, educational platforms, or reinforcement-learning pipelines.", "AI": {"tldr": "GPT-4o\u5728\u81ea\u52a8\u8bc4\u4f30\u7f16\u7a0b\u9898\u96be\u5ea6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u51c6\u786e\u7387\u8fdc\u4f4e\u4e8e\u57fa\u4e8e\u7279\u5f81\u7684LightGBM\u6a21\u578b\uff0c\u5b58\u5728\u5ffd\u89c6\u5173\u952e\u6570\u503c\u4fe1\u606f\u548c\u8bc4\u5224\u504f\u5dee\u7684\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u548c\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u7ed3\u6784\u5316\u4efb\u52a1\u5982\u7f16\u7a0b\u9898\u96be\u5ea6\u9884\u6d4b\u4e2d\u7684\u8868\u73b0\u548c\u5224\u5b9a\u673a\u5236\u5c1a\u672a\u5145\u5206\u7814\u7a76\uff0c\u4e14\u81ea\u52a8\u96be\u5ea6\u8bc4\u4f30\u5728\u7f16\u7a0b\u7ade\u8d5b\u548c\u6559\u80b2\u9886\u57df\u6709\u5b9e\u9645\u9700\u6c42\uff0c\u6545\u672c\u7814\u7a76\u65e8\u5728\u63ed\u793aGPT-4o\u5728\u6b64\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u53ca\u5c40\u9650\u6027\u3002", "method": "\u5c06GPT-4o\u7eaf\u7cb9\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u96be\u5ea6\u8bc4\u4f30\u5668\uff0c\u4e0e\u57fa\u4e8e\u663e\u5f0f\u6570\u503c\u548c\u6587\u672c\u7279\u5f81\u7684LightGBM\u6a21\u578b\u57281,825\u4e2aLeetCode\u95ee\u9898\u4e0a\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\uff0c\u91c7\u7528\u6df7\u6dc6\u77e9\u9635\u548cSHAP\u89e3\u91ca\u5de5\u5177\u5206\u6790\u6a21\u578b\u8868\u73b0\uff0c\u540c\u65f6\u8bbe\u8ba1\u5408\u6210\u96be\u9898\u751f\u6210\u5b9e\u9a8c\u63a2\u7a76GPT-4o\u8bc4\u5224\u884c\u4e3a\u3002", "result": "\u672c\u6587\u7cfb\u7edf\u6bd4\u8f83\u4e86GPT-4o\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u96be\u5ea6\u8bc4\u4f30\u5668\u4e0e\u57fa\u4e8e\u663e\u5f0f\u6570\u503c\u548c\u6587\u672c\u7279\u5f81\u8bad\u7ec3\u7684LightGBM\u6a21\u578b\u5728\u9884\u6d4bLeetCode\u7f16\u7a0b\u9898\u96be\u5ea6\uff08Easy, Medium, Hard\uff09\u4e0a\u7684\u8868\u73b0\u3002\u7ed3\u679c\u663e\u793a\uff0cLightGBM\u51c6\u786e\u7387\u8fbe86%\uff0c\u800cGPT-4o\u4ec5\u4e3a37.75%\u3002\u901a\u8fc7\u6df7\u6dc6\u77e9\u9635\u548cSHAP\u89e3\u91ca\u5206\u6790\u53d1\u73b0\uff0c\u6570\u5b57\u7ea6\u675f\uff08\u5982\u8f93\u5165\u5927\u5c0f\u9650\u5236\u548c\u901a\u8fc7\u7387\uff09\u5bf9\u533a\u5206\u96be\u9898\u81f3\u5173\u91cd\u8981\uff0c\u4f46GPT-4o\u7ecf\u5e38\u5ffd\u89c6\u8fd9\u4e9b\u4fe1\u606f\u4e14\u504f\u5411\u4e8e\u9884\u6d4b\u4e3a\u7b80\u5355\u7c7b\u522b\u3002\u6b64\u5916\uff0cGPT-4o\u5bf9\u81ea\u751f\u6210\u7684\u96be\u9898\u4e5f\u591a\u9884\u6d4b\u4e3aMedium\uff0c\u663e\u793a\u5176\u5b58\u5728\u660e\u663e\u7684\u8bc4\u5224\u504f\u5dee\u3002\u8be5\u7814\u7a76\u6307\u51fa\u5728\u7ade\u4e89\u7f16\u7a0b\u548c\u6559\u80b2\u5e73\u53f0\u4e2d\uff0c\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u96be\u5ea6\u8bc4\u4f30\u5b58\u5728\u53ef\u4fe1\u5ea6\u95ee\u9898\uff0c\u9700\u8981\u6539\u8fdb\u3002", "conclusion": "\u73b0\u6709LLM\uff0c\u7279\u522b\u662fGPT-4o\uff0c\u5728\u8bc4\u4f30\u7f16\u7a0b\u9898\u96be\u5ea6\u65f6\u5b58\u5728\u660e\u663e\u5c40\u9650\uff0c\u96be\u4ee5\u66ff\u4ee3\u57fa\u4e8e\u6570\u503c\u548c\u6587\u672c\u7279\u5f81\u7684\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5176\u8bc4\u5224\u504f\u5dee\u53ca\u5ffd\u89c6\u6570\u503c\u7ea6\u675f\u7684\u95ee\u9898\u9700\u5728\u5b9e\u9645\u5e94\u7528\u524d\u89e3\u51b3\u3002"}}
{"id": "2511.18616", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18616", "abs": "https://arxiv.org/abs/2511.18616", "authors": ["Joseph Malone", "Rachith Aiyappa", "Byunghwee Lee", "Haewoon Kwak", "Jisun An", "Yong-Yeol Ahn"], "title": "A Benchmark for Zero-Shot Belief Inference in Large Language Models", "comment": "28 pages, 5 figures", "summary": "Beliefs are central to how humans reason, communicate, and form social connections, yet most computational approaches to studying them remain confined to narrow sociopolitical contexts and rely on fine-tuning for optimal performance. Despite the growing use of large language models (LLMs) across disciplines, how well these systems generalize across diverse belief domains remains unclear. We introduce a systematic, reproducible benchmark that evaluates the ability of LLMs to predict individuals' stances on a wide range of topics in a zero-shot setting using data from an online debate platform. The benchmark includes multiple informational conditions that isolate the contribution of demographic context and known prior beliefs to predictive success. Across several small- to medium-sized models, we find that providing more background information about an individual improves predictive accuracy, but performance varies substantially across belief domains. These findings reveal both the capacity and limitations of current LLMs to emulate human reasoning, advancing the study of machine behavior and offering a scalable framework for modeling belief systems beyond the sociopolitical sphere.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u57fa\u4e8e\u5728\u7ebf\u8fa9\u8bba\u5e73\u53f0\u6570\u636e\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u96f6\u6837\u672c\u6761\u4ef6\u4e0b\u9884\u6d4b\u4e2a\u4f53\u591a\u9886\u57df\u4fe1\u5ff5\u7acb\u573a\u7684\u80fd\u529b\uff0c\u63ed\u793a\u5176\u4f18\u52bf\u4e0e\u4e0d\u8db3\u3002", "motivation": "\u63a2\u7a76\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4e0d\u540c\u4fe1\u5ff5\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u7a81\u7834\u73b0\u6709\u65b9\u6cd5\u5c40\u9650\u4e8e\u72ed\u7a84\u793e\u4f1a\u653f\u6cbb\u80cc\u666f\u5e76\u4f9d\u8d56\u5fae\u8c03\u7684\u56f0\u5883\u3002", "method": "\u6784\u5efa\u5305\u542b\u591a\u79cd\u4fe1\u606f\u6761\u4ef6\u7684\u96f6\u6837\u672c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5229\u7528\u5728\u7ebf\u8fa9\u8bba\u5e73\u53f0\u6570\u636e\u8bc4\u4f30LLMs\u5bf9\u4e0d\u540c\u4fe1\u5ff5\u4e3b\u9898\u7684\u7acb\u573a\u9884\u6d4b\u80fd\u529b\uff0c\u6bd4\u8f83\u4e0d\u540c\u6a21\u578b\u53ca\u4fe1\u606f\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u6027\u53ef\u590d\u73b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u53d1\u73b0\u63d0\u4f9b\u66f4\u591a\u4e2a\u4eba\u80cc\u666f\u4fe1\u606f\u80fd\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\uff0c\u4f46\u4e0d\u540c\u4fe1\u5ff5\u9886\u57df\u7684\u8868\u73b0\u5dee\u5f02\u663e\u8457\uff0c\u63ed\u793a\u4e86LLMs\u5728\u4eba\u7c7b\u63a8\u7406\u6a21\u62df\u4e0a\u7684\u80fd\u529b\u4e0e\u5c40\u9650\u3002", "conclusion": "\u5f53\u524dLLMs\u5728\u6a21\u62df\u4eba\u7c7b\u4fe1\u5ff5\u63a8\u7406\u65b9\u9762\u5177\u5907\u4e00\u5b9a\u80fd\u529b\uff0c\u4e14\u901a\u8fc7\u5f15\u5165\u4e2a\u4eba\u80cc\u666f\u4fe1\u606f\u53ef\u63d0\u5347\u8868\u73b0\uff0c\u4f46\u4ecd\u5b58\u5728\u9886\u57df\u95f4\u6027\u80fd\u4e0d\u5747\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u62d3\u5c55\u5176\u5e94\u7528\u8303\u56f4\u3002"}}
{"id": "2511.18618", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18618", "abs": "https://arxiv.org/abs/2511.18618", "authors": ["Mirza Raquib", "Munazer Montasir Akash", "Tawhid Ahmed", "Saydul Akbar Murad", "Farida Siddiqi Prity", "Mohammad Amzad Hossain", "Asif Pervez Polok", "Nick Rahimi"], "title": "A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News", "comment": null, "summary": "In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\\% and 73.43\\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\\% and 64.46\\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u6df7\u5408\u8fc1\u79fb\u5b66\u4e60\u6a21\u578bBERT-CNN-BiLSTM\uff0c\u5bf9\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6807\u9898\u8fdb\u884c\u540c\u65f6\u7684\u5206\u7c7b\u4e0e\u60c5\u611f\u5206\u6790\uff0c\u89e3\u51b3\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u53d6\u5f97\u4e86\u4f18\u5f02\u6027\u80fd\u3002", "motivation": "\u9762\u5bf9\u5927\u91cf\u65b0\u95fb\u5185\u5bb9\uff0c\u5feb\u901f\u7406\u89e3\u65b0\u95fb\u4e3b\u9898\u4e0e\u60c5\u611f\u6001\u5ea6\u5bf9\u4e8e\u516c\u4f17\u81f3\u5173\u91cd\u8981\u3002\u5b5f\u52a0\u62c9\u8bed\u4f5c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\uff0c\u7f3a\u4e4f\u6709\u6548\u7684\u65b0\u95fb\u6807\u9898\u4e0e\u60c5\u611f\u5206\u7c7b\u65b9\u6cd5\uff0c\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8be5\u9886\u57df\u7a7a\u767d\uff0c\u63d0\u9ad8\u4fe1\u606f\u83b7\u53d6\u6548\u7387\u3002", "method": "\u91c7\u7528\u6df7\u5408\u8fc1\u79fb\u5b66\u4e60\u6a21\u578bBERT-CNN-BiLSTM\u5728BAN-ABSA\u6570\u636e\u96c6\u4e0a\uff0c\u7ed3\u5408\u4e24\u79cd\u91c7\u6837\u7b56\u7565\uff08\u6280\u672f1\u548c\u6280\u672f2\uff09\u5206\u522b\u5904\u7406\u6570\u636e\u4e0d\u5e73\u8861\uff0c\u8fdb\u884c\u65b0\u95fb\u6807\u9898\u548c\u60c5\u611f\u7684\u8054\u5408\u5206\u7c7b\u3002", "result": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408BERT-CNN-BiLSTM\u6df7\u5408\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u7684\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6807\u9898\u5206\u7c7b\u4e0e\u60c5\u611f\u5206\u6790\u65b0\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728BAN-ABSA\u6570\u636e\u96c6\uff089014\u6761\u65b0\u95fb\u6807\u9898\uff09\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5b9e\u73b0\u4e86\u65b0\u95fb\u6807\u9898\u4e0e\u60c5\u611f\u7684\u540c\u65f6\u5206\u7c7b\u3002\u9488\u5bf9\u6570\u636e\u4e0d\u5e73\u8861\u95ee\u9898\uff0c\u7814\u7a76\u91c7\u7528\u4e86\u4e24\u79cd\u91c7\u6837\u7b56\u7565\uff0c\u6280\u672f1\uff08\u5148\u91c7\u6837\u540e\u5212\u5206\uff09\u548c\u6280\u672f2\uff08\u5148\u5212\u5206\u540e\u91c7\u6837\uff09\uff0c\u5206\u522b\u53d6\u5f97\u4e8678.57%\u548c81.37%\u7684\u6807\u9898\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4ee5\u53ca73.43%\u548c64.46%\u7684\u60c5\u611f\u5206\u7c7b\u51c6\u786e\u7387\u3002\u6240\u63d0\u6a21\u578b\u663e\u8457\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u521b\u4e0b\u5b5f\u52a0\u62c9\u8bed\u6587\u672c\u5206\u7c7b\u65b0\u7eaa\u5f55\uff0c\u662f\u4f4e\u8d44\u6e90\u8bed\u8a00\u6587\u672c\u5206\u7c7b\u7684\u6709\u529b\u57fa\u7ebf\u3002", "conclusion": "BERT-CNN-BiLSTM\u6a21\u578b\u5728\u5b5f\u52a0\u62c9\u8bed\u65b0\u95fb\u6807\u9898\u548c\u60c5\u611f\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u5353\u8d8a\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u5b9e\u4e86\u7ed3\u5408\u6807\u9898\u548c\u60c5\u611f\u6570\u636e\u96c6\u53ca\u5408\u7406\u91c7\u6837\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u4f4e\u8d44\u6e90\u8bed\u8a00\u6587\u672c\u5206\u7c7b\u63d0\u4f9b\u4e86\u5f3a\u57fa\u7ebf\u3002"}}
{"id": "2511.18619", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18619", "abs": "https://arxiv.org/abs/2511.18619", "authors": ["Maanas Taneja"], "title": "Prompt Optimization as a State-Space Search Problem", "comment": null, "summary": "Language Models are extremely susceptible to performance collapse with even small changes to input prompt strings. Libraries such as DSpy (from Stanford NLP) avoid this problem through demonstration-based prompt optimisation. Inspired by this, I propose an alternative approach that treats prompt optimisation as a classical state-space search problem. I model the prompt space as a graph where nodes represent prompt states and edges correspond to deliberate transformations such as shortening, adding examples, or re- ordering content. Using beam search and random walk algorithms, I systematically explore this space, evaluating candidates on development sets and pruning unpromising branches. Across five NLP tasks (sentiment classification, question answering, summarisation, reason- ing, and natural language inference), I find that even shallow search configurations (beam width=2, depth=2) improve upon seed prompts on development sets. For instance, beam search achieves development accuracy gains from 0.40 to 0.80 on reasoning tasks, though test set improvements are more modest (0.20 to 0.50), indicating overfitting to the develop- ment heuristic. Analysis of successful optimisation paths reveals that transformations that make prompts concise appear most frequently, while verbosity operators are never selected. My results validate prompt optimization as a search problem and suggest that with greater computational resources and improved evaluation metrics, deeper exploration could yield more robust prompts that generalize beyond development sets. Code and implementation are available at [https://github.com/MaanasTaneja/PromptOptimiser].", "AI": {"tldr": "\u5c06\u63d0\u793a\u8bcd\u4f18\u5316\u5efa\u6a21\u4e3a\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u675f\u641c\u7d22\u548c\u968f\u673a\u6e38\u8d70\u4f18\u5316\u63d0\u793a\u8bcd\uff0c\u5728\u591a\u4e2aNLP\u4efb\u52a1\u4e2d\u63d0\u5347\u63d0\u793a\u8bcd\u6027\u80fd\uff0c\u7b80\u6d01\u7684\u63d0\u793a\u6539\u8fdb\u66f4\u6709\u6548\uff0c\u63d0\u793a\u8bcd\u4f18\u5316\u5177\u5907\u641c\u7d22\u95ee\u9898\u6027\u8d28\u3002", "motivation": "\u8bed\u8a00\u6a21\u578b\u5bf9\u8f93\u5165\u63d0\u793a\u6781\u5176\u654f\u611f\uff0c\u73b0\u6709\u65b9\u6cd5\u5982DSpy\u901a\u8fc7\u793a\u4f8b\u4f18\u5316\u63d0\u793a\uff0c\u672c\u6587\u53d7\u6b64\u542f\u53d1\u63d0\u51fa\u5c06\u63d0\u793a\u4f18\u5316\u89c6\u4e3a\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\uff0c\u4ece\u800c\u7cfb\u7edf\u5316\u63a2\u7d22\u63d0\u793a\u8bcd\u7a7a\u95f4\u3002", "method": "\u5c06\u63d0\u793a\u7a7a\u95f4\u5efa\u6a21\u4e3a\u56fe\uff0c\u8282\u70b9\u4e3a\u63d0\u793a\u72b6\u6001\uff0c\u8fb9\u4e3a\u8f6c\u6362\u64cd\u4f5c\uff08\u7f29\u77ed\u3001\u589e\u52a0\u793a\u4f8b\u3001\u91cd\u6392\u5e8f\uff09\uff0c\u8fd0\u7528\u675f\u641c\u7d22\u548c\u968f\u673a\u6e38\u8d70\u7b97\u6cd5\u5728\u63d0\u793a\u7a7a\u95f4\u5185\u641c\u7d22\uff0c\u57fa\u4e8e\u5f00\u53d1\u96c6\u8bc4\u4f30\u5e76\u526a\u679d\u3002", "result": "\u672c\u6587\u63d0\u51fa\u5c06\u63d0\u793a\u8bcd\u4f18\u5316\u89c6\u4e3a\u7ecf\u5178\u7684\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u95ee\u9898\uff0c\u901a\u8fc7\u6784\u5efa\u63d0\u793a\u8bcd\u7a7a\u95f4\u7684\u56fe\u6a21\u578b\uff0c\u5229\u7528\u675f\u641c\u7d22\u548c\u968f\u673a\u6e38\u8d70\u7b97\u6cd5\u7cfb\u7edf\u63a2\u7d22\u63d0\u793a\u8bcd\u7a7a\u95f4\uff0c\u5e76\u5728\u5f00\u53d1\u96c6\u4e0a\u8bc4\u4f30\u5e76\u526a\u679d\u4e0d\u4f73\u5206\u652f\u3002\u5b9e\u9a8c\u6db5\u76d6\u4e94\u4e2aNLP\u4efb\u52a1\uff0c\u6d45\u5c42\u641c\u7d22\u914d\u7f6e\u5373\u5e26\u6765\u63d0\u793a\u8bcd\u6027\u80fd\u63d0\u5347\uff0c\u5c24\u5176\u5728\u63a8\u7406\u4efb\u52a1\u4e0a\u5f00\u53d1\u96c6\u51c6\u786e\u7387\u663e\u8457\u63d0\u5347\u3002\u5206\u6790\u8868\u660e\uff0c\u7b80\u6d01\u7684\u63d0\u793a\u8bcd\u8f6c\u6362\u66f4\u6709\u6548\uff0c\u5197\u957f\u64cd\u4f5c\u65e0\u76ca\u3002\u7ed3\u679c\u8bc1\u660e\u63d0\u793a\u8bcd\u4f18\u5316\u53ef\u4f5c\u4e3a\u4e00\u4e2a\u641c\u7d22\u95ee\u9898\uff0c\u5e76\u6307\u51fa\u82e5\u6709\u66f4\u5f3a\u8ba1\u7b97\u8d44\u6e90\u53ca\u66f4\u597d\u8bc4\u4ef7\u6307\u6807\uff0c\u6df1\u5ea6\u63a2\u7d22\u6709\u671b\u83b7\u5f97\u66f4\u5177\u6cdb\u5316\u80fd\u529b\u7684\u63d0\u793a\u8bcd\u3002", "conclusion": "\u63d0\u793a\u8bcd\u4f18\u5316\u53ef\u89c6\u4e3a\u72b6\u6001\u7a7a\u95f4\u641c\u7d22\u95ee\u9898\uff0c\u675f\u641c\u7d22\u7b49\u65b9\u6cd5\u80fd\u63d0\u5347\u63d0\u793a\u8bcd\u8d28\u91cf\uff0c\u7b80\u6d01\u63d0\u793a\u8bcd\u66f4\u4f18\u3002\u6df1\u5c42\u641c\u7d22\u4e0e\u66f4\u597d\u8bc4\u4ef7\u6307\u6807\u6709\u5229\u4e8e\u6cdb\u5316\u80fd\u529b\u7684\u63d0\u5347\u3002"}}
{"id": "2511.18622", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18622", "abs": "https://arxiv.org/abs/2511.18622", "authors": ["Michael J. Bommarito"], "title": "OpenGloss: A Synthetic Encyclopedic Dictionary and Semantic Knowledge Graph", "comment": "30 pages, 5 figures, 8 tables. Dataset available at https://huggingface.co/datasets/mjbommar/opengloss-dictionary", "summary": "We present OpenGloss, a synthetic encyclopedic dictionary and semantic knowledge graph for English that integrates lexicographic definitions, encyclopedic context, etymological histories, and semantic relationships in a unified resource. OpenGloss contains 537K senses across 150K lexemes, on par with WordNet 3.1 and Open English WordNet, while providing more than four times as many sense definitions. These lexemes include 9.1M semantic edges, 1M usage examples, 3M collocations, and 60M words of encyclopedic content.\n  Generated through a multi-agent procedural generation pipeline with schema-validated LLM outputs and automated quality assurance, the entire resource was produced in under one week for under $1,000. This demonstrates that structured generation can create comprehensive lexical resources at cost and time scales impractical for manual curation, enabling rapid iteration as foundation models improve. The resource addresses gaps in pedagogical applications by providing integrated content -- definitions, examples, collocations, encyclopedias, etymology -- that supports both vocabulary learning and natural language processing tasks.\n  As a synthetically generated resource, OpenGloss reflects both the capabilities and limitations of current foundation models. The dataset is publicly available on Hugging Face under CC-BY 4.0, enabling researchers and educators to build upon and adapt this resource.", "AI": {"tldr": "OpenGloss\u662f\u4e00\u4e2a\u7ed3\u5408\u8bcd\u5178\u5b9a\u4e49\u3001\u767e\u79d1\u4e0a\u4e0b\u6587\u3001\u8bcd\u6e90\u548c\u8bed\u4e49\u5173\u7cfb\u7684\u7efc\u5408\u77e5\u8bc6\u56fe\uff0c\u89c4\u6a21\u76f8\u5f53\u4e8eWordNet\uff0c\u4f46\u5b9a\u4e49\u66f4\u591a\uff0c\u751f\u6210\u6210\u672c\u4f4e\u4e14\u901f\u5ea6\u5feb\uff0c\u9002\u5408\u6559\u5b66\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3002", "motivation": "\u73b0\u6709\u8bcd\u6c47\u8d44\u6e90\u5728\u5b9a\u4e49\u4e30\u5bcc\u6027\u3001\u7efc\u5408\u6027\u548c\u751f\u6210\u6548\u7387\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0cOpenGloss\u65e8\u5728\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u652f\u6301\u8bcd\u6c47\u5b66\u4e60\u548c\u81ea\u7136\u8bed\u8a00\u5904\u7406\u3002", "method": "\u91c7\u7528\u591a\u667a\u80fd\u4f53\u7a0b\u5e8f\u5316\u751f\u6210\u6d41\u7a0b\uff0c\u7ed3\u5408\u6a21\u5f0f\u9a8c\u8bc1\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u548c\u81ea\u52a8\u8d28\u91cf\u4fdd\u8bc1\uff0c\u5feb\u901f\u9ad8\u6548\u5730\u751f\u6210\u8d44\u6e90\u3002", "result": "\u751f\u6210\u4e86\u5305\u542b537K\u8bcd\u4e49\u3001150K\u8bcd\u6761\u3001910\u4e07\u8bed\u4e49\u8fb9\u3001100\u4e07\u7528\u4f8b\u548c6000\u4e07\u767e\u79d1\u8bcd\u6c47\u7684\u8d44\u6e90\uff0c\u751f\u6210\u65f6\u95f4\u4e0d\u8db3\u4e00\u5468\uff0c\u6210\u672c\u4f4e\u4e8e1000\u7f8e\u5143\uff0c\u516c\u5f00\u53d1\u5e03\u3002", "conclusion": "OpenGloss\u5c55\u793a\u4e86\u901a\u8fc7\u7ed3\u6784\u5316\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f93\u51fa\u751f\u6210\u7efc\u5408\u8bcd\u6c47\u8d44\u6e90\u7684\u53ef\u884c\u6027\u4e0e\u4f18\u52bf\uff0c\u6210\u672c\u4f4e\u901f\u5ea6\u5feb\uff0c\u652f\u6301\u6559\u80b2\u4e0eNLP\u5e94\u7528\u3002"}}
{"id": "2511.18635", "categories": ["cs.CL", "cs.AI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2511.18635", "abs": "https://arxiv.org/abs/2511.18635", "authors": ["Shireen Chand", "Faith Baca", "Emilio Ferrara"], "title": "No Free Lunch in Language Model Bias Mitigation? Targeted Bias Reduction Can Exacerbate Unmitigated LLM Biases", "comment": null, "summary": "Large Language Models (LLMs) inherit societal biases from their training data, potentially leading to harmful or unfair outputs. While various techniques aim to mitigate these biases, their effects are often evaluated only along the dimension of the bias being targeted. This work investigates the cross-category consequences of targeted bias mitigation. We study four bias mitigation techniques applied across ten models from seven model families, and we explore racial, religious, profession- and gender-related biases. We measure the impact of debiasing on model coherence and stereotypical preference using the StereoSet benchmark. Our results consistently show that while targeted mitigation can sometimes reduce bias in the intended dimension, it frequently leads to unintended and often negative consequences in others, such as increasing model bias and decreasing general coherence. These findings underscore the critical need for robust, multi-dimensional evaluation tools when examining and developing bias mitigation strategies to avoid inadvertently shifting or worsening bias along untargeted axes.", "AI": {"tldr": "\u9488\u5bf9\u6027\u504f\u89c1\u7f13\u89e3\u6280\u672f\u6613\u5728\u672a\u9488\u5bf9\u7684\u504f\u89c1\u7ef4\u5ea6\u4ea7\u751f\u8d1f\u9762\u5f71\u54cd\uff0c\u9700\u591a\u7ef4\u5ea6\u8bc4\u4ef7\u907f\u514d\u504f\u89c1\u8f6c\u79fb\u6216\u6076\u5316\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u6280\u672f\u80fd\u51cf\u8f7b\u7279\u5b9a\u65b9\u5411\u7684\u504f\u89c1\uff0c\u4f46\u901a\u5e38\u53ea\u6cbf\u76ee\u6807\u504f\u89c1\u7ef4\u5ea6\u8bc4\u4f30\u6548\u679c\uff0c\u5ffd\u89c6\u4e86\u504f\u89c1\u7f13\u89e3\u5bf9\u5176\u4ed6\u7ef4\u5ea6\u7684\u4ea4\u53c9\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u4e86\u56db\u79cd\u6d88\u9664\u504f\u89c1\u7684\u6280\u672f\uff0c\u5e94\u7528\u4e8e\u6765\u81ea\u4e03\u4e2a\u6a21\u578b\u5bb6\u65cf\u7684\u5341\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8986\u76d6\u79cd\u65cf\u3001\u5b97\u6559\u3001\u804c\u4e1a\u548c\u6027\u522b\u504f\u89c1\u3002\u901a\u8fc7StereoSet\u57fa\u51c6\u8bc4\u4f30\u6d88\u9664\u504f\u89c1\u5bf9\u6a21\u578b\u8fde\u8d2f\u6027\u548c\u523b\u677f\u504f\u597d\u5f71\u54cd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u9488\u5bf9\u6027\u6d88\u9664\u504f\u89c1\u6709\u65f6\u80fd\u51cf\u5c11\u9884\u671f\u504f\u89c1\uff0c\u4f46\u5e38\u5bfc\u81f4\u5176\u4ed6\u7ef4\u5ea6\u504f\u89c1\u52a0\u5267\u548c\u6a21\u578b\u8fde\u8d2f\u6027\u4e0b\u964d\u3002", "conclusion": "\u504f\u89c1\u7f13\u89e3\u7b56\u7565\u5fc5\u987b\u91c7\u7528\u591a\u7ef4\u5ea6\u3001\u5168\u9762\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u4ee5\u9632\u6b62\u5728\u7f13\u89e3\u67d0\u4e9b\u504f\u89c1\u65f6\u65e0\u610f\u4e2d\u52a0\u5267\u5176\u4ed6\u504f\u89c1\uff0c\u4fdd\u8bc1\u6a21\u578b\u516c\u5e73\u6027\u548c\u8fde\u8d2f\u6027\u3002"}}
{"id": "2511.18649", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18649", "abs": "https://arxiv.org/abs/2511.18649", "authors": ["Goun Pyeon", "Inbum Heo", "Jeesu Jung", "Taewook Hwang", "Hyuk Namgoong", "Hyein Seo", "Yerim Han", "Eunbin Kim", "Hyeonseok Kang", "Sangkeun Jung"], "title": "Evaluating Large Language Models on the 2026 Korean CSAT Mathematics Exam: Measuring Mathematical Ability in a Zero-Data-Leakage Setting", "comment": "52 pages, Korean", "summary": "This study systematically evaluated the mathematical reasoning capabilities of Large Language Models (LLMs) using the 2026 Korean College Scholastic Ability Test (CSAT) Mathematics section, ensuring a completely contamination-free evaluation environment. To address data leakage issues in existing benchmarks, we digitized all 46 questions (22 common and 24 elective) within two hours of the exam's public release, eliminating any possibility of inclusion in model training data. We conducted comprehensive evaluations of 24 state-of-the-art LLMs across varying input modalities (text, image, text+figure) and prompt languages (Korean, English).\n  GPT-5 Codex achieved the only perfect score (100 points) with text input and Korean prompts, while Grok 4, GPT-5, and Deepseek R1 scored above 95 points. Notably, gpt-oss-20B achieved 95.7 points despite its relatively small size, demonstrating high cost-effectiveness. Problem-specific analysis revealed geometry as the weakest domain (77.7% average) with significant performance degradation on 4-point high-difficulty problems. Text input consistently outperformed image input, while prompt language effects varied by model scale.\n  In reasoning enhancement experiments with GPT-5 series, increased reasoning intensity improved performance (from 82.6 to 100 points) but quadrupled token usage and drastically reduced efficiency, suggesting that models with minimal reasoning may be more practical. This research contributes: (1) implementation of a completely unexposed evaluation environment, (2) a real-exam-based LLM assessment framework, and (3) a practical evaluation perspective integrating performance, cost, and time considerations. Detailed results and model comparisons are available at the 2026 Korean CSAT LLM Evaluation Leaderboard (https://isoft.cnu.ac.kr/csat2026/).", "AI": {"tldr": "\u672c\u7814\u7a76\u642d\u5efa\u65e0\u6cc4\u9732\u73af\u5883\uff0c\u4f7f\u75282026\u5e74\u97e9\u56fdCSAT\u6570\u5b66\u9898\u8bc4\u6d4b24\u4e2aLLMs\uff0c\u53d1\u73b0GPT-5 Codex\u6700\u4f73\uff0c\u51e0\u4f55\u8868\u73b0\u6700\u5f31\uff0c\u63a8\u7406\u589e\u5f3a\u63d0\u5347\u6210\u7ee9\u4f46\u6548\u7387\u964d\u4f4e\uff0c\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u6a21\u578b\u8bc4\u4ef7\u6846\u67b6\u3002", "motivation": "\u73b0\u6709\u516c\u5f00\u57fa\u51c6\u5b58\u5728\u6570\u636e\u6cc4\u9732\uff0c\u5bfc\u81f4\u8bc4\u6d4b\u7ed3\u679c\u4e0d\u51c6\u786e\uff0c\u4e14\u7f3a\u5c11\u57fa\u4e8e\u771f\u5b9e\u8003\u8bd5\u7684\u65e0\u6cc4\u9732\u6570\u5b66\u63a8\u7406\u8bc4\u4f30\u6846\u67b6\u3002\u8be5\u7814\u7a76\u65e8\u5728\u5efa\u7acb\u4e00\u4e2a\u7eaf\u51c0\u7684\u8bc4\u6d4b\u73af\u5883\uff0c\u771f\u5b9e\u53cd\u6620\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u80fd\u529b\u4e0a\u7684\u8868\u73b0\uff0c\u540c\u65f6\u517c\u987e\u6027\u80fd\u4e0e\u6210\u672c\u6548\u7387\uff0c\u63a8\u52a8\u6a21\u578b\u5e94\u7528\u5b9e\u7528\u5316\u3002", "method": "\u901a\u8fc7\u5728\u8003\u8bd5\u540e\u4e24\u5c0f\u65f6\u5185\u6570\u5b57\u5316\u6240\u6709\u9898\u76ee\uff0c\u907f\u514d\u6570\u636e\u6cc4\u9732\uff0c\u8bbe\u8ba1\u6db5\u76d6\u6587\u672c\u3001\u56fe\u50cf\u53ca\u6df7\u5408\u8f93\u5165\u6a21\u5f0f\uff0c\u97e9\u8bed\u548c\u82f1\u8bed\u63d0\u793a\u8bed\u8a00\uff0c\u6d4b\u8bd524\u6b3e\u4e0d\u540c\u89c4\u6a21\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u3002\u8fd8\u8fdb\u884c\u4e86\u63a8\u7406\u589e\u5f3a\u5b9e\u9a8c\uff0c\u8bc4\u4f30\u4e0d\u540c\u63a8\u7406\u5f3a\u5ea6\u4e0b\u6a21\u578b\u7684\u6027\u80fd\u53ca\u6548\u7387\u3002", "result": "\u8be5\u8bba\u6587\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u8fbe24\u79cd\u5148\u8fdb\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u57282026\u5e74\u97e9\u56fd\u5927\u5b66\u5b66\u4e1a\u80fd\u529b\u6d4b\u9a8c\u6570\u5b66\u90e8\u5206\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u786e\u4fdd\u65e0\u6570\u636e\u6cc4\u9732\u5f71\u54cd\u3002GPT-5 Codex\u4ee5\u6587\u672c\u8f93\u5165\u548c\u97e9\u8bed\u63d0\u793a\u83b7\u5f97\u6ee1\u5206\uff0c\u663e\u793a\u51fa\u4f18\u5f02\u6027\u80fd\u3002\u7814\u7a76\u5206\u6790\u4e86\u4e0d\u540c\u8f93\u5165\u6a21\u5f0f\u548c\u63d0\u793a\u8bed\u8a00\u5bf9\u6a21\u578b\u8868\u73b0\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u51e0\u4f55\u4e3a\u6a21\u578b\u7684\u8584\u5f31\u73af\u8282\uff0c\u4e14\u63d0\u9ad8\u63a8\u7406\u5f3a\u5ea6\u867d\u80fd\u63d0\u5347\u5206\u6570\u4f46\u663e\u8457\u964d\u4f4e\u6548\u7387\u3002\u7814\u7a76\u5b9e\u73b0\u4e86\u5b8c\u5168\u65e0\u6cc4\u9732\u7684\u8bc4\u6d4b\u73af\u5883\uff0c\u6784\u5efa\u4e86\u57fa\u4e8e\u771f\u5b9e\u8003\u8bd5\u7684\u6a21\u578b\u8bc4\u6d4b\u6846\u67b6\uff0c\u5e76\u63d0\u51fa\u4e86\u7ed3\u5408\u6027\u80fd\u3001\u6210\u672c\u548c\u65f6\u95f4\u7684\u5b9e\u7528\u8bc4\u4f30\u89c6\u89d2\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u5728\u65e0\u6570\u636e\u6cc4\u9732\u73af\u5883\u4e0b\uff0c\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u5728\u9ad8\u96be\u5ea6\u6570\u5b66\u8003\u8bd5\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5b58\u5728\u51e0\u4f55\u7b49\u9886\u57df\u7684\u7f3a\u9677\u3002\u63d0\u9ad8\u63a8\u7406\u5f3a\u5ea6\u80fd\u63d0\u5347\u6210\u7ee9\u4f46\u4ee3\u4ef7\u662f\u6548\u7387\u5927\u5e45\u4e0b\u964d\uff0c\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u6743\u8861\u6027\u80fd\u4e0e\u6210\u672c\u3002\u7814\u7a76\u6784\u5efa\u4e86\u771f\u5b9e\u8003\u8bd5\u57fa\u7840\u4e0b\u7684\u5168\u9762\u8bc4\u6d4b\u6846\u67b6\uff0c\u4e3a\u4eca\u540eLLM\u6570\u5b66\u63a8\u7406\u80fd\u529b\u8bc4\u4f30\u63d0\u4f9b\u4e86\u53c2\u8003\u3002"}}
{"id": "2511.18659", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18659", "abs": "https://arxiv.org/abs/2511.18659", "authors": ["Jie He", "Richard He Bai", "Sinead Williamson", "Jeff Z. Pan", "Navdeep Jaitly", "Yizhe Zhang"], "title": "CLaRa: Bridging Retrieval and Generation with Continuous Latent Reasoning", "comment": null, "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) with external knowledge but still suffers from long contexts and disjoint retrieval-generation optimization. In this work, we propose CLaRa (Continuous Latent Reasoning), a unified framework that performs embedding-based compression and joint optimization in a shared continuous space. To obtain semantically rich and retrievable compressed vectors, we introduce SCP, a key-preserving data synthesis framework using QA and paraphrase supervision. CLaRa then trains the reranker and generator end-to-end via a single language modeling loss, with gradients flowing through both modules using a differentiable top-k estimator. Theoretically, this unified optimization aligns retrieval relevance with answer quality. Experiments across multiple QA benchmarks show that CLaRa achieves state-of-the-art compression and reranking performance, often surpassing text-based fine-tuned baselines.", "AI": {"tldr": "CLaRa\u901a\u8fc7\u7edf\u4e00\u5d4c\u5165\u538b\u7f29\u548c\u8054\u5408\u4f18\u5316\uff0c\u5728\u95ee\u7b54\u4efb\u52a1\u4e2d\u63d0\u5347\u4e86\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6a21\u578b\u7684\u6548\u679c\uff0c\u8868\u73b0\u4f18\u4e8e\u591a\u79cd\u57fa\u7ebf\u3002", "motivation": "\u4f20\u7edfRAG\u65b9\u6cd5\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u548c\u68c0\u7d22\u4e0e\u751f\u6210\u6a21\u5757\u7684\u5206\u79bb\u4f18\u5316\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86\u6574\u4f53\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86CLaRa\u6846\u67b6\uff0c\u91c7\u7528\u5d4c\u5165\u538b\u7f29\u548c\u5171\u4eab\u8fde\u7eed\u7a7a\u95f4\u8054\u5408\u4f18\u5316\uff1b\u5f15\u5165SCP\u6570\u636e\u5408\u6210\u6846\u67b6\u7ed3\u5408QA\u548c\u590d\u8ff0\u76d1\u7763\uff1b\u5229\u7528\u53ef\u5fae\u5206top-k\u4f30\u8ba1\u5668\uff0c\u5b9e\u73b0\u91cd\u6392\u5e8f\u5668\u548c\u751f\u6210\u5668\u7684\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cCLaRa\u5c55\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u538b\u7f29\u548c\u91cd\u6392\u5e8f\u6027\u80fd\uff0c\u4f18\u4e8e\u57fa\u4e8e\u6587\u672c\u5fae\u8c03\u7684\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "CLaRa\u6846\u67b6\u901a\u8fc7\u8054\u5408\u4f18\u5316\u548c\u5d4c\u5165\u538b\u7f29\uff0c\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8e\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u7684\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u68c0\u7d22\u76f8\u5173\u6027\u4e0e\u7b54\u6848\u8d28\u91cf\u7684\u7edf\u4e00\u63d0\u5347\u3002"}}
{"id": "2511.18696", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18696", "abs": "https://arxiv.org/abs/2511.18696", "authors": ["Wangjiaxuan Xin"], "title": "Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models", "comment": null, "summary": "This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional Resonance, Reflective Understanding, and Integrative Synthesis, to guide models toward generating emotionally resonant and contextually aware responses. Experimental results demonstrate that ECN achieves the highest Empathy Quotient (EQ) scores across GPT-3.5-turbo and GPT-4, while maintaining competitive Regard and Perplexity metrics. These findings emphasize ECN's potential for applications requiring empathy and inclusivity in conversational AI.", "AI": {"tldr": "\u63d0\u51fa\u4e86ECN\u591a\u9636\u6bb5\u63d0\u793a\u65b9\u6cd5\uff0c\u663e\u8457\u589e\u5f3a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u540c\u7406\u5fc3\u8868\u73b0\uff0c\u9002\u7528\u4e8e\u9700\u8981\u60c5\u611f\u5171\u9e23\u7684\u5bf9\u8bdd\u7cfb\u7edf\u3002", "motivation": "\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u4e2d\u8868\u8fbe\u540c\u7406\u5fc3\u548c\u5305\u5bb9\u6027\u7684\u80fd\u529b\uff0c\u4ee5\u6ee1\u8db3\u66f4\u9ad8\u8d28\u91cf\u7684\u4ea4\u4e92\u9700\u6c42\u3002", "method": "\u91c7\u7528\u56db\u9636\u6bb5\u591a\u8f6e\u63d0\u793a\u65b9\u6cd5\uff0c\u5305\u62ec\u89c6\u89d2\u91c7\u7eb3\u3001\u60c5\u611f\u5171\u9e23\u3001\u53cd\u601d\u7406\u89e3\u548c\u7efc\u5408\u5408\u6210\uff0c\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u60c5\u611f\u5171\u9e23\u4e14\u4e0a\u4e0b\u6587\u76f8\u5173\u7684\u56de\u5e94\u3002", "result": "ECN\u5728GPT-3.5-turbo\u548cGPT-4\u4e0a\u5747\u83b7\u5f97\u6700\u9ad8\u7684\u540c\u7406\u5546\uff08EQ\uff09\u5206\u6570\uff0c\u540c\u65f6\u4fdd\u6301\u826f\u597d\u7684\u5173\u6000\u5ea6\u548c\u56f0\u60d1\u5ea6\u6307\u6807\u3002", "conclusion": "ECN\u6846\u67b6\u6210\u529f\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5171\u60c5\u80fd\u529b\uff0c\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5c55\u793a\u4e86\u5176\u5728\u9700\u8981\u540c\u7406\u5fc3\u548c\u5305\u5bb9\u6027\u7684\u5bf9\u8bddAI\u5e94\u7528\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.18743", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18743", "abs": "https://arxiv.org/abs/2511.18743", "authors": ["Yu Lei", "Shuzheng Si", "Wei Wang", "Yifei Wu", "Gang Chen", "Fanchao Qi", "Maosong Sun"], "title": "RhinoInsight: Improving Deep Research through Control Mechanisms for Model Behavior and Context", "comment": null, "summary": "Large language models are evolving from single-turn responders into tool-using agents capable of sustained reasoning and decision-making for deep research. Prevailing systems adopt a linear pipeline of plan to search to write to a report, which suffers from error accumulation and context rot due to the lack of explicit control over both model behavior and context. We introduce RhinoInsight, a deep research framework that adds two control mechanisms to enhance robustness, traceability, and overall quality without parameter updates. First, a Verifiable Checklist module transforms user requirements into traceable and verifiable sub-goals, incorporates human or LLM critics for refinement, and compiles a hierarchical outline to anchor subsequent actions and prevent non-executable planning. Second, an Evidence Audit module structures search content, iteratively updates the outline, and prunes noisy context, while a critic ranks and binds high-quality evidence to drafted content to ensure verifiability and reduce hallucinations. Our experiments demonstrate that RhinoInsight achieves state-of-the-art performance on deep research tasks while remaining competitive on deep search tasks.", "AI": {"tldr": "RhinoInsight\u901a\u8fc7\u5f15\u5165\u4e24\u79cd\u63a7\u5236\u673a\u5236\uff0c\u89e3\u51b3\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6df1\u5ea6\u7814\u7a76\u4e2d\u7684\u9519\u8bef\u7d2f\u8ba1\u548c\u4e0a\u4e0b\u6587\u8870\u51cf\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u7684\u6027\u80fd\u548c\u7ed3\u679c\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u7ebf\u6027\u8ba1\u5212\u5b58\u5728\u9519\u8bef\u79ef\u7d2f\u548c\u4e0a\u4e0b\u6587\u8870\u51cf\u95ee\u9898\uff0c\u7f3a\u4e4f\u5bf9\u6a21\u578b\u884c\u4e3a\u548c\u4e0a\u4e0b\u6587\u7684\u663e\u5f0f\u63a7\u5236\uff0c\u5f71\u54cd\u4e86\u6027\u80fd\u548c\u7ed3\u679c\u8d28\u91cf\u3002", "method": "RhinoInsight\u5229\u7528\u4e24\u4e2a\u63a7\u5236\u673a\u5236\uff1a\u53ef\u9a8c\u8bc1\u68c0\u67e5\u6e05\u5355\u6a21\u5757\u5c06\u7528\u6237\u9700\u6c42\u8f6c\u5316\u4e3a\u53ef\u8ffd\u8e2a\u548c\u9a8c\u8bc1\u7684\u5206\u76ee\u6807\uff0c\u5e76\u7ed3\u5408\u4eba\u7c7b\u6216LLM\u8bc4\u8bba\u8005\u8fdb\u884c\u7ec6\u5316\uff1b\u8bc1\u636e\u5ba1\u8ba1\u6a21\u5757\u7ed3\u6784\u5316\u641c\u7d22\u5185\u5bb9\uff0c\u66f4\u65b0\u5927\u7eb2\uff0c\u5254\u9664\u566a\u58f0\u5e76\u901a\u8fc7\u8bc4\u8bba\u8005\u7ed1\u5b9a\u9ad8\u8d28\u91cf\u8bc1\u636e\u4ee5\u786e\u4fdd\u5185\u5bb9\u7684\u53ef\u9a8c\u8bc1\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660e\uff0cRhinoInsight\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5728\u6df1\u5ea6\u641c\u7d22\u4efb\u52a1\u4e0a\u8868\u73b0\u4e5f\u5177\u6709\u7ade\u4e89\u529b\u3002", "conclusion": "RhinoInsight\u6846\u67b6\u901a\u8fc7\u5f15\u5165\u53ef\u9a8c\u8bc1\u7684\u68c0\u67e5\u6e05\u5355\u6a21\u5757\u548c\u8bc1\u636e\u5ba1\u8ba1\u6a21\u5757\uff0c\u6709\u6548\u63d0\u5347\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u7684\u9c81\u68d2\u6027\u3001\u53ef\u8ffd\u8e2a\u6027\u548c\u6574\u4f53\u8d28\u91cf\u3002"}}
{"id": "2511.18749", "categories": ["cs.CL", "cs.CY", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.18749", "abs": "https://arxiv.org/abs/2511.18749", "authors": ["Matthew R. DeVerna", "Kai-Cheng Yang", "Harry Yaojun Yan", "Filippo Menczer"], "title": "Large Language Models Require Curated Context for Reliable Political Fact-Checking -- Even with Reasoning and Web Search", "comment": null, "summary": "Large language models (LLMs) have raised hopes for automated end-to-end fact-checking, but prior studies report mixed results. As mainstream chatbots increasingly ship with reasoning capabilities and web search tools -- and millions of users already rely on them for verification -- rigorous evaluation is urgent. We evaluate 15 recent LLMs from OpenAI, Google, Meta, and DeepSeek on more than 6,000 claims fact-checked by PolitiFact, comparing standard models with reasoning- and web-search variants. Standard models perform poorly, reasoning offers minimal benefits, and web search provides only moderate gains, despite fact-checks being available on the web. In contrast, a curated RAG system using PolitiFact summaries improved macro F1 by 233% on average across model variants. These findings suggest that giving models access to curated high-quality context is a promising path for automated fact-checking.", "AI": {"tldr": "\u7814\u7a76\u53d1\u73b0\uff0c\u7ed3\u5408\u9ad8\u8d28\u91cf\u4e0a\u4e0b\u6587\u4fe1\u606f\u7684\u68c0\u7d22\u751f\u6210\u878d\u5408\uff08RAG\uff09\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u4e8b\u5b9e\u6838\u67e5\u6027\u80fd\uff0c\u800c\u63a8\u7406\u6216\u7f51\u7edc\u641c\u7d22\u624b\u6bb5\u63d0\u5347\u6709\u9650\u3002", "motivation": "\u968f\u7740\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u81ea\u52a8\u5316\u7aef\u5230\u7aef\u4e8b\u5b9e\u6838\u67e5\u4e2d\u7684\u5e94\u7528\u5c55\u671b\u9010\u6e10\u63d0\u5347\uff0c\u7136\u800c\u6b64\u524d\u7814\u7a76\u7ed3\u679c\u4e0d\u4e00\uff0c\u4e14\u4e3b\u6d41\u804a\u5929\u673a\u5668\u4eba\u914d\u5907\u4e86\u63a8\u7406\u80fd\u529b\u548c\u7f51\u9875\u641c\u7d22\u5de5\u5177\uff0c\u7528\u6237\u4f9d\u8d56\u5b83\u4eec\u8fdb\u884c\u4e8b\u5b9e\u9a8c\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u4e25\u683c\u8bc4\u4f30\u5176\u6548\u679c\u3002", "method": "\u8bc4\u4f30\u4e86\u6765\u81eaOpenAI\u3001Google\u3001Meta\u548cDeepSeek\u768415\u4e2a\u8fd1\u671f\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5728\u8d85\u8fc76000\u6761\u7531PolitiFact\u6838\u67e5\u7684\u4e8b\u5b9e\u4e3b\u5f20\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u6807\u51c6\u6a21\u578b\u4e0e\u5e26\u63a8\u7406\u548c\u7f51\u9875\u641c\u7d22\u529f\u80fd\u7684\u53d8\u4f53\u8868\u73b0\u3002", "result": "\u6807\u51c6\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u63a8\u7406\u529f\u80fd\u4ec5\u5e26\u6765\u6781\u5c0f\u63d0\u5347\uff0c\u7f51\u9875\u641c\u7d22\u5219\u63d0\u4f9b\u9002\u5ea6\u6539\u8fdb\uff0c\u5c3d\u7ba1\u4e8b\u5b9e\u6838\u67e5\u4fe1\u606f\u5728\u7f51\u7edc\u4e0a\u53ef\u83b7\u53d6\u3002\u57fa\u4e8ePolitiFact\u6458\u8981\u7684\u7cbe\u5fc3\u7b56\u5212\u7684RAG\u7cfb\u7edf\u4f7f\u5404\u6a21\u578b\u53d8\u4f53\u7684\u5b8f\u89c2F1\u503c\u5e73\u5747\u63d0\u5347\u4e86233%\u3002", "conclusion": "\u7ed9\u4e88\u6a21\u578b\u8bbf\u95ee\u7ecf\u8fc7\u7b56\u5212\u7684\u9ad8\u8d28\u91cf\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u662f\u5b9e\u73b0\u81ea\u52a8\u5316\u4e8b\u5b9e\u6838\u67e5\u7684\u6709\u5e0c\u671b\u7684\u8def\u5f84\u3002"}}
{"id": "2511.18751", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18751", "abs": "https://arxiv.org/abs/2511.18751", "authors": ["Daiqing Wu", "Dongbao Yang", "Can Ma", "Yu Zhou"], "title": "Robust Multimodal Sentiment Analysis with Distribution-Based Feature Recovery and Fusion", "comment": "Accepted by ACM MM 2024", "summary": "As posts on social media increase rapidly, analyzing the sentiments embedded in image-text pairs has become a popular research topic in recent years. Although existing works achieve impressive accomplishments in simultaneously harnessing image and text information, they lack the considerations of possible low-quality and missing modalities. In real-world applications, these issues might frequently occur, leading to urgent needs for models capable of predicting sentiment robustly. Therefore, we propose a Distribution-based feature Recovery and Fusion (DRF) method for robust multimodal sentiment analysis of image-text pairs. Specifically, we maintain a feature queue for each modality to approximate their feature distributions, through which we can simultaneously handle low-quality and missing modalities in a unified framework. For low-quality modalities, we reduce their contributions to the fusion by quantitatively estimating modality qualities based on the distributions. For missing modalities, we build inter-modal mapping relationships supervised by samples and distributions, thereby recovering the missing modalities from available ones. In experiments, two disruption strategies that corrupt and discard some modalities in samples are adopted to mimic the low-quality and missing modalities in various real-world scenarios. Through comprehensive experiments on three publicly available image-text datasets, we demonstrate the universal improvements of DRF compared to SOTA methods under both two strategies, validating its effectiveness in robust multimodal sentiment analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86DRF\u65b9\u6cd5\uff0c\u901a\u8fc7\u57fa\u4e8e\u5206\u5e03\u7684\u7279\u5f81\u6062\u590d\u4e0e\u878d\u5408\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u4e2d\u4f4e\u8d28\u91cf\u548c\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u9c81\u68d2\u6027\u3002", "motivation": "\u793e\u4ea4\u5a92\u4f53\u4e0a\u7684\u56fe\u6587\u5185\u5bb9\u8fc5\u901f\u589e\u52a0\uff0c\u73b0\u6709\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u65b9\u6cd5\u672a\u5145\u5206\u8003\u8651\u4f4e\u8d28\u91cf\u6216\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u800c\u8fd9\u4e9b\u95ee\u9898\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u9891\u7e41\u51fa\u73b0\uff0c\u8feb\u5207\u9700\u8981\u80fd\u591f\u9c81\u68d2\u9884\u6d4b\u60c5\u611f\u7684\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5206\u5e03\u7684\u7279\u5f81\u6062\u590d\u4e0e\u878d\u5408\uff08DRF\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ef4\u62a4\u6bcf\u79cd\u6a21\u6001\u7684\u7279\u5f81\u961f\u5217\u6765\u8fd1\u4f3c\u5176\u5206\u5e03\uff0c\u5b9a\u91cf\u8bc4\u4f30\u6a21\u6001\u8d28\u91cf\u4ee5\u51cf\u5f31\u4f4e\u8d28\u91cf\u6a21\u6001\u7684\u8d21\u732e\uff0c\u5e76\u901a\u8fc7\u6837\u672c\u548c\u5206\u5e03\u76d1\u7763\u6784\u5efa\u8de8\u6a21\u6001\u6620\u5c04\u5173\u7cfb\u4ee5\u6062\u590d\u7f3a\u5931\u6a21\u6001\u3002", "result": "\u5728\u4e09\u4e2a\u4eba\u4eec\u516c\u5f00\u7684\u56fe\u6587\u6570\u636e\u96c6\u4e0a\uff0c\u901a\u8fc7\u6a21\u62df\u4f4e\u8d28\u91cf\u548c\u7f3a\u5931\u6a21\u6001\u7684\u4e24\u79cd\u5e72\u6270\u7b56\u7565\uff0cDRF\u65b9\u6cd5\u76f8\u6bd4\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u5747\u8868\u73b0\u51fa\u666e\u9002\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "DRF\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86\u56fe\u6587\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u7684\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u7edf\u4e00\u5904\u7406\u4f4e\u8d28\u91cf\u548c\u7f3a\u5931\u6a21\u6001\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u591a\u6a21\u6001\u60c5\u611f\u5206\u6790\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18774", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18774", "abs": "https://arxiv.org/abs/2511.18774", "authors": ["Bashar Talafha", "Amin Abu Alhassan", "Muhammad Abdul-Mageed"], "title": "Context-Aware Whisper for Arabic ASR Under Linguistic Varieties", "comment": null, "summary": "Low-resource ASR remains a challenging problem, especially for languages like Arabic that exhibit wide dialectal variation and limited labeled data. We propose context-aware prompting strategies to adapt OpenAI's Whisper for Arabic speech recognition without retraining. Our methods include decoder prompting with first-pass transcriptions or retrieved utterances, and encoder prefixing using speech synthesized in the target speaker's voice. We introduce techniques such as prompt reordering, speaker-aware prefix synthesis, and modality-specific retrieval (lexical, semantic, acoustic) to improve transcription in real-world, zero-shot settings. Evaluated on nine Arabic linguistic conditions, our approach reduces WER by up to 22.3% on Modern Standard Arabic and 9.2% on dialectal speech, significantly mitigating hallucinations and speaker mismatch.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u4f4e\u8d44\u6e90\u8bed\u97f3\u8bc6\u522b\u7684\u4e0a\u4e0b\u6587\u611f\u77e5\u63d0\u793a\u7b56\u7565\uff0c\u5728\u4e0d\u7528\u91cd\u65b0\u8bad\u7ec3Whisper\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u89e3\u7801\u5668\u63d0\u793a\u548c\u7f16\u7801\u5668\u524d\u7f00\u7b49\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u7387\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bed\u5b58\u5728\u65b9\u8a00\u591a\u6837\u6027\u4e14\u6807\u6ce8\u6570\u636e\u6709\u9650\uff0c\u4f4e\u8d44\u6e90\u8bed\u97f3\u8bc6\u522b\u56f0\u96be\uff0c\u4f20\u7edf\u91cd\u65b0\u8bad\u7ec3\u65b9\u6cd5\u4ee3\u4ef7\u9ad8\u4e14\u4e0d\u7075\u6d3b\uff0c\u56e0\u6b64\u7814\u7a76\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u4e0a\u4e0b\u6587\u63d0\u793a\u7b56\u7565\u6765\u63d0\u5347\u8bc6\u522b\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u89e3\u7801\u5668\u63d0\u793a\uff08\u9996\u8f6e\u8f6c\u5f55\u6216\u68c0\u7d22\u53e5\u5b50\uff09\u548c\u7f16\u7801\u5668\u524d\u7f00\uff08\u76ee\u6807\u8bf4\u8bdd\u4eba\u58f0\u97f3\u5408\u6210\u8bed\u97f3\uff09\u7ed3\u5408\u591a\u6a21\u6001\u548c\u591a\u5c42\u6b21\u7684\u63d0\u793a\u6280\u672f\uff0c\u5982\u63d0\u793a\u91cd\u6392\u3001\u8bf4\u8bdd\u4eba\u611f\u77e5\u524d\u7f00\u5408\u6210\u4ee5\u53ca\u8bcd\u6c47\u3001\u8bed\u4e49\u3001\u58f0\u5b66\u68c0\u7d22\u7b49\u3002", "result": "\u5728\u4e5d\u79cd\u963f\u62c9\u4f2f\u8bed\u73af\u5883\u4e0b\u8fdb\u884c\u96f6\u6837\u672c\u6d4b\u8bd5\uff0c\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u8bc6\u522b\u51c6\u786e\u7387\u63d0\u534722.3%\uff0c\u65b9\u8a00\u8bed\u97f3\u51c6\u786e\u7387\u63d0\u53479.2%\uff0c\u6709\u6548\u964d\u4f4e\u5e7b\u89c9\u548c\u8bf4\u8bdd\u4eba\u4e0d\u5339\u914d\u95ee\u9898\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u4e5d\u79cd\u963f\u62c9\u4f2f\u8bed\u8bed\u8a00\u73af\u5883\u4e0b\u5747\u8868\u73b0\u51fa\u663e\u8457\u6548\u679c\uff0c\u5206\u522b\u5728\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u548c\u65b9\u8a00\u8bed\u97f3\u4e0a\u5c06\u5b57\u9519\u8bef\u7387\u964d\u4f4e\u4e8622.3%\u548c9.2%\uff0c\u6709\u6548\u7f13\u89e3\u4e86\u6a21\u578b\u5e7b\u89c9\u548c\u8bf4\u8bdd\u4eba\u4e0d\u5339\u914d\u95ee\u9898\u3002"}}
{"id": "2511.18808", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18808", "abs": "https://arxiv.org/abs/2511.18808", "authors": ["Cao Linxiao", "Wang Ruitao", "Li Jindong", "Zhou Zhipeng", "Yang Menglin"], "title": "HyperbolicRAG: Enhancing Retrieval-Augmented Generation with Hyperbolic Representations", "comment": "12 pages", "summary": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to access external knowledge, helping mitigate hallucinations and enhance domain-specific expertise. Graph-based RAG enhances structural reasoning by introducing explicit relational organization that enables information propagation across semantically connected text units. However, these methods typically rely on Euclidean embeddings that capture semantic similarity but lack a geometric notion of hierarchical depth, limiting their ability to represent abstraction relationships inherent in complex knowledge graphs. To capture both fine-grained semantics and global hierarchy, we propose HyperbolicRAG, a retrieval framework that integrates hyperbolic geometry into graph-based RAG. HyperbolicRAG introduces three key designs: (1) a depth-aware representation learner that embeds nodes within a shared Poincare manifold to align semantic similarity with hierarchical containment, (2) an unsupervised contrastive regularization that enforces geometric consistency across abstraction levels, and (3) a mutual-ranking fusion mechanism that jointly exploits retrieval signals from Euclidean and hyperbolic spaces, emphasizing cross-space agreement during inference. Extensive experiments across multiple QA benchmarks demonstrate that HyperbolicRAG outperforms competitive baselines, including both standard RAG and graph-augmented baselines.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faHyperbolicRAG\uff0c\u5c06\u53cc\u66f2\u51e0\u4f55\u878d\u5165\u56fe\u7ed3\u6784\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u5b9e\u73b0\u5c42\u7ea7\u611f\u77e5\u7684\u8282\u70b9\u8868\u793a\u548c\u8de8\u7a7a\u95f4\u68c0\u7d22\u4fe1\u53f7\u878d\u5408\uff0c\u663e\u8457\u63d0\u5347\u4e86\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u56fe\u57fa\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u65b9\u6cd5\u867d\u7136\u80fd\u6355\u83b7\u8bed\u4e49\u76f8\u4f3c\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u590d\u6742\u77e5\u8bc6\u56fe\u8c31\u4e2d\u5c42\u7ea7\u62bd\u8c61\u5173\u7cfb\u7684\u51e0\u4f55\u8868\u5f81\uff0c\u9650\u5236\u4e86\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u3002\u5f15\u5165\u53cc\u66f2\u51e0\u4f55\u65e8\u5728\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u4e2a\u5173\u952e\u8bbe\u8ba1\uff1a1\uff09\u57fa\u4e8ePoincare\u6d41\u5f62\u7684\u8282\u70b9\u6df1\u5ea6\u611f\u77e5\u8868\u793a\u5b66\u4e60\uff0c\u5c06\u8bed\u4e49\u76f8\u4f3c\u6027\u4e0e\u5c42\u7ea7\u5305\u542b\u5173\u7cfb\u5bf9\u9f50\uff1b2\uff09\u65e0\u76d1\u7763\u5bf9\u6bd4\u6027\u6b63\u5219\u5316\uff0c\u4fdd\u6301\u62bd\u8c61\u5c42\u7ea7\u4e4b\u95f4\u7684\u51e0\u4f55\u4e00\u81f4\u6027\uff1b3\uff09\u4e92\u6392\u540d\u878d\u5408\u673a\u5236\uff0c\u7ed3\u5408\u6b27\u51e0\u91cc\u5f97\u548c\u53cc\u66f2\u7a7a\u95f4\u7684\u68c0\u7d22\u4fe1\u53f7\uff0c\u5f3a\u5316\u8de8\u7a7a\u95f4\u4e00\u81f4\u6027\u3002", "result": "\u5728\u591a\u4e2a\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e0a\uff0cHyperbolicRAG\u663e\u8457\u4f18\u4e8e\u5305\u62ec\u6807\u51c6RAG\u548c\u73b0\u6709\u56fe\u589e\u5f3a\u57fa\u7ebf\u7684\u591a\u79cd\u7ade\u4e89\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u4f18\u8d8a\u6027\u3002", "conclusion": "HyperbolicRAG\u901a\u8fc7\u5c06\u53cc\u66f2\u51e0\u4f55\u5f15\u5165\u56fe\u7ed3\u6784\u7684\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\uff0c\u6709\u6548\u63d0\u5347\u4e86\u6a21\u578b\u5bf9\u5c42\u7ea7\u5173\u7cfb\u53ca\u8bed\u4e49\u7ec6\u7c92\u5ea6\u7684\u6355\u6349\u80fd\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684\u6b27\u51e0\u91cc\u5f97\u5d4c\u5165\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u9886\u57df\u77e5\u8bc6\u95ee\u7b54\u8868\u73b0\u3002"}}
{"id": "2511.18832", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18832", "abs": "https://arxiv.org/abs/2511.18832", "authors": ["Kaize Shi", "Xueyao Sun", "Xiaohui Tao", "Lin Li", "Qika Lin", "Guandong Xu"], "title": "Concept than Document: Context Compression via AMR-based Conceptual Entropy", "comment": null, "summary": "Large Language Models (LLMs) face information overload when handling long contexts, particularly in Retrieval-Augmented Generation (RAG) where extensive supporting documents often introduce redundant content. This issue not only weakens reasoning accuracy but also increases computational overhead. We propose an unsupervised context compression framework that exploits Abstract Meaning Representation (AMR) graphs to preserve semantically essential information while filtering out irrelevant text. By quantifying node-level entropy within AMR graphs, our method estimates the conceptual importance of each node, enabling the retention of core semantics. Specifically, we construct AMR graphs from raw contexts, compute the conceptual entropy of each node, and screen significant informative nodes to form a condensed and semantically focused context than raw documents. Experiments on the PopQA and EntityQuestions datasets show that our method outperforms vanilla and other baselines, achieving higher accuracy while substantially reducing context length. To the best of our knowledge, this is the first work introducing AMR-based conceptual entropy for context compression, demonstrating the potential of stable linguistic features in context engineering.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u610f\u4e49\u8868\u793a\uff08AMR\uff09\u56fe\u7684\u65e0\u76d1\u7763\u4e0a\u4e0b\u6587\u538b\u7f29\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c11\u5197\u4f59\u4fe1\u606f\uff0c\u63d0\u5347\u5927\u8bed\u8a00\u6a21\u578b\u5728\u957f\u6587\u672c\u5904\u7406\u4e2d\uff0c\u5c24\u5176\u662f\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\u7684\u63a8\u7406\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u4fe1\u606f\u8fc7\u8f7d\u548c\u5197\u4f59\u5185\u5bb9\u5f71\u54cd\u63a8\u7406\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u573a\u666f\u4e2d\uff0c\u9700\u8981\u6709\u6548\u538b\u7f29\u4e0a\u4e0b\u6587\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u6784\u5efa\u4e0a\u4e0b\u6587\u7684AMR\u56fe\uff0c\u8ba1\u7b97\u6bcf\u4e2a\u8282\u70b9\u7684\u6982\u5ff5\u71b5\uff0c\u7b5b\u9009\u51fa\u91cd\u8981\u8282\u70b9\uff0c\u5f62\u6210\u66f4\u7cbe\u70bc\u4e14\u8bed\u4e49\u96c6\u4e2d\u7684\u4e0a\u4e0b\u6587\uff0c\u8fdb\u800c\u7528\u4e8e\u751f\u6210\u4efb\u52a1\u3002", "result": "\u5728PopQA\u548cEntityQuestions\u6570\u636e\u96c6\u4e0a\uff0c\u65b9\u6cd5\u53d6\u5f97\u4e86\u6bd4\u57fa\u7840\u548c\u5176\u4ed6\u5bf9\u6bd4\u65b9\u6cd5\u66f4\u9ad8\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u5c55\u793a\u4e86AMR\u57fa\u7840\u8bed\u4e49\u71b5\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "conclusion": "\u5229\u7528AMR\u56fe\u4e2d\u7684\u8282\u70b9\u7ea7\u71b5\u6765\u8bc4\u4f30\u6982\u5ff5\u91cd\u8981\u6027\uff0c\u7b5b\u9009\u6838\u5fc3\u8bed\u4e49\u8282\u70b9\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u8bed\u4e49\u805a\u7126\u7684\u4e0a\u4e0b\u6587\u538b\u7f29\uff0c\u5b9e\u9a8c\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u51c6\u786e\u6027\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u4e86\u4e0a\u4e0b\u6587\u957f\u5ea6\uff0c\u6548\u679c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002"}}
{"id": "2511.18843", "categories": ["cs.CL", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.18843", "abs": "https://arxiv.org/abs/2511.18843", "authors": ["Heger Arfaoui", "Mohammed Iheb Hergli", "Beya Benzina", "Slimane BenMiled"], "title": "A Reproducible Framework for Neural Topic Modeling in Focus Group Analysis", "comment": null, "summary": "Focus group discussions generate rich qualitative data but their analysis traditionally relies on labor-intensive manual coding that limits scalability and reproducibility. We present a rigorous, reproducible computational framework for applying neural topic modeling to focus group transcripts, addressing fundamental methodological challenges: hyperparameter sensitivity, model stability, and validation of interpretability. Using BERTopic applied to ten focus groups exploring HPV vaccine perceptions in Tunisia (1,076 utterances), we conducted systematic evaluation across 27 hyperparameter configurations, assessed stability through bootstrap resampling with 30 replicates per configuration, and validated interpretability through formal human evaluation by three domain experts. Our analysis demonstrates substantial sensitivity to hyperparameter choices and reveals that metric selection for stability assessment must align with analytical goals. A hierarchical merging strategy (extracting fine-grained topics for stability then consolidating for interpretability) effectively navigates the stability-coherence tradeoff, achieving coherence of 0.558 compared to 0.539 for direct extraction. Human validation confirmed topic quality with very good inter-rater reliability (ICC = 0.79, weighted Cohen's kappa = 0.578). Our framework provides practical guidelines that researchers can adapt to their own qualitative research contexts. All code, data processing scripts, and evaluation protocols are publicly available to support reproduction and extension of this work.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\u6587\u672c\u7684\u795e\u7ecf\u4e3b\u9898\u5efa\u6a21\u8ba1\u7b97\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u8d85\u53c2\u6570\u654f\u611f\u6027\u3001\u6a21\u578b\u7a33\u5b9a\u6027\u548c\u53ef\u89e3\u91ca\u6027\u9a8c\u8bc1\u7b49\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u548c\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1\u786e\u8ba4\u65b9\u6cd5\u6709\u6548\u3002", "motivation": "\u4f20\u7edf\u7126\u70b9\u5c0f\u7ec4\u8ba8\u8bba\u5206\u6790\u4f9d\u8d56\u4eba\u5de5\u7f16\u7801\uff0c\u8d39\u65f6\u4e14\u96be\u4ee5\u6269\u5c55\u548c\u590d\u5236\uff0c\u6025\u9700\u81ea\u52a8\u5316\u4e14\u53ef\u91cd\u590d\u7684\u65b9\u6cd5\u63d0\u5347\u5206\u6790\u6548\u7387\u4e0e\u8d28\u91cf\u3002", "method": "\u57fa\u4e8eBERTopic\u5bf9\u7a81\u5c3c\u65afHPV\u75ab\u82d7\u8ba4\u77e5\u7684\u5341\u4e2a\u7126\u70b9\u5c0f\u7ec4\uff081,076\u6761\u53d1\u8a00\uff09\u6587\u672c\u8fdb\u884c\u5206\u6790\uff0c\u7cfb\u7edf\u8bc4\u4f3027\u7ec4\u8d85\u53c2\u6570\u914d\u7f6e\uff0c\u5229\u752830\u6b21\u81ea\u52a9\u6cd5\u91cd\u91c7\u6837\u8bc4\u4f30\u6a21\u578b\u7a33\u5b9a\u6027\uff0c\u91c7\u7528\u5c42\u7ea7\u5408\u5e76\u7b56\u7565\u6539\u5584\u4e3b\u9898\u7a33\u5b9a\u6027\u4e0e\u8fde\u8d2f\u6027\uff0c\u6700\u540e\u901a\u8fc7\u4e09\u4f4d\u9886\u57df\u4e13\u5bb6\u8fdb\u884c\u4eba\u7c7b\u53ef\u89e3\u91ca\u6027\u9a8c\u8bc1\u3002", "result": "\u63ed\u793a\u4e86\u8d85\u53c2\u6570\u9009\u62e9\u5bf9\u6a21\u578b\u5f71\u54cd\u663e\u8457\uff0c\u5408\u7406\u6307\u6807\u4e0e\u5206\u6790\u76ee\u6807\u9700\u5339\u914d\uff0c\u5c42\u7ea7\u5408\u5e76\u7b56\u7565\u63d0\u5347\u4e3b\u9898\u8fde\u8d2f\u6027\uff080.558\u5bf9\u6bd40.539\uff09\uff0c\u4e13\u5bb6\u8bc4\u5ba1\u663e\u793a\u9ad8\u8bc4\u5206\u4e00\u81f4\u6027\uff08ICC=0.79\uff0cCohen's kappa=0.578\uff09\uff0c\u4ee3\u7801\u548c\u6570\u636e\u516c\u5f00\u652f\u6301\u590d\u73b0\u548c\u6269\u5c55\u3002", "conclusion": "\u8be5\u8ba1\u7b97\u6846\u67b6\u6709\u6548\u63d0\u9ad8\u4e86\u7126\u70b9\u5c0f\u7ec4\u6587\u672c\u5206\u6790\u7684\u53ef\u6269\u5c55\u6027\u548c\u91cd\u73b0\u6027\uff0c\u5b9e\u73b0\u4e86\u6a21\u578b\u7a33\u5b9a\u6027\u4e0e\u89e3\u8bfb\u4e00\u81f4\u6027\u7684\u5e73\u8861\uff0c\u4e3b\u9898\u8d28\u91cf\u7ecf\u4e13\u5bb6\u9a8c\u8bc1\u6548\u679c\u826f\u597d\u3002"}}
{"id": "2511.18848", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18848", "abs": "https://arxiv.org/abs/2511.18848", "authors": ["V\u00e1clav Tran", "Jakub \u0160m\u00edd", "Ladislav Lenc", "Jean-Pierre Salmon", "Pavel Kr\u00e1l"], "title": "Large Language Models for the Summarization of Czech Documents: From History to the Present", "comment": null, "summary": "Text summarization is the task of automatically condensing longer texts into shorter, coherent summaries while preserving the original meaning and key information. Although this task has been extensively studied in English and other high-resource languages, Czech summarization, particularly in the context of historical documents, remains underexplored. This is largely due to the inherent linguistic complexity of Czech and the lack of high-quality annotated datasets.\n  In this work, we address this gap by leveraging the capabilities of Large Language Models (LLMs), specifically Mistral and mT5, which have demonstrated strong performance across a wide range of natural language processing tasks and multilingual settings. In addition, we also propose a translation-based approach that first translates Czech texts into English, summarizes them using an English-language model, and then translates the summaries back into Czech. Our study makes the following main contributions: We demonstrate that LLMs achieve new state-of-the-art results on the SumeCzech dataset, a benchmark for modern Czech text summarization, showing the effectiveness of multilingual LLMs even for morphologically rich, medium-resource languages like Czech. We introduce a new dataset, Posel od \u010cerchova, designed for the summarization of historical Czech texts. This dataset is derived from digitized 19th-century publications and annotated for abstractive summarization. We provide initial baselines using modern LLMs to facilitate further research in this underrepresented area.\n  By combining cutting-edge models with both modern and historical Czech datasets, our work lays the foundation for further progress in Czech summarization and contributes valuable resources for future research in Czech historical document processing and low-resource summarization more broadly.", "AI": {"tldr": "\u672c\u6587\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u7ffb\u8bd1\u7b56\u7565\u6539\u8fdb\u4e86\u6377\u514b\u8bed\u6587\u672c\u6458\u8981\uff0c\u63a8\u51fa\u4e86\u65b0\u7684\u5386\u53f2\u6377\u514b\u6458\u8981\u6570\u636e\u96c6\uff0c\u63a8\u52a8\u4e86\u6377\u514b\u8bed\u4f4e\u8d44\u6e90\u53ca\u5386\u53f2\u6587\u672c\u6458\u8981\u7814\u7a76\u3002", "motivation": "\u6377\u514b\u8bed\u6587\u672c\u6458\u8981\u7814\u7a76\u8f83\u5c11\uff0c\u5c24\u5176\u662f\u5386\u53f2\u6587\u732e\u9886\u57df\uff0c\u53d7\u9650\u4e8e\u8bed\u8a00\u590d\u6742\u6027\u548c\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u7684\u7f3a\u4e4f\u3002", "method": "\u672c\u6587\u91c7\u7528\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578bMistral\u548cmT5\u8fdb\u884c\u6377\u514b\u8bed\u6587\u672c\u6458\u8981\uff0c\u540c\u65f6\u63d0\u51fa\u57fa\u4e8e\u7ffb\u8bd1\u7684\u6458\u8981\u65b9\u6cd5\uff0c\u5c06\u6377\u514b\u6587\u672c\u7ffb\u8bd1\u6210\u82f1\u6587\u540e\u8fdb\u884c\u6458\u8981\uff0c\u518d\u7ffb\u8bd1\u56de\u6377\u514b\u8bed\u3002", "result": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728SumeCzech\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u65b0\u7684\u6700\u5148\u8fdb\u8868\u73b0\uff0c\u4e14\u65b0\u5efa\u7684Posel od \u010cerchova\u5386\u53f2\u6587\u672c\u6458\u8981\u6570\u636e\u96c6\u4e3a\u8be5\u9886\u57df\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u57fa\u7ebf\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u5f15\u5165\u65b0\u7684\u5386\u53f2\u6377\u514b\u6587\u672c\u6458\u8981\u6570\u636e\u96c6\uff0c\u672c\u6587\u5728\u6377\u514b\u8bed\u6587\u672c\u6458\u8981\u9886\u57df\uff0c\u5c24\u5176\u662f\u5386\u53f2\u6587\u732e\u5904\u7406\u4e2d\u53d6\u5f97\u4e86\u65b0\u7684\u7a81\u7834\uff0c\u63a8\u52a8\u4e86\u6377\u514b\u8bed\u4f4e\u8d44\u6e90\u8bed\u8a00\u6458\u8981\u7814\u7a76\u7684\u53d1\u5c55\u3002"}}
{"id": "2511.18850", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18850", "abs": "https://arxiv.org/abs/2511.18850", "authors": ["Fengyuan Liu", "Huang Yi", "Sichun Luo", "Yuqi Wang", "Yazheng Yang", "Xinye Li", "Zefa Hu", "Junlan Feng", "Qi Liu"], "title": "Cognitive Alpha Mining via LLM-Driven Code-Based Evolution", "comment": null, "summary": "Discovering effective predictive signals, or ``alphas,'' from financial data with high dimensionality and extremely low signal-to-noise ratio remains a difficult open problem. Despite progress in deep learning, genetic programming, and, more recently, large language model (LLM)--based factor generation, existing approaches still explore only a narrow region of the vast alpha search space. Neural models tend to produce opaque and fragile patterns, while symbolic or formula-based methods often yield redundant or economically ungrounded expressions that generalize poorly. Although different in form, these paradigms share a key limitation: none can conduct broad, structured, and human-like exploration that balances logical consistency with creative leaps. To address this gap, we introduce the Cognitive Alpha Mining Framework (CogAlpha), which combines code-level alpha representation with LLM-driven reasoning and evolutionary search. Treating LLMs as adaptive cognitive agents, our framework iteratively refines, mutates, and recombines alpha candidates through multi-stage prompts and financial feedback. This synergistic design enables deeper thinking, richer structural diversity, and economically interpretable alpha discovery, while greatly expanding the effective search space. Experiments on A-share equities demonstrate that CogAlpha consistently discovers alphas with superior predictive accuracy, robustness, and generalization over existing methods. Our results highlight the promise of aligning evolutionary optimization with LLM-based reasoning for automated and explainable alpha discovery. All source code will be released.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u7ed3\u5408\u5927\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u548c\u8fdb\u5316\u641c\u7d22\u7684\u8ba4\u77e5alpha\u6316\u6398\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u91d1\u878d\u9884\u6d4b\u4fe1\u53f7\u7684\u53d1\u73b0\u6548\u679c\u4e0e\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u9ad8\u7ef4\u5ea6\u548c\u4f4e\u4fe1\u566a\u6bd4\u7684\u91d1\u878d\u6570\u636e\u4e2d\u53d1\u6398\u6709\u6548\u9884\u6d4b\u4fe1\u53f7\u5b58\u5728\u5c40\u9650\uff0c\u6a21\u578b\u4e0d\u900f\u660e\u4e14\u6cdb\u5316\u5dee\uff0c\u7f3a\u4e4f\u5e7f\u6cdb\u4e14\u7ed3\u6784\u5316\u7684\u4eba\u7c7b\u5f0f\u63a2\u7d22\u3002", "method": "\u7ed3\u5408\u4ee3\u7801\u7ea7alpha\u8868\u793a\u3001\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u63a8\u7406\u548c\u8fdb\u5316\u641c\u7d22\uff0c\u5f62\u6210\u8ba4\u77e5alpha\u6316\u6398\u6846\u67b6CogAlpha\u3002\u901a\u8fc7\u591a\u9636\u6bb5\u63d0\u793a\u548c\u91d1\u878d\u53cd\u9988\uff0c\u8fed\u4ee3\u7ec6\u5316\u3001\u53d8\u5f02\u548c\u91cd\u7ec4alpha\u5019\u9009\u3002", "result": "CogAlpha\u5728A\u80a1\u5b9e\u9a8c\u4e2d\u53d1\u73b0\u7684alpha\u5728\u9884\u6d4b\u51c6\u786e\u7387\u3001\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u6df1\u5165\u601d\u8003\u548c\u7ecf\u6d4e\u53ef\u89e3\u91ca\u7684alpha\u53d1\u73b0\u3002", "conclusion": "\u5c06\u8fdb\u5316\u4f18\u5316\u4e0eLLM\u63a8\u7406\u7ed3\u5408\uff0c\u589e\u5f3a\u4e86alpha\u641c\u7d22\u7a7a\u95f4\u548c\u8d28\u91cf\uff0c\u52a9\u529b\u81ea\u52a8\u5316\u4e14\u53ef\u89e3\u91ca\u7684alpha\u53d1\u73b0\uff0c\u4ee3\u7801\u5c06\u5f00\u6e90\u3002"}}
{"id": "2511.18852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18852", "abs": "https://arxiv.org/abs/2511.18852", "authors": ["Masoomali Fatehkia", "Enes Altinisik", "Husrev Taha Sencar"], "title": "FanarGuard: A Culturally-Aware Moderation Filter for Arabic Language Models", "comment": null, "summary": "Content moderation filters are a critical safeguard against alignment failures in language models. Yet most existing filters focus narrowly on general safety and overlook cultural context. In this work, we introduce FanarGuard, a bilingual moderation filter that evaluates both safety and cultural alignment in Arabic and English. We construct a dataset of over 468K prompt and response pairs, drawn from synthetic and public datasets, scored by a panel of LLM judges on harmlessness and cultural awareness, and use it to train two filter variants. To rigorously evaluate cultural alignment, we further develop the first benchmark targeting Arabic cultural contexts, comprising over 1k norm-sensitive prompts with LLM-generated responses annotated by human raters. Results show that FanarGuard achieves stronger agreement with human annotations than inter-annotator reliability, while matching the performance of state-of-the-art filters on safety benchmarks. These findings highlight the importance of integrating cultural awareness into moderation and establish FanarGuard as a practical step toward more context-sensitive safeguards.", "AI": {"tldr": "FanarGuard\u662f\u4e00\u79cd\u8003\u8651\u6587\u5316\u80cc\u666f\u7684\u53cc\u8bed\u5185\u5bb9\u5ba1\u6838\u8fc7\u6ee4\u5668\uff0c\u5728\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u5b89\u5168\u4e0e\u6587\u5316\u5bf9\u9f50\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u5185\u5bb9\u5ba1\u6838\u8fc7\u6ee4\u5668\u5927\u591a\u5ffd\u7565\u6587\u5316\u80cc\u666f\uff0c\u5bb9\u6613\u5bfc\u81f4\u5728\u591a\u5143\u6587\u5316\u73af\u5883\u4e0b\u7684\u8bef\u5224\uff0c\u8feb\u5207\u9700\u8981\u5f00\u53d1\u80fd\u517c\u987e\u5b89\u5168\u6027\u548c\u6587\u5316\u80cc\u666f\u7684\u591a\u8bed\u8a00\u8fc7\u6ee4\u5668\uff0c\u63d0\u5347\u5185\u5bb9\u5ba1\u6838\u7684\u51c6\u786e\u6027\u4e0e\u9002\u7528\u6027\u3002", "method": "\u901a\u8fc7\u6536\u96c6468K+\u5bf9\u7ecfLLM\u8bc4\u5ba1\u6807\u6ce8\u65e0\u5bb3\u6027\u548c\u6587\u5316\u610f\u8bc6\u7684\u6570\u636e\uff0c\u8bad\u7ec3\u53cc\u8bed\u5ba1\u6838\u6a21\u578b\uff0c\u5e76\u6784\u5efa\u963f\u62c9\u4f2f\u6587\u5316\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u7684\u6587\u5316\u5bf9\u9f50\u80fd\u529b\u548c\u5b89\u5168\u6027\u80fd\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86FanarGuard\uff0c\u4e00\u79cd\u9488\u5bf9\u963f\u62c9\u4f2f\u8bed\u548c\u82f1\u8bed\u7684\u53cc\u8bed\u5185\u5bb9\u5ba1\u6838\u8fc7\u6ee4\u5668\uff0c\u80fd\u591f\u8bc4\u4f30\u5b89\u5168\u6027\u548c\u6587\u5316\u4e00\u81f4\u6027\u3002\u6784\u5efa\u4e86468K+\u5bf9\u5e26\u6709\u65e0\u5bb3\u6027\u548c\u6587\u5316\u610f\u8bc6\u8bc4\u5206\u7684\u63d0\u793a-\u54cd\u5e94\u6570\u636e\u96c6\uff0c\u5e76\u8bad\u7ec3\u4e86\u4e24\u4e2a\u8fc7\u6ee4\u5668\u53d8\u4f53\u3002\u901a\u8fc7\u5f00\u53d1\u9996\u4e2a\u9762\u5411\u963f\u62c9\u4f2f\u6587\u5316\u8bed\u5883\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u9a8c\u8bc1\u4e86FanarGuard\u5728\u6587\u5316\u5bf9\u9f50\u4e0a\u7684\u4f18\u8d8a\u8868\u73b0\u3002\u8bc4\u6d4b\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u8fc7\u6ee4\u5668\u4e0e\u4eba\u5de5\u6807\u6ce8\u7684\u7b26\u5408\u5ea6\u8d85\u8fc7\u6807\u6ce8\u8005\u4e4b\u95f4\u7684\u53ef\u9760\u6027\uff0c\u540c\u65f6\u5728\u5b89\u5168\u6027\u6d4b\u8bd5\u4e0a\u8fbe\u5230\u6700\u65b0\u6280\u672f\u6c34\u5e73\u3002\u6b64\u7814\u7a76\u5f3a\u8c03\u4e86\u6587\u5316\u610f\u8bc6\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u4e3a\u5b9e\u73b0\u66f4\u5177\u4e0a\u4e0b\u6587\u654f\u611f\u6027\u7684\u5ba1\u6838\u673a\u5236\u63d0\u4f9b\u4e86\u5b9e\u7528\u65b9\u6848\u3002", "conclusion": "\u5c06\u6587\u5316\u610f\u8bc6\u878d\u5165\u5185\u5bb9\u5ba1\u6838\u663e\u8457\u63d0\u5347\u4e86\u8fc7\u6ee4\u5668\u7684\u51c6\u786e\u5ea6\u548c\u53ef\u9760\u6027\uff0cFanarGuard\u4e3a\u5f00\u53d1\u66f4\u5177\u6587\u5316\u654f\u611f\u6027\u7684\u5185\u5bb9\u5ba1\u6838\u5de5\u5177\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\u3002"}}
{"id": "2511.18860", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18860", "abs": "https://arxiv.org/abs/2511.18860", "authors": ["Xingyu Huang", "Fei Jiang", "Jianli Xiao"], "title": "Generating Reading Comprehension Exercises with Large Language Models for Educational Applications", "comment": null, "summary": "With the rapid development of large language models (LLMs), the applications of LLMs have grown substantially. In the education domain, LLMs demonstrate significant potential, particularly in automatic text generation, which enables the creation of intelligent and adaptive learning content. This paper proposes a new LLMs framework, which is named as Reading Comprehension Exercise Generation (RCEG). It can generate high-quality and personalized English reading comprehension exercises automatically. Firstly, RCEG uses fine-tuned LLMs to generate content candidates. Then, it uses a discriminator to select the best candidate. Finally, the quality of the generated content has been improved greatly. To evaluate the performance of RCEG, a dedicated dataset for English reading comprehension is constructed to perform the experiments, and comprehensive evaluation metrics are used to analyze the experimental results. These metrics include content diversity, factual accuracy, linguistic toxicity, and pedagogical alignment. Experimental results show that RCEG significantly improves the relevance and cognitive appropriateness of the generated exercises.", "AI": {"tldr": "\u63d0\u51fa\u4e86RCEG\u6846\u67b6\uff0c\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u4e2a\u6027\u5316\u82f1\u8bed\u9605\u8bfb\u7406\u89e3\u7ec3\u4e60\u9898\uff0c\u663e\u8457\u63d0\u5347\u5185\u5bb9\u8d28\u91cf\u548c\u6559\u5b66\u9002\u5e94\u6027\u3002", "motivation": "\u968f\u7740\u5927\u8bed\u8a00\u6a21\u578b\u5feb\u901f\u53d1\u5c55\uff0c\u6559\u80b2\u9886\u57df\u5bf9\u667a\u80fd\u4e14\u4e2a\u6027\u5316\u7684\u9605\u8bfb\u7406\u89e3\u7ec3\u4e60\u9700\u6c42\u589e\u52a0\uff0c\u4fc3\u8fdb\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u5b66\u4e60\u5185\u5bb9\u6210\u4e3a\u7814\u7a76\u52a8\u673a\u3002", "method": "\u91c7\u7528\u5fae\u8c03\u7684\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u5185\u5bb9\u5019\u9009\uff0c\u901a\u8fc7\u5224\u522b\u5668\u7b5b\u9009\u6700\u4f73\u9879\u4ee5\u63d0\u9ad8\u5185\u5bb9\u8d28\u91cf\uff0c\u5e76\u6784\u5efa\u4e13\u9879\u6570\u636e\u96c6\u4e0e\u591a\u7ef4\u8bc4\u4ef7\u6307\u6807\u8fdb\u884c\u8bc4\u6d4b\u3002", "result": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aRCEG\uff08Reading Comprehension Exercise Generation\uff09\u7684\u65b0\u578b\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff0c\u80fd\u591f\u81ea\u52a8\u751f\u6210\u9ad8\u8d28\u91cf\u4e14\u4e2a\u6027\u5316\u7684\u82f1\u8bed\u9605\u8bfb\u7406\u89e3\u7ec3\u4e60\u9898\u3002\u901a\u8fc7\u5fae\u8c03LLMs\u751f\u6210\u5185\u5bb9\u5019\u9009\u9879\uff0c\u5229\u7528\u5224\u522b\u5668\u7b5b\u9009\u6700\u4f73\u5185\u5bb9\uff0c\u663e\u8457\u63d0\u5347\u751f\u6210\u5185\u5bb9\u7684\u8d28\u91cf\u3002\u6784\u5efa\u4e86\u4e13\u95e8\u7684\u82f1\u8bed\u9605\u8bfb\u7406\u89e3\u6570\u636e\u96c6\uff0c\u91c7\u7528\u5185\u5bb9\u591a\u6837\u6027\u3001\u4e8b\u5b9e\u51c6\u786e\u6027\u3001\u8bed\u8a00\u6bd2\u6027\u548c\u6559\u5b66\u5bf9\u9f50\u5ea6\u7b49\u591a\u7ef4\u8bc4\u4ef7\u6307\u6807\u8fdb\u884c\u6027\u80fd\u6d4b\u8bd5\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eRCEG\u5728\u751f\u6210\u7684\u7ec3\u4e60\u9898\u7684\u76f8\u5173\u6027\u548c\u8ba4\u77e5\u9002\u5f53\u6027\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "RCEG\u6846\u67b6\u901a\u8fc7\u5fae\u8c03\u548c\u5224\u522b\u5668\u8054\u5408\u65b9\u6cd5\uff0c\u80fd\u591f\u751f\u6210\u76f8\u5173\u6027\u5f3a\u4e14\u8ba4\u77e5\u6070\u5f53\u7684\u82f1\u8bed\u9605\u8bfb\u7406\u89e3\u7ec3\u4e60\u9898\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u6709\u6548\u6027\u3002"}}
{"id": "2511.18864", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18864", "abs": "https://arxiv.org/abs/2511.18864", "authors": ["Yang Xiang", "Yixin Ji", "Juntao Li", "Min Zhang"], "title": "Think Before You Prune: Selective Self-Generated Calibration for Pruning Large Reasoning Models", "comment": "Under Review", "summary": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning benchmarks. However, their long chain-of-thought reasoning processes incur significant inference overhead. Pruning has emerged as a promising approach to reducing computational costs. However, existing efforts have primarily focused on large language models (LLMs), while pruning LRMs remains unexplored. In this work, we conduct the first empirical study on pruning LRMs and show that directly applying existing pruning techniques fails to yield satisfactory results. Our findings indicate that using self-generated reasoning data for calibration can substantially improve pruning performance. We further investigate how the difficulty and length of reasoning data affect pruning outcomes. Our analysis reveals that challenging and moderately long self-generated reasoning data serve as ideal calibration data. Based on these insights, we propose a Selective Self-Generated Reasoning (SSGR) data construction strategy to provide effective calibration data for pruning LRMs. Experimental results on the DeepSeek-R1-Distill model series validate that our strategy improves the reasoning ability of pruned LRMs by 10%-13% compared to general pruning methods.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5b9e\u8bc1\u7814\u7a76\u4e86\u5927\u578b\u63a8\u7406\u6a21\u578b\u7684\u526a\u679d\u95ee\u9898\uff0c\u63d0\u51fa\u57fa\u4e8e\u9009\u62e9\u6027\u81ea\u751f\u6210\u63a8\u7406\u6570\u636e\u7684\u6821\u51c6\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u526a\u679d\u540e\u6a21\u578b\u7684\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5177\u6709\u51fa\u8272\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u957f\u94fe\u601d\u8003\u8fc7\u7a0b\u5e26\u6765\u9ad8\u8ba1\u7b97\u5f00\u9500\uff0c\u73b0\u6709\u526a\u679d\u6280\u672f\u4e3b\u8981\u9488\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0cLRMs\u526a\u679d\u5c1a\u672a\u6df1\u5165\u7814\u7a76\u3002", "method": "\u5229\u7528\u81ea\u751f\u6210\u7684\u63a8\u7406\u6570\u636e\u8fdb\u884c\u6821\u51c6\uff0c\u4ece\u800c\u63d0\u5347\u526a\u679d\u6548\u679c\uff1b\u63d0\u51fa\u4e86\u9009\u62e9\u6027\u81ea\u751f\u6210\u63a8\u7406\uff08SSGR\uff09\u6570\u636e\u6784\u5efa\u7b56\u7565\uff0c\u7b5b\u9009\u5408\u9002\u7684\u63a8\u7406\u6570\u636e\u7528\u4e8e\u6821\u51c6\u3002", "result": "\u91c7\u7528SSGR\u7b56\u7565\u540e\uff0c\u526a\u679d\u540e\u7684LRMs\u5728DeepSeek-R1-Distill\u6a21\u578b\u7cfb\u5217\u7684\u63a8\u7406\u80fd\u529b\u63d0\u5347\u4e8610%-13%\u3002", "conclusion": "\u901a\u8fc7\u8bbe\u8ba1\u6709\u6548\u7684\u81ea\u751f\u6210\u63a8\u7406\u6570\u636e\u8fdb\u884c\u6821\u51c6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347LRMs\u7684\u526a\u679d\u6548\u679c\uff0c\u514b\u670d\u4e86\u4f20\u7edf\u526a\u679d\u65b9\u6cd5\u7684\u5c40\u9650\u3002"}}
{"id": "2511.18889", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18889", "abs": "https://arxiv.org/abs/2511.18889", "authors": ["Jingqian Zhao", "Bingbing Wang", "Geng Tu", "Yice Zhang", "Qianlong Wang", "Bin Liang", "Jing Li", "Ruifeng Xu"], "title": "CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation", "comment": "ACL'25", "summary": "Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \\textbf{CoreEval}, a \\textbf{Co}ntamination-\\textbf{re}silient \\textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faCoreEval\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u6700\u65b0\u77e5\u8bc6\u5e93\u81ea\u52a8\u66f4\u65b0\u6570\u636e\uff0c\u89e3\u51b3\u4e86\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u4e2d\u56e0\u6570\u636e\u6c61\u67d3\u5bfc\u81f4\u7684\u6027\u80fd\u9ad8\u4f30\u95ee\u9898\u3002", "motivation": "\u6570\u636e\u6c61\u67d3\u5bfc\u81f4\u8bed\u8a00\u6a21\u578b\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u7684\u8bc4\u4f30\u4e0d\u516c\u5e73\uff0c\u56e0\u4e3a\u6a21\u578b\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u63a5\u89e6\u5230\u6d4b\u8bd5\u6570\u636e\uff0c\u5bfc\u81f4\u6027\u80fd\u88ab\u9ad8\u4f30\u3002", "method": "\u4ece\u539f\u59cb\u6570\u636e\u4e2d\u63d0\u53d6\u5b9e\u4f53\u5173\u7cfb\uff0c\u5229\u7528GDELT\u6570\u636e\u5e93\u83b7\u53d6\u6700\u65b0\u77e5\u8bc6\uff0c\u91cd\u65b0\u6784\u5efa\u5e76\u6574\u5408\u6570\u636e\uff0c\u901a\u8fc7\u53cd\u590d\u7684\u6570\u636e\u53cd\u5c04\u673a\u5236\u9a8c\u8bc1\u548c\u7ec6\u5316\u6807\u7b7e\uff0c\u4fdd\u8bc1\u6570\u636e\u8bed\u4e49\u4e00\u81f4\u548c\u4efb\u52a1\u76f8\u5173\u3002", "result": "\u63d0\u51fa\u4e86CoreEval\uff0c\u4e00\u79cd\u81ea\u52a8\u66f4\u65b0\u6570\u636e\u7684\u6c61\u67d3\u9c81\u68d2\u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u539f\u59cb\u6570\u636e\u63d0\u53d6\u5b9e\u4f53\u5173\u7cfb\u5e76\u5229\u7528\u6700\u65b0\u77e5\u8bc6\u5e93\uff08GDELT\uff09\u66f4\u65b0\u6570\u636e\uff0c\u786e\u4fdd\u6570\u636e\u7684\u8bed\u4e49\u4e00\u81f4\u6027\u548c\u4efb\u52a1\u76f8\u5173\u6027\uff0c\u5e76\u901a\u8fc7\u53cd\u590d\u9a8c\u8bc1\u6807\u7b7e\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u3002\u5b9e\u9a8c\u8bc1\u660eCoreEval\u6709\u6548\u7f13\u89e3\u4e86\u6570\u636e\u6c61\u67d3\u5bfc\u81f4\u7684\u6027\u80fd\u9ad8\u4f30\u95ee\u9898\u3002", "conclusion": "CoreEval\u80fd\u591f\u6709\u6548\u62b5\u5fa1\u6570\u636e\u6c61\u67d3\uff0c\u786e\u4fdd\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7684\u516c\u5e73\u6027\u548c\u51c6\u786e\u6027\uff0c\u5177\u6709\u8f83\u5f3a\u7684\u5b9e\u7528\u4ef7\u503c\u548c\u63a8\u5e7f\u6f5c\u529b\u3002"}}
{"id": "2511.18891", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18891", "abs": "https://arxiv.org/abs/2511.18891", "authors": ["Adam Rychert", "Gasper Spagnolo", "Evgenii Posashkov"], "title": "Reproducibility Study of Large Language Model Bayesian Optimization", "comment": "7 pages, 8 figures. Reproducibility study of the LLAMBO framework (ICLR 2024). Code: https://github.com/spagnoloG/llambo-reproducibility", "summary": "In this reproducibility study, we revisit the LLAMBO framework of Daxberger et al. (2024), a prompting-based Bayesian optimization (BO) method that uses large language models as discriminative surrogates and acquisition optimizers via text-only interactions. We replicate the core Bayesmark and HPOBench experiments under the original evaluation protocol, but replace GPT-3.5 with the open-weight Llama 3.1 70B model used for all text encoding components.\n  Our results broadly confirm the main claims of LLAMBO. Contextual warm starting via textual problem and hyperparameter descriptions substantially improves early regret behaviour and reduces variance across runs. LLAMBO's discriminative surrogate is weaker than GP or SMAC as a pure single task regressor, yet benefits from cross task semantic priors induced by the language model. Ablations that remove textual context markedly degrade predictive accuracy and calibration, while the LLAMBO candidate sampler consistently generates higher quality and more diverse proposals than TPE or random sampling. Experiments with smaller backbones (Gemma 27B, Llama 3.1 8B) yield unstable or invalid predictions, suggesting insufficient capacity for reliable surrogate behaviour.\n  Overall, our study shows that the LLAMBO architecture is robust to changing the language model backbone and remains effective when instantiated with Llama 3.1 70B.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u5b9eLLAMBO\u6846\u67b6\u5728\u4f7f\u7528Llama 3.1 70B\u65f6\u4f9d\u7136\u6709\u6548\uff0c\u6587\u672c\u4e0a\u4e0b\u6587\u4fe1\u606f\u548c\u5927\u578b\u6a21\u578b\u5bb9\u91cf\u662f\u5173\u952e\u56e0\u7d20\u3002", "motivation": "\u9a8c\u8bc1\u5e76\u590d\u73b0LLAMBO\u6846\u67b6\u7684\u6548\u679c\uff0c\u63a2\u7d22\u4f7f\u7528\u5f00\u6e90\u5927\u578b\u8bed\u8a00\u6a21\u578bLlama 3.1 70B\u66ff\u4ee3GPT-3.5\u7684\u53ef\u884c\u6027\u3002", "method": "\u590d\u73b0\u4e86\u6838\u5fc3\u5b9e\u9a8c\uff0c\u4f7f\u7528Llama 3.1 70B\u4ee3\u66ffGPT-3.5\u8fdb\u884c\u6587\u672c\u7f16\u7801\uff0c\u5206\u6790\u6a21\u578b\u6027\u80fd\u3001\u6d88\u878d\u6587\u672c\u4e0a\u4e0b\u6587\u5f71\u54cd\u3001\u6bd4\u8f83\u91c7\u6837\u5668\u6548\u679c\uff0c\u5e76\u6d4b\u8bd5\u8f83\u5c0f\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u786e\u8ba4\u4e86LLAMBO\u7684\u4e3b\u8981\u7ed3\u8bba\uff1a\u6587\u672c\u4e0a\u4e0b\u6587\u8d77\u59cb\u663e\u8457\u6539\u5584\u65e9\u671f\u8868\u73b0\u548c\u7a33\u5b9a\u6027\uff0cLLAMBO\u7684\u5224\u522b\u4ee3\u7406\u867d\u5f31\u4e8eGP\u6216SMAC\uff0c\u4f46\u901a\u8fc7\u8de8\u4efb\u52a1\u8bed\u4e49\u5148\u9a8c\u83b7\u5f97\u4f18\u52bf\uff0c\u6587\u5b57\u4e0a\u4e0b\u6587\u7f3a\u5931\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\uff0cLLAMBO\u7684\u91c7\u6837\u5668\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u8f83\u5c0f\u6a21\u578b\u4e0d\u7a33\u5b9a\u3002", "conclusion": "LLAMBO\u67b6\u6784\u5bf9\u8bed\u8a00\u6a21\u578b\u9aa8\u5e72\u66f4\u6362\u5177\u6709\u9c81\u68d2\u6027\uff0cLlama 3.1 70B\u662f\u53ef\u9760\u7684\u66ff\u4ee3\uff0c\u6587\u672c\u4e0a\u4e0b\u6587\u5bf9\u6027\u80fd\u63d0\u5347\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2511.18931", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.18931", "abs": "https://arxiv.org/abs/2511.18931", "authors": ["Sahil Kale"], "title": "Look It Up: Analysing Internal Web Search Capabilities of Modern LLMs", "comment": "10 pages, 8 figures", "summary": "Modern large language models integrate web search to provide real-time answers, yet it remains unclear whether they are efficiently calibrated to use search when it is actually needed. We introduce a benchmark evaluating both the necessity and effectiveness of web access across commercial models with no access to internal states or parameters. The dataset includes a static split of 783 temporally anchored questions answerable from pre-cutoff knowledge, aimed at testing whether models invoke search based on low internal confidence, and a dynamic split of 288 post-cutoff queries designed to test whether models recognise when search is required and retrieve updated information. Web access substantially improves static accuracy for GPT-5-mini and Claude Haiku 4.5, though confidence calibration worsens. On dynamic queries, both models frequently invoke search yet remain below 70 percent accuracy due to weak query formulation. Costs per accuracy-improving call remain low, but returns diminish once initial retrieval fails. Selective invocation helps, but models become overconfident and inconsistent after search. Overall, built-in web search meaningfully improves factual accuracy and can be invoked selectively, yet models remain overconfident, skip retrieval when it is essential, and falter once initial search queries underperform. Taken together, internal web search works better as a good low-latency verification layer than a reliable analytical tool, with clear room for improvement.", "AI": {"tldr": "\u96c6\u6210\u7f51\u7edc\u641c\u7d22\u63d0\u5347\u4e86\u6a21\u578b\u7684\u4e8b\u5b9e\u51c6\u786e\u5ea6\uff0c\u4f46\u4ecd\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u3001\u6f0f\u68c0\u5fc5\u9700\u641c\u7d22\u53ca\u521d\u59cb\u67e5\u8be2\u6548\u7387\u4f4e\u4e0b\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u96c6\u6210\u4e86\u7f51\u7edc\u641c\u7d22\u4ee5\u63d0\u4f9b\u5b9e\u65f6\u7b54\u6848\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u9700\u8981\u65f6\u662f\u5426\u80fd\u9ad8\u6548\u8c03\u7528\u641c\u7d22\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u8bbe\u8ba1\u57fa\u4e8e\u65f6\u95f4\u951a\u5b9a\u7684\u9759\u6001\u4e0e\u52a8\u6001\u95ee\u9898\u96c6\uff0c\u8bc4\u4f30\u5546\u4e1a\u6a21\u578b\u5728\u65e0\u8bbf\u95ee\u5185\u90e8\u72b6\u6001\u4e0b\u7684\u641c\u7d22\u4f7f\u7528\u5fc5\u8981\u6027\u53ca\u6709\u6548\u6027\u3002", "result": "\u5185\u7f6e\u7f51\u7edc\u641c\u7d22\u663e\u8457\u63d0\u5347\u4e86\u51c6\u786e\u7387\uff0c\u4f46\u6a21\u578b\u5728\u7f6e\u4fe1\u5ea6\u6821\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u4e14\u5728\u67e5\u8be2\u65f6\u8fc7\u4e8e\u81ea\u4fe1\u4e14\u67e5\u8be2\u5931\u8d25\u540e\u8868\u73b0\u4e0b\u964d\u3002", "conclusion": "\u7f51\u7edc\u641c\u7d22\u4f5c\u4e3a\u4f4e\u5ef6\u8fdf\u9a8c\u8bc1\u5c42\u6548\u679c\u8f83\u597d\uff0c\u4f46\u4f5c\u4e3a\u53ef\u9760\u5206\u6790\u5de5\u5177\u5c1a\u9700\u6539\u8fdb\u3002"}}
{"id": "2511.18934", "categories": ["cs.CL", "cs.AI", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.18934", "abs": "https://arxiv.org/abs/2511.18934", "authors": ["Yuchen Ji", "Bo Xu", "Jie Shi", "Jiaqing Liang", "Deqing Yang", "Yu Mao", "Hai Chen", "Yanghua Xiao"], "title": "Skeletons Matter: Dynamic Data Augmentation for Text-to-Query", "comment": "Accepted at EMNLP 2025", "summary": "The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.", "AI": {"tldr": "\u63d0\u51fa\u7edf\u4e00\u7684Text-to-Query\u4efb\u52a1\u8303\u5f0f\u548c\u57fa\u4e8e\u67e5\u8be2\u9aa8\u67b6\u7684\u52a8\u6001\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u6709\u6548\u63d0\u5347\u8de8\u67e5\u8be2\u8bed\u8a00\u8bed\u4e49\u89e3\u6790\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u805a\u7126\u5355\u4e00\u67e5\u8be2\u8bed\u8a00\uff0c\u5bfc\u81f4\u65b9\u6cd5\u6cdb\u5316\u80fd\u529b\u6709\u9650\uff0c\u7f3a\u4e4f\u8de8\u8bed\u8a00\u901a\u7528\u6027\u3002", "method": "\u5b9a\u4e49\u4e86Text-to-Query\u4efb\u52a1\u8303\u5f0f\uff0c\u7edf\u4e00\u4e86\u4e0d\u540c\u67e5\u8be2\u8bed\u8a00\u7684\u8bed\u4e49\u89e3\u6790\u4efb\u52a1\uff1b\u63d0\u51fa\u4e86\u4ee5\u67e5\u8be2\u9aa8\u67b6\u4e3a\u5171\u901a\u4f18\u5316\u76ee\u6807\u7684\u52a8\u6001\u6570\u636e\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u9488\u5bf9\u6a21\u578b\u5f31\u70b9\u5408\u6210\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728\u56db\u4e2aText-to-Query\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7528\u5c11\u91cf\u5408\u6210\u6570\u636e\u5b9e\u73b0\u4e86\u6700\u65b0\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u65b9\u6cd5\u7684\u9ad8\u6548\u6027\u548c\u901a\u7528\u6027\u3002", "conclusion": "\u65b9\u6cd5\u901a\u8fc7\u8bca\u65ad\u6a21\u578b\u9aa8\u67b6\u5904\u7406\u5f31\u70b9\uff0c\u5408\u6210\u9488\u5bf9\u6027\u8bad\u7ec3\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u4e0d\u540c\u67e5\u8be2\u8bed\u8a00\u95f4\u7684\u826f\u597d\u6cdb\u5316\u548c\u9ad8\u6027\u80fd\u8868\u73b0\uff0c\u4e3a\u7edf\u4e00\u7814\u7a76Text-to-Query\u4efb\u52a1\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2511.18937", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.18937", "abs": "https://arxiv.org/abs/2511.18937", "authors": ["Francois Vandenhende", "Anna Georgiou", "Michalis Georgiou", "Theodoros Psaras", "Ellie Karekla", "Elena Hadjicosta"], "title": "Knowledge-based Graphical Method for Safety Signal Detection in Clinical Trials", "comment": "13 pages, 3 tables, 5 figures", "summary": "We present a graphical, knowledge-based method for reviewing treatment-emergent adverse events (AEs) in clinical trials. The approach enhances MedDRA by adding a hidden medical knowledge layer (Safeterm) that captures semantic relationships between terms in a 2-D map. Using this layer, AE Preferred Terms can be regrouped automatically into similarity clusters, and their association to the trial disease may be quantified. The Safeterm map is available online and connected to aggregated AE incidence tables from ClinicalTrials.gov. For signal detection, we compute treatment-specific disproportionality metrics using shrinkage incidence ratios. Cluster-level EBGM values are then derived through precision-weighted aggregation. Two visual outputs support interpretation: a semantic map showing AE incidence and an expectedness-versus-disproportionality plot for rapid signal detection. Applied to three legacy trials, the automated method clearly recovers all expected safety signals. Overall, augmenting MedDRA with a medical knowledge layer improves clarity, efficiency, and accuracy in AE interpretation for clinical trials.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u77e5\u8bc6\u7684\u56fe\u5f62\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728MedDRA\u4e0a\u589e\u52a0\u9690\u85cf\u7684\u533b\u5b66\u77e5\u8bc6\u5c42\uff08Safeterm\uff09\uff0c\u5b9e\u73b0\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u4e0d\u826f\u4e8b\u4ef6\u7684\u81ea\u52a8\u805a\u7c7b\u548c\u5173\u8054\u5206\u6790\uff0c\u63d0\u9ad8\u4e86\u4fe1\u53f7\u68c0\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709MedDRA\u5206\u7ec4\u548c\u4e0d\u826f\u4e8b\u4ef6\u5206\u6790\u6548\u7387\u4f4e\u4e14\u51c6\u786e\u6027\u6709\u9650\uff0c\u8feb\u5207\u9700\u8981\u878d\u5408\u533b\u5b66\u77e5\u8bc6\u5c42\u4ee5\u63d0\u5347\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u4e0d\u826f\u4e8b\u4ef6\u7684\u5ba1\u67e5\u6548\u7387\u4e0e\u89e3\u8bfb\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u6dfb\u52a0\u9690\u85cf\u7684\u533b\u5b66\u77e5\u8bc6\u5c42Safeterm\uff0c\u6784\u5efa\u5305\u542b\u8bed\u4e49\u5173\u7cfb\u7684\u4e8c\u7ef4\u56fe\u8c31\uff0c\u5b9e\u73b0\u4e0d\u826f\u4e8b\u4ef6\u9996\u9009\u672f\u8bed\u7684\u81ea\u52a8\u805a\u7c7b\uff0c\u5e76\u8ba1\u7b97\u6cbb\u7597\u7279\u5f02\u6027\u7684\u5931\u6bd4\u4f8b\u6307\u6807\uff0c\u5229\u7528\u7cbe\u5ea6\u52a0\u6743\u805a\u5408\u5f97\u5230\u7c07\u7ea7EBGM\u503c\uff0c\u914d\u5408\u8bed\u4e49\u56fe\u548c\u671f\u671b\u6027\u4e0e\u5931\u6bd4\u4f8b\u56fe\u8fdb\u884c\u4fe1\u53f7\u68c0\u6d4b\u3002", "result": "\u5728\u4e09\u4e2a\u5386\u53f2\u4e34\u5e8a\u8bd5\u9a8c\u6848\u4f8b\u4e2d\uff0c\u81ea\u52a8\u5316\u65b9\u6cd5\u6210\u529f\u8bc6\u522b\u51fa\u6240\u6709\u9884\u671f\u7684\u5b89\u5168\u4fe1\u53f7\uff0c\u8bc1\u660e\u8be5\u77e5\u8bc6\u589e\u5f3a\u6a21\u578b\u80fd\u6709\u6548\u6539\u8fdb\u4fe1\u53f7\u68c0\u6d4b\u6d41\u7a0b\u548c\u7ed3\u679c\u3002", "conclusion": "\u5728\u4e09\u9879\u4e34\u5e8a\u8bd5\u9a8c\u4e2d\u9a8c\u8bc1\uff0c\u8be5\u65b9\u6cd5\u51c6\u786e\u6062\u590d\u4e86\u6240\u6709\u9884\u671f\u7684\u5b89\u5168\u4fe1\u53f7\uff0c\u8868\u660e\u901a\u8fc7\u5728MedDRA\u4e2d\u52a0\u5165\u533b\u5b66\u77e5\u8bc6\u5c42\uff0c\u80fd\u663e\u8457\u63d0\u5347\u4e0d\u826f\u4e8b\u4ef6\u89e3\u8bfb\u7684\u6e05\u6670\u5ea6\u3001\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002"}}
{"id": "2511.19063", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19063", "abs": "https://arxiv.org/abs/2511.19063", "authors": ["Hayami Takahashi", "Kensuke Takahashi"], "title": "Logic of Montage", "comment": null, "summary": "In expressing emotions, as an expression form separate from natural language, we propose an alternative form that complements natural language, acting as a proxy or window for emotional states. First, we set up an expression form \"Effect of Contradictory Structure.\" \"Effect of Contradictory Structure\" is not static but dynamic. Effect in \"Effect of Contradictory Structure\" is unpleasant or pleasant, and the orientation to avoid that unpleasantness is considered pseudo-expression of will. Second, \"Effect of Contradictory Structure\" can be overlapped with each other. This overlapping operation is called \"montage.\" A broader \"Structure\" that includes related \"Effect of Contradictory Structure\" and \"Effect of Structure\" are set up. Montage produces \"Effect of Structure\". In montage, it is necessary to set something like \"strength,\" so we adopted Deleuze and Deleuze/Guattari's word \"intensity\" and set it as an element of our model. We set up a general theoretical framework - Word Import Between Systems (Models) and justified the import of \"intensity\" through Austin's use of the word \"force.\" \"Effect of Structure\" process is demonstrated using the example of proceeding to the next level of education.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u52a8\u6001\u77db\u76fe\u7ed3\u6784\u548c\u8499\u592a\u5947\u64cd\u4f5c\u7684\u60c5\u611f\u8868\u8fbe\u65b0\u5f62\u5f0f\uff0c\u7ed3\u5408\u5f3a\u5ea6\u6982\u5ff5\u6784\u5efa\u7406\u8bba\u6846\u67b6\uff0c\u4ee5\u8865\u5145\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u60c5\u611f\u3002", "motivation": "\u73b0\u6709\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u60c5\u611f\u7684\u65b9\u5f0f\u5b58\u5728\u4e0d\u8db3\uff0c\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u52a8\u6001\u4e14\u591a\u5c42\u6b21\u7684\u60c5\u611f\u8868\u8fbe\u5f62\u5f0f\uff0c\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u7684\u8865\u5145\uff0c\u66f4\u7cbe\u51c6\u5730\u53cd\u6620\u548c\u4f20\u8fbe\u4e2a\u4f53\u60c5\u7eea\u72b6\u6001\u3002", "method": "\u5efa\u7acb\u77db\u76fe\u7ed3\u6784\u6548\u5e94\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5b9a\u4e49\u8499\u592a\u5947\u64cd\u4f5c\u53ca\u5176\u4ea7\u751f\u7684\u7ed3\u6784\u6548\u5e94\uff0c\u5f15\u5165\u54f2\u5b66\u548c\u8bed\u8a00\u5b66\u4e2d\u7684\u201c\u5f3a\u5ea6\u201d\u4e0e\u201c\u529b\u201d\u4f5c\u4e3a\u6a21\u578b\u8981\u7d20\uff0c\u6784\u5efa\u7cfb\u7edf\u95f4\u8bcd\u6c47\u5bfc\u5165\u7684\u7406\u8bba\u67b6\u6784\uff0c\u5e76\u901a\u8fc7\u5177\u4f53\u6848\u4f8b\u5c55\u793a\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f5c\u4e3a\u81ea\u7136\u8bed\u8a00\u8865\u5145\u7684\u60c5\u611f\u8868\u8fbe\u5f62\u5f0f\uff0c\u79f0\u4e3a\u201c\u77db\u76fe\u7ed3\u6784\u6548\u5e94\u201d\u3002\u8be5\u6548\u5e94\u5177\u6709\u52a8\u6001\u6027\uff0c\u8868\u73b0\u4e3a\u6109\u5feb\u6216\u4e0d\u6109\u5feb\u7684\u611f\u89c9\uff0c\u4e14\u4e0d\u6109\u5feb\u7684\u8d8b\u907f\u65b9\u5411\u88ab\u89c6\u4e3a\u610f\u5fd7\u7684\u4f2a\u8868\u8fbe\u3002\u8be5\u7ed3\u6784\u53ef\u901a\u8fc7\u201c\u8499\u592a\u5947\u201d\u64cd\u4f5c\u91cd\u53e0\u5f62\u6210\u66f4\u5e7f\u4e49\u7684\u201c\u7ed3\u6784\u6548\u5e94\u201d\uff0c\u5e76\u5f15\u5165\u4e86\u201c\u5f3a\u5ea6\u201d\u8fd9\u4e00\u5143\u7d20\u4ee5\u91cf\u5316\u5f71\u54cd\u529b\u3002\u7406\u8bba\u6846\u67b6\u91c7\u7528\u4e86\u7cfb\u7edf\u95f4\u8bcd\u6c47\u5bfc\u5165\u6a21\u578b\uff0c\u5e76\u501f\u9274\u4e86\u8bed\u8a00\u54f2\u5b66\u4e2d\u7684\u201c\u529b\u201d\u6982\u5ff5\u3002\u6700\u540e\uff0c\u901a\u8fc7\u6559\u80b2\u63d0\u5347\u7684\u4f8b\u5b50\u6f14\u793a\u4e86\u8be5\u7ed3\u6784\u6548\u5e94\u7684\u5177\u4f53\u5e94\u7528\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u77db\u76fe\u7ed3\u6784\u6548\u5e94\u53ca\u5176\u53e0\u52a0\u7684\u8499\u592a\u5947\u673a\u5236\uff0c\u5e76\u7ed3\u5408\u5f3a\u5ea6\u5143\u7d20\uff0c\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u8f85\u52a9\u81ea\u7136\u8bed\u8a00\u8868\u8fbe\u60c5\u611f\u7684\u7406\u8bba\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u5728\u5b9e\u9645\u60c5\u5883\u4e2d\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.19078", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19078", "abs": "https://arxiv.org/abs/2511.19078", "authors": ["Yutong Li", "Yitian Zhou", "Xudong Wang", "GuoChen", "Caiyan Qin"], "title": "GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faGraphMind\uff0c\u4e00\u79cd\u7ed3\u5408GNN\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u52a8\u6001\u56fe\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u6b65\u63a8\u7406\u4e2d\u7684\u5b9a\u7406\u9009\u62e9\u548c\u4e2d\u95f4\u7ed3\u8bba\u751f\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u5927\u8bed\u8a00\u6a21\u578b\u5728\u591a\u6b65\u63a8\u7406\u4e2d\u7f3a\u4e4f\u660e\u786e\u4e14\u52a8\u6001\u7684\u4e2d\u95f4\u63a8\u7406\u72b6\u6001\u7ed3\u6784\u8868\u793a\uff0c\u9650\u5236\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u5b9a\u7406\u9009\u62e9\u548c\u8fed\u4ee3\u7ed3\u8bba\u751f\u6210\u80fd\u529b\u3002", "method": "\u63d0\u51faGraphMind\uff0c\u4e00\u79cd\u7ed3\u5408\u56fe\u795e\u7ecf\u7f51\u7edc\u548c\u5927\u8bed\u8a00\u6a21\u578b\u7684\u52a8\u6001\u56fe\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u8fc7\u7a0b\u5efa\u6a21\u4e3a\u5f02\u6784\u6f14\u5316\u56fe\uff0c\u901a\u8fc7GNN\u7f16\u7801\u5f53\u524d\u63a8\u7406\u72b6\u6001\u5e76\u5229\u7528\u8bed\u4e49\u5339\u914d\u8fdb\u884c\u5b9a\u7406\u9009\u62e9\uff0c\u5b9e\u73b0\u95ed\u73af\u7ed3\u6784\u5316\u63a8\u7406\u3002", "result": "GraphMind\u5728\u591a\u6b65\u63a8\u7406\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u591a\u4e2a\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6027\u80fd\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u901a\u8fc7\u52a8\u6001\u56fe\u7ed3\u6784\u548c\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u5408\uff0cGraphMind\u5b9e\u73b0\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u4e14\u53ef\u89e3\u91ca\u7684\u591a\u6b65\u63a8\u7406\u673a\u5236\uff0c\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002"}}
{"id": "2511.19083", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19083", "abs": "https://arxiv.org/abs/2511.19083", "authors": ["Wenxuan Mu", "Jinzhong Ning", "Di Zhao", "Yijia Zhang"], "title": "A Multi-Agent LLM Framework for Multi-Domain Low-Resource In-Context NER via Knowledge Retrieval, Disambiguation and Reflective Analysis", "comment": "This paper has been accepted by AAAI 2026 (Main Technical Track)", "summary": "In-context learning (ICL) with large language models (LLMs) has emerged as a promising paradigm for named entity recognition (NER) in low-resource scenarios. However, existing ICL-based NER methods suffer from three key limitations: (1) reliance on dynamic retrieval of annotated examples, which is problematic when annotated data is scarce; (2) limited generalization to unseen domains due to the LLM's insufficient internal domain knowledge; and (3) failure to incorporate external knowledge or resolve entity ambiguities. To address these challenges, we propose KDR-Agent, a novel multi-agent framework for multi-domain low-resource in-context NER that integrates Knowledge retrieval, Disambiguation, and Reflective analysis. KDR-Agent leverages natural-language type definitions and a static set of entity-level contrastive demonstrations to reduce dependency on large annotated corpora. A central planner coordinates specialized agents to (i) retrieve factual knowledge from Wikipedia for domain-specific mentions, (ii) resolve ambiguous entities via contextualized reasoning, and (iii) reflect on and correct model predictions through structured self-assessment. Experiments across ten datasets from five domains demonstrate that KDR-Agent significantly outperforms existing zero-shot and few-shot ICL baselines across multiple LLM backbones. The code and data can be found at https://github.com/MWXGOD/KDR-Agent.", "AI": {"tldr": "KDR-Agent\u662f\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u68c0\u7d22\u3001\u5b9e\u4f53\u6d88\u6b67\u4e0e\u53cd\u601d\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u63d0\u5347\u4f4e\u8d44\u6e90\u591a\u57df\u6761\u4ef6\u4e0b\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6027\u80fd\uff0c\u6548\u679c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5185\u793a\u5b66\u4e60\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u65b9\u6cd5\u5b58\u5728\u4f9d\u8d56\u52a8\u6001\u68c0\u7d22\u6807\u6ce8\u6837\u672c\u3001\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u4ee5\u53ca\u65e0\u6cd5\u6709\u6548\u5229\u7528\u5916\u90e8\u77e5\u8bc6\u548c\u89e3\u51b3\u5b9e\u4f53\u6b67\u4e49\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u7efc\u5408\u65b9\u6cd5\u52a0\u4ee5\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u591a\u667a\u80fd\u4f53\u6846\u67b6KDR-Agent\uff0c\u5305\u62ec\u77e5\u8bc6\u68c0\u7d22\u3001\u6b67\u4e49\u6d88\u89e3\u548c\u53cd\u601d\u5206\u6790\u4e09\u90e8\u5206\uff0c\u7531\u4e2d\u592e\u8ba1\u5212\u8005\u534f\u8c03\u4e13\u95e8\u667a\u80fd\u4f53\u5408\u4f5c\u5b8c\u6210\uff0c\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7c7b\u578b\u5b9a\u4e49\u548c\u5b9e\u4f53\u7ea7\u5bf9\u6bd4\u793a\u4f8b\u8f85\u52a9\u6a21\u578b\u63a8\u7406\u3002", "result": "\u672c\u6587\u63d0\u51fa\u4e86KDR-Agent\uff0c\u4e00\u79cd\u7ed3\u5408\u77e5\u8bc6\u68c0\u7d22\u3001\u6d88\u6b67\u4e0e\u53cd\u601d\u5206\u6790\u7684\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u4f4e\u8d44\u6e90\u591a\u57df\u6761\u4ef6\u4e0b\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u81ea\u7136\u8bed\u8a00\u7c7b\u578b\u5b9a\u4e49\u548c\u5b9e\u4f53\u7ea7\u5bf9\u6bd4\u793a\u4f8b\uff0c\u51cf\u5c11\u5bf9\u5927\u91cf\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002\u901a\u8fc7\u4e2d\u592e\u8ba1\u5212\u8005\u534f\u8c03\u5404\u667a\u80fd\u4f53\u4ece\u7ef4\u57fa\u767e\u79d1\u68c0\u7d22\u9886\u57df\u77e5\u8bc6\u3001\u8fdb\u884c\u6b67\u4e49\u6d88\u89e3\u53ca\u7ed3\u6784\u5316\u81ea\u6211\u8bc4\u4f30\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u53ca\u5c11\u6837\u672c\u73af\u5883\u4e0b\u7684\u8868\u73b0\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cKDR-Agent\u4f18\u4e8e\u73b0\u6709\u7684\u96f6\u6837\u672c\u53ca\u5c11\u6837\u672c\u5185\u793a\u5b66\u4e60\u65b9\u6cd5\u3002", "conclusion": "KDR-Agent\u901a\u8fc7\u6574\u5408\u77e5\u8bc6\u68c0\u7d22\u3001\u6b67\u4e49\u6d88\u89e3\u548c\u53cd\u601d\u673a\u5236\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u57df\u4f4e\u8d44\u6e90\u6761\u4ef6\u4e0b\u7684\u547d\u540d\u5b9e\u4f53\u8bc6\u522b\u6548\u679c\uff0c\u5c55\u793a\u4e86\u8f83\u5f3a\u7684\u6cdb\u5316\u80fd\u529b\u548c\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2511.19097", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19097", "abs": "https://arxiv.org/abs/2511.19097", "authors": ["Ziyuan Gao", "Di Liang", "Xianjie Wu", "Philippe Morel", "Minlong Peng"], "title": "DeCoRL: Decoupling Reasoning Chains via Parallel Sub-Step Generation and Cascaded Reinforcement for Interpretable and Scalable RLHF", "comment": "Accepted by AAAI 2026", "summary": "Existing reinforcement learning methods for Chain-of-Thought reasoning suffer from two critical limitations. First, they operate as monolithic black boxes that provide undifferentiated reward signals, obscuring individual step contributions and hindering error diagnosis. Second, sequential decoding has O(n) time complexity. This makes real-time deployment impractical for complex reasoning tasks. We present DeCoRL (Decoupled Reasoning Chains via Coordinated Reinforcement Learning), a novel framework that transforms reasoning from sequential processing into collaborative modular orchestration. DeCoRL trains lightweight specialized models to generate reasoning sub-steps concurrently, eliminating sequential bottlenecks through parallel processing. To enable precise error attribution, the framework designs modular reward functions that score each sub-step independently. Cascaded DRPO optimization then coordinates these rewards while preserving inter-step dependencies. Comprehensive evaluation demonstrates state-of-the-art results across RM-Bench, RMB, and RewardBench, outperforming existing methods including large-scale models. DeCoRL delivers 3.8 times faster inference while maintaining superior solution quality and offers a 22.7\\% improvement in interpretability through explicit reward attribution. These advancements, combined with a 72.4\\% reduction in energy consumption and a 68\\% increase in throughput, make real-time deployment of complex reasoning systems a reality.", "AI": {"tldr": "DeCoRL\u901a\u8fc7\u5e76\u884c\u6a21\u5757\u5316\u63a8\u7406\u548c\u72ec\u7acb\u5956\u52b1\u6253\u5206\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u3001\u66f4\u53ef\u89e3\u91ca\u7684Chain-of-Thought\u63a8\u7406\uff0c\u663e\u8457\u63d0\u5347\u63a8\u7406\u901f\u5ea6\u548c\u6027\u80fd\uff0c\u964d\u4f4e\u80fd\u8017\u3002", "motivation": "\u73b0\u6709\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684Chain-of-Thought\u63a8\u7406\u65b9\u6cd5\u5b58\u5728\u9ed1\u76d2\u95ee\u9898\u96be\u4ee5\u8ffd\u8e2a\u9519\u8bef\u8d21\u732e\uff0c\u4e14\u987a\u5e8f\u89e3\u7801\u5bfc\u81f4\u65f6\u95f4\u590d\u6742\u5ea6\u9ad8\uff0c\u65e0\u6cd5\u6ee1\u8db3\u590d\u6742\u63a8\u7406\u4efb\u52a1\u7684\u5b9e\u65f6\u9700\u6c42\u3002", "method": "\u63d0\u51faDeCoRL\u6846\u67b6\uff0c\u901a\u8fc7\u5e76\u884c\u8bad\u7ec3\u8f7b\u91cf\u5316\u4e13\u95e8\u6a21\u578b\u6765\u751f\u6210\u63a8\u7406\u5b50\u6b65\u9aa4\uff0c\u91c7\u7528\u6a21\u5757\u5316\u5956\u52b1\u51fd\u6570\u5bf9\u5404\u5b50\u6b65\u9aa4\u72ec\u7acb\u6253\u5206\uff0c\u5e76\u4f7f\u7528\u7ea7\u8054DRPO\u4f18\u5316\u534f\u8c03\u5404\u5956\u52b1\u4ee5\u4fdd\u6301\u6b65\u9aa4\u95f4\u4f9d\u8d56\u3002", "result": "DeCoRL\u5728RM-Bench\u3001RMB\u548cRewardBench\u7b49\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u9886\u5148\u6027\u80fd\uff0c\u6bd4\u5927\u89c4\u6a21\u6a21\u578b\u66f4\u4f18\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u53473.8\u500d\uff0c\u89e3\u91ca\u6027\u63d0\u534722.7%\uff0c\u80fd\u8017\u964d\u4f4e72.4%\uff0c\u541e\u5410\u91cf\u63d0\u534768%\u3002", "conclusion": "DeCoRL\u6210\u529f\u5b9e\u73b0\u4e86\u590d\u6742\u63a8\u7406\u7cfb\u7edf\u7684\u5b9e\u65f6\u90e8\u7f72\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u4e2d\u7684\u9ed1\u76d2\u4e0e\u987a\u5e8f\u74f6\u9888\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u63a8\u7406\u6548\u7387\u3001\u53ef\u89e3\u91ca\u6027\u548c\u8d44\u6e90\u5229\u7528\u7387\u3002"}}
{"id": "2511.19118", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19118", "abs": "https://arxiv.org/abs/2511.19118", "authors": ["Juan-Jos\u00e9 Guzm\u00e1n-Landa", "Jes\u00fas V\u00e1zquez-Osorio", "Juan-Manuel Torres-Moreno", "Ligia Quintana Torres", "Miguel Figueroa-Saavedra", "Martha-Lorena Avenda\u00f1o-Garrido", "Graham Ranger", "Patricia Vel\u00e1zquez-Morales", "Gerardo Eugenio Sierra Mart\u00ednez"], "title": "A symbolic Perl algorithm for the unification of Nahuatl word spellings", "comment": "MICAI 2025, LNAI 16221, pp. 141-154, 2026. 10 pages, 4 Figures, 8 Tables", "summary": "In this paper, we describe a symbolic model for the automatic orthographic unification of Nawatl text documents. Our model is based on algorithms that we have previously used to analyze sentences in Nawatl, and on the corpus called $\u03c0$-yalli, consisting of texts in several Nawatl orthographies. Our automatic unification algorithm implements linguistic rules in symbolic regular expressions. We also present a manual evaluation protocol that we have proposed and implemented to assess the quality of the unified sentences generated by our algorithm, by testing in a sentence semantic task. We have obtained encouraging results from the evaluators for most of the desired features of our artificially unified sentences", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7b26\u53f7\u6a21\u578b\u7684Nawatl\u6587\u672c\u81ea\u52a8\u6b63\u5b57\u6cd5\u7edf\u4e00\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u4efb\u52a1\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002", "motivation": "\u89e3\u51b3Nawatl\u6587\u672c\u6b63\u5b57\u6cd5\u4e0d\u7edf\u4e00\u7684\u95ee\u9898", "method": "\u57fa\u4e8e\u5148\u524d\u53e5\u6cd5\u5206\u6790\u7b97\u6cd5\u548c\u591a\u79cdNawatl\u6b63\u5b57\u6cd5\u6587\u672c\u8bed\u6599\u5e93\uff0c\u4f7f\u7528\u7b26\u53f7\u6b63\u5219\u8868\u8fbe\u5f0f\u5b9e\u73b0\u81ea\u52a8\u7edf\u4e00\u7b97\u6cd5\uff0c\u5e76\u8bbe\u8ba1\u624b\u5de5\u8bc4\u4f30\u534f\u8bae\u9a8c\u8bc1\u8d28\u91cf\u3002", "result": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u7b26\u53f7\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u81ea\u52a8\u7edf\u4e00\u7b97\u6cd5\uff0c\u5e76\u7528\u8bed\u4e49\u4efb\u52a1\u7684\u624b\u5de5\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u6548\u679c\uff0c\u7ed3\u679c\u4ee4\u4eba\u9f13\u821e", "conclusion": "\u7b97\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86Nawatl\u6587\u672c\u7684\u6b63\u5b57\u6cd5\u7edf\u4e00\uff0c\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\u7edf\u4e00\u53e5\u5b50\u8d28\u91cf\u826f\u597d\u3002"}}
{"id": "2511.19120", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19120", "abs": "https://arxiv.org/abs/2511.19120", "authors": ["Phong Le", "Mees Lindeman", "Raquel G. Alhama"], "title": "On the Optimality of Discrete Object Naming: a Kinship Case Study", "comment": null, "summary": "The structure of naming systems in natural languages hinges on a trade-off between high informativeness and low complexity. Prior work capitalizes on information theory to formalize these notions; however, these studies generally rely on two simplifications: (i) optimal listeners, and (ii) universal communicative need across languages. Here, we address these limitations by introducing an information-theoretic framework for discrete object naming systems, and we use it to prove that an optimal trade-off is achievable if and only if the listener's decoder is equivalent to the Bayesian decoder of the speaker. Adopting a referential game setup from emergent communication, and focusing on the semantic domain of kinship, we show that our notion of optimality is not only theoretically achievable but also emerges empirically in learned communication systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u4fe1\u606f\u8bba\u6a21\u578b\uff0c\u8bc1\u660e\u5e76\u5b9e\u8bc1\u4e86\u81ea\u7136\u8bed\u8a00\u547d\u540d\u7cfb\u7edf\u4e2d\u4fe1\u606f\u4e0e\u590d\u6742\u5ea6\u7684\u6700\u4f18\u6743\u8861\u6761\u4ef6\u53ca\u5176\u5728\u5b66\u4e60\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u5b9e\u73b0\u3002", "motivation": "\u89e3\u51b3\u4ee5\u5f80\u7814\u7a76\u4e2d\u5173\u4e8e\u6700\u4f18\u542c\u8005\u548c\u666e\u904d\u4ea4\u6d41\u9700\u6c42\u7684\u7b80\u5316\u5047\u8bbe\uff0c\u63a2\u7d22\u81ea\u7136\u8bed\u8a00\u547d\u540d\u7cfb\u7edf\u4e2d\u7684\u4fe1\u606f\u91cf\u4e0e\u590d\u6742\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u3002", "method": "\u5f15\u5165\u4e00\u4e2a\u4fe1\u606f\u8bba\u6846\u67b6\u7528\u4e8e\u79bb\u6563\u7269\u4f53\u547d\u540d\u7cfb\u7edf\uff0c\u7ed3\u5408\u53d1\u6563\u901a\u4fe1\u4e2d\u7684\u6307\u79f0\u6e38\u620f\u65b9\u6cd5\uff0c\u5e76\u805a\u7126\u4eb2\u5c5e\u8bed\u4e49\u9886\u57df\u8fdb\u884c\u5b9e\u8bc1\u5206\u6790\u3002", "result": "\u7406\u8bba\u8bc1\u660e\u6761\u4ef6\u6210\u7acb\u4e14\u5b9e\u9a8c\u8bc1\u660e\u8be5\u6700\u4f18\u6027\u5728\u5b66\u4e60\u7684\u901a\u4fe1\u7cfb\u7edf\u4e2d\u81ea\u7136\u51fa\u73b0\u3002", "conclusion": "\u6700\u4f73\u7684\u4fe1\u606f\u6743\u8861\u53ea\u6709\u5728\u542c\u8005\u7684\u89e3\u7801\u5668\u4e0e\u8bf4\u8bdd\u8005\u7684\u8d1d\u53f6\u65af\u89e3\u7801\u5668\u7b49\u4ef7\u65f6\u624d\u80fd\u5b9e\u73b0\u3002"}}
{"id": "2511.19122", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19122", "abs": "https://arxiv.org/abs/2511.19122", "authors": ["Yaping Chai", "Haoran Xie", "Joe S. Qin"], "title": "Emotion-Enhanced Multi-Task Learning with LLMs for Aspect Category Sentiment Analysis", "comment": "8 pages, 4 figures", "summary": "Aspect category sentiment analysis (ACSA) has achieved remarkable progress with large language models (LLMs), yet existing approaches primarily emphasize sentiment polarity while overlooking the underlying emotional dimensions that shape sentiment expressions. This limitation hinders the model's ability to capture fine-grained affective signals toward specific aspect categories. To address this limitation, we introduce a novel emotion-enhanced multi-task ACSA framework that jointly learns sentiment polarity and category-specific emotions grounded in Ekman's six basic emotions. Leveraging the generative capabilities of LLMs, our approach enables the model to produce emotional descriptions for each aspect category, thereby enriching sentiment representations with affective expressions. Furthermore, to ensure the accuracy and consistency of the generated emotions, we introduce an emotion refinement mechanism based on the Valence-Arousal-Dominance (VAD) dimensional framework. Specifically, emotions predicted by the LLM are projected onto a VAD space, and those inconsistent with their corresponding VAD coordinates are re-annotated using a structured LLM-based refinement strategy. Experimental results demonstrate that our approach significantly outperforms strong baselines on all benchmark datasets. This underlines the effectiveness of integrating affective dimensions into ACSA.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u60c5\u611f\u7c7b\u522b\u591a\u4efb\u52a1\u5206\u6790\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u60c5\u7eea\u7ef4\u5ea6\u548c\u60c5\u7eea\u7cbe\u70bc\u673a\u5236\u63d0\u5347\u7ec6\u7c92\u5ea6\u60c5\u611f\u5206\u6790\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u60c5\u611f\u6781\u6027\u5206\u6790\u5ffd\u7565\u6f5c\u5728\u60c5\u7eea\u7ef4\u5ea6\uff0c\u96be\u4ee5\u6355\u6349\u7279\u5b9a\u7c7b\u522b\u7684\u7ec6\u7c92\u5ea6\u60c5\u611f\u4fe1\u53f7\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eEkman\u516d\u79cd\u57fa\u672c\u60c5\u7eea\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u751f\u6210\u60c5\u7eea\u63cf\u8ff0\uff0c\u5e76\u901a\u8fc7VAD\u7a7a\u95f4\u6620\u5c04\u52a0\u4ee5\u7cbe\u70bc\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u4f18\u8d8a\u6027\uff0c\u663e\u8457\u8d85\u8d8a\u5f3a\u57fa\u7ebf\u3002", "conclusion": "\u5f15\u5165\u60c5\u7eea\u7ef4\u5ea6\u548c\u57fa\u4e8eVAD\u6846\u67b6\u7684\u60c5\u7eea\u7cbe\u70bc\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u9762\u5411\u7c7b\u522b\u7684\u60c5\u611f\u5206\u6790\u6548\u679c\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u3002"}}
{"id": "2511.19131", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19131", "abs": "https://arxiv.org/abs/2511.19131", "authors": ["Zijian Wang", "Yanxiang Ma", "Chang Xu"], "title": "Eliciting Chain-of-Thought in Base LLMs via Gradient-Based Representation Optimization", "comment": "AAAI2026", "summary": "Chain-of-Thought (CoT) reasoning is a critical capability for large language models (LLMs), enabling them to tackle com- plex multi-step tasks. While base LLMs, pre-trained on general text corpora, often struggle with reasoning due to a lack of specialized training, recent studies reveal their latent reason- ing potential tied to hidden states. However, existing hidden state manipulation methods, such as linear activation steering, suffer from limitations due to their rigid and unconstrained nature, often leading to distribution shifts and degraded text quality. In this work, we propose a novel approach for elic- iting CoT reasoning from base LLMs through hidden state manipulation grounded in probabilistic conditional generation. By reformulating the challenge as an optimization problem with a balanced likelihood and prior regularization framework, our method guides hidden states toward reasoning-oriented trajectories while preserving linguistic coherence. Extensive evaluations across mathematical, commonsense, and logical reasoning benchmarks demonstrate that our approach con- sistently outperforms existing steering methods, offering a theoretically principled and effective solution for enhancing reasoning capabilities in base LLMs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6982\u7387\u6761\u4ef6\u751f\u6210\u7684\u9690\u85cf\u72b6\u6001\u64cd\u63a7\u65b9\u6cd5\uff0c\u7528\u4ee5\u6fc0\u53d1\u57fa\u7840\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u80fd\u529b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u57fa\u7840\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7f3a\u4e4f\u4e13\u95e8\u8bad\u7ec3\u96be\u4ee5\u8fdb\u884c\u590d\u6742\u63a8\u7406\uff0c\u800c\u73b0\u6709\u9690\u85cf\u72b6\u6001\u64cd\u63a7\u65b9\u6cd5\u8fc7\u4e8e\u521a\u6027\uff0c\u5bb9\u6613\u5bfc\u81f4\u6a21\u578b\u751f\u6210\u8d28\u91cf\u4e0b\u964d\uff0c\u4e9f\u9700\u4e00\u79cd\u65e2\u80fd\u6fc0\u53d1\u63a8\u7406\u6f5c\u529b\u53c8\u80fd\u4fdd\u6301\u8bed\u8a00\u8d28\u91cf\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u5c06\u9690\u85cf\u72b6\u6001\u64cd\u63a7\u89c6\u4e3a\u4e00\u4e2a\u5e26\u5e73\u8861\u4f3c\u7136\u548c\u5148\u9a8c\u6b63\u5219\u5316\u7684\u4f18\u5316\u95ee\u9898\uff0c\u901a\u8fc7\u6982\u7387\u6761\u4ef6\u751f\u6210\u6846\u67b6\u5f15\u5bfc\u9690\u85cf\u72b6\u6001\u8d70\u5411\u63a8\u7406\u5bfc\u5411\u7684\u8f68\u8ff9\uff0c\u4ece\u800c\u5b9e\u73b0Chain-of-Thought\u63a8\u7406\u3002", "result": "\u5728\u6570\u5b66\u3001\u5e38\u8bc6\u548c\u903b\u8f91\u63a8\u7406\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5747\u4f18\u4e8e\u73b0\u6709\u7ebf\u6027\u6fc0\u6d3b\u64cd\u63a7\u7b49\u6280\u672f\uff0c\u5c55\u793a\u4e86\u7406\u8bba\u4e0a\u7684\u5408\u7406\u6027\u548c\u5b9e\u8df5\u4e2d\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u4f18\u5316\u9690\u85cf\u72b6\u6001\u5728\u63a8\u7406\u8f68\u8ff9\u4e0a\u7684\u5f15\u5bfc\uff0c\u5e73\u8861\u4e86\u751f\u6210\u6587\u672c\u7684\u5408\u7406\u6027\u4e0e\u8bed\u4e49\u8fde\u8d2f\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u7840\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u6b65\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2511.19166", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19166", "abs": "https://arxiv.org/abs/2511.19166", "authors": ["Samantha Dies", "Courtney Maynard", "Germans Savcisens", "Tina Eliassi-Rad"], "title": "Representational Stability of Truth in Large Language Models", "comment": "25 pages, 24 figures", "summary": "Large language models (LLMs) are widely used for factual tasks such as \"What treats asthma?\" or \"What is the capital of Latvia?\". However, it remains unclear how stably LLMs encode distinctions between true, false, and neither-true-nor-false content in their internal probabilistic representations. We introduce representational stability as the robustness of an LLM's veracity representations to perturbations in the operational definition of truth. We assess representational stability by (i) training a linear probe on an LLM's activations to separate true from not-true statements and (ii) measuring how its learned decision boundary shifts under controlled label changes. Using activations from sixteen open-source models and three factual domains, we compare two types of neither statements. The first are fact-like assertions about entities we believe to be absent from any training data. We call these unfamiliar neither statements. The second are nonfactual claims drawn from well-known fictional contexts. We call these familiar neither statements. The unfamiliar statements induce the largest boundary shifts, producing up to $40\\%$ flipped truth judgements in fragile domains (such as word definitions), while familiar fictional statements remain more coherently clustered and yield smaller changes ($\\leq 8.2\\%$). These results suggest that representational stability stems more from epistemic familiarity than from linguistic form. More broadly, our approach provides a diagnostic for auditing and training LLMs to preserve coherent truth assignments under semantic uncertainty, rather than optimizing for output accuracy alone.", "AI": {"tldr": "\u8be5\u6587\u63d0\u51fa\u4e86\u201c\u8868\u5f81\u7a33\u5b9a\u6027\u201d\u6307\u6807\uff0c\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u771f\u5047\u5224\u65ad\u4e0a\u7684\u4e00\u81f4\u6027\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u719f\u6089\u5185\u5bb9\u7684\u771f\u503c\u5224\u65ad\u66f4\u7a33\u5b9a\uff0c\u4e0d\u719f\u6089\u5185\u5bb9\u5219\u6ce2\u52a8\u8f83\u5927\u3002", "motivation": "\u5f53\u524d\u7f3a\u4e4f\u5173\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u5982\u4f55\u533a\u5206\u771f\u4e0e\u975e\u771f\u7684\u8868\u5f81\u7a33\u5b9a\u6027\u7684\u7406\u89e3\uff0c\u672c\u6587\u65e8\u5728\u8bca\u65ad\u5e76\u63d0\u5347\u6a21\u578b\u5728\u8bed\u4e49\u4e0d\u786e\u5b9a\u60c5\u5883\u4e0b\u4fdd\u6301\u771f\u503c\u5224\u65ad\u4e00\u81f4\u6027\u7684\u80fd\u529b\uff0c\u800c\u975e\u5355\u7eaf\u8ffd\u6c42\u8f93\u51fa\u51c6\u786e\u6027\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u7ebf\u6027\u63a2\u9488\u5bf9\u6a21\u578b\u6fc0\u6d3b\u8fdb\u884c\u771f\u4f2a\u5206\u7c7b\uff0c\u5e76\u5728\u6807\u7b7e\u5b9a\u4e49\u53d7\u63a7\u53d8\u66f4\u4e0b\u6d4b\u91cf\u51b3\u7b56\u8fb9\u754c\u7684\u79fb\u52a8\uff0c\u5206\u6790\u6a21\u578b\u5bf9\u4e0d\u540c\u7c7b\u578b\u201c\u975e\u771f\u201d\u9648\u8ff0\uff08\u719f\u6089\u7684\u865a\u6784\u9648\u8ff0\u4e0e\u964c\u751f\u9648\u8ff0\uff09\u7684\u53cd\u5e94\u5dee\u5f02\u3002", "result": "\u672c\u6587\u7814\u7a76\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u533a\u5206\u771f\u3001\u5047\u4ee5\u53ca\u975e\u771f\u975e\u5047\u7684\u5185\u5bb9\u65f6\uff0c\u5176\u5185\u90e8\u6982\u7387\u8868\u793a\u7684\u7a33\u5b9a\u6027\u95ee\u9898\u3002\u901a\u8fc7\u7ebf\u6027\u63a2\u9488\u8bad\u7ec3\u548c\u6807\u7b7e\u5e72\u6270\u6d4b\u8bd5\uff0c\u5206\u6790\u4e86\u6a21\u578b\u5bf9\u4e0d\u540c\u7c7b\u578b\u201c\u975e\u771f\u201d\u9648\u8ff0\u7684\u8868\u73b0\u5dee\u5f02\uff0c\u53d1\u73b0\u6a21\u578b\u5bf9\u719f\u6089\u7684\u865a\u6784\u9648\u8ff0\u8868\u73b0\u51fa\u8f83\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u800c\u5bf9\u4e0d\u719f\u6089\u7684\u9648\u8ff0\u8fb9\u754c\u53d8\u5316\u663e\u8457\uff0c\u8868\u660e\u7a33\u5b9a\u6027\u66f4\u591a\u6e90\u4e8e\u8ba4\u77e5\u719f\u6089\u5ea6\u800c\u975e\u8bed\u8a00\u5f62\u5f0f\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u7684\u771f\u503c\u8868\u5f81\u7a33\u5b9a\u6027\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8ba4\u77e5\u719f\u6089\u5ea6\uff0c\u5bf9\u964c\u751f\u4fe1\u606f\u7684\u771f\u5b9e\u6027\u5224\u65ad\u5b58\u5728\u8f83\u5927\u6ce2\u52a8\uff0c\u8fd9\u4e3a\u672a\u6765\u6a21\u578b\u5ba1\u8ba1\u548c\u8bad\u7ec3\u63d0\u4f9b\u4e86\u65b0\u7684\u8bca\u65ad\u5de5\u5177\u3002"}}
{"id": "2511.19232", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.19232", "abs": "https://arxiv.org/abs/2511.19232", "authors": ["Christos-Nikolaos Zacharopoulos", "Revekka Kyriakoglou"], "title": "In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations", "comment": "Accepted at AICS2025", "summary": "How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86transformer\u6a21\u578b\u5982\u4f55\u5728\u4e0d\u540c\u5c42\u6b21\u68c0\u6d4b\u8bed\u4e49\u5f02\u5e38\uff0c\u53d1\u73b0\u5f02\u5e38\u4fe1\u53f7\u5728\u4e2d\u5c42\u663e\u8457\u589e\u5f3a\uff0c\u5e76\u4e0e\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u987a\u5e8f\u4e00\u81f4\u3002", "motivation": "\u63a2\u7a76transformer\u6a21\u578b\u5982\u4f55\u4ee5\u53ca\u5728\u54ea\u4e00\u5c42\u68c0\u6d4b\u51fa\u53e5\u5b50\u7684\u8bed\u4e49\u5f02\u5e38\u3002", "method": "\u4f7f\u7528\u9488\u5bf9\u6027\u8bed\u6599\u5e93\u6d4b\u8bd5\u9884\u8bad\u7ec3\u8bed\u8a00\u6a21\u578bphi-2\uff0c\u4ee5\u7ebf\u6027\u63a2\u9488\u9010\u5c42\u68c0\u6d4b\u6a21\u578b\u9690\u85cf\u72b6\u6001\u4e2d\u5bf9\u8bed\u4e49\u5f02\u5e38\u7684\u7f16\u7801\uff0c\u5e76\u5206\u6790\u8868\u793a\u7ef4\u5ea6\u7684\u53d8\u5316\u3002", "result": "\u6a21\u578b\u7684\u524d1/3\u5c42\u96be\u4ee5\u533a\u5206\u5408\u7406\u4e0e\u4e0d\u5408\u7406\u53e5\u5b50\u7ed3\u5c3e\uff0c\u8fa8\u8bc6\u80fd\u529b\u5728\u4e2d\u95f4\u5c42\u660e\u663e\u63d0\u9ad8\uff0c\u5e76\u5728\u9760\u8fd1\u9876\u90e8\u5c42\u8fbe\u5230\u5cf0\u503c\uff1b\u8bed\u4e49\u5f02\u5e38\u5148\u589e\u52a0\u8868\u793a\u7684\u7ef4\u5ea6\uff0c\u968f\u540e\u5728\u4e2d\u5c42\u53d1\u751f\u7ef4\u5ea6\u584c\u7f29\uff0c\u53ef\u80fd\u8868\u793a\u7ecf\u5386\u4e86\u63a2\u7d22\u5230\u5feb\u901f\u6574\u5408\u7684\u8fc7\u7a0b\u3002", "conclusion": "\u6a21\u578b\u5bf9\u8bed\u4e49\u5f02\u5e38\u7684\u68c0\u6d4b\u4e0e\u4eba\u7c7b\u8bed\u8a00\u5904\u7406\u8fc7\u7a0b\u76f8\u4f3c\uff0c\u7b26\u5408\u5fc3\u7406\u8bed\u8a00\u5b66\u4e2d\u8bed\u4e49\u5f02\u5e38\u665a\u4e8e\u53e5\u6cd5\u89e3\u6790\u88ab\u8bc6\u522b\u7684\u89c2\u70b9\uff0c\u53cd\u6620\u51fa\u5728\u7ebf\u5904\u7406\u7684\u9636\u6bb5\u6027\u3002"}}
{"id": "2511.19317", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19317", "abs": "https://arxiv.org/abs/2511.19317", "authors": ["Md. Tanzim Ferdous", "Naeem Ahsan Chowdhury", "Prithwiraj Bhattacharjee"], "title": "MultiBanAbs: A Comprehensive Multi-Domain Bangla Abstractive Text Summarization Dataset", "comment": null, "summary": "This study developed a new Bangla abstractive summarization dataset to generate concise summaries of Bangla articles from diverse sources. Most existing studies in this field have concentrated on news articles, where journalists usually follow a fixed writing style. While such approaches are effective in limited contexts, they often fail to adapt to the varied nature of real-world Bangla texts. In today's digital era, a massive amount of Bangla content is continuously produced across blogs, newspapers, and social media. This creates a pressing need for summarization systems that can reduce information overload and help readers understand content more quickly. To address this challenge, we developed a dataset of over 54,000 Bangla articles and summaries collected from multiple sources, including blogs such as Cinegolpo and newspapers such as Samakal and The Business Standard. Unlike single-domain resources, our dataset spans multiple domains and writing styles. It offers greater adaptability and practical relevance. To establish strong baselines, we trained and evaluated this dataset using several deep learning and transfer learning models, including LSTM, BanglaT5-small, and MTS-small. The results highlight its potential as a benchmark for future research in Bangla natural language processing. This dataset provides a solid foundation for building robust summarization systems and helps expand NLP resources for low-resource languages.", "AI": {"tldr": "\u672c\u6587\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u8d85\u8fc754,000\u7bc7\u8de8\u591a\u4e2a\u9886\u57df\u7684\u5b5f\u52a0\u62c9\u6587\u6587\u7ae0\u53ca\u6458\u8981\u7684\u6570\u636e\u96c6\uff0c\u65e8\u5728\u63d0\u5347\u5b5f\u52a0\u62c9\u6587\u6458\u8981\u751f\u6210\u7684\u591a\u6837\u6027\u548c\u9002\u5e94\u6027\u3002\u901a\u8fc7\u8bad\u7ec3\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u9a8c\u8bc1\u4e86\u8be5\u6570\u636e\u96c6\u7684\u6709\u6548\u6027\uff0c\u63a8\u52a8\u4f4e\u8d44\u6e90\u8bed\u8a00\u7684\u81ea\u7136\u8bed\u8a00\u5904\u7406\u53d1\u5c55\u3002", "motivation": "\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u65b0\u95fb\u9886\u57df\uff0c\u98ce\u683c\u5355\u4e00\uff0c\u96be\u4ee5\u9002\u5e94\u771f\u5b9e\u5b5f\u52a0\u62c9\u6587\u6587\u672c\u7684\u591a\u6837\u6027\uff0c\u4e14\u5f53\u524d\u4fe1\u606f\u91cf\u5927\uff0c\u9700\u8981\u6709\u6548\u7684\u6458\u8981\u7cfb\u7edf\u7f13\u89e3\u4fe1\u606f\u8fc7\u8f7d\u3002", "method": "\u6536\u96c6\u6765\u81ea\u535a\u5ba2\u548c\u591a\u5bb6\u62a5\u7eb8\u7684\u8d85\u8fc754,000\u7bc7\u6587\u7ae0\u53ca\u5176\u6458\u8981\uff0c\u6db5\u76d6\u591a\u79cd\u9886\u57df\u4e0e\u5199\u4f5c\u98ce\u683c\uff0c\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\u8bad\u7ec3\u5e76\u8bc4\u4f30LSTM\u3001BanglaT5-small\u3001MTS-small\u7b49\u6df1\u5ea6\u5b66\u4e60\u548c\u8fc1\u79fb\u5b66\u4e60\u6a21\u578b\u3002", "result": "\u591a\u9886\u57df\u3001\u591a\u98ce\u683c\u7684\u6570\u636e\u96c6\u6784\u5efa\u6210\u529f\uff0c\u8bad\u7ec3\u6a21\u578b\u8868\u73b0\u826f\u597d\uff0c\u8bc1\u660e\u6570\u636e\u96c6\u5177\u5907\u6210\u4e3a\u5b5f\u52a0\u62c9\u6587\u6458\u8981\u4efb\u52a1\u57fa\u51c6\u7684\u6f5c\u529b\uff0c\u5e76\u6709\u52a9\u4e8e\u4f4e\u8d44\u6e90\u8bed\u8a00NLP\u8d44\u6e90\u4e30\u5bcc\u3002", "conclusion": "\u5f00\u53d1\u7684\u591a\u9886\u57df\u5b5f\u52a0\u62c9\u6587\u6458\u8981\u6570\u636e\u96c6\u6709\u6548\u63d0\u5347\u4e86\u6458\u8981\u751f\u6210\u7684\u591a\u6837\u6027\u4e0e\u9002\u5e94\u6027\uff0c\u4e3a\u5b5f\u52a0\u62c9\u6587\u81ea\u7136\u8bed\u8a00\u5904\u7406\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u51c6\u548c\u8d44\u6e90\u3002"}}
{"id": "2511.19333", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.19333", "abs": "https://arxiv.org/abs/2511.19333", "authors": ["Shaltiel Shmidman", "Asher Fredman", "Oleg Sudakov", "Meriem Bendris"], "title": "Learning to Reason: Training LLMs with GPT-OSS or DeepSeek R1 Reasoning Traces", "comment": null, "summary": "Test-time scaling, which leverages additional computation during inference to improve model accuracy, has enabled a new class of Large Language Models (LLMs) that are able to reason through complex problems by understanding the goal, turning this goal into a plan, working through intermediate steps, and checking their own work before answering . Frontier large language models with reasoning capabilities, such as DeepSeek-R1 and OpenAI's gpt-oss, follow the same procedure when solving complex problems by generating intermediate reasoning traces before giving the final answer. Today, these models are being increasingly used to generate reasoning traces that serve as high-quality supervised data for post-training of small and medium-sized language models to teach reasoning capabilities without requiring expensive human curation. In this work, we compare the performance of medium-sized LLMs on Math problems after post-training on two kinds of reasoning traces. We compare the impact of reasoning traces generated by DeepSeek-R1 and gpt-oss LLMs in terms of accuracy and inference efficiency.", "AI": {"tldr": "\u5229\u7528\u5927\u578b\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u76d1\u7763\u6570\u636e\u8bad\u7ec3\u4e2d\u578b\u6a21\u578b\uff0c\u6bd4\u8f83\u4e0d\u540c\u8f68\u8ff9\u6765\u6e90\u5bf9\u6a21\u578b\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u5f71\u54cd\u3002", "motivation": "\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u9ad8\u8d28\u91cf\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u76d1\u7763\u6570\u636e\uff0c\u964d\u4f4e\u4eba\u5de5\u6807\u6ce8\u6210\u672c\uff0c\u63d0\u5347\u4e2d\u7b49\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u5728\u63a8\u7406\u9636\u6bb5\u5229\u7528\u989d\u5916\u8ba1\u7b97\u8d44\u6e90\u751f\u6210\u4e2d\u95f4\u63a8\u7406\u8f68\u8ff9\uff0c\u5bf9\u4e2d\u5c0f\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u540e\u8bad\u7ec3\uff0c\u4ece\u800c\u63d0\u5347\u5176\u590d\u6742\u6570\u5b66\u95ee\u9898\u7684\u89e3\u9898\u80fd\u529b\u3002", "result": "\u5bf9\u6bd4\u4e86\u4f7f\u7528DeepSeek-R1\u548cgpt-oss\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u4f5c\u4e3a\u8bad\u7ec3\u6570\u636e\u540e\uff0c\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u5728\u6570\u5b66\u95ee\u9898\u4e0a\u7684\u51c6\u786e\u7387\u548c\u63a8\u7406\u6548\u7387\uff0c\u53d1\u73b0\u4e24\u79cd\u8f68\u8ff9\u5bf9\u6a21\u578b\u6027\u80fd\u5b58\u5728\u5dee\u5f02\u3002", "conclusion": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684\u63a8\u7406\u8f68\u8ff9\u53ef\u6709\u6548\u63d0\u5347\u4e2d\u7b49\u89c4\u6a21\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\uff0c\u4e0d\u540c\u6765\u6e90\u7684\u8f68\u8ff9\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u5b58\u5728\u6743\u8861\u3002"}}
{"id": "2511.19399", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19399", "abs": "https://arxiv.org/abs/2511.19399", "authors": ["Rulin Shao", "Akari Asai", "Shannon Zejiang Shen", "Hamish Ivison", "Varsha Kishore", "Jingming Zhuo", "Xinran Zhao", "Molly Park", "Samuel G. Finlayson", "David Sontag", "Tyler Murray", "Sewon Min", "Pradeep Dasigi", "Luca Soldaini", "Faeze Brahman", "Wen-tau Yih", "Tongshuang Wu", "Luke Zettlemoyer", "Yoon Kim", "Hannaneh Hajishirzi", "Pang Wei Koh"], "title": "DR Tulu: Reinforcement Learning with Evolving Rubrics for Deep Research", "comment": null, "summary": "Deep research models perform multi-step research to produce long-form, well-attributed answers. However, most open deep research models are trained on easily verifiable short-form QA tasks via reinforcement learning with verifiable rewards (RLVR), which does not extend to realistic long-form tasks. We address this with Reinforcement Learning with Evolving Rubrics (RLER), in which we construct and maintain rubrics that co-evolve with the policy model during training; this allows the rubrics to incorporate information that the model has newly explored and to provide discriminative, on-policy feedback. Using RLER, we develop Deep Research Tulu (DR Tulu-8B), the first open model that is directly trained for open-ended, long-form deep research. Across four long-form deep research benchmarks in science, healthcare and general domains, DR Tulu substantially outperforms existing open deep research models, and matches or exceeds proprietary deep research systems, while being significantly smaller and cheaper per query. To facilitate future research, we release all data, models, and code, including our new MCP-based agent infrastructure for deep research systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86RLER\u65b9\u6cd5\u8bad\u7ec3\u7684DR Tulu-8B\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u9886\u57df\u957f\u7bc7\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u7684\u8868\u73b0\uff0c\u4e14\u5f00\u6e90\u4e86\u76f8\u5173\u8d44\u6e90\u63a8\u52a8\u540e\u7eed\u7814\u7a76\u3002", "motivation": "\u73b0\u6709\u516c\u5f00\u7684\u6df1\u5ea6\u7814\u7a76\u6a21\u578b\u591a\u57fa\u4e8e\u77ed\u7bc7\u4e14\u6613\u9a8c\u8bc1\u7684\u95ee\u7b54\u4efb\u52a1\u8bad\u7ec3\uff0c\u5bf9\u73b0\u5b9e\u4e2d\u9700\u8981\u957f\u7bc7\u3001\u590d\u6742\u63a8\u7406\u7684\u4efb\u52a1\u8868\u73b0\u4e0d\u8db3\uff0c\u4e9f\u9700\u6709\u6548\u8bad\u7ec3\u65b9\u6cd5\u63d0\u5347\u957f\u7bc7\u7814\u7a76\u80fd\u529b\u3002", "method": "\u91c7\u7528\u201c\u5e26\u6f14\u8fdb\u8bc4\u5206\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u201d\uff08RLER\uff09\u65b9\u6cd5\uff0c\u6784\u5efa\u4e0e\u7b56\u7565\u6a21\u578b\u5171\u540c\u6f14\u8fdb\u7684\u8bc4\u5206\u6807\u51c6\uff0c\u4ece\u800c\u63d0\u4f9b\u66f4\u5177\u8fa8\u522b\u529b\u7684\u5b9e\u65f6\u53cd\u9988\uff0c\u76f4\u63a5\u8bad\u7ec3\u6a21\u578b\u5b8c\u6210\u5f00\u653e\u5f0f\u957f\u7bc7\u7b54\u7591\u4efb\u52a1\u3002", "result": "DR Tulu-8B\u5728\u79d1\u5b66\u3001\u533b\u7597\u7b49\u56db\u4e2a\u957f\u7bc7\u6df1\u5ea6\u7814\u7a76\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u660e\u663e\u4f18\u4e8e\u73b0\u6709\u516c\u5f00\u6a21\u578b\uff0c\u5e76\u4e14\u8fbe\u5230\u751a\u81f3\u8d85\u8fc7\u4e86\u4e13\u6709\u7cfb\u7edf\u6c34\u5e73\uff0c\u540c\u65f6\u6a21\u578b\u66f4\u5c0f\u4e14\u67e5\u8be2\u6210\u672c\u66f4\u4f4e\u3002", "conclusion": "\u672c\u8bba\u6587\u63d0\u51fa\u7684\u6df1\u5ea6\u7814\u7a76\u6a21\u578bDR Tulu-8B\u5728\u5f00\u653e\u5f0f\u3001\u957f\u7bc7\u6df1\u5ea6\u7814\u7a76\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u73b0\u6709\u516c\u5f00\u6a21\u578b\uff0c\u5e76\u5339\u914d\u6216\u8d85\u8fc7\u4e13\u6709\u7cfb\u7edf\uff0c\u4e14\u6210\u672c\u66f4\u4f4e\u3002"}}
{"id": "2511.19417", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.19417", "abs": "https://arxiv.org/abs/2511.19417", "authors": ["James Y. Huang", "Sheng Zhang", "Qianchu Liu", "Guanghui Qin", "Tinghui Zhu", "Tristan Naumann", "Muhao Chen", "Hoifung Poon"], "title": "Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86BeMyEyes\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u540c\u9ad8\u6548\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b(VLM)\u611f\u77e5\u5668\u4e0e\u5f3a\u5927\u7684\u5927\u8bed\u8a00\u6a21\u578b(LLM)\u63a8\u7406\u5668\uff0c\u5b9e\u73b0\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u7684\u6269\u5c55\u3002\u8be5\u65b9\u6cd5\u907f\u514d\u4e86\u8bad\u7ec3\u5927\u89c4\u6a21\u591a\u6a21\u6001\u6a21\u578b\u7684\u9ad8\u6210\u672c\uff0c\u5e76\u4fdd\u6301LLM\u7684\u6cdb\u5316\u4e0e\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5927\u89c4\u6a21\u6a21\u578b\u5f00\u53d1\u6210\u672c\u9ad8\uff0c\u4e14\u5c0f\u578bVLM\u7f3a\u4e4f\u5e7f\u6cdb\u77e5\u8bc6\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u5982\u4f55\u9ad8\u6548\u6269\u5c55LLM\u7684\u591a\u6a21\u6001\u63a8\u7406\u80fd\u529b\u6210\u4e3a\u6311\u6218\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u4ee3\u7406\u6846\u67b6BeMyEyes\uff0c\u5206\u522b\u7531\u9ad8\u6548\u7684VLM\u611f\u77e5\u5668\u548c\u5f3a\u5927\u7684LLM\u63a8\u7406\u5668\u7ec4\u6210\uff0c\u901a\u8fc7\u5bf9\u8bdd\u534f\u4f5c\u8fdb\u884c\u591a\u6a21\u6001\u63a8\u7406\uff1b\u5e76\u8bbe\u8ba1\u4e86\u6570\u636e\u5408\u6210\u4e0e\u76d1\u7763\u5fae\u8c03\u6d41\u7a0b\u8bad\u7ec3\u611f\u77e5\u5668\uff0c\u4ee5\u5b9e\u73b0\u4e24\u8005\u7684\u6709\u6548\u534f\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cBeMyEyes\u6846\u67b6\u80fd\u4f7f\u6587\u672c\u6a21\u578b\u7ed3\u5408\u89c6\u89c9\u611f\u77e5\u80fd\u529b\uff0c\u5728\u77e5\u8bc6\u5bc6\u96c6\u7684\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u8d85\u8d8aGPT-4o\u7b49\u5927\u578b\u72ec\u6709\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u5176\u6709\u6548\u6027\u53ca\u53ef\u6269\u5c55\u6027\u3002", "conclusion": "BeMyEyes\u6846\u67b6\u901a\u8fc7\u591a\u4ee3\u7406\u534f\u4f5c\uff0c\u6709\u6548\u878d\u5408\u611f\u77e5\u4e0e\u63a8\u7406\u80fd\u529b\uff0c\u63d0\u5347\u4e86LLM\u5728\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5b9e\u73b0\u4e86\u8f7b\u91cf\u4e14\u5f00\u6e90\u7684\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\uff0c\u4f18\u4e8e\u5927\u578b\u4e13\u6709\u6a21\u578b\u3002"}}
